[{"number": 49228, "title": "[MLIR][DISC] porting dynamic shape related OPs to mhlo and lmhlo dialect", "body": "We are porting our MLIR-based dynamic shape compiler to tf community (From OP def, Patttern, to Optimization pass, etc). \r\nThis is the first PR, which including some dynamic shape OPs def in mhlo and lmhlo dialect.  \r\nFor mhlo dialect, we add:\r\n- HLO_RealDynamicSliceOp\r\n- HLO_DynamicPadOp\r\n- HLO_DynamicGatherOp\r\n- HLO_DynamicConvOp \r\n \r\nFor lmhlo dialect, we add:\r\n- LHLO_RealDynamicSliceOp\r\n- LHLO_DynamicBroadcastInDimOp\r\n- LHLO_DynamicGatherOp\r\n- LHLO_DynamicPadOp\r\n- LHLO_DynamicBitcastOp\r\n- LHLO_DynamicConvOp\r\n- LHLO_DynamicIotaOp\r\n- LHLO_DynamicReshapeOp\r\n- LHLO_DotGeneralOp\r\n- LHLO_BitcastOp\r\n\r\nRest Ops to add:\r\n* We will send a separate PR containing LHLO_DynamicWhileOp and LHLO_DynamicCaseOp for control flow.\r\n* We will add a separate dedicated dialect like mhlo_ral, which including D2HOp/H2DOp/DebugPrintOp/TopKOp, etc.\r\n\r\nPrevious discussions\uff1a[RFC](https://groups.google.com/a/tensorflow.org/g/mlir/c/_X48poNcbDI/m/jCC8BWIICQAJ), [discussion_1](https://llvm.discourse.group/t/updates-on-mlir-based-dynamic-shape-compiler/2384), [Recording of meeting](https://drive.google.com/file/d/1_uEISlV5MUWdG9faKAdKlCWnPtGjRC-D/view?usp=sharing). ", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F49228) for more info**.\n\n<!-- need_sender_cla -->", "\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F49228) for more info**.\n\n<!-- need_sender_cla -->", "\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F49228) for more info**.\n\n<!-- need_sender_cla -->", "> @googlebot I signed it!\r\n\r\n", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F49228) for more info**.\n\n<!-- need_author_cla -->", "> We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors. If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)? If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\r\n> In order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\r\n> \r\n>  **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F49228) for more info**.\r\n\r\n", "> @googlebot I fixed it.\r\n\r\n", "@joker-eph , the PR CI fails. Should I do something or you will handle this issue?", "CI Errors are unrelated.", "> CI Errors are unrelated.\r\n\r\nWhat's next step for this PR?", "You have to wait for it to got through the integration process (runs through our internal test suites, etc.)"]}, {"number": 49227, "title": "```tf.keras.callbacks.EarlyStopping``` always stops at the first epoch", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): google colab\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): 2.5.0\r\n- Python version: 3.8\r\n- CUDA/cuDNN version:  cuda11.2 cudnn8.2.0\r\n- GPU model and memory: gtx1070\r\n\r\n**Describe the current behavior**\r\n\r\n```tf.keras.callbacks.EarlyStopping``` always stops at the first epoch .\r\nHere is the colab :\r\n\r\n[https://colab.research.google.com/drive/1FvWFE26IPrc8vcfbfEGWLPASP6ZJIBPu?usp=sharing](https://colab.research.google.com/drive/1FvWFE26IPrc8vcfbfEGWLPASP6ZJIBPu?usp=sharing)\r\n\r\n**Describe the expected behavior**\r\n\r\nIt should stops at the best epoch like tensorflow2.4.1 .\r\n\r\n\r\n", "comments": ["@DachuanZhao\r\nI Could reproduce the code shared.Please find the [gist](https://colab.research.google.com/gist/UsharaniPagadala/c1e109fd66344c3c8e243b881411303f/untitled1.ipynb).\r\nNote:I changed the code little bit added **patience** keyword,Please let me know if it works\r\nThanks", "> @DachuanZhao\r\n> I Could reproduce the code shared.Please find the [gist](https://colab.research.google.com/gist/UsharaniPagadala/c1e109fd66344c3c8e243b881411303f/untitled1.ipynb).\r\n> Note:I changed the code little bit added **patience** keyword,Please let me know if it works\r\n> Thanks\r\n\r\n\r\nIt works when I change \r\n```\r\ntf.keras.callbacks.EarlyStopping(monitor='val_accuracy',verbose=1,mode=\"max\",restore_best_weights=True)\r\n```\r\nto\r\n```\r\ntf.keras.callbacks.EarlyStopping(monitor='val_accuracy',verbose=1,mode=\"max\",restore_best_weights=True,patience=1e-7)\r\n```\r\nBut the parameter ```patience``` default value is ```0``` , which causes this issue ...", "@DachuanZhao \r\nPatience has to be an integer, it denotes the number of epochs to wait for , 1e-7 is not acceptable form for an epoch as in [this gist](https://colab.research.google.com/gist/UsharaniPagadala/c1e109fd66344c3c8e243b881411303f/untitled1.ipynb)", "> @DachuanZhao\r\n> Patience has to be an integer, it denotes the number of epochs to wait for , 1e-7 is not acceptable form for an epoch as in [this gist](https://colab.research.google.com/gist/UsharaniPagadala/c1e109fd66344c3c8e243b881411303f/untitled1.ipynb)\r\n\r\nGet it . And  I think the default value of  ```patience``` should be ```1``` ...", "@DachuanZhao \r\nplease go through [this link](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping), and [example here](https://machinelearningmastery.com/how-to-stop-training-deep-neural-networks-at-the-right-time-using-early-stopping/).\r\n\r\nDetailed explanation on patience parameter  [is here](https://towardsdatascience.com/a-practical-introduction-to-early-stopping-in-machine-learning-550ac88bc8fd), for any fuurther queries please open a [stackoverflow](https://stackoverflow.com/questions/tagged/tensorflow) link as done [here](https://stackoverflow.com/questions/50284898/keras-earlystopping-which-min-delta-and-patience-to-use) and move this to close status as it is not a bug or a feature request.", "> @DachuanZhao\r\n> please go through [this link](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping), and [example here](https://machinelearningmastery.com/how-to-stop-training-deep-neural-networks-at-the-right-time-using-early-stopping/).\r\n> \r\n> Detailed explanation on patience parameter [is here](https://towardsdatascience.com/a-practical-introduction-to-early-stopping-in-machine-learning-550ac88bc8fd), for any fuurther queries please open a [stackoverflow](https://stackoverflow.com/questions/tagged/tensorflow) link as done [here](https://stackoverflow.com/questions/50284898/keras-earlystopping-which-min-delta-and-patience-to-use) and move this to close status as it is not a bug or a feature request.\r\n\r\nLet me show you the difference between 2.4.1 and 2.5.0 : \r\n\r\n2.4.1:\r\n```Python\r\n  def on_epoch_end(self, epoch, logs=None):\r\n    current = self.get_monitor_value(logs)\r\n    if current is None:\r\n      return\r\n    if self.monitor_op(current - self.min_delta, self.best):\r\n      self.best = current\r\n      self.wait = 0\r\n      if self.restore_best_weights:\r\n        self.best_weights = self.model.get_weights()\r\n    else:\r\n      self.wait += 1\r\n      if self.wait >= self.patience:\r\n        self.stopped_epoch = epoch\r\n        self.model.stop_training = True\r\n        if self.restore_best_weights:\r\n          if self.verbose > 0:\r\n            print('Restoring model weights from the end of the best epoch.')\r\n          self.model.set_weights(self.best_weights)\r\n```\r\n2.5.0 : \r\n```Python\r\n  def on_epoch_end(self, epoch, logs=None):\r\n    current = self.get_monitor_value(logs)\r\n    if current is None:\r\n      return\r\n    if self.restore_best_weights and self.best_weights is None:\r\n      # Restore the weights after first epoch if no progress is ever made.\r\n      self.best_weights = self.model.get_weights()\r\n\r\n    self.wait += 1\r\n    if self._is_improvement(current, self.best):\r\n      self.best = current\r\n      if self.restore_best_weights:\r\n        self.best_weights = self.model.get_weights()\r\n      # Only restart wait if we beat both the baseline and our previous best.\r\n      if self.baseline is None or self._is_improvement(current, self.baseline):\r\n        self.wait = 0\r\n\r\n    if self.wait >= self.patience:\r\n      self.stopped_epoch = epoch\r\n      self.model.stop_training = True\r\n      if self.restore_best_weights and self.best_weights is not None:\r\n        if self.verbose > 0:\r\n          print('Restoring model weights from the end of the best epoch.')\r\n        self.model.set_weights(self.best_weights)\r\n```\r\nIn 2.4.1 , no matter what ```patience``` is, the training will reach the second epoch . But in 2.5.0 , when ```patience = 0``` , the training will stop at  the first epoch . ", "@DachuanZhao \r\nCan you please share a colab gist with the above update, as i do not see any output for the above code.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "> @DachuanZhao\r\n> Can you please share a colab gist with the above update, as i do not see any output for the above code.\r\n\r\nWhat should  I share ? I think you will know what I means if you see the difference of the raw code between 2.4.1 and 2.5.0 ...", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "@DachuanZhao Thanks for creating this issue. This is a bug recently introduced. We will work on it to update. If you are interested in it, you can raise a PR. Thanks!", "> @DachuanZhao Thanks for creating this issue. This is a bug recently introduced. We will work on it to update. If you are interested in it, you can raise a PR. Thanks!\r\n\r\nI have raised a PR at [https://github.com/keras-team/keras/pull/14750](https://github.com/keras-team/keras/pull/14750)  : )", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49227\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49227\">No</a>\n"]}, {"number": 49226, "title": "[nnapi delegate] fix a trivial redundant comment and a typo", "body": "remove a redundant comment `// When using NN API ...` and a typo (?) `: -> .`", "comments": []}, {"number": 49225, "title": "Can't call deprecated functions when embedding Python", "body": "\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.5.0\r\n- Python version: 3.8.8\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**Describe the current behavior**\r\nWhen calling deprecated functions using Python C API, they fail with\r\n\r\n> AttributeError: 'NoneType' object has no attribute 'f_back'\r\n\r\nBecause there's not enough Python stack to be walked\r\n\r\nAny deprecated function will fail with this error.\r\n\r\n**Describe the expected behavior**\r\n\r\nIt should be possible to call deprecated functions using Python C APIs.\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n- Do you want to contribute a PR? (yes/no): yes\r\n- Briefly describe your candidate solution (if contributing): revert [offending commit](https://github.com/tensorflow/tensorflow/commit/42aab9b1f03713757d7c027b23f1113ea80f73ad) or add a check for `f == None` in [this line](https://github.com/tensorflow/tensorflow/blob/704610e1d21288482bf77923b387f9bb6c119318/tensorflow/python/util/deprecation.py#L105)\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n```c\r\nPy_Initialize();\r\nPyObject* tf_test = PyImport_ImportModule(\"tensorflow.test\");\r\nPyObject* is_gpu_available = PyObject_GetAttrString(tf_test, \"is_gpu_available\");\r\nPyObject* haveGpu = PyObject_CallObject(is_gpu_available, NULL); // will return NULL and set Python error state\r\n```\r\n", "comments": ["/cc @mdanatg ", "Looks most likely like a bug in the deprecation API: https://github.com/tensorflow/tensorflow/blob/5fca930c7fb1b302c6d7f1d05a80724028764480/tensorflow/python/util/deprecation.py#L101 \r\n\r\nIt should be straightforward to add a test an an extra check.", "@lostmsu Do you want to contribute a PR?", "I would like to contribute. This might be my first contribution for tensorflow! So, just a check for `f == None` right?", "I have made a pull request. Can you please review it and let me know if this was the expected thing?", "I hope we can close this issue.", "@mdanatg Can you close this?", "Sure. BTW, if you add \"Fixed <issue number>\" to your PR then it gets closed automatically.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49225\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49225\">No</a>\n", "> if you add \"Fixed \" to your PR then it gets closed automatically.\r\n\r\nThanks, It is what I suggest also to the triage and review teams.  To check if the submitted PR is linked or not the issue as they have the permission to link it. Sometimes contributors don't put the auto-connection string in the PR description.", "@bhack What is an auto-connection string?", "> @bhack What is an auto-connection string?\r\n\r\nYou need to use [one of these keywords](https://docs.github.com/en/issues/tracking-your-work-with-issues/linking-a-pull-request-to-an-issue#linking-a-pull-request-to-an-issue-using-a-keyword)\r\n", "Oh great, I didn't know about that! Thank you for sharing! I will definitely use that from next time."]}, {"number": 49224, "title": "Use gpudelegates failed: java.lang.IllegalArgumentException: Internal error: Failed to apply delegate: Attempting to use a delegate that only supports static-sized tensors with a graph that has dynamic-sized tensors.", "body": "Hi,\r\nThanks for the project first.\r\n\r\n### 1. System information\r\n\r\n- OS Platform and Distribution: convert on Linux Ubuntu 20.04\r\n- TensorFlow installation: pip package\r\n- TensorFlow library: 2.4.1\r\n\r\n### 2. Code\r\nThis is the model summary: \r\n\r\n![image](https://user-images.githubusercontent.com/30684101/118437622-8a743580-b715-11eb-8d4f-8dbbc1532540.png)\r\n\r\n\r\nConverter code:\r\nconverter = tf.compat.v1.lite.TFLiteConverter.from_keras_model_file('model.h5')\r\nconverter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\r\ntflite_model = converter.convert()\r\nwith open(modelpath + '/model.tflite', 'wb') as f: \r\n        f.write(tflite_model)\r\nprint(\"save successfully\")\r\n\r\n\r\n### 3. Any other info / logs\r\nI want to deploy a trained model in android with tflite and it has been deployed successfully in cpu, but when I want to use the delegate (like gpu & nnapi) to improve the performance, I get the error info: failed: java.lang.IllegalArgumentException: Internal error: Failed to apply delegate: Attempting to use a delegate that only supports static-sized tensors with a graph that has dynamic-sized tensors.\r\n\r\nI guessed that I may miss some steps to fix the size (maybe the batch size?) after loading the trained model and before converting, but I have no idea what step I missed and what API I should use.\r\n\r\nI also searched the some solution in this repo but I didn't still get the solution. Is there any solution, suggestion, or tutorial, please? \r\n\r\nThanks so much!\r\n", "comments": ["To fix the input shape, you can wrap your trained TF model with the tf.Module to limit the input tensors and output tensors like this [gist](https://colab.research.google.com/gist/abattery/c9c39317664100fa104447099da20574/tflite-signature-example.ipynb).\r\n\r\n", "Solved! Thanks so much!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49224\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49224\">No</a>\n"]}, {"number": 49223, "title": "API to get mean and standard deviation for TFLite Models", "body": "\r\n\r\nIn the example label_image.cc (under) lite/examples/label_image, we are hardcoding mean and standard deviation to 127.5f. How does this change based on model ?\r\nHow can we get these values of mean and standard deviation for any model ? Is there any API to fetch mean and std deviation ? where is this information stored ?\r\nCan these values obtained run time ?\r\n\r\nTo change these mean and standard deviation ? what is the place to change , training ? (or) conversion (or) Inference ?\r\n\r\nWhat is the significance of this mean and std deviation for LSTM(sequence) networks where input is not image ?\r\n\r\n\r\nPlease provide the API to get mean and std deviation values when running inference of any quantized model . \r\n**System information**\r\n- TensorFlow version (you are using): 2.4.1\r\n- Are you willing to contribute it (Yes/No):\r\n\r\n\r\n\r\n\r\n**Who will benefit with this feature?**\r\nWe dont have to specify mean and std deviation explicitly. \r\n", "comments": ["@daverim could you triage this issue?", "@frec could you triage this issue?", "Any update on this ", "@pranathibl,\r\n\r\nCan you please refer this [issue](https://stackoverflow.com/a/67874799/14290681) and let us know if it help you? Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 49222, "title": "Convert layer weights even within nested Functional models.", "body": "Closes #49214", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F49222) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it! ", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F49222) for more info**.\n\n<!-- need_author_cla -->", "I think the missing CLA is for `Bohumir Zamecnik` user commiter.\r\n", "Check that your committer email is the same as the CLA", "@bhack Yeah, thanks. I recommitted it with my personal email."]}, {"number": 49221, "title": "tensorflow lite chatbot and flutter integration", "body": "I would like to know if a chatbot built using tensorflow and exported as tensorflow lite model can be integrated into flutter. ", "comments": ["To use TF lite with flutter see https://pub.dev/packages/tflite\nhttps://pub.dev/packages/tflite_flutter", "@LijaAlex12 ,\r\n\r\nPlease refer the links mentioned and let us know if it helps.Thanks!", "ThIs ticket (example request) is now tracked at https://github.com/am15h/tflite_flutter_plugin/issues/116. \nWe can close this.", "Thank You Very Much.", "@bhack \r\n\r\n ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49221\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49221\">No</a>\n"]}, {"number": 49220, "title": "NotFoundError:  No algorithm worked! Function call stack: train_function", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- Ubuntu 18.04\r\n- TensorFlow installed using PIP\r\n- TensorFlow version (use command below): 2.4.1\r\n- Python version: 3.8.8\r\n- CUDA/cuDNN version: 11.0.228\r\n- GPU model and memory: RTX 2070 super 8GB\r\n\r\n\r\n**Describe the current behavior**\r\nI'm training a model  for NLP with Bert and convolutional layers and gives me the follow error.\r\n\r\n```\r\nNotFoundError:  No algorithm worked!\r\n\t [[node dcnn/conv1d_36/conv1d (defined at <ipython-input-123-fd67c57fea51>:44) ]] [Op:__inference_train_function_434559]\r\n\r\nFunction call stack:\r\ntrain_function\r\n```\r\nThe complete programming is the following:\r\n\r\n```\r\nimport numpy as np\r\nimport math\r\nimport re\r\nimport pandas as pd\r\nimport random\r\n\r\nimport tensorflow as tf\r\nimport tensorflow_hub as hub\r\nfrom tensorflow.keras import layers\r\nimport bert\r\nimport nltk\r\nimport re\r\nimport matplotlib.pyplot as plt\r\n\r\n#Configuraciones \r\nfrom tensorflow.compat.v1 import ConfigProto\r\nfrom tensorflow.compat.v1 import InteractiveSession\r\n\r\nconfig = ConfigProto()\r\nconfig.gpu_options.allow_growth = True\r\nsession = InteractiveSession(config=config)\r\n\r\n\r\nFullTokenizer = bert.bert_tokenization.FullTokenizer\r\n\r\nbert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2\", trainable=False)\r\nvocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\r\ndo_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\r\ntokenizer = FullTokenizer(vocab_file, do_lower_case)\r\n\r\ndef encode_sentence(sent):\r\n    return [\"[CLS]\"] + tokenizer.tokenize(sent) + [\"[SEP]\"]\r\n\r\ndata_inputs = [encode_sentence(sentence) for sentence in train[\"excerpt_lemma\"]]\r\n\r\ndef get_ids(tokens):\r\n    return tokenizer.convert_tokens_to_ids(tokens)\r\n\r\ndef get_mask(tokens):\r\n    return np.char.not_equal(tokens, \"[PAD]\").astype(int)\r\n\r\ndef get_segments(tokens):\r\n    seg_ids = []\r\n    current_seg_id = 0\r\n    for tok in tokens:\r\n        seg_ids.append(current_seg_id)\r\n        if tok == \"[SEP]\":\r\n            current_seg_id = 1-current_seg_id # convierte los 1 en 0 y vice versa\r\n    return seg_ids\r\n\r\n\r\ndata_with_len = [[sent, train[\"target\"][i], len(sent)]\r\n                 for i, sent in enumerate(data_inputs)]\r\n# random.shuffle(data_with_len)\r\n# data_with_len.sort(key=lambda x: x[2])\r\nsorted_all = [({\"input_1\":[get_ids(sent_lab[0]), get_mask(sent_lab[0]), get_segments(sent_lab[0])],\r\n                \"input_2\":data_train.loc[idx].values},\r\n                sent_lab[1])\r\n              for idx, sent_lab in enumerate(data_with_len)]\r\n\r\nall_dataset = tf.data.Dataset.from_generator(lambda: sorted_all,\r\n                                             output_types=({\"input_1\":tf.int32, \"input_2\":tf.float32}, tf.float32),\r\n                                             output_shapes=({\"input_1\":(3, None), \"input_2\":(18,)}, ()))\r\n\r\nBATCH_SIZE = 32\r\nall_batched = all_dataset.padded_batch(BATCH_SIZE,\r\n                                       padded_shapes=({\"input_1\":(3, None), \"input_2\":(18,)},()),\r\n                                       padding_values=({\"input_1\":0, \"input_2\":0.0}, 0.0))\r\n\r\nNB_BATCHES = math.ceil(len(sorted_all) / BATCH_SIZE)\r\nNB_BATCHES_TEST = NB_BATCHES // 10\r\nall_batched.shuffle(NB_BATCHES)\r\n\r\ntest_dataset = all_batched.take(NB_BATCHES_TEST)\r\ntrain_dataset = all_batched.skip(NB_BATCHES_TEST)\r\n\r\nclass DCNNBERTEmbedding(tf.keras.Model):\r\n    \r\n    def __init__(self,\r\n                 nb_filters=50,\r\n                 FFN_units=512,\r\n                 nb_classes=1,\r\n                 dropout_rate=0.1,\r\n                 name=\"dcnn\"):\r\n        super(DCNNBERTEmbedding, self).__init__(name=name)\r\n        \r\n        self.bert_layer = hub.KerasLayer(\r\n            \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2\",\r\n            trainable=False)\r\n\r\n        self.bigram = layers.Conv1D(filters=nb_filters,\r\n                                    kernel_size=2,\r\n                                    padding=\"valid\",\r\n                                    activation=\"relu\")\r\n        self.trigram = layers.Conv1D(filters=nb_filters,\r\n                                     kernel_size=3,\r\n                                     padding=\"valid\",\r\n                                     activation=\"relu\")\r\n        self.fourgram = layers.Conv1D(filters=nb_filters,\r\n                                      kernel_size=4,\r\n                                      padding=\"valid\",\r\n                                      activation=\"relu\")\r\n        self.pool = layers.GlobalMaxPool1D()\r\n        self.dense_1 = layers.Dense(units=FFN_units, activation=\"relu\")\r\n        self.dropout = layers.Dropout(rate=dropout_rate)\r\n        self.last_dense = layers.Dense(units=1,\r\n                                           activation=\"linear\")\r\n    \r\n    def embed_with_bert(self, all_tokens):\r\n        print(\"HOla\")\r\n        _, embs = self.bert_layer([all_tokens[\"input_1\"][:, 0, :],\r\n                                   all_tokens[\"input_1\"][:, 1, :],\r\n                                   all_tokens[\"input_1\"][:, 2, :]])\r\n        return embs\r\n\r\n    def call(self, inputs, training):\r\n        #Par\r\n        x = self.embed_with_bert(inputs)\r\n\r\n        x_1 = self.bigram(x)\r\n        x_1 = self.pool(x_1)\r\n        x_2 = self.trigram(x)\r\n        x_2 = self.pool(x_2)\r\n        x_3 = self.fourgram(x)\r\n        x_3 = self.pool(x_3)\r\n        merged = tf.concat([x_1, x_2, x_3], axis=-1) # (batch_size, 3 * nb_filters)\r\n        merged = self.dense_1(merged)\r\n        merged = self.dropout(merged, training)\r\n        output = self.last_dense(merged)\r\n\r\n        return output\r\n\r\nNB_FILTERS = 20\r\nFFN_UNITS = 20\r\n\r\nDROPOUT_RATE = 0.3\r\n\r\nNB_EPOCHS = 100\r\n\r\nDcnn = DCNNBERTEmbedding(nb_filters=NB_FILTERS,\r\n                         FFN_units=FFN_UNITS,\r\n                         dropout_rate=DROPOUT_RATE)\r\n\r\nDcnn.compile(loss=\"mse\",\r\n             optimizer=\"adam\",\r\n             metrics=[\"mse\", \"mae\"])\r\n\r\nhist = Dcnn.fit(train_dataset,\r\n         epochs=NB_EPOCHS,\r\n         validation_data = test_dataset)\r\n```\r\n\r\nThe complete error is the follow:\r\n\r\n```\r\nNotFoundError                             Traceback (most recent call last)\r\n<ipython-input-156-31a351e764a6> in <module>\r\n----> 1 hist = Dcnn.fit(train_dataset,\r\n      2          epochs=NB_EPOCHS,\r\n      3          validation_data = test_dataset)\r\n\r\n~/Desktop/Projects/kaggle/readability/readability-env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\r\n   1098                 _r=1):\r\n   1099               callbacks.on_train_batch_begin(step)\r\n-> 1100               tmp_logs = self.train_function(iterator)\r\n   1101               if data_handler.should_sync:\r\n   1102                 context.async_wait()\r\n\r\n~/Desktop/Projects/kaggle/readability/readability-env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)\r\n    826     tracing_count = self.experimental_get_tracing_count()\r\n    827     with trace.Trace(self._name) as tm:\r\n--> 828       result = self._call(*args, **kwds)\r\n    829       compiler = \"xla\" if self._experimental_compile else \"nonXla\"\r\n    830       new_tracing_count = self.experimental_get_tracing_count()\r\n\r\n~/Desktop/Projects/kaggle/readability/readability-env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)\r\n    886         # Lifting succeeded, so variables are initialized and we can run the\r\n    887         # stateless function.\r\n--> 888         return self._stateless_fn(*args, **kwds)\r\n    889     else:\r\n    890       _, _, _, filtered_flat_args = \\\r\n\r\n~/Desktop/Projects/kaggle/readability/readability-env/lib/python3.8/site-packages/tensorflow/python/eager/function.py in __call__(self, *args, **kwargs)\r\n   2940       (graph_function,\r\n   2941        filtered_flat_args) = self._maybe_define_function(args, kwargs)\r\n-> 2942     return graph_function._call_flat(\r\n   2943         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\r\n   2944 \r\n\r\n~/Desktop/Projects/kaggle/readability/readability-env/lib/python3.8/site-packages/tensorflow/python/eager/function.py in _call_flat(self, args, captured_inputs, cancellation_manager)\r\n   1916         and executing_eagerly):\r\n   1917       # No tape is watching; skip to running the function.\r\n-> 1918       return self._build_call_outputs(self._inference_function.call(\r\n   1919           ctx, args, cancellation_manager=cancellation_manager))\r\n   1920     forward_backward = self._select_forward_and_backward_functions(\r\n\r\n~/Desktop/Projects/kaggle/readability/readability-env/lib/python3.8/site-packages/tensorflow/python/eager/function.py in call(self, ctx, args, cancellation_manager)\r\n    553       with _InterpolateFunctionError(self):\r\n    554         if cancellation_manager is None:\r\n--> 555           outputs = execute.execute(\r\n    556               str(self.signature.name),\r\n    557               num_outputs=self._num_outputs,\r\n\r\n~/Desktop/Projects/kaggle/readability/readability-env/lib/python3.8/site-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\r\n     57   try:\r\n     58     ctx.ensure_initialized()\r\n---> 59     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\n     60                                         inputs, attrs, num_outputs)\r\n     61   except core._NotOkStatusException as e:\r\n\r\nNotFoundError:  No algorithm worked!\r\n\t [[node dcnn/conv1d_36/conv1d (defined at <ipython-input-123-fd67c57fea51>:44) ]] [Op:__inference_train_function_434559]\r\n\r\nFunction call stack:\r\ntrain_function\r\n```\r\n\r\nIf I try the same code but with one input instead of the dictionary with two inputs, it works. But I don't know why, I think the shapes are correctly, and if were wrong, Tensorflow have a specific error for that!\r\n\r\nCan anyone help with this error please? Thank you", "comments": ["@arubiales \r\n\r\nLooking at the output log, seems like this is similar to issue [#43174](https://github.com/tensorflow/tensorflow/issues/43174).Could you please let us know if it helps.Thanks\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49220\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49220\">No</a>\n"]}, {"number": 49219, "title": "Added tf_logging for deprecated 'experimental_run_v2' (Tf 1.x)", "body": "To resolve PR #49187 , by providing logging messages for  deprecated 'experimental_run_v2'  in Tf 1.x\r\n\r\n", "comments": ["Hi @mihaimaruseac ,\r\ncould you please specify the changes required in this case?  This PR was for adding a logging message regarding the tf version specification.", "But why add the logging messages? We don't add these messages to the other deprecated APIs\r\n", "See also https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/util/deprecation.py", "Hi, \r\nThanks for the link, I think the 'tf_logging' can be done away with, and those can be replaced with the ```@depricated``` decorator instead?\r\nFor instance:\r\n```python\r\n@doc_controls.do_not_doc_inheritable  # DEPRECATED, moving to `extended` \r\n@deprecated(None,'use extended.colocate_vars_with() instead.')\r\n def colocate_vars_with(self, colocate_with_variable):   \r\n      \"\"\"DEPRECATED: use extended.colocate_vars_with() instead.\"\"\"    \r\n      return self._extended.colocate_vars_with(colocate_with_variable)\r\n```\r\nThanks\r\n", " I have added the deprecated decorators ,please let me know if any changes are required", "Adding Ran to review the distrstrat changes", "Reverted the decorator changes for TF1.x Strategy objects , please let me know if any changes are required.", "Hi @crccw  @mihaimaruseac , I see that after merging the master in my remote, google butler removed the ready to pull tag. Can the tag be re-assigned?", "Resolved spaces, let me know if any other changes required."]}, {"number": 49218, "title": "Fixed Accuracy to be able to transform dynamically", "body": "Fixes #42383\r\n\r\ncc: @mihaimaruseac , @bhack , @SamuelMarks , @nikitamaia ", "comments": []}, {"number": 49217, "title": "TF 2.0 'Tensor' object has no attribute 'numpy' while using .numpy() when use disable_eager_execution()", "body": "I need to convert tensor to numpy array in Graph mode.", "comments": ["Check https://github.com/tensorflow/tensorflow/issues/27519#issuecomment-490388556", "> Check [#27519 (comment)](https://github.com/tensorflow/tensorflow/issues/27519#issuecomment-490388556)\r\n\r\nThank you!   For some reason, I have to use Graph mode in my code and would like to find a solution.", "If you expect to autoconvert a Tensor to numpy in graph mode we cannot support this. \r\nFor the details see https://github.com/tensorflow/tensorflow/issues/38887", "@SongyiGao \r\nWe do not suppport tensor to numpy in graph mode, you can try with the [experimental numpy API](https://www.tensorflow.org/api_docs/python/tf/experimental/numpy).", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 49216, "title": "ERROR when benchmarking TFLite model \"ERROR: Given shapes, [1, 40, 23, 256] and [1, 23, 40, 256], are not broadcastable.\"", "body": "**System information**\r\n- Have I written custom code: Yes\r\n- OS Platform and Distribution: Ubuntu 20.04/Android 10\r\n- Mobile device: Xiaomi Redmi Note 7\r\n- TensorFlow installed from: pip\r\n- TensorFlow version: v2.4.0-49-g85c8b2a817f 2.4.1\r\n- Python version: Python 3.8.8\r\n\r\n**Describe the current behavior**\r\nI am training a model and converting it to TFLite but when benchmarking it on TFLite I got an unexpected error shown below.\r\n```\r\nERROR: Given shapes, [1, 40, 23, 256] and [1, 23, 40, 256], are not broadcastable.\r\nERROR: Node number 80 (ADD) failed to prepare.\r\n```\r\n\r\n**Describe the expected behavior**\r\nSince the training works and that the shapes are good when I visualize the model in [netron](https://netron.app/), I expect it to work.\r\n![image](https://user-images.githubusercontent.com/43449205/118394198-78c25d80-b643-11eb-8b43-c55521453662.png)\r\n\r\n**Standalone code to reproduce the issue**\r\nI am running the benchmark using the native tool which includes TFOps and Flex Delegate that can be downloaded [here](https://storage.googleapis.com/tensorflow-nightly-public/prod/tensorflow/release/lite/tools/nightly/latest/android_arm_benchmark_model_plus_flex).\r\n\r\nMy model can be downloaded [here](https://github.com/tensorflow/tensorflow/files/6489086/model.zip).\r\nI run the benchmark on an android device using the following lines:\r\n```\r\nadb push android_arm_benchmark_model_plus_flex /data/local/tmp/benchmark\r\nadb shell chmod +x /data/local/tmp/benchmark\r\nadb push model.tflite /data/local/tmp/model.tflite\r\nadb shell \"/data/local/tmp/benchmark\"  --graph=\"/data/local/tmp/model.tflite\" --use_gpu=true --input_layer=input,scale_input --input_layer_shape=1,640,360,3:1,4\r\n```\r\n\r\nI do not understand where the error could be coming from since can train and run inference on the Tensorflow model and that the graph in Netron is good.\r\n\r\nThanks in advance!\r\n\r\n\r\n", "comments": ["@yann-pourcenoux could you try TF -> TFLite model conversion with the tf-nightly version to see the above issue already fixed? If possible, please share a minimal reproducible step for the TFLite conversion.", "Thanks for your quick reply @abattery, I just tried with tf-nightly `2.6.0-dev20210516` and the error is still the same. I convert my model by doing:\r\n```\r\nmobile_model = create_model(...) # I'd rather not share this\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(mobile_model)\r\n\r\n# Set the optimizations of quantization \r\nconverter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\r\n\r\n# Experimental environment\r\nconverter.experimental_new_converter = True\r\nconverter.experimental_new_quantizer = True\r\nconverter.target_spec.supported_ops = [\r\n    tf.lite.OpsSet.TFLITE_BUILTINS,  # enable TensorFlow Lite ops.\r\n    tf.lite.OpsSet.SELECT_TF_OPS,  # enable TensorFlow ops.\r\n]\r\n\r\n# Converting model\r\ntflite_model = converter.convert()\r\nwith open(tflite_filepath, \"wb\") as f:\r\n    f.write(tflite_model)\r\n```\r\n", "Sorry. It is really hard to reproduce your issue at our end. Please consider creating the simple and minimal reproducible steps as a gist and share it to us if possible.", "While creating a script to reproduce the issue, I realized I swapped the axis when specifying the input_shape for the benchmark. The error was then totally on my side.\r\nWould adding something to ensure that the model is fed the expected shape be possible to prevent such mistakes?\r\nAnyway, thanks again @abattery for your quick reply!", "Thanks for the confirmation!\r\n\r\n@multiverse-tf could you take a look at https://github.com/tensorflow/tensorflow/issues/49216#issuecomment-842566632?", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49216\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49216\">No</a>\n", "> While creating a script to reproduce the issue, I realized I swapped the axis when specifying the input_shape for the benchmark. The error was then totally on my side.\r\n> Would adding something to ensure that the model is fed the expected shape be possible to prevent such mistakes?\r\n\r\nGood suggestion! Will add more input-shape-related checks asap.\r\n\r\n> Anyway, thanks again @abattery for your quick reply!\r\n\r\n"]}, {"number": 49215, "title": "merge from ctr-opt-1.15 to tensorflow master .", "body": "Issue:https://github.com/tensorflow/tensorflow/issues/49212", "comments": ["@allenlavoie  auto check  wget 404 error . @gbaned ", "Given the 2 vs. 3 dim issue it looks like there's definitely not enough test coverage. Could you add some tests that exercise the new path?\r\n\r\nOtherwise it looks good.", "> Given the 2 vs. 3 dim issue it looks like there's definitely not enough test coverage. Could you add some tests that exercise the new path?\r\n> \r\n> Otherwise it looks good.\r\n\r\nGet, I will add some test about 2D, 3D."]}, {"number": 49214, "title": "RNN weight conversion not applied within nested Functional models", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **no**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **any**, tested on MacOS \r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: -\r\n- TensorFlow installed from (source or binary): **binary** (independent)\r\n- TensorFlow version (use command below): since **v2.3.0-rc0**, present in latest\r\n  - since refactoring https://github.com/tensorflow/tensorflow/commit/bb15c97379f197a6a46ec1446d8fb0b292b860ba\r\n- Python version: **any**, 3.7 (independent)\r\n- Bazel version (if compiling from source): -\r\n- GCC/Compiler version (if compiling from source): -\r\n- CUDA/cuDNN version: **any** (independent)\r\n- GPU model and memory: -\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\nThe function `convert_nested_model()` nested within `keras.saving.load_model_from_hdf5()` converts layers only nested within `Model` or `Sequential` submodels, but not yet `Functional`.\r\n\r\nFor a model where GRU is within Functional nested model, trained with CuDNN, conversion when loading without CuDNN is not applied.\r\n\r\nThe result is that loading fails when setting weight values of incompatible shape.\r\n\r\n**Describe the expected behavior**\r\n\r\nThe conversion is applied to GRU weights even when the layer is nested within a Functional submodel.\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)** - Do you\r\nwant to contribute a PR? (yes/no): - Briefly describe your candidate solution\r\n(if contributing):\r\n\r\nYes. I contributed the original code of some of those conversions.\r\n\r\nhttps://github.com/keras-team/keras/pull/10081\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\nI will provide a minimal example for reproduction.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\n```\r\n# in K.batch_set_value() for the GRU bias (CuDNN-compatible, ie .reset_after=True)\r\nassign_op = x.assign(assign_placeholder)\r\n\r\nself:\r\n<tf.Variable 'gru_18/gru_cell_30/bias:0' shape=(2, 384) dtype=float32>\r\nvalue:\r\n<tf.Tensor 'Placeholder_173:0' shape=(?,) dtype=float32>\r\n```\r\n\r\nThe bias value array is 768 and placeholder shape is `(?,)` (1D). It's missin conversion to proper shape: `(2, 384)` (as the variable has).\r\n\r\n## Proposed solution\r\n\r\nI tried adding the `'Functional'` to the list of nested class names to be be converted.\r\n\r\n```\r\n- elif layer.__class__.__name__ in ['Model', 'Sequential']:\r\n+ elif layer.__class__.__name__ in ['Model', 'Sequential', 'Functional']:\r\n```\r\n\r\nAnd the whole model loaded correctly.\r\n\r\n+ make unit tests\r\n", "comments": ["Thanks, can you open a PR with tests?", "Yes, I'm going to prepare some simple code for reproduction and unit tests.", "It looks that there's an existing test in [cudnn_recurrent_test.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/layers/cudnn_recurrent_test.py#L274\r\n) but for some reason has been [disabled](https://github.com/tensorflow/tensorflow/commit/8d25e4bf616b7ae4ed101c580a23421616bf674c). It was done just before v2.3.0-rc0 so it's likely caused by the bug described above.\r\n\r\n```\r\n  # TODO(b/156439419): Reenable after the bug is fixed.\r\n  @parameterized.named_parameters(\r\n      *testing_utils.generate_combinations_with_testcase_name(\r\n          rnn_type=['LSTM', 'GRU'], to_cudnn=[True, False],\r\n          bidirectional=[True, False], implementation=[1, 2],\r\n          model_nest_level=[1, 2], model_type=['seq', 'func']))\r\n  @test_util.run_v1_only('b/120911602, b/112083752')\r\n  @test_util.run_gpu_only\r\n  def DISALBED_test_load_weights_between_noncudnn_rnn(\r\n```\r\n", "A workaround to patch the module before the new Tensorflow is released (or for older TF 2 installations):\r\n\r\n```\r\nimport importlib\r\nfrom tensorflow.python.keras.saving import hdf5_format\r\n\r\nfilename = hdf5_format.__file__\r\nwith open(filename, 'r') as f:\r\n    content = f.read()\r\nif \"['Model', 'Sequential']\" in content:\r\n    print(f'Patching {filename} to support nested Functional model...')\r\n    content = content.replace(\"['Model', 'Sequential']\", \"['Model', 'Sequential', 'Functional']\")\r\n    with open(filename, 'w') as f:\r\n        f.write(content)\r\n\r\n    importlib.reload(hdf5_format)\r\n```", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49214\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49214\">No</a>\n"]}, {"number": 49213, "title": "Makefile: No such file or directory ( Windows )", "body": "@tensorflow/micro\r\n\r\n**System information**\r\n- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- TensorFlow installed from (source or binary):\r\n- Tensorflow version (commit SHA if source):\r\n- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.):\r\n\r\n**Describe the problem**\r\nTrying to run the test_hello_world_test with make command, yet the Makefile is not present although I checked its presence in the directory...\r\n**Please provide the exact sequence of commands/steps when you ran into the problem**\r\n\r\n![issue](https://user-images.githubusercontent.com/44801135/118394269-8ffd4d00-b63b-11eb-8679-8b448965172b.jpg)\r\n", "comments": ["Can you please remove `test_` prefix and try again?\r\n`make -f tensorflow/lite/micro/tools/make/Makefile hello_world_test`", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49213\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49213\">No</a>\n"]}, {"number": 49212, "title": "Add a new split way in split_v_op.cc", "body": "Now tensorflow has two way to split tensor.\r\n1. Split tensor by single thread.\r\n2. Split tensor by multi-thread.\r\nThe current data split method is not very uniform, like:\r\n![image](https://user-images.githubusercontent.com/33950866/118393504-1f255780-b672-11eb-83b0-b39e9a580392.png)\r\nWe should add a new parallel split way. like:\r\n![image](https://user-images.githubusercontent.com/33950866/118393518-2fd5cd80-b672-11eb-8f0b-eb1c1f999814.png)\r\n\r\nexample:\r\n```\r\nimport tensorflow as tf\r\nimport time\r\nsess_config = tf.ConfigProto(allow_soft_placement=False,\r\n                             log_device_placement=True)\r\n\r\ncount = 3\r\nkeys = tf.random_uniform(shape=[4800, 107, 9], dtype=tf.int64, maxval=int(1e8))\r\narr = []\r\nfor i in range(0, 30):\r\n  arr.append(1)\r\narr.append(77)\r\nret = tf.split(keys, arr, axis=1)\r\n\r\nsess = tf.Session(config = sess_config)\r\n\r\nstart = time.time()\r\nfor i in range(0, 10):\r\n    _ = sess.run(ret)\r\nprint('split_v seconds: %f' % (time.time() - start))\r\n```\r\nperformance: 0.308505s vs 0.188766s", "comments": ["I am happy to contribute my code", "The issue will move to closed status once the PR is merged.", "Moving this to closed status as pr is merged."]}, {"number": 49211, "title": "C++ compilation of rule '@llvm-project//llvm:Passes' failed", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.5 LTS\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: \r\n- TensorFlow installed from (source or binary): source (2.5.0 release)\r\n- TensorFlow version: 2.5.0\r\n- Python version: 3.8.7 GCC 7.5.0\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source): 3.7.2\r\n- GCC/Compiler version (if compiling from source): 7.5.0\r\n- CUDA/cuDNN version: 11.3 / 8.2 \r\n- GPU model and memory: NVIDIA GTX 1070 Ti / 8GB\r\n\r\n**Describe the problem**\r\nDuring the \r\nbuild process following error is thrown: \r\n[Logs+Config.zip](https://github.com/tensorflow/tensorflow/files/6488908/Logs%2BConfig.zip)\r\n\r\n```C++ compilation of rule '@llvm-project//llvm:Passes' failed (Exit 4): crosstool_wrapper_driver_is_not_gcc failed: error executing command external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -MD -MF bazel-out/host/bin/external/llvm-project/llvm/_objs/Passes/PassBuilder.pic.d ... (remaining 59 argument(s) skipped)```\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nDetailed config and log files attached.\r\n\r\nconfig => bazel build --local_ram_resources=4096 //tensorflow/tools/pip_package:build_pip_package\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["Any input?\r\n", "Any update?\r\n", "Closing due to no more updates", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49211\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49211\">No</a>\n"]}, {"number": 49210, "title": "Windows Bazel build always fails", "body": "While raising pull request, windows bazel tests always fails because of build failure. For example, you can look at this PR #49018\n\n**Describe the expected behavior**\nBuild should fail only if test cases are failing.\n\n**[Contributing](https://www.tensorflow.org/community/contribute)** - Do you\nwant to contribute a PR? (yes/no): - Briefly describe your candidate solution\n(if contributing): I want to contribute but I don't know the exact source of issue. If someone can guide me, I will raise PR.", "comments": ["Looks like it is fixed now. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49210\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49210\">No</a>\n"]}, {"number": 49209, "title": "Linking of rule '//tensorflow/python:_pywrap_tensorflow_internal.so' failed", "body": "### System information\r\n- OS: Linux Debian 9 Stretch\r\n- TensorFlow installed from (source or binary): source \r\n- TensorFlow version: 2.5.0\r\n- Python version: 3.6 - 3.9\r\n- Installed using: pip\r\n- Bazel version: 3.7.2\r\n- GCC/Compiler version: 6.3.0\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n### Describe the problem\r\n\r\nHi.\r\n\r\nI'm trying to build TensorFlow v2.5.0 on a Raspberry Pi 4B. The environment (Docker) I'm using is `quay.io/pypa/manylinux_2_24_aarch64`.\r\n\r\nWhen bazel is executing `Linking tensorflow/python/_pywrap_tensorflow_internal.so`, it always failed after about 1 minute.\r\n\r\nDuring this process...\r\n* the RAM is not insufficient\r\n* disk should be OK (space is enough, and `fsck` returns no error)\r\n* I didn't notice any other potential errors\r\n\r\n###  Provide the exact sequence of commands / steps that you executed before running into the problem\r\n\r\nFull logs here:\r\n\r\n```\r\nroot@70a1a1f01b03:~/tf/src/tensorflow# ./configure\r\nYou have bazel 3.7.2 installed.\r\nPlease specify the location of python. [Default is /usr/bin/python3]: /opt/python/cp38-cp38/bin/python3\r\n\r\n\r\nFound possible Python library paths:\r\n  /opt/python/cp38-cp38/lib/python3.8/site-packages\r\nPlease input the desired Python library path to use.  Default is [/opt/python/cp38-cp38/lib/python3.8/site-packages]\r\n\r\nDo you wish to build TensorFlow with ROCm support? [y/N]:\r\nNo ROCm support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with CUDA support? [y/N]:\r\nNo CUDA support will be enabled for TensorFlow.\r\n\r\nDo you wish to download a fresh release of clang? (Experimental) [y/N]:\r\nClang will not be downloaded.\r\n\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -Wno-sign-compare]:\r\n\r\n\r\nWould you like to interactively configure ./WORKSPACE for Android builds? [y/N]:\r\nNot configuring the WORKSPACE for Android builds.\r\n\r\nPreconfigured Bazel build configs. You can use any of the below by adding \"--config=<>\" to your build command. See .bazelrc for more details.\r\n        --config=mkl            # Build with MKL support.\r\n        --config=mkl_aarch64    # Build with oneDNN and Compute Library for the Arm Architecture (ACL).\r\n        --config=monolithic     # Config for mostly static monolithic build.\r\n        --config=numa           # Build with NUMA support.\r\n        --config=dynamic_kernels        # (Experimental) Build kernels into separate shared objects.\r\n        --config=v2             # Build TensorFlow 2.x instead of 1.x.\r\nPreconfigured Bazel build configs to DISABLE default on features:\r\n        --config=noaws          # Disable AWS S3 filesystem support.\r\n        --config=nogcp          # Disable GCP support.\r\n        --config=nohdfs         # Disable HDFS support.\r\n        --config=nonccl         # Disable NVIDIA NCCL support.\r\nConfiguration finished\r\nroot@70a1a1f01b03:~/tf/src/tensorflow#\r\n```\r\n\r\n```\r\nroot@70a1a1f01b03:~/tf/src/tensorflow# bazel build --config=noaws --config=nogcp --config=nohdfs --config=nonccl //tensorflow/tools/pip_package:build_pip_package --verbose_failures\r\nStarting local Bazel server and connecting to it...\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=146\r\nINFO: Reading rc options for 'build' from /root/tf/src/tensorflow/.bazelrc:\r\n  Inherited 'common' options: --experimental_repo_remote_exec\r\nINFO: Reading rc options for 'build' from /root/tf/src/tensorflow/.bazelrc:\r\n  'build' options: --define framework_shared_object=true --java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --host_java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2\r\nINFO: Reading rc options for 'build' from /root/tf/src/tensorflow/.tf_configure.bazelrc:\r\n  'build' options: --action_env PYTHON_BIN_PATH=/opt/python/cp38-cp38/bin/python3 --action_env PYTHON_LIB_PATH=/opt/python/cp38-cp38/lib/python3.8/site-packages --python_path=/opt/python/cp38-cp38/bin/python3\r\nINFO: Found applicable config definition build:short_logs in file /root/tf/src/tensorflow/.bazelrc: --output_filter=DONT_MATCH_ANYTHING\r\nINFO: Found applicable config definition build:v2 in file /root/tf/src/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1\r\nINFO: Found applicable config definition build:noaws in file /root/tf/src/tensorflow/.bazelrc: --define=no_aws_support=true\r\nINFO: Found applicable config definition build:nogcp in file /root/tf/src/tensorflow/.bazelrc: --define=no_gcp_support=true\r\nINFO: Found applicable config definition build:nohdfs in file /root/tf/src/tensorflow/.bazelrc: --define=no_hdfs_support=true\r\nINFO: Found applicable config definition build:nonccl in file /root/tf/src/tensorflow/.bazelrc: --define=no_nccl_support=true\r\nINFO: Found applicable config definition build:linux in file /root/tf/src/tensorflow/.bazelrc: --copt=-w --host_copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels\r\nINFO: Found applicable config definition build:dynamic_kernels in file /root/tf/src/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS\r\nINFO: Analyzed target //tensorflow/tools/pip_package:build_pip_package (404 packages loaded, 31040 targets configured).\r\nINFO: Found 1 target...\r\n[16,226 / 16,343] 4 actions, 1 running\r\n    Linking tensorflow/python/_pywrap_tensorflow_internal.so; 38s local\r\n    [Sched] Linking tensorflow/lite/python/interpreter_wrapper/_pywrap_tensorflow_interpreter_wrapper.so; 38s\r\n    [Sched] Linking tensorflow/python/_pywrap_tensorflow_internal.so [for host]; 37s\r\n    [Sched] Executing genrule @pasta//:augment/import_utils_py; 36s\r\nERROR: /root/tf/src/tensorflow/tensorflow/python/BUILD:5209:24: Linking of rule '//tensorflow/python:_pywrap_tensorflow_internal.so' failed (Exit 1): gcc failed: error executing command\r\n  (cd /root/.cache/bazel/_bazel_root/76de584e4721ac61540ca47fce08b572/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    LD_LIBRARY_PATH='' \\\r\n    PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \\\r\n    PWD=/proc/self/cwd \\\r\n    PYTHON_BIN_PATH=/opt/python/cp38-cp38/bin/python3 \\\r\n    PYTHON_LIB_PATH=/opt/python/cp38-cp38/lib/python3.8/site-packages \\\r\n    TF2_BEHAVIOR=1 \\\r\n  /usr/bin/gcc @bazel-out/aarch64-opt/bin/tensorflow/python/_pywrap_tensorflow_internal.so-2.params)\r\nExecution platform: @local_execution_config_platform//:platform\r\n/usr/bin/ld.gold: internal error in maybe_apply_stub, at ../../gold/aarch64.cc:5407\r\ncollect2: error: ld returned 1 exit status\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 355.787s, Critical Path: 77.11s\r\nINFO: 51 processes: 10 internal, 41 local.\r\nFAILED: Build did NOT complete successfully\r\nroot@70a1a1f01b03:~/tf/src/tensorflow#\r\n```\r\n\r\n### Others\r\n* This error has been reproduced on Python 3.8 and 3.9.\r\n* The exact same env and commands could successfully build TF v2.4.1 and earlier versions.\r\nIs there any possibility that is because of some new features in the latest version?\r\n\r\nThank you.", "comments": ["@KumaTea ,\r\n\r\nPlease refer the issues #48733, #48761 for similar error log.\r\n\r\nThanks!\r\n", "Thank you for your reply!\r\n\r\nI'm rebuilding with gcc v7 and checking the issues above. Maybe reporting the results in a day or two.", "Hi.\r\n\r\nI tried to use CentOS 7 this time, and manually installed gcc v7.3. However, the error logs are exactly same:\r\n\r\n```\r\n[root@3ac591ee12cb ~]# scl enable devtoolset-7 bash\r\n[root@3ac591ee12cb ~]# cd tf/src/tensorflow/\r\n[root@3ac591ee12cb tensorflow]# BAZEL_LINKLIBS=-l%:libstdc++.a bazel build --config=noaws --config=nogcp --config=nohdfs --config=nonccl //tensorflow/tools/pip_package:build_pip_package\r\nStarting local Bazel server and connecting to it...\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=220\r\nINFO: Reading rc options for 'build' from /root/tf/src/tensorflow/.bazelrc:\r\n  Inherited 'common' options: --experimental_repo_remote_exec\r\nINFO: Reading rc options for 'build' from /root/tf/src/tensorflow/.bazelrc:\r\n  'build' options: --define framework_shared_object=true --java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --host_java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2\r\nINFO: Reading rc options for 'build' from /root/tf/src/tensorflow/.tf_configure.bazelrc:\r\n  'build' options: --action_env PYTHON_BIN_PATH=/opt/python/cp39-cp39/bin/python3 --action_env PYTHON_LIB_PATH=/opt/python/cp39-cp39/lib/python3.9/site-packages --python_path=/opt/python/cp39-cp39/bin/python3\r\nINFO: Found applicable config definition build:short_logs in file /root/tf/src/tensorflow/.bazelrc: --output_filter=DONT_MATCH_ANYTHING\r\nINFO: Found applicable config definition build:v2 in file /root/tf/src/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1\r\nINFO: Found applicable config definition build:noaws in file /root/tf/src/tensorflow/.bazelrc: --define=no_aws_support=true\r\nINFO: Found applicable config definition build:nogcp in file /root/tf/src/tensorflow/.bazelrc: --define=no_gcp_support=true\r\nINFO: Found applicable config definition build:nohdfs in file /root/tf/src/tensorflow/.bazelrc: --define=no_hdfs_support=true\r\nINFO: Found applicable config definition build:nonccl in file /root/tf/src/tensorflow/.bazelrc: --define=no_nccl_support=true\r\nINFO: Found applicable config definition build:linux in file /root/tf/src/tensorflow/.bazelrc: --copt=-w --host_copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels\r\nINFO: Found applicable config definition build:dynamic_kernels in file /root/tf/src/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS\r\nINFO: Analyzed target //tensorflow/tools/pip_package:build_pip_package (404 packages loaded, 31040 targets configured).\r\nINFO: Found 1 target...\r\nINFO: Deleting stale sandbox base /root/.cache/bazel/_bazel_root/76de584e4721ac61540ca47fce08b572/sandbox\r\n```\r\n\r\n```\r\n[16,166 / 16,305] 4 actions, 3 running\r\nERROR: /root/tf/src/tensorflow/tensorflow/python/BUILD:5209:24: Linking of rule '//tensorflow/python:_pywrap_tensorflow_internal.so' failed (Exit 1): gcc failed: error executing command /opt/rh/devtoolset-7/root/usr/bin/gcc @bazel-out/host/bin/tensorflow/python/_pywrap_tensorflow_internal.so-2.params\r\nbazel-out/host/bin/external/com_github_grpc_grpc/_objs/gpr_base/string.pic.o:string.cc:function gpr_leftpad(char const*, char, unsigned long): warning: memset used with constant zero length parameter; this could be due to transposed parameters\r\n/opt/rh/devtoolset-7/root/usr/bin/ld.gold: internal error in maybe_apply_stub, at aarch64.cc:5407\r\ncollect2: error: ld returned 1 exit status\r\n[16,302 / 16,407] checking cached actions\r\n\r\nServer terminated abruptly (error code: 14, error message: 'Socket closed', log file: '/root/.cache/bazel/_bazel_root/76de584e4721ac61540ca47fce08b572/server/jvm.out')\r\n\r\n[root@3ac591ee12cb tensorflow]#\r\n```\r\n\r\n---\r\n\r\nI would stop trying for now and use [Linaro's build](https://snapshots.linaro.org/ldcg/python/tensorflow-manylinux/latest/tensorflow-cpu/) instead.\r\n\r\nThank you!", "I remember that there was other issues with gcc 7.3 https://github.com/tensorflow/tensorflow/issues/25323\r\nCan you try to build in the official ARM AArch64 images instead of `quay.io/pypa/manylinux_2_24_aarch64` https://community.arm.com/developer/tools-software/tools/b/tools-software-ides-blog/posts/aarch64-docker-images-for-tensorflow-and-pytorch", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49209\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49209\">No</a>\n"]}, {"number": 49208, "title": "Model.fit() + LearningRateSchedule ignores initial_epoch/steps_per_epoch, giving wrong learning rates when resuming from checkpoints", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes (see below)\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab, Ubuntu 20.04, Windows 10\r\n- TensorFlow installed from (source or binary): (preinstalled), (custom package), binary (pip)\r\n- TensorFlow version (use command below): v2.4.1-0-g85c8b2a817f 2.4.1, unknown 2.6.0, v2.4.0-49-g85c8b2a817f 2.4.1\r\n- Python version: Python 3.7.10, Python 3.8.5, Python 3.7.9\r\n\r\n**Describe the current behavior**\r\n\r\nWhen training using a LearningRateSchedule, Optimizer and Model.fit(), the learning rate schedule ignores \"initial_epoch\" and \"steps_per_epoch\", so when starting a new session to resume training from a checkpoint, OptimizerV2._iterations and the resulting learning rate will be incorrect.\r\n\r\n**Describe the expected behavior**\r\n\r\nModel.fit() sees that \"initial_epoch\" and \"steps_per_epoch\" have been specified, and assigns \"initial_epoch * steps_per_epoch\" to OptimizerV2._iterations so that training can resume correctly.\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\ninput = tf.keras.layers.Input(shape=(2), dtype=tf.float32)\r\noutput = tf.keras.layers.Dense(1, activation=\"relu\")(input)\r\nmodel = tf.keras.Model(input, output)\r\n\r\nlearning_rate_schedule = tf.keras.optimizers.schedules.PiecewiseConstantDecay([10], [0.5, 0.25])\r\noptimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate_schedule)\r\nmodel.compile(optimizer=optimizer, loss=\"mse\")\r\n\r\nclass ValidationCallback(tf.keras.callbacks.Callback):\r\n\r\n  def __init__(self, expected):\r\n    self.expected = expected\r\n    self.actual = []\r\n\r\n  def on_train_batch_end(self, batch, logs=None):\r\n    self.actual.append(tf.keras.backend.get_value(self.model.optimizer.learning_rate(self.model.optimizer._iterations)).item())\r\n\r\n  def on_train_end(self, logs=None):\r\n    if self.actual == self.expected:\r\n      print(\"Good\")\r\n    else:\r\n      print(f\"Bug: Expected {self.expected}, actual {self.actual}\")\r\n\r\nvalues = tf.range(20, dtype=tf.float32)\r\ninputs = tf.stack([values, values], axis=1)\r\noutputs = values * 2.0\r\ndataset = tf.data.Dataset.from_tensor_slices((inputs, outputs))\r\ndataset = dataset.batch(1)\r\n\r\n# Call fit() for steps 1-20.\r\nprint(\"Test 1\")\r\nmodel.fit(dataset, epochs=2, initial_epoch=0, steps_per_epoch=10, callbacks=[ValidationCallback([0.5] * 10 + [0.25] * 10)], verbose=0)\r\n\r\n# Call fit() for steps 1-20 again (bug: the optimizer just retains its iterations, rather than calculating from epochs + initial_epoch + steps_per_epoch).\r\nprint(\"Test 2\")\r\nmodel.fit(dataset, epochs=2, initial_epoch=0, steps_per_epoch=10, callbacks=[ValidationCallback([0.5] * 10 + [0.25] * 10)], verbose=0)\r\n\r\n# Call fit() for steps 1-20 a third time (work around the bug by resetting iterations).\r\nprint(\"Test 3\")\r\nmodel.optimizer.iterations.assign(0, read_value=False)\r\nmodel.fit(dataset, epochs=2, initial_epoch=0, steps_per_epoch=10, callbacks=[ValidationCallback([0.5] * 10 + [0.25] * 10)], verbose=0)\r\n\r\n# Call fit() for steps 11-20 (bug: should calculate iterations from epochs + initial_epoch + steps_per_epoch - very important when resuming training from a checkpoint).\r\nprint(\"Test 4\")\r\nmodel.optimizer.iterations.assign(0, read_value=False)\r\nmodel.fit(dataset, epochs=2, initial_epoch=1, steps_per_epoch=10, callbacks=[ValidationCallback([0.25] * 10)], verbose=0)\r\n\r\n# Call fit() for steps 11-20 (work around the bug by manually initializing iterations)\r\nprint(\"Test 5\")\r\ninitial_epoch = 1\r\nsteps_per_epoch = 10\r\nmodel.optimizer.iterations.assign(initial_epoch * steps_per_epoch, read_value=False)\r\nmodel.fit(dataset, epochs=2, initial_epoch=initial_epoch, steps_per_epoch=steps_per_epoch, callbacks=[ValidationCallback([0.25] * 10)], verbose=0)\r\n```\r\n\r\n**Other info / logs**\r\n\r\n```\r\nTest 1\r\nGood\r\nTest 2\r\nBug: Expected [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25], actual [0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, \r\n0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]\r\nTest 3\r\nGood\r\nTest 4\r\nBug: Expected [0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25], actual [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\r\nTest 5\r\nGood\r\n```\r\n", "comments": ["Was able to reproduce the issue using TF 2.4 and Nighty version as well. Please find the gist [here](https://colab.research.google.com/gist/saikumarchalla/d15d443885f2d85552b14cc5c9d6f594/untitled72.ipynb).Thanks!", "I think that partially could be connected with https://github.com/tensorflow/tensorflow/issues/48947 as iterations probably is not a problem with a saved and resumed model. \r\nSo I don't know if we will have other side effects manipulating `initial_epoch` on the same object. \r\n@chrisbutner Can you reproduce exactly the same training session (loss/acc) with your `model.optimizer.iterations.assign(0, read_value=False)` workaround? ", "I'm not sure what you mean by \"reproduce exactly the same training session\", sorry. Thanks for that link - it sounds like https://github.com/tensorflow/tensorflow/issues/48947 deals with a very similar issue - that one is worse because it's the way a 10-line tutorial would save and resume training progress, and it's very clear what should happen - \"iterations\" should be saved and loaded.\r\n\r\nIn my case, I have a model that I can't save and load to a SavedModel format, so whenever I need to train or use it, I construct it from code and use `save_weights` and `load_weights` to save/resume training progress.\r\n\r\nThe general problem seems to be that a `LearningRateSchedule` needs to be told by the model/optimizer exactly how \"old\" the model is in steps and/or what the \"absolute\" step number is for each batch, and the API doesn't provide a clear way to do that. If you pass a dataset to `Model.fit` with 1000 examples, are those examples 1 to 1000, or 500,001 to 501,000? That information is crucial, and the current setup doesn't make it clear which learning rate the schedule will decide to use, at API doc time or runtime, which could result in a lot of wasted work for people.\r\n\r\nIf I were to address this problem, I would look at different ways of answering the question, \"which absolute step numbers are these?\", using prioritized signal/information.\r\n- At the highest priority, passing `initial_epoch` and `steps_per_epoch` to `Model.fit` tells the model exactly which absolute step numbers are involved, even if the model along with its optimizer was saved and then loaded. That is, the `iterations` derived from `initial_epoch` and `steps_per_epoch` would override `iterations` saved as part of the optimizer state. I'm not suggesting that people should pass these two parameters as the primary way to signal absolute step numbers, but when they are passed, they provide clear signal.\r\n- At the second level of priority, if a model is saved with optimizer state included, that can be used to resume from the correct absolute step number, and this should be trusted even when `epochs=N` is passed in, as long as `initial_epoch` is left as the default, if default and zero can be differentiated (i.e. treat the default 0->N as saved->saved + N).\r\n- Finally, if `Model.fit` is just given a bunch of examples without any other clear signal, the optimizer has to assume that this is a fresh model starting from step 1. That may be a reasonable guess, but it would be better to have a clear way in the API to set absolute step number when resuming, rather than relying on `OptimizerV2.iterations` as an implementation detail. This is especially relevant to `Model.train_on_batch`.", "> I'm not sure what you mean by \"reproduce exactly the same training session\", sorry.\r\n\r\nI meant if the optimizer is exactly in the same status so if the loss/accuracy it is exactly the same at every step/epoch with your `iterations` reset workaround or we have others side effects. \r\nE.g. when serializing I still think that we have the old problem (see https://github.com/tensorflow/tensorflow/pull/42846) about recovering the optimizer status. So I don't know if we have other side effect with the `initial_epoch` if it was designed/tested only when re-loading saved models. ", "Got it. Yes, you can definitely lose state; e.g., when I construct the model/optimizer/schedule and use `load_weights` + `initial_epoch` + `steps_per_epoch` + `OptimizerV2.iterations` workaround, I'm losing SGD momentum state and just live with that, because the wrong learning rate is disastrous, but uninitialized momentum should fix itself up quickly, and I'm not giving TensorFlow any info on how to reconstruct it.\r\n\r\nIn terms of API contract and expectations, I think TensorFlow should do everything it can *with the information it has* to follow instructions and maintain trust. In this case I think it's reasonable to expect the correct learning rate, but unreasonable to expect perfectly deterministic outputs.\r\n\r\nIf you save a model and optimizer, then all of the model and optimizer state should be loaded, or the API should make it clear what wouldn't be restored.\r\n\r\nIf you reconstruct the model from code and use `load_weights` + `initial_epoch` + `steps_per_epoch`, then TensorFlow doesn't have the information necessary to reconstruct momentum state, but it does have the information necessary to know that the user intends to resume from 100k steps and wants a learning rate of 0.02 and not 0.2.\r\n\r\nThis doesn't necessarily mean that a bunch of special cases should be set up to fix one-offs, but instead that care should go into choosing inputs and what they mean. A learning rate schedule needs an absolute step, not a per-session step, so where do we get that? Does `OptimizerV2.iterations` reflect that concept, or do we need to reconstruct it in one central place as best we can based on everything that went into building/compiling/restoring/fitting the model?\r\n\r\nI'm not sure I understand your point about `initial_epoch` and side-effects, but if there are concerns about trusting existing `Model.fit` parameters when deciding on an absolute starting step, it may mean that TensorFlow needs more information; e.g. via a new parameter to the `LearningRateSchedule` constructor, optimizer, or `Model.fit`. Silently guessing and getting it wrong is very costly for users in the product space that TensorFlow operates in.", "What I meant is all these Is related to the optimizer lifecycle.\nIf you don't care about the status/reproducibilty of the optimizer iterations is related to the lifecycle of the object and not to the model or fit.\nYes probably a warning could be printed if this is the intended behaviour when you have `initial_,epoch` but with your multiple fit  example and without serialization probably It expect a new optimizer. \nE.g. https://stackoverflow.com/questions/56806419/keras-how-to-reset-optimizer-state", "Sure, I think that lines up with what I'm saying - maybe I need to explicitly tell the optimizer which absolute step to start with when starting a new `Model.fit` (just to be clear, I'm not doing multiple fit()s, that's just in the repro example).\r\n\r\nThe problem is that (a) it's not documented that `LearningRateSchedule` relies on `Optimizer.iterations`, and (b) `iterations` isn't on the public API for, e.g., https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/SGD\r\n\r\nSo, I'm happy to manually initialize `Optimizer.iterations`, but I have no way of knowing whether e.g. TF2.7 would break my code.", "As iterations is in the weights and in you real case you load the weights I think that you need to have a fresh new optimizer and re-compile after weights load", "Ah, thank you, I didn't realize `save_weights`/`load_weights` also saved optimizer state: I thought that was restricted to `Model.save`/`models.load_model`, but I see it documented there.\r\n\r\nAfter adjusting the repro, everything seems to work as expected regardless of the order of `compile` and `load_weights`.\r\n\r\nThe reason I couldn't automatically take advantage of the optimizer weights is because I was saving/loading weights using the full model but using a subset of it for compiling and training, wrapped with a new `Model`, without realizing the consequences.\r\n\r\nI think TF is behaving as expected then and this issue can be closed (it's confusing then that https://github.com/tensorflow/tensorflow/issues/48947 has a problem with iterations via `Model.save`/`models.load_model`). Thank you for explaining.", "@chrisbutner , Closing the issue since it is working as expected and your issue is resolved, Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49208\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49208\">No</a>\n"]}, {"number": 49207, "title": "Didn't find op for builtin opcode 'RESIZE_BILINEAR' version '3'", "body": "System Information:\r\nTensorFlow 2.3\r\nModel Architecture - MobileNet V1\r\nArduino_TensorFlow Lite 2.4.0 Alpha\r\n\r\nI fined Tuned Mobilenet V1 for face recoginition and later quantized using full integer Quantization Technique and later converted it to .cc format to upload it to Arduino Nano 33 BLE Sense. I used all_ops_resolver function but when i ran the Model on Microcontroller, invoke failed() and error message which was shown on Serial Monitor was \" Didn't find op for builtin opcode 'RESIZE_BILINEAR' version '3'. An older version of this builtin might be supported. Are you using an old TFLite binary with a newer model?\". Can anyone suggest me, how i can work around this error message.\r\nAfter looking through the Arduino_TensorFlow Lite 2.4.0 - APLHA , i saw that resize_bilinear() isnt available in all_ops_resolver library but it is there in the master version of TensorFlow Lite on Tensorflow Github repository.  \r\nCan anyone suggest me, how i overcome error message.\r\n\r\nColab Link - https://github.com/vatsDivyank/Face-Recoginition-TinyML/blob/985e769a84ecdd5ec8890d2288d262bbfa7cc18c/User_not_User_FineTuned.ipynb\r\n\r\n\r\n\r\n", "comments": ["Yes this opcode is quite fresh. See https://github.com/tensorflow/tensorflow/pull/48617", "I tried to generate the arduino Library using\r\n./tensorflow/lite/micro/tools/ci_build/test_arduino.sh\r\nbut the generated library is still not completly function. Is there a stable version already available?", "All the TFLite micro related code has been migrated to different repository here https://github.com/tensorflow/tflite-micro, could you try again with the latest version and the specific path for the above comment can be found here https://github.com/tensorflow/tflite-micro/tree/main/tensorflow/lite/micro/tools/ci_build.", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49207\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49207\">No</a>\n"]}, {"number": 49206, "title": "SSIM performance degradation in TF v2.5.0.", "body": "<em>Please make sure that this is an issue related to performance of TensorFlow.\r\nAs per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:performance_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Custom\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux (Colab)\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: None\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): 2.4.0/2.5.0\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source): None\r\n- GCC/Compiler version (if compiling from source): None\r\n- CUDA/cuDNN version: \r\n- GPU model and memory: K80 GPU\r\n\r\n\r\n**Describe the current behavior**\r\nSSIM has become extremely slow in TF 2.5.0 as compared to TF 2.4.x\r\nHere are some tests I ran on Colab\r\n```\r\nimport tensorflow as tf\r\nprint(tf.__version__) # 2.5.0\r\n\r\n%%timeit\r\nssim_ = tf.image.ssim(tf.random.normal((30,500,500,1)), tf.random.normal((30,500,500,1)), 1)\r\n\r\nOUTPUT:\r\n1 loop, best of 5: 30.1 s per loop\r\n```\r\n```\r\nimport tensorflow as tf\r\nprint(tf.__version__) # 2.4.0\r\n\r\n%%timeit\r\nssim_ = tf.image.ssim(tf.random.normal((30,500,500,1)), tf.random.normal((30,500,500,1)), 1)\r\n\r\nOUTPUT:\r\n10 loops, best of 5: 93.5 ms per loop\r\n```\r\nThe timeit tests warn clearly that there might be some caching involved for the 2.4.0 test (which isn't available for 2.5.0 I assume, I don't know why. Caching should be enabled for 2.5.0 as well if its the default behaviour)\r\n\r\n**Describe the expected behavior**\r\nThere is clear performance degradation between the two versions. I haven't gotten the time to go through the `tensorflow/python/ops/image_ops_impl.py` but I assume there is some implementation change that is causing this issue\r\n\r\n", "comments": ["Are you sure isn't related to the recurrent Colab issue we have on new releases?\nSee https://github.com/googlecolab/colabtools/issues/2013", "@bhack it is possible but if that is the case then why do some Colab environments have 2.5.0 by default? ", "Currently I have only found `2.4.1` default if the specific Colab notebook  doesn't have an explicit `pip install tensorflow`", "Okay, that was a problem on my end. Apparently, pip installing Tensorflow IO automatically upgrades tensorflow version to 2.5.0 to go with its 0.18 version. Closing this issue. Thanks!"]}, {"number": 49205, "title": "SSIM performance degradation in TF v2.5.0", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Custom\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux (Colab environment)\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): 2.4.0/2.5.0\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source): None\r\n- GCC/Compiler version (if compiling from source): None\r\n- CUDA/cuDNN version:\r\n- GPU model and memory: Tesla K80\r\n\r\n**Describe the current behavior**\r\nSSIM has become extremely slow in TF 2.5.0 as compared to TF 2.4.x\r\nHere are some tests I ran on Colab\r\n```\r\nimport tensorflow as tf\r\nprint(tf.__version__) # 2.5.0\r\n\r\n%%timeit\r\nssim_ = tf.image.ssim(tf.random.normal((30,500,500,1)), tf.random.normal((30,500,500,1)), 1)\r\n\r\nOUTPUT:\r\n1 loop, best of 5: 30.1 s per loop\r\n```\r\n```\r\nimport tensorflow as tf\r\nprint(tf.__version__) # 2.4.0\r\n\r\n%%timeit\r\nssim_ = tf.image.ssim(tf.random.normal((30,500,500,1)), tf.random.normal((30,500,500,1)), 1)\r\n\r\nOUTPUT:\r\n10 loops, best of 5: 93.5 ms per loop\r\n```\r\nThe timeit tests warn clearly that there might be some caching involved for the 2.4.0 test (which isn't available for 2.5.0 I assume, I don't know why. Caching should be enabled for 2.5.0 as well if its the default behaviour)\r\n\r\n**Describe the expected behavior**\r\nThe SSIM function clearly has performance degradation in 2.5.0 and should not take so much time on a GPU.\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)** - Do you\r\nwant to contribute a PR? (yes/no): - Briefly describe your candidate solution\r\n(if contributing): Yes but I will have to go through the history of the `tensorflow/python/ops/image_ops_impl.py`  file\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\nMentioned above\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49205\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49205\">No</a>\n"]}, {"number": 49204, "title": "Model re-compilation updated under Distributed Mirror Strategy issue", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution : Linux Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (use command below): 2.4.0\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source):N/A\r\n- CUDA/cuDNN version: 11.0\r\n- GPU model and memory: RTX 2080 Ti x4\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nI am faced to an issue with Tensorflow with a model trained on multiple GPUs (x4) with the Distributed Mirror Strategy. \r\nThe first training works perfectly with the Distributed Mirror Strategy.\r\nAfter, I want to update some parameters (in the same run) such as learning rate, optimizer. The model compilation works perfectly and when the new training sequence is starting, I got the error below.\r\n\r\nHere is my code. Do you have any advise to avoid this error and the training stop ? When I reload the model and run the next step of the training, it works but not in the pipeline. Do you have any idea ?\r\n```\r\nmirrored_strategy = tf.distribute.MirroredStrategy()\r\nwith mirrored_strategy.scope():\r\n    # Everything that creates variables should be under the strategy scope.\r\n    # In general this is only model construction & `compile()`.\r\n\r\n    print(\"[INFO] compiling model...\")\r\n    baseModel, headModel, model = get_model(LastLayerNeurons=20, DropOut=0.5)\r\n\r\n    for layer in baseModel.layers:\r\n        layer.trainable = False\r\n\r\n    # construct the set of metrics\r\n    metrics = ['accuracy']\r\n    opt = SGD(lr=1e-3)\r\n    model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=metrics)\r\n\r\nprint(\"[INFO] training head...\")\r\nmodel.fit(train_dataset,\r\n          steps_per_epoch=steps_per_epoch,\r\n          validation_data=val_dataset,\r\n          validation_steps=validation_steps,\r\n          epochs=10,\r\n          max_queue_size=500,\r\n          callbacks=callbacks,\r\n          verbose=1,\r\n          use_multiprocessing=True,\r\n          workers=20)\r\n\r\nwith mirrored_strategy.scope():\r\n    print(\"[INFO] re-compiling model...\")\r\n\r\n    for layer in model.layers[:]:  # Dernier block i.e #5\r\n        layer.trainable = True\r\n\r\n    # construct the set of metrics\r\n    metrics = ['accuracy']\r\n\r\n    opt = SGD(lr=1e-4)\r\n    model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=metrics)\r\n\r\nprint(\"[INFO] fine-tuning V2 model...\")\r\nmodel.fit(train_dataset,\r\n        steps_per_epoch=steps_per_epoch,\r\n        validation_data=val_dataset,\r\n        validation_steps=validation_steps,\r\n        epochs=100,\r\n        max_queue_size=500,\r\n        callbacks=callbacks,\r\n        verbose=1,\r\n        use_multiprocessing=True,\r\n        workers=20)\r\n```\r\n\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n```\r\nException ignored in: <bound method Image.__del__ of <tkinter.PhotoImage object at 0x7f1bc3ea32b0>>\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python3.6/tkinter/__init__.py\", line 3507, in __del__\r\n    self.tk.call('image', 'delete', self.name)\r\nRuntimeError: main thread is not in main loop\r\n```\r\n", "comments": ["@EdouardDKP \r\nCould you please share the colab gist with all the dependencies as to analyse the issue reported here.Thanks", "Hello,\r\nI have tested to add the code below into my callbacks files. Thanks to that, that works.\r\nNo more issue at this time.\r\n```\r\nimport matplotlib\r\nmatplotlib.use('Agg')\r\n\r\n```\r\nBest Regards", "@EdouardDKP \r\n\r\nThank you for your update, glad its working fine for you, kindly move this issue to closed status as it is resolved.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49204\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49204\">No</a>\n"]}, {"number": 49203, "title": "convert a keras model and load it on pi3, can not work", "body": "I convert a keras h5 model exported by teachable maching image classfication  to a tflite quantized model.\r\nand load the converted model on pi3(with tflite-runtime 2.1.0), such error happend:\r\n  didn't find op for builtin opcode 'conv_2d' version '5'\r\n\r\nalso i install tensorflow 2.4.0-rc2 on pi3.\r\nso i tried to load the converted model , no error happend,\r\nbut the prediction accuracy is not good at all.\r\n\r\nwhen i load the tflite quantized model export by teachable maching on pi3, it worked very well.\r\nany one know why? and how google do it?\r\n\r\n\r\n### 1. System information\r\nI convert the keras model to tflite quantized model on the following environment:\r\n- OS Platform and Distribution ( Linux Ubuntu 16.04):\r\n- TensorFlow installation (pip package or built from source): pip\r\n- TensorFlow library (version): 2.4.0\r\n\r\n### 2. The convert Code\r\nimport tensorflow as tf\r\nimport keras\r\nmodel = keras.models.load_model('./keras_model/keras_model.h5')\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\ntflite_model = converter.convert()\r\nwith open('model.tflite', 'wb') as f:\r\nf.write(tflite_model)\r\n", "comments": ["> when i load the tflite quantized model export by teachable maching on pi3, it worked very well.\n\nI don't understand what It is the configuration that It is \"working well\".", "@dfybc ,\r\n\r\nIn order to reproduce the issue reported here, could you please provide the complete code and the dataset  or colab link you are using. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "@dfybc ,\r\n\r\nPlease let us know if your issue got resolved.Also please take a look at this issues.It helps.[link1](https://github.com/tensorflow/tensorflow/issues/42305),[link2](https://github.com/tensorflow/tensorflow/issues/46409),[link3](https://github.com/tensorflow/tensorflow/issues/43372).\r\n\r\nThanks!", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 49202, "title": "\"Check failed: IsAligned()\" for pluggable devices with custom device memory allocator ", "body": "**Describe the current behavior**\r\nWe are using custom memory allocator registered for pluggable device. And while running unit tests like :while_v2_test.py\" we are running into issue of \"Check failed: IsAligned()\" \r\nhttps://cs.opensource.google/tensorflow/tensorflow/+/master:tensorflow/core/framework/tensor.cc;l=678\r\n\r\n**Describe the expected behavior**\r\nSince we are using our own memory allocator for device allocations the alignment of the data pointer is not necessarily related to the alignment of the data on the device, making this check not applicable. What can we do to fix it so that pluggable devices with custom allocators don't run into this issue. \r\n\r\nWe were thinking of propogating the use_bfc_allocator flag to Tensor class to bypass the alignment check with custom allocator devices. Please let us know if it makes sense. \r\n\r\n@mihaimaruseac , @penpornk \r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n\r\nNo this is from running the unit test case.\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nMacOS\r\n\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\nSource\r\n- TensorFlow version (use command below):\r\n- Python version:\r\n3.8.2\r\n- Bazel version (if compiling from source):\r\n3.7.2\r\n", "comments": ["Some users were affected by this bug recently: https://developer.apple.com/forums/thread/696907", "Hi! I have the same issue here. Is there a fix available?", "Try to update to tensorflow-macos==2.8.0. It seems to resolve the issue.", "> Try to update to tensorflow-macos==2.8.0. It seems to resolve the issue.\r\n\r\nWorks for me! \r\n\r\nWhen I had this problem before, the version of tensorflow-macos was only updated to 2.7, and the official version of tensorflow has been updated to 2.8. \r\n\r\nMaybe this is fixed in tensorflow-macos 2.8?", "Closing as it should be resolved with TF 2.8", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49202\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49202\">No</a>\n"]}, {"number": 49201, "title": "Tensorflower gardener reverting changes made in PRs", "body": "I had a couple of PRs merged before release of 2.5, and one after that. None of the changes in those PRs are now reflected in the code on master branch. Is this some internal process? \r\nThe PRs before release are  #48000 #48491 and the one after the release is #48610\r\n\r\nIn all the three PRs, if we see in the History section of the file, we see Tensorflower gardener pushing the changes, but reverting them in the very next commit under the title \"Internal change\". Can someone please tell what's going on?\r\n\r\nFollowing are the screenshots as well as links to the commits made by tensorflower-gardener\r\n\r\n\r\n#48000: [Internal change](https://github.com/tensorflow/tensorflow/commit/a08001f32afab9952f27cd0b5fe15352569ce93e#diff-aedc7bfa50b8c6005dd96fb3d7f2d01d7d5538933829cbb52d11ced51e37eece)\r\n![image](https://user-images.githubusercontent.com/64411306/118349261-46463100-b56d-11eb-8adc-8b09c5abbc55.png)\r\n\r\n\r\n#48610: [Internal change](https://github.com/tensorflow/tensorflow/commit/0174bcb337e2c8e7d6782b60b094ea70460ad071#diff-f52657292a8a14c55f02a6cdacca9172be68e3fee9cd722cb5ac7d27326ecf9c)\r\n![image](https://user-images.githubusercontent.com/64411306/118349280-6e359480-b56d-11eb-85bd-321fabbbd551.png)\r\n", "comments": ["In general, we are trying to be a little bit more transparent about this process and to automate the notification to the contibutors.\n\nSee https://github.com/google/copybara/issues/155\n\n/cc @mihaimaruseac @nikitamaia @theadactyl ", "@bhack \r\nOk,  but what does that mean about the PRs? Are they reassessed internally or something?\r\n\r\nAlso, on a side note, about the DepthwiseConv1D issue, I couldn't get it to build on my PC with a quarter of the resources. Thus, I will  try to use colab for that henceforth.  ", "It about something that was gone wrong internally so you are not the only one and we have other rollback conmit. You can see a recent one at https://github.com/tensorflow/tensorflow/commit/07dd16b3a09e0cfa007d9694251dd6b2cbdf36ad\n\nAbout Depthwise please leave a comment about your compiling experience/issues in its own ticket as It could have something in common to other contributors candidates experience.", "Yes, I saw that some of the merged PRs by external contributors were rolled back. So, I suppose those will be merged again later, right?\r\n\r\n>About Depthwise please leave a comment about your compiling experience/issues in its own ticket as It could have something in common to other contributors candidates experience.\r\n\r\nSure, will do", "> So, I suppose those will be merged again later, right?\r\n\r\nI don't think so as on Github you cannot re-open/unmerge PRs.\r\n\r\nThis is why I want to improve the bot to automatically notify the PR and re-open its linked ISSUE (when available) on rollbacks.\r\n\r\nThen the internal Team member/reviewer can add additional comments about what happened internally and if the contributor can do something else and re-open a new \"clone PR\".\r\n\r\nProbably there is also a better process but  currently I have no internal visibility to really understand why rollbacks happens and why they are not blocked before merge by CI checks (probably Is this related to some missing coverage about internal assets?)", "Got it, thanks", "So, internally all Google code (from all projects) is in one big repository. We have tests for other projects that depend on TF. when any test is broken, there is an automatic rollback phase. Sometimes, some Googler that saw the PRs is able to notify the PR that it got rolled back, provide help as to why that happened, etc. But this is not a given, sadly.", "I still think that we have margins to automate the bot as the copybara API are available.", "@mihaimaruseac \r\nThanks for the explanation. In that case is there any way that I can make sure that future PRs are clean? ", "There is some work that is currently planned for the OSS DevInfra team so that the gap between internal and external code is minimized. Unfortunately, if other projects rely on internal code there is nothing that can be done from the OSS side and someone in TF team needs to take to bring the other internal project up to date with the new changes.", "Thanks for the prompt and detailed explanation. Hoping that this problem will be resolved soon. ", "@AdityaKane2001 \r\n\r\nCould you please move this issue to closed status ,as it is resolved.Thanks"]}, {"number": 49200, "title": "VLOG() to Text File", "body": "Redirects the output of all active `VLOG()` calls to a text file specified by the environment variable `TF_CPP_VLOG_FILENAME`. If the environment variable is not set, or if it points to a location that cannot be opened for writing, the output continues to `stderr`.\r\n\r\n\r\nAttn: @reedwm.", "comments": ["Thanks, Reed. I believe the thread safety of `fprintf ` is linked to POSIX compliance."]}, {"number": 49199, "title": "Add missing \"metrics_*.py\" modules to tflite_runtime bazel build script", "body": "Fix for #49198 \r\n\r\n## Steps to reproduce \r\n* https://github.com/avroshk/build-tflite-runtime \r\n\r\n## Test fix \r\n* https://github.com/avroshk/build-tflite-runtime/tree/fix ", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F49199) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!\r\n", "@yyoon coud you review this PR?", "Thanks for creating this fix!\r\n\r\nI appreciate that this would probably fix the mentioned issue, but I suspect that this is caused by some missing dependency path within bazel BUILD files, and thus the metrics Python source files shouldn't need to be added like this directly in the shell script side.\r\n\r\nI'll dig deeper and let you know where we should be fixing this. Thanks again!", "@yyoon Thanks for reviewing this. I did have a suspicion that my fix was too naive, :) please let me know if I can help with anything.", "@thaink Thai, could you take a look at this PR? As I investigate more about this, the fix in this PR might be the simplest solution. Otherwise, we'd need to re-implement the metrics portable / non-portable implementation in C++ and provide a python wrapper for them. But then, we already have `metrics_wrapper` package already which is used for a different purpose (exporting metrics) so it could be pretty cumbersome to workaround.\r\n\r\nWhat do you think?", "I am also supportive with this PR since it is consistent with existing build_pip_package.sh and build_pip_package_with_cmake.sh."]}]