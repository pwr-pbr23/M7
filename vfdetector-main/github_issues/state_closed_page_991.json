[{"number": 23666, "title": "Fix dead links in toco documents", "body": "Fixed dead links in toco documents.", "comments": ["Thank you , closing this PR as changes have been internally and no longer needed this PR"]}, {"number": 23665, "title": "Possible Error for tf Gradient on mean", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): window 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):\r\n- Python version: python 3\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\nb'v1.8.0-0-g93bc2e2072' 1.8.0\r\n\r\n**Describe the current behavior**\r\nWhen taking the gradient respect to a variable and reduce mean the outcome should be \r\n1 - (1/(# of reduced dimension)) however it does not happen. \r\n\r\n\r\n**Describe the expected behavior**\r\nThere are a different blog post and resources on how to perform backpropagation for batch norm. \r\nCentering the data is a key part of any norm, and it seems like auto differentiation is getting the value wrong? Or am I just going crazy. I thought the gradient respect to the input variable should be\r\n1 - 1/(10*94*94) - since 10 is dim - 94 is dim 1 and 2. \r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\nimport tensorflow as tf\r\ntesting_tensor   = tf.placeholder(shape=[10,94,94,32],dtype=tf.float64)\r\ntesting_output   = testing_tensor - tf.reduce_mean(testing_tensor,(0,1,2),keep_dims=True) \r\nwhat_grad_auto   = tf.gradients(xs=testing_tensor,ys=testing_output)\r\n\r\n![image](https://user-images.githubusercontent.com/22832406/48318218-c9682400-e5ca-11e8-8abd-46e660ada701.png)\r\n\r\n", "comments": ["Sorry for my horrible explanation, I have the code in my GitHub repo. Or my math might just be wrong.\r\nDifferent blog post such as https://medium.com/samkirkiles/spatial-batchnorm-backprop-implementation-notes-8ccde1ac62a2 describes how to do a back prop for batch norm as well", "> Or my math might just be wrong.\r\n\r\nIndeed.\r\nThe code is working correctly.", "I get that but can you show me how the derivative work out? (assuming you know how to). I think when the mean subtraction layer is c and original input is x (10,94,94,32)\r\n\r\nx_hat = mean of x respect to axis (0,1,2) which is 10 * 94 * 94\r\nc = x -x_hat\r\n\r\ndc/dx = dc/dx + dc/dx_hat * dx_hat/dx\r\n          =   1       +  (-1)          * 1/(10 * 94 * 94)\r\n          =  0.999988683\r\n\r\nWhere was the mistake? ", "`dc/dx_hat * dx_hat/dx`\r\nNone of these terms are real numbers. They are tensors.", "okay, my bad I wrote in a confusing way, it should be in a tensor as well.\r\nBut the general concept of taking derivative respect to the input (here x) is the same. \r\n\r\nLet me give you an example, we have a function \r\n\r\ndef f(x): return tf.reduce_mean(x,(0,1,2,),keep_dims=True)\r\n\r\nso the output would be a tensor shape of (1,1,1,32) right? \r\nBut when we take the derivative respect to the original input x the derivative is 1/(10 * 94 * 94) \r\nFor all variable in x - so it would be a tensor that has a shape of (10,94,94,32) but every value would be\r\n0.00001131733\r\n\r\nI believe you know how to do these by hand right Yuxin? \r\n\r\nI have attached some screenshots to help you understand what I mean. \r\n\r\n![image](https://user-images.githubusercontent.com/22832406/48329606-7ff1f600-e617-11e8-994a-4309de03ed7e.png)\r\n\r\n![image](https://user-images.githubusercontent.com/22832406/48329616-884a3100-e617-11e8-8038-f84bd34d72e7.png)\r\n\r\n\r\n", "> def f(x): return tf.reduce_mean(x,(0,1,2,),keep_dims=True)\r\nso the output would be a tensor shape of (1,1,1,32) right?\r\nBut when we take the derivative respect to the original input x the derivative is 1/(10 * 94 * 94)\r\nFor all variable in x - so it would be a tensor that has a shape of (10,94,94,32) but every value would be\r\n0.00001131733\r\n\r\nThis is correct. And this is `dx_hat/dx`.\r\nBut the point is, because it is a tensor (not a real number), and the multiplication is a tensor product: you can only take out the individual element of the tensor after the multiplication. You can not first take one real value out of each tensor and then multiply them together.\r\n\r\nAlso, I'm not sure if you are aware, but https://www.tensorflow.org/api_docs/python/tf/gradients has this sentence that's relevant: \r\n> grad_ys is a list of tensors of the same length as ys that holds the initial gradients for each y in ys. When grad_ys is None, we fill in a tensor of '1's of the shape of y for each y in ys.\r\n\r\nThis means that you're actually computing `tf.gradients(xs=testing_tensor, ys=tf.reduce_sum(testing_output))`\r\n\r\nIf that's not clear enough, I would be sorry but I do not intend to explain more of it. My intention is mainly to give an initial triage of the issue so the TF developers can focus more on actual bugs."]}, {"number": 23664, "title": "Documents for MirroredStrategy", "body": "**System information**\r\n\r\n- TensorFlow version: 1.12\r\n- Doc Link:\r\n  1. https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/distribute\r\n  2. https://www.tensorflow.org/api_docs/python/tf/contrib/distribute/MirroredStrategy\r\n\r\n\r\n**Describe the documentation issue**\r\n\r\n[Document i](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/distribute) says that `tf.contrib.distribute.MirroredStrategy` is for only the case of \"single worker and multi GPUs\".\r\nBut [document ii](https://www.tensorflow.org/api_docs/python/tf/contrib/distribute/MirroredStrategy) says that `MirroredStrategy` can work in multi-worker (multi-node) cluster.\r\n\r\nWhich is right?\r\n\r\nIf [document i](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/distribute) is out of date, we have to update it.\r\n", "comments": ["It _looks_ like that README is out of date, but I'm no expert on the subject.\r\n\r\n@yuefengzhou can you confirm?", "`MirroredStrategy` works for multi-worker cluster but is not recommended. For multi-worker case, please use `CollectiveAllReduceStrategy`.", "I guess `tf.keras` will be the main stream of TensorFlow high level API because Estimator seems to be moved to [another repository](https://github.com/tensorflow/estimator).\r\n\r\nHowever, `tf.keras` can not use `CollectiveAllReduceStrategy` for multi-worker case (that is spacified [here](https://www.tensorflow.org/guide/keras#multiple_gpus)).\r\n\r\nIf we want to implement multi-worker case, the best way is use `tf.keras`, convert it to Estimator with `\r\ntf.keras.estimator.model_to_estimator`, and using `CollectiveAllReduceStrategy`?", "@sfujiwara This is right. And we are working on multi-worker support for Keras.", "@yuefengz I recently tested both `MirroredStrategy` and `CollectiveAllReduceStrategy` for various models on a 8 GPU server. I found `CollectiveAllReduceStrategy` is constantly slower than `MirroredStrategy` by about 30%. Is this expected? Or I am missing some configuration? Thanks!", "@ustcyue The 30% sounds bigger than what we expected. cc @poxvoculi ", "Closing this thread since the discussion for `CollectiveAllReduceStrategy`'s performance has been migrated to https://github.com/tensorflow/tensorflow/issues/24611."]}, {"number": 23663, "title": "Help with what version to install?", "body": "I have a cuda compute capability 3.0 GPU ,AMD processor and running on windows 10 64bit . So when I checked the official tensorflow website it says requires cuda compute capability 3.5 or higher. \r\n\r\nSo which version should I install from the repository to support cuda 3.0 and run on my computer. \r\n\r\n> https://www.tensorflow.org/install/gpu", "comments": ["TensorFlow officially supports NVIDIA GPU. For using AMD gpu you have to compile TensorFlow using OpenCL. Please read this [setup guide](https://developer.codeplay.com/computecppce/latest/getting-started-with-tensorflow) to get more insights on TensorFlow AMD Setup.", "> TensorFlow officially supports NVIDIA GPU. For using AMD gpu you have to compile TensorFlow using OpenCL. Please read this [setup guide](https://developer.codeplay.com/computecppce/latest/getting-started-with-tensorflow) to get more insights on TensorFlow AMD Setup.\r\n\r\nActually I have a NVIDIA GPU but it is cuda compute capability 3.0 GPU but tensorflow gpu support 3.5. So I was looking for a workaround.", "I think we don't have pre-built binaries for cuda compute capability 3.0, you may have to build from sources yourself. @mrry Can you please take a look?", "That's right: our supported capabilities are 3.5 and 5.2. It may be possible to build for 3.0 from source, but we don't support that configuration, and some of the standard kernels may use features that require a more powerful GPU.", "Are you satisfied with the resolution of your issue?\r\n[Yes](https://goo.gl/forms/Oe0tEvODFRoI2gJF3)\r\n[No](https://goo.gl/forms/fUjzOfrtkFbrOT8d2)"]}, {"number": 23662, "title": "Update c_api_experimental.h", "body": "Make it more interesting.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->", "Please review the contribution guidelines in https://github.com/tensorflow/tensorflow/blob/master/CONTRIBUTING.md."]}, {"number": 23661, "title": "[XLA] Simplify transposes that are really reshapes", "body": "A transpose like\r\n```\r\nf32[1,1,64,1] = transpose(f32[1,64,1,1]), dimensions={3,2,1,0}\r\n```\r\nis really just a reshape (because there's only one non-1 dimension).\r\nTeach algebraic simplifier to make that substitution, to enable applying\r\nreshape-combining optimizations to such instructions.", "comments": ["This change gives about a 15% performance improvement on TPUs when running ResNet50 as implemented in https://github.com/FluxML/MetalHead.jl.", "Addressed review comment from @davidel.", "Nagging Assignee @aaroey: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Updated to remove the recursion and rely on fix pointing instead. I'll take a look at the more general transform.", "Added the more general thing as a separate commit.", "Before this gets merged, I want to add the test that Blake requested and fix the typo. Will have that shortly, just one sec.", "Added (and fixed a small bug that Blake pointed out to me in person yesterday). ", "HI, I fixed the bug on an internal submit. The original version had some performance issues, so I made the optimization less agressive but still does what you wanted.", "Thanks!"]}, {"number": 23660, "title": "__manage.py__ not found", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS 10.11.6\r\n- TensorFlow installed from (source or binary): source, if this means from tensorflow.org\r\n- TensorFlow version:  TensorFlow version 1.12\r\n- Python version: Python 3.6\r\n- Installed using virtualenv? pip? condo?: installed using pip, conda and in a virtual environment\r\n- Bazel version (if compiling from source): not yet\r\n- GCC/Compiler version (if compiling from source): CPU version\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\nI installed tensorflow three weeks ago, via pip.  Then tried to start running tutorials or at least verify install.  Kept getting \"file not found\",  checked \"pip list\", it was there, but in downloads.  Then after further checking, noted it to be in site-packages under downloads.  I've done the installation as pip, as conda and in a virtual environment.  Comments like \"virtualenv\" not found frustrated the installation but I was eventually able to get set up a virtual environment.  Last night I tested it using the \"pip --upgrade tensorflow\", command.  Requirements had been met.  Then I tried opening both keras and tensorflow apps.  Okay,  tensorflow has an outer and inner directory.  No prob.  Still now I get \"__manage.py__\" not found in package.  Could not copy entire traceback from terminal but using the conda console I still get errors.  Here's a copy of the last commands I tried today and the traceback from the console,...albeit, the terminal traceback is much larger:\r\n\r\npython -c \"import tensorflow as tf; tf.enable_eager_execution(); print(tf.reduce_sum(tf.random_normal([1000, 1000])))\"\r\n\r\n1. File \"<ipython-input-1-77841da38ed1>\", line 1\r\n    python -c \"import tensorflow as tf; tf.enable_eager_execution(); print(tf.reduce_sum(tf.random_normal([1000, 1000])))\"\r\n                                                                                                                         ^\r\nSyntaxError: invalid syntax\r\n\r\n2.  File \"<ipython-input-2-92d0143764a7>\", line 1\r\n    python -c \"import tensorflow as tf; tf.enable_eager_execution()\r\n                                                                   ^\r\nSyntaxError: EOL while scanning string literal\r\n\r\n3.  File \"<ipython-input-3-7e790e56de0e>\", line 1\r\n    python -c \"import tensorflow as tf; tf.enable_eager_execution();\r\n                                                                    ^\r\nSyntaxError: EOL while scanning string literal\r\n\r\n4. File \"<ipython-input-4-77841da38ed1>\", line 1\r\n    python -c \"import tensorflow as tf; tf.enable_eager_execution(); print(tf.reduce_sum(tf.random_normal([1000, 1000])))\"\r\n                                                                                                                         ^\r\nSyntaxError: invalid syntax\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n5.   File \"<ipython-input-5-50ca0a742afa>\", line 1  [without quotes]\r\n    python -c import tensorflow as tf; tf.enable_eager_execution(); print(tf.reduce_sum(tf.random_normal([1000, 1000])))\r\n                   ^\r\nSyntaxError: invalid syntax\r\n**Any other info / logs**\r\n\r\nTrying to copy the terminal log, and traceback.\r\n\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n", "comments": ["I tried the same steps using conda  with Python 3.6 and tensorflow 1.2 version. I didn't face any problems mentioned above. \r\n```\r\n(tf_python3.6)$ python -c \"import tensorflow as tf; tf.enable_eager_execution(); print(tf.reduce_sum(tf.random_normal([1000, 1000])))\"\r\n2018-11-12 15:54:04.692350: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\ntf.Tensor(526.10333, shape=(), dtype=float32)\r\n```\r\n\r\nI am not sure if this is tensorflow issue but I usually prefer conda to install tensorflow.\r\n\r\n```\r\nconda create --name tensorflow python=3.6\r\nactivate tensorflow\r\npip install tensorflow\r\n```\r\nDont forget to activate the tensorflow environment on conda.", "Hi @dah512 ,\r\nWe are checking to see if you still need help on this issue. We recommend that you upgrade to 2.6 which is latest stable version of TF and let us know if the issue still persists in newer versions. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/23660\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/23660\">No</a>\n"]}, {"number": 23659, "title": "TPU: keras support for multiples inputs layers", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colaboratory\r\n\r\n**Describe the current behavior**\r\n\r\nI am using the functional api of keras models, and TPU does not yet support multiple inputs layers.\r\n\r\n**Describe the expected behavior**\r\n\r\nIt should support multiple inputs models.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n```\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/keras_support.py in _validate_shapes(model)\r\n   2077   \"\"\"Validate that all layers in `model` have constant shape.\"\"\"\r\n   2078   for layer in model.layers:\r\n-> 2079     if isinstance(layer.input_shape, tuple):\r\n   2080       input_shapes = [layer.input_shape]\r\n   2081     else:\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py in input_shape(self)\r\n   1351     else:\r\n   1352       raise AttributeError('The layer \"' + str(self.name) +\r\n-> 1353                            ' has multiple inbound nodes, '\r\n   1354                            'with different input shapes. Hence '\r\n   1355                            'the notion of \"input shape\" is '\r\n\r\nAttributeError: The layer \"model_encoder_vgg19 has multiple inbound nodes, with different input shapes. Hence the notion of \"input shape\" is ill-defined for the layer. Use `get_input_shape_at(node_index)` instead.\r\n```\r\nThe issue is at line 2079 of `keras_support.py` where `get_input_shape_at(node_index)` should be used instead. \r\n\r\n", "comments": ["I have the similar issue when trying to reuse already compiled keras model and convert it into TPU model:\r\n```\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-6-002cb4c34948> in <module>()\r\n     11     tf.keras.layers.Dense(1000)(training_model(training_model.inputs)),\r\n     12     strategy=tf.contrib.tpu.TPUDistributionStrategy(\r\n---> 13         tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)))\r\n     14 \r\n     15 tpu_model.fit_generator(\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/framework/python/framework/experimental.py in new_func(*args, **kwargs)\r\n     62         'any time, and without warning.',\r\n     63         decorator_utils.get_qualified_name(func), func.__module__)\r\n---> 64     return func(*args, **kwargs)\r\n     65   new_func.__doc__ = _add_experimental_function_notice_to_docstring(\r\n     66       func.__doc__)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/keras_support.py in tpu_model(model, strategy)\r\n   2139     A new `KerasTPUModel` instance.\r\n   2140   \"\"\"\r\n-> 2141   _validate_shapes(model)\r\n   2142   # TODO(xiejw): Validate TPU model. TPUModel only?\r\n   2143   # TODO(xiejw): Validate replicas. Full or 1. Shall we allow subset?\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/keras_support.py in _validate_shapes(model)\r\n   2076 def _validate_shapes(model):\r\n   2077   \"\"\"Validate that all layers in `model` have constant shape.\"\"\"\r\n-> 2078   for layer in model.layers:\r\n   2079     if isinstance(layer.input_shape, tuple):\r\n   2080       input_shapes = [layer.input_shape]\r\n\r\nAttributeError: 'Tensor' object has no attribute 'layers'\r\n```\r\nI can be reproduced with [\"Predict Shakespeare with Cloud TPUs and Keras\"](https://colab.research.google.com/github/tensorflow/tpu/blob/master/tools/colab/shakespeare_with_tpu_and_keras.ipynb#scrollTo=VzBYDJI0_Tfm) example. \r\nChanged code cell:\r\n```python\r\ntf.keras.backend.clear_session()\r\n\r\ntraining_model = lstm_model(seq_len=100, batch_size=128, stateful=False)\r\n\r\ntpu_model = tf.contrib.tpu.keras_to_tpu_model(\r\n    training_model,\r\n    strategy=tf.contrib.tpu.TPUDistributionStrategy(\r\n        tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)))\r\n\r\ntpu_model_reused = tf.contrib.tpu.keras_to_tpu_model(\r\n    tf.keras.layers.Dense(1000)(training_model(training_model.inputs)),\r\n    strategy=tf.contrib.tpu.TPUDistributionStrategy(\r\n        tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)))\r\n\r\ntpu_model.fit_generator(\r\n    training_generator(seq_len=100, batch_size=1024),\r\n    steps_per_epoch=100,\r\n    epochs=10,\r\n)\r\ntpu_model.save_weights('/tmp/bard.h5', overwrite=True)\r\n``` ", "@davidpham87 did you ever find a fix for this?", "I implemented the Estimator API (which will be depreciated in TF 2.0, lol)", "@davidpham87  \r\n\r\nI am trying to implement a siamese neural network with tf.keras and TPUs and I am running into the same issue \"ValueError: The dataset must return a 2-element tuple\" (when I have 2 input signals and 1 labelp; 3 inputs in total for the model)\r\n\r\nI am getting this error even when using the Estimator API. May I ask you what Estimator API you used to solve this problem?\r\n", "Note: I'm working on Swift now, sorry!", "@davidpham87 Is this still an issue or was it resolved? Could you check with latest version of TF and let us know. Thanks!", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will open a new issue. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=23659\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=23659\">No</a>\n", "Hi! Has anyone solved this issue?\r\n\r\nMy workaround is to replace the first half of `_validate_shapes()` function in `keras_support.py` with the following. It works great for me, at least!\r\n\r\n```\r\ndef _validate_shapes(model):\r\n  \"\"\"Validate that all layers in `model` have constant shape.\"\"\"\r\n  for layer in model.layers:\r\n    for i in range(len(layer._inbound_nodes)):\r\n      input_shape = layer.get_input_shape_at(i)\r\n\r\n      if isinstance(input_shape, tuple):\r\n        input_shapes = [input_shape]\r\n      else:\r\n        input_shapes = input_shape\r\n\r\n    for i in range(len(layer._inbound_nodes)):\r\n      output_shape = layer.get_output_shape_at(i)\r\n\r\n      if isinstance(output_shape, tuple):\r\n        output_shapes = [output_shape]\r\n      else:\r\n        output_shapes = output_shape\r\n\r\n  for shape in input_shapes + output_shapes:\r\n    for dim in shape[1:]:\r\n    ... (omitted)\r\n```\r\n\r\nI hope this helps!"]}, {"number": 23658, "title": "Fix ValueError by image.transform in eager mode", "body": "This fix tries to address the issue raised in #23654 where in eager mode tf.contrib.image.transform will throw out\r\n```\r\nValueError: The truth value of an array with more than one\r\n    element is ambiguous. Use a.any() or a.all()\r\n```\r\n\r\nThis fix addresses the issue. This fix fixes #23654.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["Ping @ringw, any chance to take a look at the PR?"]}, {"number": 23657, "title": "Multiple tensorflow devices created, then programs ends", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Written\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:-\r\n- TensorFlow installed from (source or binary): source(?) 1.12 from pip.\r\n- TensorFlow version (use command below): 1.12\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source):-\r\n- GCC/Compiler version (if compiling from source):-\r\n- CUDA/cuDNN version: 9.0\r\n- GPU model and memory: GTX 1070Ti 8GB\r\n\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n**Describe the current behavior**\r\nOriginally was not an issue. Tensorflow now creates multiple devices, see log. I installed baseline for OpenAI and this started after that. I reinstalled tensorflow and the issue persists.\r\n\r\nMy scripts no longer execute because of this.\r\n\r\n**Code to reproduce the issue**\r\nAll code results in the issue.\r\n\r\n**Other info / logs**\r\n2018-11-10 14:29:08.296852: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-11-10 14:29:08.297012: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \r\n2018-11-10 14:29:08.297107: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \r\n2018-11-10 14:29:08.297353: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6393 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n\r\n2018-11-10 14:29:08.577708: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\r\n2018-11-10 14:29:08.577917: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-11-10 14:29:08.578069: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \r\n2018-11-10 14:29:08.578162: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \r\n2018-11-10 14:29:08.578303: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/device:GPU:0 with 6393 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n_________________________________________________________________\r\n2018-11-10 14:29:15.921961: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\r\n2018-11-10 14:29:15.922125: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-11-10 14:29:15.922269: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \r\n2018-11-10 14:29:15.922362: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \r\n2018-11-10 14:29:15.922500: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/device:GPU:0 with 6393 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n", "comments": ["Do you have a small example I can run to reproduce the issue?", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "> Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n\r\nDitto."]}, {"number": 23656, "title": "Java - java.lang.UnsatisfiedLinkError: tensorflow_jni.dll: Can't find dependent libraries (only GPU version)", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- TensorFlow installed from (source or binary): Tried to compile it from source and tried binary file\r\n- TensorFlow version: 1.12.0\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source): 15.0\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: CUDA 10.0 & cuDNN 7.3.0\r\n- GPU model and memory: GTX 970 TI\r\n\r\n\r\n**Describe the problem**\r\nHello, I'm actually trying to contact you here because I'm stuck on that error for 2 days and it is frustrating.\r\nWhen I'm trying to use tensorflow_jni.dll for GPU, it says that error but when I use the CPU version, it works. The problem is that by using CPU, it take 15 seconds to recognize one image using Yolo... with my i7 4770k... I installed Visual Studio 2017, 2015, Visual Studio Build Tool 2015 and Visual C++ 2015 Redistributable. I am using java 8\r\n\r\n**Source code / logs**\r\nIt does that error when tensorflow_jni.dll is being loaded by java.\r\nException in thread \"main\" java.lang.UnsatisfiedLinkError: C:\\Programmation\\test\\NeuralNetwork\\src\\org\\tensorflow\\native\\tensorflow_jni.dll: Can't find dependent libraries\r\n\r\n\r\nThank you really much and have a good day !", "comments": ["@leomelki Try to use Dependencies on tensorflow_jni.dll to see which DLL exactly is missing:\r\nhttps://github.com/lucasg/Dependencies", "I see that you are using python 3.7. Note that python 3.7 will be supported in TF 1.13 official version.\r\nHowever the good news is that TF 1.13.0-rc0 comes pre-built cuda 10 binaries.", "TF 1.13.1 has released and it supports Python 3.7. Please give it a try. Thanks!", "Hello, I am having the same problem as topic starter\r\n@saudet I don't see any suspicious in DependenciesGui. Any tips where to look and how to use it? Thanks!\r\n@ymodak Is python required to run tf java? It is not mentioned anywhere on https://www.tensorflow.org/install/lang_java... If I install anaconda and tf for python, will it magically fix missing dependencies?\r\nThanks in advance", "Hi there. Is there any update on this issue only for Java?", "This most likely doesn't occur with JavaCPP so please give that a try: https://github.com/tensorflow/java\r\nIf it's still not working for some reason, please open an new issue over there. Thanks!", "@saudet Sorry I am not very used to work with native libraries. Does that mean that I have to create my own wrapper of the tensorflow native classes i want to use and load them using JavaCPP?\r\nThank you for your quick answer", "No, the wrappers from this repository are no longer being maintaining.\r\nDevelopment has moved to this repository: https://github.com/tensorflow/java", "Sorry but I am not getting the point. What should be the approach then? ", "Try to use the artifacts made available from that subproject.", "Thank you. However the maven artifacts of that subproject are not even ready yet, are they?", "No, they're not. We're waiting on @ewilderj for build machines.\r\nThe default ones from GitHub Actions have an issue: https://github.com/tensorflow/java/pull/25\r\n\r\n/cc @karllessard ", "Thank you very much. \r\nAnd just in case someone finds it useful, the problem that was causing this error was that I was not using the correct CUDA version. I tried for tf 1.12 and tf 1.15. For tf 1.12 I needed CUDA 9.0 and for tf 1.15 I needed CUDA 10.0"]}, {"number": 23655, "title": "r1.12 C++ tutorials_example_trainer failed to build on Windows", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Windows 10 v1803 Pro 64bit English\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:N/A\r\n- TensorFlow installed from (source or binary):source\r\n- TensorFlow version:1.12\r\n- Python version:3.6\r\n- Installed using virtualenv? pip? conda?:pip\r\n- Bazel version (if compiling from source):0.15\r\n- GCC/Compiler version (if compiling from source):MSVC 2015 update 3\r\n- CUDA/cuDNN version:N/A\r\n- GPU model and memory:N/A\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n***Commands***\r\n```\r\nbazel build -c opt --verbose_failures //tensorflow/cc:tutorials_example_trainer\r\n```\r\n\r\n***Steps***\r\nSetup as described in [official document](https://www.tensorflow.org/install/source_windows)\r\n\r\n.bazelrc is customized in the following way.\r\n```\r\nimport (YOUR_TENSORFLOW_FOLDER)/tf_configure.bazelrc\r\n```\r\n.tf_configure.bazelrc is customized in the following way.\r\n```\r\nbuild:ignite --define with_ignite_support=true\r\nbuild:xla --define with_xla_support=false\r\nbuild --action_env TF_NEED_OPENCL_SYCL=\"0\"\r\nbuild --action_env TF_NEED_ROCM=\"0\"\r\nbuild --action_env TF_NEED_CUDA=\"0\"\r\nbuild --action_env TF_DOWNLOAD_CLANG=\"0\"\r\nbuild:opt --copt=/arch:AVX2\r\nbuild:opt --define with_default_optimizations=true\r\nbuild --copt=-w --host_copt=-w\r\nbuild --verbose_failures\r\nbuild --distinct_host_configuration=false\r\nbuild --experimental_shortened_obj_file_path=true\r\nbuild --define=no_tensorflow_py_deps=true\r\nbuild --define=override_eigen_strong_inline=true\r\nbuild:v2 --define=tf_api_version=2\r\n```\r\n\r\n**Any other info / logs**\r\n```\r\nunicode_script_op.lo.lib(unicode_script_op.obj) : error LNK2019: unresolved external symbol \"__declspec(dllimport) public: virtual __cdecl icu_62::ErrorCode::~ErrorCode(void)\" (__imp_??1ErrorCode@icu_62@@UEAA@XZ) referenced in function \"public: virtual void __cdecl tensorflow::UnicodeScriptOp::Compute(class tensorflow::OpKernelContext *)\" (?Compute@UnicodeScriptOp@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)\r\nunicode_script_op.lo.lib(unicode_script_op.obj) : error LNK2019: unresolved external symbol \"__declspec(dllimport) public: signed char __cdecl icu_62::ErrorCode::isSuccess(void)const \" (__imp_?isSuccess@ErrorCode@icu_62@@QEBACXZ) referenced in function \"public: virtual void __cdecl tensorflow::UnicodeScriptOp::Compute(class tensorflow::OpKernelContext *)\" (?Compute@UnicodeScriptOp@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)\r\nunicode_script_op.lo.lib(unicode_script_op.obj) : error LNK2019: unresolved external symbol \"__declspec(dllimport) public: enum UErrorCode __cdecl icu_62::ErrorCode::reset(void)\" (__imp_?reset@ErrorCode@icu_62@@QEAA?AW4UErrorCode@@XZ) referenced in function \"public: virtual void __cdecl tensorflow::UnicodeScriptOp::Compute(class tensorflow::OpKernelContext *)\" (?Compute@UnicodeScriptOp@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)\r\nunicode_script_op.lo.lib(unicode_script_op.obj) : error LNK2019: unresolved external symbol \"__declspec(dllimport) const icu_62::ErrorCode::`vftable'\" (__imp_??_7ErrorCode@icu_62@@6B@) referenced in function \"public: virtual void __cdecl tensorflow::UnicodeScriptOp::Compute(class tensorflow::OpKernelContext *)\" (?Compute@UnicodeScriptOp@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)\r\n```\r\nSimilar to tutorials_example_trainer, build //tensorflow/examples/label_image:label_image also failed.", "comments": ["Took a look at this and the first build was done as the screenshot. [![Imgur](https://i.imgur.com/sQhvd0Wl.png)](https://imgur.com/sQhvd0W)", "Materials (rev1) are in https://gist.github.com/cielavenir/4b55dce31bbf93f5fee5c5b2bfbebfda.\r\n\r\nThe main thing win.patch consists of two parts.\r\n\r\nThe first is ICU. I needed to add U_STATIC_IMPLEMENTATION flag to link to original symbols, not `__imp_`. This had to be added also to third_party/icu/BUILD.bazel because udata.cpp tries to link __imp_icudt62_dat, which also we don't want.\r\n\r\nThe second is disabling framework_shared_object. I came up with because `tensorflow_framework` [^1] should be from `-ltensorflow_framework` or `libtensorflow_framework.so`. I knew this disabling is a workaround. To understand why disabling this makes the build successful is the next step.\r\n\r\n[^1]: `link.exe /nologo /OUT:bazel-out/host/bin/tensorflow/cc/ops/sparse_ops_gen_cc.exe tensorflow_framework /SUBSYSTEM:CONSOLE` # this tensorflow_framework is orphaned bad guy.", "@cielavenir I appreciate your kindness. I\u2019m gonna try your modification.\r\n\r\n*for everyone\r\nI heard final configuration and initial error log directly from him and updated this issue.*", "The ICU link error part was pasted, but tensorflow_framework.obj not found error is not pasted. So I'm pasting below.\r\n\r\n```\r\nERROR: C:/users/*********/tensorflow/tensorflow/cc/BUILD:456:1:\r\nLinking of rule '//tensorflow/cc:ops/data_flow_ops_gen_cc' failed\r\n(Exit 1181): link.exe failed: error executing command\r\n  cd D:/temp/_bazel_*********/kyctgnhj/execroot/org_tensorflow\r\n SET INCLUDE=C:\\Program Files (x86)\\Microsoft Visual Studio\r\n14.0\\VC\\INCLUDE;C:\\Program Files (x86)\\Microsoft Visual Studio\r\n14.0\\VC\\ATLMFC\\INCLUDE;C:\\Program Files (x86)\\Windows\r\nKits\\10\\include\\10.0.14393.0\\ucrt;C:\\Program Files (x86)\\Windows\r\nKits\\NETFXSDK\\4.6.1\\include\\um;C:\\Program Files (x86)\\Windows\r\nKits\\10\\include\\10.0.14393.0\\shared;C:\\Program Files (x86)\\Windows\r\nKits\\10\\include\\10.0.14393.0\\um;C:\\Program Files (x86)\\Windows\r\nKits\\10\\include\\10.0.14393.0\\winrt;\r\n    SET LIB=C:\\Program Files (x86)\\Microsoft Visual Studio\r\n14.0\\VC\\LIB\\amd64;C:\\Program Files (x86)\\Microsoft Visual Studio\r\n14.0\\VC\\ATLMFC\\LIB\\amd64;C:\\Program Files (x86)\\Windows\r\nKits\\10\\lib\\10.0.14393.0\\ucrt\\x64;C:\\Program Files (x86)\\Windows\r\nKits\\NETFXSDK\\4.6.1\\lib\\um\\x64;C:\\Program Files (x86)\\Windows\r\nKits\\10\\lib\\10.0.14393.0\\um\\x64;\r\n    SET PATH=C:\\Program Files (x86)\\Microsoft Visual Studio\r\n14.0\\Common7\\IDE\\CommonExtensions\\Microsoft\\TestWindow;C:\\Program\r\nFiles (x86)\\Microsoft Visual Studio\r\n14.0\\VC\\BIN\\amd64;C:\\Windows\\Microsoft.NET\\Framework64\\v4.0.30319;C:\\Program\r\nFiles (x86)\\Microsoft Visual Studio 14.0\\VC\\VCPackages;C:\\Program\r\nFiles (x86)\\Microsoft Visual Studio 14.0\\Common7\\IDE;C:\\Program Files\r\n(x86)\\Microsoft Visual Studio 14.0\\Common7\\Tools;C:\\Program Files\r\n(x86)\\Microsoft Visual Studio 14.0\\Team Tools\\Performance\r\nTools\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Team\r\nTools\\Performance Tools;C:\\Program Files (x86)\\Windows\r\nKits\\10\\bin\\x64;C:\\Program Files (x86)\\Windows\r\nKits\\10\\bin\\x86;C:\\Program Files (x86)\\Microsoft\r\nSDKs\\Windows\\v10.0A\\bin\\NETFX 4.6.1 Tools\\x64\\;;C:\\Windows\\system32\r\n    SET PWD=/proc/self/cwd\r\n    SET PYTHON_BIN_PATH=C:/Python36/python.exe\r\n    SET PYTHON_LIB_PATH=C:/Python36/lib/site-packages\r\n    SET TEMP=D:\\temp\\\r\n    SET TF_DOWNLOAD_CLANG=0\r\n    SET TF_NEED_CUDA=0\r\n    SET TF_NEED_OPENCL_SYCL=0\r\n    SET TF_NEED_ROCM=0\r\n    SET TMP=D:\\temp\\\r\n    SET USE_LINKER=1\r\n  C:/Program Files (x86)/Microsoft Visual Studio\r\n14.0/VC/bin/amd64/link.exe /nologo\r\n/OUT:bazel-out/x64_windows-opt/bin/tensorflow/cc/ops/data_flow_ops_gen_cc.exe\r\ntensorflow_framework /SUBSYSTEM:CONSOLE /MACHINE:X64\r\n@bazel-out/x64_windows-opt/bin/tensorflow/cc/ops/data_flow_ops_gen_cc.exe-2.params\r\nLINK : fatal error LNK1181: cannot open input file 'tensorflow_framework.obj'\r\nTarget //tensorflow/cc:tutorials_example_trainer failed to build\r\n```", "I found that the following option in .tf_configure.bazelrc raises the above LNK1181 error.\r\nThis option is automatically added by configure.py.\r\nSo we should manually remove this option before build.\r\n``` \r\nbuild --config monolithic\r\n```", "Hi\r\n\r\nI've just reproduced @cielavenir solution.\r\nIn my case, I only had to use the ICU flags: `#define U_STATIC_IMPLEMENTATION` and `\"-DU_STATIC_IMPLEMENTATION\"` to get it working. **No further changes were needed!**\r\n\r\nThanks for sharing your patch!\r\n\r\nMy setup:\r\nTensorflow r1.12\r\nVisual Studio 2015\r\nBazel 0.18.1\r\n\r\n\r\n\r\n", "actually bazelrc was not required so I removed it from gist", "Probable duplicate\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/24499", "@hgadig now I see this issue is closed, may I have the relevant commit?", "@stakemura @cielavenir @stbnps  how do you success?  i only changed code below according to @cielavenir 's tutorial\r\n\r\n1.  in D:\\tf3\\tensorflow-r1.12\\third_party\\icu\\BUILD.bazel \r\ncc_library(\r\n    name = \"icuuc\",\r\n    srcs = glob(\r\n        [\r\n            \"icu4c/source/common/*.c\",\r\n            \"icu4c/source/common/*.cpp\",\r\n            \"icu4c/source/stubdata/*.cpp\",\r\n        ],\r\n    ),\r\n    hdrs = glob([\r\n        \"icu4c/source/common/*.h\",\r\n    ]),\r\n    copts = [\r\n        \"-DU_COMMcON_IMPLEMENTATION\",\r\n        **\"-DU_STATIC_IMPLEMENTATION\",**\r\n        \"-DU_HAVE_STD_ATOMICS\",\r\n    ] + select({\r\n        \":android\": [\r\n\r\n2. in D:\\tf3\\tensorflow-r1.12\\tensorflow\\BUILD\r\n //Crosses between framework_shared_object and a bunch of other configurations\r\n //due to limitations in nested select() statements.\r\nconfig_setting(\r\n    name = \"framework_shared_object\",\r\n    define_values = {\r\n        **\"framework_shared_object\": \"false\",**\r\n    },\r\n    visibility = [\"//visibility:public\"],\r\n)\r\n\r\n3. in D:\\tf3\\tensorflow-r1.12\\tensorflow\\core\\kernels\\unicode_script_op.cc\r\n==============================================================================*/\r\n\r\n**#define U_STATIC_IMPLEMENTATION**\r\n\r\n#include \"unicode/errorcode.h\"  // TF:icu\r\n#include \"unicode/uscript.h\"  // TF:icu\r\n#include \"tensorflow/core/framework/op_kernel.h\"\r\n\r\nand then i run   \"bazel build --config=opt --config=cuda  //tensorflow:libtensorflow_cc.so\"\r\n\r\nFAILED: Build did NOT complete successfully (94 packages loaded)\r\njava.lang.RuntimeException: **Unrecoverable error while evaluating node** '//tensorflow/cc:ops/data_flow_ops_gen_cc BuildConfigurationValue.Key[40ef114e63aa727cdd3c39a233ab7f41] false' (requested by nodes '//tensorflow/cc:data_flow_ops_genrule BuildConfigurationValue.Key[40ef114e63aa727cdd3c39a233ab7f41] false')\r\n        at com.google.devtools.build.skyframe.AbstractParallelEvaluator$Evaluate.run(AbstractParallelEvaluator.java:497)\r\n        at com.google.devtools.build.lib.concurrent.AbstractQueueVisitor$WrappedRunnable.run(AbstractQueueVisitor.java:368)\r\n        at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n        at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n        at java.base/java.lang.Thread.run(Unknown Source)\r\nCaused by: java.lang.IllegalStateException\r\n        at com.google.common.base.Preconditions.checkState(Preconditions.java:491)\r\n        at com.google.devtools.build.lib.rules.cpp.LibrariesToLinkCollector.addDynamicInputLinkOptions(LibrariesToLinkCollector.java:290)\r\n        at com.google.devtools.build.lib.rules.cpp.LibrariesToLinkCollector.addLinkerInputs(LibrariesToLinkCollector.java:258)\r\n        at com.google.devtools.build.lib.rules.cpp.LibrariesToLinkCollector.collectLibrariesToLink(LibrariesToLinkCollector.java:203)\r\n        at com.google.devtools.build.lib.rules.cpp.CppLinkActionBuilder.build(CppLinkActionBuilder.java:916)\r\n        at com.google.devtools.build.lib.rules.cpp.CcBinary.init(CcBinary.java:413)\r\n        at com.google.devtools.build.lib.rules.cpp.CcBinary.create(CcBinary.java:179)\r\n        at com.google.devtools.build.lib.rules.cpp.CcBinary.create(CcBinary.java:71)\r\n        at com.google.devtools.build.lib.analysis.ConfiguredTargetFactory.createRule(ConfiguredTargetFactory.java:320)\r\n        at com.google.devtools.build.lib.analysis.ConfiguredTargetFactory.createConfiguredTarget(ConfiguredTargetFactory.java:205)\r\n        at com.google.devtools.build.lib.skyframe.SkyframeBuildView.createConfiguredTarget(SkyframeBuildView.java:631)\r\n        at com.google.devtools.build.lib.skyframe.ConfiguredTargetFunction.createConfiguredTarget(ConfiguredTargetFunction.java:770)\r\n        at com.google.devtools.build.lib.skyframe.ConfiguredTargetFunction.compute(ConfiguredTargetFunction.java:320)\r\n        at com.google.devtools.build.skyframe.AbstractParallelEvaluator$Evaluate.run(AbstractParallelEvaluator.java:420)\r\n        ... 4 more\r\njava.lang.RuntimeException: Unrecoverable error while evaluating node '//tensorflow/cc:ops/data_flow_ops_gen_cc BuildConfigurationValue.Key[40ef114e63aa727cdd3c39a233ab7f41] false' (requested by nodes '//tensorflow/cc:data_flow_ops_genrule BuildConfigurationValue.Key[40ef114e63aa727cdd3c39a233ab7f41] false')\r\n        at com.google.devtools.build.skyframe.AbstractParallelEvaluator$Evaluate.run(AbstractParallelEvaluator.java:497)\r\n        at com.google.devtools.build.lib.concurrent.AbstractQueueVisitor$WrappedRunnable.run(AbstractQueueVisitor.java:368)\r\n        at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n        at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n        at java.base/java.lang.Thread.run(Unknown Source)\r\nCaused by: java.lang.IllegalStateException\r\n        at com.google.common.base.Preconditions.checkState(Preconditions.java:491)\r\n        at com.google.devtools.build.lib.rules.cpp.LibrariesToLinkCollector.addDynamicInputLinkOptions(LibrariesToLinkCollector.java:290)\r\n        at com.google.devtools.build.lib.rules.cpp.LibrariesToLinkCollector.addLinkerInputs(LibrariesToLinkCollector.java:258)\r\n        at com.google.devtools.build.lib.rules.cpp.LibrariesToLinkCollector.collectLibrariesToLink(LibrariesToLinkCollector.java:203)\r\n        at com.google.devtools.build.lib.rules.cpp.CppLinkActionBuilder.build(CppLinkActionBuilder.java:916)\r\n        at com.google.devtools.build.lib.rules.cpp.CcBinary.init(CcBinary.java:413)\r\n        at com.google.devtools.build.lib.rules.cpp.CcBinary.create(CcBinary.java:179)\r\n        at com.google.devtools.build.lib.rules.cpp.CcBinary.create(CcBinary.java:71)\r\n        at com.google.devtools.build.lib.analysis.ConfiguredTargetFactory.createRule(ConfiguredTargetFactory.java:320)\r\n        at com.google.devtools.build.lib.analysis.ConfiguredTargetFactory.createConfiguredTarget(ConfiguredTargetFactory.java:205)\r\n        at com.google.devtools.build.lib.skyframe.SkyframeBuildView.createConfiguredTarget(SkyframeBuildView.java:631)\r\n        at com.google.devtools.build.lib.skyframe.ConfiguredTargetFunction.createConfiguredTarget(ConfiguredTargetFunction.java:770)\r\n        at com.google.devtools.build.lib.skyframe.ConfiguredTargetFunction.compute(ConfiguredTargetFunction.java:320)\r\n        at com.google.devtools.build.skyframe.AbstractParallelEvaluator$Evaluate.run(AbstractParallelEvaluator.java:420)\r\nFAILED: Build did NOT complete successfully (94 packages loaded)\r\n\r\nand now how can i to do correctly? thanks for a lot.", "@jesen8 Perhaps your bazel is too new. Try 0.15.0.", "oh!, @cielavenir , thanks foy your help, but after i change bazel to 0.15, the new error has occurred,that's below:\r\n\r\nD:/tf3/tensorflow-r1.12/tensorflow/cc/BUILD:456:1: Linking of rule '//tensorflow/cc:ops/state_ops_gen_cc' failed (Exit 1120): link.exe failed: error executing command\r\n  cd C:/users/swls/_bazel_swls/5dz6uozl/execroot/org_tensorflow\r\n  SET CUDA_TOOLKIT_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.0\r\n    SET CUDNN_INSTALL_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.0\r\n    SET INCLUDE=C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\ATLMFC\\INCLUDE;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\ucrt;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.6.1\\include\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\shared;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\winrt;\r\n    SET LIB=C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\LIB\\amd64;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\ATLMFC\\LIB\\amd64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.17763.0\\ucrt\\x64;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.6.1\\lib\\um\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.17763.0\\um\\x64;\r\n    SET PATH=C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Common7\\IDE\\CommonExtensions\\Microsoft\\TestWindow;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\amd64;C:\\Windows\\Microsoft.NET\\Framework64\\v4.0.30319;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\VCPackages;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Common7\\IDE;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Common7\\Tools;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Team Tools\\Performance Tools\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Team Tools\\Performance Tools;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\x86;C:\\Program Files (x86)\\Microsoft SDKs\\Windows\\v10.0A\\bin\\NETFX 4.6.1 Tools\\x64\\;;C:\\Windows\\system32\r\n    SET PWD=/proc/self/cwd\r\n    SET PYTHON_BIN_PATH=C:/Python35/python.exe\r\n    SET PYTHON_LIB_PATH=C:/Python35/lib/site-packages\r\n    SET TEMP=C:\\Users\\swls\\AppData\\Local\\Temp\r\n    SET TF_CUDA_CLANG=0\r\n    SET TF_CUDA_COMPUTE_CAPABILITIES=6.1\r\n    SET TF_CUDA_VERSION=10.0\r\n    SET TF_CUDNN_VERSION=7\r\n    SET TF_NEED_CUDA=1\r\n    SET TF_NEED_OPENCL_SYCL=0\r\n    SET TF_NEED_ROCM=0\r\n    SET TMP=C:\\Users\\swls\\AppData\\Local\\Temp\r\n  C:/Program Files (x86)/Microsoft Visual Studio 14.0/VC/bin/amd64/link.exe /nologo /OUT:bazel-out/x64_windows-opt/bin/tensorflow/cc/ops/state_ops_gen_cc /SUBSYSTEM:CONSOLE -Wl,-rpath,../local_config_cuda/cuda/lib64 -Wl,-rpath,../local_config_cuda/cuda/extras/CUPTI/lib64 /MACHINE:X64 @bazel-out/x64_windows-opt/bin/tensorflow/cc/ops/state_ops_gen_cc-2.params\r\nLINK : warning LNK4044: unrecognized option '/Wl,-rpath,../local_config_cuda/cuda/lib64'; ignored\r\nLINK : warning LNK4044: unrecognized option '/Wl,-rpath,../local_config_cuda/cuda/extras/CUPTI/lib64'; ignored\r\n\r\nlibstate_ops_op_lib.lo(state_ops.o) : error LNK2019: unresolved external symbol \"public: virtual __cdecl tensorflow::internal::LogMessageFatal::~LogMessageFatal(void)\" (??1LogMessageFatal@internal@tensorflow@@UEAA@XZ) referenced in function \"public: void __cdecl tensorflow::internal::LogMessageFatal::`vbase destructor'(void)\" (??_DLogMessageFatal@internal@tensorflow@@QEAAXXZ)\r\n\r\nlibcc_op_gen_main.a(cc_op_gen_main.o) : error LNK2001: unresolved external symbol \"public: virtual __cdecl tensorflow::internal::LogMessageFatal::~LogMessageFatal(void)\" (??1LogMessageFatal@internal@tensorflow@@UEAA@XZ)\r\n\r\nlibcc_op_gen_main.a(cc_op_gen.o) : error LNK2001: unresolved external symbol \"public: virtual __cdecl tensorflow::internal::LogMessageFatal::~LogMessageFatal(void)\" (??1LogMessageFatal@internal@tensorflow@@UEAA@XZ)\r\n\r\nlibop_gen_lib.a(op_gen_lib.o) : error LNK2001: unresolved external symbol \"public: virtual __cdecl tensorflow::internal::LogMessageFatal::~LogMessageFatal(void)\" (??1LogMessageFatal@internal@tensorflow@@UEAA@XZ)\r\n\r\n.......\r\n\r\nlibop_gen_lib.a(op_gen_lib.o) : error LNK2019: unresolved external symbol \"bool __cdecl tensorflow::str_util::EndsWith(class absl::string_view,class absl::string_view)\" (?EndsWith@str_util@tensorflow@@YA_NVstring_view@absl@@0@Z) referenced in function \"class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > __cdecl tensorflow::WordWrap(class absl::string_view,class absl::string_view,int)\" (?WordWrap@tensorflow@@YA?AV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@Vstring_view@absl@@0H@Z)\r\n\r\nlibop_gen_lib.a(op_gen_lib.o) : error LNK2019: unresolved external symbol \"public: static bool __cdecl google::protobuf::TextFormat::ParseFromString(class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const &,class google::protobuf::Message *)\" (?ParseFromString@TextFormat@protobuf@google@@SA_NAEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@PEAVMessage@23@@Z) referenced in function \"public: class tensorflow::Status __cdecl tensorflow::ApiDefMap::LoadApiDef(class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const &)\" (?LoadApiDef@ApiDefMap@tensorflow@@QEAA?AVStatus@2@AEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@Z)\r\n\r\nlibop_gen_lib.a(op_gen_lib.o) : error LNK2019: unresolved external symbol \"class tensorflow::Status __cdecl tensorflow::ReadFileToString(class tensorflow::Env *,class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const &,class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > *)\" (?ReadFileToString@tensorflow@@YA?AVStatus@1@PEAVEnv@1@AEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@PEAV45@@Z) referenced in function \"public: class tensorflow::Status __cdecl tensorflow::ApiDefMap::LoadFile(class tensorflow::Env *,class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const &)\" (?LoadFile@ApiDefMap@tensorflow@@QEAA?AVStatus@2@PEAVEnv@2@AEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@Z)\r\n\r\nlibop_gen_lib.a(op_gen_lib.o) : error LNK2019: unresolved external symbol \"class tensorflow::OpDef_AttrDefDefaultTypeInternal tensorflow::_OpDef_AttrDef_default_instance_\" (?_OpDef_AttrDef_default_instance_@tensorflow@@3VOpDef_AttrDefDefaultTypeInternal@1@A) referenced in function \"void __cdecl tensorflow::`anonymous namespace'::InitApiDefFromOpDef(class tensorflow::OpDef const &,class tensorflow::ApiDef *)\" (?InitApiDefFromOpDef@?A0x86251cb0@tensorflow@@YAXAEBVOpDef@2@PEAVApiDef@2@@Z)\r\n\r\nbazel-out/x64_windows-opt/bin/tensorflow/cc/ops/state_ops_gen_cc : fatal error LNK1120: 102 unresolved externals\r\nTarget //tensorflow:libtensorflow_cc.so failed to build\r\nINFO: Elapsed time: 2549.567s, Critical Path: 249.94s\r\nINFO: 3296 processes: 3296 local.\r\nFAILED: Build did NOT complete successfully\r\n\r\ni'm so bad to build tf for five days all fialed...,i need your help,,,please\r\nIt seems to have something to do with \"libop_gen_lib.a(op_gen_lib.o)\",,,but i don't know", "@tensorflow-copybara Sorry but this error has not been addressed yet.\r\n\r\n```\r\nERROR: C:/users/stakemura/tensorflow/tensorflow/cc/BUILD:456:1: Linking of rule '//tensorflow/cc:ops/sparse_ops_gen_cc' failed (Exit 1181): link.exe failed: error executing command\r\n  cd C:/users/stakemura/_bazel_stakemura/kyctgnhj/execroot/org_tensorflow\r\n  SET INCLUDE=C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\ATLMFC\\INCLUDE;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.14393.0\\ucrt;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.6.1\\include\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.14393.0\\shared;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.14393.0\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.14393.0\\winrt;\r\n    SET LIB=C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\LIB\\amd64;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\ATLMFC\\LIB\\amd64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.14393.0\\ucrt\\x64;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.6.1\\lib\\um\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.14393.0\\um\\x64;\r\n    SET PATH=C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Common7\\IDE\\CommonExtensions\\Microsoft\\TestWindow;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\amd64;C:\\Windows\\Microsoft.NET\\Framework64\\v4.0.30319;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\VCPackages;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Common7\\IDE;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Common7\\Tools;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Team Tools\\Performance Tools\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Team Tools\\Performance Tools;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\x86;C:\\Program Files (x86)\\Microsoft SDKs\\Windows\\v10.0A\\bin\\NETFX 4.6.1 Tools\\x64\\;;C:\\Windows\\system32\r\n    SET PWD=/proc/self/cwd\r\n    SET TEMP=C:\\Users\\STAKEM~1\\AppData\\Local\\Temp\r\n    SET TMP=C:\\Users\\STAKEM~1\\AppData\\Local\\Temp\r\n    SET USE_LINKER=1\r\n  C:/Program Files (x86)/Microsoft Visual Studio 14.0/VC/bin/amd64/link.exe /nologo /OUT:bazel-out/host/bin/tensorflow/cc/ops/sparse_ops_gen_cc.exe tensorflow_framework /SUBSYSTEM:CONSOLE /MACHINE:X64 @bazel-out/host/bin/tensorflow/cc/ops/sparse_ops_gen_cc.exe-2.params\r\nLINK : fatal error LNK1181: cannot open input file 'tensorflow_framework.obj'\r\nTarget //tensorflow/cc:tutorials_example_trainer failed to build\r\n```\r\n\r\nIt looks like I still need to force `\"framework_shared_object\": \"false\",`.", "@cielavenir you can try r1.11 version,it's no problem", "@jesen8 r1.11? The correct one is not r1.11 but r1.13,right? I believe the latest version should work.", "@stakemura  yeah,it's r1.13 right, i'm wrong", "@jesen8  Noted, thanks a lot!"]}, {"number": 23654, "title": "tf.contrib.image.transform lead to a ValueError in new releases of tensorflow", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Manjaro 18.0\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: -\r\n- TensorFlow installed from (source or binary): python-tensorflow-opt-cuda from manjaro repositories \r\n- TensorFlow version (use command below): 1.11\r\n- Python version: 3.6/3.7\r\n- Bazel version (if compiling from source): -\r\n- GCC/Compiler version (if compiling from source): -\r\n- CUDA/cuDNN version: 10.0.130-2 /   7.3.0-1\r\n- GPU model and memory: 1080Ti 11GB\r\n\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n**Describe the current behavior**\r\n\r\nAfter the release that Allow a different output shape from the input in `tf.contrib.image.transform` code that applied this function stopped working with a value error. For exampleon previous versions, using eager execution this worked:\r\n\r\n`image = tf.contrib.image.translate(image, random_translation, 'NEAREST') `\r\n\r\nBut after this change I get a `ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()`` on `tf.contrib.image.transform` on the condition of the line 273-275 of `tensorflow/tensorflow/contrib/image/python/ops/image_ops.py`, where this condition is triggered (caused by empty output shape call in tf.contrib.image.translate:\r\n\r\n```\r\nif output_shape is None:\r\n      output_shape = tensor_util.constant_value(\r\n          array_ops.shape(images)[1:3]) or array_ops.shape(images)[1:3]\r\n```\r\n\r\n**Describe the expected behavior**\r\n\r\nIf instead of `tf.contrib.image.transform` I run it with `output_shape` argument:\r\n\r\n`random_transformations = tf.contrib.image.translations_to_projective_transforms(random_shifts)\r\nimages = tf.contrib.image.transform(image, random_transformations, 'NEAREST',                                       output_shape=tf.convert_to_tensor(images.numpy().shape[1:3], dtype=np.int32))`\r\n\r\neverything goes as expected. So I guess that the issue in on passing output_shape=None in line 122-126 of `tensorflow/tensorflow/contrib/image/python/ops/image_ops.py:\r\n\r\n```\r\ndef translate(images, translations, interpolation=\"NEAREST\", name=None):\r\n  \"\"\"Translate image(s) by the passed vectors(s).\r\n  Args:\r\n    images: A tensor of shape (num_images, num_rows, num_columns, num_channels)\r\n        (NHWC), (num_rows, num_columns, num_channels) (HWC), or\r\n        (num_rows, num_columns) (HW). The rank must be statically known (the\r\n        shape is not `TensorShape(None)`.\r\n    translations: A vector representing [dx, dy] or (if images has rank 4)\r\n        a matrix of length num_images, with a [dx, dy] vector for each image in\r\n        the batch.\r\n    interpolation: Interpolation mode. Supported values: \"NEAREST\", \"BILINEAR\".\r\n    name: The name of the op.\r\n  Returns:\r\n    Image(s) with the same type and shape as `images`, translated by the given\r\n        vector(s). Empty space due to the translation will be filled with zeros.\r\n  Raises:\r\n    TypeError: If `image` is an invalid type.\r\n  \"\"\"\r\n  with ops.name_scope(name, \"translate\"):\r\n    return transform(\r\n        images,\r\n        translations_to_projective_transforms(translations),\r\n        interpolation=interpolation)\r\n\r\n```", "comments": ["Added PR #23658 for the fix.", "Nagging Assignee @wt-huang: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly."]}, {"number": 23653, "title": "Tensorflow installation issue: ImportError: DLL load failed with error code -1073741795", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 7 Service Pack1\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA\r\n- TensorFlow installed from (source or binary): https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-1.12.0-cp35-cp35m-win_amd64.whl\r\n- TensorFlow version: 1.12\r\n- Python version: 3.5.4 64-bit\r\n- Installed using virtualenv? pip? conda?: virtualenv\r\n- Bazel version (if compiling from source): \r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: \r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\nUnable to install and import Tensorflow on my PC. I have tried the below approach as mentioned on https://www.tensorflow.org/install/pip#package-location. I have also tried installation using Conda but the same problem appears. MS Visual C++ is also installed as mentioned on https://www.tensorflow.org/install/pip#package-location\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\npython -c \"import tensorflow as tf; tf.enable_eager_execution(); print(tf.reduce_sum(tf.random_normal([1000, 1000])))\"\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Desk\\AppData\\Local\\Programs\\Python\\Python35\\Scripts\\venv\\lib\\si\r\nte-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Desk\\AppData\\Local\\Programs\\Python\\Python35\\Scripts\\venv\\lib\\si\r\nte-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <modul\r\ne>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Desk\\AppData\\Local\\Programs\\Python\\Python35\\Scripts\\venv\\lib\\si\r\nte-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_i\r\nmport_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, descript\r\nion)\r\n  File \"C:\\Users\\Desk\\AppData\\Local\\Programs\\Python\\Python35\\Scripts\\venv\\lib\\im\r\np.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\Desk\\AppData\\Local\\Programs\\Python\\Python35\\Scripts\\venv\\lib\\im\r\np.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed with error code -1073741795\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\n  File \"C:\\Users\\Desk\\AppData\\Local\\Programs\\Python\\Python35\\Scripts\\venv\\lib\\si\r\nte-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-im\r\nport\r\n  File \"C:\\Users\\Desk\\AppData\\Local\\Programs\\Python\\Python35\\Scripts\\venv\\lib\\si\r\nte-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\Desk\\AppData\\Local\\Programs\\Python\\Python35\\Scripts\\venv\\lib\\si\r\nte-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\Desk\\AppData\\Local\\Programs\\Python\\Python35\\Scripts\\venv\\lib\\si\r\nte-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Desk\\AppData\\Local\\Programs\\Python\\Python35\\Scripts\\venv\\lib\\si\r\nte-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <modul\r\ne>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Desk\\AppData\\Local\\Programs\\Python\\Python35\\Scripts\\venv\\lib\\si\r\nte-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_i\r\nmport_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, descript\r\nion)\r\n  File \"C:\\Users\\Desk\\AppData\\Local\\Programs\\Python\\Python35\\Scripts\\venv\\lib\\im\r\np.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\Desk\\AppData\\Local\\Programs\\Python\\Python35\\Scripts\\venv\\lib\\im\r\np.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed with error code -1073741795", "comments": ["Got it fixed myself post looking for similar answers in internet...I had to install the airflow version 1.5 and the tensorflow backend loaded seamlessly."]}, {"number": 23652, "title": " tfjs-node - binary was not compiled to use: SSE4.2 AVX AVX2 FMA and performance on node", "body": "Hi\r\n\r\nI have looked for an issue in regards to .js and tfjs node but can't find one so apologies for reposting if i've missed it!\r\n\r\nWe're trying to deploy an API on EC2 which uses tfjs-node. My main concern is finding a way i can bring down inference time on a server.\r\n\r\nI have found instructions on using different binaries for python. Are these binaries compatible with the node tfjs wrapper? \r\n\r\nApart from anything else i assume theres a way to get rid of these warnings in the terminal?\r\n\r\n", "comments": ["Closing as this issue has been moved to the tfjs repo"]}, {"number": 23651, "title": "TFLiteConverter.from_session() error", "body": "Some of the operators in the model are not supported by the standard TensorFlow Lite runtime and are not recognized by TensorFlow. If you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, DIV, FLOOR, FULLY_CONNECTED, MUL. Here is a list of operators for which you will need custom implementations: RandomUniform.\r\n", "comments": ["As we work toward fleshing out the builtin op library for TensorFlow Lite, we've been working on an experimental feature that allows using select TensorFlow ops from within the TensorFlow Lite runtime. The goal is to help reduce some of the friction for using models that rely on ops not yet natively supported by TensorFlow Lite (at the cost of increased binary size). This feature requires opting in during model conversion, as well as adding an additional dependency. More details can be found\r\n[here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/using_select_tf_ops.md\r\n).\r\n\r\nFeedback is very much appreciated (either via GitHub or directly via tflite@tensorflow.org), and we'll be adding and refining functionality over the coming weeks. Cheers."]}, {"number": 23650, "title": "Exclude the log_dir from the metadata path", "body": "The metadata path should exclude the log directory. See https://github.com/tensorflow/tensorboard/issues/247.", "comments": ["I am not familiar with the code here. Please find another reviewer. ", "Nagging Reviewer @martinwicke, @andrewharp: You have been added as a reviewer to this pull request. Please add your review or reassign. It has been 14 days with no activity and the `awaiting review` label has been applied.", "@wolffg I believe this change is obsolete -- the tutorial has moved, correct?\r\n\r\nI will close it."]}, {"number": 23649, "title": "cannot link static library libtensorflow.a by go for tensorflow", "body": "\r\n**System information**\r\nGOARCH=\"amd64\"\r\nGOBIN=\"\"\r\nGOCACHE=\"/search/odin/tensorflow/.cache/go-build\"\r\nGOEXE=\"\"\r\nGOFLAGS=\"\"\r\nGOHOSTARCH=\"amd64\"\r\nGOHOSTOS=\"linux\"\r\nGOOS=\"linux\"\r\nGOPATH=\"/search/odin/tensorflow/gopath/\"\r\nGOPROXY=\"\"\r\nGORACE=\"\"\r\nGOROOT=\"/search/odin/tensorflow/go\"\r\nGOTMPDIR=\"\"\r\nGOTOOLDIR=\"/search/odin/tensorflow/go/pkg/tool/linux_amd64\"\r\nGCCGO=\"gccgo\"\r\nCC=\"gcc\"\r\nCXX=\"g++\"\r\nCGO_ENABLED=\"1\"\r\nGOMOD=\"\"\r\nCGO_CFLAGS=\"-I/search/odin/tensorflow/lib64/include\"\r\nCGO_CPPFLAGS=\"\"\r\nCGO_CXXFLAGS=\"-g -O2\"\r\nCGO_FFLAGS=\"-g -O2\"\r\nCGO_LDFLAGS=\"-L/search/odin/tensorflow/lib64/lib\"\r\nPKG_CONFIG=\"pkg-config\"\r\nGOGCCFLAGS=\"-std=gnu99 -fPIC -m64 -pthread -fmessage-length=0 -fdebug-prefix-map=/tmp/go-build821586571=/tmp/go-build -gno-record-gcc-switches\"\r\n\r\n\r\n**Describe the problem**\r\nI'm trying to build an executable binary file by go for tensorflow. I followed the official hello-world instructions and successfully go build everything. \r\nHowever, what I need is to link a static library libtensorflow.a instead of the dynamic one so that the executable binary file has no dependencies. **I managed to build the static library libtensorflow.a** through makefile offered with src(https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/makefile) and put it in **/search/odin/tensorflow/lib64/lib**, then I go build with the command below, and I get ld errors which I will post under **Any other info / logs**.\r\nA similar issue is [here](https://github.com/tensorflow/tensorflow/issues/15563). It seems the same problem but It's not. From what I see, it tries to build the libtensorflow.a by Go for Tensorflow then link it, but I have already got a libtensorflow.a in advance. All I need is to link the static library.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\ngo build -ldflags '-linkmode \"external\" -extldflags \"-static -L /search/odin/tensorflow/lib64/lib\"' hello_tf.go\r\n\r\n**Any other info / logs**\r\ncommand-line-arguments\r\n/search/odin/tensorflow/go/pkg/tool/linux_amd64/link: running gcc failed: exit status 1\r\n/tmp/go-link-707261891/000001.o: In function `_cgo_d969e426e2e3_Cfunc_TF_OperationGetAttrBool':\r\nattrs.cgo2.c:(.text+0x6d): undefined reference to `TF_OperationGetAttrBool'\r\n/tmp/go-link-707261891/000001.o: In function `_cgo_d969e426e2e3_Cfunc_TF_OperationGetAttrBoolList':\r\nattrs.cgo2.c:(.text+0xb4): undefined reference to `TF_OperationGetAttrBoolList'\r\n/tmp/go-link-707261891/000001.o: In function `_cgo_d969e426e2e3_Cfunc_TF_OperationGetAttrFloat':\r\nattrs.cgo2.c:(.text+0xf1): undefined reference to `TF_OperationGetAttrFloat'\r\n/tmp/go-link-707261891/000001.o: In function `_cgo_d969e426e2e3_Cfunc_TF_OperationGetAttrFloatList':\r\nattrs.cgo2.c:(.text+0x138): undefined reference to `TF_OperationGetAttrFloatList'\r\n/tmp/go-link-707261891/000001.o: In function `_cgo_d969e426e2e3_Cfunc_TF_OperationGetAttrInt':\r\nattrs.cgo2.c:(.text+0x175): undefined reference to `TF_OperationGetAttrInt'\r\n/tmp/go-link-707261891/000001.o: In function `_cgo_d969e426e2e3_Cfunc_TF_OperationGetAttrIntList':\r\nattrs.cgo2.c:(.text+0x1bc): undefined reference to `TF_OperationGetAttrIntList'\r\n/tmp/go-link-707261891/000001.o: In function `_cgo_d969e426e2e3_Cfunc_TF_OperationGetAttrMetadata':\r\nattrs.cgo2.c:(.text+0x1fe): undefined reference to `TF_OperationGetAttrMetadata'\r\n/tmp/go-link-707261891/000001.o: In function `_cgo_d969e426e2e3_Cfunc_TF_OperationGetAttrShape':\r\nattrs.cgo2.c:(.text+0x27f): undefined reference to `TF_OperationGetAttrShape'\r\n/tmp/go-link-707261891/000001.o: In function `_cgo_d969e426e2e3_Cfunc_TF_OperationGetAttrShapeList':\r\nattrs.cgo2.c:(.text+0x2e6): undefined reference to `TF_OperationGetAttrShapeList'\r\n/tmp/go-link-707261891/000001.o: In function `_cgo_d969e426e2e3_Cfunc_TF_OperationGetAttrString':\r\nattrs.cgo2.c:(.text+0x32e): undefined reference to `TF_OperationGetAttrString'\r\n/tmp/go-link-707261891/000001.o: In function `_cgo_d969e426e2e3_Cfunc_TF_OperationGetAttrStringList':\r\nattrs.cgo2.c:(.text+0x397): undefined reference to `TF_OperationGetAttrStringList'\r\n/tmp/go-link-707261891/000001.o: In function `_cgo_d969e426e2e3_Cfunc_TF_OperationGetAttrTensor':\r\nattrs.cgo2.c:(.text+0x3d4): undefined reference to `TF_OperationGetAttrTensor'\r\n/tmp/go-link-707261891/000001.o: In function `_cgo_d969e426e2e3_Cfunc_TF_OperationGetAttrTensorList':\r\nattrs.cgo2.c:(.text+0x41b): undefined reference to `TF_OperationGetAttrTensorList'\r\n/tmp/go-link-707261891/000001.o: In function `_cgo_d969e426e2e3_Cfunc_TF_OperationGetAttrType':\r\nattrs.cgo2.c:(.text+0x458): undefined reference to `TF_OperationGetAttrType'\r\n/tmp/go-link-707261891/000001.o: In function `_cgo_d969e426e2e3_Cfunc_TF_OperationGetAttrTypeList':\r\nattrs.cgo2.c:(.text+0x49f): undefined reference to `TF_OperationGetAttrTypeList'\r\n/tmp/go-link-707261891/000002.o: In function `TF_SetAttrShapeList_Helper':\r\ngraph.cgo2.c:(.text+0xf2): undefined reference to `TF_SetAttrShapeList'\r\n/tmp/go-link-707261891/000002.o: In function `_cgo_d969e426e2e3_Cfunc_TF_AddControlInput':\r\ngraph.cgo2.c:(.text+0x12e): undefined reference to `TF_AddControlInput'\r\n/tmp/go-link-707261891/000002.o: In function `_cgo_d969e426e2e3_Cfunc_TF_AddInput':\r\ngraph.cgo2.c:(.text+0x163): undefined reference to `TF_AddInput'\r\n/tmp/go-link-707261891/000002.o: In function `_cgo_d969e426e2e3_Cfunc_TF_AddInputList':\r\ngraph.cgo2.c:(.text+0x19a): undefined reference to `TF_AddInputList'\r\n/tmp/go-link-707261891/000002.o: In function `_cgo_d969e426e2e3_Cfunc_TF_DeleteBuffer':\r\ngraph.cgo2.c:(.text+0x1bf): undefined reference to `TF_DeleteBuffer'\r\n/tmp/go-link-707261891/000002.o: In function `_cgo_d969e426e2e3_Cfunc_TF_DeleteGraph':\r\ngraph.cgo2.c:(.text+0x1e4): undefined reference to `TF_DeleteGraph'\r\n/tmp/go-link-707261891/000002.o: In function `_cgo_d969e426e2e3_Cfunc_TF_DeleteImportGraphDefOptions':\r\ngraph.cgo2.c:(.text+0x209): undefined reference to `TF_DeleteImportGraphDefOptions'\r\n/tmp/go-link-707261891/000002.o: In function `_cgo_d969e426e2e3_Cfunc_TF_FinishOperation':\r\ngraph.cgo2.c:(.text+0x242): undefined reference to `TF_FinishOperation'\r\n/tmp/go-link-707261891/000002.o: In function `_cgo_d969e426e2e3_Cfunc_TF_GraphImportGraphDef':\r\ngraph.cgo2.c:(.text+0x2a5): undefined reference to `TF_GraphImportGraphDef'\r\n/tmp/go-link-707261891/000002.o: In function `_cgo_d969e426e2e3_Cfunc_TF_GraphNextOperation':\r\ngraph.cgo2.c:(.text+0x2de): undefined reference to `TF_GraphNextOperation'\r\n/tmp/go-link-707261891/000002.o: In function `_cgo_d969e426e2e3_Cfunc_TF_GraphOperationByName':\r\ngraph.cgo2.c:(.text+0x33d): undefined reference to `TF_GraphOperationByName'\r\n/tmp/go-link-707261891/000002.o: In function `_cgo_d969e426e2e3_Cfunc_TF_GraphToGraphDef':\r\ngraph.cgo2.c:(.text+0x39b): undefined reference to `TF_GraphToGraphDef'\r\n/tmp/go-link-707261891/000002.o: In function `_cgo_d969e426e2e3_Cfunc_TF_ImportGraphDefOptionsSetPrefix':\r\ngraph.cgo2.c:(.text+0x3cb): undefined reference to `TF_ImportGraphDefOptionsSetPrefix'\r\n/tmp/go-link-707261891/000002.o: In function `_cgo_d969e426e2e3_Cfunc_TF_NewBuffer':\r\ngraph.cgo2.c:(.text+0x3f4): undefined reference to `TF_NewBuffer'\r\n/tmp/go-link-707261891/000002.o: In function `_cgo_d969e426e2e3_Cfunc_TF_NewGraph':\r\ngraph.cgo2.c:(.text+0x442): undefined reference to `TF_NewGraph'\r\n/tmp/go-link-707261891/000002.o: In function `_cgo_d969e426e2e3_Cfunc_TF_NewImportGraphDefOptions':\r\ngraph.cgo2.c:(.text+0x490): undefined reference to `TF_NewImportGraphDefOptions'\r\n/tmp/go-link-707261891/000002.o: In function `_cgo_d969e426e2e3_Cfunc_TF_NewOperation':\r\ngraph.cgo2.c:(.text+0x4f6): undefined reference to `TF_NewOperation'\r\n/tmp/go-link-707261891/000002.o: In function `_cgo_d969e426e2e3_Cfunc_TF_SetAttrBool':\r\ngraph.cgo2.c:(.text+0x557): undefined reference to `TF_SetAttrBool'\r\n/tmp/go-link-707261891/000002.o: In function `_cgo_d969e426e2e3_Cfunc_TF_SetAttrBoolList':\r\ngraph.cgo2.c:(.text+0x593): undefined reference to `TF_SetAttrBoolList'\r\n/tmp/go-link-707261891/000002.o: In function `_cgo_d969e426e2e3_Cfunc_TF_SetAttrFloat':\r\ngraph.cgo2.c:(.text+0x5d2): undefined reference to `TF_SetAttrFloat'\r\n/tmp/go-link-707261891/000002.o: In function `_cgo_d969e426e2e3_Cfunc_TF_SetAttrFloatList':\r\ngraph.cgo2.c:(.text+0x60e): undefined reference to `TF_SetAttrFloatList'\r\n/tmp/go-link-707261891/000002.o: In function `_cgo_d969e426e2e3_Cfunc_TF_SetAttrInt':\r\ngraph.cgo2.c:(.text+0x646): undefined reference to `TF_SetAttrInt'\r\n/tmp/go-link-707261891/000002.o: In function `_cgo_d969e426e2e3_Cfunc_TF_SetAttrIntList':\r\ngraph.cgo2.c:(.text+0x682): undefined reference to `TF_SetAttrIntList'\r\n/tmp/go-link-707261891/000002.o: In function `_cgo_d969e426e2e3_Cfunc_TF_SetAttrShape':\r\ngraph.cgo2.c:(.text+0x6be): undefined reference to `TF_SetAttrShape'\r\n/tmp/go-link-707261891/000002.o: In function `_cgo_d969e426e2e3_Cfunc_TF_SetAttrShapeList':\r\ngraph.cgo2.c:(.text+0x705): undefined reference to `TF_SetAttrShapeList'\r\n/tmp/go-link-707261891/000002.o: In function `_cgo_d969e426e2e3_Cfunc_TF_SetAttrString':\r\ngraph.cgo2.c:(.text+0x789): undefined reference to `TF_SetAttrString'\r\n/tmp/go-link-707261891/000002.o: In function `_cgo_d969e426e2e3_Cfunc_TF_SetAttrStringList':\r\ngraph.cgo2.c:(.text+0x7d0): undefined reference to `TF_SetAttrStringList'\r\n/tmp/go-link-707261891/000002.o: In function `_cgo_d969e426e2e3_Cfunc_TF_SetAttrTensor':\r\ngraph.cgo2.c:(.text+0x80d): undefined reference to `TF_SetAttrTensor'\r\n/tmp/go-link-707261891/000002.o: In function `_cgo_d969e426e2e3_Cfunc_TF_SetAttrTensorList':\r\ngraph.cgo2.c:(.text+0x854): undefined reference to `TF_SetAttrTensorList'\r\n/tmp/go-link-707261891/000002.o: In function `_cgo_d969e426e2e3_Cfunc_TF_SetAttrType':\r\ngraph.cgo2.c:(.text+0x88b): undefined reference to `TF_SetAttrType'\r\n/tmp/go-link-707261891/000002.o: In function `_cgo_d969e426e2e3_Cfunc_TF_SetAttrTypeList':\r\ngraph.cgo2.c:(.text+0x8c7): undefined reference to `TF_SetAttrTypeList'\r\n/tmp/go-link-707261891/000002.o: In function `_cgo_d969e426e2e3_Cfunc_TF_SetDevice':\r\ngraph.cgo2.c:(.text+0x8f7): undefined reference to `TF_SetDevice'\r\n/tmp/go-link-707261891/000004.o: In function `_cgo_d969e426e2e3_Cfunc_TF_GraphGetTensorNumDims':\r\noperation.cgo2.c:(.text+0x73): undefined reference to `TF_GraphGetTensorNumDims'\r\n/tmp/go-link-707261891/000004.o: In function `_cgo_d969e426e2e3_Cfunc_TF_GraphGetTensorShape':\r\noperation.cgo2.c:(.text+0xe5): undefined reference to `TF_GraphGetTensorShape'\r\n/tmp/go-link-707261891/000004.o: In function `_cgo_d969e426e2e3_Cfunc_TF_OperationDevice':\r\noperation.cgo2.c:(.text+0x113): undefined reference to `TF_OperationDevice'\r\n/tmp/go-link-707261891/000004.o: In function `_cgo_d969e426e2e3_Cfunc_TF_OperationInput':\r\noperation.cgo2.c:(.text+0x16c): undefined reference to `TF_OperationInput'\r\n/tmp/go-link-707261891/000004.o: In function `_cgo_d969e426e2e3_Cfunc_TF_OperationInputType':\r\noperation.cgo2.c:(.text+0x1d5): undefined reference to `TF_OperationInputType'\r\n/tmp/go-link-707261891/000004.o: In function `_cgo_d969e426e2e3_Cfunc_TF_OperationName':\r\noperation.cgo2.c:(.text+0x226): undefined reference to `TF_OperationName'\r\n/tmp/go-link-707261891/000004.o: In function `_cgo_d969e426e2e3_Cfunc_TF_OperationNumInputs':\r\noperation.cgo2.c:(.text+0x27a): undefined reference to `TF_OperationNumInputs'\r\n/tmp/go-link-707261891/000004.o: In function `_cgo_d969e426e2e3_Cfunc_TF_OperationNumOutputs':\r\noperation.cgo2.c:(.text+0x2cb): undefined reference to `TF_OperationNumOutputs'\r\n/tmp/go-link-707261891/000004.o: In function `_cgo_d969e426e2e3_Cfunc_TF_OperationOpType':\r\noperation.cgo2.c:(.text+0x31c): undefined reference to `TF_OperationOpType'\r\n/tmp/go-link-707261891/000004.o: In function `_cgo_d969e426e2e3_Cfunc_TF_OperationOutputConsumers':\r\noperation.cgo2.c:(.text+0x384): undefined reference to `TF_OperationOutputConsumers'\r\n/tmp/go-link-707261891/000004.o: In function `_cgo_d969e426e2e3_Cfunc_TF_OperationOutputListLength':\r\noperation.cgo2.c:(.text+0x3e8): undefined reference to `TF_OperationOutputListLength'\r\n/tmp/go-link-707261891/000004.o: In function `_cgo_d969e426e2e3_Cfunc_TF_OperationOutputNumConsumers':\r\noperation.cgo2.c:(.text+0x43e): undefined reference to `TF_OperationOutputNumConsumers'\r\n/tmp/go-link-707261891/000004.o: In function `_cgo_d969e426e2e3_Cfunc_TF_OperationOutputType':\r\noperation.cgo2.c:(.text+0x494): undefined reference to `TF_OperationOutputType'\r\n/tmp/go-link-707261891/000005.o: In function `_cgo_d969e426e2e3_Cfunc_TF_LoadSessionFromSavedModel':\r\nsaved_model.cgo2.c:(.text+0xa2): undefined reference to `TF_LoadSessionFromSavedModel'\r\n/tmp/go-link-707261891/000006.o: In function `_cgo_d969e426e2e3_Cfunc_TF_CloseSession':\r\nsession.cgo2.c:(.text+0x60): undefined reference to `TF_CloseSession'\r\n/tmp/go-link-707261891/000006.o: In function `_cgo_d969e426e2e3_Cfunc_TF_DeleteDeviceList':\r\nsession.cgo2.c:(.text+0x85): undefined reference to `TF_DeleteDeviceList'\r\n/tmp/go-link-707261891/000006.o: In function `_cgo_d969e426e2e3_Cfunc_TF_DeletePRunHandle':\r\nsession.cgo2.c:(.text+0xaa): undefined reference to `TF_DeletePRunHandle'\r\n/tmp/go-link-707261891/000006.o: In function `_cgo_d969e426e2e3_Cfunc_TF_DeleteSession':\r\nsession.cgo2.c:(.text+0xda): undefined reference to `TF_DeleteSession'\r\n/tmp/go-link-707261891/000006.o: In function `_cgo_d969e426e2e3_Cfunc_TF_DeleteSessionOptions':\r\nsession.cgo2.c:(.text+0xff): undefined reference to `TF_DeleteSessionOptions'\r\n/tmp/go-link-707261891/000006.o: In function `_cgo_d969e426e2e3_Cfunc_TF_DeviceListCount':\r\nsession.cgo2.c:(.text+0x12d): undefined reference to `TF_DeviceListCount'\r\n/tmp/go-link-707261891/000006.o: In function `_cgo_d969e426e2e3_Cfunc_TF_DeviceListMemoryBytes':\r\nsession.cgo2.c:(.text+0x18f): undefined reference to `TF_DeviceListMemoryBytes'\r\n/tmp/go-link-707261891/000006.o: In function `_cgo_d969e426e2e3_Cfunc_TF_DeviceListName':\r\nsession.cgo2.c:(.text+0x1f4): undefined reference to `TF_DeviceListName'\r\n/tmp/go-link-707261891/000006.o: In function `_cgo_d969e426e2e3_Cfunc_TF_DeviceListType':\r\nsession.cgo2.c:(.text+0x259): undefined reference to `TF_DeviceListType'\r\n/tmp/go-link-707261891/000006.o: In function `_cgo_d969e426e2e3_Cfunc_TF_NewSession':\r\nsession.cgo2.c:(.text+0x2c0): undefined reference to `TF_NewSession'\r\n/tmp/go-link-707261891/000006.o: In function `_cgo_d969e426e2e3_Cfunc_TF_NewSessionOptions':\r\nsession.cgo2.c:(.text+0x30f): undefined reference to `TF_NewSessionOptions'\r\n/tmp/go-link-707261891/000006.o: In function `_cgo_d969e426e2e3_Cfunc_TF_SessionListDevices':\r\nsession.cgo2.c:(.text+0x36d): undefined reference to `TF_SessionListDevices'\r\n/tmp/go-link-707261891/000006.o: In function `_cgo_d969e426e2e3_Cfunc_TF_SessionPRun':\r\nsession.cgo2.c:(.text+0x428): undefined reference to `TF_SessionPRun'\r\n/tmp/go-link-707261891/000006.o: In function `_cgo_d969e426e2e3_Cfunc_TF_SessionPRunSetup':\r\nsession.cgo2.c:(.text+0x4a5): undefined reference to `TF_SessionPRunSetup'\r\n/tmp/go-link-707261891/000006.o: In function `_cgo_d969e426e2e3_Cfunc_TF_SessionRun':\r\nsession.cgo2.c:(.text+0x54a): undefined reference to `TF_SessionRun'\r\n/tmp/go-link-707261891/000006.o: In function `_cgo_d969e426e2e3_Cfunc_TF_SetConfig':\r\nsession.cgo2.c:(.text+0x590): undefined reference to `TF_SetConfig'\r\n/tmp/go-link-707261891/000006.o: In function `_cgo_d969e426e2e3_Cfunc_TF_SetTarget':\r\nsession.cgo2.c:(.text+0x5c0): undefined reference to `TF_SetTarget'\r\n/tmp/go-link-707261891/000007.o: In function `_cgo_d969e426e2e3_Cfunc_TF_DeleteStatus':\r\nstatus.cgo2.c:(.text+0x55): undefined reference to `TF_DeleteStatus'\r\n/tmp/go-link-707261891/000007.o: In function `_cgo_d969e426e2e3_Cfunc_TF_GetCode':\r\nstatus.cgo2.c:(.text+0x83): undefined reference to `TF_GetCode'\r\n/tmp/go-link-707261891/000007.o: In function `_cgo_d969e426e2e3_Cfunc_TF_Message':\r\nstatus.cgo2.c:(.text+0xd4): undefined reference to `TF_Message'\r\n/tmp/go-link-707261891/000007.o: In function `_cgo_d969e426e2e3_Cfunc_TF_NewStatus':\r\nstatus.cgo2.c:(.text+0x123): undefined reference to `TF_NewStatus'\r\n/tmp/go-link-707261891/000008.o: In function `_cgo_d969e426e2e3_Cfunc_TF_AllocateTensor':\r\ntensor.cgo2.c:(.text+0x73): undefined reference to `TF_AllocateTensor'\r\n/tmp/go-link-707261891/000008.o: In function `_cgo_d969e426e2e3_Cfunc_TF_DeleteTensor':\r\ntensor.cgo2.c:(.text+0xbe): undefined reference to `TF_DeleteTensor'\r\n/tmp/go-link-707261891/000008.o: In function `_cgo_d969e426e2e3_Cfunc_TF_Dim':\r\ntensor.cgo2.c:(.text+0xf5): undefined reference to `TF_Dim'\r\n/tmp/go-link-707261891/000008.o: In function `_cgo_d969e426e2e3_Cfunc_TF_NumDims':\r\ntensor.cgo2.c:(.text+0x149): undefined reference to `TF_NumDims'\r\n/tmp/go-link-707261891/000008.o: In function `_cgo_d969e426e2e3_Cfunc_TF_StringDecode':\r\ntensor.cgo2.c:(.text+0x1bd): undefined reference to `TF_StringDecode'\r\n/tmp/go-link-707261891/000008.o: In function `_cgo_d969e426e2e3_Cfunc_TF_StringEncode':\r\ntensor.cgo2.c:(.text+0x234): undefined reference to `TF_StringEncode'\r\n/tmp/go-link-707261891/000008.o: In function `_cgo_d969e426e2e3_Cfunc_TF_StringEncodedSize':\r\ntensor.cgo2.c:(.text+0x288): undefined reference to `TF_StringEncodedSize'\r\n/tmp/go-link-707261891/000008.o: In function `_cgo_d969e426e2e3_Cfunc_TF_TensorByteSize':\r\ntensor.cgo2.c:(.text+0x2dc): undefined reference to `TF_TensorByteSize'\r\n/tmp/go-link-707261891/000008.o: In function `_cgo_d969e426e2e3_Cfunc_TF_TensorData':\r\ntensor.cgo2.c:(.text+0x330): undefined reference to `TF_TensorData'\r\n/tmp/go-link-707261891/000008.o: In function `_cgo_d969e426e2e3_Cfunc_TF_TensorType':\r\ntensor.cgo2.c:(.text+0x384): undefined reference to `TF_TensorType'\r\n/tmp/go-link-707261891/000009.o: In function `_cgo_d969e426e2e3_Cfunc_TF_Version':\r\nversion.cgo2.c:(.text+0x59): undefined reference to `TF_Version'\r\ncollect2: error: ld returned 1 exit status\r\n", "comments": ["tensorflow/contrib/makefile are building c++ core lib (tensorflow-core.a), but you still need the c api in tensorflow.so (c/c_api.h).", "I am facing problem in golang in Raspberry PI.\r\nI have libtensorflow.so and libtensorflow_framework.so in /usr/local/lib\r\n\r\nldconfig is perfect.\r\n\r\n```\r\ngo test github.com/tensorflow/tensorflow/tensorflow/go\r\n\r\nthis test case is passing\r\n```\r\n\r\nbut when I run my test case written in go code.\r\n```\r\nimport (\r\n\ttf \"github.com/tensorflow/tensorflow/tensorflow/go\"\r\n\t\"github.com/tensorflow/tensorflow/tensorflow/go/op\"\r\n)\r\n\r\nfunc main() {\r\nmodel, err = tf.LoadSavedModel(<modelDir>, []string{ModelGraph}, nil /*options*/)\r\n...\r\n}\r\n```\r\nthis throwing me error as \r\n```\r\n github.com/<MyProject>/vendor/github.com/tensorflow/tensorflow/tensorflow/go\r\nvendor/github.com/tensorflow/tensorflow/tensorflow/go/attrs.go:20:33: fatal error: tensorflow/c/c_api.h: No such file or directory\r\n // #include \"tensorflow/c/c_api.h\"\r\n```\r\n\r\nI changed the LD path\r\n```\r\ncd ${GOPATH}/src/github.com/tensorflow/tensorflow\r\nexport LIBRARY_PATH=\"${PWD}/tensorflow:${LIBRARY_PATH}\"\r\nexport LD_LIBRARY_PATH=\"${PWD}/tensorflow:${LD_LIBRARY_PATH}\"\r\n```\r\n\r\nEven if I ran the demo code at Tensorflow official site, that failed\r\n```\r\n#include <stdio.h>\r\n#include <tensorflow/c/c_api.h>\r\n\r\nint main() {\r\n  printf(\"Hello from TensorFlow C library version %s\\n\", TF_Version());\r\n  return 0;\r\n}\r\n```\r\n```\r\npi@raspberrypi:~ $ gcc hello.c -ltensorflow -o hello_tf\r\nhello.c:2:32: fatal error: tensorflow/c/c_api.h: No such file or directory\r\n #include <tensorflow/c/c_api.h>\r\n                                ^\r\ncompilation terminated.\r\n```", "We managed to build a static version of TensorFlow for C on OS X and Linux using the scripts in `tensorflow/contrib/makefile/`. Note that you have to use GCC 4.8, otherwise your build is doomed to fail. On OS X, it doesn't seem possible to build a fully static binary, so it's kind of worthless - unless I missed something that is obvious to the specialists? On Linux, we see the errors described in this issue:\r\n\r\n```\r\n/tmp/go-link-410668561/000008.o: In function `_cgo_869dd8e38d18_Cfunc_TF_DeleteTensor':\r\n/tmp/go-build/cgo-gcc-prolog:71: undefined reference to `TF_DeleteTensor'\r\n/tmp/go-link-410668561/000009.o: In function `_cgo_869dd8e38d18_Cfunc_TF_Version':\r\n/tmp/go-build/cgo-gcc-prolog:50: undefined reference to `TF_Version'\r\ncollect2: error: ld returned 1 exit status\r\n```\r\nNote that I had to rename `libtensorflow-core.a` to `libtensorflow.a`, otherwise I get the error:\r\n\r\n```\r\n/usr/bin/ld: cannot find -ltensorflow\r\n```\r\n\r\n@phymbert The .so files as downloaded from https://www.tensorflow.org/install/lang_c and the header files in `/usr/local/include/tensorflow/` (also for v1.13.1) are still there, so I don't understand how the \"c api\" in `tensorflow.so` can be missing? Also the file is named `libtensorflow.so` unless the TensorFlow for C distribution was not complete.\r\n\r\nOther issues / comments suggest we need to copy additional files from `tensorflow/contrib/makefile/gen/`. Would be great to get some hints. At the same time, I try to find some more documentation and google around while I should do other work. This is day 6 of trying to compile a static Go binary with TensorFlow. My skin is getting pale.", "I am in the exact same situation right now. Using Golang as well.\r\nHowever, in my case I could build the static `.a` using `gcc 7.3.0`, so I don't really know if my output is valid or not but I do get the same `undefined reference to ...` errors when building with: `go build -ldflags '-linkmode \"external\" -extldflags \"-static -L /search/odin/tensorflow/lib64/lib\"' hello_tf.go`.\r\n\r\nSeems like it all boils down to this issue: [https://github.com/bazelbuild/bazel/issues/1920](https://github.com/bazelbuild/bazel/issues/1920) which is planned to be solved by end of 2019 for what I understand.\r\n\r\n[Here](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/cmake) I saw one could use CMake to statically compile TF but I still don't get if it just produces the same funky `.a` or one that actually works (don't have time to let my station compile during 2 hours straight to try right now).\r\n\r\nOn a final note, my dynamic-linked `libtensorflow.so` is not so heavy and I could live shipping it with my program. However, it depends on `gcc` which is quite heavy, so if someone has a way to use `libtensorflow.so` using the lightweight alternative `musl` instead, it would considerably reduce the overhead of porting Tensorflow related programs.", "Hey there, just in case it helps, I was able to build `libtensorflowlite_c.so`  for musl here: [tensorflow_lite_alpine](https://github.com/Jonarod/tensorflow_lite_alpine/tree/master/builder). I left some steps in the Dockerfile to build tensforflow (not lite) as well.", "@raven1989 please confirm if the above comments help resolve your issue.", "@raven1989 \r\nCan you please confirm as per above comment.\r\n@anilknayak  \r\nPlease note \"fatal error: tensorflow/c/c_api.h: No such file or directory\" error should be resolved as per [this comment](https://github.com/tensorflow/tensorflow/issues/41362#issuecomment-658301003)", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 23648, "title": "run error when i use xla", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): centos 7.0\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version:  master branch and commit id is b300c78a889aa75b04f6bcff2a6a5fb5d0976b4d\r\n- Python version: 3.6\r\n- Installed using virtualenv? pip? conda?: no\r\n- Bazel version (if compiling from source): 0.18.0\r\n- GCC/Compiler version (if compiling from source): gcc 4.9.2\r\n- CUDA/cuDNN version: no\r\n- GPU model and memory: 131G\r\n\r\n\r\n\r\n**Describe the problem**\r\nThe below is my building step:\r\n1. bazel build --jobs 32  -c opt -c dbg --strip=never  //tensorflow/tools/pip_package:build_pip_package\r\nor bazel build --jobs 32  -c opt -c dbg //tensorflow/tools/pip_package:build_pip_package\r\n\r\n2. ./bazel-bin/tensorflow/tools/pip_package/build_pip_package ./tmp/tensorflow_pkg\r\n3. pip3.6 install ./tensorflow-1.12.0rc0-cp36-cp36m-linux_x86_64.whl\r\n\r\nBut when i run the code with command\uff1a\r\nTF_XLA_FLAGS=\"--xla_hlo_graph_path=/tmp --xla_generate_hlo_graph=.*\" python3.6 mnist_softmax_xla.py\r\ni got an error:\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"/usr/local/lib64/python3.6/imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"/usr/local/lib64/python3.6/imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: /usr/local/lib/python3.6/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so: undefined symbol: _ZN10tensorflow19XlaCompilationCache28kDefaultCompilationThresholdE\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"mnist_softmax_xla.py\", line 26, in <module>\r\n    import tensorflow as tf\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/__init__.py\", line 24, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"/usr/local/lib64/python3.6/imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"/usr/local/lib64/python3.6/imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: /usr/local/lib/python3.6/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so: undefined symbol: _ZN10tensorflow19XlaCompilationCache28kDefaultCompilationThresholdE\r\n\r\nit is just like kDefaultCompilationThreshold dose not existed in tensorflow_framework.so\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\ncheck the above \r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["I got the same error when building TensorFlow 1.13.1 with Clang 7.0.2. It's caused by `kDefaultCompilationThreshold` being declared as `constexpr`. \r\n\r\nAs described [here](https://stackoverflow.com/questions/48361845), I was able to work around it by adding the following line below `namespace tensorflow` in `xla_compilation_cache.cc`:\r\n\r\n```\r\nconstexpr int64 XlaCompilationCache::kDefaultCompilationThreshold;\r\n```", "@dongAxis,\r\n\r\nWe see you were using an older version of tensorflow(1.x) which is officially considered as end of life. We recommend that you upgrade to latest stable version and let us know if the issue still persists in newer versions.we will get you the right help.Thanks!", "For me, the issue was no longer present in TensorFlow 2.1.0."]}, {"number": 23647, "title": "Added missing export for `profiler.ProfileContext`", "body": " The instruction [here](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/tfprof) says \"please use `tf.profiler.xxx` instead of `tf.contrib.tfprof.xxx`\". However, this is not exported yet. ", "comments": ["Ping @aaroey. It would be good to get this fix in before next release.", "Hey @terrytangyuan , looks like some check were not successful. Would you have time to check out why those tests aren't passing? Once they do pass, we should be able to merge this!", "@ChrisAntaki I am seeing \r\n```\r\n    from tensorflow.python.profiler.profile_context import ProfileContext\r\nImportError: No module named profile_context\r\n```\r\nHowever, I am able to import this locally without any issue. Also there are other errors that look irrelevant to this PR. Anything I missed? ", "@ymodak Could you help us with this if you've got time?", "It seems like upstream accidentally (or intentionally?) removed profiler init from [api_init_files.bzl](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/api/generator/api_init_files.bzl) so I added it back in the last commit. However, now it is complaining about API compatibility: \r\n```\r\nIssue 2\t: New object tensorflow.profiler found (added).\r\nIssue 3\t: New object tensorflow.profiler.ProfileContext found (added).\r\n```\r\nAny solution here? The new objects above are actually what we want and hence the purpose for this PR - we want to restore the previously removed `tensorflow.profiler` as well as adding the missing `tensorflow.profiler.ProfileContext`. ", "Thanks for helping out with this. I just made a PR to update the documentation #24149. It sounds like there might more approvals required to change the API in such a way as the documentation was suggesting. Thank you for pointing out the inconsistency.", "No problem. Could you help request related reviews so we can move forward with this PR? ", "@ChrisAntaki Anything I can do from here? It would be great if this could make it to v2.0. ", "Hey @terrytangyuan, I'm not sure how to move this forward. @ymodak, could you advise?", "Adding @martinwicke here. Do you have any advise on how to move this forward? ", "Maybe this symbol was left out as an oversight. There is a design what we want this to look like in 2.0. @qqfish can you share that?\r\n\r\n@azaks2 FYI", "TF 2.0 is going to remove Session which tfprof heavily depends on today. So I am working on a new tfprof API for 2.0. Will share it when finished.", "@qqfish Could you share the design in advance? It could help us plan things ahead of time.", "I found that tf runs very slower than normal with tensorflow.profiler.ProfileContext, the overhead it takes takes a large part of the total execution time, how can I get the real profile ? @qqfish ", "Sorry for delay. Out for holiday last week.\r\n\r\n[TF 2.0 Profiler](https://docs.google.com/document/d/1tsYR0lo3M1VwRG9B1o-7TeSXaY7pTAma0XhNi6wnxBs/edit?usp=sharing). Note that this is just a Draft doc. The final API may be different.\r\n\r\n@venuswu, most of the overhead in tfprof is spent between steps. So profiling results are more accurate than the slowdown. You can also try profiling with [timeline](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/client/timeline.py#L346), which should be faster. [Example](https://stackoverflow.com/questions/34293714/can-i-measure-the-execution-time-of-individual-operations-with-tensorflow/37774470#37774470)", "Any updates on this? Is the new API finalized yet as it gets closer to 2.0? In the meantime, I am going to close this since I assume you'll be doing this internally. "]}, {"number": 23646, "title": "tf.scatter_nd_update gradient support ", "body": "It seems that tf.scatter_nd_update does not support gradient back-propagation. Then in essence, it would be really hard to benefit from it in real applications where one needs to connect different components and back-propagate the error. Is there any possibility to provide the gradient support ?  ", "comments": ["I had the same problem with you at first but I managed to solve it by using `tf.scatter_nd`.", "Yes, that sounds like a good idea to have. Feel free to contribute a PR if you can implement it.", "I am looking into this.\r\n\r\nIt appears that `tf.scatter_nd_update` is one of several state-related ops for which gradients have been explicitly disabled for a long time.\r\n\r\nIn [tensorflow/python/ops/state_grad.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/state_grad.py), I see the following:\r\n```python\r\n# TODO(b/31222613): These ops may be differentiable, and there may be\r\n# latent bugs here.\r\nops.NotDifferentiable(\"Assign\")\r\nops.NotDifferentiable(\"AssignAdd\")\r\nops.NotDifferentiable(\"AssignSub\")\r\nops.NotDifferentiable(\"ScatterAdd\")\r\nops.NotDifferentiable(\"ScatterSub\")\r\nops.NotDifferentiable(\"ScatterMul\")\r\nops.NotDifferentiable(\"ScatterDiv\")\r\nops.NotDifferentiable(\"ScatterNdUpdate\")\r\nops.NotDifferentiable(\"ScatterNdAdd\")\r\nops.NotDifferentiable(\"ScatterNdSub\")\r\nops.NotDifferentiable(\"ScatterNdMul\")\r\nops.NotDifferentiable(\"ScatterNdDiv\")\r\n```\r\nI assume that `b/31222613` is a reference to some internal Google bug tracking system? Most of the code in this file dates to the initial commit of the TensorFlow library, 3 years ago.\r\n\r\n@drpngx are you sure that a gradient for `tf.scatter_nd_update` would be accepted if a non-Googler were to implement it? How about gradients for the other 11 ops referenced in `state_grad.py`? ", "tensor_scatter_nd_add etc are differentiable, so this issue is fixed\r\n", "Thanks ! ", "Hi @alextp \r\nIs `tensor_scatter_nd_add` differentiable with respect to the indices too, or only with the updates ?\r\nI am getting a warning on TF 2.0 \r\n`Gradients do not exist for variables [...] when minimizing the loss.`\r\nwhenever `updates` is not a function of my model weights, despite that `indices` still is.\r\n\r\nI found the code below, could you please help me with an explanation? Does it mean that the gradient wrt indices is None?\r\n```\r\n@ops.RegisterGradient(\"TensorScatterAdd\")\r\ndef _TensorScatterAddGrad(op, grad):\r\n  indices = op.inputs[1]\r\n  updates_grad = array_ops.gather_nd(grad, indices)\r\n  tensor_grad = array_ops.identity(grad)\r\n  return [tensor_grad, None, updates_grad]\r\n```", "The indices are integers and as such there is no meaningful gradient\ndefined for them (you cannot take the limit of a small change to an integer\nvalue as this change goes to zero).\n\nOn Wed, Oct 23, 2019 at 11:26 AM George Sterpu <notifications@github.com>\nwrote:\n\n> Hi @alextp <https://github.com/alextp>\n> Is tensor_scatter_nd_add differentiable with respect to the indices too,\n> or only with the updates ?\n> I am getting a warning on TF 2.0\n> Gradients do not exist for variables [...] when minimizing the loss.\n> whenever updates is not a function of my model weights, despite that\n> indices still is.\n>\n> I found the code below, could you please help me with an explanation? Does\n> it mean that the gradient wrt indices is None?\n>\n> @ops.RegisterGradient(\"TensorScatterAdd\")\n> def _TensorScatterAddGrad(op, grad):\n>   indices = op.inputs[1]\n>   updates_grad = array_ops.gather_nd(grad, indices)\n>   tensor_grad = array_ops.identity(grad)\n>   return [tensor_grad, None, updates_grad]\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/23646?email_source=notifications&email_token=AAABHRMPXLHAKMZYBFX7RNDQQCJLTA5CNFSM4GC7IWKKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOECCMOAY#issuecomment-545572611>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAABHRMVX3X5HP4R7UDN4LTQQCJLTANCNFSM4GC7IWKA>\n> .\n>\n\n\n-- \n - Alex\n"]}, {"number": 23645, "title": "Support MKL quantized pooling ops", "body": "This PR is to support MKL DNN version of quantized pooling operators, include MKL DNN average pooling and max pooling. ", "comments": ["@aaroey @penpornk This PR was replaced by this https://github.com/tensorflow/tensorflow/pull/23724. "]}, {"number": 23644, "title": "[INTEL MKL] Support MKL quantized concat op", "body": "This PR is to support MKL DNN based quantized concat operator. MKL DNN only supports the case that all input tensors have the same quantization range, all other cases will fall back to Eigen implementation. \r\n\r\nSince most of the case the input tensors won't exactly have the same quantization range, we developed a graph transform tool to re-range the quantization range of all tensors to the same range, so it can take the optimized case supported by MKL DNN. With Inception V3 and V2, we found this change won't affect the accuracy. That graph transform will be submitted in another PR.", "comments": []}, {"number": 23643, "title": "Mapping to a shuffled dataset yields an unmatched dataset in order.", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution : Linux Ubuntu 16.04.5 LTS (Xenial Xerus)\r\n- Mobile device if the issue happens on mobile device: None\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): v1.10.1-0-g4dcfddc\r\n- Python version: Python 3.6.5\r\n- Bazel version (if compiling from source): 0.16.1\r\n- GCC/Compiler version (if compiling from source): 5.4.0-6ubuntu1~16.04.10\r\n- CUDA/cuDNN version: V9.0.176/7.1.4.18\r\n- GPU model and memory: GeForce GTX 1080 Ti with 12GB memory\r\n\r\n**Describe the current behavior**\r\ndatasetB does not correspond to the order of shuffled dataset A.\r\n\r\n**Describe the expected behavior**\r\ndatasetB is expected to correspond to the order of shuffled dataset A.\r\n\r\n**Code to reproduce the issue**\r\nThe code below\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.data import Dataset\r\ntf.enable_eager_execution()\r\n\r\ndataset_A = Dataset.range(10).shuffle(10)\r\ndataset_B = dataset_A.map(lambda x: x * 2)\r\ndataset = Dataset.zip((dataset_A, dataset_B))\r\nfor data_A, data_B in dataset:\r\n    print(data_A, data_B)\r\n```\r\nproduces a unmatched dataset in order.\r\n```\r\ntf.Tensor(1, shape=(), dtype=int64) tf.Tensor(8, shape=(), dtype=int64)\r\ntf.Tensor(8, shape=(), dtype=int64) tf.Tensor(14, shape=(), dtype=int64)\r\ntf.Tensor(3, shape=(), dtype=int64) tf.Tensor(12, shape=(), dtype=int64)\r\ntf.Tensor(6, shape=(), dtype=int64) tf.Tensor(16, shape=(), dtype=int64)\r\ntf.Tensor(0, shape=(), dtype=int64) tf.Tensor(18, shape=(), dtype=int64)\r\ntf.Tensor(2, shape=(), dtype=int64) tf.Tensor(2, shape=(), dtype=int64)\r\ntf.Tensor(4, shape=(), dtype=int64) tf.Tensor(10, shape=(), dtype=int64)\r\ntf.Tensor(7, shape=(), dtype=int64) tf.Tensor(4, shape=(), dtype=int64)\r\ntf.Tensor(9, shape=(), dtype=int64) tf.Tensor(0, shape=(), dtype=int64)\r\ntf.Tensor(5, shape=(), dtype=int64) tf.Tensor(6, shape=(), dtype=int64)\r\n```", "comments": ["@iohara It seems to be caused by repeatedly initializing `dataset_A` when generating `dataset_B`. The following two solutions may walk around your problem:\r\n\r\n1. cache `dataset_A`\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.data import Dataset\r\ntf.enable_eager_execution()\r\n\r\ndataset_A = Dataset.range(10).shuffle(10)\r\ndataset_A.cache()\r\ndataset_B = dataset_A.map(lambda x: x * 2)\r\ndataset = Dataset.zip((dataset_A, dataset_B))\r\nfor data_A, data_B in dataset:\r\n    print(data_A, data_B)\r\n```\r\n\r\n2. set a seed for `shuffle()`  \r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.data import Dataset\r\ntf.enable_eager_execution()\r\n\r\ndataset_A = Dataset.range(10).shuffle(10, seed=1234)\r\ndataset_B = dataset_A.map(lambda x: x * 2)\r\ndataset = Dataset.zip((dataset_A, dataset_B))\r\nfor data_A, data_B in dataset:\r\n    print(data_A, data_B)\r\n```\r\n\r\n", "@feihugis \r\nThank you for your quick and accurate reply.\r\nIt was because the shuffled dataset was shuffled again when calling map.\r\nI understand that we can call map on dataset cached with `.cache()` or dataset shuffled with same seed.\r\nClose this issue.", "@feihugis\r\nOK, you gave us some workarounds, but is this behavior expected?\r\nOr is it a bug?", "@aiueogawa I am also thinking about this question. \r\n\r\n@jsimsa may have a better answer.", "This behavior is expected.\r\n\r\nThe easiest way to understand why is to assume that dataset construction is \"by value\". So when `dataset = Dataset.zip((dataset_A, dataset_B))` is called, the `dataset_A` passed as the first argument will be independent of the `dataset_A` used to create `dataset_B`.", "On a related note, you can avoid the need for `zip` altogether by doing:\r\n\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.data import Dataset\r\n\r\ntf.enable_eager_execution()\r\ndataset = Dataset.range(10).shuffle(10, seed=1234)\r\ndataset = dataset.map(lambda x: (x, x * 2))\r\nfor a in dataset:\r\n    print(a)\r\n```", "@feihugis @jsimsa\r\nThanks for all!\r\nThe way I avoided the need for `tf.data.Dataset.zip` is exactly the same as that of @jsimsa."]}, {"number": 23642, "title": "OptimizationPass::POST_REWRITE_FOR_EXEC after Grappler optimization", "body": "I found there is graph optimization ordering difference between PartitionedCallOp and GraphExecutionState.\r\nI think OptimizationPass::POST_REWRITE_FOR_EXEC should be applied after Grappler optimization because we can not add the graph conversion between Grappler optimization and graph partitioning.\r\n\r\nThis PR matches the graph optimization ordering.", "comments": ["Nagging Assignee @aaroey: It has been 16 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "@akshaym @aaroey \r\n\r\nThanks for the reviewing and testing.\r\nThe only I did is moving the original code, but I noticed that there is a clang-format check error on CI.\r\nWould you give me an advice whether I should fix the code or leave it?", "@nutti Yes please help to fix the broken tests, then we can try to merge again. Thanks.", "@aaroey @akshaym \r\n\r\nThanks for your advice.\r\nNow, I fixed the format error issued by CI.\r\nCould you review and test this patch again, please?"]}, {"number": 23641, "title": "Calculation precision issue ", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows with Tensorflow Docker \r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:no\r\n- TensorFlow installed from (source or binary):binary\r\n- TensorFlow version (use command below):1.12\r\n- Python version:2.7\r\n- Bazel version (if compiling from source):na\r\n- GCC/Compiler version (if compiling from source):na\r\n- CUDA/cuDNN version:9, 7.3.1\r\n- GPU model and memory:2080,8G \r\n\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n**Describe the current behavior**\r\nimport tensorflow as tf\r\n\r\ndef compute_area(sides):\r\n  a = sides[:,0]  # 5.0, 2.3\r\n  b = sides[:,1]  # 3.0, 4.1\r\n  c = sides[:,2]  # 7.1, 4.8\r\n  \r\n  s = (a + b + c) * 0.5   # (a + b) is a short-cut to tf.add(a, b)\r\n  areasq = s * (s - a) * (s - b) * (s - c) # (a * b) is a short-cut to tf.multiply(a, b), not tf.matmul(a, b)\r\n  return tf.sqrt(areasq)\r\n\r\nwith tf.Session() as sess:\r\n  area = compute_area(tf.constant([\r\n      [3.000000001, 4.0, 5.0],\r\n    ],dtype='float64'))\r\n  result = sess.run(area)\r\n  print(result)  \r\n\r\n[6.]\r\n\r\n**Describe the expected behavior**\r\nimport numpy as np\r\n\r\ns = (3.000000001 + 4 + 5) * 0.5\r\nareasq = s * (s - 3.000000001) * (s - 4) * (s - 5)\r\n\r\nprint(np.sqrt(areasq))\r\n\r\n6.000000001999999\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\nAttached as above \r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nN/A \r\n", "comments": ["I think this is a matter of print-time precision. If I subtract the tf result from the numpy result I get exactly zero:\r\n\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\ntf.enable_eager_execution()\r\n\r\ndef compute_area(sides):\r\n  a = sides[:,0] # 5.0, 2.3\r\n  b = sides[:,1] # 3.0, 4.1\r\n  c = sides[:,2] # 7.1, 4.8\r\n\r\n  s = (a + b + c) * 0.5 # (a + b) is a short-cut to tf.add(a, b)\r\n  areasq = s * (s - a) * (s - b) * (s - c) # (a * b) is a short-cut to tf.multiply(a, b), not tf.matmul(a, b)\r\n  return tf.sqrt(areasq)\r\n\r\na = compute_area(tf.constant([[3.000000001, 4.0, 5.0],],dtype='float64'))\r\ns = (3.000000001 + 4 + 5) * 0.5\r\nareasq = s * (s - 3.000000001) * (s - 4) * (s - 5)\r\n\r\ndif = np.sqrt(areasq) - a.numpy()\r\ndif == 0.\r\n```\r\n(prints array([ True]))"]}, {"number": 23640, "title": "Add converters for MaxPool3D-related Ops", "body": "This PR adds the converters for MaxPool3D, MaxPool3DGrad, and MaxPool3DGradGrad.", "comments": ["@agarwal-ashish I was not able to add you as reviewer, but please help to take a look. Thanks.", "@agarwal-ashish Thanks for running the test! The coding style issue has been fixed. The other test failures seem to be unrelated.", "@agarwal-ashish The test failures in `GPU CC`, `Ubuntu Python3 PIP`, `Windows Bazel`, and `Windows Bazel GPU` seems to be unrelated.", "@agarwal-ashish Could you help add `Ready to Pull` tag?"]}, {"number": 23638, "title": "OSError and ImportError ", "body": "####Solved ########\r\n**System information**\r\n- OS Platform and Distribution: Windows 8.1\r\n- TensorFlow installed from (source or binary): https://pypi.org/project/tensorflow-gpu/1.5.0/#files \r\n- TensorFlow version: 1.5.0\r\n- Python version:3.6.5.final.0\r\n- Installed using virtualenv? pip? conda?: installed on own computer with pip command \r\n- Bazel version (if compiling from source): (?)\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: v9.0/v7.4.1 (Nov 8, 2018), for CUDA 9.0\r\n- GPU model and memory: GeForce GTX 960M 6MB \r\n\r\n\r\n\r\n**Describe the problem**\r\nThe problem seems to be that when i download the tensorflow-gpu, I do now have the tensorflow module do I also need to install tensorflow sepratly, tought that will destroy the setup. \r\nAlso the environment does not recognize the cudart64_90.dll file in the folder described provided in the additional information\r\n\r\nfollowed description from https://www.youtube.com/watch?v=uIm3DMprk7M \r\n- first installing CUDA v9.0 from https://developer.nvidia.com/cuda-90-download-archive\r\n- then installing cuDNN version 7.4.1 for CUDA 9.0  from https://developer.nvidia.com/rdp/cudnn-download \r\n- then i downloaded tensorflow-gpu from https://pypi.org/project/tensorflow-gpu/1.5.0/?fbclid=IwAR3xogCL0DA4kdhIqLGCcXSYUka9n0CtBCxbpWzAh-rKrubLKQbJPIla8kA#files \r\n- lastly I opend python in anaconda navigator, then tried to import tensorflow \r\noutput is printed below.\r\n\r\nadditional information: \r\n- cudart64_90.dll is located in the folder C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.0\\bin . \r\n- comands are done on a new environment with following packages \r\nabsl-py                   0.6.1\r\nbleach                    1.5.0\r\ncertifi                   2018.10.15\r\nhtml5lib                  0.9999999\r\nMarkdown                  3.0.1\r\nnumpy                     1.15.4\r\npip                       18.1\r\nprotobuf                  3.6.1\r\npython                    3.6.7\r\nsetuptools                40.5.0\r\nsix                       1.11.0\r\ntensorflow-gpu            1.5.0\r\ntensorflow-tensorboard    1.5.1\r\nvc                        14.1\r\nvs2015_runtime            14.15.26706\r\nWerkzeug                  0.14.1\r\nwheel                     0.32.2\r\nwincertstore              0.2\r\n\r\n**Any other info / logs**\r\n>>> import tensorflow\r\nTraceback (most recent call last):\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\aienv1\\lib\\site-packages\\tensorflow\\python\r\n\\platform\\self_check.py\", line 75, in preload_check\r\n    ctypes.WinDLL(build_info.cudart_dll_name)\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\aienv1\\lib\\ctypes\\__init__.py\", line 348,\r\nin __init__\r\n    self._handle = _dlopen(self._name, mode)\r\nOSError: [WinError 126] The specified module could not be found\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\aienv1\\lib\\site-packages\\tensorflow\\__init\r\n__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\aienv1\\lib\\site-packages\\tensorflow\\python\r\n\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\aienv1\\lib\\site-packages\\tensorflow\\python\r\n\\pywrap_tensorflow.py\", line 30, in <module>\r\n    self_check.preload_check()\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\aienv1\\lib\\site-packages\\tensorflow\\python\r\n\\platform\\self_check.py\", line 82, in preload_check\r\n    % (build_info.cudart_dll_name, build_info.cuda_version_number))\r\nImportError: Could not find 'cudart64_90.dll'. TensorFlow requires that this DLL\r\n be installed in a directory that is named in your %PATH% environment variable.\r\nDownload and install CUDA 9.0 from this URL: https://developer.nvidia.com/cuda-t\r\noolkit", "comments": ["Needed to restart anaconda, everything seems fine now :) "]}, {"number": 23637, "title": "Fix the issue where distributions.percentile does not support eager mode", "body": "This fix tries to address the issue in #23619 where distributions.percentile in eager mode throws:\r\n```\r\nTypeError: unhashable type: 'list'\r\n```\r\nThe issue is that ` [x, q]` should be passed as `values`, not name default. This fix fixed the issue.\r\n\r\nThis fix fixes #23619\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["Ping @jvdillon to take a look, I think the change is quite small \u263a\ufe0f", "Nagging Reviewer @jvdillon, @rsepassi: You have been added as a reviewer to this pull request. Please add your review or reassign. It has been 14 days with no activity and the `awaiting review` label has been applied.", "At some point this got independently fixed in both TensorFlow contrib and TensorFlow probability:\r\n\r\nhttps://github.com/tensorflow/probability/blob/master/tensorflow_probability/python/stats/quantiles.py#L136 and https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/distributions/python/ops/sample_stats.py#L303\r\n\r\nSorry for dropping the ball on this PR, but at least the issue is fixed now.", "@SiegeLordEx Thanks for the help. I will close the PR now."]}, {"number": 23636, "title": "INTEL MKL: Fixing api_compatibility_test", "body": "This PR fixes the api_compatibility_test by hiding MKL ops.", "comments": ["Also I have a general concern of adding new `MKL` ops that do not start with `_Mkl` prefix. Was it discussed anywhere? I don't have enough context, but for consistency it seems that all ops that are enabled only with MKL config should start with `_Mkl`.\r\n\r\n/cc @martinwicke @tatianashp @penpornk ", "@ezhulenev We are extending existing quantization ops like quantized_conv2d and quantized_avg_pool which are already part of the golden API. We needed this to support fusions in the offline graph transform/quantization tool. We cannot make it start with \"_\" because it won't be visible in the graph transform tool.\r\nWe do have equivalent _Mkl versions and at runtime the fused quantization ops get translated to _Mkl versions like other Mkl operators.", "Is my understanding correct, that you register op specs for Quantized ops (e.g. REGISTER_OP for `QuantizedConv2DAndRelu`), but do not provide any kernel implementation. And only MKL pass through rewrite will make it actually work?", "Yes, that is correct. ", "(For tf-api-review)\r\n\r\nSomething seems amiss - we don't want to export all these as top level symbols in the Python `tf` namespace, right? (`tf. quantized_conv2d_and_relu`, `tf. quantized_conv2d_and_relu_and_requantize` etc.) \r\n\r\n\r\nI'm guessing we do _not_ want to make these operations visible from the Python API but instead hide them in graph rewrites. If so, what you're looking for is probably to add `api_def` files that hide these symbols from the Python API by adding a `visibility: HIDDEN` to `tensorflow/core/api_def/base_api/api_def_<OpName>.pbtxt` similar to https://github.com/tensorflow/tensorflow/blob/30ff2f477908ca4b038b691621d481e842713ecc/tensorflow/core/api_def/base_api/api_def_MaxPoolGrad.pbtxt#L3", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "@asimshankar thanks for the explanation. I have marked all Mkl Quantized Ops as HIDDEN. Can you have a look?", "Since there's no API change here anymore this doesn't need the API review tag.", "@alextp can you review this?", "Thanks @alextp. The failures seem not related to this PR. Can we merge it?"]}]