[{"number": 19138, "title": "precision and recall values kept unchanged for some training steps.", "body": "### System information\r\n- Have I written custom code: No, i just use a canned estimator DNNClassifier.\r\n- OS Platform and Distribution: macOS High Sierra\r\n- TensorFlow installed from: pip\r\n- TensorFlow version: 1.8.0\r\n- Bazel version: N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n- Exact command to reproduce: N/A\r\n\r\n### Describe the problem\r\nI'm using google ml-engine to train a model for ctr-prediction(the training dataset is Imbalanced).\r\nFollowing is the training log screenshot from ml-engine.\r\n![pr-auc](https://user-images.githubusercontent.com/17157194/39740932-52b01a7c-52ca-11e8-8952-820424e38357.jpg)\r\nThe problem is: the **precision** and **recall** values kept unchanged for some training steps as i annotated in the picture(auctually these two values kept unchanged for 2 epochs in this picture). I'm pretty sure this is a bug, but i don't know where is wrong.\r\nDoes any one can check the calculation of these two metrics(precision, recall) for me?", "comments": ["Can you please provide details as to what commands you ran so that we can reproduce and check?", "```\r\ngcloud ml-engine local train \\\r\n    --package-path trainer \\\r\n    --module-name trainer.task \\\r\n    --job-dir ${job_dir} \\\r\n    --distributed \\\r\n    -- \\\r\n    --train_files ${train_files} \\\r\n    --eval_files ${eval_files} \\\r\n    --hidden_units ${hidden_units} \\\r\n    --cats_path ${cats_path} \\\r\n    --job_dir ${job_dir} \\\r\n    --train_batch_size ${train_batch_size} \\\r\n    --eval_batch_size ${eval_batch_size} \\\r\n    --train_set_size ${train_set_size} \\\r\n    --num_epochs ${num_epochs}\r\n```\r\nCaned estimator, trainning and eval data in tfrecord format. That's all.\r\ntraining data size(train_set_size) is about 300M, train_batch_size=512, eval_batch_size=250, num_epochs=4.", "@hhzrz  We are checking to see if you still need help on this issue, as you are using an older version of tensorflow(1.x) which is officially considered as end of life. We recommend that you upgrade to 2.6 which is latest stable version of TF and let us know if the issue still persists in newer versions. check [**`link1`**](https://github.com/keras-team/keras/issues/2711), [**`link2`**](https://stackoverflow.com/questions/52831351/how-to-determine-an-overfitted-model-based-on-loss-precision-and-recall) Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/19138\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/19138\">No</a>\n"]}, {"number": 19137, "title": "Branch 195749522", "body": "", "comments": ["@yifeif: It looks like the Java bindings are broken:\r\n\r\ntensorflow/java/src/gen/cc/op_specs.cc:386:20: error: no member named 'deprecation_version' in 'tensorflow::ApiDef_Endpoint'\r\n      endpoint_def.deprecation_version() > 0);\r\n      ~~~~~~~~~~~~ ^\r\n1 error generated.\r\n\r\nPerhaps roll back the CL which caused this?", "Looks like it's related to https://github.com/tensorflow/tensorflow/pull/19137/commits/92acc302beefd2b596b505d9278f8b0b46239cea. cc: @annarev.", "Looks like there was a conflict with my change and a change to op_specs.cc.\r\nThe reference to deprecation_version can be removed in that file.", "Thanks @annarev! I updated the EndpointSpec class based on your suggestion. PTAL.", "Looks like the only xla failure now is due to cl/195748721, which has been rolled back internally. I'm going to try push another one.", "merged #19164 instead. Closing this one."]}, {"number": 19136, "title": "Setting default openmp settings for MKL kernels", "body": "Requesting feedback on ways to set default openmp parameters\r\n\r\nCurrently, we recommend users set these through environment variables but are looking at ways to set reasonable values automatically from within tensorflow. A few questions that I would appreciate your feedback on -\r\n1) Is it ok to use 'setenv' to set values for KMP_BLOCKTIME and OMP_PROC_BIND? There are no openmp standard APIs to programmatically set them. \r\n2) For 'setenv' to correctly set Openmp settings, the code has to execute before the openmp library is loaded i.e before any call to openmp in the program. Since MKL optimizations are the only users of openmp, we have ensured that this is the case for now. Is there a better place for this code? \r\n3) We would like to avoid placing computations on hyperthreads that compete for resources on the same CPU physical core. Looking for suggestions on getting the number of hyperthreads per core in a portable manner. https://www.open-mpi.org/projects/hwloc/ looks like a good option. Are you OK with bringing it into tensorflow? \r\n4) Is it ok to ignore the intra_op config parameter while setting number of openmp threads? Ideally, we would like to use that parameter to guide MKL kernel parallelism as well but there seem to be cases (e.g., tf_cnn_benchmarks) where intra_op is set to a very low number by default. ", "comments": ["@jbobba I don't see any precedence for using setenv in TensorFlow, but I think what you are doing is reasonable. @martinwicke any thoughts?\r\n\r\n", "There is warning here about using setenv: https://github.com/tensorflow/tensorflow/blob/70da85b727c960f62af141770827367f9c5c0117/tensorflow/core/platform/posix/subprocess.cc#L59 \r\n", "@jbobba The warning you found is not necessarily a blocker, IMHO.", "setenv: If you are always going to set the same values (KMP_BLOCKTIME=1 and OMP_PROC_BIND=true) and nobody else is using the variables, I don't think race conditions matter.", "@penpornk addressed your PR comments. please take a look.", "hwloc looks really useful. @poxvoculi would this also be useful for our work on collective communication and alternate interconnects? Have you looked at it (or alternatives)?", "Something like hwloc would probably be useful.  So far we've been adding a bit of device topology data in an ad hoc fashion, mostly addressing accelerators.  Tensorflow does not do a very good job of managing thread/core affinity, nor of reducing interference between threads in the application.    We've neglected to deal with this issue up to now because other problems have been more urgent and also the Google datacenter environment makes it difficult to optimize.   If you're serious about wanting to add hwloc I suppose we should initiate a broader discussion about costs/benefits.", "> setenv: If you are always going to set the same values (KMP_BLOCKTIME=1 and OMP_PROC_BIND=true) and nobody else is using the variables, I don't think race conditions matter.\r\n\r\nUnfortunately this is not true. setenv() is inherently thread-hostile and can't really be fixed. The only safe way to do any changing of the environment is to make sure no other thread is live when you call setenv(), ideally by doing it so early that no other thread could even have been started.\r\n\r\n(setenv() modifies the global char** environ, possibly reallocating it; getenv() iterates over environ, which is also a globally-visible symbol that anyone else can iterate over directly. POSIX doesn't specify any locking on setenv or getenv, and at least glibc has a lock around the former but not the latter, so concurrent calls to setenv() and either getenv() or direct iteration over environ will cause segfaults.)", "@poxvoculi @rmlarsen created a feature request issue for adding hwloc into TF. ", "@penpornk @rmlarsen addressed feedback.", "@penpornk i believe i have addressed all your comments. please let me know if i've missed any.", "A quick note on the test failures. They seem to be unrelated to this PR. #19364 and a few other PRs fail these tests.", "@jbobba Thanks! I believe the failing tests are unrelated. Merging.", "@jbobba this PR appears to have broken the Windows build, as commented above. Would you mind taking a look?", "Will do. @goydex @ganeshn85 can you share more info on the failure and your config. since the windows CI build passed on the PR, i'm wondering whats different in your setup.", "Does the CI test build with CUDA/NV GPU support enabled?", "i doubt but @gunan  would know best.", "@jbobba thanks. As far as config, I'm building using the CMake build on Windows with CUDA/NVIDIA GPU enabled. \r\n\r\nCMake command (obviously adjust with your personalized environment settings)\r\n\r\n```\r\ncmake .. -A x64 -DCMAKE_BUILD_TYPE=Release -G \"Visual Studio 14 2015\" ^\r\n-DSWIG_EXECUTABLE=Drive:/Path/to/swigwin-3.0.12/swig.exe ^\r\n-DPYTHON_EXECUTABLE=Drive:/Path/to/anaconda3/python.exe ^\r\n-DPYTHON_LIBRARIES=Drive:/Path/to/anaconda3/libs/python36.lib ^\r\n-Dtensorflow_ENABLE_GPU=ON ^\r\n-DCUDNN_HOME=\"Drive:/Path/to/cudnn-9.0-windows10-x64-v7.1/cuda\" ^\r\n-Dtensorflow_ENABLE_MKL_SUPPORT=ON ^\r\n-DMKL_HOME=\"C:/Program Files (x86)/IntelSWTools/compilers_and_libraries\" ^\r\n-Dtensorflow_WIN_CPU_SIMD_OPTIONS=/arch:AVX2 ^\r\n-Dtensorflow_BUILD_PYTHON_TESTS=OFF ^\r\n-Dtensorflow_BUILD_CC_TESTS=OFF ^\r\n-Dtensorflow_TF_NIGHTLY=OFF\r\n```\r\n\r\nCan then open Tensorflow.sln or build the example with\r\n\r\n```\r\nMSBuild /p:Configuration=Release tf_tutorials_example_trainer.vcxproj\r\nRelease\\tf_tutorials_example_trainer.exe\r\n```\r\nDepending on your environment, you might need to run this script first \r\n\r\n`\"C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\vcvarsall.bat\"`", "We have separate builds with and without CUDA.\r\nOn its presubmits, this PR seems to have passed the non-CUDA build.\r\nBut it looks like also our CUDA builds were passing sometime yesterday, with this PR."]}, {"number": 19135, "title": "[tftrt update]", "body": "  code cleaning, removed some boilerplate code", "comments": ["Ping @aaroey", "I was testing with my model ci_test.\r\nWill run against tf_trt_integration_test and test_tftrt.py", "test run seems to be doing fine.\r\ntf_trt_integration test is reporting `Ran 4 tests OK (skipped=1)`", "@aaroey Thanks for the review!"]}, {"number": 19134, "title": "When I try to import the kernel always gets dumped. ", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**: \r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["Nagging Assignee @bignamehyp: It has been 16 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @bignamehyp: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly."]}, {"number": 19133, "title": "[tfgan] Allow to add custom eval metrics to GANEstimator", "body": "This PR continues the work started in #19117.\r\n\r\nThis will allow users to define custom eval metrics to be used inside `GANEstimator`.\r\n\r\nThe naming of the added keyword argument `get_eval_metric_ops_fn` is a bit verbose but follows the naming schema of `get_hooks_fn` and the `eval_metric_ops` argument of `tf.estimator.EsimatorSpec`.\r\n\r\nCloses #17145", "comments": ["@rmlarsen Thanks for checking it out. Could you elaborate whats missing in the unit tests I already added?", "@lgeiger Gah! I missed that :-) Looks good!"]}, {"number": 19132, "title": "Building development docker files with AVX as well. (#19130)", "body": "1.7 cherrypick", "comments": ["Got a weird build error in Windows:\r\n\r\n```\r\n+ bazel build -c opt --define=override_eigen_strong_inline=true tensorflow/tools/pip_package:build_pip_package\r\n83\r\nT:\\src\\github\\tensorflow/tensorflow/tools/ci_build/windows/cpu/pip/build_tf_windows.sh: line 50: bazel: command not found\r\n84\r\n+ exit 127\r\n85\r\n++ '[' 3 = 1 ']'\r\n86\r\n================================================================================\r\n87\r\n```", "Bazel windows build is added after this release. We can ignore the error.", "@yifeif could you merge this? I don't have permission."]}, {"number": 19131, "title": "Building development docker files with AVX as well. (#19130)", "body": "1.8 cherrypick", "comments": ["ditto"]}, {"number": 19130, "title": "Building development docker files with AVX as well.", "body": "", "comments": []}, {"number": 19129, "title": "Linker errors building Tensorflow master on Windows 10", "body": "Hi Guys, \r\nI am trying to build tensorflow master.  \r\n\r\nI am running Windows 10, Python 3.5, Visual Studio 2015, CUDA 9.0 and cudnn 9.0 windows10 v7.1.\r\n\r\nI follow the instruction on the README file and was able to get cmake to create the visual studio solutions/project files as follows:\r\n**cmake .. -A x64 -DCMAKE_BUILD_TYPE=Release -DSWIG_EXECUTABLE=\"C:\\\\swigwin-3.0.12\\\\swig.exe\" -DPYTHON_EXECUTABLE=\"C:\\\\Python35\\\\python.exe\" -DPYTHON_LIBRARIES=\"C:\\\\Python35\\\\libs\\\\python35.lib\" -Dtensorflow_ENABLE_GPU=ON -DCUDNN_HOME=\"C:\\\\cudnn_90_712\"**\r\n\r\nHowever, when I tried to build with the following command:\r\n**MSBuild /p:Configuration=Release tf_tutorials_example_trainer.vcxproj**\r\n\r\nI got some linker errors:\r\n\"C:\\temp\\tensorflow\\tensorflow\\contrib\\cmake\\build_ex\\tf_tutorials_example_trainer.vcxproj\" (default target) (1) ->\r\n(Link target) ->\r\n  eager_operation.obj : error LNK2019: unresolved external symbol \"public: class tensorflow::AttrBuilder & __cdecl tensorflow::AttrBuilder::NumInputs(int)\" (?NumInputs@AttrBuilder@tensorflow@@QEAAAEAV12@H\r\n@Z) referenced in function \"public: void __cdecl tensorflow::EagerOperation::AddInput(class tensorflow::TensorHandle *)\" (?AddInput@EagerOperation@tensorflow@@QEAAXPEAVTensorHandle@2@@Z) [C:\\temp\\tensorfl\r\now\\tensorflow\\contrib\\cmake\\build_ex\\tf_tutorials_example_trainer.vcxproj]\r\n  execute.obj : error LNK2019: unresolved external symbol \"class tensorflow::Status __cdecl tensorflow::OpDefForOp(char const *,class tensorflow::OpDef const * *)\" (?OpDefForOp@tensorflow@@YA?AVStatus@1@P\r\nEBDPEAPEBVOpDef@1@@Z) referenced in function \"class tensorflow::Status __cdecl tensorflow::EagerExecute(class tensorflow::EagerOperation *,class tensorflow::gtl::InlinedVector<class tensorflow::TensorHand\r\nle *,2> *,int *)\" (?EagerExecute@tensorflow@@YA?AVStatus@1@PEAVEagerOperation@1@PEAV?$InlinedVector@PEAVTensorHandle@tensorflow@@$01@gtl@1@PEAH@Z) [C:\\temp\\tensorflow\\tensorflow\\contrib\\cmake\\build_ex\\tf_\r\ntutorials_example_trainer.vcxproj]\r\n  execute.obj : error LNK2019: unresolved external symbol \"public: struct tensorflow::Fprint128 __cdecl tensorflow::AttrBuilder::CacheKey(class std::basic_string<char,struct std::char_traits<char>,class s\r\ntd::allocator<char> > const &)const \" (?CacheKey@AttrBuilder@tensorflow@@QEBA?AUFprint128@2@AEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@Z) referenced in function \"class tensorflow::S\r\ntatus __cdecl tensorflow::EagerExecute(class tensorflow::EagerOperation *,class tensorflow::gtl::InlinedVector<class tensorflow::TensorHandle *,2> *,int *)\" (?EagerExecute@tensorflow@@YA?AVStatus@1@PEAVEa\r\ngerOperation@1@PEAV?$InlinedVector@PEAVTensorHandle@tensorflow@@$01@gtl@1@PEAH@Z) [C:\\temp\\tensorflow\\tensorflow\\contrib\\cmake\\build_ex\\tf_tutorials_example_trainer.vcxproj]\r\n  execute.obj : error LNK2019: unresolved external symbol \"public: class tensorflow::NodeDef const & __cdecl tensorflow::AttrBuilder::BuildNodeDef(void)\" (?BuildNodeDef@AttrBuilder@tensorflow@@QEAAAEBVNod\r\neDef@2@XZ) referenced in function \"class tensorflow::Status __cdecl tensorflow::EagerExecute(class tensorflow::EagerOperation *,class tensorflow::gtl::InlinedVector<class tensorflow::TensorHandle *,2> *,i\r\nnt *)\" (?EagerExecute@tensorflow@@YA?AVStatus@1@PEAVEagerOperation@1@PEAV?$InlinedVector@PEAVTensorHandle@tensorflow@@$01@gtl@1@PEAH@Z) [C:\\temp\\tensorflow\\tensorflow\\contrib\\cmake\\build_ex\\tf_tutorials_e\r\nxample_trainer.vcxproj]\r\n  C:\\temp\\tensorflow\\tensorflow\\contrib\\cmake\\build_ex\\Release\\tf_tutorials_example_trainer.exe : fatal error LNK1120: 4 unresolved externals [C:\\temp\\tensorflow\\tensorflow\\contrib\\cmake\\build_ex\\tf_tutor\r\nials_example_trainer.vcxproj]\r\n\r\nDo you guys know what might have been wrong?  \r\n\r\nDoes the Windows build instructions work with tensorflow master?\r\n\r\nIf not, is there another tag/version/snapshot of tensorflow that would work?\r\n\r\nThank you very much for your help in advance!\r\n\r\nThanks,\r\nBen\r\n\r\n", "comments": ["Having the same issue here. I would really appreciate a good solution :)\r\n\r\nI use Python 3.6 instead of 3.5, but except that, I'm using the same configurations like above", "version 1.70 works but the master doesn't\r\nI'll try to trace the problem but there are just too many commits to consider", "@ben11355 @Deltanullnull @fifothekid \r\nIs #12446 potentially relevant? \r\nhttps://github.com/tensorflow/tensorflow/issues/12446", "yes it is\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/20669", "This is not an issue anymore because CMake is replaces with Bazel", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 19127, "title": "Unable to build tensorflow using CMake without GPU", "body": "-Have I written custom code (as opposed to using a stock example script provided in TensorFlow) : NO\r\n\r\n    OS Platform and Distribution : WINDOWS 10\r\n    -TensorFlow installed from (source or binary) : git clone\r\n\r\n    TensorFlow version (use command below) :\r\ncommit eeab2c867faa0f10dfea8635d1e87009844f902e (HEAD -> master, origin/master, origin/HEAD)\r\nMerge: daecc72653 9a4879660f\r\nAuthor: Shanqing Cai <cais@google.com>\r\nDate:   Fri May 4 21:34:58 2018 -0400\r\n\r\n    Merge pull request #19090 from caisq/branch_195443326\r\n\r\n    Branch 195443326\r\n\r\n\r\n\r\n    Python version : 3.6.4\r\n\r\n    Bazel version (if compiling from source) : NO using CMAKE 3.11.0\r\n\r\n    GCC/Compiler version (if compiling from source): VS 2017 version 15.6.3\r\n\r\n    CUDA/cuDNN version: no only cpu version\r\n\r\n    GPU model and memory : NOT USE\r\n\r\n    Exact command to reproduce :\r\n\r\nUse cmake : cmakecache is [CMakeCache.txt](https://github.com/tensorflow/tensorflow/files/1979573/CMakeCache.tx\r\nI open my own issue : previous one was issue #19004 and @ctraina does not answer\r\nt)\r\n\r\nfull error message : \r\n[tferror.txt](https://github.com/tensorflow/tensorflow/files/1979582/tferror.txt)\r\n\r\n\r\nError message \r\n```\r\nSeverity\tCode\tDescription\tProject\tFile\tLine\tSuppression State\r\nError\tLNK2019\tunresolved external symbol \"class tensorflow::Status __cdecl tensorflow::OpDefForOp(char const *,class tensorflow::OpDef const * *)\" (?OpDefForOp@tensorflow@@YA?AVStatus@1@PEBDPEAPEBVOpDef@1@@Z) referenced in function \"class tensorflow::Status __cdecl tensorflow::EagerExecute(class tensorflow::EagerOperation *,class tensorflow::gtl::InlinedVector<class tensorflow::TensorHandle *,2> *,int *)\" (?EagerExecute@tensorflow@@YA?AVStatus@1@PEAVEagerOperation@1@PEAV?$InlinedVector@PEAVTensorHandle@tensorflow@@$01@gtl@1@PEAH@Z)\ttf_tutorials_example_trainer\tF:\\lib\\build\\tensorflow\\execute.obj\t1\t\r\nError\tLNK1120\t4 unresolved externals\ttransform_graph\tF:\\lib\\build\\tensorflow\\Release\\transform_graph.exe\t1\t\r\nError\tLNK1120\t4 unresolved externals\tbenchmark_model\tF:\\lib\\build\\tensorflow\\Release\\benchmark_model.exe\t1\t\r\nError\tLNK1120\t4 unresolved externals\ttf_tutorials_example_trainer\tF:\\lib\\build\\tensorflow\\Release\\tf_tutorials_example_trainer.exe\t1\t\r\nError\tLNK1120\t4 unresolved externals\ttf_label_image_example\tF:\\lib\\build\\tensorflow\\Release\\tf_label_image_example.exe\t1\t\r\nError\tLNK1120\t4 unresolved externals\tcompare_graphs\tF:\\lib\\build\\tensorflow\\Release\\compare_graphs.exe\t1\t\r\nError\tLNK1120\t4 unresolved externals\tgrpc_tensorflow_server\tF:\\lib\\build\\tensorflow\\Release\\grpc_tensorflow_server.exe\t1\t\r\nError\tLNK1120\t4 unresolved externals\tsummarize_graph\tF:\\lib\\build\\tensorflow\\Release\\summarize_graph.exe\t1\t\r\nError\tLNK1181\tcannot open input file '\\pywrap_tensorflow_internal.lib'\t_periodic_resample_op\tF:\\lib\\build\\tensorflow\\LINK\t1\t\r\nError\tLNK1181\tcannot open input file '\\pywrap_tensorflow_internal.lib'\t_nearest_neighbor_ops\tF:\\lib\\build\\tensorflow\\LINK\t1\t\r\nError\tLNK1181\tcannot open input file '\\pywrap_tensorflow_internal.lib'\t_beam_search_ops\tF:\\lib\\build\\tensorflow\\LINK\t1\t\r\nError\tLNK1181\tcannot open input file '\\pywrap_tensorflow_internal.lib'\t_gru_ops\tF:\\lib\\build\\tensorflow\\LINK\t1\t\r\nError\tLNK1181\tcannot open input file '\\pywrap_tensorflow_internal.lib'\t_lstm_ops\tF:\\lib\\build\\tensorflow\\LINK\t1\t\r\nError\tLNK2019\tunresolved external symbol \"class tensorflow::Status __cdecl tensorflow::OpDefForOp(char const *,class tensorflow::OpDef const * *)\" (?OpDefForOp@tensorflow@@YA?AVStatus@1@PEBDPEAPEBVOpDef@1@@Z) referenced in function \"class tensorflow::Status __cdecl tensorflow::EagerExecute(class tensorflow::EagerOperation *,class tensorflow::gtl::InlinedVector<class tensorflow::TensorHandle *,2> *,int *)\" (?EagerExecute@tensorflow@@YA?AVStatus@1@PEAVEagerOperation@1@PEAV?$InlinedVector@PEAVTensorHandle@tensorflow@@$01@gtl@1@PEAH@Z)\tbenchmark_model\tF:\\lib\\build\\tensorflow\\execute.obj\t1\t\r\nError\tLNK2019\tunresolved external symbol \"class tensorflow::Status __cdecl tensorflow::OpDefForOp(char const *,class tensorflow::OpDef const * *)\" (?OpDefForOp@tensorflow@@YA?AVStatus@1@PEBDPEAPEBVOpDef@1@@Z) referenced in function \"class tensorflow::Status __cdecl tensorflow::EagerExecute(class tensorflow::EagerOperation *,class tensorflow::gtl::InlinedVector<class tensorflow::TensorHandle *,2> *,int *)\" (?EagerExecute@tensorflow@@YA?AVStatus@1@PEAVEagerOperation@1@PEAV?$InlinedVector@PEAVTensorHandle@tensorflow@@$01@gtl@1@PEAH@Z)\ttransform_graph\tF:\\lib\\build\\tensorflow\\execute.obj\t1\t\r\nError\tLNK2019\tunresolved external symbol \"class tensorflow::Status __cdecl tensorflow::OpDefForOp(char const *,class tensorflow::OpDef const * *)\" (?OpDefForOp@tensorflow@@YA?AVStatus@1@PEBDPEAPEBVOpDef@1@@Z) referenced in function \"class tensorflow::Status __cdecl tensorflow::EagerExecute(class tensorflow::EagerOperation *,class tensorflow::gtl::InlinedVector<class tensorflow::TensorHandle *,2> *,int *)\" (?EagerExecute@tensorflow@@YA?AVStatus@1@PEAVEagerOperation@1@PEAV?$InlinedVector@PEAVTensorHandle@tensorflow@@$01@gtl@1@PEAH@Z)\ttf_label_image_example\tF:\\lib\\build\\tensorflow\\execute.obj\t1\t\r\nError\tLNK2019\tunresolved external symbol \"class tensorflow::Status __cdecl tensorflow::OpDefForOp(char const *,class tensorflow::OpDef const * *)\" (?OpDefForOp@tensorflow@@YA?AVStatus@1@PEBDPEAPEBVOpDef@1@@Z) referenced in function \"class tensorflow::Status __cdecl tensorflow::EagerExecute(class tensorflow::EagerOperation *,class tensorflow::gtl::InlinedVector<class tensorflow::TensorHandle *,2> *,int *)\" (?EagerExecute@tensorflow@@YA?AVStatus@1@PEAVEagerOperation@1@PEAV?$InlinedVector@PEAVTensorHandle@tensorflow@@$01@gtl@1@PEAH@Z)\tcompare_graphs\tF:\\lib\\build\\tensorflow\\execute.obj\t1\t\r\nError\tLNK2019\tunresolved external symbol \"class tensorflow::Status __cdecl tensorflow::OpDefForOp(char const *,class tensorflow::OpDef const * *)\" (?OpDefForOp@tensorflow@@YA?AVStatus@1@PEBDPEAPEBVOpDef@1@@Z) referenced in function \"class tensorflow::Status __cdecl tensorflow::EagerExecute(class tensorflow::EagerOperation *,class tensorflow::gtl::InlinedVector<class tensorflow::TensorHandle *,2> *,int *)\" (?EagerExecute@tensorflow@@YA?AVStatus@1@PEAVEagerOperation@1@PEAV?$InlinedVector@PEAVTensorHandle@tensorflow@@$01@gtl@1@PEAH@Z)\tgrpc_tensorflow_server\tF:\\lib\\build\\tensorflow\\execute.obj\t1\t\r\nError\tLNK2019\tunresolved external symbol \"class tensorflow::Status __cdecl tensorflow::OpDefForOp(char const *,class tensorflow::OpDef const * *)\" (?OpDefForOp@tensorflow@@YA?AVStatus@1@PEBDPEAPEBVOpDef@1@@Z) referenced in function \"class tensorflow::Status __cdecl tensorflow::EagerExecute(class tensorflow::EagerOperation *,class tensorflow::gtl::InlinedVector<class tensorflow::TensorHandle *,2> *,int *)\" (?EagerExecute@tensorflow@@YA?AVStatus@1@PEAVEagerOperation@1@PEAV?$InlinedVector@PEAVTensorHandle@tensorflow@@$01@gtl@1@PEAH@Z)\tsummarize_graph\tF:\\lib\\build\\tensorflow\\execute.obj\t1\t\r\nError\tLNK2019\tunresolved external symbol \"public: class tensorflow::AttrBuilder & __cdecl tensorflow::AttrBuilder::NumInputs(int)\" (?NumInputs@AttrBuilder@tensorflow@@QEAAAEAV12@H@Z) referenced in function \"public: void __cdecl tensorflow::EagerOperation::AddInput(class tensorflow::TensorHandle *)\" (?AddInput@EagerOperation@tensorflow@@QEAAXPEAVTensorHandle@2@@Z)\ttf_tutorials_example_trainer\tF:\\lib\\build\\tensorflow\\eager_operation.obj\t1\t\r\nError\tLNK2019\tunresolved external symbol \"public: class tensorflow::AttrBuilder & __cdecl tensorflow::AttrBuilder::NumInputs(int)\" (?NumInputs@AttrBuilder@tensorflow@@QEAAAEAV12@H@Z) referenced in function \"public: void __cdecl tensorflow::EagerOperation::AddInput(class tensorflow::TensorHandle *)\" (?AddInput@EagerOperation@tensorflow@@QEAAXPEAVTensorHandle@2@@Z)\tbenchmark_model\tF:\\lib\\build\\tensorflow\\eager_operation.obj\t1\t\r\nError\tLNK2019\tunresolved external symbol \"public: class tensorflow::AttrBuilder & __cdecl tensorflow::AttrBuilder::NumInputs(int)\" (?NumInputs@AttrBuilder@tensorflow@@QEAAAEAV12@H@Z) referenced in function \"public: void __cdecl tensorflow::EagerOperation::AddInput(class tensorflow::TensorHandle *)\" (?AddInput@EagerOperation@tensorflow@@QEAAXPEAVTensorHandle@2@@Z)\ttransform_graph\tF:\\lib\\build\\tensorflow\\eager_operation.obj\t1\t\r\nError\tLNK2019\tunresolved external symbol \"public: class tensorflow::AttrBuilder & __cdecl tensorflow::AttrBuilder::NumInputs(int)\" (?NumInputs@AttrBuilder@tensorflow@@QEAAAEAV12@H@Z) referenced in function \"public: void __cdecl tensorflow::EagerOperation::AddInput(class tensorflow::TensorHandle *)\" (?AddInput@EagerOperation@tensorflow@@QEAAXPEAVTensorHandle@2@@Z)\ttf_label_image_example\tF:\\lib\\build\\tensorflow\\eager_operation.obj\t1\t\r\nError\tLNK2019\tunresolved external symbol \"public: class tensorflow::AttrBuilder & __cdecl tensorflow::AttrBuilder::NumInputs(int)\" (?NumInputs@AttrBuilder@tensorflow@@QEAAAEAV12@H@Z) referenced in function \"public: void __cdecl tensorflow::EagerOperation::AddInput(class tensorflow::TensorHandle *)\" (?AddInput@EagerOperation@tensorflow@@QEAAXPEAVTensorHandle@2@@Z)\tcompare_graphs\tF:\\lib\\build\\tensorflow\\eager_operation.obj\t1\t\r\nError\tLNK2019\tunresolved external symbol \"public: class tensorflow::AttrBuilder & __cdecl tensorflow::AttrBuilder::NumInputs(int)\" (?NumInputs@AttrBuilder@tensorflow@@QEAAAEAV12@H@Z) referenced in function \"public: void __cdecl tensorflow::EagerOperation::AddInput(class tensorflow::TensorHandle *)\" (?AddInput@EagerOperation@tensorflow@@QEAAXPEAVTensorHandle@2@@Z)\tgrpc_tensorflow_server\tF:\\lib\\build\\tensorflow\\eager_operation.obj\t1\t\r\nError\tLNK2019\tunresolved external symbol \"public: class tensorflow::AttrBuilder & __cdecl tensorflow::AttrBuilder::NumInputs(int)\" (?NumInputs@AttrBuilder@tensorflow@@QEAAAEAV12@H@Z) referenced in function \"public: void __cdecl tensorflow::EagerOperation::AddInput(class tensorflow::TensorHandle *)\" (?AddInput@EagerOperation@tensorflow@@QEAAXPEAVTensorHandle@2@@Z)\tsummarize_graph\tF:\\lib\\build\\tensorflow\\eager_operation.obj\t1\t\r\nError\tLNK2019\tunresolved external symbol \"public: class tensorflow::NodeDef const & __cdecl tensorflow::AttrBuilder::BuildNodeDef(void)\" (?BuildNodeDef@AttrBuilder@tensorflow@@QEAAAEBVNodeDef@2@XZ) referenced in function \"class tensorflow::Status __cdecl tensorflow::EagerExecute(class tensorflow::EagerOperation *,class tensorflow::gtl::InlinedVector<class tensorflow::TensorHandle *,2> *,int *)\" (?EagerExecute@tensorflow@@YA?AVStatus@1@PEAVEagerOperation@1@PEAV?$InlinedVector@PEAVTensorHandle@tensorflow@@$01@gtl@1@PEAH@Z)\ttf_tutorials_example_trainer\tF:\\lib\\build\\tensorflow\\execute.obj\t1\t\r\nError\tLNK2019\tunresolved external symbol \"public: class tensorflow::NodeDef const & __cdecl tensorflow::AttrBuilder::BuildNodeDef(void)\" (?BuildNodeDef@AttrBuilder@tensorflow@@QEAAAEBVNodeDef@2@XZ) referenced in function \"class tensorflow::Status __cdecl tensorflow::EagerExecute(class tensorflow::EagerOperation *,class tensorflow::gtl::InlinedVector<class tensorflow::TensorHandle *,2> *,int *)\" (?EagerExecute@tensorflow@@YA?AVStatus@1@PEAVEagerOperation@1@PEAV?$InlinedVector@PEAVTensorHandle@tensorflow@@$01@gtl@1@PEAH@Z)\tbenchmark_model\tF:\\lib\\build\\tensorflow\\execute.obj\t1\t\r\nError\tLNK2019\tunresolved external symbol \"public: class tensorflow::NodeDef const & __cdecl tensorflow::AttrBuilder::BuildNodeDef(void)\" (?BuildNodeDef@AttrBuilder@tensorflow@@QEAAAEBVNodeDef@2@XZ) referenced in function \"class tensorflow::Status __cdecl tensorflow::EagerExecute(class tensorflow::EagerOperation *,class tensorflow::gtl::InlinedVector<class tensorflow::TensorHandle *,2> *,int *)\" (?EagerExecute@tensorflow@@YA?AVStatus@1@PEAVEagerOperation@1@PEAV?$InlinedVector@PEAVTensorHandle@tensorflow@@$01@gtl@1@PEAH@Z)\ttransform_graph\tF:\\lib\\build\\tensorflow\\execute.obj\t1\t\r\nError\tLNK2019\tunresolved external symbol \"public: class tensorflow::NodeDef const & __cdecl tensorflow::AttrBuilder::BuildNodeDef(void)\" (?BuildNodeDef@AttrBuilder@tensorflow@@QEAAAEBVNodeDef@2@XZ) referenced in function \"class tensorflow::Status __cdecl tensorflow::EagerExecute(class tensorflow::EagerOperation *,class tensorflow::gtl::InlinedVector<class tensorflow::TensorHandle *,2> *,int *)\" (?EagerExecute@tensorflow@@YA?AVStatus@1@PEAVEagerOperation@1@PEAV?$InlinedVector@PEAVTensorHandle@tensorflow@@$01@gtl@1@PEAH@Z)\ttf_label_image_example\tF:\\lib\\build\\tensorflow\\execute.obj\t1\t\r\nError\tLNK2019\tunresolved external symbol \"public: class tensorflow::NodeDef const & __cdecl tensorflow::AttrBuilder::BuildNodeDef(void)\" (?BuildNodeDef@AttrBuilder@tensorflow@@QEAAAEBVNodeDef@2@XZ) referenced in function \"class tensorflow::Status __cdecl tensorflow::EagerExecute(class tensorflow::EagerOperation *,class tensorflow::gtl::InlinedVector<class tensorflow::TensorHandle *,2> *,int *)\" (?EagerExecute@tensorflow@@YA?AVStatus@1@PEAVEagerOperation@1@PEAV?$InlinedVector@PEAVTensorHandle@tensorflow@@$01@gtl@1@PEAH@Z)\tcompare_graphs\tF:\\lib\\build\\tensorflow\\execute.obj\t1\t\r\nError\tLNK2019\tunresolved external symbol \"public: class tensorflow::NodeDef const & __cdecl tensorflow::AttrBuilder::BuildNodeDef(void)\" (?BuildNodeDef@AttrBuilder@tensorflow@@QEAAAEBVNodeDef@2@XZ) referenced in function \"class tensorflow::Status __cdecl tensorflow::EagerExecute(class tensorflow::EagerOperation *,class tensorflow::gtl::InlinedVector<class tensorflow::TensorHandle *,2> *,int *)\" (?EagerExecute@tensorflow@@YA?AVStatus@1@PEAVEagerOperation@1@PEAV?$InlinedVector@PEAVTensorHandle@tensorflow@@$01@gtl@1@PEAH@Z)\tgrpc_tensorflow_server\tF:\\lib\\build\\tensorflow\\execute.obj\t1\t\r\nError\tLNK2019\tunresolved external symbol \"public: class tensorflow::NodeDef const & __cdecl tensorflow::AttrBuilder::BuildNodeDef(void)\" (?BuildNodeDef@AttrBuilder@tensorflow@@QEAAAEBVNodeDef@2@XZ) referenced in function \"class tensorflow::Status __cdecl tensorflow::EagerExecute(class tensorflow::EagerOperation *,class tensorflow::gtl::InlinedVector<class tensorflow::TensorHandle *,2> *,int *)\" (?EagerExecute@tensorflow@@YA?AVStatus@1@PEAVEagerOperation@1@PEAV?$InlinedVector@PEAVTensorHandle@tensorflow@@$01@gtl@1@PEAH@Z)\tsummarize_graph\tF:\\lib\\build\\tensorflow\\execute.obj\t1\t\r\nError\tLNK2019\tunresolved external symbol \"public: struct tensorflow::Fprint128 __cdecl tensorflow::AttrBuilder::CacheKey(class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const &)const \" (?CacheKey@AttrBuilder@tensorflow@@QEBA?AUFprint128@2@AEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@Z) referenced in function \"class tensorflow::Status __cdecl tensorflow::EagerExecute(class tensorflow::EagerOperation *,class tensorflow::gtl::InlinedVector<class tensorflow::TensorHandle *,2> *,int *)\" (?EagerExecute@tensorflow@@YA?AVStatus@1@PEAVEagerOperation@1@PEAV?$InlinedVector@PEAVTensorHandle@tensorflow@@$01@gtl@1@PEAH@Z)\ttf_tutorials_example_trainer\tF:\\lib\\build\\tensorflow\\execute.obj\t1\t\r\nError\tLNK2019\tunresolved external symbol \"public: struct tensorflow::Fprint128 __cdecl tensorflow::AttrBuilder::CacheKey(class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const &)const \" (?CacheKey@AttrBuilder@tensorflow@@QEBA?AUFprint128@2@AEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@Z) referenced in function \"class tensorflow::Status __cdecl tensorflow::EagerExecute(class tensorflow::EagerOperation *,class tensorflow::gtl::InlinedVector<class tensorflow::TensorHandle *,2> *,int *)\" (?EagerExecute@tensorflow@@YA?AVStatus@1@PEAVEagerOperation@1@PEAV?$InlinedVector@PEAVTensorHandle@tensorflow@@$01@gtl@1@PEAH@Z)\tbenchmark_model\tF:\\lib\\build\\tensorflow\\execute.obj\t1\t\r\nError\tLNK2019\tunresolved external symbol \"public: struct tensorflow::Fprint128 __cdecl tensorflow::AttrBuilder::CacheKey(class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const &)const \" (?CacheKey@AttrBuilder@tensorflow@@QEBA?AUFprint128@2@AEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@Z) referenced in function \"class tensorflow::Status __cdecl tensorflow::EagerExecute(class tensorflow::EagerOperation *,class tensorflow::gtl::InlinedVector<class tensorflow::TensorHandle *,2> *,int *)\" (?EagerExecute@tensorflow@@YA?AVStatus@1@PEAVEagerOperation@1@PEAV?$InlinedVector@PEAVTensorHandle@tensorflow@@$01@gtl@1@PEAH@Z)\ttransform_graph\tF:\\lib\\build\\tensorflow\\execute.obj\t1\t\r\nError\tLNK2019\tunresolved external symbol \"public: struct tensorflow::Fprint128 __cdecl tensorflow::AttrBuilder::CacheKey(class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const &)const \" (?CacheKey@AttrBuilder@tensorflow@@QEBA?AUFprint128@2@AEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@Z) referenced in function \"class tensorflow::Status __cdecl tensorflow::EagerExecute(class tensorflow::EagerOperation *,class tensorflow::gtl::InlinedVector<class tensorflow::TensorHandle *,2> *,int *)\" (?EagerExecute@tensorflow@@YA?AVStatus@1@PEAVEagerOperation@1@PEAV?$InlinedVector@PEAVTensorHandle@tensorflow@@$01@gtl@1@PEAH@Z)\ttf_label_image_example\tF:\\lib\\build\\tensorflow\\execute.obj\t1\t\r\nError\tLNK2019\tunresolved external symbol \"public: struct tensorflow::Fprint128 __cdecl tensorflow::AttrBuilder::CacheKey(class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const &)const \" (?CacheKey@AttrBuilder@tensorflow@@QEBA?AUFprint128@2@AEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@Z) referenced in function \"class tensorflow::Status __cdecl tensorflow::EagerExecute(class tensorflow::EagerOperation *,class tensorflow::gtl::InlinedVector<class tensorflow::TensorHandle *,2> *,int *)\" (?EagerExecute@tensorflow@@YA?AVStatus@1@PEAVEagerOperation@1@PEAV?$InlinedVector@PEAVTensorHandle@tensorflow@@$01@gtl@1@PEAH@Z)\tcompare_graphs\tF:\\lib\\build\\tensorflow\\execute.obj\t1\t\r\nError\tLNK2019\tunresolved external symbol \"public: struct tensorflow::Fprint128 __cdecl tensorflow::AttrBuilder::CacheKey(class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const &)const \" (?CacheKey@AttrBuilder@tensorflow@@QEBA?AUFprint128@2@AEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@Z) referenced in function \"class tensorflow::Status __cdecl tensorflow::EagerExecute(class tensorflow::EagerOperation *,class tensorflow::gtl::InlinedVector<class tensorflow::TensorHandle *,2> *,int *)\" (?EagerExecute@tensorflow@@YA?AVStatus@1@PEAVEagerOperation@1@PEAV?$InlinedVector@PEAVTensorHandle@tensorflow@@$01@gtl@1@PEAH@Z)\tgrpc_tensorflow_server\tF:\\lib\\build\\tensorflow\\execute.obj\t1\t\r\nError\tLNK2019\tunresolved external symbol \"public: struct tensorflow::Fprint128 __cdecl tensorflow::AttrBuilder::CacheKey(class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const &)const \" (?CacheKey@AttrBuilder@tensorflow@@QEBA?AUFprint128@2@AEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@Z) referenced in function \"class tensorflow::Status __cdecl tensorflow::EagerExecute(class tensorflow::EagerOperation *,class tensorflow::gtl::InlinedVector<class tensorflow::TensorHandle *,2> *,int *)\" (?EagerExecute@tensorflow@@YA?AVStatus@1@PEAVEagerOperation@1@PEAV?$InlinedVector@PEAVTensorHandle@tensorflow@@$01@gtl@1@PEAH@Z)\tsummarize_graph\tF:\\lib\\build\\tensorflow\\execute.obj\t1\t\r\n```\r\n\r\n", "comments": ["I have pretty much the same issue. Almost all the sub-projects get built except, for the below 7. And each of them have linker error for eager_operations.obj and execute.obj. I've tried both https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/cmake/README.md and https://joe-antognini.github.io/machine-learning/build-windows-tf ways of building tensorflow, but still end up with same errors. \r\n\r\ngrpc_tensorflow_server\r\nbenchmark_model\r\ntf_tutorials_example_trainer\r\ntf_label_image_example\r\ncompare_graphs\r\ntransform_graph\r\nsummarize_graph\r\n\r\n \"C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\bin\\amd64\\vcvarsall.bat\" this particular batch file wasn't present in my system. So, instead I ran vcvars64.bat file.\r\nPlease let us know where we are going wrong.", "I think this is happening because eager dependency on c api and current cmake code doesn't handle that. #16480 might fix all of these issues.", "Assigning to @asimshankar since it might be related to Eager.", "Thanks @achalshah20 .\r\n@LaurentBerger @subhaamalraj8 - Could you try with that PR patched in? ", "I have done : \r\n`git pull `\r\nthen create a patch using https://github.com/tensorflow/tensorflow/pull/16480.patch page\r\n\r\n[pr16480.txt](https://github.com/tensorflow/tensorflow/files/2013038/pr16480.txt)\r\n\r\n\r\n\r\ntry to apply patch  (many errors with option --check): \r\n\r\n$ git apply --stat ../pr16480.patch\r\n tensorflow/contrib/cmake/tf_core_framework.cmake   |    2\r\n tensorflow/contrib/cmake/CMakeLists.txt            |   12 +-\r\n tensorflow/contrib/cmake/external/grpc.cmake       |   11 +\r\n tensorflow/contrib/cmake/tf_cc_ops.cmake           |    2\r\n tensorflow/contrib/cmake/tf_core_framework.cmake   |    8 +\r\n .../core/platform/default/gpu/cupti_wrapper.h      |    8 +\r\n tensorflow/contrib/cmake/CMakeLists.txt            |    1\r\n tensorflow/contrib/cmake/tf_core_framework.cmake   |    4 -\r\n tensorflow/contrib/cmake/tf_python.cmake           |   17 ++\r\n .../core/platform/default/gpu/cupti_wrapper.h      |    8 +\r\n .../core/platform/default/gpu/cupti_wrapper.h      |    6 -\r\n tensorflow/contrib/cmake/tf_core_ops.cmake         |    8 +\r\n tensorflow/contrib/cmake/tf_cc_ops.cmake           |    2\r\n tensorflow/contrib/cmake/CMakeLists.txt            |    5 -\r\n tensorflow/contrib/cmake/TensorflowConfig.cmake.in |   16 ++\r\n .../contrib/cmake/TensorflowConfigVersion.cmake.in |   11 +\r\n tensorflow/contrib/cmake/tf_shared_lib.cmake       |   80 +++++++++-\r\n tensorflow/contrib/cmake/README.md                 |  160 ++++++++++++++++++--\r\n tensorflow/contrib/cmake/README.md                 |    4 -\r\n tensorflow/core/util/cuda_device_functions.h       |    9 +\r\n tensorflow/core/util/cuda_device_functions.h       |    4 -\r\n tensorflow/core/util/cuda_launch_config.h          |    4 +\r\n tensorflow/contrib/cmake/external/protobuf.cmake   |    2\r\n tensorflow/contrib/cmake/CMakeLists.txt            |    7 +\r\n tensorflow/contrib/cmake/README.md                 |    4 -\r\n tensorflow/contrib/cmake/README.md                 |    4 +\r\n tensorflow/contrib/cmake/README.md                 |   16 ++\r\n tensorflow/contrib/cmake/external/grpc.cmake       |   25 +++\r\n tensorflow/contrib/cmake/external/grpc.cmake       |    2\r\n tensorflow/tools/pip_package/setup.py              |    2\r\n tensorflow/tools/pip_package/setup.py              |    3\r\n tensorflow/contrib/cmake/CMakeLists.txt            |    8 +\r\n tensorflow/contrib/cmake/external/grpc.cmake       |   55 +++++--\r\n tensorflow/contrib/cmake/external/grpc.cmake       |    2\r\n tensorflow/contrib/cmake/external/protobuf.cmake   |    2\r\n tensorflow/contrib/cmake/external/protobuf.cmake   |    2\r\n tensorflow/contrib/cmake/external/grpc.cmake       |   70 +++++----\r\n tensorflow/contrib/cmake/external/protobuf.cmake   |   11 +\r\n .../tools/ci_build/windows/cpu/cmake/run_build.bat |    3\r\n .../tools/ci_build/windows/gpu/cmake/run_build.bat |    3\r\n tensorflow/contrib/cmake/external/grpc.cmake       |   79 +++++-----\r\n tensorflow/contrib/cmake/README.md                 |   14 +-\r\n .../tools/ci_build/windows/cpu/cmake/run_build.bat |    3\r\n .../tools/ci_build/windows/gpu/cmake/run_build.bat |    3\r\n tensorflow/contrib/cmake/README.md                 |   12 +-\r\n tensorflow/contrib/cmake/README.md                 |    2\r\n tensorflow/contrib/cmake/README.md                 |    2\r\n tensorflow/contrib/cmake/external/grpc.cmake       |   40 -----\r\n tensorflow/contrib/cmake/CMakeLists.txt            |    5 +\r\n tensorflow/contrib/nccl/kernels/nccl_manager.h     |    5 +\r\n tensorflow/contrib/nccl/kernels/nccl_ops.cc        |    4 +\r\n tensorflow/contrib/nccl/kernels/nccl_manager.h     |    2\r\n tensorflow/contrib/nccl/kernels/nccl_ops.cc        |    2\r\n tensorflow/core/platform/default/logging.h         |    5 +\r\n tensorflow/contrib/cmake/README.md                 |   10 +\r\n tensorflow/contrib/cmake/CMakeLists.txt            |    2\r\n tensorflow/contrib/cmake/external/png.cmake        |    1\r\n tensorflow/contrib/cmake/tf_core_framework.cmake   |    4 +\r\n tensorflow/contrib/cmake/tf_core_ops.cmake         |    8 +\r\n tensorflow/contrib/cmake/tf_python.cmake           |   21 ++-\r\n tensorflow/contrib/cmake/CMakeLists.txt            |    4 -\r\n tensorflow/contrib/cmake/README.md                 |    6 -\r\n tensorflow/contrib/cmake/external/grpc.cmake       |    3\r\n tensorflow/contrib/cmake/tf_python.cmake           |    2\r\n tensorflow/core/util/cuda_device_functions.h       |   16 +-\r\n tensorflow/contrib/cmake/CMakeLists.txt            |    5 +\r\n tensorflow/contrib/cmake/CMakeLists.txt            |    1\r\n tensorflow/core/platform/default/logging.h         |    7 +\r\n tensorflow/contrib/nccl/kernels/nccl_manager.h     |    4 -\r\n tensorflow/c/python_api.cc                         |    2\r\n tensorflow/contrib/cmake/CMakeLists.txt            |    3\r\n tensorflow/contrib/cmake/tf_c.cmake                |   27 ++-\r\n tensorflow/contrib/cmake/tf_core_cpu.cmake         |    4 -\r\n .../contrib/cmake/tf_core_eager_runtime.cmake      |   57 +++++++\r\n tensorflow/contrib/cmake/tf_python.cmake           |    2\r\n tensorflow/contrib/cmake/tf_shared_lib.cmake       |    4 +\r\n tensorflow/contrib/cmake/tf_python.cmake           |    2\r\n tensorflow/c/python_api.cc                         |    2\r\n tensorflow/contrib/cmake/tf_c.cmake                |   34 ++++\r\n 79 files changed, 721 insertions(+), 291 deletions(-)\r\n\r\nLaurent@PC-Laurent-Vision MINGW64 /f/lib/tensorflow (master)\r\n$ git apply --check ../pr16480.patch\r\nerror: patch failed: tensorflow/contrib/cmake/tf_core_framework.cmake:126\r\nerror: tensorflow/contrib/cmake/tf_core_framework.cmake: patch does not apply\r\nerror: patch failed: tensorflow/contrib/cmake/external/grpc.cmake:21\r\nerror: tensorflow/contrib/cmake/external/grpc.cmake: patch does not apply\r\nerror: patch failed: tensorflow/contrib/cmake/tf_cc_ops.cmake:149\r\nerror: tensorflow/contrib/cmake/tf_cc_ops.cmake: patch does not apply\r\nerror: patch failed: tensorflow/core/platform/default/gpu/cupti_wrapper.h:20\r\nerror: tensorflow/core/platform/default/gpu/cupti_wrapper.h: patch does not appl                                                                                            y\r\nwarning: tensorflow/contrib/cmake/tf_python.cmake has type 100644, expected 1007                                                                                            55\r\nerror: patch failed: tensorflow/core/platform/default/gpu/cupti_wrapper.h:20\r\nerror: tensorflow/core/platform/default/gpu/cupti_wrapper.h: patch does not appl                                                                                            y\r\nerror: patch failed: tensorflow/core/platform/default/gpu/cupti_wrapper.h:20\r\nerror: tensorflow/core/platform/default/gpu/cupti_wrapper.h: patch does not appl                                                                                            y\r\nerror: patch failed: tensorflow/contrib/cmake/tf_core_ops.cmake:15\r\nerror: tensorflow/contrib/cmake/tf_core_ops.cmake: patch does not apply\r\nerror: patch failed: tensorflow/contrib/cmake/tf_cc_ops.cmake:149\r\nerror: tensorflow/contrib/cmake/tf_cc_ops.cmake: patch does not apply\r\nerror: patch failed: tensorflow/contrib/cmake/tf_shared_lib.cmake:99\r\nerror: tensorflow/contrib/cmake/tf_shared_lib.cmake: patch does not apply\r\nerror: patch failed: tensorflow/contrib/cmake/README.md:35\r\nerror: tensorflow/contrib/cmake/README.md: patch does not apply\r\nerror: patch failed: tensorflow/contrib/cmake/README.md:121\r\nerror: tensorflow/contrib/cmake/README.md: patch does not apply\r\nerror: patch failed: tensorflow/core/util/cuda_device_functions.h:28\r\nerror: tensorflow/core/util/cuda_device_functions.h: patch does not apply\r\nerror: patch failed: tensorflow/core/util/cuda_device_functions.h:28\r\nerror: tensorflow/core/util/cuda_device_functions.h: patch does not apply\r\nerror: patch failed: tensorflow/contrib/cmake/external/protobuf.cmake:16\r\nerror: tensorflow/contrib/cmake/external/protobuf.cmake: patch does not apply\r\nerror: patch failed: tensorflow/contrib/cmake/CMakeLists.txt:31\r\nerror: tensorflow/contrib/cmake/CMakeLists.txt: patch does not apply\r\nerror: patch failed: tensorflow/contrib/cmake/README.md:121\r\nerror: tensorflow/contrib/cmake/README.md: patch does not apply\r\nerror: patch failed: tensorflow/contrib/cmake/README.md:179\r\nerror: tensorflow/contrib/cmake/README.md: patch does not apply\r\nerror: patch failed: tensorflow/contrib/cmake/README.md:35\r\nerror: tensorflow/contrib/cmake/README.md: patch does not apply\r\nerror: patch failed: tensorflow/contrib/cmake/external/grpc.cmake:51\r\nerror: tensorflow/contrib/cmake/external/grpc.cmake: patch does not apply\r\nerror: patch failed: tensorflow/contrib/cmake/external/grpc.cmake:30\r\nerror: tensorflow/contrib/cmake/external/grpc.cmake: patch does not apply\r\nerror: patch failed: tensorflow/tools/pip_package/setup.py:29\r\nerror: tensorflow/tools/pip_package/setup.py: patch does not apply\r\nerror: patch failed: tensorflow/tools/pip_package/setup.py:37\r\nerror: tensorflow/tools/pip_package/setup.py: patch does not apply\r\nerror: patch failed: tensorflow/contrib/cmake/external/grpc.cmake:14\r\nerror: tensorflow/contrib/cmake/external/grpc.cmake: patch does not apply\r\nerror: patch failed: tensorflow/contrib/cmake/external/grpc.cmake:32\r\nerror: tensorflow/contrib/cmake/external/grpc.cmake: patch does not apply\r\nerror: patch failed: tensorflow/contrib/cmake/external/protobuf.cmake:16\r\nerror: tensorflow/contrib/cmake/external/protobuf.cmake: patch does not apply\r\nerror: patch failed: tensorflow/contrib/cmake/external/protobuf.cmake:16\r\nerror: tensorflow/contrib/cmake/external/protobuf.cmake: patch does not apply\r\nerror: patch failed: tensorflow/contrib/cmake/external/grpc.cmake:17\r\nerror: tensorflow/contrib/cmake/external/grpc.cmake: patch does not apply\r\nerror: patch failed: tensorflow/contrib/cmake/external/protobuf.cmake:16\r\nerror: tensorflow/contrib/cmake/external/protobuf.cmake: patch does not apply\r\nerror: patch failed: tensorflow/tools/ci_build/windows/cpu/cmake/run_build.bat:3                                                                                            4\r\nerror: tensorflow/tools/ci_build/windows/cpu/cmake/run_build.bat: patch does not                                                                                             apply\r\nerror: patch failed: tensorflow/tools/ci_build/windows/gpu/cmake/run_build.bat:3                                                                                            5\r\nerror: tensorflow/tools/ci_build/windows/gpu/cmake/run_build.bat: patch does not                                                                                             apply\r\nerror: patch failed: tensorflow/contrib/cmake/external/grpc.cmake:14\r\nerror: tensorflow/contrib/cmake/external/grpc.cmake: patch does not apply\r\nerror: patch failed: tensorflow/contrib/cmake/README.md:35\r\nerror: tensorflow/contrib/cmake/README.md: patch does not apply\r\nerror: patch failed: tensorflow/tools/ci_build/windows/cpu/cmake/run_build.bat:3                                                                                            4\r\nerror: tensorflow/tools/ci_build/windows/cpu/cmake/run_build.bat: patch does not                                                                                             apply\r\nerror: patch failed: tensorflow/tools/ci_build/windows/gpu/cmake/run_build.bat:3                                                                                            5\r\nerror: tensorflow/tools/ci_build/windows/gpu/cmake/run_build.bat: patch does not                                                                                             apply\r\nerror: patch failed: tensorflow/contrib/cmake/README.md:39\r\nerror: tensorflow/contrib/cmake/README.md: patch does not apply\r\nerror: patch failed: tensorflow/contrib/cmake/README.md:135\r\nerror: tensorflow/contrib/cmake/README.md: patch does not apply\r\nerror: patch failed: tensorflow/contrib/cmake/README.md:42\r\nerror: tensorflow/contrib/cmake/README.md: patch does not apply\r\nerror: patch failed: tensorflow/contrib/cmake/external/grpc.cmake:14\r\nerror: tensorflow/contrib/cmake/external/grpc.cmake: patch does not apply\r\nerror: patch failed: tensorflow/contrib/nccl/kernels/nccl_manager.h:20\r\nerror: tensorflow/contrib/nccl/kernels/nccl_manager.h: patch does not apply\r\nerror: patch failed: tensorflow/contrib/nccl/kernels/nccl_ops.cc:17\r\nerror: tensorflow/contrib/nccl/kernels/nccl_ops.cc: patch does not apply\r\nerror: patch failed: tensorflow/contrib/nccl/kernels/nccl_manager.h:20\r\nerror: tensorflow/contrib/nccl/kernels/nccl_manager.h: patch does not apply\r\nerror: patch failed: tensorflow/contrib/nccl/kernels/nccl_ops.cc:17\r\nerror: tensorflow/contrib/nccl/kernels/nccl_ops.cc: patch does not apply\r\nerror: patch failed: tensorflow/contrib/cmake/README.md:35\r\nerror: tensorflow/contrib/cmake/README.md: patch does not apply\r\nwarning: tensorflow/contrib/cmake/tf_python.cmake has type 100644, expected 1007                                                                                            55\r\nerror: patch failed: tensorflow/contrib/cmake/README.md:4\r\nerror: tensorflow/contrib/cmake/README.md: patch does not apply\r\nerror: patch failed: tensorflow/contrib/cmake/external/grpc.cmake:28\r\nerror: tensorflow/contrib/cmake/external/grpc.cmake: patch does not apply\r\nwarning: tensorflow/contrib/cmake/tf_python.cmake has type 100644, expected 1007                                                                                            55\r\nerror: patch failed: tensorflow/core/util/cuda_device_functions.h:28\r\nerror: tensorflow/core/util/cuda_device_functions.h: patch does not apply\r\nerror: patch failed: tensorflow/contrib/nccl/kernels/nccl_manager.h:23\r\nerror: tensorflow/contrib/nccl/kernels/nccl_manager.h: patch does not apply\r\nerror: patch failed: tensorflow/contrib/cmake/tf_core_cpu.cmake:20\r\nerror: tensorflow/contrib/cmake/tf_core_cpu.cmake: patch does not apply\r\nwarning: tensorflow/contrib/cmake/tf_python.cmake has type 100644, expected 1007                                                                                            55\r\nwarning: tensorflow/contrib/cmake/tf_python.cmake has type 100644, expected 1007                                                                                            55\r\n\r\n\r\n\r\n", "Tried that patch and didn't make a difference\r\nAny other solution?", "Ok now I think now we are on the good way: \r\n```\r\ngit pull \r\ngit log\r\ncommit ccdbd87b0bc19610f53790ae53da8cff3677cb5b (HEAD -> master, origin/master, origin/HEAD)\r\nAuthor: Pete Warden <pete@petewarden.com>\r\nDate:   Tue May 29 19:24:45 2018 -0700\r\n\r\n    Fix for Raspberry Pi wheel architecture tags (#19637)\r\n\r\n\r\ndelete cmakecache.txt\r\nrun cmake-gui \r\nconfigure (give path to swig)\r\ngenerate\r\nopen vs project\r\nclean solution\r\n\r\n```\r\nand only 7 errors but \r\n[TFerror20180530.txt](https://github.com/tensorflow/tensorflow/files/2054311/TFerror20180530.txt)\r\n\r\n1>Performing update step for 'zlib'\r\n1>CUSTOMBUILD : error : Your local changes to the following files would be overwritten by checkout:\r\n1>\tzconf.h\r\n1>Please commit your changes or stash them before you switch branches.\r\n\r\n261>LINK : fatal error LNK1181: cannot open input file '\\pywrap_tensorflow_internal.lib'\r\n261>Done building project \"_nearest_neighbor_ops.vcxproj\" -- FAILED.\r\n262>LINK : fatal error LNK1181: cannot open input file '\\pywrap_tensorflow_internal.lib'\r\n262>Done building project \"_lstm_ops.vcxproj\" -- FAILED.\r\n263>LINK : fatal error LNK1181: cannot open input file '\\pywrap_tensorflow_internal.lib'\r\n263>Done building project \"_gru_ops.vcxproj\" -- FAILED.\r\n264>LINK : fatal error LNK1181: cannot open input file '\\pywrap_tensorflow_internal.lib'\r\n264>Done building project \"_beam_search_ops.vcxproj\" -- FAILED.\r\n265>LINK : fatal error LNK1181: cannot open input file '\\pywrap_tensorflow_internal.lib'\r\n265>Done building project \"_periodic_resample_op.vcxproj\" -- FAILED.\r\n268>AttributeError: module 'tensorflow.python.training.checkpointable' has no attribute 'CheckpointableBase'\r\n268>C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\Common7\\IDE\\VC\\VCTargets\\Microsoft.CppCommon.targets(171,5): error MSB6006: \"cmd.exe\" exited with code 1.\r\n268>Done building project \"tf_python_api.vcxproj\" -- FAILED.\r\n\r\n\r\nNow I select pywrap_tensorflow_internal project and select build only : \r\n```\r\n1>------ Build started: Project: pywrap_tensorflow_internal, Configuration: Release x64 ------\r\n1>Generating __force_rebuild\r\n1>\r\n1>Running SWIG to generate Python wrappers\r\n1>pywrap_tensorflow_internal.cc\r\n1>f:\\lib\\tensorflow\\tensorflow\\c\\c_api.h(1108): warning C4190: 'TF_NewWhile' has C-linkage specified, but returns UDT 'TF_WhileParams' which is incompatible with C\r\n1>f:\\lib\\tensorflow\\tensorflow\\c\\c_api.h(1064): note: see declaration of 'TF_WhileParams'\r\n1>   Creating library F:/lib/build/tensorflow/Release/pywrap_tensorflow_internal.lib and object F:/lib/build/tensorflow/Release/pywrap_tensorflow_internal.exp\r\n1>pywrap_tensorflow_internal.exp : warning LNK4070: /OUT:_pywrap_tensorflow_internal.pyd directive in .EXP differs from output filename 'F:\\lib\\build\\tensorflow\\Release\\pywrap_tensorflow_internal.dll'; ignoring directive\r\n\r\n```\r\nSearching pywrap_tensorflow_internal.lib on my disk I can find in F:\\lib\\build\\tensorflow\\Release\\pywrap_tensorflow_internal.lib  and F:\\lib\\build\\tensorflow\\tf_python\\tensorflow\\python\\pywrap_tensorflow_internal.lib\r\nIf i give first path F:\\lib\\build\\tensorflow\\Release\\pywrap_tensorflow_internal.lib  instead of \\pywrap_tensorflow_internal.lib (path starting with a \\  ??) in input (project properties link) and rebuild project : \r\n1>------ Build started: Project: _nearest_neighbor_ops, Configuration: Release x64 ------\r\n1>_nearest_neighbor_ops.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\_nearest_neighbor_ops.dll\r\n========== Build: 1 succeeded, 0 failed, 0 up-to-date, 0 skipped ==========\r\n1>------ Build started: Project: _beam_search_ops, Configuration: Release x64 ------\r\n1>_beam_search_ops.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\_beam_search_ops.dll\r\n========== Build: 1 succeeded, 0 failed, 0 up-to-date, 0 skipped ==========\r\n1>------ Build started: Project: _gru_ops, Configuration: Release x64 ------\r\n1>_gru_ops.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\_gru_ops.dll\r\n========== Build: 1 succeeded, 0 failed, 0 up-to-date, 0 skipped ==========\r\n1>------ Build started: Project: _lstm_ops, Configuration: Release x64 ------\r\n1>_lstm_ops.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\_lstm_ops.dll\r\n========== Build: 1 succeeded, 0 failed, 0 up-to-date, 0 skipped ==========\r\n1>------ Build started: Project: _periodic_resample_op, Configuration: Release x64 ------\r\n1>_periodic_resample_op.vcxproj -> F:\\lib\\build\\tensorflow\\Release\\_periodic_resample_op.dll\r\n========== Build: 1 succeeded, 0 failed, 0 up-to-date, 0 skipped ==========\r\n\r\n\r\n\r\n\r\n\r\n", "Nagging Assignee @asimshankar: It has been 76 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "I believe we're now able to suggest building using `bazel` instead of CMake for Windows ([email thread](https://groups.google.com/a/tensorflow.org/forum/#!topic/build/9vKi3ceP2ZI)).\r\n\r\nThese instructions should be up soon, for a preview see:\r\nhttps://gist.github.com/meteorcloudy/8e5f1aab7c7fa87b16ae28e6f8fd3fd2\r\n\r\nThus, I'm tempted to close this issue and defer to #19893 and #19583 instead.\r\n\r\nLet me know if that doesn't make sense. Thanks!"]}, {"number": 19126, "title": "Build Tensorflow C++ Windows with MSVC2013", "body": "I have successfully built Tensorflow C++ Windows with MSVC2015, but currently I am interested in building Tensorflow C++ Windows with MSVC2013. May I know has anybody done this before, or does it doable?\r\n\r\nThanks!", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "It's most likely undoable. TensorFlow is written in C++11 and MSVC2013 has [limited support](https://msdn.microsoft.com/en-us/library/hh567368.aspx) for that."]}, {"number": 19125, "title": "proto issue: anchor_generator.proto", "body": "When I tried to test the model from the tensorflow/models/research folder using the command below:                 \r\n\r\n> python object_detection/builders/model_builder_test.py\r\n\r\nIt throws out error saying import is not done.\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"builders/model_builder_test.py\", line 21, in <module>\r\n    from object_detection.builders import model_builder\r\n  File \"D:\\Workspace\\Tensorflow\\models\\research\\object_detection\\builders\\model_builder.py\", line 17, in <module>\r\n    from object_detection.builders import anchor_generator_builder\r\n  File \"D:\\Workspace\\Tensorflow\\models\\research\\object_detection\\builders\\anchor_generator_builder.py\", line 21, in <module>\r\n    from object_detection.protos import anchor_generator_pb2\r\n  File \"D:\\Workspace\\Tensorflow\\models\\research\\object_detection\\protos\\anchor_generator_pb2.py\", line 27, in <module>\r\n    dependencies=[object__detection_dot_protos_dot_grid__anchor__generator__pb2.DESCRIPTOR,object__detection_dot_protos_dot_ssd__anchor__generator__pb2.DESCRIPTOR,object__detection_dot_protos_dot_multiscale__anchor__generator__pb2.DESCRIPTOR,])\r\n  File \"C:\\Users\\M1043107\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\google\\protobuf\\descriptor.py\", line 829, in __new__\r\n    return _message.default_pool.AddSerializedFile(serialized_pb)\r\nTypeError: Couldn't build proto file into descriptor pool!\r\nInvalid proto descriptor for file \"object_detection/protos/anchor_generator.proto\":\r\n  object_detection/protos/anchor_generator.proto: Import \"object_detection/protos/grid_anchor_generator.proto\" has not been loaded.\r\n  object_detection.protos.AnchorGenerator.grid_anchor_generator: \"object_detection.protos.GridAnchorGenerator\" seems to be defined in \"grid_anchor_generator.proto\", which is not imported by \"object_detection/protos/anchor_generator.proto\".  To use it here, please add the necessary import.\r\n```\r\n\r\nAny solution?\r\n", "comments": []}, {"number": 19124, "title": "/tensorflow/tensorflow/contrib/makefile/gen/bin/benchmark] Error 1", "body": "\r\n/home/pi/Downloads/tensorFlow/tfsource/tensorflow/tensorflow/contrib/makefile/gen/lib/libtensorflow-core.a(mutex.o): In function `tensorflow::condition_variable::notify_one()':\r\nmutex.cc:(.text+0xa8): undefined reference to `nsync::nsync_cv_signal(nsync::nsync_cv_s_*)'\r\n/home/pi/Downloads/tensorFlow/tfsource/tensorflow/tensorflow/contrib/makefile/gen/lib/libtensorflow-core.a(mutex.o): In function `tensorflow::condition_variable::notify_all()':\r\nmutex.cc:(.text+0xac): undefined reference to `nsync::nsync_cv_broadcast(nsync::nsync_cv_s_*)'\r\ncollect2: error: ld returned 1 exit status\r\ntensorflow/contrib/makefile/Makefile:730: recipe for target '/home/pi/Downloads/tensorFlow/tfsource/tensorflow/tensorflow/contrib/makefile/gen/bin/benchmark' failed\r\nmake: *** [/home/pi/Downloads/tensorFlow/tfsource/tensorflow/tensorflow/contrib/makefile/gen/bin/benchmark] Error 1\r\n\r\nPlease,who can help me make this issue\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "It has been 16 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Have you solved the problem?", "i have same problem!!"]}, {"number": 19123, "title": "Error converting from tflite to PB", "body": "bazel run --config=opt   //tensorflow/contrib/lite/toco:toco --   --input_file=/root/tensorflow/tensorflow/mobilenet_v1_1.0_224.tflite   --output_file=/root/tensorflow/tensorflow/tflite_2_pb.pb   --input_format=TFLITE   --output_format=TENSORFLOW_GRAPHDEF   --input_shape=1,224,224,3   --input_array=input   --output_array=MobilenetV1/Predictions/Reshape_1\r\n\r\n\r\n**It shows below error:** \r\n\r\nINFO: Analysed target //tensorflow/contrib/lite/toco:toco (0 packages loaded).\r\nINFO: Found 1 target...\r\nTarget //tensorflow/contrib/lite/toco:toco up-to-date:\r\n  bazel-bin/tensorflow/contrib/lite/toco/toco\r\nINFO: Elapsed time: 0.198s, Critical Path: 0.00s\r\nINFO: Build completed successfully, 1 total action\r\n\r\nINFO: Running command line: bazel-bin/tensorflow/contrib/lite/toco/toco '--input_file=/root/tensorflow/tensorflow/mobilenet_v1_1.0_224.tflite' '--output_file=/root/tensorflow/tensorflow/tflite_2_pb.pb' '--input_format=TFLITE' '--output_format=TENSORFLOW_GRAPHDEF' '--input_shape=1,224,224,3' '--input_array=input' '--output_array=MobilenetV1/Predictions/Reshape_1'\r\n2018-05-07 16:07:38.775341: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 31 operators, 89 arrays (0 quantized)\r\n2018-05-07 16:07:38.775647: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 31 operators, 89 arrays (0 quantized)\r\n2018-05-07 16:07:38.775663: F tensorflow/contrib/lite/toco/graph_transformations/propagate_fixed_sizes.cc:48] Check failed: dilation_width_factor >= 1 (0 vs. 1)\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "@samsun639 I wonder why you closed this issue? I wonder if there's a way to convert from tflite flat buffer model back to pb model.", "This issue is meaningful.\r\nDevelopers need to find a way to convert the tflite model to frozen model.\r\n@shashishekhar ", "@samsun639 Did you ever find a way to convert from tflite to pb? If so, I would love to know how.", "I too would like to know the same, converting .tflite to frozen model. ", "Anyone has the solution?", "Anyone?", "You can analyse TFlite, like operations and subgraph using this nice [tool](https://github.com/PeteBlackerThe3rd/tflite_analyser).", "I have more specific question: how do I get .pb for this particular .tflite model? \r\nhttps://www.tensorflow.org/lite/models/segmentation/overview\r\nI want to use the same training set as in the pre-trained .tflite model", "Regarding the general solution, toco seems not to be working (see [this](https://stackoverflow.com/questions/59924882/using-toco-command-converting-tflite-to-pb-throwing-error-tensorflow-graphdef)), and the only custom converting script I've found is [this](https://gist.github.com/tworuler/bd7bd4c6cd9a8fbbeb060e7b64cfa008). I think it should be possible to adapt it to other models as well"]}, {"number": 19122, "title": "Windows: Adding a new op", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:windows7\r\n- **TensorFlow installed from (source or binary)**:binary\r\n- **TensorFlow version (use command below)**:1.8.0\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:6.4.0\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\nI use pip to install tensorflow, but there is no library I need to compile my op.\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\nTF_CFLAGS=( $(python -c 'import tensorflow as tf; print(\" \".join(tf.sysconfig.get_compile_flags()))') ) TF_LFLAGS=( $(python -c 'import tensorflow as tf; print(\" \".join(tf.sysconfig.get_link_flags()))') ) g++ -std=c++11 -shared zero_out.cc -o zero_out.so -fPIC ${TF_CFLAGS[@]} ${TF_LFLAGS[@]} -O2 /usr/bin/ld: \u627e\u4e0d\u5230 -ltensorflow_framework collect2: \u9519\u8bef\uff1ald \u8fd4\u56de 1", "comments": ["You will need to figure out the correct ABI using `tf.__cxx11_abi_flag__` and set the following env-vars\r\n\r\n```\r\n\"\\\"%s/libtensorflow_framework.so\\\")\\n\" % tf.sysconfig.get_lib()\r\ntf.sysconfig.get_include()\r\n```\r\n\r\nBut you will run into another new issue #18841 and hence you'll need the git-repository and compile TF from source.", "@PatWie I have searched \u2018libtensorflow_framework.so' on my computer and I can not find it which may not be installed. I have tried reinstalling TF many times. However, I got the same result. Must I install TF from source if I want to add my op?", "Sorry for the trouble, we do want to make sure that the documentation is correct and useful.\r\n\r\nAre you following https://www.tensorflow.org/extend/adding_an_op#compile_the_op_using_your_system_compiler_tensorflow_binary_installation ?\r\n\r\nCould you include a [minimum, complete, verifiable](https://stackoverflow.com/help/mcve) example to reproduce the problem?\r\n\r\nThough, I see you're using Windows. In Windows, there is no equivalent of `libtensorflow_framework.so`, we compile a single monolithic library for it right now.\r\n(CC @allenlavoie )", "@asimshankar \r\n[https://tensorflow.google.cn/extend/adding_an_op#compile_the_op_using_your_system_compiler_tensorflow_binary_installation](url)\r\n\r\nI am following the tutorial except this step because of the lack of the file 'libtensorflow_framework.so'", "@deepin17 : I see, thanks for the update.\r\n\r\nHonestly, we don't have the bandwidth/expertise to update the documentation for compiling custom operations for Windows (and also, the `libtensorflow_framework` shared library doesn't exist there).\r\n\r\nI took the liberty to update the issue title to more closely reflect that.\r\nAnd we'd sincerely appreciate contributions from the community. Ideally, someone would chime in with a pull request to [update the instructions](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/docs_src/extend/adding_an_op.md) for Windows.\r\n\r\nMarking this as \"Contributions Welcome\" for this purpose.\r\n", "Also see https://github.com/tensorflow/models/issues/1103#issuecomment-302945787\r\n\r\n(CC @guschmue as an FYI)"]}, {"number": 19121, "title": "Fix alignment crashes in AVX512 builds", "body": "This pull request fixes alignment crashes on AVX512 builds seen when running the tensorflow unit tests.  It modifies tensorflow/core/framework/allocator.h so that kAllocatorAlignment is always 64 and sets the eigen define EIGEN_MAX_ALIGN_BYTES to 64.  It also updates some of the compiler unit tests so that they pass with these new settings.\r\n\r\nThe first patch in the PR was originally submitted by fenrus75 in https://github.com/tensorflow/tensorflow/pull/15606.\r\n\r\nFixes: https://github.com/tensorflow/tensorflow/issues/15588", "comments": ["@markdryan could you please take a look at the test failure?", "@rmlarsen I'm investigating the failures.  I have a fix for one of the failing tests, //tensorflow/core:framework_tensor_test, and will now take a look at //tensorflow/core/kernels:scoped_allocator_ops_test_gpu.  I'm travelling tomorrow, so I may not have an updated patch until later in the week.", "cc @sanjoy ", "@markdryan no problem. Ping the thread when you have fixed the tests.", "@rmlarsen I've updated the pull request with two new commits that fix the failing test cases.  Both of these test cases assumed 32 byte alignment, hence the failures.", "The  failure looks unrelated, but let's run the tests one more time.", "@markdryan Thanks!"]}, {"number": 19120, "title": "Cannot build tensorflow on arm with the latest bazel. _pywrap_tensorflow_internal.so: undefined symbol: _ZN10tensorflow9ConcatCPUINS_8bfloat16EEEvPNS_10DeviceBaseERKSt6vectorISt10unique_ptrINS_6TTypesIT_Li2EiE11ConstMatrixESt14default_deleteIS9_EESaISC_EEPNS8_6MatrixE", "body": "The system:\r\n\r\nHave I written custom code  \r\n- No\r\n\r\nOS Platform and Distribution \r\n- Ubuntu 18.04 LTS on odroid ux4\r\n- OS image is here https://wiki.odroid.com/odroid-xu4/os_images/linux/ubuntu_4.14/20180501\r\n- kernel 4.14\r\n- arm-linux-gnueabihf\r\n\r\nTensorFlow installed from\r\n- git https://github.com/tensorflow\r\n\r\nTensorFlow version\r\n- v1.8.0\r\n\r\nBazel version\r\n- bazel release 0.13.0\r\n- bazel release 0.11.0\r\n\r\nCUDA/cuDNN version\r\n- No\r\n\r\nGPU model and memory\r\n- Mali no Cuda\r\n\r\nUsing built-in specs.\r\nCOLLECT_GCC=gcc\r\nCOLLECT_LTO_WRAPPER=/usr/lib/gcc/arm-linux-gnueabihf/7/lto-wrapper\r\n\r\ngcc version 7.3.0 (Ubuntu/Linaro 7.3.0-16ubuntu3)\r\n**the same issue with gcc 4.8 and 5.5 **\r\n\r\n**Exact command to reproduce**\r\n\r\nbuild -c opt --local_resources 2024,8,1.0  --copt=\"-mcpu=cortex-a15\" --copt=\"-Ofast\"   tensorflow/tools/pip_package:build_pip_package  --action_env=\"LD_LIBRARY_PATH=${LD_LIBRARY_PATH}\" --verbose_failures\r\n\r\n```\r\nERROR: /home/jora/frameworks/tensorflow/tensorflow/tools/api/generator/BUILD:27:1: Executing genrule //tensorflow/tools/api/generator:python_api_gen failed (Exit 1): bash failed: error executing command\r\n  (cd /home/jora/.cache/bazel/_bazel_jora/7dfd049478ee24381bd18645ae9bd0df/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    LD_LIBRARY_PATH='' \\\r\n    PATH=/home/jora/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/usr/lib/jvm/java-8-oracle/bin:/usr/lib/jvm/java-8-oracle/db/bin:/usr/lib/jvm/java-8-oracle/jre/bin \\\r\n    PYTHON_BIN_PATH=/usr/bin/python3 \\\r\n    PYTHON_LIB_PATH=/usr/lib/python3/dist-packages \\\r\n    TF_DOWNLOAD_CLANG=0 \\\r\n    TF_NEED_CUDA=0 \\\r\n    TF_NEED_OPENCL_SYCL=0 \\\r\n  /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/host/bin/tensorflow/tools/api/generator/create_python_api bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/app/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/bitwise/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/compat/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/contrib/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/contrib/stat_summarizer/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/data/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/distributions/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/distributions/bijectors/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/errors/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/estimator/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/estimator/export/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/estimator/inputs/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/feature_column/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/gfile/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/graph_util/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/image/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/initializers/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/keras/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/keras/activations/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/keras/applications/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/keras/applications/densenet/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/keras/applications/inception_resnet_v2/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/keras/applications/inception_v3/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/keras/applications/mobilenet/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/keras/applications/nasnet/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/keras/applications/resnet50/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/keras/applications/vgg16/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/keras/applications/vgg19/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/keras/applications/xception/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/keras/backend/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/keras/callbacks/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/keras/constraints/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/keras/datasets/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/keras/datasets/boston_housing/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/keras/datasets/cifar10/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/keras/datasets/cifar100/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/keras/datasets/fashion_mnist/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/keras/datasets/imdb/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/keras/datasets/mnist/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/keras/datasets/reuters/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/keras/estimator/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/keras/initializers/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/keras/layers/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/keras/losses/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/keras/metrics/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/keras/models/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/keras/optimizers/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/keras/preprocessing/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/keras/preprocessing/image/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/keras/preprocessing/sequence/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/keras/preprocessing/text/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/keras/regularizers/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/keras/utils/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/keras/wrappers/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/keras/wrappers/scikit_learn/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/layers/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/linalg/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/logging/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/losses/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/manip/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/math/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/metrics/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/nn/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/nn/rnn_cell/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/profiler/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/python_io/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/resource_loader/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/saved_model/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/saved_model/builder/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/saved_model/constants/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/saved_model/loader/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/saved_model/main_op/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/saved_model/signature_constants/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/saved_model/signature_def_utils/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/saved_model/tag_constants/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/saved_model/utils/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/sets/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/spectral/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/summary/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/sysconfig/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/test/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/train/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/train/queue_runner/__init__.py bazel-out/arm-py3-opt/genfiles/tensorflow/tools/api/generator/api/user_ops/__init__.py')\r\nTraceback (most recent call last):\r\n  File \"/home/jora/.cache/bazel/_bazel_jora/7dfd049478ee24381bd18645ae9bd0df/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/tools/api/generator/create_python_api.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"/home/jora/.cache/bazel/_bazel_jora/7dfd049478ee24381bd18645ae9bd0df/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/tools/api/generator/create_python_api.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"/home/jora/.cache/bazel/_bazel_jora/7dfd049478ee24381bd18645ae9bd0df/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/tools/api/generator/create_python_api.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"/usr/lib/python3.6/imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"/usr/lib/python3.6/imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: /home/jora/.cache/bazel/_bazel_jora/7dfd049478ee24381bd18645ae9bd0df/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/tools/api/generator/create_python_api.runfiles/org_tensorflow/tensorflow/python/_pywrap_tensorflow_internal.so: undefined symbol: _ZN10tensorflow9ConcatCPUINS_8bfloat16EEEvPNS_10DeviceBaseERKSt6vectorISt10unique_ptrINS_6TTypesIT_Li2EiE11ConstMatrixESt14default_deleteIS9_EESaISC_EEPNS8_6MatrixE\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/jora/.cache/bazel/_bazel_jora/7dfd049478ee24381bd18645ae9bd0df/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/tools/api/generator/create_python_api.runfiles/org_tensorflow/tensorflow/tools/api/generator/create_python_api.py\", line 26, in <module>\r\n    from tensorflow.python.util import tf_decorator\r\n  File \"/home/jora/.cache/bazel/_bazel_jora/7dfd049478ee24381bd18645ae9bd0df/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/tools/api/generator/create_python_api.runfiles/org_tensorflow/tensorflow/python/__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"/home/jora/.cache/bazel/_bazel_jora/7dfd049478ee24381bd18645ae9bd0df/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/tools/api/generator/create_python_api.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"/home/jora/.cache/bazel/_bazel_jora/7dfd049478ee24381bd18645ae9bd0df/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/tools/api/generator/create_python_api.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"/home/jora/.cache/bazel/_bazel_jora/7dfd049478ee24381bd18645ae9bd0df/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/tools/api/generator/create_python_api.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"/home/jora/.cache/bazel/_bazel_jora/7dfd049478ee24381bd18645ae9bd0df/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/tools/api/generator/create_python_api.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"/usr/lib/python3.6/imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"/usr/lib/python3.6/imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: /home/jora/.cache/bazel/_bazel_jora/7dfd049478ee24381bd18645ae9bd0df/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/tools/api/generator/create_python_api.runfiles/org_tensorflow/tensorflow/python/_pywrap_tensorflow_internal.so: undefined symbol: _ZN10tensorflow9ConcatCPUINS_8bfloat16EEEvPNS_10DeviceBaseERKSt6vectorISt10unique_ptrINS_6TTypesIT_Li2EiE11ConstMatrixESt14default_deleteIS9_EESaISC_EEPNS8_6MatrixE\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 8968.754s, Critical Path: 2194.12s\r\nINFO: 3040 processes, local.\r\nFAILED: Build did NOT complete successfully\r\n```", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Looks like i was able to build the tensorflow 1.7.0 but when I try to import it into python3.6 i get the same error as above\r\n```\r\nPython 3.6.5 (default, Apr  1 2018, 05:46:30)\r\n[GCC 7.3.0] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"/usr/lib/python3.6/imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"/usr/lib/python3.6/imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: /usr/local/lib/python3.6/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so: undefined symbol: _ZN10tensorflow9ConcatCPUINS_8bfloat16EEEvPNS_10DeviceBaseERKSt6vectorISt10unique_ptrINS_6TTypesIT_Li2EiE11ConstMatrixESt14default_deleteIS9_EESaISC_EEPNS8_6MatrixE\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n```\r\nrunning ldd \r\n\r\n```\r\nldd /usr/local/lib/python3.6/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\r\n\tlinux-vdso.so.1 (0xbee51000)\r\n\tlibtensorflow_framework.so => /usr/local/lib/python3.6/dist-packages/tensorflow/python/../libtensorflow_framework.so (0xb4b39000)\r\n\tlibdl.so.2 => /lib/arm-linux-gnueabihf/libdl.so.2 (0xb4b0f000)\r\n\tlibpthread.so.0 => /lib/arm-linux-gnueabihf/libpthread.so.0 (0xb4aea000)\r\n\tlibm.so.6 => /lib/arm-linux-gnueabihf/libm.so.6 (0xb4a69000)\r\n\tlibstdc++.so.6 => /usr/lib/arm-linux-gnueabihf/libstdc++.so.6 (0xb4956000)\r\n\tlibgcc_s.so.1 => /lib/arm-linux-gnueabihf/libgcc_s.so.1 (0xb492d000)\r\n\tlibc.so.6 => /lib/arm-linux-gnueabihf/libc.so.6 (0xb4835000)\r\n\t/lib/ld-linux-armhf.so.3 (0xb6f51000)\r\n```", "I got the exact same error as xsolo. I am using python 2.7 though. \r\nDid you find any fix for this yet @xsolo ?", "I am also having same issue. I am building TF 1.12 with GCC 5.5, G++ 5.5, Odroid XU4, Bazel 0.15.0", "Hello All,\r\n\r\n#**Here is the FIX.**\r\n\r\n**My environment:**\r\n- Basel 0.15.2, GCC 4.8.5, G++ 4.8.5, Odroid XU4, Tensorflow Branch **r1.11** (r1.12 is latest and this should work also on that branch).\r\n\r\n**Steps**\r\n1. Clone Tensorflow\r\n2. Checkout r1.11\r\n3. Change /tensorflow/core/platform/platform.h (Error undefined symbol: appears because  of **IS_MOBILE_PLATFORM**. Remove lines with - and add with + in platform.h)\r\n--// Require an outside macro to tell us if we're building for Raspberry Pi or\r\n--// another ARM device that's not a mobile platform.\r\n--#if !defined(RASPBERRY_PI) && !defined(ARM_NON_MOBILE)\r\n--#define IS_MOBILE_PLATFORM\r\n--#endif  // !defined(RASPBERRY_PI) && !defined(ARM_NON_MOBILE)\r\n++#if defined(IS_MOBILE_PLATFORM) || defined(RASPBERRY_PI)\r\n++#error Wrong platform, stop building...\r\n++#endif\r\n4. If you are building with GCC5.5 or later **skip this step**. (GCC 4.8.5 causes @boringssl//:crypto error)\r\n    Change tensorflow/workspace.bzl to:\r\n\r\n```\r\n     tf_http_archive(\r\n         name = \"boringssl\",\r\n         urls = [        \r\n\"http://mirror.bazel.build/github.com/google/boringssl/archive/e3860009a091cd1bd2bc189cdbc3c6d095abde84.tar.gz\",\r\n# \"https://github.com/google/boringssl/archive/e3860009a091cd1bd2bc189cdbc3c6d095abde84.tar.gz\",  # 2017-07-07\r\n                 ],\r\n        sha256 = \"02f5950f93c4fd3691771c07c9d04cf2999ab01383ff99da345249e93b0fcfb2\",\r\n        strip_prefix = \"boringssl-e3860009a091cd1bd2bc189cdbc3c6d095abde84\",\r\n     )\r\n```\r\n5. Build using Bazel (Should be OK now)\r\n6. Create .whl file\r\n7. Install using (Python3 -m pip install <package_name.whl>\r\n\r\n------------------\r\n\r\n**Output from my device:**\r\n\r\n```\r\nodroid@odroid:~$ python3\r\nPython 3.6.7 (default, Oct 22 2018, 11:32:17) \r\n[GCC 8.2.0] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\n>>> tf.__version__\r\n'1.11.0'\r\n>>>\r\n``` \r\n", "The above worked for me! \r\n\r\n<pre>IS_MOBILE_PLATFORM. Remove lines with - and add with + in platform.h)\r\n--// Require an outside macro to tell us if we're building for Raspberry Pi or\r\n--// another ARM device that's not a mobile platform.\r\n--#if !defined(RASPBERRY_PI) && !defined(ARM_NON_MOBILE)\r\n--#define IS_MOBILE_PLATFORM\r\n--#endif // !defined(RASPBERRY_PI) && !defined(ARM_NON_MOBILE)\r\n++#if defined(IS_MOBILE_PLATFORM) || defined(RASPBERRY_PI)\r\n++#error Wrong platform, stop building...\r\n++#endif\r\n</pre>", "Hi All,\r\nI have written the installation guide for Odroid. Please check **STABLE SECTION**. We don't need to build because official binary is available with Tensorflow.\r\n\r\nhttps://github.com/Kishwar/tensorflow/tree/master/odroid-xu4", "Hi all,\r\n\r\nhere you can find my version of tensorflow (1.14.1/2.0.1) for odroid xu4 running Ubuntu 18.04 and using openmpi libraries.\r\n\r\nhttps://github.com/gmrandazzo/TOO\r\n\r\nEnjoy\r\nP.S.: builds were made directly on odroid xu4.", "Hi @xsolo! \r\nIt seems you are using older versions(1.x versions) of Tensorflow. Have you checked this issue in [Latest versions ](https://www.tensorflow.org/install/source_windows)(TF 2.6/27 yet) ? Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 19119, "title": "Cannot build tensorflow on Windows 10 CUDA", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: 1.8 or master ( tried both)\r\n- **Python version**: 3.6.4\r\n- **Bazel version (if compiling from source)**: 0.13.0\r\n- **Cmake version (if compiling from source)**: 3.10.1\r\n- **CUDA/cuDNN version**: 9.1/7.1\r\n- **GPU model and memory**: GTX 1080 Ti\r\n- **Exact command to reproduce**: \r\ncmake -T host=x64 -DCMAKE_BUILD_TYPE=Release -DSWIG_EXECUTABLE=c:/swigwin-3.0.12/swig.exe -Dtensorflow_ENABLE_GPU=ON -Dtensorflow_CUDA_VERSION=9.1 -Dtensorflow_CUDNN_VERSION=7.1 -DCUDNN_HOME=\"C:\\cudnn-9.1-windows10-x64-v7.1\\cuda\" ..\r\n\r\nNotes: -DCUDNN_HOME line could be skipped since it is already installed inside cuda 9.1 folder but tried different ones too\r\n\r\nMSBuild /p:Configuration=Release /verbosity:detailed tf_python_build_pip_package.vcxproj\r\n\r\nBuild fails, I suppose warnings are fine, but what am I missing?\r\nI need to build tensorflow because my CPU doesn't use AVX instructions (Intel Xeon 5670) and since I want to use GPU for this I only want to focus on CUDA build.\r\n\r\nI have also tried with bazel:\r\n````\r\n$ ./configure\r\nYou have bazel 0.13.0 installed.\r\nPlease specify the location of python. [Default is D:\\Miniconda3\\python.exe]:\r\n\r\n\r\nFound possible Python library paths:\r\n  D:\\Miniconda3\\lib\\site-packages\r\nPlease input the desired Python library path to use.  Default is [D:\\Miniconda3\\                               lib\\site-packages]\r\n\r\nDo you wish to build TensorFlow with XLA JIT support? [y/N]:\r\nNo XLA JIT support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with GDR support? [y/N]:\r\nNo GDR support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with VERBS support? [y/N]:\r\nNo VERBS support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with CUDA support? [y/N]: y\r\nCUDA support will be enabled for TensorFlow.\r\n\r\nPlease specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to d                               efault to CUDA 9.0]: 9.1\r\n\r\n\r\nPlease specify the location where CUDA 9.1 toolkit is installed. Refer to README                               .md for more details. [Default is C:/Program Files/NVIDIA GPU Computing Toolkit/                               CUDA/v9.1]:\r\n\r\n\r\nPlease specify the cuDNN version you want to use. [Leave empty to default to cuD                               NN 7.0]: 7.1\r\n\r\n\r\nPlease specify the location where cuDNN 7 library is installed. Refer to README.                               md for more details. [Default is C:/Program Files/NVIDIA GPU Computing Toolkit/C                               UDA/v9.1]:\r\n\r\n\r\nPlease specify a list of comma-separated Cuda compute capabilities you want to b                               uild with.\r\nYou can find the compute capability of your device at: https://developer.nvidia.                               com/cuda-gpus.\r\nPlease note that each additional compute capability significantly increases your                                build time and binary size. [Default is: 3.5,5.2]6.1\r\n\r\n\r\nDo you wish to build TensorFlow with MPI support? [y/N]:\r\nNo MPI support will be enabled for TensorFlow.\r\n\r\nPlease specify optimization flags to use during compilation when bazel option \"-                               -config=opt\" is specified [Default is /arch:AVX]:\r\n\r\n\r\nWould you like to interactively configure ./WORKSPACE for Android builds? [y/N]:                               \r\nNot configuring the WORKSPACE for Android builds.\r\n\r\nPreconfigured Bazel build configs. You can use any of the below by adding \"--con                               fig=<>\" to your build command. See tools/bazel.rc for more details.\r\n        --config=mkl            # Build with MKL support.\r\n        --config=monolithic     # Config for mostly static monolithic build.\r\nConfiguration finished\r\n\r\natro@atro-PC MINGW64 /c/tensorflow (master)\r\n$\r\n\r\natro@atro-PC MINGW64 /c/tensorflow (master)\r\n$ bazel build --config=opt --config=win-cuda //tensorflow/tools/pip_package:buil                               d_pip_package\r\nStarting local Bazel server and connecting to it...\r\n.................\r\nWARNING: The following configs were expanded more than once: [win-cuda]. For rep                               eatable flags, repeats are counted twice and may lead to unexpected behavior.\r\nLoading:\r\nLoading: 0 packages loaded\r\nLoading: 0 packages loaded\r\n    currently loading: tensorflow/tools/pip_package\r\nAnalyzing: target //tensorflow/tools/pip_package:build_pip_package (1 packages l                               oaded)\r\nWARNING: C:/users/atro/_bazel_atro/x1e5egqw/external/protobuf_archive/WORKSPACE:                               1: Workspace name in C:/users/atro/_bazel_atro/x1e5egqw/external/protobuf_archiv                               e/WORKSPACE (@com_google_protobuf) does not match the name given in the reposito                               ry's definition (@protobuf_archive); this will cause a build error in future ver                               sions\r\nWARNING: C:/users/atro/_bazel_atro/x1e5egqw/external/grpc/WORKSPACE:1: Workspace                                name in C:/users/atro/_bazel_atro/x1e5egqw/external/grpc/WORKSPACE (@com_github                               _grpc_grpc) does not match the name given in the repository's definition (@grpc)                               ; this will cause a build error in future versions\r\nWARNING: C:/users/atro/_bazel_atro/x1e5egqw/external/absl_py/WORKSPACE:1: Worksp                               ace name in C:/users/atro/_bazel_atro/x1e5egqw/external/absl_py/WORKSPACE (@io_a                               bseil_py) does not match the name given in the repository's definition (@absl_py                               ); this will cause a build error in future versions\r\nAnalyzing: target //tensorflow/tools/pip_package:build_pip_package (76 packages                                loaded)\r\nAnalyzing: target //tensorflow/tools/pip_package:build_pip_package (124 packages                                loaded)\r\nWARNING: C:/users/atro/_bazel_atro/x1e5egqw/external/grpc/BUILD:1960:1: in srcs                                attribute of cc_library rule @grpc//:grpc_nanopb: please do not import '@grpc//t                               hird_party/nanopb:pb_common.c' directly. You should either move the file to this                                package or depend on an appropriate rule there. Since this rule was created by                                the macro 'grpc_generate_one_off_targets', the error might have been caused by t                               he macro implementation in C:/users/atro/_bazel_atro/x1e5egqw/external/grpc/baze                               l/grpc_build_system.bzl:172:12\r\nWARNING: C:/users/atro/_bazel_atro/x1e5egqw/external/grpc/BUILD:1960:1: in srcs                                attribute of cc_library rule @grpc//:grpc_nanopb: please do not import '@grpc//t                               hird_party/nanopb:pb_decode.c' directly. You should either move the file to this                                package or depend on an appropriate rule there. Since this rule was created by                                the macro 'grpc_generate_one_off_targets', the error might have been caused by t                               he macro implementation in C:/users/atro/_bazel_atro/x1e5egqw/external/grpc/baze                               l/grpc_build_system.bzl:172:12\r\nWARNING: C:/users/atro/_bazel_atro/x1e5egqw/external/grpc/BUILD:1960:1: in srcs                                attribute of cc_library rule @grpc//:grpc_nanopb: please do not import '@grpc//t                               hird_party/nanopb:pb_encode.c' directly. You should either move the file to this                                package or depend on an appropriate rule there. Since this rule was created by                                the macro 'grpc_generate_one_off_targets', the error might have been caused by t                               he macro implementation in C:/users/atro/_bazel_atro/x1e5egqw/external/grpc/baze                               l/grpc_build_system.bzl:172:12\r\nAnalyzing: target //tensorflow/tools/pip_package:build_pip_package (134 packages                                loaded)\r\nAnalyzing: target //tensorflow/tools/pip_package:build_pip_package (145 packages                                loaded)\r\nAnalyzing: target //tensorflow/tools/pip_package:build_pip_package (149 packages                                loaded)\r\nAnalyzing: target //tensorflow/tools/pip_package:build_pip_package (160 packages                                loaded)\r\nWARNING: C:/tensorflow/tensorflow/contrib/learn/BUILD:17:1: in py_library rule /                               /tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depen                               ds on deprecated target '//tensorflow/contrib/session_bundle:exporter': No longe                               r supported. Switch to SavedModel immediately.\r\nWARNING: C:/tensorflow/tensorflow/contrib/learn/BUILD:17:1: in py_library rule /                               /tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depen                               ds on deprecated target '//tensorflow/contrib/session_bundle:gc': No longer supp                               orted. Switch to SavedModel immediately.\r\nAnalyzing: target //tensorflow/tools/pip_package:build_pip_package (256 packages                                loaded)\r\nINFO: Analysed target //tensorflow/tools/pip_package:build_pip_package (257 pack                               ages loaded).\r\nINFO: Found 1 target...\r\nBuilding: no action\r\n[2 / 19] [-----] BazelWorkspaceStatusAction stable-status.txt\r\nERROR: C:/tensorflow/tensorflow/core/BUILD:1800:1: C++ compilation of rule '//tensorflow/core:lib_hash_crc32c_accelerate_internal' failed (Exit 2): cl.exe failed: error executing command\r\n  cd C:/users/atro/_bazel_atro/x1e5egqw/execroot/org_tensorflow\r\n  SET INCLUDE=C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.15063.0\\ucrt;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.6.1\\include\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.15063.0\\shared;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.15063.0\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.15063.0\\winrt;\r\n    SET LIB=C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\LIB\\amd64;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\ATLMFC\\LIB\\amd64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.15063.0\\ucrt\\x64;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.6.1\\lib\\um\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.15063.0\\um\\x64;\r\n    SET PATH=C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\amd64;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\VCPackages;C:\\WINDOWS\\Microsoft.NET\\Framework64\\v4.0.30319;C:\\WINDOWS\\Microsoft.NET\\Framework64\\;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\x86;C:\\Program Files (x86)\\Microsoft SDKs\\Windows\\v10.0A\\bin\\NETFX 4.6.1 Tools\\x64\\;;C:\\WINDOWS\\system32\r\n    SET PWD=/proc/self/cwd\r\n    SET TEMP=C:\\Users\\atro\\AppData\\Local\\Temp\r\n    SET TMP=C:\\Users\\atro\\AppData\\Local\\Temp\r\n  C:/Program Files (x86)/Microsoft Visual Studio 14.0/VC/bin/amd64/cl.exe /c tensorflow/core/lib/hash/crc32c_accelerate.cc /Fobazel-out/host/bin/tensorflow/core/_objs/lib_hash_crc32c_accelerate_internal/tensorflow/core/lib/hash/crc32c_accelerate.o /nologo /DCOMPILER_MSVC /DNOMINMAX /D_WIN32_WINNT=0x0600 /D_CRT_SECURE_NO_DEPRECATE /D_CRT_SECURE_NO_WARNINGS /D_SILENCE_STDEXT_HASH_DEPRECATION_WARNINGS /bigobj /Zm500 /J /Gy /GF /EHsc /wd4351 /wd4291 /wd4250 /wd4996 /I. /Ibazel-out/host/genfiles /Iexternal/bazel_tools /Ibazel-out/host/genfiles/external/bazel_tools /showIncludes /MD /O2 /DNDEBUG -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -w -DGOOGLE_CUDA=1 -DTENSORFLOW_MONOLITHIC_BUILD /DPLATFORM_WINDOWS /DEIGEN_HAS_C99_MATH /DTENSORFLOW_USE_EIGEN_THREADPOOL /DEIGEN_AVOID_STL_ARRAY /Iexternal/gemmlowp /wd4018 /U_HAS_EXCEPTIONS /D_HAS_EXCEPTIONS=1 /EHsc /DNOGDI /DTF_COMPILE_LIBRARY\r\ntensorflow/core/lib/hash/crc32c_accelerate.cc(16): fatal error C1083: Cannot open include file: 'stddef.h': No such file or directory\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 20.360s, Critical Path: 0.32s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully\r\n````\r\n\r\n### Source code / logs\r\nAttached is the complete msbuild log. \r\n[msbuild.zip](https://github.com/tensorflow/tensorflow/files/1978158/msbuild.zip)\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nBazel version", "Of course", "@mrry can you take a look?\r\n\r\nfatal error C1083: Cannot open include file: 'stddef.h' seems to be the error line.\r\nThe CPU doesn't have AVX though. Does that matter?", "Nagging Assignee @mrry: It has been 95 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 19118, "title": "Update zlib version for cmake build", "body": "In cmake build, the zlib version was `50893291621658f355bc5b4d450a8d06a563053d`\r\nwhich is equal to v1.2.8. This creates a discrepancy between cmake and bazel build.\r\n\r\nThis fix updates the zlib version to v1.2.11 that syncs with bazel build.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": []}, {"number": 19117, "title": "[tfgan] Add discriminator and generator losses to estimator eval_metrics", "body": "This PR adds discriminator and generator losses to estimator `eval_metrics`.\r\n\r\nI used the same approach as done for [canned estimators](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/estimator/canned/head.py#L634-L661) though I'm not entirely sure if the `name_scope` is correctly used in this case.", "comments": ["@rmlarsen Thanks for approving the change! \ud83c\udf89\r\nThough it looks like there's something wrong with the [Windows CMake build](https://source.cloud.google.com/results/invocations/6891f1d5-4124-4f47-a284-13cc266c4756/targets). I also cannot access any logs to figure out why the build is failing but it seems unrelated to this PR.", "@lgeiger Thanks for the contribution. Yes, the Windows build failure is unrelated."]}, {"number": 19116, "title": "Fix doc format issue in enable_eager_execution", "body": "This fix tries to address the issue raised in #19022 where the doc of `tf.enable_eager_execution` was not well formatted. It seems the additional empty lines may confuse the doc generator. This fix fixes with proper alignment and removal of empty lines.\r\n\r\nThis fix fixes #19022.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": []}, {"number": 19115, "title": "[Example Request]: Add seq2seq in eager examples", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: NA\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: NA\r\n- **TensorFlow installed from (source or binary)**: NA\r\n- **TensorFlow version (use command below)**: NA\r\n- **Python version**:  NA\r\n- **Bazel version (if compiling from source)**: NA\r\n- **GCC/Compiler version (if compiling from source)**: NA\r\n- **CUDA/cuDNN version**: NA\r\n- **GPU model and memory**: NA\r\n- **Exact command to reproduce**: NA\r\n\r\nexisting tf.contrib.seq2seq in not compatible with eager mode. Can you add a seq2seq example with the eager mode? Something similar to [this](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html). ", "comments": ["Nagging Assignee @bignamehyp: It has been 17 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @bignamehyp: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "It's a contrib project. \r\nPlease contact the original author of seq2seq @alrojo "]}, {"number": 19114, "title": "Add support to identify elements in tensors", "body": "Problem description:\r\nI want to create symmetric matrix, which contains only n(n + 1) / 2 trainable parameters.\r\nIn general case i want to create tensor, where some elements are the same as trainable parameters.\r\nWhy is it so important?\r\n1) PointNet article about 3D point cloud classification: contains symmetric matrices for estimation\r\n2) Symmetric differential equations\r\n2) Completeness of framework as a tool for optimization tasks\r\n\r\nOne possible way to do it is to stack and concatenate different variables, but i think, low level possibility of this feature has a better perfomance\r\n\r\nSorry for my English.", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "It has been 19 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Yes", "Nagging Assignee @cy89: It has been 15 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @cy89: It has been 30 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "@DELTA37 does this StackOverflow link help: https://stackoverflow.com/questions/46718356/tensorflow-symmetric-matrix", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Ok, thank you"]}, {"number": 19113, "title": "[AdamOptimizer]Failed precondition: Attempting to use uninitialized value model_2/beta1_power", "body": "### System information\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu\r\n- **TensorFlow version (use command below)**: r1.3\r\n- **Python version**: 3.6\r\n\r\n### Describe the problem\r\nI write a model class that use a AdamOptimizer to update the parameters. It is a joint model so that there are two losses. It works well as I update all the parameters by the joint loss. But then I want to updated a subset of parameters by each of the loss respectively, that is , I had to call the apply_gradients() **twice**, it raised errors when I restore the model from .ckpt file: 'Failed precondition: Attempting to use uninitialized value model_2/beta1_power'.\r\n\r\n\r\n### Source code / logs\r\nThis is the original source code when I update the model with the whole loss.\r\n\r\n\t\ttaggingloss = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(labels = self.tag, logits = self.tagginglogits))\r\n\t\tclassifyloss = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(labels = self.label, logits = self.logits))\r\n\t\tself.loss = (1 - alpha) * classifyloss + alpha * taggingloss\r\n\t\t# Gradients\r\n\t\tparams = tf.trainable_variables()\r\n\t\topt = tf.train.AdamOptimizer(learning_rate = self.learning_rate)\r\n\t\tgradient = tf.gradients(self.loss, params)\r\n\t\tclipped_gradients, norm = tf.clip_by_global_norm(gradient, max_gradient_norm)\r\n\t\tself.gradient_norm = norm\r\n\t\tself.update = opt.apply_gradients(zip(clipped_gradients, params), global_step = self.global_step)\r\n\t\tsave_list = params\r\n\t\tsave_list.append(self.global_step)\r\n\t\tself.saver = tf.train.Saver(save_list)\r\n\r\nthen I  revised it into:\r\n\r\n\t\t# Gradients\r\n\t\tparams = tf.trainable_variables()\r\n\t\topt = tf.train.AdamOptimizer(learning_rate = self.learning_rate)\r\n\t\ttag_gradient = tf.gradients(taggingloss, params)\r\n\t\ttag_clipped_gradients, tag_norm = tf.clip_by_global_norm(tag_gradient, max_gradient_norm)\r\n\t\tself.tag_gradient_norm = tag_norm\r\n\t\tself.tag_update = opt.apply_gradients(zip(tag_clipped_gradients, params), global_step = self.global_step)\r\n\t\t\r\n\t\tclassify_gradient = tf.gradients(classifyloss, params)\r\n\t\tclassify_clipped_gradients, classify_norm = tf.clip_by_global_norm(classify_gradient, max_gradient_norm)\r\n\t\tself.classify_gradient_norm = classify_norm\r\n\t\tself.classify_update = opt.apply_gradients(zip(classify_clipped_gradients, params), global_step = self.global_step)\r\n\r\n\t\tsave_list = tf.trainable_variables()\r\n\t\tsave_list.append(self.global_step)\r\n\t\tself.saver = tf.train.Saver(save_list)\r\n\r\nThe rest are all the same, except that, I used to run the self.update operation in the train() call. Now I first run self.tag_update in the tagging() call and then run self.classify_update in the train() call.\r\n\r\nI have read the closed issue of https://github.com/tensorflow/tensorflow/issues/8057. it said in it that \r\n\r\n> I understood here such a thing: variables beta1_power and beta2_power are specific to each call to apply_gradients, but not to the whole graph. So if we want to call apply_gradients twice, two separate pairs of beta accumulators should be created, even if both calls are made within the single graph. This does not fit into the concept of \"graph slots\". Definitely, we should separate these slots by graphs, but we cannot simply key these slots by graphs only.\r\n\r\nBut I still have no idea how ti fix it.", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nTensorFlow installed from\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Could you create two optimizers for each loss?  At first calculate gradients, and then apply gradient to ops by each optimizer. Would it work for you?", "@estelll did that suggestion work for you?", "@michaelisard I did not try this method.  Now it works but I forget what I have done to the code!!!!!! OMG..it is embarrassing...\ud83d\ude13\ud83d\ude13"]}, {"number": 19112, "title": "Feeding to a list of placeholders leads to the same values for the whole list placeholders", "body": "Maybe it is not a bug, correct me if I misunderstand somewhere\r\n\r\nHere's my code:\r\n\r\n```\r\nwith tf.Graph().as_default():\r\n    list_placeholder = [tf.placeholder(dtype=tf.int32, shape=[2])] * 3\r\n    with tf.Session(config=config) as sess:\r\n        real_values = sess.run(list_placeholder, feed_dict={\r\n            list_placeholder[0]: [0, 0],\r\n            list_placeholder[1]: [1, 1],\r\n            list_placeholder[2]: [2, 2],\r\n        })\r\n        print(real_values)\r\n```\r\n\r\nIt hopefully prints out something like `[0,0], [1,1], [2,2]`, because `list_placeholders` contain 3 separate elements. The actual output is:\r\n`[array([2, 2], dtype=int32), array([2, 2], dtype=int32), array([2, 2], dtype=int32)]`\r\n\r\nSome specs of system:\r\n* Ubuntu 16.04\r\n* I encountered this issue on both python 2.7 and python 3.6\r\n* Tensorflow version: 1.4.1\r\n", "comments": ["It due to behavior of python.\r\n```x=[object] * 3``` actually creates a list of 3 ref to 1 object\r\n"]}, {"number": 19111, "title": "[tfgan] Simplify estimator gan_model_fn", "body": "This removes `_make_train_gan_model` and `_make_eval_gan_model` which are just calling `_make_gan_model` with the correct mode variable.\r\nInstead `_make_gan_model` is used directly to create both training and evaluation models.\r\n\r\nFurthermore the PR remove an outdated `TODO` which was resolved in #14723", "comments": ["Nagging Assignee @protoget: It has been 20 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @protoget: It has been 35 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "@joel-shor I removed your `TODO` comment which was resolved in #14723.\r\nCould you take a quick look at this?", "Nagging Assignee @protoget: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Closing in favor of https://github.com/tensorflow/tensorflow/commit/47dea684efa41981e10299c2737317c504ce41af#diff-996659185d809b9af814681a66df538b"]}, {"number": 19110, "title": "Add to documentation: how to install Tensorflow Lite onto Raspberry Pi 3B+ Raspian Stretch", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nNo.\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nRaspberry Pi 3B+, Raspian Stretch\r\n- **TensorFlow installed from (source or binary)**:\r\nWhat I'm asking about. \r\n- **TensorFlow version (use command below)**:\r\nTensorflow Version 1.7.0\r\n- **Python version**: \r\nPython 3.5\r\n- **Bazel version (if compiling from source)**:\r\nWhat I'm asking about. \r\n- **GCC/Compiler version (if compiling from source)**:\r\nWhat I'm asking about. \r\n- **CUDA/cuDNN version**:\r\nN/A\r\n- **GPU model and memory**:\r\nBroadcom VideoCore IV @ 250 MHz (BCM2837: 3D part of GPU @ 300 MHz, video part of GPU @ 400 MHz)\r\n- **Exact command to reproduce**:\r\nAddition to documentation: Installation of Tensorflow Lite on Raspberry Pi 3B+ Raspian Stretch. \r\n\r\n### Describe the problem\r\nI would like instructions on how to install Tensorflow Lite onto Raspberry Pi 3B+ with Raspbian Stretch OS. To the best of my knowledge, the documentation doesn't yet cover installation for Raspbian Stretch. I posted on the Raspberry Pi Stack Exchange (https://raspberrypi.stackexchange.com/questions/83498/how-do-i-install-tensorflow-lite-on-raspbian-stretch) and I was directed here. My goal is to deploy a Tensorflow neural network onto the Raspberry Pi 3B+ with Tensorflow Lite. ", "comments": ["I\u2019ve got a project using the tf nightly for Pi, thanks for that, with the Object Detection API but inference time is ~1.5 secs; I expect that I could use tf lite instead and experience significantly better performance.  Any ETA for RPi support?", "Nagging Assignee @petewarden: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @petewarden: It has been 29 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @petewarden: It has been 44 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @petewarden: It has been 59 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Resolved with nightly. For latency issue, please use quantized model, which is fast. @achowdhery.", "@tofulawrence @petewarden @achowdhery \r\nThank you!", "Documentation is here: https://www.tensorflow.org/lite/guide/build_rpi"]}, {"number": 19109, "title": "IOError: [Errno 21] Is a directory: '/tmp/speech_dataset/'", "body": "I'm following the speech recognition tutorial from TensorFlow, and when I'm running the following command, which downloads the dataset provided by TensorFlow, it runs perfectly.\r\n\r\n`python tensorflow/examples/speech_commands/train.py`\r\n\r\nHowever, when I'm changing the defaults, so that it points to my dataset, it throws the following error:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/users2/lmn/.local/lib/python2.7/site-packages/tensorflow/examples/speech_commands/train.py\", line 428, in <module>\r\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n  File \"/home/users2/lmn/.local/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 126, in run\r\n    _sys.exit(main(argv))\r\n  File \"/home/users2/lmn/.local/lib/python2.7/site-packages/tensorflow/examples/speech_commands/train.py\", line 106, in main\r\n    FLAGS.testing_percentage, model_settings)\r\n  File \"/home/users2/lmn/.local/lib/python2.7/site-packages/tensorflow/examples/speech_commands/input_data.py\", line 158, in __init__\r\n    self.maybe_download_and_extract_dataset(data_url, data_dir)\r\n  File \"/home/users2/lmn/.local/lib/python2.7/site-packages/tensorflow/examples/speech_commands/input_data.py\", line 204, in maybe_download_and_extract_dataset\r\n    tarfile.open(filepath, 'r:gz').extractall(dest_directory)\r\n  File \"/usr/lib64/python2.7/tarfile.py\", line 1693, in open\r\n    return func(name, filemode, fileobj, **kwargs)\r\n  File \"/usr/lib64/python2.7/tarfile.py\", line 1740, in gzopen\r\n    fileobj = gzip.GzipFile(name, mode, compresslevel, fileobj)\r\n  File \"/usr/lib64/python2.7/gzip.py\", line 94, in __init__\r\n    fileobj = self.myfileobj = __builtin__.open(filename, mode or 'rb')\r\nIOError: [Errno 21] Is a directory: '/tmp/speech_dataset/' \r\n\r\nThe command I'm running is:\r\n`python tensorflow/examples/speech_commands/train.py --data_url=path/to/data/ --sample_rate=20000 --wanted_words=one,two,three,four,five,six,seven,eight,nine`\r\n```\r\n\r\nNow, the error says that '/tmp/speech_dataset/' is a directory, but it is expecting a file, I guess. When I looked at `train.py` file, found the following code:\r\n\r\n```\r\nparser.add_argument(\r\n      '--data_dir',\r\n      type=str,\r\n      default='/tmp/speech_dataset/',\r\n      help=\"\"\"\\\r\n      Where to download the speech training data to.\r\n      \"\"\")\r\n```\r\nThe `--data-dir `argument defines where the files from the downloaded dataset should be stored. However, I'm not changing that argument at all, nor does the code need to save any data, since I already have the data on my computer, where I define them at `--data-url` argument. It seems to me that this is a bug in the code.\r\n\r\nDoes anyone has experience with speech recognition on TensorFlow and know where the problem might be?", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Did you try using `--data_dir` instead of `--data_url`? The docs in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/speech_commands/train.py show use of the `--data_dir` flag when using your own local data.\r\n\r\nThe stack trace reveals that Python is trying to use gzip to unpack the directory you specified in `--data_url`, because it wants to download and unarchive it.", "Hey @angersson! Thank you for your reply! The problem was there. I tried also` --data_dir ` but didn't work first, until I inspected the code and found out that when using a custom data set, one should use `--data_dir`, but in addition explicitly set the` --data_url `to the empty string."]}, {"number": 19107, "title": "[INTEL MKL] Fix for crash in mkl_layout_pass_test", "body": "This PR fixes the failure of the test //tensorflow/core:graph_mkl_layout_pass_test ", "comments": []}]