[{"number": 34887, "title": "Add info about TF_DETERMINISTIC_OPS to version 2.1 release notes", "body": "**This pull request is specifically targeted at the r2.1 branch.**\r\n\r\nThis adds information about the environment variable `TF_DETERMINISTIC_OPS`, which is first introduced in version 2.1, to the associated release notes.\r\n\r\nFor more information, see [PR 31465](https://github.com/tensorflow/tensorflow/pull/31465) that implemented this functionality.", "comments": ["I'm not familiar with this, @chsigg @sanjoy could you help to take a look?"]}, {"number": 34886, "title": "ValueError: Received a scalar value '512' as shape; require a statically known scalar with value '-1' to describe an unknown shape.", "body": "**System information**\r\n- OS Platform and Distribution: Linux Ubuntu 16.04\r\n- TensorFlow installed from :pip\r\n- TensorFlow version : 1.3\r\n- Python version: 2.7\r\n\r\n\r\n**Code to reproduce the issue**\r\n    stfts = tf.signal.rfft(frames, fft_length=512)\r\n\r\nTraceback (most recent call last):\r\n  File \"pre_process_1.py\", line 264, in <module>    feature_2,wav_lens_1,wav_lens,waveforms_0,waveforms_1,waveforms_2,waveforms,frames,stfts,stft_lens,masks = extract_features_tf(feature_1,target_sample_rate=16000)\r\n  File \"pre_process_1.py\", line 86, in extract_features_tf    filter_banks_1,wav_lens_1,wav_lens,waveforms_0,waveforms_1,waveforms_2,waveforms,frames,stfts,stft_lens,masks = common_audio_tf.compute_mel_filterbank_features(signal, sample_rate=target_sample_rate,dither=0.0, frame_length=25, window_fn=None, lower_edge_hertz=0.0, upper_edge_hertz=8000.0, num_mel_bins=64)\r\n  File \"/home/fan/anaconda3/envs/tf_asr/lib/python2.7/site-packages/tensor2tensor/layers/common_audio_tf.py\", line 130, in compute_mel_filterbank_features\r\n    stfts = tf.signal.rfft(frames, fft_length=512)\r\n  File \"/home/fan/anaconda3/envs/tf_asr/lib/python2.7/site-packages/tensorflow/python/ops/signal/fft_ops.py\", line 123, in _rfft\r\n    input_tensor = _maybe_pad_for_rfft(input_tensor, fft_rank, fft_length)\r\n  File \"/home/fan/anaconda3/envs/tf_asr/lib/python2.7/site-packages/tensorflow/python/ops/signal/fft_ops.py\", line 64, in _maybe_pad_for_rfft\r\n    fft_shape = _tensor_util.constant_value_as_shape(fft_length)\r\n  File \"/home/fan/anaconda3/envs/tf_asr/lib/python2.7/site-packages/tensorflow/python/framework/tensor_util.py\", line 888, in constant_value_as_shape\r\n    \"scalar with value '-1' to describe an unknown shape.\" % value)\r\nValueError: Received a scalar value '512' as shape; require a statically known scalar with value '-1' to describe an unknown shape.\r\n\r\n\r\n", "comments": []}, {"number": 34885, "title": "Make nccl bindings compilable with cuda 10.2", "body": "This PR fixes the bazel NCCL bindings and enables TF compilation with cuda 10.2 or later.", "comments": ["@gunan please assign appropriately if you are not the right person. Thanks.", "Might be off topic, but is there any plan to upgrade NCCL that bundled with TF? I saw 2.5.x released a couple of days ago.", "I remember discussing this with @bmzhao earlier this week, but we were not able to get to this.\r\nThank you very much for the fix!", "@gunan Would it be possible to uplift this PR to the r2.1 branch? It would be great if TF 2.1.0 could ship with CUDA 10.2 support.", "@goldiegadde please see https://github.com/tensorflow/tensorflow/pull/34885#issuecomment-563343281", "Any news?"]}, {"number": 34884, "title": "add usage examples", "body": "added usage examples for tf.image.rgb_to_grayscale and tf.image.grayscale_to_rgb", "comments": ["@alextp @mihaimaruseac I made the requested changes. Thanks!", "I think @alextp also wanted you to print the value of `converted`, basically to make this a [Python doctest](https://docs.python.org/2/library/doctest.html). See for example https://github.com/tensorflow/tensorflow/blob/f70c46f8cd2a91b390455827cda65b5b5fe92ef0/tensorflow/python/framework/ops.py#L446-L468", "Would you like me to also add `print(converted)` as @mihaimaruseac suggested? When doing that, however, I get an output such as `Tensor(\"grayscale_to_rgb_53:0\", shape=(1, 3, 3), dtype=float32)` but the two digits after the underscore (\"53\" in this case) changes each run.", "We can print only the shape. See the doctest example in https://github.com/tensorflow/tensorflow/blob/f70c46f8cd2a91b390455827cda65b5b5fe92ef0/tensorflow/python/framework/ops.py#L446-L468", "@mihaimaruseac thanks for the information, pushed the fix.", "One more thing: `>>>` should be followed by a space", "Ok, I updated that in the PR. Thanks.", "No problem, pushed with the fix again. :)", "@WilliamHYZhang Could you please address Ubuntu Sanity errors? Thanks!", "Hm, that's odd. When I run the example in Google Colab (https://colab.research.google.com/drive/1S2g8mhOj-RZDmc3JvJW7FQqM-_ds4a6V), no error returns. What can I do to address these errors in Ubuntu Sanity?", "I don't understand why the log is not visible, let's try running the test again.\r\n\r\nIn the meanwhile, can you check with pylint if the code doesn't result in formatting errors?", "Probably you have to move the doctest before the `Args:` section, not after `Returns:`", "Ok, pushed again. I moved the doctests like you suggested, thanks!", "@mihaimaruseac thank you for the suggestion, I pushed the update.", "Oh man, seems like the Ubuntu CPU test is failing again. Checked the status and seems like it returns ```[[[1.8149]]]``` instead of the expected ```array([[[1.8149]]], dtype=float32)```. Updated fix to reflect that. Also, it looks like it also was expecting the final ``` in the return as well, so I added a newline to hopefully fix that as well.", "CPU test failed again :(\r\nSeems like it didn't return the commas in the np array for grayscale_to_rgb, just pushed to fix that. @alextp Is 4 decimal places of precision too much? Should I change that line to [[[1.81...]]], I don't know if that's syntactically correct. Thanks ", "Yes, please convert to `[[[1.81...]` as `...` in doctest mean \"don't try to match after this\". \r\n\r\nSorry it's taking so long and so many review rounds", "All tests now passing besides ```import/copybara \u2014 An error happened while migrating the change```, what does this mean?", "Let's try it again. I think it's an internal error.", "Strange, the import/copybara error seems to be still happening. ", "@mihaimaruseac Shall I maybe refork the repo and create a new PR for this?", "No need to. There is an error on our side, there are people looking into it.\r\n\r\nSorry it's taking so long and sorry I couldn't respond earlier"]}, {"number": 34883, "title": "[r2.1:Cherrypick] Include build_config.bzl in Tensorflow 2.1 rc", "body": "This cherrypick adds indispensable dependency in Tensorflow 2.1, for Tensorflow Serving 2.1 release. \r\n-----\r\nThis is just the redirection point. Changing to make use of it is coming in\r\nanother CL.\r\n\r\nPiperOrigin-RevId: 282425960\r\nChange-Id: I5b12fe759e58e408246d31a8de83406dc93e1852\r\n\r\n", "comments": []}, {"number": 34882, "title": "Horizontal fusion", "body": "Horizontally fuse (independent) computations after vertical fusion is done. It helps reduces kernel launch overhead while increasing kernels launch dims (and hence parallelism). I observed around 0-5% performance gains on various models.\r\n\r\nNote that this PR depends on functionality of a previous one:\r\nhttps://github.com/tensorflow/tensorflow/pull/34880\r\n\r\n\r\n", "comments": ["@trentlo Can you please resolve conflicts? Thanks!", "\r\nThe error message appears not related to the PR. Could we run the regression test again?\r\n\r\n`4 errors detected in the compilation of \"T:/tmp/nvcc_inter_files_tmp_dir/tmp79b9es58/debug_ops_gpu.cu.compute_70.cpp1.ii\".`", "\r\nOne previous failure is gone. The error messages in the remaining failure are all about download failures. See below for example. Would you mind running the regression test again? @gbaned \r\n\r\n```\r\nWARNING: Download from https://storage.googleapis.com/mirror.tensorflow.org/github.com/google/pasta/archive/v0.1.8.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found\r\nWARNING: Download from https://storage.googleapis.com/mirror.tensorflow.org/github.com/googleapis/google-cloud-cpp/archive/v0.16.0.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found\r\n\r\n```\r\n", "@trentlo Can you please address Ubuntu Sanity errors? Thanks!", "> @trentlo Can you please address Ubuntu Sanity errors? Thanks!\r\n\r\nShould have been fixed now. It was a BUILD file format issue.\r\n\r\nIt appears someone has to approve it again for regression test?\r\n", "> This PR fails with an internal model: https://gist.github.com/sanjoy/1a23cba0e7c53419349102b53d221708 with the error: \"Invalid argument: Cannot concatenate arrays with different element types: F16 vs PRED\". Can you please take a look?\r\n\r\nThanks for the reporting. Will take a look at it soon.\r\n", "> > This PR fails with an internal model: https://gist.github.com/sanjoy/1a23cba0e7c53419349102b53d221708 with the error: \"Invalid argument: Cannot concatenate arrays with different element types: F16 vs PRED\". Can you please take a look?\r\n> \r\n> Thanks for the reporting. Will take a look at it soon.\r\n\r\nI guess we missed a consideration that we should not horizontally fuse instructions if their output types are not the same (since concat cannot support this). Will update the PR soon.\r\n", "> This PR fails with an internal model: https://gist.github.com/sanjoy/1a23cba0e7c53419349102b53d221708 with the error: \"Invalid argument: Cannot concatenate arrays with different element types: F16 vs PRED\". Can you please take a look?\r\n\r\nFixed.\r\n\r\nPlease help to take a look when you get a moment. Happy new year~\r\n", "> Updated. Please help to take a look. Thanks.\r\n\r\nPing.", "Hi @trentlo, I ran benchmarks internally. The good news is, I did not spot any regressions. Unfortunately, none of the benchmarks in the suite shows a speedup either. That's not a blocker, but ideally, we'd add one to safeguard against accidental regressions. What open-source benchmarks did you use for your own testing?", "> Hi @trentlo, I ran benchmarks internally. The good news is, I did not spot any regressions. Unfortunately, none of the benchmarks in the suite shows a speedup either. That's not a blocker, but ideally, we'd add one to safeguard against accidental regressions. What open-source benchmarks did you use for your own testing?\r\n\r\nGood to hear that there is no repression. :-)\r\n\r\nTo see performance gain, you need to enable resource variables, so that the optimizers are lowered into XLA. In TF1.x, variables are not lowered into XLA (i.e., only resource_varialbes are lowered).\r\n\r\nYou may try Resnet50 with **adam** in [tf_cnn_benchmark](https://github.com/tensorflow/benchmarks/tree/master/scripts/tf_cnn_benchmarks). I tried it with TF1.x (as it did not support TF2 few weeks ago) and see around 4% and 2% speedup with fp32 and fp16, respectively. I just saw that they updated the script and it may be compatible with TF2 now; I have never tried it with TF2 and I will find time to try it.\r\n\r\n(BTW I will take a week off until 1/24. My response time will be longer than usual.)", "Welcome back, Trent. I hope you had an enjoyable vacation!\r\n\r\nThanks for your instructions for benchmarking. Just to make sure it you didn't miss it: Some tests run into CHECK failures. See my previous comments.\r\n\r\nUnfortunately the open-source CI did not catch these test breakages. This is a known issue and a fix is underway.", "> Welcome back, Trent. I hope you had an enjoyable vacation!\r\n> \r\n> Thanks for your instructions for benchmarking. Just to make sure it you didn't miss it: Some tests run into CHECK failures. See my previous comments.\r\n> \r\n> Unfortunately the open-source CI did not catch these test breakages. This is a known issue and a fix is underway.\r\n\r\nGot it. Let me know if there is anything I can help with.\r\n", "> Got it. Let me know if there is anything I can help with.\r\n\r\nCan you fix the `CHECK`-failures Thomas mentioned [above](https://github.com/tensorflow/tensorflow/pull/34882#discussion_r367937189)?  Or are they already fixed?", "> > Got it. Let me know if there is anything I can help with.\r\n> \r\n> Can you fix the `CHECK`-failures Thomas mentioned [above](https://github.com/tensorflow/tensorflow/pull/34882#discussion_r367937189)? Or are they already fixed?\r\n\r\nNo problem to provide a fix to it. However, @thomasjoerg did you mean someone already fixed it and a commit is on the way?\r\n", "> No problem to provide a fix to it. However, @thomasjoerg did you mean someone already fix it and a commit is on the way?\r\n\r\nI suspect in \" This is a known issue and a fix is underway.\" @thomasjoerg was referring to \"Unfortunately the open-source CI did not catch these test breakages.\".  I'll ping him internally to reply here, but we're outside his working hours.", "> > No problem to provide a fix to it. However, @thomasjoerg did you mean someone already fix it and a commit is on the way?\r\n> \r\n> I suspect in \" This is a known issue and a fix is underway.\" @thomasjoerg was referring to \"Unfortunately the open-source CI did not catch these test breakages.\". I'll ping him internally to reply here, but we're outside his working hours.\r\n\r\nHi @trentlo, @sanjoy is right. The bug has slipped through CI and hence you see \"All checks have passed\". However, the CHECK failure is a real bug in this PR and needs to be fixed. I mentioned the build target above. You should be able to reproduce it.", "> Hi @trentlo, @sanjoy is right. The bug has slipped through CI and hence you see \"All checks have passed\". However, the CHECK failure is a real bug in this PR and needs to be fixed. I mentioned the build target above. You should be able to reproduce it.\r\n\r\nAh. I was confused. Looking into it then.\r\n", "There is a new build error probably because someone changed the build flag. Fixing it.\r\n\r\n```\r\nERROR: /Volumes/BuildData/tmpfs/src/github/tensorflow/tensorflow/compiler/xla/service/gpu/BUILD:1696:1: Couldn't build file tensorflow/compiler/xla/service/gpu/_objs/horizontal_fusion_test/horizontal_fusion_test.o: C++ compilation of rule '//tensorflow/compiler/xla/service/gpu:horizontal_fusion_test' failed (Exit 1)\r\ntensorflow/compiler/xla/service/gpu/horizontal_fusion_test.cc:205:45: error: non-constant-expression cannot be narrowed from type 'unsigned long' to 'long long' in initializer list [-Wc++11-narrowing]\r\n    auto shape = ShapeUtil::MakeShape(F32, {i + 1, 1024});\r\n                                            ^~~~~\r\ntensorflow/compiler/xla/service/gpu/horizontal_fusion_test.cc:205:45: note: insert an explicit cast to silence this issue\r\n    auto shape = ShapeUtil::MakeShape(F32, {i + 1, 1024});\r\n                                            ^~~~~\r\n                                            static_cast<long long>( )\r\ntensorflow/compiler/xla/service/gpu/horizontal_fusion_test.cc:295:48: error: non-constant-expression cannot be narrowed from type 'unsigned long' to 'long long' in initializer list [-Wc++11-narrowing]\r\n    auto shape = ShapeUtil::MakeShape(F32, {2, 1024 + i});\r\n                                               ^~~~~~~~\r\ntensorflow/compiler/xla/service/gpu/horizontal_fusion_test.cc:295:48: note: insert an explicit cast to silence this issue\r\n    auto shape = ShapeUtil::MakeShape(F32, {2, 1024 + i});\r\n                                               ^~~~~~~~\r\n                                               static_cast<long long>( )\r\n2 errors generated.\r\n```", "> There is a new build error probably because someone changed the build flag. Fixing it.\r\n> \r\n\r\nIt is because of some narrowing checks specific to Clang. Should have been fixed.\r\n\r\n@thomasjoerg, I will need to bother you to kick off the CI again.\r\n", "> @thomasjoerg, I will need to bother you to kick off the CI again.\r\n\r\nDone.", "> > @thomasjoerg, I will need to bother you to kick off the CI again.\r\n> \r\n> Done.\r\n\r\nThank you!"]}, {"number": 34881, "title": "[Intel MKL] Fixing MKL broken README links and updating with 1.15 and 2.0 links", "body": "", "comments": []}, {"number": 34880, "title": "Implement slice input fusion.", "body": "Implement code generation for input-fusible slices. It is useful to support split-like semantic. Before this change, slices can only be fused into their successors. This change enables the slices to be fused with their predecessors.", "comments": ["Great, thanks!\r\n\r\nFor the commit description it would be awesome to also have one micro-benchmark with `--xla_hlo_profile`before and after.", "> Great, thanks!\r\n> \r\n> For the commit description it would be awesome to also have one micro-benchmark with `--xla_hlo_profile`before and after.\r\n\r\nThanks for the review.\r\n\r\nNo problem to add a micro-benchmark. Could you give me some pointers about how to do that? Any example?", "> No problem to add a micro-benchmark. Could you give me some pointers about how to do that? Any example?\r\n\r\nThanks, e.g.\r\nhttps://github.com/tensorflow/tensorflow/commit/c6ccf6316430193e18dde016698d2d8c9989b30a\r\n\r\nYou can get the numbers by running with `XLA_FLAGS=--xla_hlo_profile`\r\n\r\nIdeally, the HLO should demonstrate that things got much faster.", "> Thanks, e.g.\r\n> [c6ccf63](https://github.com/tensorflow/tensorflow/commit/c6ccf6316430193e18dde016698d2d8c9989b30a)\r\n> \r\n> You can get the numbers by running with `XLA_FLAGS=--xla_hlo_profile`\r\n> \r\n> Ideally, the HLO should demonstrate that things got much faster.\r\n\r\nAh~ I now see where you are from.\r\n\r\nSome context: this kind of input-fusible slices is not supported by the current XLA. So, I cannot create a fused computation to do the before- and after-change comparison as you did in the given nice example. This input-fusible slice is needed by the horizontal fusion in this depending [PR](https://github.com/tensorflow/tensorflow/pull/34882). So, you can find more involved tests there (For example RMSPropLike in the [test file](https://github.com/tensorflow/tensorflow/pull/34882/files#diff-b40b77c469fb9627d0c46bf36458ce66)). The slice input fusion is exercised as the horizontal fusion relies on them for fusion. I separated them into two PRs because it will help with the review process. Briefly speaking, the horizontal fusion fuses the outputs of two independent fused computations to reduce the kernel launch overhead.\r\n\r\nPlease let me know if this fulfills your request about more involved tests. It makes sense to me that the tests that come with this PR are unit-tests while the (more involved) integration tests are with the above-mentioned horizontal fusion PR. Feel free to let me know if this makes sense to you.\r\n\r\nIn addition, I benchmarked with the [tests](https://github.com/tensorflow/tensorflow/pull/34882/files#diff-b40b77c469fb9627d0c46bf36458ce66) with `--xla_hlo_profile`. Logs are here: [log.on.txt](https://github.com/tensorflow/tensorflow/files/3947407/log.on.txt) and [log.off.txt](https://github.com/tensorflow/tensorflow/files/3947408/log.off.txt).\r\n\r\nBelow is the summary (by greping). I will add them into the commit log of the horizontal fusion. In the GradientDescentOptimizerLike case, the time is reduced from 2.39ms to 311us. Please let me know if this responds your requests for benchmark numbers.\r\n\r\n```\r\nroot@686952bd1fe5:/opt/tensorflow/tensorflow-source# grep -r \"Execution profile\" log.off.txt | grep GradientDescent\r\n2019-12-10 22:05:45.215015: I tensorflow/compiler/xla/service/executable.cc:208] Execution profile for GradientDescentOptimizerLike: (2.39 ms @ f_nom)\r\nroot@686952bd1fe5:/opt/tensorflow/tensorflow-source# grep -r \"Execution profile\" log.on.txt | grep GradientDescent\r\n2019-12-10 22:05:03.831600: I tensorflow/compiler/xla/service/executable.cc:208] Execution profile for GradientDescentOptimizerLike: (311 us @ f_nom)\r\nroot@686952bd1fe5:/opt/tensorflow/tensorflow-source# grep -r \"Execution profile\" log.off.txt | grep RMSProp\r\n2019-12-10 22:05:48.877372: I tensorflow/compiler/xla/service/executable.cc:208] Execution profile for RMSPropLike: (980 us @ f_nom)\r\nroot@686952bd1fe5:/opt/tensorflow/tensorflow-source# grep -r \"Execution profile\" log.on.txt | grep RMSProp\r\n2019-12-10 22:05:13.513901: I tensorflow/compiler/xla/service/executable.cc:208] Execution profile for RMSPropLike: (112 us @ f_nom)\r\n```\r\n\r\n\r\n\r\n", "> I might be missing something, but your change enables a fusion which was previously impossible, right? So you can profile an HLO which previously did not have this fusion, and the profile should show that it got (at least slightly) faster after this pass, right?\r\n\r\nThe difficulty I am having is that this commit touches only code generation. However, we cannot have a HLO with input-fusible slices to exercise both the codegen before and after this change, as input-fusible slices are _not_ supported by the existing codegen (without the change.)\r\n\r\nAlternatively, we can have an HLO with several kLoop fusions and use [the horizontal fusion pass](https://github.com/tensorflow/tensorflow/pull/34882) to generate input-fusible slices (by fusing the kLoop fusions). We can turn on and off the horizontal fusion pass for comparison; the slice input fusion is generated (after fusing the kLoop fusions) when the horizontal fusion is on, while kLoop fusions remain if the horizontal fusion is off. This demonstrates the effects of the change. The tests are already in the depending [PR](https://github.com/tensorflow/tensorflow/pull/34882) and numbers are reported as in my previous replies.\r\n\r\nPlease let me know if this addresses your concerns or not."]}, {"number": 34879, "title": "[Intel Mkl] Adding Bazel version and BFloat16 support to the MKL CI", "body": "MKL CI containers need to support different Bazel versions and BFloat16.", "comments": ["Hi @penpornk and @rthadur. Thanks for reviewing this. We have more updates we want to push to these files, but would like your approval here first."]}, {"number": 34878, "title": "Illegal ambiguous match on configurable attribute \"deps\" in //tensorflow/core:ops", "body": "**System information**\r\n- OS Platform and Distribution: macOS Catalina 10.15.1\r\n- TensorFlow installed from: source\r\n- TensorFlow version: 2.0.0\r\n- Python version: 3.7.4\r\n- Installed using: [spack](https://spack.io)\r\n- Bazel version: 0.26.1\r\n- Compiler version: Clang 11.0.0\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**Describe the problem**\r\n\r\nI'm trying to build a minimal TF installation, but I don't seem to be able to disable GCP support. I get the following error during build time:\r\n```\r\n/private/var/folders/21/hwq39zyj4g36x6zjfyl5l8080000gn/T/Adam/spack-stage/spack-stage-py-tensorflow-2.0.0-ve5t7rb2qt4igekam6hdrwnm6vgts22q/spack-src/tensorflow/core/BUILD:1359:12: Illegal ambiguous match on configurable attribute \"deps\" in //tensorflow/core:ops:\r\n//tensorflow:api_version_2\r\n//tensorflow:no_gcp_support\r\nMultiple matches are not allowed unless one is unambiguously more specialized.\r\n```\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nFirst, I set the following environment variables:\r\n```bash\r\nTF_CONFIGURE_IOS=0; export TF_CONFIGURE_IOS\r\nTF_DOWNLOAD_CLANG=0; export TF_DOWNLOAD_CLANG\r\nTF_ENABLE_XLA=0; export TF_ENABLE_XLA\r\nTF_NEED_AWS=0; export TF_NEED_AWS\r\nTF_NEED_CUDA=0; export TF_NEED_CUDA\r\nTF_NEED_GCP=0; export TF_NEED_GCP\r\nTF_NEED_GDR=0; export TF_NEED_GDR\r\nTF_NEED_HDFS=0; export TF_NEED_HDFS\r\nTF_NEED_IGNITE=0; export TF_NEED_IGNITE\r\nTF_NEED_JEMALLOC=0; export TF_NEED_JEMALLOC\r\nTF_NEED_KAFKA=0; export TF_NEED_KAFKA\r\nTF_NEED_MKL=0; export TF_NEED_MKL\r\nTF_NEED_MPI=0; export TF_NEED_MPI\r\nTF_NEED_NGRAPH=0; export TF_NEED_NGRAPH\r\nTF_NEED_OPENCL=0; export TF_NEED_OPENCL\r\nTF_NEED_OPENCL_SYCL=0; export TF_NEED_OPENCL_SYCL\r\nTF_NEED_ROCM=0; export TF_NEED_ROCM\r\nTF_NEED_S3=0; export TF_NEED_S3\r\nTF_NEED_VERBS=0; export TF_NEED_VERBS\r\nTF_SET_ANDROID_WORKSPACE=0; export TF_SET_ANDROID_WORKSPACE\r\n```\r\nThen, I ran:\r\n```console\r\n$ ./configure\r\n$ bazel --nohome_rc --nosystem_rc build --color=no --jobs=4 --config=opt --config=noaws --config=nogcp --config=nohdfs --config=noignite --config=nokafka --config=nonccl --config=v2 //tensorflow/tools/pip_package:build_pip_package\r\n```\r\nThe bug seems to occur regardless of whether or not `--config=v2` is added, as that is the default. Using `--config=nogcp --config=v1` seems to work, and not using `--config=nogcp` also seems to work. Is GCP support required in v2?\r\n\r\n**Any other info / logs**\r\n\r\n[build log](https://github.com/tensorflow/tensorflow/files/3928307/spack-build-out.txt)\r\n[build environment](https://github.com/tensorflow/tensorflow/files/3928308/spack-build-env.txt)\r\n\r\nThis work is being done in conjunction with https://github.com/spack/spack/pull/13112\r\n\r\nI've seen #25644 #24447 #11807 #14522 and other similar issues, but they look specific to CUDA/NCCL or are due to older versions of Bazel.", "comments": ["This bug is no longer present in 2.1.0. I'll close this, but if anyone knows which commit fixed this, I can patch 2.0.0.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34878\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34878\">No</a>\n", "For the record, this bug seems to be present in 2.0.0 and 2.0.1, and seems to have been fixed by the following commit:\r\n```\r\ncommit 837c8b6b35429ec99d977c609fe65c0e79f4569a\r\nAuthor: Gunhan Gulsoy <gunan@google.com>\r\nDate:   Wed Sep 4 13:43:49 2019 -0700\r\n\r\n    Remove contrib cloud bigtable and storage ops/kernels.\r\n    Thse have moved to github.com/tensorflow/io\r\n    PiperOrigin-RevId: 267222179\r\n```"]}, {"number": 34877, "title": "Getting Bus error in Ubuntu Mate ", "body": "WARNING:tensorflow:From /home/odroid/tensorflow1/models/research/object_detection/utils/label_map_util.py:138: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\r\n\r\nWARNING:tensorflow:From Object_detection_image.py:64: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.\r\n\r\nWARNING:tensorflow:From Object_detection_image.py:70: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\r\n\r\nBus error\r\n\r\n**Getting this Bus error in Ubuntu Mate on Odroid while running the object detection webcam script  , Using Python 3.5 and tensorflow version 1.14.0\r\nAny idea how to solve that ??", "comments": ["\r\n@Adilhossain227 \r\n\r\nRequest you to share simple stand alone code to reproduce the issue in our environment. It helps in localizing the issue faster. Thanks!\r\n\r\n", "@Adilhossain227 \r\n\r\nAny update on this issue please. Thanks!", "`import os\r\nimport cv2\r\nimport numpy as np\r\nimport tensorflow as tf\r\nimport sys\r\nsys.path.append(\"..\")\r\n\r\n# Import utilites\r\nfrom utils import label_map_util\r\nfrom utils import visualization_utils as vis_util\r\n\r\n# Name of the directory containing the object detection module we're using\r\nMODEL_NAME = 'inference_graph'\r\n\r\n# Grab path to current working directory\r\nCWD_PATH = os.getcwd()\r\n\r\nPATH_TO_CKPT = os.path.join(CWD_PATH,MODEL_NAME,'frozen_inference_graph.pb')\r\n\r\n# Path to label map file\r\nPATH_TO_LABELS = os.path.join(CWD_PATH,'training','labelmap.pbtxt')\r\n\r\n# Number of classes the object detector can identify\r\nNUM_CLASSES = 1\r\n\r\nlabel_map = label_map_util.load_labelmap(PATH_TO_LABELS)\r\ncategories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\r\ncategory_index = label_map_util.create_category_index(categories)\r\n\r\n# Load the Tensorflow model into memory.\r\ndetection_graph = tf.Graph()\r\nwith detection_graph.as_default():\r\n    od_graph_def = tf.GraphDef()\r\n    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\r\n        serialized_graph = fid.read()\r\n        od_graph_def.ParseFromString(serialized_graph)\r\n        tf.import_graph_def(od_graph_def, name='')\r\n\r\n    sess = tf.Session(graph=detection_graph)\r\n\r\nimage_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\r\ndetection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\r\ndetection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\r\ndetection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\r\n\r\n# Number of objects detected\r\nnum_detections = detection_graph.get_tensor_by_name('num_detections:0')\r\n\r\nvideo = cv2.VideoCapture(0)\r\nret = video.set(3,1280)\r\nret = video.set(4,720)\r\n\r\nwhile(True):\r\n\r\n    ret, frame = video.read()\r\n    frame_expanded = np.expand_dims(frame, axis=0)\r\n\r\n    (boxes, scores, classes, num) = sess.run(\r\n        [detection_boxes, detection_scores, detection_classes, num_detections],\r\n        feed_dict={image_tensor: frame_expanded})\r\n\r\n    vis_util.visualize_boxes_and_labels_on_image_array(\r\n        frame,\r\n        np.squeeze(boxes),\r\n        np.squeeze(classes).astype(np.int32),\r\n        np.squeeze(scores),\r\n        category_index,\r\n        use_normalized_coordinates=True,\r\n        line_thickness=8,\r\n        min_score_thresh=0.60)\r\n    cv2.imshow('Object detector', frame)\r\n\r\n    if cv2.waitKey(1) == ord('q'):\r\n        break\r\nvideo.release()\r\ncv2.destroyAllWindows()\r\n`", "@Adilhossain227 \r\n\r\nLooks like code is incomplete.Request you to share colab link or simple stand alone code with supporting files to reproduce the issue in our environment. It helps in localizing the issue faster. Thanks!", "It has been 16 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "@Adilhossain227 \r\n\r\nAny update on this issue please. Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 34876, "title": "Memory leak in fit() with callback", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n** Coding Language **\r\nPython\r\n\r\n**System information**\r\n\r\n- OS Platform and Distribution: Ubuntu 16.04\r\n- TensorFlow installed from (source or binary): pip3\r\n- TensorFlow version : 2.0.0\r\n- TensorFlow Keras version: '2.2.4-tf'\r\n- Python version: 3.6\r\n- GPU model and memory:\r\n\r\n![image](https://user-images.githubusercontent.com/7545134/70257890-11129e00-1740-11ea-944b-291d5fed4c30.png)\r\n\r\n**Describe the current behavior**\r\nCPU Ram progressively gets consumed as the fit() works. Each EPOCH consumes more and more memory. This memory leak only happens when a callback is assigned, any callback eg: tensorboard.\r\n\r\nThe memory consumption can be seen in both ways:\r\n-  System memory (vmstat)\r\n-  Printing resource memory usage in code (print(resource.getrusage(resource.RUSAGE_SELF).ru_maxrss))\r\n\r\nAttached the vmstat print to screen:\r\n![image](https://user-images.githubusercontent.com/7545134/70258980-196bd880-1742-11ea-9cfe-6d6fa684ac3b.png)\r\n\r\n\r\n**Code to reproduce the issue**\r\nBATCH_SIZE = 24\r\nlearning_rate = 0.000005\r\ndecay_rate = 1e-6\r\nEPOCHS = 4000\r\nCLIP_VALUE = 1.5\r\nl1reg = 0.01\r\nl2reg = 0.00\r\n\r\nmodel = Sequential()\r\n\r\nmodel.add(LSTM(512, input_shape=(train_x.shape[1], train_x.shape[2]), activation='relu',\r\n               return_sequences=True, bias_regularizer=L1L2(l1=l1reg, l2=l2reg)))\r\nmodel.add(Dropout(0.3))\r\nmodel.add(BatchNormalization())\r\n\r\nmodel.add(LSTM(512, activation='relu', return_sequences = True))\r\nmodel.add(Dropout(0.3))\r\nmodel.add(BatchNormalization())\r\n\r\nmodel.add(LSTM(256, activation='relu'))\r\nmodel.add(Dropout(0.25))\r\nmodel.add(BatchNormalization())\r\n\r\nmodel.add(Flatten())\r\nmodel.add(Dense(24, activation='relu'))\r\n\r\nmodel.add(Flatten())\r\nmodel.add(Dense(2, activation='softmax'))\r\nopt = tf.keras.optimizers.Adam(lr=learning_rate, decay=decay_rate, clipvalue=CLIP_VALUE)\r\n\r\nmodel.compile(\r\n    loss='sparse_categorical_crossentropy',\r\n    optimizer=opt,\r\n    metrics=['accuracy'],\r\n)\r\n\r\nNAME = f\"PARAM-{train_x.shape[2]}-FIRSTTEST-{int(time.time())}\"\r\nprint(NAME)\r\nprint('-----------------------------------------')\r\ntensorboard = TensorBoard(log_dir=f\"{ML_LOG_DIR}/{NAME}\")\r\nfilepath = \"RNN_Final-{epoch:02d}-{val_accuracy:.3f}\"\r\ncheckpoint = ModelCheckpoint(\"{}/{}.model\".format(ML_MODEL_DIR, filepath, monitor='val_accuracy',\r\n                            verbose=1, save_best_only=True, mode='max')) # saves only the best ones\r\n\r\nhistory = model.fit(\r\n        train_x,\r\n        train_y,\r\n        epochs=EPOCHS,\r\n        batch_size=BATCH_SIZE,\r\n        validation_data=(test_x, test_y)\r\n        callbacks=[tensorboard, checkpoint]\r\n)\r\n\r\n**Other info / logs**\r\nThe problem goes away if the callbacks are removed.\r\n", "comments": ["@RavindhranSankar ,\r\nCan you please provide the complete code to reproduce issue from our end?Thanks!", "@RavindhranSankar ,\r\nAny update on the issue?Thanks!", "Hi ,\n\nSorry about the delay.\n\nI attached all the code in the bug report. The rest of the code pertains to\nthe data and cleaning it.\n\nI will send across the full code tomorrow\n\nHappy Holidays\n\nRavi\n\nOn Tue, Dec 24, 2019 at 12:41 AM oanush <notifications@github.com> wrote:\n\n> @RavindhranSankar <https://github.com/RavindhranSankar> ,\n> Any update on the issue?Thanks!\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/34876?email_source=notifications&email_token=ABZSCLWI5QI2HSJNZ3ZFLI3Q2HDNBA5CNFSM4JV5CYAKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEHSZTEQ#issuecomment-568695186>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/ABZSCLW6U5CLJ5SGOFBCPDLQ2HDNBANCNFSM4JV5CYAA>\n> .\n>\n", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "@oanush  Please reopen this. I also ran into this issue. After spending a lot of time trying to debug things, it looks like this memory leak happens when TensorBoard callback is used. The moment I remove the Tensorboard callback, it goes away. ", "And it seems to only happen during validation. Training seem to go fine for me. It was really difficult to find out the source in Tensorboard callback.", "Agreed. Same experience for me. Removing the callback makes the leak go away. However as soon as the Tensorboard callback is added, it returns. \r\n\r\nIf I recollect correctly, the leak happens with any callback (not just Tensorboard)", "I tried with other callbacks of mine and also the callbacks provided by tensorflow. Are you sure it happens when you remove tensorboard? For me, it seems to work with other callbacks as long as tensorboard isn't there.", "@Regarding other callbacks: Let me get back on that. My memory could be misleading me. Will test again and report back", "Anyone actively working on this issue? Its a bug that hits a core functionality such as tensorboard"]}, {"number": 34875, "title": "Update image_ops_impl.py", "body": "Add usage example to TensorFlow 2.0 API documentation for tf.image.rgb_to_yuv()\r\n\r\n\r\nGCI 2019", "comments": []}, {"number": 34874, "title": "Skipping optimization warning when using tanh activation in LSTM layers", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 19.10\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v2.0.0-rc2-26-g64c3d38 2.0.0\r\n- Python version: 3.7\r\n- GPU model and memory: no GPU\r\n\r\n**Describe the current behavior**\r\nWhen training a model containing an LSTM layer with activation function 'tanh', I receive the following warnings:\r\n\r\n> W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference___backward_cudnn_lstm_with_fallback_2431_2613' and '__inference___backward_standard_lstm_2770_3255_specialized_for_StatefulPartitionedCall_at___inference_distributed_function_3336' both implement 'lstm_c366749f-d70a-4931-b887-2ea0c126b791' but their signatures do not match.\r\n> W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference_cudnn_lstm_with_fallback_3844' and '__inference_standard_lstm_3733_specialized_for_model_lstm_StatefulPartitionedCall_at___inference_distributed_function_4076' both implement 'lstm_3433d132-ad4b-4073-bc24-8ed871518bdc' but their signatures do not match.\r\n\r\nHowever, it feels like the model is still training, despite the warning. The warnings disappear when changing the activation function.\r\n\r\n**Describe the expected behavior**\r\nThe warning shouldn't appear.\r\n\r\n**Code to reproduce the issue**\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.layers import Input, LSTM\r\nfrom tensorflow.keras.models import Model\r\n\r\nn_trn, n_vld = 10_000, 100\r\nx_trn = np.random.randint(2, size=(n_trn, 10, 2))\r\ny_trn = x_trn\r\nx_vld = np.random.randint(2, size=(n_vld, 10, 2))\r\ny_vld = x_vld\r\n\r\ntrain_data = tf.data.Dataset.from_tensor_slices((x_trn, y_trn)).repeat().batch(100)\r\nvalid_data = tf.data.Dataset.from_tensor_slices((x_vld, y_vld)).repeat().batch(100)\r\n\r\nx = Input(shape=(10, 2))\r\ny = tf.math.abs(LSTM(2, return_sequences=True, dropout=0.3, activation='tanh')(x))\r\n\r\nmodel = Model(inputs=[x], outputs=y)\r\nmodel.compile(optimizer='adam', loss='binary_crossentropy')\r\nmodel.fit(train_data, steps_per_epoch=100, epochs=100, validation_data=valid_data, validation_steps=1)\r\n```\r\n", "comments": ["I have tried on colab with TF version 2.0 and i am not seeing any issue. Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/3d0d3b8b6d88e4b3ac4b09b060201265/untitled453.ipynb). Thanks!", "@giamic \r\n\r\nAny update on this issue please. Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 34873, "title": "Using GPU delegate causes app to crash", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (or github SHA if from source): 'org.tensorflow:tensorflow-lite-gpu:0.0.0-nightly'\r\n\r\n\r\n**Command used to run the converter or code if you\u2019re using the Python API**\r\n\r\n```\r\nmodel = tf.keras.models.load_model('my_conv.h5')\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nconverter.target_spec.supported_types = [tf.float16]\r\ntflite_model = converter.convert()\r\nopen(\"custom_cnn_f16.tflite\", \"wb\").write(tflite_model)\r\n```\r\n\r\n**The output from the converter invocation**\r\n\r\n```\r\nIt successfully converts the model to TFlite f16\r\n```\r\n\r\n**Also, please include a link to the saved model or GraphDef**\r\n\r\n```\r\n[Link](https://drive.google.com/file/d/1-0R5fPIWIM7N3Kv442QGTxVJ5Dz0ebZ-/view?usp=sharing)\r\n\r\n```\r\n\r\nThe model is a simple CNN which takes a 50x50x1 grayscale image and outputs probabilities for 10 classes. \r\n\r\n**Failure details**\r\nI want to run the Float16 version of the model using TFLite on the GPU (Samsung S10+) however using the GPU delegate on this model causes the app to crash. I have tested on other devices and this model crashes on all phones when running on the GPU.\r\n\r\n\r\n**Any other info / logs**\r\n```\r\n2019-12-05 18:06:30.715 3830-3830/? A/DEBUG: *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** ***\r\n2019-12-05 18:06:30.716 3830-3830/? A/DEBUG: Build fingerprint: 'xxxxxxxxxxxxxxxx/release-keys'\r\n2019-12-05 18:06:30.716 3830-3830/? A/DEBUG: Revision: '26'\r\n2019-12-05 18:06:30.716 3830-3830/? A/DEBUG: ABI: 'arm64'\r\n2019-12-05 18:06:30.716 3830-3830/? A/DEBUG: pid: 2979, tid: 3198, name: inference  >>> com.test.app <<<\r\n2019-12-05 18:06:30.716 3830-3830/? A/DEBUG: signal 11 (SIGSEGV), code 1 (SEGV_MAPERR), fault addr 0x0\r\n2019-12-05 18:06:30.716 3830-3830/? A/DEBUG: Cause: null pointer dereference\r\n2019-12-05 18:06:30.716 3830-3830/? A/DEBUG:     x0  0000000000000000  x1  0000000000000000  x2  00000070516c44e0  x3  00000070516c43f0\r\n2019-12-05 18:06:30.716 3830-3830/? A/DEBUG:     x4  00000000000000ba  x5  00000070546a5288  x6  000000704d0bb540  x7  000000704d0bb560\r\n2019-12-05 18:06:30.716 3830-3830/? A/DEBUG:     x8  185cb8064dde48fc  x9  185cb8064dde48fc  x10 0000000000000000  x11 00000070546a51d0\r\n2019-12-05 18:06:30.716 3830-3830/? A/DEBUG:     x12 000000704d0bb580  x13 000000704d0bb5a0  x14 00000000ffffffff  x15 0000000000000000\r\n2019-12-05 18:06:30.716 3830-3830/? A/DEBUG:     x16 00000070f06f3bd0  x17 00000070f068898c  x18 00000000ffffffff  x19 000000706424f000\r\n2019-12-05 18:06:30.716 3830-3830/? A/DEBUG:     x20 00000070516c43b0  x21 00000070516c43f0  x22 00000070516c44e0  x23 00000070642a9fe0\r\n2019-12-05 18:06:30.716 3830-3830/? A/DEBUG:     x24 00000070516c4430  x25 00000070516c7588  x26 0000007064253b88  x27 00000070516c7588\r\n2019-12-05 18:06:30.716 3830-3830/? A/DEBUG:     x28 000000704d1803c0  x29 00000070516c4390\r\n2019-12-05 18:06:30.716 3830-3830/? A/DEBUG:     sp  00000070516c42c0  lr  0000007039a729f0  pc  0000007039a729f4\r\n2019-12-05 18:06:30.739 3830-3830/? A/DEBUG: backtrace:\r\n2019-12-05 18:06:30.739 3830-3830/? A/DEBUG:     #00 pc 00000000000c49f4  /data/app/com.test.app-EdFQ7ADOagBLvNg1917Lag==/lib/arm64/libtensorflowlite_gpu_jni.so\r\n2019-12-05 18:06:30.739 3830-3830/? A/DEBUG:     #01 pc 000000000001ba8c  /data/app/com.test.app-EdFQ7ADOagBLvNg1917Lag==/lib/arm64/libtensorflowlite_gpu_jni.so\r\n2019-12-05 18:06:30.739 3830-3830/? A/DEBUG:     #02 pc 000000000017e52c  /data/app/com.test.app-EdFQ7ADOagBLvNg1917Lag==/lib/arm64/libtensorflowlite_jni.so\r\n2019-12-05 18:06:30.739 3830-3830/? A/DEBUG:     #03 pc 000000000017e0a4  /data/app/com.test.app-EdFQ7ADOagBLvNg1917Lag==/lib/arm64/libtensorflowlite_jni.so\r\n2019-12-05 18:06:30.739 3830-3830/? A/DEBUG:     #04 pc 000000000017de68  /data/app/com.test.app-EdFQ7ADOagBLvNg1917Lag==/lib/arm64/libtensorflowlite_jni.so\r\n2019-12-05 18:06:30.739 3830-3830/? A/DEBUG:     #05 pc 000000000001b5d4  /data/app/com.test.app-EdFQ7ADOagBLvNg1917Lag==/lib/arm64/libtensorflowlite_gpu_jni.so\r\n2019-12-05 18:06:30.739 3830-3830/? A/DEBUG:     #06 pc 000000000017fb08  /data/app/com.test.app-EdFQ7ADOagBLvNg1917Lag==/lib/arm64/libtensorflowlite_jni.so\r\n2019-12-05 18:06:30.739 3830-3830/? A/DEBUG:     #07 pc 0000000000182fa0  /data/app/com.test.app-EdFQ7ADOagBLvNg1917Lag==/lib/arm64/libtensorflowlite_jni.so\r\n2019-12-05 18:06:30.739 3830-3830/? A/DEBUG:     #08 pc 000000000000f214  /data/app/com.test.app-EdFQ7ADOagBLvNg1917Lag==/lib/arm64/libtensorflowlite_jni.so (Java_org_tensorflow_lite_NativeInterpreterWrapper_applyDelegate+40)\r\n2019-12-05 18:06:30.739 3830-3830/? A/DEBUG:     #09 pc 00000000005545e0  /system/lib64/libart.so (art_quick_generic_jni_trampoline+144)\r\n2019-12-05 18:06:30.739 3830-3830/? A/DEBUG:     #10 pc 000000000054b84c  /system/lib64/libart.so (art_quick_invoke_static_stub+604)\r\n2019-12-05 18:06:30.739 3830-3830/? A/DEBUG:     #11 pc 00000000000d00b8  /system/lib64/libart.so (art::ArtMethod::Invoke(art::Thread*, unsigned int*, unsigned int, art::JValue*, char const*)+232)\r\n2019-12-05 18:06:30.739 3830-3830/? A/DEBUG:     #12 pc 000000000027ec54  /system/lib64/libart.so (art::interpreter::ArtInterpreterToCompiledCodeBridge(art::Thread*, art::ArtMethod*, art::ShadowFrame*, unsigned short, art::JValue*)+344)\r\n2019-12-05 18:06:30.739 3830-3830/? A/DEBUG:     #13 pc 0000000000279da4  /system/lib64/libart.so (bool art::interpreter::DoCall<true, false>(art::ArtMethod*, art::Thread*, art::ShadowFrame&, art::Instruction const*, unsigned short, art::JValue*)+752)\r\n2019-12-05 18:06:30.739 3830-3830/? A/DEBUG:     #14 pc 000000000051d854  /system/lib64/libart.so (MterpInvokeStaticRange+148)\r\n2019-12-05 18:06:30.739 3830-3830/? A/DEBUG:     #15 pc 000000000053e014  /system/lib64/libart.so (ExecuteMterpImpl+15380)\r\n2019-12-05 18:06:30.739 3830-3830/? A/DEBUG:     #16 pc 000000000046472e  /dev/ashmem/dalvik-classes.dex extracted in memory from /data/app/com.test.app-EdFQ7ADOagBLvNg1917Lag==/base.apk_2979_2979 (deleted) (org.tensorflow.lite.NativeInterpreterWrapper.applyDelegates+122)\r\n2019-12-05 18:06:30.739 3830-3830/? A/DEBUG:     #17 pc 0000000000252c14  /system/lib64/libart.so (_ZN3art11interpreterL7ExecuteEPNS_6ThreadERKNS_20CodeItemDataAccessorERNS_11ShadowFrameENS_6JValueEb.llvm.3612284370+488)\r\n2019-12-05 18:06:30.739 3830-3830/? A/DEBUG:     #18 pc 0000000000258374  /system/lib64/libart.so (art::interpreter::ArtInterpreterToInterpreterBridge(art::Thread*, art::CodeItemDataAccessor const&, art::ShadowFrame*, art::JValue*)+216)\r\n2019-12-05 18:06:30.739 3830-3830/? A/DEBUG:     #19 pc 0000000000278c78  /system/lib64/libart.so (bool art::interpreter::DoCall<false, false>(art::ArtMethod*, art::Thread*, art::ShadowFrame&, art::Instruction const*, unsigned short, art::JValue*)+920)\r\n2019-12-05 18:06:30.739 3830-3830/? A/DEBUG:     #20 pc 000000000051be90  /system/lib64/libart.so (MterpInvokeDirect+296)\r\n2019-12-05 18:06:30.739 3830-3830/? A/DEBUG:     #21 pc 000000000053dc94  /system/lib64/libart.so (ExecuteMterpImpl+14484)\r\n2019-12-05 18:06:30.739 3830-3830/? A/DEBUG:     #22 pc 00000000004649a4  /dev/ashmem/dalvik-classes.dex extracted in memory from /data/app/com.test.app-EdFQ7ADOagBLvNg1917Lag==/base.apk_2979_2979 (deleted) (org.tensorflow.lite.NativeInterpreterWrapper.init+140)\r\n2019-12-05 18:06:30.739 3830-3830/? A/DEBUG:     #23 pc 0000000000252c14  /system/lib64/libart.so (_ZN3art11interpreterL7ExecuteEPNS_6ThreadERKNS_20CodeItemDataAccessorERNS_11ShadowFrameENS_6JValueEb.llvm.3612284370+488)\r\n2019-12-05 18:06:30.739 3830-3830/? A/DEBUG:     #24 pc 0000000000258374  /system/lib64/libart.so (art::interpreter::ArtInterpreterToInterpreterBridge(art::Thread*, art::CodeItemDataAccessor const&, art::ShadowFrame*, art::JValue*)+216)\r\n2019-12-05 18:06:30.739 3830-3830/? A/DEBUG:     #25 pc 0000000000279d88  /system/lib64/libart.so (bool art::interpreter::DoCall<true, false>(art::ArtMethod*, art::Thread*, art::ShadowFrame&, art::Instruction const*, unsigned short, art::JValue*)+724)\r\n2019-12-05 18:06:30.739 3830-3830/? A/DEBUG:     #26 pc 000000000051d6b4  /system/lib64/libart.so (MterpInvokeDirectRange+244)\r\n2019-12-05 18:06:30.739 3830-3830/? A/DEBUG:     #27 pc 000000000053df94  /system/lib64/libart.so (ExecuteMterpImpl+15252)\r\n2019-12-05 18:06:30.739 3830-3830/? A/DEBUG:     #28 pc 000000000046468c  /dev/ashmem/dalvik-classes.dex extracted in memory from /data/app/com.test.app-EdFQ7ADOagBLvNg1917Lag==/base.apk_2979_2979 (deleted) (org.tensorflow.lite.NativeInterpreterWrapper.<init>+128)\r\n2019-12-05 18:06:30.739 3830-3830/? A/DEBUG:     #29 pc 0000000000252c14  /system/lib64/libart.so (_ZN3art11interpreterL7ExecuteEPNS_6ThreadERKNS_20CodeItemDataAccessorERNS_11ShadowFrameENS_6JValueEb.llvm.3612284370+488)\r\n2019-12-05 18:06:30.739 3830-3830/? A/DEBUG:     #30 pc 0000000000258374  /system/lib64/libart.so (art::interpreter::ArtInterpreterToInterpreterBridge(art::Thread*, art::CodeItemDataAccessor const&, art::ShadowFrame*, art::JValue*)+216)\r\n2019-12-05 18:06:30.739 3830-3830/? A/DEBUG:     #31 pc 0000000000278c78  /system/lib64/libart.so (bool art::interpreter::DoCall<false, false>(art::ArtMethod*, art::Thread*, art::ShadowFrame&, art::Instruction const*, unsigned short, art::JValue*)+920)\r\n2019-12-05 18:06:30.739 3830-3830/? A/DEBUG:     #32 pc 000000000051be90  /system/lib64/libart.so (MterpInvokeDirect+296)\r\n2019-12-05 18:06:30.739 3830-3830/? A/DEBUG:     #33 pc 000000000053dc94  /system/lib64/libart.so (ExecuteMterpImpl+14484)\r\n2019-12-05 18:06:30.739 3830-3830/? A/DEBUG:     #34 pc 0000000000464002  /dev/ashmem/dalvik-classes.dex extracted in memory from /data/app/com.test.app-EdFQ7ADOagBLvNg1917Lag==/base.apk_2979_2979 (deleted) (org.tensorflow.lite.Interpreter.<init>+10)\r\n2019-12-05 18:06:30.739 3830-3830/? A/DEBUG:     #35 pc 0000000000252c14  /system/lib64/libart.so (_ZN3art11interpreterL7ExecuteEPNS_6ThreadERKNS_20CodeItemDataAccessorERNS_11ShadowFrameENS_6JValueEb.llvm.3612284370+488)\r\n2019-12-05 18:06:30.739 3830-3830/? A/DEBUG:     #36 pc 0000000000258374  /system/lib64/libart.so (art::interpreter::ArtInterpreterToInterpreterBridge(art::Thread*, art::CodeItemDataAccessor const&, art::ShadowFrame*, art::JValue*)+216)\r\n2019-12-05 18:06:30.739 3830-3830/? A/DEBUG:     #37 pc 0000000000278c78  /system/lib64/libart.so (bool art::interpreter::DoCall<false, false>(art::ArtMethod*, art::Thread*, art::ShadowFrame&, art::Instruction const*, unsigned short, art::JValue*)+920)\r\n2019-12-05 18:06:30.739 3830-3830/? A/DEBUG:     #38 pc 000000000051be90  /system/lib64/libart.so (MterpInvokeDirect+296)\r\n2019-12-05 18:06:30.739 3830-3830/? A/DEBUG:     #39 pc 000000000053dc94  /system/lib64/libart.so (ExecuteMterpImpl+14484)\r\n2019-12-05 18:06:30.739 3830-3830/? A/DEBUG:     #40 pc 0000000000044cf2  /dev/ashmem/dalvik-classes2.dex extracted in memory from /data/app/com.test.app-EdFQ7ADOagBLvNg1917Lag==/base.apk!classes2.dex_2979_2979 (deleted) (com.test.app.tflite.Classifier.runModel+302)\r\n2019-12-05 18:06:30.739 3830-3830/? A/DEBUG:     #41 pc 0000000000252c14  /system/lib64/libart.so (_ZN3art11interpreterL7ExecuteEPNS_6ThreadERKNS_20CodeItemDataAccessorERNS_11ShadowFrameENS_6JValueEb.llvm.3612284370+488)\r\n2019-12-05 18:06:30.739 3830-3830/? A/DEBUG:     #42 pc 0000000000258374  /system/lib64/libart.so (art::interpreter::ArtInterpreterToInterpreterBridge(art::Thread*, art::CodeItemDataAccessor const&, art::ShadowFrame*, art::JValue*)+216)\r\n2019-12-05 18:06:30.739 3830-3830/? A/DEBUG:     #43 pc 0000000000278c78  /system/lib64/libart.so (bool art::interpreter::DoCall<false, false>(art::ArtMethod*, art::Thread*, art::ShadowFrame&, art::Instruction const*, unsigned short, art::JValue*)+920)\r\n2019-12-05 18:06:30.739 3830-3830/? A/DEBUG:     #44 pc 000000000051ab60  /system/lib64/libart.so (MterpInvokeVirtual+584)\r\n2019-12-05 18:06:30.739 3830-3830/? A/DEBUG:     #45 pc 000000000053db94  /system/lib64/libart.so (ExecuteMterpImpl+14228)\r\n2019-12-05 18:06:30.739 3830-3830/? A/DEBUG:     #46 pc 000000000003fe80  /dev/ashmem/dalvik-classes2.dex extracted in memory from /data/app/com.test.app-EdFQ7ADOagBLvNg1917Lag==/base.apk!classes2.dex_2979_2979 (deleted) (com.test.app.home.HomeFragment$run$1.run+128)\r\n2019-12-05 18:06:30.739 3830-3830/? A/DEBUG:     #47 pc 0000000000252c14  /system/lib64/libart.so (_ZN3art11interpreterL7ExecuteEPNS_6ThreadERKNS_20CodeItemDataAccessorERNS_11ShadowFrameENS_6JValueEb.llvm.3612284370+488)\r\n2019-12-05 18:06:30.739 3830-3830/? A/DEBUG:     #48 pc 0000000000258374  /system/lib64/libart.so (art::interpreter::ArtInterpreterToInterpreterBridge(art::Thread*, art::CodeItemDataAccessor const&, art::ShadowFrame*, art::JValue*)+216)\r\n2019-12-05 18:06:30.739 3830-3830/? A/DEBUG:     #49 pc 0000000000278c78  /system/lib64/libart.so (bool art::interpreter::DoCall<false, false>(art::ArtMethod*, art::Thread*, art::ShadowFrame&, art::Instruction const*, unsigned short, art::JValue*)+920)\r\n2019-12-05 18:06:30.739 3830-3830/? A/DEBUG:     #50 pc 000000000051bacc  /system/lib64/libart.so (MterpInvokeInterface+1392)\r\n2019-12-05 18:06:30.739 3830-3830/? A/DEBUG:     #51 pc 000000000053dd94  /system/lib64/libart.so (ExecuteMterpImpl+14740)\r\n2019-12-05 18:06:30.739 3830-3830/? A/DEBUG:     #52 pc 0000000000dbd78c  /system/framework/boot-framework.vdex (android.os.Handler.handleCallback+4)\r\n2019-12-05 18:06:30.739 3830-3830/? A/DEBUG:     #53 pc 0000000000252c14  /system/lib64/libart.so (_ZN3art11interpreterL7ExecuteEPNS_6ThreadERKNS_20CodeItemDataAccessorERNS_11ShadowFrameENS_6JValueEb.llvm.3612284370+488)\r\n2019-12-05 18:06:30.739 3830-3830/? A/DEBUG:     #54 pc 0000000000258374  /system/lib64/libart.so (art::interpreter::ArtInterpreterToInterpreterBridge(art::Thread*, art::CodeItemDataAccessor const&, art::ShadowFrame*, art::JValue*)+216)\r\n2019-12-05 18:06:30.739 3830-3830/? A/DEBUG:     #55 pc 0000000000278c78  /system/lib64/libart.so (bool art::interpreter::DoCall<false, false>(art::ArtMethod*, art::Thread*, art::ShadowFrame&, art::Instruction const*, unsigned short, art::JValue*)+920)\r\n2019-12-05 18:06:30.739 3830-3830/? A/DEBUG:     #56 pc 000000000051c054  /system/lib64/libart.so (MterpInvokeStatic+204)\r\n2019-12-05 18:06:30.739 3830-3830/? A/DEBUG:     #57 pc 000000000053dd14  /system/lib64/libart.so (ExecuteMterpImpl+14612)\r\n2019-12-05 18:06:30.739 3830-3830/? A/DEBUG:     #58 pc 0000000000c658a8  /system/framework/boot-framework.vdex (android.os.Handler.dispatchMessage+8)\r\n2019-12-05 18:06:30.739 3830-3830/? A/DEBUG:     #59 pc 0000000000252c14  /system/lib64/libart.so (_ZN3art11interpreterL7ExecuteEPNS_6ThreadERKNS_20CodeItemDataAccessorERNS_11ShadowFrameENS_6JValueEb.llvm.3612284370+488)\r\n2019-12-05 18:06:30.739 3830-3830/? A/DEBUG:     #60 pc 0000000000258374  /system/lib64/libart.so (art::interpreter::ArtInterpreterToInterpreterBridge(art::Thread*, art::CodeItemDataAccessor const&, art::ShadowFrame*, art::JValue*)+216)\r\n2019-12-05 18:06:30.739 3830-3830/? A/DEBUG:     #61 pc 0000000000278c78  /system/lib64/libart.so (bool art::interpreter::DoCall<false, false>(art::ArtMethod*, art::Thread*, art::ShadowFrame&, art::Instruction const*, unsigned short, art::JValue*)+920)\r\n2019-12-05 18:06:30.739 3830-3830/? A/DEBUG:     #62 pc 000000000051ab60  /system/lib64/libart.so (MterpInvokeVirtual+584)\r\n2019-12-05 18:06:30.739 3830-3830/? A/DEBUG:     #63 pc 000000000053db94  /system/lib64/libart.so (ExecuteMterpImpl+14228)\r\n2019-12-05 18:06:30.739 3830-3830/? A/DEBUG:     #64 pc 0000000000c6e4ee  /system/framework/boot-framework.vdex (android.os.Looper.loop+406)\r\n2019-12-05 18:06:30.739 3830-3830/? A/DEBUG:     #65 pc 0000000000252c14  /system/lib64/libart.so (_ZN3art11interpreterL7ExecuteEPNS_6ThreadERKNS_20CodeItemDataAccessorERNS_11ShadowFrameENS_6JValueEb.llvm.3612284370+488)\r\n2019-12-05 18:06:30.740 3830-3830/? A/DEBUG:     #66 pc 0000000000258374  /system/lib64/libart.so (art::interpreter::ArtInterpreterToInterpreterBridge(art::Thread*, art::CodeItemDataAccessor const&, art::ShadowFrame*, art::JValue*)+216)\r\n2019-12-05 18:06:30.740 3830-3830/? A/DEBUG:     #67 pc 0000000000278c78  /system/lib64/libart.so (bool art::interpreter::DoCall<false, false>(art::ArtMethod*, art::Thread*, art::ShadowFrame&, art::Instruction const*, unsigned short, art::JValue*)+920)\r\n2019-12-05 18:06:30.740 3830-3830/? A/DEBUG:     #68 pc 000000000051c054  /system/lib64/libart.so (MterpInvokeStatic+204)\r\n2019-12-05 18:06:30.740 3830-3830/? A/DEBUG:     #69 pc 000000000053dd14  /system/lib64/libart.so (ExecuteMterpImpl+14612)\r\n2019-12-05 18:06:30.740 3830-3830/? A/DEBUG:     #70 pc 0000000000c6540c  /system/framework/boot-framework.vdex (android.os.HandlerThread.run+56)\r\n2019-12-05 18:06:30.740 3830-3830/? A/DEBUG:     #71 pc 0000000000252c14  /system/lib64/libart.so (_ZN3art11interpreterL7ExecuteEPNS_6ThreadERKNS_20CodeItemDataAccessorERNS_11ShadowFrameENS_6JValueEb.llvm.3612284370+488)\r\n2019-12-05 18:06:30.740 3830-3830/? A/DEBUG:     #72 pc 000000000050b850  /system/lib64/libart.so (artQuickToInterpreterBridge+1032)\r\n2019-12-05 18:06:30.740 3830-3830/? A/DEBUG:     #73 pc 00000000005546fc  /system/lib64/libart.so (art_quick_to_interpreter_bridge+92)\r\n2019-12-05 18:06:30.740 3830-3830/? A/DEBUG:     #74 pc 000000000054b588  /system/lib64/libart.so (art_quick_invoke_stub+584)\r\n2019-12-05 18:06:30.740 3830-3830/? A/DEBUG:     #75 pc 00000000000d0098  /system/lib64/libart.so (art::ArtMethod::Invoke(art::Thread*, unsigned int*, unsigned int, art::JValue*, char const*)+200)\r\n2019-12-05 18:06:30.740 3830-3830/? A/DEBUG:     #76 pc 0000000000454970  /system/lib64/libart.so (art::(anonymous namespace)::InvokeWithArgArray(art::ScopedObjectAccessAlreadyRunnable const&, art::ArtMethod*, art::(anonymous namespace)::ArgArray*, art::JValue*, char const*)+104)\r\n2019-12-05 18:06:30.740 3830-3830/? A/DEBUG:     #77 pc 0000000000455a3c  /system/lib64/libart.so (art::InvokeVirtualOrInterfaceWithJValues(art::ScopedObjectAccessAlreadyRunnable const&, _jobject*, _jmethodID*, jvalue*)+424)\r\n2019-12-05 18:06:30.740 3830-3830/? A/DEBUG:     #78 pc 00000000004807f0  /system/lib64/libart.so (art::Thread::CreateCallback(void*)+1260)\r\n2019-12-05 18:06:30.740 3830-3830/? A/DEBUG:     #79 pc 0000000000084148  /system/lib64/libc.so (__pthread_start(void*)+64)\r\n2019-12-05 18:06:30.740 3830-3830/? A/DEBUG:     #80 pc 0000000000023b28  /system/lib64/libc.so (__start_thread+68)\r\n```\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["I don't get a segfault but this instead:\r\n\r\n```\r\nINFO: Initialized TensorFlow Lite runtime.\r\nINFO: Created TensorFlow Lite delegate for GPU.\r\nINFO: Replacing 87 node(s) with delegate (TfLiteGpuDelegate) node, yielding 1 partitions.\r\nERROR: TfLiteGpuDelegate Prepare: Shader compilation failed: ERROR: 0:6: 'data' : Syntax error:  syntax error\r\nINTERNAL ERROR: no main() function!\r\nERROR: 1 compilation errors.  No code generated.\r\n\r\n\r\nERROR: Node number 87 (TfLiteGpuDelegate) failed to prepare.\r\n\r\nERROR: tensorflow/lite/kernels/depthwise_conv.cc:109 filter->type != data_type (10 != 1)\r\nERROR: Node number 2 (DEPTHWISE_CONV_2D) failed to prepare.\r\n\r\nF1206 14:03:13.223900   10663 jet_pilot.cc:72] Check failed: gpu_inference->ModifyGraphWithDelegate(gpu_delegate) == kTfLiteOk (1 vs. 0)\r\n```\r\n\r\nIs your network well-formed?  Tensor shapes are quite strict in the GPU runtime.  Even if TFLite runs it fine on CPU because elements are contiguous in memory, TFLite GPU can fail.", "@impjdi, I will double check my network and get back to you.", "@impjdi Here's a simple example of a CNN that causes a segfault when it is converted to F16 for TFLite. Maybe this could help useful in debugging. I don't see anything wrong with the network itself.\r\n\r\n```\r\nimport tensorflow as tf # 2.0\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D, Input, MaxPooling2D, Dropout\r\nimport numpy as np\r\n\r\ndata = np.random.uniform(0, 1, (1000, 100, 100, 1)).astype(np.float32)\r\nlabels = np.random.randint(0, 9, (1000,)).astype(np.int32)\r\ndataset = tf.data.Dataset.from_tensor_slices((data, labels))\r\n\r\nlayers = []\r\nlayers.append(Conv2D(64, 3, padding='same', activation='relu', name='conv_1', input_shape=(100, 100, 1)))\r\nlayers.append(MaxPooling2D(2, name='max_pool_1'))\r\nlayers.append(Dropout(0.2, name='dropout_1'))\r\nlayers.append(Conv2D(128, 3, padding='same', activation='relu', name='conv_2'))\r\nlayers.append(MaxPooling2D(2, name='max_pool_2'))\r\nlayers.append(Dropout(0.2, name='dropout_2'))\r\nlayers.append(Conv2D(256, 3, padding='same', activation='relu', name='conv_3'))\r\nlayers.append(MaxPooling2D(2, name='max_pool_3'))\r\nlayers.append(Dropout(0.2, name='dropout_3'))\r\nlayers.append(Flatten(name='flatten'))\r\nlayers.append(Dense(128, activation='relu', name='dense_1'))\r\nlayers.append(Dense(64, activation='relu', name='dense_2'))\r\nlayers.append(Dense(10, activation='softmax', name='dense_3'))\r\nmodel = keras.Sequential(layers, name='my_cnn')\r\nmodel.summary()\r\n\r\ndataset = dataset.batch(8)\r\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\r\nmodel.fit(dataset, epochs=1)\r\n\r\n# Convert to TFLite with Float16 quantization\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nconverter.target_spec.supported_types = [tf.float16]\r\ntflite_model = converter.convert()\r\nopen(\"my_f16_cnn.tflite\", \"wb\").write(tflite_model)\r\n\r\n```\r\n\r\nRunning this \"my_f16_cnn.tflite\" model on the device with the GPU Delegate will cause the app to crash.", "As you said, this didn't work as expected.  Some error around\r\n\r\n> INFO: Replacing 22 node(s) with delegate (TfLiteGpuDelegate) node, yielding 1 partitions.\r\n> ERROR: TfLiteGpuDelegate Prepare: Shader compilation failed: ERROR: 0:6: 'data' : Syntax error:  syntax error\r\n> INTERNAL ERROR: no main() function!\r\n> ERROR: 1 compilation errors.  No code generated.\r\n> ERROR: Node number 22 (TfLiteGpuDelegate) failed to prepare.\r\n> ERROR: third_party/tensorflow/lite/kernels/depthwise_conv.cc:109 filter->type != data_type (10 != 1)\r\n> ERROR: Node number 2 (DEPTHWISE_CONV_2D) failed to prepare.\r\n\r\nSo... I tried to get rid of the data_type 10 which is float16.  In your script, I changed it to:\r\n\r\n> converter.target_spec.supported_types = [tf.float16]\r\n\r\nThen I ran into:\r\n\r\n> ERROR: Next operations are not supported by GPU delegate:\r\n> FULLY_CONNECTED: Max version supported: 1. Requested version 3.\r\n> First 6 operations will run on the GPU, and the remaining 4 on the CPU.\r\n> ERROR: TfLiteGpuDelegate Prepare: CONV_2D: Unsupported data type for float32 tensor\r\n\r\nLet's ignore the FULLY_CONNECTED version check for the moment.\r\n\r\n`ERROR: TfLiteGpuDelegate Prepare: CONV_2D: Unsupported data type for float32 tensor` is coming from the fact that the `tensor.type = kTfLiteInt8`.  Unfortunately, I don't know enough about Keras or TFLiteConverter to tell why it's creating quantized weights =/", "Found out about the quantized weights:\r\n\r\n`converter.optimizations = [tf.lite.Optimize.DEFAULT]`\r\n\r\nwas replaced with:\r\n\r\n`converter.optimizations = []`\r\n\r\nThen I get:\r\n\r\n> ERROR: TfLiteGpuDelegate Prepare: Shader compilation failed: ERROR: 0:6: 'data' : Syntax error:  syntax error\r\n> INTERNAL ERROR: no main() function!\r\n> ERROR: 1 compilation errors.  No code generated.\r\n\r\nI will find out what's failing.", "Any update on this?", "I think I did everything on my end.  Is there any remaining action items for me?", "@impjdi Hi, I just built tensorflow-lite from source and the crash doesn't happen there anymore. So I will close the issue. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34873\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34873\">No</a>\n", "> @impjdi Hi, I just built tensorflow-lite from source and the crash doesn't happen there anymore. So I will close the issue. Thanks!\r\n\r\n@bilalsoomro Could you provide instructions for the same ? Thanks.", "@NikhilBartwal The issue has been fixed and does not happen in the nightly builds for me. If you want to also try building from source, I use the instructions provided in this [link](https://www.tensorflow.org/lite/guide/android#build_tensorflow_lite_locally).", "Hi, I'm facing the same issue. I've tried building also. Is it possible you can provide a link to your libraries."]}, {"number": 34872, "title": "ImportError: libcuda.so.1: cannot open shared object file: No such file or directory", "body": "hi im beginner in tensorflow! i want  run my tensorflow code in ipm but i got this error :\r\n\r\nTraceback (most recent call last):\r\n  File \"/share/Application/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"/share/Application/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"/share/Application/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"/share/Application/anaconda3/lib/python3.6/imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"/share/Application/anaconda3/lib/python3.6/imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: libcuda.so.1: cannot open shared object file: No such file or directory\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"main.py\", line 5, in <module>\r\n    import VDSR.vdsr as vdsr\r\n  File \"../VDSR/vdsr.py\", line 1, in <module>\r\n    import tensorflow as tf\r\n  File \"/share/Application/anaconda3/lib/python3.6/site-packages/tensorflow/__init__.py\", line 24, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"/share/Application/anaconda3/lib/python3.6/site-packages/tensorflow/python/__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"/share/Application/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"/share/Application/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"/share/Application/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"/share/Application/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"/share/Application/anaconda3/lib/python3.6/imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"/share/Application/anaconda3/lib/python3.6/imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: libcuda.so.1: cannot open shared object file: No such file or directory\r\n\r\n\r\nFailed to load the native TensorFlow runtime.", "comments": ["this is my .sh file:\r\n\r\n\r\n\r\n#!/bin/sh\r\n\r\n#PBS -l nodes=1:ppn=1\r\n#PBS -o $PBS_JOBID.log\r\n#PBS -e $PBS_JOBID.err\r\n#PBS -N Python \r\n#PBS -q limited\r\n#PBS -l walltime=700:00:00\r\n\r\nexport PATH=/share/Application/anaconda3/bin:$PATH\r\nexport LD_LIBRARY_PATH=/share/Application/anaconda3/lib:$LD_LIBRARY_PATH\r\n\r\ncd $PBS_O_WORKDIR\r\n\r\n\r\n#-------------------User Define ------------------\r\nexport InputName=main.py\r\n\r\npython --version\r\npython main.py\r\n\r\n", "It seems to me that the file libcuda.so.1 either does not exist on your system or your Tf installation fails to locate it. \r\nPlease **add /path/to/libcuda.so.1 in the LD_LIBRARY_PATH and reboot.**\r\n\r\nTo fing the path run the commands:          \r\n - *sudo updatedb*       \r\n - *sudo locate libcuda.so.1*       \r\n\r\nThen add the address of libcuda.so.1 to your $LD_LIBRARY_PATH env var and reboot.\r\n(For example, for me the path is /usr/lib/)\r\n\r\nPS: This is a common issue arising out of the multitude of ways Tf/CUDA can be installed, very similar issues on #18482, #30670\r\n\r\nPlease follow the appropriate issue template when sending in an issue. Thanks!", "In addition to above suggestion if the issue still persists then can you verify following information. Thanks!\r\n\r\n@rezaprince What version of TF are you installing? Does your CPU support AVX instruction sets?\r\n\r\n**TensorFlow release binaries version 1.6 and higher are prebuilt with AVX instruction sets.**\r\nTherefore on any CPU that does not have these instruction sets, either CPU or GPU version of TF will fail to load.\r\n\r\nIf your CPU model does not support AVX instruction sets. You can still use TensorFlow with the alternatives given below:\r\n* Try Google Colab to use TensorFlow.\r\n    * The easiest way to use TF will be to switch to [google colab](https://colab.sandbox.google.com/notebooks/welcome.ipynb#recent=true). You get pre-installed latest stable TF version. Also you can use ```pip install``` to install any other preferred TF version.\r\n    * It has an added advantage since you can you easily switch to different hardware accelerators     \r\n      (cpu, gpu, tpu) as per the task. \r\n    * All you need is a good internet connection and you are all set.\r\n* Try to build TF from sources by changing CPU optimization flags.\r\n\r\nPlease let us know if this helps.", "@rezaprince \r\n\r\nAny update on this issue please. Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34872\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34872\">No</a>\n"]}, {"number": 34871, "title": "tf.string tensors are not converted to numpy string arrays", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Bug appears on Linux Ubuntu 18.04, but also in Colab Notebooks\r\n- TensorFlow version (use command below): 2.0.0\r\n- Python version: 3.6\r\n\r\n**Describe the current behavior**\r\n\r\n[Colab Notebook to reproduce](https://colab.research.google.com/drive/13zEPEBbfOR0U5TVc4dABxtT6NUB6TftL)\r\n\r\nWhen casting a tensor of type `tf.string` to a numpy array in eager mode, the ndarray does not have a correct string dtype, but is converted to an array of arbitrary objects.\r\n\r\n```\r\ntf_str = tf.constant(['Hello World', 'B'])\r\n>> <tf.Tensor: id=1, shape=(2,), dtype=string, numpy=array([b'Hello World', b'B'], dtype=object)>\r\ntf_str.numpy()\r\n>> array([b'Hello World', b'B'], dtype=object)\r\ntf_str.numpy().astype(str)  # expicit casting to string\r\n>> array(['Hello World', 'B'], dtype='<U11')\r\n```\r\n\r\n**Describe the expected behavior**\r\nIt would be expected that a `tf.string` datatype is converted to a [numpy string datatype](https://docs.scipy.org/doc/numpy/reference/arrays.dtypes.html#string-dtype-note).\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n[Colab Notebook to reproduce](https://colab.research.google.com/drive/13zEPEBbfOR0U5TVc4dABxtT6NUB6TftL)\r\n", "comments": ["@hermannsblum Thats an expected behavior of numpy. Please refer to the following [question](https://stackoverflow.com/questions/16037824/how-to-convert-numpy-object-array-into-str-unicode-array) for more details.\r\n\r\n"]}, {"number": 34870, "title": "Use _get_distribution_strategy only when it is available.", "body": "The changes introduced in https://github.com/tensorflow/tensorflow/commit/06d8f77bcc43826eb2b30209a73f3c833079edbc are not compatible with standalone `Keras` (they are compatible with `tf.Keras`). a `keras.Model` does not have a `_get_distribution_strategy` method, which is now assumed for the `Tensorboard` callback.\r\n\r\nThese kind of differences are usually not an issue, but Keras is using [`tf.keras.callbacks.Tensorboard`](https://github.com/keras-team/keras/blob/master/keras/callbacks/tensorboard_v2.py#L18) instead of implementing its own.\r\n\r\nThis PR checks if `_get_distribution_strategy` exists and uses it if it does, making it compatible with a `keras.Model`.", "comments": ["Done :+1: ", "@hgaiser Can you please check reviewer comments and keep us posted. Thanks!", "Apologies, I forgot to update the PR. It is updated now though :+1: ", "@rchao Can you please take a look on this PR? Thanks!", "I cant get Tensorboard to work when using [keras-retinanet](https://github.com/fizyr/keras-retinanet). @hgaiser is it fixed with this commit? ", "> I cant get Tensorboard to work when using [https://github.com/fizyr/keras-retinanet](keras-retinanet). @hgaiser is it fixed with this commit?\r\n\r\nShould be, yes.", "> > I cant get Tensorboard to work when using [https://github.com/fizyr/keras-retinanet](keras-retinanet). @hgaiser is it fixed with this commit?\r\n> \r\n> Should be, yes.\r\n\r\nI am experiencing the same error as here: https://github.com/fizyr/keras-retinanet/issues/1239\r\nShould have the latest version installed. \r\n\r\nJust to get it right: Is the commit not merged yet? And is that why the error is still occurring? ", "It's not merged yet, so unless you applied this branch yourself you're not using this fix.", "> It's not merged yet, so unless you applied this branch yourself you're not using this fix.\r\n\r\nIt works - Thank you! ", "Still happening. I am using a pip installed version.\r\n`!pip freeze | grep -iE \"tensorflow|keras\"`\r\ngives\r\n```\r\nKeras==2.3.1\r\nKeras-Applications==1.0.8\r\nKeras-Preprocessing==1.1.0\r\ntensorflow==2.1.0\r\ntensorflow-estimator==2.1.0\r\n\r\n```\r\n\r\nAm I not using the latest??\r\n\r\n```\r\n$ pip search tensorflow\r\ntensorflow (2.1.0)                                - TensorFlow is an open source machine learning framework for everyone.\r\n  INSTALLED: 2.1.0 (latest)\r\ntensorflow-qndex (0.0.22)                         - tensorflow-qnd x tensorflow-extenteten\r\n\r\n```", "A Tensorflow update is missing for this to work, so you need to go edit the callbacks.py file with the edit of this commit to get it to work at the moment. In your local Tensorflow installation just replace the entire callbacks.py file. ", "thank you for your reply. I download tensorflow-master from here:\r\n\r\n`https://github.com/tensorflow/tensorflow`\r\n\r\nand I replaced the callbacks.py file but now get this error:\r\n\r\n`ImportError: cannot import name 'profiler_v2' from 'tensorflow.python.profiler' (/home/stefan/miniconda3/envs/TFg/lib/python3.7/site-packages/tensorflow_core/python/profiler/__init__.py)\r\n`", "I found profiler v2 and copied it over. Now I get this error\r\n\r\n`ImportError: cannot import name '_pywrap_profiler' from 'tensorflow.python.profiler.internal' (/home/stefan/miniconda3/envs/TFg/lib/python3.7/site-packages/tensorflow_core/python/profiler/internal/__init__.py)\r\n`\r\n\r\nThere is no '_pywrap_profiler' in the new tensorflow inside the 'profiler' folder or the 'internal' folder or anywhere in the new tensorflow archive.\r\nThere is an __init.py__ file inside 'internal' as well as the 'profiler' folder.\r\n\r\n", "I restarted the jupyter notebook from a new terminal session. Now, when I get to this step\r\n\r\n```\r\n#train for 50 epochs\r\nautoencoder.fit(x_train, x_train,\r\n                epochs=50,\r\n                batch_size=256,\r\n                shuffle=True,\r\n                validation_data=(x_test, x_test),\r\n                verbose=1)\r\n```\r\n\r\nI get this error\r\n\r\n`ImportError: cannot import name '_pywrap_profiler' from 'tensorflow.python.profiler.internal' (/home/stefan/miniconda3/envs/TFg/lib/python3.7/site-packages/tensorflow_core/python/profiler/internal/__init__.py)\r\n\r\nnotice there are no callbacks to tensorboard-this is just running the simple VAE\r\n`\r\n", "Nope not merged yet.", "AttributeError: 'Model' object has no attribute 'run_eagerly'", "AttributeError: 'ResourceVariable' object has no attribute '_distribute_strategy'"]}, {"number": 34869, "title": "[tflite] bump SPLIT op ver from 1 to 3 in NNAPI delegate", "body": "I need SPLIT op version 3. Since it's supported by TFLite and\r\nNNAPI 1.2. It should be safe to bump the op version so that\r\nI can delegate SPLIT ops to accelerators.", "comments": []}, {"number": 34868, "title": "Some of the operators in the model are not supported by the standard TensorFlow Lite runtime", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nUbuntu 16.04\r\n- TensorFlow installed from (source or binary):\r\npip install tensorflow\r\n- TensorFlow version (or github SHA if from source):\r\n2.1.0rc0\r\n\r\n\r\n**Provide the text output from tflite_convert**\r\n\r\n```\r\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, FULLY_CONNECTED, LOGISTIC, MUL, RESHAPE, STRIDED_SLICE. Here is a list of operators for which you will need custom implementations: TensorListFromTensor, TensorListReserve, TensorListStack, While.\r\n```\r\n\r\nAlso, please include a link to a GraphDef or the model if possible.\r\n\r\n**Any other info / logs**\r\n\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@YAIsaienkov Can you please share standalone code to reproduce the issue? Thanks!", "`\r\nmodel = load_model(hdf_filename)\r\nmodel.compile(loss='binary_crossentropy', optimizer='adam')\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\ntflite_model = converter.convert()\r\nwith open(tflite_filename, 'wb') as f:\r\n    f.write(tflite_model)\r\n`\r\n\r\n`    model = Sequential()\r\n    model.add(LSTM(16, input_shape=input_shape))\r\n    model.add(Dropout(.2))\r\n    model.add(BatchNormalization())\r\n    model.add(Dense(16))\r\n    model.add(Dense(1, activation='sigmoid'))\r\n    # print(model.summary())\r\n`", "@YAIsaienkov I created a colab with your code and ran it using new experimental converter as follows\r\n`converter.experimental_new_converter = True` \r\n\r\nEverything worked without an issue. I am attaching the [gist](https://colab.sandbox.google.com/gist/jvishnuvardhan/469e50fe41de23a93c4ae62de67b6770/untitled695.ipynb) for your reference. Thanks!\r\n\r\nPlease close the issue if this resolved your issue. Thanks!", "Thank's!\r\nBut I have one more question:\r\nBefore I convert model I could feed to the model shapes (n, 20, 8), but now only (1, 20, 8). Should it be like that?", "If your batch size is always intended to be the same non-1 value, we recommend setting the batch size of the input tensor in the TensorFlow model (e.g. instead of (n, 20, 8) have the model shape be (10, 20, 8)).\r\n\r\nHowever, if that's not the case, then we currently don't support dynamic shapes. There are a few other open issues about adding dynamic shape support: https://github.com/tensorflow/tensorflow/issues/24607, https://github.com/tensorflow/tensorflow/issues/33711. It's an issue we are aware of and intend to resolve.\r\n\r\nOne solution that works for some users is to call `resize_input_tensor` on the Interpreter with new input shape having the desired batch size. That allows you to change the batch size during inference. However, this is just a work around and doesn't work for most models (because of the way the model is constructed).", "Thank you all for the help!"]}, {"number": 34867, "title": "saved_model.go", "body": "    where is the package \"github.com/tensorflow/tensorflow/tensorflow/go/genop/internal/proto/github.com/tensorflow/tensorflow/tensorflow/go/core\"?\r\n   I can't build the program.", "comments": ["@jacobxy ,\r\nCan you please provide more information about the issue? also provide a standalone code to reproduce the issue,mention the TF version being used.Thanks!", "@jacobxy ,\r\nAny update on the issue?Thanks!"]}, {"number": 34866, "title": "Keras Custom Loss/Model Compilation", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nYes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nWindows 10 1909\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\nNo\r\n- TensorFlow installed from (source or binary):\r\nBinary, Pip\r\n- TensorFlow version (use command below):\r\n1.14\r\n- Python version:\r\n3.7.3\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n10/7.6.4\r\n- GPU model and memory:\r\nRTX 2080 with 8GB VRAM, 16GB DRAM DDR4\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n_for 1_: unknown 1.14.0\r\n\r\n**Describe the current behavior**\r\nModel compilation fails with the following error.\r\n\r\n    Traceback (most recent call last):\r\n      File \".\\vgg_loss.py\", line 103, in <module>\r\n        main()\r\n      File \".\\vgg_loss.py\", line 97, in main\r\n        model.compile(optimizer='adam', loss=some_loss, metrics=['accuracy'])\r\n      File \"C:\\Users\\Intel\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\", \r\n    line 457, in _method_wrapper\r\n        result = method(self, *args, **kwargs)\r\n      File \"C:\\Users\\Intel\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", \r\n    line 337, in compile\r\n        self._compile_weights_loss_and_weighted_metrics()\r\n      File \"C:\\Users\\Intel\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\", \r\n    line 457, in _method_wrapper\r\n        result = method(self, *args, **kwargs)\r\n      File \"C:\\Users\\Intel\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", \r\n    line 1710, in _compile_weights_loss_and_weighted_metrics\r\n        self.total_loss = self._prepare_total_loss(masks)\r\n    otal_loss\r\n        per_sample_losses = loss_fn.call(y_true, y_pred)\r\n      File \"C:\\Users\\Intel\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py\", line 215, \r\n    in call\r\n        return self.fn(y_true, y_pred, **self._fn_kwargs)\r\n      File \".\\vgg_loss.py\", line 86, in some_loss\r\n        return mse(vgg_model.predict(y_pred, steps=1), vgg_model.predict(y_true, steps=1))\r\n      File \"C:\\Users\\Intel\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", \r\n    line 1078, in predict       callbacks=callbacks)\r\n        batch_outs = f(actual_inputs)\r\n        run_metadata=self.run_metadata)\r\n        run_metadata_ptr)\r\n    tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.\r\n       (0) Invalid argument: You must feed a value for placeholder tensor 'input_node' with dtype \r\n         float \r\n    and shape [1,512,512,3]\r\n              [[{{node input_node}}]]\r\n              [[block4_conv3/Relu/_217]]\r\n       (1) Invalid argument: You must feed a value for placeholder tensor 'input_node' with dtype float \r\n     and shape [1,512,512,3]\r\n              [[{{node input_node}}]]\r\n     0 successful operations.\r\n     0 derived errors ignored.\r\n\r\n\r\n**Describe the expected behavior**\r\nThe code should compile properly.\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\nI am attaching the [link](https://github.com/jtdutta1/Fastest/blob/master/vgg_loss.py) to the code.\r\nAlso download the vgg model whose link is provided in the code. I am also referencing [here](https://drive.google.com/open?id=1OsKx6CPacs7V7d-1cNCI2bFIty2BVQEz) again.\r\n\r\nBe sure to run it as \r\n  \r\n    python vgg_loss.py -p <path_to_vgg_model>\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["I was able to replicate issue with given code in local for TF-1.14. Thank you!", "I didn't check myself, but does this issue occur in TF2.0? I'm using TF1.14 only because model compilation makes a dummy call to the loss function which involves empty tensors and there are core tf elements, which in 2.0 are eagerly executed by default, so ends up throwing empty tensor errors. ", "I tried it using __Tensorflow 2.0__ and this was the error:- \r\n\r\n    Traceback (most recent call last):\r\n      File \"vgg_loss.py\", line 103, in <module>\r\n        main()\r\n      File \"vgg_loss.py\", line 97, in main\r\n        model.compile(optimizer='adam', loss=some_loss, metrics=['accuracy'])\r\n      File \"C:\\Users\\Intel\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\base.py\", line 457, in _method_wrapper\r\n        result = method(self, *args, **kwargs)\r\n      File \"C:\\Users\\Intel\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 373, in compile\r\n        self._compile_weights_loss_and_weighted_metrics()\r\n      File \"C:\\Users\\Intel\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\base.py\", line 457, in _method_wrapper\r\n        result = method(self, *args, **kwargs)\r\n      File \"C:\\Users\\Intel\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 1653, in _compile_weights_loss_and_weighted_metrics\r\n        self.total_loss = self._prepare_total_loss(masks)\r\n      File \"C:\\Users\\Intel\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 1713, in _prepare_total_loss\r\n        per_sample_losses = loss_fn.call(y_true, y_pred)\r\n      File \"C:\\Users\\Intel\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\losses.py\", line 221, in call\r\n        return self.fn(y_true, y_pred, **self._fn_kwargs)\r\n      File \"vgg_loss.py\", line 86, in some_loss\r\n        return mse(vgg_model.predict(y_pred, steps=1), vgg_model.predict(y_true, steps=1))\r\n      File \"C:\\Users\\Intel\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 909, in predict\r\n        use_multiprocessing=use_multiprocessing)\r\n      File \"C:\\Users\\Intel\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\", line 722, in predict\r\n        callbacks=callbacks)\r\n      File \"C:\\Users\\Intel\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\", line 299, in model_iteration\r\n        batch_outs = f(actual_inputs)\r\n      File \"C:\\Users\\Intel\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\", line 3748, in __call__\r\n        [x._numpy() for x in outputs],  # pylint: disable=protected-access\r\n      File \"C:\\Users\\Intel\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\", line 3748, in <listcomp>\r\n        [x._numpy() for x in outputs],  # pylint: disable=protected-access\r\n    AttributeError: 'Tensor' object has no attribute '_numpy'", "I met similar issues in tf=1.14.0 of above. But I can give a workaround solution.\r\n\r\nFirst, for tf=1.14.0 of above you have to explicit assign `y_true` by `label_ref=tf.keras.layers.Input`. Otherwise, tf is not able compute shape.\r\n\r\n```python\r\n            # workaround solution\r\n            if LooseVersion(tf.__version__) < LooseVersion('1.14.0'):\r\n                label_mask  = y_true\r\n                pre_softmax = clf_out\r\n            else:\r\n                label_mask  = label_ref\r\n                pre_softmax = clf_out   \r\n```\r\n\r\nSecond, `label_ref` should be the input and feed to model.\r\n\r\n```python\r\n        # workaround solution\r\n        if LooseVersion(tf.__version__) < LooseVersion('1.14.0'):\r\n            input_list = [clf_input]\r\n        else:\r\n            input_list = [clf_input, label_ref]\r\n```\r\n\r\nThird, you have to adjust the output of the data pipeline and the input for evaluation\r\n\r\n```python\r\n        # workaround solution\r\n        if LooseVersion(tf.__version__) < LooseVersion('1.14.0'):\r\n            outputX = dataX\r\n        else:\r\n            outputX = (dataX, dataY)\r\n```\r\n\r\n```python\r\n    # workaround solution\r\n    if LooseVersion(tf.__version__) < LooseVersion('1.14.0'):\r\n        model.evaluate(testX, testY, verbose=2, batch_size=batch_size)\r\n    else:\r\n        model.evaluate( (testX, testY), testY, verbose=2, batch_size=batch_size)\r\n```\r\n\r\nFinallu, for tf=2.x you have to disable eager_mode at the begin of the program.\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\n# disable eager model for tf=2.x\r\nif LooseVersion(tf.__version__) >= LooseVersion('2.0.0'):\r\n    tf.compat.v1.disable_eager_execution()\r\n```\r\n\r\nThe following is the minimal testcase which works well in tf=1.13.1 or above:\r\n\r\n```python\r\n#%%\r\nfrom distutils.version import LooseVersion\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\n# disable eager model for tf=2.x\r\nif LooseVersion(tf.__version__) >= LooseVersion('2.0.0'):\r\n    tf.compat.v1.disable_eager_execution()\r\n\r\nbatch_size = 100\r\n#%%\r\ndef download_data():\r\n\r\n    # get raw data\r\n    (trainX, trainY), (testX, testY) = tf.keras.datasets.cifar10.load_data()\r\n    trainX = trainX.astype(np.float32)\r\n    testX  = testX.astype(np.float32)\r\n\r\n    # ont-hot\r\n    trainY = tf.keras.utils.to_categorical(trainY, 10)\r\n    testY  = tf.keras.utils.to_categorical(testY , 10)\r\n\r\n    # get validation sets\r\n    training_size = 45000\r\n    validX = trainX[training_size:,:]\r\n    validY = trainY[training_size:,:]\r\n\r\n    trainX = trainX[:training_size,:]\r\n    trainY = trainY[:training_size,:]\r\n\r\n    return trainX, trainY, validX, validY, testX, testY\r\n\r\n#%%\r\ndef data_pipeline(dataX, dataY):\r\n\r\n    # create dataset API\r\n    def preprocess_fn(dataX, dataY):\r\n        \r\n        dataX = tf.image.random_flip_left_right(dataX)\r\n\r\n        # workaround solution\r\n        if LooseVersion(tf.__version__) < LooseVersion('1.14.0'):\r\n            outputX = dataX\r\n        else:\r\n            outputX = (dataX, dataY)\r\n        return outputX, dataY\r\n\r\n    dataset = tf.data.Dataset.from_tensor_slices( (dataX, dataY) )\r\n    dataset = dataset.shuffle(batch_size * 8)\r\n    dataset = dataset.repeat()\r\n    dataset = dataset.batch(batch_size)\r\n    dataset = dataset.map(preprocess_fn, num_parallel_calls=tf.data.experimental.AUTOTUNE)\r\n    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\r\n    return dataset\r\n\r\n#%%\r\nclass custom_model():\r\n    def __init__(self):\r\n\r\n        # custom loss\r\n        def cw_loss(y_true, y_pred):\r\n\r\n            # workaround solution\r\n            if LooseVersion(tf.__version__) < LooseVersion('1.14.0'):\r\n                label_mask  = y_true\r\n                pre_softmax = clf_out\r\n            else:\r\n                label_mask  = label_ref\r\n                pre_softmax = clf_out                \r\n\r\n            # API changed\r\n            if LooseVersion(tf.__version__) < LooseVersion('1.14.0'):\r\n                correct_logit = tf.reduce_sum(label_mask * pre_softmax, axis=1, keep_dims=True)\r\n            else:\r\n                correct_logit = tf.reduce_sum(label_mask * pre_softmax, axis=1, keepdims=True)\r\n\r\n            distance = tf.nn.relu( pre_softmax - correct_logit + (1-label_mask) * 10) \r\n            inactivate = tf.cast( tf.less_equal(distance, 1e-9), dtype=tf.float32)\r\n            weight = tf.keras.layers.Activation('softmax')(-1e9*inactivate + distance)\r\n            loss = tf.reduce_sum((1-label_mask) * distance * weight, axis=1)\r\n            loss = tf.math.reduce_mean(loss)\r\n            return loss\r\n\r\n        # API changed\r\n        if LooseVersion(tf.__version__) < LooseVersion('2.0.0'):\r\n            model = tf.keras.applications.ResNet50(include_top=True, weights=None, input_shape=(32,32,3), pooling='max', classes=10)\r\n        else:\r\n            model = tf.keras.applications.resnet.ResNet50(include_top=True, weights=None, input_shape=(32,32,3), pooling='max', classes=10)\r\n\r\n        clf_input = tf.keras.layers.Input(shape=(32,32,3), name=\"model/input\")\r\n        label_ref = tf.keras.layers.Input(shape=(10,) , name='label_ref')\r\n        clf_out   = model(clf_input)\r\n\r\n        # workaround solution\r\n        if LooseVersion(tf.__version__) < LooseVersion('1.14.0'):\r\n            input_list = [clf_input]\r\n        else:\r\n            input_list = [clf_input, label_ref]\r\n    \r\n        clf_model = tf.keras.models.Model(inputs=input_list, outputs=clf_out, name='clf_model')\r\n        clf_model.compile(loss='categorical_crossentropy', optimizer='SGD', metrics=['accuracy', cw_loss])\r\n\r\n        self.clf_model = clf_model\r\n\r\n#%%\r\nif __name__ == '__main__':\r\n\r\n    # set GPU\r\n    import os\r\n    if os.environ.get(\"CUDA_VISIBLE_DEVICES\") is None:\r\n        os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\r\n\r\n    # reset tf session\r\n    tf.compat.v1.keras.backend.clear_session()\r\n    gpu_options = tf.compat.v1.GPUOptions(allow_growth=True)\r\n    sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options))\r\n    tf.compat.v1.keras.backend.set_session(sess) \r\n\r\n    # prepare data\r\n    trainX, trainY, validX, validY, testX, testY = download_data()\r\n    train_gen = data_pipeline(trainX, trainY)\r\n    valid_gen = data_pipeline(validX, validY)\r\n    test_gen = data_pipeline(testX, testY)\r\n\r\n    # build targeted model\r\n    targeted_model = custom_model()\r\n    model = targeted_model.clf_model\r\n    \r\n    # fit and evalutate\r\n    model.fit(train_gen,\r\n            steps_per_epoch = trainY.shape[0] // batch_size,\r\n            validation_data = valid_gen,\r\n            validation_steps= validY.shape[0] // batch_size,\r\n            epochs=5,\r\n            verbose=2)\r\n\r\n    # workaround solution\r\n    if LooseVersion(tf.__version__) < LooseVersion('1.14.0'):\r\n        model.evaluate(testX, testY, verbose=2, batch_size=batch_size)\r\n    else:\r\n        model.evaluate( (testX, testY), testY, verbose=2, batch_size=batch_size)\r\n```\r\n\r\nThe output in tf=1.13.1:\r\n\r\n```\r\nEpoch 1/5\r\n - 33s - loss: 2.4371 - acc: 0.2622 - cw_loss: 9.9063 - val_loss: 1.9639 - val_acc: 0.3262 - val_cw_loss: 9.8715\r\nEpoch 2/5\r\n - 26s - loss: 1.8737 - acc: 0.3829 - cw_loss: 9.8150 - val_loss: 1.8466 - val_acc: 0.4072 - val_cw_loss: 9.8049\r\nEpoch 3/5\r\n - 26s - loss: 1.6805 - acc: 0.4436 - cw_loss: 9.7643 - val_loss: 1.5574 - val_acc: 0.4428 - val_cw_loss: 9.7727\r\nEpoch 4/5\r\n - 26s - loss: 1.5725 - acc: 0.4780 - cw_loss: 9.7303 - val_loss: 1.5726 - val_acc: 0.4788 - val_cw_loss: 9.7395\r\nEpoch 5/5\r\n - 26s - loss: 1.5086 - acc: 0.5021 - cw_loss: 9.7073 - val_loss: 2.6803 - val_acc: 0.3964 - val_cw_loss: 9.8093\r\n - 4s - loss: 2.8093 - acc: 0.3939 - cw_loss: 9.8100\r\n```\r\n\r\nThe output in tf=1.14.0:\r\n\r\n```\r\nEpoch 1/5\r\n450/450 - 20s - loss: 2.5021 - acc: 0.2659 - cw_loss: 9.9067 - val_loss: 2.7677 - val_acc: 0.3236 - val_cw_loss: 9.8703\r\nEpoch 2/5\r\n450/450 - 13s - loss: 1.9023 - acc: 0.3856 - cw_loss: 9.8141 - val_loss: 2.2765 - val_acc: 0.4022 - val_cw_loss: 9.8072\r\nEpoch 3/5\r\n450/450 - 13s - loss: 1.6946 - acc: 0.4444 - cw_loss: 9.7639 - val_loss: 1.9999 - val_acc: 0.4464 - val_cw_loss: 9.7686\r\nEpoch 4/5\r\n450/450 - 13s - loss: 1.5590 - acc: 0.4810 - cw_loss: 9.7266 - val_loss: 1.5991 - val_acc: 0.4850 - val_cw_loss: 9.7293\r\nEpoch 5/5\r\n450/450 - 13s - loss: 1.4503 - acc: 0.5138 - cw_loss: 9.6943 - val_loss: 1.4578 - val_acc: 0.4950 - val_cw_loss: 9.6983\r\n10000/10000 - 3s - loss: 1.4257 - acc: 0.5055 - cw_loss: 9.6953\r\n```\r\n\r\nThe output in tf=2.0.0:\r\n\r\n```\r\n450/450 - 41s - loss: 2.3526 - accuracy: 0.3121 - cw_loss: 9.8773 - val_loss: 1.6616 - val_accuracy: 0.3846 - val_cw_loss: 9.8367\r\nEpoch 2/5\r\n450/450 - 30s - loss: 1.8045 - accuracy: 0.4361 - cw_loss: 9.7745 - val_loss: 2.3301 - val_accuracy: 0.4514 - val_cw_loss: 9.7658\r\nEpoch 3/5\r\n450/450 - 31s - loss: 1.6255 - accuracy: 0.4912 - cw_loss: 9.7207 - val_loss: 2.2725 - val_accuracy: 0.4530 - val_cw_loss: 9.7586\r\nEpoch 4/5\r\n450/450 - 30s - loss: 1.5215 - accuracy: 0.5255 - cw_loss: 9.6794 - val_loss: 5.8537 - val_accuracy: 0.4990 - val_cw_loss: 9.7133\r\nEpoch 5/5\r\n450/450 - 30s - loss: 1.4084 - accuracy: 0.5554 - cw_loss: 9.6447 - val_loss: 1.4579 - val_accuracy: 0.5442 - val_cw_loss: 9.6705\r\n10000/10000 - 3s - loss: 1.5397 - accuracy: 0.5363 - cw_loss: 9.6739\r\n```", "Ok I'll try to give this a try and get back to you in a week. ", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34866\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34866\">No</a>\n"]}, {"number": 34865, "title": "[TF2.0]how to save model to get .pb in this example?", "body": "\r\nhttps://www.tensorflow.org/tutorials/text/nmt_with_attention\r\nIn this [example](https://www.tensorflow.org/tutorials/text/nmt_with_attention) ,how to save model to get .pb ? \r\n\r\nI tried this way, but have some bugs.\r\nwhat should I do? \r\n```\r\ntf.saved_model.save(decoder, \"./decoder_out/1\")\r\ntf.saved_model.save(encoder, \"./encoder_out/1\")\r\n\r\n\r\nencoder = tf.saved_model.load('./encoder_out/1')\r\ndecoder = tf.saved_model.load('./decoder_out/1')\r\n\r\nsentence = u'\u00bftodavia estan en casa?'\r\nattention_plot = np.zeros((max_length_targ, max_length_inp))\r\nsentence = preprocess_sentence(sentence)\r\n    \r\ninputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\r\ninputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],maxlen=max_length_inp,padding='post')\r\n    \r\n    \r\ninputs = tf.convert_to_tensor(inputs)\r\nresult = ''\r\nhidden = [tf.zeros((1,units))]\r\nenc_out, enc_hidden = encoder(inputs, hidden)\r\n\r\n\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-59-ba6b7bf7814b> in <module>\r\n     10 result = ''\r\n     11 hidden = [tf.zeros((1,units))]\r\n---> 12 enc_out, enc_hidden = encoder(inputs, hidden)\r\n\r\nTypeError: '_UserObject' object is not callable\r\n\r\n```", "comments": ["the encoder.call  have two parameters. In this way, how to save model (.pd) ?\r\n```\r\nclass Encoder(tf.keras.Model):\r\n  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\r\n    super(Encoder, self).__init__()\r\n    self.batch_sz = batch_sz\r\n    self.enc_units = enc_units\r\n    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\r\n    self.gru = tf.keras.layers.GRU(self.enc_units,\r\n                                   return_sequences=True,\r\n                                   return_state=True,\r\n                                   recurrent_initializer='glorot_uniform')\r\n\r\n  def call(self, x, hidden):\r\n    x = self.embedding(x)\r\n    output, state = self.gru(x, initial_state = hidden)\r\n    return output, state\r\n\r\n  def initialize_hidden_state(self):\r\n    return tf.zeros((self.batch_sz, self.enc_units))\r\n```", "@SmileTM @oanush Hi, How did you solve this problem ? I am stuck in this problem for several days, hoping your reply, thanks.", "> @SmileTM @oanush Hi, How did you solve this problem ? I am stuck in this problem for several days, hoping your reply, thanks.\r\n\r\nIn tensorflow2.0,  if you have  two parameters or more  parameters\uff0c we need follow this code\uff1a\r\n\r\n```\r\nclass MyLayer(tf.keras.layers.Layer):\r\n    def __init__(self,**kwargs):\r\n        super(MyLayer, self).__init__(**kwargs)\r\n    def call(self, inputs):\r\n        a,b,c,d = inputs\r\n        e = a+b+c+d\r\n        return e\r\n\r\nlayer = MyLayer()\r\nresult = layer((a,b,c,d))    \r\n ```\r\n two parameters or more  parameters need to be packed by list or tuple in `def call`. \r\nIf your parameters not be packed by list or tuple, it will have some errors when you deploy `.pd` in your server .\r\n\r\nthe `.pd`, just use `model.save('path')` can be getten.", "> > @SmileTM @oanush Hi, How did you solve this problem ? I am stuck in this problem for several days, hoping your reply, thanks.\r\n> \r\n> In tensorflow2.0, if you have two parameters or more parameters\uff0c we need follow this code\uff1a\r\n> \r\n> ```\r\n> class MyLayer(tf.keras.layers.Layer):\r\n>     def __init__(self,**kwargs):\r\n>         super(MyLayer, self).__init__(**kwargs)\r\n>     def call(self, inputs):\r\n>         a,b,c,d = inputs\r\n>         e = a+b+c+d\r\n>         return e\r\n> \r\n> layer = MyLayer()\r\n> result = layer((a,b,c,d))    \r\n> ```\r\n> \r\n> two parameters or more parameters need to be packed by list or tuple in `def call`.\r\n> If your parameters not be packed by list or tuple, it will have some errors when you deploy `.pd` in your server .\r\n> \r\n> the `.pd`, just use `model.save('path')` can be getten.\r\n\r\nThanks for your quick reply, I will try.", "@SmileTM Hi, I opened a issue: https://github.com/tensorflow/tensorflow/issues/37439, which also is similar,  TypeError: '_UserObject' object is not callable, can you have a quick look, or any suggestions ? Thanks."]}, {"number": 34864, "title": "Update array ops docstrings", "body": "Moved from old PR https://github.com/tensorflow/tensorflow/pull/34360\r\nOld assignee: @gbaned , waiting  for review from @alextp ", "comments": ["@alextp, I noticed something confusing while adding the changes:\r\nSee [gist with `tf.function`](https://colab.research.google.com/gist/nikochiko/33ae06dd81f74585cf6c8ab1858e0f30/ensure-shape-1.ipynb) and [gist with `tf.placeholder` and python list](https://colab.research.google.com/gist/nikochiko/278f7dac1a00c0ca79d60b85b5fba7b2/ensure-shape-2.ipynb). It is unclear whether the error thrown should be `InvalidArgumentError` or `ValueError` when the shapes are incompatible. Is this a bug or a documentation issue?", "The example with tf.function I had in mind was something like\r\n\r\n```\r\n@tf.function(signature=[tf.TensorSpec(dtype=tf.float32, shape=None)])\r\ndef f(x):\r\n  tf.ensure_shape(x, [3, 3])\r\n\r\nf(tf.zeros([3, 3]) # Does nothing\r\nf(tf.ones([1, 2]) # fails\r\n", "@alextp Okay. \ud83d\udc4d I will add such an example.\r\nBut what I was trying to bring to your attention is that the documentation says the function will throw an `InvalidArgumentError` when the shape is not compatible. But in the gists, it throws `ValueError` for some cases too. Thus I was asking if that is a bug or a documentation issue. \r\nr2.1 Documentation for `tf.ensure_shape`:  https://www.tensorflow.org/versions/r2.1/api_docs/python/tf/ensure_shape#returns ", "Ah we need to fix the docs then.\n\nOn Tue, Dec 10, 2019 at 11:33 AM Kaustubh Maske Patil <\nnotifications@github.com> wrote:\n\n> @alextp <https://github.com/alextp> Okay. \ud83d\udc4d I will add such an example.\n> But what I was trying to bring to your attention is that the documentation\n> says the function will throw an InvalidArgumentError when the shape is\n> not compatible. But in the gists, it throws ValueError for some cases\n> too. Thus I was asking if that is a bug or a documentation issue.\n> r2.1 Documentation for tf.ensure_shape:\n> https://www.tensorflow.org/versions/r2.1/api_docs/python/tf/ensure_shape#returns\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/34864?email_source=notifications&email_token=AAABHRL76CACNR5FBUANI5DQX7VG7A5CNFSM4JVXHJA2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEGQSCVI#issuecomment-564207957>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAABHRNBNRQC3RZ3OIOIS53QX7VG7ANCNFSM4JVXHJAQ>\n> .\n>\n\n\n-- \n - Alex\n", "@alextp I have updated the example. Looks good now?\r\nSorry for the delay, I am participating in GCI as well so was hooked with some tasks.", "@nikochiko Can you please address Ubuntu Sanity errors? Thanks!", "@gbaned The sanity check failures were being caused by the doctest output lines which went over 80 chars. I used a backslash and moved the part after 80 columns to an unindented new line. ([see new commits](https://github.com/tensorflow/tensorflow/pull/34864/commits/2f3f3ee15bbc837a22b33c6177e064b5b92d5fec)) as per https://stackoverflow.com/questions/13395610/wrapping-python-doctest-results-that-are-longer-than-80-characters Is this syntax consistent with the TensorFlow documentation?", "I hopefully fixed the doctest errors which were causing the Ubuntu CPU check to fail.", "@rthadur Sorry about the doctest failures, there was only one this time and I fixed it in the new commit. ", "@nikochiko Can you please resolve conflicts? Thanks!", "Ping on resolving conflicts", "Thanks for the ping, I had missed the earlier comment.\r\nWill commit by tomorrow", "I manually fixed it, accepting both forms of the doctest, as one is a `tf.function`, the other one is assuming eager execution.", "@nikochiko Can you please resolve conflicts? Thanks!", "Manually fixed conflict again.", "@mihaimaruseac Thanks for the fixes! :smile: "]}, {"number": 34863, "title": "use 'grpc + verbs' appears (core dumped)", "body": "When I change the protocol to 'grpc + verbs' for RDMA training, the program will have a core dump:\r\n\r\nINFO tensorflow 140500786698048 Create CheckpointSaverHook.\r\nINFO tensorflow 140500786698048 Start Tensorflow server.\r\ntensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job chief\r\n...\r\ntensorflow / contrib / verbs / rdma.cc: 159] Check failed: num_devs_with_active_port> 0 There is no active port in the system\r\n(core dumped)\r\n\r\nMy underlying environment is ROCE\uff0c25worker+16ps\r\nIs it my environmental problem? The program works when I use protocol to 'grpc'.\r\nI want to know what is causing this error and how to fix it\uff1f", "comments": ["Can you please elaborate about the issue & the context.Will it be possible to provide related code.It helps us in localizing the issue faster.Also, let us know which Tensorflow version you are using?Thanks!", "@Richie-yan You could run a basic test of your RoCE environment by `ibv_devinfo`. It appears to me that all of your IB/RDMA ports are down.", "@byronyi  \r\nI use ibstat for testing. The mlx5_0 Port 1 status of several machines is Active, and I can run rdma traffic using ib_write_bw\r\n", "@Richie-yan Then you could try setting ENV VARS `RDMA_DEVICE` and `RDMA_DEVICE_PORT` manually. See https://github.com/tensorflow/tensorflow/blob/r1.15/tensorflow/contrib/verbs/rdma.cc#L129-L162 for the underlying logic.", "@Richie-yan \r\n\r\nwas this resolved by following @byronyi  suggestion? . Thanks!", "@Richie-yan \r\n\r\nAny update on this issue please. Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 34862, "title": " tf.feature_column.shared_embeddings supports eager mode ", "body": "**System information**\r\n- TensorFlow version (you are using): TF 2.0.0\r\n- Are you willing to contribute it (Yes/No): No\r\n\r\n**Describe the feature and the current behavior/state.**\r\nUsing tensorflow-2.0.0 with eager mode,  tf.feature_column.shared_embeddings  can not support eager mode. \r\n\r\n**Will this change the current api? How?**\r\nNo.\r\n\r\n**Who will benefit with this feature?**\r\ntf.feature_column.shared_embeddings is a common feature column API\uff0cwe can use it for multiple category_column with embedding parameters.\r\n\r\n**Any Other info.**\r\n", "comments": ["@workingloong \r\nDo you have any use case that requires the feature you are interested in? Please feel free to submit a PR if you have use cases that supports that feature.Thanks!", "We don't have plans for supporting additional features with feature columns at this point. The right solution will come with this [RFC](https://github.com/tensorflow/community/pull/188)", "Has this problem been solved?I had met the same problem"]}, {"number": 34861, "title": "tensorflow gredient Tape", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**:\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with:\r\n\r\n```bash\r\npython -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"\r\n```\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["@yashthesia ,\r\nCan you please fill the details for all the fields in Standard template ?Thanks!", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "@yashthesia ,\r\nAny update on the issue?Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 34860, "title": "Can not load tflite model converted from pytorch", "body": "**System information**\r\n- Win10:\r\n- TensorFlow version=1.15:\r\n\r\n\r\n**Code to generate tflite model**\r\nGenerate the tflite model with cmd\r\n```\r\npython tflite_convert.py \r\n--graph_def_file=./epoch10_model_toco.pb \r\n--output_file=./lite.tflite \r\n--inference_type=QUANTIZED_UINT8 \r\n--mean_values=0 --std_dev_values=1 \r\n--input_arrays=0 --output_arrays=Reshape_136 --input_shape=1,3,120,18,2 \r\n--default_ranges_min=0 --default_ranges_max=6 --post_training_quantize\r\n```\r\n\r\n**Code to load tflite model**\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\n# Load TFLite model and allocate tensors.\r\ninterpreter = tf.lite.Interpreter(model_path=\"converted_model.tflite\")\r\ninterpreter.allocate_tensors()\r\n\r\n# Get input and output tensors.\r\ninput_details = interpreter.get_input_details()\r\nprint(input_details)\r\noutput_details = interpreter.get_output_details()\r\nprint(output_details)\r\n\r\n# Test model on random input data.\r\ninput_shape = input_details[0]['shape']\r\ninput_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\r\ninterpreter.set_tensor(input_details[0]['index'], input_data)\r\n\r\ninterpreter.invoke()\r\n\r\n# The function `get_tensor()` returns a copy of the tensor data.\r\n# Use `tensor()` in order to get a pointer to the tensor.\r\noutput_data = interpreter.get_tensor(output_details[0]['index'])\r\nprint(output_data)\r\n```\r\n\r\n**Error Message**\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"demo.py\", line 97, in <module>\r\n    main()\r\n  File \"demo.py\", line 59, in main\r\n    interpreter = tf.lite.Interpreter(model_path=PATH_TO_TFLITE)\r\n  File \"C:\\Users\\Administrator\\.conda\\envs\\stgcn\\lib\\site-packages\\tensorflow_core\\lite\\python\\interpreter.py\", line 206, in __init__\r\n    model_path))\r\nValueError: Input array not provided for operation 'reshape'.\r\n```\r\n\r\n**If i convert .pb to .tflite without uint8 quantized**\r\n\r\n```\r\npython tflite_convert.py \r\n--graph_def_file=./epoch10_model_toco.pb \r\n--output_file=./lite.tflite \r\n--input_arrays=0 --output_arrays=Reshape_136 --input_shape=1,3,120,18,2 \r\n```\r\n\r\nThen load the tflite without quantized as the same.\r\nStill i got another error message.\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"demo.py\", line 97, in <module>\r\n    main()\r\n  File \"demo.py\", line 60, in main\r\n    interpreter.allocate_tensors()\r\n  File \"C:\\Users\\Administrator\\.conda\\envs\\stgcn\\lib\\site-packages\\tensorflow_core\\lite\\python\\interpreter.py\", line 244, in allocate_tensors\r\n    return self._interpreter.AllocateTensors()\r\n  File \"C:\\Users\\Administrator\\.conda\\envs\\stgcn\\lib\\site-packages\\tensorflow_core\\lite\\python\\interpreter_wrapper\\tensorflow_wrap_interpreter_wrapper.py\", line 106, in AllocateTensors\r\n    return _tensorflow_wrap_interpreter_wrapper.InterpreterWrapper_AllocateTensors(self)\r\nRuntimeError: tensorflow/lite/kernels/transpose.cc Transpose op only supports 1D-4D input arrays.Node number 0 (TRANSPOSE) failed to prepare.\r\n```\r\n\r\nHow can i convert the .pb to the .tflite, which could be loaded.\r\nIs there something wrong in the .tflite layer?How to correct that?", "comments": ["Hi @ambarion, could you please try setting --experimental_new_converter=True to the tflite_convert command line? ", "> Hi @ambarion, could you please try setting --experimental_new_converter=True to the tflite_convert command line?\r\n\r\nThanks for your reply, but i still got the same error.", "Having same issue::\r\nFirst converted pytorch model to onnx(model.onnx). And then converted onnx model to pb(model.pb). Then changed shape to NWHC(model_toco.pb) using https://github.com/paulbauriegel/tensorflow-tools/blob/master/convert-model-to-NWHC.py . Then used below code to convert to tflite.\r\n`converter = tf.lite.TFLiteConverter.from_frozen_graph('model_toco.pb',\r\n                                                          input_arrays=['input0'],\r\n                                                          output_arrays=['output0'] \r\n    )`\r\n    `converter.optimizations = [tf.lite.Optimize.DEFAULT]`\r\n    `tf_lite_model = converter.convert() `\r\n    `open('model_toco.tflite', 'wb').write(tf_lite_model)\r\n`\r\nWhen loading this tflite model on PC... gives the same error.\r\ntf version:: 1.15(pip install)\r\n\r\nAny solutions or way around??", "@ambarion @sanrahul, by quantizing YOLO v3 for TF Lite, I also encounter ValueError: Input array not provided for operation 'reshape'.\r\nI made a script to fix the reshape problems, plz refer to **Quantization** section in [onnx_tflite_yolov3](https://github.com/zldrobit/onnx_tflite_yolov3)", "> @ambarion @sanrahul, by quantizing YOLO v3 for TF Lite, I also encounter ValueError: Input array not provided for operation 'reshape'.\r\n> I made a script to fix the reshape problems, plz refer to **Quantization** section in [onnx_tflite_yolov3](https://github.com/zldrobit/onnx_tflite_yolov3)\r\n\r\nMine has problems of converting pytorch `F.interpolate ` and `torch.view()`. How did you converted `F.interpolate` (which is a part of yolo3 model) to TFlite?", "@Mara\r\n\r\n> > @ambarion @sanrahul, by quantizing YOLO v3 for TF Lite, I also encounter ValueError: Input array not provided for operation 'reshape'.\r\n> > I made a script to fix the reshape problems, plz refer to **Quantization** section in [onnx_tflite_yolov3](https://github.com/zldrobit/onnx_tflite_yolov3)\r\n> \r\n> Mine has problems of converting pytorch `F.interpolate ` and `torch.view()`. How did you converted `F.interpolate` (which is a part of yolo3 model) to TFlite?\r\n\r\nTFLite does not  support *5-dimensional reshape*, so you have to change the output of  [`torch.view()` to 1-4D](https://github.com/zldrobit/onnx_tflite_yolov3/blob/master/models.py#L169) \r\nI haven't seen any problems with `F.interpolate`, what the error message?", "@zldrobit \r\nMost interesting part of output\r\n```\r\n2020-05-13 11:02:11.573396: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: If\r\n2020-05-13 11:02:11.573439: F tensorflow/lite/toco/import_tensorflow.cc:114] Check failed: attr.value_case() == AttrValue::kType (1 vs. 6)\r\n```\r\nAll output\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/marat/OCR/yolo3/torch2tflite.py\", line 127, in <module>\r\n    tflite_model = converter.convert()\r\n  File \"/home/marat/anaconda3/envs/cexp/lib/python3.7/site-packages/tensorflow_core/lite/python/lite.py\", line 1007, in convert\r\n    **converter_kwargs)\r\n  File \"/home/marat/anaconda3/envs/cexp/lib/python3.7/site-packages/tensorflow_core/lite/python/convert.py\", line 457, in toco_convert_impl\r\n    enable_mlir_converter=enable_mlir_converter)\r\n  File \"/home/marat/anaconda3/envs/cexp/lib/python3.7/site-packages/tensorflow_core/lite/python/convert.py\", line 203, in toco_convert_protos\r\n    raise ConverterError(\"See console for info.\\n%s\\n%s\\n\" % (stdout, stderr))\r\ntensorflow.lite.python.convert.ConverterError: See console for info.\r\n2020-05-13 11:02:11.123019: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/home/marat/anaconda3/lib\r\n2020-05-13 11:02:11.123080: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/home/marat/anaconda3/lib\r\n2020-05-13 11:02:11.123089: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\r\n2020-05-13 11:02:11.557879: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2020-05-13 11:02:11.563803: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3407930000 Hz\r\n2020-05-13 11:02:11.564214: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56377f6b4ce0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-05-13 11:02:11.564240: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2020-05-13 11:02:11.565808: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\r\n2020-05-13 11:02:11.568053: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\r\n2020-05-13 11:02:11.568071: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: saturn\r\n2020-05-13 11:02:11.568076: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: saturn\r\n2020-05-13 11:02:11.568107: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 440.64.0\r\n2020-05-13 11:02:11.568126: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 440.64.0\r\n2020-05-13 11:02:11.568131: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 440.64.0\r\n2020-05-13 11:02:11.573396: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: If\r\n2020-05-13 11:02:11.573439: F tensorflow/lite/toco/import_tensorflow.cc:114] Check failed: attr.value_case() == AttrValue::kType (1 vs. 6)\r\nFatal Python error: Aborted\r\n\r\nCurrent thread 0x00007fa391a0b700 (most recent call first):\r\n  File \"/home/marat/anaconda3/envs/cexp/lib/python3.7/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 56 in execute\r\n  File \"/home/marat/anaconda3/envs/cexp/lib/python3.7/site-packages/absl/app.py\", line 250 in _run_main\r\n  File \"/home/marat/anaconda3/envs/cexp/lib/python3.7/site-packages/absl/app.py\", line 299 in run\r\n  File \"/home/marat/anaconda3/envs/cexp/lib/python3.7/site-packages/tensorflow_core/python/platform/app.py\", line 40 in run\r\n  File \"/home/marat/anaconda3/envs/cexp/lib/python3.7/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 93 in main\r\n  File \"/home/marat/anaconda3/envs/cexp/bin/toco_from_protos\", line 8 in <module>\r\nAborted (core dumped)\r\n```", "```\r\n2020-05-13 11:02:11.573396: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: If\r\n2020-05-13 11:02:11.573439: F tensorflow/lite/toco/import_tensorflow.cc:114] Check failed: attr.value_case() == AttrValue::kType (1 vs. 6)\r\n```\r\nIt cannot be confirmed from above that `F.interpolate`  or `torch.view()` is causing the error.\r\nYou may have to check your computation graph with netron to locate the problematic op which is near `If`.\r\nEven to debug Tensorflow/TFLite by yourself (including compilation of debug version code).", "@ambarion Hello, have you salved the problem? I met the same issue.", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information."]}, {"number": 34859, "title": "tf.train.AdamOptimizer doesn't work with custom TPU training loop", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 1.15\r\n- Python version: 3.x\r\n- Bazel version (if compiling from source): n/a\r\n- GCC/Compiler version (if compiling from source): n/a\r\n- CUDA/cuDNN version: n/a\r\n- GPU model and memory: n/a\r\n\r\n**Describe the current behavior**\r\nRun this Colab notebook with a TPU accelerator: https://colab.research.google.com/drive/1bsgSNK3aK9sETlplIPVpAa-yc4q1S3sA\r\n\r\nWhen running the above notebook with `tf.train.AdamOptimizer`, we get:\r\n```\r\nValueError: in converted code:\r\n\r\n    <ipython-input-22-807c7cf92c68>:21 simple_model_fn  *\r\n        train_op = tf.train.AdamOptimizer().minimize(y)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/optimizer.py:413 minimize\r\n        name=name)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/optimizer.py:569 apply_gradients\r\n        self._distributed_apply, args=(grads_and_vars, global_step, name))\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/distribute_lib.py:1940 merge_call\r\n        return self._merge_call(merge_fn, args, kwargs)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/distribute_lib.py:1947 _merge_call\r\n        return merge_fn(self._strategy, *args, **kwargs)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/optimizer.py:717 _distributed_apply\r\n        non_slot_devices, finish, args=(self, update_ops), group=False)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/distribute_lib.py:1577 update_non_slot\r\n        return self._update_non_slot(colocate_with, fn, args, kwargs, group)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/tpu_strategy.py:580 _update_non_slot\r\n        result = fn(*args, **kwargs)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/optimizer.py:713 finish\r\n        return self._finish(update_ops, \"update\")\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/adam.py:228 _finish\r\n        beta1_power, beta2_power = self._get_beta_accumulators()\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/adam.py:115 _get_beta_accumulators\r\n        return (self._get_non_slot_variable(\"beta1_power\", graph=graph),\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/optimizer.py:868 _get_non_slot_variable\r\n        if hasattr(non_slot, \"_distributed_container\"):\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/values.py:827 __getattr__\r\n        return super(TPUVariableMixin, self).__getattr__(name)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/values.py:389 __getattr__\r\n        return getattr(self.get(), name)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/values.py:834 get\r\n        return super(TPUVariableMixin, self).get(device=device)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/values.py:324 get\r\n        return self._device_map.select_for_device(self._values, device)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/values.py:219 select_for_device\r\n        (device, self._devices, device_util.current()))\r\n\r\n    ValueError: Device /job:worker/replica:0/task:0/device:CPU:0 not found in ('/job:worker/replica:0/task:0/device:TPU:0', '/job:worker/replica:0/task:0/device:TPU:1', '/job:worker/replica:0/task:0/device:TPU:2', '/job:worker/replica:0/task:0/device:TPU:3', '/job:worker/replica:0/task:0/device:TPU:4', '/job:worker/replica:0/task:0/device:TPU:5', '/job:worker/replica:0/task:0/device:TPU:6', '/job:worker/replica:0/task:0/device:TPU:7') (current device /job:worker/replica:0/task:0/device:CPU:0)\r\n```\r\n\r\nThis code runs just fine with `tf.train.MomentumOptimizer` and `tf.keras.optimizers.Adam` (run same code with the `optimizer_type` form variable set to `KerasAdam` or `Momentum`).\r\n\r\n**Describe the expected behavior**\r\nCode should run without error using `tf.train.AdamOptimizer`, just like it does for the other optimizers.\r\n\r\n**Code to reproduce the issue**\r\nhttps://colab.research.google.com/drive/1bsgSNK3aK9sETlplIPVpAa-yc4q1S3sA", "comments": ["I have tried on colab with TF version 1.15 and was able to reproduce the issue.Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/340328a62bf9432601cbe8ac5d08cc9e/broken-adamoptimizer-tpu-custom-loop.ipynb). Thanks!", "Is there any reason not to use tf.keras.optimizers.Adam?", "The primary reason, for us, is that Keras' optimizers throw on missing gradients instead of returning None.\r\n\r\nIt's often the case that we have multiple losses in a model. Not all variables are connected to all losses in the graph. Computing the set of variables that are connected to each loss function a priori is somewhat onerous, so we let TF do it for us. We compute the gradients of each loss with respect to all trainable variables and pull out the gradient/variable pairs that have a non-None gradient. Keras optimizers will throw an exception as soon as they encounter a disconnected variable/loss pair so we can't compute any gradients this way.\r\n\r\nWhile we're on the topic of Keras optimizers, the docs refer to `global_step` being incremented if it's non-None (https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam#apply_gradients). As far as I can tell, none of the arguments of any method take `global_step` and the optimizers don't update the `global_step` tensor created by `tf.train.get_or_create_global_step`. What am I missing here?", "optimizer.iterations is the global_step for each optimizer.\r\n\r\nThe apply_gradients for v2 optimizer (TF2) should just print a warning for variables without gradients. See: https://github.com/tensorflow/models/blob/master/official/modeling/model_training_utils.py#L258\r\nI indeed have some variables that are not connected to loss inside bert.\r\n\r\nminimize() will throw an error if there is None.", "@saberkun thanks for the tip on optimizer.iterations.\r\n\r\nThe exception is thrown when computing gradients, not when applying them. You're right that `apply_gradients` is just fine, but `tf.keras.optimizers.Adam.get_gradients` will throw. That's not the case for gradients computed through `tf.train.*Optimizer.compute_gradients`.", "Yes, we have reported this difference. @tanzhenyu\r\nIt is very common that variables without gradients and users may not want to take extra effort to organize which loss should take which set of trainable variables. \r\n\r\ntf.train.*Optimizer does not work because distribution strategy takes a different way to handle cross-replica sum internally. To correctly use TPU, you need CrossSharedOptimizer, but it cannot be used for keras v2 optimizer: https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/tpu/tpu_optimizer.py#L58\r\n\r\nIn my experience, grads = tape.gradient(loss, training_vars) will not assert error for None gradients.\r\nDoes it fit to your case?\r\nHere is the TF 1.x customized training example:\r\nhttps://github.com/tensorflow/tpu/blob/master/models/experimental/resnet50_keras/resnet50_ctl_tf1.py#L131\r\n", "I suppose we could use `GradientTape` to compute gradients instead of the optimizer's methods. It's less convenient, and more work on our part to switch everything over but it will work in general. Thanks for the suggestion.\r\n\r\nGoing back to the original bug report, it's still the case that `AdamOptimizer` can't be used with custom TPU training loops whereas other `tf.train.*Optimizer` classes can. It would be really nice to have consistency both in the semantics of gradient computations across APIs (i.e. anything that computes gradients should return None if the `xs` are not connected to the `ys`) and implementation behavior (i.e. optimizers can be swapped without introducing failures). Are these reasonable expectations to have of TensorFlow?", "I am working with TensorFlow r1.15 and am able to reproduce the same issue.\r\nThe custom TPU training loop works only with tf.train.GradientDescentOptimizer but not with any other optimizer.\r\n\r\nAlso, tf.keras.optimizers.Adam, RMSprop, Adagrad, etc. reports the same error!", "@sharvil -- in this case, the behavior of the v2 tf.keras.optimizers are consistent with the behavior of v1 tf.keras.optimizers, which also threw errors for missing gradients. Ideally, we would not break consistency with the tf.train optimizers, but in this case we had to break one way or the other. Given that we had the capacity to raise informative error messages, and that requiring filtering on the user side seems safer than potentially silently ignoring missing grads in user code, we decided to maintain consistency with the v1 tf.keras.optimizers. ", "@karmel, thanks for the explanation. Ultimately, it's the TF team's decision on the direction to take with the APIs. As a user, my feedback is that the Keras v2 optimizers API is less convenient in this particular case and that friction is why we're choosing to stick with `tf.train.*Optimizer`.\r\n\r\nBack to this bug: I've experimented with other v1 optimizers including `MomentumOptimizer`, `RMSPropOptimizer`, and `AdagradOptimizer`. All of those work just fine. It's only `AdamOptimizer` that seems to run into issues (see Colab notebook I posted in the initial bug report for reproducible examples).", "Hello,\r\n\r\nThanks @karmel for posting the colab notebooks. I'm looking into the same.\r\n\r\nActually, I'm facing similar issues and am curious to know what causes missing gradients to occur in code at the first place.\r\n\r\nAny help in this regard of handling missing gradients in code would be appreciated. \r\n\r\nJust to be specific, (TensorFlow r1.15, Debian Linux) I'm trying to train two models simultaneously inside the TPU custom training loop and both of them were constructed using simple tf.keras layers only. \r\ntf.train.GradientDescentOptimizer works just fine but not others.", "@sharvil @swghosh when you call get_gradients, it should return error information regarding which variable is missing the gradient I think?", "Hello @tanzhenyu!\r\ntf.gradients function is not able to provide any information regarding missing gradients. Also, when used with unconnected_gradients argument,\r\n```python\r\ntf.gradients(loss_value, model.trainable_variables, unconnected_gradients='zero')\r\n```\r\nthe same error is raised with with tf.train.AdamOptimizer.", "Can we move the discussion about gradients into another topic / bug? I was responding to the original question @martinwicke asked about why we're not using Keras optimizers. That discussion doesn't seem to contribute to the issue at hand, i.e. `tf.train.AdamOptimizer` not working with custom TPU training loops.", "@sharvil we provided tf.keras optimizers for use of eager mode, distribution strategy, etc. Those things are bundled through 2.0. We probably don't have plans to fix this for tf.train optimizer anymore, given there will be no more 1.x major versions to be released.\r\nThat said, if you believe the None gradient is truly a hassle, we can consider making it warning instead of error. But might need help on provide concrete examples / use cases before we make make the decision", "On the other hand, using GradientTape is the way to go in 2.0. So filtering out variables with None gradient doesn't seem too bad", "@tanzhenyu, the specific use-case is what I describe in [my comment](https://github.com/tensorflow/tensorflow/issues/34859#issuecomment-562721861) and a concrete example of it is a BERT model that @saberkun describes in [their comment](https://github.com/tensorflow/tensorflow/issues/34859#issuecomment-562726594).\r\n\r\nI understand that there are no more TF 1.x releases, but the `tf.train` APIs are still available in TF 2.x  through `tf.compat.v1.train`. Will bugs in v1.compat still be fixed in new releases of TF?", "@sharvil Unfortunately we don't have further 1.x releases (i.e., 1.16), so please keep using keras optimizers. If filtering gradients for not connected variables is desired, which does make sense, maybe file another issue for it. Meanwhile closing this for now.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34859\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34859\">No</a>\n", "@tanzhenyu, I don't understand your last comment. I agree that there are no more 1.x releases but this API is also exposed in TensorFlow 2.x and fails unexpectedly, as reported in this bug. \r\n\r\nDoes your comment mean that bugs in `v1.compat` will not be fixed in newer TF 2.x releases?", "New features (such as TPU support outside of TPUEstimator) will not\nnecessarily be supported for old (compat.v1) APIs. I believe this is such a\ncase.\n", "Thanks for clarifying, @martinwicke.", "Do we know what's the issue with AdamOptimizer? I'd like to fork it and fix it, because I do need it. `keras.optimizers.Adam` doesn't work for me. All other `tf.train.*Optimizer`s work.\r\n\r\nHere's a simple example where keras's optimizer doesn't work: https://gist.github.com/sherjilozair/db9578005a1520d357e7bd8d4ddc5168\r\n\r\nhttps://hastebin.com/atidadubux.sql\r\n"]}, {"number": 34858, "title": "SparseCategoricalCrossEntropy example contains a mistake in terms of input", "body": "## URL(s) with the issue:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/1cf0898dd4331baf93fe77205550f2c2e6c90ee5/tensorflow/python/keras/losses.py#L493\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nEntries [1,0] and [1,2] of a tensor linked to should be 10 times smaller in order for the second entry to sum up to 1.\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? \r\n\r\nNo, the change seems too small for an expensive TF CI to run. \r\n", "comments": ["Hello Developers ! I am new to open source community and want to contribute to tensorflow.\r\nI got the issue but I dont know how to solve this issue. Any help would highly be appreciated .\r\nThanks..", "@Antymon Can you please check the `master` [here](https://github.com/tensorflow/tensorflow/blob/1d846a29c7879772634e0fd286764259531b63c0/tensorflow/python/keras/losses.py#L520). It was corrected there. Thanks!", "Cool."]}]