[{"number": 47897, "title": "Cleanup expired forward compatibility horizons", "body": "The forward compatibility horizons are expired since last year, so these checks can be safely removed.", "comments": ["It could be nice if CI could check this automatically and a Github bot open a ticket. \r\n/cc @tensorflow/api-owners\r\n\r\nI have this candidates list for 2020\r\n```\r\ntensorflow/python/compat/compat_test.py:45:      self.assertTrue(compat.forward_compatible(2020, 4, 4))\r\ntensorflow/python/debug/lib/debug_v2_ops_test.py:241:    if not compat.forward_compatible(2020, 6, 24):\r\ntensorflow/python/debug/lib/dumping_callback.py:381:      if tf_compat.forward_compatible(2020, 6, 24):\r\ntensorflow/python/debug/lib/dumping_callback.py:384:      if tf_compat.forward_compatible(2020, 7, 1):\r\ntensorflow/python/keras/layers/preprocessing/image_preprocessing.py:680:    if compat.forward_compatible(2020, 8, 5):\r\ntensorflow/python/ops/stateful_random_ops.py:544:    if compat.forward_compatible(2020, 10, 25):\r\ntensorflow/python/ops/stateful_random_ops.py:585:    if compat.forward_compatible(2020, 10, 25):\r\ntensorflow/python/ops/stateful_random_ops.py:669:    if compat.forward_compatible(2020, 10, 25):\r\ntensorflow/python/ops/stateful_random_ops.py:715:    if compat.forward_compatible(2020, 10, 25):\r\ntensorflow/python/ops/stateful_random_ops.py:727:    if compat.forward_compatible(2020, 10, 25):\r\ntensorflow/python/ops/stateful_random_ops.py:799:        if compat.forward_compatible(2020, 10, 25):\r\ntensorflow/python/ops/sparse_ops.py:645:  if separator is None and not tf_compat.forward_compatible(2020, 6, 14):\r\ntensorflow/python/ops/image_ops_impl.py:3126:    if compat.forward_compatible(2020, 8, 14):\r\ntensorflow/python/ops/image_ops_impl.py:5288:      tile_size == 512 and not compat.forward_compatible(2020, 6, 23):\r\ntensorflow/python/ops/embedding_ops.py:560:      if compat.forward_compatible(2020, 5, 14):\r\ntensorflow/python/ops/stateless_random_ops.py:216:      if compat.forward_compatible(2020, 10, 25):\r\ntensorflow/python/ops/stateless_random_ops.py:229:        if compat.forward_compatible(2020, 10, 25):\r\ntensorflow/python/ops/stateless_random_ops.py:238:        if compat.forward_compatible(2020, 10, 25):\r\ntensorflow/python/ops/stateless_random_ops.py:568:    if compat.forward_compatible(2020, 10, 25):\r\ntensorflow/python/distribute/input_lib_test.py:858:    if not reshuffle and not compat.forward_compatible(2020, 5, 22):\r\ntensorflow/python/data/experimental/ops/readers.py:792:    if compat.forward_compatible(2020, 7, 3) or exclude_cols is not None:\r\ntensorflow/python/data/experimental/ops/error_ops.py:66:    if compat.forward_compatible(2020, 8, 26) or log_warning:\r\ntensorflow/compiler/tests/stateful_random_ops_test.py:162:    if compat.forward_compatible(2020, 10, 25):\r\ntensorflow/compiler/tests/stateful_random_ops_test.py:181:    if compat.forward_compatible(2020, 10, 25):\r\ntensorflow/compiler/tests/stateful_random_ops_test.py:218:    if compat.forward_compatible(2020, 10, 25):\r\ntensorflow/compiler/tests/stateful_random_ops_test.py:261:    if compat.forward_compatible(2020, 10, 25):\r\n```\r\n\r\nAnd 2021 candidates\r\n```\r\ntensorflow/python/ops/stateless_random_ops.py:127:  if compat.forward_compatible(2021, 3, 1):\r\ntensorflow/python/ops/stateless_random_ops.py:518:    if compat.forward_compatible(2021, 3, 1):\r\ntensorflow/python/ops/lookup_ops.py:753:      if self._offset != 0 or compat.forward_compatible(2021, 3, 18):\r\n```"]}, {"number": 47896, "title": "Cleanup forward compatibility of random ops", "body": "The forward compatibility horizons are expired, so these checks can be safely removed.", "comments": []}, {"number": 47895, "title": "using ragged tensors with custom loss and metric ", "body": "<em>Please make sure that this is an issue related to performance of TensorFlow.\r\nAs per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:performance_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): NA\r\n- TensorFlow version (use command below): TF 2.4.1\r\n- Python version: 3.8.5\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 11/10\r\n- GPU model and memory: NVIDIA Quadro P2000\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\nTF 2.4.1\r\n\r\n**Describe the current behavior**\r\n\r\nPlease see below link to my code. I am working with ragged tensors. My data is (N, length, features) where length is variable. I do not understand how each epoch takes around 6000 seconds to complete. Is it because of the @tf.autograph.experimental.do_not_convert decorator? Is it because of ragged tensors? Is it because of something else. I have implemented the same but padding each data observation to maximum length (therefore, did not need the custom loss and metric I implemented) and an epoch runs for 200 seconds.\r\n\r\n**Describe the expected behavior**\r\n\r\nUnderstand why using ragged tensors takes so long vs padding to max length.\r\n\r\nUnderstand \r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\nMy issue is not reproducible because I am working with ragged tensors and had to manually change some of the .py files that come with tensorflow. See issue https://github.com/tensorflow/tensorflow/pull/45015 from @pedro-r-marques and many others referencing ragged tensors. If whoever reviews this can manually make the changes then my code should work. \r\n\r\nAnyways here is my code so it helps -- also the data is fictitious. I am dealing with roughly 10 GB of data but the format is the same. A list of 2d lists with unequal sequence length (same feature length).\r\n\r\nhttps://colab.research.google.com/drive/1bXmCKuABlGwjoeTxwk-mBfKA_z7BXWYA?usp=sharing\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\nI had to add the decorator @tf.autograph.experimental.do_not_convert on essentially all functions as otherwise I would get an WARNING as such:\r\n\r\n```\r\nWARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x000001A3835F4040> and will run it as-is.\r\nCause: could not parse the source code of <function <lambda> at 0x000001A3835F4040>: no matching AST found\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\n```\r\n", "comments": ["Hopefully, someone can confirm this but looking into recurrent_v2.py in the call method of the LSTM class it is unfortunately running everything by default on CPU .... Can someone please confirm if one cannot use ragged tensors with GPU when using LSTM layers? In addition, it does not look like the ragged inputs (which are converted to tensors by padding), are passed to an actual LSTM but a plain vanilla RNN (I am seeing a call to K.rnn)?", "@funmathgt,\r\nOn opening the linked Colab notebook, I am facing the below error\r\n![image](https://user-images.githubusercontent.com/57165142/112520444-6ead7c80-8dc1-11eb-82bf-c33d13ba5210.png)\r\n\r\nCould you please provide the required permissions to view the notebook? Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 47894, "title": "Last batch always pad up to the batch size and cause error \"logits and labels must be broadcastable\"", "body": "I'm using tensorflow 2.4.1 on Win 10 and Python 3.8.6.\r\n\r\nWhen I use data generator and reach the last batch of training, the model will always pad up to the full batch size even if the real size is less than that. \r\n\r\nThis will cause an error \"logits and labels must be broadcastable\", which is basically a mismatch of my label size (13x24) and predication size (32x24), which 32 is my batch size and 24 is number of classes. \r\n\r\n```\r\nBATCH_SIZE = 32\r\nNUM_EPOCHS = 1\r\nNUM_CLASSES = 24\r\nTIME_STEPS = 1000\r\n\r\ndef build_model():\r\n    total = ((len(tr_idx) + BATCH_SIZE - 1) // BATCH_SIZE) * NUM_EPOCHS\r\n\r\n    inp1 = layers.Input(shape=(TIME_STEPS, 12))\r\n    # inp2 = layers.Input(shape=2)\r\n\r\n    out = layers.BatchNormalization(axis=1)(inp1)\r\n    out = layers.Conv1D(filters=64, kernel_size=50, strides=10, activation='relu')(out)\r\n    out = layers.Conv1D(filters=64, kernel_size=50, strides=10, activation='relu')(out)\r\n    out = layers.MaxPool1D(pool_size=2)(out)\r\n    out = layers.Flatten()(out)\r\n    out = layers.Dense(NUM_CLASSES*2, activation='relu')(out)\r\n\r\n    out1 = layers.Dense(NUM_CLASSES, activation='softmax')(out)\r\n    out2 = layers.Dense(NUM_CLASSES, activation='softmax')(out)\r\n    out3 = layers.Dense(NUM_CLASSES, activation='softmax')(out)\r\n\r\n    model = models.Model(inp1, [out1, out2, out3])\r\n    model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(learning_rate=keras.experimental.LinearCosineDecay(5e-4, total)))\r\n    # model.summary()\r\n    return model\r\n\r\nmodel = build_model()\r\n```\r\n\r\nHere is my data generator\r\n```\r\nclass datagen:\r\n    def __init__(self, data, batch_size = BATCH_SIZE, branch='train'):\r\n        self.data = data.reset_index(drop=True)\r\n        self.batch_size = batch_size\r\n        self.branch = branch\r\n        self.steps = len(self.data) // self.batch_size\r\n        if len(self.data) % self.batch_size !=0:\r\n            self.steps += 1\r\n\r\n    def __len__(self):\r\n        return self.steps\r\n\r\n    def __iter__(self):\r\n        while True:\r\n            if self.branch == 'train':\r\n                self.data = self.data.sample(frac=1).reset_index(drop=True)\r\n            for i in range(self.steps):\r\n                batch_data = self.data[i * self.batch_size: (i+1) * self.batch_size]\r\n                batch_image_ids = batch_data['ID'].tolist()\r\n                with zipfile.ZipFile('record_step1k.zip', 'r') as zipf:\r\n                    tmp = np.zeros((self.batch_size, TIME_STEPS, 12))\r\n                    for cnt, id in enumerate(batch_image_ids):\r\n                        x = zipf.read(id)\r\n                        tmp[cnt] = np.frombuffer(x).reshape((12, -1)).transpose()\r\n                if self.branch == 'train':\r\n                    yield tmp, [keras.utils.to_categorical(batch_data['Dx_1'], NUM_CLASSES), \r\n                                keras.utils.to_categorical(batch_data['Dx_2'], NUM_CLASSES),\r\n                                keras.utils.to_categorical(batch_data['Dx_3'], NUM_CLASSES)]\r\n                else:\r\n                    yield tmp\r\n```", "comments": ["Found the issue. In the data generator should change ``` tmp = np.zeros((self.batch_size, TIME_STEPS, 12))``` to ``` tmp = np.zeros((len(batch_data), TIME_STEPS, 12))```"]}, {"number": 47892, "title": "Nit: Fix listing formats for inline docs.", "body": "Fix some inline docs that contain incorrectly-formatted lists. For example, docs for `x` in [`predict_on_batch`](https://www.tensorflow.org/api_docs/python/tf/keras/Model?hl=en#predict_on_batch).", "comments": ["@tomerk do you know why `ready to pull` label will trigger another build without commit?"]}, {"number": 47891, "title": "OSError: Cannot understand given URI: <tf.Tensor 'filepath:0' shape=() dtype=string>.", "body": "Dear All,\r\nI am trying to implement a deep learning model using .tiff files\r\nTo read them I use skimage but I have difficulties to create a tensor flow dataset:\r\nI did:\r\ndataset_train = tf.data.Dataset.from_tensor_slices((X_train_path, y_train_path))\r\ndataset_train = dataset_train.map(lambda x, y : [load_image(x), load_image(y)], num_parallel_calls=-1).batch(32)\r\nWhere:\r\ndef load_image(filepath):\r\n    # read file\r\n    im = skimage.io.imread(filepath)\r\n    return im\r\n\r\nand X_train_path is an object containing the list of the tif files\r\n\r\nI have the following error message:\r\n    OSError: Cannot understand given URI: <tf.Tensor 'filepath:0' shape=() dtype=string>.\r\n\r\nImages are encoded on 4 channels.\r\nCan you help me ?", "comments": ["@jthibaut \r\n\r\nCan you please refer to similar issue and let u know: [link](https://stackoverflow.com/questions/57008293/use-tf-data-dataset-for-ppm-files)", "Thanks\r\nI already saw this solution but it does not work for .tiff files !", "@jthibaut \r\nPlease share stand alone code such that we can replicate the issue reported such that we can replicate the issue, or if possible share a colab gist with the error.", "Fine ! How can I do because I have a lot of pictures and I prefer to work on standalone rather than on collab as it is heavy each time to upload pictures and I have a limited workspace ?", "@jthibaut \r\nUse \r\n```python\r\ndef load_image(filepath):\r\n    # read file\r\n    im = skimage.io.imread(filepath.numpy())\r\n    return im\r\n```", "If I do that I have the following message:\r\n    AttributeError: 'Tensor' object has no attribute 'numpy'", "Can you see it on collab ?\r\nhttps://colab.research.google.com/drive/1H70CJKwaLNtxFWZDlw2vHZbFCapDlIz5#scrollTo=38owJ0189MbR", "@jthibaut \r\nI don't have access, can you share it as a gist?", "I am sorry I am not proficient with github\r\n\r\nhttps://github.com/jthibaut/Landscape-identification2/blob/main/MODEL1.ipynb\r\n", "no problem\r\n", "@jthibaut \r\nOk, so you may try 2 things:\r\n1. Remove the `@tf.function` decorator, as it executes in graph mode, and thus the values are not inferred using `.numpy()` function.\r\n2. If that doesn't work, execute `tf.enable_eager_execution()` as soon as you import tensorflow.\r\n\r\nHope this helps.", "@jthibaut \r\nInstall tensorflow_io using `!pip install tensorflow_io` and then\r\n\r\nTry this :\r\n```python\r\nimport tensorflow_io as tfio\r\n\r\ndef load_image(filepath):\r\n  img = tfio.experimental.image.decode_tiff(\r\n   tf.io.read_file(filepath),\r\n   index=0\r\n  )\r\n  return img\r\n```\r\n", "Thanks !\r\nIt seems to work but my data sets seems to be empty:\r\n`dataset_train = tf.data.Dataset.from_tensor_slices((X_train_path, y_train_path))`\r\n`dataset_train`\r\n<TensorSliceDataset shapes: ((), ()), types: (tf.string, tf.string)>\r\n`dataset_train = dataset_train.map(lambda x, y : [load_image(x), load_image(y)], num_parallel_calls=-1).batch(32)`\r\n`dataset_train`\r\n<BatchDataset shapes: ((None, None, None, None), (None, None, None, None)), types: (tf.uint8, tf.uint8)>", "I am not sure about the reason for not showing the output shape, but the dataset itself is not empty. You can check that by running this code : \r\n```python\r\nfor ds in dataset_train.take(1):\r\n print(ds)\r\n```", "Thanks ! It work but I have a new problem: I used a U-net architecture and if I give as a loss function 'categorical_crossentropy' I have the following error message:\r\nInvalidArgumentError:  logits and labels must be broadcastable: logits_size=[2097152,10] labels_size=[2097152,4]\r\n\t [[node categorical_crossentropy/softmax_cross_entropy_with_logits (defined at <ipython-input-93-b64f662a0ca4>:1) ]] [Op:__inference_train_function_20000]\r\n\r\nFunction call stack:\r\ntrain_function\r\n\r\nI try to predict 10 classes of pictures. I have pictures with 4 channels. I don't konw if it explains the figures [2097152,10] and [2097152,4]. And I don't know how to check these parameters !", "can you post the code for the same, meanwhile check if the labels shape that is your `y`  which should be same as your output shape that is `logits_size`  ", "I put the link here:\r\nhttps://colab.research.google.com/drive/1h63P4DhR3RJLu48IOSbgfgUz1eFYpFyj\r\n", "I don't have access to this, when you share code through Colab select \"Anyone with the link\" instead of \"Restricted\" after clicking on \"Get Link\" option, this way people can see your code but can't edit.If you want, you can either choose \"Viewer\" , \"Commenter\" (they can only comment) or \"Editor\" ( can edit your code too). In your case,\"viewer\" seems fine too.", "Does it work here ?\r\nhttps://gist.github.com/jthibaut/d947b0956b0738f508163d7d876ee89e\r\n\r\n", "Yes, I can see this one. Your outputs is of shape `(None, 256, 256, 10)`, the first one i.e. \"None\" is just your batch size. Now, In your case your dataset have two images, the second one is your label which is of shape `(256, 256, 4)`. Now you are using `sparse_categorical_loss` which is used when you have multiple classes for training. Now in here, you have two images that is your \"input image\" and \"mask\" . So using this loss function might not be the right choice.\r\n\r\nTry changing these and see if it works for you : \r\n\r\n- try to tweak your model to get the correct shape for your labels which is `mask` in your case\r\n-  then use `MSE` loss instead \r\n\r\nand if you can, it would be much better to explain what is you trying to do with your model. I have never worked with U-net.So I have a very limited idea about this architecture.", "Yes, indeed ! I should have begun by that !\r\nI just finished a training in data science and, in the frame of this training we had a project (taken from a kaggle competition) to perform but we (were 2) did not succeed to finish because we did not habe any help.\r\nIt was a cloud cell segmentation; try to find 4 shapes of clouds:\r\nhttps://gist.github.com/jthibaut/8b8ceb4f5e1842a018d0ed017f8406e8\r\n\r\nSo, to train, I found a data challenge:\r\nhttps://challengedata.ens.fr/participants/challenges/48/\r\nhttps://github.com/earthcube-lab/challenge-ens/blob/master/README.md\r\n\r\nThe aim is to predict landscape cover (they are 10).\r\nI thought to use a U-need model as it seemed to work for my cloud.\r\nThe problem here, is that the landscapes are not labelled.\r\n\r\nSo, may be, surely, my method is wrong at the beginning.\r\nI don't know how to make appear the landscapes \"classes\". They are supposed to be in the mask files.\r\nI did not want to use their file in order to train myself and also because I have a poor graphic card and no GPU.\r\nSo I want to make it simple, even though I have to limit the number of picture (that's what I did for the clouds because I took only pictures with one shape of cloud).\r\nRegards\r\nThibaut", "@jthibaut \r\nThis is not Build/Installation or Bug/Performance issue. Please post this kind of support questions at [Stackoverflow](https://stackoverflow.com/questions/tagged/tensorflow). There is a big community to support and learn from your questions. GitHub is mainly for addressing bugs in installation and performance. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 47890, "title": "Latest Windows 10 update - Import tensorflow - Kernel dies", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): custom code\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 Pro 19042.867\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:N/A\r\n- TensorFlow installed from (source or binary): binary (conda)\r\n- TensorFlow version (use command below): 2.4.0\r\n- Python version: 3.7.1 (anaconda / spyder 4.1.4)\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: CUDA 11.2 / cuDNN 8.1.0.77\r\n- GPU model and memory: Nvidia Quadro M620\r\n\r\n**Describe the current behavior**\r\nSince the last Windows 10 upgrade, it is impossible to import tensorflow. The kernel dies and restarts.\r\nNon TF python code runs fine\r\n\r\n**Describe the expected behavior**\r\nImport tensorflow as usual :)\r\n\r\n**Standalone code to reproduce the issue**\r\n`import tensorflow as tf`\r\n\r\n2021-03-18 17:10:01.890125: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\r\n\r\nKernel died, restarting\r\n\r\n\r\n \r\n2021-03-18 17:10:01.890125: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\r\n[SpyderKernelApp] WARNING | No such comm: 12ee0da4880411ebac01b6d88ae4f6b5\r\n\r\n\r\n", "comments": ["@MaudDestree,\r\nCould you please install TensorFlow outside the conda environment and check if you are facing the same issue. Thanks!", "Hello,\r\nDo you mean I need to re-install a complete env including python etc ?\r\nDo you have any hint to do that while keeping my Anaconda env ?\r\nBtw, using another Anaconda env working with TF 1.14, I don't face the same issue (still I need TF2)\r\nThank you", "@MaudDestree,\r\nPlease follow [this guide](https://www.tensorflow.org/install/pip#1.-install-the-python-development-environment-on-your-system) to create a new virtual environment and install TensorFlow in it. Thanks!", "@amahendrakar \r\nI have re-installed everything (without Anaconda) and now it is running fine. \r\nThank you", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47890\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47890\">No</a>\n"]}, {"number": 47889, "title": "Rename tf.keras.optimizers to tf.keras.optims for more aesthetic import statements", "body": "TensorFlow imports are often tedious, and i think it would be nice if some of the most common imports from `tensorflow.keras` aligned better with one another. For this reason, I propose that `tf.keras.optimizers` be renamed to `tf.keras.optims`.\r\n\r\n```python\r\nfrom tensorflow.keras.models import *\r\nfrom tensorflow.keras.layers import *\r\nfrom tensorflow.keras.losses import *\r\nfrom tensorflow.keras.optims import *\r\n```\r\n\r\nrather than\r\n\r\n```python\r\nfrom tensorflow.keras.models import *\r\nfrom tensorflow.keras.layers import *\r\nfrom tensorflow.keras.losses import *\r\nfrom tensorflow.keras.optimizers import *\r\n```", "comments": ["@Ryan-Rudes,\r\nUsing **`Optimizers`**  in the `Import` statements make code readable than **`optims`**. Can you please elaborate your request and also specify some potential disadvantages of the current notation? Thanks!", "It is disadvantageous to write out \u201coptimizers\u201d because it is tedious, and considering 3 other highly substantial `tensorflow.keras` modules (`models`, `layers`, and `losses`) are all comprised of 6 letters, it would provide better alignment to abbreviate optimizers to optims (also 6 characters). PyTorch uses `torch.optim` presumably for it is shorter and honestly does not impact readability very much at all. `tf.compat` (compatibility) and `tf.config` (configuration) are similar in that they are modules that are written as 6-character abbreviations written in a similar manner, so the argument that `tf.keras.optims` would impact readability contradicts the fact that TensorFlow already uses `tf.compat` to denote the compatibility module.", "Hi @Ryan-Rudes, changing top-level api naming tends to be a very involved, risky, general super controversial topic in any widely-used library and can cause serious backwards compatibility issues. We definitely can't rename `optimizers` to `optims` without undertaking serious risk and causing a backwards compatibility headache for existing users. At most we could add an alias of `keras.optims` in addition to `keras.optimizers`.\r\n\r\nBut, given how past discussions around potential aliases went (e.g. aliasing tf.keras.optimizers/tf.keras.layers under tf.optimizers/tf.layers), I'm inclined to say these 4 characters (`izer`) aren't worth the complexity, potential risk, or organizational work that would be required to get consensus on something like this.\r\n\r\nGood development tooling should be able to autocomplete the rest of `optimizers` for you regardless, so it would purely be a minor aesthetic change at best."]}, {"number": 47888, "title": "Tensorflow lite micro 2.4 Alpha version missing tflite::ops::micro::Register_FULLY_CONNECTED()", "body": "**System information**\r\n- Arduino Nano BLE 33 SENSE \r\n- Arudino Pro IDE Alpha 0.1.4 macos \r\n\r\n\r\n**Provide the text output from tflite_convert**\r\n\r\n```\r\n#tensorflow lite micro missing Register_FULLY_CONNECTED() layer in version 2.4 alpha when upload the Arduino IDE recommend with \"Register_UNPACK();\" but somehow it still fixing the issue during upload the problem is solved when i return back to TFlite micro version 2.1 !!!\r\nis there any replacement layer here ????? '\r\n\r\nplease helps thank you so much for who answer this question \r\n```\r\n\r\n**Standalone code to reproduce the issue** \r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\nAlso, please include a link to a GraphDef or the model if possible.\r\n\r\n**Any other info / logs**\r\n\r\nInclude any logs or source code that would be helpful to diagnose the problem.\r\nIf including tracebacks, please include the full traceback. Large logs and files\r\nshould be attached.\r\n", "comments": ["Apologies for the delay in response? \r\nI don't see TF 2.4 alpha distribution available, Can you please test with latest version of TF 2.4.1 or TF 2.5.0rc1? Thanks", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Yes Thank you for your response The problem is solved!!\n\nOn Fri, Apr 23, 2021 at 6:09 AM tensorflow-butler[bot] <\n***@***.***> wrote:\n\n> This issue has been automatically marked as stale because it has not had\n> recent activity. It will be closed if no further activity occurs. Thank you.\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/47888#issuecomment-825215622>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AK2AIHKVVXPIH7LHZDP2BMTTKCNAFANCNFSM4ZM46HIQ>\n> .\n>\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47888\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47888\">No</a>\n"]}, {"number": 47887, "title": "Change head command to use -n instead of --lines", "body": "When running the `renode_download.sh`, the following line breaks on OSX:\r\n\r\n```\r\n LATEST_RENODE_VERSION=`echo \"${RELEASES_JSON}\" |grep 'tag_name' |\\\r\n      head --lines 1 | grep --extended-regexp --only-matching '[0-9]+\\.[0-9]+\\.[0-9]+'`\r\n```\r\n\r\n`head` on OSX only accepts as options `-n` or `-c`. Changing this to `-n 1` works in the same way and is compatible with both OSX and Linux.\r\n\r\n\r\nLine that caused this issue:\r\n\r\n```\r\nmake -f tensorflow/lite/micro/tools/make/Makefile TARGET=bluepill hello_world_bin\r\n```", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n", "Thanks for the PR. With https://github.com/tensorflow/tensorflow/pull/47842, we are changing the Renode download script and it will no longer use head so that should adress compatibility with OSX.\r\n\r\nI am closing this PR but please let me know if things do not work for you once https://github.com/tensorflow/tensorflow/pull/47842 is merged.", "@advaitjain this looks great, thanks for pointing it out!"]}, {"number": 47886, "title": "Segmentation Fault when Benchmarking TFLite EfficientNetB0 ", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.02/Android 10\r\n- Mobile devices: Xiaomi Redmi Note 7 & Huawei P30\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): 2.4.1\r\n- Python version: 3.8\r\n\r\n**Describe the current behavior**\r\nWhen running the TFLite benchmark of a converted `EfficientNetB0` model on a mobile phone, I get a `Segmentation fault` error. I would be interested in any ideas of what could be causing this, if it is coming from the `.tflite` file or when running the benchmark. I am quite lost and have no idea where to look. Thanks in advance!\r\n\r\n**Describe the expected behavior**\r\nGet the profiling of the model.\r\n\r\n**Standalone code to reproduce the issue**\r\nI am generating the `tflite` file with the following script:\r\n```\r\nimport tensorflow as tf\r\nimport tensorflow_datasets as tfds\r\n\r\n# Create model\r\nmodel = tf.keras.applications.EfficientNetB0(include_top=False)\r\n\r\n\r\n# Create MNIST dataset\r\nds = tfds.load(\r\n    name=\"coco/2017\",\r\n    split=\"train\",\r\n    data_dir=\"/data/datasets/tensorflow_datasets/\",\r\n)\r\nds = ds.map(lambda obj: tf.image.resize(obj[\"image\"], (224, 224)))\r\n\r\n# Transform the dataset into a representative dataset as in the TF guide\r\ndef representative_data_gen():\r\n    for input_value in ds.batch(1).take(100):\r\n        # Model has only one input so each data point has one element.\r\n        yield [input_value]\r\n\r\n\r\n# Converter\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\n\r\n# Set the representative dataset in order to quantize the activations\r\nconverter.representative_dataset = representative_data_gen\r\n\r\n# Ensure that if any ops can't be quantized, the converter throws an error\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\r\nconverter.target_spec.supported_types = [tf.int8]\r\n\r\n# Set the input and output tensors to uint8 (APIs added in r2.3)\r\nconverter.inference_input_type = tf.uint8\r\nconverter.inference_output_type = tf.uint8\r\n\r\n# Additional tricks\r\nconverter.experimental_new_converter = True\r\nconverter.experimental_new_quantizer = True\r\nconverter.target_spec.supported_ops = [\r\n    tf.lite.OpsSet.TFLITE_BUILTINS,  # enable TensorFlow Lite ops.\r\n]\r\n\r\ntf_lite_quant_model = converter.convert()\r\n\r\n# saving converted model in TFLite file\r\nwith open(\"EfficientNetB0.tflite\", \"wb\") as tf_file:\r\n    tf_file.write(tf_lite_quant_model)\r\n\r\nprint(\"Converted\")\r\n```\r\nI use the TFLite benchmarking tool that can be downloaded [here](https://storage.googleapis.com/tensorflow-nightly-public/prod/tensorflow/release/lite/tools/nightly/latest/android_arm_benchmark_model)\r\n\r\nI am running the benchmark with the successive commands : \r\n```\r\nadb push android_arm_benchmark_model /data/local/tmp/benchmark\r\nadb shell chmod +x /data/local/tmp/benchmark\r\nadb push EfficientNetB0.tflite /data/local/tmp/model.tflite\r\nadb shell /data/local/tmp/benchmark --graph=/data/local/tmp/model.tflite --use_gpu=false\r\nadb shell rm -f /data/local/tmp/benchmark\r\nadb shell rm -f /data/local/tmp/model.tflite\r\n```", "comments": ["@yann-pourcenoux could you provide the converted model if the model is sharable? And could you also provide what kind of error message you see from the execution of the benchmark tool?", "Yes, of course, the model is the following [EfficientNetB0.zip](https://github.com/tensorflow/tensorflow/files/6167299/EfficientNetB0.zip) and has been generated with the script above.\r\nThe full log when running the benchmark above is :\r\n```\r\nSTARTING!\r\nLog parameter values verbosely: [0]\r\nGraph: [/data/local/tmp/model.tflite]\r\nUse gpu: [0]\r\nLoaded model /data/local/tmp/model.tflite\r\nINFO: Initialized TensorFlow Lite runtime.\r\nThe input model file size (MB): 5.1575\r\nInitialized session in 3.188ms.\r\nRunning benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.\r\nSegmentation fault \r\n```\r\n", "@yann-pourcenoux if you inspect your model with tools such as [`netron`](https://github.com/lutzroeder/netron), you can see that your model have 1x1x1x3 input, which looks weird. Forutunately, the model you converted has dynamic-size tensors, so you can try something like\r\n\r\n```\r\nbenchmark_model --graph=EfficientNetB0.tflite --input_layer=input  --input_layer_shape=1,224,224,3\r\n```", "By specifying `--input_layer_shape` or by creating the model with a fixed input shape I could fix the `segmentation fault` problem. But now I added a custom layer and I get a \r\n``` \r\nERROR: tensorflow/lite/kernels/strided_slice.cc:156 op_context.input->type != op_context.output->type (3 != 1)\r\nERROR: Node number 476 (STRIDED_SLICE) failed to prepare.\r\n```\r\nThe node where the error happens can be seen on this [image](https://user-images.githubusercontent.com/43449205/111805496-5d500600-88d1-11eb-840b-e393e7542e3f.png).\r\nDo you have any idea what could be causing this problem?  I didn't find a relevant answer online. \r\nThe full model is attached [here](https://github.com/tensorflow/tensorflow/files/6172459/model-EB0-full-fixed.zip).\r\n\r\n", "To avoid that problem I changed the slicing operations with `tf.unstack()` and got rid of that error.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47886\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47886\">No</a>\n"]}, {"number": 47885, "title": "I hope that the tfjs-models project will increase the configuration resource link method", "body": "Hi guys, I used tfjs-models project on my vue project for the first time today, and I also successfully launched posenet and handpose. Thank you for your contribution, but due to some special reasons, I cannot open tfhub.dev Just like google.com, I found that tfhub.dev will redirect to storage.googleapis.com, I can access storage.googleapis.com normally, and there is no problem running posenet, but handpose will fail to load mode, so I hope it can Provide a url method to configure the model, easy to replace https://github.com/tensorflow/tfjs-models/blob/master/handpose/src/index.ts 28 lines 38 lines 48 lines links.\r\n\r\nMy English is not very good, this is machine translation, thank you again for your contribution", "comments": ["@yulong88888 \r\nThis i not the Tfjs repo,please move this issue to closed status and open it in the correct repo.", "@Saduf2019 Sorry, I can't find the issue option in https://github.com/tensorflow/tfjs-models, can you help me", "I completed the requirement by code overwriting"]}, {"number": 47884, "title": "Return gradient 0 in mixed_precison setting", "body": "**System information**\r\n\r\nOS Platform and Distribution: linux\r\nTensorFlow version (use command below): tf2.4.1\r\n\r\n**Reproducing code**\r\n\r\n```\r\n\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras import layers\r\nfrom tensorflow.keras import mixed_precision\r\nimport numpy as np\r\nfrom tqdm import tqdm\r\n\r\ngpus = tf.config.experimental.list_physical_devices('GPU')\r\n\r\nfor gpu in gpus:\r\n    tf.config.experimental.set_memory_growth(gpu, True)\r\n\r\n\r\nmixed_precision.set_global_policy('mixed_float16')\r\n\r\n\r\ndef forward_conv(x, filters, kernels, name='forward', padding='same'):\r\n    i = 0\r\n    for flt, kernel in zip(filters, kernels):\r\n        x = layers.Conv3D(flt, kernel, activation='relu', padding=padding, dilation_rate=(1, 1, 1),\r\n                          use_bias=False, name=str(i) + '_' + name)(x)\r\n        x = layers.BatchNormalization(name=str(i) + '_bn_' + name)(x)\r\n        i += 1\r\n    return x\r\n\r\n\r\ndef part_one(ipt):\r\n    l1 = forward_conv(ipt, (4, 4), (3, 3), name='enc1')\r\n    d2 = layers.MaxPool3D(pool_size=(2, 2, 2))(l1)\r\n    l2 = forward_conv(d2, (4, 4), (3, 3), name='enc2')\r\n    return l1, l2\r\n\r\n\r\ndef part_inner(ipt1, ipt2):\r\n    l1 = forward_conv(ipt1, (4, 4), (3, 3), name='enc1')\r\n    l2 = forward_conv(ipt2, (4, 4), (3, 3), name='enc2')\r\n    return l1, l2\r\n\r\n\r\ndef part_two(ipt1, ipt2):\r\n    l2 = forward_conv(ipt2, (4, 4), (3, 3), name='dec2')\r\n    u1 = layers.UpSampling3D(size=(2, 2, 2))(l2)\r\n    r1 = forward_conv(ipt1 + u1, (4, 4), (3, 3), name='dec1')\r\n    return r1\r\n\r\n\r\ninitial = tf.ones([1, 256, 368, 368, 1], dtype=tf.float16)\r\n\r\ntf.random.set_seed(1)\r\n\r\nwith tf.GradientTape() as g:\r\n    g.watch(initial)\r\n    l1_, l2_ = part_one(initial)\r\n    for _ in range(2):\r\n        l1_, l2_ = part_inner(l1_, l2_)\r\n    opt_ = part_two(l1_, l2_)\r\n    loss = tf.reduce_mean(l1_) + tf.reduce_mean(opt_)\r\n    gd = g.gradient(loss, initial)\r\n    print('-' * 100)\r\n    print(f'loss is {loss} and grad is {np.sum(gd)} with ckpt= {ckpt}')\r\n```\r\n\r\n**Behavior description**\r\n\r\nWhen using tf.float32 setting, the result of gradient is reasonable with value around 0.6, however, when shift to tf.float16 with mixed_precision, the gradient is constantly 0. Should we expect that the computed gradient is so different between normal float32 mode and mixed_precision float16 mode? Thank you!\r\n\r\n", "comments": ["I have met the same issue with TF 2.4.1.  It prevents the use of newer features of new hardware.", "I tried to run the code  in TF nightly-2.6.0.dev20210603 & faced different error,please find the gist [here](https://colab.research.google.com/gist/sushreebarsa/72eb0f52a364ea5b3d8dfe33bf64323f/untitled214.ipynb)..Thanks !", "@WingsOfPanda I ran your code and face OOM error. Can you please check and reduce size to run the code successfully? Please check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/b8d5dcea3a6edd597e65af0e6918cd86/untitled214.ipynb). Thanks!\r\n\r\n```\r\nINFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\r\nYour GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: Tesla T4, compute capability 7.5\r\n---------------------------------------------------------------------------\r\nResourceExhaustedError                    Traceback (most recent call last)\r\n<ipython-input-11-2df8642d5ed4> in <module>()\r\n     53     l1_, l2_ = part_one(initial)\r\n     54     for _ in range(2):\r\n---> 55         l1_, l2_ = part_inner(l1_, l2_)\r\n     56     opt_ = part_two(l1_, l2_)\r\n     57     loss = tf.reduce_mean(l1_) + tf.reduce_mean(opt_)\r\n\r\n10 frames\r\n/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\r\n     58     ctx.ensure_initialized()\r\n     59     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\n---> 60                                         inputs, attrs, num_outputs)\r\n     61   except core._NotOkStatusException as e:\r\n     62     if name is not None:\r\n\r\nResourceExhaustedError: OOM when allocating tensor with shape[1,128,184,184,4] and type half on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Conv3D]\r\n```", "@jvishnuvardhan oh sure, u may reduce the initial size\r\n\r\n`initial = tf.ones([1, 256, 368, 368, 1], dtype=tf.float16)`\r\n\r\nto \r\n\r\n`initial = tf.ones([1, 64, 128, 128, 1], dtype=tf.float16)`\r\n\r\nin my code. or even smaller if you need", "btw, I checked with the latest build tf2.5, the result is the same", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "@jvishnuvardhan Hi. Any update? Have you able to run my code after reduce the input size? Thank you!", "@WingsOfPanda Now it is throwing the following error. Can you try installing the version mentioned in the error trace below and then verify whether the issue was resolved or not.\r\n\r\n`NotFoundError: No algorithm worked! Please try upgrading to cuDNN 8.0.5. You are using cuDNN 8.0.4, which has a bug causing this error. [Op:Conv3DBackpropFilterV2]\r\n`\r\n\r\nPlease check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/aa7d422653ad4b3580c0c5911c33ea13/untitled214.ipynb). Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47884\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47884\">No</a>\n", "@jvishnuvardhan hmm, I think I have the correct cuDNN version. on my side I didn't see this error. One more thing, I tried tf2.6 but still facing this problem. Any further suggestions?"]}, {"number": 47883, "title": "Unable to install Tensorflow due to one of the file named \"getObjectTorrentRequest.h\" file , Torrent named file are blocked in various system across organisations.", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform: Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):source\r\n- TensorFlow version:latest\r\n- Python version:3.8\r\n- Installed using virtualenv? pip? conda?:pip\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nUnable to install Tensorflow due to one of the file named \"getObjectTorrentRequest.h\" file , \"Torrent\" named file are blocked in systems across various organisations.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\npip install tensorflow\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n![image](https://user-images.githubusercontent.com/42913143/111647376-6f299e80-8828-11eb-9426-e5c7f8fca466.png)\r\n", "comments": ["@vishalyadav93,\r\nIn this case, could you please download the `.whl` file compatible with your machine form [this link](https://pypi.org/project/tensorflow/2.4.1/#files) and then install it.\r\n\r\nThanks!", "didn't help, even if we try from wheel file, it will somehow put the \"getTorrentRequest.h\" file in my system which is getting blocked due to its name.", "@vishalyadav93,\r\nI did not find any matches for the keyword `torrent` in the TensorFlow source code. Looks like the `getObjectTorrentRequest.h` file is part of the AWS SDK.\r\n\r\nIn this case, could you please get in touch with the administrator of your machine to get the url / file whitelisted. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47883\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47883\">No</a>\n"]}, {"number": 47882, "title": "How Is Padding Calculated for Conv1D,2D,....", "body": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n[https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv1D]()\r\n[https://github.com/tensorflow/tensorflow/blob/v2.4.1/tensorflow/python/keras/layers/convolutional.py#L375-L512]()\r\n[https://github.com/tensorflow/tensorflow/blob/85c8b2a817f95a3e979ecd1ed95bff1dc1335cff/tensorflow/python/keras/layers/convolutional.py#L52]()\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod\r\n\r\n## Description of issue (what needs changing):\r\nAdd clear description of how the amount of convolutional padding is computed as well as conv transpose padding.\r\n\r\n### Clear description\r\nI'm looking for the padding algorithm used to calculate the amount of padding for \"SAME,\" \"VALID,\" etc, but I cannot find it. I've looked at the above links along with some other links to find the algorithm used, but I've only seen class attributes being assigned strings of what \"mode\" to use. I could not find anything that looked like an associated function call or a dict of functions which makes it difficult to read the algorithm or even view pre-made documentation. I have looked elsewhere on the web to find methods of computing the padding size. Those methods do work for some if not most cases, but they aren't universal as many of them fail for an input dimension of 9 (9x1 1D-Conv) with a filter size of 3. In this special case, the amount of padding necessary is 3 (the same size as the filters), and the methods I have found have maxed out at a padding of 1 for both sides of the input which will fail. Also, most posts on StackOverflow are in regards to computing the output dimensions of convolutional layers which isn't what I'm looking for. I have also looked at tf.pad(), but there is no translation from \"SAME\" to an accepted function argument.\r\n\r\nThis is necessary to be able to port the Tensorflow model to a system where Tensorflow cannot run.\r\n\r\nFor example, why should someone use this method? How is it useful?\r\nThis is necessary to be able to port the Tensorflow model to a system where Tensorflow cannot run. It would also be necessary for any porting to other Deep Learning packages.\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\nAs far as I know they are.\r\n\r\n### Parameters defined\r\n\r\nN/A\r\n\r\n### Returns defined\r\n\r\nN/A\r\n\r\n### Raises listed and defined\r\n\r\nN/A\r\n\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n\r\n### Usage example\r\n\r\nN/A\r\n\r\nSee the API guide: https://www.tensorflow.org/community/contribute/docs_ref\r\non how to write testable usage examples.\r\n\r\n### Request visuals, if applicable\r\n\r\nN/A\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs,\r\ndocs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n", "comments": ["@EnderWiggin14 \r\nKindly open a [stackoverflow](https://stackoverflow.com/questions/tagged/tensorflow) issue for this as it is not a bug or feature request, Please post this kind of support questions at Stackoverflow. There is a big community to support and learn from your questions.\r\nThanks!", "I will not open a stackoverflow issue because of the times I have, I have not received a single response. This submitted as a documentation issue which it very much so is. It should not be that difficult for someone familiar with the source code to link me to correct page containing the information that I seek.", "We'll look at improving the documentation around this.\r\nIn the meantime some quick notes:\r\n\r\n`padding` gets passed to tf.nn.convolution, and you can see some formulas here (though not sure what formulas you are vs. aren't looking for).:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/nn/convolution\r\n\r\nWith `valid`, the input is not padded and you just do the convolution.\r\nWith explicit paddings (e.g. https://www.tensorflow.org/api_docs/python/tf/nn/conv2d), you specify exactly how much to pad each dimension.\r\n\r\n`same` is the more subtle one where just enough padding is added to make the input/output height/width match (e.g. conv2d). I guess there your question is exactly how much padding we add and how it gets split across the before/after?\r\n", "@tomerk I am indeed looking for the equations to calculate the total amount of padding used with parameter `same` as well as how Tensorflow splits the front and back padding.\r\n\r\nUnfortunately, the link you have provided does not answer my questions; however, I believe I will need that information eventually, so I thank you for it.", "Can I at least get a link to the source code where the amount of padding is calculated?", "The convolution padding code is found in the actual kernel implementations (not in the python).\r\n\r\nA quick skim of various C++ kernel implementations suggests many of them may be going through here:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/eigen_spatial_convolutions-inl.h#L1661\r\n\r\nThough it'll probably take building up some familiarity with eigen to fully grok what's going on in this method. (I'm not sure if there's anywhere where the logic is shown or applied in a clearer/simple format)", "Thank you! However, now I'm just confused. Starting at the same link as what you posted\r\n\r\n[https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/eigen_spatial_convolutions-inl.h#L1661]()\r\n\r\nit doesn't make sense that \"VALID\" padding would have any kind of padding at all. My understanding is that, for \"VALID\" padding, the input dimension must be mappable from integer space to integer space via division by an integer.\r\n\r\nAdditionally, it doesn't appear that this tells me how much padding is necessary to for \"SAME\" padding. I'm not looking for the `out_height` or the `out_width`. I'm looking for the padding size calculation and how it is split. My understanding from further searches tells me that Tensorflow splits odd numbered padding with the larger split on the right or bottom.\r\n\r\nI repeat, I'm not looking for `output dimensions`. I'm looking for how to calculate `input dimensions+padding`\r\n```\r\nswitch (padding_type) {\r\n    case PADDING_VALID: {\r\n      const TensorIndex InputRowsEff = InputRows + padding_top + padding_bottom;\r\n      const TensorIndex InputColsEff = InputCols + padding_left + padding_right;\r\n      out_height = divup(InputRowsEff - kernelRowsEff + 1, row_stride);\r\n      out_width = divup(InputColsEff - kernelColsEff + 1, col_stride);\r\n      break;\r\n    }\r\n    case PADDING_SAME: {\r\n      eigen_assert(!padding_explicit);\r\n      out_height = divup(InputRows, row_stride);\r\n      out_width = divup(InputCols, col_stride);\r\n      break;\r\n    }\r\n```", "I believe later parts of that method use the  `out_height` and `out_width` to compute which transformations/contractions to use with eigen. It's not super straightforward to understand which is why I gave that caveat.\r\n\r\n+Reedwm who has looked a lot at the details of different convolution paddings and might be able to provide you w/ the info you're looking for more clearly", "There used to be documentation on SAME padding, which is accessible with the wayback machine [here](https://web.archive.org/web/20181116104639/https://www.tensorflow.org/api_guides/python/nn) in the section \"Convolution\". The file with this documentation was deleted in https://github.com/tensorflow/docs/commit/1c81393168e11b106a0b4b7337cee97af3b741b8 (file `nn.md`). We should bring back this padding documentation, updating it to take into account TF2, dilations, and explicit padding.\r\n\r\n/CC @lamberta, do you know where this documentation should be placed? Perhaps on [this page](https://www.tensorflow.org/api_docs/python/tf/nn), but I don't know the corresponding source file corresponding to that page. I'm willing to add and update the documentation if you don't know anyone more suitable to update it.\r\n\r\nAlso, the padding calculations are unfortunately repeated in several places in the code. The easiest-to-understand place is here:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/dec8e0b11f4f87693b67e125e67dfbc68d26c205/tensorflow/core/framework/kernel_shape_util.cc#L45-L54", "Yes, the module overview page is a good place: https://www.tensorflow.org/api_docs/python/tf/nn\r\nAlways an adventure finding the docstring but I believe this is it: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/nn_ops.py#L15\r\n\r\n@yashk2810 Is it feasible to add a \"View in GitHub\" button to the module overview pages?", "@reedwm @lamberta\r\n\r\nI believe these sets of links are what I was looking for. I will have to see if the code linked by reedwm will need a ceil function as mentioned in the docstring laberta linked.\r\n\r\nThank you!"]}, {"number": 47881, "title": "Extracting tf.Variable() in numpy or tensor format for further processing from a ListWrapper()", "body": "Hello there,\r\n\r\nI have a simple question, that I don't seem to find any documentation on regarding it. I am using costume code, and during one of my training loops a ListWrapper Object is created containing some tensor variable.\r\n\r\nInitially when using tf.print() I was able to see the numerical contents of the tensor but not assign to a variable for further processing. \r\n\r\nAfter using tf.compat.v1.flags.tf_decorator.unwrap(x), where x is the initial ListWrapper, I am indeed able to see the tensor in tf.Variable format like that : \r\n\r\n\r\n<bound method ListWrapper.append of ListWrapper([<tf.Variable 'Variable:0' shape=(10, 10) dtype=float32, numpy=                                                                                                                array([[ 0.05768297,  0.        ,  0.        ,  0.        ,  0.        ,                                                                                                                                                                0.        ,  0.        ,  0.        ,  0.        ,  0.        ],                                                                                                                                                             [-0.00587903,  0.01599882,  0.        ,  0.        ,  0.        ,                                                                                                                                                                0.        ,  0.        ,  0.        ,  0.        ,  0.        ],                                                                                                                                                             [-0.0069333 ,  0.00599516,  0.05650787,  0.        ,  0.        ,                                                                                                                                                                0.        ,  0.        ,  0.        ,  0.        ,  0.        ],                                                                                                                                                             [-0.00601203,  0.0059952 , -0.0027298 ,  0.05753344,  0.        ,                                                                                                                                                                0.        ,  0.        ,  0.        ,  0.        ,  0.        ],                                                                                                                                                             [ 0.00507043, -0.00599517, -0.00196748,  0.00593348,  0.03158937,                                                                                                                                                                0.        ,  0.        ,  0.        ,  0.        ,  0.        ],                                                                                                                                                             [-0.00458831,  0.00599515,  0.00015493, -0.00596476, -0.00691961,                                                                                                                                                                0.03968148,  0.        ,  0.        ,  0.        ,  0.        ],                                                                                                                                                             [-0.00672386,  0.00599529,  0.00553486, -0.00642598,  0.00682343,                                                                                                                                                               -0.00884094,  0.05674272,  0.        ,  0.        ,  0.        ],                                                                                                                                                             [-0.00481304,  0.00599513,  0.00011724, -0.00551202, -0.0070322 ,                                                                                                                                                                0.00368161, -0.00388715,  0.05674548,  0.        ,  0.        ],                                                                                                                                                             [-0.00566915,  0.00599517, -0.00349799, -0.00581874, -0.00713581,                                                                                                                                                               -0.0043654 , -0.00537512, -0.00558803,  0.05750472,  0.        ],                                                                                                                                                             [-0.00441868,  0.00599512,  0.00767725, -0.00547412, -0.00668069,                                                                                                                                                                0.00388396, -0.00506157, -0.00536125, -0.00621854,  0.05662818]],                                                                                                                                                           dtype=float32)>])>   \r\n\r\n\r\nI am not able to subscript or use attributes to recover the variable and store it in numpy format, which would be the easier way for me to recover it in my training loop. \r\n\r\nAny suggesting are highly appreciated.\r\n\r\n\r\n\r\n", "comments": ["@kreouzisv \r\nKindly open a [stackoverflow](https://stackoverflow.com/questions/tagged/tensorflow) issue for this as it is not a bug or feature request, Please post this kind of support questions at Stackoverflow. There is a big community to support and learn from your questions.\r\nThanks!", "I asked in the documentation tab, wasn't a bug or feature request. I figured that you should document how to manipulate the tensorflow object : ListWrapper(). \r\n\r\nAnyways, I was able to extract the numerical values of the list wrapper and store it using:\r\n\r\nwith tf.init_scope():\r\n       store_array = x\r\n\r\nwhere x is the Listwrapper object.\r\n\r\nThanks anyway\r\n", "@kreouzisv \r\nPlease move this issue to closed status if resolved.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47881\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47881\">No</a>\n"]}, {"number": 47880, "title": "Corrected Spell, punctuation and grammar", "body": "- Corrected Spelling in documentations.\r\n- Corrected Punctuations.\r\n- Corrected Grammar mistakes.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F47880) for more info**.\n\n<!-- need_sender_cla -->", "@Palak-15 Can you please sign CLA. Thanks!", "@Palak-15 Can you please sign CLA. Thanks!", "I'm going to go ahead and close this PR, because it seems to have stalled. If you're still interested in pursing this (and responding to my comments), please feel free to reopen!"]}, {"number": 47879, "title": "Keras model functional build of a dynamic lambda layer fails with `RecursionError`", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.4.1\r\n- Python version: 3.8\r\n\r\n**Describe the current behavior**\r\nBuilding a model with dynamic lambda layer fails with exception `RecursionError`\r\n\r\n**Describe the expected behavior**\r\nThe model should build without error.\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\ninput = tf.keras.Input(shape=())\r\noutput = tf.keras.layers.Lambda(lambda x: x, dynamic=True)(input)\r\ntf.keras.Model(inputs=input, outputs=output)\r\n```\r\nOutput:\r\n`RecursionError: maximum recursion depth exceeded while calling a Python object\r\n`\r\n", "comments": ["@nicolaspi,\r\nThis issue has already been addressed in issue [#44906](https://github.com/tensorflow/tensorflow/issues/44906) by members of the TensorFlow community. Could you please go through it. Thanks!", "Indeed, this is a duplicate.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47879\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47879\">No</a>\n"]}, {"number": 47878, "title": "tensorflow 2.4.1 incompatibility with numpy 1.20.1", "body": "Hi, \r\n\r\npip install reports that tensorflow 2.4.1 is incompatible with numpy 1.20.1 as it requires numpy 1.19.x\r\n\r\nIs there any workaround for this right now or are there plans to upgrade requirements to numpy 1.20.x?\r\n\r\nThanks in advance!\r\n\r\n", "comments": ["Not for 2.4.x. For nightly or future releases please subscribe to https://github.com/tensorflow/tensorflow/issues/47691", "@ststeinberg \r\n\r\n As mentioned [here](https://github.com/tensorflow/tensorflow/blob/r2.4/tensorflow/tools/pip_package/setup.py#L84), there is a bound on numpy versions supported by TF2.4 ( ~=1.19.2). Currently numpy version should be >=1.19.2 and < 1.20.\r\n\r\nAs you mentioned in the other issue, downgrading numpy 2.x to the versions mentioned above will work without any issues. \r\nPlease move this to closed status as resolved.\r\nThanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47878\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47878\">No</a>\n", "Closing this ticket and waiting for a solution of #47691."]}, {"number": 47877, "title": " module 'tensorflow.keras.layers' has no attribute 'MulitiHeadAttention'", "body": "When i use the newest version2.4.1 when i use \r\n\r\nhead_attention1 = tf.keras.layers.MulitiHeadAttention(num_heads = 1,key_dim=1)(conv1)\r\n\r\nit will has a AttributeError : module 'tensorflow.keras.layers' has no attribute 'MulitiHeadAttention'", "comments": ["I think you had a typo for [tf.keras.layers.MultiHeadAttention](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MultiHeadAttention).\r\n\r\nIt shouldn't be an issue.", "I'll close this bug. Please reopen it if you still cannot find it in 2.4.1.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47877\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47877\">No</a>\n"]}, {"number": 47876, "title": "Tensorflow not using GPU eventhough it is detecting it.", "body": "**System information**\r\n- I have custom code\r\n- Linux, Ubuntu 20.04\r\n- Not on a mobile device\r\n- Binary\r\n- Tensorflow: v2.4.1\r\n- Python version: python3.8\r\n- CUDA/cuDNN version: v11.0, v8.0.4\r\n- GPU model and memory: Nvidia GTX 1080 Ti, 16 GB\r\n\r\nTensorflow detects my GPU. When I do` tf.config.list_physical_devices()`\r\nI get\r\n\r\n\r\n```\r\n\r\n2021-03-18 13:21:44.097589: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2021-03-18 13:21:44.113342: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\r\n2021-03-18 13:21:44.230424: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \r\npciBusID: 0000:0a:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\r\ncoreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\r\n2021-03-18 13:21:44.230498: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\r\n2021-03-18 13:21:44.248080: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\r\n2021-03-18 13:21:44.248189: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\r\n2021-03-18 13:21:44.257026: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\r\n2021-03-18 13:21:44.261437: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\r\n2021-03-18 13:21:44.277956: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\r\n2021-03-18 13:21:44.285094: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\r\n2021-03-18 13:21:44.288191: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\r\n2021-03-18 13:21:44.295201: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\r\n[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\r\n```\r\n\r\n\r\nBut when I'm training `nvidia-smi`\r\nreturns \r\n\r\n\r\n```\r\nThu Mar 18 13:22:35 2021       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 455.45.01    Driver Version: 455.45.01    CUDA Version: 11.1     |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|                               |                      |               MIG M. |\r\n|===============================+======================+======================|\r\n|   0  GeForce GTX 108...  Off  | 00000000:0A:00.0  On |                  N/A |\r\n| 32%   57C    P0    65W / 250W |    381MiB / 11177MiB |      0%      Default |\r\n|                               |                      |                  N/A |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                                  |\r\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n|        ID   ID                                                   Usage      |\r\n|=============================================================================|\r\n|    0   N/A  N/A      3413      G   /usr/lib/xorg/Xorg                 35MiB |\r\n|    0   N/A  N/A      5526      G   /usr/lib/xorg/Xorg                116MiB |\r\n|    0   N/A  N/A      5669      G   /usr/bin/gnome-shell               96MiB |\r\n|    0   N/A  N/A      7173      G   ...AAAAAAAAA= --shared-files       75MiB |\r\n|    0   N/A  N/A      7628      G   ...AAAAAAAAA= --shared-files       14MiB |\r\n|    0   N/A  N/A      7636      G   ...AAAAAAAA== --shared-files       15MiB |\r\n|    0   N/A  N/A    277380      G   ...AAAAAAAAA= --shared-files       11MiB |\r\n+-----------------------------------------------------------------------------+\r\n\r\n```\r\nIt doesn't look like my GPU is being used.\r\n\r\nI expect the GPU to be used\r\n\r\nI'm just import tensorflow and expecting it to use the GPU, tell me if there's another way.\r\nI remember setting an environment variable `CUDA_VISIBLE_DEVICES` a few versions ago. Is it still necessary to set this?", "comments": ["I've solved the issue, turns out I had to set the environment variable. I'm closing this issue.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47876\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47876\">No</a>\n"]}, {"number": 47875, "title": "Nvidia RTX 3090 is slower than Nvidia GTX 1080Ti for single image prediction", "body": "<em>Please make sure that this is an issue related to performance of TensorFlow.\r\nAs per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:performance_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 2.4.1 (2.2.5 for Keras version)\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 11.2/8.1.0\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nI tried five CNN models (ResNet50, ResNet101, ResNet152, DenseNet121, and MobileNet) to measure their inference time with  batch size one. The CNN models running on 3090 GPU is slower than running on 1080Ti GPU, and both of the devices are slow in eager execution.\r\n| | 3090 GPU (enable eager model) | 3090 GPU (disable eager model) | 1080Ti GPU (enable eager model) | 1080Ti GPU (disable eager model) |\r\n| :---: | :---: | :---: | :---: | :---: |\r\n| ResNet50 | 39.643 ms | 23.588 ms | 25.103 ms | 11.846 ms |\r\n| ResNet101  | 51.097 ms | 36.063 ms | 29.640 ms | 17.598 ms |\r\n| ResNet152  | 50.035 ms | 48.3 ms | 34.169 ms | 22.586 ms |\r\n| DenseNet121  | 52.822 ms | 43.287 ms | 29.565 ms | 18.306 ms | \r\n| MobileNet  | 28.205 ms | 10.332 ms | 21.362 ms | 4.294 ms | \r\n\r\n**Describe the expected behavior**\r\n3090 GPU is faster than 1080Ti GPU.\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\nimport tensorflow\r\nimport numpy\r\nimport time\r\nimport cv2\r\n\u00a0\r\ntensorflow.compat.v1.disable_eager_execution()\r\nkeras_resnet50 = tensorflow.keras.applications.resnet50.ResNet50()\r\nimage = numpy.asarray(cv2.resize(cv2.imread('cat.png'), (224, 224)))\r\ndata = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\r\nkeras_resnet50.predict(data)\r\nt = time.time()\r\nkeras_resnet50.predict(data)\r\nprint((time.time() - t) * 1e6)\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\nTest image: https://raw.githubusercontent.com/dmlc/mxnet.js/main/data/cat.png\r\n", "comments": ["I have the exact same problem. Just replaced my 1080ti with a 3090 and TF 2.4 is very slow (CUDA 11.0)", "Same problem. \r\nI had tested all gpu that i had ,and a lot of combinations.\r\nCUDA : 11.0,11.1,11.2\r\ntensorflow == 2.4.1,tf-nightly-gpu==2.5.0.dev20210320 or 2.5.0.dev20210320\r\nGPU device : rtx3080,3090 ,2080s,2080ti,1080ti\r\n\r\nBest performane always on rtx2080ti, and 3080/3090 worst, but the rtx20 series have stopped production.\r\nRtx30 series extremely slow (training or prediction,1.3~2times)\r\nBig trouble on my product.\r\n\r\nNow i see tf-nightly-gpu==2.6.0.dev released, i hope it can be better.", "> Same problem.\r\n> I had tested all gpu that i had ,and a lot of combinations.\r\n> CUDA : 11.0,11.1,11.2\r\n> tensorflow == 2.4.1,tf-nightly-gpu==2.5.0.dev20210320 or 2.5.0.dev20210320\r\n> GPU device : rtx3080,3090 ,2080s,2080ti,1080ti\r\n> \r\n> Best performane always on rtx2080ti, and 3080/3090 worst, but the rtx20 series have stopped production.\r\n> Rtx30 series extremely slow (training or prediction,1.3~2times)\r\n> Big trouble on my product.\r\n> \r\n> Now i see tf-nightly-gpu==2.6.0.dev released, i hope it can be better.\r\n\r\ndid it resolve your issue? I am going through similar problems now.", "> Same problem.\r\n> I had tested all gpu that i had ,and a lot of combinations.\r\n> CUDA : 11.0,11.1,11.2\r\n> tensorflow == 2.4.1,tf-nightly-gpu==2.5.0.dev20210320 or 2.5.0.dev20210320\r\n> GPU device : rtx3080,3090 ,2080s,2080ti,1080ti\r\n> \r\n> Best performane always on rtx2080ti, and 3080/3090 worst, but the rtx20 series have stopped production.\r\n> Rtx30 series extremely slow (training or prediction,1.3~2times)\r\n> Big trouble on my product.\r\n> \r\n> Now i see tf-nightly-gpu==2.6.0.dev released, i hope it can be better.\r\n\r\nHey @woonkij & @Saptr,\r\nI have similar issue when using Nvidia RTX 3080. I am seeing high inference time & high GPU Memory usage as compared to 2080Ti.\r\n\r\nA single low size model is occupying more gpu memory in 3080 than it is occupying in 2080ti.\r\n\r\nDid you had any memory issues like this?\r\n\r\n_PS_: I tried using [NGC Containers](https://ngc.nvidia.com/catalog/containers/nvidia:tensorflow) but still having the similar issue."]}, {"number": 47874, "title": "Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64", "body": "I'm having issues with lots of stuff and I've a limited amount of knowledge in nvidia drivers. So, I wanted to use my GPU for training in keras. For that, I had to make tensorflow use my GPU(correct me if I'm wrong). I have a supported GPU. I followed [this][1] tutorial. I have a Geforce GTX 1080 Ti. I installed Nvidia driver 455 successfully. I've installed Nvidia Cuda Toolkit 11.2.1 and have tried all three methods of installing. I think CUPTI comes with Nvidia Cuda Toolkit, so, I did nothing for that. and installed cuDNN v8.1.1.33.\r\n\r\n\r\nWhen I import tensorflow and list devices, I get this:\r\n\r\n    >>> tf.config.list_physical_devices()   \r\n    2021-03-18 10:56:30.410381: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n    2021-03-18 10:56:30.411387: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\r\n    2021-03-18 10:56:30.451723: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \r\n    pciBusID: 0000:0a:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\r\n    coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\r\n    2021-03-18 10:56:30.451771: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\r\n    2021-03-18 10:56:30.454059: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\r\n    2021-03-18 10:56:30.454124: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\r\n    2021-03-18 10:56:30.454855: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\r\n    2021-03-18 10:56:30.455023: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\r\n    2021-03-18 10:56:30.455150: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64\r\n    2021-03-18 10:56:30.455675: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\r\n    2021-03-18 10:56:30.455764: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\r\n    2021-03-18 10:56:30.455776: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\r\n    Skipping registering GPU devices...\r\n    [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\r\n\r\n\r\nThis is my LD_LIBRARY_PATH, All these directories exist.\r\n\r\n    export LD_LIBRARY_PATH=/usr/local/cuda-11.2/lib64\r\n    export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda/extras/CUPTI/lib64\r\n    export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda/lib64\r\n\r\n\r\n\r\nI know this issue has been reported before, but the solution there seemed to be reinstalling and I've removed and installed all of the required software multiple times. I'm at this for 4 days now. Also, I installed an outdated Nvidia Cuda toolkit v10 from `apt` once and later removed it.\r\n\r\n\r\nPlease help. Thank you.\r\n\r\n  [1]: https://www.tensorflow.org/install/gpu#software_requirements\r\n\r\n", "comments": ["@tavishm \r\n\r\nWe see that the issue template has not been filled, could you please do so as it helps us analyse the issue [tf version, steps followed before you ran into this error or stand alone code to reproduce the issue faced]\r\n\r\nDo you see the same error with CUDA 11.0. I think you need to downgrade your version of CUDA.\r\n#43947, #45263", "My CUDA version is 11.2.1. Is it not supported? If yes, which version should I downgrade to, and should I downgrade my cuDNN version too? If yes, to what?\r\nThank you", "@tavishm \r\nplease refer to the solved issues i have shared where users have downgraded to 11.0, can you please try the issues and let us know.\r\nYou may also refer to this [link](https://www.tensorflow.org/install/source_windows)", "I'm getting a different error now\r\n`2021-03-18 12:57:34.951501: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.0/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64\r\n`", "I solved this by downgrading cuDNN to 8.0.4", "@tavishm \r\nThank you for your update, glad the issue is resolved, please move this to closed status. [also share the tf version used]", "tf version is 2.4.1.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47874\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47874\">No</a>\n"]}, {"number": 47873, "title": "modernize Python in losses.py and its tests", "body": " - Do not explicitly inherit from `object`.\r\n - Simplify `super()` calls.\r\n - Remove `future` imports.\r\n - Remove uses of `six`.\r\n - Replace `.format()` with f-strings.", "comments": ["@zenogantner Can you please check @mihaimaruseac's comments and keep us posted ? Thanks!", "@zenogantner Can you please resolve conflicts? Thanks!"]}, {"number": 47872, "title": "Multi input/output model works correctly in TF 1.15; produces error in TF 2.4.1", "body": "- TensorFlow version: 2.4.1\r\n- Python version: 3.8.3\r\n\r\n\r\n**Describe the current behavior** \r\nCoded a multi input/output model\r\nmodel.fit fails with the following error:\r\n\r\nValueError: Failed to find data adapter that can handle input: (<class 'list'> containing values of types {\"<class 'numpy.ndarray'>\"}), (<class 'list'> containing values of types {'(<class \\'list\\'> containing values of types {\"<class \\'float\\'>\"})'})\r\n\r\n\r\n**Describe the expected behavior**\r\nCode runs properly as expected in TF 1.15 (with Python 3.6). \r\n\r\n**Standalone code to reproduce the issue**\r\n% Runs properly in TF 1.15\r\nmodel.fit([x1, x2], y.T.tolist(), \r\n                  batch_size=8,\r\n                  epochs=50, verbose=1, shuffle=True,\r\n                  callbacks=[earlystop])\r\n\r\n% where type(x1) is numpy.ndarray\r\n% where x1.shape is (7869, 1, 68)\r\n% where type(x2) is numpy.ndarray\r\n% where x2.shape is (7869, 500)\r\n% where type(y.T.tolist()) is list\r\n% where len(y) is 3\r\n% where type(y) is numpy.ndarray\r\n% where y.shape is (7869, 3)\r\n\r\n**Addendum**\r\n\r\nNote: I referred to [#42175](https://github.com/tensorflow/tensorflow/issues/42175) and ensured x1, x2, and y are np.array. \r\n\r\nmodel.fit([np.asarray(x1), np.asarray(x2)], y, \r\n                  batch_size=8,\r\n                  epochs=50, verbose=1, shuffle=True,\r\n                  callbacks=[earlystop])\r\n\r\nThis produced this error:\r\nTypeError: 'NoneType' object is not callable\r\n", "comments": ["@evancollins1,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code you'd run on TensorFlow v1.15 and v2.4? Thanks!", "*Here is full code to reproduce problem:*\r\n\r\nhttps://colab.research.google.com/drive/1PP9UM4KAiN4K6pKxNyOjYlHf0m49Z9Mx?usp=sharing", "@evancollins1,\r\nOn running the code with [TF v2.4](https://colab.research.google.com/gist/amahendrakar/e01a745291ced3ef687d60341655aa42/47872.ipynb#scrollTo=NdYdsfw8mIJe) and [TF v1.15](https://colab.research.google.com/gist/amahendrakar/3e768eaa20fca8c13c2aa7e1991ef5f2/47872-1-15.ipynb), I am facing the same error stating \r\n```\r\nValueError: Graph disconnected: cannot obtain value for tensor KerasTensor(type_spec=TensorSpec(shape=(None, 500), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\") at layer \"embedding_1\". The following previous layers were accessed without issue: []\r\n```\r\n\r\nPlease check the linked gist for reference. Thanks!", "Hi @amahendrakar, attached below is a link to the functional code to reproduce the issue. Thanks!\r\n\r\nhttps://colab.research.google.com/drive/1PP9UM4KAiN4K6pKxNyOjYlHf0m49Z9Mx?usp=sharing", "@evancollins1,\r\nLooking at similar issue [#35651](https://github.com/tensorflow/tensorflow/issues/35651#issuecomment-582434097), I was able to resolve the `ValueError: Failed to find data adapter that can handle input` error. But now, the code throws a different error. \r\n\r\nPlease find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/bdf382f9913c55a8a8ce75ba0fa2f648/47872.ipynb). Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47872\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47872\">No</a>\n"]}, {"number": 47870, "title": "Confine Tensorflow v2.3.2 C API to use only one thread.", "body": "\r\n\r\n**System information**\r\n- Have I written custom code: No\r\n- OS Platform and Distribution: Linux CentOS 8.3.2011\r\n- TensorFlow installed from: source (https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/lib_package/README.md)\r\n- TensorFlow version: Tensorflow C API v2.3.2 (v2.3.2-0-g9edbe5075f7)\r\n- Python version: 3.6.8\r\n- Bazel version (if compiling from source): 3.7.1\r\n- GCC/Compiler version (if compiling from source): 8.3.1\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: No GPU, 16 GB RAM\r\n\r\n\r\n\r\n\r\n**Describe the current behavior**\r\nTensorflow C API generates multiple threads during inference, with at least one thread on each available CPU.\r\n\r\n**Describe the expected behavior**\r\nThere should be one and only one thread created regardless of hardware setup (E.g. number of CPUs, number of cores etc.)\r\n\r\n**Standalone code to reproduce the issue**\r\nN/A\r\n\r\nI am interested in what source code would change in order to make TensorFlow C API use only 1 thread.\r\n\r\nSome related issues : \r\n- https://github.com/tensorflow/tensorflow/issues/43671\r\n- https://github.com/tensorflow/tensorflow/issues/42510\r\n- https://github.com/usnistgov/frvt/issues/12\r\n\r\nOther issues on Github deal with TensorFlow 1.x API, but I am specifically interested in TensorFlow v2.3.2 C API.\r\n", "comments": ["I'm not an expert, but it looks like environment variables are the easiest way https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/core/common_runtime/process_util.cc#L99", "@bplevin36 Can you elaborate on what exactly will change in that file before building TensorFlow?", "You don't even have to rebuild Tensorflow.  It reads the environment variables at run time.  Just set `TF_NUM_INTEROP_THREADS=1` and `TF_NUM_INTRAOP_THREADS=1` before running your program.", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47870\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47870\">No</a>\n"]}, {"number": 47869, "title": "[TFLM] Removed uint8 support from Softmax", "body": "As discussed https://github.com/tensorflow/tensorflow/issues/47417\r\n\r\nProgress towards https://github.com/tensorflow/tensorflow/issues/44912", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n"]}, {"number": 47868, "title": "clearer commenting dictation", "body": "no visual mush", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F47868) for more info**.\n\n<!-- need_sender_cla -->", "@jonnymiyagi Can you please sign CLA. Thanks!"]}, {"number": 47867, "title": "[Intel MKL] Upgrading to oneDNN 2.1", "body": "", "comments": ["4 github CI tests failed. \r\n`Windows Bazel` and `Windows Bazel GPU` are existing failures.\r\n`TFLite Makefile` doesn't have a log.\r\n`MacOS CPU Python3` has a [very short log](https://source.cloud.google.com/results/invocations/e9aabbda-748e-49d1-9b01-7735fbd4b742/log) that stops right when oneDNN is building. \r\n\r\nI'll rerun the tests to make sure."]}, {"number": 47865, "title": "[TFLM] Remove uint8 support from Quantize", "body": "As discussed https://github.com/tensorflow/tensorflow/issues/47417\r\n\r\nRemoved uint8 support and moved the prepare function into quantize_common.cc\r\n\r\nProgress towards #44912 ", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n", ":frowning_face: Sorry, but only Googlers may change the label `cla: yes`."]}]