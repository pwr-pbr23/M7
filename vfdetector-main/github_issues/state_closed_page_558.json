[{"number": 36969, "title": "[XLA] Change the number of threads per block for row reduction", "body": "This is a follow up from https://github.com/tensorflow/tensorflow/pull/36752\r\n\r\nThis change the number of blocks per threads. It is only the last commit that is the new feature from this PR. The others are already in 36752.\r\n\r\nI didn't change anything in the code. We can start the discussion on how to fix this and I'll update the code accordingly.\r\n\r\nThe number of threads per blocks must be determined by many factors (taken from the previous PR)\r\n\r\n- More threads per blocks mean less atomic writes (as the total number of threads is constant). This is good.\r\n- One SM can't use the full bandwidth per itself. So you need enough blocks to help saturate the IO. I did very small timing, but discarded those results as the noise was too high. There is 80 SM in V100, so ideally we would like at least 80 blocks.\r\n- The last block strangler effect. If you have 81 blocks and 80 SM, then you have 1 that will cause the computation to be as long as if you had 160 blocks. More blocks mean smaller blocks, help mitigate this, as the smaller block will run faster.\r\n- Also, we need at least 64 threads per blocks if we want full occupancy. We are limited to 0.5 occupancy if we use 32 threads per blocks.\r\n- In theory, we could also add a cost model to know if we have a IO or Compute bound kernel (fusion could create compute bound kernel). And in that case we could need different best configuration, as it could be register bound... I do not want to go there.\r\n\r\nThe problem this PR currently have is that it breaks the deterministic reduction on XLA as it is expect exactly 1024 threads per blocks. Making the tree reduction opt know about the new block size is easy (already tested). But this still cause 2 tree reduction failure as now it request 1 extra reduction. This probably slowing down the current tree reduction.\r\n\r\n- Is slowing down the tree reduction acceptable for this PR? If so, I'll just update the expected answer from those tests.\r\n- One option would be to add an attribute to the XLA reduction that would specify the number of threads (example name biggest_block).\r\n    - This isn't very good as this add an implementation detail as a Reduce attribute.\r\n- Another attribute that we could add is: \"deterministic\". This describe a behavior. I could implement that, by making sure we it generates only 1 blocks per row. If not possible, raise an error. It would be the responsibility of the optimizer to have this possible.\r\n  \r\nI like the last approch. It would also help prevent the AlgebraicOptimizer to interfer with the TreeReductionRewriter optimizer, as it could just not touch those graph.\r\n\r\nIf we choose this options, this open the doors to more optimization later. For example, you could remove the memset and replace the atomic update with a normal write at the end of the kernel.\r\n\r\n@cheshire ", "comments": ["I just pushed a new commit that make the tree reduction use the right information following the changes to XLA reduction. Now it will always use the same unroll factor and block size.\r\nSo you should be able to start the benchmark from this commit.\r\n\r\nThe reduction tests pass.", "I rebased this PR to resolve the conflicts.\r\nNote, I didn't update the tests, this PR is in a good state to be benchmarked, but not merged.", "Talked to @cheshire who has the most context here and agreed to take a look. I'm going to remove myself as reviewer.", "@nouiz Can you please resolve conflicts? Thanks!", "I have rebased it.", "@cheshire Can you please review this PR ? Thanks!", "@nouiz I'm generally fine with merging this. Could you add some micro-benchmarks in the commit description demonstrating a speed-up in small artificial test cases?", "I'll work on this probably at the end of this week.", "@nouiz  Any update on this PR? Please. Thanks!", "I'm not able to repro it anymore.  I'm not sure what is going on. As the gain was only for small case, this isn't the most important and I do not have time now to investigate this.\r\nSo I'll close this PR and if I get back to it, I'll make a new one or reopen it."]}, {"number": 36967, "title": "Unable to build tensorflow benchmark tool for android: undefined reference to `vtable for tflite::gpu::cl::SpaceToDepth'", "body": "\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.4 LTS\r\n- TensorFlow installed from (source or binary): Source\r\n- TensorFlow version:  Build from: git clone --recurse-submodules https://github.com/tensorflow/tensorflow.git\r\n- Python version: 3.6.9\r\n- Bazel version (if compiling from source): 2.0.0\r\n- GCC/Compiler version (if compiling from source):gcc (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0\r\n\r\nHere is the bazel workspace configuration:-\r\n\r\n> WARNING: Running Bazel server needs to be killed, because the startup options are different.\r\n> WARNING: ignoring LD_PRELOAD in environment.\r\n> You have bazel 2.0.0 installed.\r\n> Please specify the location of python. [Default is /usr/bin/python3]: \r\n> \r\n> \r\n> Found possible Python library paths:\r\n>   /usr/lib/python3/dist-packages\r\n>   /usr/local/lib/python3.6/dist-packages\r\n> Please input the desired Python library path to use.  Default is [/usr/lib/python3/dist-packages]\r\n> \r\n> Do you wish to build TensorFlow with XLA JIT support? [Y/n]: n\r\n> No XLA JIT support will be enabled for TensorFlow.\r\n> \r\n> Do you wish to build TensorFlow with OpenCL SYCL support? [y/N]: N\r\n> No OpenCL SYCL support will be enabled for TensorFlow.\r\n> \r\n> Do you wish to build TensorFlow with ROCm support? [y/N]: N\r\n> No ROCm support will be enabled for TensorFlow.\r\n> \r\n> Do you wish to build TensorFlow with CUDA support? [y/N]: N\r\n> No CUDA support will be enabled for TensorFlow.\r\n> \r\n> Do you wish to download a fresh release of clang? (Experimental) [y/N]: N\r\n> Clang will not be downloaded.\r\n> \r\n> Please specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native -Wno-sign-compare]: \r\n> \r\n> \r\n> Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: y\r\n> Searching for NDK and SDK installations.\r\n> \r\n> Please specify the home path of the Android NDK to use. [Default is /root/Android/Sdk/ndk-bundle]: /content/tensorflow/android-ndk-r18b\r\n> \r\n> \r\n> Please specify the (min) Android NDK API level to use. [Available levels: ['16', '17', '18', '19', '21', '22', '23', '24', '26', '27', '28']] [Default is 21]: \r\n> \r\n> \r\n> Please specify the home path of the Android SDK to use. [Default is /root/Android/Sdk]: /content/Sdk\r\n> \r\n> \r\n> Please specify the Android SDK API level to use. [Available levels: ['28']] [Default is 28]: \r\n> \r\n> \r\n> Please specify an Android build tools version to use. [Available versions: ['29.0.0']] [Default is 29.0.0]: \r\n> \r\n> \r\n> Preconfigured Bazel build configs. You can use any of the below by adding \"--config=<>\" to your build command. See .bazelrc for more details.\r\n> \t--config=mkl         \t# Build with MKL support.\r\n> \t--config=monolithic  \t# Config for mostly static monolithic build.\r\n> \t--config=ngraph      \t# Build with Intel nGraph support.\r\n> \t--config=numa        \t# Build with NUMA support.\r\n> \t--config=dynamic_kernels\t# (Experimental) Build kernels into separate shared objects.\r\n> \t--config=v2          \t# Build TensorFlow 2.x instead of 1.x.\r\n> Preconfigured Bazel build configs to DISABLE default on features:\r\n> \t--config=noaws       \t# Disable AWS S3 filesystem support.\r\n> \t--config=nogcp       \t# Disable GCP support.\r\n> \t--config=nohdfs      \t# Disable HDFS support.\r\n> \t--config=nonccl      \t# Disable NVIDIA NCCL support.\r\n> Configuration finished`\r\n\r\n`\r\n**Describe the problem**\r\nUnable to compile Tflite benchmark tool for android_arm64 platform.It gives the following error:-\r\n\r\n```\r\n!bazel build -c opt \\\r\n  --config=android_arm64 \\\r\n  tensorflow/lite/tools/benchmark:benchmark_model\r\n```\r\n(Also tried argument options plain arm, cxx-opt 14 etc..)\r\n> Compiling tensorflow/lite/delegates/gpu/common/model_builder.cc; 4s local\r\n> ERROR: /content/tensorflow/tensorflow/lite/tools/benchmark/BUILD:22:1: Linking of rule '//tensorflow/lite/tools/benchmark:benchmark_model' failed (Exit 1)\r\n> bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/cl/selectors/libsimple_selectors.a(simple_selectors.o): In function `tflite::gpu::cl::SelectSpaceToDepth(tflite::gpu::SpaceToDepthAttributes const&, tflite::gpu::cl::OperationDef const&, std::__ndk1::unique_ptr<tflite::gpu::cl::GPUOperation, std::__ndk1::default_delete<tflite::gpu::cl::GPUOperation> >*)':\r\n> /proc/self/cwd/tensorflow/lite/delegates/gpu/cl/selectors/simple_selectors.cc:132: undefined reference to `tflite::gpu::cl::CreateSpaceToDepth(tflite::gpu::cl::OperationDef const&, tflite::gpu::SpaceToDepthAttributes const&)'\r\n> bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/cl/selectors/libsimple_selectors.a(simple_selectors.o): In function `std::__ndk1::__unique_if<tflite::gpu::cl::SpaceToDepth>::__unique_single std::__ndk1::make_unique<tflite::gpu::cl::SpaceToDepth, tflite::gpu::cl::SpaceToDepth>(tflite::gpu::cl::SpaceToDepth&&)':\r\n> /proc/self/cwd/external/androidndk/ndk/sources/cxx-stl/llvm-libc++/include/memory:3114: undefined reference to `tflite::gpu::cl::SpaceToDepth::SpaceToDepth(tflite::gpu::cl::SpaceToDepth&&)'\r\n> bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/cl/selectors/libsimple_selectors.a(simple_selectors.o): In function `~SpaceToDepth':\r\n> /proc/self/cwd/./tensorflow/lite/delegates/gpu/cl/kernels/space_to_depth.h:29: undefined reference to `vtable for tflite::gpu::cl::SpaceToDepth'\r\n> /proc/self/cwd/./tensorflow/lite/delegates/gpu/cl/kernels/space_to_depth.h:29: undefined reference to `vtable for tflite::gpu::cl::SpaceToDepth'\r\n> /proc/self/cwd/./tensorflow/lite/delegates/gpu/cl/kernels/space_to_depth.h:29: undefined reference to `vtable for tflite::gpu::cl::SpaceToDepth'\r\n> /proc/self/cwd/./tensorflow/lite/delegates/gpu/cl/kernels/space_to_depth.h:29: undefined reference to `vtable for tflite::gpu::cl::SpaceToDepth'\r\n> clang: error: linker command failed with exit code 1 (use -v to see invocation)\r\n> Target //tensorflow/lite/tools/benchmark:benchmark_model failed to build\r\n> Use --verbose_failures to see the command lines of failed build steps.\r\n> INFO: Elapsed time: 833.996s, Critical Path: 35.28s\r\n> INFO: 1497 processes: 1497 local.\r\n> FAILED: Build did NOT complete successfully\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n Followed the official GitHub: https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/tools/benchmark\r\n\r\nI tried with NDK 14 and it gave error related to string parsing during compilation. In  18 and 20 NDK versions it gives error related to SpacetoBatch. I tried the compilation in google colab using command line tools for sdk manager for android.", "comments": ["The same problem. I also tried NDK 14b and stricyly followed the official guideline:\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android\r\nto configure the android NDK/SDK, but it didn't work.", "this should resolve this problem\r\n\r\n```diff\r\n--- a/tensorflow/lite/delegates/gpu/cl/selectors/BUILD\r\n+++ b/tensorflow/lite/delegates/gpu/cl/selectors/BUILD\r\n@@ -119,6 +119,7 @@ cc_library(\r\n         \"//tensorflow/lite/delegates/gpu/cl/kernels:resize\",\r\n         \"//tensorflow/lite/delegates/gpu/cl/kernels:softmax\",\r\n         \"//tensorflow/lite/delegates/gpu/cl/kernels:softmax1x1\",\r\n+        \"//tensorflow/lite/delegates/gpu/cl/kernels:space_to_depth\",\r\n         \"//tensorflow/lite/delegates/gpu/cl/kernels:strided_slice\",\r\n         \"//tensorflow/lite/delegates/gpu/cl/kernels:transpose\",\r\n         \"//tensorflow/lite/delegates/gpu/common:operations\",\r\n```", "@freedomtan  By the way which is the recommended NDK version? As per the [documentation](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android#bazel) it seems to be 14b; but it does not seem to work ", "@anilsathyan7 it seems the documentation you mentioned should be updated :-) I was able to build `benchmark_model` and `label_image` using NDK 20.", "> @anilsathyan7 it seems the documentation you mentioned should be updated :-) I was able to build `benchmark_model` and `label_image` using NDK 20.\r\n\r\nThanks for helping. But I met another problem at benchmark build: \"Linking of rule '//tensorflow/lite/tools/benchmark:benchmark_model'\"\r\nI tried to add '//tensorflow/lite/tools/benchmark:benchmark_model' cc_library like that mentioned above but it doesn't work.\r\nCan you help me to address it? Thanks in advance.", "I added that particular line in cc_library and it solved the problem.\r\nThe compilation was successful  and  the benchmark was verified!!!\r\nHere is the benchmark_model binary ...\r\n( I tried it in  google colab using the aforementioned settings  i.e. NDK20, arm_64)\r\n[benchmark_arm64.zip](https://github.com/tensorflow/tensorflow/files/4249247/benchmark_arm64.zip)\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36967\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36967\">No</a>\n", "@PoonKinWang sorry, I don't get exactly what your problem is."]}, {"number": 36966, "title": "Can't save individual models from Tensorflow 1.x Session Checkpoint", "body": "I have a folder containing 3 files\r\n**model.ckpt.data-00000-of-00001\r\nmodel.ckpt.index\r\nmodel.ckpt.meta**\r\n\r\nIt actually contains 3 models (you can check them on tensorboard)\r\n**InceptionV3\r\nTransformNet\r\nVGG16**\r\n\r\nIf you want to check it out\r\nhttps://storage.googleapis.com/download.magenta.tensorflow.org/models/arbitrary_style_transfer.tar.gz\r\n\r\nI want to separate each model to **individual .pb frozen models** and want to use them in web after conversion using tensorflowjs-converter\r\n\r\nI am using below snippet to get InceptionV3(the last node of Iv3 is Conv/BiasAdd)\r\n\r\n```\r\nFileWriter(\"__tb\", sess.graph)\r\n\r\n  \r\n  frozen_graph_def = tf.graph_util.convert_variables_to_constants(\r\n        sess,\r\n        sess.graph_def,\r\n        ['Conv/BiasAdd']) #Output_nodes\r\n\r\n    # Save the frozen graph\r\n  with open('/content/model/IV3.pb', 'wb') as f:\r\n    f.write(frozen_graph_def.SerializeToString())\r\n```\r\n\r\nBut i don't know how to get **transformer model** after **Conv/BiasAdd** node to the output node.\r\n\r\n\r\n\r\n", "comments": ["![tb](https://user-images.githubusercontent.com/58945222/75064984-f0234300-550d-11ea-87e9-08e6136b0bc8.PNG)\r\n", "@VILLAIN511, Please take a look at this [doc](https://www.tensorflow.org/tutorials/keras/save_and_load#save_checkpoints_during_training) for saving checkpoints in Tensorflow. Thanks", "@VILLAIN511, Did you get a chance to look at document provided above.", "Closing this issue since the tittle of the issue is resolved. \r\nPlease feel free to open if issue still persists. Thanks!"]}, {"number": 36965, "title": "SPLIT_V operator support", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (or github SHA if from source):\r\n\r\n\r\n**Provide the text output from tflite_convert**\r\n\r\n```\r\nWARNING:absl:Please consider switching to use new converter by setting experimental_new_converter to true. Old converter (TOCO) is deprecated and flow will be switched on by default to use new converter soon.\r\nTraceback (most recent call last):\r\n  File \"/home/elezhe01/work/scripts/test_gru_cell.py\", line 23, in <module>\r\n    tflite_model = converter.convert()\r\n  File \"/home/elezhe01/.local/lib/python3.6/site-packages/tensorflow/lite/python/lite.py\", line 518, in convert\r\n    self.experimental_new_quantizer)\r\n  File \"/home/elezhe01/.local/lib/python3.6/site-packages/tensorflow/lite/python/lite.py\", line 262, in _calibrate_quantize_model\r\n    inference_output_type, allow_float, enable_mlir_quantizer)\r\n  File \"/home/elezhe01/.local/lib/python3.6/site-packages/tensorflow/lite/python/optimize/calibrator.py\", line 81, in calibrate_and_quantize\r\n    enable_mlir_quantizer)\r\n  File \"/home/elezhe01/.local/lib/python3.6/site-packages/tensorflow/lite/python/optimize/tensorflow_lite_wrap_calibration_wrapper.py\", line 115, in QuantizeModel\r\n    return _tensorflow_lite_wrap_calibration_wrapper.CalibrationWrapper_QuantizeModel(self, *args)\r\nRuntimeError: Quantization not yet supported for op: SPLIT_V\r\n```\r\n\r\n**Standalone code to reproduce the issue** \r\n```\r\nimport tensorflow as tf\r\nimport numpy as numpy\r\n\r\nmodel = tf.keras.Sequential()\r\n\r\nmodel.add(tf.keras.layers.Input(shape=(1, 1,)))\r\n\r\ncell = tf.keras.layers.GRUCell(10)\r\n\r\nmodel.add(tf.keras.layers.RNN(cell, unroll=True))\r\n\r\nmodel.save(\"test_gru_cell.h5\", save_format='h5')\r\n\r\ndef representative_dataset_gen():\r\n    yield [numpy.random.uniform(low=-1, high=1, size=(1,1,1)).astype(numpy.float32)]\r\n\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\r\nconverter.representative_dataset = representative_dataset_gen\r\nconverter.experimental_new_converter = False\r\n\r\ntflite_model = converter.convert()\r\n\r\nopen(\"test_gru_cell.tflite\", 'wb').write(tflite_model)\r\n```\r\n", "comments": ["@wwwind \r\n\r\nYou need to enable tensorflow supported ops as follows.\r\n\r\nconverter.target_spec.supported_ops =[tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\r\n\r\nWith that modification, code works without any error. Here is the [gist](https://colab.sandbox.google.com/gist/ravikyram/a06afd2784199f46e47dec66cc984f30/untitled664.ipynb) for your reference.\r\n\r\nPlease close the issue if it was resolved for you. Thanks!", "Thanks! This option allows to do a proper quantization, but the operator SPLIT_V uses float. There are Quantize and Dequantize nodes around it.\r\n![split_v_quantized](https://user-images.githubusercontent.com/1513336/75151674-2d9af280-56ff-11ea-97ee-50ae5022600e.png)\r\n\r\n", "This PR https://github.com/tensorflow/tensorflow/pull/37016 solved my problem."]}, {"number": 36964, "title": " doesn't support control flow ops:", "body": "**System information**\r\n- OS Platform and Distribution (MAC 10.15.3 (19D76)):\r\n- TensorFlow installed from (binary):\r\n- TensorFlow version (1.15.0):\r\n\r\n\r\n**Provide the text output from tflite_convert**\r\n\r\n```\r\n# Copy and paste here\r\n```\r\n\r\n**Standalone code to reproduce the issue** \r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\nAlso, please include a link to a GraphDef or the model if possible.\r\n\r\n**Any other info / logs**\r\n\r\nInclude any logs or source code that would be helpful to diagnose the problem.\r\nIf including tracebacks, please include the full traceback. Large logs and files\r\nshould be attached.\r\n2020-02-22 01:14:04.085039: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2020-02-22 01:14:04.094983: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa5fe943ce0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-02-22 01:14:04.094997: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\nWARNING:tensorflow:From /Users/lidayuan/opt/anaconda3/envs/py371/lib/python3.7/site-packages/tensorflow_core/lite/python/convert_saved_model.py:60: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nThis function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\r\nW0222 01:14:04.095364 4577779136 deprecation.py:323] From /Users/lidayuan/opt/anaconda3/envs/py371/lib/python3.7/site-packages/tensorflow_core/lite/python/convert_saved_model.py:60: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nThis function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\r\nINFO:tensorflow:Restoring parameters from ./model/variables/variables\r\nI0222 01:14:04.311928 4577779136 saver.py:1284] Restoring parameters from ./model/variables/variables\r\nINFO:tensorflow:The given SavedModel MetaGraphDef contains SignatureDefs with the following keys: {'serving_default'}\r\nI0222 01:14:04.437039 4577779136 convert_saved_model.py:80] The given SavedModel MetaGraphDef contains SignatureDefs with the following keys: {'serving_default'}\r\nINFO:tensorflow:input tensors info: \r\nI0222 01:14:04.437269 4577779136 convert_saved_model.py:99] input tensors info: \r\nINFO:tensorflow:Tensor's key in saved_model's tensor_map: word_ids\r\nI0222 01:14:04.437363 4577779136 convert_saved_model.py:41] Tensor's key in saved_model's tensor_map: word_ids\r\nINFO:tensorflow: tensor name: word_ids:0, shape: (-1, 64), type: DT_INT32\r\nI0222 01:14:04.437431 4577779136 convert_saved_model.py:43]  tensor name: word_ids:0, shape: (-1, 64), type: DT_INT32\r\nINFO:tensorflow:Tensor's key in saved_model's tensor_map: labels\r\nI0222 01:14:04.437486 4577779136 convert_saved_model.py:41] Tensor's key in saved_model's tensor_map: labels\r\nINFO:tensorflow: tensor name: labels:0, shape: (-1, 64), type: DT_INT32\r\nI0222 01:14:04.437530 4577779136 convert_saved_model.py:43]  tensor name: labels:0, shape: (-1, 64), type: DT_INT32\r\nINFO:tensorflow:Tensor's key in saved_model's tensor_map: sequence_lengths\r\nI0222 01:14:04.437580 4577779136 convert_saved_model.py:41] Tensor's key in saved_model's tensor_map: sequence_lengths\r\nINFO:tensorflow: tensor name: sequence_lengths:0, shape: (-1), type: DT_INT32\r\nI0222 01:14:04.437623 4577779136 convert_saved_model.py:43]  tensor name: sequence_lengths:0, shape: (-1), type: DT_INT32\r\nINFO:tensorflow:output tensors info: \r\nI0222 01:14:04.437661 4577779136 convert_saved_model.py:101] output tensors info: \r\nINFO:tensorflow:Tensor's key in saved_model's tensor_map: labels_softmax_\r\nI0222 01:14:04.437716 4577779136 convert_saved_model.py:41] Tensor's key in saved_model's tensor_map: labels_softmax_\r\nINFO:tensorflow: tensor name: Cast:0, shape: (-1, -1), type: DT_INT32\r\nI0222 01:14:04.437761 4577779136 convert_saved_model.py:43]  tensor name: Cast:0, shape: (-1, -1), type: DT_INT32\r\nINFO:tensorflow:Restoring parameters from ./model/variables/variables\r\nI0222 01:14:04.642255 4577779136 saver.py:1284] Restoring parameters from ./model/variables/variables\r\n2020-02-22 01:14:04.806073: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)\r\n2020-02-22 01:14:04.806140: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\r\n2020-02-22 01:14:04.847576: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:786] Optimization results for grappler item: graph_to_optimize\r\n2020-02-22 01:14:04.847595: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   function_optimizer: function_optimizer did nothing. time = 0.003ms.\r\n2020-02-22 01:14:04.847599: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\nWARNING:tensorflow:From /Users/lidayuan/opt/anaconda3/envs/py371/lib/python3.7/site-packages/tensorflow_core/lite/python/util.py:249: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.compat.v1.graph_util.convert_variables_to_constants`\r\nW0222 01:14:04.920840 4577779136 deprecation.py:323] From /Users/lidayuan/opt/anaconda3/envs/py371/lib/python3.7/site-packages/tensorflow_core/lite/python/util.py:249: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.compat.v1.graph_util.convert_variables_to_constants`\r\nWARNING:tensorflow:From /Users/lidayuan/opt/anaconda3/envs/py371/lib/python3.7/site-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.compat.v1.graph_util.extract_sub_graph`\r\nW0222 01:14:04.921000 4577779136 deprecation.py:323] From /Users/lidayuan/opt/anaconda3/envs/py371/lib/python3.7/site-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.compat.v1.graph_util.extract_sub_graph`\r\nINFO:tensorflow:Froze 8 variables.\r\nI0222 01:14:04.977573 4577779136 graph_util_impl.py:334] Froze 8 variables.\r\nINFO:tensorflow:Converted 8 variables to const ops.\r\nI0222 01:14:05.001580 4577779136 graph_util_impl.py:394] Converted 8 variables to const ops.\r\n2020-02-22 01:14:05.044424: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)\r\n2020-02-22 01:14:05.044509: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\r\n2020-02-22 01:14:05.068744: E tensorflow/core/grappler/grappler_item_builder.cc:650] Fetch node labels doesn't exist in graph\r\nTraceback (most recent call last):\r\n  File \"/Users/lidayuan/opt/anaconda3/envs/py371/bin/tflite_convert\", line 8, in <module>\r\n    sys.exit(main())\r\n  File \"/Users/lidayuan/opt/anaconda3/envs/py371/lib/python3.7/site-packages/tensorflow_core/lite/python/tflite_convert.py\", line 515, in main\r\n    app.run(main=run_main, argv=sys.argv[:1])\r\n  File \"/Users/lidayuan/opt/anaconda3/envs/py371/lib/python3.7/site-packages/tensorflow_core/python/platform/app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"/Users/lidayuan/opt/anaconda3/envs/py371/lib/python3.7/site-packages/absl/app.py\", line 299, in run\r\n    _run_main(main, args)\r\n  File \"/Users/lidayuan/opt/anaconda3/envs/py371/lib/python3.7/site-packages/absl/app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"/Users/lidayuan/opt/anaconda3/envs/py371/lib/python3.7/site-packages/tensorflow_core/lite/python/tflite_convert.py\", line 511, in run_main\r\n    _convert_tf1_model(tflite_flags)\r\n  File \"/Users/lidayuan/opt/anaconda3/envs/py371/lib/python3.7/site-packages/tensorflow_core/lite/python/tflite_convert.py\", line 199, in _convert_tf1_model\r\n    output_data = converter.convert()\r\n  File \"/Users/lidayuan/opt/anaconda3/envs/py371/lib/python3.7/site-packages/tensorflow_core/lite/python/lite.py\", line 983, in convert\r\n    **converter_kwargs)\r\n  File \"/Users/lidayuan/opt/anaconda3/envs/py371/lib/python3.7/site-packages/tensorflow_core/lite/python/convert.py\", line 449, in toco_convert_impl\r\n    enable_mlir_converter=enable_mlir_converter)\r\n  File \"/Users/lidayuan/opt/anaconda3/envs/py371/lib/python3.7/site-packages/tensorflow_core/lite/python/convert.py\", line 200, in toco_convert_protos\r\n    raise ConverterError(\"See console for info.\\n%s\\n%s\\n\" % (stdout, stderr))\r\ntensorflow.lite.python.convert.ConverterError: See console for info.\r\n2020-02-22 01:14:07.404666: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-02-22 01:14:07.404703: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-02-22 01:14:07.404722: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-02-22 01:14:07.404731: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-02-22 01:14:07.404784: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-02-22 01:14:07.404792: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-02-22 01:14:07.404812: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-02-22 01:14:07.404822: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-02-22 01:14:07.404938: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3\r\n2020-02-22 01:14:07.404951: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-02-22 01:14:07.404960: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3\r\n2020-02-22 01:14:07.404965: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-02-22 01:14:07.404974: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-02-22 01:14:07.405028: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-02-22 01:14:07.405037: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-02-22 01:14:07.405041: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-02-22 01:14:07.405047: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-02-22 01:14:07.405050: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-02-22 01:14:07.405065: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayScatterV3\r\n2020-02-22 01:14:07.405086: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3\r\n2020-02-22 01:14:07.405091: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-02-22 01:14:07.405099: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3\r\n2020-02-22 01:14:07.405104: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-02-22 01:14:07.405111: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-02-22 01:14:07.405140: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-02-22 01:14:07.405159: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-02-22 01:14:07.405168: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-02-22 01:14:07.405172: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-02-22 01:14:07.405178: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-02-22 01:14:07.405182: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-02-22 01:14:07.405196: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayScatterV3\r\n2020-02-22 01:14:07.405204: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-02-22 01:14:07.405211: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-02-22 01:14:07.405228: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-02-22 01:14:07.405249: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-02-22 01:14:07.405266: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-02-22 01:14:07.405274: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-02-22 01:14:07.405287: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-02-22 01:14:07.405300: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-02-22 01:14:07.405324: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-02-22 01:14:07.405337: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-02-22 01:14:07.405351: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-02-22 01:14:07.405362: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: LoopCond\r\n2020-02-22 01:14:07.405388: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: LoopCond\r\n2020-02-22 01:14:07.405399: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Exit\r\n2020-02-22 01:14:07.405442: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayReadV3\r\n2020-02-22 01:14:07.405453: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArraySizeV3\r\n2020-02-22 01:14:07.405466: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Exit\r\n2020-02-22 01:14:07.405506: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayReadV3\r\n2020-02-22 01:14:07.405516: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArraySizeV3\r\n2020-02-22 01:14:07.405535: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayGatherV3\r\n2020-02-22 01:14:07.405573: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayGatherV3\r\n2020-02-22 01:14:07.405683: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayWriteV3\r\n2020-02-22 01:14:07.405704: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayWriteV3\r\n2020-02-22 01:14:07.410286: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 238 operators, 398 arrays (0 quantized)\r\n2020-02-22 01:14:07.411855: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 228 operators, 382 arrays (0 quantized)\r\n2020-02-22 01:14:07.413998: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 228 operators, 382 arrays (0 quantized)\r\n2020-02-22 01:14:07.414578: W tensorflow/lite/toco/graph_transformations/resolve_constant_random_uniform.cc:88] RandomUniform op outputting \"dropout_1/random_uniform/RandomUniform\" is truly random (using /dev/random system entropy). Therefore, cannot resolve as constant. Set \"seed\" or \"seed2\" attr non-zero to fix this\r\n2020-02-22 01:14:07.416732: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 152 operators, 242 arrays (0 quantized)\r\n2020-02-22 01:14:07.417601: W tensorflow/lite/toco/graph_transformations/resolve_constant_random_uniform.cc:88] RandomUniform op outputting \"dropout_1/random_uniform/RandomUniform\" is truly random (using /dev/random system entropy). Therefore, cannot resolve as constant. Set \"seed\" or \"seed2\" attr non-zero to fix this\r\n2020-02-22 01:14:07.418410: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 2: 151 operators, 241 arrays (0 quantized)\r\n2020-02-22 01:14:07.418796: W tensorflow/lite/toco/graph_transformations/resolve_constant_random_uniform.cc:88] RandomUniform op outputting \"dropout_1/random_uniform/RandomUniform\" is truly random (using /dev/random system entropy). Therefore, cannot resolve as constant. Set \"seed\" or \"seed2\" attr non-zero to fix this\r\n2020-02-22 01:14:07.419965: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 3: 150 operators, 239 arrays (0 quantized)\r\n2020-02-22 01:14:07.420736: W tensorflow/lite/toco/graph_transformations/resolve_constant_random_uniform.cc:88] RandomUniform op outputting \"dropout_1/random_uniform/RandomUniform\" is truly random (using /dev/random system entropy). Therefore, cannot resolve as constant. Set \"seed\" or \"seed2\" attr non-zero to fix this\r\n2020-02-22 01:14:07.421508: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 150 operators, 239 arrays (0 quantized)\r\n2020-02-22 01:14:07.422579: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 150 operators, 239 arrays (0 quantized)\r\n2020-02-22 01:14:07.424002: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 231040 bytes, theoretical optimal value: 231040 bytes.\r\n2020-02-22 01:14:07.424390: I tensorflow/lite/toco/toco_tooling.cc:454] Number of parameters: 3808024\r\n2020-02-22 01:14:07.424903: E tensorflow/lite/toco/toco_tooling.cc:481] We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md\r\n and pasting the following:\r\n\r\nTensorFlow Lite currently doesn't support control flow ops: Enter, Exit, Merge, Switch. We are working on supporting control flow ops, please see github issue at https://github.com/tensorflow/tensorflow/issues/28485. Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, ARG_MAX, CAST, CONCATENATION, FULLY_CONNECTED, GATHER, GREATER_EQUAL, LESS, LOGICAL_AND, LOGISTIC, MAXIMUM, MINIMUM, MUL, PACK, RANGE, REDUCE_MAX, RESHAPE, REVERSE_SEQUENCE, SELECT, SHAPE, SPLIT, STRIDED_SLICE, TANH, TRANSPOSE. Here is a list of operators for which you will need custom implementations: LoopCond, RandomUniform, TensorArrayGatherV3, TensorArrayReadV3, TensorArrayScatterV3, TensorArraySizeV3, TensorArrayV3, TensorArrayWriteV3.\r\nTraceback (most recent call last):\r\n  File \"/Users/lidayuan/opt/anaconda3/envs/py371/bin/toco_from_protos\", line 8, in <module>\r\n    sys.exit(main())\r\n  File \"/Users/lidayuan/opt/anaconda3/envs/py371/lib/python3.7/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 89, in main\r\n    app.run(main=execute, argv=[sys.argv[0]] + unparsed)\r\n  File \"/Users/lidayuan/opt/anaconda3/envs/py371/lib/python3.7/site-packages/tensorflow_core/python/platform/app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"/Users/lidayuan/opt/anaconda3/envs/py371/lib/python3.7/site-packages/absl/app.py\", line 299, in run\r\n    _run_main(main, args)\r\n  File \"/Users/lidayuan/opt/anaconda3/envs/py371/lib/python3.7/site-packages/absl/app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"/Users/lidayuan/opt/anaconda3/envs/py371/lib/python3.7/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 52, in execute\r\n    enable_mlir_converter)\r\nException: We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md\r\n and pasting the following:\r\n\r\nTensorFlow Lite currently doesn't support control flow ops: Enter, Exit, Merge, Switch. We are working on supporting control flow ops, please see github issue at https://github.com/tensorflow/tensorflow/issues/28485. Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, ARG_MAX, CAST, CONCATENATION, FULLY_CONNECTED, GATHER, GREATER_EQUAL, LESS, LOGICAL_AND, LOGISTIC, MAXIMUM, MINIMUM, MUL, PACK, RANGE, REDUCE_MAX, RESHAPE, REVERSE_SEQUENCE, SELECT, SHAPE, SPLIT, STRIDED_SLICE, TANH, TRANSPOSE. Here is a list of operators for which you will need custom implementations: LoopCond, RandomUniform, TensorArrayGatherV3, TensorArrayReadV3, TensorArrayScatterV3, TensorArraySizeV3, TensorArrayV3, TensorArrayWriteV3.\r\n", "comments": ["@yuanlida \r\nSupporting control flow ops is a work in progress.\r\nSee #[28485](https://github.com/tensorflow/tensorflow/issues/28485)"]}, {"number": 36963, "title": "image.resize tensor as size argumentnot working in tf.function", "body": "**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow): custom Layer, using tf.image.resize\r\n- OS Platform and Distribution (e.g.,\r\nLinux Ubuntu 16.04):  Linux Mint 19.3 Cinnamon (Ubuntu based)\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if\r\nthe issue happens on mobile device: No\r\n- TensorFlow installed from (source or\r\nbinary): pip install\r\n - TensorFlow version (use command below): v2.1.0-rc2-17-ge5bf8de 2.1.0\r\n- Python version: 3.6.9\r\n\r\n**Describe the current behavior**\r\nimage.resize is working in eager(standard) mode, with tensor as size argument\r\nstops working if warped in tf.function\r\n\r\n**Describe the expected behavior**\r\nshould work like in eager\r\n\r\npossible reason:\r\nlive tf.function tensor is in the implementation of image.resize not evaluated.\r\nso the cast to a appropriate value fails and None is returned\r\n\r\nError (full):\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/bhb/.vscode/extensions/ms-python.python-2020.2.63990/pythonFiles/ptvsd_launcher.py\", line 48, in <module>\r\n    main(ptvsdArgs)\r\n  File \"/home/bhb/.vscode/extensions/ms-python.python-2020.2.63990/pythonFiles/lib/python/old_ptvsd/ptvsd/__main__.py\", line 432, in main\r\n    run()\r\n  File \"/home/bhb/.vscode/extensions/ms-python.python-2020.2.63990/pythonFiles/lib/python/old_ptvsd/ptvsd/__main__.py\", line 316, in run_file\r\n    runpy.run_path(target, run_name='__main__')\r\n  File \"/usr/lib/python3.6/runpy.py\", line 263, in run_path\r\n    pkg_name=pkg_name, script_name=fname)\r\n  File \"/usr/lib/python3.6/runpy.py\", line 96, in _run_module_code\r\n    mod_name, mod_spec, pkg_name, script_name)\r\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/ShAReD_Net/model/modules/base.py\", line 204, in <module>\r\n    main()\r\n  File \"/home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/ShAReD_Net/model/modules/base.py\", line 191, in main\r\n    out = test_multiscale(inputs)\r\n  File \"/home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/ShAReD_Net/model/modules/base.py\", line 175, in run\r\n    outputs = op(inputs, **kwargs)\r\n  File \"/home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/venv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 822, in __call__\r\n    outputs = self.call(cast_inputs, *args, **kwargs)\r\n  File \"/home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/ShAReD_Net/model/modules/base.py\", line 126, in call\r\n    outs.append(self.hour_glass(ins))\r\n  File \"/home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/venv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 822, in __call__\r\n    outputs = self.call(cast_inputs, *args, **kwargs)\r\n  File \"/home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/ShAReD_Net/model/modules/base.py\", line 62, in call\r\n    big_normal = self.big_normal(big_shared2_shc, scale_2)\r\n  File \"/home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/venv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 822, in __call__\r\n    outputs = self.call(cast_inputs, *args, **kwargs)\r\n  File \"/home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/venv/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\", line 568, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"/home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/venv/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\", line 615, in _call\r\n    self._initialize(args, kwds, add_initializers_to=initializers)\r\n  File \"/home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/venv/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\", line 497, in _initialize\r\n    *args, **kwds))\r\n  File \"/home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/venv/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\", line 2389, in _get_concrete_function_internal_garbage_collected\r\n    graph_function, _, _ = self._maybe_define_function(args, kwargs)\r\n  File \"/home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/venv/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\", line 2703, in _maybe_define_function\r\n    graph_function = self._create_graph_function(args, kwargs)\r\n  File \"/home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/venv/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\", line 2593, in _create_graph_function\r\n    capture_by_value=self._capture_by_value),\r\n  File \"/home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/venv/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py\", line 978, in func_graph_from_py_func\r\n    func_outputs = python_func(*func_args, **func_kwargs)\r\n  File \"/home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/venv/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\", line 439, in wrapped_fn\r\n    return weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n  File \"/home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/venv/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\", line 3211, in bound_method_wrapper\r\n    return wrapped_fn(*args, **kwargs)\r\n  File \"/home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/venv/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py\", line 968, in wrapper\r\n    raise e.ag_error_metadata.to_exception(e)\r\nValueError: in converted code:\r\n\r\n    /mnt/7f43981f-bc0a-4b76-a721-46c0159f0cf5/cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/ShAReD_Net/model/layer/base.py:228 call  *\r\n        scaled_conv = tf.image.resize(conv, destination_size, preserve_aspect_ratio=True, antialias=True)\r\n    /home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/venv/lib/python3.6/site-packages/tensorflow_core/python/ops/image_ops_impl.py:1357 resize_images_v2\r\n        skip_resize_if_same=False)\r\n    /home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/venv/lib/python3.6/site-packages/tensorflow_core/python/ops/image_ops_impl.py:1100 _resize_images_common\r\n        math_ops.cast(new_height_const, dtypes.float32) /\r\n    /home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/venv/lib/python3.6/site-packages/tensorflow_core/python/util/dispatch.py:180 wrapper\r\n        return target(*args, **kwargs)\r\n    /home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/venv/lib/python3.6/site-packages/tensorflow_core/python/ops/math_ops.py:705 cast\r\n        x = ops.convert_to_tensor(x, name=\"x\")\r\n    /home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/venv/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py:1314 convert_to_tensor\r\n        ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n    /home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/venv/lib/python3.6/site-packages/tensorflow_core/python/framework/constant_op.py:317 _constant_tensor_conversion_function\r\n        return constant(v, dtype=dtype, name=name)\r\n    /home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/venv/lib/python3.6/site-packages/tensorflow_core/python/framework/constant_op.py:258 constant\r\n        allow_broadcast=True)\r\n    /home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/venv/lib/python3.6/site-packages/tensorflow_core/python/framework/constant_op.py:296 _constant_impl\r\n        allow_broadcast=allow_broadcast))\r\n    /home/bhb/Cloud/Code/Git/3D_Person_Pose_Estimation_from_2D_Singelview_Image_Data/src/venv/lib/python3.6/site-packages/tensorflow_core/python/framework/tensor_util.py:439 make_tensor_proto\r\n        raise ValueError(\"None values not supported.\")\r\n\r\n    ValueError: None values not supported.\r\n```\r\n\r\n**Standalone code to reproduce the issue** \r\nSorry not yet the time, but relevant code is:\r\n\r\ncustom Layer for scaling features to variable (depended on other feature size) size :+1: \r\n```\r\nclass Scale(keras.layers.Layer):\r\n    def __init__(self, destination_channel = None, name = \"Scale\", **kwargs):\r\n        super().__init__(name = name, **kwargs)\r\n        self.destination_channel = destination_channel\r\n        \r\n    def build(self, input_shape):\r\n        if self.destination_channel is None:\r\n            self.destination_channel = input_shape[-1]\r\n        self.compress_input = keras.layers.Convolution2D(int(input_shape[-1]/2), kernel_size=1, padding='SAME', activation=tf.nn.leaky_relu, kernel_initializer=tf.initializers.he_normal(), bias_initializer=tf.initializers.he_uniform())\r\n        self.conv = keras.layers.Convolution2D(input_shape[-1], kernel_size=3, padding='SAME', activation=tf.nn.leaky_relu, kernel_initializer=tf.initializers.he_normal(), bias_initializer=tf.initializers.he_uniform())\r\n        self.pool = keras.layers.MaxPool2D(pool_size=3,strides=1,padding=\"SAME\")\r\n        self.compress_output = keras.layers.Convolution2D(self.destination_channel, kernel_size=1, padding='SAME', activation=tf.nn.leaky_relu, kernel_initializer=tf.initializers.he_normal(), bias_initializer=tf.initializers.he_uniform())\r\n        super().build(input_shape)\r\n\r\n    def call(self, inputs, destination_size):\r\n        \r\n        compressed_input = self.compress_input(inputs)\r\n        conv = self.conv(compressed_input)\r\n        pool = self.pool(inputs)\r\n        \r\n        scaled_conv = tf.image.resize(conv, destination_size, preserve_aspect_ratio=True, antialias=True)\r\n        scaled_pool = tf.image.resize(pool, destination_size, preserve_aspect_ratio=True, antialias=True)\r\n        \r\n        concat = keras.layers.concatenate([scaled_pool, scaled_conv])\r\n        compressed_output = self.compress_output(concat)\r\n        return compressed_output\r\n```\r\nworks if like shown, stops working if @tf.function is added to \r\n`def call(self, inputs, destination_size):`\r\n\r\nCalling code:\r\n```\r\ndef call(self, inputs):\r\n        input_res, input_shc = inputs\r\n        \r\n        scale = tf.cast(input_shc.shape[1:3], dtype=tf.int32)\r\n        scale_2 = tf.cast(scale/2, dtype=tf.int32)\r\n        scale_4 = tf.cast(scale/4, dtype=tf.int32)\r\n        scale_8 = tf.cast(scale/8, dtype=tf.int32)\r\n        \r\n        big_normal = self.big_normal(big_shared2_shc, scale_2)\r\n        return big_normal\r\n```\r\n`big_normal` is a instance of `class Scale`\r\n\r\nthanks in advance", "comments": ["@bela127, Thanks for reporting this issue. \r\nCan you provide the complete code snippet to reproduce the reported issue. Thanks!", "Thanks for replying so fast,\r\nI will build a minimum test script today and provide it as soon as possible.", "here you go:\r\nfull test script with 3 test cases\r\n\r\n```\r\nimport tensorflow as tf\r\nkeras = tf.keras\r\n\r\n\r\ndef main():\r\n    eager = True                    ### please change to FALSE in eager mode all 3 tests are fine\r\n    test_nr = 1 # 1 or 2 or 3       ### please test 1 and 2 and 3 -> diffrent errors\r\n                                    ### error 3 ist clear, TensorShape is not tf.function compatible\r\n                                    ### error 1,2 has somthing todo with the image.resize implementation\r\n                                    ### runtime tensor is not evaluated and so the value is None\r\n    \r\n    tf.config.experimental_run_functions_eagerly(eager)\r\n    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\r\n    \r\n    inputs = tf.constant(100.,shape=[1,100,100,20])\r\n    inputs_small = tf.constant(100.,shape=[1,80,80,20])\r\n    \r\n    if eager or test_nr == 1:\r\n        print(\"Scaled1\")\r\n        scaled_shared = Scaled1()\r\n        test_scaled_shared = test(scaled_shared, optimizer, training = True)\r\n        out = test_scaled_shared([inputs,inputs_small])\r\n        print(\"Scaled1\")\r\n    \r\n    if eager or test_nr == 2:\r\n        print(\"Scaled2\")\r\n        scaled_shared = Scaled2()\r\n        test_scaled_shared = test(scaled_shared, optimizer, training = True)\r\n        out = test_scaled_shared([inputs,inputs_small])\r\n        print(\"Scaled2\")\r\n        \r\n    if eager or test_nr == 3:\r\n        print(\"Scaled3\")\r\n        scaled_shared = Scaled3()\r\n        test_scaled_shared = test(scaled_shared, optimizer, training = True)\r\n        out = test_scaled_shared([inputs,inputs_small])\r\n        print(\"Scaled3\")\r\n\r\ndef test(op, optimizer, **kwargs):\r\n    def run(inputs):\r\n        with tf.GradientTape() as tape:\r\n            tape.watch(op.trainable_variables)\r\n            outputs = op(inputs, **kwargs)\r\n        g = tape.gradient(outputs, op.trainable_variables)\r\n        optimizer.apply_gradients(zip(g, op.trainable_variables))\r\n        return outputs, g\r\n    return run\r\n  \r\nclass Scale(keras.layers.Layer):\r\n    def __init__(self, destination_channel = None, name = \"Scale\", **kwargs):\r\n        super().__init__(name = name, **kwargs)\r\n        self.destination_channel = destination_channel\r\n        \r\n    def build(self, input_shape):\r\n        if self.destination_channel is None:\r\n            self.destination_channel = input_shape[-1]\r\n        self.compress_input = keras.layers.Convolution2D(int(input_shape[-1]/2), kernel_size=1, padding='SAME', activation=tf.nn.leaky_relu, kernel_initializer=tf.initializers.he_normal(), bias_initializer=tf.initializers.he_uniform())\r\n        self.conv = keras.layers.Convolution2D(input_shape[-1], kernel_size=3, padding='SAME', activation=tf.nn.leaky_relu, kernel_initializer=tf.initializers.he_normal(), bias_initializer=tf.initializers.he_uniform())\r\n        self.pool = keras.layers.MaxPool2D(pool_size=3,strides=1,padding=\"SAME\")\r\n        self.compress_output = keras.layers.Convolution2D(self.destination_channel, kernel_size=1, padding='SAME', activation=tf.nn.leaky_relu, kernel_initializer=tf.initializers.he_normal(), bias_initializer=tf.initializers.he_uniform())\r\n        super().build(input_shape)\r\n\r\n    @tf.function\r\n    def call(self, inputs, destination_size):\r\n        \r\n        compressed_input = self.compress_input(inputs)\r\n        conv = self.conv(compressed_input)\r\n        pool = self.pool(inputs)\r\n        \r\n        scaled_conv = tf.image.resize(conv, destination_size, preserve_aspect_ratio=True, antialias=True)\r\n        scaled_pool = tf.image.resize(pool, destination_size, preserve_aspect_ratio=True, antialias=True)\r\n        \r\n        concat = keras.layers.concatenate([scaled_pool, scaled_conv])\r\n        compressed_output = self.compress_output(concat)\r\n        return compressed_output\r\n    \r\n    def get_config(self):\r\n        config = super().get_config()\r\n        config.update({'destination_channel': self.destination_channel,\r\n                       })\r\n        return config\r\n\r\n\r\nclass Scaled1(keras.layers.Layer):\r\n    def __init__(self, name = \"Scaled1\", **kwargs):\r\n        super().__init__(name = name, **kwargs)\r\n\r\n        \r\n    def build(self, input_shape):\r\n        res_shape, shc_shape = input_shape\r\n        self.scale_up = Scale(destination_channel = res_shape[-1])\r\n        self.scale_down = Scale()\r\n        super().build(input_shape)\r\n        \r\n    def call(self, inputs):\r\n        inputs_res, inputs_shc = inputs\r\n        shape1 = tf.shape(inputs_shc)[1:3]\r\n        shape2 = tf.shape(inputs_shc)[1:3]\r\n        \r\n        scaled_res = self.scale_down(inputs_res, shape1)\r\n        scaled_dense = self.scale_up(scaled_res, shape2)\r\n        return scaled_dense      \r\n    \r\nclass Scaled2(keras.layers.Layer):\r\n    def __init__(self, name = \"Scaled2\", **kwargs):\r\n        super().__init__(name = name, **kwargs)\r\n\r\n        \r\n    def build(self, input_shape):\r\n        res_shape, shc_shape = input_shape\r\n        self.scale_up = Scale(destination_channel = res_shape[-1])\r\n        self.scale_down = Scale()\r\n        super().build(input_shape)\r\n        \r\n    def call(self, inputs):\r\n        inputs_res, inputs_shc = inputs\r\n        \r\n        shape1 = tf.cast(tf.shape(inputs_shc)[1:3], dtype = tf.int32)\r\n        shape2 = tf.cast(tf.shape(inputs_shc)[1:3], dtype = tf.int32)\r\n        \r\n        scaled_res = self.scale_down(inputs_res, shape1)\r\n        scaled_dense = self.scale_up(scaled_res, shape2)\r\n        return scaled_dense\r\n        \r\nclass Scaled3(keras.layers.Layer):\r\n    def __init__(self, name = \"Scaled2\", **kwargs):\r\n        super().__init__(name = name, **kwargs)\r\n\r\n        \r\n    def build(self, input_shape):\r\n        res_shape, shc_shape = input_shape\r\n        self.scale_up = Scale(destination_channel = res_shape[-1])\r\n        self.scale_down = Scale()\r\n        super().build(input_shape)\r\n        \r\n    def call(self, inputs):\r\n        inputs_res, inputs_shc = inputs\r\n        \r\n        shape1 = inputs_shc.shape[1:3]\r\n        shape2 = inputs_shc.shape[1:3]\r\n        \r\n        scaled_res = self.scale_down(inputs_res, shape1)\r\n        scaled_dense = self.scale_up(scaled_res, shape2)\r\n        return scaled_dense\r\n\r\n  \r\nif __name__ == '__main__':\r\n    main()\r\n    \r\n```", "Could able to replicate the reported issue with TF 2.1 and TF-nightly.\r\nPlease find the gist [here](https://colab.sandbox.google.com/gist/gadagashwini/b758c604ee2b51b63905bf69fd10b57f/untitled401.ipynb). Thanks", "I have similar problems when adding signatures function for an existing model. But if I remove the `preserve_aspect_ratio=True`, everything works well.\r\n\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36963\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36963\">No</a>\n", "thanks, changed to nightly and the fix is working"]}, {"number": 36962, "title": "Cannot save model when not giving a name in Layer.add_weight call", "body": "**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow): Yes\r\n- OS Platform and Distribution: Manjaro 19.0.0 Kyria\r\n- TensorFlow installed from: binary\r\n- TensorFlow version: 2.1.0 \r\n- Python version: 3.7.4\r\n\r\n**Describe the current behavior**\r\nI made a custom `tf.keras.layers.Layer`, where I make my weights in the `build` function using `self.add_weight`. However, I do not pass a name to this function. When I try to save the model that uses the layer, I get an error because the name of the weight is `None` (see traceback below).\r\n\r\n**Describe the expected behavior**\r\nI expected that the weight would either get a default name (possibly only upon saving), that I would get an error when calling `add_weight` or that I would get a more informative error when saving the model.\r\n\r\n**Standalone code to reproduce the issue** \r\n```\r\nimport tensorflow as tf\r\nclass CustomLayer(tf.keras.layers.Layer):\r\n    def build(self, input_shape):\r\n        self.w = self.add_weight(shape=(input_shape[-1], 1))\r\n    def call(self, x):\r\n        return tf.matmul(x, self.w)\r\ninp = tf.keras.Input((5,))\r\nm = tf.keras.Model(inputs=inp, outputs=CustomLayer()(inp))\r\nm.save(\"/tmp/savedmodel\")\r\n```\r\n\r\n**Other info / logs**\r\n```\r\nTraceback (most recent call last):\r\n  File \"tfbug.py\", line 9, in <module>\r\n    m.save(\"/tmp/savedmodel\")\r\n  File \"/home/arno/conda/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\", line 1008, in save\r\n    signatures, options)\r\n  File \"/home/arno/conda/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/save.py\", line 115, in save_model\r\n    signatures, options)\r\n  File \"/home/arno/conda/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/save.py\", line 78, in save \r\n    save_lib.save(model, filepath, signatures, options)\r\n  File \"/home/arno/conda/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/saved_model/save.py\", line 899, in save\r\n    _ = _SaveableView(checkpoint_graph_view)\r\n  File \"/home/arno/conda/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/saved_model/save.py\", line 165, in __init__\r\n    self.checkpoint_view.objects_ids_and_slot_variables())\r\n  File \"/home/arno/conda/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/graph_view.py\", line 418, in objects_ids_and_slot_variables\r\n    object_names[obj] = _object_prefix_from_path(path)\r\n  File \"/home/arno/conda/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/graph_view.py\", line 64, in _object_prefix_from_path\r\n    for trackable in path_to_root))\r\n  File \"/home/arno/conda/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/graph_view.py\", line 64, in <genexpr>\r\n    for trackable in path_to_root))\r\n  File \"/home/arno/conda/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/graph_view.py\", line 57, in _escape_local_name\r\n    return (name.replace(_ESCAPE_CHAR, _ESCAPE_CHAR + _ESCAPE_CHAR)\r\nAttributeError: 'NoneType' object has no attribute 'replace'\r\n```\r\n", "comments": ["I have tried on colab with TF version 2.1.0 , 2.2.0-dev20200218 and was able to reproduce the issue.Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/4157045803a448cc027f1aa58f9b4adb/untitled663.ipynb). Thanks!", "I still see this with TF 2.2.0 (GIT_VERSION: v2.2.0-rc4-8-g2b96f3662b). Even if this didn't work as is (via a default name in `add_weight`, or whatever), a slightly more specific error message would've cut the time it took me to work out the cause dramatically.", "Issue is still reproducible with tf-nightly(2.4.0-dev20200813), please find the [gist here](https://colab.research.google.com/gist/Saduf2019/406eba10719ec4104af99afd2080b81f/untitled367.ipynb)", "@arnomoonens Passing a name to weight works without any error . Please check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/375dc80da27b5847a912af0665c59ac4/untitled367.ipynb). Thanks!\r\n\r\n`self.w = self.add_weight(shape=(input_shape[-1], 1), name='weight')`\r\n\r\nPlease verify once and close the issue if this resolved your issue. Thanks!", "@jvishnuvardhan that makes the code work, but the issue and comments are specific that that's not the whole story:\r\n\r\n> I expected that the weight would either get a default name (possibly only upon saving), that I would get an error when calling add_weight or that I would get a more informative error when saving the model.\r\n\r\n> Even if this didn't work as is (via a default name in add_weight, or whatever), a slightly more specific error message would've cut the time it took me to work out the cause dramatically.", "@huonw Agree with you that this is an issue. Thanks!", "Was able to reproduce your issue in Tf Nightly 2.6.0-dev20210524, please find the gist [here](https://colab.research.google.com/gist/sachinprasadhs/86b4256812ec91f4e96ba18bd0246586/35650.ipynb). Thanks!", "i am also facing the same issue when tf.keras.calbacks was used to save the model (weights only). so is it necessary to create the trainable vars with defined names?\r\n", "Hi There,\n\n This is a stale issue. As you are using an older version of tensorflow, we are checking to see if you still need help on this issue. Please test the issue with the latest TensorFlow (TF2.7 and tf-nightly). If the issue still persists with the newer versions of TF, please feel free to open it in [keras-team/keras](https://github.com/keras-team/keras/issues) repository by providing details about the issue and a standalone code to reproduce the issue. Thanks! \n\n Please note that Keras development has moved to a separate Keras-team/keras repository to focus entirely on only Keras. Thanks! ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36962\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36962\">No</a>\n"]}, {"number": 36961, "title": "[Intel Mkl] Fixing MKL test script to accept parameters", "body": "@penpornk @gunan This is not required for TF 2.2.", "comments": []}, {"number": 36960, "title": "[Intel Mkl] Upgrade Sqlite3 to fix CVE-2019-19880 CVE-2019-19244 and \u2026", "body": "\u2026CVE-2019-19645. ", "comments": ["Cherry-picked this to the 1.15, 2.0 and 2.1 branches to have them there if and when we do more patch releases. If you want, can you CLA-approve #37062, #37063 and #37064?\r\n\r\nThank you"]}, {"number": 36959, "title": "TF-TRT execution context management for multiple threads / streams", "body": "This issue is created to discuss and possibly improve execution context management during TF-TRT inference. \r\n\r\nThe TRT [best practices guide]() says: \"A common pattern is incoming requests dispatched to a pool of waiting for worker threads. In this case, the pool of worker threads will each have one execution context and CUDA stream. Each thread will request work in its own stream as the work becomes available. Each thread will synchronize with its stream to wait for results without blocking other worker threads.\"\r\n\r\nNote that we have a different pattern in TF-TRT. Let's consider the implicit batch case with  a single engine and a single execution context. For any given `TRTEngineOp` we keep a global execution context object in the resource manager. We guard the access to this `IExecutionContext` by a mutex until we prepare the buffers and equeue the inference job. But the mutex is released when we return from `ExecuteTRTEngine`, and the inference job might still be enqueued at that time when we release the mutex.\r\n\r\nThe TRT best practices guide says: to \"Create a CUDA stream using cudaStreamCreate for each independent batch and an `IExecutionContext` for each independent batch.\" ~I would~ One should interpret this the following way: if we want to enque work on multiple GPU streams then each independent batch of work has to have a separate `IExecutionContext` object. Alternatively we can use a single stream with a single execution context.\r\n\r\nSo the current scheduling of TF-TRT inference would require that TRTEngineOp_0 puts all its work always on the same stream. This (while not efficient) would guarantee correctness. \r\n\r\nIs it guaranteed that the following call would always return the same stream for the given `TRTEngineOP` object?\r\nhttps://github.com/tensorflow/tensorflow/blob/9b53275852f37fb1f48e22ed99237f1baef761c5/tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc#L416-L420\r\n\r\nTagging @bixia1", "comments": ["From how class GPUDeviceContext manipulates its stream_ field, there should be a fixed stream associated with the field for a given GPUDeviceContext class object. Therefore, the above call for the same TRTEngineOp class object should always return the same stream. https://github.com/tensorflow/tensorflow/blob/a8ac8f901a3948a71510dedee258119ff4a77363/tensorflow/core/common_runtime/gpu_device_context.h#L82-L84", "Thanks @bixia1 for the answer. One more question: Assume that we have a GPUDeviceContext assigned to TRTEngineOp. Can this context object change during future inference calls, or it remain fixed once it is assigned?", "The GPUGeviceContext  comes from here\r\nhttps://github.com/tensorflow/tensorflow/blob/aae5c218bea680b2c5ef581a4f215501ccd66b4e/tensorflow/core/common_runtime/gpu/gpu_device.cc#L479-L486\r\n\r\nwhich is initialized here and can't be changed for the object\r\nhttps://github.com/tensorflow/tensorflow/blob/aae5c218bea680b2c5ef581a4f215501ccd66b4e/tensorflow/core/common_runtime/gpu/gpu_device.cc#L359-L371\r\n", "Thanks Bixia. In general it looks like  that we have a single compute stream for a physical GPU. That ensures that the TRTEngineOp running on that GPU will have correct stream ordering. That was the main question discussed in this issue. \r\n\r\nIt is a little bit confusing though that the gpu_device_context could be [overriden](https://github.com/tensorflow/tensorflow/blob/aae5c218bea680b2c5ef581a4f215501ccd66b4e/tensorflow/core/common_runtime/gpu/gpu_device.cc#L564).  I see that when executor [calls ComputeAsync](https://github.com/tensorflow/tensorflow/blob/a8ac8f901a3948a71510dedee258119ff4a77363/tensorflow/core/common_runtime/executor.cc#L1900), it passes the context through [params](https://github.com/tensorflow/tensorflow/blob/a8ac8f901a3948a71510dedee258119ff4a77363/tensorflow/core/common_runtime/executor.cc#L1762), that was initialized [here](https://github.com/tensorflow/tensorflow/blob/a8ac8f901a3948a71510dedee258119ff4a77363/tensorflow/core/common_runtime/executor.cc#L1603). Assuming no one has overwritten the default behavior in GPUDeviceBase which ensures a single stream,  we should be all good. \r\n\r\nThe issue can be closed. I will refer this issue in the [docstring of execution_contexts](https://github.com/tensorflow/tensorflow/blob/aae5c218bea680b2c5ef581a4f215501ccd66b4e/tensorflow/compiler/tf2tensorrt/utils/trt_lru_cache.h#L153)."]}, {"number": 36958, "title": "How to optimize a complex phase?", "body": "**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow): yes\r\n- OS Platform and Distribution: MacOS 10.15.3\r\n- TensorFlow installed from binary: 2.1.0\r\n\r\n**Describe the current behavior**\r\nA real loss function that uses complex numbers internally requires Variables to be complex.\r\nBut this leads to complex gradients, even though they should be real.\r\n\r\n**Describe the expected behavior**\r\nIn TF1.x I used to circumvent this problem by defining my real variables as (e.g.):\r\n```python\r\nx = tf.complex(tf.Variable(1.0, dtype=tf.float32), tf.constant(0.0, dtype=tf.float32))\r\n```\r\nTF2.x cannot compute gradients if I use this trick.\r\n\r\n**Standalone code to reproduce the issue** \r\nFor example, I want to optimize the _real_ angle `x` in the complex phase `exp(1j*x)`:\r\n\r\n```python\r\ndef loss(x):\r\n    return tf.abs(tf.exp(1j*x)-1.0) # minimized by x = 0.0\r\n\r\nx = tf.Variable(1.0, dtype=tf.complex64) # forced to have type tf.complex64\r\nLR = 0.01\r\n\r\nfor n in range(10):\r\n    with tf.GradientTape() as tape:\r\n        L = loss(x)\r\n        grad = tape.gradient(L, x)\r\n        x.assign_sub(LR * grad)\r\n\r\nprint(x)\r\n# <tf.Variable 'Variable:0' shape=() dtype=complex64, numpy=(0.9122518+0.043542963j)>\r\n```\r\n", "comments": ["I was able to reproduce the issue with Tf 2.1.\r\nPlease take a look at the [gist](https://colab.sandbox.google.com/gist/gadagashwini/8aff9ca30ab54aae040b1a2e3628f0bc/untitled402.ipynb). Thanks", "As long as you do it inside the `GradientTape`, the same trick should work fine in 2.x:\r\n\r\n```\r\nimport tensorflow as tf\r\nv = tf.Variable(1.0, dtype=tf.float32)\r\nwith tf.GradientTape() as tape:\r\n  x = tf.complex(v, tf.constant(0.0, dtype=tf.float32)) ** 2.\r\nv_grad = tape.gradient(x, v)\r\nprint(v_grad)  # tf.Tensor(2.0, shape=(), dtype=float32)\r\n```\r\n\r\nIn 1.x it probably didn't matter where you put the `tf.complex`, but with `GradientTape` it really needs to be inside the scope so the tape can record the operation. But otherwise it'll be treated identically as with `tf.gradients`.\r\n\r\nDoes that work for you?", "It does! Thank you so much (I had forgotten to do this inside the `GradientTape` context)", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36958\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36958\">No</a>\n"]}, {"number": 36957, "title": "ImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.", "body": "#Import the libraries\r\nimport tensorflow as tf\r\n\r\n**System information**\r\n\r\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 64-bit\r\nTensorFlow installed from (source or binary): pip package manager (20.0.2)\r\nTensorFlow version (use command below): 2.1.0\r\nPython version: Python 3.6.8 64-bit (python-3.6.8-amd64)\r\nCUDA/cuDNN version: No GPU\r\nGPU model and memory: No GPU\r\nYou can collect some of this information using our environment capture script\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n**Describe the current behavior**\r\nJust to test after installation, I tried importing Tensorflow in Python, but got an unexpected error (see Code section) .\r\n\r\n**Describe the expected behavior**\r\nNeeds fixing the problem......\r\n\r\nE:\\Development\\iShaft\\iShaft-Trading-Bot\\iShaft.Python>python prototype.py\r\nC:\\Program Files (x86)\\Python36\\lib\\site-packages\\pandas_datareader\\compat\\__init__.py:7: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\r\n  from pandas.util.testing import assert_frame_equal\r\n\r\nE:\\Development\\iShaft\\iShaft-Trading-Bot\\iShaft.Python>python prototype.py\r\nC:\\Program Files (x86)\\Python36\\lib\\site-packages\\pandas_datareader\\compat\\__init__.py:7: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\r\n  from pandas.util.testing import assert_frame_equal\r\nTraceback (most recent call last):\r\n  File \"C:\\Program Files (x86)\\Python36\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Program Files (x86)\\Python36\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Program Files (x86)\\Python36\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Program Files (x86)\\Python36\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Program Files (x86)\\Python36\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"prototype.py\", line 12, in <module>\r\n    from tensorflow import keras\r\n  File \"C:\\Program Files (x86)\\Python36\\lib\\site-packages\\tensorflow\\__init__.py\", line 101, in <module>\r\n    from tensorflow_core import *\r\n  File \"C:\\Program Files (x86)\\Python36\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 40, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"C:\\Program Files (x86)\\Python36\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Program Files (x86)\\Python36\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Program Files (x86)\\Python36\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"C:\\Program Files (x86)\\Python36\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Program Files (x86)\\Python36\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Program Files (x86)\\Python36\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Program Files (x86)\\Python36\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Program Files (x86)\\Python36\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Program Files (x86)\\Python36\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Program Files (x86)\\Python36\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.", "comments": ["**Install log:**\r\n\r\nE:\\Development\\iShaft\\iShaft-Trading-Bot\\iShaft.Python>pip3 install tensorflow\r\nCollecting tensorflow\r\n  Using cached tensorflow-2.1.0-cp36-cp36m-win_amd64.whl (355.9 MB)\r\nRequirement already satisfied: tensorflow-estimator<2.2.0,>=2.1.0rc0 in c:\\program files (x86)\\python37\\lib\\site-packages (from tensorflow) (2.1.0)\r\nRequirement already satisfied: numpy<2.0,>=1.16.0 in c:\\program files (x86)\\python37\\lib\\site-packages (from tensorflow) (1.18.1)\r\nRequirement already satisfied: grpcio>=1.8.6 in c:\\program files (x86)\\python37\\lib\\site-packages (from tensorflow) (1.27.2)\r\nRequirement already satisfied: opt-einsum>=2.3.2 in c:\\program files (x86)\\python37\\lib\\site-packages (from tensorflow) (3.1.0)\r\nRequirement already satisfied: keras-applications>=1.0.8 in c:\\program files (x86)\\python37\\lib\\site-packages (from tensorflow) (1.0.8)\r\nRequirement already satisfied: wrapt>=1.11.1 in c:\\program files (x86)\\python37\\lib\\site-packages (from tensorflow) (1.12.0)\r\nRequirement already satisfied: six>=1.12.0 in c:\\program files (x86)\\python37\\lib\\site-packages (from tensorflow) (1.14.0)\r\nRequirement already satisfied: google-pasta>=0.1.6 in c:\\program files (x86)\\python37\\lib\\site-packages (from tensorflow) (0.1.8)\r\nRequirement already satisfied: protobuf>=3.8.0 in c:\\program files (x86)\\python37\\lib\\site-packages (from tensorflow) (3.11.3)\r\nRequirement already satisfied: scipy==1.4.1; python_version >= \"3\" in c:\\program files (x86)\\python37\\lib\\site-packages (from tensorflow) (1.4.1)\r\nRequirement already satisfied: gast==0.2.2 in c:\\program files (x86)\\python37\\lib\\site-packages (from tensorflow) (0.2.2)\r\nRequirement already satisfied: astor>=0.6.0 in c:\\program files (x86)\\python37\\lib\\site-packages (from tensorflow) (0.8.1)\r\nRequirement already satisfied: tensorboard<2.2.0,>=2.1.0 in c:\\program files (x86)\\python37\\lib\\site-packages (from tensorflow) (2.1.0)\r\nRequirement already satisfied: wheel>=0.26; python_version >= \"3\" in c:\\program files (x86)\\python37\\lib\\site-packages (from tensorflow) (0.34.2)\r\nRequirement already satisfied: keras-preprocessing>=1.1.0 in c:\\program files (x86)\\python37\\lib\\site-packages (from tensorflow) (1.1.0)\r\nRequirement already satisfied: absl-py>=0.7.0 in c:\\program files (x86)\\python37\\lib\\site-packages (from tensorflow) (0.9.0)\r\nRequirement already satisfied: termcolor>=1.1.0 in c:\\program files (x86)\\python37\\lib\\site-packages (from tensorflow) (1.1.0)\r\nRequirement already satisfied: h5py in c:\\program files (x86)\\python37\\lib\\site-packages (from keras-applications>=1.0.8->tensorflow) (2.10.0)\r\nRequirement already satisfied: setuptools in c:\\program files (x86)\\python37\\lib\\site-packages (from protobuf>=3.8.0->tensorflow) (45.2.0)\r\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\program files (x86)\\python37\\lib\\site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (0.4.1)\r\nRequirement already satisfied: google-auth<2,>=1.6.3 in c:\\program files (x86)\\python37\\lib\\site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (1.11.2)\r\nRequirement already satisfied: werkzeug>=0.11.15 in c:\\program files (x86)\\python37\\lib\\site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (1.0.0)\r\nRequirement already satisfied: requests<3,>=2.21.0 in c:\\program files (x86)\\python37\\lib\\site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (2.23.0)\r\nRequirement already satisfied: markdown>=2.6.8 in c:\\program files (x86)\\python37\\lib\\site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (3.2.1)\r\nRequirement already satisfied: requests-oauthlib>=0.7.0 in c:\\program files (x86)\\python37\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.3.0)\r\nRequirement already satisfied: rsa<4.1,>=3.1.4 in c:\\program files (x86)\\python37\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (4.0)\r\nRequirement already satisfied: pyasn1-modules>=0.2.1 in c:\\program files (x86)\\python37\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (0.2.8)\r\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\program files (x86)\\python37\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (4.0.0)\r\nRequirement already satisfied: certifi>=2017.4.17 in c:\\program files (x86)\\python37\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2019.11.28)\r\nRequirement already satisfied: chardet<4,>=3.0.2 in c:\\program files (x86)\\python37\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.0.4)\r\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\program files (x86)\\python37\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.25.8)\r\nRequirement already satisfied: idna<3,>=2.5 in c:\\program files (x86)\\python37\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2.9)\r\nRequirement already satisfied: oauthlib>=3.0.0 in c:\\program files (x86)\\python37\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.1.0)\r\nRequirement already satisfied: pyasn1>=0.1.3 in c:\\program files (x86)\\python37\\lib\\site-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (0.4.8)\r\nInstalling collected packages: tensorflow\r\nSuccessfully installed tensorflow-2.1.0"]}, {"number": 36956, "title": "Java.lang.ArrayIndexOutOfBoundsException: length=66049; index=66049", "body": "I'm facing this error while integrating my custom Nails Segmentation Model with the app.\r\n\r\nOther models are working find but whenever I use custom model app crashes and give above mentioned error.\r\n\r\nError in bellow while loop\r\n`while (segmentedImage.hasRemaining()){\r\n             outFrame[i++] = segmentedImage.int\r\n        }`\r\n\r\n**Android App Code to Reproduce this error:**\r\nI have upload the stand alone code on [this ](https://drive.google.com/open?id=1WQ9LmAqJpxMwZIHtzMxRP2j6nq1Ga2lD)link which produce this error.\r\n\r\n**System Information**\r\nOS Platform and Distribution: Windows 10\r\nMobile device: Samsung Galaxy\r\nTensorFlow version: Tensorflow Version installed on system is 1.15.0\r\nTensorflow Dependency using in android gradle file is: `implementation('org.tensorflow:tensorflow-lite:0.0.0-nightly') { changing = true }` \r\nTFlite Nails Detection Model file source: [Nail Detection Model](https://github.com/makeml-app/MakeML-Nails/tree/master/Segmentation%20Nails/Resources)\r\n\r\n\r\n\r\n**Expected Behavior:**\r\nExpected Behavior is showing in this [link](https://github.com/makeml-app/MakeML-Nails). \r\n\r\n**Current Behavior**\r\nCurrently when the camera view is open App crashes when the model start nails detection.\r\nException throw in above while loop.\r\nIf I hide this above while loop then app is not crashing but not detecting nails and place colors on that.\r\n\r\nWhat I need to change to get rid from this error ?\r\n\r\nThanks.\r\n", "comments": ["Please provide following applicable information, Thanks!\r\n**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow): \r\n- OS Platform and Distribution (e.g.,\r\nLinux Ubuntu 16.04): \r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if\r\nthe issue happens on mobile device: \r\n- TensorFlow installed from (source or\r\nbinary): - TensorFlow version (use command below): \r\n- Python version: - Bazel\r\nversion (if compiling from source):\r\n- GCC/Compiler version (if compiling from\r\nsource): \r\n- CUDA/cuDNN version: - GPU model and memory:\r\n\r\n**Describe the current behavior**\r\n\r\n**Describe the expected behavior**", "@ymodak  Glad to see your response Thanks.\r\nMy project deadline is already past.\r\n\r\nI have update the information above.\r\nPlease give your precious time on urgent basis on this issue.\r\nThanks.", "@Ehtasha \r\nAs this has been fixed in the latest tf version please move this to closed status.", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36956\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36956\">No</a>\n"]}, {"number": 36955, "title": "optimizer_v2: Improve error when called in cross-replica context", "body": "When calling `Optimizer.apply_gradients()` in a cross-replica distribution context\r\n(with a non-default distribution strategy), `distribute_ctx.get_replica_context()`\r\nreturns `None`, so it would fail with the error\r\n\r\n    [...]/optimizer_v2.py\", line 448, in apply_gradients\r\n        return distribute_ctx.get_replica_context().merge_call(\r\n    AttributeError: 'NoneType' object has no attribute 'merge_call'\r\n\r\nThis commit changes the error to a `RuntimeError` with a more descriptive error\r\nmessage guiding the user towards `tf.distribute.Strategy.experimental_run_v2`.", "comments": []}, {"number": 36954, "title": "I got This error by upgrading to TensorFlow 2.1: \"AttributeError: 'Operation' object has no attribute '_graph'\" .", "body": "My code is written under TensorFlow 2.0 and I run it on Ubuntu 18.04.04. The code is perfectly run with TensorFlow 2.0. But I need to use TensorFlow 2.1 because of some functionality of TensorFlow_addones library.  I upgrade the Tensorflow within my virtual environment by the command \" conda install tensorflow-gpu\" and run the code. The code run for the first epoch and save the result but as soon as it starts next epoch, it stop and show this error.\r\nIf I downgrade the TensorFlow to 2.0, again the code run without any problem. Does anybody know what is the issue?\r\n", "comments": ["@hu26hase, Can you share the standalone code to analyze the reported issue. Thanks!", "I figured it out that this Error is gone if I am not saving the model after each epoch.\r\nI used tf.save_model.save(model, path). If I comment it then, then it will no error.\r\n\r\nThen I use model.save(path), which is keras version of the saving model, it has no error.", "@hu26hase, Closing this issue since its resolved. Please feel free to comment or open if you still face issue.Thanks ", "I've reproduced this issue. It is a bug in TensorFlow-Keras. Please re-open as a bug.\r\n\r\nIssue: Model cannot be used to .predict or __call__. 'Operation' object has no attribute '_graph'. Happens if you save a model that you later want to extract layers from. E.g. keras.model(inputs=prev_model.inputs, outputs=prev_model.layers[-1].output)", "@gavinlive, Please provide the complete standalone code to reproduce the reported issue. Thanks", "@gavinlive , Can you provide the code snippet to analyze the issue. Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "@gadagashwini I also got the same error in Tensorflow 2.1. Error occurs when I call `tf.keras.layers.Conv2D` layer with `dilation_rate` greater than 1, after saving the model using `model.save`. Following is the standalone code producing the error. FYI, it gives no error in Tensorflow 2.0.\r\n\r\n```\r\nimport tensorflow as tf\r\nprint(tf.__version__).   # 2.1.0\r\n\r\nclass ConvBlock(tf.keras.layers.Layer):\r\n    \"\"\"Conv + BatchNorm + ReLU\"\"\"\r\n    def __init__(self,\r\n            filters,\r\n            kernel_size,\r\n            strides=1,\r\n            padding=\"SAME\",\r\n            dilation_rate=1,\r\n            use_bias=False,\r\n            kernel_initializer=\"he_normal\",\r\n            kernel_regularizer=None,\r\n            **bn_params):\r\n        super(ConvBlock, self).__init__()\r\n        self.filters = filters\r\n        self.kernel_size = kernel_size\r\n        self.strides = strides\r\n        self.padding = padding\r\n        self.dilation_rate = dilation_rate\r\n        self.use_bias = use_bias\r\n        self.kernel_initializer = kernel_initializer\r\n        self.kernel_regularizer = kernel_regularizer\r\n        self.bn_params = bn_params\r\n        \r\n    def get_config(self) -> Dict[str, Any]:\r\n        config = super().get_config()\r\n        config.update({\r\n            'filters': self.filters,\r\n            'kernel_size': self.kernel_size,\r\n            'strides': self.strides,\r\n            'padding': self.padding,\r\n            'use_bias': self.use_bias,\r\n            'dilation_rate': self.dilation_rate,\r\n            'kernel_initializer': self.kernel_initializer,\r\n            'kernel_regularizer': self.kernel_regularizer,\r\n            'bn_params': self.bn_params,\r\n        })\r\n        return config\r\n\r\n    def build(self, input_shape):\r\n        self.conv = tf.keras.layers.Conv2D(\r\n            self.filters, \r\n            self.kernel_size, \r\n            strides=self.strides,\r\n            padding=self.padding, \r\n            dilation_rate=self.dilation_rate, \r\n            use_bias=self.use_bias,\r\n            kernel_initializer=self.kernel_initializer, \r\n            kernel_regularizer=self.kernel_regularizer)\r\n        self.bn = tf.keras.layers.BatchNormalization(**self.bn_params)\r\n\r\n    def call(self, x, training=None):\r\n        x = self.conv(x)\r\n        x = self.bn(x, training=training)\r\n        x = tf.nn.relu(x)\r\n        return x\r\n\r\nconv_block = ConvBlock(filters=64, kernel_size=3, strides=1, dilation_rate=2)\r\n\r\ninputs = tf.keras.Input(shape=[32, 32, 1], batch_size=1)\r\noutputs = conv_block(inputs=inputs)\r\nmodel = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"debug\")\r\n\r\nx = tf.zeros((1, 32, 32, 1))\r\ny = model(x)\r\n\r\nmodel.save(\"initial\") \r\n\r\nx = tf.zeros((1, 32, 32, 1))\r\ny = model(x)\r\n```\r\n\r\nError message I got:\r\n```\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-9-1239edcd3dd0> in <module>\r\n      1 x = tf.zeros((1, 32, 32, 1))\r\n----> 2 y = model(x)\r\n\r\n~/.miniconda3/envs/py3.6-tf2.1/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py in __call__(self, inputs, *args, **kwargs)\r\n    820           with base_layer_utils.autocast_context_manager(\r\n    821               self._compute_dtype):\r\n--> 822             outputs = self.call(cast_inputs, *args, **kwargs)\r\n    823           self._handle_activity_regularization(inputs, outputs)\r\n    824           self._set_mask_metadata(inputs, outputs, input_masks)\r\n\r\n~/.miniconda3/envs/py3.6-tf2.1/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py in call(self, inputs, training, mask)\r\n    715     return self._run_internal_graph(\r\n    716         inputs, training=training, mask=mask,\r\n--> 717         convert_kwargs_to_constants=base_layer_utils.call_context().saving)\r\n    718 \r\n    719   def compute_output_shape(self, input_shape):\r\n\r\n~/.miniconda3/envs/py3.6-tf2.1/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py in _run_internal_graph(self, inputs, training, mask, convert_kwargs_to_constants)\r\n    889 \r\n    890           # Compute outputs.\r\n--> 891           output_tensors = layer(computed_tensors, **kwargs)\r\n    892 \r\n    893           # Update tensor_dict.\r\n\r\n~/.miniconda3/envs/py3.6-tf2.1/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py in __call__(self, inputs, *args, **kwargs)\r\n    820           with base_layer_utils.autocast_context_manager(\r\n    821               self._compute_dtype):\r\n--> 822             outputs = self.call(cast_inputs, *args, **kwargs)\r\n    823           self._handle_activity_regularization(inputs, outputs)\r\n    824           self._set_mask_metadata(inputs, outputs, input_masks)\r\n\r\n<ipython-input-3-1f8b326cfcd9> in call(self, x, training)\r\n     52 \r\n     53     def call(self, x, training=None):\r\n---> 54         x = self.conv(x)\r\n     55         x = self.bn(x, training=training)\r\n     56         x = tf.nn.relu(x)\r\n\r\n~/.miniconda3/envs/py3.6-tf2.1/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py in __call__(self, inputs, *args, **kwargs)\r\n    820           with base_layer_utils.autocast_context_manager(\r\n    821               self._compute_dtype):\r\n--> 822             outputs = self.call(cast_inputs, *args, **kwargs)\r\n    823           self._handle_activity_regularization(inputs, outputs)\r\n    824           self._set_mask_metadata(inputs, outputs, input_masks)\r\n\r\n~/.miniconda3/envs/py3.6-tf2.1/lib/python3.6/site-packages/tensorflow_core/python/keras/layers/convolutional.py in call(self, inputs)\r\n    207       inputs = array_ops.pad(inputs, self._compute_causal_padding())\r\n    208 \r\n--> 209     outputs = self._convolution_op(inputs, self.kernel)\r\n    210 \r\n    211     if self.use_bias:\r\n\r\n~/.miniconda3/envs/py3.6-tf2.1/lib/python3.6/site-packages/tensorflow_core/python/ops/nn_ops.py in __call__(self, inp, filter)\r\n   1133           call_from_convolution=False)\r\n   1134     else:\r\n-> 1135       return self.conv_op(inp, filter)\r\n   1136     # copybara:strip_end\r\n   1137     # copybara:insert return self.conv_op(inp, filter)\r\n\r\n~/.miniconda3/envs/py3.6-tf2.1/lib/python3.6/site-packages/tensorflow_core/python/ops/nn_ops.py in __call__(self, inp, filter)\r\n    638 \r\n    639   def __call__(self, inp, filter):  # pylint: disable=redefined-builtin\r\n--> 640     return self.call(inp, filter)\r\n    641 \r\n    642 \r\n\r\n~/.miniconda3/envs/py3.6-tf2.1/lib/python3.6/site-packages/tensorflow_core/python/ops/nn_ops.py in _with_space_to_batch_call(self, inp, filter)\r\n    614         input_shape=input_spatial_shape,\r\n    615         base_paddings=base_paddings,\r\n--> 616         block_shape=self.dilation_rate)\r\n    617 \r\n    618     dilation_rate = _with_space_to_batch_adjust(self.dilation_rate, 1,\r\n\r\n~/.miniconda3/envs/py3.6-tf2.1/lib/python3.6/site-packages/tensorflow_core/python/ops/array_ops.py in required_space_to_batch_paddings(input_shape, block_shape, base_paddings, name)\r\n   3280   \"\"\"\r\n   3281   with ops.name_scope(name, \"required_space_to_batch_paddings\",\r\n-> 3282                       [input_shape, block_shape]):\r\n   3283     input_shape = ops.convert_to_tensor(\r\n   3284         input_shape, dtype=dtypes.int32, name=\"input_shape\")\r\n\r\n~/.miniconda3/envs/py3.6-tf2.1/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py in name_scope(name, default_name, values)\r\n   6183     # pylint: enable=unidiomatic-typecheck\r\n   6184     if graph_value is not None:\r\n-> 6185       return graph_value.graph.name_scope(name)\r\n   6186   return name_scope_v2(name or \"\")\r\n   6187 \r\n\r\n~/.miniconda3/envs/py3.6-tf2.1/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py in graph(self)\r\n    414   def graph(self):\r\n    415     \"\"\"The `Graph` that contains this tensor.\"\"\"\r\n--> 416     return self._op.graph\r\n    417 \r\n    418   @property\r\n\r\n~/.miniconda3/envs/py3.6-tf2.1/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py in graph(self)\r\n   2223   def graph(self):\r\n   2224     \"\"\"The `Graph` that contains this operation.\"\"\"\r\n-> 2225     return self._graph\r\n   2226 \r\n   2227   @property\r\n\r\nAttributeError: 'Operation' object has no attribute '_graph'\r\n```\r\nThank you for your time!", "Any updates on this issue? I ran into the same thing on the end of the 2nd training epoch. Strangely enough, it saved correctly on the first epoch end."]}, {"number": 36953, "title": "MultiWorkerMirroredStrategy failed to run after a few batches occasionally", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow): YES\r\n- OS Platform and Distribution (e.g.,\r\nLinux Ubuntu 16.04): TensorFlow 2.0 Ubuntu 18.04 official image\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if\r\nthe issue happens on mobile device: \r\n- TensorFlow installed from (source or\r\nbinary): - TensorFlow version (use command below): v2.0.0-rc2-26-g64c3d38\r\n- Python version: - Bazel\r\nversion (if compiling from source): 3.6.8\r\n- GCC/Compiler version (if compiling from\r\nsource): \r\n- CUDA/cuDNN version: - GPU model and memory: CUDA 10.1 16GB\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n``` W tensorflow/core/framework/op_kernel.cc:1622] OP_REQUIRES failed at collective_ops:234 : Aborted: The same RecvBuf (GrpcWorker) request was received twice.```\r\n**Describe the expected behavior**\r\nShould be able to train on each run.\r\n**Standalone code to reproduce the issue** \r\nhttps://github.com/calmisential/TensorFlow2.0_ResNet\r\nI modified some code to make it run with different distribute strategy.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["I changed the collective OP for `MultiWorkerMirroredStrategy` from `tf.distribute.experimental.CollectiveCommunication.AUTO` to `tf.distribute.experimental.CollectiveCommunication.NCCL`. The problem exists. Before hangs, there is a WARN log from NCCL.\r\n```\r\n[0] external/nccl_archive/src/transport/net_socket.c:200 NCCL WARN NET/SOCKET : message truncated : receiving 1048576 bytes instead of 32768\r\n[0] NCCL INFO bazel-out/k8-py2-opt/bin/external/nccl_archive/_virtual_includes/include_hdrs/net.h:34 -> 3\r\n[0] NCCL INFO external/nccl_archive/src/transport/net.cc:533 -> 3\r\n[0] NCCL INFO external/nccl_archive/src/transport.cc:163 -> 3 [Proxy Thread]\r\n```", "This is different from https://github.com/tensorflow/tensorflow/issues/37112, which is caused by partial batch size. ", "Probably, this a NCCL issue. PyTorch has the same issue as TF. See https://github.com/pytorch/pytorch/issues/17703. But the issue is closed on NCCL https://github.com/NVIDIA/nccl/issues/193", "@372046933 Can you please try with the recent `tf-nightly` or `TF2.1` and let us know whether the issue persists or not. Thanks!", "I tried `TF2.1` and `tf-nightly` weeks ago. For `TF2.1` I got the same error. For `tf-nightly`, I cannot even iterate over imagenet data on HDFS, let alone the training. ", "By the way, the more workers added, the more frequently `Aborting RingReduce with Aborted: ...` occurred. I can reproduce it on 9 or 10 workers. Usually training will abort within 5 hours.", "@jvishnuvardhan  I added `TF_CPP_VMODLE=grpc_state=2` to ENV, and got some output from GRPC.\r\nDo we need to **back-off** before the first retry?\r\n```\r\nI ./tensorflow/core/distributed_runtime/grpc/grpc_state.h:127] /tensorflow.WorkerService/RecvBuf returned with non-ok status: Unavailable: Connection reset by peer Retries: 0 Max: 10\r\n{\"created\":\"@1583991368.216950699\", \"description\":\"Error received from peer\", \"file\":\"external/grpc/src/core/lib/surface/call.cc\", \"file_line\":\"1039\", \"grpc_message\":\"Connection reset by peer\", \"grpc_status\":14}\r\nI ./tensorflow/core/distributed_runtime/grpc/grpc_state.h:134] Retrying call for /tensorflow.WorkerService/RecvBufRetry: 1 of 10\r\n```", "> I changed the collective OP for `MultiWorkerMirroredStrategy` from `tf.distribute.experimental.CollectiveCommunication.AUTO` to `tf.distribute.experimental.CollectiveCommunication.NCCL`. The problem exists. Before hangs, there is a WARN log from NCCL.\r\n> \r\n> ```\r\n> [0] external/nccl_archive/src/transport/net_socket.c:200 NCCL WARN NET/SOCKET : message truncated : receiving 1048576 bytes instead of 32768\r\n> [0] NCCL INFO bazel-out/k8-py2-opt/bin/external/nccl_archive/_virtual_includes/include_hdrs/net.h:34 -> 3\r\n> [0] NCCL INFO external/nccl_archive/src/transport/net.cc:533 -> 3\r\n> [0] NCCL INFO external/nccl_archive/src/transport.cc:163 -> 3 [Proxy Thread]\r\n> ```\r\n\r\nhttps://github.com/NVIDIA/nccl/commit/6c61492eba5c25ac6ed1bf57de23c6a689aa75cc maybe fixed NCCL on `MultiWorkerMirroredStrategy`. To be verified", "@372046933 After verification, feel free to close the issue if this was resolved for you. Thanks!", "@jvishnuvardhan If I turn off NCCL, multi worker training fails also. Maybe it's due to some bug in upper layer.", "@372046933 It looks like you are using an older Version of Tensorflow. Many bugs have been fixed in the latest version. Could you please execute your code using Latest Version  2.5 and let us know if the issue still persists? Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36953\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36953\">No</a>\n"]}, {"number": 36952, "title": "update ragged_string_ops.py comment", "body": "Update comment, TF-2.x `tf.string_split` always return `RaggedTensor`, \r\nbut comment says return `SparseTensor or RaggedTensor`\r\nremove `SparseTensor`", "comments": []}, {"number": 36951, "title": "Added doc corresponding to decode_prediction() and preprocess_input()", "body": "Fixes [#25988](https://github.com/tensorflow/tensorflow/issues/25988) and #37021. @tanzhenyu , @mihaimaruseac , Please review this PR.", "comments": []}, {"number": 36950, "title": "How to use tensorflow2 keras model on java?", "body": "i use keras to build my model on tf2\r\nin tf1, keras.backend.get_session(), then create .pb file for java calling\r\nplease show me the solution of tf2", "comments": ["try [this one](https://www.tensorflow.org/install/lang_java)", "> try [this one](https://www.tensorflow.org/install/lang_java)\r\nthanks, it's tf1 java api demo, but i need some demo that tf2 model turn to tf1 model", "As mentioned in Note  [here](https://www.tensorflow.org/install/lang_java) : : There is no libtensorflow support for TensorFlow 2 yet. It is expected in a future release. tf2 is not supported yet\r\n", "> As mentioned in Note [here](https://www.tensorflow.org/install/lang_java) : : There is no libtensorflow support for TensorFlow 2 yet. It is expected in a future release. tf2 is not supported yet\r\n\r\ngot that, thank you"]}, {"number": 36949, "title": "TF2.0 - why does this keras model learn data which is explicitly avoided in the loss?", "body": "I do not understand, how does a trained model learn values not influencing the loss function as given below by a minimal example. I am avoiding the error computation of corrupted data but my model still learns that corrupted data. I want to understand what is happening.\r\n\r\nSuppose you have the following data for a function f(x) with input x (4 data points, input is 3-dimensional, output is 2-dimensional)\r\n\r\n```\r\n#%% Import\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\n#%% Data\r\nx = np.array([\r\n     [1,1,1]\r\n     ,[1,1,2]\r\n     ,[1,2,1]\r\n     ,[1,2,2]\r\n     ])\r\n\r\nx = (x-np.mean(x,axis=0))\r\n\r\nf = np.array([\r\n     [5,10]\r\n     ,[6,50]\r\n     ,[4,-30]\r\n     ,[7,-30]\r\n     ])\r\n\r\nd_f = 2\r\n```\r\n\r\nSuppose you want to train a keras model on this data, and the data values for f are corrupt in the last two data points in the second dimension. That means, I do NOT trust the number -30 (corrupted data). I still want to train a keras model. For that, I simply build a custom loss function which takes the mean squared error in the first 2 data points ([5,10] and [6,50]) and then only the square error in the last 2 data points ONLY IN THE FIRST COLUMN (from [4,-30] only [4] and from [7,-30] only [7]).\r\n\r\n```\r\n#%% Model with custom loss\r\n\r\nmodel = tf.keras.Sequential([\r\n    tf.keras.layers.Dense(16,activation='softplus')\r\n    ,tf.keras.layers.Dense(16,activation='softplus')\r\n    ,tf.keras.layers.Dense(d_f)\r\n    ])\r\n\r\ndef myloss(f,f_m):\r\n    f = tf.keras.backend.cast(f,tf.float32)\r\n    ds = (f-f_m)**2\r\n    ok = tf.keras.backend.mean(ds[0:2],axis=-1)\r\n    corrupted = ds[2:,0]\r\n    return tf.keras.backend.concatenate([ok,corrupted])\r\n\r\nmodel.compile(\r\n    optimizer='adam'\r\n    ,loss=myloss\r\n    )\r\n\r\nprint('Keras - evaluated loss:\\n\\t%.8f' % model.evaluate(x,f,verbose=0))\r\nf_m = model.predict(x)\r\nds = (f-f_m)**2\r\nmyloss_output = np.concatenate([np.mean(ds[:2],axis=-1),ds[2:,0]])\r\nprint('Check f, f_m and myloss_output')\r\nprint(f)\r\nprint(f_m)\r\nprint(myloss_output)\r\nprint('Manually computed mean:\\n\\t%.8f' % np.mean(myloss_output))\r\n```\r\n\r\nMy custom function myloss does what it should (mse w.r.t the first two data points and squared error w.r.t. the last two). The evaluation returns the mean over the computations, see code above. Deviations w.r.t. to the number -30 DO NOT APPEAR IN THE OUTPUT OF MYLOSS. The thing I do NOT understand here is that when I train the model, the trained model also approximates -30, although this is not in the output of myloss (see final code below).\r\n\r\n**1) Why is that?**\r\n\r\n**2) How can I prevent it?**\r\n\r\n**3) How can I train the model with the provided data such that after training I can see, what the model learned by itself for the positions of the corrupted data (-30)?**\r\n\r\n```\r\n#%% Train and check predictions\r\n\r\nmodel.fit(x,f,epochs=1500,verbose=2,batch_size=len(x))\r\n\r\n# I do not understand, why the components f[2:,1] are ALSO trained, although the custom loss does not contain them\r\nprint(f)\r\nprint(model.predict(x))\r\n\r\n\r\n# Output in console\r\n[[  5  10]\r\n [  6  50]\r\n [  4 -30]\r\n [  7 -30]]\r\n[[  4.269913   16.358786 ]\r\n [  6.6172767  45.615295 ]\r\n [  4.704413  -35.412888 ]\r\n [  6.408976  -25.318275 ]]\r\n```", "comments": ["Sorry, got it, I just forgot about the default shuffle, i.e., \r\n\r\n`model.fit(x,f,epochs=1500,verbose=2,batch_size=len(x),shuffle=False)`\r\n\r\nsolves the problem! I will close the issue."]}, {"number": 36948, "title": "Simpler way to avoid the UserWarning: Converting sparse IndexedSlices", "body": "\r\n\r\nI have a rnn network structure that looks like following\r\n\r\n        cells = rnn.MultiRNNCell(\r\n            [self._one_rnn_cell(l + 1) for l in range(self.layers)],\r\n            state_is_tuple=True\r\n        ) if self.layers > 1 else self._one_rnn_cell(1)\r\n\r\n\r\n        out, _ = tf.nn.dynamic_rnn(cells, self.inputs,\r\n                                   dtype=tf.float32, scope=\"DyRNN\")\r\n        out = tf.transpose(out, [1, 0, 2])\r\n        num_time_steps = int(out.get_shape()[0])\r\n        last_state = tf.gather(out, num_time_steps - 1, name=\"last_lstm_state\")\r\n\r\nHere while I am running the code, I am getting the following warning.\r\n\r\n    UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory. \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\r\n\r\nNow I understand why this error is coming. I tried out several ideas and the most common one is the following\r\n\r\nHow to deal with UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape\r\n\r\nBut the problem is this requires too many variable like\r\n\r\nmax_length time_steps seq_length n_dim partitions\r\n\r\nthis make the code very unreadable. I wanted to know if there is a simpler way I can avoid the problem.\r\n\r\nAlso if the sequence length remain same across all the batches, can I assume max_length == time_steps == seq_length ?\r\n\r\nPlease help, documentation is very less.\r\n\r\n**Note:** I added this question in stackoverflow [here](https://stackoverflow.com/questions/60269407/simpler-way-to-avoid-the-userwarning-converting-sparse-indexedslices) but haven't received any replies yet. \r\n", "comments": ["@MayukhSobo \r\n\r\nPlease provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. \r\n\r\nPlease provide the colab link or simple standalone code to reproduce the issue in our environment. It helps us in localizing the issue faster.Request you to fill [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new/choose). Thanks!\r\n\r\n\r\n", "@ravikyram \r\n\r\nPlease find the following information about the systems.\r\n\r\n**System information** \r\n\r\n- OS Platform and Distribution: Ubuntu 18.04 LTS\r\n- Tensorflow gpu was installed using conda 4.8.2\r\n- Numpy version:     1.18.1  py37h4f9e942_0\r\n- Numpy base:         1.18.1  py37hde5b4d6_1\r\n- Python version: 3.7.5\r\n- `print(tf.GIT_VERSION, tf.VERSION)` gives output as `v1.15.0-rc3-22-g590d6ee 1.15.0`\r\n\r\n\r\nHere is the code snippet of the model. Due to some legal obligation, I can not share the complete code with you..\r\n\r\n```python\r\ndef _one_rnn_cell(self, layer):\r\n        \"\"\"\r\n        This create one RNN cell\r\n        :param layer: Mention the layer number\r\n        :return: LSTM cell with or without dropout\r\n        \"\"\"\r\n\r\n        lstm_cell = rnn.LSTMCell(self.lstm_size,\r\n                                 state_is_tuple=True,\r\n                                 name=f'LSTMCell_layer_{layer}')\r\n        kp = self.keep_prob\r\n        if not self.training:\r\n            print(\"Setting keep_prob = 1 for testing!!\")\r\n            kp = 1.0\r\n\r\n        lstm_cell = rnn.DropoutWrapper(lstm_cell,\r\n                                       output_keep_prob=kp)\r\n        return lstm_cell\r\n    def _get_all_placeholders(self):\r\n        # self.learning_rate = tf.placeholder(tf.float32, None,\r\n        #                                     name=\"learning_rate\")\r\n        self.inputs = tf.placeholder(tf.float32,\r\n                                     [None, self.time_steps, self.input_size],\r\n                                     name=\"inputs\")\r\n        self.targets = tf.placeholder(tf.float32, [None, self.input_size],\r\n                                      name=\"targets\")\r\n\r\n    def _build_graph(self):\r\n        # First get all the placeholders\r\n        self._get_all_placeholders()\r\n\r\n        # Second, create multiple LSTM cells for all the layers\r\n        cells = rnn.MultiRNNCell(\r\n            [self._one_rnn_cell(l + 1) for l in range(self.layers)],\r\n            state_is_tuple=True\r\n        ) if self.layers > 1 else self._one_rnn_cell(1)\r\n\r\n        # Wrap the all the cells into an RNN\r\n        # We shall use dynamic_rnn so that\r\n        \"\"\"\r\n          1. All the cells for each time_steps in the graph \r\n            is not created while creating the RNN\r\n\r\n          2. We can pass more/less than the sequence length.\r\n        \"\"\"\r\n\r\n        # self.inputs = tf.transpose(self.inputs, perm=[1, 0, 2])\r\n        out, states = tf.nn.dynamic_rnn(cells, self.inputs,\r\n                                        dtype=tf.float32, scope=\"dynamic_rnn\",\r\n                                        time_major=False)\r\n\r\n        # output[:, ts-1, :]\r\n        # It returns the output of all the time_steps. However we need the\r\n        # output only from the last time step.\r\n\r\n        # We could have also wriiten self.time_steps - 1\r\n        # but tensorflow doesn't support negative indexing\r\n\r\n        # Actual output => (batch_size, num_steps, lstm_size)\r\n        # This converts => (num_steps, batch_size, lstm_size)\r\n        # JUST LIKE THAT!!\r\n\r\n        # all_timesteps = tf.reshape(out, [-1, self.lstm_size])\r\n        # row_inds = tf.range(0, 16) * 30 + (30 - 1)\r\n        # partitions = tf.reduce_sum(tf.one_hot(row_inds, tf.shape(all_timesteps)[0], dtype='int32'), 0)\r\n        # last_timesteps = tf.dynamic_partition(all_timesteps, partitions, 2)  # (batch_size, n_dim)\r\n        # last_state = last_timesteps[1]\r\n\r\n        out = tf.transpose(out, [1, 0, 2])\r\n        num_time_steps = int(out.get_shape()[0])\r\n        last_state = tf.gather(out, num_time_steps - 1, name=\"last_lstm_state\")\r\n\r\n        # last_state = states.h\r\n\r\n        # last_state = tf.unstack(outputs, axis=0)\r\n        # last_state = last_state[-1]\r\n        # last_state = tf.transpose(last_state, perm=[0, 1, 2])\r\n        # Now that we've got the last_state, we can add it to a linear layer for Regression.\r\n\r\n        with tf.name_scope('Linear'):\r\n            W = LstmRNN._variable_on_device(\r\n                name='l_w',\r\n                shape=(self.lstm_size, self.input_size),\r\n                initializer=tf.truncated_normal_initializer(),\r\n                device=self.device\r\n            )\r\n            bias = LstmRNN._variable_on_device(\r\n                name='l_b',\r\n                shape=(self.input_size,),\r\n                initializer=tf.constant_initializer(0.1),\r\n                device=self.device\r\n            )\r\n            self.pred = tf.add(tf.matmul(last_state, W, name='Wx'),\r\n                               bias, name='output')\r\n```\r\n\r\nThe problem (UserWarning) apparently is coming from the following lines\r\n```python \r\n        out = tf.transpose(out, [1, 0, 2])\r\n        num_time_steps = int(out.get_shape()[0])\r\n        last_state = tf.gather(out, num_time_steps - 1, name=\"last_lstm_state\")\r\n```\r\n\r\nI can use `tf.dynamic_partition` but that makes the code a lot more unreadable and not easy to follow and more than that I need to pass the `batch_size` before hand which is also a little inconvenient.\r\n\r\nI am currently not getting any warning if I write\r\n```python \r\n\r\nlast_state = states.h\r\n\r\n```\r\nBut I am not sure what would happen if the sequence length is not equal to max_length. Is is a good idea to use ```states.h``` all the time?\r\n", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\nThanks!\r\n"]}, {"number": 36947, "title": "Fix hyperlink to tf.Tensor guide.  ", "body": "cc: @jvishnuvardhan \r\n\r\nFollowup to #36775.\r\n \r\n * Fix hyperlink to tf.Tensor guide. \r\n * Add brief intro of eager and graph modes.\r\n", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F36947) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F36947) for more info**.\n\n<!-- ok -->", "Bump.  Could you please review?  Thanks.", "@jraman Can you please check lamberta's comments and keep us posted? Thanks!", "@lamberta, thank you for your review.  I have addressed your comments.\r\n\r\ncc: @gbaned ", "Bump.  Could you merge please?  Thanks.\r\ncc: @gbaned ", "Just checked on it. It's in-flight but this process can take while because of our internal CI (cl/299268631)", "@lamberta, @gbaned \r\nAny update?  Sorry to bother you, but it's almost four days since CI was last checked.  Thanks.\r\n"]}, {"number": 36946, "title": "Remove duplicate segment_reduction_ops.cc included in tf_op_files", "body": "", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F36946) for more info**.\n\n<!-- need_sender_cla -->", "> Thanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\r\n> \r\n> \ud83d\udcdd **Please visit https://cla.developers.google.com/ to sign.**\r\n> \r\n> Once you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\r\n> \r\n> #### What to do if you already signed the CLA\r\n> ##### Individual signers\r\n> * It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\r\n> \r\n> ##### Corporate signers\r\n> * Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\r\n> * The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\r\n> * The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\r\n> \r\n> \u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F36946) for more info**.\r\n\r\n@googlebot I signed it!", "@aimetrics thank you for your contribution, please sign CLA.", "> @aimetrics thank you for your contribution, please sign CLA.\r\n\r\n\r\n\r\n> @aimetrics thank you for your contribution, please sign CLA.\r\n\r\n@gbaned I signed it! \r\n@googlebot I signed it! ", "Please reopen against master, not against a release branch"]}, {"number": 36945, "title": "ImportError after installing 2.1.0 on OSX Catalina 10.15.2 (From binary and source)", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OSX Catalina 10.15.2\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): Binary AND source\r\n- TensorFlow version: 2.1.0 (switched to branch r2.1.0)\r\n- Python version: 3.7.6\r\n- Installed using virtualenv? pip? conda?: pip (pip3 on my system)\r\n- Bazel version (if compiling from source): 2.1.0\r\n- GCC/Compiler version (if compiling from source): Apple clang version 11.0.0 (clang-1100.0.33.17)\r\n- CUDA/cuDNN version:\r\n- GPU model and memory: Intel UHD (using MacBookPro GPU not compatible)\r\n\r\n\r\n\r\n**Describe the problem**\r\nAfter successfully installing Tensorflow via pip or compiling Tensorflow from source, importing the Tensorflow2.1.0 package fails with the error below on OSX Catalina 10.15.2 (CPU = 2.6 GHz 6-Core Intel Core i7). Running `pip install tensorflow==2.0.0` works fine. I've tried installing `pywrap` with `pip3 install pywrap` but this does not fix the issue.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nPIP instructions:\r\n1. `pip3 install tensorflow` (Tried `--user`, `--upgrade` and installing with `pip` as well)\r\n2. `python3`\r\n3. `>>> import tensorflow as tf`\r\n\r\nCompilation instructions:\r\n1. `git clone https://github.com/tensorflow/tensorflow.git & cd tensorflow`\r\n2. `git checkout branch_name r2.1.0`\r\n3. `./configure` setting python version as `/usr/local/bin/python3` and everything else as defaults\r\n4.  `bazel build //tensorflow/tools/pip_package:build_pip_package`\r\n5. `./bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg`\r\n6. `pip install /tmp/tensorflow_pkg/tensorflow-2.1.0-cp37-cp37m-macosx_10_15_x86_64.whl`\r\n7. `python3`\r\n8. `>>> import tensorflow`\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nERROR PRODUCED:\r\n```\r\n>>> import tensorflow as tf\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/__init__.py\", line 101, in <module>\r\n    from tensorflow_core import *\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/__init__.py\", line 40, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/importlib/__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/__init__.py\", line 50, in <module>\r\n    from tensorflow.python import _pywrap_utils\r\nImportError: dlopen(/usr/local/lib/python3.7/site-packages/tensorflow_core/python/_pywrap_utils.so, 2): Symbol not found: __ZN10tensorflow4swig10IsSequenceEP7_object\r\n  Referenced from: /usr/local/lib/python3.7/site-packages/tensorflow_core/python/_pywrap_utils.so\r\n  Expected in: flat namespace\r\n in /usr/local/lib/python3.7/site-packages/tensorflow_core/python/_pywrap_utils.so\r\n```\r\n\r\n", "comments": ["This seems like a linking issue (potentially system specific). `_pywrap_utils.so` links to `pywrap_tensorflow_internal.so`. `__ZN10tensorflow4swig10IsSequenceEP7_object`'s implementation is defined in the `cpp_python_util` target in `pywrap_tensorflow_internal.so`. Just for reference here is how we build our binaries from source for MacOS: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/ci_build/release/macos/cpu_py37_full/nightly_release.sh#L41-L49\r\n\r\nIs there any chance you can try the `tf-nightly` MacOS pip package and see if the issue still persists?", "Unfortunately unable to reproduce on Catalina 10.15.3.\r\n\r\n```\r\n$ python3 --version\r\nPython 3.7.6\r\n$ clang --version\r\nApple clang version 11.0.0 (clang-1100.0.33.17)\r\nTarget: x86_64-apple-darwin19.3.0\r\nThread model: posix\r\nInstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin\r\n$ python3\r\nPython 3.7.6 (default, Feb 22 2020, 07:58:28) \r\n[Clang 11.0.0 (clang-1100.0.33.17)] on darwin\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\n>>> tf.__version__\r\n'2.1.0'\r\n```\r\n\r\nIs there by any chance a weird ENV variable that messes with the linker?", "Checked my ENV vars and couldn't see anything weird or anything that could effect the linking process.\r\n\r\nLooking at how you guys build binaries for MacOS, I didn't export `TF_NEED_CUDA=0` or `CC_OPT_FLAGS='-mavx'` and I ran configure with `./configure`.  I also noticed some differences with the bazel build command too:\r\n\r\nYour build: `bazel build --config=opt --config=v2 tensorflow/tools/pip_package:build_pip_package`\r\n\r\nMy build: `bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package`\r\n(I followed the instructions [here](https://www.tensorflow.org/install/source) exactly)\r\n\r\nJust installed `tf-nightly` via pip with `pip install tf-nightly` and still getting the same error as above.", "I noticed you are not using a virtualenv and my test was done in a virtualenv. According to [this StackOverflow post](https://stackoverflow.com/questions/57806063/cannot-import-name-pywrap-utils-from-tensorflow-python) this error can manifest if tensorflow was not properly installed to system Python. Can you please try either uninstalling TensorFlow or reinstalling TensorFlow? An additional test is trying with a virtualenv.\r\n\r\nI'm also looking into seeing if those shared objects need to be imported in `tensorflow/python/__init__.py` and seeing if removing them is an option for the future. Sorry for the inconvenience and thanks for your patience!", "Ok I've had no luck using a virtual environment and have installed / uninstalled multiple times with the same error still occurring.\r\n\r\nSteps used to install with virtual environment:\r\n1. `python3 -m venv env`\r\n2. `source env/bin/activate`\r\n3. `pip install -U pip`\r\n4. `pip install tensorflow`\r\n5. `python`\r\n6. `>>> import tensorflow`\r\n\r\nThanks for your help!", "It turns out we do not need those imports anyways so I've removed them. Hopefully a `tf-nightly` package after tomorrow can help resolve this.\r\n\r\nhttps://github.com/tensorflow/tensorflow/commit/edda1d191fa92ac0fd7462a1deede6bd8a563861\r\n", "Awesome thanks so much, I'll try installing `tf-nightly` after tomorrow!", "@nicholascannon1,\r\nAny updates regarding this issue? Thanks!", "I'm also facing this issue.\r\n - macOS Mojave 10.14.6\r\n - python3.5 (no virtual env)\r\n - TensorFlow 2.1.0\r\n\r\nAndr\u00e9.", "Still getting pywrap `ImportError` installing `tf-nightly`.\r\n```\r\n>>> import tensorflow\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/__init__.py\", line 41, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/python/__init__.py\", line 64, in <module>\r\n    from tensorflow.python.framework.framework_lib import *  # pylint: disable=redefined-builtin\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/framework_lib.py\", line 25, in <module>\r\n    from tensorflow.python.framework.ops import Graph\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 43, in <module>\r\n    from tensorflow.python import pywrap_tfe\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/python/pywrap_tfe.py\", line 29, in <module>\r\n    from tensorflow.python._pywrap_tfe import *\r\nImportError: dlopen(/usr/local/lib/python3.7/site-packages/tensorflow/python/_pywrap_tfe.so, 2): Symbol not found: _TFE_CancellationManagerIsCancelled\r\n  Referenced from: /usr/local/lib/python3.7/site-packages/tensorflow/python/_pywrap_tfe.so\r\n  Expected in: flat namespace\r\n in /usr/local/lib/python3.7/site-packages/tensorflow/python/_pywrap_tfe.so\r\n```\r\n", "Sorry again for the frustration. Unfortunately since I cannot repro this it's difficult for me to debug.\r\n\r\nSo this new error suggests the issue was not with the `__init__.py` file as so much it was with loading shared objects in general. It appears no matter what, whenever you load the shared object first it has an issue. \r\n\r\nI looked around and found [this guide](https://developer.apple.com/library/archive/documentation/DeveloperTools/Conceptual/DynamicLibraries/100-Articles/UsingDynamicLibraries.html) which claims that adding the directory where the shared objects live to the following environment variables will help the linker find them. Could you try adding the path where the .so files live to your `LD_LIBRARY_PATH`? It appears your path is `/usr/local/lib/python3.7/site-packages/tensorflow/python/`. Additionally the shared object that has the implementation of `_TFE_CancellationManagerIsCancelled` is `_pywrap_tensorflow_internal.so`. Can you verify that shared object is in the directory I mentioned previously?\r\n\r\nThanks again for your patience. Hopefully this will resolve this. ", "Ok so I added the folder to `LD_LIBRARY_PATH` using:\r\n\r\n`export LD_LIBRARY_PATH=/usr/local/lib/python3.7/site-packages/tensorflow/python/:$LD_LIBRA    RY_PATH`\r\n\r\nand tried both `tf-nightly` and the regular `tensorflow` (installing via pip). `tensorflow` had the same error as above (the original one) and `tf-nightly` had the same error message as my last comment.\r\n\r\nChecking the folder `/usr/local/lib/python3.7/site-packages/tensorflow/python/` I can see `_pywrap_utils.so` and `_pywrap_tensorflow_internal.so`. I cannot see `_pywrap_tfe.so` which is mentioned in the previous error.\r\n\r\nHere is a list of all the shared object files in the directory `/usr/local/lib/python3.7/site-packages/tensorflow/python/`:\r\n```\r\n_dtypes.so\r\n_op_def_registry.so\r\n_pywrap_bfloat16.so\r\n_pywrap_checkpoint_reader.so\r\n_pywrap_debug_events_writer.so\r\n_pywrap_device_lib.so\r\n_pywrap_events_writer.so\r\n_pywrap_file_io.so\r\n_pywrap_kernel_registry.so\r\n_pywrap_mlir.so\r\n_pywrap_py_exception_registry.so\r\n_pywrap_py_func.so\r\n_pywrap_python_op_gen.so\r\n_pywrap_quantize_training.so\r\n_pywrap_record_io.so\r\n_pywrap_stacktrace_handler.so\r\n_pywrap_stat_summarizer.so\r\n_pywrap_tensorflow_internal.so\r\n_pywrap_tf_cluster.so\r\n_pywrap_tf_item.so\r\n_pywrap_tf_optimizer.so\r\n_pywrap_tf_session.so\r\n_pywrap_tfcompile.so\r\n_pywrap_tfe.so\r\n_pywrap_tfprof.so\r\n_pywrap_toco_api.so\r\n_pywrap_transform_graph.so\r\n_pywrap_util_port.so\r\n_pywrap_utils.so\r\n_tf_stack.so\r\n```\r\n", "Unrelated, I see `_pywrap_tfe.so` in your directory listing, so the file is there.\r\n\r\nUnfortunately I'm out of potential solutions. :( I'll keep looking around for Mac shared library issues to see if something can work. \r\n\r\nI'll keep this bug open in the event someone else ran into this issue and resolved it. Sorry I was unable to help. ", "No worries, thanks for your help!", "UPDATE\r\nStill having issues with 2.2.0 on OSX Catalina 10.15.4 installing inside a virtualenv with python 3.7.7 via pip. Python has been installed via homebrew as well (not sure if I've mentioned that above).\r\n\r\nI've also noticed I'm unable to run tensorboard as well, getting segmentation faults when running from command line. Could be unrelated though as it also seg faults with tensorflow version 2.0.1 which is the only tensorflow version that works on my machine.\r\n\r\nHere is the output error when importing tensorflow (inside virtualenv):\r\n```\r\n>>> import tensorflow\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/Users/Nicholas/Desktop/tf_test/env/lib/python3.7/site-packages/tensorflow/__init__.py\", line 41, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"/Users/Nicholas/Desktop/tf_test/env/lib/python3.7/site-packages/tensorflow/python/__init__.py\", line 64, in <module>\r\n    from tensorflow.python.framework.framework_lib import *  # pylint: disable=redefined-builtin\r\n  File \"/Users/Nicholas/Desktop/tf_test/env/lib/python3.7/site-packages/tensorflow/python/framework/framework_lib.py\", line 25, in <module>\r\n    from tensorflow.python.framework.ops import Graph\r\n  File \"/Users/Nicholas/Desktop/tf_test/env/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 43, in <module>\r\n    from tensorflow.python import pywrap_tfe\r\n  File \"/Users/Nicholas/Desktop/tf_test/env/lib/python3.7/site-packages/tensorflow/python/pywrap_tfe.py\", line 29, in <module>\r\n    from tensorflow.python._pywrap_tfe import *\r\nImportError: dlopen(/Users/Nicholas/Desktop/tf_test/env/lib/python3.7/site-packages/tensorflow/python/_pywrap_tfe.so, 2): Symbol not found: _TFE_CancellationManagerIsCancelled\r\n  Referenced from: /Users/Nicholas/Desktop/tf_test/env/lib/python3.7/site-packages/tensorflow/python/_pywrap_tfe.so\r\n  Expected in: flat namespace\r\n in /Users/Nicholas/Desktop/tf_test/env/lib/python3.7/site-packages/tensorflow/python/_pywrap_tfe.so\r\n>>>\r\n```", "This might be a long shot, but is your Xcode up to date? I'm confident the issues is machine specific. I've tried to repro on 3 different MacOS devices from Catalina and Mojave. \r\n\r\nBetween 2.0 and 2.1 we modified the way C++ code was exported to shared objects, and I guess there is an issue with `dlopen` for users that hit this particular issue.\r\n\r\nPotential other solutions:\r\n1. `$DYLD_LIBRARY_PATH` can be set to the path we tried earlier.\r\nhttps://stackoverflow.com/questions/27281943/import-matplotlib-pyplot-gives-importerror-dlopen-library-not-loaded-libpn\r\n2. The issue might be with homebrew? https://stackoverflow.com/questions/35989572/importerror-dlopen-symbol-not-found-pycodecinfo-getincrementaldecoder", "SOLVED!\r\nI was digging through my `.zshrc` file and noticed I had added an export when first upgrading to zsh that fixed vim from crashing. The export was `export DYLD_FORCE_FLAT_NAMESPACE=1`. After removing this export I was able to import Tensorflow successfully!!\r\n\r\nSo I guess if anyone is having the same issue check if you've been messing with the DYLD linker.\r\n\r\nThanks for the help @av8ramit ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36945\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36945\">No</a>\n", "Hi Nicholas,\r\n\r\nI am running OSX 10.11.6 El Capitan and trying to upgrade my tensorflow 2.0.0 to tensorflow 2.3.1.  \r\n\r\nWhen I try pip3 installing tensorflow in a virtual environment, I can't even import tensorflow.   I have to conda install tensorflow.  And when I try upgrading to tensorflow 2.3.1 after conda installing I get the error if I try importing:\r\n\r\nFile \"/Users/blah/anaconda3/envs/test2/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 64, in\r\nfrom tensorflow.python._pywrap_tensorflow_internal import *\r\nImportError: dlopen(/Users/blah/anaconda3/envs/test2/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so, 6): Symbol not found: _SecKeyCopyExternalRepresentation\r\nReferenced from: /Users/blah/anaconda3/envs/test2/lib/python3.7/site-packages/tensorflow/python/../libtensorflow_framework.2.dylib\r\nExpected in: /System/Library/Frameworks/Security.framework/Versions/A/Security\r\nin /Users/blah/anaconda3/envs/test2/lib/python3.7/site-packages/tensorflow/python/../libtensorflow_framework.2.dylib\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\n\"Traceback (most recent call last):\r\nFile \"\", line 1, in\r\nFile \"/Users/blah/anaconda3/envs/test2/lib/python3.7/site-packages/tensorflow/init.py\", line 41, in\r\nfrom tensorflow.python.tools import module_util as _module_util\r\nFile \"/Users/blah/anaconda3/envs/test2/lib/python3.7/site-packages/tensorflow/python/init.py\", line 40, in\r\nfrom tensorflow.python.eager import context\r\nFile \"/Users/blah/anaconda3/envs/test2/lib/python3.7/site-packages/tensorflow/python/eager/context.py\", line 35, in\r\nfrom tensorflow.python import pywrap_tfe\r\nFile \"/Users/blah/anaconda3/envs/test2/lib/python3.7/site-packages/tensorflow/python/pywrap_tfe.py\", line 28, in\r\nfrom tensorflow.python import pywrap_tensorflow\r\nFile \"/Users/blah/anaconda3/envs/test2/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 83, in\r\nraise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\nFile \"/Users/blah/anaconda3/envs/test2/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 64, in\r\nfrom tensorflow.python._pywrap_tensorflow_internal import *\r\nImportError: dlopen(/Users/blah/anaconda3/envs/test2/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so, 6): Symbol not found: _SecKeyCopyExternalRepresentation\r\nReferenced from: /Users/blah/anaconda3/envs/test2/lib/python3.7/site-packages/tensorflow/python/../libtensorflow_framework.2.dylib\r\nExpected in: /System/Library/Frameworks/Security.framework/Versions/A/Security\r\nin /Users/blah/anaconda3/envs/test2/lib/python3.7/site-packages/tensorflow/python/../libtensorflow_framework.2.dylib\"\r\n\r\nWould you have an idea of what I might be doing wrong?\r\n\r\n> UPDATE\r\n> Still having issues with 2.2.0 on OSX Catalina 10.15.4 installing inside a virtualenv with python 3.7.7 via pip. Python has been installed via homebrew as well (not sure if I've mentioned that above).\r\n> \r\n> I've also noticed I'm unable to run tensorboard as well, getting segmentation faults when running from command line. Could be unrelated though as it also seg faults with tensorflow version 2.0.1 which is the only tensorflow version that works on my machine.\r\n> \r\n> Here is the output error when importing tensorflow (inside virtualenv):\r\n> \r\n> ```\r\n> >>> import tensorflow\r\n> Traceback (most recent call last):\r\n>   File \"<stdin>\", line 1, in <module>\r\n>   File \"/Users/Nicholas/Desktop/tf_test/env/lib/python3.7/site-packages/tensorflow/__init__.py\", line 41, in <module>\r\n>     from tensorflow.python.tools import module_util as _module_util\r\n>   File \"/Users/Nicholas/Desktop/tf_test/env/lib/python3.7/site-packages/tensorflow/python/__init__.py\", line 64, in <module>\r\n>     from tensorflow.python.framework.framework_lib import *  # pylint: disable=redefined-builtin\r\n>   File \"/Users/Nicholas/Desktop/tf_test/env/lib/python3.7/site-packages/tensorflow/python/framework/framework_lib.py\", line 25, in <module>\r\n>     from tensorflow.python.framework.ops import Graph\r\n>   File \"/Users/Nicholas/Desktop/tf_test/env/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 43, in <module>\r\n>     from tensorflow.python import pywrap_tfe\r\n>   File \"/Users/Nicholas/Desktop/tf_test/env/lib/python3.7/site-packages/tensorflow/python/pywrap_tfe.py\", line 29, in <module>\r\n>     from tensorflow.python._pywrap_tfe import *\r\n> ImportError: dlopen(/Users/Nicholas/Desktop/tf_test/env/lib/python3.7/site-packages/tensorflow/python/_pywrap_tfe.so, 2): Symbol not found: _TFE_CancellationManagerIsCancelled\r\n>   Referenced from: /Users/Nicholas/Desktop/tf_test/env/lib/python3.7/site-packages/tensorflow/python/_pywrap_tfe.so\r\n>   Expected in: flat namespace\r\n>  in /Users/Nicholas/Desktop/tf_test/env/lib/python3.7/site-packages/tensorflow/python/_pywrap_tfe.so\r\n> >>>\r\n> ```\r\n\r\n\r\n\r\n> _Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template_\r\n> \r\n> **System information**\r\n> \r\n> * OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OSX Catalina 10.15.2\r\n> * Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n> * TensorFlow installed from (source or binary): Binary AND source\r\n> * TensorFlow version: 2.1.0 (switched to branch r2.1.0)\r\n> * Python version: 3.7.6\r\n> * Installed using virtualenv? pip? conda?: pip (pip3 on my system)\r\n> * Bazel version (if compiling from source): 2.1.0\r\n> * GCC/Compiler version (if compiling from source): Apple clang version 11.0.0 (clang-1100.0.33.17)\r\n> * CUDA/cuDNN version:\r\n> * GPU model and memory: Intel UHD (using MacBookPro GPU not compatible)\r\n> \r\n> **Describe the problem**\r\n> After successfully installing Tensorflow via pip or compiling Tensorflow from source, importing the Tensorflow2.1.0 package fails with the error below on OSX Catalina 10.15.2 (CPU = 2.6 GHz 6-Core Intel Core i7). Running `pip install tensorflow==2.0.0` works fine. I've tried installing `pywrap` with `pip3 install pywrap` but this does not fix the issue.\r\n> \r\n> **Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n> PIP instructions:\r\n> \r\n> 1. `pip3 install tensorflow` (Tried `--user`, `--upgrade` and installing with `pip` as well)\r\n> 2. `python3`\r\n> 3. `>>> import tensorflow as tf`\r\n> \r\n> Compilation instructions:\r\n> \r\n> 1. `git clone https://github.com/tensorflow/tensorflow.git & cd tensorflow`\r\n> 2. `git checkout branch_name r2.1.0`\r\n> 3. `./configure` setting python version as `/usr/local/bin/python3` and everything else as defaults\r\n> 4. `bazel build //tensorflow/tools/pip_package:build_pip_package`\r\n> 5. `./bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg`\r\n> 6. `pip install /tmp/tensorflow_pkg/tensorflow-2.1.0-cp37-cp37m-macosx_10_15_x86_64.whl`\r\n> 7. `python3`\r\n> 8. `>>> import tensorflow`\r\n> \r\n> **Any other info / logs**\r\n> Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n> \r\n> ERROR PRODUCED:\r\n> \r\n> ```\r\n> >>> import tensorflow as tf\r\n> Traceback (most recent call last):\r\n>   File \"<stdin>\", line 1, in <module>\r\n>   File \"/usr/local/lib/python3.7/site-packages/tensorflow/__init__.py\", line 101, in <module>\r\n>     from tensorflow_core import *\r\n>   File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/__init__.py\", line 40, in <module>\r\n>     from tensorflow.python.tools import module_util as _module_util\r\n>   File \"/usr/local/lib/python3.7/site-packages/tensorflow/__init__.py\", line 50, in __getattr__\r\n>     module = self._load()\r\n>   File \"/usr/local/lib/python3.7/site-packages/tensorflow/__init__.py\", line 44, in _load\r\n>     module = _importlib.import_module(self.__name__)\r\n>   File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/importlib/__init__.py\", line 127, in import_module\r\n>     return _bootstrap._gcd_import(name[level:], package, level)\r\n>   File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/__init__.py\", line 50, in <module>\r\n>     from tensorflow.python import _pywrap_utils\r\n> ImportError: dlopen(/usr/local/lib/python3.7/site-packages/tensorflow_core/python/_pywrap_utils.so, 2): Symbol not found: __ZN10tensorflow4swig10IsSequenceEP7_object\r\n>   Referenced from: /usr/local/lib/python3.7/site-packages/tensorflow_core/python/_pywrap_utils.so\r\n>   Expected in: flat namespace\r\n>  in /usr/local/lib/python3.7/site-packages/tensorflow_core/python/_pywrap_utils.so\r\n> ```\r\n\r\n"]}, {"number": 36944, "title": "[Intel MKL] Fixing Device() API usage in mkl_eager_op_rewrite.cc", "body": "API change in TF core caused a build failure in MKL CPU backend. This commit fixes the compilation failure.", "comments": []}, {"number": 36943, "title": "assertion \"exponent <= 31\" failed while executing interpreter->Invoke()", "body": "@tensorflow/micro\r\n\r\n**System information**\r\n- Host OS Platform and Distribution: Windows 10\r\n- TensorFlow installed from binary\r\n- Tensorflow version: TF 2.0.0\r\n- Target platform: M5Stack (ESP32)\r\n\r\n\r\n**Description of the problem:**\r\n\r\nI'm working on a CNN model that tries to detect a situation that occurs to patient with Parkinson disease. Based on accelerometers values, I try to detect the appearance of this situation with a CNN.\r\nI trained a model with the Python version of TF, and I converted the model into a .tflite file that I'm using to put the model on a M5Stack microcontroller.\r\n\r\nWhen I execute a basic program consisting in giving an input to my model on the microcontroller, this error is sent through the serial monitor:\r\n\r\n> assertion \"exponent <= 31\" failed: file \"lib\\tfmicro/fixedpoint/fixedpoint.h\", line 359, function: IntegerType gemmlowp::RoundingDivideByPOT(IntegerType, int) [with IntegerType = int]\r\n\r\nIt seems to happen when the \"interpreter->Invoke()\" part of the code is executed. \r\n\r\n\r\n**How I ran into the problem:**\r\n\r\nThe code in which I'm using the model on the microcontroller is based the the helloworld example. I'm simply just creating a sample user input, loading the model, and trying to invoke the interpreter on the sample data, but I get the \"assertion failed\" error.\r\n\r\nI'm getting the error when the following part of the code is executed:\r\n```cpp\r\nif (interpreter->Invoke() != kTfLiteOk)\r\n{\r\n    M5.Lcd.println(\"There was an error invoking the interpreter!\");\r\n    return;\r\n}\r\n```\r\nOn this code, the message is not even printed, the \"assertion failed\" comes from the execution of *interpreter->Invoke()*.\r\nThis error makes my microcontroller reboot, again and again.\r\n\r\nThe repository https://github.com/GlennWasAlreadyTaken/CNN_M5Stack contains my whole project. \r\nIn the cnn folder, you'll find the Python script I made for the training of the model and conversion to tflite file. You'll also find the weights (.h5), and the converted file (tflite) and the C array (.cc).\r\nThe M5StackCNN folder contains the code for the microcontroller, that should run the model. I use Platformio in order to deploy the program on the M5Stack.\r\nYou'll find the main code for the microcontroller in M5StackCNN/src/main.cpp.\r\n\r\nThank you in advance.", "comments": ["**Possible solution to the problem:**\r\n\r\nI was helped by an engineer of the TFLite team. \r\nThe problem may come from the model, which might be a hybrid model, not supported by TFLite.\r\nOne solution would be to make the model *Fully quantized*, which I tried. However, I'm still facing difficulties:\r\n\r\nWhen converting the model to a tflite model, I was told to use the following converter optimization:\r\n`converter.optimizations = [tf.lite.Optimize.TFLITE_BUILTINS_INT8]`\r\n\r\nHowever, it seems like tf.lite.Optimize does not have any attribute named TFLITE_BUILTINS_INT8, as I'm getting an *AttributeError* when trying to use it.\r\n\r\nI saw that tf.lit.OpsSet had an attribute named TFLITE_BUILTINS_INT8. Hence, I decided to remplace the line by `converter.optimizations = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]`, knowing that this was probably not the good solution, but I just wanted to try in case it could work (actually, I discovered that it didn't call the representative dataset function, so I'm pretty sure this is not the good solution). And actually, it produced a tflite file. I tried to test it but the .cc file I generated from it was to heavy for the microcontroller I'm using, so in order to test I would need to re-train the model (which can be long so I didn't try this).\r\nIn order to reduce the size file, I decided to add the optimization \"OPTIMIZE_FOR_SIZE\", thinking that it would help. However, I get another error in the script, which is the following:\r\n\r\n> ValueError: Cannot set tensor: Got tensor of type *INT32* but expected type FLOAT32 for input 1, name: conv2d_18_input\r\n\r\nIt seems like this error appear when trying to use the representative dataset. By looking at my script, I remembered this line I wrote when collecting the sample data used in the representative dataset:\r\n\r\n`# Cutting the line into array of values\r\nstr_values = line.split()\r\nvalues = [[int(nb)] for nb in str_values]`\r\n\r\nSo, naturally, I changed the int cast to a float cast, thinking it would come from that. I get the exact same error, except for the element in bold:\r\n\r\n> ValueError: Cannot set tensor: Got tensor of type NOTYPE but expected type FLOAT32 for input 1, name: conv2d_18_input \r\n\r\nThe error seems very weird, as the only thing I changed was that cast in the collection of the sample values. Could it come from the fact that I didn't change it in the collection of the training data and validation data?\r\n\r\nThe generated .tflite and .cc files are available on my github repository (https://github.com/GlennWasAlreadyTaken/CNN_M5Stack, in cnn/ folder). The code trying to make a fully quantized conversion into tflite is also available, in the .ipynb file in the same folder. \r\n", "I noticed that the inputs to the model are supplied as a list of arrays without any type.\r\nUpdate this to:\r\n`all_data = np.array(all_data, dtype=np.float32)`\r\nSimilarly update the validation and test datasets and try again.\r\n\r\n----------------------------------------\r\n\r\nThe optimization which you used is correct: `converter.optimizations = [tf.lite.Optimize.TFLITE_BUILTINS_INT8]`. I was referring to this one when I said `TFLITE_BUILTINS_INT8` -- sorry for not specifying it in detail.\r\n\r\nHowever, with further clarification from my team -- I've realized that it's best if you use\r\n`converter.optimizations = [tf.lite.Optimize.DEFAULT]` and NOT `tf.lite.Optimize.TFLITE_BUILTINS_INT8`. Instead, optimize as follows: \r\n\r\n```\r\nimport tensorflow as tf\r\n\r\ndef representative_dataset_gen():\r\n  for _ in range(num_calibration_steps):\r\n    # Get sample input data as a numpy array in a method of your choosing.\r\n    yield [input]\r\n\r\nconverter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nconverter.representative_dataset = representative_dataset_gen\r\ntflite_quant_model = converter.convert()\r\n```\r\n\r\nYou **need** to provide a representative dataset to ensure that the model is quantized correctly.  On doing this, the model will have float inputs and outputs and rest of the model would be int8 quantized. As you're using TF2.0, use this model as is and pass float values to the model in your interpreter code as well (which I think you've already done)", "I seem to have the same problem when using optimizations. My issue #36914 seems to be related to this one.", "@GlennWasAlreadyTaken seems like the issue could be with the Interpreter as another user (refer to the post above) is also facing this, apologies if so! I will get back to both these issues once I look into this further.", "@MeghnaNatraj I made the changes you suggested, and I think I have managed to make the model quantized correctly, as I got a tflite file produced with no error. However, I'm facing another error while allocating the tensors to the memory pool in the microcontroller code:\r\n\r\n> Didn't find op for builtin opcode 'DEPTHWISE_CONV_2D' version '3'\r\n> \r\n> Failed to gt registration from op code  d\r\n> \r\n> Guru Meditation Error: Core  1 panic'ed (LoadProhibited). Exception was unhandled.\r\n\r\nBy looking to the error, it also seems related to #36914 when trying to use a representative dataset.\r\nI've updated my training script code and tflite model on my repository.\r\n\r\n", "@GlennWasAlreadyTaken Thanks for the update! The correct way to fully integer quantize a model is given here: https://www.tensorflow.org/lite/performance/post_training_quantization#integer_only\r\n```\r\n# Convert a Tensorflow Model to a TFLite Fully Integer Quantized Model\r\nimport tensorflow as tf\r\nconverter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\ndef representative_dataset_gen():\r\n  for _ in range(num_calibration_steps):\r\n    # Get sample input data as a numpy array in a method of your choosing.\r\n    yield [input]\r\nconverter.representative_dataset = representative_dataset_gen\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\r\nconverter.inference_input_type = tf.int8  # or tf.uint8\r\nconverter.inference_output_type = tf.int8  # or tf.uint8\r\ntflite_quant_model = converter.convert()\r\n```\r\n\r\nThe basic TFLite Micro example, i.e, the [hello world example](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/micro/examples/hello_world/) has been updated as well:\r\n\r\n- [hello world training README](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/micro/examples/hello_world/train) \r\n- [hello world training using Google Colab](https://colab.sandbox.google.com/github/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/examples/hello_world/train/train_hello_world_model.ipynb) The colab uses the updated post training quantization steps, so either resources should be a good point to refer back to.\r\n\r\n"]}, {"number": 36942, "title": "[Intel MKL] Fixing Device() API usage in mkl_eager_op_rewrite.cc", "body": "API change in TF core caused a build failure in MKL CPU backend. This commit fixes the compilation failure.", "comments": []}, {"number": 36941, "title": "[XLA] Fix mode for some files", "body": "Based on @byronyi 's comment  on https://github.com/tensorflow/tensorflow/pull/31597 (https://github.com/tensorflow/tensorflow/pull/31597#issuecomment-584833205), fixed the modes on some files that were touched in https://github.com/tensorflow/tensorflow/pull/31597.\r\n", "comments": []}, {"number": 36940, "title": "typo or bug in documentation", "body": "https://www.tensorflow.org/tutorials/quickstart/advanced\r\n\r\nThis page has an example class \"MyModel\".  When it is invoked further down the page, it is invoked with a \"training\" keyword argument that does not appear to be in the definition.\r\n\r\nSlavishly copying the code produces this error:\r\n\r\n```\r\nTypeError: in converted code:\r\n\r\n    tf/tutorial.py:61 train_step *\r\n        predictions = model(images, training=True)\r\n    /usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:634 __call__\r\n        outputs = call_fn(inputs, *args, **kwargs)\r\n\r\n    TypeError: tf__call() got an unexpected keyword argument 'training'\r\n```\r\n\r\n**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow): NO, this is as appears on doc page.\r\nUsing singularity, with docker://tensorflow/tensorflow.\r\n\r\nWhen I remove the 'training' keyword, the operation executes, though I don't know if it's going to come out correctly or not. What is it supposed to do?\r\n\r\n```\r\nSingularity tf-py3.simg:~/projects> python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\" \r\n('v1.14.0-rc1-22-gaf24dc91b5', '1.14.0')\r\nSingularity tf-py3.simg:~/projects> \r\n```\r\n\r\n\r\n- OS Platform and Distribution (e.g.,\r\nLinux Ubuntu 16.04): \r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if\r\nthe issue happens on mobile device: \r\n- TensorFlow installed from (source or\r\nbinary): - TensorFlow version (use command below): \r\n- Python version: - Bazel\r\nversion (if compiling from source):\r\n- GCC/Compiler version (if compiling from\r\nsource): \r\n- CUDA/cuDNN version: - GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\n**Describe the expected behavior**\r\n\r\n**Standalone code to reproduce the issue** \r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["@tsgouros  Was able to execute the tutorial with out any errors on Colab. Please find the [gist](https://colab.sandbox.google.com/gist/saikumarchalla/6779bea9e27bb17b304c26502c88ca23/advanced.ipynb) here.Thanks!", "Thank you. Yes, it runs in that gist, but it still doesn't run for me. \r\n\r\nI constructed the script by copying and pasting, so I'm relatively sure there aren't typos. But more important, when I examine the gist code, I'm unable to see where the 'training' keyword is defined for the example model class. Perhaps that's part of the parent 'Model' class? But it isn't mentioned here: [https://keras.io/models/model/](https://keras.io/models/model/). Is there some version of Keras:Model that has this defined?\r\n\r\nMore detail here: I get some ominous warnings when I follow the instructions carefully. To me, they don't seem relevant to this problem, which just seems like a basic Python coding issue, but maybe they contain clues?\r\n\r\n```\r\n>>> class MyModel(Model):\r\n...     def __init__(self):\r\n...             super(MyModel, self).__init__()\r\n...             self.conv1 = Conv2D(32, 3, activation='relu')\r\n...             self.flatten = Flatten()\r\n...             self.d1 = Dense(128, activation='relu')\r\n...             self.d2 = Dense(10)\r\n...     def call(self,x):\r\n...             x = self.conv1(x)\r\n...             x = self.flatten(x)\r\n...             x=self.d1(x)\r\n...             return self.d2(x)\r\n... \r\n>>> (x_train, y_train), (x_test, y_test) = mnist.load_data()\r\n>>> x_train, x_test = x_train / 255.0, x_test / 255.0\r\n>>> x_train = x_train[..., tf.newaxis]\r\n>>> x_test = x_test[..., tf.newaxis]\r\n>>> train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(32)\r\n>>> test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)\r\n>>> model=MyModel()\r\nWARNING: Logging before flag parsing goes to stderr.\r\nW0224 08:39:02.590373 140374803265344 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling __init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nCall initializer instance with the dtype argument instead of passing it to the constructor\r\n>>> train_ds\r\n<DatasetV1Adapter shapes: ((?, 28, 28, 1), (?,)), types: (tf.float64, tf.uint8)>\r\n>>> for images, labels in train_ds:\r\n...     p = model(images, training=True)\r\n... \r\nW0224 08:43:44.608691 140374803265344 ag_logging.py:145] Entity <bound method MyModel.call of <__main__.MyModel object at 0x7fab8436f910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MyModel.call of <__main__.MyModel object at 0x7fab8436f910>>: ValueError: Unable to locate the source code of <bound method MyModel.call of <__main__.MyModel object at 0x7fab8436f910>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\r\nWARNING: Entity <bound method MyModel.call of <__main__.MyModel object at 0x7fab8436f910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MyModel.call of <__main__.MyModel object at 0x7fab8436f910>>: ValueError: Unable to locate the source code of <bound method MyModel.call of <__main__.MyModel object at 0x7fab8436f910>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 2, in <module>\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 634, in __call__\r\n    outputs = call_fn(inputs, *args, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/autograph/impl/api.py\", line 149, in wrapper\r\n    raise e.ag_error_metadata.to_exception(type(e))\r\nTypeError: in converted code:\r\n\r\n\r\n    TypeError: call() got an unexpected keyword argument 'training'\r\n\r\n>>> \r\n```\r\n\r\nI did try this as a script, with the verbosity set to 10:\r\n\r\n```\r\nSingularity tf-py3.simg:~/projects/tf> export AUTOGRAPH_VERBOSITY=10\r\nSingularity tf-py3.simg:~/projects/tf> ./tutorial.py\r\nWARNING: Logging before flag parsing goes to stderr.\r\nW0224 08:48:42.010809 140518177331008 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling __init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nCall initializer instance with the dtype argument instead of passing it to the constructor\r\n2020-02-24 08:48:42.061510: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2600075000 Hz\r\n2020-02-24 08:48:42.065871: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56487af63e70 executing computations on platform Host. Devices:\r\n2020-02-24 08:48:42.065931: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\r\n2020-02-24 08:48:42.082351: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\r\nTraceback (most recent call last):\r\n  File \"./tutorial.py\", line 89, in <module>\r\n    train_step(images, labels)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/eager/def_function.py\", line 414, in __call__\r\n    self._initialize(args, kwds, add_initializers_to=initializer_map)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/eager/def_function.py\", line 357, in _initialize\r\n    *args, **kwds))\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/eager/function.py\", line 1349, in _get_concrete_function_internal_garbage_collected\r\n    graph_function, _, _ = self._maybe_define_function(args, kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/eager/function.py\", line 1652, in _maybe_define_function\r\n    graph_function = self._create_graph_function(args, kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/eager/function.py\", line 1545, in _create_graph_function\r\n    capture_by_value=self._capture_by_value),\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/func_graph.py\", line 715, in func_graph_from_py_func\r\n    func_outputs = python_func(*func_args, **func_kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/eager/def_function.py\", line 307, in wrapped_fn\r\n    return weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/func_graph.py\", line 705, in wrapper\r\n    raise e.ag_error_metadata.to_exception(type(e))\r\nTypeError: in converted code:\r\n\r\n    ./tutorial.py:61 train_step *\r\n        predictions = model(images, training=True)\r\n    /usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:634 __call__\r\n        outputs = call_fn(inputs, *args, **kwargs)\r\n\r\n    TypeError: tf__call() got an unexpected keyword argument 'training'\r\n```", "@tsgouros  I tried to execute the code which you have provided but not getting any errors. please find the [gist](https://colab.sandbox.google.com/gist/saikumarchalla/4d99177cc6473ce579616e4adab61ba8/36940.ipynb) here.Thanks!", "Fair enough, but the error I'm getting is very specific. The 'training' keyword argument that's tripping me up is not defined in this example code, so it must be inherited from the Model object of Keras, no? How would I check for a version mismatch? I don't see it in the Keras documentation I linked to. Where did it come from? The docker tensorflow thing equipped me with Python 2.7.15. Could that be an issue? \r\n\r\nObviously the code runs for some people. Any clues about why it might not run for me are welcome. Thanks.", "Now I get it, you are using Tensorflow 1.14 for this tutorial. Please use tensorflow 2.0 as this tutorial is supposed to run in Tensorflow 2.0.\r\n\r\nTo check your tensorflow version, please use \r\n```\r\nimport tensorflow as tf\r\ntf.__version__\r\n```\r\nClosing this issue as it has been resolved.", "Thank you, that does appear to be the problem. Fixed now."]}, {"number": 36939, "title": "[XLA:GPU][ROCm]Fixing address space cast in reduction epilog", "body": "Introduced by commit 0c3feb1. 10+ regressions in the unit test that complained below:\r\n\r\n> Internal: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:425) !llvm::verifyModule(llvm_module, &err_stream) Invalid LLVM IR before optimizations:\r\nInvalid operands for select instruction!\r\n  %635 = select i1 %634, float* %632, float addrspace(5)* %633\r\n\r\nThis CL does two things:\r\n- Make sure there is a address space cast for the newly allocated local, by `shared_to_global` helper function\r\n- Make sure the allocation happens at function entry\r\n\r\n/cc: @whchung ", "comments": []}]