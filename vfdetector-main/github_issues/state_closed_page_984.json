[{"number": 23884, "title": "Fix: protobuf hardcoded url in contrib/makefile", "body": "Fixed contrib/makefile/download_dependencies.sh protobuf hardcoded url.\r\n\r\nIt will now look for the required version in the bazel workspace file instead of downloading an incompatible version whenever there is a change.", "comments": ["Nagging Reviewer @petewarden, @wolffg: You have been added as a reviewer to this pull request. Please add your review or reassign. It has been 29 days with no activity and the `awaiting review` label has been applied.", "The issue looks to be fixed by https://github.com/tensorflow/tensorflow/commit/5bedbfd6211aedadb70b40a8e2729cb792754ff3"]}, {"number": 23883, "title": "pip install tensorflow not working for py version 3.7.0 and 3.7.1", "body": "\r\n**System information**\r\n- OS : Win 10\r\n- TensorFlow installed from : pip\r\n- TensorFlow version: 1.12.0\r\n- Python version: 3.7.0 and 3.7.1\r\n- Installed using: pip\r\n\r\n\r\n\r\n`$ python --version`\r\n`Python 3.7.1`\r\n`pip --version`\r\n`pip 18.1`\r\n`pip install tensorflow`", "comments": ["@gatarelib  We are maintaining a single issue i.e #20517 to track tensorflow compatibility with Python 3.7. Request you to refer it and post your comments there. Thank you !"]}, {"number": 23882, "title": "The same op seed gives different results in eager execution", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux openSUSE Leap 42.3\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: none\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v1.12.0-0-ga6d8ffae09 1.12.0\r\n- Python version: 3.6.4\r\n- Bazel version (if compiling from source): none\r\n- GCC/Compiler version (if compiling from source): none\r\n- CUDA/cuDNN version: none\r\n- GPU model and memory: none\r\n\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n**Describe the current behavior**\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\ntf.enable_eager_execution()\r\n\r\na = tf.random_uniform((3, ), seed=0)\r\nb = tf.random_uniform((3, ), seed=0)\r\nprint(a)\r\nprint(b)\r\n```\r\n\r\nprints\r\n\r\n```\r\ntf.Tensor([0.10086262 0.9701668  0.8487642 ], shape=(3,), dtype=float32)\r\ntf.Tensor([0.5689162  0.31256282 0.09009469], shape=(3,), dtype=float32)\r\n```\r\n\r\nWhen run in a graph, the output is the same.\r\n\r\n**Describe the expected behavior**\r\n\r\nI would have expected the output to be same in eager mode as well, just like in graph mode.\r\n", "comments": ["The behavior is caused by the fact that eager engine caches and reuses the same op node, and the random_uniform node has an internal state so multiple executions of it give different results. We are addressing this problem by a comprehensive overhaul in RFC tensorflow/community#38. Please comment on that.", "I'm closing this since the new RNGs (https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/stateful_random_ops.py) are ready."]}, {"number": 23881, "title": "tensorflow1.8 cuda 9.0 cuDNN ubuntu16.04 install wrong", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version:1.8.0-gpu\r\n- Python version:3.5.2\r\n- Installed using virtualenv? pip? conda?:pip\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):4.4\r\n- CUDA/cuDNN version:9/7\r\n- GPU model and memory:1050 Ti  4g\r\n\r\nwhen i used python to import tensorflow as tf ,there is a problem :ImportError: libcusolver.so.8.0: cannot open shared object file: No such file or directory. but when i searched the file in the /usr/local/cuda/lib64, there existed a file named libcusolver.so.9.0.\r\n\r\n", "comments": ["@banbsyip  We encourage users to stay with the two latest versions of TF.  Please use tensorflow 1.11 or 1.12. This issue would not occur with these versions.", "> @banbsyip We encourage users to stay with the two latest versions of TF. Please use tensorflow 1.11 or 1.12. This issue would not occur with these versions.\r\n\r\ni run a project with pycharm, it could work,then i uninstall the tensorflow1.8 and installed TensorFlow1.12, the same wrong came again,but i could run the project with pycharm yesterday night. this morning i run the project but failed, it shows taht  \"Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\" the detail as fllow:\r\n\r\n\r\nUsing TensorFlow backend.\r\n2018-11-21 09:16:41.195484: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\r\n2018-11-21 09:16:41.195534: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-11-21 09:16:41.195539: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \r\n2018-11-21 09:16:41.195543: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \r\n2018-11-21 09:16:41.195656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3638 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n2018-11-21 09:16:52.238761: E tensorflow/stream_executor/cuda/cuda_dnn.cc:373] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\r\n2018-11-21 09:16:52.241850: E tensorflow/stream_executor/cuda/cuda_dnn.cc:373] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\r\nTraceback (most recent call last):\r\n  File \"/home/cq/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\r\n    return fn(*args)\r\n  File \"/home/cq/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1319, in _run_fn\r\n    options, feed_dict, fetch_list, target_list, run_metadata)\r\n  File \"/home/cq/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1407, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.UnknownError: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\r\n     [[{{node conv1_1/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv1_1/Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer, conv1_1/weights/read)]]\r\n     [[{{node rois/Reshape/_97}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_587_rois/Reshape\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/cq/\u684c\u9762/chinese_ocr-master/demo.py\", line 21, in <module>\r\n    result, image_framed = ocr.model(image)\r\n  File \"/home/cq/\u684c\u9762/chinese_ocr-master/ocr.py\", line 83, in model\r\n    text_recs, img_framed, img = text_detect(img)\r\n  File \"/home/cq/\u684c\u9762/chinese_ocr-master/ctpn/text_detect.py\", line 90, in text_detect\r\n    scores, boxes, img, scale = ctpn(img)\r\n  File \"/home/cq/\u684c\u9762/chinese_ocr-master/ctpn/text_detect.py\", line 52, in ctpn\r\n    scores, boxes = test_ctpn(sess, net, img)\r\n  File \"/home/cq/\u684c\u9762/chinese_ocr-master/ctpn/lib/fast_rcnn/test.py\", line 51, in test_ctpn\r\n    rois = sess.run([net.get_output('rois')[0]],feed_dict=feed_dict)\r\n  File \"/home/cq/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 929, in run\r\n    run_metadata_ptr)\r\n  File \"/home/cq/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/home/cq/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\r\n    run_metadata)\r\n  File \"/home/cq/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.UnknownError: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\r\n     [[node conv1_1/Conv2D (defined at /home/cq/\u684c\u9762/chinese_ocr-master/ctpn/lib/networks/network.py:167)  = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv1_1/Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer, conv1_1/weights/read)]]\r\n     [[{{node rois/Reshape/_97}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_587_rois/Reshape\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\r\n\r\nCaused by op 'conv1_1/Conv2D', defined at:\r\n  File \"/home/cq/\u684c\u9762/chinese_ocr-master/demo.py\", line 3, in <module>\r\n    import ocr\r\n  File \"<frozen importlib._bootstrap>\", line 969, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 958, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 673, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 665, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 222, in _call_with_frames_removed\r\n  File \"/home/cq/\u684c\u9762/chinese_ocr-master/ocr.py\", line 10, in <module>\r\n    from ctpn.text_detect import text_detect\r\n  File \"<frozen importlib._bootstrap>\", line 969, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 958, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 673, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 665, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 222, in _call_with_frames_removed\r\n  File \"/home/cq/\u684c\u9762/chinese_ocr-master/ctpn/text_detect.py\", line 45, in <module>\r\n    sess, net = load_tf_model()\r\n  File \"/home/cq/\u684c\u9762/chinese_ocr-master/ctpn/text_detect.py\", line 30, in load_tf_model\r\n    net = get_network(\"VGGnet_test\")\r\n  File \"/home/cq/\u684c\u9762/chinese_ocr-master/ctpn/lib/networks/factory.py\", line 8, in get_network\r\n    return VGGnet_test()\r\n  File \"/home/cq/\u684c\u9762/chinese_ocr-master/ctpn/lib/networks/VGGnet_test.py\", line 14, in __init__\r\n    self.setup()\r\n  File \"/home/cq/\u684c\u9762/chinese_ocr-master/ctpn/lib/networks/VGGnet_test.py\", line 21, in setup\r\n    .conv(3, 3, 64, 1, 1, name='conv1_1')\r\n  File \"/home/cq/\u684c\u9762/chinese_ocr-master/ctpn/lib/networks/network.py\", line 23, in layer_decorated\r\n    layer_output = op(self, layer_input, *args, **kwargs)\r\n  File \"/home/cq/\u684c\u9762/chinese_ocr-master/ctpn/lib/networks/network.py\", line 176, in conv\r\n    conv = convolve(input, kernel)\r\n  File \"/home/cq/\u684c\u9762/chinese_ocr-master/ctpn/lib/networks/network.py\", line 167, in <lambda>\r\n    convolve = lambda i, k: tf.nn.conv2d(i, k, [1, s_h, s_w, 1], padding=padding)\r\n  File \"/home/cq/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 957, in conv2d\r\n    data_format=data_format, dilations=dilations, name=name)\r\n  File \"/home/cq/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/home/cq/anaconda3/lib/python3.5/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/home/cq/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\r\n    op_def=op_def)\r\n  File \"/home/cq/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\nUnknownError (see above for traceback): Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\r\n     [[node conv1_1/Conv2D (defined at /home/cq/\u684c\u9762/chinese_ocr-master/ctpn/lib/networks/network.py:167)  = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv1_1/Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer, conv1_1/weights/read)]]\r\n     [[{{node rois/Reshape/_97}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_587_rois/Reshape\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\r\n", "> > @banbsyip We encourage users to stay with the two latest versions of TF. Please use tensorflow 1.11 or 1.12. This issue would not occur with these versions.\r\n> \r\n> i run a project with pycharm, it could work,then i uninstall the tensorflow1.8 and installed TensorFlow1.12, the same wrong came again,but i could run the project with pycharm yesterday night. this morning i run the project but failed, it shows taht \"Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\" the detail as fllow:\r\n> \r\n> Using TensorFlow backend.\r\n> 2018-11-21 09:16:41.195484: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\r\n> 2018-11-21 09:16:41.195534: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n> 2018-11-21 09:16:41.195539: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988] 0\r\n> 2018-11-21 09:16:41.195543: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0: N\r\n> 2018-11-21 09:16:41.195656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3638 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n> 2018-11-21 09:16:52.238761: E tensorflow/stream_executor/cuda/cuda_dnn.cc:373] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\r\n> 2018-11-21 09:16:52.241850: E tensorflow/stream_executor/cuda/cuda_dnn.cc:373] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\r\n> Traceback (most recent call last):\r\n> File \"/home/cq/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\r\n> return fn(*args)\r\n> File \"/home/cq/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1319, in _run_fn\r\n> options, feed_dict, fetch_list, target_list, run_metadata)\r\n> File \"/home/cq/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1407, in _call_tf_sessionrun\r\n> run_metadata)\r\n> tensorflow.python.framework.errors_impl.UnknownError: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\r\n> [[{{node conv1_1/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv1_1/Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer, conv1_1/weights/read)]]\r\n> [[{{node rois/Reshape/_97}} = _Recvclient_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_587_rois/Reshape\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]]\r\n> \r\n> During handling of the above exception, another exception occurred:\r\n> \r\n> Traceback (most recent call last):\r\n> File \"/home/cq/\u684c\u9762/chinese_ocr-master/demo.py\", line 21, in \r\n> result, image_framed = ocr.model(image)\r\n> File \"/home/cq/\u684c\u9762/chinese_ocr-master/ocr.py\", line 83, in model\r\n> text_recs, img_framed, img = text_detect(img)\r\n> File \"/home/cq/\u684c\u9762/chinese_ocr-master/ctpn/text_detect.py\", line 90, in text_detect\r\n> scores, boxes, img, scale = ctpn(img)\r\n> File \"/home/cq/\u684c\u9762/chinese_ocr-master/ctpn/text_detect.py\", line 52, in ctpn\r\n> scores, boxes = test_ctpn(sess, net, img)\r\n> File \"/home/cq/\u684c\u9762/chinese_ocr-master/ctpn/lib/fast_rcnn/test.py\", line 51, in test_ctpn\r\n> rois = sess.run([net.get_output('rois')[0]],feed_dict=feed_dict)\r\n> File \"/home/cq/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 929, in run\r\n> run_metadata_ptr)\r\n> File \"/home/cq/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\r\n> feed_dict_tensor, options, run_metadata)\r\n> File \"/home/cq/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\r\n> run_metadata)\r\n> File \"/home/cq/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\r\n> raise type(e)(node_def, op, message)\r\n> tensorflow.python.framework.errors_impl.UnknownError: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\r\n> [[node conv1_1/Conv2D (defined at /home/cq/\u684c\u9762/chinese_ocr-master/ctpn/lib/networks/network.py:167) = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv1_1/Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer, conv1_1/weights/read)]]\r\n> [[{{node rois/Reshape/_97}} = _Recvclient_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_587_rois/Reshape\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]]\r\n> \r\n> Caused by op 'conv1_1/Conv2D', defined at:\r\n> File \"/home/cq/\u684c\u9762/chinese_ocr-master/demo.py\", line 3, in \r\n> import ocr\r\n> File \"\", line 969, in _find_and_load\r\n> File \"\", line 958, in _find_and_load_unlocked\r\n> File \"\", line 673, in _load_unlocked\r\n> File \"\", line 665, in exec_module\r\n> File \"\", line 222, in _call_with_frames_removed\r\n> File \"/home/cq/\u684c\u9762/chinese_ocr-master/ocr.py\", line 10, in \r\n> from ctpn.text_detect import text_detect\r\n> File \"\", line 969, in _find_and_load\r\n> File \"\", line 958, in _find_and_load_unlocked\r\n> File \"\", line 673, in _load_unlocked\r\n> File \"\", line 665, in exec_module\r\n> File \"\", line 222, in _call_with_frames_removed\r\n> File \"/home/cq/\u684c\u9762/chinese_ocr-master/ctpn/text_detect.py\", line 45, in \r\n> sess, net = load_tf_model()\r\n> File \"/home/cq/\u684c\u9762/chinese_ocr-master/ctpn/text_detect.py\", line 30, in load_tf_model\r\n> net = get_network(\"VGGnet_test\")\r\n> File \"/home/cq/\u684c\u9762/chinese_ocr-master/ctpn/lib/networks/factory.py\", line 8, in get_network\r\n> return VGGnet_test()\r\n> File \"/home/cq/\u684c\u9762/chinese_ocr-master/ctpn/lib/networks/VGGnet_test.py\", line 14, in **init**\r\n> self.setup()\r\n> File \"/home/cq/\u684c\u9762/chinese_ocr-master/ctpn/lib/networks/VGGnet_test.py\", line 21, in setup\r\n> .conv(3, 3, 64, 1, 1, name='conv1_1')\r\n> File \"/home/cq/\u684c\u9762/chinese_ocr-master/ctpn/lib/networks/network.py\", line 23, in layer_decorated\r\n> layer_output = op(self, layer_input, *args, **kwargs)\r\n> File \"/home/cq/\u684c\u9762/chinese_ocr-master/ctpn/lib/networks/network.py\", line 176, in conv\r\n> conv = convolve(input, kernel)\r\n> File \"/home/cq/\u684c\u9762/chinese_ocr-master/ctpn/lib/networks/network.py\", line 167, in \r\n> convolve = lambda i, k: tf.nn.conv2d(i, k, [1, s_h, s_w, 1], padding=padding)\r\n> File \"/home/cq/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 957, in conv2d\r\n> data_format=data_format, dilations=dilations, name=name)\r\n> File \"/home/cq/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n> op_def=op_def)\r\n> File \"/home/cq/anaconda3/lib/python3.5/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\r\n> return func(*args, **kwargs)\r\n> File \"/home/cq/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\r\n> op_def=op_def)\r\n> File \"/home/cq/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1770, in **init**\r\n> self._traceback = tf_stack.extract_stack()\r\n> \r\n> UnknownError (see above for traceback): Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\r\n> [[node conv1_1/Conv2D (defined at /home/cq/\u684c\u9762/chinese_ocr-master/ctpn/lib/networks/network.py:167) = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv1_1/Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer, conv1_1/weights/read)]]\r\n> [[{{node rois/Reshape/_97}} = _Recvclient_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_587_rois/Reshape\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]]\r\n\r\ni changed tensorflow1.12 to 1.9,the problem above disappeared, the new problems as follow:\r\n2018-11-21 14:33:14.477867: E tensorflow/stream_executor/cuda/cuda_blas.cc:459] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\r\n2018-11-21 14:33:14.481006: E tensorflow/stream_executor/cuda/cuda_blas.cc:459] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\r\n2018-11-21 14:33:14.482237: E tensorflow/stream_executor/cuda/cuda_blas.cc:459] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\r\n2018-11-21 14:33:14.483350: E tensorflow/stream_executor/cuda/cuda_blas.cc:459] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\r\n2018-11-21 14:33:14.484005: E tensorflow/stream_executor/cuda/cuda_blas.cc:459] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\r\n2018-11-21 14:33:14.488353: E tensorflow/stream_executor/cuda/cuda_dnn.cc:332] could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR", "i have to run the command \"rm -rf ~/.nv/\" after run the project each time, otherwise the problem will appear again, i do not know the reason", "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.7)\r\nconfig = tf.ConfigProto(allow_soft_placement=True, gpu_options=gpu_options)\r\nsess = tf.Session(config=config)\r\ni found the reason finally, i changed the per_process_gpu_memory_fraction set, it worked. so i colse the issue.", "Have about the same error on Ubuntu 16:\r\n`UnknownError (see above for traceback): Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.`\r\n\r\nI have installed tensorflow via: `sudo pip3 install tensorflow-gpu==1.12.0`, cuda-9.0 is under `/usr/local/cuda/`.\r\n\r\nI have installed cudnn  and it's not helped:\r\nhttps://gist.github.com/kylemcdonald/3ae0b88a1bf91afc00ba441fe6823a17", "> Have about the same error on Ubuntu 16:\r\n> `UnknownError (see above for traceback): Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.`\r\n> \r\n> I have installed tensorflow via: `sudo pip3 install tensorflow-gpu==1.12.0`, cuda-9.0 is under `/usr/local/cuda/`.\r\n> \r\n> I have installed cudnn and it's not helped:\r\n> https://gist.github.com/kylemcdonald/3ae0b88a1bf91afc00ba441fe6823a17\r\n\r\nmy problem is that the memory of gpu is not enough,so I setted the gpu_options in the project as follow:\r\ngpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.7)\r\nconfig = tf.ConfigProto(allow_soft_placement=True, gpu_options=gpu_options)\r\nI've just used TensorFlow, and a lot of things aren't clear yet.", "> Have about the same error on Ubuntu 16:\r\n> `UnknownError (see above for traceback): Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.`\r\n> \r\n> I have installed tensorflow via: `sudo pip3 install tensorflow-gpu==1.12.0`, cuda-9.0 is under `/usr/local/cuda/`.\r\n> \r\n> I have installed cudnn and it's not helped:\r\n> https://gist.github.com/kylemcdonald/3ae0b88a1bf91afc00ba441fe6823a17\r\nhttps://github.com/tensorflow/tensorflow/issues/6698\r\n", "I think in my case it was I cuda vs cudnn version mismatch \r\nhttps://stackoverflow.com/questions/50622525/which-tensorflow-and-cuda-version-combinations-are-compatible"]}, {"number": 23880, "title": "[tf.keras] Enable tf.keras.callbacks.CallbackList API for tf.keras", "body": "In keras I'm used to use `keras.callbacks.CallbackList` I'd like to be able to use it also in the tf.keras this PR should enable the API `tf.keras.callbacks.CallbackList`.", "comments": ["@karmel @harshini-gadige any progress reviewing this PR? It'd be nice to have this in one of the next tensorflow releases. I assume that this might be beneficial for people that are used to standard keras in order to have the same API also for the `tf.keras`.", "Thanks for the PR. Can you clarify why you want to use CallbackList as a public API?", "@karmel I'm used to it from Keras. It very much simplifies the code if you need to do a custom training for example training of GANs, etc. When you're working with several callbacks there at once.\r\nYou can do something like:\r\n```\r\ncallbacks = CallbackList(callbacks)\r\ncallbacks.set_model(model)\r\ncallbacks.set_params({....})\r\ncallbacks.on_train_begin()\r\n....\r\n```\r\nOtherwise I'd have to do for loop for each of the callbacks. So `CallbackList` as it was available in Keras simplified things a lot.\r\n\r\nIt's probably the very last thing that's preventing me from smooth migrating from keras to tf.keras, ehich I'd prefer since I'm using only tensorflow as a backend.", "Assigning to @fchollet for thoughts on exposing CallbackList to the public API.", "@fchollet @karmel any progress reviewing this PR?", "@fchollet @karmel @harshini-gadige any progress reviewing and possibly merging this one-line PR?", "> @fchollet @karmel @harshini-gadige any progress reviewing and possibly merging this one-line PR?\r\n\r\n@karmel  @fchollet  Any update please ?", "@omalleyt12 do you see any downsides here? I am okay with this in theory.", "> @omalleyt12 do you see any downsides here? I am okay with this in theory.\r\n\r\nHm, I'm torn because It's mostly an implementation detail, but I see the benefit for the use @ziky90 is mentioning. I don't see `CallbackList` documented in external Keras docs https://keras.io/callbacks/ \r\n\r\n2 potential downsides are:\r\n\r\n1) Users might do: `model.fit(x, y, callbacks=keras.callbacks.CallbackList([cb1, cb2]))` which will actually short-circuit our Callback configuration logic as it's currently written\r\n\r\n2) If anyone subclasses this class and overrides methods for use in Keras's own fit/eval/predict, there will be some unintuitive behavior. (Methods like `on_test_batch_begin` are never called directly in these loops, instead `_call_batch_hook` is called). But I don't see many users wanting to do that.\r\n\r\n@ziky90 you ought to be able to do:\r\n\r\n```python\r\nfrom tensorflow.python.keras.callbacks import CallbackList\r\n```", "@omalleyt12 thank you\r\n`from tensorflow.python.keras.callbacks import CallbackList` works for me, but it is a bit hacky way, right? I assume that one shouldn't use imports from `tensorflow.python` at all, right?\r\n\r\nRegarding the downsides:\r\nIs 1. a problem? I don't think so.\r\n2. You're right, might be a problem.", "Nagging Reviewer @karmel, @fchollet: You have been added as a reviewer to this pull request. Please add your review or reassign. It has been 14 days with no activity and the `awaiting review` label has been applied.", "@ziky90 -- it sounds like the direct import is working for you? Can we close this PR? Thanks--", "@karmel It works for me, so we can close the PR for now.", "I'm not sure where to submit this, but this line of code wasn't in the 2.0 version I built from source. I added it in manually to my local version, but it still did not fully fix the problem.\r\n\r\nBasically, I can use \r\n`from tensorflow.python.keras.callbacks import CallbackList`\r\nbut not\r\n`from tensorflow.keras.callbacks import CallbackList`\r\nafter adding the line of code in the original pull request above.\r\n\r\nTo fix this, I had to go into the machine-generated code (not ideal I know) in \"tensorflow/_api/v1/keras/callbacks/__init__.py\" and add\r\n`from tensorflow.python.keras.callbacks import CallbackList`\r\n\r\nPerhaps someone could reopen this pull request, add that to the build code (that creates the machine-generated code) and close it? That's kind of outside of my knowledge. Thanks!"]}, {"number": 23879, "title": "1 error detected in the compilation of \"C:/Users/dorp/AppData/Local/Temp/nvcc_in ter_files_tmp_dir/reduce_slice_ops_gpu.cu.compute_70.cpp1.ii\".", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 7\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 1.11/1.12\r\n- Python version:2.6\r\n- Bazel version (if compiling from source):1.18\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:9/9.2\r\n- GPU model and memory:gtx1070 8gb\r\n\r\nUsed the command:\r\n\r\n> C:\\Users\\dorp\\Desktop\\tensorflow-1.11.0>bazel build --config=opt --config=cuda -\r\n-define=no_tensorflow_py_deps=true //tensorflow/tools/pip_package:build_pip_pack\r\nage\r\n\r\nAnd got the error\r\n> 1 error detected in the compilation of \"C:/Users/dorp/AppData/Local/Temp/nvcc_in\r\nter_files_tmp_dir/reduce_slice_ops_gpu.cu.compute_70.cpp1.ii\".\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 285.274s, Critical Path: 58.63s\r\nINFO: 1550 processes: 1550 local.\r\nFAILED: Build did NOT complete successfully\r\nFAILED: Build did NOT complete successfully\r\n\r\n\r\n", "comments": ["@dorp92  Please try wih Bazel 0.15 and CUDA 9, cuDNN 7", "Closing as this issue is in \"awaiting response\" status for more than 7 days and did not hear back from the user. Please post your comments if any, we will reopen. Thanks !", "Are you satisfied with the resolution of your issue?\r\n[Yes](https://goo.gl/forms/Oe0tEvODFRoI2gJF3)\r\n[No](https://goo.gl/forms/fUjzOfrtkFbrOT8d2)"]}, {"number": 23878, "title": "Bug: instantiating dynamic_rnn with tf.int32 in input and state raises TypeError", "body": "**System information**\r\n- OS Platform: OS X 10.13.3\r\n- Custom code\r\n- tensorflow version: 1.12.0\r\n- python version: 3.6.5\r\n\r\n**Describe the current behavior**\r\nTensorflow raises a TypeError when creating a dynamic_rnn with tf.int32 type in its input and state. When changing the type to tf.float32 the error is not raised.\r\n\r\n**Describe the expected behavior**\r\nIdeally, a dynamic_rnn should support tf.in32 types. If there's any reason why instantiating a dynamic_rnn with tf.int32 type in its input and state should not be allowed, a custom error should be raised.  \r\n\r\n**Code to reproduce the issue**\r\nThe code below reproduces the error:\r\n```\r\nimport tensorflow as tf\r\n\r\nX = tf.placeholder(tf.int32, [None, 10, 1])\r\ncell = tf.nn.rnn_cell.LSTMCell(1, dtype=tf.int32)\r\noutput, state = tf.nn.dynamic_rnn(cell=cell, inputs=X, dtype=tf.int32)\r\n\r\n```\r\nThe code below doesn't:\r\n```\r\n\r\nimport tensorflow as tf\r\n\r\nX = tf.placeholder(tf.float32, [None, 10, 1])\r\ncell = tf.nn.rnn_cell.LSTMCell(1, dtype=tf.float32)\r\noutput, state = tf.nn.dynamic_rnn(cell=cell, inputs=X, dtype=tf.float32)\r\n\r\n```\r\n\r\nNote the change in dtype.\r\n\r\n**Other info / logs**\r\nTRACEBACK:\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-3-1d83a30f7748> in <module>()\r\n      2 X = tf.placeholder(tf.int32, [None, 10, 1])\r\n      3 cell = tf.nn.rnn_cell.LSTMCell(1, dtype=tf.int32)\r\n----> 4 output, state = tf.nn.dynamic_rnn(cell=cell, inputs=X, dtype=tf.int32)#, initial_state=state)\r\n      5 \r\n\r\n~/jonassucks3/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py in dynamic_rnn(cell, inputs, sequence_length, initial_state, dtype, parallel_iterations, swap_memory, time_major, scope)\r\n    662         swap_memory=swap_memory,\r\n    663         sequence_length=sequence_length,\r\n--> 664         dtype=dtype)\r\n    665 \r\n    666     # Outputs of _dynamic_rnn_loop are always shaped [time, batch, depth].\r\n\r\n~/jonassucks3/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py in _dynamic_rnn_loop(cell, inputs, initial_state, parallel_iterations, swap_memory, sequence_length, dtype)\r\n    870       parallel_iterations=parallel_iterations,\r\n    871       maximum_iterations=time_steps,\r\n--> 872       swap_memory=swap_memory)\r\n    873 \r\n    874   # Unpack final output if not using output tuples.\r\n\r\n~/jonassucks3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py in while_loop(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\r\n   3289       ops.add_to_collection(ops.GraphKeys.WHILE_CONTEXT, loop_context)\r\n   3290     result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants,\r\n-> 3291                                     return_same_structure)\r\n   3292     if maximum_iterations is not None:\r\n   3293       return result[1]\r\n\r\n~/jonassucks3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py in BuildLoop(self, pred, body, loop_vars, shape_invariants, return_same_structure)\r\n   3002       with ops.get_default_graph()._mutation_lock():  # pylint: disable=protected-access\r\n   3003         original_body_result, exit_vars = self._BuildLoop(\r\n-> 3004             pred, body, original_loop_vars, loop_vars, shape_invariants)\r\n   3005     finally:\r\n   3006       self.Exit()\r\n\r\n~/jonassucks3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py in _BuildLoop(self, pred, body, original_loop_vars, loop_vars, shape_invariants)\r\n   2937         flat_sequence=vars_for_body_with_tensor_arrays)\r\n   2938     pre_summaries = ops.get_collection(ops.GraphKeys._SUMMARY_COLLECTION)  # pylint: disable=protected-access\r\n-> 2939     body_result = body(*packed_vars_for_body)\r\n   2940     post_summaries = ops.get_collection(ops.GraphKeys._SUMMARY_COLLECTION)  # pylint: disable=protected-access\r\n   2941     if not nest.is_sequence(body_result):\r\n\r\n~/jonassucks3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py in <lambda>(i, lv)\r\n   3258         cond = lambda i, lv: (  # pylint: disable=g-long-lambda\r\n   3259             math_ops.logical_and(i < maximum_iterations, orig_cond(*lv)))\r\n-> 3260         body = lambda i, lv: (i + 1, orig_body(*lv))\r\n   3261 \r\n   3262     if context.executing_eagerly():\r\n\r\n~/jonassucks3/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py in _time_step(time, output_ta_t, state)\r\n    838           skip_conditionals=True)\r\n    839     else:\r\n--> 840       (output, new_state) = call_cell()\r\n    841 \r\n    842     # Keras cells always wrap state as list, even if it's a single tensor.\r\n\r\n~/jonassucks3/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py in <lambda>()\r\n    824     if is_keras_rnn_cell and not nest.is_sequence(state):\r\n    825       state = [state]\r\n--> 826     call_cell = lambda: cell(input_t, state)\r\n    827 \r\n    828     if sequence_length is not None:\r\n\r\n~/jonassucks3/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py in __call__(self, inputs, state, scope, *args, **kwargs)\r\n    368     # method.  See the class docstring for more details.\r\n    369     return base_layer.Layer.__call__(self, inputs, state, scope=scope,\r\n--> 370                                      *args, **kwargs)\r\n    371 \r\n    372 \r\n\r\n~/jonassucks3/lib/python3.6/site-packages/tensorflow/python/layers/base.py in __call__(self, inputs, *args, **kwargs)\r\n    372 \r\n    373       # Actually call layer\r\n--> 374       outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\r\n    375 \r\n    376     if not context.executing_eagerly():\r\n\r\n~/jonassucks3/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py in __call__(self, inputs, *args, **kwargs)\r\n    755       if not in_deferred_mode:\r\n    756         self._in_call = True\r\n--> 757         outputs = self.call(inputs, *args, **kwargs)\r\n    758         self._in_call = False\r\n    759         if outputs is None:\r\n\r\n~/jonassucks3/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py in call(self, inputs, state)\r\n   1003            sigmoid(i + self._w_i_diag * c_prev) * self._activation(j))\r\n   1004     else:\r\n-> 1005       c = (sigmoid(f + self._forget_bias) * c_prev + sigmoid(i) *\r\n   1006            self._activation(j))\r\n   1007 \r\n\r\nTypeError: unsupported operand type(s) for +: 'Tensor' and 'float'", "comments": ["Thanks for the clear repro example. Probably this is a duplicate of [#14729](https://github.com/tensorflow/tensorflow/issues/14729)", "Thanks for the report, I will take a look today or tomorrow.", "Sorry for the very late reply. After some digging, the root cause is because of the default forget gate bias being initialized as float. However, even casting it to be int32 will still causing the code to fail down the road since the activation function for LSTM (tanh and sigmoid) only support floating numbers. So the conclusion is that LSTM will only support floating numbers as the dtype for input and states.\r\n\r\nI will update the code to have a clear error message when the input dtype is not float number."]}, {"number": 23877, "title": "[XLA/AOT] Add check for --help command line option.", "body": "By default Flags::Parse from tensorflow util returns false\r\nif argv[1] == \"--help\" and in this case tfcompile fails with\r\nSIGABRT.\r\n\r\nExample:\r\ntfcompile --help\r\n\r\nOutput:\r\nAborted (core dumped)\r\n", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "PING @hawkinsp @harshini-gadige ", "PING^2 @tatatodd @harshini-gadige ", "Nagging Reviewer @tatatodd: You have been added as a reviewer to this pull request. Please add your review or reassign. It has been 14 days with no activity and the `awaiting review` label has been applied.", "@hgadig can you please change the reviewer, it's seems like, his account is not active for couple of months.", "> @hgadig can you please change the reviewer, it's seems like, his account is not active for couple of months.\r\n\r\nThanks for getting this to notice. ", "@jlebar  thans for the answer,\r\n\r\n> This looks fine to me, but to check my understanding, even without this change, --help prints the usage, the problem is that it also exits with an error code (and prints an error?) rather than exiting 0. Is that right?\r\n\r\nYes, as we can see https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/util/command_line_flags.cc#L280\r\nthe flag parser returns false in case args[1] == \"--help\", and after that the CHECK \r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/aot/tfcompile_main.cc#L140\r\nwill generate an error which cause a SIGABORT. ", "@jlebar @hgadig I was accidentally deleting the tf repo for this pull request and not able to update it, sorry for that.\r\n Can you please review this one https://github.com/tensorflow/tensorflow/pull/25017, I've updated it, regarding to your comments.\r\nThanks."]}, {"number": 23876, "title": "How to use tf.contrib.periodic_resample", "body": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version: 1.6.0\r\n- Doc Link: https://www.tensorflow.org/api_docs/python/tf/contrib/periodic_resample/periodic_resample\r\n\r\n\r\n**Describe the documentation issue**\r\nThere is no example on how to use the operation at all. Specifically, most graphs that this operation is useful for (DCGANs) use 4D tensors (batch size, height, width, channels), with the batch size being unknown already (``None``) and the operation should decrease a single dimension specified as ``None``. Since we usually don't want to decrease the batch size with this operation, I have no idea how to actually use it in this case.\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\nIf I understand how to actually use this function, yes.\r\n", "comments": ["@akshaym and @caisq seem to be the owners of this code.", "I don't know anything about `tf.contrib.periodic_resample`. Removing myself from assignees.", "I'm sorry, I don't know much about this code either. \r\n\r\nCC @mrry and @martinwicke who reviewed the original PR (https://github.com/tensorflow/tensorflow/pull/14339), @jhetherly who authored the original PR.", "This is in contrib, which is maintained and supported by the community. If you cannot identify an owner, you can ask on StackOverflow. If you cannot get help there, I fear that we won't be able to help."]}, {"number": 23875, "title": "DCGAN implementation differs between GitHub and Colab", "body": "There's a difference between the [DCGAN](https://github.com/tensorflow/tensorflow/blob/r1.11/tensorflow/contrib/eager/python/examples/generative_examples/dcgan.ipynb) implementation present on GitHub and the one present in Colab.\r\nAlso, they both suffer the same problem as #19643 #23873 ", "comments": ["This is no longer a issue, as contrib folder has been removed.Thank you "]}, {"number": 23874, "title": "warning \"using ptxas 10.0.145, which is older than 9.2.88\"", "body": "\"*** WARNING *** You are using ptxas 10.0.145, which is older than 9.2.88\"\r\nhttps://storage.googleapis.com/tf-performance/tf_binary/tensorflow-1.12.0.a6d8ffa.AVX2.CUDA10-cp27-cp27mu-linux_x86_64.whl\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/f827bad24efc949e657e141464ea1010c18d812c/tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc#L427 \r\n", "comments": ["It looks like you haven't used a template to create this issue. Please resubmit your issue using a template from [here](https://github.com/tensorflow/tensorflow/issues/new/choose). We ask users to use the template because it reduces overall time to resolve a new issue by avoiding extra communication to get to the root of the issue. We will close this issue in lieu of the new one you will create from the template. Thank you for your cooperation.\r\n", "This is a bug and has been fixed in https://github.com/tensorflow/tensorflow/commit/83ff640fa5026b8bd3cb9c2ceff9e99e8e03823a#diff-888940c777f83519bd1e27349427d51e .", "Closing since it has been resolved. Feel free to reopen the issue if the problem still persists. Thanks!\r\n\r\n> This is a bug and has been fixed in [83ff640#diff-888940c777f83519bd1e27349427d51e](https://github.com/tensorflow/tensorflow/commit/83ff640fa5026b8bd3cb9c2ceff9e99e8e03823a#diff-888940c777f83519bd1e27349427d51e) .\r\n\r\n"]}, {"number": 23873, "title": "Keras layers: no update ops added even when used as a \"simplified interface to Tensorflow\"", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Archlinux\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 1.12\r\n- Python version: 3.6\r\n- CUDA/cuDNN version: cuda 9.0, cudnn 7.1\r\n- GPU model and memory: nvidia 1080ti\r\n\r\n**Describe the current behavior**\r\n\r\nI'm migrating my codebase to a Tensorflow 2.0 compatible version, thus I'm replacing all the `tf.layers` call with their `tf.keras.layers` counterpart.\r\n\r\nI want to continue using static graphs and MonitoredSession to train my models (since I do have all the input pipelines defined with tf.data.Dataset and all the training script defined to work in this way).\r\n\r\nHowever, there's a huge problem when a layer adds some update operation (like the BatchNormalization layer).\r\n\r\nThe actual behavior is that the update operations (of moving mean and variance) are not called when training the model.\r\n\r\nThis can be OK in a full-keras solution, where the connection among models, the update operations and so on, are managed by the `train_on_batch` + `model.compile` + `model.fit` call (that do some magic in the background).\r\nIn fact, @fchollet said this is by design: https://github.com/tensorflow/tensorflow/issues/19643#issuecomment-394527486\r\n\r\nBut since I don't want to migrate to a full keras-based solution, how can I handle the updates?\r\n\r\nI found some theoretical workaround (collected the update operations `model.updates` + collect the inputs `model.inputs`, loop over the inputs, feed the correct input and execute with sess.run the updates), but those are really ugly and they don't work: I can trigger the parameter update, but the time-step of the update execution is wrong and the solution does not converge: moreover, when the model becomes complex (like in the example of BiGAN below) it can be a real mess and the code become unmaintenable.\r\n\r\n**Describe the expected behavior**\r\n\r\nWhen I'm using keras layers to define the models and I'm not calling `train_on_batch` or `compile` or any other method to train the model that's pure keras, the update operations should be placed into the graph (having thus the same behavior of the batch normalization layer present in `tf.layers`) and executed when model `.trainable` is `True`.\r\n\r\nMoreover, there's another strange behavour: when I define a model output passing a new input (hence I invoke the `Model.call` method) the update operation have no idea of this new input.\r\n\r\nProbably, the `.call` method shouln't just return the output tensor, but it should return a new `Model` that shared the same parameters of the orignial one, but defined with a new input (and thus with its update ops aware of the new input).\r\n\r\n**Code to reproduce the issue**\r\nA BiGAN implementation.\r\n\r\n```python\r\nfrom typing import Tuple, Callable, Any, Optional\r\nimport multiprocessing\r\nimport sys\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow import keras as k\r\nfrom tensorflow.python.training.summary_io import SummaryWriterCache\r\n\r\n\r\ndef dataset(\r\n    shape: Tuple[int, int],\r\n    batch_size: int = 32,\r\n    epochs: int = None,\r\n    train: bool = False,\r\n    _batch=True,\r\n) -> tf.data.Dataset:\r\n    \"\"\"Returns the dataset correcly batched and resized\r\n    Args:\r\n        shape: The output shape of the images in the Dataset\r\n        batch_size: The size of the batch to return at each invocation\r\n        epochs: The the number of times that the dataset will repeat itself\r\n                before throwing an exception\r\n        train: when True, returns the shuffled train dataset, when False returns\r\n               the test, not shuffled, dataset\r\n        _batch: private, do not use\r\n    Returns:\r\n        The dataset\r\n    \"\"\"\r\n\r\n    def _process(image, label):\r\n        \"\"\"The function used to resize the image to the specified shape.\r\n        Used in the tf.data.Dataset.map function\r\n        Args:\r\n            image: the input image\r\n            label: the input label\r\n        Return:\r\n            resized_image, label\r\n        \"\"\"\r\n        nonlocal shape\r\n        image = tf.image.resize_images(\r\n            tf.expand_dims(image, axis=0), shape, tf.image.ResizeMethod.NEAREST_NEIGHBOR\r\n        )\r\n        image = tf.cast(image, tf.float32)\r\n        image = tf.squeeze(image, axis=[0])\r\n        return image, label\r\n\r\n    (train_images, train_labels), (\r\n        test_images,\r\n        test_labels,\r\n    ) = k.datasets.cifar10.load_data()\r\n    if not train:\r\n        train_images = test_images\r\n        train_labels = test_labels\r\n    train_images = (train_images - 127.5) / 127.5\r\n\r\n    def _generator():\r\n        r\"\"\"The generator that returns the pair image,label\r\n        This must be used in order to don't use tf.data.Dataset.from_tensor_slices.abs\r\n        In this way, we can build a dataset from a generator and solve the problem of huge\r\n        graphs created by from_tensor_slices (it creates a constant in the graph :\\)\r\n        \"\"\"\r\n        for image, label in zip(train_images, train_labels):\r\n            yield image, label\r\n\r\n    def _set_shape(image, label):\r\n        \"\"\"Set the static + dynamic shape of the image, in order to correctly build the\r\n        input pipeline in both phases\r\n        Args:\r\n            image: the input image\r\n            label: the input label\r\n        Return:\r\n            image, label\r\n        \"\"\"\r\n        image.set_shape((32, 32, 3))  # static\r\n        image = tf.reshape(image, (32, 32, 3))  # dynamic\r\n        return image, label\r\n\r\n    _dataset = tf.data.Dataset.from_generator(\r\n        _generator, (tf.float32, tf.int32)\r\n    )  # unkown shape\r\n    _dataset = _dataset.map(\r\n        _set_shape, num_parallel_calls=multiprocessing.cpu_count()\r\n    )  # known static chsape\r\n\r\n    _dataset = _dataset.map(\r\n        _process, num_parallel_calls=multiprocessing.cpu_count()\r\n    )  # resize to desired input shape\r\n\r\n    if _batch:\r\n        _dataset = _dataset.batch(batch_size, drop_remainder=True)\r\n        if epochs:\r\n            _dataset = _dataset.repeat(epochs)\r\n    elif epochs:\r\n        _dataset = _dataset.repeat(epochs)\r\n\r\n    _dataset = _dataset.prefetch(1)\r\n    return _dataset\r\n\r\n\r\nKERNEL_INITIALIZER = k.initializers.RandomNormal(mean=0.0, stddev=0.02)\r\nALMOST_ONE = k.initializers.RandomNormal(mean=1.0, stddev=0.02)\r\n\r\n\r\ndef discriminator(\r\n    visual_shape: tf.TensorShape,\r\n    encoding_shape: tf.TensorShape,\r\n    conditioning: Optional[Any] = None,\r\n    l2_penalty: float = 0.0,\r\n) -> k.Model:\r\n    \"\"\"\r\n    Build the Discriminator model.\r\n\r\n    Returns a k.Model with 2 inputs and a single output.\r\n    The inputs are an image and its encoded/latent representation.\r\n\r\n    Args:\r\n        visual_shape: The shape of the visual input, 3D tensor\r\n        encoding_shape: The shape of the latent/encoded representation\r\n        # NOT IMPLEMENTED: Conditioning: data used as GAN conditioning\r\n        # UNUSED: l2_penalty: l2 regularization strength\r\n\r\n    Returns:\r\n        The discriminator model.\r\n\r\n    \"\"\"\r\n    kernel_size = (5, 5)\r\n\r\n    # Inputs\r\n    # (64, 64, C)\r\n    # (Latent Dimension, )\r\n    input_visual = k.layers.Input(shape=visual_shape)\r\n    input_encoding = k.layers.Input(shape=encoding_shape)\r\n\r\n    # Data\r\n    # ### Layer 0\r\n    # (64, 64, 32)\r\n    visual = k.layers.Conv2D(\r\n        filters=32,\r\n        kernel_size=kernel_size,\r\n        strides=(1, 1),\r\n        padding=\"same\",\r\n        kernel_initializer=KERNEL_INITIALIZER,\r\n        kernel_regularizer=k.regularizers.l2(l2_penalty),\r\n    )(input_visual)\r\n    visual = k.layers.LeakyReLU(alpha=0.1)(visual)\r\n\r\n    # Data\r\n    # ### Layer 1\r\n    # (32, 32, 32)\r\n    visual = k.layers.Conv2D(\r\n        filters=32,\r\n        kernel_size=kernel_size,\r\n        strides=(2, 2),\r\n        padding=\"same\",\r\n        kernel_initializer=KERNEL_INITIALIZER,\r\n        kernel_regularizer=k.regularizers.l2(l2_penalty),\r\n    )(visual)\r\n    visual = k.layers.BatchNormalization()(visual)\r\n    visual = k.layers.LeakyReLU(alpha=0.1)(visual)\r\n    visual = k.layers.Dropout(rate=0.5)(visual)\r\n\r\n    # ### Layer 2\r\n    # (16, 16, 64)\r\n    visual = k.layers.Conv2D(\r\n        filters=64,\r\n        kernel_size=kernel_size,\r\n        strides=(2, 2),\r\n        padding=\"same\",\r\n        kernel_initializer=KERNEL_INITIALIZER,\r\n    )(visual)\r\n    visual = k.layers.BatchNormalization()(visual)\r\n    visual = k.layers.LeakyReLU(alpha=0.1)(visual)\r\n    visual = k.layers.Dropout(rate=0.5)(visual)\r\n\r\n    # Flatten\r\n    visual = k.layers.Flatten()(visual)\r\n\r\n    # Encoding\r\n    # ### Layer 5 D(z)\r\n    # (512,)\r\n    encoding = k.layers.Dense(units=512, kernel_initializer=KERNEL_INITIALIZER)(\r\n        input_encoding\r\n    )\r\n    encoding = k.layers.LeakyReLU(alpha=0.1)(encoding)\r\n    encoding = k.layers.Dropout(rate=0.5)(encoding)\r\n\r\n    # Data + Encoding\r\n    # ### Layer 6 D(x, z)\r\n    # (4608,)\r\n    mixed = k.layers.Concatenate()([visual, encoding])\r\n    mixed = k.layers.Dense(units=1024, kernel_initializer=KERNEL_INITIALIZER)(mixed)\r\n    mixed = k.layers.LeakyReLU(alpha=0.1)(mixed)\r\n    mixed = k.layers.Dropout(rate=0.5)(mixed)\r\n    features = mixed\r\n\r\n    # Final Step\r\n    # ### Layer 7\r\n    # (1)\r\n    out = k.layers.Dense(1, kernel_initializer=KERNEL_INITIALIZER)(mixed)\r\n\r\n    # Use the functional interface\r\n    model = k.Model(inputs=[input_visual, input_encoding], outputs=[out, features])\r\n    model.summary()\r\n    return model\r\n\r\n\r\ndef generator(\r\n    input_shape: int,\r\n    output_depth: int = 3,\r\n    conditioning: Optional[Any] = None,\r\n    l2_penalty: float = 0.0,\r\n) -> k.Model:\r\n    \"\"\"\r\n    Build the Generator model.\r\n\r\n    Given a latent representation, generates a meaningful image.\r\n    The input shape must be in the form of a vector 1x1xD.\r\n\r\n    Args:\r\n        input_shape: The shape of the noise prior\r\n        output_depth: The number of channels of the generated image\r\n        # NOT IMPLEMENTED: Conditioning: data used as GAN conditioning\r\n        l2_penalty: l2 regularization strength\r\n\r\n    Returns:\r\n        The Generator model.\r\n\r\n    \"\"\"\r\n    kernel_size = (5, 5)\r\n    model = k.Sequential(name=\"generator\")\r\n\r\n    # Project and Reshape the latent space\r\n    # ### Layer 1\r\n    # (4*4*64,)\r\n    model.add(\r\n        k.layers.Dense(\r\n            units=4 * 4 * 64,\r\n            kernel_initializer=KERNEL_INITIALIZER,\r\n            input_shape=input_shape,\r\n            kernel_regularizer=k.regularizers.l2(l2_penalty),\r\n        )\r\n    )\r\n    model.add(k.layers.Activation(k.activations.relu))\r\n    model.add(k.layers.Reshape((4, 4, 64)))\r\n\r\n    # Starting Deconvolutions\r\n    # ### Layer 2\r\n    # (8, 8, 64)\r\n    model.add(\r\n        k.layers.Conv2DTranspose(\r\n            filters=64,\r\n            kernel_size=kernel_size,\r\n            strides=(2, 2),\r\n            padding=\"same\",\r\n            kernel_initializer=KERNEL_INITIALIZER,\r\n        )\r\n    )\r\n    model.add(k.layers.BatchNormalization())\r\n    model.add(k.layers.Activation(k.activations.relu))\r\n\r\n    # Starting Deconvolutions\r\n    # ### Layer 3\r\n    # (16, 16, 128)\r\n    model.add(\r\n        k.layers.Conv2DTranspose(\r\n            filters=128,\r\n            kernel_size=kernel_size,\r\n            strides=(2, 2),\r\n            padding=\"same\",\r\n            kernel_initializer=KERNEL_INITIALIZER,\r\n        )\r\n    )\r\n    model.add(k.layers.BatchNormalization())\r\n    model.add(k.layers.Activation(k.activations.relu))\r\n\r\n    # ### Layer 4\r\n    # (32, 32, 256)\r\n    model.add(\r\n        k.layers.Conv2DTranspose(\r\n            filters=256,\r\n            kernel_size=kernel_size,\r\n            strides=(2, 2),\r\n            padding=\"same\",\r\n            kernel_initializer=KERNEL_INITIALIZER,\r\n        )\r\n    )\r\n    model.add(k.layers.BatchNormalization())\r\n    model.add(k.layers.Activation(k.activations.relu))\r\n\r\n    # ### Layer 5\r\n    # (64, 64, C)\r\n    model.add(\r\n        k.layers.Conv2DTranspose(\r\n            filters=output_depth,\r\n            kernel_size=kernel_size,\r\n            strides=(2, 2),\r\n            padding=\"same\",\r\n            kernel_initializer=KERNEL_INITIALIZER,\r\n        )\r\n    )\r\n    model.add(k.layers.Activation(k.activations.tanh))  # G(z) in [-1,1]\r\n\r\n    model.summary()\r\n    return model\r\n\r\n\r\ndef encoder(\r\n    visual_shape: int, latent_dimension: int, l2_penalty: float = 0.0\r\n) -> k.Model:\r\n    \"\"\"\r\n    Build the Encoder model.\r\n\r\n    The encoder encodes the input in a vector with shape 1x1xlatent_dimension.\r\n\r\n    Args:\r\n        visual_shape: The shape of the input to encode\r\n        latent_dimension: The number of dimensions (along the depth) to use.\r\n        # NOT IMPLEMENTED: conditioning: Data used as GAN conditioning\r\n        l2_penalty: l2 regularization strength\r\n\r\n    Returns:\r\n        The Encoder model.\r\n\r\n    \"\"\"\r\n\r\n    kernel_size = (5, 5)\r\n\r\n    # Inputs\r\n    # (64, 64, C)\r\n    # (Latent Dimension, )\r\n    input_visual = k.layers.Input(shape=visual_shape)\r\n\r\n    # Data\r\n    # ### Layer 0\r\n    # (64, 64, 32)\r\n    visual = k.layers.Conv2D(\r\n        filters=32,\r\n        kernel_size=kernel_size,\r\n        strides=(1, 1),\r\n        padding=\"same\",\r\n        kernel_initializer=KERNEL_INITIALIZER,\r\n        kernel_regularizer=k.regularizers.l2(l2_penalty),\r\n    )(input_visual)\r\n    visual = k.layers.LeakyReLU(alpha=0.1)(visual)\r\n\r\n    # Data\r\n    # ### Layer 1\r\n    # (32, 32, 32)\r\n    visual = k.layers.Conv2D(\r\n        filters=32,\r\n        kernel_size=kernel_size,\r\n        strides=(2, 2),\r\n        padding=\"same\",\r\n        kernel_initializer=KERNEL_INITIALIZER,\r\n        kernel_regularizer=k.regularizers.l2(l2_penalty),\r\n    )(visual)\r\n    visual = k.layers.BatchNormalization()(visual)\r\n    visual = k.layers.LeakyReLU(alpha=0.1)(visual)\r\n    visual = k.layers.Dropout(rate=0.5)(visual)\r\n\r\n    # ### Layer 2\r\n    # (16, 16, 64)\r\n    visual = k.layers.Conv2D(\r\n        filters=128,\r\n        kernel_size=kernel_size,\r\n        strides=(2, 2),\r\n        padding=\"same\",\r\n        kernel_initializer=KERNEL_INITIALIZER,\r\n    )(visual)\r\n    visual = k.layers.BatchNormalization()(visual)\r\n    visual = k.layers.LeakyReLU(alpha=0.1)(visual)\r\n    visual = k.layers.Dropout(rate=0.5)(visual)\r\n\r\n    # Flatten\r\n    visual = k.layers.Flatten()(visual)\r\n\r\n    # Encoding\r\n    # (Latent space, )\r\n    # ### Layer 5\r\n    visual = k.layers.Dense(\r\n        units=latent_dimension, kernel_initializer=KERNEL_INITIALIZER\r\n    )(visual)\r\n\r\n    model = k.Model(inputs=input_visual, outputs=visual)\r\n    model.summary()\r\n    return model\r\n\r\n\r\ndef bce(x: tf.Tensor, label: tf.Tensor) -> tf.Tensor:\r\n    \"\"\"Returns the discrete binary cross entropy between x and the discrete label\r\n    Args:\r\n        x: a 2D tensor\r\n        label: the discrite label, aka, the distribution to match\r\n\r\n    Returns:\r\n        The binary cros entropy\r\n    \"\"\"\r\n    assert len(x.shape) == 2 and len(label.shape) == 0\r\n\r\n    return tf.losses.sigmoid_cross_entropy(tf.ones_like(x) * label, x)\r\n\r\n\r\ndef min_max(positive: tf.Tensor, negative: tf.Tensor) -> tf.Tensor:\r\n    \"\"\"Returns the discriminator (min max) loss\r\n    Args:\r\n        positive: the discriminator output for the positive class: 2D tensor\r\n        negative: the discriminator output for the negative class: 2D tensor\r\n    Returns:\r\n        The sum of 2 BCE\r\n    \"\"\"\r\n    one = tf.constant(1.0)\r\n    zero = tf.constant(0.0)\r\n    d_loss = bce(positive, one) + bce(negative, zero)\r\n    return d_loss\r\n\r\n\r\ndef train():\r\n    \"\"\"Train the GAN.\"\"\"\r\n    batch_size = 32\r\n    epochs = 100\r\n    latent_dimension = 100\r\n    l2_penalty = 0.0\r\n\r\n    x_, y_ = dataset((64, 64), batch_size, epochs).make_one_shot_iterator().get_next()\r\n\r\n    x = tf.placeholder(tf.float32, list(x_.shape))\r\n    tf.summary.image(\"x\", x, max_outputs=3)\r\n\r\n    # Define the Models\r\n    E = encoder(x.shape[1:], latent_dimension, l2_penalty)\r\n\r\n    z_ = tf.random_normal([batch_size, latent_dimension], mean=0.0, stddev=1.0)\r\n\r\n    z = tf.placeholder(tf.float32, list(z_.shape))\r\n    G = generator(z.shape[1:], x.shape[-1].value, l2_penalty)\r\n    D = discriminator(x.shape[1:], E.output.shape[1:], l2_penalty)\r\n\r\n    # Generate from latent representation z\r\n    G_z = G(z)\r\n    tf.summary.image(\"G(z)\", G_z, max_outputs=3)\r\n\r\n    # encode x to a latent representation\r\n    E_x = E(x)\r\n\r\n    G_Ex = G(E_x)\r\n    tf.summary.image(\"G(E(x))\", G_Ex, max_outputs=3)\r\n\r\n    # plot image difference\r\n    tf.summary.image(\r\n        \"G(E(x)) - x\", tf.norm(G_Ex - x_, axis=3, keepdims=True), max_outputs=3\r\n    )\r\n\r\n    # The output of the discriminator is a bs,n,n,value\r\n    # hence flatten all the values of the map and compute\r\n    # the loss element wise\r\n    D_Gz, F_Gz = D(inputs=[G_z, z])\r\n    D_x, F_x = D(inputs=[x, E_x])\r\n    D_Gz = k.layers.Flatten()(D_Gz)\r\n    F_Gz = k.layers.Flatten()(F_Gz)\r\n    D_x = k.layers.Flatten()(D_x)\r\n    F_x = k.layers.Flatten()(F_x)\r\n\r\n    ## Discriminator\r\n    d_loss = min_max(D_x, D_Gz)\r\n\r\n    ## Generator\r\n    g_loss = bce(D_Gz, tf.constant(1.0))\r\n    # Encoder\r\n    e_loss = bce(D_x, tf.constant(0.0))\r\n\r\n    # add regularizations defined in the keras layers\r\n    d_loss += tf.add_n(D.losses)\r\n    e_loss += tf.add_n(E.losses)\r\n    g_loss += tf.add_n(G.losses)\r\n\r\n    tf.summary.scalar(\"d_loss\", d_loss)\r\n    tf.summary.scalar(\"g_loss\", g_loss)\r\n    tf.summary.scalar(\"e_loss\", e_loss)\r\n\r\n    global_step = tf.train.get_or_create_global_step()\r\n\r\n    lr = 1e-4\r\n    tf.summary.scalar(\"lr\", lr)\r\n\r\n    # Define the D train op\r\n    train_d = tf.train.AdamOptimizer(lr, beta1=0.5).minimize(\r\n        d_loss, var_list=D.trainable_variables\r\n    )\r\n\r\n    # Define the G + E train ops (the models can be trained\r\n    # the same step, but separately)\r\n    train_g = tf.train.AdamOptimizer(lr, beta1=0.5).minimize(\r\n        g_loss, global_step=global_step, var_list=G.trainable_variables\r\n    )\r\n\r\n    train_e = tf.train.AdamOptimizer(lr, beta1=0.5).minimize(\r\n        e_loss, var_list=E.trainable_variables\r\n    )\r\n\r\n    log_dir = f\"logs/test\"\r\n    summary_op = tf.summary.merge_all()\r\n\r\n    scaffold = tf.train.Scaffold()\r\n    config = tf.ConfigProto()\r\n    config.gpu_options.allow_growth = True\r\n    session_creator = tf.train.ChiefSessionCreator(\r\n        config=config, scaffold=scaffold, checkpoint_dir=log_dir\r\n    )\r\n\r\n    def _loop(func: Callable) -> None:\r\n        \"\"\"\r\n        Execute func for the specified number of epochs or max_steps.\r\n\r\n        Args:\r\n            func: callable to loop\r\n\r\n        Returns:\r\n            None.\r\n        \"\"\"\r\n        try:\r\n            while True:\r\n                func()\r\n        except tf.errors.OutOfRangeError:\r\n            pass\r\n\r\n    with tf.train.MonitoredSession(\r\n        session_creator=session_creator,\r\n        hooks=[\r\n            tf.train.CheckpointSaverHook(log_dir, save_steps=100, scaffold=scaffold)\r\n            # tf.train.ProfilerHook(save_steps=1000, output_dir=log_dir),\r\n        ],\r\n    ) as sess:\r\n        # Get the summary writer.\r\n        # The rational behind using the writer (from the scaffold)\r\n        # and not using the SummarySaverHook is that we want to log\r\n        # every X steps the output of G, G(E(x)) and x\r\n        # But since we need to use placeholders to feed the same data\r\n        # to G, D and E, we can't use the Hook, because the first\r\n        # sess.run on the data, will trigger the summary save op\r\n        # and the summary save op needs the data from the placeholder\r\n        writer = SummaryWriterCache.get(log_dir)\r\n\r\n        def _train():\r\n            # First create the input, that must be shared between the 2\r\n            # training iteration\r\n            real, noise = sess.run([x_, z_])\r\n            feed_dict = {x: real, z: noise}\r\n\r\n            # train D\r\n            d_gz_, d_x, _, d_loss_value = sess.run(\r\n                [D_Gz, D_x, train_d, d_loss], feed_dict\r\n            )\r\n\r\n            # train G+E\r\n            _, g_loss_value, _, e_loss_value, step = sess.run(\r\n                [train_g, g_loss, train_e, e_loss, global_step], feed_dict\r\n            )\r\n\r\n            if step % 100 == 0:\r\n                summaries = sess.run(summary_op, feed_dict)\r\n                print(\r\n                    f\"[{step}] d: {d_loss_value} - g: {g_loss_value} - e: {e_loss_value}\"\r\n                )\r\n                print(np.mean(d_gz_), np.mean(d_x))\r\n                writer.add_summary(summaries, step)\r\n                writer.flush()\r\n\r\n        _loop(_train)\r\n    return 0\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    sys.exit(train())\r\n```\r\n", "comments": ["The same behavior seems to be present in your example of [DCGAN](https://github.com/tensorflow/tensorflow/blob/r1.11/tensorflow/contrib/eager/python/examples/generative_examples/dcgan.ipynb) if checking the value of the instanced layers of BatchNorm the moving mean and variance do not move at all.\r\n\r\nEDIT: since updates are not compatible with Eager Execution I was limited to checking the moving average/variance", "@galeone Your code is very long so I only skimmed it, but I think the gist of what you're saying is that `keras.layers.BatchNormalization` update is not being done during training. If that's the case, does it work if you collect the update ops as described in #19643 and use them as `control_dependencies` for your training ops (`train_d`, `train_g`, `train_e`)?", "It doesn't work because, as stated by @fchollet in the comment I linked, the update operations are no more added to the graph (in the global collection) by Keras design, because the keras layers are designed to be used with the keras training loop.\r\n\r\nHowever, this is a huge problem for the upcoming Tensorflow 2.0, since tf.layers are going to be removed in favor of tf.keras.layers, but those are not drop in replacement.\r\n\r\nAs a proof I added the line:\r\n```python\r\nupdate_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\r\n```\r\njust before the definition of `train_d`.\r\n\r\nThe `update_ops` variable is an empty list.\r\n\r\nI could find the update operations inside the Keras model using `D.updates`, `G.updates`, `E.updates`: but those operations are a function of some \"input\" that's not the input I define when, for example, I define the output tensor `G_z = G(z)`.\r\n\r\nHence, Keras layers are not a replacement for the tf.layers and this is a huge problem, especially for people that don't want to use Keras and want to continue using Tensorflow using MonitoredSession, static graph definition and defining the training loop by their self.", "@galeone To collect update ops properly, can you call `generator`, `discriminator` etc afresh each time you need to call the resulting Keras layer/model with some input? As alluded [here](https://github.com/tensorflow/tensorflow/issues/19643#issuecomment-440209107), the `updates` property is updated after each call of the layer/model with an input, not before.", "I don't see the rationale here.\r\n`generator` is a function that creates a new `Model`, if I call `generator` again, I create a new model, that's not what I want.\r\n\r\nI created `G` calling `generator` and `G` is the model I want to use.\r\n\r\nThe problem is that `G.updates` are a set of operations that are not added to the graph because I defined the model using the keras layers (that are not a replacement for tf.layers - sadly).\r\n\r\nMoreover, `G.updates` need an input that a \"generic\" input that Keras overwrites when calling `model.fit`, `compile`, `train_on_batch` and so on.\r\n\r\nBut if I try to run `sess.run(G.updates)` it raises an error since the input is not defined.\r\n\r\nThis is wrong, since if I defined `G_z = G(z)` I want that when I call `train_g`, that's a function of `G(z)`, all the required operations for the training [hence also the update ops] must be executed (or at least, added to the graph, so I can trigger the update operations when the training steps are executed).", "Another instance of the same problem #24050 ", "I'm also stuck on a similar incarnation of this issue. I use a `tf.keras` model within a custom `tf.Estimator`. The estimator is not created using `model_to_estimator`, but the usual way for vanilla tf estimators. The Keras model is incorporated into the graph by calling the model with a tensor as argument. While I can collect some update_ops via `model.updates`, these seem to be connected to the wrong input placeholders as hinted by @galeone: When training the model, I get an error that the inputs need feeding. In fact `model.updates` seems to be populated already before the model is called, and likely it is not being updated when the model is called.", "@burnpanck, I met exactly the same issue as you.  many people said use model.updates  to get update ops. I think they did not really that by themselves. my code likes this:\r\n\r\nupdate_ops = base_model.updates\r\nwith tf.control_dependencies(update_ops):\r\n    train_step = tf.train.AdamOptimizer(lr).minimize(cross_entropy_mean) \r\n\r\nand error:\r\nYou must feed a value for placeholder tensor 'dense_1_input' with dtype\r\n\r\nSo, Did  you find any solutions?", "@hurri2000: Not really. I backported my code from `tf.keras.layers` to `tf.layers`. In my case this was possible, because I really only needed the functional interface of the keras layers. However, it seems `tf.layers` is deprecated and scheduled for removal in TF 2.0. I assume I'll have to port forwards again then, hoping that this is fixed by then.", "I've debugged a little bit this problem and I wrote a complete report on my blog: https://pgaleone.eu/tensorflow/keras/2019/01/19/keras-not-yet-interface-to-tensorflow/\r\n\r\nIn short: the problem is present only when defining a static input shape for the keras model", "@fchollet Will this be fixed or will this issue just die with sessions?\r\nLooking at some official colab examples updates might happen if calling the model with narg training=true.   Have to look into that - the eager pix2pix example might just be wrong ...", "Maybe this issue could be closed? (need to check if this works - but even if it works, the API is a bit misleading - maybe model.updates should be renamed?) \r\n> @eldar please replace `model.updates` with `model.get_updates_for(image)`.\r\n> \r\n> `model.updates` includes all updates, including the ones created when constructing your model off of the `keras.Input`s\r\n\r\nvia https://github.com/tensorflow/tensorflow/issues/26322#issuecomment-474520177", "The `model.get_updates_for` call, in a scenario like the one I presented in the opening post, can't be called (when you're sharing the model parameters).\r\n\r\nI guess it's better to do not close the issue since people are starting to migrate their codebase to TF2 by using Keras models and not `tf.layers` and until TF2 is not the recommended default, many of them just use Keras + Session (and thus the will face these issues).\r\n", "@galeone I did not yet have the opportunity to look into `model.get_updates_for` , thanks for clarifying.\r\n\r\nTo me `tf.keras` seems not yet ready for the big switch coming with `tf2` - but that might be just me not seeing the whole picture. Toying around with StyleGAN like things right now and feeling very constrained by Keras :/ - but  then again, I'm very happy that `tf` and alike exist at all and are free & open.", "Initially, I was thinking the same but I wasn't looking at the entire picture.\r\nUsing Keras in pure Tensorflow 2.0 style already works almost perfectly. The problem is when we mix sessions and Keras (or even worse, tf.estimator + Keras models -> if you try using tf.contrib.gan and define a model using Keras, it never learns to generate something useful, while when using tf.layers it works perfectly).\r\n\r\nI'm writing a book about this and I can confirm that, really, TF 2 + Keras is a huge improvement over the TF1 architecture; but it requires to relearn the frameworks (I learned the hard way; if you are an experienced TF1 user it requires an initial struggle doing this mind-switch)\r\n", "my temporary solution is changing argument of add_update input to None. \r\nwhich is located in normalization.py->Batch normal->call. \r\nby doing so, BN Layer immediately add updates to model.update on its init checking call. \r\nThen, add update ops. \r\nthere'll be BN/Assign~ and model/BN/assign~blah\r\ni think former is for initializing and later is what we want\r\n                \r\n```\r\nself.update_ops = []\r\nfor update_op in self.model.updates:\r\n    if \"model\" in update_op.name:\r\n        self.update_ops.append(update_op)\r\n```\r\nif you are using Sequence, the \"model\" term will be \"sequence\" I think. \r\nthen,\r\n```\r\nwith tf.control_dependencies(self.update_ops):\r\n    minimize = optimizer.minimize(modified_loss,global_step=g_step)\r\n```\r\nor\r\n`session.run(update_ops, feed_dict={something})`", "These gaps between keras and tf must be described clearly in documentation. Be clear and concise. Current docs/tuts about keras are mostly like magic. There are too many options that most people never use, and popular options that work in a way most people do not expect. Many if not most of issues and questions about batchnorm can be avoided if it were to be simplified.", "Can confirm that @CosmosBloomj hacky workaround works. Thank you very much! However, I would like to resolve this issue without resorting to hacky workarounds.\r\n\r\n@galeone , your solution as written in your blog looks much more elegant by using dynamic input sizes. However, is this also possible when using the functional API instead of sequential API? I am unable to replicate your findings with the functional API, but that might simply be my inexperience.", "> These gaps between keras and tf must be described clearly in documentation. Be clear and concise. Current docs/tuts about keras are mostly like magic. There are too many options that most people never use, and popular options that work in a way most people do not expect. Many if not most of issues and questions about batchnorm can be avoided if it were to be simplified.\r\n\r\nI'm not quite clear from this thread what is the current best solution for something simple like the BatchNorm update ops. \r\n\r\nThe docs should maybe focus on the ONE TRUE WAY first and the ONE TRUE WAY should be the subclass api with custom training via gradient tape (no keras model.compile) as it supports all custom ops.  This one step in the docs will greatly simplify the real complexity of all these corner cases. To some extent, if the functional API needs much documentation, it is wrong.\r\n\r\n", "So, currently, if I want to use batch normalization layers with session, I'd better use tf.layers interface and use control_dependencies to update batch normalization's moving varaibles. Am I right? If I use tf.layers instead of keras.layers, is it still necessary to use control_dependencies in tf2?", "Hi @galeone !We are checking to see if you still need help on this issue. We recommend that you upgrade to 2.6 which is latest stable version of TF and let us know if the issue still persists in newer versions.  You can follow our [migration document](https://www.tensorflow.org/guide/migrate) to migrate your code base to 2.x versions . Thanks!", "I guess this issue can be closed, no one should use TensorFlow 2.x in this way (with sessions)", "Ok @galeone ,Closing this issue then ! Feel to free open a new one if you face any further problems. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/23873\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/23873\">No</a>\n"]}, {"number": 23872, "title": "SparseTensor multiplication in tf.keras.layers.Dense", "body": "**System information**\r\n- TensorFlow version (you are using): 1.12.0\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n**Describe the feature and the current behavior/state.**\r\nIn `keras.layers.Dense`, `tf.sparse_tensor_dense_matmul` is called for SparseTensor as [this](https://github.com/keras-team/keras/blob/master/keras/backend/tensorflow_backend.py#L1093-L1094).\r\nBut in `tf.keras`, only `tf.tensordot` (which can not treats SparseTensor) is called as [this](https://github.com/tensorflow/tensorflow/blob/f827bad24efc949e657e141464ea1010c18d812c/tensorflow/python/keras/layers/core.py#L955-L972).\r\n\r\nDo you have any plan to treat SparseTensor in `tf.keras`?\r\n\r\n**Will this change the current api? How?**\r\nWe can fix it simply using `tf.sparse_tensor_dense_matmul`.\r\nIf needed, I can create PR.\r\n", "comments": ["I believe we have this feature now in TF [tf.sparse.sparse_dense_matmul](https://www.tensorflow.org/api_docs/python/tf/sparse/sparse_dense_matmul). Please reopen if that's not the case. Thanks!\r\n"]}, {"number": 23871, "title": "[Feature Request] Make some parameter untrainable when training on estimator", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 1.10\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n**Describe the feature and the current behavior/state.**\r\n1. In estimator, I am wondering if there are way to make some parameter untrainable when training on estimator.\r\nIn session approaches, it's just load tf.trainable_variable() and remove parameters from list before\r\noptimizer process, but I cannot see any features related to those in estimator.\r\n\r\n**Will this change the current api? How?**\r\n\r\nThis is basic features and already implemented on the session method. So, the estimator should support this.", "comments": ["I do not fully understand the request here. Can you provide a concise code sample demonstrating the current behavior, and the desired behavior?", "We are closing this issue for now due to lack of activity. Please comment if this is still an issue for you. Thanks!"]}, {"number": 23870, "title": "In implementation of ConvLSTM,I  want to know where is the w_ci dot C_t-1 in paper formula (3)", "body": "```\r\n\r\n  def call(self, inputs, state, scope=None):\r\n    cell, hidden = state\r\n    new_hidden = _conv([inputs, hidden], self._kernel_shape,\r\n                       4 * self._output_channels, self._use_bias)\r\n    gates = array_ops.split(\r\n        value=new_hidden, num_or_size_splits=4, axis=self._conv_ndims + 1)\r\n\r\n    input_gate, new_input, forget_gate, output_gate = gates\r\n    new_cell = math_ops.sigmoid(forget_gate + self._forget_bias) * cell\r\n    new_cell += math_ops.sigmoid(input_gate) * math_ops.tanh(new_input)\r\n    output = math_ops.tanh(new_cell) * math_ops.sigmoid(output_gate)\r\n\r\n    if self._skip_connection:\r\n      output = array_ops.concat([output, inputs], axis=-1)\r\n    new_state = rnn_cell_impl.LSTMStateTuple(new_cell, output)\r\nreturn output, new_state\r\n```\r\n\r\nIn this implementation, I wonder where is  w_ci dot C_t-1 appearing in paper formula (3)", "comments": ["The function `def call()` is the main part implemetation of paper:https://arxiv.org/pdf/1506.04214v1.pdf. But a problem now confused me is that in the main part implementation `w_ci dot C_t-1` has disappeared while it appears in paper formula (3).  Why?\r\n\r\nThe full implementation of ConvLSTM at [here](https://github.com/tensorflow/tensorflow/blob/r1.12/tensorflow/contrib/rnn/python/ops/rnn_cell.py#L2046)", "I'm not sure what you mean. The convolution is wrapped into the `_conv` function in that file.", "I wanna say if the implementation of ConvLSTM is based on the LSTM  not the FC-LSTM mentioned in (Convolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting).\r\nBecause i cannt find the 'peepholes' step in ConvLSTM. @drpngx", "Hi @TolicWang , Feel free to share in TF discuss [Forum ](https://discuss.tensorflow.org/)if issue still  persists as this is not a bug or feature request.\r\n\r\nWe also  see that you are using old version of Tensorflow which is officially considered as end of life, We recommend that you upgrade to 2.6 version and let us know if the issue still persists in newer versions .Please open a new issue in case you face any errors, we will get you the right help .\r\n\r\nThanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/23870\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/23870\">No</a>\n"]}, {"number": 23869, "title": "Fix incorrect link in lite dev guide", "body": "This fix fixes incorrect link in lite dev guide", "comments": ["Hi @yongtang, do you mind fixing the conflict? Thank you!", "@yifeif Looks like the fix has already been in place so this PR is not needed any more. I will close the PR now. Thanks for the help."]}, {"number": 23868, "title": "Exporting GraphDef from File and using the resulting TFLite model in the TFLite Android App doesn't work.", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS High Sierra 10.13.4\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Lenovo Tab 10\r\n- TensorFlow installed from (source or binary): source I think\r\n- TensorFlow version (use command below): 1.11.0\r\n- Python version: 3.6.5\r\n- Bazel version (if compiling from source): 0.16.1\r\n- GCC/Compiler version (if compiling from source): 4.2.1\r\n- CUDA/cuDNN version: I don't have CUDA\r\n- GPU model and memory: I'm not running on a GPU\r\n\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\nI have downloaded the tensorflow Release 1.12.0.\r\nUsing Android Studio, I imported the Tensorflow-Lite sample for Android located in tensorflow/tensorflow/lite/examples/android folder. I edited the Manifest so that only the DetectActivity would be installed and would run. I deployed it in my Lenovo Tab 10 Tablet and it ran well.\r\n\r\nI wanted to use my own model, and while checking [this TensorFlow Guide](https://www.tensorflow.org/lite/convert/python_api#exporting_a_graphdef_from_file_), I downloaded the Mobilenet_1.0_224 to see how the conversion would go. As I was using TensorFlow 1.11, my Python Script looked like:\r\n\r\n\timport tensorflow as tf\r\n\r\n\tgraph_def_file = \"mobilenet_v1_1.0_224/frozen_graph.pb\"\r\n\tinput_arrays = [\"input\"]\r\n\toutput_arrays = [\"MobilenetV1/Predictions/Softmax\"]\r\n\r\n\tconverter = tf.contrib.lite.TocoConverter.from_frozen_graph(\r\n\t  graph_def_file, \r\n\t  input_arrays, \r\n\t  output_arrays)\r\n\ttflite_model = converter.convert()\r\n\topen(\"converted_model.tflite\", \"wb\").write(tflite_model)\r\n\r\nI got the converted_model.tflite and the labels.txt and copied it to the assets folder. I ran the app again, expecting it to run like before, but I hit an error:\r\n\r\n    java.lang.IllegalArgumentException: Cannot convert between a TensorFlowLite buffer with 602112 bytes and a ByteBuffer with 270000 bytes.\r\n\r\nThe line at fault is this line from TFLiteObejctDetectionAPIModel:\r\n    tfLite.runForMultipleInputsOutputs(inputArray, outputMap);\r\n\r\nI had expected the app to run again and use my new model since I'm feeding the converted model from what TensorFlow showed in their example. But it seems that this is not the case.\r\n\r\nI also changed the variable TF_OD_API_IS_QUANTIZED to false.\r\n\r\n**Code to reproduce the issue**\r\nTo reproduce the issue I had encountered, download the TensorFlow-Lite example. Check the manifest and comment out the other activities and just leave the DetectorActivity. Run it and it should run as expected. Now, use the guide linked above to convert a GraphDef to a TFLite example, and then copy the resulting tflite model to the assets folder of the Android Sample code. Update the value of TF_OD_API_IS_QUANTIZED to false, and then run it. \r\n\r\n\r\n**Other info / logs**\r\n    java.lang.IllegalArgumentException: Cannot convert between a TensorFlowLite buffer with 602112 bytes and a ByteBuffer with 270000 bytes.\r\n        at org.tensorflow.lite.Tensor.throwExceptionIfTypeIsIncompatible(Tensor.java:175)\r\n        at org.tensorflow.lite.Tensor.setTo(Tensor.java:65)\r\n        at org.tensorflow.lite.NativeInterpreterWrapper.run(NativeInterpreterWrapper.java:126)\r\n        at org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:168)\r\n        at org.tensorflow.demo.TFLiteObjectDetectionAPIModel.recognizeImage(TFLiteObjectDetectionAPIModel.java:216)\r\n        at org.tensorflow.demo.DetectorActivity$3.run(DetectorActivity.java:249)\r\n        at android.os.Handler.handleCallback(Handler.java:751)\r\n        at android.os.Handler.dispatchMessage(Handler.java:95)\r\n        at android.os.Looper.loop(Looper.java:154)\r\n        at android.os.HandlerThread.run(HandlerThread.java:61)\r\n", "comments": ["Hi! I tried to do the same thing, and the same error occurred. Some advance?", "Hi @Zeit42! We are checking to see if  you still need help in this issue.\r\nIt also seems you are using older versions(1.x versions) of Tensorflow. We recommend that you upgrade  your code base to 2.x  versions as many features and bug fixes has been done in newer versions and create a new issue if the issue still persists in newer versions.  Also  Feel free to go through [issue ](https://github.com/tensorflow/tensorflow/issues/24190)with similar Error Stack trace.Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 23867, "title": "Document about using custom op to build graph in C++", "body": "**System information**\r\n- TensorFlow version: ALL\r\n- Doc Link: \r\nCustom op: https://www.tensorflow.org/guide/extend/op\r\nBuild graph in c++: https://www.tensorflow.org/guide/extend/cc\r\n\r\n\r\n**Describe the documentation issue**\r\nPlease provide documentation about how to build graph using custom OP.\r\nRelated StackOverflow question: https://stackoverflow.com/questions/53384454/how-to-use-custom-op-to-build-tensorflow-graph-in-c\r\n", "comments": ["Borrowing from the [StackOverflow post linked above](https://stackoverflow.com/questions/53384454/how-to-use-custom-op-to-build-tensorflow-graph-in-c)...\r\n\r\nTaking `ZeroOut` from [here](https://www.tensorflow.org/guide/extend/op) as an example, you have to do the following:\r\n\r\n```\r\n    class ZeroOut {\r\n     public:\r\n      ZeroOut(const ::tensorflow::Scope& scope, ::tensorflow::Input x);\r\n      operator ::tensorflow::Output() const { return y; }\r\n      operator ::tensorflow::Input() const { return y; }\r\n      ::tensorflow::Node* node() const { return y.node(); }\r\n    \r\n      ::tensorflow::Output y;\r\n    };\r\n    \r\n    ZeroOut::ZeroOut(const ::tensorflow::Scope& scope, ::tensorflow::Input x) {\r\n      if (!scope.ok()) return;\r\n      auto _x = ::tensorflow::ops::AsNodeOut(scope, x);\r\n      if (!scope.ok()) return;\r\n      ::tensorflow::Node* ret;\r\n      const auto unique_name = scope.GetUniqueNameForOp(\"ZeroOut\");\r\n      auto builder = ::tensorflow::NodeBuilder(unique_name, \"ZeroOut\")\r\n                         .Input(_x)\r\n      ;\r\n      scope.UpdateBuilder(&builder);\r\n      scope.UpdateStatus(builder.Finalize(scope.graph(), &ret));\r\n      if (!scope.ok()) return;\r\n      scope.UpdateStatus(scope.DoShapeInference(ret));\r\n      this -> y = Output(ret, 0);\r\n    }\r\n```\r\n\r\nThen you can use it to build a graph:\r\n\r\n```\r\n    Scope root = Scope::NewRootScope();\r\n\r\n    // Matrix A = [3 2; -1 0]\r\n    auto A = Const(root, { {3, 2}, {-1, 0} });\r\n    auto v = ZeroOut(root.WithOpName(\"v\"), A);\r\n    std::vector<Tensor> outputs;\r\n    ClientSession session(root);\r\n\r\n    // Run and fetch v\r\n    TF_CHECK_OK(session.Run({v}, &outputs));\r\n    LOG(INFO) << outputs[0].matrix<int>();\r\n```\r\n\r\n**Note**: For TensorFlow inherent ops, code like `ZeroOut class` is autogenerated by a bazel rule. You can imitate that code (e.g. `tensorflow/cc/ops/math_ops.h`) to hand write your own classes, if you only have a few custom ops.", "@egolearner,\r\nThe documentation for Creating a Custom OP is present in the [Tensorflow Site](https://www.tensorflow.org/guide/create_op). Also refer this [Github page](https://github.com/tensorflow/custom-op) for end-to-end code example, as well as Docker images for building and distributing your custom ops. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n"]}, {"number": 23866, "title": "TF-TRT: Improve log", "body": "Add more information to the log including unsupported ops.", "comments": ["So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored or co-authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of all the commit author(s), set the `cla` label to `yes` (if enabled on your project), and then merge this pull request when appropriate.*\n\n<!-- need_author_consent -->", "CLAs look good, thanks!\n\n<!-- ok -->", "@pooyadavoodi Please help to fix the clang-format and sanity check errors. Thanks. :)"]}, {"number": 23865, "title": "R1.11", "body": "i need to build tensorflow  v1.11", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->", "@cutefulf could you use the v1.11 branch? Closing this PR.\r\n"]}, {"number": 23864, "title": "I want ot know where is the w_ci dot C_t-1 in paper formulation (3)", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n**Describe the current behavior**\r\n\r\n**Describe the expected behavior**\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": []}, {"number": 23863, "title": "SimpleRNN + batch_normalization causes inexplicable InvalidArgumentError", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Fedora 22\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): v1.12.0-0-ga6d8ffae09 1.12.0\r\n- Python version: 3.6.5\r\n- Bazel version (if compiling from source): NA\r\n- GCC/Compiler version (if compiling from source): NA\r\n- CUDA/cuDNN version: NA\r\n- GPU model and memory: NA\r\n\r\n**Describe the current behavior**\r\nThe test program throws an exception `tensorflow.python.framework.errors_impl.InvalidArgumentError: Retval[0] does not have value` in session run. However, it completes normally if `EPISODE_LENGTH` is halved, the `SimpleRNN` layer is commented out or the `batch_normalization` layer is commented out. The problem also goes away if I replace the `RandomDataset`-derived dataset with one built with `from_tensor_slices` from constant data.\r\n\r\n**Describe the expected behavior**\r\nThe test program should complete normally. I don't think my program has a bug that is responsible for the exception but even if it does, the throwing of the exception should be consistent and not depend on `EPISODE_LENGTH` being big enough.\r\n\r\n**Code to reproduce the issue**\r\n```\r\n#!/usr/bin/env python3\r\n\r\nimport numpy as np\r\nimport tensorflow as tf\r\nimport tensorflow.keras.layers as kl\r\n\r\nNUM_FEATURES = 2\r\nEPISODE_LENGTH = 32\r\nBATCH_SIZE = 2\r\n\r\nclass GraphBuilder:\r\n    def __init__(self):\r\n        g = tf.Graph()\r\n        with g.as_default():\r\n            tf.set_random_seed(0)\r\n\r\n            with tf.variable_scope('input'):\r\n                ds = tf.data.Dataset.from_tensors(\r\n                    (np.zeros(shape=(BATCH_SIZE, EPISODE_LENGTH, NUM_FEATURES), dtype=np.float32),\r\n                     np.zeros(shape=(BATCH_SIZE, EPISODE_LENGTH), dtype=np.float32)))\r\n                it = ds.make_one_shot_iterator()\r\n                batch = it.get_next(name='batch')\r\n                batch_x, batch_y = batch\r\n            with tf.variable_scope('nn'):\r\n                layer = batch_x\r\n                layer = kl.SimpleRNN(1, return_sequences=True)(layer, training=True)\r\n                layer = tf.layers.batch_normalization(layer, axis=2, training=True)\r\n                batch_pred = layer[:, :, 0]\r\n\r\n            with tf.variable_scope('loss'):\r\n                num_rows = tf.reduce_prod(tf.shape(batch_y))\r\n                e = tf.subtract(batch_y, batch_pred, name='error')\r\n                sse = tf.reduce_sum(tf.square(e), name='sse')\r\n                mse = tf.divide(sse, tf.cast(num_rows, tf.float32), name='mse')\r\n                rmse = tf.sqrt(mse, name='rmse')\r\n\r\n            with tf.variable_scope('train'):\r\n                optimizer = tf.train.AdamOptimizer(0.001)\r\n                update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\r\n                with tf.control_dependencies(update_ops):\r\n                    train_op = optimizer.minimize(mse)\r\n\r\n        self.rmse = rmse\r\n        self.train_op = train_op\r\n        self.graph = g\r\n\r\n\r\ndef main():\r\n    gb = GraphBuilder()\r\n    config = tf.ConfigProto(intra_op_parallelism_threads=2, inter_op_parallelism_threads=2)\r\n    config.device_count['GPU'] = 0\r\n    with tf.Session(graph=gb.graph, config=config) as sess:\r\n        sess.run(tf.global_variables_initializer())\r\n        sess.run([gb.rmse, gb.train_op])\r\n\r\nmain()\r\n```\r\n\r\n\r\n**Other info / logs**\r\n```\r\n2018-11-20 13:31:56.998664: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\nTraceback (most recent call last):\r\n  File \"/data/jchia/venv/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\r\n    return fn(*args)\r\n  File \"/data/jchia/venv/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1319, in _run_fn\r\n    options, feed_dict, fetch_list, target_list, run_metadata)\r\n  File \"/data/jchia/venv/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1407, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Retval[0] does not have value\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"py3/train2.py\", line 56, in <module>\r\n    main()\r\n  File \"py3/train2.py\", line 54, in main\r\n    sess.run([gb.rmse, gb.train_op])\r\n  File \"/data/jchia/venv/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\r\n    run_metadata_ptr)\r\n  File \"/data/jchia/venv/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/data/jchia/venv/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\r\n    run_metadata)\r\n  File \"/data/jchia/venv/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Retval[0] does not have value\r\n```", "comments": ["I suppose stacking `keras.layers.SimpleRNN` with `tf.layers.batch_normalization` instead of `keras.layers.BatchNormalization` is probably not an intended use case, but if it's not allowed, the error message should be clear and consistent.", "This looks like a duplicate of #14357."]}, {"number": 23862, "title": "Python API documentation fixes", "body": "This PR fixes some minor grammatical and typo errors in the Python tf.data APIs that I came across while working with the code.\r\n\r\nI generated documentation markdown files and checked them for correctness.", "comments": ["@yifeif  A quick question. Looks like Kokoro checks are not done for this. Since this is just related to grammatical changes in the documentation, did we bypass this intentionally ?\r\nWould you like me to proceed further without kokoro checks ? Please confirm.", "Hi @harshini-gadige you are correct, this change is relatively low risk, and we are already running these Kokoro builds internally, therefore I didn't trigger them here :). But in general, we do want to make sure PR passes Kokoro builds first.  You can proceed with the safe review approval. Thanks for checking!", "Thank you @yifeif and @harshini-gadige !"]}, {"number": 23861, "title": "matmul with large matrices fails with float16, but succeeds with float32", "body": "- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nYes. see below\r\n\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nLinux Ubuntu 16.04\r\n\r\n- **TensorFlow installed from (source or binary)**:\r\nThis bug occurs with every version of GPU tensorflow I've tried or built, including several binaries and currently building from source.\r\n\r\n- **TensorFlow version (use command below)**:\r\nv1.12.0-rc0-2836-gd63e3ea\r\n\r\n- **Python version**:\r\n2.7\r\n\r\n- **Bazel version (if compiling from source)**:\r\n0.19.1\r\n\r\n- **GCC/Compiler version (if compiling from source)**:\r\n5.4.0\r\n\r\n- **CUDA/cuDNN version**:\r\nCurrently building from source with CUDA 10.0 and cuDNN 7.4, but previously the bug occurred with binaries using CUDA 9.0 and cuDNN 7.4 and cuDNN 7.0\r\n\r\n- **GPU model and memory**:\r\nGeForce GTX 1070 8GB\r\n\r\n- **Exact command to reproduce**:\r\nRun the following python script:\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\nxvar = tf.placeholder (tf.float16, name=\"x\",shape=[None,2])\r\n\r\nweight_init = tf.uniform_unit_scaling_initializer (factor=1,dtype=tf.float16)\r\nW = tf.get_variable (\"W\",[2,2],initializer=weight_init,dtype=tf.float16)\r\n\r\noutput = tf.matmul (xvar,W)\r\n\r\ninit = tf.global_variables_initializer ()\r\n\r\nwith tf.Session () as sess:\r\n    sess.run (init)\r\n    o = sess.run (output, feed_dict = {xvar:np.zeros ((8500000,2),dtype=np.float16)})\r\n```\r\n\r\n### Describe the problem\r\nMatmul fails with large float16 matrices. If you reduce the size of the matrix to 8e6, the code runs. If you keep the size of the matrix the same, but change all the data types to float32, it runs. The limiting factor seems to be the single largest dimension. For example, doing the matmul with sizes (8e6,100) and (100,100) works in float16\r\n\r\nPerhaps this is not a Tensorflow issue, but an internal CUDA issue?\r\n\r\n### Source code / logs\r\n```\r\nWARNING:tensorflow:From float16_demo.py:6: __init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\r\nWARNING:tensorflow:From /home/ilia/tensorflow/venv-source-nightly-2018nov19/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nColocations handled automatically by placer.\r\n2018-11-19 15:49:01.787213: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:993] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2018-11-19 15:49:01.787660: I tensorflow/compiler/xla/service/service.cc:149] XLA service 0x4863200 executing computations on platform CUDA. Devices:\r\n2018-11-19 15:49:01.787676: I tensorflow/compiler/xla/service/service.cc:157]   StreamExecutor device (0): GeForce GTX 1070, Compute Capability 6.1\r\n2018-11-19 15:49:01.787882: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \r\nname: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7465\r\npciBusID: 0000:01:00.0\r\ntotalMemory: 7.92GiB freeMemory: 7.52GiB\r\n2018-11-19 15:49:01.787894: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\r\n2018-11-19 15:49:01.788392: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-11-19 15:49:01.788401: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \r\n2018-11-19 15:49:01.788405: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \r\n2018-11-19 15:49:01.788537: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7316 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n2018-11-19 15:49:03.017490: E tensorflow/stream_executor/cuda/cuda_blas.cc:652] failed to run cuBLAS routine cublasSgemmEx: CUBLAS_STATUS_EXECUTION_FAILED\r\nTraceback (most recent call last):\r\n  File \"float16_demo.py\", line 15, in <module>\r\n    o = sess.run (output, feed_dict = {xvar:np.zeros ((8500000,2),dtype=np.float16)})\r\n  File \"/home/ilia/tensorflow/venv-source-nightly-2018nov19/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 929, in run\r\n    run_metadata_ptr)\r\n  File \"/home/ilia/tensorflow/venv-source-nightly-2018nov19/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/home/ilia/tensorflow/venv-source-nightly-2018nov19/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\r\n    run_metadata)\r\n  File \"/home/ilia/tensorflow/venv-source-nightly-2018nov19/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InternalError: Blas GEMM launch failed : a.shape=(8500000, 2), b.shape=(2, 2), m=8500000, n=2, k=2\r\n\t [[node MatMul (defined at float16_demo.py:9) ]]\r\n\r\nCaused by op u'MatMul', defined at:\r\n  File \"float16_demo.py\", line 9, in <module>\r\n    output = tf.matmul (xvar,W)\r\n  File \"/home/ilia/tensorflow/venv-source-nightly-2018nov19/local/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py\", line 2272, in matmul\r\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\r\n  File \"/home/ilia/tensorflow/venv-source-nightly-2018nov19/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 4763, in mat_mul\r\n    name=name)\r\n  File \"/home/ilia/tensorflow/venv-source-nightly-2018nov19/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/home/ilia/tensorflow/venv-source-nightly-2018nov19/local/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py\", line 512, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/home/ilia/tensorflow/venv-source-nightly-2018nov19/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 3268, in create_op\r\n    op_def=op_def)\r\n  File \"/home/ilia/tensorflow/venv-source-nightly-2018nov19/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1831, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\nInternalError (see above for traceback): Blas GEMM launch failed : a.shape=(8500000, 2), b.shape=(2, 2), m=8500000, n=2, k=2\r\n\t [[node MatMul (defined at float16_demo.py:9) ]]\r\n```", "comments": ["I was able to run your code snippet successfully. I suspect it's not a TensorFlow related issue, however you can try shutting down all the processes/notebooks that utilize your GPU and run the code again.", "I am running this in multi-user.target, so other GPU utilization is\nnon-existent. Do you have the same GPU or different? Perhaps on other GPUs\nthe limit is higher? I understand that there may be a limit to how big\nmatrices can be, it just doesn't make sense for that limit to be lower for\nfp16 than it is for fp32.\n\nOn Mon, Nov 26, 2018, 7:17 PM ymodak <notifications@github.com wrote:\n\n> I was able to run your code snippet successfully. I suspect it's not a\n> TensorFlow related issue, however you can try shutting down all the\n> processes/notebooks that utilize your GPU and run the code again.\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/23861#issuecomment-441849075>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AYkCWqbB3uJe2p33kKdyomI2cP4goJJ0ks5uzISJgaJpZM4Yp5CY>\n> .\n>\n", "Could it be because of a change in the float type in Python 2.7 vs Python 3.6? I personally use Python 3.6 and it works with no problem... I know they tweaked some little details with floats in the newer version, but I think it's just related to int division (now giving floats instead of rounded integers), so it should not have anything to do with it. Still, that could be something to try out for you!", "/CC @chsigg, can you take a look?", "Tried on python3 with the stable 1.13 binary release and CUDA 10.0, identical behavior", "Identical behavior on python3 TF 2.0 alpha with the following code:\r\n\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\n@tf.function\r\ndef myMatMul (x,W):\r\n    return tf.matmul (x,W)\r\n\r\nW = np.ones ((2,2), dtype=np.float16)\r\nx = np.zeros ((8500000,2), dtype=np.float16)\r\n\r\noutput = myMatMul (x,W)\r\n\r\n```\r\n\r\nAs before, reducing the large dimension to 8e6 results in a successful computation, or keeping it at 8.5e6 and changing the data type to np.float32", "@ilia-nikiforov Is this still an issue for you? I ran your code in [colab](https://colab.research.google.com/gist/jvishnuvardhan/d55d141cb5eab8da277f08bf37c9ff30/untitled48.ipynb) with GPU and don't see any issue. I guess your GPU may had less memory when compared to colab GPU. \r\n\r\nThere were lot of performance improvement over the time and TF2.3 and `tf-nightly` has some performance upgrades. Thanks!", "I am closing this issue as this was resolved in `tf-nightly`. Please feel free to reopen the issue If i am mistaken. Thanks!"]}, {"number": 23860, "title": "Poor memory performance of K.batch_dot under tensorflow backend relative to batched tf.matmul ", "body": "[ x] Check that you are up-to-date with the master branch of Keras. You can update with:\r\npip install git+git://github.com/keras-team/keras.git --upgrade --no-deps\r\n\r\n[ x] Check that your version of TensorFlow is up-to-date. The installation instructions can be found here.\r\n\r\n[x ] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).\r\n\r\nI am performing batch matrix multiplies of two tensors of size (batch, N, M) and (batch, M, K) to get a tensor of size (batch, N, K), with the matrix products. This behavior can be done with both tf.matmul and K.batch_dot with the default axis arguments.\r\n\r\nHowever in K.batch_dot, the elementwise multiplication in the line\r\n\r\nkeras/keras/backend/tensorflow_backend.py\r\n\r\nLine 1248 in 75a3503\r\n\r\n result = tf.reduce_sum(x * y, 1) \r\neats up a lot of memory. The elementwise multiplication followed by summing over an axis is of course mathematically equivalent to the matrix multiply, but in the two-step implementation, Tensorflow assigns memory to the intermediate very large tensor.\r\nIn this simple example, my small GPU (Nvidia 970) is able to perform the calculation using tf.matmul, but using K.batch_dot Tensorflow fails with an OOM error.\r\n\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom keras import backend as K\r\n\r\na = np.random.normal(size=(100, 500, 10000)).astype(np.float32)\r\nb = np.random.normal(size=(100, 10000, 32)).astype(np.float32)\r\n\r\na_t = K.placeholder(a.shape)\r\nb_t = K.placeholder(b.shape)\r\n\r\ntd = tf.matmul(a_t, b_t)\r\nbd = K.batch_dot(a_t, b_t)\r\n\r\nsess = K.get_session()\r\nsess.run(td, feed_dict={a_t: a, b_t: b})\r\nsess.run(bd, feed_dict={a_t: a, b_t: b})\r\nThis fails when it tries to assign a tensor of size (100, 10000, 500, 32) in the elementwise multiply in batch_dot (the dimension of 10000 not being strictly necessary in this case since we are only interested in the sum).", "comments": []}, {"number": 23859, "title": "Android Bazel Build Error ", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: \r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: master (5c60fb7e9b90d6641c2b5848773ef49956ed54e3)\r\n- Python version: Python 2.7.15rc1\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source): 0.19.1\r\n- GCC/Compiler version (if compiling from source): gcc 7.3.0\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nI am trying to build `//tensorflow/contrib/android:libtensorflow_inference.so` so I can use some new ops (cos specifically) in my graph, but am getting build errors:\r\n```\r\nERROR: /home/iwsmith/.cache/bazel/_bazel_iwsmith/df6342feda2c8ba7bff417a851a0ca71/external/llvm/BUILD.bazel:1941:1: C++ compilation of rule '@llvm//:support' failed (Exit 1)\r\nIn file included from external/llvm/lib/Support/Path.cpp:1111:                        \r\nexternal/llvm/lib/Support/Unix/Path.inc:633:9: error: no member named 'futimens' in the global namespace\r\n  if (::futimens(FD, Times))                                                                                                     \r\n      ~~^                                                                                                                                                                             1 error generated.                                                    \r\nTarget //tensorflow/contrib/android:libtensorflow_inference.so failed to build\r\n```\r\nNDK: r17c\r\nSDK: 28\r\n```iwsmith@bob:~/sdk/tools$ bin/sdkmanager --list                                                                                                       \r\nWarning: File /home/iwsmith/.android/repositories.cfg could not be loaded.                                                                                           \r\nInstalled packages:=====================] 100% Computing updates...                                                                                  \r\n  Path                 | Version | Description                       | Location                                                                      \r\n  -------              | ------- | -------                           | -------                                                                        \r\n  build-tools;28.0.3   | 28.0.3  | Android SDK Build-Tools 28.0.3    | build-tools/28.0.3/                                                          \r\n  platform-tools       | 28.0.1  | Android SDK Platform-Tools 28.0.1 | platform-tools/                                                                \r\n  platforms;android-28 | 6       | Android SDK Platform 28           | platforms/android-28/                                                        \r\n  tools                | 26.1.1  | Android SDK Tools 26.1.1          | tools/    \r\n```\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n1. `git clone --recurse-submodules https://github.com/tensorflow/tensorflow.git`\r\n1. `./configure`\r\n1. `bazel clean`\r\n1. `bazel build -c opt //tensorflow/contrib/android:libtensorflow_inference.so --crosstool_top=//external:android/crosstool    --host_crosstool_top=@bazel_tools//tools/cpp:toolchain    --cxxopt=-std=c++11    --cpu=armeabi-v7a`\r\n\r\n**Any other info / logs**\r\nI have tried with a variety of NDK versions (18b, 14b) and get different build errors each time. I also tried with `--cpu=arm64-v8a` and got build errors. I am unsure which cpu architecture to target for the Pixel.\r\n", "comments": ["@iwsmith  Please use Bazel 0.15 and GCC 4.8 and see if this issue persists. \r\n\r\n\r\n\r\n", "Thanks for the quick followup! \r\nI've done as you suggested, and am now trying with bazel 0.15.2 and GCC 4.8.5:\r\n```\r\niwsmith@bob:~/tensorflow$ bazel version\r\nBuild label: 0.15.2\r\nBuild target: bazel-out/k8-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Tue Jul 17 12:22:40 2018 (1531830160)\r\nBuild timestamp: 1531830160\r\nBuild timestamp as int: 1531830160\r\niwsmith@bob:~/tensorflow$ gcc --version\r\ngcc (Ubuntu 4.8.5-4ubuntu8) 4.8.5\r\n```\r\nHowever, I am still getting the following build errors:\r\n```\r\nERROR: /home/iwsmith/.cache/bazel/_bazel_iwsmith/df6342feda2c8ba7bff417a851a0ca71/external/llvm/BUILD.bazel:1995:1: C++ compilation of rule '@llvm//:target' failed (Exit 1)\r\nIn file included from external/llvm/lib/Target/TargetIntrinsicInfo.cpp:14:\r\nIn file included from external/llvm/include/llvm/Target/TargetIntrinsicInfo.h:17:\r\nIn file included from external/llvm/include/llvm/ADT/StringRef.h:13:\r\nIn file included from external/llvm/include/llvm/ADT/STLExtras.h:21:\r\nIn file included from external/llvm/include/llvm/ADT/SmallVector.h:20:\r\nIn file included from external/llvm/include/llvm/Support/MathExtras.h:18:\r\nIn file included from external/llvm/include/llvm/Support/SwapByteOrder.h:19:\r\nIn file included from external/llvm/include/llvm/Support/DataTypes.h:17:\r\nIn file included from external/llvm/include/llvm-c/DataTypes.h:28:\r\nIn file included from external/androidndk/ndk/sources/cxx-stl/llvm-libc++/include/cmath:305:\r\nIn file included from external/androidndk/ndk/sources/android/support/include/math.h:32:\r\nexternal/androidndk/ndk/sources/cxx-stl/llvm-libc++/include/math.h:1302:93: error: no member named 'log2f' in the global namespace\r\ninline _LIBCPP_INLINE_VISIBILITY float       log2(float __lcpp_x) _NOEXCEPT       {return ::log2f(__lcpp_x);}\r\n                                                                                          ~~^\r\nexternal/androidndk/ndk/sources/cxx-stl/llvm-libc++/include/math.h:1303:93: error: no member named 'log2l' in the global namespace\r\ninline _LIBCPP_INLINE_VISIBILITY long double log2(long double __lcpp_x) _NOEXCEPT {return ::log2l(__lcpp_x);}\r\n                                                                                          ~~^\r\nexternal/androidndk/ndk/sources/cxx-stl/llvm-libc++/include/math.h:1308:38: error: call to 'log2' is ambiguous\r\nlog2(_A1 __lcpp_x) _NOEXCEPT {return ::log2((double)__lcpp_x);}\r\n                                     ^~~~~~\r\nexternal/androidndk/ndk/sources/cxx-stl/llvm-libc++/include/math.h:1302:46: note: candidate function\r\ninline _LIBCPP_INLINE_VISIBILITY float       log2(float __lcpp_x) _NOEXCEPT       {return ::log2f(__lcpp_x);}\r\n                                             ^\r\nexternal/androidndk/ndk/sources/cxx-stl/llvm-libc++/include/math.h:1303:46: note: candidate function\r\ninline _LIBCPP_INLINE_VISIBILITY long double log2(long double __lcpp_x) _NOEXCEPT {return ::log2l(__lcpp_x);}\r\n                                             ^\r\n3 errors generated.\r\nTarget //tensorflow/contrib/android:libtensorflow_inference.so failed to build\r\n```\r\n\r\nFurthermore, at the start of the build I receive the following warning:\r\n```\r\nWARNING: The major revision of the Android NDK referenced by android_ndk_repository rule 'androidndk' is 17. The major revisions supported by Bazel are [10, 11, 12, 13, 14, 15, 16]. \r\nBazel will attempt to treat the NDK as if it was r16. This may cause compilation and linkage problems. Please download a supported NDK version.  \r\n```\r\n\r\nI went ahead and tried with NDK 16b and go the following compile error (which matches the original one):\r\n```\r\nERROR: /home/iwsmith/.cache/bazel/_bazel_iwsmith/df6342feda2c8ba7bff417a851a0ca71/external/llvm/BUILD.bazel:1941:1: C++ compilation of rule '@llvm//:support' failed (Exit 1)\r\nIn file included from external/llvm/lib/Support/Path.cpp:1111:\r\nexternal/llvm/lib/Support/Unix/Path.inc:633:9: error: no member named 'futimens' in the global namespace\r\n  if (::futimens(FD, Times))\r\n      ~~^\r\n1 error generated.\r\nTarget //tensorflow/contrib/android:libtensorflow_inference.so failed to build\r\n```", "@gunan  PTAL", "Is there any further information I can provide to help out? I am happy to try things out, just need some direction.\r\n\r\nThanks!", "@achowdhery , were you looking at this?", "FWIW, I pulled from master (9b964193d9e9cc2b082f634010102b320daf70e2) and still get the exact same error. Did a `bazel clean` before the build.", "Hi, any fix/update for this?\r\nTried with various other NDK versions and facing the same issue", "FWIW I never got it working and eventually had to abandon the idea.", "Please try Android Studio version of this tutorial which does not require NDK build version.", "Is there any other way to build `libtensorflow_inference.so`, to link with a native application?", "You may use Makefiles. Some examples are there for our builds for microcontroller devices.", "Hi @iwsmith ,Could you please visit [here](https://www.tensorflow.org/install/source_windows) for installing latest TF version as \r\nWe see that you are using old version of Tensorflow which is officially considered as end of life, We recommend that you upgrade to 2.6 version and let us know if the issue still persists in newer versions .Please open a new issue in case you face any errors, we will get you the right help .Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/23859\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/23859\">No</a>\n"]}, {"number": 23858, "title": "Key Variable not found in checkpoint      [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_INT32], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]", "body": "How should I fix this issue? --the checkpoint is correct.\r\n\r\n```\r\ndef image_filling(image, mask, args):\r\n    with tf.Graph().as_default():\r\n        dummy = tf.Variable(0)  # dummy variable !!!\r\n        with tf.Session() as sess:\r\n            sess.run(tf.global_variables_initializer())\r\n            saver = tf.train.Saver()\r\n            saver.restore(sess, \"image_completion/gan.ckpt\")\r\n\r\n```\r\n\r\nError is:\r\n\r\n```\r\n$ python completion_DCGAN.py \r\n2018-11-19 03:36:55.472699: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2018-11-19 03:36:55.641138: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 0 with properties: \r\nname: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\r\npciBusID: 0000:02:00.0\r\ntotalMemory: 11.91GiB freeMemory: 11.63GiB\r\n2018-11-19 03:36:55.641170: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 0\r\n2018-11-19 03:36:55.928819: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-11-19 03:36:55.928849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      0 \r\n2018-11-19 03:36:55.928855: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 0:   N \r\n2018-11-19 03:36:55.929099: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11251 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:02:00.0, compute capability: 6.0)\r\n2018-11-19 03:36:56.139821: I tensorflow/core/common_runtime/process_util.cc:69] Creating new thread pool with default inter op setting: 28. Tune using inter_op_parallelism_threads for best performance.\r\n2018-11-19 03:36:56.162713: W tensorflow/core/framework/op_kernel.cc:1275] OP_REQUIRES failed at save_restore_v2_ops.cc:184 : Not found: Key Variable not found in checkpoint\r\nTraceback (most recent call last):\r\n  File \"/share/pkg/tensorflow/r1.10/install/py3-gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1278, in _do_call\r\n    return fn(*args)\r\n  File \"/share/pkg/tensorflow/r1.10/install/py3-gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1263, in _run_fn\r\n    options, feed_dict, fetch_list, target_list, run_metadata)\r\n  File \"/share/pkg/tensorflow/r1.10/install/py3-gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1350, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.NotFoundError: Key Variable not found in checkpoint\r\n     [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_INT32], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/share/pkg/tensorflow/r1.10/install/py3-gpu/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1725, in restore\r\n    {self.saver_def.filename_tensor_name: save_path})\r\n  File \"/share/pkg/tensorflow/r1.10/install/py3-gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 877, in run\r\n    run_metadata_ptr)\r\n  File \"/share/pkg/tensorflow/r1.10/install/py3-gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1100, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/share/pkg/tensorflow/r1.10/install/py3-gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1272, in _do_run\r\n    run_metadata)\r\n  File \"/share/pkg/tensorflow/r1.10/install/py3-gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1291, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.NotFoundError: Key Variable not found in checkpoint\r\n     [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_INT32], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\r\n\r\nCaused by op 'save/RestoreV2', defined at:\r\n  File \"completion_DCGAN.py\", line 299, in <module>\r\n    image_filling(real_batch, mask, args)\r\n  File \"completion_DCGAN.py\", line 267, in image_filling\r\n    saver = tf.train.Saver()\r\n  File \"/share/pkg/tensorflow/r1.10/install/py3-gpu/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1281, in __init__\r\n    self.build()\r\n  File \"/share/pkg/tensorflow/r1.10/install/py3-gpu/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1293, in build\r\n    self._build(self._filename, build_save=True, build_restore=True)\r\n  File \"/share/pkg/tensorflow/r1.10/install/py3-gpu/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1330, in _build\r\n    build_save=build_save, build_restore=build_restore)\r\n  File \"/share/pkg/tensorflow/r1.10/install/py3-gpu/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 778, in _build_internal\r\n    restore_sequentially, reshape)\r\n  File \"/share/pkg/tensorflow/r1.10/install/py3-gpu/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 397, in _AddRestoreOps\r\n    restore_sequentially)\r\n  File \"/share/pkg/tensorflow/r1.10/install/py3-gpu/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 829, in bulk_restore\r\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\r\n  File \"/share/pkg/tensorflow/r1.10/install/py3-gpu/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1463, in restore_v2\r\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\r\n  File \"/share/pkg/tensorflow/r1.10/install/py3-gpu/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/share/pkg/tensorflow/r1.10/install/py3-gpu/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/share/pkg/tensorflow/r1.10/install/py3-gpu/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\r\n    op_def=op_def)\r\n  File \"/share/pkg/tensorflow/r1.10/install/py3-gpu/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\nNotFoundError (see above for traceback): Key Variable not found in checkpoint\r\n     [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_INT32], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/share/pkg/tensorflow/r1.10/install/py3-gpu/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1737, in restore\r\n    checkpointable.OBJECT_GRAPH_PROTO_KEY)\r\n  File \"/share/pkg/tensorflow/r1.10/install/py3-gpu/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 351, in get_tensor\r\n    status)\r\n  File \"/share/pkg/tensorflow/r1.10/install/py3-gpu/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\", line 519, in __exit__\r\n    c_api.TF_GetCode(self.status.status))\r\ntensorflow.python.framework.errors_impl.NotFoundError: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"completion_DCGAN.py\", line 299, in <module>\r\n    image_filling(real_batch, mask, args)\r\n  File \"completion_DCGAN.py\", line 268, in image_filling\r\n    saver.restore(sess, \"image_completion/gan.ckpt\")\r\n  File \"/share/pkg/tensorflow/r1.10/install/py3-gpu/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1743, in restore\r\n    err, \"a Variable name or other graph key that is missing\")\r\ntensorflow.python.framework.errors_impl.NotFoundError: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\r\n\r\nKey Variable not found in checkpoint\r\n     [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_INT32], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\r\n\r\nCaused by op 'save/RestoreV2', defined at:\r\n  File \"completion_DCGAN.py\", line 299, in <module>\r\n    image_filling(real_batch, mask, args)\r\n  File \"completion_DCGAN.py\", line 267, in image_filling\r\n    saver = tf.train.Saver()\r\n  File \"/share/pkg/tensorflow/r1.10/install/py3-gpu/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1281, in __init__\r\n    self.build()\r\n  File \"/share/pkg/tensorflow/r1.10/install/py3-gpu/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1293, in build\r\n    self._build(self._filename, build_save=True, build_restore=True)\r\n  File \"/share/pkg/tensorflow/r1.10/install/py3-gpu/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1330, in _build\r\n    build_save=build_save, build_restore=build_restore)\r\n  File \"/share/pkg/tensorflow/r1.10/install/py3-gpu/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 778, in _build_internal\r\n    restore_sequentially, reshape)\r\n  File \"/share/pkg/tensorflow/r1.10/install/py3-gpu/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 397, in _AddRestoreOps\r\n    restore_sequentially)\r\n  File \"/share/pkg/tensorflow/r1.10/install/py3-gpu/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 829, in bulk_restore\r\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\r\n  File \"/share/pkg/tensorflow/r1.10/install/py3-gpu/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1463, in restore_v2\r\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\r\n  File \"/share/pkg/tensorflow/r1.10/install/py3-gpu/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/share/pkg/tensorflow/r1.10/install/py3-gpu/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/share/pkg/tensorflow/r1.10/install/py3-gpu/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\r\n    op_def=op_def)\r\n  File \"/share/pkg/tensorflow/r1.10/install/py3-gpu/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\nNotFoundError (see above for traceback): Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\r\n\r\nKey Variable not found in checkpoint\r\n     [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_INT32], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\r\n```\r\n\r\nI have the following:\r\n```\r\nTensorflow 1.10\r\nPython3.6.2\r\n$ uname -a\r\nLinux scc1 2.6.32-696.28.1.el6.x86_64 #1 SMP Wed May 9 23:09:02 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\r\n$ lsb_release -a\r\nLSB Version:\t:base-4.0-amd64:base-4.0-noarch:core-4.0-amd64:core-4.0-noarch:graphics-4.0-amd64:graphics-4.0-noarch:printing-4.0-amd64:printing-4.0-noarch\r\nDistributor ID:\tCentOS\r\nDescription:\tCentOS release 6.4 (Final)\r\nRelease:\t6.4\r\nCodename:\tFinal\r\n```\r\n", "comments": ["@monajalal  Hi, request you to fill [this](https://github.com/tensorflow/tensorflow/issues/new?template=00-bug-performance-issue.md) template which help us to look into the issue. Thanks !", "Closing as this issue is in \"awaiting response\" status for more than 7 days and did not hear back from the user. Please post your comments if any, we will reopen. Thanks !"]}, {"number": 23857, "title": "Add RCCL package and ops.", "body": "These contributed RCCL ops are based on the NCCL ops. Due to the intentional similarities of the RCCL API to the NCCL1 API, in most cases, these can be used as a drop-in replacement for NCCL when compiling with ROCm.", "comments": ["@chsigg  @gunan   -   Any update please ?", "I am not familiar with nccl myself, adding @azaks2 for review.", "@jeffdaily could you address `clang-format` checks? failures in other test targets don't seem to be that relevant to this PR on the other hand.", "> @jeffdaily could you address `clang-format` checks?\r\n\r\n@whchung Done.", "Nagging Reviewer @yifeif, @chsigg, @gunan, @azaks2, @aaroey: You have been added as a reviewer to this pull request. Please add your review or reassign. It has been 29 days with no activity and the `awaiting review` label has been applied.", "Hi Jeff. Sorry for the long delay. \r\n\r\nThe RCCL ops should move from contrib to core. Contrib is going away in TF 2.0.\r\n\r\nI will make sure this gets reviewed/approved promptly afterwards. Thanks for your patience.", "> Hi Jeff. Sorry for the long delay.\r\n> \r\n> The RCCL ops should move from contrib to core. Contrib is going away in TF 2.0.\r\n> \r\n> I will make sure this gets reviewed/approved promptly afterwards. Thanks for your patience.\r\n\r\n@chsigg would you like me to close this PR and create a new one against core?", "@jeffdaily I think it\u2019s up to you. You can create a new one or git push \u2014force and rewrite commit history here.", "Yes, whatever works best for you.\n\nOn Tue, Feb 12, 2019 at 5:22 PM Wen-Heng (Jack) Chung <\nnotifications@github.com> wrote:\n\n> @jeffdaily <https://github.com/jeffdaily> I think it\u2019s up to you. You can\n> create a new one or git push \u2014force and rewrite commit history here.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/23857#issuecomment-462824176>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AHLOjoPZ0fsf8F2XJdowF0fhPLzEjquPks5vMupHgaJpZM4Ypg7R>\n> .\n>\n"]}, {"number": 23856, "title": "GPU there still training on CPU", "body": "./deviceQuery Starting...\r\n\r\n CUDA Device Query (Runtime API) version (CUDART static linking)\r\n\r\nDetected 1 CUDA Capable device(s)\r\n\r\nDevice 0: \"GeForce 940MX\"\r\n  CUDA Driver Version / Runtime Version          9.0 / 9.0\r\n  CUDA Capability Major/Minor version number:    5.0\r\n  Total amount of global memory:                 2003 MBytes (2100232192 bytes)\r\n  ( 3) Multiprocessors, (128) CUDA Cores/MP:     384 CUDA Cores\r\n  GPU Max Clock rate:                            1242 MHz (1.24 GHz)\r\n  Memory Clock rate:                             1001 Mhz\r\n  Memory Bus Width:                              64-bit\r\n  L2 Cache Size:                                 1048576 bytes\r\n  Maximum Texture Dimension Size (x,y,z)         1D=(65536), 2D=(65536, 65536), 3D=(4096, 4096, 4096)\r\n  Maximum Layered 1D Texture Size, (num) layers  1D=(16384), 2048 layers\r\n  Maximum Layered 2D Texture Size, (num) layers  2D=(16384, 16384), 2048 layers\r\n  Total amount of constant memory:               65536 bytes\r\n  Total amount of shared memory per block:       49152 bytes\r\n  Total number of registers available per block: 65536\r\n  Warp size:                                     32\r\n  Maximum number of threads per multiprocessor:  2048\r\n  Maximum number of threads per block:           1024\r\n  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)\r\n  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)\r\n  Maximum memory pitch:                          2147483647 bytes\r\n  Texture alignment:                             512 bytes\r\n  Concurrent copy and kernel execution:          Yes with 1 copy engine(s)\r\n  Run time limit on kernels:                     Yes\r\n  Integrated GPU sharing Host Memory:            No\r\n  Support host page-locked memory mapping:       Yes\r\n  Alignment requirement for Surfaces:            Yes\r\n  Device has ECC support:                        Disabled\r\n  Device supports Unified Addressing (UVA):      Yes\r\n  Supports Cooperative Kernel Launch:            No\r\n  Supports MultiDevice Co-op Kernel Launch:      No\r\n  Device PCI Domain ID / Bus ID / location ID:   0 / 1 / 0\r\n  Compute Mode:\r\n     < Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) >\r\n\r\ndeviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 9.0, CUDA Runtime Version = 9.0, NumDevs = 1\r\nResult = PASS\r\n\r\n**this shows my cuda is ok**\r\n\r\ncudnnGetVersion() : 7401 , CUDNN_VERSION from cudnn.h : 7401 (7.4.1)\r\nHost compiler version : GCC 5.4.0\r\nThere are 1 CUDA capable devices on your machine :\r\ndevice 0 : sms  3  Capabilities 5.0, SmClock 1241.5 Mhz, MemSize (Mb) 2002, MemClock 1001.0 Mhz, Ecc=0, boardGroupID=0\r\nUsing device 0\r\n\r\nTesting single precision\r\nLoading image data/one_28x28.pgm\r\nPerforming forward propagation ...\r\nTesting cudnnGetConvolutionForwardAlgorithm ...\r\nFastest algorithm is Algo 1\r\nTesting cudnnFindConvolutionForwardAlgorithm ...\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 0: 0.028768 time requiring 0 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 1: 0.044288 time requiring 3464 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 2: 0.054624 time requiring 57600 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 4: 0.197760 time requiring 207360 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 7: 0.501696 time requiring 2057744 memory\r\nResulting weights from Softmax:\r\n0.0000000 0.9999399 0.0000000 0.0000000 0.0000561 0.0000000 0.0000012 0.0000017 0.0000010 0.0000000 \r\nLoading image data/three_28x28.pgm\r\nPerforming forward propagation ...\r\nResulting weights from Softmax:\r\n0.0000000 0.0000000 0.0000000 0.9999288 0.0000000 0.0000711 0.0000000 0.0000000 0.0000000 0.0000000 \r\nLoading image data/five_28x28.pgm\r\nPerforming forward propagation ...\r\nResulting weights from Softmax:\r\n0.0000000 0.0000008 0.0000000 0.0000002 0.0000000 0.9999820 0.0000154 0.0000000 0.0000012 0.0000006 \r\n\r\nResult of classification: 1 3 5\r\n\r\nTest passed!\r\n\r\nTesting half precision (math in single precision)\r\nLoading image data/one_28x28.pgm\r\nPerforming forward propagation ...\r\nTesting cudnnGetConvolutionForwardAlgorithm ...\r\nFastest algorithm is Algo 1\r\nTesting cudnnFindConvolutionForwardAlgorithm ...\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 0: 0.028288 time requiring 0 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 1: 0.038432 time requiring 3464 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 2: 0.057536 time requiring 28800 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 4: 0.199968 time requiring 207360 memory\r\n^^^^ CUDNN_STATUS_SUCCESS for Algo 7: 0.498144 time requiring 2057744 memory\r\nResulting weights from Softmax:\r\n0.0000001 1.0000000 0.0000001 0.0000000 0.0000563 0.0000001 0.0000012 0.0000017 0.0000010 0.0000001 \r\nLoading image data/three_28x28.pgm\r\nPerforming forward propagation ...\r\nResulting weights from Softmax:\r\n0.0000000 0.0000000 0.0000000 1.0000000 0.0000000 0.0000714 0.0000000 0.0000000 0.0000000 0.0000000 \r\nLoading image data/five_28x28.pgm\r\nPerforming forward propagation ...\r\nResulting weights from Softmax:\r\n0.0000000 0.0000008 0.0000000 0.0000002 0.0000000 1.0000000 0.0000154 0.0000000 0.0000012 0.0000006 \r\n\r\nResult of classification: 1 3 5\r\n\r\nTest passed!\r\n **this shows my cudnn is ok**\r\n\r\n\r\n[0] GeForce 940MX    | 51'C,  92 % |  1904 /  2002 MB | yuvraj(1699M) root(94M) yuvraj(55M) yuvraj(43M)\r\n this is command gpustat during training \r\n\r\n nvidia-smi\r\nMon Nov 19 21:54:09 2018       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 384.130                Driver Version: 384.130                   |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  GeForce 940MX       Off  | 00000000:01:00.0 Off |                  N/A |\r\n| N/A   61C    P0    N/A /  N/A |   1927MiB /  2002MiB |     91%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID   Type   Process name                             Usage      |\r\n|=============================================================================|\r\n|    0       942      G   /usr/lib/xorg/Xorg                           103MiB |\r\n|    0      1749      G   compiz                                        57MiB |\r\n|    0      2278      G   ...uest-channel-token=13477521418036853922    45MiB |\r\n|    0      3726      C   /home/yuvraj/anaconda3/envs/tf/bin/python   1699MiB |\r\n|    0      3873      C   /usr/lib/libreoffice/program/soffice.bin      17MiB |\r\n+-----------------------------------------------------------------------------+ \r\n\r\nthis is nvidia-smi during training as we can see the load is 90% but training is on CPU as CPU load is also 90% and the training time was similar to that of cpu like before i installed GPU version i had CPU version and the training time was similar i was doing it on mnist dataset with batch size 32 and it was taking 40-45sec per epoch so idk where i have done wrong please help !!!\r\n\r\n\r\n\r\n\r\n\r\n", "comments": ["You need to install tensorflow-gpu version and not the regular tensorflow for gpu support. Can you confirm your installation pick? Also can you please provide following info.:\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version:\r\n- Python version:\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:", "Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 23855, "title": "Tf Lite only support 4D(or less) tensors stack op?", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes, that is a custom model\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: None\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below):1.12-gpu\r\n- Python version:3.6\r\n- Bazel version (if compiling from source):0.19\r\n- GCC/Compiler version (if compiling from source):5.4\r\n- CUDA/cuDNN version:9.0/7.3.1\r\n- GPU model and memory:GTX 1080 ti\r\n\r\n**Describe the current behavior**\r\nI created a custom TensorFlow model and converted it tflite with \r\n`converter = tf.lite.TFLiteConverter.from_session(sess, [img], [out])`\r\n`tflite_model = converter.convert()`\r\n`open(\"converted_model.tflite\", \"wb\").write(tflite_model).`\r\nThe process was fine. Then I tried to test the file with interpreter. But when I run\r\n`interpreter = tf.lite.Interpreter(model_path=\"converted_model.tflite\")`\r\n `interpreter.allocate_tensors()`\r\nI get the following runtime error:\r\n`tensorflow/contrib/lite/kernels/pack.cc:38 NumDimensions(input0) < 4 was not true.Node number 14 (PACK) failed to prepare.`\r\n\r\n**Code to reproduce the issue**\r\n`z = tf.stack([x, y], axis=3), where x and y both are 4D tensor.` \r\nWhat can I do to get the interpreter run? Any help will be appreciated.\r\n", "comments": ["Fixed internally. Please give it a try with the nightly build.", "Closing for now. Feel free to reopen if you run into any issue.", "I meet the same problem in Tensorflow 1.13.1 (Python2.7), how to fix it...", "My case is a bit special, 5D is just a temporary tensor, So I sacrifice the\nbatch dim because it is 1.\nCodingMice <notifications@github.com> \u4e8e 2019\u5e746\u670811\u65e5\u5468\u4e8c \u4e0b\u53487:47\u5199\u9053\uff1a\n\n> I meet the same problem in Tensorflow 1.13.1 (Python2.7), how to fix it...\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/23855?email_source=notifications&email_token=AIE2F5T3XYJPFWSHFFFSPETPZ6GFHA5CNFSM4GFE7IS2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODXM2UII#issuecomment-500804129>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AIE2F5RG5EE2URZLKWEKR4TPZ6GFHANCNFSM4GFE7ISQ>\n> .\n>\n", "OK, I have solved it with two tf.reshape. It works though it adds additional ops, thank you"]}]