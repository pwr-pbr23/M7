[{"number": 1390, "title": "Attempting to use uninitialized value lstm/LSTMCell/W_0", "body": "### Environment info\n\nOperating System: Rocks OS (Centos 6.5)\n\nI installed from sources, and here is my version:\nhttps://github.com/shiyemin/tensorflow/\nNothing changed but to make it compile successfully on our server.\n### Steps to reproduce\n1. add a LSTM layer between local3 and local4 in cifar10.py\n   \n   ```\n   # lstm\n   with tf.variable_scope('lstm') as scope:\n     lstm_cell = rnn_cell.LSTMCell(512, input_size=384)\n     feed_in = tf.split(0, 16, local3)\n     outputs, states = rnn.rnn(lstm_cell, feed_in, scope=scope, dtype=tf.float32)\n     lstm1 = tf.concat(0, outputs)\n   \n   # local4\n   with tf.variable_scope('local4') as scope:\n     weights = _variable_with_weight_decay('weights', shape=[512, 192],\n                                           stddev=0.04, wd=0.004)\n     biases = _variable_on_cpu('biases', [192], tf.constant_initializer(0.1))\n     local4 = tf.nn.relu(tf.matmul(lstm1, weights) + biases, name=scope.name)\n     _activation_summary(local4)\n   ```\n2. run cifar10_multi_gpu_train.py\n3. Error: Attempting to use uninitialized value lstm/LSTMCell/W_0\n### What have you tried?\n1. Run this network in Test mode, and everything is fine. \n2. Run this network in Train mode, error \"Attempting to use uninitialized value lstm/LSTMCell/W_0\" occurs.\n### Logs or other output that would be helpful\n\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:107] Allocating 10.60GiB bytes.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:118] GPU 0 memory begins at 0x23ee00000 extends to 0x4e573199a\nW tensorflow/core/common_runtime/executor.cc:1221] 0xb26c6f0 Compute status: Failed precondition: Attempting to use uninitialized value lstm/LSTMCell/W_0\n     [[Node: lstm/LSTMCell/W_0/_9 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_292_lstm/LSTMCell/W_0\", _device=\"/job:localhost/replica:0/task:0/gpu:0\"](lstm/LSTMCell/W_0)]]\n     [[Node: Identity_7/_8 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_267_Identity_7\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\nW tensorflow/core/common_runtime/executor.cc:1221] 0xb26c6f0 Compute status: Failed precondition: Attempting to use uninitialized value lstm/LSTMCell/W_0\n     [[Node: lstm/LSTMCell/W_0/_9 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_292_lstm/LSTMCell/W_0\", _device=\"/job:localhost/replica:0/task:0/gpu:0\"](lstm/LSTMCell/W_0)]]\n     [[Node: Identity_6/_16 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_295_Identity_6\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\nW tensorflow/core/common_runtime/executor.cc:1221] 0xb255bf0 Compute status: Failed precondition: Attempting to use uninitialized value lstm/LSTMCell/W_0\n     [[Node: lstm/LSTMCell/W_0/_9 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_292_lstm/LSTMCell/W_0\", _device=\"/job:localhost/replica:0/task:0/gpu:0\"](lstm/LSTMCell/W_0)]]\n     [[Node: lstm/LSTMCell/B/Assign/_5 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_265_lstm/LSTMCell/B/Assign\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\nW tensorflow/core/common_runtime/executor.cc:1221] 0xb255bf0 Compute status: Failed precondition: Attempting to use uninitialized value lstm/LSTMCell/W_0\n     [[Node: lstm/LSTMCell/W_0/_9 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_292_lstm/LSTMCell/W_0\", _device=\"/job:localhost/replica:0/task:0/gpu:0\"](lstm/LSTMCell/W_0)]]\n     [[Node: lstm/LSTMCell/W_0/Assign/_13 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_293_lstm/LSTMCell/W_0/Assign\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\nW tensorflow/core/common_runtime/executor.cc:1221] 0xb255bf0 Compute status: Failed precondition: Attempting to use uninitialized value lstm/LSTMCell/W_0\n     [[Node: lstm/LSTMCell/W_0/_9 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_292_lstm/LSTMCell/W_0\", _device=\"/job:localhost/replica:0/task:0/gpu:0\"](lstm/LSTMCell/W_0)]]\n     [[Node: init/NoOp_1/_19 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_5848_init/NoOp_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\nW tensorflow/core/common_runtime/executor.cc:1221] 0xb26c6f0 Compute status: Failed precondition: Attempting to use uninitialized value lstm/LSTMCell/W_0\n     [[Node: lstm/LSTMCell/W_0/_9 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_292_lstm/LSTMCell/W_0\", _device=\"/job:localhost/replica:0/task:0/gpu:0\"](lstm/LSTMCell/W_0)]]\n     [[Node: lstm/LSTMCell/B/Assign/_4 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_265_lstm/LSTMCell/B/Assign\", _device=\"/job:localhost/replica:0/task:0/gpu:0\"](lstm/LSTMCell/B/Assign/_3)]]\nW tensorflow/core/common_runtime/executor.cc:1221] 0xb26c6f0 Compute status: Failed precondition: Attempting to use uninitialized value lstm/LSTMCell/W_0\n     [[Node: lstm/LSTMCell/W_0/_9 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_292_lstm/LSTMCell/W_0\", _device=\"/job:localhost/replica:0/task:0/gpu:0\"](lstm/LSTMCell/W_0)]]\n     [[Node: lstm/LSTMCell/W_0/Assign/_12 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_293_lstm/LSTMCell/W_0/Assign\", _device=\"/job:localhost/replica:0/task:0/gpu:0\"](lstm/LSTMCell/W_0/Assign/_11)]]\nTraceback (most recent call last):\n  File \"cifar10_multi_gpu_train.py\", line 282, in <module>\n    tf.app.run()\n  File \"/home/shiyemin/code/tensorflow/_python_build/tensorflow/python/platform/default/_app.py\", line 30, in run\n    sys.exit(main(sys.argv))\n  File \"cifar10_multi_gpu_train.py\", line 278, in main\n    train()\n  File \"cifar10_multi_gpu_train.py\", line 237, in train\n    sess.run(init)\n  File \"/home/shiyemin/code/tensorflow/_python_build/tensorflow/python/client/session.py\", line 315, in run\n    return self._run(None, fetches, feed_dict)\n  File \"/home/shiyemin/code/tensorflow/_python_build/tensorflow/python/client/session.py\", line 511, in _run\n    feed_dict_string)\n  File \"/home/shiyemin/code/tensorflow/_python_build/tensorflow/python/client/session.py\", line 564, in _do_run\n    target_list)\n  File \"/home/shiyemin/code/tensorflow/_python_build/tensorflow/python/client/session.py\", line 586, in _do_call\n    e.code)\ntensorflow.python.framework.errors.FailedPreconditionError: Attempting to use uninitialized value lstm/LSTMCell/W_0\n     [[Node: lstm/LSTMCell/W_0/_9 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_292_lstm/LSTMCell/W_0\", _device=\"/job:localhost/replica:0/task:0/gpu:0\"](lstm/LSTMCell/W_0)]]\n     [[Node: lstm/LSTMCell/B/Assign/_5 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_265_lstm/LSTMCell/B/Assign\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n", "comments": ["It sounds like the variables were not initialized, but that's strange if tf.initialize_all_variables is being run. Can you check that you initialized the variables? Also - could you make a repo with just the problematic model and test it against the head TensorFlow?\n", "@lukaszkaiser OK, give me a minute.\n", "@lukaszkaiser There is no way for me to compile it without modifying some of configuration... Will you please test it for me? It's quite easy to test as what i said in issue.\n", "@lukaszkaiser By the way, everything is fine wittout LSTM or single GPU with LSTM. This can be confirmed by run cifar10_train.py and cifar10_multi_gpu_train.py.\n", "I tried to replicate your problem, but I can't -- I don't have a multi-gpu machine and, even though I tried, I cannot replicate the problem in a single-gpu setting in any way. In fact I even managed to run \"python cifar10_multi_gpu_train.py --num_gpus=2\" with your change and it was all ok, but I guess it just soft-placed everything on GPU0. One problem I can think of is that in your code your LSTM variables will not be placed on CPU, like the other ones. Can you try to put the whole LSTM on cpu first, just for a test (using tf.device around it)? If that works, then you can use pin_variables_to_cpu in your tf.device to just put the variables there, I hope. (It did not work once, I guess that's why cifar10 has _variable_on_cpu, but I think it's ok now.)\n", "@lukaszkaiser Yeah, you are right. It works well after put LSTM on CPU. I can not find this \"pin_variables_to_cpu\". But i will modify LSTM to add a parameter and let it have a option to put variables on CPU.\n\nA suggestion for this problem is to **add this pin_variables_to_cpu kind of parameter to rnn.rnn function**.\n\nThanks for your help!\n", "@lukaszkaiser After putting all LSTM variables on CPU,  the error \"Attempting to use uninitialized value lstm/LSTMCell/W_0\" is still there. I have to give up on this and use single GPU. But there may be bugs in LSTM in a multi GPU situation.\n", "I don't think there are any bugs in LSTM. Variable placement in a multi-device or multi-machine setting is hard, but it's solved by tf.device. We do not want to have parameters for this in LSTM or any other function, as we'd basically need to add the same code to every function we write. It is solved differently using tf.device -- you can use a tf.device context around anything you want, and it will put variables (or any other ops you wish) on any device you specify. Here is an example.\n  https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/client/graph_util_test.py#L57\n", "I find the same problem\n", "when I use multi layer lstm, \nif I put the lstm variables in gpu:0, it works well . \nbut when I change the lstm variable to gpu:1 or gpu:2,  \nerror:\ntensorflow.python.framework.errors.FailedPreconditionError: Attempting to use uninitialized value RNN/MultiRNNCell/Cell0/LSTMCell/W_0\n", "there may be bugs in LSTM in a multi GPU situation.\n", "@thewintersun In a multi GPUs situation, we should put all variables on CPU. However, the sample code will put them on GPU. You may try copying the code out and having a little modification.\n", "@shiyemin but I want to use multi-gpu to accelerate my calculate. \nif I put the variables on CPU, then the calcelate is on CPU too. \nso  the calcelerate is slow, that is not my purpose. \n", "your means is put variables define on CPU, the variables's operation on GPU? @shiyemin \n", "Yeah, you may refer to the cifar10 multi-gpu sample code. Variables should be put on CPU and ops can be put on GPUs.\n", "ok\uff0cit works,  thank you\n", "@shiyemin @lukaszkaiser \nHi, \nI have the same issue but with GRUCell using dynamic_rnn. I'm using them in a slightly modified seq-seq model. To be sure you're solution was something like this ? : \n\n```\ngru_cell = rnn_cell.GRUCell(1000)\nwith tf.device('/cpu:0'):    \n    output,final_state = rnn.dynamic_rnn(gru_cell,decoder_batch,initial_state = encoder_state,sequence_length = lens)\n```\n\nIts not working for me :/\n\nRelevant error stack - \n\n```\ntensorflow.python.framework.errors.FailedPreconditionError: Attempting to use uninitialized value seqToseq/RNN/GRUCell/Candidate/Linear/Matrix\n         [[Node: seqToseq/RNN/GRUCell/Candidate/Linear/Matrix/read = Identity[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](seqT\noseq/RNN/GRUCell/Candidate/Linear/Matrix)]]\nCaused by op u'seqToseq/RNN/GRUCell/Candidate/Linear/Matrix/read', defined at:\n\nFile \"chatbot.py\", line 85, in <module>\n    output,final_state = rnn.dynamic_rnn(gru_cell,decoder_batch,initial_state = encoder_state,sequence_length = decoder_lens)\n\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py\", line 580, in dynamic_rnn\n    swap_memory=swap_memory, sequence_length=sequence_length)\n\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py\", line 709, in _dynamic_rnn_loop\n    swap_memory=swap_memory)\n\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 1873, in while_loop\n    result = context.BuildLoop(cond, body, loop_vars)\n\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 1749, in BuildLoop\n    body_result = body(*vars_for_body_with_tensor_arrays)\n\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py\", line 692, in _time_step\n    skip_conditionals=True)\n\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py\", line 326, in _rnn_step\n    new_output, new_state = call_cell()\n\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py\", line 680, in <lambda>\n    call_cell = lambda: cell(input_t, state)\n\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn_cell.py\", line 266, in __call__\n    self._num_units, True))\n\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn_cell.py\", line 910, in _linear\n    matrix = vs.get_variable(\"Matrix\", [total_arg_size, output_size])\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py\", line 732, in get_variable\n    partitioner=partitioner, validate_shape=validate_shape)\n\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py\", line 161, in get_variable\n    caching_device=caching_device, validate_shape=validate_shape)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py\", line 478, in _get_single_variable\n\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py\", line 211, in __init__\n    dtype=dtype)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py\", line 316, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 831, in identity\n    result = _op_def_lib.apply_op(\"Identity\", input=input, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py\", line 704, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2260, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1230, in __init__\n    self._traceback = _extract_stack()\n```\n", "Nevermind. I figured it out. I was running the init op before starting queue runner threads\n", "I also met a similar error, but it was cause by my own fault.\r\nfor my case, I defined the LSTM within a function (within a class), say\r\n---\r\ndef prediction(self):\r\n  some codes..\r\n  lstm_cell = tf.nn.rnn_cell.LSTMCell(self.size_inner_vector)\r\n  lstm_cell = tf.nn.rnn_cell.DropoutWrapper(lstm_cell, output_keep_prob=self.dropout)\r\n  lstm_stack = tf.nn.rnn_cell.MultiRNNCell([lstm_cell] * self.num_hiddden_layers)\r\n  output, _ = tf.nn.dynamic_rnn(lstm_stack, batch_3D_input2lstm, dtype=tf.float32)\r\n  some codes..\r\n\r\n  return result\r\n---\r\n\r\nFor my case, I initialised the class without calling this function.\r\nWhen I fetch the value of a variable within this function, I got the above error.\r\n\r\nThus a possible reason is that: your expected graph has not been constructed, but you are fetching the value of a non-existing node. 'this is my stupid case>_<'\r\n\r\nBy sharing it here, I hope it can help someone else.", "I have the same problem, could you help me to solve it \r\nmy code is :\r\n****\r\ntrain_count = len(X_train)\r\nN_HIDDEN_UNITS = 64\r\n\r\nlstm_fw_cell = tf.contrib.rnn.BasicLSTMCell(N_HIDDEN_UNITS)\r\nlstm_bw_cell = tf.contrib.rnn.BasicLSTMCell(N_HIDDEN_UNITS)\r\n\r\ndef shared_layer(input_data):\r\n    print('i m in shared layer')\r\n    print(input_data)\r\n    (output_fw, output_bw), (output_state_fw, output_state_bw) = tf.nn.bidirectional_dynamic_rnn(\r\n                lstm_fw_cell,\r\n                lstm_bw_cell,\r\n                input_data,\r\n                sequence_length=None,\r\n                initial_state_fw=None,\r\n                initial_state_bw=None,\r\n                dtype=tf.float32,\r\n                parallel_iterations=None,\r\n                swap_memory=False,\r\n                time_major=False,\r\n                scope=None\r\n            )\r\n    outputs = tf.concat(axis=2, values=[output_fw, output_bw])\r\n    return outputs\r\n\r\ntf.get_default_graph()\r\nX = tf.placeholder(tf.float32, [BATCH_SIZE, N_TIME_STEPS,N_FEATURES],name=\"input\")\r\n#Initialize the variables\r\ninit = tf.global_variables_initializer()\r\n# launch the graph\r\nwith tf.Session() as sess:\r\n    sess.run(init)\r\n    for start, end in zip(range(0, train_count, BATCH_SIZE),\r\n                          range(BATCH_SIZE, train_count + 1,BATCH_SIZE)):\r\n        sess.run(shared_layer(X), feed_dict={X: X_train[start:end]})\r\n****\r\nthe shared layer function run for tensor(input:0) but it does not for the next tensor, it araise the folowing error : \r\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value bidirectional_rnn/bw/basic_lstm_cell/kernel\r\n\t [[Node: bidirectional_rnn/bw/basic_lstm_cell/kernel/read = Identity[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](bidirectional_rnn/bw/basic_lstm_cell/kernel)]]\r\n\r\n"]}, {"number": 1389, "title": "Tensorflow tutorial \"How to Retrain\": error when saving the model", "body": "For bugs/issues, please fill in the following.  The more information you\nprovide, the more likely we can help you.\n\nhello,\nI am trying to run the tutorial 'How to Retrain Inception's Final Layer for New Categories'\navailable here: https://www.tensorflow.org/versions/master/how_tos/image_retraining/index.html\n### Environment info\n\nOperating System: Ubuntu 14.04\n\nIf installed from binary pip package, provide:\n1. Which pip package you installed: I use the following AWS community AMI: \n   Axel TensorFlow machine - ami-a41147ce   in Northern Virginia region.\n2. The output from python -c \"import tensorflow; print(tensorflow.**version**)\":\n\nI tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcublas.so.7.0 locally\nI tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcudnn.so.6.5 locally\nI tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcufft.so.7.0 locally\nI tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcuda.so locally\nI tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcurand.so.7.0 locally\n0.5.0\n\nIf installed from sources, provide the commit hash:\n### Steps to reproduce\n\nstep 1. download and unpack images: curl -O http://download.tensorflow.org/example_images/flower_photos.tgz\ntar xzf flower_photos.tgz\n\nstep 2. run:    python retrain.py --image_dir ~/flower_photos\n### What have you tried?\n1. nothing: I do not know what to do\n### Logs or other output that would be helpful\n\n(If logs are large, please upload as attachment).\n\nthe only difference with the tutorial is that I do not use Bazel, I just do: \n\npython retrain.py --image_dir ~/flower_photos\n\nEverything runs smoothly, until I get this error:\n\nFinal test accuracy = 91.6%\nTraceback (most recent call last):\nFile \"retrain.py\", line 829, in <module>\ntf.app.run()\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/default/_app.py\", line 30, in run\nsys.exit(main(sys.argv))\nFile \"retrain.py\", line 820, in main\noutput_graph_def = graph_util.convert_variables_to_constants(\nAttributeError: 'module' object has no attribute 'convert_variables_to_constants'\n\nThe problematic portion of the code is:\n\n  # Write out the trained graph and labels with the weights stored as constants.\n  output_graph_def = graph_util.convert_variables_to_constants(\n      sess, graph.as_graph_def(), [FLAGS.final_tensor_name])\n  with gfile.FastGFile(FLAGS.output_graph, 'wb') as f:\n    f.write(output_graph_def.SerializeToString())\n  with gfile.FastGFile(FLAGS.output_labels, 'w') as f:\n    f.write('\\n'.join(image_lists.keys()) + '\\n')\n\nWhat should I do?\n", "comments": ["The Bazel build process helps set up the dependency paths for things like graph_util, so that's the supported path for this. Looking at your error, I'm guessing you have an older pip-installed version of TensorFlow, where the graph_util namespace didn't include that function, which was introduced after 0.7.1.\nhttps://github.com/tensorflow/tensorflow/commit/2179890199c3561ff3a1297c5e9c073471473a77#diff-33f2d39e607bc1b6234f0972973159cb\nI hope this explanation helps. I'm closing this since I believe it's working as intended.\n", "yes, you were right, with the version 0.7.1, it worked. it would be nice to specify this requirement in the tutorial, as many people use older versions\n"]}, {"number": 1388, "title": "Potential bug: Gradients currently flow through variables that are fed", "body": "```\nx = tf.Variable(1.0)\ny = 2*x\nz = 3*y\ndzdx, = tf.gradients(z, x)\n\nsess.run(tf.initialize_all_variables())\nprint(sess.run([z, dzdx], feed_dict={y: 10.0}))\n\n# Result: z = 30.0, dzdx = 6.0\n```\n\nTo me this seems like a bug: the only reasonable behavior here seems to be to treat `y` as constant, so that `dzdx` is 0.0. This would let us feed parts of models when needed, in turn automatically shutting off all gradient updates with respect to the parameters that would have been responsible for generating these fed values.\n\nThis would be a nice thing to have in my current use case. If we want to perform iterative optimization with respect to two parameter sets, we would like to feed results from set 1 and optimize set 2; feed results from set 2 and optimize set 1; etc.\n\nIs the current behavior intended and/or useful in some use cases? If not, can we fix this?\n", "comments": ["This is intended behavior and unlikely to change: tf.gradients adds new nodes to the graph via symbolic differentiation.  The underlying TensorFlow runtime doesn't have any idea these nodes are gradients, so it won't treat them specially based on feeding.\n\nFor your use case: ask `tf.gradients` to give you the gradient w.r.t. y as well, then feed zeros to `dzdy` to tell the backward pass that you want nothing to pass through there.  It won't be as fast as possible, though.\n", "What I ended up doing was collecting the variables of the two models separately and computing separate gradients/minimizing ops for each (after debugging as I had assumed that gradients would stop at fed nodes). Thanks though, now I see why it's expected behavior.\n", "@rdipietro: Yep, that's actually better than my suggestion, since the graphs don't be doing any unnecessary computations on zeros. \n"]}, {"number": 1387, "title": "For poor guys without access to boringssl located in google's server", "body": "When I cloned the latest tensorflow and compile it with bazel, bazel clones grpc.git from github.\nHowever grpc.git need clone submodule boringssl which is located in google's server. Since I have no stable vpn to have access to boringssl, I forked grpc.git to my github and changed WORKSPACE of tensorflow (located in tensorflow's root path) as follows:\n git_repository(\n     name = \"grpc\",\n-    commit = \"73979f4\",\n-    commit = \"403cd6c\",\n   init_submodules = True,\n-    remote = \"https://github.com/grpc/grpc.git\",\n-    remote = \"https://github.com/melody-rain/grpc.git\",\n  )\n\nand also I changed the .gitmodule of grpc.git so that boringssl is downloaded from  \n\n[submodule \"third_party/boringssl\"]\n    path = third_party/boringssl\n    url = https://github.com/doubler/boringssl.git\n\nThanks @doubler for his help. \n\nFor those have access to google's service, just ignore this issue,\n", "comments": ["I was about to do the same thing, and found this issue. Many thanks!\n\nLife is tough for Chinese mainland people...\n", "@yangyanli  not easy to be a programmer...\n", "@   melody-rain I also meet the problem. I don't see git_repository name = \"grpc\" in my workspace. What I see is new_git_repository.\n", "@MisayaZ  have a look at https://github.com/grpc/grpc/issues/5853. The code might be changed.\n", "I think this is fixed thanks to the underlying fixes in gRPC.\n"]}, {"number": 1386, "title": "Also testing align_corners feature when comparing implementations", "body": "A follow up to #588 \n", "comments": ["Can one of the admins verify this patch?\n", "@tensorflow-jenkins: test this please\n", "Merged\n"]}, {"number": 1385, "title": "bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package", "body": "Why executing \n\"bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\"\n\ndeletes grpc.git and repulls it If I execute \"bazel clean\" ?\n", "comments": ["This is probably more a question for the bazel team, but bazel clean is supposed to clean up all state to try to provide hermeticity in builds.\n"]}, {"number": 1384, "title": "Improvements to Issue template language", "body": "Points people to StackOverflow for non bugs / features  as an attempt to try to keep github issues mostly for bugs / feature tracking instead of general support.\n", "comments": ["Merged\n"]}, {"number": 1383, "title": "Attempting to use uninitialized value RNN/GRUCell/Gates/Linear/Bias", "body": "### Environment info\n\nOperating System:\nRocks OS (Centos 6.5)\n\nI installed from sources, and here is my version:\nhttps://github.com/shiyemin/tensorflow/\nNothing changed but to make it compile successfully on our server.\n### ERROR\n\nI use https://github.com/ethereon/caffe-tensorflow to convert caffe model to tensorflow and the GoogLeNet is selected to construct our network.\n\nI add  a LSTM layer to this code as follows:\n\n```\n@layer\ndef lstm(self, input, lstm_type, n_steps, initial_state, num_units, name):\n    #  with tf.variable_scope(name) as scope:\n    input_shape = input.get_shape()\n    dim = 1\n    for d in input_shape[1:].as_list():\n        dim *= d\n    input = tf.reshape(input, [input_shape[0].value, -1])\n\n    # select LSTM type, Define a lstm cell with tensorflow\n    if lstm_type == 'basic':\n        lstm_cell = rnn_cell.BasicLSTMCell(num_units, input_size=dim)\n    elif lstm_type == 'lstm':\n        lstm_cell = rnn_cell.LSTMCell(num_units, input_size=dim)\n    elif lstm_type == 'GRU':\n        lstm_cell = rnn_cell.GRUCell(num_units, input_size=dim)\n    else:\n        raise ValueError(\"LSTM type %s error.\"%lstm_type)\n\n    # Split data because rnn cell needs a list of inputs for the RNN inner loop\n    input = tf.split(0, n_steps, input) # n_steps * (batch_size, n_hidden)\n\n    # Get lstm cell output\n    outputs, states = rnn.rnn(lstm_cell, input, initial_state=initial_state) # , scope=scope)\n    outputs = tf.concat(0, outputs)\n    return outputs #, states\n```\n\nWhen i add this LSTM layer to GoogLeNet, \"Failed precondition: Attempting to use uninitialized value  RNN/GRUCell/Gates/Linear/Bias\" occurs. But when i using the code from https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3%20-%20Neural%20Networks/recurrent_network.py, everything works well.\n\nAnyone knows what happened? I don't know how to debug this error.\n", "comments": ["Unless you think this is a bug in TensorFlow, this question is better suited to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow)\n"]}, {"number": 1382, "title": "Tensorflow Tutorial websites are full of \"Math Processing Error\" messages", "body": "Hi,\n\nI just wanted to bring this up, many of the tutorial pages in the current website are showing an error as follows:\n\n[Math Processing Error]\n\nThis is showing instead of the formulas and make the learning processed a little bit more complicated.\n\nExample affected page:\n\nhttps://www.tensorflow.org/versions/r0.7/tutorials/word2vec/index.html#vector-representations-of-words\n", "comments": ["Closing as duplicate of #1377 -- thanks for the report!\n"]}, {"number": 1381, "title": "inner product", "body": "how to do inner product with tensorflow?\n", "comments": ["This isn't a bug  / feature request, so StackOverflow is a better venue for this question.\n"]}, {"number": 1380, "title": "Changes to pip.sh; adding docker_test.sh", "body": "1) Breaking pip.sh into the install step (pip.sh) and the test step\n(newly added test_installation.sh)\n\npip.sh now performs only the building and install of the pip package,\nwith the install happening inside virtualenv. (vritualenv address the\nreinstallation issue on Mac pip tests). Then it calls\ntest_installation.sh and test_tutorials.sh to test the virtualenv pip\ninstall of TensorFlow.\n\n2) Adding a new file, docker_test.sh, as a first step toward automation\nof TensorFlow docker image build and test process.\n\nThis script builds and tests docker images with TensorFlow pip whl\ninstalled. The tests include the Python unit tests and tutorial tests\nagainst the (non-virtualenv) install. This is not fully functional yet, because\nwe need to further automate the pip package uploading process, so the\nDockerfiles in tensorflow/tools/docker can point to the latest pip\nfiles.\n", "comments": ["Can one of the admins verify this patch?\n", "Nice!\n\nBut let's make the line wrapping good. I see it was broken on many places even before this commit (at least in parametrized_build). We normally indent by two spaces. Hence when the line is too long and continues on next one it should have the same indentation PLUS 4 spaces. And all the || and && should be at the end of the lines not beginnings. Right?\n", "Addressed @jendap's latest comments. Tested on Jenkins. This PR is ready to be merged. \n", "Thank you!\n\nNit: There are still a few multiline statements without intending the next line by two indents. For example\n\n```\n  die \"FAILED: Unable to find the base directory where the dockerfile \"\\\n\"${DOCKERFFILE} resides\"\n```\n\nis missing 6 spaces on the second line. And there are others.\n", "@tensorflow-jenkins test this please.\n", "We found a Contributor License Agreement for you (the sender of this pull request) and all commit authors, but as best as we can tell these commits were authored by someone else.  If that's the case,  please add them to this pull request and have them confirm that they're okay with these commits being contributed to Google.  If we're mistaken and you did author these commits, just reply here to confirm.\n\n<!-- need_author_consent -->\n", "CLAs look good, thanks!\n\n<!-- ok -->\n"]}, {"number": 1379, "title": "IF Exists the method about \"dropconnect\", THANK YOU !!", "body": "For bugs/issues, please fill in the following.  The more information you\nprovide, the more likely we can help you.\n### Environment info\n\nOperating System:\n\nIf installed from binary pip package, provide:\n1. Which pip package you installed.\n2. The output from python -c \"import tensorflow; print(tensorflow.**version**)\".\n\nIf installed from sources, provide the commit hash:\n### Steps to reproduce\n\n1.\n2.\n3.\n### What have you tried?\n\n1.\n### Logs or other output that would be helpful\n\n(If logs are large, please upload as attachment).\n", "comments": ["This isn't a bug or a feature request (as far as I can tell), so this is better suited to Stack Overflow\n"]}, {"number": 1378, "title": "load_op_library breaks when loading 2 different .so ", "body": "For bugs/issues, please fill in the following.  The more information you\nprovide, the more likely we can help you.\n### Environment info\n\nOperating System:\nRhel 7\n\nIf installed from binary pip package, provide:\n1. Which pip package you installed.\n   Built from source.  0.7.1 master 3/3/2016\n2. The output from python -c \"import tensorflow; print(tensorflow.**version**)\".\n   0.7.1\n   If installed from sources, provide the commit hash:\n   99952d68444cd2b08e88af972bd9eb7034fbc1e7\n### Steps to reproduce\n1.  Follow Instructions via:\n   https://www.tensorflow.org/versions/master/how_tos/adding_an_op/index.html\n2.  Create zero_out.cc and build zero_out.so\n\n```\n#include \"tensorflow/core/framework/op.h\"\n\nREGISTER_OP(\"ZeroOut\")\n    .Input(\"to_zero: int32\")\n    .Output(\"zeroed: int32\");\n\n#include \"tensorflow/core/framework/op_kernel.h\"\n\nusing namespace tensorflow;\n\nclass ZeroOutOp : public OpKernel {\n public:\n  explicit ZeroOutOp(OpKernelConstruction* context) : OpKernel(context) {}\n\n  void Compute(OpKernelContext* context) override {\n    // Grab the input tensor\n    const Tensor& input_tensor = context->input(0);\n    auto input = input_tensor.flat<int32>();\n\n    // Create an output tensor\n    Tensor* output_tensor = NULL;\n    OP_REQUIRES_OK(context, context->allocate_output(0, input_tensor.shape(),\n                                                     &output_tensor));\n    auto output = output_tensor->template flat<int32>();\n\n    // Set all but the first element of the output tensor to 0.\n    const int N = input.size();\n    for (int i = 1; i < N; i++) {\n      output(i) = 0;\n    }\n\n    // Preserve the first input value if possible.\n    if (N > 0) output(0) = input(0);\n  }\n};\n\nREGISTER_KERNEL_BUILDER(Name(\"ZeroOut\").Device(DEVICE_CPU), ZeroOutOp);\n```\n1.  Create one_out.cc and build one_out.so\n\n```\n#include \"tensorflow/core/framework/op.h\"\n\nREGISTER_OP(\"OneOut\")\n    .Input(\"to_one: int32\")\n    .Output(\"oneed: int32\");\n\n#include \"tensorflow/core/framework/op_kernel.h\"\n\nusing namespace tensorflow;\n\nclass OneOutOp : public OpKernel {\n public:\n  explicit OneOutOp(OpKernelConstruction* context) : OpKernel(context) {}\n\n  void Compute(OpKernelContext* context) override {\n    // Grab the input tensor\n    const Tensor& input_tensor = context->input(0);\n    auto input = input_tensor.flat<int32>();\n\n    // Create an output tensor\n    Tensor* output_tensor = NULL;\n    OP_REQUIRES_OK(context, context->allocate_output(0, input_tensor.shape(),\n                                                     &output_tensor));\n    auto output = output_tensor->template flat<int32>();\n\n    // Set all but the first element of the output tensor to 0.\n    const int N = input.size();\n    for (int i = 1; i < N; i++) {\n      output(i) = 1;\n    }\n\n    // Preserve the first input value if possible.\n    if (N > 0) output(0) = input(0);\n  }\n};\n\nREGISTER_KERNEL_BUILDER(Name(\"OneOut\").Device(DEVICE_CPU), OneOutOp);\n```\n1.  Attempt to load both so in same script:\n\n```\nimport tensorflow as tf\n\nzero_out_module = tf.load_op_library('./zero_out.so')\none_out_module = tf.load_op_library('./one_out.so')\n\nwith tf.Session('') as session:\n    inputs = tf.constant([[1,1,1], [-2, -2, -2]], dtype=tf.int32)\n    print(inputs.eval())\n```\n1. Get Error:\n\n```\nF tensorflow/core/framework/op.cc:119] Check failed: ::tensorflow::Status::OK() == (RegisterAlreadyLocked(op_def)) (OK vs. Already exists: Op with name ZeroOu\nt)Attempting to register: Op<name=ZeroOut; signature=to_zero:int32 -> zeroed:int32>\nAborted\n\n```\n", "comments": ["e774fa8 is of great help, thanks! \nHowever, when calling `tf.load_op_library` _twice_ (for the _same_ .so), the loaded module no longer has any of the defined ops (the OP_LIST is empty as well). \n"]}, {"number": 1377, "title": "Tensorflow Website : Missing Mathjax results in broken equations", "body": "The website tries to load,\n\n`\nhttps://www.tensorflow.org/MathJax/jax/output/HTML-CSS/fonts/STIX/fontdata.js?rev=2.6.1\n`\n\nand fails. Someone needs to fix the path to get the right version of mathjax, and have all the LaTeX symbols show up.\n\nThanks.\n", "comments": ["This issue still affects the website for me (both on Chrome 49 and Firefox 44). \n", "The \"MNIST For ML Beginners\" has most equations working, but there's several in the Training section that are showing \"Math Processing Error\":\n\nhttps://www.tensorflow.org/versions/r0.7/tutorials/mnist/beginners/index.html#training\n\n```\nError: Cannot read property 'fontInherit' of undefined\nDebugging tips: use 'unpacked/MathJax.js', inspect 'MathJax.Hub.lastError' in the browser console\n```\n\nUsing Mathjax's right-click menu to set the Renderer to SVG works, so it's just the HTML+CSS renderer having issues.\n", "This is fixed now.\n", "The same problem still appears in Chrome (latest version, Version 59.0.3071.115) on Mac OS. In Firefox and Safari on Mac OS, it works fine.\r\nExample affected page: https://www.tensorflow.org/tutorials/word2vec\r\n\r\n<img width=\"725\" alt=\"wx20170705-102404 2x\" src=\"https://user-images.githubusercontent.com/13765633/27846840-8a9e1ccc-616c-11e7-8d2f-f0d77240bde7.png\">\r\n"]}, {"number": 1376, "title": "AttributeError: 'module' object has no attribute 'random_crop'", "body": "I'm on using Ubuntu 14.04 and installed tensorflow. When I ran the image processing example as in the website, it failed complaining about random_crop not found. I took the code from here \nhttps://github.com/tensorflow/tensorflow/blob/r0.7/tensorflow/models/image/cifar10/\n\nHere's the exception stack:\n\n```\nTraceback (most recent call last):\n  File \"cifar10_train.py\", line 136, in <module>\n    tf.app.run()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/default/_app.py\", line 11, in run\n    sys.exit(main(sys.argv))\n  File \"cifar10_train.py\", line 132, in main\n    train()\n  File \"cifar10_train.py\", line 67, in train\n    images, labels = cifar10.distorted_inputs()\n  File \"/home/sarah/Documents/SVHN/cifar10.py\", line 150, in distorted_inputs\n    batch_size=FLAGS.batch_size)\n  File \"/home/sarah/Documents/SVHN/cifar10_input.py\", line 161, in distorted_inputs\n    distorted_image = tf.random_crop(reshaped_image, [height, width, 3])\nAttributeError: 'module' object has no attribute 'random_crop'\n\n```\n", "comments": ["what version of tensorflow do you have?  We renamed tf.image.random_crop to tf.random_crop between 0.6 to 0.7 -- upgrading should solve the problem, or checking out the code at the 0.6.0 branch if you don't want to upgrade.\n"]}, {"number": 1375, "title": "Compilation issue: 'Matrix' is not a class, namespace, or enumeration", "body": "### Environment info\n\nOperating System: CentOS 6.7\nIf installed from sources, provide the commit hash: eda89e930cfcbd992ecacafd40267d733e2153dc\n### Steps to reproduce\n1. Configure for gcc 4.8.2\n2. ./configure\n3. Edit third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc\n   - This is necessary; otherwise `gcc` can't find `as`.\n   - In fact, there are notes about this:\n     - `# TODO(zhengxq): for some reason, 'gcc' needs this help to find 'as'.`\n     - `# Need to investigate and fix.`\n   - I had to comment their fix to get gcc to find `as` on my system.\n   - Specifically, `# cmd = 'PATH=' + PREFIX_DIR + ' ' + cmd`\n4. `bazel build -c opt --config=cuda --verbose_failures --genrule_strategy=standalone --spawn_strategy=standalone //tensorflow/tools/pip_package:build_pip_package`\n### What have you tried?\n1. I don't know what else to try.\n### Logs or other output that would be helpful\n\nMost of the build succeeds, but then I get\n\n```\nINFO: Found 1 target...\nERROR: /home-4/rdipiet2@jhu.edu/install/tensorflow/tensorflow/core/kernels/BUILD:560:1: C++ compilation of rule '//tensorflow/core/kernels:matrix_solve_ls_op' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command \n  (cd /home-4/rdipiet2@jhu.edu/.cache/bazel/_bazel_rdipiet2@jhu.edu/549db212089e33b4d213773753834e47/tensorflow && \\\n  exec env - \\\n    PATH=/home-4/rdipiet2@jhu.edu/install/bazel/output:/home-4/rdipiet2@jhu.edu/.usr/bin:/home-4/rdipiet2@jhu.edu/vc/scripts:/home-4/rdipiet2@jhu.edu/.local/bin:/cm/shared/apps/java/JDK_1.8.0_45/bin:/cm/shared/apps/cuda/7.0/bin:/cm/shared/apps/git/2.6.4/bin:/cm/shared/apps/anaconda/2.7.10/bin:/cm/shared/apps/slurm/current/sbin:/cm/shared/apps/slurm/current/bin:/cm/shared/apps/gcc/4.8.2/bin:/cm/shared/apps/Intel/openmpi/1.8.4/bin:/cm/shared/apps/binutils:/cm/shared/apps/binutils/2.25/src/bin:/cm/shared/apps/parallel_studio_xe_2015_update2/composer_xe_2015.2.164/bin/intel64:/usr/lib64/qt-3.3/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/opt/ibutils/bin:/sbin:/usr/sbin:/cm/local/apps/environment-modules/3.2.10/bin:/opt/dell/srvadmin/bin:/home-4/rdipiet2@jhu.edu/bin \\\n  third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections '-std=c++11' -iquote . -iquote bazel-out/local_linux-opt/genfiles -iquote external/bazel_tools -iquote bazel-out/local_linux-opt/genfiles/external/bazel_tools -iquote external/jpeg_archive -iquote bazel-out/local_linux-opt/genfiles/external/jpeg_archive -iquote external/png_archive -iquote bazel-out/local_linux-opt/genfiles/external/png_archive -iquote external/re2 -iquote bazel-out/local_linux-opt/genfiles/external/re2 -iquote external/eigen_archive -iquote bazel-out/local_linux-opt/genfiles/external/eigen_archive -isystem google/protobuf/src -isystem bazel-out/local_linux-opt/genfiles/google/protobuf/src -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/jpeg_archive/jpeg-9a -isystem bazel-out/local_linux-opt/genfiles/external/jpeg_archive/jpeg-9a -isystem external/png_archive/libpng-1.2.53 -isystem bazel-out/local_linux-opt/genfiles/external/png_archive/libpng-1.2.53 -isystem external/re2 -isystem bazel-out/local_linux-opt/genfiles/external/re2 -isystem third_party/eigen3 -isystem bazel-out/local_linux-opt/genfiles/third_party/eigen3 -isystem external/eigen_archive/eigen-eigen-017cff30cf74 -isystem bazel-out/local_linux-opt/genfiles/external/eigen_archive/eigen-eigen-017cff30cf74 -isystem third_party/gpus/cuda -isystem bazel-out/local_linux-opt/genfiles/third_party/gpus/cuda -isystem third_party/gpus/cuda/include -isystem bazel-out/local_linux-opt/genfiles/third_party/gpus/cuda/include -fno-exceptions -DEIGEN_AVOID_STL_ARRAY '-DGOOGLE_CUDA=1' -pthread '-DGOOGLE_CUDA=1' -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -fno-canonical-system-headers '-frandom-seed=bazel-out/local_linux-opt/bin/tensorflow/core/kernels/_objs/matrix_solve_ls_op/tensorflow/core/kernels/matrix_solve_ls_op.pic.o' -MD -MF bazel-out/local_linux-opt/bin/tensorflow/core/kernels/_objs/matrix_solve_ls_op/tensorflow/core/kernels/matrix_solve_ls_op.pic.d -fPIC -c tensorflow/core/kernels/matrix_solve_ls_op.cc -o bazel-out/local_linux-opt/bin/tensorflow/core/kernels/_objs/matrix_solve_ls_op/tensorflow/core/kernels/matrix_solve_ls_op.pic.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1: crosstool_wrapper_driver_is_not_gcc failed: error executing command \n  (cd /home-4/rdipiet2@jhu.edu/.cache/bazel/_bazel_rdipiet2@jhu.edu/549db212089e33b4d213773753834e47/tensorflow && \\\n  exec env - \\\n    PATH=/home-4/rdipiet2@jhu.edu/install/bazel/output:/home-4/rdipiet2@jhu.edu/.usr/bin:/home-4/rdipiet2@jhu.edu/vc/scripts:/home-4/rdipiet2@jhu.edu/.local/bin:/cm/shared/apps/java/JDK_1.8.0_45/bin:/cm/shared/apps/cuda/7.0/bin:/cm/shared/apps/git/2.6.4/bin:/cm/shared/apps/anaconda/2.7.10/bin:/cm/shared/apps/slurm/current/sbin:/cm/shared/apps/slurm/current/bin:/cm/shared/apps/gcc/4.8.2/bin:/cm/shared/apps/Intel/openmpi/1.8.4/bin:/cm/shared/apps/binutils:/cm/shared/apps/binutils/2.25/src/bin:/cm/shared/apps/parallel_studio_xe_2015_update2/composer_xe_2015.2.164/bin/intel64:/usr/lib64/qt-3.3/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/opt/ibutils/bin:/sbin:/usr/sbin:/cm/local/apps/environment-modules/3.2.10/bin:/opt/dell/srvadmin/bin:/home-4/rdipiet2@jhu.edu/bin \\\n  third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections '-std=c++11' -iquote . -iquote bazel-out/local_linux-opt/genfiles -iquote external/bazel_tools -iquote bazel-out/local_linux-opt/genfiles/external/bazel_tools -iquote external/jpeg_archive -iquote bazel-out/local_linux-opt/genfiles/external/jpeg_archive -iquote external/png_archive -iquote bazel-out/local_linux-opt/genfiles/external/png_archive -iquote external/re2 -iquote bazel-out/local_linux-opt/genfiles/external/re2 -iquote external/eigen_archive -iquote bazel-out/local_linux-opt/genfiles/external/eigen_archive -isystem google/protobuf/src -isystem bazel-out/local_linux-opt/genfiles/google/protobuf/src -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/jpeg_archive/jpeg-9a -isystem bazel-out/local_linux-opt/genfiles/external/jpeg_archive/jpeg-9a -isystem external/png_archive/libpng-1.2.53 -isystem bazel-out/local_linux-opt/genfiles/external/png_archive/libpng-1.2.53 -isystem external/re2 -isystem bazel-out/local_linux-opt/genfiles/external/re2 -isystem third_party/eigen3 -isystem bazel-out/local_linux-opt/genfiles/third_party/eigen3 -isystem external/eigen_archive/eigen-eigen-017cff30cf74 -isystem bazel-out/local_linux-opt/genfiles/external/eigen_archive/eigen-eigen-017cff30cf74 -isystem third_party/gpus/cuda -isystem bazel-out/local_linux-opt/genfiles/third_party/gpus/cuda -isystem third_party/gpus/cuda/include -isystem bazel-out/local_linux-opt/genfiles/third_party/gpus/cuda/include -fno-exceptions -DEIGEN_AVOID_STL_ARRAY '-DGOOGLE_CUDA=1' -pthread '-DGOOGLE_CUDA=1' -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -fno-canonical-system-headers '-frandom-seed=bazel-out/local_linux-opt/bin/tensorflow/core/kernels/_objs/matrix_solve_ls_op/tensorflow/core/kernels/matrix_solve_ls_op.pic.o' -MD -MF bazel-out/local_linux-opt/bin/tensorflow/core/kernels/_objs/matrix_solve_ls_op/tensorflow/core/kernels/matrix_solve_ls_op.pic.d -fPIC -c tensorflow/core/kernels/matrix_solve_ls_op.cc -o bazel-out/local_linux-opt/bin/tensorflow/core/kernels/_objs/matrix_solve_ls_op/tensorflow/core/kernels/matrix_solve_ls_op.pic.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\ntensorflow/core/kernels/matrix_solve_ls_op.cc: In member function 'void tensorflow::MatrixSolveLsOp<Scalar, SupportsBatchOperationT>::ComputeMatrix(tensorflow::OpKernelContext*, const typename tensorflow::BinaryLinearAlgebraOp<Scalar, SupportsBatchOperationT>::ConstMatrixMap&, const typename tensorflow::BinaryLinearAlgebraOp<Scalar, SupportsBatchOperationT>::ConstMatrixMap&, typename tensorflow::BinaryLinearAlgebraOp<Scalar, SupportsBatchOperationT>::MatrixMap*)':\ntensorflow/core/kernels/matrix_solve_ls_op.cc:111:41: error: 'Matrix' is not a class, namespace, or enumeration\n               (Scalar(l2_regularizer) * Matrix::Ones(cols, 1)).asDiagonal();\n                                         ^\ntensorflow/core/kernels/matrix_solve_ls_op.cc:131:41: error: 'Matrix' is not a class, namespace, or enumeration\n               (Scalar(l2_regularizer) * Matrix::Ones(rows, 1)).asDiagonal();\n                                         ^\nIn file included from ./tensorflow/core/framework/op_kernel.h:22:0,\n                 from tensorflow/core/kernels/matrix_solve_ls_op.cc:23:\n./tensorflow/core/framework/allocator.h: In member function 'virtual std::size_t tensorflow::Allocator::RequestedSize(void*)':\n./tensorflow/core/framework/allocator.h:152:3: warning: control reaches end of non-void function [-Wreturn-type]\n   }\n   ^\nIn file included from ./tensorflow/core/framework/op_kernel.h:25:0,\n                 from tensorflow/core/kernels/matrix_solve_ls_op.cc:23:\n./tensorflow/core/framework/device_base.h: In member function 'virtual tensorflow::Allocator* tensorflow::DeviceBase::GetAllocator(tensorflow::AllocatorAttributes)':\n./tensorflow/core/framework/device_base.h:150:3: warning: control reaches end of non-void function [-Wreturn-type]\n   }\n   ^\n./tensorflow/core/framework/device_base.h: In member function 'virtual const tensorflow::DeviceAttributes& tensorflow::DeviceBase::attributes() const':\n./tensorflow/core/framework/device_base.h:181:3: warning: control reaches end of non-void function [-Wreturn-type]\n   }\n   ^\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\nINFO: Elapsed time: 12.708s, Critical Path: 12.06s\n\n```\n\nI'm hoping very much to get this running on a CentOS cluster \u2013 any help will be very appreciated. Thanks.\n", "comments": ["Duplicate of #1362 -- can you see the suggestion I added there?\n"]}, {"number": 1374, "title": "Document trick with slash in scope names", "body": "The documentation for `tf.name_scope` is rather ambiguous on what happens if the scope name ends with '/', merely stating what happens if it doesn't end with a '/'. The fact that the behavior is different, specifically that ending with a '/' does not result in automatically uniqueifying the scope name, is very important and useful, because sometimes one wants to reenter a previously created scope. This possibility is only alluded to when describing recapturing `scope` variables, but the functionality is more general than that.\n", "comments": ["Does the code with scope name ends with '/' run ? ", "@alquraishi does this issue still look relevant?\r\n", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 29 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 1373, "title": "import tensorflow results in segfault.", "body": "For bugs/issues, please fill in the following.  The more information you\nprovide, the more likely we can help you.\n### Environment info\n\nOperating System:\nubuntu 15.10 64-bit\nPython 3.4.3+\n\nIf installed from binary pip package, provide:\n1. Which pip package you installed.\nhttps://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.7.1-cp34-none-linux_x86_64.whl\n2. The output from python -c \"import tensorflow; print(tensorflow.**version**)\".\npython3 -c \"import tensorflow; print(tensorflow.**version**)\"\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally\n0.7.1\n### Steps to reproduce\n1. import gi\n2. from gi.repository import Gtk\n3. import tensorflow\n### What have you tried?\n1. Identified the necessary steps to reproduce the segfault.\n2. Importing in opposite order does NOT produce any segfault.\n   1. import tensorflow\n   2. import gi\n   3. from gi.repository import Gtk\n### Logs or other output that would be helpful\n\nSegmentation fault (core dumped)\n", "comments": ["What version of python3 do you have installed?\n\nHave you tried installing tensorflow within a virtualenv, to isolate the environment?\n", "I used Python 3.4.3+\n", "Which version of CUDA are you using?\n", "Nvidia version:\n`cat /proc/driver/nvidia/version`\n\n`NVRM version: NVIDIA UNIX x86_64 Kernel Module  352.63  Sat Nov  7 21:25:42 PST 2015`\n`GCC version:  gcc version 5.2.1 20151010 (Ubuntu 5.2.1-22ubuntu2)`\n\nCUDA complier version:\n`nvcc -V`\n\n`nvcc: NVIDIA (R) Cuda compiler driver`\n`Copyright (c) 2005-2015 NVIDIA Corporation`\n`Built on Mon_Feb_16_22:59:02_CST_2015`\n`Cuda compilation tools, release 7.0, V7.0.27`\n\n`./deviceQuery`\n\n`./deviceQuery Starting...`\n`CUDA Device Query (Runtime API) version (CUDART static linking)`\n `Detected 1 CUDA Capable device(s)`\n\n`Device 0: \"Quadro K2200\"`\n  `CUDA Driver Version / Runtime Version          7.5 / 7.0`\n  `CUDA Capability Major/Minor version number:    5.0`\n...\n`deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 7.5, CUDA Runtime Version = 7.0, NumDevs = 1, Device0 = Quadro K2200`\n`Result = PASS`\n\nGtk version:\n`Gtk._version\n3.0`\n", "This happened to me when I configured the system to use CUDA 6.x but had 7.x installed and dylib/symlinks weren't updated correctly.\n\nMy suggestion would be to clean out your CUDA/CUDNN installation, and reconfigure in a clean environment. \n", "> > > import tensorflow\n> > > I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally\n> > > I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally\n> > > I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally\n> > > I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally\n> > > I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally\n> > > Segmentation fault\n\nhow to solve this problem????\n", "I have the same issue. I am using python2.7, ubuntu 14.04, cudnn v4 and cuda 7.5 \n\n``` python\nIn [1]: import tensorflow\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally\nSegmentation fault (core dumped)\n```\n", "It seems that chengdianxuezi and pulkitag suffer a somewhat different problem than I did. In my case, Python only crashed when I had imported Gtk before importing tensorflow. I get the impression that the two previous posters suffer from seg faults that doesn't involve Gtk.\n\nI have not been able to test viksit's suggestion since I currently do not have access to a Nvidia graphics card.\n", "Same issue here. Im using python 2.7, cudnn v4, cuda 7.5 on ubuntu 14.04.\n", "I think, I know where the problem is but don't know how to fix it. \nIf you run:\n\n```\ngdb python\n(gdb) run tf.py \n```\n\nwhere tf.py has\n\n``` python\nimport tensorflow as tf\n```\n\nthe trace tells that segfault is happening at:  \nPyArray_API () from /usr/local/lib/python2.7/dist-packages/numpy/core/multiarray.so\n\nSo its probably some issue with numpy. \n", "It runs for me now. I basically had to uninstall `six, wheel, numpy, scipy, sckit-image, scikit-learn, protobuf` and then re-install them using `pip`\n", "I also have a problem with 0.8.0 nightly (on the other hand, 0.7.1 stable works well) Following @pulkitag, I tried to uninstall the packages and then reinstall them; but segmentation fault still occurs.\n\nWhen I install numpy (1.11) and tensorflow (0.8.0) only, segfault did not occur. However, just after installing `scikit-learn` (0.17.1), segfault started to occur. I am not sure why this happens, but we might need to inspect this situation as well.\n\nUPD: I found that this is under discussion in #2034.\n", "Did you use `pip --upgrade` while re-installing packages? \n", "Can I close this bug as a duplicate of #2034?\n", "I `pip install` tensorflow egg to **Anaconda** python instead of to system python and this bug disappears. May help someone deal with it.\n", "@girving  Yes, its the same as #2034.  \n", "Closing as duplicate of #2034. \n", "I had a similar issue, the first time I tried importing tensorflow I got:\nAttributeError: NewBase is_abstract, ImportError: ...\nAnd starting the second time I got the above mentioned error. What solved the issue for me is to update the version of 'six' as instructed in \nhttps://github.com/tensorflow/tensorflow/issues/1965\n\nCheers\n", "@cruvadom: That sounds like an unrelated issue, since what you describe is not a segfault.  If your issue still occurs with tensorflow at master, please file a separate issue.\n", "`sckit-image` should be `scikit-image` I assume?\n", "@viksit: Sorry for the delay. I did a fresh tensorflow installation on a new computer and the problem remains. I get a segfault if I import Gtk and tensorflow. Cuda version 6 has never been installed on the computer (only Cuda compilation tools release 7.5, V7.5.17 and CUDNN is v 4).\n\nI want to point out that the segfault ONLY occurs when importing both Gtk (ie `import gi; from gi.repository import Gtk`) and tensorflow. I haven't encountered any segfaults related to numpy or scipy (as in #2034 ) or from tensorflow alone.\nEarlier, it worked if I imported tensorflow before Gtk, but now import order also gives a segfault. However, the error is probably different, since doing this outputs some information about a difference between the installed and compiled against version of protobuf. I guess it is irrelevant to the original problem.\n", "@kalleknast That does seem like it could be a similar problem, but please file a separate issue anyway since we're trying to keep the issue tracker organized and this one has already been fixed.  Apologies for the bureaucracy, but keeping issues focused helps us not let fall through the cracks (and not get fixed).\n", "@girving \nThe back trace from core dump from the original segfault (ie importing Gtk before tensorflow):\n\n`[Thread debugging using libthread_db enabled]\nUsing host libthread_db library \"/lib/x86_64-linux-gnu/libthread_db.so.1\".\nCore was generated by`/usr/bin/python3 /usr/local/bin/ipython'.`\nProgram terminated with signal SIGSEGV, Segmentation fault.\n#0  0x00007fdd874a4b2b in tensorflow::kernel_factory::OpKernelRegistrar::InitInternal(tensorflow::KernelDef const*, tensorflow::StringPiece, tensorflow::OpKernel* (*)(tensorflow::OpKernelConstruction*)) () from /usr/local/lib/python3.5/dist-packages/tensorflow/python/_pywrap_tensorflow.so\n[Current thread is 1 (Thread 0x7fddb1d0b700 (LWP 13674))]\n(gdb) \n(gdb) bt\n#0  0x00007fdd874a4b2b in tensorflow::kernel_factory::OpKernelRegistrar::InitInternal(tensorflow::KernelDef const*, tensorflow::StringPiece, tensorflow::OpKernel* (*)(tensorflow::OpKernelConstruction*)) () from /usr/local/lib/python3.5/dist-packages/tensorflow/python/_pywrap_tensorflow.so\n#1  0x00007fdd8655442e in _GLOBAL__sub_I_py_func.cc ()\n   from /usr/local/lib/python3.5/dist-packages/tensorflow/python/_pywrap_tensorflow.so\n#2  0x00007fddb1b194ea in call_init (l=<optimized out>, argc=argc@entry=2, \n    argv=argv@entry=0x7ffc8038a018, env=env@entry=0x122be60) at dl-init.c:72\n#3  0x00007fddb1b195fb in call_init (env=0x122be60, argv=0x7ffc8038a018, argc=2, l=<optimized out>)\n    at dl-init.c:30\n#4  _dl_init (main_map=main_map@entry=0x1471390, argc=2, argv=0x7ffc8038a018, env=0x122be60)\n    at dl-init.c:120\n#5  0x00007fddb1b1e712 in dl_open_worker (a=a@entry=0x7ffc80384650) at dl-open.c:575\n#6  0x00007fddb1b19394 in _dl_catch_error (objname=objname@entry=0x7ffc80384640, \n    errstring=errstring@entry=0x7ffc80384648, mallocedp=mallocedp@entry=0x7ffc8038463f, \n    operate=operate@entry=0x7fddb1b1e300 <dl_open_worker>, args=args@entry=0x7ffc80384650)\n    at dl-error.c:187\n#7  0x00007fddb1b1dbd9 in _dl_open (\n    file=0x7fddac03d7c0 \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/_pywrap_tensorflow.so\", mode=-2147483390, caller_dlopen=0x62735a <_PyImport_FindSharedFuncptr+138>, nsid=-2, \n    argc=<optimized out>, argv=<optimized out>, env=0x122be60) at dl-open.c:660\n#8  0x00007fddb131ff09 in dlopen_doit (a=a@entry=0x7ffc80384880) at dlopen.c:66\n#9  0x00007fddb1b19394 in _dl_catch_error (objname=0xe752f0, errstring=0xe752f8, \n    mallocedp=0xe752e8, operate=0x7fddb131feb0 <dlopen_doit>, args=0x7ffc80384880) at dl-error.c:187\n#10 0x00007fddb1320571 in _dlerror_run (operate=operate@entry=0x7fddb131feb0 <dlopen_doit>, \n    args=args@entry=0x7ffc80384880) at dlerror.c:163\n#11 0x00007fddb131ffa1 in __dlopen (file=<optimized out>, mode=<optimized out>) at dlopen.c:87\n#12 0x000000000062735a in _PyImport_FindSharedFuncptr ()\n#13 0x000000000060473b in _PyImport_LoadDynamicModuleWithSpec ()\n#14 0x0000000000604c78 in ?? ()\n#15 0x00000000004e6513 in PyCFunction_Call ()\n#16 0x00000000005407ef in PyEval_EvalFrameEx ()`\n...\n\nThere is no mentioning of protobuf in this core dump.\n\nHowever, protobuf is mentioned in the core dump from the segfault caused by importing in the reverse order (tensorflow before Gtk). I'll file that as a separate issue.\n"]}, {"number": 1372, "title": "Compilation error: missing dependency declarations ... external/re2/util/rune.cc", "body": "### Environment info\n\nOperating System: CentOS 6.7\n\nIf installed from sources, provide the commit hash: eda89e930cfcbd992ecacafd40267d733e2153dc\n### Steps to reproduce\n1. ./configure (CUDA enabled)\n2. bazel build -c opt --config=cuda --verbose_failures --genrule_strategy=standalone --spawn_strategy=standalone //tensorflow/cc:tutorials_example_trainer\n### What have you tried?\n1. Using --genrule_strategy=standalone --spawn_strategy=standalone as possible solutions from other errors that seem related, but this doesn't work.\n### Logs or other output that would be helpful\n\n```\nWARNING: Output base '/home-4/rdipiet2@jhu.edu/.cache/bazel/_bazel_rdipiet2@jhu.edu/549db212089e33b4d213773753834e47'\n is on NFS. This may lead to surprising failures and undetermined behavior.\nWARNING: Sandboxed execution is not supported on your system and thus hermeticity of actions cannot be guaranteed. Se\ne http://bazel.io/docs/bazel-user-manual.html#sandboxing for more information. You can turn off this warning via --ig\nnore_unsupported_sandboxing.\nINFO: Found 1 target...\nERROR: /home-4/rdipiet2@jhu.edu/.cache/bazel/_bazel_rdipiet2@jhu.edu/549db212089e33b4d213773753834e47/external/re2/BU\nILD:9:1: undeclared inclusion(s) in rule '@re2//:re2':\nthis rule is missing dependency declarations for the following files included by 'external/re2/util/rune.cc':\n  '/cm/shared/apps/gcc/4.8.2/lib/gcc/x86_64-unknown-linux-gnu/4.8.2/include/stdarg.h'\n  '/cm/shared/apps/gcc/4.8.2/lib/gcc/x86_64-unknown-linux-gnu/4.8.2/include/stddef.h'\n  '/cm/shared/apps/gcc/4.8.2/lib/gcc/x86_64-unknown-linux-gnu/4.8.2/include/stdint.h'.\nTarget //tensorflow/cc:tutorials_example_trainer failed to build\nINFO: Elapsed time: 5.291s, Critical Path: 2.47s\n```\n### Other Info\n\nI was able to compile Bazel with older libc, and now I'm hoping I can compile TensorFlow on this server. Any help will be very much appreciated.\n", "comments": ["Are you able to use bazel to compile the re2 library from https://github.com/google/re2 by itself?  If not, you might want to file the issue with either re2 / bazel, since this looks like it's not Tensorflow related from a first glance.\n", "I just cloned google/re2 alone and ran\n\n`bazel build -c opt --config=cuda --verbose_failures --genrule_strategy=standalone --spawn_strategy=standalone :re2`\n\nI get no errors and bazel-bin is populated appropriately.\n", "I just realized that TensorFlow has a similar CROSSTOOL file with the same hard-coded paths as bazel. I'll try updating these in the same way that I did with bazel and see what happens / will update soon.\n", "I got by this error but am still stuck. Will open another issue as it has nothing to do with this one. In case others have this problem:\n\nSee https://github.com/bazelbuild/bazel/issues/760\n\nYou need to edit tensorflow/third_party/gpus/crosstool/CROSSTOOL and make the same gcc / cpp / linker_flag / cxx_builtin_include_directory adjustments.\n"]}, {"number": 1371, "title": "Add check_numerics_op.cc to Android extended operator filegroup.", "body": "The check_numerics_op.cc is needed to load the newer inception model/retrained inception model in the android demo. Refer to the issue #1269 .\n", "comments": ["Can one of the admins verify this patch?\n", "@tensorflow-jenkins: test this please\n", "@tensorflow-jenkins: test this please\n", "Merged\n"]}, {"number": 1370, "title": "MultiRNNCell with different cell sizes", "body": "When I try to create a MultiRNNCell with different number of units in the recurrent cells (e.g. 5-layer RNN with 32-64-32 GRUCells in the hidden layers) I got the following error:\n\n`ValueError: In MultiRNNCell, the input size of each next cell must match the output size of the previous one. Mismatched output size in cell 0.`\n\nIs it currently possible to create a MultiRNNCell with different number of hidden units?\n", "comments": ["It's pretty much what it says: when you construct the cells, every next cell's input must have the same size as the previous cell's output. Unless it's changed recently, BasicLSTMCell makes the input size and the hidden size = output size the same. So it can't be used for what you're trying to do. If you're using that, take a look at LSTMCell instead, where you can specify the sizes separately.\n", "All the cells implemented in `rnn_cell` allow specification of the input size via `input_size`, which by default is set to equal `num_units`. \n", "That wasn't true a short time ago. Just checked. If he's using 0.6.0 or r0.7, then `BasicLSTMCell` doesn't accept input size.\n", "Yes, I'm using TF r0.7 and, as Robert says, you can specify the output size only for the LSTMCell.\n", "@ebrevdo Is this still an issue? \n", "Should be fixed now.\n", "So how is it possible to stack multiple cells with different number of units ?", "The LSTMCell does not seem to have output_size as a valid argument, so how should one stack lstm layers with different sizes ?\r\nhttps://www.tensorflow.org/api_docs/python/tf/contrib/rnn/LSTMCell"]}, {"number": 1369, "title": "Tensorflow issue ", "body": "For bugs/issues, please fill in the following.  The more information you\nprovide, the more likely we can help you.\n### Environment info\n\nOperating System:\nOSx\nIf installed from binary pip package, provide:\npip, Virtualenv\n1. Which pip package you installed.\n2. The output from python -c \"import tensorflow; print(tensorflow.**version**)\".\n0.7.1\nIf installed from sources, provide the commit hash:\n### Steps to reproduce\n\n1.activate the virtualenv\n2.ipython nootebook\n3.\n### What have you tried?\n1. (tensorflow) \u279c  ~  ipython notebook\n### Logs or other output that would be helpful\n\n(If logs are large, please upload as attachment).\n\n[TerminalIPythonApp] WARNING | Subcommand `ipython notebook` is deprecated and will be removed in future versions.\n[TerminalIPythonApp] WARNING | You likely want to use `jupyter notebook`... continue in 5 sec. Press Ctrl-C to quit now.\nTraceback (most recent call last):\n  File \"/Users/maheshwarligade/tensorflow/bin/ipython\", line 9, in <module>\n    load_entry_point('ipython==4.1.1', 'console_scripts', 'ipython')()\n  File \"/Users/maheshwarligade/tensorflow/lib/python3.5/site-packages/ipython-4.1.1-py3.5.egg/IPython/**init**.py\", line 119, in start_ipython\n    return launch_new_instance(argv=argv, *_kwargs)\n  File \"/Users/maheshwarligade/tensorflow/lib/python3.5/site-packages/traitlets-4.1.0-py3.5.egg/traitlets/config/application.py\", line 588, in launch_instance\n    app.initialize(argv)\n  File \"<decorator-gen-111>\", line 2, in initialize\n  File \"/Users/maheshwarligade/tensorflow/lib/python3.5/site-packages/traitlets-4.1.0-py3.5.egg/traitlets/config/application.py\", line 74, in catch_config_error\n    return method(app, *args, *_kwargs)\n  File \"/Users/maheshwarligade/tensorflow/lib/python3.5/site-packages/ipython-4.1.1-py3.5.egg/IPython/terminal/ipapp.py\", line 297, in initialize\n    super(TerminalIPythonApp, self).initialize(argv)\n  File \"<decorator-gen-7>\", line 2, in initialize\n  File \"/Users/maheshwarligade/tensorflow/lib/python3.5/site-packages/traitlets-4.1.0-py3.5.egg/traitlets/config/application.py\", line 74, in catch_config_error\n    return method(app, _args, *_kwargs)\n  File \"/Users/maheshwarligade/tensorflow/lib/python3.5/site-packages/ipython-4.1.1-py3.5.egg/IPython/core/application.py\", line 401, in initialize\n    self.parse_command_line(argv)\n  File \"/Users/maheshwarligade/tensorflow/lib/python3.5/site-packages/ipython-4.1.1-py3.5.egg/IPython/terminal/ipapp.py\", line 292, in parse_command_line\n    return super(TerminalIPythonApp, self).parse_command_line(argv)\n  File \"<decorator-gen-4>\", line 2, in parse_command_line\n  File \"/Users/maheshwarligade/tensorflow/lib/python3.5/site-packages/traitlets-4.1.0-py3.5.egg/traitlets/config/application.py\", line 74, in catch_config_error\n    return method(app, _args, *_kwargs)\n  File \"/Users/maheshwarligade/tensorflow/lib/python3.5/site-packages/traitlets-4.1.0-py3.5.egg/traitlets/config/application.py\", line 485, in parse_command_line\n    return self.initialize_subcommand(subc, subargv)\n  File \"/Users/maheshwarligade/tensorflow/lib/python3.5/site-packages/ipython-4.1.1-py3.5.egg/IPython/core/application.py\", line 211, in initialize_subcommand\n    return super(BaseIPythonApplication, self).initialize_subcommand(subc, argv)\n  File \"<decorator-gen-3>\", line 2, in initialize_subcommand\n  File \"/Users/maheshwarligade/tensorflow/lib/python3.5/site-packages/traitlets-4.1.0-py3.5.egg/traitlets/config/application.py\", line 74, in catch_config_error\n    return method(app, _args, *_kwargs)\n  File \"/Users/maheshwarligade/tensorflow/lib/python3.5/site-packages/traitlets-4.1.0-py3.5.egg/traitlets/config/application.py\", line 416, in initialize_subcommand\n    subapp = import_item(subapp)\n  File \"/Users/maheshwarligade/tensorflow/lib/python3.5/site-packages/ipython_genutils-0.1.0-py3.5.egg/ipython_genutils/importstring.py\", line 31, in import_item\nImportError: No module named 'notebook'\n", "comments": ["This doesn't look like an issue with TensorFlow -- please comment if you disagree.\n", "This is not an issue with tensorflow but encounter when I fallow the udacity deep learning course.\nHow do I resolve that one?\n"]}, {"number": 1368, "title": "svhn: tensorflow/core/common_runtime/executor.cc:1027] 0x2076650 Compute status: Invalid argument: Indices are not valid (out of bounds).  Shape: dim { size: 128 } dim { size: 10 }", "body": "When I tried to train model by SVHN data I faced the above exception.\nStackoverflow link is here: http://stackoverflow.com/questions/35756236/tensorflow-tried-svhn-by-editing-label-0-9-still-not-working\n\nDid I did something wrong/ missed any logic or is it a bug?\nPlease help me. I have already attempted in several ways but could not figure out the reason.\n\nThanks\n", "comments": ["Solved. If interested follow the stackoverflow link.\n", "Thanks, updating tensorflow solved the issue\n"]}, {"number": 1367, "title": "ImportError: No module named core.framework.graph_pb2", "body": "Hello, I am trying to build tensorflow from source without CPU support. When I try to import it in python I am getting the error \"ImportError: No module named core.framework.graph_pb2\".\n\nI have tried this on Arch Linux AND on Ubuntu which gives me the impression I might be doing something wrong. However I am exactly following the instructions on the TF homepage.\n\nI would appreciate any help!!\n#### Environment info\n\nOperating System: Arch Linux\nCommit hash: 263d00d2710779d5c4ac66e335b2ba07d8385b6b\n### Steps to reproduce\n1. ./configure\n2. bazel build -c opt //tensorflow/cc:tutorials_example_trainer\n3. python2\n4. import tensorflow\n### What have you tried?\n1. I made sure I am not in the build directory\n2. I have uninstalled protobuf and reinstalled it\n3. I have reinstalled six\n4. I tried with different versions of protobuf\n5. I tried the same on Ubuntu 15.04 -> getting the same error ()\n### Logs or other output that would be helpful\n\n> > > import tensorflow\n> > > Traceback (most recent call last):\n> > >   File \"<stdin>\", line 1, in <module>\n> > >   File \"/home/.../Development/tensorflow/tensorflow/**init**.py\", line 23, in <module>\n> > >     from tensorflow.python import *\n> > >   File \"/home/.../Development/tensorflow/tensorflow/python/**init**.py\", line 41, in <module>\n> > >     raise ImportError(msg)\n> > > ImportError: Traceback (most recent call last):\n> > >   File \"/home/.../Development/tensorflow/tensorflow/python/**init**.py\", line 35, in <module>\n> > >     from tensorflow.core.framework.graph_pb2 import *\n> > > ImportError: No module named core.framework.graph_pb2\n", "comments": ["The problem was that I did not do the pip install step.\n"]}, {"number": 1366, "title": "Implement the Special Functions incbet,igam,igamc for CPU+GPU for float & double.", "body": "incbet: [incomplete beta integral](http://www.netlib.org/cephes/doubldoc.html#incbet)\nigam: [incomplete gamma integral](http://www.netlib.org/cephes/doubldoc.html#igam)\nigamc: [complemented incomplete gamma integral](http://www.netlib.org/cephes/doubldoc.html#igamc)\n", "comments": ["@ebrevdo Friendly ping to update the status of this bug when you have a chance, thanks!\n", "Will mark as fixed once betainc is in.  Work is ongoing.\n\nOn Mon, Aug 15, 2016 at 4:16 PM, Todd Wang notifications@github.com wrote:\n\n> @ebrevdo https://github.com/ebrevdo Friendly ping to update the status\n> of this bug when you have a chance, thanks!\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/1366#issuecomment-239957329,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/ABtim3mGdoT6qxw8EwCuStxy7ij8iwCdks5qgPNagaJpZM4HoHtj\n> .\n", "@ebrevdo Is this done now?\n", "Yup\n\nOn Oct 12, 2016 6:00 PM, \"Andrew Selle\" notifications@github.com wrote:\n\n> @ebrevdo https://github.com/ebrevdo Is this done now?\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/1366#issuecomment-253381782,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/ABtim1NstWNQoNmb3FzM6Em9WKUD9BLSks5qzYKagaJpZM4HoHtj\n> .\n"]}, {"number": 1365, "title": "histogram_summary does not respect name_scope", "body": "I am getting a Duplicate tag error when I try to write out histogram summaries for a multi-layer network that I generate procedurally. The problem is that the name given to a histogram_summary (and I assume all summaries) does not respect name_scope. As a consequence, the names are not unique. This seems like a bug.\n\nFor example, in:\n\n```\nwith tf.name_scope(some_unique_name):\n  ...\n  _ = tf.histogram_summary('weights', kernel_weights)\n```\n\nI'd assume that 'weights' would be scoped to some_unique_name but I'm suspecting that it is not. I added code to make the names unique and the Duplicate tag problem goes away.\n### Environment info\n\nOperating System: OSX\nTensorFlow version: 0.7.0 \n", "comments": ["I think this is intended behavior, unfortunately.  A typical resolution to this is to pick `kernel_weights` to have a nice name and use\n\n```\n`tf.histogram_summary(kernel_weights.name, kernel_weights)`\n```\n"]}, {"number": 1364, "title": "Fix typos in image_retraining how-to documentation", "body": "", "comments": ["Can one of the admins verify this patch?\n", "Merged\n"]}, {"number": 1363, "title": "Tests in //tensorflow/core/distributed_runtime/... sometimes time out", "body": "Some of the tests in this directory (in particular, `master_test` and `rpc/grpc_session_test`) spawn subprocesses containing TensorFlow servers that listen on unused ports. There is a potential TOCTOU bug in this code because the process is:\n1. Pick unused ports in the parent.\n2. Fork processes and instruct them to bind to the picked ports. (At this point another process can bind the same ports.)\n3. Connect to subprocesses from the parent.\n\nRunning these tests in exclusive mode is a workaround for the problem.\n", "comments": ["Nobody has complained about this for some time, so I'm going to close this bug. Famous last words....\n"]}, {"number": 1362, "title": "matrix_solve_ls_op Compile Error on gcc 4.8 (using typename error)", "body": "I have been trying to compile tensorflow from source without success.\nI could compile version 0.6.0 with no trouble, but trying to compile 0.7.1 produces the following error:\n\n<blockquote>\ntensorflow/core/kernels/matrix_solve_ls_op.cc: In member function 'void tensorflow::MatrixSolveLsOp<Scalar, SupportsBatchOperationT>::ComputeMatrix(tensorflow::OpKernelContext*, const typename tensorflow::BinaryLinearAlgebraOp<Scalar, SupportsBatchOperationT>::ConstMatrixMap&, const typename tensorflow::BinaryLinearAlgebraOp<Scalar, SupportsBatchOperationT>::ConstMatrixMap&, typename tensorflow::BinaryLinearAlgebraOp<Scalar, SupportsBatchOperationT>::MatrixMap*)':\ntensorflow/core/kernels/matrix_solve_ls_op.cc:111:41: error: 'Matrix' is not a class, namespace, or enumeration\n               (Scalar(l2_regularizer) * Matrix::Ones(cols, 1)).asDiagonal();\n                                         ^\ntensorflow/core/kernels/matrix_solve_ls_op.cc:131:41: error: 'Matrix' is not a class, namespace, or enumeration\n               (Scalar(l2_regularizer) * Matrix::Ones(rows, 1)).asDiagonal();\n                                         ^\nIn file included from ./tensorflow/core/framework/op_kernel.h:22:0,\n                 from tensorflow/core/kernels/matrix_solve_ls_op.cc:23:\n./tensorflow/core/framework/allocator.h: In member function 'virtual std::size_t tensorflow::Allocator::RequestedSize(void*)':\n./tensorflow/core/framework/allocator.h:128:3: warning: control reaches end of non-void function [-Wreturn-type]\n   }\n   ^\nIn file included from ./tensorflow/core/framework/op_kernel.h:25:0,\n                 from tensorflow/core/kernels/matrix_solve_ls_op.cc:23:\n./tensorflow/core/framework/device_base.h: In member function 'virtual tensorflow::Allocator* tensorflow::DeviceBase::GetAllocator(tensorflow::AllocatorAttributes)':\n./tensorflow/core/framework/device_base.h:149:3: warning: control reaches end of non-void function [-Wreturn-type]\n   }\n   ^\n./tensorflow/core/framework/device_base.h: In member function 'virtual const tensorflow::DeviceAttributes& tensorflow::DeviceBase::attributes() const':\n./tensorflow/core/framework/device_base.h:179:3: warning: control reaches end of non-void function [-Wreturn-type]\n   }\n   ^\n</blockquote>\n\n\nI tried to find the definition of Matrix::Ones in all folders, but couldn't find anything. In fact \n\n> grep \"Ones\" tensorflow/\\* -R \n\nreturns \n\n<blockquote>\ncore/kernels/matrix_solve_ls_op.cc:              (Scalar(l2_regularizer) * Matrix::Ones(cols, 1)).asDiagonal();\ncore/kernels/matrix_solve_ls_op.cc:              (Scalar(l2_regularizer) * Matrix::Ones(rows, 1)).asDiagonal();\npython/kernel_tests/constant_op_test.py:class OnesTest(tf.test.TestCase):\npython/kernel_tests/constant_op_test.py:  def _Ones(self, shape):\npython/kernel_tests/constant_op_test.py:    self.assertTrue(np.array_equal(self._Ones([2, 3]), np.array([[1] * 3] * 2)))\npython/kernel_tests/constant_op_test.py:class OnesLikeTest(tf.test.TestCase):\npython/kernel_tests/constant_op_test.py:  def testOnesLike(self):\npython/kernel_tests/constant_op_test.py:  def testOnesLikePartialShape(self):\npython/kernel_tests/shape_ops_test.py:  def testSqueezeAllOnes(self):\npython/kernel_tests/shape_ops_test.py:  def testSqueezeOnlyOnes(self):\n</blockquote>\n\n### Environment info\n\nOS : CentOS 6.6, but I have gcc 4.8.2 installed.\n### Steps to reproduce\n\n> ./configure\n\nsay yes to GPU, cuda 7.5, cudnn 4\n\n> bazel build --config=cuda --jobs 6 --verbose_failures --linkopt=\"-lrt\" --linkopt=\"-lm\" --genrule_strategy=standalone --spawn_strategy=standalone -c opt //tensorflow/tools/pip_package:build_pip_package\n", "comments": ["I don't have gcc 4.8 installed, and I think the problem is that gcc 4.8 can't understand the 'using typename' declaration there.\n\nIn https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/matrix_solve_ls_op.cc#L66, can you try changing the\n'using' to just 'typedef' ?\n", "This didn't work for me \u2013 resulted in further errors:\n\n```\n   typedef typename BinaryLinearAlgebraOp<Scalar, SupportsBatchOperationT>::Matrix;\n                                                                            ^\ntensorflow/core/kernels/matrix_solve_ls_op.cc:68:66: error: declaration does not declare anything [-fpermissive]\n                                        SupportsBatchOperationT>::MatrixMap;\n                                                                  ^\ntensorflow/core/kernels/matrix_solve_ls_op.cc:70:66: error: declaration does not declare anything [-fpermissive]\n                                        SupportsBatchOperationT>::ConstMatrixMap;\n```\n\nAny thoughts @vrv ? If more error log would be helpful just let me know. Thanks!\n", "you should do typedef typename BinaryLinear......::Matrix Matrix;\n\n(Need to give it a name)\n", "That's right. The following changes fixed the problem on gcc 4.8.2\n\nreplace \nusing typename BinaryLinearAlgebraOp<Scalar, SupportsBatchOperationT>::Matrix;\nusing typename BinaryLinearAlgebraOp<Scalar,\n                                       SupportsBatchOperationT>::MatrixMap;\nusing typename BinaryLinearAlgebraOp<Scalar,\n                                       SupportsBatchOperationT>::ConstMatrixMap;\n\nwith\n\ntypedef typename BinaryLinearAlgebraOp<Scalar, SupportsBatchOperationT>::Matrix Matrix;\ntypedef typename BinaryLinearAlgebraOp<Scalar,\n                                      SupportsBatchOperationT>::MatrixMap MatrixMap;\ntypedef typename BinaryLinearAlgebraOp<Scalar,\n                                     SupportsBatchOperationT>::ConstMatrixMap ConstMatrixMap;\n", "Let me submit a fix to this\n", "This worked for me too. Thank you for the help.\n"]}, {"number": 1361, "title": "Installation error \"error: identifier \"__shfl_down\" is undefined\"  (Trying with Compute Capability  2.0) ", "body": "I'm trying to install tensor flow from source, as I would like to use GPU's \nthat have compute capability == 2.0. (And I suspect that problems lies here and might be not have a trivial solution)\n### Environment info\n\nOperating System:\nuname -or\n3.16.0-4-amd64 GNU/Linux\nbazel release 0.2.0\n# Commit hash\n\ngit log --pretty=format:'%h' -n 1\n99952d6\ngit log -1 --format=\"%H\"\n99952d68444cd2b08e88af972bd9eb7034fbc1e7\n\nI use TF_UNOFFICIAL_SETTING=1 ./configure \nand  choose Compute Capability  2.0 \n\nbazel build -c opt  --config=cuda  --spawn_strategy=standalone --verbose_failures  //tensorflow/cc:tutorials_example_trainer\n\nFull output here : https://gist.github.com/cbonnett/97aec5a35209f0501993\n\n**What seems to be the key-error:**\nINFO: From Compiling tensorflow/core/kernels/sparse_xent_op_gpu.cu.cc:\nexternal/eigen_archive/eigen-eigen-017cff30cf74/unsupported/Eigen/CXX11/src/Tensor/TensorReductionCuda.h(111): **error: identifier \"__shfl_down\" is undefined**\n\nIt seems \"__shfl_down\" was added in Kepler (compute capability == 3.x )\nhttps://devblogs.nvidia.com/parallelforall/faster-parallel-reductions-kepler/\nand as my cards are pre-Kepler, this seems to be the culprit. Can anybody confirm this ? or might there be a solution ?  \n", "comments": ["Yeah, I don't think TensorFlow's or Eigen's GPU kernels are written for pre 3.0 compute capability :(\n", "I was afraid that was the case.... \n", "Have you found the solution to undefined __shfl_down?\nI am trying to install cunn for lua and I have the same issue:\n\n> error: identifier \"__shfl_down\" is undefined\n\nI am using a GPU with compute capability 2.1 and Ubuntu 16.04\n", "I'm having the same problem.\n\n```\n/tmp/luarocks_cunn-scm-1-7288/cunn/lib/THCUNN/SpatialClassNLLCriterion.cu(16): error: identifier \"__shfl_down\" is undefined\n\n1 error detected in the compilation of \"/tmp/tmpxft_0000402e_00000000-20_SpatialClassNLLCriterion.compute_20.cpp1.ii\".\nCMake Error at THCUNN_generated_SpatialClassNLLCriterion.cu.o.cmake:264 (message):\n  Error generating file\n  /tmp/luarocks_cunn-scm-1-7288/cunn/build/lib/THCUNN/CMakeFiles/THCUNN.dir//./THCUNN_generated_SpatialClassNLLCriterion.cu.o\n\n\nmake[2]: *** [lib/THCUNN/CMakeFiles/THCUNN.dir/./THCUNN_generated_SpatialClassNLLCriterion.cu.o] Error 1\nmake[2]: *** Waiting for unfinished jobs....\nmake[1]: *** [lib/THCUNN/CMakeFiles/THCUNN.dir/all] Error 2\nmake: *** [all] Error 2\n\nError: Build error: Failed building.\n```\n\nAny ideas?\n", "I found a `__shfl_down` replacement here: https://github.com/parallel-forall/code-samples/blob/master/posts/parallel_reduction_with_shfl/fake_shfl.h\n\nThat might help you get around this particular compile issues.\n", "I never looked for a solution, I was lucky enough to find access to some newer cards. \n", "I meet the same problem, @cbonnett did you find a solution?\n", "nope, I got access to newer GPU cards so that solved my problem. Theano should work fine though.  \n", "@zach-capalbo the replace func can compile well ,but is this func produce the same result as the offical one?", "Try to move from cuda 10.1 to cuda 9.1 `sudo apt install nvidia-cuda-toolkit` and `gcc-7` to `gcc-5` . It worked for me after trying all solutions available so far.\r\n"]}]