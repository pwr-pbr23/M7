[{"number": 36528, "title": " the tf c version doesn't work when it contains LSTM block, until replacing LSTM with others. It reply that op doesn't register.  The tf.contrib module don't work. The tensorflow c version is  r1.13.  here is the error information:  Not found: Op type not registered 'LSTMBlockCell' in binary running on t640_m160p36.", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\n**Describe the expected behavior**\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\nPlease, provide minimum standalone code to reproduce the issue in our environment.It helps in localizing the issue faster. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!\r\n", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 36527, "title": "[CI] Ubuntu CPU is still \"Expected \u2014 Waiting for status to be reported\" after 14 days.", "body": "It is strange. Please look at the execution status (**See the red rectangle below)** of the Tensorflow CI on  PR #36186.  The work status of **Ubuntu CPU** and **Ubuntu Sanity** checker are still running. The current status of two checkers is \"**Expected \u2014 Waiting for status to be reported**\" even though 14 days is passed after the contributor submitted PR #36186. Why do not these checkers report the execution result either PASS or FAILURE? As we all know the 14 days are not reasonable to us. And, it will be helpful to the reviewers?\r\n\r\n![image](https://user-images.githubusercontent.com/82404/74004185-65443380-49b8-11ea-986c-58791e241d50.png)\r\n\r\nAbove all, many PRs do not have been getting the test result from the CI checkers in time.  It seems that the TensorFlow community does not have Cloud instances enough to run CI checkers whenever PRs are submitted by the contributors. Or because of the unstable CI system.\r\n", "comments": ["@leemgs \r\nPR has to be approved by the reviewer. Then CI checks will run automatically and PR process will take it forward accordingly.Thanks!", "> PR has to be approved by the reviewer. \r\n> Then CI checks will run automatically and the PR process will take it forward accordingly.\r\n\r\nThank you for the fast reply. In the case of https://github.com/tensorflow/tensorflow/pull/35286 (and https://github.com/tensorflow/tensorflow/pull/33803), although the PR is approved by the reviewer, the CI check is still running for 4 days. What is the **\"import / capybara\"** module waiting for?\r\n\r\n* https://github.com/tensorflow/tensorflow/pull/35286  status:\r\n![image](https://user-images.githubusercontent.com/82404/74026736-1fa05e80-49ea-11ea-8283-647b28f87b8c.png)\r\n\r\n\r\n@ravikyram, I wonder why the CI checks start the execution **after the reviewers approve PRs** finally. Let's assume that a PR of contributor has a build error. Is it meaningful the execution sequence of the existing CI checks to help reviewers?  I think that most of the automatic CI checks have to be successfully run in order to reduce non-productive review activities before reviewers start reviewing PRs. \r\n\r\nAs a case study, let's see the https://github.com/tensorflow/tensorflow/pull/31191 as follows. First of all, a reviewer commented on the PR, then the reviewer approved the PR finally. Then, the CI checks report  4 failure reports.  Although the PR is approved by the reviewer, it seems that the PR cannot be merged due to the failures of the 4 CI checks. As we all know, it means that the reviewers waste their valuable time by reviewing the unstable PRs.\r\n\r\n![image](https://user-images.githubusercontent.com/82404/74027673-f08aec80-49eb-11ea-9f3f-8212daf75b24.png)\r\n\r\n", "Here is another case on (1) the merging time of the PR and (2) the execution time of the CI checks. \r\n\r\n- (1) PR https://github.com/tensorflow/tensorflow/pull/36523: About the merging time\r\n   - When the reviewer **frankchn** of two reviewers approved the PR, The CI checks work. Then, all checks are passed. It seems that the PR is still not merged due to the 1 pending reviewer (**gunan**). In this case, what are the criteria to merge this PR as a final step?\r\n   - Screenshot:\r\n      ![image](https://user-images.githubusercontent.com/82404/74029403-f7b3f980-49ef-11ea-81cc-c57e2673b4e2.png)\r\n\r\n- (2) PR https://github.com/tensorflow/tensorflow/pull/33524 : About the execution cost of CI checks\r\n   - It's weird. When **omalleyt12** approved the PR 33524, the three checks are still keeping the \"Waiting for status ....\" after 2hour. Why do not CI checks start a task? Does the CI system require 2hour+ to check the PR status?\r\n      - Ubuntu CPU Expected \u2014 Waiting for status to be reported  Required\r\n      - Ubuntu Sanity Expected \u2014 Waiting for status to be reported Required\r\n      - import/copybara Expected \u2014 Waiting for status to be reported\r\n   - Screenshot: \r\n      ![image](https://user-images.githubusercontent.com/82404/74030714-1071de80-49f3-11ea-9861-415988076e32.png)\r\n\r\n\r\n", "@leemgs thank for your concern , please post questions regarding tensorflow library. It looks like you haven't used a template to create this issue. Please resubmit your issue using a template from [here](https://github.com/tensorflow/tensorflow/issues/new/choose). Thank you for your cooperation.\r\ncc @mihaimaruseac @chanshah \r\n", "@leemgs There is a long process around accepting PRs. There are costs associated with it, but the costs of not following the process are more harmful to Google.\r\n\r\nFirst, you must keep in mind that CI runs on Google infrastructure and can impact Google in multiple ways. As such, it must not be triggered unless a Googler vouches that the PR is not malicious. This is why no CI except sanity check runs before the first green review.\r\n\r\nSecond, you must keep in mind that there are hundreds of PRs in flight daily and they use CI infrastructure that is also shared by people developing TensorFlow inside Google. So we are looking at high hundreds of CI process running in a day. Add to this the fact that CI needs to take a very long time. This is way CI only runs by default once PR is approved or once the `kokoro:force run` label is applied.\r\n\r\nFinally, even after PR is approved and all CI passes, there are 2 more steps to do: first is to import the change inside Google and integrate it with the Google internal version of TensorFlow (that's what Copybara does). Then this needs another approval and another round of CI run (because sometimes the integration cannot be automated and there is an engineer that does it manually). The import only happens if `ready to pull` tag is automatically applied and that tag is only applied when all reviewers on the PR have approved it.\r\n\r\nThis process is in place for security reasons and also because there are many concerns related to a PR. There are multiple areas that should be analyzed (for example API changes are discussed in API steering meetings, C++ code is analyzed for style guide by one person and for suitability with the rest of the code by another, etc.).\r\n\r\nIf this seems too long, note that we are exporting the [scripts used for these CI checks](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/ci_build/presubmit) and you could attempt to run them manually.\r\n\r\nHope this clarifies the entire process.", ">  Please resubmit your issue using a template from here. Thank you for your cooperation.\r\n\r\n@rthadur, Got it. Since @mihaimarusea already explained Google infrastructure status for CI, The shared scripts for the manual run test in case of long CI checks, and the security reasons for the issue 36527 that is posted by me. So, I will follow up the template that you commented on from the next issue. \r\n\r\n> There are costs associated with it, but the costs of not following the process are more harmful to Google.\r\n\r\n@mihaimaruseac,  Before posting this issue, I thought that Google Tensorflow community already has been used many GCP (Google Cloud Platform) instances enough for massive/popular Tensorflow deep-learning framework because Google has lots of GCP instances as global cloud infrastructure.\r\n\r\n> Finally, even after PR is approved and all CI passes, there are 2 more steps to do: \r\n\r\n@mihaimaruseac, Although this issue is closed by @rthadur 10 hours ago, I want to post my comment on your reply. As we all know, the reviewers must consume their valuable time to approve the malicious/pre-mature/bad/unstable PRs if the reviewers verify and approve the PRs first without the assistance of automated CI facilities.\r\n"]}, {"number": 36526, "title": "Removed NDIMS template arg from BinaryElementWiseOp::Operate", "body": "Fixes #36525 ", "comments": []}, {"number": 36525, "title": "BinaryElementWiseOp::Operate template argument not used and can cause unnecessary errors", "body": "**System information**\r\n- Have I written custom code: yes\r\n- OS Platform and Distribution: macOS 10\r\n- TensorFlow installed from: binary\r\n- TensorFlow version: 2.1\r\n- Python version: 3.7.2\r\n\r\n**Describe the current behavior**\r\n\r\n[`BinaryElementWiseOp`](https://github.com/tensorflow/tensorflow/blob/c7a0fc02f6d1211b7c1c34061fd1b821029e089a/tensorflow/core/framework/numeric_op.h#L67-L109) expects child classes to define an `Operate()` method, which is used in the `Compute()` method to perform the class's operation. This `Operate()` method has an `int` template parameter `NDIMS` which represents the dimension of the inputs and output.\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/c7a0fc02f6d1211b7c1c34061fd1b821029e089a/tensorflow/core/framework/numeric_op.h#L84-L107\r\n\r\nHowever, this template parameter is not used by any `BinaryElementWiseOp` subclass; all subclasses currently call an `OperateNoTemplate()` method from inside `Operate()`. For example, ReLU:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/c7a0fc02f6d1211b7c1c34061fd1b821029e089a/tensorflow/core/kernels/relu_op.h#L66-L79\r\n\r\nThis leads to seemingly unnecessary errors like in the following Python code:\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\nx = tf.reshape(0.0, [1] * 9)  # Too many dimensions for ReluGradOp\r\nx = tf.Variable(x)\r\nwith tf.GradientTape() as tape:\r\n  tape.watch(x)\r\n  y = tf.nn.relu(x)\r\n\r\ntape.gradient(y, x)  # tensorflow.python.framework.errors_impl.InvalidArgumentError: We only handle up to Tensor::dims() up to 8, not 9 [Op:ReluGrad]\r\n```\r\n\r\nThe full list of `BinaryElementWiseOp` subclasses I was able to find is\r\n\r\n* [`ReluGradOp`](https://github.com/tensorflow/tensorflow/blob/c7a0fc02f6d1211b7c1c34061fd1b821029e089a/tensorflow/core/kernels/relu_op.h#L61-L80)\r\n* [`Relu6GradOp`](https://github.com/tensorflow/tensorflow/blob/c7a0fc02f6d1211b7c1c34061fd1b821029e089a/tensorflow/core/kernels/relu_op.h#L104-L122)\r\n* [`LeakyReluGradOp`](https://github.com/tensorflow/tensorflow/blob/c7a0fc02f6d1211b7c1c34061fd1b821029e089a/tensorflow/core/kernels/relu_op.h#L154-L182)\r\n* [`EluGradOp`](https://github.com/tensorflow/tensorflow/blob/c7a0fc02f6d1211b7c1c34061fd1b821029e089a/tensorflow/core/kernels/relu_op.h#L207-L225)\r\n* [`SeluGradOp`](https://github.com/tensorflow/tensorflow/blob/c7a0fc02f6d1211b7c1c34061fd1b821029e089a/tensorflow/core/kernels/relu_op.h#L249-L267)\r\n* [`SoftsignGradOp`](https://github.com/tensorflow/tensorflow/blob/c7a0fc02f6d1211b7c1c34061fd1b821029e089a/tensorflow/core/kernels/softsign_op.cc#L46-L66)\r\n* [`SoftplusGradOp`](https://github.com/tensorflow/tensorflow/blob/c7a0fc02f6d1211b7c1c34061fd1b821029e089a/tensorflow/core/kernels/softplus_op.cc#L46-L66)\r\n* [`FakeQuantWithMinMaxArgsGradientOp`](https://github.com/tensorflow/tensorflow/blob/c7a0fc02f6d1211b7c1c34061fd1b821029e089a/tensorflow/core/kernels/fake_quant_ops.cc#L102-L148)\r\n\r\nAll of them follow the `Operate()` calling `OperateNoTemplate()` pattern. It seems like `BinaryElementWiseOp` and its subclasses can be refactored by removing the `NDIMS` template argument from `Operate()` and moving the contents of each subclass's `OperateNoTemplate()` method into the corresponding `Operate()` method.\r\n", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36525\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36525\">No</a>\n"]}, {"number": 36524, "title": "wide and deep code written fully in tensorflow 2.1 throws tensorflow 1 and 2 incompatability error", "body": "Hi, \r\nI am writing a code in tensorflow 2.1 with feature_columns but it is giving me errors:\r\n\r\nThis is the code snippet:\r\nI am keeping the data in pandas dataframe: df\r\nI am defining the feature columns similar to the code snippet below, containing crossed features, categorical features, numerical features:\r\n\r\n\r\ncat_f1=tf.feature_column.categorical_column_with_vocabulary_list('cat_col_name_1' , df['cat_col_name_1'].unique())\r\n...\r\nnum_fn  = tf.feature_column.numeric_column(\"num_col_name_n\") \r\n\r\nwide_columns = {cat_f1.key: cat_f1,\r\n...\r\n}\r\ndeep_columns = {\r\n...\r\nnum_fn.key: num_fn,\r\n}\r\noutput_feature = ['label']\r\n\r\n\r\n\r\n\r\n\r\nAnd this is how I am defining my input_fn:\r\n\r\ndef input_fn(df,inner_batch_size=-1,shuffle=False):\r\n    input_features=[]\r\n    for key ,_ in wide_columns.items():\r\n        input_features.append(key)\r\n    for key, _ in deep_columns.items():\r\n        if '-crossed' in key:\r\n            k = key.replace('-crossed','')\r\n            keys=[]\r\n            keys = k.split('-')\r\n            for k in keys: \r\n                input_features.append(k)\r\n        else: \r\n            input_features.append(key)\r\n    dataset=tf.data.Dataset.from_tensor_slices((dict(df[input_features]) , df[output_feature].values))\r\n    if shuffle ==True: \r\n        dataset = dataset.shuffle(100).repeat()\r\n    if inner_batch_size>0:\r\n        dataset = dataset.batch(inner_batch_size)    \r\n    return dataset\r\n\r\n\r\n\r\n\r\n\r\n\r\nAnd the definition of estimator: \r\n\r\nmodel_dir = tempfile.mkdtemp()\r\noptimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001)\r\nestimator = tf.estimator.DNNLinearCombinedClassifier(model_dir = model_dir,\r\n                                                linear_feature_columns = wide_columns , \r\n                                                dnn_feature_columns=deep_columns,\r\n                                                dnn_hidden_units = [100,50],\r\n                                                dnn_optimizer = optimizer)\r\n \r\n\r\n\r\n\r\n\r\n\r\n\r\nand after data preparation, calling the train:\r\nestimator.train(input_fn = lambda: input_fn(train_batch_data,inner_batch_size,shuffle=True) ,steps=10)\r\nmetrics = estimator.evaluate(input_fn = lambda: input_fn(val_batch_data,shuffle=False)  , steps = 5)\r\nfor key in sorted(metrics):\r\n    print (\"%s: %s\" % (key, results[key]))\r\n\r\n\r\n\r\n\r\nThis throws the error:\r\n\r\nReceived a feature column from TensorFlow v1, but this is a TensorFlow v2 Estimator. Please either use v2 feature columns (accessible via tf.feature_column.* in TF 2.x) with this Estimator, or switch to a v1 Estimator for use with v1 feature columns (accessible via tf.compat.v1.estimator.* and tf.compat.v1.feature_column.*, respectively.\r\n\r\n\r\nWhat is the problem? ", "comments": ["@shnamin \r\n\r\nCan you please share the simple standalone code with proper indentation and supporting files or colab link to reproduce the issue in our environment. It helps us in localizing the issue faster. Thanks!", "I figured out what the problem was. TF2 requires deep and wide features to be passed as lists (as opposed to dict as is shown in the example), which is a difference between TF2.1 and TF1.X. By passing the list, the error disappears. \r\nThere are no examples in TF2.X for wide and deep, and the examples that I found online are for TF1.X and refer to broken links. This causes confusion, I suggest writing a notebook/example for wide and deep in TF2.1 as it is still a popular approach. \r\n\r\nThanks @ravikyram for the great support anyway.  ", "@shnamin \r\n\r\nGlad to know you found the solution. Please, see the [link](https://medium.com/ml-book/demonstration-of-tensorflow-feature-columns-tf-feature-column-3bfcca4ca5c4) if it helps you. Please,let me know if we can close this issue since it looks to be fixed. Thanks!"]}, {"number": 36523, "title": "Check in generated protobufs for Go", "body": "To make it more idiomatic and easier to install. See #35133 \r\n\r\nGunhan, any objections to doing this? It adds 1.3 MB of generated files to the repo.", "comments": ["Did we not do this internally?\r\nI am confused?", "@jhseu, @frankchn Any update on this PR? Please. Thanks!", "Any update on when this will be merged?", "Why Merging is blocked?", "please please please merge this PR. Every other Go package we use we can just \"go get\". I really don't want to have to have special case code in our build for tensorflow.", "@jhseu, @frankchn Any update on this PR? Please. Thanks!", "There is some issue merging this in where the CL doesn't seem to be able to be merged properly internally. @jhseu might know more", "## How to build tensorflow\r\n1. Get a job at Google\r\n2. ...\r\n3. ...\r\n4. \ud83d\udcb0 ", "We had a discussion with the Go team who discouraged checking this in because other projects had faced issues with conflicts between generated protobufs and the protobuf files generated by bazel. Closing for now.\r\n\r\nUsers should run go generate as mentioned in the [README](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/go/README.md).", "please please please merge this PR. Every other Go package we use we can just \"go get\". I really don't want to have to have special case code in our build for tensorflow.\r\n\r\nNo other package I've ever seen does this."]}, {"number": 36522, "title": "fcn8_tf2/Scripts/SegNet_fab.py:518 segnet  *         dec = segnet_deconv(     fcn8_tf2/Scripts/SegNet_fab.py:278 segnet_deconv  *         dec = Conv2D(     venv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py:817 __call__         self._maybe_build(inputs)     venv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py:2141 _maybe_build         self.build(input_shapes)     venv/lib/python3.6/site-packages/tensorflow_core/python/keras/layers/convolutional.py:153 build         raise ValueError('The channel dimension of the inputs '      ValueError: The channel dimension of the inputs should be defined. Found `None`.", "body": "Hi Everyone, I am trying to implement Segnet in tensorflow 2. \r\nWhen I run the code I get this error:\r\n\r\n**fcn8_tf2/Scripts/SegNet_fab.py:518 segnet  *\r\n        dec = segnet_deconv(\r\n    fcn8_tf2/Scripts/SegNet_fab.py:278 segnet_deconv  *\r\n        dec = Conv2D(\r\n    venv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py:817 __call__\r\n        self._maybe_build(inputs)\r\n    venv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py:2141 _maybe_build\r\n        self.build(input_shapes)\r\n    venv/lib/python3.6/site-packages/tensorflow_core/python/keras/layers/convolutional.py:153 build\r\n        raise ValueError('The channel dimension of the inputs '\r\n\r\n    ValueError: The channel dimension of the inputs should be defined. Found `None`.**\r\n\r\nBelow the scripts.\r\n**train.py**\r\nfrom Segnet_fab import segnet\r\ninputs = Input(shape=(*params['image_size'], params['num_channels']), name='input')\r\noutputs = segnet(inputs, n_labels=2, kernel=3, pool_size=(2, 2), output_mode=None)\r\n\t\t\t # we define our U-Net to output logits\r\nmodel = Model(inputs, outputs)\r\n\r\n**Segnet_fab.py**\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.layers import *\r\nfrom tensorflow.keras import Model\r\nfrom tensorflow.keras import backend as K\r\n\r\ndef MaxUnpooling2D(updates, mask):\r\n\tsize = 2\r\n\tmask = tf.cast(mask, 'int32')\r\n\tinput_shape = tf.shape(updates, out_type='int32')\r\n\r\n\t#  calculation new shape\r\n\toutput_shape = (\r\n\t\t\tinput_shape[0],\r\n\t\t\tinput_shape[1]*size,\r\n\t\t\tinput_shape[2]*size,\r\n\t\t\tinput_shape[3])\r\n\t# calculation indices for batch, height, width and feature maps\r\n\tone_like_mask = tf.ones_like(mask, dtype='int32')\r\n\tbatch_shape = tf.concat(\r\n\t\t\t[[input_shape[0]], [1], [1], [1]],\r\n\t\t\taxis=0)\r\n\tbatch_range = tf.reshape(\r\n\t\t\ttf.range(output_shape[0], dtype='int32'),\r\n\t\t\tshape=batch_shape)\r\n\tb = one_like_mask * batch_range\r\n\ty = mask // (output_shape[2] * output_shape[3])\r\n\tx = (mask // output_shape[3]) % output_shape[2]\r\n\tfeature_range = tf.range(output_shape[3], dtype='int32')\r\n\tf = one_like_mask * feature_range\r\n\tupdates_size = tf.size(updates)\r\n\tindices = K.transpose(K.reshape(\r\n\t\ttf.stack([b, y, x, f]),\r\n\t\t[4, updates_size]))\r\n\tvalues = tf.reshape(updates, [updates_size])\r\n\treturn tf.scatter_nd(indices, values, output_shape)\r\n\r\ndef segnet_conv(\r\n\t\tinputs,\r\n\t\tkernel_size=3,\r\n\t\tkernel_initializer='glorot_uniform',\r\n\t\tbatch_norm = False,\r\n\t\t**kwargs):\r\n################################# block1 #################################\r\n\r\n\tconv1 = Conv2D(\r\n\t\t\tfilters=64,\r\n\t\t\tkernel_size=kernel_size,\r\n\t\t\tpadding='same',\r\n\t\t\tactivation=None,\r\n\t\t\tkernel_initializer=kernel_initializer,\r\n\t\t\tname='conv_1'\r\n\t\t)(inputs)\r\n\t\r\n\tif batch_norm:\r\n\t\tconv1 = BatchNormalization(name='bn_1')(conv1)\r\n\tconv1 = LeakyReLU(alpha=0.3, name='activation_1')(conv1)\r\n\r\n\tconv1 = Conv2D(\r\n\t\t\tfilters=64,\r\n\t\t\tkernel_size=kernel_size,\r\n\t\t\tpadding='same',\r\n\t\t\tactivation=None,\r\n\t\t\tkernel_initializer=kernel_initializer,\r\n\t\t\tname='conv_2'\r\n\t\t)(conv1)\r\n\t\r\n\tif batch_norm:\r\n\t\tconv1 = BatchNormalization(name='bn_2')(conv1)\r\n\tconv1 = LeakyReLU(alpha=0.3, name='activation_2')(conv1)\r\n\r\n\tpool1, mask1 = tf.nn.max_pool_with_argmax(\r\n\t\t\tinput=conv1,\r\n\t\t\tksize=2,\r\n\t\t\tstrides=2,\r\n\t\t\tpadding='SAME'\r\n\t\t)\r\n\t\r\n################################# block2 #################################\r\n\tconv2 = Conv2D(\r\n\t\t\tfilters=128,\r\n\t\t\tkernel_size=kernel_size,\r\n\t\t\tpadding='same',\r\n\t\t\tactivation=None,\r\n\t\t\tkernel_initializer=kernel_initializer,\r\n\t\t\tname='conv_3'\r\n\t\t)(pool1)\r\n\t\r\n\tif batch_norm:\r\n\t\tconv2 = BatchNormalization(name='bn_3')(conv2)\r\n\tconv2 = LeakyReLU(alpha=0.3, name='activation_3')(conv2)\r\n\r\n\tconv2 = Conv2D(\r\n\t\t\tfilters=128,\r\n\t\t\tkernel_size=kernel_size,\r\n\t\t\tpadding='same',\r\n\t\t\tactivation=None,\r\n\t\t\tkernel_initializer=kernel_initializer,\r\n\t\t\tname='conv_4'\r\n\t\t)(conv2)\r\n\t\r\n\tif batch_norm:\r\n\t\tconv2 = BatchNormalization(name='bn_4')(conv2)\r\n\tconv2 = LeakyReLU(alpha=0.3, name='activation_4')(conv2)\r\n\r\n\tpool2, mask2 = tf.nn.max_pool_with_argmax(\r\n\t\t\tinput=conv2,\r\n\t\t\tksize=2,\r\n\t\t\tstrides=2,\r\n\t\t\tpadding='SAME'\r\n\t\t)\r\n\r\n################################# block3 #################################\r\n\tconv3 = Conv2D(\r\n\t\t\tfilters=256,\r\n\t\t\tkernel_size=kernel_size,\r\n\t\t\tpadding='same',\r\n\t\t\tactivation=None,\r\n\t\t\tkernel_initializer=kernel_initializer,\r\n\t\t\tname='conv_5'\r\n\t\t)(pool2)\r\n\t\r\n\tif batch_norm:\r\n\t\tconv3 = BatchNormalization(name='bn_5')(conv3)\r\n\tconv3 = LeakyReLU(alpha=0.3, name='activation_5')(conv3)\r\n\t\r\n\tconv3 = Conv2D(\r\n\t\t\tfilters=256,\r\n\t\t\tkernel_size=kernel_size,\r\n\t\t\tpadding='same',\r\n\t\t\tactivation=None,\r\n\t\t\tkernel_initializer=kernel_initializer,\r\n\t\t\tname='conv_6'\r\n\t\t)(conv3)\r\n\t\r\n\tif batch_norm:\r\n\t\tconv3 = BatchNormalization(name='bn_6')(conv3)\r\n\tconv3 = LeakyReLU(alpha=0.3, name='activation_6')(conv3)\r\n\r\n\tconv3 = Conv2D(\r\n\t\t\tfilters=256,\r\n\t\t\tkernel_size=kernel_size,\r\n\t\t\tpadding='same',\r\n\t\t\tactivation=None,\r\n\t\t\tkernel_initializer=kernel_initializer,\r\n\t\t\tname='conv_7'\r\n\t\t)(conv3)\r\n\t\r\n\tif batch_norm:\r\n\t\tconv3 = BatchNormalization(name='bn_7')(conv3)\r\n\tconv3 = LeakyReLU(alpha=0.3, name='activation_7')(conv3)\r\n\r\n\tpool3, mask3 = tf.nn.max_pool_with_argmax(\r\n\t\t\tinput=conv3,\r\n\t\t\tksize=2,\r\n\t\t\tstrides=2,\r\n\t\t\tpadding='SAME'\r\n\t\t)\r\n\r\n################################# block4 #################################\r\n\tconv4 = Conv2D(\r\n\t\t\tfilters=512,\r\n\t\t\tkernel_size=kernel_size,\r\n\t\t\tpadding='same',\r\n\t\t\tactivation=None,\r\n\t\t\tkernel_initializer=kernel_initializer,\r\n\t\t\tname='conv_8'\r\n\t\t)(pool3)\r\n\t\r\n\tif batch_norm:\r\n\t\tconv4 = BatchNormalization(name='bn_8')(conv4)\r\n\tconv4 = LeakyReLU(alpha=0.3, name='activation_8')(conv4)\r\n\r\n\tconv4 = Conv2D(\r\n\t\t\tfilters=512,\r\n\t\t\tkernel_size=kernel_size,\r\n\t\t\tpadding='same',\r\n\t\t\tactivation=None,\r\n\t\t\tkernel_initializer=kernel_initializer,\r\n\t\t\tname='conv_9'\r\n\t\t)(conv4)\r\n\t\r\n\tif batch_norm:\r\n\t\tconv4 = BatchNormalization(name='bn_9')(conv4)\r\n\tconv4 = LeakyReLU(alpha=0.3, name='activation_9')(conv4)\r\n\r\n\tconv4 = Conv2D(\r\n\t\t\tfilters=512,\r\n\t\t\tkernel_size=kernel_size,\r\n\t\t\tpadding='same',\r\n\t\t\tactivation=None,\r\n\t\t\tkernel_initializer=kernel_initializer,\r\n\t\t\tname='conv_10'\r\n\t\t)(conv4)\r\n\t\r\n\tif batch_norm:\r\n\t\tconv4 = BatchNormalization(name='bn_10')(conv4)\r\n\tconv4 = LeakyReLU(alpha=0.3, name='activation_10')(conv4)\r\n\r\n\tpool4, mask4 = tf.nn.max_pool_with_argmax(\r\n\t\t\tinput=conv4,\r\n\t\t\tksize=2,\r\n\t\t\tstrides=2,\r\n\t\t\tpadding='SAME'\r\n\t\t)\r\n\r\n################################# block5 #################################\r\n\tconv5 = Conv2D(\r\n\t\t\tfilters=512,\r\n\t\t\tkernel_size=kernel_size,\r\n\t\t\tpadding='same',\r\n\t\t\tactivation=None,\r\n\t\t\tkernel_initializer=kernel_initializer,\r\n\t\t\tname='conv_11'\r\n\t\t)(pool4)\r\n\t\r\n\tif batch_norm:\r\n\t\tconv5 = BatchNormalization(name='bn_11')(conv5)\r\n\tconv5 = LeakyReLU(alpha=0.3, name='activation_11')(conv5)\r\n\r\n\tconv5 = Conv2D(\r\n\t\t\tfilters=512,\r\n\t\t\tkernel_size=kernel_size,\r\n\t\t\tpadding='same',\r\n\t\t\tactivation=None,\r\n\t\t\tkernel_initializer=kernel_initializer,\r\n\t\t\tname='conv_12'\r\n\t\t)(conv5)\r\n\t\r\n\tif batch_norm:\r\n\t\tconv5 = BatchNormalization(name='bn_12')(conv5)\r\n\tconv5 = LeakyReLU(alpha=0.3, name='activation_12')(conv5)\r\n\r\n\tconv5 = Conv2D(\r\n\t\t\tfilters=512,\r\n\t\t\tkernel_size=kernel_size,\r\n\t\t\tpadding='same',\r\n\t\t\tactivation=None,\r\n\t\t\tkernel_initializer=kernel_initializer,\r\n\t\t\tname='conv_13'\r\n\t\t)(conv5)\r\n\t\r\n\tif batch_norm:\r\n\t\tconv5 = BatchNormalization(name='bn_13')(conv5)\r\n\tconv5 = LeakyReLU(alpha=0.3, name='activation_13')(conv5)\r\n\r\n\tpool5, mask5 = tf.nn.max_pool_with_argmax(\r\n\t\t\tinput=conv5,\r\n\t\t\tksize=2,\r\n\t\t\tstrides=2,\r\n\t\t\tpadding='SAME'\r\n\t\t)\r\n\r\n\treturn pool5, mask1,mask2,mask3,mask4,mask5\r\n##########################################################################\r\n############################## decod block1 ##############################\r\n##########################################################################\r\n\r\ndef segnet_deconv(\r\n\t\t\tpool5,\r\n\t\t\tmask1,\r\n\t\t\tmask2,\r\n\t\t\tmask3,\r\n\t\t\tmask4,\r\n\t\t\tmask5,\r\n\t\t\tkernel_size=3,\r\n\t\t\tkernel_initializer='glorot_uniform',\r\n\t\t\tbatch_norm = False,\r\n\t\t\t**kwargs\r\n\t\t):\r\n\r\n\tdec = MaxUnpooling2D(pool5, mask5)\r\n\r\n\tdec = Conv2D(\r\n\t\t\tfilters=512,\r\n\t\t\tkernel_size=kernel_size,\r\n\t\t\tpadding='same',\r\n\t\t\tactivation=None,\r\n\t\t\tkernel_initializer=kernel_initializer,\r\n\t\t\tname='upconv_13'\r\n\t\t)(dec)\r\n\r\n\tif batch_norm:\r\n\t\tdec = BatchNormalization(name='upbn_13')(dec)\r\n\tdec = LeakyReLU(alpha=0.3, name='upactivation_13')(dec)\r\n\t\r\n\tdec = Conv2D(\r\n\t\t\tfilters=512,\r\n\t\t\tkernel_size=kernel_size,\r\n\t\t\tpadding='same',\r\n\t\t\tactivation=None,\r\n\t\t\tkernel_initializer=kernel_initializer,\r\n\t\t\tname='upconv_12'\r\n\t\t)(dec)\r\n\r\n\tif batch_norm:\r\n\t\tdec = BatchNormalization(name='upbn_12')(dec)\r\n\tdec = LeakyReLU(alpha=0.3, name='upactivation_12')(dec)\r\n\r\n\tdec = Conv2D(\r\n\t\t\tfilters=512,\r\n\t\t\tkernel_size=kernel_size,\r\n\t\t\tpadding='same',\r\n\t\t\tactivation=None,\r\n\t\t\tkernel_initializer=kernel_initializer,\r\n\t\t\tname='upconv_11'\r\n\t\t)(dec)\r\n\r\n\tif batch_norm:\r\n\t\tdec = BatchNormalization(name='upbn_11')(dec)\r\n\tdec = LeakyReLU(alpha=0.3, name='upactivation_11')(dec)\r\n\r\n############################## decod block2 ##############################\r\n\r\n\tdec = MaxUnpooling2D(dec, mask4)\r\n\t\r\n\tdec = Conv2D(\r\n\t\t\tfilters=512,\r\n\t\t\tkernel_size=kernel_size,\r\n\t\t\tpadding='same',\r\n\t\t\tactivation=None,\r\n\t\t\tkernel_initializer=kernel_initializer,\r\n\t\t\tname='upconv_10'\r\n\t\t)(dec)\r\n\r\n\tif batch_norm:\r\n\t\tdec = BatchNormalization(name='upbn_10')(dec)\r\n\tdec = LeakyReLU(alpha=0.3, name='upactivation_10')(dec)\r\n\t\r\n\tdec = Conv2D(\r\n\t\t\tfilters=512,\r\n\t\t\tkernel_size=kernel_size,\r\n\t\t\tpadding='same',\r\n\t\t\tactivation=None,\r\n\t\t\tkernel_initializer=kernel_initializer,\r\n\t\t\tname='upconv_9'\r\n\t\t)(dec)\r\n\r\n\tif batch_norm:\r\n\t\tdec = BatchNormalization(name='upbn_9')(dec)\r\n\tdec = LeakyReLU(alpha=0.3, name='upactivation_9')(dec)\r\n\r\n\tdec = Conv2D(\r\n\t\t\tfilters=256,\r\n\t\t\tkernel_size=kernel_size,\r\n\t\t\tpadding='same',\r\n\t\t\tactivation=None,\r\n\t\t\tkernel_initializer=kernel_initializer,\r\n\t\t\tname='upconv_8'\r\n\t\t)(dec)\r\n\r\n\tif batch_norm:\r\n\t\tdec = BatchNormalization(name='upbn_8')(dec)\r\n\tdec = LeakyReLU(alpha=0.3, name='upactivation_8')(dec)\r\n\r\n############################## decod block3 ##############################\r\n\r\n\tdec = MaxUnpooling2D(dec, mask3)\r\n\t\r\n\tdec = Conv2D(\r\n\t\t\tfilters=256,\r\n\t\t\tkernel_size=kernel_size,\r\n\t\t\tpadding='same',\r\n\t\t\tactivation=None,\r\n\t\t\tkernel_initializer=kernel_initializer,\r\n\t\t\tname='upconv_7'\r\n\t\t)(dec)\r\n\r\n\tif batch_norm:\r\n\t\tdec = BatchNormalization(name='upbn_7')(dec)\r\n\tdec = LeakyReLU(alpha=0.3, name='upactivation_7')(dec)\r\n\t\r\n\tdec = Conv2D(\r\n\t\t\tfilters=256,\r\n\t\t\tkernel_size=kernel_size,\r\n\t\t\tpadding='same',\r\n\t\t\tactivation=None,\r\n\t\t\tkernel_initializer=kernel_initializer,\r\n\t\t\tname='upconv_6'\r\n\t\t)(dec)\r\n\r\n\tif batch_norm:\r\n\t\tdec = BatchNormalization(name='upbn_6')(dec)\r\n\tdec = LeakyReLU(alpha=0.3, name='upactivation_6')(dec)\r\n\r\n\tdec = Conv2D(\r\n\t\t\tfilters=128,\r\n\t\t\tkernel_size=kernel_size,\r\n\t\t\tpadding='same',\r\n\t\t\tactivation=None,\r\n\t\t\tkernel_initializer=kernel_initializer,\r\n\t\t\tname='upconv_5'\r\n\t\t)(dec)\r\n\r\n\tif batch_norm:\r\n\t\tdec = BatchNormalization(name='upbn_5')(dec)\r\n\tdec = LeakyReLU(alpha=0.3, name='upactivation_5')(dec)\r\n\r\n############################## decod block4 ##############################\r\n\r\n\tdec = MaxUnpooling2D(dec, mask2)\r\n\t\r\n\tdec = Conv2D(\r\n\t\t\tfilters=128,\r\n\t\t\tkernel_size=kernel_size,\r\n\t\t\tpadding='same',\r\n\t\t\tactivation=None,\r\n\t\t\tkernel_initializer=kernel_initializer,\r\n\t\t\tname='upconv_4'\r\n\t\t)(dec)\r\n\r\n\tif batch_norm:\r\n\t\tdec = BatchNormalization(name='upbn_4')(dec)\r\n\tdec = LeakyReLU(alpha=0.3, name='upactivation_4')(dec)\r\n\t\r\n\tdec = Conv2D(\r\n\t\t\tfilters=64,\r\n\t\t\tkernel_size=kernel_size,\r\n\t\t\tpadding='same',\r\n\t\t\tactivation=None,\r\n\t\t\tkernel_initializer=kernel_initializer,\r\n\t\t\tname='upconv_3'\r\n\t\t)(dec)\r\n\r\n\tif batch_norm:\r\n\t\tdec = BatchNormalization(name='upbn_3')(dec)\r\n\tdec = LeakyReLU(alpha=0.3, name='upactivation_3')(dec)\r\n\r\n############################## decod block5 ##############################\r\n\r\n\tdec = MaxUnpooling2D(dec, mask1)\r\n\t\r\n\tdec = Conv2D(\r\n\t\t\tfilters=64,\r\n\t\t\tkernel_size=kernel_size,\r\n\t\t\tpadding='same',\r\n\t\t\tactivation=None,\r\n\t\t\tkernel_initializer=kernel_initializer,\r\n\t\t\tname='upconv_2'\r\n\t\t)(dec)\r\n\r\n\tif batch_norm:\r\n\t\tdec = BatchNormalization(name='upbn_2')(dec)\r\n\tdec = LeakyReLU(alpha=0.3, name='upactivation_2')(dec)\r\n\t\r\n\tdec = Conv2D(\r\n\t\t\tfilters=64,\r\n\t\t\tkernel_size=kernel_size,\r\n\t\t\tpadding='same',\r\n\t\t\tactivation=None,\r\n\t\t\tkernel_initializer=kernel_initializer,\r\n\t\t\tname='upconv_3'\r\n\t\t)(dec)\r\n\r\n\tif batch_norm:\r\n\t\tdec = BatchNormalization(name='upbn_3')(dec)\r\n\tdec = LeakyReLU(alpha=0.3, name='upactivation_3')(dec)\r\n\treturn dec\r\n##########################################################################\r\n############################### classifier ###############################\r\n##########################################################################\r\ndef classifier(\r\n\t\tdec,\r\n\t\tch_out=2,\r\n\t\tkernel_size=3,\r\n\t\tfinal_activation=None,\r\n\t\tbatch_norm = False,\r\n\t\t**kwargs\r\n\t):\r\n\tdec = Conv2D(\r\n\t\t\tfilters=64,\r\n\t\t\tkernel_size=kernel_size,\r\n\t\t\tactivation='relu',\r\n\t\t\tpadding='same',\r\n\t\t\tname='dec_out1'\r\n\t\t)(dec)\r\n\r\n\tdec = Dropout(0.3, name='drop_out1')(dec)\r\n\r\n\tx = Conv2D(\r\n\t\t\tfilters=64,\r\n\t\t\tkernel_size=kernel_size,\r\n\t\t\tactivation='relu',\r\n\t\t\tpadding='same',\r\n\t\t\tname='dec_out2'\r\n\t\t)(dec)\r\n\r\n\tdec = Dropout(0.3, name='drop_out2')(dec)\r\n\tdec = Conv2D(\r\n\t\t\tfilters=ch_out,\r\n\t\t\tkernel_size=1,\r\n\t\t\tactivation=final_activation,\r\n\t\t\tpadding='same',\r\n\t\t\tname='dec_output'\r\n\t\t)(dec)\r\n\treturn dec\r\n@tf.function\r\ndef segnet(\r\n\t\tinputs,\r\n\t\tch_out=2,\r\n\t\tkernel_size=3,\r\n\t\tkernel_initializer='glorot_uniform',\r\n\t\tfinal_activation=None,\r\n\t\tbatch_norm = False,\r\n\t\t**kwargs\r\n\t\t):\r\n\r\n\tpool5, mask1, mask2, mask3, mask4, mask5 = segnet_conv(\r\n\t\t\t\t\t\t\t\tinputs,\r\n\t\t\t\t\t\t\t\tkernel_size=3,\r\n\t\t\t\t\t\t\t\tkernel_initializer='glorot_uniform',\r\n\t\t\t\t\t\t\t\tbatch_norm = False\r\n\t\t\t\t\t\t\t)\r\n\tdec = segnet_deconv(\r\n\t\t\t\tpool5,\r\n\t\t\t\tmask1,\r\n\t\t\t\tmask2,\r\n\t\t\t\tmask3,\r\n\t\t\t\tmask4,\r\n\t\t\t\tmask5,\r\n\t\t\t\tkernel_size=kernel_size,\r\n\t\t\t\tkernel_initializer=kernel_initializer,\r\n\t\t\t\tbatch_norm = batch_norm\r\n\t\t\t)\r\n\r\n\toutput = classifier(\r\n\t\t\t\tdec,\r\n\t\t\t\tch_out=2,\r\n\t\t\t\tkernel_size=3,\r\n\t\t\t\tfinal_activation=None,\r\n\t\t\t\tbatch_norm = batch_norm\r\n\t\t\t)\r\n\treturn output\r\n\r\napparently the function MaxUnpooling2D gives none output.\r\nCan you help me, Please?", "comments": ["In order to expedite the trouble-shooting process, could you please provide the minimal code to reproduce the issue reported here. Thanks!", "`    import tensorflow as tf\r\n    from tensorflow.keras.layers import *\r\n    from tensorflow.keras import Model\r\n    from tensorflow.keras import backend as K\r\n\r\n    #def MaxUnpooling2D(Layer):\r\n    #    def __init__(self, size):\r\n    #        super(MaxUnpooling2D, self).__init__()\r\n    #        self.size = size\r\n\r\n    def MaxUnpooling2D(updates, mask):\r\n        size = 2\r\n        mask = tf.cast(mask, 'int32')\r\n        input_shape = tf.shape(updates, out_type='int32')\r\n\r\n        #  calculation new shape\r\n        output_shape = (\r\n            input_shape[0],\r\n            input_shape[1]*size,\r\n            input_shape[2]*size,\r\n            input_shape[3])\r\n        # calculation indices for batch, height, width and feature maps\r\n        one_like_mask = tf.ones_like(mask, dtype='int32')\r\n        batch_shape = tf.concat(\r\n            [[input_shape[0]], [1], [1], [1]],\r\n            axis=0)\r\n        batch_range = tf.reshape(\r\n            tf.range(output_shape[0], dtype='int32'),\r\n            shape=batch_shape)\r\n        b = one_like_mask * batch_range\r\n        y = mask // (output_shape[2] * output_shape[3])\r\n        x = (mask // output_shape[3]) % output_shape[2]\r\n        feature_range = tf.range(output_shape[3], dtype='int32')\r\n        f = one_like_mask * feature_range\r\n        updates_size = tf.size(updates)\r\n        indices = K.transpose(K.reshape(\r\n        tf.stack([b, y, x, f]),\r\n        [4, updates_size]))\r\n        values = tf.reshape(updates, [updates_size])\r\n        return tf.scatter_nd(indices, values, output_shape)\r\n\r\n    def segnet_conv(\r\n        inputs,\r\n        kernel_size=3,\r\n        kernel_initializer='glorot_uniform',\r\n        batch_norm = False,\r\n        **kwargs):\r\n    ################################# block1 #################################\r\n\r\n        conv1 = Conv2D(\r\n            filters=64,\r\n            kernel_size=kernel_size,\r\n            padding='same',\r\n            activation=None,\r\n            kernel_initializer=kernel_initializer,\r\n            name='conv_1'\r\n        )(inputs)\r\n        \r\n        if batch_norm:\r\n        conv1 = BatchNormalization(name='bn_1')(conv1)\r\n        conv1 = LeakyReLU(alpha=0.3, name='activation_1')(conv1)\r\n\r\n        conv1 = Conv2D(\r\n            filters=64,\r\n            kernel_size=kernel_size,\r\n            padding='same',\r\n            activation=None,\r\n            kernel_initializer=kernel_initializer,\r\n            name='conv_2'\r\n        )(conv1)\r\n        \r\n        if batch_norm:\r\n        conv1 = BatchNormalization(name='bn_2')(conv1)\r\n        conv1 = LeakyReLU(alpha=0.3, name='activation_2')(conv1)\r\n\r\n        pool1, mask1 = tf.nn.max_pool_with_argmax(\r\n            input=conv1,\r\n            ksize=2,\r\n            strides=2,\r\n            padding='SAME'\r\n        )\r\n        \r\n    ################################# block2 #################################\r\n        conv2 = Conv2D(\r\n            filters=128,\r\n            kernel_size=kernel_size,\r\n            padding='same',\r\n            activation=None,\r\n            kernel_initializer=kernel_initializer,\r\n            name='conv_3'\r\n        )(pool1)\r\n        \r\n        if batch_norm:\r\n        conv2 = BatchNormalization(name='bn_3')(conv2)\r\n        conv2 = LeakyReLU(alpha=0.3, name='activation_3')(conv2)\r\n\r\n        conv2 = Conv2D(\r\n            filters=128,\r\n            kernel_size=kernel_size,\r\n            padding='same',\r\n            activation=None,\r\n            kernel_initializer=kernel_initializer,\r\n            name='conv_4'\r\n        )(conv2)\r\n        \r\n        if batch_norm:\r\n        conv2 = BatchNormalization(name='bn_4')(conv2)\r\n        conv2 = LeakyReLU(alpha=0.3, name='activation_4')(conv2)\r\n\r\n        pool2, mask2 = tf.nn.max_pool_with_argmax(\r\n            input=conv2,\r\n            ksize=2,\r\n            strides=2,\r\n            padding='SAME'\r\n        )\r\n\r\n    ################################# block3 #################################\r\n        conv3 = Conv2D(\r\n            filters=256,\r\n            kernel_size=kernel_size,\r\n            padding='same',\r\n            activation=None,\r\n            kernel_initializer=kernel_initializer,\r\n            name='conv_5'\r\n        )(pool2)\r\n        \r\n        if batch_norm:\r\n        conv3 = BatchNormalization(name='bn_5')(conv3)\r\n        conv3 = LeakyReLU(alpha=0.3, name='activation_5')(conv3)\r\n        \r\n        conv3 = Conv2D(\r\n            filters=256,\r\n            kernel_size=kernel_size,\r\n            padding='same',\r\n            activation=None,\r\n            kernel_initializer=kernel_initializer,\r\n            name='conv_6'\r\n        )(conv3)\r\n        \r\n        if batch_norm:\r\n        conv3 = BatchNormalization(name='bn_6')(conv3)\r\n        conv3 = LeakyReLU(alpha=0.3, name='activation_6')(conv3)\r\n\r\n        conv3 = Conv2D(\r\n            filters=256,\r\n            kernel_size=kernel_size,\r\n            padding='same',\r\n            activation=None,\r\n            kernel_initializer=kernel_initializer,\r\n            name='conv_7'\r\n        )(conv3)\r\n        \r\n        if batch_norm:\r\n        conv3 = BatchNormalization(name='bn_7')(conv3)\r\n        conv3 = LeakyReLU(alpha=0.3, name='activation_7')(conv3)\r\n\r\n        pool3, mask3 = tf.nn.max_pool_with_argmax(\r\n            input=conv3,\r\n            ksize=2,\r\n            strides=2,\r\n            padding='SAME'\r\n        )\r\n\r\n    ################################# block4 #################################\r\n        conv4 = Conv2D(\r\n            filters=512,\r\n            kernel_size=kernel_size,\r\n            padding='same',\r\n            activation=None,\r\n            kernel_initializer=kernel_initializer,\r\n            name='conv_8'\r\n        )(pool3)\r\n        \r\n        if batch_norm:\r\n        conv4 = BatchNormalization(name='bn_8')(conv4)\r\n        conv4 = LeakyReLU(alpha=0.3, name='activation_8')(conv4)\r\n\r\n        conv4 = Conv2D(\r\n            filters=512,\r\n            kernel_size=kernel_size,\r\n            padding='same',\r\n            activation=None,\r\n            kernel_initializer=kernel_initializer,\r\n            name='conv_9'\r\n        )(conv4)\r\n        \r\n        if batch_norm:\r\n        conv4 = BatchNormalization(name='bn_9')(conv4)\r\n        conv4 = LeakyReLU(alpha=0.3, name='activation_9')(conv4)\r\n\r\n        conv4 = Conv2D(\r\n            filters=512,\r\n            kernel_size=kernel_size,\r\n            padding='same',\r\n            activation=None,\r\n            kernel_initializer=kernel_initializer,\r\n            name='conv_10'\r\n        )(conv4)\r\n        \r\n        if batch_norm:\r\n        conv4 = BatchNormalization(name='bn_10')(conv4)\r\n        conv4 = LeakyReLU(alpha=0.3, name='activation_10')(conv4)\r\n\r\n        pool4, mask4 = tf.nn.max_pool_with_argmax(\r\n            input=conv4,\r\n            ksize=2,\r\n            strides=2,\r\n            padding='SAME'\r\n        )\r\n\r\n    ################################# block5 #################################\r\n        conv5 = Conv2D(\r\n            filters=512,\r\n            kernel_size=kernel_size,\r\n            padding='same',\r\n            activation=None,\r\n            kernel_initializer=kernel_initializer,\r\n            name='conv_11'\r\n        )(pool4)\r\n        \r\n        if batch_norm:\r\n        conv5 = BatchNormalization(name='bn_11')(conv5)\r\n        conv5 = LeakyReLU(alpha=0.3, name='activation_11')(conv5)\r\n\r\n        conv5 = Conv2D(\r\n            filters=512,\r\n            kernel_size=kernel_size,\r\n            padding='same',\r\n            activation=None,\r\n            kernel_initializer=kernel_initializer,\r\n            name='conv_12'\r\n        )(conv5)\r\n        \r\n        if batch_norm:\r\n        conv5 = BatchNormalization(name='bn_12')(conv5)\r\n        conv5 = LeakyReLU(alpha=0.3, name='activation_12')(conv5)\r\n\r\n        conv5 = Conv2D(\r\n            filters=512,\r\n            kernel_size=kernel_size,\r\n            padding='same',\r\n            activation=None,\r\n            kernel_initializer=kernel_initializer,\r\n            name='conv_13'\r\n        )(conv5)\r\n        \r\n        if batch_norm:\r\n        conv5 = BatchNormalization(name='bn_13')(conv5)\r\n        conv5 = LeakyReLU(alpha=0.3, name='activation_13')(conv5)\r\n\r\n        pool5, mask5 = tf.nn.max_pool_with_argmax(\r\n            input=conv5,\r\n            ksize=2,\r\n            strides=2,\r\n            padding='SAME'\r\n        )\r\n\r\n        return pool5, mask1,mask2,mask3,mask4,mask5\r\n    ##########################################################################\r\n    ############################## decod block1 ##############################\r\n    ##########################################################################\r\n\r\n    def segnet_deconv(\r\n            pool5,\r\n            mask1,\r\n            mask2,\r\n            mask3,\r\n            mask4,\r\n            mask5,\r\n            kernel_size=3,\r\n            kernel_initializer='glorot_uniform',\r\n            batch_norm = False,\r\n            **kwargs\r\n        ):\r\n\r\n        dec = MaxUnpooling2D(pool5, mask5)\r\n\r\n        dec = Conv2D(\r\n            filters=512,\r\n            kernel_size=kernel_size,\r\n            padding='same',\r\n            activation=None,\r\n            kernel_initializer=kernel_initializer,\r\n            name='upconv_13'\r\n        )(dec)\r\n\r\n        if batch_norm:\r\n        dec = BatchNormalization(name='upbn_13')(dec)\r\n        dec = LeakyReLU(alpha=0.3, name='upactivation_13')(dec)\r\n        \r\n        dec = Conv2D(\r\n            filters=512,\r\n            kernel_size=kernel_size,\r\n            padding='same',\r\n            activation=None,\r\n            kernel_initializer=kernel_initializer,\r\n            name='upconv_12'\r\n        )(dec)\r\n\r\n        if batch_norm:\r\n        dec = BatchNormalization(name='upbn_12')(dec)\r\n        dec = LeakyReLU(alpha=0.3, name='upactivation_12')(dec)\r\n\r\n        dec = Conv2D(\r\n            filters=512,\r\n            kernel_size=kernel_size,\r\n            padding='same',\r\n            activation=None,\r\n            kernel_initializer=kernel_initializer,\r\n            name='upconv_11'\r\n        )(dec)\r\n\r\n        if batch_norm:\r\n        dec = BatchNormalization(name='upbn_11')(dec)\r\n        dec = LeakyReLU(alpha=0.3, name='upactivation_11')(dec)\r\n\r\n    ############################## decod block2 ##############################\r\n\r\n        dec = MaxUnpooling2D(dec, mask4)\r\n        \r\n        dec = Conv2D(\r\n            filters=512,\r\n            kernel_size=kernel_size,\r\n            padding='same',\r\n            activation=None,\r\n            kernel_initializer=kernel_initializer,\r\n            name='upconv_10'\r\n        )(dec)\r\n\r\n        if batch_norm:\r\n        dec = BatchNormalization(name='upbn_10')(dec)\r\n        dec = LeakyReLU(alpha=0.3, name='upactivation_10')(dec)\r\n        \r\n        dec = Conv2D(\r\n            filters=512,\r\n            kernel_size=kernel_size,\r\n            padding='same',\r\n            activation=None,\r\n            kernel_initializer=kernel_initializer,\r\n            name='upconv_9'\r\n        )(dec)\r\n\r\n        if batch_norm:\r\n        dec = BatchNormalization(name='upbn_9')(dec)\r\n        dec = LeakyReLU(alpha=0.3, name='upactivation_9')(dec)\r\n\r\n        dec = Conv2D(\r\n            filters=256,\r\n            kernel_size=kernel_size,\r\n            padding='same',\r\n            activation=None,\r\n            kernel_initializer=kernel_initializer,\r\n            name='upconv_8'\r\n        )(dec)\r\n\r\n        if batch_norm:\r\n        dec = BatchNormalization(name='upbn_8')(dec)\r\n        dec = LeakyReLU(alpha=0.3, name='upactivation_8')(dec)\r\n\r\n    ############################## decod block3 ##############################\r\n\r\n        dec = MaxUnpooling2D(dec, mask3)\r\n        \r\n        dec = Conv2D(\r\n            filters=256,\r\n            kernel_size=kernel_size,\r\n            padding='same',\r\n            activation=None,\r\n            kernel_initializer=kernel_initializer,\r\n            name='upconv_7'\r\n        )(dec)\r\n\r\n        if batch_norm:\r\n        dec = BatchNormalization(name='upbn_7')(dec)\r\n        dec = LeakyReLU(alpha=0.3, name='upactivation_7')(dec)\r\n        \r\n        dec = Conv2D(\r\n            filters=256,\r\n            kernel_size=kernel_size,\r\n            padding='same',\r\n            activation=None,\r\n            kernel_initializer=kernel_initializer,\r\n            name='upconv_6'\r\n        )(dec)\r\n\r\n        if batch_norm:\r\n        dec = BatchNormalization(name='upbn_6')(dec)\r\n        dec = LeakyReLU(alpha=0.3, name='upactivation_6')(dec)\r\n\r\n        dec = Conv2D(\r\n            filters=128,\r\n            kernel_size=kernel_size,\r\n            padding='same',\r\n            activation=None,\r\n            kernel_initializer=kernel_initializer,\r\n            name='upconv_5'\r\n        )(dec)\r\n\r\n        if batch_norm:\r\n        dec = BatchNormalization(name='upbn_5')(dec)\r\n        dec = LeakyReLU(alpha=0.3, name='upactivation_5')(dec)\r\n\r\n    ############################## decod block4 ##############################\r\n\r\n        dec = MaxUnpooling2D(dec, mask2)\r\n        \r\n        dec = Conv2D(\r\n            filters=128,\r\n            kernel_size=kernel_size,\r\n            padding='same',\r\n            activation=None,\r\n            kernel_initializer=kernel_initializer,\r\n            name='upconv_4'\r\n        )(dec)\r\n\r\n        if batch_norm:\r\n        dec = BatchNormalization(name='upbn_4')(dec)\r\n        dec = LeakyReLU(alpha=0.3, name='upactivation_4')(dec)\r\n        \r\n        dec = Conv2D(\r\n            filters=64,\r\n            kernel_size=kernel_size,\r\n            padding='same',\r\n            activation=None,\r\n            kernel_initializer=kernel_initializer,\r\n            name='upconv_3'\r\n        )(dec)\r\n\r\n        if batch_norm:\r\n        dec = BatchNormalization(name='upbn_3')(dec)\r\n        dec = LeakyReLU(alpha=0.3, name='upactivation_3')(dec)\r\n\r\n    ############################## decod block5 ##############################\r\n\r\n        dec = MaxUnpooling2D(dec, mask1)\r\n        \r\n        dec = Conv2D(\r\n            filters=64,\r\n            kernel_size=kernel_size,\r\n            padding='same',\r\n            activation=None,\r\n            kernel_initializer=kernel_initializer,\r\n            name='upconv_2'\r\n        )(dec)\r\n\r\n        if batch_norm:\r\n        dec = BatchNormalization(name='upbn_2')(dec)\r\n        dec = LeakyReLU(alpha=0.3, name='upactivation_2')(dec)\r\n        \r\n        dec = Conv2D(\r\n            filters=64,\r\n            kernel_size=kernel_size,\r\n            padding='same',\r\n            activation=None,\r\n            kernel_initializer=kernel_initializer,\r\n            name='upconv_3'\r\n        )(dec)\r\n\r\n        if batch_norm:\r\n        dec = BatchNormalization(name='upbn_3')(dec)\r\n        dec = LeakyReLU(alpha=0.3, name='upactivation_3')(dec)\r\n        return dec\r\n    ##########################################################################\r\n    ############################### classifier ###############################\r\n    ##########################################################################\r\n    def classifier(\r\n        dec,\r\n        ch_out=2,\r\n        kernel_size=3,\r\n        final_activation=None,\r\n        batch_norm = False,\r\n        **kwargs\r\n        ):\r\n        dec = Conv2D(\r\n            filters=64,\r\n            kernel_size=kernel_size,\r\n            activation='relu',\r\n            padding='same',\r\n            name='dec_out1'\r\n        )(dec)\r\n\r\n        dec = Dropout(0.3, name='drop_out1')(dec)\r\n\r\n        x = Conv2D(\r\n            filters=64,\r\n            kernel_size=kernel_size,\r\n            activation='relu',\r\n            padding='same',\r\n            name='dec_out2'\r\n        )(dec)\r\n\r\n        dec = Dropout(0.3, name='drop_out2')(dec)\r\n        dec = Conv2D(\r\n            filters=ch_out,\r\n            kernel_size=1,\r\n            activation=final_activation,\r\n            padding='same',\r\n            name='dec_output'\r\n        )(dec)\r\n        return dec\r\n    @tf.function\r\n    def segnet(\r\n        inputs,\r\n        ch_out=2,\r\n        kernel_size=3,\r\n        kernel_initializer='glorot_uniform',\r\n        final_activation=None,\r\n        batch_norm = False,\r\n        **kwargs\r\n        ):\r\n\r\n        pool5, mask1, mask2, mask3, mask4, mask5 = segnet_conv(\r\n                                inputs,\r\n                                kernel_size=3,\r\n                                kernel_initializer='glorot_uniform',\r\n                                batch_norm = False\r\n                            )\r\n        dec = segnet_deconv(\r\n                pool5,\r\n                mask1,\r\n                mask2,\r\n                mask3,\r\n                mask4,\r\n                mask5,\r\n                kernel_size=kernel_size,\r\n                kernel_initializer=kernel_initializer,\r\n                batch_norm = batch_norm\r\n            )\r\n\r\n        output = classifier(\r\n                dec,\r\n                ch_out=2,\r\n                kernel_size=3,\r\n                final_activation=None,\r\n                batch_norm = batch_norm\r\n            )\r\n        return output\r\n    inputs = Input(shape=(*params['image_size'], params['num_channels']), name='input')\r\n    outputs = segnet(\r\n\t\t\t\tinputs,\r\n\t\t\t\tch_out=2,\r\n\t\t\t\tkernel_size=3,\r\n\t\t\t\tkernel_initializer='glorot_uniform',\r\n\t\t\t\tfinal_activation=None, # we define our U-Net to output logits\r\n\t\t\t\tbatch_norm = False,\r\n\t\t\t)\r\n    model = Model(inputs, outputs)`", "@ucesfpa,\r\nI am facing an error stating `NameError: name 'params' is not defined` while running the code. You can check the Gist of it [here](https://colab.sandbox.google.com/gist/amahendrakar/b8b3e0ce48c7bdfbd589c4207f62c1fa/36522.ipynb).\r\n\r\nCould you please provide a minimal sample code with all the variables used in the code? \r\n\r\nAlternatively, you can also run the code on Google Colab from [this](https://colab.sandbox.google.com/notebook#create=true&language=python3) link and share the Gist with us. Go to \"File\" -> \"Save a copy as a Github Gist\" and share the link of the new window with us. Thanks!", "` import tensorflow as tf\r\nfrom tensorflow.keras.layers import *\r\nfrom tensorflow.keras import Model\r\nfrom tensorflow.keras import backend as K\r\n\r\ndef parse_function(filenames, resize_to=[226, 226], augment=True):\r\n\t\"\"\"\r\n\tParse files into input/label image pair.\r\n\t:param filenames:   Dict containing the file(s) (filenames['image'], filenames['label'])\r\n\t:param resize_to:   H x W Dimensions to resize the image and label to\r\n\t:param augment:\t Flag to augment the pair\r\n\t:return:\t\t\tInput tensor, Label tensor\r\n\t\"\"\"\r\n\r\n\timg_filename, gt_filename = filenames['image'], filenames.get('label', None)\r\n\r\n\t# Reading the file and returning its content as bytes:\r\n\timage_string = tf.io.read_file(img_filename)\r\n\t# Decoding into an image:\r\n\timage_decoded = tf.io.decode_jpeg(image_string, channels=3)\r\n\r\n\t# Converting image to float:\r\n\timage = tf.image.convert_image_dtype(image_decoded, tf.float32)\r\n\r\n\t# Resizing:\r\n\timage = tf.image.resize(image, resize_to)\r\n\r\n\tif gt_filename is not None:\r\n\t\t# Same for GT image:\r\n\t\tgt_string = tf.io.read_file(gt_filename)\r\n\t\tgt_decoded = tf.io.decode_png(gt_string, channels=1)\r\n\t\tgt = tf.cast(gt_decoded, dtype=tf.int32)\r\n\t\tgt = tf.image.resize(gt, resize_to, method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\r\n\t\t\r\n\t\t# Opt. augmenting the image:\r\n\t\tif augment:\r\n\t\t\timage, gt = _augmentation_fn(image, gt)\r\n\t\treturn image, gt\r\n\telse:\r\n\t\tif augment:\r\n\t\t\timage = _augmentation_fn(image)\r\n\t\treturn image\r\n\r\n\r\n\r\ndef segmentation_input_fn(image_files, gt_files=None, resize_to=[256, 256],\r\n\t\t\t\t\t\t  shuffle=False, batch_size=32, augment=False,\r\n\t\t\t\t\t\t  seed=None):\r\n\t\"\"\"\r\n\tSet up an input data pipeline for semantic segmentation applications.\r\n\t:param image_files:\t List of input image files\r\n\t:param gt_files:\t\t(opt.) List of corresponding label image files\r\n\t:param resize_to:\t   H x W Dimensions to resize the image and label to\r\n\t:param shuffle:\t\t Flag to shuffle the dataset\r\n\t:param batch_size:\t  Batch size\r\n\t:param augment:\t\t Flag to augment the pairs\r\n\t:param seed:\t\t\t(opt) Seed\r\n\t:return:\t\t\t\ttf.data.Dataset\r\n\t\"\"\"\r\n\t# Converting to TF dataset:\r\n\timage_files = tf.constant(image_files)\r\n\tdata_dict = {'image': image_files}\r\n\tif gt_files is not None:\r\n\t\tgt_files = tf.constant(gt_files)\r\n\t\tdata_dict['label'] = gt_files\r\n\tdataset = tf.data.Dataset.from_tensor_slices(data_dict)\r\n\r\n\tif shuffle:\r\n\t\tdataset = dataset.shuffle(buffer_size=1000, seed=seed)\r\n\tdataset = dataset.prefetch(1)\r\n\r\n\t# Batching + adding parsing operation:\r\n\tparse_fn = functools.partial(parse_function, resize_to=resize_to, augment=augment)\r\n\tdataset = dataset.map(parse_fn, num_parallel_calls=4)\r\n\tdataset = dataset.batch(batch_size)\r\n\r\n\tdataset = dataset.repeat()\r\n\treturn dataset\r\n\r\n\r\ndef dice_loss(y_true, y_pred, ignore_value=None,\r\n\t\t\t  eps=1e-6, spatial_axes=[1, 2], from_logits=True):\r\n\t\"\"\"\r\n\tCompute the Dice loss for semantic segmentation, ignoring pixels from some misc. classes.\r\n\t:param y_true:\t\tGround-truth label map(s) (e.g., of shape B x H x W)\r\n\t:param y_pred:\t\tPredicted logit map(s) () (e.g., of shape B x H x W x N, N number of classes)\r\n\t:param ignore_value:  trainID value of ignored classes (`None` if ignored none) \r\n\t:param eps:\t\t   Epsilon small value (smooth) \r\n\t:param spatial_axes:  Spatial axes\r\n\t:param from_logits:   Flag if predictions are logits (not normalized)\r\n\t:return:\t\t\t  Loss value\r\n\t\"\"\"\r\n\tnum_classes = y_pred.shape[-1]\r\n\t\t\r\n\t# (opt.) Build mask to remove pixels from ignored classes:\r\n\t# if ignore_value is not None:\r\n\t#\t y_true, y_pred = prepare_data_for_segmentation_loss(\r\n\t#\t\t y_true, y_pred, num_classes=num_classes, ignore_value=ignore_value)\r\n\r\n\t# Transform logits in probabilities, and one-hot the ground-truth:\r\n\tif from_logits:\r\n\t\ty_pred = tf.nn.softmax(y_pred, axis=-1)\r\n\ty_true = tf.squeeze(tf.cast(y_true, tf.int32), axis=-1)\r\n\ty_true_onehot  = tf.one_hot(y_true, num_classes, dtype=y_pred.dtype)\r\n\r\n\t# (opt.) Build mask to remove pixels from ignored classes:\r\n\t\r\n\r\n\t# Compute Dice numerator and denominator:\r\n\tnum_perclass = 2 * tf.reduce_sum(y_pred * y_true_onehot, axis=spatial_axes)\r\n\tden_perclass = tf.reduce_sum(y_pred + y_true_onehot, axis=spatial_axes)\r\n\r\n\t# Compute Dice and average over batch and classes:\r\n\tdice = tf.reduce_mean((num_perclass + eps) / (den_perclass + eps))\r\n\r\n\treturn 1 - dice\r\n\r\n\r\ndef train_step(optimizer, model, metrics, train_images, train_labels):\r\n\twith tf.GradientTape() as tape:\r\n\r\n\t\tpred = model(train_images, training=True)\r\n\r\n\t\tloss = dice_loss(train_labels,pred)\r\n\r\n\t\ttrain_iou = tf.keras.metrics.MeanIoU(num_classes=2)\r\n\t\ttrain_iou.update_state(train_labels, tf.argmax(tf.nn.softmax(pred,axis=-1),axis=-1))\r\n\r\n\r\n\t\taccuracy = tf.keras.metrics.Accuracy() \r\n\t\taccuracy.update_state(train_labels, tf.argmax(tf.nn.softmax(pred,axis=-1),axis=-1))\r\n\r\n\t\tprecision = tf.keras.metrics.Precision()\r\n\t\tprecision.update_state(tf.squeeze(train_labels,axis=-1), tf.argmax(tf.nn.softmax(pred,axis=-1),axis=-1))\r\n\r\n\t\trecall = tf.keras.metrics.Recall()\r\n\t\trecall.update_state(tf.squeeze(train_labels,axis=-1), tf.argmax(tf.nn.softmax(pred,axis=-1),axis=-1))\r\n\r\n\r\n\tgradients = tape.gradient(loss, model.trainable_variables)\r\n\toptimizer.apply_gradients(zip(gradients, model.trainable_variables))\r\n\tmetrics[0].update_state([loss])\r\n\tmetrics[1].update_state([train_iou.result()])\r\n\tmetrics[2].update_state([precision.result()])\r\n\tmetrics[3].update_state([recall.result()])\r\n\tmetrics[4].update_state([accuracy.result()])\r\n\treturn metrics, pred, gradients\r\n\r\ndef validation_step(model, metrics, train_images, train_labels):\r\n\tpred = model(train_images)\r\n\tloss = dice_loss(train_labels, pred)\r\n\r\n\ttrain_iou = tf.keras.metrics.MeanIoU(num_classes=2)\r\n\ttrain_iou.update_state(train_labels, tf.argmax(tf.nn.softmax(pred,axis=-1),axis=-1))\r\n\r\n\taccuracy = tf.keras.metrics.Accuracy()\r\n\taccuracy.update_state(train_labels, tf.argmax(tf.nn.softmax(pred,axis=-1),axis=-1))\r\n\r\n\tprecision = tf.keras.metrics.Precision()\r\n\tprecision.update_state(tf.squeeze(train_labels,axis=-1), tf.argmax(tf.nn.softmax(pred,axis=-1),axis=-1))\r\n\r\n\trecall = tf.keras.metrics.Recall()\r\n\trecall.update_state(tf.squeeze(train_labels,axis=-1), tf.argmax(tf.nn.softmax(pred,axis=-1),axis=-1))\r\n\r\n\tmetrics[0].update_state([loss])\r\n\tmetrics[1].update_state([train_iou.result()])\r\n\tmetrics[2].update_state([precision.result()])\r\n\tmetrics[3].update_state([recall.result()])\r\n\tmetrics[4].update_state([accuracy.result()])\r\n\r\n\treturn metrics, tf.argmax(tf.nn.softmax(pred,axis=-1),axis=-1)\r\n\r\n#def MaxUnpooling2D(Layer):\r\n#    def __init__(self, size):\r\n#        super(MaxUnpooling2D, self).__init__()\r\n#        self.size = size\r\n\r\ndef MaxUnpooling2D(updates, mask):\r\n    size = 2\r\n    mask = tf.cast(mask, 'int32')\r\n    input_shape = tf.shape(updates, out_type='int32')\r\n\r\n    #  calculation new shape\r\n    output_shape = (\r\n        input_shape[0],\r\n        input_shape[1]*size,\r\n        input_shape[2]*size,\r\n        input_shape[3])\r\n    # calculation indices for batch, height, width and feature maps\r\n    one_like_mask = tf.ones_like(mask, dtype='int32')\r\n    batch_shape = tf.concat(\r\n        [[input_shape[0]], [1], [1], [1]],\r\n        axis=0)\r\n    batch_range = tf.reshape(\r\n        tf.range(output_shape[0], dtype='int32'),\r\n        shape=batch_shape)\r\n    b = one_like_mask * batch_range\r\n    y = mask // (output_shape[2] * output_shape[3])\r\n    x = (mask // output_shape[3]) % output_shape[2]\r\n    feature_range = tf.range(output_shape[3], dtype='int32')\r\n    f = one_like_mask * feature_range\r\n    updates_size = tf.size(updates)\r\n    indices = K.transpose(K.reshape(\r\n    tf.stack([b, y, x, f]),\r\n    [4, updates_size]))\r\n    values = tf.reshape(updates, [updates_size])\r\n    return tf.scatter_nd(indices, values, output_shape)\r\n\r\ndef segnet_conv(\r\n    inputs,\r\n    kernel_size=3,\r\n    kernel_initializer='glorot_uniform',\r\n    batch_norm = False,\r\n    **kwargs):\r\n################################# block1 #################################\r\n\r\n    conv1 = Conv2D(\r\n        filters=64,\r\n        kernel_size=kernel_size,\r\n        padding='same',\r\n        activation=None,\r\n        kernel_initializer=kernel_initializer,\r\n        name='conv_1'\r\n    )(inputs)\r\n    \r\n    if batch_norm:\r\n    conv1 = BatchNormalization(name='bn_1')(conv1)\r\n    conv1 = LeakyReLU(alpha=0.3, name='activation_1')(conv1)\r\n\r\n    conv1 = Conv2D(\r\n        filters=64,\r\n        kernel_size=kernel_size,\r\n        padding='same',\r\n        activation=None,\r\n        kernel_initializer=kernel_initializer,\r\n        name='conv_2'\r\n    )(conv1)\r\n    \r\n    if batch_norm:\r\n    conv1 = BatchNormalization(name='bn_2')(conv1)\r\n    conv1 = LeakyReLU(alpha=0.3, name='activation_2')(conv1)\r\n\r\n    pool1, mask1 = tf.nn.max_pool_with_argmax(\r\n        input=conv1,\r\n        ksize=2,\r\n        strides=2,\r\n        padding='SAME'\r\n    )\r\n    \r\n################################# block2 #################################\r\n    conv2 = Conv2D(\r\n        filters=128,\r\n        kernel_size=kernel_size,\r\n        padding='same',\r\n        activation=None,\r\n        kernel_initializer=kernel_initializer,\r\n        name='conv_3'\r\n    )(pool1)\r\n    \r\n    if batch_norm:\r\n    conv2 = BatchNormalization(name='bn_3')(conv2)\r\n    conv2 = LeakyReLU(alpha=0.3, name='activation_3')(conv2)\r\n\r\n    conv2 = Conv2D(\r\n        filters=128,\r\n        kernel_size=kernel_size,\r\n        padding='same',\r\n        activation=None,\r\n        kernel_initializer=kernel_initializer,\r\n        name='conv_4'\r\n    )(conv2)\r\n    \r\n    if batch_norm:\r\n    conv2 = BatchNormalization(name='bn_4')(conv2)\r\n    conv2 = LeakyReLU(alpha=0.3, name='activation_4')(conv2)\r\n\r\n    pool2, mask2 = tf.nn.max_pool_with_argmax(\r\n        input=conv2,\r\n        ksize=2,\r\n        strides=2,\r\n        padding='SAME'\r\n    )\r\n\r\n################################# block3 #################################\r\n    conv3 = Conv2D(\r\n        filters=256,\r\n        kernel_size=kernel_size,\r\n        padding='same',\r\n        activation=None,\r\n        kernel_initializer=kernel_initializer,\r\n        name='conv_5'\r\n    )(pool2)\r\n    \r\n    if batch_norm:\r\n    conv3 = BatchNormalization(name='bn_5')(conv3)\r\n    conv3 = LeakyReLU(alpha=0.3, name='activation_5')(conv3)\r\n    \r\n    conv3 = Conv2D(\r\n        filters=256,\r\n        kernel_size=kernel_size,\r\n        padding='same',\r\n        activation=None,\r\n        kernel_initializer=kernel_initializer,\r\n        name='conv_6'\r\n    )(conv3)\r\n    \r\n    if batch_norm:\r\n    conv3 = BatchNormalization(name='bn_6')(conv3)\r\n    conv3 = LeakyReLU(alpha=0.3, name='activation_6')(conv3)\r\n\r\n    conv3 = Conv2D(\r\n        filters=256,\r\n        kernel_size=kernel_size,\r\n        padding='same',\r\n        activation=None,\r\n        kernel_initializer=kernel_initializer,\r\n        name='conv_7'\r\n    )(conv3)\r\n    \r\n    if batch_norm:\r\n    conv3 = BatchNormalization(name='bn_7')(conv3)\r\n    conv3 = LeakyReLU(alpha=0.3, name='activation_7')(conv3)\r\n\r\n    pool3, mask3 = tf.nn.max_pool_with_argmax(\r\n        input=conv3,\r\n        ksize=2,\r\n        strides=2,\r\n        padding='SAME'\r\n    )\r\n\r\n################################# block4 #################################\r\n    conv4 = Conv2D(\r\n        filters=512,\r\n        kernel_size=kernel_size,\r\n        padding='same',\r\n        activation=None,\r\n        kernel_initializer=kernel_initializer,\r\n        name='conv_8'\r\n    )(pool3)\r\n    \r\n    if batch_norm:\r\n    conv4 = BatchNormalization(name='bn_8')(conv4)\r\n    conv4 = LeakyReLU(alpha=0.3, name='activation_8')(conv4)\r\n\r\n    conv4 = Conv2D(\r\n        filters=512,\r\n        kernel_size=kernel_size,\r\n        padding='same',\r\n        activation=None,\r\n        kernel_initializer=kernel_initializer,\r\n        name='conv_9'\r\n    )(conv4)\r\n    \r\n    if batch_norm:\r\n    conv4 = BatchNormalization(name='bn_9')(conv4)\r\n    conv4 = LeakyReLU(alpha=0.3, name='activation_9')(conv4)\r\n\r\n    conv4 = Conv2D(\r\n        filters=512,\r\n        kernel_size=kernel_size,\r\n        padding='same',\r\n        activation=None,\r\n        kernel_initializer=kernel_initializer,\r\n        name='conv_10'\r\n    )(conv4)\r\n    \r\n    if batch_norm:\r\n    conv4 = BatchNormalization(name='bn_10')(conv4)\r\n    conv4 = LeakyReLU(alpha=0.3, name='activation_10')(conv4)\r\n\r\n    pool4, mask4 = tf.nn.max_pool_with_argmax(\r\n        input=conv4,\r\n        ksize=2,\r\n        strides=2,\r\n        padding='SAME'\r\n    )\r\n\r\n################################# block5 #################################\r\n    conv5 = Conv2D(\r\n        filters=512,\r\n        kernel_size=kernel_size,\r\n        padding='same',\r\n        activation=None,\r\n        kernel_initializer=kernel_initializer,\r\n        name='conv_11'\r\n    )(pool4)\r\n    \r\n    if batch_norm:\r\n    conv5 = BatchNormalization(name='bn_11')(conv5)\r\n    conv5 = LeakyReLU(alpha=0.3, name='activation_11')(conv5)\r\n\r\n    conv5 = Conv2D(\r\n        filters=512,\r\n        kernel_size=kernel_size,\r\n        padding='same',\r\n        activation=None,\r\n        kernel_initializer=kernel_initializer,\r\n        name='conv_12'\r\n    )(conv5)\r\n    \r\n    if batch_norm:\r\n    conv5 = BatchNormalization(name='bn_12')(conv5)\r\n    conv5 = LeakyReLU(alpha=0.3, name='activation_12')(conv5)\r\n\r\n    conv5 = Conv2D(\r\n        filters=512,\r\n        kernel_size=kernel_size,\r\n        padding='same',\r\n        activation=None,\r\n        kernel_initializer=kernel_initializer,\r\n        name='conv_13'\r\n    )(conv5)\r\n    \r\n    if batch_norm:\r\n    conv5 = BatchNormalization(name='bn_13')(conv5)\r\n    conv5 = LeakyReLU(alpha=0.3, name='activation_13')(conv5)\r\n\r\n    pool5, mask5 = tf.nn.max_pool_with_argmax(\r\n        input=conv5,\r\n        ksize=2,\r\n        strides=2,\r\n        padding='SAME'\r\n    )\r\n\r\n    return pool5, mask1,mask2,mask3,mask4,mask5\r\n##########################################################################\r\n############################## decod block1 ##############################\r\n##########################################################################\r\n\r\ndef segnet_deconv(\r\n        pool5,\r\n        mask1,\r\n        mask2,\r\n        mask3,\r\n        mask4,\r\n        mask5,\r\n        kernel_size=3,\r\n        kernel_initializer='glorot_uniform',\r\n        batch_norm = False,\r\n        **kwargs\r\n    ):\r\n\r\n    dec = MaxUnpooling2D(pool5, mask5)\r\n\r\n    dec = Conv2D(\r\n        filters=512,\r\n        kernel_size=kernel_size,\r\n        padding='same',\r\n        activation=None,\r\n        kernel_initializer=kernel_initializer,\r\n        name='upconv_13'\r\n    )(dec)\r\n\r\n    if batch_norm:\r\n    dec = BatchNormalization(name='upbn_13')(dec)\r\n    dec = LeakyReLU(alpha=0.3, name='upactivation_13')(dec)\r\n    \r\n    dec = Conv2D(\r\n        filters=512,\r\n        kernel_size=kernel_size,\r\n        padding='same',\r\n        activation=None,\r\n        kernel_initializer=kernel_initializer,\r\n        name='upconv_12'\r\n    )(dec)\r\n\r\n    if batch_norm:\r\n    dec = BatchNormalization(name='upbn_12')(dec)\r\n    dec = LeakyReLU(alpha=0.3, name='upactivation_12')(dec)\r\n\r\n    dec = Conv2D(\r\n        filters=512,\r\n        kernel_size=kernel_size,\r\n        padding='same',\r\n        activation=None,\r\n        kernel_initializer=kernel_initializer,\r\n        name='upconv_11'\r\n    )(dec)\r\n\r\n    if batch_norm:\r\n    dec = BatchNormalization(name='upbn_11')(dec)\r\n    dec = LeakyReLU(alpha=0.3, name='upactivation_11')(dec)\r\n\r\n############################## decod block2 ##############################\r\n\r\n    dec = MaxUnpooling2D(dec, mask4)\r\n    \r\n    dec = Conv2D(\r\n        filters=512,\r\n        kernel_size=kernel_size,\r\n        padding='same',\r\n        activation=None,\r\n        kernel_initializer=kernel_initializer,\r\n        name='upconv_10'\r\n    )(dec)\r\n\r\n    if batch_norm:\r\n    dec = BatchNormalization(name='upbn_10')(dec)\r\n    dec = LeakyReLU(alpha=0.3, name='upactivation_10')(dec)\r\n    \r\n    dec = Conv2D(\r\n        filters=512,\r\n        kernel_size=kernel_size,\r\n        padding='same',\r\n        activation=None,\r\n        kernel_initializer=kernel_initializer,\r\n        name='upconv_9'\r\n    )(dec)\r\n\r\n    if batch_norm:\r\n    dec = BatchNormalization(name='upbn_9')(dec)\r\n    dec = LeakyReLU(alpha=0.3, name='upactivation_9')(dec)\r\n\r\n    dec = Conv2D(\r\n        filters=256,\r\n        kernel_size=kernel_size,\r\n        padding='same',\r\n        activation=None,\r\n        kernel_initializer=kernel_initializer,\r\n        name='upconv_8'\r\n    )(dec)\r\n\r\n    if batch_norm:\r\n    dec = BatchNormalization(name='upbn_8')(dec)\r\n    dec = LeakyReLU(alpha=0.3, name='upactivation_8')(dec)\r\n\r\n############################## decod block3 ##############################\r\n\r\n    dec = MaxUnpooling2D(dec, mask3)\r\n    \r\n    dec = Conv2D(\r\n        filters=256,\r\n        kernel_size=kernel_size,\r\n        padding='same',\r\n        activation=None,\r\n        kernel_initializer=kernel_initializer,\r\n        name='upconv_7'\r\n    )(dec)\r\n\r\n    if batch_norm:\r\n    dec = BatchNormalization(name='upbn_7')(dec)\r\n    dec = LeakyReLU(alpha=0.3, name='upactivation_7')(dec)\r\n    \r\n    dec = Conv2D(\r\n        filters=256,\r\n        kernel_size=kernel_size,\r\n        padding='same',\r\n        activation=None,\r\n        kernel_initializer=kernel_initializer,\r\n        name='upconv_6'\r\n    )(dec)\r\n\r\n    if batch_norm:\r\n    dec = BatchNormalization(name='upbn_6')(dec)\r\n    dec = LeakyReLU(alpha=0.3, name='upactivation_6')(dec)\r\n\r\n    dec = Conv2D(\r\n        filters=128,\r\n        kernel_size=kernel_size,\r\n        padding='same',\r\n        activation=None,\r\n        kernel_initializer=kernel_initializer,\r\n        name='upconv_5'\r\n    )(dec)\r\n\r\n    if batch_norm:\r\n    dec = BatchNormalization(name='upbn_5')(dec)\r\n    dec = LeakyReLU(alpha=0.3, name='upactivation_5')(dec)\r\n\r\n############################## decod block4 ##############################\r\n\r\n    dec = MaxUnpooling2D(dec, mask2)\r\n    \r\n    dec = Conv2D(\r\n        filters=128,\r\n        kernel_size=kernel_size,\r\n        padding='same',\r\n        activation=None,\r\n        kernel_initializer=kernel_initializer,\r\n        name='upconv_4'\r\n    )(dec)\r\n\r\n    if batch_norm:\r\n    dec = BatchNormalization(name='upbn_4')(dec)\r\n    dec = LeakyReLU(alpha=0.3, name='upactivation_4')(dec)\r\n    \r\n    dec = Conv2D(\r\n        filters=64,\r\n        kernel_size=kernel_size,\r\n        padding='same',\r\n        activation=None,\r\n        kernel_initializer=kernel_initializer,\r\n        name='upconv_3'\r\n    )(dec)\r\n\r\n    if batch_norm:\r\n    dec = BatchNormalization(name='upbn_3')(dec)\r\n    dec = LeakyReLU(alpha=0.3, name='upactivation_3')(dec)\r\n\r\n############################## decod block5 ##############################\r\n\r\n    dec = MaxUnpooling2D(dec, mask1)\r\n    \r\n    dec = Conv2D(\r\n        filters=64,\r\n        kernel_size=kernel_size,\r\n        padding='same',\r\n        activation=None,\r\n        kernel_initializer=kernel_initializer,\r\n        name='upconv_2'\r\n    )(dec)\r\n\r\n    if batch_norm:\r\n    dec = BatchNormalization(name='upbn_2')(dec)\r\n    dec = LeakyReLU(alpha=0.3, name='upactivation_2')(dec)\r\n    \r\n    dec = Conv2D(\r\n        filters=64,\r\n        kernel_size=kernel_size,\r\n        padding='same',\r\n        activation=None,\r\n        kernel_initializer=kernel_initializer,\r\n        name='upconv_3'\r\n    )(dec)\r\n\r\n    if batch_norm:\r\n    dec = BatchNormalization(name='upbn_3')(dec)\r\n    dec = LeakyReLU(alpha=0.3, name='upactivation_3')(dec)\r\n    return dec\r\n##########################################################################\r\n############################### classifier ###############################\r\n##########################################################################\r\ndef classifier(\r\n    dec,\r\n    ch_out=2,\r\n    kernel_size=3,\r\n    final_activation=None,\r\n    batch_norm = False,\r\n    **kwargs\r\n    ):\r\n    dec = Conv2D(\r\n        filters=64,\r\n        kernel_size=kernel_size,\r\n        activation='relu',\r\n        padding='same',\r\n        name='dec_out1'\r\n    )(dec)\r\n\r\n    dec = Dropout(0.3, name='drop_out1')(dec)\r\n\r\n    x = Conv2D(\r\n        filters=64,\r\n        kernel_size=kernel_size,\r\n        activation='relu',\r\n        padding='same',\r\n        name='dec_out2'\r\n    )(dec)\r\n\r\n    dec = Dropout(0.3, name='drop_out2')(dec)\r\n    dec = Conv2D(\r\n        filters=ch_out,\r\n        kernel_size=1,\r\n        activation=final_activation,\r\n        padding='same',\r\n        name='dec_output'\r\n    )(dec)\r\n    return dec\r\n@tf.function\r\ndef segnet(\r\n    inputs,\r\n    ch_out=2,\r\n    kernel_size=3,\r\n    kernel_initializer='glorot_uniform',\r\n    final_activation=None,\r\n    batch_norm = False,\r\n    **kwargs\r\n    ):\r\n\r\n    pool5, mask1, mask2, mask3, mask4, mask5 = segnet_conv(\r\n                            inputs,\r\n                            kernel_size=3,\r\n                            kernel_initializer='glorot_uniform',\r\n                            batch_norm = False\r\n                        )\r\n    dec = segnet_deconv(\r\n            pool5,\r\n            mask1,\r\n            mask2,\r\n            mask3,\r\n            mask4,\r\n            mask5,\r\n            kernel_size=kernel_size,\r\n            kernel_initializer=kernel_initializer,\r\n            batch_norm = batch_norm\r\n        )\r\n\r\n    output = classifier(\r\n            dec,\r\n            ch_out=2,\r\n            kernel_size=3,\r\n            final_activation=None,\r\n            batch_norm = batch_norm\r\n        )\r\n    return output\r\ndef train(config, params):\r\n        random_seed = np.random.seed(params['random_seed'])\r\n\tuse_batch_norm = params['batch_size'] > 1\r\n\ttf.random.set_seed(random_seed)\r\n\r\n\ttrain_images_dir = os.path.join(config['image_dir'], 'train/image/*')\r\n\ttrain_images_list = glob.glob(train_images_dir)\r\n\ttrain_gt_dir = os.path.join(config['image_dir'], 'train/gt/*')\r\n\ttrain_gt_list = glob.glob(train_gt_dir)\r\n\r\n\ttest_images_dir = os.path.join(config['image_dir'], 'val/image/*')\r\n\ttest_images_list = glob.glob(test_images_dir)\r\n\ttest_gt_dir = os.path.join(config['image_dir'], 'val/gt/*')\r\n\ttest_gt_list = glob.glob(test_gt_dir)\r\n\r\n\ttrain_dataset = segmentation_input_fn(train_images_list, train_gt_list, resize_to=params['image_size'], batch_size=params['batch_size'],shuffle=True,\r\n\t\t\t\t\t\t\t\t\t\taugment=False, seed=random_seed)\r\n\ttest_dataset = segmentation_input_fn(test_images_list, test_gt_list, resize_to=params['image_size'],batch_size=params['batch_size'],shuffle=True,\r\n\t\t\t\t\t\t\t\t\t\taugment=False, seed=random_seed)\r\n\r\n\ttrain_steps_per_epoch = math.ceil(len(train_images_list) / params['batch_size'])\r\n\ttest_steps_per_epoch   = math.ceil(len(test_images_list) / params['batch_size'])\r\n\r\n\t#inputs = Input(shape=(*params['image_size'], params['num_channels']), name='input')\r\n\t#outputs = segnet(inputs, n_labels=2, kernel=3, pool_size=(2, 2), output_mode=None)\r\n\t\t\t # we define our U-Net to output logits.\r\n               \r\n\r\n\tmodel = segnet()#inputs)#, outputs)\r\n\t\r\n\toptimizer = tf.keras.optimizers.Adam(lr=params['lr'])\r\n\t#define the train and test metrics\r\n\ttrain_metrics = [tf.keras.metrics.Mean() for _ in range(5)]\r\n\ttest_metrics = [tf.keras.metrics.Mean() for _ in range(5)]\r\n\t#train_metrics.append(tf.keras.metrics.Accuracy())\r\n\t#test_metrics.append(tf.keras.metrics.Accuracy())\r\n\t#current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\r\n\ttrain_log_dir = (config['log_dir'] + '/train')\r\n\ttest_log_dir = (config['log_dir'] +  '/test')\r\n\ttrain_summary_writer = tf.summary.create_file_writer(train_log_dir)\r\n\ttest_summary_writer = tf.summary.create_file_writer(test_log_dir)\r\n\r\n\r\n\ttf.summary.trace_on(graph=True, profiler=False)\r\n\r\n\r\n\ttf_utils.print_summary(model, config, params)\r\n\t\r\n\tepoch=0\r\n\tmin_loss = 1e10\r\n\twith train_summary_writer.as_default():\r\n\t\ttf.summary.text('config', tf_utils.tb_config(config, params), step=0)\r\n\twhile True:\r\n\t\ttrain_images, train_labels = train_dataset.__iter__().next()\r\n\t\ttrain_metrics, preds, grads  = train_step(\r\n\t\t\t\t\t\toptimizer,\r\n\t\t\t\t\t\tmodel,\r\n\t\t\t\t\t\ttrain_metrics,\r\n\t\t\t\t\t\ttrain_images,\r\n\t\t\t\t\t\ttrain_labels)\t\r\n\r\n\t\tif optimizer.iterations % config['log_freq'] == 0:\r\n\t\t\twith train_summary_writer.as_default():\r\n\t\t\t\tprint(len(np.unique(preds)))\r\n\t\t\t#if optimizer.iteration % 10 ==0: #config['log_freq'] == 0:\r\n\t\t\t\ttf.summary.scalar('train loss', train_metrics[0].result().numpy(), step=optimizer.iterations)\r\n\t\t\t\ttf.summary.scalar('train mIoU', train_metrics[1].result().numpy(), step=optimizer.iterations)\r\n\t\t\t\ttf.summary.scalar('train precision', train_metrics[2].result().numpy(), step=optimizer.iterations)\r\n\t\t\t\ttf.summary.scalar('train recall', train_metrics[3].result().numpy(),step=optimizer.iterations)\r\n\t\t\t\ttf.summary.scalar('train accuracy', train_metrics[4].result().numpy(), step=optimizer.iterations)\r\n\r\n\t\t\ttemplate_log = 'Step {}, Loss: {}, m_IoU: {}, Precision: {}, Recall: {}, Accuracy: {}'\r\n\t\t\tprint (template_log.format(optimizer.iterations.numpy(), train_metrics[0].result().numpy(),train_metrics[1].result().numpy(),\r\n\t\t\t\t\ttrain_metrics[2].result().numpy(),train_metrics[3].result().numpy(), train_metrics[4].result().numpy()))\r\n\r\n\t\tif optimizer.iterations % config['test_freq'] == 0:\r\n\t\t\ttest_images, test_labels = test_dataset.__iter__().next()\r\n\t\t\ttest_metrics, test_pred = validation_step(model, test_metrics, test_images, test_labels)\r\n\t\t\twith test_summary_writer.as_default():\r\n\t\t\t\ttf.summary.scalar('test loss', test_metrics[0].result().numpy(), step=optimizer.iterations)\r\n\t\t\t\ttf.summary.scalar('test mIoU', test_metrics[1].result().numpy(), step=optimizer.iterations)\r\n\t\t\t\ttf.summary.scalar('test precision', test_metrics[2].result().numpy(), step=optimizer.iterations)\r\n\t\t\t\ttf.summary.scalar('test recall', test_metrics[3].result().numpy(),step=optimizer.iterations)\r\n\t\t\t\ttf.summary.scalar('test accuracy', test_metrics[4].result().numpy(), step=optimizer.iterations)\r\n\t\t\t\ttf.summary.image(\"input\", test_images,step=optimizer.iterations, max_outputs=params['batch_size'])\r\n\t\t\t\ttf.summary.image(\"ground_truth\", tf.one_hot(tf.squeeze(test_labels, axis=-1),depth=2,axis=-1),step=optimizer.iterations, max_outputs=params['batch_size'])\r\n\t\t\t\ttf.summary.image(\"prediction_output\",tf.one_hot(test_pred,depth=2,axis=-1),step=optimizer.iterations, max_outputs=params['batch_size'])\r\n\r\n\t\t\ttemplate_log = 'Step {}, Test_Loss: {}, Test_m_IoU: {}, Test_Precision: {}, Test_Recall: {}, Test_Accuracy: {}'\r\n\t\t\tprint (template_log.format(optimizer.iterations.numpy(), test_metrics[0].result().numpy(),test_metrics[1].result().numpy(),\r\n\t\t\t\ttest_metrics[2].result().numpy(),test_metrics[3].result().numpy(), test_metrics[4].result().numpy()))\r\n\r\n\r\n\t\t\tif test_metrics[0].result().numpy() < min_loss:\r\n\t\t\t\tmodel.save_weights(\r\n\t\t\t\t\tos.path.join(\r\n\t\t\t\t\t\tconfig['log_dir'],\r\n\t\t\t\t\t\tconfig['log_code'],\r\n\t\t\t\t\t\t'weights.ckpt'\r\n\t\t\t\t\t),\r\n\t\t\t\t\toverwrite = True\r\n\t\t\t\t)\r\n\r\n\t\t\t\tmin_loss = test_metrics[0].result().numpy()\r\n\t\"\"\"\r\n\tfig, axs = plt.subplots(2, params['batch_size'])\r\n\tn = 0\r\n\tfor n in range (0,params['batch_size']): \r\n#\t\t#ax[0,col].plot(val_image_samples[col])#\r\n#\t\tprint(tf.shape(tf.squeeze(val_gt_samples, axis=[-1])[col]))\r\n\t\t\r\n\t\taxs[0,n].imshow(tf.squeeze(val_gt_samples, axis = [-1])[n])\r\n\t\t#ax[1].imshow(tf.squeeze(val_gt_samples, axis = [-1])[n])\r\n\t\taxs[1,n].imshow(tf.squeeze(tf.image.rgb_to_grayscale(val_image_samples),axis=[-1])[n])\r\n\t\tn+=1\r\n\t\t\t#axs.set_title('A single plot')\r\n\tplt.show()\r\n\t\"\"\"\r\nif __name__ == '__main__':\r\n\r\n\tconfig = {\r\n\t\t'image_dir' : '../Dataset',\r\n\t\t#'dataset' : 'Crack260_train.tfrecords',\r\n\t\t'log_dir' : './model_logs_dice_dep4',\r\n\t\t'log_code' : 'saved_weights',\r\n\t\t'log_freq' : 10,\r\n\t\t'test_freq' : 100\r\n\t}\r\n\t\r\n\tparams = {\r\n\t\t'random_seed' : 42, # Fixing the seed for PRNGs, to help reproducibility\r\n\t\t'num_channels' : 3,\r\n\t\t'kernel_size' : 4,\r\n\t\t'filters_orig' : 32,\r\n\t\t'layer_depth' : 4,\r\n\t\t'image_size' : [512,512],\r\n\t\t'batch_size' : 4,\r\n\t\t'num_epochs' : 50,\r\n\t\t'num_shown' : 2,\r\n\t\t'lr' : 1e-4,\r\n\t}\r\n\t#with mirrored_strategy.scope():\r\n\ttrain(config, params)\r\n`", "This is so hard to read.\r\n\r\nPlease use ` ``` ` on a single line **before** and **after** your code blocks. Please make sure you use proper markdown format, so devs can understand what is happening and can fix the issue faster.", "@ucesfpa,\r\nPlease take a look at @mihaimaruseac's comment.\r\n\r\nAlso, there line `train(config, params)` in your code seems to raise an error. Please find the gist of it [here](https://colab.sandbox.google.com/gist/amahendrakar/95f19dc1d8a54c1c843ec4301b7af1f0/36522.ipynb).\r\n\r\nCould you please provide a minimal code sample to reproduce the error? You can also try [Google colab](https://colab.sandbox.google.com/notebook#create=true&language=python3) or share the Python notebook file with us. Thanks!", "@ucesfpa,\r\nAny updates regarding this issue? Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 36521, "title": "TemporalDropout1D", "body": "Removing words and estimating from context is one of the recent language modeling tasks. This kind of noise could be useful as regularization as well. ", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F36521) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F36521) for more info**.\n\n<!-- ok -->", "@halidziya Can you please check reviewer comments and keep us posted. Thanks!", "Closing this PR now. See discussions above. Let us know if you have other concerns."]}, {"number": 36520, "title": "wrong error message from tf.data.Dataset when GPU OOM", "body": "I am filing this issue in case someone else ran into the same problem.\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.1.0\r\n- Python version: 3.6.9\r\n- CUDA/cuDNN version: 10.1/7\r\n- GPU model and memory:Titan XP/12GB\r\n\r\n**Describe the current behavior**\r\n\r\nWhen GPU memory is `fully` taken by another tf session, I failed to run the following script:\r\n\r\n```python\r\ntf.data.Dataset.list_files(\"some files\")\r\n```\r\n\r\nand got the following error:\r\n```\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: buffer_size must be greater than zero. [Op:ShuffleDatasetV2]\r\n```\r\n\r\n**Describe the expected behavior**\r\n\r\nI expected to get an OOM error, which is much clear about the real root cause of the problem.\r\n\r\n**Code to reproduce the issue**\r\n\r\nIn one python session, run some tensorflow code to take all the GPU memory  (I ran some MobileNet inference to take  11879MiB / 12194MiB of the GPU memory).\r\nIn another python session, run `tf.data.Dataset.list_files(\"./*\")`  will reproduce the misleading error message.\r\n\r\n\r\n", "comments": ["@jiayiliu It looks like you are using an older Version of Tensorflow . Many bugs have been fixed in the latest version. Could you please execute your code using Latest Version 2.5 and let us know if the issue still persists? Thanks!", "The error indicates that the `shuffle` buffer size used by the implementation of `list_files` [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/data/ops/dataset_ops.py#L1241-L1246), which indicates that the pattern that you provided did not match any files. This should be caught by the [following check](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/data/ops/dataset_ops.py#L1235-L1238), which was  introduced after TF 2.1. \r\n\r\nAll in all, the error you are seeing has nothing to do with GPU memory and instead is caused by the fact that your file pattern does not match any files. Latest version of TF provides a clear error message for this.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36520\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36520\">No</a>\n"]}, {"number": 36519, "title": "Use deserialize-helper for deserializing dict activations", "body": "Allows `tf.keras.activations` to be deserialized with `dict`s. Fixes #36518.", "comments": []}, {"number": 36518, "title": "Allow `tf.keras.activations` to be deserialized with dicts.", "body": "**System information**\r\n- TensorFlow version (you are using): `2.1`\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\n`tf.keras.activations` deserialization doesn't work for dict-based identifier. It would be nice if it did work in a similar way as other module deserializers such as `tf.keras.initializers`. The following snippet currently raises `ValueError: Unknown activation: relu` for the activation deserialization.\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\n\r\n# Works\r\ninitilizer = tf.keras.initializers.get({\r\n    'class_name': 'random_normal_initializer',\r\n    'config': {}\r\n})\r\n\r\n# Does not work\r\nactivation = tf.keras.activations.get({\r\n    'class_name': 'relu',\r\n    'config': {}\r\n})\r\n```\r\n\r\n\r\n\r\n**Will this change the current api? How?**\r\nIt would add the ability to use `tf.keras.activations.get({...})`.\r\n\r\n**Who will benefit with this feature?**\r\nUsers who want to serialize/deserialize their activation functions for example as json.\r\n\r\n**Any Other info.**\r\nI'm happy to submit a PR for this.", "comments": []}, {"number": 36517, "title": "TensorFlow Lite Conversion Fails (Check failed: start_indices_size <= num_input_axes (2 vs. 1)StridedSlice op requires no more than 1 start indices)", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux CentOS 7.5\r\n- TensorFlow installed from (source or binary): Tensorflow is preinstalled on the server.\r\n- TensorFlow version (or github SHA if from source): Tensorflow/2.0.0\r\n\r\n\r\n**Command used to run the converter or code if you\u2019re using the Python API**\r\n```\r\nimport tensorflow as tf\r\n# Note: full quantization requires tf 1.15 or higher\r\nimport numpy as np\r\nfrom PIL import Image\r\n\r\ndef representative_dataset_gen():\r\n  data = np.random.rand(100,416,416,3).astype(dtype=np.float32)\r\n  for i in range(num_calibration_steps):\r\n    # Get sample input data as a numpy array in a method of your choosing.\r\n    # image, = data.take(1)\r\n    image = np.expand_dims(data[i,:,:,:], axis=0)\r\n    yield [image]\r\n\r\nnum_calibration_steps = 100\r\nsaved_model_dir = '/projectnb/ec720prj/nakamura/Spring2020/tf2-yolov3/savedmodel/yolov3/1' # dir of YOLOv3 tf implementation\r\n\r\nconverter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\n# converter.representative_dataset = tf.lite.RepresentativeDataset(representative_dataset_gen)\r\nconverter.representative_dataset = representative_dataset_gen\r\n\r\n# Enforce full integer quantization for all ops and use int input/output\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\r\nconverter.inference_input_type = tf.uint8\r\nconverter.inference_output_type = tf.uint8\r\n\r\ntflite_quant_model = converter.convert()\r\nopen(\"./converted_model.tflite\", \"wb\").write(tflite_quant_model)\r\n```\r\n\r\n**The output from the converter invocation**\r\n\r\n```\r\n2020-02-06 10:53:25.407210: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  AVX AVX2 FMA\r\nTo enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2020-02-06 10:53:25.425952: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2394310000 Hz\r\n2020-02-06 10:53:25.427429: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xce6d420 executing computations on platform Host. Devices:\r\n2020-02-06 10:53:25.427467: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\r\n2020-02-06 10:53:25.436305: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 28. Tune using inter_op_parallelism_threads for best performance.\r\n2020-02-06 10:53:42.002931: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)\r\n2020-02-06 10:53:42.003093: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\r\n2020-02-06 10:53:42.111911: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:716] Optimization results for grappler item: graph_to_optimize\r\n2020-02-06 10:53:42.111960: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   function_optimizer: Graph size after: 2070 nodes (1696), 5733 edges (5354), time = 66.938ms.\r\n2020-02-06 10:53:42.111973: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   function_optimizer: function_optimizer did nothing. time = 1.093ms.\r\n2020-02-06 10:53:48.038844: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)\r\n2020-02-06 10:53:48.038997: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\r\n2020-02-06 10:53:49.980217: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:716] Optimization results for grappler item: graph_to_optimize\r\n2020-02-06 10:53:49.980262: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   constant folding: Graph size after: 1268 nodes (-370), 4423 edges (-734), time = 922.534ms.\r\n2020-02-06 10:53:49.980274: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   constant folding: Graph size after: 1268 nodes (0), 4423 edges (0), time = 255.534ms.\r\nTraceback (most recent call last):\r\n  File \"coral/coral_quantizer.py\", line 38, in <module>\r\n    tflite_quant_model = converter.convert()\r\n  File \"/share/pkg.7/tensorflow/2.0.0/install/lib/SCC/../python3.6/site-packages/tensorflow_core/lite/python/lite.py\", line 446, in convert\r\n    **converter_kwargs)\r\n  File \"/share/pkg.7/tensorflow/2.0.0/install/lib/SCC/../python3.6/site-packages/tensorflow_core/lite/python/convert.py\", line 449, in toco_convert_impl\r\n    enable_mlir_converter=enable_mlir_converter)\r\n  File \"/share/pkg.7/tensorflow/2.0.0/install/lib/SCC/../python3.6/site-packages/tensorflow_core/lite/python/convert.py\", line 200, in toco_convert_protos\r\n    raise ConverterError(\"See console for info.\\n%s\\n%s\\n\" % (stdout, stderr))\r\ntensorflow.lite.python.convert.ConverterError: See console for info.\r\n2020-02-06 10:54:00.060634: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 676 operators, 1271 arrays (0 quantized)\r\n2020-02-06 10:54:00.077126: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 676 operators, 1271 arrays (0 quantized)\r\n2020-02-06 10:54:00.465306: F tensorflow/lite/toco/graph_transformations/resolve_strided_slice_attributes.cc:95] Check failed: start_indices_size <= num_input_axes (2 vs. 1)StridedSlice op requires no more than 1 start indices\r\nFatal Python error: Aborted\r\n\r\nCurrent thread 0x00007fbbde05b740 (most recent call first):\r\n  File \"/share/pkg.7/tensorflow/2.0.0/install/lib/SCC/../python3.6/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 52 in execute\r\n  File \"/share/pkg.7/tensorflow/2.0.0/install/lib/SCC/../python3.6/site-packages/absl/app.py\", line 250 in _run_main\r\n  File \"/share/pkg.7/tensorflow/2.0.0/install/lib/SCC/../python3.6/site-packages/absl/app.py\", line 299 in run\r\n  File \"/share/pkg.7/tensorflow/2.0.0/install/lib/SCC/../python3.6/site-packages/tensorflow_core/python/platform/app.py\", line 40 in run\r\n  File \"/share/pkg.7/tensorflow/2.0.0/install/lib/SCC/../python3.6/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 89 in main\r\n  File \"/share/pkg.7/tensorflow/2.0.0/install/bin/toco_from_protos\", line 10 in <module>\r\n```\r\n\r\n**Also, please include a link to the saved model or GraphDef**\r\n\r\n```\r\n# Put link here or attach to the issue.\r\nhttps://drive.google.com/a/bu.edu/file/d/1STaqguXrsKaqNbzxmvGVwzpwWZEiC4K6/view?usp=sharing\r\n```\r\n\r\n**Failure details**\r\nHello,\r\nI am trying to run the full YOLOv3 on Coral EdgeTPU. To do this, I am currently trying to convert the savedmodel (.pb format) of trained yolov3 into the quantized .tflite model using the code I attached above.\r\nFor some reason, the conversion failed with this error:\r\n```\r\nCheck failed: start_indices_size <= num_input_axes (2 vs. 1)StridedSlice op requires no more than 1 start indices\r\nFatal Python error: Aborted)\r\n```\r\nI was able to convert the official pretrained MobileNetv1 savedmodel file into the quantized .tflite model using the exact same code. \r\n\r\nI am using this repo (https://github.com/YunYang1994/TensorFlow2.0-Examples/tree/master/4-Object_Detection/YOLOV3) for the YOLOv3 Tensorflow 2.0.0 implementation.\r\n\r\nDo you know what is causing this failure of conversion?\r\nThank you.\r\n\r\n**Any other info / logs**\r\n\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nYOLOv3's implementation code => (https://github.com/YunYang1994/TensorFlow2.0-Examples/tree/master/4-Object_Detection/YOLOV3)\r\n\r\nThank you for your help.\r\n", "comments": ["@raltech I can reproduce the issue. [Here](https://colab.research.google.com/gist/jvishnuvardhan/a6cfd1f9542e8159a5248c159115351b/untitled812.ipynb) is the gist for our reference. Thanks!", "@miaout17 @jvishnuvardhan Thank you for your reply. I looked at the gist you shared above; however, the error message you got seems different from mine. In your gist, it seems like the conversion failed because of ResizeNearestNeighbor function? Which, to me, does not make sense because ResizeNearestNeighbor is a supported discretize function according to [this](https://coral.ai/docs/edgetpu/models-intro/) page.\r\nIs the difference between our error messages caused by the difference in the minor versions of TensorFlow? (i.e., I used a stable version of tf, but you seem using tf-nightly.)\r\nThank you!", "@miaout17 @jvishnuvardhan \r\nWhen I switched to tf-nightly, I could reproduce the exact same error as yours.\r\n```\r\nException: <unknown>:0: error: loc(fused[\"model/tf_op_layer_resize/ResizeNearestNeighbor/resize/ResizeNearestNeighbor@__inference__wrapped_model_28454\", \"StatefulPartitionedCall/model/tf_op_layer_resize/ResizeNearestNeighbor/resize/ResizeNearestNeighbor\"]): 'tf.ResizeNearestNeighbor' op is neither a custom op nor a flex op\r\n<unknown>:0: error: loc(fused[\"model/tf_op_layer_resize_1/ResizeNearestNeighbor/resize_1/ResizeNearestNeighbor@__inference__wrapped_model_28454\", \"StatefulPartitionedCall/model/tf_op_layer_resize_1/ResizeNearestNeighbor/resize_1/ResizeNearestNeighbor\"]): 'tf.ResizeNearestNeighbor' op is neither a custom op nor a flex op\r\n<unknown>:0: error: failed while converting: 'main': Ops that can be supported by the flex runtime (enabled via setting the -emit-select-tf-ops flag): ResizeNearestNeighbor,ResizeNearestNeighbor\r\n```\r\n\r\nAny updates on this issue?", "@miaout17 \r\nI am still stuck on this issue. Could you tell me how to fix this?", "I have same problem. Did you fix it?@raltech@miaout17", "Hi @jdduke I'm running into a similar issue.  I'm using tf version 2.2.0-rc3 and and the mlir converter: \r\n```error: 'tf.ResizeNearestNeighbor' op is neither a custom op nor a flex op```\r\n\r\nI don't get the error using the toco converter :(. \r\n\r\nAre y'all aware of this/have any MLIR workarounds? Until then i'll just be turning the mlir converter off.", "Can you share what are the parameters passed to ResizeNearestNeighbor in your model ?", "This is because of the `half_pixel_centers` argument switched on my default in TF2. The old converter ignores it and converts the op to a ResizeNearestNeighbor with `half_pixel_centers=false` (which is likely to give inaccurate results). The new converter doesn't recognize this, so fails.\r\n\r\nSupporting all arguments in TFLite's ResizeNearestNeighbor should fix this issue. @ghop02 I will work on this and ping back on this issue for you to switch on the new converter again.", "I have encountered the same problem. hoping you can solve it as soon as possible. thank you @srjoglekar246 ", "Also facing the same issue.\r\n\r\nI will try loading the weighs on a YOLOv3 TF1.15 + Keras implementation and see how it behaves. Anyone tried that yet?", "@ghop02 @raltech \r\n\r\n[This commit](https://github.com/tensorflow/tensorflow/commit/48baba71cf3d115c7ec47f9e3902a78ee71ab8e9) should enable the correct resize-NN behavior in TFLite.\r\nCould you verify and close the bug if it works?", "@srjoglekar246 With `tf-nightly`, i get little different error with the gist I uploaded earlier. Here is the full trace of error\r\n```\r\n\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-7-20e4a2d2e08d> in <module>()\r\n     28 converter.inference_output_type = tf.uint8\r\n     29 \r\n---> 30 tflite_quant_model = converter.convert()\r\n     31 open(\"./converted_model.tflite\", \"wb\").write(tflite_quant_model)\r\n\r\n2 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/optimize/calibrator.py in calibrate_and_quantize(self, dataset_gen, input_type, output_type, allow_float, resize_input)\r\n     91     return self._calibrator.QuantizeModel(\r\n     92         np.dtype(input_type.as_numpy_dtype()).num,\r\n---> 93         np.dtype(output_type.as_numpy_dtype()).num, allow_float)\r\n     94 \r\n     95   def calibrate_and_quantize_single(self,\r\n\r\nRuntimeError: Quantization not yet supported for op: EXP\r\n```", "@jianlijianli Jian could you take a look at the above quantization error?", "@srjoglekar246 @jianlijianli \r\n\r\nWhile using latest tf-nightly build (tf-nightly-2.3.0.dev20200613), i noticed that it can convert a SavedModel generated by TF 2.2.0 to TFLite flatbuffer successfully. This verified the fix for ResizeNearestNeighbor with MLIR.\r\n\r\nHowever, if I generate a SavedModel using this tf-nightly build, and convert again, it will fail and prompt something like `'tf.All' op is neither a custom op nor a flex op` . And then keep prompting a bunch of hex values. This seems to be a regression.\r\n\r\nIt also happens to tf-nightly-2.3.0.dev20200614. Could you look into this to make sure it won't fail in the coming TF 2.3.0? Or should I make a separate ticket?", "@ethanyanjiali Looks like there were some changes in the upstream TensorFlow graph-generating code :-/. Could you share the SavedModel (or any other details?). We will need to look at the source ops to see why/how its placing `tf.All` in the source graph.", "@srjoglekar246 \r\nhere's the SavedModel generated by 2.2.0, and 2.3.0-dev20200614 can covert it to TFLite model with no problem. https://drive.google.com/file/d/1eR6Iz-RQA44YONqyUSOMFaRo5JAZBbQ-/view?usp=sharing\r\n\r\nand here's the SavedModel generated by 2.3.0-dev20200614. With this, 2.3.0-dev20200614 will fail after a few optimization steps. https://drive.google.com/file/d/1u618HSmT-g6XyLAF9yJ3JSC455CQ4XPZ/view?usp=sharing\r\n\r\nThe error may come from `tf.image.non_max_suppression_padded` in my code, more stack trace here:\r\n```\r\n<unknown>:0: note: loc(callsite(callsite(\"non_max_suppression_padded/while/suppression_loop_body/while/All@__inference_non_max_suppression_padded_while_suppression_loop_body_while_body_12844_41994\" at \"non_max_suppression_padded/while/suppression_loop_body/while@__inference_non_max_suppression_padded_while_body_12795_42163\") at fused[callsite(\"non_max_suppression_padded/while@__inference_serve_44818\"(\"/Users/yanjia.li/Projects/perceptron2/env/lib/python3.7/site-packages/tensorflow/python/saved_model/load.py\":608:0) at callsite(\"/Users/yanjia.li/Projects/perceptron2/env/lib/python3.7/site-packages/tensorflow/python/saved_model/load.py\":582:0 at callsite(\"main.py\":25:0 at callsite(\"/Users/yanjia.li/Projects/perceptron2/env/lib/python3.7/site-packages/click/core.py\":555:0 at callsite(\"/Users/yanjia.li/Projects/perceptron2/env/lib/python3.7/site-packages/click/core.py\":956:0 at callsite(\"/Users/yanjia.li/Projects/perceptron2/env/lib/python3.7/site-packages/click/core.py\":717:0 at callsite(\"/Users/yanjia.li/Projects/perceptron2/env/lib/python3.7/site-packages/click/core.py\":764:0 at \"main.py\":65:0))))))), \"StatefulPartitionedCall/non_max_suppression_padded/while\"])): see current operation: %32 = \"tf.All\"(%31, %cst_0) {device = \"\", keep_dims = false} : (tensor<1x512x512xi1>, tensor<1xi32>) -> tensor<1x512xi1>\r\n<unknown>:0: error: failed while converting: 'main': Ops that can be supported by the flex runtime (enabled via setting the -emit-select-tf-ops flag):\r\n        tf.All {device = \"\", keep_dims = false}\r\n        tf.All {device = \"/device:CPU:0\", keep_dims = false}\r\n<unknown>:0: note: see current operation: \"func\"() ( {\r\n^bb0(%arg0: tensor<416x416x3xf32>):  // no predecessors\r\n  %cst = \"std.constant\"() {value = dense<\"0x00000000000000000000803F000000000000004000000000000040400000000000008040000000000000A040000000000000C040000000000000E040000000000000004100000000000010410000000000\r\n```\r\nand then this hex values just keep going forever\r\n\r\nAlso I'm using new converter\r\n```python\r\nconverter.experimental_new_converter = True\r\n```", "Argh. This is related to some (known) changes in the upstream TensorFlow, which re-implemented non_max_suppression_with_padding in a way that no longer uses ops fully supported by TFLite. Lemme get back to you with some updates.", "@ethanyanjiali in your comment, do you mean that with TF2.3, the model does not train as expected (irrespective of TFLite conversion)?\r\n\r\nAlso, can you share with me the snippet of code where your code calls non_max_suppression_padded? ", "@srjoglekar246 \r\nit's only refers to post-training model saving and converting. I haven't tried to use TF2.3dev to train a model yet. \r\n\r\nThe reason there could be a combination of TF2.3dev SavedModel and TF2.3dev converter is because I reloaded checkpoint and re-generated SavedModel after training. Likewise, I also reloaded checkpoint and re-generated SavedModel using TF2.2. I have to do this because of an issue here: https://github.com/tensorflow/tensorflow/issues/39918 \r\n\r\nAnd now that I have two versions of SavedModel from TF2.2 and TF2.3dev, I tried to use TF2.3dev converter to convert them. Only TF2.2 SavedModel works with TF2.3dev converter. The converter will output the error for TF2.3dev SavedModel.\r\n\r\ncode snippet:\r\n```python\r\n        boxes = boxes[0]\r\n        scores = scores[0]\r\n        class_probs = class_probs[0]\r\n\r\n        selected_indices_padded, num_valid = tf.image.non_max_suppression_padded(\r\n            boxes,\r\n            tf.squeeze(scores, axis=-1),\r\n            self.max_detection,\r\n            iou_threshold=self.iou_threshold,\r\n            score_threshold=self.score_threshold,\r\n            pad_to_max_output_size=True,\r\n        )\r\n\r\n        selected_boxes = tf.gather(boxes, selected_indices_padded)\r\n        selected_scores = tf.gather(scores, selected_indices_padded)\r\n        classes = tf.argmax(tf.gather(class_probs, selected_indices_padded), axis=-1)\r\n```", "@ethanyanjiali Can you check w/ the nightly in a day or so (or build from master)?\r\nTF2.3 rc2 should have the fix too.", "> @ethanyanjiali Can you check w/ the nightly in a day or so (or build from master)?\r\n> TF2.3 rc2 should have the fix too.\r\n\r\nI had same issue and with tf-nightly I can fix this.", "Awesome. Thanks for verifying!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36517\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36517\">No</a>\n", "@raltech I am still stuck on this issue.\u201cCheck failed: start_indices_size <= num_input_axes (2 vs. 1)StridedSlice op requires no more than 1 start indices\u201d\r\nHave you solved this problem and how?\r\nthanks!", "> @raltech I am still stuck on this issue.\u201cCheck failed: start_indices_size <= num_input_axes (2 vs. 1)StridedSlice op requires no more than 1 start indices\u201d\r\n> Have you solved this problem and how?\r\n> thanks!\r\n\r\nHi HaoWang I stumble across this exact same issue also, trying to do post quantization on Yunyang1994 Yolov3 implementation, I am using Tensorflow2.1.0 on Windows.\r\nMay I know hv you solved this problem?", "@lucastan5596 Please create a new issue with a simple standalone code to reproduce the error you are noticing? Thanks!", "\n  \n  \n   \n   \n  \n    \u4f60\u597d\uff0c\u6211\u4e5f\u6ca1\u6709\u89e3\u51b3\uff0c\u6700\u540e\u653e\u5f03\u4e86 \n    \n   \n   \n  ------------------ \u539f\u59cb\u90ae\u4ef6 ------------------\u53d1\u4ef6\u4eba\uff1aVishnuvardhan Janapati \"notifications@github.com\"\u65f6\u3000\u95f4\uff1a2020/11/10 00:32:42 \u5468\u4e8c\u6536\u4ef6\u4eba\uff1atensorflowtensorflow \"tensorflow@noreply.github.com\"\u6284\u9001\u4eba\uff1aHaoWang1006 \"15510991006@189.cn\", Comment \"comment@noreply.github.com\"\u4e3b\u3000\u9898\uff1aRe: [tensorflow/tensorflow] TensorFlow Lite Conversion Fails (Check failed: start_indices_size <= num_input_axes (2 vs. 1)StridedSlice op requires no more than 1 start indices) (#36517) \n   \n  @lucastan5596 Please create a new issue with a simple standalone code to reproduce the error you are noticing? Thanks! \n  \u2014You are receiving this because you commented.Reply to this email directly, view it on GitHub, or unsubscribe.", "\u6211\u5012\u662f\u89e3\u51b3\u4e86 \u4f60\u8fd8\u6709\u9700\u8981\u5417\uff1f\n\nOn Mon, Nov 16, 2020, 8:48 AM HaoWang1006 <notifications@github.com> wrote:\n\n>\n>\n>\n>\n>\n>\n> \u4f60\u597d\uff0c\u6211\u4e5f\u6ca1\u6709\u89e3\u51b3\uff0c\u6700\u540e\u653e\u5f03\u4e86\n>\n>\n>\n> ------------------ \u539f\u59cb\u90ae\u4ef6 ------------------\u53d1\u4ef6\u4eba\uff1aVishnuvardhan Janapati \"\n> notifications@github.com\"\u65f6 \u95f4\uff1a2020/11/10 00:32:42\n> \u5468\u4e8c\u6536\u4ef6\u4eba\uff1atensorflowtensorflow \"tensorflow@noreply.github.com\"\u6284\u9001\u4eba\uff1aHaoWang1006\n> \"15510991006@189.cn\", Comment \"comment@noreply.github.com\"\u4e3b \u9898\uff1aRe:\n> [tensorflow/tensorflow] TensorFlow Lite Conversion Fails (Check failed:\n> start_indices_size <= num_input_axes (2 vs. 1)StridedSlice op requires no\n> more than 1 start indices) (#36517)\n>\n> @lucastan5596 Please create a new issue with a simple standalone code to\n> reproduce the error you are noticing? Thanks!\n> \u2014You are receiving this because you commented.Reply to this email\n> directly, view it on GitHub, or unsubscribe.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/36517#issuecomment-727671363>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/APODHARNNT6QLMRGRQ77FPTSQBZHFANCNFSM4KQ7VZNQ>\n> .\n>\n", "> \u6211\u5012\u662f\u89e3\u51b3\u4e86 \u4f60\u8fd8\u6709\u9700\u8981\u5417\uff1f\r\n> [\u2026](#)\r\n> On Mon, Nov 16, 2020, 8:48 AM HaoWang1006 ***@***.***> wrote: \u4f60\u597d\uff0c\u6211\u4e5f\u6ca1\u6709\u89e3\u51b3\uff0c\u6700\u540e\u653e\u5f03\u4e86 ------------------ \u539f\u59cb\u90ae\u4ef6 ------------------\u53d1\u4ef6\u4eba\uff1aVishnuvardhan Janapati \" ***@***.***\"\u65f6 \u95f4\uff1a2020/11/10 00:32:42 \u5468\u4e8c\u6536\u4ef6\u4eba\uff1atensorflowtensorflow ***@***.***\"\u6284\u9001\u4eba\uff1aHaoWang1006 ***@***.***\", Comment ***@***.***\"\u4e3b \u9898\uff1aRe: [tensorflow/tensorflow] TensorFlow Lite Conversion Fails (Check failed: start_indices_size <= num_input_axes (2 vs. 1)StridedSlice op requires no more than 1 start indices) (#36517) @lucastan5596 Please create a new issue with a simple standalone code to reproduce the error you are noticing? Thanks! \u2014You are receiving this because you commented.Reply to this email directly, view it on GitHub, or unsubscribe. \u2014 You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub <[#36517 (comment)](https://github.com/tensorflow/tensorflow/issues/36517#issuecomment-727671363)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/APODHARNNT6QLMRGRQ77FPTSQBZHFANCNFSM4KQ7VZNQ> .\r\n\r\n\u9700\u8981"]}, {"number": 36515, "title": "Provide complete tutorial on how to use MultiWorkerMirroredStrategy", "body": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras#train_the_model_with_multiworkermirroredstrategy\r\n\r\n## Description of issue (what needs changing):\r\n\r\nThere is a large and often overlooked caveat: You need to pass `steps_per_epoch`. This leads to issues like https://github.com/tensorflow/tensorflow/issues/34821, https://github.com/tensorflow/tensorflow/issues/36153. It should be explained, how `steps_per_epoch` should be set. Searching the examples does not really help: `num_samples / batch_size` is sometimes rounded up and sometimes down. A clear guideline for Multi-Worker would be appreciated.\r\n\r\nAlso it is not described how loading the dataset should happen. Doing that in a Multi-Worker setting is tricky as the data needs to be downloaded exactly once. See https://github.com/tensorflow/datasets/issues/1302\r\n\r\nAlso the developers of `tensorflow_datasets` claim, that the auto-sharding done by TF won't work properly and suggest to use custom functions: https://github.com/tensorflow/datasets/issues/1302, https://github.com/tensorflow/datasets/issues/1426. It should be evaluated whether this is the case and where this has to be addressed.\r\n\r\nFinally a description on how to run the evaluation is missing for completeness. This runs into another issue that by default files are sharded and e.g. MNIST only has 1 file for test data which makes TF fail. See also https://github.com/tensorflow/datasets/issues/1405\r\n\r\nFor the last point the solution is to use \r\n\r\n```\r\noptions = tf.data.Options()\r\noptions.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.DATA\r\ntrain_datasets = train_datasets.with_options(options)\r\n```\r\nWhich can be found by searching the docs. But it needs to be in the tutorial (and maybe even the default)", "comments": ["Thank you for the feedback. For the first point, the third note in the [tutorial you linked to](https://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras#train_the_model_with_multiworkermirroredstrategy) includes a description for how to set steps_per_epoch. Can you clarify what specifically is unclear about the explanation? Would like to understand if the explanation is unclear, or if an example is needed, or if you think this information should exist somewhere other than just the tutorial.", "That third point does indeed help and seems to be new. It is quit good except of a few typos (e.g. `should be set to the size of the smallest *sharded* *devided*`)\r\n\r\nMy suggestion was that it is not fully clear how that value should be set when you are given a dataset with a size (# examples/batches). The example on the linked page uses a hard-coded value (which is IMO bad style [see magic numbers] especially for a tutorial) Now try to search the docs for `steps_per_epoch` like a user looking for help would do. He'd find code like `steps_per_epoch = np.ceil(image_data.samples/image_data.batch_size)`, `np.ceil(image_count/BATCH_SIZE)`, and `train_generator.samples // train_generator.batch_size` As you can see this is inconsistent without any given reason. So for a user it is hard to tell what the right way is.\r\n\r\nI learnt through experimentation and parallel study of the docs that `MultiWorkerMirroredStrategy` doesn't work with trailing batches so the \"round down\" semantic of the last example is correct for this use case.\r\n\r\nSo 3 improvements here:\r\n- Show `steps_per_epoch = train_generator.samples // train_generator.batch_size`-like code in the linked tutorial\r\n- Explain the implications (e.g. with growing number of workers and batch sizes an increasing number of images from an epoch won't be handled) and why round-down (yes it is mentioned in the third point so that could be referenced)\r\n- make the other examples consistent and explain why ceil/floor semantic is used", "@Flamefire  closing the issue since  the documentation was updated. Please feel  free to re-open the issue  if necessary. Thanks!", "It seems like the explanation about steps_per_epoch was removed from the tutorial, now it is just some random hard coded values. I had lots of problems setting up steps_per_epoch for multi worker strategy in context of multi nodes as it also change the behavior of how the dataset is iterated over.  "]}, {"number": 36514, "title": "bfloat16 does not flush denormals (subnormal floats) to zero", "body": "[BFloat16: The secret to high performance on Cloud TPUs](https://cloud.google.com/blog/products/ai-machine-learning/bfloat16-the-secret-to-high-performance-on-cloud-tpus), Shibo Wang, Pankaj Kanwar (@pkanwar23 right?) , August 23, 2019, says:\r\n\r\n> bfloat16 handles denormals differently from FP32: it flushes them to zero\r\n\r\nI assume this implies that for a denormal 32-bit floating point, `denorm`, the expression `float{bfloat16{denorm}}` should be equal to zero.\r\n\r\nThe current implementation of `tensorflow::bfloat16` (master branch, revision bc28d49ce2659f846e03c13a64ebe83fc6fb8ff1) appears to behave differently. As can be observed by the following test:\r\n\r\n    for (float denorm = std::numeric_limits<float>::denorm_min();\r\n      denorm < std::numeric_limits<float>::min();\r\n      denorm = std::nextafterf(denorm, 1.0f))\r\n        ASSERT_EQ(float{ tensorflow::bfloat16{denorm} }, 0.0f);\r\n\r\nThis assertion fails on the current implementation, from [tensorflow/core/lib/bfloat16](https://github.com/tensorflow/tensorflow/tree/bc28d49ce2659f846e03c13a64ebe83fc6fb8ff1/tensorflow/core/lib/bfloat16)\r\n\r\nIs that indeed a bug in `tensorflow::bfloat16`?\r\n\r\n\r\n\r\n\r\n\r\n", "comments": ["Looks like this issue was addressed by @tensorflower-gardener, Mar 20, 2020, \"Flush denormals to +/- 0 when converting float to bfloat16.\" https://github.com/tensorflow/tensorflow/commit/b04c4e0e4338924d5281626445594a900bd673a6 right?\r\n", "@N-Dekker Yes, This was addressed on Mar 20. Can you please verify once and close the issue if this was resolved for you. Thanks!", "Just verified! This is indeed resolved! I'll close the issue!\r\n\r\nFYI, I tried the [bfloat16.DenormalFloatsConvertToZero](https://github.com/biovault/biovault_bfloat16/blob/b145861475eb9cf7cff952475b98828c8435561a/biovault_bfloat16_test.cpp#L193) unit test that I wrote before for `biovault::bfloat16_t` on your `tensorflow::bfloat16` struct and it passed just fine now  \ud83d\udc4d  Thank you @jvishnuvardhan and @tensorflower-gardener ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36514\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36514\">No</a>\n", "For the record: This issue appears related to Eigen merge request \"remove denormal flushing in fp32tobf16 for avx & avx512\", https://gitlab.com/libeigen/eigen/-/merge_requests/580 by Gauri Deshpande (@gaurides)"]}, {"number": 36513, "title": "Cannot perform full-integer post-training quantization in converting to flite models", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Both\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS, Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): either\r\n- TensorFlow version (use command below): 1.15.2\r\n- Python version: 3\r\n- Bazel version (if compiling from source): 0.26.1\r\n- GCC/Compiler version (if compiling from source): - \r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**Describe the current behavior**\r\nThe issue relates to full integer post-training quantization in tflite conversion. Following the same example in the [documentation](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/performance/post_training_integer_quant.ipynb), but applied to my data have issues when I identify the input_data for the interpreter as float32 (below my data in R is in float32 already normalized between [0,10]):\r\n\r\n`input_data = np.array(R, dtype=np.float32)`\r\n`interpreter.set_tensor(input_details[0]['index'], input_data)`\r\n `interpreter.invoke()`\r\n\r\nWhen then I call the TFLite converter (using `tf.compat.v1.lite.TFLiteConverter.from_keras_model_file` in TF2.x or `tf.lite.TFLiteConverter.from_keras_model_file` in TF1.x) again following from the documentation:\r\n\r\n`converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]`\r\n    `converter.representative_dataset = representative_dataset_gen`\r\n    `converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]`\r\n    `converter.inference_input_type = tf.uint8`\r\n    `converter.inference_output_type = tf.uint8`\r\n    `tflite_quant_model = converter.convert()`\r\n\r\n\r\nThe post-quantized tflite is correctly created (and when compiled for the TPU, all ops are correctly assigned). However, when I run a prediction, I get the following error:\r\n`ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 16, name: conv2d_input`\r\n\r\nEssentially, the `input_data = np.array(R, dtype=np.float32)`, needs to be set as uint8 for this to work. However, that breaks the model completely, as it casts all data between [0,1] into just zeros. \r\n\r\nTo be clear, this does NOT happen when using TF2.x, by calling the converter with `tf.lite.TFLiteConverter.from_keras_model()`. Using the `input_data = np.array(R, dtype=np.float32)`, the post-training quantized tflite model is created and when used for predictions, it works as intended. However, when compiled, because I am using the `TFLiteConverterV2` , the quantization/dequantization ops are not assigned to the TPU, making it useless to deploy in embedded devices that require full integer quantization.\r\n\r\nAny insight is greatly appreciated. Thanks in advance.\r\n\r\n", "comments": ["The same issue can be reproduces with a slightly modified [code in the documentation](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/performance/post_training_integer_quant.ipynb). Please see the attachment (it's obviously python3 code, despite the txt extension to allow upload). \r\n\r\nWhen line 52 is uncommented and line 55 is commented the code works. \r\nWhen line 52 is commented and line 55 is uncommented, the code does not work and gives the same error message in the previous comment:\r\n\r\n`ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 11, name: reshape_input `\r\n\r\n[test_issue_36513.txt](https://github.com/tensorflow/tensorflow/files/4165369/test_issue_36513.txt)\r\n", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36513\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36513\">No</a>\n"]}, {"number": 36512, "title": "Micro: Fix error in README for network_tester example", "body": "There's an error in the README in the make-command. This PR fixes that.", "comments": []}, {"number": 36511, "title": "bug of keras.metrics under @tf.function", "body": "**System information**\r\n- TensorFlow installed from source\r\n- TensorFlow version: v2.1.0-0-ge5bf8de410 2.1.0\r\n- Python version: 3.6.9 (default, Nov  7 2019, 10:44:02) [GCC 8.3.0]\r\n- Bazel version (if compiling from source): 0.29.1\r\n- GCC/Compiler version (if compiling from source): gcc (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0\r\n- CUDA/cuDNN version: n/a\r\n- GPU model and memory: n/a\r\n\r\nThe tf.keras.metrics.Mean() class is not performing correctly under @tf.function annotation. It looks like some control_dependencies issues and I suspect similar bugs for other metrics.\r\n\r\n**Code to reproduce the issue**\r\nThe results of `func1()`, `func2()`, and `func3()` should be all the same (a series of numbers starting from 4.5) in the following. However, `func2()` produces different result (a series of numbers starting from 0).\r\n```\r\nimport tensorflow as tf\r\n\r\neval_dataset = tf.data.Dataset.range(10)\r\nmetric = tf.keras.metrics.Mean(name='mean', dtype=tf.float32)\r\n\r\ndef func1():\r\n    for step in range(100):\r\n        if tf.equal(step % 5, 0):\r\n            for y in eval_dataset:\r\n                x = tf.cast(y + step, tf.float32)\r\n                metric(x)\r\n            print(metric.result().numpy())\r\n            metric.reset_states()\r\n\r\nfunc1()\r\n\r\n@tf.function\r\ndef func2():\r\n    for step in range(100):\r\n        if tf.equal(step % 5, 0):\r\n            for y in eval_dataset:\r\n                x = tf.cast(y + step, tf.float32)\r\n                metric(x)\r\n            tf.print(metric.result())\r\n            metric.reset_states()\r\n\r\nfunc2()\r\n\r\n@tf.function\r\ndef func3():\r\n    for step in range(100):\r\n        if tf.equal(step % 5, 0):\r\n            total = metric.total.assign(0.0)\r\n            count = metric.count.assign(0)\r\n            for y in eval_dataset:\r\n                x = tf.cast(y + step, tf.float32)\r\n                with tf.control_dependencies([total, count]):\r\n                    total = metric.total.assign_add(x)\r\n                    count = metric.count.assign_add(1)\r\n            result = tf.math.divide_no_nan(total, count)\r\n            tf.print(result)\r\n\r\nfunc3()\r\n```", "comments": ["This is a similar issue:\r\nhttps://github.com/tensorflow/tensorflow/issues/31458", "Was able to reproduce the issue with Tf 2.1.\r\nPlease find the gist [here](https://colab.research.google.com/gist/gadagashwini/ae1d5953733646431d7797d8c70b9a36/untitled380.ipynb). Thanks!", "@tianran, This issue is fixed in latest tf-nightly version. \r\nPlease take a look at [gist](https://colab.research.google.com/gist/gadagashwini/b88fcb61527e52da8feeb7ee50a64174/untitled381.ipynb). Thanks", "Closing since its fixed. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36511\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36511\">No</a>\n"]}, {"number": 36510, "title": "MirroredStrategy() crashes with NVLinked GPUs", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nyes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nProgress Linux 5+ (engywuck-backports) (Linux Debian Buster)\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v2.1.0-rc2-17-ge5bf8de 2.1.0\r\n- Python version: 3.7.3\r\n- CUDA/cuDNN version: 10.1/7.0\r\n- GPU model and memory: 2x Asus GeForxe RTX 2080 Ti, Compute Capability 7.5, With NVLink\r\n\r\n**Describe the current behavior**\r\nTraining of a ResNet with NVLink enabled crashes with following error:\r\n```bash\r\ntensorflow.python.framework.errors_impl.InternalError: 2 root error(s) found.\r\n  (0) Internal:  unhandled cuda error\r\n         [[node Adam/NcclAllReduce (defined at workspace/gpu_tests/test_gpus.py:60) ]]\r\n  (1) Internal:  unhandled cuda error\r\n         [[node Adam/NcclAllReduce (defined at workspace/gpu_tests/test_gpus.py:60) ]]\r\n         [[GroupCrossDeviceControlEdges_0/Adam/Adam/update_1_1/Const/_39]]\r\n0 successful operations.\r\n1 derived errors ignored. [Op:__inference_distributed_function_36247]\r\n\r\nFunction call stack:\r\ndistributed_function -> distributed_function\r\n```\r\nWhen I use cross_device_ops=tf.distribute.ReductionToOneDevice() it doesn't crash but it's not the optimal performance since it's not using NCCL. The NCCL seems to work however. Check the NCCL/all_reduce_perf log below. \r\n\r\n**Describe the expected behavior**\r\nTraining should not crash. \r\n\r\n**Code to reproduce the issue**\r\n```bash\r\n# -*- coding: utf-8 -*-\r\n\r\nimport numpy as np\r\nfrom tensorflow.keras.applications.resnet50 import ResNet50\r\nimport tensorflow as tf\r\nimport tensorflow_datasets as tfds\r\n\r\nLENGTH_DATASET = 17509\r\nNUM_CLASSES = 9\r\nIMG_SHAPE = (256, 256, 3)\r\nBATCH_SIZE = 32\r\n\r\n\r\ndef mymap_func(features):\r\n    return features[\"image\"], features[\"label\"]\r\n\r\n\r\nAUTOTUNE = tf.data.experimental.AUTOTUNE\r\n\r\n# create input pipeline\r\ndataset = tfds.load(name=\"deep_weeds\", split=\"train\")\r\ndataset = dataset.map(mymap_func,\r\n                      num_parallel_calls=tf.data.experimental.AUTOTUNE)\r\ndataset = dataset.cache()\r\ndataset = dataset.shuffle(buffer_size=LENGTH_DATASET, seed=42,\r\n                          reshuffle_each_iteration=True)\r\ndataset = dataset.batch(batch_size=BATCH_SIZE, drop_remainder=True).repeat()\r\ndataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\r\n\r\n\r\n# create model\r\nimg_width, img_height = 270, 270\r\n\r\nshape, classes = (img_width, img_height, 1), 3\r\n\r\n# strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.ReductionToOneDevice())\r\nstrategy = tf.distribute.MirroredStrategy()\r\nprint(\"Number of devices in strategy: {}\".format(strategy.num_replicas_in_sync))\r\n\r\nwith strategy.scope():\r\n\r\n    model = ResNet50(include_top=True,\r\n                       weights=None,\r\n                       input_tensor=None,\r\n                       input_shape=IMG_SHAPE,\r\n                       pooling=None,\r\n                       classes=NUM_CLASSES)\r\n\r\n    model.compile(optimizer=tf.optimizers.Adam(),\r\n                    loss='sparse_categorical_crossentropy',\r\n                    metrics=[\"accuracy\"])\r\n\r\n    train_steps = np.ceil(LENGTH_DATASET / BATCH_SIZE)\r\n    history = model.fit(\r\n            x=dataset,\r\n            epochs=10,\r\n            verbose=1,\r\n            steps_per_epoch=train_steps,\r\n            use_multiprocessing=False,\r\n            workers=8)\r\n```\r\n\r\n**Other info / logs**\r\nFull Tensorflow Dump:\r\n```bash\r\n2020-02-06 13:50:44.982897: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer.so.6\r\n2020-02-06 13:50:44.984479: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer_plugin.so.6\r\n2020-02-06 13:50:46.159056: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\r\n2020-02-06 13:50:46.251661: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \r\npciBusID: 0000:3b:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\r\ncoreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\r\n2020-02-06 13:50:46.252336: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 1 with properties: \r\npciBusID: 0000:af:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\r\ncoreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\r\n2020-02-06 13:50:46.252374: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\r\n2020-02-06 13:50:46.252413: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\r\n2020-02-06 13:50:46.254193: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\r\n2020-02-06 13:50:46.254548: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\r\n2020-02-06 13:50:46.256609: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\r\n2020-02-06 13:50:46.257880: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\r\n2020-02-06 13:50:46.257929: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2020-02-06 13:50:46.260454: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0, 1\r\n2020-02-06 13:50:46.260872: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\r\n2020-02-06 13:50:46.305692: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz\r\n2020-02-06 13:50:46.313917: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x43d2220 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-02-06 13:50:46.313956: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2020-02-06 13:50:46.929224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4360be0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\r\n2020-02-06 13:50:46.929289: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2080 Ti, Compute Capability 7.5\r\n2020-02-06 13:50:46.929335: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): GeForce RTX 2080 Ti, Compute Capability 7.5\r\n2020-02-06 13:50:46.931578: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \r\npciBusID: 0000:3b:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\r\ncoreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\r\n2020-02-06 13:50:46.933238: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 1 with properties: \r\npciBusID: 0000:af:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\r\ncoreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\r\n2020-02-06 13:50:46.933319: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\r\n2020-02-06 13:50:46.933354: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\r\n2020-02-06 13:50:46.933404: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\r\n2020-02-06 13:50:46.933441: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\r\n2020-02-06 13:50:46.933477: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\r\n2020-02-06 13:50:46.933514: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\r\n2020-02-06 13:50:46.933544: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2020-02-06 13:50:46.939900: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0, 1\r\n2020-02-06 13:50:46.939975: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\r\n2020-02-06 13:50:47.657348: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-02-06 13:50:47.657397: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 1 \r\n2020-02-06 13:50:47.657405: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N Y \r\n2020-02-06 13:50:47.657411: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 1:   Y N \r\n2020-02-06 13:50:47.659222: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10235 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:3b:00.0, compute capability: 7.5)\r\n2020-02-06 13:50:47.660401: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10235 MB memory) -> physical GPU (device: 1, name: GeForce RTX 2080 Ti, pci bus id: 0000:af:00.0, compute capability: 7.5)\r\nNumber of devices in strategy: 2\r\nTrain for 548.0 steps\r\nEpoch 1/10\r\n2020-02-06 13:51:06.516702: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\r\n2020-02-06 13:51:08.552933: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2020-02-06 13:51:09.714280: W tensorflow/stream_executor/gpu/redzone_allocator.cc:312] Not found: ./bin/ptxas not found\r\nRelying on driver to perform ptx compilation. This message will be only logged once.\r\n2020-02-06 13:51:11.686255: W tensorflow/core/framework/op_kernel.cc:1655] OP_REQUIRES failed at nccl_ops.cc:104 : Internal: unhandled cuda error\r\n2020-02-06 13:51:11.686300: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Internal: unhandled cuda error\r\n         [[{{node Adam/NcclAllReduce}}]]\r\n         [[GroupCrossDeviceControlEdges_0/Adam/Adam/update_1_1/Const/_39]]\r\n2020-02-06 13:51:11.686335: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Internal: unhandled cuda error\r\n         [[{{node Adam/NcclAllReduce}}]]\r\n         [[Identity_2/_60]]\r\n2020-02-06 13:51:11.686381: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Internal: unhandled cuda error\r\n         [[{{node Adam/NcclAllReduce}}]]\r\n2020-02-06 13:51:11.686678: W tensorflow/core/framework/op_kernel.cc:1655] OP_REQUIRES failed at nccl_ops.cc:104 : Internal: unhandled cuda error\r\n  1/548 [..............................] - ETA: 2:54:10Traceback (most recent call last):\r\n  File \"workspace/gpu_tests/test_gpus.py\", line 60, in <module>\r\n    workers=8)\r\n  File \"/home/sam2/workspace/python_venvs/tf-run/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\", line 819, in fit\r\n    use_multiprocessing=use_multiprocessing)\r\n  File \"/home/sam2/workspace/python_venvs/tf-run/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 342, in fit\r\n    total_epochs=epochs)\r\n  File \"/home/sam2/workspace/python_venvs/tf-run/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 128, in run_one_epoch\r\n    batch_outs = execution_function(iterator)\r\n  File \"/home/sam2/workspace/python_venvs/tf-run/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\", line 98, in execution_function\r\n    distributed_function(input_fn))\r\n  File \"/home/sam2/workspace/python_venvs/tf-run/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\", line 568, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"/home/sam2/workspace/python_venvs/tf-run/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\", line 632, in _call\r\n    return self._stateless_fn(*args, **kwds)\r\n  File \"/home/sam2/workspace/python_venvs/tf-run/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 2363, in __call__\r\n    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\r\n  File \"/home/sam2/workspace/python_venvs/tf-run/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 1611, in _filtered_call\r\n    self.captured_inputs)\r\n  File \"/home/sam2/workspace/python_venvs/tf-run/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 1692, in _call_flat\r\n    ctx, args, cancellation_manager=cancellation_manager))\r\n  File \"/home/sam2/workspace/python_venvs/tf-run/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 545, in call\r\n    ctx=ctx)\r\n  File \"/home/sam2/workspace/python_venvs/tf-run/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\", line 67, in quick_execute\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.InternalError: 2 root error(s) found.\r\n  (0) Internal:  unhandled cuda error\r\n         [[node Adam/NcclAllReduce (defined at workspace/gpu_tests/test_gpus.py:60) ]]\r\n  (1) Internal:  unhandled cuda error\r\n         [[node Adam/NcclAllReduce (defined at workspace/gpu_tests/test_gpus.py:60) ]]\r\n         [[GroupCrossDeviceControlEdges_0/Adam/Adam/update_1_1/Const/_39]]\r\n0 successful operations.\r\n1 derived errors ignored. [Op:__inference_distributed_function_36247]\r\n\r\nFunction call stack:\r\ndistributed_function -> distributed_function\r\n\r\n2020-02-06 13:51:12.044366: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\r\n2020-02-06 13:51:12.045417: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\r\n\r\n```\r\nNVIDIA NCCL Test Dump:\r\n```bash\r\nworkspace/nccl-tests/build/all_reduce_perf -b 8 -e 128M -g 2   \r\n# nThread 1 nGpus 2 minBytes 8 maxBytes 134217728 step: 1048576(bytes) warmup iters: 5 iters: 20 validation: 1 \r\n#\r\n# Using devices\r\n#   Rank  0 Pid   2374 on     tf-run device  0 [0x3b] GeForce RTX 2080 Ti\r\n#   Rank  1 Pid   2374 on     tf-run device  1 [0xaf] GeForce RTX 2080 Ti\r\n#\r\n#                                                     out-of-place                       in-place          \r\n#       size         count    type   redop     time   algbw   busbw  error     time   algbw   busbw  error\r\n#        (B)    (elements)                     (us)  (GB/s)  (GB/s)            (us)  (GB/s)  (GB/s)       \r\n           8             2   float     sum    14.31    0.00    0.00  0e+00    13.72    0.00    0.00  0e+00\r\n     1048584        262146   float     sum    69.45   15.10   15.10  0e+00    69.72   15.04   15.04  0e+00\r\n     2097160        524290   float     sum    111.0   18.89   18.89  0e+00    108.2   19.39   19.39  0e+00\r\n     3145736        786434   float     sum    151.2   20.80   20.80  0e+00    149.1   21.10   21.10  0e+00\r\n     4194312       1048578   float     sum    192.3   21.81   21.81  0e+00    191.3   21.93   21.93  0e+00\r\n     5242888       1310722   float     sum    233.3   22.48   22.48  0e+00    231.2   22.68   22.68  0e+00\r\n     6291464       1572866   float     sum    273.2   23.03   23.03  0e+00    271.2   23.20   23.20  0e+00\r\n     7340040       1835010   float     sum    312.8   23.46   23.46  0e+00    310.1   23.67   23.67  0e+00\r\n     8388616       2097154   float     sum    333.5   25.16   25.16  0e+00    327.8   25.59   25.59  0e+00\r\n     9437192       2359298   float     sum    379.4   24.88   24.88  0e+00    377.8   24.98   24.98  0e+00\r\n    10485768       2621442   float     sum    417.6   25.11   25.11  0e+00    416.1   25.20   25.20  0e+00\r\n    11534344       2883586   float     sum    439.1   26.27   26.27  0e+00    437.6   26.36   26.36  0e+00\r\n    12582920       3145730   float     sum    492.7   25.54   25.54  0e+00    491.0   25.63   25.63  0e+00\r\n    13631496       3407874   float     sum    490.5   27.79   27.79  0e+00    480.3   28.38   28.38  0e+00\r\n    14680072       3670018   float     sum    495.9   29.60   29.60  0e+00    491.4   29.87   29.87  0e+00\r\n    15728648       3932162   float     sum    526.7   29.86   29.86  0e+00    525.1   29.95   29.95  0e+00\r\n    16777224       4194306   float     sum    549.9   30.51   30.51  0e+00    546.8   30.68   30.68  0e+00\r\n    17825800       4456450   float     sum    579.1   30.78   30.78  0e+00    578.4   30.82   30.82  0e+00\r\n    18874376       4718594   float     sum    631.1   29.90   29.90  0e+00    629.7   29.98   29.98  0e+00\r\n    19922952       4980738   float     sum    664.7   29.97   29.97  0e+00    661.5   30.12   30.12  0e+00\r\n    20971528       5242882   float     sum    699.4   29.98   29.98  0e+00    699.0   30.00   30.00  0e+00\r\n    22020104       5505026   float     sum    757.4   29.07   29.07  0e+00    754.8   29.17   29.17  0e+00\r\n    23068680       5767170   float     sum    718.0   32.13   32.13  0e+00    717.8   32.14   32.14  0e+00\r\n    24117256       6029314   float     sum    777.1   31.04   31.04  0e+00    775.5   31.10   31.10  0e+00\r\n    25165832       6291458   float     sum    807.1   31.18   31.18  0e+00    805.2   31.26   31.26  0e+00\r\n    26214408       6553602   float     sum    838.5   31.26   31.26  0e+00    836.8   31.33   31.33  0e+00\r\n    27262984       6815746   float     sum    871.7   31.27   31.27  0e+00    870.8   31.31   31.31  0e+00\r\n    28311560       7077890   float     sum    934.3   30.30   30.30  0e+00    931.6   30.39   30.39  0e+00\r\n    29360136       7340034   float     sum    934.6   31.41   31.41  0e+00    934.2   31.43   31.43  0e+00\r\n    30408712       7602178   float     sum    968.5   31.40   31.40  0e+00    965.5   31.50   31.50  0e+00\r\n    31457288       7864322   float     sum   1035.0   30.39   30.39  0e+00   1032.3   30.47   30.47  0e+00\r\n    32505864       8126466   float     sum   1102.1   29.50   29.50  0e+00   1099.9   29.55   29.55  0e+00\r\n    33554440       8388610   float     sum    963.5   34.83   34.83  0e+00    960.3   34.94   34.94  0e+00\r\n    34603016       8650754   float     sum    989.6   34.97   34.97  0e+00    987.8   35.03   35.03  0e+00\r\n    35651592       8912898   float     sum   1055.1   33.79   33.79  0e+00   1054.7   33.80   33.80  0e+00\r\n    36700168       9175042   float     sum   1163.0   31.56   31.56  0e+00   1158.4   31.68   31.68  0e+00\r\n    37748744       9437186   float     sum   1155.9   32.66   32.66  0e+00   1152.5   32.76   32.76  0e+00\r\n    38797320       9699330   float     sum   1185.6   32.72   32.72  0e+00   1183.4   32.78   32.78  0e+00\r\n    39845896       9961474   float     sum   1261.6   31.58   31.58  0e+00   1259.5   31.64   31.64  0e+00\r\n    40894472      10223618   float     sum   1206.2   33.90   33.90  0e+00   1204.0   33.97   33.97  0e+00\r\n    41943048      10485762   float     sum   1235.5   33.95   33.95  0e+00   1233.4   34.01   34.01  0e+00\r\n    42991624      10747906   float     sum   1310.8   32.80   32.80  0e+00   1307.8   32.87   32.87  0e+00\r\n    44040200      11010050   float     sum   1343.2   32.79   32.79  0e+00   1339.9   32.87   32.87  0e+00\r\n    45088776      11272194   float     sum   1376.5   32.76   32.76  0e+00   1373.3   32.83   32.83  0e+00\r\n    46137352      11534338   float     sum   1406.1   32.81   32.81  0e+00   1403.5   32.87   32.87  0e+00\r\n    47185928      11796482   float     sum   1386.1   34.04   34.04  0e+00   1382.8   34.12   34.12  0e+00\r\n    48234504      12058626   float     sum   1418.1   34.01   34.01  0e+00   1415.0   34.09   34.09  0e+00\r\n    49283080      12320770   float     sum   1498.5   32.89   32.89  0e+00   1494.7   32.97   32.97  0e+00\r\n    50331656      12582914   float     sum   1482.1   33.96   33.96  0e+00   1478.4   34.05   34.05  0e+00\r\n    51380232      12845058   float     sum   1507.4   34.08   34.08  0e+00   1505.2   34.14   34.14  0e+00\r\n    52428808      13107202   float     sum   1536.0   34.13   34.13  0e+00   1534.1   34.18   34.18  0e+00\r\n    53477384      13369346   float     sum   1568.3   34.10   34.10  0e+00   1563.7   34.20   34.20  0e+00\r\n    54525960      13631490   float     sum   1601.1   34.05   34.05  0e+00   1596.8   34.15   34.15  0e+00\r\n    55574536      13893634   float     sum   1691.0   32.87   32.87  0e+00   1687.4   32.93   32.93  0e+00\r\n    56623112      14155778   float     sum   1721.4   32.89   32.89  0e+00   1717.8   32.96   32.96  0e+00\r\n    57671688      14417922   float     sum   1751.2   32.93   32.93  0e+00   1747.9   32.99   32.99  0e+00\r\n    58720264      14680066   float     sum   1716.3   34.21   34.21  0e+00   1714.4   34.25   34.25  0e+00\r\n    59768840      14942210   float     sum   1748.4   34.19   34.19  0e+00   1744.2   34.27   34.27  0e+00\r\n    60817416      15204354   float     sum   1709.5   35.58   35.58  0e+00   1707.4   35.62   35.62  0e+00\r\n    61865992      15466498   float     sum   1803.8   34.30   34.30  0e+00   1799.7   34.38   34.38  0e+00\r\n    62914568      15728642   float     sum   1968.9   31.95   31.95  0e+00   1966.7   31.99   31.99  0e+00\r\n    63963144      15990786   float     sum   2141.1   29.87   29.87  0e+00   2133.0   29.99   29.99  0e+00\r\n    65011720      16252930   float     sum   2173.3   29.91   29.91  0e+00   2168.4   29.98   29.98  0e+00\r\n    66060296      16515074   float     sum   2206.5   29.94   29.94  0e+00   2200.0   30.03   30.03  0e+00\r\n    67108872      16777218   float     sum   1526.3   43.97   43.97  0e+00   1526.4   43.96   43.96  0e+00\r\n    68157448      17039362   float     sum   1547.9   44.03   44.03  0e+00   1549.3   43.99   43.99  0e+00\r\n    69206024      17301506   float     sum   1570.9   44.05   44.05  0e+00   1573.0   44.00   44.00  0e+00\r\n    70254600      17563650   float     sum   1593.1   44.10   44.10  0e+00   1595.0   44.05   44.05  0e+00\r\n    71303176      17825794   float     sum   1773.7   40.20   40.20  0e+00   1770.2   40.28   40.28  0e+00\r\n    72351752      18087938   float     sum   1954.7   37.01   37.01  0e+00   1948.8   37.13   37.13  0e+00\r\n    73400328      18350082   float     sum   2058.5   35.66   35.66  0e+00   2058.1   35.66   35.66  0e+00\r\n    74448904      18612226   float     sum   2005.1   37.13   37.13  0e+00   2003.9   37.15   37.15  0e+00\r\n    75497480      18874370   float     sum   1948.4   38.75   38.75  0e+00   1950.2   38.71   38.71  0e+00\r\n    76546056      19136514   float     sum   1976.9   38.72   38.72  0e+00   1973.3   38.79   38.79  0e+00\r\n    77594632      19398658   float     sum   1999.2   38.81   38.81  0e+00   1999.1   38.81   38.81  0e+00\r\n    78643208      19660802   float     sum   2024.9   38.84   38.84  0e+00   2023.3   38.87   38.87  0e+00\r\n    79691784      19922946   float     sum   2140.6   37.23   37.23  0e+00   2139.8   37.24   37.24  0e+00\r\n    80740360      20185090   float     sum   2167.3   37.25   37.25  0e+00   2166.1   37.28   37.28  0e+00\r\n    81788936      20447234   float     sum   2197.1   37.23   37.23  0e+00   2195.4   37.25   37.25  0e+00\r\n    82837512      20709378   float     sum   2224.3   37.24   37.24  0e+00   2223.9   37.25   37.25  0e+00\r\n    83886088      20971522   float     sum   2075.4   40.42   40.42  0e+00   2076.2   40.40   40.40  0e+00\r\n    84934664      21233666   float     sum   2193.7   38.72   38.72  0e+00   2191.7   38.75   38.75  0e+00\r\n    85983240      21495810   float     sum   2304.1   37.32   37.32  0e+00   2304.0   37.32   37.32  0e+00\r\n    87031816      21757954   float     sum   2336.0   37.26   37.26  0e+00   2332.1   37.32   37.32  0e+00\r\n    88080392      22020098   float     sum   2264.8   38.89   38.89  0e+00   2264.1   38.90   38.90  0e+00\r\n    89128968      22282242   float     sum   2289.7   38.93   38.93  0e+00   2285.5   39.00   39.00  0e+00\r\n    90177544      22544386   float     sum   2322.3   38.83   38.83  0e+00   2319.9   38.87   38.87  0e+00\r\n    91226120      22806530   float     sum   2349.6   38.83   38.83  0e+00   2346.1   38.88   38.88  0e+00\r\n    92274696      23068674   float     sum   2373.6   38.87   38.87  0e+00   2369.7   38.94   38.94  0e+00\r\n    93323272      23330818   float     sum   2499.7   37.33   37.33  0e+00   2498.5   37.35   37.35  0e+00\r\n    94371848      23592962   float     sum   2326.3   40.57   40.57  0e+00   2324.5   40.60   40.60  0e+00\r\n    95420424      23855106   float     sum   2455.4   38.86   38.86  0e+00   2452.3   38.91   38.91  0e+00\r\n    96469000      24117250   float     sum   2478.8   38.92   38.92  0e+00   2478.5   38.92   38.92  0e+00\r\n    97517576      24379394   float     sum   2398.4   40.66   40.66  0e+00   2402.4   40.59   40.59  0e+00\r\n    98566152      24641538   float     sum   2635.1   37.41   37.41  0e+00   2630.0   37.48   37.48  0e+00\r\n    99614728      24903682   float     sum   2769.1   35.97   35.97  0e+00   2766.5   36.01   36.01  0e+00\r\n   100663304      25165826   float     sum   2253.1   44.68   44.68  0e+00   2253.7   44.67   44.67  0e+00\r\n   101711880      25427970   float     sum   2276.9   44.67   44.67  0e+00   2274.8   44.71   44.71  0e+00\r\n   102760456      25690114   float     sum   2411.1   42.62   42.62  0e+00   2410.8   42.62   42.62  0e+00\r\n   103809032      25952258   float     sum   2546.9   40.76   40.76  0e+00   2548.4   40.73   40.73  0e+00\r\n   104857608      26214402   float     sum   2569.5   40.81   40.81  0e+00   2573.8   40.74   40.74  0e+00\r\n   105906184      26476546   float     sum   2486.3   42.60   42.60  0e+00   2483.1   42.65   42.65  0e+00\r\n   106954760      26738690   float     sum   2624.7   40.75   40.75  0e+00   2625.0   40.75   40.75  0e+00\r\n   108003336      27000834   float     sum   2649.5   40.76   40.76  0e+00   2647.9   40.79   40.79  0e+00\r\n   109051912      27262978   float     sum   2553.7   42.70   42.70  0e+00   2553.3   42.71   42.71  0e+00\r\n   110100488      27525122   float     sum   2691.2   40.91   40.91  0e+00   2687.1   40.97   40.97  0e+00\r\n   111149064      27787266   float     sum   2837.8   39.17   39.17  0e+00   2836.9   39.18   39.18  0e+00\r\n   112197640      28049410   float     sum   2506.7   44.76   44.76  0e+00   2508.9   44.72   44.72  0e+00\r\n   113246216      28311554   float     sum   2655.0   42.65   42.65  0e+00   2654.6   42.66   42.66  0e+00\r\n   114294792      28573698   float     sum   2676.8   42.70   42.70  0e+00   2675.6   42.72   42.72  0e+00\r\n   115343368      28835842   float     sum   2697.5   42.76   42.76  0e+00   2689.4   42.89   42.89  0e+00\r\n   116391944      29097986   float     sum   2842.8   40.94   40.94  0e+00   2846.4   40.89   40.89  0e+00\r\n   117440520      29360130   float     sum   2621.1   44.81   44.81  0e+00   2618.9   44.84   44.84  0e+00\r\n   118489096      29622274   float     sum   2777.0   42.67   42.67  0e+00   2774.3   42.71   42.71  0e+00\r\n   119537672      29884418   float     sum   2795.5   42.76   42.76  0e+00   2796.7   42.74   42.74  0e+00\r\n   120586248      30146562   float     sum   2946.1   40.93   40.93  0e+00   2945.9   40.93   40.93  0e+00\r\n   121634824      30408706   float     sum   2712.3   44.85   44.85  0e+00   2714.7   44.81   44.81  0e+00\r\n   122683400      30670850   float     sum   2861.5   42.87   42.87  0e+00   2865.6   42.81   42.81  0e+00\r\n   123731976      30932994   float     sum   2749.9   45.00   45.00  0e+00   2752.6   44.95   44.95  0e+00\r\n   124780552      31195138   float     sum   2778.3   44.91   44.91  0e+00   2779.9   44.89   44.89  0e+00\r\n   125829128      31457282   float     sum   2797.9   44.97   44.97  0e+00   2796.1   45.00   45.00  0e+00\r\n   126877704      31719426   float     sum   2822.8   44.95   44.95  0e+00   2823.7   44.93   44.93  0e+00\r\n   127926280      31981570   float     sum   2838.3   45.07   45.07  0e+00   2845.2   44.96   44.96  0e+00\r\n   128974856      32243714   float     sum   2862.4   45.06   45.06  0e+00   2864.9   45.02   45.02  0e+00\r\n   130023432      32505858   float     sum   2887.1   45.04   45.04  0e+00   2891.1   44.97   44.97  0e+00\r\n   131072008      32768002   float     sum   2907.2   45.08   45.08  0e+00   2913.2   44.99   44.99  0e+00\r\n   132120584      33030146   float     sum   2931.8   45.07   45.07  0e+00   2937.5   44.98   44.98  0e+00\r\n   133169160      33292290   float     sum   2955.3   45.06   45.06  0e+00   2959.4   45.00   45.00  0e+00\r\n# Out of bounds values : 0 OK\r\n# Avg bus bandwidth    : 35.5133 \r\n#\r\n\r\n```\r\n", "comments": ["i let it run with `NCCL_DEBUG` = `INFO` it gives following extra info:\r\n```bash\r\ntf-run:2950:3375 [1] NCCL INFO Setting affinity for GPU 1 to ffff0000,ffff0000\r\ntf-run:2950:3374 [0] NCCL INFO Setting affinity for GPU 0 to ffff,0000ffff\r\ntf-run:2950:3374 [0] NCCL INFO Channel 00 :    0   1\r\ntf-run:2950:3374 [0] NCCL INFO Channel 01 :    0   1\r\ntf-run:2950:3374 [0] NCCL INFO Channel 02 :    0   1\r\ntf-run:2950:3374 [0] NCCL INFO Channel 03 :    0   1\r\ntf-run:2950:3374 [0] NCCL INFO Ring 00 : 0[0] -> 1[1] via P2P/direct pointer\r\ntf-run:2950:3375 [1] NCCL INFO Ring 00 : 1[1] -> 0[0] via P2P/direct pointer\r\ntf-run:2950:3374 [0] NCCL INFO Ring 01 : 0[0] -> 1[1] via P2P/direct pointer\r\ntf-run:2950:3375 [1] NCCL INFO Ring 01 : 1[1] -> 0[0] via P2P/direct pointer\r\n\r\ntf-run:2950:3374 [0] bazel-out/k8-py2-opt/bin/external/nccl_archive/_virtual_includes/include_hdrs/alloc.h:40 NCCL WARN Cuda failure 'out of memory'\r\ntf-run:2950:3374 [0] NCCL INFO external/nccl_archive/src/transport/p2p.cc:521 -> 1\r\ntf-run:2950:3374 [0] NCCL INFO external/nccl_archive/src/init.cc:339 -> 1\r\ntf-run:2950:3374 [0] NCCL INFO external/nccl_archive/src/init.cc:649 -> 1\r\ntf-run:2950:3374 [0] NCCL INFO external/nccl_archive/src/init.cc:814 -> 1\r\ntf-run:2950:3374 [0] NCCL INFO external/nccl_archive/src/init.cc:950 -> 1\r\ntf-run:2950:3374 [0] NCCL INFO external/nccl_archive/src/misc/group.cc:69 -> 1 [Async thread]\r\n2020-02-06 14:10:45.228124: W tensorflow/core/framework/op_kernel.cc:1655] OP_REQUIRES failed at nccl_ops.cc:104 : Internal: unhandled cuda error\r\n2020-02-06 14:10:45.228167: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Internal: unhandled cuda error\r\n         [[{{node Adam/NcclAllReduce}}]]\r\n         [[Identity_2/_60]]\r\n2020-02-06 14:10:45.228204: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Internal: unhandled cuda error\r\n         [[{{node Adam/NcclAllReduce}}]]\r\n         [[GroupCrossDeviceControlEdges_0/Adam/Adam/update_1_1/Const/_39]]\r\n2020-02-06 14:10:45.228228: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Internal: unhandled cuda error\r\n         [[{{node Adam/NcclAllReduce}}]]\r\n2020-02-06 14:10:45.228328: W tensorflow/core/framework/op_kernel.cc:1655] OP_REQUIRES failed at nccl_ops.cc:104 : Internal: unhandled cuda error\r\n\r\ntf-run:2950:3375 [1] bazel-out/k8-py2-opt/bin/external/nccl_archive/_virtual_includes/include_hdrs/alloc.h:40 NCCL WARN Cuda failure 'out of memory'\r\ntf-run:2950:3375 [1] NCCL INFO external/nccl_archive/src/transport/p2p.cc:521 -> 1\r\ntf-run:2950:3375 [1] NCCL INFO external/nccl_archive/src/init.cc:339 -> 1\r\ntf-run:2950:3375 [1] NCCL INFO external/nccl_archive/src/init.cc:649 -> 1\r\ntf-run:2950:3375 [1] NCCL INFO external/nccl_archive/src/init.cc:814 -> 1\r\ntf-run:2950:3375 [1] NCCL INFO external/nccl_archive/src/init.cc:950 -> 1\r\ntf-run:2950:3375 [1] NCCL INFO external/nccl_archive/src/misc/group.cc:69 -> 1 [Async thread]\r\n\r\n```", "Same issue here. Running ubuntu 18.04 x64 with 4 2080ti by 2 nvlinks. The only way I can do is switching to  cross_device_ops=tf.distribute.HierarchicalCopyAllReduce().", "The log with NCCL_DEBUG = INFO suggests it's out of memory. ", "@crccw but it happens right at the beginning with a fresh booted system? there should be more than enough memory left. changing the batch size didn't chance anything aswell. \r\nwhat would you suggest?", "In my case, setting environment variable \"TF_FORCE_GPU_ALLOW_GROWTH=true\" can train the model without crash.", "Thanks for sharing your solution. There're more details on https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth\r\n\r\nYou can also use logical GPU as described in the guide. ", "@supasitk thanks for your tipp. It solves my problem. \r\n\r\n@crccw for me this sounds more like a workaround to a problem than a good solution? but i won't reopen the issue at this point. I can live with that. ", "I found that this is still an issue. Training with four 2080 Ti GPUs crashes with the following error:\r\n\r\n```\r\nUsing strategy: <tensorflow.python.distribute.mirrored_strategy.MirroredStrategy object at 0x7fd76aa625c0>\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 226, in <module>\r\n    train(args=args, run=run)\r\n  File \"train.py\", line 178, in train\r\n    distributed_train_step((source[0], target[0]), strat=strategy)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\", line 828, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\", line 895, in _call\r\n    filtered_flat_args, self._concrete_stateful_fn.captured_inputs)  # pylint: disable=protected-access\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 1919, in _call_flat\r\n    ctx, args, cancellation_manager=cancellation_manager))\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 560, in call\r\n    ctx=ctx)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\", line 60, in quick_execute\r\n    inputs, attrs, num_outputs)\r\ntensorflow.python.framework.errors_impl.InternalError: 5 root error(s) found.\r\n  (0) Internal:  NCCL: unhandled system error. Set NCCL_DEBUG=WARN for detail.\r\n\t [[{{node StatefulPartitionedCall/Adam_3/NcclAllReduce}}]]\r\n\t [[StatefulPartitionedCall/Identity_18/_240]]\r\n  (1) Internal:  NCCL: unhandled system error. Set NCCL_DEBUG=WARN for detail.\r\n\t [[{{node StatefulPartitionedCall/Adam_3/NcclAllReduce}}]]\r\n  (2) Internal:  NCCL: unhandled system error. Set NCCL_DEBUG=WARN for detail.\r\n\t [[{{node StatefulPartitionedCall/Adam_3/NcclAllReduce}}]]\r\n\t [[StatefulPartitionedCall/Adam_3/Adam/group_deps/_123]]\r\n  (3) Internal:  NCCL: unhandled system error. Set NCCL_DEBUG=WARN for detail.\r\n\t [[{{node StatefulPartitionedCall/Adam_3/NcclAllReduce}}]]\r\n\t [[StatefulPartitionedCall/Adam_3/Adam/group_deps/_127]]\r\n  (4) Internal:  NCCL: unhandled system error. Set NCCL_DEBUG=WARN for detail.\r\n\t [[{{node StatefulPartitionedCall/Adam_3/NcclAllReduce}}]]\r\n\t [[StatefulPartitionedCall/Adam/Adam/group_deps/_179]]\r\n0 successful operations.\r\n0 derived errors ignored. [Op:__inference_distributed_train_step_79361]\r\n\r\nFunction call stack:\r\ndistributed_train_step -> distributed_train_step -> distributed_train_step -> distributed_train_step -> distributed_train_step\r\n```\r\n\r\nSetting `strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.ReductionToOneDevice())` works but slows down training.\r\n\r\nAre there any updates on this?", "@Yannik1337  I was facing the same issue. But below worked for multiple gpus\r\n`strategy = tf.distribute.MirroredStrategy(devices = gpu_devices_list, cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())`.", "> I found that this is still an issue. Training with four 2080 Ti GPUs crashes with the following error:\r\n> \r\n> ```\r\n> Using strategy: <tensorflow.python.distribute.mirrored_strategy.MirroredStrategy object at 0x7fd76aa625c0>\r\n> Traceback (most recent call last):\r\n>   File \"/home/stud/janetzky/musikseminar/custom_scripts/train.py\", line 226, in <module>\r\n>     train(args=args, run=run)\r\n>   File \"/home/stud/janetzky/musikseminar/custom_scripts/train.py\", line 178, in train\r\n>     distributed_train_step((source[0], target[0]), strat=strategy)\r\n>   File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\", line 828, in __call__\r\n>     result = self._call(*args, **kwds)\r\n>   File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\", line 895, in _call\r\n>     filtered_flat_args, self._concrete_stateful_fn.captured_inputs)  # pylint: disable=protected-access\r\n>   File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 1919, in _call_flat\r\n>     ctx, args, cancellation_manager=cancellation_manager))\r\n>   File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 560, in call\r\n>     ctx=ctx)\r\n>   File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\", line 60, in quick_execute\r\n>     inputs, attrs, num_outputs)\r\n> tensorflow.python.framework.errors_impl.InternalError: 5 root error(s) found.\r\n>   (0) Internal:  NCCL: unhandled system error. Set NCCL_DEBUG=WARN for detail.\r\n> \t [[{{node StatefulPartitionedCall/Adam_3/NcclAllReduce}}]]\r\n> \t [[StatefulPartitionedCall/Identity_18/_240]]\r\n>   (1) Internal:  NCCL: unhandled system error. Set NCCL_DEBUG=WARN for detail.\r\n> \t [[{{node StatefulPartitionedCall/Adam_3/NcclAllReduce}}]]\r\n>   (2) Internal:  NCCL: unhandled system error. Set NCCL_DEBUG=WARN for detail.\r\n> \t [[{{node StatefulPartitionedCall/Adam_3/NcclAllReduce}}]]\r\n> \t [[StatefulPartitionedCall/Adam_3/Adam/group_deps/_123]]\r\n>   (3) Internal:  NCCL: unhandled system error. Set NCCL_DEBUG=WARN for detail.\r\n> \t [[{{node StatefulPartitionedCall/Adam_3/NcclAllReduce}}]]\r\n> \t [[StatefulPartitionedCall/Adam_3/Adam/group_deps/_127]]\r\n>   (4) Internal:  NCCL: unhandled system error. Set NCCL_DEBUG=WARN for detail.\r\n> \t [[{{node StatefulPartitionedCall/Adam_3/NcclAllReduce}}]]\r\n> \t [[StatefulPartitionedCall/Adam/Adam/group_deps/_179]]\r\n> 0 successful operations.\r\n> 0 derived errors ignored. [Op:__inference_distributed_train_step_79361]\r\n> \r\n> Function call stack:\r\n> distributed_train_step -> distributed_train_step -> distributed_train_step -> distributed_train_step -> distributed_train_step\r\n> ```\r\n> \r\n> Setting `strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.ReductionToOneDevice())` works but slows down training.\r\n> \r\n> Are there any updates on this?\r\n\r\nAre you using WSL? That doesn't work for NCCL", "> Are you using WSL? That doesn't work for NCCL\r\n\r\nI assume that you mean Windows Subsystem Linux. If that is correct, then, no, I am running on Ubuntu in a Docker environment.\r\nHowever, I have not checked the code for a couple of months. Once I found that using `strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())` worked, I proceeded with experimentation.\r\n\r\nWhat I want to mention is that I was also using the Weights&Biases logging library. If I activated logging, I had to set `strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.ReductionToOneDevice())` instead.\r\n\r\n", "@Yannik1337 @sureshbhusare @crccw  These options still lead to slowdowns since NCCL is not being used. \r\n\r\n\r\n", "> @Yannik1337 @sureshbhusare @crccw These options still lead to slowdowns since NCCL is not being used.\r\n\r\nOn another issue, I found it mentioned to try using a `MultiWorkerMirroredStrategy` on a single device with multiple GPUs (see here: https://github.com/tensorflow/tensorflow/issues/41898#issuecomment-668786507). Have you tried that (though it's proposed in a different context).", "Experiencing similar errors on ai platform with A100s. Has this not been resolved or am I nuts?\r\n\r\n<img width=\"755\" alt=\"Screen Shot 2022-03-25 at 4 02 38 PM\" src=\"https://user-images.githubusercontent.com/42384776/160212811-e36a6874-86dc-4b62-bc4e-5683286f8341.png\">\r\n ", "> > @Yannik1337 @sureshbhusare @crccw These options still lead to slowdowns since NCCL is not being used.\r\n> \r\n> On another issue, I found it mentioned to try using a `MultiWorkerMirroredStrategy` on a single device with multiple GPUs (see here: [#41898 (comment)](https://github.com/tensorflow/tensorflow/issues/41898#issuecomment-668786507)). Have you tried that (though it's proposed in a different context).\r\n\r\nCan confirm that `MultiWorkerMirroredStrategy` works but `MirroredStrategy` don't.", "I recently successfully used MultiWorkerMirroredStrategy\r\non an EC2 instance with multiple GPUs and it worked. I used tensor-flow\r\nversion 2.8.0", "@all Dont use TF stuff for distributed training. Just use Horovod. You wont\nregret it.\n\nOn Fri, Mar 25, 2022 at 8:19 PM Suresh Bhusare ***@***.***>\nwrote:\n\n> I recently successfully used MultiWorkerMirroredStrategy\n> on an EC2 instance with multiple gpus and it worked. I used tensor-flow\n> version 2.8.0\n>\n>\n> On Fri, Mar 25, 2022 at 8:17 PM Ben Li ***@***.***> wrote:\n>\n> > @Yannik1337 <https://github.com/Yannik1337> @sureshbhusare\n> > <https://github.com/sureshbhusare> @crccw <https://github.com/crccw>\n> > These options still lead to slowdowns since NCCL is not being used.\n> >\n> > On another issue, I found it mentioned to try using a\n> > MultiWorkerMirroredStrategy on a single device with multiple GPUs (see\n> > here: #41898 (comment)\n> > <\n> https://github.com/tensorflow/tensorflow/issues/41898#issuecomment-668786507\n> >).\n> > Have you tried that (though it's proposed in a different context).\n> >\n> > Can confirm that MultiWorkerMirroredStrategy works but MirroredStrategy\n> > don't.\n> >\n> > \u2014\n> > Reply to this email directly, view it on GitHub\n> > <\n> https://github.com/tensorflow/tensorflow/issues/36510#issuecomment-1079529844\n> >,\n> > or unsubscribe\n> > <\n> https://github.com/notifications/unsubscribe-auth/AHVJPW6L6VGYQAYBGIX7RQDVBZJP7ANCNFSM4KQ4QLZA\n> >\n> > .\n> > You are receiving this because you were mentioned.Message ID:\n> > ***@***.***>\n> >\n>\n> \u2014\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/36510#issuecomment-1079530638>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/ADKT4SV4DSQFBYU2JSEDZKLVBZJ2RANCNFSM4KQ4QLZA>\n> .\n> You are receiving this because you commented.Message ID:\n> ***@***.***>\n>\n"]}, {"number": 36509, "title": "ValueError: Duplicate node name in graph", "body": "I am trying to run following code\uff08which comes from Chollet's Deep Learning with Python) on a kaggle kernel,but get an error\r\n```\r\nimport keras\r\nfrom keras import layers\r\nfrom keras import backend as K\r\nfrom keras.models import Model\r\nimport numpy as np\r\nimg_shape=(28,28,1)\r\nbatch_size=16\r\nlatent_dim=2\r\ninput_img=keras.Input(shape=img_shape)\r\nx=layers.Conv2D(32,3,padding='same',activation='relu')(input_img)\r\nx=layers.Conv2D(64,3,padding='same',activation='relu',strides=(2,2))(x)\r\nx=layers.Conv2D(64,3,padding='same',activation='relu')(x)\r\nx=layers.Conv2D(64,3,padding='same',activation='relu')(x)\r\nshape_before_flattening=K.int_shape(x)\r\nx=layers.Flatten()(x)\r\nx=layers.Dense(32,activation='relu')(x)\r\nz_mean=layers.Dense(latent_dim)(x)\r\nz_log_var=layers.Dense(latent_dim)(x)\r\ndef sampling(args):\r\n    z_mean,z_log_var=args\r\n    epsilon=K.random_normal(shape=(K.shape(z_mean)[0],latent_dim),mean=0,stddev=1)\r\n    return z_mean+K.exp(0.5*z_log_var)*epsilon\r\nz=layers.Lambda(sampling)([z_mean,z_log_var])\r\n```\r\nthe trace back is following\r\n```\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py in _create_c_op(graph, node_def, inputs, control_inputs)\r\n   1618   try:\r\n-> 1619     c_op = c_api.TF_FinishOperation(op_desc)\r\n   1620   except errors.InvalidArgumentError as e:\r\n\r\nInvalidArgumentError: Duplicate node name in graph: 'lambda_7/random_normal/shape'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-12-6c91b1ce5964> in <module>\r\n      3     epsilon=K.random_normal(shape=(K.shape(z_mean)[0],latent_dim),mean=0,stddev=1)\r\n      4     return z_mean+K.exp(0.5*z_log_var)*epsilon\r\n----> 5 z=layers.Lambda(sampling)([z_mean,z_log_var])\r\n\r\n/opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py in symbolic_fn_wrapper(*args, **kwargs)\r\n     73         if _SYMBOLIC_SCOPE.value:\r\n     74             with get_graph().as_default():\r\n---> 75                 return func(*args, **kwargs)\r\n     76         else:\r\n     77             return func(*args, **kwargs)\r\n\r\n/opt/conda/lib/python3.6/site-packages/keras/engine/base_layer.py in __call__(self, inputs, **kwargs)\r\n    504             if all([s is not None\r\n    505                     for s in to_list(input_shape)]):\r\n--> 506                 output_shape = self.compute_output_shape(input_shape)\r\n    507             else:\r\n    508                 if isinstance(input_shape, list):\r\n\r\n/opt/conda/lib/python3.6/site-packages/keras/layers/core.py in compute_output_shape(self, input_shape)\r\n    672                     xs = [K.placeholder(shape=shape, dtype=dtype)\r\n    673                           for shape, dtype in zip(input_shape, self._input_dtypes)]\r\n--> 674                     x = self.call(xs)\r\n    675                 else:\r\n    676                     x = K.placeholder(shape=input_shape, dtype=self._input_dtypes)\r\n\r\n/opt/conda/lib/python3.6/site-packages/keras/layers/core.py in call(self, inputs, mask)\r\n    714         else:\r\n    715             self._input_dtypes = K.dtype(inputs)\r\n--> 716         return self.function(inputs, **arguments)\r\n    717 \r\n    718     def compute_mask(self, inputs, mask=None):\r\n\r\n<ipython-input-12-6c91b1ce5964> in sampling(args)\r\n      1 def sampling(args):\r\n      2     z_mean,z_log_var=args\r\n----> 3     epsilon=K.random_normal(shape=(K.shape(z_mean)[0],latent_dim),mean=0,stddev=1)\r\n      4     return z_mean+K.exp(0.5*z_log_var)*epsilon\r\n      5 z=layers.Lambda(sampling)([z_mean,z_log_var])\r\n\r\n/opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py in random_normal(shape, mean, stddev, dtype, seed)\r\n   4327     with tf_ops.init_scope():\r\n   4328         return tf_keras_backend.random_normal(\r\n-> 4329             shape, mean=mean, stddev=stddev, dtype=dtype, seed=seed)\r\n   4330 \r\n   4331 \r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py in random_normal(shape, mean, stddev, dtype, seed)\r\n   5600     seed = np.random.randint(10e6)\r\n   5601   return random_ops.random_normal(\r\n-> 5602       shape, mean=mean, stddev=stddev, dtype=dtype, seed=seed)\r\n   5603 \r\n   5604 \r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/ops/random_ops.py in random_normal(shape, mean, stddev, dtype, seed, name)\r\n     67   \"\"\"\r\n     68   with ops.name_scope(name, \"random_normal\", [shape, mean, stddev]) as name:\r\n---> 69     shape_tensor = tensor_util.shape_tensor(shape)\r\n     70     mean_tensor = ops.convert_to_tensor(mean, dtype=dtype, name=\"mean\")\r\n     71     stddev_tensor = ops.convert_to_tensor(stddev, dtype=dtype, name=\"stddev\")\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/framework/tensor_util.py in shape_tensor(shape)\r\n    992       # not convertible to Tensors becasue of mixed content.\r\n    993       shape = tuple(map(tensor_shape.dimension_value, shape))\r\n--> 994   return ops.convert_to_tensor(shape, dtype=dtype, name=\"shape\")\r\n    995 \r\n    996 \r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py in convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\r\n   1312 \r\n   1313     if ret is None:\r\n-> 1314       ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n   1315 \r\n   1316     if ret is NotImplemented:\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/ops/array_ops.py in _autopacking_conversion_function(v, dtype, name, as_ref)\r\n   1366   elif dtype != inferred_dtype:\r\n   1367     v = nest.map_structure(_cast_nested_seqs_to_dtype(dtype), v)\r\n-> 1368   return _autopacking_helper(v, dtype, name or \"packed\")\r\n   1369 \r\n   1370 \r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/ops/array_ops.py in _autopacking_helper(list_or_tuple, dtype, name)\r\n   1302           elems_as_tensors.append(\r\n   1303               constant_op.constant(elem, dtype=dtype, name=str(i)))\r\n-> 1304       return gen_array_ops.pack(elems_as_tensors, name=scope)\r\n   1305     else:\r\n   1306       return converted_elems\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_array_ops.py in pack(values, axis, name)\r\n   5702   axis = _execute.make_int(axis, \"axis\")\r\n   5703   _, _, _op, _outputs = _op_def_library._apply_op_helper(\r\n-> 5704         \"Pack\", values=values, axis=axis, name=name)\r\n   5705   _result = _outputs[:]\r\n   5706   if _execute.must_record_gradient():\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/framework/op_def_library.py in _apply_op_helper(op_type_name, name, **keywords)\r\n    740       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\r\n    741                                  name=scope, input_types=input_types,\r\n--> 742                                  attrs=attr_protos, op_def=op_def)\r\n    743 \r\n    744     # `outputs` is returned as a separate return value so that the output\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py in _create_op_internal(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\r\n    593     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\r\n    594         op_type, inputs, dtypes, input_types, name, attrs, op_def,\r\n--> 595         compute_device)\r\n    596 \r\n    597   def capture(self, tensor, name=None, shape=None):\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py in _create_op_internal(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\r\n   3320           input_types=input_types,\r\n   3321           original_op=self._default_original_op,\r\n-> 3322           op_def=op_def)\r\n   3323       self._create_op_helper(ret, compute_device=compute_device)\r\n   3324     return ret\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py in __init__(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\r\n   1784           op_def, inputs, node_def.attr)\r\n   1785       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\r\n-> 1786                                 control_input_ops)\r\n   1787       name = compat.as_str(node_def.name)\r\n   1788     # pylint: enable=protected-access\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py in _create_c_op(graph, node_def, inputs, control_inputs)\r\n   1620   except errors.InvalidArgumentError as e:\r\n   1621     # Convert to ValueError for backwards compatibility.\r\n-> 1622     raise ValueError(str(e))\r\n   1623 \r\n   1624   return c_op\r\n\r\nValueError: Duplicate node name in graph: 'lambda_7/random_normal/shape'\r\n```\r\n\r\nThis is quite strange as I can run these codes normally on my laptop.I wonder whether it comes \r\nfrom difference of environment,but I don't know how to check the environment of kaggle kernel\r\n", "comments": ["@AIChuY \r\n\r\nWhich version of  TensorFlow you are using. I am not seeing any issue with Tensor Flow 1.14 and 1.15. Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/9fc7369e207dd371756e8ece973d9d2a/untitled627.ipynb).If you are using TF 2.X you should use tf.keras instead.Thanks!", "> @AIChuY\r\n> \r\n> Which version of TensorFlow you are using. I am not seeing any issue with Tensor Flow 1.14 and 1.15. Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/9fc7369e207dd371756e8ece973d9d2a/untitled627.ipynb).If you are using TF 2.X you should use tf.keras instead.Thanks!\r\n\r\nIt seems that kaggle kernel is using a tensorflow 2.1.0. I have managed to rewrite the codes and \r\neverything is ok now.\r\nThanks for your help!", "> > @AIChuY\r\n> > Which version of TensorFlow you are using. I am not seeing any issue with Tensor Flow 1.14 and 1.15. Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/9fc7369e207dd371756e8ece973d9d2a/untitled627.ipynb).If you are using TF 2.X you should use tf.keras instead.Thanks!\r\n> \r\n> It seems that kaggle kernel is using a tensorflow 2.1.0. I have managed to rewrite the codes and\r\n> everything is ok now.\r\n> Thanks for your help!\r\n\r\nI have the seem question as you. Could you please post your new codes?", "> > > @AIChuY\r\n> > > Which version of TensorFlow you are using. I am not seeing any issue with Tensor Flow 1.14 and 1.15. Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/9fc7369e207dd371756e8ece973d9d2a/untitled627.ipynb).If you are using TF 2.X you should use tf.keras instead.Thanks!\r\n> > \r\n> > \r\n> > It seems that kaggle kernel is using a tensorflow 2.1.0. I have managed to rewrite the codes and\r\n> > everything is ok now.\r\n> > Thanks for your help!\r\n> \r\n> I have the seem question as you. Could you please post your new codes?\r\n\r\nYou need to replace the line you import the keras backend with:\r\n```\r\nfrom tensorflow.keras import backend as K\r\n```"]}, {"number": 36508, "title": "keras LSTM Fail to find the dnn implementation ", "body": "**System information**\r\n- CUDA/cuDNN version: 10.1\r\n- GPU model and memory: GeForce RTX 2080\r\n- TF 2.1.0:\r\n\r\nuncommenting the LSTM layer will yield the following error:\r\n\r\n```\r\nUnknownError:  [_Derived_]  Fail to find the dnn implementation.\r\n\t [[{{node CudnnRNN}}]]\r\n\t [[sequential_6/bidirectional_2/backward_lstm_3/StatefulPartitionedCall]]\r\n\t [[Reshape_11/_38]] [Op:__inference_distributed_function_39046]\r\n```\r\n\r\nworking code:\r\n```\r\nmodel = tf.keras.Sequential([\r\n    tf.keras.layers.Embedding(encoder.vocab_size, 64),\r\n    #tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\r\n    tf.keras.layers.Dense(64, activation='relu'),\r\n    tf.keras.layers.Dense(1, activation='sigmoid')\r\n])\r\nmodel.compile(loss='binary_crossentropy',\r\n              optimizer=tf.keras.optimizers.Adam(1e-4),\r\n              metrics=['accuracy'])\r\nhistory = model.fit(train_dataset, epochs=10,\r\n                    validation_data=test_dataset, \r\n                    validation_steps=30)\r\n```", "comments": ["@ARozental  Could you please provide us with supporting files and complete stand alone code to replicate the issue in our environment.", "@Saduf2019 \r\nthe code is from one of the TF official tutorials and the working version is attached here, uncommenting the LSTM line will raise the error:\r\n\r\n```\r\nfrom __future__ import absolute_import, division, print_function, unicode_literals\r\nimport os\r\nimport tensorflow_datasets as tfds\r\nimport tensorflow as tf\r\nfrom tensorflow.python.client import device_lib\r\n\r\ndataset, info = tfds.load('imdb_reviews/subwords8k', with_info=True,\r\n                          as_supervised=True)\r\ntrain_dataset, test_dataset = dataset['train'], dataset['test']\r\n\r\nBUFFER_SIZE = 10000\r\nBATCH_SIZE = 64\r\n\r\ntrain_dataset = train_dataset.shuffle(BUFFER_SIZE)\r\ntrain_dataset = train_dataset.padded_batch(BATCH_SIZE, train_dataset.output_shapes)\r\n\r\ntest_dataset = test_dataset.padded_batch(BATCH_SIZE, test_dataset.output_shapes)\r\nencoder = info.features['text'].encoder\r\n\r\n\r\nmodel = tf.keras.Sequential([\r\n    tf.keras.layers.Embedding(encoder.vocab_size, 64),\r\n    #tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\r\n    tf.keras.layers.Dense(64, activation='relu'),\r\n    tf.keras.layers.Dense(1, activation='sigmoid')\r\n])\r\nmodel.compile(loss='binary_crossentropy',\r\n              optimizer=tf.keras.optimizers.Adam(1e-4),\r\n              metrics=['accuracy'])\r\nhistory = model.fit(train_dataset, epochs=10,\r\n                    validation_data=test_dataset, \r\n                    validation_steps=30)\r\n```\r\n \r\nAlso, I use ubuntu 18.04.\r\nThanks. ", "@alonRozental  I ran the code [on nightly] after un-commenting the LSTM line and did not face any issues, please find the gist [here](https://colab.research.google.com/gist/Saduf2019/f1b1a090b3308b7ae5539594bf8bbddb/36508.ipynb)", "@Saduf2019  I'm running TF 2.1.0.\r\nI don't think the problem exists in TF1 which is used in the notebook.\r\nalso making the following change makes the code work:\r\n\r\n```\r\n    #tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\r\n    tf.keras.layers.Bidirectional(tf.keras.layers.RNN(tf.keras.layers.LSTMCell(64))),\r\n```\r\nI would think that those 2 lines should do the same thing (please correct me if I'm wrong) but it seems only the second line works. ", "@ARozental I ran the code on nightly ['2.2.0-dev20200210'] and on tensorflow==2.1.0, un-commenting the LSTM line as requested by you and did not face any issues,  please find the gist of 2.1.0 [here](https://colab.research.google.com/gist/Saduf2019/6e154d2e10a11bf658ce742182066fd1/latest.ipynb)", "@Saduf2019 than I don't know how to replicate it on Colab, maybe it only occurs with specific hardware (ti 2080). In anyway, can you confirm that those 2 lines should do the exact same thing? if this is indeed the case we can look at the difference (that shouldn't exist) between the 2 implementations to find the bug. ", "me too\r\n```\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_ALLOC_FAILED\r\n2020-02-12 04:48:50.916938: W tensorflow/core/framework/op_kernel.cc:1655] OP_REQUIRES failed at cudnn_rnn_ops.cc:1510 : Unknown: Fail to find the dnn implementation.\r\n2020-02-12 04:48:50.923690: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Unknown: Fail to find the dnn implementation.\r\n         [[{{node CudnnRNN}}]]\r\n2020-02-12 04:48:50.931195: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Unknown: {{function_node __inference_cudnn_lstm_with_fallback_1954_specialized_for_sequential_1_lstm_StatefulPartitionedCall_at___inference_distributed_function_2139}} {{function_node __inference_cudnn_lstm_with_fallback_1954_specialized_for_sequential_1_lstm_StatefulPartitionedCall_at___inference_distributed_function_2139}} Fail to find the dnn implementation.\r\n         [[{{node CudnnRNN}}]]\r\n         [[sequential_1/lstm/StatefulPartitionedCall]]\r\n```", "@Lay4U @ARozental Please use the below code while importing tensorflow and let me know if the issue still persists. Thanks!\r\n\r\n```\r\nimport tensorflow as tf\r\nphysical_devices = tf.config.list_physical_devices('GPU')\r\ntf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\r\n```", "@gowthamkpr It doesn't help", "I confirm that it does not help", "I confirm that it does not help\r\n", "> @Saduf2019 I'm running TF 2.1.0.\r\n> I don't think the problem exists in TF1 which is used in the notebook.\r\n> also making the following change makes the code work:\r\n> \r\n> ```\r\n>     #tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\r\n>     tf.keras.layers.Bidirectional(tf.keras.layers.RNN(tf.keras.layers.LSTMCell(64))),\r\n> ```\r\n> \r\n> I would think that those 2 lines should do the same thing (please correct me if I'm wrong) but it seems only the second line works.\r\n\r\nThose two line will build different graph under the hood, but should produce same math result. \r\nThe first line will use cudnn kernel on GPU if GPU is available, whereas the second line will use generic kernel on GPU. \r\n\r\nAdding @houtoms from Nvidia side. Is there any recent change to the kernel CudnnRNN?", "I wasn't able to produce this issue on a GPU colab as well. I think this somehow indicate its a environment issue, we probably should check the cuda kernel version.", "From the error log, the cuDNN didn't successfully create the handler. So, it seems not to be a CuDNN RNN issue. Can you try some convolution examples to see if the cuDNN is able to create handler? @ARozental ", "I resolved this problem by reinstalling CUDA, cuDNN and tensorflow. I followed the instructions at tensorflow website https://www.tensorflow.org/install/gpu , but took CUDA 10.2 and did not specify the version of cuDNN  and version of libnvinfer (so I suppose it took the latest version).  I also updated the PATH and removed the old versions of CUDA", "Thanks @olalakul for the sharing. I think this is an env config issue, and reconfig the runtime (or virtual env) should fix the issue.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36508\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36508\">No</a>\n", "> @Lay4U @ARozental Please use the below code while importing tensorflow and let me know if the issue still persists. Thanks!\r\n> \r\n> ```\r\n> import tensorflow as tf\r\n> physical_devices = tf.config.list_physical_devices('GPU')\r\n> tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\r\n> ```\r\n\r\nthis resolved the issue in my case.. Using:\r\n\r\n- CUDA 12.2\r\n- tf.__version__ is 2.1.0\r\n- tf.keras.__version__ is: 2.2.4-tf\r\n- Python 3.7.4\r\n- cuDNN v7.6.5 (November 18th, 2019), for CUDA 10.2\r\n\r\n", "> \r\n> \r\n> @Lay4U @ARozental Please use the below code while importing tensorflow and let me know if the issue still persists. Thanks!\r\n> \r\n> ```\r\n> import tensorflow as tf\r\n> physical_devices = tf.config.list_physical_devices('GPU')\r\n> tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\r\n> ```\r\n\r\nRan into this same issue and this option also fixed it for me (fresh install of Anaconda 4.8.2, tensorflow-gpu 2.1.0 installed via Conda). Thanks!", "> > @Lay4U @ARozental Please use the below code while importing tensorflow and let me know if the issue still persists. Thanks!\r\n> > ```\r\n> > import tensorflow as tf\r\n> > physical_devices = tf.config.list_physical_devices('GPU')\r\n> > tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\r\n> > ```\r\n> \r\n> Ran into this same issue and this option also fixed it for me (fresh install of Anaconda 4.8.2, tensorflow-gpu 2.1.0 installed via Conda). Thanks!\r\n\r\nAre you using windows or linux?", "@talhaanwarch sorry, just noticed this question was to me. This is on Windows 10.", "I got the same problem, which is solved by this. Thanks a lot!\r\n> @Lay4U @ARozental Please use the below code while importing tensorflow and let me know if the issue still persists. Thanks!\r\n> \r\n> ```\r\n> import tensorflow as tf\r\n> physical_devices = tf.config.list_physical_devices('GPU')\r\n> tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\r\n> ```\r\n\r\n", "Just a heads up I had this error but I noticed in the output this error as well\r\n```\r\nLoaded runtime CuDNN library: 7.1.3 but source was compiled with: 7.6.4.  CuDNN library major and minor version needs to match or have higher minor version in case of CuDNN 7.0 or later version.\r\n```\r\n\r\nResolved by updating my conda env with\r\n```\r\nconda install -c anaconda cudnn\r\n```", "> @Lay4U @ARozental Please use the below code while importing tensorflow and let me know if the issue still persists. Thanks!\r\n> \r\n> ```\r\n> import tensorflow as tf\r\n> physical_devices = tf.config.list_physical_devices('GPU')\r\n> tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\r\n> ```\r\n\r\nworked for me with\r\n    CUDA/cuDNN version: 10.1\r\n    GPU model and memory: GeForce RTX 2080 Ti\r\n    TF 2.1.0:\r\n", "I have similar issues. The memory_growth trick worked in the past but seems to have no effect now. GPU is detected and used, but the dnn implementation error is constant.\r\n\r\nFail to find the dnn implementation\r\n\r\nUbuntu 20.04 or 18.04\r\nTF2.2 or 2.1\r\nCUDA/cuDNN version: 10.2\r\nGPU model and memory: GeForce RTX 2080 Super\r\n\r\nI cannot get cuda 10.1 properly as the GPU guide on tensorflow website suggest.\r\nUpon running it, one of the packages bumps the NVIDIA driver to 440 and subsequently cuda to 10.2\r\n\r\nWas working until last week, so some tampering from my side must have helped break it. Now even with a clean install, drivers purge and re-install, etc, nothing works. :/", "> I have similar issues. The memory_growth trick worked in the past but seems to have no effect now. GPU is detected and used, but the dnn implementation error is constant.\r\n> \r\n> Fail to find the dnn implementation\r\n> \r\n> Ubuntu 20.04 or 18.04\r\n> TF2.2 or 2.1\r\n> CUDA/cuDNN version: 10.2\r\n> GPU model and memory: GeForce RTX 2080 Super\r\n> \r\n> I cannot get cuda 10.1 properly as the GPU guide on tensorflow website suggest.\r\n> Upon running it, one of the packages bumps the NVIDIA driver to 440 and subsequently cuda to 10.2\r\n> \r\n> Was working until last week, so some tampering from my side must have helped break it. Now even with a clean install, drivers purge and re-install, etc, nothing works. :/\r\n\r\nI used the steps in the following link in order to get cuda version 10.1 (instead of 10.2) on my Ubuntu 18.04\r\nhttps://askubuntu.com/questions/1077061/how-do-i-install-nvidia-and-cuda-drivers-into-ubuntu\r\n", "I do have 10.1 installed and loaded but TF fails the same way.\r\nIronically, the line before failure is \r\n```\r\nSuccessfully opened dynamic library libcudnn.so.7\r\n```\r\n\r\nand the only error I get is when training, our old friend\r\n```\r\ntensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\r\ntensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at cudnn_rnn_ops.cc:1510 : Unknown: Fail to find the dnn implementation.\r\n```\r\n", "> @Lay4U @ARozental Please use the below code while importing tensorflow and let me know if the issue still persists. Thanks!\r\n> \r\n> ```\r\n> import tensorflow as tf\r\n> physical_devices = tf.config.list_physical_devices('GPU')\r\n> tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\r\n> ```\r\n\r\nJust wanted to response, to say thank you. That works for me, as well.\r\n\r\nOS: Windows 10\r\nCUDA/cuDNN: 10.1\r\nGPU: GeForce RTX 2060 Super 8GB\r\nTF: 2.2.0", "```python\r\ngpus = tf.config.experimental.list_physical_devices(device_type='GPU')\r\ntf.config.experimental.set_visible_devices(devices=gpus[1], device_type='GPU')\r\ntf.config.experimental.set_memory_growth(device=gpus[1], enable=True)\r\n````\r\n\r\nabove work for me.", "Ok I managed to make it work after fighting with CUDA 10.1 and 10.2 (10.2 works nice with 2.3 nightly) for a while, environments, OS and everything.\r\n\r\nNarrowed it to a seeming harmless line\r\n\r\nI was running `tf.test.gpu_device_name()` to check there was a GPU and print its name. That command when run at any time makes the model fail on train with the mentioned error: `Unknown: Fail to find the dnn implementation`\r\n\r\nThe `tf.config.experimental.set_visible_devices` command that @shaoeChen mentioned didn't change anything for me so I removed it.\r\n\r\nI managed to make it work more reliably running this right after importing tensorflow (and other libs, but I don't think it changes anything)\r\n```\r\ngpus = tf.config.experimental.list_physical_devices(device_type='GPU')\r\ntf.config.experimental.set_memory_growth(device=gpus[0], enable=True)\r\n```\r\n\r\nIs this a known bug or some unintended behaviour?", "> Just a heads up I had this error but I noticed in the output this error as well\r\n> \r\n> ```\r\n> Loaded runtime CuDNN library: 7.1.3 but source was compiled with: 7.6.4.  CuDNN library major and minor version needs to match or have higher minor version in case of CuDNN 7.0 or later version.\r\n> ```\r\n> \r\n> Resolved by updating my conda env with\r\n> \r\n> ```\r\n> conda install -c anaconda cudnn\r\n> ```\r\n\r\nYes, simply works! Thank you.", "Why this is closed? I got the same error in ubuntu 20.04 jupyterlab '2.1.5' tensorflow 2.2.0 (with GPU) CUDA Version 10.1.105 when building a model in jupyter-lab using a kernel having tensorflow 2.2.0\r\n\r\nOnly thing that helped is the workaround presented earlier:\r\n\r\n```\r\nfrom tensorflow.keras.layers import RNN, LSTMCell\r\ndef build_model(feature_count=feature_count, seq_len=seq_len):\r\n    inputs = tensorflow.keras.Input(shape=(seq_len, feature_count))\r\n    X = RNN(LSTMCell(units=seq_len), input_shape=(seq_len, feature_count), return_sequences=True, stateful=False)(inputs)\r\n\r\n```\r\nterveisin, Markus", "> @Lay4U @ARozental Please use the below code while importing TensorFlow and let me know if the issue still persists. Thanks!\r\n> \r\n> ```\r\n> import tensorflow as tf\r\n> physical_devices = tf.config.list_physical_devices('GPU')\r\n> tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\r\n> ```\r\n\r\nHello,\r\nThanks @gowthamkpr \ud83d\udc4d \r\nThis solved my problem. My configuration is:\r\n**OS**: Windows 10 x64\r\n**Python** : 3.6\r\n**TensorFlow-GPU** : 2.2.0\r\n**Cuda** : 10.1\r\n**Cudnn** : 7.6.5", "> ```\r\n> conda install -c anaconda cudnn\r\n> ```\r\n\r\nThis worked for us when getting\r\n```\r\ntensorflow.python.framework.errors_impl.UnknownError:  [_Derived_]  Fail to find the dnn implementation.\r\n```\r\n\r\nThanks @ElliotVilhelm ", "> ```python\r\n> gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\r\n> tf.config.experimental.set_visible_devices(devices=gpus[1], device_type='GPU')\r\n> tf.config.experimental.set_memory_growth(device=gpus[1], enable=True)\r\n> ```\r\n> \r\n> above work for me.\r\n\r\nalso worked for me (tf 2.3). Does this mean CUDA was not installed correctly or is this a tensorflow bug?", "> @Lay4U @ARozental Please use the below code while importing tensorflow and let me know if the issue still persists. Thanks!\r\n> \r\n> ```\r\n> import tensorflow as tf\r\n> physical_devices = tf.config.list_physical_devices('GPU')\r\n> tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\r\n> ```\r\n\r\nWorked for me. tks.\r\nRunning BiLSTM on TF2.1 with two 2080S ", "> @Lay4U @ARozental Please use the below code while importing tensorflow and let me know if the issue still persists. Thanks!\r\n> \r\n> ```\r\n> import tensorflow as tf\r\n> physical_devices = tf.config.list_physical_devices('GPU')\r\n> tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\r\n> ```\r\n\r\nIt solved my problem.   Using tf 2.2.0 with one 2070s.", "> @Lay4U @ARozental Please use the below code while importing tensorflow and let me know if the issue still persists. Thanks!\r\n> \r\n> ```\r\n> import tensorflow as tf\r\n> physical_devices = tf.config.list_physical_devices('GPU')\r\n> tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\r\n> ```\r\n\r\nIt worked for me, running GRU using TF 2.3.0 with one 2060. Thanks!", "> @Lay4U @ARozental Please use the below code while importing tensorflow and let me know if the issue still persists. Thanks!\r\n> \r\n> ```\r\n> import tensorflow as tf\r\n> physical_devices = tf.config.list_physical_devices('GPU')\r\n> tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\r\n> ```\r\n\r\nThis solves the problem for me as well. \r\nOS: Ubuntu 18.04\r\nPython : 3.6.9\r\nTensorFlow-GPU : 2.3.0\r\nCuda : 10.1\r\nCudnn : 7.6.5", "thx, solved the problem:\r\nlinux mint 20\r\ngeforce RTX 2060", "I think a lot of the cuDNN related problems could be solved by adding these code.\r\nhttps://leimao.github.io/blog/TensorFlow-cuDNN-Failure/\r\n", "> @Lay4U @ARozental Please use the below code while importing tensorflow and let me know if the issue still persists. Thanks!\r\n> \r\n> ```\r\n> import tensorflow as tf\r\n> physical_devices = tf.config.list_physical_devices('GPU')\r\n> tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\r\n> ```\r\n\r\nthis solved it for me.  What does this do exactly?", "> @Lay4U @ARozental Please use the below code while importing tensorflow and let me know if the issue still persists. Thanks!\r\n> \r\n> ```\r\n> import tensorflow as tf\r\n> physical_devices = tf.config.list_physical_devices('GPU')\r\n> tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\r\n> ```\r\nJust getting this:\r\nRuntimeError: Physical devices cannot be modified after being initialized\r\n\r\nDid that work for you?", "@JamieMoon Just close the terminal/python console and run the below code first, then your LSTM\r\n\r\nimport tensorflow as tf\r\nphysical_devices = tf.config.list_physical_devices('GPU')\r\ntf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\r\n\r\n", "I continue without solving this issue...\r\nI have tried all that you have mentioned but it continues the same problem\r\nmy OS is:\r\n\r\nUbuntu 18.04\r\nCUDA 10.0\r\nTensorflow 2.0\r\nNvidia-driver 460 (Although I have tried with 450 and it also does not work)\r\ngeForce RTX2060\r\nPython 3.7\r\n\r\nI have tried to compile with CUDA 10.1 and TF 2.1 but I continue without solving it. It starts to be a little frustrating\r\n\r\nThis is what I obtain after fitting:\r\n\r\nEpoch 1/50\r\n2021-01-25 18:59:34.964218: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\r\n2021-01-25 18:59:35.096029: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n 128/2156 [>.............................] - ETA: 15sWARNING:tensorflow:Can save best model only with val_loss available, skipping.\r\n\r\n.2021-01-25 18:59:35.364099: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\r\n2021-01-25 18:59:35.364136: W tensorflow/core/framework/op_kernel.cc:1655] OP_REQUIRES failed at cudnn_rnn_ops.cc:1510 : Unknown: Fail to find the dnn implementation.\r\n2021-01-25 18:59:35.364158: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Unknown: Fail to find the dnn implementation.\r\n         [[{{node CudnnRNN}}]]\r\n2021-01-25 18:59:35.364356: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Unknown: {{function_node __forward_cudnn_lstm_with_fallback_2517_specialized_for_sequential_lstm_StatefulPartitionedCall_at___inference_distributed_function_3196}} {{function_node __forward_cudnn_lstm_with_fallback_2517_specialized_for_sequential_lstm_StatefulPartitionedCall_at___inference_distributed_function_3196}} Fail to find the dnn implementation.\r\n         [[{{node CudnnRNN}}]]\r\n         [[sequential/lstm/StatefulPartitionedCall]]\r\n\r\nAll testings of the cuDnn and Cuda works well.\r\n\r\n", "> @Lay4U @ARozental Please use the below code while importing tensorflow and let me know if the issue still persists. Thanks!\r\n> \r\n> ```\r\n> import tensorflow as tf\r\n> physical_devices = tf.config.list_physical_devices('GPU')\r\n> tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\r\n> ```\r\nJust had the same issue here, managed to fix with this solution\r\n\r\nMy setup:\r\nWindows 10\r\nCUDA 11.2\r\nTensorflow 2.3\r\nNvidia Driver 460.x\r\nGeforce RTX 2060\r\nPython 3.8\r\n", "Same issue here\r\nI tried all the aforementioned solutions. None seems to resolve the issue", "> @Lay4U @ARozental Please use the below code while importing tensorflow and let me know if the issue still persists. Thanks!\r\n> \r\n> ```\r\n> import tensorflow as tf\r\n> physical_devices = tf.config.list_physical_devices('GPU')\r\n> tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\r\n> ```\r\n\r\n**RuntimeError: Physical devices cannot be modified after being initialized**", "I had the same issue. Updating tensorflow with `pip install -U tensorflow` solved it"]}, {"number": 36507, "title": "How to use prepare_for_training with model.fit", "body": "\r\n\r\n## URL(s) with the issue: \r\n\r\nhttps://www.tensorflow.org/tutorials/load_data/images\r\n\r\n## Description of issue (what needs changing):\r\n\r\n\r\nI have been spending a lot of time trying to figure out how I can use the batch map to train my model. Which method should I use model.fit, model.fit_generator or something else", "comments": ["@HadiSDev \r\n\r\nCan you go through this [link](https://www.tensorflow.org/tutorials/images/classification#data_preparation) and see if it helps you. Thanks!"]}, {"number": 36506, "title": "Failed to install tfx=0.15.0 ", "body": "**System information**\r\n- OS Platform and Distribution: Windows 10\r\n- TensorFlow version: 1.15.0\r\n- Python version: 3.7.6\r\n\r\n**Describe the problem**\r\n\r\n(CPU_3.7.6_tfx_2) C:\\Users\\SakhawathHossain\\AppData\\Local\\Continuum\\anaconda3\\envs>pip install tfx==0.15.0\r\nCollecting tfx==0.15.0\r\n  Using cached tfx-0.15.0-py3-none-any.whl (504 kB)\r\nCollecting tensorflow-model-analysis<0.16,>=0.15.2\r\n  Using cached tensorflow_model_analysis-0.15.4-py3-none-any.whl (1.4 MB)\r\nProcessing c:\\users\\sakhawath\\appdata\\local\\pip\\cache\\wheels\\65\\72\\ba\\7ad835954f31d6ef4f2741f602a685ac203fce168c2f31adc6\\apache_beam-2.19.0-py3-none-any.whl\r\nProcessing c:\\users\\sakhawath\\appdata\\local\\pip\\cache\\wheels\\46\\91\\e3\\0fced4f5fbc0a051a5667096826186c9ff60f2d0e9bf0f1cdc\\absl_py-0.8.1-py3-none-any.whl\r\nERROR: Could not find a version that satisfies the requirement tensorflow-data-validation<0.16,>=0.15 (from tfx==0.15.0) (from versions: 0.21.0)\r\nERROR: No matching distribution found for tensorflow-data-validation<0.16,>=0.15 (from tfx==0.15.0)\r\n.............................................................................\r\n(CPU_3.7.6_tfx_2) C:\\Users\\sakhawath\\AppData\\Local\\Continuum\\anaconda3\\envs>pip install tfx==0.15.0rc0\r\nCollecting tfx==0.15.0rc0\r\n  Using cached tfx-0.15.0rc0-py3-none-any.whl (475 kB)\r\nERROR: Could not find a version that satisfies the requirement tfx-bsl<0.16,>=0.15.1 (from tfx==0.15.0rc0) (from versions: 0.21.0)\r\nERROR: No matching distribution found for tfx-bsl<0.16,>=0.15.1 (from tfx==0.15.0rc0)\r\n.......................................................................\r\n(CPU_3.7.6_tfx_2) C:\\Users\\Sakhawath\\AppData\\Local\\Continuum\\anaconda3\\envs>pip install tfx==0.21.0\r\nERROR: Could not find a version that satisfies the requirement tfx==0.21.0 (from versions: 0.13.0rc0, 0.13.0rc1, 0.13.0rc2, 0.13.0, 0.14.0rc1, 0.14.0, 0.15.0rc0, 0.15.0, 0.21.0rc0)\r\nERROR: No matching distribution found for tfx==0.21.0\r\n", "comments": []}, {"number": 36504, "title": "ValueError when trying to speed up model by decorating tf.function", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): 2.1.0\r\n- Python version:  3.6.7\r\n- CUDA/cuDNN version:  7.6.5\r\n- GPU model and memory:  GTX1660Ti , 6GB\r\n\r\n**Describe the current behavior**\r\n\r\n    Traceback (most recent call last):\r\n    File \"model_test.py\", line 12, in <module>\r\n        output = ModelTest(input_layer)\r\n    File \"/home/wilson/venv_tf2.0/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\", line 568, in __call__\r\n        result = self._call(*args, **kwds)\r\n    File \"/home/wilson/venv_tf2.0/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\", line 632, in _call\r\n        return self._stateless_fn(*args, **kwds)\r\n    File \"/home/wilson/venv_tf2.0/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\", line 2362, in __call__\r\n        graph_function, args, kwargs = self._maybe_define_function(args, kwargs)\r\n    File \"/home/wilson/venv_tf2.0/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\", line 2703, in _maybe_define_function\r\n        graph_function = self._create_graph_function(args, kwargs)\r\n    File \"/home/wilson/venv_tf2.0/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\", line 2593, in _create_graph_function\r\n        capture_by_value=self._capture_by_value),\r\n    File \"/home/wilson/venv_tf2.0/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py\", line 978, in func_graph_from_py_func\r\n        func_outputs = python_func(*func_args, **func_kwargs)\r\n    File \"/home/wilson/venv_tf2.0/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\", line 439, in wrapped_fn\r\n        return weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n    File \"/home/wilson/venv_tf2.0/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py\", line 968, in wrapper\r\n        raise e.ag_error_metadata.to_exception(e)\r\n    ValueError: in converted code:\r\n\r\n        model_test.py:8 ModelTest  *\r\n            x = tf.keras.layers.Dense(10)(x)\r\n        /home/wilson/venv_tf2.0/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py:748 __call__\r\n            self._maybe_build(inputs)\r\n        /home/wilson/venv_tf2.0/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py:2116 _maybe_build\r\n            self.build(input_shapes)\r\n        /home/wilson/venv_tf2.0/lib/python3.6/site-packages/tensorflow_core/python/keras/layers/core.py:1113 build\r\n            trainable=True)\r\n        /home/wilson/venv_tf2.0/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py:446 add_weight\r\n            caching_device=caching_device)\r\n        /home/wilson/venv_tf2.0/lib/python3.6/site-packages/tensorflow_core/python/training/tracking/base.py:744 _add_variable_with_custom_getter\r\n            **kwargs_for_getter)\r\n        /home/wilson/venv_tf2.0/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py:142 make_variable\r\n            shape=variable_shape if variable_shape else None)\r\n        /home/wilson/venv_tf2.0/lib/python3.6/site-packages/tensorflow_core/python/ops/variables.py:258 __call__\r\n            return cls._variable_v1_call(*args, **kwargs)\r\n        /home/wilson/venv_tf2.0/lib/python3.6/site-packages/tensorflow_core/python/ops/variables.py:219 _variable_v1_call\r\n            shape=shape)\r\n        /home/wilson/venv_tf2.0/lib/python3.6/site-packages/tensorflow_core/python/ops/variables.py:65 getter\r\n            return captured_getter(captured_previous, **kwargs)\r\n        /home/wilson/venv_tf2.0/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py:502 invalid_creator_scope\r\n            \"tf.function-decorated function tried to create \"\r\n\r\n        ValueError: tf.function-decorated function tried to create variables on non-first call.\r\n\r\n\r\n**Describe the expected behavior**\r\n\r\n    print the inference results as below:\r\n    tf.Tensor( [[ 1.5871892   1.028789    0.6445342  -1.9210143  -1.7477174   3.1219487\r\n   1.8073429   2.62254    -0.01772228 -2.2654278 ]], shape=(1, 10), dtype=float32)\r\n\r\n\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n    import numpy as np\r\n    import tensorflow as tf\r\n    from tensorflow.keras.layers import Flatten, Dense\r\n   \r\n    @tf.function  # with this, it will raise error listed above\r\n    def ModelTest(input_layer):\r\n        x = Flatten()(input_layer)\r\n        x = tf.keras.layers.Dense(10)(x)\r\n        return x\r\n\r\n    input_layer = tf.keras.layers.Input([32, 32, 3])\r\n    output = ModelTest(input_layer)\r\n    model = tf.keras.Model(input_layer, output)\r\n\r\n    a = np.ones([1, 32, 32, 3])\r\n    print(model(a))\r\n\r\nI try to run YOLOv3 by TF2, but it's so slow compared to other framework, can be seen from the following table.\r\n![image](https://user-images.githubusercontent.com/20164141/73921384-31a6d200-4902-11ea-9162-d6207f60b425.png)\r\n\r\nSo by a naive example, I just want to speed up the inference of the model by decorating ModelTest with tf.function, but it will raise error. How should I fix this error or are there other ways to speed up the model? Thanks\r\n", "comments": ["I have tried on colab with TF version 2.1, 2.2.0-dev20200206 and was able to reproduce the issue.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/6f460f8bbf48b3b697a5fec56f9a6a16/untitled625.ipynb). Thanks!", "The error is raised because tf.function doesn't like it when you create variables inside it. In this case, the Keras layers are attempting to create variables so you should create those outside the tf.function.\r\n\r\nOn the other hand, I don't know if this is the recommended way of creating layers. @fchollet @omalleyt12 can give better advice there.\r\n\r\nAlso copying @karmel for the performance question.\r\n\r\nHere are a couple of ways in which you can build your example model that I tested myself. In both cases, tf.function should be applied automatically:\r\n\r\nFunctional style:\r\n```\r\ninput_layer = tf.keras.layers.Input([32, 32, 3])\r\nmodel = tf.keras.models.Sequential(\r\n    [input_layer, Flatten(), tf.keras.layers.Dense(10)])\r\n\r\na = np.ones([1, 32, 32, 3], dtype=np.float32)\r\nprint(model(a))\r\n```\r\n\r\nObject-oriented style:\r\n```\r\nclass KerasModel(tf.keras.models.Model):\r\n\r\n  def __init__(self):\r\n    super(KerasModel, self).__init__()\r\n    self.flatten = Flatten()\r\n    self.dense = tf.keras.layers.Dense(10)\r\n\r\n  def call(self, input_layer):\r\n    x = input_layer\r\n    x = self.flatten(x)\r\n    x = self.dense(x)\r\n    return x\r\n\r\nmodel = KerasModel()\r\n\r\na = np.ones([1, 32, 32, 3], dtype=np.float32)\r\nprint(model(a))\r\n```\r\n\r\nYou can also customize the way the code is optimized by adding `@tf.function` manually. For example the code below will use XLA (if available in your installation) which is usually faster:\r\n\r\n```\r\nclass KerasModel(tf.keras.models.Model):\r\n\r\n  def __init__(self):\r\n    super(KerasModel, self).__init__()\r\n    self.flatten = Flatten()\r\n    self.dense = tf.keras.layers.Dense(10)\r\n\r\n  @tf.function(experimental_compile=True)\r\n  def call(self, input_layer):\r\n    x = input_layer\r\n    x = self.flatten(x)\r\n    x = self.dense(x)\r\n    return x\r\n\r\nmodel = KerasModel()\r\n\r\na = np.ones([1, 32, 32, 3], dtype=np.float32)\r\nprint(model(a))\r\n```", "Yes this is intended behavior. `tf.function` should not be used when constructing a Functional API Model. `tf.function` should only be used when running the actual training of the Model:\r\n\r\n```\r\nmodel = tf.keras.Model(inputs, outputs)\r\n\r\n@tf.function\r\ndef train_step(x, y):\r\n  y_pred = model(x)\r\n  ...\r\n```", "Sorry to ask one more question. Does tf.function apply to the model built by Keras Functional API automatically?\r\n\r\n\r\n    import numpy as np\r\n    import tensorflow as tf\r\n    from tensorflow.keras.layers import Flatten, Dense\r\n\r\n    @tf.function  # <= Is this decoration uncessary ? \r\n    def ModelTest(input_layer):\r\n        x = Flatten()(input_layer)\r\n        x = tf.keras.layers.Dense(10)(x)\r\n        return x\r\n\r\n    input_layer = tf.keras.layers.Input([32, 32, 3])\r\n    output = ModelTest(input_layer)\r\n    model = tf.keras.Model(input_layer, output)  # Does this model apply tf.function automatically?\r\n\r\n\r\nI read a model from this tutorial page. Is this model already applied tf.function?\r\nhttps://www.tensorflow.org/guide/keras/functional#all_models_are_callable_just_like_layers\r\n", "No, I don't think that `tf.function` automatically applies to Keras layers, see the example using `tf.keras.layers.Conv2d` in https://www.tensorflow.org/guide/function#usage as well as the`SequentialModel` in https://www.tensorflow.org/guide/intro_to_graphs#seeing_the_speed_up. All the solutions above work, but if you want another way to apply  `tf.function` to `ModelTest`, you can subclass tf.keras.layers.Layer and decorate the `call` function like so:\r\n```\r\nclass ModelTest(tf.keras.layers.Layer):\r\n\r\n  def __init__(self):\r\n    super(ModelTest, self).__init__()\r\n    self.flatten = Flatten()\r\n    self.dense = tf.keras.layers.Dense(10)\r\n\r\n  @tf.function\r\n  def call(self, input_layer):\r\n    x = input_layer\r\n    x = self.flatten(x)\r\n    x = self.dense(x)\r\n    return x\r\n\r\ninput_layer = tf.keras.layers.Input([32, 32, 3])\r\noutput_layer = ModelTest()(input_layer)\r\nmodel = tf.keras.Model(input_layer, output_layer)\r\n```"]}, {"number": 36503, "title": "Illegal Instruction on importing tensorflow (Intel J3455, debian)", "body": "\r\ntensorflow 2.1.0 from pip3 \r\ncrashing on execute a PXOR instruction\r\n\r\nbuild with (-Wno-sign-compare -march=skylake -mno-avx -mno-avx2 -mno-fma -msse4.1 -msse4.2)\r\ncrashing on execute a SHLX instruction\r\n\r\nbuild with (-Wno-sign-compare -march=skylake -mno-avx -mno-avx2 -mno-fma -msse4.1 -msse4.2 -mno-bmi -mno-sgx -mno-bmi2)\r\nnot crash but process freeze\r\n\r\n\r\n\r\n\r\n**System information**\r\n```\r\ndebian 10.2\r\nPython 3.7.3 (default, Apr  3 2019, 05:39:12) \r\n[GCC 8.3.0] on linux\r\ntensorflow 2.1.0 from pip3 also tried build from source(-Wno-sign-compare -march=skylake -mno-avx -mno-avx2 -mno-fma -msse4.1 -msse4.2)\r\n\r\n$ lscpu \r\nArchitecture:        x86_64\r\nCPU op-mode(s):      32-bit, 64-bit\r\nByte Order:          Little Endian\r\nAddress sizes:       39 bits physical, 48 bits virtual\r\nCPU(s):              4\r\nOn-line CPU(s) list: 0-3\r\nThread(s) per core:  1\r\nCore(s) per socket:  4\r\nSocket(s):           1\r\nNUMA node(s):        1\r\nVendor ID:           GenuineIntel\r\nCPU family:          6\r\nModel:               92\r\nModel name:          Intel(R) Celeron(R) CPU J3455 @ 1.50GHz\r\nStepping:            9\r\nCPU MHz:             2179.725\r\nCPU max MHz:         2300.0000\r\nCPU min MHz:         800.0000\r\nBogoMIPS:            2995.20\r\nVirtualization:      VT-x\r\nL1d cache:           24K\r\nL1i cache:           32K\r\nL2 cache:            1024K\r\nNUMA node0 CPU(s):   0-3\r\nFlags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology tsc_reliable nonstop_tsc cpuid aperfmperf tsc_known_freq pni pclmulqdq dtes64 monitor ds_cpl vmx est tm2 ssse3 sdbg cx16 xtpr pdcm sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave rdrand lahf_lm 3dnowprefetch cpuid_fault cat_l2 pti tpr_shadow vnmi flexpriority ept vpid ept_ad fsgsbase tsc_adjust smep erms mpx rdt_a rdseed smap clflushopt intel_pt sha_ni xsaveopt xsavec xgetbv1 xsaves dtherm ida arat pln pts\r\n\r\n$ g++ -march=native -Q --help=target\r\nThe following options are target specific:\r\n  -m128bit-long-double        \t\t[enabled]\r\n  -m16                        \t\t[disabled]\r\n  -m32                        \t\t[disabled]\r\n  -m3dnow                     \t\t[disabled]\r\n  -m3dnowa                    \t\t[disabled]\r\n  -m64                        \t\t[enabled]\r\n  -m80387                     \t\t[enabled]\r\n  -m8bit-idiv                 \t\t[disabled]\r\n  -m96bit-long-double         \t\t[disabled]\r\n  -mabi=                      \t\tsysv\r\n  -mabm                       \t\t[disabled]\r\n  -maccumulate-outgoing-args  \t\t[disabled]\r\n  -maddress-mode=             \t\tlong\r\n  -madx                       \t\t[disabled]\r\n  -maes                       \t\t[enabled]\r\n  -malign-data=               \t\tcompat\r\n  -malign-double              \t\t[disabled]\r\n  -malign-functions=          \t\t0\r\n  -malign-jumps=              \t\t0\r\n  -malign-loops=              \t\t0\r\n  -malign-stringops           \t\t[enabled]\r\n  -mandroid                   \t\t[disabled]\r\n  -march=                     \t\tskylake\r\n  -masm=                      \t\tatt\r\n  -mavx                       \t\t[disabled]\r\n  -mavx2                      \t\t[disabled]\r\n  -mavx256-split-unaligned-load \t[enabled]\r\n  -mavx256-split-unaligned-store \t[enabled]\r\n  -mavx5124fmaps              \t\t[disabled]\r\n  -mavx5124vnniw              \t\t[disabled]\r\n  -mavx512bitalg              \t\t[disabled]\r\n  -mavx512bw                  \t\t[disabled]\r\n  -mavx512cd                  \t\t[disabled]\r\n  -mavx512dq                  \t\t[disabled]\r\n  -mavx512er                  \t\t[disabled]\r\n  -mavx512f                   \t\t[disabled]\r\n  -mavx512ifma                \t\t[disabled]\r\n  -mavx512pf                  \t\t[disabled]\r\n  -mavx512vbmi                \t\t[disabled]\r\n  -mavx512vbmi2               \t\t[disabled]\r\n  -mavx512vl                  \t\t[disabled]\r\n  -mavx512vnni                \t\t[disabled]\r\n  -mavx512vpopcntdq           \t\t[disabled]\r\n  -mbionic                    \t\t[disabled]\r\n  -mbmi                       \t\t[disabled]\r\n  -mbmi2                      \t\t[disabled]\r\n  -mbranch-cost=<0,5>         \t\t3\r\n  -mcall-ms2sysv-xlogues      \t\t[disabled]\r\n  -mcet-switch                \t\t[disabled]\r\n  -mcld                       \t\t[disabled]\r\n  -mclflushopt                \t\t[enabled]\r\n  -mclwb                      \t\t[disabled]\r\n  -mclzero                    \t\t[disabled]\r\n  -mcmodel=                   \t\t[default]\r\n  -mcpu=                      \t\t\r\n  -mcrc32                     \t\t[disabled]\r\n  -mcx16                      \t\t[enabled]\r\n  -mdispatch-scheduler        \t\t[disabled]\r\n  -mdump-tune-features        \t\t[disabled]\r\n  -mf16c                      \t\t[disabled]\r\n  -mfancy-math-387            \t\t[enabled]\r\n  -mfentry                    \t\t[disabled]\r\n  -mfma                       \t\t[disabled]\r\n  -mfma4                      \t\t[disabled]\r\n  -mforce-drap                \t\t[disabled]\r\n  -mforce-indirect-call       \t\t[disabled]\r\n  -mfp-ret-in-387             \t\t[enabled]\r\n  -mfpmath=                   \t\tsse\r\n  -mfsgsbase                  \t\t[enabled]\r\n  -mfunction-return=          \t\tkeep\r\n  -mfused-madd                \t\t\r\n  -mfxsr                      \t\t[enabled]\r\n  -mgeneral-regs-only         \t\t[disabled]\r\n  -mgfni                      \t\t[disabled]\r\n  -mglibc                     \t\t[enabled]\r\n  -mhard-float                \t\t[enabled]\r\n  -mhle                       \t\t[enabled]\r\n  -miamcu                     \t\t[disabled]\r\n  -mieee-fp                   \t\t[enabled]\r\n  -mincoming-stack-boundary=  \t\t0\r\n  -mindirect-branch-register  \t\t[disabled]\r\n  -mindirect-branch=          \t\tkeep\r\n  -minline-all-stringops      \t\t[disabled]\r\n  -minline-stringops-dynamically \t[disabled]\r\n  -mintel-syntax              \t\t\r\n  -mlarge-data-threshold=<number> \t65536\r\n  -mlong-double-128           \t\t[disabled]\r\n  -mlong-double-64            \t\t[disabled]\r\n  -mlong-double-80            \t\t[enabled]\r\n  -mlwp                       \t\t[disabled]\r\n  -mlzcnt                     \t\t[disabled]\r\n  -mmemcpy-strategy=          \t\t\r\n  -mmemset-strategy=          \t\t\r\n  -mmitigate-rop              \t\t[disabled]\r\n  -mmmx                       \t\t[enabled]\r\n  -mmovbe                     \t\t[enabled]\r\n  -mmovdir64b                 \t\t[disabled]\r\n  -mmovdiri                   \t\t[disabled]\r\n  -mmpx                       \t\t[disabled]\r\n  -mms-bitfields              \t\t[disabled]\r\n  -mmusl                      \t\t[disabled]\r\n  -mmwaitx                    \t\t[disabled]\r\n  -mno-align-stringops        \t\t[disabled]\r\n  -mno-default                \t\t[disabled]\r\n  -mno-fancy-math-387         \t\t[disabled]\r\n  -mno-push-args              \t\t[disabled]\r\n  -mno-red-zone               \t\t[disabled]\r\n  -mno-sse4                   \t\t[disabled]\r\n  -mnop-mcount                \t\t[disabled]\r\n  -momit-leaf-frame-pointer   \t\t[disabled]\r\n  -mpc32                      \t\t[disabled]\r\n  -mpc64                      \t\t[disabled]\r\n  -mpc80                      \t\t[disabled]\r\n  -mpclmul                    \t\t[enabled]\r\n  -mpcommit                   \t\t[disabled]\r\n  -mpconfig                   \t\t[disabled]\r\n  -mpku                       \t\t[disabled]\r\n  -mpopcnt                    \t\t[enabled]\r\n  -mprefer-avx128             \t\t\r\n  -mprefer-vector-width=      \t\tnone\r\n  -mpreferred-stack-boundary= \t\t0\r\n  -mprefetchwt1               \t\t[disabled]\r\n  -mprfchw                    \t\t[enabled]\r\n  -mpush-args                 \t\t[enabled]\r\n  -mrdpid                     \t\t[disabled]\r\n  -mrdrnd                     \t\t[enabled]\r\n  -mrdseed                    \t\t[enabled]\r\n  -mrecip                     \t\t[disabled]\r\n  -mrecip=                    \t\t\r\n  -mrecord-mcount             \t\t[disabled]\r\n  -mred-zone                  \t\t[enabled]\r\n  -mregparm=                  \t\t6\r\n  -mrtd                       \t\t[disabled]\r\n  -mrtm                       \t\t[disabled]\r\n  -msahf                      \t\t[enabled]\r\n  -msgx                       \t\t[disabled]\r\n  -msha                       \t\t[enabled]\r\n  -mshstk                     \t\t[disabled]\r\n  -mskip-rax-setup            \t\t[disabled]\r\n  -msoft-float                \t\t[disabled]\r\n  -msse                       \t\t[enabled]\r\n  -msse2                      \t\t[enabled]\r\n  -msse2avx                   \t\t[disabled]\r\n  -msse3                      \t\t[enabled]\r\n  -msse4                      \t\t[enabled]\r\n  -msse4.1                    \t\t[enabled]\r\n  -msse4.2                    \t\t[enabled]\r\n  -msse4a                     \t\t[disabled]\r\n  -msse5                      \t\t\r\n  -msseregparm                \t\t[disabled]\r\n  -mssse3                     \t\t[enabled]\r\n  -mstack-arg-probe           \t\t[disabled]\r\n  -mstack-protector-guard-offset= \t\r\n  -mstack-protector-guard-reg= \t\t\r\n  -mstack-protector-guard-symbol= \t\r\n  -mstack-protector-guard=    \t\ttls\r\n  -mstackrealign              \t\t[disabled]\r\n  -mstringop-strategy=        \t\t[default]\r\n  -mstv                       \t\t[enabled]\r\n  -mtbm                       \t\t[disabled]\r\n  -mtls-dialect=              \t\tgnu\r\n  -mtls-direct-seg-refs       \t\t[enabled]\r\n  -mtune-ctrl=                \t\t\r\n  -mtune=                     \t\tgeneric\r\n  -muclibc                    \t\t[disabled]\r\n  -mvaes                      \t\t[disabled]\r\n  -mveclibabi=                \t\t[default]\r\n  -mvect8-ret-in-mem          \t\t[disabled]\r\n  -mvpclmulqdq                \t\t[disabled]\r\n  -mvzeroupper                \t\t[enabled]\r\n  -mwbnoinvd                  \t\t[disabled]\r\n  -mx32                       \t\t[disabled]\r\n  -mxop                       \t\t[disabled]\r\n  -mxsave                     \t\t[disabled]\r\n  -mxsavec                    \t\t[disabled]\r\n  -mxsaveopt                  \t\t[disabled]\r\n  -mxsaves                    \t\t[disabled]\r\n\r\n  Known assembler dialects (for use with the -masm= option):\r\n    att intel\r\n\r\n  Known ABIs (for use with the -mabi= option):\r\n    ms sysv\r\n\r\n  Known code models (for use with the -mcmodel= option):\r\n    32 kernel large medium small\r\n\r\n  Valid arguments to -mfpmath=:\r\n    387 387+sse 387,sse both sse sse+387 sse,387\r\n\r\n  Known indirect branch choices (for use with the -mindirect-branch=/-mfunction-return= options):\r\n    keep thunk thunk-extern thunk-inline\r\n\r\n  Known data alignment choices (for use with the -malign-data= option):\r\n    abi cacheline compat\r\n\r\n  Known vectorization library ABIs (for use with the -mveclibabi= option):\r\n    acml svml\r\n\r\n  Known address mode (for use with the -maddress-mode= option):\r\n    long short\r\n\r\n  Known preferred register vector length (to use with the -mprefer-vector-width= option)\r\n    128 256 512 none\r\n\r\n  Known stack protector guard (for use with the -mstack-protector-guard= option):\r\n    global tls\r\n\r\n  Valid arguments to -mstringop-strategy=:\r\n    byte_loop libcall loop rep_4byte rep_8byte rep_byte unrolled_loop vector_loop\r\n\r\n  Known TLS dialects (for use with the -mtls-dialect= option):\r\n    gnu gnu2\r\n\r\n```\r\n\r\n\r\n**Describe the current behavior**\r\n\r\n**Describe the expected behavior**\r\n\r\n**Code to reproduce the issue**\r\ntensorflow 2.1.0 from pip3 \r\n```\r\nSuccessfully installed gast-0.2.2 tensorboard-2.1.0 tensorflow-2.1.0 tensorflow-estimator-2.1.0\r\n# gdb --args python3.7 -c \"import tensorflow\"\r\nGNU gdb (Debian 8.2.1-2+b3) 8.2.1\r\nCopyright (C) 2018 Free Software Foundation, Inc.\r\nLicense GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>\r\nThis is free software: you are free to change and redistribute it.\r\nThere is NO WARRANTY, to the extent permitted by law.\r\nType \"show copying\" and \"show warranty\" for details.\r\nThis GDB was configured as \"x86_64-linux-gnu\".\r\nType \"show configuration\" for configuration details.\r\nFor bug reporting instructions, please see:\r\n<http://www.gnu.org/software/gdb/bugs/>.\r\nFind the GDB manual and other documentation resources online at:\r\n    <http://www.gnu.org/software/gdb/documentation/>.\r\n\r\nFor help, type \"help\".\r\nType \"apropos word\" to search for commands related to \"word\"...\r\nReading symbols from python3.7...(no debugging symbols found)...done.\r\n(gdb) run\r\nStarting program: /usr/bin/python3.7 -c import\\ tensorflow\r\n[Thread debugging using libthread_db enabled]\r\nUsing host libthread_db library \"/lib/x86_64-linux-gnu/libthread_db.so.1\".\r\n[New Thread 0x7ffff4c9c700 (LWP 8462)]\r\n[New Thread 0x7ffff249b700 (LWP 8463)]\r\n[New Thread 0x7ffff1c9a700 (LWP 8464)]\r\n\r\nThread 1 \"python3.7\" received signal SIGILL, Illegal instruction.\r\n0x00007fffb412f6c0 in nsync::nsync_mu_init(nsync::nsync_mu_s_*) ()\r\n   from /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so\r\n(gdb) disas 0x00007fffb412f6c0\r\nDump of assembler code for function _ZN5nsync13nsync_mu_initEPNS_11nsync_mu_s_E:\r\n=> 0x00007fffb412f6c0 <+0>:\tvpxor  %xmm0,%xmm0,%xmm0\r\n   0x00007fffb412f6c4 <+4>:\tpush   %rbp\r\n   0x00007fffb412f6c5 <+5>:\tmov    %rsp,%rbp\r\n   0x00007fffb412f6c8 <+8>:\tvmovups %xmm0,(%rdi)\r\n   0x00007fffb412f6cc <+12>:\tpop    %rbp\r\n   0x00007fffb412f6cd <+13>:\tretq   \r\nEnd of assembler dump.\r\n(gdb) \r\n\r\n```\r\n\r\nbuild from source tensorflow #v2.1.0(-Wno-sign-compare -march=skylake -mno-avx -mno-avx2 -mno-fma -msse4.1 -msse4.2)\r\n```\r\nroot@acd9a1d666ad:/tensorflow_src# ./configure \r\nWARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command \"bazel shutdown\".\r\nYou have bazel 1.2.1 installed.\r\nPlease specify the location of python. [Default is /usr/local/bin/python]: /usr/bin/python3.7\r\n\r\n\r\nFound possible Python library paths:\r\n  /usr/lib/python3/dist-packages\r\n  /usr/local/lib/python3.7/dist-packages\r\nPlease input the desired Python library path to use.  Default is [/usr/lib/python3/dist-packages]\r\n\r\nDo you wish to build TensorFlow with XLA JIT support? [Y/n]: \r\nXLA JIT support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with OpenCL SYCL support? [y/N]: \r\nNo OpenCL SYCL support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with ROCm support? [y/N]: \r\nNo ROCm support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with CUDA support? [y/N]: \r\nNo CUDA support will be enabled for TensorFlow.\r\n\r\nDo you wish to download a fresh release of clang? (Experimental) [y/N]: \r\nClang will not be downloaded.\r\n\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native -Wno-sign-compare]: -Wno-sign-compare -march=skylake -mno-avx -mno-avx2 -mno-fma -msse4.1 -msse4.2\r\n\r\n\r\nWould you like to interactively configure ./WORKSPACE for Android builds? [y/N]: \r\nNot configuring the WORKSPACE for Android builds.\r\n\r\nPreconfigured Bazel build configs. You can use any of the below by adding \"--config=<>\" to your build command. See .bazelrc for more details.\r\n\t--config=mkl         \t# Build with MKL support.\r\n\t--config=monolithic  \t# Config for mostly static monolithic build.\r\n\t--config=ngraph      \t# Build with Intel nGraph support.\r\n\t--config=numa        \t# Build with NUMA support.\r\n\t--config=dynamic_kernels\t# (Experimental) Build kernels into separate shared objects.\r\n\t--config=v2          \t# Build TensorFlow 2.x instead of 1.x.\r\nPreconfigured Bazel build configs to DISABLE default on features:\r\n\t--config=noaws       \t# Disable AWS S3 filesystem support.\r\n\t--config=nogcp       \t# Disable GCP support.\r\n\t--config=nohdfs      \t# Disable HDFS support.\r\n\t--config=nonccl      \t# Disable NVIDIA NCCL support.\r\nConfiguration finished\r\n\r\nroot@acd9a1d666ad:/tensorflow_src# bazel build --config=opt --config=noaws --config=nogcp --config=nonccl //tensorflow/tools/pip_package:build_pip_package --jobs 4\r\n```\r\n\r\n```\r\n# gdb --args python3.7 -c \"import tensorflow\"\r\nGNU gdb (Debian 8.2.1-2+b3) 8.2.1\r\nCopyright (C) 2018 Free Software Foundation, Inc.\r\nLicense GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>\r\nThis is free software: you are free to change and redistribute it.\r\nThere is NO WARRANTY, to the extent permitted by law.\r\nType \"show copying\" and \"show warranty\" for details.\r\nThis GDB was configured as \"x86_64-linux-gnu\".\r\nType \"show configuration\" for configuration details.\r\nFor bug reporting instructions, please see:\r\n<http://www.gnu.org/software/gdb/bugs/>.\r\nFind the GDB manual and other documentation resources online at:\r\n    <http://www.gnu.org/software/gdb/documentation/>.\r\n\r\nFor help, type \"help\".\r\nType \"apropos word\" to search for commands related to \"word\"...\r\nReading symbols from python3.7...(no debugging symbols found)...done.\r\n(gdb) run\r\nStarting program: /usr/bin/python3.7 -c import\\ tensorflow\r\n[Thread debugging using libthread_db enabled]\r\nUsing host libthread_db library \"/lib/x86_64-linux-gnu/libthread_db.so.1\".\r\n[New Thread 0x7ffff4c9c700 (LWP 10774)]\r\n[New Thread 0x7ffff249b700 (LWP 10775)]\r\n[New Thread 0x7fffefc9a700 (LWP 10776)]\r\n\r\nThread 1 \"python3.7\" received signal SIGILL, Illegal instruction.\r\n0x00007fffddb28ee0 in tensorflow::UnaryVariantOpRegistry::RegisterDeviceCopyFn(tensorflow::VariantDeviceCopyDirection, tensorflow::TypeIndex const&, std::function<tensorflow::Status (tensorflow::Variant const&, tensorflow::Variant*, std::function<tensorflow::Status (tensorflow::Tensor const&, tensorflow::Tensor*)>)> const&) ()\r\n   from /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/../libtensorflow_framework.so.2\r\n(gdb) disas 0x00007fffddb28ee0,0x00007fffddb28eff\r\nDump of assembler code from 0x7fffddb28ee0 to 0x7fffddb28eff:\r\n=> 0x00007fffddb28ee0 <_ZN10tensorflow22UnaryVariantOpRegistry20RegisterDeviceCopyFnENS_26VariantDeviceCopyDirectionERKNS_9TypeIndexERKSt8functionIFNS_6StatusERKNS_7VariantEPS7_S5_IFS6_RKNS_6TensorEPSB_EEEE+544>:\tshlx   %r14d,%edx,%eax\r\n\r\n```\r\n\r\n**Other info / logs**\r\nhttps://www.felixcloutier.com/x86/pxor (AVX)\r\nhttps://www.felixcloutier.com/x86/sarx:shlx:shrx (BMI2)\r\n", "comments": ["finally compile with `-Wno-sign-compare -march=core2 -mno-avx -mno-avx2 -mno-fma -msse4.1 -msse4.2 -mno-bmi  -mno-bmi2` works\r\n```\r\nPython 3.7.3 (default, Apr  3 2019, 05:39:12) \r\n[GCC 8.3.0] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow\r\n/home/x/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\r\n/home/x/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\r\n/home/x/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\r\n/home/x/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\r\n/home/x/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\r\n/home/x/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\r\n>>> print(tensorflow.__version__)\r\n2.1.0\r\n```\r\n"]}, {"number": 36502, "title": "Update nn_impl.py", "body": "fix package name", "comments": ["@372046933 Could you please fix build errors? Thanks!", "@gbaned I didn't change any other code beyond this file. Can the CI process be retested?", "@372046933 Can you please address Ubuntu Sanity errors? Thanks!", "@gbaned I have run `./tensorflow/tools/ci_build/ci_sanity.sh`. And step 1 `configure.py` looks for CUDA. Step 1 failed to pass. Why CUDA is a must?"]}, {"number": 36501, "title": "Tensorflow 1.15 doesn't do incremental memory growth", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): NixOS\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): unknown 1.15.0\r\n- Python version: 3.7.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10.2.89\r\n- GPU model and memory: RTX 2070 - 440.44\r\n\r\n**Describe the current behavior**\r\n\r\nI'm trying to activate incremental memory growth. However in all the ways I've done it, it always ends up allocating almost the entire GPU.\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport tensorflow.keras as keras\r\nimport tensorflow.keras.applications as applications\r\nimport tensorflow.keras.utils as utils\r\nimport numpy as np\r\n\r\nnum_samples = 1000\r\nheight = 224\r\nwidth = 224\r\nnum_classes = 1000\r\n\r\nconfig = tf.compat.v1.ConfigProto()\r\nconfig.gpu_options.allow_growth = True\r\nsess = tf.compat.v1.Session(config=config)\r\nkeras.backend.set_session(sess)\r\n\r\n# gpus = tf.config.experimental.list_physical_devices('GPU')\r\n# for gpu in gpus:\r\n#     tf.config.experimental.set_memory_growth(gpu, True)\r\n# logical_gpus = tf.config.experimental.list_logical_devices('GPU')\r\n\r\nmodel = applications.ResNet50(weights=None, input_shape=(height, width, 3), classes=num_classes)\r\n\r\nparallel_model = utils.multi_gpu_model(model, gpus=2, cpu_relocation=True)\r\nparallel_model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\r\n\r\nx = np.random.random((num_samples, height, width, 3))\r\ny = np.random.random((num_samples, num_classes))\r\n\r\nparallel_model.fit(x, y, epochs=20, batch_size=2)\r\n\r\nprint('all done')\r\n```\r\n\r\nAs I watch `nvidia-smi`, I always see almost the entire GPUs allocated.\r\n\r\nThis is true for the compat v1 and for the new tf.config.experimental commands and also for the environment variable `TF_FORCE_GPU_ALLOW_GROWTH`.\r\n\r\nThe only one that has any effect is `config.gpu_options.per_process_gpu_memory_fraction = 0.5`.\r\n\r\nIn all other cases I see the the GPU memories get used up entirely and I get these messages:\r\n\r\n```\r\n2020-02-06 15:48:35.517899: I tensorflow/stream_executor/cuda/cuda_driver.cc:831] failed to allocate 3.18G (3411184640 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n```", "comments": ["> As I watch `nvidia-smi`, I always see almost the entire GPUs allocated.\r\n\r\n`allow_growth` only means that TF will *start off* with allocating only part of the GPU memory, but there is no limit to how much of the GPU memory it can use over the execution of the program (i.e. over time, the GPU memory usage can grow).  Is this what you are observing?  If so, I think this is WAI.\r\n\r\nTo keep TF from allocation more than half the GPU for the lifetime of the process, you need to use `per_process_gpu_memory_fraction`, as you said you are doing.\r\n\r\n> In all other cases I see the the GPU memories get used up entirely and I get these messages:\r\n\r\nAre these fatal errors or does the program continue to work?  TF often tries to allocate memory speculatively to use as workspace for cuDNN convolutions, but if the allocation fails it just falls back to a slower algorithm that uses less memory.  So if the OOM warnings are non-fatal then this is WAI too, although it does indicate the logging output could be made more helpful.", "This behaviour is different from before. When allow memory growth was enabled I saw a progressive incremental gpu memory growth. But now its instantly all the gpu memory. So the errors are non fatal. But previously I didn't need to enable this for tf to work on rtx 2070.\n\nOn 13 February 2020 18:29:22 GMT+11:00, Sanjoy Das <notifications@github.com> wrote:\n>> As I watch `nvidia-smi`, I always see almost the entire GPUs\n>allocated.\n>\n>`allow_growth` only means that TF will *start off* with allocating only\n>part of the GPU memory, but there is no limit to how much of the GPU\n>memory it can use over the execution of the program (i.e. over time,\n>the GPU memory usage can grow).  Is this what you are observing?  If\n>so, I think this is WAI.\n>\n>To keep TF from allocation more than half the GPU for the lifetime of\n>the process, you need to use `per_process_gpu_memory_fraction`, as you\n>said you are doing.\n>\n>> In all other cases I see the the GPU memories get used up entirely\n>and I get these messages:\n>\n>Are these fatal errors or does the program continue to work?  TF often\n>tries to allocate memory speculatively to use as workspace for cuDNN\n>convolutions, but if the allocation fails it just falls back to a\n>slower algorithm that uses less memory.  So if the OOM warnings are\n>non-fatal then this is WAI too, although it does indicate the logging\n>output could be made more helpful.\n>\n>-- \n>You are receiving this because you authored the thread.\n>Reply to this email directly or view it on GitHub:\n>https://github.com/tensorflow/tensorflow/issues/36501#issuecomment-585589881\n\n-- \nSent from my Android device with K-9 Mail. Please excuse my brevity.", "> This behaviour is different from before. When allow memory growth was enabled I saw a progressive incremental gpu memory growth.\r\n\r\nIt would be nice to have some more information here (what TF versions are you comparing?) but ultimately I'm not sure if there is much for us to do here.  The could just be a matter of the executor executing the graph in a different order.", "Are you implying that memory growth is not happening any more on 1.15 and RTX2070. Cause that's what the option says. But it immediately allocates all memory.\n\nOn 15 February 2020 17:46:21 GMT+11:00, Sanjoy Das <notifications@github.com> wrote:\n>> This behaviour is different from before. When allow memory growth was\n>enabled I saw a progressive incremental gpu memory growth.\n>\n>It would be nice to have some more information here (what TF versions\n>are you comparing?) but ultimately I'm not sure if there is much for us\n>to do here.  The could just be a matter of the executor executing the\n>graph in a different order.\n>\n>-- \n>You are receiving this because you authored the thread.\n>Reply to this email directly or view it on GitHub:\n>https://github.com/tensorflow/tensorflow/issues/36501#issuecomment-586560852\n\n-- \nSent from my Android device with K-9 Mail. Please excuse my brevity.", "> Are you implying that memory growth is not happening any more on 1.15 and RTX2070.\r\n\r\nallow_growth is a core TF level setting.  When it is set to false (default) TensorFlow itself allocates almost all of the GPU memory into its memory pool and uses this memory pool to satisfy memory allocation requests from the various GPU kernels.  When it is set to true then TF starts of allocating only a small amount of memory into the pool, and expands the pool as needed (e.g. if the pool has 1G of memory free and a GPU kernel wants 2G of memory then TF will allocate 1G more from the GPU runtime).\r\n\r\nHowever, allow_growth has no bearing on how much memory will actually be demanded by GPU kernels.  As an extreme example, if you have a GPU kernel that by itself needs all the memory the GPU has available, then irrespective of whether allow_growth is true or false, the program will immediately consume all of the GPU's memory when this kernel runs.\r\n\r\nI suspect that this is what is happening here.  We have not stopped respecting allow_growth, but the newer cuDNN probably has some algorithms that ask for more scratch memory in order to run faster.\r\n\r\nSpecifically, if I disable autotuning by setting the environment variable `TF_CUDNN_USE_AUTOTUNE` to `false` then the memory use stabilizes to 1857MiB (on my Titan-V).  If you are okay with the performance hit of disabling autotuning then this could be a good workaround for you.", "@CMCDragonkai -- I also faced the same issue as you. \r\nI had ported code from tf 1.15 to tf 2.1 and tried running the same code that work on my other machine. Following the tensorflow guide at https://www.tensorflow.org/guide/gpu, i had tried these 2 block of codes:\r\n\r\ncode 1\r\n```\r\ngpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=gpu_max_mem, allow_growth=True)\r\nsess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options))\r\n```\r\ncode 2\r\n```\r\ngpus = tf.config.experimental.list_physical_devices('GPU')\r\nif gpus:\r\n     # Restrict TensorFlow to only use the first GPU\r\n     try:\r\n         # Currently, memory growth needs to be the same across GPUs\r\n         for gpu in gpus:\r\n             tf.config.experimental.set_memory_growth(gpu, True)\r\n         tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\r\n         logical_gpus = tf.config.experimental.list_logical_devices('GPU')\r\n         print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\r\n     except RuntimeError as e:\r\n         # Visible devices must be set before GPUs have been initialized\r\n         print(e)\r\n```\r\nBoth code blocks allocated all GPU memory instead of my previously observed behavior of incremental increase in the GPU memory before inference. (During inference, the model do take up most of the memory space.)\r\n\r\nAt the moment, what work for me was setting the environment variable ```TF_FORCE_GPU_ALLOW_GROWTH = \"true\"```\r\n\r\nI noticed this changes when there was some update to my nvidia driver, cuda and cudnn.\r\nMACHINE 1\r\nnvidia_driver ver = 440.64.00\r\ncuda = 10.1.243\r\ncudnn =7.6.5\r\ntf 2.1.1\r\npython = 3.7.3\r\n\r\n\r\nwhen I tried it on another machine with specs below, the behaviour was expected without any setting of the environment variable ```TF_FORCE_GPU_ALLOW_GROWTH = \"true\"```\r\nMACHINE 2\r\nnvidia_driver ver = 440.64.00\r\ncuda = 10.0.130\r\ncudnn =7.6.5\r\ntf 1.15\r\npython = 3.7.3", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36501\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36501\">No</a>\n"]}, {"number": 36500, "title": "Error when converting my_frozen_graph.pb to .tflite for Speech Commands example app TF Speech", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (or github SHA if from source): Tensorflow 2.0.1\r\n\r\n\r\n**Command used to run the converter or code if you\u2019re using the Python API**\r\ntflite_convert.py\r\n```\r\n\r\n# Copy and paste here the exact command\r\n```\r\npython tensorflow/lite/python/tflite_convert.py --enable_v1_converter --output_file=/tmp/foo.tflite --graph_def_file=/tmp/my_frozen_graph_anika_26000.pb --input_arrays=wav_data --output_arrays=labels_softmax --input_shapes=1,3920\r\n\r\n**The output from the converter invocation**\r\n```\r\nHere is a list of operators for which you will need custom implementations: AudioSpectrogram, DecodeWav, Mfcc.\r\n\r\n# Copy and paste the output here.\r\n```\r\nTraceback (most recent call last):\r\n  File \"tensorflow_core/lite/python/tflite_convert.py\", line 598, in <module>\r\n    main()\r\n  File \"tensorflow_core/lite/python/tflite_convert.py\", line 594, in main\r\n    app.run(main=run_main, argv=sys.argv[:1])\r\n  File \"C:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\platform\\app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"C:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\absl\\app.py\", line 299, in run\r\n    _run_main(main, args)\r\n  File \"C:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\absl\\app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"tensorflow_core/lite/python/tflite_convert.py\", line 580, in run_main\r\n    _convert_tf1_model(tflite_flags)\r\n  File \"tensorflow_core/lite/python/tflite_convert.py\", line 210, in _convert_tf1_model\r\n    output_data = converter.convert()\r\n  File \"C:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\lite\\python\\lite.py\", line 1007, in convert\r\n    **converter_kwargs)\r\n  File \"C:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\lite\\python\\convert.py\", line 457, in toco_convert_impl\r\n    enable_mlir_converter=enable_mlir_converter)\r\n  File \"C:\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\lite\\python\\convert.py\", line 203, in toco_convert_protos\r\n    raise ConverterError(\"See console for info.\\n%s\\n%s\\n\" % (stdout, stderr))\r\ntensorflow.lite.python.convert.ConverterError: See console for info.\r\n2020-02-05 20:57:48.272648: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found\r\n2020-02-05 20:57:48.273069: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\r\n2020-02-05 20:57:49.877294: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: DecodeWav\r\n2020-02-05 20:57:49.877602: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: AudioSpectrogram\r\n2020-02-05 20:57:49.877911: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Mfcc\r\n2020-02-05 20:57:49.883065: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 24 operators, 36 arrays (0 quantized)\r\n2020-02-05 20:57:49.883549: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 24 operators, 36 arrays (0 quantized)\r\n2020-02-05 20:57:49.884589: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 11 operators, 22 arrays (0 quantized)\r\n2020-02-05 20:57:49.887081: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 2: 10 operators, 21 arrays (0 quantized)\r\n2020-02-05 20:57:49.887552: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 3: 9 operators, 19 arrays (0 quantized)\r\n2020-02-05 20:57:49.888012: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 9 operators, 19 arrays (0 quantized)\r\n2020-02-05 20:57:49.888461: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 9 operators, 19 arrays (0 quantized)\r\n2020-02-05 20:57:49.888891: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Identify nearest upsample.: 9 operators, 19 arrays (0 quantized)\r\n2020-02-05 20:57:49.889328: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 0 bytes, theoretical optimal value: 0 bytes.\r\n2020-02-05 20:57:49.889717: I tensorflow/lite/toco/toco_tooling.cc:471] Number of parameters: 926865\r\n2020-02-05 20:57:49.890164: E tensorflow/lite/toco/toco_tooling.cc:498] We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md\r\n and pasting the following:\r\n\r\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: CONV_2D, FULLY_CONNECTED, MAX_POOL_2D, RESHAPE, SOFTMAX. Here is a list of operators for which you will need custom implementations: AudioSpectrogram, DecodeWav, Mfcc.\r\nTraceback (most recent call last):\r\n  File \"c:\\anaconda3\\envs\\tf-gpu\\lib\\runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"c:\\anaconda3\\envs\\tf-gpu\\lib\\runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"C:\\Anaconda3\\envs\\tf-gpu\\Scripts\\toco_from_protos.exe\\__main__.py\", line 7, in <module>\r\n  File \"c:\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\lite\\toco\\python\\toco_from_protos.py\", line 93, in main\r\n    app.run(main=execute, argv=[sys.argv[0]] + unparsed)\r\n  File \"c:\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\platform\\app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"c:\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\absl\\app.py\", line 299, in run\r\n    _run_main(main, args)\r\n  File \"c:\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\absl\\app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"c:\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\lite\\toco\\python\\toco_from_protos.py\", line 56, in execute\r\n    enable_mlir_converter)\r\nException: We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md\r\n and pasting the following:\r\n\r\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: CONV_2D, FULLY_CONNECTED, MAX_POOL_2D, RESHAPE, SOFTMAX. Here is a list of operators for which you will need custom implementations: AudioSpectrogram, DecodeWav, Mfcc.\r\n\r\n\r\n**Also, please include a link to the saved model or GraphDef**\r\n\r\n```\r\n# Put link here or attach to the issue.\r\n```\r\n\r\n**Failure details**\r\nIf the conversion is successful, but the generated model is wrong,\r\nstate what is wrong:\r\n- Producing wrong results and/or decrease in accuracy\r\n- Producing correct results, but the model is slower than expected (model generated from old converter)\r\nWhen I try to convert without '--target_ops=TFLITE_BUILTINS,SELECT_TF_OPS', I get the error saying Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. These are: AudioSpectrogram, DecodeWav, Mfcc.\r\nWhen I use '--target_ops=TFLITE_BUILTINS,SELECT_TF_OPS', I do get a .tflite file, but that file fails to run on Andriod, and gives the error message: \"Unexpected failure when preparing tensor allocations: Regular TensorFlow ops are not supported by this interpreter\"\r\n\r\n**Any other info / logs**\r\nComplete Error when running a .tflite file (that was created using the SELECT_TF_OPS option) on Andriod: \r\nerror running on android:\r\njava.lang.RuntimeException: Unable to start activity ComponentInfo{org.tensorflow.lite.examples.speech/org.tensorflow.lite.examples.speech.SpeechActivity}: java.lang.RuntimeException: java.lang.IllegalStateException: Internal error: Unexpected failure when preparing tensor allocations: Regular TensorFlow ops are not supported by this interpreter. Make sure you apply/link the Flex delegate before inference.\r\n\r\n\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["Try this\r\ntflite_convert \\\r\n--output_file=/output.tflite \\\r\n--graph_def_file /path/to/my_frozen_graph.pb \\\r\n--input_arrays decoded_sample_data,decoded_sample_data:1 \\\r\n--output_arrays labels_softmax \\\r\n--allow_custom_ops", "Thanks! I will try it out soon and let you know. ", "You need to create custom implementations: AudioSpectrogram, DecodeWav, Mfcc. as they are not currently covered by the tflite ops.\r\nSee https://www.tensorflow.org/lite/guide/ops_custom\r\n", "> Try this\r\n> tflite_convert\r\n> --output_file=/output.tflite\r\n> --graph_def_file /path/to/my_frozen_graph.pb\r\n> --input_arrays decoded_sample_data,decoded_sample_data:1\r\n> --output_arrays labels_softmax\r\n> --allow_custom_ops\r\n\r\nThanks it works with above. I only needed to add --enable_v1_converter", "> You need to create custom implementations: AudioSpectrogram, DecodeWav, Mfcc. as they are not currently covered by the tflite ops.\r\n> See https://www.tensorflow.org/lite/guide/ops_custom\r\n\r\nThanks! The command mentioned above worked, but I want to know why you think I will need to do the custom implementations. And if I do need to, is it already not available in GitHub by someone?", "> > Try this\r\n> > tflite_convert\r\n> > --output_file=/output.tflite\r\n> > --graph_def_file /path/to/my_frozen_graph.pb\r\n> > --input_arrays decoded_sample_data,decoded_sample_data:1\r\n> > --output_arrays labels_softmax\r\n> > --allow_custom_ops\r\n> \r\n> Thanks it works with above. I only needed to add --enable_v1_converter\r\n\r\n@Kamanica Did you try the tflite model in android studio?Is it working there?.could you please send the images of the tflite model and graphdef model by opening it in https://lutzroeder.github.io/netron/", "Thanks for providing the link to open the model. I am finding some differences between the original tflite model from the Android example app (conv_actions_frozen.tflite.png) and the new one I created using the tflite_convert command you provided (foo1.tflite.png)\r\n\r\n![conv_actions_frozen tflite](https://user-images.githubusercontent.com/30161253/75095814-fbef2380-5566-11ea-8bde-d450fa75fe39.png)\r\n\r\n![foo1 tflite](https://user-images.githubusercontent.com/30161253/75095821-145f3e00-5567-11ea-9f57-e339a80a1db8.png)\r\n\r\nAny idea why the two tflite models differ, and how to get the new model to be the same as original model? The tensorflow model (pb file) I am using was created using the example speech_commands app, and I had only changed the wav files to customize them, and used the original train.py file to create the model (tensorflow/examples/speech_commands/train.py).", "> Thanks for providing the link to open the model. I am finding some differences between the original tflite model from the Android example app (conv_actions_frozen.tflite.png) and the new one I created using the tflite_convert command you provided (foo1.tflite.png)\r\n> \r\n> ![conv_actions_frozen tflite](https://user-images.githubusercontent.com/30161253/75095814-fbef2380-5566-11ea-8bde-d450fa75fe39.png)\r\n> \r\n> ![foo1 tflite](https://user-images.githubusercontent.com/30161253/75095821-145f3e00-5567-11ea-9f57-e339a80a1db8.png)\r\n> \r\n> Any idea why the two tflite models differ, and how to get the new model to be the same as original model? The tensorflow model (pb file) I am using was created using the example speech_commands app, and I had only changed the wav files to customize them, and used the original train.py file to create the model (tensorflow/examples/speech_commands/train.py).\r\n\r\ni dont know ,but the new tflite model which u got will work in android studio", "Closing this issue since it's resolved. Thanks."]}, {"number": 36499, "title": "tensorflow.fill does not work in keras.layers and models with dynamic shape as it should and as similar functions do", "body": "\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): (MacOS) Darwin-19.2.0-x86_64-i386-64bit - mac version: ('10.15.2', ('', '', ''), 'x86_64')\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): binary (pip install)\r\n- TensorFlow version (use command below): v2.1.0-rc2-17-ge5bf8de410 2.1.0\r\n- Python version: Python 3.7.6\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n\r\n**Describe the current behavior**\r\nIf I use tensorflow.fill in tf.keras.layers layer, where the shape for the fill depends on the input, it doesn't work, although it works with plenty of other similar functions, and would be reasonably expected to work.  \r\n\r\nSpecifically, I call:\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nX = tf.keras.Input((1,))\r\nX2 = tf.keras.layers.Lambda(lambda x: tf.fill((tf.shape(X)[0],1),2.5))(X)\r\nmodel = tf.keras.Model(inputs=X,outputs=X2)\r\nmodel.predict(np.random.randn(10,1))\r\n```\r\n\r\nI get the following error when I try to run \"predict\" with a model built with the label (full error output below):\r\n> _SymbolicException: Inputs to eager execution function cannot be Keras symbolic tensors, but found [<tf.Tensor 'input_1:0' shape=(None, 1) dtype=float32>]\r\n\r\n**Describe the expected behavior**\r\nI expect it to output a 10x1 numpy array of ones.  This happens with other similar functions used in the same way.  E.g., the following all work fine used in the same way:\r\n```\r\nX2 = tf.keras.layers.Lambda(lambda x: tf.random.uniform(tf.shape(x)))(X) \r\nX2 = tf.keras.layers.Lambda(lambda x: tf.zeros_like(x))(X)\r\nX2 = tf.keras.layers.Lambda(lambda x: tf.ones_like(x)*3.5)(X)\r\n```\r\nand they all depend on the shape of the input, for the case of random.uniform it even takes the same call tf.shape in the input and works fine.   There's no reason tf.fill shouldn't work / the similar capability to create a full tensor for an arbitrary value and input shape.\r\n\r\n**Code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nX = tf.keras.Input((1,))\r\nX2 = tf.keras.layers.Lambda(lambda x: tf.fill((tf.shape(X)[0],1),2.5))(X)\r\nmodel = tf.keras.Model(inputs=X,outputs=X2)\r\nmodel.predict(np.random.randn(10,1))\r\n```\r\n\r\n**Other info / logs**\r\n\r\n> Here is the full error output / trace:\r\n> ---------------------------------------------------------------------------\r\n> TypeError                                 Traceback (most recent call last)\r\n> /Users/workspaces/python_virtualenv/tensorflow2/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\r\n>      60                                                op_name, inputs, attrs,\r\n> ---> 61                                                num_outputs)\r\n>      62   except core._NotOkStatusException as e:\r\n> \r\n> TypeError: An op outside of the function building code is being passed\r\n> a \"Graph\" tensor. It is possible to have Graph tensors\r\n> leak out of the function building context by including a\r\n> tf.init_scope in your function building code.\r\n> For example, the following function will fail:\r\n>   @tf.function\r\n>   def has_init_scope():\r\n>     my_constant = tf.constant(1.)\r\n>     with tf.init_scope():\r\n>       added = my_constant * 2\r\n> The graph tensor has name: input_1:0\r\n> \r\n> During handling of the above exception, another exception occurred:\r\n> \r\n> _SymbolicException                        Traceback (most recent call last)\r\n> <ipython-input-1-c6ef6980c816> in <module>\r\n>       5 X2 = tf.keras.layers.Lambda(lambda x: tf.fill((tf.shape(X)[0],1),2.5))(X)\r\n>       6 model = tf.keras.Model(inputs=X,outputs=X2)\r\n> ----> 7 model.predict(np.random.randn(10,1))\r\n> \r\n> /Users/workspaces/python_virtualenv/tensorflow2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py in predict(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\r\n>    1011         max_queue_size=max_queue_size,\r\n>    1012         workers=workers,\r\n> -> 1013         use_multiprocessing=use_multiprocessing)\r\n>    1014 \r\n>    1015   def reset_metrics(self):\r\n> \r\n> /Users/workspaces/python_virtualenv/tensorflow2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py in predict(self, model, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\r\n>     496         model, ModeKeys.PREDICT, x=x, batch_size=batch_size, verbose=verbose,\r\n>     497         steps=steps, callbacks=callbacks, max_queue_size=max_queue_size,\r\n> --> 498         workers=workers, use_multiprocessing=use_multiprocessing, **kwargs)\r\n>     499 \r\n>     500 \r\n> \r\n> /Users/workspaces/python_virtualenv/tensorflow2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py in _model_iteration(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\r\n>     473               mode=mode,\r\n>     474               training_context=training_context,\r\n> --> 475               total_epochs=1)\r\n>     476           cbks.make_logs(model, epoch_logs, result, mode)\r\n>     477 \r\n> \r\n> /Users/workspaces/python_virtualenv/tensorflow2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py in run_one_epoch(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\r\n>     126         step=step, mode=mode, size=current_batch_size) as batch_logs:\r\n>     127       try:\r\n> --> 128         batch_outs = execution_function(iterator)\r\n>     129       except (StopIteration, errors.OutOfRangeError):\r\n>     130         # TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\r\n> \r\n> /Users/workspaces/python_virtualenv/tensorflow2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py in execution_function(input_fn)\r\n>      96     # `numpy` translates Tensors to values in Eager mode.\r\n>      97     return nest.map_structure(_non_none_constant_value,\r\n> ---> 98                               distributed_function(input_fn))\r\n>      99 \r\n>     100   return execution_function\r\n> \r\n> /Users/workspaces/python_virtualenv/tensorflow2/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py in __call__(self, *args, **kwds)\r\n>     566         xla_context.Exit()\r\n>     567     else:\r\n> --> 568       result = self._call(*args, **kwds)\r\n>     569 \r\n>     570     if tracing_count == self._get_tracing_count():\r\n> \r\n> /Users/workspaces/python_virtualenv/tensorflow2/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py in _call(self, *args, **kwds)\r\n>     636               *args, **kwds)\r\n>     637       # If we did not create any variables the trace we have is good enough.\r\n> --> 638       return self._concrete_stateful_fn._filtered_call(canon_args, canon_kwds)  # pylint: disable=protected-access\r\n>     639 \r\n>     640     def fn_with_cond(*inner_args, **inner_kwds):\r\n> \r\n> /Users/workspaces/python_virtualenv/tensorflow2/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in _filtered_call(self, args, kwargs)\r\n>    1609          if isinstance(t, (ops.Tensor,\r\n>    1610                            resource_variable_ops.BaseResourceVariable))),\r\n> -> 1611         self.captured_inputs)\r\n>    1612 \r\n>    1613   def _call_flat(self, args, captured_inputs, cancellation_manager=None):\r\n> \r\n> /Users/workspaces/python_virtualenv/tensorflow2/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in _call_flat(self, args, captured_inputs, cancellation_manager)\r\n>    1690       # No tape is watching; skip to running the function.\r\n>    1691       return self._build_call_outputs(self._inference_function.call(\r\n> -> 1692           ctx, args, cancellation_manager=cancellation_manager))\r\n>    1693     forward_backward = self._select_forward_and_backward_functions(\r\n>    1694         args,\r\n> \r\n> /Users/workspaces/python_virtualenv/tensorflow2/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in call(self, ctx, args, cancellation_manager)\r\n>     543               inputs=args,\r\n>     544               attrs=(\"executor_type\", executor_type, \"config_proto\", config),\r\n> --> 545               ctx=ctx)\r\n>     546         else:\r\n>     547           outputs = execute.execute_with_cancellation(\r\n> \r\n> /Users/workspaces/python_virtualenv/tensorflow2/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\r\n>      73       raise core._SymbolicException(\r\n>      74           \"Inputs to eager execution function cannot be Keras symbolic \"\r\n> ---> 75           \"tensors, but found {}\".format(keras_symbolic_tensors))\r\n>      76     raise e\r\n>      77   # pylint: enable=protected-access\r\n> \r\n> _SymbolicException: Inputs to eager execution function cannot be Keras symbolic tensors, but found [<tf.Tensor 'input_1:0' shape=(None, 1) dtype=float32>]\r\n", "comments": ["i am able to replicate the issue, please find the [gist](https://colab.research.google.com/gist/Saduf2019/693f9a278227723a2456a7a76a607e0b/36499.ipynb#scrollTo=mAH7En1bh4TG) here.\r\n\r\n", "It looks like you have mistyped the `X` as uppercase in the call to tf.shape?\r\n\r\n```\r\nX2 = tf.keras.layers.Lambda(lambda x: tf.fill((tf.shape(X)[0],1),2.5))(X)\r\n```\r\n\r\nShould be:\r\n\r\n```\r\nX2 = tf.keras.layers.Lambda(lambda x: tf.fill((tf.shape(x)[0],1),2.5))(X)\r\n```", "@brian36  Closing this issue as this is the expected behavior. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36499\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36499\">No</a>\n"]}, {"number": 36498, "title": "[INTEL MKL] MKL-DNNL v1.0 integration with AddN ops", "body": "", "comments": []}, {"number": 36497, "title": "[INTEL MKL] Slice and Reshape op support with MKLDNN 1.0", "body": "This PR updates kernels for SliceOp and ReshapeOp to enable MKLDNN 1.0 functionality.", "comments": ["@penpornk Thanks a lot for reviewing this PR. I have addressed all your comments. Please check."]}]