[{"number": 696, "title": "Serialize GraphKeys into GraphDef", "body": "As I understand it, `GraphKeys.VARIABLES` and `GraphKeys.TRAINABLE_VARIABLES` (and other collections) are not serialized with the GraphDef. This means that in order to train a model that had previously been serialized we must recreate all of the variables (simply reifying a `GraphDef` doesn't perform the same init.)\n\nThere seem to be two solutions here:\n1. To serialize these keys into their respective types on `GraphDef` so we can add the variables to their appropriate collections inside `import_graph_def`. (Seems easy enough?)\n2. To recreate the variables the same way, they're created with `tf.Variable` when calling `import_graph_def`. (Seems harder, maybe cleaner?)\n\nThis is apparently on the roadmap per http://stackoverflow.com/a/33763208/307401 but I'd be happy to contribute a fix if someone can point me in the right direction.\n\n(The goal is to be able to train something I've previously serialized.)\n\nEDIT: This should also improve restoring `GraphDef` with `Saver` which is cumbersome.\n", "comments": ["Ok, so I can partially train from a deserialized graph if I manually create the missing `tf.Variable`'s and hooking up their internal properties to the tensors and operations from the original graph. So maybe the GraphKeys don't need to be serialized but I would like to make this process easier.\r\n", "I am working on making save and restore more self-contained. Stay tuned.\n\nSherry\n\nOn Wed, Jan 6, 2016 at 4:09 PM, Jim Fleming notifications@github.com\nwrote:\n\n> Ok, so I can partially train from a deserialized graph by manually create\n> the missing tf.Variable's and hooking up their internal properties to the\n> tensors and operations from the original graph. So maybe the GraphKeys\n> don't need to be serialized but I would like to make this process easier.\n> \n> \u2014\n> Reply to this email directly or view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/696#issuecomment-169504754\n> .\n", "Thanks, that's great to hear!\n\nI have a temporary solution working until that lands.\n", "Hello, my question is more simple. Sorry, I'm discovering tensorflow.\n\nHow can i save GraphDef in python that can be used in C++?\n\nThanks if you can give some some guide with example. I'm not so familiar with Python :)\n\nSophea\n", "To provide an example, it would be great to be able to do something like this:\n\n``` python\nimport tensorflow as tf\nimport numpy as np\n\ntest_input = np.random.rand(10, 1)\n\nwith tf.Graph().as_default() as g_1:\n    inputs = tf.placeholder(tf.float32, [10, 1], name='i')\n    w = tf.Variable(tf.random_normal([10,1]), name='w')\n    b = tf.Variable(tf.random_normal([10]), name='b')\n    output = tf.identity(tf.mul(inputs, w) + b, name='o')\n\ngdef_1 = g_1.as_graph_def()\n\nwith tf.Graph().as_default() as g_combined:\n    x = tf.placeholder(tf.float32, name='inputs')\n    y, = tf.import_graph_def(gdef_1, input_map={\"i:0\": x}\n                             , return_elements=[\"o:0\"])\n    # Maybe do some other imports here...\n    cost = tf.nn.l2_loss(y-x)\n    optimizer = tf.train.AdamOptimizer()\n    trainer = optimizer.minimize(cost)\n\n    with tf.Session() as sess:\n        sess.run(tf.initialize_all_variables())\n        _, c = sess.run([trainer, cost], feed_dict={x: test_input})\n        print c\n```\n", "This should have been fixed by \n\nhttps://github.com/tensorflow/tensorflow/commit/0269c3690b402c63100869cbb7f8a8ea190e8c0a#diff-6de345a74f7146d4104e2c3c4ad2d89b\n\nPlease open a new issue if this doesn't address what you would like to be able to do. Thanks.\n\nSherry\n"]}, {"number": 695, "title": "Add BUILD rule to create a shared library", "body": "#108 (https://github.com/tensorflow/tensorflow/issues/108#issuecomment-167847860)\n\ncc @martinwicke\n", "comments": ["Jenkins, test this please.\n", "Can one of the admins verify this patch?\n"]}, {"number": 694, "title": "Determining if A Value is in a Set", "body": "Hey TF,\n\nThe `logical_or`, `logical_and`, and `select` functions are very useful.\n\nHowever, suppose you have value x, and you wanted to see if it was in a set(a,b,c,d,e). In python you would simply write:\n\n``` python\n\nif x in set([a,b,c,d,e]):\n   #do action\n```\n\nAs far as I can tell, the only way to do this in tensorflow, is to have nested 'logical_or' along with 'tf.equal'. I provided just one iteration of this concept below:\n\n``` python\ntf.logical_or(\ntf.logical_or(tf.equal(x, a), tf.equal(x,b)),\ntf.logical_or(tf.equal(x, c), tf.equal(x,d)),\n)\n\n```\n\n I feel that there must be an easier way to do this in tensorflow. Is there?\n", "comments": ["(Stackoverflow is the appropriate location for this question, since this isn't a bug / feature request)\n", "thanks I will ask there\n"]}, {"number": 693, "title": "Fix file exists error", "body": "In function `tf.train.write_graph`, first check if `logdir` exists, then write file in \"w\" or \"wb\" mode depends on `as_text`\n", "comments": ["Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "I signed it!\n", "CLAs look good, thanks!\n\n<!-- ok -->\n", "(squash the commits once this is done and i'll run a quick test before merging)\n", "Can one of the admins verify this patch?\n", "Can one of the admins verify this patch?\n", "@vrv, done, thanks\n", "@tensorflow-jenkins, test this please.\n", "(ugh, give us some time to fix our CI testing, sorry)\n", "Jenkins, test this please.\n", "@martinwicke: why is one check stuck?\n", "We're working on it. Looking good though, I think we can merge (I'll take the beating if I'm wrong).\n"]}, {"number": 692, "title": "How to read saved model", "body": "I have trained a model, and I would like to write a code file implemented with C++. I know how to restore model with tf.train.Saver().restore() function, while how to get the values of parameters of trained model? Thanks in advance.\n", "comments": ["Load the graph first, call the 'restore_all' subgraph will restore your variables from a checkpoint file\n", "This is a better question for stackoverflow.  Github issues are for bugs or feature requests.\n", "@koth  thanks for your information :+1: \n"]}, {"number": 691, "title": "Wheels are far behind on tensorflow.org", "body": "Hi there,\n\nI'm new to GitHub contributions so let me know if I'm wrong in posting this here.\n\nI have installed both TensorFlows (CPU and GPU) on Ubuntu 14.04 using pip. I faced many problems and then realized that the wheels on the <a href src=\"https://www.tensorflow.org/versions/master/get_started/os_setup.html\">TensorFlow website</a> are quite outdated. The source on GitHub is moving really quickly. In particular, the GPU version does not have stuff like the configure file, among many others.\n\nI then downloaded from source and built the wheels locally. Is there any intention to update the TensorFlow website soon? I can help to solve this issue too so let me know how I can help.\n", "comments": ["We will release new versions of the wheels when we release a new version of tensorflow. As you note, the code moves quite quickly, and so the wheels seem stale, but the last release is not even a month old. We're still working on our automated testing setup and we'll probably make new binaries shortly after.\n"]}, {"number": 690, "title": "list of Ref(float) ", "body": "How do you REGISTER_OP with a list of Ref(float) as input, for example use the OpKernelContext::mutable_input_list to modify a list of inputs:\n\n.Attr(\"y: int\")\n.Input(\"x: y \\* Ref(float)\")\n\nisn't working... how should I define it in the REGISTER_OP?\n\nThanks!\n", "comments": ["Please ask questions like this on stackoverflow.  Github issues are for bugs and feature requests.  Also, whenever something isn't working, please include the error messages you're seeing.\n"]}, {"number": 689, "title": "Fix typos of sample python code and docs in howtos", "body": "", "comments": ["Thank you.\n"]}, {"number": 688, "title": "deadlock running MNIST example in debug mode on GPU", "body": "tensorflow sources at commit d4f3c0a9a5d4bce0752b2883167092a8f5cfb494\n\nwhen building TF for cuda debug:\nbazel build  -config=cuda -c dbg --strip=never //tensorflow/tools/pip_package:build_pip_package\n\nrunning the convolution model results in a hang\n[~/tensorflow/tensorflow/models/image/mnist] python convolutional.py\nExtracting data/train-images-idx3-ubyte.gz\nExtracting data/train-labels-idx1-ubyte.gz\nExtracting data/t10k-images-idx3-ubyte.gz\nExtracting data/t10k-labels-idx1-ubyte.gz\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:909] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:103] Found device 0 with properties:\nname: GeForce GTX TITAN X\nmajor: 5 minor: 2 memoryClockRate (GHz) 1.076\npciBusID 0000:05:00.0\nTotal memory: 12.00GiB\nFree memory: 11.87GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:127] DMA: 0\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:137] 0:   Y\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:702] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:05:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Allocating 11.27GiB bytes.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:52] GPU 0 memory begins at 0xb06c80000 extends to 0xdd853359a\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 1.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 2.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 4.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 8.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 16.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 32.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 64.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 128.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 256.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 512.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 1.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 2.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 4.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 8.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 16.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 32.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 64.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 128.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 256.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 512.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 1.00GiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 2.00GiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 4.00GiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 8.00GiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 16.00GiB\nInitialized!\nEpoch 0.00\nMinibatch loss: 10.112, learning rate: 0.010000\nMinibatch error: 82.8%\nValidation error: 92.4%\n\nattaching a debugger shows the following thread state:\n\n(gdb) i th\n  Id   Target Id         Frame\n  22   Thread 0x7f775789e700 (LWP 18189) \"python\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  21   Thread 0x7f775709d700 (LWP 18190) \"python\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  20   Thread 0x7f775689c700 (LWP 18191) \"python\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  19   Thread 0x7f774bca6700 (LWP 18192) \"python\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  18   Thread 0x7f774b4a5700 (LWP 18193) \"python\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  17   Thread 0x7f774aca4700 (LWP 18194) \"python\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  16   Thread 0x7f771eda3700 (LWP 18195) \"python\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  15   Thread 0x7f771e5a2700 (LWP 18196) \"python\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  14   Thread 0x7f771dda1700 (LWP 18197) \"python\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  13   Thread 0x7f771d5a0700 (LWP 18198) \"python\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  12   Thread 0x7f771cd9f700 (LWP 18199) \"python\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  11   Thread 0x7f771c59e700 (LWP 18200) \"python\" 0x00007f775a41212d in poll () at ../sysdeps/unix/syscall-template.S:81\n  10   Thread 0x7f7709bff700 (LWP 18201) \"python\" pthread_cond_timedwait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_timedwait.S:238\n  9    Thread 0x7f770931e700 (LWP 18202) \"python\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  8    Thread 0x7f7708b1d700 (LWP 18203) \"python\" 0x00007f775a3e5f3d in nanosleep () at ../sysdeps/unix/syscall-template.S:81\n  7    Thread 0x7f770831c700 (LWP 18204) \"python\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  6    Thread 0x7f7707b1b700 (LWP 18205) \"python\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  5    Thread 0x7f770731a700 (LWP 18206) \"python\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  4    Thread 0x7f7706b19700 (LWP 18207) \"python\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  3    Thread 0x7f76fa9b0700 (LWP 18208) \"python\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n  2    Thread 0x7f76fa1af700 (LWP 18209) \"python\" sem_wait () at ../nptl/sysdeps/unix/sysv/linux/x86_64/sem_wait.S:85\n- 1    Thread 0x7f775ab0a740 (LWP 18188) \"python\" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185\n\nthis state never changes.\nbuilding TF w/o GPU support. or in release mode works fine\n", "comments": ["I can reproduce this problem on my side. The hang only shows up with\nexternal Eigen library. During the hang, one Eigen kernel was stuck on GPU.\nIt is unclear whether it is a real hang, or it was just the kernel run\nextremely slowly.\n\nIt is known that there is a recent slowdown after switching to the external\nlibrary. Benoit is currently working on a fix.\n\nOn Tue, Jan 5, 2016 at 1:35 AM, Martin Wicke notifications@github.com\nwrote:\n\n> Assigned #688 https://github.com/tensorflow/tensorflow/issues/688 to\n> @zheng-xq https://github.com/zheng-xq.\n> \n> \u2014\n> Reply to this email directly or view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/688#event-505699811.\n", "I believe this was fixed by https://github.com/tensorflow/tensorflow/commit/38f54b55cdc66e12a2f6ce9d6724440e9738ac6f. After the upgrade to the latest version of Eigen, I can now run mnist on GPU in debug mode:\n\nbazel run --config=cuda -c dbg --strip=never //tensorflow/models/image/mnist:convolutional\n...\nInitialized!\nStep 0 (epoch 0.00), 23.4 ms\nMinibatch loss: 12.054, learning rate: 0.010000\nMinibatch error: 90.6%\nValidation error: 84.6%\nStep 100 (epoch 0.12), 58.6 ms\nMinibatch loss: 3.293, learning rate: 0.010000\nMinibatch error: 6.2%\nValidation error: 7.1%\nStep 200 (epoch 0.23), 57.0 ms\nMinibatch loss: 3.525, learning rate: 0.010000\nMinibatch error: 14.1%\nValidation error: 3.9%\n...\n\nI have run 2900 steps with no problem so far, so I'm closing this issue. Feel free to reopen if you still experience this deadlock\n"]}, {"number": 687, "title": "Pass on a default if debug_name is not set in parse_single_sequence_example", "body": "If left None, debug_name is set to 'SequenceExample'. Fixes #680.\n", "comments": ["@tensorflow-jenkins, test this please.\n", "Pre-empted by internal commit.\n"]}, {"number": 686, "title": "tf.Fill has no gradient.  (Was: \"ValueError: No inputs provided\" when creating optimizer, seems like a bug)", "body": "I am in the process of implementing a version of BinaryConnect in tensorflow, and ran into this weird crash.  I pasted a simple example to demonstrate the crash.  Seems that line w = tf.select(draws,mx_fill,-mx_fill) is causing the problem when the optimization graph is being constructed.\n\n```\n# Simplified example to demonstrate the crash.  Seems that line w = tf.select(draws,mx_fill,-mx_fill) is causing the problem when the optimization graph is being constructed.\n\nimport tensorflow as tf\n\n# Parameters\nlearning_rate = 0.001\nbatch_size = 100\nSEED = None  # Set to None for random seed.\n\n# Network Parameters\nn_image_size = 28\nn_channels = 1\nn_classes = 10 # MNIST total classes (0-9 digits)\n\n# tf Graph input\nx = tf.placeholder(tf.types.float32, [batch_size, n_image_size, n_image_size, n_channels])\ny = tf.placeholder(tf.types.float32, [batch_size, n_classes])\n\n#BinaryConnect like projections\ndef project(W):\n    weights = tf.clip_by_value(W,0.1,-0.1)\n    shape = weights.get_shape()\n    rnd = tf.random_uniform(shape, minval=0, maxval=1.0, dtype=tf.float32, seed=None)\n    mx = tf.reduce_max(tf.abs(weights))\n    mx_fill = tf.fill(shape,mx)        \n    w_norm = tf.div(weights,mx_fill)\n    #[-1,1] -> [0,1]\n    w_prob = tf.div(tf.add(w_norm,tf.fill(shape,1.0)),tf.fill(shape,2.0))\n    prob = tf.clip_by_value(w_prob, 0.0, 1.0) \n    draws = tf.greater(rnd,tf.fill(shape,1.0) - prob)\n    w = tf.select(draws,mx_fill,-mx_fill) #This line seems to be the issue\n    #Note that uncommenting below seems work, suggesting the graph is constructed correctly\n    #w = tf.select(draws,mx_fill,weights)\n    return w\n\ndef net_conv(_x, _weights): \n    wconv_proj = project(_weights['layer1'])\n    out1 = tf.nn.relu(tf.nn.conv2d(x, wconv_proj, strides=[1, 1, 1, 1], padding='SAME'))\n    out1p = tf.nn.max_pool(out1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n\n    wfc_proj = project(_weights['layer2'])\n    shape = out1p.get_shape().as_list()\n    reshape = tf.reshape(out1p, [shape[0], shape[1] * shape[2] * shape[3]])\n    out2 = tf.nn.relu(tf.matmul(reshape, wfc_proj))\n\n    return out2\n\nweights_conv = {\n    'layer1': tf.Variable(tf.truncated_normal([5, 5, n_channels, 32], stddev=0.1, seed=SEED)),\n    'layer2': tf.Variable(tf.truncated_normal([14 * 14 * 32, n_classes], stddev=0.1, seed=SEED))\n}\n\npred1  = net_conv(x, weights_conv)\ncost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred1, y))\noptimizer1 = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n```\n", "comments": ["Sorry, I don't know what is going wrong here.  I'll see if I can get someone to look at it.\n", "(a) the code is broken:  it uses tf.types.float32, which should just be tf.float32.\n\n(b)  The problem is because when you're doing the tf.select(draws, mx_fill, weights), you're potentially sending the gradients to the result of tf.fill().  Fill has no gradient registered.\n\nFill should have a gradient.  Hang on.\n", "Fixed.  Should be pushed here within a day.\n", "(Thanks for catching this!)\n", "Thanks for the quick turnaround guys, look forward to the update!\n", "(just to confirm, it got pushed in the above commit, so it's available at HEAD now)\n"]}, {"number": 685, "title": "Could contens on tensorflow.org be mirrored on github or other places other than google server? ", "body": "I am from China, and I cannot open the tensorflow.org web site. As known to all, google services are not available in China because the Firewall. It would be very helpful if the documents and turoirals can be obtained from other places other than google server. Sorry to bother. Thanks!\n", "comments": ["All of the content on tensorflow.org (without the fancy styling and some math formatting) is also available on github, in the tensorflow/g3doc folder. The HTML on tensorflow.org is generated quite similarly to what github's MarkDown viewer does, so the experience shouldn't be all that different.\n", "Thanks, that's very useful. I have just started to learn tensorflow, it is the place where I can begin ~~\n"]}, {"number": 684, "title": "CUDA_ERROR_NO_DEVICE with Tesla K40c", "body": "Hi,\n\nI'm trying to use TF on a machine with 40 CPUs and 1 Tesla K40c. \n\nThe machine is running openSUSE 13.2 and has CUDA 7 and cuDNN 6.5 installed.\n\n**Problem**\n\nWhen trying to run a simple test script\n\n```\nimport tensorflow as tf\nhello = tf.constant('Hello, TensorFlow!')\nsess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\nprint sess.run(hello)\na = tf.constant(10)\nb = tf.constant(32)\nprint sess.run(a+b)\n```\n\nI get this output + the error \"CUDA_ERROR_NO_DEVICE\":\n\n```\nI tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcublas.so.7.0 locally\nI tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcudnn.so.6.5 locally\nI tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcufft.so.7.0 locally\nI tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcuda.so locally\nI tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcurand.so.7.0 locally\nI tensorflow/core/common_runtime/local_device.cc:40] Local device intra op parallelism threads: 40\nE tensorflow/stream_executor/cuda/cuda_driver.cc:481] failed call to cuInit: CUDA_ERROR_NO_DEVICE\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:114] retrieving CUDA diagnostic information for host: ml-login2\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:121] hostname: ml-login2\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:146] libcuda reported version is: 346.46\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] driver version file contents: \"\"\"NVRM version: NVIDIA UNIX x86_64 Kernel Module  346.46  Tue Feb 17 17:56:08 PST 2015\nGCC version:  gcc version 4.8.3 20140627 [gcc-4_8-branch revision 212064] (SUSE Linux) \nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:150] kernel reported version is: 346.46\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:226] kernel version seems to match DSO: 346.46\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:127] DMA: \nI tensorflow/core/common_runtime/direct_session.cc:58] Direct session inter op parallelism threads: 40\nDevice mapping: no known devices.\nI tensorflow/core/common_runtime/direct_session.cc:134] Device mapping:\n\nConst: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Const: /job:localhost/replica:0/task:0/cpu:0\nHello, TensorFlow!\nConst_2: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Const_2: /job:localhost/replica:0/task:0/cpu:0\nConst_1: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Const_1: /job:localhost/replica:0/task:0/cpu:0\nadd: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] add: /job:localhost/replica:0/task:0/cpu:0\n```\n\n**What I've tried**\nI've tried reinstalling the CUDA toolkit, installing TF from source, but all resulted in the same error. \nnvidia-smi properly finds the GPU and I can successfully run GPU computations through C code that depends on CUDA. It seems that somehow TF can't detect the GPU.\n\nIs this a known issue with k40c GPUs and is there a fix?\n\nThanks!\n-Stephan\n", "comments": ["Does this crash your program? What is CUDA_VISIBLE_DEVICES set to? I get similar output when I set CUDA_VISIBLE_DEVICES=-1, but my program still runs. (I am also using a K40c).\n", "@skearnes Thanks so much! After adding the CUDA_VISIBLE_DEVICES=0 environment variable, TF now detects the GPU :). \n", "Where do you set CUDA_VISIBLE_DEVICES? is it just `export CUDA_VISIBLE_DEVICES=\"-1\"`? I'm getting the same error with the same GPU\n", "I'm having what appears to be the same problem. I get the error message:\n\n> Device mapping: no known devices.\n> I tensorflow/core/common_runtime/direct_session.cc:175] Device mapping:\n> MatMul: /job:localhost/replica:0/task:0/cpu:0\n> I tensorflow/core/common_runtime/simple_placer.cc:818] MatMul: /job:localhost/replica:0/task:0/cpu:0\n> b: /job:localhost/replica:0/task:0/cpu:0\n> I tensorflow/core/common_runtime/simple_placer.cc:818] b: /job:localhost/replica:0/task:0/cpu:0\n> a: /job:localhost/replica:0/task:0/cpu:0\n> I tensorflow/core/common_runtime/simple_placer.cc:818] a: /job:localhost/replica:0/task:0/cpu:0\n\nFrom running:\n\n``` python\nimport tensorflow as tf\n# Creates a graph.\na = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\nb = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\nc = tf.matmul(a, b)\n# Creates a session with log_device_placement set to True.\nsess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n# Runs the op.\nprint sess.run(c)\n```\n\nSetting CUDA_VISIBLE_DEVICES=0 did not solve it for me. I installed TensorFlow using pip on 64-bit Linux (Linux Mint 17.3) with Python 2.7, Cuda 7.5, and cuDNN v4 installed. My graphics card is a GeForce GTX 750 Ti.\n", "anybody found a solution for this ?", "I am also having the same problem with CUDA,8.0 cuDNN v5.", "also have the same question. but the differents is when i use gpu in docker container,will occur the question.  but on my linux environment, it's ok. thankyou", "@tbchj, the issue is probably that you need to use https://github.com/NVIDIA/nvidia-docker for GPU to work in Docker. You don't _have_ to use it, but then you'll basically have to replicate it, and that's no fun, so just use nvidia-docker.", "@dmitry-xnor   yeah, i had already installed nvidia-docker.  if container use gpu must according to  nvidia-docker ? because i used k8s, and the base of k8s  used  is  docker. now i run gpu on k8s   by using the way of  docker volumn (k8s  volumeMounts).  and it works. also needs nvidia-docker.  \r\nnow gpu works.    thank you", "From what I understand, k8s needs to be set up specifically to support GPUs. Try starting your container with nvidia-docker and see if that works, just to narrow down the root cause.", "@dmitry-xnor  enen, yes, k8s needs to be set up specifically to support GPUs. kubelet servicce has some parameters to set for gpu.\r\ndo you use this? k8s+docker+tensorflow  and gpu", "No, in my case it's just docker+tensorflow. I would be interested in reading a HOWTO if you get this working, though. We do have a need for k8s, just not the time to investigate the details.", "now ,our team is building a platform using k8s,gpu,cpu,tensorflow  for training. it's simple, up to now, it  basically works well .   i will consider to write something  if  i'm not busy. haha"]}, {"number": 683, "title": "Fixes two minor anchor link issues.", "body": "I think these were missed by PR #660 \n", "comments": ["Thanks for checking over the last PR! It looks like I definitely missed changing the '#sources' links, so that's good. I was looking over the change on line 110 of adding_an_op/index.md, and after seeing where the links point, there might be an even better anchor to use. Moving to a line note for context.\n"]}, {"number": 682, "title": "TensorFlow on iOS", "body": "In his NIPS tutorial, Jeff Dean mentioned that Google has an internal version of TensorFlow which runs on iOS.  Will this be open sourced?  If so, is there an estimate of how long until it will be available? \n", "comments": ["Yes, we are planning to open source it.  No timeline, but there's a tracking bug here: https://github.com/tensorflow/tensorflow/issues/16.\n"]}, {"number": 681, "title": "Building on OSX with custom swig location", "body": "Tried to compile Tensorflow on OSX where I'd installed swig (through homebrew) to a location not usually in PATH (~/homebrew/bin) and found that it failed to run swig due to an issue with the swig.sh that's checked in. \n\nChanging the path in the swig.sh to the absolute path (rather than rely on it being globally accessible) fixed the issue, but I'm unsure how to fix properly through bazel.\n\nHappy to submit a pull req. if someone could advise how best to fix the issue!\n", "comments": ["so ~/homebrew/bin is in your PATH? I think this is a question for the bazel folk. Bazel passes on the PATH environment variable to shell scripts it runs, but I don't know off the top of my head how to set it explicitly.\n\nClosing this here -- feel free to reopen if it turns out we should have written swig.sh differently.\n", "Yes, ~/homebrew/bin is in my path, but for some reason it's not picked up by the BUILD system. Will check to see what PATH is used when building through bazel and see if there's a way to fix. Thanks!\n"]}, {"number": 680, "title": "Document parse_single_sequence_example", "body": "The docs are completely silent on `parse_single_sequence_example`, even though the (officially referenced) `tf.train.Example` protocol buffers documentation mentions `SequenceExample`, and the documentation for `parse_single_sequence_example` in the source code (parsing_ops.py) appears rather complete. I think just exposing the source code documentation would be very helpful to people. In general though `SequenceExample` could use better documentation as it's a very useful feature.\n", "comments": ["The docs are not exposed so people don't start relying on this feature (whose interface is very likely to change in the future). It's not part of the public API. I realize the distinction isn't perfect, especially if related things are referenced in the parts of the docs that are referenced from official documentation.\n\nThis should be resolved once we publish a more mature version for these ops.\n", "OK, but maybe update the source code docs to point out that `debug_name` must have a value (or fix it so that it doesn't fail if it doesn't.) May save the adventurous among us a few hours of debugging :)\n", "Can you look if #687 fixes the issue? Clearly, the mismatch between documentation and code is a bug.\n", "Yes #687 fixes it. Thanks.\n"]}, {"number": 679, "title": "Fix typo", "body": "Fix typo\n", "comments": []}, {"number": 678, "title": "Tensorboard: missing variable name/label", "body": "When I run the [MNIST example](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/mnist/mnist_with_summaries.py) with tensorboard (v0.6.0) and look at the graph, the bias variable is unnamed (just `Variable`).  If I switch the order that the variables are defined, I can make it so that the weights variable is unnamed.  \n\nIt looks like perhaps the name of the last variable defined isn't captured in the graph_def?  Or perhaps tensorboard isn't picking up the name of the last variable defined?\n\n![image](https://cloud.githubusercontent.com/assets/37310/12095395/28a32d5e-b2c3-11e5-9f26-0378f17f1cdb.png)\n", "comments": ["@dsmilkov \n", "I believe this is fixed, see: https://www.tensorflow.org/tensorboard/index.html#graphs\n", "Hi, the bug persists on my end. I wonder if it was fixed, or was there some special settings to make the variable names show up?"]}, {"number": 677, "title": "Tensorboard: missing image/broken link", "body": "When running Tensorboard (v0.6.0) on the output from https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/mnist/mnist_with_summaries.py I get a broken link symbol and the following in the logs:\n\n```\n192.168.99.1 - - [04/Jan/2016 16:58:45] code 404, message Not Found\n192.168.99.1 - - [04/Jan/2016 16:58:45] \"GET /lib/svg/summary-icon.svg HTTP/1.1\" 404 -\nWARNING:tensorflow:IOError [Errno 2] No such file or directory: '/usr/local/lib/python2.7/dist-packages/tensorflow/tensorboard/lib/svg/summary-icon.svg' on path /usr/local/lib/python2.7/dist-packages/tensorflow/tensorboard/lib/svg/summary-icon.svg\n```\n", "comments": ["I should note that this is in the \"Graph\" view.\n", "@dsmilkov \n", "I have the same issue, nothing whatsoever appears to load into tensorboard, no images, no CSS, no summaries of anything.\n\nAfter viewing source I followed a link:\nhttp://localhost:6006/external/paper-button/paper-button.html\n\n404\n", "Hi guys,\n\nThis has been fixed, but after the 0.6.0 release. You can either wait for the 0.7.0 which will be released soon, or rebuild tensorboard yourself following the instructions at https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tensorboard/README.md#tensorboard-development-instructions\n\nHope this helps!\n", "I built mine 2 days ago.\n", "@Dringite It seems for you, the whole TensorBoard is not working, not just a broken summary icon. For that, see issue #1076 . There is a fix pushed to the release branch but if you want it sooner, take this commit: https://github.com/tensorflow/tensorflow/commit/68e8b0f1e02f1e0e10f4fdd689ede80f973e2756\n", "@jbeda To fix the summary-icon, you need to rebuild tensorboard using bazel and run it:\n\n```\nbazel build tensorflow/tensorboard\nbazel-bin/tensorflow/tensorboard/tensorboard --logdir path/to/log/dir\n```\n\nFor more information about installing and building TensorFlow and TensorBoard from source, see https://www.tensorflow.org/versions/v0.6.0/get_started/os_setup.html#source\n"]}, {"number": 676, "title": " Run tutorials convolutional.py,  resource exhausted: OOM", "body": "My PC has Nvidia GTX960 2G memory, while run the convolutional.py of tutorials failed,\nthe tensorflow version is 0.6,  need some modify on  convolutional.py?\n\n$ cd tensorflow/models/image/mnist\n$ python convolutional.py\nMinibatch loss: 0.739, learning rate: 0.006302\nMinibatch error: 0.0%\nValidation error: 2.0%\nEpoch 9.84\n......\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:403]      Summary of in-use Chunks by size: \nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:406] 28 Chunks of size 256 totalling 7.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:406] 1 Chunks of size 1280 totalling 1.2KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:406] 4 Chunks of size 2048 totalling 8.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:406] 3 Chunks of size 3328 totalling 9.8KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:406] 3 Chunks of size 20480 totalling 60.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:406] 1 Chunks of size 100352 totalling 98.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:406] 3 Chunks of size 204800 totalling 600.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:406] 1 Chunks of size 1605632 totalling 1.53MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:406] 1 Chunks of size 4941824 totalling 4.71MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:406] 3 Chunks of size 6422528 totalling 18.38MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:406] 1 Chunks of size 13302272 totalling 12.69MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:406] 1 Chunks of size 31360000 totalling 29.91MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:406] 1 Chunks of size 1636141568 totalling 1.52GiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:410] Sum Total of in-use chunks: 1.59GiB\nW tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:166] Ran out of memory trying to allocate 39.06MiB.  See logs for memory state\nW tensorflow/core/kernels/conv_ops.cc:288] Resource exhausted: OOM when allocating tensor with shapedim { size: 10000 } dim { size: 32 } dim { size: 32 } dim { size: 1 }\nW tensorflow/core/common_runtime/executor.cc:1076] 0x5a5c0d0 Compute status: Resource exhausted: OOM when allocating tensor with shapedim { size: 10000 } dim { size: 32 } dim { size: 32 } dim { size: 1 }\n     [[Node: Conv2D_4 = Conv2D[T=DT_FLOAT, padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Const_1, Variable/read)]]\nW tensorflow/core/common_runtime/executor.cc:1076] 0x62eaae0 Compute status: Resource exhausted: OOM when allocating tensor with shapedim { size: 10000 } dim { size: 32 } dim { size: 32 } dim { size: 1 }\n     [[Node: Conv2D_4 = Conv2D[T=DT_FLOAT, padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Const_1, Variable/read)]]\n     [[Node: Softmax_2/_53 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_753_Softmax_2\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\nTraceback (most recent call last):\n  File \"/usr/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/models/image/mnist/convolutional.py\", line 292, in <module>\n    tf.app.run()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/default/_app.py\", line 30, in run\n    sys.exit(main(sys.argv))\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/models/image/mnist/convolutional.py\", line 283, in main\n    test_error = error_rate(test_prediction.eval(), test_labels)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 460, in eval\n    return _eval_using_default_session(self, feed_dict, self.graph, session)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2910, in _eval_using_default_session\n    return session.run(tensors, feed_dict)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 368, in run\n    results = self._do_run(target_list, unique_fetch_targets, feed_dict_string)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 444, in _do_run\n    e.code)\ntensorflow.python.framework.errors.ResourceExhaustedError: OOM when allocating tensor with shapedim { size: 10000 } dim { size: 32 } dim { size: 32 } dim { size: 1 }\n     [[Node: Conv2D_4 = Conv2D[T=DT_FLOAT, padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Const_1, Variable/read)]]\n     [[Node: Softmax_2/_53 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_753_Softmax_2\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\nCaused by op u'Conv2D_4', defined at:\n  File \"/usr/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/models/image/mnist/convolutional.py\", line 292, in <module>\n    tf.app.run()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/default/_app.py\", line 30, in run\n    sys.exit(main(sys.argv))\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/models/image/mnist/convolutional.py\", line 253, in main\n    test_prediction = tf.nn.softmax(model(test_data_node))\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/models/image/mnist/convolutional.py\", line 190, in model\n    padding='SAME')\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py\", line 211, in conv2d\n    use_cudnn_on_gpu=use_cudnn_on_gpu, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py\", line 664, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1834, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1043, in __init__\n    self._traceback = _extract_stack()\n", "comments": ["Dupe: https://github.com/tensorflow/tensorflow/issues/609\n"]}, {"number": 675, "title": "Gradients of non-scalars (higher rank Jacobians)", "body": "Currently if you call gradients(ys, xs), it will return the sum of dy/dx over all ys for each x in xs. I believe this doesn't accord with an a priori mathematical notion of the derivative of a vector. I'd like the way to take the derivative of ys wrt xs where both are vectors and have a Jacobian matrix returned. By extension, I'd like to take the derivative of a vector wrt a matrix and get back a 3-tensor. There doesn't seem to be a convenient tensorflow function to compute the Jacobian or higher order derivatives. Am I missing something or is this functionality that we could add? \n", "comments": ["zackchase@, you are right about the current `gradients` function. Currently, you can compute the Jacobian of, say, a vector, by calling `gradients` multiple times, one for every scalar component (obtained by slicing) of the original vector, and reassembling the results. Contributions are welcome to make this nicer and efficient.\n", "It'd be pretty hard to support gradients of non-scalars with our current setup, since it would require every gradient function to handle extra rank input.  The one possibility I could see would be if we add some sort of map facility to register how to add extra ranks to ops, then compute gradients with respect to extra rank by computing lower rank and calling the registered map transformations.\n\nSomeone asked for map a while back, so if anyone wanted to tackle this task that might be the way to go.  Handling it at the gradient function level is probably bad, since it would add required complexity to an existing feature.  Warning: This is a pretty large change, so a good deal of discussion would be in order before starting.\n", "Hi Geoffrey, thanks for taking an interest in this issue. I was initially confused by the use of \"rank\" to describe the number of dimensions of the array. Should we avoid this name in the thread title and documentation to preempt confusion via overloading the linear algebra notion of rank?\n", "Tensor rank is very standard terminology: http://mathworld.wolfram.com/TensorRank.html\n", "Cool. The terminology gets funny when we talk about rank-R decompositions of tensors, meaning the tensor can be represented as a sum of R outer products of rank-1 tensors, but probably not a problem for us to solve here.\n\nOne thing I thought of is that I would like to compute the frobenius norm of the Jacobian of the log probabilities for use as a smoothness penalty much like the smoothness penalty used in a contractive autoencoder. In this case, as we only seek a scalar at the end, is there a more efficient method than separately calculating the derivative of each output with respect to the inputs?\n", "Are you saying your network has a bunch of outputs, and then you combine them into a single scalar that you are trying to optimize?  In that case, you should differentiate with respect to that single scalar.\n", "Not exactly. I'm saying if one wants to penalize the norm of the Jacobian of the mapping function. \nSo optimization objective would be (pseudocode):\n\ncost(y,yhat, X) = loss(y,yhat) + norm(Jacobian(log(yhat), X))\n", "Ah, sorry for not reading carefully.  You're correct that (as far as I know) there's no easy way to do that in current tensorflow.  According to someone more knowledgeable than I, people generally do such contractive autoencoders by writing out the first derivative manually.  Also, they generally restrict to single layer at a time networks for speed issues, since doing the full Jacobian for a multilayer network is quite expensive.\n", "Regardless, it would be good to have a way to call derivatives of vectors and receive gradients of the expected shape.\n", "Differentiating with respect to one variable is similar to how it works in Theano. I agree it may be confusing when TensorFlow automatically turns many variables into one by taking the sum. An alternative would be to fail if there's more than 1 output variable specified, or have a wrapper that automatically calls existing gradient function on each output variable\n\nThe reason for \"one output variable at a time\" in TensorFlow (and Theano) is because we do reverse mode AD by default. In reverse AD you have a single target scalar quantity and you propagate sensitivities with respect to that quantity. In contrast, if you we did forward AD instead, we would naturally support multiple output variables, but only compute derivative with respect to one scalar variable at a time. Supporting mixed mode propagation to cover \"multiple inputs/multiple outputs\" case in the most efficient way could be a lot of extra plumbing.\n\nIf you have a small number of output variables but large number of input variables, standard thing to do is to apply reverse AD with respect to each variable in a loop. This is what Theano recommends to do for compute Hessian for instance: http://deeplearning.net/software/theano/tutorial/gradients.html#computing-the-hessian. If you have a small number of input variables but large number of output variables, then the most efficient thing to do would be to run forward-mode AD for all the input variables in a loop. Forward mode AD is not implemented and would require adding an equivalent of Theano's \"Rop\" operator to differentiable ops and some plumbing to call them instead of existing op \"gradient\" function (existing gradient function is an equivalent of Lop operation, or \"left multiply sensitivity vector by op's jacobian\" operation) \n", "I was hoping to implement higher order derivatives using the map function but am getting an error message I can't quite get my head around. My implementation is (in pseudo code)\n\n```\nparams = tf.Variable(\"some initial value\")\nloss = some_function(params)\ngrads = tf.gradients(loss, params)[0]\nhess = tf.map_fn(lambda grad: tf.gradients(grad, X)[0], grads)\n```\n\nWhen I fetch the hessian, I get the error message\n\n```\nInvalidArgumentError: All inputs to node map/while/gradients/map/TensorArrayUnpack_grad/TensorArrayGrad/TensorArrayGrad must be from the same frame.\n```\n\nI assumed that tensorflow has an issue because it doesn't know about `params` in the loop (cf. [`non_sequences` in theano `scan`](http://deeplearning.net/software/theano/library/scan.html)), and extended `map_fn` to pass extra arguments to the loop. Unfortunately, the extra arguments get wrapped in an identity transformation and `tf.gradients(params, tf.identity(params))` gives `[None]`, which seems a bit unintuitive.\n\nLooping in python is of course fine but I'd like to avoid introducing an extra node to the graph for every parameter. Any suggestions?\n", "@yuanbyu: Do you understand this issue with `tf.map_fn`?\n", "Note for anyone who comes across this thread: `tf.map_fn` is an unrelated thing involving control flow, not something related to mapping over extra rank tensors.\n", "We don't support higher-order gradients for while_loop/map_fn/scan/fold. You should see an informative error message if you try to do that.\n", "@yaroslavvb Any plans on adding forward mode AD? I filed an issue on it a couple weeks ago but haven't heard back.\n", "@vladfi1 I'm no longer at Brain, so I wouldn't know. I would say it is unlikely to ever be part of core TensorFlow. There are >450 ops in TF, so Brain team would have to implement forward AD grad method for all of 450 ops and maintain them forever, or alternatively have to explain why someone's favorite op doesn't have forward AD support.  It seems more realistic that someone would create a separately maintained library that does forward-AD, and utilizes TensorFlow as backend. Kind of like autograd but using TensorFlow instead of numpy as the backend.\n", "Is [`tf.test.compute_gradient`](https://www.tensorflow.org/versions/r0.12/api_docs/python/test/gradient_checking) is some kind of function that we can get the Jacobian matrix (not as a tensor but as a numpy.ndarray) of a vector tensor y w.r.t. a vector tensor x? ", "There are no built-in jacobians in TensorFlow, instead anything called\n'grad' or 'gradient' computes Jacobian-vector product (also called LOp in\ntheano), see\nhttps://en.wikipedia.org/wiki/Automatic_differentiation#Reverse_accumulation\n\nOn Mon, Feb 20, 2017 at 4:04 AM, MYaooo <notifications@github.com> wrote:\n\n> Is tf.test.compute_gradient is some kind of funtion that we can get the\n> jacobian matrix (not as a tensor but as a numpy.ndarray) of a vector tensor\n> y w.r.t. a vector tensor x?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/675#issuecomment-281062188>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AABaHO7dLBLvhJH5KoSiV8WcySnfR5cnks5reYFMgaJpZM4G9_8_>\n> .\n>\n", "@yaroslavvb Thanks for your reply. I see why it's expensive to do that.\r\nDo you have any suggestions if I want to get the numerical results of the Jacobian with certain inputs x. The only not so expensive workaround I can think of is to apply perturbation on each dim of x to get the approximate results.", "[Hessians](https://www.tensorflow.org/api_docs/python/tf/hessians) are supported. But, as you mentioned, they are expensive to compute.", "@myaooo currently `tf.gradients` gives gradient of function which outputs a scalar. You could call it multiple times for each output. IE, `[tf.gradients(component, var) for component in vector]`. \r\nThere's a trick for computing hessians more efficiently described in https://github.com/tensorflow/tensorflow/issues/4897#issuecomment-253056458", "Adding a comment that this was also a bit of a gotcha for me, and simultaenously adding a vote to consider a change to the api. Calling `tf.gradients(matrix, vector, aggregation_method=None)` I would have expected it to return an tensor of the same shape as `matrix`, but it returns `sum(M)` along an axis.", "It's a little less surprising when you know that there's no efficient algorithm to compute Jacobian in this setting, therefore all neural net frameworks use reverse mode AD which requires target to be a scalar", "@el3ment I consider this a bug.  Unfortunately, I've looked into fixing it, and there's a surprising number of tests within TensorFlow that depend on it.  I didn't get past said piles of tests to see whether there's interesting downstream code in Google that uses it.", "@el3ment @girving \r\nI found this confusion as well.\r\n```\r\nx = tf.constant([3], dtype=tf.float32)\r\ny = tf.constant([9,8,7,6,5], dtype=tf.float32)\r\nz = x_mean * y\r\nsess.run(tf.gradients(z, x_mean))\r\n```\r\nand I got array([35.])", "Just trying to understand something. I was trying to make a hack of `tf.gradient` that would give, for a `y` of rank (M,N) and an `x` of rank (Q,P) a gradient tensor of rank (M,N,Q,P) as one would naturally expect. However, as mentioned already here, what one gets is a rank (Q,P) which is the grad of the sum of the elements of `y`.  Now what I can't figure out, looking into the tensorflow code is where is that sum over elements of `y`  made? Is it as the beginning or at the end? Could someone help me pinpoint the lines of code where that is done? ", "Note that \"summing ys together\" is sort of buried deep in backprop. Note that TensorFlow uses Reverse Mode AD in order to compute gradients, and reverse mode AD only supports a scalar output function. If you have non-scalar output, we don't have any algorithm much better than calling reverse mode AD on each of the components of the output separate.\r\n\r\n(there's a trick mentioned by ian [here](https://github.com/tensorflow/tensorflow/issues/4897#issuecomment-253056458) which is a bit better on Python overhead compared to calling gradients many times)\r\n\r\nThat said, the place where `summation of ys` happens is in line 479-481 in [gradients_impl.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/gradients_impl.py#L479)\r\n\r\nFirst note that `grad_ys` are set to the same value in this line\r\n`grad_ys = _DefaultGradYs(grad_ys, ys, colocate_gradients_with_ops)\r\n`\r\nLater there's this block\r\n```\r\n\r\n # Add the initial gradients for the ys.\r\n    for y, grad_y in zip(ys, grad_ys):\r\n      _SetGrad(grads, y, grad_y)\r\n```\r\n\r\nNote that if you had a single y*=y1+y2+y3+..., then the gradients would propagate in the same way -- the same backprop value from y would be copied over to nodes y1,y2,y3, so this block implicitly treats `ys` as being added up into the final sum", "Thanks for your response @yaroslavvb !\r\n\r\nBut there are two things which confuse me from your answer:\r\n\r\n**(1)** \r\n\r\n> we don't have any algorithm much better than calling reverse mode AD on each of the components of the output separate.\r\n\r\nI'm pretty sure that that cannot be the case. If you think of a deep network outputting a vector `y`, then the gradient of `y[0]` is basically the same as that from `y[1]`, they only defer by the last weight matrix elements. i.e. `y[0] = W(0,j) V(j, ...) ` while `y[1] = W(1,j) V(j,...)`.\r\n\r\n**(2)**     You say the summation happens at line 479-481 of gradients_impl.py\r\nBut just above those lines, there is the following comment in the code: \r\n    # grads: op => list of gradients received on each output endpoint of the\r\n    # op.  The gradients for each endpoint are initially collected as a list.\r\n    # When it is time to call the op's gradient function, for each endpoint we\r\n    # aggregate the list of received gradients into a Add() Operation if there\r\n    # is more than one.\r\n\r\nAnd indeed when one looks into the function `_SetGrad` there is no addition, only appending to a list, and all the `y` 's, if I understand correctly, are still kept separate by being different keys to the dictionary `grads`.  \r\n\r\nSo I am utterly confused by this.\r\n\r\nAlso thank you very much for @goodfeli 's trick, but I don't really understand what he means or how to implement it in practice. \r\n", "@isabeaups the two gradients can differ significantly when there are non-linear operators, as is the case for neural networks.\r\n\r\nAs a toy example, suppose there's some operation that when f(x)=1, and you compute gradient, one of the backprop operators hits limits of its numeric range and produces a NaN, which is a valid float32 value. If you want to backprop from vector [1,2], you are going to have to do full backprop from 1, and from 2, to determine which value causes a NaN. There's no shortcut that'll let you keep same size intermediate matrices and be able to backprop from both values in parallel", "I'm reopening this issue since I think it's still a valid feature request -- @yuanbyu's comment https://github.com/tensorflow/tensorflow/issues/675#issuecomment-241961454 from last year closing it seems to be talking about something else.\r\n\r\nOne simple way to implement this in TensorFlow -- though possibly not the most efficient -- is with `tf.reshape`, `tf.map_fn` and `tf.gradients`:\r\n```python\r\ndef jacobian(y, x):\r\n  def fn(y_i):\r\n    (result,) = tf.gradients(y_i, x)\r\n    return result\r\n  y_flat = tf.reshape(y, (-1,))\r\n  jacobian_flat = tf.map_fn(fn, y_flat)\r\n  return tf.reshape(jacobian_flat, y.shape.concatenate(x.shape))\r\n```\r\n**EDIT: This doesn't work, see @harpone's comment below for a version that works**\r\n\r\nExample usage:\r\n```\r\n>>> x = tf.ones((3,))\r\n>>> y = x ** 2\r\n>>> jacobian(y, x)\r\n<tf.Tensor 'Reshape_6:0' shape=(3, 3) dtype=float32>\r\n```\r\n\r\nCould we simply add `tf.jacobian` to the TensorFlow API and keep `tf.gradients` unchanged?", "@shoyer I can't get your `jacobian` to work (seems like a similar issue to [here](https://github.com/tensorflow/tensorflow/issues/675#issuecomment-215130212)). Here's a minimal example:\r\n\r\n```\r\ntf.reset_default_graph()\r\n\r\nx = tf.placeholder(tf.float32, shape=[3])\r\ny = x ** 2 / 2\r\n\r\njac = jacobian(y, x)\r\n\r\nsess = tf.Session()\r\n\r\nx_val = np.random.randn(3).astype(np.float32)\r\n\r\njac_val = sess.run(jac, feed_dict={x: x_val})\r\n```\r\n\r\nI get\r\n`InvalidArgumentError: TensorArray map/TensorArray_16@map/while/gradients: Could not write to TensorArray index 1 because it has already been read.`\r\n", "Just a FYI for anyone who happens to stumble here looking for a `tf.jacobian`: this seems to work (props to @yaroslavvb):\r\n\r\n```\r\nN = 3\r\n\r\ntf.reset_default_graph()\r\n\r\nx = tf.placeholder(tf.float32, shape=[N])\r\ny = x ** 2 / 2\r\n\r\ny_list = tf.unstack(y)\r\njacobian_list = [tf.gradients(y_, x)[0] for y_ in y_list]  # list [grad(y0, x), grad(y1, x), ...]\r\njacobian = tf.stack(jacobian_list)\r\n\r\nsess = tf.Session()\r\n\r\nx_val = np.random.randn(N)\r\njacobian_val = sess.run(jacobian, feed_dict={x:x_val})\r\n\r\nprint(x_val)\r\nprint(jacobian_val)\r\n```\r\nIndeed seems pretty slow for bigger values of N... would be nice to get the `map_fn` method to work (if it's going to be faster).", "@harpone oops -- good catch! Apologies for posting untested code :). (The version that I actually got working on Friday used a static loop, but then I mistakenly assumed `tf.map_fn` would simplify it.)\r\n\r\nThis version works, but requires that `y` has statically known shape:\r\n```python\r\ndef jacobian(y, x):\r\n  y_flat = tf.reshape(y, (-1,))\r\n  jacobian_flat = tf.stack(\r\n      [tf.gradients(y_i, x)[0] for y_i in tf.unstack(y_flat)])\r\n  return tf.reshape(jacobian_flat, y.shape.concatenate(x.shape))\r\n```", "@shoyer Hi. Thanks for your example to compute jocabian. Computing jocabian by gradients in an `for` iteration is quite slow. Is there a way to use `map_fn` method to accelerate computing?\r\n\r\nI tried `map_fn` in \r\n```python\r\ny_flat = tf.reshape(y, (-1,))\r\njacobian_flat = tf.map_fn(fn, y_flat)\r\n\r\ny_flat = tf.unstack(y, num=3)\r\njacobian_flat = tf.map_fn(fn, y_flat)\r\n\r\ny_flat = tf.split(y, 3)\r\njacobian_flat = tf.map_fn(fn, y_flat)\r\n```\r\nBut all of them can not work. Could you give me some examples for `tf.gradients` in `map_fn`?", "There is no current plan to accelerate computing jacobians. Even if while loops were fixed to be differentiable you wouldn't get a substantial speedup after graph building time, I think.", "I've played a bit with using `while_loop` to build Hessians. The graph build time is significantly reduced (about an order of magnitude). <s>Unfortunately, the evaluation time seems to be worse (about a factor of three worse). Would be nice if we could get the best of both worlds.</s> The evaluation speed is also improved.\r\n\r\nFull details here: #10830 \r\n\r\n", "@liber145 I have to compute semi-large Jacobians and am also having performance issues using a for loop.\r\n\r\nAfter looking at the code by @tillahoffmann I came up with the following function, which gives a decent speedup for larger N:\r\n\r\n``` python\r\ndef jacobian(y_flat, x):\r\n    n = y_flat.shape[0]\r\n\r\n    loop_vars = [\r\n        tf.constant(0, tf.int32),\r\n        tf.TensorArray(tf.float32, size=n),\r\n    ]\r\n\r\n    _, jacobian = tf.while_loop(\r\n        lambda j, _: j < n,\r\n        lambda j, result: (j+1, result.write(j, tf.gradients(y_flat[j], x))),\r\n        loop_vars)\r\n\r\n    return jacobian.stack()\r\n```\r\nIn my case speed is similar to Theano's [`jacobian`](http://deeplearning.net/software/theano/library/gradient.html#theano.gradient.jacobian) function\r\n", "@jeisses, the implementation of `hessians` on the `master` branch looks very similar to the one you suggested (see [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/gradients_impl.py#L941)). ", "@tillahoffmann, yes, I did derive the function directly from that code :smile:. \r\n\r\nBut I'm looking for just a Jacobian matrix, doesn't the `hessians` function contain second order derivates, and still use aggregated gradients? Or could I use the `hessians` function for this?\r\n\r\nThanks", "@jeisses, of course, my bad. In fact, it would be great if we could integrate your proposed Jacobian implementation and simply implement the hessian as `hessian(y, x) = jacobian(gradient(f, x), x)`.", "@shoyer  I used your version to compute the value of Jacobian passing y=model.total_loss and x=weights. The value of jacobian for different weights is exactly same as the value of gradients. Why is it so", "Hi,\n\nI tried the suggestions. But these are errors I get.\n\nIn the first one, y_list = tf.unstack(y[0]) gives error. I am computing the\njacobian of model.total_loss wrt model.trainable_weights. So it gives\nerror: Index out of range using input dim 0; input has only 0 dims for\n'strided_slice_4' (op: 'StridedSlice') with input shapes: [], [1], [1], [1]\nand with computed input tensors: input[3] = <1>.\n\nIn the second one, model.out.shape is (40,10) where 40 is batch size and 10\nis dimension. It gives error in syntax: def jacobian(y,\nx,(model.output.shape):\n\nOn Tue, Sep 26, 2017 at 7:33 PM, candidj0 <notifications@github.com> wrote:\n\n> @shaifugpt <https://github.com/shaifugpt> take a look to your output\n> function, the functions here work for a y = [y0, y1, ...], your output is\n> surely [[y0,y1, ...]] so you can try :\n>\n> def jacobian(y, x):\n>     y_list = tf.unstack(y[0])\n>     jacobian_list = [tf.gradients(y_, x)[0] for y_ in y_list]  # list [grad(y0, x), grad(y1, x), ...]\n>     return tf.stack(jacobian_list)\n>\n> or\n>\n> def jacobian(y, x, size_y):\n>     n = size_y\n>     loop_vars = [\n>         tf.constant(0, tf.int32),\n>         tf.TensorArray(tf.float32, size=n),\n>     ]\n>     _, jacobian = tf.while_loop(\n>         lambda j, _: j < n,\n>         lambda j, result: (j+1, result.write(j, tf.gradients(y[0][j], x))),\n>         loop_vars)\n>     return jacobian.stack()\n>\n> where size_y is the size of the output of your model.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/675#issuecomment-332206689>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AbjabSMFJuQqMcQ3G4sNP1hWB6ljYr34ks5smQRPgaJpZM4G9_8_>\n> .\n>\n", "Sorry @shaifugpt, try this one : \r\n``` \r\ndef jacobian(y, x, n):\r\n    y_list = tf.unstack(y, num = n)\r\n    jacobian_list = [[tf.gradients(y_, x)[0][i] for y_ in tf.unstack(y_list[i])] for i in range(n)] # list [grad(y0, x), grad(y1, x), ...]\r\n    return tf.stack(jacobian_list)\r\n```\r\nn is the batch size.", "Hi\n\nI tried your code. But I could not understand why did you unstack y i.e\nmodel.total_loss in my case. Your code is giving error: ValueError: Invalid\naxis: 0; must be in [0,0) for 'unstack_25' (op: 'Unpack') with input\nshapes: []. This is because model.total_loss has shape: <tf.Tensor\n'mul_1:0' shape=() dtype=float32>\n\nOn Wed, Sep 27, 2017 at 10:31 PM, candidj0 <notifications@github.com> wrote:\n\n> Sorry @shaifugpt <https://github.com/shaifugpt>, try this one :\n>\n> def jacobian(y, x, n):\n>     y_list = tf.unstack(y, num = n)\n>     jacobian_list = [[tf.gradients(y_, x)[0][i] for y_ in tf.unstack(y_list[i])] for i in range(n)] # list [grad(y0, x), grad(y1, x), ...]\n>     return y_list, tf.stack(jacobian_list)\n>\n> n is the batch size.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/675#issuecomment-332586492>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AbjabSyDIDMa_6sSXTL-RCxZiB5unfn-ks5smn91gaJpZM4G9_8_>\n> .\n>\n", "@jeisses and @shoyer I am somewhat confused by the implementation because of the resulting shape of J.\r\n\r\nAccording to [https://en.wikipedia.org/wiki/Jacobian_matrix_and_determinant](url)\r\nLet f: R^n -> R^m , then the J(f) is a m * n matrix. Given, that the input has a size s, J should be a s * m * n matrix, which the implementation of @candidj0 gives us. (However, it is slow due to the for loop.)\r\n\r\n[None, n] doesn't work\r\n\r\nSetting s = 1, \r\nJacobian_1 gives (1, 1, 1, 500) in 3s \r\nJacobian_2 gives (1, 10, 500) in 3s, \r\nJacobian_3 gives (1, 10, 1, 500) in 3s,\r\n\r\nwhereas an s=20 is outputting\r\nJacobian_1 gives (20, 1, 20, 500) in 3s,\r\nJacobian_2 gives (20, 10, 500) in 19s, \r\nJacobian_3 gives (20, 10, 20, 500) in 61,\r\n\r\nHave I missed a point somewhere in the implementation (because I really like to get that speedup)?\r\n\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport time\r\n\r\ndef jacobian_1(y_flat, x):\r\n    n = y_flat.shape[0]\r\n\r\n    loop_vars = [\r\n        tf.constant(0, tf.int32),\r\n        tf.TensorArray(tf.float32, size=n),\r\n    ]\r\n    _, jacobian = tf.while_loop(\r\n        lambda j, _: j < n,\r\n        lambda j, result: (j+1, result.write(j, tf.gradients(y_flat[j], x))),\r\n        loop_vars)\r\n    return jacobian.stack()\r\n\r\ndef jacobian_2(y, x, n):\r\n    y_list = tf.unstack(y, num = n)\r\n    jacobian_list = [[tf.gradients(y_, x)[0][i] for y_ in tf.unstack(y_list[i])] for i in range(n)] # list [grad(y0, x), grad(y1, x), ...]\r\n    return tf.stack(jacobian_list)\r\n\r\ndef jacobian_3(y, x):\r\n  y_flat = tf.reshape(y, (-1,))\r\n  jacobian_flat = tf.stack(\r\n      [tf.gradients(y_i, x)[0] for y_i in tf.unstack(y_flat)])\r\n  return tf.reshape(jacobian_flat, y.shape.concatenate(x.shape))\r\n\r\ns = 20\r\nn = 500\r\nm = 10\r\n\r\nx = tf.placeholder(tf.float32, [s, n])\r\nw = tf.Variable(tf.truncated_normal([n, m], stddev=0.1))\r\nb = tf.Variable(tf.constant(0.1, shape=[m]))\r\ny = tf.matmul(x, w) + b\r\n\r\ninit = tf.global_variables_initializer()\r\nsess = tf.Session()\r\nsess.run(init)\r\n\r\nstart = time.time()\r\nj = jacobian_1(y, x)\r\nj_out = sess.run(j, feed_dict={x:np.random.rand(s,n)})\r\nprint(str(int(time.time() - start)) + \" Seconds: \" + str(j_out.shape))\r\n\r\nstart = time.time()\r\nj_2 = jacobian_2(y,x, s)\r\nj_out = sess.run(j_2, feed_dict={x:np.random.rand(s,n)})\r\nprint(str(int(time.time() - start)) + \" Seconds: \" + str(j_out.shape))\r\n\r\nstart = time.time()\r\nj_3 = jacobian_3(y,x)\r\nj_out = sess.run(j_3, feed_dict={x:np.random.rand(s,n)})\r\nprint(str(int(time.time() - start)) + \" Seconds: \" + str(j_out.shape))\r\n```", "For me, I prefer computing the Jacobian matrix using very lightweight operations in the graph.\r\nSince tf.gradients returns the sum, I mask the layer at a single index and then compute the gradient.\r\nI compute the Jacobian for each point in batches then I stack them at the end outside the graph. \r\nHere is a running example based on @oborchers example that produces (s x m x n) array:\r\n```python\r\nimport time\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\n\r\ndef jacobian(session, y, x, points, batch_size, as_matrix=True):\r\n    \"\"\"The Jacobian matrix of `y` w.r.t. `x` at `points`\r\n\r\n    Let f(x) be some function that has a Jacobian A at point p\r\n    then, f(p) = y = Ap+b\r\n    where A of shape mxn, p of shape nx1 and b of shape mx1\r\n\r\n    Args:\r\n        y: The output tensor\r\n        x: The input tensor\r\n        points: The points of linearization where it can be many points\r\n            of shape [num_points, *self.features_shape]\r\n        batch_size: How many rows of the Jacobian to compute at once\r\n        as_matrix: Whether to return the Jacobian as a matrix or retain\r\n            the shape of the input\r\n\r\n    Returns:\r\n        The Jacobian matrices for the given points\r\n        of shape [num_points, *jacobian_shape]\r\n        If `as_matrix`, jacobian_shape is [y.size, *x.shape]\r\n        else, jacobian_shape is [y.size, x.size]\r\n    \"\"\"\r\n    # add and/or get cached ops to the graph\r\n    if not hasattr(session.graph, \"_placeholder\"):\r\n        session.graph._placeholder = {}\r\n    if not hasattr(session.graph, \"_gradient\"):\r\n        session.graph._gradient = {}\r\n    with session.graph.as_default():\r\n        if y.dtype in session.graph._placeholder:\r\n            placeholder = session.graph._placeholder[y.dtype]\r\n        else:\r\n            placeholder = tf.placeholder(y.dtype)\r\n            session.graph._placeholder[y.dtype] = placeholder\r\n\r\n        if (y, x) in session.graph._gradient:\r\n            gradient = session.graph._gradient[(y, x)]\r\n        else:\r\n            gradient = tf.gradients(placeholder * y, x)[0]\r\n            session.graph._gradient[(y, x)] = gradient\r\n\r\n    # extract the Jacobians for all points\r\n    jacobians_list = []\r\n    for i in range(points.shape[0]):\r\n        # extract the Jacobian matrix for a single point\r\n        partials_list = []\r\n        point = points[i:i + 1, :]\r\n        shape = y.shape.as_list()[1:]\r\n        repeated_point = point\r\n        for mask in masks_batches(shape, batch_size):\r\n            # repeat the point according to the mask's batch_size\r\n            batch_size = mask.shape[0]\r\n            if repeated_point.shape[0] < batch_size:\r\n                repeated_point = np.vstack([point] * batch_size)\r\n            if repeated_point.shape[0] > batch_size:\r\n                repeated_point = repeated_point[:batch_size, :]\r\n            feed = {placeholder: mask, x: repeated_point}\r\n            partial = session.run(gradient, feed_dict=feed)\r\n            partials_list.append(partial)\r\n        jacobian = np.vstack(partials_list)\r\n\r\n        # reshape it as a matrix\r\n        if as_matrix:\r\n            jacobian = jacobian.reshape(jacobian.shape[0], -1)\r\n\r\n        jacobians_list.append(jacobian)\r\n\r\n    # stack Jacobians\r\n    jacobians = np.stack(jacobians_list)\r\n\r\n    return jacobians\r\n\r\n\r\ndef masks_batches(shape, batch_size):\r\n    \"\"\"Batches iterator over all possible masks of the given shape\r\n\r\n    A mask is a numpy.ndarray of shape `shape` of all zeros except\r\n    for a single position it is one. It is useful to get those masks\r\n    in batches instead of getting them one by one.\r\n\r\n    Args:\r\n        shape: The shape of each mask\r\n        batch_size: How many masks to return in each iteration\r\n\r\n    Returns:\r\n        A batch of masks of shape [batch_size, *shape]\r\n    \"\"\"\r\n    num_rows = np.prod(shape)\r\n    if num_rows < batch_size:\r\n        batch_size = num_rows\r\n\r\n    eye = np.eye(batch_size)\r\n    _mask = np.zeros((batch_size, *shape))\r\n    mask = _mask.reshape(batch_size, -1)\r\n\r\n    num_batches = -(-num_rows // batch_size)\r\n    for i in range(num_batches):\r\n        start = i * batch_size\r\n        end = min(start + batch_size, num_rows)\r\n\r\n        # check if last batch is smaller than batch size\r\n        if end - start < batch_size:\r\n            batch_size = end - start\r\n            eye = np.eye(batch_size)\r\n            _mask = np.zeros((batch_size, *shape))\r\n            mask = _mask.reshape(batch_size, -1)\r\n\r\n        mask[:, start:end] = eye\r\n        yield _mask\r\n        mask[:, start:end] = 0\r\n\r\n\r\nif __name__ == '__main__':\r\n    m = 10\r\n    n = 500\r\n    s = 20\r\n\r\n    x = tf.placeholder(tf.float32)\r\n    w = tf.Variable(tf.truncated_normal([n, m], stddev=0.1))\r\n    b = tf.Variable(tf.constant(0.1, shape=[m]))\r\n    y = tf.matmul(x, w) + b\r\n\r\n    init = tf.global_variables_initializer()\r\n    sess = tf.Session()\r\n    sess.run(init)\r\n\r\n    start = time.time()\r\n    j_out = jacobian(sess, y, x, np.random.rand(s, n), m)\r\n    w_out = sess.run(w)\r\n    # they should be equal and error ~ < 1e-6 (single precision)\r\n    error = np.linalg.norm(w_out.T - np.mean(j_out, axis=0))\r\n    if error < 1e-6:\r\n        print(\"Correct Jacobian!\")\r\n    else:\r\n        print(\"Error was {}\".format(error))\r\n    print(str(int(time.time() - start)) + \" Seconds: \" + str(j_out.shape))\r\n\r\n```", "@oborchers i don't check the time but maybe you can try :\r\n\r\n```\r\ndef body(y, x, i):\r\n    n = tf.shape(y)[0]\r\n    loop_vars = [\r\n        tf.constant(0, tf.int32),\r\n        tf.TensorArray(tf.float32, size=n),\r\n    ]\r\n    _, jacobian = tf.while_loop(\r\n        lambda j, _: j < n,\r\n        lambda j, result: (j+1, result.write(j, tf.gradients(y[j], x)[0][i])),\r\n        loop_vars)\r\n    return jacobian.stack()\r\n\r\ndef tf_jacobian(y, x, n):\r\n    loop_vars = [\r\n        tf.constant(0, tf.int32),\r\n        tf.TensorArray(tf.float32, size=n),\r\n    ]\r\n    _, jacobian = tf.while_loop(\r\n        lambda i, _: i < n,\r\n        lambda i, result: (i+1, result.write(i, body(y[i], x, i))),\r\n        loop_vars)\r\n    return jacobian.stack()\r\n```\r\n\r\njacobians =  tf_jacobian(y, x, n) where n is the batch size.", "@ModarTensai this is great! Thank you. \r\n\r\nIt produces an error for me, though, when `m=1`. I'd like to use this to produce per-example gradients of a single-valued output, so my application will have `m=1` as well. Is there an easy fix you know of, before I dig in?", "@aribenjamin If m = 1, w is a vector not a matrix but I fixed and updated the code\r\nall what I needed to change is line 53 from \r\n```python\r\nrepeated_point = np.zeros(1)\r\n```\r\nto \r\n```python\r\nrepeated_point = point\r\n```\r\nThanks for noticing the bug!", "@ModarTensai and @candidj0 : Awesome guys! You rock, thank you! I'll test them over the weekend and see how they work on a toy dataset.", "> There are no built-in jacobians in TensorFlow, instead anything called\r\n'grad' or 'gradient' computes Jacobian-vector product (also called LOp in\r\ntheano),\r\n\r\nSanity checking, but LOp is vector-Jacobian product, not Jacobian-vector product, correct?", "Nobody seems to have posted any followup, but the codes proposed by @candidj0 and @jeisses do not work when nested (testing in tensorflow 1.5.0). So computing the hessian by nesting will not work (@tillahoffmann). Let me make this a bit more concrete. I am using the jacobian\r\n\r\n```\r\ndef map(f, x, dtype=None, parallel_iterations=10):\r\n    '''\r\n    Apply f to each of the elements in x using the specified number of parallel iterations.\r\n\r\n    Important points:\r\n    1. By \"elements in x\", we mean that we will be applying f to x[0],...x[tf.shape(x)[0]-1].\r\n    2. The output size of f(x[i]) can be arbitrary. However, if the dtype of that output\r\n       is different than the dtype of x, then you need to specify that as an additional argument.\r\n    '''\r\n    if dtype is None:\r\n        dtype = x.dtype\r\n\r\n    n = tf.shape(x)[0]\r\n    loop_vars = [\r\n        tf.constant(0, n.dtype),\r\n        tf.TensorArray(dtype, size=n),\r\n    ]\r\n    _, fx = tf.while_loop(\r\n        lambda j, _: j < n,\r\n        lambda j, result: (j + 1, result.write(j, f(x[j]))),\r\n        loop_vars,\r\n        parallel_iterations=parallel_iterations\r\n    )\r\n    return fx.stack()\r\n\r\ndef jacobian(fx, x, parallel_iterations=10):\r\n    '''\r\n    Given a tensor fx, which is a function of x, vectorize fx (via tf.reshape(fx, [-1])),\r\n    and then compute the jacobian of each entry of fx with respect to x.\r\n    Specifically, if x has shape (m,n,...,p), and fx has L entries (tf.size(fx)=L), then\r\n    the output will be (L,m,n,...,p), where output[i] will be (m,n,...,p), with each entry denoting the\r\n    gradient of output[i] wrt the corresponding element of x.\r\n    '''\r\n    return map(lambda fxi: tf.gradients(fxi, x)[0],\r\n               tf.reshape(fx, [-1]),\r\n               dtype=x.dtype,\r\n               parallel_iterations=parallel_iterations)\r\n```\r\n\r\nI am using this because it supports dynamic sizes, that is, one of the dimensions can be `None`. \r\n\r\nHowever, this simple test \r\n\r\n```\r\n    import numpy\r\n    from numpy.random import randn\r\n\r\n    numpy.random.seed(0)\r\n\r\n    # Here is how everything would look in numpy\r\n    x = randn(3, 3)\r\n    A = randn(2, 3)\r\n    y = numpy.dot(A,numpy.dot(x,x))\r\n\r\n    # and in tensorflow... \r\n    xtf = tf.constant(x, tf.float64)\r\n    Atf = tf.constant(A, tf.float64)\r\n    ytf = tf.matmul(tf.matmul(Atf, xtf), xtf)\r\n\r\n    with tf.Session() as sess:\r\n\r\n        # Now let's try to compute the jacobian \r\n        dydx = jacobian(ytf, xtf)\r\n        print(sess.run(dydx))\r\n        \r\n        # and the hessian... \r\n        d2ydx2 = tf.squeeze(jacobian(dydx, xtf))\r\n        print(sess.run(d2ydx2))\r\n```\r\nthrows the error \r\n\r\n`ValueError: Cannot use 'while_1/while/gradients/f_count_1' as input to 'while_1/while/gradients/f_count' because they are in different while loops. See info log for more details.\r\n`\r\n\r\nDoes anybody know the issue here? \r\nThe first jacobian is correct. The second one (essentially the hessian) throws an error.\r\n\r\n\r\n", "I just tested the previous code on the nightly Docker build, and the error remains. ", "@mholzel I wanted to thank you for that `jacobian` implementation, seems to work perfectly for a problem I am working on. In my opinion, this capability should be pushed to the main TensorFlow branch, as it is useful in many problems.", "@mholzel Have you found how to nest while loop to make it work?", "No. It seems like a really subtle bug in either the gradient or while loop implementation. That requires somebody with a lot more knowledge than me about what is going on there", "damn, thanks anyway... Is there anyone that can help? maybe we can bother @ebrevdo ?", "@marcociccone in TF 1.4 seems to be working fine, if this is an alternative for you.", "This is indeed a bug in TF. It's caused by taking the gradient(y, x) inside a while loop wrt such that the computation of y from x goes through a different while loop, something like:\r\n```\r\nx = ...\r\ny = while_loop(..., [x])\r\nz = while_loop(..., tf.gradients(y, x), [y])\r\n```\r\n\r\nSo in @mholzel's script, it's from passing the outcome of one jacobian call to the other jacobian call. (BTW, thanks very much for the easy repro.)\r\n\r\nUnfortunately this is quite tricky to fix. I'll try to take another look at it tomorrow and see if I can come up with something.", "This is actually extremely tricky to fix. I'm not sure how this was working in 1.4, was it definitely giving the right answer?\r\n\r\nThe fundamental problem is that the second jacobian call (i.e. the hessian) is calling tf.gradients() inside a while loop, and that backprop calculation must go through the while loop from the first jacobian call. TF computes while loop gradients using stacks to store intermediate loop values, so if you're doing that calculation multiple times via another loop, we'd have to somehow re-use the stack values on each iteration. This is conceptually possible but would be a pretty big change. I can at least try to improve the error message though.", "I have never seen the nested call work, but I did not try 1.4. ", "@mholzel for the double jacobian, suppose you just map to tf.hessian instead of tf.gradient. Doesn't solve to arbitrary order but it does get the hessian of a tensor wrt variables.", "There is now an experimental new approach to doing Jacobians here:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/parallel_for/gradients.py#L28", "> There is now an experimental new approach to doing Jacobians here:\r\n> https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/parallel_for/gradients.py#L28\r\n\r\nDid anyone compare the performance of the new functionality and the previous solution posted by @mholzel [here](https://github.com/tensorflow/tensorflow/issues/675#issuecomment-362853672)? I am finding the new `jacobian` included in `gradients.py` way slower than @mholzel solution...", "> > There is now an experimental new approach to doing Jacobians here:\r\n> > https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/parallel_for/gradients.py#L28\r\n> \r\n> Did anyone compare the performance of the new functionality and the previous solution posted by @mholzel [here](https://github.com/tensorflow/tensorflow/issues/675#issuecomment-362853672)? I am finding the new `jacobian` included in `gradients.py` way slower than @mholzel solution...\r\n\r\ngradients_test.py in the same file has some benchmarks that show that pfor based jacobian generally works much faster than a while loop based one. Can you share your benchmark ? ", "I threw together this function, it uses tf.map_fn and assumes a batch style input, but at least it works for batches. It's pretty high level but seems to adress some of the ideas if the conversation above:\r\n````\r\ndef Jacobian(X, y):\r\n    J = tf.map_fn(lambda m: tf.gradients(y[:,:,m:m+1], X)[0], tf.range(tf.shape(y)[-1]), tf.float32)\r\n    J = tf.transpose(tf.squeeze(J), perm = [1,0,2])\r\n    return J\r\n```", "@zackchase Is this resolved? Please close If it was resolved already. Thanks!", "tf.GradientTape.jacobian and tf.GradientTape.batch_jacobian APIs have been added for computing Jacobians. These are based on experimental pfor logic which can also be disabled to fallback to loop based implementation."]}, {"number": 674, "title": "Use of deprecated (Py2.6) / removed (Py3) BaseException.message", "body": "The `message` attribute was [deprecated in Python 2.6 and removed in Python 3](https://www.python.org/dev/peps/pep-0352/). However, it's still used in TensorFlow.\n\nFor instance, [over here in session.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/client/session.py#L354). Under Python 3, this will raise another exception during exception handling.\n", "comments": ["Thanks for the report - feel free to send us a pull request to fix this!\n", "I fixed this for the next release!\n"]}, {"number": 673, "title": "PoolAlloc: Remove div by zero, demote WARN->INFO", "body": "", "comments": []}, {"number": 672, "title": "Running different parts of a graph at a time without recomputation", "body": "Motivated by [this StackOverflow question](http://stackoverflow.com/questions/34536340/how-to-use-tensorflow-optimizer-without-recomputing-activations-in-reinforcement)\n\nAccording to George Dahl's answer, there is currently no way to run part of a graph, then later run the entire graph without recomputing that part of the graph.  Couldn't you always just run the whole thing in the first place, you ask?  Consider this scenario:\n### Context/Example\n\nYou're using tensorflow to implement a reinforcement learning agent with value function approximation trained using stochastic gradient descent.  You're agent contains a method that is called once every iteration/timestep in the experiment.  The method takes an obervation and reward as input and outputs an action.  Consider this sequence of events (Say you're doing q-learning):\n1.  At the end of an iteration, you compute your state-action values to choose an action and then return control to the calling program to simulate a step in the environment.\n2.  At the beginning of the next iteration, it's time to update the parameters.  You want to use tensorflow's optimizer class to automatically calculate the gradients.  Here, you have three options:\n-  Just recompute the state-action values, so you can use the optimizer.  This option leaves you inefficiently calculating part of the graph twice.  This also might not even be viable if you were using something like recurrent neural networks, where calculating the activations changes the state of the nodes.\n-  Hardcode the gradients.  You could just write a function to calculate the gradients yourself and not even use optimizer.  However, if you were experimenting with different network architectures and activation functions in a big convolutional network, this could get pretty cumbersome.\n-  Call everything else from within your agent.  This sacrifices a lot of modularity and neatness in any framework bigger than a small experiment.\n\nSo, in this case, the problem is that your graph (learning with SGD) depends on a value (observation/reward), calculated externally, that depends on the result of part of the graph (state-action values).  And we can't save the state-action values as variables to feed later as placeholders, because then they wouldn't be associated with the operations that produced them, which are required for automatic differentiation.\n### Solution\n\nI'm not yet very familiar with the inner workings of tensorflow, so I'm not sure what the best solution would be.  It would need to be able to give Optimizer the tensors already calculated and the graph with the operations that produced them.  Maybe some kind of Session.partial_run() that saves the computed tensors associated with their nodes until a normal run is done?  Maybe a new method under Optimizer that returns an operation to calculate gradients, depending on a placeholder?  What do you think?\n", "comments": ["+1 for this. \n", "+1 for this.\n", "Try out partial_run. https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/client/session.py#L317\n\nThe feature is still experimental and might yet change.\n", "@georgedahl: Who's working on partial_run so that I can assign this to them?  Do you know if it's time to close?\n", "`partial_run` is a very useful feature! \n\nJust to make sure I understand correctly: \n\nIn the following toy code, when I first derive `tmp` using `partial_run` and then compute the `cost` and `gradient`, is `tmp` only computed once and then reused multiple times?\n\n```\nimport tensorflow as tf\n\nw = tf.Variable(1.0)\ninit = tf.initialize_all_variables()\n\nx = tf.placeholder(\"float\")\nslow = tf.exp(w * x * tf.constant(2.0))\ncost = x * slow + x * slow\ngrad = tf.gradients(cost, w)[0]\nfeed = {x: 3.0}\n\n# Efficient\nwith tf.Session() as sess:\n    sess.run(init)\n    h = sess.partial_run_setup([slow, cost, grad], [x])\n    # First derive slow\n    sess.partial_run(h, slow, feed_dict=feed)\n    # Then re-use slow multiple times (w/o recomputing it)\n    print(sess.partial_run(h, cost))\n    print(sess.partial_run(h, grad))\n\n# Naive / Inefficient \nwith tf.Session() as sess:\n    sess.run(init)\n    # Cost and grad each recompute 'slow' twice\n    print(sess.run(cost, feed_dict=feed))\n    print(sess.run(grad, feed_dict=feed))\n```\n\nAnd, is there a way to see/check the computation steps it's doing?\n", "Hi,\nDoe's partial_run work for RNN?\nThanks,\nNir\n", "It should work for any TensorFlow graph, as far as I know. If it doesn't file a bug.\n", "@markusdr,\r\n\r\nThis is exactly what I need to know about partial run! Have you found an answer to your questions? \r\n\r\nLen", "@markusdr \r\n\r\nIn the simple case you described, wont the following code do exactly that?\r\n```python\r\ncost_val, grad_val = sess.run([cost,grad], feed_dict=feed)\r\n```\r\nIf not, can someone explain the difference?\r\n\r\nThanks, Jaideep", "There is some interesting logic in following code.\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\none = tf.constant(1, name=\"constant_1\")\r\nstate = tf.Variable(0, name=\"variable_1\")\r\n\r\nnew_state = tf.add(state, one)\r\nupdate_op = tf.assign(state, new_state)\r\n\r\n\r\nsess = tf.Session()\r\nsess.run(tf.global_variables_initializer())\r\nsess.run(tf.local_variables_initializer())\r\n\r\nfor _ in range(4):\r\n    # way 1\r\n    sess.run(update_op)\r\n    result = sess.run([state, new_state])\r\n    # way 2\r\n    # result = sess.run([update_op, state, new_state])\r\n    # way 3\r\n    # result = sess.run([state, new_state, update_op])\r\n    print(result)\r\n```\r\n\r\nWay 1 outputs:\r\n```\r\n[1, 2]\r\n[2, 3]\r\n[3, 4]\r\n[4, 5]\r\n```\r\nBut Way 2 and 3 output:\r\n```\r\n[1, 1, 1]\r\n[2, 2, 2]\r\n[3, 3, 3]\r\n[4, 4, 4]\r\n```", "@Amitayus because 1 is not equivalent to 2 and 3. #13133.", "The documentation for `partial_run` is a little ambiguous. If you're wondering, like I and @markusdr were, \"does `partial_run` keep computed values stored?\", the example in the docs doesn't clear much up. The example there (modified to work standalone) is:\r\n```\r\nimport tensorflow as tf\r\na = tf.placeholder(tf.float32, shape=[])\r\nb = tf.placeholder(tf.float32, shape=[])\r\nc = tf.placeholder(tf.float32, shape=[])\r\nr1 = tf.add(a, b)\r\nr2 = tf.multiply(r1, c)\r\n\r\nwith tf.Session() as sess:\r\n    h = sess.partial_run_setup([r1, r2], [a, b, c])\r\n    res = sess.partial_run(h, r1, feed_dict={a: 1, b: 2})\r\n    res = sess.partial_run(h, r2, feed_dict={c: res})\r\n    \r\n    print(res)\r\n```\r\nThis returns `9.0`. But do we always need to need the result of a previous `partial_run` as input? Changing the input of the last line shows that this is not the case. Internal values are stored.\r\n```\r\nimport tensorflow as tf\r\na = tf.placeholder(tf.float32, shape=[])\r\nb = tf.placeholder(tf.float32, shape=[])\r\nc = tf.placeholder(tf.float32, shape=[])\r\nr1 = tf.add(a, b)\r\nr2 = tf.multiply(r1, c)\r\n\r\nwith tf.Session() as sess:\r\n    h = sess.partial_run_setup([r1, r2], [a, b, c])\r\n    res = sess.partial_run(h, r1, feed_dict={a: 1, b: 2})\r\n    res = sess.partial_run(h, r2, feed_dict={c: 2})\r\n    \r\n    print(res)\r\n```\r\nReturns `6.0`.", "Found some weird behavior of `partial_run`. If we add `optimizer.apply_gradients` to fetches, it updates the variables without any `partial_run` calls to `optimizer.apply_gradients` op and without even calling `partial_run` on `cost`. So when it is actually computed? Looks like, it computes everything it can with inputs already fed.", "But why this throws exception ? \r\n\r\n```\r\nimport tensorflow as tf\r\na = tf.placeholder(tf.float32, shape=[])\r\nb = tf.placeholder(tf.float32, shape=[])\r\nc = tf.placeholder(tf.float32, shape=[])\r\nr1 = tf.add(a, b)\r\nr2 = tf.multiply(r1, c)\r\n\r\nwith tf.Session() as sess:\r\n    h = sess.partial_run_setup([r1, r2], [a, b, c])\r\n    res = sess.partial_run(h, r1, feed_dict={a: 1, b: 2})\r\n    res = sess.partial_run(h, r2, feed_dict={c: 2})\r\n    res = sess.partial_run(h, r2, feed_dict={c: 3})\r\n    \r\n    print(res)\r\n```\r\nWhich prints the following exception. :\r\n`InvalidArgumentError: Must run 'setup' before performing partial runs!`\r\n", "I was also expecting ```partial_run``` to work as @basejn used it. Is that in any way possible? I would like to store the tensor of an intermediate graph node and then only run the rest of the graph with that stored tensor so I don't have to rerun the first part of the graph over and over again even though nothing changes."]}, {"number": 671, "title": "Fix IPython case in MNIST tutorial", "body": "Quick fix to respect the will of IPython developers.\n", "comments": []}, {"number": 670, "title": "Added citations to the relevant papers for Adam, AdaGrad, and RMSprop", "body": "Added citations to the relevant papers for Adam, AdaGrad, and RMSprop keeping with the documentation style used in the RNN docstrings. I think this would be helpful, especially for lesser known optimizers like Adam. \n", "comments": ["Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "I signed it!\n\nOn Sat, Jan 2, 2016 at 7:24 PM, googlebot notifications@github.com wrote:\n\n> Thanks for your pull request. It looks like this may be your first\n> contribution to a Google open source project. Before we can look at your\n> pull request, you'll need to sign a Contributor License Agreement (CLA).\n> \n> [image: :memo:] _Please visit https://cla.developers.google.com/\n> https://cla.developers.google.com/ to sign._\n> \n> Once you've signed, please reply here (e.g. I signed it!) and we'll\n> \n> ## verify. Thanks.\n> - If you've already signed a CLA, it's possible we don't have your\n>   GitHub username or you're using a different email address. Check your\n>   existing CLA data https://cla.developers.google.com/clas and verify\n>   that your email is set on your git commits\n>   https://help.github.com/articles/setting-your-email-in-git/.\n> - If you signed the CLA as a corporation, please let us know the\n>   company's name.\n> \n> \u2014\n> Reply to this email directly or view it on GitHub\n> https://github.com/tensorflow/tensorflow/pull/670#issuecomment-168456156\n> .\n", "CLAs look good, thanks!\n\n<!-- ok -->\n", "Cool, squash the commits into one and we'll merge it in.  Thanks!\n", "No problem. Done! Should appear as one commit now.\n\nOn Sun, Jan 3, 2016 at 7:56 PM, Vijay Vasudevan notifications@github.com\nwrote:\n\n> Cool, squash the commits into one and we'll merge it in. Thanks!\n> \n> \u2014\n> Reply to this email directly or view it on GitHub\n> https://github.com/tensorflow/tensorflow/pull/670#issuecomment-168575579\n> .\n"]}, {"number": 669, "title": "Fix a few typos in convolutional.py and os_setup.md.", "body": "", "comments": ["Thank you!\n"]}, {"number": 668, "title": "Issue from executing zipalign_runner", "body": "", "comments": []}, {"number": 667, "title": "Question about the API document of convolution", "body": "In [issue 196](https://github.com/tensorflow/tensorflow/issues/196), the problem of definition of different padding is mentioned. \nhttps://www.tensorflow.org/versions/master/api_docs/python/nn.html#convolution\n\nI think the document of convolution is still quite confusing right now. \nWhat does the different dimension of `strides = [1, 1, 1, 1]` mean?\nWhy the definition of \"VALID\" and \"SAME\" padding is quite different from the [Stanford cs131n](http://cs231n.github.io/convolutional-networks/) tutorial. \n\nI think most of the people learn CNN according to the tutorials online. Is it possible to modify the document according to the tutorial?  Thank you very much. \n", "comments": ["The strides = [1, 2, 2, 1] are the strides for each of the dimension of the input tensor [batch, in_height, in_width, in_channels]. For the tf.nn.conv2d function the dimension 0 and 3 must have strides equal to 1. Based on what @Yangqing said in #196 I think the padding scheme is non-intuitive due to legacy reasons.\n", "Closing due to lack of activity.\n"]}]