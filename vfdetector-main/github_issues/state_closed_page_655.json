[{"number": 33962, "title": "AutoGraph unexpected indent in tf-nightly-gpu-2.1.0.dev20191103", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): `tf-nightly-gpu-2.1.0.dev20191103`\r\n- Python version: 3.5.2\r\n- CUDA/cuDNN version: 10.0/7.1\r\n- GPU model and memory: GTX 1080 Ti\r\n\r\n**Describe the current behavior**\r\n\r\nAfter upgrading to `tf-nightly-gpu-2.1.0.dev20191103` from `tensorflow-gpu-2.0.0`, I obtained this error when running my code:\r\n\r\n```\r\nWARNING:tensorflow:AutoGraph could not transform <bound method CRFLayer.mean_field of <models.crf_layer.CRFLayer object at 0x7f6124237b00>> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: unexpected indent (<unknown>, line 36)\r\n```\r\nI did `export AUTOGRAPH_VERBOSITY=10` but did not observe any other types of output other than the above. It says **unexpected indent** so I guess something changed in the parsing of Python code when building the graph? The problem does not occur on `tensorflow-gpu-2.0.0` (I installed `tf-nightly-gpu-2.1.0.dev20191103` because I need to be able to `load_weights(pretrained_weights, by_name=True, skip_mismatch=True)`, which is not available in 2.0.0. There is another bug with this function that I will report in a separate issue.)\r\n\r\n**Describe the expected behavior**\r\nLike in TF 2.0.0: no AutoGraph warning.\r\n\r\n**Code to reproduce the issue**\r\nUnfortunately my code has a lot of dependencies and I was unable to create a minimal reproducible example. But from the warning message I guess it's easy enough to check in the source code.", "comments": ["@netw0rkf10w ,\r\nWill you be able to provide Colab link with code you are trying to execute ?Thanks!", "Hi @oanush. Unfortunately this code has a custom TF op in C++ that needs to be compiled. I'm not sure it's possible to do that in Colab. Let me know if sharing a zip file of source code is ok.", "@netw0rkf10w Please share the zip file of source code. Thanks!", "@netw0rkf10w Can you please share the source code?", "@gowthamkpr Sorry for the delay, I have been overwhelmed over the last days. I'm preparing the code.", "Closing this issue as it has been inactive for more than 2 weeks. Please add additional comments and we can open this issue again. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33962\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33962\">No</a>\n", "We have observed similar issues with TF 2.1-rc0. Cannot share source code, but hopefully I could get a minimal reproducible case later on.\r\n\r\n```\r\nWARNING:tensorflow:AutoGraph could not transform <bound method TransformerDecoder._transform of <bytedseq.decoders.transformer_decoder.TransformerDecoder object at 0x7f727cc9e390>> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: unexpected indent (<unknown>, line 31)\r\nW1219 06:50:06.045258 140133751701632 ag_logging.py:146] AutoGraph could not transform <bound method TransformerDecoder._transform of <bytedseq.decoders.transformer_decoder.TransformerDecoder object at 0x7f727cc9e390>> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: unexpected indent (<unknown>, line 31)\r\n```", "Gently ping @mdanatg; does this look familiar to you?", "These unexpected indent errors are new to me, but it looks like a regression. Setting `AUTOGRAPH_VERBOSITY=10` should have given you a whole lot of extra logging. Since autograph outputs to the abseil logger, try adding this somewhere early in your code:\r\n\r\n```\r\nfrom absl import logging\r\nlogging.set_verbosity(logging.INFO)\r\n```\r\n\r\nIn the mean time, could you visually inspect the source code of one of the functions that it complains about? Like e.g. `TransformerDecoder._transform` - does it contain any thing out of the ordinary, like mixing tabs with spaces, backslash `\\` continuations or anything like that?\r\n\r\nAs a side note, to get a minimal repro, could you also try the following command: `tf.autograph.to_code(TransformerDecoder._transform)`. It should allow us to test things outside of your main program, even with unbound variables or missing arguments.", "Also having this problem on a fairly innocuous piece of code:\r\n```\r\n\r\ndef reverse_edges(edges):\r\n    \"\"\"\r\n    Reverse edges to point from left_node -> right_node to\r\n    right_node -> left_node\r\n\r\n    :param edges: dict(('layer', 'idx')), edges\r\n\r\n    :return reversed_edges: dict(('layer', idx')), reversed edges\r\n    \"\"\"\r\n    llayer = edges['layer'][0, 0]\r\n    rlayer = edges['layer'][0, 1]\r\n    reversed_edges = {\r\n            'layer': tf.constant([[rlayer, llayer]]),\r\n            'idx': reverse_edge_idxs(edges['idx']),\r\n            }\r\n    return reversed_edges\r\n\r\ndef key_to_layers(key):\r\n    \"\"\"\r\n    Decodes a key into layer numbers.\r\n\r\n    :param key: str, node or edge key\r\n\r\n    :return llayer: str, left or sender layer number\r\n    :return rlayer: str, right or receiver layer number\r\n    \"\"\"\r\n    if '_to_' in key:\r\n        llayer, _, rlayer = key.split('_')\r\n    else:\r\n        llayer = rlayer = key.split('_')[-1]\r\n    return llayer, rlayer\r\n\r\ndef build_edges(edges, load_reverse_edges = False)\r\n    # Reverse edges do not have to be loaded but can be constructed\r\n    # This is the line that causes the autograph issue\r\n    if not load_reverse_edges:\r\n        for k in list(edges.keys()):\r\n            llayer, rlayer = key_to_layers(k)\r\n            if llayer != rlayer:\r\n                edges[connect_key(rlayer, llayer)] = gbuild.reverse_edges(edges[k])\r\n                edges.pop(k)\r\n```\r\nwhere edges is a dictionary containing tensors as values. Not a complete example, but maybe might help isolating the issue? \r\n", "@mjlbach I tried your code by passing them directly to autograph, e.g. `print(tf.autograph.to_code(build_edges))`. I'm not seeing any errors in Python 3.7; I'll try with 3.5 shortly.\r\n\r\nIf you have the chance, could you try the same test on the function mentioned in the warning message?", "Ok, the two errors are:\r\n```\r\nWARNING:tensorflow:AutoGraph could not transform <bound method ParticleGraphConstructorFromRecords.construct_hierarchy_from_records of <boxphysics.model.fromrecords.BoxGraphConstructorFromRecords object at 0x7fbbf055fd68>> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: unexpected indent (<unknown>, line 91)\r\nWARNING:tensorflow:AutoGraph could not transform <bound method ParticleGraphConstructorFromRecords.remove_invalid_parts_by_nodes of <boxphysics.model.fromrecords.BoxGraphConstructorFromRecords object at 0x7fbbf055fd68>> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: expected an indented block (<unknown>, line 27)\r\n````\r\n\r\nIf I try to run autograph_to_code on the first one, I get:\r\n```\r\n*** IndentationError: unexpected indent\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py\", line 831, in to_code\r\n    experimental_optional_features=experimental_optional_features))\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py\", line 658, in to_graph\r\n    return conversion.convert(entity, program_ctx)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/conversion.py\", line 359, in convert\r\n    free_nonglobal_var_names)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/conversion.py\", line 274, in _convert_with_cache\r\n    entity, program_ctx)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/conversion.py\", line 508, in convert_entity_to_ast\r\n    nodes, name, entity_info = convert_func_to_ast(o, program_ctx)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/conversion.py\", line 668, in convert_func_to_ast\r\n    node, source = parser.parse_entity(f, future_features=future_features)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/pyct/parser.py\", line 209, in parse_entity\r\n    return _attempt_to_parse_normal_source(source, future_features)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/pyct/parser.py\", line 113, in _attempt_to_parse_normal_source\r\n    return parse(source, preamble_len=len(future_features)), source\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/pyct/parser.py\", line 226, in parse\r\n    module_node = gast.parse(src)\r\n  File \"/usr/local/lib/python3.6/dist-packages/gast/gast.py\", line 295, in parse\r\n    return ast_to_gast(_ast.parse(*args, **kwargs))\r\n  File \"/usr/lib/python3.6/ast.py\", line 35, in parse\r\n    return compile(source, filename, mode, PyCF_ONLY_AST)\r\n  File \"<unknown>\", line 91\r\n    if not load_reverse_edges:\r\n```\r\nThe relevant block of code is :\r\n```\r\n    def construct_hierarchy_from_records(self,\r\n            particles,\r\n            edges,\r\n            node_feat_keys = ['pos', 'mass', 'vel', 'force', 'next_vel',\r\n                'material', 'undeform', 'obj_id', 'mask'],\r\n            is_time_consistent = True,\r\n            load_reverse_edges = False,\r\n            ):\r\n        \"\"\"\r\n        Constructs a hierarchical graph of colored nodes and edges from tfrecords\r\n        inputs.\r\n\r\n        :param particles: dict, particles\r\n        :param edges: dict, colored edges\r\n        :param node_feat_keys: list(str), node feature keys to be added to nodes\r\n        :param is_time_consistent: bool, if true it is assumed that the graph does\r\n                not change over time\r\n        :param load_reverse_edges: bool, if true reverse edges are loaded from files\r\n                instead of being constructed\r\n\r\n        :return graph: dict, graph of colored nodes and edges\r\n        \"\"\"\r\n        # IMPORTANT: TO_PARENT AND TO_CHILD EDGES MUST BE SORTED!!! ASC AND DESC!!!\r\n\r\n        # If edges are same across time remove time dimension\r\n        if is_time_consistent:\r\n            for k in edges:\r\n                edges[k] = edges[k][:, 0]\r\n        else:\r\n            raise NotImplementedError('Edges must be consistent across time!')\r\n\r\n        # Convert to edge format\r\n        for k in edges:\r\n            if 'inner' in k or 'outer' in k:\r\n                llayer = rlayer = k.split('_')[-1]\r\n            elif 'to' in k:\r\n                llayer, _, rlayer = k.split('_')\r\n            else:\r\n                raise KeyError('Unknown Edge Key \"%s\"' % k)\r\n            edges[k] = {\r\n                    'layer': np.array([[int(name_key(llayer)), int(name_key(rlayer))]]),\r\n                    'idx': edges[k],\r\n                    }\r\n\r\n        # Reverse edges do not have to be loaded but can be constructed\r\n        if not load_reverse_edges:\r\n            for k in list(edges.keys()):\r\n                llayer, rlayer = key_to_layers(k)\r\n                if llayer > rlayer:\r\n                    edges.pop(k)\r\n\r\n\r\n        # Determine number of nodes per layer\r\n        num_nodes = gbuild.get_num_nodes_per_layer(edges)\r\n        num_nodes[name_key(0)] = tf.shape(particles['mass'])[2]\r\n\r\n        # Convert to batch unique idxs\r\n        for k in edges:\r\n            llayer, rlayer = key_to_layers(k)\r\n            lnum_node = num_nodes[llayer]\r\n            rnum_node = num_nodes[rlayer]\r\n            edges[k]['idx'] = gbuild.batch_edge_idxs(edges[k]['idx'], lnum_node, rnum_node)\r\n\r\n        # Fold time dimension of particles into state dimension\r\n        batch_dim, node_dim = particles['mass'][:, -1].shape.as_list()[0:2]\r\n        leaf_nodes = {}\r\n\r\n        for k in node_feat_keys:\r\n            leaf_nodes[k] = tf.reshape(tf.transpose(particles[k], [0, 2, 1, 3]),\r\n                    [batch_dim, node_dim, -1])\r\n            leaf_nodes[k] = tf.reshape(leaf_nodes[k], [-1, leaf_nodes[k].shape[-1]])\r\n\r\n        leaf_nodes['num_children'] = tf.zeros_like(leaf_nodes['mask'])\r\n\r\n        nodes = {\r\n                name_key(0): leaf_nodes\r\n                }\r\n        dims = {\r\n                name_key(0): [batch_dim, node_dim]\r\n                }\r\n        valid = {\r\n                name_key(0): tf.reshape(nodes[name_key(0)]['mask'][:, 0] * \\\r\n                tf.minimum(nodes[name_key(0)]['obj_id'][:, 0], 1), shape = [-1, 1])\r\n                }\r\n\r\n        # Remove invalid nodes and remap edges\r\n        nodes, edges = self.remove_invalid_parts_by_nodes(nodes, edges, layer = name_key(0))\r\n        edges = self.remap_edges_continuous(edges, num_nodes)\r\n\r\n        # Construct reverse edges if needed\r\n        if not load_reverse_edges:\r\n            for k in list(edges.keys()):\r\n                llayer, rlayer = key_to_layers(k)\r\n                if llayer != rlayer:\r\n                    edges[connect_key(rlayer, llayer)] = gbuild.reverse_edges(edges[k])\r\n\r\n        # Construct higher level nodes\r\n        for layer in range(1, len(num_nodes)):\r\n            layer_nodes = nodes[name_key(0)]\r\n            lindex = edges[connect_key(layer, 0)]['idx'][:, 1:2]\r\n            rindex = edges[connect_key(layer, 0)]['idx'][:, 0]\r\n\r\n            parent_nodes = {}\r\n            for k in layer_nodes:\r\n                parent_nodes[k] = tf.math.unsorted_segment_mean(\r\n                        tf.gather_nd(layer_nodes[k], lindex),\r\n                        rindex, gutils.len_index(rindex))\r\n\r\n            # Correct mass and avoid zero division\r\n            num_children = tf.math.unsorted_segment_sum(\r\n                    tf.gather_nd(tf.ones(tf.shape(layer_nodes['mass']),\r\n                        dtype = layer_nodes['mass'].dtype), lindex),\r\n                    rindex, gutils.len_index(rindex))\r\n            # TODO Check if works???\r\n            parent_nodes['mass'] /= num_children + \\\r\n                    tf.cast(tf.equal(num_children, 0), parent_nodes['mass'].dtype)\r\n            parent_nodes['num_children'] = num_children\r\n\r\n            nodes[name_key(layer)] = parent_nodes\r\n\r\n        # Convert nodes and edges to graph\r\n        for layer in nodes:\r\n            nodes[layer] = nodes[layer]\r\n\r\n        for edge_type in edges:\r\n            edges[edge_type] = edges[edge_type]\r\n\r\n        for layer in nodes:\r\n            if layer == name_key(0):\r\n                continue\r\n            dims[layer] = [batch_dim, num_nodes[layer]]\r\n\r\n        for layer in nodes:\r\n            if layer == name_key(0):\r\n                continue\r\n            valid[layer] = tf.reshape([nodes[layer]['mask'][:, 0] * \\\r\n                    tf.minimum(nodes[layer]['obj_id'][:, 0], 1)], shape = [-1, 1])\r\n\r\n        # New graph construction\r\n        graph = {}\r\n        graph['nodes'] = nodes\r\n        graph['edges'] = edges\r\n        graph['dims'] = dims\r\n        graph['valid'] = valid\r\n\r\n        return graph\r\n```\r\n\r\nOn the second:\r\n```\r\n*** IndentationError: expected an indented block\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py\", line 831, in to_code\r\n    experimental_optional_features=experimental_optional_features))\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py\", line 658, in to_graph\r\n    return conversion.convert(entity, program_ctx)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/conversion.py\", line 359, in convert\r\n    free_nonglobal_var_names)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/conversion.py\", line 274, in _convert_with_cache\r\n    entity, program_ctx)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/conversion.py\", line 508, in convert_entity_to_ast\r\n    nodes, name, entity_info = convert_func_to_ast(o, program_ctx)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/conversion.py\", line 668, in convert_func_to_ast\r\n    node, source = parser.parse_entity(f, future_features=future_features)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/pyct/parser.py\", line 209, in parse_entity\r\n    return _attempt_to_parse_normal_source(source, future_features)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/pyct/parser.py\", line 113, in _attempt_to_parse_normal_source\r\n    return parse(source, preamble_len=len(future_features)), source\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/pyct/parser.py\", line 226, in parse\r\n    module_node = gast.parse(src)\r\n  File \"/usr/local/lib/python3.6/dist-packages/gast/gast.py\", line 295, in parse\r\n    return ast_to_gast(_ast.parse(*args, **kwargs))\r\n  File \"/usr/lib/python3.6/ast.py\", line 35, in parse\r\n    return compile(source, filename, mode, PyCF_ONLY_AST)\r\n  File \"<unknown>\", line 27\r\n    llayer, rlayer = key_to_layers(k)\r\n```\r\nThe relevant block of code is:\r\n```\r\n\r\n    def remove_invalid_parts_by_nodes(self,\r\n            nodes,\r\n            edges,\r\n            layer = name_key(0)\r\n            ):\r\n        \"\"\"\r\n        Removes invalid nodes and adjusts edges to point to the correct node indices\r\n        after removal for the specified layer.\r\n\r\n        :param nodes: dict, colored nodes\r\n        :param edges: dict, colored edges\r\n        :param layer: str, name key of layer\r\n\r\n        :return nodes: dict, valid colored nodes\r\n        :return edges: dict, remapped colored edges\r\n        \"\"\"\r\n        valid_idxs = tf.where(nodes[layer]['mask'][:, 0] * \\\r\n                nodes[layer]['obj_id'][:, 0])\r\n        mapping = tf.scatter_nd(\r\n                indices = valid_idxs,\r\n                updates = tf.range(tf.shape(valid_idxs)[0]),\r\n                shape = tf.cast(tf.shape(nodes[layer]['mask'])[0:1], tf.int64),\r\n                )\r\n\r\n        for k in edges:\r\n            #test\r\n            llayer, rlayer = key_to_layers(k)\r\n\r\n            if llayer != layer and rlayer != layer:\r\n                continue\r\n\r\n            lidxs = edges[k]['idx'][:, 0:1]\r\n            ridxs = edges[k]['idx'][:, 1:2]\r\n\r\n            if llayer == layer:\r\n                lidxs = gbuild.remap_edge_idxs(lidxs, mapping)\r\n\r\n            if rlayer == layer:\r\n                ridxs = gbuild.remap_edge_idxs(ridxs, mapping)\r\n\r\n            edges[k]['idx'] = tf.concat([lidxs, ridxs], axis = -1)\r\n\r\n        for k in nodes[layer]:\r\n            nodes[layer][k] = tf.gather_nd(nodes[layer][k], valid_idxs)\r\n\r\n        return nodes, edges\r\n```", "Thank you, and sorry for the delay. It looks like the warning is caused by the same bug as #35765. Removing the backslash continuations worked in my tests. Until that's fixed, any of these workarounds should silence the warning:\r\n * removing the backslash continuations\r\n * decorating the function with @tf.autograph.experimental.do_not_convert, since it doesn't contain data-dependent control flow\r\n\r\nNote that you can use parentheses to break expressions on multiple lines, as alternative to backslash continuations.", "> Thank you, and sorry for the delay. It looks like the warning is caused by the same bug as #35765. Removing the backslash continuations worked in my tests. Until that's fixed, any of these workarounds should silence the warning:\r\n> \r\n>     * removing the backslash continuations\r\n> \r\n>     * decorating the function with @tf.autograph.experimental.do_not_convert, since it doesn't contain data-dependent control flow\r\n> \r\n> \r\n> Note that you can use parentheses to break expressions on multiple lines, as alternative to backslash continuations.\r\n\r\nThank you!\r\n", "Backslash continuations should now be properly supported; the fix is in tf-nightly and will be available in TF 2.2.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33962\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33962\">No</a>\n"]}, {"number": 33961, "title": "dynamic shape for deconv ops", "body": "i just check https://github.com/tensorflow/tensorflow/issues/833\r\nit provide code for tf.nn.conv2d_transpose to support dyncmic shape. i want to ask how to apply it for slim.conv2d_transpose. Plz help to check. thank you!", "comments": ["This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n Thanks!\r\n"]}, {"number": 33960, "title": "Docker/Kubernetes memory limits not respected? OOMKilled when deployed to GCP ", "body": "````\r\n== check python ===================================================\r\npython version: 3.5.6\r\npython branch: \r\npython build version: ('default', 'Aug 26 2018 21:41:56')\r\npython compiler version: GCC 7.3.0\r\npython implementation: CPython\r\n\r\n\r\n== check os platform ===============================================\r\nos: Linux\r\nos kernel version: #1 SMP Tue Jul 2 22:58:16 UTC 2019\r\nos release version: 4.9.184-linuxkit\r\nos platform: Linux-4.9.184-linuxkit-x86_64-with-debian-buster-sid\r\nlinux distribution: ('debian', 'buster/sid', '')\r\nlinux os distribution: ('debian', 'buster/sid', '')\r\nmac version: ('', ('', '', ''), '')\r\nuname: uname_result(system='Linux', node='413655a3a81f', release='4.9.184-linuxkit', version='#1 SMP Tue Jul 2 22:58:16 UTC 2019', machine='x86_64', processor='x86_64')\r\narchitecture: ('64bit', '')\r\nmachine: x86_64\r\n\r\n\r\n== are we in docker =============================================\r\nYes\r\n\r\n== compiler =====================================================\r\nc++ (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0\r\nCopyright (C) 2017 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n\r\n== check pips ===================================================\r\nnumpy                              1.15.2           \r\nnumpydoc                           0.9.1            \r\nprotobuf                           3.9.1            \r\ntensorflow                         1.14.0           \r\ntensorflow-estimator               1.14.0           \r\ntensorflow-hub                     0.6.0            \r\ntensorflow-serving-api             1.14.0           \r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\ntf.version.VERSION = 1.14.0\r\ntf.version.GIT_VERSION = v1.14.0-0-g87989f6\r\ntf.version.COMPILER_VERSION = 4.8.4\r\nSanity check: array([1], dtype=int32)\r\n        65:\tfind library=libpthread.so.0 [0]; searching\r\n   (hundreds of lines follow here)\r\n== env ==========================================================\r\nLD_LIBRARY_PATH is unset\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\n./tf_env_collect.sh.1: line 147: nvidia-smi: command not found\r\n\r\n== cuda libs  ===================================================\r\n\r\n== tensorflow installed from info ==================\r\nName: tensorflow\r\nVersion: 1.14.0\r\nSummary: TensorFlow is an open source machine learning framework for everyone.\r\nHome-page: https://www.tensorflow.org/\r\nAuthor-email: packages@tensorflow.org\r\nLicense: Apache 2.0\r\nLocation: /root/miniconda3/lib/python3.5/site-packages\r\nRequired-by: witwidget, tensorflow-serving-api, seldon-core\r\n\r\n== python version  ==============================================\r\n(major, minor, micro, releaselevel, serial)\r\n(3, 5, 6, 'final', 0)\r\n\r\n== bazel version  ===============================================\r\nBuild label: 0.19.0\r\nBuild time: Mon Oct 29 14:35:30 2018 (1540823730)\r\nBuild timestamp: 1540823730\r\nBuild timestamp as int: 1540823730\r\n````\r\n\r\n**Describe the current behavior**\r\nI'm using Kubeflow to deploy a simple Keras/TF model training job (two LSTM layers, 28000x150x27 input from CSV). The Dockerfile it produces is:\r\n\r\n````\r\nFROM gcr.io/deeplearning-platform-release/tf-cpu.1-14\r\nWORKDIR /python_env\r\nCOPY requirements.txt .\r\nRUN python3 -m pip install -r requirements.txt\r\nCOPY . .\r\n````\r\n\r\n...and the output at the top of this issue is from within the resulting container.\r\n\r\nThe container has a CPU limit of 7 cores and a memory limit of 26Gi (the host node has 8 cores and 30Gi).\r\n\r\nBy the 3rd of 20 epochs, after about 50 minutes, the container is killed by Kubernetes with OOMKilled. Looking at a graph of memory use, it increases linearly over the 50 minutes, and evidently ignores the limits.\r\n\r\nI have previously trained this model on my laptop (8 cores / 16GB RAM), 20 epochs, without issue, so this looks to be related to the Docker or Kubernetes environment.\r\n\r\n**Describe the expected behavior**\r\nMemory limits are respected.\r\n\r\n**Code to reproduce the issue**\r\nThe above Dockerfile, plus:\r\n\r\n````python\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.models import Sequential\r\nfrom tensorflow.keras.layers import Dense, Dropout, LSTM\r\nfrom urllib.request import urlopen\r\nimport numpy as np\r\nimport importlib\r\nimport os\r\n\r\n# here's how data is loaded\r\ndataset = np.loadtxt(raw_data, delimiter=\",\")\r\n\r\n# build model\r\nmodel = Sequential()\r\nmodel.add(LSTM(32, return_sequences=True))\r\nmodel.add(LSTM(32))\r\nmodel.add(Dense(32, activation='softmax'))\r\nopt = tf.keras.optimizers.Adam(lr=1e-3, decay=1e-5)\r\nmodel.compile(loss='sparse_categorical_crossentropy',\r\n              optimizer=opt, metrics=['accuracy'])\r\n\r\n# training (data has been loaded via np.loadtxt)\r\nmodel.fit(\r\n    training_dataset,\r\n    training_labels,\r\n    epochs=20,\r\n    shuffle=True,\r\n    validation_data=(validation_dataset, validation_labels)\r\n)\r\n````\r\n", "comments": ["Additionally, running the same image locally on my MBP (default Docker setup: 2GiB RAM allocated), the process exited with a `Killed` message.  Via `dmesg` after that:\r\n\r\n````\r\n[ 2045.760028] Out of memory: Kill process 2439 (python3) score 888 or sacrifice child\r\n[ 2045.761277] Killed process 2439 (python3) total-vm:5014356kB, anon-rss:1879228kB, file-rss:0kB, shmem-rss:0kB\r\n[ 2046.137806] oom_reaper: reaped process 2439 (python3), now anon-rss:0kB, file-rss:0kB, shmem-rss:0kB\r\n````\r\n", "A quick note, when I use `tensorflow/tensorflow:latest-py3`, I do not experience the bug. Let me know if there's somewhere else I should raise this (it's `gcr.io/deeplearning-platform-release/tf-cpu.1-14`, GCP's purpose-built-for-GCP image, which doesn't work).\r\n", "@kierenj What file are you using i.e., 'raw_data' in your code?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "I'm very sorry, my time for this whole project was very limited, and I've worked around using `tensorflow/tensorflow:latest-py3`. I haven't managed to find even an hour to share more detail, though I know that is not helpful.", "I am gonna close this issue as it has been resolved. Please add additional comments and we can open this issue again. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33960\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33960\">No</a>\n"]}, {"number": 33959, "title": "libtensorflowlite.so build not correct", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): build use Linux Ubuntu 16.04,deploy on android 9.0(arm64)\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:None\r\n- TensorFlow installed from (source or binary): git clone source code from master branch\r\n- TensorFlow version:master\r\n- Python version:anaconda python 3.6\r\n- Installed using virtualenv? pip? conda?:source code ,none\r\n- Bazel version (if compiling from source):0.24.1\r\n- GCC/Compiler version (if compiling from source):ndk r19c\r\n- CUDA/cuDNN version:none\r\n- GPU model and memory:none\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nI want to build c++ interface of tflite on android device ,using command:\r\nbazel build -s //tensorflow/lite:libtensorflowlite.so --config=android_arm64 --cxxopt='--std=c++11' -c opt\r\nthe build could be succeed ,but the libtensorflowlite.so built is only 5784 Byte, and doesn't work correctly.\r\n\r\nI use the same command on tensorlfow 1.15 ,and can get the right lib ,which is 2MB.\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["The only difference from your environment is the Ubuntu and NDK versions, but the following steps were successful.\r\n\r\n**Tensorflow v2.0.0 + ndk r17c + sdk 29 + Ubuntu 18.04 + Python 3.6**\r\n```bash\r\n$ bazel build \\\r\n-s //tensorflow/lite:libtensorflowlite.so \\\r\n--config=android_arm64 \\\r\n--cxxopt='--std=c++11' \\\r\n-c opt \\\r\n--config=v2\r\n```\r\n![Terminal - b920405@ubuntu: -media-b920405-Windows1-git-tensorflow2 0 0_051](https://user-images.githubusercontent.com/33194443/68121012-0ea70380-ff4a-11e9-8e7f-705f737abe84.png)\r\n![lite - \u30d5\u30a1\u30a4\u30eb\u30de\u30cd\u30fc\u30b8\u30e3\u30fc_052](https://user-images.githubusercontent.com/33194443/68121151-62195180-ff4a-11e9-8f8d-9c0f4edb25b2.png)\r\n", "I have the exact same issue: Running `bazel build -c opt --config android_arm64 //tensorflow/lite:libtensorflowlite.so` on the latest commit `965f4b71f0c719f5466fe0f25f326593ae9e220a` yields a 5.7K `libtensorflowlite.so` (no build errors), while the randomly picked commit `1cf6cb79156d488fd97504ecc6744cd0ab2d31fa` from ~2 weeks ago properly yields 2.3 MB binary .so file.\r\nUsing the recommended Bazel and Android NDK versions.\r\n\r\nNote that I also have the same issue when trying to build for linux x86_64 with `bazel build //tensorflow/lite:libtensorflowlite.so`.", "Thanks for flagging the issue, this does look like a recent regression, likely due to our use of the TF build rule for generating a binary. We'll try to get a fix out quickly, but in the meantime you can sync to a slightly earlier build.", "FYI, this is caused by commit f58c9f835c32e02895bdd629c7660567ae011001. So, another alternative is to comment out \"build --incompatible_remove_legacy_whole_archive\" in tensorflow/.bazelrc.", "Thank you!", "Let me close this since it's working well now."]}, {"number": 33958, "title": "Is it possible to reduce the number of kernels/filters in a trained model in Tensorflow?", "body": "If I have a trained model, where I want to retrain the same model, with few filters/kernel removed from the existing model. e.g. \r\n(The sam ecan be found [here](https://stackoverflow.com/questions/58313035/how-to-reduce-the-number-of-kernels-filters-in-a-trained-model-in-tensorflow?noredirect=1&lq=1), i searched, but came to know that TF dose not support variable resizing, only reshape is supported)\r\n`conv1 = tf.get_variable('conv1_1', shape=(11, 11, 3, 64), initializer=tf.contrib.layers.xavier_initializer()),`\r\nand I want to resize this tensor such that it has the shape of (11, 11, 3, 20) but the same name and position, mean exactly the same variable. Advance thanks for the help.\r\n\r\nI have tried tf.reshape but it gives me error of not matching the number of elements in a and b I have also tried tf.assign(a,b, validate_shape=false)\r\n\r\n```\r\nself.weights = {\r\n    'conv1_': tf.get_variable('conv1_l1', shape=(11, 11, 3, 64), initializer=tf.contrib.layers.xavier_initializer()),\r\n    'conv2_': tf.get_variable('conv2_l1', shape=(7, 7, 64, 128), initializer=tf.contrib.layers.xavier_initializer())\r\n}\r\n```\r\n\r\n", "comments": ["Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\nMake sure you also include the exact command if possible to produce the output included in your test case. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!\r\n", "@ravikyram brother I updated the post, but i think its not allowing any update. I am giving you the details here. Please let me know should you need more details. Thank you. \r\n**System information**\r\n\r\n- My Python version 3.7 and TF version 1.14 (installed via 'pip install') on Windows. \r\n\r\n- Are you willing to contribute it (Yes/No): Unfortunately I have no that much stuff to contribute \ud83d\udc4e \r\n\r\nfurther, for example I have the following code (This is NOT Keras)\r\n```\r\nself.weights = {\r\n    'conv1_': tf.get_variable('conv1_l1', shape=(11, 11, 3, 64), initializer=tf.contrib.layers.xavier_initializer()),\r\n    'conv2_': tf.get_variable('conv2_l1', shape=(7, 7, 64, 128), initializer=tf.contrib.layers.xavier_initializer())\r\n}\r\n```\r\nand I want to resize any of these variable, such that its shape become like 'shape=(11, 11, 3, 20)' during the training. for reference, I am using [this](https://github.com/hugochan/Eye-Tracker/blob/master/itracker_adv.py) code.\r\n**Who will benefit with this feature?**\r\nthose researchers, who are working on network regularization.\r\nMay be, TF have such support, but I tried my best to find any such command, but failed. \r\nthank you ", "@Safiullahmarwat \r\n\r\nCan you please confirm TF version you are using it is 1.4 or 1.14?", "@ravikyram Sir,I am soo sory, my TF version is 1.14.0", "Hi there! should i wait for any response? I dont know why the @tensorflowbutler removed the awaiting response :)", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\nThanks!\r\n", "I think there is no such question on StackOveflow. I asked the question on the [forum ](https://stackoverflow.com/questions/58313035/how-to-reduce-the-number-of-kernels-filters-in-a-trained-model-in-tensorflow/58315394) but nobody answered me, thats why i requested for the feature. If you know any link toward such question, please let me know. Thank you \ud83e\udd47 "]}, {"number": 33957, "title": "model restore error/confict in tensorflow", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): sudo pip3 install tensorflow-gpu==2.0.0\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10.0.130/7.6.2\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nI have saved one model (with more than two layers) using `model.save_weights` and want to restore its weights and only use the front conv layers. But when I using `model.load_weights`, I got two different results:\r\n\r\n1. First, when I load weights only for the front conv layers, one bigger model can load successfully but another smaller model can not load.\r\n2. Two, the bigger model load success but the weights of the last layer is wrong but any other layers weiight is right.\r\n\r\n**Describe the expected behavior**\r\n\r\nI want to load a .ckpt into a smaller model successfully.\r\n\r\n**Code to reproduce the issue**\r\nHere is my bigger model definition:\r\n\r\n```\r\nimport tensorflow as tf\r\nimport math\r\n\r\nNUM_CLASSES = 10\r\n\r\ndef swish(x):\r\n    return x * tf.keras.activations.sigmoid(x)\r\n\r\ndef round_filters(filters, multiplier):\r\n    depth_divisor = 8\r\n    min_depth = None\r\n    min_depth = min_depth or depth_divisor\r\n    filters = filters * multiplier\r\n    new_filters = max(min_depth, int(filters + depth_divisor / 2) // depth_divisor * depth_divisor)\r\n    if new_filters < 0.9 * filters:\r\n        new_filters += depth_divisor\r\n    return int(new_filters)\r\n\r\ndef round_repeats(repeats, multiplier):\r\n    if not multiplier:\r\n        return repeats\r\n    return int(math.ceil(multiplier * repeats))\r\n\r\ndef SEBlock(inputs, input_channels, ratio=0.25):\r\n\r\n    num_reduced_filters = max(1, int(input_channels * ratio))\r\n    branch = tf.keras.layers.GlobalAveragePooling2D()(inputs)\r\n    # branch = tf.keras.layers.Lambda(lambda branch: tf.expand_dims(input=branch, axis=1))(branch)\r\n    branch = tf.keras.backend.expand_dims(branch, 1)\r\n    branch = tf.keras.backend.expand_dims(branch, 1)\r\n    # branch = tf.keras.layers.Lambda(lambda branch: tf.expand_dims(input=branch, axis=1))(branch)\r\n    branch = tf.keras.layers.Conv2D(filters=num_reduced_filters, kernel_size=(1, 1), strides=1, padding=\"same\")(branch)\r\n    branch = swish(branch)\r\n    branch = tf.keras.layers.Conv2D(filters=input_channels, kernel_size=(1, 1), strides=1, padding='same')(branch)\r\n    branch = tf.keras.activations.sigmoid(branch)\r\n    output = inputs * branch\r\n\r\n    return output\r\n\r\ndef MBConv(in_channels, out_channels, expansion_factor, stride, k, drop_connect_rate, inputs, training=False):\r\n    x = tf.keras.layers.Conv2D(filters=in_channels * expansion_factor,kernel_size=(1, 1),strides=1,padding=\"same\")(inputs)\r\n    x = tf.keras.layers.BatchNormalization()(x, training=training)\r\n    x = swish(x)\r\n    x = tf.keras.layers.DepthwiseConv2D(kernel_size=(k, k), strides=stride, padding=\"same\")(x)\r\n    x = tf.keras.layers.BatchNormalization()(x, training=training)\r\n    x = SEBlock(x, in_channels*expansion_factor)\r\n    x = swish(x)\r\n    x = tf.keras.layers.Conv2D(filters=out_channels,kernel_size=(1, 1),strides=1,padding=\"same\")(x)\r\n    x = tf.keras.layers.BatchNormalization()(x, training=training)\r\n    if stride == 1 and in_channels == out_channels:\r\n        if drop_connect_rate:\r\n            x = tf.keras.layers.Dropout(rate=drop_connect_rate)(x, training=training)\r\n        x = tf.keras.layers.Add()([x, inputs])\r\n\r\n    return x\r\n\r\ndef build_mbconv_block(inputs, in_channels, out_channels, layers, stride, expansion_factor, k, drop_connect_rate, training):\r\n\r\n    x = inputs\r\n    for i in range(layers):\r\n        if i == 0:\r\n            x = MBConv(in_channels=in_channels, out_channels=out_channels, expansion_factor=expansion_factor,\r\n                       stride=stride, k=k, drop_connect_rate=drop_connect_rate, inputs=x, training=training)\r\n        else:\r\n            x = MBConv(in_channels=out_channels, out_channels=out_channels, expansion_factor=expansion_factor,\r\n                       stride=1, k=k, drop_connect_rate=drop_connect_rate, inputs=x, training=training)\r\n\r\n    return x\r\n\r\n\r\ndef EfficientNet(inputs, width_coefficient, depth_coefficient, dropout_rate, drop_connect_rate=0.2, training=False):\r\n\r\n    features = []\r\n\r\n    x = tf.keras.layers.Conv2D(filters=round_filters(32, width_coefficient),kernel_size=(3, 3),strides=2, padding=\"same\") (inputs)\r\n    x = tf.keras.layers.BatchNormalization()(x, training=training)\r\n    x = swish(x)\r\n\r\n    x = build_mbconv_block(x, in_channels=round_filters(32, width_coefficient),\r\n                           out_channels=round_filters(16, width_coefficient),\r\n                           layers=round_repeats(1, depth_coefficient),\r\n                           stride=1,\r\n                           expansion_factor=1, k=3,\r\n                           drop_connect_rate=drop_connect_rate,\r\n                           training=training)\r\n    features.append(x)\r\n\r\n    x = build_mbconv_block(x, in_channels=round_filters(16, width_coefficient),\r\n                           out_channels=round_filters(24, width_coefficient),\r\n                           layers=round_repeats(2, depth_coefficient),\r\n                           stride=1,\r\n                           expansion_factor=6, k=3,\r\n                           drop_connect_rate=drop_connect_rate,\r\n                           training=training)\r\n    features.append(x)\r\n\r\n    x = build_mbconv_block(x, in_channels=round_filters(24, width_coefficient),\r\n                           out_channels=round_filters(40, width_coefficient),\r\n                           layers=round_repeats(2, depth_coefficient),\r\n                           stride=2,\r\n                           expansion_factor=6, k=5,\r\n                           drop_connect_rate=drop_connect_rate,\r\n                           training=training)\r\n    features.append(x)\r\n\r\n    x = build_mbconv_block(x, in_channels=round_filters(40, width_coefficient),\r\n                           out_channels=round_filters(80, width_coefficient),\r\n                           layers=round_repeats(3, depth_coefficient),\r\n                           stride=2,\r\n                           expansion_factor=6, k=3,\r\n                           drop_connect_rate=drop_connect_rate,\r\n                           training=training)\r\n    features.append(x)\r\n\r\n    x = build_mbconv_block(x, in_channels=round_filters(80, width_coefficient),\r\n                           out_channels=round_filters(112, width_coefficient),\r\n                           layers=round_repeats(3, depth_coefficient),\r\n                           stride=1,\r\n                           expansion_factor=6, k=5,\r\n                           drop_connect_rate=drop_connect_rate,\r\n                           training=training)\r\n    features.append(x)\r\n\r\n    x = build_mbconv_block(x, in_channels=round_filters(112, width_coefficient),\r\n                           out_channels=round_filters(192, width_coefficient),\r\n                           layers=round_repeats(4, depth_coefficient),\r\n                           stride=2,\r\n                           expansion_factor=6, k=5,\r\n                           drop_connect_rate=drop_connect_rate,\r\n                           training=training)\r\n    features.append(x)\r\n\r\n    x = build_mbconv_block(x, in_channels=round_filters(192, width_coefficient),\r\n                           out_channels=round_filters(320, width_coefficient),\r\n                           layers=round_repeats(1, depth_coefficient),\r\n                           stride=1,\r\n                           expansion_factor=6, k=3,\r\n                           drop_connect_rate=drop_connect_rate,\r\n                           training=training)\r\n    features.append(x)\r\n\r\n    x = tf.keras.layers.Conv2D(filters=round_filters(1280, width_coefficient), kernel_size=(1, 1), strides=1, padding='same')(x)\r\n    x = tf.keras.layers.BatchNormalization()(x, training=training)\r\n    x = swish(x)\r\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\r\n    x = tf.keras.layers.Dropout(rate=dropout_rate)(x, training=training)\r\n    x = tf.keras.layers.Dense(units=1, activation=tf.keras.activations.softmax)(x)\r\n\r\n    return x, features\r\n\r\n\r\ndef efficient_net_b0(inputs, training):\r\n    return EfficientNet(inputs,\r\n                        width_coefficient=1.0,\r\n                        depth_coefficient=1.0,\r\n                        dropout_rate=0.2,\r\n                        drop_connect_rate=0.2,\r\n                        training=training)\r\n\r\ndef up_sample(inputs, training=True):\r\n    x = tf.keras.layers.UpSampling2D()(inputs)\r\n    x = tf.keras.layers.BatchNormalization()(x, training=training)\r\n    x = tf.keras.layers.ReLU()(x)\r\n    return x\r\n\r\ndef biggerModel(inputs, outc, training=True):\r\n\r\n    _, features =  efficient_net_b0(inputs=inputs, training=training)\r\n\r\n    # [ 1/2, 1/4, 1/8, 1/8, 1/16]\r\n    outputs = []\r\n    for i, name in enumerate(features):\r\n        x = features[i]\r\n        if x.shape[1] > inputs.shape[1] // 4:\r\n            continue\r\n        while x.shape[1] < (inputs.shape[1]//4):\r\n            x = up_sample(x, training)\r\n        outputs.append(x)\r\n\r\n    quater_res = tf.keras.layers.Concatenate()(outputs)\r\n    quater_res = tf.keras.layers.Conv2D(512, 3, 1, 'same', activation=tf.nn.relu)(quater_res)\r\n    quater_res = tf.keras.layers.Conv2D(512, 3, 1, 'same', activation=tf.nn.relu)(quater_res)\r\n    quater_res_out = tf.keras.layers.Conv2D(outc, 1, 1, 'same', name='quater', activation=None)(quater_res)\r\n\r\n    half_res = up_sample(quater_res, training)\r\n    half_res = tf.keras.layers.Conv2D(512, 3, 1, 'same', activation=tf.nn.relu)(half_res)\r\n    half_res = tf.keras.layers.Conv2D(512, 3, 1, 'same', activation=tf.nn.relu)(half_res)\r\n    half_res_out = tf.keras.layers.Conv2D(outc, 1, 1, 'same', name='half', activation=None)(half_res)\r\n    \r\n    if training:\r\n        return quater_res_out, half_res_out\r\n    else:\r\n        return quater_res_out\r\n```\r\nAnd here is my smaller model definition:\r\n```\r\ndef smallModel(inputs, outc, training=True):\r\n\r\n\r\n    quater_res = tf.keras.layers.Conv2D(512, 3, 1, 'same', activation=tf.nn.relu)(inputs)\r\n    quater_res = tf.keras.layers.Conv2D(512, 3, 1, 'same', activation=tf.nn.relu)(quater_res)\r\n    quater_res_out = tf.keras.layers.Conv2D(outc, 1, 1, 'same',  activation=None)(quater_res)\r\n\r\n\r\n    half_res = tf.keras.layers.Conv2D(512, 3, 1, 'same', activation=tf.nn.relu)(quater_res)\r\n    half_res = tf.keras.layers.Conv2D(512, 3, 1, 'same', activation=tf.nn.relu)(half_res)\r\n    half_res_out = tf.keras.layers.Conv2D(outc, 1, 1, 'same', activation=None)(half_res)\r\n\r\n    if training:\r\n        return quater_res_out, half_res_out\r\n    else:\r\n        return quater_res_out\r\n```\r\nAbout bigger model, first, I save weights and print layer named 'quater' weights :\r\n\r\n```\r\nif __name__ == '__main__':\r\n    import os\r\n    os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\r\n    inputs = tf.keras.Input(shape=(224, 224, 3), name='modelInput')\r\n    outputs = biggerModel(inputs, outc=18 + 1, training=True)\r\n    model = tf.keras.Model(inputs, outputs)\r\n    # model.summary()\r\n\r\n    model.save_weights('models/test/test')\r\n    # model.load_weights('models/test/test')\r\n\r\n    print(model.get_layer('quater').get_weights()[0][0][0][0:4])\r\n```\r\nand I get this:\r\n![image](https://user-images.githubusercontent.com/18358653/68102867-8441ae00-ff0f-11e9-9d00-3fb77fb126c7.png)\r\nand then I restore weight by setting parameter `training = False` and print **quater layer weights**:\r\n```\r\nif __name__ == '__main__':\r\n\r\n    import os\r\n    os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\r\n    inputs = tf.keras.Input(shape=(224, 224, 3), name='modelInput')\r\n    outputs = biggerModel(inputs, outc=18 + 1, training=False)\r\n    model = tf.keras.Model(inputs, outputs)\r\n    # model.summary()\r\n\r\n    # model.save_weights('models/test/test')\r\n    model.load_weights('models/test/test')\r\n\r\n    print(model.get_layer('quater').get_weights()[0][0][0][0:4])\r\n```\r\nand got result like this:\r\n![image](https://user-images.githubusercontent.com/18358653/68103002-12b62f80-ff10-11e9-8912-b0364f2d39fc.png)\r\nWe can see that this two outputs are different, but I have checkout all other layers weights are same resutlts, so, it's really weird.\r\n\r\nFor smaller model, as like in bigger model I have done, first save weights and print **quater layer weights**:\r\n```\r\n\r\nif __name__ == '__main__':\r\n\r\n    import os\r\n    os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\r\n    inputs = tf.keras.Input(shape=(224, 224, 3), name='modelInput')\r\n    outputs = smallModel(inputs, outc=18 + 1, training=True)\r\n    model = tf.keras.Model(inputs, outputs)\r\n    # model.summary()\r\n\r\n    # model.save_weights('models/test/test')\r\n    model.load_weights('models/test/test')\r\n\r\n    print(model.get_layer('quater').get_weights()[0][0][0][0:4])\r\n```\r\nand result is:\r\n![image](https://user-images.githubusercontent.com/18358653/68103215-d931f400-ff10-11e9-9e32-32bcf90239d1.png)\r\nThen I tried to restore this and setting parameter `training = False`:\r\n```\r\nif __name__ == '__main__':\r\n\r\n    import os\r\n    os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\r\n    inputs = tf.keras.Input(shape=(224, 224, 3), name='modelInput')\r\n    outputs = smallModel(inputs, outc=18 + 1, training=False)\r\n    model = tf.keras.Model(inputs, outputs)\r\n    # model.summary()\r\n\r\n    # model.save_weights('models/test/test')\r\n    model.load_weights('models/test/test')\r\n\r\n    print(model.get_layer('quater').get_weights()[0][0][0][0:4])\r\n```\r\nI got this error:\r\n![image](https://user-images.githubusercontent.com/18358653/68103275-0bdbec80-ff11-11e9-92d9-ba878cc2c4be.png)\r\n\r\nHow can I fix this?\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@murdockhou, Thanks for reporting this issue.\r\nI tried to execute the smaller model but ended up in some error. Please take a look at the [gist](https://colab.sandbox.google.com/gist/gadagashwini/52e93f6695ab783769e3c234ca2270ad/untitled235.ipynb). \r\nPlease help us to reproduce the reported issue. Thanks!", "@gadagashwini,\r\nHi, for smaller model, you need also run `model.save_weights('models/test/test')` first, and then run `model.load_weights('models/test/test')` and will find that we can not load it. In this [gist](https://colab.research.google.com/gist/gadagashwini/52e93f6695ab783769e3c234ca2270ad/untitled235.ipynb#scrollTo=yeS7bTQYo_xd), you just load weights from bigger model save which is not right. By the way, the smaller model do not need any other func except `def smallModel(inputs, outc, training=True)` func.", " \r\n\r\n> @gadagashwini,\r\n> Hi, for smaller model, you need also run `model.save_weights('models/test/test')` first, and then run `model.load_weights('models/test/test')` and will find that we can not load it. In this [gist](https://colab.research.google.com/gist/gadagashwini/52e93f6695ab783769e3c234ca2270ad/untitled235.ipynb#scrollTo=yeS7bTQYo_xd), you just load weights from bigger model save which is not right. By the way, the smaller model do not need any other func except `def smallModel(inputs, outc, training=True)` func.\r\n\r\nChanged the code accordingly and tried to replicate the issue but got a different error. Please see the gist [here](https://colab.sandbox.google.com/gist/gadagashwini/5379f634a5c37b1eb9ef48aa81e38e0c/untitled239.ipynb). Thanks!", "@gadagashwini , its my fault, I forget to set names for output layer, please  use the following `smallModel` instead of the previous one.\r\n```\r\ndef smallModel(inputs, outc, training=True):\r\n\r\n    quater_res = tf.keras.layers.Conv2D(512, 3, 1, 'same', activation=tf.nn.relu)(inputs)\r\n    quater_res = tf.keras.layers.Conv2D(512, 3, 1, 'same', activation=tf.nn.relu)(quater_res)\r\n    quater_res_out = tf.keras.layers.Conv2D(outc, 1, 1, 'same', name='quater', activation=None)(quater_res)\r\n\r\n    half_res = tf.keras.layers.Conv2D(512, 3, 1, 'same', activation=tf.nn.relu)(quater_res)\r\n    half_res = tf.keras.layers.Conv2D(512, 3, 1, 'same', activation=tf.nn.relu)(half_res)\r\n    half_res_out = tf.keras.layers.Conv2D(outc, 1, 1, 'same', name='half', activation=None)(half_res)\r\n\r\n    if training:\r\n        return quater_res_out, half_res_out\r\n    else:\r\n        return quater_res_out\r\n```\r\n\r\nAnd please remember that when save_weights we set parameter `training = True` but will be False when load_weights.\r\n\r\n", "Issue is replicating with TF 2.0.0 on colab. Please take a look at the [gist](https://colab.sandbox.google.com/gist/gadagashwini/13c417c65cbf1a5753d75af39377059b/untitled239.ipynb). Thanks!", "@murdockhou I looked into `smallModel`. When you set `training=True`, function returns a model that has weights of 6 layers (excluding input layer) that you are saving using `save_weights`. Then when you set `training=False`, function returns a model that has 3 layers (excluding input layer). When you try to load weights of 6 layers (saved earlier) into a model that has 3 layers, then the code throws an error. I hope it is clear.\r\n```\r\n## model.summary (with 6 layers)\r\n\r\nModel: \"model_1\"\r\n__________________________________________________________________________________________________\r\nLayer (type)                    Output Shape         Param #     Connected to                     \r\n==================================================================================================\r\nmodelInput (InputLayer)         [(None, 224, 224, 3) 0                                            \r\n__________________________________________________________________________________________________\r\nConv2_1 (Conv2D)                (None, 224, 224, 512 14336       modelInput[0][0]                 \r\n__________________________________________________________________________________________________\r\nConv2_2 (Conv2D)                (None, 224, 224, 512 2359808     Conv2_1[0][0]                    \r\n__________________________________________________________________________________________________\r\nconv2d_4 (Conv2D)               (None, 224, 224, 512 2359808     Conv2_2[0][0]                    \r\n__________________________________________________________________________________________________\r\nconv2d_5 (Conv2D)               (None, 224, 224, 512 2359808     conv2d_4[0][0]                   \r\n__________________________________________________________________________________________________\r\nquater (Conv2D)                 (None, 224, 224, 19) 9747        Conv2_2[0][0]                    \r\n__________________________________________________________________________________________________\r\nhalf (Conv2D)                   (None, 224, 224, 19) 9747        conv2d_5[0][0]                   \r\n==================================================================================================\r\nTotal params: 7,113,254\r\nTrainable params: 7,113,254\r\nNon-trainable params: 0\r\n\r\n## model.summary (with 3 layers)\r\n\r\nModel: \"model_2\"\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\nmodelInput (InputLayer)      [(None, 224, 224, 3)]     0         \r\n_________________________________________________________________\r\nConv2_1 (Conv2D)             (None, 224, 224, 512)     14336     \r\n_________________________________________________________________\r\nConv2_2 (Conv2D)             (None, 224, 224, 512)     2359808   \r\n_________________________________________________________________\r\nquater (Conv2D)              (None, 224, 224, 19)      9747      \r\n=================================================================\r\nTotal params: 2,383,891\r\nTrainable params: 2,383,891\r\nNon-trainable params: 0\r\n_________________________________________________________________\r\n```\r\n\r\nPlease close the issue it this was resolved. Please post this kind of support questions in Stackoverflow where we can resolve. GitHub is mainly for Bug/Performance issue only. Thanks!", "I understand what's your means. But the bigger model is also set\n`training=False` when load it and I can successfully load it with wrong\nweights of the last layer, but the smaller model can not load anymore. What\nI think is that they should be consistent but actually not.\n\nVishnuvardhan Janapati <notifications@github.com> \u4e8e2019\u5e7412\u67085\u65e5\u5468\u56db \u4e0a\u53487:11\u5199\u9053\uff1a\n\n> @murdockhou <https://github.com/murdockhou> I looked into smallModel.\n> When you set training=True, function returns a model that has weights of\n> 6 layers (excluding input layer) that you are saving using save_weights.\n> Then when you set training=False, function returns a model that has 3\n> layers (excluding input layer). When you try to load weights of 6 layers\n> (saved earlier) into a model that has 3 layers, then the code throws an\n> error. I hope it is clear.\n>\n> ## model.summary (with 6 layers)\n>\n> Model: \"model_1\"\n> __________________________________________________________________________________________________\n> Layer (type)                    Output Shape         Param #     Connected to\n> ==================================================================================================\n> modelInput (InputLayer)         [(None, 224, 224, 3) 0\n> __________________________________________________________________________________________________\n> Conv2_1 (Conv2D)                (None, 224, 224, 512 14336       modelInput[0][0]\n> __________________________________________________________________________________________________\n> Conv2_2 (Conv2D)                (None, 224, 224, 512 2359808     Conv2_1[0][0]\n> __________________________________________________________________________________________________\n> conv2d_4 (Conv2D)               (None, 224, 224, 512 2359808     Conv2_2[0][0]\n> __________________________________________________________________________________________________\n> conv2d_5 (Conv2D)               (None, 224, 224, 512 2359808     conv2d_4[0][0]\n> __________________________________________________________________________________________________\n> quater (Conv2D)                 (None, 224, 224, 19) 9747        Conv2_2[0][0]\n> __________________________________________________________________________________________________\n> half (Conv2D)                   (None, 224, 224, 19) 9747        conv2d_5[0][0]\n> ==================================================================================================\n> Total params: 7,113,254\n> Trainable params: 7,113,254\n> Non-trainable params: 0\n>\n> ## model.summary (with 3 layers)\n>\n> Model: \"model_2\"\n> _________________________________________________________________\n> Layer (type)                 Output Shape              Param #\n> =================================================================\n> modelInput (InputLayer)      [(None, 224, 224, 3)]     0\n> _________________________________________________________________\n> Conv2_1 (Conv2D)             (None, 224, 224, 512)     14336\n> _________________________________________________________________\n> Conv2_2 (Conv2D)             (None, 224, 224, 512)     2359808\n> _________________________________________________________________\n> quater (Conv2D)              (None, 224, 224, 19)      9747\n> =================================================================\n> Total params: 2,383,891\n> Trainable params: 2,383,891\n> Non-trainable params: 0\n> _________________________________________________________________\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/33957?email_source=notifications&email_token=AEMCC7OCXZ3TT2JSJYSQN4DQXA2JNA5CNFSM4JIPT5D2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEF62TFA#issuecomment-561883540>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AEMCC7NUP77MSTV2TLZCQKDQXA2JNANCNFSM4JIPT5DQ>\n> .\n>\n", "This is happening because `model.save/load_weights` creates a `tf.train.Checkpoint` which assumes  the models have the same structure. If you're changing the model structure between saving and loading, you should create a `tf.train.Checkpoint` object that is compatible with both models.\r\n\r\nFor example, if the layer names are consistent, then you could create a `tf.train.Checkpoint` that maps layer names to layers:\r\n```\r\ndef create_checkpoint(model):\r\n  return tf.train.Checkpoint(**{layer.name: layer for layer in model.layers})\r\n\r\nmodel = ...\r\nckpt = create_checkpoint(model)\r\nckpt_path = ckpt.save(\"/path/to/ckpt\")\r\n\r\n# loading\r\nmodel = ...\r\nckpt = create_checkpoint(model)\r\nckpt.restore(ckpt_path)\r\n```\r\n\r\nI'm closing this issue since there's nothing we can really do. When the model structure changes between saving/loading, any assumptions we make about the variables to load would be unsafe.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33957\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33957\">No</a>\n"]}, {"number": 33956, "title": "The same code, trained in the Ubuntu environment, Loss can converge, but under Windows training, Loss can not converge.", "body": "I ran a project on github, the project address is https://github.com/qxde01/keras-alchemy, I tried to train a mobilenetv2 image classifier directly by running the `train_cifar100_classify.py` file, but I encountered some problems at runtime. .\r\n\r\nMy Windows environment:\r\n```\r\nWindows 10\r\nTensorflow-gpu 2.0\r\nKeras 2.3.1\r\nCUDA 10.0\r\n```\r\nMy Ubuntu environment:\r\n```\r\nUbuntu 16.04\r\nTensorflow-gpu 1.12\r\nKeras 2.2.4\r\nCUDA 9.0\r\n```\r\n\r\nI changed all `if tf.__version__<'2.0':` results to true at runtime to use keras as a front end to reduce version incompatibility issues.\r\n\r\nThe final result, as the title says, is trained on Windows and Loss is completely unable to converge. What is the reason for this? Can someone help me analyze it? thank you very much!\r\n", "comments": []}, {"number": 33955, "title": "comp:micro - Set g_pdm_dma_error_reporter pointer to the error_reporter passed to InitAudioRecording()", "body": "Fix for micro_speech example on apollo3evb boards:\r\n\r\nThe pointer g_pdm_dma_error_reporter is used to report DMA errors on apollo3evb boards.\r\nHowever currently it is always set to a nullptr due to an initialization bug.\r\nThis causes crashes on DMA errors like fifo overflows.\r\n \r\nPlease add the following labels:\r\n**comp:lite**\r\n**comp:micro**", "comments": ["@suphoff Can you please resolve conflicts? Thanks!", "Updated", "@petewarden Can you please take a look on this PR? Thanks!", "@wangtz Can you please take a look on this PR? Thanks!", "@wangtz can you please help review this PR", "Sry for taking so long to come back to this PR. For some reason it didn't show up in my \"review request\" board. (Still learning how to use Github efficiently). What you replied sounds reasonable to me. Do you mind leaving some comments in the code to explain why you want to structure the code in this way as a reference for the future?\r\n\r\nThx."]}, {"number": 33954, "title": "Update import_pb_to_tensorboard.py script to be compatible with TF2.0 saved_model files #8854", "body": "This fixes an issued raised recently in the closed issue #8854, where the newer saved_model pb file format in TF2.0 can no longer be read using `graph_pb2.GraphDef().ParseFromString()`, and results in this error:\r\n\r\n> ```\r\n> google.protobuf.message.DecodeError:` Error parsing message\r\n> ```\r\n\r\nChanged to use `saved_model_utils.get_meta_graph_def()` instead.\r\n\r\nThe parameters have been updated to support the new-style saved_model directory structure, where you specify the saved model version directory, and (optionally) a tag-set list (defaults to `serve`). e.g.:\r\n\r\n```\r\npython -m tensorflow_core.python.tools.import_pb_to_tensorboard --model_dir new_model/1 --tag_set serve --log_dir logs/001\r\n```", "comments": ["this script cannot draw edges on tf2.0 saved models"]}, {"number": 33953, "title": "Fix TensorFlow on Python 3.8 logger issue", "body": "This fix tries to address the issue raised in #33799 where running tensorflow on python 3.8 (Ubuntu 18.04) raised the following error:\r\n```\r\nTypeError: _logger_find_caller() takes from 0 to 1 positional arguments but 2 were given\r\n```\r\n\r\nThe issue was that findCaller changed in Python 3.8\r\n\r\nThis PR fixes the issue.\r\n\r\nThis PR fixes #33799\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": []}, {"number": 33952, "title": "custom object detection data set tflite_convert", "body": "I have followed \"https://medium.com/tensorflow/training-and-serving-a-realtime-mobile-object-detector-in-30-minutes-with-cloud-tpus-b78971cf1193\" with \"ssd_mobilenet_v1_quantized_300x300_coco14_sync_2018_07_18.tar.gz\" model... Only thing I have changed bazel to tflite_convert . I have prepared 300x300x3 labeled images and trained. after trained i have generated frozen_graph. pb file to check on jupyter notebook and wola it runs ... After that I have used below code  to produce tflite_graph.pbtxt and tflite_graph.pb files . \r\n\r\n\"python export_tflite_ssd_graph.py --pipeline_config_path training/pipeline.config --trained_checkpoint_prefix training/model.ckpt-2927 --output_directory export_tflite_ssd_graph/tflite --add_postprocessing_op true\"\r\n\r\nFinally I have used below code to get detect.tflite file and bomm. Nothing happen when I have started https://github.com/tensorflow/examples/tree/master/lite/examples/object_detection/android that project on android studio.  The project perfectly runs own original detect.tflite file....\r\n\r\n\"D:\\First\\Projects\\visionApi\\START\\models\\research\\object_detection>tflite_convert  --output_file export_tflite_ssd_graph/tflite/detect.tflite --input_shapes 1,300,300,3 --input_arrays normalized_input_image_tensor --output_arrays \"TFLite_Detection_PostProcess\" \"TFLite_Detection_PostProcess:1\" \"TFLite_Detection_PostProcess:2\" \"FLite_Detection_PostProcess:3\" --mean_values 128 --std_dev_values 127 --allow_custom_ops --graph_def_file export_tflite_ssd_graph/tflite/tflite_graph.pb change_concat_input_ranges false --inference_type FLOAT \"\r\n\r\nAbove code generate a detect.tflite file but it did not run on above android project. \r\n\r\nHow could I do correctly ? please help.\r\n\r\nAfter that I tried to change code as below.... and get that error...\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): windows 10 \r\n- TensorFlow installed from (source or binary):  binary\r\n- TensorFlow version (or github SHA if from source): 1.13.1\r\n\r\n**Provide the text output from tflite_convert**\r\n\r\n```\r\nD:\\First\\Projects\\visionApi\\START\\models\\research\\object_detection>tflite_convert  --output_file export_tflite_ssd_graph/tflite/detect.tflite --input_shapes 1,300,300,3 --input_arrays normalized_input_image_tensor --output_arrays \"TFLite_Detection_PostProcess\" \"TFLite_Detection_PostProcess:1\" \"TFLite_Detection_PostProcess:2\" \"FLite_Detection_PostProcess:3\" --mean_values 128 --std_dev_values 127 --allow_custom_ops --graph_def_file export_tflite_ssd_graph/tflite/tflite_graph.pb change_concat_input_ranges false --inference_type QUANTIZED_UINT8\r\n\r\n2019-11-03 19:04:05.430457: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\n2019-11-03 19:04:06.351615: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties:\r\nname: GeForce GTX 1060 major: 6 minor: 1 memoryClockRate(GHz): 1.6705\r\npciBusID: 0000:01:00.0\r\ntotalMemory: 6.00GiB freeMemory: 4.97GiB\r\n2019-11-03 19:04:06.358836: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\r\n2019-11-03 19:04:06.856355: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-11-03 19:04:06.860494: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0\r\n2019-11-03 19:04:06.863385: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N\r\n2019-11-03 19:04:06.867189: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4716 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\nTraceback (most recent call last):\r\n  File \"c:\\python\\python37\\lib\\runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"c:\\python\\python37\\lib\\runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"C:\\Python\\Python37\\Scripts\\tflite_convert.exe\\__main__.py\", line 9, in <module>\r\n  File \"c:\\python\\python37\\lib\\site-packages\\tensorflow\\lite\\python\\tflite_convert.py\", line 442, in main\r\n    app.run(main=run_main, argv=sys.argv[:1])\r\n  File \"c:\\python\\python37\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"c:\\python\\python37\\lib\\site-packages\\tensorflow\\lite\\python\\tflite_convert.py\", line 438, in run_main\r\n    _convert_model(tflite_flags)\r\n  File \"c:\\python\\python37\\lib\\site-packages\\tensorflow\\lite\\python\\tflite_convert.py\", line 191, in _convert_model\r\n    output_data = converter.convert()\r\n  File \"c:\\python\\python37\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py\", line 461, in convert\r\n    **converter_kwargs)\r\n  File \"c:\\python\\python37\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py\", line 411, in toco_convert_graph_def\r\n    input_data.SerializeToString())\r\n  File \"c:\\python\\python37\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py\", line 205, in toco_convert_protos\r\n    \"TOCO failed. See console for info.\\n%s\\n%s\\n\" % (stdout, stderr))\r\ntensorflow.lite.python.convert.ConverterError: TOCO failed. See console for info.\r\n2019-11-03 19:04:08.261635: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: TFLite_Detection_PostProcess\r\n2019-11-03 19:04:08.262132: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: \"WrapDatasetVariant\" device_type: \"CPU\"') for unknown op: WrapDatasetVariant\r\n2019-11-03 19:04:08.262371: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: \"WrapDatasetVariant\" device_type: \"GPU\" host_memory_arg: \"input_handle\" host_memory_arg: \"output_handle\"') for unknown op: WrapDatasetVariant\r\n2019-11-03 19:04:08.262670: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: \"UnwrapDatasetVariant\" device_type: \"CPU\"') for unknown op: UnwrapDatasetVariant\r\n2019-11-03 19:04:08.262925: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: \"UnwrapDatasetVariant\" device_type: \"GPU\" host_memory_arg: \"input_handle\" host_memory_arg: \"output_handle\"') for unknown op: UnwrapDatasetVariant\r\n2019-11-03 19:04:08.289925: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 878 operators, 1279 arrays (0 quantized)\r\n2019-11-03 19:04:08.342088: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 878 operators, 1279 arrays (0 quantized)\r\n2019-11-03 19:04:08.405873: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 100 operators, 259 arrays (1 quantized)\r\n2019-11-03 19:04:08.408766: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before pre-quantization graph transformations: 100 operators, 259 arrays (1 quantized)\r\n2019-11-03 19:04:08.410769: F tensorflow/lite/toco/tooling_util.cc:1702] Array FeatureExtractor/MobilenetV2/Conv/Relu6, which is an input to the DepthwiseConv operator producing the output array FeatureExtractor/MobilenetV2/expanded_conv/depthwise/Relu6, is lacking min/max data, which is necessary for quantization. If accuracy matters, either target a non-quantized output format, or run quantized training with your model from a floating point checkpoint to change the input graph to contain min/max information. If you don't care about accuracy, you can pass --default_ranges_min= and --default_ranges_max= for easy experimentation.\r\n```\r\n\r\n\r\n\r\n\r\n", "comments": ["Thank you so much... I have already solved that issue you can close it. \r\n\r\nBest Regards.", "Hi did you solved the above issue , i did the same , got the detect.tflite , but when i am using in android , the detection is not showing result which i was getting in python . please help me"]}, {"number": 33951, "title": "tf.volume.resize ", "body": "\r\n**System information**\r\n- TensorFlow version (you are using): 1.14\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\ntf.image.resize works for 2D images, would be nice with tf.volume.resize for 3D volumes, instead of using tf.keras.layers.UpSampling3D that only performs nearest neighbor interpolation.\r\n\r\n**Will this change the current api? How?**\r\n\r\nI don't think so\r\n\r\n**Who will benefit with this feature?**\r\n\r\nMany working with 3D data\r\n\r\n**Any Other info.**\r\n", "comments": ["Is there any update on this?\r\nJust as [(TF2.2.0) tf.image.resize](https://www.tensorflow.org/api_docs/python/tf/image/resize) offers an option for bilinear interpolation, it would be great to have a tf.volume.resize that offers trilinear interpolation.\r\n\r\nThe closest thing right now is [(TF2.2.0) tf.keras.backend.resize_volumes](https://www.tensorflow.org/api_docs/python/tf/keras/backend/resize_volumes) but that repeats elements when you look into its [source code](https://github.com/tensorflow/tensorflow/blob/v2.2.0/tensorflow/python/keras/backend.py#L2835-L2864).", "+1 Please add this functionality similar to torch.nn.functional.interpolate", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Any update on this feature request? I would love to see it implemented as well.", "Same question. Will you update this feature? ", "any updates? ", "It is submitted again in https://github.com/keras-team/keras/issues/16260\r\n\r\nYou could subscribe and comment there."]}, {"number": 33950, "title": "OP_REQUIRES failed at save_restore_v2_ops.cc:184 : Not found: Key aux_logits/Conv/biases/ExponentialMovingAverage not found in checkpoint", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n\r\n- TensorFlow installed from (source or binary): conda install\r\n- TensorFlow version (use command below): v1.14\r\n- Python version: anaconda 3.7\r\n- Bazel version (if compiling from source): 1.01\r\n\r\nFull enviorment details : `\r\n[tf_env.txt](https://github.com/tensorflow/tensorflow/files/3801902/tf_env.txt)\r\n\r\n\r\n**Describe the current behavior**\r\nI am attempting to evaluate my custom trained inception V3 model, but the variables to restore being generated by this call \r\n` variable_averages = tf.train.ExponentialMovingAverage(\r\n        inception.MOVING_AVERAGE_DECAY)\r\n    variables_to_restore = variable_averages.variables_to_restore()` \r\n\r\nare not found in my checkpoint file. \r\n\r\nI get this error:\r\n\r\n````\r\nException has occurred: NotFoundError\r\nRestoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\r\n\r\nKey aux_logits/Conv/biases/ExponentialMovingAverage not found in checkpoint\r\n\t [[node save/RestoreV2 (defined at /02_testing/xClasses/inception/nc_inception_eval.py:418) ]]\r\n\r\nOriginal stack trace for 'save/RestoreV2':\r\n  File \"/.vscode-server/extensions/ms-python.python-2019.10.44104/pythonFiles/ptvsd_launcher.py\", line 43, in <module>\r\n    main(ptvsdArgs)\r\n  File \"/.vscode-server/extensions/ms-python.python-2019.10.44104/pythonFiles/lib/python/old_ptvsd/ptvsd/__main__.py\", line 432, in main\r\n    run()\r\n  File \"/.vscode-server/extensions/ms-python.python-2019.10.44104/pythonFiles/lib/python/old_ptvsd/ptvsd/__main__.py\", line 316, in run_file\r\n    runpy.run_path(target, run_name='__main__')\r\n  File \"/anaconda3/envs/tensorflow_p36/lib/python3.6/runpy.py\", line 263, in run_path\r\n    pkg_name=pkg_name, script_name=fname)\r\n  File \"/anaconda3/envs/tensorflow_p36/lib/python3.6/runpy.py\", line 96, in _run_module_code\r\n    mod_name, mod_spec, pkg_name, script_name)\r\n  File \"/anaconda3/envs/tensorflow_p36/lib/python3.6/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/02_testing/xClasses/nc_imagenet_eval.py\", line 271, in <module>\r\n    tf.app.run()\r\n  File \"/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/absl/app.py\", line 300, in run\r\n    _run_main(main, args)\r\n  File \"/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/absl/app.py\", line 251, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"/02_testing/xClasses/nc_imagenet_eval.py\", line 65, in main\r\n    precision_at_1, current_score = nc_inception_eval.evaluate(dataset)\r\n  File \"/02_testing/xClasses/inception/nc_inception_eval.py\", line 418, in evaluate\r\n    saver = tf.train.Saver(variables_to_restore)\r\n  File \"/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 831, in __init__\r\n    self.build()\r\n  File \"/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 843, in build\r\n    self._build(self._filename, build_save=True, build_restore=True)\r\n  File \"/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 881, in _build\r\n    build_restore=build_restore)\r\n  File \"/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 514, in _build_internal\r\n    restore_sequentially, reshape)\r\n  File \"/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 334, in _AddRestoreOps\r\n    restore_sequentially)\r\n  File \"/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 581, in bulk_restore\r\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\r\n  File \"/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1696, in restore_v2\r\n    name=name)\r\n  File \"/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3616, in create_op\r\n    op_def=op_def)\r\n  File \"/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2005, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n  File \"/home/ubuntu/02_testing/xClasses/inception/nc_inception_eval.py\", line 83, in _eval_once\r\n    saver.restore(sess, ckpt.model_checkpoint_path)\r\n  File \"/home/ubuntu/02_testing/xClasses/inception/nc_inception_eval.py\", line 427, in evaluate\r\n    precision_at_1, current_score = _eval_once(saver, summary_writer, top_1_op, top_5_op, summary_op, max_percent, all_filenames, filename_queue, net2048, sel_end_points, logits, labels)\r\n  File \"/home/ubuntu/02_testing/xClasses/nc_imagenet_eval.py\", line 65, in main\r\n    precision_at_1, current_score = nc_inception_eval.evaluate(dataset)\r\n  File \"/home/ubuntu/02_testing/xClasses/nc_imagenet_eval.py\", line 271, in <module>\r\n    tf.app.run()\r\n````\r\n\r\n**Describe the expected behavior**\r\nI have done this several times before so I am not sure why I am all the sudden getting this error. I even tried evaluating my old model with these scripts and it still gives me the same error. \r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n```\r\n`inception_eval.evaluate(dataset)`\r\n\r\n\r\n`def evaluate(dataset):\r\n  \"\"\"Evaluate model on Dataset for a number of steps.\"\"\"\r\n  with tf.Graph().as_default():\r\n    # Get images and labels from the dataset.\r\n    images, labels, all_filenames, filename_queue = image_processing.inputs(dataset)\r\n\r\n    # Number of classes in the Dataset label set plus 1.\r\n    # Label 0 is reserved for an (unused) background class\r\n    num_classes = dataset.num_classes() + 1\r\n    print(\"there are %d classes!\" % dataset.num_classes())\r\n\r\n    # Build a Graph that computes the logits predictions from the\r\n    # inference model.\r\n    logits, _, end_points, net2048, sel_end_points = inception.inference(images, num_classes)\r\n\r\n    # Calculate predictions.\r\n    #max_percent =  tf.argmax(logits,1)\r\n    #max_percent = tf.reduce_max(logits, reduction_indices=[1]) / tf.add_n(logits)\r\n    max_percent = end_points['predictions']\r\n    # max_percent = len(end_points)\r\n    #for kk in range(len(labels)):\r\n    #   #max_percent.append(end_points['predictions'][kk][labels[kk]])\r\n    #   max_percent.append(labels[kk])\r\n    if FLAGS.mode == '0_softmax':\r\n      top_1_op = tf.nn.in_top_k(logits, labels, 1)\r\n      top_5_op = tf.nn.in_top_k(logits, labels, 5)\r\n    elif FLAGS.mode == '1_sigmoid':\r\n      top_1_op = None\r\n      top_5_op = None\r\n    # Restore the moving average version of the learned variables for eval.\r\n\r\n    variable_averages = tf.train.ExponentialMovingAverage(\r\n        inception.MOVING_AVERAGE_DECAY)\r\n    variables_to_restore = variable_averages.variables_to_restore()\r\n    with open('./vars2res.txt', 'w') as vas:\r\n      for k, v in variables_to_restore.items():\r\n        vas.write(k)\r\n        vas.write('\\n')\r\n    saver = tf.train.Saver(variables_to_restore)\r\n\r\n    # Build the summary operation based on the TF collection of Summaries.\r\n    summary_op = tf.summary.merge_all()\r\n\r\n    graph_def = tf.get_default_graph().as_graph_def()\r\n    summary_writer = tf.summary.FileWriter(FLAGS.eval_dir, graph_def=graph_def)\r\n\r\n    while True:\r\n      precision_at_1, current_score = _eval_once(saver, summary_writer, top_1_op, top_5_op, summary_op, max_percent, all_filenames, filename_queue, net2048, sel_end_points, logits, labels)`\r\n\r\n`def _eval_once(saver, summary_writer, top_1_op, top_5_op, summary_op, max_percent_op, all_filenames, filename_queue, net2048_op, endpoints_op, logits_op, labels_op):\r\n  \"\"\"Runs Eval once.\r\n\r\n  Args:\r\n    saver: Saver.\r\n    summary_writer: Summary writer.\r\n    top_1_op: Top 1 op.\r\n    top_5_op: Top 5 op.\r\n    summary_op: Summary op.\r\n  \"\"\"\r\n  #tf.initialize_all_variables()\r\n  # modify for new tensorflow releases\r\n  tf.global_variables_initializer()\r\n  with tf.Session() as sess:\r\n    ckpt = tf.train.get_checkpoint_state(FLAGS.checkpoint_dir)\r\n    if ckpt and ckpt.model_checkpoint_path:\r\n      if os.path.isabs(ckpt.model_checkpoint_path):\r\n        # Restores from checkpoint with absolute path.\r\n        saver.restore(sess, ckpt.model_checkpoint_path)`\r\n```\r\n\r\n\r\n**Other info / logs**\r\nTensors in my model\r\n[tensors2.txt](https://github.com/tensorflow/tensorflow/files/3801898/tensors2.txt)\r\n\r\nVariables attempting to restore\r\n[var2res.txt](https://github.com/tensorflow/tensorflow/files/3801904/var2res.txt)\r\n", "comments": ["@mattreex, Please provide us the simple standalone code to reproduce the reported issue. Thanks!", "@mattreex, Provide the sample code snippet to replicate the issue. Thanks!", "Have you solved this issue? It happened to me when I use AI platform's distributed training service. \r\n\r\nMy error is very similar with what @gadagashwini reported.  It complains about `bundle_tower/dense/bias/rt_0/ExponentialMovingAverage` is not found in the checkpoint.\r\n\r\nWhen I print out variables from checkpoint, you can see `part_0` is partially stripped to `rt_0`. \r\n```\r\n(0): bundle_tower/dense/bias: [1285]\r\n(1): bundle_tower/dense/bias/dense/bias/part_0/Adam: [1285]\r\n(2): bundle_tower/dense/bias/dense/bias/part_0/Adam_1: [1285]\r\n(3): bundle_tower/dense/bias/rt_0/ExponentialMovingAverage: [1285]\r\n```\r\nThis happens for all partitioned `ExponentialMovingAverage` variables.\r\n"]}, {"number": 33949, "title": "Tensorflow Android Library doesn't define targetSdkVersion", "body": "Hey,\r\nI'm using your android tensorflow library for an android library I'm working on.\r\n\r\nWhen adding your sdk I automatically see 2 additional permissions - Phone and Storage.\r\nI checked and turns our the permissions are added because your SDK doesn't define a targetSdkVersion, so by default the targetSdkVersion of your sdk is considered 1, and according to [android docs](https://developer.android.com/studio/build/manifest-merge.html#implicit_system_permissions) the permissions are added automatically in such case.\r\n\r\nPlease let me know if you can solve my issue (maybe by adding targetSdkVersion to your project?)\r\n\r\n**System information**\r\nThe android dependency I'm using is: implementation 'org.tensorflow:tensorflow-android:1.13.1'\r\n\r\nThanks!", "comments": ["@ori-6over6,\r\nPlease follow the instructions mentioned in this [link](https://www.tensorflow.org/lite/guide/android) for Tensorflow android. Thanks!", "@gadagashwini I'll check it out. Thanks!", "@ori-6over6, Were you able to resolve this issue. Thanks!", "@gadagashwini yeah the permissions issue is solved when using the library you recommended, thanks!\r\nWe are currently working on integrating this library to work with our model", "@gadagashwini Hey, we are trying to convert our pb model to a tflite model.\r\nOur model is frozen. Is it possible to convert it?", "@ori-6over6, Here is the [link](https://www.tensorflow.org/lite/convert/python_api) for Tensorflow lite converter.\r\nThanks! ", "@gadagashwini Thanks for the quick response!\r\nWe looked over the documentation (actually preferred the command line tool over the python api but who cares (; ). At first we couldn't convert the model because apparently [Tensorflow 2 converter doesn't support frozen models graphs](https://www.tensorflow.org/lite/convert/python_api#formats_supported_by_tfliteconverter), so we had to use Tensorflow 1 for the conversion.\r\nRight now we have a tflite version of our model and we are in the process of making it work.\r\nWill let you know once we are successful. Thanks again!", "@ori-6over6, Is this still an issue. ", "Hey @gadagashwini, we were using [MTCNN4Android](https://github.com/vcvycy/MTCNN4Android) for detecting eyes using Tensorflow so we are now trying to use an [equivalent version for TFLite](https://github.com/syaringan357/Android-MobileFaceNet-MTCNN-FaceDeSpoofing), but their model detection is less accurate.\r\nAnyway the TFLite integration seems to be working and the extra permissions are no longer needed, so I guess this issue can be considered solved. Thanks for the help!", "@ori-6over6, Closing the issue since its resolved. Thanks!"]}, {"number": 33948, "title": "ValueError: Shapes (8334, 256) and (8335, 256) are incompatible", "body": "# **System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): \r\nTwo OS used:\r\n  - Windows 10\r\n  - Google Compute Engine (GPU) OS (whatever that might be?)\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.0.0 (on both OS)\r\n- Python version: \r\n  - Windows 10 (running Python 3.6.6)\r\n  - Google Compute Engine OS (running Python 3.6)\r\n\r\n# **Describe the current behavior**\r\nA model is compiled and trained using `script A` on the Google Compute Engine. The weights are saved separately rather than altogether due to #33947 , using the `model.save_weights()`.\r\n\r\nThe weights are then saved as a zip, and transferred to a Windows-based machine.\r\n\r\nOn the Windows-based machine, the same code is run to compile the model but instead of training the model again - the weights are loaded using `model.load_weights()`.\r\n\r\nThis results in a \r\n```\r\nValueError: Shapes (8334, 256) and (8335, 256) are incompatible\r\n```\r\n\r\n# **Describe the expected behavior**\r\nA model is compiled and trained using `script A` on the Google Compute Engine. The weights are saved separately rather than altogether due to #33947 , using the `model.save_weights()`.\r\n\r\nThe weights are then saved as a zip, and transferred to a Windows-based machine.\r\n\r\nOn the Windows-based machine, the same code is run to compile the model but instead of training the model again - the weights are loaded using `model.load_weights()`.\r\n\r\nThe weights are loaded successfully.\r\n\r\n# **Possible Cause**\r\n**Model Summary on the two machines are different... which is likely causing the issue.**\r\n- Google Compute Engine (GPU):\r\n```\r\nModel: \"transformer\"\r\n__________________________________________________________________________________________________\r\nLayer (type)                    Output Shape         Param #     Connected to                     \r\n==================================================================================================\r\ninputs (InputLayer)             [(None, None)]       0                                            \r\n__________________________________________________________________________________________________\r\ndec_inputs (InputLayer)         [(None, None)]       0                                            \r\n__________________________________________________________________________________________________\r\nenc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \r\n__________________________________________________________________________________________________\r\nencoder (Model)                 (None, None, 256)    3187968     inputs[0][0]                     \r\n                                                                 enc_padding_mask[0][0]           \r\n__________________________________________________________________________________________________\r\nlook_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \r\n__________________________________________________________________________________________________\r\ndec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \r\n__________________________________________________________________________________________________\r\ndecoder (Model)                 (None, None, 256)    3715328     dec_inputs[0][0]                 \r\n                                                                 encoder[1][0]                    \r\n                                                                 look_ahead_mask[0][0]            \r\n                                                                 dec_padding_mask[0][0]           \r\n__________________________________________________________________________________________________\r\noutputs (Dense)                 (None, None, 8335)   2142095     decoder[1][0]                    \r\n==================================================================================================\r\nTotal params: 9,045,391\r\nTrainable params: 9,045,391\r\nNon-trainable params: 0\r\n__________________________________________________________________________________________________\r\n```\r\n- Windows-based Machine:\r\n```\r\nModel: \"transformer\"\r\n__________________________________________________________________________________________________\r\nLayer (type)                    Output Shape         Param #     Connected to\r\n==================================================================================================\r\ninputs (InputLayer)             [(None, None)]       0\r\n__________________________________________________________________________________________________\r\ndec_inputs (InputLayer)         [(None, None)]       0\r\n__________________________________________________________________________________________________\r\nenc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]\r\n__________________________________________________________________________________________________\r\nencoder (Model)                 (None, None, 256)    3187712     inputs[0][0]\r\n                                                                 enc_padding_mask[0][0]\r\n__________________________________________________________________________________________________\r\nlook_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]\r\n__________________________________________________________________________________________________\r\ndec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]\r\n__________________________________________________________________________________________________\r\ndecoder (Model)                 (None, None, 256)    3715072     dec_inputs[0][0]\r\n                                                                 encoder[1][0]\r\n                                                                 look_ahead_mask[0][0]\r\n                                                                 dec_padding_mask[0][0]\r\n__________________________________________________________________________________________________\r\noutputs (Dense)                 (None, None, 8334)   2141838     decoder[1][0]\r\n==================================================================================================\r\nTotal params: 9,044,622\r\nTrainable params: 9,044,622\r\nNon-trainable params: 0\r\n__________________________________________________________________________________________________\r\n```\r\n\r\n# **Other info / logs**\r\n[log.txt](https://github.com/tensorflow/tensorflow/files/3801603/log.txt)\r\n\r\n\r\n", "comments": ["In order to expedite the trouble-shooting process, please provide a minimal standalone code to reproduce the issue reported here. Thanks!", "The minimal standalone code is literally my whole project. I'm sure TensorFlow developers can replicate this issue using Google Colab & a personal device using Attention() layers and saving model weights. @ravikyram \r\n", "@TheBlackPlague I think it is difficult to find the source without a standalone code. Other than the size mismatch, number of weights of different layers is different between GCP model and the local model. Can you please take any simple model (if your model is private) from TF website and create a standalone code? Can you please mention what steps(defined model architecture, compiled, trained the model, saved_weights,.......)  you followed with little more details. Thanks! ", "Of course. This is very similar to what I was doing and I think this may be a good replication. \r\n\r\nhttps://github.com/tensorflow/examples/blob/master/community/en/transformer_chatbot.ipynb\r\n\r\nHope this helps and you can reproduce.\r\n@jvishnuvardhan ", "Any update on this? @jvishnuvardhan ", "@TheBlackPlague Sorry for the very late response. Can you please provide a simple standalone code to reproduce the issue?  Recently there were couple of important updates in model saving and loading related codes. Can you please try `model.save` approach that saves everything. Thanks!", "Yeah this issue was fixed with the latest updates.", "@TheBlackPlague Thanks for the confirmation. I will close the issue. Thanks!", "@jvishnuvardhan  I have such a similar problem, and it happened on the latest version. I hope you can give me some suggestions.\r\nmy code as below:\r\n\r\n```\r\n%tensorflow_version 2.x\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport h5py\r\nimport t3f\r\nimport matplotlib.pyplot as plt\r\nfilename = \"./video.h5\"\r\nnp.random.seed(0)\r\nwith h5py.File(filename, \"r\") as f:\r\n    print(\"Keys: %s\" % f.keys())\r\n    a_group_key = list(f.keys())[0]\r\n    data = list(f[a_group_key])\r\n    data_np = np.array(data)\r\ndata_tensor = tf.convert_to_tensor(data_np)\r\nshape = [107]+[60]+[80]+[3]\r\n# A is large tt-ranks tensor\r\nA = t3f.to_tt_tensor(data_tensor)\r\n# Create an X variable.\r\ninit_X = t3f.random_tensor(shape, tt_rank=3)\r\nX = t3f.get_variable('X', initializer=init_X)\r\ndef step():\r\n    gradF = X - A\r\n    riemannian_grad = t3f.riemannian.project(gradF, X)\r\n    alpha = 1.0\r\n    t3f.assign(X, t3f.round(X - alpha * riemannian_grad, max_tt_rank=2))\r\n    return 0.5 * t3f.frobenius_norm_squared(X - A)\r\nlog = []\r\nfor i in range(1000):\r\n    F = step()\r\n    if i % 10 == 0:\r\n        print(F)\r\n    log.append(F.numpy())\r\n```\r\nExit:\r\n> ---------------------------------------------------------------------------\r\n> ValueError                                Traceback (most recent call last)\r\n> <ipython-input-34-e5f2500494ee> in <module>()\r\n>       1 log = []\r\n>       2 for i in range(1000):\r\n> ----> 3     F = step()\r\n>       4     if i % 10 == 0:\r\n>       5         print(F)\r\n> \r\n> 4 frames\r\n> /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_shape.py in assert_is_compatible_with(self, other)\r\n>    1115     \"\"\"\r\n>    1116     if not self.is_compatible_with(other):\r\n> -> 1117       raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\r\n>    1118 \r\n>    1119   def most_specific_compatible_shape(self, other):\r\n> \r\n> ValueError: Shapes (1, 107, 3) and (1, 107, 2) are incompatible\r\n> \r\n\r\nBut the data_tensor's shape is [107]+[60]+[80]+[3], it's same with A or X, I'm confused.\r\n\r\nI runned this code on google colab with tf2 and python3.6.\r\n\r\nIn this link you would recurrence my question [https://colab.research.google.com/drive/1Qz-TBBAbnflKioPn-YxxFwl59K3DVlWb?usp=sharing](url)", "@jianmosier Please create a new issue with the content you mentioned above. It will be easy for the community to follow. Please ping me there. Thanks!", "raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\r\nValueError: Shapes (2, 56, 56, 1024) and () are incompatible\r\n\r\nCan anyone help me?"]}, {"number": 33947, "title": "NotImplementedError: Layers with arguments in `__init__` must override `get_config`", "body": "Related to #32662\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): \r\n`Google Compute Engine (GPU)` running `Intel(R) Xeon(R) CPU @ 2.30GHz` \r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.0.0\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n**Describe the current behavior**\r\nModel is unable to be saved using `model.save()`\r\n\r\n**Describe the expected behavior**\r\nModel is saved successfully.\r\n\r\n**Code to reproduce the issue**\r\nCode to reproduce this issue can be found on the related Stackoverflow page: https://stackoverflow.com/q/58678836/12315223\r\n\r\nAnother good reproduction of this since I'm using `Attention()` layers is found here:\r\nhttps://github.com/tensorflow/tensorflow/issues/33380#issuecomment-542931948\r\n\r\n**Other info / logs**\r\n[log.txt](https://github.com/tensorflow/tensorflow/files/3801439/log.txt)\r\n", "comments": ["This issue has been resolved thanks to a \"hacky solution\".\r\n\r\nSolution:\r\nhttps://stackoverflow.com/a/58680354/12315223\r\n\r\nI'll leave this issue open in-case a better solution is provided on Stackoverflow or here. Feel free to close it here if no solution better than mine is available. ", "Closing this issue since its resolved. Feel free to reopen if necessary. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33947\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33947\">No</a>\n"]}, {"number": 33946, "title": "model summary, input_layer, output_layer not working properly in sub-classing method of tf.keras", "body": "**EDIT:** _After further research I found that in subclassing many of the models methods and attributes are not working examples are input_names, output_names etc.._\r\n\r\nI am using TF2 I am trying to build a model via sub-classing method. In sequantial model; methods and attributes such as summary, input_layer, output_layer works\r\n\r\n```\r\nimport tensorflow as tf\r\nimport tensorflow.keras as keras\r\n\r\nmodel = keras.Sequential([\r\n    keras.layers.Dense(4,input_shape=(None,3)),\r\n    keras.layers.Dense(3, activation='relu'),\r\n    keras.layers.Dense(2, activation='softmax')\r\n])\r\nmodel.compile(optimizer='adam',\r\n              loss='sparse_categorical_crossentropy',\r\n              metrics=['accuracy'])\r\n\r\nprint(model.summary())\r\nprint(model.input_shape)\r\nprint(model.output_shape)\r\n```\r\n\r\nBut in sub classing those methods and attributes are not working properly.\r\n\r\n```\r\nclass MLP(tf.keras.Model):\r\n    def __init__(self):\r\n        super().__init__()\r\n        self.fc1 = tf.keras.layers.Dense(4,input_shape=(None,3))\r\n        self.fc2 = tf.keras.layers.Dense(3,activation = 'relu')\r\n        self.fc3 = tf.keras.layers.Dense(2,activation ='softmax')\r\n    def call(self,x):\r\n        x = self.fc1(x)\r\n        x = self.fc2(x)\r\n        x = self.fc3(x)\r\n        return x\r\n\r\n\r\nmodel = MLP()\r\nmodel.build((1,3))\r\nprint(model.summary())\r\n\r\nprint(model.input_shape)\r\nprint(model.output_shape)\r\n```\r\n\r\nThe summary output in sub class model doesn't show the output shapes\r\n```\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\ndense_11 (Dense)             multiple                  16        \r\n_________________________________________________________________\r\ndense_12 (Dense)             multiple                  15        \r\n_________________________________________________________________\r\ndense_13 (Dense)             multiple                  8         \r\n=================================================================\r\nTotal params: 39\r\nTrainable params: 39\r\nNon-trainable params: 0\r\n```\r\nand model.input_shape and model.output_shape returns this error,\r\n>raise AttributeError('The layer has never been called '\r\nAttributeError: The layer has never been called and thus has no defined output shape.", "comments": ["Issue replicating for given code TF-2.0, please find the [gist](https://colab.sandbox.google.com/gist/oanush/10d4f67e126e105e8972f47b023f98f1/33946.ipynb) of colab.Thanks!", "@fightthepower There are some differences between subclass model and other models (Sequential and Functional). \r\n\r\nFunctional and Sequential models are static graphs of layers, so you can infer the shapes while building the model. Whereas Subclass model is a piece of Python code (a call method), there is no static graph of layers. So it is difficult to know how layers are connected to each other  (because that's defined in the body of call, not as an explicit data structure), so we cannot infer input / output shapes. Only when we train or test with real data, then only we know the shape. I think there are some workaround suggested by some of the users [here](https://github.com/tensorflow/tensorflow/issues/29132).\r\n\r\nI think this is resolved. I am closing this issue. Feel free to open a new issue if you encounter any other issue. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33946\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33946\">No</a>\n"]}, {"number": 33945, "title": "Add gelu", "body": "Closes #32783. Migrate gelu activation from addons https://github.com/tensorflow/addons/issues/550.\r\n\r\nSome benchmark between C++ and python implementation.\r\n\r\nWithout XLA: 10 times faster than composite python operations \r\nhttps://colab.research.google.com/drive/1P14w9KjnBLjnyEIs2k7Oy3w0QAa5BxKM\r\n\r\nWith XLA: 2 times faster than python operations when enabling XLA\r\nhttps://colab.research.google.com/drive/1pQFOp5sEp3Gw0LGHlZ6dPsNGfZPWXcgc\r\n\r\nNote that addons implementation does not have XLA ops. Would like to deal with XLA and mixed precision part if this gets merges.", "comments": ["cc @fchollet ", "+1 for merging the PR.", "Please migrate the Gelu layer too.\r\n", "Sorry for the cross Org reference but handling tickets It Is going to be hard between Keras repos:\r\nhttps://github.com/keras-team/keras/issues/11834", "@WindQAQ  Can you please resolve conflicts? Thanks!", "@gbaned Done!", "@fchollet Can you please take a look on this PR? Thanks!", "@fchollet @gbaned @WindQAQ Since this migration started we have created a new procedure for moving from TF-Addons to core:\r\nhttps://github.com/tensorflow/addons/blob/master/MIGRATION_TO_CORE.md\r\n\r\nWould it be benneficial for us to create an RFC on keras-governance in order to process this migration?", "@fchollet @seanpmorgan Any progress on merging this PR? This PR is beneficial to improving performance on BERT", "> This also needs a tfxla kernel for Gelu or we cannot support gelu with XLA on TPU/GPU.\r\n\r\nHi @alextp . So this PR and migration from TFA has gotten a bit stale. Wanted to give a quick update on where we are with this in Addons and see if you have some advice. As a side note we were requested to submit a PR to keras/governance as well, but haven't gotten around to it.\r\n\r\nWe've ran into issues supporting XLA / TPUs in our repo (no way to load custom XLA kernels): \r\nhttps://github.com/tensorflow/custom-op/issues/53#issuecomment-617100900\r\n\r\nIn order to support TPUs (as well as ABI incompatible installs of TF) we've implemented a python composite op for gelu:\r\nhttps://github.com/tensorflow/addons/blob/master/tensorflow_addons/activations/gelu.py#L67\r\n\r\nWe benchmarked the CPU/GPU custom-op implementations vs. XLA compiled python version:\r\nhttps://colab.research.google.com/drive/1rLb4EuydbFg9PbhboXhCDqopcl6BmphG\r\n\r\nThere are some noticeable speed ups on (especially CUDA kernel and backward passes), but it's becoming quite a maintenance burden for us to support custom-ops for simple activations. Would TF core be willing to merge in a python composite op version or would it be preferable to migrate the custom-op with a tfxla kernel? \r\n\r\nIs there any documentation on writing tfxla kernels? I suppose it could [mostly be inferred from say relu](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/tf2xla/kernels/relu_op.cc), but it's quite difficult for us to test any implementation. ", "We would merge a python composite op version.\n\nWe're in the process of revamping tfxla to make writing kernels unnecessary\n(you'll write MLIR legalization passes instead, with more syntactic sugar)\nso I'd rather wait a bit and expose that API to addons.\n\nOn Tue, Apr 21, 2020 at 6:52 PM Sean Morgan <notifications@github.com>\nwrote:\n\n> This also needs a tfxla kernel for Gelu or we cannot support gelu with XLA\n> on TPU/GPU.\n>\n> Hi @alextp <https://github.com/alextp> . So this PR and migration from\n> TFA has gotten a bit stale. Wanted to give a quick update on where we are\n> with this in Addons and see if you have some advice. As a side note we were\n> requested to submit a PR to keras/governance as well, but haven't gotten\n> around to it.\n>\n> We've ran into issues supporting XLA / TPUs in our repo (no way to load\n> custom XLA kernels):\n> tensorflow/custom-op#53 (comment)\n> <https://github.com/tensorflow/custom-op/issues/53#issuecomment-617100900>\n>\n> In order to support TPUs (as well as ABI incompatible installs of TF)\n> we've implemented a python composite op for gelu:\n>\n> https://github.com/tensorflow/addons/blob/master/tensorflow_addons/activations/gelu.py#L67\n>\n> We benchmarked the CPU/GPU custom-op implementations vs. XLA compiled\n> python version:\n> https://colab.research.google.com/drive/1rLb4EuydbFg9PbhboXhCDqopcl6BmphG\n>\n> There are some noticeable speed ups on (especially CUDA kernel and\n> backward passes), but it's becoming quite a maintenance burden for us to\n> support custom-ops for simple activations. Would TF core be willing to\n> merge in a python composite op version or would it be preferable to migrate\n> the custom-op with a tfxla kernel?\n>\n> Is there any documentation on writing tfxla kernels? I suppose it could mostly\n> be inferred from say relu\n> <https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/tf2xla/kernels/relu_op.cc>,\n> but it's quite difficult for us to test any implementation.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/33945#issuecomment-617499180>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAABHRIO25FYWK7HC45WIMDRNZEWJANCNFSM4JIKFKMA>\n> .\n>\n\n\n-- \n - Alex\n", "@cheshire and @sanjoy  might be interested in the performance of XLA vs the custom op here\r\n\r\n@joker-eph are there docs for how to make the moral equivalent of tfxla kernels in the new bridge yet?", "> @joker-eph are there docs for how to make the moral equivalent of tfxla kernels in the new bridge yet?\r\n\r\nThere are no docs, but it should be fairly easy to lookup at example like:\r\n- SigmoidGradOp through a [declarative pattern](https://github.com/tensorflow/tensorflow/commit/76079c00ac45b2bd48b3749a490e464149f4b244)\r\n- RandomShuffleOp through a [C++ rewrite pattern](https://github.com/tensorflow/tensorflow/commit/0bc5e0beabefb97842cc71487f6adb0a76859b0b)\r\n\r\nNote that pattern are applied transitively: you can convert a TensorFlow Operation to others TensorFlow operations (or to a mix of TensorFlow and HLO operations) as long as these TensorFlow operations can then be expanded to HLO with other patterns. ", "I think that with this PR we are not compliant with the approved [Migration to Core](https://github.com/tensorflow/addons/blob/master/MIGRATION_TO_CORE.md) guidelines at point n. 3.\r\nThen it is normal to have comment like this one https://github.com/tensorflow/tensorflow/pull/37937#issuecomment-604694529 when the TF team propose to route a new op, that was originally proposed in TF, to Addons.\r\nAlso it is quite hard to fairly estimate the first migration criteria from the TensorFlow team point of view:\r\n> The addition is widely used throughout the community\r\n\r\nCause https://github.com/tensorflow/addons/issues/236 it is stalled.\r\n\r\n", "@alextp Hi Alexandre, is it ok now for me to close this one and open a new PR for python ops? Thank you!", "I am also willing to contribute C++ ops along with XLA kernel if there are some complaints about performance/speed, but for now, maybe python ops is the final decision on both end of addons and core. Please correct me if I misread anything. Thanks again for everyone's suggestion.", "A PR with python ops SGTM!\n\nOn Wed, Apr 29, 2020 at 12:38 PM Tzu-Wei Sung <notifications@github.com>\nwrote:\n\n> I am also willing to contribute C++ ops along with XLA kernel if there are\n> some complaints about performance/speed, but for now, maybe python ops is\n> the final decision on both end of addons and core. Please correct me if I\n> misread anything. Thanks again for everyone's suggestion.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/33945#issuecomment-621415285>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAABHROIMWAJHBW2SVN4NYLRPB64VANCNFSM4JIKFKMA>\n> .\n>\n\n\n-- \n - Alex\n", "Sure, would do it real quick :-)\r\n\r\n@seanpmorgan is there any change we should do in addons? Thanks.", "> Sure, would do it real quick :-)\r\n> \r\n> @seanpmorgan is there any change we should do in addons? Thanks.\r\n\r\nWe'll need to alias core gelu at some point and think about issues for removing the activation custom-op support going forward. I've marked the topic on our agenda for this Friday. Thanks @WindQAQ !\r\n\r\nWe should also submit a minor RFC in order to comply with the process that we established after this PR was started. Don't think that gates submitting the PR though.", "@WindQAQ  I think it will has a lower overhead for you if we have this approved with a \"very light\" RFC so you will not waste your time on coding if it will be rejected.", "@WindQAQ I think there is still value in having the C++ kernel, even if it's just for CPUs. Would you mind keeping the C++ kernel?\r\n\r\n@alextp said he's okay with having both C++ kernel and python op if there's a selector (e.g., like in [RNN layer](https://github.com/tensorflow/tensorflow/blob/b4300661a666fa0ca9ebf4e80927bb155f39ec4e/tensorflow/python/keras/layers/recurrent_v2.py#L47)) to choose between implementations. ", "@WindQAQ Can you please check @penpornk's comments and keep us posted. Thanks!", "@penpornk @gbaned  I think the implementation is probably better discussed in the GELU migration RFC that we'll make. As soon as https://github.com/tensorflow/community/pull/241 is merged we can get that posted.\r\n\r\nI can't speak for @WindQAQ, but I'm personally unfamiliar with the define_fun `_FUNCTION_API_NAME_ATTRIBUTE` so we may need sponsor support in describing how this should be done.\r\n\r\n", "@seanpmorgan Got it. Thank you for the reply! \r\n\r\nI'm not familiar with `_FUNCTION_API_NAME_ATTRIBUTE` either, but I think @alextp can help loop someone in on this.", "That is used for the implementation selector. cc @qlzh727 ", "_FUNCTION_API_NAME_ATTRIBUTE is used by https://github.com/tensorflow/tensorflow/blob/a913689fddb70729dbce45a2cad44f4bd0f03935/tensorflow/core/grappler/optimizers/implementation_selector.cc. It allows user to define multiple TF functions which are optimized for specific hardware, and select the best options based on the device placement.\r\n\r\nThe LSTM/GRU layer is using it to leverage fused cudnn kernel when its landed on GPU, to achieve better performance.", "@WindQAQ, @seanpmorgan, @qlzh727  Any update on this PR? Please. Thanks!", "@WindQAQ @seanpmorgan @qlzh727 we have some interest in this OP too. Is there anything we can do to help push this forward?", "> @cheshire and @sanjoy might be interested in the performance of XLA vs the custom op here\r\n\r\nI've filed a bug internally to track this.\r\n\r\nIf XLA was as fast as the hand-written kernel would we not need to add a new op?  Or are we going to add the new op either way (for instance, because we expect this op to be called with many shapes so the recompilation overhead is high)?", "> @WindQAQ @seanpmorgan @qlzh727 we have some interest in this OP too. Is there anything we can do to help push this forward?\r\n\r\nApologies for the delay. [RFC #252](https://github.com/tensorflow/community/pull/252) created to discuss and then we can submit a follow up PR.", "@penpornk @seanpmorgan @alextp the RFC does not seem to contain the core C++ kernel requests. I have made a mention to continue this discussion as we see value in the kernel. Here is the discussion within the RFC channel: https://github.com/tensorflow/community/pull/252#discussion_r437542649\r\nAttn: @agramesh1 ", "The problem with adding a CPU kernel is that we'll need to add a gradient,\nfor rule, tfxla bridge, gpu kernel, etc, or the op will have spotty\ncoverage. For now addons found that turning xla jit on could match the\nperformance of the CPU kernel for inference. For backprop just doing that\nhas slightly higher memory usage but we're working on improving the support\nof tf.recompute_grad on xla to fix this.\n\nOn Tue, Jun 9, 2020 at 9:00 AM nammbash <notifications@github.com> wrote:\n\n> @penpornk <https://github.com/penpornk> @seanpmorgan\n> <https://github.com/seanpmorgan> @alextp <https://github.com/alextp> the\n> RFC does not seem to contain the core CPU kernel requests. I have made a\n> mention to continue this discussion as we see value in the kernel. Here is\n> the discussion within the RFC channel: tensorflow/community#252 (comment)\n> <https://github.com/tensorflow/community/pull/252#discussion_r437542649>\n> Attn: @agramesh1 <https://github.com/agramesh1>\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/33945#issuecomment-641400004>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAABHRJJVVFFX3YJ6ADHQTTRVZMB7ANCNFSM4JIKFKMA>\n> .\n>\n\n\n-- \n - Alex\n", "@alext I think that If you need max performance on a specific platform it could be also already intercepeted by other compliers like in https://github.com/NervanaSystems/ngraph/blob/master/src/contrib/mlir/core/ngraph_dialect/fused_ops.td#L853", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "@alextp there are loads of optimizations and fusions based on GELU op being present in the core. Having it as a c++ kernel is of immense performance boost, in models such as BERT", "> Having it as a c++ kernel is of immense performance boost, in models such as BERT\r\n\r\nThis is true. For instance, the [PyTorch implementation](https://github.com/pytorch/pytorch/commit/93ae040ff03266a26339f5d1582020185e0f0f92) (added a year ago)  ''can reduce the forward time from 333ms to 109ms'' compared to the unspecialized implementation. Edit: I remember a JAX presentation last summer showing automatic and large speedups to the GELU specifically.", "But with xla we should be able to close the gap. Can you try a\ntf.function(experimental_compile=True) around gelu and measure the\nperformance?\n\nOn Tue, Jun 30, 2020 at 9:54 PM Dan Hendrycks <notifications@github.com>\nwrote:\n\n> Having it as a c++ kernel is of immense performance boost, in models such\n> as BERT\n>\n> This is true. For instance, the PyTorch implementation\n> <https://github.com/pytorch/pytorch/commit/93ae040ff03266a26339f5d1582020185e0f0f92>\n> (added a year ago) ''can reduce the forward time from 333ms to 109ms''\n> compared to the pythonic implementation.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/33945#issuecomment-652189446>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAABHRNG2KIUHOL253SVMK3RZK6QTANCNFSM4JIKFKMA>\n> .\n>\n\n\n-- \n - Alex\n", "@alextp Why we have not benchmarks in CI for some PR? Could be integrated with https://github.com/tensorflow/benchmarks?", "@naveenjha123 @zongweiz  do either of you know how easy it is to externalize the visibility of the benchmarks we already run continuously?", "> @naveenjha123 @zongweiz do either of you know how easy it is to externalize the visibility of the benchmarks we already run continuously?\r\n\r\n@alextp this is a great suggestion. Thanks. We have [TF2 benchmarks] (https://github.com/tensorflow/models/tree/master/official/benchmark) from every official model garden model and they continuously running internally, using [PerfZero framework](https://github.com/tensorflow/benchmarks/perfzero). We should be able to select a set of benchmarks and hook it up with github CI (jenkins). Added @sganeshb to this thread for information and we will follow up.\r\n\r\nAnother thought is to start CI tests using a selected set of tf_benchmarks, for example, this [one](https://github.com/tensorflow/tensorflow/blob/7b9f5cce9309e0198af4dc3f2c8bcd9943c877fa/tensorflow/tools/test/BUILD#L106) ", "Can we move this part of the thread in another place? Like in a community or build repos issue. \nI don't want to loose this part of the thread when Gelu is merged.", "@WindQAQ doesn't seem responsive so who is taking care of this?\r\nIf the optimized tanh approximation of the GELU is around as fast as the exact version ``x * 0.5 * (1.0 + tf.math.erf(x / sqrt_two))``, then it would make sense to use the exact version. I originally used the approximation with the tanh approximation because years ago the exact unoptimized pythonic version was very slow.", "I think there will be always the opportunity at the end of the game to call canned ops. I.e. for Intel CPU/GPU  \r\n\r\nhttps://github.com/oneapi-src/oneDNN/blob/master/tests/benchdnn/dnn_types.hpp#L184-L185", "Hi all, as per https://github.com/tensorflow/community/pull/252, we open a new PR https://github.com/tensorflow/tensorflow/pull/41178. Please see that PR for more details and updates.", "@WindQAQ I see the python implementation is forked out of this. Any word on the C++ implementation \r\n@alextp  or @WindQAQ  \r\n\r\nAttn: @penpornk  @agramesh1 ", "> @WindQAQ I see the python implementation is forked out of this. Any word on the C++ implementation\r\n> @alextp or @WindQAQ\r\n> \r\n> Attn: @penpornk @agramesh1\r\n\r\nPlease see https://github.com/tensorflow/tensorflow/pull/41178#issuecomment-655231498."]}, {"number": 33944, "title": "TPU support has regressed in tf-nightly (worked well in tf=2.0.0) - operation or function not registered in the binary running in this process", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes (see below).  The code has been adopted from the Colab notebook (https://colab.research.google.com/drive/1yWaLpCWImXZE2fPV0ZYDdWWI8f52__9A#scrollTo=mnhwpzb73KIL) with instructions below on how to run a TPU using ctpu.  I have 90 days free access with TFRC.\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Cloud TPU pair (Master VM is Linux 4.9.0-11-amd64 #1 SMP Debian 4.9.189-3+deb9u1 (2019-09-20) x86_64 GNU/Linux and TPU is v3.8 8 corel)\r\n- TensorFlow installed from (source or binary):  binary (pip)\r\n- TensorFlow version (use command below): Tested on tf-nightly binary (2.1.0-dev20191102) from pip.\r\n- Python version: conda-forge 3.7.3\r\n\r\n**Describe the current behavior**\r\nWhen tf-nightly is installed, following the setup instructions below and running the attached code (yourcode.py) gives an error.  It occurs at lines 54-56 (traceback line 56) of yourcode.py:\r\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver()\r\ntf.config.experimental_connect_to_cluster(tpu)\r\ntf.tpu.experimental.initialize_tpu_system(tpu)\r\n\r\nI have marked the place at line 58 with \"# This is where the error occurs\".\r\n\r\nThe full output including the error is (follow the steps under \"Code to reproduce this issue\"):\r\n\r\n2019-11-03 06:59:16.549391: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory\r\n2019-11-03 06:59:16.549450: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\r\n2.1.0-dev20191102\r\n2019-11-03 06:59:18.662355: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\r\n2019-11-03 06:59:18.662422: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: UNKNOWN ERROR (303)\r\n2019-11-03 06:59:18.662459: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (mimetic): /proc/driver/nvidia/version does not exist\r\n2019-11-03 06:59:18.663151: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2019-11-03 06:59:18.672455: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\r\n2019-11-03 06:59:18.673297: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55ca94e697b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2019-11-03 06:59:18.673382: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\nINFO:absl:Overwrite dataset info from restored data version.\r\nINFO:absl:Reusing dataset glue (gs://mimetic_store/glue/mrpc/0.0.2)\r\nINFO:absl:Constructing tf.data.Dataset for split None, from gs://mimetic_store/glue/mrpc/0.0.2\r\nSaved glue_mnli_train.\r\nSaved glue_mnli_valid.\r\n2019-11-03 07:00:41.886095: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:300] Initialize GrpcChannelCache for job worker -> {0 -> 10.240.1.2:8470}\r\n2019-11-03 07:00:41.886162: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:300] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:54535}\r\n2019-11-03 07:01:53.957214: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:300] Initialize GrpcChannelCache for job worker -> {0 -> 10.240.1.2:8470}\r\n2019-11-03 07:01:53.957297: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:300] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:54535}\r\n2019-11-03 07:01:53.958220: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:390] Started server with target: grpc://localhost:54535\r\nINFO:absl:Entering into master device scope: /job:worker/replica:0/task:0/device:CPU:0\r\nTraceback (most recent call last):\r\n  File \"yourcode.py\", line 56, in <module>\r\n    tf.tpu.experimental.initialize_tpu_system(tpu)\r\n  File \"/home/daniel_bonner_anu_edu_au/anaconda3/envs/tfgpu/lib/python3.7/site-packages/tensorflow_core/python/tpu/tpu_strategy_util.py\", line 103, in initialize_tpu_system\r\n    serialized_topology = output.numpy()\r\n  File \"/home/daniel_bonner_anu_edu_au/anaconda3/envs/tfgpu/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 942, in numpy\r\n    maybe_arr = self._numpy()  # pylint: disable=protected-access\r\n  File \"/home/daniel_bonner_anu_edu_au/anaconda3/envs/tfgpu/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 910, in _numpy\r\n    six.raise_from(core._status_to_exception(e.code, e.message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.NotFoundError: '__inference__tpu_init_fn_4206710' is neither a type of a primitive operation nor a name of a function registered in binary running on n-48a744b7-w-0. Make sure the operation or function is registered in the binary running in this process.\r\n2019-11-03 07:01:54.492446: W tensorflow/core/distributed_runtime/eager/remote_tensor_handle_data.cc:75] Unable to destroy remote tensor handles. If you are running a tf.function, it usually indicates some op in the graph gets an error: '__inference__tpu_init_fn_4206710' is neither a type of a primitive operation nor a name of a function registered in binary running on n-48a744b7-w-0. Make sure the operation or function is registered in the binary running in this process.\r\n\r\n**Describe the expected behavior**\r\nWhen tested on tensorflow==2.0.0 from pip, the code completes. \r\nThe whole process (with tf2.0.0) outputs at the end:\r\nEpoch: [2] Validation accuracy = 0.843137264251709\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\nCreate a Google Cloud master VM and TPU pair:\r\n\r\nctpu up --name=yourtpupair --zone=us-central1-a --tpu-size=v3-8 --machine-type=n1-standard-8 --disk-size-gb=40\r\n\r\nSet up a conda python 3.7 development environment with tf-nightly on the master VM\r\n\r\nsudo apt update && sudo apt install bzip2 libxml2-dev libxslt-dev -y && wget https://repo.anaconda.com/archive/Anaconda3-2019.10-Linux-x86_64.sh && bash Anaconda3-2019.10-Linux-x86_64.sh\r\n\r\nAccept the defaults and initialize Anaconda\r\n\r\nrm Anaconda3-2019.10-Linux-x86_64.sh && . ~/.bashrc && conda config --add channels anaconda && conda config --add channels conda-forge && conda config --set channel_priority strict && conda create -n yourconda python=3.7 -y && conda activate yourconda\r\n\r\nconda install tqdm\r\n\r\npip install tensorflow-datasets transformers && pip install --upgrade google-api-python-client && pip install --upgrade oauth2client && pip install --ignore-installed --upgrade tf-nightly\r\n\r\nDownload the \"glue/mrpc\" dataset to ~/tensorflow_datasets in a python shell:\r\n\r\npython\r\nimport tensorflow as tf\r\nimport tensorflow_datasets\r\ndata = tensorflow_datasets.load(\"glue/mrpc\")\r\n\r\nCreate a Google storage bucket named \"your_bucket\".\r\n\r\nCopy the entire folder (~/tensorflow_datasets/glue) to gs://your_bucket\r\n\r\nRun the code in yourcode.py on a Google Cloud VM master's conda environment (yourconda) connected to TPU:\r\n\r\npython yourcode.py\r\n\r\nThe output above (including the error) is produced.\r\n\r\nNow install tensorflow==2.0.0 and rerun it and training will complete:\r\n\r\npip install --ignore-installed --upgrade tensorflow==2.0.0\r\npython yourcode.py\r\n\r\n[yourcode.py.txt](https://github.com/tensorflow/tensorflow/files/3801308/yourcode.py.txt)\r\n(rename it yourcode.py)", "comments": ["@dbonner,\r\nCould you please update TensorFlow to the latest stable version v2.4 and check if you are facing the same error. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33944\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33944\">No</a>\n"]}, {"number": 33943, "title": "The current session will be closed and a new session will be created. Error: Stream IDs exhausted", "body": "System information\r\nTensorFlow:\r\n\r\nOS Platform and Distribution (e.g., centos7):\r\nTensorFlow installed from ( binary):\r\nTensorFlow version (1.8):\r\nin Distrubuted TensorFlow, train 38 days, we get the error \" INFO:tensorflow:An error was raised. This may be due to a preemption in a connected worker or parameter server. The current session will be closed and a new session will be created. Error: Stream IDs exhausted \" ,\r\nany better to solve this quesution?\r\n\r\nmore info\r\nINFO:tensorflow:An error was raised. This may be due to a preemption in a connected worker or parameter server. The current session will be closed and a new session will be created. Error: Stream IDs exhausted\r\n\t [[Node: Embedding/emb_D_DOCID_lookup_sparse/embedding_lookup/DynamicPartition_S9663 = _Recv[client_terminated=false, recv_device=\"/job:ps/replica:0/task:0/device:CPU:0\", send_device=\"/job:worker/replica:0/task:0/device:CPU:0\", send_device_incarnation=-1272333736861591317, tensor_name=\"edge_636_Embedding/emb_D_DOCID_lookup_sparse/embedding_lookup/DynamicPartition\", tensor_type=DT_INT64, _device=\"/job:ps/replica:0/task:0/device:CPU:0\"]()]]\r\n\t [[Node: Embedding/emb_U_USERID_lookup_sparse/embedding_lookup/GatherV2_85_S10351 = _HostRecv[client_terminated=false, recv_device=\"/job:worker/replica:0/task:0/device:GPU:0\", send_device=\"/job:ps/replica:0/task:0/device:CPU:0\", send_device_incarnation=-4470066425874193753, tensor_name=\"edge_1755_Embedding/emb_U_USERID_lookup_sparse/embedding_lookup/GatherV2_85\", tensor_type=DT_FLOAT, _device=\"/job:worker/replica:0/task:0/device:GPU:0\"]()]]\r\n\t [[Node: Embedding/emb_U_USERID_lookup_sparse/embedding_lookup/DynamicPartition_S9895 = _Recv[client_terminated=false, recv_device=\"/job:ps/replica:0/task:1/device:CPU:0\", send_device=\"/job:worker/replica:0/task:0/device:CPU:0\", send_device_incarnation=-1272333736861591317, tensor_name=\"edge_1132_...cPartition\", tensor_type=DT_INT64, _device=\"/job:ps/replica:0/task:1/device:CPU:0\"]()]]\r\n", "comments": ["Request you to provide more information, minimal standalone code to reproduce the issue. Please, share the correct links,as current links you shared are routing to same issue again.Thanks!", "@ravikyram this is all the information , no other information in log", "potential duplicate https://github.com/tensorflow/models/issues/5633\r\nFrom the thread, solution will be to switch to latest tf version. Thanks!", "It has been 29 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 33942, "title": "Stacking CNN wrecks reproducibility (even with seed & CPU)", "body": "**REPRODUCIBLE**:\r\n```python\r\nipt = Input(batch_shape=batch_shape)\r\nx   = Conv2D(6, (8, 8), strides=(2, 2), activation='relu')(ipt)\r\nx   = Flatten()(x)\r\nout = Dense(6, activation='softmax')(x)\r\n```\r\n**NOT REPRODUCIBLE**:\r\n```python\r\nipt = Input(batch_shape=batch_shape)\r\nx   = Conv2D(6, (8, 8), strides=(2, 2), activation='relu')(ipt)\r\nx   = Conv2D(6, (8, 8), strides=(2, 2), activation='relu')(x)\r\nx   = Flatten()(x)\r\nout = Dense(6, activation='softmax')(x)\r\n```\r\n<hr>\r\n\r\nThe difference amplifies substantially when using a larger model, and actual data instead of random noise - up to **30% difference in accuracy** (relative) within a single small epoch. Environment setup, considered sources, and full minimal reproducible example below. [Relevant SO](https://stackoverflow.com/questions/58675856/why-does-stacking-cnn-wreck-reproducibility-even-with-seed-cpu?noredirect=1#comment103653213_58675856)\r\n\r\nWhat is the problem, and how to fix it?\r\n\r\n<hr>\r\n\r\n**POSSIBLE SOURCES**: (**[x]** = ruled out)\r\n\r\n - **[x]** TF2 vs. TF1; Keras 2.3.0+ vs. Keras 2.2.5 (tested both)\r\n - **[x]** Random seeds (`numpy`, `tf`, `random`, `PYTHONHASHSEED`)\r\n - **[x]** Data values / shuffling (same values, no shuffling)\r\n - **[x]** Weight initializations (same values)\r\n - **[x]** GPU usage (used CPU)\r\n - **[x]** CPU multithreading (used single thread; also see below's 'further')\r\n - **[x]** Numeric imprecision (used float64; further, extent of discrepancy too large for num. impr.)\r\n - **[x]** Bad CUDA install (all [official guide](https://docs.nvidia.com/cuda/archive/10.0/cuda-installation-guide-microsoft-windows/index.html) tests passed, TF detects GPU & CUDA)\r\n\r\n<hr>\r\n\r\n**ENVIRONMENT**:\r\n\r\n - CUDA 10.0.130, cuDNN 7.6.0, Windows 10, GTX 1070\r\n - Python 3.7.4, Spyder 3.3.6, Anaconda 3.0 10/19\r\n - Anaconda Powershell Prompt terminal to set `PYTHONHASHSEED` and start Spyder\r\n\r\n<hr>\r\n\r\n**OBSERVATIONS**:\r\n\r\n - `float64` vs. `float32` - no noticeable difference\r\n - CPU vs. GPU - no noticeable difference\r\n - Non-reproducible also for `Conv1D`\r\n - Reproducible for `Dense` replacing `Conv`; other layers not tested\r\n - For a [larger model](https://pastebin.com/VSV7jv7x), which is still 'small', loss variance is substantial within a single epoch:\r\n\r\n```python\r\none_epoch_loss = [1.6814, 1.6018, 1.6577, 1.6789, 1.6878, 1.7022, 1.6689]\r\none_epoch_acc  = [0.2630, 0.3213, 0.2991, 0.3185, 0.2583, 0.2463, 0.2815]\r\n```\r\n\r\n<hr>\r\n\r\n**CODE**:\r\n\r\n```python\r\nbatch_shape = (32, 64, 64, 3)\r\nnum_samples = 1152\r\n\r\nipt = Input(batch_shape=batch_shape)\r\nx   = Conv2D(6, (8, 8), strides=(2, 2), activation='relu')(ipt)\r\nx   = Conv2D(6, (8, 8), strides=(2, 2), activation='relu')(x)\r\nx   = Flatten()(x)\r\nout = Dense(6, activation='softmax')(x)\r\nmodel = Model(ipt, out)\r\nmodel.compile('adam', 'sparse_categorical_crossentropy')\r\n\r\nX = np.random.randn(num_samples, *batch_shape[1:])\r\ny = np.random.randint(0, 6, (num_samples, 1))\r\n\r\nreset_seeds()\r\nmodel.fit(x_train, y_train, epochs=5, shuffle=False)\r\n```\r\n<hr>\r\n\r\n**Imports / setup**:\r\n\r\n\r\n```python\r\nimport os\r\nos.environ['PYTHONHASHSEED'] = '0'\r\nos.environ['CUDA_VISIBLE_DEVICES'] = '-1'\r\nimport numpy as np\r\nnp.random.seed(1)\r\nimport random\r\nrandom.seed(2)\r\n\r\nimport tensorflow as tf\r\nsession_conf = tf.ConfigProto(\r\n      intra_op_parallelism_threads=1,\r\n      inter_op_parallelism_threads=1)\r\nsess = tf.Session(config=session_conf) # single-threading; TF1-only\r\n\r\ndef reset_seeds():\r\n    np.random.seed(1)\r\n    random.seed(2)\r\n    if tf.__version__[0] == '2':\r\n        tf.random.set_seed(3)\r\n    else:\r\n        tf.set_random_seed(3)\r\n    print(\"RANDOM SEEDS RESET\")\r\nreset_seeds()\r\n\r\nfrom keras.layers import Input, Dense, Conv2D, Flatten\r\nfrom keras.models import Model\r\nimport keras.backend as K\r\n\r\nK.set_floatx('float64')\r\n```", "comments": ["@OverLordGoldDragon Can you please provide a simple standalone code to reproduce the issue? If you can, please create a colab gist or Jupyter notebook whichever is convenient to you. Can you please add more details on what you mean by \r\n\r\n> up to 30% difference in accuracy (relative) within a single small epoch\r\n\r\nThanks!", "@jvishnuvardhan Standalone code's in the original post, with random seeds set so you can reproduce the issue. The \"30%\" refers to the final bullet point under \"OBSERVATIONS\"; if needed, I can provide code to reproduce that as well - it's of a small-medium sized model w/ more conv layers.\r\n\r\nLet me know if more info's needed - thanks", "The problem is rather severe; should I produce a more obvious example? Haven't had a chance to investigate this fully yet - did anyone look into it? ", "It looks like the results is reproducible using tf-nightly. Closing this for now, but feel free to reopen it if it doesn't work on your end. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33942\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33942\">No</a>\n"]}, {"number": 33941, "title": "Visualize accuracy on tensorboard", "body": "\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):binary\r\n- TensorFlow version (use command below):1.13.1\r\n- Python version:3.6.4\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:9/7.4\r\n- GPU model and memory: Nvidia Geforce 840m 4 Go\r\n\r\n**Describe the current behavior**\r\nHello,\r\nI'm trained a model and I have all .ckpts files with `graph.pbtxt` and `checkpoint` file.\r\nI would like to visualize all parameters, for e.g ( accuracy , precision , valid loss and train loss ) using Tensorboard.\r\nThe problem is that I can only visualize the loss and the learning_rate graph\r\n\r\nHow can I see all the metrics and graphs on Tensorboard? \r\n\r\n", "comments": ["@abdou31,\r\nAs per my understanding, you might be using the code similar to that shown below, as shown in [this link](https://www.tensorflow.org/tensorboard/scalars_and_keras#training_the_model_and_logging_loss) \r\n\r\n`model.compile(loss='mse', # keras.losses.mean_squared_error    optimizer=keras.optimizers.SGD(lr=0.2))`\r\n\r\nBy adding the line, `metrics=['accuracy']`, you should be able to visualize the Accuracy in Tensorboard. Code should be as shown below:\r\n\r\n```\r\nmodel.compile(loss='mse', # keras.losses.mean_squared_error\r\n    metrics=['accuracy'],\r\n    optimizer=keras.optimizers.SGD(lr=0.2),)\r\n```\r\n\r\nPlease let us know if it works. Thanks!", "Sorry, for some false information.\r\nI can see only the variable of `global_steps` and `loss`, not `learning_rate` and `loss` variables as mentioned in the image below:\r\n\r\n![image](https://user-images.githubusercontent.com/19480228/68116957-5bfc8400-fefc-11e9-9cc2-49d0cf2d32ec.png)\r\n\r\nFor the code , I do not have used keras implementation , I have used estimator and that was some of my code:\r\n```python\r\nif mode == tf.estimator.ModeKeys.PREDICT:\r\n        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions_dict)\r\n\r\n    # Calculate loss using mean squared error.\r\n    label_tensor = tf.convert_to_tensor(labels, dtype=tf.float32)\r\n    loss = tf.losses.mean_squared_error(\r\n        labels=label_tensor, predictions=logits)\r\n\r\n    # Configure the train OP for TRAIN mode.\r\n\r\n    if mode == tf.estimator.ModeKeys.TRAIN:\r\n        optimizer = tf.train.AdamOptimizer(learning_rate=0.0001) # Reducing the learning rate value from 0.001 to 0.0001\r\n        train_op = optimizer.minimize(\r\n            loss=loss,\r\n            global_step=tf.train.get_global_step()\r\n            )\r\n        return tf.estimator.EstimatorSpec(\r\n            mode=mode,\r\n            loss=loss,\r\n            train_op=train_op,\r\n            export_outputs={'marks': tf.estimator.export.RegressionOutput(logits)})\r\n\r\n    # Add evaluation metrics (for EVAL mode)\r\n    eval_metric_ops = {\r\n        \"accuracy\": tf.metrics.accuracy(\r\n            labels=label_tensor,\r\n            predictions=logits)}\r\n    return tf.estimator.EstimatorSpec(\r\n        mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\r\n\r\n```\r\n\r\nWhat should I change?\r\n\r\n\r\nNote: That I can evaluate the model using ModeKeys.Eval but the accuracy is very strange, it gives (0.0014) and the prediction is so differents ( detect eye landmarks );\r\n\r\n![rseess](https://user-images.githubusercontent.com/19480228/68117238-1096a580-fefd-11e9-8e94-1c7a8ff6563f.PNG)\r\n", "@abdou31,\r\nCan you please check [this link](https://towardsdatascience.com/first-contact-with-tensorflow-estimator-69a5e072998d) where the Model is built using Estimators and Accuracy is Visualized in Tensorboard. \r\nThanks!", "I have tried what is mentionned in the link but , I go this error:\r\n>ValueError: Passed (<tf.Tensor 'accuracy/value:0' shape=() dtype=float32>, <tf.Tensor 'accuracy/update_op:0' shape=() dtype=float32>) should have graph attribute that is equal to current graph <tensorflow.python.framework.ops.Graph object at 0x0000018B36721DA0>.\r\n\r\n\r\nThat was what I have added :\r\n\r\n```python \r\n accuracy=tf.metrics.accuracy(labels=label_tensor,predictions=logits)\r\n    # Create train hook list to visualize loss , accuracy and global_steps\r\n\r\n    train_hook_list=[]\r\n    train_tensors_log={\"accuracy\":accuracy,\"loss\":loss,\"global_steps\":tf.train.get_global_step()}\r\n    train_hook_list.append(tf.train.LoggingTensorHook(tensors=train_tensors_log,every_n_iter=100))\r\n    # Configure the train OP for TRAIN mode.\r\n\r\n    if mode == tf.estimator.ModeKeys.TRAIN:\r\n        optimizer = tf.train.AdamOptimizer(learning_rate=0.0001) # Reducing the learning rate value from 0.001 to 0.0001\r\n        train_op = optimizer.minimize(\r\n            loss=loss,\r\n            global_step=tf.train.get_global_step()\r\n            )\r\n        return tf.estimator.EstimatorSpec(\r\n            mode=mode,\r\n            loss=loss,\r\n            train_op=train_op,\r\n            training_hooks=train_hook_list,\r\n            export_outputs={'marks': tf.estimator.export.RegressionOutput(logits)})\r\n\r\n```\r\n\r\n\r\n\r\n**Update**:\r\n\r\nI solved this problem, in training it appears the accuracy:\r\n\r\n![zzssacuu](https://user-images.githubusercontent.com/19480228/68469772-1c46dc80-021b-11ea-9c0e-1eaef8d0c6ad.PNG)\r\n\r\n\r\nBut when I try to visualize the accuracy on Tensorboard, I didn't get it :\r\n\r\n![accurrc](https://user-images.githubusercontent.com/19480228/68469814-3680ba80-021b-11ea-8430-0ba733e0a7a3.PNG)\r\n\r\n\r\nWhat is the problem here??", "To solve the error please go through the following [question](https://stackoverflow.com/questions/42799041/valueerror-passed-tensor-should-have-graph-attribute-that-is-equal-to-curr) @abdou31 ", "@abdou31 Were you able to solve the probe using the recommendation above? Thanks!", "No . \r\nBecause my problem is related to regression not classification", "Can you try just adding `tf.summary.scalar(\"accuracy\", accuracy)` to your estimator model function, below where you define the accuracy metric?", "@nfelt sorry but the main problem here is a regression problem. There is no accuracy in regression ", "I asked about accuracy because that's what was shown in the sample of your model function.  If that's not the model function and metric you're interested in getting working, can you post the details of what those are and what the specific problem is?", "@nfelt , The problem is I would like to show accuracy in Tensorboard after training my model.\r\nI'm working on a model that predict eye landmarks in real-time, I would like to tell you that this is related to a regression problem, not a classification problem.\r\nDo you have any idea how can I see the correct accuracy ( summary graph ) on Tensorboard ?\r\nNote: the original project that I work on it is CNN facial Facial landmark of Yin Guibang , ", "> \r\n> \r\n> I have tried what is mentionned in the link but , I go this error:\r\n> \r\n> > ValueError: Passed (<tf.Tensor 'accuracy/value:0' shape=() dtype=float32>, <tf.Tensor 'accuracy/update_op:0' shape=() dtype=float32>) should have graph attribute that is equal to current graph <tensorflow.python.framework.ops.Graph object at 0x0000018B36721DA0>.\r\n> \r\n> That was what I have added :\r\n> \r\n> ```python\r\n>  accuracy=tf.metrics.accuracy(labels=label_tensor,predictions=logits)\r\n>     # Create train hook list to visualize loss , accuracy and global_steps\r\n> \r\n>     train_hook_list=[]\r\n>     train_tensors_log={\"accuracy\":accuracy,\"loss\":loss,\"global_steps\":tf.train.get_global_step()}\r\n>     train_hook_list.append(tf.train.LoggingTensorHook(tensors=train_tensors_log,every_n_iter=100))\r\n>     # Configure the train OP for TRAIN mode.\r\n> \r\n>     if mode == tf.estimator.ModeKeys.TRAIN:\r\n>         optimizer = tf.train.AdamOptimizer(learning_rate=0.0001) # Reducing the learning rate value from 0.001 to 0.0001\r\n>         train_op = optimizer.minimize(\r\n>             loss=loss,\r\n>             global_step=tf.train.get_global_step()\r\n>             )\r\n>         return tf.estimator.EstimatorSpec(\r\n>             mode=mode,\r\n>             loss=loss,\r\n>             train_op=train_op,\r\n>             training_hooks=train_hook_list,\r\n>             export_outputs={'marks': tf.estimator.export.RegressionOutput(logits)})\r\n> ```\r\n> \r\n> **Update**:\r\n> \r\n> I solved this problem, in training it appears the accuracy:\r\n> \r\n> ![zzssacuu](https://user-images.githubusercontent.com/19480228/68469772-1c46dc80-021b-11ea-9c0e-1eaef8d0c6ad.PNG)\r\n> \r\n> But when I try to visualize the accuracy on Tensorboard, I didn't get it :\r\n> \r\n> ![accurrc](https://user-images.githubusercontent.com/19480228/68469814-3680ba80-021b-11ea-8430-0ba733e0a7a3.PNG)\r\n> \r\n> What is the problem here??\r\n\r\nwhere I can add your code for show accuracy when training my model ", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33941\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33941\">No</a>\n"]}, {"number": 33940, "title": "Add dropout layer to a Resnet Model", "body": "Hello, \r\nThis is not a bug, I'm searching for help or a suggestion, I have posted many questions on StackOverflow but I didn't get any answer.\r\nI search for a way to add a dropout layer to improve the precision and accuracy of the model.\r\n```python\r\n    flatten = tf.layers.flatten(inputs=conv8)\r\n\r\n   # dropout=tf.layers.dropout(inputs=flatten,training=false) # Add dropout here\r\n\r\n    # Dense layer 1, a fully connected layer.\r\n    dense1 = tf.layers.dense(\r\n        inputs=flatten,\r\n        units=1024,\r\n        activation=tf.nn.relu,\r\n        use_bias=True)\r\n\r\n    # Dense layer 2, also known as the output layer.\r\n    logits = tf.layers.dense(\r\n        inputs=dense1,\r\n        units=80,\r\n        activation=None,\r\n        use_bias=True,\r\n        name=\"logits\")\r\n\r\n    # Make prediction for PREDICATION mode.\r\n    predictions_dict = {\r\n        \"name\": features['name'],\r\n        \"logits\": logits\r\n    }\r\n\r\n```\r\n\r\nIs it possible to add dropout layer between the flatten and the dense layer?\r\n", "comments": ["The most common practice is to use dropout layer after fully connected layer (Dense).\r\nSee [Dropout: A Simple Way to Prevent Neural Networks from Overfitting](http://jmlr.org/papers/v15/srivastava14a.html)\r\n However you may try using dropout between flatten and dense layer and study the effects.", "Already, I have trying using between the flatten and dense layer.\r\n+ No change in results and graph of the loss.\r\n\r\nI will try using the dropout layer after the dense layer ( dense 1 ) and I will tell you what is changed.", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 33939, "title": "Laconic error when validation_steps ommitted for model.fit in TF 2.0.0", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): **Colab**\r\n- TensorFlow version (use command below): v2.0.0-rc2-26-g64c3d38 2.0.0\r\n- Python version: 3.6.8\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory: **TPU selected Colab**\r\n\r\n**Describe the current behavior**\r\nWhen running the script below on TF 1.15, it runs well throughout.\r\nRunning in TF 2.0, it crashes on the validation stage of the first epoch.\r\nif `validation_steps` in `model.fit` is included it does run throughout.\r\nhowever, if it's omitted (which is natural to assume, as the dataset itself is not repeated)\r\na strange error message `TypeError: 'function' object is not subscriptable` is given.\r\n\r\n**Describe the expected behavior**\r\nEither, TF 2 should behave similarly to TF 1, ie use up the entire validation set.\r\nOr report a more informative error regarding 'validation_steps' requirement (similar to the error if steps_per_epoch are omitted for the training data).\r\n\r\n**Code to reproduce the issue**\r\n```\r\n%tensorflow_version 2.x  #(commented out for TF 1.x case)\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\nimport tensorflow_datasets as tfds\r\nimport os\r\n\r\nresolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\r\ntf.config.experimental_connect_to_cluster(resolver)\r\ntf.tpu.experimental.initialize_tpu_system(resolver)\r\nstrategy = tf.distribute.experimental.TPUStrategy(resolver)\r\n\r\nIMG_HEIGHT=IMG_WIDTH=200\r\nBATCH_SIZE=128\r\n\r\ndef create_model():\r\n  model = tf.keras.models.Sequential()\r\n  model.add(tf.keras.layers.BatchNormalization(input_shape=(IMG_HEIGHT,IMG_WIDTH,1)))\r\n  model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='elu'))\r\n  model.add(tf.keras.layers.MaxPooling2D(2))\r\n  model.add(tf.keras.layers.Dropout(0.25))\r\n\r\n  model.add(tf.keras.layers.BatchNormalization(input_shape=(IMG_HEIGHT,IMG_WIDTH,3)))\r\n  model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='elu'))\r\n  model.add(tf.keras.layers.MaxPooling2D(2))\r\n  model.add(tf.keras.layers.Dropout(0.25))\r\n\r\n  model.add(tf.keras.layers.BatchNormalization(input_shape=(IMG_HEIGHT,IMG_WIDTH,3)))\r\n  model.add(tf.keras.layers.Conv2D(64, (5, 5), activation='elu'))\r\n  model.add(tf.keras.layers.MaxPooling2D(2))\r\n  model.add(tf.keras.layers.Dropout(0.25))\r\n\r\n  model.add(tf.keras.layers.BatchNormalization())\r\n  model.add(tf.keras.layers.Conv2D(128, (3, 3),  activation='elu'))\r\n  model.add(tf.keras.layers.MaxPooling2D(2))\r\n  model.add(tf.keras.layers.Dropout(0.25))\r\n\r\n  model.add(tf.keras.layers.BatchNormalization())\r\n  model.add(tf.keras.layers.Conv2D(256, (3, 3),  activation='elu'))\r\n  #model.add(tf.keras.layers.MaxPooling2D(2))\r\n  model.add(tf.keras.layers.Dropout(0.25))\r\n\r\n  model.add(tf.keras.layers.BatchNormalization())\r\n  model.add(tf.keras.layers.Conv2D(512, (3, 3),  activation='elu'))\r\n  model.add(tf.keras.layers.MaxPooling2D(2))\r\n  model.add(tf.keras.layers.Dropout(0.25))\r\n\r\n  model.add(tf.keras.layers.Flatten())\r\n  model.add(tf.keras.layers.Dense(256))\r\n  model.add(tf.keras.layers.Activation('elu'))\r\n  model.add(tf.keras.layers.Dropout(0.5))\r\n  model.add(tf.keras.layers.Dense(10))\r\n  model.add(tf.keras.layers.Activation('softmax'))\r\n  return model\r\n\r\n\r\nwith strategy.scope():\r\n  train_ds = (tfds.load(\"mnist:3.*.*\", split=\"train\", as_supervised=True, try_gcs=True)\r\n    .map(lambda image,label:(tf.image.convert_image_dtype(image, tf.float32),label))\r\n    .map(lambda image,label:(tf.image.resize(image,(IMG_HEIGHT,IMG_WIDTH)),label))\r\n    #.map(lambda image,label:(tf.cast(image, tf.float32)/255.0,tf.cast(label, tf.float32)))\r\n    .batch(BATCH_SIZE))\r\n\r\n  #distributed_train_ds=strategy.experimental_distribute_dataset(train_ds)\r\n\r\n  validation_ds = (tfds.load(\"mnist:3.*.*\", split=\"test\", as_supervised=True, try_gcs=True)\r\n    .map(lambda image,label:(tf.image.convert_image_dtype(image, tf.float32),label))\r\n    .map(lambda image,label:(tf.image.resize(image,(IMG_HEIGHT,IMG_WIDTH)),label))\r\n    #.map(lambda image,label:(tf.cast(image, tf.float32)/255.0,tf.cast(label, tf.float32)))\r\n    .batch(BATCH_SIZE))\r\n\r\n  #distributed_validation_ds=strategy.experimental_distribute_dataset(validation_ds)\r\n\r\n  model=create_model()\r\n  model.compile(\r\n        optimizer=tf.keras.optimizers.Adam(),\r\n        loss=\"sparse_categorical_crossentropy\",\r\n        metrics=['sparse_categorical_accuracy'])\r\n\r\nmodel.fit(train_ds,epochs=3,steps_per_epoch=100,validation_data=validation_ds)\r\n```\r\nthis produces this output, after going through the training fine, it crashes on the validation set\r\n```\r\nTrain on 100 steps\r\nEpoch 1/3\r\n 99/100 [============================>.] - ETA: 0s - loss: 1.4453 - sparse_categorical_accuracy: 0.7015\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-10-fd27085b00aa> in <module>()\r\n----> 1 model.fit(train_ds,epochs=3,steps_per_epoch=100,validation_data=validation_ds)\r\n\r\n5 frames\r\n/tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/engine/training_utils.py in check_num_samples(ins, batch_size, steps, steps_name)\r\n    425     return None\r\n    426 \r\n--> 427   if hasattr(ins[0], 'shape'):\r\n    428     return int(ins[0].shape[0])\r\n    429   return None  # Edge case where ins == [static_learning_phase]\r\n\r\nTypeError: 'function' object is not subscriptable\r\n\r\n```\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["We should minimally be able to improve the error message here. @yhliang2018 will take a look, but if you are interested in contributing a fix, please let us know.", "@MikeOfZen This issue should have been fixed. Can you verify it with tf-nightly? If the error is gone, feel free to close the issue.", "@MikeOfZen As mentioned by @yhliang2018 , this was resolved `TF2.2.0-rc2`. Please check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/bbdb01789e1f322d5ddf16f329109309/untitled49.ipynb). Thanks!\r\n\r\nCan you please verify and close the issue? Thanks! ", "Closing this issue as this is fixed in the latest upcoming release as well as fix is available in tf-nightly. @MikeOfZen Please reopen if you are still running into issues. \r\nThanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33939\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33939\">No</a>\n"]}, {"number": 33938, "title": "CUDNN_STATUS_EXECUTION_FAILED", "body": "**System information**\r\n- I have written custom code (as opposed to using a stock example script provided in TensorFlow): Slightly modified version of seq2seq model from keras documentation \r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (use command below): 2.0.0 Stable\r\n- Python version: 3.7.5\r\n- CUDA/cuDNN version: CUDA-10.0, CuDNN-7.6.4.38\r\n- GPU model and memory: Nvidia 1050Ti(4GB) + 16GB RAM\r\n\r\n**Describe the current behavior**\r\nI'm getting an error while training on a small dataset using a seq2seq model. It trains upto 4 or 5 epochs after which it throws an error saying \"CUDNN_STATUS_EXECUTION_FAILED\" along with \"Failed to call ThenRnnBackward\"\r\n\r\n**Describe the expected behavior**\r\nI have tried reducing batch size and LSTM latent dimension but it crashes irrespectively. I recently updated to tf 2.0.0 and I never faced any such issues on 1.x\r\n\r\n**Code to reproduce the issue**\r\n\r\n\r\nbatch_size = 16\r\nepochs = 50\r\nlatent_dim = 50\r\ntraining_samples = 5000\r\n\r\nencoder_input_data = np.zeros((len(input_texts), max_encoder_seq_length, num_encoder_tokens),dtype='float32')\r\ndecoder_input_data = np.zeros((len(input_texts), max_decoder_seq_length, num_decoder_tokens),dtype='float32')\r\ndecoder_target_data = np.zeros((len(input_texts), max_decoder_seq_length, num_decoder_tokens),dtype='float32')\r\n\r\nfor i, (input_text, target_text) in enumerate(zip(input_texts, output_texts)):\r\n    for t, char in enumerate(input_text):\r\n        encoder_input_data[i, t, input_token_index.get(char)] = 1.\r\n    encoder_input_data[i, t + 1:, input_token_index.get(' ')] = 1.\r\n\r\n    for t, char in enumerate(target_text):\r\n        decoder_input_data[i, t, target_token_index.get(char)] = 1.\r\n        if t > 0:\r\n            decoder_target_data[i, t - 1, target_token_index.get(char)] = 1.\r\n    decoder_input_data[i, t + 1:, target_token_index.get(' ')] = 1.\r\n    decoder_target_data[i, t:, target_token_index.get(' ')] = 1.\r\n\r\n\r\nencoder_inputs = tf.keras.layers.Input(shape=(None, num_encoder_tokens))\r\nencoder = tf.keras.layers.LSTM(latent_dim, return_state=True)\r\nencoder_outputs, state_h, state_c = encoder(encoder_inputs)\r\nencoder_states = [state_h, state_c]\r\n\r\nencoder_input_datas = tf.keras.layers.Input(shape=(None,num_encoder_tokens))\r\nencoder = tf.keras.layers.LSTM(latent_dim,return_state=True)\r\nencoder_outputs, state_h, state_c = encoder(encoder_input_datas)\r\nencoder_states = [state_h,state_c]\r\n\r\ndecoder_inputs = tf.keras.layers.Input(shape=(None,num_decoder_tokens))\r\ndecoder = tf.keras.layers.LSTM(latent_dim,return_sequences=True,return_state=True)\r\ndecoder_outputs,_,_ = decoder(decoder_inputs,initial_state=encoder_states)\r\ndecoder_dense = tf.keras.layers.Dense(num_decoder_tokens,activation='softmax')\r\ndecoder_outputs = decoder_dense(decoder_outputs)\r\n\r\nmodel = tf.keras.models.Model([encoder_input_datas,decoder_inputs],decoder_outputs)\r\n\r\nmodel.compile(optimizer='rmsprop', loss='categorical_crossentropy',metrics=['accuracy'])\r\nmodel.fit([encoder_input_data,decoder_input_data],decoder_target_data,epochs=epochs)\r\n\r\n**Other info / logs**\r\nFull log:\r\nhttps://pastebin.com/Yht9t6fZ\r\n", "comments": ["Looks like code is incomplete.In order to expedite the trouble-shooting process, please provide complete code snippet to reproduce the issue in our environment.It helps in localizing the issue faster. Thanks!", "> Looks like code is incomplete.In order to expedite the trouble-shooting process, please provide complete code snippet to reproduce the issue in our environment.It helps in localizing the issue faster. Thanks!\r\n\r\nhttps://github.com/DarshanDeshpande/Seq2Seq-Model\r\nThis is the link to the project along with the files used. I did some reading and found out a similar issue to this. The person fixed it by downgrading their Nvidia drivers. I tried that too but that doesn't seem to work either", "Apologies for the delay in response. Is this still an issue? \r\nYou may try gpu memory resources management by allowing gpu memory growth.  \r\nTo know more see https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth\r\nYou can try Allowing GPU memory growth with:\r\n```python\r\nimport tensorflow as tf\r\ngpu = tf.config.experimental.list_physical_devices('GPU')\r\ntf.config.experimental.set_memory_growth(gpu[0], True)\r\n```", "> Apologies for the delay in response. Is this still an issue?\r\n> You may try gpu memory resources management by allowing gpu memory growth.\r\n> To know more see https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth\r\n> You can try Allowing GPU memory growth with:\r\n> \r\n> ```python\r\n> import tensorflow as tf\r\n> gpu = tf.config.experimental.list_physical_devices('GPU')\r\n> tf.config.experimental.set_memory_growth(gpu[0], True)\r\n> ```\r\n\r\nI tried this but it didn't work out for me. There's no problem with the code as such because it ran fine on my colab notebook. Maybe it's just the GPU driver issue or something. Anyway thanks for the help. Closing this topic now", "@DarshanDeshpande: Were you able to find out what was the issue or not? I see you've closed the issue with statement it might be GPU driver issue. Not sure if it's true as I am working on Windows machine with different setup (TF 2.0.1, CUDA 10.1, cuDNN 7.6.5.32, GeForce RTX 2070 with Max-Q Design) and it works in some cases (especially with lower batch size) and crashes randomly. Any help would be appreciated.", "Same error here, TF 2.2.0rc3, CUDA10.1, cuDNN 7.6.5.32, GeForce RTX 2070 with Max-Q Design. \r\n\r\nI have tried \r\n```\r\ngpu = tf.config.experimental.list_physical_devices('GPU')\r\ntf.config.experimental.set_memory_growth(gpu[0], True)\r\n```\r\n\r\nSimple model: \r\n\r\n```\r\nfrom tensorflow.keras import layers\r\nfrom tensorflow.keras import models\r\n\r\ndef make_model():\r\n\r\n    model = models.Sequential([\r\n        layers.LSTM(300, batch_input_shape=(8, 4096, 25), return_sequences=True),\r\n        layers.LSTM(100, return_sequences=True),  \r\n        layers.Dense(1, activation='sigmoid')\r\n    ])\r\n    \r\n    model.compile(\r\n      optimizer=\"adam\",\r\n      loss='binary_crossentropy'\r\n    )\r\n    return model\r\n\r\n```"]}, {"number": 33937, "title": "CuDNN faild to initialize after correct installation, ", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): PiP\r\n- TensorFlow version (use command below): 2.0.0\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10.0/7.6.3\r\n- GPU model and memory: RTX 2080TI\r\n\r\n**Describe the current behavior**\r\nCuDNN faild to initialize after correct installation, cant make TF2 work\r\n\r\n**Describe the expected behavior**\r\ntraining a conv network without an error\r\n\r\n**Other info / logs**\r\n\r\n> UnknownError                              Traceback (most recent call last)\r\n<ipython-input-12-4f1e47465b18> in <module>\r\n      1 # Train model\r\n----> 2 model.fit(x, y, epochs=5)\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\r\n    726         max_queue_size=max_queue_size,\r\n    727         workers=workers,\r\n--> 728         use_multiprocessing=use_multiprocessing)\r\n    729 \r\n    730   def evaluate(self,\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\r\n    322                 mode=ModeKeys.TRAIN,\r\n    323                 training_context=training_context,\r\n--> 324                 total_epochs=epochs)\r\n    325             cbks.make_logs(model, epoch_logs, training_result, ModeKeys.TRAIN)\r\n    326 \r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py in run_one_epoch(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\r\n    121         step=step, mode=mode, size=current_batch_size) as batch_logs:\r\n    122       try:\r\n--> 123         batch_outs = execution_function(iterator)\r\n    124       except (StopIteration, errors.OutOfRangeError):\r\n    125         # TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py in execution_function(input_fn)\r\n     84     # `numpy` translates Tensors to values in Eager mode.\r\n     85     return nest.map_structure(_non_none_constant_value,\r\n---> 86                               distributed_function(input_fn))\r\n     87 \r\n     88   return execution_function\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py in __call__(self, *args, **kwds)\r\n    455 \r\n    456     tracing_count = self._get_tracing_count()\r\n--> 457     result = self._call(*args, **kwds)\r\n    458     if tracing_count == self._get_tracing_count():\r\n    459       self._call_counter.called_without_tracing()\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py in _call(self, *args, **kwds)\r\n    518         # Lifting succeeded, so variables are initialized and we can run the\r\n    519         # stateless function.\r\n--> 520         return self._stateless_fn(*args, **kwds)\r\n    521     else:\r\n    522       canon_args, canon_kwds = \\\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py in __call__(self, *args, **kwargs)\r\n   1821     \"\"\"Calls a graph function specialized to the inputs.\"\"\"\r\n   1822     graph_function, args, kwargs = self._maybe_define_function(args, kwargs)\r\n-> 1823     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\r\n   1824 \r\n   1825   @property\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py in _filtered_call(self, args, kwargs)\r\n   1139          if isinstance(t, (ops.Tensor,\r\n   1140                            resource_variable_ops.BaseResourceVariable))),\r\n-> 1141         self.captured_inputs)\r\n   1142 \r\n   1143   def _call_flat(self, args, captured_inputs, cancellation_manager=None):\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py in _call_flat(self, args, captured_inputs, cancellation_manager)\r\n   1222     if executing_eagerly:\r\n   1223       flat_outputs = forward_function.call(\r\n-> 1224           ctx, args, cancellation_manager=cancellation_manager)\r\n   1225     else:\r\n   1226       gradient_name = self._delayed_rewrite_functions.register()\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py in call(self, ctx, args, cancellation_manager)\r\n    509               inputs=args,\r\n    510               attrs=(\"executor_type\", executor_type, \"config_proto\", config),\r\n--> 511               ctx=ctx)\r\n    512         else:\r\n    513           outputs = execute.execute_with_cancellation(\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\r\n     65     else:\r\n     66       message = e.message\r\n---> 67     six.raise_from(core._status_to_exception(e.code, message), None)\r\n     68   except TypeError as e:\r\n     69     keras_symbolic_tensors = [\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\six.py in raise_from(value, from_value)\r\n\r\nUnknownError:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\r\n\t [[node sequential_1/conv2d_8/Conv2D (defined at C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1751) ]] [Op:__inference_distributed_function_2411]\r\n\r\nFunction call stack:\r\n", "comments": ["@tomergt45,\r\nIn order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!\r\n", "May be you have multiple computations executing simultaneously. Can you kill all python sessions and try again?", "@tomergt45, Did you try @ymodak's workaround to resolve this issue. Thanks!", "@tomergt45, Were you able to resolve this issue. Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 33936, "title": "sigmoid is ignored when calculating loss by calling method model.fit", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Windoiws\r\n\r\nVersion: ('v2.0.0-rc2-26-g64c3d382ca', '2.0.0')\r\n\r\n**Describe the current behavior**\r\n    I got a incorrect loss from history returned by calling model.fit.  You can see the correct and  incorrect result by change parameter \"error \" from my code.\r\n\r\n**Code to reproduce the issue**\r\n```python\r\nimport math\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\nerror = True\r\nn_features = 100\r\nbatch = 2\r\n\r\n\"\"\"\r\nmodel\r\n\"\"\"\r\nx = tf.keras.Input(shape=(n_features,), dtype=tf.float32)\r\nw = tf.Variable([1.0] * n_features)\r\nb = tf.Variable(1.0)\r\nz = tf.reduce_sum(w * x, axis=1, keepdims=True) + b\r\n\r\n\"\"\"\r\nloss is incorrect if error is true\r\n\"\"\"\r\nif error:\r\n    y_ = tf.sigmoid(z)\r\nelse:\r\n    y_ = 1.0 / (1.0 + math.e ** (-z))\r\n\r\nm = tf.keras.Model(inputs=x, outputs=y_)\r\n\r\n\"\"\"\r\nloss\r\n\"\"\"\r\noptimizer=tf.keras.optimizers.SGD(learning_rate=0.001)\r\nloss = tf.keras.losses.BinaryCrossentropy()\r\nm.compile(optimizer = optimizer, loss = loss)\r\n\r\n\"\"\"\r\ntrain dataset\r\n\"\"\"\r\nx = np.array([[1.0 for i in range(n_features)]] * batch, dtype=np.float32)\r\ny = np.array([0.0] * batch, dtype=np.float32)\r\n\r\n\"\"\"\r\nget correct loss\r\n\"\"\"\r\nlogits = m(x)\r\nl = loss(y, logits)\r\n\r\n\"\"\"\r\nget incorrect loss\r\n\"\"\"\r\nhistory = m.fit(x, y)\r\n\r\n\"\"\"\r\nhistory.history['loss'] != l.numpy()\r\n\"\"\"\r\nprint(history.history)\r\nprint(l.numpy())\r\n```", "comments": ["I have tried on colab with TF version 2.0 ,2.1.0-dev20191103 and was able to reproduce the issue.Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/31f5ab164a9db29145e388857c50e05d/untitled327.ipynb). Thanks!", "I have got the same result on macos. Please make sure whether this is a bug. ", "Could replicate this issue with Tf 2.1 and Tf-nighly\r\nPlease find the gist [here](https://colab.sandbox.google.com/gist/gadagashwini/5e918b04d0826e7de1eeeb4a53fa1a6b/untitled467.ipynb). Thanks", "I did some digging. This is an issue since this [commit](https://github.com/tensorflow/tensorflow/commit/03c045e146d441a0db4bd5cc1ecef1517e5c6708)\r\n\r\nSo both loss are not wrong. It's just different on how we make numeric approximation on INF. More specifically the binary_crossentropy loss is:\r\n`bce = y*logp + (1-y)log(1-p)`, and y=0, p=sigmoid(logits)=1, logits=101\r\nThis is theoretically -INF, however in graph mode our computation relies on `tf.nn. sigmoid_cross_entropy_with_logits`, which under their [docstring](https://www.tensorflow.org/api_docs/python/tf/nn/sigmoid_cross_entropy_with_logits) is:\r\n`max(logits, 0) - logits * y + log(1 + exp(-abs(logits)))`\r\nso loss is same as logits, which is 101, and also what history.loss reports.\r\n\r\nOn the other hand, in eager mode our computation relies on:\r\n`output=clip(epsilon, 1-epsilon)`\r\n`y * log(p + epsilon) + (1-y) * log(1-output_epsilon) == log(2*epsilon)`\r\nwhich ends up 15.33, different than above.\r\n\r\n@tornadoyi I wouldn't think this is a huge issue, since this is on very saturated case and approximating how we deal with INF, and it's not how we usually initialize kernels. Let us know if you still have concerns.\r\n", "Closing it for now. Let us know if the previous comments didn't help you :-)", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33936\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33936\">No</a>\n"]}, {"number": 33935, "title": "Remove h5py hard dependency to support python 3.8 on Ubuntu 18.04", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): master\r\n- Are you willing to contribute it (Yes/No): yes\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nAt the moment, I have been able to build tensorflow master on Ubuntu 18.04 with Python 3.8. However, the generated wheel package still could not be installed because `h5py` could not be installed on Ubuntu 18.04 with python 3.8 support.\r\n\r\nNote I am using python 3.8 deadsnake/ppa.\r\n\r\nI checked the dependency maps of pip. It looks like h5py is not a hard dependency as in tensorflow h5py is dynamically loaded.\r\n\r\nIf h5py could be removed from the pip requirement, then I think tensorflow could fully support python 3.8.\r\n\r\n**Will this change the current api? How?**\r\n\r\nn/a\r\n\r\n**Who will benefit with this feature?**\r\n\r\npython 3.8 support for tensorflow\r\n\r\n**Any Other info.**\r\n", "comments": ["The h5py dependency seems to come from keras_applications. Have opened an issue in:\r\n\r\nhttps://github.com/keras-team/keras-applications/issues/147\r\n\r\nto see if it is possible to remove h5py from keras_applications.", "Added a PR:\r\n\r\nhttps://github.com/keras-team/keras-applications/pull/148\r\n\r\nto remove hard dependency of h5py from Keras-applications.", "not just h5py, grpcio is also another dependency that still does not have python 3.8.\r\nMoreover, h5py now has python 3.8 support on windows. not sure about linux."]}, {"number": 33934, "title": "Unable to install tflite-runtime", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nuname -a\r\nLinux matje 4.19.0-5-amd64 #1 SMP Debian 4.19.37-5+deb10u2 (2019-08-08) x86_64 GNU/Linux\r\n- Python version:\r\npython3 --version\r\nPython 3.7.3\r\n- Installed using virtualenv? pip? conda?:\r\npipsi list\r\nPackages and scripts installed through pipsi:\r\n  Package \"pipsi\":\r\n    pipsi\r\n  Package \"virtualenv\":\r\n    virtualenv\r\n\r\n**Describe the problem**\r\nUnable to install tflite-runtime\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\npipsi install tflite_runtime-1.14.0-cp37-cp37m-linux_x86_64.whl \r\nRunning virtualenv with interpreter /root/.local/venvs/pipsi/bin/python3\r\nAlready using interpreter /root/.local/venvs/pipsi/bin/python3\r\nUsing base prefix '/usr'\r\nNew python executable in /root/.local/venvs/tflite-runtime-1.14.0-cp37-cp37m-linux-x86-64.whl/bin/python3\r\nAlso creating executable in /root/.local/venvs/tflite-runtime-1.14.0-cp37-cp37m-linux-x86-64.whl/bin/python\r\nInstalling setuptools, pip, wheel...\r\ndone.\r\nProcessing ./tflite_runtime-1.14.0-cp37-cp37m-linux_x86_64.whl\r\nInstalling collected packages: tflite-runtime\r\nSuccessfully installed tflite-runtime-1.14.0\r\nDid not find any scripts.  Uninstalling.\r\n\r\n", "comments": ["pipsi issue. I solved it by using standard debian package"]}, {"number": 33933, "title": "AttributeError: module 'tensorflow_core.compat.v1.compat' has no attribute 'v1'", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\n**Describe the expected behavior**\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": []}]