[{"number": 28475, "title": "[Java] Eager operations implementation", "body": "Pull request #4/5 for enabling eager execution support in the Java client.\r\n\r\nThis one is implementing the `Operation` interface for eager environments, via `EagerOperation`, and include some additional unit tests.\r\n\r\nCC: @sjamesr ", "comments": ["@karllessard there were some internal lint errors , can you please fix them", "@rthadur : fixed, thank you.\r\n\r\n@sjamesr : do you need to reapprove? I was also looking to add those new lint checks to our list of [compiler rules](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/java/build_defs.bzl) but I did not find their equivalent, I guess those are internal rules only?"]}, {"number": 28474, "title": "Seek help ", "body": "I use tensorflow to train a end-to-end scene text recognition system. The training stage seems good. total_loss gradually declined until convergence. But when I load pretrained weight and use the same network to predict a picture. it reminds me:\r\n###\r\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value recognition_lstm/stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/lstm_cell/bias\r\n###\r\nMeanwhile  I run my demo.py and print(tf.global_variables()).\r\nI found that some variables related to recognition part are not in tf.global_variables()\r\nWhy? Any help will be appreciated.\r\n\r\nHere is my demo.py\r\n#####################################################################\r\n![2019-05-07 20-39-22\u5c4f\u5e55\u622a\u56fe](https://user-images.githubusercontent.com/34428575/57300316-2ae7f600-7109-11e9-87de-89123c56a123.png)\r\n![2019-05-07 20-39-35\u5c4f\u5e55\u622a\u56fe](https://user-images.githubusercontent.com/34428575/57300329-320f0400-7109-11e9-912c-a434dcb658b0.png)\r\n![2019-05-07 20-39-44\u5c4f\u5e55\u622a\u56fe](https://user-images.githubusercontent.com/34428575/57300338-363b2180-7109-11e9-93c6-57a2fbb196c6.png)\r\n", "comments": ["@Polaris-SDU It looks like you haven't used a template to create this issue. Please resubmit your issue using a template from [here](https://github.com/tensorflow/tensorflow/issues/new/choose). We ask users to use the template because it reduces overall time to resolve a new issue by avoiding extra communication to get to the root of the issue. We will close this issue in lieu of the new one you will create from the template. Thank you for your cooperation.\r\n"]}, {"number": 28473, "title": "suppress logging messages in tf2.0", "body": "We have tf.logging.set_verbesity() in tf1.x.\r\n\r\nbut tf2.0 there is not such module, what should we do?", "comments": ["Please have a look on heading Some Highlights under Release 2.0 in this [link](https://github.com/tensorflow/tensorflow/releases) which says tf.logging is not supported in 2.0. Let us know if that resolves the issue. Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 28472, "title": "Low GPU utilization ", "body": "I am running windows 10, core i7-8700 cpu, gtx geforce 1660 ti GPU.\r\nWhen training models, gpu utilization is very low (5-10% at max, sometimes lower).\r\nEven is network is five layers. CPU utilization on the other hand is 30% and above.", "comments": ["@hn2 This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.If you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new/choose). Thanks!\r\n"]}, {"number": 28471, "title": "verbs: fix compilation error", "body": "The forwarded declarations in the header were removed in e7d82e218d538c83cea259cf0f834d406350c911, causing errors in the header file.", "comments": ["@martinwicke Martin, could you help to cherry-pick this into r1.14? We had verbs broken for the last couple of releases, and I hope that it ships with this one.", "It's mightly late, but @bananabowl knows in detail. We've had our share of issues with this release, so maybe it's not too late.", "As we are waiting on a few remaining cpicks, I'll try getting this in for 1.14. ", "> As we are waiting on a few remaining cpicks, I'll try getting this in for 1.14.\r\n\r\nThanks! That's very much appreciated."]}, {"number": 28470, "title": "[nGraph] mkldnn::relu_forward and mkldnn::relu_backward error: expected type-specifier", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian 9.4\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy): N/A\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: dc77be8f92fd7b7ac57d69e35c4d0dbd994bf1a0\r\n- Python version: 3.5.3\r\n- Installed using virtualenv? pip? conda?: virtualenv\r\n- Bazel version (if compiling from source): 0.24.1\r\n- GCC/Compiler version (if compiling from source): gcc (Debian 6.3.0-18+deb9u1) 6.3.0 20170516\r\n- CPU model: Intel(R) Xeon(R) Gold 6130 CPU @ 2.10GHz\r\n\r\n\r\n**Describe the problem**\r\n\r\n```\r\nbazel build --config=opt --config=mkl --config=numa --config=ngraph //tensorflow/tools/pip_package:build_pip_package\r\n```\r\n\r\n\r\n**Any other info / logs**\r\n\r\n```\r\nERROR: /root/.cache/bazel/_bazel_root/5f3660b20527c5657e75cad53b138917/external/ngraph/BUILD.bazel:11:1: C++ compilation of rule '@ngraph//:ngraph_cpu_backend' failed (Exit 1) \r\nexternal/ngraph/src/ngraph/runtime/cpu/mkldnn_emitter.cpp: In member function 'size_t ngraph::runtime::cpu::MKLDNNEmitter::build_relu_forward(const mkldnn::memory::desc&, const mkldnn::memory::desc&)': \r\nexternal/ngraph/src/ngraph/runtime/cpu/mkldnn_emitter.cpp:810:51: error: expected type-specifier\r\n      size_t primitive_index = insert_primitive(new mkldnn::relu_forward(\r\n                                                    ^~~~~~\r\nexternal/ngraph/src/ngraph/runtime/cpu/mkldnn_emitter.cpp: In member function 'size_t ngraph::runtime::cpu::MKLDNNEmitter::build_relu_backward(const mkldnn::memory::desc&, const mkldnn::memory::desc&, const mkldnn::memory::desc&)':\r\nexternal/ngraph/src/ngraph/runtime/cpu/mkldnn_emitter.cpp:828:51: error: expected type-specifier\r\n      size_t primitive_index = insert_primitive(new mkldnn::relu_backward(\r\n                                                    ^~~~~~\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build \r\nUse --verbose_failures to see the command lines of failed build steps. \r\nINFO: Elapsed time: 95.354s, Critical Path: 46.01s \r\nINFO: 1419 processes: 1419 local. \r\nFAILED: Build did NOT complete successfully\r\n```\r\n\r\nr1.14 branch:\r\n\r\n```\r\nERROR: /root/.cache/bazel/_bazel_root/5f3660b20527c5657e75cad53b138917/external/ngraph/BUILD.bazel:11:1: C++ compilation of rule '@ngraph//:ngraph_cpu_backend' failed (Exit 1)\r\nexternal/ngraph/src/ngraph/runtime/cpu/mkldnn_utils.cpp: In function 'std::map<mkldnn::memory::format, const std::__cxx11::basic_string<char> >& ngraph::runtime::cpu::mkldnn_utils::get_mkldnn_format_string_map()':\r\nexternal/ngraph/src/ngraph/runtime/cpu/mkldnn_utils.cpp:162:10: error: 'ldigo_p' is not a member of 'mkldnn::memory::format'\r\n         {memory::format::ldigo_p, \"memory::format::ldigo_p\"},\r\n          ^~~~~~\r\nexternal/ngraph/src/ngraph/runtime/cpu/mkldnn_utils.cpp:164:10: error: 'ldgoi_p' is not a member of 'mkldnn::memory::format'\r\n         {memory::format::ldgoi_p, \"memory::format::ldgoi_p\"},\r\n          ^~~~~~\r\nexternal/ngraph/src/ngraph/runtime/cpu/mkldnn_utils.cpp:168:5: error: no matching function for call to 'std::map<mkldnn::memory::format, const std::__cxx11::basic_string<char> >::map(<brace-enclosed initializer list>)'\r\n     };\r\n     ^\r\nIn file included from /usr/include/c++/6/map:61:0,\r\n                 from external/ngraph/src/ngraph/autodiff/adjoints.hpp:19,\r\n                 from external/ngraph/src/ngraph/node.hpp:32,\r\n                 from external/ngraph/src/ngraph/runtime/cpu/mkldnn_utils.cpp:22:\r\n/usr/include/c++/6/bits/stl_map.h:273:9: note: candidate: template<class _InputIterator> std::map<_Key, _Tp, _Compare, _Alloc>::map(_InputIterator, _InputIterator, const _Compare&, const allocator_type&)\r\n         map(_InputIterator __first, _InputIterator __last,\r\n         ^~~\r\n/usr/include/c++/6/bits/stl_map.h:273:9: note:   template argument deduction/substitution failed:\r\nexternal/ngraph/src/ngraph/runtime/cpu/mkldnn_utils.cpp:168:5: note:   candidate expects 4 arguments, 82 provided\r\n     };\r\n     ^\r\nIn file included from /usr/include/c++/6/map:61:0,\r\n                 from external/ngraph/src/ngraph/autodiff/adjoints.hpp:19,\r\n                 from external/ngraph/src/ngraph/node.hpp:32,\r\n                 from external/ngraph/src/ngraph/runtime/cpu/mkldnn_utils.cpp:22:\r\n/usr/include/c++/6/bits/stl_map.h:256:9: note: candidate: template<class _InputIterator> std::map<_Key, _Tp, _Compare, _Alloc>::map(_InputIterator, _InputIterator)\r\n         map(_InputIterator __first, _InputIterator __last)\r\n         ^~~\r\n/usr/include/c++/6/bits/stl_map.h:256:9: note:   template argument deduction/substitution failed:\r\nexternal/ngraph/src/ngraph/runtime/cpu/mkldnn_utils.cpp:168:5: note:   candidate expects 2 arguments, 82 provided\r\n     };\r\n     ^\r\nIn file included from /usr/include/c++/6/map:61:0,\r\n                 from external/ngraph/src/ngraph/autodiff/adjoints.hpp:19,\r\n                 from external/ngraph/src/ngraph/node.hpp:32,\r\n                 from external/ngraph/src/ngraph/runtime/cpu/mkldnn_utils.cpp:22:\r\n/usr/include/c++/6/bits/stl_map.h:239:9: note: candidate: template<class _InputIterator> std::map<_Key, _Tp, _Compare, _Alloc>::map(_InputIterator, _InputIterator, const allocator_type&)\r\n         map(_InputIterator __first, _InputIterator __last,\r\n         ^~~\r\n/usr/include/c++/6/bits/stl_map.h:239:9: note:   template argument deduction/substitution failed:\r\nexternal/ngraph/src/ngraph/runtime/cpu/mkldnn_utils.cpp:168:5: note:   candidate expects 3 arguments, 82 provided\r\n     };\r\n     ^\r\nIn file included from /usr/include/c++/6/map:61:0,\r\n                 from external/ngraph/src/ngraph/autodiff/adjoints.hpp:19,\r\n                 from external/ngraph/src/ngraph/node.hpp:32,\r\n                 from external/ngraph/src/ngraph/runtime/cpu/mkldnn_utils.cpp:22:\r\n/usr/include/c++/6/bits/stl_map.h:233:7: note: candidate: std::map<_Key, _Tp, _Compare, _Alloc>::map(std::initializer_list<std::pair<const _Key, _Tp> >, const allocator_type&) [with _Key = mkldnn::memory::format; _Tp = const std::__cxx11::basic_string<char>; _Compare = std::less<mkldnn::memory::format>; _Alloc = std::allocator<std::pair<const mkldnn::memory::format, const std::__cxx11::basic_string<char> > >; std::map<_Key, _Tp, _Compare, _Alloc>::allocator_type = std::allocator<std::pair<const mkldnn::memory::format, const std::__cxx11::basic_string<char> > >]\r\n       map(initializer_list<value_type> __l, const allocator_type& __a)\r\n       ^~~\r\n/usr/include/c++/6/bits/stl_map.h:233:7: note:   candidate expects 2 arguments, 82 provided\r\n/usr/include/c++/6/bits/stl_map.h:227:7: note: candidate: std::map<_Key, _Tp, _Compare, _Alloc>::map(std::map<_Key, _Tp, _Compare, _Alloc>&&, const allocator_type&) [with _Key = mkldnn::memory::format; _Tp = const std::__cxx11::basic_string<char>; _Compare = std::less<mkldnn::memory::format>; _Alloc = std::allocator<std::pair<const mkldnn::memory::format, const std::__cxx11::basic_string<char> > >; std::map<_Key, _Tp, _Compare, _Alloc>::allocator_type = std::allocator<std::pair<const mkldnn::memory::format, const std::__cxx11::basic_string<char> > >]\r\n       map(map&& __m, const allocator_type& __a)\r\n       ^~~\r\n/usr/include/c++/6/bits/stl_map.h:227:7: note:   candidate expects 2 arguments, 82 provided\r\n/usr/include/c++/6/bits/stl_map.h:223:7: note: candidate: std::map<_Key, _Tp, _Compare, _Alloc>::map(const std::map<_Key, _Tp, _Compare, _Alloc>&, const allocator_type&) [with _Key = mkldnn::memory::format; _Tp = const std::__cxx11::basic_string<char>; _Compare = std::less<mkldnn::memory::format>; _Alloc = std::allocator<std::pair<const mkldnn::memory::format, const std::__cxx11::basic_string<char> > >; std::map<_Key, _Tp, _Compare, _Alloc>::allocator_type = std::allocator<std::pair<const mkldnn::memory::format, const std::__cxx11::basic_string<char> > >]\r\n       map(const map& __m, const allocator_type& __a)\r\n       ^~~\r\n/usr/include/c++/6/bits/stl_map.h:223:7: note:   candidate expects 2 arguments, 82 provided\r\n/usr/include/c++/6/bits/stl_map.h:219:7: note: candidate: std::map<_Key, _Tp, _Compare, _Alloc>::map(const allocator_type&) [with _Key = mkldnn::memory::format; _Tp = const std::__cxx11::basic_string<char>; _Compare = std::less<mkldnn::memory::format>; _Alloc = std::allocator<std::pair<const mkldnn::memory::format, const std::__cxx11::basic_string<char> > >; std::map<_Key, _Tp, _Compare, _Alloc>::allocator_type = std::allocator<std::pair<const mkldnn::memory::format, const std::__cxx11::basic_string<char> > >]\r\n       map(const allocator_type& __a)\r\n       ^~~\r\n/usr/include/c++/6/bits/stl_map.h:219:7: note:   candidate expects 1 argument, 82 provided\r\n/usr/include/c++/6/bits/stl_map.h:211:7: note: candidate: std::map<_Key, _Tp, _Compare, _Alloc>::map(std::initializer_list<std::pair<const _Key, _Tp> >, const _Compare&, const allocator_type&) [with _Key = mkldnn::memory::format; _Tp = const std::__cxx11::basic_string<char>; _Compare = std::less<mkldnn::memory::format>; _Alloc = std::allocator<std::pair<const mkldnn::memory::format, const std::__cxx11::basic_string<char> > >; std::map<_Key, _Tp, _Compare, _Alloc>::allocator_type = std::allocator<std::pair<const mkldnn::memory::format, const std::__cxx11::basic_string<char> > >]\r\n       map(initializer_list<value_type> __l,\r\n       ^~~\r\n/usr/include/c++/6/bits/stl_map.h:211:7: note:   candidate expects 3 arguments, 82 provided\r\n/usr/include/c++/6/bits/stl_map.h:196:7: note: candidate: std::map<_Key, _Tp, _Compare, _Alloc>::map(std::map<_Key, _Tp, _Compare, _Alloc>&&) [with _Key = mkldnn::memory::format; _Tp = const std::__cxx11::basic_string<char>; _Compare = std::less<mkldnn::memory::format>; _Alloc = std::allocator<std::pair<const mkldnn::memory::format, const std::__cxx11::basic_string<char> > >]\r\n       map(map&& __x)\r\n       ^~~\r\n/usr/include/c++/6/bits/stl_map.h:196:7: note:   candidate expects 1 argument, 82 provided\r\n/usr/include/c++/6/bits/stl_map.h:185:7: note: candidate: std::map<_Key, _Tp, _Compare, _Alloc>::map(const std::map<_Key, _Tp, _Compare, _Alloc>&) [with _Key = mkldnn::memory::format; _Tp = const std::__cxx11::basic_string<char>; _Compare = std::less<mkldnn::memory::format>; _Alloc = std::allocator<std::pair<const mkldnn::memory::format, const std::__cxx11::basic_string<char> > >]\r\n       map(const map& __x)\r\n       ^~~\r\n/usr/include/c++/6/bits/stl_map.h:185:7: note:   candidate expects 1 argument, 82 provided\r\n/usr/include/c++/6/bits/stl_map.h:174:7: note: candidate: std::map<_Key, _Tp, _Compare, _Alloc>::map(const _Compare&, const allocator_type&) [with _Key = mkldnn::memory::format; _Tp = const std::__cxx11::basic_string<char>; _Compare = std::less<mkldnn::memory::format>; _Alloc = std::allocator<std::pair<const mkldnn::memory::format, const std::__cxx11::basic_string<char> > >; std::map<_Key, _Tp, _Compare, _Alloc>::allocator_type = std::allocator<std::pair<const mkldnn::memory::format, const std::__cxx11::basic_string<char> > >]\r\n       map(const _Compare& __comp,\r\n       ^~~\r\n/usr/include/c++/6/bits/stl_map.h:174:7: note:   candidate expects 2 arguments, 82 provided\r\n/usr/include/c++/6/bits/stl_map.h:162:7: note: candidate: std::map<_Key, _Tp, _Compare, _Alloc>::map() [with _Key = mkldnn::memory::format; _Tp = const std::__cxx11::basic_string<char>; _Compare = std::less<mkldnn::memory::format>; _Alloc = std::allocator<std::pair<const mkldnn::memory::format, const std::__cxx11::basic_string<char> > >]\r\n       map()\r\n       ^~~\r\n/usr/include/c++/6/bits/stl_map.h:162:7: note:   candidate expects 0 arguments, 82 provided\r\nexternal/ngraph/src/ngraph/runtime/cpu/mkldnn_utils.cpp: In function 'mkldnn::memory::desc ngraph::runtime::cpu::mkldnn_utils::rotate_blocked_md(const mkldnn::memory::desc&, const ngraph::AxisVector&)':\r\nexternal/ngraph/src/ngraph/runtime/cpu/mkldnn_utils.cpp:469:26: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n     for (size_t i = 0; i < in.data.ndims; i++)\r\n                        ~~^~~~~~~~~~~~~~~\r\nexternal/ngraph/src/ngraph/runtime/cpu/mkldnn_utils.cpp: In function 'mkldnn::memory::desc ngraph::runtime::cpu::mkldnn_utils::squeeze_blocked_md(const mkldnn::memory::desc&, ngraph::AxisVector&)':\r\nexternal/ngraph/src/ngraph/runtime/cpu/mkldnn_utils.cpp:492:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n     if (in.data.ndims <= axis_list.size())\r\n         ~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~\r\nexternal/ngraph/src/ngraph/runtime/cpu/mkldnn_utils.cpp:513:33: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n     for (size_t i = 0, j = 0; i < in.data.ndims; i++)\r\n                               ~~^~~~~~~~~~~~~~~\r\nexternal/ngraph/src/ngraph/runtime/cpu/mkldnn_utils.cpp: In function 'mkldnn::memory::desc ngraph::runtime::cpu::mkldnn_utils::expand_blocked_md(const mkldnn::memory::desc&, ngraph::AxisVector&)':\r\nexternal/ngraph/src/ngraph/runtime/cpu/mkldnn_utils.cpp:546:33: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n     for (size_t i = 0, j = 0; j < md.ndims; j++)\r\n                               ~~^~~~~~~~~~\r\nexternal/ngraph/src/ngraph/runtime/cpu/mkldnn_utils.cpp:567:42: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n                 for (size_t idx = 0; idx < in.data.ndims; idx++)\r\n                                      ~~~~^~~~~~~~~~~~~~~\r\nexternal/ngraph/src/ngraph/runtime/cpu/mkldnn_utils.cpp: In function 'bool ngraph::runtime::cpu::mkldnn_utils::is_mkldnn_padded_layout(const mkldnn::memory::desc&, const ngraph::AxisVector&)':\r\nexternal/ngraph/src/ngraph/runtime/cpu/mkldnn_utils.cpp:630:26: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n     for (size_t i = 0; i < in.data.ndims; i++)\r\n                        ~~^~~~~~~~~~~~~~~\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 108.907s, Critical Path: 44.36s\r\nINFO: 3128 processes: 3128 local.\r\nFAILED: Build did NOT complete successfully\r\n```", "comments": ["Gentle ping @avijit-nervana", "Ping @agramesh1 as well; looks like `ldigo_p` got removed when upgrading MKLDNN to 0.18.", "@byronyi There are two ways to use nGraph with TensorFlow - one is to compile nGraph with TensorFlow build - that you are attempting and the other is to build nGraph only and dynamically loading when running TensorFlow. The second approach is much easier to build and use. See the `Build Option 2` here: https://github.com/tensorflow/ngraph-bridge#option-2-build-ngraph-bridge-with-binary-tensorflow-installation\r\n\r\nPlease try that and let us know if you run into any issues.\r\n", "> @byronyi There are two ways to use nGraph with TensorFlow - one is to compile nGraph with TensorFlow build - that you are attempting and the other is to build nGraph only and dynamically loading when running TensorFlow. The second approach is much easier to build and use. See the `Build Option 2` here: https://github.com/tensorflow/ngraph-bridge#option-2-build-ngraph-bridge-with-binary-tensorflow-installation\r\n> \r\n> Please try that and let us know if you run into any issues.\r\n\r\nDoes that mean the Bazel option with the `--opt=ngraph` no longer be supported? It might better be removed entirely if so.\r\n\r\nWe build nGraph with TF as we did customize our internal TF build. The binary approach isn't always the best choice as TF does not provide a stable ABI now (it's moving to that goal as in the [modular TF RFC](https://github.com/tensorflow/community/pull/77) but it's gonna take some time to be implemented). See https://github.com/tensorflow/tensorflow/issues/27067 for a potential problem.", "@byronyi \r\n\r\nIs this issue present?\r\nIf yes, please update the status with above suggestion.\r\nIs no, could you close it?", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/28470\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/28470\">No</a>\n", "The nGraph build option seems to be removed and migrated to a separate package. Closing for now.", "@byronyi \r\n\r\nThank you very much!"]}, {"number": 28469, "title": "TFLite: please don't force copy outputs", "body": "**System information**\r\n- TensorFlow version (you are using): **1.3.1**\r\n- Are you willing to contribute it (Yes/No): **Yes**\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nCurrently, TFLite insistes that the [outputs](https://github.com/alexcohn/tensorflow/blob/master/tensorflow/lite/java/src/main/java/org/tensorflow/lite/NativeInterpreterWrapper.java#L123) must not be empty, and copies the output tensor after each run to the array or ByteBuffer we provide in the *outputs* Map. This copy may come with a significant performance price, and may easily be avoided. \r\n\r\nInstead of providing the output buffer, the app can simply call\r\n\r\n    interpreter.runForMultipleInputsOutputs(arrayOfInputs, null);\r\n    drawResults(interpreter.getOutputTensor(0).buffer());\r\n\r\n**Will this change the current api? How?**\r\n\r\n1. second parameter of [**Interpreter.runForMultipleInputsOutputs()**](https://github.com/alexcohn/tensorflow/blob/master/tensorflow/lite/java/src/main/java/org/tensorflow/lite/Interpreter.java#L273) will become **Nullable**.\r\n2. **NativeInterpreterWrapper.run()** will not [throw](https://github.com/alexcohn/tensorflow/blob/master/tensorflow/lite/java/src/main/java/org/tensorflow/lite/NativeInterpreterWrapper.java#L123) when it gets **null** or empty **output**.\r\n3. The [copy cycle](https://github.com/alexcohn/tensorflow/blob/master/tensorflow/lite/java/src/main/java/org/tensorflow/lite/NativeInterpreterWrapper.java#L160) in the epilogue of **NativeInterpreterWrapper.run()** will not be invoked if **outputs == null**.\r\n4. [Tensor.buffer()](https://github.com/alexcohn/tensorflow/blob/master/tensorflow/lite/java/src/main/java/org/tensorflow/lite/Tensor.java#L303) will become **public**.\r\n\r\n**Who will benefit with this feature?**\r\n\r\nWhen I don't need a persistent copy of inference outputs, and only have some quick things to do with these buffers, this approach can save memory and CPU cycles.\r\n\r\n**Any Other info.**\r\n\r\nI have run tests with mobileNet_v1 on Android arm64 device from the **master** branch with the above patches, and have encountered no problems.", "comments": ["In general this seems fine. Is the problem that you don't want to copy all outputs? Or you don't want to copy *any* outputs. If the former, I have a slight preference for not exposing `Tensor.buffer()` yet, instead exposing `Tensor.copyTo()`.\r\n\r\nJust curious, are you using a `ByteBuffer` in your output? Or a multi-dimensional array? The latter can be extremely slow for cases where the inner dimension is small (e.g., an image).", "I use DirectByteBuffer for all tensors, it is both faster, and easier to manage. IMO, Java multi-dimensional arrays were born in sin, and should be avoided at any cost.\r\n\r\nI don't understand why I need an extra copy of the output buffer, that's why I would prefer to have `Tensor.buffer()` exposed. Unless there are bad implications. I would be glad to learn about that: I have similar procedure in my C++ implementation, and if there is a problem with this, same problem may haunt my C++ lib.\r\n\r\nIn my case, `copyTo()` will not really help: my `drawResults()` takes FloatBuffer and converts it to bitmap. It is synchronous, and fast. I never need to keep these floats.\r\n\r\nThere are natural expectations when `interpreter.getOutputTensor(n).buffer()` is used. E.g. this should be over when the next `interpreter.run()` is called."]}, {"number": 28468, "title": "Issue in using Tensorflow lite GPU delegate on iOS device", "body": "\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.13.6\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:iPhone X\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (use command below): 1.13.1\r\n- Python version: 3.7.3\r\n- Bazel version (if compiling from source): NA\r\n- GCC/Compiler version (if compiling from source): NA\r\n- CUDA/cuDNN version: NA\r\n- GPU model and memory: NA\r\n\r\n**Describe the current behavior**\r\nI am trying to benchmark a custom TF lite model on Android and iOS devices with the GPU delegate option. On the Android device(Google Pixel 3), I am able to successfully benchmark the model using the Tensorflow provided benchmark utility (https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/tools/benchmark).\r\n\r\nRunning the same model on iOS device (iPhone X) without GPU delegate option works fine. However when I try to run it with the GPU delegate option I observe the following error:\r\n\r\n**tflite_camera_example[572:134773] [DYMTLInitPlatform] platform initialization successful\r\nLoaded model 1resolved reporter\r\ntflite_camera_example[572:134606] Metal GPU Frame Capture Enabled\r\ntflite_camera_example[572:134606] Metal API Validation Enabled\r\n**depth_multiplier 16 != weights output channels 1**\r\nNode number 53 (MetalGpuDelegate) failed to prepare.\r\nNode number 53 (MetalGpuDelegate) failed to prepare.\r\nFailed to allocate tensors!\r\ntflite_camera_example[572:134606] [MC] System group container for systemgroup.com.apple.configurationprofiles path is /private/var/containers/Shared/SystemGroup/systemgroup.com.apple.configurationprofiles\r\ntflite_camera_example[572:134606] [MC] Reading from public effective user settings.\r\n(lldb)** \r\n\r\nI am modifying the iOS Tensorflowlite sample camera app(https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/examples/ios/camera) as per the instructions in this video from Tensorflow : https://www.youtube.com/watch?v=a5H4Zwjp49c&feature=youtu.be to evaluate the GPU delegate option.\r\n\r\n**Describe the expected behavior**\r\nShould be able to run the inference using the GPU delegate on iOS with the same model that worked on android\r\n\r\n**Code to reproduce the issue**\r\n\r\n**Other info / logs**\r\n", "comments": ["Any update on this issue? I am also facing the same issue. Need urgent help!", "[commit](https://github.com/tensorflow/tensorflow/commit/403417fdc85650181f894ee0aa0fb85dfa75fea4) should resolve the issue.\r\n@manoharyes on which version do you have the issue?", "@NikolayChirkov I am not building TF-lite GPU delegate from source and using it . I am modifying the TF-lite iOS camera example app to evaluate the GPU delegate, which uses pod file based method to fetch the TF-lite GPU delegate library . In the pod file both the options namely : pod 'TensorFlowLiteGpuExperimental' and pod 'TensorFlowLiteGpuExperimental', '0.0.1' \u00a0resulted in the same error described in this issue \r\n\u00a0\r\nCould you share the instructions for building the TF-lite GPU delegate for iOS ? \r\nAny reference to sample iOS application/example that uses this prebuilt TF-lite GPU delegate would also be really useful.", "Yes, I saw a similar issue after using my own built tensorflow_lite_gpu.framework.\r\nI built it at latest master branch and have to fix minor errors in metal_delegate.mm. Then built it using \r\n`bazel build --apple_platform_type ios --cpu=ios_arm64 --cxxopt=-std=c++14 -c opt --copt -DTFLITE_GPU_BINARY_RELEASE --copt -fvisibility=hidden --linkopt -s tensorflow/lite/delegates/gpu:libtensorflowlite_gpu_metal.so`\r\nBuilt succeed, but when I use it in my app, I get error: Error initialization of input buffer converter", "\r\nI was able to build the latest code of TF-lite GPU delegate for iOS . With this TF-lite GPU delegate library the earlier error (depth_multiplier 16 != weights output channels 1) is no longer there. However when I try to run GPU based inference on my custom model the following error is observed :\r\n\r\n**Initialized TensorFlow Lite runtime.\r\nCreated TensorFlow Lite delegate for Metal.\r\nMetal GPU Frame Capture Enabled\r\nMetal API Validation Enabled\r\nExecution of the command buffer was aborted due to an error during execution. Caused GPU Hang Error (IOAF code 3)**\r\n\r\n@NikolayChirkov  : Any suggestions on how to address this issue? \r\n\r\n@tsujie : I faced a similar error when I ran GPU based inference on iOS devices with SW version below 12.0, but not on devices with version greater than or equal to 12.0\r\n", "@tsujie Can build binary for ios with universal binary at once?", "@weinixuehao I need to built libmetal_delegate.a firstly, then run ios universal build script to create the final framework", "@tsujie if so you need to build libmetal_delegate several time for x86 armv7 arm64 ... ?\r\nDo i uderstand correctness ?", "@tsujie arm64 x86_64 compiled successfully but armv7s is failed\r\n![image](https://user-images.githubusercontent.com/17869361/60005742-af82d980-96a1-11e9-9405-d85576e9796f.png)\r\n", "@weinixuehao I only built arm64 & x86_64 ", "@tsujie \r\n![image](https://user-images.githubusercontent.com/17869361/60074748-3b563d80-9756-11e9-884f-503b91da1c81.png)\r\nThis issue has fixed?", "That's weird. Looking into.", "@weinixuehao I built at latest master branch. It is working now. ", "@tsujie \r\nWhat date you built?  My is at latest master too.", "@tsujie @NikolayChirkov\r\n![image](https://user-images.githubusercontent.com/17869361/60144984-1960c780-97f7-11e9-8925-5b64bfff211a.png)\r\nMay be this reason which not support simulator\r\n![image](https://user-images.githubusercontent.com/17869361/60145098-83796c80-97f7-11e9-89b3-044387240c7d.png)\r\n![image](https://user-images.githubusercontent.com/17869361/60145104-8b391100-97f7-11e9-8129-dc7da784a1dc.png)\r\nBoth print outputs is null\r\n\r\nps:\r\nReal device is ok!\r\n", "> @NikolayChirkov I am not building TF-lite GPU delegate from source and using it . I am modifying the TF-lite iOS camera example app to evaluate the GPU delegate, which uses pod file based method to fetch the TF-lite GPU delegate library . In the pod file both the options namely : pod 'TensorFlowLiteGpuExperimental' and pod 'TensorFlowLiteGpuExperimental', '0.0.1' \u00a0resulted in the same error described in this issue\r\n> \u00a0\r\n> Could you share the instructions for building the TF-lite GPU delegate for iOS ?\r\n> Any reference to sample iOS application/example that uses this prebuilt TF-lite GPU delegate would also be really useful.\r\n@manoharyes\r\nIs this solved?Were you able to run it with GPU on iOS device?\r\nI am also facing the same issue!"]}, {"number": 28467, "title": "DOC get_data_files: Remove \"not\"", "body": "", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F28467) for more info**.\n\n<!-- need_sender_cla -->", "@rvinas Please sign CLA in order to proceed with next steps. Thank you !", "I signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F28467) for more info**.\n\n<!-- ok -->", "@sguada can you please review this PR ?  "]}, {"number": 28466, "title": "tf.distribute behave inconsistent when using custom loss(BUG?)", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): win10\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): 2.0 alpha gpu\r\n- Python version: 3.7\r\n\r\n**Describe the current behavior**\r\nUPDATE:\r\nI tried the latest nightly building, still no luck and now more error info showed:\r\n```\r\ntensorflow.python.framework.errors_impl.InternalError: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run DeleteIterator: No unary variant device copy function found for direction: 1 and Variant type_index: class tensorflow::data::IteratorResource::Deleter [Op:DeleteIterator]\r\n```\r\n\r\n\r\n\r\n**Below is on alpha 2.0 gpu**\r\nI'm trying to transfer my tf1.0 code to 2.0 these days. And want to make use of the distribution strategy to optimize the multi-gpu training scheme. Simply description here:\r\n\r\n> My goal is adopting a complex loss that computed by args more than just (y_true, y_pred) in a distribution manner\r\n\r\nMy older version implementation of the custom-loss is following  [@fchollet suggestion](https://github.com/tensorflow/addons/issues/26#issuecomment-473139603) by using add_loss/add_metric function.However if i want to use tf.distribution, the add_loss way is not allowed:\r\n```\r\nValueError: We currently do not support compiling the model with distribution strategy if `model.add_loss(tensor)` or `model.add_metric(tensor)` has been called.\r\n```\r\nSo, I am using another working-around from [here](https://towardsdatascience.com/advanced-keras-constructing-complex-custom-losses-and-metrics-c07ca130a618)\r\n\r\nA working simplified code is:\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.python import keras\r\nfrom tensorflow.python.keras import layers as KL\r\nfrom tensorflow.python.keras import models as KM\r\nimport numpy as np\r\nprint(tf.__version__)\r\n\r\ndef my_custom_loss_wrapper(input_weight):\r\n    def real_loss(y_true, y_pred):\r\n        # expand the out put of binary_crossentropy(64,64) to (64,64,1) to match the shape of input_weight\r\n        bce_loss = tf.expand_dims(keras.losses.binary_crossentropy(y_true, y_pred), axis=-1)\r\n        return bce_loss * input_weight\r\n\r\n    return real_loss\r\n\r\nfake_img = np.ones((64, 64, 3))\r\nfake_label = np.ones((64, 64, 1))\r\nfake_weight = np.ones((64, 64, 1)) * 5\r\ndataset = tf.data.Dataset.from_tensors(((fake_img, fake_weight), fake_label)).repeat(100).batch(10)\r\n\r\nimg_input = KL.Input(shape=(64, 64, 3))\r\nweight_input = KL.Input(shape=(64, 64, 1))\r\nx = KL.Conv2D(32, (3, 3), strides=2, padding=\"same\")(img_input)\r\nx = KL.Conv2DTranspose(32, (3, 3), strides=2, padding=\"same\")(x)\r\nmask = KL.Conv2D(1, (1, 1), strides=1, activation=\"sigmoid\", name=\"mask\")(x)\r\nmodel = KM.Model(inputs=[img_input, weight_input], outputs=mask)\r\nmodel.compile(\r\n    loss=my_custom_loss_wrapper(weight_input),  # return a function real_loss(y_true, y_pred)\r\n    optimizer='sgd'\r\n)\r\nmodel.fit(dataset, epochs=1000)\r\n```\r\nSince above code is working good, let's enable the distribution strategy:\r\n```\r\nstrategy = tf.distribute.MirroredStrategy(\r\n    cross_device_ops=tf.distribute.HierarchicalCopyAllReduce()\r\n)\r\nwith strategy.scope():\r\n    img_input = KL.Input(shape=(64, 64, 3))\r\n    weight_input = KL.Input(shape=(64, 64, 1))\r\n    x = KL.Conv2D(32, (3, 3), strides=2, padding=\"same\")(img_input)\r\n    x = KL.Conv2DTranspose(32, (3, 3), strides=2, padding=\"same\")(x)\r\n    mask = KL.Conv2D(1, (1, 1), strides=1, activation=\"sigmoid\", name=\"mask\")(x)\r\n    model = KM.Model(inputs=[img_input, weight_input], outputs=mask)\r\n    model.compile(\r\n        # loss=\"mse\",\r\n        loss=my_custom_loss_wrapper(weight_input),  # return a function real_loss(y_true, y_pred)\r\n        optimizer='sgd'\r\n    )\r\nmodel.fit(dataset, epochs=1000)\r\n```\r\nNo luck this time:\r\n```\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: You must feed a value for placeholder tensor 'input_2' with dtype float and shape [?,64,64,1]\r\n\t [[{{node input_2}}]]\r\n\t [[mask_sample_weights_1/_11]] [Op:__inference_keras_scratch_graph_1609]\r\n```\r\nI was trying to debug this by trace the _**actual_inputs**_ values in this [file ](https://github.com/tensorflow/tensorflow/blob/f7e3da0d6a284399ef2d6e79f4dbe61b32ae70f5/tensorflow/python/keras/engine/training_arrays.py), however it's exactly same with the non-distributed version. And the training engine just cannot get the \"input_2\". Which I double checked do have values match the type and shape in  _**actual_inputs**_ .\r\n\r\nMy very personal guess is that in the strategy scope, the context somehow nested and the feeding data process therefore failed when custom loss involved with another layer of the model like in my example \"input_weight\" except y_true and y_pred. If i don use the input_weight values in the function, the other code can still work.\r\n```\r\ndef my_custom_loss_wrapper(input_weight):\r\n    def real_loss(y_true, y_pred):\r\n        # expand the out put of binary_crossentropy(64,64) to (64,64,1) to match the shape of input_weight\r\n        bce_loss = tf.expand_dims(keras.losses.binary_crossentropy(y_true, y_pred), axis=-1)\r\n        return bce_loss\r\n    return real_loss\r\n```\r\nI dont know if this the reason why add_loss not supported by tf.distribution now. Any thought is appreciated!\r\n\r\n\r\n**Describe the expected behavior**\r\nCustom loss with multiple input layer works consistent in both distribute and non-distribute env.\r\n\r\n\r\n\r\n\r\n", "comments": ["@ziyigogogo I ran the below codes and respective log is attached.\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.python import keras\r\nfrom tensorflow.python.keras import layers as KL\r\nfrom tensorflow.python.keras import models as KM\r\nimport numpy as np\r\nprint(tf.__version__)\r\n\r\ndef my_custom_loss_wrapper(input_weight):\r\n    def real_loss(y_true, y_pred):\r\n        # expand the out put of binary_crossentropy(64,64) to (64,64,1) to match the shape of input_weight\r\n        bce_loss = tf.expand_dims(keras.losses.binary_crossentropy(y_true, y_pred), axis=-1)\r\n        return bce_loss * input_weight\r\n\r\n    return real_loss\r\n\r\nfake_img = np.ones((64, 64, 3))\r\nfake_label = np.ones((64, 64, 1))\r\nfake_weight = np.ones((64, 64, 1)) * 5\r\ndataset = tf.data.Dataset.from_tensors(((fake_img, fake_weight), fake_label)).repeat(100).batch(10)\r\nstrategy = tf.distribute.MirroredStrategy(\r\n    cross_device_ops=tf.distribute.HierarchicalCopyAllReduce()\r\n)\r\nwith strategy.scope():\r\n    img_input = KL.Input(shape=(64, 64, 3))\r\n    weight_input = KL.Input(shape=(64, 64, 1))\r\n    x = KL.Conv2D(32, (3, 3), strides=2, padding=\"same\")(img_input)\r\n    x = KL.Conv2DTranspose(32, (3, 3), strides=2, padding=\"same\")(x)\r\n    mask = KL.Conv2D(1, (1, 1), strides=1, activation=\"sigmoid\", name=\"mask\")(x)\r\n    model = KM.Model(inputs=[img_input, weight_input], outputs=mask)\r\n    model.compile(\r\n        # loss=\"mse\",\r\n        loss=my_custom_loss_wrapper(weight_input),  # return a function real_loss(y_true, y_pred)\r\n        optimizer='sgd'\r\n    )\r\nmodel.fit(dataset, epochs=1000)\r\n```\r\n\r\nLog: 2.0.0-alpha0\r\nW0510 06:40:37.825564 139900658984832 training_utils.py:1353] Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-3-fe0c49a72aee> in <module>()\r\n     33         optimizer='sgd'\r\n     34     )\r\n---> 35 model.fit(dataset, epochs=1000)\r\n\r\n23 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py in add_n(inputs, name)\r\n   2781   \"\"\"\r\n   2782   if not inputs or not isinstance(inputs, (list, tuple)):\r\n-> 2783     raise ValueError(\"inputs must be a list of at least one \"\r\n   2784                      \"Tensor/IndexedSlices with the same dtype and shape\")\r\n   2785   inputs = ops.convert_n_to_tensor_or_indexed_slices(inputs)\r\n\r\nValueError: inputs must be a list of at least one Tensor/IndexedSlices with the same dtype and shape\r\n\r\n\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.python import keras\r\nfrom tensorflow.python.keras import layers as KL\r\nfrom tensorflow.python.keras import models as KM\r\nimport numpy as np\r\nprint(tf.__version__)\r\n\r\ndef my_custom_loss_wrapper(input_weight):\r\n    def real_loss(y_true, y_pred):\r\n        # expand the out put of binary_crossentropy(64,64) to (64,64,1) to match the shape of input_weight\r\n        bce_loss = tf.expand_dims(keras.losses.binary_crossentropy(y_true, y_pred), axis=-1)\r\n        return bce_loss\r\n    return real_loss\r\nfake_img = np.ones((64, 64, 3))\r\nfake_label = np.ones((64, 64, 1))\r\nfake_weight = np.ones((64, 64, 1)) * 5\r\ndataset = tf.data.Dataset.from_tensors(((fake_img, fake_weight), fake_label)).repeat(100).batch(10)\r\nstrategy = tf.distribute.MirroredStrategy(\r\n    cross_device_ops=tf.distribute.HierarchicalCopyAllReduce()\r\n)\r\nwith strategy.scope():\r\n    img_input = KL.Input(shape=(64, 64, 3))\r\n    weight_input = KL.Input(shape=(64, 64, 1))\r\n    x = KL.Conv2D(32, (3, 3), strides=2, padding=\"same\")(img_input)\r\n    x = KL.Conv2DTranspose(32, (3, 3), strides=2, padding=\"same\")(x)\r\n    mask = KL.Conv2D(1, (1, 1), strides=1, activation=\"sigmoid\", name=\"mask\")(x)\r\n    model = KM.Model(inputs=[img_input, weight_input], outputs=mask)\r\n    model.compile(\r\n        # loss=\"mse\",\r\n        loss=my_custom_loss_wrapper(weight_input),  # return a function real_loss(y_true, y_pred)\r\n        optimizer='sgd'\r\n    )\r\nmodel.fit(dataset, epochs=1000)\r\n```\r\n\r\nLog:\r\n2.0.0-alpha0\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-4-610a09e59654> in <module>()\r\n     19     cross_device_ops=tf.distribute.HierarchicalCopyAllReduce()\r\n     20 )\r\n---> 21 with strategy.scope():\r\n     22     img_input = KL.Input(shape=(64, 64, 3))\r\n     23     weight_input = KL.Input(shape=(64, 64, 1))\r\n\r\n3 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py in _wrong_strategy_scope(strategy, context)\r\n    117     raise RuntimeError(\r\n    118         \"Mixing different tf.distribute.Strategy objects: %s is not %s\" %\r\n--> 119         (context.strategy, strategy))\r\n    120 \r\n    121 \r\n\r\nRuntimeError: Mixing different tf.distribute.Strategy objects: <tensorflow.python.distribute.mirrored_strategy.MirroredStrategy object at 0x7f3d2273c7b8> is not <tensorflow.python.distribute.mirrored_strategy.MirroredStrategy object at 0x7f3c7f68b358>\r\n", "@muddham  The fact is that I just cannot make the custom loss work on 2.0 alpha in any way. And the latest tf nightly enabled the add_loss& add_metric again. So im using a add_loss way to achieve my target.\r\nSo for me at least, the latest version meets my needs. \r\nHowever, there are still bugs on the thing I reported: you can make the custom_loss_function work ONLY WITHOUT distribute strategy.  This is kinda inconsistent, so if the custom_loss_function is not recommend compared with the add_loss way, TF team should throw some warning messages.", "Question: What is the code that fails? Does it fail without a custom loss?\r\n\r\nAlso, does it still fail if you remove the \"cross_device_ops=tf.distribute.HierarchicalCopyAllReduce()\" line? We are switching to NCCL, and are planning  to deprecate it.\r\n", "> Question: What is the code that fails? Does it fail without a custom loss?\r\n> \r\n> Also, does it still fail if you remove the \"cross_device_ops=tf.distribute.HierarchicalCopyAllReduce()\" line? We are switching to NCCL, and are planning to deprecate it.\r\n\r\nSorry for the late response, since I am moving to use tf2.0 beta, which added support for add_loss() so that my problem is addressed. By the way, as for \"cross_device_ops=tf.distribute.HierarchicalCopyAllReduce()\", i have machines on both windows and linux, and on windows NCCL is not working so i used HierarchicalCopyAllReduce(). And i dont think this is related.", "Thanks for the update! I will close the issue then since it seems addressed. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=28466\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=28466\">No</a>\n"]}, {"number": 28465, "title": "Poor performance while writing custom layers", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- Windows 10\r\n- Tensorflow installed from pre-built binary\r\n- TensorFlow version: 1.13.1\r\n- Python: 3.6.6\r\n- CUDA/cuDNN version: 10.0/7.1\r\n- GPU model and memory: GTX 960M/4GB\r\n- CPU: Intel i7 6700HQ\r\n\r\n**Describe the current behavior**\r\nI recently had the requirement to code a slightly different version of the convolution layer. The first choice for me was to build a custom layer using your article [here](https://www.tensorflow.org/tutorials/eager/custom_layers). I coded a naive version of 2D Convolution using a O(n^4) code just for basic prototyping. I used a lot of low-level operations like tf.ones, tf.concat, tf.tile, tf.reduce_sum and matrix slicing. To measure inference time I decided to call the object manually by supplying a (256, 256, 3) image as input to the overridden call() method. However, before calling I  included a tf.enable_eager_execution() call at the starting of the code by mistake. The code takes 50 seconds to execute the code on GPU(I monitored the GPU usage so I know it is using the GPU indeed). The peculiar part is that when I omit the tf.enable_eager_execution() it seems to run on the CPU rather inefficiently, in about 980 seconds. To have a yardstick for CPU execution, I re-wrote the same O(n^4) code using numpy exclusively and it takes just 210 seconds.\r\n\r\nI also included the custom layer as part of a tf.keras.model and simply printed the model summary. The issue in this scenario is that it seems to execute the entire call routine to print the summary which essentially means that it takes 980 seconds to just print the summary!\r\n\r\n**Describe the expected behavior**\r\nThere are a couple of questions I have:\r\n\r\n1. While I realize that numpy and tensorflow as two completely different libraries, should the disparity in performance be this much? I am overriding the __init__, build and call functions while making the appropriate super calls as per your article. Am I doing something wrong?\r\n2. Do custom layers use the CPU by default? I also tried forcing it by including a with tf.device(\"/gpu:0\") call but that doesn't seem to help at all.\r\n\r\nI realize that it might be more efficient to code the convolution by adding a custom op but I want to avoid that in the prototyping stage as much as possible.\r\n\r\n**Code to reproduce the issue**\r\nI cannot reveal the code for proprietary reasons but I could furnish a similar version if need be.\r\n\r\nAny help in this regard would be much appreciated. \r\n", "comments": ["It will be great if you can provide us with the minimal code snippet which can replicate the scenario. Thanks!\r\n", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 28464, "title": " Where is the entry point for Receiver to receive Tensor using GRPC?", "body": "I'm a student trying to understand how distributed TensorFlow transmits Tensor through GRPC. I have now found that the Sender is issuing a generic asynchronous request by calling the `IssueRequest` tool function(as listed below), but how does the Receiver respond to this request? Where is the entry point?\r\n\r\n>   // file path: \\tensorflow-r1.12\\tensorflow\\core\\distributed_runtime\\rpc\\grpc_remote_worker.cc\r\n  // Utility method for issuing a generic asynchronous request. The\r\n  // given callback, `done`, will be called when the RPC completes.\r\n  void IssueRequest(const protobuf::Message* request, TensorResponse* response,\r\n                    const ::grpc::string& method, StatusCallback done,\r\n                    CallOptions* call_opts = nullptr) {\r\n        new RPCState<TensorResponse>(&stub_, cq_, method, *request, response,\r\n                                     std::move(done), call_opts);\r\n  }\r\n\r\nThanks!\r\n", "comments": ["This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged//tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n"]}, {"number": 28463, "title": "Why does TF run ops in the build phase?", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information** \r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): source \r\n- TensorFlow version:  tf-nightly-1.13.1\r\n- Python version: python 3\r\n- Installed using virtualenv? pip? conda?:  pip\r\n- Bazel version (if compiling from source):  0.23.2\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10.0/7\r\n- GPU model and memory: 1080ti\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nAdd logging to the code:\r\n\r\n```cpp\r\n...\r\nstd::clog << \"Terminated \\n\";\r\nec_.Notify(true);\r\nreturn false;\r\n...\r\n```\r\n\r\nBazel build output:\r\n\r\n```bash\r\nINFO: From Executing genrule //tensorflow/python:cudnn_rnn_ops_pygenrule:\r\nTerminated  # my std::clog output\r\nTerminated \r\nTerminated \r\nTerminated \r\nTerminated \r\nTerminated \r\nTerminated \r\nTerminated \r\nTerminated \r\nTerminated \r\nTerminated \r\nTerminated \r\nTerminated \r\nTerminated \r\nTerminated \r\nTerminated \r\nINFO: From Executing genrule //tensorflow/python:candidate_sampling_ops_pygenrule:\r\nTerminated \r\nTerminated \r\nTerminated \r\nTerminated \r\nTerminated \r\nTerminated \r\nTerminated \r\nTerminated \r\nTerminated \r\nTerminated \r\nTerminated \r\nTerminated \r\nTerminated \r\nTerminated \r\nTerminated \r\nTerminated \r\n```\r\n\r\nI use local eigen instead of the remote repo. I try to tracing / logging eigen library, like `WaitForWork`. \r\nI find that when I build TF from source, it seems like TF runs the code. Worse, it will segmentation fault / core dump if I add logging to some part code of eigen, like loop.\r\nWhat is the design behind it? ", "comments": ["@shizukanaskytree  This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.If you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new/choose). Thanks!\r\n"]}, {"number": 28462, "title": "Poor performance on debug version", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Centos7.5\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): Source\r\n- TensorFlow version (use command below): 1.12\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source): 0.19\r\n- GCC/Compiler version (if compiling from source): 6.3\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nI build tensorflow from source code for debug with the options **\"-c dbg\"** \r\nI also remove the build options: **\"-c opt --copt=-O3\"**\r\nWith this debug version, I only get 1/10 performance comparing with the release version.\r\nI don't know it's normal in your aspect?\r\nWhich one(add \"-c dbg\" or remove \"-c opt --copt=-O3\") may majorly cause this problem.\r\n\r\n**Describe the expected behavior**\r\nDebug version and release version has similar performance.\r\n\r\n", "comments": ["@Leslie-Fang Could you provide more details about the issue and context? Also, In order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!", "@gadagashwini Thanks for you reply. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=28462\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=28462\">No</a>\n", "I suppose it's a expected behavior."]}, {"number": 28461, "title": "Fix tf.signal.inverse_stft AttributeError in tf 2.0", "body": "This fix tries to address the issue raised in #28444 where tf.signal.inverse_stft causes AttributeError with:\r\n```\r\nframe_length = 512\r\nframe_step = 256\r\nsignal = tf.random.uniform(shape=(1000,))\r\nx = tf.signal.stft(signal, frame_length, frame_step)\r\ny = tf.signal.inverse_stft(x, frame_length, frame_step)\r\n\r\nAttributeError: 'int' object has no attribute 'value'\r\n```\r\n\r\nThe issue is that, in `inverse_stft`, `real_frames.shape[-1].value` has been used to get the value of the dim -1 for shape. However, the `real_frames.shape[-1].value` only works in non-eager mode where shape gives list of `Dimension` (value works). It does not work in eager mode (2.0) where shape gives list of ints.\r\n\r\nThis fix replaces with `real_frames.shape.as_list()[-1]` which should work in eager and non-eager mode.\r\n\r\nThis fix fixes #28444.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": []}, {"number": 28460, "title": "adjust_hsv_nhwc doesn't process all items", "body": "CUDA kernel  \"adjust_hsv_nhwc\" in [adjust_hsv_gpu.cu.h](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/adjust_hsv_gpu.cu.h) doesn't fully iterate through all the items in the input array when the number of threads spawned is larger than the total number of items. A simple fix would be to have each thread iterate through all the items inside a for-loop in order to check that all the items in the input array has been processed. I have implemented a fix for this kernel, and would like to send a pull request after consulting with a dev from TF. ( I can attach my test code if needed )", "comments": ["@ThisIsIsaac Thanks for your effort. Please provide your code and elaborate in detail the added fix.", "@ThisIsIsaac Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "@muddham\r\nSorry for not mentioning here. I have made a [pull request](https://github.com/tensorflow/tensorflow/pull/28686) for the bug and asked one of the TF devs in contact to review. "]}, {"number": 28459, "title": "How to export a eager mode checkpoint for tfserving", "body": "I have train a model by tf1.13 and eager mode, then save it to checkpoint.\r\n\r\nnow I need to export the model to pb file and deploy on tfserving ?\r\n\r\nIs there any one help me?", "comments": ["I'd check out the SavedModel guide: https://www.tensorflow.org/alpha/guide/saved_model. You'll want to export a `@tf.function` for serving.\r\n\r\nNot really a bug though; please ask these kinds of things on StackOverflow so it's easier to archive the answers.", "> I'd check out the SavedModel guide: https://www.tensorflow.org/alpha/guide/saved_model. You'll want to export a `@tf.function` for serving.\r\n> \r\n> Not really a bug though; please ask these kinds of things on StackOverflow so it's easier to archive the answers.\r\n\r\ntf1.13 had no tf.function.\r\nAnd if using tf2.0's savedModel, It can not loads  tf1.13's checkpoints correctly.\r\n\r\n", "> And if using tf2.0's savedModel, It can not loads tf1.13's checkpoints correctly.\r\n\r\nNot sure what that means. If you have code you think should work, please file a bug with a reproduction and I'm happy to take a look.", "Thanks for your reply.\r\nFinally, the graph mode works ."]}, {"number": 28458, "title": "map_fn() missing GPU implementation", "body": "It appears that `map_fn()` does not have a GPU implementation for integer tensors, which seems to be causing performance issues for some networks I'm designing (e.g. excessive data copying).\r\n\r\nThis may be related to #5965, but `map_fn()` isn't explicitly mentioned there.\r\n\r\n**System information**\r\n- Have I written custom code: Yes\r\n- OS Platform and Distribution: Linux Ubuntu 18.04 & Windows 10 x64\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): Ubuntu apt-get repo, WinPython\r\n- TensorFlow version (use command below): b'v1.13.1-0-g6612da8951' 1.13.1\r\n- Python version: 3.6.7\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: CUDA 10.0, cuDNN 7.4.1.5\r\n- GPU model and memory: nVidia K80 & nVidia GTX 1050 Ti\r\n\r\n**Describe the current behavior**\r\n`tf.map_fn()` is located on the CPU when calling with integer tensors. Forcing GPU location results in an error message.\r\n\r\n**Describe the expected behavior**\r\n`tf.map_fn()` should have a GPU implementation to avoid excessive data copying.\r\n\r\n**Code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\n\r\ninitial_integers = tf.zeros((10,), dtype=tf.int32)\r\ninitial_floats = tf.zeros((10,), dtype=tf.float32)\r\n                \r\nwith tf.Session(config=tf.ConfigProto(allow_soft_placement=False)) as sess:\r\n    with tf.device('/device:GPU:0'):\r\n\r\n        # This works on GPU:\r\n        results1 = tf.map_fn(tf.square, initial_floats)\r\n        output1 = sess.run(results1)\r\n\r\n        # This fails to locate on GPU, and results in an error.\r\n        results2 = tf.map_fn(tf.square, initial_integers)\r\n        output2 = sess.run(results2)\r\n```", "comments": ["Yes, map_fn is central for parallelization. In https://github.com/tensorflow/tensorflow/issues/24774 ,  hansok has mentioned the problems 4 months ago, we request you to make this better.\r\n\r\n4 years into tf, finding that a central op for parallelization on this lower layer isn't fast enough is a shame. https://github.com/tensorflow/tensorflow/issues/27644 issue is also related", "@reedwm would you please take a look? Thanks.", "The error message I get is:\r\n\r\n```\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation map_1/TensorArray: Could not satisfy explicit device specification '' because the node {{colocation_node map_1/TensorArray}} was colocated with a group of nodes that required incompatible device '/device:GPU:0'. All available devices [/job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:XLA_CPU:0, /job:localhost/replica:0/task:0/device:XLA_GPU:0, /job:localhost/replica:0/task:0/device:GPU:0]. \r\nColocation Debug Info:\r\nColocation group had the following types and supported devices: \r\nRoot Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='' supported_device_types_=[CPU, XLA_CPU, XLA_GPU] possible_devices_=[]\r\nTensorArrayScatterV3: CPU XLA_CPU XLA_GPU \r\nTensorArrayReadV3: CPU XLA_CPU XLA_GPU \r\nEnter: GPU CPU XLA_CPU XLA_GPU \r\nConst: GPU CPU XLA_CPU XLA_GPU \r\nTensorArrayV3: CPU XLA_CPU XLA_GPU \r\n\r\nColocation members, user-requested devices, and framework assigned devices, if any:\r\n  zeros (Const) \r\n  map_1/TensorArray (TensorArrayV3) \r\n  map_1/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3 (TensorArrayScatterV3) \r\n  map_1/while/TensorArrayReadV3/Enter (Enter) /device:GPU:0\r\n  map_1/while/TensorArrayReadV3 (TensorArrayReadV3) /device:GPU:0\r\n\r\n\t [[{{node map_1/TensorArray}}]]\r\n```\r\n\r\nThe core problem is that TensorArray does not have a GPU implementation for most integer types, although int64 support was added in #22157.\r\n\r\nMarking as contributions welcome for support for other integer types.", "Hi, I would like to work on this issue. Is that ok?", "@ila96, that sounds good. Thank you for working on this.", "Hi, while I think we can enable support for int8 and int16, the int32 support is problematic because we often use int32s to represent shapes and sizes.  writing int32s to the GPU just to pull them off again to get a shape will create performance regressions for many existing users.", "The current workaround is to store int32s that you want to have on GPU as int64s.  We are working on some grappler optimizers to determine whether a Tensor should be on CPU or GPU in a more intelligent fashion, but again we need to resolve some performance regressions before turning that on.  Once that's in, we can probably add a full non-host int32 gpu kernel.", "@ebrevdo, thanks for the feedback, I will change my PR to remove int32 then ;) ", "This is now fixed with recent TF 2.X versions.\r\nI have tested TF 2.5, please refer the colab [gist](https://colab.sandbox.google.com/gist/ymodak/72706ea02f26fc3d63f12fb60fb4dd3a/gh_issue_28458.ipynb) Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/28458\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/28458\">No</a>\n"]}, {"number": 28457, "title": "Tensor flow 2.0 and OpenCV usage", "body": "Hi,\r\n       I have already opened this issue in [Stack Overflow ](https://stackoverflow.com/questions/55986982/what-is-the-way-to-use-tensor-flow-2-0-object-in-open-cv2-python-and-why-is-it-s)but without much notice, I decided to add it here too. My question is related to usage of OpenCv operations like for instance in a train_step lets say I want to use an opencv function of remap - say undistort the output from a training model, then how do I do this in tensorflow ? Is this impossible as tensor flow object resides on GPU and calling an open cv operation requires a CPU copy and then a GPU push ? Is there already exists a provision through py_function  (I tried it) or something fancier ? Please advice.  ", "comments": ["@syedalamabbas This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.If you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new/choose). Thanks!\r\n", "@muddham  If you feel there is nothing you can add to the discussion about the issue since its already on Stack Overflow as my first post described, you may close it. ", "@syedalamabbas Since it is not a bug or feature request, this issue will be closed. Thanks!"]}, {"number": 28456, "title": "Add the validation of the last component in FilterByLastComponentDataset with tests", "body": "This PR adds the validation of the last component in `FilterByLastComponentDataset` and also adds the tests.\r\n\r\ncc: @jsimsa \r\n\r\n", "comments": ["@jsimsa The dtype check for the last component is added in this commit (https://github.com/tensorflow/tensorflow/pull/28456/commits/8459281eebf1a8eccc9ea7904324fb991ca6cc55). It also removes the unnecessary test cases. Could you please have a look at the change?", "> Change the message to \"Last component must be a bool scalar.\", otherwise LGTM.\r\n\r\n@jsimsa The message has been revised here (https://github.com/tensorflow/tensorflow/pull/28456/commits/c8d7dc556955d3d6939b79e67366bec88cde7844). Could you have a look?\r\n\r\n"]}, {"number": 28455, "title": "[TF-TRT] Ignore StopGradient ops", "body": "StopGradient is a no-op during inference and can interfere with TF-TRT segmentation. This PR supports StopGradient in TF-TRT in the same way as Identity or Snapshot.", "comments": []}, {"number": 28454, "title": "Fix weighted top_k_categorical_accuracy keras metric", "body": "Metrics top_k_categorical_accuracy and sparse_top_k_categorical_accuracy should output a vector of accuracies instead of single scalar.\r\n\r\nSee this Keras PR for more details: https://github.com/keras-team/keras/pull/12632", "comments": []}, {"number": 28453, "title": "[ROCm] Adding ROCm support for the dense update ops", "body": "This PR adds ROCm support for the dense update ops\r\n\r\nThe changes here are trivial...please approve and merge.\r\n\r\n------------------\r\n\r\n@tatianashp , @whchung : just FYI\r\n", "comments": ["@chsigg \r\n\r\ngentle ping....just wondering what is holding up the merge for this PR.\r\n\r\nthanks\r\n\r\ndeven", "The merge got stuck in our pipeline. It should land soon."]}, {"number": 28452, "title": "cuda: fix symbol name in cudart_stub for cuda10.1", "body": "The symbol name is __cudaRegisterFatBinaryEnd, not\r\n__cudaUnregisterFatBinaryEnd\r\n\r\nSigned-off-by: Jason Zaman <jason@perfinion.com>", "comments": ["CC @wdirons ", "Actually stream_executor team just approve the internal version of the change, which will get submitted faster without the github round trip. I'll close this one. Thanks again @perfinion!", "@yifeif awesome, thanks :)"]}, {"number": 28451, "title": "[ROCm] Adding ROm support for \"concat\", \"pack\", \"unpack\" and \"split\" ops", "body": "This PR add ROCm support for \"concat\", \"pack\", \"unpack\" and \"split\" ops\r\n\r\nPR #28343 is a pre-req for this PR, and hence this PR includes commits from PR #28343\r\nOnly the last three commits in this PR is exclusive to this PR, and hence should be the only one reviewed.\r\n\r\n-------------------------------\r\n\r\nPlease ignore the cla check failure...that is getting triggered because this PR builds on top of PR #28343 (which is submitted by a different developer). Once that PR is merged, and I rebase this PR, the commit triggering the cla check failure will be gone from this commit\r\n\r\n-------------------------------\r\n\r\n@tatianashp , @whchung : just FYI\r\n", "comments": ["So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored or co-authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of all the commit author(s), set the `cla` label to `yes` (if enabled on your project), and then merge this pull request when appropriate.*\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F28451) for more info**.\n\n<!-- need_author_consent -->", "@chsigg , would you be able to take a look at this and PR 28450 as they are TF implementation changes?", "Please do not rename the symbols or macros as part of this PR. This is better done from our end, because of internal dependencies that you cannot update.", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F28451) for more info**.\n\n<!-- ok -->", "@chsigg\r\n\r\nrebased this PR now that the updates related to Cuda* to Gpu* renaming are merged into master.\r\n\r\nThis PR is now trivial, please review and merge.\r\n\r\nthanks", "The failures in the `LInux GPU` CI run are due to the fact that PR #28834 is not yet merged.\r\n\r\nPR #28834 renames the `cuda_helper` namespace to `gpu_helper` (an alias `cuda_helper` is also introduced for backward compatbility).  \r\n\r\nThis PR updates the the `cuda_helper` reference to `gpu_helper` (since the `cuda_helper` name is not visible in ROCm builds). Please re-run CI after PR #28834 is merged, that should get rid of the errors.\r\n\r\nthanks", "Yes, we can address the dynamic shared memory in a separate change.\n\nOn Thu, May 23, 2019, 20:59 Rajeshwar Reddy T <notifications@github.com>\nwrote:\n\n> @rthadur <https://github.com/rthadur> requested your review on: #28451\n> <https://github.com/tensorflow/tensorflow/pull/28451> [ROCm] Adding ROm\n> support for \"concat\", \"pack\", \"unpack\" and \"split\" ops.\n>\n> \u2014\n> You are receiving this because your review was requested.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/28451?email_source=notifications&email_token=ABZM5DRAVB5UBLKOAMVN2Q3PW3SPXA5CNFSM4HLDPJDKYY3PNVWWK3TUL52HS4DFWZEXG43VMVCXMZLOORHG65DJMZUWGYLUNFXW5KTDN5WW2ZLOORPWSZGORTPWNTA#event-2363451084>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABZM5DVULTNHLG56LCHCHXDPW3SPXANCNFSM4HLDPJDA>\n> .\n>\n"]}, {"number": 28450, "title": "[ROCm] Adding ROCm support for \"sparse_tensor_dense_matmul\" op ", "body": "This PR adds ROCm support for  \"sparse_tensor_dense_matmul\" op \r\n\r\nPR #28343 is a pre-req for this PR, and hence this PR includes commits from PR #28343\r\nOnly the last commit in this PR is exclusive to this PR, and hence should be the only one reviewed.\r\n\r\n---------------------\r\n\r\nPlease ignore the cla check failure...that is getting triggered because this PR builds on top of PR #28343 (which is submitted by a different developer). Once that PR is merged, and I rebase this PR, the commit triggering the cla check failure will be gone from this commit\r\n\r\n---------------------\r\n\r\n@tatianashp , @whchung : just FYI\r\n", "comments": ["So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored or co-authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of all the commit author(s), set the `cla` label to `yes` (if enabled on your project), and then merge this pull request when appropriate.*\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F28450) for more info**.\n\n<!-- need_author_consent -->", "Please do not mix functional changes with symbol renaming. It makes it hard to review. Renaming is better done on our end.", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F28450) for more info**.\n\n<!-- ok -->", " @chsigg\r\n\r\nrebased this PR now that the updates related to Cuda* to Gpu* renaming are merged into master.\r\n\r\nThis PR is now trivial, please review and merge.\r\n\r\nthanks"]}, {"number": 28449, "title": "Typo in TensorFlow For Poets", "body": "## Existing URLs containing the issue:\r\nhttps://codelabs.developers.google.com/codelabs/tensorflow-for-poets/#3\r\n\r\n## Description of issue (what needs changing):\r\nTypo\r\n\r\n### Clear Description\r\n```\r\nMobileNet is a a small efficient convolutional neural network.\r\n```\r\nshould be\r\n```\r\nMobileNet is a small efficient convolutional neural network.\r\n```\r\n\r\n### Submit PR?\r\nI couldn't find the source for this codelab to fix the error. Is this tutorial obsolete or has it been updated for TensorFlow 2.0?\r\n\r\nThe issue has also been reported [here](https://github.com/googlecodelabs/tensorflow-for-poets-2/issues/67).", "comments": ["@cseas : Can you please help us to know the origin of this link. Is it directed somewhere from TensorFlow official website ? Thanks!  ", "I'm not sure about the TenforFlow website, but the CodeLab link is referenced here:\r\nhttps://www.youtube.com/watch?v=cSKfRcEDGUs\r\n\r\nThe video mentions the link to the CodeLab:\r\n https://goo.gl/QTwZ3v\r\n\r\nI can now see that this CodeLab has been deprecated and an alternate TF 2.0 Notebook has been provided for the same. However, I feel that the original link is more intuitive and explains the process in a more beginner-friendly way. The original article should be re-written to be TF 2.0 compatible instead of just providing a Colab Notebook with minimal text-based explanations.", "THis has been deprecated. Please see this page for the replacements (https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/#0). Thank you!"]}, {"number": 28448, "title": "[ROCm] Adding ROCm support for \"depth_to_space\" and \"space_to_depth\" ops", "body": "This PR adds support for \"depth_to_space\" and \"space_to_depth\" ops\r\n\r\nPR #28343 is a pre-req for this PR, and hence this PR includes commits from PR #28343\r\nOnly the last two commits in this PR is exclusive to this PR, and hence should be the only one reviewed.\r\n\r\n--------------------\r\n\r\nPlease ignore the cla check failure...that is getting triggered because this PR builds on top of PR #28343 (which is submitted by a different developer). Once that PR is merged, and I rebase this PR, the commit triggering the cla check failure will be gone from this commit\r\n\r\n---------------------\r\n\r\n@tatianashp , @whchung : just FYI", "comments": ["So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored or co-authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of all the commit author(s), set the `cla` label to `yes` (if enabled on your project), and then merge this pull request when appropriate.*\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F28448) for more info**.\n\n<!-- need_author_consent -->", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F28448) for more info**.\n\n<!-- ok -->", "@gunan @chsigg\r\n\r\nrebased this PR now that the updates related to Cuda* to Gpu* renaming are merged into master.\r\n\r\nThis PR is now trivial, please review and merge.\r\n\r\nthanks", "@gunan a gentle ping."]}, {"number": 28447, "title": "[ROCm] Adding ROCm support for \"space_to_batch\" op", "body": "This PR adds ROCm support for the \"space_to_batch\" op.\r\n\r\nPR #28343 is a pre-req for this PR, and hence this PR includes commits from PR #28343 \r\nOnly the last commit in this PR is exclusive to this PR, and hence should be the only one reviewed.\r\n\r\n------------------------------------------\r\n\r\n@tatianashp , @whchung : just FYI\r\n", "comments": ["So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored or co-authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of all the commit author(s), set the `cla` label to `yes` (if enabled on your project), and then merge this pull request when appropriate.*\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F28447) for more info**.\n\n<!-- need_author_consent -->", "Please ignore the `cla` check failure...that is getting triggered because this PR builds on top of PR #28343 (which is submitted by a different developer). Once that PR is merged, and I rebase this PR, the commit triggering the `cla` check failure will be gone from this commit", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F28447) for more info**.\n\n<!-- ok -->", "@gunan @chsigg\r\n\r\nrebased this PR now that the updates related to Cuda* to Gpu* renaming are merged into master.\r\n\r\nThis PR is now trivial, please review and merge.\r\n\r\nthanks", "@gunan a gentle ping."]}, {"number": 28446, "title": "Return better error message when using RefVariables with v2 control flow", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):archlinux\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:n/a\r\n- TensorFlow installed from (source or binary):binary\r\n- TensorFlow version (use command below):v1.12.0-12395-g32b84a4 1.14.1-dev20190412  (this is the nightly at 20190412).\r\n- Python version:3.7\r\n- Bazel version (if compiling from source):n/a\r\n- GCC/Compiler version (if compiling from source):n/a\r\n- CUDA/cuDNN version:n/a\r\n- GPU model and memory:n/a\r\n\r\nThe following code:\r\n```python\r\nimport os\r\nos.environ['TF_ENABLE_COND_V2'] = '1'\r\nimport tensorflow as tf\r\n\r\na = tf.get_variable(\"x\", dtype=tf.float32, shape=[3])\r\nloss = tf.reduce_sum(a)\r\nopt = tf.train.GradientDescentOptimizer(0.1)\r\ndef f():\r\n    train_op = opt.minimize(loss)\r\n    return train_op\r\nop = tf.cond(tf.greater(a[0], 0), f, tf.no_op)\r\nprint(op)\r\n```\r\nthrows:\r\n```\r\nWARNING: Logging before flag parsing goes to stderr.\r\nW0506 12:29:26.078263 140364116391744 deprecation.py:506] From /home/XXX/environments/tf1-nightly/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1257: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nCall initializer instance with the dtype argument instead of passing it to the constructor\r\nTensor(\"x/Initializer/random_uniform/max:0\", shape=(), dtype=float32) Tensor(\"x/Initializer/random_uniform/min:0\", shape=(), dtype=float32)\r\nTensor(\"x/Initializer/random_uniform/RandomUniform:0\", shape=(3,), dtype=float32) Tensor(\"x/Initializer/random_uniform/sub:0\", shape=(), dtype=float32)\r\nTraceback (most recent call last):\r\n  File \"a.py\", line 20, in <module>\r\n    op = tf.cond(tf.greater(a[0], 0), f, tf.no_op)\r\n  File \"/home/XXX/environments/tf1-nightly/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/home/XXX/environments/tf1-nightly/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 1921, in cond\r\n    return cond_v2.cond_v2(pred, true_fn, false_fn, name)\r\n  File \"/home/XXX/environments/tf1-nightly/lib/python3.7/site-packages/tensorflow/python/ops/cond_v2.py\", line 74, in cond_v2\r\n    op_return_value=pred)\r\n  File \"/home/XXX/environments/tf1-nightly/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\", line 710, in func_graph_from_py_func\r\n    func_outputs = python_func(*func_args, **func_kwargs)\r\n  File \"a.py\", line 16, in f\r\n    train_op = opt.minimize(loss)\r\n  File \"/home/XXX/environments/tf1-nightly/lib/python3.7/site-packages/tensorflow/python/training/optimizer.py\", line 412, in minimize\r\n    name=name)\r\n  File \"/home/XXX/environments/tf1-nightly/lib/python3.7/site-packages/tensorflow/python/training/optimizer.py\", line 594, in apply_gradients\r\n    update_ops.append(processor.update_op(self, grad))\r\n  File \"/home/XXX/environments/tf1-nightly/lib/python3.7/site-packages/tensorflow/python/training/optimizer.py\", line 118, in update_op\r\n    update_op = optimizer._apply_dense(g, self._v)  # pylint: disable=protected-access\r\n  File \"/home/XXX/environments/tf1-nightly/lib/python3.7/site-packages/tensorflow/python/training/gradient_descent.py\", line 60, in _apply_dense\r\n    use_locking=self._use_locking).op\r\n  File \"/home/XXX/environments/tf1-nightly/lib/python3.7/site-packages/tensorflow/python/training/gen_training_ops.py\", line 639, in apply_gradient_descent\r\n    use_locking=use_locking, name=name)\r\n  File \"/home/XXX/environments/tf1-nightly/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/home/XXX/environments/tf1-nightly/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\", line 461, in create_op\r\n    compute_device=compute_device)\r\n  File \"/home/XXX/environments/tf1-nightly/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/home/XXX/environments/tf1-nightly/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 3579, in create_op\r\n    op_def=op_def)\r\n  File \"/home/XXX/environments/tf1-nightly/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 1969, in __init__\r\n    input_types))\r\nTypeError: In op 'GradientDescent/update_x/ApplyGradientDescent', input types ([tf.float32, tf.float32, tf.float32]) are not compatible with expected types ([tf.float32_ref, tf.float32, tf.float32])\r\n```\r\n\r\nBut it works without COND_V2. Similar to #24517.", "comments": ["Could you try using [`tf.enable_resource_variables()`](https://www.tensorflow.org/api_docs/python/tf/enable_resource_variables) or `tf.get_variable(\"x\", dtype=tf.float32, shape=[3], use_resource=True)`.\r\n\r\nv2 control flow does not support RefVariables.", "Thanks! This does fix the issue. Perhaps this behavior should trigger a more clear error message?", "Yep, that would be useful. Let me look into that. Thanks!", "@ppwwyyxx Is this still an issue for you? When I ran your code, the error message was clear as shown below. Please check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/e655879c992dabf6b083af88d7d3cf50/untitled997.ipynb). Thanks!\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-3-5216065f60d8> in <module>()\r\n      9     train_op = opt.minimize(loss)\r\n     10     return train_op\r\n---> 11 op = tf.cond(tf.greater(a[0], 0), f, tf.no_op)\r\n     12 print(op)\r\n\r\n13 frames\r\n/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/ops.py in __init__(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\r\n   1724         raise TypeError(\"In op '%s', input types (%s) are not compatible \"\r\n   1725                         \"with expected types (%s)\" %\r\n-> 1726                         (node_def.name, [i.dtype for i in inputs], input_types))\r\n   1727 \r\n   1728     # Build the list of control inputs.\r\n\r\nTypeError: In op 'GradientDescent/update_x/ApplyGradientDescent', input types ([tf.float32, tf.float32, tf.float32]) are not compatible with expected types ([tf.float32_ref, tf.float32, tf.float32])\r\n```\r\n\r\nThe error was already resolved by @saxenasaurabh suggestion. Thanks!", "In fact nothing changes and the error message is the same as two years ago.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/28446\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/28446\">No</a>\n", "Hi @ppwwyyxx!  I have edited code and  issue is not replicating after multiple use . please find [GIST ](https://colab.research.google.com/gist/mohantym/b9c052452fa3f11504c1f0044f0b1bd5/untitled997.ipynb#scrollTo=yb2BJyV0HDCm)for reference.", "Thanks! It seems it was fixed.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/28446\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/28446\">No</a>\n"]}]