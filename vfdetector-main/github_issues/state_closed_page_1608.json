[{"number": 4671, "title": "fixing image loading error, autocomplete with ipython", "body": "Adding Pillow, pyreadline to fix image loading error, autocomplete with iPython\n", "comments": ["@neilhan, thanks for your PR! By analyzing the annotation information on this pull request, we identified @vincentvanhoucke and @jendap to be potential reviewers\n", "Can one of the admins verify this patch?\n", "Jenkins, test this please\n", "For future reference, you can also update the commit in the same pull request :)\n", "thanks, new tricks everyday. cheers\n\nOn Thu, Sep 29, 2016, 21:26 Jonathan Hseu notifications@github.com wrote:\n\n> For future reference, you can also update the commit in the same pull\n> request :)\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/pull/4671#issuecomment-250655601,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/ACq4eenf-UC1XEgPI9xhc0uiJdfBxH9Zks5qvI9ZgaJpZM4KKtfR\n> .\n"]}, {"number": 4670, "title": "Fix stddev computation in TensorBoard examples. (#4054)", "body": "", "comments": ["Can one of the admins verify this patch?\n", "@yli192, thanks for your PR! By analyzing the annotation information on this pull request, we identified @petewarden, @danmane and @tensorflower-gardener to be potential reviewers\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "Thanks for the change! These are already fixed in master and are in the latest 0.11.0rc0 release, which we're pushing out right now. We're not making anymore 0.10 releases.\n"]}, {"number": 4669, "title": "Added scikit-learn, pyreadline, and Pillow", "body": "The dockerfile has a few problems on my Mac os10.11.\nNeeded scikit-learn, and pillow to run 1_notmnist.ipynb\nipython auto complete isn't working, added pyreadline fixed it.\n", "comments": ["Can one of the admins verify this patch?\n", "@neilhan, thanks for your PR! By analyzing the annotation information on this pull request, we identified @vincentvanhoucke and @jendap to be potential reviewers\n", "Jenkins, test this please\n", "yes, sorry, unnecessary scikit-learn. the pillow solves an error.\npyreadline is nice to have for iPhone autocomplete.\n\nOn Thu, Sep 29, 2016, 20:13 Jonathan Hseu notifications@github.com wrote:\n\n> Jenkins, test this please\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/pull/4669#issuecomment-250648645,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/ACq4eVNm_uPklP8179HjsXk6aOb7M1szks5qvH5bgaJpZM4KKqHY\n> .\n", "Yeah, seems reasonable to me. Mind updating the change to remove the duplicated entry?\n", "yes, will do\n\nOn Thu, Sep 29, 2016, 21:09 Jonathan Hseu notifications@github.com wrote:\n\n> Yeah, seems reasonable to me. Mind updating the change to remove the\n> duplicated entry?\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/pull/4669#issuecomment-250653999,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/ACq4ee6bPX925yzzZArmtigOH_3eDI_9ks5qvIt0gaJpZM4KKqHY\n> .\n", "sending another one without duplicate scikit-learn\n"]}, {"number": 4668, "title": "Implement tf.nn.atrous_conv2d_transpose()", "body": "Can we have a `atrous_conv2d_transpose()` function, just like the existing `conv2d_transpose()` function? Or is there some simple way to get what I am looking for using other existing functions?\n\nI had a look at the `conv2d_transpose()` code, and it seems shouldn't be too difficult to adapt it to get a `atrous_conv2d_transpose()`.\n\nThanks.\n", "comments": ["I am not aware of anyone actively working on this.  Marking as contributions welcome, and feel free to send us a PR!\n", "I want to work on it !\n", "Hi @Fenugreek  Could you offer some documents with the atrous_conv2d_transpose\uff1f\n", "Yes. Here's code that worked for me. It requires three variables that need to be implemented, placed in < >, that I'll say more about below:\n\n``` python\ndef atrous_conv2d_transpose(value, filters, rate, padding, name=None):\n    value = array_ops.space_to_batch(input=value,\n                                     paddings=<batch_to_space_crop>,\n                                     block_size=rate)\n\n    value = tf.nn.conv2d_transpose(value, filters,\n                                   <output_shape>, [1, 1, 1, 1],\n                                   padding='VALID', name=name)\n\n    value = array_ops.batch_to_space(input=value,\n                                     crops=<space_to_batch_pad>,\n                                     block_size=rate)\n    return value\n```\n\nYou'll notice that the steps above are the steps in `nn_ops.atrous_conv2d()` in reverse. In that code, the variables `batch_to_space_crop` and `space_to_batch_pad` are constructed. We can use the same construction (I did, and it worked). The other variable in the code excerpt above that needs implementation, `output_shape`, however, needs some new calculation. I hard-coded it to work in my specific case, and so have no code to offer for the general case.\n\nAlso: I see in the code for `nn_ops.conv2d_transpose()` a call to `gen_nn_ops.conv2d_backprop_input(...)`. Not sure if it's better to implement/use something like that rather than above approach.\n\nThanks.\n", "great!\n", "#5300 \nI am curious what the motivation/use for adding `atrous_conv2d_transpose(inputs, filters)` is in the first place.\nSince `atrous_conv2d()` always has `stride=1`, its transpose `atrous_conv2d_transpose(inputs, filters)` is equivalent to `atrous_conv2d(inputs, mirrored(filters))` -- see for example sec. 4.3 and 4.4 of https://arxiv.org/pdf/1603.07285.pdf.\n", "@gpapan I didn't realize that, though I'd read that guide (to convolution arithmetic) you linked to before -- I looked at it again just now. Yes, if you set `tf.transpose(filters, perm=[1, 0])` as the kernel you can achieve the transpose.\n\nThe one complication I see is for the most common case when the original convolution has `padding=\"SAME\"` (rather than `padding=\"VALID\"`), after the transpose you'll have values which contain some zero-padding. This zero-padding is easily stripped using array slicing, which I think has recently been implemented (including gradients), but at least I am not so confident of just writing it into my code without testing to check that I used the right indices for the slices.\n\nSo maybe worth implementing anyway. I don't know if this approach (just calling atrous_conv2d with transposed filters, stripping any resulting zero-padding) is different from and/or faster than what @guotong1988 did in #5300. Thanks.\n", "@gpapan Can you please provide the exact `mirrored` function? Thank you!", "@guotong1988 I will look into it in detail and get back to you later this week.", "@guotong1988 -- `mirrored(filters)` should just be `tf.transpose(filters, perm=[1, 0])`. But @gpapan can confirm.", "@Fenugreek Could you provide your hard-coded exact code? In fact I'm not sure that my test case can cover that much. Thank you . Here is my only test case.\r\n\r\n```\r\n# Input, output: [batch, height, width, depth]\r\nx_image = tf.placeholder(tf.float32,shape=[1])\r\nx = tf.reshape(x_image,[1,1,1,1])\r\n\r\n#Filter: W [kernel_height, kernel_width, output_depth, input_depth]\r\nW_cpu = np.array([[1,-1,1],[1,1,1],[-1,1,-1]],dtype=np.float32)\r\nW = tf.Variable(W_cpu)\r\nW = tf.reshape(W, [3,3,1,1])\r\n\r\nstrides=[1, 1, 1, 1]\r\npadding='VALID'\r\n\r\ny = tf.nn.atrous_conv2d_transpose(x, W, [1,5,5,1], 2, strides, padding)\r\n\r\nx_data = np.array([1],dtype=np.float32)\r\nwith tf.Session() as sess:\r\n    init = tf.initialize_all_variables()\r\n    sess.run(init)\r\n\r\n    x = (sess.run(x, feed_dict={x_image: x_data}))\r\n    W = (sess.run(W, feed_dict={x_image: x_data}))\r\n    y = (sess.run(y, feed_dict={x_image: x_data}))\r\n\r\n    print \"The shape of x:\\t\", x.shape, \",\\t and the x.reshape(1) is :\"\r\n    print x.reshape(1)\r\n    print \"\"\r\n\r\n    print \"The shape of x:\\t\", W.shape, \",\\t and the W.reshape(3,3) is :\"\r\n    print W.reshape(3,3)\r\n    print \"\"\r\n\r\n    print \"The shape of y:\\t\", y.shape, \",\\t and the y.reshape(5,5) is :\"\r\n    print y.reshape(5,5)\r\n    print \"\"\r\n```", "@Fenugreek I confirm my commit by write two more examples [here](https://github.com/tensorflow/tensorflow/pull/5300) .\r\nBut I'm afraid that there is still some bug with my commit.", "@guotong1988  I tried running your code and got an output shape I was not expecting. Maybe the code is missing the trimming of the zero-padding. See my comment on #5300.", "@Fenugreek I get your point . When the padding is SAME . I should cut the surrounding pixels.\r\nOr when the padding is SAME, I could use `atrous_conv2d(inputs, mirrored(filters))`", "@guotong1988 OK, I ran your code after your fix, and got reasonable correct looking results this time (I trained something on MNIST and got convergence).\r\n\r\nThis is with `rate=2` and filters with shape `[5, 5, 1, 8]` and `padding='SAME'`. \r\n\r\nOne minor thing I saw was that you take `strides` as an argument but don't use it for `padding='SAME'` (and possibly misuse it for `padding='VALID'`). Maybe simply don't support it? (Since `atrous_conv2d` does not support it.)", "@Fenugreek I think you are right. I remove the parameter."]}, {"number": 4667, "title": "Branch 134734156", "body": "", "comments": []}, {"number": 4666, "title": "autocomplete and image read fix", "body": "Added pyreadline to enable ipython autocomplete\nAdded Pillow to fix an image loading error\n", "comments": ["@neilhan, thanks for your PR! By analyzing the annotation information on this pull request, we identified @vincentvanhoucke, @keveman and @caisq to be potential reviewers\n", "Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "I signed it!\n", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for the commit author(s).  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\n\n<!-- need_author_cla -->\n"]}, {"number": 4665, "title": "Branch 134731106", "body": "", "comments": ["Redoing\n"]}, {"number": 4664, "title": "ImportError: libcudart.so.7.5: cannot open shared object file: No such file or directory", "body": "I'm a new user of tensorflow.I install tensorflow like this.\n1.export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.10.0-cp27-none-linux_x86_64.whl\n2.sudo pip install --upgrade $TF_BINARY_URL\n\nand I succeed install tensorflow ,when I import tensorflow ,It happens that \"ImportError: libcudart.so.7.5: cannot open shared object file: No such file or directory\".It's crazy,I find some solution ,that my shell environment variables should do like this:\n1.export LD_LIBRARY_PATH=\"$LD_LIBRARY_PATH:/usr/local/cuda/lib64\"\n2.export CUDA_HOME=/usr/local/cuda\nbut it not works.\nI find there is not libcudart.so.7.5 in \"/usr/local/cuda/lib64\",it's only \"libcudart so.8.0\"\n\nos:ubuntu 16.04 LTS,cuda:8.0\n", "comments": ["You need to install CUDA 7.5 rather than CUDA 8.0 which is not yet\nsupported by pre-built binaries\n\nOn Thu, Sep 29, 2016 at 4:58 PM, lxj0276 notifications@github.com wrote:\n\n> I'm a new user of tensorflow.I install tensorflow like this.\n> 1.export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/\n> linux/gpu/tensorflow-0.10.0-cp27-none-linux_x86_64.whl\n> 2.sudo pip install --upgrade $TF_BINARY_URL\n> \n> and I succeed install tensorflow ,when I import tensorflow ,It happens\n> that \"ImportError: libcudart.so.7.5: cannot open shared object file: No\n> such file or directory\".It's crazy,I find some solution ,that my shell\n> environment variables should do like this:\n> 1.export LD_LIBRARY_PATH=\"$LD_LIBRARY_PATH:/usr/local/cuda/lib64\"\n> 2.export CUDA_HOME=/usr/local/cuda\n> but it not works.\n> I find there is not libcudart.so.7.5 in \"/usr/local/cuda/lib64\",it's only\n> \"libcudart so.8.0\"\n> \n> os:ubuntu 16.04 LTS,cuda:8.0\n> \n> \u2014\n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/4664, or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AABaHP8DQIGixnv8CEimUzlK8nKPmOazks5qvFC9gaJpZM4KKmkP\n> .\n", "What @yaroslavvb said.  Feel free to re-open if CUDA 7.5 did not work for you.\n", "If I install cuda7.5 and cuda8.0 at the same time ,they  will not clash?\n"]}, {"number": 4663, "title": "Control dependency on identity containing assign not working", "body": "I'm running Tensorflow 0.10.\n\nThe following code \n\n``` python\nimport tensorflow as tf\n\nx = tf.Variable(0, dtype=tf.int32)\n\nold_val = tf.identity(x)\nwith tf.control_dependencies([old_val]):\n    new_val = tf.assign(x, x + 1)\n\nwith tf.Session() as sess:\n    sess.run(tf.initialize_all_variables())\n\n    for i in xrange(3):\n        print sess.run([old_val, new_val, x])\n```\n\noutputs\n\n```\n[1, 1, 1]\n[2, 2, 2]\n[3, 3, 3]\n```\n\nFrom reading the docs on `control_dependencies` and `identity` as well as StackOverflow, I expected output\n\n```\n[0, 1, ?]\n[1, 2, ?]\n[2, 3, ?]\n```\n\nwhere `?` indicates that the variable value is unspecified.\n\nIs this a bug? If this is not a bug, what is the correct way to refer to the value of variable before and after assignment in a single graph?\n", "comments": ["Hm, that's weird, seems like some kind of optimization for tf.identity that\nonly shows up in the final fetch\n\nIf you add the line below, you'll see that identity op gets executed before\nassignment\nold_val = tf.Print(old_val, [old_val])\n\nThis means you can refer to \"x\" in computation,  and this will refer to old\nvalue as long as control_dependency forces this computation to happen\nbefore tf.assign.\n\nNote that if you do another op, ie, old_val = tf.square, then this behavior\ndoesn't happen\n\nOn Thu, Sep 29, 2016 at 4:54 PM, Eric Martin notifications@github.com\nwrote:\n\n> I'm running Tensorflow 0.10.\n> \n> The following code\n> \n> import tensorflow as tf\n> \n> x = tf.Variable(0, dtype=tf.int32)\n> \n> old_val = tf.identity(x)with tf.control_dependencies([old_val]):\n>     new_val = tf.assign(x, x + 1)\n> with tf.Session() as sess:\n>     sess.run(tf.initialize_all_variables())\n> \n> ```\n> for i in xrange(3):\n>     print sess.run([old_val, new_val, x])\n> ```\n> \n> outputs\n> \n> [1, 1, 1]\n> [2, 2, 2]\n> [3, 3, 3]\n> \n> From reading the docs on control_dependencies and identity as well as\n> StackOverflow, I expected output\n> \n> [0, 1, ?]\n> [1, 2, ?]\n> [2, 3, ?]\n> \n> where ? indicates that the variable value is unspecified.\n> \n> Is this a bug? If this is not a bug, what is the correct way to refer to\n> the value of variable before and after assignment in a single graph?\n> \n> \u2014\n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/4663, or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AABaHMmYr83smkIteubJqVOXJ-r1FLi7ks5qvE_DgaJpZM4KKma6\n> .\n", "I'm guessing `identity` has an optimization to not perform a copy if there is no device transfer. In this case, I do need a copy of `x`.\n\nReally, what I want is a function that returns both the old value and the new value of a variable. As you noted with your `tf.square` example, applying a non-identity op to `x` seems to cause a copy, so I can likely hack around this bug with `old_val = x + 0`.\n\nedit: I confirmed that replacing `old_val = tf.identity(x)` with `old_val = x + 0` causes `old_val` to fetch as `new_val - 1` (correct behavior) rather than `new_val`.\n", "This is intended behavior, unfortunately. The identity op returns a tensor that shares the same memory buffer as the variable, so any update to variable will get reflected in the output of the identity op. If you change the identity op to tf.add(x, 0), you should see the \"old\" value.\n", "It seems that `identity` never had a fully defined specification.\n\nThe docs read \"Return a tensor with the same shape and contents as the input tensor or value\", which seems to indicate a copy. When used across devices, it does cause a copy. I haven't tested it, but I believe if I located `old_val` on a GPU, then the output of `sess.run([old_val, new_val])` would be `[0, 1]` rather than `[1, 1]`. Changing the device on which the op is located shouldn't change the semantics of the control dependency, so this seems like a bug. Additionally, if the official way to make a copy on the same device is to add 0, this seems like a bad spec.\n\nIf I may suggest a spec for identity:\n\"Identity returns the value of the tensor at the time of evaluation.\"\nThis could eventually be optimized to not perform a copy unless needed. For instance, if I did `old_val = tf.identity(x); foo = 2 * old_val;` and had a control dependency for `assign` on old_val, I could shift the control dependency to be on `foo` and not have to make an unnecessary copy of `old_val`.\n", "You are right that if the identity op is on a different device than the variable, its output is a copy. We had many discussions on this and even had some proposals that would give the option of stronger memory semantics.  I am hopeful that we will get this mess fixed soon.\n", "@yuanbyu : Should we update the documentation for the identity op as @lightcatcher suggests?\n", "Has there been any progress on this?", "`tf.identity` does some weird things (like removing ref-ness from its input), I think @alextp was working on sorting out semantics, @alextp will your resource containers work affect behavior of identity?", "tf.identity doesn't actually copy the value of the variable (if you want a copy something like +0 will do). For the new variables I'm working on there'll be a read op which does act like it makes a copy.", "@alextp Any progress on the new variables? I see ``Variable.read_value()`` has been introduced in 0.12 (or sometime before)", "If you want to try using the new variables wrap your code around a\nvariable_scope(..., use_resource=True) and use tf.get_variable() to create\nthe variables. Bear in mind that I don't expect it at this point to be\nbug-free nor as performant in all use-cases as old variables but I'd\nappreciate any bugs you find.\n\nOn Tue, Feb 14, 2017 at 9:44 PM, Eric Martin <notifications@github.com>\nwrote:\n\n> @alextp <https://github.com/alextp> Any progress on the new variables? I\n> see Variable.read_value() has been introduced in 0.12 (or sometime before)\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/4663#issuecomment-279922432>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAATxWKWx7u1rorX50feCr-jNXR8BTHYks5rcpCwgaJpZM4KKma6>\n> .\n>\n\n\n\n-- \n - Alex\n", "Don't think this is a bug. tf.identity simply copied the shape and content of x, WHERE x IS UPDATED EVERYTIME BY tf.assign(x,x+1) though you have defined a new tensor new_val.\r\n\r\nthe definition of tf.assign is \r\n\"assign(\r\n    ref,\r\n    value,\r\n    validate_shape=None,\r\n    use_locking=None,\r\n    name=None\r\n)\r\nUpdate 'ref' by assigning 'value' to it.\r\n\r\nThis operation outputs \"ref\" after the assignment is done. This makes it easier to chain operations that need to use the reset value.\"\r\n\r\nSo x is constantly being updated and copied to new_val\r\n\r\n", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "Can we please reopen this issue? The top two answers in https://stackoverflow.com/a/34881060/6531137 implies that this behavior is not expected. The x+0 workaround is also very ugly.", "This issue is very old, we now have resource variables which have different semantics (don't use tf.identity, but rather var.read_value())", "real_value doesn't seem to make OP's code work. Am I doing something wrong here? The +0 workaround does work however.\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\nx = tf.Variable(0, dtype=tf.int32)\r\n\r\nold_val = x.read_value() # workaround: old_val = x+0\r\nwith tf.control_dependencies([old_val]):\r\n    new_val = tf.assign(x, x + 1)\r\n\r\nwith tf.Session() as sess:\r\n    sess.run(tf.global_variables_initializer())\r\n\r\n    for i in range(3):\r\n        print(sess.run([old_val, new_val, x]))\r\n```", "```\r\nimport tensorflow as tf\r\nfrom tensorflow.python.ops import resource_variable_ops as rr\r\n\r\nx = rr.ResourceVariable(0, dtype=tf.int32)\r\n\r\nold_val = x.read_value() # workaround: old_val = x+0\r\nwith tf.control_dependencies([old_val]):\r\n    new_val = tf.assign(x, x.read_value() + 1)\r\n\r\nwith tf.Session() as sess:\r\n    sess.run(tf.global_variables_initializer())\r\n\r\n    for i in range(3):\r\n        print(sess.run([old_val, new_val, x.read_value()]))\r\n```\r\n\r\nThis prints\r\n```\r\n[0, 1, 0]\r\n[1, 2, 1]\r\n[2, 3, 2]\r\n```\r\n\r\nThe point is to always refer to \"x.read_value()\" instead of \"x\"", "I also came across this problem, when I tried to swap the values of two Variables. It seems that only `+0` trick works, instead of `read_value()`.\r\n\r\nThis works:\r\n```python\r\na = tf.Variable(1.)\r\nb = tf.Variable(0.)\r\na_old = a + 0\r\nb_old = b + 0\r\nwith tf.control_dependencies([a_old]):\r\n    assign_a = a.assign(b_old)\r\nwith tf.control_dependencies([b_old]):\r\n    assign_b = b.assign(a_old)\r\nsess = tf.Session()\r\nsess.run(tf.global_variables_initializer())\r\nsess.run([a_old, b_old, assign_a, assign_b])\r\n# => [1.0, 0.0, 0.0, 1.0]\r\n```\r\n\r\nThis doesn't work:\r\n```python\r\na = tf.Variable(1.)\r\nb = tf.Variable(0.)\r\na_old = a.read_value()\r\nb_old = b.read_value()\r\nwith tf.control_dependencies([a_old]):\r\n    assign_a = a.assign(b_old)\r\nwith tf.control_dependencies([b_old]):\r\n    assign_b = b.assign(a_old)\r\nsess = tf.Session()\r\nsess.run(tf.global_variables_initializer())\r\nsess.run([a_old, b_old, assign_a, assign_b])\r\n# => [0.0, 0.0, 0.0, 0.0]\r\n```\r\n\r\nWhy? I'm really confused.", "@yaroslavvb Seems that `var.read_value()` is just implemented by `tf.identity`.\r\n```python\r\n  def read_value(self):\r\n    \"\"\"Returns the value of this variable, read in the current context.\r\n\r\n    Can be different from value() if it's on another device, with control\r\n    dependencies, etc.\r\n\r\n    Returns:\r\n      A `Tensor` containing the value of the variable.\r\n    \"\"\"\r\n    return array_ops.identity(self._variable, name=\"read\")\r\n```", "@thjashin note that your example is not using read_value() on the RHS of your assign op, whereas my example is using it", "@yaroslavvb I tried but your code works because you use `ResourceVariable`. When I changed the snippet to\r\n```python\r\na = rr.ResourceVariable(1.)\r\nb = rr.ResourceVariable(0.)\r\na_old = a.read_value()\r\nb_old = b.read_value()\r\nwith tf.control_dependencies([a_old]):\r\n    assign_a = a.assign(b_old)\r\nwith tf.control_dependencies([b_old]):\r\n    assign_b = b.assign(a_old)\r\nsess = tf.Session()\r\nsess.run(tf.global_variables_initializer())\r\nsess.run([a_old, b_old, assign_a, assign_b])\r\n```\r\nIt does work.\r\n\r\nWhen I changed your code to\r\n```python\r\nx = tf.Variable(0, dtype=tf.int32)\r\n\r\nold_val = x.read_value() # workaround: old_val = x+0\r\nwith tf.control_dependencies([old_val]):\r\n    new_val = tf.assign(x, x.read_value() + 1)\r\n\r\nwith tf.Session() as sess:\r\n    sess.run(tf.global_variables_initializer())\r\n\r\n    for i in range(3):\r\n        print(sess.run([old_val, new_val, x.read_value()]))\r\n```\r\nThe result is\r\n```\r\n[1, 1, 1]\r\n[2, 2, 2]\r\n[3, 3, 3]\r\n```\r\nPretty strange. Just wonder why `control_dependencies` only work when the variable is `ResourceVariable`.", "tf.Variable is semi broken, ResourceVariable is the replacement\n\nOn Oct 13, 2017 18:47, \"Shi Jiaxin\" <notifications@github.com> wrote:\n\n> @yaroslavvb <https://github.com/yaroslavvb> I tried but your code works\n> because you use ResourceVariable. When I changed the snippet to\n>\n> a = rr.ResourceVariable(1.)\n> b = rr.ResourceVariable(0.)\n> a_old = a.read_value()\n> b_old = b.read_value()with tf.control_dependencies([a_old]):\n>     assign_a = a.assign(b_old)with tf.control_dependencies([b_old]):\n>     assign_b = b.assign(a_old)\n> sess = tf.Session()\n> sess.run(tf.global_variables_initializer())\n> sess.run([a_old, b_old, assign_a, assign_b])\n>\n> It does work.\n>\n> When I changed your code to\n>\n> x = tf.Variable(0, dtype=tf.int32)\n>\n> old_val = x.read_value() # workaround: old_val = x+0with tf.control_dependencies([old_val]):\n>     new_val = tf.assign(x, x.read_value() + 1)\n> with tf.Session() as sess:\n>     sess.run(tf.global_variables_initializer())\n>\n>     for i in range(3):\n>         print(sess.run([old_val, new_val, x.read_value()]))\n>\n> The result is\n>\n> [1, 1, 1]\n> [2, 2, 2]\n> [3, 3, 3]\n>\n> Pretty strange. Just wonder why control_dependencies only work when the\n> variable is ResourceVariable.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/4663#issuecomment-336600995>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AABaHDPfLnH8-IHGWpF53pzzkqgZ37Gtks5ssBKsgaJpZM4KKma6>\n> .\n>\n", "Oh I see. Thanks for clarifying this. Would be better if there is a warning about this in the doc string of `Variable`."]}, {"number": 4662, "title": "./configure should fail if the bazel commands fail", "body": "The configure script now calls bazel clean and bazel fetch (as of ~Aug 2016).  If they fail, the script should exit with a nonzero exit status rather than continuing onwards.  This is important for automated build systems to detect failed configure calls.\n", "comments": ["@davidzchen added these to configure script.\nDavid, is this the case at the moment?\n", "The reason why the script continues even when commands fail is because the script does not `set -e`. Perhaps we should set `set -e` and some other shell settings in the `configure` script as described by [Writing Safe Shell Scripts](https://sipb.mit.edu/doc/safe-shell/).\n", "@martinwicke, is there a reason we do not have `set -e` in the configure script?\n", "If you use `set -e`, I'd put it near the end after the configuration but before the bazel commands, or put it in the `bazel_clean_and_fetch()` function and unset it when it exits that function. Otherwise stuff like `default_python_bin_path=$(which python)` will fail the script if there is no python on the path.\n", "Philosophically speaking, I'd prefer for the configure script not to run any bazel commands (esp fetch, since that does a lot of work). It would be more \"normal\" to write some config files and have the build step clean/fetch if it detects a config change.\n\nBut.. if this is really complicated, I dont feel very strongly, just figured I'd voice my opinion.\n", "+cc @damienmg \n\n@llchan That is a good point. For those lines where we have command substitution, would it be idiomatic to do the following to prevent the non-zero exit code:\n\n``` sh\ndefault_python_bin_path=$(which python || true)\n```\n\nIt is not ideal to have to run those bazel commands in the `configure` script. We are working on improving the cache invalidation for external repositories and have plans to let repository rules declare which environment variables they consume and would invalidate the repository if they change.\n\nAt the same time, ideally, a shell script as non-trivial as `configure` should try to be as strict as possible and exit immediately if any of the commands fail.\n", "set -e is generally a good idea, unless we can include error messages\nbetter than the ones generated by the failing commands.\nOn Fri, Sep 30, 2016 at 19:16 David Z. Chen notifications@github.com\nwrote:\n\n> +cc @damienmg https://github.com/damienmg\n> \n> @llchan https://github.com/llchan That is a good point. For those lines\n> where we have command substitution, would it be idiomatic to do the\n> following to prevent the non-zero exit code:\n> \n> default_python_bin_path=$(which python || true)\n> \n> It is not ideal to have to run those bazel commands in the configure\n> script. We are working on improving the cache invalidation for external\n> repositories and have plans to let repository rules declare which\n> environment variables they consume and would invalidate the repository if\n> they change.\n> \n> At the same time, ideally, a shell script as non-trivial as configure\n> should try to be as strict as possible and exit immediately if any of the\n> commands fail.\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/4662#issuecomment-250873132,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AAjO_b3G4q6e6_S0udyuh5pk-ziuj_3Mks5qvZgygaJpZM4KKgF0\n> .\n"]}, {"number": 4661, "title": "Defun grad_func should accept the outputs of the function being differentiated", "body": "When dealing with discrete stochastic units, one often wants to define custom gradients. It seems like the most legitimate way to it in Tensorflow is to use `grad_func` keyword argument of `function.Defun` from `tensorflow.python.framework`.  However, the gradient function is only given the inputs of the function defined and the gradients, whereas it would be often very convenient to also use the outputs. \n\nFor example, see the code below.\n\n``` python\n# In current Tensorflow I have to do like this:\n\n@function.Defun(*(3 * [tf.float32]))\ndef oneovertwo_unit_bprop(probs, noise, grads):\n  outcome = tf.to_float(tf.less(noise, probs))\n  outcome_probs = outcome * probs + (1 - outcome) * (1 - probs)\n  return grads / 2. / outcome_probs, tf.zeros_like(noise)\n\n\n@function.Defun(*(2 * [tf.float32]), grad_func=oneovertwo_unit_bprop)\ndef oneovertwo_unit_fprop(probs, noise):\n  return tf.to_float(tf.less(noise, probs))\n\n\ndef oneovertwo_unit(probs):\n  return oneovertwo_unit_fprop(probs, tf.random_uniform(tf.shape(probs)))\n\n# I would like to do like this\n\ndef oneovertwo_unit_bprop(probs, outcome, grads):\n  outcome_probs = outcome * probs + (1 - outcome) * (1 - probs)\n  return grads / 2. / outcome_probs\n\n\n@function.Defun(*(2 * [tf.float32]), grad_func=oneovertwo_unit_bprop)\ndef oneovertwo_unit(probs):\n  return tf.to_float(tf.less(tf.random_uniform(probs.get_shape()), probs))\n```\n\nFYI, this an implementation of the gradient estimator from the DARN paper (https://arxiv.org/pdf/1310.8499v2.pdf).\n", "comments": ["@zffchen78: is this something on the radar?  \n\nIf not, we can mark it as contributions welcome, as a workaround seems to exist.\n", "It's work as intended. The seemingly duplicated computation done by tf.to_float(tf.less(noise, probs)) can be eliminated by TF runtime. See example in function_test.py. Look for usage of _OptimizationOptions().\n\nThe reasoning behind my design choice is that if the grad_func's signature always gives the implementation the result of the forward function. That typically means the result is needed to be kept around until backprop. It's not always a good choice in face of limited memory.\n\nInstead, if you always recompute the forward compution inside the backward function, TF can have choice to either eliminate the duplicated computation during the whole graph optimization but likely to use more memory; or redo the computation instead using less memory. E.g., in your case, the way to least memory is to have different random_uniform generator which determisticly generates its output from an input seed(s), that way, only the seed (64-bit) is needed in a very long forward-backward chain and can cheaply regenerate the mask.\n\nIn your case, pulling out the random_uniform as the noise is the right choice. Because random_uniform is a stateful operation which outputs different results on each innovation.\n\nBTW, I recently improved the Defun syntax so that you no longer needs specify the type in the Defun decorator constructor. So you can remove *(3 \\* [tf.float32]) and *(2 \\* [tf.float32]): E.g.,\n\n```\n@function.Defun()\ndef oneovertwo_unit(probs):\n\n  @function.Defun()\n  def bprop(probs, noise, grads):\n    outcome = tf.to_float(tf.less(noise, probs))\n    outcome_probs = outcome * probs + (1 - outcome) * (1 - probs)\n    return grads / 2. / outcome_probs, tf.zeros_like(noise)\n\n\n  @function.Defun(grad_func=bprop)\n  def fprop(probs, noise):\n    return tf.to_float(tf.less(noise, probs))\n\n  return fprop(probs, tf.random_uniform(tf.shape(probs)))\n\n```\n"]}, {"number": 4660, "title": "link to better jupyter notebook preview", "body": "As mentioned in [the deep dream tutorial readme](https://github.com/tensorflow/tensorflow/blob/bc64f05d4090262025a95438b42a54bfdc5bcc80/tensorflow/examples/tutorials/deepdream/README.md) the jupyter notebook preview on nbviewer is better than the one on github. Specifically, github removes the network graph visualizations.\n", "comments": ["Can one of the admins verify this patch?\n", "@hrldcpr, thanks for your PR! By analyzing the annotation information on this pull request, we identified @tensorflower-gardener, @keveman and @wjarek to be potential reviewers\n", "We probably want to leave it the way it is for consistency with the rest of the tutorials. It should be a relative link like the others, though, so feel free to make it a relative link instead.\n", "@jhseu As far as I can tell, this is the only tutorial which is a jupyter notebook, and clicking that link just redirects to github, so I think it's doomed to inconsistency regardless \ud83d\ude09 \n", "Jenkins, test this please\n"]}, {"number": 4659, "title": "Missing python packages from Dockerfile, scikit-learn, pyreadline", "body": "I am using the Dockerfile provided in this project to do the Udacity assignments. \n\nThe first example of the Udacity DL fails at this line:\n   \"from sklearn.linear_model import LogisticRegression\"\n\nThe iPython notebook also doesn't support tab-autocomplete. \n\nThe fix is to add the two missing python packages in the Dockerfile, line 32, 33:\n\n26 RUN pip --no-cache-dir install \\\n 27         ipykernel \\\n 28         jupyter \\\n 29         matplotlib \\\n 30         numpy \\\n 31         scipy \\\n 32         scikit-learn \\\n 33         pyreadline \\\n 34         && \\\n 35     python -m ipykernel.kernelspec\n### Environment info\n\nOperating System:\nMac OS 10.11.6\n", "comments": ["I should have used the Dockerfile under example/udacity/\n"]}, {"number": 4658, "title": "Change variable name  not take effect in checkpoints", "body": "I want to load into one session different checkpoints of the same model. Like take step 10 and step 100\nIn order to avoid conflict name, I try to modify the variable name first, like change from \nshow_and_tell/model_init/emb:0 to show_and_tell_1/model_init/emb:0,\nmy input checkpoint with all varaibles starts with show_and_tell, and I want to modify it to show_and_tell_1\nso I can load the two models at once.\nCode like below, but the savec checkpoint.meta shows still show_and_tell/model_init/emb:0, what's wrong?\n\ndef reset_model_top_scope():\n    sess = tf.InteractiveSession()\n    meta_filename = \".\".join([input_checkpoint, \"meta\"])\n    saver = tf.train.import_meta_graph(meta_filename)\n    saver.restore(sess, input_checkpoint)\n    scope = FLAGS.scope\n    out_scope = FLAGS.out_scope if FLAGS.out_scope else '%s_%d'%(scope, FLAGS.out_index)\n    output_checkpoint = FLAGS.output_checkpoint \n    with tf.variable_scope(scope) as topscope:\n        src_vars =[v for v in tf.all_variables() if v.name.startswith(topscope.name)]\n    out_vars = {out_scope + v.name[len(scope):v.name.rfind(':')]:v for v in src_vars}\n    tf.train.Saver(var_list=out_vars).save(sess, output_checkpoint)\n    sess.close()\n", "comments": ["well close it , solved\n", "To load model rename scope and save. Right now tensorflow 10.0 has problem with Saver. I see in the master, has commeted the assertion. And if you comment this assertion it works.\ntensorflow/tensorflow/python/training/saver.py\n   # In the following use case, it's possible to have restore_ops be called\n    # something else:\n    # - Build inference graph and export a meta_graph.\n    # - Import the inference meta_graph\n    # - Extend the inference graph to a train graph.\n    # - Export a new meta_graph.\n    # Now the second restore_op will be called \"restore_all_1\".\n    # As such, comment out the assert for now until we know whether supporting\n    # such usage model makes sense.\n    #\n    # assert restore_op.name.endswith(\"restore_all\"), restore_op.name\n"]}, {"number": 4657, "title": "arg_scope overwrite fails for positional arguments", "body": "The code\n\n```\nx = tf.placeholder(tf.float32, [None, 10])\nwith slim.arg_scope([slim.fully_connected], num_outputs=20):\n    y = slim.fully_connected(x, 30)\n```\n\nraises\n\n```\nTypeError: fully_connected() got multiple values for argument 'num_outputs'\n```\n\nThere is an easy workaround, namely changing `30` to `num_outputs=30` seems to work fine.  I'm not sure if this is easy to fix or was even intended to work.\n", "comments": ["I believe the arg_scope will add those to the function calls below. Also:\nThis is a question better suited for StackOverflow. Please ask it there and tag it with the `tensorflow` tag.\n", "I don't see how this addresses the bug of arg_scope not working with positional arguments.  I also don't see how StackOverflow would be appropriate because this is not a question, it's a bug report.\n", "@sguada Please clarify what is your intended behavior. Thanks.\n", "Arg_scope only affect key-word arguments, which have a default value.\n\nOn Oct 2, 2016 8:50 AM, \"Jianmin Chen\" notifications@github.com wrote:\n\n> @sguada https://github.com/sguada Please clarify what is your intended\n> behavior. Thanks.\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/4657#issuecomment-250957042,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/ABr0fEuB5h2UW408ccaAVEmzChGOOD_qks5qv1RMgaJpZM4KKIJB\n> .\n", "The current behavior is somewhere in the middle: arg_scope affects positional arguments, but they cannot be overridden positionally, only by specifying them by name as keyword arguments.  It makes perfect sense to me that a relatively straightforward implementation would lead to this behavior and that it might be much more complicated to either remove the ability of arg_scope to affect positional arguments entirely or to add the ability to override them positionally.  So I think leaving the behavior as is would be reasonable, I just wanted to make sure the developers were aware of it, because the error message is a little confusing if you don't think about how arg_scope could be implemented.\n", "Your assessment is correct. We'll try to clarify behavior via documentation. Thanks for pointing this out!\n"]}, {"number": 4656, "title": "Missing documentation", "body": "Hi,\n\nThe documentation for tf.contrib.learn.LinearRegressor.weights_ is missing. Can you update what the values returned by the above param means?\n\nThank,\nSumit\n", "comments": ["It's probably obvious, but I imagine you're looking for a more rigorous spec such as a formula?  Assigning to @martinwicke to take a look or re-assign if appropriate. \n", "weights_ may actually go away soon, so I wouldn't rely on it. Please use get_tensor_value instead. \n\nOut of interest, what would you be using it for? We're removing it because we didn't feel it was worth it.\n", "Not anything in particular. Was exploring the parameters to understand what model is learning, and had difficulty understanding what the parameters returned by `weights_` meant.\n", "Any idea about how to proceed, @martinwicke @concretevitamin?\n\n```\nAttributeError: 'LinearRegressor' object has no attribute 'get_tensor_value'\n```\n", "Sorry -- I should have said `get_variable_names` and `get_variable_value`.\n"]}, {"number": 4655, "title": "expend the output of CNN", "body": "I am trying to expend the outputs of my network from 11 to 12 outputs, i have restored the previous checkpoint that is already retrained in 11 outputs. I got the answer from  here http://stackoverflow.com/questions/34913762/how-to-expand-a-tensorflow-variable in This question told me how to change the shape of the variable, to expand it to fit another row of weights, but I don't know if i initialize the weight and biases in the right way. Actually i don't have error but the the test accuracy is decreased from 95% to 9%. may be there is somewhere wrong issue in the code. that's the code:\n\n```\n w_b_not = {\n  'weight_4': tf.Variable(tf.random_normal([num_hidden, num_labels], stddev=0.1)),\n  'bias_4'  : tf.Variable(tf.constant(1.0, shape=[num_labels])),}\n\n w_b = {\n  'wc1_0': tf.Variable(tf.random_normal([patch_size_1, patch_size_1, num_channels, depth],stddev=0.1)),\n   .....\n  'bc1_0' : tf.Variable(tf.zeros([depth]))}\n\n .... #here is the networks model\n\n num_steps = 1001 \n with tf.Session(graph=graph) as sess:\n    ckpt = ('path_of_checkpoint.ckpt')\n    if os.path.isfile(ckpt) :\n       layer6_weights = tf.Variable(tf.random_normal([num_hidden, num_labels], stddev=0.1))\n       layer6_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n\n  n_w_b = {\n  'new_layer_weights' : tf.concat(0,[w_b_not['weight_4'], layer6_weights]),\n  'new_layer_biases' : tf.concat(0,[w_b_not['bias_4'], layer6_biases])}\n  resize_var_1 = tf.assign(w_b_not['weight_4'], n_w_b['new_layer_weights'], validate_shape=False)\n  resize_var_2 = tf.assign(w_b_not['bias_4'], n_w_b['new_layer_biases'], validate_shape=False)\n  logits = tf.get_collection('logits')[0]\n  w_b_new_saver = tf.train.Saver()\n  init_op = tf.initialize_all_variables()        \n  w_b_saver.restore(sess, ckpt)\n  print(\"restore complete\")\n  for step in xrange(num_steps):\n    sess.run(init_op)\n  print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval() , test_labels,  force = False ))  \n```\n", "comments": []}, {"number": 4654, "title": "expend the output of CNN", "body": "NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.\n\nFor general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed\nout of scope for GitHub Issues and point people to StackOverflow.\n\nFor bugs or installation issues, please provide the following information.\nThe more information you provide, the more easily we will be able to offer\nhelp and advice.\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\n### Environment info\n\nOperating System:\n\nInstalled version of CUDA and cuDNN: \n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\n\nIf installed from binary pip package, provide:\n1. A link to the pip package you installed:\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\n\nIf installed from source, provide \n1. The commit hash (`git rev-parse HEAD`)\n2. The output of `bazel version`\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\n### What other attempted solutions have you tried?\n### Logs or other output that would be helpful\n\n(If logs are large, please upload as attachment or provide link).\n", "comments": []}, {"number": 4653, "title": "sysmalloc in session.run(tf.initialize_all_variables()) - cuda 8.0 + cudnn 5/5.1 + tensorflow 0.9/0.10", "body": "Hi all\nI recently bought a new Titan X Pascal, and needed to upgrade cuda from 7 to 8.\nAfter updating cuda 7 + cudnn 4 + tensorflow 0.9 -> cuda 8 + cudnn 5 + tensorflow 0.10, my code which used to work fine now crashes with a segfault : \n- with my GPUs on : \n\n```\n/usr/bin/python2.7 /work/repos/qs-lab-cornerdetection/model_noclass.py\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: \nname: TITAN X (Pascal)\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.531\npciBusID 0000:03:00.0\nTotal memory: 11.90GiB\nFree memory: 11.76GiB\nW tensorflow/stream_executor/cuda/cuda_driver.cc:572] creating context when one is currently active; existing: 0x30882d0\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 1 with properties: \nname: GeForce GTX TITAN X\nmajor: 5 minor: 2 memoryClockRate (GHz) 1.076\npciBusID 0000:04:00.0\nTotal memory: 11.92GiB\nFree memory: 11.81GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 0 to device ordinal 1\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 1 to device ordinal 0\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 1 \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y N \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 1:   N Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:0) -> (device: 0, name: TITAN X (Pascal), pci bus id: 0000:03:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GeForce GTX TITAN X, pci bus id: 0000:04:00.0)\npython2.7: malloc.c:2372: sysmalloc: Assertion `(old_top == (((mbinptr) (((char *) &((av)->bins[((1) - 1) * 2])) - __builtin_offsetof (struct malloc_chunk, fd)))) && old_size == 0) || ((unsigned long) (old_size) >= (unsigned long)((((__builtin_offsetof (struct malloc_chunk, fd_nextsize))+((2 *(sizeof(size_t))) - 1)) & ~((2 *(sizeof(size_t))) - 1))) && ((old_top)->size & 0x1) && ((unsigned long) old_end & pagemask) == 0)' failed.\n\nProcess finished with exit code 134 (interrupted by signal 6: SIGABRT)\n```\n- if I restrict to 1 detected device with `os.environ['CUDA_VISIBLE_DEVICES'] = '1'`, it still crashes (with any of my 2 gpus) but with a different signal code: \n\n```\n/usr/bin/python2.7 /work/repos/qs-lab-cornerdetection/model_noclass.py\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: \nname: GeForce GTX TITAN X\nmajor: 5 minor: 2 memoryClockRate (GHz) 1.076\npciBusID 0000:04:00.0\nTotal memory: 11.92GiB\nFree memory: 11.81GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:04:00.0)\n\nProcess finished with exit code 139 (interrupted by signal 11: SIGSEGV)\n```\n- If finally I restrict to CPU only, it works fine.\n\nI verified, both host and docker have the same driver version (367.48 ), cuda is installed correctly (on my host AND in my docker), nvdia-smi correctly finds the 2 GPUs, deviceQuery runs fine (also on the host and inside the docker), cudnn libraries are there, and moreover caffe works just fine on the gpus, which would indicate that my install is indeed correct.\n\nThe problem persists with cudnn 5.1, and on both version of cudnn if i rollback to tensorflow 0.9\n### Environment info\n\nOperating System:\nDocker ubuntu 14.04\n\nInstalled version of CUDA and cuDNN: \n\n```\n-rw-r--r-- 1 root root   558720 Sep 29 09:18 /usr/local/cuda/lib64/libcudadevrt.a\nlrwxrwxrwx 1 root root       16 Sep 29 09:18 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0\nlrwxrwxrwx 1 root root       38 Sep 29 10:01 /usr/local/cuda/lib64/libcudart.so.7.5 -> /usr/local/cuda/lib64/libcudart.so.8.0\nlrwxrwxrwx 1 root root       19 Sep 29 09:18 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44\n-rwxr-xr-x 1 root root   415432 Sep 29 09:18 /usr/local/cuda/lib64/libcudart.so.8.0.44\n-rw-r--r-- 1 root root   775162 Sep 29 09:18 /usr/local/cuda/lib64/libcudart_static.a\nlrwxrwxrwx 1 1000 1000       13 Apr 25 01:19 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.5\nlrwxrwxrwx 1 1000 1000       17 Apr 25 01:19 /usr/local/cuda/lib64/libcudnn.so.5 -> libcudnn.so.5.0.5\n-rwxr-xr-x 1 1000 1000 78065952 Apr 22 19:17 /usr/local/cuda/lib64/libcudnn.so.5.0.5\n```\n\nBut the problem remains with cudnn 5.1\n\nIf installed from binary pip package, provide:\n1. A link to the pip package you installed:\n   `http://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.10.0-cp27-none-linux_x86_64.whl`\n\n(but the problem reproduces with tensorflow 0.9)\n1. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\n\n```\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally\n0.10.0\n```\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\n\nComplicated at this point, but I'm not sure its relevant...\n### What other attempted solutions have you tried?\n\nTried with cudnn-5 and cudnn 5.1, and tensorflow 0.9 / 0.10\n### Logs or other output that would be helpful\n\n(If logs are large, please upload as attachment or provide link).\n", "comments": ["The only thing I'm not sure of is my step\n`ln -sf /usr/local/cuda/lib64/libcudart.so.8.0 /usr/local/cuda/lib64/libcudart.so.7.5`\nbefore compiling tensorflow, because otherwise the compilation fails...\n", "Ok, finally found out that I had to build tensorflow from sources to support cudnn 5.1\nOnce rebuilt, everything works fine.\n"]}, {"number": 4652, "title": "tensorflow running principle ", "body": "1. In tensorflow/python/ops/seq2seq_model.py  line 236 , we see the output_feed cosists of  self.updates and self.gradient_norms.\n   And the self.updates is not used in anywhere, I wonder if I can delete this from output_feed ?\n2. How does the tensorflow run:  If a variable is not in its output_feed list, does tensorflow count this variable ?\n", "comments": ["@KingAndQueen please say which version of tensorflow you're using:\n\nIf installed from binary pip package, provide:\n1. A link to the pip package you installed:\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\n\nIf installed from source, provide \n1. The commit hash (`git rev-parse HEAD`)\n2. The output of `bazel version`\n\nFor basic usage of tensorflow, see the documentation:\nhttps://www.tensorflow.org/versions/r0.11/get_started/basic_usage.html#basic-usage\n\nHope this helps!\n", "Closing for now, because there does not seem to be any bug or enhancement request. Please read the documentation, and if you need specific usage help, you can post on StackOverFlow. Thank you!\n"]}, {"number": 4651, "title": "Distributed tensorflow hangs ", "body": "I set up a distributed tensorflow according to the inception example(https://github.com/tensorflow/models/tree/master/inception/inception), with a very deep network.\nDuring training(minutes or hours), it must run into hanging. No error occurs in ps or workers, but the cpu/gpu usage falls to zero and no any further steps are made.\nIf I replace the network with a much simpler one(much less variables), all things work fine.\nIs there any limit on the amount of vars placed on ps? or any suggestions to deal with the problem?\n\nSetup: tensorflow r0.10 build on cuda 7.5 and cudnn v5 \n", "comments": ["We'll need much more details to diagnose this:\n1. How large is large?  What's the # of vars?\n2. What's your cluster configuration?  Spec of each machine's hardware?\n3. We will need info/error logs and stack traces.\n", "[network.py.txt](https://github.com/tensorflow/tensorflow/files/502540/network.py.txt)\n1. please see the python file.\n2. the cluster is set on 2 servers. each one has a ps and a worker. And each worker works on 4 gpu cards.\n3. nothing unusual appears in logs, all logs were print as I coded until it hangs. I do not have stack details right now, but both ps and workers are on locks, and workers still send messages periodically.  \n", "In order for us to help, we need simple specific steps to reproduce the problem. We're not able to troubleshoot nontrivial scripts. Here's an [example](https://github.com/tensorflow/tensorflow/issues/3978) of an issue that demonstrated a hanging issue which was able to be reproduced and solved. Please feel free to file another issue if necessary.\n", "Have you found the reason? @passerbydj ", "@passerbydj, still meet hang problem using the latest tf version?"]}, {"number": 4650, "title": "Could not create TensorFlow Graph: Not found: ~/graphs/inception/tensorflow_inception_graph.pb", "body": "### Environment info\n\nOperating System: Ubuntu 14.04\n\n**URL:** https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/makefile#building-on-linux\n\nI'm following the \"Building on Linux\", however all commands run fine, but when I've run this following command\n`tensorflow/contrib/makefile/gen/bin/benchmark \\\n --graph=~/graphs/inception/tensorflow_inception_graph.pb`\n\n**Output** on terminal is as following:\n\n`I tensorflow/tools/benchmark/benchmark_model.cc:202] Graph: [~/graphs/inception/tensorflow_inception_graph.pb]\n I tensorflow/tools/benchmark/benchmark_model.cc:203] Input layer: [input:0]\n I tensorflow/tools/benchmark/benchmark_model.cc:204] Input shape: [1,224,224,3]\n I tensorflow/tools/benchmark/benchmark_model.cc:205] Input type: [float]\n I tensorflow/tools/benchmark/benchmark_model.cc:206] Output layer: [output:0]\n I tensorflow/tools/benchmark/benchmark_model.cc:207] Num runs: [50]\n I tensorflow/tools/benchmark/benchmark_model.cc:208] Inter-run delay (seconds): [-1.0]\n I tensorflow/tools/benchmark/benchmark_model.cc:209] Num threads: [-1]\n I tensorflow/tools/benchmark/benchmark_model.cc:210] Benchmark name: []\n I tensorflow/tools/benchmark/benchmark_model.cc:211] Output prefix: []\n I tensorflow/tools/benchmark/benchmark_model.cc:212] Show sizes: [0]\n I tensorflow/tools/benchmark/benchmark_model.cc:51] Loading TensorFlow.\n I tensorflow/tools/benchmark/benchmark_model.cc:58] Got config, 0 devices\n E tensorflow/tools/benchmark/benchmark_model.cc:64] Could not create TensorFlow Graph: Not found: ~/graphs/inception/tensorflow_inception_graph.pb`\n\nWhy at last TensorFlow Graph is not created or found at ~/graphs/inception/tensorflow_inception_graph.pb even that file is there. \n", "comments": ["Hello, \n\nYou have to download the graph and label files as a zip file from [https://storage.googleapis.com/download.tensorflow.org/models/inception5h.zip] and extract the contents to `~/graphs/inception/` folder since you are using the `--graph` flag as `--graph=~/graphs/inception/tensorflow_inception_graph.pb`.\n", "Try to do an `ls -l  ~/graphs/inception/tensorflow_inception_graph.pb` to see if the file is indeed there.\n\nIf so and the error still persists, try to expand \"~\" to the absolute path when launching the program.\n\nFeel free to reopen if there's still issues.\n", "@concretevitamin I've tried `ls -l ~/graphs/inception/tensorflow_inception_graph.pb` and found it there \n`-rw-r----- 1 tushar tushar 53884595 Nov 18  2015 /home/tushar/graphs/inception/tensorflow_inception_graph.pb`\n\neven I can see that file via clicking on that same folder path, but error is same.\n", "@concretevitamin I've found it working when I've change the path to graph relative to current directory rather from home folder.\n", "@tusharsoni08 thanks! works for me. \n"]}, {"number": 4649, "title": "build failed", "body": "Build failed with \n\n```\nbazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\n```\n\n,but\n\n```\nbazel build -c opt //tensorflow/tools/pip_package:build_pip_package\n```\n\n works. Any suggestions? Thanks\n\nHere are the error messages:\n\n```\nERROR: /data1/wenhaojiang/.cache/bazel/_bazel_wenhaojiang/4d6dbdb415b7bb548255a6ccf48e22e6/external/protobuf/BUILD:73:1: undeclared inclusion(s) in rule '@protobuf//:protobuf_lite':\nthis rule is missing dependency declarations for the following files included by 'external/protobuf/src/google/protobuf/stubs/once.cc':\n  '/include/c++/4.8.2/string'\n  '/include/c++/4.8.2/x86_64-redhat-linux/bits/c++config.h'\n  '/include/c++/4.8.2/x86_64-redhat-linux/bits/os_defines.h'\n  '/include/c++/4.8.2/x86_64-redhat-linux/bits/cpu_defines.h'\n  '/include/c++/4.8.2/bits/stringfwd.h'\n  '/include/c++/4.8.2/bits/memoryfwd.h'\n  '/include/c++/4.8.2/bits/char_traits.h'\n  '/include/c++/4.8.2/bits/stl_algobase.h'\n  '/include/c++/4.8.2/bits/functexcept.h'\n  '/include/c++/4.8.2/bits/exception_defines.h'\n  '/include/c++/4.8.2/bits/cpp_type_traits.h'\n  '/include/c++/4.8.2/ext/type_traits.h'\n  '/include/c++/4.8.2/ext/numeric_traits.h'\n  '/include/c++/4.8.2/bits/stl_pair.h'\n  '/include/c++/4.8.2/bits/move.h'\n  '/include/c++/4.8.2/bits/concept_check.h'\n  '/include/c++/4.8.2/type_traits'\n  '/include/c++/4.8.2/bits/stl_iterator_base_types.h'\n  '/include/c++/4.8.2/bits/stl_iterator_base_funcs.h'\n  '/include/c++/4.8.2/debug/debug.h'\n  '/include/c++/4.8.2/bits/stl_iterator.h'\n  '/include/c++/4.8.2/bits/postypes.h'\n  '/include/c++/4.8.2/cwchar'\n  '/lib/gcc/x86_64-redhat-linux/4.8.2/include/stdarg.h'\n  '/lib/gcc/x86_64-redhat-linux/4.8.2/include/stddef.h'\n  '/include/c++/4.8.2/cstdint'\n  '/lib/gcc/x86_64-redhat-linux/4.8.2/include/stdint.h'\n  '/include/c++/4.8.2/bits/allocator.h'\n  '/include/c++/4.8.2/x86_64-redhat-linux/bits/c++allocator.h'\n  '/include/c++/4.8.2/ext/new_allocator.h'\n  '/include/c++/4.8.2/new'\n  '/include/c++/4.8.2/exception'\n  '/include/c++/4.8.2/bits/atomic_lockfree_defines.h'\n  '/include/c++/4.8.2/bits/exception_ptr.h'\n  '/include/c++/4.8.2/bits/nested_exception.h'\n  '/include/c++/4.8.2/bits/localefwd.h'\n  '/include/c++/4.8.2/x86_64-redhat-linux/bits/c++locale.h'\n  '/include/c++/4.8.2/clocale'\n  '/include/c++/4.8.2/iosfwd'\n  '/include/c++/4.8.2/cctype'\n  '/include/c++/4.8.2/bits/ostream_insert.h'\n  '/include/c++/4.8.2/bits/cxxabi_forced.h'\n  '/include/c++/4.8.2/bits/stl_function.h'\n  '/include/c++/4.8.2/backward/binders.h'\n  '/include/c++/4.8.2/bits/range_access.h'\n  '/include/c++/4.8.2/bits/basic_string.h'\n  '/include/c++/4.8.2/ext/atomicity.h'\n  '/include/c++/4.8.2/x86_64-redhat-linux/bits/gthr.h'\n  '/include/c++/4.8.2/x86_64-redhat-linux/bits/gthr-default.h'\n  '/include/c++/4.8.2/x86_64-redhat-linux/bits/atomic_word.h'\n  '/include/c++/4.8.2/initializer_list'\n  '/include/c++/4.8.2/ext/string_conversions.h'\n  '/include/c++/4.8.2/cstdlib'\n  '/include/c++/4.8.2/cstdio'\n  '/include/c++/4.8.2/cerrno'\n  '/include/c++/4.8.2/bits/functional_hash.h'\n  '/include/c++/4.8.2/bits/hash_bytes.h'\n  '/include/c++/4.8.2/bits/basic_string.tcc'\n  '/include/c++/4.8.2/cstddef'\n  '/lib/gcc/x86_64-redhat-linux/4.8.2/include/limits.h'\n  '/lib/gcc/x86_64-redhat-linux/4.8.2/include/syslimits.h'\n  '/include/c++/4.8.2/utility'\n  '/include/c++/4.8.2/bits/stl_relops.h'.\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\nUse --verbose_failures to see the command lines of failed build steps.\nINFO: Elapsed time: 3.151s, Critical Path: 0.87s\n```\n\nCUDA 7.5\ngcc -v\n\n```\nUsing built-in specs.\nCOLLECT_GCC=gcc\nCOLLECT_LTO_WRAPPER=/usr/libexec/gcc/x86_64-redhat-linux/4.8.2/lto-wrapper\nTarget: x86_64-redhat-linux\nConfigured with: ../configure --prefix=/usr --mandir=/usr/share/man --infodir=/usr/share/info --with-bugurl=http://bugzilla.redhat.com/bugzilla --enable-bootstrap --enable-shared --enable-threads=posix --enable-checking=release --with-system-zlib --enable-__cxa_atexit --disable-libunwind-exceptions --enable-gnu-unique-object --enable-linker-build-id --with-linker-hash-style=gnu --enable-languages=c,c++,objc,obj-c++,java,fortran,ada,go,lto --enable-plugin --enable-initfini-array --disable-libgcj --with-isl=/builddir/build/BUILD/gcc-4.8.2-20140120/obj-x86_64-redhat-linux/isl-install --with-cloog=/builddir/build/BUILD/gcc-4.8.2-20140120/obj-x86_64-redhat-linux/cloog-install --enable-gnu-indirect-function --with-tune=generic --with-arch_32=x86-64 --build=x86_64-redhat-linux\nThread model: posix\ngcc version 4.8.2 20140120 (Red Hat 4.8.2-16) (GCC)\n```\n\nbazel version\n\n```\nBuild label: 0.3.1-jdk7\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\nBuild time: Fri Jul 29 09:07:03 2016 (1469783223)\nBuild timestamp: 1469783223\n```\n\noutput of `echo | gcc -E -xc++ - -v`:\n\n```\nUsing built-in specs.\nCOLLECT_GCC=gcc\nTarget: x86_64-redhat-linux\nConfigured with: ../configure --prefix=/usr --mandir=/usr/share/man --infodir=/usr/share/info --with-bugurl=http://bugzilla.redhat.com/bugzilla --enable-bootstrap --enable-shared --enable-threads=posix --enable-checking=release --with-system-zlib --enable-__cxa_atexit --disable-libunwind-exceptions --enable-gnu-unique-object --enable-linker-build-id --with-linker-hash-style=gnu --enable-languages=c,c++,objc,obj-c++,java,fortran,ada,go,lto --enable-plugin --enable-initfini-array --disable-libgcj --with-isl=/builddir/build/BUILD/gcc-4.8.2-20140120/obj-x86_64-redhat-linux/isl-install --with-cloog=/builddir/build/BUILD/gcc-4.8.2-20140120/obj-x86_64-redhat-linux/cloog-install --enable-gnu-indirect-function --with-tune=generic --with-arch_32=x86-64 --build=x86_64-redhat-linux\nThread model: posix\ngcc version 4.8.2 20140120 (Red Hat 4.8.2-16) (GCC)\nCOLLECT_GCC_OPTIONS='-E' '-v' '-mtune=generic' '-march=x86-64'\n /usr/libexec/gcc/x86_64-redhat-linux/4.8.2/cc1plus -E -quiet -v -D_GNU_SOURCE - -mtune=generic -march=x86-64\nignoring nonexistent directory \"/usr/lib/gcc/x86_64-redhat-linux/4.8.2/include-fixed\"\nignoring nonexistent directory \"/usr/lib/gcc/x86_64-redhat-linux/4.8.2/../../../../x86_64-redhat-linux/include\"\n#include \"...\" search starts here:\n#include <...> search starts here:\n /usr/lib/gcc/x86_64-redhat-linux/4.8.2/../../../../include/c++/4.8.2\n /usr/lib/gcc/x86_64-redhat-linux/4.8.2/../../../../include/c++/4.8.2/x86_64-redhat-linux\n /usr/lib/gcc/x86_64-redhat-linux/4.8.2/../../../../include/c++/4.8.2/backward\n /usr/lib/gcc/x86_64-redhat-linux/4.8.2/include\n /usr/local/include\n /usr/include\nEnd of search list.\n#1 \"<stdin>\"\n#1 \"<command-line>\"\n#1 \"/usr/include/stdc-predef.h\" 1 3 4\n#1 \"<command-line>\" 2\n#1 \"<stdin>\"\nCOMPILER_PATH=/usr/libexec/gcc/x86_64-redhat-linux/4.8.2/:/usr/libexec/gcc/x86_64-redhat-linux/4.8.2/:/usr/libexec/gcc/x86_64-redhat-linux/:/usr/lib/gcc/x86_64-redhat-linux/4.8.2/:/usr/lib/gcc/x86_64-redhat-linux/\nLIBRARY_PATH=/usr/lib/gcc/x86_64-redhat-linux/4.8.2/:/usr/lib/gcc/x86_64-redhat-linux/4.8.2/../../../../lib64/:/lib/../lib64/:/usr/lib/../lib64/:/usr/lib/gcc/x86_64-redhat-linux/4.8.2/../../../:/lib/:/usr/lib/\nCOLLECT_GCC_OPTIONS='-E' '-v' '-mtune=generic' '-march=x86-64'\n```\n", "comments": ["Same here also on centos 7. And I've tried with gcc 4.9 from SCL with same (bad) result.\nCuda 7.5 (/usr/local/cuda-7.5)\nCudnn 5.1.3 (which is installed in my home folder, as tell to th configure script)\n", "@cswhjiang @kadafax take a look at #3985 and let me know if that fixes things.\n", "thanks. The problem was solved by using `/usr/bin/gcc` instead of `/bin/gcc` in `./configure` \n", "Still failling:\n\nCentos 7\n$ gcc --version\ngcc (GCC) 4.8.3 20140911 (Red Hat 4.8.3-9)\n$ bazel version\nBuild label: 0.3.1-2016-10-05 (@27cd7f6)\nBuild target: bazel-out/local-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\nBuild time: Wed Oct 5 14:02:43 2016 (1475676163)\nBuild timestamp: 1475676163\nBuild timestamp as int: 1475676163\n\nCUDA 7.5 (/usr/local/cuda-7.5)\n\n## CUDNN 5.1.3 (in my home folder)\n\n./configure:\n\n> [kadafax@GPUNODE1 tensorflow]$ ./configure\n> /home/kadafax/corner/tarballs/tensorflow /home/kadafax/corner/tarballs/tensorflow\n> Please specify the location of python. [Default is /bin/python]:\n> Do you wish to build TensorFlow with Google Cloud Platform support? [y/N]\n> No Google Cloud Platform support will be enabled for TensorFlow\n> Do you wish to build TensorFlow with Hadoop File System support? [y/N]\n> No Hadoop File System support will be enabled for TensorFlow\n> Found possible Python library paths:\n>   /usr/lib/python2.7/site-packages\n>   /usr/lib64/python2.7/site-packages\n> Please input the desired Python library path to use.  Default is [/usr/lib/python2.7/site-packages]\n> \n> /usr/lib/python2.7/site-packages\n> Do you wish to build TensorFlow with GPU support? [y/N] Y\n> GPU support will be enabled for TensorFlow\n> Please specify which gcc should be used by nvcc as the host compiler. [Default is /usr/lib64/ccache/gcc]: /usr/bin/gcc\n> Please specify the Cuda SDK version you want to use, e.g. 7.0. [Leave empty to use system default]: 7.5\n> Please specify the location where CUDA 7.5 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: /usr/local/cuda-7.5\n> Please specify the Cudnn version you want to use. [Leave empty to use system default]: 5.1.3\n> Please specify the location where cuDNN 5.1.3 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda-7.5]: /home/kadafax/corner\n> Please specify a list of comma-separated Cuda compute capabilities you want to build with.\n> You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\n> Please note that each additional compute capability significantly increases your build time and binary size.\n> [Default is: \"3.5,5.2\"]: 3.7,3.5\n> Extracting Bazel installation...\n> Killed non-responsive server process (pid=1228)\n> ............\n> INFO: Starting clean (this may take a while). Consider using --expunge_async if the clean takes more than several minutes.\n> .........\n> INFO: All external dependencies fetched successfully.\n> Configuration finished\n\nbazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package:\n\n> ERROR: /home/kadafax/corner/tarballs/tensorflow/tensorflow/stream_executor/BUILD:5:1: C++ compilation of rule '//tensorflow/stream_executor:stream_executor' failed: crosstool_wrapper_dr\n> iver_is_not_gcc failed: error executing command external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -\n> Wunused-but-set-parameter ... (remaining 114 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\n> tensorflow/stream_executor/cuda/cuda_dnn.cc: In instantiation of 'cudnnStatus_t perftools::gputools::cuda::dynload::DynLoadShim__cudnnSetRNNDescriptor::operator()(perftools::gputools::cuda::CUDAExecutor\n> _, Args ...) [with Args = {cudnnRNNStruct_, int, int, cudnnDropoutStruct_, cudnnRNNInputMode_t, cudnnDirectionMode_t, cudnnRNNMode_t, cudnnDataType_t}]':\n> tensorflow/stream_executor/cuda/cuda_dnn.cc:1005:50:   required from here\n> tensorflow/stream_executor/cuda/cuda_dnn.cc:166:38: error: invalid conversion from 'cudnnDropoutStruct_' to 'int' [-fpermissive]\n", "@kadafax that looks like a different problem.  Here's how to look for similar issues:\n\nhttps://github.com/issues?utf8=%E2%9C%93&q=is%3Aissue+repo%3Atensorflow%2Fmodels+repo%3Atensorflow%2Ftensorflow+crosstool_wrapper_driver_is_not_gcc\n\nIn particular, #4705 and #4105 seem related.  You can try running bazel clean and fetch after ./configure, and see if that fixes things.  Details in the referenced issues.\n", "OK thanks. Got it working.\n\nFor the records:\n- tell the configure.sh script to use /usr/bin/gcc \n- put cuda 7.5 and cudnn 5.1.3 in the same folder (can be in $HOME)\n- export CC=/usr/bin/gcc\n- modify third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc.tpl by adding the following line (showed by a + sign below):\n  \n  +cpu_compiler_flags.append('-fno-use-linker-plugin')\n    return subprocess.call([CPU_COMPILER] + cpu_compiler_flags)\n", "Cool, glad it's working.  Closing this out, but feel free to comment or file a new issue if you run into other problems.\n"]}, {"number": 4648, "title": "tf.contrib.learn.estimator each call to predict() reloads the model", "body": "### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\n\nNone\n### Environment info\n\nOperating System:\nOSX & Ubuntu 14.04\n### If possible, provide a minimal reproducible example - Explanation\n\nEach call to estimator.predict() completely reloads the model, which is very slow. Is there any mechanism to maintain the model in GPU/memory for consecutive calls? \n\nI understand that large arrays can be passed to the function for simultaneous predictions, but my use case is for slowly arriving data which must be processed quickly. Is there a mechanism for decreasing the 'start-up' time of this function?\n### What other attempted solutions have you tried?\n\nLooked through API docs & source code for alternative solutions\n###### \n", "comments": ["I discussed this issue briefly with Martin Wicke on the mailing list: https://groups.google.com/a/tensorflow.org/forum/#!topic/discuss/rOP4VKcfphg .\n\nIt seems that this use case is not supported OOB. \n\nThe ability to persistently load a model into memory for multiple predict calls would be a very useful enhancement.\n", "Hi @ashern \r\nDid you find a workaround? Anything that prevents reloading the model on each predict call?", "I have modified estimator.py (Added my own predict function in BaseEstimator class). It's working for me. It's available [here](https://github.com/ahmed-18/tensorflow/tree/master/tf.contrib.learn) for anyone's use. ", "In case someone else runs into this, predict can take a generator as a parameter. \r\n\r\nHere's a class that wraps an estimator with a generator. This means you can make multiple calls to predict without reloading the graph.\r\n\r\nhttps://github.com/marcsto/rl/blob/master/src/fast_predict.py", "Hi Marc, with the deprecation of sklearn compatibility in recent versions, how do you see the required changes? I tried wrapping the estimator with SKCompat to keep using x as argument but then I have problems down the line. It seems to me that keeping input_fn open as a generator would make perfect sense, especially for big (and streaming) data (not relying only on parsing TFrecords and such)", "Hi guys, I have trained my cnn model with `tf.estimator` and `tf.data` API. Model's input is an one-shot iterator. The relative model files(ckpt, meta, index) have been saved in `model_dir`. **Now I want to predict one or more images' label using the trained model.**\r\n\r\nAny instructions for this?", "I'd like to second (or third?) that, it would be absolutely useful to have an out-of-the-box way to do multiple predictions asynchronously with the same graph in memory. @marcsto 's solution (fast_predict.py) is not working for me in TF 1.4.0. \r\n\r\nI also found this suggestion: \r\n\r\nhttps://stackoverflow.com/questions/45111480/how-to-run-asynchronous-predictions-with-tensorflow-estimator-api\r\n\r\nWhich is not working for me sadly (seems to have worked in TF 1.2.1)", "Has anyone come up with a similar solution for a tensorflow estimator.Estimator object? ", "@j3ven7 I wrote a example using `tf.estimator`, whick separate the train and predict process in different python file. You can see [secsilm/understaing-datasets-estimators-tfrecords](https://github.com/secsilm/understaing-datasets-estimators-tfrecords). There is a chinese README.md, but the two main python files are [cifar10_estimator_dataset.py](https://github.com/secsilm/understaing-datasets-estimators-tfrecords/blob/master/cifar10_estimator_dataset.py) for train and [cifar10_estimator_dataset_predict.py](https://github.com/secsilm/understaing-datasets-estimators-tfrecords/blob/master/cifar10_estimator_dataset_predict.py) for predict. \r\n\r\nHope it helps you.", "@secsilm Does the code you wrote address the issue regarding the model re-loading on each predict? Or is this strictly a tutorial on how to train and predict?", "@j3ven7 I don't know whether it's a right solution or not. I combine 10 images to an numpy array and pass it to the predict function in my code. But the point is, I think tensorflow will reload the model in different run. Might not solve your problem? For reference only. \ud83d\ude04 ", "I updated fast_predict2.py to support tensorflow 1.4 and later. I hope it helps!\r\nhttps://github.com/marcsto/rl/blob/master/src/fast_predict2.py", "@marcsto  fast_predict test file is still old, can u please fix it.Any idea on how can we pass pandas df to it", "Thanks to @marcsto, I got this working for a DNNClassifier that's using several numeric feature columns. I found it a bit tricky to figure out exactly how to set up the generator, so there's a gist here: \r\n\r\nhttps://gist.github.com/mikeoconnor0308/521ae2eb1555edc6550014ce0500e6a2\r\n\r\n", "@mikeoconnor0308 @marcsto thanks, this is exactly the issue I've been facing!", "another way can work around this problem,  you can define a \"input_fn\" with a dataset , and you can use dataset.from_generator(generator, ****),  in the definition of 'generator' you can use yield after read from outside queue , such as Kafka\u3002and estimator predict also return an generator. You can get the result from the predict result generator supply to the caller ", "@marcsto I tried using your script and wanted the model to use a batch size of more than 1 and hence changed - `.batch(1)` to `.batch(batch_size)`.\r\nFor some reason the model does not receive new input on subsequent calls and the outputs from the model are completely destroyed on any call after the first call. If I send the same input in subsequent calls as the first call, then the output is fine. I am guessing there is some kind of flushing out of data that I need to do but I am not sure why that would be needed. Any pointers?"]}, {"number": 4647, "title": "Fix gcs_test issues", "body": "1) pip install issue related to recent numpy upgrade\n2) OutOfRange package issue caused by recent changes in TF Python code\n", "comments": ["@caisq, thanks for your PR! By analyzing the annotation information on this pull request, we identified @martinwicke to be a potential reviewer\n"]}, {"number": 4646, "title": "Make whl file URL in dist_test Dockerfiles configurable", "body": "", "comments": ["@caisq, thanks for your PR! By analyzing the annotation information on this pull request, we identified @vrv and @gunan to be potential reviewers\n", "Ping @gunan \n"]}, {"number": 4645, "title": "Branch 134608953", "body": "", "comments": []}, {"number": 4644, "title": "Add cuDNN 5.0 support to release notes.", "body": "", "comments": ["@gunan, thanks for your PR! By analyzing the annotation information on this pull request, we identified @vrv, @tensorflower-gardener and @ilblackdragon to be potential reviewers\n"]}, {"number": 4643, "title": "Inf/Nan in MSE/CE with very simple demo", "body": "Hi there,\n\nI would use a very simple LSTM demo with only forward without any BP tuning to clear the question. I pass one random batch of size (2,2,3) to a rnn_cell.LSTMcell, using 100 hidden layer, and output the mse/ce between the output and the last time step (:, -1, :). What strike me is the both the SE/CE are very strange (too large or even inf).\n\nBelow is my code.\n\n```\nimport tensorflow as tf\nimport numpy as np\n\n\nn_steps = 2\nn_visible = 3\nn_hidden = 100\n\nx = tf.placeholder(tf.float64, [None, n_steps, n_visible])\nx_ = tf.placeholder(tf.float64, [None, n_steps, n_visible])\nbatch_size = tf.placeholder(tf.int32)\n\nlow = - 4 * np.sqrt(6. / (n_hidden + n_visible))\nhigh = 4 * np.sqrt(6. / (n_hidden + n_visible))\n\n\nW2 = tf.Variable(tf.random_uniform([n_hidden ,n_visible], minval=low, maxval=high, dtype=tf.float64))\n\nb2 = tf.Variable(tf.zeros(n_visible, dtype = tf.float64))\n\n\nlstm_cell = tf.nn.rnn_cell.LSTMCell(n_hidden, state_is_tuple = True, forget_bias=1.)\ninitial_state = lstm_cell.zero_state(batch_size, tf.float64)\nstate = initial_state\n\ninputs = [tf.squeeze(input_, [1])  for input_ in tf.split(1, n_steps, x)]\nencoder = tf.nn.rnn(lstm_cell, inputs, initial_state=initial_state)\ndecoder = tf.nn.sigmoid(tf.matmul(encoder[-1][0], W2) + b2)\n\nce = -x[:,-1,:] * tf.log(decoder)+(1-x[:,-1,:])*tf.log(1 - decoder)\nse = (x[:,-1,:] - decoder)**2\nmse = tf.reduce_mean(se)\nrmse = tf.sqrt(mse)\n\n\nsess = tf.Session()\nsess.run(tf.initialize_all_variables())\nx_train_batch = np.random.rand(2,2,3)\nfeed_dict = {x: x_train_batch, x_:x_train_batch, batch_size: 2}\nencoder_, decoder_, se_, mse_, rmse_, ce_=  sess.run([encoder, decoder, se, mse, rmse, ce], feed_dict=feed_dict)\n\n```\n\nThe outputs are:\n\n```\nce_\nOut[2]: \narray([[ -9.30480083e-001,  -7.45718134e-001,   1.65488117e+243],\n       [ -8.92276217e-001,  -7.66764460e-001,   5.43823895e+064]])\n\nse_\nOut[3]: \narray([[  3.66794556e-001,   2.76262193e-001,               inf],\n       [  3.48428030e-001,   2.86745693e-001,   1.23185516e+129]])\n\ndecoder_\nOut[4]: \narray([[ 0.60563566,  0.5256065 ,  0.62439037],\n       [ 0.59027793,  0.53548641,  0.69399984]])\n\nx_train_batch[:,-1,:]\nOut[5]: \narray([[ 0.93217308,  0.28895401,  0.31784797],\n       [ 0.57656244,  0.73494513,  0.57125778]])\n\n```\n\nThe value of decoder and x seems well, but why ce_ and se_ has inf and some weird value like 1.23E+129?\n\nIt is running on a Mac OS EI Captain 64 bit without GPU support.\n\n```\ntf.__version__\nOut[6]: '0.10.0'\n```\n", "comments": ["After upgrade to version 0.10.0rc0,  this would not happen again... I would close this issue.\n"]}, {"number": 4642, "title": "Update instructions for installing protobuf package.", "body": "To triage #3856 \n", "comments": ["@gunan, thanks for your PR! By analyzing the annotation information on this pull request, we identified @omtcyfz, @keveman and @vrv to be potential reviewers\n", "Probably even more than upgrade, you have to uninstall first otherwise pip\nmay not install anything find you have 3.0.0 already.\nOn Thu, Sep 29, 2016 at 01:23 Jonathan Hseu notifications@github.com\nwrote:\n\n> ## _@jhseu_ commented on this pull request.\n> \n> In tensorflow/g3doc/get_started/os_setup.md\n> https://github.com/tensorflow/tensorflow/pull/4642#pullrequestreview-2073555\n> :\n> \n> > +If your system/configuration is not listed above, you can use the following\n> > +instructions to build your own protobuf wheel file.\n> > +To install its prerequisites, [see\n> > +here](https://github.com/google/protobuf/blob/master/src/README.md):\n> > +\n> > +Then:\n> > +```bash\n> > +$ git clone https://github.com/google/protobuf.git\n> \n> +$ cd protobuf\n> +$ ./autogen.sh\n> +$ CXXFLAGS=\"-fPIC -g -O2\" ./configure\n> +$ make -j12\n> +$ export PROTOC=$PWD/src/protoc\n> +$ cd python\n> +$ python setup.py bdist_wheel --cpp_implementation --compile_static_extension\n> +$ pip install dist/<wheel file name>\n> \n> pip3 install --upgrade ?\n> \n> \u2014\n> You are receiving this because you were assigned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/pull/4642#pullrequestreview-2073555,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AAjO_aFnU9NHQQHH2ZiOn82CztbkP99rks5qu0tfgaJpZM4KJd46\n> .\n", "simply pip uninstall, then pip install?\n", "That's what I'm thinking but I can't test it right now. Not sure if we need\nsomething like apt's --purge.\nOn Thu, Sep 29, 2016 at 01:37 gunan notifications@github.com wrote:\n\n> simply pip uninstall, then pip install?\n> \n> \u2014\n> You are receiving this because you were assigned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/pull/4642#issuecomment-250374485,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AAjO_S4JrxYugGmhbBmsqpLfskLe3Nj9ks5qu06WgaJpZM4KJd46\n> .\n", "@martinwicke you are right about uninstall and reinstall. Exactly what I did to get it work - and it's a good habit too.\n"]}]