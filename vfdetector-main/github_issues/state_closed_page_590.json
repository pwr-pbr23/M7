[{"number": 35977, "title": "windows build failed with master branch", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 x64\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: master 2.1.0\r\n- Python version: 3.7.6\r\n- Installed using virtualenv? pip? conda?: N/A\r\n- Bazel version (if compiling from source): 1.2.1\r\n- GCC/Compiler version (if compiling from source):  Visual Studio 2019 C++ compiler\r\n- CUDA/cuDNN version: 10.2 / 7.6.5\r\n- GPU model and memory:\r\n\r\nRTX2080Ti GDDR6 11GB\r\n\r\n\r\n\r\n**Describe the problem**\r\nbazel build failed\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nbazel build //tensorflwo/tools/pip_package:build_pip_package\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n```\r\nERROR: D:/repo/tensorflow/tensorflow/BUILD:867:1: Executing genrule //tensorflow:tf_python_api_gen_v2 failed (Exit 1)\r\nC:\\Anaconda3\\lib\\site-packages\\numpy\\__init__.py:140: UserWarning: mkl-service package failed to import, therefore Intel(R) MKL initialization ensuring its correct out-of-the box operation under condition when Gnu OpenMP had already been loaded by Python process is not assured. Please install mkl-service package, see http://github.com/IntelPython/mkl-service\r\n  from . import _distributor_init\r\nTraceback (most recent call last):\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\numpy\\core\\__init__.py\", line 24, in <module>\r\n    from . import multiarray\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\numpy\\core\\multiarray.py\", line 14, in <module>\r\n    from . import overrides\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\numpy\\core\\overrides.py\", line 7, in <module>\r\n    from numpy.core._multiarray_umath import (\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"\\\\?\\C:\\Users\\ALAN-W~1\\AppData\\Local\\Temp\\Bazel.runfiles_t25kvwuy\\runfiles\\org_tensorflow\\tensorflow\\python\\tools\\api\\generator\\create_python_api.py\", line 27, in <module>\r\n    from tensorflow.python.tools.api.generator import doc_srcs\r\n  File \"\\\\?\\C:\\Users\\ALAN-W~1\\AppData\\Local\\Temp\\Bazel.runfiles_t25kvwuy\\runfiles\\org_tensorflow\\tensorflow\\python\\__init__.py\", line 48, in <module>\r\n    import numpy as np\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\numpy\\__init__.py\", line 142, in <module>\r\n    from . import core\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\numpy\\core\\__init__.py\", line 54, in <module>\r\n    raise ImportError(msg)\r\nImportError:\r\n\r\nIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\r\n\r\nImporting the numpy c-extensions failed.\r\n- Try uninstalling and reinstalling numpy.\r\n- If you have already done that, then:\r\n  1. Check that you expected to use Python3.7 from \"C:\\Anaconda3\\python.exe\",\r\n     and that you have no directories in your PATH or PYTHONPATH that can\r\n     interfere with the Python and numpy version \"1.18.1\" you're trying to use.\r\n  2. If (1) looks fine, you can open a new issue at\r\n     https://github.com/numpy/numpy/issues.  Please include details on:\r\n     - how you installed Python\r\n     - how you installed numpy\r\n     - your operating system\r\n     - whether or not you have multiple versions of Python installed\r\n     - if you built from source, your compiler versions and ideally a build log\r\n\r\n- If you're working with a numpy git repository, try `git clean -xdf`\r\n  (removes all files not under version control) and rebuild numpy.\r\n\r\nNote: this error has many possible causes, so please don't comment on\r\nan existing issue about this - open a new one instead.\r\n\r\nOriginal error was: DLL load failed: The specified module could not be found.\r\n\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nERROR: D:/repo/tensorflow/tensorflow/tools/pip_package/BUILD:229:1 Executing genrule //tensorflow:tf_python_api_gen_v2 failed (Exit 1)\r\n```\r\n", "comments": ["some said this should be related to numpy environment, but branch r2.1 had no problem building tensorflow, and suddenly this came out with migration to master ( which accompanies bazel 1.2.1 )\r\n\r\nBTW, last time I had numpy 1.18.1(in conda environment)", "@alanpurple, Tensorflow 2.1 supports numpy =1.17.5.\r\nPlease take a look at similar issue [#35036](https://github.com/tensorflow/tensorflow/issues/35036)", "@gadagashwini \r\n\r\nsetup.py says\r\n\r\n'numpy >= 1.16.0, < 2.0'", "@alanpurple,\r\nJust to verify, did you install multiple versions of numpy. ", "@gadagashwini \r\n\r\nof course not.\r\n\r\nI've checked several times", "@ymodak \r\n\r\nafter update another error came up.\r\nthis time, short and brief\r\n\r\n```\r\nERROR: D:/repo/tensorflow/tensorflow/lite/core/api/BUILD:9:1: C++ compilation of rule '//tensorflow/lite/core/api:api' failed (Exit 2)\r\ncl : Command line error D8021 : invalid numeric argument '/Wsign-compare'\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 789.391s, Critical Path: 59.28s\r\nINFO: 1173 processes: 1173 local.\r\nFAILED: Build did NOT complete successfully\r\n```", "@alanpurple have you found a final solution? \r\n\r\n> @ymodak\r\n> \r\n> after update another error came up.\r\n\r\nCould you please tell what exactly did you updated?\r\n\r\nThanks", "@gsdaemon \r\nwhat i meant was \"git pull\" in master", "2/2/2020\r\n\r\nstill numpy error", "I've reinstalled whole anaconda environment, but still same error.\r\n\r\nsimple 'import numpy' with python works fine, but emit error only with tensorflow build", "solved.\r\n\r\nuninstall conda numpy and install numpy with pip fixed this issue\r\n\r\ntensorflow build has some problem with conda environment recently ( branch 2.1 was fine )", "I am also suffering from the same problem with compiling tf2.2.0rc0 on windows.\r\n\r\nIt seems like somehow the PATH variable is not used correctly for that build.....\r\n\r\nNumpy works fine on my Windows but if you do `$env:PATH=\"\"` to reset the PATH variable as empty in your current terminal, and then call python with full path to start python (since your PATH variable is empty now so you need to call python with full path), and then `import numpy`, you will get the exact same error", "is this ever gonna be fixed?(is it possible?) I'm just curious", "I cannot reproduce the issue you are seeing, that is why this is taking so long.\r\n\r\n@jjhelmus do you know of any conda + bazel experts who may be able to help with this issue?", "@gunan \r\n\r\nstill happens with fresh windows 10 2004 installation + anaconda3-2020.07", "I am guessing this is a problem where in anaconda installation numpy headers end up in a different location.\r\nAs we do not build/test with anaconda, I would have to defer to anaconda TF maintainers.\r\n\r\n@ymodak do we have a pointer to anaconda issue tracker?", "The `_multiarray_umath` import error is supposedly fixed by putting `Library\\bin` of the Anaconda env in `PATH` according to [this](https://github.com/numpy/numpy/issues/14770). But bazel overwrites `PATH` before invoking the script so doing that won't solve this issue.\r\n\r\n```sh\r\nERROR: C:/users/rafael/source/repos/open-source/tensorflow/tensorflow/BUILD:1031:19: Executing genrule //tensorflow:tf_python_api_gen_v2 failed (Exit 1): bash.exe failed: error executing command\r\n  cd C:/users/rafael/_bazel_rafael/y6bxy5a7/execroot/org_tensorflow\r\n  SET CUDA_TOOLKIT_PATH=C:/Local/CUDA/v11.1\r\n    SET PATH=C:\\Users\\Rafael\\AppData\\Local\\Programs\\msys64\\usr\\bin;C:\\Users\\Rafael\\AppData\\Local\\Programs\\msys64\\bin;C:\\WINDOWS;C:\\WINDOWS\\System32;C:\\WINDOWS\\System32\\WindowsPowerShell\\v1.0\r\n    SET PYTHON_BIN_PATH=C:/Local/Miniconda3/envs/ml/python.exe\r\n    SET PYTHON_LIB_PATH=C:/Local/Miniconda3/envs/ml/lib/site-packages\r\n    SET RUNFILES_MANIFEST_ONLY=1\r\n    SET TF2_BEHAVIOR=1\r\n    SET TF_CONFIGURE_IOS=0\r\n    SET TF_CUDA_COMPUTE_CAPABILITIES=6.1\r\n    SET TF_NEED_CUDA=1\r\n  C:/Users/Rafael/AppData/Local/Programs/msys64/usr/bin/bash.exe bazel-out/x64_windows-opt/bin/tensorflow/tf_python_api_gen_v2.genrule_script.sh\r\n```\r\n\r\nNoticing that `msys64\\bin` is nonexistent, I made such a folder and copied the contents of `Library\\bin`, `Scripts` and the dll's at the root of the env there to make it build successfully (v2.4.0rc1). For some reason, `Library\\bin` alone is not enough.", "Hi @alanpurple , Could you try with tested configuration mentioned here in this [link ](https://www.tensorflow.org/install/source_windows#gpu) .  ", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35977\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35977\">No</a>\n"]}, {"number": 35976, "title": "Add Usage Example for Keras Nadam Optimizer", "body": "", "comments": ["@jedlimlx thank you, it is failing doctest can you please check here for [logs](https://source.cloud.google.com/results/invocations/7304655e-a12c-4555-8997-4d0bbdeb7b67/targets/%2F%2Ftensorflow%2Ftools%2Fdocs:tf_doctest/tests).\r\n\r\nPlease run the doctest locally as mentioned here in the [contributor guidelines](https://www.tensorflow.org/community/contribute/docs_ref).", "@jedlimlx please raise your PR against master, we only accept security fixes to release branch. Thank you."]}, {"number": 35975, "title": "ResNet model in keras and tf.keras give different output for the same image", "body": "For a given image, I'm extracting ResNet features i.e. after all conv layers and global max pooling, which gives a 2048 length vector per image. \r\n\r\nEarlier, I was using `keras==2.3.1` with backend `tensorflow==1.13.1`. Now, I've shifted to `tensorflow==2.0.0` since keras has been merged with tensorflow. I replaced my code with `tf.keras` instead of `keras`.\r\n\r\nBut now the features extracted are not the same as the features extracted earlier. ResNet is a model which is independent of tensorflow/keras or even pytorch for that matter. It's functionality is predefined. Why is this difference occuring? Are there any parameters that can be tweaked to get the same functionality?\\\r\n\r\n```\r\n    from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\r\n    resnet_model = ResNet50(include_top=False)\r\n```", "comments": ["@NagabhushanSN95 ,\r\nYou can refer this [SO link ](https://stackoverflow.com/questions/59783361/resnet-model-in-keras-and-tf-keras-give-different-output-for-the-same-image)for the solution. Please feel free to close the issue if its resolved.Thanks!", "Thanks. Would it be possible to add a parameter to load original ResNet weights?", "@NagabhushanSN95 \r\nThis question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged//tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n", "No. I'm asking for a feature request.\r\nIs it possible to provide a flag or parameter to make ResNet model use the weights from original ResNet model?", "Is this still an issue? Can you try with latest version of tensorflow keras? Thanks!\r\n"]}, {"number": 35974, "title": "[tflite] add Hexagon delegate to label_image", "body": "add Hexagon Delegte support to label_image and remove unnecessary\r\ndepependency in //tensorflow/lite/examples/label_image/BUILD", "comments": ["@karimnosseir OK, I'll add a usage example."]}, {"number": 35973, "title": "Script fix", "body": "", "comments": []}, {"number": 35972, "title": "[ROCm] Enabling several cwise op kernels", "body": "This PR enables on the ROCm platform:\r\n\"Div\", \"RealDiv\", \"DivNoNan\", \"MulNoNan\" for complex\r\n\"xlogy\" for float, half, double\r\nBenchmark tests for DivNoNan and Cube", "comments": []}, {"number": 35971, "title": "[ROCm] GpuManagedAllocator and common_runtime unit tests", "body": "This PR:\r\nImplements GpuManagedAllocator for ROCm\r\nEnables several core/common-runtime unit tests", "comments": []}, {"number": 35970, "title": "Allow relative min_delta for EarlyStopping", "body": "**System information**\r\n- TensorFlow version (you are using): 2.1.0\r\n- Are you willing to contribute it (Yes/No): maybe\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nCurrently the [EarlyStopping callback](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping) `min_delta` is an absolute value. Meaning that the metric being monitored must improve by that fixed amount. The proposal is to add the ability to use a relative threshold instead (e.g. a ratio or percentage).\r\n\r\nAn example use case is probably easier to understand. Lets say we're doing a hyperparameter search, so we're running a bunch of different models, and we want to stop early on the bad ones. On good models our loss value is in the single digits. So we set the parameters `baseline=50` (a little high so that we allow models to start off somewhat bad), and `min_delta=0.1`. Now with this, if a model gets under 50, but drops to just 48.9, that'll keep it from triggering the abort threshold. If this were instead a ratio, such that `min_delta=0.1` means `10%`, the loss would have to go from 50 to 45 to keep it from triggering, and a good model at say 1.2 would only have to drop to 1.08.\r\n\r\nNow we could try other approaches to address this problem, such as lowering `baseline`, and increasing `patience` (allowing bad starts a little longer to come down further), but by increasing patience, this increases the amount of time we have to wait for good models to stop as well.\r\n\r\n&nbsp;\r\n\r\nInstead of adding a flag for toggling whether `min_delta` is absolute or relative, I think it might be better to allow the user to provide their own \"is this new value good enough\" function/lambda. Currently you can technically override `EarlyStopping.monitor_op`, but it's clearly not designed to operate that way as the arguments to `monitor_op` aren't simple \"best\" and \"current\" values, and there's also code which directly checks whether `monitor_op == np.less`, which overriding breaks.\r\n\r\nSo ultimately the request is to either add a new argument to the initializer accepting the signature `(current:float, best:float) -> bool`, or adjust the code to allow overriding `monitor_op` with that signature.\r\n\r\n**Will this change the current api? How?**\r\nMaybe, if the direction is to add an additional parameter to the initializer.\r\n\r\n**Who will benefit with this feature?**\r\nThose doing hyperparameter searches, or potentially other cases.\r\n\r\n**Any Other info.**\r\n", "comments": ["Here's an actual real world example:\r\n![image](https://user-images.githubusercontent.com/1826947/72591154-7627ea80-38cd-11ea-98cf-3bd1dcc6f4b9.png)\r\nThis is the tensorboard output for several different models being tested. The ones worth investigating further are the ones that are linear on the graph (linear even though the graph is logarithmically scaled), as they show that with further training, they will likely continue to improve. This is exactly what a relative `min_delta` would help find.\r\nI want to have `min_delta` set low enough so that the ones like that orange at the bottom continue all the way to the end. But by setting `min_delta` low, the ones that continued to the end, but were virtually flat were also allowed to continue.\r\nIn addition, some of the ones that were terminated early were very linear (again linear on the logarithmic scale), and if allowed to continue might have ended up among the best results.\r\n\r\nAnd here's what it looks like with a dirty hacked up implementation of a relative `min_delta` (set so loss has to drop by half over 5 epochs to continue):\r\n![image](https://user-images.githubusercontent.com/1826947/72596022-25b68a00-38d9-11ea-9265-3c053359df53.png)\r\nAs you can see, it's very effective at stopping them as they flatten out (though I was probably a little aggressive on the threshold).", "@phemmer Interesting feature request. Sorry for the late response.\r\nAre you still interested in contributing? If yes, please feel free to open a PR in  [keras-team/keras repo.](https://github.com/keras-team/keras/issues) repository.\r\n\r\nPlease note that Keras development moved to keras-team/keras repository to focus on only keras. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 35969, "title": "ImportError: cannot import name '_tf_stack' from 'tensorflow_core.python' ", "body": "When i am trying to execute the below commands in jupyter notebook\r\nfrom keras.models import Sequential\r\nfrom keras.utils import to_categorical\r\nfrom keras.layers import Dense\r\nfrom keras.datasets import mnist\r\n\r\nam getting the below error.\r\n\r\nUsing TensorFlow backend.\r\nERROR:root:Internal Python error in the inspect module.\r\nBelow is the traceback from this internal error.\r\n\r\nERROR:root:Internal Python error in the inspect module.\r\nBelow is the traceback from this internal error.\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 2453, in <module>\r\n    from tensorflow.python.util import deprecation\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\", line 25, in <module>\r\n    from tensorflow.python.platform import tf_logging as logging\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\platform\\tf_logging.py\", line 38, in <module>\r\n    from tensorflow.python.util.tf_export import tf_export\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\tf_export.py\", line 48, in <module>\r\n    from tensorflow.python.util import tf_decorator\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\tf_decorator.py\", line 64, in <module>\r\n    from tensorflow.python.util import tf_stack\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\tf_stack.py\", line 29, in <module>\r\n    from tensorflow.python import _tf_stack\r\nImportError: cannot import name '_tf_stack' from 'tensorflow_core.python' (C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\__init__.py)\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-15-8bc4ca592e3e>\", line 2, in <module>\r\n    from keras.models import Sequential\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\keras\\__init__.py\", line 3, in <module>\r\n    from . import utils\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\keras\\utils\\__init__.py\", line 6, in <module>\r\n    from . import conv_utils\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\keras\\utils\\conv_utils.py\", line 9, in <module>\r\n    from .. import backend as K\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\keras\\backend\\__init__.py\", line 89, in <module>\r\n    from .tensorflow_backend import *\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 6, in <module>\r\n    from tensorflow.python.framework import ops as tf_ops\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 31, in <module>\r\n    from tensorflow.core.framework import attr_value_pb2\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\__init__.py\", line 42, in <module>\r\n    from . _api.v2 import audio\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\_api\\v2\\audio\\__init__.py\", line 10, in <module>\r\n    from tensorflow.python.ops.gen_audio_ops import decode_wav\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\gen_audio_ops.py\", line 9, in <module>\r\n    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 2453, in <module>\r\n    from tensorflow.python.util import deprecation\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\", line 25, in <module>\r\n    from tensorflow.python.platform import tf_logging as logging\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\platform\\tf_logging.py\", line 38, in <module>\r\n    from tensorflow.python.util.tf_export import tf_export\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\tf_export.py\", line 48, in <module>\r\n    from tensorflow.python.util import tf_decorator\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\tf_decorator.py\", line 64, in <module>\r\n    from tensorflow.python.util import tf_stack\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\tf_stack.py\", line 29, in <module>\r\n    from tensorflow.python import _tf_stack\r\nImportError: cannot import name '_tf_stack' from 'tensorflow_core.python' (C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\__init__.py)\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2040, in showtraceback\r\n    stb = value._render_traceback_()\r\nAttributeError: 'ImportError' object has no attribute '_render_traceback_'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 2453, in <module>\r\n    from tensorflow.python.util import deprecation\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\", line 25, in <module>\r\n    from tensorflow.python.platform import tf_logging as logging\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\platform\\tf_logging.py\", line 38, in <module>\r\n    from tensorflow.python.util.tf_export import tf_export\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\tf_export.py\", line 48, in <module>\r\n    from tensorflow.python.util import tf_decorator\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\tf_decorator.py\", line 64, in <module>\r\n    from tensorflow.python.util import tf_stack\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\tf_stack.py\", line 29, in <module>\r\n    from tensorflow.python import _tf_stack\r\nImportError: cannot import name '_tf_stack' from 'tensorflow_core.python' (C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\__init__.py)\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\r\n    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\r\n    return f(*args, **kwargs)\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\r\n    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\inspect.py\", line 1502, in getinnerframes\r\n    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\inspect.py\", line 1460, in getframeinfo\r\n    filename = getsourcefile(frame) or getfile(frame)\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\inspect.py\", line 696, in getsourcefile\r\n    if getattr(getmodule(object, filename), '__loader__', None) is not None:\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\inspect.py\", line 733, in getmodule\r\n    if ismodule(module) and hasattr(module, '__file__'):\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\__init__.py\", line 42, in <module>\r\n    from . _api.v2 import audio\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\_api\\v2\\audio\\__init__.py\", line 10, in <module>\r\n    from tensorflow.python.ops.gen_audio_ops import decode_wav\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\gen_audio_ops.py\", line 9, in <module>\r\n    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 2453, in <module>\r\n    from tensorflow.python.util import deprecation\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\", line 25, in <module>\r\n    from tensorflow.python.platform import tf_logging as logging\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\platform\\tf_logging.py\", line 38, in <module>\r\n    from tensorflow.python.util.tf_export import tf_export\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\tf_export.py\", line 48, in <module>\r\n    from tensorflow.python.util import tf_decorator\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\tf_decorator.py\", line 64, in <module>\r\n    from tensorflow.python.util import tf_stack\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\tf_stack.py\", line 29, in <module>\r\n    from tensorflow.python import _tf_stack\r\nImportError: cannot import name '_tf_stack' from 'tensorflow_core.python' (C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\__init__.py)\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-15-8bc4ca592e3e>\", line 2, in <module>\r\n    from keras.models import Sequential\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\keras\\__init__.py\", line 3, in <module>\r\n    from . import utils\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\keras\\utils\\__init__.py\", line 6, in <module>\r\n    from . import conv_utils\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\keras\\utils\\conv_utils.py\", line 9, in <module>\r\n    from .. import backend as K\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\keras\\backend\\__init__.py\", line 89, in <module>\r\n    from .tensorflow_backend import *\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 6, in <module>\r\n    from tensorflow.python.framework import ops as tf_ops\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 31, in <module>\r\n    from tensorflow.core.framework import attr_value_pb2\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\__init__.py\", line 42, in <module>\r\n    from . _api.v2 import audio\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\_api\\v2\\audio\\__init__.py\", line 10, in <module>\r\n    from tensorflow.python.ops.gen_audio_ops import decode_wav\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\gen_audio_ops.py\", line 9, in <module>\r\n    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 2453, in <module>\r\n    from tensorflow.python.util import deprecation\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\", line 25, in <module>\r\n    from tensorflow.python.platform import tf_logging as logging\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\platform\\tf_logging.py\", line 38, in <module>\r\n    from tensorflow.python.util.tf_export import tf_export\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\tf_export.py\", line 48, in <module>\r\n    from tensorflow.python.util import tf_decorator\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\tf_decorator.py\", line 64, in <module>\r\n    from tensorflow.python.util import tf_stack\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\tf_stack.py\", line 29, in <module>\r\n    from tensorflow.python import _tf_stack\r\nImportError: cannot import name '_tf_stack' from 'tensorflow_core.python' (C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\__init__.py)\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2040, in showtraceback\r\n    stb = value._render_traceback_()\r\nAttributeError: 'ImportError' object has no attribute '_render_traceback_'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 2453, in <module>\r\n    from tensorflow.python.util import deprecation\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\", line 25, in <module>\r\n    from tensorflow.python.platform import tf_logging as logging\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\platform\\tf_logging.py\", line 38, in <module>\r\n    from tensorflow.python.util.tf_export import tf_export\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\tf_export.py\", line 48, in <module>\r\n    from tensorflow.python.util import tf_decorator\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\tf_decorator.py\", line 64, in <module>\r\n    from tensorflow.python.util import tf_stack\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\tf_stack.py\", line 29, in <module>\r\n    from tensorflow.python import _tf_stack\r\nImportError: cannot import name '_tf_stack' from 'tensorflow_core.python' (C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\__init__.py)\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 2453, in <module>\r\n    from tensorflow.python.util import deprecation\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\", line 25, in <module>\r\n    from tensorflow.python.platform import tf_logging as logging\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\platform\\tf_logging.py\", line 38, in <module>\r\n    from tensorflow.python.util.tf_export import tf_export\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\tf_export.py\", line 48, in <module>\r\n    from tensorflow.python.util import tf_decorator\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\tf_decorator.py\", line 64, in <module>\r\n    from tensorflow.python.util import tf_stack\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\tf_stack.py\", line 29, in <module>\r\n    from tensorflow.python import _tf_stack\r\nImportError: cannot import name '_tf_stack' from 'tensorflow_core.python' (C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\__init__.py)\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-15-8bc4ca592e3e>\", line 2, in <module>\r\n    from keras.models import Sequential\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\keras\\__init__.py\", line 3, in <module>\r\n    from . import utils\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\keras\\utils\\__init__.py\", line 6, in <module>\r\n    from . import conv_utils\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\keras\\utils\\conv_utils.py\", line 9, in <module>\r\n    from .. import backend as K\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\keras\\backend\\__init__.py\", line 89, in <module>\r\n    from .tensorflow_backend import *\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 6, in <module>\r\n    from tensorflow.python.framework import ops as tf_ops\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 31, in <module>\r\n    from tensorflow.core.framework import attr_value_pb2\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\__init__.py\", line 42, in <module>\r\n    from . _api.v2 import audio\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\_api\\v2\\audio\\__init__.py\", line 10, in <module>\r\n    from tensorflow.python.ops.gen_audio_ops import decode_wav\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\gen_audio_ops.py\", line 9, in <module>\r\n    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 2453, in <module>\r\n    from tensorflow.python.util import deprecation\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\", line 25, in <module>\r\n    from tensorflow.python.platform import tf_logging as logging\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\platform\\tf_logging.py\", line 38, in <module>\r\n    from tensorflow.python.util.tf_export import tf_export\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\tf_export.py\", line 48, in <module>\r\n    from tensorflow.python.util import tf_decorator\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\tf_decorator.py\", line 64, in <module>\r\n    from tensorflow.python.util import tf_stack\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\tf_stack.py\", line 29, in <module>\r\n    from tensorflow.python import _tf_stack\r\nImportError: cannot import name '_tf_stack' from 'tensorflow_core.python' (C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\__init__.py)\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2040, in showtraceback\r\n    stb = value._render_traceback_()\r\nAttributeError: 'ImportError' object has no attribute '_render_traceback_'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3249, in run_ast_nodes\r\n    if (await self.run_code(code, result,  async_=asy)):\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\r\n    self.showtraceback(running_compiled_code=True)\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2043, in showtraceback\r\n    value, tb, tb_offset=tb_offset)\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1385, in structured_traceback\r\n    self, etype, value, tb, tb_offset, number_of_lines_of_context)\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1288, in structured_traceback\r\n    self, etype, value, tb, tb_offset, number_of_lines_of_context\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1150, in structured_traceback\r\n    formatted_exceptions += self.prepare_chained_exception_message(evalue.__cause__)\r\nTypeError: can only concatenate str (not \"list\") to str\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2040, in showtraceback\r\n    stb = value._render_traceback_()\r\nAttributeError: 'TypeError' object has no attribute '_render_traceback_'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 2453, in <module>\r\n    from tensorflow.python.util import deprecation\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\", line 25, in <module>\r\n    from tensorflow.python.platform import tf_logging as logging\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\platform\\tf_logging.py\", line 38, in <module>\r\n    from tensorflow.python.util.tf_export import tf_export\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\tf_export.py\", line 48, in <module>\r\n    from tensorflow.python.util import tf_decorator\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\tf_decorator.py\", line 64, in <module>\r\n    from tensorflow.python.util import tf_stack\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\tf_stack.py\", line 29, in <module>\r\n    from tensorflow.python import _tf_stack\r\nImportError: cannot import name '_tf_stack' from 'tensorflow_core.python' (C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\__init__.py)\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\r\n    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\r\n    return f(*args, **kwargs)\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\r\n    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\inspect.py\", line 1502, in getinnerframes\r\n    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\inspect.py\", line 1460, in getframeinfo\r\n    filename = getsourcefile(frame) or getfile(frame)\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\inspect.py\", line 696, in getsourcefile\r\n    if getattr(getmodule(object, filename), '__loader__', None) is not None:\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\inspect.py\", line 733, in getmodule\r\n    if ismodule(module) and hasattr(module, '__file__'):\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\__init__.py\", line 42, in <module>\r\n    from . _api.v2 import audio\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\_api\\v2\\audio\\__init__.py\", line 10, in <module>\r\n    from tensorflow.python.ops.gen_audio_ops import decode_wav\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\gen_audio_ops.py\", line 9, in <module>\r\n    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 2453, in <module>\r\n    from tensorflow.python.util import deprecation\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\", line 25, in <module>\r\n    from tensorflow.python.platform import tf_logging as logging\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\platform\\tf_logging.py\", line 38, in <module>\r\n    from tensorflow.python.util.tf_export import tf_export\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\tf_export.py\", line 48, in <module>\r\n    from tensorflow.python.util import tf_decorator\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\tf_decorator.py\", line 64, in <module>\r\n    from tensorflow.python.util import tf_stack\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\tf_stack.py\", line 29, in <module>\r\n    from tensorflow.python import _tf_stack\r\nImportError: cannot import name '_tf_stack' from 'tensorflow_core.python' (C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\__init__.py)\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-15-8bc4ca592e3e>\", line 2, in <module>\r\n    from keras.models import Sequential\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\keras\\__init__.py\", line 3, in <module>\r\n    from . import utils\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\keras\\utils\\__init__.py\", line 6, in <module>\r\n    from . import conv_utils\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\keras\\utils\\conv_utils.py\", line 9, in <module>\r\n    from .. import backend as K\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\keras\\backend\\__init__.py\", line 89, in <module>\r\n    from .tensorflow_backend import *\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 6, in <module>\r\n    from tensorflow.python.framework import ops as tf_ops\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 31, in <module>\r\n    from tensorflow.core.framework import attr_value_pb2\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\__init__.py\", line 42, in <module>\r\n    from . _api.v2 import audio\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\_api\\v2\\audio\\__init__.py\", line 10, in <module>\r\n    from tensorflow.python.ops.gen_audio_ops import decode_wav\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\gen_audio_ops.py\", line 9, in <module>\r\n    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 2453, in <module>\r\n    from tensorflow.python.util import deprecation\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\", line 25, in <module>\r\n    from tensorflow.python.platform import tf_logging as logging\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\platform\\tf_logging.py\", line 38, in <module>\r\n    from tensorflow.python.util.tf_export import tf_export\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\tf_export.py\", line 48, in <module>\r\n    from tensorflow.python.util import tf_decorator\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\tf_decorator.py\", line 64, in <module>\r\n    from tensorflow.python.util import tf_stack\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\tf_stack.py\", line 29, in <module>\r\n    from tensorflow.python import _tf_stack\r\nImportError: cannot import name '_tf_stack' from 'tensorflow_core.python' (C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\__init__.py)\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2040, in showtraceback\r\n    stb = value._render_traceback_()\r\nAttributeError: 'ImportError' object has no attribute '_render_traceback_'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3249, in run_ast_nodes\r\n    if (await self.run_code(code, result,  async_=asy)):\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\r\n    self.showtraceback(running_compiled_code=True)\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2043, in showtraceback\r\n    value, tb, tb_offset=tb_offset)\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1385, in structured_traceback\r\n    self, etype, value, tb, tb_offset, number_of_lines_of_context)\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1288, in structured_traceback\r\n    self, etype, value, tb, tb_offset, number_of_lines_of_context\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1150, in structured_traceback\r\n    formatted_exceptions += self.prepare_chained_exception_message(evalue.__cause__)\r\nTypeError: can only concatenate str (not \"list\") to str\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2040, in showtraceback\r\n    stb = value._render_traceback_()\r\nAttributeError: 'TypeError' object has no attribute '_render_traceback_'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 2453, in <module>\r\n    from tensorflow.python.util import deprecation\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\", line 25, in <module>\r\n    from tensorflow.python.platform import tf_logging as logging\r\n  File \"C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\platform\\tf_logging.py\", line 38, in <module>\r\n    from tensorflow.python.util.tf_export import tf_export\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\tf_export.py\", line 48, in <module>\r\n    from tensorflow.python.util import tf_decorator\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\tf_decorator.py\", line 64, in <module>\r\n    from tensorflow.python.util import tf_stack\r\n  File \"C:\\Users\\Saranya\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\tf_stack.py\", line 29, in <module>\r\n    from tensorflow.python import _tf_stack\r\nImportError: cannot import name '_tf_stack' from 'tensorflow_core.python' (C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\__init__.py)\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n---------------------------------------------------------------------------\r\nImportError                               Traceback (most recent call last)\r\n~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py in <module>\r\n     57 \r\n---> 58   from tensorflow.python.pywrap_tensorflow_internal import *\r\n     59   from tensorflow.python.pywrap_tensorflow_internal import __version__\r\n\r\n~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py in <module>\r\n   2452 \r\n-> 2453 from tensorflow.python.util import deprecation\r\n   2454 from tensorflow.python.util.tf_export import tf_export\r\n\r\n~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py in <module>\r\n     24 \r\n---> 25 from tensorflow.python.platform import tf_logging as logging\r\n     26 from tensorflow.python.util import decorator_utils\r\n\r\n~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\platform\\tf_logging.py in <module>\r\n     37 \r\n---> 38 from tensorflow.python.util.tf_export import tf_export\r\n     39 \r\n\r\n~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\tf_export.py in <module>\r\n     47 \r\n---> 48 from tensorflow.python.util import tf_decorator\r\n     49 from tensorflow.python.util import tf_inspect\r\n\r\n~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\tf_decorator.py in <module>\r\n     63 \r\n---> 64 from tensorflow.python.util import tf_stack\r\n     65 \r\n\r\n~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\tf_stack.py in <module>\r\n     28 # TODO(b/138203821): change to from ...util import ... once the bug is fixed.\r\n---> 29 from tensorflow.python import _tf_stack\r\n     30 \r\n\r\nImportError: cannot import name '_tf_stack' from 'tensorflow_core.python' (C:\\Users\\Saranya\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\__init__.py)\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nAttributeError                            Traceback (most recent call last)\r\n~\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in showtraceback(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\r\n   2039                         # in the engines. This should return a list of strings.\r\n-> 2040                         stb = value._render_traceback_()\r\n   2041                     except Exception:\r\n\r\nAttributeError: 'ImportError' object has no attribute '_render_traceback_'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTypeError                                 Traceback (most recent call last)\r\n~\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self, code_obj, result, async_)\r\n   3341             if result is not None:\r\n   3342                 result.error_in_exec = sys.exc_info()[1]\r\n-> 3343             self.showtraceback(running_compiled_code=True)\r\n   3344         else:\r\n   3345             outflag = False\r\n\r\n~\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in showtraceback(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\r\n   2041                     except Exception:\r\n   2042                         stb = self.InteractiveTB.structured_traceback(etype,\r\n-> 2043                                             value, tb, tb_offset=tb_offset)\r\n   2044 \r\n   2045                     self._showtraceback(etype, value, stb)\r\n\r\n~\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py in structured_traceback(self, etype, value, tb, tb_offset, number_of_lines_of_context)\r\n   1383         self.tb = tb\r\n   1384         return FormattedTB.structured_traceback(\r\n-> 1385             self, etype, value, tb, tb_offset, number_of_lines_of_context)\r\n   1386 \r\n   1387 \r\n\r\n~\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py in structured_traceback(self, etype, value, tb, tb_offset, number_of_lines_of_context)\r\n   1286             # Verbose modes need a full traceback\r\n   1287             return VerboseTB.structured_traceback(\r\n-> 1288                 self, etype, value, tb, tb_offset, number_of_lines_of_context\r\n   1289             )\r\n   1290         elif mode == 'Minimal':\r\n\r\n~\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py in structured_traceback(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\r\n   1148         exception = self.get_parts_of_chained_exception(evalue)\r\n   1149         if exception:\r\n-> 1150             formatted_exceptions += self.prepare_chained_exception_message(evalue.__cause__)\r\n   1151             etype, evalue, etb = exception\r\n   1152         else:\r\n\r\nTypeError: can only concatenate str (not \"list\") to str\r\n\r\n\r\nPlease help me in rectifying this error.", "comments": ["@SaranyaPandiaraj ,\r\nWhen tried running the same code in both Jupyter notebook and Colab, was able to run successfully.Kindly find the screenshot for reference. \r\n![35969](https://user-images.githubusercontent.com/52397990/72589995-c2514a00-3922-11ea-96fe-faeacf440e0b.png)\r\nCan you try again and let us know?Thanks!\r\n", "Well i re-installed the keras and the kernel and its working now. Thank you ! :)"]}, {"number": 35968, "title": "Could not load dynamic library 'libnvinfer_plugin.so.6'", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): wheel\r\n- TensorFlow version: 2.1.0\r\n- Python version: 3.7\r\n- Installed using virtualenv? pip? conda?: pip in virtualenv\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10.1\r\n- GPU model and memory: Titan XP\r\n\r\n**Describe the problem**\r\n```\r\n2020-01-16 20:21:32.912603: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer.so.6 \r\n\r\n2020-01-16 20:21:32.912768: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6:  cannot open shared object file: No such file or directory \r\n\r\n2020-01-16 20:21:32.912782: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\r\n```\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n```\r\nimport tensorflow\r\n```\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n```\r\ncuda-10-1/unknown,now 10.1.243-1 amd64 [installed]\r\ncuda-command-line-tools-10-1/unknown,now 10.1.243-1 amd64 [installed,automatic]\r\ncuda-compiler-10-1/unknown,now 10.1.243-1 amd64 [installed,automatic]\r\ncuda-cudart-10-1/unknown,now 10.1.243-1 amd64 [installed,automatic]\r\ncuda-cudart-dev-10-1/unknown,now 10.1.243-1 amd64 [installed,automatic]\r\ncuda-cufft-10-1/unknown,now 10.1.243-1 amd64 [installed,automatic]\r\ncuda-cufft-dev-10-1/unknown,now 10.1.243-1 amd64 [installed,automatic]\r\ncuda-cuobjdump-10-1/unknown,now 10.1.243-1 amd64 [installed,automatic]\r\ncuda-cupti-10-1/unknown,now 10.1.243-1 amd64 [installed,automatic]\r\ncuda-curand-10-1/unknown,now 10.1.243-1 amd64 [installed,automatic]\r\ncuda-curand-dev-10-1/unknown,now 10.1.243-1 amd64 [installed,automatic]\r\ncuda-cusolver-10-1/unknown,now 10.1.243-1 amd64 [installed,automatic]\r\ncuda-cusolver-dev-10-1/unknown,now 10.1.243-1 amd64 [installed,automatic]\r\ncuda-cusparse-10-1/unknown,now 10.1.243-1 amd64 [installed,automatic]\r\ncuda-cusparse-dev-10-1/unknown,now 10.1.243-1 amd64 [installed,automatic]\r\ncuda-demo-suite-10-1/unknown,now 10.1.243-1 amd64 [installed,automatic]\r\ncuda-documentation-10-1/unknown,now 10.1.243-1 amd64 [installed,automatic]\r\ncuda-driver-dev-10-1/unknown,now 10.1.243-1 amd64 [installed,automatic]\r\ncuda-drivers/unknown,now 440.33.01-1 amd64 [installed,automatic]\r\ncuda-gdb-10-1/unknown,now 10.1.243-1 amd64 [installed,automatic]\r\ncuda-gpu-library-advisor-10-1/unknown,now 10.1.243-1 amd64 [installed,automatic]\r\ncuda-libraries-10-1/unknown,now 10.1.243-1 amd64 [installed,automatic]\r\ncuda-libraries-dev-10-1/unknown,now 10.1.243-1 amd64 [installed,automatic]\r\ncuda-license-10-1/unknown,now 10.1.243-1 amd64 [installed,automatic]\r\ncuda-license-10-2/unknown,now 10.2.89-1 amd64 [installed,automatic]\r\ncuda-memcheck-10-1/unknown,now 10.1.243-1 amd64 [installed,automatic]\r\ncuda-misc-headers-10-1/unknown,now 10.1.243-1 amd64 [installed,automatic]\r\ncuda-npp-10-1/unknown,now 10.1.243-1 amd64 [installed,automatic]\r\ncuda-npp-dev-10-1/unknown,now 10.1.243-1 amd64 [installed,automatic]\r\ncuda-nsight-10-1/unknown,now 10.1.243-1 amd64 [installed,automatic]\r\ncuda-nsight-compute-10-1/unknown,now 10.1.243-1 amd64 [installed,automatic]\r\ncuda-nsight-systems-10-1/unknown,now 10.1.243-1 amd64 [installed,automatic]\r\ncuda-nvcc-10-1/unknown,now 10.1.243-1 amd64 [installed,automatic]\r\ncuda-nvdisasm-10-1/unknown,now 10.1.243-1 amd64 [installed,automatic]\r\ncuda-nvgraph-10-1/unknown,now 10.1.243-1 amd64 [installed,automatic]\r\ncuda-nvgraph-dev-10-1/unknown,now 10.1.243-1 amd64 [installed,automatic]\r\ncuda-nvjpeg-10-1/unknown,now 10.1.243-1 amd64 [installed,automatic]\r\ncuda-nvjpeg-dev-10-1/unknown,now 10.1.243-1 amd64 [installed,automatic]\r\ncuda-nvml-dev-10-1/unknown,now 10.1.243-1 amd64 [installed,automatic]\r\ncuda-nvprof-10-1/unknown,now 10.1.243-1 amd64 [installed,automatic]\r\ncuda-nvprune-10-1/unknown,now 10.1.243-1 amd64 [installed,automatic]\r\ncuda-nvrtc-10-1/unknown,now 10.1.243-1 amd64 [installed,automatic]\r\ncuda-nvrtc-dev-10-1/unknown,now 10.1.243-1 amd64 [installed,automatic]\r\ncuda-nvtx-10-1/unknown,now 10.1.243-1 amd64 [installed,automatic]\r\ncuda-nvvp-10-1/unknown,now 10.1.243-1 amd64 [installed,automatic]\r\ncuda-repo-ubuntu1604/unknown,now 10.1.243-1 amd64 [installed,upgradable to: 10.2.89-1]\r\ncuda-runtime-10-1/unknown,now 10.1.243-1 amd64 [installed,automatic]\r\ncuda-samples-10-1/unknown,now 10.1.243-1 amd64 [installed,automatic]\r\ncuda-sanitizer-api-10-1/unknown,now 10.1.243-1 amd64 [installed,automatic]\r\ncuda-toolkit-10-1/unknown,now 10.1.243-1 amd64 [installed,automatic]\r\ncuda-tools-10-1/unknown,now 10.1.243-1 amd64 [installed,automatic]\r\ncuda-visual-tools-10-1/unknown,now 10.1.243-1 amd64 [installed,automatic]\r\nlibcuda1-440/unknown,now 440.33.01-0ubuntu1 amd64 [installed,automatic]\r\nlibcudnn7/unknown,now 7.6.4.38-1+cuda10.1 amd64 [installed,upgradable to: 7.6.5.32-1+cuda10.2]\r\nlibcudnn7-dev/unknown,now 7.6.4.38-1+cuda10.1 amd64 [installed,upgradable to: 7.6.5.32-1+cuda10.2]\r\nlibnvinfer-dev/unknown,now 6.0.1-1+cuda10.1 amd64 [installed,upgradable to: 7.0.0-1+cuda10.2]\r\nlibnvinfer6/unknown,now 6.0.1-1+cuda10.1 amd64 [installed,upgradable to: 6.0.1-1+cuda10.2]\r\n```\r\n\r\nNote this doesn't occur on nightly", "comments": ["I run into the same issue with slightly different system informations", "Had the same issue on Linux, Ubuntu 18.04.3, using Python 3.7.3, within virtual environment, when running in the console : \r\n\r\n`python -c; import keras;print(keras.__version__)`\r\n\r\nThe problem occurs when trying to import keras or tensorflow.", "This also arise when tensorflow-gpu is not installed, which is surprising", "Found [this link](https://mc.ai/tensorflow-gpu-installation-on-ubuntu-18-04) with explication of how to install tensorflow-gpu on Linux. Is is really necessary? ", "Almost exactly the same issue with fresh install of Ubuntu. \r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04 LTS\r\n- TensorFlow installed from (source or binary): wheel\r\n- TensorFlow version: 2.1.0\r\n- Python version: 3.6.9\r\n-  Installed using virtualenv? pip? conda?: pip in virtualenv\r\n- CUDA/cuDNN version: 10.0\r\n-  GPU model and memory: 1080 Ti\r\n\r\nI followed [this guide](https://www.pyimagesearch.com/2019/12/09/how-to-install-tensorflow-2-0-on-ubuntu/) almost to the letter but ran into issues with nvidia-drm, which I used tty3 to work around as suggested by one of the comments. \r\n\r\nWhen I run ```tf.test.is_gpu_available()```... \r\n\r\n```>>> tf.test.is_gpu_available()\r\n2020-01-20 23:18:14.446621: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n\r\n2020-01-20 23:18:14.448592: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \r\npciBusID: 0000:01:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\r\ncoreClock: 1.6575GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\r\n\r\n2020-01-20 23:18:14.449086: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.0/lib64\r\n\r\n2020-01-20 23:18:14.449397: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10'; dlerror: libcublas.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.0/lib64\r\n2020-01-20 23:18:14.449635: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.0/lib64\r\n\r\n2020-01-20 23:18:14.449877: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.0/lib64\r\n\r\n2020-01-20 23:18:14.450111: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.0/lib64\r\n\r\n2020-01-20 23:18:14.450330: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10'; dlerror: libcusparse.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.0/lib64\r\n\r\n2020-01-20 23:18:14.450391: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n\r\n2020-01-20 23:18:14.450418: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1592] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\r\nSkipping registering GPU devices...\r\n\r\n2020-01-20 23:18:14.450481: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n\r\n2020-01-20 23:18:14.450533: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 \r\n\r\n2020-01-20 23:18:14.450580: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N \r\n\r\nFalse\r\n```\r\n\r\n\r\n**When I encountered this issue, I was able [to get tf to detect my card](https://stackoverflow.com/questions/47068709/your-cpu-supports-instructions-that-this-tensorflow-binary-was-not-compiled-to-u) with ```pip install tensorflow-gpu==2.0```**.", "@sharonwoo\r\n\r\nTry `ls /usr/local/cuda-10.0/lib64` or `ls /usr/local/cuda/lib64` and see if the libraries are found\r\n\r\nand try exporting the path `export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda/lib64`\r\n\r\nNow try `tf.test.is_gpu_available()`\r\n\r\nThe above worked for me and my tensorflow-gpu version is 2.0", "Just to reiterate, this is a problem with tensorflow 2.1, not nightly or 2.0. \r\n\r\n@gnthibault tensorflow and tensorflow-gpu now point to the same package as of 2.1", "Hi, just reporting that I too am seeing this same issue. This happens even in the python repl when simply trying to import tensorflow.\r\n\r\nHere are my system specs:\r\n\r\n```\r\nKernel: 5.4.3-arch1-1 \r\nCPU: Intel i9-9900K (16) @ 5.000GHz \r\nGPU: NVIDIA GeForce RTX 2070 Rev. A\r\nCUDA: Cuda compilation tools, release 10.2, V10.2.89\r\n```\r\n\r\n```\r\n$ pip freeze | grep tensorflow\r\ntensorflow==2.1.0\r\ntensorflow-estimator==2.1.0\r\ntensorflow-gpu==2.1.0\r\n```\r\n\r\nPython Version: 3.7.6\r\nPip Version: 19.3.1\r\n\r\nEverything works normally in version 2.0.0 however.", "@mjlbach yes, reporting for tf 2.1. \r\n\r\nI downgraded to 2.0 to get a working version of tf, and added in the note as info to anyone coming here after encountering the error. I have edited the wording to make it less confusing.", "I get the same problem, but because other reason:\r\n```\r\n2020-01-21 16:37:57.869790: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: /lib/x86_64-linux-gnu/libm.so.6: version `GLIBC_2.27' not found (required by /usr/lib/x86_64-linux-gnu/libnvinfer.so.6)\r\n2020-01-21 16:37:57.870308: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: /lib/x86_64-linux-gnu/libm.so.6: version `GLIBC_2.27' not found (required by /usr/lib/x86_64-linux-gnu/libnvinfer.so.6)\r\n```\r\n\r\nIt is because `GLIBC`.", "I get the same problem as well. Had to downgrade to `2.0`.", "I reinstalled Tensorflow 2.0 and Keras and now it works -- but not on Jupyter Notebook, where I get the same error when importing Tensorflow. Therefore I do not use Jupyter but other editors.", "I got the same error as well. When I downgraded to TensorFlow 2.0.0 (with `pip install tensorflow-gpu==2.0.0`) it solved the issue. ", "it is a warning, i found that [**TensorRT**](https://developer.nvidia.com/tensorrt) is a **nVidia** developed library to improve the _CNN_ performance, but i think it is not needed, I'm working with `tensorflow 2.0` in **Colab** and it is working very good.\r\n\r\nYou can find a tutorial here: https://medium.com/@ardianumam/installing-tensorrt-in-ubuntu-dekstop-1c7307e1dcf6", "That is correct.\r\nif you install tensorrt, the problem should go away.\r\nBut otherwise, TF should continue running.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35968\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35968\">No</a>\n", "Just to clarify, the install instructions for Ubuntu 16.04 should be updated; there are several errors, one being that cuda-10-1 is the appropriate cuda package, the other is that  libnvinfer-plugin6=6.0.1-1+cuda10.1 is missing.\r\n\r\n``` bash\r\n# Add NVIDIA package repositories\r\n# Add HTTPS support for apt-key\r\nsudo apt-get install gnupg-curl\r\nwget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/cuda-repo-ubuntu1604_10.1.243-1_amd64.deb\r\nsudo dpkg -i cuda-repo-ubuntu1604_10.1.243-1_amd64.deb\r\nsudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/7fa2af80.pub\r\nsudo apt-get update\r\nwget http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1604/x86_64/nvidia-machine-learning-repo-ubuntu1604_1.0.0-1_amd64.deb\r\nsudo apt install ./nvidia-machine-learning-repo-ubuntu1604_1.0.0-1_amd64.deb\r\nsudo apt-get update\r\n\r\n# Install NVIDIA driver\r\n# Issue with driver install requires creating /usr/lib/nvidia\r\nsudo mkdir /usr/lib/nvidia\r\nsudo apt-get install --no-install-recommends nvidia-418\r\n# Reboot. Check that GPUs are visible using the command: nvidia-smi\r\n\r\n# Install development and runtime libraries (~4GB)\r\nsudo apt-get install --no-install-recommends \\\r\n    cuda-10-1 \\\r\n    libcudnn7=7.6.4.38-1+cuda10.1  \\\r\n    libcudnn7-dev=7.6.4.38-1+cuda10.1\r\n\r\n\r\n# Install TensorRT. Requires that libcudnn7 is installed above.\r\nsudo apt-get install -y --no-install-recommends libnvinfer6=6.0.1-1+cuda10.1 \\\r\n    libnvinfer-dev=6.0.1-1+cuda10.1 \\\r\n    libnvinfer-plugin6=6.0.1-1+cuda10.1\r\n\r\n```", "See: https://github.com/tensorflow/docs/pull/1403 . Also, still unclear why nightly is not showing this error.", "Installing tensorflow-gpu==2.0 worked for me!", "The solution isn't to downgrade tensorflow (there is no problem with tensorflow 2.1, just the install docs). Install the missing library:\r\n\r\n``` bash\r\napt install libnvinfer-plugin6=6.0.1-1+cuda10.1\r\n```\r\nThere is a PR to fix the docs.", "> The solution isn't to downgrade tensorflow (there is no problem with tensorflow 2.1, just the install docs). Install the missing library:\r\n> \r\n> ```shell\r\n> apt install libnvinfer-plugin6=6.0.1-1+cuda10.1\r\n> ```\r\n> \r\n> There is a PR to fix the docs.\r\n\r\nIt leads to another error\r\n\r\n> Reading package lists... Done\r\nBuilding dependency tree\r\nReading state information... Done\r\nE: Unable to locate package libnvinfer-plugin6\r\n\r\n", "> > The solution isn't to downgrade tensorflow (there is no problem with tensorflow 2.1, just the install docs). Install the missing library:\r\n> > ```shell\r\n> > apt install libnvinfer-plugin6=6.0.1-1+cuda10.1\r\n> > ```\r\n> > \r\n> > \r\n> > There is a PR to fix the docs.\r\n> \r\n> It leads to another error\r\n> \r\n> > Reading package lists... Done\r\n> > Building dependency tree\r\n> > Reading state information... Done\r\n> > E: Unable to locate package libnvinfer-plugin6\r\n\r\nI don't know the specifics of your OS/package manager, but it is likely there is a conflicting package or you did not enable the right repos. This works on Ubuntu 16.04/18.04", "> > > The solution isn't to downgrade tensorflow (there is no problem with tensorflow 2.1, just the install docs). Install the missing library:\r\n> > > ```shell\r\n> > > apt install libnvinfer-plugin6=6.0.1-1+cuda10.1\r\n> > > ```\r\n> > > \r\n> > > \r\n> > > There is a PR to fix the docs.\r\n> > \r\n> > \r\n> > It leads to another error\r\n> > > Reading package lists... Done\r\n> > > Building dependency tree\r\n> > > Reading state information... Done\r\n> > > E: Unable to locate package libnvinfer-plugin6\r\n> \r\n> I don't know the specifics of your OS/package manager, but it is likely there is a conflicting package or you did not enable the right repos. This works on Ubuntu 16.04/18.04\r\nIs is supposed to work on a system without NVidia card and hence without CUDA? And why would an NVidia-specific package be required in the first place? I am getting precisely the same error just importing tensorflow 2.1 from Ubuntu shell under Windows WSL. It goes away if I downgrade to tensorflow 2.0.", "@Black-Behemoth Tensorflow 2.1 is no longer split into a gpu and non-gpu package", "> @Black-Behemoth Tensorflow 2.1 is no longer split into a gpu and non-gpu package\r\n\r\nDoes not explain why \"import tensorflow\" works in tensrflow 2.0 but attempts to invoke  a cuda library in tensorflow 2.1. On a laptop with an AMD card no less.", "Had the same issue, agree with @gunan that tensorRT is not needed. \r\nInstalling `conda install -c anaconda cudatoolkit=10.1` solved the issue.\r\nI have cudnn 7.6.5", "> > @Black-Behemoth Tensorflow 2.1 is no longer split into a gpu and non-gpu package\r\n> \r\n> Does not explain why \"import tensorflow\" works in tensrflow 2.0 but attempts to invoke a cuda library in tensorflow 2.1. On a laptop with an AMD card no less.\r\n\r\nQuoting myself :D  to add further that I have booted into MacOS, installed Homebrew and then tesnsorflow 2.1. \"import tf\" does not call for any libraries with *cuda* in their names there, so I see no reason why they should be needed in the first place on a machine without an NVidia card.", "> That is correct.\r\n> if you install tensorrt, the problem should go away.\r\n> But otherwise, TF should continue running.\r\n\r\n> @Black-Behemoth Tensorflow 2.1 is no longer split into a gpu and non-gpu package\r\n\r\nAnd therefore it should give the user three Warnings whenever you use it on any computer without a Nvidia GPU? Sure feels odd to me, but if _it's a feature_ \u2122 then alright. :sweat_smile: \r\n\r\nGetting the same warnings here. (Intel gpu machine)\r\n\r\n\r\n\r\n", "I couldn't get this to work on Ubuntu 18.04 either - specifically the first part which is supposed to add the repo's didn't work (i.e. nothing added to /etc/apt/sources.list [1]) so everything else will clearly then fail.\r\n\r\nWhat I ended up doing was to download the deb files directly from http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64/\r\n\r\ni.e. I located the version of libcudnn7, libcudnn7-dev, libnvinfer6, libnvinfer-dev, libnvinfer-plugin6 for my cuda version (which is 10.2 not 10.1 and I have driver 440 not 418 but it seems to be working) and installed them using `sudo apt install`\r\n\r\n[1] I'm not a linux expert, I checked with `grep -r --include '*.list' '^deb ' /etc/apt/sources.list /etc/apt/sources.list.d/` and the gnome gui tools.", "Some additional info I've discovered, the reason it failed for me (Ubuntu 18.04) is the step to install the key\r\n\r\n`sudo apt-key adv --fetch-keys http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/7fa2af80.pub`\r\n\r\nerrors with \r\n\r\n`gpg: WARNING: unable to fetch URI http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/7fa2af80.pub: Address family not supported by protocol`\r\n\r\nI'm not sure why, google suggest using http rather than https but that also fails. So I installed the key manually, i.e.\r\n\r\n```\r\nwget http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/7fa2af80.pub\r\nsudo apt-key add 7fa2af80.pub\r\n```\r\n\r\nAnd even after this, I still had to configure the sources manually i.e.\r\n\r\n```\r\nsudo bash -c 'echo \"deb https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/ /\" > /etc/apt/sources.list.d/cuda.list'\r\nsudo bash -c 'echo \"deb https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64 /\" > /etc/apt/sources.list.d/machine-learning.list'\r\n```\r\n\r\n\r\n", "@sharonwoo\r\nI solved exactly the same problem by upgrading to CUDA 10.1 (both toolkit and CUDNN). I had CUDA 10.0 on Ubuntu 18.04.", "I have the same problem. How to slove it?  Too many answers confuse me .Can someone summarize the solution to this problem?", "@ai-starter basically you need to upgrade to cuda 10.1 and install the correct version CUDNN and TensorRT libraries\r\n\r\nYou should be able to follow https://github.com/tensorflow/tensorflow/issues/35968#issuecomment-577329399\r\n\r\nIf it doesn't work this is what worked for me - I suspect what works may depend on what you currently have installed / how you installed it.\r\n\r\n```\r\n# install nvidia key\r\nwget http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/7fa2af80.pub\r\nsudo apt-key add 7fa2af80.pub\r\n\r\n# add repo's\r\nsudo bash -c 'echo \"deb https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/ /\" > /etc/apt/sources.list.d/cuda.list'\r\nsudo bash -c 'echo \"deb https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64 /\" > /etc/apt/sources.list.d/machine-learning.list'\r\n\r\nsudo apt-get update\r\n\r\n# Install development and runtime libraries (~4GB)\r\nsudo apt-get install --no-install-recommends \\\r\n    cuda-10-1 \\\r\n    libcudnn7=7.6.4.38-1+cuda10.1  \\\r\n    libcudnn7-dev=7.6.4.38-1+cuda10.1\r\n\r\n\r\n# Install TensorRT. Requires that libcudnn7 is installed above.\r\nsudo apt-get install -y --no-install-recommends libnvinfer6=6.0.1-1+cuda10.1 \\\r\n    libnvinfer-dev=6.0.1-1+cuda10.1 \\\r\n    libnvinfer-plugin6=6.0.1-1+cuda10.1\r\n```", "I am experiencing the same issue with 'libnvinfer_plugin.so.6', even with cuda 10.1 and TensorRT 6.0.\r\nHowever, 'tf.test.is_gpu_available()' yields True.\r\n\r\nMight it be that the plugin doesn't come with the TensorRT installation?", "2 hours into troubleshooting this error.  What the hell is TensorRT and why do we even need it?  Seems like more trouble than it's worth to me.", "Ok, figured mine out.  Here's an outline of what i did.  I was running multiple TF versions, so I wanted to go the manual route.  I've had bad experiences with NVIDIA and Ubuntu nixing each others packages.\r\n\r\nchecked the version of tensorflow I had installed by starting the venv and then\r\n\r\n``\r\npip list | grep tensorflow\r\n``\r\ntensorflow-gpu         2.1.0 \r\ntensorflow-estimator   2.1.0 \r\n\r\nChecked https://www.tensorflow.org/install/source#tested_build_configurations for the versions required.\r\n\r\nDownloaded local installer of CUDA 10.1 from NVIDIA and ran the installer.  Carefully navigated the menus so that it only copied the files to /usr/local/cuda-10.1 directory  (ie: if it wanted to \"help\" me, i told it \"no thanks\").\r\nDownloaded  cuDNN 7.6.5.32.tar.gz and tar xvf'd it to my download directory, it created a \"cuda\" directory\r\nbacked up /usr/local/cuda-10.1 by copying it\r\nCopied the cuda/include/cudnn.h to /usr/local/cuda-10.1/include\r\nCopied the contents of cuda/lib to /usr/local/cuda-10.1\r\nDownloaded TensorRT 6 tarball\r\nExtracted TensorRT 6 to my download directory.\r\nOpened my .venv/bin/activate script\r\n\r\nAdded /usr/local/cuda-10.1 and TensorRT 6 to the LD_LIBRARY_PATH and EXPORT\r\n```\r\nLD_LIBRARY_PATH=\"/usr/local/cuda-10.1/lib64:/home/duane/Downloads/TensorRT-6.0.1.5/lib\"\r\nexport LD_LIBRARY_PATH\r\n```\r\nthen sourced the environment \r\n\r\n```\r\n. activate\r\n```\r\n\r\npython\r\n\r\n```\r\nimport tensorflow as tf\r\ntf.test.is_gpu_available()\r\n```\r\n\r\nWah lah...\r\n\r\n2020-02-28 19:39:35.895538: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/device:GPU:0 with 7386 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 SUPER, pci bus id: 0000:08:00.0, compute capability: 7.5)\r\n\r\nThen I went into my living room, sat on the lounge, drank a bottle of vodka, and passed out.\r\n\r\nNow I feel much better :)", "I had to add --allow-downgrade flag to apt-get to install Tensorflow RT libnvinfer6. I.e.:\r\n\r\n```\r\nsudo apt-get install --no-install-recommends \\\r\n    cuda-10-1 \\\r\n    libcudnn7=7.6.4.38-1+cuda10.1  \\\r\n    libcudnn7-dev=7.6.4.38-1+cuda10.1\r\n\r\nsudo apt-get install -y --allow-downgrades --no-install-recommends \\\r\n        libnvinfer6=6.0.1-1+cuda10.1 \\\r\n        libnvinfer-dev=6.0.1-1+cuda10.1 \\\r\n        libnvinfer-plugin6=6.0.1-1+cuda10.1\r\n```\r\n\r\nThe problem went away.\r\n", "I am using anaconda with Ububtu and tensorflow-2.1, as mentioned above \r\n\r\n- pip install tensorflow-gpu==2.0.0\r\n- pip install tensorflow==2.0.0\r\n\r\nworked for me too", "> Just to clarify, the install instructions for Ubuntu 16.04 should be updated; there are several errors, one being that cuda-10-1 is the appropriate cuda package, the other is that libnvinfer-plugin6=6.0.1-1+cuda10.1 is missing.\r\n> \r\n> ```shell\r\n> # Add NVIDIA package repositories\r\n> # Add HTTPS support for apt-key\r\n> sudo apt-get install gnupg-curl\r\n> wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/cuda-repo-ubuntu1604_10.1.243-1_amd64.deb\r\n> sudo dpkg -i cuda-repo-ubuntu1604_10.1.243-1_amd64.deb\r\n> sudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/7fa2af80.pub\r\n> sudo apt-get update\r\n> wget http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1604/x86_64/nvidia-machine-learning-repo-ubuntu1604_1.0.0-1_amd64.deb\r\n> sudo apt install ./nvidia-machine-learning-repo-ubuntu1604_1.0.0-1_amd64.deb\r\n> sudo apt-get update\r\n> \r\n> # Install NVIDIA driver\r\n> # Issue with driver install requires creating /usr/lib/nvidia\r\n> sudo mkdir /usr/lib/nvidia\r\n> sudo apt-get install --no-install-recommends nvidia-418\r\n> # Reboot. Check that GPUs are visible using the command: nvidia-smi\r\n> \r\n> # Install development and runtime libraries (~4GB)\r\n> sudo apt-get install --no-install-recommends \\\r\n>     cuda-10-1 \\\r\n>     libcudnn7=7.6.4.38-1+cuda10.1  \\\r\n>     libcudnn7-dev=7.6.4.38-1+cuda10.1\r\n> \r\n> \r\n> # Install TensorRT. Requires that libcudnn7 is installed above.\r\n> sudo apt-get install -y --no-install-recommends libnvinfer6=6.0.1-1+cuda10.1 \\\r\n>     libnvinfer-dev=6.0.1-1+cuda10.1 \\\r\n>     libnvinfer-plugin6=6.0.1-1+cuda10.1\r\n> ```\r\n\r\nThanks so much - This worked perfectly on Ubuntu 19.10 for tensorflow 2.1.0 substituting Ubuntu 18.04 libs for the 16.04 ones above", "@gunan:  @behdadforghani-cbre's solution to add `--allow-downgrades` to the last batch of installs solved the issue on two Ubuntu 18.04 machines, it might be good to add it to the [install page](https://www.tensorflow.org/install/gpu#ubuntu_1804_cuda_101)? \r\n```\r\n# Install TensorRT. Requires that libcudnn7 is installed above.\r\nsudo apt-get install -y --allow-downgrades --no-install-recommends \\\r\n        libnvinfer6=6.0.1-1+cuda10.1 \\\r\n        libnvinfer-dev=6.0.1-1+cuda10.1 \\\r\n        libnvinfer-plugin6=6.0.1-1+cuda10.1\r\n```", "I had the same issue and I solve it by adding cudatoolkit and cudnnin in my environment. if you install tnsorflow with \"pip install \" the cudatoolkit and cudnn are not added automatically, not like installing tensoflow with conda that add this libraries automatically.\r\nso you need just to install cudatoolkit and cudnnin in your environment using the following command:\r\n\r\nconda install -c anaconda cudatoolkit=10.1 cudnn=7.6.4", "@lamberta PTAL. Looks like we may need to add tensorrt installation to our docs.\r\n\r\n@reedwm I thought tensorrt was optional. Looks like our users are seeing problems if it is not installed?", "cc: @bixia1", "Just to clarify: following the [steps](https://www.tensorflow.org/install/gpu#ubuntu_1804_cuda_101) to install TF2 on Ubuntu 18.04 I could make it work (GPU recognised), I just had the same error message as the original poster. TensorRT is indeed optional, but as the `--allow-downgrades` completed the install I thought it might be a nice addition.\r\n\r\n@rimdk just to confirm, you say that you've done everything thru conda, sth like this:\r\n```\r\nconda install -c conda-forge tensorflow\r\nconda install -c anaconda cudatoolkit=10.1 cudnn=7.6.4\r\n```\r\nAnd it worked? If so it might be worth adding it to the instructions.", "@jchwenger I installed all my environment using pip install, and when i tried to execute my program i had the same issue, so i added cudatoolkit=10.1 and cudnn=7.6.4 in my env using \r\nconda install -c anaconda cudatoolkit=10.1 cudnn=7.6.4, and it work for me.", "@rimdk, grand, thank you!", "@behdadforghani-cbre's  solution to add --allow-downgrades , solved my issue in ubuntu 18.04", "I think this thread summarizes very well what it's like working with cuda/tensorflow", "An additional problem I continuously encounter is the repo's mentioned in the installation guide will get updated with the newer version at some point but tensorflow requires a specific version. Hence once you get it working, in order to keep it working you really need to `hold` the installed packages (I'm specifically talking about apt on Linux). Otherwise next time you update packages it'll roll the cuda packages forward and break everything", "Folks, I'm trying to run tensorflow from Google Colab, which can be found [here](https://colab.research.google.com/drive/1iJgo-mXyxUjtiVbjbExeYfib_MbcfolR)\r\n\r\nI get as far as \"Training\", but when I start running the code I get the following:\r\n\r\n`2021-02-02 16:40:50.077388: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\r\n2021-02-02 16:40:50.077542: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\r\n2021-02-02 16:40:50.077562: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.`\r\n\r\n\r\nAny recommendations for solving this in this particular situation?", "Make sure you have installed TensorRT and Cuda appropriately. This fixed my problem. \r\nI was trying to run on a conda environment where no TensorRT was installed. Later ran the same code on Jetson where everything was configured. Ran flawlessly!"]}, {"number": 35967, "title": "Removed redundant nullptr check", "body": "Removed duplicate check.", "comments": ["Uh, I think that check is required?\r\n\r\n\"first_side_effecting_node_on_path\" is a variable outside the lambda, and it might become non-null inside the lambda.\r\n", "Correct. In the ReverseDFS function, there are two lambda functions [&] who can access \"Node* first_side_effecting_node_on_path\" by reference.\r\n\r\nHowever, \r\n- first_side_effecting_node_on_path is a local variable, not a static or class variable.\r\n- the function arguments (as expressions) are evaluated in sequence,  \r\n- these two lambda functions do not call each other and cannot be recursive in nature (since they are nameless)\r\n\r\nthe first time the pointer first_side_effecting_node_on_path is accessed (line: 102) appears to be redundant after which is reassigned to n (line: 106). Thoughts ? ", "Nope it's not redundant.\r\n\r\nNotice that these 2 lambdas are called for each node in the graph.\r\n\r\nThe first time we call the first lambda, first_side_effecting_node_on_path will be nullptr. Later in the first lambda we might set first_side_effecting_node_on_path to some node. And after that, we might still call the first lambda and then first_side_effecting_node_on_path will be non-null and we want to keep the original value for first_side_effecting_node_on_path."]}, {"number": 35966, "title": "[ROCm] Complex sparse ops", "body": "This PR enables the following kernels for complex64 and complex128 on ROCm:\r\nCSRSparseMatrixToDense\r\nDenseToCSRSparseMatrix\r\nSparseMatrixMul\r\nCSRSparseMatrixComponents\r\nDenseToCSRSparseMatrix\r\nSparseTensorToCSRSparseMatrix\r\n\r\nIn addition, it fixes a problem in one of the sparse kernel implementations, and enables unit tests for all of the above.", "comments": ["gentle ping", "gentle ping"]}, {"number": 35965, "title": "[ROCm] Enabling the kernel Relu for float16", "body": "This PR enables the kernel Relu for float16 on ROCm and removes some obsolete #ifdef's from relu_op_gpu.cu.cc.", "comments": ["gentle ping"]}, {"number": 35964, "title": "[ROCm] Enabling //tensorflow/core/framework:variant_op_registry_test", "body": "This PR enables //tensorflow/core/framework:variant_op_registry_test for ROCm.", "comments": []}, {"number": 35963, "title": "loose shape check in PointwiseToLinalgConverter", "body": "PointwiseToLinalgConverter only needs static rank not static shape, change accordingly to loose the restriction.", "comments": ["This is the enhancement of the original PR #35812 \uff0cwith a small test added. "]}, {"number": 35962, "title": "Add complex number support for tf.extract_image_patches", "body": "\r\nThis PR tries to address the issue raised in #35955 where\r\nthere was no complex number support for tf.extract_image_patches.\r\nThe op `tf.extract_image_patches` itself could be used in many\r\nways than just image so it makes sense to add complex support.\r\n\r\nThis fix fixes #35955.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["@jaingaurav Thanks for the review! The PR has been updated and the following has been added to capture realnumbertypes + complex64+ complex128:\r\n```\r\n+    .Attr(\r\n+        \"T: {bfloat16, half, float, double, int8, int16, int32, int64, \"\r\n+        \"uint8, uint16, uint32, uint64, complex64, complex128, bool}\")\r\n```\r\n\r\nPlease take a look and let me know if there are any other issues.", "@yongtang: can you rewrite history to strip & merge the commit messages down to something simple? There seems to be a special character in there somewhere which is messing with our infra. Sorry for the inconvenience.", "@jaingaurav Thanks for the help. I have squashed and rebased against the latest master. The PR has been pushed. Let me know if there are any issues.", "Thanks @rmlarsen for the review. The PR has been updated with test case enhanced. Please take a look and let me know if there are any issues."]}, {"number": 35961, "title": "Fix tf.cast issue when python native data type is combined with dtype=tf.float64", "body": "This fix tries to address the issue raised in 35938 where the following issue exist:\r\n```\r\n>>> tf.cast(0.2, tf.float64)\r\n<tf.Tensor: id=37, shape=(), dtype=float64, numpy=0.20000000298023224>\r\n```\r\n\r\nThe issue was that, in tf.cast, 0.2 was first converted to a float32 dtype tensor,\r\nthen cast to float64 tensor.\r\n\r\nThis fix adds dtype_hint=dtype to convert_to_tensor so that native dtype is preserved.\r\n\r\nThis fix fixes #35938.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": []}, {"number": 35959, "title": "core: mark function `inline` (NFC)", "body": "Mark this stub as `inline` to ensure that the body is emitted inline and\r\nno symbol implementation is provided.  This is required as otherwise,\r\nthe function is emitted everywhere as a result of being defined in the\r\nheader, but is not given COMDAT resulting in a multiply defined symbol.\r\n\r\nThis allows linking tensorflow.dll on Windows with VS2019.", "comments": ["CC: @gunan "]}, {"number": 35958, "title": "Details about Tensorflow's I/O", "body": "I'm currently trying to develop an I/O optimization for DL frameworks and for this purpose I would like to understand exactly how Tensorflow behaves when the dataset doesn't fit in memory. More precisely, I want to know how much data is fetched at a time from storage and how frequently it is fetched. I also need to get in more detail about how the prefetching and shuffling features work. I have already been looking for information on these matters and have also read the documentation, but I still haven't got the details I need. Therefore, can anyone tell me where can I find an extensive explanation of Tensorflow's I/O and prefetching and shuffling methods? Or what's the code responsible for handling this?\r\n\r\nThanks", "comments": ["@claudiacorreia60 \r\n\r\nCan you please go through this [link](https://www.tensorflow.org/guide/data_performance) and see if it helps you.Thanks!", "@ravikyram \r\n\r\nThat link has useful information about the prefetching process, and [this one](https://www.tensorflow.org/guide/data#randomly_shuffling_input_data) helped me understand the shuffling process. However, I need to know details such as:\r\n- The elements that are prefetched are stored in memory or in storage?\r\n- The buffer used for shuffling fetches elements from memory or from storage? Are they fetched in a specific order?\r\n\r\nMaybe if I realize what happens when the dataset doesn't fit in memory, I'll find out the answer to these questions.\r\n\r\nThanks for your help!", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n Thanks!\r\n"]}, {"number": 35957, "title": "Fix micro_speech header path in OSX makefile", "body": "I tried to run the following command:\r\n```\r\nmake -f tensorflow/lite/micro/tools/make/Makefile generate_projects\r\ntensorflow/lite/micro/tools/make/download_and_extract.sh \"https://github.com/google/gemmlowp/archive/719139ce755a0f31cbf1c37f7f98adcc7fc9f425.zip\" \"7e8191b24853d75de2af87622ad293ba\" tensorflow/lite/micro/tools/make/downloads/gemmlowp\r\ndownloading https://github.com/google/gemmlowp/archive/719139ce755a0f31cbf1c37f7f98adcc7fc9f425.zip\r\ntensorflow/lite/micro/tools/make/download_and_extract.sh \"https://storage.googleapis.com/mirror.tensorflow.org/github.com/google/flatbuffers/archive/v1.11.0.tar.gz\" \"02c64880acb89dbd57eebacfd67200d8\" tensorflow/lite/micro/tools/make/downloads/flatbuffers\r\ndownloading https://storage.googleapis.com/mirror.tensorflow.org/github.com/google/flatbuffers/archive/v1.11.0.tar.gz\r\ntensorflow/lite/micro/tools/make/download_and_extract.sh \"https://storage.googleapis.com/download.tensorflow.org/data/tf_lite_micro_person_data_grayscale_2019_11_21.zip\" \"fe2934bd0788f1dcc7af3f0a954542ab\" tensorflow/lite/micro/tools/make/downloads/person_model_grayscale\r\ndownloading https://storage.googleapis.com/download.tensorflow.org/data/tf_lite_micro_person_data_grayscale_2019_11_21.zip\r\ntensorflow/lite/micro/tools/make/download_and_extract.sh \"https://storage.googleapis.com/download.tensorflow.org/data/tf_lite_micro_person_data_int8_grayscale_2020_01_13.zip\" \"8a7d2c70325f53136faea6dde517b8cc\" tensorflow/lite/micro/tools/make/downloads/person_model_int8\r\ndownloading https://storage.googleapis.com/download.tensorflow.org/data/tf_lite_micro_person_data_int8_grayscale_2020_01_13.zip\r\ntensorflow/lite/micro/tools/make/download_and_extract.sh \"https://github.com/mborgerding/kissfft/archive/v130.zip\" \"438ba1fef5783cc5f5f201395cc477ca\" tensorflow/lite/micro/tools/make/downloads/kissfft patch_kissfft\r\ndownloading https://github.com/mborgerding/kissfft/archive/v130.zip\r\nFinished patching kissfft\r\ncp -r tensorflow/lite/micro/tools/make/gen/osx_x86_64/prj/person_detection/arduino tensorflow/lite/micro/tools/make/gen/osx_x86_64/prj/person_detection/tensorflow_lite\r\npython tensorflow/lite/micro/tools/make/fix_arduino_subfolders.py tensorflow/lite/micro/tools/make/gen/osx_x86_64/prj/person_detection/tensorflow_lite\r\ncp -r tensorflow/lite/micro/tools/make/gen/osx_x86_64/prj/hello_world/arduino tensorflow/lite/micro/tools/make/gen/osx_x86_64/prj/hello_world/tensorflow_lite\r\npython tensorflow/lite/micro/tools/make/fix_arduino_subfolders.py tensorflow/lite/micro/tools/make/gen/osx_x86_64/prj/hello_world/tensorflow_lite\r\ncp -r tensorflow/lite/micro/tools/make/gen/osx_x86_64/prj/magic_wand/arduino tensorflow/lite/micro/tools/make/gen/osx_x86_64/prj/magic_wand/tensorflow_lite\r\npython tensorflow/lite/micro/tools/make/fix_arduino_subfolders.py tensorflow/lite/micro/tools/make/gen/osx_x86_64/prj/magic_wand/tensorflow_lite\r\ncp -r tensorflow/lite/micro/tools/make/gen/osx_x86_64/prj/person_detection_int8/arduino tensorflow/lite/micro/tools/make/gen/osx_x86_64/prj/person_detection_int8/tensorflow_lite\r\npython tensorflow/lite/micro/tools/make/fix_arduino_subfolders.py tensorflow/lite/micro/tools/make/gen/osx_x86_64/prj/person_detection_int8/tensorflow_lite\r\nmake: *** No rule to make target 'tensorflow/lite/micro/tools/make/gen/osx_x86_64/prj/micro_speech/make/tensorflow/lite/experimental/micro/examples/micro_speech/simple_features/simple_model_settings.h', needed by 'generate_micro_speech_make_project'.  Stop.\r\n```\r\nBut it failed, I figured after moving the `micro` out of the experimental directory this Makefile was not properly edited.\r\nThis PR will solve this particular issue on MacOS and projects are generated properly.", "comments": []}, {"number": 35956, "title": "[TF_MICRO]  Adding cwrapper and compiler option example for building library", "body": "- adding example cwrapper which generates the projects with simple api\r\n- adding make library option to the makefile template\r\n- make project have the compiler path defined setting\r\n- adds a parser to pull out only the used ops from a tflite model", "comments": ["All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F35956) for more info**.\n\n<!-- need_author_consent -->", "@googlebot I consent.", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F35956) for more info**.\n\n<!-- ok -->", "Thanks @cdknorow! This is tackling an important issue for us, I've emailed you offline to discuss more about these changes.", "@petewarden gentle ping for any update ?", "@cdknorow  Can you please resolve conflicts? Thanks!", "Sorry for the long delay on this one @cdknorow - we've been taking a look at how to fit this in, and I'm not sure we're ready to take it yet. It does look useful, but would it be okay to keep this in your fork for now? I'm happy to do a quick followup call to chat more about our thinking on this, if that would be helpful, and thanks again for your patience."]}, {"number": 35955, "title": "Allow tf.image.extract_image_patches to work with complex numbers", "body": "It would be nice if `tf.image.extract_image_patches` were extended to work with complex numbers as well.\r\n\r\nI work extensively with audio data and after applying an STFT, I get a tensor of complex numbers. As I perform my training on patches from this tensor, it would be great if these patches could be extracted using `tf.image.extract_image_patches`.\r\n\r\nI think this is something that would be valuable to many people working in the audio space.\r\n", "comments": ["`tf.image.extract_image_patches` is quite useful and I used it before to create a sliding window effect. It makes sense to add full support for all common types.\r\n\r\nAdded a PR #35962 for complex number support.", "Wow. That was fast!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35955\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35955\">No</a>\n"]}, {"number": 35954, "title": "[TF_MICRO] Adding cwrapper example and generic cortex m4 makefile", "body": "- adding example cwrapper which generates a library to be included in c projects with simple api\r\n- adding make library option to the makefile template making the generated\r\n- allow make projects to have the compiler path explicitly defined in MakeFile\r\n- adds a python parser to pull out only the used ops from a tflite model", "comments": ["need to resubmit under different account."]}, {"number": 35953, "title": "failed to convert attention-ocr frozen graph to tflite", "body": "**System information**\r\n- OS Platform and Distribution Linux Ubuntu 18.04\r\n- TensorFlow installed from binary\r\n- TensorFlow version 1.15.0\r\n\r\n**I am using the following chunk of code to convert attention-ocr frozen graph to tflite**\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\n\r\nPATH_TO_MODEL = \"./exported-model/frozen_graph.pb\"\r\n\r\n\r\ninput_arrays = ['input_image_as_bytes']\r\noutput_arrays = ['prediction']\r\n\r\nconverter = tf.lite.TFLiteConverter.from_frozen_graph(graph_def_file=PATH_TO_MODEL,\r\n                                                      input_arrays=input_arrays,\r\n                                                      output_arrays=output_arrays,\r\n                                                      input_shapes= {\"input_image_as_bytes\" : (1, 128, 32)})\r\n\r\ntflite_model = converter.convert()\r\n\r\nopen(\"converted_model.tflite\", \"wb\").write(tflite_model)\r\n```\r\n\r\n**The output from the converter invocation**\r\n\r\n```\r\n2020-01-16 21:04:14.913210: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:786] Optimization results for grappler item: graph_to_optimize\r\n2020-01-16 21:04:14.913239: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   constant_folding: Graph size after: 2801 nodes (-133), 3997 edges (-163), time = 2018.08203ms.\r\n2020-01-16 21:04:14.913245: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   constant_folding: Graph size after: 2801 nodes (0), 3997 edges (0), time = 159.867ms.\r\nTraceback (most recent call last):\r\n  File \"converter.py\", line 18, in <module>\r\n    tflite_model = converter.convert()\r\n  File \"venv/lib/python3.6/site-packages/tensorflow_core/lite/python/lite.py\", line 983, in convert\r\n    **converter_kwargs)\r\n  File \"venv/lib/python3.6/site-packages/tensorflow_core/lite/python/convert.py\", line 449, in toco_convert_impl\r\n    enable_mlir_converter=enable_mlir_converter)\r\n  File \"venv/lib/python3.6/site-packages/tensorflow_core/lite/python/convert.py\", line 200, in toco_convert_protos\r\n    raise ConverterError(\"See console for info.\\n%s\\n%s\\n\" % (stdout, stderr))\r\ntensorflow.lite.python.convert.ConverterError: See console for info.\r\n2020-01-16 21:04:16.445609: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: MutableHashTableV2\r\n2020-01-16 21:04:16.445658: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-01-16 21:04:16.445688: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-01-16 21:04:16.445702: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-01-16 21:04:16.445710: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 2\r\n2020-01-16 21:04:16.445724: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-01-16 21:04:16.445734: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-01-16 21:04:16.445743: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: LookupTableInsertV2\r\n2020-01-16 21:04:16.445867: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-01-16 21:04:16.445878: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-01-16 21:04:16.445885: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-01-16 21:04:16.445948: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-01-16 21:04:16.445959: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-01-16 21:04:16.445968: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-01-16 21:04:16.445976: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-01-16 21:04:16.445986: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-01-16 21:04:16.445995: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-01-16 21:04:16.446013: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-01-16 21:04:16.446081: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3\r\n2020-01-16 21:04:16.446095: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-01-16 21:04:16.446105: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3\r\n2020-01-16 21:04:16.446114: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-01-16 21:04:16.446122: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-01-16 21:04:16.446135: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-01-16 21:04:16.446143: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-01-16 21:04:16.446151: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-01-16 21:04:16.446161: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-01-16 21:04:16.446169: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-01-16 21:04:16.446180: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayScatterV3\r\n2020-01-16 21:04:16.446194: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-01-16 21:04:16.446204: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: LoopCond\r\n2020-01-16 21:04:16.446221: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Exit\r\n2020-01-16 21:04:16.446310: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayReadV3\r\n2020-01-16 21:04:16.446323: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArraySizeV3\r\n2020-01-16 21:04:16.446345: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: DecodePng\r\n2020-01-16 21:04:16.446388: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayGatherV3\r\n2020-01-16 21:04:16.446430: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 2\r\n2020-01-16 21:04:16.446440: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 2\r\n2020-01-16 21:04:16.446553: F tensorflow/lite/toco/import_tensorflow.cc:1585] Check failed: data_type == DT_FLOAT \r\nFatal Python error: Aborted\r\n\r\nCurrent thread 0x00007fe7d035f740 (most recent call first):\r\n  File \"venv/lib/python3.6/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 52 in execute\r\n  File \"venv/lib/python3.6/site-packages/absl/app.py\", line 250 in _run_main\r\n  File \"venv/lib/python3.6/site-packages/absl/app.py\", line 299 in run\r\n  File \"venv/lib/python3.6/site-packages/tensorflow_core/python/platform/app.py\", line 40 in run\r\n  File \"venv/lib/python3.6/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 89 in main\r\n  File \"venv/bin/toco_from_protos\", line 8 in <module>\r\nAborted (core dumped)\r\n```\r\n\r\n**Here you can find a link to the frozen graph**\r\n\r\n```\r\nhttps://drive.google.com/open?id=1fD8PbgszlBscxyV2qVFqyEWFVlMcQvCd\r\n```\r\n\r\n**Failure details**\r\nI am attempting to convert this frozen graph to tflite.I tried all the possibilities, a) using a SavedModel for conversion, b) the tflite_convert command, c) using bazel to run the toco file but all produced the same file. I had found the following [issue](https://github.com/emedvedev/attention-ocr/issues/136) referenced on the aocr github repo page but it doesn't seem to take me anywhere.\r\n\r\nAny help is much appreciated!\r\n", "comments": ["@jvishnuvardhan any idea how to solve this?", "@vladdders I can reproduce the issue with `TF1.15` as well as `tf-nightly`. [Here](https://colab.sandbox.google.com/gist/jvishnuvardhan/f98dc30ec4ddbd421127bc5f99f639ec/untitled799.ipynb) is the gist with `tf-nightly` for our reference. [Here](https://colab.sandbox.google.com/gist/jvishnuvardhan/141126a417bd41cf53f287dc900e7366/untitled800.ipynb) is the gist with `TF1.15`.\r\n\r\nDo you have access to the code that was used to create the model? I think the `input` to the model was used as `tf.float64` which was not supported in `tf_lite`. Can you cast the input to `tf.float32` and save the model, convert the model to *.pb. Please let us know what you think? Thanks! ", "@jvishnuvardhan The code is in the aocr package, you can obtain it by `pip install aocr` or by visiting [this](https://github.com/emedvedev/attention-ocr). Below is the part that I think it pre-processes the data:\r\n\r\n```\r\nself.height = tf.constant(DataGen.IMAGE_HEIGHT, dtype=tf.int32)\r\nself.height_float = tf.constant(DataGen.IMAGE_HEIGHT, dtype=tf.float64)\r\n\r\nself.img_pl = tf.placeholder(tf.string, name='input_image_as_bytes')\r\nself.img_data = tf.cond(\r\n    tf.less(tf.rank(self.img_pl), 1),\r\n    lambda: tf.expand_dims(self.img_pl, 0),\r\n    lambda: self.img_pl\r\n)\r\nself.img_data = tf.map_fn(self._prepare_image, self.img_data, dtype=tf.float32)\r\nnum_images = tf.shape(self.img_data)[0]\r\n```\r\n\r\nWhen I try to change the type from float64 to float32 in line 2 I get the following:\r\n`ValueError: Tensor conversion requested dtype float64 for Tensor with dtype float32: <tf.Tensor 'Const_1:0' shape=() dtype=float32>`. Any idea why that might be? Thanks you!", "@vladdders What command you used to convert dtype? You can use this [tf.cast](https://www.tensorflow.org/api_docs/python/tf/cast) command to convert dtype. May be you need to convert dtype later in the code. May be you can post it in that repo so that you can get faster resolution. If you can make any standalone code, I will try to help. Thanks!", "I managed to solve the issue by casting those `float64` data types to `float32`. Thanks for your guidance!", "@vladdders \r\nHi I'm facing the same problem while converting the Attention-based OCR model into tflite, and have almost same unsupported op such as TensorArrayV3. How do you solve this? \r\n\r\nThank you so much for helping! ", "> I managed to solve the issue by casting those `float64` data types to `float32`. Thanks for your guidance!\r\n\r\nHi @vladdders : I tried converting my .pb file from float64 dtype to float32, by using the following code:\r\n\r\n```\r\ndef load_pb(path_to_pb):\r\n    with tf.gfile.GFile(path_to_pb, 'rb') as f:\r\n        graph_def = tf.GraphDef()\r\n        graph_def.ParseFromString(f.read())\r\n    with tf.Graph().as_default() as graph:\r\n        tf.import_graph_def(graph_def, name='')\r\n        return graph\r\n\r\n#For loading the .pb file\r\ntf_graph = load_pb('fbank_net/weights/triplet_loss_trained_model.pb')\r\nsess = tf.Session(graph=tf_graph)\r\n\r\n# To get the tensors, I used the following line\r\nall_tensors = [tensor for op in tf_graph.get_operations()for tensor in op.values()]\r\n# I iterated over all the tensors then cast them to tf.float32\r\nfor i, tensor in enumerate(all_tensors):\r\n    all_tensors[i] = tf.cast(tensor, tf.float32)\r\n# And saved the .pb file using\r\ntf.io.write_graph(tf_graph, '.', 'myfloat32m.pb')\r\n```\r\n\r\nBut when I use tf.lite.TFLiteConverter and then converter.convert() as shown below:\r\n```\r\nconverter = tf.lite.TFLiteConverter.from_frozen_graph('./myfloat32m.pb', input\r\n   ...: _arrays=['main_input'], output_arrays=['add_17'])\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\ntf_lite_model = converter.convert()\r\n\r\n# I get valueError dtype float64\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-9-92f300cb4b59> in <module>\r\n----> 1 tf_lite_model = converter.convert()\r\n\r\n~/.virtualenvs/pytorch2tensorflow/lib/python3.7/site-packages/tensorflow_core/lite/python/lite.py in convert(self)\r\n    981           input_tensors=self._input_tensors,\r\n    982           output_tensors=self._output_tensors,\r\n--> 983           **converter_kwargs)\r\n    984     else:\r\n    985       result = _toco_convert_graph_def(\r\n\r\n~/.virtualenvs/pytorch2tensorflow/lib/python3.7/site-packages/tensorflow_core/lite/python/convert.py in toco_convert_impl(input_data, input_tensors, output_tensors, enable_mlir_converter, *args, **kwargs)\r\n    440   \"\"\"\r\n    441   model_flags, toco_flags, debug_info = build_toco_convert_protos(\r\n--> 442       input_tensors, output_tensors, *args, **kwargs)\r\n    443   debug_info_str = debug_info.SerializeToString() if debug_info else None\r\n    444   data = toco_convert_protos(\r\n\r\n~/.virtualenvs/pytorch2tensorflow/lib/python3.7/site-packages/tensorflow_core/lite/python/convert.py in build_toco_convert_protos(input_tensors, output_tensors, inference_type, inference_input_type, input_format, input_shapes, output_format, quantized_input_stats, default_ranges_stats, drop_control_dependency, reorder_across_fake_quant, allow_custom_ops, change_concat_input_ranges, post_training_quantize, quantize_to_float16, dump_graphviz_dir, dump_graphviz_video, target_ops, allow_nonexistent_arrays, debug_info)\r\n    337     input_array.name = util.get_tensor_name(input_tensor)\r\n    338     input_array.data_type = util.convert_dtype_to_tflite_type(\r\n--> 339         input_tensor.dtype)\r\n    340 \r\n    341     if toco.inference_input_type == _types_pb2.QUANTIZED_UINT8:\r\n\r\n~/.virtualenvs/pytorch2tensorflow/lib/python3.7/site-packages/tensorflow_core/lite/python/util.py in convert_dtype_to_tflite_type(tf_dtype)\r\n     62   result = _MAP_TF_TO_TFLITE_TYPES.get(tf_dtype)\r\n     63   if result is None:\r\n---> 64     raise ValueError(\"Unsupported tf.dtype {0}\".format(tf_dtype))\r\n     65   return result\r\n     66 \r\n\r\nValueError: Unsupported tf.dtype <dtype: 'float64'>\r\n\r\n```\r\n\r\nCan you please help me out @vladdders  @jvishnuvardhan . Thanks a lot!\r\n", "@kylechang523 yeah I think that is because of the `map` operation. Check in `model.py`. You will have to remove all the operations that are not supported in tf lite, especially control flow operations.\r\n\r\n@sirius0503 it seems like for whatever reason you still have some float64 operations. Try to read your new graph and print the layers' datatypes to see where these could occur.", "@vladdders did you ever manage to export a tflite model from attention-ocr? "]}, {"number": 35952, "title": "Device placement function for placing network variables on specific device", "body": "Hey guys,\r\n\r\nI'm having trouble with using a placement function inside `tf.device(...)`. Basically I want that all network variables are placed on a specific device (e.g. cpu). All other tensors and operations should be placed at the current scope. Because a placement function inside `tf.decive(...)` needs always to return a device I implemented the function `pin_network_variables`, which separates the variables, tensors and ops to two devices.\r\nMy problem with that is, that now nesting multiple device scopes doesn't work any more. Now all variables, tensors and ops are placed accordingly to `pin_network_variables`.\r\nHere is a minimal example to illustrate the behavior:\r\n\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.layers import Dense\r\n\r\ndef pin_network_variables(var_device, op_device):\r\n    \"\"\"\r\n    Pins network variables to the specified device.\r\n\r\n    Args:\r\n        var_device: Device to put network variables on.\r\n        op_device: Device for everything except network variables.\r\n    \"\"\"\r\n\r\n    VAR_NAME_TYPS = ['kernel', 'bias', 'gamma', 'beta', 'moving_mean', 'moving_variance', 'recurrent_kernel']\r\n    def _is_network_var(op):\r\n        for var_type in VAR_NAME_TYPS:\r\n            if op.name.endswith('/' + var_type):\r\n                return True\r\n        return False\r\n\r\n    def _assign(op):\r\n        if _is_network_var(op):\r\n            return var_device\r\n        else:\r\n            return op_device\r\n\r\n    return _assign\r\n\r\ndef main(unused_argv):\r\n\r\n    # normally all network varibles whould be placed on cpu and everything else on gpu\r\n    with tf.device(pin_network_variables('/cpu:0', '/gpu:0')):\r\n\r\n        input_tensor = tf.ones((1, 5), tf.float32, 'input_tensor')\r\n\r\n        # the kernel and bias tensors are placed on cpu correctly\r\n        dense_1 = Dense(units=3,\r\n                        activation='softmax',\r\n                        use_bias=True,\r\n                        kernel_initializer='glorot_uniform',\r\n                        bias_initializer='zeros',\r\n                        name='dense_1')\r\n        dense_2 = Dense(units=3,\r\n                        activation='softmax',\r\n                        use_bias=True,\r\n                        kernel_initializer='glorot_uniform',\r\n                        bias_initializer='zeros',\r\n                        name='dense_2')\r\n\r\n        # the call ops of the layers are placed on gpu correctly\r\n        dense_1_out = dense_1(input_tensor)\r\n        dense_2_out = dense_2(input_tensor)\r\n\r\n        # in this scope are for example tensors and ops that need to be put on cpu, for computational reason\r\n        with tf.device('/cpu:0'):\r\n\r\n            # this op shoud be placed on cpu, but its put on gpu (due to 'pin_network_variables')\r\n            output_tensor = tf.add(dense_1_out, dense_2_out)\r\n\r\n    print('--------------------')\r\n    print('input_tensor\\t', input_tensor.device)\r\n    print('dense_1.kernel\\t', dense_1.kernel.device)\r\n    print('dense_1.bias\\t', dense_1.bias.device)\r\n    print('dense_2.kernel\\t', dense_2.kernel.device)\r\n    print('dense_2.bias\\t', dense_2.bias.device)\r\n    print('dense_1_out\\t', dense_1_out.device)\r\n    print('dense_2_out\\t', dense_2_out.device)\r\n    print('output_tensor\\t', output_tensor.device) # this should be put on cpu\r\n    print('--------------------')\r\n\r\n    # create, initialise and session\r\n    sess = tf.compat.v1.Session()\r\n    sess.run(tf.compat.v1.global_variables_initializer())\r\n    output = sess.run(output_tensor)\r\n    print(output)\r\n\r\nif __name__ == '__main__':\r\n    tf.compat.v1.app.run()\r\n```\r\n\r\nDoes anybody now a fix to this?\r\n\r\nOS Platform and Distribution: Windows 10\r\nTensorFlow installed from: pip\r\nTensorFlow version: 1.14.0\r\nPython version: 3.6", "comments": ["@baiztencale Sorry for missing this issue. Is this still an issue or was this resolved in recent TF versions `TF1.15.3` or `TF2.2`. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 35951, "title": "how to change model.trainable_weights manually", "body": "I am using TensorFlow 2.0 with Python 3.7.5 to manually change the weights of a neural network model. The code I have to change weights in a layer-wise manner is as follows:\r\n\r\n```\r\ndef create_nn():\r\n\t\"\"\"\r\n\tFunction to create a toy neural network model\r\n\t\"\"\"\r\n\t\r\n\tmodel = Sequential()\r\n\r\n\tmodel.add(\r\n\t\tDense(\r\n\t\t\tunits = 4, activation = 'relu',\r\n\t\t\tkernel_initializer = tf.keras.initializers.GlorotNormal(),\r\n\t\t\tinput_shape = (4,)\r\n\t\t\t)\r\n\t\t)\r\n\r\n\tmodel.add(\r\n\t\tDense(\r\n\t\t\tunits = 3, activation = 'relu',\r\n\t\t\tkernel_initializer = tf.keras.initializers.GlorotNormal()\r\n\t\t\t)\r\n\t\t)\r\n\r\n\tmodel.add(\r\n\t\tDense(\r\n\t\t\tunits = 1, activation = 'sigmoid')\r\n\t\t)\r\n\r\n\t# Compile the defined NN model above-\r\n\tmodel.compile(\r\n\t\tloss = 'binary_crossentropy',  # loss = 'categorical_crossentropy'\r\n\t\toptimizer = tf.keras.optimizers.Adam(lr = 0.001),\r\n\t\tmetrics=['accuracy']\r\n\t)\r\n\r\n\treturn model\r\n\r\n\r\n# Instantiate a neural network model-\r\norig_model = create_nn()\r\n\r\n# modify weights in each layer such that: weights less than 0.5 should become zero,\r\n# while weights greater than or equal to 0.5 should remain as it is-\r\nfor layer in orig_model.trainable_weights: \r\n    layer = tf.where(tf.less(layer, 0.5), 0, layer)\r\n\r\n# Check whether the manual weight modifications work-\r\nfor layer in orig_model.trainable_weights:\r\n    print(layer.numpy())\r\n```\r\n\r\nWhat can I do to modify/change the weights in a layer-wise manner in the above example?\r\n\r\nThanks", "comments": ["@arjun-majumdar \r\n\r\nCan you please go through the [link ](https://stackoverflow.com/questions/51354186/how-to-update-weights-manually-with-keras) and see if it helps you. Thanks!", "Problem Solved. Thanks!"]}, {"number": 35950, "title": "Error in cuda_dnn.cc(1921) with cudnnRNNBackwardData.  Failed to call ThenRNNBackward", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): [No](https://www.tensorflow.org/tutorials/text/text_classification_rnn)\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v2.1.0-rc1-58-g9837eceb39\r\n- Python version: 3.6.8\r\n- Bazel version (if compiling from source): n/a\r\n- GCC/Compiler version (if compiling from source): n/a\r\n- CUDA/cuDNN version: 10.1.243 / 7.6.0.64\r\n- GPU model and memory: NVIDIA GeForce GTX 1050, 4.00GiB\r\n\r\n**Describe the current behavior**\r\nI'm attempting to learn about Recurrent Neural Networks following [this](https://www.tensorflow.org/tutorials/text/text_classification_rnn) guide from Tensorflow.  For some reason whenever I try to run the network it fails.\r\n\r\nInterestingly network only ever seems to get past one epoch when verbose is set to 1, or excluded.  In this case it will typically complete 1-3 epochs before failing.\r\n\r\n**Other info / logs**\r\n\r\nPotentially similar to [this issue](https://github.com/tensorflow/tensorflow/issues/35791)\r\n\r\n```\r\n2020-01-16 10:26:44.374373: E tensorflow/stream_executor/dnn.cc:596] CUDNN_STATUS_INTERNAL_ERROR\r\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(1802): 'cudnnRNNForwardTraining( cudnn.handle(), rnn_desc.handle(), model_dims.max_seq_length, input_desc.handles(), input_data.opaque(), input_h_desc.handle(), input_h_data.opaque(), input_c_desc.handle(), input_c_data.opaque(), rnn_desc.params_handle(), params.opaque(), output_desc.handles(), output_data->opaque(), output_h_desc.handle(), output_h_data->opaque(), output_c_desc.handle(), output_c_data->opaque(), workspace.opaque(), workspace.size(), reserve_space.opaque(), reserve_space.size())'\r\n2020-01-16 10:26:44.375949: W tensorflow/core/framework/op_kernel.cc:1655] OP_REQUIRES failed at cudnn_rnn_ops.cc:1517 : Internal: Failed to call ThenRnnForward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 64, 64, 1, 1850, 64, 64] \r\n2020-01-16 10:26:44.376544: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Internal: Failed to call ThenRnnForward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 64, 64, 1, 1850, 64, 64] \r\n\t [[{{node CudnnRNN}}]]\r\n2020-01-16 10:26:44.377273: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Internal: {{function_node __forward_cudnn_lstm_with_fallback_4560_specialized_for_sequential_bidirectional_backward_lstm_StatefulPartitionedCall_at___inference_distributed_function_5790}} {{function_node __forward_cudnn_lstm_with_fallback_4560_specialized_for_sequential_bidirectional_backward_lstm_StatefulPartitionedCall_at___inference_distributed_function_5790}} Failed to call ThenRnnForward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 64, 64, 1, 1850, 64, 64] \r\n\t [[{{node CudnnRNN}}]]\r\n\t [[sequential/bidirectional/backward_lstm/StatefulPartitionedCall]]\r\n\t [[Reshape_11/_38]]\r\n2020-01-16 10:26:44.379170: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Internal: {{function_node __forward_cudnn_lstm_with_fallback_4560_specialized_for_sequential_bidirectional_backward_lstm_StatefulPartitionedCall_at___inference_distributed_function_5790}} {{function_node __forward_cudnn_lstm_with_fallback_4560_specialized_for_sequential_bidirectional_backward_lstm_StatefulPartitionedCall_at___inference_distributed_function_5790}} Failed to call ThenRnnForward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 64, 64, 1, 1850, 64, 64] \r\n\t [[{{node CudnnRNN}}]]\r\n\t [[sequential/bidirectional/backward_lstm/StatefulPartitionedCall]]\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Cal\\Desktop\\python\\NN\\RNN\\RNN.py\", line 50, in <module>\r\n    validation_steps=30)\r\n  File \"C:\\Users\\Cal\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 819, in fit\r\n    use_multiprocessing=use_multiprocessing)\r\n  File \"C:\\Users\\Cal\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\", line 342, in fit\r\n    total_epochs=epochs)\r\n  File \"C:\\Users\\Cal\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\", line 128, in run_one_epoch\r\n    batch_outs = execution_function(iterator)\r\n  File \"C:\\Users\\Cal\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\", line 98, in execution_function\r\n    distributed_function(input_fn))\r\n  File \"C:\\Users\\Cal\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\", line 568, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"C:\\Users\\Cal\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\", line 599, in _call\r\n    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\r\n  File \"C:\\Users\\Cal\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 2363, in __call__\r\n    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\r\n  File \"C:\\Users\\Cal\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 1611, in _filtered_call\r\n    self.captured_inputs)\r\n  File \"C:\\Users\\Cal\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 1692, in _call_flat\r\n    ctx, args, cancellation_manager=cancellation_manager))\r\n  File \"C:\\Users\\Cal\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 545, in call\r\n    ctx=ctx)\r\n  File \"C:\\Users\\Cal\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\", line 67, in quick_execute\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.InternalError:  [_Derived_]  Failed to call ThenRnnForward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 64, 64, 1, 1850, 64, 64] \r\n\t [[{{node CudnnRNN}}]]\r\n\t [[sequential/bidirectional/backward_lstm/StatefulPartitionedCall]]\r\n\t [[Reshape_11/_38]] [Op:__inference_distributed_function_5790]\r\n\r\nFunction call stack:\r\ndistributed_function -> distributed_function -> distributed_function\r\n```\r\n\r\n**Describe the expected behavior**\r\nThe network trains without error.\r\n\r\n**Code to reproduce the issue**\r\n\r\n````\r\nfrom __future__ import absolute_import, division, print_function, unicode_literals\r\n\r\nimport tensorflow_datasets as tfds\r\nimport tensorflow as tf\r\nimport matplotlib.pyplot as plt\r\n\r\ndef plot_graphs(history, string):\r\n  plt.plot(history.history[string])\r\n  plt.plot(history.history['val_'+string], '')\r\n  plt.xlabel(\"Epochs\")\r\n  plt.ylabel(string)\r\n  plt.legend([string, 'val_'+string])\r\n  plt.show()\r\n\r\ndataset, info = tfds.load('imdb_reviews/subwords8k', with_info=True,\r\n                          as_supervised=True)\r\ntrain_dataset, test_dataset = dataset['train'], dataset['test']\r\nencoder = info.features['text'].encoder\r\n\r\nBUFFER_SIZE = 10000\r\nBATCH_SIZE = 64\r\n\r\ntrain_dataset = train_dataset.shuffle(BUFFER_SIZE)\r\ntrain_dataset = train_dataset.padded_batch(BATCH_SIZE, tf.compat.v1.data.get_output_shapes(train_dataset))\r\n\r\ntest_dataset = test_dataset.padded_batch(BATCH_SIZE, tf.compat.v1.data.get_output_shapes(test_dataset))\r\n\r\nmodel = tf.keras.Sequential([\r\n    tf.keras.layers.Embedding(encoder.vocab_size, 64),\r\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\r\n    tf.keras.layers.Dense(64, activation='relu'),\r\n    tf.keras.layers.Dense(1, activation='sigmoid')\r\n])\r\n\r\nmodel.compile(loss='binary_crossentropy',\r\n    optimizer=tf.keras.optimizers.Adam(1e-4),\r\n    metrics=['accuracy'])\r\n\r\nhistory = model.fit(train_dataset, epochs=10, verbose=0,\r\n                    validation_data=test_dataset,\r\n                    validation_steps=30)\r\n\r\ntest_loss, test_acc = model.evaluate(test_dataset)\r\nprint('Test Loss: {}'.format(test_loss))\r\nprint('Test Accuracy: {}'.format(test_acc))\r\n````\r\n\r\n**Already Tried:**\r\n-Updating tensorflow to 2.1, then to 2.1rc1.\r\n-Updating CUDA\r\n-Updating cudNN to 7.6.5.32\r\n-Allowing GPU memory growth.\r\n", "comments": ["@Kal213 ,\r\nI was able to run the code in tf-nightly successfully, please find [gist](https://colab.sandbox.google.com/gist/oanush/2c3e0b9043e7f0ca278843749da2d996/35950.ipynb) for your reference.Thanks!", "Thanks for the reply @oanush.  I've tried updating to tf-nightly-gpu in my environment, but it still doesn't seem to work using GPU.  I've done some more reading and I believe it is an issue that only occurs when using a GPU.\r\n\r\nI still can't seem to get it working on my local environment using a GPU.  I've added \r\n`drop_remainder=True`\r\nto my batch functions, and it's now yielding me a different error:\r\n\r\n```\r\n2020-01-17 09:32:40.284023: E tensorflow/stream_executor/dnn.cc:613] CUDNN_STATUS_INTERNAL_ERROR\r\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(1921): 'cudnnRNNBackwardData( cudnn.handle(), rnn_desc.handle(), model_dims.max_seq_length, output_desc.handles(), output_data.opaque(), output_desc.handles(), output_backprop_data.opaque(), output_h_desc.handle(), output_h_backprop_data.opaque(), output_c_desc.handle(), output_c_backprop_data.opaque(), rnn_desc.params_handle(), params.opaque(), input_h_desc.handle(), input_h_data.opaque(), input_c_desc.handle(), input_c_data.opaque(), input_desc.handles(), input_backprop_data->opaque(), input_h_desc.handle(), input_h_backprop_data->opaque(), input_c_desc.handle(), input_c_backprop_data->opaque(), workspace.opaque(), workspace.size(), reserve_space_data->opaque(), reserve_space_data->size())'\r\n2020-01-17 09:32:40.284092: F tensorflow/stream_executor/cuda/cuda_dnn.cc:189] Check failed: status == CUDNN_STATUS_SUCCESS (7 vs. 0)Failed to set cuDNN stream.\r\n```\r\n\r\nAs a note, it provides this error when not using `drop_remainder=True`:\r\n```\r\n2020-01-17 09:39:13.713818: E tensorflow/stream_executor/dnn.cc:613] CUDNN_STATUS_EXECUTION_FAILED\r\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(1921): 'cudnnRNNBackwardData( cudnn.handle(), rnn_desc.handle(), model_dims.max_seq_length, output_desc.handles(), output_data.opaque(), output_desc.handles(), output_backprop_data.opaque(), output_h_desc.handle(), output_h_backprop_data.opaque(), output_c_desc.handle(), output_c_backprop_data.opaque(), rnn_desc.params_handle(), params.opaque(), input_h_desc.handle(), input_h_data.opaque(), input_c_desc.handle(), input_c_data.opaque(), input_desc.handles(), input_backprop_data->opaque(), input_h_desc.handle(), input_h_backprop_data->opaque(), input_c_desc.handle(), input_c_backprop_data->opaque(), workspace.opaque(), workspace.size(), reserve_space_data->opaque(), reserve_space_data->size())'\r\n2020-01-17 09:39:13.715385: W tensorflow/core/framework/op_kernel.cc:1712] OP_REQUIRES failed at cudnn_rnn_ops.cc:1922 : Internal: Failed to call ThenRnnBackward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 64, 64, 1, 3944, 64, 64] \r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Cal\\Desktop\\python\\NN\\RNN\\RNN.py\", line 41, in <module>\r\n    validation_steps=30)\r\n  File \"C:\\Users\\Cal\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 712, in fit\r\n    use_multiprocessing=use_multiprocessing)\r\n  File \"C:\\Users\\Cal\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\", line 341, in fit\r\n    109/Unknown - 19s 176ms/step - loss: 0.6929 - accuracy: 0.5070\r\n    110/Unknown - 21s 195ms/step - loss: 0.6929 - accuracy: 0.5070\r\n    total_epochs=epochs)\r\n  File \"C:\\Users\\Cal\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\", line 128, in run_one_epoch\r\n    batch_outs = execution_function(iterator)\r\n  File \"C:\\Users\\Cal\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\", line 98, in execution_function\r\n    distributed_function(input_fn))\r\n  File \"C:\\Users\\Cal\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\", line 571, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"C:\\Users\\Cal\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\", line 602, in _call\r\n    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\r\n  File \"C:\\Users\\Cal\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 2414, in __call__\r\n    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\r\n  File \"C:\\Users\\Cal\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 1660, in _filtered_call\r\n    self.captured_inputs)\r\n  File \"C:\\Users\\Cal\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 1741, in _call_flat\r\n    ctx, args, cancellation_manager=cancellation_manager))\r\n  File \"C:\\Users\\Cal\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 598, in call\r\n    ctx=ctx)\r\n  File \"C:\\Users\\Cal\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\", line 60, in quick_execute\r\n    inputs, attrs, num_outputs)\r\ntensorflow.python.framework.errors_impl.InternalError:  [_Derived_]  Failed to call ThenRnnBackward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 64, 64, 1, 3944, 64, 64] \r\n\t [[{{node gradients/CudnnRNN_grad/CudnnRNNBackprop}}]]\r\n\t [[StatefulPartitionedCall]]\r\n\t [[Reshape_10/_38]] [Op:__inference_distributed_function_5769]\r\n\r\nFunction call stack:\r\ndistributed_function -> distributed_function -> distributed_function\r\n```\r\n\r\nI'm very lost and confused as to why it won't work when using my GPU.  Any ideas?", "I just thought I'd update with the fix in case anyone else is unfortunate enough to experience this!\r\n\r\n[I found the fix here.](https://devtalk.nvidia.com/default/topic/1068082/cudnn/cudnn-lstm-is-broken-above-driver-431-60-unexpected-event-status-1-cuda-/)  The gist of it is that LSTM layers are a bit messy with NVIDIA drivers above 431.60.  Downgrading to 431.36 with a clean install fixed the problem and now allows me to run the network with a GPU.", "@oanush I get the same issue with similar code. Using tf2.1 on cuda 10.2 with driver 440.33.01. Interestingly this error only appears when all of the following settings\r\n\r\n* under a strategy scope\r\n* with more than one gpu\r\n* when the sequence_length changes (e.g. going from train to test back to train)\r\n* not in eager mode\r\n\r\nany workaround?", "I have had exactly the same problem with an RTX 2060 on Win10. And downgrading NVIDIA to 431.86 driver (from factory installation 442.23) with TF 2.2, CUDA 10.1 and CUDNN 7.6.5 seems to work for me too. Thanks.\r\n\r\nHowever, I am wondering: has a workaround been found to be able to run on newer driver versions? I'm surprised this issue hasn't been fixed by Nvidia yet... I would obviously prefer to avoid having to roll back to this old driver whenever it gets updated..."]}, {"number": 35949, "title": "AttributeError: 'Tensor' object has no attribute '_datatype_enum'", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS X Catalina (10.15.2)\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v2.0.0-rc2-26-g64c3d382ca 2.0.0\r\n- Python version: 3.7.5\r\n- GPU model and memory: Intel Iris Pro 1536 MB\r\n\r\n**Describe the current behavior**\r\n\r\nI get the errors\r\n\r\n> tensorflow.python.eager.core._FallbackException: This function does not handle the case of the path where all inputs are not already EagerTensors.\r\n\r\nthen \r\n\r\n> AttributeError: 'Tensor' object has no attribute '_datatype_enum'\r\n\r\nand then\r\n\r\n> AttributeError: 'ProgbarLogger' object has no attribute 'log_values'\r\n\r\nwhen I add the following callback to the list of callbacks of `my_model.fit`\r\n\r\n```\r\nmy_callback = tf.keras.callbacks.LambdaCallback(on_batch_begin=lambda batch, logs: tf.print(my_model.losses))\r\n```\r\n\r\n**Describe the expected behavior**\r\n\r\nNo error.\r\n\r\n**Code to reproduce the issue**\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\n\r\ndef get_model():\r\n    inp = tf.keras.layers.Input(shape=(1,))\r\n    x = tf.keras.layers.Dense(8, activity_regularizer=tf.keras.regularizers.l1(0.01))(inp)\r\n    x = tf.keras.layers.Dense(16, activity_regularizer=tf.keras.regularizers.l1(0.01))(x)\r\n    out = tf.keras.layers.Dense(1)(x)\r\n    model = tf.keras.Model(inputs=inp, outputs=out)\r\n    return model\r\n\r\n\r\ndef train():\r\n    my_model = get_model()\r\n    my_model.compile(optimizer=\"adam\", loss=\"mse\")\r\n    my_callback = tf.keras.callbacks.LambdaCallback(on_batch_begin=lambda batch, logs: tf.print(my_model.losses))\r\n    my_model.fit([1, 2, 3, 4], [0.1, 0.2, 0.4, 0.2], callbacks=[my_callback])\r\n\r\n\r\nif __name__ == '__main__':\r\n    train()\r\n```\r\n\r\nThis issue may be related to https://github.com/tensorflow/tensorflow/issues/28924 and https://github.com/tensorflow/tensorflow/issues/29931. Note that, if I don't use any regulariser, `tf.print` prints an empty list and no error occurs.", "comments": ["Issue replicating for 2.0 and [tf-nightly](https://colab.sandbox.google.com/gist/oanush/f48bb5fa2028ece28e5fcee88551e852/35949.ipynb).Thanks!", "You may use `print` instead of `tf.print` in `LambdaCallback` like,\r\n```python\r\nmy_callback = tf.keras.callbacks.LambdaCallback(on_batch_begin=lambda batch, logs: print(my_model.losses))\r\n```\r\nOutput:\r\n```python\r\nTrain on 4 samples\r\n[<tf.Tensor 'dense_6/ActivityRegularizer/truediv:0' shape=() dtype=float32>, <tf.Tensor 'dense_7/ActivityRegularizer/truediv:0' shape=() dtype=float32>]\r\n4/4 [==============================] - 2s 432ms/sample - loss: 1.7403\r\n```", "@ymodak In the example above, I am trying to print the `losses` property, but, actually, I wanted to print the output of a layer.\r\n\r\nHere's a complete working example to reproduce the same error when attempting to print out the values of the outputs of a layer.\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\n\r\ndef get_model():\r\n    inp = tf.keras.layers.Input(shape=(1,))\r\n    x = tf.keras.layers.Dense(8, activity_regularizer=tf.keras.regularizers.l1(0.01))(inp)\r\n    x = tf.keras.layers.Dense(16, activity_regularizer=tf.keras.regularizers.l1(0.01))(x)\r\n    out = tf.keras.layers.Dense(1)(x)\r\n    model = tf.keras.Model(inputs=inp, outputs=out)\r\n    model.summary()\r\n    return model\r\n\r\n\r\ndef train():\r\n    my_model = get_model()\r\n    my_model.compile(optimizer=\"adam\", loss=\"mse\")\r\n    my_callback = tf.keras.callbacks.LambdaCallback(\r\n        on_batch_begin=lambda batch, logs: tf.print(my_model.get_layer(\"dense\").output))\r\n\r\n    my_model.fit([1, 2, 3, 4], [0.1, 0.2, 0.4, 0.2], callbacks=[my_callback])\r\n\r\n\r\nif __name__ == '__main__':\r\n    train()\r\n```\r\n\r\n_Note that I want to print out the values of the tensors and not their symbolic representation._", "@ymodak The documentation of `tf.print` says\r\n\r\n> A TensorFlow operator that prints the specified inputs to a desired output stream or logging level. The inputs may be **dense** or **sparse Tensors**, **primitive python objects**, **data structures that contain tensors**, and **printable Python objects**. Printed tensors will recursively show the first and last elements of each dimension to summarize.\r\n\r\nSo are outputs of layers considered either sparse tensors or dense tensors? They should not be considered primitive Python objects, data structures that contain tensors or printable Python objects. \r\n\r\nAnyway, my main goal is to be able to print out the activations for each layer of a model at the end of the mini-batch (thus while training the model). See also https://stackoverflow.com/q/59789526/3924118.", "same issue with minimal example:\r\n\r\nar0 = Input(shape=(2,8,8,),name='ar0')\r\ntf.print(ar0)", "@Apsylem \r\nI had probably the same issue as you.\r\nThe reason IMHO is that the statement \"tf.print(ar0)\" is being executed. in the declaration phase of the tensorflow graph and not when the graph itself is being executed. In the declaration phase the tensors are not completely defined, they  have no real content.\r\n\r\nI came over this by creating a small Print-Layer and attaching it to the graph.\r\nYou could do something like this:\r\n\r\n```\r\n\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.layers import Layer, Input\r\n\r\n#The Printer-Layer class\r\nclass Print(Layer):\r\n    verbose=True#False\r\n\r\n    def __init__(self,message=\"\", fn=lambda arg: arg,**kwargs):\r\n        super(Print, self).__init__(**kwargs)\r\n        self.message=message\r\n        self.fn=fn\r\n        \r\n    def get_config(self):\r\n        return super(Print, self).get_config()\r\n\r\n    def call(self, inputs, *args, **kwargs):\r\n        if Print.verbose:\r\n          tf.print(self.message,self.fn(inputs))\r\n        return super(Print, self).call(inputs, *args, **kwargs)\r\n      \r\n    @classmethod\r\n    def print(cls,*args, **kwargs):    \r\n        if Print.verbose:\r\n          tf.print(*args, **kwargs)\r\n\r\n#somewhere where you define your model :\r\ndef defineModel():\r\n  ar0 = Input(shape=(2,8,8,),name='ar0')\r\n  ar0Intermediate = Print(\"shape of ar0 =\",fn=lambda x: tf.shape(x) )(ar0) #show the shape of ar0\r\n  ar0Intermediate = Print(\"Content of ar0 = \" )(ar0Intermediate) #show the content of ar0\r\n  out = tf.keras.layers.Dense(1)(ar0Intermediate)\r\n  model = tf.keras.Model(inputs=ar0, outputs=out)\r\n  return model\r\n  \r\ndef train():\r\n    trainData=np.random.uniform(low=0,high=15.0,size=(4,2,8,8))\r\n    testData=np.random.uniform(low=0,high=10.0,size=(4,2,8,8))\r\n\r\n    my_model = defineModel()\r\n    my_model.compile(optimizer=\"adam\", loss=\"mse\")\r\n    my_model.fit(trainData, testData)\r\n\r\nif __name__ == '__main__':\r\n   Print.verbose=True #False\r\n  train()\r\n```\r\nATTENTION!\r\nIn the function defineModel() I did ` ar0Intermediate = Print(...`  by purpose!\r\nIf I had written ` ar0 = Print(...`  the tensorflow graph would have been broken because in \r\n` model = tf.keras.Model(inputs=ar0, outputs=out)` ar0 is used as input tensor.\r\n\r\n[GitHubIssue35950_Apsylem.txt](https://github.com/tensorflow/tensorflow/files/4475613/GitHubIssue35950_Apsylem.txt)\r\n", "Is there a simple solution to this issue?\r\n\r\nSame problem here in tensorflow 2.2.0. I'm not able to print the values of a tensor in my loss function used within a keras model.", "@omalleyt12 We might expect tf.print to be wrapped by TensorFlowOpLayer?", "I have tried in colab with TF version 2.2, nightly version and was able to reproduce the issue.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/cf46faed2315a686d2c7aa5789b4626c/untitled26.ipynb).Thanks!", "@tomerk this is likely something `KerasTensor`s fixes", "So, some context on what's happening here:\r\n`tf.print` is meant to mimic python printing, and does not return values.\r\nIf you do `x = print(...)` x holds no value. `x = tf.print(...)` acts the same way. If there was meant to be a return value it would be very ambiguous whether the returned value should be the inputs, or the printed string.\r\n\r\nSo, if you do:\r\n```\r\na = tf.keras.Input(...)\r\nb = layer(a)\r\nc = tf.print(b)\r\n```\r\n`c` will not hold any value. So, putting `tf.print` in the middle of your functional api construction won't automatically turn it into a \"printing layer\". We don't plan to change this because printing is not an identity operation, and thinking of printing as an identity is an anti-pattern. More context on the design of `tf.print` can be found here: https://github.com/tensorflow/community/blob/master/rfcs/20180824-tf-print-v2.md\r\n\r\nDuring functional model construction `tf.print` will act like `print` and try to print the python object that symbolically represents that intermediate output.\r\n\r\n\r\nIf you want to observe intermediate values during the model call, and you're using functional model construction, then you have a few options:\r\n1. Use a keras lambda layer to run a function that tf.prints the inputs and then returns them\r\n2. Write a custom `Printer` layer that prints the inputs\r\n3. include the intermediate outputs you want to inspect in the outputs of your functional model. You can then directly inspect them programmatically after calling your model\r\n\r\n---------------------------------------------\r\nI'm closing the issue because the discussion has veered off from the initial `AttributeError` report. and it won't be easy to find for people who are looking for info about printing in Keras.\r\n\r\nBut, if the above three options don't meet your needs we encourage you to open a feature request specifically around extending the mechanisms for printingdebugging intermediate activations in Keras layers.\r\n\r\nSome extra context about your needs when you open the feature request would also be useful, so we can understand why the correct solutions don't meet them.\r\n\r\nE.g.\r\nAre you looking to interactively debug the activations?\r\nWould you like the model to *always* print?\r\nDo you want printing/debugging to happen during actual fitting, or just when interacting with a model object batch by batch?\r\nDo you need sporadic logging of intermediate activations that don't happen at each batch?", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35949\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35949\">No</a>\n"]}, {"number": 35948, "title": "Support for saved_model (tf2.*) in tf_compile", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 2.*\r\n- Are you willing to contribute it (Yes/No): No\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nTF_Compile doesn't accept saved_model\r\n**Will this change the current api? How?**\r\nit would add a saved_model entry under tf_library macro\r\n**Who will benefit with this feature?**\r\nAnyone using tf2.* and tf-compile. Frozen graphs are deprecated in 2.0\r\n**Any Other info.**\r\n<3", "comments": ["@Arjuna197,\r\nSorry for the delayed response. Is this **`feature`** still relevant? If so, can you please let us know the **`use case`** where this **`Feature`** is applicable? Thanks! ", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 35947, "title": "undef TranslateName to avoid name collision on Windows", "body": "On WIN32, many APIs are defined with suffix `A` or `W`\r\nto accomodate ASCII (CHAR) or wide char (WCHAR), e.g.\r\n`CopyFile` could be `CopyFileA` or `CopyFileW` depending\r\non Visual Studio configuration.\r\n\r\nWhile working on porting our Azure file system from Linux\r\nto Windows, we noticed the following errors:\r\n```\r\nazfs_ops.lo.lib(azfs_ops.obj) : error LNK2001: unresolved external symbol \"public: virtual class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > __cdecl tensorflow::FileSystem::TranslateNameA(class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const &)const \" (?TranslateNameA@FileSystem@tensorflow@@UEBA?AV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@AEBV34@@Z)\r\n```\r\n\r\nThe issue was that TranslateName is also a WIN32 API that was defined\r\nas TranslateNameA (or TranslateNameW) on Visual Studio when certain header\r\nfile are configured.\r\n\r\nThis PR undef TranslateName before `class FileSystem`, similiar to already undef'ed\r\n`CopyFile` and `DeleteFile` (see source code), to avoid name collision.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": []}]