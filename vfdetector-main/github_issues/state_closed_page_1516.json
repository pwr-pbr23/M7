[{"number": 7447, "title": "update", "body": "", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->", "Is this PR created by mistake, by any chance?\r\nI do not think we can accept this change, but just to make sure,\r\ncc/ @josh11b @asimshankar @skye ", "I'm guessing this was accidentally created too.\r\nIf I'm wrong, @jsonkey , would appreciate some discussion on what you're trying to achieve here and the best way to do so (for example, we'd want to avoid enhancements to `TF_DeprecatedSession` and instead have changes focused on `TF_Session`)."]}, {"number": 7446, "title": "Android Example TF Detect crashes when built with files in source directory", "body": "Android TF Detect crashes when I make the apk with inception_5 and mobile_multibox files in the assets directory and removed in BUILD as per the instructions at https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android\r\n\r\nIt works when built with automatic download. \r\n\r\nI commented out lines 66 & 67 in BUILD.\r\n \"@inception5h//:model_files\",\r\n \"@mobile_multibox//:model_files\",\r\n\r\nThe file size of the apk built with the files added to assets manually is 4195 bytes smaller than the apk built with automatically downloaded files.  ", "comments": ["What is the actual message for the crash? (Use adb logcat)\r\n\r\nIf you run unzip -v on the apk, do the contents look the same with either method? You probably have an extra layer of directories in there or something similar.", "I tracked down the issue.  The difference between builds is the automatic download version gets https://storage.googleapis.com/download.tensorflow.org/models/mobile_multibox_v1a.zip while the instructions at https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android specify to download https://storage.googleapis.com/download.tensorflow.org/models/mobile_multibox_v1.zip . (notice the \"a\" in the file name).  \r\n\r\nOne file contains multibox_location_priors.pb while the other has multibox_location_priors.txt.   "]}, {"number": 7445, "title": "memory overflow when processing Variable.eval()", "body": "I'm using Tensorflow to process a simple matrix factorization algorithm. Every step went correct but at the last step, where I want to `eval()` a Tensor to store it, the program didn't work and only occupied more and more memory. I tried to `eval()` the initial parameters before the algorithm, it correctly processed. Then I'm confused where the bug is.\r\nCore code is as follows.\r\n```\r\n\r\nclass model(object):\r\n    def __init__(self, others):\r\n        self.D = tf.constant(D, dtype = tf.float32)\r\n        self.Q = tf.constant(Q, dtype = tf.float32)\r\n        self.W = tf.Variable((np.random.rand(self.rank, sample_num)), dtype = tf.float32, name = 'W')\r\n        self.C = tf.Variable((np.random.rand(context_num, self.rank)), dtype = tf.float32, name = 'C')\r\n\r\n    def _run(self, sess):\r\n        Q = self.Q\r\n        D = self.D\r\n        W = self.W\r\n        print W.eval()     #correct results\r\n        C = self.C\r\n        #the optimization step, you can jump this because I think it's not the point\r\n        for i in xrange(self.max_iter):\r\n            if (i + 1) % 2 == 1:\r\n                for j in xrange(self.inner_maxiter):\r\n                    ED = tf.transpose(Q) * (1.0 / (1.0 + tf.exp(- tf.matmul(C, W))))\r\n                    recons = D - ED\r\n                    W_grad = tf.matmul(tf.transpose(C), recons)\r\n                    W = W + self.stepsize * W_grad\r\n            else:\r\n                for j in xrange(self.inner_maxiter):\r\n                    ED = tf.transpose(Q) * (1.0 / (1.0 + tf.exp(- tf.matmul(C, W))))\r\n                    recons = D - ED\r\n                    C_grad = tf.matmul(recons, tf.transpose(W))\r\n                    C = C + self.stepsize * C_grad\r\n            print 'epoch: %d' % i\r\n        \r\n        print W.eval()  #program stopped and occupying memory \r\n        print C.eval()\r\n\r\ntrain_epoch = model(D, Q, others)\r\nwith tf.Session(config = config) as sess:\r\n    tf.initialize_all_variables().run()\r\n    train_epoch._run(sess)\r\n```\r\n\r\nIt's fairly strange because eval() just work well before the optimization step, but crashed after it. Is this a bug in eval()?", "comments": ["solved", "How did you solve it?"]}, {"number": 7444, "title": "tfprof model analyzer ignores scalar parameters", "body": "### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\nSearched issues for \"tfprof\"\r\n\r\n### Environment info\r\ngcr.io/tensorflow/tensorflow:1.0.0-rc2-devel-gpu\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\n```python\r\nimport tensorflow as tf\r\n\r\nsess = tf.InteractiveSession()\r\nv = tf.Variable(0., dtype=tf.float32, trainable=True)\r\n\r\ntf.contrib.tfprof.model_analyzer.print_model_analysis(tf.get_default_graph())\r\n```\r\n\r\nThis will show `total_parameters` of `0`, despite there being a parameter.\r\n\r\n### What other attempted solutions have you tried?\r\nN/A\r\n\r\n### Logs or other output that would be helpful\r\n```\r\nname: \"_TFProfRoot\"\r\nexec_micros: 0\r\nrequested_bytes: 0\r\ntotal_exec_micros: 0\r\ntotal_requested_bytes: 0\r\ntotal_parameters: 0\r\nchildren {\r\n  name: \"Variable\"\r\n  exec_micros: 0\r\n  requested_bytes: 0\r\n  total_exec_micros: 0\r\n  total_requested_bytes: 0\r\n  total_parameters: 0\r\n  float_ops: 0\r\n  total_float_ops: 0\r\n}\r\nfloat_ops: 0\r\ntotal_float_ops: 0\r\n```\r\n\r\nI believe this is coming from the logic here: https://github.com/tensorflow/tensorflow/blob/v1.0.0-rc2/tensorflow/tools/tfprof/internal/tfprof_show.cc#L37 which skips nodes with empty shapes, which includes scalars.", "comments": [" @petewarden does tfprof maintainer have github username? tensorflow/tensorflow/tools/tfprof/", "I believe it's @panyx0718, but I'm not certain.", "Let me look into it", "A fix has been submitted. Will be available in next release", "Fixed #7444", "Cool \u2013 should we close this issue then, or does that typically wait until the change lands in the public GH repo?", "I would suggest you wait until the release. It would be great if you can further verify the fix. Thanks!", "@panyx0718 possibly related issue: http://stackoverflow.com/questions/42309202/profiling-tensorflow-using-tfprof (sorry, I'd  cc you on email but couldn't find it)", "Confirmed this was fixed by https://github.com/tensorflow/tensorflow/commit/1849946c09ad93bc2e4f49c658049223e1efe908 from https://github.com/tensorflow/tensorflow/pull/7539."]}, {"number": 7443, "title": "Add Continuous Integration + Review Requirements to CONTRIBUTING.md", "body": "Could some basic instructions and suggestions be added to [CONTRIBUTING.md](\r\nhttps://github.com/tensorflow/tensorflow/blob/master/CONTRIBUTING.md)?\r\n\r\nExample notes to add:\r\n - correctly installing and configuring a compliant python/C++ linter\r\n - links and explanation of other guidelines that must be followed\r\n - how to run tests on your own machine\r\n", "comments": ["I agree that it would be useful to community. I think perhaps someone who has recently gone through the process might be motivated to put the important things together into a nice guide.\r\n\r\nSome snippets from my development notes:\r\n\r\nmaking a PR: https://gist.github.com/yaroslavvb/bdb0a92f2a516ebbe2d386c48f5e2c45\r\n\r\n- license\r\n\r\nYou must sign CLA agreement. See comments from Chris DiBona for why this license was chosen -- https://www.reddit.com/r/MachineLearning/comments/3s4qpm/google_tensorflow_released/\r\n\r\nIf you created your commits with a wrong address (ie, default one git sets up), you have to rewrite your commit history to change your address to the one that corresponds to the one you signed CLA with. (github help pages a rewriting script that provded useful for this,  https://help.github.com/articles/changing-author-info/)\r\n\r\n- pylint\r\n\r\n```\r\npip install pylint\r\nwget -O /tmp/pylintrc https://raw.githubusercontent.com/tensorflow/tensorflow/master/tensorflow/tools/ci_build/pylintrc\r\npylint myfile.py --rcfile=/tmp/pylintrc\r\n```\r\n\r\n- buildifier\r\n\r\nInstall https://github.com/bazelbuild/buildifier and running it over the BUILD file to fix any formatting issues\r\n\r\n- clang format\r\nTo see style corrections suggested by `clang-format`\r\n\r\n```\r\nbrew install clang-format\r\nclang-format tensorflow/stream_executor/cuda/cuda_diagnostics.cc --style=google > /tmp/cuda_diagnostics.cc\r\ndiff tensorflow/stream_executor/cuda/cuda_diagnostics.cc /tmp/cuda_diagnostics.cc\r\n\r\n```\r\n- Running tests\r\n\r\nUse `bazel test`. To see pip install requirements,  check in tensorflow/tools/ci_build/install/install_pip_packages.sh\r\n\r\nMost recently this meant doing this\r\n\r\n```\r\npip install -I --upgrade setuptools\r\npip install portpicker\r\npip install mock\r\npip install pep8\r\npip install pylint\r\npip install py-cpuinfo\r\npip install pandas==0.18.1\r\npip install wheel\r\npip install --upgrade six==1.10.0\r\npip install --upgrade werkzeug==0.11.10\r\npip install --upgrade protobuf==3.0.0\r\n\r\n```\r\n\r\nThen on Ubuntu:\r\n```\r\nexport LD_LIBRARY_PATH=\"/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:$LD_LIBRARY_PATH\"\r\n\r\nexport flags=\"--config=opt --config=cuda -k\"\r\nbazel test $flags //tensorflow/python/...\r\n```\r\n\r\nOn MacOS: (bazel needs to be explicitly told to pass env vars for some reason)\r\n```\r\nexport CUDA_HOME=/usr/local/cuda\r\nexport DYLD_LIBRARY_PATH=/usr/local/cuda/lib:/usr/local/cuda/extras/CUPTI/lib\r\nexport LD_LIBRARY_PATH=$DYLD_LIBRARY_PATH\r\nexport PATH=$DYLD_LIBRARY_PATH:$PATH\r\n\r\nexport flags=\"--config=cuda --config=opt -k --action_env PATH --action_env DYLD_LIBRARY_PATH --action_env LD_LIBRARY_PATH -k\"\r\nbazel test $flags //tensorflow/python/...\r\n```\r\n\r\nFor changes to core framework\r\n`bazel test $flags //tensorflow/...\r\n`\r\n\r\nKeeping flags in $flags is important because if you you forget a flag, and do `bazel run` or `bazel test` with a new setting, it'll start building everything from scratch, aka 20+ mins of machine being semi-unresponsive.\r\n\r\nFor long running tests, tmux is useful for provide robustness against disconnection/closing terminal:\r\n```\r\ntmux new -s bazel -n 0\r\nbazel test //tensorflow/...\r\n\r\n```\r\nAlso, this to keep bazel from wiping its state overnight \r\n\r\n`echo \"startup --max_idle_secs=100000000\"  > ~/.bazelrc\r\n`\r\n\r\nAlso, some notes on general philosophy of contributions -- when you contribute something to TensorFlow, the maintenance burden is transferred to the Google TensorFlow team. This means that benefit of contribution must be compared against the cost of maintaining that feature until the heat death of universe.\r\n\r\nHence there are cases when you want to extend functionality of TensorFlow, while remaining the owner/maintainer of this extension. This can be done by keeping extra functionality in a separate repo and using TensorFlow API to bring it in during runtime. For instance, new kernels/ops can be added to TensorFlow using TensorFlow plugin mechanism (load_library)", "Awesome info! Since you mentioned tmux there is also http://byobu.co/ which is built on top of tmux and improves usability.", "@ahundt, would you be willing to contribute a document to this effect? @gunan, do you have any other suggestions?", "One quick way to contribute would be to use our devel dockerfiles.\r\nBut what is already mentioned sounds good to me.", "@aselle I don't know all the policies at the moment that's why I asked, heh", "I've added a couple of things (buildifier, clang-format) to original reply. I'll keep merging in extra things I come across in there until there's a better place", "@yaroslavvb Could you just create a pull request directly adding the text to [CONTRIBUTING.md](CONTRIBUTING.md)?\r\n\r\nRegarding the folder of docker files, some of those scripts do look fairly straightforward and could be referenced:\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/docker", "FYI, we are working on the suggested improvements to CONTRIBUTING.md and possibly the docker files as well.", "@vrv @caisq Thanks that guide looks super helpful!"]}, {"number": 7442, "title": "Add a bit more descriptions on adding an op?", "body": "Hi,\r\n\r\nI'm trying to add my custom op and feeling that the document doesn't give enough information on how it works. I struggled a lot and finally I'm able to figure things out by reading the code of some header files.\r\n\r\nCan anyone take a look if the changes to the document in this PR will make it better for new people?", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored by someone other than the pull request submitter.  We need to confirm that they're okay with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of the commit author(s) and merge this pull request when appropriate.*\n\n<!-- need_author_consent -->", "Added a bit of grammar/reworded, looks good otherwise", "That's weird, CLA bot didn't recognize my email (its first time I made edit directly from to PR from the github window), github commit page still shows me as author, any ideas @martinwicke ? The \"red cross\" icon next to commit says \"CLA is signed but we are unable to verify author consent\"", "See the fine print in the CLAbot message: It's giving up and it's up to us to make sure you're ok with us merging your commit. Since you clearly are, we will proceed to ignore CLAbot.", "This is nice, thanks for these clarifications.  Apparently our documentation is in the middle of a reorganization and will be done in a week or two, and we've been told to hold off on changes to documentation this week and next, otherwise these changes will get lost in the changeover.\r\n\r\nWe can re-ping this PR once the new documentation files are up, and you can make changes to those files once they are ready.  Thank you for the contribution and your patience!", "OK, no problem. It's a great news that there will be a better docs in 1-2 weeks!", "In this case, I don't think there are going to be new docs for adding an op, just a restructuring (there some edits, but not the ones you made, which are great).", "Could you please update your PR to reflect our move from g3doc/ to doc_src/?\r\nhttps://github.com/tensorflow/tensorflow/commit/1c707ac780313f48a6733dc3beedf4b8a2b3df77\r\n\r\nIn particular, there are some new instructions here:\r\nhttps://github.com/tensorflow/tensorflow/blob/1c707ac780313f48a6733dc3beedf4b8a2b3df77/tensorflow/g3doc/README.txt\r\n\r\nThanks!", "I think this is just a merge", "@tensorflow-jenkins Test this please"]}, {"number": 7441, "title": "GraphDef is deprecated.", "body": "", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "doc change, just merging."]}, {"number": 7440, "title": "can't install TensorFlow properly (to use KeraS)", "body": "I can't install TensorFlow properly (to use it with Keras)  \r\nI did install it manually with this command:\r\npip install tensorflow-1.0.0rc2-py2-none-any.whl\r\nMy operating system: OSX: 10.12.3\r\n\r\nhere's the error I get, any suggestions?\r\n\r\nUsing TensorFlow backend.\r\n\r\nTraceback (most recent call last):\r\n  File \"<pyshell#1>\", line 1, in <module>\r\n    import keras\r\n  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/keras/__init__.py\", line 2, in <module>\r\n    from . import backend\r\n  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/keras/backend/__init__.py\", line 67, in <module>\r\n    from .tensorflow_backend import *\r\n  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py\", line 1, in <module>\r\n    import tensorflow as tf\r\n  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/__init__.py\", line 72, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/__init__.py\", line 61, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 28, in <module>\r\n    _pywrap_tensorflow = swig_import_helper()\r\n  File \"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)\r\nImportError: dlopen(/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so, 10): no suitable image found.  Did find:\r\n\t/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so: mach-o, but wrong architecture\r\n\r\n\r\nFailed to load the native TensorFlow runtime.", "comments": ["Could you please try importing tensorflow only. You need to make sure that tensorflow is working itself. If that doesn't work, using keras together with tensorflow will certainly not work. Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "Hi,\r\n\r\nI got the same problem.\r\n\r\nI installed tensorflow with \"pip install --upgrade https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-1.0.1-py2-none-any.whl\"\r\n\r\nPython 2.7.13 (v2.7.13:a06454b1afa1, Dec 17 2016, 12:40:10) \r\n[GCC 4.2.1 (Apple Inc. build 5577)] on darwin\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/Users/misak/tensorflow/lib/python2.7/site-packages/tensorflow/__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"/Users/misak/tensorflow/lib/python2.7/site-packages/tensorflow/python/__init__.py\", line 72, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"/Users/misak/tensorflow/lib/python2.7/site-packages/tensorflow/python/__init__.py\", line 61, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"/Users/misak/tensorflow/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 28, in <module>\r\n    _pywrap_tensorflow = swig_import_helper()\r\n  File \"/Users/misak/tensorflow/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)\r\nImportError: dlopen(/Users/misak/tensorflow/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so, 10): no suitable image found.  Did find:\r\n\t/Users/misak/tensorflow/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so: mach-o, but wrong architecture\r\n\t/Users/misak/tensorflow/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so: mach-o, but wrong architecture\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md#import_error\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\n", "Never mind. I got it working with python3."]}, {"number": 7439, "title": "Batch Normalization for Multi-GPU / Data Parallelism", "body": "Where is the batch normalization implementation for Multi-GPU scenarios? How does one keep track of `mean`, `variance`, `offset` and `scale` in the context of the Multi-GPU example as given in the [CIFAR-10 tutorial](https://github.com/tensorflow/models/blob/master/tutorials/image/cifar10/cifar10_multi_gpu_train.py)?\r\n\r\nWhy is the question on [StackOverflow](http://stackoverflow.com/questions/41819080/how-do-i-use-batch-normalization-in-a-multi-gpu-setting-in-tensorflow) left unanswered for so long?\r\n\r\nFor all the beauty that it brings with Tensorboard etc.. , it's kinda appalling to see Tensorflow so far behind Torch in terms of its modeling capability. I'd be really glad if someone takes up responsibility and comes up with a decent Batch Normalization implementation for all cases. Even if it is already there, could anyone care enough to make a **good documentation** out of it?\r\n\r\nThere are so many issues pertaining to batch normalization with Tensorflow. It's important that you guys straighten this out as batch normalization enables super-fast convergence for very deep networks and it is **REALLY** important for modern day deep learning research.\r\n\r\nPS: Please spare my outburst. I've been a Torch user for more than a year and I had very high hopes on Tensorflow.", "comments": ["How does Torch handle multi-GPU batch normalization? Batch normalization on multi-GPU batch incurs and extra performance penalty because statistics need to be communicated across all GPUs, so are some performance questions to consider in. You can aggregate statistics on CPU, aggregate them by going around in a ring along the lines of how Nvidia NCCL all-reduce does, or aggregate them by doing a tree reduction.\r\n\r\nAlso you can also do a \"pseudo-batch normalization\", by using existing batch norm layer to normalize GPU-sized batches, and then add batches together for a single \"multi-GPU batch\".\r\n\r\nI suspect there are easier ways to handle normalization of huge batches that doesn't introduce the performance hit you would see with batch normalization, like weight normalization -- https://arxiv.org/pdf/1602.07868.pdf", "@kvrd18 As pointed out above, there are just too many ways to implement batch norm across GPUs. TensorFlow now doesn't seem to provide a \"default\" way how it is implemented.\r\n\r\n@yaroslavvb My understanding is that most frameworks (including caffe & torch) doesn't aggregate statistics across GPUs at all. Different GPUs maintain statistics independently and statistics from only one GPU are used at test time. The official inceptionv3 example in tensorflow/models also [does something similar](https://github.com/tensorflow/models/blob/master/inception/inception/inception_train.py#L249).\r\nI've used the same strategy for quite a while and it's working fine. One catch is that in this case it's more important to shuffle the training data, otherwise the statistics on different GPUs are not i.i.d any more. \r\n", "I have the same issue, too. I believe distributed batch normalization is very important for some problems like action recognition. It will be very useful if Tensorflow can provide an implementation.\r\n\r\n[Here](https://github.com/shiyemin/shuttleNet/blob/master/train_video_classifier.py#L408-L429) is my trick for train BN on action recognition, which just rearranges the sample order so that every GPU can get reasonable mean and variance.", "@shiyemin are approaches mentioned in @ppwwyyxx reply acceptable for your needs? This may be a good material for community contribution. If Google adds multi-GPU batch-norm it may end up optimized for their custom interconnect hardware, rather than commodity hardware.", "@ppwwyyxx @yaroslavvb As far as i know, shuffling the training data is not enough for tasks like action recognition. Because that one GPU can only handle 2 videos (each video have 16 frames), which is a too small batch size for calculating the mean and variance. That's the reason i shuffle the batch itself at each step. After go through the CNN, the batch will be rearranged to its original order to be fed into LSTM.\r\n\r\nHowever, my trick will hurt the speed **severely**.", "@yaroslavvb, in Torch, the weights updates for each module in a replica are accumulated and summed together on the first replica. Owing to Torch's modular code base, with `BatchNormalization` being a module, its internal parameters also undergo the same computational flow as described above. Also, Torch has used [NCCL](https://github.com/NVIDIA/nccl) to enable fast inter-GPU communication.\r\n\r\nTo define a model in Torch, you would do this,\r\n```lua\r\n\r\nfunction makeConvNet()\r\n  model = nn.Sequential()\r\n  model:add(nn.SpatialConvolution(1,32,3,3))\r\n  model:add(nn.SpatialBatchNormalization(32))\r\n  model:add(nn.View(-1):setNumInputDims(3))\r\n  return model\r\nend\r\n```\r\n\r\nHere, `nn.SpatialConvolution` and `nn.SpatialBatchNormalization` are modules which have its own `forward` and `backward` passes. All you have to do to make it compatible with data parallelism is to invoke [`nn.DataParallelTable`](https://github.com/torch/cunn/blob/master/DataParallelTable.lua)\r\n\r\n```lua\r\n-- CONSTRUCT MODEL:\r\nconv_net = makeConvNet()  -- i.e. create nn.Sequential() and fill it\r\nnet = nn.DataParallelTable(1)  -- Split along first (batch) dimension\r\nnet:add(conv_net, {1, 2}) -- Use GPUs 1 and 2\r\n-- TRAINING:\r\nfor i = 1, num_epochs do\r\n  local output = net:forward(input)\r\n  local err = criterion:forward(output, target)\r\n  net:zeroGradParameters()\r\n  local gradOutput = criterion:backward(output, target)\r\n  local gradInput = net:backward(input, gradOutput)\r\n  net:updateParameters(lr)\r\nend\r\n```", "@kvrd18 What you described is the general case for most modules in torch. However for batch normalization, my best understanding is that torch by default doesn't synchronize the mean/variance among GPUs, but only the other two parameters (scaling and shifting).\r\nRelevant issue here: https://github.com/torch/nn/issues/1071 ", "It's going to be painful to train fully convolutional networks on multiple GPUs that cannot afford to have huge batch sizes to alleviate the problems that might arise out of not synchronizing mean and variance among GPUs.", "It would be good experiment to make -- compare torch approach, vs. keeping variance on GPU0 vs keep variance on CPU. I suspect when your GPUs are p2p connected, keeping vars on GPU0 will be better. (ie, I found cifar multi-GPU example runs 15% faster when weights are pinned to GPU0)", "@kvrd18 It could be an improvement to aggregate the statistics (before the actual normalization), instead of normalizing by each GPU's own statistics. This can avoid potential problems that the statistics of a small batch is too unstable. You can do this in tensorflow but this is going to be very expensive.\r\n\r\nMaybe [Batch Renormalization](https://arxiv.org/abs/1702.03275) is a better option in this case. It shows a better performance on small batches.", "This question might be better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a clear feature request yet.  However, if we define this as a feature for simple easy to use multi-gpu batch normalization, that would be a great contribution. Marking this as contributions welcome as a result. Thanks!", "I've built a batch normalization layer for multi-GPU. It predicts well on the validation set only if the `is_training` is `True`. Not sure why though. Can someone help me with this?\r\n\r\n```python\r\n\r\ndef _variable_on_cpu(name, shape, initializer, trainable=True):\r\n\r\n\twith tf.device('/cpu:0'):\r\n\t\tdtype = tf.float32\r\n\t\tvar = tf.get_variable(name, shape, initializer=initializer, dtype=dtype, trainable=trainable)\r\n\treturn var\r\n\r\ndef BatchNorm(inputs, is_training, decay = 0.9, epsilon=1e-3):\r\n\r\n\tscale = _variable_on_cpu('scale', inputs.get_shape()[-1], tf.constant_initializer(1.0))\r\n\tbeta = _variable_on_cpu('beta', inputs.get_shape()[-1], tf.constant_initializer(0.0))\r\n\tpop_mean = _variable_on_cpu('mean', inputs.get_shape()[-1], tf.constant_initializer(0.0), trainable=False)\r\n\tpop_var = _variable_on_cpu('variance', inputs.get_shape()[-1], tf.constant_initializer(1.0), trainable=False)\r\n\taxis = list(range(len(inputs.get_shape())-1))\r\n\r\n\tdef Train(inputs, pop_mean, pop_var, scale, beta):\r\n\t\tbatch_mean, batch_var = tf.nn.moments(inputs,axis)\r\n\t\ttrain_mean = tf.assign(pop_mean, pop_mean * decay + batch_mean * (1 - decay))\r\n\t\ttrain_var = tf.assign(pop_var, pop_var * decay + batch_var * (1 - decay))\r\n\t\twith tf.control_dependencies([train_mean,train_var]):\r\n\t\t\treturn tf.nn.batch_normalization(inputs, batch_mean, batch_var, beta, scale, epsilon)\r\n\r\n\tdef Eval(inputs, pop_mean, pop_var, scale, beta):\r\n\t\treturn tf.nn.batch_normalization(inputs, pop_mean, pop_var, beta, scale, epsilon)\r\n\r\n\treturn tf.cond(is_training, lambda: Train(inputs, pop_mean, pop_var, scale, beta),\r\n\t\tlambda: Eval(inputs, pop_mean, pop_var, scale, beta))\r\n```\r\n\r\nThis is working well on multi-GPU / data parallelism as long as the module is in training mode.", "@kvrd18 For a multi-GPU batch norm, we have to sync the batch_mean and batch_var, not just the moving_mean and moving_var, so that every GPU will get batch_mean and batch_var which are close to the global mean and variance.", "@shiyemin Each layer in each GPU will have its own `batch_mean` and `batch_var`, if I'm correct because the input data is split across the batch dimension and fed to each GPU. I do not understand what you mean when you say we'll have to sync the `batch_mean` and `batch_var`. They're specific to the input batch and are computed by `tf.nn.moments`.", "@shiyemin If I understood you right, I'd have to compute the `moments` by concatenating the input batches on the fly when the forward pass is being computed. That is going to be very expensive, computationally. Is this where the usage of NVIDIAs nccl is recommended?", "The inception example as pointed in https://github.com/tensorflow/tensorflow/issues/7439#issuecomment-279193381 is a good enough solution for me now. Thanks, @ppwwyyxx.", "Hello, I am training the BatchNorm layer in multiple GPUs using `tf.contrib.layers.batch_norm` function. In the training phase, we have to collect moving_mean and moving_variance using the function\r\n\r\n    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS) \r\n\r\nHowever, I found that utilization of the function has some ways\r\n\r\n1.**Inside a loop function** [cifar10_main][1]\r\n\r\n\r\n    with tf.device('/cpu:0'):\r\n      update_ops=[]\r\n      with tf.variable_scope(tf.get_variable_scope()):\r\n         for i in range(self.conf.num_gpus):\r\n            with tf.device('/gpu:%d' % i):\r\n    \t   with tf.name_scope('device_%d' % i):\r\n    \t      update_ops.extend(tf.get_collection(tf.GraphKeys.UPDATE_OPS))\r\n      variable_averages = tf.train.ExponentialMovingAverage(self.conf.MOVING_AVERAGE_DECAY, global_step)\r\n      variables_averages_op = variable_averages.apply(tf.trainable_variables())\r\n      with tf.control_dependencies(update_ops):\r\n         self.train_op = tf.group(train_op_conv,variables_averages_op)\r\n\r\n2.**Outside a loop function** [cifar10_multi_gpu][2]\r\n\r\n\r\n    with tf.device('/cpu:0'):\r\n      with tf.variable_scope(tf.get_variable_scope()):\r\n         for i in range(self.conf.num_gpus):\r\n            with tf.device('/gpu:%d' % i):\r\n    \t   with tf.name_scope('device_%d' % i):\r\n    \t      #Igore the line update_ops\r\n      variable_averages = tf.train.ExponentialMovingAverage(self.conf.MOVING_AVERAGE_DECAY, global_step)\r\n      variables_averages_op = variable_averages.apply(tf.trainable_variables())\r\n      update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)  \r\n      with tf.control_dependencies(update_ops):\r\n         self.train_op = tf.group(train_op_conv,variables_averages_op)\r\n\r\n3.**Both inside and outside a loop function** [inception v3][3], [cifar10][4]\r\n\r\n    with tf.device('/cpu:0'):\r\n      with tf.variable_scope(tf.get_variable_scope()):\r\n         for i in range(self.conf.num_gpus):\r\n            with tf.device('/gpu:%d' % i):\r\n    \t   with tf.name_scope('device_%d' % i):\r\n    \t      update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS) \r\n      variable_averages = tf.train.ExponentialMovingAverage(self.conf.MOVING_AVERAGE_DECAY, global_step)\r\n      variables_averages_op = variable_averages.apply(tf.trainable_variables())            \r\n      batchnorm_updates_op = tf.group(*update_ops)\r\n      self.train_op = tf.group(train_op_conv, train_op_fc,variables_averages_op,batchnorm_updates_op)\r\n\r\nWhat is the right way? In my opinion, it may be the third way\r\n\r\n\r\n  [1]: https://github.com/tensorflow/models/blob/master/tutorials/image/cifar10_estimator/cifar10_main.py#L121\r\n  [2]: https://github.com/tensorflow/models/blob/master/tutorials/image/cifar10/cifar10_multi_gpu_train.py\r\n  [3]: https://github.com/tensorflow/models/blob/master/research/inception/inception/inception_train.py\r\n  [4]: https://github.com/tensorflow/models/blob/dd9a81c03bf924db8d461a3e696ba1bd4bb193fc/tutorials/image/cifar10_estimator/cifar10_main.py", "I've found a simple way to implement distributed batch normalization in pure tensorflow, which I would like to share with you guys: [batch norm across GPUs](https://github.com/holyseven/PSPNet-TF-Reproduce/blob/master/model/utils_mg.py#L177). \r\n\r\nThis may be interesting for video/action recognition, image segmentation and other domains where the batch size is very limited in a single GPU.", "@ppwwyyxx hi, yuxin, is this the way to go for distributed batchnorm ?\r\n\r\nhttps://github.com/tensorflow/models/blob/9b57f41ce21cd7264c52140c9ab31cdfc5169fcd/research/inception/inception/inception_distributed_train.py#L200-L205", "@MrWanter The code you linked to has nothing to do with batchnorm.", "For batch norm with multi-gpu statistics, the link given by @holyseven looks like a right implementation. Tensorpack also has such feature that works with its multigpu trainers.\r\nFor distributed batch norm, tensorpack has an implementation based on its HorovodTrainer but it would depend on https://github.com/uber/horovod/pull/331 ", "@holyseven's implementation seems split batch and construct each layer on each gpu one by one, but in distributed training with multiple workers would that be hard to integrate into existing functions like `tf.train.replica_device_setter`, also split whole batch across workers with this implementation seems infeasible?", "> do you know the purpose of variables_to_average=variables_to_average in the tf.train.SyncReplicasOptimizer? \r\n\r\nIt averages the trainable parameters and the moving averages among workers. It does not perform cross-gpu or cross-machine batch norm.\r\n\r\n> is it possible to modify for distributed batchnorm?\r\n\r\nIt's very far from that.\r\n\r\n> can you refer to some examples for the distributed batchnorm with Horovod\r\n\r\nWith a working horovod training code, adding an option `sync_statistics='horovod'` to `BatchNorm` is all you need to do. But for now its performance has a lot of room for improvement (https://github.com/uber/horovod/issues/318#issuecomment-401216615).", "Thanks for the response, how about using your implementation of with `tf.contrib.nccl`? As In the thread, you mention your CGBN based on tf.contrib.nccl is `1380im/s`, and without CGBN, it is `1556im/s`, so the overhead is small. \r\nSo you mean the room for improvement is the remaining around `170im/s`?", "I meant there might be room for horovod, not much for nccl.", "I see, have you tried using nccl for synchronous distributed batchnorm, the communication would be heavier since batch statistics need to aggregate per layer over workers through internet connection", "nccl does not support it.", "seems nccl2 support inter-node all_reduce operation", "seems there is no way to use it from tensorflow", "What is the difference between @holyseven's implementation and the inception example?", "Here is a custom Keras layer which implements train-phase cross-replica batch normalization under a MirroredStrategy. If anyone finds this useful or wants to submit a PR, I could use some help implementing the prediction phase (i.e. moving mean/variance). \r\n```python\r\nfrom __future__ import absolute_import\r\nfrom __future__ import print_function\r\nfrom __future__ import division\r\n\r\nfrom tensorflow.python.keras.engine.base_layer import InputSpec, Layer\r\nimport tensorflow as tf\r\n\r\nclass SyncBatchNorm(Layer):\r\n  \"\"\"Cross-replica batch normalization layer\"\"\"\r\n  def __init__(\r\n      self,\r\n      center=True,\r\n      scale=False,\r\n      trainable=True,\r\n      name=None,\r\n      **kwargs\r\n    ):\r\n    super(SyncBatchNorm, self).__init__(\r\n      name=name, trainable=trainable, **kwargs)\r\n    self.axis = -1\r\n    self.center = center\r\n    self.scale = scale\r\n    self.supports_masking = True\r\n    self.epsilon = 1e-3\r\n\r\n  def build(self, input_shape):\r\n    dim = input_shape[self.axis]\r\n    if dim is None:\r\n      raise ValueError(\r\n        'Axis ' + str(self.axis) + ' of '\r\n        'input tensor should have a defined dimension '\r\n        'but the layer received an input with shape ' +\r\n        str(input_shape) + '.'\r\n      )\r\n    self.input_spec = InputSpec(\r\n      ndim=len(input_shape),\r\n      axes={self.axis: dim}\r\n    )\r\n    shape = (dim,)\r\n    if self.scale:\r\n      self.gamma = self.add_weight(\r\n        shape=shape,\r\n        name='gamma',\r\n        initializer='ones',\r\n      )\r\n    else:\r\n      self.gamma = None\r\n    if self.center:\r\n      self.beta = self.add_weight(\r\n        shape=shape,\r\n        name='beta',\r\n        initializer='zeros',\r\n      )\r\n    else:\r\n      self.beta = None\r\n    self.built = True\r\n\r\n  def call(self, x, training=None):\r\n    ctx = tf.distribute.get_replica_context()\r\n    n = ctx.num_replicas_in_sync\r\n    mean, mean_sq = ctx.all_reduce(\r\n      tf.distribute.ReduceOp.SUM,\r\n      [tf.reduce_mean(x, axis=0) / n,\r\n       tf.reduce_mean(x**2, axis=0) / n]\r\n    )\r\n    variance = mean_sq - mean ** 2\r\n    return tf.nn.batch_normalization(\r\n      x,\r\n      mean,\r\n      variance,\r\n      self.beta,\r\n      self.gamma,\r\n      self.epsilon)\r\n\r\n  def compute_output_shape(self, input_shape):\r\n    return input_shape\r\n\r\n  def get_config(self):\r\n    return {\r\n      'axis': self.axis,\r\n      'epsilon': self.epsilon,\r\n      'center': self.center,\r\n      'scale': self.scale,\r\n    }\r\n``` ", "> Hello, I am training the BatchNorm layer in multiple GPUs using `tf.contrib.layers.batch_norm` function. In the training phase, we have to collect moving_mean and moving_variance using the function\r\n> \r\n> ```\r\n> update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS) \r\n> ```\r\n> \r\n> However, I found that utilization of the function has some ways\r\n> \r\n> 1.**Inside a loop function** [cifar10_main](https://github.com/tensorflow/models/blob/master/tutorials/image/cifar10_estimator/cifar10_main.py#L121)\r\n> \r\n> ```\r\n> with tf.device('/cpu:0'):\r\n>   update_ops=[]\r\n>   with tf.variable_scope(tf.get_variable_scope()):\r\n>      for i in range(self.conf.num_gpus):\r\n>         with tf.device('/gpu:%d' % i):\r\n> \t   with tf.name_scope('device_%d' % i):\r\n> \t      update_ops.extend(tf.get_collection(tf.GraphKeys.UPDATE_OPS))\r\n>   variable_averages = tf.train.ExponentialMovingAverage(self.conf.MOVING_AVERAGE_DECAY, global_step)\r\n>   variables_averages_op = variable_averages.apply(tf.trainable_variables())\r\n>   with tf.control_dependencies(update_ops):\r\n>      self.train_op = tf.group(train_op_conv,variables_averages_op)\r\n> ```\r\n> \r\n> 2.**Outside a loop function** [cifar10_multi_gpu](https://github.com/tensorflow/models/blob/master/tutorials/image/cifar10/cifar10_multi_gpu_train.py)\r\n> \r\n> ```\r\n> with tf.device('/cpu:0'):\r\n>   with tf.variable_scope(tf.get_variable_scope()):\r\n>      for i in range(self.conf.num_gpus):\r\n>         with tf.device('/gpu:%d' % i):\r\n> \t   with tf.name_scope('device_%d' % i):\r\n> \t      #Igore the line update_ops\r\n>   variable_averages = tf.train.ExponentialMovingAverage(self.conf.MOVING_AVERAGE_DECAY, global_step)\r\n>   variables_averages_op = variable_averages.apply(tf.trainable_variables())\r\n>   update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)  \r\n>   with tf.control_dependencies(update_ops):\r\n>      self.train_op = tf.group(train_op_conv,variables_averages_op)\r\n> ```\r\n> \r\n> 3.**Both inside and outside a loop function** [inception v3](https://github.com/tensorflow/models/blob/master/research/inception/inception/inception_train.py), [cifar10](https://github.com/tensorflow/models/blob/dd9a81c03bf924db8d461a3e696ba1bd4bb193fc/tutorials/image/cifar10_estimator/cifar10_main.py)\r\n> \r\n> ```\r\n> with tf.device('/cpu:0'):\r\n>   with tf.variable_scope(tf.get_variable_scope()):\r\n>      for i in range(self.conf.num_gpus):\r\n>         with tf.device('/gpu:%d' % i):\r\n> \t   with tf.name_scope('device_%d' % i):\r\n> \t      update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS) \r\n>   variable_averages = tf.train.ExponentialMovingAverage(self.conf.MOVING_AVERAGE_DECAY, global_step)\r\n>   variables_averages_op = variable_averages.apply(tf.trainable_variables())            \r\n>   batchnorm_updates_op = tf.group(*update_ops)\r\n>   self.train_op = tf.group(train_op_conv, train_op_fc,variables_averages_op,batchnorm_updates_op)\r\n> ```\r\n> \r\n> What is the right way? In my opinion, it may be the third way\r\n\r\nhave you got the right way? thanks", "I never used tensorflow again because it is hard to research. I killed it without finding the answer. I guess to move to pytorch", "Does run under horovod average batch norm statistics across gpus?", "> Does run under horovod average batch norm statistics across gpus?\r\n\r\nThe answer is no AFAIK, at least for Horovod 0.19.0.\r\n\r\nFYI, TF just added Sync BN: adf769043f0c48a44c05c5a24aac14f0b4951896"]}, {"number": 7438, "title": "During makefile CI build, adjust ownership of the files docker writes\u2026", "body": "\u2026 to host filesystem.", "comments": ["Jenkins, test this please.", "@tensorflow-jenkins test this please\r\n\r\n(one more try)", "Ubuntu repos not found?\r\nI do not know what is going on with the makefile failure.", "So what should we do?", "I am hoping this is a transient issue with ubuntu servers. I will try to debug locally to see if there is something I am doing that is causing this problem.", "@tensorflow-jenkins test this please", "Ill close this until I figure out what the problem with ubuntu repositories are."]}, {"number": 7437, "title": "Fixed off-by-one error in L115-116 in wordvec_basic.py", "body": "In the original tensorflow word2vec tutorial, words in the end of a batch will be skipped.\r\nCheck [issue 6860](https://github.com/tensorflow/tensorflow/issues/6860) for details.\r\n\r\nFixes #6860 ", "comments": ["Can one of the admins verify this patch?", "No tests, so skipping tests to save our CI."]}, {"number": 7436, "title": "Update release note.", "body": "", "comments": []}, {"number": 7435, "title": "Update version string for 1.0.0.", "body": "", "comments": []}, {"number": 7434, "title": "InvalidArgumentError Invalid JPEG data, size 4096 for retain.py(image_retrain), Not JPEG file 0x00 0x05", "body": "Problem: when i run the retrain script with my sub_folder(my photos) shown in the Image retrain tutorial,\r\nhttps://www.tensorflow.org/how_tos/image_retraining/\r\n It gives that error, InvalidArgumentError Invalid JPEG data. I took a look at this thread https://github.com/tensorflow/tensorflow/issues/4009\r\n\r\nAnd changed the tf.image.decode_jpeg to tf.image.decode_image, but no luck(i also made sure all the photos are jpeg). I am wondering the retrain script for the tutorial is there a Max-size set for the images? Because i couldnt find if there is a max-size, or if its still some problem with format of the photos i put in. \r\n\r\nI have ran the flower_photos example with no problem, running on Ubuntu 16.04, CUDA 8.0. \r\n\r\n\r\nEdit: I am using the flower_photos dataset from the tensorflow website, i used a USB stick to transfer the file to the window machine running virtual box Ubuntu 16.04, i deleted 4 sub_folders(only training daisy and dandelion), then the bottleneck process went through about 912 photos and suddenly a daisy photo had the same Invalid JPEG error. I am wondering if its because of the photos transfered through a USB from a Mac to Window then onto a virtual box causes JPEG to corrupt? ", "comments": ["I have managed to locate the root of my problem, the transfer of JPEGS dataset via USB will corrupt the file, so that when you decode it, the decoder will think its not JPEG calling a Invalid JPEG 0x00 0x05. ", "I had a similar error even though my images appear to be valid JPEG images. Like the previous error my Tensorflow error was:\r\nInvalidArgumentError (see above for traceback): Invalid JPEG data, size 4096\r\n         [[Node: DecodeJpeg = DecodeJpeg[acceptable_fraction=1, channels=3, dct_method=\"\", fancy_upscaling=true, ratio=1, try_recover_truncated=false, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_DecodeJpeg/contents_0)]]\r\nI checked the JPEG files with \r\nfile *.jpg\r\nThey are all: JPEG image data, JFIF standard 1.01\r\nWith vi -b 01-007.jpg   The files start: \r\n<ff><d8><ff><e0>^@^PJFIF^@^A^A^A^A,\r\nWhich seems to match \"Valid JFIF files begin with FF D8 FF E0 ?? ?? 'J' 'F' 'I' 'F' 00.\" from Wikipedia: http://fileformats.archiveteam.org/wiki/JFIF \r\nAll the images decode without error using a Tensorflow call\r\nwith tf.Graph().as_default():\r\n        image_contents = tf.read_file(filePath)\r\n        image = tf.image.decode_jpeg(image_contents, channels=channels)\r\n        init_op = tf.tables_initializer()\r\n        with tf.Session() as sess:\r\n            sess.run(init_op)\r\n            decoded = sess.run(image)\r\nSo I don't know what causing the error.\r\n", "Does the problem have been solved?", "@clarklight ,  I meet a silimar question with you when i train models on google TensorFlow Object Detection API, May i ask if the question has been solved? what's the problem and how to solved? thank you!", "Hi,not sure if this manage to response back to the thread. That problem\noccurs when the Jpeg starting pixel breaks.....like the starting bits is\nmissing. That occurs for me when I transferred images from a system to\nanother via USB. You have to check if the base64 is still 100% intact, the\nimage will view ok, but you will see the base64 is different. If the image\nis correct then it will train correctly.\n\nOn 23 Feb 2018 20:16, \"clovking\" <notifications@github.com> wrote:\n\n> @clarklight <https://github.com/clarklight> , I meet a silimar question\n> with you when i train models on google TensorFlow Object Detection API, May\n> i ask if the question has been solved? what's the problem and how to\n> solved? thank you!\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/7434#issuecomment-367993507>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AI3mgCFNfgVN0Sh545XIyY8uOW1Hjt0gks5tXqwogaJpZM4L-E1a>\n> .\n>\n", "For me anyway the jpeg looked like it was correct, the format looked\ncorrect. I checked everything,I even open it to view the image, everything\nlooked right, but for some reason for me when the images is moved from a\nfolder to another some transfer method causes jpeg to loss some bits from\nit's base64 string.......no idea why. When I compared the Actual base64\nthen I saw the string was slightly different.......then I tried a different\ntransfer method, when the base64 string is 100% the same.....then it\nworked. No idea why, I think the Tensorflow has to mount the image into the\nimage parser in C++ then read it, so basically the system couldn't mount\nthe image to parse and gave that error, if you guys base64 is correct or\nfile format is correct, maybe take a look at the log to see if the image is\neven getting read correctly.\n\nOn 23 Feb 2018 20:16, \"clovking\" <notifications@github.com> wrote:\n\n> @clarklight <https://github.com/clarklight> , I meet a silimar question\n> with you when i train models on google TensorFlow Object Detection API, May\n> i ask if the question has been solved? what's the problem and how to\n> solved? thank you!\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/7434#issuecomment-367993507>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AI3mgCFNfgVN0Sh545XIyY8uOW1Hjt0gks5tXqwogaJpZM4L-E1a>\n> .\n>\n", "Thank you for your patient and detailed explanation. I will try it as you say. Thank you!!!\n\n\n\n\n\n\n\nAt 2018-02-23 19:30:01, \"clarklight\" <notifications@github.com> wrote:\nFor me anyway the jpeg looked like it was correct, the format looked\ncorrect. I checked everything,I even open it to view the image, everything\nlooked right, but for some reason for me when the images is moved from a\nfolder to another some transfer method causes jpeg to loss some bits from\nit's base64 string.......no idea why. When I compared the Actual base64\nthen I saw the string was slightly different.......then I tried a different\ntransfer method, when the base64 string is 100% the same.....then it\nworked. No idea why, I think the Tensorflow has to mount the image into the\nimage parser in C++ then read it, so basically the system couldn't mount\nthe image to parse and gave that error, if you guys base64 is correct or\nfile format is correct, maybe take a look at the log to see if the image is\neven getting read correctly.\n\nOn 23 Feb 2018 20:16, \"clovking\" <notifications@github.com> wrote:\n\n> @clarklight <https://github.com/clarklight> , I meet a silimar question\n> with you when i train models on google TensorFlow Object Detection API, May\n> i ask if the question has been solved? what's the problem and how to\n> solved? thank you!\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/7434#issuecomment-367993507>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AI3mgCFNfgVN0Sh545XIyY8uOW1Hjt0gks5tXqwogaJpZM4L-E1a>\n> .\n>\n\n\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub, or mute the thread.", "Something funny happened, I used to run my Tensorflow on Linux and Unix\nsystem. Today was my first time to install and run on a window\ndevice.....and I ran into a problem with retraining a model as well. But\nit's slightly different. It kept complaining about flower_photos not found.\nAs if the directory isn't there.....but I made sure it is........not sure\nwhat's the problem still.....\n\nOn 23 Feb 2018 20:27, \"clark ho\" <clarkswork@gmail.com> wrote:\n\n> For me anyway the jpeg looked like it was correct, the format looked\n> correct. I checked everything,I even open it to view the image, everything\n> looked right, but for some reason for me when the images is moved from a\n> folder to another some transfer method causes jpeg to loss some bits from\n> it's base64 string.......no idea why. When I compared the Actual base64\n> then I saw the string was slightly different.......then I tried a different\n> transfer method, when the base64 string is 100% the same.....then it\n> worked. No idea why, I think the Tensorflow has to mount the image into the\n> image parser in C++ then read it, so basically the system couldn't mount\n> the image to parse and gave that error, if you guys base64 is correct or\n> file format is correct, maybe take a look at the log to see if the image is\n> even getting read correctly.\n>\n> On 23 Feb 2018 20:16, \"clovking\" <notifications@github.com> wrote:\n>\n>> @clarklight <https://github.com/clarklight> , I meet a silimar question\n>> with you when i train models on google TensorFlow Object Detection API, May\n>> i ask if the question has been solved? what's the problem and how to\n>> solved? thank you!\n>>\n>> \u2014\n>> You are receiving this because you were mentioned.\n>> Reply to this email directly, view it on GitHub\n>> <https://github.com/tensorflow/tensorflow/issues/7434#issuecomment-367993507>,\n>> or mute the thread\n>> <https://github.com/notifications/unsubscribe-auth/AI3mgCFNfgVN0Sh545XIyY8uOW1Hjt0gks5tXqwogaJpZM4L-E1a>\n>> .\n>>\n>\n", "It , I run google object detection API, shows the error log such as : \n\nInput file read error\nINFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, Invalid JPEG data or crop window, data size 166476\n[[Node: case/If_0/decode_image/cond_jpeg/DecodeJpeg = DecodeJpeg[acceptable_fraction=1, channels=3, dct_method=\"\", fancy_upscaling=true, ratio=1, try_recover_truncated=false, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](case/If_0/ decode_image/cond_jpeg/cond_png/DecodePng/Switch:1, ^case/Assert/AssertGuard/Merge, ^case/If_0/decode_image/cond_jpeg/Assert/ Assert)]]. \n\nIt is found that a few pictures are invalid format when I use tf.image.decode_jpeg() function to detect and the same error upon is found. Just discard this invalid pictures. The function will consume a lot of time.\nOf course, maybe the question , you and me, is not the same question, just give the method which is valid for me.\nThank you for your reply.\n\n\u53d1\u9001\u81ea Windows 10 \u7248\u90ae\u4ef6\u5e94\u7528\n\n\u53d1\u4ef6\u4eba: clarklight\n\u53d1\u9001\u65f6\u95f4: 2018\u5e743\u670814\u65e5 2:05\n\u6536\u4ef6\u4eba: tensorflow/tensorflow\n\u6284\u9001: clovking; Comment\n\u4e3b\u9898: Re: [tensorflow/tensorflow] InvalidArgumentError Invalid JPEG data,size 4096 for retain.py(image_retrain), Not JPEG file 0x00 0x05 (#7434)\n\nSomething funny happened, I used to run my Tensorflow on Linux and Unix\nsystem. Today was my first time to install and run on a window\ndevice.....and I ran into a problem with retraining a model as well. But\nit's slightly different. It kept complaining about flower_photos not found.\nAs if the directory isn't there.....but I made sure it is........not sure\nwhat's the problem still.....\n\nOn 23 Feb 2018 20:27, \"clark ho\" <clarkswork@gmail.com> wrote:\n\n> For me anyway the jpeg looked like it was correct, the format looked\n> correct. I checked everything,I even open it to view the image, everything\n> looked right, but for some reason for me when the images is moved from a\n> folder to another some transfer method causes jpeg to loss some bits from\n> it's base64 string.......no idea why. When I compared the Actual base64\n> then I saw the string was slightly different.......then I tried a different\n> transfer method, when the base64 string is 100% the same.....then it\n> worked. No idea why, I think the Tensorflow has to mount the image into the\n> image parser in C++ then read it, so basically the system couldn't mount\n> the image to parse and gave that error, if you guys base64 is correct or\n> file format is correct, maybe take a look at the log to see if the image is\n> even getting read correctly.\n>\n> On 23 Feb 2018 20:16, \"clovking\" <notifications@github.com> wrote:\n>\n>> @clarklight <https://github.com/clarklight> , I meet a silimar question\n>> with you when i train models on google TensorFlow Object Detection API, May\n>> i ask if the question has been solved? what's the problem and how to\n>> solved? thank you!\n>>\n>> \u2014\n>> You are receiving this because you were mentioned.\n>> Reply to this email directly, view it on GitHub\n>> <https://github.com/tensorflow/tensorflow/issues/7434#issuecomment-367993507>,\n>> or mute the thread\n>> <https://github.com/notifications/unsubscribe-auth/AI3mgCFNfgVN0Sh545XIyY8uOW1Hjt0gks5tXqwogaJpZM4L-E1a>\n>> .\n>>\n>\n\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub, or mute the thread.\n\n", "I faced similar problem. there is a problem in some of your training data. you can use code below to check which jpeg image is corrupted and delete it.\r\n\r\n```\r\nfrom struct import unpack\r\nimport os\r\n\r\n\r\nmarker_mapping = {\r\n    0xffd8: \"Start of Image\",\r\n    0xffe0: \"Application Default Header\",\r\n    0xffdb: \"Quantization Table\",\r\n    0xffc0: \"Start of Frame\",\r\n    0xffc4: \"Define Huffman Table\",\r\n    0xffda: \"Start of Scan\",\r\n    0xffd9: \"End of Image\"\r\n}\r\n\r\n\r\nclass JPEG:\r\n    def __init__(self, image_file):\r\n        with open(image_file, 'rb') as f:\r\n            self.img_data = f.read()\r\n    \r\n    def decode(self):\r\n        data = self.img_data\r\n        while(True):\r\n            marker, = unpack(\">H\", data[0:2])\r\n            # print(marker_mapping.get(marker))\r\n            if marker == 0xffd8:\r\n                data = data[2:]\r\n            elif marker == 0xffd9:\r\n                return\r\n            elif marker == 0xffda:\r\n                data = data[-2:]\r\n            else:\r\n                lenchunk, = unpack(\">H\", data[2:4])\r\n                data = data[2+lenchunk:]            \r\n            if len(data)==0:\r\n                break        \r\n\r\n\r\nbads = []\r\n\r\nfor img in tqdm(images):\r\n  image = osp.join(root_img,img)\r\n  image = JPEG(image) \r\n  try:\r\n    image.decode()   \r\n  except:\r\n    bads.append(img)\r\n\r\n\r\nfor name in bads:\r\n  os.remove(osp.join(root_img,name))\r\n```\r\nI used [yasoob](https://yasoob.me/posts/understanding-and-writing-jpeg-decoder-in-python/) script to decode jpeg image."]}, {"number": 7433, "title": "Failed to build from source for r0.12 about :_rules_closure: no such attribute 'urls\"", "body": "Hi, I'm trying to install tensorflow r0.12 on a cluster with CentOS. i came across with following errors:\r\n```\r\nERROR: /data0/title/tensorflow/WORKSPACE:3:1: //external:io_bazel_rules_closure: no such attribute 'urls' in 'http_archive' rule.\r\nERROR: /data0/title/tensorflow/WORKSPACE:3:1: //external:io_bazel_rules_closure: missing value for mandatory attribute 'url' in 'http_archive' rule.\r\nERROR: com.google.devtools.build.lib.packages.BuildFileContainsErrorsException: error loading package '': Encountered error while reading extension file 'closure/defs.bzl': no such package '@io_bazel_rules_closure//closure': error loading package 'external': Could not load //external package.\r\n\r\n```\r\n\r\nbazel 0.4.0\r\ncuda 7.5\r\ncudnn 5.1\r\nsmall help will welcome, tks.", "comments": ["Please upgrade to bazel version 0.4.1 or higher.\r\nWe had to make backwards incompatible changes to our build files, so any bazel version before 0.4.1 will not work.", "another question: i upgrade bazel to 0.4.2, and then recompile, i came across with another following error:\r\n```\r\njava.lang.RuntimeException: Unrecoverable error while evaluating node 'REPOSITORY_DIRECTORY:@org_polymer_webcomponentsjs' (requested by nodes 'REPOSITORY:@org_polymer_webcomponentsjs')\r\n\tat com.google.devtools.build.skyframe.ParallelEvaluator$Evaluate.run(ParallelEvaluator.java:429)\r\n\tat com.google.devtools.build.lib.concurrent.AbstractQueueVisitor$WrappedRunnable.run(AbstractQueueVisitor.java:501)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\nCaused by: java.lang.IllegalArgumentException: Invalid EvalException:\r\njava.lang.InterruptedException\r\n\tat java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:998)\r\n\tat java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304)\r\n\tat java.util.concurrent.Semaphore.acquire(Semaphore.java:312)\r\n\tat com.google.devtools.build.lib.bazel.repository.downloader.HttpDownloader.download(HttpDownloader.java:196)\r\n\tat com.google.devtools.build.lib.bazel.repository.skylark.SkylarkRepositoryContext.downloadAndExtract(SkylarkRepositoryContext.java:594)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:483)\r\n\tat com.google.devtools.build.lib.syntax.FuncallExpression.callMethod(FuncallExpression.java:316)\r\n\tat com.google.devtools.build.lib.syntax.FuncallExpression.invokeObjectMethod(FuncallExpression.java:732)\r\n\tat com.google.devtools.build.lib.syntax.FuncallExpression.invokeObjectMethod(FuncallExpression.java:784)\r\n\tat com.google.devtools.build.lib.syntax.FuncallExpression.doEval(FuncallExpression.java:770)\r\n\tat com.google.devtools.build.lib.syntax.Expression.eval(Expression.java:48)\r\n\tat com.google.devtools.build.lib.syntax.ExpressionStatement.doExec(ExpressionStatement.java:46)\r\n\tat com.google.devtools.build.lib.syntax.Statement.exec(Statement.java:37)\r\n\tat com.google.devtools.build.lib.syntax.UserDefinedFunction.call(UserDefinedFunction.java:136)\r\n\tat com.google.devtools.build.lib.syntax.BaseFunction.call(BaseFunction.java:439)\r\n\tat com.google.devtools.build.lib.bazel.repository.skylark.SkylarkRepositoryFunction.fetch(SkylarkRepositoryFunction.java:106)\r\n\tat com.google.devtools.build.lib.rules.repository.RepositoryDelegatorFunction.compute(RepositoryDelegatorFunction.java:155)\r\n\tat com.google.devtools.build.skyframe.ParallelEvaluator$Evaluate.run(ParallelEvaluator.java:370)\r\n\tat com.google.devtools.build.lib.concurrent.AbstractQueueVisitor$WrappedRunnable.run(AbstractQueueVisitor.java:501)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\n\r\n\tat com.google.devtools.build.lib.syntax.EvalException.<init>(EvalException.java:112)\r\n\tat com.google.devtools.build.lib.syntax.EvalException$EvalExceptionWithJavaCause.<init>(EvalException.java:209)\r\n\tat com.google.devtools.build.lib.syntax.EvalException$EvalExceptionWithJavaCause.<init>(EvalException.java:217)\r\n\tat com.google.devtools.build.lib.syntax.FuncallExpression.callMethod(FuncallExpression.java:344)\r\n\tat com.google.devtools.build.lib.syntax.FuncallExpression.invokeObjectMethod(FuncallExpression.java:732)\r\n\tat com.google.devtools.build.lib.syntax.FuncallExpression.invokeObjectMethod(FuncallExpression.java:784)\r\n\tat com.google.devtools.build.lib.syntax.FuncallExpression.doEval(FuncallExpression.java:770)\r\n\tat com.google.devtools.build.lib.syntax.Expression.eval(Expression.java:48)\r\n\tat com.google.devtools.build.lib.syntax.ExpressionStatement.doExec(ExpressionStatement.java:46)\r\n\tat com.google.devtools.build.lib.syntax.Statement.exec(Statement.java:37)\r\n\tat com.google.devtools.build.lib.syntax.UserDefinedFunction.call(UserDefinedFunction.java:136)\r\n\tat com.google.devtools.build.lib.syntax.BaseFunction.call(BaseFunction.java:439)\r\n\tat com.google.devtools.build.lib.bazel.repository.skylark.SkylarkRepositoryFunction.fetch(SkylarkRepositoryFunction.java:106)\r\n\tat com.google.devtools.build.lib.rules.repository.RepositoryDelegatorFunction.compute(RepositoryDelegatorFunction.java:155)\r\n\tat com.google.devtools.build.skyframe.ParallelEvaluator$Evaluate.run(ParallelEvaluator.java:370)\r\n\t... 4 more\r\njava.lang.RuntimeException: Unrecoverable error while evaluating node 'REPOSITORY_DIRECTORY:@org_polymer_webcomponentsjs' (requested by nodes 'REPOSITORY:@org_polymer_webcomponentsjs')\r\n\tat com.google.devtools.build.skyframe.ParallelEvaluator$Evaluate.run(ParallelEvaluator.java:429)\r\n\tat com.google.devtools.build.lib.concurrent.AbstractQueueVisitor$WrappedRunnable.run(AbstractQueueVisitor.java:501)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\nCaused by: java.lang.IllegalArgumentException: Invalid EvalException:\r\njava.lang.InterruptedException\r\n\tat java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:998)\r\n\tat java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304)\r\n\tat java.util.concurrent.Semaphore.acquire(Semaphore.java:312)\r\n\tat com.google.devtools.build.lib.bazel.repository.downloader.HttpDownloader.download(HttpDownloader.java:196)\r\n\tat com.google.devtools.build.lib.bazel.repository.skylark.SkylarkRepositoryContext.downloadAndExtract(SkylarkRepositoryContext.java:594)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:483)\r\n\tat com.google.devtools.build.lib.syntax.FuncallExpression.callMethod(FuncallExpression.java:316)\r\n\tat com.google.devtools.build.lib.syntax.FuncallExpression.invokeObjectMethod(FuncallExpression.java:732)\r\n\tat com.google.devtools.build.lib.syntax.FuncallExpression.invokeObjectMethod(FuncallExpression.java:784)\r\n\tat com.google.devtools.build.lib.syntax.FuncallExpression.doEval(FuncallExpression.java:770)\r\n\tat com.google.devtools.build.lib.syntax.Expression.eval(Expression.java:48)\r\n\tat com.google.devtools.build.lib.syntax.ExpressionStatement.doExec(ExpressionStatement.java:46)\r\n\tat com.google.devtools.build.lib.syntax.Statement.exec(Statement.java:37)\r\n\tat com.google.devtools.build.lib.syntax.UserDefinedFunction.call(UserDefinedFunction.java:136)\r\n\tat com.google.devtools.build.lib.syntax.BaseFunction.call(BaseFunction.java:439)\r\n\tat com.google.devtools.build.lib.bazel.repository.skylark.SkylarkRepositoryFunction.fetch(SkylarkRepositoryFunction.java:106)\r\n\tat com.google.devtools.build.lib.rules.repository.RepositoryDelegatorFunction.compute(RepositoryDelegatorFunction.java:155)\r\n\tat com.google.devtools.build.skyframe.ParallelEvaluator$Evaluate.run(ParallelEvaluator.java:370)\r\n\tat com.google.devtools.build.lib.concurrent.AbstractQueueVisitor$WrappedRunnable.run(AbstractQueueVisitor.java:501)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\n\r\n\tat com.google.devtools.build.lib.syntax.EvalException.<init>(EvalException.java:112)\r\n\tat com.google.devtools.build.lib.syntax.EvalException$EvalExceptionWithJavaCause.<init>(EvalException.java:209)\r\n\tat com.google.devtools.build.lib.syntax.EvalException$EvalExceptionWithJavaCause.<init>(EvalException.java:217)\r\n\tat com.google.devtools.build.lib.syntax.FuncallExpression.callMethod(FuncallExpression.java:344)\r\n\tat com.google.devtools.build.lib.syntax.FuncallExpression.invokeObjectMethod(FuncallExpression.java:732)\r\n\tat com.google.devtools.build.lib.syntax.FuncallExpression.invokeObjectMethod(FuncallExpression.java:784)\r\n\tat com.google.devtools.build.lib.syntax.FuncallExpression.doEval(FuncallExpression.java:770)\r\n\tat com.google.devtools.build.lib.syntax.Expression.eval(Expression.java:48)\r\n\tat com.google.devtools.build.lib.syntax.ExpressionStatement.doExec(ExpressionStatement.java:46)\r\n\tat com.google.devtools.build.lib.syntax.Statement.exec(Statement.java:37)\r\n\tat com.google.devtools.build.lib.syntax.UserDefinedFunction.call(UserDefinedFunction.java:136)\r\n\tat com.google.devtools.build.lib.syntax.BaseFunction.call(BaseFunction.java:439)\r\n\tat com.google.devtools.build.lib.bazel.repository.skylark.SkylarkRepositoryFunction.fetch(SkylarkRepositoryFunction.java:106)\r\n\tat com.google.devtools.build.lib.rules.repository.RepositoryDelegatorFunction.compute(RepositoryDelegatorFunction.java:155)\r\n\tat com.google.devtools.build.skyframe.ParallelEvaluator$Evaluate.run(ParallelEvaluator.java:370)\r\n\t... 4 more\r\n```", "i compile again, it appeared a new error:\r\n```\r\nERROR: /data0/title/download/tensorflow/tensorflow/workspace.bzl:423:3: no such package '@junit_jar//jar': Error downloading [https://github.com/junit-team/junit4/releases/download/r4.12/junit-4.12.jar] to /root/.cache/bazel/_bazel_root/d5c4498fef8d232536c486a547731ad0/external/junit_jar/junit-4.12.jar: Tried to reconnect at offset 189,857 but server didn't support it and referenced by '//external:junit'.\r\nERROR: /data0/title/download/tensorflow/tensorflow/workspace.bzl:423:3: no such package '@junit_jar//jar': Error downloading [https://github.com/junit-team/junit4/releases/download/r4.12/junit-4.12.jar] to /root/.cache/bazel/_bazel_root/d5c4498fef8d232536c486a547731ad0/external/junit_jar/junit-4.12.jar: Tried to reconnect at offset 189,857 but server didn't support it and referenced by '//external:junit'.\r\nERROR: Evaluation of query \"deps((((//tensorflow/... - //tensorflow/contrib/nccl/...) - //tensorflow/examples/android/...) union @bazel_tools//tools/jdk:toolchain))\" failed: errors were encountered while computing transitive closure.\r\n```", "This one looks like a transient download error. Please try again.\n\nOn Feb 11, 2017 6:58 AM, \"zheng\" <notifications@github.com> wrote:\n\n> i compile again, it appeared a new error:\n>\n> ERROR: /data0/title/download/tensorflow/tensorflow/workspace.bzl:423:3: no such package '@junit_jar//jar': Error downloading [https://github.com/junit-team/junit4/releases/download/r4.12/junit-4.12.jar] to /root/.cache/bazel/_bazel_root/d5c4498fef8d232536c486a547731ad0/external/junit_jar/junit-4.12.jar: Tried to reconnect at offset 189,857 but server didn't support it and referenced by '//external:junit'.\n> ERROR: /data0/title/download/tensorflow/tensorflow/workspace.bzl:423:3: no such package '@junit_jar//jar': Error downloading [https://github.com/junit-team/junit4/releases/download/r4.12/junit-4.12.jar] to /root/.cache/bazel/_bazel_root/d5c4498fef8d232536c486a547731ad0/external/junit_jar/junit-4.12.jar: Tried to reconnect at offset 189,857 but server didn't support it and referenced by '//external:junit'.\n> ERROR: Evaluation of query \"deps((((//tensorflow/... - //tensorflow/contrib/nccl/...) - //tensorflow/examples/android/...) union @bazel_tools//tools/jdk:toolchain))\" failed: errors were encountered while computing transitive closure.\n>\n> \u2014\n> You are receiving this because you modified the open/close state.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/7433#issuecomment-279149360>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AHlCOVioR5PKen4Sd4q55v70TgGsHHgLks5rbcyZgaJpZM4L-Ezh>\n> .\n>\n", "i have a try. it seems to configure successfully. And then i run `bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package`. it appear error followed:\r\n```\r\nWARNING: Sandboxed execution is not supported on your system and thus hermeticity of actions cannot be guaranteed. See http://bazel.build/docs/bazel-user-manual.html#sandboxing for more information. You can turn off this warning via --ignore_unsupported_sandboxing.\r\nINFO: Found 1 target...\r\nERROR: /root/.cache/bazel/_bazel_root/d5c4498fef8d232536c486a547731ad0/external/pcre/BUILD.bazel:5:1: undeclared inclusion(s) in rule '@pcre//:pcre':\r\nthis rule is missing dependency declarations for the following files included by 'external/pcre/pcre_byte_order.c':\r\n  '/lib/gcc/x86_64-redhat-linux/4.8.3/include/limits.h'\r\n  '/lib/gcc/x86_64-redhat-linux/4.8.3/include/syslimits.h'\r\n  '/lib/gcc/x86_64-redhat-linux/4.8.3/include/stddef.h'\r\n  '/lib/gcc/x86_64-redhat-linux/4.8.3/include/stdarg.h'\r\n  '/lib/gcc/x86_64-redhat-linux/4.8.3/include/stdint.h'.\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 3.348s, Critical Path: 0.60s\r\n```", "We do not have official support for centOS, but here is a user who was able to successfully build TF on RHEL, which is very close:\r\nhttps://github.com/tensorflow/tensorflow/issues/7118\r\n\r\nYour particular problem was seen in that thread and resolved.\r\n\r\nAlso feel free to reach out to stackoverflow for issues on centOS.", "i have this error after running sudo ./configure\r\n ERROR: Evaluation of query \"deps(((//tensorflow/... - //tensorflow/contrib/nccl/...) - //tensorflow/examples/android/...))\" failed: errors were encountered while computing transitive closure.\r\n", "@moveforever The key in your error message is this part:\r\n```\r\n  '/lib/gcc/x86_64-redhat-linux/4.8.3/include/limits.h'\r\n  '/lib/gcc/x86_64-redhat-linux/4.8.3/include/syslimits.h'\r\n  '/lib/gcc/x86_64-redhat-linux/4.8.3/include/stddef.h'\r\n  '/lib/gcc/x86_64-redhat-linux/4.8.3/include/stdarg.h'\r\n  '/lib/gcc/x86_64-redhat-linux/4.8.3/include/stdint.h'.\r\n```\r\nYou may need to reinstall gcc and g++.\r\n\r\n@amel2houwi please file a new issue by filling out the full form. If you are on windows, this is a known issue. If you check out r1.0 branch, you should be able to build fine.", "i just met the same problem, i was stuck when upgrade the bazel 0.4.2, then  the same java error occured\r\nhow did you solve it ,i compile again, but make no use\r\n", "@limingfan Which version of the repo are you trying to build?\r\nI recommend building 1.0, or if you really need an older version 0.12.\r\n\r\nBazel and TF are both very quickly evolving, and both had to have a lot of backwards/forwards incompatible changes. So older versions may be more difficult to build.", "Hi I tried installing SyntaxNet today and I am stuck with the below error: Can somebody please guide me whats wrong here. \r\nERROR: Error downloading [http://bazel-mirror.storage.googleapis.com/repo1.maven.org/maven2/com/google/guava/guava/20.0/guava-20.0.jar, http://repo1.maven.org/maven2/com/google/guava/guava/20.0/guava-20.0.jar, http://maven.ibiblio.org/maven2/com/google/guava/guava/20.0/guava-20.0.jar] to /home/gemini/.cache/bazel/_bazel_gemini/0d0ea192abd8cc4ee452d1e7288e5f03/external/com_google_guava/guava-20.0.jar: All mirrors are down: [Checksum was 4b52abfc70f48238e972dd7e49ef73adf7e36ff34eaaa97c2482a1f8ca8d3123 but wanted 36a666e3b71ae7f0f0dca23654b67e086e6c93d192f60ba5dfd5519db6c288c8, Checksum was f64edf0b2bb22bb37860a54e8d79fdb500ac88bb51c598bf66b953fc8b59997b but wanted 36a666e3b71ae7f0f0dca23654b67e086e6c93d192f60ba5dfd5519db6c288c8, Checksum was feee555b39925f3c22dbe1838cea193aef2bea7c2745066ef8c05be98fc72928 but wanted 36a666e3b71ae7f0f0dca23654b67e086e6c93d192f60ba5dfd5519db6c288c8] and referenced by '@io_bazel_rules_closure//java/io/bazel/rules/closure:ClosureWorker'.\r\n\r\nERROR:  java.io.IOException: Error downloading [http://bazel-mirror.storage.googleapis.com/repo1.maven.org/maven2/com/google/guava/guava/20.0/guava-20.0.jar, http://repo1.maven.org/maven2/com/google/guava/guava/20.0/guava-20.0.jar, http://maven.ibiblio.org/maven2/com/google/guava/guava/20.0/guava-20.0.jar] to /home/gemini/.cache/bazel/_bazel_gemini/0d0ea192abd8cc4ee452d1e7288e5f03/external/com_google_guava/guava-20.0.jar: All mirrors are down: [Checksum was 4b52abfc70f48238e972dd7e49ef73adf7e36ff34eaaa97c2482a1f8ca8d3123 but wanted 36a666e3b71ae7f0f0dca23654b67e086e6c93d192f60ba5dfd5519db6c288c8, Checksum was f64edf0b2bb22bb37860a54e8d79fdb500ac88bb51c598bf66b953fc8b59997b but wanted 36a666e3b71ae7f0f0dca23654b67e086e6c93d192f60ba5dfd5519db6c288c8, Checksum was feee555b39925f3c22dbe1838cea193aef2bea7c2745066ef8c05be98fc72928 but wanted 36a666e3b71ae7f0f0dca23654b67e086e6c93d192f60ba5dfd5519db6c288c8] and referenced by '@com_google_template_soy//:com_google_template_soy'.\r\n\r\nERROR: Evaluation of query \"deps(((//tensorflow/... - //tensorflow/contrib/nccl/...) - //tensorflow/examples/android/...))\" failed: errors were encountered while computing transitive closure.\r\n"]}, {"number": 7432, "title": "Batch normalization for  Bidirectional RNN ?tensorflow support it?", "body": "Batch normalization for  Bidirectional RNN ?tensorflow support it?", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 7431, "title": "Fix regression in TensorBoard", "body": "TensorBoard is currently broken. This fixes it. See #7375.", "comments": ["Approved and merging as users tested this and it is reported to be working.\r\nJust for my curiosity, what was the problem with the old name of the repo? was there a collision in name?", "In a CL I changed the name to that thing when I shouldn't have, because I ended up changing the new webfiles repository to be org_polymer instead of what I was originally going to name it: polymer.", "Thanks for the clarification, and the fix!"]}, {"number": 7430, "title": "Upgrade Dockerized Android builds to use NDK 12b", "body": "Upgrade to Android NDK 12b for nightly builds. This will fix an issue with the arm64 native libraries on Android where the Inception classifier returns incorrect results.", "comments": ["@tensorflow-jenkins Test this, please.", "@tensorflow-jenkins Test this, please.", "Jenkins, test this please."]}, {"number": 7429, "title": "Fix: make sure to join all threads to avoid flakes in sync_replicas_optimizer_test.", "body": "", "comments": []}, {"number": 7428, "title": "Add plugins/debugger to tf_python.cmake", "body": "This fixes issue #7352 by making the debugger Tensorboard plugin available to cmake builds. ", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please.", "Feel free to merge once the tests pass.", "Thanks for the quick fix, @chihuahua "]}, {"number": 7427, "title": "Seal contrib", "body": "", "comments": ["Jenkins, test this please\r\n", "Looks like a missing reroute_a2b_ts ->reroute_ts in transform.py?  Not sure about the gen_doc failure.", "Jenkins, test this please\r\n"]}, {"number": 7426, "title": "CP 1.0", "body": "Fix double evaluation of macro argument that was causing duplicate CUDA batched GEMM calls.\r\n\r\nChange: 147025110\r\n\r\n(cherry picked from commit f439016532a8b310bb4cc984eed1c331b4d3be8a)", "comments": ["In particular, it's dangerous for future usage but (probably) isn't causing any bugs right now."]}, {"number": 7425, "title": "Bump protobuf version to fix the mac GPU build", "body": "", "comments": []}, {"number": 7424, "title": "Fix typo CUDNN_RETURN_IF_FAIL.", "body": "", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please."]}, {"number": 7423, "title": "tfdbg doc: move PNG image files to g3doc/images", "body": "Change: 146289701", "comments": ["test failure is unrelated. should be okay to merge."]}, {"number": 7422, "title": "Feature: Add reduce_average (weighted reduce_mean)", "body": "[Numpy has a function `average`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.average.html) which peforms a weighted mean. I suggest adding this function to tensorflow or adding an optional `weights` argument to `reduce_mean`.", "comments": ["Could you just use broadcasting and call `reduce_mean`?\r\n\r\n```\r\ntf.reduce_mean(weights * x)\r\n```\r\n\r\nEDIT: corrected typo", "Yes though also want to divide through by sum of weights since it may not sum to 1", "@aselle Thoughts?  It seems pretty trivial to implement (`tf.reduce_sum(weights * x) / tf.reduce_sum(weights)`) so I'm not sure we need it, but it does exist in numpy.", "As we've gotten to 1.0, there is now more careful review of API additions. I'm also working on finishing up a proposal on sub-modules and aliases. My feeling is that we should probably minimize what we add to the root tf namespace (even NumPy compatible aliases/macro functionality) and defer those to the planned numpy submodule. The idea would be that you get more numpy compatible names in the numpy sub-module. That proposal isn't quite ready yet, but that's where I would imagine average() going. ", "+1\r\n\r\nI hand code a weighted average all the time in my models! I would love a built in function", "+1\r\nI have to explicitly handle this. An optional weight parameter to reduce_mean like in mean_squared_error would be great.", "What would the usecase of this parameter?\n\nOn 20 Nov 2017 5:40 p.m., \"Ashwini Reddy Challa\" <notifications@github.com>\nwrote:\n\n> +1\n> I have to explicitly handle this. An optional weight parameter to\n> reduce_mean like in mean_squared_error would be great.\n>\n> \u2014\n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/7422#issuecomment-345752808>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AFjlg6zFjFbScqBq7lOVQ9GLtsomc_3-ks5s4auOgaJpZM4L9vTT>\n> .\n>\n", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Seems reasonable, but I won't have time to do it now, so marking it contributions welcome.", "This seems to work faster\r\n```\r\ndef reduce_average(x, weight):\r\n\treturn tf.squeeze(tf.matmul(x, weight, transpose_a=True), axis=-1)\r\n```\r\n", "Can this now be closed?\r\nI see docs for\r\nhttps://www.tensorflow.org/api_docs/python/tf/nn/weighted_moments", "Hi @cancan101 ! Does [weighted_moments](https://www.tensorflow.org/api_docs/python/tf/nn/weighted_moments) api address this feature request?", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 7421, "title": "Change mismatched ref input error message", "body": "Closes #202", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins  test this please."]}, {"number": 7420, "title": "TypeError: Input 'y' of 'Mul' Op has type float32 that does not match type int32 of argument 'x'.", "body": "I tried to start these tutorial https://github.com/nlintz/TensorFlow-Tutorials/blob/master/08_word2vec.py and get these error\r\n>D:\\Programms\\Python35>python 08_word2vec.py\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\dso_loader.cc:128] successfully opened CUDA libr\r\nary cublas64_80.dll locally\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\dso_loader.cc:128] successfully opened CUDA libr\r\nary cudnn64_5.dll locally\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\dso_loader.cc:128] successfully opened CUDA libr\r\nary cufft64_80.dll locally\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\dso_loader.cc:128] successfully opened CUDA libr\r\nary nvcuda.dll locally\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\dso_loader.cc:128] successfully opened CUDA libr\r\nary curand64_80.dll locally\r\nWord count [('cats', 10), ('dogs', 6), ('and', 5), ('are', 4), ('love', 3)]\r\nSample data [7, 12, 24, 11, 13, 19, 7, 15, 17, 27] ['the', 'quick', 'brown', 'fox', 'jumped', 'over', 'the', 'lazy', 'dog', 'I']\r\nContext pairs [[[7, 24], 12], [[12, 11], 24], [[24, 13], 11], [[11, 19], 13], [[13, 7], 19], [[19, 15], 7], [[7, 17], 15], [[15, 27], 17], [\r\n[17, 4], 27], [[27, 0], 4]]\r\nskip-gram pairs [[12, 7], [12, 24], [24, 12], [24, 11], [11, 24]]\r\nBatches (x, y) ([17, 20, 0], [[15], [14], [25]])\r\nTraceback (most recent call last):\r\nFile \"D:\\Programms\\Python35\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 490, in apply_op\r\npreferred_dtype=default_dtype)\r\nFile \"D:\\Programms\\Python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 669, in convert_to_tensor\r\nret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\nFile \"D:\\Programms\\Python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 583, in _TensorTensorConversionFunction\r\n% (dtype.name, t.dtype.name, str(t)))\r\nValueError: Tensor conversion requested dtype int32 for Tensor with dtype float32: 'Tensor(\"nce_loss/Reshape_1:0\", shape=(?, 1, ?), dtype=fl\r\noat32)'\r\n\r\n> During handling of the above exception, another exception occurred:\r\n\r\n>Traceback (most recent call last):\r\nFile \"08_word2vec.py\", line 92, in \r\nloss = tf.reduce_mean(tf.nn.nce_loss(nce_weights, nce_biases, train_labels, embed, num_sampled, voc_size))\r\nFile \"D:\\Programms\\Python35\\lib\\site-packages\\tensorflow\\python\\ops\\nn.py\", line 1336, in nce_loss\r\nname=name)\r\nFile \"D:\\Programms\\Python35\\lib\\site-packages\\tensorflow\\python\\ops\\nn.py\", line 1198, in _compute_sampled_logits\r\narray_ops.reshape(true_w, new_true_w_shape))\r\nFile \"D:\\Programms\\Python35\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 1613, in mul\r\nresult = _op_def_lib.apply_op(\"Mul\", x=x, y=y, name=name)\r\nFile \"D:\\Programms\\Python35\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 521, in apply_op\r\ninferred_from[input_arg.type_attr]))\r\nTypeError: Input 'y' of 'Mul' Op has type float32 that does not match type int32 of argument 'x'.", "comments": ["Please file this issue with https://github.com/nlintz/TensorFlow-Tutorials."]}, {"number": 7419, "title": "Build android demo using a custom classifier", "body": "I want build TensorFlow Android Camera Demo using a custom classifier following [this](https://www.oreilly.com/learning/tensorflow-on-android) tutorial.\r\nWhen I build the app using `bazel build //tensorflow/examples/android:tensorflow_demo` I get:\r\n```\r\nCONFLICT: asset:WORKSPACE is provided with ambiguous priority from:\r\n        external/mobile_multibox/WORKSPACE\r\n        external/inception5h/WORKSPACE\r\nCONFLICT: asset:WORKSPACE is provided with ambiguous priority from:\r\n        external/stylize/WORKSPACE\r\n        external/mobile_multibox/WORKSPACE\r\n```\r\nThanks in advance!\r\n", "comments": ["@davideb91 That article is somewhat outdated. The model files are now downloaded automatically by Bazel, which is why you're getting conflicts with the manually downloaded ones. You can either delete the files from assets/, or remove the dependencies on the file archives in the tensorflow/examples/android/BUILD file.", "Thanks @andrewharp , it works now!\r\nHowever when I try to open the app on my android phone it is terminated.\r\n\r\nTo build the app I ran\r\n```\r\n$ bazel-bin/tensorflow/python/tools/optimize_for_inference \\\r\n--input=tf_files/retrained_graph.pb \\\r\n--output=tensorflow/examples/android/assets/retrained_graph.pb\r\n--input_names=Mul \\\r\n--output_names=final_result\r\n```\r\nin order to optimize my graph, and I copied retrained_label.txt in /android/assets/ .\r\nThen I added these line in /tensorflow/tensorflow/examples/android/src/org/tensorflow/demo/TensorFlowImageClassifier.java\r\n```\r\nprivate static final int INPUT_SIZE = 299;\r\nprivate static final int IMAGE_MEAN = 128;\r\nprivate static final float IMAGE_STD = 128;\r\nprivate static final String INPUT_NAME = \"Mul:0\";\r\nprivate static final String OUTPUT_NAME = \"final_result:0\";\r\n\r\nprivate static final String MODEL_FILE = \"file:///android_asset/retrained_graph.pb\";\r\nprivate static final String LABEL_FILE = \"file:///android_asset/retrained_labels.txt\";\r\n```\r\nAnd I removed other dependencies on the file archives in the tensorflow/examples/android/BUILD file:\r\n```\r\n    assets = [\r\n        \"//tensorflow/examples/android/assets:asset_files\",\r\n#        \"@inception5h//:model_files\",\r\n#        \"@mobile_multibox//:model_files\",\r\n#        \"@stylize//:model_files\",\r\n    ]\r\n```\r\n\r\nWhen I build my app with `bazel build //tensorflow/examples/android:tensorflow_demo`, it works correctly, but when I try to open the app on my phone, it gives error and is terminated.\r\n\r\nDo you have any suggestion please?\r\nThank you very much!", "@davideb91 What does adb logcat say?", "@andrewharp This is the output of adb logcat:\r\n```\r\n02-11 15:49:40.331 15832 15832 I TensorFlowImageClassifier: Reading labels from: imagenet_comp_graph_label_strings.txt\r\n02-11 15:49:40.351 15832 15832 E AndroidRuntime: FATAL EXCEPTION: main\r\n02-11 15:49:40.351 15832 15832 E AndroidRuntime: Process: org.tensorflow.demo, PID: 15832\r\n02-11 15:49:40.351 15832 15832 E AndroidRuntime: java.lang.RuntimeException: Error initializing TensorFlow!\r\n02-11 15:49:40.351 15832 15832 E AndroidRuntime: at org.tensorflow.demo.ClassifierActivity.onPreviewSizeChosen(ClassifierActivity.java:135)\r\n02-11 15:49:40.351 15832 15832 E AndroidRuntime: at org.tensorflow.demo.CameraActivity$1.onPreviewSizeChosen(CameraActivity.java:158)\r\n02-11 15:49:40.351 15832 15832 E AndroidRuntime: at org.tensorflow.demo.CameraConnectionFragment.setUpCameraOutputs(CameraConnectionFragment.java:394)\r\n02-11 15:49:40.351 15832 15832 E AndroidRuntime: at org.tensorflow.demo.CameraConnectionFragment.openCamera(CameraConnectionFragment.java:411)\r\n02-11 15:49:40.351 15832 15832 E AndroidRuntime: at org.tensorflow.demo.CameraConnectionFragment.access$000(CameraConnectionFragment.java:63)\r\n02-11 15:49:40.351 15832 15832 E AndroidRuntime: at org.tensorflow.demo.CameraConnectionFragment$1.onSurfaceTextureAvailable(CameraConnectionFragment.java:94)\r\n```\r\n", "Is the label file actually in your assets folder?", "@andrewharp In asset folder (tensorflow/tensorflow/examples/android/asset) there are only label and graph file of my retrained model, and I haven't found any file named imagenet_comp_graph_label_strings.txt in tensorflow/*.\r\nWith a grep command I found the string (\"imagenet_comp_graph_label_strings.txt\") in these files:\r\n\r\ntensorflow/tensorflow/java/src/main/java/org/tensorflow/examples/LabelImage.java\r\ntensorflow/tensorflow/core/kernels/hexagon/hexagon_graph_execution_test.cc\r\ntensorflow/tensorflow/contrib/ios_examples/.gitignore\r\ntensorflow/tensorflow/contrib/ios_examples/benchmark/benchmark.xcodeproj/project.pbxproj\r\ntensorflow/tensorflow/contrib/ios_examples/simple/tf_ios_makefile_example.xcodeproj/project.pbxproj\r\ntensorflow/tensorflow/contrib/ios_examples/camera/camera_example.xcodeproj/project.pbxproj\r\ntensorflow/tensorflow/contrib/pi_examples/label_image/label_image.cc\r\ntensorflow/tensorflow/contrib/pi_examples/.gitignore\r\ntensorflow/tensorflow/contrib/pi_examples/camera/camera.cc\r\ntensorflow/tensorflow/examples/label_image/main.cc\r\ntensorflow/tensorflow/examples/android/src/org/tensorflow/demo/ClassifierActivity.java \r\n\r\nCould one of these files be the problem? ", "Solved!\r\nProblem was in `tensorflow/tensorflow/examples/android/src/org/tensorflow/demo/ClassifierActivity.java`\r\nI had to set dependencies to my model. \r\nThanks Andrew for help", "Great!", "@davideb91 I heave the same problem. Can you please say - which dependencies you set?", "@AnSharipov I set these dependencies in `tensorflow/tensorflow/examples/android/src/org/tensorflow/demo/ClassifierActivity.java` :\r\n```\r\n  private static final int NUM_CLASSES = 1008;\r\n  private static final int INPUT_SIZE = 299;\r\n  private static final int IMAGE_MEAN = 128;\r\n  private static final float IMAGE_STD = 128;\r\n  private static final String INPUT_NAME = \"Mul:0\";\r\n  private static final String OUTPUT_NAME = \"final_result:0\";\r\n  private static final String MODEL_FILE = \"file:///android_asset/retrained_graph.pb\";\r\n  private static final String LABEL_FILE = \"file:///android_asset/retrained_labels.txt\";\r\n```", "@davideb91  can u pls explain what are these parameters and how to set these values , since i have trained the model in darknet and converted using darkflow\r\n  private static final int IMAGE_MEAN = 128;\r\n  private static final float IMAGE_STD = 128;\r\n  private static final String INPUT_NAME = \"Mul:0\";\r\n  private static final String OUTPUT_NAME = \"final_result:0\";", "Hi @davideb91 and @andrewharp \r\n\r\n I'm working in a street object clasification project. I would like to know if the performance is better if I'll train only a few categories (cars, trucks, bus, pedestrian...) than use a COCO .pb database. Do you test it ? Best regards.\r\nMartin", "Gyz I also working on the same project with same model but my own dataset. But facing same error.My app is running but not giving labeling for the images.Do not know what to do. Please help... I also change dependencies as given above but its not working."]}, {"number": 7418, "title": "Branch 147149282", "body": "", "comments": []}]