[{"number": 39588, "title": "tf.keras.model fit() significantly slower when using weighted validation data in comparison to tf2.1.0", "body": "<em>Please make sure that this is an issue related to performance of TensorFlow.\r\nAs per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:performance_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nNo\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nArchLinux & Ubuntu 18.04 LTS\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\nNo\r\n- TensorFlow installed from (source or binary):\r\nbinary\r\n- TensorFlow version (use command below):\r\nv2.2.0-rc4-8-g2b96f3662b 2.2.0\r\n(compared to: v2.1.0-rc2-17-ge5bf8de 2.1.0)\r\n- Python version:\r\n3.7.5\r\n\r\nThe ArchLinux machine runs on CPU\r\nThe Ubuntu machine runs on GPU with:\r\n- CUDA/cuDNN version:\r\n10.1.243\r\n- GPU model and memory:\r\nGeForce GTX 1080 with 7126 MB memory\r\n\r\n**Describe the current behavior**\r\nWhen training a simple tf.keras.model multilayer perceptron with a call to .fit() containing a validation_data that contains weights results in a significant slower fit() then in comparison to TensorFlow 2.1.0 with the exact same code.\r\n\r\n**Describe the expected behavior**\r\nSimilar performance between TensorFlow 2.1.0 and 2.2.0 when training a tf.keras.model with a weighted validation data set.\r\n\r\n**Standalone code to reproduce the issue**\r\nPackage requirements for code snippet using python 3.7.5:\r\n``` py\r\nnumpy= \"==1.18.2\"\r\ntensorflow = \"==2.2.0\"\r\ntensorflow-datasets = \"==3.1.0\"\r\n```\r\n```py\r\nimport typing\r\n\r\nimport numpy as np\r\nfrom tensorflow import keras\r\nimport tensorflow_datasets as tfds\r\n\r\n\r\ndef build_neural_network(input_dimension: int, number_of_classes: int, compile_options: dict):\r\n    model = keras.Sequential()\r\n    model.add(keras.layers.Dense(112, activation='relu', input_dim=input_dimension))\r\n    model.add(keras.layers.Dense(112, activation='relu'))\r\n    model.add(keras.layers.Dense(number_of_classes, activation='softmax'))\r\n\r\n    model.compile(**compile_options)\r\n\r\n    print(model.summary())\r\n\r\n    return model\r\n\r\ndef load_in_images_and_labels_and_reshape(dataset) -> typing.Tuple[np.ndarray, np.ndarray]:\r\n    images = []\r\n    labels = []\r\n    for image, label in tfds.as_numpy(dataset):\r\n        new_image_shape = image.shape[0] * image.shape[1]\r\n        images.append(image.reshape(new_image_shape))\r\n        labels.append(label)\r\n\r\n    return np.array(images), np.array(labels)\r\n\r\n\r\ndef train_neural_network(is_random_weighing: bool):\r\n    dataset_train      = tfds.load('emnist', split='train', as_supervised=True)\r\n    dataset_validation = tfds.load('emnist', split='test', as_supervised=True)\r\n\r\n    train_images, train_labels           = load_in_images_and_labels_and_reshape(dataset_train)\r\n    validation_images, validation_labels = load_in_images_and_labels_and_reshape(dataset_validation)\r\n    train_labels      = keras.utils.to_categorical(train_labels)\r\n    validation_labels = keras.utils.to_categorical(validation_labels)\r\n\r\n    print(\"load\")\r\n    compile_options =  {\r\n        \"loss\": \"categorical_crossentropy\",\r\n        \"optimizer\": \"adam\",\r\n        \"metrics\": [\"categorical_accuracy\"],\r\n        \"weighted_metrics\": [\"categorical_accuracy\"]\r\n    }\r\n    network = build_neural_network(train_images.shape[-1], len(train_labels[0]), compile_options)\r\n\r\n    fit_options = {    \r\n        \"batch_size\": 2048,\r\n        \"epochs\": 10,\r\n        \"verbose\": 1,\r\n        \"workers\": 1\r\n    }\r\n    if is_random_weighing:\r\n        random_weights = np.random.rand(len(validation_images))\r\n        validation_data_tuple = (validation_images, validation_labels, random_weights)\r\n    else:\r\n        validation_data_tuple = (validation_images, validation_labels)\r\n    history = network.fit(train_images, train_labels, validation_data=validation_data_tuple, **fit_options)\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    is_random_weighing = True\r\n    train_neural_network(is_random_weighing)\r\n\r\n```\r\n\r\n**Other info / logs**\r\nRunning the above code snippet on the ArchLinux machine, run on CPU:\r\ntakes roughly 19 seconds per epoch. When the same code is run in TensorFlow 2.1.0 it takes roughly 5 seconds per epoch. When the weighing off the validation dataset is turned off with TensorFlow 2.2.0 (is_random_weighing = False) the performance becomes similar to TensorFlow 2.1.0; roughly 5 seconds per epoch.\r\nThe slowdown is also seen on the Ubuntu machine, run on GPU, but then due to likely different hardware, tf 2.2.0 is 7 times as slow as  tf 2.1.0.\r\n\r\nThe effect was not seen (but maybe it was not measurable) when using mnist in place of emnist.\r\n\r\nThe issue seems related to: #39039\r\nIn which the comment by @romanovzky brought to light that it might be due to the validation data or validation split. Although that is in the context of comparing a tensorflow estimator to keras.\r\n\r\nThis issue also seems related to: #39434\r\nIn which also from tf2.1 to tf.2.2 a  significant performance drop is seen.\r\n\r\nIt seems like another small puzzle piece in a larger puzzle (or I do something simple wrong on both machines).\r\n", "comments": ["Was able to reproduce the issue. [TF v2.2](https://colab.research.google.com/gist/amahendrakar/46164b8bcb6761d64167d45494b8b1d6/39588-2-2.ipynb) and [TF-nightly](https://colab.research.google.com/gist/amahendrakar/5212de55fe93c63892fa5edfefbff602/39588-tf-nightly.ipynb) take more time for each epoch when compared to [TF v2.1](https://colab.research.google.com/gist/amahendrakar/c391c251960c9f359f05eaf5ba169942/39588-2-1.ipynb). Please find the attached gist. Thanks!", "Any update on these performance problems in TF 2.2? This issue is one of many; see also https://github.com/tensorflow/tensorflow/issues/39665 and https://github.com/tensorflow/tensorflow/issues/38675 and https://github.com/tensorflow/tensorflow/issues/39574 and https://github.com/tensorflow/tensorflow/issues/39434.\r\n\r\nWhat is the status?", "Tensorflow 2.2 takes much more time than 2.1/2.0 to start training, after called \"keras.fit\". \r\n\r\n```\r\n2020-06-01 10:16:44.991459: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2020-06-01 10:16:46.235945: W tensorflow/stream_executor/gpu/asm_compiler.cc:81] Running ptxas --version returned 256\r\n2020-06-01 10:16:46.328871: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: \r\nRelying on driver to perform ptx compilation. \r\nModify $PATH to customize ptxas location.\r\nThis message will be only logged once.\r\n2020-06-01 10:16:48.148004: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\r\n2020-06-01 10:23:36.473814: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session started.\r\n\r\n```\r\n\r\nIt stucks about 7 mins to start training.", "Log from 2.1\r\n\r\n```\r\nINFO:tensorflow:batch_all_reduce: 436 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\r\nI0531 20:55:03.956965 139684401002304 cross_device_ops.py:760] batch_all_reduce: 436 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\r\nINFO:tensorflow:batch_all_reduce: 436 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\r\nI0531 20:55:14.695299 139684401002304 cross_device_ops.py:760] batch_all_reduce: 436 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\r\n2020-05-31 20:55:39.932592: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2020-05-31 20:55:41.811100: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\r\n2020-05-31 20:55:48.718710: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.\r\n```\r\n", "Interesting that the random weighing causes the performance slowdown. In my case, turning on dropout layers (even with dropout_prob=0) causes the performance slowdown. Could it be something in the tensorflow randomness modules?", "What is the status of this issue? Is someone actively looking into it? If not is there any estimation when someone might look at this issue? \r\nIt is understandable that handling issues might take a while, especially due to the huge quantity tensorflow receive!\r\n\r\nIs there something I can do to help?\r\n\r\nCurrently this issue circumvents us from updating to tensorflow 2.2 and thus updating to python 3.8. Luckily python 3.8 or tensorflow 2.2 is not yet a requirement.\r\n", "@sirvincent thanks for reporting the issue, a fix was submitted in [1d2d05f](https://github.com/tensorflow/tensorflow/commit/0cc6210daa35247daf7f4cc98c115de611d2d05f). that is available in the latest nightly. ", "Thanks @goldiegadde I have tested tf-nightly 2.3.0.dev20200619 and the issue seems to be fixed.\r\nThank you!", "This regretion is not completely fixed with 2.3.0. It seems that, for whatever reason, the first epoch needs a long time to start, and the first validation step is also very slow.  From the 2nd epoch onward, the epoch times are comparable.\r\n~This can be reproduced in this colab~. EDIT: Colab link removed as it is pointing to another colab, I have lost (probably deleted) the original one.", "@romanovzky Can you please open a new issue with the gist (you already have one above). Thanks!", "I had the same issue and was able to circumvent it by converting my weights numpy-array into a pandas series. Training now starts immediately and I do not have to wait anymore.\r\n`pd.Series(my_weights)`", "> \r\n> \r\n> I had the same issue and was able to circumvent it by converting my weights numpy-array into a pandas series. Training now starts immediately and I do not have to wait anymore.\r\n> `pd.Series(my_weights)`\r\n\r\nThis is works for me, but how that actual works? the API isn't only numpy array?", "The problem is also fixed if you use a generator (keras Sequence), which is what I have been using.\r\n\r\n", "> I had the same issue and was able to circumvent it by converting my weights numpy-array into a pandas series. Training now starts immediately and I do not have to wait anymore.\r\n> `pd.Series(my_weights)`\r\n\r\nIf this work, I call sorcery. Thank you!", "> I had the same issue and was able to circumvent it by converting my weights numpy-array into a pandas series. Training now starts immediately and I do not have to wait anymore. `pd.Series(my_weights)`\r\n\r\nIt's work for me", "New issue has been opened recently: https://github.com/tensorflow/tensorflow/issues/48965"]}, {"number": 39587, "title": "TS_SessionRun: 'Input to reshape' errors.  Requested shape is always tensor_size ^ 2", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nYes\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nUbuntu 16.04, Ubuntu 18.04\r\n\r\n- TensorFlow installed from (source or binary):\r\nBinary, From pip. C-API downloaded from https://www.tensorflow.org/install/lang_c\r\n\r\n- TensorFlow version (use command below):\r\n('v2.1.0-rc2-17-ge5bf8de', '2.1.0')\r\nC-API: Hello from TensorFlow C library version 1.15.0\r\n\r\n- Python version:\r\nPython 2.7.12\r\n\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n**Describe the current behavior**\r\nLoading a saved model with the C-API  fails to run the graph. All input placeholders fail in the 'reshape' operation. For example:\r\n`TF_SessionRun status: 3:Input to reshape is a tensor with 3715 values, but the requested shape has 13801225`\r\n\r\n`TF_SessionRun status: 3:Input to reshape is a tensor with 2 values, but the requested shape has 4`\r\n\r\n`TF_SessionRun status: 3:Input to reshape is a tensor with 1422 values, but the requested shape has 2022084`\r\nThe number of values in the requested shape is always the 'expected number of values' ^ 2.\r\nI suspect the following line of code plays a role in this: https://github.com/tensorflow/tensorflow/blob/77245d07d13522a5cb5d060390fffa1894df5bbf/tensorflow/core/kernels/reshape_op.h#L139\r\n\r\nTF_LoadSessionFromSavedModel loads the model successfully. And it will correctly fail to run if I don't provide all inputs. I can see from stderr that it is calling the InitOp:\r\n`2020-05-15 19:18:37.508528: I tensorflow/cc/saved_model/loader.cc:202] Restoring SavedModel bundle.`\r\n\r\n`2020-05-15 19:18:37.529034: I tensorflow/cc/saved_model/loader.cc:151] Running initialization op on SavedModel bundle at path: /home/james/model/bq/1`\r\n\r\n`2020-05-15 19:18:38.585963: I tensorflow/cc/saved_model/loader.cc:311] SavedModel load for tags { serve }; Status: success. Took 1097826 microseconds.`\r\n\r\nMore on the StackOverflow question: https://stackoverflow.com/questions/61787472/reshape-input-layer-requested-shape-size-always-input-shape-size-squared\r\n\r\n`signature_def:`\r\n` - name: 'serving_default'`\r\n` - method_name: 'tensorflow/serving/predict'`\r\n\r\n**Describe the expected behavior**\r\nTF_LoadSessionFromSavedModel outputs a runnable graph, or if extra steps are required to run a saved_model with the C-API they should be documented.\r\nUsing the JNI code as an example, I cannot find extra steps there: https://github.com/tensorflow/tensorflow/blob/ff17316b19d5958605cebf941e4302d60f405784/tensorflow/java/src/main/native/session_jni.cc#L132\r\nI cannot use the C++ shared lib because of the `No session factory registered for the given session options: {target: \"\" config: } Registered factories are {}.` issue that I cannot get around.\r\n\r\n**Standalone code to reproduce the issue**\r\nI don't think this is possible. The operations that fail are all populated by files in the 'assets' directory.\r\nThe values in the 'tensor with ??? values' are correct, the requested shape is not.\r\nThe code is pretty much just a standard C-API block, influenced by the JNI code above:\r\n\r\n`session = TF_LoadSessionFromSavedModel(...);`\r\n`for each input:`\r\n`   inputs.push_back(TF_GraphOperationByName(...));`\r\n\r\n`for each output:`\r\n`   outputs.push_back(TF_GraphOperationByName(...));`\r\n\r\n`TF_SessionRun(session, inputs, ..., outputs, ....);`\r\n\r\n\r\n", "comments": ["I think the problem was in my input Tensor creation. It is something like this:\r\n\r\n```\r\nTF_Tensor* NewStringTensor(StringView s, TF_Status* status = nullptr)\r\n{\r\n   const int OFFSET = 8;\r\n   auto dstLen = TF_StringEncodedSize(s.length());\r\n\r\n   TF_Tensor* t = TF_AllocateTensor(TF_STRING, nullptr, 0, OFFSET + dstLen);\r\n   char* dst = static_cast<char*>(TF_TensorData(t));\r\n   std::memset(dst, 0, OFFSET);\r\n\r\n   TF_StringEncode(s.data(), s.length(), dst + OFFSET, dstLen, status);\r\n\r\n   return t;\r\n}\r\n```\r\n\r\nand\r\n\r\n```\r\nTF_Tensor* NewFloatTensor(float v)\r\n{\r\n   auto tensor = TF_AllocateTensor(TF_FLOAT, nullptr, 0, sizeof(v));\r\n   auto data = static_cast<float*>(TF_TensorData(tensor));\r\n   std::memcpy(data, &v, sizeof(v));\r\n\r\n   return tensor;\r\n}\r\n```\r\n\r\nI ported from the test code here: https://github.com/Neargye/hello_tf_c_api/blob/28f7ed7aeaf4fb6462918d3358c6c5d3d517e081/src/tf_utils.cpp#L71\r\n\r\nIt seems that I actually need to set the `const int64_t*` and `num_dims` parameters to TF_AllocateTensor to proper values (unlike in the JNI example)? Like:\r\n\r\n```\r\nTF_Tensor* NewStringTensor(StringView s)\r\n{\r\n   const int OFFSET = 8;\r\n   auto dstLen = TF_StringEncodedSize(s.length());\r\n\r\n   int64_t dims = 0;\r\n   TF_Tensor* t = TF_AllocateTensor(TF_STRING, &dims, 1, OFFSET + dstLen);\r\n   if (!t)\r\n   {\r\n      return nullptr;\r\n   }\r\n   \r\n   char* dst = static_cast<char*>(TF_TensorData(t));\r\n   std::memset(dst, 0, OFFSET);\r\n\r\n   TF_Status* status = TF_NewStatus();\r\n   TF_StringEncode(s.data(), s.length(), dst + OFFSET, dstLen, status);\r\n   TF_DeleteStatus(status);\r\n\r\n   return t;\r\n}\r\n```\r\n\r\nand similarly for NewFloatTensor. Is this correct? ", "Now the issue is that the output tensors seem to be empty always. Here's the code\r\n\r\n```\r\n   std::vector<TF_Tensor*> outputValues = { nullptr, nullptr, nullptr };\r\n\r\n   TF_Status* s = TF_NewStatus();\r\n   TF_SessionRun(\r\n      session.get(),\r\n      nullptr,\r\n      inputs.inputs.data(),\r\n      inputs.inputData.data(),\r\n      inputs.inputs.size(),\r\n      outputs.data(),\r\n      outputValues.data(),\r\n      outputs.size(),\r\n      nullptr,\r\n      0,\r\n      nullptr,\r\n      s\r\n   );\r\n\r\n   printf(\"TF_SessionRun status: %u\\n\", TF_GetCode(s));\r\n   TF_DeleteStatus(s);\r\n   \r\n   for (TF_Tensor* ov : outputValues)\r\n   {\r\n      if (ov == nullptr)\r\n      {\r\n         std::cout << \"output failure\\n\";\r\n         continue;\r\n      }\r\n      \r\n      std::cout << \"output (0x\" << ov << \"):\\n\";\r\n      std::cout << \" - type: \" << TF_TensorType(ov) << \"\\n\";\r\n      std::cout << \" - bytesize: \" << TF_TensorByteSize(ov) << \"\\n\";\r\n      std::cout << \" - element_count: \" << TF_TensorElementCount(ov) << \"\\n\";\r\n      std::cout << \" - data: \" << TF_TensorData(ov) << \"\\n\";\r\n      std::cout << \" - num_dims: \" << TF_NumDims(ov) << \"\\n\";\r\n\r\n      for (int i = 0; i < TF_NumDims(ov); ++i)\r\n      {\r\n         std::cout << \"  - size_dim[\" << i << \"]: \" << TF_Dim(ov, i) << \"\\n\";\r\n      }\r\n      \r\n      TF_DeleteTensor(ov);\r\n      std::cout << \"\\n\";\r\n   }\r\n\r\n```\r\n\r\nand here's the dump of the TF_Tensor* in the `outputValues` vector:\r\n\r\n```\r\nTF_LoadSessionFromSavedModel status: 0:\r\nTF_SessionRun status: 0\r\noutput (0x0x324f020):\r\n - type: 2\r\n - bytesize: 0\r\n - element_count: 0\r\n - data: 0x324ecc0\r\n - num_dims: 2\r\n  - size_dim[0]: 0\r\n  - size_dim[1]: 2\r\n\r\noutput (0x0x3031c60):\r\n - type: 7\r\n - bytesize: 0\r\n - element_count: 0\r\n - data: 0x7f32ba518189\r\n - num_dims: 2\r\n  - size_dim[0]: 0\r\n  - size_dim[1]: 2\r\n\r\noutput (0x0x324f7c0):\r\n - type: 7\r\n - bytesize: 0\r\n - element_count: 0\r\n - data: 0x7f32ba518189\r\n - num_dims: 2\r\n  - size_dim[0]: 0\r\n  - size_dim[1]: 1\r\n```", "I figured it out. I wasn't setting the dims of the input tensors correctly. I now use these two functions to input a single float and single string. It seems to work and I hope they're correct.\r\n\r\nHow up to date are the C-API tar.gz binaries?\r\n\r\n```\r\nTF_Tensor* TensorflowWrapper::NewStringTensor(StringView s)\r\n{\r\n   const int OFFSET = sizeof(int64_t);\r\n   auto dstLen = ::TF_StringEncodedSize(s.length());\r\n\r\n   std::array<int64_t, 1> dims{1};  // Change at your peril.\r\n   TF_Tensor* t = TF_AllocateTensor(TF_STRING, dims.data(), dims.size(), OFFSET + dstLen);\r\n   if (t)\r\n   {\r\n      char* dst = static_cast<char*>(::TF_TensorData(t));\r\n      std::memset(dst, 0, OFFSET);\r\n\r\n      // TODO: Handle errors properly.\r\n      TF_Status* status = TF_NewStatus();\r\n      TF_StringEncode(s.data(), s.length(), dst + OFFSET, dstLen, status);\r\n      TF_DeleteStatus(status);\r\n   }\r\n\r\n   return t;\r\n}\r\n\r\nTF_Tensor* TensorflowWrapper::NewFloatTensor(float v)\r\n{\r\n   std::array<int64_t, 1> dims{1};  // Change at your peril.\r\n\r\n   TF_Tensor* t = TF_AllocateTensor(TF_FLOAT, dims.data(), dims.size(), sizeof(float));\r\n   if (t)\r\n   {\r\n      auto data = static_cast<float*>(TF_TensorData(t));\r\n      std::memcpy(data, &v, sizeof(float));\r\n   }\r\n\r\n   return t;\r\n\r\n}\r\n```", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39587\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39587\">No</a>\n"]}, {"number": 39586, "title": "tf.metrics.MeanIoU throws dimensions mismatch error when used with SparseCategoricalCrossEntropy", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 20.04\r\n- TensorFlow installed from (source or binary): Source\r\n- TensorFlow version (use command below): TF.2.2.0\r\n- Python version: 3.8\r\n- Bazel version (if compiling from source): 2.0\r\n- GCC/Compiler version (if compiling from source): gcc7\r\n- CUDA/cuDNN version: 10.2\r\n- GPU model and memory: Nvidia Titan Xp (12GB)\r\n\r\n\r\n**Describe the current behavior**\r\n\r\n`tf.metrics.meanIOU` throws a dimensions mismatch error when using a model trained using `SparseCategoricalCrossEntropy `for a semantic segmentation problem.\r\n`My model outputs  dimensions = 224x224x2, y_true = 224x224x1 (class_indices).`\r\n\r\nA workaround was suggested at https://github.com/tensorflow/tensorflow/issues/32875#issuecomment-629360707 and worked for TF2.1, but fails with a dimensions mismatch error for TF2.2.\r\n The suggested fix that doesn't work in TF.2.2:\r\n\r\n```\r\n\r\n# fix for miou calculation when using sparse_categorical _cross_entropy \r\n    # https://github.com/tensorflow/tensorflow/issues/32875\r\n\r\nclass UpdatedMeanIoU(tf.keras.metrics.MeanIoU):\r\n    @tf.function\r\n    def __call__(self, y_true, y_pred, sample_weight=None):\r\n        self.y_pred = tf.math.argmax(self.y_pred, axis=-1)\r\n        return super().__call__(y_true, self.y_pred, sample_weight=sample_weight)\r\n\r\n```\r\nHere is the error:\r\n\r\nTraceback (most recent call last):\r\n\r\n```\r\n\r\n    ValueError: Dimension 0 in both shapes must be equal, but are 1048576 and 2097152. Shapes are [1048576] and [2097152].\r\n    \tFrom merging shape 0 with other shapes. for '{{node confusion_matrix/stack_1}} = Pack[N=2, T=DT_INT64, axis=1](confusion_matrix/control_dependency_2, confusion_matrix/control_dependency_3)' with input shapes: [1048576], [2097152].\r\n```\r\n\r\n\r\n\r\nAppreciate a fix.", "comments": ["@dhaneshr \r\n\r\nRequest you to share colab link or simple standalone code to reproduce the issue in our environment.It helps us in localizing the issue faster.Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "also having this issue. bump!", "try this out: https://stackoverflow.com/questions/61824470/dimensions-mismatch-error-when-using-tf-metrics-meaniou-with-sparsecategorical", "I also have this problem, this is my notebook:\r\n\r\nhttps://colab.research.google.com/drive/15Sta5cKbQ8e4UC1Fh_D2yg9nYpmVzNIT#scrollTo=NkQtWL5PMj0l\r\n\r\nYou can check it. There are some workarounds using inheritance of tf.keras.metrics.Metric but I think it's better that this bug is fixed.", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39586\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39586\">No</a>\n"]}, {"number": 39585, "title": "Create bot_config.yml", "body": "", "comments": []}, {"number": 39584, "title": "tf.keras.preprocessing.text_dataset_from_directory function", "body": "AttributeError                            Traceback (most recent call last)\r\n<ipython-input-15-9116635614ef> in <module>()\r\n----> 1 train_ds = tf.keras.preprocessing.text_dataset_from_directory( x_train,\r\n      2                                                               labels='inferred',\r\n      3                                                               label_mode='int',\r\n      4                                                               batch_size=batch_size,\r\n      5                                                               validation_split=0.2,\r\n\r\nAttributeError: module 'tensorflow.keras.preprocessing' has no attribute 'text_dataset_from_directory'", "comments": ["@victorkab92,\r\nAs per the [documentation](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text_dataset_from_directory), the API is available only in TF-nightly version.\r\n\r\nI was able to import the API with the latest TF-nightly. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/67a1fb7ec8dec4595659f95a8f039687/39584.ipynb). Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "i am facing the same issue, i installed tf - nightly as well as suggested, but still unable to resolve issue. I am getting the same error while loading text_dataset_from_directory and TextVectorization functions. I am not sure if am missing anything. Please help me on this. ", "> i am facing the same issue, i installed tf - nightly as well as suggested, but still unable to resolve issue. I am getting the same error while loading text_dataset_from_directory and TextVectorization functions. I am not sure if am missing anything. Please help me on this.\r\n\r\n@Harish2104,\r\nCould you please submit a new issue from [this link](https://github.com/tensorflow/tensorflow/issues/new/choose) and fill in the template along with the complete code, so that we can track the issue there. Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "i am facing the same issue, any solution please  ?!!", "Same error here", "@Rajalod75, @tabatabaeis \r\nCould y'all please submit a new issue from [this link](https://github.com/tensorflow/tensorflow/issues/new/choose) and fill in the template, so that we can track the issue there. Thanks!"]}, {"number": 39583, "title": "Training-Time updated custom Layer attributes are NOT saved", "body": "\r\n**System information**\r\n\r\n- OS Platform and Distribution: Linux Ubuntu 19.10\r\n- TensorFlow installed from: Docker Image latest-gpu-py3-jupyter\r\n- TensorFlow version: v2.1.0-rc2-17-ge5bf8de 2.1.0\r\n- Python version: (major, minor, micro, release level, serial) (3, 6, 9, 'final', 0)\r\n- CUDA/cuDNN version: 10.1\r\n- GPU model and memory: GeForce GTX 1050 Ti\r\n\r\n**Describe the current behavior**\r\nI am not able to save the updated attribute value `self.ratio` of the following custom `tf.keras.layer.Layer`\r\n```\r\n   class Kwta(Layer):\r\n\r\n    def __init__(self, ratio, conv = False, data_format=\"channels_last\", **kwargs):\r\n        super(Kwta, self).__init__(**kwargs)\r\n        self.conv = conv\r\n        self.ratio = ratio\r\n        self.data_format = data_format\r\n        \r\n    def build(self, input_shape):\r\n        #Not important here, see Reproducible Example Section for the full code\r\n        \r\n    def call(self, inputs):\r\n      #Not important here, see Reproducible Example Section for the full code\r\n    \r\n    def get_config(self):\r\n        my_config = {\r\n            'conv' : self.conv,\r\n            'ratio' : self.ratio,\r\n            'data_format' : self.data_format,\r\n            'dim' : self.dim\r\n        }\r\n\r\n        base_config = super(Kwta, self).get_config()\r\n        return dict(list(base_config.items()) + list(my_config.items()))\r\n```\r\nWhich gets incrementally updated while training by the following custom `tf.keras.callbacks.Callback`\r\n\r\n```\r\nclass incremental_learning_withDecreasing_ratio(tf.keras.callbacks.Callback):\r\n    \"\"\" Icrementally adjust the Kwta self.ratio attribute every 2 epochs.\r\n         End the learning process when ratio == 0.3  \"\"\"\r\n\r\n    def __init__(self, delta = 0.05):\r\n        super(incremental_learning_withDecreasing_ratio, self).__init__()\r\n        self.delta = delta\r\n\r\n    def on_epoch_begin(self, epoch, logs=None):\r\n        # The update occurs at the beginning of every 2 epochs\r\n        if epoch % 2 == 0:  \r\n            for i in range(1, 5): # For each Kwta layer\r\n                name = 'kwta_'+str(i)\r\n                layer = self.model.get_layer(name = name)      \r\n                layer.ratio -= self.delta\r\n            \r\n            print('\\n Fine tuning: current ratio {} \\n'.format(round(layer.ratio, 2)))\r\n    \r\n    def on_epoch_end(self, epoch, logs=None):\r\n        layer = self.model.get_layer('kwta_1')\r\n        if ( round(layer.ratio, 2) == 0.3 ) and epoch % 2 == 1: \r\n                print('\\n Desired Ratio reached, stop training...')\r\n                self.model.stop_training = True\r\n```\r\nThis is the whole model on which I use the Kwta layer and the callback\r\n\r\n```\r\nkwta_cnn = tf.keras.models.Sequential([\r\n  layers.Conv2D(32, 3, padding='same', activation=None, input_shape = (32, 32, 3)),\r\n  Kwta(ratio=0.6, conv=True, name='kwta_1'),\r\n  layers.Conv2D(32, 3, padding='same', activation=None),\r\n  Kwta(ratio=0.6, conv=True, name='kwta_2'),\r\n  layers.MaxPooling2D(pool_size=(2,2)),\r\n  layers.Dropout(0.2, seed=42),\r\n\r\n  layers.Conv2D(64, 3, padding='same', activation=None),\r\n  Kwta(ratio=0.6, conv=True, name='kwta_3'),\r\n  layers.Conv2D(64, 3, padding='same', activation=None),\r\n  Kwta(ratio=0.6, conv=True, name='kwta_4'),\r\n  layers.MaxPooling2D(pool_size=(2,2)),\r\n  layers.Dropout(0.3, seed=42),\r\n\r\n  layers.Flatten(),\r\n  layers.Dense(10, activation='softmax', kernel_regularizer= tf.keras.regularizers.l2(0.0005))\r\n])\r\n```\r\nWhen I fit the model `self.ratio` is correctly updated until its value is `0.3` as printed by the callback\r\n```\r\nhistory_kwta_ft = kwta_cnn.fit(x=x_train, y=y_train, epochs = 20, callbacks=[incremental_learning_withDecreasing_ratio()])\r\n```\r\n```\r\n......\r\n \r\nFine tuning: current ratio 0.4 \r\n\r\nEpoch 7/20\r\n50000/50000 [==============================] - 40s 798us/sample - loss: 0.9049 - accuracy: 0.7080\r\nEpoch 8/20\r\n50000/50000 [==============================] - 39s 787us/sample - loss: 0.8921 - accuracy: 0.7122\r\n\r\n Fine tuning: current ratio 0.35 \r\n\r\nEpoch 9/20\r\n50000/50000 [==============================] - 39s 782us/sample - loss: 0.8862 - accuracy: 0.7141\r\nEpoch 10/20\r\n50000/50000 [==============================] - 39s 785us/sample - loss: 0.8819 - accuracy: 0.7147\r\n\r\n Fine tuning: current ratio 0.3 \r\n\r\nEpoch 11/20\r\n50000/50000 [==============================] - 40s 793us/sample - loss: 0.8812 - accuracy: 0.7174\r\nEpoch 12/20\r\n49920/50000 [============================>.] - ETA: 0s - loss: 0.8651 - accuracy: 0.7218\r\n Desired Ratio reached, stop training...\r\n```\r\n**Here is where the issue emerges**: I am getting two way different accuracies when I evaluate the trained model on the test set before and after saving it:\r\n```\r\n# Before Saving\r\nkwta_cnn.evaluate(x = x_test, y = y_test, batch_size=128)\r\n10000/10000 [==============================] - 5s 534us/sample - loss: 0.9503 - accuracy: 0.7017\r\n\r\nkwta_cnn.save('saved_custom_model/kwta_cnn_minimal') \r\ndel kwta_cnn\r\nkwta_cnn = tf.keras.models.load_model('saved_custom_model/kwta_cnn_minimal')\r\n\r\n# After Saving\r\nkwta_cnn.evaluate(x = x_test, y = y_test, batch_size=128)\r\n10000/10000 [==============================] - 3s 341us/sample - loss: 1.1248 - accuracy: 0.6349\r\n```\r\nAfter debugging for a while, I am strongly confident this drop in accuracy is due to `self.ratio` not being correctly saved by `model.save()`. In particular, I believe TF only store the original attribute (in this specific case `0.6`) and cannot deal with dynamic updated attributes that are neither `tf.Variable()` nor `self.add_weight()`. Unfortunatly the latter is not an option in my case since I seem to be able to handle only integers inside the `call(inputs)` method to perform my computation and not `tf.Tensor`s.\r\n\r\n**Describe the expected behavior**\r\nTo be able to save and store a `tf.keras.layers.Layer` with training-time updated attributes.  \r\n\r\n**Standalone code to reproduce the issue**\r\n [Colab Minimal Example](https://colab.research.google.com/drive/1LHvG8yNrX3C9SJHJ2OojZCryFSCw8nG0?usp=sharing)\r\n", "comments": ["I am able to replicate the gist shared above, please find the replicated [gist here](https://colab.sandbox.google.com/gist/Saduf2019/73f7d2b339de0f2c29d5923c8190b469/untitled182.ipynb)", "After further debugging I figured out that the attribute is actually very well stored by `model.save` it was just me missing to add the label `custom_objects = {'Kwta':Kwta}` while loading the model. No I am able to access it.\r\n\r\nSo what is causing the drop in Accuracy after saving the model? What is even more strange is that the predictions before and after saving (resp. model names `kwta_cnn`, `kwta_cnn_after`) are actually the same! \r\n\r\n```\r\ntf.reduce_sum(tf.cast(tf.math.logical_not(tf.math.equal(kwta_cnn.predict(x_test), kwta_cnn_after.predict(x_test))), dtype=tf.float32))\r\n\r\n<tf.Tensor: shape=(), dtype=float32, numpy=0.0>\r\n```\r\nTherefore I believe the problem has to do with `model.Evaluate()` which somehow does not update the computation in `call()` when it relies on non-tensors, sticking with the original value of the attribute, not the one updated by the callback. Thus I experience such different evaluations, because before saving the original value of `self.ratio=0.6` and after saving will be `self.ratio=02`.\r\nAt least this is my intuition. It would be nice if someone could point me out what is really going on.\r\n\r\nHowever, I have managed to correctly get same Accuracy before and after saving by defining the attribute `self.ratio` as a `tf.Variable(ratio, traiable=False)` instead of a float.", "Was able replicate the issue with TF v2.5,please find the gist[ here](https://colab.research.google.com/gist/sushreebarsa/7413aa8d0f29dc7bb7583d9a14df7405/untitled182.ipynb#scrollTo=74S0CjIiW61I)....Thanks!", "Hi There,\n\n This is a stale issue. As you are using an older version of tensorflow, we are checking to see if you still need help on this issue. Please test the issue with the latest TensorFlow (TF2.7 and tf-nightly). If the issue still persists with the newer versions of TF, please feel free to open it in [keras-team/keras](https://github.com/keras-team/keras/issues) repository by providing details about the issue and a standalone code to reproduce the issue. Thanks! \n\n Please note that Keras development has moved to a separate Keras-team/keras repository to focus entirely on only Keras. Thanks! ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39583\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39583\">No</a>\n"]}, {"number": 39582, "title": "AttributeError: 'Tensor' object has no attribute 'numpy' in Tensorflow 2.1", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA\r\n- TensorFlow installed from (source or binary): Binary (pip install)\r\n- TensorFlow version (use command below): 2.1.0\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source): \r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory: NA\r\n\r\n**Describe the current behavior**\r\nI am trying to generate a custom loss function but to do that I need to extract the value of the tensor. However, when I use the numpy() function, it says \"AttributeError: 'Tensor' object has no attribute 'numpy'\". I don't understand why this is happening. Also, tf.executing_eagerly() returns false even though I include the parameter \"run_eagerly=True\" in the compile statement. Any help would be appreciated.\r\n\r\n**Describe the expected behavior**\r\nIdeally, the code should let me access the value of the tensor for further manipulation.\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n```\r\ndef custom_error_finder(y_actual,y_pred):\r\n\tprint(tf.executing_eagerly())\r\n\tcount = 0\r\n\tqw = tf.py_function((y_actual).numpy())\r\n\tya = ((y_actual[0].numpy()).decode())\r\n\typ = ((y_pred[0].numpy()).decode())\r\n\tfor i,j in ya,yp:\r\n\t\tif i!=j:\r\n\t\t\tcount = count+1\r\n\tmse = pow(count,2)/len(ya)\r\n\treturn mse\r\n```\r\nAbove is the custom loss function that I am trying to use. The dataset I am training my model on contains only strings.\r\n", "comments": ["@kevin-bony8998 \r\n\r\nLooks like code is incomplete. Request you to share colab link or simple standalone code to reproduce the issue in our environment.It helps us in localizing the issue faster.Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39582\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39582\">No</a>\n"]}, {"number": 39581, "title": "Why is tensorflow-gpu still being released for new versions of tensorflow?", "body": "The tensorflow documentation states that the `tensorflow` package supports both CPU and GPU (since version 2.x).\r\n\r\nMy question is why the `tensorflow-gpu` package is still being released for new versions of tensorflow.\r\n\r\nThis might be confusing to people (it was for me, definitely), especially because  https://pypi.org/project/tensorflow-gpu has no information on the matter.\r\n\r\nI think it would be nice to add a note to the documentation and pypi, _why_ the `tensorflow-gpu` package still exists (if it must), so that other people don't have to go through the trouble of downloading and `diff`ing the wheels. :grimacing:\r\n\r\nCheers!", "comments": ["There are toolchains that explicitly install tensorflow-gpu, that's why we continue to release them, although they are the same pip just renamed.", "As @mihaimaruseac expressed, it is still being released to ensure that all systems have ample time to migrate.\r\n\r\n@yifeif Can you add some information on pypi pages for tensorflow.* and tf-nightly.* ?"]}, {"number": 39580, "title": "Model saved with Lambda layer with a ragged input breaks when reloading", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): linux\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.2\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n**Describe the current behavior**\r\nWith the following model ragged inputs -> Embeddings -> reduce_sum with lambda layer -> Dense a saved model cannot be loaded back. \r\n\r\n```\r\na = Input(ragged=True, name='a', shape=(None,), dtype=tf.int32)\r\nb = Input(ragged=True, name='b', shape=(None,), dtype=tf.int32)\r\nembed_a = Embedding(10,  3)(a)\r\nembed_b = Embedding(10, 3)(b)\r\nembed_a_reduced = Lambda(tf.reduce_sum, arguments=dict(axis=1))(embed_a)\r\nembed_b_reduced = Lambda(tf.reduce_sum, arguments=dict(axis=1))(embed_b)\r\nconcat = Concatenate()([embed_a_reduced, embed_b_reduced])\r\nout = Dense(1)(concat)\r\nm = Model([a, b], out)\r\nm([tf.ragged.constant([[0], [], [1]]), tf.ragged.constant([[0], [], [1]])])\r\nm.save('/tmp/test')\r\nreloaded_model = tf.keras.models.load_model('/tmp/test')\r\n```\r\n```\r\nTypeError                                 Traceback (most recent call last)\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py in wrapper(*args, **kwargs)\r\n    200     try:\r\n--> 201       return target(*args, **kwargs)\r\n    202     except (TypeError, ValueError):\r\n\r\nTypeError: 'str' object is not callable\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTypeError                                 Traceback (most recent call last)\r\n14 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py in wrapper(*args, **kwargs)\r\n    203       # Note: convert_to_eager_tensor currently raises a ValueError, not a\r\n    204       # TypeError, when given unexpected types.  So we need to catch both.\r\n--> 205       result = dispatch(wrapper, *args, **kwargs)\r\n    206       if result is not OpDispatcher.NOT_SUPPORTED:\r\n    207         return result\r\n\r\nTypeError: 'module' object is not callable\r\n```\r\nif we debug dispatch is the module dispatch and not the function in that file. \r\n\r\n**Describe the expected behavior**\r\nWe should be able to save / load back the model.\r\n\r\n**Standalone code to reproduce the issue**\r\nhttps://colab.research.google.com/gist/tanguycdls/4685e5111c5e3bad43c7699977b49c9c/untitled.ipynb Tested on 2.2 but same error in nightlies. \r\n\r\n**Other info / logs** \r\nOne fix is to use tf nightly and override a keras Layer it then works. \r\n\r\n", "comments": ["I am able to replicate this error reported, please find the [gist here](https://colab.sandbox.google.com/gist/Saduf2019/ae5cd9a949c09ee078e41fb22d7bddc2/untitled183.ipynb)", "What is worse on this error is, that even if it is caught (by except), it somehow mangles the imports and naming and subsequently\r\n`tf.keras.layers.Reshape([1, 1])` returns `{TypeError}super() argument 1 must be type, not function` (will add some reproduction soon)", "Still an issue in TF 2.4.1 (same gist updated the version)", "@tanguycdls I updated two lines in your code as shown below. With that modification, it worked without any error. Please check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/c0c8c9500cb5fbfd4e71915d577e9b99/untitled183.ipynb)\r\n\r\n#### Two line before update \r\n```\r\n\r\n# embed_a_reduced = Lambda(tf.reduce_sum, arguments=dict(axis=1))(embed_a)\r\n# embed_b_reduced = Lambda(tf.reduce_sum, arguments=dict(axis=1))(embed_b)\r\n```\r\n\r\n#### Two line after update \r\n```\r\nembed_a_reduced = Lambda(lambda x:tf.reduce_sum(x,axis=1))(embed_a)\r\nembed_b_reduced = Lambda(lambda x:tf.reduce_sum(x, axis=1))(embed_b)\r\n```\r\n\r\nPlease verify once and close the issue if this was resolved for you. Thanks!", "@jvishnuvardhan Thanks I confirm it works: that's really strange. Do you see why such behavior happens ?", "@tanguycdls I am not an expert in serialization. But, this approach worked for me in my other code. Thanks!\r\n\r\nI am closing this issue as this was resolved. Please feel free to reopen if this issue persists again. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39580\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39580\">No</a>\n", "@tanguycdls @tomerk is an expert and he recommends using tensorflow `op` layer over `lambda` layer as op layers will serialize/deserialize more reliably than arbitrary lambda layers. So, the following approach is the best. Please check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/5a1821b0f30a02c37ff7e9ecf61840f5/untitled183.ipynb). Thanks!\r\n\r\n\r\n```\r\n# This works\r\nembed_a_reduced = tf.reduce_sum(embed_a, axis=1)\r\nembed_b_reduced = tf.reduce_sum(embed_b, axis=1)\r\n```"]}, {"number": 39579, "title": "Different training performance in eager, model.fit and estimator.train", "body": "**System information**\r\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\nTensorFlow installed from (source or binary): binary\r\nTensorFlow version (use command below): v2.0.0-rc2-26-g64c3d38 2.0.0\r\nPython version: 3.5\r\nCUDA/cuDNN version: 10.1\r\nGPU model and memory: GeForce RTX 2080Ti 11GB\r\n\r\n**Describe the current behavior**\r\nWe find the training performance is different among eager, model.fit and estimator.train.\r\nWe try to transform a YOLOv3 model from tf.keras to tf.estimator and find the training performance is different while we fixed the initial weight, input image, optimizer, learning rate, trainable variables and regularization loss. The first loss is the same, however the following training performance is different. Keras model seems more roberst.\r\n\r\nThus we tried to use some simple model to reproduce the phynominon. The input is a (1, 224, 224 3) matrix with all 1 elements, weights is ImageNet weights. optimizer uses SGD and learning rate uses 1e-4.\r\n\r\nWe find the first loss of the three keep its value in repetitive experiments.\r\nEager: 7.28364\r\nEstimator: 7.283639\r\nKeras model: 7.2836\r\n\r\nHowever, from the second step, the loss varies in different area.\r\nEager: 7.308 to 7.311\r\nEstimator: 7.3092x\r\nKeras model: 7.3085 to 7.3086\r\n\r\nSo, why the values are totally different? And how can we unite the performance.\r\n\r\n**Describe the expected behavior**\r\n\r\nWe want the performance in these three APIs can be same.\r\n\r\n**Standalone code to reproduce the issue**\r\n***keras_model_2ckpt.py***\r\n```\r\n# Transform .h5 to .ckpt\r\nimport numpy as np\r\nimport tensorflow as tf\r\nimport logging\r\nfrom tensorflow.python.ops import control_flow_ops\r\nimport os\r\nfrom tensorflow.python.framework.ops import disable_eager_execution\r\n\r\ndisable_eager_execution()\r\n\r\ndef build_model(name, random_bn_params=None):\r\n    '''\r\n    bild model by name\r\n    '''\r\n    tf.keras.backend.set_learning_phase(True)\r\n    if name == \"ResNet50\":\r\n        model = tf.keras.applications.ResNet50(\r\n            input_shape=(224, 224, 3),\r\n            pooling=\"avg\")\r\n    elif name == \"MobileNetV2\":\r\n        model = tf.keras.applications.MobileNetV2(\r\n            input_shape=(224, 224, 3),\r\n            alpha = 0.35,\r\n            pooling=\"avg\")\r\n    elif name == \"VGG16\":\r\n        model = tf.keras.applications.VGG16(\r\n            input_shape=(224, 224, 3),\r\n            pooling=\"avg\")\r\n    return model\r\n\r\nmodel = build_model(\"MobileNetV2\")\r\nmodel_dict ={\"mobile\":model}\r\n\r\n#transform h5 file to ckpt\r\nos.makedir(\"ckpt_model\")\r\nfor name in model_dict:    \r\n    image = tf.compat.v1.placeholder(tf.float32, [None, 224, 224, 3])    \r\n    global_step = tf.compat.v1.train.get_or_create_global_step()    \r\n    prediction = model_dict[name](image)\r\n    sess = tf.compat.v1.keras.backend.get_session()\r\n    sess.run(tf.compat.v1.variables_initializer([global_step]))\r\n    saver = tf.compat.v1.train.Saver()\r\n    save_path = saver.save(sess, \"ckpt_model/%s.ckpt\" % name)\r\n```\r\n\r\n***eager_train.py***\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\nimport logging\r\nfrom tensorflow.python.ops import control_flow_ops\r\nimport os\r\n\r\ndef build_model(name, random_bn_params=None):\r\n    tf.keras.backend.set_learning_phase(True)\r\n    if name == \"ResNet50\":\r\n        model = tf.keras.applications.ResNet50(\r\n            input_shape=(224, 224, 3),\r\n            pooling=\"avg\")\r\n    elif name == \"MobileNetV2\":\r\n        model = tf.keras.applications.MobileNetV2(\r\n            input_shape=(224, 224, 3),\r\n            alpha = 0.35,\r\n            pooling=\"avg\")\r\n    elif name == \"VGG16\":\r\n        model = tf.keras.applications.VGG16(\r\n            input_shape=(224, 224, 3),\r\n            pooling=\"avg\")\r\n    return model\r\n\r\n\r\nmodel = build_model(\"MobileNetV2\")\r\nfor lay in model.layers:\r\n    lay.trainable=True\r\n\r\nimg = 1.0*np.ones(shape=(1,224, 224,3))\r\nlabel = np.array([1])\r\n\r\nb = (img, label)\r\n\r\ndef data_provider(repeat):\r\n    return tf.data.Dataset.from_tensors(b).repeat(repeat)\r\n\r\n\r\nfeature = tf.constant(img)\r\noptimizer = tf.keras.optimizers.SGD(learning_rate=1e-4)\r\nfor index in range(10):\r\n    with tf.GradientTape() as t:\r\n        logits = model(feature)       \r\n\r\n        loss_value  = tf.keras.losses.sparse_categorical_crossentropy(tf.constant(label), logits)\r\n        grads = t.gradient(loss_value, model.trainable_variables)\r\n        optimizer.apply_gradients(zip(grads, model.trainable_variables))\r\n        print(loss_value)\r\n```\r\n\r\n***keras_fit_train.py***\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\nimport logging\r\nfrom tensorflow.python.ops import control_flow_ops\r\nimport os\r\n\r\ndef build_model(name, random_bn_params=None):\r\n    tf.keras.backend.set_learning_phase(True)\r\n    if name == \"ResNet50\":\r\n        model = tf.keras.applications.ResNet50(\r\n            input_shape=(224, 224, 3),\r\n            pooling=\"avg\")\r\n    elif name == \"MobileNetV2\":\r\n        model = tf.keras.applications.MobileNetV2(\r\n            input_shape=(224, 224, 3),\r\n            alpha = 0.35,\r\n            pooling=\"avg\")\r\n    elif name == \"VGG16\":\r\n        model = tf.keras.applications.VGG16(\r\n            input_shape=(224, 224, 3),\r\n            pooling=\"avg\")\r\n    return model\r\n\r\n\r\nmodel = build_model(\"MobileNetV2\")\r\nfor lay in model.layers:\r\n    lay.trainable=True\r\n\r\nimg = 1.0*np.ones(shape=(1,224, 224,3))\r\nlabel = np.array([1])\r\nmodel.compile(optimizer=tf.keras.optimizers.SGD(1e-4),\r\n              loss='sparse_categorical_crossentropy',\r\n              metrics=['accuracy'])\r\n\r\nb = (img, label)\r\n\r\ndef data_provider(repeat):\r\n    return tf.data.Dataset.from_tensors(b).repeat(repeat)\r\nmodel.fit_generator(data_provider(1),\r\n          epochs=10,\r\n          validation_data=data_provider(1),\r\n          shuffle=True)\r\n\r\n```\r\n\r\n***estimator_train.py***\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\nimport logging\r\nfrom tensorflow.python.ops import control_flow_ops\r\nimport os\r\nLOGGER = logging.getLogger(\"tensorflow\")\r\nLOGGER.setLevel(logging.INFO)\r\ndef build_model(name, random_bn_params=None):\r\n    tf.keras.backend.set_learning_phase(True)\r\n    if name == \"ResNet50\":\r\n        model = tf.keras.applications.ResNet50(\r\n            input_shape=(224, 224, 3),\r\n            pooling=\"avg\")\r\n    elif name == \"MobileNetV2\":\r\n        model = tf.keras.applications.MobileNetV2(\r\n            input_shape=(224, 224, 3),\r\n            alpha = 0.35,\r\n            pooling=\"avg\")\r\n    elif name == \"VGG16\":\r\n        model = tf.keras.applications.VGG16(\r\n            input_shape=(224, 224, 3),\r\n            pooling=\"avg\")\r\n    return model\r\ndef _init_variables_from_checkpoint(checkpoint_path, model_dir):\r\n    flags_checkpoint_path = checkpoint_path\r\n    # Warn the user if a checkpoint exists in the model_dir. Then ignore.\r\n    if tf.compat.v1.train.latest_checkpoint(model_dir):\r\n        LOGGER.info(\r\n            \"Ignoring model_init_name because a checkpoint already exists in %s.\" % model_dir)\r\n        return None\r\n    if flags_checkpoint_path is \"\":\r\n        return None\r\n\r\n    # Gather all trainable variables to initialize.\r\n    variables_to_init = tf.compat.v1.trainable_variables()\r\n    addition_variables_to_init = [v for v in tf.compat.v1.all_variables() if\r\n                      \"moving_mean\" in v.name or \"moving_variance\" in v.name]\r\n    variables_to_init.extend(addition_variables_to_init)\r\n\r\n    variables_to_init_dict = {var.name.rsplit(\":\", 1)[0]: var for var in variables_to_init}\r\n\r\n    if tf.compat.v1.gfile.IsDirectory(flags_checkpoint_path):\r\n        checkpoint_path = tf.compat.v1.train.latest_checkpoint(flags_checkpoint_path)\r\n    else:\r\n        checkpoint_path = flags_checkpoint_path\r\n\r\n    LOGGER.info(\"Fine-tuning from %s.\" % checkpoint_path)\r\n\r\n    # Gather all available variables to initialize.\r\n    available_var_map = _get_variables_available_in_checkpoint(variables_to_init_dict,\r\n                                                               checkpoint_path)\r\n\r\n    init_op = tf.compat.v1.train.init_from_checkpoint(checkpoint_path, available_var_map)\r\n    LOGGER.info(\"%d/%d variables in checkpoint has been restored.\" % (len(available_var_map),\r\n                                                                      len(variables_to_init)))\r\n\r\n    return tf.compat.v1.train.Scaffold(init_op=init_op)\r\n\r\n\r\ndef _get_variables_available_in_checkpoint(variables,\r\n                                           checkpoint_path,\r\n                                           include_global_step=False):\r\n    \"\"\"Returns the subset of variables in the checkpoint.\r\n\r\n    Inspects given checkpoint and returns the subset of variables that are\r\n    available in it.\r\n\r\n    Args:\r\n        variables: A dictionary of variables to find in checkpoint.\r\n        checkpoint_path: Path to the checkpoint to restore variables from.\r\n        include_global_step: Whether to include `global_step` variable, if it\r\n            exists. Default True.\r\n\r\n    Returns:\r\n        A dictionary of variables.\r\n\r\n    Raises:\r\n        ValueError: If `variables` is not a dict.\r\n    \"\"\"\r\n    if not isinstance(variables, dict):\r\n        raise ValueError(\"`variables` is expected to be a dict.\")\r\n\r\n    # Available variables\r\n    ckpt_reader = tf.compat.v1.train.NewCheckpointReader(checkpoint_path)\r\n    ckpt_vars_to_shape_map = ckpt_reader.get_variable_to_shape_map()\r\n    if not include_global_step:\r\n        ckpt_vars_to_shape_map.pop(tf.compat.v1.GraphKeys.GLOBAL_STEP, None)\r\n    vars_in_ckpt = {}\r\n\r\n    # for key in ckpt_vars_to_shape_map:\r\n    #     LOGGER.info(\"Available variable name: %s\", key)\r\n\r\n    for variable_name, variable in sorted(variables.items()):\r\n        if variable_name in ckpt_vars_to_shape_map:\r\n            if ckpt_vars_to_shape_map[variable_name] == variable.shape.as_list():\r\n                vars_in_ckpt[variable_name] = variable\r\n            else:\r\n                LOGGER.warning(\"Variable [%s] is available in checkpoint, but has an incompatible \"\r\n                               \"shape with model variable. Checkpoint shape: [%s], model variable \"\r\n                               \"shape: [%s]. This variable will not be initialized from the \"\r\n                               \"checkpoint.\",\r\n                               variable_name,\r\n                               ckpt_vars_to_shape_map[variable_name],\r\n                               variable.shape.as_list())\r\n        else:\r\n            LOGGER.warning(\"Variable [%s] is not available in checkpoint\", variable_name)\r\n    return vars_in_ckpt\r\n\r\ndef model_fn(features, labels, mode):\r\n    # Set Keras learning phase for alter BatchNorm and Dropout performance.\r\n    tf.keras.backend.set_learning_phase(mode == tf.estimator.ModeKeys.TRAIN)\r\n\r\n    m = build_model(\"MobileNetV2\")\r\n    predictions = m(features)\r\n    global_step = tf.compat.v1.train.get_or_create_global_step()\r\n    \r\n    scaffold = None\r\n   # if MODEL_NAME in {\"ResNet50\", \"VGG16\", \"MobileNetV2_1.0\"}:\r\n    scaffold = _init_variables_from_checkpoint(\"./ckpt_model/moiblenet.ckpt\", '.')\r\n    loss_value  = tf.keras.losses.sparse_categorical_crossentropy(labels, predictions)\r\n    optimizer =tf.keras.optimizers.SGD(learning_rate=1e-4)\r\n    update_ops = m.get_updates_for(features)\r\n    optimizer.iterations = global_step\r\n    train_op = optimizer.get_updates(loss_value, m.trainable_variables)\r\n    train_op = control_flow_ops.group(train_op, *update_ops)\r\n\r\n\r\n    # Create estimator_spec for Estimator.\r\n    estimator_spec = tf.estimator.EstimatorSpec(\r\n        mode=mode,\r\n        predictions=predictions,\r\n        loss = loss_value,\r\n        train_op = train_op\r\n#         scaffold = scaffold\r\n    )\r\n    return estimator_spec\r\n\r\n\r\nestimator_config = tf.estimator.RunConfig(\r\n  \r\n    keep_checkpoint_max=1,\r\n    save_summary_steps=1,\r\n    log_step_count_steps =1\r\n\r\n)\r\n\r\nimg = 1.0*np.ones(shape=(1,224, 224,3))\r\nlabel = np.array([1])\r\n\r\nb = (img, label)\r\n\r\ndef data_provider(repeat):\r\n    return tf.data.Dataset.from_tensors(b).repeat(repeat)\r\n\r\nestimator_handmake = tf.estimator.Estimator(model_fn=model_fn, config= estimator_config)\r\n\r\nestimator_handmake.train(input_fn=lambda: data_provider(10), steps =10)\r\n```\r\n", "comments": ["@mysephi \r\n\r\nWhen i tried to execute the estimator_train.py in colab with TF 2.2 i am seeing the below error message.`NotFoundError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for ./ckpt_model/moiblenet.ckpt`.Request you to share colab link or simple standalone code to reproduce the issue in our environment. It helps us in localizing the issue faster.Thanks!\r\n", "> @mysephi\r\n> \r\n> When i tried to execute the estimator_train.py in colab with TF 2.2 i am seeing the below error message.`NotFoundError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for ./ckpt_model/moiblenet.ckpt`.Request you to share colab link or simple standalone code to reproduce the issue in our environment. It helps us in localizing the issue faster.Thanks!\r\n\r\nSorry for the code error. Just change \"./ckpt_model/moiblenet.ckpt\" to \"./ckpt_model/mobile.ckpt\".", "@mysephi \r\n\r\nI tried in colab with TF version 2.2.Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/e6f971968d82490f3aaa5ed560a5f4b5/untitled901.ipynb).Is this the expected behavior? Thanks!", "> @mysephi\r\n> \r\n> I tried in colab with TF version 2.2.Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/e6f971968d82490f3aaa5ed560a5f4b5/untitled901.ipynb).Is this the expected behavior? Thanks!\r\n\r\nI think there is a little different.\r\nFirst, the result in eager_train.py should return EagerTensor instead of Tensor.\r\nSecond, I rerun these codes on both RTX2080Ti and GTX1060. \r\n\r\n- In GTX1060, it gives the result as you showed. The first loss in three train method are same. And the second one varies in same range.\r\n- In RTX2080Ti, it gives the result as I showed you. The results ranges differently. The second loss is different from that in GTX1060.\r\n\r\nI think maybe the performance difference is caused by CUDA or GPU.", "@mysephi,\r\nSorry for the delayed response. Can you please let us know if this performance issue is still relevant as we predominantly use TF Keras and doesn't use Estimators? Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 39578, "title": "Problem with layer generation under the functional API", "body": "Hi there, I am having problems with the functional API.\r\n\r\n - OS: Mac OS Catalina 10.15.4\r\n - Python-Version: 3.7.4\r\n - Tensorflow-Version: 2.1.0\r\n\r\nWhen I run the example for the functional API here (https://www.tensorflow.org/guide/keras/functional)\r\n\r\nwith this code snippet:\r\nimport numpy as np\r\n\r\nimport tensorflow as tf\r\n\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras import layers\r\n\r\ntf.keras.backend.clear_session()\r\ninputs = keras.Input(shape=(784,))\r\ndense = layers.Dense(64, activation='relu')\r\nx = dense(inputs)\r\n\r\nI get the following error:\r\n\r\nAttributeError: 'google.protobuf.pyext._message.RepeatedCompositeCo' object has no attribute 'append'\r\n\r\nI do not know how to handle this error, can you help?\r\n\r\nThis is how the whole error output looks like:\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-4-c3d73338788b> in <module>\r\n      9 inputs = keras.Input(shape=(784,))\r\n     10 dense = layers.Dense(64, activation='relu')\r\n---> 11 x = dense(inputs)\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py in __call__(self, inputs, *args, **kwargs)\r\n    746           # Build layer if applicable (if the `build` method has been\r\n    747           # overridden).\r\n--> 748           self._maybe_build(inputs)\r\n    749           cast_inputs = self._maybe_cast_inputs(inputs)\r\n    750 \r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py in _maybe_build(self, inputs)\r\n   2114         # operations.\r\n   2115         with tf_utils.maybe_init_scope(self):\r\n-> 2116           self.build(input_shapes)\r\n   2117       # We must set self.built since user defined build functions are not\r\n   2118       # constrained to set self.built.\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/layers/core.py in build(self, input_shape)\r\n   1111         constraint=self.kernel_constraint,\r\n   1112         dtype=self.dtype,\r\n-> 1113         trainable=True)\r\n   1114     if self.use_bias:\r\n   1115       self.bias = self.add_weight(\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py in add_weight(self, name, shape, dtype, initializer, regularizer, trainable, constraint, partitioner, use_resource, synchronization, aggregation, **kwargs)\r\n    444         synchronization=synchronization,\r\n    445         aggregation=aggregation,\r\n--> 446         caching_device=caching_device)\r\n    447     backend.track_variable(variable)\r\n    448 \r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/base.py in _add_variable_with_custom_getter(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\r\n    742         dtype=dtype,\r\n    743         initializer=initializer,\r\n--> 744         **kwargs_for_getter)\r\n    745 \r\n    746     # If we set an initializer and the variable processed it, tracking will not\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py in make_variable(name, shape, dtype, initializer, trainable, caching_device, validate_shape, constraint, use_resource, collections, synchronization, aggregation, partitioner)\r\n    140       synchronization=synchronization,\r\n    141       aggregation=aggregation,\r\n--> 142       shape=variable_shape if variable_shape else None)\r\n    143 \r\n    144 \r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/variables.py in __call__(cls, *args, **kwargs)\r\n    256   def __call__(cls, *args, **kwargs):\r\n    257     if cls is VariableV1:\r\n--> 258       return cls._variable_v1_call(*args, **kwargs)\r\n    259     elif cls is Variable:\r\n    260       return cls._variable_v2_call(*args, **kwargs)\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/variables.py in _variable_v1_call(cls, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, use_resource, synchronization, aggregation, shape)\r\n    217         synchronization=synchronization,\r\n    218         aggregation=aggregation,\r\n--> 219         shape=shape)\r\n    220 \r\n    221   def _variable_v2_call(cls,\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/variables.py in <lambda>(**kwargs)\r\n    195                         shape=None):\r\n    196     \"\"\"Call on Variable class. Useful to force the signature.\"\"\"\r\n--> 197     previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\r\n    198     for _, getter in ops.get_default_graph()._variable_creator_stack:  # pylint: disable=protected-access\r\n    199       previous_getter = _make_getter(getter, previous_getter)\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/variable_scope.py in default_variable_creator(next_creator, **kwargs)\r\n   2594         synchronization=synchronization,\r\n   2595         aggregation=aggregation,\r\n-> 2596         shape=shape)\r\n   2597   else:\r\n   2598     return variables.RefVariable(\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/variables.py in __call__(cls, *args, **kwargs)\r\n    260       return cls._variable_v2_call(*args, **kwargs)\r\n    261     else:\r\n--> 262       return super(VariableMetaclass, cls).__call__(*args, **kwargs)\r\n    263 \r\n    264 \r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py in __init__(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)\r\n   1409           aggregation=aggregation,\r\n   1410           shape=shape,\r\n-> 1411           distribute_strategy=distribute_strategy)\r\n   1412 \r\n   1413   def _init_from_args(self,\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py in _init_from_args(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape)\r\n   1555               shared_name=shared_name,\r\n   1556               name=name,\r\n-> 1557               graph_mode=self._in_graph_mode)\r\n   1558         # pylint: disable=protected-access\r\n   1559         if (self._in_graph_mode and initial_value is not None and\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py in eager_safe_variable_handle(initial_value, shape, shared_name, name, graph_mode)\r\n    230   dtype = initial_value.dtype.base_dtype\r\n    231   return _variable_handle_from_shape_and_dtype(\r\n--> 232       shape, dtype, shared_name, name, graph_mode, initial_value)\r\n    233 \r\n    234 \r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py in _variable_handle_from_shape_and_dtype(shape, dtype, shared_name, name, graph_mode, initial_value)\r\n    166     handle_data = cpp_shape_inference_pb2.CppShapeInferenceResult.HandleData()\r\n    167     handle_data.is_set = True\r\n--> 168     handle_data.shape_and_type.append(\r\n    169         cpp_shape_inference_pb2.CppShapeInferenceResult.HandleShapeAndType(\r\n    170             shape=shape.as_proto(), dtype=dtype.as_datatype_enum))\r\n\r\nAttributeError: 'google.protobuf.pyext._message.RepeatedCompositeCo' object has no attribute 'append'\r\n\r\ntf.__version__\r\n\r\n'2.1.0'\r\n\r\n\r\n", "comments": ["@RalfKellner,\r\nI was able to run both the tutorial and the sample code you have given, without any issues. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/8cdceee5e89d9790f9a668fddc7c84af/39578-2-2.ipynb). \r\nCould you please check if you are facing the same issue in a virtual environment. Thanks!", "Also, please take a look at [this comment](https://github.com/tensorflow/tensorflow/issues/33348#issuecomment-541915323) from a similar issue and let us know if it helps. Thanks!", "Alright, I tried to run it in a new virtual environment and it works. So the problem is maybe related to something else. Thank you very much, I will just use the virutal environment which is probably better anyway!"]}, {"number": 39577, "title": "CUDNN v8 support", "body": "Enables building against the CUDNN v8 library.\r\n\r\nAttn: @reedwm \r\n\r\nNote this PR can be applied separately from the cuda 11 PR (39576), but both modify find_cuda_config.py. As a result, they will conflcit on find_cuda_config.py.gz.base64 and that file will need to be regenerated via compress_find_cuda_config.py when the second PR is merged.", "comments": ["Hi Nathan, thank you very much for this PR. I'm going to temporarily mark it as 'ready to pull'. This will simplify testing it on our side and merging it.", "@nluehr can you please resolve conflicts ?", "> @nluehr can you please resolve conflicts ?\r\n\r\nHi Nathan, you don't need to resolve, it's easier to merge this manually from our side and I'm actively working on that. The CUDA 11 changes have been merged already, and hopefully this one will land until Monday as well. There was some trouble with compiler commands going over the Windows character limit and unrelated breakages.\r\n\r\nI'm removing the 'ready to pull' tag again so the automated tools don't try to submit it as well.", "What was the reason for not using `WINOGRAD_NONFUSED` algorithms?", "> What was the reason for not using WINOGRAD_NONFUSED algorithms?\r\n\r\nJust leaving a comment here so that future visitors can get the answer to the above quesiton.\r\n\r\nhttps://forums.developer.nvidia.com/t/variations-in-heuristics-for-selecting-conv-algorithm-in-different-apis/139730/2", "The reason was just to match the behavior with cudnn v7."]}, {"number": 39576, "title": "Enable build with CUDA 11", "body": "Attn: @reedwm This enables building TensorFlow against the upcoming CUDA 11.0 toolkit.", "comments": ["Hi Nathan, thank you very much for this PR. I'm going to temporarily mark it as 'ready to pull'. This will simplify testing it on our side and merging it.", "Adding the kokoro tag to run all presubmits on GitHub too."]}, {"number": 39575, "title": "get_tensor CheckpointReader_GetTensor error", "body": "\r\n**System information**\r\n- OS Platform and Distribution :win 10\r\n- OS -V:1903\r\n- TensorFlow installed from (source or binary):binary\r\n- TensorFlow version:TensorFlow-gpu==2.0.0\r\n- Python version:3.6.5\r\n- Installed using virtualenv? pip? conda?:pip\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:cuda:10.0.130 cudnn:7.6.5\r\n-nvidia driver :445.87\r\n- GPU model and memory:2070super 8G      64G Ram\r\n\r\nThe phenomenon that I encountered was this\r\n```\r\nfrom tensorflow.python import pywrap_tensorflow\r\nmodel_reader = pywrap_tensorflow.NewCheckpointReader(r\"E:\\dl_model\\chinese_L-12_H-768_A-12\\bert_model.ckpt\")\r\nvar_dict = model_reader.get_variable_to_shape_map()\r\nfor key in var_dict:\r\n    print(\"variable name: \", key)\r\n    print(model_reader.get_tensor(key))\r\n```\r\nI run this code.\r\nide print\r\n```\r\nC:\\public\\study\\python\\python.exe C:/public/study/work/test/test.py\r\n2020-05-15 20:18:56.028434: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll\r\nvariable name:  bert/encoder/layer_0/output/dense/kernel\r\n\r\nProcess finished with exit code -1073741819 (0xC0000005)\r\n```\r\nThe code runs to\r\n```\r\nget_tensor\r\n\r\nreturn CheckpointReader_GetTensor(self, compat.as_bytes(tensor_str))\r\n```\r\nWhen compat.as_bytes(tensor_str) get result.\r\nI click step into.\r\nThe ide shows the code running for a while.\r\nAnd then,print\r\n`Process finished with exit code -1073741819 (0xC0000005).`\r\n\r\nI try 3 models to read.They have the same result. I think it is not model cause question.\r\nI try to delete cuda ,cudnn,nvidia driver.Install other version.\r\nFrom 10.1.243/7.6.5  10.1.243/7.6.4 10.1.168/7.6.5 10.2.89/7.6.5 10.0.130/7.6.5 10.0.130/7.4.2\r\nI install Visual Studio 2015/2017/2019 not include many plug-ins.\r\nI install conda(python3.7) try to install tensorflow-gpu==2.0.0.\r\n\r\nI don't know what causes this question.\r\nMaybe it's my gpu environment,computer environment,maybe other.\r\n\r\nMy understanding of the problem is that python calls c.\r\nSo many people have no problem, so the probability is not a problem of the code.\r\nAlthough I know about the installation environment, I shouldn't be looking for you on github.\r\nBut I really tried what I thought, what I found on the Internet, and it still hasn't been solved.\r\nI hope you can help me, even if only in some directions.\r\nIf you need any other information, please tell me \r\n\r\n\r\n\r\n", "comments": ["@luoqishuai \r\nCan you please share simple stand alone code for us to replicate this along with the error logs for us to analyse, or if possible share a colab gist with error for us to analyse and help you.", "> \r\n> \r\n> @luoqishuai\r\n> Can you please share simple stand alone code for us to replicate this along with the error logs for us to analyse, or if possible share a colab gist with error for us to analyse and help you.\r\n\r\nIn fact, This is the code in question.At get_tensor ,ide print `Process finished with exit code -1073741819 (0xC0000005)`\r\n```\r\nfrom tensorflow.python import pywrap_tensorflow\r\nmodel_reader = pywrap_tensorflow.NewCheckpointReader(r\"E:\\dl_model\\chinese_L-12_H-768_A-12\\bert_model.ckpt\")\r\nvar_dict = model_reader.get_variable_to_shape_map()\r\nfor key in var_dict:\r\n    print(\"variable name: \", key)\r\n    print(model_reader.get_tensor(key))\r\n```\r\n\r\nI debug it.\r\nIt is exit at pywrap_tensorflow_internal.py 915  :\r\nCheckpointReader_GetTensor(self, compat.as_bytes(tensor_str))\r\nIt not raise Exception by python .", "bert_model.ckpt is download by \r\nhttps://storage.googleapis.com/bert_models/2018_11_03/chinese_L-12_H-768_A-12.zip", "I can try anything to give you the information you want, except to smash the computer.", "When i in pywrap_tensorflow_internal.py CheckpointReader_GetTensor .\r\nI cant click CheckpointReader_GetTensor.\r\nThere is a picture \r\nhttps://sm.ms/image/RjDNG8nLaQWfYsb\r\n\r\n```\r\ntf.test.is_built_with_cuda()\r\ntf.test.is_gpu_available()\r\ntf.test.is_built_with_gpu_support()\r\n```\r\nAll return True\r\nMy vs2017 can import cuda10.\r\nIs there anything else that might cause me to not be able to run **get_tensor** method?\r\nI'm going to try everything\r\n", "@Saduf2019", "I can't \r\n`use _pywrap_tensorflow_internal.pyd `\r\n`CheckpointReader_GetTensor `\r\nto get tensor", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39575\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39575\">No</a>\n"]}, {"number": 39574, "title": "Training produces Out Of Memory error with TF 2.* but works with TF 1.14", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.4 LTS\r\n- TensorFlow installed from (source or binary): pip 20.1\r\n- TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b 2.2.0\r\n- Python version: Python 3.7.7\r\n- GCC/Compiler version (if compiling from source): gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\r\n- CUDA/cuDNN version: Cuda compilation tools, release 10.0, V10.0.130\r\n- GPU model and memory: Nvidia K80 12GB (AWS p2.xlarge Deep Learning AMI (Ubuntu 18.04) Version 28.1)\r\n\r\n\r\n**Describe the current behavior**\r\nTraining a simple model on a data set:\r\n    X shape: (35000, 200, 311)\r\n    y shape: (35000, 200, 19)\r\nRight before the start of the first epoch, when using TF 2.2.0 the training stops with an error:\r\n`tensorflow.python.framework.errors_impl.InternalError: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run GatherV2: Dst tensor is not initialized. [Op:GatherV2]`\r\n(abbreviated for readability and because this error seems to point to Out Of Memory issues indirectly)\r\n(also because the code example below can reproduce the error message)\r\n\r\nInterestingly: The exact same setup, model and training set trains well on TF 1.14\r\n\r\nNOTES:\r\n* I've tried changing the batch size (down to 1) to no avail.\r\n* Decreasing Training Set to ~10,000 test cases works fine.\r\n* Error also occurs on freshly re-started instances.\r\n* `allow_growth` option didn't make a difference.\r\n* GPU memory is being used by training (confirmed by looking at GPU usage and by showing found GPU devices)\r\n\r\n**Describe the expected behavior**\r\nTraining above model runs as expected and does not error out.\r\n\r\n**Standalone code to reproduce the issue**\r\nThe [colab link](https://colab.research.google.com/drive/1IWzCIljUTBNfmtsP1Sefu6usrhMp4pGL?usp=sharing) can be executed, but if not run on the specified hardware, it wouldn't make sense to test this way.\r\n\r\nBest to reproduce is running following code on the described setup with TF 1.14 and TF 2.2.0\r\n```\r\nimport json\r\nimport numpy as np\r\nfrom tensorflow.keras.layers import GRU, Bidirectional, Dense, Masking, Input, TimeDistributed\r\nfrom tensorflow.keras.models import Sequential\r\nfrom tensorflow.keras.callbacks import ModelCheckpoint\r\nfrom tensorflow.keras.utils import to_categorical\r\n\r\ny_raw = np.random.randint(19, size=(35000,200))\r\ny = to_categorical(y_raw, num_classes=19)\r\nX = np.random.rand(35000, 200, 311)\r\n\r\nmodel = Sequential()\r\nmodel.add(Masking(mask_value=0.0, input_shape=(200,311)))\r\nmodel.add(\r\n            Bidirectional(\r\n                        GRU(\r\n                            256,\r\n                            return_sequences=True,\r\n                            unroll=True,\r\n                            recurrent_dropout=0.233,\r\n                            recurrent_activation=\"sigmoid\"\r\n                           )\r\n                         )\r\n         )\r\n\r\nmodel.add(TimeDistributed(Dense(19, activation=\"softmax\")))\r\n\r\nmodel.compile(\r\n            loss=\"categorical_crossentropy\",\r\n            optimizer=\"rmsprop\",\r\n            metrics=[\"categorical_accuracy\"],\r\n            )\r\n\r\nmodel.summary()\r\n\r\narchitecture_path = \"candidate_architecture.json\"\r\nmodel_json = model.to_json()\r\nwith open(architecture_path, 'w') as json_file:\r\n    json_file.write(model_json)\r\nprint(f\"Saved model architecture to {architecture_path}\")\r\n\r\nfilepath = \"candidate_model-{epoch:02d}-{val_categorical_accuracy:.4f}.h5\"\r\ncheckpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min', save_weights_only=True)\r\ncallbacks_list = [checkpoint]\r\n\r\nhistory = model.fit(X, y, epochs=10,\r\n                    validation_split=0.2,\r\n                    batch_size=16,\r\n                    callbacks=callbacks_list)\r\n```\r\n\r\n**Other info / logs** \r\nFull traceback of error:\r\n\r\n```\r\n2020-05-14 07:16:34.619007: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\r\n2020-05-14 07:16:34.652784: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-05-14 07:16:34.653592: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties:\r\npciBusID: 0000:00:1e.0 name: Tesla K80 computeCapability: 3.7\r\ncoreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\r\n2020-05-14 07:16:34.653944: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\r\n2020-05-14 07:16:34.656389: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\r\n2020-05-14 07:16:34.658467: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\r\n2020-05-14 07:16:34.658882: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\r\n2020-05-14 07:16:34.661237: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\r\n2020-05-14 07:16:34.662515: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\r\n2020-05-14 07:16:34.666590: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2020-05-14 07:16:34.666743: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-05-14 07:16:34.667562: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-05-14 07:16:34.668297: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\r\n2020-05-14 07:17:53.690634: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2020-05-14 07:17:53.714191: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2300050000 Hz\r\n2020-05-14 07:17:53.714472: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f3970000b20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-05-14 07:17:53.714508: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2020-05-14 07:17:53.816549: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-05-14 07:17:53.817400: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x555a5231f6d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\r\n2020-05-14 07:17:53.817432: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\r\n2020-05-14 07:17:53.817690: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-05-14 07:17:53.818466: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties:\r\npciBusID: 0000:00:1e.0 name: Tesla K80 computeCapability: 3.7\r\ncoreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\r\n2020-05-14 07:17:53.818528: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\r\n2020-05-14 07:17:53.818570: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\r\n2020-05-14 07:17:53.818598: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\r\n2020-05-14 07:17:53.818625: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\r\n2020-05-14 07:17:53.818677: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\r\n2020-05-14 07:17:53.818722: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\r\n2020-05-14 07:17:53.818752: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2020-05-14 07:17:53.818859: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-05-14 07:17:53.819637: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-05-14 07:17:53.820344: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\r\n2020-05-14 07:17:53.820395: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\r\n2020-05-14 07:17:53.822110: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-05-14 07:17:53.822137: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0\r\n2020-05-14 07:17:53.822153: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N\r\n2020-05-14 07:17:53.822277: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-05-14 07:17:53.823052: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-05-14 07:17:53.823792: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10691 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7)\r\nWARNING:tensorflow:Layer gru will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\r\nWARNING:tensorflow:Layer gru will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\r\nWARNING:tensorflow:Layer gru will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\r\nLabel count: 19\r\nModel defined.\r\nModel: \"sequential\"\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #\r\n=================================================================\r\nmasking (Masking)            (None, 200, 311)          0\r\n_________________________________________________________________\r\nbidirectional (Bidirectional (None, 200, 512)          873984\r\n_________________________________________________________________\r\ntime_distributed (TimeDistri (None, 200, 19)           9747\r\n=================================================================\r\nTotal params: 883,731\r\nTrainable params: 883,731\r\nNon-trainable params: 0\r\n_________________________________________________________________\r\nNone\r\nSaved model architecture to candidate_architecture.json\r\n2020-05-14 07:18:19.476160: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 14639392000 exceeds 10% of free system memory.\r\n2020-05-14 07:18:40.240359: W tensorflow/core/common_runtime/bfc_allocator.cc:434] Allocator (GPU_0_bfc) ran out of memory trying to allocate 13.63GiB (rounded to 14639392000)\r\nCurrent allocation summary follows.\r\n2020-05-14 07:18:40.243374: I tensorflow/core/common_runtime/bfc_allocator.cc:934] BFCAllocator dump for GPU_0_bfc\r\n2020-05-14 07:18:40.243393: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (256):   Total Chunks: 11, Chunks in use: 11. 2.8KiB allocated for chunks. 2.8KiB in use in bin. 116B client-requested in use in bin.\r\n2020-05-14 07:18:40.243409: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (512):   Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2020-05-14 07:18:40.243434: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (1024):  Total Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\r\n2020-05-14 07:18:40.243451: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (2048):  Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2020-05-14 07:18:40.243474: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (4096):  Total Chunks: 2, Chunks in use: 2. 12.0KiB allocated for chunks. 12.0KiB in use in bin. 12.0KiB client-requested in use in bin.\r\n2020-05-14 07:18:40.243496: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (8192):  Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2020-05-14 07:18:40.243568: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (16384):         Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2020-05-14 07:18:40.243595: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (32768):         Total Chunks: 3, Chunks in use: 1. 113.5KiB allocated for chunks. 38.0KiB in use in bin. 38.0KiB client-requested in use in bin.\r\n2020-05-14 07:18:40.243630: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (65536):         Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2020-05-14 07:18:40.243655: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (131072):        Total Chunks: 1, Chunks in use: 0. 130.0KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2020-05-14 07:18:40.243698: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (262144):        Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2020-05-14 07:18:40.243721: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (524288):        Total Chunks: 5, Chunks in use: 2. 4.07MiB allocated for chunks. 1.66MiB in use in bin. 1.50MiB client-requested in use in bin.\r\n2020-05-14 07:18:40.243756: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (1048576):       Total Chunks: 2, Chunks in use: 2. 2.68MiB allocated for chunks. 2.68MiB in use in bin. 1.82MiB client-requested in use in bin.\r\n2020-05-14 07:18:40.243773: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (2097152):       Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2020-05-14 07:18:40.243782: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (4194304):       Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2020-05-14 07:18:40.243792: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (8388608):       Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2020-05-14 07:18:40.243825: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (16777216):      Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2020-05-14 07:18:40.243841: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (33554432):      Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2020-05-14 07:18:40.243861: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (67108864):      Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2020-05-14 07:18:40.243893: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (134217728):     Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2020-05-14 07:18:40.243916: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (268435456):     Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2020-05-14 07:18:40.243934: I tensorflow/core/common_runtime/bfc_allocator.cc:957] Bin for 13.63GiB was 256.00MiB, Chunk State:\r\n2020-05-14 07:18:40.243949: I tensorflow/core/common_runtime/bfc_allocator.cc:970] Next region of size 1048576\r\n2020-05-14 07:18:40.243962: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 1203be0000 of size 1280 next 1\r\n2020-05-14 07:18:40.243976: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 1203be0500 of size 256 next 5\r\n2020-05-14 07:18:40.243983: I tensorflow/core/common_runtime/bfc_allocator.cc:990] Free  at 1203be0600 of size 1047040 next 18446744073709551615\r\n2020-05-14 07:18:40.243994: I tensorflow/core/common_runtime/bfc_allocator.cc:970] Next region of size 2097152\r\n2020-05-14 07:18:40.244014: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 1203ee0000 of size 256 next 3\r\n2020-05-14 07:18:40.244027: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 1203ee0100 of size 256 next 4\r\n2020-05-14 07:18:40.244039: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 1203ee0200 of size 256 next 10\r\n2020-05-14 07:18:40.244058: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 1203ee0300 of size 6144 next 14\r\n2020-05-14 07:18:40.244071: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 1203ee1b00 of size 6144 next 17\r\n2020-05-14 07:18:40.244086: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 1203ee3300 of size 256 next 20\r\n2020-05-14 07:18:40.244103: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 1203ee3400 of size 256 next 23\r\n2020-05-14 07:18:40.244121: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 1203ee3500 of size 256 next 24\r\n2020-05-14 07:18:40.244134: I tensorflow/core/common_runtime/bfc_allocator.cc:990] Free  at 1203ee3600 of size 38144 next 15\r\n2020-05-14 07:18:40.244151: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 1203eecb00 of size 256 next 18\r\n2020-05-14 07:18:40.244164: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 1203eecc00 of size 256 next 19\r\n2020-05-14 07:18:40.244171: I tensorflow/core/common_runtime/bfc_allocator.cc:990] Free  at 1203eecd00 of size 39168 next 21\r\n2020-05-14 07:18:40.244179: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 1203ef6600 of size 38912 next 22\r\n2020-05-14 07:18:40.244187: I tensorflow/core/common_runtime/bfc_allocator.cc:990] Free  at 1203effe00 of size 133120 next 11\r\n2020-05-14 07:18:40.244193: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 1203f20600 of size 256 next 13\r\n2020-05-14 07:18:40.244204: I tensorflow/core/common_runtime/bfc_allocator.cc:990] Free  at 1203f20700 of size 692224 next 6\r\n2020-05-14 07:18:40.244223: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 1203fc9700 of size 1140992 next 18446744073709551615\r\n2020-05-14 07:18:40.244240: I tensorflow/core/common_runtime/bfc_allocator.cc:970] Next region of size 4194304\r\n2020-05-14 07:18:40.244253: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 12040e0000 of size 256 next 8\r\n2020-05-14 07:18:40.244269: I tensorflow/core/common_runtime/bfc_allocator.cc:990] Free  at 12040e0100 of size 786432 next 9\r\n2020-05-14 07:18:40.244283: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 12041a0100 of size 786432 next 12\r\n2020-05-14 07:18:40.244297: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 1204260100 of size 955392 next 16\r\n2020-05-14 07:18:40.244315: I tensorflow/core/common_runtime/bfc_allocator.cc:990] InUse at 1204349500 of size 1665792 next 18446744073709551615\r\n2020-05-14 07:18:40.244332: I tensorflow/core/common_runtime/bfc_allocator.cc:995]      Summary of in-use Chunks by size:\r\n2020-05-14 07:18:40.244348: I tensorflow/core/common_runtime/bfc_allocator.cc:998] 11 Chunks of size 256 totalling 2.8KiB\r\n2020-05-14 07:18:40.244366: I tensorflow/core/common_runtime/bfc_allocator.cc:998] 1 Chunks of size 1280 totalling 1.2KiB\r\n2020-05-14 07:18:40.244380: I tensorflow/core/common_runtime/bfc_allocator.cc:998] 2 Chunks of size 6144 totalling 12.0KiB\r\n2020-05-14 07:18:40.244390: I tensorflow/core/common_runtime/bfc_allocator.cc:998] 1 Chunks of size 38912 totalling 38.0KiB\r\n2020-05-14 07:18:40.244397: I tensorflow/core/common_runtime/bfc_allocator.cc:998] 1 Chunks of size 786432 totalling 768.0KiB\r\n2020-05-14 07:18:40.244411: I tensorflow/core/common_runtime/bfc_allocator.cc:998] 1 Chunks of size 955392 totalling 933.0KiB\r\n2020-05-14 07:18:40.244418: I tensorflow/core/common_runtime/bfc_allocator.cc:998] 1 Chunks of size 1140992 totalling 1.09MiB\r\n2020-05-14 07:18:40.244433: I tensorflow/core/common_runtime/bfc_allocator.cc:998] 1 Chunks of size 1665792 totalling 1.59MiB\r\n2020-05-14 07:18:40.244447: I tensorflow/core/common_runtime/bfc_allocator.cc:1002] Sum Total of in-use chunks: 4.39MiB\r\n2020-05-14 07:18:40.244464: I tensorflow/core/common_runtime/bfc_allocator.cc:1004] total_region_allocated_bytes_: 7340032 memory_limit_: 11210358784 available bytes: 11203018752 curr_region_allocation_bytes_: 8388608\r\n2020-05-14 07:18:40.244482: I tensorflow/core/common_runtime/bfc_allocator.cc:1010] Stats:\r\nLimit:                 11210358784\r\nInUse:                     4603904\r\nMaxInUse:                  6655232\r\nNumAllocs:                      66\r\nMaxAllocSize:              1665792\r\n\r\n2020-05-14 07:18:40.244501: W tensorflow/core/common_runtime/bfc_allocator.cc:439] *_____________****_________**************x*__________***********************x**************xxxxxxxxx\r\nTraceback (most recent call last):\r\n  File \"modules/training-suite-controller/training-suite-controller/train_open_model.py\", line 108, in <module>\r\n    process(training_setup)\r\n  File \"modules/training-suite-controller/training-suite-controller/train_open_model.py\", line 85, in process\r\n    batch_size=training_setup['batch_size'], callbacks=callbacks_list)\r\n  File \"/home/ubuntu/.cache/pypoetry/virtualenvs/snapaddy-deep-learning-training-suite-YlZOSDlZ-py3.7/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\", line 66, in _method_wrapper\r\n    return method(self, *args, **kwargs)\r\n  File \"/home/ubuntu/.cache/pypoetry/virtualenvs/snapaddy-deep-learning-training-suite-YlZOSDlZ-py3.7/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\", line 797, in fit\r\n    shuffle=False))\r\n  File \"/home/ubuntu/.cache/pypoetry/virtualenvs/snapaddy-deep-learning-training-suite-YlZOSDlZ-py3.7/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 1338, in train_validation_split\r\n    functools.partial(_split, indices=train_indices), arrays)\r\n  File \"/home/ubuntu/.cache/pypoetry/virtualenvs/snapaddy-deep-learning-training-suite-YlZOSDlZ-py3.7/lib/python3.7/site-packages/tensorflow/python/util/nest.py\", line 617, in map_structure\r\n    structure[0], [func(*x) for x in entries],\r\n  File \"/home/ubuntu/.cache/pypoetry/virtualenvs/snapaddy-deep-learning-training-suite-YlZOSDlZ-py3.7/lib/python3.7/site-packages/tensorflow/python/util/nest.py\", line 617, in <listcomp>\r\n    structure[0], [func(*x) for x in entries],\r\n  File \"/home/ubuntu/.cache/pypoetry/virtualenvs/snapaddy-deep-learning-training-suite-YlZOSDlZ-py3.7/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 1335, in _split\r\n    return array_ops.gather_v2(t, indices)\r\n  File \"/home/ubuntu/.cache/pypoetry/virtualenvs/snapaddy-deep-learning-training-suite-YlZOSDlZ-py3.7/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\", line 180, in wrapper\r\n    return target(*args, **kwargs)\r\n  File \"/home/ubuntu/.cache/pypoetry/virtualenvs/snapaddy-deep-learning-training-suite-YlZOSDlZ-py3.7/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py\", line 4541, in gather_v2\r\n    batch_dims=batch_dims)\r\n  File \"/home/ubuntu/.cache/pypoetry/virtualenvs/snapaddy-deep-learning-training-suite-YlZOSDlZ-py3.7/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\", line 180, in wrapper\r\n    return target(*args, **kwargs)\r\n  File \"/home/ubuntu/.cache/pypoetry/virtualenvs/snapaddy-deep-learning-training-suite-YlZOSDlZ-py3.7/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py\", line 4524, in gather\r\n    return gen_array_ops.gather_v2(params, indices, axis, name=name)\r\n  File \"/home/ubuntu/.cache/pypoetry/virtualenvs/snapaddy-deep-learning-training-suite-YlZOSDlZ-py3.7/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3755, in gather_v2\r\n    _ops.raise_from_not_ok_status(e, name)\r\n  File \"/home/ubuntu/.cache/pypoetry/virtualenvs/snapaddy-deep-learning-training-suite-YlZOSDlZ-py3.7/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 6653, in raise_from_not_ok_status\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.InternalError: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run GatherV2: Dst tensor is not initialized. [Op:GatherV2]\r\n```\r\n", "comments": ["Can you compare behavior on 1.15, 2.0 and 2.1 too please?", "Thank you for your response.\r\n\r\nI'll compare this on 1.15, 2.0 and 2.1 aswell. I might just not be able to do it until next week.\r\n\r\nUntil then:\r\n* Does anyone know what could be the cause?\r\n* Can there be a workaround?\r\n* Why does the `allow_growth` option not work?", "I am also facing the issue of Out of memory. I am using tensorflow 2.0 and have enabled the allow_growth option.", "I have tried in colab with TF-GPU with version 1.15,2.0,2.1, 2.2 and was able to reproduce the issue.Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/c77f00df5a6e6046abda6c220f823470/untitled918.ipynb).Thanks!", "@ravikyram thank you for reproducing the problem!\r\n\r\nIf you need me to provide any further information to this, please don't hesitate to comment.", "Just tested the same procedure (with TF 1.15 and TF 2.2) on a larger AWS instance (p3.8xlarge with 4 GPUs).\r\nUsed a fix for memory distribution (https://github.com/tensorflow/tensorflow/issues/30321#issuecomment-508956878).\r\nEven in this setting, TF 1.15 worked well and TF2.2 produced the OOM error.\r\n\r\n@ravikyram Maybe this helps assessing the scope of the problem.", "@Philipduerholt  Did you update your cuda version to 10.1 when using TF 2.2?", "@ymodak No, the CUDA version is 10.0.130", "The example code crashes on google colab with TF version 1.14 as well as 2.2 on cpu/gpu runtime.", "Could reproduce the issue with **`Tensorflow Version 2.5`** and **`Tensorflow Nightly (2.6.0-dev20210602)`**. Please find [the Gist](https://colab.research.google.com/gist/rmothukuru/e8f1806d5162b6574b524ed364c67b11/untitled918.ipynb). Thanks!", "Keras's numpy support involves data copies and is not designed for performant processing of large numpy datasets. I suggest either using tf.data to construct your inputs directly, or give `from_numpy` from Tensorflow IO (to efficiently turn a numpy array into a tf.data dataset) a try: https://www.tensorflow.org/io/api_docs/python/tfio/experimental/IODataset#from_numpy", "Feel free to reopen if the above suggestion does not work for you."]}, {"number": 39573, "title": "Update SECURITY.md", "body": "simple error correction.\r\nI changed the lower case into capital letters.\r\n\r\n1. :first --> :First \r\n2. Tensorflow -->TensorFlow", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F39573) for more info**.\n\n<!-- need_sender_cla -->", "> @googlebot I signed it!\r\n\r\n", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F39573) for more info**.\n\n<!-- ok -->", "thanks."]}, {"number": 39572, "title": "The New Converter of Tensorflow 2.2.0 generate incorrect model output", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): windows/ubuntu\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (or github SHA if from source): 2.2.0\r\n\r\n\r\n**Command used to run the converter or code if you\u2019re using the Python API**\r\n\r\n\r\n``` python\r\nhttps://colab.research.google.com/drive/1uMiHGTFrj7R_rFcGJoje3Yfbap0sC9H-?usp=sharing\r\nimport tensorflow as tf\r\nimport numpy as np\r\nnp.set_printoptions(suppress=True)\r\n\r\nlength = 66\r\n\r\na = tf.constant(\r\n    np.random.rand(length,length).astype(np.float32),\r\n    shape=[length, length])\r\n\r\nc = [ tf.constant(\r\n    np.random.rand(length).astype(np.float32),\r\n    shape=[ length]) for i in range(0,3)]\r\n\r\n\r\n@tf.function\r\ndef func2(x ,c1, c2):\r\n    return  tf.multiply(x, c2) + c2\r\n\r\n@tf.function\r\ndef func(x):\r\n    return  func2(tf.nn.bias_add(tf.matmul(x,a) , c[0] ), c[1],  c[2])\r\n     \r\n\r\n\r\ninput =  np.random.rand(1,length).astype(np.float32)\r\noriginal_output = func(input).numpy()\r\n\r\nprint(\"Orginal:\")\r\nprint(original_output)\r\n\r\n\r\ndef save_and_test(experimental_new_converter , filename):\r\n\r\n    lite = tf.lite.TFLiteConverter.from_concrete_functions([func.get_concrete_function(x = tf.TensorSpec(shape=[None,length], dtype=tf.float32) )])\r\n    lite.experimental_new_converter  = experimental_new_converter\r\n    open(filename,\"wb\").write(lite.convert())\r\n\r\n    interpreter = tf.lite.Interpreter(model_path=filename)\r\n    interpreter.allocate_tensors()\r\n    interpreter.set_tensor(interpreter.get_input_details()[0]['index'], input)\r\n    interpreter.invoke()\r\n\r\n    print(filename, \":\")\r\n    output = interpreter.get_tensor(interpreter.get_output_details()[0]['index'])\r\n    print(output)\r\n    print(filename, \" sum of absolute difference: \", np.sum(np.absolute(original_output - output)))\r\n\r\n\r\nsave_and_test(True, \"mlir\")\r\nsave_and_test(False, \"toco\")\r\n```\r\n\r\n**The output from the converter invocation**\r\n\r\n``` \r\nOrginal:\r\n[[ 6.9496317   7.9791102   0.23810546  1.6724037   9.687994   11.553456\r\n   0.60509163  8.606714   17.731003    2.52809    16.075905    0.50299734\r\n   6.119868   12.388639    8.383967   11.989329    7.3116794   8.7486725\r\n   9.714089   12.450738    1.4212162   7.567941   14.836599    5.73806\r\n   8.028838    2.5774102   7.9609547  19.35534    11.474097    1.2807347\r\n   5.075203   17.249842    3.0866256  17.775652    7.390017   15.896519\r\n  16.136719    6.5862875  12.216141    0.33137095 18.97356     1.9778614\r\n   5.3641543   1.9284656   1.8500257  16.767817   12.7209     14.047361\r\n   7.367909    3.1752422   5.949711   15.742522    2.2939441  16.137108\r\n   1.6687201  13.069997    8.666047   16.782955    1.3117387   6.3798137\r\n   6.557558   15.286772    7.5772853   9.168247    3.2267199   1.5568383 ]]\r\n\r\nmlir :\r\n[[ 8.160242   9.0523     7.3261642  8.867854   7.860682   8.722304\r\n   7.2230916  8.622743   9.271859   7.7777925  9.489797   7.390472\r\n   8.524878   9.906944   8.355099   8.330111   8.341421   8.271743\r\n   8.937096   8.515015   7.225615   9.190289   8.9844675  8.162167\r\n   8.694139   6.9362564  9.618863  10.1376915  8.462459   8.29322\r\n   8.158456   8.796178   8.039083   9.774652   8.209907   9.378836\r\n  10.289057   7.984726   8.897137   9.119129   9.802201   8.349303\r\n   6.498592   8.638722   8.569397   9.730883   8.358421   9.018978\r\n   8.4079275  6.496749   8.111706   8.541293   9.513434   9.01988\r\n   7.2715945  8.307488   8.566431   9.748925   8.775068   7.9520493\r\n   7.9917192  9.261906   7.9303417  9.471784   9.427535   7.840794 ]]\r\nmlir  sum of absolute difference:  284.37515\r\n\r\ntoco :\r\n[[ 6.9496307   7.9791093   0.23810542  1.6724037   9.687995   11.553459\r\n   0.6050917   8.606714   17.731003    2.5280902  16.075907    0.50299734\r\n   6.1198673  12.388639    8.383966   11.98933     7.311679    8.748673\r\n   9.714088   12.450737    1.4212162   7.567941   14.836597    5.73806\r\n   8.028838    2.5774097   7.960953   19.355337   11.474101    1.2807347\r\n   5.075203   17.24984     3.086626   17.775652    7.390019   15.896517\r\n  16.13672     6.586289   12.216139    0.33137095 18.973562    1.9778614\r\n   5.364155    1.9284654   1.8500254  16.767818   12.7209015  14.047361\r\n   7.367908    3.1752434   5.94971    15.74252     2.2939441  16.137106\r\n   1.6687204  13.069999    8.666047   16.782953    1.3117385   6.379814\r\n   6.557558   15.286772    7.577286    9.168246    3.2267199   1.5568382 ]]\r\ntoco  sum of absolute difference:  5.4582953e-05\r\n```\r\n\r\n**Failure details**\r\nThe conversion is successful, but the generated model is wrong,\r\nThe result running with the model is much different from the original result.\r\n\r\n\r\n\r\n\r\n", "comments": ["Was able to reproduce the issue with [TF v2.2](https://colab.research.google.com/gist/amahendrakar/97a184c5b298585bd18887b72e57c3e1/39572.ipynb) and [TF-nightly](https://colab.research.google.com/gist/amahendrakar/6a8783e3a871557adffddc2899e76661/39572-tf-nightly.ipynb). Please find the attached gist. Thanks!", "Looks like the fusion in MLIR is broken. I can reproduce this with the following minimal function as well:\r\n```python\r\nlength = 66\r\na = tf.random.uniform([length, length], dtype=tf.float32)\r\nc = tf.random.uniform([length], dtype=tf.float32)\r\n\r\n@tf.function\r\ndef func(x):\r\n    return tf.matmul(x, a) * c\r\n```\r\nThe weights in the generated flatbuffer are definitely different.", "It looks like this is not a new issue. I can reproduce this in v2.1.0 as well.", "https://github.com/tensorflow/tensorflow/blob/020a88ac127caa1e333ce36873ad2602abc5f7d7/tensorflow/compiler/mlir/lite/transforms/optimize.cc#L361-L368\r\nThese lines are skipped if the filter is square matrix.\r\n", "Hi @liufengdb,\r\n\r\nDo you think you can take a look?", "lgeiger, I'm a little bit confused by your example. The patterns used for `tf.matmul(x, a) * c` in your example is different from the issue description, right? ", "> lgeiger, I'm a little bit confused by your example. The patterns used for `tf.matmul(x, a) * c` in your example is different from the issue description, right?\r\n\r\n@liufengdb Thanks for checking it out. Yes, the example is different on purpose since it uses a subset of the ops of the original example and I thought it might be helpful for debugging to have a smaller graph that reproduces the same issue. Please let me know if the two examples are not related, I am happy to open up a new issue for it.", "https://github.com/tensorflow/tensorflow/blob/ed0eb69b76f9ff7ac952a3f36692d2c86929a6bf/tensorflow/compiler/mlir/lite/tests/optimize.mlir#L252-L264\r\nThe test is invalid too.\r\n\r\n```\r\ncst0 = [[1.0, 2.0],\r\n        [3.0, 4.0]]\r\n\r\ncst1 = [1.0, 2.0]\r\n\r\narg0 = [x, y]\r\n\r\n%0 = tfl.fully_connected(arg0, cst0) = tf.matmul(arg0, tf.transpose(cst0)) = [1.0x + 2.0y, 3.0x + 4.0y]\r\n\r\n%1 = tfl.mul(%0, cst1) = [1.0x + 2.0y, 6.0x + 8.0y] = tf.matmul(arg0, [[1.0, 6.0], [2.0, 8.0]]) = tf.matmul(arg0, tf.transpose([[1.0, 2.0], [6.0, 8.0]]))\r\n\r\n%[[CONSTANT]] = [[1.0, 2.0], [6.0, 8.0]]  !=  [[1.0, 4.0], [3.0, 8.0]]  \r\n\r\n\r\n```", "Are there any updates on this? It looks like the related PR is stale #40013 but it would be great if this issue would be fixed.", "I submitted #41790 a few weeks ago to fix this, any chance someone could review it?", "This is still a major issue and a fix is available at #41790, it would be great if this could still make it into the 2.4 release.", "I can still reproduce this in the latest tf-nightly: https://colab.research.google.com/drive/1kcw_zhk_7wj8zOVf3VH1V-2GjN0eFQJF?usp=sharing\r\n\r\nAny news on when #41790 could get a review?", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39572\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39572\">No</a>\n"]}, {"number": 39571, "title": "Convert ctc_decode in tf.keras to .pb model, Getting call error.", "body": "\r\n**System information**\r\n- Windows 10:\r\n- TensorFlow installed from (binary):\r\n- TensorFlow version (1.10):\r\n- Python version: 3.6\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\n\r\n\r\n**Describe the current behavior**\r\nI convert ctc_model `tensorflow.backend.keras.ctc_decode` to pb model, Then call with java ,There are exception\r\n\r\n```\r\nException in thread \"main\" java.lang.IllegalArgumentException: sequence_length is not a vector\r\n\t [[Node: decode/CTCGreedyDecoder = CTCGreedyDecoder[merge_repeated=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](decode/Log, decode/ToInt32)]]\r\n```\r\nThe code contains\u201csequence_length\u201d is (parameter input_length is a vector):\r\n\r\n```\r\n\r\n@tf_export('keras.backend.ctc_decode')\r\ndef ctc_decode(y_pred, input_length, greedy=True, beam_width=100, top_paths=1):\r\n  \"\"\"Decodes the output of a softmax.\r\n\r\n  Can use either greedy search (also known as best path)\r\n  or a constrained dictionary search.\r\n\r\n  Arguments:\r\n      y_pred: tensor `(samples, time_steps, num_categories)`\r\n          containing the prediction, or output of the softmax.\r\n      input_length: tensor `(samples, )` containing the sequence length for\r\n          each batch item in `y_pred`.\r\n      greedy: perform much faster best-path search if `true`.\r\n          This does not use a dictionary.\r\n      beam_width: if `greedy` is `false`: a beam search decoder will be used\r\n          with a beam of this width.\r\n      top_paths: if `greedy` is `false`,\r\n          how many of the most probable paths will be returned.\r\n\r\n  Returns:\r\n      Tuple:\r\n          List: if `greedy` is `true`, returns a list of one element that\r\n              contains the decoded sequence.\r\n              If `false`, returns the `top_paths` most probable\r\n              decoded sequences.\r\n              Important: blank labels are returned as `-1`.\r\n          Tensor `(top_paths, )` that contains\r\n              the log probability of each decoded sequence.\r\n  \"\"\"\r\n  y_pred = math_ops.log(array_ops.transpose(y_pred, perm=[1, 0, 2]) + epsilon())\r\n  input_length = math_ops.to_int32(input_length)\r\n\r\n  if greedy:\r\n    (decoded, log_prob) = ctc.ctc_greedy_decoder(\r\n        inputs=y_pred, sequence_length=input_length)\r\n  else:\r\n    (decoded, log_prob) = ctc.ctc_beam_search_decoder(\r\n        inputs=y_pred,\r\n        sequence_length=input_length,\r\n        beam_width=beam_width,\r\n        top_paths=top_paths)\r\n  decoded_dense = [\r\n      sparse_ops.sparse_to_dense(\r\n          st.indices, st.dense_shape, st.values, default_value=-1)\r\n      for st in decoded\r\n  ]\r\n  return (decoded_dense, log_prob)\r\n```\r\n\r\n**Describe the expected behavior**\r\nRun smoothly\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["The Java call code:\r\n```\r\ntry(Tensor x= Tensor.create(input);\r\n                Tensor x_2 = Tensor.create(length);\r\n            Tensor y = sess.runner().feed(\"input_1\", x).feed(\"input_length\", x_2).fetch(\"decode/SparseToDense\").run().get(0)){\r\n                System.out.print(\"success\");\r\n            }\r\n```", "@emptyknowledge \r\n\r\nIs there any particular reason to be using such a old version of tensor flow can you please upgrade to later versions and see if it helps resolve the issue as there will be no updates on this old version.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39571\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39571\">No</a>\n"]}, {"number": 39570, "title": "Fix person detection example", "body": "esp32-camera repo is progressing and the example code now fails to build.\r\n\r\nFixed example and modified instructions to clone specific version of esp32-camera.\r\n\r\nSigned-off-by: Vikram Dattu <vikram.dattu@espressif.com>", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F39570) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F39570) for more info**.\n\n<!-- ok -->", "cc: @AdityaHPatwardhan @kedars"]}, {"number": 39569, "title": "SyncBatchNormalization would cause gradient explosion occasionally", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below): 2.2.0\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10.1\r\n- GPU model and memory: 8x V100 16G\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\nWhen using SyncBN in my network, sometimes i would see gradient explosion for no reason. However, there's no such problem when using regular BN.\r\n\r\ni'm not 100% sure if this is a bug of SyncBN, but want to leave an issue here to see if anyone else has run into similar problem.\r\n\r\ni printed gradient and loss for two mini batches, the first one is a normal batch, and gradient exploded in the second batch.\r\n```\r\n# normal batch\r\nmax gradient:  0.326069444 max grad var:  detector_scale_large_final_conv2d/bias:0\r\nmax gradient:  0.340717554 max grad var:  detector_scale_large_final_conv2d/bias:0\r\nmax gradient:  0.231284797 max grad var:  detector_scale_large_final_conv2d/bias:0\r\nmax gradient:  0.460334092 max grad var:  detector_scale_large_final_conv2d/bias:0\r\nmax gradient:  1.16038787 max grad var:  detector_scale_large_final_conv2d/bias:0\r\nmax gradient:  0.489672422 max grad var:  detector_scale_large_final_conv2d/bias:0\r\nmax gradient:  0.276092589 max grad var:  detector_scale_large_final_conv2d/bias:0\r\nmax gradient:  0.48520276 max grad var:  detector_scale_large_final_conv2d/bias:0\r\nmax weights after gd:  82.8172226 max weights var:  detector_scale_large_final_conv2d/bias:0\r\nmax weights after gd:  82.8172226 max weights var:  detector_scale_large_final_conv2d/bias:0\r\nmax weights after gd:  82.8172226 max weights var:  detector_scale_large_final_conv2d/bias:0\r\nmax weights after gd:  82.8172226 max weights var:  detector_scale_large_final_conv2d/bias:0\r\nmax weights after gd:  82.8172226 max weights var:  detector_scale_large_final_conv2d/bias:0\r\nmax weights after gd:  82.8172226 max weights var:  detector_scale_large_final_conv2d/bias:0\r\nmax weights after gd:  82.8172226 max weights var:  detector_scale_large_final_conv2d/bias:0\r\nmax weights after gd:  82.8172226 max weights var:  detector_scale_large_final_conv2d/bias:0\r\nTrained batch: 1051 batch loss: 120.549194 batch l2 loss 5413.74561\r\n\r\n# exploded batch\r\nmax gradient:  6.35045412e+17 max grad var:  detector_scale_large_final_conv2d/bias:0\r\nmax gradient:  1.04548427e+19 max grad var:  detector_scale_large_final_conv2d/bias:0\r\nmax gradient:  8.70996347e+16 max grad var:  detector_scale_large_final_conv2d/bias:0\r\nmax gradient:  2.92331335e+18 max grad var:  detector_scale_large_final_conv2d/bias:0\r\nmax gradient:  1.48902926e+17 max grad var:  detector_scale_large_final_conv2d/bias:0\r\nmax gradient:  7.38057557e+17 max grad var:  detector_scale_large_final_conv2d/bias:0\r\nmax gradient:  3.23904746e+18 max grad var:  detector_scale_large_final_conv2d/bias:0\r\nmax gradient:  4.20917e+17 max grad var:  detector_scale_large_final_conv2d/bias:0\r\nmax weights after gd:  4.87674142e+14 max weights var:  detector_scale_large_final_conv2d/bias:0\r\nmax weights after gd:  4.87674142e+14 max weights var:  detector_scale_large_final_conv2d/bias:0\r\nmax weights after gd:  4.87674142e+14 max weights var:  detector_scale_large_final_conv2d/bias:0\r\nmax weights after gd:  4.87674142e+14 max weights var:  detector_scale_large_final_conv2d/bias:0\r\nmax weights after gd:  4.87674142e+14 max weights var:  detector_scale_large_final_conv2d/bias:0\r\nmax weights after gd:  4.87674142e+14 max weights var:  detector_scale_large_final_conv2d/bias:0\r\nmax weights after gd:  4.87674142e+14 max weights var:  detector_scale_large_final_conv2d/bias:0\r\nmax weights after gd:  4.87674142e+14 max weights var:  detector_scale_large_final_conv2d/bias:0\r\nTrained batch: 1052 batch loss: 120.594421 batch l2 loss 5413.69141\r\n```\r\n\r\n**Describe the expected behavior**\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["@ethanyanjiali \r\n\r\nRequest you to share colab link or simple standalone code to reproduce the issue in our environment.It helps us in localizing the issue faster.Thanks!", "@ravikyram due to the nature of this bug, this is very hard to make a minimum reproducible example, two reasons:\r\n\r\n1) SyncBN is used in multi-gpu training, i'm not sure if you can do that in colab?\r\n2) from my experience, this is not a deterministic bug. i'm not sure if it will occur with a smaller network. it probably requires some special combination of data, loss function, batch size and network arch to reproduce.\r\n\r\nanyhow, i'll see if i can make a simple example and share it here", "Could you try:\r\n\r\n```\r\ntf.distribute.experimental.MultiWorkerMirroredStrategy(communication=\r\n    tf.distribute.experimental.CollectiveCommunication.NCCL)\r\n```\r\n\r\ninstead of MirroredStrategy to see if the issue still occurs. We have a suspect in #41980, and it would be to verify whether this is the same issue. You can use MultiWorkerMirroredStrategy with one host without additional setup.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39569\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39569\">No</a>\n"]}, {"number": 39568, "title": "predict_signature_def to support multiple inputs and outputs", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 3.6\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nTo covert a Keras model to Tensorflow, we need the input and output signatures. This is registered via the function `predict_signature_def`\r\nThis methods requires inputs  and outputs be a single Tensor.  If my Keras model has multiple inputs and outputs, how to I specify them in this API? \r\n\r\n**Will this change the current api? How?**\r\n\r\n**Who will benefit with this feature?**\r\nDevelopers looking to migrate from Keras to Tensor format\r\n\r\n**Any Other info.**\r\n", "comments": ["You can specify multiple inputs and outputs in dictionary of string to tensor.\r\nSee https://www.tensorflow.org/api_docs/python/tf/compat/v1/saved_model/predict_signature_def\r\n```python. \r\n signature = tf.saved_model.predict_signature_def(\r\n                        inputs = {'input1':x1,'input2':x2},\r\n                        outputs = {'output1':y1,'output2:y2})\r\n```", "Thanks . I am able to convert now. If I may suggest, the documentation for the API is brief, and it will be useful  to have these nuances mentioned. There are lot of posts on Stackoverflow where developers assume that this API is only for Single Tensors.", "Thanks for the feedback. I will update that piece of documentation soon.\r\nClosing this issue since it's resolved.\r\n"]}, {"number": 39567, "title": "Unable to save ensembled tf.keras.Model instance ", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n**Yes**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n**Linux Ubuntu 18.04**\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n**NIL**\r\n- TensorFlow installed from (source or binary):\r\n**Binary**\r\n- TensorFlow version (use command below):\r\n**2.1.0**\r\n- Python version:\r\n**3.6**\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n**10.1 /  7.6.4**\r\n- GPU model and memory:\r\n**RTX 2070 Super/8GB**\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\nI am unable to save an ensembled model after training it to completion.\r\n\r\nMy ensembled network is as follows:\r\n```python\r\n\r\ninputs = tf.keras.layers.Input(shape=[224, 224, 3])\r\n\r\ndef Net(inputs):\r\n    base_model = DenseNet121(include_top=False, weights='imagenet', input_tensor=inputs)\r\n    output = base_model.get_layer(\"pool3_conv\").output\r\n    x = Conv2D(128, 3, activation='relu', padding='same')(output)\r\n    x = BatchNormalization()(x)\r\n    x = Conv2D(64, 3, activation='relu', padding='same')(x)\r\n    x = BatchNormalization()(x)\r\n    x = Flatten()(x)\r\n    x = Dense(2, activation='softmax', name='clf_output')(x)\r\n\r\n    model = tf.keras.models.Model(inputs=[base_model.input], outputs=[x])\r\n\r\n    return model\r\n\r\ndef create_ensemble(models, inputs):\r\n    for i in range(len(models)):\r\n        # Each model is a Net object\r\n        model = models[i]\r\n        for layer in model.layers[1:]:\r\n            layer.trainable = False\r\n            layer._name = 'ensemble_' + str(i+1) + '_' + layer._name\r\n\r\n    stack_outputs = [model(inputs) for model in models]\r\n    merge = Concatenate()(stack_outputs) \r\n    x = Dense(16, activation='relu')(merge)\r\n    x = Dense(2, activation='softmax')(x)\r\n\r\n    print(inputs)\r\n    model = tf.keras.models.Model(inputs=inputs, outputs=x, name='ensemble')\r\n\r\n    return model\r\n```\r\nPortion of training code:\r\n```python\r\n # Creating Ensemble\r\n    print(\"Creating Ensemble\")\r\n    ensemble = create_ensemble(models, inputs)\r\n\r\n    print(\"Ensemble architecture: \")\r\n    print(ensemble.summary())\r\n\r\n    ensemble.compile(loss=\"categorical_crossentropy\", \r\n                     optimizer=opt, \r\n                     metrics=[\"accuracy\"])\r\n\r\n    ensemble_checkpoint = tf.keras.callbacks.ModelCheckpoint(\"ensemble_backup_weights.h5\", \r\n                                                             monitor='val_loss', \r\n                                                             verbose=1, \r\n                                                             save_weights_only=True, \r\n                                                             save_best_only=True)\r\nhistory = ensemble.fit(train_ds, \r\n                           epochs=EPOCHS, \r\n                           verbose=1,\r\n                           steps_per_epoch=(len(imagePaths)-VAL_SPLIT) // BS, \r\n                           validation_data=(val_ds), \r\n                           validation_steps = VAL_SPLIT // BS, \r\n                           callbacks=[ensemble_checkpoint, reducelr])\r\n\r\n    print(\"Saving Ensemble\")\r\n    ensemble.save_weights(\"ensemble_weights.h5\")\r\n    ensemble.save(\"ensemble\", include_optimizer=False)\r\n```\r\n\r\n**Describe the expected behavior**\r\n```ensemble.save``` should work normally. I am able to save the weights, but not the model as a whole.\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\nError encountered is as follows:\r\n```\r\nEpoch 00001: val_loss improved from inf to 0.45252, saving model to ensemble_backup_weights.h5\r\n265/265 [==============================] - 52s 195ms/step - loss: 0.5693 - accuracy: 0.7101 - val_loss: 0.4525 - val_accuracy: 0.9116\r\nSaving Ensemble\r\n2020-05-15 11:42:31.230630: W tensorflow/python/util/util.cc:319] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 146, in <module>\r\n    main(ap.parse_args())\r\n  File \"train.py\", line 140, in main\r\n    ensemble.save(\"ensemble\", include_optimizer=False)\r\n  File \"/home/tedmund/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py\", line 1008, in save\r\n    signatures, options)\r\n  File \"/home/tedmund/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py\", line 115, in save_model\r\n    signatures, options)\r\n  File \"/home/tedmund/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/save.py\", line 78, in save\r\n    save_lib.save(model, filepath, signatures, options)\r\n  File \"/home/tedmund/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/saved_model/save.py\", line 923, in save\r\n    saveable_view, asset_info.asset_index)\r\n  File \"/home/tedmund/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/saved_model/save.py\", line 653, in _serialize_object_graph\r\n    _write_object_proto(obj, obj_proto, asset_file_def_index)\r\n  File \"/home/tedmund/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/saved_model/save.py\", line 692, in _write_object_proto\r\n    metadata=obj._tracking_metadata)\r\n  File \"/home/tedmund/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 2412, in _tracking_metadata\r\n    return self._trackable_saved_model_saver.tracking_metadata\r\n  File \"/home/tedmund/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/base_serialization.py\", line 57, in tracking_metadata\r\n    self.python_properties,\r\n  File \"/home/tedmund/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/layer_serialization.py\", line 40, in python_properties\r\n    return self._python_properties_internal()\r\n  File \"/home/tedmund/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/model_serialization.py\", line 35, in _python_properties_internal\r\n    metadata = super(ModelSavedModelSaver, self)._python_properties_internal()\r\n  File \"/home/tedmund/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/network_serialization.py\", line 32, in _python_properties_internal\r\n    metadata = super(NetworkSavedModelSaver, self)._python_properties_internal()\r\n  File \"/home/tedmund/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/layer_serialization.py\", line 58, in _python_properties_internal\r\n    metadata['config'] = self.obj.get_config()\r\n  File \"/home/tedmund/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py\", line 918, in get_config\r\n    return copy.deepcopy(get_network_config(self))\r\n  File \"/home/tedmund/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py\", line 1993, in get_network_config\r\n    layer_config = serialize_layer_fn(layer)\r\n  File \"/home/tedmund/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/utils/generic_utils.py\", line 198, in serialize_keras_object\r\n    config = instance.get_config()\r\n  File \"/home/tedmund/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py\", line 918, in get_config\r\n    return copy.deepcopy(get_network_config(self))\r\n  File \"/home/tedmund/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py\", line 2025, in get_network_config\r\n    model_outputs = nest.pack_sequence_as(network._nested_outputs, model_outputs)\r\n  File \"/home/tedmund/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/util/nest.py\", line 504, in pack_sequence_as\r\n    return _pack_sequence_as(structure, flat_sequence, expand_composites)\r\n  File \"/home/tedmund/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/util/nest.py\", line 453, in _pack_sequence_as\r\n    len(flat_sequence), truncate(flat_sequence, 100)))\r\nValueError: The target structure is of type `<class 'tensorflow.python.framework.ops.Tensor'>`\r\n  Tensor(\"clf_output/Identity:0\", shape=(None, 2), dtype=float32)\r\nHowever the input structure is a sequence (<class 'list'>) of length 0.\r\n  []\r\nnest cannot guarantee that it is safe to map one to the other.\r\n```", "comments": ["@iobtl \r\ncan you please try \"**pip install -U tf-nightly**\" and see if it helps resolve your issue.\r\n\r\nI ran the code shared there are too many indentation errors, could you please share code such that we could replicate the issue, if possible please share a colab gist so we could analyse the issue.\r\nPlease find the [gist of error faced](https://colab.sandbox.google.com/gist/Saduf2019/5043c9e4d6d7f700edbf40c44c4df37b/untitled182.ipynb)", "Currently the use case is for a production environment so I am unable to perform that command. Have circumvented the issue by performing ```ensemble.save_weights``` instead and reloading the weights after reconstructing the network.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39567\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39567\">No</a>\n", "I've hit this error too, on a custom architecture that uses multiple MobileNetV2s as feature extractors.\r\n\r\nI'm on `v2.2.0-rc4-8-g2b96f3662b 2.2.0`\r\n\r\nManually calling `save_weights` works", "I don't understand why this is closed... I am on v2.3.0-rc2-23-gb36436b087 2.3.0 and have the same problems - I did not have this problem on TF1 few months ago. I changed to TF2 recently and all of a sudden I cannot save my models after training. \r\nMy model without 'Concatenate' layer is saving fine so I'm guessing the problem lies in the doing the concatenation after input goes through the nested models? Same problem trying to save model with ModelCheckpoint. \r\n\r\nSaving the weight seems to work at least.... ", "I have the same issue with v 2.1 saving a network with custom layers. I have tried both `tf` and `h5` format to save.", "I have the same issue in tf 2.3, tried both `tf` and `h5` as well.  tf 2.4 nightly doesn't solve this either.  Much slower in production environment to load structure and add weights", "\r\n@a3cel2 maybe this works for you:\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/43954#issuecomment-709925095", "I ran into the same issue as described above.\r\nDropping the lines to rename the base model layers in `create_ensemble` solved the issue for me, using TF 2.5.0"]}, {"number": 39566, "title": "Multithreaded Function Stops after Model is Instantiated", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 19.04\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.1.0\r\n- Python version: 3.7.7\r\n- CUDA/cuDNN version: 10.1/7.6.5\r\n- GPU model and memory: RTX 2070\r\n\r\nThis is kind of a follow up to [a previous issue](https://github.com/tensorflow/tensorflow/issues/39431) I had, about a Python hanging when `.predict` was called in a thread, however, that wasn't thoroughly reproducible.\r\n\r\nI have further narrowed down the issue to a model being instantiated inside a thread.  Below is a useless function that demonstrates the issue:\r\n\r\n```python\r\ndef my_function():\r\n    print('barfoo')\r\n    a = tf.keras.Sequential([tf.keras.layers.Dense(4, input_shape=(16,))])\r\n    print('foobar')\r\n```\r\n\r\nWhen this isn't put in a thread with multiprocessing, it correctly prints:\r\n\r\n```\r\nbarfoo\r\nfoobar\r\n```\r\n\r\nHowever, when put in a multiprocessing thread, it only prints:\r\n\r\n```\r\nbarfoo\r\n```\r\n\r\n[Here](https://colab.research.google.com/gist/LryF/3898b2da42d706bb0be910b572d97a6c/other-test.ipynb) is a notebook that replicates the issue.", "comments": ["I have tried in colab with TF GPU 2.1.0, 2.2.0 and was able to reproduce the issue.Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/07100c361ddcd855b68038ede0cc19c5/untitled888.ipynb).Thanks!", "Any thoughts? @omalleyt12 ", "@LryF  Could you please try on latest stable version of tf 2.5 or 2.4.1 and let us know if this is still an issue.Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39566\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39566\">No</a>\n"]}, {"number": 39564, "title": "[RNN] Error Optimizing Tensorflow keras model", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS Catalina v 10.15.3\r\n- TensorFlow installed from (source or binary): binary (pip install tensorflow)\r\n- TensorFlow version (or github SHA if from source):  2.1.0\r\n\r\n\r\n**Command used to run the converter or code if you\u2019re using the Python API**\r\nIf possible, please share a link to Colab/Jupyter/any notebook.\r\n```\r\nimport tensorflow as tf\r\n\r\nx_inputs = tf.keras.layers.Input((3,229,1))\r\nx = tf.keras.layers.Conv2D(32, (3,3), padding='same')(x_inputs)\r\nx = tf.keras.layers.BatchNormalization()(x)\r\nx = tf.keras.layers.Activation('relu')(x)\r\nx = tf.keras.layers.Dropout(0.25)(x)\r\nx = tf.keras.layers.MaxPooling2D((1,2))(x)\r\nx = tf.keras.layers.Conv2D(64, (3,3), padding='same')(x)\r\nx = tf.keras.layers.BatchNormalization()(x)\r\nx = tf.keras.layers.Activation('relu')(x)\r\nx = tf.keras.layers.MaxPooling2D((1,2))(x)\r\nx = tf.keras.layers.Reshape((-1,tf.keras.backend.int_shape(x)[-1] * tf.keras.backend.int_shape(x)[-2]))(x)\r\nx = tf.keras.layers.LSTM(256)(x)\r\nx = tf.keras.layers.Dense(1)(x)\r\nx = tf.keras.layers.Activation('sigmoid')(x)\r\nmodel = tf.keras.models.Model(x_inputs, x)\r\nmodel.summary()\r\n\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\nconverter.experimental_new_converter = True\r\nconverter.allow_custom_ops = True\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\ntflite_model = converter.convert()\r\n```\r\n\r\n**The output from the converter invocation**\r\n```\r\n2020-05-14 16:58:55.177804: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)\r\n2020-05-14 16:58:55.177972: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\r\n2020-05-14 16:58:55.332306: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: graph_to_optimize\r\n2020-05-14 16:58:55.332333: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: Graph size after: 836 nodes (0), 1109 edges (0), time = 27.123ms.\r\n2020-05-14 16:58:55.332339: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: Graph size after: 836 nodes (0), 1109 edges (0), time = 70.348ms.\r\n2020-05-14 16:58:55.332343: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: model_1_bidirectional_1_forward_lstm_1_while_body_42042\r\n2020-05-14 16:58:55.332348: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-05-14 16:58:55.332353: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-05-14 16:58:55.332358: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: model_1_bidirectional_1_backward_lstm_1_while_cond_42307\r\n2020-05-14 16:58:55.332363: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-05-14 16:58:55.332369: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-05-14 16:58:55.332374: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: model_1_bidirectional_1_backward_lstm_1_while_body_42308\r\n2020-05-14 16:58:55.332380: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-05-14 16:58:55.332385: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-05-14 16:58:55.332390: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: model_1_bidirectional_2_forward_lstm_2_while_body_42685\r\n2020-05-14 16:58:55.332395: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-05-14 16:58:55.332399: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-05-14 16:58:55.332404: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: model_1_bidirectional_1_forward_lstm_1_while_cond_42041\r\n2020-05-14 16:58:55.332409: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-05-14 16:58:55.332415: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-05-14 16:58:55.332421: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: model_1_bidirectional_2_backward_lstm_2_while_cond_42950\r\n2020-05-14 16:58:55.332445: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-05-14 16:58:55.332486: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-05-14 16:58:55.332492: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: model_1_bidirectional_2_forward_lstm_2_while_cond_42684\r\n2020-05-14 16:58:55.332497: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-05-14 16:58:55.332502: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-05-14 16:58:55.332507: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: model_1_bidirectional_2_backward_lstm_2_while_body_42951\r\n2020-05-14 16:58:55.332512: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-05-14 16:58:55.332544: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-05-14 16:58:58.205307: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)\r\n2020-05-14 16:58:58.205687: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\r\n2020-05-14 16:59:00.586252: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: graph_to_optimize\r\n2020-05-14 16:59:00.586377: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 420 nodes (-60), 591 edges (-90), time = 1090.02698ms.\r\n2020-05-14 16:59:00.586382: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 420 nodes (0), 591 edges (0), time = 381.193ms.\r\n2020-05-14 16:59:00.586385: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: model_1_bidirectional_1_backward_lstm_1_while_body_42308_frozen\r\n2020-05-14 16:59:00.586390: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 107 nodes (-2), 155 edges (0), time = 3.961ms.\r\n2020-05-14 16:59:00.586393: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 107 nodes (0), 155 edges (0), time = 2.811ms.\r\n2020-05-14 16:59:00.586474: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: model_1_bidirectional_1_forward_lstm_1_while_cond_42041_frozen\r\n2020-05-14 16:59:00.586484: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 14 nodes (0), 4 edges (0), time = 0.298ms.\r\n2020-05-14 16:59:00.586489: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 14 nodes (0), 4 edges (0), time = 0.254ms.\r\n2020-05-14 16:59:00.586492: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: model_1_bidirectional_1_backward_lstm_1_while_cond_42307_frozen\r\n2020-05-14 16:59:00.586496: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 14 nodes (0), 4 edges (0), time = 0.761ms.\r\n2020-05-14 16:59:00.586499: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 14 nodes (0), 4 edges (0), time = 0.358ms.\r\n2020-05-14 16:59:00.586657: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: model_1_bidirectional_1_forward_lstm_1_while_body_42042_frozen\r\n2020-05-14 16:59:00.586668: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 107 nodes (-2), 155 edges (0), time = 4.465ms.\r\n2020-05-14 16:59:00.586673: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 107 nodes (0), 155 edges (0), time = 2.419ms.\r\n2020-05-14 16:59:00.586678: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: model_1_bidirectional_2_forward_lstm_2_while_body_42685_frozen\r\n2020-05-14 16:59:00.586683: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 107 nodes (-2), 155 edges (0), time = 4.247ms.\r\n2020-05-14 16:59:00.586687: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 107 nodes (0), 155 edges (0), time = 2.45ms.\r\n2020-05-14 16:59:00.586790: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: model_1_bidirectional_2_backward_lstm_2_while_body_42951_frozen\r\n2020-05-14 16:59:00.586802: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 107 nodes (-2), 155 edges (0), time = 4.046ms.\r\n2020-05-14 16:59:00.586808: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 107 nodes (0), 155 edges (0), time = 2.454ms.\r\n2020-05-14 16:59:00.586813: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: model_1_bidirectional_2_backward_lstm_2_while_cond_42950_frozen\r\n2020-05-14 16:59:00.586817: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 14 nodes (0), 4 edges (0), time = 0.334ms.\r\n2020-05-14 16:59:00.586820: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 14 nodes (0), 4 edges (0), time = 0.245ms.\r\n2020-05-14 16:59:00.586958: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: model_1_bidirectional_2_forward_lstm_2_while_cond_42684_frozen\r\n2020-05-14 16:59:00.586967: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 14 nodes (0), 4 edges (0), time = 0.286ms.\r\n2020-05-14 16:59:00.586987: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 14 nodes (0), 4 edges (0), time = 0.247ms.\r\n\r\n``\r\n**Any other info / logs**\r\nThe model comprises of multiple LSTM, and some other custom layers. Without quantization, the model conversion works only with the experimental_new_converter set to true. Removing the LSTM layer fixes the issue", "comments": ["@ahmedalesh Please share a model or standalone code to reproduce the issue? Thanks!", "I have updated the issue with a standalone code\r\n\r\nYou can also find a standalone code here\r\n\r\nhttps://colab.research.google.com/drive/1iXWuI10KpWfp57989kkmoakiI9f3bF2I?usp=sharing\r\n\r\nWithout the experimental new converter, I am able to convert the model but unable to load the model from memory or allocate tensors after", "Hi @ahmedalesh,\r\n\r\nA couple of things \r\n\r\n1. `tf.lite.Optimize.DEFAULT` should only be set if using quantization\r\n2. rnn is only supported converting `from_saved_model`\r\n\r\nI made a working version of the code at:\r\nhttps://colab.research.google.com/drive/1OVnfSk45qTYBzbLJeyte05QDAxNKA6CI?usp=sharing\r\n", "> Hi @ahmedalesh,\r\n> \r\n> A couple of things\r\n> \r\n> 1. `tf.lite.Optimize.DEFAULT` should only be set if using quantization\r\n> 2. rnn is only supported converting `from_saved_model`\r\n> \r\n> I made a working version of the code at:\r\n> https://colab.research.google.com/drive/1OVnfSk45qTYBzbLJeyte05QDAxNKA6CI?usp=sharing\r\n\r\nThanks @daverim for the working version. However, I do intend to use quantization. As.I mentioned earlier, by not setting quantization, the model conversion works. I tried your code and when i set tf.lite.Optimize.DEFAULT, the issue persists.\r\n\r\nThis is a similar working version to your notebook but using`'from_keras_model` without quantizing the model weight. \r\n\r\nhttps://colab.research.google.com/drive/13lN61zcxoepgBFn5ZjSGqHDS-qYefVPU?usp=sharing\r\n\r\nI am confident the issue is because of the LSTM layer in the model, using both tf saver and keras model save does not fix the issue.\r\n\r\nAhmed ", "Ah sorry, I must have been really confused when I wrote my response. My apologies.\r\n\r\nThe reason why your code doesn't work is because the lstm layer is being converted as a subgraph, which the quantizer does not support.\r\n\r\nTo get this to work, you need the converter to convert the lstm layer as a builtin op, for which you should use `convert_from_saved_model` in combination with the concrete function to fix the batch size.\r\n\r\nI've updated my gist here:\r\nhttps://colab.research.google.com/drive/1OVnfSk45qTYBzbLJeyte05QDAxNKA6CI?usp=sharing\r\n\r\nI left out the update to tf-nightly as well as a  setting a correct batch size in my previous version.\r\n\r\nIf you look at the resulting graph using Netron you will see that the while loop is replaced with a UnidirectionalSequenceLstmOp (https://imgur.com/2PJSJTG) Since this is a single op, the quantizer doesn't fail on multiple subgraphs.\r\n\r\nUsing your version will have the while loop rather than the fused op, and that's why it doesn't work. \r\nHope that helps.\r\n", "@daverim thanks a lot that seems to help using tf-nightly, I would be closing the issue now.", "@ahmedalesh Hi I'm dealing with the same error. Could you tell which version is it to fix it ? Thx", "> @ahmedalesh Hi I'm dealing with the same error. Could you tell which version is it to fix it ? Thx\r\n\r\n@07freedom Hello, I was able to use 2.3.0-dev20200601 to do the conversion. You can \r\n`pip install tf-nightly`"]}, {"number": 39563, "title": "[Intel MKL] Adding MklTanh op", "body": "This PR adds Tanh op to MKL CPU backend.", "comments": ["@penpornk Can you please take a look on this PR ? Thanks!", "@nhasabni Can you please check @penpornk's comments and keep us posted. Thanks!", "> Thank you again for the PR!\r\n\r\nThanks for review and approval!"]}, {"number": 39562, "title": "[ROCm] NonMaxSuppression", "body": "This PR fixes and enables the NonMaxSuppression kernel and corresponding test for ROCm.", "comments": ["@chsigg Can you please take a look on this PR ? Thanks!", "@ekuznetsov139  Can you please resolve conflicts? Thanks!", "This PR has conflicts and doesn't build. Could you please address the issues? Thanks.", "@chsigg Can you please take a look on this PR ? Thanks!"]}, {"number": 39561, "title": "Cadence:HiFi Mini NN Library: Optimized kernels integration", "body": "Integrated fully_connected, softmax and svdf cadence  HiFi Mini optimized kernels\r\nto tensor flow lite micro kernels. These optimized kernels gives better performance\r\nover reference kernels while running keyword_benchmark application.\r\n\r\nSigned-off-by: Bhanu Prakash Bandaru Venkata <bhanup@cadence.com>\r\nSigned-off-by: Harshavardhan Ravindra Joshi <joshih@cadence.com>\r\nSigned-off-by: Pramod Kumar Surana <pramods@cadence.com>\r\nSigned-off-by: Prasad Nikam <pnikam@cadence.com>", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F39561) for more info**.\n\n<!-- need_author_cla -->", "@nyadla-sys Thank you for your contribution. Can you please sign CLA? Thanks!", "@nyadla-sys Can you please sign CLA and resolve conflicts? Thanks!", "@nyadla-sys can you please check latest comments from @njeffrie ", "@rthadur @njeffrie \r\nBhanu uploaded new PR and I am going to take off this pull request\r\nhttps://github.com/tensorflow/tensorflow/pull/39691\r\n"]}, {"number": 39559, "title": "ImportError: cannot import name 'tf2' which type of error is that                                          tensorflow version=1.12 and python version=3.7", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**:\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with:\r\n\r\n```bash\r\npython -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"\r\n```\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["TF 1.12 is too old. Recommend switching to 1.15, 2.0, 2.1 or 2.2 (1.15 or 2.2 are the best)\r\n\r\nYou have not filled the issue template at all. Hence, closing the issue. Please open a new one if you still have issues on the recommended versions and please flll in issue template when doing so.", "> \r\n> \r\n> TF 1.12 is too old. Recommend switching to 1.15, 2.0, 2.1 or 2.2 (1.15 or 2.2 are the best)\r\n> \r\n> You have not filled the issue template at all. Hence, closing the issue. Please open a new one if you still have issues on the recommended versions and please flll in issue template when doing so.\r\n\r\nHi, I'm having the same error even though i'm using tf 1.15... I just can't find any solution...\r\nI opened a new issue: https://github.com/tensorflow/models/issues/8572"]}, {"number": 39558, "title": "Tf Lite conversion error", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (or github SHA if from source): 2.1.0\r\n\r\n\r\n**Provide the text output from tflite_convert**\r\n\r\n```\r\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime and are not recognized by TensorFlow. If you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: FILL, FULLY_CONNECTED, PACK, RESHAPE, SHAPE, STRIDED_SLICE, TRANSPOSE. Here is a list of operators for which you will need custom implementations: TensorListFromTensor, TensorListReserve, TensorListStack, While.\r\n\r\n```\r\n\r\n**Standalone code to reproduce the issue** \r\nimport tensorflow as tf\r\nmodelIMU = tf.keras.Sequential()\r\n# inputs: A 3D tensor, with shape [batch, timesteps, feature].\r\nmodelIMU.add(GRU(3, input_shape=(2,6,),return_sequences=True))\r\nmodelIMU.add(GRU(3))\r\nmodelIMU.add(Dense(6))\r\nmodelIMU.compile(loss='mean_squared_error', optimizer='adam')\r\nprint(modelIMU.summary())\r\n\r\nconverter = tf.lite.TFLiteConverter.from_saved_model('modelIMU')\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,\r\n                                       tf.lite.OpsSet.SELECT_TF_OPS]\r\nquantized_model = converter.convert()\r\nopen(\"modelIMU.tflite\", \"wb\").write(quantized_model)\r\nAlso, please include a link to a GraphDef or the model if possible.\r\n\r\n**Any other info / logs**\r\n\r\nInclude any logs or source code that would be helpful to diagnose the problem.\r\nIf including tracebacks, please include the full traceback. Large logs and files\r\nshould be attached.\r\n", "comments": ["@imranmomtaz \r\nCould you please refer to below issues with similar error and let us know if it helps.\r\n#33490 #29117 #33393 #31844 #[link](https://stackoverflow.com/questions/58069572/workaround-for-lack-of-broadcast-in-tflite) #37134 #32206 #35008 #35818 #33515  #33059", "Hello, I was able to solve the problem with the help of https://github.com/tensorflow/tensorflow/issues/34266#issuecomment-554376129. Thanks."]}, {"number": 39557, "title": "Error in tflite conversion", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (or github SHA if from source): 2.0.0\r\n\r\n\r\n**Provide the text output from tflite_convert**\r\n\r\n```\r\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: FILL, FULLY_CONNECTED, PACK, RESHAPE, SHAPE, STRIDED_SLICE, TRANSPOSE. Here is a list of operators for which you will need custom implementations: TensorListFromTensor, TensorListReserve, TensorListStack, While.\r\nTraceback (most recent call last):\r\n  File \"/home/momtaz/PycharmProjects/untitled2/venv/bin/toco_from_protos\", line 10, in <module>\r\n    sys.exit(main())\r\n  File \"/home/momtaz/PycharmProjects/untitled2/venv/lib/python3.6/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 93, in main\r\n    app.run(main=execute, argv=[sys.argv[0]] + unparsed)\r\n  File \"/home/momtaz/PycharmProjects/untitled2/venv/lib/python3.6/site-packages/tensorflow_core/python/platform/app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"/home/momtaz/PycharmProjects/untitled2/venv/lib/python3.6/site-packages/absl/app.py\", line 299, in run\r\n    _run_main(main, args)\r\n  File \"/home/momtaz/PycharmProjects/untitled2/venv/lib/python3.6/site-packages/absl/app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"/home/momtaz/PycharmProjects/untitled2/venv/lib/python3.6/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 56, in execute\r\n    enable_mlir_converter)\r\nException: We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md\r\n and pasting the following:\r\n\r\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: FILL, FULLY_CONNECTED, PACK, RESHAPE, SHAPE, STRIDED_SLICE, TRANSPOSE. Here is a list of operators for which you will need custom implementations: TensorListFromTensor, TensorListReserve, TensorListStack, While.\r\n\r\n```\r\n\r\n**Standalone code to reproduce the issue** \r\nimport tensorflow as tf\r\nconverter = tf.lite.TFLiteConverter.from_saved_model('models/modelIMU')\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nquantized_model = converter.convert()\r\nopen(\"modelIMU.tflite\", \"wb\").write(quantized_model)\r\n\r\nAlso, please include a link to a GraphDef or the model if possible.\r\n\r\n**Any other info / logs**\r\n\r\nInclude any logs or source code that would be helpful to diagnose the problem.\r\nIf including tracebacks, please include the full traceback. Large logs and files\r\nshould be attached.\r\n", "comments": ["@can you please share a standalone code to reproduce the issue? or share the model. Thanks!", "Hello, I was able to solve this with the suggestion https://github.com/tensorflow/tensorflow/issues/34266#issuecomment-554376129. Thanks."]}]