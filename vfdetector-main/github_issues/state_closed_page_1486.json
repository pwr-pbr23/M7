[{"number": 8360, "title": "bug in cudnn  for cnn?", "body": "tensorflow 1.0\r\ncuda 8.0\r\ncudnn 5.0\r\n\r\ninstall method:\r\npip install --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-1.0.1-cp27-none-linux_x86_64.whl \r\n\r\nwhen  I run the  models/tutorials/image/mnist/convolutional.py\r\nI got:\r\nE tensorflow/stream_executor/cuda/cuda_dnn.cc:390]Loaded runtime CuDNN library: 5005 (compatibility version 5000) but source was compiled with 5110 (compatibility version 5100).  If using a binary install, upgrade your CuDNN library to matchIf building from sources, make sure the library loaded at runtime matches a compatible version specified during compile configuration.\r\nF tensorflow/core/kernels/conv_ops.cc:605] Check failed: stream->parent()->GetConvolveAlgorithms(&algorithms) \r\nAborted\r\n\r\nI thought it may be the cudnn, I load cudnn5110 and export it to LD_LIBURARY_PATH\r\nbut I  got another problem:\r\nE tensorflow/stream_executor/cuda/cuda_dnn.cc:397] could not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZED\r\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:363] driver version file contents: \"\"\"NVRM version: NVIDIA UNIX x86_64 Kernel Module  361.62  Tue May 24 20:21:31 PDT 2016\r\nGCC version:  gcc version 4.8.5 20150623 (Red Hat 4.8.5-4) (GCC) \r\n\"\"\"\r\nI tensorflow/stream_executor/cuda/cuda_dnn.cc:408] running driver version: 361.62.0\r\nE tensorflow/stream_executor/cuda/cuda_dnn.cc:364] could not destroy cudnn handle: CUDNN_STATUS_BAD_PARAM\r\nF tensorflow/core/kernels/conv_ops.cc:605] Check failed: stream->parent()->GetConvolveAlgorithms(&algorithms) \r\nAborted (core dumped)\r\n\r\nHow can i fix this problem?\r\n\r\nit's the driver's problem ? ", "comments": ["Please fill all of the issue template when filing issues.\r\n\r\nMoreover, TensorFlow does not have official support for RedHat.\r\nTherefore, I will mark this issue Community Support.\r\nYou can probably get more help on this through stackoverflow.\r\n", "@gunan thanks for ur attention.  I solved this problem already. I down load the  cudnn5110 for cuda7.5 but not for 8.0 , and use it with my cuda8.0, it works.  But I don't know why this can work "]}, {"number": 8359, "title": "tf.layers.conv3d_transpose missing", "body": "In tf.layers, there are conv2d and conv2d_transpose. There is conv3d, but no conv3d_transpose. \r\n\r\nI'm wondering if it is possible to have conv3d_transpose any time soon. \r\n\r\nThanks,", "comments": ["Hi, I'm taking this issue up. Please expect a PR soon. :smile:"]}, {"number": 8358, "title": "Fixing function path for 'bow_encoder' -- Closes #8353", "body": "", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please", "PR merged. Thank you for the fix, @MicaelCarvalho !"]}, {"number": 8357, "title": "Fix for compilation error in OS/X, due to size mismatch", "body": "See https://github.com/tensorflow/tensorflow/issues/8238\r\n\r\nError was:\r\n\r\n```\r\ntensorflow/compiler/xla/service/allocation_tracker.cc:178:54: error: non-constant-expression cannot be narrowed from type 'std::vector<se::DeviceMemoryBase>::size_type' (aka 'unsigned long') to 'long long' in initializer list [-Wc++11-narrowing]\r\n        ShapeUtil::GetSubshape(allocation->shape(), {i}),\r\n                                                     ^\r\ntensorflow/compiler/xla/service/allocation_tracker.cc:178:54: note: insert an explicit cast to silence this issue\r\n        ShapeUtil::GetSubshape(allocation->shape(), {i}),\r\n                                                     ^\r\n                                                     static_cast<long long>( )\r\n1 error generated.\r\n```\r\n\r\n\r\n", "comments": ["Can one of the admins verify this patch?", "No = your change includes this one."]}, {"number": 8356, "title": "Create hello.txt", "body": "", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->"]}, {"number": 8355, "title": "tensorflow's textsum model has version compatibile issue", "body": "Hi there,\r\n\r\nI installed tensorflow and tried its textsum model. Unfortunately, I hit lots of module has not attribute issues. I used release version it does not compatible with textsum model in github master branch. I build tensorflow from source from master branch. But, there are still lots of version compatible issues. \r\n\r\nAnyone here tried this model before? I need to find a release of tesnsorflow and textsum model and they are compatible. \r\n\r\nAlso, does this model work with tensorflow CPU (not GPU) edition?\r\n\r\nthanks in advance!\r\n\r\nYiyu ", "comments": ["/cc @panyx0718 \r\n\r\n@YiyuJia: did you try using TensorFlow 1.0 with the master branch version of textsum?", "yes. I tried. \r\npip install --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.10.0rc0-cp35-cp35m-linux_x86_64.whl\r\n\r\n\r\nI also tried master branch version of tesnsorflow. \r\n\r\nI tried upgrade script too. https://www.tensorflow.org/install/migration \r\n\r\nPlease let me know which version of tensorflow is compatible with master branch textsum or which version of textsum model is compatible with which version of tensorflow. \r\n\r\nmany thanks!\r\n", "This is a models issue, not a tensorflow issue."]}, {"number": 8354, "title": "Test8 file missing in word2vec_basic file", "body": "Test File (test8.zip) is missing the location http://mattmahoney.net/dc/", "comments": ["If anyone needs it while the link gets fixed: \r\n- https://www.dropbox.com/s/34ln5b6sqbwroam/text8.zip?dl=0\r\n- wget http://francky.me/files/text8.zip"]}, {"number": 8353, "title": "Error while running TextClassification in examples", "body": "Getting error\r\nmodule 'tensorflow.contrib.layers' has no attribute 'bow_encoder'\r\nif running bag of words model", "comments": ["This function is inside `tensorflow.contrib.layers.python.layers`.\r\n\r\nYou should run:\r\n```\r\nfrom tensorflow.contrib.layers.python.layers import encoders\r\nencoders.bow_encoder\r\n```\r\n\r\nThese kind of questions are better addressed at [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow), the GitHub is used for bug reporting mainly. And when bug reporting, please follow guidelines for your post \u2014 filling all the required fields when opening a new Issue.", "Raised it here since it is a bug in the code . code does not have the import correctly"]}, {"number": 8352, "title": "GPU memory problem when using tensorflow 1.0.0 on TITAN X (Pascal) ", "body": "### Environment info\r\nOperating System: Fedora 25\r\ncuda 8.0 and cuDNN 5.1\r\nTITAN X (Pascal) and Driver Version: 375.26\r\n\r\nI installed tensorflow 1.0.0 using pip install under anaconda\r\nhttps://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-1.0.1-cp27-none-linux_x86_64.whl\r\n\r\nI have a problem when using tensorflow on TITAN X (Pascal) . I am able to ran my code on other type of GPUs. I also tried running theano and matconvnet on the same GPU but there is no problem.\r\n\r\nI tried several ways to check it.\r\n1. if I directly run sess = tf.Session(), it gets stuck there.\r\n\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\r\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: \r\nname: TITAN X (Pascal)\r\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.531\r\npciBusID 0000:01:00.0\r\nTotal memory: 11.90GiB\r\nFree memory: 10.97GiB\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: TITAN X (Pascal), pci bus id: 0000:01:00.0)\r\nKilled\r\n\r\n2. I also tried to set allow_growth=True and it is able to run tf.Session.\r\ngpu_options= tf.GPUOptions(allow_growth=True)\r\ntf_config = tf.ConfigProto(allow_soft_placement=True, log_device_placement=True, gpu_options=gpu_options)\r\nsess = tf.Session(config=tf_config)\r\n\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\r\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: \r\nname: TITAN X (Pascal)\r\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.531\r\npciBusID 0000:01:00.0\r\nTotal memory: 11.90GiB\r\nFree memory: 10.97GiB\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: TITAN X (Pascal), pci bus id: 0000:01:00.0)\r\nDevice mapping:\r\n/job:localhost/replica:0/task:0/gpu:0 -> device: 0, name: TITAN X (Pascal), pci bus id: 0000:01:00.0\r\nI tensorflow/core/common_runtime/direct_session.cc:257] Device mapping:\r\n/job:localhost/replica:0/task:0/gpu:0 -> device: 0, name: TITAN X (Pascal), pci bus id: 0000:01:00.0\r\n\r\nI check the GPU memory being used, it is 151MB.\r\n\r\n3. I also tried to allocate different amount of GPU memory in the following way and it crashed.\r\ntf_config = tf.ConfigProto()\r\ntf_config.gpu_options.per_process_gpu_memory_fraction = 0.1\r\nsess = tf.Session(config=tf_config)\r\n\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\r\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: \r\nname: TITAN X (Pascal)\r\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.531\r\npciBusID 0000:01:00.0\r\nTotal memory: 11.90GiB\r\nFree memory: 10.97GiB\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: TITAN X (Pascal), pci bus id: 0000:01:00.0)\r\nterminate called after throwing an instance of 'std::system_error'\r\n  what():  Resource temporarily unavailable\r\nAborted (core dumped)\r\n\r\nCan anyone help me on this? Thanks a lot.", "comments": ["It seems you either have TF installation problems or driver issues. I have a similar setup (X Pascal + Debian) running without problems.\r\n\r\nCould you try installing the package directly from pip? With `pip3 install --upgrade tensorflow-gpu` for python3 or `pip install --upgrade tensorflow-gpu` for python2.7. Also, run `nvidia-smi` to see if the driver was installed correctly (possibly it can work with a broken driver installation, but this will detect at least the basic problems).", "Thank you for your reply. I run nvidia-smi and here is the output.\r\nMon Mar 13 14:42:23 2017       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 375.26                 Driver Version: 375.26                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  TITAN X (Pascal)    On   | 0000:01:00.0      On |                  N/A |\r\n| 36%   57C    P2    57W / 250W |    853MiB / 12189MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID  Type  Process name                               Usage      |\r\n|=============================================================================|\r\n|    0      9695    C   .../visics/rdegeest/torch/install/bin/luajit   427MiB |\r\n|    0     16304    G   /usr/bin/krunner                                 2MiB |\r\n|    0     16305    G   /usr/bin/plasmashell                            59MiB |\r\n|    0     16358    G   /usr/bin/korgac                                  3MiB |\r\n|    0     16633    G   /usr/bin/akonadi_archivemail_agent               3MiB |\r\n|    0     16643    G   /usr/bin/akonadi_mailfilter_agent                3MiB |\r\n|    0     16651    G   /usr/bin/akonadi_newmailnotifier_agent           3MiB |\r\n|    0     16652    G   /usr/bin/akonadi_notes_agent                     3MiB |\r\n|    0     16656    G   /usr/bin/akonadi_sendlater_agent                 3MiB |\r\n|    0     16930    G   ...nnectMore/Enabled/PreferHtmlOverPlugins/E   210MiB |\r\n|    0     24746    G   /usr/libexec/Xorg                              131MiB |\r\n+-----------------------------------------------------------------------------+\r\n\r\nWith the current tensorflow installation, I do not have problem when running it on machines with other type of GPUs. And as you can see here, torch is able to run on this GPU. I feel very confused about this problem.", "I found these 3 issues with similar messages: #3470, #2416, #1658 (two memory-related and one of thread limits). Could you try checking their approaches, to see if it works for you? Particularly the last, could be easily solvable if thread limit is the problem.", "Thank you for your help. I checked the three issues. I think mine is similar to #2416. But I did not find solution there. ", "Hi @MicaelCarvalho , I find where the problem is. Actually, it is because of our administrator set a limit to virtual memory. When I increase the limit value or set it to unlimited, it works. Thanks a lot for your help.", "Hi @stephenjia ,I have the same problem with you.But I don not know how many virtury memory to increase,Will virtual memory be twice the size of memory?Becaues My Linux partition spaces are not enough\uff0chow to expand swap partition in Ubuntu 16.04 dual-boot system(Windows10 &Ubuntu16.04)?\r\nCan you help me on these? Thanks a lot."]}, {"number": 8351, "title": "how to avoid generating large metagraph?", "body": "\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\n\r\nx_nparray = $VERY_LARGE_NP_ARRAY(bigger than 2G)\r\n\r\nx = tf.Variable(init_value=x_nparray)\r\n\r\nsaver=tf.Saver()\r\nwith tf.Session() as sess:\r\n  saver.save(sess, 'path/to/save')\r\n\r\nthat would generate very large metagraph binary file, when i try to restore the model, it would failed because of the meta graph file size exceed  the protobuf limit size.\r\n\r\n\r\nI cannot reduce the size of x_nparray, because it's generated by other training system like caffe. \r\n\r\n### What other attempted solutions have you tried?\r\nset bigger limit byte of protobuf, however, the x_nparray is bigger than 3G, while the largest limit i can set is 2G. \r\n", "comments": ["By default, calling `tf.Saver()` will grab all variables currently in the graph.  Can you try to manipulate the [`var_list` argument](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/saver.py#L947) to exclude this large variable?", "i solve this problem, by an unusual way.  the  large variable is what i must keep for online inference.  however, i find it is interesting that the meta graph  save duplicate graphs in proto file.  specifically,  it has \"graph_def\" proto and \"serving_graph\" proto,  and i found remove serving_graph won't affect my online inference. also, i found the constant( such as numpy array,  python scalar variables ) used by the graph building process will saved in the meta graph as const tensor, this is the reason which make my meta graph proto very big.  i use tf.assign to inject my numpy array to the tensor variables and then remove the tf.assign op(with the constant tensor in meta graph) from the graph when i export the model ( i don't need the assign op in inference process ).   in this way, i reduce my meta graph to very small. ", "@bluekingsong glad to know you've found a workaround. Just for the record: indeed, the _actual values_ of constant Tensors are (unfortunately?) embedded in GraphDefs, whereas Variables don't have this issue."]}, {"number": 8350, "title": "Not able to run tensorflow with OpenBLAS support", "body": "Hi,\r\n\r\nIm trying to use OpenBLAS for gemm operations instead of EIGEN with tensorflow.\r\nI have followed the steps given in \r\nhttp://eigen.tuxfamily.org/dox-devel/TopicUsingBlasLapack.html\r\n\r\nand compiled the tensoflow android demo application with -DEIGEN_USE_BLAS support and have linked the libopenblas.a to EIGEN by placing the OpenBLAS headers and static library in eigen_archive along with BUILD file.\r\n****The BUILD File of OpenBLAS is as follows**:**\r\n\r\nlicenses([\"notice\"])\r\n\r\n cc_library(\r\n      name = \"openblas\",\r\n      hdrs = glob([\"include/*.h\"]),\r\n      srcs = [\"lib/libopenblas.a\"],\r\n      visibility = [\"//visibility:public\"],\r\n  )\r\n\r\nThe BUILD file of EIGEN has been appended to include and link the openblas library as follows:\r\n cc_library(\r\n     name = \"eigen\",\r\n     hdrs = EIGEN_MPL2_HEADER_FILES,\r\n     defines = [\r\n         # This define (mostly) guarantees we don't link any problematic\r\n         # code. We use it, but we do not rely on it, as evidenced above.\r\n         \"EIGEN_MPL2_ONLY\",\r\n     ],\r\n     includes = [\".\"],\r\n     copts = [\"-IOpenBLAS/include\"],\r\n     deps = [\"//OpenBLAS:openblas\"],\r\n     visibility = [\"//visibility:public\"],\r\n )\r\n\r\nThe build is given as follows:\r\nbazel build --copt=-DEIGEN_USE_BLAS --fat_apk_cpu=arm64-v8a //tensorflow/examples/android:tensorflow_demo --verbose_failures\r\n\r\nThe Build is completed successfully and im able to run the apks installed on the target. But the print statements which i have put in OpenBLAS and Eigen/src/Core/products/GeneralMatrixMatrix_BLAS.h using android logging LOGI or LOGD doesnt get displayed in logcat of the device.\r\n\r\nThe Build fails if i dont link the openblas library in EIGEN BUILD file and use  -DEIGEN_USE_BLAS, which shows that libopenblas is getting linked to EIGEN.\r\n\r\nCan you please suggest what is the problem in the above procedure ?\r\nHow can we validate OpenBLAS is actually getting used?", "comments": ["BTW, as a meta-comment, Eigen is quite deeply integrated with TensorFlow. An alternative to replacing Eigen for some functionality, would be to add new op which calls OpenBLAS explicitly. This is what's done for MKL integration of matmul -- https://github.com/tensorflow/tensorflow/pull/7333", "This is also interesting https://github.com/ARM-software/ComputeLibrary/issues/7", "Hi, did you solve this problem?", "Hello, we are moving support issues from GitHub to StackOverflow. This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow). It is easier for users to discover support isssues on StackOverflow. There is also a larger community that reads questions there. I will close the issue here. Please post it on StackOverflow.\r\n"]}, {"number": 8349, "title": "/tutorials/using_gpu doc (possibly other) should use print() since Windows needs Python 3.x", "body": "Should the Python samples in /tutorials/using_gpu and other docs be in 3.5.x form?\r\n\r\n* In /install/install_windows we're told \"TensorFlow only supports version 3.5.x of Python on Windows\"\r\n* In /tutorials/using_gpu there is sample Python code in 2.x style, \"print sess.run(c)\"\r\n* This code snippet chokes when run on Windows, while print(sess.run(c)) is fine. Trivial to fix but distracts from the task at hand.\r\n\r\nThere may be more nuance to this (afaik print with parens is ok in 2.7), but it seems like avoidable friction if not.\r\n\r\n", "comments": ["TF is mostly used on linux-based systems, it seems natural to have code written for python 2.7, since TF supports this version of python outside Windows. I do agree with you, however, that at least the `print` functions could be written with parenthesis, just to avoid those simple incompatibility issues. I'm not part of the team, but I believe TF members wouldn't oppose the change, if you send a pull request with them.", "Not a big deal, haven't find any other error under python3.", "We currently don't have anybody working on this. It would be great if you could help us by working on this and submitting a PR. Let us know if you need further clarification. Thanks!", "Hi all, I just submitted a PR to fix this issue, please review, thanks a lot \ud83d\ude04 ", "Thanks @jerryshao!"]}, {"number": 8348, "title": "Taking gradients after using SparseTensor in while_loop leads to TypeError", "body": "### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\n\r\nFound various issues on SparseTensors, but nothing about while loops and gradients.\r\n\r\n\r\n### Environment info\r\nOperating System:\r\nUbuntu 14.04\r\n\r\nInstalled version of CUDA and cuDNN: \r\nNone\r\n\r\nIf installed from binary pip package, provide:\r\n\r\n1. A link to the pip package you installed: https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.12.1-cp35-cp35m-linux_x86_64.whl\r\n\r\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`: \r\n0.12.1\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\n\r\nThis code leads to the error (when trying to compute the gradients) `TypeError: Expected binary or unicode string, got <tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7fb966845f98>`\r\n```\r\nimport tensorflow as tf\r\n\r\n\r\ndef body(A, b, x, i):\r\n    i += 1\r\n    b = b + tf.sparse_tensor_dense_matmul(A, x)\r\n    return A, b, x, i\r\n\r\n\r\ndef cond(A, b, x, i):\r\n    return i < 5\r\n\r\n\r\nsess = tf.InteractiveSession()\r\nindices = [[0, 0], [1, 1]]\r\nvalues = [1., 1.]\r\nA = tf.SparseTensor(indices, values, (100, 100))\r\nx = tf.ones((100, 1))\r\nb = tf.zeros_like(x)\r\n[_, b, _, _] = tf.while_loop(cond, body, [A, b, x, tf.constant(0)])\r\ngrad = tf.gradients(b, x)\r\nprint(sess.run([grad]))\r\nsess.close()\r\n```\r\n\r\n### What other attempted solutions have you tried?\r\n\r\nIf `A` is removed as a loop variable everything works as expected:\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\n\r\ndef body(b, x, i):\r\n    i += 1\r\n    b = b + tf.sparse_tensor_dense_matmul(A, x)\r\n    return b, x, i\r\n\r\n\r\ndef cond(b, x, i):\r\n    return i < 5\r\n\r\n\r\nsess = tf.InteractiveSession()\r\nindices = [[0, 0], [1, 1]]\r\nvalues = [1., 1.]\r\nA = tf.SparseTensor(indices, values, (100, 100))\r\nx = tf.ones((100, 1))\r\nb = tf.zeros_like(x)\r\n[b, _, _] = tf.while_loop(cond, body, [b, x, tf.constant(0)])\r\ngrad = tf.gradients(b, x)\r\nprint(sess.run([grad]))\r\nsess.close()\r\n```\r\n\r\n\r\n### Logs or other output that would be helpful\r\n(If logs are large, please upload as attachment or provide link).\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"sparse_tensor_gradient_error.py\", line 21, in <module>\r\n    grad = tf.gradients(b, x)\r\n  File \"/home/y/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py\", line 427, in gradients\r\n    _SetGrad(grads, y, loop_state.ZerosLikeForExit(y))\r\n  File \"/home/y/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 1165, in ZerosLikeForExit\r\n    result = array_ops.zeros_like(val, optimize=False)\r\n  File \"/home/y/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\", line 1471, in zeros_like\r\n    tensor = ops.convert_to_tensor(tensor, name=\"tensor\")\r\n  File \"/home/y/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 669, in convert_to_tensor\r\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n  File \"/home/y/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py\", line 176, in _constant_tensor_conversion_function\r\n    return constant(v, dtype=dtype, name=name)\r\n  File \"/home/y/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py\", line 165, in constant\r\n    tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape, verify_shape=verify_shape))\r\n  File \"/home/y/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/tensor_util.py\", line 441, in make_tensor_proto\r\n    tensor_proto.string_val.extend([compat.as_bytes(x) for x in proto_values])\r\n  File \"/home/y/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/tensor_util.py\", line 441, in <listcomp>\r\n    tensor_proto.string_val.extend([compat.as_bytes(x) for x in proto_values])\r\n  File \"/home/y/anaconda3/lib/python3.5/site-packages/tensorflow/python/util/compat.py\", line 65, in as_bytes\r\n    (bytes_or_text,))\r\nTypeError: Expected binary or unicode string, got <tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7fb966845f98>\r\n```\r\n", "comments": ["Looks like worth looking into/fixing.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=8348\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=8348\">No</a>\n", "Looks like this was resolved in `TF1.15.5`. Please check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/00076bbceda2b8c1d5a3b8a69a2afd90/untitled.ipynb).\r\n\r\nI am closing this issue as this was resolved. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/8348\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/8348\">No</a>\n"]}, {"number": 8347, "title": "Quantize Neural Networks with TensorFlow doesn't work on my models", "body": "I'm following this [tutorial here](https://www.tensorflow.org/performance/quantization).\r\n\r\nAnd this code works fine.\r\n```\r\ncurl http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz -o /tmp/inceptionv3.tgz\r\ntar xzf /tmp/inceptionv3.tgz -C /tmp/\r\nbazel build tensorflow/tools/quantization/tools:quantize_graph\r\nbazel-bin/tensorflow/tools/quantization/tools/quantize_graph \\\r\n  --input=/tmp/classify_image_graph_def.pb \\\r\n  --output_node_names=\"softmax\" --output=/tmp/quantized_graph.pb \\\r\n  --mode=eightbit\r\n```\r\n\r\nBut when I try with another .pb it does not work, it tells me that the output node does not exist.\r\n\r\n**With non frozen .pb**\r\n```\r\nTraceback (most recent call last):\r\n  File \"/sandbox/tensorflow/bazel-bin/tensorflow/tools/quantization/quantize_graph.runfiles/org_tensorflow/tensorflow/tools/quantization/quantize_graph.py\", line 1304, in <module>\r\n    app.run()\r\n  File \"/sandbox/tensorflow/bazel-bin/tensorflow/tools/quantization/quantize_graph.runfiles/org_tensorflow/tensorflow/python/platform/app.py\", line 44, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"/sandbox/tensorflow/bazel-bin/tensorflow/tools/quantization/quantize_graph.runfiles/org_tensorflow/tensorflow/tools/quantization/quantize_graph.py\", line 1271, in main\r\n    tf_graph.ParseFromString(data)\r\n  File \"/usr/local/lib/python2.7/dist-packages/google/protobuf/message.py\", line 185, in ParseFromString\r\n    self.MergeFromString(serialized)\r\n  File \"/usr/local/lib/python2.7/dist-packages/google/protobuf/internal/python_message.py\", line 1091, in MergeFromString\r\n    if self._InternalParse(serialized, 0, length) != length:\r\n  File \"/usr/local/lib/python2.7/dist-packages/google/protobuf/internal/python_message.py\", line 1117, in InternalParse\r\n    new_pos = local_SkipField(buffer, new_pos, end, tag_bytes)\r\n  File \"/usr/local/lib/python2.7/dist-packages/google/protobuf/internal/decoder.py\", line 850, in SkipField\r\n    return WIRETYPE_TO_SKIPPER[wire_type](buffer, pos, end)\r\n  File \"/usr/local/lib/python2.7/dist-packages/google/protobuf/internal/decoder.py\", line 820, in _RaiseInvalidWireType\r\n    raise _DecodeError('Tag had invalid wire type.')\r\ngoogle.protobuf.message.DecodeError: Tag had invalid wire type.\r\n\r\n```\r\n\r\n**With frozen .pb**\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/sandbox/tensorflow/bazel-bin/tensorflow/tools/quantization/quantize_graph.runfiles/org_tensorflow/tensorflow/tools/quantization/quantize_graph.py\", line 1304, in <module>\r\n    app.run()\r\n  File \"/sandbox/tensorflow/bazel-bin/tensorflow/tools/quantization/quantize_graph.runfiles/org_tensorflow/tensorflow/python/platform/app.py\", line 44, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"/sandbox/tensorflow/bazel-bin/tensorflow/tools/quantization/quantize_graph.runfiles/org_tensorflow/tensorflow/tools/quantization/quantize_graph.py\", line 1295, in main\r\n    output_graph = rewriter.rewrite(FLAGS.output_node_names.split(\",\"))\r\n  File \"/sandbox/tensorflow/bazel-bin/tensorflow/tools/quantization/quantize_graph.runfiles/org_tensorflow/tensorflow/tools/quantization/quantize_graph.py\", line 400, in rewrite\r\n    for output_node_name in output_node_names\r\nKeyError: 'my_output_node'\r\n```\r\n\r\nI'm sure the output_node_names is correct.\r\n\r\nIs there any requirements on the .pb file so the tool can quantize it ?\r\n\r\nnb: one should edit the doc because the tool is no longer in `tensorflow/tools/quantization/tools:quantize_graph` but `tensorflow/tools/quantization:quantize_graph`\r\n\r\n", "comments": ["@petewarden could you take a look?", "Me too had the same issue, because I gave wrong name in \"output_node_names\". Otherwise, it worked fine. And the tool worked fine for my own network stored as frozen .pb file. Are you sure you passed all the four params correctly, especially the output_node_names?", "Same problem here, I get `KeyError: 'output'` (`output`) is the name of my output node. I am using a frozen .pb", "I'm getting this issue also, I've confirmed that I'm using the right output names by using the summarize graph tool mentioned here https://github.com/thtrieu/darkflow/issues/143#issuecomment-292825749", "I figured out the source of the error. I was using `tf.identity` ops to name my output tensors. The call to `graph_util.remove_training_nodes` on line 413 in `quantize_graph.py` removes all identity ops from the graph causing a KeyError. Apparently,\r\n\r\n> \"There are nodes like Identity and CheckNumerics that are only useful\r\n>   during training, and can be removed in graphs that will be used for\r\n>   nothing but inference. Here we identify and remove them, returning an\r\n>   equivalent graph. To be specific, CheckNumerics nodes are always removed, and\r\n>   Identity nodes that aren't involved in control edges are spliced out so that\r\n>   their input and outputs are directly connected.\"\r\n\r\nfrom the comment on tensorflow/python/framework/graph_util_impl.py\r\n\r\nI don't know what the best workaround would be, for now I'm just going to change line 417 from `self.set_input_graph(graph_util.remove_training_nodes(self.input_graph))` to `self.set_input_graph(self.input_graph)`\r\n\r\nAs far as I know there are no CheckNumeric ops in my network and the only identity calls are the output nodes, so hopefully this won't affect much.\r\n", "Glad you found a workaround!"]}, {"number": 8346, "title": "I can't compile tensorflow on Ubuntu 16.10 ", "body": "I have given these commands to compile tensorflow:\r\n`sudo apt-get install python-numpy python-dev python-pip python-wheel`\r\n\r\n`sudo apt-get install python3-numpy python3-dev python3-pip python3-wheel`\r\n\r\n`git clone https://github.com/tensorflow/tensorflow `\r\n\r\n`cd tensorflow/`\r\n\r\n`git checkout r1.0`\r\n\r\n`./configure`\r\n\r\n`bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package --verbose_failures`\r\n\r\nIt gives this error:\r\n\r\n> ERROR: /home/raspberry/tensorflow/tensorflow/core/kernels/BUILD:2468:1: C++ compilation of rule '//tensorflow/core/kernels:bias_op' failed: gcc failed: error executing command \r\n  (cd /home/raspberry/.cache/bazel/_bazel_raspberry/e683ea6480b94d5dcdb0f13cb220eff8/execroot/tensorflow && \\\r\n  exec env - \\\r\n  /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections '-march=native' '-std=c++0x' '-march=native' -MD -MF bazel-out/local-py3-opt/bin/tensorflow/core/kernels/_objs/bias_op/tensorflow/core/kernels/bias_op.pic.d '-frandom-seed=bazel-out/local-py3-opt/bin/tensorflow/core/kernels/_objs/bias_op/tensorflow/core/kernels/bias_op.pic.o' -fPIC -DEIGEN_MPL2_ONLY -DTENSORFLOW_USE_JEMALLOC -iquote . -iquote bazel-out/local-py3-opt/genfiles -iquote external/bazel_tools -iquote bazel-out/local-py3-opt/genfiles/external/bazel_tools -iquote external/eigen_archive -iquote bazel-out/local-py3-opt/genfiles/external/eigen_archive -iquote external/local_config_sycl -iquote bazel-out/local-py3-opt/genfiles/external/local_config_sycl -iquote external/jemalloc -iquote bazel-out/local-py3-opt/genfiles/external/jemalloc -iquote external/protobuf -iquote bazel-out/local-py3-opt/genfiles/external/protobuf -iquote external/gif_archive -iquote bazel-out/local-py3-opt/genfiles/external/gif_archive -iquote external/jpeg -iquote bazel-out/local-py3-opt/genfiles/external/jpeg -iquote external/com_googlesource_code_re2 -iquote bazel-out/local-py3-opt/genfiles/external/com_googlesource_code_re2 -iquote external/farmhash_archive -iquote bazel-out/local-py3-opt/genfiles/external/farmhash_archive -iquote external/highwayhash -iquote bazel-out/local-py3-opt/genfiles/external/highwayhash -iquote external/png_archive -iquote bazel-out/local-py3-opt/genfiles/external/png_archive -iquote external/zlib_archive -iquote bazel-out/local-py3-opt/genfiles/external/zlib_archive -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/eigen_archive -isystem bazel-out/local-py3-opt/genfiles/external/eigen_archive -isystem external/jemalloc/include -isystem bazel-out/local-py3-opt/genfiles/external/jemalloc/include -isystem external/protobuf/src -isystem bazel-out/local-py3-opt/genfiles/external/protobuf/src -isystem external/gif_archive/lib -isystem bazel-out/local-py3-opt/genfiles/external/gif_archive/lib -isystem external/farmhash_archive/src -isystem bazel-out/local-py3-opt/genfiles/external/farmhash_archive/src -isystem external/highwayhash -isystem bazel-out/local-py3-opt/genfiles/external/highwayhash -isystem external/png_archive -isystem bazel-out/local-py3-opt/genfiles/external/png_archive -isystem external/zlib_archive -isystem bazel-out/local-py3-opt/genfiles/external/zlib_archive -DEIGEN_AVOID_STL_ARRAY -Iexternal/gemmlowp -Wno-sign-compare -fno-exceptions -pthread -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -c tensorflow/core/kernels/bias_op.cc -o bazel-out/local-py3-opt/bin/tensorflow/core/kernels/_objs/bias_op/tensorflow/core/kernels/bias_op.pic.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 4.\r\ngcc: internal compiler error: Killed (program cc1plus)\r\nPlease submit a full bug report,\r\nwith preprocessed source if appropriate.\r\nSee <file:///usr/share/doc/gcc-6/README.Bugs> for instructions.\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 15812.554s, Critical Path: 15700.39s\r\n\r\nVersion of bazel:\r\n\r\nBuild label: 0.4.4\r\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Wed Feb 1 18:54:21 2017 (1485975261)\r\nBuild timestamp: 1485975261\r\nBuild timestamp as int: 1485975261\r\n\r\n", "comments": ["I use ubuntu 16.04 , and in tensorflow's official website, ubuntu 14.04 and ubuntu 16.04 are supported. How about using these command:\r\n**sudo pip install tensorflow**", "I'm afraid that's a bug in gcc. Can you print `gcc --version`? Is this the gcc was came default with the system?\r\n\r\n@rmlarsen @benoitsteiner maybe it's related to eigen?\r\n@gunan if this is the stock gcc coming with ubuntu 16, we should probably try to have a workaround.", "Looks like gcc crashed when compiling `tensorflow/core/kernels/bias_op.cc`\r\nI agree that we need to have TF building on stock compilers. So I am happy to accept a workaround (currently busy with other things, so I wont be able to debug this myself).", "I've found a solution for this issue. I have increased memory of virtualbox virtual machine. I made it 5gb. So then I compiled tensorflow without problem.", "Oh, good to know. Definitely a template expansion artifact.\r\n\r\nI'm closing this issue since we found the root cause. Thanks for reporting.", "> I've found a solution for this issue. I have increased memory of virtualbox virtual machine. I made it 5gb. So then I compiled tensorflow without problem.\r\n\r\nit works for me. thanks!"]}, {"number": 8345, "title": "How to Add Adam optimizer metrics to Tensorboard?", "body": "When I trained model for several epochs and want to retrain it again for more epochs. How would Adam optimizer work. will it initialize the time from t =0 or will it save the last time step?  \r\n\r\na) The documentation in tensorflow shows the following calculations. Is there a away I can add these metrics to tensorboard. \r\n\r\n    t <- t + 1\r\n    lr_t <- learning_rate * sqrt(1 - beta2^t) / (1 - beta1^t)\r\n\r\n    m_t <- beta1 * m_{t-1} + (1 - beta1) * g\r\n    v_t <- beta2 * v_{t-1} + (1 - beta2) * g * g\r\n    variable <- variable - lr_t * m_t / (sqrt(v_t) + epsilon)\r\n\r\nI know this question need to be asked in stackoverflow . but there are no answers for a few questions since a long time [question1](http://stackoverflow.com/questions/36990476/getting-the-current-learning-rate-from-a-tf-train-adamoptimizer) and [question2](http://stackoverflow.com/questions/40752053/how-to-add-learning-rate-to-summaries).\r\n\r\nI am actually getting a problem with error rate when re-training the model from the last checkpoint and I was not sure what exactly is happening with Adam optimizer in this case ?", "comments": ["To monitor those values in TensorBoard, you can use `tf.summary.scalar()`.  Give it a try?", "No it is not working .", "Could you extract a minimum runnable code snippet to demonstrate the issue?  One quick thing to check is to see if there are any event files on-disk (those are used to render values in Tensorboard).", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 8344, "title": "Doesn't inefficient and unfriendly for Distributed tensorflow for our model training? ", "body": "If we want deployed tensorflow on our cluster, it is really inefficient in my opinion. As the official tutorial shows, how many task you have launched, then how many times you should run you program file on those nodes. \r\n\r\nAs our developers hope, tensorflow will be our Hadoop in Deep Learning. Hadoop to launch an job would be more convenient just execute once your job command. \r\n\r\nMaybe I doesn't use this framework correctly, if you have any good ideas for this, we can discussed an nice solution and make our world beautiful.\r\n", "comments": ["@jhseu maybe there is an ecosystem answer?\r\n\r\n@rhaertel80 for CloudML.", "We consider job setup not to be a responsibility of TensorFlow core. It's more suited to other things, like Kubernetes, Mesos, or Spark.\r\n\r\nTake a look at TensorFlow on Spark if you already have Spark cluster:\r\nhttps://github.com/yahoo/TensorFlowOnSpark\r\n\r\nOr if you're running Kubernetes, you can use a configuration from https://github.com/tensorflow/ecosystem", "OK\uff0cthis sounds reasonable, thanks @jhseu ", "If you're open to using cloud technologies, [Google Cloud Machine Learning Engine](https://cloud.google.com/ml-engine/) is a managed service that automatically brings up and takes down nodes for running your TensorFlow jobs. For an example of how simple it can be to launch your distributed TensorFlow job, see the [quickstart](https://cloud.google.com/ml-engine/docs/how-tos/getting-started-training-prediction#cloud-train-dist)."]}, {"number": 8343, "title": "The inputs of dynamic_rnn must be 3-D tensor?", "body": "hi,\r\n    I want to use _dynamic_rnn_ to train my convLSTM, the original data should be videos with dimension: [batch_size, max_time_step, high, width,channel]. But i failed to feed the data to dynamic_rnn.\r\nI get such error:\r\n`ValueError: Dimension must be 5 but is 3 for 'transpose' (op: 'Transpose') with input shapes: [16,?,11,40,1], [3].`\r\nwhat should i do to use dynamic rnn?\r\nversion: tf 1.0", "comments": ["If this isn't a bug, it will be better/faster answered on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) \u2014 the correct place to ask for help.\r\n\r\nIf this is a bug, please follow guidelines for reporting problems. When you click on \"New issue\" there is a template to be filled. It is very hard to reproduce your problem and check what's wrong if you don't provide the required information. For example, you did not provide a sample code for reproducing the problem. ;-)\r\n\r\nLooking just at your error message, I would say your input vector is wrongly formatted. Try printing it to see what's going on.", "This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!", "I spent much time debugging this issue in my own code and googling found this (NiHaoUCAS, this will possibly help you as well):\r\nhttp://stackoverflow.com/questions/42513613/tensorflow-dynamic-rnn-regressor-valueerror-dimension-mismatch\r\n\r\nFurther search in the github repository found this issue. It's obviously a pain point for users.\r\nEdit: note that one of the Google Brain developers answered in SO that it is a bug in one of the execution branches and that they are working on fixing it.", "/cc @ebrevdo (originally added `dynamic_rnn()`) & @mrry (who answered the SO question).", "I believe we have a fix in the works, can push it tomorrow.", "thanks a lot @ebrevdo ", "Many thanks @ebrevdo et al \ud83d\udc4d ", "@ebrevdo is this pushed?  Could you close the issue when the fix is in?  Thanks.", "hi,\r\nIs this fixed? \r\nWhen I run:\r\n```\r\nx = tf.placeholder(tf.float32, [1, 100, 9, 161])\r\ncell = rnn.BasicLSTMCell(1024)\r\noutput, state = tf.nn.dynamic_rnn(cell, x, dtype=tf.float32)\r\n```\r\nI get such error:\r\n```\r\nValueError: linear is expecting 2D arguments: [TensorShape([Dimension(1), Dimension(9), Dimension(161)]), TensorShape([Dimension(1), Dimension(1024)])]\r\n```\r\nversion: tf 1.4.1"]}, {"number": 8342, "title": "[TensorBoard] load data from relative path with the projector plugin", "body": "This is a  problem similar with issue #7382 but it has been closed.\r\n\r\n@dandelionmane \r\nAnother place that still has the similar problem in #7382 is the request of project plugin data in Embeddings panel, e.g.  /data/plugin/projector/runs still requests in a absolute path.\r\nI found the code  [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tensorboard/components/tf_tensorboard/tf-tensorboard.html#L134) , there is a leading slash for the `route-prefix` property in `vz-projector-dashboard`.\r\nIf that is correct, I will submit a PR. Thanks!\r\n\r\nAnother question is when will the tensorboard be recompiled. As now in version 1.0 these features are not included.\r\n", "comments": ["I migrated this to the new TensorBoard repository. https://github.com/tensorflow/tensorboard/issues/37"]}, {"number": 8341, "title": "when i use tensorflow v1.01  python3 there are SyntaxError: invalid syntax", "body": "when i use tensorflow-gpu v1.01  python3.5 there are SyntaxError: invalid syntax\r\nbut i only install tensorflow-gpu v1.01 python2.7 there are no  SyntaxError: invalid syntax\r\nlike i use tensorboard when i have installed tensorflow-gpu v1.01 python3.5\r\n\r\n #cy@cy:~/PycharmProjects/models-master/slim$ tensorboard --logdir=./\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally\r\nTraceback (most recent call last):\r\n  File \"/usr/local/bin/tensorboard\", line 7, in <module>\r\n    from tensorflow.tensorboard.tensorboard import main\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/tensorboard/tensorboard.py\", line 34, in <module>\r\n    from tensorflow.tensorboard.backend import server\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/tensorboard/backend/server.py\", line 38, in <module>\r\n    from tensorflow.tensorboard.plugins.projector import plugin as projector_plugin\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/tensorboard/plugins/projector/plugin.py\", line 27, in <module>\r\n    from tensorflow.contrib.tensorboard.plugins.projector import PROJECTOR_FILENAME\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/__init__.py\", line 29, in <module>\r\n    from tensorflow.contrib import factorization\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/factorization/__init__.py\", line 24, in <module>\r\n    from tensorflow.contrib.factorization.python.ops.gmm import *\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/factorization/python/ops/gmm.py\", line 32, in <module>\r\n    from tensorflow.contrib.learn.python.learn import graph_actions\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/__init__.py\", line 70, in <module>\r\n    from tensorflow.contrib.learn.python.learn import *\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/__init__.py\", line 23, in <module>\r\n    from tensorflow.contrib.learn.python.learn import *\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/__init__.py\", line 25, in <module>\r\n    from tensorflow.contrib.learn.python.learn import estimators\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/estimators/__init__.py\", line 310, in <module>\r\n    from tensorflow.contrib.learn.python.learn.estimators.dnn import DNNClassifier\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py\", line 29, in <module>\r\n    from tensorflow.contrib.learn.python.learn.estimators import dnn_linear_combined\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/estimators/dnn_linear_combined.py\", line 33, in <module>\r\n    from tensorflow.contrib.learn.python.learn.estimators import estimator\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 51, in <module>\r\n    from tensorflow.contrib.learn.python.learn.learn_io import data_feeder\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/learn_io/__init__.py\", line 21, in <module>\r\n    from tensorflow.contrib.learn.python.learn.learn_io.dask_io import extract_dask_data\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/learn_io/dask_io.py\", line 26, in <module>\r\n    import dask.dataframe as dd\r\n  File \"/home/cy/.local/lib/python3.5/site-packages/dask/dataframe/__init__.py\", line 3, in <module>\r\n    from .core import (DataFrame, Series, Index, _Frame, map_partitions,\r\n  File \"/home/cy/.local/lib/python3.5/site-packages/dask/dataframe/core.py\", line 11, in <module>\r\n    import pandas as pd\r\n  File \"/home/cy/.local/lib/python3.5/site-packages/pandas/__init__.py\", line 22, in <module>\r\n    from pandas.compat.numpy import *\r\n  File \"/home/cy/.local/lib/python3.5/site-packages/pandas/compat/__init__.py\", line 357, in <module>\r\n    from dateutil import parser as _date_parser\r\n  File \"/home/cy/.local/lib/python3.5/site-packages/dateutil/parser.py\", line 158\r\n    l.append(\"%s=%s\" % (attr, `value`))\r\n                              ^\r\nSyntaxError: invalid syntax\r\n\r\n\r\n#cy@cy:~/PycharmProjects/models-master/slim$ python3 train_image_classifier.py \r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally\r\nTraceback (most recent call last):\r\n  File \"train_image_classifier.py\", line 24, in <module>\r\n    from datasets import dataset_factory\r\n  File \"/home/cy/PycharmProjects/models-master/slim/datasets/dataset_factory.py\", line 21, in <module>\r\n    from datasets import cifar10\r\n  File \"/home/cy/PycharmProjects/models-master/slim/datasets/cifar10.py\", line 30, in <module>\r\n    slim = tf.contrib.slim\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/__init__.py\", line 35, in __getattr__\r\n    contrib = importlib.import_module('tensorflow.contrib')\r\n  File \"/usr/lib/python3.5/importlib/__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/__init__.py\", line 29, in <module>\r\n    from tensorflow.contrib import factorization\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/factorization/__init__.py\", line 24, in <module>\r\n    from tensorflow.contrib.factorization.python.ops.gmm import *\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/factorization/python/ops/gmm.py\", line 32, in <module>\r\n    from tensorflow.contrib.learn.python.learn import graph_actions\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/__init__.py\", line 70, in <module>\r\n    from tensorflow.contrib.learn.python.learn import *\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/__init__.py\", line 23, in <module>\r\n    from tensorflow.contrib.learn.python.learn import *\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/__init__.py\", line 25, in <module>\r\n    from tensorflow.contrib.learn.python.learn import estimators\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/estimators/__init__.py\", line 310, in <module>\r\n    from tensorflow.contrib.learn.python.learn.estimators.dnn import DNNClassifier\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py\", line 29, in <module>\r\n    from tensorflow.contrib.learn.python.learn.estimators import dnn_linear_combined\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/estimators/dnn_linear_combined.py\", line 33, in <module>\r\n    from tensorflow.contrib.learn.python.learn.estimators import estimator\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 51, in <module>\r\n    from tensorflow.contrib.learn.python.learn.learn_io import data_feeder\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/learn_io/__init__.py\", line 21, in <module>\r\n    from tensorflow.contrib.learn.python.learn.learn_io.dask_io import extract_dask_data\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/learn_io/dask_io.py\", line 26, in <module>\r\n    import dask.dataframe as dd\r\n  File \"/home/cy/.local/lib/python3.5/site-packages/dask/dataframe/__init__.py\", line 3, in <module>\r\n    from .core import (DataFrame, Series, Index, _Frame, map_partitions,\r\n  File \"/home/cy/.local/lib/python3.5/site-packages/dask/dataframe/core.py\", line 11, in <module>\r\n    import pandas as pd\r\n  File \"/home/cy/.local/lib/python3.5/site-packages/pandas/__init__.py\", line 22, in <module>\r\n    from pandas.compat.numpy import *\r\n  File \"/home/cy/.local/lib/python3.5/site-packages/pandas/compat/__init__.py\", line 357, in <module>\r\n    from dateutil import parser as _date_parser\r\n  File \"/home/cy/.local/lib/python3.5/site-packages/dateutil/parser.py\", line 158\r\n    l.append(\"%s=%s\" % (attr, `value`))\r\n                              ^\r\nSyntaxError: invalid syntax\r\n\r\n", "comments": ["It seems to be a bad installation, try reinstalling TF.\r\n\r\nAnd please follow guidelines for filling an issue: You did not provide most of the required information for a proper analysis of the problem (when you start a new issue, by default the template tells you what to do, you only have to fill in the fields, instead of erasing it all and writing over it). Also, enclose your outputs with the code tag, so they can be more easily read. ;-)", "Moreover, the file syntax error is emitted from is here:\r\n```\r\nFile \"/home/cy/.local/lib/python3.5/site-packages/dateutil/parser.py\", line 158\r\nl.append(\"%s=%s\" % (attr, value))\r\n^\r\nSyntaxError: invalid syntax\r\n```\r\nThat is not really a TensorFlow file. I think some other package in your python installation may be corrupted. A google search seems to support this theory:\r\nhttps://www.google.com/search?q=\"dateutil%2Fparser.py\"%2C+line+158\"+invalid+syntax&oq=\"dateutil%2Fparser.py\"%2C+line+158\"+invalid+syntax\r\n\r\nWhich people point to a bug in dateutil package.\r\nPlease make sure to search for relevant bugs before filing issues."]}, {"number": 8340, "title": "How to adjust verbosity to suppress thousands of lines of informational logs?", "body": "Per [#1258](https://github.com/tensorflow/tensorflow/issues/1258), here's my current import:\r\n\r\n```python\r\nimport os\r\nos.environ['TF_CPP_MIN_VLOG_LEVEL'] = '3'\r\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\r\nfrom keras.constraints import maxnorm\r\nfrom keras.layers import Dense, Dropout\r\nfrom keras.models import Sequential\r\nfrom keras.wrappers.scikit_learn import KerasRegressor, KerasClassifier\r\n```\r\n\r\nHowever, as you can see if you look at a recent [Travis build](https://travis-ci.org/ClimbsRocks/auto_ml/jobs/210446239), there are still tens of thousands of lines of informational logs, like so:\r\n\r\n```\r\nLevel 1:tensorflow:Registering Pack (<function _PackGrad at 0x7fc9c4ab3b70>) in gradient.\r\nLevel 1:tensorflow:Registering Unpack (<function _UnpackGrad at 0x7fc9c490d730>) in gradient.\r\nLevel 1:tensorflow:Registering Concat (<function _ConcatGrad at 0x7fc9c490d840>) in gradient.\r\nLevel 1:tensorflow:Registering ConcatV2 (<function _ConcatGradV2 at 0x7fc9c490d8c8>) in gradient.\r\nLevel 1:tensorflow:Registering ConcatOffset (None) in gradient.\r\nLevel 1:tensorflow:Registering Slice (<function _SliceGrad at 0x7fc9c490d9d8>) in gradient.\r\n\r\n...\r\n\r\nLevel 1:tensorflow:  in  --> gradients_49/Relu_86_grad/ReluGrad:0\r\nLevel 1:tensorflow:  out --> gradients_49/add_896_grad/Reshape:0, gradients_49/add_896_grad/Reshape_1:0\r\nLevel 1:tensorflow:Gradient for 'MatMul_135'\r\nLevel 1:tensorflow:  in  --> gradients_49/add_896_grad/Reshape:0\r\nLevel 1:tensorflow:  out --> gradients_49/MatMul_135_grad/MatMul:0, gradients_49/MatMul_135_grad/MatMul_1:0\r\nLevel 1:tensorflow:Gradient for 'Relu_85'\r\nLevel 1:tensorflow:  in  --> gradients_49/MatMul_135_grad/MatMul:0\r\nLevel 1:tensorflow:  out --> gradients_49/Relu_85_grad/ReluGrad:0\r\nLevel 1:tensorflow:Gradient for 'add_895'\r\n```\r\n\r\nThe [docs](https://www.tensorflow.org/api_docs/python/tf/logging/vlog) are not obvious for how to adjust this. \r\n\r\n***Using Python and Keras, how can I adjust verbosity to ignore these logs?***\r\n\r\n### Environment info\r\nOperating System:\r\nLinux and Mac\r\n\r\nUsing v1.0.1 on both platforms, installed directly from binary URLs", "comments": ["Could you try adjusting the environment variables outside the program i.e. using export \r\n```sh\r\nTF_CPP_MIN_VLOG_LEVEL=3.\r\n```\r\nIt could be that os.environ() is not succesfully putenving the updates. ", "Thanks for the idea, but unfortunately that didn't help either. \r\n\r\nI was able to at least reduce the amount of logging during training time using the following code snippet \r\n\r\n```\r\n# Suppress some level of logs\r\nos.environ['TF_CPP_MIN_VLOG_LEVEL'] = '3'\r\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\r\nfrom tensorflow import logging\r\nlogging.set_verbosity(logging.INFO)\r\nfrom keras.constraints import maxnorm\r\n# more imports and everything else follows below\r\n```\r\n\r\nThe above reduces training logging, but I'm still facing several hundred lines of `tensorflow: Level 1: Registering` logging, which I assume comes when the package is first imported\r\n\r\n```\r\ntensorflow: Level 1: Registering FakeQuantWithMinMaxArgs (<function _FakeQuantWithMinMaxArgsGradient at 0x115e56320>) in gradient.\r\ntensorflow: Level 1: Registering FakeQuantWithMinMaxVars (<function _FakeQuantWithMinMaxVarsGradient at 0x115ef9230>) in gradient.\r\ntensorflow: Level 1: Registering FakeQuantWithMinMaxVarsPerChannel (<function _FakeQuantWithMinMaxVarsPerChannelGradient at 0x115ef92a8>) in gradient.\r\ntensorflow: Level 1: Registering MatMul,flops (<function _calc_mat_mul_flops at 0x11611fcf8>) in statistical functions.\r\ntensorflow: Level 1: Registering cond_context ((<class 'tensorflow.core.protobuf.control_flow_pb2.CondContextDef'>, <unbound method CondContext.to_proto>, <function from_proto at 0x1161c42a8>)) in proto functions.\r\ntensorflow: Level 1: Registering while_context ((<class 'tensorflow.core.protobuf.control_flow_pb2.WhileContextDef'>, <unbound method WhileContext.to_proto>, <function from_proto at 0x1161c4b18>)) in proto functions.\r\ntensorflow: Level 1: Registering Pack (<function _PackGrad at 0x11622bd70>) in gradient.\r\ntensorflow: Level 1: Registering Unpack (<function _UnpackGrad at 0x11622bde8>) in gradient.\r\nten\r\n``` \r\n\r\nThe Registering logging is particularly annoying when running the test suite, because it puts several hundred lines of logs in between the info I'm scrolling between. \r\n\r\nAny thoughts? Can we get any signal from the fact that `logging.set_verbosity()` reduces logs for training, and use that to understanding how we might be able to suppress the Registering logging? ", "I think the logging is in keras. Can you check where it comes from?", "@drpngx Thanks for the response! \r\n\r\nI tried commenting out all of the Keras imports in my tests, and still got the \"Registering\" logs.\r\n\r\nThe log looks like it's coming from https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/framework/registry.py#L64\r\n\r\nLet me know if there's any other info I can provide to help debug this! My current hypothesis is that all this logging happens as part of the `import tensorflow as tf`, before I'm able to set_logging. \r\n\r\nOne possible workaround is to allow the user to import some very tiny function like `set_logging` that lets them set logging defaults before importing the rest of tensorflow. ", "OK, can you set the `vlog` to `0`, import tensorflow, then set it back to whatever you want?", "@drpngx : \r\n\r\nJust tried: \r\n\r\n```\r\n    os.environ['TF_CPP_MIN_VLOG_LEVEL'] = '0'\r\n    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '0'\r\n    from tensorflow import logging\r\n    logging.set_verbosity(logging.INFO)\r\n```\r\n\r\nAnd still got the same Registering messages: \r\n\r\n```\r\n...\r\nLevel 1:tensorflow:Registering TopK (<function _TopKGrad at 0x10c8625f0>) in gradient.\r\nLevel 1:tensorflow:Registering CTCLoss (<function _CTCLossGrad at 0x10c8626e0>) in gradient.\r\nLevel 1:tensorflow:Registering CTCGreedyDecoder (None) in gradient.\r\nLevel 1:tensorflow:Registering CTCBeamSearchDecoder (None) in gradient.\r\nLevel 1:tensorflow:Registering SetSize (None) in gradient.\r\nLevel 1:tensorflow:Registering DenseToDenseSetOperation (None) in gradient.\r\nLevel 1:tensorflow:Registering DenseToSparseSetOperation (None) in gradient.\r\nLevel 1:tensorflow:Registering SparseToSparseSetOperation (None) in gradient.\r\nLevel 1:tensorflow:Registering SdcaFprint (None) in gradient.\r\nLevel 1:tensorflow:Registering SdcaOptimizer (None) in gradient.\r\nLevel 1:tensorflow:Registering SdcaShrinkL1 (None) in gradient.\r\nLevel 1:tensorflow:Registering RandomCrop (None) in gradient.\r\nLevel 1:tensorflow:Registering RGBToHSV (None) in gradient.\r\nLevel 1:tensorflow:Registering HSVToRGB (None) in gradient.\r\nLevel 1:tensorflow:Registering DrawBoundingBoxes (None) in gradient.\r\nLevel 1:tensorflow:Registering SampleDistortedBoundingBox (None) in gradient.\r\nLevel 1:tensorflow:Registering ExtractGlimpse (None) in gradient.\r\nLevel 1:tensorflow:Registering NonMaxSuppression (None) in gradient.\r\nLevel 1:tensorflow:Registering savers ((<class 'tensorflow.core.protobuf.saver_pb2.SaverDef'>, <unbound method Saver.to_proto>, <function from_proto at 0x10c9a27d0>)) in proto functions.\r\nLevel 1:tensorflow:Registering Fact (<function call_without_requiring at 0x10bce4a28>) in default shape functions.\r\nLevel 1:tensorflow:Registering TensorSummary (None) in gradient.\r\nLevel 1:tensorflow:Registering queue_runners ((<class 'tensorflow.core.protobuf.queue_runner_pb2.QueueRunnerDef'>, <unbound method QueueRunner.to_proto>, <function from_proto at 0x10ca1cc08>)) in proto functions.\r\n```\r\n\r\nIs there a different way I should be setting the vlog?'\r\n\r\nIf it helps any, this is while running `nosetests -v tests` (which is what's run on the travis-build I reference above).\r\n\r\nThanks again for the help!", "OK, here's the thing:\r\n\r\n1. The logging default is set during `tf.logging` [initialization](https://www.github.com/tensorflow/tensorflow/blob/master/tensorflow/python/platform/default/_tf_logging.py#L55)\r\n2. You can't set the logging without triggering `tensorflow/__init__.py`, which will trigger registering all gradients.\r\n\r\nI don't see any way to change this short of changing the code. One last ditch effort would be to try and set `sys.flags.interactive = False` but it's probably already there.\r\n\r\nSorry, I'm going to close this issue because I don't think it's feasible for us to fix this reasonably well. Feel free to open a new feature request or re-open if you feel strongly about that.", "I know it's a bit late, but it seems this issue was never solved. I encountered the same issue when running `nosetests` and found a solution on [StackOverflow](https://stackoverflow.com/questions/43337601/nosetests-with-tensorflow-lots-of-debugging-output-how-to-disable):\r\n```\r\nimport logging\r\nlogging.getLogger('tensorflow').disabled = True\r\n```\r\nAdding this before importing TensorFlow (e.g. somewhere in `__init__.py`) solves it for me.", "Thanks @CNugteren.", "Thank you @CNugteren. It's never too late.\r\n\r\nI added your snippet in `<app_name>/tests/__init__.py`.\r\n\r\nNow, I need to do: `./manage.py test <app_name>.tests` to run the tests.\r\nNot just `./manage.py test` or `./manage.py test <app_name>`, otherwise the logs will appear again.", "> I know it's a bit late, but it seems this issue was never solved. I encountered the same issue when running `nosetests` and found a solution on [StackOverflow](https://stackoverflow.com/questions/43337601/nosetests-with-tensorflow-lots-of-debugging-output-how-to-disable):\r\n> \r\n> ```\r\n> import logging\r\n> logging.getLogger('tensorflow').disabled = True\r\n> ```\r\n> \r\n> Adding this before importing TensorFlow (e.g. somewhere in `__init__.py`) solves it for me.\r\n\r\nThis did solve the Issue I've been looking for it everywhere. thank you @CNugteren ", "For whoever gets here today, setting the tensorflow logger level to warning does the job as well:\r\n\r\n```\r\nImport logging\r\nlogging.getLogger('tensorflow').setLevel(logging.WARNING)\r\n```", "> For whoever gets here today, setting the tensorflow logger level to warning does the job as well:\r\n> \r\n> ```\r\n> Import logging\r\n> logging.getLogger('tensorflow').setLevel(logging.WARNING)\r\n> ```\r\n\r\nThis works for me. Maybe it can also be applied to others, for example:\r\n\r\n```python\r\nimport logging\r\nlogging.getLogger('absl').setLevel('ERROR')\r\n```"]}, {"number": 8339, "title": "Comment fix", "body": "", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please", "Ignoring flaky test."]}, {"number": 8338, "title": "Segmentation fault after calling tf.contrib.distributions `sample().eval()` several times", "body": "I ran the following code and after calling `sample().eval()` several times (like 15 times), the program will crash.\r\n```python\r\nimport tensorflow as tf\r\nmu = [1, 2, 3.]\r\ndiag_stdev = [4, 5, 6.]\r\ndist = tf.contrib.distributions.MultivariateNormalDiag(mu, diag_stdev)\r\nsess = tf.InteractiveSession()\r\ndist.sample().eval()\r\ndist.sample().eval()\r\n...\r\n```\r\nI don't know if this is a bug in memory management, just reporting it. I tried to run this short code several times, and the program all crashed after calling `sample()` several times.\r\n\r\nI am using TensorFlow 1.0.1, ubuntu 14.04, cuDNN 5.1. CUDA 8.0.\r\nI am running the code in ipython\r\n```python\r\n$ ipython\r\nPython 2.7.6 (default, Oct 26 2016, 20:30:19) \r\nType \"copyright\", \"credits\" or \"license\" for more information.\r\n\r\nIPython 5.1.0 -- An enhanced Interactive Python.\r\n?         -> Introduction and overview of IPython's features.\r\n%quickref -> Quick reference.\r\nhelp      -> Python's own help system.\r\nobject?   -> Details about 'object', use 'object??' for extra details.\r\n\r\nIn [1]: import tensorflow as tf\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally\r\n\r\nIn [2]: tf.__version__\r\nOut[2]: '1.0.1'\r\n\r\nIn [3]: import tensorflow as tf\r\n   ...: mu = [1, 2, 3.]\r\n   ...: diag_stdev = [4, 5, 6.]\r\n   ...: dist = tf.contrib.distributions.MultivariateNormalDiag(mu, diag_stdev)\r\n   ...: sess = tf.InteractiveSession()\r\n   ...: dist.sample().eval()\r\n   ...: \r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\r\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: \r\nname: TITAN X (Pascal)\r\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.531\r\npciBusID 0000:01:00.0\r\nTotal memory: 11.90GiB\r\nFree memory: 11.18GiB\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: TITAN X (Pascal), pci bus id: 0000:01:00.0)\r\nOut[3]: array([-3.5554738 , -9.19613838,  0.99159908], dtype=float32)\r\n\r\nIn [4]: dist.sample().eval()\r\nOut[4]: array([  3.23878694,  10.00256252,  -1.83450556], dtype=float32)\r\n\r\nIn [5]: dist.sample().eval()\r\nOut[5]: array([-3.07549763,  2.88274646,  1.73206449], dtype=float32)\r\n\r\nIn [6]: dist.sample().eval()\r\nOut[6]: array([-6.32968855,  5.16116142,  3.4088428 ], dtype=float32)\r\n\r\nIn [7]: dist.sample().eval()\r\nOut[7]: array([-10.45146465,   8.00740719,  12.19320011], dtype=float32)\r\n\r\nIn [8]: dist.sample().eval()\r\nOut[8]: array([ 2.50515604, -0.90315008,  8.30728722], dtype=float32)\r\n\r\nIn [9]: dist.sample().eval()\r\nOut[9]: array([ 1.11648369,  2.883286  ,  5.3753109 ], dtype=float32)\r\n\r\nIn [10]: dist.sample().eval()\r\nOut[10]: array([ 1.42068732, -1.55020142,  7.90944004], dtype=float32)\r\n\r\nIn [11]: dist.sample().eval()\r\nOut[11]: array([-2.47698998,  5.00640774,  9.55048275], dtype=float32)\r\n\r\nIn [12]: dist.sample().eval()\r\nOut[12]: array([-2.72261739,  8.12374115,  6.6374836 ], dtype=float32)\r\n\r\nIn [13]: dist.sample().eval()\r\nOut[13]: array([-5.90653419,  2.76514864,  1.68261075], dtype=float32)\r\n\r\nIn [14]: dist.sample().eval()\r\nSegmentation fault (core dumped)\r\n```", "comments": ["Can you provide more info, like running it in gdb and pasting the backtrace?", "@ebrevdo Thanks, I just added more info above.", "The error only occurs when I use `ipython` instead of `python` in terminal. And furthermore, ipython will exit with `Segementation fault` even with the following code. I.e., when I typed `exit()`, it exited with the seg fault error.\r\n```python\r\n$ ipython\r\nPython 2.7.6 (default, Oct 26 2016, 20:30:19) \r\nType \"copyright\", \"credits\" or \"license\" for more information.\r\n\r\nIPython 5.3.0 -- An enhanced Interactive Python.\r\n?         -> Introduction and overview of IPython's features.\r\n%quickref -> Quick reference.\r\nhelp      -> Python's own help system.\r\nobject?   -> Details about 'object', use 'object??' for extra details.\r\n\r\nIn [1]: import tensorflow as tf\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally\r\n\r\nIn [2]: mu = [1, 2, 3.]\r\n\r\nIn [3]: diag_stdev = [4, 5, 6.]\r\n\r\nIn [4]: dist = tf.contrib.distributions.MultivariateNormalDiag(mu, diag_stdev)\r\n\r\nIn [5]: exit()\r\nSegmentation fault (core dumped)\r\n```", "I hit similar issue both w/ tensorflow pypi package and one compiled locally. This seems to be new as of 1.0.1, r0.12 didnt have issues for me.\r\n\r\nSimply adding\r\n```\r\nimport tensorflow as tf\r\nds = tf.contrib.distributions\r\n```\r\nis enough to cause segfaults. Removing these lines things run fine. \r\n\r\nBasically, it looks like tensorflow does lazy loading for contrib and importing tf.contrib.distributions causes memory corruption. \r\n\r\nThe actual backtrace is in unrelated code (e.g. python dict internals) so it seems thats not particularly relevant... \r\n\r\nI'll see if theres a way to provide more info though and in particular see if I can figure out how importing `tf.contrib.distributions` could possibly be causing memory corruption as there doesnt seem to be any compiled code there...", "In our case at least, this seems to be a dupe of #6968 \r\n\r\n```\r\npip install --no-binary=:all: numpy\r\n```\r\n\r\ncaused the segfaults to go away \r\n\r\n\r\n"]}, {"number": 8337, "title": "tfdbg error: Causality violated in timing relations of debug dumps", "body": "\r\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\nNothing found\r\n### Environment info\r\nOperating System:\r\nUbuntu 14.04\r\nInstalled version of CUDA and cuDNN: \r\nCUDA 8.0, cuDNN 5.1\r\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\r\n```\r\n-rw-r--r-- 1 root root   558720  9\u6708 15 07:02 /usr/local/cuda/lib64/libcudadevrt.a\r\nlrwxrwxrwx 1 root root       16  9\u6708 15 07:05 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0\r\nlrwxrwxrwx 1 root root       19  9\u6708 15 07:05 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44\r\n-rw-r--r-- 1 root root   415432  9\u6708 15 07:02 /usr/local/cuda/lib64/libcudart.so.8.0.44\r\n-rw-r--r-- 1 root root   775162  9\u6708 15 07:02 /usr/local/cuda/lib64/libcudart_static.a\r\n-rwxr-xr-x 1 root root 79337624 11\u6708 16 22:50 /usr/local/cuda/lib64/libcudnn.so\r\n-rwxr-xr-x 1 root root 79337624 11\u6708 16 22:50 /usr/local/cuda/lib64/libcudnn.so.5\r\n-rwxr-xr-x 1 root root 79337624 11\u6708 16 22:50 /usr/local/cuda/lib64/libcudnn.so.5.1.5\r\n-rw-r--r-- 1 root root 69756172 11\u6708 16 22:50 /usr/local/cuda/lib64/libcudnn_static.a\r\n```\r\nIf installed from source, provide \r\n\r\n1. The commit hash (`git rev-parse HEAD`)\r\n12a98726e769e988f6368a029ec2f5b0ac3ccbd4\r\n2. The output of `bazel version`\r\n```\r\nBuild label: 0.4.4\r\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Wed Feb 1 18:54:21 2017 (1485975261)\r\nBuild timestamp: 1485975261\r\nBuild timestamp as int: 1485975261\r\n```\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\nI have a model that basically consists of several bidirectional rnns, the longest of which has hundreds of timesteps.\r\n### What other attempted solutions have you tried?\r\n\r\n### Logs or other output that would be helpful\r\nWhen I try to launch the first Session.run() call in tfdbg using command r, I got the following error:\r\n```\r\n2017-03-13 10:54:06.173974: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 0 with properties:\r\nname: GeForce GTX 1080\r\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.7335\r\npciBusID 0000:81:00.0\r\nTotal memory: 7.92GiB\r\nFree memory: 7.81GiB\r\n2017-03-13 10:54:06.174082: I tensorflow/core/common_runtime/gpu/gpu_device.cc:908] DMA: 0\r\n2017-03-13 10:54:06.174106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 0:   Y\r\n2017-03-13 10:54:06.174138: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:81:00.0)\r\nCreated model with fresh parameters.\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 143, in <module>\r\n    trainer.train()\r\n  File \"train.py\", line 76, in train\r\n    step_loss, summary = self.m.train_step(self.sess, batch_docs, batch_queries, batch_answers, batch_target)\r\n  File \"/home/zhangx/nn_tool_x33/MR_base/model.py\", line 186, in train_step\r\n    feed_dict=feed_dict, options=run_options, run_metadata=run_metadata)\r\n  File \"/home/zhangx/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/debug/wrappers/framework.py\", line 470, in run\r\n    run_end_resp = self.on_run_end(run_end_req)\r\n  File \"/home/zhangx/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/debug/wrappers/local_cli_wrapper.py\", line 267, in on_run_end\r\n    self._dump_root, partition_graphs=partition_graphs)\r\n  File \"/home/zhangx/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/debug/lib/debug_data.py\", line 502, in __init__\r\n    self._load_partition_graphs(partition_graphs, validate)\r\n  File \"/home/zhangx/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/debug/lib/debug_data.py\", line 760, in _load_partition_graphs\r\n    self._validate_dump_with_graphs()\r\n  File \"/home/zhangx/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/debug/lib/debug_data.py\", line 927, in _validate_dump_with_graphs\r\n    (node, datum.timestamp, repr(pending_inputs[node])))\r\nValueError: Causality violated in timing relations of debug dumps: optimizer/gradients/inference/encode/docs/encode/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/b_acc_2 (1489373660302841): these input(s) are not satisfied: [('optimizer/gradients/inference/encode/docs/encode/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/b_acc_1', 0), ('optimizer/gradients/inference/encode/docs/encode/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/NextIteration', 0)]\r\n```\r\nIs this a model related error or possibly a tfdbg bug?", "comments": ["@zxvix From your error message, it appears that you are using `tf.while_loop`. Can you try setting its `paralle_iterations` parameter to 1 and see if the error still happens?\r\n\r\nThere may be a bug in how tfdbg handles while_loops with parallel_iterations > 1.", "I think it might be a GPU thing.\r\n\r\nThe example below errors if run as `python tf_8337_minimal.py` but is fine is run as `CUDA_VISIBLE_DEVICES=-1 python tf_8337_minimal.py`.\r\n\r\n```python\r\nfrom __future__ import division\r\nimport logging\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow.contrib.rnn import BasicLSTMCell, MultiRNNCell\r\nfrom tensorflow.python import debug as tfdbg\r\n\r\n\r\ndef output_layer(inputs, out_size, keep_prob):\r\n  batch_size, time_size, in_size = inputs.get_shape().as_list()\r\n  inputs = tf.reshape(inputs, [batch_size * time_size, in_size])\r\n  weights = tf.get_variable('weights', [in_size, out_size], tf.float32)\r\n  biases = tf.get_variable('biases', [out_size], tf.float32, tf.zeros_initializer())\r\n  outputs = tf.matmul(tf.nn.dropout(inputs, keep_prob), weights) + biases\r\n  return tf.reshape(outputs, [batch_size, time_size, out_size])\r\n\r\ntf._log = tf.log\r\ndef log(x, name=None):\r\n  return tf._log(x + 1e-10, name)\r\ntf.log = log\r\n\r\n\r\nclass Network(object):\r\n  def __init__(self):\r\n    self.sess = tf.Session()\r\n    self.sess = tfdbg.LocalCLIDebugWrapperSession(self.sess)\r\n    self.sess.add_tensor_filter('has_inf_or_nan', tfdbg.has_inf_or_nan)\r\n    self.x = tf.placeholder(tf.float32, [1, 6, 6])\r\n    self.p = tf.placeholder(tf.float32, [1, 6, 3])\r\n    self.keep_prob = tf.placeholder_with_default(tf.ones([], tf.float32), [])\r\n    sequence_length = self._get_sequence_length()\r\n    multicell = MultiRNNCell([BasicLSTMCell(128) for _ in xrange(2)])\r\n    output, _state = tf.nn.dynamic_rnn(multicell, self.x,\r\n                                       sequence_length=sequence_length,\r\n                                       dtype=tf.float32,\r\n                                       parallel_iterations=1)\r\n    output = output_layer(output, 3, self.keep_prob)\r\n    self.p_hat = tf.nn.softmax(output)\r\n    mask = tf.sequence_mask(sequence_length, 6, tf.float32)\r\n    num_events = tf.to_float(tf.reduce_sum(sequence_length))\r\n    self.loss = tf.reduce_sum(-tf.log(tf.reduce_sum(self.p_hat * self.p, axis=2)) * mask) / num_events\r\n    optimiser = tf.train.GradientDescentOptimizer(learning_rate=0)\r\n    gradients = optimiser.compute_gradients(self.loss)\r\n    self.train_op = optimiser.apply_gradients(gradients)\r\n\r\n  def train(self, x, p):\r\n    feed_dict = {self.x: x, self.p: p, self.keep_prob: 0.5}\r\n    fetches = [self.train_op, self.loss]\r\n    return self.sess.run(fetches, feed_dict)[1:]\r\n\r\n  def _get_sequence_length(self):\r\n    used = tf.sign(tf.reduce_max(tf.abs(self.x), reduction_indices=2))\r\n    self._sequence_length = tf.cast(tf.reduce_sum(used, reduction_indices=1), tf.int32)\r\n    return self._sequence_length\r\n\r\n\r\nx = np.hstack((np.random.randn(1, 2, 6), np.zeros((1, 4, 6))))\r\np = np.zeros((1, 6, 3))\r\np[0, 0, 2] = 1\r\np[0, 1, 1] = 1\r\n\r\nnetwork = Network()\r\nnetwork.sess.run(tf.global_variables_initializer())\r\nresults = network.train(x, p)\r\n```\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"tf_8337_minimal.py\", line 64, in <module>\r\n    results = network.train(x, p)\r\n  File \"tf_8337_minimal.py\", line 49, in train\r\n    return self.sess.run(fetches, feed_dict)[1:]\r\n  File \"/home/arun/tensorflows/master/local/lib/python2.7/site-packages/tensorflow/python/debug/wrappers/framework.py\", line 470, in run\r\n    run_end_resp = self.on_run_end(run_end_req)\r\n  File \"/home/arun/tensorflows/master/local/lib/python2.7/site-packages/tensorflow/python/debug/wrappers/local_cli_wrapper.py\", line 267, in on_run_end\r\n    self._dump_root, partition_graphs=partition_graphs)\r\n  File \"/home/arun/tensorflows/master/local/lib/python2.7/site-packages/tensorflow/python/debug/lib/debug_data.py\", line 502, in __init__\r\n    self._load_partition_graphs(partition_graphs, validate)\r\n  File \"/home/arun/tensorflows/master/local/lib/python2.7/site-packages/tensorflow/python/debug/lib/debug_data.py\", line 760, in _load_partition_graphs\r\n    self._validate_dump_with_graphs()\r\n  File \"/home/arun/tensorflows/master/local/lib/python2.7/site-packages/tensorflow/python/debug/lib/debug_data.py\", line 927, in _validate_dump_with_graphs\r\n    (node, datum.timestamp, repr(pending_inputs[node])))\r\nValueError: Causality violated in timing relations of debug dumps: gradients/rnn/while/multi_rnn_cell/cell_0/basic_lstm_cell/basic_lstm_cell_1/MatMul/Enter_grad/b_acc_2 (1489433694505012): these input(s) are not satisfied: [(u'gradients/rnn/while/multi_rnn_cell/cell_0/basic_lstm_cell/basic_lstm_cell_1/MatMul/Enter_grad/b_acc_1', 0), (u'gradients/rnn/while/multi_rnn_cell/cell_0/basic_lstm_cell/basic_lstm_cell_1/MatMul/Enter_grad/NextIteration', 0)]\r\n```\r\n\r\nThe final error tends to change in a non-deterministic fashion. I have also got:\r\n```\r\nValueError: Causality violated in timing relations of debug dumps: gradients/rnn/while/Switch_5_grad/b_switch (1489433796485511): these input(s) are not satisfied: [(u'gradients/rnn/while/Exit_5_grad/b_exit', 0), (u'gradients/rnn/while/Switch_5_grad_1/NextIteration', 0)]\r\n```\r\n\r\nUbuntu 16.04.2\r\nSource: 12a9872\r\nBazel 0.4.4\r\nCUDA 8.0\r\nCUDNN 5.1.5\r\npython 2.7.12\r\n2 GPUs: Titan X (pascal)", "Thanks for the info. Ah - I see you have more than one GPUs. As a diagnostic step, does this error occur if you run the code on a single GPU? ", "Yeah, same thing:\r\n\r\n```\r\n(master) arun@abacus:~/source/deep_experiments/arun_experiments$ CUDA_VISIBLE_DEVICES=1 python tf_8337_minimal.py \r\n2017-03-13 23:22:22.446582: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 0 with properties: \r\nname: TITAN X (Pascal)\r\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.531\r\npciBusID 0000:81:00.0\r\nTotal memory: 11.90GiB\r\nFree memory: 10.54GiB\r\n2017-03-13 23:22:22.446634: I tensorflow/core/common_runtime/gpu/gpu_device.cc:908] DMA: 0 \r\n2017-03-13 23:22:22.446644: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 0:   Y \r\n2017-03-13 23:22:22.446667: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: TITAN X (Pascal), pci bus id: 0000:81:00.0)\r\nTraceback (most recent call last):\r\n  File \"tf_8337_minimal.py\", line 64, in <module>\r\n    results = network.train(x, p)\r\n  File \"tf_8337_minimal.py\", line 49, in train\r\n    return self.sess.run(fetches, feed_dict)[1:]\r\n  File \"/home/arun/tensorflows/master/local/lib/python2.7/site-packages/tensorflow/python/debug/wrappers/framework.py\", line 470, in run\r\n    run_end_resp = self.on_run_end(run_end_req)\r\n  File \"/home/arun/tensorflows/master/local/lib/python2.7/site-packages/tensorflow/python/debug/wrappers/local_cli_wrapper.py\", line 267, in on_run_end\r\n    self._dump_root, partition_graphs=partition_graphs)\r\n  File \"/home/arun/tensorflows/master/local/lib/python2.7/site-packages/tensorflow/python/debug/lib/debug_data.py\", line 502, in __init__\r\n    self._load_partition_graphs(partition_graphs, validate)\r\n  File \"/home/arun/tensorflows/master/local/lib/python2.7/site-packages/tensorflow/python/debug/lib/debug_data.py\", line 760, in _load_partition_graphs\r\n    self._validate_dump_with_graphs()\r\n  File \"/home/arun/tensorflows/master/local/lib/python2.7/site-packages/tensorflow/python/debug/lib/debug_data.py\", line 927, in _validate_dump_with_graphs\r\n    (node, datum.timestamp, repr(pending_inputs[node])))\r\nValueError: Causality violated in timing relations of debug dumps: gradients/rnn/while/multi_rnn_cell/cell_1/basic_lstm_cell/basic_lstm_cell_1/BiasAdd/Enter_grad/b_acc_2 (1489447350946236): these input(s) are not satisfied: [(u'gradients/rnn/while/multi_rnn_cell/cell_1/basic_lstm_cell/basic_lstm_cell_1/BiasAdd/Enter_grad/b_acc_1', 0), (u'gradients/rnn/while/multi_rnn_cell/cell_1/basic_lstm_cell/basic_lstm_cell_1/BiasAdd/Enter_grad/NextIteration', 0)]\r\n```\r\n\r\nThanks for looking into this.", "I'm seeing this error on CPU (1e33acb381430ed0004eb76b98181624af267b2c) with `parallel_iterations=1`, so it's not entirely a GPU thing:\r\n```\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 123, in <module>\r\n    feed_dict={x: batch_xs, y_: batch_ys})\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/debug/wrappers/framework.py\", line 470, in run\r\n    run_end_resp = self.on_run_end(run_end_req)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/debug/wrappers/local_cli_wrapper.py\", line 275, in on_run_end\r\n    self._dump_root, partition_graphs=partition_graphs)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/debug/lib/debug_data.py\", line 524, in __init__\r\n    self._load_partition_graphs(partition_graphs, validate)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/debug/lib/debug_data.py\", line 782, in _load_partition_graphs\r\n    self._validate_dump_with_graphs()\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/debug/lib/debug_data.py\", line 954, in _validate_dump_with_graphs\r\n    (node, datum.timestamp, repr(pending_inputs[node])))\r\nValueError: Causality violated in timing relations of debug dumps: while/mul (1490664758938833): these input(s) are not satisfied: [('while/mul/Enter', 0)]\r\n```", "@jekbradbury It will be helpful if you could provide some code for reproducing this error on our and and let us know how reproducible (% time it happens) this crash is. Thanks.", "My guess is that I've done something dumb in the optimization routine (I'm getting NaNs, which is why I tried the debugger). But here's [the gist](https://gist.github.com/jekbradbury/05e9f17776771f1f501919b7eff58c7f) anyway -- it has happened all three times I've tried running it with the debugger; the error comes on the second use of `run` (the first time the optimization routine happens). On v1.0 stable, it hangs like in [this issue](https://github.com/tensorflow/tensorflow/issues/7774).", "Thanks @jekbradbury , your code reproduces the issue on my machine (CPU only).\r\nAlso, @al626 's code also errors out on my GPU machine, but works fine on CPU-only.\r\nThese may be different manifestations of the same issue. We'll look into it.", "FYI, this bug should have been fixed by 7b410eb. I verified it works with the two reproduction code samples above. The fix will become available in the nightly artifacts on the next successful build.", "I am having the same problem, getting NaNs when using dynamic_rnn, and the td_debugger exiting with\r\n`ValueError: Causality violated in timing relations of debug dumps: gradients/rnn/while/rnn/dnc_cell/head_0/strided_slice_7_grad/StridedSliceGrad/StackPush_1 (1501099455073575): these input(s) are not satisfied: [('gradients/rnn/while/rnn/dnc_cell/head_0/strided_slice_7_grad/StridedSliceGrad/RefEnter_1', 0)]\r\n`\r\n\r\nUsing tensorflow 1.2.0 with python3."]}, {"number": 8336, "title": "Operations missing for TF on windows", "body": "NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.\r\n\r\nFor general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\r\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed\r\nout of scope for GitHub Issues and point people to StackOverflow.\r\n\r\nFor bugs or installation issues, please provide the following information.\r\nThe more information you provide, the more easily we will be able to offer\r\nhelp and advice.\r\n\r\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\n\r\n### Environment info\r\nOperating System: Windows 10\r\n\r\nInstalled version of CUDA and cuDNN: \r\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\r\n`Cuda compilation tools, release 8.0, V8.0.60`\r\n\r\nIf installed from binary pip package, provide:\r\n`pip install --upgrade tensorflow-gpu`\r\n\r\n1. A link to the pip package you installed:\r\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\r\n\r\nIf installed from source, provide \r\n\r\n1. The commit hash (`git rev-parse HEAD`)\r\n2. The output of `bazel version`\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\nThese errors happened every time I tried to import tensorflow package in py35, when all the dependent dlls are loaded **correctly** as follows:\r\n`I c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\dso_loader.cc:135] successfully opened CUDA library cublas64_80.dll locally\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\dso_loader.cc:135] successfully opened CUDA library cudnn64_5.dll locally\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\dso_loader.cc:135] successfully opened CUDA library cufft64_80.dll locally\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\dso_loader.cc:135] successfully opened CUDA library nvcuda.dll locally\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\dso_loader.cc:135] successfully opened CUDA library curand64_80.dll locally`\r\n\r\n### What other attempted solutions have you tried?\r\n1. reinstalled tensorflow and related cuda packages\r\n2. switch graphic cards\r\n\r\n### Logs or other output that would be helpful\r\n(If logs are large, please upload as attachment or provide link).\r\n`E c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('op: \"BestSplits\" device_type: \"CPU\"') for unknown op: BestSplits`\r\n`E c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('op: \"CountExtremelyRandomStats\" device_type: \"CPU\"') for unknown op: CountExtremelyRandomStats`\r\n`E c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('op: \"FinishedNodes\" device_type: \"CPU\"') for unknown op: FinishedNodes`\r\n`E c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('op: \"GrowTree\" device_type: \"CPU\"') for unknown op: GrowTree`\r\n`E c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('op: \"ReinterpretStringToFloat\" device_type: \"CPU\"') for unknown op: ReinterpretStringToFloat`\r\n`E c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('op: \"SampleInputs\" device_type: \"CPU\"') for unknown op: SampleInputs`\r\n`E c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('op: \"ScatterAddNdim\" device_type: \"CPU\"') for unknown op: ScatterAddNdim`\r\n`E c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('op: \"TopNInsert\" device_type: \"CPU\"') for unknown op: TopNInsert`\r\n`E c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('op: \"TopNRemove\" device_type: \"CPU\"') for unknown op: TopNRemove`\r\n`E c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('op: \"TreePredictions\" device_type: \"CPU\"') for unknown op: TreePredictions`\r\n`E c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('op: \"UpdateFertileSlots\" device_type: \"CPU\"') for unknown op: UpdateFertileSlots`\r\n", "comments": ["This has been fixed at HEAD since January 17th. You can safely ignore this error message, or upgrade to a nightly build to use the fix. Closing as a duplicate of #8334.", "@mrry I need a working version for windows. where are located the nightly build with this fix?", "@AndreaFar Links to the nightly builds on all platforms can be found in the readme here: https://github.com/tensorflow/tensorflow/blob/master/README.md", "@mrry with nightly build (22-mar-2017 2.25.00) \r\nhttps://ci.tensorflow.org/view/Nightly/job/nightly-win/DEVICE=cpu,OS=windows/\r\nkernel crashes with a different error\r\n\r\n```\r\nWarning! ***HDF5 library version mismatched error***\r\nThe HDF5 header files used to compile this application do not match\r\nthe version used by the HDF5 library to which this application is linked.\r\nData corruption or segmentation faults may occur if the application continues.\r\nThis can happen when an application was compiled by one version of HDF5 but\r\nlinked with a different version of static or shared HDF5 library.\r\nYou should recompile the application or check your shared library related\r\nsettings such as 'LD_LIBRARY_PATH'.\r\nYou can, at your own risk, disable this warning by setting the environment\r\nvariable 'HDF5_DISABLE_VERSION_CHECK' to a value of '1'.\r\nSetting it to 2 or higher will suppress the warning messages totally.\r\nHeaders are 1.8.15, library is 1.8.18\r\n      SUMMARY OF THE HDF5 CONFIGURATION\r\n      =================================\r\n\r\nGeneral Information:\r\n-------------------\r\n                   HDF5 Version: 1.8.18\r\n                  Configured on: 2017-03-06\r\n                  Configured by: Visual Studio 14 2015 Win64\r\n                 Configure mode: CMAKE 3.7.2\r\n                    Host system: Windows-10.0.14393\r\n              Uname information: Windows\r\n                       Byte sex: little-endian\r\n                      Libraries:\r\n             Installation point: C:/Program Files/HDF5\r\n\r\nCompiling Options:\r\n------------------\r\n               Compilation Mode:\r\n                     C Compiler: C:/Program Files (x86)/Microsoft Visual Studio 14.0/VC/bin/x86_amd64/cl.exe\r\n                         CFLAGS: /DWIN32 /D_WINDOWS /W3\r\n                      H5_CFLAGS:\r\n                      AM_CFLAGS:\r\n                       CPPFLAGS:\r\n                    H5_CPPFLAGS:\r\n                    AM_CPPFLAGS:\r\n               Shared C Library: YES\r\n               Static C Library: YES\r\n  Statically Linked Executables: OFF\r\n                        LDFLAGS: /machine:x64\r\n                     AM_LDFLAGS:\r\n                Extra libraries: X:inclib-vc14-x64/zlib.lib;X:/inclib-vc14-x64/libsz.lib;X:/inclib-vc14-x64/libaec.lib\r\n                       Archiver:\r\n                         Ranlib:\r\n              Debugged Packages:\r\n                    API Tracing: OFF\r\n\r\nLanguages:\r\n----------\r\n                        Fortran: OFF\r\n               Fortran Compiler:\r\n          Fortran 2003 Compiler:\r\n                  Fortran Flags:\r\n               H5 Fortran Flags:\r\n               AM Fortran Flags:\r\n         Shared Fortran Library: YES\r\n         Static Fortran Library: YES\r\n\r\n                            C++: ON\r\n                   C++ Compiler: C:/Program Files (x86)/Microsoft Visual Studio 14.0/VC/bin/x86_amd64/cl.exe\r\n                      C++ Flags: /DWIN32 /D_WINDOWS /W3 /GR /EHsc\r\n                   H5 C++ Flags:\r\n                   AM C++ Flags:\r\n             Shared C++ Library: YES\r\n             Static C++ Library: YES\r\n\r\nFeatures:\r\n---------\r\n                  Parallel HDF5: OFF\r\n             High Level library: ON\r\n                   Threadsafety: OFF\r\n            Default API Mapping: v18\r\n With Deprecated Public Symbols: ON\r\n         I/O filters (external):  DEFLATE DECODE ENCODE\r\n                            MPE:\r\n                     Direct VFD:\r\n                        dmalloc:\r\nClear file buffers before write: ON\r\n           Using memory checker: OFF\r\n         Function Stack Tracing: OFF\r\n      Strict File Format Checks: OFF\r\n   Optimization Instrumentation:\r\nBye...\r\n```", "@AndreaFar I don't think this problem is TensorFlow-specific, because the TensorFlow binaries do not include any HDF5 support. It's possible that one of the libraries TensorFlow depends on is not working. (Perhaps Pands? It seems to have had similar [problems in the past](https://github.com/pandas-dev/pandas/issues/3091)....) Therefore it might be possible to fix this by upgrading your other installed packages and/or the copy of HDF5 that seems to be installed in `C:\\Program Files\\HDF5`.\r\n\r\nIf you continue to have problems, please feel free to open another issue with more details about your configuration.", "@mrry dependencies are updated to latest release available on pip, I get this error with Tensorflow nightly build, but not with tensorflow release(that crashes because of the bug reported here). Maybe the nightly build use a different version not released? I have opened a new issue here https://github.com/tensorflow/tensorflow/issues/8627"]}, {"number": 8335, "title": "Adding instructions on SavedModelBundle usage", "body": "", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please"]}, {"number": 8334, "title": "An error occurred while starting the kernel on Windows", "body": "I get this error when start the execution of some optical recognition routines\r\nTensorflow: 1.0.1 \r\nOS: Windows 10 x64\r\nNvidia cuDNN: 5.1\r\nNvidia CUDA: 8.0\r\n\r\n```\r\nAn error occurred while starting the kernel\r\nI c:\\tf_jenkins\\home\\workspace\\release\u2011win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\dso_loader.cc:135] successfully opened CUDA library cublas64_80.dll locally\r\nI c:\\tf_jenkins\\home\\workspace\\release\u2011win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\dso_loader.cc:135] successfully opened CUDA library cudnn64_5.dll locally\r\nI c:\\tf_jenkins\\home\\workspace\\release\u2011win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\dso_loader.cc:135] successfully opened CUDA library cufft64_80.dll locally\r\nI c:\\tf_jenkins\\home\\workspace\\release\u2011win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\dso_loader.cc:135] successfully opened CUDA library nvcuda.dll locally\r\nI c:\\tf_jenkins\\home\\workspace\\release\u2011win\\device\\gpu\\os\\windows\\tensorflow\\stream_executor\\dso_loader.cc:135] successfully opened CUDA library curand64_80.dll locally\r\nI c:\\tf_jenkins\\home\\workspace\\release\u2011win\\device\\gpu\\os\\windows\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:885] Found device 0 with properties: \r\nname: GeForce GTX 670\r\nmajor: 3 minor: 0 memoryClockRate (GHz) 0.95\r\npciBusID 0000:01:00.0\r\nTotal memory: 4.00GiB\r\nFree memory: 3.36GiB\r\nI c:\\tf_jenkins\\home\\workspace\\release\u2011win\\device\\gpu\\os\\windows\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:906] DMA: 0 \r\nI c:\\tf_jenkins\\home\\workspace\\release\u2011win\\device\\gpu\\os\\windows\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:916] 0: Y \r\nI c:\\tf_jenkins\\home\\workspace\\release\u2011win\\device\\gpu\\os\\windows\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:975] Creating TensorFlow device (/gpu:0) \u2011> (device: 0, name: GeForce GTX 670, pci bus id: 0000:01:00.0)\r\nE c:\\tf_jenkins\\home\\workspace\\release\u2011win\\device\\gpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('op: \"BestSplits\" device_type: \"CPU\"') for unknown op: BestSplits\r\nE c:\\tf_jenkins\\home\\workspace\\release\u2011win\\device\\gpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('op: \"CountExtremelyRandomStats\" device_type: \"CPU\"') for unknown op: CountExtremelyRandomStats\r\nE c:\\tf_jenkins\\home\\workspace\\release\u2011win\\device\\gpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('op: \"FinishedNodes\" device_type: \"CPU\"') for unknown op: FinishedNodes\r\nE c:\\tf_jenkins\\home\\workspace\\release\u2011win\\device\\gpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('op: \"GrowTree\" device_type: \"CPU\"') for unknown op: GrowTree\r\nE c:\\tf_jenkins\\home\\workspace\\release\u2011win\\device\\gpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('op: \"ReinterpretStringToFloat\" device_type: \"CPU\"') for unknown op: ReinterpretStringToFloat\r\nE c:\\tf_jenkins\\home\\workspace\\release\u2011win\\device\\gpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('op: \"SampleInputs\" device_type: \"CPU\"') for unknown op: SampleInputs\r\nE c:\\tf_jenkins\\home\\workspace\\release\u2011win\\device\\gpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('op: \"ScatterAddNdim\" device_type: \"CPU\"') for unknown op: ScatterAddNdim\r\nE c:\\tf_jenkins\\home\\workspace\\release\u2011win\\device\\gpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('op: \"TopNInsert\" device_type: \"CPU\"') for unknown op: TopNInsert\r\nE c:\\tf_jenkins\\home\\workspace\\release\u2011win\\device\\gpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('op: \"TopNRemove\" device_type: \"CPU\"') for unknown op: TopNRemove\r\nE c:\\tf_jenkins\\home\\workspace\\release\u2011win\\device\\gpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('op: \"TreePredictions\" device_type: \"CPU\"') for unknown op: TreePredictions\r\nE c:\\tf_jenkins\\home\\workspace\\release\u2011win\\device\\gpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('op: \"UpdateFertileSlots\" device_type: \"CPU\"') for unknown op: UpdateFertileSlots\r\nI c:\\tf_jenkins\\home\\workspace\\release\u2011win\\device\\gpu\\os\\windows\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:975] Creating TensorFlow device (/gpu:0) \u2011> (device: 0, name: GeForce GTX 670, pci bus id: 0000:01:00.0)\r\nI c:\\tf_jenkins\\home\\workspace\\release\u2011win\\device\\gpu\\os\\windows\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:975] Creating TensorFlow device (/gpu:0) \u2011> (device: 0, name: GeForce GTX 670, pci bus id: 0000:01:00.0)\r\nI c:\\tf_jenkins\\home\\workspace\\release\u2011win\\device\\gpu\\os\\windows\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:975] Creating TensorFlow device (/gpu:0) \u2011> (device: 0, name: GeForce GTX 670, pci bus id: 0000:01:00.0)\r\nI c:\\tf_jenkins\\home\\workspace\\release\u2011win\\device\\gpu\\os\\windows\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:975] Creating TensorFlow device (/gpu:0) \u2011> (device: 0, name: GeForce GTX 670, pci bus id: 0000:01:00.0)\r\n\r\n...\r\n```", "comments": ["This has been fixed at HEAD since January 17th. You can safely ignore this error message, or upgrade to a nightly build to use the fix. Closing as a duplicate of #8336.", "@mrry The linked issue was reported for the previous 1.0.0 version compared to the latest 1.0.1 that I'm using. In what release will be included?\r\n", "Sadly the fix was not cherry-picked into the 1.0.1 release. It will be in 1.1.\r\n\r\n(@gunan I assume we're still not doing a 1.0.2? If we are, we should definitely cherry-pick this fix.)", "We will start working on 1.1 soon, that will definitely have the fix. since 1.1 is around the corner, I think we will not do 1.0.2", "I get it.Thanks.", "@gunan sadly I just installed Tensorflow today March 26th and received the same message. ", "@mrnameless123 Could you file a new issue, filling in the issue template as much as you can?"]}, {"number": 8333, "title": "Fixing building from source instructions in README", "body": "", "comments": ["Can one of the admins verify this patch?", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for the commit author(s).  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\n\n<!-- need_author_cla -->", "CLAs look good, thanks!\n\n<!-- ok -->", "Fixed @asimshankar! Please check again now.", "@asimshankar fixed!", "Jenkins, test this please"]}, {"number": 8332, "title": "Using control flow loops in @function.Defun fails with InvalidArgumentError", "body": "Quoting from [this Stack Overflow question](http://stackoverflow.com/q/42752060/3574081). The following code snippet:\r\n\r\n```python\r\ndef add_func(x):\r\n    return x+1\r\n\r\n@function.Defun(tf.float32)\r\ndef test(a):\r\n    return tf.map_fn(add, a)\r\n\r\nwith tf.Session() as sess:\r\n    a = tf.ones(shape=(6,1))\r\n    res = sess.run(test(a))\r\n```\r\n\r\n...generates the following error:\r\n\r\n```\r\nInvalidArgumentError: 25 nodes in a cycle\r\n     [[Node: test_8028ca0d_2 = test_8028ca0d[_device=\"/job:localhost/replica:0/task:0/cpu:0\"](ones_4)]]\r\n\r\nCaused by op 'test_8028ca0d_2', defined at:\r\n  File \"C:\\Users\\Nicki\\Anaconda3\\lib\\site-packages\\spyder\\utils\\ipython\\start_kernel.py\", line 223, in <module>\r\n    main()\r\n  File \"C:\\Users\\Nicki\\Anaconda3\\lib\\site-packages\\spyder\\utils\\ipython\\start_kernel.py\", line 219, in main\r\n    kernel.start()\r\n  File \"C:\\Users\\Nicki\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 474, in start\r\n    ioloop.IOLoop.instance().start()\r\n  File \"C:\\Users\\Nicki\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\r\n    super(ZMQIOLoop, self).start()\r\n  File \"C:\\Users\\Nicki\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 887, in start\r\n    handler_func(fd_obj, events)\r\n  File \"C:\\Users\\Nicki\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\r\n    return fn(*args, **kwargs)\r\n  File \"C:\\Users\\Nicki\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\r\n    self._handle_recv()\r\n  File \"C:\\Users\\Nicki\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\r\n    self._run_callback(callback, msg)\r\n  File \"C:\\Users\\Nicki\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\r\n    callback(*args, **kwargs)\r\n  File \"C:\\Users\\Nicki\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\r\n    return fn(*args, **kwargs)\r\n  File \"C:\\Users\\Nicki\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 276, in dispatcher\r\n    return self.dispatch_shell(stream, msg)\r\n  File \"C:\\Users\\Nicki\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 228, in dispatch_shell\r\n    handler(stream, idents, msg)\r\n  File \"C:\\Users\\Nicki\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 390, in execute_request\r\n    user_expressions, allow_stdin)\r\n  File \"C:\\Users\\Nicki\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\r\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\r\n  File \"C:\\Users\\Nicki\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 501, in run_cell\r\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\r\n  File \"C:\\Users\\Nicki\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2717, in run_cell\r\n    interactivity=interactivity, compiler=compiler, result=result)\r\n  File \"C:\\Users\\Nicki\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2827, in run_ast_nodes\r\n    if self.run_code(code, result):\r\n  File \"C:\\Users\\Nicki\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-19-c5e48d04d428>\", line 1, in <module>\r\n    runfile('C:/Users/Nicki/.spyder-py3/temp.py', wdir='C:/Users/Nicki/.spyder-py3')\r\n  File \"C:\\Users\\Nicki\\Anaconda3\\lib\\site-packages\\spyder\\utils\\site\\sitecustomize.py\", line 866, in runfile\r\n    execfile(filename, namespace)\r\n  File \"C:\\Users\\Nicki\\Anaconda3\\lib\\site-packages\\spyder\\utils\\site\\sitecustomize.py\", line 102, in execfile\r\n    exec(compile(f.read(), filename, 'exec'), namespace)\r\n  File \"C:/Users/Nicki/.spyder-py3/temp.py\", line 156, in <module>\r\n    res = sess.run(test(a))\r\n  File \"C:\\Users\\Nicki\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\function.py\", line 618, in __call__\r\n    return _call(self._definition.signature, *args, **kwargs)\r\n  File \"C:\\Users\\Nicki\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\function.py\", line 271, in _call\r\n    compute_shapes=False)\r\n  File \"C:\\Users\\Nicki\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2240, in create_op\r\n    original_op=self._default_original_op, op_def=op_def)\r\n  File \"C:\\Users\\Nicki\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1128, in __init__\r\n    self._traceback = _extract_stack()\r\n\r\nInvalidArgumentError (see above for traceback): 25 nodes in a cycle\r\n     [[Node: test_8028ca0d_2 = test_8028ca0d[_device=\"/job:localhost/replica:0/task:0/cpu:0\"](ones_4)]]\r\n```\r\n\r\nIt looks like the error is coming from [this line in `graph_constructor.cc`](https://github.com/tensorflow/tensorflow/blob/12a98726e769e988f6368a029ec2f5b0ac3ccbd4/tensorflow/core/graph/graph_constructor.cc#L719), but I'm not sure what path a FunctionDef takes to get here.\r\n\r\n@skye: Preliminarily assigning this to you because you've been making functions work a lot better, but please feel free to nominate someone else (or I can help dig into it more).", "comments": ["Nicki, the example snippet you provided doesn't reproduce the error on my machine. Which TensorFlow version are you using?", "Was apparently using a older version (even though i thought that i had the newest version), after updating to newest version the problem is gone.  ", "Great, thanks for following up. For future reference current newest version = 1.0."]}, {"number": 8331, "title": "Fix `go generate` error in case multiple directories in GOPATH exist", "body": "This fix tries to address the issue raised in #7136 where `go generate` will produce an error when multiple directories in GOPATH exists.\r\n\r\nThe issue is because, in case multiple directories exist in GOPATH, the following line in `generate.sh` will not work:\r\n```\r\ncd $(dirname $0)\r\nTF_DIR=${GOPATH}/src/github.com/tensorflow/tensorflow\r\nPROTOC=\"${TF_DIR}/bazel-out/host/bin/external/protobuf/protoc\"\r\n```\r\n\r\nThis fix address the issue by iterating througgh each directory in `GOPATH` so that `protoc` (`${PROTOC}`) could be correctly located:\r\n```\r\nfor g in $(echo $GOPATH | sed \"s/:/ /g\"); do\r\n    TF_DIR=\"${g}/src/github.com/tensorflow/tensorflow\"\r\n    PROTOC=\"${TF_DIR}/bazel-out/host/bin/external/protobuf/protoc\"\r\n    if [ -x \"${PROTOC}\" ]; then\r\n        break\r\n    fi\r\ndone\r\n```\r\n\r\nThis fix fixes #7136.", "comments": ["Can one of the admins verify this patch?", "i'm not a shell script expert, but i think i get the idea and it looks good to me\r\n", "@tensorflow-jenkins test this please"]}]