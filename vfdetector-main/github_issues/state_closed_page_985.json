[{"number": 23854, "title": "Error using Estimator export_saved_model (Not found: Key global_step not found in checkpoint)", "body": "Hello,\r\n\r\nI am trying to prepare a pre-trained model for google cloud ML. I am trying to use an estimator to export the model. During the loading of the checkpoints by the estimator I get the following error:\r\n\r\n```\r\n2018-11-19 13:28:57.526564: W tensorflow/core/framework/op_kernel.cc:1273] OP_REQUIRES failed at save_restore_v2_ops.cc:184 : Not found: Key global_step not found in checkpoint\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1334, in _do_call\r\n    return fn(*args)\r\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1319, in _run_fn\r\n    options, feed_dict, fetch_list, target_list, run_metadata)\r\n  File \"C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1407, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.NotFoundError: Key global_step not found in checkpoint\r\n         [[{{node save_1/RestoreV2}} = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_1/Const_0_0, save_1/RestoreV2/tensor_names, save_1/RestoreV2/shape_and_slices)]]\r\n```\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (use command below): 1.12.0\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory: Tesla K80\r\n\r\n**Code to reproduce the issue**\r\n\r\n```\r\nMODEL_DIR='model/'\r\ndef decode_image(image_bytes):\r\n    image = tf.image.decode_image(image_bytes)\r\n    image = tf.cast(image, dtype=tf.uint8)\r\n    return image\r\n\r\ndef serving_input_fn():\r\n    createmodel()\r\n    inputs = {'image_bytes': tf.placeholder(tf.string, shape=(), name=\"image_bytes\")}\r\n    imagebytes = tf.squeeze(inputs['image_bytes']) # make it a scalar\r\n    image = decode_image(imagebytes)\r\n    # make the outer dimension unknown (and not 1)\r\n    image = tf.placeholder_with_default(image, shape=[None, None, None, 3])\r\n\r\n    features = {'image_bytes' : image}\r\n    return tf.estimator.export.ServingInputReceiver(features, inputs)\r\n\r\ndef model_fn(features, labels, mode, params):\r\n    pred = tf.get_default_graph().get_tensor_by_name(\"fc1_voc12:0\")\r\n    return tf.estimator.EstimatorSpec(\r\n        mode=tf.estimator.ModeKeys.PREDICT,\r\n        predictions=pred,\r\n        export_outputs={'pred':tf.estimator.export.PredictOutput(pred)}\r\n        )\r\n\r\nestimator = tf.estimator.Estimator(\r\n    model_fn=model_fn,\r\n    model_dir=MODEL_DIR)\r\n\r\nestimator.export_savedmodel('deployment_gcp_1', serving_input_fn, strip_default_attrs=True)\r\n```\r\n\r\nI have searched this issue quite a bit. There was one bug report for an older version of tensorflow (I think 1.2.0 but I am not sure now). I am able to load and save this model using tf.saved_model.simple_save, and it works when I run predictions on it.\r\n\r\nI am not sure if this is a bug or if I am missing something really simple.\r\n", "comments": ["I have tried the same script on a linux machine, with python2.7, tensorflow 1.4.0 and no longer receive the error. This appears to be a bug, maybe in newer versions of tensorflow or python3.6 and windows.", "@ispirmustafa  Is this an issue with the tensorflow version ?", "I did some more work on this and the issue appeared on tensorflow 1.4 as well. I managed to work around the issue by loading the chexkpoint, adding a variable named global_step and then exporting it again. Once I did that I was able to use my original code without this error.", "@burhanbvk  Glad to know that your issue is resolved.", "@harshini-gadige please note that Karmel is the current owner of Estimators for your future references.", "> @harshini-gadige please note that Karmel is the current owner of Estimators for your future references.\r\n\r\nThanks for the information. I was following the sheet which I had. Going forward I'll route to Karmel.", "@harshini-gadige please let me know where I can find the sheet. I'll update it."]}, {"number": 23853, "title": "Graph optimized using tf.contrib.tensorrt is not loadable with TF_GraphImportGraphDef", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes.\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\n\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): Source.\r\n- TensorFlow version (use command below): v1.12\r\n- Python version: 2.7.12\r\n\r\n- Bazel version (if compiling from source): 0.19.0\r\n- GCC/Compiler version (if compiling from source): 5.4.0\r\n- CUDA/cuDNN version: 9.0/7.0.5\r\n- GPU model and memory: 1080 Ti\r\n\r\n**Describe the current behavior**\r\n\r\nI optimize a TensorFlow graph with\r\n```\r\n    precision_mode = 'FP32'  # \"FP32\",\"FP16\" or \"INT8\"\r\n    graph_def = trt.create_inference_graph(\r\n        input_graph_def=graph_def,\r\n        outputs=output_node_names,\r\n        max_batch_size=num_cameras,\r\n        max_workspace_size_bytes=4*10**9,\r\n        precision_mode=precision_mode,\r\n        minimum_segment_size=10,  # minimum number of nodes in an engine,\r\n    )\r\n```\r\n\r\n, save the resulting graph, and try to load it in a C++ program using C API.\r\n\r\nFirst, I call\r\n\r\n```\r\nTF_LoadLibrary(\"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tensorrt/python/ops/_trt_engine_op.so\", status)\r\n```\r\n\r\nand call `TF_GraphImportGraphDef` with the optimized graph.\r\n\r\nI get the following error:\r\n\r\n```\r\nTF_GraphImportGraphDef: No shape inference function exists for op 'TRTEngineOp', did you forget to define it?\r\n```\r\n\r\n**Describe the expected behavior**\r\n\r\nThe call to `TF_GraphImportGraphDef` must succeed.\r\n\r\n**Code to reproduce the issue**\r\n\r\nIt seems that the issue, although not in the bug tracker, should be already known to the authors: https://github.com/tensorflow/tensorflow/blob/v1.12.0/tensorflow/contrib/tensorrt/ops/trt_engine_op.cc#L46\r\nHowever, I can make a minimal example to reproduce the problem on demand.\r\n\r\n**Other info / logs**\r\n\r\nIt is a pain that a TRT-optimized graph cannot be used outside of python now.\r\nI would be happy to know about a workaround, in case one exists.\r\n", "comments": ["Hello @yegord,\r\n\r\nCould you please link your application with trt_conversion.so and trt_engine_op_op_lib", "@samikama \r\n\r\nthis is with respect to https://github.com/tensorflow/tensorflow/issues/23243 \r\n\r\nWhere is the lib located, \u201ctrt_conversion.so\u201d , can you please tell?\r\n\u00a0\r\nThere is library named _wrap_conversion.so\r\n\u00a0\r\n```\r\nTensorFlow.loadLibrary(\"/home/sujitb/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/contrib/tensorrt/python/ops/_trt_engine_op.so\")\r\nTensorFlow.loadLibrary(\"/home/sujitb/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/contrib/tensorrt/_wrap_conversion.so\")\r\n\u00a0\r\n```\r\n```\r\nException in thread \"main\" java.lang.UnsatisfiedLinkError: /home/sujitb/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/contrib/tensorrt/_wrap_conversion.so: undefined symbol: _Py_NoneStruct\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at org.tensorflow.TensorFlow.loadLibrary(TensorFlow.java:47)\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at com.nvidia.tf.InspectModel2$.main(InspectModel2.scala:22)\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at com.nvidia.tf.InspectModel2.main(InspectModel2.scala)\r\n```\r\n\r\n", "So there seem to be two issues here:\r\n\r\n1. That there is no shape inference function registered (the [Python API uses a backdoor](https://github.com/tensorflow/tensorflow/blob/30344d07629fd350686046079fe1ff75c8d36fb5/tensorflow/python/framework/ops.py#L2880) to be okay with that, but ideally we want all operations to have a shape inference function, even if that function says \"Unknown Shape\". And we want to get rid of that backdoor). I'll try a fix for that.\r\n\r\n2. For reasons I'm not quite clear on (@aaroey @samikama may know), the `TRTEngine` operation's kernel is included in a Python specific target ([`//tensorflow/contrib/tensorrt:wrap_conversion`](https://github.com/tensorflow/tensorflow/blob/a6d8ffae097d0132989ae4688d224121ec6d8f35/tensorflow/contrib/tensorrt/BUILD#L196)) instead of in the [shared library for the op](https://github.com/tensorflow/tensorflow/blob/a6d8ffae097d0132989ae4688d224121ec6d8f35/tensorflow/contrib/tensorrt/BUILD#L53). I suspect/hope this can be changed to make the kernel independent of Python. Will look into it.", "@asimshankar Excellent summary, thanks!\r\n\r\n@samikama So, I cherry-picked the patch enabling the shape function (4fbbeea).\r\nI also applied the following changes:\r\n\r\n```diff\r\ndiff --git a/tensorflow/BUILD b/tensorflow/BUILD\r\nindex 9b62a50..254ad51 100644\r\n--- a/tensorflow/BUILD\r\n+++ b/tensorflow/BUILD\r\n@@ -443,6 +443,9 @@ tf_cc_shared_object(\r\n         \"//tensorflow/c:version_script.lds\",\r\n         \"//tensorflow/c/eager:c_api\",\r\n         \"//tensorflow/core:tensorflow\",\r\n+        \"//tensorflow/contrib/tensorrt:trt_conversion\",\r\n+        \"//tensorflow/contrib/tensorrt:trt_engine_op_op_lib\",\r\n+        \"//tensorflow/contrib/tensorrt:trt_engine_op_kernel\",\r\n     ],\r\n )\r\n```\r\n\r\n(Somehow without `trt_engine_op_kernel` the kernel was not successfully registered.)\r\n\r\nAs a result, I get the expected performance boost of around 10% against vanilla TensorFlow graph.\r\nHowever, my C++ application starts crashing after dozens of seconds running, with the following message:\r\n```\r\n2018-11-27 19:19:10.135505: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\r\n2018-11-27 19:19:11.164065: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-11-27 19:19:11.164123: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0\r\n2018-11-27 19:19:11.164136: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N\r\n2018-11-27 19:19:11.164648: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9426 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:03:00.0, compute capability: 6.1)\r\n2018-11-27 19:19:52.094600: E tensorflow/stream_executor/cuda/cuda_event.cc:48] Error polling for event status: failed to query event: CUDA_ERROR_ILLEGAL_ADDRESS: an illegal memory access was encountered\r\n2018-11-27 19:19:52.094660: F tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc:274] Unexpected Event status: 1\r\nssd_detection2:terminate_handler.cpp:25: terminate_handler(): abort\r\n0. /usr/lib/libassert.so(+0x32d0) [0x7fcafecdb2d0]\r\n1. /lib/x86_64-linux-gnu/libc.so.6(+0x354b0) [0x7fcad54544b0]\r\n2. /lib/x86_64-linux-gnu/libc.so.6(gsignal+0x38) [0x7fcad5454428]\r\n3. /lib/x86_64-linux-gnu/libc.so.6(abort+0x16a) [0x7fcad545602a]\r\n4. /usr/lib/libtensorflow_framework.so(+0x6eeab7) [0x7fcaca33bab7]\r\n5. /usr/lib/libtensorflow_framework.so(_ZN10tensorflow8EventMgr10PollEventsEbPN4absl13InlinedVectorINS0_5InUseELm4ESaIS3_EEE+0xf3) [0x7fcaca306633]\r\n6. /usr/lib/libtensorflow_framework.so(_ZN10tensorflow8EventMgr8PollLoopEv+0xce) [0x7fcaca306dee]\r\n7. /usr/lib/libtensorflow_framework.so(_ZN5Eigen26NonBlockingThreadPoolTemplIN10tensorflow6thread16EigenEnvironmentEE10WorkerLoopEi+0x241) [0x7fcaca30c441]\r\n8. /usr/lib/libtensorflow_framework.so(_ZNSt17_Function_handlerIFvvEZN10tensorflow6thread16EigenEnvironment12CreateThreadESt8functionIS0_EEUlvE_E9_M_invokeERKSt9_Any_data+0x37) [0x7fcaca30a007]\r\n9. /usr/lib/x86_64-linux-gnu/libstdc++.so.6(+0xb8c80) [0x7fcad5dc0c80]\r\n10. /lib/x86_64-linux-gnu/libpthread.so.0(+0x76ba) [0x7fcae428c6ba]\r\n11. /lib/x86_64-linux-gnu/libc.so.6(clone+0x6d) [0x7fcad552641d]\r\n```\r\n\r\nThe application runs TF_SessionRun on the same session from two threads in parallel.\r\nIf I disable one of the threads, the crash goes away.\r\nSo, it is either plain OOM (caught too late), or some data race.\r\nDoes it ring the bell to anybody?\r\n", "@pooyadavoodi may have an idea for the crash problem.\r\nAlso, @yegord do you have a repro for that? Thanks.", "If you have a hypothesis \u2014 shoot, I will check it.\r\nIf the cause is not that clear, I will make a minimal example, but it will take another day or so.\r\n", "@yegord I thought TF_SessionRun() is not thread-safe.", "Could you reduce `max_workspace_size_bytes` and also use `allow_growth` in the session config and see if the problem persists.", "@samikama : `TF_SessionRun` is thread-safe (and op kernels are supposed to be too).", "> @asimshankar Excellent summary, thanks!\r\n> \r\n> @samikama So, I cherry-picked the patch enabling the shape function ([4fbbeea](https://github.com/tensorflow/tensorflow/commit/4fbbeea283de57deb681699a93694871a297d286)).\r\n> I also applied the following changes:\r\n> \r\n> ```diff\r\n> diff --git a/tensorflow/BUILD b/tensorflow/BUILD\r\n> index 9b62a50..254ad51 100644\r\n> --- a/tensorflow/BUILD\r\n> +++ b/tensorflow/BUILD\r\n> @@ -443,6 +443,9 @@ tf_cc_shared_object(\r\n>          \"//tensorflow/c:version_script.lds\",\r\n>          \"//tensorflow/c/eager:c_api\",\r\n>          \"//tensorflow/core:tensorflow\",\r\n> +        \"//tensorflow/contrib/tensorrt:trt_conversion\",\r\n> +        \"//tensorflow/contrib/tensorrt:trt_engine_op_op_lib\",\r\n> +        \"//tensorflow/contrib/tensorrt:trt_engine_op_kernel\",\r\n>      ],\r\n>  )\r\n> ```\r\n> \r\n> (Somehow without `trt_engine_op_kernel` the kernel was not successfully registered.)\r\n> \r\n> As a result, I get the expected performance boost of around 10% against vanilla TensorFlow graph.\r\n> However, my C++ application starts crashing after dozens of seconds running, with the following message:\r\n> \r\n> ```\r\n> 2018-11-27 19:19:10.135505: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\r\n> 2018-11-27 19:19:11.164065: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n> 2018-11-27 19:19:11.164123: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0\r\n> 2018-11-27 19:19:11.164136: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N\r\n> 2018-11-27 19:19:11.164648: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9426 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:03:00.0, compute capability: 6.1)\r\n> 2018-11-27 19:19:52.094600: E tensorflow/stream_executor/cuda/cuda_event.cc:48] Error polling for event status: failed to query event: CUDA_ERROR_ILLEGAL_ADDRESS: an illegal memory access was encountered\r\n> 2018-11-27 19:19:52.094660: F tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc:274] Unexpected Event status: 1\r\n> ssd_detection2:terminate_handler.cpp:25: terminate_handler(): abort\r\n> 0. /usr/lib/libassert.so(+0x32d0) [0x7fcafecdb2d0]\r\n> 1. /lib/x86_64-linux-gnu/libc.so.6(+0x354b0) [0x7fcad54544b0]\r\n> 2. /lib/x86_64-linux-gnu/libc.so.6(gsignal+0x38) [0x7fcad5454428]\r\n> 3. /lib/x86_64-linux-gnu/libc.so.6(abort+0x16a) [0x7fcad545602a]\r\n> 4. /usr/lib/libtensorflow_framework.so(+0x6eeab7) [0x7fcaca33bab7]\r\n> 5. /usr/lib/libtensorflow_framework.so(_ZN10tensorflow8EventMgr10PollEventsEbPN4absl13InlinedVectorINS0_5InUseELm4ESaIS3_EEE+0xf3) [0x7fcaca306633]\r\n> 6. /usr/lib/libtensorflow_framework.so(_ZN10tensorflow8EventMgr8PollLoopEv+0xce) [0x7fcaca306dee]\r\n> 7. /usr/lib/libtensorflow_framework.so(_ZN5Eigen26NonBlockingThreadPoolTemplIN10tensorflow6thread16EigenEnvironmentEE10WorkerLoopEi+0x241) [0x7fcaca30c441]\r\n> 8. /usr/lib/libtensorflow_framework.so(_ZNSt17_Function_handlerIFvvEZN10tensorflow6thread16EigenEnvironment12CreateThreadESt8functionIS0_EEUlvE_E9_M_invokeERKSt9_Any_data+0x37) [0x7fcaca30a007]\r\n> 9. /usr/lib/x86_64-linux-gnu/libstdc++.so.6(+0xb8c80) [0x7fcad5dc0c80]\r\n> 10. /lib/x86_64-linux-gnu/libpthread.so.0(+0x76ba) [0x7fcae428c6ba]\r\n> 11. /lib/x86_64-linux-gnu/libc.so.6(clone+0x6d) [0x7fcad552641d]\r\n> ```\r\n> The application runs TF_SessionRun on the same session from two threads in parallel.\r\n> If I disable one of the threads, the crash goes away.\r\n> So, it is either plain OOM (caught too late), or some data race.\r\n> Does it ring the bell to anybody?\r\n\r\n@yegord Could you provide a repro. We need to look into the kernel registration that you mentioned above.\r\n", "> So, it is either plain OOM (caught too late), or some data race.\r\n\r\nDoes not look like an OOM, because reducing the input image size by a factor of many (6-fold or so) does not fix it.\r\n\r\n> use allow_growth in the session config\r\n\r\nAlready there.\r\n\r\n> reduce max_workspace_size_bytes\r\n\r\nReducing from `4*10**9` to `2*10**9` does not make the crash go away.\r\n\r\nI'll be back with a repro then.", "Please find the repro here: https://github.com/yegord/tf-trt-linking-and-data-race-example\r\n`make && ./main` should reproduce the crash.\r\n\r\nThe error message that I personally observe is here: https://github.com/yegord/tf-trt-linking-and-data-race-example/blob/master/crash.txt\r\n\r\nTensorflow version being used (v1.12 with two patches: uncomment the shape function and link tensorrt operation into libtensorflow.so): https://github.com/yegord/tensorflow/tree/issue-23853\r\n\r\nTensorFlow is installed with `bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package //tensorflow:libtensorflow.so && bazel-bin/tensorflow/tools/pip_package/build_pip_package .. && sudo pip uninstall -y tensorflow; sudo pip install ../tensorflow*.whl && sudo cp bazel-bin/tensorflow/*.so /usr/lib && sudo mkdir -p /usr/lib/tensorflow/c && sudo cp tensorflow/c/c_api.h /usr/include/tensorflow/c`\r\n\r\nThe repro demonstrates two points. First, there must be a way to link for an external user to link against something from TensorFlow (without patching TensorFlow like I did) and be able to start using TensorRT operation. Second, parallel calls to TensorRT operations should not crash the process.\r\n", "As of the crash, it might happen because you seem call `enqueue` on the same `nvinfer1::IExecutionContext` instance in parallel: https://github.com/tensorflow/tensorflow/blob/5d45c7e715eb1ea8b69133da52228b34ccb3d29d/tensorflow/contrib/tensorrt/kernels/trt_engine_op.cc#L406\r\nAnd, as my coworker noticed, this is not thread-safe: https://docs.nvidia.com/deeplearning/sdk/tensorrt-best-practices/index.html#thread-safety\r\n", "@ yegord,\r\nThat is correct. adding a mutex around the call should solve it since enqueue is pretty lightweight. There were plans to move away from class member execution context but things are reprioritized. I will take a look at your example and get back to you.", "I can reproduce the error and I added a mutex which did solve the problem. I'll make a fix soon.", "Apparently, there is also a data race leading to a crash during the parallel creation of multiple dynamic int8 engines. Could you have a look?\r\n\r\nThe repro is here: https://github.com/yegord/tf-trt-linking-and-data-race-example/tree/crash-with-int8-engines\r\n\r\nThe error message that I see: https://github.com/yegord/tf-trt-linking-and-data-race-example/blob/crash-with-int8-engines/crash.txt\r\n\r\nThe TensorFlow version used is 1.12 with few patches from you: https://github.com/yegord/tensorflow/tree/issue-23853-2\r\n\r\nBuild instructions are as above: https://github.com/tensorflow/tensorflow/issues/23853#issuecomment-443270387\r\n\r\n(I hope you do not mind that I pile up remotely related issues into a single ticket.)\r\n\r\nThanks!", "Thanks for the repro @yegord, I'll try it and get back to you.", "The original problem in this issue is fixed: if we install the latest nightly pip package, we should see the TF-TRT shared library in `site-packages/tensorflow/compiler/tf2tensorrt/python/ops/libtftrt.so`.\r\n\r\n@yegord, to solve your linking problem, I have an example in https://github.com/aaroey/tensorflow/blob/issue_repros/test/fixed-issue23853/Makefile#L14.", "For the INT8 calibration problem, I believe it's fixed at HEAD. Here is a (fixed) repo for it: https://github.com/aaroey/tensorflow/blob/issue_repros/test/fixed-issue23853-int8/Makefile\r\n\r\nI'm closing this, feel free to let me know if there are any questions. Thanks."]}, {"number": 23852, "title": "reduce_max returns wrong shape", "body": "**Problem**\r\n**tf.reduce_max returns tensor with wrong shape**\r\n\r\n    ...\r\n    left_expr = tf.reduce_sum(left_encs, axis=1)\r\n    left_expr = tf.Print(left_expr,  [tf.shape(left_encs), tf.shape(left_expr)], message=\"Shapes Are: \")\r\n    ...\r\n\r\nand the output is:\r\n\r\n    Shapes Are: [46 21 512][1 512]\r\n\r\nthe tensor `left_encs` is the output of transformer encoder, the meaning of the shape is [batch_size, sequence_length, hidden_dim]\r\n\r\nI have tried to construct a random tensor with same shape as `left_encs` and the call `tf.reduce_sum(left_encs, axis=1)` and the output is as expected `[46, 512]`.\r\n\r\nbut I cannot get it right from the real code.\r\n\r\nis there any operation should I do before calling `tf.reduce_sum`?\r\n\r\n**System information**\r\n- TensorFlow installed from: Anaconda\r\n- TensorFlow version: v1.11\r\n- Python version: 3.6\r\n- CUDA/cuDNN version: v9.0\r\n- GPU model and memory: Tesla K40\r\n\r\n", "comments": ["In order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!\r\n", "Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 23851, "title": "Error in running pre-compiled binary on tensorflow", "body": "\r\nSystem information\r\n\r\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 (64-bit)\r\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\nTensorFlow installed from (source or binary): Source\r\nTensorFlow version:1.7 - 1.9\r\nPython version:3.6\r\nInstalled using virtualenv? pip? conda?: Git\r\nBazel version (if compiling from source):No\r\nGCC/Compiler version (if compiling from source): CMake : 3.10.1\r\nCUDA/cuDNN version: No\r\nGPU model and memory: No\r\nDescribe the problem\r\nI am trying to run the pre-compiled tensor flow binaries and run the tensorflow example.\r\nI know the support for cmake have been depreciated but i am using  an old version of tensorflow\r\nso need some help in regards.\r\n\r\nProvide the exact sequence of commands / steps that you executed before running into the problem\r\n1. Downloading the pre-compiled binary for windows.\r\n2. Included the project in qt-creator\r\n3. Build the project\r\n\r\nAny other info / logs:\r\nmain.obj : error LNK2019: unresolved external symbol \"public: virtual __cdecl tensorflow::ConfigProto::~ConfigProto(void)\" (??1ConfigProto@tensorflow@@UEAA@XZ) referenced in function \"public: __cdecl tensorflow::SessionOptions::~SessionOptions(void)\" (??1SessionOptions@tensorflow@@QEAA@XZ)\r\nmain.obj : error LNK2019: unresolved external symbol \"public: __cdecl tensorflow::SessionOptions::SessionOptions(void)\" (??0SessionOptions@tensorflow@@QEAA@XZ) referenced in function main\r\nmain.obj : error LNK2019: unresolved external symbol \"class tensorflow::Status __cdecl tensorflow::NewSession(struct tensorflow::SessionOptions const &,class tensorflow::Session * *)\" (?NewSession@tensorflow@@YA?AVStatus@1@AEBUSessionOptions@1@PEAPEAVSession@1@@Z) referenced in function main\r\ndebug\\tensorflowcppNew.exe : fatal error LNK1120: 4 unresolved externals", "comments": ["The standard Python binaries exist only for Python 3.5. Please take a look at [TensorFlow CMake build](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/cmake#tensorflow-cmake-build) to know more.", "@ymodak : Here i am refering to c++ binaries. I had a issue in linking and running them", "@asimshankar knows more about the c++ libraries.", "Unfortunately, I am not familiar with qt-creator or Windows development enough to provide any useful thoughts here. A cursory look at the error messages suggest that somehow your project isn't linking against the TensorFlow C libraries (`tensorflow.dll` on Windows).\r\n\r\nThat said, I'm confused about the exact setup here -  how did you install TensorFlow (pip / conda / something else?)? In the questionnaire above, the answer is \"git\".\r\n\r\nMarking as \"Community Support\" in case other Windows users who use qt-creator can chime in. ", "@asimshankar : In qt creator you can specify the compiler to use so i am using MSVC compiler.\r\nIt's similar using visual studio.\r\nI was able to run the binary build using sse2. The problem is arising with avx2 which i am currently \r\ntrying to figure out."]}, {"number": 23850, "title": "Bugfix: remove first arg instead of `self`", "body": "Bugfix: remove first arg instead of `self` to make the function more robust and works for classmethod", "comments": ["@case540  Any update please ?", "@case540 A friendly ping", "@case540 Could you PTAL and approve", "Nagging Reviewer @case540: You have been added as a reviewer to this pull request. Please add your review or reassign. It has been 14 days with no activity and the `awaiting review` label has been applied."]}, {"number": 23849, "title": " How to get coordinates on the screen frame \uff1f", "body": "I ran the Android example of TensorFlow successfully, but I want to know that there is a blue box in the TFL Detect application. I want to know which method is used to get the coordinates of the box. Which class or method is the specific Android code? Who can help me? Thank you.", "comments": ["This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged//tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n"]}, {"number": 23848, "title": "Object detection example for TFLite", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 1.12.0\r\n- Are you willing to contribute it (Yes/No):Yes\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nI want to add an example for converting an object detection model say, ssd_mobilenet_v1 to TFLite. The code will have a Makefile for setting up everything and a jupyter notebook for showing step by step procedure for conversion.\r\n**Will this change the current api? How?**\r\nNo\r\n**Who will benefit with this feature?**\r\nI see that a lot of people ask questions around this as they don't follow the correct procedure. Even I have invested a lot of time in it and I think that a working example can help them in saving a lot of time.\r\n**Any Other info.**\r\nAfter that, I can even write script for running it on Raspberry Pi 3.", "comments": ["Hi @aselle, I want your views on this. Will it be a good idea or not?", "\ud83d\udc4d would like to see this", "We have several tutorials for object detection @ https://www.tensorflow.org/lite/models/object_detection/overview."]}, {"number": 23847, "title": "~40% performance decrease since Tensorflow 1.9 when training large models", "body": "**System information**\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v1.9.0-0-g25c197e 1.9.0\r\n- Python version: 3\r\n- Bazel version (if compiling from source): -\r\n- GCC/Compiler version (if compiling from source): -\r\n- CUDA/cuDNN version: 9.0.176/7.1.4.18\r\n- GPU model and memory: 8 x Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\r\n\r\n**Describe the current behavior**\r\nI train a model using slim in tensorflow models with the flowers dataset and the large nasnet. This were run on the official tensorflow docker images.\r\nOn my Tesla V100 for tensorflow 1.8.0-devel-gpu-py3 I got around \r\n`INFO:tensorflow:global_step/sec: 1.33334`\r\nWith tensorflow 1.9.0-devel-gpu-py3 a maximum at\r\n`INFO:tensorflow:global_step/sec: 0.89946`\r\nWith the current tensorflow 1.12.0-devel-gpu-py3 a maximum at\r\n`INFO:tensorflow:global_step/sec: 0.900003`\r\n\r\n**Describe the expected behavior**\r\nThere should not be an performance decrease in this drastic \r\n\r\n**Code to reproduce the issue**\r\n```shell\r\n#!/usr/bin/env bash\r\n[ ! -d \"models\" ] && git clone https://github.com/tensorflow/models.git\r\ncd models/research/slim/\r\nMODEL_NAME=\"nasnet_large\"\r\nTRAIN_DIR=/tmp/flowers-models/${MODEL_NAME}\r\nDATASET_DIR=/tmp/flowers\r\nrm -rf \"$TRAIN_DIR\"\r\nexport CUDA_DEVICE_ORDER=\"PCI_BUS_ID\"\r\nexport CUDA_VISIBLE_DEVICES=\"0,1\"\r\n\r\npython download_and_convert_data.py \\\r\n    --dataset_name=flowers \\\r\n    --dataset_dir=${DATASET_DIR}\r\n\r\npython train_image_classifier.py \\\r\n    --train_dir=${TRAIN_DIR}/all \\\r\n    --dataset_name=flowers \\\r\n    --dataset_split_name=train \\\r\n    --dataset_dir=${DATASET_DIR} \\\r\n    --model_name=${MODEL_NAME} \\\r\n    --max_number_of_steps=500 \\\r\n    --batch_size=16 \\\r\n    --learning_rate=0.015 \\\r\n    --save_interval_secs=60000 \\\r\n    --save_summaries_secs=60 \\\r\n    --log_every_n_steps=10 \\\r\n    --optimizer=rmsprop \\\r\n    --num_preprocessing_threads 4 \\\r\n    --num_readers 8 \\\r\n    --moving_average_decay=0.9999 \\\r\n    --weight_decay=0.00005 \\\r\n    --learning_rate_decay_type=exponential \\\r\n    --learning_rate_decay_factor=0.97 \\\r\n    --label_smoothing=0.1\r\n```\r\n\r\n**Other info / logs**\r\nI thought this issue #20843 is related to the problem but I have done a git bisect between the `v1.8.0` and the `v1.9.0` tag and running the script above for every commit and found the one that introduce the largest drop in performance: d4976f7. This commit enabled the layout optimizer by default for all gpu cluster. As a workaround and a proof I disabled the layout optimizer with the following config:\r\n```python\r\nrewrite_options = rewriter_config_pb2.RewriterConfig(layout_optimizer=rewriter_config_pb2.RewriterConfig.OFF)\r\ngraph_options = tf.GraphOptions(rewrite_options=rewrite_options)\r\nconfig = tf.ConfigProto(graph_options=graph_options) \r\n```  \r\nAnd most of the performance were back again in `tensorflow 1.9.0-devel-gpu-py3`:\r\n`INFO:tensorflow:global_step/sec: 1.18333`\r\nAnd in the latest release `tensorflow 1.12.0-devel-gpu-py3`:\r\n`INFO:tensorflow:global_step/sec: 1.23337`\r\n[Here](https://gist.github.com/DavidWiesner/c6af3238a90b3a8b1209543a9f8d7127#file-git-bisect-log) is a full log of my bisect script. [One another log](https://gist.github.com/DavidWiesner/c6af3238a90b3a8b1209543a9f8d7127#file-git-bisect-layout_optimizer-on-off-log) shows the influence of disabling the layout-optimizer in commit d4976f7 (that introducing the drop in performance) and some release versions of tensorflow. \r\nMaybe @yaozhang can answer why the layout optimizer was disabled for some architectures until 1.8.0 in f0d1abbf2 and why @zhangyaobit enabled for all architectures since 1.9.0 in d4976f7\r\n", "comments": ["I was able to measure 10-15% performance regression with a batch size 4 on a single V100 GPU (larger batch OOMs). V100 has faster (30%-50%) convolutions (and conv gradients) in NCHW data format, and layout optimizer correctly swaps all convs from default NHWC to NCHW in this model, however it seems that all the extra transpose nodes are killing all the conv gains.\r\n\r\nLooking at the executed graph and profiles, maybe layout optimizer missed an opportunity to remove redundant transposes.\r\n\r\n", "The problem is that NASNet model has mostly 1x1 convolutions, and in NHWC format they are computed as a matrix multiplication, in NCHW they go though cuDNN convolution, and it's ~30-50% slower. I'll try to come up with a better strategy for layout swapping,  though it might be problematic, because currently we can only have a single \"target\" data format for the graph.", "@ezhulenev Any updates on this?", "I'm working on a new layout optimizer in MLIR framework, and this problem is solved there, however I'm not sure when it will be on by default, should have some certainty in a few weeks.", "@DavidWiesner,\r\n Sorry for the delayed response. As per [this comment](https://github.com/tensorflow/tensorflow/issues/23847#issuecomment-604629618), your issue should be resolved. Can you please check and let us know if it is so? Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 23846, "title": "Distributed TensorFlow hangs at the end of one iteration when using DataSet api", "body": "Training epoch by epoch, the program will hangs on some random nodes forever at the end of one iteration, namely the end of one epoch. It appears certainly when using `DataSet` api, while it is fine when using old `Queue` based data api. I have set `inter_op_parallelism_threads=1, intra_op_parallelism_threads=1`. @mrry \r\n\r\nEnv:\r\n  Distributed running on Yarn.\r\n  Node information: CentOS, linux kernel 3.10.0. Only CPU.\r\n  TensorFlow: r1.12, built from source.\r\n\r\nDemo(It's independent of the model. It's easier to reproduce by using more worker nodes. Here, I use 50 worker nodes and 20 ps nodes.)\r\n```python\r\nflags.DEFINE_string(\"ps_hosts\", \"\", \"Comma-separated list of hostname:port pairs\")\r\nflags.DEFINE_string(\"worker_hosts\", \"\", \"Comma-separated list of hostname:port pairs\")\r\nflags.DEFINE_string(\"job_name\", \"\", \"One of 'ps', 'worker'\")\r\nflags.DEFINE_integer(\"task_index\", 0, \"Index of task within the job\")\r\n\r\nFLAGS(sys.argv)\r\n\r\nclass Job(object):\r\n    def __init__(self):\r\n        self.ps_hosts = FLAGS.ps_hosts.split(',')\r\n        self.worker_hosts = FLAGS.worker_hosts.split(',')\r\n        self.job_name = FLAGS.job_name\r\n        self.task_index = FLAGS.task_index\r\n        self.cluster = tf.train.ClusterSpec({'ps': self.ps_hosts, 'worker': self.worker_hosts})\r\n        self.server = tf.train.Server(self.cluster, job_name=self.job_name, task_index=self.task_index)\r\n        self.is_chief = (self.task_index == 0 and self.job_name == 'worker')\r\n        worker_prefix = '/job:worker/task:%s' % self.task_index\r\n        self.cpu_device = '%s/cpu:0' % worker_prefix\r\n        self.param_server_device = tf.train.replica_device_setter(\r\n            worker_device=self.cpu_device, cluster=self.cluster,\r\n            ps_strategy=tf.contrib.training.GreedyLoadBalancingStrategy(len(self.ps_hosts), tf.contrib.training.byte_size_load_fn))\r\n        self.num_ps = self.cluster.num_tasks('ps')\r\n        self.num_worker = self.cluster.num_tasks('worker')\r\n\r\n    def data_iter(self, batch_size=1000, file_pattern='./input/part-*'):\r\n        def _parse_function(examples):\r\n            features = {}\r\n            features['label'] = tf.FixedLenFeature([], tf.float32)\r\n            features['user_id'] = tf.FixedLenFeature([1], tf.int64)\r\n            features['item_id'] = tf.FixedLenFeature([1], tf.int64)\r\n            instance = tf.parse_example(examples, features)\r\n            return instance['label'], instance['user_id'], instance['item_id']\r\n\r\n        with tf.name_scope('input'):\r\n            files = tf.data.Dataset.list_files(file_pattern)\r\n            dataset = files.apply(tf.contrib.data.parallel_interleave(\r\n                        lambda file: tf.data.TFRecordDataset(file),\r\n                        cycle_length=1, sloppy=True))\r\n            dataset = dataset.prefetch(buffer_size=batch_size*2)\r\n            dataset = dataset.batch(batch_size)\r\n            dataset = dataset.map(_parse_function, num_parallel_calls=1)\r\n            iterator = dataset.make_initializable_iterator()\r\n            return iterator\r\n\r\n    def model(self, user_id, item_id):\r\n        user_embedding_variable = tf.get_variable('user_emb_var', [1000000, 32], initializer=tf.random_uniform_initializer(minval=-0.5, maxval=0.5, dtype=tf.float32))\r\n        item_embedding_variable = tf.get_variable('user_emb_var', [500000, 32], initializer=tf.random_uniform_initializer(minval=-0.5, maxval=0.5, dtype=tf.float32))\r\n        user_embedding = tf.nn.embedding_lookup(user_embedding_variable, user_id)\r\n        item_embedding = tf.nn.embedding_lookup(item_embedding_variable, item_id)\r\n        user_embedding = tf.reshape(user_embedding, [-1, 32])\r\n        item_embedding = tf.reshape(item_embedding, [-1, 32])\r\n        cross = tf.reduce_sum(user_embedding * item_embedding, 1, keep_dims=True)\r\n        bias = tf.get_variable('bias', initializer=tf.constant(np.zeros((1), dtype=np.float32)), dtype=tf.float32)\r\n        layer = cross + bias\r\n        weight_np = np.zeros((1, 2), dtype=np.float32)\r\n        weight_np[:, 1] = 1\r\n        weight = tf.get_variable('weight', initializer=tf.constant(weight_np), dtype=tf.float32, trainable=False)\r\n        logits = tf.matmul(layer, weight)\r\n        return logits\r\n\r\n    def train(self):\r\n        if self.job_name == 'ps':\r\n            with tf.device('/cpu:0'):\r\n                self.server.join()\r\n        elif self.job_name == 'worker':\r\n            with tf.Graph().as_default():\r\n                with tf.device(self.param_server_device):\r\n                    train_iterator = self.data_iter()\r\n                    train_label, train_user_id, train_item_id = train_iterator.get_next()\r\n                    train_logit = self.model(train_user_id, train_item_id)\r\n                    train_label = tf.to_int64(train_label)\r\n                    train_cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=train_logit, labels=train_label)\r\n                    train_loss = tf.reduce_mean(train_cross_entropy, name='loss')\r\n                    opt = tf.train.AdamOptimizer(learning_rate=0.001)\r\n                    train_op = opt.minimize(train_loss)\r\n                    saver = tf.train.Saver()\r\n\r\n                    sess_config = tf.ConfigProto(allow_soft_placement=True,\r\n                        log_device_placement=False,\r\n                        device_filters=[\"/job:ps\", \"/job:%s/task:%d\" % (self.job_name, self.task_index)],\r\n                        operation_timeout_in_ms=60000,\r\n                        inter_op_parallelism_threads=1,\r\n                        intra_op_parallelism_threads=1)\r\n                    with tf.train.MonitoredTrainingSession(master=self.server.target,\r\n                                                           is_chief=self.is_chief,\r\n                                                           config=sess_config) as sess:\r\n                        epoch_num = 0\r\n                        while epoch_num < 10:\r\n                            epoch_num += 1\r\n                            sess.run(train_iterator.initializer)\r\n                            while True:\r\n                                try:\r\n                                    sess.run(train_op)\r\n                                except tf.errors.OutOfRangeError:\r\n                                    saver.save(sess=sess._sess._sess._sess._sess,\r\n                                            save_path=\"some_hdfs_path/model.checkpoint.\"+str(epoch_num),\r\n                                            latest_filename='checkpoint.'+str(epoch_num))\r\n                                    break\r\n\r\ndef main(_):\r\n    job = Job()\r\n    job.train()\r\n\r\nif __name__ == '__main__':\r\n    tf.app.run()\r\n```\r\n\r\nFully pstack: \r\n  https://github.com/formath/TensorFlow-Bugs/blob/master/39024.pstack\r\n\r\n", "comments": ["A few questions, since we don't have a way to reproduce your job:\r\n\r\n* What Python line of code is executing when the process freezes?\r\n* The `inter_op_parallelism_threads` and `intra_op_parallelism_threads` configuration is not having an effect, because you're using a `tf.train.Server` (which sets those values once for all sessions on the server). Try the following change to server creation:\r\n\r\n    ```python\r\n    server_config = tf.ConfigProto(inter_op_parallelism_threads=1,\r\n                                   intra_op_parallelism_threads=1)\r\n    self.server = tf.train.Server(self.cluster, job_name=self.job_name,\r\n                                  task_index=self.task_index, config=server_config)\r\n\r\n    ```\r\n\r\n  Can you generate new stack traces with this configuration? (This will cut down on the number of irrelevant threads in the trace.)\r\n\r\n* From the stack traces, all we can see is that the process is blocked waiting for a response from some remote worker. It doesn't appear to be doing anything else. Can you gather a stack trace from the worker(s) in `/job:ps` that it might be using? If you can reproduce this using a single PS task, it will make it easier to debug.\r\n* Is the call to `self.data_iter()` inside a `with tf.device(self.param_server_device):` block intentional? Usually, each worker would create an iterator on the local CPU device. If you do that instead, does it still hang? (One possibility is that the single PS task that is responsible for all 50 workers' input pipelines is massively oversubscribed, and it starts paging or dropping packets. However, that should not cause an indefinite hang, just very bad performance.)\r\n", "@mrry\r\n* If setting\r\n```python\r\nserver_config = tf.ConfigProto(inter_op_parallelism_threads=1,\r\n                               intra_op_parallelism_threads=1)\r\nself.server = tf.train.Server(self.cluster, job_name=self.job_name,\r\n                              task_index=self.task_index, config=server_config)\r\n```\r\nor set `ps` num 1, the problem disappear. I reproduced it using `inter_op_parallelism_threads=16,intra_op_parallelism_threads=16` and `ps` num 5. `worker_2` hangs.\r\nFull pstack (Sorry for so many threads):\r\nps_0: https://github.com/formath/TensorFlow-Bugs/blob/master/ps0.pstack\r\nps_1: https://github.com/formath/TensorFlow-Bugs/blob/master/ps1.pstack\r\nps_2: https://github.com/formath/TensorFlow-Bugs/blob/master/ps2.pstack\r\nps_3: https://github.com/formath/TensorFlow-Bugs/blob/master/ps3.pstack\r\nps_4: https://github.com/formath/TensorFlow-Bugs/blob/master/ps4.pstack\r\nblocked worker_2: https://github.com/formath/TensorFlow-Bugs/blob/master/worker2.pstack\r\nchief worker: https://github.com/formath/TensorFlow-Bugs/blob/master/worker0.pstack\r\n\r\nI also tested other configuration combinations and found only when setting both `inter_op_parallelism_threads` and num of `ps` bigger than 1, the problem occur. `intra_op_parallelism_threads` has no relationship with this problem.\r\n\r\n* About `self.data_iter()`, I prefetch data from hdfs to the `worker` nodes. Worker nodes will load data from local disk so `ps` nodes have no relationship with data reading.\r\n```\r\n2018-11-22 14:20:26.003705: I tensorflow/core/common_runtime/placer.cc:949] input/list_files/MatchingFiles: (MatchingFiles)/job:worker/replica:0/task:1/device:CPU:0\r\n2018-11-22 14:20:26.003748: I tensorflow/core/common_runtime/placer.cc:949] input/list_files/Shape: (Shape)/job:worker/replica:0/task:1/device:CPU:0\r\n2018-11-22 14:20:26.003784: I tensorflow/core/common_runtime/placer.cc:949] input/list_files/strided_slice: (StridedSlice)/job:worker/replica:0/task:1/device:CPU:0\r\n2018-11-22 14:20:26.003790: I tensorflow/core/common_runtime/placer.cc:949] input/list_files/match_not_empty: (Greater)/job:worker/replica:0/task:1/device:CPU:0\r\n2018-11-22 14:20:26.003796: I tensorflow/core/common_runtime/placer.cc:949] input/list_files/ReduceJoin: (ReduceJoin)/job:worker/replica:0/task:1/device:CPU:0\r\n2018-11-22 14:20:26.003801: I tensorflow/core/common_runtime/placer.cc:949] input/list_files/message: (Add)/job:worker/replica:0/task:1/device:CPU:0\r\n2018-11-22 14:20:26.003806: I tensorflow/core/common_runtime/placer.cc:949] input/list_files/assert_not_empty/Assert: (Assert)/job:worker/replica:0/task:1/device:CPU:0\r\n2018-11-22 14:20:26.003812: I tensorflow/core/common_runtime/placer.cc:949] input/list_files/Identity: (Identity)/job:worker/replica:0/task:1/device:CPU:0\r\n2018-11-22 14:20:26.003829: I tensorflow/core/common_runtime/placer.cc:949] input/list_files/Shape_1: (Shape)/job:worker/replica:0/task:1/device:CPU:0\r\n2018-11-22 14:20:26.003834: I tensorflow/core/common_runtime/placer.cc:949] input/list_files/strided_slice_1: (StridedSlice)/job:worker/replica:0/task:1/device:CPU:0\r\n2018-11-22 14:20:26.003840: I tensorflow/core/common_runtime/placer.cc:949] input/list_files/Maximum: (Maximum)/job:worker/replica:0/task:1/device:CPU:0\r\n2018-11-22 14:20:26.003845: I tensorflow/core/common_runtime/placer.cc:949] input/list_files/seed2/Equal: (Equal)/job:worker/replica:0/task:1/device:CPU:0\r\n2018-11-22 14:20:26.003850: I tensorflow/core/common_runtime/placer.cc:949] input/list_files/seed2/Equal_1: (Equal)/job:worker/replica:0/task:1/device:CPU:0\r\n2018-11-22 14:20:26.003855: I tensorflow/core/common_runtime/placer.cc:949] input/list_files/seed2/LogicalAnd: (LogicalAnd)/job:worker/replica:0/task:1/device:CPU:0\r\n2018-11-22 14:20:26.003860: I tensorflow/core/common_runtime/placer.cc:949] input/list_files/seed2: (Select)/job:worker/replica:0/task:1/device:CPU:0\r\n2018-11-22 14:20:26.003867: I tensorflow/core/common_runtime/placer.cc:949] input/TensorSliceDataset: (TensorSliceDataset)/job:worker/replica:0/task:1/device:CPU:0\r\n2018-11-22 14:20:26.003872: I tensorflow/core/common_runtime/placer.cc:949] input/ShuffleDataset: (ShuffleDataset)/job:worker/replica:0/task:1/device:CPU:0\r\n2018-11-22 14:20:26.003878: I tensorflow/core/common_runtime/placer.cc:949] input/ParallelInterleaveDataset: (ParallelInterleaveDataset)/job:worker/replica:0/task:1/device:CPU:0\r\n2018-11-22 14:20:26.003883: I tensorflow/core/common_runtime/placer.cc:949] input/PrefetchDataset: (PrefetchDataset)/job:worker/replica:0/task:1/device:CPU:0\r\n2018-11-22 14:20:26.003888: I tensorflow/core/common_runtime/placer.cc:949] input/BatchDatasetV2: (BatchDatasetV2)/job:worker/replica:0/task:1/device:CPU:0\r\n2018-11-22 14:20:26.003893: I tensorflow/core/common_runtime/placer.cc:949] input/ParallelMapDataset: (ParallelMapDataset)/job:worker/replica:0/task:1/device:CPU:0\r\n2018-11-22 14:20:26.003898: I tensorflow/core/common_runtime/placer.cc:949] input/MakeIterator: (MakeIterator)/job:worker/replica:0/task:1/device:CPU:0\r\n2018-11-22 14:20:26.003903: I tensorflow/core/common_runtime/placer.cc:949] input/IteratorToStringHandle: (IteratorToStringHandle)/job:worker/replica:0/task:1/device:CPU:0\r\n2018-11-22 14:20:26.003908: I tensorflow/core/common_runtime/placer.cc:949] IteratorGetNext: (IteratorGetNext)/job:worker/replica:0/task:1/device:CPU:0\r\n```\r\n", "I also found a strange thing. If replacing the inputs of `self.model` from tensors generated by data iterator with tensor placeholder, the program will not hangs.\r\n```python\r\ntrain_user_id_placeholder = tf.placeholder(...)\r\ntrain_item_id_placeholder = ...\r\ntrain_label_placeholder = ...\r\ntrain_logit = self.model(train_user_id_placeholder, train_item_id_placeholder)\r\n...\r\ntrain_op = opt.minimize(train_loss)\r\n...\r\ntry:\r\n  train_user_id_val, train_item_id_val, train_label_val = sess.run([train_user_id, train_item_id, train_label])\r\n  sess.run(train_op,\r\n      feed_dict={\r\n        train_user_id_placeholder: train_user_id_val,\r\n        train_item_id_placeholder: train_item_id_val,\r\n        train_label_placeholder: train_label_val})\r\nexcept tf.errors.OutOfRangeError:\r\n   ...\r\n```", "Did you resolve this issue?", "I don't find real cause. I just use the alternative solution mentioned above.", "> I don't find real cause. I just use the alternative solution mentioned above.\r\n\r\nhi, I meet the same problem, should this issue be reopened?"]}, {"number": 23845, "title": "Some confusion about Gather OP implement", "body": "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/gather_functor.h#L137\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/gather_functor.h#L139\r\n\r\nIn TensorFlow master branch, gather_functor::GatherFunctorCPU template specialization when slice_size==10 or slice_size==20, why this two magic number?", "comments": ["@ebrevdo \r\nthanks", "@ebrevdo @harshini-gadige please assign to other tensorflower", "@candyzone \r\nCould you please try on latest stable version of tf and let us know if this is still an issue.Thanks!", "Moving this to closed status due to lack of activity.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/23845\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/23845\">No</a>\n"]}, {"number": 23844, "title": "ERROR: missing input file '@local_config_nccl//:nccl/NCCL-SLA.txt' on Ubuntu18.4LTS", "body": "<em>This is a build/installation issue.</em>\r\n\r\n\r\n**_System information_**\r\n OS Platform and Distribution (Linux Ubuntu 18.04):\r\n-\r\n- TensorFlow installed from source \r\n- TensorFlow version: 1.8.0\r\n- Python version:3.6\r\n- Installed using virtualenv? pip? conda?: PIP\r\n- Bazel version (if compiling from source):0.14\r\n- GCC/Compiler version (if compiling from source):7.3.0\r\n- CUDA/cuDNN version:7.1.4\r\n- GPU model and memory:GeForce GT 710B-\r\n\r\n\r\n**_Problem description_**\r\n\r\nI tried installing Tensorflow on Ubuntu 18.4 -LTS following instructions from [(https://medium.com/@Oysiyl/install-tensorflow-1-8-0-with-gpu-from-source-on-ubuntu-18-04-bionic-beaver-35cfa9df3600 )] (https://medium.com/@Oysiyl/install-tensorflow-1-8-0-with-gpu-from-source-on-ubuntu-18-04-bionic-beaver-35cfa9df3600 ) BUT BUILD NOT SUCCESSFUL and WITH ERRORS\r\n\r\n_**Exact sequence of commands / steps that I executed before running into the problem**_\r\n-\r\n**Step 1:** Updated and upgraded the system : \r\n`\r\n    sudo apt-get update \r\n    sudo apt-get upgrade\r\n`\r\n\r\n**Step 2 :** Verified having CUDA capable GPU : \r\n`    lspci | grep -i nvidia`\r\n\r\n**Step 3:** Verified 64bit version of lnux : \r\n   ` uname -m && cat /etc/*release`\r\n\r\n**Step 4:**  Installed dependencies : \r\n   ` sudo apt-get install build-essential \r\n    sudo apt-get install cmake git unzip zip\r\n    sudo add-apt-repository ppa:deadsnakes/ppa\r\n    sudo apt-get update\r\n    sudo apt-get install python2.7-dev python3.5-dev python3.6-dev pylint`\r\n\r\n**Step 5:** Installed Linux 4.16 kernel : \r\n    `uname -r\r\n    wget http://kernel.ubuntu.com/~kernel-ppa/mainline/v4.16/linux-headers-4.16.0-041600_4.16.0-041600.201804012230_all.deb\r\n    wget http://kernel.ubuntu.com/~kernel-ppa/mainline/v4.16/linux-headers-4.16.0-041600-generic_4.16.0-041600.201804012230_amd64.deb\r\n    wget http://kernel.ubuntu.com/~kernel-ppa/mainline/v4.16/linux-image-4.16.0-041600-generic_4.16.0-041600.201804012230_amd64.deb\r\n    sudo dpkg -i *.deb\r\n    uname -sr`\r\n\r\n**Step 6:**  Installed nVidia CUDA 9.2 : \r\n    `sudo apt-get purge nvidia*\r\n    sudo apt-get autoremove\r\n    sudo apt-get autoclean\r\n    sudo rm -rf /usr/local/cuda*`\r\n\r\n    sudo apt-key adv --fetch-keys http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1710/x86_64/7fa2af80.pub\r\n    echo \"deb https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1710/x86_64 /\" | sudo tee /etc/apt/sources.list.d/cuda.list\r\n    sudo apt-get update \r\n    sudo apt-get -o Dpkg::Options::=\"--force-overwrite\" install cuda-9-2 cuda-drivers\r\n`\r\n**Step 7 & 8 :** After rebooting, \r\n\r\n    `echo 'export PATH=/usr/local/cuda-9.2/bin${PATH:+:${PATH}}' >> ~/.bashrc\r\n     echo 'export LD_LIBRARY_PATH=/usr/local/cuda-9.2/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}' >> ~/.bashrc\r\n    source ~/.bashrc\r\n    sudo ldconfig\r\n    nvidia-smi`\r\n  \r\n    Created xorg file for nvidia resolution settings\r\n\r\n    `sudo nvidia-xconfig\r\n     nvidia-settings`\r\n\r\n**Step 9 :** Installed CuDNN 7.1.4 \r\n\r\n   ` tar -xf cudnn-9.2-linux-x64-v7.1.tgz\r\n    sudo cp -R cuda/include/* /usr/local/cuda-9.2/include\r\n    sudo cp -R cuda/lib64/* /usr/local/cuda-9.2/lib64`\r\n\r\n**Step 10 :** Installed NCCL 2.2.13\r\n\r\n   ` tar -xf nccl_2.2.13-1+cuda9.2_x86_64.txz\r\n    cd nccl_2.2.13-1+cuda9.2_x86_64\r\n    sudo cp -R * /usr/local/cuda-9.2/targets/x86_64-linux/\r\n    sudo ldconfig`\r\n\r\n**Step 11 :** Installed dependencies \r\n\r\n    `sudo apt-get install libcupti-dev\r\n    echo 'export LD_LIBRARY_PATH=/usr/local/cuda/extras/CUPTI/lib64:$LD_LIBRARY_PATH' >> \r\n    ~/.bashrc\r\n    sudo apt-get install python3-numpy python3-dev python3-pip python3-wheel`\r\n\r\n**Step 12 :** Configured Tensorflow from source \r\n\r\n   ` cd ~/\r\n    wget https://github.com/bazelbuild/bazel/releases/download/0.14.0/bazel-0.14.0-installer-linux-x86_64.sh\r\n    chmod +x bazel-0.14.0-installer-linux-x86_64.sh\r\n    ./bazel-0.14.0-installer-linux-x86_64.sh --user\r\n    echo 'export PATH=\"$PATH:$HOME/bin\"' >> ~/.bashrc`\r\n(Reloading environment variables) : \r\n   ` source ~/.bashrc\r\n    sudo ldconfig`\r\n\r\n(Built Tensorflow 1.8.0 )\r\n    `cd ~/\r\n    git clone https://github.com/tensorflow/tensorflow.git\r\n    cd tensorflow\r\n    git pull\r\n    git checkout r1.8\r\n    ./configure`\r\n**Step 13 :** Building Tensorflow with Bazel : \r\n\r\n  ->upto this point everything went fine.\r\n\r\n   `bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package  --config-monolothic`\r\n\r\n->It took nearly 5 hours for this but finally failed to build successfully.-\r\n\r\n\r\n**_Errors :_** \r\n\r\n1)` ERROR: missing input file '@local_config_nccl//:nccl/NCCL-SLA.txt'`\r\n\r\n2) `ERROR: /home/vikranth/tensorflow/tensorflow/tools/pip_package/BUILD:166:1: //tensorflow/tools/pip_package:build_pip_package: missing input file '@local_config_nccl//:nccl/NCCL-SLA.txt'\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.`\r\n\r\n3) `ERROR: /home/vikranth/tensorflow/tensorflow/tools/pip_package/BUILD:166:1 1 input file(s) do not exist\r\nINFO: Elapsed time: 222.836s, Critical Path: 25.63s\r\nINFO: 386 processes, local.`\r\n\r\n4)` FAILED: Build did NOT complete successfully`\r\n\r\n\r\n\r\n\r\n**\r\n\r\n> \r\n\r\n- **Other info / logs**\r\n\r\n**\r\n\r\nUpdated log(re-running the command : \r\n   `bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package  --config-monolothic`\r\n)\r\n\r\n\r\n**_Terminal Output :_** \r\n___________________________________________________________________________________\r\n\r\n`vikranth@MySys:~$ cd tensorflow`\r\n\r\n`vikranth@MySys:~/tensorflow$ bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package --config=monolithic`\r\n\r\n`Starting local Bazel server and connecting to it...`\r\n`................`\r\nWARNING: `/home/vikranth/.cache/bazel/_bazel_vikranth/31056e930c01d2cff6d6b0198442019b/external/grpc/BUILD:1943:1: in srcs attribute of cc_library rule @grpc//:grpc_nanopb: please do not import '@grpc//third_party/nanopb:pb_common.c' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'grpc_generate_one_off_targets', the error might have been caused by the macro implementation in /home/vikranth/.cache/bazel/_bazel_vikranth/31056e930c01d2cff6d6b0198442019b/external/grpc/bazel/grpc_build_system.bzl:172:12`\r\nWARNING: `/home/vikranth/.cache/bazel/_bazel_vikranth/31056e930c01d2cff6d6b0198442019b/external/grpc/BUILD:1943:1: in srcs attribute of cc_library rule @grpc//:grpc_nanopb: please do not import '@grpc//third_party/nanopb:pb_decode.c' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'grpc_generate_one_off_targets', the error might have been caused by the macro implementation in /home/vikranth/.cache/bazel/_bazel_vikranth/31056e930c01d2cff6d6b0198442019b/external/grpc/bazel/grpc_build_system.bzl:172:12`\r\nWARNING: `/home/vikranth/.cache/bazel/_bazel_vikranth/31056e930c01d2cff6d6b0198442019b/external/grpc/BUILD:1943:1: in srcs attribute of cc_library rule @grpc//:grpc_nanopb: please do not import '@grpc//third_party/nanopb:pb_encode.c' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'grpc_generate_one_off_targets', the error might have been caused by the macro implementation in /home/vikranth/.cache/bazel/_bazel_vikranth/31056e930c01d2cff6d6b0198442019b/external/grpc/bazel/grpc_build_system.bzl:172:12`\r\nWARNING: \r\n`/home/vikranth/tensorflow/tensorflow/contrib/learn/BUILD:17:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:exporter': No longer supported. Switch to SavedModel immediately.`\r\nWARNING: \r\n`/home/vikranth/tensorflow/tensorflow/contrib/learn/BUILD:17:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:gc': No longer supported. Switch to SavedModel immediately.\r\nINFO: Analysed target //tensorflow/tools/pip_package:build_pip_package (286 packages loaded).\r\nINFO: Found 1 target...\r\nINFO: From Compiling tensorflow/contrib/lite/util.cc [for host]:\r\ntensorflow/contrib/lite/util.cc: In function 'TfLiteIntArray* tflite::ConvertArrayToTfLiteIntArray(int, const int*)':`\r\n`tensorflow/contrib/lite/util.cc:25:24: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   for (size_t i = 0; i < rank; i++) {\r\n                      ~~^~~~~~`\r\n`INFO: From Compiling tensorflow/contrib/lite/kernels/gemm_support.cc [for host]:`\r\n`In file included from external/gemmlowp/public/../internal/../fixedpoint/fixedpoint.h:871:0,\r\n                 from external/gemmlowp/public/../internal/output.h:26,\r\n                 from external/gemmlowp/public/../internal/unpack.h:23,\r\n                 from external/gemmlowp/public/../internal/single_thread_gemm.h:29,\r\n                 from external/gemmlowp/public/../internal/multi_thread_gemm.h:24,\r\n                 from external/gemmlowp/public/../internal/dispatch_gemm_shape.h:23,\r\n                 from external/gemmlowp/public/gemmlowp.h:19,\r\n                 from ./tensorflow/contrib/lite/kernels/gemm_support.h:18,\r\n                 from tensorflow/contrib/lite/kernels/gemm_support.cc:15:\r\nexternal/gemmlowp/public/../internal/../fixedpoint/./fixedpoint_sse.h:43:39: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n struct FixedPointRawTypeTraits<__m128i> {`\r\n                                       ^\r\n`In file included from external/gemmlowp/public/../internal/simd_wrappers.h:509:0,\r\n                 from external/gemmlowp/public/../internal/output.h:28,\r\n                 from external/gemmlowp/public/../internal/unpack.h:23,\r\n                 from external/gemmlowp/public/../internal/single_thread_gemm.h:29,\r\n                 from external/gemmlowp/public/../internal/multi_thread_gemm.h:24,\r\n                 from external/gemmlowp/public/../internal/dispatch_gemm_shape.h:23,\r\n                 from external/gemmlowp/public/gemmlowp.h:19,\r\n                 from ./tensorflow/contrib/lite/kernels/gemm_support.h:18,\r\n                 from tensorflow/contrib/lite/kernels/gemm_support.cc:15:\r\nexternal/gemmlowp/public/../internal/simd_wrappers_sse.h:31:72: warning: ignoring attributes on template argument 'gemmlowp::Int32x4 {aka __vector(2) long long int}' [-Wignored-attributes]\r\n       typename std::conditional<ScalarCount >= 4, Int32x4, std::int32_t>::type;`\r\n                                                                        ^\r\n`external/gemmlowp/public/../internal/simd_wrappers_sse.h:37:72: warning: ignoring attributes on template argument 'gemmlowp::Int16x8 {aka __vector(2) long long int}' [-Wignored-attributes]\r\n       typename std::conditional<ScalarCount >= 8, Int16x8, std::int16_t>::type;`\r\n                                                                        ^\r\n`external/gemmlowp/public/../internal/simd_wrappers_sse.h:45:52: warning: ignoring attributes on template argument 'gemmlowp::Uint8x16 {aka __vector(2) long long int}' [-Wignored-attributes]\r\n                                 std::uint8_t>::type>::type;`\r\n                                                    ^\r\n`INFO: From Compiling tensorflow/contrib/lite/arena_planner.cc [for host]:\r\ntensorflow/contrib/lite/arena_planner.cc: In member function 'virtual TfLiteStatus tflite::ArenaPlanner::PlanAllocations()':\r\ntensorflow/contrib/lite/arena_planner.cc:82:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   for (int i = 0; i < graph_info_->num_nodes(); ++i) {`\r\n                   ~~^~~~~~~~~~~~~~~~~~~~~~~~~~\r\n`tensorflow/contrib/lite/arena_planner.cc:101:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   for (int i = 0; i < graph_info_->num_nodes(); ++i) {`\r\n                   ~~^~~~~~~~~~~~~~~~~~~~~~~~~~\r\n`tensorflow/contrib/lite/arena_planner.cc: In member function 'virtual TfLiteStatus tflite::ArenaPlanner::ExecuteAllocations(int, int)':\r\ntensorflow/contrib/lite/arena_planner.cc:139:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   for (int i = 0; i < graph_info_->num_tensors(); ++i) {`\r\n                   ~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n`tensorflow/contrib/lite/arena_planner.cc: In member function 'TfLiteStatus tflite::ArenaPlanner::CalculateAllocationOfInternalTensors(int)':\r\ntensorflow/contrib/lite/arena_planner.cc:232:18: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   if (node_index < graph_info_->num_nodes()) {`\r\n       ~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~\r\n`tensorflow/contrib/lite/arena_planner.cc: In member function 'TfLiteStatus tflite::ArenaPlanner::CalculateDeallocationOfInternalTensors(int)':\r\ntensorflow/contrib/lite/arena_planner.cc:245:18: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   if (node_index < graph_info_->num_nodes()) {`\r\n       ~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~\r\n`ERROR: missing input file '@local_config_nccl//:nccl/NCCL-SLA.txt'\r\nERROR: /home/vikranth/tensorflow/tensorflow/tools/pip_package/BUILD:166:1: //tensorflow/tools/pip_package:build_pip_package: missing input file '@local_config_nccl//:nccl/NCCL-SLA.txt'`\r\n`Target //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nERROR: /home/vikranth/tensorflow/tensorflow/tools/pip_package/BUILD:166:1 1 input file(s) do not exist\r\nINFO: Elapsed time: 222.836s, Critical Path: 25.63s\r\nINFO: 386 processes, local.\r\nFAILED: Build did NOT complete successfully`\r\n\r\n`vikranth@MySys:~/tensorflow$ tensorflow -V\r\ntensorflow: command not found`\r\n", "comments": ["@infotechie  Hi, we encourage you to follow these[ instructions](https://www.tensorflow.org/install/source) to build tensorflow from source. These are the instructions from the official site. Please post here if you are facing any difficulty after following these steps. Thank you !", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Closing as this issue is in \"awaiting response\" status for more than 7 days and did not hear back from the user. Please post your comments if any, we will reopen. Thanks !"]}, {"number": 23843, "title": "Ceil op for TFLITE", "body": "CEIL basic ops for tensorflow lite\r\n", "comments": ["@aselle could you please help to review this ops. TIA", "Nagging Reviewer @aselle: You have been added as a reviewer to this pull request. Please add your review or reassign. It has been 14 days with no activity and the `awaiting review` label has been applied.", "Please review, ABS already got merged internally.", " @aselle Could you please take a look at this PR. Thanks in advance", "@harshini-gadige could you please help to review this PR. thanks in advance.", "@jdduke Thank you very much for your time and reviewing my code. I have updated the code based on your review comments. ", "@jdduke @aselle @dksb Could you please review again and approve if everything is fine? thanks in advance.\r\n", "@siju-samuel  Can you please run clang-format on your code.", "@jdduke please approve again. just updated some spacing issues found using clang-format.\r\n\r\n@hgadig the sanity test was failing due to the below error\r\n\r\n```\r\n=== Sanity check step 5 of 12: do_bazel_nobuild (bazel nobuild) ===\r\nFAIL: bazel build --nobuild  -- //tensorflow/... -//tensorflow/lite/java/demo/app/... -//tensorflow/lite/examples/android/... -//tensorflow/lite/schema/...\r\n  This is due to invalid BUILD files. See lines above for details.\r\nERROR: error loading package 'tensorflow/lite/experimental/swift': Extension file not found. Unable to load file '@bazel_skylib//lib:partial.bzl': file doesn't exist or isn't a file\r\n```\r\n", "@hgadig Anything pending from my side for this PR? ", "> @hgadig Anything pending from my side for this PR?\r\n\r\nNothing from your end. We are looking into this.", "There are some minor tweaks we need to make internally, it should land in the next day or so, thanks for your patience."]}, {"number": 23842, "title": "Run time GPU resources allocation in Tensorflow", "body": "Hi\r\nI have developed a model which is  Real time vehicle and person detection using tensor flow as back end in python and have  ten jobs (ten video feed from different cctv camera ) or more than that at run time some time jobs are more than ten or less than ten  jobs ,I want to run ten  jobs at a same time on one  gpu(GT X 1080 memory 8118MiB) using tensor flow  but if i have ten jobs then GPU resources equally distribute to every jobs and if jobs are five then resource equally distributed to five jobs i.e run time GPU resources allocation on the basis of number of available jobs(may be more than ten jobs or less than ten jobs) like cpu use its intelligence when one job/process complete then it release resources and cpu assign these resources to other process so  I want to utilize my whole resources of my GPU at every time\r\nsuggest me any approach\r\nThanks", "comments": ["We encourage to post these type of questions on [StackOverflow](http://stackoverflow.com/questions/tagged//tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n"]}, {"number": 23841, "title": "Add float16 support for tf.qr", "body": "This fix tries to address the issue raised in #23830 where tf.qr does not support float16 data types.\r\nThis fix adds the float16 support for tf.qr.\r\n\r\nThis fix fixes #23830.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["@reedwm are you the right person to take a look at this?", "/CC @rmlarsen, can you take a look? I am not familiar with QR.\r\n\r\nAlso, a test should probably be added to [qr_op_test.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/tests/qr_op_test.py).", "> /CC @rmlarsen, can you take a look? I am not familiar with QR.\r\n> \r\n> Also, a test should probably be added to [qr_op_test.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/tests/qr_op_test.py).\r\n\r\n@rmlarsen  Any update please ?", "Nagging Reviewer @rmlarsen, @caisq: You have been added as a reviewer to this pull request. Please add your review or reassign. It has been 14 days with no activity and the `awaiting review` label has been applied.", "@yongtang could you please resolve the conflicts? Thanks!", "@yongtang  gentle ping to resolve the conflicts. Thanks!", "@yongtang Did you get a chance to look on conflicts? Please let us know on the update. Thanks!", "Sorry for the delay. Let me close this PR for now. Will reopen once all issue has been resolved."]}, {"number": 23840, "title": "RuntimeWarning: compiletime version 3.4 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5; uiltins.type size changed, may indicate binary incompatibility. Expected 432, got 412", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template </em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Raspbian 9\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary, I think? (_pip_ installed)\r\n- TensorFlow version (use command below): 1.11.0\r\n- Python version: 3.5.3\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: N/A, no GPU\r\n- GPU model and memory: N/A, no GPU\r\n\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n**Describe the current behavior**\r\nAs you know with the title, when I import tensorflow in shell window, I get a warning. (See code)\r\n**Describe the expected behavior**\r\nI recently saw some issues, and they says that it is OK to use tensorflow with this. But my question is: <strong>how can I get rid of this?</strong>\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n```\r\n\r\n>>> import tensorflow as tf\r\n\r\nWarning (from warnings module):\r\n  File \"/usr/lib/python3.5/importlib/_bootstrap.py\", line 222\r\n    return f(*args, **kwds)\r\nRuntimeWarning: compiletime version 3.4 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\r\n\r\nWarning (from warnings module):\r\n  File \"/usr/lib/python3.5/importlib/_bootstrap.py\", line 222\r\n    return f(*args, **kwds)\r\nRuntimeWarning: builtins.type size changed, may indicate binary incompatibility. Expected 432, got 412\r\n>>> \r\n```\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["I know it is good to keep going, but I want to get rid of it. OK?", "@sjkim04   Could you please try with Python 3.6 ? If you already tried, does it give the same error ?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Closing as this issue is in \"awaiting response\" status for more than 7 days and did not hear back from the user. Please post your comments if any, we will reopen. Thanks !", "This issue still persists as of April 7, 2019. I installed Raspbian and then followed the instructions as per Tensorflow installation [guide](https://www.tensorflow.org/install/pip). Then, I got this error message.", "the same error on rpi 3b+ with python 3.5", "@hgadig I've installed Python 3.6.8 (Raspbian Stretch).\r\nAnd I've got these warnings as well:\r\n/usr/local/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.4 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\r\n  return f(*args, **kwds)\r\n/usr/local/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: builtins.type size changed, may indicate binary incompatibility. Expected 432, got 412\r\n  return f(*args, **kwds)\r\n", "the same error on rpi 2 with python 3.5\r\n\r\n/home/pi/venv/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.4 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\r\n  return f(*args, **kwds)\r\n/home/pi/venv/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: builtins.type size changed, may indicate binary incompatibility. Expected 432, got 412\r\n  return f(*args, **kwds)\r\n\r\n\r\n", "I'm on Raspbian Stretch with Python 3.6, and got thess warnings upon installing `tensorflow-1.13.1-cp36-none-linux_armv7l.whl`:\r\n```\r\npi@raspberrypi:~ $ python -c \"import tensorflow as tf;print(tf.reduce_sum(tf.random.normal([1000, 1000])))\"\r\n/home/pi/.pyenv/versions/3.6.8/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.4 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\r\n  return f(*args, **kwds)\r\n/home/pi/.pyenv/versions/3.6.8/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: builtins.type size changed, may indicate binary incompatibility. Expected 432, got 412\r\n  return f(*args, **kwds)\r\nTensor(\"Sum:0\", shape=(), dtype=float32)\r\n```", "I have the very same problem with the latest RaspberryPi image and tensorflow  https://www.piwheels.org/simple/tensorflow/tensorflow-1.13.1-cp27-none-linux_armv7l.whl \r\n\r\n```\r\n/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.4 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\r\n  return f(*args, **kwds)\r\n/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: builtins.type size changed, may indicate binary incompatibility. Expected 432, got 412\r\n  return f(*args, **kwds)\r\n^CTraceback (most recent call last):\r\n  File \"<frozen importlib._bootstrap_external>\", line 88, in _path_is_mode_type\r\n  File \"<frozen importlib._bootstrap_external>\", line 82, in _path_stat\r\nFileNotFoundError: [Errno 2] No such file or directory: '/home/pi/.local/lib/python3.5/site-packages/gast/__init__.cpython-35m-arm-linux-gnueabihf.so'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n```\r\n\r\n", "Any fix for this same issue as below:\r\n\r\n\r\n```\r\n/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.4 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\r\n  return f(*args, **kwds)\r\n/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: builtins.type size changed, may indicate binary incompatibility. Expected 432, got 412\r\n  return f(*args, **kwds)\r\n```", "I tested different tensorflow version on the latest raspian and I have always the same error.\r\n(tested with tf  1.9.0, 1.10.1, 1.11.0, 1.12.0, 1.13.1)\r\n\r\nI think the ticket should be reopend or using https://github.com/tensorflow/tensorflow/issues/26459 to track this issue? ", "I installed the arm6 version from here and it works on a pi zero\r\n\r\nhttps://github.com/lhelontra/tensorflow-on-arm/releases/tag/v1.13.1", "You saved my day. Many thanks. \r\n\r\nBut I don't understand why I have to access third party sources to install tensorflow properly on a current Raspberry. Anyway - I have a solution and am happy. Mayn thanks again to you and the\r\nprovider of the tensorflow whl\r\n\r\n```sh\r\nwget https://github.com/lhelontra/tensorflow-on-arm/releases/download/v1.13.1/tensorflow-1.13.1-cp35-none-linux_armv7l.whl\r\nsudo pip3 install ./tensorflow-1.13.1-cp35-none-linux_armv7l.whl\r\npython3 -c 'import tensorflow as tf; print(tf.__version__)'\r\n1.13.1\r\n\r\n```\r\n", "**@everyone this is not an error it is a warning. Tensorflow still works.**", "@bennuttall I think this is more than a warning, right?\r\n\r\nIf you look at @jingw222 's log, it says:\r\n\r\n> I'm on Raspbian Stretch with Python 3.6, and got thess warnings upon installing `tensorflow-1.13.1-cp36-none-linux_armv7l.whl`:\r\n> \r\n> ```\r\n> pi@raspberrypi:~ $ python -c \"import tensorflow as tf;print(tf.reduce_sum(tf.random.normal([1000, 1000])))\"\r\n> /home/pi/.pyenv/versions/3.6.8/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.4 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\r\n>   return f(*args, **kwds)\r\n> /home/pi/.pyenv/versions/3.6.8/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: builtins.type size changed, may indicate binary incompatibility. Expected 432, got 412\r\n>   return f(*args, **kwds)\r\n> Tensor(\"Sum:0\", shape=(), dtype=float32)\r\n> ```\r\n\r\nA sum of 0 doesn't seem right to me. I get the exact same error.", "> @bennuttall I think this is more than a warning, right?\r\n\r\n```\r\nRuntimeWarning: compiletime version 3.4 of module\r\n```\r\n\r\nYou can turn warnings off: `python -W ignore -c \"import tensorflow\"`\r\n\r\n> A sum of 0 doesn't seem right to me. I get the exact same error.\r\n\r\nThat's not output, that's the stack trace.\r\n\r\nIf Tensorflow isn't working for you. I'd suggest showing code examples."]}, {"number": 23839, "title": "Documentaion section comparing_compiler_optimizations has been removed from performance overview", "body": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version:\r\n- Doc Link: https://www.tensorflow.org/guide/performance/overview#comparing_compiler_optimizations\r\n\r\n\r\n**Describe the documentation issue**\r\nThe following section has been removed from official documentation: \r\nhttps://www.tensorflow.org/guide/performance/overview#comparing_compiler_optimizations\r\nI was able to find the benchmark after long search here:\r\nhttps://github.com/tensorflow/tensorflow/issues/13050#issuecomment-330699371\r\nI was wondering if the section was removed deliberately or by accident?\r\n\r\nRegards, Anton\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\n", "comments": ["This appears to be intentional.\r\n\r\n@tfboyd the edit came from you. Can you confirm? why this section was dropped?  cl/198077351"]}, {"number": 23838, "title": "Updated PR for \"Fold BN after depthwise conv\"(#21023)", "body": "[Original PR is here](https://github.com/tensorflow/tensorflow/pull/21023)", "comments": ["Could you pull rebase and push again?", "@smillius if you could take a quick look, that would be great. Thanks!", "@zhaoyongke could you run clang-format-3.6.0 on this?", "@drpngx can u provide full command lines for clang-format-3.6.0? ", "> @drpngx can u provide full command lines for clang-format-3.6.0?\r\n\r\n@drpngx  Any update please ?", "You need to download the tool and run it.", "> @zhaoyongke could you run clang-format-3.6.0 on this?\r\n\r\n@zhaoyongke   Any update please ?", "I tried to run clang-format-3.6 on modified files in this PR, nothing meaningful found, only generated the almost same code again with some indent changed.@drpngx @harshini-gadige ", "Can someone from Tensorflow team look at this? It would be nice to include this PR in next TF release.", "> I tried to run clang-format-3.6 on modified files in this PR, nothing meaningful found, only generated the almost same code again with some indent changed.@drpngx @harshini-gadige\r\n\r\n@drpngx  Can  you please suggest the user on this.", "Please push the files. Clang format will have nothing meaningful, just\nspaces.\n\nOn Tue, Dec 4, 2018, 3:34 PM harshini-gadige <notifications@github.com\nwrote:\n\n> I tried to run clang-format-3.6 on modified files in this PR, nothing\n> meaningful found, only generated the almost same code again with some\n> indent changed.@drpngx <https://github.com/drpngx> @harshini-gadige\n> <https://github.com/harshini-gadige>\n>\n> @drpngx <https://github.com/drpngx> Can you please suggest the user on\n> this.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/23838#issuecomment-444246567>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AT_SbTUwNARev0zxFHqTjaCu3p2mKo9tks5u1txZgaJpZM4Yn-4A>\n> .\n>\n", "Hi @drpngx @mingxingtan @smillius, \r\nThe only thing left is the code review,  can you guys approve it?  The old PR has been reviewed once already.", "Sounds good. Started the test & pull to internal.", "Nagging Reviewer @mingxingtan: You have been added as a reviewer to this pull request. Please add your review or reassign. It has been 29 days with no activity and the `awaiting review` label has been applied."]}, {"number": 23837, "title": "The accuracy of the CNN I made is 0.1. It seems to be a matter of function used", "body": "It's a cnn I made, and no matter how much I learn or test, the accuracy is 0.1. My guess is, I've probably correct 1/10, so the accuracy is 0.1. What do you think? Where do i have to modify it to get like this \"100% accuracy\"\r\n\r\ni think The cause seems to be this part.\r\n\r\nonehot_labels = tf.one_hot(indices=tf.cast(labels, tf.int32), depth=10)\r\nloss = tf.losses.softmax_cross_entropy(onehot_labels=onehot_labels, logits=logits)\r\n(Note, training accuracy increases with execution.)\r\n\r\ndef cnn_model_fn(features, labels, mode):\r\n\"\"\"Model function for CNN.\"\"\"\r\n# Input Layer\r\ninput_layer = tf.reshape(features[\"image\"], [-1, 28, 28, 3])\r\n\r\n# Convolutional Layer #1\r\nconv1 = tf.layers.conv2d(\r\n    inputs=input_layer,\r\n    filters=32,\r\n    kernel_size=[5, 5],\r\n    padding=\"SAME\",\r\n    activation=tf.nn.relu)\r\n\r\n# Pooling Layer #1\r\npool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\r\n\r\n# Convolutional Layer #2 and Pooling Layer #2\r\nconv2 = tf.layers.conv2d(\r\n    inputs=pool1,\r\n    filters=64,\r\n    kernel_size=[5, 5],\r\n    padding=\"SAME\",\r\n    activation=tf.nn.relu)\r\npool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\r\n\r\n# Dense Layer\r\npool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\r\ndense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\r\ndropout = tf.layers.dropout(inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\r\n\r\n# Logits Layer\r\nlogits = tf.layers.dense(inputs=dropout, units=10)\r\n\r\npredictions = {\r\n    # Generate predictions (for PREDICT and EVAL mode)\r\n    \"classes\": tf.argmax(input=logits, axis=1),\r\n    # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\r\n    # `logging_hook`.\r\n    \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\r\n}\r\n\r\nif mode == tf.estimator.ModeKeys.PREDICT:\r\n    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\r\n\r\nonehot_labels = tf.one_hot(indices=tf.cast(labels, tf.int32), depth=10)\r\nloss = tf.losses.softmax_cross_entropy(onehot_labels=onehot_labels, logits=logits)\r\n\r\n# Configure the Training Op (for TRAIN mode)\r\nif mode == tf.estimator.ModeKeys.TRAIN:\r\n    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\r\n    train_op = optimizer.minimize(\r\n        loss=loss,\r\n        global_step=tf.train.get_global_step())\r\n    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\r\n\r\n# Add evaluation metrics (for EVAL mode)\r\neval_metric_ops = {\r\n    \"accuracy\": tf.metrics.accuracy(\r\n        labels=labels, predictions=predictions[\"classes\"])}\r\nreturn tf.estimator.EstimatorSpec(\r\n    mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)", "comments": ["This issue is more suitable on [tensorflow/models](https://github.com/tensorflow/models/issues/new) repo. Closing this issue since its not a bug or feature request related to TensorFlow. Feel free to post this issue on [tensorflow/models](https://github.com/tensorflow/models/issues/new) repo. Thanks!"]}, {"number": 23836, "title": "ImportError with Win10", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Win10 build 17134\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): `pip install tensorflow-gpu`\r\n- TensorFlow version (use command below): 1.12.0\r\n- Python version: 3.5\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 9.0/7.4.1.5\r\n- GPU model and memory: GTX1060 6GB\r\n\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n```\r\nimport numpy as np\r\nimport os\r\nimport six.moves.urllib as urllib\r\nimport sys\r\nimport tarfile\r\nimport tensorflow as tf\r\nimport zipfile\r\n\r\nfrom distutils.version import StrictVersion\r\nfrom collections import defaultdict\r\nfrom io import StringIO\r\nfrom matplotlib import pyplot as plt\r\nfrom PIL import Image\r\n\r\n# This is needed since the notebook is stored in the object_detection folder.\r\nsys.path.append(\"..\")\r\nfrom object_detection.utils import ops as utils_ops\r\n\r\nif StrictVersion(tf.__version__) < StrictVersion('1.9.0'):\r\n  raise ImportError('Please upgrade your TensorFlow installation to v1.9.* or later!') \r\n```\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n```\r\nImportError                               Traceback (most recent call last)\r\nc:\\users\\khvlo\\anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py in <module>\r\n     57 \r\n---> 58   from tensorflow.python.pywrap_tensorflow_internal import *\r\n     59   from tensorflow.python.pywrap_tensorflow_internal import __version__\r\n\r\nc:\\users\\khvlo\\anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py in <module>\r\n     27             return _mod\r\n---> 28     _pywrap_tensorflow_internal = swig_import_helper()\r\n     29     del swig_import_helper\r\n\r\nc:\\users\\khvlo\\anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py in swig_import_helper()\r\n     23             try:\r\n---> 24                 _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n     25             finally:\r\n\r\nc:\\users\\khvlo\\anaconda3\\envs\\tensorflow1\\lib\\imp.py in load_module(name, file, filename, details)\r\n    242         else:\r\n--> 243             return load_dynamic(name, filename, file)\r\n    244     elif type_ == PKG_DIRECTORY:\r\n\r\nc:\\users\\khvlo\\anaconda3\\envs\\tensorflow1\\lib\\imp.py in load_dynamic(name, path, file)\r\n    342             name=name, loader=loader, origin=path)\r\n--> 343         return _load(spec)\r\n    344 \r\n\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nImportError                               Traceback (most recent call last)\r\n<ipython-input-2-1e9eee4e6961> in <module>\r\n      4 import sys\r\n      5 import tarfile\r\n----> 6 import tensorflow as tf\r\n      7 import zipfile\r\n      8 \r\n\r\nc:\\users\\khvlo\\anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\__init__.py in <module>\r\n     22 \r\n     23 # pylint: disable=g-bad-import-order\r\n---> 24 from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n     25 \r\n     26 try:\r\n\r\nc:\\users\\khvlo\\anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\__init__.py in <module>\r\n     47 import numpy as np\r\n     48 \r\n---> 49 from tensorflow.python import pywrap_tensorflow\r\n     50 \r\n     51 from tensorflow.python.tools import component_api_helper\r\n\r\nc:\\users\\khvlo\\anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py in <module>\r\n     72 for some common reasons and solutions.  Include the entire stack trace\r\n     73 above this error message when asking for help.\"\"\" % traceback.format_exc()\r\n---> 74   raise ImportError(msg)\r\n     75 \r\n     76 # pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\r\n\r\nImportError: Traceback (most recent call last):\r\n  File \"c:\\users\\khvlo\\anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"c:\\users\\khvlo\\anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"c:\\users\\khvlo\\anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"c:\\users\\khvlo\\anaconda3\\envs\\tensorflow1\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"c:\\users\\khvlo\\anaconda3\\envs\\tensorflow1\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n```", "comments": ["@khvmaths Can you please check if any dependencies are out-of-date and try upgrading those.\r\nTry upgrading pandas and reconfigure tensorflow.", "Hi all, I am closing this issue. I found out that i downgraded by CUDA and CUDnn and the PATH variable is not updated."]}, {"number": 23835, "title": "Preventing crash when building with local MKL", "body": "Preventing crash when MKL include dir. contains something else (e.g. fortran defs.).", "comments": ["Nagging Assignee @wt-huang: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly."]}, {"number": 23834, "title": "Relative Device Placement", "body": "**System information**\r\n- TensorFlow version (you are using): 1.10+\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nFrom the [Using GPUs] Guide (under [multiple gpus][Using Multiple GPUs])  there is a part about using multiple GPUs in a \"multi-tower fashion\":\r\n\r\n```\r\nfor d in ['/device:GPU:2', '/device:GPU:3']:\r\n  with tf.device(d):\r\n```\r\n\r\nSeeing this, one might be tempted to leverage this style for multiple GPU training in a custom Estimator to indicate to the model that it can be distributed across multiple GPUs efficiently.\r\n\r\nTo my knowledge, if manual device placement is absent TensorFlow does not have some form of optimal device mapping (expect perhaps if you have the GPU version installed and a GPU is available, using it over the CPU). So what other choice do you have?\r\n\r\nAnyway, you carry on with training your estimator and export it to a `SavedModel` via `estimator.export_savedmodel(...)` and wish to use this `SavedModel` later... perhaps on a different machine, one which may not have as many GPUs as the device on which the model was trained (or maybe no GPUs)\r\n\r\nso when you run\r\n\r\n```\r\nfrom tensorflow.contrib import predictor\r\npredict_fn = predictor.from_saved_model(model_dir)\r\n```\r\n\r\nyou get\r\n\r\n```\r\nCannot assign a device for operation <OP-NAME>. Operation was \r\nexplicitly assigned to <DEVICE-NAME> but available devices are \r\n[<AVAILABLE-DEVICE-0>,...]\r\n```\r\n\r\nNow if you share a GPU cluster and are specifying TensorFlow to run your model on `GPU:3` and `GPU:6`, then go to run your model on your local machine, which may have 2 GPUs, you get the same problem.\r\n\r\n## Putative Solution\r\n\r\nI propose either:\r\n\r\n1. machine device mapping\r\n\r\n2. introducing relative device placement with automatic fallback. \r\n\r\n\r\nFor the former, this means that I can tell TensorFlow that at the beginning to treat the manual placement of devices in the graph to another via a dictionary:\r\n\r\n```\r\n# map all GPUs to single core CPU\r\nmachine_device_map = {\"device:GPU:{}\".format(i): \"device/CPU:0\" for i in range(8)}\r\n\r\n# map odd GPUs to GPU 0 and even GPUs to GPU 1 on smaller GPU machine\r\nmachine_device_map = {\r\n    \"device/GPU:{}\".format(i): \"device:GPU:{}\".format(i % 2)\r\n    for i in range(8)\r\n}\r\n\r\n\r\n# then something like this goes after importing TensorFlow\r\ntf.devices.map_device(machine_device_map)\r\n```\r\n\r\nFor the latter if I train my model on GPUs 1,4,6,7  and my machine only has GPUs 0 and 1 then  device placement 1,4 falls back to 0 and 6,7 falls back to 1. If my device only has a single CPU\r\n\r\nThis would be done with something like:\r\n\r\n```\r\nwith tf.relative_device('GPU:0'):\r\n```\r\n\r\nwhere, given 'device/relative/GPU:0' relative device calls\r\n\r\n```\r\nfrom TensorFlow's.python.client import device_lib\r\ndevices = device_lib.list_local_devices()\r\n\r\nrelative_device_num = 0\r\nrelative_device_type = 'GPU'\r\n\r\ncpus = [d for d in devices if d.device_type == 'CPU']\r\ngpus = [d for d in devices if d.device_type == 'GPU']\r\n\r\nif relative_device_type=='GPU':\r\n    if gpus:\r\n        return gpus[relative_device_num % len(gpus)] \r\n\r\nreturn cpus[relative_device_num % len(cpus)]\r\n\r\n```\r\n\r\n\r\n\r\n[Using GPUs]: https://www.tensorflow.org/guide/using_gpu#manual_device_placement\r\n[Using Multiple GPUs]: https://www.tensorflow.org/guide/using_gpu#using_multiple_gpus\r\n\r\n**Will this change the current api? How?**\r\n\r\nNo. It would add the ability to change device placement for distributed models after training\r\n\r\n**Who will benefit with this feature?**\r\n\r\nAll TF users\r\n\r\n**Any Other info.**\r\n", "comments": ["Are you trying to continue with training of the model. Or use the graph for inference?", "Use the same model on another machine (device (s)) for inference but the ability to continue training should exist \r\n\r\n\r\n> On Jan 15, 2019, at 11:49, azaks2 <notifications@github.com> wrote:\r\n> \r\n> Are you trying to continue with training of the model. Or use the graph for inference?\r\n> \r\n> \u2014\r\n> You are receiving this because you authored the thread.\r\n> Reply to this email directly, view it on GitHub, or mute the thread.\r\n", "@reedwm Can you look into this?", "If I'm understand correctly, the problem you're trying to solve is that you want to save your model, then continue training or do evaluation on a machine with less GPUs. You propose two mechanisms for treating a device spec such as GPU:4 to refer to a lower-numbered GPU if GPU:4 doesn't exist, either through an explicit or implicit mapping.\r\n\r\n@josh11b what do you think of this idea? How does one train/evaluate on a machine with less GPUs currently with DistributionStrategy?", "@reedwm yes but it solves more than just that... or at least it did.\r\n\r\nAlthough `tf.estimators` will be around in 2.0 they (especially user made) seem to be on the way out and contributors to that module have stated that active development really isn't much of a thing... (although TensorFlow made estimators might still stick around)\r\n\r\nAt the moment, prior to `DistributionStrategy`, `tf.estimator` does not have a `\"clear_device_placement\u201d` as a option in its exporter. So user made estimators are stuck mapped to whatever gpus it was trained on (see issues #23834, and #23900).\r\n\r\nAnd this of course means that you are also stuck to running inference with the same devices.\r\nIf you have say 6 gpus, and run hyperparameter optimization, running a model on 2 gpus each, and the \"best\" model happens to have been trained on gpus 3 and 5, inference / training can not be done on gpus 0 and 1 since `estimator`s (specifically) lack a way to clear device placement and according to the tf documentation (at the time these issues were open), the way to run distributed models were to specify device placement as done so above and in linked issues. \r\n\r\n", "Also @alextp and @jaingaurav, any thoughts on the proposed solution?", "I think with Estimator you get to choose whether to build your eval graph with or without distribution strategy, right?", "And by eval I meant inference, which is the graph that gets exported.\n\nOn Thu, May 23, 2019 at 4:54 PM Alexandre Passos <notifications@github.com>\nwrote:\n\n> I think with Estimator you get to choose whether to build your eval graph\n> with or without distribution strategy, right?\n>\n> \u2014\n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/23834?email_source=notifications&email_token=AAABHRIZUNGT77LVLERFRGTPW4VCRA5CNFSM4GE7JSNKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODWDZANA#issuecomment-495423540>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAABHRLJUCUA6Q3CZ3JSNOLPW4VCRANCNFSM4GE7JSNA>\n> .\n>\n\n\n-- \n - Alex\n", "\r\n@alextp of course you can not use distribution when you make the graph, but this issue is specific to when device placement is used (as shown in official tf docs for distribution)\r\n\r\nThe best exporter exports the graph ran during training and there is very little support for loading an exported estimator (most focus is in serving them)\r\n\r\nSo when you try to load the exported estimator (which includes the graph) that was trained with distribution ) you have no choice but to run on same devices.", "My advice is to add a flag or environment variable when exporting and skip adding the device annotations then.", "@alextp that isn't possible at the moment (to my knowledge) hence the issue and the device annotations are _required_ ", "You can always do that, no>?\n\nOn Fri, May 24, 2019 at 8:26 AM SumNeuron <notifications@github.com> wrote:\n\n> @alextp <https://github.com/alextp> that isn't possible at the moment (to\n> my knowledge) hence the issue and the device annotations are *required*\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/23834?email_source=notifications&email_token=AAABHRMH2LT7BTHZAH55D53PXACITA5CNFSM4GE7JSNKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODWFWHSI#issuecomment-495674313>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAABHRLMFGDLQ5QEG3RKJ53PXACITANCNFSM4GE7JSNA>\n> .\n>\n\n\n-- \n - Alex\n", "@alextp to my knowledge, with estimators, no", "@alextp this seems to be rearing its head again in [Keras](https://github.com/tensorflow/tensorflow/issues/33474) as sessions takes the saved the model which doesn't have device replacment", "Hi @SumNeuron ! \r\nIt seems you are using older versions(1.x versions) of Tensorflow which is not supported any more. Please visit these links to upgrade your codebase to [latest versions](https://www.tensorflow.org/guide/gpu#manual_device_placement).Ref [1](https://www.tensorflow.org/addons),[2](https://www.tensorflow.org/guide/migrate). Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 23833, "title": "The same compilation target results in different compilation results", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- Linux Ubuntu 16.04\r\n- TensorFlow version:1.8.0\r\n- Python version:3.5\r\n- Bazel version (if compiling from source):0.17.2\r\n- GCC/Compiler version (if compiling from source):gcc 5.4\r\n\r\n**Describe the problem**\r\n\r\nInitially, I used tensorflow1.8.0 as my external dependency for development, mainly using core:lib core:all_kernels core:core_cpu as the compilation target, and I wanted to use these three library files to generate my.so dynamic library files\r\n\r\nIt does works and Everything seems normal, but I find that if I compile the same goal in tensorflow's self workspace, The generated binaries will be much smaller than the ones I compiled using external dependencies.\r\n\r\nIn the beginning, I thought this was a problem caused by bazel compilation, so I consulted on bazle's community. Here is the issue I initiated\r\n\r\nhttps://github.com/bazelbuild/bazel/issues/6677\r\n\r\nBut after analysis by the developers, it is likely that tensorflow controls itself.\r\n\r\nThis problem has been bothering me for a long time. I hope you can give me some ideas or Suggestions to solve the problem. Thank you very much!\r\n\r\nHere are the issues and validation process I mentioned in issue.\r\n\r\n\r\nThe situation became clear, and I simplified my work the most, remove BUILD file and modified WORKSPACE file to the following\uff1a\r\n```\r\nlocal_repository(\r\n        name=\"org_tensorflow\",\r\n        path=\"../tensorflow\",\r\n)\r\n# TensorFlow depends on \"io_bazel_rules_closure\" so we need this here.\r\n# Needs to be kept in sync with the same target in TensorFlow's WORKSPACE file.\r\nhttp_archive(\r\n    name = \"io_bazel_rules_closure\",\r\n    sha256 = \"6691c58a2cd30a86776dd9bb34898b041e37136f2dc7e24cadaeaf599c95c657\",\r\n    strip_prefix = \"rules_closure-08039ba8ca59f64248bb3b6ae016460fe9c9914f\",\r\n    urls = [\r\n        \"https://mirror.bazel.build/github.com/bazelbuild/rules_closure/archive/08039ba8ca59f64248bb3b6ae016460fe9c9914f.tar.gz\",\r\n        \"https://github.com/bazelbuild/rules_closure/archive/08039ba8ca59f64248bb3b6ae016460fe9c9914f.tar.gz\",  # 2018-01-16\r\n    ],\r\n)\r\nload('@org_tensorflow//tensorflow:workspace.bzl', 'tf_workspace')\r\ntf_workspace(path_prefix = \"\", tf_repo_name = \"org_davinci\")\r\n```\r\n\r\nI then modified the BUILD file in the tensorflow source directory \uff08../tensorflow\uff09\uff0c\r\n```\r\nexports_files(\r\n    [\r\n        \"LICENSE\",\r\n        \"ACKNOWLEDGEMENTS\",\r\n    ],\r\n)\r\n#bazel build //tensorflow/contrib/davinci_adpt_2:libtf_kernels.so\r\n#By default, packages of \u201c_impl\u201d are not visible\uff0cHere I changed the package visibility in core/framework/BUILD\r\n## \r\ncc_binary(\r\n    name = \"libtf_kernels.so\",\r\n    visibility = [\"//visibility:public\"],\r\n    deps = [\r\n        \":op_interface\",\r\n        \"//tensorflow/core:framework_internal_impl\",\r\n        \"//tensorflow/core:lib_internal_impl\",\r\n        \"//tensorflow/core:core_cpu_impl\",\r\n    ],\r\n    linkstatic = True,\r\n    linkshared = True,\r\n)\r\ncc_library(\r\n    name = \"op_interface\",\r\n    visibility = [\"//visibility:public\"],\r\n    srcs = glob([],exclude=[]),\r\n    hdrs = glob([],exclude=[]),\r\n    deps = [\r\n        \"//tensorflow/core:all_kernels\",\r\n        \"//tensorflow/core:lib\",\r\n        \"//tensorflow/core:core_cpu\",\r\n    ],\r\n)\r\n```\r\nI tested three scenarios\uff1a\r\n- In my workspace dir\r\n```\r\nbazel build @org_tensorflow//:libtf_kernels.so\r\n```\r\nThis creates a 700M .so file\r\n\r\n- in the tensorflow source directory\r\n```\r\nbazel build //:libtf_kernels.so\r\n```\r\nThis creates a 125M .so file\r\n\r\n- in the tensorflow source directory\r\n```\r\nbazel build @org_tensorflow//:libtf_kernels.so\r\n```\r\nThis also creates a 125M .so file\r\n\r\n### Here if I don't add the three \"_impl\" dependencies and run `bazel build //:libtf_kernels.so` in the source directory of tensorflow, I will fail in the link phase!  But even without the three \"_impl\" dependencies, I can still compile successfully in my own workspace!\r\n\r\nI don't know what the problem is there, it looks like the content is similar when linked, but when I executed under the source directory of tensorflow, bazel didn't compile enough targets?\r\n", "comments": ["Done"]}, {"number": 23832, "title": "Tensorflow conda-forge installation issues", "body": "**System information**\r\n- OS Platform and Distribution: MacOSX version 10.11.6\r\n- TensorFlow version: 1.10\r\n- Python version: 3.6\r\n- Installed using conda\r\n\r\nJust to clarify, I'm trying to perform an out-of-the-box installation of tensorflow.  Below is the tensorflow installation procedure that I used, in addition to the error that I get\r\n\r\n```\r\nconda create -n tf-test tensorflow -c conda-forge\r\nsource activate tf-test\r\npython -c \"import tensorflow\"\r\n\r\nTraceback (most recent call last):\r\n  File \"/Users/mortonjt/miniconda3/envs/tf-test/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"/Users/mortonjt/miniconda3/envs/tf-test/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"/Users/mortonjt/miniconda3/envs/tf-test/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"/Users/mortonjt/miniconda3/envs/tf-test/lib/python3.6/imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"/Users/mortonjt/miniconda3/envs/tf-test/lib/python3.6/imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: dlopen(/Users/mortonjt/miniconda3/envs/tf-test/lib/python3.6/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so, 6): Symbol not found: _SecKeyCopyExternalRepresentation\r\n  Referenced from: /Users/mortonjt/miniconda3/envs/tf-test/lib/python3.6/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so (which was built for Mac OS X 10.12)\r\n  Expected in: /System/Library/Frameworks/Security.framework/Versions/A/Security\r\n in /Users/mortonjt/miniconda3/envs/tf-test/lib/python3.6/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/Users/mortonjt/miniconda3/envs/tf-test/lib/python3.6/site-packages/tensorflow/__init__.py\", line 22, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"/Users/mortonjt/miniconda3/envs/tf-test/lib/python3.6/site-packages/tensorflow/python/__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"/Users/mortonjt/miniconda3/envs/tf-test/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"/Users/mortonjt/miniconda3/envs/tf-test/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"/Users/mortonjt/miniconda3/envs/tf-test/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"/Users/mortonjt/miniconda3/envs/tf-test/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"/Users/mortonjt/miniconda3/envs/tf-test/lib/python3.6/imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"/Users/mortonjt/miniconda3/envs/tf-test/lib/python3.6/imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: dlopen(/Users/mortonjt/miniconda3/envs/tf-test/lib/python3.6/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so, 6): Symbol not found: _SecKeyCopyExternalRepresentation\r\n  Referenced from: /Users/mortonjt/miniconda3/envs/tf-test/lib/python3.6/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so (which was built for Mac OS X 10.12)\r\n  Expected in: /System/Library/Frameworks/Security.framework/Versions/A/Security\r\n in /Users/mortonjt/miniconda3/envs/tf-test/lib/python3.6/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n```\r\n\r\nThe full information about the conda environment can be found below\r\n\r\n<br/>\r\n\r\nEnvironment (<code>conda list</code>):\r\n<details>\r\n\r\n```\r\n$ conda list\r\n# packages in environment at /Users/mortonjt/miniconda3/envs/tf-test:\r\n#\r\n# Name                    Version                   Build  Channel\r\nabsl-py                   0.6.1                 py36_1000    conda-forge\r\nastor                     0.7.1                      py_0    conda-forge\r\nblas                      1.0                         mkl  \r\nbzip2                     1.0.6                         1    conda-forge\r\nc-ares                    1.15.0               h470a237_1    conda-forge\r\nca-certificates           2018.10.15           ha4d7672_0    conda-forge\r\ncertifi                   2018.10.15            py36_1000    conda-forge\r\ngast                      0.2.0                      py_0    conda-forge\r\ngrpcio                    1.16.0           py36hd60e7a3_0    conda-forge\r\nintel-openmp              2019.0                      118  \r\nlibffi                    3.2.1                hfc679d8_5    conda-forge\r\nlibgfortran               3.0.1                h93005f0_2  \r\nlibprotobuf               3.6.1                hd28b015_0    conda-forge\r\nmarkdown                  2.6.11                     py_0    conda-forge\r\nmkl                       2019.0                      118  \r\nmkl_fft                   1.0.6                    py36_0    conda-forge\r\nmkl_random                1.0.2                    py36_0    conda-forge\r\nncurses                   6.1                  hfc679d8_1    conda-forge\r\nnumpy                     1.15.4           py36h6a91979_0  \r\nnumpy-base                1.15.4           py36h8a80b8c_0  \r\nopenssl                   1.0.2p               h470a237_1    conda-forge\r\npip                       18.1                  py36_1000    conda-forge\r\nprotobuf                  3.6.1            py36hfc679d8_1    conda-forge\r\npython                    3.6.6                h5001a0f_0    conda-forge\r\nreadline                  7.0                  haf1bffa_1    conda-forge\r\nsetuptools                40.6.2                   py36_0    conda-forge\r\nsix                       1.11.0                py36_1001    conda-forge\r\nsqlite                    3.25.3               hb1c47c0_0    conda-forge\r\ntensorboard               1.10.0                   py36_0    conda-forge\r\ntensorflow                1.10.0                   py36_0    conda-forge\r\ntermcolor                 1.1.0                      py_2    conda-forge\r\ntk                        8.6.9                ha92aebf_0    conda-forge\r\nwerkzeug                  0.14.1                     py_0    conda-forge\r\nwheel                     0.32.2                   py36_0    conda-forge\r\nxz                        5.2.4                h470a237_1    conda-forge\r\nzlib                      1.2.11               h470a237_3    conda-forge\r\n```\r\n\r\n</details>\r\n\r\nDetails about  <code>conda</code> and system ( <code>conda info</code> ):\r\n<details>\r\n\r\n```\r\n$ conda info\r\n     active environment : tf-test\r\n    active env location : /Users/mortonjt/miniconda3/envs/tf-test\r\n            shell level : 1\r\n       user config file : /Users/mortonjt/.condarc\r\n populated config files : \r\n          conda version : 4.5.11\r\n    conda-build version : not installed\r\n         python version : 3.7.0.final.0\r\n       base environment : /Users/mortonjt/miniconda3  (writable)\r\n           channel URLs : https://repo.anaconda.com/pkgs/main/osx-64\r\n                          https://repo.anaconda.com/pkgs/main/noarch\r\n                          https://repo.anaconda.com/pkgs/free/osx-64\r\n                          https://repo.anaconda.com/pkgs/free/noarch\r\n                          https://repo.anaconda.com/pkgs/r/osx-64\r\n                          https://repo.anaconda.com/pkgs/r/noarch\r\n                          https://repo.anaconda.com/pkgs/pro/osx-64\r\n                          https://repo.anaconda.com/pkgs/pro/noarch\r\n          package cache : /Users/mortonjt/miniconda3/pkgs\r\n                          /Users/mortonjt/.conda/pkgs\r\n       envs directories : /Users/mortonjt/miniconda3/envs\r\n                          /Users/mortonjt/.conda/envs\r\n               platform : osx-64\r\n             user-agent : conda/4.5.11 requests/2.19.1 CPython/3.7.0 Darwin/15.6.0 OSX/10.11.6\r\n                UID:GID : 501:20\r\n             netrc file : None\r\n           offline mode : False\r\n```\r\n</details>\r\n\r\nNot sure about the connection between conda-forge and the main TF branch, but this is an awesome resource and having these sorts of issues resolved in the conda recipe would be extremely helpful, particularly for software that heavily depend on conda.\r\n\r\nThis issue has been referenced here:\r\nhttps://github.com/conda-forge/tensorflow-feedstock/issues/64\r\n\r\nEdit: the tensorflow installation from the anaconda channel seems to be working\r\n\r\n```\r\nconda create -n tf-test2 tensorflow\r\nsource activate tf-test2\r\npython -c \"import tensorflow\" \r\n```", "comments": ["Anaconda and conda-forge TF releases are not owned by us.\r\nThey are maintained by the community.\r\nPlease reach out to the package owners through conda-forge."]}, {"number": 23831, "title": "Documentation link broken", "body": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version: 1.12\r\n- Doc Link: https://www.tensorflow.org/guide/extend/model_files\r\n\r\n\r\n**Describe the documentation issue**\r\nLinked file in https://www.tensorflow.org/guide/extend/model_files#text_or_binary was already removed from tensorboard repo by https://github.com/tensorflow/tensorboard/pull/1512.\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\nCan not.", "comments": ["@wydwww Which link are you referring to?\r\nLinks for graph_run_run2.pbtxt and inception_v3 archive seem to be working correctly.", "@Ayush517 It's already been fixed. Closed."]}, {"number": 23830, "title": "Not compatible with tf.float16", "body": "### System information\r\n- **OS Platform - Windows10 (64-bit OS and x64-based processor)**:\r\n- **TensorFlow installed from Anaconda**:\r\n- **TensorFlow version - 1.11.0**:\r\n- **Python version - 3.6.5**:\r\n\r\nfloat16 not in the list of allowed values.\r\n**Command:**\r\n```\r\na = tf.placeholder(tf.float16, shape=[2, 2])\r\ngen_linalg_ops.qr(a)\r\n```\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-11-9aca9b273d31> in <module>\r\n      1 a = tf.placeholder(tf.float16, shape=[2, 2])\r\n----> 2 gen_linalg_ops.qr(a)\r\n\r\nG:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_linalg_ops.py in qr(input, full_matrices, name)\r\n   1486     full_matrices = _execute.make_bool(full_matrices, \"full_matrices\")\r\n   1487     _, _, _op = _op_def_lib._apply_op_helper(\r\n-> 1488         \"Qr\", input=input, full_matrices=full_matrices, name=name)\r\n   1489     _result = _op.outputs[:]\r\n   1490     _inputs_flat = _op.inputs\r\n\r\nG:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py in _apply_op_helper(self, op_type_name, name, **keywords)\r\n    607               _SatisfiesTypeConstraint(base_type,\r\n    608                                        _Attr(op_def, input_arg.type_attr),\r\n--> 609                                        param_name=input_name)\r\n    610             attrs[input_arg.type_attr] = attr_value\r\n    611             inferred_from[input_arg.type_attr] = input_name\r\n\r\nG:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py in _SatisfiesTypeConstraint(dtype, attr_def, param_name)\r\n     58           \"allowed values: %s\" %\r\n     59           (param_name, dtypes.as_dtype(dtype).name,\r\n---> 60            \", \".join(dtypes.as_dtype(x).name for x in allowed_list)))\r\n     61 \r\n     62 \r\n\r\nTypeError: Value passed to parameter 'input' has DataType float16 not in list of allowed values: float64, float32, complex64, complex128\r\n", "comments": ["Added the PR #23841 for the fix.", "@tensorflowbutler I don't have permission to update the label. It would be great if you could do that!", "@Shwetago  Awaiting for the PR to get merged. ", "Okay. Could you please explain what are the changes you have made? Is it working? @harshini-gadige ", "Hi @Shwetago!\r\nWe are checking to see if you still need help in this issue , Have you tried latest stable version TF 2.6  yet? Please create a new issue if the issue is replicating in newer version. Thanks!", "Hi @mohantym, \r\nYes, the issue has been resolved now. It is working on version TF 2.6. I have tested it on Google Colab. I am closing this issue as of now!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/23830\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/23830\">No</a>\n"]}, {"number": 23829, "title": "[TFLite] Add options for benchmark_model and label_image to allow fp16 for fp32 models", "body": "Add options for benchmark_model and label_image to allow running fp32 models with fp16. Useful when testing NNPAI accelerators with fp16 capability.", "comments": ["@freedomtan please rebase branch", "@rthadur it seems the patch is merged into master already, see https://github.com/tensorflow/tensorflow/commit/c28a24b5f40a2ba887981e55b8f449633a71ccda", "> @rthadur it seems the patch is merged into master already, see [c28a24b](https://github.com/tensorflow/tensorflow/commit/c28a24b5f40a2ba887981e55b8f449633a71ccda)\r\n\r\nyes , thank you closing this PR"]}, {"number": 23828, "title": "Fixes the long sentences and categorisation in README.md", "body": "- brakes the very long sentences into two relative short sentences\r\n- for language supports just list the languages.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->", "I'd rather we didn't make that change.\r\n\r\n1. The wording with \"or\" is clearer.\r\n2. The long lines make it harder to use tooling, which is why we typically limit to 80 characters.\r\n3. The wording about languages is intentional and it's the guarantee that we have. We don't have stable language support for Go etc.", "Re point 3 of @drpngx , the API in the JavaScript version (TensorFlow.js) hasn't reached stability (v1.0), either."]}, {"number": 23827, "title": "Tensor cpu need cuda?", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): W7 64 bit\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version: 1.12.0\r\n- Python version: 3.6.5\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: not supported by GPU\r\n- GPU model and memory: Geforce GT 330m\r\n\r\n\r\n\r\n**Describe the problem**\r\ni have cpu tensor,couse my video card don't support cuda acceleration.\r\nI have correctly installed tensorflow by pip command,but i got error when import.\r\nsome one told me about cuda driver etc,but why i need it if i want use cpu version?\r\ni tryed to use cuda and cudnn,but error persist\r\ni got this error using keras too\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Xxx\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\\r\ntensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\xxx\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\\r\ntensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, descript\r\nion)\r\n  File \"C:\\Users\\xxx\\AppData\\Local\\Programs\\Python\\Python36\\lib\\imp.py\", line\r\n243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\xxxx\\AppData\\Local\\Programs\\Python\\Python36\\lib\\imp.py\", line\r\n343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed with error code -1073741795\r\n343, in load_dynamic\r\n   \r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n", "comments": ["There's a strong possibility your CPU is refusing to work with the most recent version of TensorFlow. This is a recurring error for newcomers to TensorFlow. Installing any data science library is an art and not a straight-forward task. You'll be lucky if all of your dependencies are in-check and everything works the first time. In short, you will need to downgrade your TensorFlow wheel version.  \r\n\r\nSomething like this: \r\n`python -m pip uninstall tensorflow`\r\n\r\nThen, proceed to install an earlier version of Tensorflow, like so:\r\n`python -m pip uninstall tensorflow==1.5`\r\n\r\nYour computer may require a later(e.g. Tensorflow==1.7) or even an earlier(e.g. Tensorflow==1.4) version. You will need to play and tweak as needed. \r\n\r\nPlease be advised that earlier versions of TensorFlow lack performance as well as some features.", "i checked and googled all the possibilities,probably is cpu incompatibly with tensors,i downgraded at 1.10.0 and checked the right wheel config.\r\nnow seems working but have to test it\r\nmy cpu is 720qm (too old)", "I see. You will need to invest in a more capable computer in the near future if you want to test newer Tensorflow features. ", "i7-720QM does not support AVX. \r\nTensorflow==1.5 is the last (official) version that build w/o AVX.\r\nYou can use newer tensorflow by installing a custom build w/o AVX, for example: https://github.com/fo40225/tensorflow-windows-wheel\r\n\r\nEdit:\r\nfo40225 build tensorflow using VisualStudio 2017. It may not work properly on Windows 7."]}, {"number": 23826, "title": "Why is bias is added by 0.5", "body": "\r\n![biaserr](https://user-images.githubusercontent.com/5864369/48667949-7ae2ea00-eae2-11e8-9a5a-a24e1049d54f.png)\r\nHello I'm wondering why is the predicted bias term is always 0.5 greater than the real bias term, I know that I'm adding noise but in the example in cognitive classes they dont have this problem. Thoughts ?", "comments": []}, {"number": 23825, "title": "Fix deprecated div", "body": "While running test I noticed the following warning:\r\n```\r\nWARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_ops.py:2744: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nDeprecated in favor of operator or tf.math.divide.\r\n```\r\n\r\nThis fix fixes the deprecated warning.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["@alextp  Can we bypass the two Windows Bazel failures and proceed ? Please correct me if I'm wrong.", "Let's retry instead."]}]