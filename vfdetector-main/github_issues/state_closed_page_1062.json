[{"number": 21425, "title": "Refactor dependencies so keras_support can be imported directly.", "body": "PiperOrigin-RevId: 207569055", "comments": ["The cmake breakage looks real. You may need to apply the changes to the cmake build file as well.", "The only place relevant I can see is adding `tensorflow/compiler/xla/` to `tensorflow/contrib/cmake/python_protos.txt`.  \r\n\r\nAll of the other references seem reasonable."]}, {"number": 21424, "title": "Fix readme formatting", "body": "", "comments": ["Hello, my PR already fixes this: https://github.com/tensorflow/tensorflow/pull/21375"]}, {"number": 21423, "title": "Fix bazel issue with jpeg lib on arm v7", "body": "Without this, you'll get errors, because you end up including these files. This is already fixed when compiling for ARM v8, but wasn't fixed for ARM v7.", "comments": []}, {"number": 21422, "title": "Don't include -lpthread for android", "body": "Created to fix https://github.com/tensorflow/tensorflow/issues/21421. \r\n\r\nI'm not sure this is a good idea, this might break something else?", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n<!-- need_author_cla -->", "CLAs look good, thanks!\n\n<!-- ok -->"]}, {"number": 21421, "title": "Android: cannot find -lpthread for simple binary", "body": "I'm trying to compile a simple application for Android and getting linker errors: Bazel is linking in `-lpthread`, even though Android doesn't support that.\r\n\r\nThe application code is as follows:\r\n\r\n*tensorflow/demo-bug/main.cc*:\r\n```\r\nint main() {\r\n  return 0;\r\n}\r\n```\r\n\r\nThe BUILD file is as follows:\r\n\r\n*tensorflow/demo-bug/BUILD*:\r\n```\r\ncc_binary(\r\n    name = \"main\",\r\n    srcs = [\"main.cc\"],\r\n    deps = [\"//tensorflow/core:core_cpu\"],\r\n)\r\n```\r\n\r\nIf you don't include `//tensorflow/core:core_cpu` in the `deps`, the error doesn't happen. For some reason, that dependency pulls in the `-lpthread` from somewhere.\r\n\r\nWhen you run the `bazel build` command (see below), you get the following error:\r\n```\r\nexternal/androidndk/ndk/toolchains/arm-linux-androideabi-4.9/prebuilt/linux-x86_64/lib/gcc/arm-linux-androideabi/4.9.x/../../../../arm-linux-androideabi/bin/ld: error: cannot find -lpthread\r\n```\r\nIndeed, looking through the command that it uses to compile it, you see the flag:\r\n```\r\n...-stl/llvm-libc++/libs/armeabi-v7a/libunwind.a -ldl -lm -ldl -lpthread -lm -pthread -lm -lm -static-libgcc -gcc-toolchain external/androidndk/ndk/toolchains/arm-linux-androideabi-4.9/prebuilt/linux-x86_64 -no-canonical-prefixes ...\r\n```\r\n(Full command below)\r\n```\r\n  external/androidndk/ndk/toolchains/llvm/prebuilt/linux-x86_64/bin/clang -o bazel-out/armeabi-v7a-py3-opt/bin/tensorflow/demo-bug/main bazel-out/armeabi-v7a-py3-opt/bin/tensorflow/demo-bug/_objs/main/tensorflow/demo-bug/main.o -Wl,-whole-archive bazel-out/armeabi-v7a-py3-opt/bin/tensorflow/core/libcore_cpu_internal.lo -Wl,-no-whole-archive bazel-out/armeabi-v7a-py3-opt/bin/tensorflow/core/grappler/optimizers/libmeta_optimizer.a bazel-out/armeabi-v7a-py3-opt/bin/tensorflow/core/grappler/optimizers/libarithmetic_optimizer.a bazel-out/armeabi-v7a-py3-opt/bin/tensorflow/core/grappler/optimizers/libgraph_optimizer_stage.a bazel-out/armeabi-v7a-py3-opt/bin/tensorflow/core/grappler/optimizers/libauto_parallel.a bazel-out/armeabi-v7a-py3-opt/bin/tensorflow/core/grappler/optimizers/libcustom_graph_optimizer_registry_impl.a bazel-out/armeabi-v7a-py3-opt/bin/tensorflow/core/grappler/optimizers/libdebug_stripper.a bazel-out/armeabi-v7a-py3-opt/bin/tensorflow/core/grappler/optimizers/libdependency_optimizer.a bazel-out/armeabi-v7a-py3-opt/bin/tensorflow/core/grappler/optimizers/libfunction_optimizer.a bazel-out/armeabi-v7a-py3-opt/bin/tensorflow/core/grappler/optimizers/liblayout_optimizer.a bazel-out/armeabi-v7a-py3-opt/bin/tensorflow/core/grappler/optimizers/libloop_optimizer.a bazel-out/armeabi-v7a-py3-opt/bin/tensorflow/core/grappler/optimizers/libmemory_optimizer.a bazel-out/armeabi-v7a-py3-opt/bin/tensorflow/core/grappler/optimizers/libstatic_schedule.a bazel-out/armeabi-v7a-py3-opt/bin/tensorflow/core/grappler/costs/libgraph_memory.a bazel-out/armeabi-v7a-py3-opt/bin/tensorflow/core/grappler/clusters/libvirtual_cluster.a bazel-out/armeabi-v7a-py3-opt/bin/tensorflow/core/grappler/costs/libop_level_cost_estimator.a bazel-out/armeabi-v7a-py3-opt/bin/tensorflow/core/grappler/costs/libvirtual_scheduler.a bazel-out/armeabi-v7a-py3-opt/bin/tensorflow/core/grappler/costs/libvirtual_placer.a bazel-out/armeabi-v7a-py3-opt/bin/tensorflow/core/grappler/libdevices.a bazel-out/armeabi-v7a-py3-opt/bin/tensorflow/core/grappler/utils/libtraversal.a bazel-out/armeabi-v7a-py3-opt/bin/tensorflow/core/grappler/optimizers/libmodel_pruner.a bazel-out/armeabi-v7a-py3-opt/bin/tensorflow/core/grappler/optimizers/libgraph_rewriter.a bazel-out/armeabi-v7a-py3-opt/bin/tensorflow/core/grappler/optimizers/libremapper.a bazel-out/armeabi-v7a-py3-opt/bin/tensorflow/core/grappler/optimizers/libconstant_folding.a bazel-out/armeabi-v7a-py3-opt/bin/tensorflow/core/grappler/optimizers/libscoped_allocator_optimizer.a -Wl,-whole-archive bazel-out/armeabi-v7a-py3-opt/bin/tensorflow/core/libscoped_allocator_ops_op_lib.lo -Wl,-no-whole-archive bazel-out/armeabi-v7a-py3-opt/bin/tensorflow/core/grappler/optimizers/libshape_optimizer.a bazel-out/armeabi-v7a-py3-opt/bin/tensorflow/core/grappler/optimizers/libsymbolic_shapes.a bazel-out/armeabi-v7a-py3-opt/bin/tensorflow/core/grappler/costs/libgraph_properties.a bazel-out/armeabi-v7a-py3-opt/bin/tensorflow/core/grappler/costs/libutils.a bazel-out/armeabi-v7a-py3-opt/bin/tensorflow/core/grappler/clusters/libutils.a bazel-out/armeabi-v7a-py3-opt/bin/tensorflow/core/libgpu_id_impl.a bazel-out/armeabi-v7a-py3-opt/bin/tensorflow/core/grappler/libgraph_view.a bazel-out/armeabi-v7a-py3-opt/bin/tensorflow/core/grappler/clusters/libcluster.a bazel-out/armeabi-v7a-py3-opt/bin/tensorflow/core/grappler/utils/libframe.a -Wl,-whole-archive bazel-out/armeabi-v7a-py3-opt/bin/tensorflow/core/libcore_cpu_base.lo -Wl,-no-whole-archive -Wl,-whole-archive bazel-out/armeabi-v7a-py3-opt/bin/tensorflow/core/libfunction_ops_op_lib.lo -Wl,-no-whole-archive -Wl,-whole-archive bazel-out/armeabi-v7a-py3-opt/bin/tensorflow/core/libfunctional_grad.lo -Wl,-no-whole-archive -Wl,-whole-archive bazel-out/armeabi-v7a-py3-opt/bin/tensorflow/core/libfunctional_ops_op_lib.lo -Wl,-no-whole-archive bazel-out/armeabi-v7a-py3-opt/bin/tensorflow/core/grappler/utils/libcolocation.a bazel-out/armeabi-v7a-py3-opt/bin/tensorflow/core/grappler/utils/libfunctions.a bazel-out/armeabi-v7a-py3-opt/bin/tensorflow/core/grappler/utils/libtopological_sort.a -Wl,-whole-archive bazel-out/armeabi-v7a-py3-opt/bin/tensorflow/core/kernels/libno_op.lo -Wl,-no-whole-archive -Wl,-whole-archive bazel-out/armeabi-v7a-py3-opt/bin/tensorflow/core/kernels/libsendrecv_ops.lo -Wl,-no-whole-archive -Wl,-whole-archive bazel-out/armeabi-v7a-py3-opt/bin/tensorflow/core/libno_op_op_lib.lo -Wl,-no-whole-archive -Wl,-whole-archive bazel-out/armeabi-v7a-py3-opt/bin/tensorflow/core/libsendrecv_ops_op_lib.lo -Wl,-no-whole-archive -Wl,-whole-archive bazel-out/armeabi-v7a-py3-opt/bin/tensorflow/core/libcore_cpu_impl.lo -Wl,-no-whole-archive bazel-out/armeabi-v7a-py3-opt/bin/tensorflow/core/libgraph.a bazel-out/armeabi-v7a-py3-opt/bin/tensorflow/core/grappler/libgrappler_item.a bazel-out/armeabi-v7a-py3-opt/bin/tensorflow/core/grappler/libop_types.a bazel-out/armeabi-v7a-py3-opt/bin/tensorflow/core/grappler/libutils.a -Wl,-whole-archive bazel-out/armeabi-v7a-py3-opt/bin/tensorflow/core/libframework_internal_impl.lo -Wl,-no-whole-archive bazel-out/armeabi-v7a-py3-opt/bin/tensorflow/core/libprotos_all_proto_text.a bazel-out/armeabi-v7a-py3-opt/bin/tensorflow/core/liberror_codes_proto_text.a bazel-out/armeabi-v7a-py3-opt/bin/tensorflow/core/liblib_internal_impl.a bazel-out/armeabi-v7a-py3-opt/bin/tensorflow/core/liblib_hash_crc32c_accelerate_internal.a bazel-out/armeabi-v7a-py3-opt/bin/tensorflow/core/liblib_proto_parsing.a bazel-out/armeabi-v7a-py3-opt/bin/tensorflow/core/libabi.a bazel-out/armeabi-v7a-py3-opt/bin/tensorflow/core/libcore_stringpiece.a bazel-out/armeabi-v7a-py3-opt/bin/tensorflow/core/libplatform_base.a bazel-out/armeabi-v7a-py3-opt/bin/external/snappy/libsnappy.a bazel-out/armeabi-v7a-py3-opt/bin/external/double_conversion/libdouble-conversion.a bazel-out/armeabi-v7a-py3-opt/bin/tensorflow/core/grappler/costs/libop_performance_data_cc_impl.a bazel-out/armeabi-v7a-py3-opt/bin/tensorflow/core/libversion_lib.a bazel-out/armeabi-v7a-py3-opt/bin/external/gif_archive/libgif.a bazel-out/armeabi-v7a-py3-opt/bin/external/jpeg/libjpeg.a bazel-out/armeabi-v7a-py3-opt/bin/external/jpeg/libsimd_armv7a.a bazel-out/armeabi-v7a-py3-opt/bin/external/com_googlesource_code_re2/libre2.a bazel-out/armeabi-v7a-py3-opt/bin/external/farmhash_archive/libfarmhash.a bazel-out/armeabi-v7a-py3-opt/bin/external/fft2d/libfft2d.a bazel-out/armeabi-v7a-py3-opt/bin/external/highwayhash/libsip_hash.a bazel-out/armeabi-v7a-py3-opt/bin/external/highwayhash/libarch_specific.a bazel-out/armeabi-v7a-py3-opt/bin/external/png_archive/libpng.a bazel-out/armeabi-v7a-py3-opt/bin/external/zlib_archive/libzlib.a bazel-out/armeabi-v7a-py3-opt/bin/external/nsync/libnsync_cpp.a bazel-out/armeabi-v7a-py3-opt/bin/tensorflow/core/libprotos_all_proto_cc_impl.a bazel-out/armeabi-v7a-py3-opt/bin/tensorflow/core/liberror_codes_proto_cc_impl.a bazel-out/armeabi-v7a-py3-opt/bin/external/protobuf_archive/libprotobuf.a bazel-out/armeabi-v7a-py3-opt/bin/external/protobuf_archive/libprotobuf_lite.a external/androidndk/ndk/sources/cxx-stl/llvm-libc++/libs/armeabi-v7a/libandroid_support.a external/androidndk/ndk/sources/cxx-stl/llvm-libc++/libs/armeabi-v7a/libc++.a external/androidndk/ndk/sources/cxx-stl/llvm-libc++/libs/armeabi-v7a/libc++_static.a external/androidndk/ndk/sources/cxx-stl/llvm-libc++/libs/armeabi-v7a/libc++abi.a external/androidndk/ndk/sources/cxx-stl/llvm-libc++/libs/armeabi-v7a/libunwind.a -ldl -lm -ldl -lpthread -lm -pthread -lm -lm -static-libgcc -gcc-toolchain external/androidndk/ndk/toolchains/arm-linux-androideabi-4.9/prebuilt/linux-x86_64 -no-canonical-prefixes -target armv7-none-linux-androideabi -Wl,--fix-cortex-a8 -Lexternal/androidndk/ndk/sources/cxx-stl/llvm-libc++/libs/armeabi-v7a '--sysroot=external/androidndk/ndk/platforms/android-23/arch-arm')\r\n```\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes, see above\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: N/A\r\n- **TensorFlow installed from (source or binary)**: Source\r\n- **TensorFlow version (use command below)**: v1.9.0 (git tag)\r\n- **Python version**: 3.5\r\n- **Bazel version (if compiling from source)**: 0.15.2\r\n- **GCC/Compiler version (if compiling from source)**: Android NDK r17b\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**:\r\n```\r\n# ARM v7\r\nbazel \\\r\n  --crosstool_top=//external:android/crosstool \\\r\n  --host_crosstool_top=@bazel_tools//tools/cpp:toolchain \\\r\n  --config=android \\\r\n  --cpu=armeabi-v7a \\\r\n  --fat_apk_cpu=armeabi-v7a \\\r\n  --verbose_failures \\\r\n  --cxxopt=-std=c++11 \\\r\n  --config=monolithic \\\r\n  //tensorflow/demo-bug:main\r\n\r\n# ARM v8\r\nbazel \\\r\n  --crosstool_top=//external:android/crosstool \\\r\n  --host_crosstool_top=@bazel_tools//tools/cpp:toolchain \\\r\n  --config=android \\\r\n  --cpu=arm64-v8a \\\r\n  --fat_apk_cpu=arm64-v8a \\\r\n  --verbose_failures \\\r\n  --cxxopt=-std=c++11 \\\r\n  --config=monolithic \\\r\n  //tensorflow/demo-bug:main\r\n```", "comments": ["I have confirmed that the behaviour is identical on current `master` (`1282e2b6fbb5f3ce9745402922a84291786ec62d`).", "I've traced this down to \r\n```\r\n\"//conditions:default\": [\r\n    \"-ldl\",\r\n    \"-lpthread\",\r\n],\r\n```\r\nwhich is [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/BUILD#L2036).\r\n\r\nIs this a bug? \r\n\r\nIf I add `//tensorflow:android\": []` as an option in the `select`, this goes away.", "Additionally, the same problem seems to exist with the target `\"//tensorflow/core/kernels/data:dataset_ops\"`.", "There is no libpthread in Android. Another easy way to compile your app is to add `linkopts` to your `BUILD`, something like\r\n```\r\n    linkopts = select({\r\n        \"//tensorflow:android\": [],\r\n        \"//conditions:default\":......\r\n    }),\r\n```", "@freedomtan I'm not sure you understood what the bug report is, sorry if I was unclear.\r\n\r\nEven if I add those `linkopts` to my build, if I depend on `//tensorflow/core:lib`, I will get `-lpthread` as an argument, because the `linkopts` from `//tensorflow/core:lib` propagate upwards to my app. This needs to be fixed in the `//tensorflow/core` `BUILD` file, I think.", "@gibiansky because you are not supposed to build `//tensorflow/core:lib` for Android. There are Android specific targets. Check [this](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/label_image/BUILD#L35-L51) as an example.", "Ah, perfect, I'll try it out. Maybe it'll reduce file size a bit to do this although I think the selective op registration is already working fine.\r\n\r\nFWIW everything seems to work smoothly depending on the standard TF lib as long as you add a `//tensorflow:android` condition."]}, {"number": 21420, "title": "Merge pull request #21386 from ageron:fix_unread_var_name", "body": "PiperOrigin-RevId: 207588692", "comments": []}, {"number": 21419, "title": "Updating the version to 1.10 final.", "body": "", "comments": []}, {"number": 21418, "title": "Fix the name property for the _UnreadVariable class in eager mode (fi\u2026", "body": "\u2026xes #21384)", "comments": ["So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored or co-authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of the commit author(s) and merge this pull request when appropriate.*\n\n<!-- need_author_consent -->", "A Googler has manually verified that the CLAs look good.\n\n(Googler, please make sure the reason for overriding the CLA status is clearly documented in these comments.)\n\n<!-- cla_yes -->"]}, {"number": 21417, "title": "Discrepancy between Python and C++ loading of corrupt SavedModels", "body": "\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: YES\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS High Seirra 10.13.6\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: NOT MOBILE\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: ('v1.9.0-0-g25c197e023', '1.9.0')\r\n- **Python version**:Python 2.7.10\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: \r\n \t- Train and export the MNIST model with `python mnist.py`. This will export a model in tmp directory in the same folder as mnist.py script.\r\n\r\n \t-  Remove the variables.index file from ./tmp/mnist_model/15*/variables/ folder. This is an important step required to reproduce the partial model load issue.\r\n\t- Load the model in python with load.py (might want to change path on line 6) by executing\r\n\t`python load.py`. This should throw an error. Expected behavior.\r\n\t- Load the model in java with Load.java (might want to change path on line 6) by executing\r\n\t`javac -cp libtensorflow-1.9.0.jar Load.java` and\r\n\t`java -cp libtensorflow-1.9.0.jar:. -Djava.library.path=./jni Load`. This does not throw an error. Only when you send some input data to this model does it throw an error. Unexpected behavior.\r\n\r\n### Describe the problem\r\nThis bug is to illustrate the partial model load discrepancy in the Python and Java API.\r\n\r\n- The exported model directory consists of a saved_model.pb file corresponding to the \r\ngraph of the exported model. The directory also consists of a variables directory. This variables\r\ndirectory consists of a variables.index file which list the variables used by the model and a variables.data file. Note that it is possible to have a model with no variables directory for a model with zero variables.\r\n\r\n\r\n- Situation: In cases where model does not have the variables.index file, Python API throws an exception whereas Java API doesn't throw an exception.\r\n\r\nIf you load the partial model in Python with\r\n\r\n`tf.saved_model.loader.load`\r\nthe missing variables.index file issue is caught and it throws an error. This is because, in python when it loads the model, it restores the variables too: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/saved_model/loader_impl.py#L349. It sees that some of the variables needed in the graph, are not specified via the variables.index file, hence results in UndefinedError.\r\n\r\nIf you load the partial model in Java with\r\n\r\n`SavedModelBundle.load`\r\nthe missing variables.index file issue is not caught and therefore it does not throw an error. This is because in Java, when it loads the model: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/cc/saved_model/loader.cc#L171, it sees that the variables.index file is missing, hence makes the assumption that the graph does not have any variables.\r\n\r\n\r\n\r\n\r\n\r\n### Source code / logs\r\nmnist.py\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nfrom tensorflow.examples.tutorials.mnist import input_data\r\nmnist = input_data.read_data_sets('MNIST_data')\r\n\r\ndef input(dataset):\r\n    return dataset.images, dataset.labels.astype(np.int32)\r\n\r\n# Specify feature\r\nfeature_columns = [tf.feature_column.numeric_column(\"x\", shape=[28, 28])]\r\n\r\n# Build 2 layer DNN classifier\r\nclassifier = tf.estimator.DNNClassifier(\r\n    feature_columns=feature_columns,\r\n    hidden_units=[256, 32],\r\n    optimizer=tf.train.AdamOptimizer(1e-4),\r\n    n_classes=10,\r\n    dropout=0.1,\r\n    model_dir=\"./tmp/mnist_model\"\r\n)\r\n\r\n# Define the training inputs\r\ntrain_input_fn = tf.estimator.inputs.numpy_input_fn(\r\n    x={\"x\": input(mnist.train)[0]},\r\n    y=input(mnist.train)[1],\r\n    num_epochs=None,\r\n    batch_size=50,\r\n    shuffle=True\r\n)\r\n\r\nclassifier.train(input_fn=train_input_fn, steps=100)\r\n\r\n# Define the test inputs\r\ntest_input_fn = tf.estimator.inputs.numpy_input_fn(\r\n    x={\"x\": input(mnist.test)[0]},\r\n    y=input(mnist.test)[1],\r\n    num_epochs=1,\r\n    shuffle=False\r\n)\r\n\r\n# Evaluate accuracy\r\naccuracy_score = classifier.evaluate(input_fn=test_input_fn)[\"accuracy\"]\r\nprint(\"\\nTest Accuracy: {0:f}%\\n\".format(accuracy_score*100))\r\nimage = tf.placeholder(tf.float32,[None])\r\nclassifier.export_savedmodel(\"./tmp/mnist_model\", \r\n\ttf.estimator.export.build_raw_serving_input_receiver_fn({\"x\":image}))\r\n```\r\n\r\nload.py (might want to change path in line 6)\r\n```python\r\nimport tensorflow as tf \r\n\r\nsess = tf.Session()\r\ntf.saved_model.loader.load(sess, \r\n\t[tf.saved_model.tag_constants.SERVING],\r\n\t'./tmp/mnist_model/1533576273')\r\n```\r\n\r\nLoad.java (might want to change path in line 6)\r\n```java\r\nimport org.tensorflow.SavedModelBundle;\r\n\r\npublic class Load {\r\n  public static void main(String[] args) throws Exception {\r\n  \tSavedModelBundle savedModelBundle = SavedModelBundle.load(\r\n  \t\t\"./tmp/mnist_model/1533576273/\", \"serve\");\r\n  }\r\n}\r\n```\r\n\r\nHere's the output when loading the model in python:\r\n```sh\r\n$ python load.py\r\n/Users/priyankj/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\r\n  from ._conv import register_converters as _register_converters\r\n2018-08-06 15:27:37.363952: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2018-08-06 15:27:37.411644: W tensorflow/core/framework/op_kernel.cc:1318] OP_REQUIRES failed at save_restore_tensor.cc:170 : Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for ./tmp/mnist_model/1533576273/variables/variables\r\nTraceback (most recent call last):\r\n  File \"load.py\", line 6, in <module>\r\n    './tmp/mnist_model/1533576273')\r\n  File \"/Users/priyankj/lib/python2.7/site-packages/tensorflow/python/saved_model/loader_impl.py\", line 229, in load\r\n    saver.restore(sess, variables_path)\r\n  File \"/Users/priyankj/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1768, in restore\r\n    six.reraise(exception_type, exception_value, exception_traceback)\r\n  File \"/Users/priyankj/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1752, in restore\r\n    {self.saver_def.filename_tensor_name: save_path})\r\n  File \"/Users/priyankj/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 900, in run\r\n    run_metadata_ptr)\r\n  File \"/Users/priyankj/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1135, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/Users/priyankj/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1316, in _do_run\r\n    run_metadata)\r\n  File \"/Users/priyankj/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1335, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.NotFoundError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for ./tmp/mnist_model/1533576273/variables/variables\r\n\t [[Node: save_1/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT64], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_1/Const_0_0, save_1/RestoreV2/tensor_names, save_1/RestoreV2/shape_and_slices)]]\r\n\r\nCaused by op u'save_1/RestoreV2', defined at:\r\n  File \"load.py\", line 6, in <module>\r\n    './tmp/mnist_model/1533576273')\r\n  File \"/Users/priyankj/lib/python2.7/site-packages/tensorflow/python/saved_model/loader_impl.py\", line 219, in load\r\n    saver = tf_saver.import_meta_graph(meta_graph_def_to_load, **saver_kwargs)\r\n  File \"/Users/priyankj/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1960, in import_meta_graph\r\n    **kwargs)\r\n  File \"/Users/priyankj/lib/python2.7/site-packages/tensorflow/python/framework/meta_graph.py\", line 744, in import_scoped_meta_graph\r\n    producer_op_list=producer_op_list)\r\n  File \"/Users/priyankj/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py\", line 432, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/Users/priyankj/lib/python2.7/site-packages/tensorflow/python/framework/importer.py\", line 442, in import_graph_def\r\n    _ProcessNewOps(graph)\r\n  File \"/Users/priyankj/lib/python2.7/site-packages/tensorflow/python/framework/importer.py\", line 234, in _ProcessNewOps\r\n    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\r\n  File \"/Users/priyankj/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 3563, in _add_new_tf_operations\r\n    for c_op in c_api_util.new_tf_operations(self)\r\n  File \"/Users/priyankj/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 3450, in _create_op_from_tf_operation\r\n    ret = Operation(c_op, self)\r\n  File \"/Users/priyankj/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1740, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\nNotFoundError (see above for traceback): Unsuccessful TensorSliceReader constructor: Failed to find any matching files for ./tmp/mnist_model/1533576273/variables/variables\r\n\t [[Node: save_1/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT64], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_1/Const_0_0, save_1/RestoreV2/tensor_names, save_1/RestoreV2/shape_and_slices)]]\r\n```\r\n\r\nHere's the output of loading the model in Java:\r\n```sh\r\n$ javac -cp libtensorflow-1.9.0.jar Load.java\r\n$ java -cp libtensorflow-1.9.0.jar:. -Djava.library.path=./jni Load\r\n2018-08-06 14:56:48.242783: I tensorflow/cc/saved_model/loader.cc:242] Loading SavedModel with tags: { serve }; from: ./tmp/mnist_model/1533576273/\r\n2018-08-06 14:56:48.244329: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.2 AVX AVX2 FMA\r\n2018-08-06 14:56:48.246854: I tensorflow/cc/saved_model/loader.cc:161] Restoring SavedModel bundle.\r\n2018-08-06 14:56:48.246888: I tensorflow/cc/saved_model/loader.cc:171] The specified SavedModel has no variables; no checkpoints were restored.\r\n2018-08-06 14:56:48.246894: I tensorflow/cc/saved_model/loader.cc:196] Running LegacyInitOp on SavedModel bundle.\r\n2018-08-06 14:56:48.250752: I tensorflow/cc/saved_model/loader.cc:291] SavedModel load for tags { serve }; Status: success. Took 8012 microseconds.\r\n```", "comments": ["Thanks for the detailed report and the debugging @priyankjain.\r\n\r\n@karmel : If I may summarize, there is a discrepancy between the Python and [C++](https://github.com/tensorflow/tensorflow/blob/4aa639c0cbb47f4707f735e0cc80f4c39506d928/tensorflow/cc/saved_model/loader.cc#L171) implementations of loading a saved model where the former raises an exception on a missing `variables.index` file and the latter doesn't. Though, admittedly this can only happen if someone explicitly removed the `variables.index` file from the saved model directory.\r\n", "@christisg -- we can add the corresponding validation of variables.index in C++, but is that okay from the serving side? Are there reasons to avoid checking?", "It's not acceptable to crash serving because of a missing variables.index file for one of the models.\r\nWould it make sense to make the Python implementation consistent with C++? i.e. can we reconsider throwing exception in this case?\r\n@chrisolston for additional perspective.", "+1 on not crashing the server if the variables.index file is absent. SGTM to throw an exception instead. Thanks @karmel !", "As I understand the outlined solutions: One is to change the Python implementation to match C++ logic (proposed by @christisg). Second is to modify the C++ implementation to add the check (proposed by @karmel). Solution 1 will not throw an exception. Solution 2 will always throw an exception. The plan is to go ahead with solution 2? \r\n\r\nCould you confirm whether my understanding is correct? Not sure what the \"crashing the server\" terminology is in this context, is it related to tensorflow serving or simply graceful handling of exception instead of failing the program?", "I just want to make sure the C++ \"check\" throws a tensorflow::Status error, rather than crashing the program. That's all. (I think the confusion may stem from the fact that inside Google the term \"check\" is often used to mean crash, for reasons having to do with some APIs we have internally.)", "Got you, thanks Chris!", "Checking in to see if there was any progress on this? Thanks!", "Bump, wondering whether you got a chance to look into this.", "Sorry, we have not had the time to look into this yet. Would you be interested in contributing a PR?", "Yes, I can contribute a PR. It should be around two weeks before I start working on it, feel free to assign this issue to me.", "Great, thanks!", "Bump,\r\nWhat is the current status on this regarding TF2? I see that model loading of TF 1.xx serialized models in TF2 allows this.", "Hi There,\n\n We are checking to see if you still need help on this issue, as you are using an older version of tensorflow(1.x) which is officially considered as end of life. We recommend that you upgrade to 2.4 or later version and let us know if the issue still persists in newer versions. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, Please open a new issue for any help you need against 2.x, and we will get you the right help. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/21417\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/21417\">No</a>\n"]}, {"number": 21416, "title": "Android: Compiling ops yields \"THIS_TYPE_IS_NOT_SUPPORTED\" for cwise_op", "body": "Using TF 1.9.0, I cannot build applications for Android due to errors from `cwise_op`. \r\n\r\nBuilding for ARM v8, the error is `THIS_TYPE_IS_NOT_SUPPORTED`:\r\n```In file included from tensorflow/core/kernels/cwise_op_lgamma.cc:16:\r\nIn file included from ./tensorflow/core/kernels/cwise_ops_common.h:29:\r\nIn file included from ./tensorflow/core/kernels/cwise_ops.h:23:\r\nIn file included from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1:\r\nIn file included from external/eigen_archive/unsupported/Eigen/CXX11/Tensor:31:\r\nIn file included from external/eigen_archive/unsupported/Eigen/CXX11/../SpecialFunctions:50:\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/../src/SpecialFunctions/SpecialFunctionsImpl.h:177:5: error: static_assert failed \"THIS_TYPE_IS_NOT_SUPPORTED\"\r\n    EIGEN_STATIC_ASSERT((internal::is_same<Scalar, Scalar>::value == false),\r\n```\r\n\r\nFor ARM v7, the error is `no matching function for call to 'acosh'`:\r\n```In file included from tensorflow/core/kernels/cwise_op_acosh.cc:16:\r\nIn file included from ./tensorflow/core/kernels/cwise_ops_common.h:29:\r\n./tensorflow/core/kernels/cwise_ops.h:55:12: error: no matching function for call to 'acosh'\r\n    return std::acosh(a);\r\n           ^~~~~~~~~~\r\n```\r\n\r\nThe exact bazel command is quite simple and is provided below.\r\n\r\nThis is an isolated issue which crops up when trying to build a larger target (which depends on the cwise kernels). I can provide additional information about the larger target, but the error is the same and boils down to being unable to compile cwise_ops. The same error also occurred on TF 1.8.0.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No (failure occurs when compiling TF target)\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: N/A\r\n- **TensorFlow installed from (source or binary)**: Source\r\n- **TensorFlow version (use command below)**: 1.9 (git tag v1.9.0)\r\n- **Python version**: (3.5)\r\n- **Bazel version (if compiling from source)**: 0.15.2\r\n- **GCC/Compiler version (if compiling from source)**: Android NDK r16b\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**:\r\n\r\n```\r\n# For ARM v8\r\nbazel \\\r\n  --crosstool_top=//external:android/crosstool \\\r\n  --host_crosstool_top=@bazel_tools//tools/cpp:toolchain \\\r\n  --config=android \\\r\n  --cpu=arm64-v8a \\\r\n  --fat_apk_cpu=arm64-v8a \\\r\n  --verbose_failures \\\r\n  --cxxopt=-std=c++11 \\\r\n  --copt=-D__ANDROID_TYPES_SLIM__ \\\r\n  --copt=-DIS_MOBILE_PLATFORM \\\r\n  //tensorflow/core/kernels:cwise_op\r\n\r\n# For ARM v7\r\nbazel \\\r\n  --crosstool_top=//external:android/crosstool \\\r\n  --host_crosstool_top=@bazel_tools//tools/cpp:toolchain \\\r\n  --config=android \\\r\n  --cpu=armeabi-v7a \\\r\n  --fat_apk_cpu=armeabi-v7a \\\r\n  --verbose_failures \\\r\n  --cxxopt=-std=c++11 \\\r\n  --copt=-D__ANDROID_TYPES_SLIM__ \\\r\n  --copt=-DIS_MOBILE_PLATFORM \\\r\n  //tensorflow/core/kernels:cwise_op\r\n```\r\n", "comments": ["Additionally, I have confirmed that the same behaviour is present on current `master` (`1282e2b6fbb5f3ce9745402922a84291786ec62d`).", "Updates: Changing the NDK to `r17b` seems to fix this problem. Tested on `master` and tag `v1.9.0` with both the ARM v7 and ARM v8 versions of the command.\r\n\r\nThat said, when using NDK `r17b`, I get the following message from `bazel`:\r\n\r\n```\r\nThe major revision of the Android NDK referenced by android_ndk_repository rule 'androidndk' is 17. \r\nThe major revisions supported by Bazel are [10, 11, 12, 13, 14, 15, 16]. \r\nBazel will attempt to treat the NDK as if it was r16. \r\nThis may cause compilation and linkage problems. \r\nPlease download a supported NDK version.\r\n```\r\n\r\nIs this warning message out of date? Does TensorFlow for Android now expect/depend upon r17b to function?", "@petewarden : Is this your issue, or an eigen issue?", "@poxvoculi which NDK version are support by now, both bazel and makefile", "We're now deprecating mainline TensorFlow Android builds in favor of TensorFlow Lite, so closing this as unlikely to get fixed.", "@peterwarden.. so if i need full libtensorflow_cc.so for android which will be last tag ..most of the time model is not comoatible for tensorflow lite so what should be done?"]}, {"number": 21415, "title": "tensorflow ScipyOptimizerInterface feeding error ", "body": "-----------------------\r\nMy code are as follow:\r\n```\r\np_f = tf.get_variable('p_f', shape=(1, 1)) #corresponding index 0 in \r\n\r\nW1_1 = tf.constant(paras[0], dtype=tf.float32, name='W1_1' )\r\nW1_2_1 = tf.constant(paras[1][0, :], dtype=tf.float32, shape=[1, 79], name='W1_2_1')\r\nW1_2_2 = tf.constant(paras[1][1:, :], dtype=tf.float32, name='W1_2_2')\r\nb1 = tf.constant(paras[2], dtype=tf.float32, name='b1' )\r\nW2_1_1 = tf.constant(paras[3][0, :], dtype=tf.float32, shape=[1, 1], name='W1_2_1')\r\nW2_1_2 = tf.constant(paras[3][1:, :], dtype=tf.float32, name='W1_2_2')\r\nW2_2 = tf.constant(paras[4], dtype=tf.float32, name='W2_2' )\r\nb2 = tf.constant(paras[5], dtype=tf.float32, name='b2' )\r\n\r\np_sub =  tf.placeholder(shape=(None, 18), dtype=tf.float32 , name=\"p_sub\")\r\np_t =  tf.placeholder(shape=(None, 60), dtype=tf.float32, name= 'p_t') #the other part except for the price\r\n\r\nD = tf.matmul(tf.nn.sigmoid(tf.matmul(p_f, W1_2_1)+ tf.matmul(p_t, W1_2_2) + tf.matmul(p_sub, W1_1)+b1), W2_2)+tf.matmul(p_f, W2_1_1)+ tf.matmul(p_t, W2_1_2)+b2\r\n    \r\np_loss = tf.reduce_mean(-p_f*D) #self defined loss\r\n\r\n###parameters\r\nlearning_rate = 0.5\r\noptimizer = tf.contrib.opt.ScipyOptimizerInterface(p_loss, method='L-BFGS-B', options={'maxiter': 1000})\r\n\r\nwith tf.Session() as sess:\r\n    init = tf.global_variables_initializer()\r\n    for step in range(419):\r\n        #parameters \r\n        x1_train = tv_train.iloc[step*batch_size:step*batch_size+batch_size, 66:84].values \r\n        x1_test = tv_test.iloc[:, 66:84].values\r\n        x2_train = np.concatenate((tv_train.iloc[step*batch_size:step*batch_size+batch_size, 4:11].values, tv_train.iloc[step*batch_size:step*batch_size+batch_size, 14:67].values), 1) \r\n        #x2_train = tf.concat(axis=1, values=[tv_train.iloc[step*batch_size:step*batch_size+batch_size, 4:11].values, tv_train.iloc[step*batch_size:step*batch_size+batch_size, 14:67].values])\r\n        x2_test = np.concatenate((tv_test.iloc[:, 4:11].values, tv_test.iloc[:, 14:67].values), 1) \r\n        \r\n        sess.run(init, feed_dict={p_sub: x1_train, \r\n                                  p_t: x2_train})\r\n        optimizer.minimize(sess) \r\n        ret=sess.run(p_f)\r\n        \r\n        if step % 200 == 0:\r\n            print()\r\n            print(ret)\r\n            print()\r\n```\r\n```\r\n----------------------------------------------------\r\nInvalidArgumentError                      Traceback (most recent call last)\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py in _do_call(self, fn, *args)\r\n   1349     try:\r\n-> 1350       return fn(*args)\r\n   1351     except errors.OpError as e:\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py in _run_fn(session, feed_dict, fetch_list, target_list, options, run_metadata)\r\n   1328                                    feed_dict, fetch_list, target_list,\r\n-> 1329                                    status, run_metadata)\r\n   1330 \r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py in __exit__(self, type_arg, value_arg, traceback_arg)\r\n    472             compat.as_text(c_api.TF_Message(self.status.status)),\r\n--> 473             c_api.TF_GetCode(self.status.status))\r\n    474     # Delete the underlying status object from memory otherwise it stays alive\r\n\r\nInvalidArgumentError: You must feed a value for placeholder tensor 'p_sub' with dtype float and shape [?,18]\r\n\t [[Node: p_sub = Placeholder[dtype=DT_FLOAT, shape=[?,18], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n<ipython-input-67-986c52132edf> in <module>()\r\n     39         sess.run(init, feed_dict={p_sub: x1_train, \r\n     40                                   p_t: x2_train})\r\n---> 41         optimizer.minimize(sess)\r\n     42         ret=sess.run(p_f)\r\n     43 \r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\opt\\python\\training\\external_optimizer.py in minimize(self, session, feed_dict, fetches, step_callback, loss_callback, **run_kwargs)\r\n    205         packed_bounds=self._packed_bounds,\r\n    206         step_callback=step_callback,\r\n--> 207         optimizer_kwargs=self.optimizer_kwargs)\r\n    208     var_vals = [\r\n    209         packed_var_val[packing_slice] for packing_slice in self._packing_slices\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\opt\\python\\training\\external_optimizer.py in _minimize(self, initial_val, loss_grad_func, equality_funcs, equality_grad_funcs, inequality_funcs, inequality_grad_funcs, packed_bounds, step_callback, optimizer_kwargs)\r\n    404 \r\n    405     import scipy.optimize  # pylint: disable=g-import-not-at-top\r\n--> 406     result = scipy.optimize.minimize(*minimize_args, **minimize_kwargs)\r\n    407 \r\n    408     message_lines = [\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\_minimize.py in minimize(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\r\n    448     elif meth == 'l-bfgs-b':\r\n    449         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\r\n--> 450                                 callback=callback, **options)\r\n    451     elif meth == 'tnc':\r\n    452         return _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py in _minimize_lbfgsb(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\r\n    326             # until the completion of the current minimization iteration.\r\n    327             # Overwrite f and g:\r\n--> 328             f, g = func_and_grad(x)\r\n    329         elif task_str.startswith(b'NEW_X'):\r\n    330             # new iteration\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py in func_and_grad(x)\r\n    276     else:\r\n    277         def func_and_grad(x):\r\n--> 278             f = fun(x, *args)\r\n    279             g = jac(x, *args)\r\n    280             return f, g\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py in function_wrapper(*wrapper_args)\r\n    290     def function_wrapper(*wrapper_args):\r\n    291         ncalls[0] += 1\r\n--> 292         return function(*(wrapper_args + args))\r\n    293 \r\n    294     return ncalls, function_wrapper\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py in __call__(self, x, *args)\r\n     61     def __call__(self, x, *args):\r\n     62         self.x = numpy.asarray(x).copy()\r\n---> 63         fg = self.fun(x, *args)\r\n     64         self.jac = fg[1]\r\n     65         return fg[0]\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\opt\\python\\training\\external_optimizer.py in loss_grad_func_wrapper(x)\r\n    365     def loss_grad_func_wrapper(x):\r\n    366       # SciPy's L-BFGS-B Fortran implementation requires gradients as doubles.\r\n--> 367       loss, gradient = loss_grad_func(x)\r\n    368       return loss, gradient.astype('float64')\r\n    369 \r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\opt\\python\\training\\external_optimizer.py in eval_func(x)\r\n    276 \r\n    277       augmented_fetch_vals = session.run(\r\n--> 278           augmented_fetches, feed_dict=augmented_feed_dict)\r\n    279 \r\n    280       if callable(callback):\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py in run(self, fetches, feed_dict, options, run_metadata)\r\n    893     try:\r\n    894       result = self._run(None, fetches, feed_dict, options_ptr,\r\n--> 895                          run_metadata_ptr)\r\n    896       if run_metadata:\r\n    897         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)\r\n   1126     if final_fetches or final_targets or (handle and feed_dict_tensor):\r\n   1127       results = self._do_run(handle, final_targets, final_fetches,\r\n-> 1128                              feed_dict_tensor, options, run_metadata)\r\n   1129     else:\r\n   1130       results = []\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\r\n   1342     if handle is None:\r\n   1343       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\r\n-> 1344                            options, run_metadata)\r\n   1345     else:\r\n   1346       return self._do_call(_prun_fn, self._session, handle, feeds, fetches)\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py in _do_call(self, fn, *args)\r\n   1361         except KeyError:\r\n   1362           pass\r\n-> 1363       raise type(e)(node_def, op, message)\r\n   1364 \r\n   1365   def _extend_graph(self):\r\n\r\nInvalidArgumentError: You must feed a value for placeholder tensor 'p_sub' with dtype float and shape [?,18]\r\n\t [[Node: p_sub = Placeholder[dtype=DT_FLOAT, shape=[?,18], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\r\n\r\nCaused by op 'p_sub', defined at:\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\r\n    app.launch_new_instance()\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\r\n    app.start()\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\r\n    ioloop.IOLoop.instance().start()\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\r\n    super(ZMQIOLoop, self).start()\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\r\n    handler_func(fd_obj, events)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\r\n    return fn(*args, **kwargs)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\r\n    self._handle_recv()\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\r\n    self._run_callback(callback, msg)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\r\n    callback(*args, **kwargs)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\r\n    return fn(*args, **kwargs)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\r\n    return self.dispatch_shell(stream, msg)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\r\n    handler(stream, idents, msg)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\r\n    user_expressions, allow_stdin)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\r\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\r\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2717, in run_cell\r\n    interactivity=interactivity, compiler=compiler, result=result)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2821, in run_ast_nodes\r\n    if self.run_code(code, result):\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-67-986c52132edf>\", line 18, in <module>\r\n    p_sub =  tf.placeholder(shape=(None, 18), dtype=tf.float32 , name=\"p_sub\")\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 1680, in placeholder\r\n    return gen_array_ops._placeholder(dtype=dtype, shape=shape, name=name)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 4105, in _placeholder\r\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3160, in create_op\r\n    op_def=op_def)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1625, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'p_sub' with dtype float and shape [?,18]\r\n\t [[Node: p_sub = Placeholder[dtype=DT_FLOAT, shape=[?,18], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\r\n```", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "The error message:\r\n```\r\nYou must feed a value for placeholder tensor 'p_sub' with dtype float and shape [?,18]\r\n```\r\nsuggests that the value being fed to `p_sub`, i.e., the value of `x1_train` in the line:\r\n```python\r\n        sess.run(init, feed_dict={p_sub: x1_train, p_t: x2_train})\r\n```\r\nhas either the wrong type (i.e., is not a `float32`) or has an incompatible shape (i.e., is not a 2-dimensional tensor, or the size of the second dimension is not 18).\r\n\r\nYou'd want to verify that:\r\n```python\r\n        x1_train = tv_train.iloc[step*batch_size:step*batch_size+batch_size, 66:84].values \r\n```\r\nhas the right shape and type.\r\n\r\nHope that helps."]}, {"number": 21414, "title": "issue in Google LOGO...", "body": "hi there..\r\nmy wife got a meticulous problem in the official LOGO of Tensorflow.\r\n\r\nsee the logo:\r\n(https://user-images.githubusercontent.com/39337227/43732365-c2b3a27e-99c6-11e8-94dc-735a1727678e.JPG)\r\n\r\nin T of the logo, its have 4 column but in shadow its have 3 column.\r\ncorroct it.\r\n\r\nwe also accept any gift for that . \ud83e\udd47 ", "comments": ["This is funny - your wife needs to project a little more @sauronpy ", "not sure if this is a bug", "Nagging Assignee @wolffg: It has been 44 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "This is a duplicate of #1922. It comes up from time to time."]}, {"number": 21413, "title": "tensorflow-1.0.0rc0-cp27-none-linux_x86_64.whl is not a supported wheel on this platform.", "body": "\r\nI've activated tensorflow in terminal, and I'm trying to set up tensorflow fold. When I try doing this, the above error pops up\r\n`tensorflow-1.0.0rc0-cp27-none-linux_x86_64.whl is not a supported wheel on this platform.`\r\n\r\nI searched other forums and tried to resolve the issue by trying the solutions suggested, but I wasn't able to solve the problem. \r\nThanks!\r\n\r\n", "comments": ["Hi @harshita-kaushal can you please provide more information? What commands are you running? Are you running in a virtual environment? I'm guessing you're running python2. Are you directly installing a whl file or just running a pip install. If you provide more information I may be able to help.", "Sorry, yes, I'll provide more information. Thanks for the prompt response. \r\nThis is my local terminal, and the following command was the command I ran. I am running Python 2, yes. I am running a pip install as you see below as well. It seems to use a \r\n\r\n`(tensorflow)hkaushal-mac01:~ hkaushal$ sudo -H pip install  ** proxy specific part to intel that i cannot provide**-U https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-1.0.0rc0-cp27-none-linux_x86_64.whl\r\n`\r\n(This is what I am trying to do)\r\n\r\n<img width=\"1064\" alt=\"screen shot 2018-08-06 at 10 21 37 am\" src=\"https://user-images.githubusercontent.com/26784357/43731171-89dfb910-9962-11e8-8df8-3acd60b82239.png\">\r\n", "You're using a specific link which for whatever reason may not be compatible. Can you try this?\r\n\r\n```sudo -H pip install ** proxy specific part to intel that i cannot provide** -U tensorflow==1.10.0rc0```", "```\r\nCollecting tensorflow==1.10.0rc0\r\n  Downloading https://files.pythonhosted.org/packages/bf/4e/e7b7ad91063b88b180558f9f4970cb4867761218054886e38238e742c97f/tensorflow-1.10.0rc0-cp27-cp27m-macosx_10_11_x86_64.whl (55.5MB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 55.5MB 469kB/s \r\nRequirement not upgraded as not directly required: numpy>=1.13.3 in ./tensorflow/lib/python2.7/site-packages (from tensorflow==1.10.0rc0) (1.14.5)\r\nRequirement not upgraded as not directly required: mock>=2.0.0 in ./tensorflow/lib/python2.7/site-packages (from tensorflow==1.10.0rc0) (2.0.0)\r\nRequirement not upgraded as not directly required: protobuf>=3.6.0 in ./tensorflow/lib/python2.7/site-packages (from tensorflow==1.10.0rc0) (3.6.0)\r\nCollecting setuptools<=39.1.0 (from tensorflow==1.10.0rc0)\r\n  Downloading https://files.pythonhosted.org/packages/8c/10/79282747f9169f21c053c562a0baa21815a8c7879be97abd930dbcf862e8/setuptools-39.1.0-py2.py3-none-any.whl (566kB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 573kB 3.5MB/s \r\nRequirement not upgraded as not directly required: wheel in ./tensorflow/lib/python2.7/site-packages (from tensorflow==1.10.0rc0) (0.31.1)\r\nRequirement not upgraded as not directly required: astor>=0.6.0 in ./tensorflow/lib/python2.7/site-packages (from tensorflow==1.10.0rc0) (0.6.2)\r\nRequirement not upgraded as not directly required: backports.weakref>=1.0rc1 in ./tensorflow/lib/python2.7/site-packages (from tensorflow==1.10.0rc0) (1.0.post1)\r\nRequirement not upgraded as not directly required: termcolor>=1.1.0 in ./tensorflow/lib/python2.7/site-packages (from tensorflow==1.10.0rc0) (1.1.0)\r\nRequirement not upgraded as not directly required: gast>=0.2.0 in ./tensorflow/lib/python2.7/site-packages (from tensorflow==1.10.0rc0) (0.2.0)\r\nRequirement not upgraded as not directly required: grpcio>=1.8.6 in ./tensorflow/lib/python2.7/site-packages (from tensorflow==1.10.0rc0) (1.13.0)\r\nRequirement not upgraded as not directly required: six>=1.10.0 in ./tensorflow/lib/python2.7/site-packages (from tensorflow==1.10.0rc0) (1.11.0)\r\nRequirement not upgraded as not directly required: absl-py>=0.1.6 in ./tensorflow/lib/python2.7/site-packages (from tensorflow==1.10.0rc0) (0.2.2)\r\nRequirement not upgraded as not directly required: enum34>=1.1.6 in ./tensorflow/lib/python2.7/site-packages (from tensorflow==1.10.0rc0) (1.1.6)\r\nRequirement not upgraded as not directly required: tensorboard<1.9.0,>=1.8.0 in ./tensorflow/lib/python2.7/site-packages (from tensorflow==1.10.0rc0) (1.8.0)\r\nRequirement not upgraded as not directly required: pbr>=0.11 in ./tensorflow/lib/python2.7/site-packages (from mock>=2.0.0->tensorflow==1.10.0rc0) (4.0.4)\r\nRequirement not upgraded as not directly required: funcsigs>=1; python_version < \"3.3\" in ./tensorflow/lib/python2.7/site-packages (from mock>=2.0.0->tensorflow==1.10.0rc0) (1.0.2)\r\nRequirement not upgraded as not directly required: futures>=2.2.0 in ./tensorflow/lib/python2.7/site-packages (from grpcio>=1.8.6->tensorflow==1.10.0rc0) (3.2.0)\r\nRequirement not upgraded as not directly required: html5lib==0.9999999 in ./tensorflow/lib/python2.7/site-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow==1.10.0rc0) (0.9999999)\r\nRequirement not upgraded as not directly required: bleach==1.5.0 in ./tensorflow/lib/python2.7/site-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow==1.10.0rc0) (1.5.0)\r\nRequirement not upgraded as not directly required: werkzeug>=0.11.10 in ./tensorflow/lib/python2.7/site-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow==1.10.0rc0) (0.14.1)\r\nRequirement not upgraded as not directly required: markdown>=2.6.8 in ./tensorflow/lib/python2.7/site-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow==1.10.0rc0) (2.6.11)\r\nmatplotlib 1.3.1 requires nose, which is not installed.\r\nmatplotlib 1.3.1 requires tornado, which is not installed.\r\nInstalling collected packages: setuptools, tensorflow\r\n  Found existing installation: setuptools 39.2.0\r\n    Uninstalling setuptools-39.2.0:\r\n      Successfully uninstalled setuptools-39.2.0\r\n  Found existing installation: tensorflow 1.8.0\r\n    Uninstalling tensorflow-1.8.0:\r\n      Successfully uninstalled tensorflow-1.8.0\r\nSuccessfully installed setuptools-39.1.0 tensorflow-1.10.0rc0\r\nYou are using pip version 10.0.1, however version 18.0 is available.\r\nYou should consider upgrading via the 'pip install --upgrade pip' command.\r\n(tensorflow) hkaushal-mac01:~ hkaushal$ \r\n```\r\n\r\nHmm.. I think this was able to set up the tools for tensorflow, but I don't think it installed fold? Or did fold install with this? ", "```\r\n(tensorflow) hkaushal-mac01:~ hkaushal$ python -c 'import tensorflow_fold'\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\nImportError: No module named tensorflow_fold\r\n```\r\nThis is the error generated. ", "Now after tensorflow is installed try the install tensorflow_fold line again:\r\n\r\n```\r\npip install https://storage.googleapis.com/tensorflow_fold/tensorflow_fold-0.0.1-cp27-none-linux_x86_64.whl\r\n```", "The same error is generated when I run the install tensorflow_fold command:\r\n`tensorflow_fold-0.0.1-cp27-none-linux_x86_64.whl is not a supported wheel on this platform.`", "So now the error is different. Earlier the error was \"tensorflow-1.0.0rc0\" is not a supported. Unfortunately I cannot help you with tensorflow_fold issues. I suggest you file an issue [here](https://github.com/tensorflow/fold/issues). \r\n\r\nMy unofficial advice would be to try this:\r\n```\r\nwget https://storage.googleapis.com/tensorflow_fold/tensorflow_fold-0.0.1-cp27-none-linux_x86_64.whl\r\nmv tensorflow_fold-0.0.1-cp27-none-linux_x86_64.whl tensorflow_fold-0.0.1-cp27-cp27mu-manylinux1_x86_64.whl \r\npip install tensorflow_fold-0.0.1-cp27-cp27mu-manylinux1_x86_64.whl \r\n``` \r\n\r\nMy theory is that your virtualenv does not like the whl file extension."]}, {"number": 21412, "title": "Error in Distribution Strategy with train_and_evaluate", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes \r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04.4 LTS\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: No\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.10.0-rc1 and nightly\r\n- **Python version**: Python 3.5.2\r\n- **Bazel version (if compiling from source)**: No\r\n- **GCC/Compiler version (if compiling from source)**: No\r\n- **CUDA/cuDNN version**: 9.0.176\r\n- **GPU model and memory**: Tesla V100 16152MiB\r\n- **Exact command to reproduce**: Save the snippet in test.py and run \"python test.py\"\r\n\r\n\r\n### Describe the problem\r\nUsing the distribute strategy (OneDeviceStrategy) I have a crash with train_and_evaluate method of the estimator.\r\nThe code below works with train and evaluate as separeted functions, but it doesn't work with train_and_evaluate.\r\nI have attached a snipped with train, evaluate and train_and_evaluate methods togheter to gather the behaviour differences. At the end I've put the output error log.\r\nNote: it works with tensorflow 1.9.0 and codalab\r\n```\r\nfrom tensorflow import keras as ks\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow.python.estimator import keras as keras_lib\r\n\r\n\r\ntf.logging.set_verbosity(tf.logging.INFO)\r\n\r\n\r\ndef input_fn():\r\n    x = np.random.random((1024, 10))\r\n    y = np.random.randint(2, size=(1024, 1))\r\n    x = tf.cast(x, tf.float32)\r\n    dataset = tf.data.Dataset.from_tensor_slices((x, y))\r\n    dataset = dataset.repeat(100)\r\n    dataset = dataset.batch(1)\r\n    return dataset\r\n\r\n\r\nmodel = ks.Sequential()\r\nmodel.add(ks.layers.Dense(16, activation='relu', input_shape=(10,)))\r\nmodel.add(ks.layers.Dense(1, activation='sigmoid'))\r\n\r\noptimizer = tf.train.GradientDescentOptimizer(0.2)\r\n\r\nmodel.compile(loss='binary_crossentropy', optimizer=optimizer)\r\n\r\nstrategy = tf.contrib.distribute.OneDeviceStrategy(\"device:GPU:0\")\r\nconfig = tf.estimator.RunConfig(train_distribute=strategy)\r\n\r\nkeras_estimator = keras_lib.model_to_estimator(\r\n  keras_model=model,\r\n  config=config)\r\n\r\nkeras_estimator.train(input_fn=input_fn, steps=10)\r\nkeras_estimator.evaluate(input_fn=input_fn, steps=3)\r\n\r\ntrain_spec = tf.estimator.TrainSpec(\r\n    input_fn=input_fn,\r\n    max_steps=20)\r\neval_spec = tf.estimator.EvalSpec(\r\n    input_fn=input_fn,\r\n    steps=3)\r\n\r\ntf.estimator.train_and_evaluate(keras_estimator, train_spec, eval_spec)\r\n```\r\n\r\n### Source code / logs\r\n```\r\nINFO:tensorflow:Using the Keras model provided.\r\nWARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp_xh7nsci\r\nINFO:tensorflow:Using config: {'_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_keep_checkpoint_every_n_hours': 10000, '_global_id_in_cluster': 0, '_task_type': 'worker', '_session_config': None, '_is_chief': True, '_evaluation_master': '', '_log_step_count_steps': 100, '_model_dir': '/tmp/tmp_xh7nsci', '_save_checkpoints_secs': 600, '_save_summary_steps': 100, '_service': None, '_save_checkpoints_steps': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9a715b1240>, '_device_fn': None, '_keep_checkpoint_max': 5, '_num_worker_replicas': 1, '_train_distribute': <tensorflow.contrib.distribute.python.one_device_strategy.OneDeviceStrategy object at 0x7f9a630426d8>}\r\n2018-08-06 11:45:02.557498: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2018-08-06 11:45:02.679737: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:897] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2018-08-06 11:45:02.680248: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1404] Found device 0 with properties: \r\nname: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\r\npciBusID: 0000:00:1e.0\r\ntotalMemory: 15.77GiB freeMemory: 15.36GiB\r\n2018-08-06 11:45:02.680294: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1483] Adding visible gpu devices: 0\r\n2018-08-06 11:45:03.032268: I tensorflow/core/common_runtime/gpu/gpu_device.cc:964] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-08-06 11:45:03.032321: I tensorflow/core/common_runtime/gpu/gpu_device.cc:970]      0 \r\n2018-08-06 11:45:03.032339: I tensorflow/core/common_runtime/gpu/gpu_device.cc:983] 0:   N \r\n2018-08-06 11:45:03.032678: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14856 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:1e.0, compute capability: 7.0)\r\n2018-08-06 11:45:03.032984: E tensorflow/core/common_runtime/gpu/gpu_device.cc:228] Illegal GPUOptions.experimental.num_dev_to_dev_copy_streams=0 set to 1 instead.\r\n2018-08-06 11:45:03.353069: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1483] Adding visible gpu devices: 0\r\n2018-08-06 11:45:03.353135: I tensorflow/core/common_runtime/gpu/gpu_device.cc:964] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-08-06 11:45:03.353154: I tensorflow/core/common_runtime/gpu/gpu_device.cc:970]      0 \r\n2018-08-06 11:45:03.353162: I tensorflow/core/common_runtime/gpu/gpu_device.cc:983] 0:   N \r\n2018-08-06 11:45:03.353297: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14856 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:1e.0, compute capability: 7.0)\r\nINFO:tensorflow:Calling model_fn.\r\nINFO:tensorflow:Done calling model_fn.\r\nINFO:tensorflow:Create CheckpointSaverHook.\r\nINFO:tensorflow:Graph was finalized.\r\n2018-08-06 11:45:04.042046: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1483] Adding visible gpu devices: 0\r\n2018-08-06 11:45:04.042111: I tensorflow/core/common_runtime/gpu/gpu_device.cc:964] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-08-06 11:45:04.042128: I tensorflow/core/common_runtime/gpu/gpu_device.cc:970]      0 \r\n2018-08-06 11:45:04.042148: I tensorflow/core/common_runtime/gpu/gpu_device.cc:983] 0:   N \r\n2018-08-06 11:45:04.042305: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14856 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:1e.0, compute capability: 7.0)\r\nINFO:tensorflow:Restoring parameters from /tmp/tmp_xh7nsci/keras_model.ckpt\r\nINFO:tensorflow:Running local_init_op.\r\nINFO:tensorflow:Done running local_init_op.\r\nINFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp_xh7nsci/model.ckpt.\r\nINFO:tensorflow:loss = 0.6695193, step = 0\r\nINFO:tensorflow:Saving checkpoints for 10 into /tmp/tmp_xh7nsci/model.ckpt.\r\nINFO:tensorflow:Loss for final step: 0.3536753.\r\nINFO:tensorflow:Calling model_fn.\r\nINFO:tensorflow:Done calling model_fn.\r\nINFO:tensorflow:Starting evaluation at 2018-08-06-11:45:04\r\nINFO:tensorflow:Graph was finalized.\r\n2018-08-06 11:45:04.822515: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1483] Adding visible gpu devices: 0\r\n2018-08-06 11:45:04.822570: I tensorflow/core/common_runtime/gpu/gpu_device.cc:964] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-08-06 11:45:04.822594: I tensorflow/core/common_runtime/gpu/gpu_device.cc:970]      0 \r\n2018-08-06 11:45:04.822613: I tensorflow/core/common_runtime/gpu/gpu_device.cc:983] 0:   N \r\n2018-08-06 11:45:04.822780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14856 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:1e.0, compute capability: 7.0)\r\nINFO:tensorflow:Restoring parameters from /tmp/tmp_xh7nsci/model.ckpt-10\r\nINFO:tensorflow:Running local_init_op.\r\nINFO:tensorflow:Done running local_init_op.\r\nINFO:tensorflow:Evaluation [1/3]\r\nINFO:tensorflow:Evaluation [2/3]\r\nINFO:tensorflow:Evaluation [3/3]\r\nINFO:tensorflow:Finished evaluation at 2018-08-06-11:45:04\r\nINFO:tensorflow:Saving dict for global step 10: global_step = 10, loss = 0.1408012\r\nINFO:tensorflow:Saving 'checkpoint_path' summary for global step 10: /tmp/tmp_xh7nsci/model.ckpt-10\r\nINFO:tensorflow:Running training and evaluation locally (non-distributed).\r\nINFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\r\nINFO:tensorflow:Calling model_fn.\r\nINFO:tensorflow:Done calling model_fn.\r\nINFO:tensorflow:Create CheckpointSaverHook.\r\nINFO:tensorflow:Graph was finalized.\r\n2018-08-06 11:45:05.220540: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1483] Adding visible gpu devices: 0\r\n2018-08-06 11:45:05.220581: I tensorflow/core/common_runtime/gpu/gpu_device.cc:964] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-08-06 11:45:05.220600: I tensorflow/core/common_runtime/gpu/gpu_device.cc:970]      0 \r\n2018-08-06 11:45:05.220615: I tensorflow/core/common_runtime/gpu/gpu_device.cc:983] 0:   N \r\n2018-08-06 11:45:05.220760: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14856 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:1e.0, compute capability: 7.0)\r\nINFO:tensorflow:Restoring parameters from /tmp/tmp_xh7nsci/model.ckpt-10\r\nINFO:tensorflow:Running local_init_op.\r\nINFO:tensorflow:Done running local_init_op.\r\nINFO:tensorflow:Saving checkpoints for 10 into /tmp/tmp_xh7nsci/model.ckpt.\r\nINFO:tensorflow:loss = 1.5840994, step = 10\r\nINFO:tensorflow:Saving checkpoints for 20 into /tmp/tmp_xh7nsci/model.ckpt.\r\nINFO:tensorflow:Calling model_fn.\r\nINFO:tensorflow:Done calling model_fn.\r\nTraceback (most recent call last):\r\n  File \"test2.py\", line 45, in <module>\r\n    tf.estimator.train_and_evaluate(keras_estimator, train_spec, eval_spec)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/training.py\", line 451, in train_and_evaluate\r\n    return executor.run()\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/training.py\", line 590, in run\r\n    return self.run_local()\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/training.py\", line 691, in run_local\r\n    saving_listeners=saving_listeners)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py\", line 376, in train\r\n    loss = self._train_model(input_fn, hooks, saving_listeners)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py\", line 1143, in _train_model\r\n    return self._train_model_distributed(input_fn, hooks, saving_listeners)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py\", line 1368, in _train_model_distributed\r\n    saving_listeners)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py\", line 1451, in _train_with_estimator_spec\r\n    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 695, in __exit__\r\n    self._close_internal(exception_type)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 727, in _close_internal\r\n    h.end(self._coordinated_creator.tf_sess)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 470, in end\r\n    self._save(session, last_step)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 489, in _save\r\n    if l.after_save(session, step):\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/training.py\", line 497, in after_save\r\n    self._evaluate(global_step_value)  # updates self.eval_result\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/training.py\", line 517, in _evaluate\r\n    self._evaluator.evaluate_and_export())\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/training.py\", line 884, in evaluate_and_export\r\n    hooks=self._eval_spec.hooks)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py\", line 463, in evaluate\r\n    input_fn, hooks, checkpoint_path)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py\", line 1474, in _evaluate_build_graph\r\n    model_fn_lib.LOSS_METRIC_KEY] = metrics_lib.mean(estimator_spec.loss)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/metrics_impl.py\", line 376, in mean\r\n    mean_t = distribute_lib.get_tower_context().merge_call(\r\nAttributeError: 'NoneType' object has no attribute 'merge_call'\r\n\r\n```\r\n", "comments": ["probably related to https://github.com/tensorflow/tensorflow/issues/21180", "@guptapriya: could you take a look. ", "yes, I looked into this briefly sometime ago, will be working on it soon. Duplicate of this issue: https://github.com/tensorflow/tensorflow/issues/21180", "This should be fixed in master now"]}, {"number": 21411, "title": "Tensorflow does not recognize GPU ", "body": "\r\nOS: Ubuntu 18.04.1 LTS\r\nTensorflow: 1.9.0 \r\nTensorflow- GPU: 1.9.0\r\nBoth installed from pip/pip3\r\n\r\nGraphics Card: GeForce GTX 1080 TI \r\nNvidia SMI Driver Version: 390.77\r\nPython: 2.7.15, 3.6.5 \r\nCUDA Toolkit:  9.0, V9.0.176 ( I also have 8 installed) \r\nCuDNN: \r\n![asfd](https://user-images.githubusercontent.com/22109013/43723326-5e2d6d0a-9965-11e8-9362-e5ff24c99e4f.png)\r\n\r\nRunning this: \r\n![screenshot from 2018-08-06 10-34-04](https://user-images.githubusercontent.com/22109013/43722870-4de50daa-9964-11e8-9648-050d643e0d16.png)\r\n\r\nI get the following errors/CPU only: \r\n![screenshot from 2018-08-06 10-33-35](https://user-images.githubusercontent.com/22109013/43722894-5ad5ef02-9964-11e8-9b17-721294c7e15d.png)\r\n\r\n\r\nI need to be able to access/run models off the GPU and am struggling to debug this issue alone. This seems to be a common problem, any help would be appreciated! ", "comments": ["hi\r\ni got same problem and after 4 days i finally fixed it.\r\n\r\ni installed any update that available and tried any solution in the internet.\r\n\r\ni've found the solution me myself after 4 days :)))\r\n\r\nunfortunately the Linux system dont recognize your second graphic cart (usually NVIDIA cards) until your system BIOS is UEFI.\r\nyou must change it to Legacy support  and reinstall ubuntu.\r\nafter reinstall that you need to update your graphic cart in additional driver to active it.\r\n\r\ncheers. ", "Thanks for your response! \r\n\r\nMy system BIOS has actually always been UEFI. \r\nMy system recognizes the cards, and uses them for display settings and such ( as far as what I can tell from the  NVIDIA X Server Settings ) \r\n\r\n", "so you need to update your driver in additional driver\n\nOn Mon, Aug 6, 2018, 23:30 Ahson Saiyed <notifications@github.com> wrote:\n\n> Thanks for your response!\n>\n> My system BIOS has actually always been UEFI.\n> My system recognizes the cards, and uses them for display settings and\n> such ( as far as what I can tell from the NVIDIA X Server Settings )\n>\n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/21411#issuecomment-410815870>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/Alg9Cxl2kH9NfAZYANS7AC2pk8zyAfsZks5uOJJggaJpZM4Vwhdt>\n> .\n>\n", "Do you mean the Nvidia driver for the graphics card? ", "Sorry not sure what you mean exactly by additional driver", "try this link :  \r\n\r\nhttps://askubuntu.com/questions/47506/how-do-i-install-additional-drivers", "I hope this will help you", "Yall need to take this to stack overflow this is for bugs/feature requests only.", "Fixed! It was a problem with python packages. Should I delete this issue? @gragundier ", "Closing it is just fine.  "]}, {"number": 21410, "title": "Memory leak with tf.py_func", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes, see below\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: v1.9.0-rc2-1738-ge70f94e 1.10.0-rc1\r\n- **Python version**: 3.5\r\n- **Bazel version (if compiling from source)**: 0.16.0\r\n- **GCC/Compiler version (if compiling from source)**: 5.4.0\r\n- **CUDA/cuDNN version**: 9.2 / 7\r\n- **GPU model and memory**: Nvidia 1080Ti, 11 GB\r\n- **Exact command to reproduce**: ./leak.py (see attached file)\r\n\r\n### Describe the problem\r\nThe attached script uses more and more CPU memory in each iteration until it runs out of memory. It does not do anything useful but it is a small test case to demonstrate the problem.", "comments": ["leak.py:\r\n```\r\n#!/usr/bin/env python3\r\n\r\nimport numpy as np\r\n\r\nimport tensorflow as tf\r\n\r\nwith tf.Graph().as_default():\r\n    config = tf.ConfigProto()\r\n    config.allow_soft_placement = True\r\n    session = tf.Session(config=config)\r\n\r\n    width = 2048\r\n    height = 1024\r\n    batch = 1\r\n    cls = 200\r\n    elems = batch * height * width\r\n\r\n    with tf.device('/gpu:0'):\r\n        x = tf.random_uniform([batch, height, width, 3], minval=0.0, maxval=200.0)\r\n        conv = tf.keras.layers.Conv2D(cls, [3, 3], padding='same')\r\n        x = conv(x)\r\n        x = tf.reshape(x, [-1, cls])\r\n\r\n        y = tf.random_uniform([], minval=0, maxval=cls, dtype=tf.int32)\r\n        def fn(y):\r\n            res = np.zeros([elems, cls], dtype=np.int32)\r\n            res[y] = 1\r\n            return res\r\n        y = tf.py_func(fn, [y], tf.int32)\r\n\r\n        z = tf.random_uniform([elems], minval=0, maxval=2, dtype=tf.int32)\r\n\r\n        mask = tf.not_equal(z, tf.constant(1))\r\n        x = tf.boolean_mask(x, mask)\r\n        y = tf.boolean_mask(y, mask)\r\n        y = tf.stop_gradient(y)\r\n\r\n        logits = tf.stack([-x, x], axis=-1)\r\n        labels = tf.stack([1 - y, y], axis=-1)\r\n        loss = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=labels)\r\n        loss = tf.reduce_sum(loss)\r\n\r\n        train_op = tf.train.AdamOptimizer().minimize(loss)\r\n\r\n    # Initialize global variables\r\n    session.run(tf.global_variables_initializer())\r\n\r\n    i = 0\r\n    while True:\r\n        i += 1\r\n        print(\"Iteration %d\" % i)\r\n        session.run(train_op)\r\n```", "I forgot to mention that this seems to only be an issue if it runs on the GPU.\r\nAlso setting TF_CPU_ALLOCATOR_USE_BFC seems to help.", "It seems that the code just allocates and deallocates a lot of memory - maybe because the size of the masked tensor changes all the time.\r\n\r\nThe allocated tensors are quite large but when the pool of the PoolAllocator cannot find a matching chunk it allocates a new one. Since the pool size is only tracked in the number of entries instead of the allocated memory size, the eviction code will only be triggered when the count limit (initially 100) is reached. At this point there are already a lot of unused huge chunks in the pool.\r\n\r\nMaybe PoolAllocator should track the number of bytes in use and try to free huge chunks early if it contains a lot of them?\r\n\r\nAnother problem that I saw with the code is that there is a hardcoded eviction rate limit in PoolAllocator. If the eviction rate is high, PoolAllocator does not release the memory but just keeps growing the pool size.\r\nThis seems useful for performance reasons to some degree, but probably the pool size should have a hard limit since the amount of memory is not unlimited?\r\nMaybe a good idea would be to ignore the eviction rate once e. g. more than 80% of the system memory is in use. What do you think?", "@zheng-xq  can you please take a look? Thanks.\r\n", "I meet similar question, under watching.", "Nagging Assignee @ymodak: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Does this still happen under nightly?", "I can't reproduce the problem with the current nightly build. However, the code in PoolAllocator was not touched and still has the problems I described. So I assume that either another allocator is used by default now or that the allocation pattern with my test case changed.", "PoolAllocator is probably not the source of the memory leak. There were a\nfew issues with py_func fixed since then, and one of those might have made\nyour leak go away.\n\nOn Sat, Oct 13, 2018 at 2:02 AM Niels Ole Salscheider <\nnotifications@github.com> wrote:\n\n> I can't reproduce the problem with the current nightly build. However, the\n> code in PoolAllocator was not touched and still has the problems I\n> described. So I assume that either another allocator is used by default now\n> or that the allocation pattern with my test case changed.\n>\n> \u2014\n> You are receiving this because you were assigned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/21410#issuecomment-429523800>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAATxQpuOLWcYibQyrRDVn0xsx2XYhbjks5ukawpgaJpZM4VwdDU>\n> .\n>\n\n\n-- \n - Alex\n", "So I'm closing this issue; please reopen if you can reproduce at master."]}, {"number": 21408, "title": "The installation procedure for Ubuntu does not work.", "body": "I tried to follow the procedure for installing on Ubuntu 16.04 or later.\r\nI am using Ubuntu 16.04 with the latest updates on 64-bit AMD/Intel.\r\nI am using Python 3, version 3.5.2. I checked the version of pip3, it is 8.1.1\r\nThe step of the procedure which fails is:\r\nvirtualenv --system-site-packages -p python3 venv\r\n\r\nand the error messages are as follows:\r\nAlready using interpreter /usr/bin/python3\r\nUsing base prefix '/usr'\r\nNew python executable in /home/nick/tensorflow/venv/bin/python3\r\nAlso creating executable in /home/nick/tensorflow/venv/bin/python\r\nInstalling setuptools, pkg_resources, pip, wheel...\r\n  Complete output from command /home/nick/tensorflow/venv/bin/python3 - setuptools pkg_resources pip wheel:\r\n  Collecting setuptools\r\nException:\r\nTraceback (most recent call last):\r\n  File \"/home/nick/tensorflow/venv/share/python-wheels/urllib3-1.13.1-py2.py3-none-any.whl/urllib3/connectionpool.py\", line 560, in urlopen\r\n    body=body, headers=headers)\r\n  File \"/home/nick/tensorflow/venv/share/python-wheels/urllib3-1.13.1-py2.py3-none-any.whl/urllib3/connectionpool.py\", line 346, in _make_request\r\n    self._validate_conn(conn)\r\n  File \"/home/nick/tensorflow/venv/share/python-wheels/urllib3-1.13.1-py2.py3-none-any.whl/urllib3/connectionpool.py\", line 787, in _validate_conn\r\n    conn.connect()\r\n  File \"/home/nick/tensorflow/venv/share/python-wheels/urllib3-1.13.1-py2.py3-none-any.whl/urllib3/connection.py\", line 252, in connect\r\n    ssl_version=resolved_ssl_version)\r\n  File \"/home/nick/tensorflow/venv/share/python-wheels/urllib3-1.13.1-py2.py3-none-any.whl/urllib3/util/ssl_.py\", line 305, in ssl_wrap_socket\r\n    return context.wrap_socket(sock, server_hostname=server_hostname)\r\n  File \"/usr/lib/python3.5/ssl.py\", line 377, in wrap_socket\r\n    _context=self)\r\n  File \"/usr/lib/python3.5/ssl.py\", line 752, in __init__\r\n    self.do_handshake()\r\n  File \"/usr/lib/python3.5/ssl.py\", line 988, in do_handshake\r\n    self._sslobj.do_handshake()\r\n  File \"/usr/lib/python3.5/ssl.py\", line 633, in do_handshake\r\n    self._sslobj.do_handshake()\r\nConnectionResetError: [Errno 104] Connection reset by peer\r\n", "comments": ["Hi @rogermorgan unfortunately this seems to be a virtualenv with python3 issue you're hitting as opposed to a TensorFlow issue. Unfortunately it's not easily reproducible since it most like is an issue with the machine you're running on. I recommend maybe asking on StackOverFlow if any other users have seen this. Maybe you're hitting [this](https://stackoverflow.com/questions/15954467/python-ssl-example-from-docs-gives-connection-reset-by-peer-error)?"]}, {"number": 21407, "title": "Error installing tensorflow from source", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS High Sierra 10.13.6\r\n- **TensorFlow installed from (source or binary)**: Source with CPU-only support\r\n- **TensorFlow version (use command below)**: b'v1.9.0-rc2-1183-g1b33df1814' 1.9.0\r\n- **Python version**: 3.6.6\r\n- **Bazel version (if compiling from source)**: 0.15.2\r\n- **GCC/Compiler version (if compiling from source)**: gcc version 7.3.0 (MacPorts gcc7 7.3.0_1)\r\n- **CUDA/cuDNN version:** N/A\r\n- **GPU model and memory:** N/A\r\n- **Mobile device:** N/A\r\n- **Exact command to reproduce**: \r\n`bazel build --config=opt --cxxopt=\"-D_GLIBCXX_USE_CXX11_ABI=0\" --verbose_failures //tensorflow/tools/pip_package:build_pip_package`\r\n\r\n(I used the flag `--cxxopt=\"-D_GLIBCXX_USE_CXX11_ABI=0\"` as suggested at https://www.tensorflow.org/install/install_sources; removing this flag leads to the same error)\r\n\r\n### Describe the problem\r\nThe above command yields an error related to gcc (the complete log file is attached):\r\n`ERROR: /private/var/tmp/_bazel_ptighin/1e40e60bad53a8010892ea7aefd4f97f/external/protobuf_archive/BUILD:260:1: Linking of rule '@protobuf_archive//:js_embed' failed (Exit 1): cc_wrapper.sh failed: error executing command\r\n  (cd /private/var/tmp/_bazel_ptighin/1e40e60bad53a8010892ea7aefd4f97f/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    APPLE_SDK_PLATFORM='' \\\r\n    APPLE_SDK_VERSION_OVERRIDE='' \\\r\n    PATH=/Users/ptighin/bin:opt/local/libexec/gnubin:/opt/local/bin:/opt/local/sbin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Library/TeX/texbin:/opt/local/libexec/gnubin:/opt/local/bin:/opt/local/sbin \\\r\n    XCODE_VERSION_OVERRIDE=9.4.1 \\\r\n  external/local_config_cc/cc_wrapper.sh -fobjc-link-runtime -Wl,-S -o bazel-out/host/bin/external/protobuf_archive/js_embed bazel-out/host/bin/external/protobuf_archive/_objs/js_embed/external/protobuf_archive/src/google/protobuf/compiler/js/embed.o -headerpad_max_install_names -lc++ -no-canonical-prefixes)\r\ngcc: error: unrecognized command line option '-fobjc-link-runtime'; did you mean '-fgnu-runtime'?\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 117.328s, Critical Path: 28.23s\r\nINFO: 63 processes: 63 local.\r\nFAILED: Build did NOT complete successfully`\r\n\r\n### Source code / logs\r\n[logs.txt](https://github.com/tensorflow/tensorflow/files/2262594/logs.txt)\r\n\r\n### Temporary solution that worked for me\r\nGo to `/private/var/tmp/_bazel_<YOUR_USERNAME>/<HASH>/execroot/org_tensorflow/external/local_config_cc/cc_wrapper.sh`  (`<YOUR_USERNAME>` and `<HASH>` can be found in the error message) and change line 56\r\n`/opt/local/bin/gcc \"$@\"` (or wherever your C++ compiler is)\r\nto\r\n`/opt/local/bin/clang \"$@\"` (or wherever your clang compiler is)\r\n\r\nThe problem seems to be that the wrapper of the C++-compiler points to gcc but passes clang-type flags.", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nCUDA/cuDNN version\nGPU model and memory\nMobile device", "@tensorflowbutler , done! They are indeed not relevant, which is why I left them out in the first place.", "@meteorcloudy @damienmg this looks like a bazel mac configuration error? ", "/cc @mhlopko Do you have any idea on this?", "Does it still fail after runnning `bazel clean --expunge` and `./configure`?", "@mhlopko Yes it does.", "I assume you have Xcode installed? Does it still fail when you run `BAZEL_USE_CPP_ONLY_TOOLCHAIN=1 bazel build //foo`?", "@mhlopko Yes, it does fail but in this case I get a different error, see enclosed (I made sure to run `bazel clean --expunge` before running `./configure` and `BAZEL_USE_CPP_ONLY_TOOLCHAIN=1 bazel build --config=opt --cxxopt=\"-D_GLIBCXX_USE_CXX11_ABI=0\" --verbose_failures //tensorflow/tools/pip_package:build_pip_package`). And yes, I do have Xcode installed.\r\n\r\n[logs.txt](https://github.com/tensorflow/tensorflow/files/2335827/logs.txt)\r\n\r\n\r\n", "@mhlopko Update: I am not sure whether the flag `--cxxopt=\"-D_GLIBCXX_USE_CXX11_ABI=0\"` is still relevant for the case when only the c++ compiler is invoked so I also tried to run `BAZEL_USE_CPP_ONLY_TOOLCHAIN=1 bazel build //foo` without the above flag. I get a similar error though, see enclosed.\r\n\r\n[logs_update.txt](https://github.com/tensorflow/tensorflow/files/2335869/logs_update.txt)\r\n", "@mhlopko does that help debugging?", "From the log, it seems like the protobuf compilation problem. This is a genrule invoking `js_embed` tool, which I have no idea what it does. I'd file an issue against protobuf. I don't think this is a bazel or tensorflow issue.\r\n\r\n```\r\nbash failed: error executing command\r\n  (cd /private/var/tmp/_bazel_ptighin/1e40e60bad53a8010892ea7aefd4f97f/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    PATH=/Users/ptighin/bin:/opt/local/libexec/gnubin:/opt/local/bin:/opt/local/sbin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Library/TeX/texbin \\\r\n  /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/host/bin/external/protobuf_archive/js_embed external/protobuf_archive/src/google/protobuf/compiler/js/well_known_types/any.js external/protobuf_archive/src/google/protobuf/compiler/js/well_known_types/struct.js external/protobuf_archive/src/google/protobuf/compiler/js/well_known_types/timestamp.js > bazel-out/host/genfiles/external/protobuf_archive/src/google/protobuf/compiler/js/well_known_types_embed.cc')\r\n/bin/bash: line 1: 88691 Segmentation fault: 11  bazel-out/host/bin/external/protobuf_archive/js_embed external/protobuf_archive/src/google/protobuf/compiler/js/well_known_types/any.js external/protobuf_archive/src/google/protobuf/compiler/js/well_known_types/struct.js external/protobuf_archive/src/google/protobuf/compiler/js/well_known_types/timestamp.js > bazel-out/host/genfiles/external/protobuf_archive/src/google/protobuf/compiler/js/well_known_types_embed.cc\r\n```", "@mhlopko -  Hi, did you open a new issue for protobuf ? If so, feel free to close this.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "In \"awaiting response\" status for more than 3 days. Hence closing this. Please post the updates here if any, we will reopen the issue. Thanks !", "Facing the same issue. Any help will be much appreciated. ", "Couldn't build file external/protobuf_archive/js_embed: Linking of rule '@protobuf_archive//:js_embed' failed (Exit 1)\r\nld: unknown option: -no-as-needed\r\nclang: error: linker command failed with exit code 1 (use -v to see invocation)\r\n\r\n-----\r\n\r\ndoes any one know how to resolve this problem, i use mac osx, tensorflow 1.4, bazel 0.9", "> Couldn't build file external/protobuf_archive/js_embed: Linking of rule '@protobuf_archive//:js_embed' failed (Exit 1)\r\n> ld: unknown option: -no-as-needed\r\n> clang: error: linker command failed with exit code 1 (use -v to see invocation)\r\n> \r\n> does any one know how to resolve this problem, i use mac osx, tensorflow 1.4, bazel 0.9\r\n\r\nSame issue with you, and I am using MacOS Catalina 10.15.5, tensorflow 1.10, bazel 0.15.", "> > Couldn't build file external/protobuf_archive/js_embed: Linking of rule '@protobuf_archive//:js_embed' failed (Exit 1)\r\n> > ld: unknown option: -no-as-needed\r\n> > clang: error: linker command failed with exit code 1 (use -v to see invocation)\r\n> > does any one know how to resolve this problem, i use mac osx, tensorflow 1.4, bazel 0.9\r\n> \r\n> Same issue with you, and I am using MacOS Catalina 10.15.5, tensorflow 1.10, bazel 0.15.\r\n\r\nI also have this problem. Mac Os 10.15, tf 1.12 and bazel 0.15. Have you solved it?", "> > > Couldn't build file external/protobuf_archive/js_embed: Linking of rule '@protobuf_archive//:js_embed' failed (Exit 1)\r\n> > > ld: unknown option: -no-as-needed\r\n> > > clang: error: linker command failed with exit code 1 (use -v to see invocation)\r\n> > > does any one know how to resolve this problem, i use mac osx, tensorflow 1.4, bazel 0.9\r\n> > \r\n> > \r\n> > Same issue with you, and I am using MacOS Catalina 10.15.5, tensorflow 1.10, bazel 0.15.\r\n> \r\n> I also have this problem. Mac Os 10.15, tf 1.12 and bazel 0.15. Have you solved it?\r\n\r\nUpgrade bazel to 0.15.2 can solve this issue."]}, {"number": 21406, "title": "Error with tf 1.10.0rc1", "body": "Hi,\r\n\r\nAfter upgrading to 1.10.0rc1, I got an error: E tensorflow/core/common_runtime/gpu/gpu_device.cc:228] Illegal GPUOptions.experimental.num_dev_to_dev_copy_streams=0 set to 1 instead. However, the program is still running. Is it still ok with this error?\r\n\r\nThanks,\r\nTuan\r\n\r\n", "comments": ["Yes, that is a benign message that you can ignore.\r\nWe'll look into make that message less ominous! :)", "Thanks @asimshankar .", "(Actually, this was fixed in commit bb52a6663a0141de53ddaf844f6c7087c0ddf7f7, but that isn't included in 1.10 so there will be spurious messages in 1.10.\r\n\r\n@av8ramit : Should we cherry pick that fix?)"]}, {"number": 21405, "title": "Tensorflow Moving Average Optimizer and Distribution Strategy", "body": "- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: 16.04.4 LTS (Xenial Xerus)\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: No\r\n- **TensorFlow installed from (source or binary)**: From source\r\n- **TensorFlow version (use command below)**: 1.9.0\r\n- **Python version**: 3.5\r\n- **Bazel version (if compiling from source)**: 0.11.0\r\n- **GCC/Compiler version (if compiling from source)**: (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\r\n- **CUDA/cuDNN version**: 7.1.4.18\r\n- **GPU model and memory**: Quadro K620 and Tesla K40c -- 2GB and 11.5GB respectively.\r\n- **Exact command to reproduce**:\r\n```\r\nwith tf.Graph().as_default() as graph:\r\n    config = tf.estimator.RunConfig(\r\n        model_dir=\"./output\",\r\n        save_summary_steps=FLAGS.saving_summ_freq, \r\n        save_checkpoints_steps=FLAGS.saving_ckpt_freq,\r\n        keep_checkpoint_max=3,\r\n        train_distribute=tf.contrib.distribute.MirroredStrategy()\r\n    )\r\n    classifier = tf.estimator.Estimator(\r\n        model_fn, \r\n        config=config)\r\n    train_spec = tf.estimator.TrainSpec(gen_input_fn('train', FLAGS.num_epochs))\r\n    valid_spec = tf.estimator.EvalSpec(gen_input_fn('valid', 1))\r\n    tf.estimator.train_and_evaluate(classifier, train_spec, valid_spec)\r\n```\r\nHello Tensorflow Devs,\r\n\r\nI try to add exponential moving average support to the optimization step. However, this new Estimator API backed by the \"Mirrored Distrubution Strategy\" fails due to a tensor conversion method specific to this strategy.\r\n\r\nWhen I call ema.apply_gradients(...) it ends up with the following exception:\r\n```\r\n\r\nINFO:tensorflow:Using config: {'_model_dir': './output', 1    365       saving_listeners = _check_listeners_type(saving_listeners)\r\n--> 366       loss = self._train_model(input_fn, hooks, saving_listeners)\r\n    367       logging.info('Loss for final step: %s.', loss)\r\n    368       return self\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py in _train_model(self, input_fn, hooks, saving_listeners)\r\n   1115   def _train_model(self, input_fn, hooks, saving_listeners):\r\n   1116     if self._distribution:\r\n-> 1117       return self._train_model_distributed(input_fn, hooks, saving_listeners)\r\n   1118     else:\r\n   1119       return self._train_model_default(input_fn, hooks, saving_listeners)\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py in _train_model_distributed(self, input_fn, hooks, saving_listeners)\r\n   1158             labels,  # although this will be None it seems\r\n   1159             model_fn_lib.ModeKeys.TRAIN,\r\n-> 1160             self.config)\r\n   1161 \r\n   1162         # TODO(anjalisridhar): Figure out how to resolve the following scaffold\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/distribute.py in call_for_each_tower(self, fn, *args, **kwargs)\r\n    792     \"\"\"\r\n    793     _require_cross_tower_context(self)\r\n--> 794     return self._call_for_each_tower(fn, *args, **kwargs)\r\n    795 \r\n    796   def _call_for_each_tower(self, fn, *args, **kwargs):\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py in _call_for_each_tower(self, fn, *args, **kwargs)\r\n    267       for t in threads:\r\n    268         t.should_run.set()\r\n--> 269       coord.join(threads)\r\n    270 \r\n    271     return values.regroup({t.device: t.main_result for t in threads})\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/coordinator.py in join(self, threads, stop_grace_period_secs, ignore_live_threads)\r\n    387       self._registered_threads = set()\r\n    388       if self._exc_info_to_raise:\r\n--> 389         six.reraise(*self._exc_info_to_raise)\r\n    390       elif stragglers:\r\n    391         if ignore_live_threads:\r\n\r\n/usr/local/lib/python3.5/dist-packages/six.py in reraise(tp, value, tb)\r\n    691             if value.__traceback__ is not tb:\r\n    692                 raise value.with_traceback(tb)\r\n--> 693             raise value\r\n    694         finally:\r\n    695             value = None\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/coordinator.py in stop_on_exception(self)\r\n    295     \"\"\"\r\n    296     try:\r\n--> 297       yield\r\n    298     except:  # pylint: disable=bare-except\r\n    299       self.request_stop(ex=sys.exc_info())\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py in run(self)\r\n    477                 self._captured_var_scope, reuse=self.tower_id > 0), \\\r\n    478             variable_scope.variable_creator_scope(self.variable_creator_fn):\r\n--> 479           self.main_result = self.main_fn(*self.main_args, **self.main_kwargs)\r\n    480           self.done = True\r\n    481       finally:\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py in _call_model_fn(self, features, labels, mode, config)\r\n   1105 \r\n   1106     logging.info('Calling model_fn.')\r\n-> 1107     model_fn_results = self._model_fn(features=features, **kwargs)\r\n   1108     logging.info('Done calling model_fn.')\r\n   1109 \r\n\r\n<ipython-input-9-2239e101f763> in model_fn(features, labels, mode)\r\n      3     loss = tfsi_model(features)\r\n      4     if mode == tf.estimator.ModeKeys.TRAIN:\r\n----> 5         train_op, grads, saver = minimize(loss)\r\n      6         writer, merged = prepare_summary(tf.get_default_graph(), loss, grads)\r\n      7         chkpt_hook = tf.train.CheckpointSaverHook(\r\n\r\n<ipython-input-7-8dbd2a0df6d6> in minimize(loss)\r\n     17         train_op = ema.apply_gradients(\r\n     18             grads,\r\n---> 19             global_step=tf.train.get_or_create_global_step()\r\n     20         )\r\n     21         return train_op, grads, ema.swapping_saver()\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/opt/python/training/moving_average_optimizer.py in apply_gradients(self, grads_and_vars, global_step, name)\r\n     97     if self._sequential_update:\r\n     98       with ops.control_dependencies([train_op]):\r\n---> 99         ma_op = self._ema.apply(var_list)\r\n    100     else:\r\n    101       ma_op = self._ema.apply(var_list)\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/moving_averages.py in apply(self, var_list)\r\n    428         zero_debias = self._averages[var] in zero_debias_true\r\n    429         updates.append(assign_moving_average(\r\n--> 430             self._averages[var], var, decay, zero_debias=zero_debias))\r\n    431       return control_flow_ops.group(*updates, name=scope)\r\n    432 \r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/moving_averages.py in assign_moving_average(variable, value, decay, zero_debias, name)\r\n     82   with ops.name_scope(name, \"AssignMovingAvg\",\r\n     83                       [variable, value, decay]) as scope:\r\n---> 84     with ops.colocate_with(variable):\r\n     85       decay = ops.convert_to_tensor(1.0 - decay, name=\"decay\")\r\n     86       if decay.dtype != variable.dtype.base_dtype:\r\n\r\n/usr/lib/python3.5/contextlib.py in __enter__(self)\r\n     57     def __enter__(self):\r\n     58         try:\r\n---> 59             return next(self.gen)\r\n     60         except StopIteration:\r\n     61             raise RuntimeError(\"generator didn't yield\") from None\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py in _colocate_with_for_gradient(self, op, gradient_uid, ignore_existing)\r\n   4217   def _colocate_with_for_gradient(self, op, gradient_uid,\r\n   4218                                   ignore_existing=False):\r\n-> 4219     with self.colocate_with(op, ignore_existing):\r\n   4220       if gradient_uid is not None and self._control_flow_context is not None:\r\n   4221         try:\r\n\r\n/usr/lib/python3.5/contextlib.py in __enter__(self)\r\n     57     def __enter__(self):\r\n     58         try:\r\n---> 59             return next(self.gen)\r\n     60         except StopIteration:\r\n     61             raise RuntimeError(\"generator didn't yield\") from None\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py in colocate_with(self, op, ignore_existing)\r\n   4270     if op is not None and not isinstance(op, Operation):\r\n   4271       # We always want to colocate with the reference op.\r\n-> 4272       op = internal_convert_to_tensor_or_indexed_slices(op, as_ref=True).op\r\n   4273 \r\n   4274     # By default, colocate_with resets the device function stack,\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py in internal_convert_to_tensor_or_indexed_slices(value, dtype, name, as_ref)\r\n   1266   else:\r\n   1267     return internal_convert_to_tensor(\r\n-> 1268         value, dtype=dtype, name=name, as_ref=as_ref)\r\n   1269 \r\n   1270 \r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py in internal_convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, ctx)\r\n   1105 \r\n   1106     if ret is None:\r\n-> 1107       ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n   1108 \r\n   1109     if ret is NotImplemented:\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/distribute/python/values.py in _tensor_conversion(var, dtype, name, as_ref)\r\n    243   # Try to avoid assignments to and other mutations of MirroredVariable\r\n    244   # state except through a DistributionStrategy.update() call.\r\n--> 245   assert not as_ref\r\n    246   return ops.internal_convert_to_tensor(\r\n    247       var.get(), dtype=dtype, name=name, as_ref=as_ref)\r\n\r\nAssertionError: \r\n```\r\nHere is the code for creating optimizer and applying backpropagation to the specified loss function:\r\n```\r\n\r\ndef minimize(loss):\r\n\r\n    lr = tf.constant(learning_rate_schedule[0], dtype=tf.float32)\r\n    for key, val in learning_rate_schedule.items():\r\n        lr = tf.cond(\r\n            tf.less(tf.train.get_or_create_global_step(), key), \r\n            lambda : lr,\r\n            lambda : tf.constant(val, dtype=tf.float32)\r\n        )\r\n    opt = tf.train.AdamOptimizer(learning_rate=lr, epsilon=FLAGS.epsilon)\r\n    if FLAGS.is_ema_enabled:\r\n        ema = tf.contrib.opt.MovingAverageOptimizer(\r\n            opt, \r\n            num_updates=tf.train.get_or_create_global_step()\r\n        )\r\n        grads = ema.compute_gradients(loss)\r\n        train_op = ema.apply_gradients(\r\n            grads,\r\n            global_step=tf.train.get_or_create_global_step()\r\n        )\r\n        return train_op, grads, ema.swapping_saver()\r\n    else:\r\n        grads = opt.compute_gradients(loss)\r\n        train_op = opt.apply_gradients(\r\n            grads, \r\n            global_step=tf.train.get_or_create_global_step()\r\n        )\r\n        return train_op, grads, tf.train.Saver()\r\n```\r\nIt seems that it causes a trouble when \"internal_tensor_conversion\" receives a reference variable though I am not sure of it. Am I doing something wrong or is it a bug?\r\n\r\nThank you for the help in advance.", "comments": ["/CC @anj-s, can you take a look?", "I am currently working on fixing this issue. Here is duplicate bug which I believe is the same issue: https://github.com/tensorflow/tensorflow/issues/19551", "@anj-s , yes it is true. It is exactly the same issue. So you want to merge them? Or close  both of them after you fix it? Another question of mine is whether you will have the fix in 1.10?", "Duplicate of #19551", "Hello @anj-s  Is this bug fixed already? I really need to use ExponentialMovingAverage alongside MirroredStrategy :(", "@iliTheFallen We are currently working on this bug since this slightly different from the one I fixed in #19551. \r\n@josh11b is working on this and we will update the bug as soon as possible.", "Nagging Assignees @josh11b, @anj-s: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "I think I have run across this as well. I believe it arises from my use of batch norm in my model. Happy to try and provide more detail if you need it.", "I have looked at https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/moving_averages.py and it does need to be updated to support DistributionStrategy. I needed to get https://github.com/tensorflow/tensorflow/commit/bb1f9e1a57c8bc18325b3c86298be96e6647a0a3 in first since the moving average changes rely on that functionality.\r\n\r\nWhat specific APIs are you trying to use? I'm only likely to update the versions inside core TensorFlow, not in contrib.", "I was using tf.contrib.layers. I switched to tf.layers and that does work. Should I open a separate issue for the tf.contrib.layers people or is that going to be EOLed?", "tf.contrib.layers is deprecated and will be removed later.", "Thanks. It does not say that currently in the docs."]}, {"number": 21404, "title": "Request: Add Golang API bindings for C-API TF_AddGradients()", "body": "Hi,\r\n\r\ncurrently the Golang bindings to Tensorflow (via the C API) allow me to define a graph, do most computations, load a trained model, and perform inference. However, it would be very helpful to be able to obtain gradients aswell. It looks like the C-API now has the TF_AddGradients call which makes it possible to get grads for some (but not all) operations. \r\n\r\nAdding a binding to this call in the Go API would allow me to use the C API through golang as a general autodiff library, which would help with some projects (such as the implementation of gradient-based stochastic samplers in Go like SGHMC). If this is actually easier than it looks, any pointers on how I might attempt it would be welcomed. Thanks!", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "@alextp Do you have any pointers in this?", "I'm tempted to mark this as contributions welcome; it should be straightforward with the way the go bindings work. Asim, does that make sense?", "Yup, it should be relatively straightforward and can be done as it was similarly done for Java recently (commit fac56f9c9ab58fe7406a826683559de4cef85637).\r\n\r\nMarking as \"Contributions Welcome\" in case someone wants to get to it before I do :)", "@asimshankar I would like to try this if no else is. Would send a PR by next week.", "@sanketloke : Sure thing, looking forward to it.", "After a week and still not fixed, it seems that  no one continue this issue, so I just submit a pull request.\r\n\r\nWish it's not too abrupt", "Is there still work to do here or did #21895 wrap this up?", "Thanks for linking this up @marpaia . Yeah #21895 should have closed this (and if there are missing features, a new issue can/should be filed).\r\n\r\n@ymodak : Could you close this? Thanks!"]}, {"number": 21403, "title": "Crash during folder creation from Estimator exporter.py in Python 3.6", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.8.0 and 1.9.0\r\n- **Python version**: 3.6\r\n- **GPU model and memory**: GTX 1080 Ti\r\n- **Exact command to reproduce**: See [here](https://github.com/tensorflow/models/issues/4996#issue-347431961)\r\n\r\n### Describe the problem\r\nWhen exporting of a snapshot during training with Estimator, [`export.py`](https://github.com/tensorflow/tensorflow/blob/e70f94ee089abbb9eb70361b5cdef55aa9beb18b/tensorflow/python/estimator/export/export.py#L600) creates an invalid path with Python 3.6, due to handling of strings as bytes (!!!). \r\n\r\nIn [`estimator.py`](https://github.com/tensorflow/tensorflow/blob/e70f94ee089abbb9eb70361b5cdef55aa9beb18b/tensorflow/python/estimator/estimator.py#L779), the following string is generated for the variable `export_dir`: `b'C:/Users/Alex/pet-train\\\\export\\\\Servo\\\\1533549311'`, which is afterwards corrupted by the `get_temp_export_dir` command, which defaces it into `b\"C:/Users/Alex/pet-train\\\\export\\\\Servo\\\\temp-b'1533549311'\"` which further down the road causes the program to crash with the following exception:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"C:\\Program Files\\JetBrains\\PyCharm 2018.1.2\\helpers\\pydev\\pydevd.py\", line 1664, in <module>\r\n    main()\r\n  File \"C:\\Program Files\\JetBrains\\PyCharm 2018.1.2\\helpers\\pydev\\pydevd.py\", line 1658, in main\r\n    globals = debugger.run(setup['file'], None, None, is_module)\r\n  File \"C:\\Program Files\\JetBrains\\PyCharm 2018.1.2\\helpers\\pydev\\pydevd.py\", line 1068, in run\r\n    pydev_imports.execfile(file, globals, locals)  # execute the script\r\n  File \"C:\\Program Files\\JetBrains\\PyCharm 2018.1.2\\helpers\\pydev\\_pydev_imps\\_pydev_execfile.py\", line 18, in execfile\r\n    exec(compile(contents+\"\\n\", file, 'exec'), glob, loc)\r\n  File \"C:/Users/Alex/Repositories/MusicObjectDetector-TF2/research/object_detection/model_main.py\", line 101, in <module>\r\n    tf.app.run()\r\n  File \"C:\\Programmieren\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 126, in run\r\n    _sys.exit(main(argv))\r\n  File \"C:/Users/Alex/Repositories/MusicObjectDetector-TF2/research/object_detection/model_main.py\", line 97, in main\r\n    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])\r\n  File \"C:\\Programmieren\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\training.py\", line 439, in train_and_evaluate\r\n    executor.run()\r\n  File \"C:\\Programmieren\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\training.py\", line 518, in run\r\n    self.run_local()\r\n  File \"C:\\Programmieren\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\training.py\", line 657, in run_local\r\n    eval_result = evaluator.evaluate_and_export()\r\n  File \"C:\\Programmieren\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\training.py\", line 858, in evaluate_and_export\r\n    self._export_eval_result(eval_result, is_the_final_export)\r\n  File \"C:\\Programmieren\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\training.py\", line 889, in _export_eval_result\r\n    is_the_final_export=is_the_final_export)\r\n  File \"C:\\Programmieren\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\exporter.py\", line 177, in export\r\n    is_the_final_export)\r\n  File \"C:\\Programmieren\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\exporter.py\", line 123, in export\r\n    strip_default_attrs=self._strip_default_attrs)\r\n  File \"C:\\Programmieren\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 644, in export_savedmodel\r\n    builder = saved_model_builder.SavedModelBuilder(temp_export_dir)\r\n  File \"C:\\Programmieren\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\saved_model\\builder_impl.py\", line 92, in __init__\r\n    file_io.recursive_create_dir(self._export_dir)\r\n  File \"C:\\Programmieren\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\", line 374, in recursive_create_dir\r\n    pywrap_tensorflow.RecursivelyCreateDir(compat.as_bytes(dirname), status)\r\n  File \"C:\\Programmieren\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\", line 519, in __exit__\r\n    c_api.TF_GetCode(self.status.status))\r\ntensorflow.python.framework.errors_impl.NotFoundError: Failed to create a directory: C:/Users/Alex/pet-train\\export\\Servo\\temp-b'1533549311'; No such file or directory\r\n\r\nProcess finished with exit code -1\r\n```\r\n", "comments": ["Ok, I guess - despite being ugly - the path is actually valid on Windows. Then the problem seems to be caused by the implementation of `RecursivelyCreateDir`. Why not using the good old [`os.makedirs`](https://docs.python.org/3.6/library/os.html#os.makedirs) command? \r\n\r\nReplacing `file_io.recursive_create_dir(self._export_dir)` in [line 92](https://github.com/tensorflow/tensorflow/blob/9d2d40079c273e8de8644136b452715c0146b907/tensorflow/python/saved_model/builder_impl.py#L92) with `os.makedirs(compat.as_str(self._export_dir), exist_ok=True)`. Fixed the problem on my side. Notice that the `exists=True` flag does not yet exist in Python 2.7.", "I think the `compat.as_bytes` was intended to make the function compatible with both python 2 and python 3, but `compat.as_bytes` was missing when adding `\"temp-\"`.\r\n\r\nAdded a PR #21426 to try to fix the issue.", "Can someone confirm that this small fix fixes the problem? ", "It didn't work for me.  (using Python 3.6, tf 1.8, Anaconda 3) \r\n\r\n**NotFoundError:** Failed to create a directory: E:/VGNE/Estimators/batch_version\\export\\model_1d_bv_fn\\temp-1534163718; No such file or directory\r\n[edit:copied wrong error message]\r\n\r\nThis is after I applied the following changes (I took the changes from the code shown here https://github.com/tensorflow/tensorflow/pull/21426/files):\r\n\r\n**File changed:**\r\nD:\\Anaconda3\\envs\\py36\\Lib\\site-packages\\tensorflow\\python\\estimator\\export\\export.py \r\n\r\n**From:**\r\n```\r\ndef get_temp_export_dir(timestamped_export_dir):\r\n    (dirname, basename) = os.path.split(timestamped_export_dir)\r\n    temp_export_dir = os.path.join(\r\n        compat.as_bytes(dirname), compat.as_bytes('temp-{}'.format(basename)))\r\n```\r\n**To:**\r\n```\r\ndef get_temp_export_dir(timestamped_export_dir):\r\n    (dirname, basename) = os.path.split(timestamped_export_dir)\r\n    temp_export_dir = os.path.join(\r\n        compat.as_bytes(dirname),\r\n        compat.as_bytes('temp-') + compat.as_bytes(basename))\r\n```\r\n\r\n**_I'm currently using the following workaround, which succeeds:-_**\r\n\r\n**File changed:**  D:\\Anaconda3\\envs\\py36\\Lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\r\n\r\n**From:**\r\n```\r\ndef recursive_create_dir(dirname):\r\n    with errors.raise_exception_on_not_ok_status() as status:\r\n        pywrap_tensorflow.RecursivelyCreateDir(compat.as_bytes(dirname), status)\r\n```\r\n**To:**\r\n```\r\ndef recursive_create_dir(dirname):\r\n    with errors.raise_exception_on_not_ok_status() as status:\r\n        os.makedirs(dirname, exist_ok=True)\r\n```\r\nIt worked both with and without applying the #21426 suggested fix. I don't handle errors though in this workaround", "Thanks @Wuppus for clarifying this again (as I've note already above): The problem apparently is the `pywrap_tensorflow.RecursivelyCreateDir(compat.as_bytes(dirname), status)` command. The old path seemed ugly and not what it was intended to be, but it is not the cause of the problem.\r\n\r\nWhy wouldn't you use the Python standard `os.makedirs()` command anyway?", "Seems like the only one who really gets nagged by the tensorflowbutler is me... \r\nNever mind this issue, I'm switching to PyTorch now.", "@apacha Indeed! I got a new machine over the weekend, installed latest TF and didn't think to check this line. Overnight run failed with the same issue. I moved to using estimators because Keras doesn't keep up with changes, maybe I need to look outside the Tensorflow world too!", "@Wuppus is this still the recommended solution to date?\r\n\r\n**Edit:** worked for me. Is there a PR for this?", "@austinmw Glad it worked for you - I've just experienced this issue again this morning having installed the latest Tensorflow-gpu. Only change seems to be the substitution of 'path' for 'dirname'. Someone went to the trouble of creating another decorator and just referenced the same faulty code...", "Sigh.. I feel like there's 10 different versions of python scattered through this api.", "Any changes to this issue? Or does it still require you to rewrite basic tensorflow functions?", "@apacha We see that you are using old version of tensorflow which is officially considered as end of life, We recommend that you upgrade to 2.4 or later version and let us know if the issue still persists in newer versions .Please open a new issue in case you face any errors, we will get you the right help .Hence moving this to closed status.Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/21403\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/21403\">No</a>\n"]}, {"number": 21402, "title": "Features: train.saver  namescoped-restoring", "body": "Hello:\r\n\r\nScenario of need:\r\nJoe the ML-engineer wants a model that predict multiple thing out of a single img (lets say object detection & some environment values: hour of day, type of surroundings: inside/outside/forest/stadium/etc).\r\nSo Joe train a model to get its object detected.\r\nThen Joe train a model to get its environment data.\r\nAnd now, Joe want a model that does both in a single prediction.\r\nBut Joe may want to have a clean **modulated model** (for scalable/maintainable purposes)\r\n\r\nScenario of usage:\r\nJoe create its model of object detection using the same function he used for first creating it, but in a name scope.\r\nJoe then use the `saver` to restore his checkpoint, adding the name scope as parameter to indicate that his variables are now contained in a name_scope thus their name has changed.\r\nThen the same for the environment model.\r\n\r\n\r\nThis feature need was inspired by this issue: \r\n[make-predictions-with-an-old-model-without-losing-the-current-model](https://stackoverflow.com/questions/51654259/make-predictions-with-an-old-model-without-losing-the-current-model/51654678?noredirect=1#comment90301946_51654678)\r\n\r\nHave I written custom code: N/A\r\nOS Platform and Distribution: N/A\r\nTensorFlow installed from: N/A\r\nTensorFlow version: N/A\r\nBazel version: N/A\r\nCUDA/cuDNN version: N/A\r\nGPU model and memory: N/A\r\nExact command to reproduce: N/A\r\nMobile device: N/A", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "filled the field even though it's not technically and issue, and more of a feature request/proposition", "Nagging Assignee @bignamehyp: It has been 45 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 21401, "title": "Request: Be able to tell if tensorflow is making use of tensor cores on V100", "body": "It would be really great if you could tell if the model you were training was successfully making use of the tensor cores on the Nvidia Tesla V100.\r\n\r\nThis would help in deciding whether spending the extra money on the V100 would be worth it, which it would be if the model is making good use of the tensor cores.\r\n\r\nI've tried to find the information using Nvidia's `nvidia-smi` tool, but it doesn't seem to how utilization by type of core.\r\n\r\nThanks\r\nChris", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "@ChrisBellew my understanding of V100 architecture is that the TensorCores aren't separated out--they use the same registers and reuse the ALUs of the main SM. So it may not be meaningful to ask for the utilization of the TC versus the normal SIMD cores. \r\n\r\nI would think that what you actually want to know is the performance benefits from using the TensorCores. Is your problem that you don't have a V100 and want to know if your model is likely to benefit from running on it? If you have a V100 sample, can't you do end-to-end timing measurements on it versus the alternatives? \r\n\r\n", "Thanks Cliff.\n\nMy situation is that I am using V100 GPUs on AWS using keras/tensorflow.\nThere are some rules that you must use to ensure the calculations are half\nprecision floating point such as:\n\n* Setting float X to float 16\n* Ensuring input arrays are float 16\n\nIf you don't abide by these, the GPU will just use the standard single\nprecision cores and you won't get the significant speed up. My problem is\nthat I don't know if I have successfully moved some calculations onto the\ntensor cores or if I have made a mistake. I suppose I could ensure all my\ntypes are float 32 and then compare to the float 16 times, and they should\nbe very different, but i wanted to know if there was a way tensorflow could\ngive me some feedback.\n\nThanks\n\nOn Sat., 18 Aug. 2018, 6:16 am Cliff Young, <notifications@github.com>\nwrote:\n\n> @ChrisBellew <https://github.com/ChrisBellew> my understanding of V100\n> architecture is that the TensorCores aren't separated out--they use the\n> same registers and reuse the ALUs of the main SM. So it may not be\n> meaningful to ask for the utilization of the TC versus the normal SIMD\n> cores.\n>\n> I would think that what you actually want to know is the performance\n> benefits from using the TensorCores. Is your problem that you don't have a\n> V100 and want to know if your model is likely to benefit from running on\n> it? If you have a V100 sample, can't you do end-to-end timing measurements\n> on it versus the alternatives?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/21401#issuecomment-414001164>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AEYM0vRvCisXbpOP1ZAIk8sr_2P180mOks5uR0DXgaJpZM4Vv-Ty>\n> .\n>\n", "@zheng-xq can you offer hints, please? ", "Tensor cores are used on V100s for various ops, such as matrix multiplications and convolutions, if the op inputs are float16. So this question is equivalent to checking if float16 is used in the model.\r\n\r\nAs @cy89 mentioned, one way is to measure the performance. Another way is to check the graph in TensorBoard to see the dtype ops are done in. A third option is to print `layer.input` and `layer.output` for each layer to verify the inputs and outputs are float16.\r\n\r\nA mixed precision API is being worked on, which when released, will make it easy to build a model in float16. Once released, it will be clear models that use the API will be done in float16, and therefore tensor cores are being used."]}, {"number": 21400, "title": "contrib.rnn.ConvLSTMCell: zero_state has wrong size if cell has skip connections", "body": "There seems to be a bug in how ConvLSTMCell handles its states:\r\n\r\nWhen calculating the output size, ConvLSTMCell has one more channel dimension (in general, as many more channels as there are input channels) than what was given as output_channels. \r\nThis is only if skip_connection was True at initialization, **and makes sense** (the input is concatenated to the output --> n_channels_out = n_channels_in + original_n_channels_out).\r\n\r\nAlso, when creating a cell and applying it to inputs and a state:\r\n### Minimal reproducible example\r\n```\r\ncell = tf.contrib.rnn.ConvLSTMCell(conv_ndims=2, input_shape=[80,80,1], output_channels=2,\r\n                                               kernel_shape=[5,5], skip_connection=True)\r\nstate= cell.zero_state(10, dtype=tf.float32)\r\noutput, next_state = cell(last_outputs, state)\r\n```\r\n\r\n--> next_state is an LSTMStateTuple with shapes (?, 80, 80, 2) and (?, 80, 80, **3**). Still makes sense since it stores its hidden state as well as outputs and re-uses them in the next timestep, and the outputs gained an additional channel. But cell.zero_state() will have other shapes ( (?, 80, 80, 2) and (?, 80, 80, 2).)\r\n\r\n\r\nThe zero_state() calculation seems wrong; the code reads (in contrib/rnn/python/ops/rnn_cell.py):\r\n\r\n```\r\n    self._total_output_channels = output_channels\r\n    if self._skip_connection:\r\n      self._total_output_channels += self._input_shape[-1]\r\n\r\n    state_size = tensor_shape.TensorShape(\r\n        self._input_shape[:-1] + [self._output_channels])\r\n    self._state_size = rnn_cell_impl.LSTMStateTuple(state_size, state_size)\r\n    self._output_size = tensor_shape.TensorShape(\r\n        self._input_shape[:-1] + [self._total_output_channels])\r\n```\r\n\r\nShouldn't it be not` rnn_cell_impl.LSTMStateTuple(state_size, state_size)`, but `rnn_cell_impl.LSTMStateTuple(state_size, self._output_size)` ?\r\n\r\nFunnily, it does not disturb the cell to be called with a state of size (80, 80, **2**)   - but for me it raised an error when called again with its next state which has size (80, 80, 3). For completeness, this error was (and this error is _not my problem_, my problem was inconsistency of shapes of the cell states): \r\n\r\n> Traceback (most recent call last):\r\n  File \"/home/me/programs/pycharm-community-2016.1.1/helpers/pydev/_pydevd_bundle/pydevd_comm.py\", line 1079, in do_it\r\n    result = pydevd_vars.evaluate_expression(self.thread_id, self.frame_id, self.expression, self.doExec)\r\n  File \"/home/me/programs/pycharm-community-2016.1.1/helpers/pydev/_pydevd_bundle/pydevd_vars.py\", line 352, in evaluate_expression\r\n    Exec(expression, updated_globals, frame.f_locals)\r\n  File \"/home/me/programs/pycharm-community-2016.1.1/helpers/pydev/_pydevd_bundle/pydevd_exec2.py\", line 3, in Exec\r\n    exec(exp, global_vars, local_vars)\r\n  File \"<string>\", line 1, in <module>\r\n  File \"/home/me/miniconda3/envs/tf36/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 232, in __call__\r\n    return super(RNNCell, self).__call__(inputs, state)\r\n  File \"/home/me/miniconda3/envs/tf36/lib/python3.6/site-packages/tensorflow/python/layers/base.py\", line 717, in __call__\r\n    outputs = self.call(inputs, *args, **kwargs)\r\n  File \"/home/me/miniconda3/envs/tf36/lib/python3.6/site-packages/tensorflow/contrib/rnn/python/ops/rnn_cell.py\", line 2113, in call\r\n    4 * self._output_channels, self._use_bias)\r\n  File \"/home/me/miniconda3/envs/tf36/lib/python3.6/site-packages/tensorflow/contrib/rnn/python/ops/rnn_cell.py\", line 2207, in _conv\r\n    \"kernel\", filter_size + [total_arg_size_depth, num_features], dtype=dtype)\r\n  File \"/home/me/miniconda3/envs/tf36/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 1317, in get_variable\r\n    constraint=constraint)\r\n  File \"/home/me/miniconda3/envs/tf36/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 1079, in get_variable\r\n    constraint=constraint)\r\n  File \"/home/me/miniconda3/envs/tf36/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 417, in get_variable\r\n    return custom_getter(**custom_getter_kwargs)\r\n  File \"/home/me/miniconda3/envs/tf36/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 235, in _rnn_get_variable\r\n    variable = getter(*args, **kwargs)\r\n  File \"/home/me/miniconda3/envs/tf36/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 394, in _true_getter\r\n    use_resource=use_resource, constraint=constraint)\r\n  File \"/home/me/miniconda3/envs/tf36/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 738, in _get_single_variable\r\n    found_var.get_shape()))\r\nValueError: Trying to share variable conv_lstm_cell/kernel, but specified shape (5, 5, 4, 8) and found shape (5, 5, 3, 8).\r\n\r\n\r\n\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nYes.\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nLinux Ubuntu 14.04\r\n- **TensorFlow installed from (source or binary)**: \r\nbinary\r\n- **TensorFlow version (use command below)**:\r\n1.8.0\r\n- **Python version**:\r\n3.6\r\n- **Bazel version (if compiling from source)**: \r\n-\r\n- **GCC/Compiler version (if compiling from source)**:\r\n-\r\n- **CUDA/cuDNN version**:\r\n- (using CPU version)\r\n- **GPU model and memory**:\r\n- (using CPU version)\r\n- **Exact command to reproduce**:\r\nSee description above\r\n- **Mobile device**:\r\nN/A\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nMobile device", "Sure...", "Thank you for the detailed report. That seems reasonable! Feel free to contribute a PR.", "Hi, @su-si .\r\nI want to know if the `tf.nn.dynamic` did not suport the `ConvLSTMCell` ?", "Hi @songzenghui ,\r\nIn my case I couldn't use a dynamic_rnn, so I don't know. (I had a problem with changing state sizes using ConvLSTMCell in a tf.while loop.) So just give it a try :) dynamic_rnn is probably the most frequent use case, so it will probably work. \r\nThe code to dynamic_rnn looks a bit complicated, I don't see right away whether they circumvent the changing state size within a while loop. It might be they do the first step outside of the loop, then both old and 'fixed' versions should work fine with dynamic_rnn.\r\nCould still be that my suggested fix destroys compatibility with dynamic_rnn.", "Contrib folder is not supported in latest versions , so closing this request. Please check tf-addons for further updates."]}, {"number": 21399, "title": "Fix TFLite's Makefile error of the cross compile tool chain name", "body": "The space between the CC_PREFIX and 'gcc' makes system failed to find the\r\ncorrect gcc binary. This issue shown as soon as you run build_rpi_lib.sh with cross\r\ntoolchain used. \r\n\r\nDetail:\r\nCC := $(CC_PREFIX) ${TARGET_TOOLCHAIN_PREFIX}gcc\r\nThere is a space after $(CC_PREFIX).\r\n\r\nSigned-off-by: Pei Zhang <changpei1982@gmail.com>", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->"]}, {"number": 21398, "title": "Questiona about Multi gpus using estimator in tensorflow 1.9", "body": "Now I am using estimator to train models in multi gpus.\r\n\r\nWhen I used the original sess.run() and trained in multi gpus before, I found that the batchnorm statistics cannot be shared between multi gpus and had a bad effect on the evaluation result.\r\n\r\nSo I change the code to tensorflow 1.9 and used estimator to train. \r\n\r\nEstimator can support a distributed multi-server environment without changing your model I am not sure if estimator support sharing the batchnorm statistics between multi gpus. And I think this is very important. \r\n\r\nSo I want to make sure about this.", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "@martinwicke any comment on batchnorm with distributed estimator?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Do you mean synchronized? https://github.com/tensorflow/tensorflow/issues/18222", "I think this is referring to `sync_batch_norm` as @bhack points out. Closing. Feel free to reopen if I misunderstood."]}, {"number": 21397, "title": "HParams: Clarify what happens when a new value is input to some methods", "body": "The current docstrings don't state that the methods don't accept new hyperparameters.", "comments": ["@danabo could you take a look?", "@ebrevdo  Could you please verify and LGTM this ?"]}, {"number": 21396, "title": "tensorflowDemo", "body": "", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->"]}, {"number": 21395, "title": "import_meta_graph + load model, then fail to model_export with signature", "body": "I was fail to export model for tf-serving, and this is my error message, but i hava no idea about it:\r\n```\r\nTypeError: Can't convert Operation 'in_table' to Tensor (target dtype=None, name=None, as_ref=True)\r\n```\r\nAnd those are part of my code:\r\n```\r\n        self.symbol2index = tf.contrib.lookup.MutableHashTable(\r\n            key_dtype=tf.string,\r\n            value_dtype=tf.int64,\r\n            default_value=self.UNK_ID,\r\n            shared_name=\"in_table_share\",\r\n            name=\"in_table\",\r\n            checkpoint=True)\r\n\r\n        self.index2symbol = tf.contrib.lookup.MutableHashTable(\r\n            key_dtype=tf.int64,\r\n            value_dtype=tf.string,\r\n            default_value=self.UNK,\r\n            shared_name=\"out_table_share\",\r\n            name=\"out_table\",\r\n            checkpoint=True)\r\n```\r\nSave model with:\r\n```\r\nself.saver.save(sess, \"%s/model.ckpt\" % ckpt_dir, global_step=global_step)\r\n```\r\nLoad with:\r\n```\r\nckpt = tf.train.latest_checkpoint(checkpoint_dir=tfFLAGS.train_dir)\r\ngraph_from_meta=ckpt + \".meta\"\r\nself.saver = tf.train.import_meta_graph(graph_from_meta)\r\nself.saver.restore(sess, tf.train.latest_checkpoint(ckpt_dir))\r\n```\r\nmodel export with:\r\n```\r\n        prediction_signature = tf.saved_model.signature_def_utils.build_signature_def(\r\n            inputs={\r\n                'question': question_placeholder,\r\n                'answer': answer_placeholder,\r\n                'question_len': qes_len_placeholder,\r\n                'answer_len': ans_len_placeholder,\r\n            },\r\n            outputs={'output': out_infers},\r\n            method_name=tf.saved_model.signature_constants.PREDICT_METHOD_NAME)\r\n\r\n        # legacy_init_op = tf.group(tf.tables_initializer(), name='legacy_init_op')\r\n        builder.add_meta_graph_and_variables(\r\n            sess,\r\n            tags=[tf.saved_model.tag_constants.SERVING],\r\n            signature_def_map={'prediction': prediction_signature},\r\n        )\r\n        builder.save()\r\n\r\n```\r\n\r\nI have try to rebuild graph with the same parameters instead load them with `import_meta_graph`, it works, but it not convenient. \r\n\r\nHope anyone can help me, thanks!", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "@tensorflowbutler Thanks for your reply, i have run the code on two environments: PC and Platform:\r\nPC:\r\n  Have I written custom code: No\r\n  OS Platform: Mac OS 10.11.6, no distribution\r\n  TensorFlow installed with conda4.5.4, version is 1.2.0, without Bazel\r\n\r\nPlatform:\r\n  ubuntu16.04, cuda8, cudnn5,\r\n  python2.7, tensorflow 1.2.1, Bazel 0.15.0\r\n  tensorflow install by docker, \r\n\r\nThat's all i know about environment. And both of them can not work. And i use the rebuild graph for now.", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new). Thanks!\r\n"]}]