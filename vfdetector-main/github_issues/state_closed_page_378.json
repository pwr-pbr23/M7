[{"number": 42663, "title": "Add TF_Log for gcs", "body": "@mihaimaruseac \r\nThis PR add loggging for gcs filesystem", "comments": ["As part of the final evaluation, I must provide a link to the work I have done. Since the blog post isn't finished yet. I've created a small gist and once we finish the blog post, we could add its link to the gist. Could you take a look at it ? Here is the link: https://gist.github.com/vnvo2409/dc1e3d98c8958efe8ebac2773f9a33fd Thank you!", "Sorry for the delay, have been out of GitHub in the past few days.\r\n\r\nThe Gist looks good so far, make sure you fix typos. Under Link, you can say that these are links to the implementation. If possible, you can also add other links for all the PRs you have done or a link to the search page that lists all the PRs.\r\n\r\nYou also have contributions to Bazel and aws I recall. We should include them too in the gist."]}, {"number": 42662, "title": "Problems with custom learning rate schedules and it's not clear why", "body": "### System information\r\n\r\n-   **Have I written custom code (as opposed to using a stock example script\r\n    provided in TensorFlow)**: Yes\r\n-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Colab\r\n-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue\r\n    happens on a mobile device**:\r\n-   **TensorFlow installed from (source or binary)**:\r\n-   **TensorFlow version (use command below)**: 2.3.0\r\n-   **Python version**:\r\n-   **Bazel version (if compiling from source)**:\r\n-   **GCC/Compiler version (if compiling from source)**:\r\n-   **CUDA/cuDNN version**:\r\n-   **GPU model and memory**:\r\n-   **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with:\r\n\r\n```bash\r\npython -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"\r\n```\r\n\r\n### Describe the problem\r\n\r\nI referred to [this example](https://www.tensorflow.org/tutorials/text/transformer) and especially the callback presented here. So, I decided to write out a callback inspired by [this one](https://github.com/facebookresearch/swav/blob/master/main_swav.py#L175). Basically it combines warm-ups and cosine decays. \r\n\r\nHere's how I coded it up - \r\n\r\n```python\r\nclass CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\r\n    def __init__(self, base_lr=0.1, end_lr=0.001, warmup_steps=390*5):\r\n        super(CustomSchedule, self).__init__()\r\n\r\n        self.base_lr = base_lr\r\n        self.end_lr = end_lr\r\n        self.warmup_steps = warmup_steps\r\n    \r\n    def __call__(self, step=390*35):\r\n        warmup_lr_schedule = tf.linspace(0., self.base_lr, self.warmup_steps)\r\n        iters = tf.range(step, dtype=tf.float32) \r\n        cosine_lr_schedule = tf.convert_to_tensor([self.end_lr + 0.5 * (self.base_lr - self.end_lr) * (1 + \\\r\n                        tf.math.cos(tf.constant(math.pi) * t / (step))) for t in iters])\r\n        lr_schedule = tf.concat([warmup_lr_schedule, cosine_lr_schedule], axis=0)\r\n        \r\n        return lr_schedule\r\n```\r\n\r\nI verified if this is the one I wanted and indeed it is - \r\n\r\n![image](https://user-images.githubusercontent.com/22957388/91200950-761e8180-e71d-11ea-93aa-abee10df7f2b.png)\r\n\r\nBut when I pass this callback inside an optimizer I run into weird stuff - \r\n\r\n```\r\nOperatorNotAllowedInGraphError: iterating over `tf.Tensor` is not allowed: AutoGraph did convert this function. This might indicate you are trying to use an unsupported feature.\r\n```\r\n\r\nWhat am I missing out on?\r\n\r\n### Source code / logs\r\n\r\n[Colab Notebook](https://colab.research.google.com/gist/sayakpaul/0f75d0177cf6824f80fcc62cd49dc78f/scratchpad.ipynb)\r\n", "comments": ["Was able to reproduce the issue with TF v2.3 and TF-nightly. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/b8ab5045ae609f60d75e430479f3d868/42662.ipynb). Thanks!", "Any updates? ", "TF: 2.3.0\r\nSimilar issue:\r\n```\r\nclass CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\r\n  def __init__(self, warmup_steps=1e4):\r\n    super().__init__()\r\n\r\n    self.warmup_steps = tf.cast(warmup_steps, tf.float32)\r\n    \r\n  def __call__(self, step):\r\n    step = tf.cast(step, tf.float32)\r\n    m = tf.maximum(self.warmup_steps, step)\r\n    m = tf.cast(m, tf.float32)\r\n    lr = tf.math.rsqrt(m)\r\n    \r\n    return lr\r\n\r\n```\r\n### Function output:\r\n```\r\nschedule = CustomSchedule()\r\nplt.plot(schedule(tf.range(25000, dtype=tf.float32)))\r\n```\r\n![lr_schedule](https://user-images.githubusercontent.com/17620536/92232869-b671c280-eec8-11ea-9f20-9c274cadcddc.png)\r\n\r\n\r\n\r\n```\r\nlearning_rate_fn = CustomSchedule()\r\noptimizer = tf.keras.optimizer.Adam(learning_rate_fn)\r\n\r\nmodel.compile(optimizer=optimizer, ...)\r\nmodel.fit(dataset, epochs=1)\r\n```\r\n\r\n### Error:\r\n**TypeError: To be compatible with tf.eager.defun, Python functions must return zero or more Tensors; in compilation of <function Model.make_train_function.<locals>.train_function at 0x7fdf2c2b9c80>, found return value of type <class '__main__.CustomSchedule'>, which is not a Tensor.**\r\n", "@sayakpaul Thanks for the issue! The `LearningRateSchedule.__call__` method should accept a `Tensor` `step` argument and output a `Tensor` that represents the learning rate to use for that particular step. It looks like your subclass is outputting an entire schedule every step rather than the learning rate for that particular step.", "@omalleyt12 any hints to my issue?", "@omalleyt12 okay. So, how should I approach it if I were to use the schedule I mentioned in the first place? "]}, {"number": 42661, "title": "Out of memory situation with tf keras Model.fit using tcmalloc library", "body": "<em>\r\nThis is a bug related to memory management\r\n</em>\r\n\r\n**System information**\r\n- I have created my own code for tf.Keras model building and compiling and run model.fit train and eval:\r\n- Red Hat 7.8 (Maipo):\r\n- Not a mobile device:\r\n- From binary:\r\n- v2.0.0-rc2-26-g64c3d38 2.0.0:\r\n- 3.6.9:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- Cuda 10.0/cuDNN 7.X:\r\n- Tesla P-100, 16 GB:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**\r\nCurrently the model.fit training and eval aborts due to out of memory error.  I found from stackoverflow that this error is due to the inability of malloc to efficiently collect garbage.  As suggested [here](https://github.com/tensorflow/tensorflow/issues/2942), I used tcmalloc through LD_PRELOAD=/usr/lib/x86_64-linux-gnu/libtcmalloc_minimal.so.4 before running the tensorflow training script.  The problem is alleviated but not eliminated completely.  Compared to just using gcc malloc, the tcmalloc allows for training a few more epochs, but ultimately gets into an out of memory situation.  The CPU memory that I have available is ~377 GB.  As the training proceeds over epochs, the memory usage increases until the limit and the whole program aborts.  Also, the speed of training decreases with every epoch\r\n**\r\n\r\n**\r\nI expect the out of memory issue to never occur.  Also, I expect the speed of training to be consistent across the epochs.\r\n**\r\n\r\n**\r\n`\r\nif __name__=='__main__':\r\n    tf.keras.backend.clear_session()\r\n    tf.config.optimizer.set_jit(True)\r\n    from tf_tools import read_h5\r\n    from glob import glob\r\n    import os\r\n    from Feature_compression import build_model\r\n    train_data_folder = os.path.join(os.environ['FAST_DRIVE'],'DATA','DSIFT','train','Visible','imagery')\r\n    test_data_folder = os.path.join(os.environ['FAST_DRIVE'],'DATA','DSIFT','test','Visible','imagery')\r\n    vis_model_folder = os.path.join(os.environ['FAST_DRIVE'],'MODEL','Visible2')\r\n    with h5py.File(os.path.join(train_data_folder,'All_train_visible_data.h5'),'r') as f:\r\n        num_samples = len(f['DSIFT_image'])*(len(f['DSIFT_image'])-1)//2\r\n    strategy = tf.distribute.MirroredStrategy()\r\n    BATCH_SIZE_PER_REPLICA =512\r\n    BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\r\n    EPOCHS =15 \r\n    STEPS_PER_EPOCH = 5000 #int(num_samples/EPOCHS) \r\n    model_folder = os.path.join(os.environ['FAST_DRIVE'],'MODEL','Visible_2_Visible')\r\n    os.makedirs(model_folder,exist_ok=True)\r\n    csv_logger = CSVLogger(os.path.join(model_folder,'DSIFT_training.log'),append=True)\r\n    checkpoint_dir = os.path.join(model_folder,'training_checkpoints')\r\n    checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\r\n    early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy',patience=3,min_delta=1E-5,baseline=0.999)\r\n    #tf.keras.callbacks.TensorBoard(log_dir='./logs'),\r\n    callbacks = [tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix, save_weights_only=True),csv_logger]#,early_stop]\r\n#====================== Preparing the dataset optimizaion options =============================================================================#\r\n    dataset_options = tf.data.Options()\r\n    dataset_options.experimental_threading.private_threadpool_size = 60#mp.cpu_count()\r\n    dataset_options.experimental_threading.max_intra_op_parallelism = 1 #mp.cpu_count()\r\n    dataset_options.experimental_optimization.apply_default_optimizations = True\r\n    dataset_options.experimental_optimization.map_vectorization.enabled = True\r\n#====================== Preparing the training dataset =============================================================================#\r\n    train = read_h5(h5py.File(os.path.join(train_data_folder,'All_train_visible_data.h5'),'r'),dataset=['DSIFT_image','labels'],label_str='labels')\r\n\r\n    train_input_pds=tf.data.Dataset.from_generator(train.gen_func_pairwise(cls='positive'),output_types=(tf.uint8,tf.float32),\r\n                     output_shapes=(tf.TensorShape((2,24,24,64)),tf.TensorShape((2,))))\r\n    \r\n    train_input_nds=tf.data.Dataset.from_generator(train.gen_func_pairwise(cls='negative'),output_types=(tf.uint8,tf.float32),\r\n                     output_shapes=(tf.TensorShape((2,24,24,64)),tf.TensorShape((2,))))\r\n\r\n    train_balanced_ds = tf.data.experimental.sample_from_datasets([train_input_pds.repeat(),train_input_nds.repeat()], [0.5,0.5]).batch(BATCH_SIZE)\r\n    train_dataset = train_balanced_ds.map(lambda features,labels: (tf.concat(tf.unstack(features,axis=1),axis=0)/255,\r\n                                        tf.cast(tf.equal(*tf.unstack(labels,axis=1)), dtype=tf.float32)),\r\n                                        num_parallel_calls=tf.data.experimental.AUTOTUNE).prefetch(tf.data.experimental.AUTOTUNE)\r\n    train_dataset.with_options(dataset_options)\r\n#==================================================================================================================================#\r\n#====================== Preparing the testing dataset =============================================================================#\r\n    test = read_h5(h5py.File(os.path.join(test_data_folder,'All_test_visible_data.h5'),'r'),dataset=['DSIFT_image','labels'],label_str='labels')\r\n\r\n    test_input_pds=tf.data.Dataset.from_generator(test.gen_func_pairwise(cls='positive'),output_types=(tf.uint8,tf.float32),\r\n                     output_shapes=(tf.TensorShape((2,24,24,64)),tf.TensorShape((2,))))\r\n    \r\n    test_input_nds=tf.data.Dataset.from_generator(test.gen_func_pairwise(cls='negative'),output_types=(tf.uint8,tf.float32),\r\n                     output_shapes=(tf.TensorShape((2,24,24,64)),tf.TensorShape((2,))))\r\n\r\n    test_balanced_ds = tf.data.experimental.sample_from_datasets([test_input_pds.repeat(),test_input_nds.repeat()], [0.5,0.5]).batch(BATCH_SIZE) \r\n    test_dataset = test_balanced_ds.map(lambda features,labels: (tf.concat(tf.unstack(features,axis=1),axis=0)/255,tf.cast(tf.equal(*tf.unstack(labels,axis=1)), dtype=tf.float32)),num_parallel_calls=tf.data.experimental.AUTOTUNE).prefetch(tf.data.experimental.AUTOTUNE)\r\n\r\n    test_dataset.with_options(dataset_options)\r\n#==================================================================================================================================#\r\n    with strategy.scope():\r\n        CNN_model = build_model(num_classes=473)\r\n        df = pd.read_csv(os.path.join(vis_model_folder,'DSIFT_Training_History.csv'),delimiter=',')\r\n        CNN_model.load_weights(os.path.join(vis_model_folder,'training_checkpoints',f'ckpt_{1+df[\"val_accuracy\"].argmax()}'))\r\n        CNN_base_model = tf.keras.Sequential(CNN_model.layers[:-1])\r\n        dnn_model = build_vis2vis_model(layer_shape=[2,2])\r\n        CNN_base_model.trainable = False\r\n        inputs = tf.keras.Input(shape=CNN_base_model.input_shape[1:])\r\n        x = CNN_base_model(inputs,training=False)\r\n        x = tf.abs(tf.keras.layers.Subtract()(tf.split(x,2,axis=0)))\r\n        outputs = dnn_model(x)\r\n        model = tf.keras.Model(inputs,outputs)\r\n        model.compile(loss=tf.keras.losses.hinge,\r\n                      optimizer=tf.keras.optimizers.Adam(), metrics =['accuracy'])\r\n    history = model.fit(x=train_dataset, epochs=EPOCHS,validation_data=test_dataset,\r\n                        steps_per_epoch=STEPS_PER_EPOCH,validation_steps=STEPS_PER_EPOCH,\r\n                        callbacks=callbacks)\r\n    pd.DataFrame(history.history).to_csv(os.path.join(model_folder,\"DSIFT_Training_History.csv\"),index=False)\r\n`\r\n**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**\r\nTrain for 5000 steps, validate for 5000 steps\r\nEpoch 1/15\r\n5000/5000 [==============================] - 5142s 1s/step - loss: 3.5599e-04 - accuracy: 0.9999 - val_loss: 0.1393 - val_accuracy: 0.9757\r\nEpoch 2/15\r\n5000/5000 [==============================] - 5206s 1s/step - loss: 0.0346 - accuracy: 0.9971 - val_loss: 8.6923e-06 - val_accuracy: 1.0000\r\nEpoch 3/15\r\n5000/5000 [==============================] - 5217s 1s/step - loss: 3.7841e-04 - accuracy: 1.0000 - val_loss: 3.2933e-07 - val_accuracy: 1.0000\r\nEpoch 4/15\r\n5000/5000 [==============================] - 5264s 1s/step - loss: 7.6284e-04 - accuracy: 0.9999 - val_loss: 3.1577e-06 - val_accuracy: 1.0000\r\nEpoch 5/15\r\n5000/5000 [==============================] - 5335s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0950e-06 - val_accuracy: 1.0000\r\nEpoch 6/15\r\n5000/5000 [==============================] - 5223s 1s/step - loss: 5.6489e-04 - accuracy: 0.9999 - val_loss: 1.1722e-05 - val_accuracy: 1.0000\r\nEpoch 7/15\r\n5000/5000 [==============================] - 5353s 1s/step - loss: 1.2962e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\r\nEpoch 8/15\r\n5000/5000 [==============================] - 5390s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\r\nEpoch 9/15\r\n5000/5000 [==============================] - 5487s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\r\nEpoch 10/15\r\n5000/5000 [==============================] - 5761s 1s/step - loss: 3.3989e-04 - accuracy: 0.9999 - val_loss: 1.2558e-08 - val_accuracy: 1.0000\r\nEpoch 11/15\r\n4999/5000 [============================>.] - ETA: 0s - loss: 1.1383e-08 - accuracy: 1.0000/var/spool/pbs/mom_priv/jobs/6135009.pbsserver.SC: line 26:  5302 Killed                  singularity run --nv -B ${FAST_DRIVE}:/p/work3/srini ./tensorflow_2_0_0-gpu_tcmalloc.img python /p/work3/srini/python_scripts/Vis_to_Vis_mapping.py\r\nStart Epilogue v2.5.3 Tue Aug 25 14:41:53 UTC 2020 \r\nMemory usage reported in GB\r\n                    % of     user     user     user    total    total\r\nNode               limit      max    limit  current  current     phys\r\ngaffney-g05       100.00   365.00   365.00     0.02     5.57   377.33\r\nMemory summary:\r\n\t\tmin  365.00 GB\r\n\t\tmax  365.00 GB\r\n\t\tave  365.00 GB\r\nOut of Memory condition reached, job memory usage should be reevaluated.\r\n** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["@s0r2637 \r\nPlease share complete stand alone indented code for us to replicate the issue faced or if possible share colab gist with error faced.\r\nCan you verify if there is any other python code running in parallel, or anything in parallel consuming memory.", "I shared with you all the code I can.  There are small modules that I import.  It will be hard to share all those modules.  Is there anything specifically you are looking for?  As far as I know,  there weren;t any other python codes running in parallel.  I was running my tensorflow training inside a singularity container.", "@s0r2637 \r\nPlease share a colab gist with the issue reported.\r\n\r\n[you could use [this](https://colab.sandbox.google.com/#create=true&language=python3) link to run the code and share the Gist (File -> Save a copy as Github gist) with us. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42661\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42661\">No</a>\n"]}, {"number": 42659, "title": "How to print Quantization Aware Training Model Int8 weights without TFLite", "body": "Hi, I I've been trying to [Quantization aware training in Keras example](https://www.tensorflow.org/model_optimization/guide/quantization/training_example)\r\n\r\nI thought QAT Model weight data type is FP32, but it's real value represents fixed-point number.\r\nI want to know how to print fixed-point number of weights without converting TFLite.\r\n\r\nThank you.", "comments": ["After `model.fit` cell in the colab, save the quantization aware model in `h5` format using `model.save` method.\r\nFurther use [netron web browser](https://github.com/lutzroeder/netron) application to view the weights of the saved model.\r\nYou may also use TensorBoard to visualize the op-level graph and inspect weights.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "> After `model.fit` cell in the colab, save the quantization aware model in `h5` format using `model.save` method.\r\n> Further use [netron web browser](https://github.com/lutzroeder/netron) application to view the weights of the saved model.\r\n> You may also use TensorBoard to visualize the op-level graph and inspect weights.\r\n\r\nIt is a good idea to visualize the weights in the output model this way. However, after QAT, what we can see are not INT8 weights but FP32 ones in a wrapper."]}, {"number": 42658, "title": "Data shape mismatch in custom training with 'train_step'  and `__get_item__`", "body": "- TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"` : `unknown 2.2.0`\r\n\r\n## Problem description \r\nI am developing a custom model training by overriding `train_step` inherited from `tf.keras.Model` and `__getitem__` of my data generator inherited from `tf.keras.utils.Sequence`. The `__get_item__` method returns the following data:\r\n\r\n`return [train_data, observed_data]`\r\nwhere `train_data` and `observed_data` are numpy arrays with shape (20, 92)\r\n\r\nHowever, when I receive them in `train_step` function, the shapes of these variables are not correct: \r\nIn `train_step` method, I extract the data as follows: \r\n`train_data, observed_data = data[0]` \r\n\r\nand here is what I get: \r\n\r\n- `train_data Tensor(\"IteratorGetNext:0\", shape=(None, None), dtype=float32)`\r\n- `observed_data Tensor(\"IteratorGetNext:1\", shape=(None, None), dtype=float32)`\r\n\r\n## The expected behavior\r\nI am not sure if this is a bug or not, but the expected shape of these tensors should be as good as what is specified in `__get_item__` method.", "comments": ["@Hamidreza3252 \r\nPlease provide complete indented stand alone code for us to replicate the issue faced or if possible share a colab gist with the issue reported for us to analyse. Thanks!", "@Saduf2019 \r\nI invited you to my repo, https://github.com/Hamidreza3252/HI-VAE . Please accept and you will get access to my code. \r\nThe code is under development, so in order to see the issue, please follow these steps:\r\n1. After clone, run `main_scripts.py` in debug mode\r\n2. The code works up to line 117, `vae_model.fit`, so suggest to put a break-point there.\r\n3. The `__get_item__` method is implemented in `hivae_data_generator.py`. Please look for the method and watch what it returns, (the numpy arrays, as explained in the issue above)\r\n4. The `train_step` function is overridden in `vae_base_model.py`. In lines between 205 and 214 you can watch the data passed to `train_step` method, as described in the issue above, with wrong/ not-specified shapes.", "@Saduf2019  and @gowthamkpr   Please let me know if you could reproduce my problem", "Hi @Hamidreza3252, are you still facing this issue? If so, please provide a minimal reproducible example.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42658\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42658\">No</a>\n"]}, {"number": 42657, "title": "Tensorflow go installation fail (cannot find import)", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version:\r\n- Python version: 3.8\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source): 3.1\r\n- GCC/Compiler version (if compiling from source):9.3\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\nI have installed C , following the instructions from https://www.tensorflow.org/install/lang_c and when i ran:                       go get github.com/tensorflow/tensorflow/tensorflow/go\r\nI get the following error:\r\n../github.com/tensorflow/tensorflow/tensorflow/go/saved_model.go:25:2: cannot find package \"github.com/tensorflow/tensorflow/tensorflow/go/core/protobuf/for_core_protos_go_proto\" in any of:\r\n                     /usr/local/go/src/github.com/tensorflow/tensorflow/tensorflow/go/core/protobuf/for_core_protos_go_proto (from $GOROOT)\r\n\t            /home/nyein/go/src/github.com/tensorflow/tensorflow/tensorflow/go/core/protobuf/for_core_protos_go_proto (from $GOPATH)\r\n\r\nI tried following this fix here at https://github.com/tensorflow/tensorflow/issues/14546#issuecomment-347433966 and I checkout from r1.11 and I am getting this error now:\r\n/usr/bin/ld: $WORK/b032/_x007.o: in function `_cgo_d969e426e2e3_Cfunc_TF_DeviceListCount':\r\n/tmp/go-build/cgo-gcc-prolog:115: undefined reference to `TF_DeviceListCount'\r\n/usr/bin/ld: $WORK/b032/_x007.o: in function `_cgo_d969e426e2e3_Cfunc_TF_DeviceListMemoryBytes':\r\n/tmp/go-build/cgo-gcc-prolog:136: undefined reference to `TF_DeviceListMemoryBytes'\r\n/usr/bin/ld: $WORK/b032/_x007.o: in function `_cgo_d969e426e2e3_Cfunc_TF_DeviceListName':\r\n/tmp/go-build/cgo-gcc-prolog:157: undefined reference to `TF_DeviceListName'\r\n/usr/bin/ld: $WORK/b032/_x007.o: in function `_cgo_d969e426e2e3_Cfunc_TF_DeviceListType':\r\n/tmp/go-build/cgo-gcc-prolog:178: undefined reference to `TF_DeviceListType'\r\n/usr/bin/ld: $WORK/b032/_x007.o: in function `_cgo_d969e426e2e3_Cfunc_TF_SessionListDevices':\r\n/tmp/go-build/cgo-gcc-prolog:234: undefined reference to `TF_SessionListDevices'\r\n/usr/bin/ld: $WORK/b032/_x007.o: in function `_cgo_d969e426e2e3_Cfunc_TF_DeleteDeviceList':\r\n/tmp/go-build/cgo-gcc-prolog:62: undefined reference to `TF_DeleteDeviceList'\r\ncollect2: error: ld returned 1 exit status\r\n\r\nCan someone point me to right right direction on fixing this problem?\r\n", "comments": ["Try checking out v2.1.0 and run the go get command again. To verify try the go test command with the same endpoint", "I tried checking out v2.1.0 and it does not work either. But then my test successfully build after I changed the tensorflow C **to version 1.15.** Does it mean that tensorflow-go is incompatible with tensorflow-2? ", "@plyte,\r\nCan you please try Building `Tensorflow` with latest version of `Tensorflow`, i.e., `2.3` and let us know how it goes. Thank you! ", "@rmothukuru oh yeah tensorflow c 2.3.0 as of today works with tensorflow v2.1.0. The latest version has issues with the \"go get\" command as reported by @nyeinsoe26.", "@nyeinsoe26 can you run the go get again, but include a -v in your declaration aka:\r\n`go get -v github.com/tensorflow/tensorflow/tensorflow/go`\r\n\r\nthen comment the results please", "nyein@nyein:~/Downloads$ ./hello_tf\r\nHello from TensorFlow C library version 2.3.0\r\nnyein@nyein:~/Downloads$ go get -v  github.com/tensorflow/tensorflow/tensorflow/go\r\ngithub.com/tensorflow/tensorflow (download)\r\ncannot find package \"github.com/tensorflow/tensorflow/tensorflow/go/core/protobuf/for_core_protos_go_proto\" in any of:\r\n\t/usr/local/go/src/github.com/tensorflow/tensorflow/tensorflow/go/core/protobuf/for_core_protos_go_proto (from $GOROOT)\r\n\t/home/nyein/go/src/github.com/tensorflow/tensorflow/tensorflow/go/core/protobuf/for_core_protos_go_proto (from $GOPATH)\r\n\r\nIt seems I am still having this issue with tensorflow C 2.3.0. Its working fine for me with tensorflow C 1.15", "Oh sorry I didnt read the above messages clearly. I checked out from v2.1.0, my test build successfully now.\r\n\r\nnyein@nyein:~/go/src/github.com/tensorflow/tensorflow/tensorflow/go$ go test github.com/tensorflow/tensorflow/tensorflow/go\r\n\r\n> # github.com/tensorflow/tensorflow/tensorflow/go\r\n> /usr/bin/ld: /usr/local/lib/libtensorflow.so: .dynsym local symbol at index 851 (>= sh_info of 2)\r\n> /usr/bin/ld: /usr/local/lib/libtensorflow.so: .dynsym local symbol at index 1959 (>= sh_info of 2)\r\n> /usr/bin/ld: /usr/local/lib/libtensorflow.so: .dynsym local symbol at index 2329 (>= sh_info of 2)\r\n> /usr/bin/ld: /usr/local/lib/libtensorflow.so: .dynsym local symbol at index 2517 (>= sh_info of 2)\r\n> /usr/bin/ld: /usr/local/lib/libtensorflow.so: .dynsym local symbol at index 2732 (>= sh_info of 2)\r\n> /usr/bin/ld: /usr/local/lib/libtensorflow.so: .dynsym local symbol at index 2733 (>= sh_info of 2)\r\n> # github.com/tensorflow/tensorflow/tensorflow/go.test\r\n> /usr/bin/ld: /usr/local/lib/libtensorflow.so: .dynsym local symbol at index 851 (>= sh_info of 2)\r\n> /usr/bin/ld: /usr/local/lib/libtensorflow.so: .dynsym local symbol at index 1959 (>= sh_info of 2)\r\n> /usr/bin/ld: /usr/local/lib/libtensorflow.so: .dynsym local symbol at index 2329 (>= sh_info of 2)\r\n> /usr/bin/ld: /usr/local/lib/libtensorflow.so: .dynsym local symbol at index 2517 (>= sh_info of 2)\r\n> /usr/bin/ld: /usr/local/lib/libtensorflow.so: .dynsym local symbol at index 2732 (>= sh_info of 2)\r\n> /usr/bin/ld: /usr/local/lib/libtensorflow.so: .dynsym local symbol at index 2733 (>= sh_info of 2)\r\n> ok  \tgithub.com/tensorflow/tensorflow/tensorflow/go\t0.152s\r\n\r\nThis is with tensorflow C 2.3.0. It works fine after checking out from v2.1.0. Thank you for all the help @plyte  @rmothukuru ", "\ud83c\udf89 \ud83c\udf88 \ud83c\udf89 \r\nGlad to help! Good luck with your tensorflow/golang adventures!", "Thanks. Since this is resolved, I will be closing the issue.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42657\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42657\">No</a>\n"]}, {"number": 42656, "title": "[ROCm] Removing TPU tests from the ROCm CSB + CI scripts.", "body": "The ROCm CSB + CI scripts were not skipping the tests within `//tensorflow/core/tpu`.\r\nSome of the targets within `//tensorflow/core/tpu` have had build errors creep into them over the last week, resulting in the ROCm CSB and CI scripts failing due to those build errors.\r\n\r\nThis commit simply updates the ROCm CSB + CI scripts to skip the tests within `//tensorflow/core/tpu`.\r\n\r\n-------------------------------------------\r\n\r\n/cc @chsigg @cheshire @nvining-work \r\n\r\n", "comments": ["@chsigg gentle ping", "@chsigg gentle ping", "@chsigg gentle ping", "@chsigg gentle ping", "@chsigg gentle ping"]}, {"number": 42655, "title": "Cannot see per operator profiling in android studio with tensorflow lite models", "body": "## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\n\r\nhttps://www.tensorflow.org/lite/performance/measurement#adding_trace_events_in_java_code\r\n\r\nhttps://www.tensorflow.org/lite/performance/images/as_traces.png\r\n\r\n## Description of issue (what needs changing):\r\n\r\nI've added the trace sections to the code around the ``` interpreter.run() ``` command. When I start to profile the app I cannot see \r\nthe per operator profiling as we can see in the second link.\r\n\r\n### Clear description\r\n\r\nThis will help us in seeing how much time is being taken by each layer in the tflite model and we can change our models\r\naccording to that.\r\n\r\n### My Code\r\n\r\n``` \r\nTrace.beginSection(\"runInference\");\r\n tflite_sr.run(ybuffer,sr_y_channel);\r\n Trace.endSection(); \r\n```", "comments": ["@anidh,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here and also the TensorFlow version you are using. Thanks!", "Hi @amahendrakar ,\r\nThanks for replying. The tensorflow version is 1.15 to convert to a tflite file\r\nThe code which i'm using to do the inference is \r\n``` public ByteBuffer sr_exec(byte[] inp)  {\r\n\r\n    //gpuDelegate = new GpuDelegate();\r\n    //tfliteOptions_sr.addDelegate((gpuDelegate));\r\n    //tfliteOptions_sr.setNumThreads(numThreads);\r\n\r\n    ByteBuffer ybuffer = ByteBuffer.allocateDirect(i_prod).order(ByteOrder.nativeOrder());\r\n    ybuffer.rewind();\r\n    ybuffer.put(y_channel_inp);\r\n\r\n    ByteBuffer out_channel = ByteBuffer.allocateDirect(o_prod).order(ByteOrder.nativeOrder());\r\n\r\n    try {\r\n      Trace.beginSection(\"recognizeImage\");\r\n      //long startTime = System.currentTimeMillis();\r\n      Trace.beginSection(\"runInference\");\r\n      tflite_sr.run(inp,out_channel);\r\n      Trace.endSection();\r\n\r\n      //long stopTime = System.currentTimeMillis();\r\n      //long elapsedTime = stopTime - startTime;\r\n      //System.out.println(\"&&&&&&&&&&&&&&&&&&&&&&\"+elapsedTime);\r\n      Trace.endSection();\r\n\r\n    }\r\n    catch (Exception e) {\r\n      Log.d(TAG, \"Error in Inference: \"+e);\r\n    }\r\n    return out_channel;\r\n  } ```\r\n```\r\nThis is the code which is used for the inference, the ip buffer is of int type. When i do the profiling on the mobile device I am not able to see the layer wise timing as what has been mentioned in the documentation.\r\n\r\nThanks,\r\nAnidh", "Hi Xunkai & Lu, can you guys take a look?\r\n\r\nthanks", "Hi Juho, could you please take a look at this issue?", "Hi Anidh,\r\nI'd like to ask some details about the running environment.\r\n\r\n- Can you see 'runInference' trace while you cannot see per-operator profiling result?\r\n\r\n- Did you use org.tensorflow:tensorflow-lite:0.0.0-nightly for dependency? tensorflow-lite:2.3.0 or older stable aar libraries don't have this feature.\r\n\r\n- Is the nightly library is up-to-date version? In your app's build.gradle file add 'changing = true', to make sure the library is automatically refreshed.\r\n  implementation('org.tensorflow:tensorflow-lite:0.0.0-nightly') { changing = true }\r\n\r\n- Did you run the command 'adb shell setprop debug.tflite.trace 1' before you started profiler?\r\n  FYI, this property value is removed if you reboot the device.\r\n\r\n- If everything is configured correctly, can you try with https://github.com/tensorflow/examples/tree/master/lite/examples/image_classification/android or other tensorflow lite examples? When I tested with the examples, it worked well.\r\n", "Hi @hajuho ,\r\n\r\nThanks a lot for the quick reply. Here are some of the observations in relation to your comment.\r\n\r\n> Can you see 'runInference' trace while you cannot see per-operator profiling result?\r\n\r\nYes I'm able to see the \"runInference\" trace when I'm doing a systrace.\r\n\r\n>Did you use org.tensorflow:tensorflow-lite:0.0.0-nightly for dependency? tensorflow-lite:2.3.0 or older stable aar libraries don't have this feature.\r\n\r\nI was using a stable build of the aar file. I changed it to ``` implementation 'org.tensorflow:tensorflow-lite:0.0.0-nightly' ```  \r\n\r\n> Is the nightly library is up-to-date version? In your app's build.gradle file add 'changing = true', to make sure the library is automatically refreshed.\r\nimplementation('org.tensorflow:tensorflow-lite:0.0.0-nightly') { changing = true }\r\n\r\nI was not using the nightly library and thus never used this flag. I have now included the flag.\r\n\r\n> Did you run the command 'adb shell setprop debug.tflite.trace 1' before you started profiler?\r\nFYI, this property value is removed if you reboot the device.\r\n\r\nNo, I was not using any such command and I have used this command now and it's now **showing** me all of the layers and timing of each and every layer.\r\n\r\nI still have some doubt. The inference I did was for some 100 frames or such and continuously is the timing which is reported is cumulative or it is average over all of the runs. Moreover if I want to see the timing for only one of the frames is there nay method to do it for only one run?\r\n\r\nSorry I closed the issue by mistake and thus reopening the issue. Thanks a lot for your help.\r\n", "Hi Anidh,\r\nI guess you may see a result like https://www.tensorflow.org/lite/performance/images/as_traces.png\r\nThe result windows of CPU profile consists of two panes. The left one is timeline view of traces and the right one is analysis report.\r\nIf you see the 'All threads' tab of analysis report, it shows the cumulative timing values.\r\nYou can click each section of running in the left pane. For example, if you click one frame of the 'runInference' sections, there will be a 'runInference' tab on the right pane and it will show the report for only that frame including children sections such as tflite op invocations. Moreover, if you click another frame of 'runInference' sections, the analysis report will show the value for the new frame.", "> Hi Anidh,\r\n> I guess you may see a result like https://www.tensorflow.org/lite/performance/images/as_traces.png\r\n> The result windows of CPU profile consists of two panes. The left one is timeline view of traces and the right one is analysis report.\r\n> If you see the 'All threads' tab of analysis report, it shows the cumulative timing values.\r\n> You can click each section of running in the left pane. For example, if you click one frame of the 'runInference' sections, there will be a 'runInference' tab on the right pane and it will show the report for only that frame including children sections such as tflite op invocations. Moreover, if you click another frame of 'runInference' sections, the analysis report will show the value for the new frame.\r\n\r\n@hajuho \r\n\r\nThanks a lot. The steps you mentioned worked perfectly. "]}, {"number": 42654, "title": "TFLite C++ API docs seems broken", "body": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/lite/api_docs/cc\r\n\r\n## Description of issue (what needs changing):\r\n\r\nThe C++ API references for TFLite are missing many important components on tensorflow.org. For example, the docs for `tflite::FlatBufferModel` and `tflite::InterpreterBuilder` are completely gone, which used to be there the last time I checked, about two months ago.\r\n", "comments": ["@katherlee Looks like this was resolved. I have checked all the links on the TF page https://www.tensorflow.org/lite/api_docs/cc . All the links are working.\r\n\r\nPlease verify once and close the issue. Thanks!", "Indeed, thanks!"]}, {"number": 42653, "title": "(esp32) fixes invalid use of struct TfLiteTensor from common.h header", "body": "TF_LITE_STATIC_MEMORY will be set if tflite for uc lib is compiled with that flag.\r\nOtherwise struct TfLiteTensor is broken when used in application code.\r\n\r\nfixes  #42165", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\r\n\r\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\r\nRead the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\r\nCreated a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\r\nLinked to the issue from the PR description\r\n\r\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.", "@gbaned: Pull request is linked with #42165"]}, {"number": 42652, "title": "(esp32) fixes invalid use of struct TfLiteTensor from common.h header.", "body": "Wrongly created pull request. I created a new one.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F42652) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F42652) for more info**.\n\n<!-- need_author_cla -->", "I will create a new pullrequest."]}, {"number": 42651, "title": "Add CMSIS-NN SVDF kernel.", "body": "This pull request adds the optimized version of the (int8) SVDF kernel in CMSIS-NN to TensorFlow Lite Micro.\r\n\r\nThe pull request to CMSIS-NN is still pending, and the CMSIS version in third_party_downloads.inc will need to be updated once that is merged.\r\n\r\nFixes #42650", "comments": ["> This looks great - just one nitpick:\r\n> Since this is the first time we are duplicating the SVDF float code (xtensa_hifimini does not implement a floating point SVDF), do you think we can extract the contents of EvalFLoatSVDF into tensorflow/lite/kernels/internal/reference/svdf.h and share the implementation between the CMSIS-NN kernel and the reference kernel?\r\n> \r\n> Let me know if this sounds reasonable to you.\r\n\r\nSounds good, I'll update the pull request with that change.", "> This looks great - just one nitpick:\r\n> Since this is the first time we are duplicating the SVDF float code (xtensa_hifimini does not implement a floating point SVDF), do you think we can extract the contents of EvalFLoatSVDF into tensorflow/lite/kernels/internal/reference/svdf.h and share the implementation between the CMSIS-NN kernel and the reference kernel?\r\n> \r\n> Let me know if this sounds reasonable to you.\r\n\r\nI had a bit of a look at it, and there seems to already be a EvalFloatSVDF() in tensorflow/kernels/inernal/reference/svdf.h. The difference between that EvalFloatSVDF() and the one found in micro is (among other things) that the micro-version have TfLiteEvalTensor as input. Should I still copy over the EvalFloatSVDF() function from micro to that file?\r\n\r\nEDIT: On second, that won't work due to the fact that tensorflow/lite/kernels/reference/svdf.h depends on tensorflow/lite/kernels/reference/tensor_utils.h, which in turn depends on Eigen. @njeffrie do you have a preferred solution for this? ", "> It looks like we need to do some internal clean-up for the shared SVDF code before it will work for this. Let's land this first then we can internally manage extracting the float version into a common kernel in a future change.\r\n\r\nSounds good! Let me know if you need anything from my end.", "Hi @jenselofsson, I am curious how you use this kernel? Is there a python implementation of svdf that converts to this tf lite op?", "@jenselofsson Can you please resolve conflicts? Thanks!", "@gbaned Done!"]}, {"number": 42650, "title": "Add optimized SVDF kernel from CMSIS-NN", "body": "@tensorflow/micro\r\n\r\n**System information**\r\n- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): NA\r\n- TensorFlow installed from (source or binary): NA\r\n- Tensorflow version (commit SHA if source): NA\r\n- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): ARM Cortex-M\r\n\r\nAn optimized version of SVDF will soon be present in CMSIS-NN, and the \"glue\" code for it should be added to TensorFlow Lite Micro.", "comments": ["Fixed in #42651 ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42650\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42650\">No</a>\n"]}, {"number": 42648, "title": "Calculation of effective scale differs from TFLite implementation in quantize kernel", "body": "@tensorflow/micro\r\n\r\n**Describe the problem**\r\n\r\nIn the quantize kernel the calculation of the effective scale differs slightly between TFLite and TFLu. We found that in some cases this results in single bit differences in output. Is this difference in implementation intentional?\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/de1a269b21cbad035faa095d8ce88fc2d680cf4a/tensorflow/lite/kernels/quantize.cc#L129-L133\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/de1a269b21cbad035faa095d8ce88fc2d680cf4a/tensorflow/lite/micro/kernels/quantize.cc#L75-L79\r\n", "comments": ["Thanks for catching this. This is oversight on our part. I have created a PR to fix this."]}, {"number": 42647, "title": "whether is it better to add class_weight to validation dataset or not?", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 2.x\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\n## set `class_weight` to validation dataset\r\n\r\nIt is common for us to set `class_weight` to something like inverse of class supports  to `Model.fit()` when dealing with imbalance classification problems. And as the code implemented in `tensorflow.python.keras.engine.data_adapter._make_class_weight_map_fn`, `class_weight` will eventually be converted to `sample_weight`.\r\n\r\nHowever, the current implementation of `Model.fit()` only add `class_weight` to the training dataset but not to the validation dataset\r\n\r\n```python\r\n# for training dataset\r\ndata_handler = data_adapter.DataHandler(\r\n  x=x,\r\n  y=y,\r\n  sample_weight=sample_weight,\r\n  batch_size=batch_size,\r\n  steps_per_epoch=steps_per_epoch,\r\n  initial_epoch=initial_epoch,\r\n  epochs=epochs,\r\n  shuffle=shuffle,\r\n  class_weight=class_weight,\r\n  max_queue_size=max_queue_size,\r\n  workers=workers,\r\n  use_multiprocessing=use_multiprocessing,\r\n  model=self,\r\n  steps_per_execution=self._steps_per_execution)\r\n\r\n# for validation dataset\r\nself._eval_data_handler = data_adapter.DataHandler(\r\n    x=val_x,\r\n    y=val_y,\r\n    sample_weight=val_sample_weight,\r\n    batch_size=validation_batch_size or batch_size,\r\n    steps_per_epoch=validation_steps,\r\n    initial_epoch=0,\r\n    epochs=1,\r\n    max_queue_size=max_queue_size,\r\n    workers=workers,\r\n    use_multiprocessing=use_multiprocessing,\r\n    model=self,\r\n    steps_per_execution=self._steps_per_execution)\r\n```\r\n\r\n\r\nwhich will output training loss and validation loss with (maybe) large gap, such as:\r\n\r\n```\r\nEpoch 2/10000\r\n128/128 [==============================] - 63s 489ms/step - loss: 379.6439 - acc: 0.0073 - acc_f1: 0.0077 - cm: 10485.7598 - val_loss: 4.9299 - val_acc: 0.0076 - val_acc_f1: 0.0081 - val_cm: 2621.4399\r\n128/128 [==============================] - 63s 492ms/step - loss: 374.9651 - acc: 0.0078 - acc_f1: 0.0099 - cm: 10485.7598 - val_loss: 4.8990 - val_acc: 0.0078 - val_acc_f1: 0.0120 - val_cm: 2621.4399\r\n```\r\n\r\n**I am wondering whether it is a good practice to add the same `class_weight` parameter to the training dataset and the validation dataset, in order to keep training loss and validation loss with the same scale**.\r\n\r\n\r\n## normalized loss by the sum of `sample_weight`\r\n\r\nAnd by the way, while reducing the loss by the size of a batch, the current loss is normalized by the size of `weighted_loss` (ref. to `tensorflow.python.keras.utils.losses_utils.reduce_weighted_loss`),  **whether is it better to normalize the loss by the sum of `sample_weight`**?\r\n\r\n\r\n\r\n**Will this change the current api? How?**\r\nAlmost no changes.\r\n\r\nFor adding `class_weight` to validation dataset, only add `class_weight=class_weight` when calling `data_adapter.DataHandler`\r\n\r\n```python\r\nself._eval_data_handler = data_adapter.DataHandler(\r\n    x=val_x,\r\n    y=val_y,\r\n    sample_weight=val_sample_weight,\r\n    batch_size=validation_batch_size or batch_size,\r\n    steps_per_epoch=validation_steps,\r\n    initial_epoch=0,\r\n    epochs=1,\r\n    shuffle=shuffle,\r\n    class_weight=class_weight,\r\n    max_queue_size=max_queue_size,\r\n    workers=workers,\r\n    use_multiprocessing=use_multiprocessing,\r\n    model=self,\r\n    steps_per_execution=self._steps_per_execution)\r\n```\r\n\r\n\r\nFor normalizing loss with the sum of `sample_weight`,  only changes the code snippet of `python.keras.utils.losses_utils.compute_weighted_loss`\r\n\r\nfrom \r\n\r\n```python\r\n    ....\r\n    # Apply reduction function to the individual weighted losses.\r\n    loss = reduce_weighted_loss(weighted_losses, reduction)\r\n    # Convert the result back to the input type.\r\n    loss = math_ops.cast(loss, input_dtype)\r\n    return loss\r\n```\r\nto \r\n\r\n```python\r\n   \r\n    if sample_weight is None:\r\n      sample_weight = array_ops.ones_like(losses, dtype=losses.dtype)\r\n   ...\r\n    # Apply reduction function to the individual weighted losses\r\n    if reduction == ReductionV2.NONE:\r\n      loss = weighted_losses\r\n    else:\r\n      loss = math_ops.reduce_sum(weighted_losses)\r\n      if reduction == ReductionV2.SUM_OVER_BATCH_SIZE:\r\n        loss = _safe_mean(loss, math_ops.reduce_sum(sample_weight))\r\n    \r\n    # Convert the result back to the input type.\r\n    loss = math_ops.cast(loss, input_dtype)\r\n    return loss\r\n```\r\n\r\n\r\n**Who will benefit with this feature?**\r\neveryone if it is a good practice.\r\n\r\n**Any Other info.**\r\n", "comments": ["@loveychen You are not supposed to apply weights to your validation set since it is supposed to measure your model's performance. If you'll do that you'll probably get better results for validation but once your model is deployed it will perform worse on new data. Weighting, resampling techniques etc. - they all should be done on the training set only!", "thanks, @gowthamkpr. You are right, the loss gap is not that important, and we should keep our eyes on the performance on new data."]}, {"number": 42646, "title": "Fix dlpack device for int32", "body": "Using BackingDeviceName instead of DeviceName, to set the correct device for int32 tensors\r\nFix https://github.com/tensorflow/tensorflow/issues/41307", "comments": ["I just fixed the lint error. But have no idea about why windows build failed", "Fixed lint problem and merge with the latest master. Hope this could fix the CI errors "]}, {"number": 42645, "title": "ImportError: Traceback (most recent call last) while importing the tensorflow", "body": "**import tensorflow as**\r\nI am getting following error error. Importing at jupyter notebook. Python version is 3.8.3.\r\n\r\n---------------------------------------------------------------------------\r\nImportError                               Traceback (most recent call last)\r\n~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py in <module>\r\n     63   try:\r\n---> 64     from tensorflow.python._pywrap_tensorflow_internal import *\r\n     65   # This try catch logic is because there is no bazel equivalent for py_extension.\r\n\r\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nImportError                               Traceback (most recent call last)\r\n<ipython-input-1-64156d691fe5> in <module>\r\n----> 1 import tensorflow as tf\r\n\r\n~\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py in <module>\r\n     39 import sys as _sys\r\n     40 \r\n---> 41 from tensorflow.python.tools import module_util as _module_util\r\n     42 from tensorflow.python.util.lazy_loader import LazyLoader as _LazyLoader\r\n     43 \r\n\r\n~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py in <module>\r\n     38 # pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\r\n     39 \r\n---> 40 from tensorflow.python.eager import context\r\n     41 \r\n     42 # pylint: enable=wildcard-import\r\n\r\n~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\context.py in <module>\r\n     33 from tensorflow.core.protobuf import config_pb2\r\n     34 from tensorflow.core.protobuf import rewriter_config_pb2\r\n---> 35 from tensorflow.python import pywrap_tfe\r\n     36 from tensorflow.python import tf2\r\n     37 from tensorflow.python.client import pywrap_tf_session\r\n\r\n~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tfe.py in <module>\r\n     26 \r\n     27 # pylint: disable=invalid-import-order,g-bad-import-order, wildcard-import, unused-import\r\n---> 28 from tensorflow.python import pywrap_tensorflow\r\n     29 from tensorflow.python._pywrap_tfe import *\r\n\r\n~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py in <module>\r\n     81 for some common reasons and solutions.  Include the entire stack trace\r\n     82 above this error message when asking for help.\"\"\" % traceback.format_exc()\r\n---> 83   raise ImportError(msg)\r\n     84 \r\n     85 # pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\r\n\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\ssahu\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 64, in <module>\r\n    from tensorflow.python._pywrap_tensorflow_internal import *\r\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.", "comments": ["@ssahu2498,\r\nInstallation issues within the Anaconda environment are tracked in the Anaconda repo.\r\n\r\nCould you please submit a new issue using [this link](https://github.com/ContinuumIO/anaconda-issues/issues) and fill in the template, so that the issue can be tracked there. Thanks!", "I come cross the same problem", "> I come cross the same problem\r\n\r\n@chaizhongming,\r\nCould you please submit a new issue from [this link](https://github.com/tensorflow/tensorflow/issues/new/choose) and fill in the template, so that we can track the issue there. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42645\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42645\">No</a>\n", "Having the same issue currently, it was working yesterday with no issues and today it started giving errors even though I changed nothing. Why's this happening?", "@Khezkid,\r\nCould you please submit a new issue from [this link](https://github.com/tensorflow/tensorflow/issues/new/choose) and fill in the template, so that we can track the issue there. Thanks!\r\n", "![Capture](https://user-images.githubusercontent.com/81622361/112975850-9445d780-916d-11eb-8190-991b62599216.PNG)\r\nON \"ANACONDA.NAVIGATOR\" MAIN PAGE CHANGE THE setting of  \"APPLICATION ON TENSORFLOW OR TF\""]}, {"number": 42644, "title": "what  updates have been made in TF2.0 vs TF1.0 for c++ layer  such as  communication?", "body": "Recently  I  have been doing my model training  based on TF2.2(**without  eager**) and  TF1.10\u3002The result shows the TF2.2 have better performance than  TF1.10,  such as the training speed\u3002\r\nso\uff0cI wanna know  what updates have been made in TF2.2(without eager) to make  my model train faster\uff0csuch  as  communication in c++ layer  or  GPU driver?  \r\nHope to hear from you soon! Thanks!", "comments": ["Thanks for trying TF2 and your feedback. However, This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\nThanks!\r\n"]}, {"number": 42643, "title": "TFLite Int8 Quantization Conversion - There are unresolved custom ops: []", "body": "**Error**\r\n```\r\nRuntimeError: Failed to initialize op resolver for calibration:\r\nThere are unresolved custom ops: []Encountered unresolved custom op: RandomStandardNormal.Node number 0 (RandomStandardNormal) failed to prepare.\r\n```\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (or github SHA if from source): 2.3.0\r\n\r\n\r\n**Command used to run the converter or code if you\u2019re using the Python API**\r\nIf possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n```\r\nimport os, glob\r\nos.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"\r\nimport tensorflow.compat.v1 as tf\r\n\r\nfrom tensorflow.python.client import device_lib\r\nimport numpy as np\r\n\r\nimport faulthandler\r\nfaulthandler.enable()\r\n\r\nimport pdb\r\n\r\npath = os.path.dirname(os.path.abspath(__file__))\r\npb_model_name = \"model.pb\"\r\npb_model_path = os.path.join(path, pb_model_name)\r\n\r\nmodel_name = 'model_int8.tflite'\r\n\r\nif __name__ == '__main__':\r\n  with tf.device(\"/cpu:0\"):\r\n    configuration = tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)\r\n    with tf.Session(config=configuration) as sess:\r\n      converter = tf.lite.TFLiteConverter.from_frozen_graph(\r\n        graph_def_file=pb_model_path,\r\n        # input_arrays=[\"device_0/wav_and_noisy:1\"],\r\n        input_arrays=[\"device_0/wav_and_noisy:1\"],\r\n        output_arrays=[\"device_0/g_ae_1/Tanh\"],\r\n        input_shapes={\"device_0/wav_and_noisy:1\": [100, 16384]}\r\n      )\r\n      converter.allow_custom_ops = True\r\n      # converter.experimental_new_converter = True\r\n      converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8,\r\n                                             tf.lite.OpsSet.SELECT_TF_OPS]\r\n      # converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8,\r\n      #                                        tf.lite.OpsSet.TFLITE_BUILTINS,\r\n      #                                        tf.lite.OpsSet.SELECT_TF_OPS]\r\n      converter.optimizations = [tf.lite.Optimize.DEFAULT]\r\n      # converter.target_spec.supported_types = [tf.int8]\r\n      converter.inference_input_type = tf.int8  # or tf.uint8\r\n      converter.inference_output_type = tf.int8  # or tf.uint8\r\n\r\n      def test():\r\n        pdb.set_trace()\r\n        zeros = np.zeros(shape=(1, 100, 16384), dtype='int8')\r\n        dataset = tf.data.Dataset.from_tensor_slices(zeros).batch(1)\r\n        yield [zeros]\r\n      converter.representative_dataset = test\r\n\r\n      # pdb.set_trace()\r\n      tflite_model = converter.convert()\r\n\r\n      tflite_model_size = open(model_name, 'wb').write(tflite_model)\r\n      print('TFLite Model is %d bytes' % tflite_model_size)\r\n```\r\n\r\nI've tried also including the `TFLITE_BUILTINS` in addition to `TFLITE_BUILTINS_INT8`. In other issues on github, I've seen that adding `SELECT_TF_OPS` solves errors similar to mine, but it did not fix it for me. \r\n\r\n**The output from the converter invocation**\r\n\r\n```\r\n2020-08-25 02:22:18.873117: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\r\n2020-08-25 02:22:18.873149: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\r\nWARNING:tensorflow:From convert_model_to_tflite_int8.py:24: experimental_run_functions_eagerly (from tensorflow.python.eager.def_function) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.config.run_functions_eagerly` instead of the experimental version.\r\n2020-08-25 02:22:19.959195: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\r\n2020-08-25 02:22:19.959229: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\r\n2020-08-25 02:22:19.959253: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-5-134): /proc/driver/nvidia/version does not exist\r\n2020-08-25 02:22:19.959493: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2020-08-25 02:22:19.984669: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2999995000 Hz\r\n2020-08-25 02:22:19.984899: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3d64580 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-08-25 02:22:19.984922: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2020-08-25 02:22:19.987088: I tensorflow/core/common_runtime/direct_session.cc:360] Device mapping:\r\n/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\r\n\r\n2020-08-25 02:22:22.412284: I tensorflow/core/grappler/devices.cc:69] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\r\n2020-08-25 02:22:22.412445: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\r\n2020-08-25 02:22:23.196542: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: graph_to_optimize\r\n2020-08-25 02:22:23.196595: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.005ms.\r\n2020-08-25 02:22:23.196614: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-08-25 02:22:24.510075: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:313] Ignored output_format.\r\n2020-08-25 02:22:24.510118: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:316] Ignored drop_control_dependency.\r\nTraceback (most recent call last):\r\n  File \"convert_model_to_tflite_int8.py\", line 102, in <module>\r\n    tflite_model = converter.convert()\r\n  File \"../python3.6/site-packages/tensorflow/lite/python/lite.py\", line 1970, in convert\r\n    return super(TFLiteConverter, self).convert()\r\n  File \"../python3.6/site-packages/tensorflow/lite/python/lite.py\", line 1339, in convert\r\n    result = self._calibrate_quantize_model(result, **flags)\r\n  File \"../python3.6/site-packages/tensorflow/lite/python/lite.py\", line 452, in _calibrate_quantize_model\r\n    inference_output_type, allow_float, activations_type)\r\n  File \"../python3.6/site-packages/tensorflow/lite/python/optimize/calibrator.py\", line 91, in calibrate_and_quantize\r\n    self._calibrator.Prepare([list(s.shape) for s in sample])\r\nRuntimeError: Failed to initialize op resolver for calibration:\r\nThere are unresolved custom ops: []Encountered unresolved custom op: RandomStandardNormal.Node number 0 (RandomStandardNormal) failed to prepare.\r\n```\r\n\r\n**Also, please include a link to the saved model or GraphDef**\r\nUnfortunately cannot provide publicly at this time. I can share privately if needed.\r\n\r\n**Failure details**\r\nThe conversion hits a RuntimeError and stops. From PDB (below) I know it is hitting my `representative_dataset` function twice before crashing.\r\n\r\n**Any other info / logs**\r\n\r\nWith a break point inside my `representative_dataset` function:\r\n```\r\n2020-08-25 02:29:39.675277: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\r\n2020-08-25 02:29:39.675311: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\r\nWARNING:tensorflow:From /home/ubuntu/denoise-gst/denoise_deploy/inference_module/convert_model_to_tflite_int8.py:18: experimental_run_functions_eagerly (from tensorflow.python.eager.def_function) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.config.run_functions_eagerly` instead of the experimental version.\r\n2020-08-25 02:29:40.563260: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\r\n2020-08-25 02:29:40.563287: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\r\n2020-08-25 02:29:40.563307: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-5-134): /proc/driver/nvidia/version does not exist\r\n2020-08-25 02:29:40.563535: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2020-08-25 02:29:40.588667: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2999995000 Hz\r\n2020-08-25 02:29:40.588892: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3c1a8b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-08-25 02:29:40.588920: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2020-08-25 02:29:40.591168: I tensorflow/core/common_runtime/direct_session.cc:360] Device mapping:\r\n/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\r\n\r\n2020-08-25 02:29:42.998639: I tensorflow/core/grappler/devices.cc:69] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\r\n2020-08-25 02:29:42.998794: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\r\n2020-08-25 02:29:43.773981: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: graph_to_optimize\r\n2020-08-25 02:29:43.774020: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.006ms.\r\n2020-08-25 02:29:43.774031: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-08-25 02:29:45.082195: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:313] Ignored output_format.\r\n2020-08-25 02:29:45.082241: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:316] Ignored drop_control_dependency.\r\n> /home/ubuntu/denoise-gst/denoise_deploy/inference_module/convert_model_to_tflite_int8.py(93)test()\r\n-> zeros = np.zeros(shape=(1, 100, 16384), dtype='int8')\r\n(Pdb) n\r\n> /home/ubuntu/denoise-gst/denoise_deploy/inference_module/convert_model_to_tflite_int8.py(94)test()\r\n-> dataset = tf.data.Dataset.from_tensor_slices(zeros).batch(1)\r\n(Pdb)\r\n> /home/ubuntu/denoise-gst/denoise_deploy/inference_module/convert_model_to_tflite_int8.py(97)test()\r\n-> yield [zeros]\r\n(Pdb)\r\nGeneratorExit\r\n> /home/ubuntu/denoise-gst/denoise_deploy/inference_module/convert_model_to_tflite_int8.py(97)test()\r\n-> yield [zeros]\r\n(Pdb)\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python3.6/pdb.py\", line 1667, in main\r\n    pdb._runscript(mainpyfile)\r\n  File \"/usr/lib/python3.6/pdb.py\", line 1548, in _runscript\r\n    self.run(statement)\r\n  File \"/usr/lib/python3.6/bdb.py\", line 434, in run\r\n    exec(cmd, globals, locals)\r\n  File \"<string>\", line 1, in <module>\r\n  File \"/home/ubuntu/denoise-gst/denoise_deploy/inference_module/convert_model_to_tflite_int8.py\", line 18, in <module>\r\n    '''\r\n  File \".../python3.6/site-packages/tensorflow/lite/python/lite.py\", line 1970, in convert\r\n    return super(TFLiteConverter, self).convert()\r\n  File \".../python3.6/site-packages/tensorflow/lite/python/lite.py\", line 1339, in convert\r\n    result = self._calibrate_quantize_model(result, **flags)\r\n  File \".../python3.6/site-packages/tensorflow/lite/python/lite.py\", line 452, in _calibrate_quantize_model\r\n    inference_output_type, allow_float, activations_type)\r\n  File \".../python3.6/site-packages/tensorflow/lite/python/optimize/calibrator.py\", line 91, in calibrate_and_quantize\r\n    self._calibrator.Prepare([list(s.shape) for s in sample])\r\nRuntimeError: Failed to initialize op resolver for calibration:\r\nThere are unresolved custom ops: []Encountered unresolved custom op: RandomStandardNormal.Node number 0 (RandomStandardNormal) failed to prepare.\r\n\r\nUncaught exception. Entering post mortem debugging\r\nRunning 'cont' or 'step' will restart the program\r\n> .../python3.6/site-packages/tensorflow/lite/python/optimize/calibrator.py(91)calibrate_and_quantize()\r\n-> self._calibrator.Prepare([list(s.shape) for s in sample])\r\n```\r\n", "comments": ["@CoreyCole Can you please share a standalone code and *.pb file. [Here](https://colab.research.google.com/gist/jvishnuvardhan/a35756d09a46c7c82b8dd6c449bea591/untitled12.ipynb) is a gist that is throwing different error. thanks!", "Could you try the conversion with tf-nightly version? We've landed a fix for supporting integer eight kernels with Flex operators recently.", "Thank you for the support @jvishnuvardhan and @abattery\r\n\r\nI believe turned out to be a problem with how I was exporting the saved model before further converting to tflite. By using the correct input node/shape and upgrading to tensorflow==2.3.0 the problem has gone away.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42643\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42643\">No</a>\n"]}, {"number": 42642, "title": "Add preliminary methods to env class", "body": "This PR adds new methods with transaction support to Env class. A follow up PR will forward non-transactional API to transactional API with nullptr. This is necessary to workaround issues described in PR #41615", "comments": ["@samikama does anything use the new functionality? how does it relate to https://github.com/tensorflow/community/pull/277? Adding use case specific arguments to most file system APIs sets a bad precedent and I would like to revert this change.", "@jsimsa Yes. It is still waiting for you some PRs to be merged in to the upstream. Implementation was finished last year but since it was deemed too big, it was chunked into smaller segments. But that lead to delays in the review process.\r\n\r\nAlso can you be a bit more specific? Most io operations rely on transactions. Some filesystems hide it in OS level api (such as in kernel calls) however it is always there. I do not think this is use case specific and allows extension of data access to data stores than other posix file systems.\r\n\r\nhttps://github.com/tensorflow/community/pull/277 is a different matter. It allows users to tune the filesystem settings for their use cases. Current implementations of data i/o modules have some generic levels of settings which may not be optimal for all use cases. For example, reading a text file for tokens and searching in a video file would require different access patterns and priorities. Likewise, storing a checkpoint file, a debug output and a critical log file would require different buffering mechanisms. In one case. You would want critical log to be unbuffered, checkpoint to be atomic and debug output to with whatever the filesystem defaults.\r\n\r\nContrary to what you think, TF currently has use-case specific code right now, for example, checkpoint saving relies on \"atomic\" move property of the posix filesystem to implement a transactional save of the multiple files. These proposals, add formal api for such operations so that other data sources do not have to solve \"create tmp dir, save checkpoints into tmp dir, rename tmp dir\"\r\nand map it to their model of transactions.\r\n\r\nPerhaps you can tell me what is your point of view. I may be missing something.\r\n\r\n", "Thank you for your response. Please disregard https://github.com/tensorflow/tensorflow/commit/ab4922b33e0c482c67683da9c8e58cf06aaba56e, my intention was to wait for your response and the CL was submitted by accident. I will roll it back.\r\n\r\nMy main objection to your changes is that introducing `TransactionToken` to several APIs is not maintainable approach. Every time we would need to do something like that, the number of possible endpoints to update either doubles, or you need to update user code. Instead, an approach which uses an extensible `Options` argument should be used instead.", "Thanks and I agree in complexity issue. May be I am missing something but  tensorflow/community#277 can not satisfy the requirements of transactional file systems. For example, how does it solve checkpoint saving? In order to emulate an atomic transaction for posix file system, TF uses atomic nature of the move operation. However move operation is not atomic in all file systems, especially non-blocking, asynchronous file systems and databases etc. Unfortunately these two approaches are orthogonal and one can not replace another. Can you see a way satisfying the requirements? I believe these two RFCs are essential in building up large infrastructure and allowing more storage solutions to be used as input and/or output of the TF workflow. Of course, just for running TF with local filesystem based i/o this is a bit heavy weight, move trick is sufficient to save checkpoints without corrupting rest of the workflow whenever atomic move is available.\r\n", "I don't think you are missing anything. Again, I am not questioning whether the functionality the RFCs are proposing is useful (it is). All I am saying that I hope we could replace the `TransactionToken` argument with an options-based approach. In particular, replacing:\r\n\r\n```\r\nStatus NewRandomAccessFile(const std::string& fname, TransactionToken* token, std::unique_ptr<RandomAccessFile>* result);\r\n```\r\nwith\r\n```\r\nStatus NewRandomAccessFile(const std::string& fname, Options options, std::unique_ptr<RandomAccessFile>* result);\r\n```\r\nwhere `Options` is an object that can be extended in the future with additional functionality without requiring introducing new overrides `NewRandomAccessFile` or updating all callsites of `NewRandomAccessFile`.", "For the specific method you mentioned it is probably ok. But it also means options must be added to all i/o methods and all i/o layers need to be able to decode the options to get the transaction information even if they don't implement options. Since options would be passed for different type of operations, the I would worry that either it is going to be an opaque structure that changes meaning depending on the call which means bugs everywhere, or it is going to be a huge structure too heavy weight to construct, pass around and decode. Do you have an implementation with options approach that would satisfy these requirements. I am worried that it may not work in all cases and then cause a bigger problem in the ecosystem.\r\n", "Google has an implementation that satisfies these requirements but it is not externally available. It represents options as a generic proto, which is a union of API specific options. That way, different APIs only need to understand options meant for them.\r\n\r\nIn any case, this was a drive by comment because I think adding a use case specific argument to a large number of file system API sets a bad precedent and is not scalable. The amount of effort needed to use a scalable approach might be greater now (relative to the alternative), but its cost will be amortized over future changes that introduce additional options. This is actually how I came across this -- I want to add an option to one of the methods and if I follow the precedent of `TransactionToken`, we would end up with 4 methods (as default arguments to virtual methods are discouraged because of their [surprising behavior](https://www.geeksforgeeks.org/output-of-c-program-set-12-2/)).", "Would it be possible to describe what you mean in an RFC. Perhaps others not in Google want to comment. It may be possible that we do not see all the use cases and external parties may be affected from such a change. I am not against changing these but I would prefer it more eyes go through that. Transactions went through some scrutiny and in general people seemed ok with any potential side effects,", "I unfortunately won't have bandwidth for this in the foreseeable future. This plus the fact I have missed the opportunity to provide my feedback during the RFC period, means that I will hold my peace.", "I understand. Though I would really like to see your proposal. I am all for improving the design. I also feel your pain in modification since I went through that myself. If you have time, I encourage you to consider preparing an RFC so that we can take a look in the design and possibly implement it if everyone is happy. I can try to pitch in at implementation part."]}, {"number": 42641, "title": "TypeError: can't pickle _thread.RLock objects: SKlearn/Tensorflow/Third Party content interference?", "body": "For Neural-Network regression prediction task cross_val_predict from SKlearn throws the error (full error further below, below the model used)\r\n\r\n```\r\nTypeError: can't pickle _thread.RLock objects\r\n```\r\n\r\nwhen utilizing it with input data of form \r\n\r\n```\r\nX_train.shape=1200,18,15 \r\ny_train.shape=1200,18,1 \r\n```\r\n\r\nand the following in NN\r\n\r\n```\r\ndef twds_model(layer1=32, layer2=32, layer3=16, dropout_rate=0.5, optimizer='Adam'\r\n                    , learning_rate=0.001, activation='relu', loss='mse'):#, n_jobs=1):layer3=80, \r\n    \r\n    model = Sequential()\r\n    model.add(Bidirectional(GRU(layer1, return_sequences=True),input_shape=(X_train.shape[1],X_train.shape[2])))\r\n    model.add(AveragePooling1D(2))\r\n    model.add(Conv1D(layer2, 3, activation=activation, padding='same', \r\n               name='extractor'))\r\n    model.add(Flatten())\r\n    model.add(Dense(layer3,activation=activation))\r\n    model.add(Dropout(dropout_rate))\r\n    model.add(Dense(1))\r\n    model.compile(optimizer=optimizer,loss=loss)\r\n    return model\r\n\r\ntwds_model=twds_model()\r\nprint(twds_model.summary())\r\n```\r\n\r\n```\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\nbidirectional_4 (Bidirection (None, 18, 64)            9216      \r\n_________________________________________________________________\r\naverage_pooling1d_1 (Average (None, 9, 64)             0         \r\n_________________________________________________________________\r\nextractor (Conv1D)           (None, 9, 32)             6176      \r\n_________________________________________________________________\r\nflatten_1 (Flatten)          (None, 288)               0         \r\n_________________________________________________________________\r\ndense_3 (Dense)              (None, 16)                4624      \r\n_________________________________________________________________\r\ndropout_4 (Dropout)          (None, 16)                0         \r\n_________________________________________________________________\r\ndense_4 (Dense)              (None, 1)                 17        \r\n=================================================================\r\nTotal params: 20,033\r\nTrainable params: 20,033\r\nNon-trainable params: 0\r\n_________________________________________________________________\r\nNone\r\n```\r\n\r\nand \r\n\r\n```\r\nmodel_twds=KerasRegressor(build_fn=twds_model, batch_size=144,epochs=6)#12\r\n```\r\n\r\nThe error was mentioned at [SKlearn](https://github.com/scikit-learn/scikit-learn/issues/18171), but it was contemplated that the error is likely to be on the Tensorflow site or that it might be caused by third party content - however, I have no idea where this content might be involved.\r\n\r\nThe complete error: \r\n\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-603-37b55dfd53fd> in <module>\r\n----> 1 GridLSTM.fit(X_train, y_train)\r\n\r\n~\\Anaconda3\\envs\\Tensorflow\\lib\\site-packages\\sklearn\\utils\\validation.py in inner_f(*args, **kwargs)\r\n     70                           FutureWarning)\r\n     71         kwargs.update({k: arg for k, arg in zip(sig.parameters, args)})\r\n---> 72         return f(**kwargs)\r\n     73     return inner_f\r\n     74 \r\n\r\n~\\Anaconda3\\envs\\Tensorflow\\lib\\site-packages\\sklearn\\model_selection\\_search.py in fit(self, X, y, groups, **fit_params)\r\n    679         n_splits = cv.get_n_splits(X, y, groups)\r\n    680 \r\n--> 681         base_estimator = clone(self.estimator)\r\n    682 \r\n    683         parallel = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\r\n\r\n~\\Anaconda3\\envs\\Tensorflow\\lib\\site-packages\\sklearn\\utils\\validation.py in inner_f(*args, **kwargs)\r\n     70                           FutureWarning)\r\n     71         kwargs.update({k: arg for k, arg in zip(sig.parameters, args)})\r\n---> 72         return f(**kwargs)\r\n     73     return inner_f\r\n     74 \r\n\r\n~\\Anaconda3\\envs\\Tensorflow\\lib\\site-packages\\sklearn\\base.py in clone(estimator, safe)\r\n     85     new_object_params = estimator.get_params(deep=False)\r\n     86     for name, param in new_object_params.items():\r\n---> 87         new_object_params[name] = clone(param, safe=False)\r\n     88     new_object = klass(**new_object_params)\r\n     89     params_set = new_object.get_params(deep=False)\r\n\r\n~\\Anaconda3\\envs\\Tensorflow\\lib\\site-packages\\sklearn\\utils\\validation.py in inner_f(*args, **kwargs)\r\n     70                           FutureWarning)\r\n     71         kwargs.update({k: arg for k, arg in zip(sig.parameters, args)})\r\n---> 72         return f(**kwargs)\r\n     73     return inner_f\r\n     74 \r\n\r\n~\\Anaconda3\\envs\\Tensorflow\\lib\\site-packages\\sklearn\\base.py in clone(estimator, safe)\r\n     69     elif not hasattr(estimator, 'get_params') or isinstance(estimator, type):\r\n     70         if not safe:\r\n---> 71             return copy.deepcopy(estimator)\r\n     72         else:\r\n     73             if isinstance(estimator, type):\r\n\r\n~\\Anaconda3\\envs\\Tensorflow\\lib\\copy.py in deepcopy(x, memo, _nil)\r\n    178                     y = x\r\n    179                 else:\r\n--> 180                     y = _reconstruct(x, memo, *rv)\r\n    181 \r\n    182     # If is its own copy, don't memoize.\r\n\r\n~\\Anaconda3\\envs\\Tensorflow\\lib\\copy.py in _reconstruct(x, memo, func, args, state, listiter, dictiter, deepcopy)\r\n    278     if state is not None:\r\n    279         if deep:\r\n--> 280             state = deepcopy(state, memo)\r\n    281         if hasattr(y, '__setstate__'):\r\n    282             y.__setstate__(state)\r\n\r\n~\\Anaconda3\\envs\\Tensorflow\\lib\\copy.py in deepcopy(x, memo, _nil)\r\n    148     copier = _deepcopy_dispatch.get(cls)\r\n    149     if copier:\r\n--> 150         y = copier(x, memo)\r\n    151     else:\r\n    152         try:\r\n\r\n~\\Anaconda3\\envs\\Tensorflow\\lib\\copy.py in _deepcopy_dict(x, memo, deepcopy)\r\n    238     memo[id(x)] = y\r\n    239     for key, value in x.items():\r\n--> 240         y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n    241     return y\r\n    242 d[dict] = _deepcopy_dict\r\n\r\n~\\Anaconda3\\envs\\Tensorflow\\lib\\copy.py in deepcopy(x, memo, _nil)\r\n    148     copier = _deepcopy_dispatch.get(cls)\r\n    149     if copier:\r\n--> 150         y = copier(x, memo)\r\n    151     else:\r\n    152         try:\r\n\r\n~\\Anaconda3\\envs\\Tensorflow\\lib\\copy.py in _deepcopy_list(x, memo, deepcopy)\r\n    213     append = y.append\r\n    214     for a in x:\r\n--> 215         append(deepcopy(a, memo))\r\n    216     return y\r\n    217 d[list] = _deepcopy_list\r\n\r\n~\\Anaconda3\\envs\\Tensorflow\\lib\\copy.py in deepcopy(x, memo, _nil)\r\n    178                     y = x\r\n    179                 else:\r\n--> 180                     y = _reconstruct(x, memo, *rv)\r\n    181 \r\n    182     # If is its own copy, don't memoize.\r\n\r\n~\\Anaconda3\\envs\\Tensorflow\\lib\\copy.py in _reconstruct(x, memo, func, args, state, listiter, dictiter, deepcopy)\r\n    278     if state is not None:\r\n    279         if deep:\r\n--> 280             state = deepcopy(state, memo)\r\n    281         if hasattr(y, '__setstate__'):\r\n    282             y.__setstate__(state)\r\n\r\n~\\Anaconda3\\envs\\Tensorflow\\lib\\copy.py in deepcopy(x, memo, _nil)\r\n    148     copier = _deepcopy_dispatch.get(cls)\r\n    149     if copier:\r\n--> 150         y = copier(x, memo)\r\n    151     else:\r\n    152         try:\r\n\r\n~\\Anaconda3\\envs\\Tensorflow\\lib\\copy.py in _deepcopy_dict(x, memo, deepcopy)\r\n    238     memo[id(x)] = y\r\n    239     for key, value in x.items():\r\n--> 240         y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n    241     return y\r\n    242 d[dict] = _deepcopy_dict\r\n\r\n~\\Anaconda3\\envs\\Tensorflow\\lib\\copy.py in deepcopy(x, memo, _nil)\r\n    148     copier = _deepcopy_dispatch.get(cls)\r\n    149     if copier:\r\n--> 150         y = copier(x, memo)\r\n    151     else:\r\n    152         try:\r\n\r\n~\\Anaconda3\\envs\\Tensorflow\\lib\\copy.py in _deepcopy_list(x, memo, deepcopy)\r\n    213     append = y.append\r\n    214     for a in x:\r\n--> 215         append(deepcopy(a, memo))\r\n    216     return y\r\n    217 d[list] = _deepcopy_list\r\n\r\n~\\Anaconda3\\envs\\Tensorflow\\lib\\copy.py in deepcopy(x, memo, _nil)\r\n    178                     y = x\r\n    179                 else:\r\n--> 180                     y = _reconstruct(x, memo, *rv)\r\n    181 \r\n    182     # If is its own copy, don't memoize.\r\n\r\n~\\Anaconda3\\envs\\Tensorflow\\lib\\copy.py in _reconstruct(x, memo, func, args, state, listiter, dictiter, deepcopy)\r\n    278     if state is not None:\r\n    279         if deep:\r\n--> 280             state = deepcopy(state, memo)\r\n    281         if hasattr(y, '__setstate__'):\r\n    282             y.__setstate__(state)\r\n\r\n~\\Anaconda3\\envs\\Tensorflow\\lib\\copy.py in deepcopy(x, memo, _nil)\r\n    148     copier = _deepcopy_dispatch.get(cls)\r\n    149     if copier:\r\n--> 150         y = copier(x, memo)\r\n    151     else:\r\n    152         try:\r\n\r\n~\\Anaconda3\\envs\\Tensorflow\\lib\\copy.py in _deepcopy_dict(x, memo, deepcopy)\r\n    238     memo[id(x)] = y\r\n    239     for key, value in x.items():\r\n--> 240         y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n    241     return y\r\n    242 d[dict] = _deepcopy_dict\r\n\r\n~\\Anaconda3\\envs\\Tensorflow\\lib\\copy.py in deepcopy(x, memo, _nil)\r\n    178                     y = x\r\n    179                 else:\r\n--> 180                     y = _reconstruct(x, memo, *rv)\r\n    181 \r\n    182     # If is its own copy, don't memoize.\r\n\r\n~\\Anaconda3\\envs\\Tensorflow\\lib\\copy.py in _reconstruct(x, memo, func, args, state, listiter, dictiter, deepcopy)\r\n    278     if state is not None:\r\n    279         if deep:\r\n--> 280             state = deepcopy(state, memo)\r\n    281         if hasattr(y, '__setstate__'):\r\n    282             y.__setstate__(state)\r\n\r\n~\\Anaconda3\\envs\\Tensorflow\\lib\\copy.py in deepcopy(x, memo, _nil)\r\n    148     copier = _deepcopy_dispatch.get(cls)\r\n    149     if copier:\r\n--> 150         y = copier(x, memo)\r\n    151     else:\r\n    152         try:\r\n\r\n~\\Anaconda3\\envs\\Tensorflow\\lib\\copy.py in _deepcopy_dict(x, memo, deepcopy)\r\n    238     memo[id(x)] = y\r\n    239     for key, value in x.items():\r\n--> 240         y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n    241     return y\r\n    242 d[dict] = _deepcopy_dict\r\n\r\n~\\Anaconda3\\envs\\Tensorflow\\lib\\copy.py in deepcopy(x, memo, _nil)\r\n    178                     y = x\r\n    179                 else:\r\n--> 180                     y = _reconstruct(x, memo, *rv)\r\n    181 \r\n    182     # If is its own copy, don't memoize.\r\n\r\n~\\Anaconda3\\envs\\Tensorflow\\lib\\copy.py in _reconstruct(x, memo, func, args, state, listiter, dictiter, deepcopy)\r\n    278     if state is not None:\r\n    279         if deep:\r\n--> 280             state = deepcopy(state, memo)\r\n    281         if hasattr(y, '__setstate__'):\r\n    282             y.__setstate__(state)\r\n\r\n~\\Anaconda3\\envs\\Tensorflow\\lib\\copy.py in deepcopy(x, memo, _nil)\r\n    148     copier = _deepcopy_dispatch.get(cls)\r\n    149     if copier:\r\n--> 150         y = copier(x, memo)\r\n    151     else:\r\n    152         try:\r\n\r\n~\\Anaconda3\\envs\\Tensorflow\\lib\\copy.py in _deepcopy_dict(x, memo, deepcopy)\r\n    238     memo[id(x)] = y\r\n    239     for key, value in x.items():\r\n--> 240         y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n    241     return y\r\n    242 d[dict] = _deepcopy_dict\r\n\r\n~\\Anaconda3\\envs\\Tensorflow\\lib\\copy.py in deepcopy(x, memo, _nil)\r\n    178                     y = x\r\n    179                 else:\r\n--> 180                     y = _reconstruct(x, memo, *rv)\r\n    181 \r\n    182     # If is its own copy, don't memoize.\r\n\r\n~\\Anaconda3\\envs\\Tensorflow\\lib\\copy.py in _reconstruct(x, memo, func, args, state, listiter, dictiter, deepcopy)\r\n    278     if state is not None:\r\n    279         if deep:\r\n--> 280             state = deepcopy(state, memo)\r\n    281         if hasattr(y, '__setstate__'):\r\n    282             y.__setstate__(state)\r\n\r\n~\\Anaconda3\\envs\\Tensorflow\\lib\\copy.py in deepcopy(x, memo, _nil)\r\n    148     copier = _deepcopy_dispatch.get(cls)\r\n    149     if copier:\r\n--> 150         y = copier(x, memo)\r\n    151     else:\r\n    152         try:\r\n\r\n~\\Anaconda3\\envs\\Tensorflow\\lib\\copy.py in _deepcopy_dict(x, memo, deepcopy)\r\n    238     memo[id(x)] = y\r\n    239     for key, value in x.items():\r\n--> 240         y[deepcopy(key, memo)] = deepcopy(value, memo)\r\n    241     return y\r\n    242 d[dict] = _deepcopy_dict\r\n\r\n~\\Anaconda3\\envs\\Tensorflow\\lib\\copy.py in deepcopy(x, memo, _nil)\r\n    167                     reductor = getattr(x, \"__reduce_ex__\", None)\r\n    168                     if reductor:\r\n--> 169                         rv = reductor(4)\r\n    170                     else:\r\n    171                         reductor = getattr(x, \"__reduce__\", None)\r\n\r\nTypeError: can't pickle _thread.RLock objects\r\n\r\n\r\n```\r\nThe versions used:\r\n\r\n```\r\nPackage                  Version\r\n------------------------ ---------------\r\n-                        nsorflow-gpu\r\n-ensorflow-gpu           2.3.0\r\n-rotobuf                 3.11.3\r\nabsl-py                  0.9.0\r\nantlr4-python3-runtime   4.8\r\nasn1crypto               1.3.0\r\nastor                    0.7.1\r\nastropy                  3.2.1\r\nastunparse               1.6.3\r\nattrs                    19.3.0\r\naudioread                2.1.8\r\nautopep8                 1.5.3\r\nbackcall                 0.1.0\r\nbeautifulsoup4           4.9.0\r\nbezier                   0.8.0\r\nbkcharts                 0.2\r\nbleach                   3.1.4\r\nblis                     0.2.4\r\nbokeh                    1.1.0\r\nboto3                    1.9.253\r\nbotocore                 1.12.253\r\nBottleneck               1.3.2\r\ncachetools               4.1.0\r\ncertifi                  2020.4.5.1\r\ncffi                     1.14.0\r\nchardet                  3.0.4\r\nclick                    6.7\r\ncloudpickle              0.5.3\r\ncmdstanpy                0.4.0\r\ncolor                    0.1\r\ncolorama                 0.4.3\r\ncolorcet                 0.9.1\r\nconvertdate              2.2.1\r\ncopulas                  0.2.5\r\ncryptography             2.8\r\nctgan                    0.2.1\r\ncycler                   0.10.0\r\ncymem                    2.0.2\r\nCython                   0.29.17\r\ndash                     0.26.0\r\ndash-core-components     0.27.2\r\ndash-html-components     0.11.0\r\ndash-renderer            0.13.2\r\ndask                     0.18.1\r\ndataclasses              0.6\r\ndatashader               0.7.0\r\ndatashape                0.5.2\r\ndatawig                  0.1.10\r\ndeap                     1.3.0\r\ndecorator                4.4.2\r\ndefusedxml               0.6.0\r\ndeltapy                  0.1.1\r\ndill                     0.2.9\r\ndistributed              1.22.1\r\ndocutils                 0.14\r\nentrypoints              0.3\r\nephem                    3.7.7.1\r\net-xmlfile               1.0.1\r\nexrex                    0.10.5\r\nFaker                    4.0.3\r\nfastai                   1.0.60\r\nfastprogress             0.2.2\r\nfbprophet                0.6\r\nfire                     0.3.1\r\nFlask                    1.0.2\r\nFlask-Compress           1.4.0\r\nfuture                   0.17.1\r\ngast                     0.3.3\r\ngeojson                  2.4.1\r\ngeomet                   0.2.0.post2\r\ngoogle-auth              1.14.0\r\ngoogle-auth-oauthlib     0.4.1\r\ngoogle-pasta             0.2.0\r\ngplearn                  0.4.1\r\ngraphviz                 0.13.2\r\ngrpcio                   1.29.0\r\nh5py                     2.10.0\r\nHeapDict                 1.0.0\r\nholidays                 0.10.2\r\nholoviews                1.12.1\r\nhtml2text                2018.1.9\r\nhyperas                  0.4.1\r\nhyperopt                 0.1.2\r\nidna                     2.6\r\nimageio                  2.5.0\r\nimbalanced-learn         0.3.3\r\nimblearn                 0.0\r\nimportlib-metadata       1.5.0\r\nimpyute                  0.0.8\r\nipykernel                5.1.4\r\nipython                  7.13.0\r\nipython-genutils         0.2.0\r\nipywidgets               7.5.1\r\nitsdangerous             0.24\r\njdcal                    1.4\r\njedi                     0.16.0\r\nJinja2                   2.11.1\r\njmespath                 0.9.5\r\njoblib                   0.13.2\r\njsonschema               3.2.0\r\njupyter                  1.0.0\r\njupyter-client           6.1.2\r\njupyter-console          6.0.0\r\njupyter-core             4.6.3\r\nKeras                    2.4.3\r\nKeras-Applications       1.0.8\r\nKeras-Preprocessing      1.1.2\r\nkeras-rectified-adam     0.17.0\r\nkiwisolver               1.2.0\r\nkorean-lunar-calendar    0.2.1\r\nlibrosa                  0.7.2\r\nllvmlite                 0.32.1\r\nlml                      0.0.1\r\nlocket                   0.2.0\r\nLunarCalendar            0.0.9\r\nMarkdown                 2.6.11\r\nMarkupSafe               1.1.1\r\nmatplotlib               3.2.1\r\nmissingpy                0.2.0\r\nmistune                  0.8.4\r\nmkl-fft                  1.0.15\r\nmkl-random               1.1.0\r\nmkl-service              2.3.0\r\nmock                     4.0.2\r\nmsgpack                  0.5.6\r\nmultipledispatch         0.6.0\r\nmurmurhash               1.0.2\r\nmxnet                    1.4.1\r\nnb-conda                 2.2.1\r\nnb-conda-kernels         2.2.3\r\nnbconvert                5.6.1\r\nnbformat                 5.0.4\r\nnbstripout               0.3.7\r\nnetworkx                 2.1\r\nnotebook                 6.0.3\r\nnumba                    0.49.1\r\nnumexpr                  2.7.1\r\nnumpy                    1.18.5\r\noauthlib                 3.1.0\r\nolefile                  0.46\r\nopencv-python            4.2.0.34\r\nopenpyxl                 2.5.5\r\nopt-einsum               3.2.1\r\npackaging                20.3\r\npandas                   1.0.3\r\npandasvault              0.0.3\r\npandocfilters            1.4.2\r\nparam                    1.9.0\r\nparso                    0.6.2\r\npartd                    0.3.8\r\npatsy                    0.5.1\r\npbr                      5.1.3\r\npickleshare              0.7.5\r\nPillow                   7.0.0\r\npip                      20.2.2\r\nplac                     0.9.6\r\nplotly                   4.7.1\r\nplotly-express           0.4.1\r\npreshed                  2.0.1\r\nprometheus-client        0.7.1\r\nprompt-toolkit           3.0.4\r\nprotobuf                 3.11.3\r\npsutil                   5.4.7\r\npy                       1.8.0\r\npyasn1                   0.4.8\r\npyasn1-modules           0.2.8\r\npycodestyle              2.6.0\r\npycparser                2.20\r\npyct                     0.4.5\r\npyensae                  1.3.839\r\npyexcel                  0.5.8\r\npyexcel-io               0.5.7\r\nPygments                 2.6.1\r\npykalman                 0.9.5\r\nPyMeeus                  0.3.7\r\npymongo                  3.8.0\r\npyOpenSSL                19.1.0\r\npyparsing                2.4.7\r\npypi                     2.1\r\npyquickhelper            1.9.3418\r\npyrsistent               0.16.0\r\nPySocks                  1.7.1\r\npystan                   2.19.1.1\r\npython-dateutil          2.8.1\r\npytz                     2019.3\r\npyviz-comms              0.7.2\r\nPyWavelets               0.5.2\r\npywin32                  227\r\npywinpty                 0.5.7\r\nPyYAML                   5.3.1\r\npyzmq                    18.1.1\r\nqtconsole                4.4.4\r\nrdt                      0.2.1\r\nRegscorePy               1.1\r\nrequests                 2.23.0\r\nrequests-oauthlib        1.3.0\r\nresampy                  0.2.2\r\nretrying                 1.3.3\r\nrsa                      4.0\r\ns3transfer               0.2.1\r\nscikit-image             0.15.0\r\nscikit-learn             0.23.2\r\nscipy                    1.4.1\r\nsdv                      0.3.2\r\nseaborn                  0.9.0\r\nseasonal                 0.3.1\r\nSend2Trash               1.5.0\r\nsentinelsat              0.12.2\r\nsetuptools               46.3.0\r\nsetuptools-git           1.2\r\nsix                      1.14.0\r\nsklearn                  0.0\r\nsortedcontainers         2.0.4\r\nSoundFile                0.10.3.post1\r\nsoupsieve                2.0\r\nspacy                    2.1.8\r\nsrsly                    0.1.0\r\nstatsmodels              0.9.0\r\nstopit                   1.1.2\r\nsugartensor              1.0.0.2\r\nta                       0.5.25\r\ntb-nightly               1.14.0a20190603\r\ntblib                    1.3.2\r\ntensorboard              2.3.0\r\ntensorboard-plugin-wit   1.7.0\r\ntensorflow-gpu           2.3.0\r\ntensorflow-gpu-estimator 2.3.0\r\ntermcolor                1.1.0\r\nterminado                0.8.3\r\ntestpath                 0.4.4\r\ntext-unidecode           1.3\r\ntexttable                1.4.0\r\nTheano                   1.0.4\r\nthinc                    7.0.8\r\nthreadpoolctl            2.1.0\r\ntoml                     0.10.1\r\ntoolz                    0.10.0\r\ntorch                    1.4.0\r\ntorchvision              0.5.0\r\ntornado                  6.0.4\r\nTPOT                     0.10.2\r\ntqdm                     4.45.0\r\ntraitlets                4.3.3\r\ntransforms3d             0.3.1\r\ntsaug                    0.2.1\r\ntypeguard                2.7.1\r\ntyping                   3.6.6\r\nupdate-checker           0.16\r\nurllib3                  1.22\r\nutm                      0.4.2\r\nwasabi                   0.2.2\r\nwcwidth                  0.1.9\r\nwebencodings             0.5.1\r\nWerkzeug                 1.0.1\r\nwheel                    0.34.2\r\nwidgetsnbextension       3.5.1\r\nwin-inet-pton            1.1.0\r\nwincertstore             0.2\r\nwrapt                    1.11.2\r\nxarray                   0.10.8\r\nxlrd                     1.1.0\r\nyahoo-historical         0.3.2\r\nzict                     0.1.3\r\nzipp                     2.2.0\r\n```", "comments": ["@tolandwehr,\r\nI was able to run the given code snippet without any issues, please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/f8fa230015bd4fdda159ac0c4ef7ce28/42641.ipynb).\r\n\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here. Thanks!", "Okay. Gist is a little short, as it misses the \r\n\r\n```'\r\ncross_val_predict\r\n```\r\n, where the error happens. My description might have left this unclear, sry. Here the notebook, which is a little messy, though, as it also involves other tasks:\r\n\r\n```\r\nimport tensorflow as tf\r\nimport os\r\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\r\nos.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\r\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = '0' # Set to -1 if CPU should be used CPU = -1 , GPU = 0\r\n\r\ngpus = tf.config.experimental.list_physical_devices('GPU')\r\ncpus = tf.config.experimental.list_physical_devices('CPU')\r\n\r\nif gpus:\r\n    try:\r\n        # Currently, memory growth needs to be the same across GPUs\r\n        for gpu in gpus:\r\n            tf.config.experimental.set_memory_growth(gpu, True)\r\n        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\r\n        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\r\n    except RuntimeError as e:\r\n        # Memory growth must be set before GPUs have been initialized\r\n        print(e)\r\nelif cpus:\r\n    try:\r\n        # Currently, memory growth needs to be the same across GPUs\r\n        logical_cpus= tf.config.experimental.list_logical_devices('CPU')\r\n        print(len(cpus), \"Physical CPU,\", len(logical_cpus), \"Logical CPU\")\r\n    except RuntimeError as e:\r\n        # Memory growth must be set before GPUs have been initialized\r\n        print(e)\r\n\r\n#from __future__ import print_function, division\r\n\r\n\r\nimport plotly.express as px\r\nimport pandas as pd\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\nimport tensorflow as tf\r\nimport keras\r\nimport sys\r\nimport os\r\n\r\nimport tsaug\r\nfrom tsaug.visualization import plot\r\nfrom tsaug import TimeWarp, Crop, Quantize, Drift, Reverse, Convolve, AddNoise, Dropout, Pool, Resize\r\n\r\nimport statsmodels\r\nimport datawig\r\nimport impyute\r\n\r\nimport missingpy\r\nfrom missingpy import KNNImputer,MissForest\r\n\r\nfrom impyute.imputation.cs import mice\r\nfrom datawig import SimpleImputer\r\nfrom statsmodels import robust\r\nfrom operator import itemgetter,attrgetter\r\nfrom functools import partial\r\nfrom scipy import stats\r\n\r\nfrom pylab import rcParams\r\nfrom tpot import TPOTRegressor\r\n\r\nfrom sklearn import preprocessing\r\nfrom sklearn.decomposition import PCA\r\nfrom sklearn import model_selection\r\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, Normalizer, LabelEncoder, RobustScaler, QuantileTransformer\r\nfrom sklearn.linear_model import LinearRegression\r\nfrom sklearn.model_selection import train_test_split,cross_val_score, cross_val_predict, cross_validate, GridSearchCV, RandomizedSearchCV, TimeSeriesSplit, KFold\r\nfrom sklearn.metrics import mean_squared_error, r2_score, explained_variance_score, make_scorer,median_absolute_error, mean_absolute_error,max_error,explained_variance_score\r\nfrom sklearn.base import BaseEstimator, TransformerMixin\r\nfrom sklearn.utils.validation import check_array, check_is_fitted\r\nfrom sklearn.experimental import enable_iterative_imputer  # noqa\r\nfrom sklearn.impute import IterativeImputer, SimpleImputer\r\n\r\n\r\nfrom tensorflow.keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\r\nfrom kerastuner import HyperModel\r\n\r\n\r\n# import tensorflow as tf\r\n# import cProfile\r\n# tf.enable_eager_execution()\r\n# tf.executing_eagerly()\r\n\r\nfrom tensorflow.python.keras.layers import InputLayer, TimeDistributed, Lambda, Dense, Dot, Reshape,Concatenate, Embedding, Activation, Conv1D, Conv2D, Cropping2D, MaxPooling2D, Flatten, Dropout, LSTM, GRU, Bidirectional, Input, LeakyReLU,Conv2DTranspose, ZeroPadding2D, ZeroPadding1D, UpSampling2D, UpSampling1D,multiply,AveragePooling1D # components of network\r\nfrom tensorflow.python.keras.models import Model, Sequential # type of model\r\nfrom tensorflow.python.keras.layers import BatchNormalization\r\nfrom tensorflow.python.keras.optimizers import Adam, RMSprop, SGD, Nadam, Adadelta, Adamax\r\nfrom tensorflow.python.keras.regularizers import l2\r\nfrom tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\r\n\r\n#from SpectralNormalizationKeras import DenseSN, ConvSN2D\r\n\r\n\r\nfrom ctgan import CTGANSynthesizer\r\n\r\n#import tensorflow.keras.backend as K\r\nfrom tensorflow.python.keras.backend import expand_dims, squeeze\r\n\r\nfrom tqdm import tqdm\r\n\r\n######loading and preparing data\r\n\r\nHeisei_T=pd.read_excel('Heisei_Whoa.xlsx')\r\nHeisei_T=Heisei_T.drop(Heisei_T.columns[0], axis=1)\r\n\r\nYear_Frame = 18\r\nSet_Len = len(Heisei_T)\r\nSample_Len = int(Set_Len/Year_Frame)\r\nSet_Width = len(Heisei_T.columns)\r\n\r\nHeisei_Heads=Heisei_T.columns\r\nHeisei_TR=np.array(Heisei_T).reshape(Sample_Len,Year_Frame,Set_Width)\r\nnp.random.shuffle(Heisei_TR)\r\nHeisei_T=Heisei_TR.reshape(Sample_Len*Year_Frame,Set_Width)\r\n\r\ndef split_sequences(sequences, n_steps):\r\n    X, y = list(), list()\r\n    for i in range(len(sequences)):\r\n        # find the end of this pattern\r\n        end_ix = i + n_steps\r\n        # check if we are beyond the dataset\r\n        if end_ix > len(sequences):\r\n            break\r\n        # gather input and output parts of the pattern\r\n        seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1, -1]\r\n        X.append(seq_x)\r\n        y.append(seq_y)\r\n    return np.array(X), np.array(y)\r\n\r\nn_steps = 3\r\n\r\nX_full=[]\r\ny_full=[]\r\n\r\n\r\nfor x in range(0,Sample_Len):\r\n    X,y=split_sequences(Heisei_T[x*Year_Frame:(x+1)*Year_Frame,:],n_steps)\r\n    X_full.append(X)\r\n    y_full.append(y)\r\n    \r\nX_full=np.array(X_full)\r\ny_full=np.array(y_full)\r\n\r\nX_full.shape\r\nX_full=X_full.reshape(Sample_Len*16,n_steps,Set_Width-1)\r\ny_full=y_full.reshape(Sample_Len*16,1)\r\n#pd.DataFrame(y_full).head(90)\r\n\r\n\r\nX_full.shape\r\n#y_full.shape\r\n\r\nprint(pd.DataFrame(y_full).max())\r\n\r\ny_test=np.array(pd.DataFrame(y_full).tail(round(0.10001671123*y_full.shape[0])))\r\ny_train=np.array(pd.DataFrame(y_full).head(round((1-0.10001671123)*y_full.shape[0])))\r\n\r\n\r\nX_test=np.array(pd.DataFrame(X_full.reshape(X_full.shape[0],X_full.shape[1]*X_full.shape[2])).tail(round(0.10001671123*X_full.shape[0]))).reshape(round(0.10001671123*X_full.shape[0]),X_full.shape[1],X_full.shape[2])\r\nX_train=np.array(pd.DataFrame(X_full.reshape(X_full.shape[0],X_full.shape[1]*X_full.shape[2])).head(round(1-0.10001671123*X_full.shape[0]-1))).reshape(round((1-0.10001671123)*X_full.shape[0]),X_full.shape[1],X_full.shape[2])\r\n\r\nTrain_Len=len(X_train)\r\nTest_Len=len(X_test)\r\n\r\nprint(y_train.shape,y_test.shape,X_train.shape,X_test.shape)\r\n\r\n\r\nX_test_scaler = preprocessing.StandardScaler()\r\ny_test_scaler = preprocessing.StandardScaler()\r\nX_train_scaler = preprocessing.StandardScaler()\r\ny_train_scaler = preprocessing.StandardScaler()\r\n\r\ny_test=y_test_scaler.fit_transform(y_test)\r\ny_train=y_train_scaler.fit_transform(y_train)\r\n\r\nX_test=X_test_scaler.fit_transform(X_test.reshape(Test_Len*n_steps,Set_Width-1))\r\nX_train=X_train_scaler.fit_transform(X_train.reshape(Train_Len*n_steps,Set_Width-1))\r\n\r\nX_test=X_test.reshape(Test_Len,n_steps,Set_Width-1)\r\nX_train=X_train.reshape(Train_Len,n_steps,Set_Width-1)\r\n\r\n\r\n\r\n#########Model and SKlearn Cross_Val_Predict\r\n\r\ndef twds_model(layer1=32, layer2=32, layer3=16, dropout_rate=0.5, optimizer='Adam'\r\n                    , learning_rate=0.001, activation='relu', loss='mse'):#, n_jobs=1):layer3=80, \r\n    \r\n    model = Sequential()\r\n    model.add(Bidirectional(GRU(layer1, return_sequences=True),input_shape=(X_train.shape[1],X_train.shape[2])))\r\n    model.add(AveragePooling1D(2))\r\n    model.add(Conv1D(layer2, 3, activation=activation, padding='same', \r\n               name='extractor'))\r\n    model.add(Flatten())\r\n    model.add(Dense(layer3,activation=activation))\r\n    model.add(Dropout(dropout_rate))\r\n    model.add(Dense(1))\r\n    model.compile(optimizer=optimizer,loss=loss)\r\n    return model\r\n\r\ntwds_model=twds_model()\r\nprint(twds_model.summary())\r\n\r\n\r\ndef CustomVarious(y_true, y_pred):\r\n    y_true=y_true.reshape(len(y_true[:,1])*Heisei_TR.shape[1],)\r\n    \r\n    if np.isnan(y_pred).any():\r\n        result=-1000000\r\n        MAD= 1000000\r\n    else:\r\n        y_pred=y_pred.reshape(len(y_pred[:,1])*Heisei_TR.shape[1],)\r\n        MAD=median_absolute_error(y_true, y_pred)\r\n\r\n        print(MAD)\r\n\r\n        \r\n        \r\n\r\n    return MAD\r\n\r\nscorer = make_scorer(CustomVarious, greater_is_better=False\r\n\r\nmodel_twds=KerasRegressor(build_fn=twds_Model, batch_size=256,epochs=6)\r\n\r\n\r\n############# PLACE OF THE ERROR ############\r\ntwds_Pred=cross_val_predict(model_twds, \r\n               X_train, \r\n               y_train, \r\n               n_jobs=1, \r\n               cv=4, \r\n               verbose=2)\r\n\r\n```\r\n\r\n\r\n", "@tolandwehr,\r\nOn running the code I am facing an error stating `FileNotFoundError: [Errno 2] No such file or directory: 'Heisei_Whoa.xlsx'`. Could you please provide all the necessary files to run the code?\r\n\r\nAlso, could you please remove the dependencies and get the example down to the simplest possible repro? That will allow us to easily debug the issue. Thanks!", "@amahendrakar \r\n\r\nWhoa contains data that I'm not allowed to pass, unfortunately ^^'. But it was checked with \r\n\r\n```\r\n.isnull().sum().sum()\r\n```\r\n\r\nto be free on NaNs.\r\n\r\nYou can dense the code down to:\r\n\r\n```\r\nimport tensorflow as tf\r\nimport os\r\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\r\nos.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\r\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = '0' # Set to -1 if CPU should be used CPU = -1 , GPU = 0\r\n\r\ngpus = tf.config.experimental.list_physical_devices('GPU')\r\ncpus = tf.config.experimental.list_physical_devices('CPU')\r\n\r\nif gpus:\r\n    try:\r\n        # Currently, memory growth needs to be the same across GPUs\r\n        for gpu in gpus:\r\n            tf.config.experimental.set_memory_growth(gpu, True)\r\n        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\r\n        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\r\n    except RuntimeError as e:\r\n        # Memory growth must be set before GPUs have been initialized\r\n        print(e)\r\nelif cpus:\r\n    try:\r\n        # Currently, memory growth needs to be the same across GPUs\r\n        logical_cpus= tf.config.experimental.list_logical_devices('CPU')\r\n        print(len(cpus), \"Physical CPU,\", len(logical_cpus), \"Logical CPU\")\r\n    except RuntimeError as e:\r\n        # Memory growth must be set before GPUs have been initialized\r\n        print(e)\r\n\r\n#from __future__ import print_function, division\r\n\r\n\r\nimport plotly.express as px\r\nimport pandas as pd\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\nimport tensorflow as tf\r\nimport keras\r\nimport sys\r\nimport os\r\n\r\nimport tsaug\r\nfrom tsaug.visualization import plot\r\nfrom tsaug import TimeWarp, Crop, Quantize, Drift, Reverse, Convolve, AddNoise, Dropout, Pool, Resize\r\n\r\nimport statsmodels\r\nimport datawig\r\nimport impyute\r\n\r\nimport missingpy\r\nfrom missingpy import KNNImputer,MissForest\r\n\r\nfrom impyute.imputation.cs import mice\r\nfrom datawig import SimpleImputer\r\nfrom statsmodels import robust\r\nfrom operator import itemgetter,attrgetter\r\nfrom functools import partial\r\nfrom scipy import stats\r\n\r\nfrom pylab import rcParams\r\nfrom tpot import TPOTRegressor\r\n\r\nfrom sklearn import preprocessing\r\nfrom sklearn.decomposition import PCA\r\nfrom sklearn import model_selection\r\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, Normalizer, LabelEncoder, RobustScaler, QuantileTransformer\r\nfrom sklearn.linear_model import LinearRegression\r\nfrom sklearn.model_selection import train_test_split,cross_val_score, cross_val_predict, cross_validate, GridSearchCV, RandomizedSearchCV, TimeSeriesSplit, KFold\r\nfrom sklearn.metrics import mean_squared_error, r2_score, explained_variance_score, make_scorer,median_absolute_error, mean_absolute_error,max_error,explained_variance_score\r\nfrom sklearn.base import BaseEstimator, TransformerMixin\r\nfrom sklearn.utils.validation import check_array, check_is_fitted\r\nfrom sklearn.experimental import enable_iterative_imputer  # noqa\r\nfrom sklearn.impute import IterativeImputer, SimpleImputer\r\n\r\n\r\nfrom tensorflow.keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\r\nfrom kerastuner import HyperModel\r\n\r\n\r\n\r\nfrom tensorflow.python.keras.layers import InputLayer, TimeDistributed, Lambda, Dense, Dot, Reshape,Concatenate, Embedding, Activation, Conv1D, Conv2D, Cropping2D, MaxPooling2D, Flatten, Dropout, LSTM, GRU, Bidirectional, Input, LeakyReLU,Conv2DTranspose, ZeroPadding2D, ZeroPadding1D, UpSampling2D, UpSampling1D,multiply,AveragePooling1D # components of network\r\nfrom tensorflow.python.keras.models import Model, Sequential # type of model\r\nfrom tensorflow.python.keras.layers import BatchNormalization\r\nfrom tensorflow.python.keras.optimizers import Adam, RMSprop, SGD, Nadam, Adadelta, Adamax\r\nfrom tensorflow.python.keras.regularizers import l2\r\nfrom tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\r\n\r\n\r\n\r\nfrom ctgan import CTGANSynthesizer\r\n\r\n#import tensorflow.keras.backend as K\r\nfrom tensorflow.python.keras.backend import expand_dims, squeeze\r\n\r\nfrom tqdm import tqdm\r\n\r\n\r\nX_full = np.random.rand(1200,18,15)\r\ny_full = np.random.rand(1200,18 )\r\n\r\n\r\ny_test=np.array(pd.DataFrame(y_full).tail(round(0.10001671123*y_full.shape[0])))\r\ny_train=np.array(pd.DataFrame(y_full).head(round((1-0.10001671123)*y_full.shape[0])))\r\n\r\n\r\nX_test=np.array(pd.DataFrame(X_full.reshape(X_full.shape[0],X_full.shape[1]*X_full.shape[2])).tail(round(0.10001671123*X_full.shape[0]))).reshape(round(0.10001671123*X_full.shape[0]),X_full.shape[1],X_full.shape[2])\r\nX_train=np.array(pd.DataFrame(X_full.reshape(X_full.shape[0],X_full.shape[1]*X_full.shape[2])).head(round(1-0.10001671123*X_full.shape[0]-1))).reshape(round((1-0.10001671123)*X_full.shape[0]),X_full.shape[1],X_full.shape[2])\r\n\r\nTrain_Len=len(X_train)\r\nTest_Len=len(X_test)\r\n\r\nprint(y_train.shape,y_test.shape,X_train.shape,X_test.shape)\r\n\r\n\r\nX_test_scaler = preprocessing.StandardScaler()\r\ny_test_scaler = preprocessing.StandardScaler()\r\nX_train_scaler = preprocessing.StandardScaler()\r\ny_train_scaler = preprocessing.StandardScaler()\r\n\r\ny_test=y_test_scaler.fit_transform(y_test)\r\ny_train=y_train_scaler.fit_transform(y_train)\r\n\r\nX_test=X_test_scaler.fit_transform(X_test.reshape(Test_Len*n_steps,Set_Width-1))\r\nX_train=X_train_scaler.fit_transform(X_train.reshape(Train_Len*n_steps,Set_Width-1))\r\n\r\nX_test=X_test.reshape(Test_Len,n_steps,Set_Width-1)\r\nX_train=X_train.reshape(Train_Len,n_steps,Set_Width-1)\r\n\r\n\r\n\r\n#########Model and SKlearn Cross_Val_Predict\r\n\r\ndef twds_model(layer1=32, layer2=32, layer3=16, dropout_rate=0.5, optimizer='Adam'\r\n                    , learning_rate=0.001, activation='relu', loss='mse'):#, n_jobs=1):layer3=80, \r\n    \r\n    model = Sequential()\r\n    model.add(Bidirectional(GRU(layer1, return_sequences=True),input_shape=(X_train.shape[1],X_train.shape[2])))\r\n    model.add(AveragePooling1D(2))\r\n    model.add(Conv1D(layer2, 3, activation=activation, padding='same', \r\n               name='extractor'))\r\n    model.add(Flatten())\r\n    model.add(Dense(layer3,activation=activation))\r\n    model.add(Dropout(dropout_rate))\r\n    model.add(Dense(1))\r\n    model.compile(optimizer=optimizer,loss=loss)\r\n    return model\r\n\r\ntwds_model=twds_model()\r\nprint(twds_model.summary())\r\n\r\n\r\ndef CustomVarious(y_true, y_pred):\r\n    y_true=y_true.reshape(len(y_true[:,1])*Heisei_TR.shape[1],)\r\n    \r\n    if np.isnan(y_pred).any():\r\n        result=-1000000\r\n        MAD= 1000000\r\n    else:\r\n        y_pred=y_pred.reshape(len(y_pred[:,1])*Heisei_TR.shape[1],)\r\n        MAD=median_absolute_error(y_true, y_pred)\r\n\r\n        print(MAD)\r\n\r\n        \r\n        \r\n\r\n    return MAD\r\n\r\nscorer = make_scorer(CustomVarious, greater_is_better=False)\r\n\r\nmodel_twds=KerasRegressor(build_fn=twds_Model, batch_size=256,epochs=6)\r\n\r\n\r\n############# PLACE OF THE ERROR ############\r\ntwds_Pred=cross_val_predict(model_twds, \r\n               X_train, \r\n               y_train, \r\n               n_jobs=1, \r\n               cv=4, \r\n               verbose=2)\r\n\r\n```", "Or actually you could leave all the data preshaping and just feed in with \r\n```\r\nX_train = np.random.rand(1200,18,15)\r\nX_train = np.random.rand(1200,18,1 )\r\n```", "@tolandwehr Thank you for the update. I was able to reproduce the issue with [TF v2.3](https://colab.research.google.com/gist/amahendrakar/6c96a7afe89fcafdd512b62f0765f28f/42641.ipynb).\r\n\r\nWhereas on running the code with [TF-nightly](https://colab.research.google.com/gist/amahendrakar/74ae2a69f7d043f4be9d26b1e449738e/42641-tf-nightly.ipynb#scrollTo=EudEPDicA6HK), I am facing a different error stating `ValueError: The first argument to Layer.call must always be passed.` Please find the attached gist. Thanks!", " \r\n> ```\r\n> ---------------------------------------------------------------------------\r\n> TypeError                                 Traceback (most recent call last)\r\n> <ipython-input-603-37b55dfd53fd> in <module>\r\n> ----> 1 GridLSTM.fit(X_train, y_train)\r\n> \r\n> ~\\Anaconda3\\envs\\Tensorflow\\lib\\site-packages\\sklearn\\utils\\validation.py in inner_f(*args, **kwargs)\r\n>      70                           FutureWarning)\r\n>      71         kwargs.update({k: arg for k, arg in zip(sig.parameters, args)})\r\n> ---> 72         return f(**kwargs)\r\n>      73     return inner_f\r\n>      74 \r\n> \r\n> ```\r\n\r\n@tolandwehr,\r\nLooking at the error log, it seems like the error is thrown from a `sklearn\\utils\\validation.py` module and `Tensorflow` is the name of your environment. Please correct me if I am wrong, thanks!", "@amahendrakar \r\n\r\nExactly, the environ was called 'Tensorflow', the module is 'sklearn\\utils\\validation.py'.", "@gowthamkpr,\r\nRunning the code with [TF v2.3](https://colab.research.google.com/gist/amahendrakar/6c96a7afe89fcafdd512b62f0765f28f/42641.ipynb#scrollTo=EudEPDicA6HK), throws an error stating `TypeError: can't pickle _thread.RLock objects`. \r\n\r\nHowever with [TF-nightly](https://colab.research.google.com/gist/amahendrakar/74ae2a69f7d043f4be9d26b1e449738e/42641-tf-nightly.ipynb#scrollTo=EudEPDicA6HK), the error changes to `ValueError: The first argument to Layer.call must always be passed.`. Please find the attached gist. Thanks! ", "@tolandwehr,\r\nCan you please refer [this Article](https://machinelearningmastery.com/use-keras-deep-learning-models-scikit-learn-python/) which comprises Using Keras Wrapper in Scikit Learn. Thanks!", "@tolandwehr,\r\nCan you please respond to the above comment. Thanks! ", "@rmothukuru \r\nSry, the last weeks are very busy on releasing some topics, I will come back to the issue next week.", "@tolandwehr,\r\nCan you please respond to the [above comment](https://github.com/tensorflow/tensorflow/issues/42641#issuecomment-725284038). Thanks! ", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42641\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42641\">No</a>\n", "I've just opened this related issue, but now with data freely available. https://github.com/tensorflow/tensorflow/issues/47324"]}, {"number": 42640, "title": "Tensorflow lite arm64 cross/native build issue", "body": "Hi,\r\n\r\nI am trying to build tensorflow-lite with edgetpu on Coral development board and following the instructions from the link below\r\nhttps://www.tensorflow.org/lite/guide/build_arm64#compile_natively_on_arm64\r\n\r\nI am checked out to d855adfc5a0195788bf5f92c3c7352e638aa1109(https://github.com/google-coral/edgetpu/blob/c48c88871fd3d2e10d298126cd6a08b88d22496c/WORKSPACE#L5 as per the instructions on step 3 of the link - https://coral.ai/docs/edgetpu/tflite-cpp/#build-your-project\r\n\r\nI am running into build issues with native as well as cross compilation with this SHA(master builds fine). Below is the log snippet of build failure\r\n\r\n```\r\nIn file included from /home/mg/workspace/nxpdemo/tensorflow/tensorflow/lite/tools/make/downloads/absl/absl/base/internal/periodic_sampler.h:22:0,\r\n                 from tensorflow/lite/tools/make/downloads/absl/absl/base/internal/periodic_sampler.cc:15:\r\n/home/mg/workspace/nxpdemo/tensorflow/tensorflow/lite/tools/make/downloads/absl/absl/base/internal/exponential_biased.h:24:1: error: \u2018ABSL_NAMESPACE_BEGIN\u2019 does not name a type\r\n ABSL_NAMESPACE_BEGIN\r\n ^~~~~~~~~~~~~~~~~~~~\r\ntensorflow/lite/tools/make/downloads/absl/absl/base/internal/exponential_biased.cc:28:1: error: \u2018ABSL_NAMESPACE_BEGIN\u2019 does not name a type\r\n ABSL_NAMESPACE_BEGIN\r\n ^~~~~~~~~~~~~~~~~~~~\r\n/home/mg/workspace/nxpdemo/tensorflow/tensorflow/lite/tools/make/downloads/absl/absl/base/internal/exponential_biased.h:127:1: error: \u2018ABSL_NAMESPACE_END\u2019 does not name a type; did you mean \u2018ABSL_BASE_PORT_H_\u2019?\r\n ABSL_NAMESPACE_END\r\n ^~~~~~~~~~~~~~~~~~\r\n\r\n```\r\n**Steps to build tensorflow-lite**\r\n\r\n1. git clone https://github.com/tensorflow/tensorflow and checkout to  d855adfc5a0195788bf5f92c3c7352e638aa1109\r\n2. cd tensorflow \r\n3. ./tensorflow/lite/tools/make/download_dependencies.sh\r\n4. ./tensorflow/lite/tools/make/build_aarch64_lib.sh\r\n\r\nI also tried to use master of tensorflow-lite with released version of libedgetup.so.1.0 with a sample test and ran into problems which I suspect are related to mismatch of versions between tensorflow-lite and libedgetpu\r\n\r\n> mendel@neat-jet:~/coral-demo/tflite/cpp/examples/classification$ ./minimal \r\n>  model: /edgetpu/test_data/mobilenet_v1_1.0_224_quant_edgetpu.tflite\r\n>  data: /edgetpu/test_data/resized_cat.bmp\r\n> ERROR: Internal: Unsupported data type in custom op handler: -591183536\r\n> ERROR: Node number 0 (edgetpu-custom-op) failed to prep\r\n\r\nThanks,\r\n\r\n", "comments": ["@clsdmgtk \r\nCould you please fill in the issue template, i am unable to find details as the tf version and system information.", "@Saduf2019 \r\n\r\n**System information for cross compile**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source):   https://github.com/tensorflow/tensorflow and checkout to d855adf\r\n- TensorFlow version: -\r\n- GCC/Compiler version (if compiling from source): aarch64-linux-gnu-g++ (Ubuntu/Linaro 7.5.0-3ubuntu1~18.04) 7.5.0\r\n\r\n**Native compile on Coral dev board**\r\n- OS Platform and Distribution: mendel 5.0\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source):   https://github.com/tensorflow/tensorflow and checkout to d855adf\r\n- TensorFlow version: -\r\n- GCC/Compiler version (if compiling from source): aarch64-linux-gnu-g++ (Debian 8.3.0-6) 8.3.0\r\n\r\nPlease let me know if I need to provide any other information.", "For some reason I was able to build both native and cross compile version today. However, I had to address the issue in https://github.com/google-coral/edgetpu/issues/201 which is not related to the original issue I saw yesterday.\r\n\r\nThanks for your attention on this issue.\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42640\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42640\">No</a>\n", "> For some reason I was able to build both native and cross compile version today. However, I had to address the issue in [google-coral/edgetpu#201](https://github.com/google-coral/edgetpu/issues/201) which is not related to the original issue I saw yesterday.\r\n> \r\n> Thanks for your attention on this issue.\r\n\r\nMay I know how did you solve this issue?"]}, {"number": 42639, "title": "How do I use a local LLVM installation?", "body": "Hi,\r\n\r\nI've been trying to build TensorFlow with my local LLVM installation. I figured I have to choose `N` when I run `./configure`:\r\n```\r\nDo you wish to download a fresh release of clang? (Experimental) [y/N]: n\r\n```\r\nI also tried setting the environment variable manually for the build:\r\n```\r\nTF_DOWNLOAD_CLANG=\"0\" bazel build ...\r\n```\r\nHowever the build is still pulling llvm-project as an external dependency. Is using a local LLVM installation not supported? What do I need to do? Could you please give me the steps I need to take as I am new to Bazel or refer me to a resource?", "comments": ["@daravi,\r\nPlease provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\nMake sure you also include the exact command if possible to produce the output included in your test case. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!\r\n ", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42639\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42639\">No</a>\n"]}, {"number": 42638, "title": "resized temp outputs in MnistForwardModel", "body": "@saxenasaurabh\r\n\r\npotential fix to segfault in TestMNISTForward", "comments": ["This still segfaults internally due to another bug in the gradients infra so I had to disable the test.\r\n\r\n@mihaimaruseac would you know why the tests for the original PR #41432 did not catch this?\r\n\r\n@amturati Are you able to repro the segfault on your machine. If not, we should look into that.", "@saxenasaurabh No, on my machine it compiles and runs succesfully", "@amturati what flags do you compile with? Which operating system? Trying to bisect", "I don't run any additional flags; the command I run is `bazel test: XXX`. I've been working through Secure Shell on the Linux Beta offered on the pixelbooks. "]}, {"number": 42636, "title": "Cannot convert predict function of LinearRegressor", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nWindows 10\r\n- TensorFlow installed from (source or binary):\r\nbinary / pip\r\n- TensorFlow version (or github SHA if from source):\r\n2.4.0-dev20200824\r\n\r\n**Command used to run the converter or code if you\u2019re using the Python API**\r\nIf possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n```\r\n# I have a tf.estimator.LinearRegressor and save it first with function export_saved_model from LinearRegressor.\r\n# Then I load it and save only the predict funtion\r\nimported = tf.saved_model.load('./modelbefore')\r\ntf.saved_model.save(imported, 'model', imported.signatures[\"predict\"])\r\n# Saved model attached below\r\n# Wenn I then try to load as following I get the error below\r\nconverter = tf.lite.TFLiteConverter.from_saved_model('model')\r\ntflite_model = converter.convert()\r\n```\r\n\r\n**The output from the converter invocation**\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nException                                 Traceback (most recent call last)\r\n~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\r\n    195     try:\r\n--> 196       model_str = wrap_toco.wrapped_toco_convert(model_flags_str,\r\n    197                                                  toco_flags_str, input_data_str,\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\lite\\python\\wrap_toco.py in wrapped_toco_convert(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\r\n     31   \"\"\"Wraps TocoConvert with lazy loader.\"\"\"\r\n---> 32   return _pywrap_toco_api.TocoConvert(\r\n     33       model_flags_str,\r\n\r\nException: :0: error: loc(callsite(callsite(\"ParseExample/ParseExampleV2@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): 'tf.ParseExampleV2' op is neither a custom op nor a flex op\r\n:0: note: loc(\"StatefulPartitionedCall_1\"): called from\r\n:0: note: loc(callsite(callsite(\"ParseExample/ParseExampleV2@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): see current operation: %sparse_indices:5, %sparse_values:5, %sparse_shapes:5, %dense_values:5 = \"tf.ParseExampleV2\"(%arg0, %cst_6, %cst_7, %cst_5, %cst_6, %cst_4, %cst_4, %cst_4, %cst_4, %cst_4) {dense_shapes = [#tf.shape<1>, #tf.shape<1>, #tf.shape<1>, #tf.shape<1>, #tf.shape<1>], device = \"\", num_sparse = 5 : i64, result_segment_sizes = dense<[5, 5, 5, 5, 0, 0]> : vector<6xi32>} : (tensor, tensor<0x!tf.string>, tensor<5x!tf.string>, tensor<5x!tf.string>, tensor<0x!tf.string>, tensor<0xf32>, tensor<0xf32>, tensor<0xf32>, tensor<0xf32>, tensor<0xf32>) -> (tensor, tensor, tensor, tensor, tensor, tensor, tensor, tensor, tensor, tensor, tensor<2xi64>, tensor<2xi64>, tensor<2xi64>, tensor<2xi64>, tensor<2xi64>, tensor, tensor, tensor, tensor, tensor)\r\n:0: error: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/category_id/category_id_lookup/hash_table/hash_table@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): 'tf.HashTableV2' op is neither a custom op nor a flex op\r\n:0: note: loc(\"StatefulPartitionedCall_1\"): called from\r\n:0: note: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/category_id/category_id_lookup/hash_table/hash_table@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): see current operation: %4 = \"tf.HashTableV2\"() {container = \"\", device = \"\", key_dtype = i64, shared_name = \"hash_table_8d6f1b8e-423d-4fff-8a54-69f4ddbecf04_load_0_197\", use_node_name_sharing = true, value_dtype = i64} : () -> tensor\r\n:0: error: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/category_id/hash_table_Lookup/LookupTableFindV2@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): 'tf.LookupTableFindV2' op is neither a custom op nor a flex op\r\n:0: note: loc(\"StatefulPartitionedCall_1\"): called from\r\n:0: note: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/category_id/hash_table_Lookup/LookupTableFindV2@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): see current operation: %5 = \"tf.LookupTableFindV2\"(%4, %sparse_values#0, %cst_9) {device = \"\"} : (tensor, tensor, tensor) -> tensor<*xi64>\r\n:0: error: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/category_id/SparseReshape@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): 'tf.SparseReshape' op is neither a custom op nor a flex op\r\n:0: note: loc(\"StatefulPartitionedCall_1\"): called from\r\n:0: note: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/category_id/SparseReshape@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): see current operation: %output_indices, %output_shape = \"tf.SparseReshape\"(%sparse_indices#0, %sparse_shapes#0, %8) {device = \"\"} : (tensor, tensor<2xi64>, tensor<2xi64>) -> (tensor, tensor<2xi64>)\r\n:0: error: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/category_id/weighted_sum/SparseReshape@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): 'tf.SparseReshape' op is neither a custom op nor a flex op\r\n:0: note: loc(\"StatefulPartitionedCall_1\"): called from\r\n:0: note: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/category_id/weighted_sum/SparseReshape@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): see current operation: %output_indices_22, %output_shape_23 = \"tf.SparseReshape\"(%output_indices, %output_shape, %17) {device = \"\"} : (tensor, tensor<2xi64>, tensor<2xi64>) -> (tensor, tensor<2xi64>)\r\n:0: error: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/category_id/weighted_sum/SparseFillEmptyRows/SparseFillEmptyRows@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): 'tf.SparseFillEmptyRows' op is neither a custom op nor a flex op\r\n:0: note: loc(\"StatefulPartitionedCall_1\"): called from\r\n:0: note: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/category_id/weighted_sum/SparseFillEmptyRows/SparseFillEmptyRows@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): see current operation: %output_indices_24, %output_values, %empty_row_indicator, %reverse_index_map = \"tf.SparseFillEmptyRows\"(%18, %14, %output_shape_23, %cst_13) {device = \"\"} : (tensor, tensor<*xi64>, tensor<2xi64>, tensor) -> (tensor, tensor, tensor, tensor)\r\n:0: error: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/description/description_lookup/hash_table/hash_table@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): 'tf.HashTableV2' op is neither a custom op nor a flex op\r\n:0: note: loc(\"StatefulPartitionedCall_1\"): called from\r\n:0: note: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/description/description_lookup/hash_table/hash_table@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): see current operation: %22 = \"tf.HashTableV2\"() {container = \"\", device = \"\", key_dtype = !tf.string, shared_name = \"hash_table_fc7c2e70-8a89-4115-84d4-2f713273e69c_load_0_198\", use_node_name_sharing = true, value_dtype = i64} : () -> tensor\r\n:0: error: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/description/hash_table_Lookup/LookupTableFindV2@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): 'tf.LookupTableFindV2' op is neither a custom op nor a flex op\r\n:0: note: loc(\"StatefulPartitionedCall_1\"): called from\r\n:0: note: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/description/hash_table_Lookup/LookupTableFindV2@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): see current operation: %23 = \"tf.LookupTableFindV2\"(%22, %sparse_values#1, %cst_9) {device = \"\"} : (tensor, tensor, tensor) -> tensor<*xi64>\r\n:0: error: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/description/SparseReshape@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): 'tf.SparseReshape' op is neither a custom op nor a flex op\r\n:0: note: loc(\"StatefulPartitionedCall_1\"): called from\r\n:0: note: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/description/SparseReshape@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): see current operation: %output_indices_25, %output_shape_26 = \"tf.SparseReshape\"(%sparse_indices#1, %sparse_shapes#1, %26) {device = \"\"} : (tensor, tensor<2xi64>, tensor<2xi64>) -> (tensor, tensor<2xi64>)\r\n:0: error: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/description/weighted_sum/SparseReshape@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): 'tf.SparseReshape' op is neither a custom op nor a flex op\r\n:0: note: loc(\"StatefulPartitionedCall_1\"): called from\r\n:0: note: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/description/weighted_sum/SparseReshape@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): see current operation: %output_indices_27, %output_shape_28 = \"tf.SparseReshape\"(%output_indices_25, %output_shape_26, %35) {device = \"\"} : (tensor, tensor<2xi64>, tensor<2xi64>) -> (tensor, tensor<2xi64>)\r\n:0: error: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/description/weighted_sum/SparseFillEmptyRows/SparseFillEmptyRows@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): 'tf.SparseFillEmptyRows' op is neither a custom op nor a flex op\r\n:0: note: loc(\"StatefulPartitionedCall_1\"): called from\r\n:0: note: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/description/weighted_sum/SparseFillEmptyRows/SparseFillEmptyRows@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): see current operation: %output_indices_29, %output_values_30, %empty_row_indicator_31, %reverse_index_map_32 = \"tf.SparseFillEmptyRows\"(%36, %32, %output_shape_28, %cst_13) {device = \"\"} : (tensor, tensor<*xi64>, tensor<2xi64>, tensor) -> (tensor, tensor, tensor, tensor)\r\n:0: error: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/host_id/host_id_lookup/hash_table/hash_table@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): 'tf.HashTableV2' op is neither a custom op nor a flex op\r\n:0: note: loc(\"StatefulPartitionedCall_1\"): called from\r\n:0: note: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/host_id/host_id_lookup/hash_table/hash_table@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): see current operation: %40 = \"tf.HashTableV2\"() {container = \"\", device = \"\", key_dtype = i64, shared_name = \"hash_table_b60d3bcd-14f8-4085-a3b2-85948ec09373_load_0_199\", use_node_name_sharing = true, value_dtype = i64} : () -> tensor\r\n:0: error: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/host_id/hash_table_Lookup/LookupTableFindV2@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): 'tf.LookupTableFindV2' op is neither a custom op nor a flex op\r\n:0: note: loc(\"StatefulPartitionedCall_1\"): called from\r\n:0: note: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/host_id/hash_table_Lookup/LookupTableFindV2@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): see current operation: %41 = \"tf.LookupTableFindV2\"(%40, %sparse_values#3, %cst_9) {device = \"\"} : (tensor, tensor, tensor) -> tensor<*xi64>\r\n:0: error: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/host_id/SparseReshape@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): 'tf.SparseReshape' op is neither a custom op nor a flex op\r\n:0: note: loc(\"StatefulPartitionedCall_1\"): called from\r\n:0: note: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/host_id/SparseReshape@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): see current operation: %output_indices_35, %output_shape_36 = \"tf.SparseReshape\"(%sparse_indices#3, %sparse_shapes#3, %44) {device = \"\"} : (tensor, tensor<2xi64>, tensor<2xi64>) -> (tensor, tensor<2xi64>)\r\n:0: error: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/host_id/weighted_sum/SparseReshape@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): 'tf.SparseReshape' op is neither a custom op nor a flex op\r\n:0: note: loc(\"StatefulPartitionedCall_1\"): called from\r\n:0: note: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/host_id/weighted_sum/SparseReshape@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): see current operation: %output_indices_37, %output_shape_38 = \"tf.SparseReshape\"(%output_indices_35, %output_shape_36, %53) {device = \"\"} : (tensor, tensor<2xi64>, tensor<2xi64>) -> (tensor, tensor<2xi64>)\r\n:0: error: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/host_id/weighted_sum/SparseFillEmptyRows/SparseFillEmptyRows@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): 'tf.SparseFillEmptyRows' op is neither a custom op nor a flex op\r\n:0: note: loc(\"StatefulPartitionedCall_1\"): called from\r\n:0: note: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/host_id/weighted_sum/SparseFillEmptyRows/SparseFillEmptyRows@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): see current operation: %output_indices_39, %output_values_40, %empty_row_indicator_41, %reverse_index_map_42 = \"tf.SparseFillEmptyRows\"(%54, %50, %output_shape_38, %cst_13) {device = \"\"} : (tensor, tensor<*xi64>, tensor<2xi64>, tensor) -> (tensor, tensor, tensor, tensor)\r\n:0: error: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/size_id/size_id_lookup/hash_table/hash_table@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): 'tf.HashTableV2' op is neither a custom op nor a flex op\r\n:0: note: loc(\"StatefulPartitionedCall_1\"): called from\r\n:0: note: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/size_id/size_id_lookup/hash_table/hash_table@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): see current operation: %58 = \"tf.HashTableV2\"() {container = \"\", device = \"\", key_dtype = i64, shared_name = \"hash_table_cb0918fe-8c8e-41f5-9aad-3750ec00bdad_load_0_200\", use_node_name_sharing = true, value_dtype = i64} : () -> tensor\r\n:0: error: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/size_id/hash_table_Lookup/LookupTableFindV2@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): 'tf.LookupTableFindV2' op is neither a custom op nor a flex op\r\n:0: note: loc(\"StatefulPartitionedCall_1\"): called from\r\n:0: note: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/size_id/hash_table_Lookup/LookupTableFindV2@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): see current operation: %59 = \"tf.LookupTableFindV2\"(%58, %sparse_values#4, %cst_9) {device = \"\"} : (tensor, tensor, tensor) -> tensor<*xi64>\r\n:0: error: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/size_id/SparseReshape@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): 'tf.SparseReshape' op is neither a custom op nor a flex op\r\n:0: note: loc(\"StatefulPartitionedCall_1\"): called from\r\n:0: note: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/size_id/SparseReshape@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): see current operation: %output_indices_45, %output_shape_46 = \"tf.SparseReshape\"(%sparse_indices#4, %sparse_shapes#4, %62) {device = \"\"} : (tensor, tensor<2xi64>, tensor<2xi64>) -> (tensor, tensor<2xi64>)\r\n:0: error: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/size_id/weighted_sum/SparseReshape@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): 'tf.SparseReshape' op is neither a custom op nor a flex op\r\n:0: note: loc(\"StatefulPartitionedCall_1\"): called from\r\n:0: note: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/size_id/weighted_sum/SparseReshape@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): see current operation: %output_indices_47, %output_shape_48 = \"tf.SparseReshape\"(%output_indices_45, %output_shape_46, %71) {device = \"\"} : (tensor, tensor<2xi64>, tensor<2xi64>) -> (tensor, tensor<2xi64>)\r\n:0: error: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/size_id/weighted_sum/SparseFillEmptyRows/SparseFillEmptyRows@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): 'tf.SparseFillEmptyRows' op is neither a custom op nor a flex op\r\n:0: note: loc(\"StatefulPartitionedCall_1\"): called from\r\n:0: note: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/size_id/weighted_sum/SparseFillEmptyRows/SparseFillEmptyRows@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): see current operation: %output_indices_49, %output_values_50, %empty_row_indicator_51, %reverse_index_map_52 = \"tf.SparseFillEmptyRows\"(%72, %68, %output_shape_48, %cst_13) {device = \"\"} : (tensor, tensor<*xi64>, tensor<2xi64>, tensor) -> (tensor, tensor, tensor, tensor)\r\n:0: error: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/category_id/weighted_sum/embedding_lookup_sparse@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): 'tf.SparseSegmentSum' op is neither a custom op nor a flex op\r\n:0: note: loc(\"StatefulPartitionedCall_1\"): called from\r\n:0: note: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/category_id/weighted_sum/embedding_lookup_sparse@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): see current operation: %127 = \"tf.SparseSegmentSum\"(%76, %idx, %21) {T = f32, Tidx = i32, Tsegmentids = i64, device = \"\"} : (tensor, tensor, tensor) -> tensor\r\n:0: error: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/description/weighted_sum/embedding_lookup_sparse@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): 'tf.SparseSegmentSum' op is neither a custom op nor a flex op\r\n:0: note: loc(\"StatefulPartitionedCall_1\"): called from\r\n:0: note: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/description/weighted_sum/embedding_lookup_sparse@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): see current operation: %127 = \"tf.SparseSegmentSum\"(%88, %idx_34, %39) {T = f32, Tidx = i32, Tsegmentids = i64, device = \"\"} : (tensor, tensor, tensor) -> tensor\r\n:0: error: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/host_id/weighted_sum/embedding_lookup_sparse@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): 'tf.SparseSegmentSum' op is neither a custom op nor a flex op\r\n:0: note: loc(\"StatefulPartitionedCall_1\"): called from\r\n:0: note: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/host_id/weighted_sum/embedding_lookup_sparse@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): see current operation: %127 = \"tf.SparseSegmentSum\"(%100, %idx_44, %57) {T = f32, Tidx = i32, Tsegmentids = i64, device = \"\"} : (tensor, tensor, tensor) -> tensor\r\n:0: error: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/size_id/weighted_sum/embedding_lookup_sparse@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): 'tf.SparseSegmentSum' op is neither a custom op nor a flex op\r\n:0: note: loc(\"StatefulPartitionedCall_1\"): called from\r\n:0: note: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/size_id/weighted_sum/embedding_lookup_sparse@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): see current operation: %127 = \"tf.SparseSegmentSum\"(%113, %idx_54, %75) {T = f32, Tidx = i32, Tsegmentids = i64, device = \"\"} : (tensor, tensor, tensor) -> tensor\r\n:0: error: failed while converting: 'main': Ops that can be supported by the flex runtime (enabled via setting the -emit-select-tf-ops flag):\r\n\ttf.ParseExampleV2 {dense_shapes = [#tf.shape<1>, #tf.shape<1>, #tf.shape<1>, #tf.shape<1>, #tf.shape<1>], device = \"\", num_sparse = 5 : i64, result_segment_sizes = dense<[5, 5, 5, 5, 0, 0]> : vector<6xi32>}\r\n\ttf.SparseFillEmptyRows {device = \"\"}\r\n\ttf.SparseReshape {device = \"\"}\r\n\ttf.SparseSegmentSum {T = f32, Tidx = i32, Tsegmentids = i64, device = \"\"}Ops that need custom implementation (enabled via setting the -emit-custom-ops flag):\r\n\ttf.HashTableV2 {container = \"\", device = \"\", key_dtype = !tf.string, shared_name = \"hash_table_fc7c2e70-8a89-4115-84d4-2f713273e69c_load_0_198\", use_node_name_sharing = true, value_dtype = i64}\r\n\ttf.HashTableV2 {container = \"\", device = \"\", key_dtype = i64, shared_name = \"hash_table_8d6f1b8e-423d-4fff-8a54-69f4ddbecf04_load_0_197\", use_node_name_sharing = true, value_dtype = i64}\r\n\ttf.HashTableV2 {container = \"\", device = \"\", key_dtype = i64, shared_name = \"hash_table_b60d3bcd-14f8-4085-a3b2-85948ec09373_load_0_199\", use_node_name_sharing = true, value_dtype = i64}\r\n\ttf.HashTableV2 {container = \"\", device = \"\", key_dtype = i64, shared_name = \"hash_table_cb0918fe-8c8e-41f5-9aad-3750ec00bdad_load_0_200\", use_node_name_sharing = true, value_dtype = i64}\r\n\ttf.LookupTableFindV2 {device = \"\"}\r\n:0: note: see current operation: \"func\"() ( {\r\n^bb0(%arg0: tensor):  // no predecessors\r\n  %cst = \"std.constant\"() {value = dense<[[0.117987722], [-0.0684242323], [0.100408614], [0.0145546673], [0.0430826135], [-0.103112921], [0.0680344701], [-0.0248609539], [0.0398180261], [0.122247897], [0.0273514148], [0.0187784135], [0.102349631], [-0.0905613824], [-0.0723603144], [-0.0438856669], [0.0021427928], [0.0984751954], [0.0817138106], [-0.109699354], [-0.191155598], [-0.0545536913], [-9.727810e-02], [0.0141912363], [7.680510e-02], [-0.0899474472], [0.0498611145], [-0.0884774774], [-0.114087969], [0.0725763887], [-0.141074464], [-0.176522136], [0.0143758887], [0.0524854325], [-0.155160338], [-0.0285528414], [-0.264534861], [0.106433257], [0.135232121], [0.225332677], [0.129775301], [-0.191358164], [-0.0178745817], [0.0918667614], [0.107648872], [-0.0921946167], [0.064818345], [0.0105348462], [-0.132097453], [-0.110714845], [0.0700208098], [0.034297362], [0.0263220761], [-0.059998773], [-0.0116290115], [0.101751082], [0.0713425949], [-0.0987613201], [-0.209998265], [0.0471415743], [0.10908471], [7.703180e-03], [0.0123223783], [0.103961319], [0.00920343306], [-0.110373154], [-0.113558963], [-0.0215992182], [-0.21590668], [-0.103494935], [-0.21094574], [-0.132196262], [0.18838799], [0.659609914], [-0.209931418], [-0.195380583], [-0.115891144], [-0.130379677], [-0.236354247], [0.111823596]]> : tensor<80x1xf32>} : () -> tensor<80x1xf32>\r\n  %cst_0 = \"std.constant\"() {value = dense<[[0.0778336599], [0.0839953199]]> : tensor<2x1xf32>} : () -> tensor<2x1xf32>\r\n  %cst_1 = \"std.constant\"() {value = dense<\"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tensor<6203x1xf32>} : () -> tensor<6203x1xf32>\r\n  %cst_2 = \"std.constant\"() {value = dense<[[0.137156427], [0.0727723241], [0.0427678488], [-2.75064172E-4], [-0.0233619846], [0.0394954272], [-0.0791109725]]> : tensor<7x1xf32>} : () -> tensor<7x1xf32>\r\n  %cst_3 = \"std.constant\"() {value = dense<0.131277829> : tensor<1xf32>} : () -> tensor<1xf32>\r\n  %cst_4 = \"std.constant\"() {value = dense<> : tensor<0xf32>} : () -> tensor<0xf32>\r\n  %cst_5 = \"std.constant\"() {value = dense<[\"lat\", \"long\", \"month\", \"price\", \"year\"]> : tensor<5x!tf.string>} : () -> tensor<5x!tf.string>\r\n  %cst_6 = \"std.constant\"() {value = dense<> : tensor<0x!tf.string>} : () -> tensor<0x!tf.string>\r\n  %cst_7 = \"std.constant\"() {value = dense<[\"category_id\", \"description\", \"gender\", \"host_id\", \"size_id\"]> : tensor<5x!tf.string>} : () -> tensor<5x!tf.string>\r\n  %cst_8 = \"std.constant\"() {value = dense<-1> : tensor} : () -> tensor\r\n  %cst_9 = \"std.constant\"() {value = dense<-1> : tensor} : () -> tensor\r\n  %cst_10 = \"std.constant\"() {value = dense<[-1, 1]> : tensor<2xi32>} : () -> tensor<2xi32>\r\n  %cst_11 = \"std.constant\"() {value = dense<-1> : tensor<1xi32>} : () -> tensor<1xi32>\r\n  %cst_12 = \"std.constant\"() {value = dense<1> : tensor} : () -> tensor\r\n  %cst_13 = \"std.constant\"() {value = dense<0> : tensor} : () -> tensor\r\n  %cst_14 = \"std.constant\"() {value = dense<-0.0035018248> : tensor<1x1xf32>} : () -> tensor<1x1xf32>\r\n  %cst_15 = \"std.constant\"() {value = dense<0> : tensor<1xi32>} : () -> tensor<1xi32>\r\n  %cst_16 = \"std.constant\"() {value = dense<0> : tensor<2xi32>} : () -> tensor<2xi32>\r\n  %cst_17 = \"std.constant\"() {value = dense<[0, 1]> : tensor<2xi32>} : () -> tensor<2xi32>\r\n  %cst_18 = \"std.constant\"() {value = dense<1> : tensor<2xi32>} : () -> tensor<2xi32>\r\n  %cst_19 = \"std.constant\"() {value} : () -> none\r\n  %cst_20 = \"std.constant\"() {value = dense<2> : tensor<1xi32>} : () -> tensor<1xi32>\r\n  %cst_21 = \"std.constant\"() {value = dense<1> : tensor<1xi32>} : () -> tensor<1xi32>\r\n  %sparse_indices:5, %sparse_values:5, %sparse_shapes:5, %dense_values:5 = \"tf.ParseExampleV2\"(%arg0, %cst_6, %cst_7, %cst_5, %cst_6, %cst_4, %cst_4, %cst_4, %cst_4, %cst_4) {dense_shapes = [#tf.shape<1>, #tf.shape<1>, #tf.shape<1>, #tf.shape<1>, #tf.shape<1>], device = \"\", num_sparse = 5 : i64, result_segment_sizes = dense<[5, 5, 5, 5, 0, 0]> : vector<6xi32>} : (tensor, tensor<0x!tf.string>, tensor<5x!tf.string>, tensor<5x!tf.string>, tensor<0x!tf.string>, tensor<0xf32>, tensor<0xf32>, tensor<0xf32>, tensor<0xf32>, tensor<0xf32>) -> (tensor, tensor, tensor, tensor, tensor, tensor, tensor, tensor, tensor, tensor, tensor<2xi64>, tensor<2xi64>, tensor<2xi64>, tensor<2xi64>, tensor<2xi64>, tensor, tensor, tensor, tensor, tensor)\r\n  %0 = \"tfl.cast\"(%sparse_shapes#0) : (tensor<2xi64>) -> tensor<2xi32>\r\n  %1 = \"tfl.cast\"(%sparse_shapes#1) : (tensor<2xi64>) -> tensor<2xi32>\r\n  %2 = \"tfl.cast\"(%sparse_shapes#3) : (tensor<2xi64>) -> tensor<2xi32>\r\n  %3 = \"tfl.cast\"(%sparse_shapes#4) : (tensor<2xi64>) -> tensor<2xi32>\r\n  %4 = \"tf.HashTableV2\"() {container = \"\", device = \"\", key_dtype = i64, shared_name = \"hash_table_8d6f1b8e-423d-4fff-8a54-69f4ddbecf04_load_0_197\", use_node_name_sharing = true, value_dtype = i64} : () -> tensor\r\n  %5 = \"tf.LookupTableFindV2\"(%4, %sparse_values#0, %cst_9) {device = \"\"} : (tensor, tensor, tensor) -> tensor<*xi64>\r\n  %6 = \"tfl.strided_slice\"(%0, %cst_15, %cst_21, %cst_21) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<2xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor\r\n  %7 = \"tfl.pack\"(%6, %cst_8) {axis = 0 : i32, values_count = 2 : i32} : (tensor, tensor) -> tensor<2xi32>\r\n  %8 = \"tfl.cast\"(%7) : (tensor<2xi32>) -> tensor<2xi64>\r\n  %output_indices, %output_shape = \"tf.SparseReshape\"(%sparse_indices#0, %sparse_shapes#0, %8) {device = \"\"} : (tensor, tensor<2xi64>, tensor<2xi64>) -> (tensor, tensor<2xi64>)\r\n  %9 = \"tfl.cast\"(%output_shape) : (tensor<2xi64>) -> tensor<2xi32>\r\n  %10 = \"tfl.gather\"(%output_shape, %cst_12) {axis = 0 : i32} : (tensor<2xi64>, tensor) -> tensor\r\n  %11 = \"tfl.greater_equal\"(%5, %cst_13) : (tensor<*xi64>, tensor) -> tensor<*xi1>\r\n  %12 = \"tfl.where\"(%11) : (tensor<*xi1>) -> tensor\r\n  %13 = \"tfl.reshape\"(%12, %cst_11) : (tensor, tensor<1xi32>) -> tensor\r\n  %14 = \"tfl.gather\"(%5, %13) {axis = 0 : i32} : (tensor<*xi64>, tensor) -> tensor<*xi64>\r\n  %15 = \"tfl.slice\"(%output_shape, %cst_15, %cst_21) : (tensor<2xi64>, tensor<1xi32>, tensor<1xi32>) -> tensor<1xi64>\r\n  %16 = \"tfl.reduce_prod\"(%15, %cst_15) {keep_dims = false} : (tensor<1xi64>, tensor<1xi32>) -> tensor\r\n  %17 = \"tfl.pack\"(%16, %10) {axis = 0 : i32, values_count = 2 : i32} : (tensor, tensor) -> tensor<2xi64>\r\n  %output_indices_22, %output_shape_23 = \"tf.SparseReshape\"(%output_indices, %output_shape, %17) {device = \"\"} : (tensor, tensor<2xi64>, tensor<2xi64>) -> (tensor, tensor<2xi64>)\r\n  %18 = \"tfl.gather\"(%output_indices_22, %13) {axis = 0 : i32} : (tensor, tensor) -> tensor\r\n  %19 = \"tfl.slice\"(%9, %cst_15, %cst_21) : (tensor<2xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<1xi32>\r\n  %output_indices_24, %output_values, %empty_row_indicator, %reverse_index_map = \"tf.SparseFillEmptyRows\"(%18, %14, %output_shape_23, %cst_13) {device = \"\"} : (tensor, tensor<*xi64>, tensor<2xi64>, tensor) -> (tensor, tensor, tensor, tensor)\r\n  %20 = \"tfl.reshape\"(%empty_row_indicator, %cst_10) : (tensor, tensor<2xi32>) -> tensor\r\n  %output, %idx = \"tfl.unique\"(%output_values) : (tensor) -> (tensor, tensor)\r\n  %21 = \"tfl.strided_slice\"(%output_indices_24, %cst_16, %cst_17, %cst_18) {begin_mask = 1 : i32, ellipsis_mask = 0 : i32, end_mask = 1 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 2 : i32} : (tensor, tensor<2xi32>, tensor<2xi32>, tensor<2xi32>) -> tensor\r\n  %22 = \"tf.HashTableV2\"() {container = \"\", device = \"\", key_dtype = !tf.string, shared_name = \"hash_table_fc7c2e70-8a89-4115-84d4-2f713273e69c_load_0_198\", use_node_name_sharing = true, value_dtype = i64} : () -> tensor\r\n  %23 = \"tf.LookupTableFindV2\"(%22, %sparse_values#1, %cst_9) {device = \"\"} : (tensor, tensor, tensor) -> tensor<*xi64>\r\n  %24 = \"tfl.strided_slice\"(%1, %cst_15, %cst_21, %cst_21) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<2xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor\r\n  %25 = \"tfl.pack\"(%24, %cst_8) {axis = 0 : i32, values_count = 2 : i32} : (tensor, tensor) -> tensor<2xi32>\r\n  %26 = \"tfl.cast\"(%25) : (tensor<2xi32>) -> tensor<2xi64>\r\n  %output_indices_25, %output_shape_26 = \"tf.SparseReshape\"(%sparse_indices#1, %sparse_shapes#1, %26) {device = \"\"} : (tensor, tensor<2xi64>, tensor<2xi64>) -> (tensor, tensor<2xi64>)\r\n  %27 = \"tfl.cast\"(%output_shape_26) : (tensor<2xi64>) -> tensor<2xi32>\r\n  %28 = \"tfl.gather\"(%output_shape_26, %cst_12) {axis = 0 : i32} : (tensor<2xi64>, tensor) -> tensor\r\n  %29 = \"tfl.greater_equal\"(%23, %cst_13) : (tensor<*xi64>, tensor) -> tensor<*xi1>\r\n  %30 = \"tfl.where\"(%29) : (tensor<*xi1>) -> tensor\r\n  %31 = \"tfl.reshape\"(%30, %cst_11) : (tensor, tensor<1xi32>) -> tensor\r\n  %32 = \"tfl.gather\"(%23, %31) {axis = 0 : i32} : (tensor<*xi64>, tensor) -> tensor<*xi64>\r\n  %33 = \"tfl.slice\"(%output_shape_26, %cst_15, %cst_21) : (tensor<2xi64>, tensor<1xi32>, tensor<1xi32>) -> tensor<1xi64>\r\n  %34 = \"tfl.reduce_prod\"(%33, %cst_15) {keep_dims = false} : (tensor<1xi64>, tensor<1xi32>) -> tensor\r\n  %35 = \"tfl.pack\"(%34, %28) {axis = 0 : i32, values_count = 2 : i32} : (tensor, tensor) -> tensor<2xi64>\r\n  %output_indices_27, %output_shape_28 = \"tf.SparseReshape\"(%output_indices_25, %output_shape_26, %35) {device = \"\"} : (tensor, tensor<2xi64>, tensor<2xi64>) -> (tensor, tensor<2xi64>)\r\n  %36 = \"tfl.gather\"(%output_indices_27, %31) {axis = 0 : i32} : (tensor, tensor) -> tensor\r\n  %37 = \"tfl.slice\"(%27, %cst_15, %cst_21) : (tensor<2xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<1xi32>\r\n  %output_indices_29, %output_values_30, %empty_row_indicator_31, %reverse_index_map_32 = \"tf.SparseFillEmptyRows\"(%36, %32, %output_shape_28, %cst_13) {device = \"\"} : (tensor, tensor<*xi64>, tensor<2xi64>, tensor) -> (tensor, tensor, tensor, tensor)\r\n  %38 = \"tfl.reshape\"(%empty_row_indicator_31, %cst_10) : (tensor, tensor<2xi32>) -> tensor\r\n  %output_33, %idx_34 = \"tfl.unique\"(%output_values_30) : (tensor) -> (tensor, tensor)\r\n  %39 = \"tfl.strided_slice\"(%output_indices_29, %cst_16, %cst_17, %cst_18) {begin_mask = 1 : i32, ellipsis_mask = 0 : i32, end_mask = 1 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 2 : i32} : (tensor, tensor<2xi32>, tensor<2xi32>, tensor<2xi32>) -> tensor\r\n  %40 = \"tf.HashTableV2\"() {container = \"\", device = \"\", key_dtype = i64, shared_name = \"hash_table_b60d3bcd-14f8-4085-a3b2-85948ec09373_load_0_199\", use_node_name_sharing = true, value_dtype = i64} : () -> tensor\r\n  %41 = \"tf.LookupTableFindV2\"(%40, %sparse_values#3, %cst_9) {device = \"\"} : (tensor, tensor, tensor) -> tensor<*xi64>\r\n  %42 = \"tfl.strided_slice\"(%2, %cst_15, %cst_21, %cst_21) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<2xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor\r\n  %43 = \"tfl.pack\"(%42, %cst_8) {axis = 0 : i32, values_count = 2 : i32} : (tensor, tensor) -> tensor<2xi32>\r\n  %44 = \"tfl.cast\"(%43) : (tensor<2xi32>) -> tensor<2xi64>\r\n  %output_indices_35, %output_shape_36 = \"tf.SparseReshape\"(%sparse_indices#3, %sparse_shapes#3, %44) {device = \"\"} : (tensor, tensor<2xi64>, tensor<2xi64>) -> (tensor, tensor<2xi64>)\r\n  %45 = \"tfl.cast\"(%output_shape_36) : (tensor<2xi64>) -> tensor<2xi32>\r\n  %46 = \"tfl.gather\"(%output_shape_36, %cst_12) {axis = 0 : i32} : (tensor<2xi64>, tensor) -> tensor\r\n  %47 = \"tfl.greater_equal\"(%41, %cst_13) : (tensor<*xi64>, tensor) -> tensor<*xi1>\r\n  %48 = \"tfl.where\"(%47) : (tensor<*xi1>) -> tensor\r\n  %49 = \"tfl.reshape\"(%48, %cst_11) : (tensor, tensor<1xi32>) -> tensor\r\n  %50 = \"tfl.gather\"(%41, %49) {axis = 0 : i32} : (tensor<*xi64>, tensor) -> tensor<*xi64>\r\n  %51 = \"tfl.slice\"(%output_shape_36, %cst_15, %cst_21) : (tensor<2xi64>, tensor<1xi32>, tensor<1xi32>) -> tensor<1xi64>\r\n  %52 = \"tfl.reduce_prod\"(%51, %cst_15) {keep_dims = false} : (tensor<1xi64>, tensor<1xi32>) -> tensor\r\n  %53 = \"tfl.pack\"(%52, %46) {axis = 0 : i32, values_count = 2 : i32} : (tensor, tensor) -> tensor<2xi64>\r\n  %output_indices_37, %output_shape_38 = \"tf.SparseReshape\"(%output_indices_35, %output_shape_36, %53) {device = \"\"} : (tensor, tensor<2xi64>, tensor<2xi64>) -> (tensor, tensor<2xi64>)\r\n  %54 = \"tfl.gather\"(%output_indices_37, %49) {axis = 0 : i32} : (tensor, tensor) -> tensor\r\n  %55 = \"tfl.slice\"(%45, %cst_15, %cst_21) : (tensor<2xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<1xi32>\r\n  %output_indices_39, %output_values_40, %empty_row_indicator_41, %reverse_index_map_42 = \"tf.SparseFillEmptyRows\"(%54, %50, %output_shape_38, %cst_13) {device = \"\"} : (tensor, tensor<*xi64>, tensor<2xi64>, tensor) -> (tensor, tensor, tensor, tensor)\r\n  %56 = \"tfl.reshape\"(%empty_row_indicator_41, %cst_10) : (tensor, tensor<2xi32>) -> tensor\r\n  %output_43, %idx_44 = \"tfl.unique\"(%output_values_40) : (tensor) -> (tensor, tensor)\r\n  %57 = \"tfl.strided_slice\"(%output_indices_39, %cst_16, %cst_17, %cst_18) {begin_mask = 1 : i32, ellipsis_mask = 0 : i32, end_mask = 1 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 2 : i32} : (tensor, tensor<2xi32>, tensor<2xi32>, tensor<2xi32>) -> tensor\r\n  %58 = \"tf.HashTableV2\"() {container = \"\", device = \"\", key_dtype = i64, shared_name = \"hash_table_cb0918fe-8c8e-41f5-9aad-3750ec00bdad_load_0_200\", use_node_name_sharing = true, value_dtype = i64} : () -> tensor\r\n  %59 = \"tf.LookupTableFindV2\"(%58, %sparse_values#4, %cst_9) {device = \"\"} : (tensor, tensor, tensor) -> tensor<*xi64>\r\n  %60 = \"tfl.strided_slice\"(%3, %cst_15, %cst_21, %cst_21) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<2xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor\r\n  %61 = \"tfl.pack\"(%60, %cst_8) {axis = 0 : i32, values_count = 2 : i32} : (tensor, tensor) -> tensor<2xi32>\r\n  %62 = \"tfl.cast\"(%61) : (tensor<2xi32>) -> tensor<2xi64>\r\n  %output_indices_45, %output_shape_46 = \"tf.SparseReshape\"(%sparse_indices#4, %sparse_shapes#4, %62) {device = \"\"} : (tensor, tensor<2xi64>, tensor<2xi64>) -> (tensor, tensor<2xi64>)\r\n  %63 = \"tfl.cast\"(%output_shape_46) : (tensor<2xi64>) -> tensor<2xi32>\r\n  %64 = \"tfl.gather\"(%output_shape_46, %cst_12) {axis = 0 : i32} : (tensor<2xi64>, tensor) -> tensor\r\n  %65 = \"tfl.greater_equal\"(%59, %cst_13) : (tensor<*xi64>, tensor) -> tensor<*xi1>\r\n  %66 = \"tfl.where\"(%65) : (tensor<*xi1>) -> tensor\r\n  %67 = \"tfl.reshape\"(%66, %cst_11) : (tensor, tensor<1xi32>) -> tensor\r\n  %68 = \"tfl.gather\"(%59, %67) {axis = 0 : i32} : (tensor<*xi64>, tensor) -> tensor<*xi64>\r\n  %69 = \"tfl.slice\"(%output_shape_46, %cst_15, %cst_21) : (tensor<2xi64>, tensor<1xi32>, tensor<1xi32>) -> tensor<1xi64>\r\n  %70 = \"tfl.reduce_prod\"(%69, %cst_15) {keep_dims = false} : (tensor<1xi64>, tensor<1xi32>) -> tensor\r\n  %71 = \"tfl.pack\"(%70, %64) {axis = 0 : i32, values_count = 2 : i32} : (tensor, tensor) -> tensor<2xi64>\r\n  %output_indices_47, %output_shape_48 = \"tf.SparseReshape\"(%output_indices_45, %output_shape_46, %71) {device = \"\"} : (tensor, tensor<2xi64>, tensor<2xi64>) -> (tensor, tensor<2xi64>)\r\n  %72 = \"tfl.gather\"(%output_indices_47, %67) {axis = 0 : i32} : (tensor, tensor) -> tensor\r\n  %73 = \"tfl.slice\"(%63, %cst_15, %cst_21) : (tensor<2xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<1xi32>\r\n  %output_indices_49, %output_values_50, %empty_row_indicator_51, %reverse_index_map_52 = \"tf.SparseFillEmptyRows\"(%72, %68, %output_shape_48, %cst_13) {device = \"\"} : (tensor, tensor<*xi64>, tensor<2xi64>, tensor) -> (tensor, tensor, tensor, tensor)\r\n  %74 = \"tfl.reshape\"(%empty_row_indicator_51, %cst_10) : (tensor, tensor<2xi32>) -> tensor\r\n  %output_53, %idx_54 = \"tfl.unique\"(%output_values_50) : (tensor) -> (tensor, tensor)\r\n  %75 = \"tfl.strided_slice\"(%output_indices_49, %cst_16, %cst_17, %cst_18) {begin_mask = 1 : i32, ellipsis_mask = 0 : i32, end_mask = 1 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 2 : i32} : (tensor, tensor<2xi32>, tensor<2xi32>, tensor<2xi32>) -> tensor\r\n  %76 = \"tfl.gather\"(%cst_2, %output) {axis = 0 : i32} : (tensor<7x1xf32>, tensor) -> tensor\r\n  %77 = \"tfl.custom_tf\"(%76, %idx, %21) ( {\r\n    %127 = \"tf.SparseSegmentSum\"(%76, %idx, %21) {T = f32, Tidx = i32, Tsegmentids = i64, device = \"\"} : (tensor, tensor, tensor) -> tensor\r\n    \"tfl.yield\"(%127) : (tensor) -> ()\r\n  }) : (tensor, tensor, tensor) -> tensor\r\n  %78 = \"tfl.shape\"(%77) : (tensor) -> tensor<2xi32>\r\n  %79 = \"tfl.strided_slice\"(%78, %cst_21, %cst_20, %cst_21) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<2xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor\r\n  %80 = \"tfl.pack\"(%cst_12, %79) {axis = 0 : i32, values_count = 2 : i32} : (tensor, tensor) -> tensor<2xi32>\r\n  %81 = \"tfl.tile\"(%20, %80) : (tensor, tensor<2xi32>) -> tensor\r\n  %82 = \"tfl.zeros_like\"(%77) : (tensor) -> tensor\r\n  %83 = \"tfl.select\"(%81, %82, %77) : (tensor, tensor, tensor) -> tensor\r\n  %84 = \"tfl.shape\"(%83) : (tensor) -> tensor<2xi32>\r\n  %85 = \"tfl.slice\"(%84, %cst_21, %cst_11) : (tensor<2xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<1xi32>\r\n  %86 = \"tfl.concatenation\"(%19, %85) {axis = 0 : i32, fused_activation_function = \"NONE\"} : (tensor<1xi32>, tensor<1xi32>) -> tensor<2xi32>\r\n  %87 = \"tfl.reshape\"(%83, %86) : (tensor, tensor<2xi32>) -> tensor\r\n  %88 = \"tfl.gather\"(%cst_1, %output_33) {axis = 0 : i32} : (tensor<6203x1xf32>, tensor) -> tensor\r\n  %89 = \"tfl.custom_tf\"(%88, %idx_34, %39) ( {\r\n    %127 = \"tf.SparseSegmentSum\"(%88, %idx_34, %39) {T = f32, Tidx = i32, Tsegmentids = i64, device = \"\"} : (tensor, tensor, tensor) -> tensor\r\n    \"tfl.yield\"(%127) : (tensor) -> ()\r\n  }) : (tensor, tensor, tensor) -> tensor\r\n  %90 = \"tfl.shape\"(%89) : (tensor) -> tensor<2xi32>\r\n  %91 = \"tfl.strided_slice\"(%90, %cst_21, %cst_20, %cst_21) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<2xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor\r\n  %92 = \"tfl.pack\"(%cst_12, %91) {axis = 0 : i32, values_count = 2 : i32} : (tensor, tensor) -> tensor<2xi32>\r\n  %93 = \"tfl.tile\"(%38, %92) : (tensor, tensor<2xi32>) -> tensor\r\n  %94 = \"tfl.zeros_like\"(%89) : (tensor) -> tensor\r\n  %95 = \"tfl.select\"(%93, %94, %89) : (tensor, tensor, tensor) -> tensor\r\n  %96 = \"tfl.shape\"(%95) : (tensor) -> tensor<2xi32>\r\n  %97 = \"tfl.slice\"(%96, %cst_21, %cst_11) : (tensor<2xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<1xi32>\r\n  %98 = \"tfl.concatenation\"(%37, %97) {axis = 0 : i32, fused_activation_function = \"NONE\"} : (tensor<1xi32>, tensor<1xi32>) -> tensor<2xi32>\r\n  %99 = \"tfl.reshape\"(%95, %98) : (tensor, tensor<2xi32>) -> tensor\r\n  %100 = \"tfl.gather\"(%cst_0, %output_43) {axis = 0 : i32} : (tensor<2x1xf32>, tensor) -> tensor\r\n  %101 = \"tfl.custom_tf\"(%100, %idx_44, %57) ( {\r\n    %127 = \"tf.SparseSegmentSum\"(%100, %idx_44, %57) {T = f32, Tidx = i32, Tsegmentids = i64, device = \"\"} : (tensor, tensor, tensor) -> tensor\r\n    \"tfl.yield\"(%127) : (tensor) -> ()\r\n  }) : (tensor, tensor, tensor) -> tensor\r\n  %102 = \"tfl.shape\"(%101) : (tensor) -> tensor<2xi32>\r\n  %103 = \"tfl.strided_slice\"(%102, %cst_21, %cst_20, %cst_21) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<2xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor\r\n  %104 = \"tfl.pack\"(%cst_12, %103) {axis = 0 : i32, values_count = 2 : i32} : (tensor, tensor) -> tensor<2xi32>\r\n  %105 = \"tfl.tile\"(%56, %104) : (tensor, tensor<2xi32>) -> tensor\r\n  %106 = \"tfl.zeros_like\"(%101) : (tensor) -> tensor\r\n  %107 = \"tfl.select\"(%105, %106, %101) : (tensor, tensor, tensor) -> tensor\r\n  %108 = \"tfl.shape\"(%107) : (tensor) -> tensor<2xi32>\r\n  %109 = \"tfl.slice\"(%108, %cst_21, %cst_11) : (tensor<2xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<1xi32>\r\n  %110 = \"tfl.concatenation\"(%55, %109) {axis = 0 : i32, fused_activation_function = \"NONE\"} : (tensor<1xi32>, tensor<1xi32>) -> tensor<2xi32>\r\n  %111 = \"tfl.reshape\"(%107, %110) : (tensor, tensor<2xi32>) -> tensor\r\n  %112 = \"tfl.fully_connected\"(%dense_values#3, %cst_14, %cst_19) {fused_activation_function = \"NONE\", keep_num_dims = false, weights_format = \"DEFAULT\"} : (tensor, tensor<1x1xf32>, none) -> tensor\r\n  %113 = \"tfl.gather\"(%cst, %output_53) {axis = 0 : i32} : (tensor<80x1xf32>, tensor) -> tensor\r\n  %114 = \"tfl.custom_tf\"(%113, %idx_54, %75) ( {\r\n    %127 = \"tf.SparseSegmentSum\"(%113, %idx_54, %75) {T = f32, Tidx = i32, Tsegmentids = i64, device = \"\"} : (tensor, tensor, tensor) -> tensor\r\n    \"tfl.yield\"(%127) : (tensor) -> ()\r\n  }) : (tensor, tensor, tensor) -> tensor\r\n  %115 = \"tfl.shape\"(%114) : (tensor) -> tensor<2xi32>\r\n  %116 = \"tfl.strided_slice\"(%115, %cst_21, %cst_20, %cst_21) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<2xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor\r\n  %117 = \"tfl.pack\"(%cst_12, %116) {axis = 0 : i32, values_count = 2 : i32} : (tensor, tensor) -> tensor<2xi32>\r\n  %118 = \"tfl.tile\"(%74, %117) : (tensor, tensor<2xi32>) -> tensor\r\n  %119 = \"tfl.zeros_like\"(%114) : (tensor) -> tensor\r\n  %120 = \"tfl.select\"(%118, %119, %114) : (tensor, tensor, tensor) -> tensor\r\n  %121 = \"tfl.shape\"(%120) : (tensor) -> tensor<2xi32>\r\n  %122 = \"tfl.slice\"(%121, %cst_21, %cst_11) : (tensor<2xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<1xi32>\r\n  %123 = \"tfl.concatenation\"(%73, %122) {axis = 0 : i32, fused_activation_function = \"NONE\"} : (tensor<1xi32>, tensor<1xi32>) -> tensor<2xi32>\r\n  %124 = \"tfl.reshape\"(%120, %123) : (tensor, tensor<2xi32>) -> tensor\r\n  %125 = \"tfl.add_n\"(%87, %99, %111, %112, %124) : (tensor, tensor, tensor, tensor, tensor) -> tensor\r\n  %126 = \"tfl.add\"(%125, %cst_3) {fused_activation_function = \"NONE\"} : (tensor, tensor<1xf32>) -> tensor\r\n  \"std.return\"(%126) : (tensor) -> ()\r\n}) {arg0 = {tf_saved_model.index_path = [\"examples\"]}, result0 = {tf_saved_model.index_path = [\"predictions\"]}, sym_name = \"main\", tf.entry_function = {control_outputs = \"\", inputs = \"serving_default_examples:0\", outputs = \"StatefulPartitionedCall_1:0\"}, tf_saved_model.exported_names = [\"serving_default\"], type = (tensor) -> tensor} : () -> ()\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nConverterError                            Traceback (most recent call last)\r\n in \r\n      1 converter = tf.lite.TFLiteConverter.from_saved_model('test2')\r\n----> 2 tflite_model = converter.convert()\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py in convert(self)\r\n    722         for key in signature_def.outputs\r\n    723     ]\r\n--> 724     return super(TFLiteSavedModelConverterV2,\r\n    725                  self).convert(meta_graph.graph_def, input_tensors,\r\n    726                                output_tensors)\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py in convert(self, graph_def, input_tensors, output_tensors)\r\n    637 \r\n    638     # Converts model.\r\n--> 639     result = _toco_convert_impl(\r\n    640         input_data=graph_def,\r\n    641         input_tensors=input_tensors,\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py in toco_convert_impl(input_data, input_tensors, output_tensors, enable_mlir_converter, *args, **kwargs)\r\n    567       input_tensors, output_tensors, *args, **kwargs)\r\n    568   debug_info_str = debug_info.SerializeToString() if debug_info else None\r\n--> 569   data = toco_convert_protos(\r\n    570       model_flags.SerializeToString(),\r\n    571       toco_flags.SerializeToString(),\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\r\n    200       return model_str\r\n    201     except Exception as e:\r\n--> 202       raise ConverterError(str(e))\r\n    203 \r\n    204   if distutils.spawn.find_executable(_toco_from_proto_bin) is None:\r\n\r\nConverterError: :0: error: loc(callsite(callsite(\"ParseExample/ParseExampleV2@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): 'tf.ParseExampleV2' op is neither a custom op nor a flex op\r\n:0: note: loc(\"StatefulPartitionedCall_1\"): called from\r\n:0: note: loc(callsite(callsite(\"ParseExample/ParseExampleV2@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): see current operation: %sparse_indices:5, %sparse_values:5, %sparse_shapes:5, %dense_values:5 = \"tf.ParseExampleV2\"(%arg0, %cst_6, %cst_7, %cst_5, %cst_6, %cst_4, %cst_4, %cst_4, %cst_4, %cst_4) {dense_shapes = [#tf.shape<1>, #tf.shape<1>, #tf.shape<1>, #tf.shape<1>, #tf.shape<1>], device = \"\", num_sparse = 5 : i64, result_segment_sizes = dense<[5, 5, 5, 5, 0, 0]> : vector<6xi32>} : (tensor, tensor<0x!tf.string>, tensor<5x!tf.string>, tensor<5x!tf.string>, tensor<0x!tf.string>, tensor<0xf32>, tensor<0xf32>, tensor<0xf32>, tensor<0xf32>, tensor<0xf32>) -> (tensor, tensor, tensor, tensor, tensor, tensor, tensor, tensor, tensor, tensor, tensor<2xi64>, tensor<2xi64>, tensor<2xi64>, tensor<2xi64>, tensor<2xi64>, tensor, tensor, tensor, tensor, tensor)\r\n:0: error: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/category_id/category_id_lookup/hash_table/hash_table@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): 'tf.HashTableV2' op is neither a custom op nor a flex op\r\n:0: note: loc(\"StatefulPartitionedCall_1\"): called from\r\n:0: note: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/category_id/category_id_lookup/hash_table/hash_table@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): see current operation: %4 = \"tf.HashTableV2\"() {container = \"\", device = \"\", key_dtype = i64, shared_name = \"hash_table_8d6f1b8e-423d-4fff-8a54-69f4ddbecf04_load_0_197\", use_node_name_sharing = true, value_dtype = i64} : () -> tensor\r\n:0: error: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/category_id/hash_table_Lookup/LookupTableFindV2@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): 'tf.LookupTableFindV2' op is neither a custom op nor a flex op\r\n:0: note: loc(\"StatefulPartitionedCall_1\"): called from\r\n:0: note: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/category_id/hash_table_Lookup/LookupTableFindV2@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): see current operation: %5 = \"tf.LookupTableFindV2\"(%4, %sparse_values#0, %cst_9) {device = \"\"} : (tensor, tensor, tensor) -> tensor<*xi64>\r\n:0: error: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/category_id/SparseReshape@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): 'tf.SparseReshape' op is neither a custom op nor a flex op\r\n:0: note: loc(\"StatefulPartitionedCall_1\"): called from\r\n:0: note: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/category_id/SparseReshape@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): see current operation: %output_indices, %output_shape = \"tf.SparseReshape\"(%sparse_indices#0, %sparse_shapes#0, %8) {device = \"\"} : (tensor, tensor<2xi64>, tensor<2xi64>) -> (tensor, tensor<2xi64>)\r\n:0: error: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/category_id/weighted_sum/SparseReshape@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): 'tf.SparseReshape' op is neither a custom op nor a flex op\r\n:0: note: loc(\"StatefulPartitionedCall_1\"): called from\r\n:0: note: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/category_id/weighted_sum/SparseReshape@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): see current operation: %output_indices_22, %output_shape_23 = \"tf.SparseReshape\"(%output_indices, %output_shape, %17) {device = \"\"} : (tensor, tensor<2xi64>, tensor<2xi64>) -> (tensor, tensor<2xi64>)\r\n:0: error: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/category_id/weighted_sum/SparseFillEmptyRows/SparseFillEmptyRows@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): 'tf.SparseFillEmptyRows' op is neither a custom op nor a flex op\r\n:0: note: loc(\"StatefulPartitionedCall_1\"): called from\r\n:0: note: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/category_id/weighted_sum/SparseFillEmptyRows/SparseFillEmptyRows@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): see current operation: %output_indices_24, %output_values, %empty_row_indicator, %reverse_index_map = \"tf.SparseFillEmptyRows\"(%18, %14, %output_shape_23, %cst_13) {device = \"\"} : (tensor, tensor<*xi64>, tensor<2xi64>, tensor) -> (tensor, tensor, tensor, tensor)\r\n:0: error: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/description/description_lookup/hash_table/hash_table@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): 'tf.HashTableV2' op is neither a custom op nor a flex op\r\n:0: note: loc(\"StatefulPartitionedCall_1\"): called from\r\n:0: note: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/description/description_lookup/hash_table/hash_table@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): see current operation: %22 = \"tf.HashTableV2\"() {container = \"\", device = \"\", key_dtype = !tf.string, shared_name = \"hash_table_fc7c2e70-8a89-4115-84d4-2f713273e69c_load_0_198\", use_node_name_sharing = true, value_dtype = i64} : () -> tensor\r\n:0: error: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/description/hash_table_Lookup/LookupTableFindV2@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): 'tf.LookupTableFindV2' op is neither a custom op nor a flex op\r\n:0: note: loc(\"StatefulPartitionedCall_1\"): called from\r\n:0: note: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/description/hash_table_Lookup/LookupTableFindV2@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): see current operation: %23 = \"tf.LookupTableFindV2\"(%22, %sparse_values#1, %cst_9) {device = \"\"} : (tensor, tensor, tensor) -> tensor<*xi64>\r\n:0: error: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/description/SparseReshape@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): 'tf.SparseReshape' op is neither a custom op nor a flex op\r\n:0: note: loc(\"StatefulPartitionedCall_1\"): called from\r\n:0: note: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/description/SparseReshape@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): see current operation: %output_indices_25, %output_shape_26 = \"tf.SparseReshape\"(%sparse_indices#1, %sparse_shapes#1, %26) {device = \"\"} : (tensor, tensor<2xi64>, tensor<2xi64>) -> (tensor, tensor<2xi64>)\r\n:0: error: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/description/weighted_sum/SparseReshape@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): 'tf.SparseReshape' op is neither a custom op nor a flex op\r\n:0: note: loc(\"StatefulPartitionedCall_1\"): called from\r\n:0: note: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/description/weighted_sum/SparseReshape@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): see current operation: %output_indices_27, %output_shape_28 = \"tf.SparseReshape\"(%output_indices_25, %output_shape_26, %35) {device = \"\"} : (tensor, tensor<2xi64>, tensor<2xi64>) -> (tensor, tensor<2xi64>)\r\n:0: error: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/description/weighted_sum/SparseFillEmptyRows/SparseFillEmptyRows@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): 'tf.SparseFillEmptyRows' op is neither a custom op nor a flex op\r\n:0: note: loc(\"StatefulPartitionedCall_1\"): called from\r\n:0: note: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/description/weighted_sum/SparseFillEmptyRows/SparseFillEmptyRows@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): see current operation: %output_indices_29, %output_values_30, %empty_row_indicator_31, %reverse_index_map_32 = \"tf.SparseFillEmptyRows\"(%36, %32, %output_shape_28, %cst_13) {device = \"\"} : (tensor, tensor<*xi64>, tensor<2xi64>, tensor) -> (tensor, tensor, tensor, tensor)\r\n:0: error: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/host_id/host_id_lookup/hash_table/hash_table@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): 'tf.HashTableV2' op is neither a custom op nor a flex op\r\n:0: note: loc(\"StatefulPartitionedCall_1\"): called from\r\n:0: note: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/host_id/host_id_lookup/hash_table/hash_table@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): see current operation: %40 = \"tf.HashTableV2\"() {container = \"\", device = \"\", key_dtype = i64, shared_name = \"hash_table_b60d3bcd-14f8-4085-a3b2-85948ec09373_load_0_199\", use_node_name_sharing = true, value_dtype = i64} : () -> tensor\r\n:0: error: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/host_id/hash_table_Lookup/LookupTableFindV2@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): 'tf.LookupTableFindV2' op is neither a custom op nor a flex op\r\n:0: note: loc(\"StatefulPartitionedCall_1\"): called from\r\n:0: note: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/host_id/hash_table_Lookup/LookupTableFindV2@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): see current operation: %41 = \"tf.LookupTableFindV2\"(%40, %sparse_values#3, %cst_9) {device = \"\"} : (tensor, tensor, tensor) -> tensor<*xi64>\r\n:0: error: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/host_id/SparseReshape@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): 'tf.SparseReshape' op is neither a custom op nor a flex op\r\n:0: note: loc(\"StatefulPartitionedCall_1\"): called from\r\n:0: note: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/host_id/SparseReshape@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): see current operation: %output_indices_35, %output_shape_36 = \"tf.SparseReshape\"(%sparse_indices#3, %sparse_shapes#3, %44) {device = \"\"} : (tensor, tensor<2xi64>, tensor<2xi64>) -> (tensor, tensor<2xi64>)\r\n:0: error: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/host_id/weighted_sum/SparseReshape@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): 'tf.SparseReshape' op is neither a custom op nor a flex op\r\n:0: note: loc(\"StatefulPartitionedCall_1\"): called from\r\n:0: note: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/host_id/weighted_sum/SparseReshape@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): see current operation: %output_indices_37, %output_shape_38 = \"tf.SparseReshape\"(%output_indices_35, %output_shape_36, %53) {device = \"\"} : (tensor, tensor<2xi64>, tensor<2xi64>) -> (tensor, tensor<2xi64>)\r\n:0: error: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/host_id/weighted_sum/SparseFillEmptyRows/SparseFillEmptyRows@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): 'tf.SparseFillEmptyRows' op is neither a custom op nor a flex op\r\n:0: note: loc(\"StatefulPartitionedCall_1\"): called from\r\n:0: note: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/host_id/weighted_sum/SparseFillEmptyRows/SparseFillEmptyRows@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): see current operation: %output_indices_39, %output_values_40, %empty_row_indicator_41, %reverse_index_map_42 = \"tf.SparseFillEmptyRows\"(%54, %50, %output_shape_38, %cst_13) {device = \"\"} : (tensor, tensor<*xi64>, tensor<2xi64>, tensor) -> (tensor, tensor, tensor, tensor)\r\n:0: error: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/size_id/size_id_lookup/hash_table/hash_table@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): 'tf.HashTableV2' op is neither a custom op nor a flex op\r\n:0: note: loc(\"StatefulPartitionedCall_1\"): called from\r\n:0: note: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/size_id/size_id_lookup/hash_table/hash_table@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): see current operation: %58 = \"tf.HashTableV2\"() {container = \"\", device = \"\", key_dtype = i64, shared_name = \"hash_table_cb0918fe-8c8e-41f5-9aad-3750ec00bdad_load_0_200\", use_node_name_sharing = true, value_dtype = i64} : () -> tensor\r\n:0: error: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/size_id/hash_table_Lookup/LookupTableFindV2@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): 'tf.LookupTableFindV2' op is neither a custom op nor a flex op\r\n:0: note: loc(\"StatefulPartitionedCall_1\"): called from\r\n:0: note: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/size_id/hash_table_Lookup/LookupTableFindV2@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): see current operation: %59 = \"tf.LookupTableFindV2\"(%58, %sparse_values#4, %cst_9) {device = \"\"} : (tensor, tensor, tensor) -> tensor<*xi64>\r\n:0: error: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/size_id/SparseReshape@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): 'tf.SparseReshape' op is neither a custom op nor a flex op\r\n:0: note: loc(\"StatefulPartitionedCall_1\"): called from\r\n:0: note: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/size_id/SparseReshape@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): see current operation: %output_indices_45, %output_shape_46 = \"tf.SparseReshape\"(%sparse_indices#4, %sparse_shapes#4, %62) {device = \"\"} : (tensor, tensor<2xi64>, tensor<2xi64>) -> (tensor, tensor<2xi64>)\r\n:0: error: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/size_id/weighted_sum/SparseReshape@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): 'tf.SparseReshape' op is neither a custom op nor a flex op\r\n:0: note: loc(\"StatefulPartitionedCall_1\"): called from\r\n:0: note: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/size_id/weighted_sum/SparseReshape@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): see current operation: %output_indices_47, %output_shape_48 = \"tf.SparseReshape\"(%output_indices_45, %output_shape_46, %71) {device = \"\"} : (tensor, tensor<2xi64>, tensor<2xi64>) -> (tensor, tensor<2xi64>)\r\n:0: error: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/size_id/weighted_sum/SparseFillEmptyRows/SparseFillEmptyRows@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): 'tf.SparseFillEmptyRows' op is neither a custom op nor a flex op\r\n:0: note: loc(\"StatefulPartitionedCall_1\"): called from\r\n:0: note: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/size_id/weighted_sum/SparseFillEmptyRows/SparseFillEmptyRows@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): see current operation: %output_indices_49, %output_values_50, %empty_row_indicator_51, %reverse_index_map_52 = \"tf.SparseFillEmptyRows\"(%72, %68, %output_shape_48, %cst_13) {device = \"\"} : (tensor, tensor<*xi64>, tensor<2xi64>, tensor) -> (tensor, tensor, tensor, tensor)\r\n:0: error: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/category_id/weighted_sum/embedding_lookup_sparse@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): 'tf.SparseSegmentSum' op is neither a custom op nor a flex op\r\n:0: note: loc(\"StatefulPartitionedCall_1\"): called from\r\n:0: note: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/category_id/weighted_sum/embedding_lookup_sparse@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): see current operation: %127 = \"tf.SparseSegmentSum\"(%76, %idx, %21) {T = f32, Tidx = i32, Tsegmentids = i64, device = \"\"} : (tensor, tensor, tensor) -> tensor\r\n:0: error: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/description/weighted_sum/embedding_lookup_sparse@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): 'tf.SparseSegmentSum' op is neither a custom op nor a flex op\r\n:0: note: loc(\"StatefulPartitionedCall_1\"): called from\r\n:0: note: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/description/weighted_sum/embedding_lookup_sparse@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): see current operation: %127 = \"tf.SparseSegmentSum\"(%88, %idx_34, %39) {T = f32, Tidx = i32, Tsegmentids = i64, device = \"\"} : (tensor, tensor, tensor) -> tensor\r\n:0: error: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/host_id/weighted_sum/embedding_lookup_sparse@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): 'tf.SparseSegmentSum' op is neither a custom op nor a flex op\r\n:0: note: loc(\"StatefulPartitionedCall_1\"): called from\r\n:0: note: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/host_id/weighted_sum/embedding_lookup_sparse@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): see current operation: %127 = \"tf.SparseSegmentSum\"(%100, %idx_44, %57) {T = f32, Tidx = i32, Tsegmentids = i64, device = \"\"} : (tensor, tensor, tensor) -> tensor\r\n:0: error: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/size_id/weighted_sum/embedding_lookup_sparse@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): 'tf.SparseSegmentSum' op is neither a custom op nor a flex op\r\n:0: note: loc(\"StatefulPartitionedCall_1\"): called from\r\n:0: note: loc(callsite(callsite(\"linear/linear_model/linear/linear_model/linear/linear_model/size_id/weighted_sum/embedding_lookup_sparse@__inference_pruned_1133\" at \"StatefulPartitionedCall@__inference_signature_wrapper_1850\") at \"StatefulPartitionedCall_1\")): see current operation: %127 = \"tf.SparseSegmentSum\"(%113, %idx_54, %75) {T = f32, Tidx = i32, Tsegmentids = i64, device = \"\"} : (tensor, tensor, tensor) -> tensor\r\n:0: error: failed while converting: 'main': Ops that can be supported by the flex runtime (enabled via setting the -emit-select-tf-ops flag):\r\n\ttf.ParseExampleV2 {dense_shapes = [#tf.shape<1>, #tf.shape<1>, #tf.shape<1>, #tf.shape<1>, #tf.shape<1>], device = \"\", num_sparse = 5 : i64, result_segment_sizes = dense<[5, 5, 5, 5, 0, 0]> : vector<6xi32>}\r\n\ttf.SparseFillEmptyRows {device = \"\"}\r\n\ttf.SparseReshape {device = \"\"}\r\n\ttf.SparseSegmentSum {T = f32, Tidx = i32, Tsegmentids = i64, device = \"\"}Ops that need custom implementation (enabled via setting the -emit-custom-ops flag):\r\n\ttf.HashTableV2 {container = \"\", device = \"\", key_dtype = !tf.string, shared_name = \"hash_table_fc7c2e70-8a89-4115-84d4-2f713273e69c_load_0_198\", use_node_name_sharing = true, value_dtype = i64}\r\n\ttf.HashTableV2 {container = \"\", device = \"\", key_dtype = i64, shared_name = \"hash_table_8d6f1b8e-423d-4fff-8a54-69f4ddbecf04_load_0_197\", use_node_name_sharing = true, value_dtype = i64}\r\n\ttf.HashTableV2 {container = \"\", device = \"\", key_dtype = i64, shared_name = \"hash_table_b60d3bcd-14f8-4085-a3b2-85948ec09373_load_0_199\", use_node_name_sharing = true, value_dtype = i64}\r\n\ttf.HashTableV2 {container = \"\", device = \"\", key_dtype = i64, shared_name = \"hash_table_cb0918fe-8c8e-41f5-9aad-3750ec00bdad_load_0_200\", use_node_name_sharing = true, value_dtype = i64}\r\n\ttf.LookupTableFindV2 {device = \"\"}\r\n:0: note: see current operation: \"func\"() ( {\r\n^bb0(%arg0: tensor):  // no predecessors\r\n  %cst = \"std.constant\"() {value = dense<[[0.117987722], [-0.0684242323], [0.100408614], [0.0145546673], [0.0430826135], [-0.103112921], [0.0680344701], [-0.0248609539], [0.0398180261], [0.122247897], [0.0273514148], [0.0187784135], [0.102349631], [-0.0905613824], [-0.0723603144], [-0.0438856669], [0.0021427928], [0.0984751954], [0.0817138106], [-0.109699354], [-0.191155598], [-0.0545536913], [-9.727810e-02], [0.0141912363], [7.680510e-02], [-0.0899474472], [0.0498611145], [-0.0884774774], [-0.114087969], [0.0725763887], [-0.141074464], [-0.176522136], [0.0143758887], [0.0524854325], [-0.155160338], [-0.0285528414], [-0.264534861], [0.106433257], [0.135232121], [0.225332677], [0.129775301], [-0.191358164], [-0.0178745817], [0.0918667614], [0.107648872], [-0.0921946167], [0.064818345], [0.0105348462], [-0.132097453], [-0.110714845], [0.0700208098], [0.034297362], [0.0263220761], [-0.059998773], [-0.0116290115], [0.101751082], [0.0713425949], [-0.0987613201], [-0.209998265], [0.0471415743], [0.10908471], [7.703180e-03], [0.0123223783], [0.103961319], [0.00920343306], [-0.110373154], [-0.113558963], [-0.0215992182], [-0.21590668], [-0.103494935], [-0.21094574], [-0.132196262], [0.18838799], [0.659609914], [-0.209931418], [-0.195380583], [-0.115891144], [-0.130379677], [-0.236354247], [0.111823596]]> : tensor<80x1xf32>} : () -> tensor<80x1xf32>\r\n  %cst_0 = \"std.constant\"() {value = dense<[[0.0778336599], [0.0839953199]]> : tensor<2x1xf32>} : () -> tensor<2x1xf32>\r\n  %cst_1 = \"std.constant\"() {value = dense<\"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tensor<6203x1xf32>} : () -> tensor<6203x1xf32>\r\n  %cst_2 = \"std.constant\"() {value = dense<[[0.137156427], [0.0727723241], [0.0427678488], [-2.75064172E-4], [-0.0233619846], [0.0394954272], [-0.0791109725]]> : tensor<7x1xf32>} : () -> tensor<7x1xf32>\r\n  %cst_3 = \"std.constant\"() {value = dense<0.131277829> : tensor<1xf32>} : () -> tensor<1xf32>\r\n  %cst_4 = \"std.constant\"() {value = dense<> : tensor<0xf32>} : () -> tensor<0xf32>\r\n  %cst_5 = \"std.constant\"() {value = dense<[\"lat\", \"long\", \"month\", \"price\", \"year\"]> : tensor<5x!tf.string>} : () -> tensor<5x!tf.string>\r\n  %cst_6 = \"std.constant\"() {value = dense<> : tensor<0x!tf.string>} : () -> tensor<0x!tf.string>\r\n  %cst_7 = \"std.constant\"() {value = dense<[\"category_id\", \"description\", \"gender\", \"host_id\", \"size_id\"]> : tensor<5x!tf.string>} : () -> tensor<5x!tf.string>\r\n  %cst_8 = \"std.constant\"() {value = dense<-1> : tensor} : () -> tensor\r\n  %cst_9 = \"std.constant\"() {value = dense<-1> : tensor} : () -> tensor\r\n  %cst_10 = \"std.constant\"() {value = dense<[-1, 1]> : tensor<2xi32>} : () -> tensor<2xi32>\r\n  %cst_11 = \"std.constant\"() {value = dense<-1> : tensor<1xi32>} : () -> tensor<1xi32>\r\n  %cst_12 = \"std.constant\"() {value = dense<1> : tensor} : () -> tensor\r\n  %cst_13 = \"std.constant\"() {value = dense<0> : tensor} : () -> tensor\r\n  %cst_14 = \"std.constant\"() {value = dense<-0.0035018248> : tensor<1x1xf32>} : () -> tensor<1x1xf32>\r\n  %cst_15 = \"std.constant\"() {value = dense<0> : tensor<1xi32>} : () -> tensor<1xi32>\r\n  %cst_16 = \"std.constant\"() {value = dense<0> : tensor<2xi32>} : () -> tensor<2xi32>\r\n  %cst_17 = \"std.constant\"() {value = dense<[0, 1]> : tensor<2xi32>} : () -> tensor<2xi32>\r\n  %cst_18 = \"std.constant\"() {value = dense<1> : tensor<2xi32>} : () -> tensor<2xi32>\r\n  %cst_19 = \"std.constant\"() {value} : () -> none\r\n  %cst_20 = \"std.constant\"() {value = dense<2> : tensor<1xi32>} : () -> tensor<1xi32>\r\n  %cst_21 = \"std.constant\"() {value = dense<1> : tensor<1xi32>} : () -> tensor<1xi32>\r\n  %sparse_indices:5, %sparse_values:5, %sparse_shapes:5, %dense_values:5 = \"tf.ParseExampleV2\"(%arg0, %cst_6, %cst_7, %cst_5, %cst_6, %cst_4, %cst_4, %cst_4, %cst_4, %cst_4) {dense_shapes = [#tf.shape<1>, #tf.shape<1>, #tf.shape<1>, #tf.shape<1>, #tf.shape<1>], device = \"\", num_sparse = 5 : i64, result_segment_sizes = dense<[5, 5, 5, 5, 0, 0]> : vector<6xi32>} : (tensor, tensor<0x!tf.string>, tensor<5x!tf.string>, tensor<5x!tf.string>, tensor<0x!tf.string>, tensor<0xf32>, tensor<0xf32>, tensor<0xf32>, tensor<0xf32>, tensor<0xf32>) -> (tensor, tensor, tensor, tensor, tensor, tensor, tensor, tensor, tensor, tensor, tensor<2xi64>, tensor<2xi64>, tensor<2xi64>, tensor<2xi64>, tensor<2xi64>, tensor, tensor, tensor, tensor, tensor)\r\n  %0 = \"tfl.cast\"(%sparse_shapes#0) : (tensor<2xi64>) -> tensor<2xi32>\r\n  %1 = \"tfl.cast\"(%sparse_shapes#1) : (tensor<2xi64>) -> tensor<2xi32>\r\n  %2 = \"tfl.cast\"(%sparse_shapes#3) : (tensor<2xi64>) -> tensor<2xi32>\r\n  %3 = \"tfl.cast\"(%sparse_shapes#4) : (tensor<2xi64>) -> tensor<2xi32>\r\n  %4 = \"tf.HashTableV2\"() {container = \"\", device = \"\", key_dtype = i64, shared_name = \"hash_table_8d6f1b8e-423d-4fff-8a54-69f4ddbecf04_load_0_197\", use_node_name_sharing = true, value_dtype = i64} : () -> tensor\r\n  %5 = \"tf.LookupTableFindV2\"(%4, %sparse_values#0, %cst_9) {device = \"\"} : (tensor, tensor, tensor) -> tensor<*xi64>\r\n  %6 = \"tfl.strided_slice\"(%0, %cst_15, %cst_21, %cst_21) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<2xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor\r\n  %7 = \"tfl.pack\"(%6, %cst_8) {axis = 0 : i32, values_count = 2 : i32} : (tensor, tensor) -> tensor<2xi32>\r\n  %8 = \"tfl.cast\"(%7) : (tensor<2xi32>) -> tensor<2xi64>\r\n  %output_indices, %output_shape = \"tf.SparseReshape\"(%sparse_indices#0, %sparse_shapes#0, %8) {device = \"\"} : (tensor, tensor<2xi64>, tensor<2xi64>) -> (tensor, tensor<2xi64>)\r\n  %9 = \"tfl.cast\"(%output_shape) : (tensor<2xi64>) -> tensor<2xi32>\r\n  %10 = \"tfl.gather\"(%output_shape, %cst_12) {axis = 0 : i32} : (tensor<2xi64>, tensor) -> tensor\r\n  %11 = \"tfl.greater_equal\"(%5, %cst_13) : (tensor<*xi64>, tensor) -> tensor<*xi1>\r\n  %12 = \"tfl.where\"(%11) : (tensor<*xi1>) -> tensor\r\n  %13 = \"tfl.reshape\"(%12, %cst_11) : (tensor, tensor<1xi32>) -> tensor\r\n  %14 = \"tfl.gather\"(%5, %13) {axis = 0 : i32} : (tensor<*xi64>, tensor) -> tensor<*xi64>\r\n  %15 = \"tfl.slice\"(%output_shape, %cst_15, %cst_21) : (tensor<2xi64>, tensor<1xi32>, tensor<1xi32>) -> tensor<1xi64>\r\n  %16 = \"tfl.reduce_prod\"(%15, %cst_15) {keep_dims = false} : (tensor<1xi64>, tensor<1xi32>) -> tensor\r\n  %17 = \"tfl.pack\"(%16, %10) {axis = 0 : i32, values_count = 2 : i32} : (tensor, tensor) -> tensor<2xi64>\r\n  %output_indices_22, %output_shape_23 = \"tf.SparseReshape\"(%output_indices, %output_shape, %17) {device = \"\"} : (tensor, tensor<2xi64>, tensor<2xi64>) -> (tensor, tensor<2xi64>)\r\n  %18 = \"tfl.gather\"(%output_indices_22, %13) {axis = 0 : i32} : (tensor, tensor) -> tensor\r\n  %19 = \"tfl.slice\"(%9, %cst_15, %cst_21) : (tensor<2xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<1xi32>\r\n  %output_indices_24, %output_values, %empty_row_indicator, %reverse_index_map = \"tf.SparseFillEmptyRows\"(%18, %14, %output_shape_23, %cst_13) {device = \"\"} : (tensor, tensor<*xi64>, tensor<2xi64>, tensor) -> (tensor, tensor, tensor, tensor)\r\n  %20 = \"tfl.reshape\"(%empty_row_indicator, %cst_10) : (tensor, tensor<2xi32>) -> tensor\r\n  %output, %idx = \"tfl.unique\"(%output_values) : (tensor) -> (tensor, tensor)\r\n  %21 = \"tfl.strided_slice\"(%output_indices_24, %cst_16, %cst_17, %cst_18) {begin_mask = 1 : i32, ellipsis_mask = 0 : i32, end_mask = 1 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 2 : i32} : (tensor, tensor<2xi32>, tensor<2xi32>, tensor<2xi32>) -> tensor\r\n  %22 = \"tf.HashTableV2\"() {container = \"\", device = \"\", key_dtype = !tf.string, shared_name = \"hash_table_fc7c2e70-8a89-4115-84d4-2f713273e69c_load_0_198\", use_node_name_sharing = true, value_dtype = i64} : () -> tensor\r\n  %23 = \"tf.LookupTableFindV2\"(%22, %sparse_values#1, %cst_9) {device = \"\"} : (tensor, tensor, tensor) -> tensor<*xi64>\r\n  %24 = \"tfl.strided_slice\"(%1, %cst_15, %cst_21, %cst_21) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<2xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor\r\n  %25 = \"tfl.pack\"(%24, %cst_8) {axis = 0 : i32, values_count = 2 : i32} : (tensor, tensor) -> tensor<2xi32>\r\n  %26 = \"tfl.cast\"(%25) : (tensor<2xi32>) -> tensor<2xi64>\r\n  %output_indices_25, %output_shape_26 = \"tf.SparseReshape\"(%sparse_indices#1, %sparse_shapes#1, %26) {device = \"\"} : (tensor, tensor<2xi64>, tensor<2xi64>) -> (tensor, tensor<2xi64>)\r\n  %27 = \"tfl.cast\"(%output_shape_26) : (tensor<2xi64>) -> tensor<2xi32>\r\n  %28 = \"tfl.gather\"(%output_shape_26, %cst_12) {axis = 0 : i32} : (tensor<2xi64>, tensor) -> tensor\r\n  %29 = \"tfl.greater_equal\"(%23, %cst_13) : (tensor<*xi64>, tensor) -> tensor<*xi1>\r\n  %30 = \"tfl.where\"(%29) : (tensor<*xi1>) -> tensor\r\n  %31 = \"tfl.reshape\"(%30, %cst_11) : (tensor, tensor<1xi32>) -> tensor\r\n  %32 = \"tfl.gather\"(%23, %31) {axis = 0 : i32} : (tensor<*xi64>, tensor) -> tensor<*xi64>\r\n  %33 = \"tfl.slice\"(%output_shape_26, %cst_15, %cst_21) : (tensor<2xi64>, tensor<1xi32>, tensor<1xi32>) -> tensor<1xi64>\r\n  %34 = \"tfl.reduce_prod\"(%33, %cst_15) {keep_dims = false} : (tensor<1xi64>, tensor<1xi32>) -> tensor\r\n  %35 = \"tfl.pack\"(%34, %28) {axis = 0 : i32, values_count = 2 : i32} : (tensor, tensor) -> tensor<2xi64>\r\n  %output_indices_27, %output_shape_28 = \"tf.SparseReshape\"(%output_indices_25, %output_shape_26, %35) {device = \"\"} : (tensor, tensor<2xi64>, tensor<2xi64>) -> (tensor, tensor<2xi64>)\r\n  %36 = \"tfl.gather\"(%output_indices_27, %31) {axis = 0 : i32} : (tensor, tensor) -> tensor\r\n  %37 = \"tfl.slice\"(%27, %cst_15, %cst_21) : (tensor<2xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<1xi32>\r\n  %output_indices_29, %output_values_30, %empty_row_indicator_31, %reverse_index_map_32 = \"tf.SparseFillEmptyRows\"(%36, %32, %output_shape_28, %cst_13) {device = \"\"} : (tensor, tensor<*xi64>, tensor<2xi64>, tensor) -> (tensor, tensor, tensor, tensor)\r\n  %38 = \"tfl.reshape\"(%empty_row_indicator_31, %cst_10) : (tensor, tensor<2xi32>) -> tensor\r\n  %output_33, %idx_34 = \"tfl.unique\"(%output_values_30) : (tensor) -> (tensor, tensor)\r\n  %39 = \"tfl.strided_slice\"(%output_indices_29, %cst_16, %cst_17, %cst_18) {begin_mask = 1 : i32, ellipsis_mask = 0 : i32, end_mask = 1 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 2 : i32} : (tensor, tensor<2xi32>, tensor<2xi32>, tensor<2xi32>) -> tensor\r\n  %40 = \"tf.HashTableV2\"() {container = \"\", device = \"\", key_dtype = i64, shared_name = \"hash_table_b60d3bcd-14f8-4085-a3b2-85948ec09373_load_0_199\", use_node_name_sharing = true, value_dtype = i64} : () -> tensor\r\n  %41 = \"tf.LookupTableFindV2\"(%40, %sparse_values#3, %cst_9) {device = \"\"} : (tensor, tensor, tensor) -> tensor<*xi64>\r\n  %42 = \"tfl.strided_slice\"(%2, %cst_15, %cst_21, %cst_21) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<2xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor\r\n  %43 = \"tfl.pack\"(%42, %cst_8) {axis = 0 : i32, values_count = 2 : i32} : (tensor, tensor) -> tensor<2xi32>\r\n  %44 = \"tfl.cast\"(%43) : (tensor<2xi32>) -> tensor<2xi64>\r\n  %output_indices_35, %output_shape_36 = \"tf.SparseReshape\"(%sparse_indices#3, %sparse_shapes#3, %44) {device = \"\"} : (tensor, tensor<2xi64>, tensor<2xi64>) -> (tensor, tensor<2xi64>)\r\n  %45 = \"tfl.cast\"(%output_shape_36) : (tensor<2xi64>) -> tensor<2xi32>\r\n  %46 = \"tfl.gather\"(%output_shape_36, %cst_12) {axis = 0 : i32} : (tensor<2xi64>, tensor) -> tensor\r\n  %47 = \"tfl.greater_equal\"(%41, %cst_13) : (tensor<*xi64>, tensor) -> tensor<*xi1>\r\n  %48 = \"tfl.where\"(%47) : (tensor<*xi1>) -> tensor\r\n  %49 = \"tfl.reshape\"(%48, %cst_11) : (tensor, tensor<1xi32>) -> tensor\r\n  %50 = \"tfl.gather\"(%41, %49) {axis = 0 : i32} : (tensor<*xi64>, tensor) -> tensor<*xi64>\r\n  %51 = \"tfl.slice\"(%output_shape_36, %cst_15, %cst_21) : (tensor<2xi64>, tensor<1xi32>, tensor<1xi32>) -> tensor<1xi64>\r\n  %52 = \"tfl.reduce_prod\"(%51, %cst_15) {keep_dims = false} : (tensor<1xi64>, tensor<1xi32>) -> tensor\r\n  %53 = \"tfl.pack\"(%52, %46) {axis = 0 : i32, values_count = 2 : i32} : (tensor, tensor) -> tensor<2xi64>\r\n  %output_indices_37, %output_shape_38 = \"tf.SparseReshape\"(%output_indices_35, %output_shape_36, %53) {device = \"\"} : (tensor, tensor<2xi64>, tensor<2xi64>) -> (tensor, tensor<2xi64>)\r\n  %54 = \"tfl.gather\"(%output_indices_37, %49) {axis = 0 : i32} : (tensor, tensor) -> tensor\r\n  %55 = \"tfl.slice\"(%45, %cst_15, %cst_21) : (tensor<2xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<1xi32>\r\n  %output_indices_39, %output_values_40, %empty_row_indicator_41, %reverse_index_map_42 = \"tf.SparseFillEmptyRows\"(%54, %50, %output_shape_38, %cst_13) {device = \"\"} : (tensor, tensor<*xi64>, tensor<2xi64>, tensor) -> (tensor, tensor, tensor, tensor)\r\n  %56 = \"tfl.reshape\"(%empty_row_indicator_41, %cst_10) : (tensor, tensor<2xi32>) -> tensor\r\n  %output_43, %idx_44 = \"tfl.unique\"(%output_values_40) : (tensor) -> (tensor, tensor)\r\n  %57 = \"tfl.strided_slice\"(%output_indices_39, %cst_16, %cst_17, %cst_18) {begin_mask = 1 : i32, ellipsis_mask = 0 : i32, end_mask = 1 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 2 : i32} : (tensor, tensor<2xi32>, tensor<2xi32>, tensor<2xi32>) -> tensor\r\n  %58 = \"tf.HashTableV2\"() {container = \"\", device = \"\", key_dtype = i64, shared_name = \"hash_table_cb0918fe-8c8e-41f5-9aad-3750ec00bdad_load_0_200\", use_node_name_sharing = true, value_dtype = i64} : () -> tensor\r\n  %59 = \"tf.LookupTableFindV2\"(%58, %sparse_values#4, %cst_9) {device = \"\"} : (tensor, tensor, tensor) -> tensor<*xi64>\r\n  %60 = \"tfl.strided_slice\"(%3, %cst_15, %cst_21, %cst_21) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<2xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor\r\n  %61 = \"tfl.pack\"(%60, %cst_8) {axis = 0 : i32, values_count = 2 : i32} : (tensor, tensor) -> tensor<2xi32>\r\n  %62 = \"tfl.cast\"(%61) : (tensor<2xi32>) -> tensor<2xi64>\r\n  %output_indices_45, %output_shape_46 = \"tf.SparseReshape\"(%sparse_indices#4, %sparse_shapes#4, %62) {device = \"\"} : (tensor, tensor<2xi64>, tensor<2xi64>) -> (tensor, tensor<2xi64>)\r\n  %63 = \"tfl.cast\"(%output_shape_46) : (tensor<2xi64>) -> tensor<2xi32>\r\n  %64 = \"tfl.gather\"(%output_shape_46, %cst_12) {axis = 0 : i32} : (tensor<2xi64>, tensor) -> tensor\r\n  %65 = \"tfl.greater_equal\"(%59, %cst_13) : (tensor<*xi64>, tensor) -> tensor<*xi1>\r\n  %66 = \"tfl.where\"(%65) : (tensor<*xi1>) -> tensor\r\n  %67 = \"tfl.reshape\"(%66, %cst_11) : (tensor, tensor<1xi32>) -> tensor\r\n  %68 = \"tfl.gather\"(%59, %67) {axis = 0 : i32} : (tensor<*xi64>, tensor) -> tensor<*xi64>\r\n  %69 = \"tfl.slice\"(%output_shape_46, %cst_15, %cst_21) : (tensor<2xi64>, tensor<1xi32>, tensor<1xi32>) -> tensor<1xi64>\r\n  %70 = \"tfl.reduce_prod\"(%69, %cst_15) {keep_dims = false} : (tensor<1xi64>, tensor<1xi32>) -> tensor\r\n  %71 = \"tfl.pack\"(%70, %64) {axis = 0 : i32, values_count = 2 : i32} : (tensor, tensor) -> tensor<2xi64>\r\n  %output_indices_47, %output_shape_48 = \"tf.SparseReshape\"(%output_indices_45, %output_shape_46, %71) {device = \"\"} : (tensor, tensor<2xi64>, tensor<2xi64>) -> (tensor, tensor<2xi64>)\r\n  %72 = \"tfl.gather\"(%output_indices_47, %67) {axis = 0 : i32} : (tensor, tensor) -> tensor\r\n  %73 = \"tfl.slice\"(%63, %cst_15, %cst_21) : (tensor<2xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<1xi32>\r\n  %output_indices_49, %output_values_50, %empty_row_indicator_51, %reverse_index_map_52 = \"tf.SparseFillEmptyRows\"(%72, %68, %output_shape_48, %cst_13) {device = \"\"} : (tensor, tensor<*xi64>, tensor<2xi64>, tensor) -> (tensor, tensor, tensor, tensor)\r\n  %74 = \"tfl.reshape\"(%empty_row_indicator_51, %cst_10) : (tensor, tensor<2xi32>) -> tensor\r\n  %output_53, %idx_54 = \"tfl.unique\"(%output_values_50) : (tensor) -> (tensor, tensor)\r\n  %75 = \"tfl.strided_slice\"(%output_indices_49, %cst_16, %cst_17, %cst_18) {begin_mask = 1 : i32, ellipsis_mask = 0 : i32, end_mask = 1 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 2 : i32} : (tensor, tensor<2xi32>, tensor<2xi32>, tensor<2xi32>) -> tensor\r\n  %76 = \"tfl.gather\"(%cst_2, %output) {axis = 0 : i32} : (tensor<7x1xf32>, tensor) -> tensor\r\n  %77 = \"tfl.custom_tf\"(%76, %idx, %21) ( {\r\n    %127 = \"tf.SparseSegmentSum\"(%76, %idx, %21) {T = f32, Tidx = i32, Tsegmentids = i64, device = \"\"} : (tensor, tensor, tensor) -> tensor\r\n    \"tfl.yield\"(%127) : (tensor) -> ()\r\n  }) : (tensor, tensor, tensor) -> tensor\r\n  %78 = \"tfl.shape\"(%77) : (tensor) -> tensor<2xi32>\r\n  %79 = \"tfl.strided_slice\"(%78, %cst_21, %cst_20, %cst_21) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<2xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor\r\n  %80 = \"tfl.pack\"(%cst_12, %79) {axis = 0 : i32, values_count = 2 : i32} : (tensor, tensor) -> tensor<2xi32>\r\n  %81 = \"tfl.tile\"(%20, %80) : (tensor, tensor<2xi32>) -> tensor\r\n  %82 = \"tfl.zeros_like\"(%77) : (tensor) -> tensor\r\n  %83 = \"tfl.select\"(%81, %82, %77) : (tensor, tensor, tensor) -> tensor\r\n  %84 = \"tfl.shape\"(%83) : (tensor) -> tensor<2xi32>\r\n  %85 = \"tfl.slice\"(%84, %cst_21, %cst_11) : (tensor<2xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<1xi32>\r\n  %86 = \"tfl.concatenation\"(%19, %85) {axis = 0 : i32, fused_activation_function = \"NONE\"} : (tensor<1xi32>, tensor<1xi32>) -> tensor<2xi32>\r\n  %87 = \"tfl.reshape\"(%83, %86) : (tensor, tensor<2xi32>) -> tensor\r\n  %88 = \"tfl.gather\"(%cst_1, %output_33) {axis = 0 : i32} : (tensor<6203x1xf32>, tensor) -> tensor\r\n  %89 = \"tfl.custom_tf\"(%88, %idx_34, %39) ( {\r\n    %127 = \"tf.SparseSegmentSum\"(%88, %idx_34, %39) {T = f32, Tidx = i32, Tsegmentids = i64, device = \"\"} : (tensor, tensor, tensor) -> tensor\r\n    \"tfl.yield\"(%127) : (tensor) -> ()\r\n  }) : (tensor, tensor, tensor) -> tensor\r\n  %90 = \"tfl.shape\"(%89) : (tensor) -> tensor<2xi32>\r\n  %91 = \"tfl.strided_slice\"(%90, %cst_21, %cst_20, %cst_21) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<2xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor\r\n  %92 = \"tfl.pack\"(%cst_12, %91) {axis = 0 : i32, values_count = 2 : i32} : (tensor, tensor) -> tensor<2xi32>\r\n  %93 = \"tfl.tile\"(%38, %92) : (tensor, tensor<2xi32>) -> tensor\r\n  %94 = \"tfl.zeros_like\"(%89) : (tensor) -> tensor\r\n  %95 = \"tfl.select\"(%93, %94, %89) : (tensor, tensor, tensor) -> tensor\r\n  %96 = \"tfl.shape\"(%95) : (tensor) -> tensor<2xi32>\r\n  %97 = \"tfl.slice\"(%96, %cst_21, %cst_11) : (tensor<2xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<1xi32>\r\n  %98 = \"tfl.concatenation\"(%37, %97) {axis = 0 : i32, fused_activation_function = \"NONE\"} : (tensor<1xi32>, tensor<1xi32>) -> tensor<2xi32>\r\n  %99 = \"tfl.reshape\"(%95, %98) : (tensor, tensor<2xi32>) -> tensor\r\n  %100 = \"tfl.gather\"(%cst_0, %output_43) {axis = 0 : i32} : (tensor<2x1xf32>, tensor) -> tensor\r\n  %101 = \"tfl.custom_tf\"(%100, %idx_44, %57) ( {\r\n    %127 = \"tf.SparseSegmentSum\"(%100, %idx_44, %57) {T = f32, Tidx = i32, Tsegmentids = i64, device = \"\"} : (tensor, tensor, tensor) -> tensor\r\n    \"tfl.yield\"(%127) : (tensor) -> ()\r\n  }) : (tensor, tensor, tensor) -> tensor\r\n  %102 = \"tfl.shape\"(%101) : (tensor) -> tensor<2xi32>\r\n  %103 = \"tfl.strided_slice\"(%102, %cst_21, %cst_20, %cst_21) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<2xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor\r\n  %104 = \"tfl.pack\"(%cst_12, %103) {axis = 0 : i32, values_count = 2 : i32} : (tensor, tensor) -> tensor<2xi32>\r\n  %105 = \"tfl.tile\"(%56, %104) : (tensor, tensor<2xi32>) -> tensor\r\n  %106 = \"tfl.zeros_like\"(%101) : (tensor) -> tensor\r\n  %107 = \"tfl.select\"(%105, %106, %101) : (tensor, tensor, tensor) -> tensor\r\n  %108 = \"tfl.shape\"(%107) : (tensor) -> tensor<2xi32>\r\n  %109 = \"tfl.slice\"(%108, %cst_21, %cst_11) : (tensor<2xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<1xi32>\r\n  %110 = \"tfl.concatenation\"(%55, %109) {axis = 0 : i32, fused_activation_function = \"NONE\"} : (tensor<1xi32>, tensor<1xi32>) -> tensor<2xi32>\r\n  %111 = \"tfl.reshape\"(%107, %110) : (tensor, tensor<2xi32>) -> tensor\r\n  %112 = \"tfl.fully_connected\"(%dense_values#3, %cst_14, %cst_19) {fused_activation_function = \"NONE\", keep_num_dims = false, weights_format = \"DEFAULT\"} : (tensor, tensor<1x1xf32>, none) -> tensor\r\n  %113 = \"tfl.gather\"(%cst, %output_53) {axis = 0 : i32} : (tensor<80x1xf32>, tensor) -> tensor\r\n  %114 = \"tfl.custom_tf\"(%113, %idx_54, %75) ( {\r\n    %127 = \"tf.SparseSegmentSum\"(%113, %idx_54, %75) {T = f32, Tidx = i32, Tsegmentids = i64, device = \"\"} : (tensor, tensor, tensor) -> tensor\r\n    \"tfl.yield\"(%127) : (tensor) -> ()\r\n  }) : (tensor, tensor, tensor) -> tensor\r\n  %115 = \"tfl.shape\"(%114) : (tensor) -> tensor<2xi32>\r\n  %116 = \"tfl.strided_slice\"(%115, %cst_21, %cst_20, %cst_21) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<2xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor\r\n  %117 = \"tfl.pack\"(%cst_12, %116) {axis = 0 : i32, values_count = 2 : i32} : (tensor, tensor) -> tensor<2xi32>\r\n  %118 = \"tfl.tile\"(%74, %117) : (tensor, tensor<2xi32>) -> tensor\r\n  %119 = \"tfl.zeros_like\"(%114) : (tensor) -> tensor\r\n  %120 = \"tfl.select\"(%118, %119, %114) : (tensor, tensor, tensor) -> tensor\r\n  %121 = \"tfl.shape\"(%120) : (tensor) -> tensor<2xi32>\r\n  %122 = \"tfl.slice\"(%121, %cst_21, %cst_11) : (tensor<2xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<1xi32>\r\n  %123 = \"tfl.concatenation\"(%73, %122) {axis = 0 : i32, fused_activation_function = \"NONE\"} : (tensor<1xi32>, tensor<1xi32>) -> tensor<2xi32>\r\n  %124 = \"tfl.reshape\"(%120, %123) : (tensor, tensor<2xi32>) -> tensor\r\n  %125 = \"tfl.add_n\"(%87, %99, %111, %112, %124) : (tensor, tensor, tensor, tensor, tensor) -> tensor\r\n  %126 = \"tfl.add\"(%125, %cst_3) {fused_activation_function = \"NONE\"} : (tensor, tensor<1xf32>) -> tensor\r\n  \"std.return\"(%126) : (tensor) -> ()\r\n}) {arg0 = {tf_saved_model.index_path = [\"examples\"]}, result0 = {tf_saved_model.index_path = [\"predictions\"]}, sym_name = \"main\", tf.entry_function = {control_outputs = \"\", inputs = \"serving_default_examples:0\", outputs = \"StatefulPartitionedCall_1:0\"}, tf_saved_model.exported_names = [\"serving_default\"], type = (tensor) -> tensor} : () -> ()\r\n```\r\n\r\n**Also, please include a link to the saved model or GraphDef**\r\n\r\n```\r\n[model.zip](https://github.com/tensorflow/tensorflow/files/5120025/model.zip)\r\n```\r\n\r\n**Failure details**\r\nIf the conversion is successful, but the generated model is wrong,\r\nstate what is wrong:\r\n- Producing wrong results and/or decrease in accuracy\r\n- Producing correct results, but the model is slower than expected (model generated from old converter)\r\n\r\n\r\n**RNN conversion support**\r\nIf converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.\r\n\r\n**Any other info / logs**\r\n\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@NiBurhe \r\nCan you please refer to [this link](https://github.com/tensorflow/tensorflow/issues/34350#issuecomment-579027135) with same error and let us know.", "Hi @Saduf2019 ,\r\n\r\nI now tried it with\r\n\r\n`converter.experimental_new_converter = True\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,\r\n                                       tf.lite.OpsSet.SELECT_TF_OPS]`\r\n\r\nand now the tf.HashTableV2 and tf.LookupTableFindV2 are not supported, Full log see \r\n[tflite.log](https://github.com/tensorflow/tensorflow/files/5137556/tflite.log)\r\n\r\nIs there a way to get it running? I have no idea how to implement that function on my own.\r\n\r\nThanks & Regards,\r\nNiBurhe\r\n\r\n\r\n", "I can reproduce the issue. [Here](https://colab.research.google.com/gist/jvishnuvardhan/269f579b3a0ff1101741ef46a5ab80fe/untitled.ipynb) is the gist for our reference. Thanks!", "Team is working on e2e hash table support. I will update this thread once the feature is landed.", "Any update on 'tf.LookupTableFindV2' support?", "Was able to reproduce your issue in Tf Nightly 2.6.0-dev20210526, please find the gist [here](https://colab.research.google.com/gist/sachinprasadhs/26e6935549ab8bb0b235d0d45c8426d8/42636.ipynb). Thanks!", "Hash table is now supported through the builtin op set and saved model converter.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42636\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42636\">No</a>\n"]}, {"number": 42635, "title": "Fix implicit conversion for hello_world on Sparkfun Edge", "body": "Fixes #42517\r\n\r\nManually tested that the following command succeeds with this change:\r\n```\r\nmake -f tensorflow/lite/micro/tools/make/Makefile TARGET=sparkfun_edge hello_world_bin -j8\r\n```", "comments": []}, {"number": 42634, "title": "Fix #41630: include max_seq_length in cudnn descriptor cache key", "body": "", "comments": ["@goldiegadde @mihaimaruseac Here is a PR against r1.15 :)", "Thanks @mihaimaruseac, so I see 1.15.4 finally made it yesterday, that's great news. However, it is not pushed to Docker Hub: https://hub.docker.com/r/tensorflow/tensorflow/tags?page=1&name=1.15.\r\n\r\nWe have a training docker image that depends on your upstream Docker Hub images, so the lack of 1.15.4 release there is kinda problematic. I'm going to file a new issue for that."]}, {"number": 42633, "title": "Fix the documentation of unique_indices in EmitScatter.", "body": "The documentation was erroneously pointing to the case `unique_indices = False` as being potentially unsafe.\r\nThis fixes that mistake, and reformulates the last two sentences so as to be somewhat clearer.", "comments": []}, {"number": 42632, "title": "error when installing for go from source.", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nLinux Debian 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\nN/A\r\n- TensorFlow installed from (source or binary):\r\nsource\r\n- TensorFlow version:\r\ncommit 2d0592a000989c28e94dbc6efabe6c3be54762e1\r\n- Python version:\r\nPython 3.7.3\r\n- Installed using virtualenv? pip? conda?:\r\ncomiled from source, following [this](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/go/README.md)\r\n- Bazel version (if compiling from source):\r\nbazel 3.1.0\r\n- GCC/Compiler version (if compiling from source):\r\ngcc (Debian 8.3.0-6) 8.3.0\r\n- CUDA/cuDNN version:\r\nno idea\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\non step 4 of the instructions (`go generate github.com/tensorflow/tensorflow/tensorflow/go/op`) I got:\r\n```\r\ngoogle/protobuf/any.proto: File not found.\r\ngoogle/protobuf/duration.proto: File not found.\r\ntensorflow/core/protobuf/autotuning.proto:10:1: Import \"google/protobuf/any.proto\" was not found or had errors.\r\ntensorflow/core/protobuf/autotuning.proto:11:1: Import \"google/protobuf/duration.proto\" was not found or had errors.\r\ntensorflow/core/protobuf/autotuning.proto:61:3: \"google.protobuf.Duration\" is not defined.\r\ntensorflow/core/protobuf/autotuning.proto:74:3: \"google.protobuf.Any\" is not defined.\r\n../genop/generate.go:19: running \"bash\": exit status 1\r\nop/generate.go:17: running \"go\": exit status 1\r\n```\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n```\r\ngo get -d github.com/tensorflow/tensorflow/tensorflow/go\r\n\r\ncd ${GOPATH}/src/github.com/tensorflow/tensorflow\r\n./configure\r\nbazel build -c opt //tensorflow:libtensorflow.so\r\n\r\nsudo cp ${GOPATH}/src/github.com/tensorflow/tensorflow/bazel-bin/tensorflow/libtensorflow.so /usr/local/lib\r\nsudo cp ${GOPATH}/src/github.com/tensorflow/tensorflow/bazel-bin/tensorflow/libtensorflow_framework.so.2 /usr/local/lib/libtensorflow_framework.so\r\n\r\ngo generate github.com/tensorflow/tensorflow/tensorflow/go/op\r\n```\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@lolbinarycat \r\nCan you try \"go get github.com/tensorflow/tensorflow/tensorflow/go\" and let us know, please refer to: [link](https://github.com/tensorflow/tensorflow/issues/23681)\r\n#34580 [link](https://stackoverflow.com/questions/60631279/not-able-to-get-tensorflow-go ) [link](https://github.com/tensorflow/tensorflow/issues/13765) #3437", "```\r\ncannot find package \"github.com/tensorflow/tensorflow/tensorflow/go/core/protobuf/for_core_protos_go_proto\" in any of:\r\n        /usr/lib/go-1.15/src/github.com/tensorflow/tensorflow/tensorflow/go/core/protobuf/for_core_protos_go_proto (from $GOROOT)\r\n        /home/binarycat/go/src/github.com/tensorflow/tensorflow/tensorflow/go/core/protobuf/for_core_protos_go_proto (from $GOPATH)\r\n```\r\n", "@lolbinarycat \r\nCan you please refer to this issue and let us know if it helps. #42657", "> @lolbinarycat\r\n> Can you please refer to this issue and let us know if it helps. #42657\r\n\r\nI was reading through it, but It's hard to follow along as running a single `bazel` command takes around a day, and it makes my computer slow. If there are any steps I should take in particular let me know, but I didn't see anything that looked super helpful.", "let me tell you the steps I took to resolve this:\r\n1. Install TensorFlow C based on the instructions given in this website: ->          https://www.tensorflow.org/install/lang_c\r\n2. Once tensorflow C is installed, install go:\r\n            go get -v github.com/tensorflow/tensorflow/tensorflow/go\r\n3. If it succeeds by this step, then grats. if not run this command:\r\n            cd $GOPATH/src/github.com/tensorflow/tensorflow/tensorflow/go\r\n            git checkout tags/v2.1.0\r\n4. Test your build with \r\n            go test github.com/tensorflow/tensorflow/tensorflow/go\r\n    if the test produce this line \"ok github.com/tensorflow/tensorflow/tensorflow/go 0.152s\" at the end, then you are good to go. At least it did for me. Good luck ", "Thanks! I'll try that when I have the time.", "@lolbinarycat,\r\n\r\nHave you tried installing as per the suggestions from @nyeinsoe26 ? Please try installing the latest stable version and use this [guide](https://github.com/tensorflow/build/tree/master/golang_install_guide) as a reference. Let us know if you face any problems while following the same. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42632\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42632\">No</a>\n"]}, {"number": 42631, "title": "Embedding layer doesn't follow mixed_precision policy by default", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 Pro 1909 OS build 18363.1016\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.2.0\r\n- Python version: 3.6\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**Describe the current behavior**\r\nEmbedding layer's output is float32 despite mixed_bfloat16 policy\r\n\r\n**Describe the expected behavior**\r\nEmbedding layer's output should tie to mixed_bfloat16 policy\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.mixed_precision import experimental as mixed_precision\r\npolicy = mixed_precision.Policy('mixed_bfloat16')\r\nmixed_precision.set_policy(policy)\r\ninputs = tf.keras.Input(shape=(100,), name='digits')\r\nemb = tf.keras.layers.Embedding(100, 100)\r\ndense = tf.keras.layers.Dense(100)\r\n\r\noutputs = emb(inputs) + dense(inputs) # <= the error is here (adding two different types)\r\n\r\nmodel = tf.keras.Model(inputs=inputs, outputs=outputs)\r\nmodel.compile(loss='sparse_categorical_crossentropy',\r\n              optimizer=tf.keras.optimizers.Adam(),\r\n              metrics=['accuracy'])\r\ninput = tf.random.uniform(shape=[1,25], maxval=100, dtype=tf.int32)\r\nhist = model.fit(input, input, epochs=1, steps_per_epoch=1,verbose=0)\r\n\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\n> ValueError: Tensor conversion requested dtype float32 for Tensor with dtype bfloat16: <tf.Tensor 'dense/Identity:0' shape=(None, 100) dtype=bfloat16>\r\n\r\n", "comments": ["Was able to reproduce the issue with TF v2.3 and TF-nightly. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/8bcbf72e06fa014e1a2b1970fd2bb2ef/42631.ipynb#scrollTo=sfr6zmv_ELEj). Thanks!", "@brand17 In` tf.keras.layers.Embedding()`, auto casting is set to false as shown [here](https://github.com/tensorflow/tensorflow/blob/b36436b087bd8e8701ef51718179037cccdfc26e/tensorflow/python/keras/layers/embeddings.py#L108) and that is the cause of the error. ", "Not clear for me - is it impossible to fix ? I don't understand - why casting embedding matrix to float16 before casting input to int32 might cause the int32 values to be different due to a loss of precision\r\n"]}]