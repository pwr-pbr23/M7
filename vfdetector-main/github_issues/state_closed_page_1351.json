[{"number": 12551, "title": "add function gradients()  return  none exception", "body": "Signed-off-by: \ud55c\ud604\ubbfc <um4825@gmail.com>", "comments": ["Can one of the admins verify this patch?", "@HyunMinH, thanks for your PR! By analyzing the history of the files in this pull request, we identified @drpngx, @ebrevdo and @tensorflower-gardener to be potential reviewers.", "Jenkins, test this please.", "I do not understand the rationale for raising Exception with no error message when gradients returns None. Can you explain?", "Closing this for now. Please reopen with a justification for why None here is a good idea."]}, {"number": 12550, "title": "Implements safe casting of to_<dtypes>() (#12235)", "body": "* saturate_cast() supports SparseTensor\r\n\r\n* to_float(), to_double(), to_int32(), to_int36(), to_bfloat16()\r\nsupports safe casting", "comments": ["Can one of the admins verify this patch?", "@ebrevdo is working on sparse support. Any opinion here?", "@ebrevdo ping", "@ebrevdo can you take a look?", "@Edwin222 any news? I'll mark this as stalled.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Closing for now. Feel free to reopen when you're ready."]}, {"number": 12549, "title": "layers.py spatial_softmax activation can be selected by user", "body": "Allow user specified activation functions to be selected when calling `spatial_softmax`. \r\n\r\nI wanted to keep the changes minimal, but it may be worth considering a rename of the layer to `spatial_activation` with softmax as the default. `spatial_softmax` could simply call `spatial_activation` or be removed. Thoughts?", "comments": ["@ahundt, thanks for your PR! By analyzing the history of the files in this pull request, we identified @tensorflower-gardener, @jart and @zhangyaobit to be potential reviewers.", "Can one of the admins verify this patch?", "@sguada what do you think?", "@sguada PTAL?", "@sguada could you take another look at this?", "@sguada Would you mind taking a look at my reply?", "Please rebase and fix the errors.", "@ahundt could you pull rebase and push again? Thanks.", "should be able to do this shortly, sorry for the delay.", "@drpngx I've merged with the latest master now", "Jenkins, test this please\n\nOn Sun, Jan 7, 2018, 7:30 PM Andrew Hundt <notifications@github.com> wrote:\n\n> @drpngx <https://github.com/drpngx> I've merged with the latest master now\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/12549#issuecomment-355878310>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AT_SbaV5wXW1gP7ZRG1Tl5AN9EkDprpeks5tIYvXgaJpZM4PA_fS>\n> .\n>\n", "When I try to follow the linux CPU tests (python 3) and ci.tensorflow.org link to look at the reason for CI failure I get the following:\r\n```\r\nHTTP ERROR 404\r\nProblem accessing /job/tensorflow-pull-requests-multijob/8773/. Reason:\r\n\r\n    Not Found\r\nPowered by Jetty:// 9.4.z-SNAPSHOT\r\n```\r\nDo you need to re-run jenkins or something?", "`contrib:layers_test` is failing:\r\n\r\n```\r\n=====================================================================\r\nERROR: testMaxActivationsAtEdges (__main__.SpatialSoftmaxTests)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/tmp/botexec/bazel-out/k8-py3-opt/bin/tensorflow/contrib/layers/layers_test.runfiles/org_tensorflow/tensorflow/contrib/layers/python/layers/layers_test.py\", line 3520, in testMaxActivationsAtEdges\r\n    spatial_softmax = _layers.spatial_softmax(features)\r\n  File \"/tmp/botexec/bazel-out/k8-py3-opt/bin/tensorflow/contrib/layers/layers_test.runfiles/org_tensorflow/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 182, in func_with_args\r\n    return func(*args, **current_args)\r\n  File \"/tmp/botexec/bazel-out/k8-py3-opt/bin/tensorflow/contrib/layers/layers_test.runfiles/org_tensorflow/tensorflow/contrib/layers/python/layers/layers.py\", line 2723, in spatial_softmax\r\n    return feature_keypoints\r\nUnboundLocalError: local variable 'feature_keypoints' referenced before assignment\r\n```", "@drpngx sorry about that I believe it should be fixed now", "```\r\n======================================================================\r\nERROR: testSpatialSoftmaxSigmoid (__main__.SpatialSoftmaxTests)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/tmp/botexec/bazel-out/k8-py3-opt/bin/tensorflow/contrib/layers/layers_test.runfiles/org_tensorflow/tensorflow/contrib/layers/python/layers/layers_test.py\", line 3604, in testSpatialSoftmaxSigmoid\r\n    features, activation_fn=nn_ops.sigmoid)\r\nAttributeError: module 'tensorflow.python.ops.nn_ops' has no attribute 'sigmoid'\r\n\r\n----------------------------------------------------------------------\r\nRan 338 tests in 11.478s\r\n\r\nFAILED (errors=1)\r\n```", "@drpngx Hopefully the unit test failure should be fixed now", "```\r\n======================================================================\r\nERROR: testSpatialSoftmaxNCHW (__main__.SpatialSoftmaxTests)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/Volumes/BuildData/tmpfs/tmp/bazel/execroot/org_tensorflow/bazel-out/darwin_x86_64-opt/bin/tensorflow/contrib/layers/layers_test.runfiles/org_tensorflow/tensorflow/contrib/layers/python/layers/layers_test.py\", line 3656, in testSpatialSoftmaxNCHW\r\n    np_features[:, c, x_loc[c], y_loc[c]] = 100.\r\nIndexError: list index out of range\r\n\r\n======================================================================\r\nFAIL: testSpatialSoftmaxSigmoid (__main__.SpatialSoftmaxTests)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/Volumes/BuildData/tmpfs/tmp/bazel/execroot/org_tensorflow/bazel-out/darwin_x86_64-opt/bin/tensorflow/contrib/layers/layers_test.runfiles/org_tensorflow/tensorflow/contrib/layers/python/layers/layers_test.py\", line 3643, in testSpatialSoftmaxSigmoid\r\n    self.assertAllClose(keypoints, np_keypoints)\r\n  File \"/Volumes/BuildData/tmpfs/tmp/bazel/execroot/org_tensorflow/bazel-out/darwin_x86_64-opt/bin/tensorflow/contrib/layers/layers_test.runfiles/org_tensorflow/tensorflow/python/framework/test_util.py\", line 1177, in assertAllClose\r\n    self._assertAllCloseRecursive(a, b, rtol=rtol, atol=atol)\r\n  File \"/Volumes/BuildData/tmpfs/tmp/bazel/execroot/org_tensorflow/bazel-out/darwin_x86_64-opt/bin/tensorflow/contrib/layers/layers_test.runfiles/org_tensorflow/tensorflow/python/framework/test_util.py\", line 1155, in _assertAllCloseRecursive\r\n    path_str))\r\n  File \"/Volumes/BuildData/tmpfs/tmp/bazel/execroot/org_tensorflow/bazel-out/darwin_x86_64-opt/bin/tensorflow/contrib/layers/layers_test.runfiles/org_tensorflow/tensorflow/python/framework/test_util.py\", line 1069, in _assertArrayLikeAllClose\r\n    (a.shape, b.shape))\r\nAssertionError: Shape mismatch: expected (2, 2), got (4, 2).\r\n\r\n----------------------------------------------------------------------\r\nRan 340 tests in 16.920s\r\n```", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "sorry about this, I have a deadline and hope to properly fix it after that's passed", "Nagging Assignees @sguada, @drpngx: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "I'll make a new PR when/if this becomes ready."]}, {"number": 12548, "title": "Update head.py", "body": "Update contrib lookup to core lookup", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please", "Jenkins, test this please"]}, {"number": 12547, "title": "Update RELEASE.md", "body": "Removed extra \"for\".", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please"]}, {"number": 12546, "title": "Simple release note typo.", "body": "Simple typo on 1.3.0 release note.\r\n![2017-08-24 14 57 12](https://user-images.githubusercontent.com/6247953/29651709-f8d65474-88dc-11e7-9a73-b68f7db09474.png)\r\n", "comments": ["I initiated pull request based on your suggestion, [link](https://github.com/tensorflow/tensorflow/pull/12547)"]}, {"number": 12545, "title": "tfdbg doesn't work when using start_queue_runners", "body": "Today, i tried to use tfdbg to debug my tensorflow model, but i found that the run end CLI didn't show up when using start_queue_runners. here is my code.\r\n```python\r\ntf.global_variables_initializer().run()\r\n\r\ntf.local_variables_initializer().run()\r\n\r\ncoord = tf.train.Coordinator()\r\n\r\nthreads = tf.train.start_queue_runners(sess=sess, coord=coord)\r\n\r\nGLOBAL_STEP = 2\r\n\r\ndebug_sess = tf_debug.LocalCLIDebugWrapperSession(sess=sess)\r\n\r\ntry:\r\n     while not coord.should_stop():\r\n           model.train_n_iteration(sess=debug_sess, n=300, file_writer=file_writer)\r\n           model.save_deeplabv3_ckpt(ckpt_path='ckpt/deeplabv3.ckpt', global_step=GLOBAL_STEP)\r\n           GLOBAL_STEP += 1\r\nexcept tf.errors.OutOfRangeError:\r\n      print('num epoch exceeds the limits')\r\n   \r\nexcept KeyboardInterrupt:\r\n      print('key board interrupt')\r\n    \r\nfinally:\r\n     coord.request_stop()\r\n     coord.join(threads=threads)\r\n```\r\n", "comments": ["@KeithYin, to make sure I understand the issue: are you trying to debug runs of the queues, or runs of some other main training ops on the main thread? \r\n\r\nAlso, `model` and `train_n_iteration` seem to be custom (non-tensorflow) class and method. Can you point me to the code so I can see how they use `sess`?", "@caisq Thanks for responding, I found a bug in my `train_n_iteration` code, i use the `tf.get_default_sesstion()` instead within `train_n_iteration`, that is why the *run end CLI* didn't show up.\r\n\r\nThanks again."]}, {"number": 12544, "title": "remove temp variable", "body": "1. I remove temp variable, and return it directly. \r\n2. using `auto` deduction. ", "comments": ["Can one of the admins verify this patch?", "I have rollbacked the modification, and please review again.", "Jenkins, test this please."]}, {"number": 12543, "title": "Error in installation guide for windows -- should use cuDNN v6.0 with tensorflow v1.3.0", "body": "In the installation guide for windows https://www.tensorflow.org/install/install_windows, where it says 'Requirements to run TensorFlow with GPU support' and 'cuDNN v5.1'.\r\n\r\nActually using cnDNN v5.1 will not work. Instead cnDNN v6.0 works.\r\nThis error would cause great waste of time for newbees. Please update the doc. Thanks.", "comments": ["## This is installation Window 10\r\n\r\nThis link is help you\r\nhttps://nitishmutha.github.io/tensorflow/2017/01/22/TensorFlow-with-gpu-for-windows.html\r\n\r\nAnd I have a question to you.\r\n\r\nI want to fix the documents. But, I don't know where is fix document. I see two documents in website and github. What document should I fix? Please comment to me. Thank you.", "There is already an open issue for this at #11784 ", "Closing as dup"]}, {"number": 12542, "title": "Branch 166267240", "body": "Repushing to fix the Go build", "comments": []}, {"number": 12541, "title": "Feature Request - Dynamic Dispatch of optimized functions for deployment builds", "body": "P\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nNA\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nMac OS X 10.12.16 \r\n- **TensorFlow installed from (source or binary)**:\r\nN/A\r\n- **TensorFlow version (use command below)**:\r\nN/A\r\n- **Python version**: \r\nN/A\r\n- **Bazel version (if compiling from source)**:\r\nN/A\r\n- **CUDA/cuDNN version**:\r\nN/A\r\n- **GPU model and memory**:\r\nN/A\r\n- **Exact command to reproduce**:\r\nN/A\r\n\r\n### Describe the problem\r\n\r\nHello. Thanks for TF.\r\n\r\nRecently OpenCV has integrated dynamic dispatch allowing OpenCV library to leverage optimal code paths for supported hardware acceleration (sse, fma, avx, avx2 etc), from a single compiled binary. This is super useful for deployment builds when you are unsure what CPU family/features will potentially run your binary. \r\n\r\nI understand TF's execution model and potentially XLA may add complications, not even to say GPU support - but for CPU ops, or CPU only deployments I imagine something equivalent would be well received.\r\n\r\nWhile we are speaking of deployment builds, are folks just shipping non-optimized-for-client-hardware binaries, or compiling different builds for different hardware features for end products?\r\n\r\nThank you. \r\n", "comments": ["If you build TF with MKL support, the MKL library will detect your CPU architecture (at runtime) and use the appropriate instruction set for that CPU (so you'll get optimizations that work for that particular CPU). Is this what you mean by dynamic dispatch?", "Hi @andydavis1 - yes, apologies if my terminology was incorrect or misleading - I was following OpenCVs terminology which I presumed was standard.\r\n\r\nI didn't realize MKL supports this. Thats great news. I am happy to give that a shot. Does Master have working MKL compilation out of the box for Mac OS X? Happy to mark this issue closed and move commentary to #10685 if you feel that is appropriate.\r\n\r\n", "Interesting about the MKL on OS X performance though. Its never straightforward is it !?\r\n", "Yes, please move commentary to #10685, I'll close this out.", "IMHO it would be great to remove the need for instruction-specific builds. It seems technically hard to implement and possibly not priority for Google since it has small number of CPU configurations and an easy way to build separate binaries for them. MKL integration introduces dispatch for ops with MKL implementations (ie, subset of 500+ ops in TensorFlow), hopefully that covers all ops that matter for performance", "I was also surprised to learn that TensorFlow does not do automatic CPU dispatch. MKL as such is fine but why not support it out of the box? Using an auto-vectorizing compiler like MSVC++ could do this for some algorithms."]}, {"number": 12540, "title": "Adding tf_nightly info to the readme.", "body": "", "comments": ["@av8ramit, thanks for your PR! By analyzing the history of the files in this pull request, we identified @keveman, @alanyee and @vrv to be potential reviewers."]}, {"number": 12539, "title": "libtensorflow_cc.so linker issues with r 1.3 on Mac OS X Undefined symbols for architecture", "body": "\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nYes, but this appears to be a linker issue.\r\n\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nMac OS X 10.12.6\r\n\r\n- **TensorFlow installed from (source or binary)**:\r\nSource\r\n- **TensorFlow version (use command below)**:\r\nGit tagged at 1.3 and master at 593dc8e5d65f4db93e8f5fced772abb3531a9752 \r\n- **Python version**: \r\n2.7 (OS Default).\r\n- **Bazel version (if compiling from source)**:\r\n 0.5.3-homebrew\r\n- **CUDA/cuDNN version**:\r\nN/A\r\n- **GPU model and memory**:\r\nN/A\r\n\r\n- **Exact command to reproduce**:\r\nbazel clean\r\n./configure stating N to every option for CPU only build.\r\nbazel build //tensorflow:libtensorflow_cc.so with no optimizations  (testing deployment)\r\n\r\n### Describe the problem\r\n\r\nThe above commands builds a libtensorflow_cc.so from for TF 1.3\r\n\r\nLinking my built libtensorflow_cc.so to a C++ / Obj-C App which has successfully linked against a TF 1.2 build of libtensorflow_cc.so, results in the following linker errors in the log section of this bug report.\r\n\r\nNo code changes were made on my end between a working 1.2 libtensorflow_cc.so and a new 1.3 libtensorflow_cc.so - Just replacing the binary so file, building clean and re-compiling.\r\n\r\nThank you.\r\n\r\n### Source code / logs\r\n```Ld /Users/vade/Library/Developer/Xcode/DerivedData/Synopsis-cdbnfomidhkpiodcmhdwciqcvshg/Build/Products/Release/Synopsis.framework/Versions/A/Synopsis normal x86_64\r\n    cd /Users/vade/Documents/Repositories/Synopsis/Synopsis/Synopsis/Synopsis-Framework/Synopsis\r\n    export MACOSX_DEPLOYMENT_TARGET=10.11\r\n    /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/clang++ -arch x86_64 -dynamiclib -isysroot /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.12.sdk -L/Users/vade/Library/Developer/Xcode/DerivedData/Synopsis-cdbnfomidhkpiodcmhdwciqcvshg/Build/Products/Release -L/Users/vade/Documents/Repositories/Synopsis/Synopsis/Synopsis/Synopsis-Framework/Synopsis/Synopsis/Tensorflow/lib -F/Users/vade/Library/Developer/Xcode/DerivedData/Synopsis-cdbnfomidhkpiodcmhdwciqcvshg/Build/Products/Release -F/Users/vade/Documents/Repositories/Synopsis/Synopsis/Synopsis/Synopsis-Framework/Synopsis/Synopsis/OpenCV -filelist /Users/vade/Library/Developer/Xcode/DerivedData/Synopsis-cdbnfomidhkpiodcmhdwciqcvshg/Build/Intermediates/Synopsis-Framework.build/Release/Synopsis-macOS.build/Objects-normal/x86_64/Synopsis.LinkFileList -install_name @rpath/Synopsis.framework/Versions/A/Synopsis -Xlinker -rpath -Xlinker @executable_path/../Frameworks -Xlinker -rpath -Xlinker @loader_path/Frameworks -mmacosx-version-min=10.11 -Xlinker -object_path_lto -Xlinker /Users/vade/Library/Developer/Xcode/DerivedData/Synopsis-cdbnfomidhkpiodcmhdwciqcvshg/Build/Intermediates/Synopsis-Framework.build/Release/Synopsis-macOS.build/Objects-normal/x86_64/Synopsis_lto.o -fobjc-arc -fobjc-link-runtime -stdlib=libc++ -lblas -framework Accelerate -lz -framework Cocoa -framework CoreMedia -framework CoreMediaIO -framework CoreVideo -framework OpenCL -framework opencv2 /Users/vade/Documents/Repositories/Synopsis/Synopsis/Synopsis/Synopsis-Framework/Synopsis/Synopsis/Tensorflow/lib/libtensorflow_cc.so -single_module -compatibility_version 1 -current_version 1 -Xlinker -dependency_info -Xlinker /Users/vade/Library/Developer/Xcode/DerivedData/Synopsis-cdbnfomidhkpiodcmhdwciqcvshg/Build/Intermediates/Synopsis-Framework.build/Release/Synopsis-macOS.build/Objects-normal/x86_64/Synopsis_dependency_info.dat -o /Users/vade/Library/Developer/Xcode/DerivedData/Synopsis-cdbnfomidhkpiodcmhdwciqcvshg/Build/Products/Release/Synopsis.framework/Versions/A/Synopsis\r\n\r\nUndefined symbols for architecture x86_64:\r\n  \"tensorflow::TensorShape::SlowCopyFrom(tensorflow::TensorShape const&)\", referenced from:\r\n      tensorflow::Tensor::Tensor(tensorflow::Tensor const&) in TensorflowFeatureModule.o\r\n  \"tensorflow::TensorShape::DestructorOutOfLine()\", referenced from:\r\n      -[TensorflowFeatureModule initWithQualityHint:] in TensorflowFeatureModule.o\r\n      tensorflow::Tensor::Tensor(tensorflow::Tensor const&) in TensorflowFeatureModule.o\r\n  \"tensorflow::TensorShape::TensorShape(tensorflow::gtl::ArraySlice<long long>)\", referenced from:\r\n      -[TensorflowFeatureModule initWithQualityHint:] in TensorflowFeatureModule.o\r\n  \"tensorflow::TensorShape::dim_size(int) const\", referenced from:\r\n      Eigen::DSizes<long, 4> tensorflow::TensorShape::AsEigenDSizesWithPadding<4>() const in TensorflowFeatureModule.o\r\nld: symbol(s) not found for architecture x86_64\r\nclang: error: linker command failed with exit code 1 (use -v to see invocation)\r\n```", "comments": ["Ive attempted the compilation tweaks for libtensorflow_cc.so mentioned here:\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/11180#issuecomment-318928593 - specifically `bazel clean --expunge`\r\nTo no end - \r\n\r\nCompiling libtensorflow_cc.so  with --config=opt has the same linker error as well when attempting to link a binary that compiled / linked properly against a similarly compiled TF 1.2 libtensorflow_cc.so\r\n\r\nThank you.  ", "Reverting to my git checkout to tag of  1.2.1, and  running the both \r\n`bazel build //tensorflow:libtensorflow_cc.so`\r\n\r\nand \r\n\r\n`bazel build  --config=opt //tensorflow:libtensorflow_cc.so`\r\n\r\nresult in binaries that successfully link, load, and run inference in my codebase.\r\n\r\nThanks!", "Sorry to manually ping, but @petewarden Ive seen you look at build issue for Mac OS in other filed issues. Just curious if you've come across this one before!\r\n\r\nThanks in advance!", "@gunan @petewarden Can you comment on this one?", "@asimshankar Looks like we are having problems with libtensorflow_cc\r\nI am not sure what is going on.", "FWIW, as of today (commit 9b5bf2b6786a58df679b4be2249da8a235b9f4fd) linker issues remain: \r\n\r\n```Ld /Users/vade/Library/Developer/Xcode/DerivedData/Synopsis-cdbnfomidhkpiodcmhdwciqcvshg/Build/Products/Release/Synopsis.framework/Versions/A/Synopsis normal x86_64\r\n    cd /Users/vade/Documents/Repositories/Synopsis/Synopsis/Synopsis/Synopsis-Framework/Synopsis\r\n    export MACOSX_DEPLOYMENT_TARGET=10.11\r\n    /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/clang++ -arch x86_64 -dynamiclib -isysroot /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.13.sdk -L/Users/vade/Library/Developer/Xcode/DerivedData/Synopsis-cdbnfomidhkpiodcmhdwciqcvshg/Build/Products/Release -L/Users/vade/Documents/Repositories/Synopsis/Synopsis/Synopsis/Synopsis-Framework/Synopsis/Synopsis/Tensorflow/lib -F/Users/vade/Library/Developer/Xcode/DerivedData/Synopsis-cdbnfomidhkpiodcmhdwciqcvshg/Build/Products/Release -F/Users/vade/Documents/Repositories/Synopsis/Synopsis/Synopsis/Synopsis-Framework/Synopsis/Synopsis/OpenCV -filelist /Users/vade/Library/Developer/Xcode/DerivedData/Synopsis-cdbnfomidhkpiodcmhdwciqcvshg/Build/Intermediates.noindex/Synopsis-Framework.build/Release/Synopsis-macOS.build/Objects-normal/x86_64/Synopsis.LinkFileList -install_name @rpath/Synopsis.framework/Versions/A/Synopsis -Xlinker -rpath -Xlinker @executable_path/../Frameworks -Xlinker -rpath -Xlinker @loader_path/Frameworks -mmacosx-version-min=10.11 -Xlinker -object_path_lto -Xlinker /Users/vade/Library/Developer/Xcode/DerivedData/Synopsis-cdbnfomidhkpiodcmhdwciqcvshg/Build/Intermediates.noindex/Synopsis-Framework.build/Release/Synopsis-macOS.build/Objects-normal/x86_64/Synopsis_lto.o -fobjc-arc -fobjc-link-runtime -stdlib=libc++ -lblas -framework Accelerate -lz -framework Cocoa -framework CoreMedia -framework CoreMediaIO -framework CoreVideo -framework OpenCL -framework opencv2 /Users/vade/Documents/Repositories/Synopsis/Synopsis/Synopsis/Synopsis-Framework/Synopsis/Synopsis/Tensorflow/lib/libtensorflow_cc.so -single_module -compatibility_version 1 -current_version 1 -Xlinker -dependency_info -Xlinker /Users/vade/Library/Developer/Xcode/DerivedData/Synopsis-cdbnfomidhkpiodcmhdwciqcvshg/Build/Intermediates.noindex/Synopsis-Framework.build/Release/Synopsis-macOS.build/Objects-normal/x86_64/Synopsis_dependency_info.dat -o /Users/vade/Library/Developer/Xcode/DerivedData/Synopsis-cdbnfomidhkpiodcmhdwciqcvshg/Build/Products/Release/Synopsis.framework/Versions/A/Synopsis\r\n\r\nUndefined symbols for architecture x86_64:\r\n  \"tensorflow::TensorShape::SlowCopyFrom(tensorflow::TensorShape const&)\", referenced from:\r\n      tensorflow::Tensor::Tensor(tensorflow::Tensor const&) in TensorflowFeatureModule.o\r\n  \"tensorflow::TensorShape::DestructorOutOfLine()\", referenced from:\r\n      -[TensorflowFeatureModule initWithQualityHint:] in TensorflowFeatureModule.o\r\n      tensorflow::Tensor::Tensor(tensorflow::Tensor const&) in TensorflowFeatureModule.o\r\n  \"tensorflow::TensorShape::TensorShape(tensorflow::gtl::ArraySlice<long long>)\", referenced from:\r\n      -[TensorflowFeatureModule initWithQualityHint:] in TensorflowFeatureModule.o\r\n  \"tensorflow::port::InitMain(char const*, int*, char***)\", referenced from:\r\n      -[TensorflowFeatureModule initWithQualityHint:] in TensorflowFeatureModule.o\r\n  \"tensorflow::TensorShape::dim_size(int) const\", referenced from:\r\n      Eigen::DSizes<long, 4> tensorflow::TensorShape::AsEigenDSizesWithPadding<4>() const in TensorflowFeatureModule.o\r\nld: symbol(s) not found for architecture x86_64\r\nclang: error: linker command failed with exit code 1 (use -v to see invocation)\r\n```\r\n\r\nwith a very basic but successful CPU build on Mac OS X 10.13 ( bazel build --config=opt //tensorflow:libtensorflow_cc.so )\r\n\r\nThank you.\r\n\r\n ", "any solution? I got same issue on 1.4.0 release", "Note that `libtensorflow_cc.so` has a dependency on `libtensorflow_framework.so`.\r\nCan you run: `otool -L libtensorflow_cc.so` and provide the output? \r\n\r\nI suspect what's happening is that the linker isn't finding `libtensorflow_framework.so` in its path.\r\nWhen we build the C libraries for release we package both libraries and set the `rpath` appropriately.", "I am running on linux, here is the output from ldd:\r\n\r\n\tlinux-vdso.so.1 =>  (0x00007ffc9afb7000)\r\n\tlibtensorflow_framework.so => /usr/local/lib/./libtensorflow_framework.so (0x00007fc7fb95d000)\r\n\tlibmklml_intel.so => not found\r\n\tlibiomp5.so => not found\r\n\tlibm.so.6 => /lib/x86_64-linux-gnu/libm.so.6 (0x00007fc7fb615000)\r\n\tlibdl.so.2 => /lib/x86_64-linux-gnu/libdl.so.2 (0x00007fc7fb410000)\r\n\tlibpthread.so.0 => /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007fc7fb1f3000)\r\n\tlibrt.so.1 => /lib/x86_64-linux-gnu/librt.so.1 (0x00007fc7fafeb000)\r\n\tlibstdc++.so.6 => /usr/lib/x86_64-linux-gnu/libstdc++.so.6 (0x00007fc7fac68000)\r\n\tlibgcc_s.so.1 => /lib/x86_64-linux-gnu/libgcc_s.so.1 (0x00007fc7faa52000)\r\n\tlibc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007fc7fa688000)\r\n\t/lib64/ld-linux-x86-64.so.2 (0x0000557e22c3d000)\r\n\tlibmklml_intel.so => not found\r\n\tlibiomp5.so => not found\r\n\r\nThanks!", "@tho15 : The original bug report was on Mac OS X, so I'd like to confirm that your issue is the same as the original one. What linker errors are you getting?\r\n\r\nIt seems you have `libtensorflow_framework.so`, but have compiled the C++ library differently than the original poster (e.g., it seems you've enabled MKL support). If the errors are different, perhaps file a separate issue detailing the exact error message and steps to reproduce the problem. Though, looking at the `ldd` output, it seems that there are some MKL dependencies that cannot be found, so the issue would be different (are you linker errors related to MKL as well?)", "@asimshankar, Thanks!  I actually created a issue #14632, but it was closed by @allenlavoie. Can you take a look? The error is not related with MKL. It complains about undefined reference to some basic classes. ", "@tho15 happy to re-open if you're still having issues once you link in libtensorflow_cc (maybe post the updated command and the new error you're getting?). Your original command was just linking in the C API, which is not going to define any C++ symbols.", "@tho15 @vade : Could you add `-ltensorflow_framework` to your `g++` command-line and see if that helps?\r\n\r\nIf not, please do paste the error along with the command you tried as I suspect the errors change. For example, in #14632 - adding `-ltensorflow_cc` would have changed the errors from what was initially reported.\r\n\r\nAnyway, please do try with `-ltensorflow_framework` and let us know what happens. Thanks.", "@allenlavoie Sorry, the command I typed may mislead you. I am actually using libtensorflow_cc library, not the C library. Can you reopen it? Thanks. ", "@asimshankar Thanks, add -ltensorflow_framework to compiling command:\r\ng++ -I/usr/local/include -L/usr/local/lib -ltensorflow_cc -ltensorflow_framework -std=c++11 tl_classifier.cc\r\n\r\nStill got following errors:\r\n\r\n/tmp/ccfJaOU3.o: In function `LoadGraph(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::unique_ptr<tensorflow::Session, std::default_delete<tensorflow::Session> >*)':\r\ntl_classifier.cc:(.text+0x90): undefined reference to `tensorflow::GraphDef::GraphDef()'\r\ntl_classifier.cc:(.text+0xa4): undefined reference to `tensorflow::Env::Default()'\r\ntl_classifier.cc:(.text+0xc4): undefined reference to `tensorflow::ReadBinaryProto(tensorflow::Env*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, google::protobuf::MessageLite*)'\r\ntl_classifier.cc:(.text+0x15e): undefined reference to `tensorflow::SessionOptions::SessionOptions()'\r\ntl_classifier.cc:(.text+0x16d): undefined reference to `tensorflow::NewSession(tensorflow::SessionOptions const&)'\r\ntl_classifier.cc:(.text+0x22a): undefined reference to `tensorflow::GraphDef::~GraphDef()'\r\ntl_classifier.cc:(.text+0x2b7): undefined reference to `tensorflow::GraphDef::~GraphDef()'\r\n/tmp/ccfJaOU3.o: In function `ReadTensorFromImageFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, int, int, float, float, std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> >*)':\r\ntl_classifier.cc:(.text+0x332): undefined reference to `tensorflow::Scope::NewRootScope()'\r\ntl_classifier.cc:(.text+0x3dd): undefined reference to `tensorflow::Scope::WithOpName(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const'\r\ntl_classifier.cc:(.text+0x3fd): undefined reference to `tensorflow::ops::ReadFile::ReadFile(tensorflow::Scope const&, tensorflow::Input)'\r\ntl_classifier.cc:(.text+0x40c): undefined reference to `tensorflow::Scope::~Scope()'\r\ntl_classifier.cc:(.text+0x504): undefined reference to `tensorflow::Scope::WithOpName(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const'\r\ntl_classifier.cc:(.text+0x528): undefined reference to `tensorflow::ops::DecodePng::DecodePng(tensorflow::Scope const&, tensorflow::Input, tensorflow::ops::DecodePng::Attrs const&)'\r\ntl_classifier.cc:(.text+0x587): undefined reference to `tensorflow::Scope::~Scope()'\r\ntl_classifier.cc:(.text+0x671): undefined reference to `tensorflow::Scope::WithOpName(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const'\r\ntl_classifier.cc:(.text+0x691): undefined reference to `tensorflow::ops::DecodeGif::DecodeGif(tensorflow::Scope const&, tensorflow::Input)'\r\ntl_classifier.cc:(.text+0x6f4): undefined reference to `tensorflow::Scope::WithOpName(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const'\r\ntl_classifier.cc:(.text+0x714): undefined reference to `tensorflow::ops::Squeeze::Squeeze(tensorflow::Scope const&, tensorflow::Input)'\r\ntl_classifier.cc:(.text+0x773): undefined reference to `tensorflow::Scope::~Scope()'\r\ntl_classifier.cc:(.text+0x7be): undefined reference to `tensorflow::Scope::~Scope()'\r\ntl_classifier.cc:(.text+0x867): undefined reference to `tensorflow::Scope::WithOpName(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const'\r\ntl_classifier.cc:(.text+0x88b): undefined reference to `tensorflow::ops::DecodeJpeg::DecodeJpeg(tensorflow::Scope const&, tensorflow::Input, tensorflow::ops::DecodeJpeg::Attrs const&)'\r\ntl_classifier.cc:(.text+0x8ea): undefined reference to `tensorflow::Scope::~Scope()'\r\ntl_classifier.cc:(.text+0x97a): undefined reference to `tensorflow::Scope::WithOpName(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const'\r\ntl_classifier.cc:(.text+0x99c): undefined reference to `tensorflow::ops::Cast::Cast(tensorflow::Scope const&, tensorflow::Input, tensorflow::DataType)'\r\ntl_classifier.cc:(.text+0x9ab): undefined reference to `tensorflow::Scope::~Scope()'\r\ntl_classifier.cc:(.text+0xa38): undefined reference to `tensorflow::ops::ExpandDims::ExpandDims(tensorflow::Scope const&, tensorflow::Input, tensorflow::Input)'\r\ntl_classifier.cc:(.text+0xaea): undefined reference to `tensorflow::Scope::WithOpName(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const'\r\ntl_classifier.cc:(.text+0xb0a): undefined reference to `tensorflow::ops::Const(tensorflow::Scope const&, tensorflow::Input::Initializer const&)'\r\ntl_classifier.cc:(.text+0xb60): undefined reference to `tensorflow::ops::ResizeBilinear::ResizeBilinear(tensorflow::Scope const&, tensorflow::Input, tensorflow::Input)'\r\ntl_classifier.cc:(.text+0xb9c): undefined reference to `tensorflow::Scope::~Scope()'\r\ntl_classifier.cc:(.text+0xc9c): undefined reference to `tensorflow::ops::Subtract::Subtract(tensorflow::Scope const&, tensorflow::Input, tensorflow::Input)'\r\ntl_classifier.cc:(.text+0xcd5): undefined reference to `tensorflow::Scope::WithOpName(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const'\r\ntl_classifier.cc:(.text+0xcf9): undefined reference to `tensorflow::ops::Div::Div(tensorflow::Scope const&, tensorflow::Input, tensorflow::Input)'\r\ntl_classifier.cc:(.text+0xd17): undefined reference to `tensorflow::Scope::~Scope()'\r\ntl_classifier.cc:(.text+0xdbb): undefined reference to `tensorflow::GraphDef::GraphDef()'\r\ntl_classifier.cc:(.text+0xddb): undefined reference to `tensorflow::Scope::ToGraphDef(tensorflow::GraphDef*) const'\r\ntl_classifier.cc:(.text+0xe3e): undefined reference to `tensorflow::SessionOptions::SessionOptions()'\r\ntl_classifier.cc:(.text+0xe4d): undefined reference to `tensorflow::NewSession(tensorflow::SessionOptions const&)'\r\ntl_classifier.cc:(.text+0x109e): undefined reference to `tensorflow::GraphDef::~GraphDef()'\r\ntl_classifier.cc:(.text+0x1116): undefined reference to `tensorflow::Scope::~Scope()'\r\ntl_classifier.cc:(.text+0x1175): undefined reference to `tensorflow::Scope::~Scope()'\r\ntl_classifier.cc:(.text+0x11b4): undefined reference to `tensorflow::Scope::~Scope()'\r\ntl_classifier.cc:(.text+0x1216): undefined reference to `tensorflow::Scope::~Scope()'\r\ntl_classifier.cc:(.text+0x1275): undefined reference to `tensorflow::Scope::~Scope()'\r\n/tmp/ccfJaOU3.o:tl_classifier.cc:(.text+0x12d7): more undefined references to `tensorflow::Scope::~Scope()' follow\r\n/tmp/ccfJaOU3.o: In function `ReadTensorFromImageFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, int, int, float, float, std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> >*)':\r\ntl_classifier.cc:(.text+0x15ee): undefined reference to `tensorflow::GraphDef::~GraphDef()'\r\ntl_classifier.cc:(.text+0x167a): undefined reference to `tensorflow::Scope::~Scope()'\r\n/tmp/ccfJaOU3.o: In function `GetTopLabels(std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> > const&, int, tensorflow::Tensor*, tensorflow::Tensor*)':\r\ntl_classifier.cc:(.text+0x18fe): undefined reference to `tensorflow::Scope::NewRootScope()'\r\ntl_classifier.cc:(.text+0x1999): undefined reference to `tensorflow::Scope::WithOpName(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const'\r\ntl_classifier.cc:(.text+0x19bd): undefined reference to `tensorflow::ops::TopK::TopK(tensorflow::Scope const&, tensorflow::Input, tensorflow::Input)'\r\ntl_classifier.cc:(.text+0x19db): undefined reference to `tensorflow::Scope::~Scope()'\r\ntl_classifier.cc:(.text+0x1a08): undefined reference to `tensorflow::GraphDef::GraphDef()'\r\ntl_classifier.cc:(.text+0x1a28): undefined reference to `tensorflow::Scope::ToGraphDef(tensorflow::GraphDef*) const'\r\n", "@tho15 : The `-ltensorflow_framework` argument should be after the source file. Can you try putting it at the end (after `tf_classifier.cc`)?", "@asimshankar After putting both -ltensorflow_cc and -ltensorflow_framework after the source, I got some errors, but it is different and much shorter:\r\n\r\n/usr/bin/ld: warning: libmklml_intel.so, needed by /usr/local/lib/libtensorflow_cc.so, not found (try using -rpath or -rpath-link)\r\n/usr/bin/ld: warning: libiomp5.so, needed by /usr/local/lib/libtensorflow_cc.so, not found (try using -rpath or -rpath-link)\r\n/usr/local/lib/libtensorflow_framework.so: undefined reference to `i_realloc'\r\n/usr/local/lib/libtensorflow_cc.so: undefined reference to `dnnLRNCreateForward_F32'\r\n/usr/local/lib/libtensorflow_cc.so: undefined reference to `dnnLRNCreateBackward_F32'\r\n/usr/local/lib/libtensorflow_cc.so: undefined reference to `cblas_dgemm'\r\n/usr/local/lib/libtensorflow_cc.so: undefined reference to `dnnBatchNormalizationCreateBackward_v2_F32'\r\n/usr/local/lib/libtensorflow_cc.so: undefined reference to `dnnPoolingCreateForward_F32'\r\n/usr/local/lib/libtensorflow_cc.so: undefined reference to `cblas_cgemm'\r\n/usr/local/lib/libtensorflow_cc.so: undefined reference to `dnnLayoutGetMemorySize_F32'\r\n/usr/local/lib/libtensorflow_cc.so: undefined reference to `dnnExecute_F32'\r\n/usr/local/lib/libtensorflow_cc.so: undefined reference to `dnnBatchNormalizationCreateForward_v2_F32'\r\n/usr/local/lib/libtensorflow_cc.so: undefined reference to `omp_in_parallel@VERSION'\r\n/usr/local/lib/libtensorflow_cc.so: undefined reference to `dnnLayoutSerializationBufferSize_F32'\r\n/usr/local/lib/libtensorflow_framework.so: undefined reference to `i_calloc'\r\n/usr/local/lib/libtensorflow_cc.so: undefined reference to `GOMP_barrier@VERSION'\r\n/usr/local/lib/libtensorflow_cc.so: undefined reference to `omp_get_num_threads@VERSION'\r\n/usr/local/lib/libtensorflow_cc.so: undefined reference to `dnnConvolutionCreateBackwardFilter_F32'\r\n/usr/local/lib/libtensorflow_cc.so: undefined reference to `dnnLayoutCreateFromPrimitive_F32'\r\n/usr/local/lib/libtensorflow_cc.so: undefined reference to `GOMP_parallel@VERSION'\r\n/usr/local/lib/libtensorflow_cc.so: undefined reference to `MKL_Somatcopy'\r\n/usr/local/lib/libtensorflow_cc.so: undefined reference to `dnnReLUCreateForward_F32'\r\n/usr/local/lib/libtensorflow_cc.so: undefined reference to `dnnConvolutionCreateBackwardData_F32'\r\n/usr/local/lib/libtensorflow_cc.so: undefined reference to `dnnConcatCreate_F32'\r\n/usr/local/lib/libtensorflow_cc.so: undefined reference to `dnnLayoutDelete_F32'\r\n/usr/local/lib/libtensorflow_cc.so: undefined reference to `dnnLayoutDeserialize_F32'\r\n/usr/local/lib/libtensorflow_cc.so: undefined reference to `cblas_zgemm'\r\n/usr/local/lib/libtensorflow_cc.so: undefined reference to `dnnPoolingCreateBackward_F32'\r\n/usr/local/lib/libtensorflow_cc.so: undefined reference to `dnnConvolutionCreateForward_F32'\r\n/usr/local/lib/libtensorflow_cc.so: undefined reference to `cblas_sgemm'\r\n/usr/local/lib/libtensorflow_cc.so: undefined reference to `dnnLayoutCompare_F32'\r\n/usr/local/lib/libtensorflow_cc.so: undefined reference to `dnnConvolutionCreateForwardBias_F32'\r\n/usr/local/lib/libtensorflow_cc.so: undefined reference to `dnnConvolutionCreateBackwardBias_F32'\r\n/usr/local/lib/libtensorflow_cc.so: undefined reference to `dnnConversionExecute_F32'\r\n/usr/local/lib/libtensorflow_framework.so: undefined reference to `i_malloc'\r\n/usr/local/lib/libtensorflow_cc.so: undefined reference to `omp_get_max_threads@VERSION'\r\n/usr/local/lib/libtensorflow_cc.so: undefined reference to `omp_get_thread_num@VERSION'\r\n/usr/local/lib/libtensorflow_framework.so: undefined reference to `i_free'\r\n/usr/local/lib/libtensorflow_cc.so: undefined reference to `dnnDelete_F32'\r\n/usr/local/lib/libtensorflow_cc.so: undefined reference to `dnnLayoutCreate_F32'\r\n/usr/local/lib/libtensorflow_cc.so: undefined reference to `dnnLayoutSerialize_F32'\r\n/usr/local/lib/libtensorflow_cc.so: undefined reference to `dnnSumCreate_F32'\r\n/usr/local/lib/libtensorflow_cc.so: undefined reference to `dnnConversionCreate_F32'\r\n/usr/local/lib/libtensorflow_cc.so: undefined reference to `dnnReLUCreateBackward_F32'\r\ncollect2: error: ld returned 1 exit status\r\n\r\nThanks.", "@asimshankar If I only put -ltensorflow_framework after source file, I got following errors:\r\n\r\n/usr/bin/ld: warning: libmklml_intel.so, needed by /usr/local/lib/libtensorflow_framework.so, not found (try using -rpath or -rpath-link)\r\n/usr/bin/ld: warning: libiomp5.so, needed by /usr/local/lib/libtensorflow_framework.so, not found (try using -rpath or -rpath-link)\r\n/tmp/ccAJKAVH.o: In function `ReadTensorFromImageFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, int, int, float, float, std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> >*)':\r\ntl_classifier.cc:(.text+0x332): undefined reference to `tensorflow::Scope::NewRootScope()'\r\ntl_classifier.cc:(.text+0x3dd): undefined reference to `tensorflow::Scope::WithOpName(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const'\r\ntl_classifier.cc:(.text+0x3fd): undefined reference to `tensorflow::ops::ReadFile::ReadFile(tensorflow::Scope const&, tensorflow::Input)'\r\ntl_classifier.cc:(.text+0x40c): undefined reference to `tensorflow::Scope::~Scope()'\r\ntl_classifier.cc:(.text+0x504): undefined reference to `tensorflow::Scope::WithOpName(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const'\r\ntl_classifier.cc:(.text+0x528): undefined reference to `tensorflow::ops::DecodePng::DecodePng(tensorflow::Scope const&, tensorflow::Input, tensorflow::ops::DecodePng::Attrs const&)'\r\ntl_classifier.cc:(.text+0x587): undefined reference to `tensorflow::Scope::~Scope()'\r\ntl_classifier.cc:(.text+0x671): undefined reference to `tensorflow::Scope::WithOpName(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const'\r\ntl_classifier.cc:(.text+0x691): undefined reference to `tensorflow::ops::DecodeGif::DecodeGif(tensorflow::Scope const&, tensorflow::Input)'\r\ntl_classifier.cc:(.text+0x6f4): undefined reference to `tensorflow::Scope::WithOpName(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const'\r\ntl_classifier.cc:(.text+0x714): undefined reference to `tensorflow::ops::Squeeze::Squeeze(tensorflow::Scope const&, tensorflow::Input)'\r\ntl_classifier.cc:(.text+0x773): undefined reference to `tensorflow::Scope::~Scope()'\r\ntl_classifier.cc:(.text+0x7be): undefined reference to `tensorflow::Scope::~Scope()'\r\ntl_classifier.cc:(.text+0x867): undefined reference to `tensorflow::Scope::WithOpName(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const'\r\ntl_classifier.cc:(.text+0x88b): undefined reference to `tensorflow::ops::DecodeJpeg::DecodeJpeg(tensorflow::Scope const&, tensorflow::Input, tensorflow::ops::DecodeJpeg::Attrs const&)'\r\ntl_classifier.cc:(.text+0x8ea): undefined reference to `tensorflow::Scope::~Scope()'\r\ntl_classifier.cc:(.text+0x97a): undefined reference to `tensorflow::Scope::WithOpName(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const'\r\ntl_classifier.cc:(.text+0x99c): undefined reference to `tensorflow::ops::Cast::Cast(tensorflow::Scope const&, tensorflow::Input, tensorflow::DataType)'\r\ntl_classifier.cc:(.text+0x9ab): undefined reference to `tensorflow::Scope::~Scope()'\r\ntl_classifier.cc:(.text+0xa38): undefined reference to `tensorflow::ops::ExpandDims::ExpandDims(tensorflow::Scope const&, tensorflow::Input, tensorflow::Input)'\r\ntl_classifier.cc:(.text+0xaea): undefined reference to `tensorflow::Scope::WithOpName(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const'\r\ntl_classifier.cc:(.text+0xb0a): undefined reference to `tensorflow::ops::Const(tensorflow::Scope const&, tensorflow::Input::Initializer const&)'\r\ntl_classifier.cc:(.text+0xb60): undefined reference to `tensorflow::ops::ResizeBilinear::ResizeBilinear(tensorflow::Scope const&, tensorflow::Input, tensorflow::Input)'\r\ntl_classifier.cc:(.text+0xb9c): undefined reference to `tensorflow::Scope::~Scope()'\r\ntl_classifier.cc:(.text+0xc9c): undefined reference to `tensorflow::ops::Subtract::Subtract(tensorflow::Scope const&, tensorflow::Input, tensorflow::Input)'\r\ntl_classifier.cc:(.text+0xcd5): undefined reference to `tensorflow::Scope::WithOpName(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const'\r\ntl_classifier.cc:(.text+0xcf9): undefined reference to `tensorflow::ops::Div::Div(tensorflow::Scope const&, tensorflow::Input, tensorflow::Input)'\r\ntl_classifier.cc:(.text+0xd17): undefined reference to `tensorflow::Scope::~Scope()'\r\ntl_classifier.cc:(.text+0xddb): undefined reference to `tensorflow::Scope::ToGraphDef(tensorflow::GraphDef*) const'\r\ntl_classifier.cc:(.text+0x1116): undefined reference to `tensorflow::Scope::~Scope()'\r\ntl_classifier.cc:(.text+0x1175): undefined reference to `tensorflow::Scope::~Scope()'\r\ntl_classifier.cc:(.text+0x11b4): undefined reference to `tensorflow::Scope::~Scope()'\r\ntl_classifier.cc:(.text+0x1216): undefined reference to `tensorflow::Scope::~Scope()'\r\ntl_classifier.cc:(.text+0x1275): undefined reference to `tensorflow::Scope::~Scope()'\r\n/tmp/ccAJKAVH.o:tl_classifier.cc:(.text+0x12d7): more undefined references to `tensorflow::Scope::~Scope()' follow\r\n/tmp/ccAJKAVH.o: In function `GetTopLabels(std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> > const&, int, tensorflow::Tensor*, tensorflow::Tensor*)':\r\ntl_classifier.cc:(.text+0x18fe): undefined reference to `tensorflow::Scope::NewRootScope()'\r\ntl_classifier.cc:(.text+0x1999): undefined reference to `tensorflow::Scope::WithOpName(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const'\r\ntl_classifier.cc:(.text+0x19bd): undefined reference to `tensorflow::ops::TopK::TopK(tensorflow::Scope const&, tensorflow::Input, tensorflow::Input)'\r\ntl_classifier.cc:(.text+0x19db): undefined reference to `tensorflow::Scope::~Scope()'\r\ntl_classifier.cc:(.text+0x1a28): undefined reference to `tensorflow::Scope::ToGraphDef(tensorflow::GraphDef*) const'\r\ntl_classifier.cc:(.text+0x1d9c): undefined reference to `tensorflow::Scope::~Scope()'\r\ntl_classifier.cc:(.text+0x1de4): undefined reference to `tensorflow::Scope::~Scope()'\r\ntl_classifier.cc:(.text+0x1f3d): undefined reference to `tensorflow::Scope::~Scope()'\r\n/tmp/ccAJKAVH.o: In function `tensorflow::Input::Input(tensorflow::Input::Initializer const&)':\r\ntl_classifier.cc:(.text._ZN10tensorflow5InputC2ERKNS0_11InitializerE[_ZN10tensorflow5InputC5ERKNS0_11InitializerE]+0x40): undefined reference to `tensorflow::Operation::Operation(tensorflow::Node*)'\r\n/tmp/ccAJKAVH.o: In function `tensorflow::Input::Input(tensorflow::Tensor const&)':\r\ntl_classifier.cc:(.text._ZN10tensorflow5InputC2ERKNS_6TensorE[_ZN10tensorflow5InputC5ERKNS_6TensorE]+0x39): undefined reference to `tensorflow::Operation::Operation(tensorflow::Node*)'\r\n/tmp/ccAJKAVH.o: In function `tensorflow::Input::Input(std::initializer_list<tensorflow::Input::Initializer> const&)':\r\ntl_classifier.cc:(.text._ZN10tensorflow5InputC2ERKSt16initializer_listINS0_11InitializerEE[_ZN10tensorflow5InputC5ERKSt16initializer_listINS0_11InitializerEE]+0x45): undefined reference to `tensorflow::Operation::Operation(tensorflow::Node*)'\r\ntl_classifier.cc:(.text._ZN10tensorflow5InputC2ERKSt16initializer_listINS0_11InitializerEE[_ZN10tensorflow5InputC5ERKSt16initializer_listINS0_11InitializerEE]+0x15e): undefined reference to `tensorflow::Input::Initializer::Initializer(std::initializer_list<tensorflow::Input::Initializer> const&)'\r\n/tmp/ccAJKAVH.o: In function `tensorflow::Output::Output()':\r\ntl_classifier.cc:(.text._ZN10tensorflow6OutputC2Ev[_ZN10tensorflow6OutputC5Ev]+0x19): undefined reference to `tensorflow::Operation::Operation(tensorflow::Node*)'\r\n/usr/local/lib/libtensorflow_framework.so: undefined reference to `omp_in_parallel@VERSION'\r\n/usr/local/lib/libtensorflow_framework.so: undefined reference to `i_calloc'\r\n/usr/local/lib/libtensorflow_framework.so: undefined reference to `omp_get_max_threads@VERSION'\r\n/usr/local/lib/libtensorflow_framework.so: undefined reference to `omp_get_thread_num@VERSION'\r\n/usr/local/lib/libtensorflow_framework.so: undefined reference to `i_malloc'\r\n/usr/local/lib/libtensorflow_framework.so: undefined reference to `GOMP_barrier@VERSION'\r\n/usr/local/lib/libtensorflow_framework.so: undefined reference to `omp_get_num_threads@VERSION'\r\n/usr/local/lib/libtensorflow_framework.so: undefined reference to `i_free'\r\n/usr/local/lib/libtensorflow_framework.so: undefined reference to `GOMP_parallel@VERSION'\r\n/usr/local/lib/libtensorflow_framework.so: undefined reference to `i_realloc'\r\ncollect2: error: ld returned 1 exit status\r\n\r\nThanks.", "@asimshankar Looks the errors now are related to mkl library, I'll rebuild libtensorflow_cc without mkl and try again. Thanks.", "@asimshankar after add mkl library and put the -ltensorflow_cc -ltensorflow_framework after the source file. It works now. Many thanks for you help!\r\n\r\n#14632 issue can be closed.", "Hi.\r\n\r\nIm still having the above issue with TF 1.4 final via git, compiled with -config-opt without any MKL or anything on Darwin (10.13.1)\r\n\r\nMy application is now linking both libtensorflow_cc.so and libtensorflow_framework.so\r\n\r\n```\r\notool -L libtensorflow_cc.so \r\nlibtensorflow_cc.so:\r\n\t@rpath/libtensorflow_cc.so (compatibility version 0.0.0, current version 0.0.0)\r\n\t@rpath/libtensorflow_framework.so (compatibility version 0.0.0, current version 0.0.0)\r\n\t/usr/lib/libSystem.B.dylib (compatibility version 1.0.0, current version 1252.0.0)\r\n```\r\n\r\n``` \r\notool -L libtensorflow_framework.so \r\nlibtensorflow_framework.so:\r\n\t@rpath/libtensorflow_framework.so (compatibility version 0.0.0, current version 0.0.0)\r\n\t/usr/lib/libSystem.B.dylib (compatibility version 1.0.0, current version 1252.0.0)\r\n\t/System/Library/Frameworks/IOKit.framework/Versions/A/IOKit (compatibility version 1.0.0, current version 275.0.0)\r\n```\r\n\r\nAnd I have linker errors same as what I reported earlier:\r\n\r\n```Undefined symbols for architecture x86_64:\r\n  \"tensorflow::TensorShape::SlowCopyFrom(tensorflow::TensorShape const&)\", referenced from:\r\n      tensorflow::Tensor::Tensor(tensorflow::Tensor const&) in TensorflowFeatureModule.o\r\n  \"tensorflow::TensorShape::DestructorOutOfLine()\", referenced from:\r\n      -[TensorflowFeatureModule initWithQualityHint:] in TensorflowFeatureModule.o\r\n      tensorflow::Tensor::Tensor(tensorflow::Tensor const&) in TensorflowFeatureModule.o\r\n  \"tensorflow::TensorShape::TensorShape(tensorflow::gtl::ArraySlice<long long>)\", referenced from:\r\n      -[TensorflowFeatureModule initWithQualityHint:] in TensorflowFeatureModule.o\r\n  \"tensorflow::TensorShape::dim_size(int) const\", referenced from:\r\n      Eigen::DSizes<long, 4> tensorflow::TensorShape::AsEigenDSizesWithPadding<4>() const in TensorflowFeatureModule.o\r\nld: symbol(s) not found for architecture x86_64\r\n```\r\n\r\n", "Hi. So this issue is now partially resolved, partially due to stale project headers and also resolving an issue introduced in 1.4 by way of https://github.com/tensorflow/tensorflow/issues/12482.\r\n\r\nIn my particular case, getting the C++ Api of TF 1.4 via libtensorflow_cc.so properly linking into my app I needed to\r\n\r\n**1 Compile TF via the normal instructions**\r\n* bazel clean\r\n* ./configure\r\n* bazel build --config=opt //tensorflow:libtensorflow_cc.so\r\n\r\n**2 Configure Xcode**\r\n* copy libtensorflow_cc.so & libtensorflow_framework.so from to my project from bazel-bin/tensorflow/\r\n* Ensure my Library Search Paths in my Xcode Build Settings referenced the containing folder for libtensorflow_cc.so & libtensorflow_framework.so (Xcode should do this automatically but it helps to check).\r\n\r\n**3 Setup headers**\r\n* Run a script to nab all of the headers and deposit them to a single location\r\n* Grab the **generated** protocol buffer headers from the libtensorflow_cc bazel build output and add them to my include folder.\r\n* Ensure Xcode references this include folder in the build settings.\r\n* Finally, edit mutex.h to fix NSync compile issues once you've jumped through those hoops. (#12482)\r\n\r\nHopefully this is helpful to someone in the future!", "This appears to be resolved, so I'm closing the issue to help keep the issue tracker focused.", "> @tho15 : The `-ltensorflow_framework` argument should be after the source file. Can you try putting it at the end (after `tf_classifier.cc`)?\r\n\r\nI got almost the same issue, this is just the right answer, and --rpath or LD_LIBRARY_PATH should be checked. Thank you so so much."]}, {"number": 12537, "title": "Printing lines without logging prefix using tf.Print()", "body": "Right now, all messages printed via `tf.Print()` are prefixed by:\r\n\r\n```\r\n<timestamp>: I tensorflow/core/kernels/logging_ops.cc:79]\r\n```\r\n\r\nIt would be useful to have a way to print user-friendly output from within the graph. Therefore, suggest adding a parameter for the logging format to `tf.Print()`, or at least adding a flag that disables the logging prefix.", "comments": ["The prefix comes from LOG(INFO) inside the logging_ops kernel.  The fix needs to be made at the C++ level, though I don't have a good recommendation as to how."]}, {"number": 12536, "title": "Eager execution API strided slice problem.", "body": "@alextp there seems to be a problem with eagerly executing strided slice ops. The problem seems to be in the shape inference component and is non-deterministic. If you add the following code in the `eager/c_api_test.cc` file and run the test multiple times, you'll notice that sometimes it succeeds and sometimes it fails, randomly. More specifically, I get errors related to the strides input tensor, but I think this may have to do with how the memory is managed for eager tensors:\r\n\r\n```cc\r\nTFE_TensorHandle* TestBeginTensorHandle() {\r\n  int64_t dims[] = {2};\r\n  int data[] = {1, 0};\r\n  TF_Tensor* t = TF_AllocateTensor(\r\n      TF_INT32, &dims[0], sizeof(dims) / sizeof(int64_t), sizeof(data));\r\n  memcpy(TF_TensorData(t), &data[0], TF_TensorByteSize(t));\r\n  TFE_TensorHandle* th = TFE_NewTensorHandle(t);\r\n  TF_DeleteTensor(t);\r\n  return th;\r\n}\r\n\r\nTFE_TensorHandle* TestEndTensorHandle() {\r\n  int64_t dims[] = {2};\r\n  int data[] = {2, 1};\r\n  TF_Tensor* t = TF_AllocateTensor(\r\n      TF_INT32, &dims[0], sizeof(dims) / sizeof(int64_t), sizeof(data));\r\n  memcpy(TF_TensorData(t), &data[0], TF_TensorByteSize(t));\r\n  TFE_TensorHandle* th = TFE_NewTensorHandle(t);\r\n  TF_DeleteTensor(t);\r\n  return th;\r\n}\r\n\r\nTFE_TensorHandle* TestStridesTensorHandle() {\r\n  int64_t dims[] = {2};\r\n  int data[] = {1};\r\n  TF_Tensor* t = TF_AllocateTensor(\r\n      TF_INT32, &dims[0], sizeof(dims) / sizeof(int64_t), sizeof(data));\r\n  memcpy(TF_TensorData(t), &data[0], TF_TensorByteSize(t));\r\n  TFE_TensorHandle* th = TFE_NewTensorHandle(t);\r\n  TF_DeleteTensor(t);\r\n  return th;\r\n}\r\n\r\nTEST(CAPI, ExecuteStridedSlice) {\r\n  TF_Status* status = TF_NewStatus();\r\n  TF_SessionOptions* opts = TF_NewSessionOptions();\r\n  TFE_Context* ctx = TFE_NewContext(opts, status);\r\n  CHECK_EQ(TF_OK, TF_GetCode(status)) << TF_Message(status);\r\n  TF_DeleteSessionOptions(opts);\r\n\r\n  TFE_TensorHandle* a = TestMatrixTensorHandle();\r\n  TFE_TensorHandle* begin = TestBeginTensorHandle();\r\n  TFE_TensorHandle* end = TestEndTensorHandle();\r\n  TFE_TensorHandle* strides = TestStridesTensorHandle();\r\n  TFE_Op* op = TFE_NewOp(ctx, \"StridedSlice\", status);\r\n  CHECK_EQ(TF_OK, TF_GetCode(status)) << TF_Message(status);\r\n  TFE_OpAddInput(op, a, status);\r\n  CHECK_EQ(TF_OK, TF_GetCode(status)) << TF_Message(status);\r\n  TFE_OpAddInput(op, begin, status);\r\n  CHECK_EQ(TF_OK, TF_GetCode(status)) << TF_Message(status);\r\n  TFE_OpAddInput(op, end, status);\r\n  CHECK_EQ(TF_OK, TF_GetCode(status)) << TF_Message(status);\r\n  TFE_OpAddInput(op, strides, status);\r\n  CHECK_EQ(TF_OK, TF_GetCode(status)) << TF_Message(status);\r\n  TFE_OpSetAttrType(op, \"T\", TFE_TensorHandleDataType(a));\r\n  TFE_OpSetAttrType(op, \"Index\", TFE_TensorHandleDataType(begin));\r\n  TFE_OpSetAttrInt(op, \"begin_mask\", 0);\r\n  TFE_OpSetAttrInt(op, \"end_mask\", 0);\r\n  TFE_OpSetAttrInt(op, \"ellipsis_mask\", 0);\r\n  TFE_OpSetAttrInt(op, \"new_axis_mask\", 0);\r\n  TFE_OpSetAttrInt(op, \"shrink_axis_mask\", 3);\r\n\r\n  TFE_TensorHandle* retvals[2] = {nullptr};\r\n  int num_retvals = 2;  // Should be reduced to 1 by the TFE_Execute call.\r\n  TFE_Execute(op, &retvals[0], &num_retvals, status);\r\n  EXPECT_EQ(TF_OK, TF_GetCode(status)) << TF_Message(status);\r\n  TFE_DeleteOp(op);\r\n  TFE_DeleteTensorHandle(a);\r\n  TFE_DeleteTensorHandle(begin);\r\n  TFE_DeleteTensorHandle(end);\r\n  TFE_DeleteTensorHandle(strides);\r\n  TFE_DeleteContext(ctx, status);\r\n  ASSERT_EQ(TF_OK, TF_GetCode(status)) << TF_Message(status);\r\n  ASSERT_EQ(1, num_retvals);\r\n\r\n  TF_Tensor* t = TFE_TensorHandleResolve(retvals[0], status);\r\n  TFE_DeleteTensorHandle(retvals[0]);\r\n  ASSERT_EQ(TF_OK, TF_GetCode(status)) << TF_Message(status);\r\n  float result[1] = {0};\r\n  EXPECT_EQ(sizeof(result), TF_TensorByteSize(t));\r\n  memcpy(&result[0], TF_TensorData(t), TF_TensorByteSize(t));\r\n  TF_DeleteTensor(t);\r\n  EXPECT_EQ(3, result[0]);\r\n  TF_DeleteStatus(status);\r\n}\r\n```", "comments": ["The error I get is\n\n0823 13:19:03.218401  373487 op_kernel.cc:1192] Invalid argument: only\nstride 1 allowed on non-range indexing.\nthird_party/tensorflow/c/eager/c_api_test.cc:546: Failure\nExpected equality of these values:\n  TF_OK\n    Which is: 0\n  TF_GetCode(status)\n    Which is: 3\nonly stride 1 allowed on non-range indexing.\nStack trace:\n\nwhich comes from calling stridedslice wrong. It's really hard to call it\nright, though :-/\n\nStrides needs to be higher-dimensional in your case, so change it to\n\nTFE_TensorHandle* TestStridesTensorHandle() {\n  int64_t dims[] = {2};\n  int data[] = {1, 1};\n  TF_Tensor* t = TF_AllocateTensor(\n      TF_INT32, &dims[0], sizeof(dims) / sizeof(int64_t), sizeof(data));\n  memcpy(TF_TensorData(t), &data[0], TF_TensorByteSize(t));\n  TFE_TensorHandle* th = TFE_NewTensorHandle(t);\n  TF_DeleteTensor(t);\n  return th;\n}\n\n\n(i.e. data went from {1} to {1, 1})\n\nThen the tests pass deterministically for me.\n\n\n\nOn Wed, Aug 23, 2017 at 4:01 PM, Anthony Platanios <notifications@github.com\n> wrote:\n\n> @alextp <https://github.com/alextp> there seems to be a problem with\n> eagerly executing strided slice ops. The problem seems to be in the shape\n> inference component and is non-deterministic. If you add the following code\n> in the eager/c_api_test.cc file and run the test multiple times, you'll\n> notice that sometimes it succeeds and sometimes it fails, randomly. More\n> specifically, I get errors related to the strides input tensor, but I think\n> this may have to do with how the memory is managed for eager tensors:\n>\n> TFE_TensorHandle* TestBeginTensorHandle() {\n>   int64_t dims[] = {2};\n>   int data[] = {1, 0};\n>   TF_Tensor* t = TF_AllocateTensor(\n>       TF_INT32, &dims[0], sizeof(dims) / sizeof(int64_t), sizeof(data));\n>   memcpy(TF_TensorData(t), &data[0], TF_TensorByteSize(t));\n>   TFE_TensorHandle* th = TFE_NewTensorHandle(t);\n>   TF_DeleteTensor(t);\n>   return th;\n> }\n>\n> TFE_TensorHandle* TestEndTensorHandle() {\n>   int64_t dims[] = {2};\n>   int data[] = {2, 1};\n>   TF_Tensor* t = TF_AllocateTensor(\n>       TF_INT32, &dims[0], sizeof(dims) / sizeof(int64_t), sizeof(data));\n>   memcpy(TF_TensorData(t), &data[0], TF_TensorByteSize(t));\n>   TFE_TensorHandle* th = TFE_NewTensorHandle(t);\n>   TF_DeleteTensor(t);\n>   return th;\n> }\n>\n> TFE_TensorHandle* TestStridesTensorHandle() {\n>   int64_t dims[] = {2};\n>   int data[] = {1};\n>   TF_Tensor* t = TF_AllocateTensor(\n>       TF_INT32, &dims[0], sizeof(dims) / sizeof(int64_t), sizeof(data));\n>   memcpy(TF_TensorData(t), &data[0], TF_TensorByteSize(t));\n>   TFE_TensorHandle* th = TFE_NewTensorHandle(t);\n>   TF_DeleteTensor(t);\n>   return th;\n> }\n>\n> TEST(CAPI, ExecuteStridedSlice) {\n>   TF_Status* status = TF_NewStatus();\n>   TF_SessionOptions* opts = TF_NewSessionOptions();\n>   TFE_Context* ctx = TFE_NewContext(opts, status);\n>   CHECK_EQ(TF_OK, TF_GetCode(status)) << TF_Message(status);\n>   TF_DeleteSessionOptions(opts);\n>\n>   TFE_TensorHandle* a = TestMatrixTensorHandle();\n>   TFE_TensorHandle* begin = TestBeginTensorHandle();\n>   TFE_TensorHandle* end = TestEndTensorHandle();\n>   TFE_TensorHandle* strides = TestStridesTensorHandle();\n>   TFE_Op* op = TFE_NewOp(ctx, \"StridedSlice\", status);\n>   CHECK_EQ(TF_OK, TF_GetCode(status)) << TF_Message(status);\n>   TFE_OpAddInput(op, a, status);\n>   CHECK_EQ(TF_OK, TF_GetCode(status)) << TF_Message(status);\n>   TFE_OpAddInput(op, begin, status);\n>   CHECK_EQ(TF_OK, TF_GetCode(status)) << TF_Message(status);\n>   TFE_OpAddInput(op, end, status);\n>   CHECK_EQ(TF_OK, TF_GetCode(status)) << TF_Message(status);\n>   TFE_OpAddInput(op, strides, status);\n>   CHECK_EQ(TF_OK, TF_GetCode(status)) << TF_Message(status);\n>   TFE_OpSetAttrType(op, \"T\", TFE_TensorHandleDataType(a));\n>   TFE_OpSetAttrType(op, \"Index\", TFE_TensorHandleDataType(begin));\n>   TFE_OpSetAttrInt(op, \"begin_mask\", 0);\n>   TFE_OpSetAttrInt(op, \"end_mask\", 0);\n>   TFE_OpSetAttrInt(op, \"ellipsis_mask\", 0);\n>   TFE_OpSetAttrInt(op, \"new_axis_mask\", 0);\n>   TFE_OpSetAttrInt(op, \"shrink_axis_mask\", 3);\n>\n>   TFE_TensorHandle* retvals[2] = {nullptr};\n>   int num_retvals = 2;  // Should be reduced to 1 by the TFE_Execute call.\n>   TFE_Execute(op, &retvals[0], &num_retvals, status);\n>   EXPECT_EQ(TF_OK, TF_GetCode(status)) << TF_Message(status);\n>   TFE_DeleteOp(op);\n>   TFE_DeleteTensorHandle(a);\n>   TFE_DeleteTensorHandle(begin);\n>   TFE_DeleteTensorHandle(end);\n>   TFE_DeleteTensorHandle(strides);\n>   TFE_DeleteContext(ctx, status);\n>   ASSERT_EQ(TF_OK, TF_GetCode(status)) << TF_Message(status);\n>   ASSERT_EQ(1, num_retvals);\n>\n>   TF_Tensor* t = TFE_TensorHandleResolve(retvals[0], status);\n>   TFE_DeleteTensorHandle(retvals[0]);\n>   ASSERT_EQ(TF_OK, TF_GetCode(status)) << TF_Message(status);\n>   float result[1] = {0};\n>   EXPECT_EQ(sizeof(result), TF_TensorByteSize(t));\n>   memcpy(&result[0], TF_TensorData(t), TF_TensorByteSize(t));\n>   TF_DeleteTensor(t);\n>   EXPECT_EQ(3, result[0]);\n>   TF_DeleteStatus(status);\n> }\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/12536>, or mute the\n> thread\n> <https://github.com/notifications/unsubscribe-auth/AAATxXFGjPv87KFy7jZfND0cRks7z7Npks5sbIT9gaJpZM4PAgVi>\n> .\n>\n\n\n\n-- \n - Alex\n", "I see. You're actually right. I guess I'm only trying to reproduce a problem I'm getting when setting this up through my JNI bindings. The error I get (and which is not deterministic) is:\r\n\r\n`W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: strides[0] must be non-zero`\r\n\r\nAnd the actual values I'm passing to the op are exactly the same as in the above example. Do you have any idea as to why this might be happening? Thanks! :)", "What this looks like to me from the non-determinism is that JNI is freeing\nthe tensor while tensorflow still has a reference to it.\n\nMaybe try making a copy of the memory before creating a tensor and see if\nit goes away?\n\nOddly I can't find where in the code this error is coming from. Can you\nedit the line 1192 in op_kernel.cc and make it crash the program and\nproduce a stack trace, in case my suggestion above doesn't work?\n\nOn Wed, Aug 23, 2017 at 2:42 PM, Anthony Platanios <notifications@github.com\n> wrote:\n\n> I see. You're actually right. I guess I'm only trying to reproduce a\n> problem I'm getting when setting this up through my JNI bindings. The error\n> I get (and which is not deterministic) is:\n>\n> W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument:\n> strides[0] must be non-zero\n>\n> And the actual values I'm passing to the op are exactly the same as in the\n> above example. Do you have any idea as to why this might be happening?\n> Thanks! :)\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/12536#issuecomment-324470106>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAATxRlIF80A_btxawrJB0HeYafHejcfks5sbJy4gaJpZM4PAgVi>\n> .\n>\n\n\n\n-- \n - Alex\n", "Actually this is where the error is raised:\nhttps://github.com/tensorflow/tensorflow/blob/593dc8e5d65f4db93e8f5fced772abb3531a9752/tensorflow/core/util/strided_slice_op.cc#L257\n\nSince I assume you're setting the strides correctly (they must be non-zero)\nI think we're looking at memory being freed before tensorflow gets to it.\n\nOn Wed, Aug 23, 2017 at 3:06 PM, Alexandre Passos <apassos@google.com>\nwrote:\n\n> What this looks like to me from the non-determinism is that JNI is freeing\n> the tensor while tensorflow still has a reference to it.\n>\n> Maybe try making a copy of the memory before creating a tensor and see if\n> it goes away?\n>\n> Oddly I can't find where in the code this error is coming from. Can you\n> edit the line 1192 in op_kernel.cc and make it crash the program and\n> produce a stack trace, in case my suggestion above doesn't work?\n>\n> On Wed, Aug 23, 2017 at 2:42 PM, Anthony Platanios <\n> notifications@github.com> wrote:\n>\n>> I see. You're actually right. I guess I'm only trying to reproduce a\n>> problem I'm getting when setting this up through my JNI bindings. The error\n>> I get (and which is not deterministic) is:\n>>\n>> W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument:\n>> strides[0] must be non-zero\n>>\n>> And the actual values I'm passing to the op are exactly the same as in\n>> the above example. Do you have any idea as to why this might be happening?\n>> Thanks! :)\n>>\n>> \u2014\n>> You are receiving this because you were mentioned.\n>> Reply to this email directly, view it on GitHub\n>> <https://github.com/tensorflow/tensorflow/issues/12536#issuecomment-324470106>,\n>> or mute the thread\n>> <https://github.com/notifications/unsubscribe-auth/AAATxRlIF80A_btxawrJB0HeYafHejcfks5sbJy4gaJpZM4PAgVi>\n>> .\n>>\n>\n>\n>\n> --\n>  - Alex\n>\n\n\n\n-- \n - Alex\n", "@alextp I also believe that's what's happening. I have the following related question:\r\n\r\nThrough the C API I can create `TF_Tensor` objects and specify a deallocator for them. This allows me to create a tensor using a buffer created on the Scala side and pass as the deallocator a function that removes a reference to this buffer from the garbage collector (loosely speaking). Now, if I:\r\n1. Create a `TF_Tensor` from a Scala-allocated buffer.\r\n2. Create a `TFE_TensorHandle` using that tensor.\r\n3. Delete the `TF_Tensor` so that I can keep using only my `TFE_TensorHandle`.\r\n\r\nThen the underlying buffer may be deallocated by the JVM because the `TF_Tensor` deallocator will notify the JVM that the underlying buffer is not being used by the native library anymore. So, this raises a couple questions:\r\n1. How can I avoid this using the eager API? Shouldn't I be able to create a `TFE_TensorHandle` and let it have it's own deallocation function, similar to how it's done for `TF_Tensor`s?\r\n2. Why have both `TFE_TensorHandle`s and `TF_Tensor`s in the first place? Isn't there a simple way to merge the two and avoid the complexity of having to deal with both types of tensors?\r\n\r\nI hope this makes sense.", "On Wed, Aug 23, 2017 at 3:22 PM, Anthony Platanios <notifications@github.com\n> wrote:\n\n> @alextp <https://github.com/alextp> I also believe that's what's\n> happening. I have the following related question:\n>\n> Through the C API I can create TF_Tensor objects and specify a\n> deallocator for them. This allows me to create a tensor using a buffer\n> created on the Scala side and pass as the deallocator a function that\n> removes a reference to this buffer from the garbage collector (loosely\n> speaking). Now, if I:\n>\n>    1. Create a TF_Tensor from a Scala-allocated buffer.\n>    2. Create a TFE_TensorHandle using that tensor.\n>    3. Delete the TF_Tensor so that I can keep using only my\n>    TFE_TensorHandle.\n>\n>\nThis sequence of operations should be fine. We should only call the\ndestructor after the last reference to the buffer (not the tf_tensor) has\ngone. So once you create the tfe_tensorhandle and delete the tf_tensor the\ndestructor should not be called until you delete the tfe_tensorhandle.\n\n\n>\n>\n> Then the underlying buffer may be deallocated by the JVM because the\n> TF_Tensor deallocator will notify the JVM that the underlying buffer is\n> not being used by the native library anymore. So, this raises a couple\n> questions:\n>\n>    1. How can I avoid this using the eager API? Shouldn't I be able to\n>    create a TFE_TensorHandle and let it have it's own deallocation\n>    function, similar to how it's done for TF_Tensors?\n>    2. Why have both TFE_TensorHandles and TF_Tensors in the first place?\n>    Isn't there a simple way to merge the two and avoid the complexity of\n>    having to deal with both types of tensors?\n>\n>\nA TF_Tensor means a bit of memory allocated in the CPU and easily\ninspectable by custom code. a TFE_TensorHandle can be on the GPU and can\nhave internal state which is in an internal format that requires converting\nto the tf_tensor format (like in the case of strings).\n\n-- \n - Alex\n", "@alextp I see. That sounds reasonable. I checked and can now verify that the buffers are not deallocated by the JVM. I guess my question now is whether or not it matters where those buffers live. I'm currently allocating them using Java DirectByteBuffers. Do you think that this may be causing a problem?", "I do not understand how JNI buffers work. Can you try copying the memory\ninto a  malloc-allocated buffer and using free as your destructor, to see\nwhether the issue goes away?\n\nOn Wed, Aug 23, 2017 at 3:53 PM, Anthony Platanios <notifications@github.com\n> wrote:\n\n> @alextp <https://github.com/alextp> I see. That sounds reasonable. I\n> checked and can now verify that the buffers are not deallocated by the JVM.\n> I guess my question now is whether or not it matters where those buffers\n> live. I'm currently allocating them using Java DirectByteBuffers. Do you\n> think that this may be causing a problem?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/12536#issuecomment-324484640>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAATxcg2q41zA-AHAR9r2Z1bBTC-CkhLks5sbK1ZgaJpZM4PAgVi>\n> .\n>\n\n\n\n-- \n - Alex\n", "@alextp This has to do with JNI byte buffers indeed. I'll close this issue and I'll look into how to make all tensor memory managed by the TensorFlow native library."]}, {"number": 12535, "title": "Added shape information to the while loop input placeholders for the C API.", "body": "As discussed with @skye :)", "comments": ["Can one of the admins verify this patch?", "@skye Thanks for pointing out those things. I made all the requested changes. :)", "Done :)", "I hope it all looks good now! :)", "Can one of the admins verify this patch?"]}, {"number": 12534, "title": "[CMake] fatal error: 'nsync_time_init.h' file not found on mac", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nNo.\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nDarwin T-X.local 16.5.0 Darwin Kernel Version 16.5.0: Fri Mar  3 16:52:33 PST 2017; root:xnu-3789.51.2~3/RELEASE_X86_64 x86_64\r\n- **TensorFlow installed from (source or binary)**:\r\nSource.\r\n- **TensorFlow version (use command below)**:\r\nNot applicable. Happens during build.\r\n- **Python version**: \r\nNot applicable. Happens during build.\r\n- **Bazel version (if compiling from source)**:\r\nNot applicable. Compiling directory tensorflow/contrib/cmake using CMake 3.7.2 and clang Apple LLVM version 8.1.0 (clang-802.0.42).\r\n- **CUDA/cuDNN version**:\r\nNot applicable.\r\n- **GPU model and memory**:\r\nNot applicable.\r\n- **Exact command to reproduce**:\r\ncmake --build /Users/kasper/Development/tensorflow_pr/tensorflow/contrib/cmake --target all -- -j 8\r\n\r\n### Describe the problem\r\nThis is a bug related to the CMake build of TensorFlow which fails on my system due to an error with the nsync build. The nsync build seems to not include some headers (see below). I have tested with TensorFlow v1.0.0, v1.1.0, v1.2.0 and the current master branch. I have not been able to investigate the nsync error because a standalone nsync build (i.e. clone->cmake->make) fails at an earlier step (`/Users/kasper/Development/nsync/platform/macos/platform.h:35:13: error: typedef redefinition with different types ('int' vs 'enum clockid_t') typedef int clockid_t;`). Unfortunately, I have not been able to submit an issue to https://github.com/google/nsync and resolve this problem because issues are disabled for this repository.\r\n\r\n### Source code / logs\r\n[ 46%] Building CXX object CMakeFiles/nsync.dir/platform/c++11/src/time_rep_timespec.cc.o\r\nno\r\n/Users/kasper/Development/TensorFlowImageFilter/SuperBuild/cmake-build-debug/TensorFlow-build/nsync/src/nsync/platform/c++11/src/time_rep_timespec.cc:19:10: fatal error: 'nsync_time_init.h' file not found\r\n#include \"nsync_time_init.h\"", "comments": ["Manually copying `nsync_time_init.h` from `nsync/platform/posix` to `nsync/platform/macos` fixes the problem. Closing since this is not a TensorFlow issue. Pinging @m3bm3b.", "@m3bm3b The issue is still present in TensorFlow 1.4. Are you interested in a PR?", "Beware that the cmake build is not fully supported \r\nand not routinely tested on MacOS.  \r\nThe cmake build is there mostly for Windows.\r\n\r\nHowever, at least for that particular error\r\n     'nsync_time_init.h' file not found\r\nthe current master branch of TensorFlow should \r\nget past that point in the build.\r\nThe key difference from 1.4 that should fix the issue is in the file\r\n   tensorflow/contrib/cmake/patches/nsync/CMakeLists.txt\r\nand especially (new) line 64 of that file. \r\n\r\n\r\n\r\n\r\n", "Okay, many thanks for the update! Appreciated."]}, {"number": 12533, "title": "Branch 166229572", "body": "", "comments": ["Committing with the one broken test. Fixed internally. Will repush to fix that test."]}, {"number": 12532, "title": "Undefined symbol 'fixed_address_empty_string' : new tensorflow op with protobuf ", "body": "I would like to create a new operation that can communicate to an\r\nexternal python process. At the momemnt, I created a new operation\r\nthat sends to a python process \"hello world\" with `protobuf`.\r\n\r\nIn this tiny example, I'm sending a string. In the future I would like\r\nto send more complex data, like Eigen matrices, that's why I chose\r\n`protobuf`. (and for possible 'easy integration into tensorflow).\r\n\r\n**msg.proto** :\r\n```\r\npackage prototest;\r\n\r\nmessage Foo {\r\n  required string bar = 1;\r\n}\r\n```\r\n\r\n- `protoc msg.proto --cpp_out=. --python_out=.`\r\n- generates : `msg.pb.cc  msg.pb.h  msg_pb2.py`\r\n\r\n**hello_world.cc** :\r\n\r\n```cpp\r\n#include \"tensorflow/core/framework/op_kernel.h\"\r\n#include \"tensorflow/core/framework/tensor_shape.h\"\r\n#include \"tensorflow/core/platform/default/logging.h\"\r\n#include \"tensorflow/core/framework/shape_inference.h\"\r\n\r\n// to send serialized data through UPD socket\r\n#include <sys/socket.h>\r\n#include <arpa/inet.h>\r\n\r\n// generated header file from protoc\r\n#include \"msg.pb.h\"\r\n\r\nnamespace tensorflow{\r\n    namespace shape_inference{\r\n\r\n        Status HelloWorldShape(InferenceContext* c){\r\n            std::cout << \"shape_infernce is done\" << std::endl;\r\n            return Status::OK();\r\n        }\r\n        REGISTER_OP(\"HelloWorld\")\r\n            .SetShapeFn(HelloWorldShape)\r\n            .Doc(R\"doc(HelloWorld operation)doc\");\r\n    } // end namespace shape_inference\r\n\r\n    class HelloWorldOp : public OpKernel {\r\n    public :\r\n        // constructor\r\n        explicit HelloWorldOp(OpKernelConstruction* context) : OpKernel(context) {\r\n            std::cout << \"HelloWorldOp constructor\" << std::endl;\r\n        }\r\n\r\n        void Compute(OpKernelContext* context) override {\r\n            std::cout << \"Start Compute method\" << std::endl;\r\n            //-----------------------------------------------------------------\r\n            // send something to a Python process with protobuf\r\n            struct sockaddr_in addr;\r\n            addr.sin_family = AF_INET;\r\n            inet_aton(\"127.0.0.1\", &addr.sin_addr);\r\n            addr.sin_port = htons(5555);\r\n\r\n            // initialise a foo and set some properties\r\n            GOOGLE_PROTOBUF_VERIFY_VERSION;\r\n\r\n            prototest::Foo foo;\r\n            foo.set_bar(\"Hello World\");\r\n\r\n            // serialise to string, this one is obvious ; )\r\n            std::string buf;\r\n            foo.SerializeToString(&buf);\r\n\r\n            int sock = socket(PF_INET, SOCK_DGRAM, 0);\r\n            sendto(sock, buf.data(), buf.size(), 0, (struct sockaddr *)&addr, sizeof(addr));\r\n            //------------------------------------------------------------------\r\n            std::cout << \"Compute method is done\" << std::endl;\r\n        }\r\n    };\r\n    REGISTER_KERNEL_BUILDER(Name(\"HelloWorld\").Device(DEVICE_CPU), HelloWorldOp);\r\n} // end namespace tensorflow\r\n```\r\n\r\nTo compile and run my code, I use a test scrip found at [#10950](http://github.com/tensorflow/tensorflow/issues/10950)\r\n\r\n**compiler_and_run.py** :\r\n\r\n```python\r\n#!/usr/bin/env python3.5\r\n\r\n# Demo from https://github.com/tensorflow/tensorflow/issues/10950\r\n\r\nfrom __future__ import print_function\r\nimport os\r\nimport sys\r\nimport tensorflow as tf\r\n\r\n\r\nmy_dir = os.path.dirname(os.path.abspath(__file__))\r\nso_filename = \"lib_hello_world.so\"\r\ncc_filename = \"hello_world.cc\"\r\n\r\n\r\ndef compile():\r\n    # Fix for undefined symbol: _ZN6google8protobuf8internal26fixed_address_empty_stringE.\r\n    # https://github.com/tensorflow/tensorflow/issues/1419\r\n    from google.protobuf.pyext import _message as msg\r\n    lib = msg.__file__\r\n    ld_flags = [\r\n        \"-Xlinker\", \"-rpath\", \"-Xlinker\", os.path.dirname(lib),\r\n        \"-L\", os.path.dirname(lib), \"-l\", \":\" + os.path.basename(lib)]\r\n    common_opts = [\"-shared\", \"-O2\", \"-std=c++11\"]\r\n    if sys.platform == \"darwin\":\r\n        common_opts += [\"-undefined\", \"dynamic_lookup\"]\r\n    common_opts += [\"-I\", tf.sysconfig.get_include()]\r\n    common_opts += [\"-fPIC\"]\r\n    common_opts += [\"-D_GLIBCXX_USE_CXX11_ABI=0\"]  # might be obsolete in the future\r\n    opts = common_opts + [cc_filename, \"-o\", so_filename]\r\n    opts += ld_flags\r\n    cmd_bin = \"g++\"\r\n    cmd_args = [cmd_bin] + opts\r\n    from subprocess import Popen, PIPE, STDOUT, CalledProcessError\r\n    print(\"compile call: %s\" % \" \".join(cmd_args))\r\n    proc = Popen(cmd_args, stdout=PIPE, stderr=STDOUT)\r\n    stdout, stderr = proc.communicate()\r\n    assert stderr is None  # should only have stdout\r\n    if proc.returncode != 0:\r\n      print(\"compile failed: %s\" % cmd_bin)\r\n      print(\"Original stdout/stderr:\")\r\n      print(stdout)\r\n      raise CalledProcessError(returncode=proc.returncode, cmd=cmd_args)\r\n    assert os.path.exists(so_filename)\r\n\r\n\r\ndef main():\r\n    print(\"TensorFlow version:\", tf.GIT_VERSION, tf.VERSION)\r\n    os.chdir(my_dir)\r\n    compile()\r\n    mod = tf.load_op_library(\"%s/%s\" % (my_dir, so_filename))\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    main()\r\n```\r\n\r\n\r\nThis returns :\r\n\r\n```txt\r\nTensorFlow version: v1.2.0-rc2-21-g12f033d 1.2.0\r\ncompile call: g++ -shared -O2 -std=c++11 -I /usr/local/lib/python3.5/dist-packages/tensorflow/include -fPIC -D_GLIBCXX_USE_CXX11_ABI=0 hello_world.cc -o lib_hello_world.so -Xlinker -rpath -Xlinker /usr/local/lib/python3.5/dist-packages/protobuf-3.2.0-py3.5-linux-x86_64.egg/google/protobuf/pyext -L /usr/local/lib/python3.5/dist-packages/protobuf-3.2.0-py3.5-linux-x86_64.egg/google/protobuf/pyext -l :_message.cpython-35m-x86_64-linux-gnu.so\r\nTraceback (most recent call last):\r\n  File \"./compile_and_test.py\", line 55, in <module>\r\n    main()\r\n  File \"./compile_and_test.py\", line 51, in main\r\n    mod = tf.load_op_library(\"%s/%s\" % (my_dir, so_filename))\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/load_library.py\", line 64, in load_op_library\r\n    None, None, error_msg, error_code)\r\ntensorflow.python.framework.errors_impl.NotFoundError: /src/ext_hello_world/lib_hello_world.so: undefined symbol: _ZN6google8protobuf8internal26fixed_address_empty_stringE\r\n```\r\n\r\nCompilation seems to work (no fatal error). But `tf.load_op_library()``fails due to undefined library in shared lib (*.so).\r\n\r\nThis undefined symbol seems to come from protobuf.\r\n\r\nI installed `protoc` by myself (see Note about it).\r\n\r\n\r\nIn `tf.sysconfig.get_include()` there is a  `google/protobuf` folder with header files from built tensorflow.\r\n\r\nSo I don't know which header files are used during compilation :\r\n - header files from include files of tensorflow ?\r\n - header files of hand-installed protobuf ?\r\n\r\nOr this undefined symbol is not due to this fact ? \r\n\r\n- How can I resolve this undefined symbol error in the shared library ?\r\n- May I have to install `protoc` starting from `tensorflow/includes/google/protobuf` ? (and not from scratch)\r\n\r\n\r\nI observed that in [#10950](https://github.com/tensorflow/tensorflow/issues/10950) : \r\n```python\r\nfrom google.protobuf.pyext import _message as msg\r\nlib = msg.__file__\r\n```\r\nreturns : `/u/zeyer/.local/lib/python2.7/site-packages/google/protobuf/pyext/_message.so`\r\n\r\nIn my case it's : `/usr/local/lib/python3.5/dist-packages/protobuf-3.2.0-py3.5-linux-x86_64.egg/google/protobuf/pyext/_message.cpython-35m-x86_64-linux-gnu.so`\r\nThis file about protobuf seems to be completely different ... \r\n\r\n \r\n\r\n**Note about protoc install** :\r\n`protoc` (protobuf compiler) was not installed.\r\nI identified the version of protobuf used in tensorflow : v3.2.0 !\r\n\r\nAfter, I followed protobuf installation instruction (C++ and Python implementation).\r\n\r\n    ```bash\r\n    cd /opt/\r\n    # clone protobuf repo\r\n    git clone https://github.com/google/protobuf.git\r\n    cd protobuf\r\n\r\n    # change to the right branch\r\n    # list tags\r\n    git tag -l\r\n    git checkout tags/v3.2.0\r\n\r\n    # install protobuf\r\n    apt-get install autoconf automake libtool curl make g++ unzip\r\n    ./autogen.sh\r\n    ./configure\r\n    make\r\n    make check\r\n    make install\r\n    ldconfig\r\n\r\n    # protoc version\r\n    protoc --version\r\n    >>> libprotoc 3.2.0\r\n\r\n    # print linker and compiler files\r\n    pkg-config --cflags --libs protobuf\r\n    >>> -pthread -I/usr/local/include -L/usr/local/lib -lprotobuf -pthread -lpthread\r\n\r\n    #some useful env variables\r\n    PB_INC=$(pkg-config --cflags protobuf)\r\n    PB_LINK=$(pkg-config --libs protobuf)\r\n    TF_INC=$(python3.5 -c 'import tensorflow as tf; print(tf.sysconfig.get_include())')\r\n    TF_LIBS=$(find $TF_INC/../ -name \"*.so\")\r\n\r\n    # here, I used python3.5\r\n    cd python\r\n    export LD_LIBRARY_PATH=../src/.libs\r\n    python3.5 setup.py build --cpp_implementation\r\n    python3.5 setup.py test --cpp_implementation\r\n    python3.5 setup.py install --cpp_implementation\r\n    ```\r\n### System information\r\n\r\n- docker : Docker version 1.12.6, build 78d1802\r\n- image : tensorflow/tensorflow:1.2.0-devel-gpu-py3\r\n- based on : ubuntu 16.04 (4.4.0-78-generic)\r\n- tensorflow build from source\r\n- tensorflow version : 1.2.0\r\n- python version : Python 3.5.2\r\n- bazel version :\r\n    ```\r\n    Build label: 0.4.5\r\n    Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\n    Build time: Thu Mar 16 12:19:38 2017 (1489666778)\r\n    Build timestamp: 1489666778\r\n    Build timestamp as int: 1489666778\r\n    ```\r\n- gcc -v :\r\n    ```\r\n    Using built-in specs.\r\n    COLLECT_GCC=gcc\r\n    COLLECT_LTO_WRAPPER=/usr/lib/gcc/x86_64-linux-gnu/5/lto-wrapper\r\n    Target: x86_64-linux-gnu\r\n    Configured with: ../src/configure -v --with-pkgversion='Ubuntu 5.4.0-6ubuntu1~16.04.4' --with-bugurl=file:///usr/share/doc/gcc-5/README.Bugs --enable-languages=c,ada,c++,java,go,d,fortran,objc,obj-c++ --prefix=/usr --program-suffix=-5 --enable-shared --enable-linker-build-id --libexecdir=/usr/lib --without-included-gettext --enable-threads=posix --libdir=/usr/lib --enable-nls --with-sysroot=/ --enable-clocale=gnu --enable-libstdcxx-debug --enable-libstdcxx-time=yes --with-default-libstdcxx-abi=new --enable-gnu-unique-object --disable-vtable-verify --enable-libmpx --enable-plugin --with-system-zlib --disable-browser-plugin --enable-java-awt=gtk --enable-gtk-cairo --with-java-home=/usr/lib/jvm/java-1.5.0-gcj-5-amd64/jre --enable-java-home --with-jvm-root-dir=/usr/lib/jvm/java-1.5.0-gcj-5-amd64 --with-jvm-jar-dir=/usr/lib/jvm-exports/java-1.5.0-gcj-5-amd64 --with-arch-directory=amd64 --with-ecj-jar=/usr/share/java/eclipse-ecj.jar --enable-objc-gc --enable-multiarch --disable-werror --with-arch-32=i686 --with-abi=m64 --with-multilib-list=m32,m64,mx32 --enable-multilib --with-tune=generic --enable-checking=release --build=x86_64-linux-gnu --host=x86_64-linux-gnu --target=x86_64-linux-gnu\r\n    Thread model: posix\r\n    gcc version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.4)\r\n    ```\r\nInformation from https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh :\r\n\r\n```txt\r\n== cat /etc/issue ===============================================\r\nLinux 2b98f5ebc987 4.4.0-78-generic #99-Ubuntu SMP Thu Apr 27 15:29:09 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\nVERSION=\"16.04.2 LTS (Xenial Xerus)\"\r\nVERSION_ID=\"16.04\"\r\nVERSION_CODENAME=xenial\r\n\r\n== are we in docker =============================================\r\nYes\r\n== compiler =====================================================\r\nc++ (Ubuntu 5.4.0-6ubuntu1~16.04.4) 5.4.0 20160609\r\nCopyright (C) 2015 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n== uname -a =====================================================\r\nLinux 2b98f5ebc987 4.4.0-78-generic #99-Ubuntu SMP Thu Apr 27 15:29:09 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\n== check pips ===================================================\r\nnumpy (1.13.0)\r\nprotobuf (3.3.0)\r\ntensorflow (1.2.0)\r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n== tensorflow import ============================================\r\ntf.VERSION = 1.2.0\r\ntf.GIT_VERSION = v1.2.0-rc2-21-g12f033d\r\ntf.COMPILER_VERSION = v1.2.0-rc2-21-g12f033d\r\nSanity check: array([1], dtype=int32)\r\n== env ==========================================================\r\nLD_LIBRARY_PATH /usr/local/cuda/extras/CUPTI/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\r\nDYLD_LIBRARY_PATH is unset\r\n== nvidia-smi ===================================================\r\nWed Aug 23 17:24:13 2017\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 370.28                 Driver Version: 370.28                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  GeForce 940MX       Off  | 0000:01:00.0     Off |                  N/A |\r\n| N/A   54C    P0    N/A /  N/A |    277MiB /  2002MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n\r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID  Type  Process name                               Usage      |\r\n|=============================================================================|\r\n+-----------------------------------------------------------------------------+\r\n\r\n== cuda libs  ===================================================\r\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart_static.a\r\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart.so.8.0.61\r\n```", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 12531, "title": "Enable int16 and uint16 for reverse op", "body": "This fix tries to address the issue in #12528 where it was not possible to run uint16 on rot90 (reverse) op\r\n\r\nThe int16 and uint16 has been implemented in CPU though they were not enabled yet.\r\n\r\nThis fix enables int16 and uint16.\r\n\r\nThis fix fixes #12528.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please"]}, {"number": 12530, "title": "Is there any method to dump the IR and machine code of XLA compiler?", "body": "Is there any method to dump the IR of tensorflow xla `from the compilers front end to the backend`, as detailed as better!\r\nSuch as the HLO IR to LLO IR and the machine code generated by xla backend? I wonder the details of TensorFlow XLA compiler, the official website isn't detailed...", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!", "I posted some information on this here: https://stackoverflow.com/a/45518731", "@learyg ok, thanks", "I am not able to take ir dump using new flag --xla_dump_ir_to=/path\r\nthe previous flag I am able to get the dump xla_generate_hlo_text_to"]}, {"number": 12529, "title": "Docs typo fix", "body": "`(key, value pair) -> (key, value) pair`", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please"]}, {"number": 12528, "title": "Data Augmentation of uint16 images (such as PNG)", "body": "How we can do data augmentation (rotation, flip,...) of uint16 images?\r\n\r\nHere is a piece of my code:\r\n\r\nimport os\r\nimport tensorflow as tf\r\n\r\nfilQ=['ex4497_fbp_13.png','ex4497_fbp_12.png']\r\nfilQQ=tf.train.string_input_producer(filQ)\r\n\r\nreader =tf.WholeFileReader()\r\nkey, value = reader.read(filQQ)\r\n\r\nmyimg = tf.image.decode_png(value, dtype=tf.uint16) \r\nmyimg1 = tf.image.rot90(myimg,k=1,name=None)\r\n\r\nI get an error that:\r\n\r\nTypeError: Value passed to parameter 'tensor' has DataType uint16 not in list of allowed values: uint8, int8, int32, int64, bool, float16, float32, float64, complex64, complex128, string\r\n\r\nSo basically unit16 doesn't exist!\r\nunit8 is not a good choice because the pixel values in my image are NOT in the range [0 255],\r\nand we can only use data type uint8, uint16 for PNG in tensorflow!!\r\n\r\n\r\nSo again the question becomes:\r\n**How we can do data augmentation (rotation, flip,...) of uint16 images?**\r\n\r\n\r\n", "comments": ["The issue comes from the uint16 support of `rot90` (`reverse`). The uint16 and int16 are already available in CPU. Added a PR #12531 to enable the uint16 and int16 support of `reverse`.", "Thank you! I am not sure what to do next now that you added this PR. \r\nWould you please let me know what should I do?", "@aziabari once the PR #12531 is merged your issue will be resolved.", "I am new to Python/TF. Could you please let me know what do you mean by merging PR #12531?\r\nDo I need to update anything or make any changes on my computer?", "@aziabari The necessary code change that is needed to fixed the issue you encountered has been made. In the next release of TensorFlow (I don't know but I would guess 1.4) you can update your local TensorFlow installment and the issue you encountered on you local computer would be gone.\r\n\r\nI am not sure what is the next release date of TensorFlow (1.4) though it may take some time.\r\n\r\nIn the mean time, you can also try building TensorFlow from source: https://www.tensorflow.org/install/install_sources\r\n\r\nThat will allows you to update your local TensorFlow installment without waiting for the official release of 1.4.\r\n", "Thanks!"]}, {"number": 12527, "title": "Optimize non_max_suppression by iterating backwards", "body": "In typical scenarios, high-overlapping boxes are likely to have similar scores.\r\nTherefore if there are any high-overlapping boxes, it's faster to find them starting from boxes that have similar scores.\r\n\r\nThis simple heuristic improves performance of the op on several actual workload by 10%~20%. The workloads are like ~10k boxes produced by a region proposal network.", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please", "Jenkins, test this please", "@ppwwyyxx Thanks for the contribution!"]}, {"number": 12526, "title": "This is regarding the installation of tensorflow in windows.For version 1.3,you have said cuDNN 5.1 for CUDA 8.0 is required.I wasted 2 days trying to overcome the errors but later I found that cuDNN 6 is required for TensorFlow v1.3", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug or a feature request.\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**: \r\n- **Bazel version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["@Murali81 \r\ncudnn 6 is not available in nvidia cudnn archive.. Any links to the setup?", "You can find cuDNN v6 here \ud83d\udc4d \r\nhttps://developer.nvidia.com/rdp/cudnn-download\r\nP.S: You need to signup for the download to start.", "followed the [official](https://www.tensorflow.org/install/install_windows) instuctions..the pip command shows successfully installed tensorflow gpu... But still getting error(**no module named tensorflow**) when i use import tensorflow as tf.\r\n\r\nUsing Anaconda", "Try installing cuDNN v6 and add \"cudnn-8.0-windows10-x64-v6.0\\cuda\\bincudnn64_6.dll\" to PATH in system variables if you are using windows.\r\nThat will solve your problem.", "added already"]}, {"number": 12525, "title": "bug in DataFeeder constructor  ", "body": "\r\n### System information\r\n- centos 7.0\r\n- python 3.4\r\n- tensorflow 1.2.1\r\n\r\n\r\n### Describe the problem\r\nWhen I call tensorflow.contrib.learn.DNNRegressor.fit(x_train_dict , y_train,steps=1000)  , x_train_dict is dict  and y_train is array , the program throws the following exception: \r\n```\r\nFile \"/home/star/yuce.ddxq.mobi/zhuge/management/commands/forecast_product_sale.py\", line 148, in tflearn_dnn_train2\r\n    regressor.fit(x_train_dict, y_train, steps=10000, batch_size=10)\r\n  File \"/usr/lib/python3.4/site-packages/tensorflow/python/util/deprecation.py\", line 289, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/usr/lib/python3.4/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 439, in fit\r\n    SKCompat(self).fit(x, y, batch_size, steps, max_steps, monitors)\r\n  File \"/usr/lib/python3.4/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 1340, in fit\r\n    epochs=None)\r\n  File \"/usr/lib/python3.4/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 137, in _get_input_fn\r\n    epochs=epochs)\r\n  File \"/usr/lib/python3.4/site-packages/tensorflow/contrib/learn/python/learn/learn_io/data_feeder.py\", line 152, in setup_train_data_feeder\r\n    x, y, n_classes, batch_size, shuffle=shuffle, epochs=epochs)\r\n  File \"/usr/lib/python3.4/site-packages/tensorflow/contrib/learn/python/learn/learn_io/data_feeder.py\", line 326, in __init__\r\n    dict([(k, check_array(v, v.dtype)) for k, v in list(y.items())]) if x_is_dict else check_array(y, y.dtype)\r\nAttributeError: 'numpy.ndarray' object has no attribute 'items'\r\n```\r\nand the related code is:  \r\n```\r\n   x_is_dict, y_is_dict = isinstance(x, dict), y is not None and isinstance(\r\n        y, dict)\r\n    if isinstance(y, list):\r\n      y = np.array(y)\r\n\r\n    self._x = dict([(k, check_array(v, v.dtype)) for k, v in list(x.items())\r\n                   ]) if x_is_dict else check_array(x, x.dtype)\r\n    self._y = None if y is None else \\\r\n      dict([(k, check_array(v, v.dtype)) for k, v in list(y.items())]) if x_is_dict else check_array(y, y.dtype)\r\n\r\n```\r\nthe last line of the code seems wrong , it should use the y_is_dict instead of x_is_dict  ? \r\nI change the code to : \r\n```\r\ndict([(k, check_array(v, v.dtype)) for k, v in list(y.items())]) if y_is_dict else check_array(y, y.dtype)\r\n```\r\nand then  it works .\r\n\r\n\r\n", "comments": ["I think the fix is correct. Created a PR #12562", "@jhseu Can you close this when PR #12562 is merged?"]}, {"number": 12524, "title": "nsync is broken on Windows in Bazel build", "body": "http://ci.tensorflow.org/job/tf-master-win-bzl/1459/console\r\n```\r\n11:36:56 ERROR: C:/tmp/_bazel_system/424zmya1/external/nsync/BUILD:357:13: Configurable attribute \"copts\" doesn't match this configuration (would a default condition help?).\r\n11:36:56 Conditions checked:\r\n11:36:56  @nsync//:android_arm\r\n11:36:56  @nsync//:android_arm64\r\n11:36:56  @nsync//:android_armeabi\r\n11:36:56  @nsync//:android_x86_32\r\n11:36:56  @nsync//:android_x86_64\r\n11:36:56  @nsync//:clang_macos_x86_64\r\n11:36:56  @nsync//:gcc_linux_aarch64\r\n11:36:56  @nsync//:gcc_linux_ppc64\r\n11:36:56  @nsync//:gcc_linux_x86_64_1\r\n11:36:56  @nsync//:gcc_linux_x86_64_2\r\n11:36:56  @nsync//:ios_x86_64\r\n11:36:56 ERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted\r\n```\r\n nsync is introduced in b48cfaea2aea3707a33e60c10385a87e37101b95\r\n\r\nFortunately, nsync already builds on Windows with CMake, I've sent a PR to add Bazel support.\r\nhttps://github.com/google/nsync/pull/1\r\n\r\n/cc @m3bm3b Could you please merge the PR, or is there any other way you prefer me to contribute to this repo?\r\n", "comments": ["Replicated this with Bazel 0.5.3 on Windows 10. Couldn't get 0.5.4 to work, otherwise I'd try with that too.", "Please provide details about what platform you are using  (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?  Make sure you also include the exact command if possible to produce  the output included in your test case. If you are unclear what to include  see the issue template displayed in  [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new).\r\n\r\n We ask for this in the issue submission template, because    it is really difficult to help without that information. Thanks!", "@FKNoble This issue has been fixed from nsync repo by https://github.com/google/nsync/commit/d3bc53d38bee13bf66354ca61694956c92ffe879\r\n\r\nWe also have a [PR](https://github.com/tensorflow/tensorflow/pull/12603#issuecomment-325004977) to update nsync in TensorFlow.", "Adding contributions welcome tag while PR is in flight.", "Fixed by https://github.com/tensorflow/tensorflow/pull/12603"]}, {"number": 12523, "title": "[feature request] Need QuantizedFusedBatchNorm ", "body": "There is no QuantizedFusedBatchNorm operator. The graph transform tools treats FusedBatchNorm operator with fold_old_batch_morm. But not all bns are ready to be folded. This will leave many isolated un-quantized fbn ops in the graph.", "comments": ["@petewarden Can you comment on this?", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Assignee @cy89: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @cy89: It has been 15 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @cy89: It has been 257 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @cy89: It has been 273 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @cy89: It has been 288 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @cy89: It has been 303 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @cy89: It has been 318 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @cy89: It has been 333 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @cy89: It has been 348 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "@suharshs could you please take a look, and comment or redirect?", "Hi, quantization efforts have been prioritized for TensorFlow Lite.\r\n\r\nBesides that quantized unfused batch norm can result in accuracy issues that we haven't explored fully yet, especially if the entire model is being run in uint8. That being said we will be releasing more tools to quantize TensorFlow Lite models that should address and avoid this eventually."]}, {"number": 12522, "title": "Stacking CNN with LSTM", "body": "I am trying to stack CNN before LSTM, however, I am experience a little problem. \r\nMy LSTM + CTC works fine. However, I want to pass extracted feature from CNN to LSTM instead of whole image. \r\n\r\nThe code is here: https://gist.github.com/kjanjua26/b756b6aae2277423c1f94b435a82f808\r\n\r\nI error I am facing is: \r\n\r\n`File \"trainer2.py\", line 182, in <module>\r\n    train()\r\n  File \"trainer2.py\", line 75, in train\r\n    logits, inputs, targets, seq_len,W, b = model.get_train_model()\r\n  File \"/home2/kamranjanjua/tf_cnnlstm/tlstm9Aug/model.py\", line 97, in get_train_model\r\n    outputs, _ = tf.nn.bidirectional_dynamic_rnn(forwardH1,backwardH1,x,seq_len,dtype=tf.float32)\r\n  File \"/home/kamranjanjua/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py\", line 652, in bidirectional_dynamic_rnn\r\n    time_major=time_major, scope=fw_scope)\r\n  File \"/home/kamranjanjua/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py\", line 845, in dynamic_rnn\r\n    dtype=dtype)\r\n  File \"/home/kamranjanjua/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py\", line 919, in _dynamic_rnn_loop\r\n    \"Input size (depth of inputs) must be accessible via shape inference,\"\r\nValueError: Input size (depth of inputs) must be accessible via shape inference, but saw value None.`\r\n\r\nAny help in this matter would be appreciated. I am kind of stuck here. \r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Custom code.\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: Source\r\n- **TensorFlow version (use command below)**: 0.12 (Using this on purpose since my older code works in 0.12 and I didn't update it for the new version.\r\n- **Python version**: 2.7\r\n- **GPU model and memory**: TitanX, 12 GB\r\n", "comments": ["I am running into the same issue as well: output of a cnn, reshaped, concatenated and then fed into `tf.nn.bidirectional_dynamic_rnn` as input.", "Have you tried in tf nightly?", "@ebrevdo : Yes, I tried with tf-nightly (1.5.0.dev20171101). Still the same error. I'll post a reduced but self contained snippet just to be sure.", "@amundle-cs thanks!", "I came across this problem sometime ago, I did solve it. The thing is you have to reshape the output of CNN's last layer into time steps so that you can feed it into the LSTM. The CNN output's a 1D tensor at the end, re-shape it to 3D tensor with `nb_timesteps` so that your LSTM takes your features distributed over timesteps as input. ", "@kjanjua26 : The output of the CNN (at least per my architecture is a 3D tensor), gist below\r\n@ebrevdo : Here's the gist: https://gist.github.com/amundle-cs/9dcf32bf8ee53d8e868fbf332f54312d", "@amundle-cs try to print the shape of the last layer, also, if it is 3D tensor, it is still not distributed over time. Re-shape the output of CNN like `(nb_samples, timesteps, nb_features)` and then you feed it to LSTM.\r\nUse tf.squeeze on the output of CNN. \r\n`lastCNN = tf.squeeze(lastCNN,[1])`\r\nThen you can feed this to LSTM in addition to the `sequenceLength` which is set according to the highest sequence in your ground truth. \r\nHave a look: https://github.com/AimeeKing/crnn-tensorflow/blob/master/net/model.py", "@kjanjua26 Thanks for you suggestion. I believe, that the 3D tensor (output of CNN) is being reshaped into [`samples x time x features`](https://gist.github.com/amundle-cs/9dcf32bf8ee53d8e868fbf332f54312d#file-cnn_bilstm-py-L80) Please let me know if you think otherwise.\r\nInstead of using `tf.squeeze(...)`,[ I am applying `tf.reduce_max(...)` to the output of CNN.](https://gist.github.com/amundle-cs/9dcf32bf8ee53d8e868fbf332f54312d#file-cnn_bilstm-py-L71)\r\n\r\nI did try to run my code using `tf.squeeze` instead of `tf.reduce_max` but I am running into the same issue.\r\n\r\n@ebrevdo The [`tf.nn.bidirectional_dynamic_rnn`](https://gist.github.com/amundle-cs/9dcf32bf8ee53d8e868fbf332f54312d#file-cnn_bilstm-py-L88) seems works fine if the [`char_embeddings`](https://gist.github.com/amundle-cs/9dcf32bf8ee53d8e868fbf332f54312d#file-cnn_bilstm-py-L49) shape is a static, instead of using `tf.shape(...)` which is dynamic.\r\n~~After doing some more experiments, I think it is tripping up because it cannot infer the size since [placeholders's shape partially defined](https://gist.github.com/amundle-cs/9dcf32bf8ee53d8e868fbf332f54312d#file-cnn_bilstm-py-L22-L24), which I **have to** for variable sentence and word length.~~ Nah. It still fails if the placeholder's shape if completely specified.", "@ebrevdo Any updates?", "Before you run `dynamic_rnn`, you can manually add static shape information to your inputs, i.e.\r\n\r\n`inputs.set_shape([None, None, input_depth])`\r\n\r\nwhere input_depth is a python int; and the first two dimensions are the unknown time & batch dimensions.  If you have those, add them in as well.", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Hi, I am facing the same problem with `bidirectional_dynamic_rnn` layers in tensorflow. I am trying to feed output from a convolution layer, converted from 4D to 3D with variable length sequences to a bidirectional LSTM and am getting the below mentioned error.\r\n\r\n`\"Input size (depth of inputs) must be accessible via shape inference,\"`\r\n`ValueError: Input size (depth of inputs) must be accessible via shape inference, but saw value None.`\r\n\r\nHave tried everything that I can think of aside from extensive googling. Is there any update here ?\r\n\r\n@amundle-cs : Were you able to solve this ? Do let me know. TIA.\r\n@kjanjua26 : Thoughts ?"]}, {"number": 12521, "title": "Install instructions should ask for libcudnn 6.0", "body": "\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nNo\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nUbuntu 17.04\r\n- **TensorFlow installed from (source or binary)**:\r\nbinary (pip3)\r\n- **TensorFlow version (use command below)**:\r\nv1.3.0-rc2-20-g0787eee 1.3.0\r\n- **Python version**: \r\nPython 3.5.3\r\n- **Bazel version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n6.0\r\n- **GPU model and memory**:\r\nGTX 1080 8GB\r\n- **Exact command to reproduce**:\r\nNA\r\n\r\n### Describe the problem\r\nThe install instructions at https://www.tensorflow.org/install/install_linux tell users to install libcudnn 5.1. \r\nI followed these and ended up with the error on \r\n\r\n    import tensorflow\r\n\r\n    ImportError: libcudnn.so.6: cannot open shared object file: No such file or directory\r\n\r\nSo I installed libcudnn 6.0 instead and tensorflow is now working. \r\nMy request is for the install instructions to be updated to reflect the move to cudnn 6.0\r\n\r\n### Source code / logs\r\nNA", "comments": ["See #12416 and  PR #12463.", "Similar issue for Windows users here #11784 ", "@frehoy I believe this got fixed alongside #11784 ", "Yeah, this is definitely fixed and you can even see it in the docs_src directory here on Github:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/docs_src/install/install_linux.md\r\n\r\nBut it sometimes takes a while for these things to propagate to the root directory on tensorflow.org as we usually only update that with version releases.", "@frehoy  hello, i have a question. thank help me fix it. \r\n![qq 20170830183806](https://user-images.githubusercontent.com/13164077/29868736-b82eafae-8db2-11e7-976f-2e6247b351b6.png)\r\n i have installed  cuDNN v6.0. CUDA Version:8.0, Nvidia driver is newest.\r\nthank you before\r\n", "updating to cuDNN v6 for cuda 8 solved my problem"]}]