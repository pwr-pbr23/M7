[{"number": 2262, "title": "tensors_flowing.gif", "body": "who knows how to make this gif? https://www.tensorflow.org/images/tensors_flowing.gif\n", "comments": ["@colah did you make this one?\n", "From previous discussions, I believe this was manually created with After Effects, so there isn't an easy way to do something similar without using motion graphics tools.\n", "I've made great animations using Keynote. This one would actually be pretty easy, just tedious.\n", "Or D3 with an SVG/JS ninja  :smile: http://bl.ocks.org/nitaku/6354551\n", "http://bl.ocks.org/mbostock/5649592\n", "/cc @mbostock What D3 [Dan](https://en.wikipedia.org/wiki/Dan_%28rank%29) do you think it is required to produce this animation?\n", "Closing, since this is a question not an issue.\n", "Is it possible to train GIF and TIFF images in tensor-flow image classification? "]}, {"number": 2261, "title": "Add complex128 support", "body": "Added complex128 support, based on the guidance from @girving and others in PR #2244. All (python) tests passed.\n\nComplex128 support is not added for  `*FFT*` ops with input: complex64 and output: complex64.\n", "comments": ["Can one of the admins verify this patch?\n"]}, {"number": 2260, "title": "tensorflow can't support float64 type when reading from csv data?", "body": "I just follow the  examples,and tried to read csv data with float types\n\nfilename_queue = tf.train.string_input_producer([\"test1.csv\"])\n\nreader = tf.TextLineReader()\nkey, value = reader.read(filename_queue)\n\nrecord_defaults = [[1], [1.0], [1.0], [1.0], [1.0]]\ncol1,col2,col3,col4, col5 = tf.decode_csv(\n    value, record_defaults=record_defaults)\nfeatures = tf.pack([col1, col2, col3, col4])\n\nwith tf.Session() as sess:\n  #print sess.run(value)\n  # Start populating the filename queue.\n  coord = tf.train.Coordinator()\n  threads = tf.train.start_queue_runners(coord=coord)\n  print key,value\n  for i in range(1200):\n    # Retrieve a single instance:\n    example, label = sess.run([features, col5])\n\n  coord.request_stop()\n  coord.join(threads)\n~ \nBut it need to read data into memory first.Because the csv file it too big to read into memory.Can it possbile read with shuffle and minibatch and then training?\n", "comments": ["Sorry you're hitting problems! I'm a bit confused though - the title indicates a problem reading float64 values, but the text talks about hitting memory usage problems.\n\nDo you have an example of the error message you're hitting? That might help.\n", "You can checkout some examples in skflow using dask if it doesn't fit in memory.  You can also use pandas to load csv files. \n", "Closing this issue due to inactivity. If you revisit it, @liumilan, I think this might be a better question for Stack Overflow....\n"]}, {"number": 2259, "title": "Branch 121719728", "body": "Merge internal changes\n", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for the commit author(s).  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\n\n<!-- need_author_cla -->\n", "@tensorflow-jenkins test this please\n", "@caisq, @vrv, @martinwicke, do we need the \"cla/google\" for this merge? \n", "@zheng-xq My understanding is that cla is usually not in a good state for pushes PRs like this because not every internal author has registered on GH. @vrv and @martinwicke have the permissions to merge without cla being satisfied in this case.\n", "Adding @martinwicke to merge the pull request, given the cla issue. \n"]}, {"number": 2258, "title": "Fixes for protobuf changes", "body": "", "comments": ["@petewarden do I retry testing?  what is this fixing?\n", "This has been superseded by https://github.com/google/protobuf/pull/1586, so closing this PR.\n"]}, {"number": 2257, "title": "Update os_setup.md", "body": "From PR#2095, I've checked command to Installing from sources on OS X.\n\nTo set up the TensorFlow form source on OS X, pip installation need root permission. \n\n> sudo pip install /tmp/tensorflow_pkg/tensorflow-0.8.0-py2-none-any.whl\n", "comments": ["Can one of the admins verify this patch?\n", "Test this please, Jenkins.\n", "I'm still not happy about just blanket adding sudo. We already have a sentence there saying the command (whl file name) may depend on the platform. I suggest we add there that \"on some platforms (some versions of MacOS in particular), you may have to use sudo\", without actually putting that into the code.\n\nIf you add sudo on a linux machine, it will actually mess with your pip install and prevent updates without sudo and all kinds of other nasty stuff. \n", "Never mind. I got confused where in the doc this was. Sorry about that.\n"]}, {"number": 2256, "title": "missing build_pip_package runfiles tensorflow external", "body": "-bash-4.1$ bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg\nFri May 6 18:41:53 UTC 2016 : === Using tmpdir: /tmp/tmp.HLtyx30grJ\ncp: cannot stat `bazel-bin/tensorflow/tools/pip_package/build_pip_package.runfiles/tensorflow': No such file or directory\ncp: cannot stat`bazel-bin/tensorflow/tools/pip_package/build_pip_package.runfiles/external': No such file or directory\n### Environment info\n\nOperating System:\n\nredhat-release-server-6Server-6.7.0.3.el6.x86_64\nepel-release-6-8.noarch\nscl python27 devtoolset-2 enable\nnumpy 1.11.0\n\nInstalled version of CUDA and cuDNN: \n\nNo CUDA -- configured without GPU\n\nIf installed from sources, provide the commit hash:\n\nf8eb1d70a7ea7dc2cd5e1eddde389395f88a6be9\n### Steps to reproduce\n\ngit clone https://github.com/bazelbuild/bazel.git\ncd bazel/\n./compile.sh\n\n--git 1.7.1\ngit clone --recursive https://github.com/tensorflow/tensorflow\nbazel build -c opt //tensorflow/tools/pip_package:build_pip_package\nbazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg\n### What have you tried?\n1. With previously installed protobuf from source 3.0.0b2- thought that was the problem so\n2. Tried on another box with no previously installed protobuf\n### Logs or other output that would be helpful\n\n(If logs are large, please upload as attachment).\n\nWARNING: Sandboxed execution is not supported on your system and thus hermeticity of actions cannot be guaranteed. See http://bazel.io/docs/bazel-user-manual.html#sandboxing for more information. You can turn off this warning via --ignore_unsupported_sandboxing.\nWARNING: /home/ebice/.cache/bazel/_bazel_ebice/e10106cd0aa7dd3e05f3af5f70558af6/external/grpc/WORKSPACE:1: Workspace name in /home/ebice/.cache/bazel/_bazel_ebice/e10106cd0aa7dd3e05f3af5f70558af6/external/grpc/WORKSPACE (@__main__) does not match the name given in the repository's definition (@grpc); this will cause a build error in future versions.\nWARNING: /home/ebice/.cache/bazel/_bazel_ebice/e10106cd0aa7dd3e05f3af5f70558af6/external/re2/WORKSPACE:1: Workspace name in /home/ebice/.cache/bazel/_bazel_ebice/e10106cd0aa7dd3e05f3af5f70558af6/external/re2/WORKSPACE (@__main__) does not match the name given in the repository's definition (@re2); this will cause a build error in future versions.\nINFO: Loading complete.  Analyzing...\n", "comments": ["I'm having the same issue, performing the same steps as above.\n\n## Environment Info\n\nRed Hat Enterprise Linux Server release 6.6 (Santiago)\nPython 3.5\n\nNo CUDA\n\nIf installed from sources, provide the commit hash:\n\n85f494e7e2354dd674a7831deb38cc9c1acdee1a\n\n## What have you tried\n\nDifferent GCC compilers, different versions of Bazel.\n", "Looks like the bazel is too new.\nMissing directories are now placed in `.runfiles/__main__/` instead of `.runfiles/`.\n\nhttps://github.com/bazelbuild/bazel/wiki/Updating-the-runfiles-tree-structure\nbazelbuild/bazel@857cda2\n", "Which versions of bazel are you using? \n", "I used 2.2b, this is the top one which is present in the release page https://github.com/bazelbuild/bazel/releases which is linked to from the setup instructions: https://www.tensorflow.org/versions/r0.8/get_started/os_setup.html#installation-for-linux\n\nWhat is the recommended version?\n", "Ah sorry, actually I was using HEAD of master of the basel github repository. I had to build it from source.\n", "I hope that 2.2 would work. We'll have to make changes to make 2.3 work\nwhen it comes out.\nOn Sun, May 8, 2016 at 13:53 Valentine Svensson notifications@github.com\nwrote:\n\n> Ah sorry, actually I was using HEAD of master of the basel github\n> repository. I had to build it from source.\n> \n> \u2014\n> You are receiving this because you were assigned.\n> Reply to this email directly or view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/2256#issuecomment-217745439\n", "I rolled back to 0.2.2 by `git checkout 759bbfe` in the bazel repository, then rebuilt. After this I could successfully build tenssorflow!\n", "Thanks, it's good to know we'll have to fix TensorFlow for the next bazel\nrelease.\nOn Sun, May 8, 2016 at 14:23 Valentine Svensson notifications@github.com\nwrote:\n\n> I rolled back to 0.2.2 by git checkout 759bbfe in the bazel repository,\n> then rebuilt. After this I could successfully build tenssorflow!\n> \n> \u2014\n> You are receiving this because you were assigned.\n> Reply to this email directly or view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/2256#issuecomment-217746981\n", "I rolled back to 0.2.2 - thanks @vals - but ran into a different issue\n\nERROR: /home/ebice/.cache/bazel/_bazel_ebice/87c284e4831886db3eb74a03d0a82dcb/external/grpc/BUILD:1597:1: Linking of rule '@grpc//:grpc_cpp_plugin' failed: gcc failed: error executing command /opt/rh/devtoolset-2/root/usr/bin/gcc -o bazel-out/host/bin/external/grpc/grpc_cpp_plugin -no-canonical-prefixes -B/opt/rh/devtoolset-2/root/usr/bin -pass-exit-codes '-Wl,--build-id=md5' ... (remaining 12 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\n/opt/rh/devtoolset-2/root/usr/bin/ld: /opt/rh/devtoolset-2/root/usr/lib/gcc/x86_64-redhat-linux/4.8.2/libstdc++_nonshared.a(hashtable_c++0x44.o): undefined reference to symbol 'ceil@@GLIBC_2.2.5'\n/opt/rh/devtoolset-2/root/usr/bin/ld: note: 'ceil@@GLIBC_2.2.5' is defined in DSO /lib64/libm.so.6 so try adding it to the linker command line\n/lib64/libm.so.6: could not read symbols: Invalid operation\ncollect2: error: ld returned 1 exit status\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\n", "Seems the above is a known Bazel CentOS issue [https://github.com/bazelbuild/bazel/issues/1190](url). Will close this issue and chase this elsewhere.\n"]}, {"number": 2255, "title": "Calculating Gradients Through tf.complex64 Numbers", "body": "Hey TF,\n\nIts very nice that you support so many complex number calculations like `tf.complex_abs` and `fft`. I am trying replicate this [Associative LSTM paper ](http://arxiv.org/abs/1602.03032)where complex numbers are needed. \n\nHowever, when I try to calculate the gradient using `tf.gradient`, I get the traceback below. Is it not possible to calculate the gradient if complex numbers are used with type `tf.complex64`? If not, this would be an incredibly useful feature as there are several new RNN papers that require complex numbers to be used. \n\nI am initializing a `tf.complex64` dtype weight matrix as follows:\n\n``` python\n      if complex_weights: \n        a = tf.truncated_normal([total_arg_size, output_size], stddev=0.1)\n        weight_matrix = tf.Variable(tf.complex(a,a), name=\"Complex_Weight\")\n```\n\nPerhaps I'm missing something or not writing the code properly. I have TF 0.8 installed. \n\n`````` python\n    gradients = tf.gradients(self.average_mean_loss, params)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients.py\", line 481, in gradients\n    in_grads = _AsList(grad_fn(op, *out_grads))\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_grad.py\", line 414, in _DivGrad\n    return (array_ops.reshape(math_ops.reduce_sum(grad / y, rx), sx),\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py\", line 526, in r_binary_op_wrapper\n    x = ops.convert_to_tensor(x, dtype=y.dtype.base_dtype, name=\"x\")\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 566, in convert_to_tensor\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients.py\", line 94, in _IndexedSlicesToTensor\n    name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 1759, in unsorted_segment_sum\n    num_segments=num_segments, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py\", line 486, in apply_op\n    _Attr(op_def, input_arg.type_attr))\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py\", line 59, in _SatisfiesTypeConstraint\n    \", \".join(dtypes.as_dtype(x).name for x in allowed_list)))\nTypeError: DataType complex64 for attr 'T' not in list of allowed values: float32, float64, int32, int64, uint8, int16, int8, uint16```\n\n``````\n", "comments": ["Re-assigning this to @yuanbyu, who knows the current gradients code best, and would be able to estimate the changes needed. (I suspect that this would require a considerable amount of work to update the existing gradient functions, which may have latent assumptions about expecting `tf.float32` or `tf.float64` values.)\n", "Thanks @mrry \n\nHere's the full situation. TensorFlow has operations such as batch_ifft which only accept complex64 numbers. To implement papers like unitary RNN's http://arxiv.org/abs/1511.06464, we need these transforms. \n\nWe also need to operate in the complex domain. Now you can simulate imaginary numbers with float32 numbers, but still -- we can't use FFT's which is a critical piece. \n\nThere are many other networks that use complex numbers like Associative LSTMs which could receive significant speed boosts if complex64 could be backproped. Thanks!\n", "Hi, I'm a bit surprised about this issue, as it seems that calculating gradients for expressions involving `complex64` seems to work, even if `tf.fft` is involved.\nMaybe it's a specific op that hasn't been extended to `complex64` yet that's causing the problem?\n\n``` python\nimport tensorflow as tf\nx = tf.linspace(0., 1., 10)\nz = tf.complex(x, x)\nexpr = tf.reduce_sum(tf.complex_abs(tf.fft(z)))\nprint(s.run(tf.gradients(expr, x)))\n```\n\n```\n[array([ -7.51478004e+00,  -1.36133647e+00,   1.19209290e-07,\n         6.93636179e-01,   1.19022393e+00,   1.63820338e+00,\n         2.13479161e+00,   2.82842731e+00,   4.18976402e+00,\n         1.03432074e+01], dtype=float32)]\n```\n\n**edit:** Ah, I was using the GPU here. Maybe the problem is only with the CPU ops (e.g. there's currently no fft kernel)?\n", "I have been using a gpu as well but I do run other operations like `tf.embedding_lookup` which do require cpu operations. I was very careful to check that all calculations I do accept `complex64` and this error only happens upon compilation.\n\nI use float32 for the majority of operations, but i use complex64 within the RNN and then convert the output back to float32. This would be a critical issue for RNN's that use imaginary numbers as described above. \n", "I'm trying to implement unitary RNN and I have exactly the same issue. It appears TF can't calculate complex gradient through transpose op. But otherwise complex gradient works well.\n\n```\n    out_ = vec_in * diag0\n    refl0 = normalize_c(refl0)\n    refl1 = normalize_c(refl1)\n    out_ = refl_c(math_ops.batch_fft(out_)*fft_scale,refl0)\n    out_ = diag1 * tf.transpose(tf.gather(tf.transpose(out_), perm0))\n    #above line works if changed to out_=diag1 * out_\n    out_ = diag2 * refl_c(math_ops.batch_ifft(out_)*fft_scale, refl1)\n```\n\nError message:\n\n```\nFile \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/gradients.py\", line 481, in gradients\n    in_grads = _AsList(grad_fn(op, *out_grads))\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/array_grad.py\", line 260, in _TransposeGrad\n    return [array_ops.transpose(grad, array_ops.invert_permutation(p)), None]\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/array_ops.py\", line 694, in transpose\n    ret = gen_array_ops.transpose(a, perm, name=name)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 1905, in transpose\n    result = _op_def_lib.apply_op(\"Transpose\", x=x, perm=perm, name=name)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/op_def_library.py\", line 455, in apply_op\n    as_ref=input_arg.is_ref)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/ops.py\", line 620, in convert_to_tensor\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/gradients.py\", line 94, in _IndexedSlicesToTensor\n    name=name)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 2147, in unsorted_segment_sum\n    num_segments=num_segments, name=name)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/op_def_library.py\", line 530, in apply_op\n    _Attr(op_def, input_arg.type_attr))\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/op_def_library.py\", line 61, in _SatisfiesTypeConstraint\n    \", \".join(dtypes.as_dtype(x).name for x in allowed_list)))\nTypeError: DataType complex64 for attr 'T' not in list of allowed values: float32, float64, int32, int64, uint8, int16, int8, uint16, float16\n```\n", "Looks like the problem is that `tf.unsorted_segment_sum` is only enabled for real number types.\nSeeing as `tf.reduce_sum` does work for complex numbers, I would say that `tf.unsorted_segment_sum` (and `_prod`) should also be enabled for consistency.\n", "I've submitted a PR that enables complex numbers for the segment reduction ops.\nIf this gets merged, @khaotik and @LeavesBreathe should have another look at whether their model runs using the current `master`.\n", "@khaotik and @LeavesBreathe: The PR has been merged. It would be great if you could test your model with the latest `master`.\n", "@ibab thanks for the update. I was using the transpose op as well, so this is probably what was causing the issue. I'm in the middle of testing other architectures right now, but when I get a chance, i will test the Unitary RNN  and Associative LSTM and post back. I will build from the current master. \n", "@ibab thanks for your pull as it did resolve the `tf.transpose` issue that was occuring. However, a new issue has arisen. When I `optimizer.apply_gradients()`, I get the following error message:\n\ngradient code:\n\n``` python\n         params = tf.trainable_variables()\n          gradients = tf.gradients(self.losses[b], params) #aggregation_method = 2\n          for i, grad in enumerate(gradients):\n            if grad is not None and grad.dtype.name != 'complex64':\n              gradients[i] = tf.clip_by_norm(grad, max_gradient_norm)\n\n\n        self.gradient_norms.append(norm)\n        self.updates.append(opt.apply_gradients(\n            zip(gradients, params), global_step=self.global_step))\n```\n\n``` python\nTraceback (most recent call last):\n  File \"train_seq2seq.py\", line 778, in <module>\n    tf.app.run()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 30, in run\n    sys.exit(main(sys.argv))\n  File \"train_seq2seq.py\", line 775, in main\n    train()\n  File \"train_seq2seq.py\", line 393, in train\n    model = create_model(sess, False)\n  File \"train_seq2seq.py\", line 328, in create_model\n    description_text = description_text)\n  File \"/home/nick/Project_RNN_Enhancement/rnn_enhancement/seq2seq_model_enhanced.py\", line 305, in __init__\n    zip(gradients, params), global_step=self.global_step))\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py\", line 291, in apply_gradients\n    self._assert_valid_dtypes([g, v])\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py\", line 365, in _assert_valid_dtypes\n    dtype, t.name, [v for v in valid_dtypes]))\nValueError: Invalid type tf.complex64 for gradients/model_with_buckets/embedding_attention_seq2seq/RNN/MultiRNNCell/Cell0/AssociativeBasicLSTMCell/gate_multiplication/Enhanced_Linear/MatMul_grad/MatMul_1:0, expected: [tf.float32, tf.float64, tf.float16].\n```\n\nBasically, there are both complex64 and float32 trainable variables that I have in the `seq2seq.py` which is based upon tensorflow's `seq2seq.py`. These trainable variables enter the params argument in `apply_gradients`.\n\nIs there a problem when you use trainable variables of both `float32` and `complex64` types? I really appreciate your help. I'm running rc version 0.9. \n", "~~That's strange, as MatMul has support for `complex64`, although only on the CPU.\nMaybe you are somehow forcing the op to execute on the GPU?\nCurrently complex support is a bit poor for GPU ops, as discussed in this issue: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/matmul_op.cc#L219~~\n\n**Edit:** Sorry, I totally misread the backtrace (need more :coffee:).\nThe `MatMul` is actually the input and it's the optimization framework that's complaining about its dtype.\nI'm not sure whether it makes sense to run an optimization with complex parameters or a complex loss function.\nIt would probably make sense to parameterize your complex variables in terms of real variables, as in\n\n``` python\nx = tf.Variable(1.)\ny = tf.Variable(1.)\nz = tf.complex(x, y)\n```\n\nand then optimize in terms of `x` and `y`, and to make sure that the loss function and its gradients are real as well.\n", "Thanks again @ibab -- can't believe I didn't think of that. I'll try that out and get back to you with results. \n", "Reporting back to @ibab  -- I tried `tf.complex(var,var)` and unfortunately it produced the same error as above. I looked at your crossed out message and I am running this on a titan x -- so this could be the problem. Here's my weight matrix code:\n\n``` python\n  with tf.variable_scope(scope or \"Enhanced_Linear\"):\n  #this will make a class for these variables so you can reference them in the future. \n\n    '''initialize weight matrix properly'''\n    if weight_initializer == \"uniform_unit\":\n      matrix = tf.get_variable(\"Uniform_Matrix\", [total_arg_size, output_size], initializer = tf.uniform_unit_scaling_initializer()) \n    elif weight_initializer == \"truncated\" or weight_initializer == \"truncated_uniform\":\n      if complex_weights: \n        real_w = tf.Variable(tf.truncated_normal([total_arg_size, output_size], stddev=0.1), name = \"complex_weight_real\")\n        imag_w = tf.Variable(tf.truncated_normal([total_arg_size, output_size], stddev=0.1), name = \"complex_weight_imag\")\n        matrix = tf.complex(real_w, imag_w)\n```\n", "My guess is that the problem is caused by some of the gradients being complex.\nIf you post your loss function, I might be able to help.\nAlternatively, you could post this to StackOverflow, as people there are usually very quick at responding to tensorflow questions (and it might be more appropriate, as I suspect that this isn't a bug in tensorflow).\n", "@ibab, the loss function is the seq2seq sequence loss function from tensorflow ops:\n\n``` python\ndef sequence_loss_by_example(logits, targets, weights,\n                             average_across_timesteps=True,\n                             softmax_loss_function=None, name=None):\n  \"\"\"Weighted cross-entropy loss for a sequence of logits (per example).\n  Args:\n    logits: List of 2D Tensors of shape [batch_size x num_decoder_symbols].\n    targets: List of 1D batch-sized int32 Tensors of the same length as logits.\n    weights: List of 1D batch-sized float-Tensors of the same length as logits.\n    average_across_timesteps: If set, divide the returned cost by the total\n      label weight.\n    softmax_loss_function: Function (inputs-batch, labels-batch) -> loss-batch\n      to be used instead of the standard softmax (the default if this is None).\n    name: Optional name for this operation, default: \"sequence_loss_by_example\".\n  Returns:\n    1D batch-sized float Tensor: The log-perplexity for each sequence.\n  Raises:\n    ValueError: If len(logits) is different from len(targets) or len(weights).\n  \"\"\"\n  if len(targets) != len(logits) or len(weights) != len(logits):\n    raise ValueError(\"Lengths of logits, weights, and targets must be the same \"\n                     \"%d, %d, %d.\" % (len(logits), len(weights), len(targets)))\n  with ops.op_scope(logits + targets + weights, name,\n                    \"sequence_loss_by_example\"):\n    log_perp_list = []\n    for logit, target, weight in zip(logits, targets, weights):\n      if softmax_loss_function is None:\n        # TODO(irving,ebrevdo): This reshape is needed because\n        # sequence_loss_by_example is called with scalars sometimes, which\n        # violates our general scalar strictness policy.\n        target = array_ops.reshape(target, [-1])\n        crossent = nn_ops.sparse_softmax_cross_entropy_with_logits(\n            logit, target)\n      else:\n        crossent = softmax_loss_function(logit, target)\n      log_perp_list.append(crossent * weight)\n    log_perps = math_ops.add_n(log_perp_list)\n    if average_across_timesteps:\n      total_size = math_ops.add_n(weights)\n      total_size += 1e-12  # Just to avoid division by 0 for all-0 weights.\n      log_perps /= total_size\n  return log_perps\n\n\ndef sequence_loss(logits, targets, weights,\n                  average_across_timesteps=True, average_across_batch=True,\n                  softmax_loss_function=None, name=None):\n  \"\"\"Weighted cross-entropy loss for a sequence of logits, batch-collapsed.\n  Args:\n    logits: List of 2D Tensors of shape [batch_size x num_decoder_symbols].\n    targets: List of 1D batch-sized int32 Tensors of the same length as logits.\n    weights: List of 1D batch-sized float-Tensors of the same length as logits.\n    average_across_timesteps: If set, divide the returned cost by the total\n      label weight.\n    average_across_batch: If set, divide the returned cost by the batch size.\n    softmax_loss_function: Function (inputs-batch, labels-batch) -> loss-batch\n      to be used instead of the standard softmax (the default if this is None).\n    name: Optional name for this operation, defaults to \"sequence_loss\".\n  Returns:\n    A scalar float Tensor: The average log-perplexity per symbol (weighted).\n  Raises:\n    ValueError: If len(logits) is different from len(targets) or len(weights).\n  \"\"\"\n  with ops.op_scope(logits + targets + weights, name, \"sequence_loss\"):\n    cost = math_ops.reduce_sum(sequence_loss_by_example(\n        logits, targets, weights,\n        average_across_timesteps=average_across_timesteps,\n        softmax_loss_function=softmax_loss_function))\n    if average_across_batch:\n      batch_size = array_ops.shape(targets[0])[0]\n      return cost / math_ops.cast(batch_size, dtypes.float32)\n    else:\n      return cost\n\n```\n\nI can post on this on Overflow, but I do believe it is a bug. I think inherently some of the gradients are complex because i'm doing several complex computations for the associative LSTM (and likewise would be doing the same for the unitary RNN). \n\nAssociative LSTM paper\nhttps://arxiv.org/abs/1602.03032\n\nHere is an example of part of the cell:\n\n``` python\n        '''in_gate, out_gate, forget_gate have dim/2 each'''\n        with tf.variable_scope(\"gate_multiplication\"):\n          concat = lfe.enhanced_linear([inputs, prev_state], int(1.5 * self._num_units), True, weight_initializer = self._weight_initializer, complex_weights = True)\n          in_gate, out_gate, forget_gate = tf.split(1, 3, concat)\n          in_gate, out_gate, forget_gate = tf.sigmoid(in_gate), tf.sigmoid(out_gate), tf.sigmoid(forget_gate + self._forget_bias)\n\n        with tf.variable_scope(\"key_multiplication\"):\n          #in_key, out_key, and u are double the size -- 3 units\n          concat = lfe.enhanced_linear([inputs, prev_state], int(1.5 * self._num_units), True, weight_initializer = self._weight_initializer, complex_weights = True)\n          in_key, out_key, u = tf.split(1, 3, concat)\n          in_key, out_key, u = self.bound(in_key), self.bound(out_key), self.bound(u) #dimension might need to be higher here\n\n        #B = Batch size F = dimension size\n        # B x F --> C x B x F\n        in_keys = self.permute(in_key)\n        # B x F --> C x B x F\n        out_keys = self.permute(out_key)\n\n        '''equation 27 -- forming next_cells'''\n        f_x_c = tf.expand_dims(forget_gate,0) * c #takes on shape of c\n        print('u\\n', u)\n        print('in_gate\\n',in_gate)\n        i_x_u = tf.expand_dims(in_gate * u,0) \n        next_cells = f_x_c + self.complex_mult(in_keys, i_x_u)\n```\n\nI guess my question is: are complex gradients possible? And if not, can these be implemented in soon? There are many applications that complex gradients would immensely benefit from. Currently non-complex versions take far longer to run in tensorflow and its very inefficient. \n\nWhen I look at the list of gradients, some of them are complex64 dtypes. This is despite making the actual trainable variables both real. \n", "Note that the gradient of a complex expression can be complex, even if the variables that you take the derivative with respect to are real.\nFor example, the derivative of `(1 + 1j * x)` with regard to `x` is `1j`, even if `x` is a real parameter.\nThat means you have to explicitly make sure that all expressions that you differentiate are real.\nUnfortunately, the associative LSTM paper doesn't seem to explain how they've taken this into account Maybe I have to read it more carefully.\n\nThat said, I just tried running the following code:\n\n```\nimport tensorflow as tf\n\ns = tf.Session()\nx = tf.placeholder(tf.float32)\nz1 = tf.complex(0., x)\n\nprint(s.run(tf.gradients(z, [x]), feed_dict={x: 1}))\n```\n\nand it prints out `[0.]`, which seems wrong to me (I expected `[0 + 1j]`).\nMy guess is that the gradient code only returns the real part of a complex gradient, if the variable that we differentiate by is real. I'll open a bug report on this.\n", "Thanks @ibab -- the Associative LSTM paper was done in Theano and their code is here. They do not use any complex variables, but rather simulate it with real ones. This can be done in tensorflow as well, but for unitary RNN's this can not be done since the `ifft` args require complex inputs.\n\nhttps://github.com/mohammadpz/Associative_LSTM\n\nBasically the main issue with using non-complex variables is that the implementation is much slower. If complex gradients could be handled, this would be a major advantage for tensorflow, and would open many doors.  \n", "@LeavesBreathe In my TF unitary RNN implementation, I had real and complex parameters, and my cost function was real. It seems working well. However I'm not sure if the above \"cast away imag part gradient\" runtime issue occurred in my implementation.\n\n``` python\nfrom math import sqrt\n\nimport numpy as np\n\nimport tensorflow as tf\nfrom tensorflow.python.ops import variable_scope as vs\nfrom tensorflow.python.ops import array_ops\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow.python.ops import nn_ops\n\nrnn_cell = tf.nn.rnn_cell\nseq2seq = tf.nn.seq2seq\n\ndef complex_mul_real( c, r ):\n    return tf.complex(tf.real(c)*r, tf.imag(c)*r)\n\n\ndef refl_c(in_, normal_):\n    normal_rk2 = tf.expand_dims( normal_, 1 )\n    scale = 2*tf.matmul( in_, tf.conj( normal_rk2 ) )\n    return in_ - tf.matmul(scale, tf.transpose(normal_rk2))\n\n\ndef complex_abs_sq(z):\n    return tf.real(z)*tf.real(z) + tf.imag(z)*tf.imag(z)\n\n\ndef normalize_c(in_):\n    norm = tf.sqrt(tf.reduce_sum(complex_abs_sq(in_)))\n    scale = 1./(norm + 1e-5)\n    return complex_mul_real( in_, scale )\n\n\ndef get_complex_variable( name, scope, shape ):\n    re, im = vs.get_variable(name+'_re', shape=shape), vs.get_variable(name+'_im', shape=shape)\n    return tf.complex(re,im, name=name)\n\n\n'''multiply complex vector by parameterized unitary matrix'''\ndef ulinear(vec_in, out_size, scope=None):\n    shape = vec_in.get_shape().as_list()\n    if len(shape) != 2:\n        raise ValueError( 'argument vec_in must be a batch of vectors (2D tensor)' )\n    in_size = shape[1]\n    fft_scale = 1./sqrt(out_size)\n    with vs.variable_scope(scope or 'ULinear') as _s:\n        diag0 = get_complex_variable('diag0', _s, shape=[out_size])\n        diag1 = get_complex_variable('diag1', _s, shape=[out_size])\n        diag2 = get_complex_variable('diag2', _s, shape=[out_size])\n        refl0 = get_complex_variable('refl0', _s, shape=[out_size])\n        refl1 = get_complex_variable('refl1', _s, shape=[out_size])\n        perm0 = tf.constant(np.random.permutation(out_size), name='perm0',dtype='int32')\n        out_ = vec_in * diag0\n        refl0 = normalize_c(refl0)\n        refl1 = normalize_c(refl1)\n        out_ = refl_c(math_ops.batch_fft(out_)*fft_scale,refl0)\n        #out_ = math_ops.batch_fft(out_)*fft_scale\n        out_ = diag1 * tf.transpose(tf.gather(tf.transpose(out_), perm0))\n        #out_ = diag1 * out_\n        out_ = diag2 * refl_c(math_ops.batch_ifft(out_)*fft_scale, refl1)\n        #out_ = diag2 * math_ops.batch_ifft(out_)*fft_scale\n        return out_\n\n\ndef modReLU(in_c, bias, scope=None):\n    with vs.variable_scope(scope or \"ULinear\"):\n        n = tf.complex_abs(in_c)\n        scale = 1./(n+1e-5)\n    return complex_mul_real(in_c, ( nn_ops.relu(n+bias)*scale ))\n\n\ndef abssigm(in_c, scope=None):\n    with vs.variable_scope(scope or 'ULinear'):\n        re,im = tf.real(in_c), tf.imag(in_c)\n        scale = 1./tf.sqrt(re*re + im*im + 1.)\n    return complex_mul_real(in_c,scale)\n\n\nclass URNNCell(rnn_cell.RNNCell):\n    def __init__(self, num_units, input_size=None):\n        self._num_units = num_units\n        self._input_size = num_units if input_size==None else input_size\n\n    @property\n    def input_size(self):\n        return self._input_size\n\n    @property\n    def output_size(self):\n        return self._num_units\n\n    @property\n    def state_size(self):\n        return self._num_units\n\n    def __call__(self, inputs, state, scope=None ):\n        with vs.variable_scope(scope or type(self).__name__):\n            mat_in = vs.get_variable('mat_in', [self.input_size, self.state_size*2])\n            mat_out = vs.get_variable('mat_out', [self.state_size*2, self.output_size])\n            in_proj = math_ops.matmul(inputs, mat_in)\n            in_proj_c = tf.complex( in_proj[:, :self.state_size], in_proj[:, self.state_size:] )\n            out_state = modReLU( in_proj_c + \n                ulinear(state, self.state_size),\n                vs.get_variable(name='bias', dtype=tf.float32, shape=[self.state_size]),\n                scope=scope)\n            '''\n            out_state = abssigm( in_proj_c +\n                                ulinear(state, self.state_size),\n                                scope=scope )\n            '''\n            out_ = math_ops.matmul( array_ops.concat(1,[tf.real(out_state), tf.imag(out_state)] ), mat_out)\n        return out_, out_state\n```\n", "@khaotik thanks for sharing your unitary code. I have a similar script for unitary. I think as the implementation stands right now, the gradient you're processing from your Unitary Cell is not correct as @ibab illustrated with his newly raised issue. Hopefully this will be resolved in a later build.\n\n---\n\nCompletely on the side (and we can start a separate thread for this) but I do have some questions about your unitary implementation. \n1. Why do you multiply 3 separate times by `fft_scale` -- in the original paper this is not called for.\n2. Your `diag` variables do not appear to be diagonal, but rather normal complex matrices. \n3. In your `modrelu` function you multiply by `in_c`. From my impression, the paper simply uses as `modrelu` as an activation function and do not multiply the output by `in_c`. \n", "The issue with casting away the imaginary part of the gradient shouldn't affect either of you.\nIt only seems to affect the final result that's returned by `tf.gradients`, not any of the intermediate computations. If your gradients are all real (as they should be if you want to run an optimization), then you won't have any issues with this.\n", "@ibab maybe I'm misunderstanding something here. In both the Associative LSTM and Unitary, there are intermediate complex calculations that are called for. How could all gradients be real if there are complex calculations occurring? \n\nI understand that you can initialize all the trainable variables with `tf.complex(var1, var2)`. However, when I run the `tf.gradient` function on a real cost function, some of the gradients are indeed `dtype` `complex64`. Mathematically, this makes sense as well since the gradient had to flow through complex calculations for each of the trainable variables. \n\nPerhaps I'm missing something here, but it seems clear that complex gradients need to be established before either of these two types of RNN's can work. \n", "If both the function that you are computing and the variables that you differentiate with respect to are real, then the gradients must be real, even if there were intermediate complex calculations involved.\nYou can see this from the following argument:\n- If both the differentiated function and the variables are real, then we can construct a fully real function by simply keeping track of the real and imaginary part separately\n- The gradient of such a real function must necessarily be real (as there were no complex calculations involved)\n- Because the real version of our function produces identical results to the original (complex) one, the gradients of the two functions must be the same, and therefore they must be real.\n\nApart from that, it looks like `tf.gradients` only returns complex numbers if the diff variables are complex at the moment. \nMaybe some of the variables that you differentiate by are still complex?\n\n**Edit:** Another argument to see that the gradients must be real is the definition of the derivative:\n\n```\nlim h\u21920 (f(x + h) - f(x)) / h\n```\n\nAs all variables here (`f`, `x` and `h`) are real, the result must be real as well\n", "@LeavesBreathe\n\n> Why do you multiply 3 separate times by fft_scale -- in the original paper this is not called for.\n\nMy bad. One line in the code is supposed to be commented out, already edited. There should be only one FFT/IFFT pair.\nAs for why I multiply `fft_scale`, is due to TF's FFT is not a normalized FFT, it will scale the norm of the vector being FFTed. For example:\n\n``` python\nprint(raw_fft( [1.,1.] )) #[2.,0.]\nprint(normalized_fft([1., 1.])) #[1.4142, 0.]\n```\n\n> Your `diag` variables do not appear to be diagonal, but rather normal complex matrices.\n\nThey are diagonal.\nIf you multiply (NOT `matmul`) tensor `x` of shape `[4]` with tensor `y` of shape `[100,4]`, you get broadcasted multiplication in TF, which is equivalent to `matmul( y, diag(x) )`.\n\n> In your `modrelu` function you multiply by `in_c`. From my impression, the paper simply uses as `modrelu` as an activation function and do not multiply the output by `in_c`\n\n`modrelu`, by design, changes the abs of input complex number to its ReLU-ed value while keeping phase intact. My `modReLU` does this: Calculated ReLU-ed abs, then multiply it by normalized input complex number. This is consistent with original paper.\n", "> Apart from that, it looks like tf.gradients only returns complex numbers if the diff variables are complex at the moment. \n> Maybe some of the variables that you differentiate by are still complex?\n\n@ibab  You could be right. I will carefully analyze all of my `trainable variables` and ensure that they are all real.\n\nThank you very much for the comprehensive mathematical explanation for gradient understanding. Makes much more sense to me now. \n\n---\n\n@khaotik \n\nApologies for some of my misunderstandings. Makes complete sense how your variables are indeed diagonal. Really clever how you avoided wasting memory for the diagonal matrix.\n\nThanks for the `fft_scale` explanation. Its logical that you only want this multiplication to occur twice, before it enters `batch_fft` and after its inverse `batch_ifft`. \n\nYour `mod_relu` implementation is completely correct. I just did not notice the `z` in the numerator which is what threw me off (don't know how I missed that). Will go back through my implementation and make the correction. We should either push your or mine implementation to TensorFlow so others have it. \n\nI'll also try stacking multiple layers of the uRNN and see how they do. I've heard that uLSTM is also very powerful, but hasn't been published yet. \n\nWill post back with findings a few days from now as I am away from my gpu's at the moment. \n\nIn the meantime, I added a few things to your unitary implementation:\n- Initialized R1 and R2 uniformly between `[-1,1]` as they indicate in their paper\n- Initialized Diagonal matrices between `[-pi, pi]`.\n- Initialized all Biases to zero as they do in the paper. \n- Added Out Bias\n- Commented out the extra `batch_fft` line\n\n``` python\nfrom math import sqrt\n\nimport numpy as np\n\nimport tensorflow as tf\nfrom tensorflow.python.ops import variable_scope as vs\nfrom tensorflow.python.ops import array_ops\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow.python.ops import nn_ops\n\nrnn_cell = tf.nn.rnn_cell\nseq2seq = tf.nn.seq2seq\n\ndef complex_mul_real( c, r ):\n    return tf.complex(tf.real(c)*r, tf.imag(c)*r)\n\n\ndef refl_c(in_, normal_):\n    normal_rk2 = tf.expand_dims( normal_, 1 )\n    scale = 2*tf.matmul( in_, tf.conj( normal_rk2 ) )\n    return in_ - tf.matmul(scale, tf.transpose(normal_rk2))\n\n\ndef complex_abs_sq(z):\n    return tf.real(z)*tf.real(z) + tf.imag(z)*tf.imag(z)\n\n\ndef normalize_c(in_):\n    norm = tf.sqrt(tf.reduce_sum(complex_abs_sq(in_)))\n    scale = 1./(norm + 1e-5)\n    return complex_mul_real( in_, scale )\n\n\ndef get_complex_variable( name, scope, shape, initializer):\n    re, im = vs.get_variable(name+'_re', shape=shape), vs.get_variable(name+'_im', shape=shape, initializer = initializer)\n    return tf.complex(re,im, name=name)\n\n\n'''multiply complex vector by parameterized unitary matrix'''\ndef ulinear(vec_in, out_size, scope=None):\n    shape = vec_in.get_shape().as_list()\n    if len(shape) != 2:\n        raise ValueError( 'argument vec_in must be a batch of vectors (2D tensor)' )\n    in_size = shape[1]\n    fft_scale = 1./sqrt(out_size)\n    with vs.variable_scope(scope or 'ULinear') as _s:\n        '''Equation W = D2 R1 F-1 D1 Perm R0 FFT D0'''\n        diag0 = get_complex_variable('diag0', _s, shape=[out_size], tf.random_uniform_initializer(-np.pi, np.pi))\n        diag1 = get_complex_variable('diag1', _s, shape=[out_size], tf.random_uniform_initializer(-np.pi, np.pi))\n        diag2 = get_complex_variable('diag2', _s, shape=[out_size], tf.random_uniform_initializer(-np.pi, np.pi))\n        refl0 = get_complex_variable('refl0', _s, shape=[out_size], tf.random_uniform_initializer(-1., 1.)) #nick notice how all of these are O(size), and not squared\n        refl1 = get_complex_variable('refl1', _s, shape=[out_size], tf.random_uniform_initializer(-1., 1.))\n        perm0 = tf.constant(np.random.permutation(out_size), name='perm0',dtype='int32')\n        refl0 = normalize_c(refl0)\n        refl1 = normalize_c(refl1)\n        #Equation Calculation\n        out_ = vec_in * diag0\n        out_ = refl_c(math_ops.batch_fft(out_)*fft_scale, refl0)\n        out_ = diag1 * tf.transpose(tf.gather(tf.transpose(out_), perm0))\n        out_ = diag2 * refl_c(math_ops.batch_ifft(out_)*fft_scale, refl1)\n        return out_\n\n\ndef modReLU(in_c, bias, scope=None):\n    with vs.variable_scope(scope or \"ULinear\"):\n        n = tf.complex_abs(in_c)\n        scale = 1./(n+1e-5)\n    return complex_mul_real(in_c, ( nn_ops.relu(n+bias)*scale ))\n\n\ndef abssigm(in_c, scope=None):\n    with vs.variable_scope(scope or 'ULinear'):\n        re,im = tf.real(in_c), tf.imag(in_c)\n        scale = 1./tf.sqrt(re*re + im*im + 1.)\n    return complex_mul_real(in_c,scale)\n\n\nclass URNNCell(rnn_cell.RNNCell):\n    def __init__(self, num_units, input_size=None):\n        self._num_units = num_units\n        self._input_size = num_units if input_size==None else input_size\n\n    @property\n    def input_size(self):\n        return self._input_size\n\n    @property\n    def output_size(self):\n        return self._num_units\n\n    @property\n    def state_size(self):\n        return self._num_units\n\n    def __call__(self, inputs, state, scope=None ):\n        with vs.variable_scope(scope or type(self).__name__):\n            mat_in = vs.get_variable('mat_in', [self.input_size, self.state_size*2])\n            mat_out = vs.get_variable('mat_out', [self.state_size*2, self.output_size])\n            in_proj = math_ops.matmul(inputs, mat_in)\n            in_proj_c = tf.complex( in_proj[:, :self.state_size], in_proj[:, self.state_size:] )\n            out_state = modReLU( in_proj_c + \n                ulinear(state, self.state_size),\n                vs.get_variable(name='bias', dtype=tf.float32, shape=[self.state_size], initializer = tf.constant_initalizer(0.)),\n                scope=scope)\n            '''\n            out_state = abssigm( in_proj_c +\n                                ulinear(state, self.state_size),\n                                scope=scope )\n            '''\n\n            out_bias = vs.get_variable(name = \"out_bias\", dtype = tf.float32, shape = [self.output_size], initializer = tf.constant_initalizer(0.))\n            out_ = math_ops.matmul( array_ops.concat(1,[tf.real(out_state), tf.imag(out_state)] ), mat_out) + out_bias\n        return out_, out_state\n```\n", "@LeavesBreathe Thanks for improving my code. I just put the new code in a new [repo](https://github.com/khaotik/char-rnn-tensorflow), which is a fork of [char-rnn-tensorflow](https://github.com/sherjilozair/char-rnn-tensorflow). Feel free doing experiments or contributing.\n"]}, {"number": 2254, "title": "segfault if import nltk after tensorflow", "body": "### Environment info\n\nOperating System: Centos 7\nLinux c7-dev01 3.10.0-327.el7.x86_64 #1 SMP Thu Nov 19 22:10:57 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux\n\nTensorflow version 0.8.0 (CPU tensorflow-0.8.0-cp34-cp34m-linux_x86_64.whl)\nNltk version 3.2.1 \n### Steps to reproduce\n\nWhen import tensorflow and nltk:\n(core) [gbelousov@c7-dev01 ~]$ python -c \"import tensorflow; import nltk;\"\nSegmentation fault\n\nWhen importing nltk and then tensorfklow:\n(core) [gbelousov@c7-dev01 ~]$ python -c \"import nltk; import tensorflow\"\nOk.\n### Logs or other output that would be helpful\n\npython[5334]: segfault at 7f63fea092a0 ip 00007f63fea092a0 sp 00007ffde9450138 error 15 in multiarray.cpython-34m.so[7f63fea01000+f000]\n", "comments": ["This seems similar to #2034. Can you try nightly build with the fix, if it still has this issue?\n", "Also, try importing numpy before either TensorFlow or NLTK; this is what solved the referenced issue.\n", "Closing as duplicate of #2034, which is fixed in 0.9.\n"]}, {"number": 2253, "title": "Tensorflow GPU r0.7 compilation => gcc:  language cuda not recognized", "body": "Hi, \nI am facing an issue while compiling tensorflow-r0.7 on centos6 with gcc-4.9.3(Configured with: ./configure --prefix=/home/soft/gcc-4.9.3)+cuda 7.0 + cudnn 7.0.3.0:\n\n`____[72 / 801] Compiling tensorflow/core/kernels/cwise_op_gpu_real.cu.cc\nERROR: /home/user/TENSOR_GPU/tensorflow/tensorflow/core/BUILD:334:1: C++ compilation of rule '//tensorflow/core:gpu_kernels' failed: gcc failed: error executing command \n  (cd /home/user/.cache/bazel/_bazel_jca142469/fc6103a815c76da222bbe3b7c887440a/tensorflow && \\\n  exec env - \\\n    PATH=/home/soft/cuda-7.0/bin:/home/apps/BINUTILS/2.25/gnu/bin:/home/soft/intel2015/composer_xe_2015.3.187/mkl/bin:/home/soft/gcc-4.9.3/bin:/home/user/TENSOR_GPU/jdk1.8.0_92/jre/bin:/home/user/TENSOR_GPU/jdk1.8.0_92/bin:/home/apps/PROTOBUF/2.6.1/gnu/include:/home/apps/PROTOBUF/2.6.1/gnu/bin:/home/apps/Caffe/CaffeDependencies/include:/home/soft/cuda-6.5/bin:/usr/lib64/qt-3.3/bin:/usr/kerberos/sbin:/usr/kerberos/bin:/opt/pbs/default/bin:/opt/pbs/default/sbin:/opt/pbs/default/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/opt/ibutils/bin:/home/apps/MATLAB/R2014b/bin:/home/user/bin \\\n  /home/soft/gcc-4.9.3/bin/gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections '-std=c++11' -iquote . -iquote bazel-out/local_linux-opt/genfiles -iquote external/bazel_tools -iquote bazel-out/local_linux-opt/genfiles/external/bazel_tools -iquote external/jpeg_archive -iquote bazel-out/local_linux-opt/genfiles/external/jpeg_archive -iquote external/png_archive -iquote bazel-out/local_linux-opt/genfiles/external/png_archive -iquote external/re2 -iquote bazel-out/local_linux-opt/genfiles/external/re2 -iquote external/eigen_archive -iquote bazel-out/local_linux-opt/genfiles/external/eigen_archive -isystem third_party/gpus/cuda/include -isystem bazel-out/local_linux-opt/genfiles/third_party/gpus/cuda/include -isystem external/bazel_tools/tools/cpp/gcc3 -isystem google/protobuf/src -isystem bazel-out/local_linux-opt/genfiles/google/protobuf/src -isystem external/jpeg_archive/jpeg-9a -isystem bazel-out/local_linux-opt/genfiles/external/jpeg_archive/jpeg-9a -isystem external/png_archive/libpng-1.2.53 -isystem bazel-out/local_linux-opt/genfiles/external/png_archive/libpng-1.2.53 -isystem external/re2 -isystem bazel-out/local_linux-opt/genfiles/external/re2 -isystem third_party/eigen3 -isystem bazel-out/local_linux-opt/genfiles/third_party/eigen3 -isystem external/eigen_archive/eigen-eigen-c5e90d9e764e -isystem bazel-out/local_linux-opt/genfiles/external/eigen_archive/eigen-eigen-c5e90d9e764e -isystem third_party/gpus/cuda -isystem bazel-out/local_linux-opt/genfiles/third_party/gpus/cuda -x cuda '-DGOOGLE_CUDA=1' -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -fno-canonical-system-headers '-frandom-seed=bazel-out/local_linux-opt/bin/tensorflow/core/_objs/gpu_kernels/tensorflow/core/kernels/cwise_op_gpu_equal_to.cu.pic.o' -MD -MF bazel-out/local_linux-opt/bin/tensorflow/core/_objs/gpu_kernels/tensorflow/core/kernels/cwise_op_gpu_equal_to.cu.pic.d -fPIC -c tensorflow/core/kernels/cwise_op_gpu_equal_to.cu.cc -o bazel-out/local_linux-opt/bin/tensorflow/core/_objs/gpu_kernels/tensorflow/core/kernels/cwise_op_gpu_equal_to.cu.pic.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\ngcc: error: language cuda not recognized`\n\nalso in  gcc man page, i can't locate **cuda** as a possible value of language switch:\n -x language\n           Specify explicitly the language for the following input files (rather than letting the compiler choose a default based on the file name suffix).  This option applies to all following input files until the next -x option.  Possible values for language are:\n**c  c-header  c-cpp-output  c++  c++-header  c++-cpp-output  objective-c  objective-c-header  objective-c-cpp-output objective-c++ objective-c++-header objective-c++-cpp-output assembler  assembler-with-cpp ada  f77  f77-cpp-input f95  f95-cpp-input  java**\n\nAny help/hint will be very useful.\nEagerly awaiting your replies..\n", "comments": ["within tensorflow/tensorflow.bzl, if i set \ncuda_copts = [\"-x\", \"c++\", \"-DGOOGLE_CUDA=1\",\n                \" \"] + cuda_copts\nmy compilation proceeds , but as expected (due to cuda constructs like threadIdx.x) the compilation fails.\nusually i have seen: \nnvcc -ccbin \"gcc\" -Xcompiler -fPIC\n\nbut the -x cuda syntax appears a bit weird!! what am i missing  here??\n", "The problem is that file should not be sent to gcc. It could be a bazel misconfiguration somewhere. \n\nThe correct sequence is as follows. You can follow it and see where things went wrong. \n- bazel.rc has this line \"build:cuda --crosstool_top=@tf//third_party/gpus/crosstool\". So under \"--config=cuda\" third_party/gpus/crosstool should be used instead of the default. \n- third_party/gpus/crosstool should have this line \"tool_path { name: \"gcc\" path: \"clang/bin/crosstool_wrapper_driver_is_not_gcc\" }\", which instructs the bazel to use that as the compiler instead of gcc. It understands the \"-x cuda\" option and knows which compiler to use. \n", "Hi,\ninitially With **crosstool_wrapper_driver_is_not_gcc**, i ran into  compilation errors (mentioned below) like  **error: unrecognized command line option \"-std=c++11\"**, so i manually replaced the same with **gcc**. I had modified the third_party/gpus/crosstool/CROSSTOOL as per rdipietro's comment for my gcc 4.9.3 (7 Mar) at : https://github.com/bazelbuild/bazel/issues/760.\nOne of the replacement was:\n tool_path { name: \"gcc\" path: \"clang/bin/crosstool_wrapper_driver_is_not_gcc\" } ===>  tool_path { name: \"gcc\" path: \"/home/soft/gcc-4.9.3/bin/gcc\" }.\n\nYou may like to have a look at the [CROSSTOOL file](https://drive.google.com/open?id=0B2ywpNeYZkgydEI3cHEzT3ZmMHM) which i am currently using.  Please suggest modifications if any.\n\nerror log:\n`____Building...\n____[1 / 139] Compiling external/re2/util/valgrind.cc\n____[1 / 303] Compiling external/re2/util/stringprintf.cc [for host]\n____[1 / 324] Compiling external/re2/re2/dfa.cc [for host]\nERROR: /home/user/.cache/bazel/_bazel_jca142469/fc6103a815c76da222bbe3b7c887440a/external/re2/BUILD:9:1: C++ compilation of rule '@re2//:re2' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command\n  (cd /home/user/.cache/bazel/_bazel_jca142469/fc6103a815c76da222bbe3b7c887440a/tensorflow && \\\n  exec env - \\\n    PATH=/home/soft/cuda-7.0/bin:/home/apps/BINUTILS/2.25/gnu/bin:/home/soft/intel2015/composer_xe_2015.3.187/mkl/bin:/home/soft/gcc-4.9.3/bin:/home/user/TENSOR_GPU/jdk1.8.0_92/jre/bin:/home/user/TENSOR_GPU/jdk1.8.0_92/bin:/home/apps/PROTOBUF/2.6.1/gnu/include:/home/apps/PROTOBUF/2.6.1/gnu/bin:/home/apps/Caffe/CaffeDependencies/include:/home/soft/cuda-6.5/bin:/usr/lib64/qt-3.3/bin:/usr/kerberos/sbin:/usr/kerberos/bin:/opt/pbs/default/bin:/opt/pbs/default/sbin:/opt/pbs/default/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/opt/ibutils/bin:/home/apps/MATLAB/R2014b/bin:/home/user/bin \\\n  third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections '-std=c++11' -iquote external/re2 -iquote bazel-out/local_linux-opt/genfiles/external/re2 -iquote external/bazel_tools -iquote bazel-out/local_linux-opt/genfiles/external/bazel_tools -isystem external/re2 -isystem bazel-out/local_linux-opt/genfiles/external/re2 -isystem external/bazel_tools/tools/cpp/gcc3 -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -fno-canonical-system-headers '-frandom-seed=bazel-out/local_linux-opt/bin/external/re2/_objs/re2/external/re2/re2/set.pic.o' -MD -MF bazel-out/local_linux-opt/bin/external/re2/_objs/re2/external/re2/re2/set.pic.d -fPIC -c external/re2/re2/set.cc -o bazel-out/local_linux-opt/bin/external/re2/_objs/re2/external/re2/re2/set.pic.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\ngcc: unrecognized option '-no-canonical-prefixes'\ncc1plus: error: unrecognized command line option \"-std=c++11\"\ncc1plus: error: unrecognized command line option \"-fno-canonical-system-headers\"\ncc1plus: warning: unrecognized command line option \"-Wno-free-nonheap-object\"\n____Building complete.\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\n____Elapsed time: 2.826s, Critical Path: 2.08s\n`\n", "Hi,\ni got past the **cc1plus: error: unrecognized command line option \"-std=c++11\"** error by making the compiler settings in : third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc as:\n\n```\nimport pipes\nprint (sys.version)\nCURRENT_DIR = os.path.dirname(sys.argv[0])\nCPU_COMPILER = ('/home/soft/gcc-4.9.3/bin/gcc')\nNVCC_PATH = ('/home/soft/cuda-7.0/bin/nvcc')\nGCC_HOST_COMPILER_PATH = ('/home/soft/gcc-4.9.3/bin/gcc')\nLLVM_HOST_COMPILER_PATH = ('/home/soft/gcc-4.9.3/bin/gcc')\nPREFIX_DIR = os.path.dirname(GCC_HOST_COMPILER_PATH)\n```\n\nbut now i am getting errors  : ImportError: **No module named argparse**, even though **argeparse-1.4.0** is available as python module.\n\n```\n[user@gpulogin01 ~/TENSOR_GPU/tensorflow]\n$ python\nPython 2.7.10 (default, May  5 2016, 17:12:28)\n[GCC 4.9.3] on linux2\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>> from argparse import ArgumentParser\n>>>\n>>>\n\n```\n\nI guess it is using the /usr/bin/python instead of ~/TENSOR_GPU/jdk1.8.0_92/bin/python\ncan you suggest the file where i can make python compiler path setting?\n\n```\n$ bazel build --verbose_failures -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package 2>&1|tee tensorflow_build.log\nWARNING: Sandboxed execution is not supported on your system and thus hermeticity of actions cannot be guaranteed. See http://bazel.io/docs/bazel-user-manual.html#sandboxing for more information. You can turn off this warning via --ignore_unsupported_sandboxing.\n____Loading...\n____Found 1 target...\n____Building...\n____[1 / 7] Linking google/protobuf/libprotobuf_lite.a [for host]\n____[1 / 42] Compiling google/protobuf/src/google/protobuf/compiler/java/java_primitive_field_lite.cc [for host]\n____[1 / 481] Linking external/re2/libre2.pic.a\nERROR: /home/user/TENSOR_GPU/tensorflow/google/protobuf/BUILD:520:1: Linking of rule '//google/protobuf:internal/_api_implementation.so' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command\n  (cd /home/user/.cache/bazel/_bazel_user/fc6103a815c76da222bbe3b7c887440a/tensorflow && \\\n  exec env - \\\n  third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -shared -o bazel-out/local_linux-opt/bin/google/protobuf/internal/_api_implementation.so -Wl,-whole-archive bazel-out/local_linux-opt/bin/google/protobuf/_objs/internal/_api_implementation.so/google/protobuf/python/google/protobuf/internal/api_implementation.pic.o -Wl,-no-whole-archive -lstdc++ -B/usr/bin/ -Wl,-R/home/soft/gcc-4.9.3/lib64 -Wl,-z,relro,-z,now -no-canonical-prefixes -pass-exit-codes '-Wl,--build-id=md5' '-Wl,--hash-style=gnu' -Wl,--gc-sections): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\nTraceback (most recent call last):\n  File \"third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc\", line 39, in <module>\n    from argparse import ArgumentParser\nImportError: No module named argparse\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\n____Elapsed time: 0.598s, Critical Path: 0.16s\n\n```\n", "Hi ,\nafter adding cxx_builtin_include_directory: \"/home/soft/cuda-7.0/include/\" in crosstool\n& adding default interpreter as: /home/user/TENSOR_GPU/jdk1.8.0_92/bin/python\nI got past previous error, and now i am stuck at:\n\n`____From Compiling tensorflow/core/kernels/cwise_op_equal_to.cc:\n2.7.10 (default, May  5 2016, 17:12:28)\n[GCC 4.9.3]\nIn file included from ./tensorflow/core/platform/default/logging.h:23:0,\n                 from ./tensorflow/core/platform/logging.h:24,\n                 from ./tensorflow/core/lib/core/status.h:24,\n                 from ./tensorflow/core/framework/op_def_builder.h:25,\n                 from ./tensorflow/core/framework/op.h:23,\n                 from ./tensorflow/core/kernels/cwise_ops_common.h:25,\n                 from tensorflow/core/kernels/cwise_op_equal_to.cc:16:\n./tensorflow/core/platform/default/logging.h: In instantiation of 'std::string* tensorflow::internal::Check_EQImpl(const T1&, const T2&, const char*) [with T1 = long unsigned int; T2 = int; std::string = std::basic_string<char>]':\n./tensorflow/core/kernels/cwise_ops_common.h:55:5:   required from 'static Eigen::array<long int, NDIMS> tensorflow::BinaryOpShared::ToIndexArray(const Vec&) [with int NDIMS = 2; tensorflow::BCast::Vec = tensorflow::gtl::InlinedVector<long long int, 4>]'\n./tensorflow/core/kernels/cwise_ops_common.h:110:7:   required from 'void tensorflow::BinaryOp<Device, Functor>::Compute(tensorflow::OpKernelContext*) [with Device = Eigen::GpuDevice; Functor = tensorflow::functor::equal_to<long long int>]'\ntensorflow/core/kernels/cwise_op_equal_to.cc:37:1:   required from here\n./tensorflow/core/platform/default/logging.h:194:25: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n                         == )  // Compilation error with CHECK_EQ(NULL, x)?\n                         ^\n./tensorflow/core/platform/macros.h:54:28: note: in definition of macro 'TF_PREDICT_TRUE'\n #define TF_PREDICT_TRUE(x) x\n                            ^\n./tensorflow/core/platform/default/logging.h:193:1: note: in expansion of macro 'TF_DEFINE_CHECK_OP_IMPL'\n TF_DEFINE_CHECK_OP_IMPL(Check_EQ,\n ^\n____From Compiling tensorflow/core/kernels/l2loss_op_gpu.cu.cc:\n2.7.10 (default, May  5 2016, 17:12:28)\n[GCC 4.9.3]\ngcc: error trying to exec 'as': execvp: No such file or directory\nERROR: /home/user/TENSOR_GPU/tensorflow/tensorflow/core/BUILD:334:1: output 'tensorflow/core/_objs/gpu_kernels/tensorflow/core/kernels/l2loss_op_gpu.cu.pic.o' was not created.\nERROR: /home/user/TENSOR_GPU/tensorflow/tensorflow/core/BUILD:334:1: not all outputs were created.\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\n____Elapsed time: 35.525s, Critical Path: 34.98s\n`\nbut as is within my PATH at: /home/apps/BINUTILS/2.25/gnu/bin/as as well as /usr/bin/as.\n", "Unfortunately we don't officially support CentOS. We'll do our best to support installation on unsupported platforms, but in this case, it's unclear what we can do. If it turns out there is a problem that can be fixed with changes to TensorFlow, we're happy to accept a PR.\n", "I built the latest Tensorflow (github master branch) with GPU support on a supercomputing center (CentOS 6.7 with gcc 4.9.2). I pointed out some of environment variables settings that are necessary for a success built. You can refer to my protocol:\r\n\r\nhttp://biophysics.med.jhmi.edu/~yliu120/tensorflow.html\r\n\r\nTensorflow can be built with almost all Linux distributions with gcc >= 4.8 (usually libstdc++ comes with gcc 4.8). You just need to set the correct ENVs."]}, {"number": 2252, "title": "R0.7", "body": "", "comments": ["Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "I will close this PR. It appears it's outdated. Please comment if that's not the case.\n"]}, {"number": 2251, "title": "get error when slice tensor", "body": "I want to slice tensor to get specific tensor by list of index, for example:\n\n```\nword_weight   = tf.get_variable(\"word_weight\", [20])\na= word_weight[ [1,6,5] ]\n```\n\n(I want to get word_weight[1],  word_weight[6],  word_weight[5])\n\n---\n\nBut I get error when I run above code.\n\n```\nraise ValueError(\"Shape %s must have rank %d\" % (self, rank))\nValueError: Shape (16491,) must have rank 3\n\n```\n", "comments": ["That syntax (which might be valid in NumPy - I'm not sure) doesn't work for TensorFlow slicing. To get rows 1, 6, and 5 from a tensor or variable, you use [`tf.gather()`](https://www.tensorflow.org/versions/r0.8/api_docs/python/array_ops.html#gather):\n\n``` python\na = tf.gather(word_weight, [1, 6, 5])\n```\n"]}, {"number": 2250, "title": "fix compile issue on os x", "body": "for issue #2243\n", "comments": ["Can one of the admins verify this patch?\n", "@tensorflow-jenkins test this please\n"]}, {"number": 2249, "title": "add test file", "body": "add test file for test\n", "comments": ["Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n"]}, {"number": 2248, "title": "Tensorflow r0.8 doesn't work with scikit-learn and scikit-Image", "body": "I tried two installation method. Without scikit-Learn and scikit-Image, tensorflow works fine and I can run the deepdream ipynb. \n1. cuda 7.5 + cudnn v5 with source code compiled\n2. cuda 7.5 + cudnn v4 pip GPU install\n\nAll according to https://www.tensorflow.org/versions/r0.8/get_started/os_setup.html\n\nAfter I installed scikit-learn, the segmentation fault (core dumped) following the Tensorflow loading message even though I import numpy before tesorflow. I will post more info here later.\n", "comments": ["A small code segment to reproduce the error and an error message log will be very helpful. \n", "This seems similar to #2034. Can you try nightly build with the fix, if it still has this issue?\n", "Because I am using a server remotely, several people use the server together. I only have chance now to access it. \n\nTo fix it , I fully deleted all. Then, after git pull latest code I did the following:\n1. conda create virtual environment for python 2.7 and install whole anaconda including scikit-learn.\n2. compile Tensorflow according to the tutorial steps.\nIt works fine now. I tried mnist.py in skflow.  All good. \n", "This can be closed https://github.com/tensorflow/tensorflow/issues/2034#issuecomment-217632558\n"]}, {"number": 2247, "title": "Doubt with sharing variable ", "body": "http://tensorflow.org/how_tos/variable_scope/index.md\n\nI was experiencing serious difficulties at first and believed we're endeavoring to utilize the same weights for both of the conv layers. It didn't help that the definition for \"variables_dict\" just unequivocally expresses the presence for the weights for the primary conv layer, persuading that the weights of the 2 layers are really shared also.\n", "comments": ["I am not sure that I understand the question here. Could you elaborate with a small code example? \n", "Closing due to lack of activity.\n"]}, {"number": 2246, "title": "Branch 121636618", "body": "Merge internal changes.\n", "comments": ["Can one of the admins verify this patch?\n", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for the commit author(s).  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\n\n<!-- need_author_cla -->\n", "@tensorflow-jenkins, test this please. \n", "@tensorflow-jenkins test this please\n", "@tensorflow-jenkins test this please\n", "@tensorflow-jenkins test this please\n", "@martinwicke @vrv : ready to merge!\n", "Thanks for resolving the conflicts and fixing the tests, @zheng-xq \n"]}, {"number": 2245, "title": "how to delete node from old graph\uff1f", "body": "I build retrain_image for 5 new flowers,and got a pb file ,87M,has 1001 nodes.I put it in android demo.Every run costs 2S.It is terrorable.I guess,because of too many unusefull nodes.So,how to delete nodes those I wish in retraining?\n", "comments": ["One way is to change the default graph, and not putting all the nodes on the same graph. \n\nwith tf.Graph().as_default():\n\nAdding @mrry to point out if there are better ways. \n", "If a graph node is unused, it will not be executed, and hence it won't contribute to the step time (apart from possibly the first step, when the graph is first built and pruned). There's no API for deleting nodes in Python, but you can try using the [`extract_sub_graph()`](https://github.com/tensorflow/tensorflow/blob/5f4524928af5ba5727fa97a35ddd5da72be0c476/tensorflow/python/client/graph_util.py#L125) function to prune the graph to only the nodes that are needed. (Note that doing this is unlikely to improve performance though.)\n", "If you use `extract_sub_graph()` you risk that it'll \"break\" the graph (the resulting subgraph would be useless).\r\n\r\nA **variable** consist of few nodes and there is no single node that has an outgoing connection to each other. \r\n_Thanks to this fact `export_sub_graph()` breaks variable structure and effectivly removes variable from graph. \r\nIs there a smart way around it? (I didn't try explicitely listing all the nodes for each variable used by source graph - but this wouldn't be super efficient and clean).\r\n\r\nOne should construct graph extraction function in a way it preserves higher order structures (variables) too.\r\nNot only singular graph nodes.", "There's a more advanced subgraph extractor proposed in https://github.com/tensorflow/tensorflow/pull/5802", "I think I need this feature.  I trained a graph with queue runners and now need to run inference against it with feed_dict.  When I load the meta graph the first part of the graph is the queue runner input pipeline; so when I call predict; it hangs unless I start the queue runners; when I start the queue runners they are empty because I'm not putting anything on the queue; I have no idea how to enqueue items...  The inference images never hit disk until the whole process is done and even then only in collection mode.", "@drcrook1 This sounds like a problem for the [TensorFlow graph transform tool](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/graph_transforms/README.md). It enables you to specify an input node (which in your case would probably come after the `\"DequeueMany\"` op from the queue), and will prune the irrelevant nodes for you.\r\n\r\n/cc @petewarden ", "@mrry any plans to add a feature to remove dropout in the tensorflow graph transform tool? I am running into the issue that nvidia's tensorrt does not support the op, which forces me to manually remove the nodes. Or is there an easy way to do that already with optimizing for deployment?", "@ljstrnadiii I'm not sure what the plans are for the graph transform tool, but @petewarden would know. It might be worth creating a new issue with this high-level feature request.", "Thanks @mrry .", "@drcrook1 I have same problem, have you fixed it ?", "@mrry  I have seen [TensorFlow graph transform tool](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/graph_transforms/README.md#merge_duplicate_nodes), but I don't figure out which transform operation can implement \"specify an input node\"...", "I have the same issue as @ysw361564483. Anyone knows how to set an input (e.g. phase_train) which is placeholder with graph transform tool for inference optimization? ", "@drcrook1  I have added manually an input placeholder node with right dimensions and deleted the whole queue related nodes in the pbtxt file, but for this you have to know where to connect your new node (looking at the graph in tensorboard helped me)", "> @mrry any plans to add a feature to remove dropout in the tensorflow graph transform tool? I am running into the issue that nvidia's tensorrt does not support the op, which forces me to manually remove the nodes. Or is there an easy way to do that already with optimizing for deployment?\r\n\r\nI have the same problem that need to remove unspported op in using tensorrt,do you have some way to solve this problem?Thanks you", "build a new inference graph without unused nodes, then freeze_graph with the new graph and old chekcpoint. done.", "Basically, inspect nodes connections and have in mind what the new graph shall look like, then construct a new one with reindexing the old graphs.\r\n\r\nCheck this: https://github.com/KleinYuan/tf-tailor/blob/master/tailor.py#L16-L23\r\n"]}, {"number": 2244, "title": "Updated API docs to sync with supported data types in csiwe_op_*.", "body": "Based on excellent comments from @yaroslavvb and @zheng-xq, this PR changes API docs to sync with supported data types in csiwe_op_*.\n\nThis addresses #2225 \n", "comments": ["Can one of the admins verify this patch?\n", "@girving Will this be a backward-compatibilty issue?\n", "It will break the backwards compatibility test, since it reduces the list of datatypes the ops are registered for.  However, it's not otherwise a backwards compatibility issue if the removed ops never ran, and it's a good change to make since it stops us from lying.  We should arguably make an exception and do the necessary surgery to fix the test.\n\nI believe the backwards compatibility test is open source, so @hunkim: am I correct that you haven't tried running the unit tests yet with your change? \n", "@josh11b: If you agree, what's the best way to perform the necessary surgery to clarify that `tf.sqrt` has never worked on `int32`? \n", "@girving, @martinwicke Not at all. I haven't reduced the list of datatypes the ops are registered for. Now this API doc is synced with actual implementation.  \n", "This is not a doc file. This is the file that actually defined which\nkernels are compiled.\n\nOn Fri, May 6, 2016 at 8:53 AM Sung Kim notifications@github.com wrote:\n\n> @girving https://github.com/girving, @martinwicke\n> https://github.com/martinwicke Not at all. Now this API doc is synced\n> with actual implementation.\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> \n> Reply to this email directly or view it on GitHub\n> https://github.com/tensorflow/tensorflow/pull/2244#issuecomment-217482152\n", "@hunkim: I understand that your change is good, but by \"Not at all\" do you mean that you definitely haven't run the tests?  I believe they will fail, since we have a backwards compatibility check that registered ops only get more permissive (ignoring the kernels).\n", "@girving I just generated API docs and it was successful. So I assumed it was OK. It was my bad.\n\nI just ran the python tests. They all passed, but as you said //tensorflow/python:nn_test failed. \n\n`TypeError: DataType int32 for attr 'T' not in list of allowed values: float16, float32, float64, complex64`\n\nHow to update docs without breaking this? Currently, supported types in doc and code are different as discussed PR #2227.\n\n> A Tensor. Must be one of the following types: float32, float64, int32, complex64, int64\n\n`\nREGISTER4(UnaryOp, CPU, \"Cos\", functor::cos, float, Eigen::half, double, complex64);`\n", "Adding @girving to give guidance on how to deal with the backward compatibility test. \n\nIn general, it is a good idea to run the TensorFlow tests locally. \n", "@zheng-xq Thanks for the tip. I'll always run tests locally even for doc changes.\n\nHowever, testing takes a really long time for me: about 40 min in my Mac, and over 10 min in a good google cloud machine (16 vCPUs, 60 GB memory) even if I change only one code line.\n\nI wonder why it runs all tests again and again for just one-line-change? Can it only run affected test cases by the change?\n", "> > I wonder why it runs all tests again and again for just one-line-change? Can it only run affected test cases by the change?\n\nThe public bazel does not have the capability to achieve that automatically. \n\nWhen you get to the point that you know the test structure, you can just run the tests that are most likely to fail. \n", "Verifying with @josh11b, but I think we should do the surgery to make the backwards compatibility test pass.  However, you seem to say above that the backwards compatibility test doesn't fail with your change, which is suspicious.  To confirm, can you do\n\n```\nbazel test core/ops/compat:backwards_compatibility_test\n```\n\nThat should fail.  Assuming it does, it should be reasonably easy to fix by manually editing\n\n```\n core/ops/compat/ops_history.v0.pbtxt\n```\n\nto remove the types that are invalid.  I will then look at the changes to that file very carefully. :)\n", "@hunkim: Go for stripping the bad dtypes out of `ops_history.v0.pbtxt`.  Let me know if you have questions or want help.\n", "I have submitted a new PR #2435.\n"]}, {"number": 2243, "title": "Error when building on Mac with GPU", "body": "I am new to this so feel free to delete this if this is trivial.\n\nI encountered the following errors when building from source on Mac with GPU support\n\n`tensorflow/core/kernels/cudnn_pooling_gpu.cc:71:32: error: implicit instantiation of undefined template 'std::__1::array<long long, 3>'\n  for (size_t i = 0; i < window.size(); ++i) {\n                               ^\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/__tuple:95:65: note: template is declared here\ntemplate <class _Tp, size_t _Size> struct _LIBCPP_TYPE_VIS_ONLY array;\n                                                                ^\ntensorflow/core/kernels/cudnn_pooling_gpu.cc:73:42: error: implicit instantiation of undefined template 'std::__1::array<long long, 3>'\n    pooling_desc.set_window(dim_i, window.rbegin()[i]);\n                                         ^\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/__tuple:95:65: note: template is declared here\ntemplate <class _Tp, size_t _Size> struct _LIBCPP_TYPE_VIS_ONLY array;\n`\nand seven other similar errors.\n\nIncluding `<array>` in `tensorflow/tensorflow/core/kernels/cudnn_pooling_gpu.cc` seems to fix the problem\n", "comments": []}, {"number": 2242, "title": "Silent fail when network is big", "body": "### Steps to reproduce\n1. Build a 10 layer hidden network with 2400 neurons in each layer \n2. Have data with correlation\n3. Accuracy will be 1 / n_classes_outputs for each training step. \n### What have you tried?\n1. If you will have less neurons and layers, everything works\n\nI presume that there is a issue with memory and setting weights, but a error message would be nice.\n", "comments": ["Could you post your environment, and a small code segment to reproduce the problem? Also please upload the log file so we can check if there is something meaningful there. \n", "Using Ubuntu, pip installation and latest TensorFlow (0.8.0). The issue seems to be, that my biases and weights go all to NaN objects, but I have no idea why. I remember getting similar error in the past, then Exception was thrown, now it is silent and training goes to end. Everything works well, if the network is smaller.\n\nThe issue seems to be about the learning rate. If it is too small or too big (0.000001 is too small, 0.1 is too big), weights and biases go to NaN really fast, when network has over 5 layers and over 300 neurons. \n", "@mxrguspxrt: Exploding to nans with high learning rate is standard behavior for neural networks.  If you're seeing a rapidly exploding network with a very small learning rate, there might be an issue, but as in I'm going to close this as (unfortunately) intended behavior.  Please comment if you think it should be reopened.  \n"]}, {"number": 2241, "title": "Core dumped error for specific example codes (virtualenv related?)", "body": "Hi there,\n\nI have installed TensorFlow on my system, and was able to run some examples just fine on the gpu: (e.g. 0_multiply.py, 1_linear_regression.py, 4_modern_net.py, etc). However, when I try to run some CNN-related codes, I am getting a core-dumped error.\n### Environment info\n\nOperating System: Ubuntu 14.04, TensorFlow installed in virtualenv\n\nInstalled version of CUDA and cuDNN: \n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\n\n> -rw-r--r-- 1 root root   322936 Aug 15  2015 /usr/local/cuda/lib64/libcudadevrt.a\n> lrwxrwxrwx 1 root root       16 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.7.5\n> lrwxrwxrwx 1 root root       19 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18\n> -rwxr-xr-x 1 root root   383336 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5.18\n> -rw-r--r-- 1 root root   720192 Aug 15  2015 /usr/local/cuda/lib64/libcudart_static.a\n> lrwxrwxrwx 1 root root       13 May  5 12:48 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.5\n> lrwxrwxrwx 1 root root       17 May  5 12:48 /usr/local/cuda/lib64/libcudnn.so.5 -> libcudnn.so.5.0.4\n> -rwxrwxr-x 1 root root 59823168 Mar 21 20:37 /usr/local/cuda/lib64/libcudnn.so.5.0.4\n> -rwxr-xr-x 1 root root 19340472 Apr 19 09:43 /usr/local/cuda/lib64/libcudnn.so.6.5\n> -rwxr-xr-x 1 root root 19340472 Apr 19 09:43 /usr/local/cuda/lib64/libcudnn.so.6.5.18\n> -rw-rw-r-- 1 root root 58734618 Mar 21 20:37 /usr/local/cuda/lib64/libcudnn_static.a\n\nI installed TF using this page: https://www.tensorflow.org/versions/r0.8/get_started/os_setup.html#virtualenv-installation\nvia virtualenv. I needed virtualenv because I don't want it to screw with my python/Theano.\n### Steps to reproduce\n1. Running 5_convolutional_net.py will produce the log file.\n### What have you tried?\n\nI'm using CUDA 7.5, so I tried reinstalling CUDA 7.0 and CUDA 6.5\n### Logs or other output that would be helpful\n\n> I tensorflow/core/common_runtime/gpu/gpu_device.cc:755] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:06:00.0)\n> I tensorflow/core/common_runtime/gpu/gpu_device.cc:755] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GeForce GTX TITAN Black, pci bus id: 0000:03:00.0)\n> Building graph...\n> I tensorflow/core/common_runtime/gpu/gpu_device.cc:755] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:06:00.0)\n> I tensorflow/core/common_runtime/gpu/gpu_device.cc:755] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GeForce GTX TITAN Black, pci bus id: 0000:03:00.0)\n> Exception AssertionError: AssertionError() in <bound method InteractiveSession.__del__ of <tensorflow.python.client.session.InteractiveSession object at 0x7f4bf7816390>> ignored\n> F tensorflow/stream_executor/cuda/cuda_dnn.cc:204] could not find cudnnCreateTensorDescriptor in cudnn DSO; dlerror: /usr/local/lib/libcudnn.so: undefined symbol: cudnnCreateTensorDescriptor\n> Aborted (core dumped)\n\nThanks for your help! It was able to use my GPU fine for other codes, not particularly the ones involving CNNs.\n", "comments": ["I was experiencing this error too, redownloading and reinstalling cudnn (4.0.7) worked for me. \n", "I used\ncudnn-6.5-linux-x64-v2.tgz of \nDownload cuDNN v2 (March 17,2015), for CUDA 6.5 and later.\n", "That might be the problem. as written [here](https://www.tensorflow.org/versions/r0.8/get_started/os_setup.html#requirements), prebuilt GPU version works with cuda 7.5 + cuDNN v4. Try it with 4.0.7, and see if it works.\n", "@martinwicke: Is there a convenient way to report error message in this case instead of crashing? \n", "I don't know. @zheng-xq? \n\nThis is almost certainly due to the version conflict. Our binaries are built against cudnn4, Cuda 7.5. Any other version will have some problem like this.\n"]}, {"number": 2240, "title": "Will it conflict installing by soucecode ,with installing by pip", "body": "I have install tensorflow by pip.\nAnd Because I have to add some code in tensorflow ,so I need to build tensorflow by sourcecode.\nAnd when run bazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer\nit will report \nconfigure: error: zlib not installed\nTarget //tensorflow/cc:tutorials_example_trainer failed to build\nUse --verbose_failures to see the command lines of failed build steps.\nINFO: Elapsed time: 2.743s, Critical Path: 2.24s\nBut in fact ,I have install zlib.\n\nINFO: Elapsed time: 2.743s, Critical Path: 2.24s\n[@sjs_88_31 tensorflow]# yum install zlib\nLoaded plugins: fastestmirror, langpacks\nLoading mirror speeds from cached hostfile\n- epel: mirrors.neusoft.edu.cn\n  _Package zlib-1.2.7-13.el7.x86_64 already installed and latest version\n  _Nothing to do\n  So how can I fixed it?\n  My Os is cenos7.1.\n\nAnd how can i add souce files if just only using pip install?\n", "comments": ["Please run with --verbose_failures and post the results. \n\nI am not sure whether Centos 7.1 is supported by bazel. You can also file a bazel bug to get more help on bazel issues. \n", "Closing for now due to insufficient information.  @liumilan: I am happy to reopen if there are more details. \n"]}, {"number": 2239, "title": "tensorflow error in a docker container ", "body": "GitHub issues are for bugs / installation problems / feature requests.  \nFor general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed\nout of scope for GitHub Issues and point people to StackOverflow.\n\nFor bugs or installation issues, please provide the following information.\nThe more information you provide, the more easily we will be able to offer\nhelp and advice.\n### Environment info\n\nOperating System: ubuntu 14.04\n\nInstalled version of CUDA and cuDNN: 7.5 and 4 \n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\n\nIf installed from binary pip package, provide: \n1. Which pip package you installed.\n2. The output from python -c \"import tensorflow; print(tensorflow.**version**)\".\n\nIf installed from sources, provide the commit hash:\n### Steps to reproduce\n1. Install tensorflow-gpu-devel\n2. docker run the image\n3. python and import tensorflow\n### What have you tried?\n1. Tried the example from tensorflow website: https://www.tensorflow.org/versions/r0.8/get_started/os_setup.html#test-the-tensorflow-installation\n### Logs or other output that would be helpful\n\n(If logs are large, please upload as attachment).\n\n> > > import tensorflow as tf\n> > > I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so.7.5 locally\n> > > I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so.4 locally\n> > > I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so.7.5 locally\n> > > I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally\n> > > I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so.7.5 locally\n> > > sess = tf.Session()\n> > > E tensorflow/stream_executor/cuda/cuda_driver.cc:481] failed call to cuInit: CUresult(-1)\n> > > I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:114] retrieving CUDA diagnostic information for host: 18a61c37a941\n> > > I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:121] hostname: 18a61c37a941\n> > > I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:146] libcuda reported version is: Invalid argument: expected %d.%d form for driver version; got \"1\"\n> > > I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] driver version file contents: \"\"\"NVRM version: NVIDIA UNIX x86_64 Kernel Module  352.93  Tue Apr  5 18:18:24 PDT 2016\n> > > GCC version:  gcc version 4.8.4 (Ubuntu 4.8.4-2ubuntu1~14.04) \n> > > \"\"\"\n> > > I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:150] kernel reported version is: 352.93\n> > > I tensorflow/core/common_runtime/gpu/gpu_init.cc:81] No GPU devices available on machine.\n", "comments": ["Why do I have this error?\n", "The error says no GPU can be found on this machine. \n\nCould you run \"nvidia-smi\" and post the log? \n", "Host machine:\n\nFri May  6 08:34:30 2016  \n+------------------------------------------------------+  \n| NVIDIA-SMI 352.93     Driver Version: 352.93         |  \n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  GeForce GTX TIT...  Off  | 0000:03:00.0     Off |                  N/A |\n| 22%   35C    P8    15W / 250W |    135MiB / 12287MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   1  GeForce GTX TIT...  Off  | 0000:04:00.0     Off |                  N/A |\n| 22%   36C    P8    15W / 250W |     23MiB / 12287MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   2  GeForce GTX TIT...  Off  | 0000:81:00.0     Off |                  N/A |\n| 22%   36C    P8    14W / 250W |     23MiB / 12287MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   3  GeForce GTX TIT...  Off  | 0000:82:00.0     Off |                  N/A |\n| 22%   33C    P8    15W / 250W |     23MiB / 12287MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n\n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID  Type  Process name                               Usage      |\n|=============================================================================|\n|    0      1184    C   /usr/bin/python                                110MiB |\n+-----------------------------------------------------------------------------+\n\nand in the docker container, I can't run nvidia-smi. it says command not found.  \n", "This is an Docker-Issue.\n\nDocker does not support GPUs by the default settings. You can test:\nhttps://github.com/NVIDIA/nvidia-docker\n\nor add \n\n```\n--device /dev/nvidia0:/dev/nvidia0 --device /dev/nvidiactl:/dev/nvidiactl --device /dev/nvidia-uvm:/dev/nvidia-uvm\n```\n", "I already tried the both way. But still have the same message and tensor doesn't work with gpus. Then shall I open this issue on Docker?\n", "@martinwicke: It looks like our docker instructions are out of sync.  One of these says to use nvidia-docker; the other does not.\n\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/docker#running-the-container\nhttps://www.tensorflow.org/versions/master/get_started/os_setup.html#docker-installation\n\nShould they be synchronized?\n", "@caisq, which one are the \"correct\" ones? There should definitely only be one version.\n", "Cc @jendap who said he was planning to synchronize the two places.\n", "@jendap are you still working on this?\n", "@caisq could you take a look at resolving this issue?\n", "This appears to be fixed. Both recommend using nvidia-docker now.\n", "Due some reasons, I am allowed to use official `docker` instead of `nvidia-docker` in my program. But I still need gpu access with Tensorflow, and I encountered the same problem as @gnujimmik posted. Do you have any ideas about it?"]}, {"number": 2238, "title": "Issue with conditional comparing (equal returning wrong type)", "body": "### Environment info\n\nOperating System: Ubuntu\n\nInstalled version of CUDA and cuDNN: \n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`): (this path did not exist)\n7.5 is CUDA\n\nIf installed from binary pip package, provide:\n1. Which pip package you installed. GPU Ubuntu .8.0\n2. The output from python -c \"import tensorflow; print(tensorflow.**version**)\".\n   I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally\n   I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally\n   I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally\n   I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally\n   I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally\n   0.8.0\n### Steps to reproduce\n\nCode is also in this stack Overflow:\nhttp://stackoverflow.com/questions/37044006/tensorflow-conditional-throwing-value-error/37053896#37053896\n\n```\nimport tensorflow as tf\nimport numpy as np\n\nX = tf.constant([1, 0])\nY = tf.constant([0, 1])\nBOTH = tf.constant([1, 1])\nWORKING = tf.constant(1)\n\ndef create_mult_func(tf, amount, list):\n    def f1():\n        return tf.scalar_mul(amount, list)\n    return f1\n\ndef create_no_op_func(tensor):\n    def f1():\n        return tensor\n    return f1\n\ndef stretch(tf, points, dim, amount):\n    \"\"\"points is a 2 by ??? tensor, dim is a 1 by 2 tensor, amount is tensor scalor\"\"\"\n    x_list, y_list = tf.split(0, 2, points)\n    x_stretch, y_stretch = tf.split(0, 2, dim)\n    is_stretch_X = tf.equal(x_stretch, WORKING, name=\"is_stretch_x\")\n    is_stretch_Y = tf.equal(y_stretch, WORKING, name=\"is_stretch_Y\")\n    print tf.shape(is_stretch_X)\n    print tf.shape(is_stretch_Y)\n    x_list_stretched = tf.cond(is_stretch_X,\n                               create_mult_func(tf, amount, x_list), create_no_op_func(x_list))\n    y_list_stretched = tf.cond(is_stretch_Y,\n                               create_mult_func(tf, amount, y_list), create_no_op_func(y_list))\n    return tf.pack(x_list_stretched, y_list_stretched)\n\nexample_points = np.array([[1, 1], [2, 2], [3, 3]], dtype=np.float32)\nexample_point_list = tf.placeholder(tf.float32)\n\nresult = stretch(tf, example_point_list, X, 1)\nsess = tf.Session()\n\nwith tf.Session() as sess:\n    result = sess.run(result, feed_dict={example_point_list: example_points})\n    print(result)\n```\n### What have you tried?\n1. passing in a scalar instead of a tensor by reshaping the tensor\n2. changing `WORKING` to ```tf.constant([1]) \n### This fixes the error but seems very wrong and does not fix the other issues\n\n```\nis_stretch_X = tf.reshape(tf.cast(tf.equal(x_stretch, WORKING, name=\"is_stretch_x\"), tf.bool), [])\nis_stretch_Y = tf.reshape(tf.cast(tf.equal(y_stretch, WORKING, name=\"is_stretch_Y\"), tf.bool), [])\n```\n\nThe result of equal should be passed to the conditional without needing to reshape or cast to a boolean first.\nBtw it ignores the cast to the boolean as well leaving it as an int32\n### Logs or other output that would be helpful\n\n(If logs are large, please upload as attachment).\n\n```\nFile \"/path/test2.py\", line 36, in <module>\n    result = stretch(tf, example_point_list, X, 1)\n  File \"/path/test2.py\", line 28, in stretch\n    create_mult_func(tf, amount, x_list), create_no_op_func(x_list))\n  File \"/path/tensorflow/python/ops/control_flow_ops.py\", line 1142, in cond\n    p_2, p_1 = switch(pred, pred)\n  File \"/path/tensorflow/python/ops/control_flow_ops.py\", line 203, in switch\n    return gen_control_flow_ops._switch(data, pred, name=name)\n  File \"/path/tensorflow/python/ops/gen_control_flow_ops.py\", line 297, in _switch\n    return _op_def_lib.apply_op(\"Switch\", data=data, pred=pred, name=name)\n  File \"/path/tensorflow/python/ops/op_def_library.py\", line 655, in apply_op\n    op_def=op_def)\n  File \"/path/tensorflow/python/framework/ops.py\", line 2156, in create_op\n    set_shapes_for_outputs(ret)\n  File \"/path/tensorflow/python/framework/ops.py\", line 1612, in set_shapes_for_outputs\n    shapes = shape_func(op)\n  File \"/path/tensorflow/python/ops/control_flow_ops.py\", line 2032, in _SwitchShape\n    unused_pred_shape = op.inputs[1].get_shape().merge_with(tensor_shape.scalar())\n  File \"/path/tensorflow/python/framework/tensor_shape.py\", line 554, in merge_with\n    (self, other))\nValueError: Shapes (1,) and () are not compatible\n```\n", "comments": ["I can't reproduce the issue in title, ie `sess.run(tf.equal(1, 2))` produces `bool` rather than `int32`\n", "It seems the problem was in the inputs to cond being wrong shape, keveman gave solution here http://stackoverflow.com/a/37053896/419116\n", "Yes I see that.  But shouldn't a logic statement be directly usable as a conditional without needing to be reshapen?\n", "@dtracers: Like numpy, `tf.equal` returns a broadcasted tensor of whatever shapes you gave it as input.  You can only use it as a conditional if the shape is scalar (0-dimensional).  `tf.reduce_all` or `tf.reduce_any` can be used to collapse to a scalar, or `tf.squeeze_dims` in this case. \n", "We follow numpy convention on that. IE the following returns an array of [False] and it can't be used directly as a conditional\n\n`np.array([1])==np.array([2])`\n"]}, {"number": 2237, "title": "Add support for recursive neural networks", "body": "I'd like to implement a recursive neural network as in [[Socher et al. 2011]](http://www.socher.org/index.php/Main/ParsingNaturalScenesAndNaturalLanguageWithRecursiveNeuralNetworks) in TensorFlow.\n\nNote that this is different from recurrent neural networks, which are nicely supported by TensorFlow. The difference is that the network is not replicated into a linear sequence of operations, but into a tree structure.\n\nMaybe a tree traversal can already be implemented using `While` ops, but I'm not sure how.\n(A bottom-up traversal of a tree would have to be performed for each entry in the dataset, applying the network at each node)\nInstinctively, I have the impression that this would need a new C++ op that generalizes `While`.\n", "comments": ["Adding @yuanbyu to comment on how to use the control flow the implement recursive network.\n\nMy guess is that the control flow plus stack might be helpful. \n", "I think a \"stack of tensors\" data structure could be implemented in a similar way to the existing [`TensorArray`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/tensor_array_ops.py#L36). I'm not sure how to propagate the gradients, though.\n", "Looks like it's possible to implement this in Theano: https://github.com/ofirnachum/tree_rnn\n(Haven't taken a closer look at the implementation yet, though)\n", "@yuanbyu: Do you have any suggestions?  I'll mark this contributions welcome for now.  If it's added, we should make sure it supports efficient batching. \n", "I think the hardest part about this is coming up with a nice way of storing tree-shaped entries and passing them to Tensorflow ops.\nThen a monolithic tensorflow op could provide endpoints for a tensor computation, which allows the user to define the network that will be replicated at each node of the tree.\nThe API could be something like this:\n\n``` python\ndef network(x, y):\n  # Define transformation\n  return z\n\n# Evaluation\ntf.recursive_eval(network, \"tree_data_input\", \"tree_data_output\")\n# Training\nloss = tf.recursive_loss(network, \"tree_data_input\", \"tree_data_reference\")\n```\n", "This is an NLP style model (sentiment analysis) and is based upon assignment 3 from [Stanford CS224D](http://cs224d.stanford.edu/syllabus.html). The tree structure is created as a purely python structure (tree class and node class). The variable state is saved/restored on a per batch usage and the tree structure is created using recursive descent (with any leaf nodes using an embedding operation to generate a feature vector), the loss could be created in a similar manner.\n\nThe tree class is made up of nodes (tree structure is created through a parser - I'm leaving the details out for now):\n\n```\nclass Node:  # a node in the tree\n    def __init__(self, label, word=None):\n        self.label = label\n        self.word = word\n        self.parent = None  # reference to parent\n        self.left = None  # reference to left child\n        self.right = None  # reference to right child\n        # true if I am a leaf (could have probably derived this from if I have\n        # a word)\n        self.isLeaf = False\n        # true if we have finished performing fowardprop on this node (note,\n        # there are many ways to implement the recursion.. some might not\n        # require this flag)\n```\n\nThe tensorflow contributions, there are few parts:\n(1) Variable creation (**NOTE**: `saver.restore(sess, './weights/%s.temp'%self.config.model_name)` is used to reload state) :\n\n```\n    def add_model_vars(self):\n        '''\n        You model contains the following parameters:\n            embedding:  tensor(vocab_size, embed_size)\n            W1:         tensor(2* embed_size, embed_size)\n            b1:         tensor(1, embed_size)\n            U:          tensor(embed_size, output_size)\n            bs:         tensor(1, output_size)\n        Hint: Add the tensorflow variables to the graph here and *reuse* them while building\n                the compution graphs for composition and projection for each tree\n        Hint: Use a variable_scope \"Composition\" for the composition layer, and\n              \"Projection\") for the linear transformations preceding the softmax.\n        '''\n        with tf.variable_scope('Composition'):\n            ### YOUR CODE HERE\n            #initializer=initializer=tf.random_normal_initializer(0,3)\n            embedding = tf.get_variable(\"embedding\",\n                                        [self.vocab.total_words, self.config.embed_size])\n            W1 = tf.get_variable(\"W1\", [2 * self.config.embed_size, self.config.embed_size])\n            b1 = tf.get_variable(\"b1\", [1, self.config.embed_size])\n            ### END YOUR CODE\n        with tf.variable_scope('Projection'):\n            ### YOUR CODE HERE\n            U = tf.get_variable(\"U\", [self.config.embed_size, self.config.label_size])\n            bs = tf.get_variable(\"bs\", [1, self.config.label_size])\n            ### END YOUR CODE\n```\n\n(2) model construction:\n\n```\ndef add_model(self, node):\n        \"\"\"Recursively build the model to compute the phrase embeddings in the tree\n\n        Hint: Refer to tree.py and vocab.py before you start. Refer to\n              the model's vocab with self.vocab\n        Hint: Reuse the \"Composition\" variable_scope here\n        Hint: Store a node's vector representation in node.tensor so it can be\n              used by it's parent\n        Hint: If node is a leaf node, it's vector representation is just that of the\n              word vector (see tf.gather()).\n        Args:\n            node: a Node object\n        Returns:\n            node_tensors: Dict: key = Node, value = tensor(1, embed_size)\n        \"\"\"\n        with tf.variable_scope('Composition', reuse=True):\n            ### YOUR CODE HERE\n            embedding = tf.get_variable(\"embedding\")\n            W1 = tf.get_variable(\"W1\")\n            b1 = tf.get_variable(\"b1\")\n            l2_loss = tf.nn.l2_loss(W1) + tf.nn.l2_loss(b1)\n            tf.add_to_collection(name=\"l2_loss\", value=l2_loss)\n            ### END YOUR CODE\n\n        W_split = tf.split(0, 2, W1)\n        W_left  = W_split[0]\n        W_right = W_split[1]\n        node_tensors = OrderedDict()\n        curr_node_tensor = None\n        if node.isLeaf:\n            ### YOUR CODE HERE\n            word_id = self.vocab.encode(node.word)\n            curr_node_tensor = tf.expand_dims(tf.gather(embedding, word_id),0)\n            ### END YOUR CODE\n        else:\n            node_tensors.update(self.add_model(node.left))\n            node_tensors.update(self.add_model(node.right))\n            ### YOUR CODE HERE\n            #This operation could be done without the split call above\n            #child_tensor = tf.concat(1, [node_tensors[node.left], node_tensors[node.right]])\n            #curr_node_tensor = tf.nn.relu(tf.matmul(child_tensor, W1) + b1)\n            curr_node_tensor = tf.matmul(node_tensors[node.left], W_left) + tf.matmul(node_tensors[node.right], W_right) + b1\n            ### END YOUR CODE\n        node_tensors[node] = curr_node_tensor\n        return node_tensors\n```\n\n(3) the projection layer is used to construct the sentiment for the root node:\n\n```\n    def add_projections(self, node_tensors):\n        \"\"\"Add projections to the composition vectors to compute the raw sentiment scores\n\n        Hint: Reuse the \"Projection\" variable_scope here\n        Args:\n            node_tensors: tensor(?, embed_size)\n        Returns:\n            output: tensor(?, label_size)\n        \"\"\"\n        logits = None\n        ### YOUR CODE HERE\n        with tf.variable_scope(\"Projection\", reuse=True):\n            U = tf.get_variable(\"U\")\n            bs = tf.get_variable(\"bs\")\n        logits = tf.matmul(node_tensors, U) + bs\n        ### END YOUR CODE\n        return logits\n```\n\n(4) loss (note: that you can use all the nodes, or just the root node for inference):\n `tf.reduce_sum(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=labels))`,\nwhere `logits` is given by a call to `inference`\n\n```\n    def inference(self, tree, predict_only_root=False):\n        \"\"\"For a given tree build the RNN models computation graph up to where it\n            may be used for inference.\n        Args:\n            tree: a Tree object on which to build the computation graph for the RNN\n        Returns:\n            softmax_linear: Output tensor with the computed logits.\n        \"\"\"\n        node_tensors = self.add_model(tree.root)\n        if predict_only_root:\n            node_tensors = node_tensors[tree.root]\n        else:\n            node_tensors = [tensor for node, tensor in node_tensors.items() if node.label!=2]\n            node_tensors = tf.concat(0, node_tensors)\n        return self.add_projections(node_tensors)\n```\n", "Thanks for posting this, @kingtaurus! This is quite useful for me.\nIf I'm not mistaken, your code constructs a tensorflow expression on a per-tree basis.\nI think it would be more efficient to use control flow mechanisms to collect the tensors at each node and send them through a single previously defined network in batches.\nBut it seems that implementing it this way is quite tricky.\n", "@ibab - Yup, you're correct about the per-tree basis. I believe that this gives a non-ideal starting point for how to implement recursive structure in tensorflow. Right now it's problematic because the graph state has to be cleared (since each tree gets a graph, some memory may be allocated, so this has to be dealt with) and then reloaded. I think trying to shoe-horn in the other flow-control operations might be bad idea (this really doesn't fall into any of the operations like `tf.map_fn`, `tf.scan`, or `tf.foldl` or `tf.foldr`). I guess you could try using `tf.case` and `tf.while_loop` but that looks like a pain.\n\nThere are few things that need to be implemented:\n(1) recursive descent graph construction (based upon 'node' type and 'loss' type). This become even more complex if you need things like attention. Ideally I would like something like,\n`tf.walk( leaf_func, node_func, output_func, tree_storage, output_style=\"root_only | all \")`\n\n(2) dynamic construction of and freeing of the computation graphs (you can't maintain all the possible allocated graphs in memory, but you can use flyweights and have an allocatation pool for storage).\n\n(3) tensorboard interface/display changes to handle this new 'dynamic' graph behavior.\n", "You can use a while loop with TensorArray.  What you need to do is find an indexing structure mapping a linear index to nodes of the tree and back.\n", "@ebrevdo: I thought about doing that at first, for example using heap indexing (or something more clever to deal with trees that are not complete).\nThe problem I had is that each single example in the dataset can have a different shape.\nE.g. if we want to do sentiment analysis on sentences, then the number of words can be different in each sentence and the structure of each tree depends on how the corresponding sentence was parsed.\nOr maybe I've misunderstood your idea?\n\nI think a `TensorTrees` data structure that's similar in spirit to `TensorArray` could be a nice API.\nIt could hold a number of trees (different tree structure for each example), and batch together all inputs/outputs that can currently be evaluated.\n(Note that not all nodes inside a tree can be evaluated at the same time, as we need don't know the inputs for the upper levels of the tree at first).\nThen a while loop could be used to manage the step by step evaluation of all trees.\nIt could work something like this (in pseudocode):\n\n```\ntrees = TensorTrees()\nwhile not trees.is_fully_evaluated():\n  inputs, outputs = trees.get_batch(max_batch_size=1000)\n  # Process inputs and store result in outputs\n```\n\nThis would evaluate the lower levels of the trees in the first few batches, and then move upwards in later batches.\nNot sure whether it would make sense to put this into the tensorflow core, maybe [tensorflow/models](https://github.com/tensorflow/models) would be a better location.\n", "I also followed the example in CS224D until I hit a wall when trying to do mini-batching. My graph and dataset are both so large that rebuilding the graph for each tree and running them one at a time is just not feasible. I also thought about using a while_loop, but I don't see how this can work since the incoming trees have different sizes, as @ibab mentioned.\n", "Even if we don't support a Tree datatype right away, I'd think that a way to perform recursion in-graph would be sufficient to at least allow for a working solution. Then we could arrange the trees linearly and use gather recursively to interact with the computed tensors. It looks like theano doesn't even support true recursion, so perhaps this alone is a really hard problem.\n", "I've been working with tree-structured examples on tensorflow using Control Flow ops.  While I haven't implemented the Socher et al. 2011 paper, I use the indexing structure to represent edges between nodes.  Something like:\n\n```\n  state = ta.TensorArray( tf.float32, size=1, dynamic_size=True, infer_shape=False, clear_after_read=False)\n\n  # A super-simple tree:\n  #       1   2   3\n  #        \\   \\ /\n  #         \\   -\n  #          \\ /\n  #           -\n  node_features = [1.0, 2, 3]\n  state = state.unpack(node_features)\n  edges = [[1, 2, 3], [0, 3, 4]]\n\n  def body(pos, state):\n    edge = tf.gather(edges, pos)\n    left_idx, right_idx, out_idx = tf.unpack(edge)\n    # In the real-world we'd do something more useful that just tf.sub...\n    out_state = tf.sub(state.read(left_idx), state.read(right_idx))\n    return pos + 1, state.write(out_idx, out_state)\n\n  def cond(pos, _):\n    return tf.less(pos, len(edges))\n\n  _, res = tf.while_loop(cond, body, [tf.constant(0), state])\n  with tf.Session():\n    print(res.pack().eval())\n```\n\nIn order to generalize this type of processing and make it scale there is work in progress exploring support for things like:\n- efficient batching - processing more than one edge at a time;\n- parsing structured examples into edge and vertex tensors (kind of like tf.parse_example where one specifies in what order to traverse the tree etc.); and, \n- higher-level ops for traversing/backpropagating structured examples.  (This might well include something in the direction of what @ibab mentioned with a TensorTree.)\n", "Awesome, thanks for sharing this!\nI never thought of solving it this way, where the traversal instructions are \"pre-packaged\" by the operator that parses the examples.\n", "This feels like it is more appropriate as a StackOverflow thread, not github issues.\n", "Here's the StackOverflow question I created originally: http://stackoverflow.com/questions/37054188/how-can-i-implement-a-recursive-neural-network-in-tensorflow\n\nI thought that the issue might be appropriate as a feature request.\nFeel free to close this issue if you prefer.\n", "@ibab did you manage to implement the recursive net this way? How did it end up?", "There's a TensorFlow library in the works that can do data-dependent computation using a single graph -- https://openreview.net/pdf?id=ryrGawqex", "@yaroslavvb Thanks for the pointer, really nice work! Are there plans to open source TensorFlow Fold in the near future?\r\n\r\nOn Fri, Dec 30, 2016 at 9:07 AM, Yaroslav Bulatov <notifications@github.com>\r\nwrote:\r\n\r\n> There's a TensorFlow library in the works that can do data-dependent\r\n> computation using a single graph -- https://openreview.net/pdf?id=\r\n> ryrGawqex\r\n>\r\n> \u2014\r\n> You are receiving this because you are subscribed to this thread.\r\n> Reply to this email directly, view it on GitHub\r\n> <https://github.com/tensorflow/tensorflow/issues/2237#issuecomment-269795678>,\r\n> or mute the thread\r\n> <https://github.com/notifications/unsubscribe-auth/AAlivg-YwZgjxt9s523qYxAS3bxqG5Ysks5rNTpOgaJpZM4IYHB2>\r\n> .\r\n>\r\n", "The paper says it'll be made available with the final version of the ICLR submission, so I guess sometime before Feb 2nd?", "@ibab I believe that this can now be solved using just `tf.while_loop` and then making sure your data is appropriately formatted. Using the idea from @bogatyy [cs224d/repo](https://github.com/bogatyy/cs224d/tree/master/assignment3) - I  modified it so that it doesn't require storage in a `tf.TensorArray` (the `while_loop` iteration is used for storage). Below is a rough sketch of a solution.\r\n\r\n```python\r\n    # private functions used to construct the graph.\r\n    def _embed_word(self, word_index):\r\n        with tf.variable_scope(\"Composition\", reuse=True) as scope:\r\n            embedding = tf.get_variable(\"embedding\")\r\n        return tf.expand_dims(tf.gather(embedding, word_index), 0)\r\n\r\n    # private functions used to construct the graph.\r\n    def _combine_children(self, tensor_concat, left_idx, right_idx):\r\n        left_tensor = tf.expand_dims(tf.gather(tensor_concat, left_idx), 0)\r\n        right_tensor = tf.expand_dims(tf.gather(tensor_concat, right_idx), 0)\r\n        with tf.variable_scope('Composition', reuse=True):\r\n            W1 = tf.get_variable('W1')\r\n            b1 = tf.get_variable('b1')\r\n        return tf.nn.relu(tf.matmul(tf.concat(1, [left_tensor, right_tensor]), W1) + b1)\r\n\r\n    def _loop_over_tree(self, i, tensor_list):\r\n        is_leaf = tf.gather(self.is_a_leaf, i)\r\n        word_idx    = tf.gather(self.word_index, i)\r\n        left_child  = tf.gather(self.left_child, i)\r\n        right_child = tf.gather(self.right_child, i)\r\n        node_tensor = tf.cond(is_leaf, lambda : self._embed_word(word_idx),\r\n                                       lambda : self._combine_children(tensor_list, left_child, right_child))\r\n        tensor_list = tf.concat(0, [tensor_list, node_tensor])\r\n        i = tf.add(i,1)\r\n        return i, tensor_list\r\n\r\n    def construct_tensor_array(self):\r\n        loop_condition = lambda i, tensor_array: \\\r\n                         tf.less(i, tf.squeeze(tf.shape(self.is_a_leaf)))\r\n        \r\n        left_most_element = self._embed_word(tf.gather(self.word_index, 0))\r\n        #index should start @ 1\r\n        i1 = tf.constant(1, dtype=tf.int32)\r\n\r\n        while_loop_op = tf.while_loop(cond=loop_condition,\r\n                                       body=self._loop_over_tree,\r\n                                       loop_vars=[i1, left_most_element],\r\n                                       shape_invariants=[i1.get_shape(), tf.TensorShape([None,50])])\r\n        \r\n        return while_loop_op[1]\r\n```\r\n\r\nwhere,\r\n```python\r\n        self.is_a_leaf   = tf.placeholder(tf.bool, [None], name=\"is_a_leaf\")\r\n        self.left_child  = tf.placeholder(tf.int32, [None], name=\"lchild\")\r\n        self.right_child = tf.placeholder(tf.int32, [None], name=\"rchild\")\r\n        self.word_index  = tf.placeholder(tf.int32, [None], name=\"word_index\")\r\n        self.labelholder = tf.placeholder(tf.int32, [None], name=\"labels_holder\")\r\n```\r\n\r\nand the feed dictionary is built as follows:\r\n```python\r\n    def build_feed_dict(self, in_node):\r\n        nodes_list = []\r\n        tr.leftTraverse(in_node, lambda node, args: args.append(node), nodes_list)\r\n        node_to_index = OrderedDict()\r\n        for idx, i in enumerate(nodes_list):\r\n            node_to_index[i] = idx\r\n\r\n        feed_dict = {\r\n          self.is_a_leaf   : [ n.isLeaf for n in nodes_list ],\r\n          self.left_child  : [ node_to_index[n.left] if not n.isLeaf else -1 for n in nodes_list ],\r\n          self.right_child : [ node_to_index[n.right] if not n.isLeaf else -1 for n in nodes_list ],\r\n          self.word_index  : [ self.vocab.encode(n.word) if n.word else -1 for n in nodes_list ],\r\n          self.labelholder : [ n.label for n in nodes_list ]\r\n        }\r\n        return feed_dict\r\n```\r\n\r\n", "FYI we just released [TensorFlow Fold](github.com/tensorflow/fold/). [This notebook](https://github.com/tensorflow/fold/blob/master/tensorflow_fold/g3doc/sentiment.ipynb) shows how to implement a recursive neural network.", "Looks good. So this implementation assumes that the tree is known a-priori, doesn't it?\r\nSo it maps (embeddings, tree) to (sentiment).\r\n\r\nWould it also be able to map (embeddings) to (tree,sentiment)? because that is what [the paper which OP refers to](http://www.socher.org/index.php/Main/ParsingNaturalScenesAndNaturalLanguageWithRecursiveNeuralNetworks) is doing", "Great question. You're right, this example does assume that the tree structure is part of the input. The particular model in the Socher paper that generates trees can be implemented with Fold, because the shape of the computation graph is a function of the input data (I'm assuming here that the terminals and adjacency matrix are provided as inputs to the model).\r\n\r\nHowever Fold in its current form will not help with arbitrary \"computation-dependent-computation\" e.g. a complete generative model for trees.", "@moshelooks strong answer. thanks for the info", "I'm closing to this bug as fixed for now given Fold.  Further requests for fold features should be filed at https://github.com/tensorflow/fold."]}, {"number": 2236, "title": "Can't separate by sentences when running word2vec model?", "body": "In gensim word2vec, the input can be a list of sentences. However, in tensorflow word2vec, the input is a list of words (concatenate sentences together). Can you add the feature to separate by sentences to word2vec?\n I am using the following code: https://github.com/tensorflow/tensorflow/blob/r0.8/tensorflow/models/embedding/word2vec.py\n", "comments": ["Adding @a-dai to comment. \n", "@a-dai can confirm, but I don't think anyone is working on this at the moment.  PRs are welcome, though! \n", "However, since this is about tensorflow/models, not tensorflow/tensorflow, it should be refiled at the right repo.\n"]}, {"number": 2235, "title": "'module' object has no attribute 'conv3d' but only in Jupyter Notebook", "body": "Hi! This isn't really a bug, but more a support request.\n\nI tried to use the new conv3d operations from 6a187ccddaebb741ea77fc3201c6e36625f0aadb, so I built a pip wheel from the latest sources, created a virtualenv called \"tensorflow-dev\" and instlled the wheel there.\n\nNow I am running into weirdness that I cannot explain...\n\nPython works:\n\n```\n$ python3\nPython 3.5.1 (default, Mar  7 2016, 18:39:06) \n[GCC 5.3.1 20151207 (Red Hat 5.3.1-2)] on linux\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>> import tensorflow as tf\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally\n>>> tf.nn.conv3d\n<function conv3d at 0x7fb58acc3400>\n>>> \n```\n\nIpython works:\n\n```\n$ ipython3\nPython 3.5.1 (default, Mar  7 2016, 18:39:06) \nType \"copyright\", \"credits\" or \"license\" for more information.\n\nIPython 4.2.0 -- An enhanced Interactive Python.\n?         -> Introduction and overview of IPython's features.\n%quickref -> Quick reference.\nhelp      -> Python's own help system.\nobject?   -> Details about 'object', use 'object??' for extra details.\n\nIn [1]: import tensorflow as tf\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally\n\nIn [2]: tf.nn.conv3d\nOut[2]: <function tensorflow.python.ops.gen_nn_ops.conv3d>\n```\n\nBut the Jupyter notebook does not!!\n\n```\nIn [1]: import tensorflow as tf\nIn [2]: tf.nn.conv3d\n---------------------------------------------------------------------------\nAttributeError                            Traceback (most recent call last)\n<ipython-input-2-9e3b7db30b11> in <module>()\n----> 1 tf.nn.conv3d\n\nAttributeError: 'module' object has no attribute 'conv3d'\n```\n\nAll three were started form the same shell, after activating the same virtualenv. I really can't explain this. Does anyone have any ideas what's wrong with my install?\n", "comments": ["Can you check the output of `which ipython3` to see if it is running the version inside your virtualenv? You may need to install it inside your virtualenv (e.g. using `pip install`) to get it to work.\n", "@mrry \n\n```\n$ which ipython3\n~/.virtualenvs/tensorflow-dev/bin/ipython3\n\n$ which jupyter\n~/.virtualenvs/tensorflow-dev/bin/jupyter\n\n$ which python3\n~/.virtualenvs/tensorflow-dev/bin/python3\n```\n\nthe latter being a link to python3.5\n\nI think I am having troubles with my jupyter install... Ipython and python3.5 use Python 3.5, but from within the Jupyter notebook:\n\n```\n>>> import sys\n>>> print(sys.version)\n3.4.3 (default, Mar 31 2016, 20:42:37) \n[GCC 5.3.1 20151207 (Red Hat 5.3.1-2)]\n```\n\nThis is very strange. I will investigate further.\n", "So here is what happened: somehow, something installed a kernelspec for Jupyter in /usr/local/share/jupyter/kernels for my old python3.4 installation. I deleted the Kernelspec there, and Jupyter and the import of tf.nn.conv3d started working.\n\nSorry for the inconvenience.\n", "Can i ask you something? \n\nIn my case, There was a same error, 'module' object has no attribute 'conv3d'.\nI used jupyter notebook and shell to run tf.nn.conv3d, but coudn't run it.\nI typed this code \" print(sys.version) \".\nThe result is 2.7.6 (default, Jun 22 2015, 17:58:13) \nShould i install another version of python in my computer to run tf.nn.conv3d?? \n", "@power9694 \n\nNo, python 2.7 should definitely work with TensorFlow. What is your TensorFlow version?\nconv3d should be present from version 0.9 on.\n\nCould you run the following code:\n\n```\nimport tensorflow\nprint(tensorflow.__version__)\nprint(tensorflow.__path__)\n```\n", "@akors \n\nI actually runned the code, print(tensorflow.**version**), and found that version of the tensorflow in my computer was 0.8.0. \nAfter i updated the version, i can run tf.nn.conv3d well.\nVery thank you for your advice. :)\n", "@akors \r\n\r\ncould you please go in to a little more detail about how to delete this kernel spec thing?\r\nI'm new to tf. Thanks!", "Actually ignore that. I solved it by removing tensorflow and then reinstalling! I think it's because I installed the gpu and cpu versions then removed the cpu version to be left with a non-functional gpu version.\r\n\r\nOr maybe it's just magic."]}, {"number": 2234, "title": "`_tanh(x)` returns different values for the same `x`", "body": "Why is the last one (`0.99505478`) different from the first four?\n\n``` python\n>>> import tensorflow as tf\n>>> from tensorflow.python.ops.gen_math_ops import _tanh\n>>> a = tf.ones([1, 3], tf.float32)\n>>> b = tf.ones([3, 5], tf.float32)\n>>> c = tf.matmul(a, b)\n>>> sess = tf.Session()\n>>> print(sess.run(_tanh(c)))\n[[ 0.99505472  0.99505472  0.99505472  0.99505472  0.99505478]]\n```\n\nWith `tf.float64`, the values are all `0.99505475`.\n", "comments": ["Can't reproduce, tried on Z420 and Z840 machines and TF at head.\n\nAre you using GPU?\n\n```\nimport tensorflow as tf\nwith tf.device(\"/cpu:0\"):\n  a = tf.ones([1, 3], tf.float32)\n  b = tf.ones([3, 5], tf.float32)\nsess = tf.Session()\nprint(sess.run(tf.tanh(tf.matmul(a, b))))\n\n[[ 0.99505478  0.99505478  0.99505478  0.99505478  0.99505478]]\n```\n", "I get the same result even with your code specifying `tf.device(\"/cpu:0\")`.\nI am using 0.8.0 in the VirtualBox image of Ubuntu (`vagrant-ubuntu-vivid-64 3.19.0-10-generic #10-Ubuntu SMP`).\n", "Can you try and see if it's still non-deterministic when using with less threads\n\n```\nimport tensorflow as tf\nwith tf.device(\"/cpu:0\"):\n  a = tf.ones([1, 3], tf.float32)\n  b = tf.ones([3, 5], tf.float32)\n  c = tf.tanh(tf.matmul(a, b))\nconfig = tf.ConfigProto(inter_op_parallelism_threads=1, intra_op_parallelism_threads=1)\nsess = tf.Session(config=config)\nprint(sess.run(c))\n```\n", "I can reproduce it (in python 3.5.1):\n![image](https://cloud.githubusercontent.com/assets/901975/15057830/71bdc75e-134b-11e6-83d2-f451ee11d611.png)\n\nIt's getting interesting when I change the input size to 10:\n\n![image](https://cloud.githubusercontent.com/assets/901975/15057856/890356b8-134b-11e6-8265-a45179fbe818.png)\n\nwith 100, the problem is gone:\n![image](https://cloud.githubusercontent.com/assets/901975/15057865/9a53da64-134b-11e6-9dc6-10cfe1f38bc2.png)\n", "Hm, could it be numpy display issue? What if you do\n\n```\nimport tensorflow as tf\nwith tf.device(\"/cpu:0\"):\n  a = tf.ones([1, 3], tf.float32)\n  b = tf.ones([3, 5], tf.float32)\n  c = tf.log(tf.tanh(tf.matmul(a, b))-0.99505478)/tf.log(2.)\nconfig = tf.ConfigProto(inter_op_parallelism_threads=1, intra_op_parallelism_threads=1)\nsess = tf.Session(config=config)\nprint(sess.run(c))\n```\n\nI see\n`[[-inf -inf -inf -inf -inf]]`\n", "I suspect eigen packet/vector vs non vector difference. Inputs mod 4 will\nbe the same, the remainder will be different because it uses a different\ncode path?\n\nOn Thu, May 5, 2016, 3:37 PM Yaroslav Bulatov notifications@github.com\nwrote:\n\n> Hm, could it be numpy display issue? What if you do\n> \n> import tensorflow as tf\n> with tf.device(\"/cpu:0\"):\n> \n> a = tf.ones([1, 3], tf.float32)\n> b = tf.ones([3, 5], tf.float32)\n> \n> c = tf.log(tf.tanh(tf.matmul(a, b))-0.99505478)/tf.log(2.)\n> \n> config = tf.ConfigProto(inter_op_parallelism_threads=1,\n> intra_op_parallelism_threads=1)\n> sess = tf.Session(config=config)\n> print(sess.run(c))\n> \n> \u2014\n> \n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly or view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/2234#issuecomment-217287498\n", "@benoitsteiner @rmlarsen for comment?\n\nOn Thu, May 5, 2016, 3:40 PM Vijay Vasudevan vrv@google.com wrote:\n\n> I suspect eigen packet/vector vs non vector difference. Inputs mod 4 will\n> be the same, the remainder will be different because it uses a different\n> code path?\n> \n> On Thu, May 5, 2016, 3:37 PM Yaroslav Bulatov notifications@github.com\n> wrote:\n> \n> > Hm, could it be numpy display issue? What if you do\n> > \n> > import tensorflow as tf\n> > with tf.device(\"/cpu:0\"):\n> > \n> > a = tf.ones([1, 3], tf.float32)\n> > b = tf.ones([3, 5], tf.float32)\n> > \n> > c = tf.log(tf.tanh(tf.matmul(a, b))-0.99505478)/tf.log(2.)\n> > \n> > config = tf.ConfigProto(inter_op_parallelism_threads=1,\n> > intra_op_parallelism_threads=1)\n> > sess = tf.Session(config=config)\n> > print(sess.run(c))\n> > \n> > \u2014\n> > \n> > You are receiving this because you are subscribed to this thread.\n> > Reply to this email directly or view it on GitHub\n> > https://github.com/tensorflow/tensorflow/issues/2234#issuecomment-217287498\n", "We have an optimized version of the tanh function that processes coefficients 4 by 4. In a tensor of 10 elements we call that function twice to process the 8 first element, and we process the last 2 elements one by one by calling std::tanh. std::tanh and our optimized versions don't fully agree on the final result, which is why the last 2 coefficients are slightly different from the rest.\n\nWhen the input contains 100 elements, we simply call the optimized version of tanh 25 times, so all the results match.\n", "Contributions welcome to fix this to be consistent!\n", "I'll work on this\n", "I find that SSE2 vectorization is a feature of eigen, so adding addtional code to tensorflow may be a good choice.\n", "one eigen's core dev pushed [some update](https://bitbucket.org/eigen/eigen/pull-requests/215/fix_tanh_inconsistent_for_tensorflow/diff) to tanh.\n", "I've confirmed that this is now fixed.\n"]}, {"number": 2233, "title": "protobuf message overflow on trying distributed ", "body": "I'm trying to build an RNN on multi-machines following the [Distributed Tensorflow](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/how_tos/distributed/index.md). \nwhen I use \"with sv.managed_session(server.target) as sess:\", it shows error:\nAttributeError: 'Supervisor' object has no attribute 'managed_session'\nSo I follow the code of \"Inception\":\nwith sv.prepare_or_wait_for_session(server.target, config = sess_config) as sess :\n\nThen it starts to run, but hangs immediately after reporting the following error:\n\n[libprotobuf WARNING google/protobuf/src/google/protobuf/io/coded_stream.cc:569] Reading dangerously large protocol message.  If the message turns out to be larger than 67108864 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.\n[libprotobuf ERROR google/protobuf/src/google/protobuf/io/coded_stream.cc:207] A protocol message was rejected because it was too big (more than 67108864 bytes).  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.\n[libprotobuf WARNING google/protobuf/src/google/protobuf/io/coded_stream.cc:81] The total number of bytes read was 67108864\nE tensorflow/core/framework/tensor.cc:105] Input size was 67108839 and expected 72000800\n\nWould you please help me on this?\nThanks a lot in advance!\n", "comments": ["Thanks for letting us know about this - it sounds like a bug in the tensor serialization code, but to figure out what's going wrong, we're going to need more information:\n1. Can you pinpoint the line of Python on which it hangs? (Does it hang on the `sv.prepare_or_wait_for_session()` or does it hang when you try to run something?)\n2. Is there an obviously-large tensor in your program? Does it exist as a `tf.constant()`, a numpy array that is implicitly converted to a `tf.constant()`, a value that is fed into the graph, or could it be a result that you're fetching? (Looking at the expected size, 72000800 bytes, I'm guessing that it's a tensor with size 90001 in one dimension, maybe a 200 x 90001 matrix of floats?) All of these cases should be handled, but this will help to construct a minimal failing test case.\n3. Can you try running the code in the following tests from [`server_lib_test.py`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/server_lib_test.py) in your environment: `testLargeConstant()`, `testLargeFetch()`, and `testLargeFeed()`.\n", "Thanks very much for your quick response!\n1. It passes sv.prepare_or_wait_for_session() and hangs in session.run(...)\n2. Yes. I just follow the tutorial [ptb_word_lm.py](https://www.tensorflow.org/versions/r0.8/tutorials/recurrent/index.html#recurrent-neural-networks)  RNN model and made just a little modification to make it do classfication work. The \"embedding\" is 90001*200 floats. The embedding definition is just same as ptb_word_lm.py:\n   \n   with tf.device(\"/cpu:0\"):\n     embedding = tf.get_variable(\"embedding\", [vocab_size, size]) # [90001, 200] in my code.\n     inputs = tf.nn.embedding_lookup(embedding, self._input_data)\n3. I run your code with \"python ./server_lib_test.py\", after showing a lot of log messages, it shows the following message:\n\n## .......\n\nRan 12 tests in 4.028s\n\nOK\n\nWhen I try to decease the \"embedding\" matrix to smaller size such as [101, 200], it never hangs and  run correctly.\nI run the [90001, 200] again today, the warning message \"Input size was 67108839 and expected 72000800\" still shows but it don't hang again. I don't known why...\n\nBTW, is there any RNN sample code that could run on multi-cards(multi-tower style) or distributed multi-machines? I tried to port multi-tower from CIFAR-10 example code to my RNN code, after 1 week's work I failed(I'll report the bugs in another issue). Then I gave up and turn to distributed style. The \"Inception\" example code needs BIG data set ILSVRC2012 and it's time consuming to download the data(especially from China...). Since RNN is especially usefull in many application domains, would you mind show me the multi-cards or multi-machines existing code if you know?\n\nWhen I decrease the embedding size to [101, 200], it starts running. But still it can't fully use my 4 GPU cards in the machine. There is only 1 card with more than 0% usage. Would you mind giving me an email then I can send my code to you?\n\nThanks a lot again for your time!\n", "@mrry \nIn order to make you easier to reproduce the bug, I just take  [ptb_word_lm.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/rnn/ptb/ptb_word_lm.py) as example. I added Async-Distributed tensorflow code to it.\nI run it by using 1 ps-server and 2 workers, all of them on the same node:\n\n```\nCUDA_VISIBLE_DEVICES='' python ./ptb_word_lm.py --ps_hosts=\"10.141.33.61:2222\" --worker_hosts=\"10.141.33.61:2223,10.141.33.61:2224\" --job_name=ps --task_index=0\npython ./ptb_word_lm.py --ps_hosts=\"10.141.33.61:2222\" --worker_hosts=\"10.141.33.61:2223,10.141.33.61:2224\" --job_name=worker --task_index=0 --data_path=.\npython ./ptb_word_lm.py --ps_hosts=\"10.141.33.61:2222\" --worker_hosts=\"10.141.33.61:2223,10.141.33.61:2224\" --job_name=worker --task_index=1 --data_path=.\n```\n\nWhen I set \"vocab_size\" to bigger than 83887, (83887*200*4>67108864), it shows the following error(job crash by most cases, but not always crash):\n\n```\nI tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:202] Started server with target: grpc://localhost:2223\nEpoch: 1 Learning rate: 0.000\n[libprotobuf WARNING google/protobuf/src/google/protobuf/io/coded_stream.cc:569] Reading dangerously large protocol message.  If the message turns out to be larger than 67108864 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.\n[libprotobuf ERROR google/protobuf/src/google/protobuf/io/coded_stream.cc:207] A protocol message was rejected because it was too big (more than 67108864 bytes).  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.\n[libprotobuf WARNING google/protobuf/src/google/protobuf/io/coded_stream.cc:81] The total number of bytes read was 67108864\nE tensorflow/core/framework/tensor.cc:105] Input size was 67108839 and expected 67109600\n[libprotobuf WARNING google/protobuf/src/google/protobuf/io/coded_stream.cc:569] Reading dangerously large protocol message.  If the message turns out to be larger than 67108864 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.\n[libprotobuf ERROR google/protobuf/src/google/protobuf/io/coded_stream.cc:207] A protocol message was rejected because it was too big (more than 67108864 bytes).  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.\n[libprotobuf WARNING google/protobuf/src/google/protobuf/io/coded_stream.cc:81] The total number of bytes read was 67108864\n[libprotobuf WARNING google/protobuf/src/google/protobuf/io/coded_stream.cc:569] Reading dangerously large protocol message.  If the message turns out to be larger than 67108864 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.\n[libprotobuf ERROR google/protobuf/src/google/protobuf/io/coded_stream.cc:207] A protocol message was rejected because it was too big (more than 67108864 bytes).  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.\n[libprotobuf WARNING google/protobuf/src/google/protobuf/io/coded_stream.cc:81] The total number of bytes read was 67108864\nE tensorflow/core/framework/tensor.cc:105] Input size was 67108839 and expected 67109600\nTraceback (most recent call last):\n  File \"./ptb_word_lm.py\", line 358, in <module>\n    tf.app.run()\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 30, in run\n    sys.exit(main(sys.argv))\n  File \"./ptb_word_lm.py\", line 355, in main\n    run_worker(server, cluster)\n  File \"./ptb_word_lm.py\", line 335, in run_worker\n    verbose=True)\n  File \"./ptb_word_lm.py\", line 264, in run_epoch\n    m.lr : cur_lr })\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 340, in run\n    run_metadata_ptr)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 564, in _run\n    feed_dict_string, options, run_metadata)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 637, in _do_run\n    target_list, options, run_metadata)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 659, in _do_call\n    e.code)\ntensorflow.python.framework.errors.AbortedError: Step 79814040532157923\n     [[Node: model/clip_by_global_norm/model/clip_by_global_norm/_5_S67 = _Recv[client_terminated=false, recv_device=\"/job:ps/replica:0/task:0/cpu:0\", send_device=\"/job:worker/replica:0/task:0/gpu:0\", send_device_incarnation=67222584234197827, tensor_name=\"edge_9213_model/clip_by_global_norm/model/clip_by_global_norm/_5\", tensor_type=DT_FLOAT, _device=\"/job:ps/replica:0/task:0/cpu:0\"]()]]\n```\n\nWhen I set \"vocab_size\" to less than but near to 83886, (83886*200*4<67108864), it shows the warning:\n\n```\n[libprotobuf WARNING google/protobuf/src/google/protobuf/io/coded_stream.cc:81] The total number of bytes read was 67108834\n[libprotobuf WARNING google/protobuf/src/google/protobuf/io/coded_stream.cc:569] Reading dangerously large protocol message.  If the message turns out to be larger than 67108864 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.\n```\n\nIn our large-scale web mining job, we need to increase the word-embedding vocabulary size to millions of words. So we have no way but to solve this problem.\n\nMy code is here: ([reader.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/rnn/ptb/reader.py) is just from github and unchanged)\n[ptb_word_lm.py.txt](https://github.com/tensorflow/tensorflow/files/270704/ptb_word_lm.py.txt)\n", "Did you solve this problem? I have similar problem with my async-distributed word2vec.(79840 vocab, 300 dim)\n\n```\nI tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job ps -> {localhost:2422}\nI tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job worker -> {50.1.100.102:2432, 50.1.100.108:2432}\nI tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:202] Started server with target: grpc://localhost:2422\n[libprotobuf WARNING google/protobuf/src/google/protobuf/io/coded_stream.cc:569] Reading dangerously large protocol message.  If the message turns out to be larger than 67108864 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.\n[libprotobuf ERROR google/protobuf/src/google/protobuf/io/coded_stream.cc:207] A protocol message was rejected because it was too big (more than 67108864 bytes).  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.\n[libprotobuf WARNING google/protobuf/src/google/protobuf/io/coded_stream.cc:81] The total number of bytes read was 67108864\nE tensorflow/core/framework/tensor.cc:105] Input size was 67108839 and expected 95808000\n```\n", "I think the solution is in #582, the protobuf python package solution as the bottom of the thread doesn't seem to work for everyone as mentioned in #2046.\n", "Is it working for distributed version?\nI have checked that the protobuf warning/error message has gone for word2vec_optimized example.\nBut same problem occurs while running my own distributed word2vec_optimized.\n", "Hi folks, sorry for the delay on this one. We've tracked down the issue: the generated code for gRPC uses a [protobuf parsing routine](https://github.com/grpc/grpc/blob/305b0f4e2f99d2326bf1aaa881f857bb5fe1a817/include/grpc%2B%2B/impl/codegen/proto_utils.h#L209) that doesn't override the default 64MB limit.\n\nGenerally speaking, if your trainer is transferring large tensors in every step, there might be a more efficient way to implement it at the Python level. For example, instead of fetching a large fully connected layer to compute the logits, you might use a [sampled loss function](https://www.tensorflow.org/versions/r0.8/api_docs/python/nn.html#sampled-loss-functions), and you can use [`tf.nn.embedding_lookup()`](https://www.tensorflow.org/versions/r0.8/api_docs/python/nn.html#embedding_lookup) instead of [`tf.gather()`](https://www.tensorflow.org/versions/r0.8/api_docs/python/array_ops.html#gather) to more efficiently access sparse rows in an embedding matrix. Alternatively, you can shard your variables manually to avoid the limit.\n\nClearly, this isn't ideal, and we're working on a more robust fix.\n", "@swlsw , I use your codes(ptb_word_lm.py.txt) and run it on two machine. but i get the errror:RuntimeError: Graph is finalized and cannot be modified. I also run it by using 1 ps-server and 2 workers. hope to get yours help?\n"]}]