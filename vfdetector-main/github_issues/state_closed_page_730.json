[{"number": 31675, "title": "[Intel MKL] Upgrading curl to 7.65.3 to fix CVE-2019-5443", "body": "# [CVE-2019-5443](https://nvd.nist.gov/vuln/detail/CVE-2019-5443)\r\n\r\n**NVD:** 2019/07/02 - CVSS v2.0 Base Score: 4.6 - CVSS v3.0 Base Score: 7.8\r\n\r\n`A non-privileged user or program can put code and a config file in a known non-privileged path (under C:/usr/local/) that will make curl <= 7.65.1 automatically run the code (as an openssl \"engine\") on invocation. If that curl is invoked by a privileged user it can do anything it wants.`\r\n\r\n## References to Advisories, Solutions, and Tools\r\nSource | Link | Type\r\n---- | ---- | ----\r\nMLIST | [www.openwall.com](http://www.openwall.com/lists/oss-security/2019/06/24/1) | Mailing List, Patch, Third Party Advisory\r\nBID | [www.securityfocus.com](http://www.securityfocus.com/bid/108881) | Third Party Advisory, VDB Entry\r\nMISC | [curl.haxx.se](https://curl.haxx.se/docs/CVE-2019-5443.html) | Patch, Vendor Advisory\r\n\r\n", "comments": ["@mihaimaruseac @goldiegadde we should cherrypick this fix into 2.0 branch.", "I'll make a PR."]}, {"number": 31674, "title": "Move to cuDNN 7.6.2 and TensorRT 5.1.5", "body": "Nightly docker builds (TF 1.15 would also maybe end up broken) are currently broken because they are on cuDNN 7.4.1 but TensorFlow is being built with TensorRT 5.1.5.  \r\n\r\nWe will need to cherry pick this on to the TF 2.0 RC branch as soon as it is accepted.  \r\n\r\nI did the following testing:\r\n- Built all of the GPU docker files and the \"finished\"\r\n- Started the py3-gpu docker and ran some perfzero tests with success.  ", "comments": ["Thank you @tfboyd ! This will close #31622, though we need to include this fix in custom-op docker images as well cc @yifeif ", "@seanpmorgan  Point me to the Docker files and I will update them.  Maybe I will add a note to the TensorFlow docker README.md to not forget to update those.  I am in a Docker mood.  :-)", "> @seanpmorgan Point me to the Docker files and I will update them. Maybe I will add a note to the TensorFlow docker README.md to not forget to update those.\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/ci_build/Dockerfile.custom_op_ubuntu_16_gpu\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/ci_build/Dockerfile.custom_op_gpu\r\n\r\ncc @av8ramit ", "@seanpmorgan Ahh those use NVIDIA's nvidia/cuda:10.0-cudnn7-devel-ubuntu16.04.  That explains why they do not use the same process.  I would guess (CONFIRMED, see next comment) nvidia already moved those to 7.6.2; but I am feeling good and will give a look this morning and report back.  The good is they are likely updated faster than our offiical dockers, the bad is they may not always be aligned; which may be ok 95% of the time.  The 1% or 5% is the fun.  ", "libcudnn7/now 7.6.2.24-1+cuda10.0 amd64 [installed,local]\r\nlibcudnn7-dev/now 7.6.2.24-1+cuda10.0 amd64 [installed,local]\r\n\r\nAll good NVIDIA updated their docker.  I did a build of the custom op docker (ubuntu) and ran \r\n\r\n`apt list --installed | grep cuda`"]}, {"number": 31673, "title": "Make `maybe_set_static_shape` a no-op when `shape` is a python constant.", "body": "`maybe_set_static_shape` is only meant to handle cases that C++ shape inference cannot, which is when shape is a tensor that has a path to a captured placeholder inside a FuncGraph. So this change does not break any use-cases we care about.\r\nThis fixes an issue with creating spurious constants in the Graph which are unused after shape inference.\r\n\r\nPiperOrigin-RevId: 263666943", "comments": []}, {"number": 31672, "title": "r2.0-rc0 cherry-pick request: [INTEL MKL] Fix for Batchmatmul regression", "body": "Recently, TF added a BatchMatMulV2 op (which now is the default BatchMatMul). This caused a performance regression in TF-MKL because it didn't know how to convert BatchMatMulV2 op to its corresponding MKL BatchMatMul op. This PR fixes the regression by adding a rule to convert the  BatchMatMulV2 op to MKL op.\r\n\r\nNote from the original PR https://github.com/tensorflow/tensorflow/pull/31623:\r\nBatchMatmul now uses the BatchMatMulV2 operator, however TF+MKL hadn't been updated accordingly. Fixed this issue and also added missing unit tests. ", "comments": ["All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F31672) for more info**.\n\n<!-- need_author_consent -->", "A Googler has manually verified that the CLAs look good.\n\n(Googler, please make sure the reason for overriding the CLA status is clearly documented in these comments.)\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F31672) for more info**.\n\n<!-- cla_yes -->"]}, {"number": 31671, "title": " TF-TRT: Assertion `mParams.k > 0' failed.", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):binary\r\n- TensorFlow version (use command below):1.14\r\n- Python version:2.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:10.1\r\n- GPU model and memory:T4\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nSeeing the following error:\r\n```\r\n2019-08-16 03:21:42.299651: E tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:41] DefaultLogger Parameter check failed at: ../builder/Layers.cpp::TopKLayer::2009, condition: k > 0 && k <= MAX_TOPK_K\r\nb_engine-0: ../builder/Layers.cpp:2048: virtual bool nvinfer1::TopKLayer::validate(const std::vector<nvinfer1::TensorForm>&, const nvinfer1::NetworkLayer::ValidationContext&) const: Assertion `mParams.k > 0' failed.\r\n\r\n```\r\n**Describe the expected behavior**\r\n\r\nWhat is this error for  ? How to stop this from happening ? \r\n\r\n**Code to reproduce the issue**\r\n\r\nTry to create a snippet.\r\n\r\n**Other info / logs**\r\n\r\n", "comments": ["@sgambient ,\r\nIn order to expedite the trouble-shooting process, please provide complete code snippet to reproduce the issue reported here. Thanks!\r\n", "Will try to get a code snippet to reproduce this bug.    That is a  very time consuming and laborious process. There must be better and more efficient ways.   Is  there a way to get more verbose debug message to see what exactly is causing the problem ? ", "MAX_TOPK_K is the problem. What is this value, is there a way to adjust it ? ", "nvinfer1::TopKLayer::validate ()  is called  when tf.nn.top_k (    input, k=1, sorted=True, name=None) is   present. Setting k  =< 3000, seems to fix the problem.  The value for MAX_TOPK_K needs to be higher.", "@sgambient According to the TensorRT documentation, only k<=25 are supported.\r\nhttps://docs.nvidia.com/deeplearning/sdk/tensorrt-api/c_api/classnvinfer1_1_1_i_top_k_layer.html#abab2c02652dfacb19297e978b82cfcb2\r\n\r\nWhat value of k do you need in your model?\r\n\r\nAre you sure k is not 0 or negative in your runs, given that the error message says `mParams.k > 0`?", "Actually the upper limit for k is 3840, according to this doc: https://docs.nvidia.com/deeplearning/sdk/tensorrt-developer-guide/index.html#topk-layer\r\n\r\nPlease make sure k>0 in you test.", "The error message was not correct about which side is the problem for k.  In my case it was the upper limit , not 0.  ", "@sgambient Did the problem go away when you decrease k to <=3840?\r\n\r\nWhat version of TensorRT are you using?", "With k =3000 it worked. However, not ideal. Not sure about the exact version ( whatever comes with  the nvcr container for TF 1.14).  Is there a good way to find that out ? ", "I think there is an environment variable you can check `echo $TRT_VERSION`.", "TRT_VERSION=5.1.5.0", "I think this is fixed in TRT7.\r\n@sgambient would you be able to verify that?", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/31671\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/31671\">No</a>\n"]}, {"number": 31670, "title": "Make Tensorflow lite android project using tflite of ssd_mobilenet_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03 model", "body": "Hello, everyone.\r\nRecently I try to make android project of tensorflow lite object detection.\r\nI have successfully converted to tflite file from http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03.tar.gz, which uses 640*640 input image size.\r\nBut I have memory overflow error on running my project on the android mobile.\r\nIn my previous test, I can run 300*300, 224*224 tflite model on my android mobile.\r\nI use libtensorflowlite_gpu_jni.so and libtensorflowlite_jni.so distributed.\r\nCould anyone tell me the maximum value of tensorflow lite input image size?\r\nIf we can run 640*640 tflite model, what should I fix the android code?\r\nThanks in advance.\r\n\r\n\r\n ", "comments": ["My guess is that on your mobile device, you don't have enough memory to run this model.\r\nWe don't have a formula to calculate the runtime memory usage required for each model, but it should be easy to find it out - e.g. checking the ram usage of a process?", "@Wolf20199 \r\n\r\nLooks like issue is addressed.I am closing this issue. Please, feel free to reopen if the issue still persists.Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=31670\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=31670\">No</a>\n"]}, {"number": 31669, "title": "Failed to build pip package with syntax error ", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): centos\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source \r\n- TensorFlow version: master branch\r\n- Python version: 3.6\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\nwhen I try to build the tensorflow,with command\r\n```\r\nbazel-bin/tensorflow/tools/pip_package/build_pip_package $build_dir\r\n```\r\n I got the error \r\n```\r\nbazel-bin/tensorflow/tools/pip_package/build_pip_package: line 263: syntax error near unexpected token `done'\r\n```\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n```\r\nbazel-bin/tensorflow/tools/pip_package/build_pip_package $build_dir\r\n```\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["Ohhh, there goes a hot fix already\r\nhttps://github.com/tensorflow/tensorflow/commit/75a63b0527bb0ca9604a4e3f5a941e8f689c5fc9"]}, {"number": 31668, "title": "Models with tf.keras.layers.BatchNormalisation layers give errors when frozen, or are frozen incorrectly and cannot be loaded", "body": "This issue continues on from #31331 with a more wide ranging scope\r\n\r\n**System information**\r\n- Have I written custom code: Yes\r\n- OS Platform and Distribution: Windows 1903\r\n- TensorFlow installed from: pip\r\n- TensorFlow version: 1.13.1 / 1.14.0 / tf-nightly\r\n- Python version: 3.7.3\r\n- GPU model and memory: RTX 2080 Ti \r\n\r\n**Problem**\r\n\r\nFreezing a model with tf.keras.layers.BatchNormalization layers either gives an error, or does not freeze correctly and gives an error when loading, depending on the tensorflow version.\r\n\r\n**Method**\r\n\r\n- Freezing: Save a model with tf.keras.layers.BatchNormalization layers using `tf.saved_model.simple_save` and then freeze it using `tensorflow.python.tools.freeze_graph.freeze_graph`.\r\n- Loading: Load the frozen model using tf.import_graph_def()\r\n\r\n**Results**\r\n\r\n*1.13.1*\r\n- Freezing: no error\r\n- Loading: `ValueError: Input 0 of node batch_normalization/cond/ReadVariableOp/Switch was passed float from batch_normalization/gamma:0 incompatible with expected resource`\r\n\r\n*1.14.0*\r\n- Freezing: `ValueError: Tensor name 'batch_normalization/cond/ReadVariableOp/Switch:1' is invalid.`\r\n- Loading: n/a\r\n\r\n*tf-nightly  1.15.0-dev20190815*\r\n- Freezing: no error\r\n- Loading: `Node 'batch_normalization/cond/ReadVariableOp/Switch_3' has an _output_shapes attribute inconsistent with the GraphDef for output #0: Shapes must be equal rank, but are 1 and 0`\r\n\r\n**Code to reproduce**\r\n\r\nColab gist is here: https://colab.research.google.com/gist/geometrikal/da64b13d8a579bc46c005e981d9bc051/tf_31331_freezing_savedmodel.ipynb\r\n\r\n```\r\nimport tensorflow as tf\r\nimport tensorflow.keras.backend as K\r\nimport os\r\nimport datetime\r\nimport shutil\r\nfrom tensorflow.python.tools import freeze_graph\r\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D, Input, Activation, BatchNormalization, Lambda\r\nfrom tensorflow.keras.models import Model\r\nfrom tensorflow.python.platform import gfile\r\n\r\n# Clear the session\r\nK.clear_session()\r\n\r\n# TF version\r\nprint(\"TF version is \" + tf.__version__)\r\n\r\n# Create model\r\nprint('# Creating model')\r\ndef create_model():\r\n    inputs = Input(shape=(128, 128, 1))\r\n    x = Conv2D(4, (3, 3))(inputs)\r\n    x = BatchNormalization()(x)\r\n    # x = Lambda((lambda x: tf.layers.batch_normalization(x)))(x)\r\n    x = Activation('relu')(x)\r\n    x = Flatten()(x)\r\n    x = Dense(5, activation='softmax')(x)\r\n    model = Model(inputs, x, name='test')\r\n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\r\n    return model\r\n\r\nmodel = create_model()\r\n\r\n# Remove old frozen graph directory\r\nif os.path.exists('/content/frozen/'):\r\n  shutil.rmtree('/content/frozen/')\r\n\r\n# Create saved model\r\nprint('# Saving model')\r\nsave_dir = \"/content/frozen/\"\r\ntf.saved_model.simple_save(K.get_session(),\r\n                           save_dir,\r\n                           inputs={\"input\": model.inputs[0]},\r\n                           outputs={\"output\": model.outputs[0]})\r\n\r\n# Freeze graph from saved model checkpoint\r\nprint('# Freezing graph')\r\nfreeze_graph.freeze_graph(None,\r\n                          None,\r\n                          None,\r\n                          None,\r\n                          model.outputs[0].op.name,\r\n                          None,\r\n                          None,\r\n                          os.path.join(save_dir, \"frozen_model.pb\"),\r\n                          False,\r\n                          \"\",\r\n                          input_saved_model_dir=save_dir)\r\n\r\n# Try to load frozen graph\r\nprint('# Loading graph')\r\nsource = \"/content/frozen/frozen_model.pb\"\r\nsession = K.get_session()\r\nwith gfile.Open(source, 'rb') as f:\r\n    graph_def = tf.GraphDef()\r\n    graph_def.ParseFromString(f.read())\r\n    session.graph.as_default()\r\n    tf.import_graph_def(graph_def, name='')\r\n```\r\n\r\n**Workaround**\r\n\r\nWorkaround is to save the weights, clear the session, `tf.keras.backend.set_learning_phase(0)`, recreate the model, restore the weights, and then freeze. https://github.com/tensorflow/tensorflow/issues/31331#issuecomment-518655879", "comments": ["This should work on the latest nightly. Please reopen if you still have issues with running the script provided above.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=31668\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=31668\">No</a>\n", "This is happening in TF 2.x when using hub to transfer learn. I can't clear these layers when freezing either so I can't take the model outside of TF to say Open CV DNN."]}, {"number": 31667, "title": "Improve NumPy to Dataset performance with vectorized shuffling.", "body": "PiperOrigin-RevId: 263611727", "comments": ["There\u2019s a follow up fix to this bc this was causing a recursion error in some cases, should we wait for that? Or submit this and then follow up?", "yea, Please cherrypick the followup as well", "> yea, Please cherrypick the followup as well\r\n\r\nDone."]}, {"number": 31666, "title": "Call NNAPI cpu implementation on linux machine", "body": "I am trying to implement the example in the following link on my linux machine:\r\nhttps://developer.android.com/ndk/guides/neuralnetworks\r\nI know if there is no no delegation for nnapi, it will fall back to cpu implementation. So I tried to link the shared library libneuralnetworks.so which is from NDK prebuilt library to my example code. But it does not work. It seems that this .so file is not dynamic link library. Is there anyone know how to run NNAPI cpu implementation on linux machine? \r\n\r\nThanks very much.\r\n\r\n\r\n\r\n\r\n", "comments": ["Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\nMake sure you also include the exact command if possible to produce the output included in your test case. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!\r\n", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=31666\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=31666\">No</a>\n"]}, {"number": 31665, "title": "tf.math ops do not work on MirroredVariables", "body": "**System information**\r\n- Have I written custom code: yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS Mojave 10.14.5\r\n- TensorFlow installed from (source or binary): binary (tf-nightly)\r\n- TensorFlow version (use command below): 1.15.0-dev20190729\r\n- Python version: 3.7.4\r\n\r\n**Describe the current behavior**\r\nWhen I am using the `tf.distribute.MirroredStrategy` with multiple replicas, `tf.math` ops do not work on `MirroredVariables` when inside a cross-replica scope.\r\n\r\n**Describe the expected behavior**\r\nThe [MirroredVariable class](https://github.com/tensorflow/tensorflow/blob/e19c354920c3b246dda6598229210a582caaa1a9/tensorflow/python/distribute/values.py#L782) is a subclass of the [DistributedDelegate class](https://github.com/tensorflow/tensorflow/blob/e19c354920c3b246dda6598229210a582caaa1a9/tensorflow/python/distribute/values.py#L375), which if I understand correctly, means that `MirroredVariables` are supposed to act like regular tensors that you can perform ops on. This works fine with most standard ops, like multiplication, division, subtraction, etc. However, if you try to use any `tf.math` ops, you get `TypeError: Failed to convert object of type <class 'tensorflow.python.distribute.values.Mirrored'> to Tensor`.\r\n\r\n**Code to reproduce the issue**\r\n```Python\r\nimport tensorflow as tf\r\n\r\ndef merge(strategy, var):\r\n  var = strategy.extended.reduce_to(tf.distribute.ReduceOp.SUM, var, var)\r\n  # return var + 1  # this does work\r\n  return tf.math.add(var, 1)  # this doesn't work\r\n\r\ndef run(var):\r\n  var = var * var\r\n  return tf.distribute.get_replica_context().merge_call(merge, args=(var,))\r\n\r\nstrategy = tf.distribute.MirroredStrategy(['/cpu:0', '/cpu:1'])\r\nwith strategy.scope():\r\n  var = tf.Variable(2, dtype=tf.float32)\r\n  result = strategy.experimental_run_v2(run, args=(var,))\r\n  print(result)\r\n```\r\n", "comments": ["@kevin3-black ,\r\nWhen tried executing the given code, I got output  as per the screenshot below\r\n![errror](https://user-images.githubusercontent.com/52397990/63159607-8e9f8a80-c039-11e9-92b1-fcadadafd312.png). Thanks\r\n", "Sorry, I forgot to comment out a line. I've updated the post, and reproduced the result on Google Colab: https://colab.research.google.com/drive/1pLeHBPaZxC_OlQw4hXfGyC4gJtZ5e5gT", "This issue should be fixed with [commit](1348a03037e6ea79129024f318f8ae9b8f268df8). Please reopen if the issue still persists. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/31665\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/31665\">No</a>\n"]}, {"number": 31664, "title": "Building tflite-with-select-ops.aar library in tf v1.12", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 1.14, 1.13, 1.12\r\n- Python version: 2.7, 3.6\r\n- Bazel version (if compiling from source): 0.28, 0.16\r\n\r\n\r\n**Describe the problem**\r\nBefore getting into the problem I need a little intro.\r\nI'm trying to run a tflite model on android. The first little issue that I met was during `.pb` file conversion. One of my ops wasn't supported by tf lite builtins and so I have to export my model using the **SELECT_TF_OPS** tag as bescribed in the [official guide](https://www.tensorflow.org/lite/guide/ops_select#converting_the_model) .\r\nNo big deal. **The model was converted using tf v1.14**.\r\nAfter the successful conversion I needed only to build (from source) my custom select-ops friendly library that should be imported in my project. So I configured the bazel WORKSPACE as explained in [this guide](https://www.tensorflow.org/lite/guide/android#build_tensorflow_lite_locally).\r\nI've chosen ANDROID SDK 23 (also tried 29) and NDK 18.\r\nThen I've built the library using the bazel (v0.28 i guess) build arguments described [here](https://www.tensorflow.org/lite/guide/ops_select#android_aar).\r\nThe build took a **long time**, I imported it into my project and I get this Error:\r\n**This was the first real problem**\r\n`java.lang.UnsatisfiedLinkError: No implementation found for long org.tensorflow.lite.NativeInterpreterWrapper.createErrorReporter(int) (tried Java_org_tensorflow_lite_NativeInterpreterWrapper_createErrorReporter and Java_org_tensorflow_lite_NativeInterpreterWrapper_createErrorReporter__I)`\r\n\r\nNo bad, I surfed the web and found [this fix](https://github.com/googlecodelabs/tensorflow-for-poets-2/issues/26). They say to downgrade tf back to 1.12.\r\nHonestly I wasn't feeling really well on this, but I have to try.\r\nChanged Gradle version to 4.1 and Plugin Version to 3.0.0.\r\n_Before the fix I decided to try the previous aar build procedure on tf v1.13. But still this `java.lang.UnsatisfiedLinkError` appear._\r\nOk let's move on **tf v1.12**.\r\nNow **Bazel is v0.16**. The WORKSPACE now was ANDROID SDK 23 and NDK 15.\r\n**Here the second issue will come**, when building with select ops in tf 1.12 the bazel command [given by the official guide](https://www.tensorflow.org/lite/guide/ops_select#android_aar) is not working. Cause _//tensorflow/lite/java:tensorflow-lite-with-select-tf-ops_ cannot be resolved.\r\nSo I tried this, taking the idea from [here](https://www.tensorflow.org/lite/guide/ops_select#c):\r\n`bazel build --cxxopt='--std=c++11' `\r\n`-c opt`\r\n`--config=android_arm` \r\n`--config=monolithic` \r\n`--jobs=1` \r\n`--define=with_select_tf_ops=true `\r\n`//tensorflow/contrib/lite/java:tensorflow-lite`\r\n\r\nThe build was **really fast**. _Don't feel good about this._\r\nThen, imported the model into android studio, run and again : \r\n`java.lang.UnsatisfiedLinkError: No implementation found for long org.tensorflow.lite.NativeInterpreterWrapper.createErrorReporter(int) (tried Java_org_tensorflow_lite_NativeInterpreterWrapper_createErrorReporter and Java_org_tensorflow_lite_NativeInterpreterWrapper_createErrorReporter__I)`\r\n\r\nI really don't know what I am getting wrong.\r\n\r\nWhat is this error and why does it keeps coming?\r\n\r\nIs my bazel build command correct (for building my tflite select-ops friendly aar library in tf v1.12)? \r\n\r\nShould I use ANDROID NDK 17 as [described here](https://www.tensorflow.org/lite/guide/android#install_bazel_and_android_prerequisites)?\r\n\r\nI can't find anything that could help me on the web.\r\nLastly : \r\nShould I convert the `.pb` model to `.tflite` in tf v1.12?\r\n\r\nI will really appreciate any help.\r\nSorry for bad english I'm not native.", "comments": ["Can you attach the logcat surrounding this error? And how you're using the locally built .aar in your build.gradle? What device are you using? And what version of Android are you running with? \r\n\r\nI should note, we're hoping to release a nightly build of this AAR in the near future, which should dramatically simplify development when using these ops. I would not recommend downgrading to 1.12 for this.", "Hi @jdduke and thanks for your reply.\r\n\r\nI'm testing my app on AVD :\r\n- Nexus 5 , Android 9.0 (API 28)\r\n- Nexus 5, Android 7.1.1 (API 25)\r\n\r\nThey both get the same error.\r\nAlso tested on my phone Asus zenfone max pro m1 android 9.0. App crashed.\r\n\r\nHere is my build.gradle (followed the offical tf lite guide):\r\n```\r\napply plugin: 'com.android.application'\r\n\r\nandroid {\r\n    compileSdkVersion 29\r\n    buildToolsVersion \"29.0.2\"\r\n    defaultConfig {\r\n        applicationId \"com.example.tflitetestsdkapi29\"\r\n        minSdkVersion 23\r\n        targetSdkVersion 29\r\n        versionCode 1\r\n        versionName \"1.0\"\r\n        testInstrumentationRunner \"androidx.test.runner.AndroidJUnitRunner\"\r\n    }\r\n    buildTypes {\r\n        release {\r\n            minifyEnabled false\r\n            proguardFiles getDefaultProguardFile('proguard-android-optimize.txt'), 'proguard-rules.pro'\r\n        }\r\n    }\r\n    splits {\r\n        abi {\r\n            enable true\r\n            reset()\r\n            include 'x86', 'armeabi-v7a', 'x86_64'\r\n            universalApk true\r\n        }\r\n    }\r\n    aaptOptions {\r\n        noCompress \"tflite\"\r\n        noCompress \"lite\"\r\n    }\r\n}\r\n\r\nallprojects {\r\n    repositories {\r\n        jcenter()\r\n        flatDir {\r\n            dirs 'libs'\r\n        }\r\n    }\r\n}\r\n\r\n\r\ndependencies {\r\n    implementation fileTree(dir: 'libs', include: ['*.jar'])\r\n    implementation 'androidx.appcompat:appcompat:1.0.2'\r\n    implementation 'androidx.constraintlayout:constraintlayout:1.1.3'\r\n    testImplementation 'junit:junit:4.12'\r\n    androidTestImplementation 'androidx.test:runner:1.2.0'\r\n    androidTestImplementation 'androidx.test.espresso:espresso-core:3.2.0'\r\n    implementation name:'tensorflow-lite-with-select-tf-ops', ext:'aar'\r\n    implementation files('libs\\\\commons-io-2.6.jar')\r\n}\r\n```\r\n\r\nNow the logcat (verbose) generated from Nexus 5 API 25 :\r\n`--------- beginning of crash\r\n2019-08-17 19:58:17.279 6303-6303/com.example.tflitetestsdkapi29 E/AndroidRuntime: FATAL EXCEPTION: main\r\n    Process: com.example.tflitetestsdkapi29, PID: 6303\r\n    java.lang.UnsatisfiedLinkError: No implementation found for long org.tensorflow.lite.NativeInterpreterWrapper.createErrorReporter(int) (tried Java_org_tensorflow_lite_NativeInterpreterWrapper_createErrorReporter and Java_org_tensorflow_lite_NativeInterpreterWrapper_createErrorReporter__I)\r\n        at org.tensorflow.lite.NativeInterpreterWrapper.createErrorReporter(Native Method)\r\n        at org.tensorflow.lite.NativeInterpreterWrapper.<init>(NativeInterpreterWrapper.java:40)\r\n        at org.tensorflow.lite.Interpreter.<init>(Interpreter.java:171)\r\n        at org.tensorflow.lite.Interpreter.<init>(Interpreter.java:148)\r\n        at com.example.tflitetestsdkapi29.TFLiteTester.<init>(TFLiteTester.java:66)\r\n        at com.example.tflitetestsdkapi29.MainActivity$1.onClick(MainActivity.java:45)\r\n        at android.view.View.performClick(View.java:5637)\r\n        at android.view.View$PerformClick.run(View.java:22429)\r\n        at android.os.Handler.handleCallback(Handler.java:751)\r\n        at android.os.Handler.dispatchMessage(Handler.java:95)\r\n        at android.os.Looper.loop(Looper.java:154)\r\n        at android.app.ActivityThread.main(ActivityThread.java:6119)\r\n        at java.lang.reflect.Method.invoke(Native Method)\r\n        at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:886)\r\n        at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:776)`", "If you're running in an emulator, then change `--config=android_arm` to `--config=android_x86`. If you want to support both in a single .aar, you can use `--config=android --fat_apk_cpu=x86,arm64-v8a,armeabi-v7a`", "With `--config=android_x86` i get :\r\n`ERROR: Config value android_x86 is not defined in any .rc file`\r\n\r\nInstead with `--config=android --fat_apk_cpu=x86,arm64-v8a,armeabi-v7a` : \r\n`ERROR: /home/dav/.cache/bazel/_bazel_dav/53e97091f1d0420dd55249f05e42312f/external/androidndk/BUILD.bazel:39:1: in cc_toolchain_suite rule @androidndk//:toolchain-libcpp: cc_toolchain_suite '@androidndk//:toolchain-libcpp' does not contain a toolchain for cpu 'k8'`\r\n\r\nTF 1.14.\r\n\r\nAlready deleted the cache of previous bazel installations ", "It sounds like you might need to re-configure your workspace for targeting Android (see https://www.tensorflow.org/lite/guide/android#configure_workspace_and_bazelrc). There's no reason you should be able to build for `--config=android_arm` but not `--config=android_x86`.", "Ok, right now I've removed the \r\n`--config=android` \r\nargument and leaved \r\n`--fat_apk_cpu=x86,arm64-v8a,armeabi-v7a`\r\nand the build is starting correctly.\r\nNo more _toolchain issues_ :+1: \r\n\r\nI will update you on any progess.\r\nHope it will work this time ", "After 3 hours of build i get this error:\r\n`Linking of rule '//tensorflow/core/kernels:android_tensorflow_kernels' failed (Exit 1)`\r\nIts a week that I'm going mad on building this tf lite `.aar`.\r\nI'll move to tensorflow mobile", "Was there any additional output for the failed linkage? We haven't been able to repro that. As noted, we're hoping to have the nightly build of the select-tf-ops aar available in our nightly builds within the next week or so.", "Created new issue here [ #32183](https://github.com/tensorflow/tensorflow/issues/32183).\r\nI moved back to tflite and tf v1.14.\r\nI'm trying to build an `.aar` library that would run on emulator.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=31664\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=31664\">No</a>\n", "@jdduke can i ask if the select-tf-ops aar available in nightly build? if so can you point to which version should i use from here? \r\nhttps://bintray.com/google/tensorflow/tensorflow-lite", "Prebuilt libs are available @ https://bintray.com/google/tensorflow/tensorflow-lite-select-tf-ops. You can add that target in addition to the standard https://bintray.com/google/tensorflow/tensorflow-lite target.", "@jdduke Thank you so much for the info :smile: "]}, {"number": 31663, "title": "r2.0 Cherrypick: bugs fixes and test fixes.", "body": "", "comments": []}, {"number": 31662, "title": "Tensorflow Lite Op Report", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS\r\n- TensorFlow installed from (source or binary): Source\r\n- TensorFlow version (or github SHA if from source): 1.14.0\r\n\r\n\r\n**Provide the text output from tflite_convert**\r\n\r\n```\r\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, ARG_MIN, CAST, CONCATENATION, EXPAND_DIMS, FULLY_CONNECTED, GATHER, GATHER_ND, LESS, MAXIMUM, MINIMUM, MUL, ONE_HOT, PACK, RANGE, REDUCE_MIN, RESHAPE, REVERSE_V2, SHAPE, SQUEEZE, STRIDED_SLICE, SUM, TANH, TRANSPOSE, UNPACK, ZEROS_LIKE. Here is a list of operators for which you will need custom implementations: Enter, Exit, LoopCond, Merge, Switch, TensorArrayGatherV3, TensorArrayReadV3, TensorArrayScatterV3, TensorArraySizeV3, TensorArrayV3, TensorArrayWriteV3.\r\n```\r\n", "comments": ["@Jbiloki ,\r\nCan you please refer the [link](https://www.tensorflow.org/lite/guide/ops_custom) .Thanks!", "@oanush Thank you for the link, I will have to implement these operators myself to compile the graph!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=31662\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=31662\">No</a>\n"]}, {"number": 31661, "title": "Tensorflow Lite Allow Variable length sequences", "body": "**System information**\r\n- TensorFlow version (you are using): 1.14.9\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.** \r\n\r\nCurrently, porting a tensorflow model to tflite does not allow for variable length inputs and instead throws\r\n\r\n```\r\nValueError: None is only supported in the 1st dimension. Tensor 'input_2' has invalid shape '[None, None, 1]'.\r\n```\r\n\r\nMany NLP applications require the second axis of the shape to allow for variable length input sequences.\r\n\r\n**Will this change the current api? How?** N/A\r\n\r\n**Who will benefit with this feature?** NLP/CV applications of tflite", "comments": ["is it working in any tf version now?", "is it working in any tf version now?", "anyone?", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information."]}, {"number": 31660, "title": "TOCO fails to handle Dilated Convolution properly with use_bias=False", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 1.14\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**Describe the current behavior**\r\nconv1 = tf.layers.conv2d(x, 32, 3, dilation_rate=(2,2), activation=tf.nn.relu, use_bias=False)\r\nTF will wrap this convolution into Space2Batch and Batch2Space pair. When converting to float tflite toco/tflite_convert fails to fold them back into single op. I think that happens because it doesn't match any of the patterns that identify_dilated_conv.cc analyzes.\r\n\r\nIf use_bias=True then everything works as expected.\r\n\r\n**Describe the expected behavior**\r\n\r\n\r\n**Code to reproduce the issue**\r\nN/A\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["If use_bias=True , When converting to float tflite toco/tflite_convert can fold them back into single op.Is that ture?why i can't fuse them to a op.thanks", "i've submitted a fix for dilated conv in the new mlir converter.\r\nhttps://github.com/tensorflow/tensorflow/commit/f54bb6f5578b931d79884302768996ba1073f685\r\n\r\ncould you please download latest tf-nightly and then try convert your model with the new converter?\r\n\r\n(please set converter.experimental_new_converter = True).\r\nthanks.", "feel free to reopen if the issue still persists. thanks!"]}, {"number": 31659, "title": "Add tests of RandomDataset", "body": "This PR adds tests for the RandomDataset kernel, following the general approach from @feihugis's latest updates to the `DatasetOpsTestBaseV2` test harness class.\r\n\r\nI also split `random_dataset_op.cc` into separate `.cc` and `.h` files so that the test cases can instantiate the kernel. ", "comments": ["> Can you use the `ITERATOR_GET_NEXT_TEST_P`, `DATASET_NODE_NAME_TEST_P`, etc macros that @feihugis added?\r\n\r\nSure, can do. Commit 0a70de6 modifies the test cases that have corresponding macros to use the macros (with the exception of the test for `GetNext`, as noted in the conversation with @feihugis above).", "Can one of the admins verify this patch?", "Looking into the build file issues.", "Build files updated, then updated a second time to reflect changes in master.", "The \"Ubuntu CC\" CI test for this PR has been in the \"Expected\" state for a while. Is something stuck?", "```\r\nthird_party/tensorflow/core/kernels/data/experimental/random_dataset_op_test.cc:55:65: error: only virtual member functions can be marked 'override'\r\n  Status MakeInputs(gtl::InlinedVector<TensorValue, 4>* inputs) override {\r\n                                                                ^~~~~~~~~\r\nthird_party/tensorflow/core/kernels/data/experimental/random_dataset_op_test.cc:65:36: error: unknown template name 'DatasetOpsTestBaseV2'\r\nclass RandomDatasetOpTest : public DatasetOpsTestBaseV2<RandomDatasetParams> {\r\n                                   ^\r\nthird_party/tensorflow/core/kernels/data/experimental/random_dataset_op_test.cc:67:58: error: only virtual member functions can be marked 'override'\r\n  Status Initialize(RandomDatasetParams* dataset_params) override {\r\n                                                         ^~~~~~~~~\r\nthird_party/tensorflow/core/kernels/data/experimental/random_dataset_op_test.cc:105:68: error: only virtual member functions can be marked 'override'\r\n                             std::unique_ptr<OpKernel>* op_kernel) override {\r\n                                                                   ^~~~~~~~~\r\nthird_party/tensorflow/core/kernels/data/experimental/random_dataset_op_test.cc:69:39: error: use of undeclared identifier 'thread_num_'\r\n    TF_RETURN_IF_ERROR(InitThreadPool(thread_num_));\r\n                                      ^\r\nthird_party/tensorflow/core/kernels/data/experimental/random_dataset_op_test.cc:70:55: error: use of undeclared identifier 'cpu_num_'\r\n    TF_RETURN_IF_ERROR(InitFunctionLibraryRuntime({}, cpu_num_));\r\n                                                      ^\r\nthird_party/tensorflow/core/kernels/data/experimental/random_dataset_op_test.cc:79:62: error: use of undeclared identifier 'dataset_kernel_'\r\n    TF_RETURN_IF_ERROR(MakeDatasetOpKernel(*dataset_params, &dataset_kernel_));\r\n                                                             ^\r\nthird_party/tensorflow/core/kernels/data/experimental/random_dataset_op_test.cc:84:30: error: use of undeclared identifier 'dataset_kernel_'\r\n        CreateDatasetContext(dataset_kernel_.get(), &inputs, &dataset_ctx_));\r\n                             ^\r\nthird_party/tensorflow/core/kernels/data/experimental/random_dataset_op_test.cc:84:63: error: use of undeclared identifier 'dataset_ctx_'\r\n        CreateDatasetContext(dataset_kernel_.get(), &inputs, &dataset_ctx_));\r\n                                                              ^\r\nthird_party/tensorflow/core/kernels/data/experimental/random_dataset_op_test.cc:89:23: error: use of undeclared identifier 'dataset_kernel_'\r\n        CreateDataset(dataset_kernel_.get(), dataset_ctx_.get(), &dataset_));\r\n                      ^\r\nthird_party/tensorflow/core/kernels/data/experimental/random_dataset_op_test.cc:89:46: error: use of undeclared identifier 'dataset_ctx_'\r\n        CreateDataset(dataset_kernel_.get(), dataset_ctx_.get(), &dataset_));\r\n                                             ^\r\nthird_party/tensorflow/core/kernels/data/experimental/random_dataset_op_test.cc:89:67: error: use of undeclared identifier 'dataset_'\r\n        CreateDataset(dataset_kernel_.get(), dataset_ctx_.get(), &dataset_));\r\n                                                                  ^\r\nthird_party/tensorflow/core/kernels/data/experimental/random_dataset_op_test.cc:94:31: error: use of undeclared identifier 'dataset_ctx_'\r\n        CreateIteratorContext(dataset_ctx_.get(), &iterator_ctx_));\r\n                              ^\r\nthird_party/tensorflow/core/kernels/data/experimental/random_dataset_op_test.cc:94:52: error: use of undeclared identifier 'iterator_ctx_'\r\n        CreateIteratorContext(dataset_ctx_.get(), &iterator_ctx_));\r\n                                                   ^\r\nthird_party/tensorflow/core/kernels/data/experimental/random_dataset_op_test.cc:95:24: error: use of undeclared identifier 'dataset_'\r\n    TF_RETURN_IF_ERROR(dataset_->MakeIterator(iterator_ctx_.get(),\r\n                       ^\r\nthird_party/tensorflow/core/kernels/data/experimental/random_dataset_op_test.cc:95:47: error: use of undeclared identifier 'iterator_ctx_'\r\n    TF_RETURN_IF_ERROR(dataset_->MakeIterator(iterator_ctx_.get(),\r\n                                              ^\r\nthird_party/tensorflow/core/kernels/data/experimental/random_dataset_op_test.cc:96:65: error: use of undeclared identifier 'iterator_'; did you mean 'IteratorResource::State::iterator'?\r\n                                              kIteratorPrefix, &iterator_));\r\n                                                                ^~~~~~~~~\r\n                                                                IteratorResource::State::iterator\r\n./third_party/tensorflow/core/lib/core/errors.h:73:43: note: expanded from macro 'TF_RETURN_IF_ERROR'\r\n    const ::tensorflow::Status _status = (__VA_ARGS__);  \\\r\n                                          ^\r\n./third_party/tensorflow/core/kernels/data/iterator_ops.h:82:35: note: 'IteratorResource::State::iterator' declared here\r\n    std::unique_ptr<IteratorBase> iterator;\r\n                                  ^\r\nthird_party/tensorflow/core/kernels/data/experimental/random_dataset_op_test.cc:111:57: error: reference to non-static member function must be called; did you mean to call it with no arguments?\r\n        {{RandomDatasetOp::kOutputTypes, dataset_params.output_dtypes},\r\n                                         ~~~~~~~~~~~~~~~^~~~~~~~~~~~~\r\n                                                                     ()\r\nthird_party/tensorflow/core/kernels/data/experimental/random_dataset_op_test.cc:112:58: error: reference to non-static member function must be called; did you mean to call it with no arguments?\r\n         {RandomDatasetOp::kOutputShapes, dataset_params.output_shapes}});\r\n                                          ~~~~~~~~~~~~~~~^~~~~~~~~~~~~\r\n                                                                      ()\r\nfatal error: too many errors emitted, stopping now [-ferror-limit=]\r\n20 errors generated.\r\n```", "I've merged the latest updates from `master` and added some changes that should resolve the build issues.", "@frreiss can you please check build failures ?", "I've put in another layer of changes in the BUILD files that this PR modifies. The build is now working again on my test machines. Hopefully it works on all the different CI targets now.", "`third_party/tensorflow/core/kernels/data/experimental/random_dataset_op_test.cc:15:10: error: module //third_party/tensorflow/core/kernels/data/experimental:random_dataset_op_test does not depend on a module exporting 'third_party/tensorflow/core/lib/random/philox_random.h'\r\n\r\nbuild_cleaner //third_party/tensorflow/core/kernels/data/experimental:random_dataset_op_test\r\n#include \"third_party/tensorflow/core/lib/random/philox_random.h\"\r\n         ^\r\nthird_party/tensorflow/core/kernels/data/experimental/random_dataset_op_test.cc:16:10: error: module //third_party/tensorflow/core/kernels/data/experimental:random_dataset_op_test does not depend on a module exporting 'third_party/tensorflow/core/lib/random/random_distributions.h'\r\n//third_party/tensorflow/core/kernels/data/experimental:random_dataset_op_test\r\n#include \"third_party/tensorflow/core/lib/random/random_distributions.h`\r\n\r\n@frreiss can you please check above error ?", "I have added some dependencies to the `random_dataset_op_test` target that hopefully will clear up the error described above.\r\n\r\nI also updated one of the test cases to conform to the latest version of the test harness.", "@rachellim can you please review new changes ?", "This has merged internally , waiting for auto-merge to happen, thank you."]}, {"number": 31658, "title": "Exception has occurred: KeyError in Tensor.py", "body": "Hi there!\r\nI wanna run an example from [this tutorial](https://colab.sandbox.google.com/github/tensorflow/docs/blob/r2.0rc/site/en/r2/tutorials/text/nmt_with_attention.ipynb)\r\nFirstly I've got an error but that was fixed by adding this line:\r\n`tf.enable_eager_execution()`\r\nI downloaded [French - English dataset](http://www.manythings.org/anki/)\r\nThen script was built successfully but at the end I've got another error:\r\n```\r\nException has occurred: KeyError\r\n'desole'\r\n  File \"C:\\Users\\xxx\\Python\\Tensor.py\", line 314, in <listcomp>\r\n    inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\r\n  File \"C:\\Users\\xxx\\Python\\Tensor.py\", line 314, in evaluate\r\n    inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\r\n  File \"C:\\Users\\xxx\\Python\\Tensor.py\", line 366, in translate\r\n    result, sentence, attention_plot = evaluate(sentence)\r\n  File \"C:\\Users\\xxx\\Python\\Tensor.py\", line 377, in <module>\r\n    translate(u'Je suis d\u00e9sol\u00e9, mais je ne peux pas r\u00e9pondre tout de suite.')\r\n```\r\n\r\nThis error occurs on this line:\r\n`translate(u'Je suis desole, mais je ne peux pas repondre tout de suite .')`\r\nImplementation of this function you can get from tutorial above.\r\n\r\n**System information**\r\nOS: latest Windows 10 build;\r\nTensorFlow: 1.14.0;\r\nPython: 3.7.3;\r\n[MSC v.1916 64 bit (AMD64)];\r\nCPU: AMD Ryzen 7 2700x;\r\nGPU: NVidia GeForce GTX 1050 Ti.\r\n\r\nIf you need some additional info, I will provide it.\r\nHelp me please to solve this issue or tell me where I'm doing something wrong.\r\n", "comments": ["Perhaps you can try this tutorial with TF 2.X version as mentioned in the colab.", "> Perhaps you can try this tutorial with TF 2.X version as mentioned in the colab.\r\n\r\nThanks for reply!\r\nI found that I had some issues with versions of TF. I fixed it, but described issue still appears.", "@iSapGod \r\n\r\nLooks like some words are missing in your dataset. Please, include those words and try again.Thanks!", "@ravikyram \r\nThanks for reply.\r\nYeah, I thought about it too. But then I just used sentences from dataset, and nothing changed.", "@iSapGod Sorry for the delay. Can you create a standalone code to reproduce the issue. Thanks!", "@jvishnuvardhan \r\nThis issue occurs only after model is trained and trying to get some results. All code is provided via link above (actually, code hasn't a lot of lines)", "@iSapGod I ran it with T2.0 without any issues. Here is the [gist](https://colab.sandbox.google.com/gist/jvishnuvardhan/a1d51dd24e14b789285462a9324565f8/nmt_with_attention.ipynb). One modification I made was uploading `fra.txt` to colab and read it from there. Please check the gist and let me know if you see anything missing. \r\n\r\nWhen you respond or create a new TF issue, Please provide a simple standalone code (the current code (tutorial) is too long and requires lot of efforts to resolve). If you provide simple standalone code, then it is easy for localizing the issue faster. Thanks again.!", "Automatically closing this out since I understand it to be resolved, but please let me know if I'm mistaken.Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=31658\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=31658\">No</a>\n", "\r\nplease help me i have the same error\r\ndef evaluate(sentence):\r\n  attention_plot = np.zeros((max_length_targ, max_length_inp))\r\n\r\n  sentence = preprocess_sentence(sentence)\r\n\r\n  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\r\n  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\r\n                                                         maxlen=max_length_inp,\r\n                                                         padding='post')\r\n  inputs = tf.convert_to_tensor(inputs)\r\n\r\n  result = ''\r\n\r\n  hidden = [tf.zeros((1, units))]\r\n  enc_out, enc_hidden = encoder(inputs, hidden)\r\n\r\n  dec_hidden = enc_hidden\r\n  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\r\n\r\n  for t in range(max_length_targ):\r\n    predictions, dec_hidden, attention_weights = decoder(dec_input,\r\n                                                         dec_hidden,\r\n                                                         enc_out)\r\n\r\n    # storing the attention weights to plot later on\r\n    attention_weights = tf.reshape(attention_weights, (-1, ))\r\n    attention_plot[t] = attention_weights.numpy()\r\n\r\n    predicted_id = tf.argmax(predictions[0]).numpy()\r\n\r\n    result += targ_lang.index_word[predicted_id] + ' '\r\n\r\n    if targ_lang.index_word[predicted_id] == '<end>':\r\n      return result, sentence, attention_plot\r\n", "KeyError                                  Traceback (most recent call last)\r\n[<ipython-input-41-664e526d304d>](https://localhost:8080/#) in <module>()\r\n----> 1 translate(u'Trois')\r\n\r\n2 frames\r\n[<ipython-input-37-88c350b1987b>](https://localhost:8080/#) in <listcomp>(.0)\r\n      4   sentence = preprocess_sentence(sentence)\r\n      5 \r\n----> 6   inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\r\n      7   inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\r\n      8                                                          maxlen=max_length_inp,\r\n\r\nKeyError: 'trois'\r\n", "@laurianekoffi As closed issue was an old issue, can you please open a new issue with a simple standalone code to reproduce the issue? Thanks!"]}, {"number": 31657, "title": "[2.0 Cherrypick] Bug fixes for Keras SavedModel", "body": "", "comments": ["Whoops, thanks for catching that. I meant to delete only the change that was added to the file. Updating the commit", "`gbdt_batch.py` has been undeleted.", "2022-01-08 12:47:32.812069: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/intel/openvino_2021/data_processing/dl_streamer/lib:/opt/intel/openvino_2021/data_processing/gstreamer/lib:/opt/intel/openvino_2021/opencv/lib:/opt/intel/openvino_2021/deployment_tools/ngraph/lib:/opt/intel/openvino_2021/deployment_tools/inference_engine/external/tbb/lib::/opt/intel/openvino_2021/deployment_tools/inference_engine/external/hddl/lib:/opt/intel/openvino_2021/deployment_tools/inference_engine/external/omp/lib:/opt/intel/openvino_2021/deployment_tools/inference_engine/external/gna/lib:/opt/intel/openvino_2021/deployment_tools/inference_engine/external/mkltiny_lnx/lib:/opt/intel/openvino_2021/deployment_tools/inference_engine/lib/intel64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\r\n2022-01-08 12:47:32.812092: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\r\n2022-01-08 12:47:32.812107: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:163] no NVIDIA GPU device is present: /dev/nvidia0 does not exist\r\n2022-01-08 12:47:32.812367: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\nWARNING:absl:Please consider providing the trackable_obj argument in the from_concrete_functions. Providing without the trackable_obj argument is deprecated and it will use the deprecated conversion path.\r\n2022-01-08 12:47:34.806218: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\r\n2022-01-08 12:47:34.806383: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\r\n2022-01-08 12:47:34.860258: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1164] Optimization results for grappler item: graph_to_optimize\r\n  function_optimizer: function_optimizer did nothing. time = 0.008ms.\r\n  function_optimizer: function_optimizer did nothing. time = 0ms.\r\n\r\n2022-01-08 12:47:37.790651: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:357] Ignored output_format.\r\n2022-01-08 12:47:37.790685: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:360] Ignored drop_control_dependency.\r\n2022-01-08 12:47:38.104138: W tensorflow/compiler/mlir/lite/flatbuffer_export.cc:1892] TFLite interpreter needs to link Flex delegate in order to run the model since it contains the following Select TFop(s):\r\nFlex ops: FlexStridedSlice, FlexTranspose\r\nDetails:\r\n\ttf.StridedSlice(tensor<1x120x160x3x1x32xf32>, tensor<6xi32>, tensor<6xi32>, tensor<6xi32>) -> (tensor<1x120x160x1x32xf32>) : {begin_mask = 55 : i64, device = \"\", ellipsis_mask = 0 : i64, end_mask = 55 : i64, new_axis_mask = 0 : i64, shrink_axis_mask = 8 : i64}\r\n\ttf.Transpose(tensor<1x30x4x40x4x1x4xf32>, tensor<7xi32>) -> (tensor<1x30x40x1x4x4x4xf32>) : {device = \"\"}\r\nSee instructions: https://www.tensorflow.org/lite/guide/ops_select\r\n2022-01-08 12:47:38.104385: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:1963] Estimated count of arithmetic ops: 53.877 G  ops, equivalently 26.938 G  MACs\r\n\r\nEstimated count of arithmetic ops: 53.877 G  ops, equivalently 26.938 G  MACs\r\nWARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded", "gh pr checkout 26682", "???/"]}, {"number": 31656, "title": "[tflite] Metal GPU delegate: implement Mean operator", "body": "Basic first-pass implementation of the Mean operator (assumes mean is always taken over axis 1 and 2, shader code likely has room for optimization)", "comments": ["@LK can you please resolve conflicts ?", "Can one of the admins verify this patch?", "I'm going to go ahead and close this PR, because it seems to have stalled. If you're still interested in pursing this (and responding to my comments), please feel free to reopen!"]}, {"number": 31655, "title": "[tflite] Metal GPU delegate: improve op scheduling", "body": "Improve how we schedule ops to the GPU. Rather than reverting all ops to the CPU once we encounter a CPU op in the linear execution plan, we now only move ops to the GPU if any of their inputs are not computable on the GPU. This allows two parallel branches to both be partially scheduled on the GPU.\r\n\r\nThis seems to work for my model, but not familiar with TFLite internals enough to determine if this is going to cause any unexpected downstream problems or thrashing.", "comments": ["Can one of the admins verify this patch?", "@mellanox-github \r\n\r\nWithout full unit testing of various network scenarios, it's going to be hard to verify the validity of this.  \"This seems to work for my model, but not familiar with TFLite internals enough to determine if this is going to cause any unexpected downstream problems or thrashing.\"  is not going to be good enough, and Google products use this too =/", "@impjdi of course \u2014 I\u2019m hoping that somebody on the TF team with more context around this code path can shed some light on how things are moved to/from the GPU and any potential problems this change might cause there.\r\n\r\nAs for unit tests, I mentioned this in one of my other PRs, but I\u2019m not sure how to run unit tests for the Metal kernel, since AFAIK they can\u2019t run on the simulator. If you could point me in the right direction there, I can definitely go back and add tests here!", "@LK any updates ?", "@rthadur @impjdi is there any way for me to run the unit tests for the Metal GPU delegate? At least this way I could put together a test suite to test various network configurations.", "reassigning to @NikolayChirkov ", "@LK We're working on xcode project for testing operations and models", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "It has been 43 days that this pull-request has stalled. Please create a new pull-request with the requested changes."]}, {"number": 31654, "title": "Running tensorflow on GPU is far slower than on CPU", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 1809 & Windows Server 2016\r\n- TensorFlow installed from (source or binary): pip install tensorflow-gpu==2.0.0-beta1, as well as tensorflow-gpu, compared to tensorflow & tensorflow==2.0.0-beta1\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source): -\r\n- GCC/Compiler version (if compiling from source): - \r\n- CUDA/cuDNN version: Cuda 10 & cuDNN 7.6.2 for cuda 10.0\r\n\r\n### Current behavior:\r\nIm getting a 50%+ performance loss with GPU!\r\nIn the below example, the CPU version is even training way faster on a bigger model with slightly bigger epochs.\r\n![time](https://user-images.githubusercontent.com/12736950/63144316-9daf1a00-bff2-11e9-9b39-036fd9291008.png)\r\n\r\nIm training on 2 different systems:\r\nMy server, without a GPU:\r\n\r\nIntel Core i5 6500T (4x@2.5 ghz) Notebook processor\r\nNetwork attached storage for training data and output\r\n16 Gb DDR 4 Ram\r\nMy Desktop PC:\r\n\r\nIntel core i7 3770k (4x3,5-4 ghz)\r\nNvidia GTX 970 @4GB\r\n32gb ddr3 ram\r\nTraining Data on local SSD, output to NAS\r\n\r\nNow interestingly 3000 epochs, 100000 records each, takes roughly 3h on the server using TF 1.14\r\nThe same on my Desktop with GPU takes 8h with TF 2.0\r\nIt sits with full Video Ram but at 3% graphical processor use.\r\nThe CPU is sometimes at 30% use with tensorflow GPU but 100%  at any time with any CPU build.  \r\nThe harddisk is utilized with a whopping 0%.\r\n![system utilisation](https://user-images.githubusercontent.com/12736950/63122624-7f6ffc80-bfa7-11e9-81ee-2b76e4bc5d99.png)\r\n\r\n### Expected behavior:\r\nTensorflow-GPU trains faster than Tensorflow CPU\r\n\r\n### Code to reproduce the issue:\r\nMy model is a fairly simple keras sequential lstm:\r\n```\r\nfor learningrate in learningrates:\r\n\tfor layerdensity in layerdensitys:\r\n\t\tfor layer in amount_of_layers:\r\n\t\t\t################################\r\n\t\t\t# generate model               #\r\n\t\t\t################################\r\n\t\t\tmodelname = f\"{layer}-layer_{layerdensity}-nodes_selu-adam_{learningrate}-learningrate_{records_per_epoch}-epochsize_{appendix}\"\r\n\t\t\tmodel = keras.Sequential()\r\n\t\t\tmodel.add(Dense(layerdensity, activation=tf.nn.selu, input_dim=15))\r\n\t\t\tfor i in range(layer-1):\r\n\t\t\t\tmodel.add(Dense(layerdensity, activation=tf.nn.selu))\r\n\t\t\tmodel.add(Dense(9,activation=tf.nn.softmax, name = \"Output\"))\r\n\t\t\t# Compile\r\n\t\t\toptimizer = tf.keras.optimizers.Adam(lr=learningrate)\r\n\t\t\tmodel.compile(\r\n\t\t\t\toptimizer=optimizer,\r\n\t\t\t\tloss='sparse_categorical_crossentropy',\r\n\t\t\t\tmetrics=['accuracy'])\r\n\t\t\tmodel.summary()\r\n\t\t\ttensorboard = TensorBoard(log_dir=\"\\\\\\\\drg-fs01\\\\BigData\\\\Projects\\\\Notebooks\\\\PokerBot\\\\log\\\\\" + modelname,\r\n\t\t\t\thistogram_freq = 100, write_graph = False)\r\n\t\t\t#cp_callback = tf.keras.callbacks.ModelCheckpoint(\"\\\\\\\\drg-fs01\\\\BigData\\\\Projects\\\\Notebooks\\\\PokerBot\\\\checkpoints\\\\\" + modelname, verbose=0)\r\n\t\t\t################################\r\n\t\t\t# train model                  #\r\n\t\t\t################################\r\n\t\t\tmodel.fit(trainSet, \r\n\t\t\t\tepochs = epochs, \r\n\t\t\t\tsteps_per_epoch = trainSteps, \r\n\t\t\t\tshuffle = True, \r\n\t\t\t\tvalidation_data = testSet, \r\n\t\t\t\tvalidation_steps = testSteps, \r\n\t\t\t\tvalidation_freq = int(epochs/maxTestEpochs),\r\n\t\t\t\tverbose = verbose, \r\n\t\t\t\tcallbacks = [tensorboard])#,cp_callback])\r\n\t\t\tmodel.save(basePath+'saved_models/' + modelname + '.h5')\r\n```\r\nI am having lots of test data which does not fit in memory so I use interleaved datasets:\r\n```\r\n# dataset modeler\r\ndef modelDataset(sourcepath, badgesize, repeat = False, repetitions = 10):\r\n    #get all files\r\n    list = os.listdir(sourcepath)\r\n    pathfiles = [sourcepath+x for x in list]\r\n    \r\n    #get metrics\r\n    rows_per_file = count_lines(sourcepath+\"0.csv\")\r\n    number_of_files = len(list)\r\n    total_rows = (rows_per_file * number_of_files)\r\n    print(f\"records: {total_rows}\")\r\n    # get number of steps per Epoch\r\n    steps_per_epoch = int(rows_per_file / badgesize) # 2000 badges per epoch\r\n    epochs = number_of_files\r\n    if badgesize == 1:\r\n        epochs = 1 \r\n    print(f\"number epochs: {epochs}\")\r\n    # model interleaved dataset\r\n    dataset = (tf.data.Dataset.from_tensor_slices(pathfiles).interleave(lambda x:\r\n        tf.data.TextLineDataset(x).map(parse_csv, num_parallel_calls=4),\r\n        cycle_length=4, block_length=16))\r\n    dataset.columns = CSV_COLUMNS\r\n    \r\n    if badgesize != 1:\r\n        dataset = dataset.shuffle(buffer_size=badgesize)\r\n    if repeat:\r\n        dataset = dataset.repeat(repetitions)\r\n        epochs = epochs * repetitions\r\n    dataset = dataset.batch(badgesize)\r\n    dataset = dataset.prefetch(2)  # prefetch one batch\r\n    return dataset, steps_per_epoch, epochs, badgesize\r\n```", "comments": ["@forReason Provide us the full code snippet to reproduce the reported issue. It will indeed help us to move faster. Thanks!", "I have been able to increase the speed by upping the Batchsize to 128.\r\nWhen upping the batchsize to 2048, my CPU is nearly 100% used. I can train a little faster than on my Server without GPU but I suspect this is due to the faster processor. Additionally this comes at a high Accuracy/Loss tradeoff. Diminishing the faster training.\r\n\r\nStill taskmanager shows a low gpu utilisation but the cpu utilisation increased.\r\n![2019-08-16 13_11_51-Task Manager](https://user-images.githubusercontent.com/12736950/63164174-ecc37200-c027-11e9-9860-563e10fd1cdd.png)\r\n\r\nAdditionally I get a warning \"Method (on_train_batch_end) is slow compared to the batch update (0.117879). Check your callbacks.\" whis is coming from Tensorboard. I could however verify that this does not affect training speed greatly as it is only called x epochs. when disabling the tensorboard callback the warning disappears. but speed only increases by ~2%.\r\n\r\nhere is my full script trainmodel.py:\r\n\r\n```\r\nfrom __future__ import absolute_import, division, print_function, unicode_literals\r\n\r\nfrom sklearn.model_selection import train_test_split\r\n\r\n# TensorFlow and tf.keras\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras.initializers import glorot_uniform\r\nfrom tensorflow import feature_column\r\nfrom tensorflow.keras import layers\r\nfrom tensorflow.keras.callbacks import TensorBoard\r\nfrom tensorflow.keras.models import Sequential\r\nfrom tensorflow.keras.layers import Dense, Activation, Embedding, Flatten, LeakyReLU, BatchNormalization, Dropout\r\nimport tensorflow_datasets as tfds\r\n\r\n# Helper libraries\r\nimport numpy as np\r\nimport time\r\nimport os\r\nfrom tqdm import tqdm #progressbars\r\n\r\nprint(tf.__version__)\r\n\r\n# count lines\r\ndef count_lines(path):\r\n    rownumber = 0\r\n    with open(path, \"r\",encoding=\"utf-8\",errors='ignore') as f:\r\n        rownumber =  sum(bl.count(\"\\n\") for bl in blocks(f))\r\n    return rownumber\r\n\r\ndef blocks(files, size=65536):\r\n    while True:\r\n        b = files.read(size)\r\n        if not b: break\r\n        yield b\r\n\r\nbasePath = \"//[fileshare]/BigData/Projects/Notebooks/Trainmodel/\"\r\nlocalPath = \"C:/temp/Trainmodel/\"\r\n                                                                                  \r\nvalPath = localPath+\"val/\"\r\ntrainPath = localPath+\"train/\"\r\ntestPath = localPath+\"test/\"\r\n\r\n# csv to tensor parser\r\ndef parse_csv(line):\r\n        parsed_line = tf.io.decode_csv(line, [[0.], [0.], [0.],[0.], [0.], [0.], [0.],[0.], [0.], [0.], [0.],[0.], [0.], [0.], [0.], [0]])\r\n        label = parsed_line[-1:]\r\n        del parsed_line[-1]\r\n        features = parsed_line\r\n        return tf.stack(features),label\r\n\r\n# dataset modeler\r\ndef modelDataset(sourcepath, badgesize, repeat = False, repetitions = 10):\r\n    #get all files\r\n    list = os.listdir(sourcepath)\r\n    pathfiles = [sourcepath+x for x in list]\r\n    \r\n    #get metrics\r\n    rows_per_file = count_lines(sourcepath+\"0.csv\")\r\n    number_of_files = len(list)\r\n    total_rows = (rows_per_file * number_of_files)\r\n    print(f\"records: {total_rows}\")\r\n    # get number of steps per Epoch\r\n    steps_per_epoch = int(rows_per_file / badgesize) # 2000 badges per epoch\r\n    epochs = number_of_files\r\n    if badgesize == 1:\r\n        epochs = 1 \r\n    print(f\"number epochs: {epochs}\")\r\n    # model interleaved dataset\r\n    dataset = (tf.data.Dataset.from_tensor_slices(pathfiles).interleave(lambda x:\r\n        tf.data.TextLineDataset(x).map(parse_csv, num_parallel_calls=4),\r\n        cycle_length=4, block_length=16))\r\n    #dataset.columns = CSV_COLUMNS\r\n    \r\n    if badgesize != 1:\r\n        dataset = dataset.shuffle(buffer_size=badgesize)\r\n    if repeat:\r\n        dataset = dataset.repeat(repetitions)\r\n        epochs = epochs * repetitions\r\n    dataset = dataset.batch(badgesize)\r\n    dataset = dataset.prefetch(2)  # prefetch one batch\r\n    return dataset, steps_per_epoch, epochs, badgesize\r\n\r\n# load interleaved dataset\r\ntrainSet, trainSteps, maxTrainEpochs, trainBadgeSize = modelDataset(trainPath, 32, True)\r\nprint (f\"max number of epochs: {maxTrainEpochs}\")\r\ntestSet, testSteps, maxTestEpochs, testBadgeSize = modelDataset(testPath, 32,True,4)\r\nvalSet, valSteps, maxValEpochs, valBadgeSize = modelDataset(valPath, 1)\r\n\r\n# compile model\r\nlearningrates = [0.0002]\r\nlayerdensitys = [40]\r\namount_of_layers = [5]\r\nappendix = \"GPUtest\"\r\nepochs = maxTrainEpochs\r\nrecords_per_epoch = trainSteps * trainBadgeSize\r\nverbose = 0\r\n\r\n################################\r\n# train model                  #\r\n################################\r\nmodelname = \"unspecified\"\r\nfor learningrate in learningrates:\r\n\tfor layerdensity in layerdensitys:\r\n\t\tfor layer in amount_of_layers:\r\n\t\t\t################################\r\n\t\t\t# generate model               #\r\n\t\t\t################################\r\n\t\t\tmodelname = f\"{layer}-layer_{layerdensity}-nodes_selu-adam_{learningrate}-learningrate_{records_per_epoch}-epochsize_{appendix}\"\r\n\t\t\tmodel = keras.Sequential()\r\n\t\t\tmodel.add(Dense(layerdensity, activation=tf.nn.selu, input_dim=15))\r\n\t\t\tfor i in range(layer-1):\r\n\t\t\t\tmodel.add(Dense(layerdensity, activation=tf.nn.selu))\r\n\t\t\tmodel.add(Dense(9,activation=tf.nn.softmax, name = \"Output\"))\r\n\t\t\t# Compile\r\n\t\t\toptimizer = tf.keras.optimizers.Adam(lr=learningrate)\r\n\t\t\tmodel.compile(\r\n\t\t\t\toptimizer=optimizer,\r\n\t\t\t\tloss='sparse_categorical_crossentropy',\r\n\t\t\t\tmetrics=['accuracy'])\r\n\t\t\tmodel.summary()\r\n\t\t\ttensorboard = TensorBoard(log_dir=\"\\\\\\\\[fileshare]\\\\BigData\\\\Projects\\\\Notebooks\\\\Trainmodel\\\\log\\\\\" + modelname,\r\n\t\t\t\thistogram_freq = 100, write_graph = False)\r\n            #cp_callback = tf.keras.callbacks.ModelCheckpoint(\"\\\\\\\\[Fileshare]\\\\BigData\\\\Projects\\\\Notebooks\\\\Trainmodel\\\\checkpoints\\\\\" + modelname, verbose=0)\r\n            ################################\r\n            # train model                  #\r\n            ################################\r\n\t\t\tmodel.fit(trainSet, \r\n\t\t\t\tepochs = epochs, \r\n\t\t\t\tsteps_per_epoch = trainSteps, \r\n\t\t\t\tshuffle = True, \r\n\t\t\t\tvalidation_data = testSet, \r\n\t\t\t\tvalidation_steps = testSteps, \r\n\t\t\t\tvalidation_freq = int(epochs/maxTestEpochs),\r\n\t\t\t\tverbose = verbose, \r\n\t\t\t\tcallbacks = [tensorboard])#,cp_callback])\r\n\t\t\tmodel.save(basePath+'saved_models/' + modelname + '.h5')\r\n```\r\n\r\nfirst 10 records from training data 0.csv.\r\n```\r\n0.25,0.846153846153846,0.5,0.615384615384615,0.75,0.461538461538462,0.25,0.461538461538462,0.75,0.769230769230769,0.75,0.384615384615385,0.25,0.538461538461538,1,8\r\n1,0.923076923076923,0.5,0.0769230769230769,1,0.538461538461538,0.25,0.384615384615385,1,0.846153846153846,0.75,0.384615384615385,1,0.692307692307692,0.444444444444444,2\r\n0.75,0.538461538461538,0.25,0.846153846153846,0.75,0.461538461538462,1,0.769230769230769,0.75,1,1,0.461538461538462,0.75,0.307692307692308,0.555555555555556,3\r\n0.5,0.307692307692308,0.75,0.615384615384615,1,0.0769230769230769,0.75,0.0769230769230769,0.5,0.538461538461538,0.75,0.230769230769231,0.25,0.461538461538462,0.888888888888889,4\r\n0.5,0.307692307692308,0.25,0.769230769230769,1,1,1,0.384615384615385,0.25,1,0.75,0.230769230769231,0.75,0.307692307692308,0.444444444444444,1\r\n1,0.923076923076923,0.5,0.846153846153846,0.75,0.153846153846154,0.5,0.769230769230769,0.25,0.230769230769231,1,0.846153846153846,1,0.307692307692308,0.777777777777778,5\r\n0.5,0.769230769230769,1,0.846153846153846,0.25,0.0769230769230769,0.25,1,0.25,0.692307692307692,0.5,0.923076923076923,0.5,0.230769230769231,0.555555555555556,0\r\n0.5,0.230769230769231,0.25,0.923076923076923,0.5,0.846153846153846,0.5,0.384615384615385,1,0.615384615384615,1,0.384615384615385,0.5,0.153846153846154,1,5\r\n0.25,0.230769230769231,0.5,0.769230769230769,0.75,0.692307692307692,1,0.769230769230769,0.25,0.153846153846154,0.5,1,0.25,0.538461538461538,0.666666666666667,2\r\n0.5,0.615384615384615,1,0.923076923076923,0.75,0.307692307692308,1,0.307692307692308,0.5,0.692307692307692,0.25,0.615384615384615,0.5,0.461538461538462,1,3\r\n```\r\nThere are files 0.csv ... 2846.csv with 99999 records each\r\n\r\nattached is also the validation set which is quite small\r\n\r\n[0.txt](https://github.com/tensorflow/tensorflow/files/3509424/0.txt)\r\n\r\n- dont expect high accuracys, its an incomplete information problem ;)", "I have also faced this issue when training a GAN on gpu, but I do see sparks up to .3% utilization when placement is default. Manually placing had no effect, but I thought it may be because slow transfer/read from cpu to gpu, but this makes it seem like something else. Thanks for doing the research on this @forReason ", "@esslushy Really nothing jumps to my mind. First, I thought it might be the IO on network so I pulled 50GB of data locally *grr*. didnt help. \r\nHaving Drive and Network at Literally 0% is a headscratcher to me.\r\nNext, I thought it might be the parse function:\r\n```\r\n# csv to tensor parser\r\ndef parse_csv(line):\r\n        parsed_line = tf.io.decode_csv(line, [[0.], [0.], [0.],[0.], [0.], [0.], [0.],[0.], [0.], [0.], [0.],[0.], [0.], [0.], [0.], [0]])\r\n        label = parsed_line[-1:]\r\n        del parsed_line[-1]\r\n        features = parsed_line\r\n        return tf.stack(features),label\r\n```\r\nWhen preparing the data with my own c# Program, I can shuffle, augment data and write to disk roughly 1ep/3secs (100'000 records)\r\nbut when training, I can get 1 step in 2.45s \r\nSo if this function is not way, way slower than my simple c$ code, that should not be too much of an issue. Would be great if there was a way to debug this part. But im very fresh to python.\r\n\r\nSo I'm left with \"why would it be faster on a slower cpu where it has to parse and train on the same chip than on cpu + gpu?\"", "I think that your CPU performance is better than GPU performance because you have a relatively small model.  You should try a test run with \r\n`amount_of_layers = [5, 50, 150]`\r\nAnd see if GPU is still performing slower than CPU.\r\n\r\n\r\nAs a poster on S.O. says, \"the overhead of invoking GPU kernels, and copying data to and from GPU, is very high. For operations on models with very little parameters it is not worth of using GPU\"\r\n[Related StackOverflow Post](https://stackoverflow.com/questions/55749899/training-a-simple-model-in-tensorflow-gpu-slower-than-cpu)", "Additionally, you can also try to use the [TensorBoard profiler](https://www.tensorflow.org/tensorboard/tensorboard_profiling_keras) to see if that points to any red flags.", "Hello Guys,\r\n\r\nIssue seems to be fixed with TF 2.1 for me as well as Graphics card swap to RTX 2080.\r\nStill many thanks for your assistance.", "I've just spent half a day, trying to get through the flimsy installation of GPU support for Windows 10, and when I finally got it all working, I got my GTX 780 performing about 10 times worse than my CPU. That's bad.\r\n", "> Hello Guys,\r\n> \r\n> Issue seems to be fixed with TF 2.1 for me as well as Graphics card swap to RTX 2080.\r\n> Still many thanks for your assistance.\r\n\r\nSo the only solution is updating TF? that's bad since I have a older GPU and as far as I remember the newer TF are not compatible with older cuda versions... And what exactly was the problem, I'm a bit confused with your solution, the solution was to buy a new GPU? or update TF? or only by doing both?\r\nThanks =)", "> I've just spent half a day, trying to get through the flimsy installation of GPU support for Windows 10, and when I finally got it all working, I got my GTX 780 performing about 10 times worse than my CPU. That's bad.\r\n\r\nDid you solve your performance problem ? \r\nI have the same problem : GPU : GeForce GTX 1080 8Go, CPU : Intel Xeon E5-2667 v3 @ 3.20GHz RAM 12Mo...\r\nActually, I have install tensorflow 2.1.0 with Anaconda interface. But as I didn't see my GPU with this command : \r\n`import tensorflow as tf\r\nprint(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))`\r\nor\r\n`tf.test.is_built_with_gpu_support()`\r\nor\r\n`tf.test.is_built_with_cuda()`\r\nor \r\n`tf.test.gpu_device_name()`\r\n\r\nAll these command return False or nothing.\r\n\r\nAfter, I installed with Anaconda interface  : \r\ntensorflow-gpu 2.1.0 (i don't understand why this exist because I thought that tensorflow 2.1.0 is for both CPU and GPU)\r\nAfter that, the commands above works well : \r\ncommands return True or GPU : '/device:GPU:0'\r\n\r\nBut, with this installation (with tensorflow-gpu),  my training is 5 times slower .\r\nI think I don't use a good example to compare... I don't understand if I really use the GPU...", "> > Hello Guys,\r\n> > Issue seems to be fixed with TF 2.1 for me as well as Graphics card swap to RTX 2080.\r\n> > Still many thanks for your assistance.\r\n> \r\n> So the only solution is updating TF? that's bad since I have a older GPU and as far as I remember the newer TF are not compatible with older cuda versions... And what exactly was the problem, I'm a bit confused with your solution, the solution was to buy a new GPU? or update TF? or only by doing both?\r\n> Thanks =)\r\n\r\nHey Arruda,\r\n\r\nunfortunately I can not specify as I upgraded both at the same time.\r\n\r\nApparently, I have to upgrade my cpu now since after upgrading GPU now my CPU is the Bottleneck... 7 Years old computer... But its still a lot faster.\r\n\r\nII guess at this point, that more powerful hardware = faster processing no matter if there is a bug or not.", "[Here](https://medium.com/lsc-psd/tensorflow-2-1-doesnt-seem-to-see-my-gpu-even-though-cuda-10-1-with-solution-7b44297843a) you can find a very usefull tutorial. I faced the same problem, and that post really helped. The issue was in cudnn- and cuda- conda driver versions incompatibility.\r\nHope, this will help", "I have my better gpu running 50% slower than my worse gpu.\r\nBetter GPU PC:\r\nCPU 9900K\r\nMemory 16G*4\r\nGPU NVIDIA 2080 8G\r\nWorse GPU PC:\r\nCPU 9700\r\nMemory 16G+4G\r\nGPU NVIDIA 1650 4G\r\n\r\nRunning environment:\r\nTensorflow 1.14.0\r\nPython3.7\r\nCUDA 10.0\r\nCUDNN 7.4\r\n\r\nThat makes me crazy.", "@Kalethars Please open a new issue with more details about your issue and also fill the issue template (TF versions, cuda version etc). Thanks!", "Changing my batch size from `10` to `2048` increased performance from about 6 minutes to 15 seconds."]}, {"number": 31653, "title": "ValueError: Cannot add function 'TRTEngineOp_0_native_segment' because a different function with the same name already exists.", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):18.04 \r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below): 1.14 and dev\r\n- Python version:2.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:10.1\r\n- GPU model and memory:T4\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nNot able to call trt.create_inference_graph more than once to create TF-TRT nodes for disjointed sub-graphs. Throws the above error.\r\n\r\n**Describe the expected behavior**\r\nShould not throw the above error.\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n```\r\nfrom tensorflow.contrib.slim.nets import resnet_v1\r\nimport tensorflow as tf\r\nimport tensorflow.contrib.slim as slim\r\nimport numpy as np\r\nimport time\r\nimport os\r\nfrom PIL import Image\r\n#import tensorflow.contrib.tensorrt as tftrt\r\nfrom tensorflow.python.compiler.tensorrt import trt_convert as tftrt\r\nimport argparse\r\n\r\nPATH_TO_CKPT = \"resnet_v1_50.ckpt\"\r\nTEST_IMAGE_PATHS = [ \"elephant_small.jpg\", \"tabby_tiger_cat.jpg\"]\r\nBATCH_SIZE=25\r\nMAX_BATCH_SIZE=1000\r\nHEIGHT=224\r\nWIDTH=224\r\nCHANNELS=3\r\n\r\n\r\ndef load_image_into_numpy_array(image, batch_size=1):\r\n  (im_width, im_height) = image.size\r\n  x = np.array(image.getdata()).reshape(\r\n      (HEIGHT, WIDTH, CHANNELS)).astype(np.uint8)\r\n  x = np.expand_dims(x, axis=0)\r\n  xsl = list (x.shape)\r\n  xsl[0] = batch_size#MAX_BATCH_SIZE\r\n  x = np.broadcast_to(x[0,:,:,:], xsl) \r\n  return x\r\n\r\ndef run_resnet_50():\r\n    # Create graph\r\n    inputs = tf.placeholder(tf.float32, shape=[BATCH_SIZE, HEIGHT, WIDTH, CHANNELS])\r\n    with slim.arg_scope(resnet_v1.resnet_arg_scope()):\r\n            net, end_points = resnet_v1.resnet_v1_50(inputs, is_training=False)\r\n    \r\n    saver = tf.train.Saver()\r\n    \r\n    with tf.Session() as sess:\r\n            saver.restore(sess, PATH_TO_CKPT)\r\n            representation_tensor = sess.graph.get_tensor_by_name('resnet_v1_50/pool5:0') # if you don't know names like these, consider referring to corresponding model file or generate .pbtxt file as mentioned in  @civilman628 's answer above\r\n            img = np.ones((batch_size, height, width, channels))   #load image here with size [1, 224,224, 3]\r\n            features = sess.run(representation_tensor, {'Placeholder:0': img})\r\n            print ( \"features\", features)\r\n\r\ndef renamed_ckpt_save(name):\r\n    with tf.Session() as sess:# Restore the TF checkpoint\r\n\r\n        for var_name, var_shape in tf.contrib.framework.list_variables(PATH_TO_CKPT):\r\n            var = tf.contrib.framework.load_variable(PATH_TO_CKPT, var_name)\r\n            new_name_parts = [name] + var_name.split('/')[1:]\r\n            new_name = '/'.join(new_name_parts)\r\n            var = tf.Variable(var, name=new_name)\r\n            print var_name, var_shape, var.name\r\n\r\n        ckpt_dir = \"/tmp/\"+name\r\n        if not os.path.exists(ckpt_dir):\r\n            os.mkdir(ckpt_dir)\r\n        sess.run(tf.global_variables_initializer())\r\n        saver = tf.train.Saver()\r\n        saver.save(sess, ckpt_dir)\r\n\r\ndef renamed_ckpt_mem(sess, name):\r\n\r\n        for var_name, var_shape in tf.contrib.framework.list_variables(PATH_TO_CKPT):\r\n            var = tf.contrib.framework.load_variable(PATH_TO_CKPT, var_name)\r\n            new_name_parts = [name] + var_name.split('/')[1:]\r\n            new_name = '/'.join(new_name_parts)\r\n            var = tf.Variable(var, name=new_name)\r\n            print var_name, var_shape, var.name\r\n\r\ndef build_graph (sess, input_graph, name='graph1'):\r\n\r\n    inputs = tf.placeholder(tf.float32, shape=[BATCH_SIZE, HEIGHT, WIDTH, CHANNELS])\r\n    with slim.arg_scope(resnet_v1.resnet_arg_scope()):\r\n            net, end_points = resnet_v1.resnet_v1_50(inputs, is_training=False, scope=name)\r\n\r\n    with input_graph.as_default():\r\n      # Get handles to input and output tensors\r\n      ops = tf.get_default_graph().get_operations()\r\n      all_tensor_names = {output.name for op in ops for output in op.outputs}\r\n      tensor_dict = {}\r\n      for key in [\r\n          'pool5',\r\n      ]:\r\n        if name == '':\r\n            tensor_name = key + ':0'\r\n        else :\r\n            tensor_name = name+'/'+key + ':0'\r\n        if tensor_name in all_tensor_names:\r\n                tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\r\n                tensor_name)\r\n                print ( \"tensor_name\", tensor_name, tensor_dict[key])\r\n        else:\r\n           print( \"tensor_name \", tensor_name, \" not found\")\r\n\r\n\r\n    # Restore the TF checkpoint\r\n    saver = tf.train.Saver()\r\n    saver.restore(sess, \"/tmp/\"+name)\r\n    return tensor_dict\r\n\r\nclass TfTrt():\r\n\r\n    @staticmethod\r\n    def build(sess, graph, name='', import_name='import'):\r\n        tensor_dict = build_graph(sess, graph, name=name, )\r\n\r\n        outputl = []\r\n        for i,nname in enumerate(tensor_dict):\r\n            nvalue = tensor_dict[nname].name.split(\":\")[0]\r\n            print( i, nname, tensor_dict[nname].name )\r\n            outputl.append(nvalue)\r\n        print ( \"outputl \", outputl)\r\n\r\n        #node_names = [n.name for n in graph.as_graph_def().node]\r\n        #import pdb\r\n        #pdb.set_trace()\r\n\r\n        # Freeze the graph:\r\n        frozen_graph = tf.graph_util.convert_variables_to_constants(\r\n        sess,\r\n        sess.graph_def,\r\n        output_node_names= outputl)\r\n\r\n        # remove training nodes\r\n        frozen_graph = tf.compat.v1.graph_util.remove_training_nodes(frozen_graph)\r\n        # Now you can create a TensorRT inference graph from your frozen graph\r\n\r\n        tftrt_graph = tftrt.create_inference_graph(\r\n            input_graph_def=frozen_graph,\r\n            outputs = outputl,\r\n            max_batch_size = MAX_BATCH_SIZE ,\r\n            max_workspace_size_bytes= 1024*1024*1024,\r\n            precision_mode=\"FP16\")\r\n\r\n        output_nodes = tf.import_graph_def(\r\n            tftrt_graph,\r\n            return_elements = outputl,\r\n            name=import_name\r\n        )\r\n\r\n        tensor_dict = {}\r\n        for opname, opnode in zip (outputl, output_nodes):\r\n            tensor_dict[opnode.name] = opnode.outputs[0]\r\n\r\n        print ( \"tensor_dict\", tensor_dict)\r\n\r\n        return tensor_dict\r\n\r\n    @staticmethod\r\n    def run(sess, tensor_dict, image_tensor, image_np_expanded):\r\n        output_dict = sess.run(tensor_dict, feed_dict={image_tensor: image_np_expanded})\r\n        return output_dict\r\n\r\nclass Tf():\r\n\r\n    @staticmethod\r\n    def build(sess, graph, name='', import_name=None):\r\n        return build_graph(sess, graph, name=name)\r\n\r\n    @staticmethod\r\n    def run(sess, tensor_dict, image_tensor, image_np_expanded):\r\n        output_dict = sess.run(tensor_dict, feed_dict={image_tensor: image_np_expanded})\r\n        return output_dict\r\n\r\ndef run (runtime='TF'):\r\n\r\n    if runtime=='TF':\r\n        RunClass = Tf\r\n        import_name1= ''\r\n        import_name2= ''\r\n        placeholder_name1 = 'Placeholder:0'\r\n        placeholder_name2 = 'Placeholder_1:0'\r\n    elif runtime=='TFTRT':\r\n        RunClass = TfTrt\r\n        import_name1 = 'import1'\r\n        import_name2 = 'import2'\r\n        placeholder_name1 = 'import1/Placeholder:0'\r\n        placeholder_name2 = 'import2/Placeholder_1:0'\r\n\r\n    graph = tf.Graph()\r\n\r\n    config = tf.ConfigProto()\r\n    config.gpu_options.allow_growth = True\r\n    #config.gpu_options.per_process_gpu_memory_fraction = 0.33\r\n    config.graph_options.rewrite_options.auto_mixed_precision = 1\r\n    with tf.Session(graph=graph, config=config) as sess:\r\n        #renamed_ckpt_mem(sess, 'resnet_v1_50_1')\r\n        #renamed_ckpt_mem(sess, 'resnet_v1_50_2')\r\n        tensor_dict1 = RunClass.build(sess, graph, name='resnet_v1_50_1', import_name=import_name1)\r\n        tensor_dict2 = RunClass.build(sess, graph, name='resnet_v1_50_2', import_name=import_name2)\r\n        tensorboard_dir = os.environ['TENSORBOARD_DIR']\r\n        file_writer = tf.summary.FileWriter(tensorboard_dir, sess.graph)\r\n        image_path = TEST_IMAGE_PATHS[0]\r\n        print ( \"image_path {}\".format(image_path))\r\n        image = Image.open(image_path)\r\n        image = image.resize((WIDTH, HEIGHT))\r\n        image_np_expanded = load_image_into_numpy_array(image, batch_size=BATCH_SIZE)\r\n        image_tensor1 = graph.get_tensor_by_name(placeholder_name1)\r\n        image_tensor2 = graph.get_tensor_by_name(placeholder_name2)\r\n        time0 = time.time()\r\n        for i in range(1,1001):\r\n            output_dict1 = RunClass.run(sess, tensor_dict1, image_tensor1, image_np_expanded)\r\n            output_dict2 = RunClass.run(sess, tensor_dict2, image_tensor2, image_np_expanded)\r\n            if i % 100 == 0:\r\n                time_taken = (time.time() - time0 )/(i * 1.0)\r\n                print (i, time_taken)\r\n        time_taken = (time.time() - time0 )/(i * 1.0)\r\n        print (\"time_taken \", time_taken, \"output_dict\", output_dict1, output_dict2)\r\n\r\nif __name__ == '__main__':\r\n    parser = argparse.ArgumentParser()\r\n    parser.add_argument('--runtime', default='TF', help='TF or TFTRT')\r\n    parser.add_argument('--rewrite_ckpt', action='store_true',  help='rename checkpoints')\r\n    args = parser.parse_args()\r\n    if args.rewrite_ckpt:\r\n        renamed_ckpt_save('resnet_v1_50_1')\r\n        renamed_ckpt_save('resnet_v1_50_2')\r\n\r\n    run (args.runtime)\r\n\r\n\r\n\r\n```\r\nTo run \r\n```\r\nPYTHONPATH=$PYTHONPATH:~/models/research/slim  python ./tftrt_resnet2x.py --runtime TFTRT\r\n```\r\n**Other info / logs**\r\n```\r\n File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/importer.py\", line 430, in import_graph_def\r\n    raise ValueError(str(e))\r\nValueError: Cannot add function 'TRTEngineOp_0_native_segment' because a different function with the same name already exists.\r\n```\r\n", "comments": ["@sgambient I think the reason of the failure is that, when using class `TfTrt`, there are two `build()` method manipulating the same `graph` object:\r\n```\r\ntensor_dict1 = RunClass.build(sess, graph, name='resnet_v1_50_1', import_name=import_name1)\r\ntensor_dict2 = RunClass.build(sess, graph, name='resnet_v1_50_2', import_name=import_name2)\r\n```\r\nboth `build()` run a `tf.import_graph_def` to import the `create_inference_graph`-converted TRT graph, and both TRT graph have a function with the same name `TRTEngineOp_0_native_segment`. I think the error will go away if you use different `graph` to call the `build()`.", "That is certainly the issue.    However, do not think  using a different graph is an option, as loading graphs  is a time consuming operation.  The example is a toy case,  the real  application network of course  have different networks that are run under  different  TF sessions . ", "@sgambient I don't quite understand `as loading graphs is a time consuming operation`, so what would be the performance difference if you load the graphdef into a different graph object?", "Here is the real problem. TFTRT as it stands now breaks the current TF model. TF  allows one to load  as many unconnected  sub-graphs as needed in a single graph.  By loading I mean building the network and restoring checkpoints.   Checkpoint restore is a graph specific operation, and time consuming.  So during inference, if  one is looking at removing milliseconds, the checkpoint restore is going to consume seconds, hence not viable.  Any work around will be be great. ", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/31653\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/31653\">No</a>\n"]}, {"number": 31652, "title": "How to preprocess a dataset with multiple input variables for integration with Tensorflow for binary classification?", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: Tensorflow 2.0\r\n- Python version: 3.7.1\r\n- Installed using virtualenv? pip? conda?:pip\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory:\r\n\r\n**Describe the problem**\r\n\r\nI am trying to setup a minimum viable neural network to train for a binary classification task. I am importing a CSV file with seven total columns, the first column is the true label, 1 or -1. I have divided the dataset into a training set and test set. Additionally, I have been able to import the dataset into python, and normalize the six variables to numbers between zero and one.\r\n\r\nI have been spending the past few hours developing ad hoc, layers for a neural network. I have been able to get the network to feedforward, and to make binary predictions. However, I am totally at a loss for how to train the model because I cannot figure out how to update the weights. Generally, I am familiar with back-propagation, SGD, derivates, ADAM, and the perceptron learning rule. The problem is I have been unable to figure out how to implement any of these methods, so my program learns. In short, my goal is to update the weights of the neural network if the predict label and true label are not the same, so the network can learn.\r\n\r\nI have tried using Keras because it is a high level API. [Keras](https://www.tensorflow.org/tutorials/keras/basic_classification#build_the_model ) While keras is good for getting started, it is very difficult to use Keras or Tensorflow on the datasets I generated myself. I am having trouble reformatting a neural network for the MNIST dataset to the needs of my present dataset [See Computer Vision]((https://medium.com/@brian.s.haney44/computer-vision-b39256f13fa4)).\r\n\r\nIn short, I am simply trying to find a way to develop and train a neural network on a dataset I developed. I have gone through the preprocessing and labeling, but I haven't been able load the dataset into python with Tensorflow. Instead, I am only able to load it into python through the standard library through the CSV module.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n1. I gathered the data and went through pre-processing procedures.\r\n2. I found a way to load the dataset into Python.\r\n3. I found a way to normalize the input layer.\r\n4. I was able to complete the feedforward aspect of the network.\r\n\r\nThe problem I ran into was updating the weight when the network makes a decision contradicted by the true label.\r\n\r\n**Any other info / logs**\r\n\r\nThis is the code I have been working from. A link to a dummy dataset can be found on my  [Github](https://github.com/Bhaney44/Deep-Neural-Network)\r\n```\r\nimport csv\r\nimport numpy as np\r\n\r\nwith open('data.csv', 'r') as data:\r\n    reader = csv.reader(data)\r\n    for row in reader:\r\n        #True Label\r\n        true_label = int(row[0])\r\n        #Input_Variable 1\r\n        var_1_string = (row[1])\r\n        var_1 = float(var_1_string.replace(',',''))\r\n        #Input_Variable 2\r\n        var_2_string = (row[2])\r\n        var_2 = float(var_2_string.replace(',',''))\r\n        #Input_Variable 3\r\n        var_3_string = (row[3])\r\n        var_3 = float(var_3_string.replace(',',''))\r\n\r\n        #Input Array\r\n        input_array = (true_label, var_1, var_2, var_3)\r\n\r\n        #Input layer with three nodes and a normalization function\r\n        def input_layer():\r\n            x_1 = (input_array[1])/float(100)\r\n            x_2 = (input_array[2])/float(100)\r\n            x_3 = (input_array[2])/float(100)\r\n\r\n            #Hidden layer\r\n            def hidden_layer():\r\n                w_0 = 0.1\r\n                w_1 = 0.1\r\n                w_2 = 0.1\r\n                w_3 = 0.1\r\n                x_4 = (x_1 * w_0)+(x_2 * w_1)\r\n                x_5 = (x_2 * w_2)+(x_3 * w_3)\r\n\r\n                #Output layer\r\n                def output_layer():\r\n                    w_4 = 0.1\r\n                    w_5 = 0.1\r\n                    x_6 = (x_4 * w_4)+(x_5 * w_5)\r\n\r\n                    #Activation function\r\n                    def activation():\r\n                        #True label\r\n                        x_0 = input_array[0]\r\n                        #decision function\r\n                        if x_6 > 0.5:\r\n                            y = 1\r\n                        else:\r\n                            y = -1\r\n\r\n                        #activation function\r\n                        if y is x_0:\r\n                            #Here the network predicted right\r\n                            print('correct')\r\n                        else:\r\n                            #Here I want to adjust the weigh parameters\r\n                            #However, I am not sure where to start, ideas include:\r\n                                #calculate loss function\r\n                                #change the way the wights are structured in the program\r\n                                #use matrices instead of linear coefficients\r\n                            print('update weights')\r\n     \r\n                    activation()\r\n                output_layer()\r\n            hidden_layer()\r\n        input_layer()  `\r\n```\r\n\r\nAs far as the work I have done in keras so far:\r\n\r\n```\r\nfrom __future__ import absolute_import, division, print_function, unicode_literals\r\nimport tensorflow as tf\r\n\r\nmnist = tf.keras.datasets.mnist\r\n\r\n(x_train, y_train),(x_test, y_test) = mnist.load_data()\r\nx_train, x_test = x_train / 255.0, x_test / 255.0\r\n\r\nmodel = tf.keras.models.Sequential([\r\n  tf.keras.layers.Flatten(input_shape=(28, 28)),\r\n  tf.keras.layers.Dense(512, activation=tf.nn.relu),\r\n  tf.keras.layers.Dropout(0.2),\r\n  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\r\n])\r\n\r\nmodel.compile(optimizer='adam',\r\n              loss='sparse_categorical_crossentropy',\r\n              metrics=['accuracy'])\r\n\r\nmodel.fit(x_train, y_train, epochs=5)\r\nmodel.evaluate(x_test, y_test)\r\n```\r\nHowever, this code is difficult to adapt to a different dataset. Indeed, I am unsure of the purpose of the  (x_train, y_train), (x_test, y_test) syntax and my dataset is size very differently than MNIST. Any help, suggestions, or criticisms would be greatly appreciated. \r\n\r\nWith thanks,\r\n\r\nBrian\r\n\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=31652\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=31652\">No</a>\n"]}, {"number": 31651, "title": "keras.optimizers.Adam cannot apply gradients if ResourceVariable has unknown shape.", "body": "With ResourceVariables we specify unknown shape dimensions for variables which can be resized after initializations similarly to how `validate_shape=False` worked previously.\r\n\r\nApplying gradients to ResourceVariables with unknown dimension sizes using `tf.keras.optimizers.Adam` currently crashes with the exception\r\n\r\n> ValueError: Cannot convert a partially known TensorShape to a Tensor: (None,)\r\n\r\nAttached is a minimal example to reproduce:\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\nprint(tf.__version__)\r\n\r\nw = tf.Variable([[1.0]], shape=tf.TensorShape([None]))\r\nwith tf.GradientTape() as tape:\r\n  loss = w * w\r\n\r\ngrad = tape.gradient(loss, w)\r\ntf.keras.optimizers.SGD().apply_gradients([(grad, w)])\r\nprint('that worked')\r\ntf.keras.optimizers.Adam().apply_gradients([(grad, w)])\r\nprint('that crashed')\r\n```\r\n\r\nOutputs:\r\n\r\n```\r\n2.0.0-beta1\r\nthat worked\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n~/.local/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py in zeros(shape, dtype, name)\r\n   1862         shape = constant_op._tensor_shape_tensor_conversion_function(\r\n-> 1863             tensor_shape.TensorShape(shape))\r\n   1864       except (TypeError, ValueError):\r\n\r\n~/.local/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py in _tensor_shape_tensor_conversion_function(s, dtype, name, as_ref)\r\n    325     raise ValueError(\r\n--> 326         \"Cannot convert a partially known TensorShape to a Tensor: %s\" % s)\r\n    327   s_list = s.as_list()\r\n\r\nValueError: Cannot convert a partially known TensorShape to a Tensor: (None,)\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-174-2eba6f36340c> in <module>\r\n      6 tf.keras.optimizers.SGD().apply_gradients([(grad, w)])\r\n      7 print('that worked')\r\n----> 8 tf.keras.optimizers.Adam().apply_gradients([(grad, w)])\r\n      9 print('that crashed')\r\n\r\n~/.local/lib/python3.6/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py in apply_gradients(self, grads_and_vars, name)\r\n    433         _ = self.iterations\r\n    434         self._create_hypers()\r\n--> 435         self._create_slots(var_list)\r\n    436 \r\n    437       self._prepare(var_list)\r\n\r\n~/.local/lib/python3.6/site-packages/tensorflow/python/keras/optimizer_v2/adam.py in _create_slots(self, var_list)\r\n    143     # Separate for-loops to respect the ordering of slot variables from v1.\r\n    144     for var in var_list:\r\n--> 145       self.add_slot(var, 'm')\r\n    146     for var in var_list:\r\n    147       self.add_slot(var, 'v')\r\n\r\n~/.local/lib/python3.6/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py in add_slot(self, var, slot_name, initializer)\r\n    576             dtype=var.dtype,\r\n    577             trainable=False,\r\n--> 578             initial_value=initial_value)\r\n    579       backend.track_variable(weight)\r\n    580       slot_dict[slot_name] = weight\r\n\r\n~/.local/lib/python3.6/site-packages/tensorflow/python/ops/variables.py in __call__(cls, *args, **kwargs)\r\n    260       return cls._variable_v1_call(*args, **kwargs)\r\n    261     elif cls is Variable:\r\n--> 262       return cls._variable_v2_call(*args, **kwargs)\r\n    263     else:\r\n    264       return super(VariableMetaclass, cls).__call__(*args, **kwargs)\r\n\r\n~/.local/lib/python3.6/site-packages/tensorflow/python/ops/variables.py in _variable_v2_call(cls, initial_value, trainable, validate_shape, caching_device, name, variable_def, dtype, import_scope, constraint, synchronization, aggregation, shape)\r\n    254         synchronization=synchronization,\r\n    255         aggregation=aggregation,\r\n--> 256         shape=shape)\r\n    257 \r\n    258   def __call__(cls, *args, **kwargs):\r\n\r\n~/.local/lib/python3.6/site-packages/tensorflow/python/ops/variables.py in <lambda>(**kws)\r\n    235                         shape=None):\r\n    236     \"\"\"Call on Variable class. Useful to force the signature.\"\"\"\r\n--> 237     previous_getter = lambda **kws: default_variable_creator_v2(None, **kws)\r\n    238     for _, getter in ops.get_default_graph()._variable_creator_stack:  # pylint: disable=protected-access\r\n    239       previous_getter = _make_getter(getter, previous_getter)\r\n\r\n~/.local/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py in default_variable_creator_v2(next_creator, **kwargs)\r\n   2549       synchronization=synchronization,\r\n   2550       aggregation=aggregation,\r\n-> 2551       shape=shape)\r\n   2552 \r\n   2553 \r\n\r\n~/.local/lib/python3.6/site-packages/tensorflow/python/ops/variables.py in __call__(cls, *args, **kwargs)\r\n    262       return cls._variable_v2_call(*args, **kwargs)\r\n    263     else:\r\n--> 264       return super(VariableMetaclass, cls).__call__(*args, **kwargs)\r\n    265 \r\n    266 \r\n\r\n~/.local/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py in __init__(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)\r\n    462           synchronization=synchronization,\r\n    463           aggregation=aggregation,\r\n--> 464           shape=shape)\r\n    465 \r\n    466   def __repr__(self):\r\n\r\n~/.local/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py in _init_from_args(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, shape)\r\n    606           with ops.name_scope(\"Initializer\"), device_context_manager(None):\r\n    607             initial_value = ops.convert_to_tensor(\r\n--> 608                 initial_value() if init_from_fn else initial_value,\r\n    609                 name=\"initial_value\", dtype=dtype)\r\n    610           # Don't use `shape or initial_value.shape` since TensorShape has\r\n\r\n~/.local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops_v2.py in __call__(self, shape, dtype)\r\n     96   def __call__(self, shape, dtype=dtypes.float32):\r\n     97     dtype = dtypes.as_dtype(dtype)\r\n---> 98     return array_ops.zeros(shape, dtype)\r\n     99 \r\n    100 \r\n\r\n~/.local/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py in zeros(shape, dtype, name)\r\n   1864       except (TypeError, ValueError):\r\n   1865         # Happens when shape is a list with tensor elements\r\n-> 1866         shape = ops.convert_to_tensor(shape, dtype=dtypes.int32)\r\n   1867     if not shape._shape_tuple():\r\n   1868       shape = reshape(shape, [-1])  # Ensure it's a vector\r\n\r\n~/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in convert_to_tensor(value, dtype, name, preferred_dtype, dtype_hint)\r\n   1098   preferred_dtype = deprecation.deprecated_argument_lookup(\r\n   1099       \"dtype_hint\", dtype_hint, \"preferred_dtype\", preferred_dtype)\r\n-> 1100   return convert_to_tensor_v2(value, dtype, preferred_dtype, name)\r\n   1101 \r\n   1102 \r\n\r\n~/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in convert_to_tensor_v2(value, dtype, dtype_hint, name)\r\n   1156       name=name,\r\n   1157       preferred_dtype=dtype_hint,\r\n-> 1158       as_ref=False)\r\n   1159 \r\n   1160 \r\n\r\n~/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in internal_convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, ctx, accept_symbolic_tensors, accept_composite_tensors)\r\n   1235 \r\n   1236     if ret is None:\r\n-> 1237       ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n   1238 \r\n   1239     if ret is NotImplemented:\r\n\r\n~/.local/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py in _tensor_shape_tensor_conversion_function(s, dtype, name, as_ref)\r\n    324   if not s.is_fully_defined():\r\n    325     raise ValueError(\r\n--> 326         \"Cannot convert a partially known TensorShape to a Tensor: %s\" % s)\r\n    327   s_list = s.as_list()\r\n    328   int64_value = 0\r\n\r\nValueError: Cannot convert a partially known TensorShape to a Tensor: (None,)\r\n```", "comments": ["I am able to reproduce the issue with Tensorflow 2.0.0.beta1. Please take a look at colab gist [here](https://colab.research.google.com/drive/1gHDBXwR_VRorIYITJkc7gBinojOP2puy).Thanks! ", "You may achieve this by setting `validate_shape=False`, as its value is `True` by default for ref variable (see [here](https://www.tensorflow.org/api_docs/python/tf/Variable?version=nightly#__init__)).", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/31651\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/31651\">No</a>\n", "Setting validate_shape=False does nothing to solve this issue. I just encountered it under Tensorflow version 1.15. The problem is that the apply_gradients method of the Adam optimizer appears to require the shape to be fully known, however the SGD optimizer does not. validate_shape=False simply allows a tf.Variable to be initialized without a fully known shape. What's frustrating is that I actually know the shape in my case and could supply a hint to make optimization work. However, there is no way to specify the static shape of a tf.Variable object (the set_shape method is apparently not implemented for tf.Variables and tf.ensure_shape returns a new Tensor object that cannot be optimized)."]}, {"number": 31650, "title": "tf.keras.backend.function ignores input shapes?", "body": "**System information**\r\n- Have I written custom code: Yes\r\n- OS Platform and Distribution: Windows 10\r\n- TensorFlow installed from (source or binary): conda install/update tensorflow\r\n- TensorFlow version (use command below): 1.14.0\r\n- Python version: 3.7.3\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**Describe the current behavior**\r\ntf.keras.backend.function seems to ignore explicitly defined input shapes, almost as if the model were defined using None shapes (dynamic reshape).\r\n\r\n**Describe the expected behavior**\r\nI expected an error to be thrown, as the wrong input shape was fed to the model. Instead, it seems as if the model was run using a dynamic reshape.\r\n\r\n**Code to reproduce the issue**\r\n```\r\nimport numpy as np\r\nimport tensorflow.keras as K\r\nimport tensorflow.keras.backend as Kb\r\n\r\nsub_in = K.layers.Input(shape = (1,5,1))\r\nx = K.layers.Conv2D(1, (1,1))(sub_in)\r\nx = K.layers.Flatten()(x)\r\nsub = K.models.Model(inputs=sub_in, outputs=x)\r\n\r\nmain_in = K.layers.Input(shape = (1,10,1))\r\nmain_in1 = K.layers.Lambda(lambda x: x[:,:,:5,:])(main_in)\r\nmain_in2 = K.layers.Lambda(lambda x: x[:,:,8:,:])(main_in)\r\nx1 = sub(main_in1)\r\nx2 = sub(main_in2)\r\nx = K.layers.Concatenate()([x1,x2])\r\nmain = K.models.Model(inputs=main_in, outputs=x)\r\n\r\narr = np.arange(30).reshape((3,1,10,1))\r\n\r\npred = main.predict(arr)\r\nprint(pred.shape)\r\n\r\nsubOutFunc = Kb.function(sub.input, sub.output)\r\nsubOut = subOutFunc(arr)\r\nprint(subOut.shape)\r\n```\r\nRunning this, you should see output shapes of (3,7) and (3,10), which in my opinion should not be possible. The sub model should only accept inputs of shape (?,1,5,1), yet in the two above examples inputs of shapes (?,1,2,1) and (?,1,10,1) are fed to it, and it works.\r\n\r\nThe first example (using the .predict method) gives it the (?,1,2,1) input, via the second Lambda split of the main input. No error. The second example calls backend.function directly on the sub model with a (?,1,10,1). Also no error.\r\n\r\nMaybe this was/is the desired behavior of backend.function ? It is not what I expected. Hence raising up in case this is a bug. Thank you!", "comments": ["I was able to reproduce the issue for given code TF version-1.14,kindly find the [gist](https://colab.sandbox.google.com/drive/1lPtZHkiU5Y7absQsIgbsPNLF2MRkeDj-#scrollTo=WQ-ndvvGIM3m) of colab.", "The `Conv2D` layer will[ re-create the conv op](https://github.com/tensorflow/tensorflow/blob/8502c9e5c8efa59b326e5743e64b283730145f5c/tensorflow/python/keras/layers/convolutional.py#L194) if the actual input has different shape other than the specified 'Input' shape. So the shape from the actual input is used.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/31650\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/31650\">No</a>\n"]}, {"number": 31649, "title": "Keras -> TfLite (AttributeError: 'Node' object has no attribute 'output_masks')", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS\r\n- TensorFlow installed from (source or binary): Source\r\n- TensorFlow version (or github SHA if from source): 1.14.0\r\n\r\n\r\n**Provide the text output from tflite_convert**\r\n\r\n```\r\n>>> converter = tf.lite.TFLiteConverter.from_keras_model_file('nlp-lite/app/src/main/python/deeplearning/models/parsing/en/Deep_CRF.h5', custom_objects=custom_objects)\r\nWARNING: Logging before flag parsing goes to stderr.\r\nW0814 17:56:27.203332 4401333696 deprecation.py:506] From /anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nCall initializer instance with the dtype argument instead of passing it to the constructor\r\nW0814 17:56:27.470824 4401333696 deprecation_wrapper.py:119] From /anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/lite/python/lite.py\", line 747, in from_keras_model_file\r\n    keras_model = _keras.models.load_model(model_file, custom_objects)\r\n  File \"/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/saving/save.py\", line 146, in load_model\r\n    return hdf5_format.load_model_from_hdf5(filepath, custom_objects, compile)\r\n  File \"/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/saving/hdf5_format.py\", line 212, in load_model_from_hdf5\r\n    custom_objects=custom_objects)\r\n  File \"/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/saving/model_config.py\", line 55, in model_from_config\r\n    return deserialize(config, custom_objects=custom_objects)\r\n  File \"/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/layers/serialization.py\", line 89, in deserialize\r\n    printable_module_name='layer')\r\n  File \"/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/utils/generic_utils.py\", line 192, in deserialize_keras_object\r\n    list(custom_objects.items())))\r\n  File \"/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py\", line 1131, in from_config\r\n    process_node(layer, node_data)\r\n  File \"/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py\", line 1087, in process_node\r\n    layer(flat_input_tensors[0], **kwargs)\r\n  File \"/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/base_layer.py\", line 443, in __call__\r\n    previous_mask = _collect_previous_mask(inputs)\r\n  File \"/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/base_layer.py\", line 1311, in _collect_previous_mask\r\n    mask = node.output_masks[tensor_index]\r\nAttributeError: 'Node' object has no attribute 'output_masks'\r\n```\r\n\r\nModel:\r\n\r\n```\r\nfrom keras_contrib.metrics import crf_viterbi_accuracy, crf_accuracy\r\nfrom keras_contrib.losses import crf_loss\r\nfrom keras_contrib.layers import CRF\r\n\r\n\r\nfrom keras.preprocessing.sequence import pad_sequences\r\nfrom keras.preprocessing.text import Tokenizer\r\n\r\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger\r\nfrom keras.utils import to_categorical\r\nfrom keras import backend as K\r\n\r\n\r\n# Defining the network dependencies\r\nfrom keras.layers import LSTM, Dense, Embedding, Input, TimeDistributed, Flatten, Lambda\r\nfrom keras.models import load_model, Model\r\ndef make_model():\r\n        #layers comes from a pretrained model\r\n        lm_model.layers[1].trainable = False\r\n        lm_model.layers[1].input_length = None\r\n        lm_model.layers[1].batch_input_shape = (None, None, 1)\r\n        lm_model.layers[2].batch_input_shape = (1, None, 1)\r\n        lm_model.layers[2].stateful = False\r\n        crf_input = Input(batch_shape=(None, None, 1))\r\n        crf_emb = lm_model.layers[1](crf_input)\r\n        reshape = Lambda(lambda x: K.squeeze(x, 2))(crf_emb)\r\n        crf_lstm = lm_model.layers[2](reshape)\r\n        crf_dense1 = TimeDistributed(Dense(TD_nodes, activation='relu'))(crf_lstm)\r\n        crf_out = CRF(n_tags, sparse_target=True)(crf_dense1)\r\n        crf_model = Model(inputs=crf_input, outputs=crf_out)\r\n        crf_model.compile(optimizer='rmsprop', loss=crf_loss, metrics=[crf_viterbi_accuracy, crf_accuracy, 'accuracy'])\r\n```\r\n\r\nI am using CRF from Keras Contrib\r\n", "comments": ["`TFLiteConverter.from_keras_model_file` only supports `tf.keras` models ([documentation](https://www.tensorflow.org/api_docs/python/tf/lite/TFLiteConverter#from_keras_model_file)). Therefore, your imports in the model generation code need to be `from tensorflow.keras...` instead of `from keras...`.", "@gargn I see, thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=31649\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=31649\">No</a>\n"]}, {"number": 31648, "title": "Fix warmstart", "body": "Follow up on https://github.com/tensorflow/tensorflow/pull/31503", "comments": ["@yunjiangster can you please check build failures ?", "@rthadur I incorrectly submitted the fix for r1.14. It's actually meant for r1.12. Will submit a new request. Sorry for the inconvenience.", "This is the new one, with two unit tests added: https://github.com/tensorflow/tensorflow/pull/31718", "@yunjiangster np, closing this PR, thank you "]}, {"number": 31647, "title": "Graph visualization of subclassed model/layer", "body": "**System information**\r\n- TensorFlow version (you are using): tensorflow-2.0b1\r\n- Are you willing to contribute it (Yes/No): Yes \r\n\r\n**Describe the feature and the current behavior/state.**\r\nGraph visualization of subclassed model/layer/tf.functions\r\n\r\n**Will this change the current api? How?**\r\nNot sure\r\n\r\n**Who will benefit with this feature?**\r\nAll users\r\n\r\n**Details**\r\nI posted this question on stack overflow a week ago and it seems it is completely ignored.  This is an attempt to reach out to experts who are more familiar to the inner working of the graph network implementation, and/or tf.function visualization in Tensorboard.  Please forgive me if this is not the right place, and I hope someone here can point me to the right place, thanks.\r\n  \r\n`https://stackoverflow.com/questions/57421766/plotting-subclassed-model-in-tensorflow-2-0-beta`\r\n\r\nI have a subclassed model that instantiates a few custom layers via subclassing.  I tried using `keras.utils.plot_model()` but all it does is print the model block, none of the layers appeared.  \r\n\r\nCan a Tensorflow expert comment on this?  Will this feature ever be implemented in the future?  If not, what is the next best alternative to examine the computation graph?  Note that `model.summary()` only gives a summary of the parameters of the custom layer, within which contains two dense layers.  Ideally, I like to see all the computations, if that is not asking too much...\r\n\r\n**Update**: I dug into the source, looks like plot_model() first check for the `_is_graph_network` attribute.  Graph Networks are used in Functional and Sequential APIs.  From the source:\r\n\r\n> Two types of `Networks` exist: Graph Networks and Subclass Networks. Graph\r\n>  networks are used in the Keras Functional and Sequential APIs. Subclassed\r\n>  networks are used when a user subclasses the `Model` class. In general,\r\n>  more Keras features are supported with Graph Networks than with Subclassed\r\n>  Networks, specifically:\r\n\r\n>  - Model cloning (`keras.models.clone()`)\r\n>  - Serialization (`model.get_config()/from_config()`, `model.to_json()/to_yaml()`)\r\n>  - Whole-model saving (`model.save()`)\r\n\r\n(**custom graph component**)\r\nNaturally, I like to know if I can build a graph network component, so my subclassed model/layer can work with these features.  Does that involve a lot of effort?\r\n\r\n(**tf.function graph visualization**)\r\nCan someone let me know if graph visualization via Tensorboard works with Tensorflow2 tf.functions?  In Tensorflow 1.x, one defines a name scope for a logical group of ops (e.g. generator/discriminator in GAN, encoder/decoder in VAE and loss/metrics), they are then displayed as a high-level block in the graph visualization.  Can I define something similar for tf.functions?\r\n\r\n", "comments": ["@gowthamkpr ,\r\ncan you please check the issue.Thanks!", "Please take a look at the solution provided [here](https://stackoverflow.com/questions/56690089/how-to-graph-tf-keras-model-in-tensorflow-2-0/56698035#56698035), where the user has provided the solution on how to graph a tf.keras model in tensorflow 2.0.", "Thanks, the solution is not applicable to my situation as I am neither\nusing sequential/functional API, nor calling model.fit().\nAs stated in my stack overflow question and repeated in the github issue, I\nam using a subclassed model and a custom training loop.\nIn any case, I found most of what I need by reading the source.\nThanks for your help.\n\nOn Mon, Aug 26, 2019 at 11:56 AM gowthamkpr <notifications@github.com>\nwrote:\n\n> Please take a look at the solution provided here\n> <https://stackoverflow.com/questions/56690089/how-to-graph-tf-keras-model-in-tensorflow-2-0/56698035#56698035>,\n> where the user has provided the solution on how to graph a tf.keras model\n> in tensorflow 2.0.\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/31647?email_source=notifications&email_token=ABSL7M3Y5EHOZOFONYI5NPLQGQRMBA5CNFSM4IL76DQ2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD5FJLOI#issuecomment-524981689>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABSL7MZ4YBYCBSSZWXOQ6UTQGQRMBANCNFSM4IL76DQQ>\n> .\n>\n", "I do not recall exact details at the moment but I believe there was a innate difficulties with subclassed Model.\r\n\r\n@omalleyt12 I vaguely remember that subclassed Layer/Model cannot be guaranteed to be graph friendly and thus fallback to the eager mode. Is this correct? \r\n\r\nAlso, reassigning to Tom as he has more expertise on the domain. ", "cc @davidsoergel ", "Yes in general we can't assume anything about the structure of a subclassed Model. If your Model can be though of as blocks of Layers and you wish to visualize it like that, we recommend you view the Functional API", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=31647\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=31647\">No</a>\n", "[I've answered it in [StackOverflow](https://stackoverflow.com/a/63898244/9215780) firstly, re-posting.]\r\n\r\nI've found some workaround to plot with the model sub-classing API. For the obvious reason **Sub-Classing** API doesn't support **Sequential or Functional** API like `model.summary()` and nice visualization using `plot_model`. Here, I will demonstrate both.\r\n\r\n```python\r\nclass my_model(Model):\r\n    def __init__(self, dim):\r\n        super(my_model, self).__init__()\r\n        self.Base  = VGG16(input_shape=(dim), include_top = False, weights = 'imagenet')\r\n        self.GAP   = L.GlobalAveragePooling2D()\r\n        self.BAT   = L.BatchNormalization()\r\n        self.DROP  = L.Dropout(rate=0.1)\r\n        self.DENS  = L.Dense(256, activation='relu', name = 'dense_A')\r\n        self.OUT   = L.Dense(1, activation='sigmoid')\r\n    \r\n    def call(self, inputs):\r\n        x  = self.Base(inputs)\r\n        g  = self.GAP(x)\r\n        b  = self.BAT(g)\r\n        d  = self.DROP(b)\r\n        d  = self.DENS(d)\r\n        return self.OUT(d)\r\n    \r\n    # AFAIK: The most convenient method to print model.summary() \r\n    # similar to the sequential or functional API like.\r\n    def build_graph(self):\r\n        x = Input(shape=(dim))\r\n        return Model(inputs=[x], outputs=self.call(x))\r\n\r\ndim = (124,124,3)\r\nmodel = my_model((dim))\r\nmodel.build((None, *dim))\r\nmodel.build_graph().summary()\r\n```\r\n\r\nIt will produce as follows:\r\n\r\n```\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\ninput_67 (InputLayer)        [(None, 124, 124, 3)]     0         \r\n_________________________________________________________________\r\nvgg16 (Functional)           (None, 3, 3, 512)         14714688  \r\n_________________________________________________________________\r\nglobal_average_pooling2d_32  (None, 512)               0         \r\n_________________________________________________________________\r\nbatch_normalization_7 (Batch (None, 512)               2048      \r\n_________________________________________________________________\r\ndropout_5 (Dropout)          (None, 512)               0         \r\n_________________________________________________________________\r\ndense_A (Dense)              (None, 256)               402192    \r\n_________________________________________________________________\r\ndense_7 (Dense)              (None, 1)                 785       \r\n=================================================================\r\nTotal params: 14,848,321\r\nTrainable params: 14,847,297\r\nNon-trainable params: 1,024\r\n```\r\n\r\nNow by using the `build_graph` function, we can simply plot the whole architecture. \r\n\r\n```python\r\n# Just showing all possible argument for newcomer.  \r\ntf.keras.utils.plot_model(\r\n    model.build_graph(),                      # here is the trick (for now)\r\n    to_file='model.png', dpi=96,              # saving  \r\n    show_shapes=True, show_layer_names=True,  # show shapes and layer name\r\n    expand_nested=False                       # will show nested block\r\n)\r\n```\r\n\r\nIt will produce as follows: -)\r\n\r\n![a](https://user-images.githubusercontent.com/17668390/93187371-8e545000-f761-11ea-8d70-74dc2fe7c644.png)\r\n", "I dont think we really need `build_graph` function in the custom model\r\nOne can just do this\r\n```\r\nmy_model = MyModel()  # You can provide the arguments that 'your model class` requires\r\n# Note : class MyModel(Model), does not have any def build_graph function\r\n\r\ninputs = Input(shape=(100,100,3)) # Provide the shape you wish to provide, with respect to 'your model class' expectation\r\nmodel = Model(inputs=[inputs],outputs=my_model.call(inputs))\r\n\r\nmodel.summary() # This will print the summary properly\r\ntf.keras.utils.plot_model(model,show_shapes=True) # This will give you the visualization of the model.\r\n```", "Yes, we can do that too. But there is nothing big differenc. I mean, here you're doing the same thing without defining it in a function within `Model` class. IMO, defining such function within `Model` class is more intuitive. And also we're building functional api model from subclassed api. "]}, {"number": 31646, "title": "Adding details to LSTM documentation #31237", "body": "Fixing  #31237", "comments": ["Hmm, the two failing builds have apparently nothing to do with the proposed changes..."]}]