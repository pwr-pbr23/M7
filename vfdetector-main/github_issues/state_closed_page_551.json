[{"number": 37186, "title": "tensorflow/stream_executor/lib/statusor.cc:34] Attempting to fetch value instead of handling error Internal: failed to get device attribute 13 for device 0: CUDA_ERROR_UNKNOWN: unknown error", "body": "**System information** \r\n- OS Platform and Distribution (e.g.,\r\nLinux Ubuntu 16.04):  Windows 10\r\n- TensorFlow installed from (source or\r\nbinary): Tried with both pip and conda\r\n- TensorFlow version (use command below): 2.10\r\n- Python version: 3.6\r\n- CUDA/cuDNN version:  CUDA 10.1 , cuDNN 7.6.5\r\n- GPU model and memory: NVIDIA MX250 , 2GB\r\n\r\n**Describe the current behavior**\r\nTensorFlow 2.10 gets installed. It is also imported into Python. When I try to list the available GPUs,\r\n\r\n`from __future__ import absolute_import, division, print_function, unicode_literals\r\nimport tensorflow as tf\r\nprint(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))`\r\n\r\nthe following error occurs.\r\n`2020-02-29 18:26:23.596966: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll\r\n2020-02-29 18:26:24.237060: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties:\r\npciBusID: 0000:02:00.0 name: GeForce MX250 computeCapability: 6.1\r\ncoreClock: 1.582GHz coreCount: 3 deviceMemorySize: 2.00GiB deviceMemoryBandwidth: 44.76GiB/s\r\n2020-02-29 18:26:24.240888: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n2020-02-29 18:26:24.544030: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll\r\n2020-02-29 18:26:24.727079: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll\r\n2020-02-29 18:26:24.811098: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll\r\n2020-02-29 18:26:24.994088: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll\r\n2020-02-29 18:26:25.075048: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll\r\n2020-02-29 18:26:25.508640: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\r\n2020-02-29 18:26:25.513010: F tensorflow/stream_executor/lib/statusor.cc:34] Attempting to fetch value instead of handling error Internal: failed to get device attribute 13 for device 0: CUDA_ERROR_UNKNOWN: unknown error`\r\n\r\nWhen it's run inside a Jupyter notebook, the kernel freezes for a while and then restarts.\r\n\r\n**Other info / logs** \r\n![Capture2](https://user-images.githubusercontent.com/5057255/75608230-b95bb700-5b23-11ea-802a-1ce3b7d8c252.PNG)\r\n", "comments": ["Updating the NVIDIA driver from version 430.90 to the latest version (441.37) solved the problem", "@shehanmunasinghe, Glad that its resolved. \r\nClosing this issue, please feel free to open if you still face the issue . Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37186\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37186\">No</a>\n", "I just wanted to note that I had the very same problem after upgrading to Anaconda 2020.02 and TF 2.1.0. I upgraded my NVIDIA driver (for GTX 850M) and it all workie...", "thank you very much!best wish to you!"]}, {"number": 37185, "title": "Tensorflow 2.1.0 causing all RAM to be consumed on model.fit", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow): \r\n- OS Platform and Distribution (e.g.,\r\nLinux Ubuntu 16.04): Linux Ubuntu 19\r\n\r\n- Tensorflow version: 2.1.0cp37\r\n- CUDA/cuDNN version: - GPU model and memory:\r\n1070 GTX 8 GB GDDR5\r\n\r\n**Describe the current behavior**\r\nI am using tf.data dataset API. When using model.fit, on the first epoch, I am already consuming 16 GB of RAM when I run with GPU, but when I run with CPU the memory consumption is very small. \r\n\r\nEDIT: tensorflow-cpu actually has the same issue with high memory consumption\r\n\r\nSame dataset, same code. This only happens in Tensorflow 2.>\r\n\r\nIs this a known issue? What can I do as a temporarily fix?\r\n\r\n**Standalone code to reproduce the issue** \r\nJust a simpel model, with a dataset which loads images:\r\n```\r\nmodel = models.Sequential()\r\nmodel.add(Conv2D(4, (9, 9), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)))\r\nmodel.add(MaxPooling2D((2, 2)))\r\nmodel.add(Conv2D(8, (9, 9), activation='relu'))\r\nmodel.add(MaxPooling2D((2, 2)))\r\nmodel.add(Conv2D(16, (9, 9), activation='relu'))\r\nmodel.add(MaxPooling2D((2, 2)))\r\n\r\n\r\nmodel.add(Flatten())\r\nmodel.add(Dense(5, activation='sigmoid'))\r\n\r\nmodel.summary()\r\n\r\nmodel.compile(optimizer='adam', loss=losses.binary_crossentropy, metrics=['accuracy'])\r\n\r\nhistory = model.fit(ds_train,\r\n                    steps_per_epoch=steps_per_epoch,\r\n                    validation_data=ds_val,\r\n                    validation_steps=validation_steps,\r\n                    epochs=10)\r\n```\r\n\r\nI should also mention that the images I am using are concatenated images that are 320px * 4 in width and 180 in height\r\n", "comments": ["Actually even when I use tensorflow-cpu, memory consumption is still very high:\r\n![image](https://user-images.githubusercontent.com/10367624/75608492-252c2880-5b00-11ea-913a-fd0ac85dcdff.png)\r\n", "@HadiSDev \r\n\r\nCould you please share colab link or simple standalone code with supporting files to reproduce the issue in our environment. It helps us in localizing the issue faster. Thanks!", "Here is the colab link: https://colab.research.google.com/drive/19p1PTKnje-tldQfYCTPimBT99bYK1y7N\r\n\r\nIt is working on colab but not on my own pc. ", "Exact same code and the same pictures", "Might be related to: https://github.com/tensorflow/tensorflow/issues/35030", "It gets worse when I use concatenated images where it is 320px * 4 in width. \r\nI have tried in 2.0.0 (all versions), but with no luck", "Yes @HadiSDev Looks like it is indeed duplicate of #35030 ", "Did you try using the latest tf-nightly version i.e., 2.2dev0 @HadiSDev ?", "I was going to try but when I try to import tensorflow i get:\r\n```\r\nPython 3.7.5 (default, Nov 20 2019, 09:21:52) \r\n[GCC 9.2.1 20191008] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/hadi/.local/lib/python3.7/site-packages/tensorflow/__init__.py\", line 48, in <module>\r\n    from ._api.v2 import compat\r\n  File \"/home/hadi/.local/lib/python3.7/site-packages/tensorflow/_api/v2/compat/__init__.py\", line 39, in <module>\r\n    from . import v1\r\n  File \"/home/hadi/.local/lib/python3.7/site-packages/tensorflow/_api/v2/compat/v1/__init__.py\", line 34, in <module>\r\n    from . import compat\r\n  File \"/home/hadi/.local/lib/python3.7/site-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py\", line 39, in <module>\r\n    from . import v1\r\n  File \"/home/hadi/.local/lib/python3.7/site-packages/tensorflow/_api/v2/compat/v1/compat/v1/__init__.py\", line 673, in <module>\r\n    _module_dir = _module_util.get_parent_dir_for_name(_estimator_module)\r\n  File \"/home/hadi/.local/lib/python3.7/site-packages/tensorflow/python/tools/module_util.py\", line 62, in get_parent_dir_for_name\r\n    if not spec.origin:\r\nAttributeError: 'NoneType' object has no attribute 'origin'\r\n```", "@HadiSDev Can you try reinstalling tensorflow 2.2.0 and let me know if the issue still persists. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing this issue as it has been inactive for more than 3 weeks. Please add additional comments for us to open this issue again. Thanks!"]}, {"number": 37184, "title": "Serialization fails for nested models (models containing another model)", "body": "Looks like a duplicate of #37158\r\n\r\n**System information** \r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):  Custom code, Auto-encoder sample, based on a tutorial:\r\nhttps://www.pyimagesearch.com/2020/02/17/autoencoders-with-keras-tensorflow-and-deep-learning/\r\n\r\n- OS Platform and Distribution \r\nWindows 10\r\n- TensorFlow installed from (source orbinary): \r\npip install tensorflow-gpu\r\n- TensorFlow version (use command below): \r\nv2.1.0-rc2-17-ge5bf8de410 2.1.0\r\n- Python version:\r\n3.7.6\r\n - Bazel version (if compiling from source):\r\nnot used\r\n- GCC/Compiler version (if compiling from source): \r\nnot used\r\n- CUDA/cuDNN version: - GPU model and memory:\r\nCUDA Version 10.1.243\r\ncudnn-10.1-windows10-x64-v7.6.5.32\r\n\r\n**Describe the current behavior**\r\nsaving autoencoder throws\r\n`WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000002065515D678> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, export AUTOGRAPH_VERBOSITY=10) and attach the full output.\r\nCause: WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000002065515D678> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, export AUTOGRAPH_VERBOSITY=10) and attach the full output.\r\nCause: INFO:tensorflow:Assets written to: test\\assets`\r\n\r\nloading the saved model fails with the message\r\n`keras.models.load_model('run/autoencoder/')\r\nTraceback (most recent call last):\r\n  File \"<ipython-input-39-0e89c2f914ad>\", line 1, in <module>\r\n    keras.models.load_model('run/autoencoder/')\r\n  File \"c:\\python37\\lib\\site-packages\\tensorflow_core\\python\\keras\\saving\\save.py\", line 150, in load_model\r\n    return saved_model_load.load(filepath, compile)\r\n  File \"c:\\python37\\lib\\site-packages\\tensorflow_core\\python\\keras\\saving\\saved_model\\load.py\", line 89, in load\r\n    model = tf_load.load_internal(path, loader_cls=KerasObjectLoader)\r\n  File \"c:\\python37\\lib\\site-packages\\tensorflow_core\\python\\saved_model\\load.py\", line 552, in load_internal\r\n    export_dir)\r\n  File \"c:\\python37\\lib\\site-packages\\tensorflow_core\\python\\keras\\saving\\saved_model\\load.py\", line 119, in __init__\r\n    self._finalize()\r\n  File \"c:\\python37\\lib\\site-packages\\tensorflow_core\\python\\keras\\saving\\saved_model\\load.py\", line 157, in _finalize\r\n    created_layers={layer.name: layer for layer in node.layers})\r\n  File \"c:\\python37\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\", line 1903, in reconstruct_from_config\r\n    process_node(layer, node_data)\r\n  File \"c:\\python37\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\", line 1851, in process_node\r\n    output_tensors = layer(input_tensors, **kwargs)\r\n  File \"c:\\python37\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\", line 773, in __call__\r\n    outputs = call_fn(cast_inputs, *args, **kwargs)\r\n  File \"c:\\python37\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\", line 712, in call\r\n    raise NotImplementedError('When subclassing the Model class, you should'\r\nNotImplementedError: When subclassing the Model class, you should implement a call method.`\r\n\r\nsaving and loading of encode/decoder models works, but for autoencoder it fails, therefor I suspect that this is related to nested models\r\n\r\n**Describe the expected behavior**\r\nsave / load cycle works without error message\r\n\r\n**Standalone code to reproduce the issue** \r\n\r\n[train_auto_encoder_mnist.py.txt](https://github.com/tensorflow/tensorflow/files/4270255/train_auto_encoder_mnist.py.txt)\r\n\r\nCode is based on a tutorial form\r\nhttps://www.pyimagesearch.com/2020/02/17/autoencoders-with-keras-tensorflow-and-deep-learning/", "comments": ["@ArnoSchaepe,\r\nI was able to run the code from the given link without any issues. Please find the gist of it [here](https://colab.sandbox.google.com/gist/amahendrakar/016664986b3a85397336150d03e37d19/37184-from-tutorial.ipynb). Thanks!", "Sorry the code I uploaded does not reproduce the issue correctly. As it really seems to be a duplicate of 37158 I would propose to close this issue."]}, {"number": 37183, "title": "Remote monitoring of DL models", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 2.1.0\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nAn app or a website that lets you remotely monitor your deep learning model's metrics. It can also notify you when your model has completed training or has crashed. I have worked on this before and I wish it could come inbuilt with Tensorflow. You can check out that project [here](https://github.com/CleanPegasus/TensorDash). \r\n\r\n**Will this change the current api? How?**\r\nThere will be a few miscellaneous codes added to the tensorflow library.\r\n\r\n**Who will benefit with this feature?**\r\nThis will benefit the researchers who are training huge models. This will save them a lot of time.\r\n\r\n**Any Other info.**\r\n", "comments": ["I would like to work on it as a G-SOC project.", "How is this different from TensorBoard?", "Tensorboard does lets you monitor your model through a remote server. It is quite complicated and mot many can afford a remote server. My friend and I worked on an app that makes it easy for remote monitoring and notifies you when your model has completed or crashed.\r\n<br>\r\nIt'll be easy for people to use this compared to a remote server since they get all the details in an app.\r\nSomething like this\r\n![sample](https://user-images.githubusercontent.com/42714467/75746995-d2da4a00-5d41-11ea-9326-e8f0da37102b.jpeg)\r\n", "Great! It seems you have created all you need. What is this issue about?\n", "I'm hoping to add this to tensorboard as my G-soc project. Is it possible?", "You should file an issue at tensorflow/tensorboard.\n\nSince you already have this up and running, it's not entirely clear to me\nwhat \"adding it to TensorBoard\" would entail. But you can clarify there.\n", "Thank you!"]}, {"number": 37182, "title": "Could not find any TF GPUs when I use trt_convert", "body": "I use:\r\nOS: 16.04\r\ncuda: 10.2\r\ncudnn: 7\r\npython:3.6\r\ntensorflow-gpu:2.1\r\nGPU: Titan V - 12GB\r\nI convert model tensorflow to tensorRT:\r\n`from tensorflow.python.compiler.tensorrt import trt_convert as trt`\r\n`input_saved_model_dir = \"./model_tensor/\"`\r\n`output_saved_model_dir = \"./model_tensor_rt/\"`\r\n`converter = trt.TrtGraphConverterV2(input_saved_model_dir=input_saved_model_dir)`\r\n`converter.convert()`\r\n`converter.save(output_saved_model_dir)`\r\n\r\nI still can inference model on tensorflow:\r\nHowever I cannot convert to tensorRT: \r\n\r\n2020-02-29 17:19:35.901924: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:102]Could not find any TF GPUs\r\n\r\n2020-02-29 17:19:35.901927: W tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:726] Can't identify the cuda device. Running on device 0 \r\n\r\n2020-02-29 17:19:35.901958: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:737] Replaced segment 5 consisting of 4 nodes by \r\nStatefulPartitionedCall/X/Y/TRTEngineOp_5.\r\n\r\nThanks", "comments": ["@kimchicanh \r\n\r\nCan you please go through the [link](https://www.tensorflow.org/api_docs/python/tf/experimental/tensorrt/Converter) and see if it helps you. If it does not solve your issue, please share the simple standalone code with supporting files to\r\nreproduce the issue in our environment. It helps us in localizing the issue faster. Thanks!", "@ravikyram Thanks you. I try your link but it still fail. I send you my model yolo tiny v3, code and log file\r\n[link](https://drive.google.com/drive/folders/1xR5FziDC4m8Lv-eTiNXUNvegOKmBhu_r?usp=sharing)\r\n\r\nThis is my export CUDA:\r\nexport PATH=/usr/local/cuda-10.2/bin:/usr/local/cuda-10.2/NsightCompute-2019.1${PATH:+:${PATH}}\r\nexport LD_LIBRARY_PATH=/usr/local/cuda-10.2/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}\r\nexport CUDA_HOME=/usr/local/cuda-10.2\r\nThanks\r\n\r\n\r\n", "@kimchicanh \r\n\r\nWill it be possible for you to check with CUDA 10.1 and see still you are facing the issue? Thanks!", "@ravikyram thanks, I just change to 10.1, and there are new log file, [link](https://drive.google.com/drive/folders/1xR5FziDC4m8Lv-eTiNXUNvegOKmBhu_r?usp=sharing)\r\n\r\nIt is core dumped", "@ravikyram @ymodak Hi, Are there any solution???", "@kimchicanh \r\nIs this still an issue in the latest tf version as many bugs have been solved could you please confirm.", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37182\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37182\">No</a>\n"]}, {"number": 37181, "title": "tf2.0 when use large input dims in tf.keras.layers.Embedding layer under eager mode, it turns to be very slow", "body": "<em>Please make sure that this is an issue related to performance of TensorFlow.\r\nAs per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:performance_template</em>\r\n\r\n**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow):  yes\r\n- OS Platform and Distribution (e.g.,\r\nLinux Ubuntu 16.04):  centos7\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if\r\nthe issue happens on mobile device: \r\n- TensorFlow installed from (source or\r\nbinary): - TensorFlow version (use command below):  2.0.0\r\n- Python version: - Bazel \r\nversion (if compiling from source): 3.6.8\r\n- GCC/Compiler version (if compiling from\r\nsource):  \r\n- CUDA/cuDNN version: - GPU model and memory: CUDA10.0 tesla v100 16G\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\ni set the input dims be 10,000,000 when I use tf.keras.layers.Embedding. Under the eager mode(default), mode.fit() is very slow. But when i disable the eager mode, the speed turns to be normal.\r\n**Describe the expected behavior**\r\nit should be no difference if i enable eager mode or not.\r\n**Standalone code to reproduce the issue** \r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n```\r\ntest_input = tf.ones((1000, 1), dtype=tf.int64)\r\nlabel = tf.ones((1000, 1))\r\nm_input = Input(shape=(1,))\r\ndense = Embedding(5000000, 16,name='embed')(m_input)\r\ndense = Dense(10)(dense)\r\ndense = Dense(5)(dense)\r\noutput = Dense(1,'sigmoid')(Flatten()(dense))\r\nmodel = Model(inputs=[m_input], outputs=[output])\r\nmodel.compile(\"adam\", loss='binary_crossentropy')\r\nmodel.fit(test_input, label, steps_per_epoch=1000, epochs=1)\r\n```\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\n```\r\nwhen use eager mode, time cost is as follow\r\n\r\n1/1000 [..............................] - ETA: 29:49 - loss: 0.7492\r\n2/1000 [..............................] - ETA: 25:54 - loss: 0.7430\r\n3/1000 [..............................] - ETA: 24:58 - loss: 0.7368\r\n4/1000 [..............................] - ETA: 24:21 - loss: 0.7307\r\n\r\ndisable the eager mode using tf.compat.v1.disable_eager_execution()\r\n\r\n\r\n 706/1000 [====================>.........] - ETA: 0s - loss: 0.0520\r\n 765/1000 [=====================>........] - ETA: 0s - loss: 0.0484\r\n 819/1000 [=======================>......] - ETA: 0s - loss: 0.0455\r\n 870/1000 [=========================>....] - ETA: 0s - loss: 0.0430\r\n 926/1000 [==========================>...] - ETA: 0s - loss: 0.0406\r\n 984/1000 [============================>.] - ETA: 0s - loss: 0.0384\r\n1000/1000 [==============================] - 2s 2ms/step - loss: 0.0379\r\n\r\n```\r\n", "comments": ["anyone can helps?", "Was able to reproduce the issue, noticed significant time difference with eager mode [enabled](https://colab.sandbox.google.com/gist/amahendrakar/c3d6a26fda1dd7ea937cf35b1b853292/37181.ipynb) and [disabled](https://colab.sandbox.google.com/gist/amahendrakar/b94900e29ea7509d41d4222f7a80e15d/37181-w-o-eager.ipynb). Got similar results with TF-nightly too. Please find the attached gist. Thanks!", "@nnnnwang There has been quite some updates in 2.2 for eager performance, would you mind re-trying on the latest version and see if the issue goes away?", "I have executed your code in **`Tensorflow Version 2.5`** and could see not much difference in the **`performance`**, between [Eager](https://colab.research.google.com/gist/rmothukuru/c7e69db93fb36254a3c105baed596220/37181.ipynb) and [non-Eager](https://colab.research.google.com/gist/rmothukuru/9069bb355bf55e9db6b77fef08c48c58/37181-w-o-eager.ipynb) Execution.  Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 37180, "title": "tf.keras.callbacks.TensorBoard  type profiling support for straight Tensorflow", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 1.15\r\n- Are you willing to contribute it (Yes/No):\r\nNo sure.\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\ntf.keras.callbacks.TensorBoard has a nice and simple way to  do profiling and  throwing the result up on Tensorboard.  It would be great to have that easy feature also for plain TF (sess.run).  \r\n\r\nIn addition, I think  the following enhancements will be very useful. \r\n1.  Ability to aggregate a number of traces.\r\n2.  Backport the range of batch ( instead of just one batch ) from 2.x to 1.5 ?\r\n3.  Linking the  time line traces with graph in both direction, from profile to graph and vice-versa.\r\n4.  The Op names in the graph and profile should exactly match. Currently they are not exactly same ( e.g. out_0/MatMul:_MklMatMul vs out_0/MatMul/(MatMul) ).\r\n5. There seems to be a number of different ways to profile straight TF and Keras. The following are what I am able to  find (so far, not sure if there are more).  Clear, concise and comprehensive documentation will be good.\r\n           - tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE) and tf.compat.v1.summary.FileWriter.add_run_metadata() .  Seems to be graph annotations and does not seem to capture Keras  backprop part.\r\n           -  tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE) and timeline.Timeline() - seems to work with both TF and Keras. However generates  JSON and hence does not get displayed by Tensorbaord. \r\n           - tf.keras.callbacks.TensorBoard() - only works with Keras and captures only one batch out off all in the epoch. \r\n\r\n**Will this change the current api? How?**\r\nN/A\r\n\r\n**Who will benefit with this feature?**\r\nEvery user. \r\n**Any Other info.**\r\n", "comments": ["Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information."]}, {"number": 37179, "title": "Wrong \"name\" parameter default for Nadam optimizer", "body": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Nadam\r\n\r\n## Description of issue (what needs changing):\r\nOptional name attribute is said to default as \"Adamax\" rather than \"Nadam\"\r\n\r\n### Clear description\r\n\r\nname: Optional name for the operations created when applying gradients. Defaults to \"Adamax\".\r\n\r\n### Correct links\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/keras/optimizer_v2/nadam.py#L33-L238\r\n\r\nSource code correctly shows default as name=\"Nadam\". Therefore documentation issue.\r\n\r\n### Submit a pull request?\r\n\r\nNot at the moment", "comments": ["Please close this issue. The error was resolved in #37111 "]}, {"number": 37178, "title": ".prefetch() and .cache() not speeding up tf.data.Dataset pipeline ", "body": "I have a very big dataset so I am training over small chunks using keras.fit. \r\nFor loading chunks in memory I have a generator function which generates a tuple of tensors of variable size which I pass to tf.data.Dataset to create a data pipeline.\r\n\r\n```\r\ndef extract_XY(list_idx):\r\n    read_files(list_idx)\r\n    append to list X\r\n    process, reshape and convert to tensor X (?,100,100,3)  #? means variable size\r\n    Y = f(X)  \r\n    return X,Y\r\n\r\nfor i in range(epochs):\r\n    for j in range(chunks):\r\n        x,y = extract_XY(list_idx) #list_idx changes in each loop\r\n        data = tf.data.Dataset.from_tensor_slices((X,Y)).batch(64).cache().prefetch(tf.data.experimental.AUTOTUNE)\r\n        model.fit(data,epochs=2,verbose=1)\r\n\r\n```\r\n\r\nMy training with keras fit works fine but I see no speed up using .cache() or .prefetch()\r\nCan anyone help me understand if I am using them correctly in my case.\r\n\r\nCan I make my data-pipeline more efficient i.e., loading next chunk while model is training? any suggestions would be helpfull?\r\nDoes using multiprocessing=True in Keras.fit() will help more? or tf.data.Dataset is already taking care of I/O bottleneck.\r\n\r\n\r\nThanks in advance!\r\n\r\n\r\n\r\n", "comments": ["@Jamesswiz,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here and also the TensorFlow version you are using. Thanks!", "[This](https://github.com/tensorflow/tensorflow/issues/24520#issuecomment-596213250) helped in my case. Using Keras' `model.fit()`\r\n\r\nBut is this the correct implementation? Or is this a bad way to do it?", "Any updates regarding this issue? Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37178\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37178\">No</a>\n", "same issues\r\n", "@WillLiGitHub,\r\nCould you please submit a new issue from [this link](https://github.com/tensorflow/tensorflow/issues/new/choose) and fill in the template, so that we can track the issue there. Thanks!"]}, {"number": 37177, "title": "NotImplementedError: Cannot convert a symbolic Tensor (up_sampling2d_5_target_2:0) to a numpy array.", "body": "```\r\nimport keras.backend as K\r\nfrom keras.optimizers import Adam\r\nfrom keras.losses import binary_crossentropy\r\n\r\n## intersection over union\r\ndef IoU(y_true, y_pred, eps=1e-6):\r\n    print(y_true)\r\n    if np.max(y_true) == 0.0:\r\n        return IoU(1-y_true, 1-y_pred) ## empty image; calc IoU of zeros\r\n    #if 0 == K.equal(y_true, 0):\r\n    #    y_true = K.switch(0, 1-y_true, y_true)\r\n    #    y_pred = K.switch(0, 1-y_pred, y_pred)\r\n    #    return IoU(1-y_true, 1-y_pred) ## empty image; calc IoU of zeros\r\n        \r\n    intersection = K.sum(y_true * y_pred, axis=[1,2,3])\r\n    union = K.sum(y_true, axis=[1,2,3]) + K.sum(y_pred, axis=[1,2,3]) - intersection\r\n    return -K.mean( (intersection + eps) / (union + eps), axis=0)\r\n```\r\n\r\n\r\n> Tensor(\"up_sampling2d_5_target_2:0\", shape=(None, None, None, None), dtype=float32)\r\n> ---------------------------------------------------------------------------\r\n> NotImplementedError                       Traceback (most recent call last)\r\n> <ipython-input-26-466b05eae4fa> in <module>\r\n>      14 \r\n>      15 while True:\r\n> ---> 16     loss_history = fit()\r\n>      17     if np.min([mh.history['val_loss'] for mh in loss_history]) < -0.2:\r\n>      18         break\r\n> \r\n> <ipython-input-26-466b05eae4fa> in fit()\r\n>       1 def fit():\r\n> ----> 2     seg_model.compile(optimizer=Adam(1e-3, decay=1e-6), loss=IoU, metrics=['binary_accuracy'])\r\n>       3 \r\n>       4     step_count = min(MAX_TRAIN_STEPS, train_df.shape[0]//BATCH_SIZE)\r\n>       5     aug_gen = create_aug_gen(make_image_gen(train_df))\r\n> \r\n> ~/venv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py in symbolic_fn_wrapper(*args, **kwargs)\r\n>      73         if _SYMBOLIC_SCOPE.value:\r\n>      74             with get_graph().as_default():\r\n> ---> 75                 return func(*args, **kwargs)\r\n>      76         else:\r\n>      77             return func(*args, **kwargs)\r\n> \r\n> ~/venv/lib/python3.7/site-packages/keras/engine/training.py in compile(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\r\n>     227         #                   loss_weight_2 * output_2_loss_fn(...) +\r\n>     228         #                   layer losses.\r\n> --> 229         self.total_loss = self._prepare_total_loss(masks)\r\n>     230 \r\n>     231         # Functions for train, test and predict will\r\n> \r\n> ~/venv/lib/python3.7/site-packages/keras/engine/training.py in _prepare_total_loss(self, masks)\r\n>     690 \r\n>     691                     output_loss = loss_fn(\r\n> --> 692                         y_true, y_pred, sample_weight=sample_weight)\r\n>     693 \r\n>     694                 if len(self.outputs) > 1:\r\n> \r\n> ~/venv/lib/python3.7/site-packages/keras/losses.py in __call__(self, y_true, y_pred, sample_weight)\r\n>      69         scope_name = 'lambda' if self.name == '<lambda>' else self.name\r\n>      70         with K.name_scope(scope_name):\r\n> ---> 71             losses = self.call(y_true, y_pred)\r\n>      72             return losses_utils.compute_weighted_loss(\r\n>      73                 losses, sample_weight, reduction=self.reduction)\r\n> \r\n> ~/venv/lib/python3.7/site-packages/keras/losses.py in call(self, y_true, y_pred)\r\n>     130             Loss values per sample.\r\n>     131         \"\"\"\r\n> --> 132         return self.fn(y_true, y_pred, **self._fn_kwargs)\r\n>     133 \r\n>     134     def get_config(self):\r\n> \r\n> <ipython-input-24-d1d9fb424ded> in IoU(y_true, y_pred, eps)\r\n>       6 def IoU(y_true, y_pred, eps=1e-6):\r\n>       7     print(y_true)\r\n> ----> 8     if np.max(y_true) == 0.0:\r\n>       9         return IoU(1-y_true, 1-y_pred) ## empty image; calc IoU of zeros\r\n>      10     #if 0 == K.equal(y_true, 0):\r\n> \r\n> <__array_function__ internals> in amax(*args, **kwargs)\r\n> \r\n> ~/venv/lib/python3.7/site-packages/numpy/core/fromnumeric.py in amax(a, axis, out, keepdims, initial, where)\r\n>    2619     \"\"\"\r\n>    2620     return _wrapreduction(a, np.maximum, 'max', axis, None, out,\r\n> -> 2621                           keepdims=keepdims, initial=initial, where=where)\r\n>    2622 \r\n>    2623 \r\n> \r\n> ~/venv/lib/python3.7/site-packages/numpy/core/fromnumeric.py in _wrapreduction(obj, ufunc, method, axis, dtype, out, **kwargs)\r\n>      88                 return reduction(axis=axis, out=out, **passkwargs)\r\n>      89 \r\n> ---> 90     return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\r\n>      91 \r\n>      92 \r\n> \r\n> ~/venv/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py in __array__(self)\r\n>     734   def __array__(self):\r\n>     735     raise NotImplementedError(\"Cannot convert a symbolic Tensor ({}) to a numpy\"\r\n> --> 736                               \" array.\".format(self.name))\r\n>     737 \r\n>     738   def __len__(self):\r\n> \r\n> NotImplementedError: Cannot convert a symbolic Tensor (up_sampling2d_5_target_2:0) to a numpy array.", "comments": ["@SlowMonk, thanks for reporting this issue.\r\nCan you post the complete code to replicate the reported issue and also provide Tensorflow version that you are using. Thanks", "import keras\r\nimport tensorflow as tf\r\nprint(keras.__version__)\r\nprint(tf.__version__)\r\n2.3.1\r\n2.0.0", "@SlowMonk, I tried replicating the issue with Tf 2.0 but looks like code is incomplete to reproduce the issue. Please take a look at gist [here](https://colab.sandbox.google.com/gist/gadagashwini/be6355138fa9668e4faaf7fc25d48730/untitled415.ipynb). Thanks!", "@SlowMonk, Did you check the above provided gist. ", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "NotImplementedError                       Traceback (most recent call last)\r\n<ipython-input-36-6d13580ffc58> in <module>\r\n      5 \r\n      6     # Synthetic Data Generation\r\n----> 7     dataX_hat, loss_list = timegan(dataX, parameters)  # Returns to synthetic dataset and stored loss values\r\n      8     losses.append(loss_list)\r\n      9     print('Finish Synthetic Data Generation')\r\n\r\nD:\\Juypter_Sujan\\CS591_TimeGAN\\tgan.py in timegan(data, params)\r\n    184     # LOSSES\r\n    185 \r\n--> 186     D_loss, G_loss, S_loss, E_loss, E_loss_only, G_loss_adv_sup, G_loss_V = get_losses(Y_real, Y_fake, Y_fake_sup, H, H_sup, X_tilde_fake_sup, X, X_tilde)\r\n    187 \r\n    188 \r\n\r\nD:\\Juypter_Sujan\\CS591_TimeGAN\\tgan.py in get_losses(Y_real, Y_fake, Y_fake_sup, H, H_sup, X_tilde_fake_sup, X, X_tilde)\r\n    115       G_loss_adv = tf.losses.sigmoid_cross_entropy(tf.ones_like(Y_fake), Y_fake)\r\n    116       #generator mean and variance difference L1 loss\r\n--> 117       G_loss_V1 = tf.reduce_mean(np.abs(tf.sqrt(tf.nn.moments(X_tilde_fake_sup,[0])[1] + 1e-6) - tf.sqrt(tf.nn.moments(X,[0])[1] + 1e-6)))\r\n    118       G_loss_V2 = tf.reduce_mean(np.abs((tf.nn.moments(X_tilde_fake_sup,[0])[0]) - (tf.nn.moments(X,[0])[0])))\r\n    119       G_loss_V = G_loss_V1 + G_loss_V2\r\n\r\nD:\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py in __array__(self)\r\n    734   def __array__(self):\r\n    735     raise NotImplementedError(\"Cannot convert a symbolic Tensor ({}) to a numpy\"\r\n--> 736                               \" array.\".format(self.name))\r\n    737 \r\n    738   def __len__(self):\r\n\r\nNotImplementedError: Cannot convert a symbolic Tensor (sub:0) to a numpy array.", "complete code as below\r\n\r\ndef timegan(data, params):\r\n    tf.reset_default_graph()\r\n    data_len = len(data)\r\n    data_dim = len(data[0][0,:])\r\n    max_seq_len = len(data[0][:,0])\r\n    seq_len_list = []\r\n\r\n    for i in range(data_len):\r\n        seq_len = len(data[i][:,0])\r\n        seq_len_list.append(seq_len)\r\n        if max_seq_len < seq_len:\r\n            max_seq_len = seq_len\r\n    \r\n    # Get Parameters\r\n    hidden_dim   = params['hidden_dim'] \r\n    num_layers   = params['num_layers']\r\n    iterations   = params['iterations']\r\n    batch_size   = params['batch_size']\r\n    module_name  = params['module_name']  \r\n    z_dim        = params['z_dim']\r\n    gamma        = 1\r\n    \r\n    # input place holders\r\n    \r\n    X = tf.placeholder(tf.float32, [None, max_seq_len, data_dim], name = \"input_x\")\r\n    Z = tf.placeholder(tf.float32, [None, max_seq_len, params['z_dim']], name = \"input_z\")\r\n    T = tf.placeholder(tf.int32, [None], name = \"input_t\")\r\n\r\n    \r\n    \r\n    H = embedder(X, T, params) # input mapped into the embedding space\r\n    X_tilde = recovery(H, T, params, data_dim) # recovered input with recovery function\r\n    \r\n    # Generator\r\n    H_fake = generator(Z, T, params) # Generated data\r\n    H_fake_sup = supervisor(H_fake, T, params) # Supervising the fake data\r\n    H_sup = supervisor(H, T, params) # Supervising the real data\r\n    \r\n    # Synthetic data\r\n    X_tilde_fake_sup = recovery(H_fake_sup, T, params, data_dim) # Fake data recovered\r\n    \r\n    # Discriminator\r\n    Y_fake_sup = discriminator(H_fake_sup, T, params)  #Supervised fake data classification outputs\r\n    Y_real = discriminator(H, T, params) # Real data classification outputs\r\n    Y_fake = discriminator(H_fake, T, params) #Fake data classification outputs\r\n    \r\n    # Variables        \r\n    emb_vars = [v for v in tf.trainable_variables() if v.name.startswith('embedder')]\r\n    rec_vars = [v for v in tf.trainable_variables() if v.name.startswith('recovery')]\r\n    gen_vars = [v for v in tf.trainable_variables() if v.name.startswith('generator')]\r\n    sup_vars = [v for v in tf.trainable_variables() if v.name.startswith('supervisor')]\r\n    dis_vars = [v for v in tf.trainable_variables() if v.name.startswith('discriminator')]\r\n    \r\n    # LOSSES\r\n   \r\n    D_loss, G_loss, S_loss, E_loss, E_loss_only, G_loss_adv_sup, G_loss_V = get_losses(Y_real, Y_fake, Y_fake_sup, H, H_sup, X_tilde_fake_sup, X, X_tilde)\r\n    \r\n     \r\n    # optimizer\r\n    E0_opt = tf.train.AdamOptimizer().minimize(E_loss_only, var_list = emb_vars + rec_vars)\r\n    E_opt = tf.train.AdamOptimizer().minimize(E_loss, var_list = emb_vars + rec_vars)\r\n    D_opt = tf.train.AdamOptimizer().minimize(D_loss, var_list = dis_vars)\r\n    G_opt = tf.train.AdamOptimizer().minimize(G_loss, var_list = gen_vars + sup_vars)      \r\n    S_opt = tf.train.AdamOptimizer().minimize(S_loss, var_list = gen_vars + sup_vars)   \r\n    \r\n    \r\n    session = tf.Session()\r\n    session.run(tf.global_variables_initializer())\r\n    e_loss_list = []\r\n    s_loss_list = []\r\n    d_loss_list = []\r\n    g_loss_adv_list = []\r\n    g_loss_v_list = []\r\n    e_loss_joint_list = []\r\n    s_loss_joint_list = []        \r\n    #Embedder training\r\n    \r\n    for i in range(params['iterations']):\r\n        \r\n        # Batch setting\r\n        index = np.random.permutation(data_len)\r\n        train_index = index[:params['batch_size']]   \r\n            \r\n        X_mb = list(data[j] for j in train_index)\r\n        T_mb = list(seq_len_list[j] for j in train_index)\r\n            \r\n        # Train embedder        \r\n        _, step_e_loss = session.run([E0_opt, E_loss_only], feed_dict={X: X_mb, T: T_mb})\r\n        \r\n        if i % 10 == 0:\r\n            print('step: '+ str(i) + ', e_loss: ' + str(np.round(np.sqrt(step_e_loss),4)) ) \r\n            e_loss_list.append(np.round(np.sqrt(step_e_loss),4))\r\n    \r\n    # Supervisor training\r\n    \r\n    for i in range(params['iterations']):\r\n        \r\n        # Batch setting\r\n        index = np.random.permutation(data_len)\r\n        train_index = index[:params['batch_size']]   \r\n            \r\n        X_mb = list(data[j] for j in train_index)\r\n        T_mb = list(seq_len_list[j] for j in train_index)      \r\n        \r\n        Z_mb = random_generator(params['batch_size'], params['z_dim'], T_mb, max_seq_len)\r\n        \r\n        # Train generator       \r\n        _, step_s_loss = session.run([S_opt, S_loss], feed_dict={Z: Z_mb, X: X_mb, T: T_mb})\r\n\r\n                           \r\n        if i % 10 == 0:\r\n            print('step: '+ str(i) + ', s_loss: ' + str(np.round(np.sqrt(step_s_loss),4)))\r\n            s_loss_list.append(np.round(np.sqrt(step_s_loss),4))\r\n    #Joint Training\r\n            \r\n    for i in range(params['iterations']):\r\n      \r\n        # Generator Training\r\n        for kk in range(2): #FIXME: Why 2 ?\r\n          \r\n            # Batch setting\r\n            index = np.random.permutation(data_len)\r\n            train_index = index[:params['batch_size']] \r\n            \r\n            X_mb = list(data[j] for j in train_index)\r\n            T_mb = list(seq_len_list[j] for j in train_index)     \r\n            \r\n            # Random vector generation\r\n            Z_mb = random_generator(params['batch_size'], params['z_dim'], T_mb, max_seq_len)\r\n            \r\n            # Train generator\r\n            _, step_g_loss_adv, step_s_loss, step_g_loss_v = session.run([G_opt, G_loss_adv_sup, S_loss, G_loss_V], feed_dict={Z: Z_mb, X: X_mb, T: T_mb})\r\n            \r\n            # Train embedder        \r\n            _, step_e_loss_only = session.run([E_opt, E_loss_only], feed_dict={Z: Z_mb, X: X_mb, T: T_mb})   \r\n           \r\n        # Discriminator Training\r\n        \r\n        # Batch setting\r\n        index = np.random.permutation(data_len)\r\n        train_index = index[:params['batch_size']]  \r\n        \r\n        X_mb = list(data[j] for j in train_index)\r\n        T_mb = list(seq_len_list[j] for j in train_index)  \r\n        \r\n        # Random vector generation\r\n        Z_mb = random_generator(params['batch_size'], params['z_dim'], T_mb, max_seq_len)\r\n            \r\n        \r\n        d_loss = session.run(D_loss, feed_dict={X: X_mb, T: T_mb, Z: Z_mb})\r\n        \r\n        # Train discriminator\r\n        \r\n        if (d_loss > 0.15):        \r\n            _, step_d_loss = session.run([D_opt, D_loss], feed_dict={X: X_mb, T: T_mb, Z: Z_mb})\r\n        \r\n        # Checkpoints\r\n        if i % 10 == 0:\r\n            print('step: '+ str(i) + \r\n                  ', d_loss: ' + str(np.round(step_d_loss,4)) + \r\n                  ', g_loss_adv: ' + str(np.round(step_g_loss_adv,4)) + \r\n                  ', s_loss: ' + str(np.round(np.sqrt(step_s_loss),4)) + \r\n                  ', g_loss_v: ' + str(np.round(step_g_loss_v,4)) + \r\n                  ', e_loss_t0: ' + str(np.round(np.sqrt(step_e_loss_only),4)))\r\n            d_loss_list.append(np.round(step_d_loss,4))\r\n            g_loss_adv_list.append(np.round(step_g_loss_adv,4))\r\n            g_loss_v_list.append(np.round(step_g_loss_v,4))\r\n            s_loss_joint_list.append(np.round(np.sqrt(step_s_loss),4))\r\n            e_loss_joint_list.append(np.round(np.sqrt(step_e_loss_only),4))\r\n            \r\n        \r\n    Z_mb = random_generator(data_len, params['z_dim'], seq_len_list, max_seq_len)\r\n    out = session.run(X_tilde_fake_sup, feed_dict={Z: Z_mb, X: data, T: seq_len_list}) \r\n    loss_list = [e_loss_list, s_loss_list, d_loss_list, g_loss_adv_list, g_loss_v_list, e_loss_joint_list, s_loss_joint_list ]\r\n    output = []\r\n    for i in range(data_len):\r\n        temp_out = out[i,:seq_len_list[i],:]\r\n        output.append(temp_out)   \r\n        \r\n    return output, loss_list\r\n    \r\n   "]}, {"number": 37176, "title": "[Intel MKL] Supporting exponential_avg_factor attr for _MklFusedBatch\u2026", "body": "\u2026Norm ops\r\n\r\nThis PR supports exponential_avg_factor in MklBatchNorm ops to adjust the output mean/var.\r\n\r\nNew formula is\r\n\r\n```mean = (1 - exponential_avg_factor) * old_mean + exponential_avg_factor * batch_mean```\r\n```var = (1 - exponential_avg_factor) * old_var + exponential_avg_factor * batch_var * adjust```", "comments": ["Hi @penpornk, this is 2nd PR. I've added the description of the change. Pls let me know if that is not enough. Thanks in advance.", "@penpornk Sorry I missed your review comments. If some changes still need to be done, I will address them after branch cut. Thanks.", "@nhasabni I added a TODO for the refactoring. All the minor fixes are done. Thank you! :)", "@nhasabni (And no worries!)"]}, {"number": 37175, "title": "[Intel MKL] Making BFloat16 MatMul & BatchMatMul in DNNL 1.2 conditio\u2026", "body": "\u2026nally compilable\r\n\r\nThis PR makes BFloat16 support for MatMul and BatchMatMul conditionally compilable by\r\nremoving macros that were guarding DNNLv1.2 specific code. It also makes necessary\r\nchanges to Gemm helper functions in MklBatchMatMulOp to handle type-specific helper\r\nfunctions appropriately.", "comments": ["Hi @penpornk, I've added an explanation in the PR description. Let me know if that is not enough. I can add more details. Thanks."]}, {"number": 37174, "title": "Export encode_png to tf.io", "body": "Fix https://github.com/tensorflow/tensorflow/issues/37168\r\n\r\nCurrently, all Image decoding and encoding functions are available in the `tf.io` module but `encode_png` function is still only included in the `tf.image` module.", "comments": ["This changes API, so it needs API owners review.", "Thanks @vijayphoenix.\r\n\r\nThe context from the bug, makes it clear that this change gets `encode_png` more inline with all the other image encoding operations.  So I support it.\r\n\r\n@mihaimaruseac, what is the API review process for PRs? Are they part of the weekly api-review meeting?", "@MarkDaoust yes, they are reviewed during those meetings."]}, {"number": 37173, "title": "Null pointer to a converted model using Tensorflow Lite in Android Studio. \"Byte buffer is not a valid flatbuffer model.\" Exception", "body": "i made a model containing layers of type: Conv3D, MaxPool3D, Flatten, Dense and Batch normalization and converted it to tflite model as follows..\r\n\r\n```bash\r\nimport tensorflow as tf\r\n\r\nconverter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,\r\n                                       tf.lite.OpsSet.SELECT_TF_OPS]\r\ntflite_model = converter.convert()\r\n```\r\n\r\nThe problem is when i load this converted model in Android Studio it always gives me illegal argument exception saying  **\"Byte buffer is not a valid flatbuffer model\"** & a null pointer to it\r\n\r\ni also, specified this dependency in my build.gradle to add the necessary TF op support.\r\n\r\n```bash\r\ndependencies {\r\n    implementation 'org.tensorflow:tensorflow-lite:0.0.0-nightly'\r\n    implementation 'org.tensorflow:tensorflow-lite-select-tf-ops:0.0.0-nightly'\r\n} \r\n```\r\nAny help?", "comments": ["@mainouraldeen use tensorflow-nighty build gradle version 0.1.2\r\n` implementation 'org.tensorflow:tensorflow-lite:0.1.2-nightly'`\r\n\r\nFor more information Please go through this i[ssue](https://stackoverflow.com/questions/56256478/converted-model-tflite-does-not-encode-a-valid-tensorflowlite-model-could-not-o/56269570).", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "@mainouraldeen \r\n\r\nAny update on this issue please. Thanks!", "Closing this issue as it has been inactive for 4 weeks. Please add additional comments for us to open this issue again. Thanks!"]}, {"number": 37172, "title": "module 'tensorflow._api.v1.nn' has no attribute 'seq2seq'", "body": "when i execute this command \r\npython tensorflow/models/rnn/translate/translate.py \r\n\r\n\r\ni get \r\n\r\nPreparing WMT data in /home/baba055h_s/\r\n2020-02-28 17:45:29.997997: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2020-02-28 17:45:30.002826: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\r\n2020-02-28 17:45:30.003172: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55c1f9a006a0 executing computations on platform Host. Devices:\r\n2020-02-28 17:45:30.003209: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\r\nCreating 3 layers of 1024 units.\r\nWARNING:tensorflow:From /home/baba055h_s/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nColocations handled automatically by placer.\r\nWARNING:tensorflow:From /home/baba055h_s/ten3/tensorflow/tensorflow/models/rnn/translate/seq2seq_model.py:117: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nThis class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.\r\nWARNING:tensorflow:From /home/baba055h_s/ten3/tensorflow/tensorflow/models/rnn/translate/seq2seq_model.py:122: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nThis class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\r\nWARNING:tensorflow:At least two cells provided to MultiRNNCell are the same object and will share weights.\r\nTraceback (most recent call last):\r\n  File \"./translate.py\", line 290, in <module>\r\n    tf.app.run()\r\n  File \"/home/baba055h_s/anaconda3/lib/python3.7/site-packages/tensorflow/python/platform/app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"./translate.py\", line 287, in main\r\n    train()\r\n  File \"./translate.py\", line 152, in train\r\n    model = create_model(sess, False)\r\n  File \"./translate.py\", line 131, in create_model\r\n    dtype=dtype)\r\n  File \"/home/baba055h_s/ten3/tensorflow/tensorflow/models/rnn/translate/seq2seq_model.py\", line 168, in __init__\r\n    self.outputs, self.losses = tf.nn.seq2seq.model_with_buckets(\r\nAttributeError: module 'tensorflow._api.v1.nn' has no attribute 'seq2seq'\r\n\r\n\r\n\r\n\r\n\r\nplease can any one help", "comments": ["@mohlondon,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here and also the TensorFlow version you are using. Thanks!", "thank you for your reply i did managed to fix this by downgrading tensorflow to 0.12.1 version then it worked but i have a problem the chat i created it doesn't work correctly i guess it keep gigin me this resault no matter how much time i train it \r\n\r\n> python3 ./translate.py  --en_vocab_size=40000 --fr_vocab_size=40000 --data_dir=/home/baba055h_s/ --train_dir=/home/baba055h_s/ --decode\r\n/home/baba055h_s/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:463: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\r\n/home/baba055h_s/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:464: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\r\n/home/baba055h_s/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:465: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\r\n/home/baba055h_s/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:466: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\r\n/home/baba055h_s/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:467: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\r\nWARNING:tensorflow:From /home/baba055h_s/ten3/tensorflow/tensorflow/models/rnn/translate/seq2seq_model.py:188 in __init__.: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\r\nInstructions for updating:\r\nPlease use tf.global_variables instead.\r\nCreated model with fresh parameters.\r\nWARNING:tensorflow:From ./translate.py:138 in create_model.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\r\nInstructions for updating:\r\nUse `tf.global_variables_initializer` instead.\r\n/> hi\r\nsample sample sample sample sample sample sample sample letter-sized letter-sized\r\n>/> what's up\r\nsample sample sample soil soil soil neski neski neski neski\r\n\r\n\r\nsee what is that all about is it something wrong with the data i provided\r\nplease help me ", "@mohlondon,\r\nI was able to reproduce the error `AttributeError: module 'tensorflow._api.v1.nn' has no attribute 'seq2seq'` with [TF1.15](https://colab.sandbox.google.com/gist/amahendrakar/91c7aaada701ffd291ce90a73d652373/37172.ipynb#scrollTo=6m5QcJq4YXLi). \r\n\r\nHowever, running the code with [TF 0.12](https://colab.sandbox.google.com/gist/amahendrakar/33999ac65f2885262d08f9384d0e9a0c/37172-0-12.ipynb), gives a different error `TypeError: cannot use a bytes pattern on a string-like object`. Please find the attached gist. Thanks!", "Any updates regarding this issue? Thanks!", "The error you got it is because you used 0.12.0,  you need to use 0.12.1 version of tf\r\nBut,  I am trying to build my own model because i couldn't find the problem", "@mohlondon,\r\nSorry for the confusion. Even though the comment says TF v0.12, I am using TF v0.12.1, to run the code.\r\n\r\n> But, I am trying to build my own model because i couldn't find the problem\r\n\r\nCould you please elaborate your concern. Thanks!", "> @mohlondon,\r\n> I was able to reproduce the error `AttributeError: module 'tensorflow._api.v1.nn' has no attribute 'seq2seq'` with [TF1.15](https://colab.sandbox.google.com/gist/amahendrakar/91c7aaada701ffd291ce90a73d652373/37172.ipynb#scrollTo=6m5QcJq4YXLi).\r\n> \r\n> However, running the code with [TF 0.12](https://colab.sandbox.google.com/gist/amahendrakar/33999ac65f2885262d08f9384d0e9a0c/37172-0-12.ipynb), gives a different error `TypeError: cannot use a bytes pattern on a string-like object`. Please find the attached gist. Thanks!\r\n\r\nI am facing the same issue. Did you get any solution?\r\n", "@mohlondon,\r\n> Could you please elaborate your concern. Thanks!\r\n\r\nAny updates on this issue?\r\n\r\n@Zer0-dev115,\r\nI am still facing the same issue, no solution as of now. \r\n\r\nThanks! ", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "AttributeError: module 'tensorflow._api.v1.nn' has no attribute 'seq2seq'", "@Godwin45,\r\nCould you please submit a new issue from [this link](https://github.com/tensorflow/tensorflow/issues/new/choose) and fill in the template, so that we can track the issue there. Thanks!"]}, {"number": 37171, "title": "Update tf.image documentation", "body": "* Fix https://github.com/tensorflow/tensorflow/issues/28169\r\n* Update `tf.image` documentation", "comments": ["Hi @MarkDaoust,\r\nPlease also review PR https://github.com/tensorflow/tensorflow/pull/37174 as this will have a minor effect on this PR.\r\n\r\nThank you"]}, {"number": 37170, "title": "Why tensorflow creates gru/while in graph?", "body": "I am trying to compute the flop of a GRU model for one step. I understand all results but not the gru/while. Why TensorFlow need to create gru/while in the graph doubling the computations? I also asked this question in StackOverflow (https://stackoverflow.com/questions/60453735/what-tensorflow-keras-will-create-gru-while-in-graph) but have not got any answer yet. ", "comments": ["@bzhong2 We will try to answer this on stackovrflow itself. I am closing this issue for now as github is only meant for build/install, bug/performance, feature request or docs related issues. Thanks!"]}, {"number": 37169, "title": "tensorflow has no attribute \"assign_add\"", "body": "i am using tensorflow-GPU 2.0.0 version . I caught a error that tensorflow has no attribute \"assign_add\". could anyone please help me please", "comments": ["Try tf.compat.v1.assign_add", "@aimanjavid \r\n\r\nCan you please go through the [link](https://www.tensorflow.org/api_docs/python/tf/compat/v1/assign_add) and see if it helps you. Thanks!", "thank you so much\n\nOn Mon, Mar 2, 2020 at 3:11 PM ravikyram <notifications@github.com> wrote:\n\n> @aimanjavid <https://github.com/aimanjavid>\n>\n> Can you please go through the link\n> <https://www.tensorflow.org/api_docs/python/tf/compat/v1/assign_add> and\n> see if it helps you. Thanks!\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/37169?email_source=notifications&email_token=AK7CFYJDUZ5XXSAWAUATFYLRFOA5ZA5CNFSM4K5T2CYKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOENOWZJA#issuecomment-593325220>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AK7CFYJB7DMUSNBOB2XTRJ3RFOA5ZANCNFSM4K5T2CYA>\n> .\n>\n", "@aimanjavid \r\n\r\nPlease close this thread if it solves your question. Thanks!"]}, {"number": 37168, "title": "`encode_png` function should be exported from `tf.io` module", "body": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/api_docs/python/tf/image/encode_png\r\n\r\n## Description of the issue (what needs changing):\r\n\r\nCurrently, all Image decoding and encoding functions are a part of the `tf.io` module but `encode_png` function is still a part of the `tf.image` module.\r\n\r\n## Changes required\r\n\r\nChange `tf.image.encode_png`  to `tf.io.encode_png`\r\n\r\n\r\n### Submit a pull request?\r\nI will be happy to help.\r\n", "comments": []}, {"number": 37167, "title": "[TF 2.1] BUG: set_seed with categorical in a conditional branch in graph mode.", "body": "**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g.,\r\nLinux Ubuntu 16.04): Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if\r\nthe issue happens on mobile device: \r\n- TensorFlow installed from (source or\r\nbinary): - TensorFlow version (use command below):  From source and binary using pip.\r\n- Python version: - Bazel\r\nversion (if compiling from source): Python=3.6.9, Bazel=2.0.0\r\n- GCC/Compiler version (if compiling from\r\nsource): 8.3.0\r\n- CUDA/cuDNN version: - GPU model and memory:\r\n\r\n**Describe the current behavior**\r\nThe example containing the bug always returns the first step in `tf.function` with `tf.cond` if we define a seed with `tf.random.set_seed`.\r\nA= tf.Tensor([0 0 0 0 0 0 0 0 0 0 0 0], shape=(12,), dtype=int64)\r\n\r\n**Describe the expected behavior**\r\nA= tf.Tensor([0 1 1 0 0 1 1 1 1 0 1 1], shape=(12,), dtype=int64)\r\nA= tf.Tensor([0 0 0 0 0 0 1 1 0 1 1 0], shape=(12,), dtype=int64)\r\n...\r\n\r\n**Standalone code to reproduce the issue** \r\nBug sample:\r\n```\r\nimport tensorflow as tf\r\n\r\ntf.random.set_seed(0)\r\n\r\ndef f1():\r\n    return(tf.random.categorical(tf.math.log([[0.5, 0.5]]), 1))\r\n\r\n@tf.function\r\ndef body():\r\n    Y = []\r\n    for t in range(12):\r\n        Y.append(\r\n            tf.cond(tf.constant(True),\r\n                    f1,\r\n                    f1)\r\n        )\r\n    return(tf.squeeze(Y))\r\n\r\nA = body()\r\n\r\nprint(\"A=\", A)\r\n# A= tf.Tensor([0 0 0 0 0 0 0 0 0 0 0 0], shape=(12,), dtype=int64)\r\n```\r\n\r\n1. Working sample:\r\n```\r\nimport tensorflow as tf\r\n\r\ndef f1():\r\n    return(tf.random.categorical(tf.math.log([[0.5, 0.5]]), 1))\r\n\r\n@tf.function\r\ndef body():\r\n    Y = []\r\n    for t in range(12):\r\n        Y.append(\r\n            tf.cond(tf.constant(True),\r\n                    f1,\r\n                    f1)\r\n        )\r\n    return(tf.squeeze(Y))\r\n\r\nA = body()\r\n\r\nprint(\"A=\", A)\r\n# A= tf.Tensor([0 1 1 0 0 1 1 1 1 0 1 1], shape=(12,), dtype=int64)\r\n```\r\n\r\n2. Working sample:\r\n```\r\nimport tensorflow as tf\r\n\r\ntf.random.set_seed(0)\r\n\r\ndef f1():\r\n    return(tf.random.categorical(tf.math.log([[0.5, 0.5]]), 1))\r\n\r\n@tf.function\r\ndef body():\r\n    Y = []\r\n    for t in range(12):\r\n        ret_0 = f1()\r\n        ret_1 = f1()\r\n        \r\n        Y.append(\r\n            tf.cond(tf.constant(True),\r\n                    lambda: ret_0,\r\n                    lambda: ret_1)\r\n        )\r\n    return(tf.squeeze(Y))\r\n\r\nA = body()\r\n\r\nprint(\"A=\", A)\r\n# A= tf.Tensor([0 0 0 0 0 0 1 1 0 1 1 0], shape=(12,), dtype=int64)\r\n```\r\n\r\n", "comments": ["I could replicate the issue with Tf 2.1.\r\nPlease find the gist [here](https://colab.sandbox.google.com/gist/gadagashwini/13114a2582e4e947b9baf7bea25d9358/untitled.ipynb). Thanks!", "@SebastienKeroack Can you elaborate more in a detailed manner as I am having a hard time to understand what you are trying to convey. Thanks!", "The example containing the bug should work logically as example number 2. No?", "It's actually intended behavior. When set_seed has been called and f1 is traced, it picks an op seed (an attribute) for the random.categorical op. When f1 is called multiple times in `body` with tf.cond, f1 is inlined and the  random.categorical op is duplicated, all with the same op_seed attribute. So they'll give you the same random number.\r\n\r\nIn contrast, in Working Sample 2, although f1 is also called multiple times, it's not inlined and duplicated. Instead, it's just eagerly called many times during the tracing of `body`, leaving multiple random.categorical ops on the graph, and the eager context picks different op_seed attributes for them.\r\n\r\nWhen set_seed is not called, as in Working Sample 1, the random.categorical ops get value (0,0) for their (graph_seed, op_seed) attributes, which is a special value telling the kernel to non-deterministically pick a seed at runtime.\r\n\r\nThis again shows how broken the old RNGs (and any stateful kernels) are.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37167\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37167\">No</a>\n"]}, {"number": 37166, "title": "TFLM: implement new memory planning API.", "body": "This is a test. \r\n\r\nhttps://unhashable.com/stacked-pull-requests-keeping-github-diffs-small/", "comments": ["@wangtz  Can you please resolve conflicts? Thanks!", "@wangtz  Gentle ping to resolve conflicts. Thanks!", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "It has been 43 days that this pull-request has stalled. Please create a new pull-request with the requested changes."]}, {"number": 37165, "title": "Pr1 branch", "body": "This is to test stacked Github PR\r\nPlease do not review nor merge.\r\n\r\nGuide:\r\nhttps://unhashable.com/stacked-pull-requests-keeping-github-diffs-small/", "comments": []}, {"number": 37164, "title": "TensorFlow 2.1.0 Not utilising GPU even though it can see it.  ", "body": "TensorFlow does not utilise the GPU despite being able to see it. When I run a script, task manager does not show any activity on the GPU...\r\n\r\n**Recently I have tried:**\r\n\r\nUpdated NVIDIA driver.\r\n\r\nUninstalled Tensorflow, python 3.7, cuDNN, CUDA, Visual Studio.\r\n\r\nInstalled Visual Studio.\r\n\r\nInstalled CUDA 10.1 [cuda_10.1.243_426.00_win10].\r\n\r\nInstalled cuDNN (and moved the .dll, .h, .lib files) [cudnn-10.1-windows10-x64-v7.6.5.32.zip]\r\n\r\nInstalled python [python-3.7.4-amd64.exe]\r\n\r\nInstalled Tensorflow (2.1.0) into a new environment and made a Kernel\r\n\r\n**When I run ...**\r\nimport tensorflow as tf\r\ntf.test.is_gpu_available(\r\n    cuda_only=False, min_cuda_compute_capability=None\r\n)\r\n**\u2026 it returns** \r\n\"true\"\r\n\r\n**when I run**\r\n\"from tensorflow.python.client import device_lib\r\nprint(device_lib.list_local_devices())\"\r\n\r\n**it returns**\r\n [name: \"/device:CPU:0\"\r\ndevice_type: \"CPU\"\r\nmemory_limit: 268435456\r\nlocality {\r\n}\r\nincarnation: 3456819361691180826\r\n, name: \"/device:GPU:0\"\r\ndevice_type: \"GPU\"\r\nmemory_limit: 9105744200\r\nlocality {\r\n  bus_id: 1\r\n  links {\r\n  }\r\n}\r\nincarnation: 18022178943584354069\r\nphysical_device_desc: \"device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\"\r\n\r\nHowever, when I run my script the task manager shows no activation on the GPU.  ", "comments": ["@georgeparry12 \r\nCan you please follow the gpu usage guide [here](https://www.tensorflow.org/guide/gpu) and let us know whether it resolved your issue. Thanks!", "@ravikyram that link was useful, however, it's shown me I have a different problem. \r\n\r\n**When I run**\r\nfrom __future__ import absolute_import, division, print_function, unicode_literals\r\nimport tensorflow as tf\r\nprint(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU'))) \r\n\r\n**I get**\r\nNum GPUs Available:  1\r\n\r\nSo it's only seeing the NVIDA GPU, yet when I run scripts the Task Manager shows no activity on the GPU at all?", "@georgeparry12 \r\n\r\nCan you please go through the [link](https://www.tensorflow.org/guide/gpu#logging_device_placement) and see if it helps you.Please, add `tf.debugging.set_log_device_placement(True)` and execute piece of code as given in the link and verify.Thanks!", "@georgeparry12 \r\n\r\nAny update on this issue please. Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 37163, "title": "Fix test that should only be running in v1", "body": "After https://github.com/tensorflow/tensorflow/commit/84f2ec1d60b5bb14a59ccef8f8fa7eb5a1096e8f#diff-42d3946a49d3adc16b4a37e844f986e0R469-R473 the test `testBatchNormGradInferenceShape1 ` is incorrectly enabled in v2, causing the following error:\r\n\r\n```\r\n[  FAILED  ] BatchNormalizationTest.testBatchNormGradInferenceShape1\r\n======================================================================\r\nERROR: testBatchNormGradInferenceShape1 (__main__.BatchNormalizationTest)\r\ntestBatchNormGradInferenceShape1 (__main__.BatchNormalizationTest)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/run/bazel-buildfarm/default/operations/9d248bd8-a122-4dee-8f35-b5c55d793f8f/bazel-out/k8-opt/bin/tensorflow/python/nn_fused_batchnorm_test_gpu.runfiles/org_tensorflow/tensorflow/python/ops/nn_fused_batchnorm_test.py\", line 471, in testBatchNormGradInferenceShape1\r\n    self._runtests(x_shape, is_training=False, gradient_test=True)\r\n  File \"/run/bazel-buildfarm/default/operations/9d248bd8-a122-4dee-8f35-b5c55d793f8f/bazel-out/k8-opt/bin/tensorflow/python/nn_fused_batchnorm_test_gpu.runfiles/org_tensorflow/tensorflow/python/ops/nn_fused_batchnorm_test.py\", line 407, in _runtests\r\n    exponential_avg_factor=exponential_avg_factor)\r\n  File \"/run/bazel-buildfarm/default/operations/9d248bd8-a122-4dee-8f35-b5c55d793f8f/bazel-out/k8-opt/bin/tensorflow/python/nn_fused_batchnorm_test_gpu.runfiles/org_tensorflow/tensorflow/python/ops/nn_fused_batchnorm_test.py\", line 263, in _test_gradient\r\n    x_shape)\r\n  File \"/run/bazel-buildfarm/default/operations/9d248bd8-a122-4dee-8f35-b5c55d793f8f/bazel-out/k8-opt/bin/tensorflow/python/nn_fused_batchnorm_test_gpu.runfiles/org_tensorflow/tensorflow/python/ops/nn_fused_batchnorm_test.py\", line 203, in _compute_gradient_error_float16\r\n    x, x_shape, y, y_shape, delta=1e-3, x_init_value=x_init_val)\r\n  File \"/run/bazel-buildfarm/default/operations/9d248bd8-a122-4dee-8f35-b5c55d793f8f/bazel-out/k8-opt/bin/tensorflow/python/nn_fused_batchnorm_test_gpu.runfiles/org_tensorflow/tensorflow/python/util/deprecation.py\", line 324, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/run/bazel-buildfarm/default/operations/9d248bd8-a122-4dee-8f35-b5c55d793f8f/bazel-out/k8-opt/bin/tensorflow/python/nn_fused_batchnorm_test_gpu.runfiles/org_tensorflow/tensorflow/python/ops/gradient_checker.py\", line 332, in compute_gradient\r\n    dx, dy = _compute_dx_and_dy(x, y, y_shape)\r\n  File \"/run/bazel-buildfarm/default/operations/9d248bd8-a122-4dee-8f35-b5c55d793f8f/bazel-out/k8-opt/bin/tensorflow/python/nn_fused_batchnorm_test_gpu.runfiles/org_tensorflow/tensorflow/python/ops/gradient_checker.py\", line 202, in _compute_dx_and_dy\r\n    with x.graph.as_default():\r\n  File \"/run/bazel-buildfarm/default/operations/9d248bd8-a122-4dee-8f35-b5c55d793f8f/bazel-out/k8-opt/bin/tensorflow/python/nn_fused_batchnorm_test_gpu.runfiles/org_tensorflow/tensorflow/python/framework/ops.py\", line 1118, in graph\r\n    \"Tensor.graph is meaningless when eager execution is enabled.\")\r\nAttributeError: Tensor.graph is meaningless when eager execution is enabled.\r\n```", "comments": ["Thanks for the fix! Note sure why this didn't fail the presubmit tests."]}, {"number": 37162, "title": "using tensorflow-hub model elmo ensorflow.python.framework.errors_impl.ResourceExhaustedError", "body": "Python 3.6.10 \r\ntensorflow 1.12.0 gpu_py36he68c306_0\r\ntensorflow-base 1.12.0 gpu_py36h8e0ae2d_0\r\ntensorflow-gpu 1.12.0 h0d30ee6_0\r\ntensorflow-hub 0.5.0 pypi_0 pypi cudatoolkit 9.0 h13b8566_0\r\ncudnn 7.6.5  cuda9.0_0\r\n\r\nNVIDIA-SMI 418.87.01 Driver Version: 418.87.01 CUDA Version: 10.1\r\n0 Tesla V100-SXM2... Off | 00000000:18:00.0 Off | 0 | | N/A 37C P0 43W / 300W | 11MiB / 32480MiB | 0% Default | +-------------------------------+----------------------+----------------------+ | 1 Tesla V100-SXM2... Off | 00000000:3B:00.0 Off | 0 | | N/A 34C P0 42W / 300W | 11MiB / 32480MiB | 0% Default | +-------------------------------+----------------------+----------------------+ | 2 Tesla V100-SXM2... Off | 00000000:86:00.0 Off | 0 | | N/A 34C P0 43W / 300W | 11MiB / 32480MiB | 0% Default | +-------------------------------+----------------------+----------------------+ | 3 Tesla V100-SXM2... Off | 00000000:AF:00.0 Off | 0 | | N/A 38C P0 43W / 300W | 11MiB / 32480MiB | 0% Default\r\n\r\nerror: Using TensorFlow backend. /share/nishome/19930072_0/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'. _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)]) /share/nishome/19930072_0/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'. _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)]) /share/nishome/19930072_0/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'. _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)]) /share/nishome/19930072_0/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'. _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)]) /share/nishome/19930072_0/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'. _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)]) /share/nishome/19930072_0/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'. np_resource = np.dtype([(\"resource\", np.ubyte, 1)]) INFO:bert_bilstm_softmax.py:running bert_bilstm_softmax.py INFO:root:loading data... INFO:absl:Using /tmp/tfhub_modules to cache modules. INFO:tensorflow:Saver not created because there are no variables in the graph to restore INFO:tensorflow:Saver not created because there are no variables in the graph to restore INFO:tensorflow:Saver not created because there are no variables in the graph to restore INFO:tensorflow:Saver not created because there are no variables in the graph to restore 38 7 (2742, 38, 1024) (392, 38, 1024) (2742, 38, 2) (392, 38, 2)\r\n\r\nLayer (type) Output Shape Param #\r\ninput_1 (InputLayer) (None, 38, 1024) 0\r\n\r\nbatch_normalization_1 (Batch (None, 38, 1024) 4096\r\n\r\nmasking_1 (Masking) (None, 38, 1024) 0\r\n\r\nbidirectional_1 (Bidirection (None, 38, 256) 1180672\r\n\r\nbidirectional_2 (Bidirection (None, 38, 256) 394240\r\n\r\ndropout_1 (Dropout) (None, 38, 256) 0\r\n\r\ndense_1 (Dense) (None, 38, 2) 514\r\nTotal params: 1,579,522 Trainable params: 1,577,474 Non-trainable params: 2,048\r\n\r\nTrain on 2742 samples, validate on 392 samples Epoch 1/30 2020-02-28 19:42:36.337714: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA 2020-02-28 19:42:36.787351: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53 pciBusID: 0000:18:00.0 totalMemory: 31.72GiB freeMemory: 31.41GiB 2020-02-28 19:42:36.957634: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 1 with properties: name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53 pciBusID: 0000:3b:00.0 totalMemory: 31.72GiB freeMemory: 31.41GiB 2020-02-28 19:42:37.143501: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 2 with properties: name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53 pciBusID: 0000:86:00.0 totalMemory: 31.72GiB freeMemory: 31.41GiB 2020-02-28 19:42:37.336031: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 3 with properties: name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53 pciBusID: 0000:af:00.0 totalMemory: 31.72GiB freeMemory: 31.41GiB 2020-02-28 19:42:37.336143: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0, 1, 2, 3 2020-02-28 19:42:41.617032: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix: 2020-02-28 19:42:41.617079: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988] 0 1 2 3 2020-02-28 19:42:41.617090: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0: N Y Y Y 2020-02-28 19:42:41.617122: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 1: Y N Y Y 2020-02-28 19:42:41.617132: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 2: Y Y N Y 2020-02-28 19:42:41.617158: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 3: Y Y Y N 2020-02-28 19:42:41.617526: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30472 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:18:00.0, compute capability: 7.0) 2020-02-28 19:42:41.634656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 30472 MB memory) -> physical GPU (device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:3b:00.0, compute capability: 7.0) 2020-02-28 19:42:41.635333: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 30472 MB memory) -> physical GPU (device: 2, name: Tesla V100-SXM2-32GB, pci bus id: 0000:86:00.0, compute capability: 7.0) 2020-02-28 19:42:41.635518: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 30472 MB memory) -> physical GPU (device: 3, name: Tesla V100-SXM2-32GB, pci bus id: 0000:af:00.0, compute capability: 7.0) 2020-02-28 19:43:06.568339: W tensorflow/core/common_runtime/bfc_allocator.cc:267] Allocator (GPU_0_bfc) ran out of memory trying to allocate 8.94GiB. Current allocation summary follows. 2020-02-28 19:43:06.568442: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (256): Total Chunks: 147, Chunks in use: 145. 36.8KiB allocated for chunks. 36.2KiB in use in bin. 1.1KiB client-requested in use in bin.\r\n\r\n2020-02-28 19:43:06.568541: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (65536): Total Chunks: 36, Chunks in use: 36. 2.27MiB allocated for chunks. 2.27MiB in use in bin. 2.25MiB client-requested in use in bin. 2020-02-28 19:43:06.568552: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (131072): Total Chunks: 18, Chunks in use: 18. 2.42MiB allocated for chunks. 2.42MiB in use in bin. 2.38MiB client-requested in use in bin. 2020-02-28 19:43:06.568564: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (262144): Total Chunks: 19, Chunks in use: 18. 5.06MiB allocated for chunks. 4.69MiB in use in bin. 4.69MiB client-requested in use in bin. 2020-02-28 19:43:06.568577: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (524288): Total Chunks: 31, Chunks in use: 28. 16.48MiB allocated for chunks. 14.59MiB in use in bin. 14.59MiB client-requested in use in bin. 2020-02-28 19:43:06.568588: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (1048576): Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin. 2020-02-28 19:43:06.568600: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (2097152): Total Chunks: 7, Chunks in use: 7. 14.00MiB allocated for chunks. 14.00MiB in use in bin. 14.00MiB client-requested in use in bin. 2020-02-28 19:43:06.568611: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (4194304): Total Chunks: 2, Chunks in use: 1. 8.00MiB allocated for chunks. 4.00MiB in use in bin. 4.00MiB client-requested in use in bin. 2020-02-28 19:43:06.568624: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (8388608): Total Chunks: 4, Chunks in use: 4. 32.00MiB allocated for chunks. 32.00MiB in use in bin. 32.00MiB client-requested in use in bin. 2020-02-28 19:43:06.568636: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (16777216): Total Chunks: 5, Chunks in use: 4. 80.00MiB allocated for chunks. 64.00MiB in use in bin. 64.00MiB client-requested in use in bin. 2020-02-28 19:43:06.568648: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (33554432): Total Chunks: 1, Chunks in use: 0. 32.02MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin. 2020-02-28 19:43:06.568661: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (67108864): Total Chunks: 5, Chunks in use: 4. 340.04MiB allocated for chunks. 256.00MiB in use in bin. 256.00MiB client-requested in use in bin. 2020-02-28 19:43:06.568670: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (134217728): Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin. 2020-02-28 19:43:06.568679: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (268435456): Total Chunks: 13, Chunks in use: 7. 29.24GiB allocated for chunks. 18.58GiB in use in bin. 18.58GiB client-requested in use in bin. 2020-02-28 19:43:06.568687: I tensorflow/core/common_runtime/bfc_allocator.cc:613] Bin for 8.94GiB was 256.00MiB, Chunk State: 2020-02-28 19:43:06.568701: I tensorflow/core/common_runtime/bfc_allocator.cc:619] Size: 317.98MiB | Requested Size: 317.98MiB | in_use: 0, prev: Size: 256B | Requested Size: 4B | in_use: 1, next: Size: 317.98MiB | Requested Size: 317.98MiB | in_use: 1 2020-02-28 19:43:06.568712: I tensorflow/core/common_runtime/bfc_allocator.cc:619] Size: 635.96MiB | Requested Size: 623.24MiB | in_use: 0, prev: Size: 317.98MiB | Requested Size: 317.98MiB | in_use: 1, next: Size: 635.96MiB | Requested Size: 635.96MiB | in_use: 1 2020-02-28 19:43:06.568721: I tensorflow/core/common_runtime/bfc_allocator.cc:619] Size: 1.19GiB | Requested Size: 1.17GiB | in_use: 0, prev: Size: 623.24MiB | Requested Size: 623.24MiB | in_use: 1, next: Size: 1.19GiB | Requested Size: 1.19GiB | in_use: 1 2020-02-28 19:43:06.568729: I tensorflow/core/common_runtime/bfc_allocator.cc:619] Size: 1.62GiB | Requested Size: 80.0KiB | in_use: 0, prev: Size: 8.94GiB | Requested Size: 8.94GiB | in_use: 1 2020-02-28 19:43:06.568739: I tensorflow/core/common_runtime/bfc_allocator.cc:619] Size: 2.33GiB | Requested Size: 1.43GiB | in_use: 0, prev: Size: 1.19GiB | Requested Size: 1.19GiB | in_use: 1, next: Size: 2.33GiB | Requested Size: 2.33GiB | in_use: 1 2020-02-28 19:43:06.568776: I tensorflow/core/common_runtime/bfc_allocator.cc:619] Size: 4.57GiB | Requested Size: 4.57GiB | in_use: 0, prev: Size: 2.33GiB | Requested Size: 2.33GiB | in_use: 1, next: Size: 4.57GiB | Requested Size: 4.57GiB | in_use: 1 2020-02-28 19:43:06.568791: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0x7f566e000000 of size 1280 0x7f568efea100 of size 65536 2020-02-28 19:43:06.570830: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0x7f568effa100 of size 65536 2020-02-28 19:43:06.570835: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0x7f568f00a100 of size 65536 2020x7f568f3ea100 of size 524288 2020-02-28 19:43:06.571038: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0x7f568f46a100 of size 65536 202 2507372544 totalling 2.33GiB 2020-02-28 19:43:06.571302: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 1 Chunks of size 4908048384 totalling 4.57GiB 2020-02-28 19:43:06.571308: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 1 Chunks of size 9602703360 totalling 8.94GiB 2020-02-28 19:43:06.571314: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Sum Total of in-use chunks: 18.97GiB 2020-02-28 19:43:06.571322: I tensorflow/core/common_runtime/bfc_allocator.cc:647] Stats: Limit: 31952542106 InUse: 20365600256 MaxInUse: 20365600256 NumAllocs: 582 MaxAllocSize: 9602703360\r\n\r\n2020-02-28 19:43:06.571344: W tensorflow/core/common_runtime/bfc_allocator.cc:271] ****_******___*****______*********_______________**********************************************_____ 2020-02-28 19:43:06.571376: W tensorflow/core/framework/op_kernel.cc:1273] OP_REQUIRES failed at conv_ops.cc:746 : Resource exhausted: OOM when allocating tensor with shape[2742,512,38,45] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc 2020-02-28 19:43:16.573348: W tensorflow/core/common_runtime/bfc_allocator.cc:267] Allocator (GPU_0_bfc) ran out of memory trying to allocate 17.49GiB. Current allocation summary follows. 2020-02-28 19:43:16.573412: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (256): Total Chunks: 147, Chunks in use: 145. 36.8KiB allocated for chunks. 36.2KiB in use in bin. 1.1KiB client-requested in use in bin. 2020-02-28 19:43:16.573425: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (512): Total Chunks: 19, Chunks in use: 17. 9.5KiB allocated for chunks. 8.5KiB in use in bin. 8.5KiB client-requested in use in bin. 2020-02-28 19:43:16.573434: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (1024): Total Chunks: 2, Chunks in use: 2. 2.2KiB allocated for chunks. 2.2KiB in use in bin. 2.0KiB client-requested in use in bin. 2020-02-28 19:43:16.573443: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (2048): Total Chunks: 24, Chunks in use: 22. 48.2KiB allocated for chunks. 44.0KiB in use in bin. 44.0KiB client-requested in use in bin. 2020-02-28 19:43:16.573453: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (4096): Total Chunks: 15, Chunks in use: 15. 60.0KiB allocated for chunks. 60.0KiB in use in bin. 60.0KiB client-requested in use in bin. 2020-02-28 19:43:16.573468: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (8192): Total Chunks: 11, Chunks in use: 6. 111.5KiB allocated for chunks. 53.5KiB in use in bin. 53.4KiB client-requested in use in bin. 2020-02-28 19:43:16.573478: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (16384): Total Chunks: 1, Chunks in use: 0. 16.2KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin. 2020-02-28 19:43:16.573486: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (32768): Total Chunks: 3, Chunks in use: 0. 96.2KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin. 2020-02-28 19:43:16.573494: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (65536): Total Chunks: 36, Chunks in use: 36. 2.27MiB allocated for chunks. 2.27MiB in use in bin. 2.25MiB client-requested in use in bin. 2020-02-28 19:43:16.573503: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (131072): Total Chunks: 17, Chunks in use: 16. 2.24MiB allocated for chunks. 2.00MiB in use in bin. 2.00MiB client-requested in use in bin. 2020-02-28 19:43:16.573512: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (262144): Total Chunks: 18, Chunks in use: 18. 4.69MiB allocated for chunks. 4.69MiB in use in bin. 4.69MiB client-requested in use in bin. 2020-02-28 19:43:16.573520: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (524288): Total Chunks: 30, Chunks in use: 28. 15.60MiB allocated for chunks. 14.59MiB in use in bin. 14.59MiB client-requested in use in bin. 2020-02-28 19:43:16.573528: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (1048576): Total Chunks: 1, Chunks in use: 0. 1.44MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin. 2020-02-28 19:43:16.573537: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (2097152): Total Chunks: 7, Chunks in use: 7. 14.00MiB allocated for chunks. 14.00MiB in use in bin. 14.00MiB client-requested in use in bin. 2020-02-28 19:43:16.573545: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (4194304): Total Chunks: 2, Chunks in use: 1. 8.00MiB allocated for chunks. 4.00MiB in use in bin. 4.00MiB client-requested in use in bin. 2020-02-28 19:43:16.573553: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (8388608): Total Chunks: 4, Chunks in use: 4. 32.00MiB allocated for chunks. 32.00MiB in use in bin. 32.00MiB client-requested in use in bin. 2020-02-28 19:43:16.573562: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (16777216): Total Chunks: 5, Chunks in use: 4. 80.00MiB allocated for chunks. 64.00MiB in use in bin. 64.00MiB client-requested in use in bin. 2020-02-28 19:43:16.573570: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (33554432): Total Chunks: 1, Chunks in use: 0. 32.02MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin. 2020-02-28 19:43:16.573579: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (67108864): Total Chunks: 5, Chunks in use: 4. 340.04MiB allocated for chunks. 256.00MiB in use in bin. 256.00MiB client-requested in use in bin. 2020-02-28 19:43:16.573587: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (134217728): Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin. 2020-02-28 19:43:16.573595: I tensorflow/core/common_runtime/bfc_allocator.cc:597] Bin (268435456): Total Chunks: 12, Chunks in use: 6. 29.24GiB allocated for chunks. 9.64GiB in use in bin. 9.64GiB client-requested in use in bin. 2020-02-28 19:43:16.573604: I tensorflow/core/common_runtime/bfc_allocator.cc:613] Bin for 17.49GiB was 256.00MiB, Chunk State: 2020-02-28 19:43:16.573618: I tensorflow/core/common_runtime/bfc_allocator.cc:619] Size: 317.98MiB | Requested Size: 317.98MiB | in_use: 0, prev: Size: 256B | Requested Size: 4B | in_use: 1, next: Size: 317.98MiB | Requested Size: 317.98MiB | in_use: 1 2020-02-28 19:43:16.573630: I tensorflow/core/common_runtime/bfc_allocator.cc:619] Size: 635.96MiB | Requested Size: 623.24MiB | in_use: 0, prev: Size: 317.98MiB | Requested Size: 317.98MiB | in_use: 1, next: Size: 635.96MiB | Requested Size: 635.96MiB | in_use: 1 2020-02-28 19:43:16.573641: I tensorflow/core/common_runtime/bfc_allocator.cc:619] Size: 1.19GiB | Requested Size: 1.17GiB | in_use: 0, prev: Size: 623.24MiB | Requested Size: 623.24MiB | in_use: 1, next: Size: 1.19GiB | Requested Size: 1.19GiB | in_use: 1 2020-02-28 19:43:16.573650: I tensorflow/core/common_runtime/bfc_allocator.cc:619] Size: 2.33GiB | Requested Size: 1.43GiB | in_use: 0, prev: Size: 1.19GiB | Requested Size: 1.19GiB | in_use: 1, next: Size: 2.33GiB | Requested Size: 2.33GiB | in_use: 1 2020-02-28 19:43:16.573695: I tensorflow/core/common_runtime/bfc_allocator.cc:619] Size: 4.57GiB | Requested Size: 4.57GiB | in_use: 0, prev: Size: 2.33GiB | Requested Size: 2.33GiB | in_use: 1, next: Size: 4.57GiB | Requested Size: 4.57GiB | in_use: 1 2020-02-28 19:43:16.573704: I tensorflow/core/common_runtime/bfc_allocator.cc:619] Size: 10.57GiB | Requested Size: 8.94GiB | in_use: 0, prev: Size: 4.57GiB | Requested Size: 4.57GiB | in_use: 1 2020-02-28 19:43:16.573714: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0x7f566e000000 of size 1280 2020-02-28 19:43:16.573720: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0x7f566e000500 of size 256\r\n\r\n2020-02-28 19:43:16.576222: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 1 Chunks of size 1024 totalling 1.0KiB 666854400 totalling 635.96MiB 2020-02-28 19:43:16.576352: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 1 Chunks of size 1280360448 totalling 1.19GiB 2020-02-28 19:43:16.576358: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 1 Chunks of size 2507372544 totalling 2.33GiB 2020-02-28 19:43:16.576364: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 1 Chunks of size 4908048384 totalling 4.57GiB 2020-02-28 19:43:16.576371: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Sum Total of in-use chunks: 10.02GiB 2020-02-28 19:43:16.576380: I tensorflow/core/common_runtime/bfc_allocator.cc:647] Stats: Limit: 31952542106 InUse: 10762452480 MaxInUse: 20365600256 NumAllocs: 582 MaxAllocSize: 9602703360\r\n\r\n2020-02-28 19:43:16.576403: W tensorflow/core/common_runtime/bfc_allocator.cc:271] ***************______*********_______________****************___________________________________ 2020-02-28 19:43:16.576430: W tensorflow/core/framework/op_kernel.cc:1273] OP_REQUIRES failed at conv_ops.cc:446 : Resource exhausted: OOM when allocating tensor with shape[2742,1024,38,44] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc Traceback (most recent call last): File \"bert_bilstm_softmax.py\", line 321, in model.fit(train_vectors, val_train_labels, epochs=nb_epoch,steps_per_epoch=1,validation_data=[test_vectors, val_test_labels],validation_steps=1) File \"/share/nishome/19930072_0/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/training.py\", line 1039, in fit validation_steps=validation_steps) File \"/share/nishome/19930072_0/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/training_arrays.py\", line 154, in fit_loop outs = f(ins) File \"/share/nishome/19930072_0/anaconda3/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 2715, in __call return self._call(inputs) File \"/share/nishome/19930072_0/anaconda3/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 2675, in _call fetched = self._callable_fn(*array_vals) File \"/share/nishome/19930072_0/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1439, in call run_metadata_ptr) File \"/share/nishome/19930072_0/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\", line 528, in exit c_api.TF_GetCode(self.status.status)) tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[2742,512,38,45] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [[{{node module_apply_default/bilm/CNN/Conv2D_5}} = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](module_apply_default/bilm/CNN/Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer, module_apply_default/bilm/CNN/Conv2D_5/ReadVariableOp/_299)]] Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n [[{{node bidirectional_2/transpose_4/_313}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1962_bidirectional_2/transpose_4\", tensor_type=DT_BOOL, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.", "comments": ["@DavidInWuhanChina,\r\nLooks like the issue is related to TensorFlow-Hub. Could you please open a new issue in the Tensorflow-Hub repository from [this](https://github.com/tensorflow/hub/issues/new) link. Thanks!", "Any updates regarding this issue? Thanks!", "I have solve this problem\uff0cthanks\uff01"]}, {"number": 37161, "title": "Latest GPUDelegate from 'org.tensorflow:tensorflow-lite-gpu:0.0.0-nightly' crashes", "body": "**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow):  No\r\n- OS Platform and Distribution (e.g.,\r\nLinux Ubuntu 16.04): \r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if\r\nthe issue happens on mobile device: All devices\r\n- TensorFlow installed from (source or\r\nbinary): binary\r\n- TensorFlow version (use command below):  'org.tensorflow:tensorflow-lite-gpu:0.0.0-nightly'\r\n- Python version: - Bazel\r\nversion (if compiling from source):\r\n- GCC/Compiler version (if compiling from\r\nsource): \r\n- CUDA/cuDNN version: - GPU model and memory:\r\n\r\n**Describe the current behavior**\r\nAndroid app crashes when using GPUDelegate from the latest nightly build.\r\n\r\n**Describe the expected behavior**\r\nIt shouldn't crash.\r\n\r\n**Standalone code to reproduce the issue** \r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n```\r\nProcess: com.test.app, PID: 16875\r\n    java.lang.UnsatisfiedLinkError: dlopen failed: cannot locate symbol \"_ZTVN6tflite3gpu2cl12SpaceToDepthE\" referenced by \"/data/app/com.test.app-ujX5oxWg44XmBTPZMarXvQ==/base.apk!/lib/arm64-v8a/libtensorflowlite_gpu_jni.so\"...\r\n        at java.lang.Runtime.loadLibrary0(Runtime.java:1071)\r\n        at java.lang.Runtime.loadLibrary0(Runtime.java:1007)\r\n        at java.lang.System.loadLibrary(System.java:1667)\r\n```\r\n", "comments": ["This should be addressed by https://github.com/tensorflow/tensorflow/pull/37033.", "@bilalsoomro, Can we close this issue, Since the associated PR has been merged. Thanks!", "@gadagashwini Yep, thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37161\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37161\">No</a>\n"]}, {"number": 37160, "title": "Thread leakage in TF2.1", "body": "**System information** \r\nRed Hat Enterprise Linux Server release 7.7 (Maipo)\r\n\r\n- TensorFlow in docker container (nvcr.io/nvidia/tensorflow:20.01-tf2-py3 and tensorflow/tensorflow:2.1.0-gpu-py3-jupyter): - TensorFlow version: 2.1.0\r\n\r\n- Python version: 3.6.9\r\n\r\n- CUDA/cuDNN version: - GPU model and memory: CUDA 10.2, libcudnn.so.7, DGX-1 server with 8xTesla V100-SXM2 (32GB)\r\n\r\n**Describe the current behavior**\r\n\r\nWhen executing the following jupyter block in TF2.1, we experience thread leakage that results in a crash after around 720 epochs. It seems that with every epoch, 5-6 new threads are created that are never cleaned up.\r\n\r\n```\r\nThistory = []\r\n\r\nhistory = model.fit(trnx, trny, \r\n          epochs=1000,                   # doesn't seem to make any difference\r\n          batch_size = 1024,            # affects GPU utilization\r\n          validation_split=0.06,        # , (note comma!) # use 6% for validation\r\n          class_weight={0:1, 1:50.0}, # Pay a lot more attention to Class \"1\"\r\n         )\r\n\r\nThistory.append(history)\r\n```\r\nWhen examining the core dump, we see that at the time of the crash approx. 4090 threads have been created and the backtrace of the crashing thread looks like this:\r\n\r\n```\r\n(gdb) bt\r\n#0  __GI_raise (sig=sig@entry=6) at ../sysdeps/unix/sysv/linux/raise.c:51\r\n#1  0x00007fd6d9854801 in __GI_abort () at abort.c:79\r\n#2  0x00007fd6d3d32c02 in __gnu_cxx::__verbose_terminate_handler() () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6\r\n#3  0x00007fd6d3d30ab6 in ?? () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6\r\n#4  0x00007fd6d3d30af1 in std::terminate() () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6\r\n#5  0x00007fd6a19ab3de in std::execute_native_thread_routine (__p=0x8f947540) at /dt7-src/libstdc++-v3/src/nonshared11/../c++11/thread.cc:91\r\n#6  0x00007fd6d95fc6db in start_thread (arg=0x7fc6b3fff700) at pthread_create.c:463\r\n#7  0x00007fd6d993588f in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:95\r\n```\r\nHere is the full log of the failing run:\r\n\r\n```\r\nFeb 27 16:08:03 bash[4775]: ================\r\nFeb 27 16:08:03 bash[4775]: == TensorFlow ==\r\nFeb 27 16:08:03 bash[4775]: ================\r\nFeb 27 16:08:03 bash[4775]: NVIDIA Release 20.02-tf2 (build 9892252)\r\nFeb 27 16:08:03 bash[4775]: TensorFlow Version 2.1.0\r\nFeb 27 16:08:03 bash[4775]: Container image Copyright (c) 2019, NVIDIA CORPORATION.  All rights reserved.\r\nFeb 27 16:08:03 bash[4775]: Copyright 2017-2019 The TensorFlow Authors.  All rights reserved.\r\nFeb 27 16:08:03 bash[4775]: Various files include modifications (c) NVIDIA CORPORATION.  All rights reserved.\r\nFeb 27 16:08:03 bash[4775]: NVIDIA modifications are covered by the license terms that apply to the underlying project or file\r\n.\r\nFeb 27 16:08:03 bash[4775]: NOTE: Legacy NVIDIA Driver detected.  Compatibility mode ENABLED.\r\nFeb 27 16:08:03 bash[4775]: NOTE: Detected MOFED driver 5.0-0; version automatically updated.\r\nFeb 27 16:08:03 bash[4775]: NOTE: MOFED driver was detected, but nv_peer_mem driver was not detected.\r\nFeb 27 16:08:03 bash[4775]: Multi-node communication performance may be reduced.\r\nFeb 27 16:08:05 bash[4775]: 2020-02-27 16:08:05.294586: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Succes\r\nsfully opened dynamic library libcudart.so.10.2\r\nFeb 27 16:08:06 bash[4775]: 2020-02-27 16:08:06.049185: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Succes\r\nsfully opened dynamic library libnvinfer.so.7\r\nFeb 27 16:08:06 bash[4775]: 2020-02-27 16:08:06.050172: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Succes\r\nsfully opened dynamic library libnvinfer_plugin.so.7\r\nFeb 27 16:08:06 bash[4775]: [I 16:08:06.830 NotebookApp] jupyter_tensorboard extension loaded.\r\nFeb 27 16:08:06 bash[4775]: [I 16:08:06.862 NotebookApp] JupyterLab extension loaded from /usr/local/lib/python3.6/dist-packag\r\nes/jupyterlab\r\nFeb 27 16:08:06 bash[4775]: [I 16:08:06.862 NotebookApp] JupyterLab application directory is /usr/local/share/jupyter/lab\r\nFeb 27 16:08:06 bash[4775]: [I 16:08:06.864 NotebookApp] [Jupytext Server Extension] NotebookApp.contents_manager_class is (a\r\nsubclass of) jupytext.TextFileContentsManager already - OK\r\nFeb 27 16:08:06 bash[4775]: [I 16:08:06.865 NotebookApp] Serving notebooks from local directory: /home/xxxxxx\r\nFeb 27 16:08:06 bash[4775]: [I 16:08:06.865 NotebookApp] The Jupyter Notebook is running at:\r\nFeb 27 16:08:06 bash[4775]: [I 16:08:06.865 NotebookApp] http://hostname:8888/\r\nFeb 27 16:08:06 bash[4775]: [I 16:08:06.865 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to\r\n skip confirmation).\r\nFeb 27 16:08:30 bash[4775]: [W 16:08:30.916 NotebookApp] 404 GET /api/kernels/2a8b1a39-d9f0-48f5-8b4d-7bc1188a06c4/channels?se\r\nssion_id=7c85bda7cc01423c89e3b2d4652db535 (172.27.68.155): Kernel does not exist: 2a8b1a39-d9f0-48f5-8b4d-7bc1188a06c4\r\nFeb 27 16:08:30 bash[4775]: [W 16:08:30.944 NotebookApp] 404 GET /api/kernels/2a8b1a39-d9f0-48f5-8b4d-7bc1188a06c4/channels?se\r\nssion_id=7c85bda7cc01423c89e3b2d4652db535 (172.27.68.155) 38.39ms referer=None\r\nFeb 27 16:08:50 bash[4775]: [W 16:08:50.358 NotebookApp] 404 GET /nbconvert/html/Notebooks/custom.css (172.27.68.155): No such\r\n file or directory: Notebooks/custom.css\r\nFeb 27 16:08:50 bash[4775]: [W 16:08:50.359 NotebookApp] 404 GET /nbconvert/html/Notebooks/custom.css (172.27.68.155) 13.11ms\r\nreferer=None\r\nFeb 27 16:08:51 bash[4775]: [I 16:08:51.706 NotebookApp] Kernel started: 5ff3ace7-0cf6-4cd1-8610-1b721b134801\r\nFeb 27 16:08:51 bash[4775]: [W 16:08:51.713 NotebookApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=202002271608\r\n04 (172.27.68.155) 3.03ms referer=http://dls007.idc.ctbto.org:8888/notebooks/Notebooks/20200225A.ipynb\r\nFeb 27 16:08:52 bash[4775]: [IPKernelApp] WARNING | Could not set permissions on /home/xxxxxx/.ipython/profile_default/securit\r\ny\r\nFeb 27 16:08:52 bash[4775]: [IPKernelApp] WARNING | Could not set permissions on /home/xxxxxx/.ipython/profile_default/pid\r\nFeb 27 16:08:52 bash[4775]: [IPKernelApp] WARNING | Could not set permissions on /home/xxxxxx/.ipython/profile_default/securit\r\ny\r\nFeb 27 16:08:52 bash[4775]: [IPKernelApp] WARNING | Could not set permissions on /home/xxxxxx/.ipython/profile_default/pid\r\nFeb 27 16:08:56 bash[4775]: [I 16:08:56.902 NotebookApp] Saving file at /Notebooks/20200225A.ipynb\r\nFeb 27 16:08:56 bash[4775]: [I 16:08:56.903 NotebookApp] Saving 20200225A.ipynb\r\nFeb 27 16:09:07 bash[4775]: [W 16:09:07.039 NotebookApp] 404 GET /api/contents/Notebooks/20200227B.ipynb?type=notebook&content\r\n=0&_=1582819731172 (172.27.68.155): No such file or directory: Notebooks/20200227B.ipynb\r\nFeb 27 16:09:07 bash[4775]: [W 16:09:07.040 NotebookApp] No such file or directory: Notebooks/20200227B.ipynb\r\nFeb 27 16:09:07 bash[4775]: [W 16:09:07.041 NotebookApp] 404 GET /api/contents/Notebooks/20200227B.ipynb?type=notebook&content\r\n=0&_=1582819731172 (172.27.68.155) 1.91ms referer=http://dls007.idc.ctbto.org:8888/notebooks/Notebooks/20200225A.ipynb\r\nFeb 27 16:09:07 bash[4775]: [I 16:09:07.060 NotebookApp] Uploading file to /Notebooks/20200227B.ipynb\r\nFeb 27 16:09:07 bash[4775]: [I 16:09:07.061 NotebookApp] Saving 20200227B.ipynb\r\nFeb 27 16:09:11 bash[4775]: [I 16:09:11.094 NotebookApp] Saving file at /Notebooks/20200227B.ipynb\r\nFeb 27 16:09:11 bash[4775]: [I 16:09:11.095 NotebookApp] Saving 20200227B.ipynb\r\nFeb 27 16:09:13 bash[4775]: 2020-02-27 16:09:13.621022: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Succes\r\nsfully opened dynamic library libcudart.so.10.2\r\nFeb 27 16:09:14 bash[4775]: 2020-02-27 16:09:14.257420: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Succes\r\nsfully opened dynamic library libnvinfer.so.7\r\nFeb 27 16:09:14 bash[4775]: 2020-02-27 16:09:14.258187: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Succes\r\nsfully opened dynamic library libnvinfer_plugin.so.7\r\nFeb 27 16:10:51 bash[4775]: [I 16:10:51.723 NotebookApp] Saving file at /Notebooks/20200227B.ipynb\r\nFeb 27 16:10:51 bash[4775]: [I 16:10:51.723 NotebookApp] Saving 20200227B.ipynb\r\nFeb 27 16:11:44 bash[4775]: 2020-02-27 16:11:44.933864: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Succes\r\nsfully opened dynamic library libcuda.so.1\r\nFeb 27 16:11:45 bash[4775]: 2020-02-27 16:11:45.339561: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device\r\n0 with properties:\r\nFeb 27 16:11:45 bash[4775]: pciBusID: 0000:06:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\r\nFeb 27 16:11:45 bash[4775]: coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.72GiB deviceMemoryBandwidth: 836.37GiB/s\r\nFeb 27 16:11:45 bash[4775]: 2020-02-27 16:11:45.341723: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device\r\n1 with properties:\r\nFeb 27 16:11:45 bash[4775]: pciBusID: 0000:07:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\r\nFeb 27 16:11:45 bash[4775]: coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.72GiB deviceMemoryBandwidth: 836.37GiB/s\r\nFeb 27 16:11:45 bash[4775]: 2020-02-27 16:11:45.343843: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device\r\n2 with properties:\r\nFeb 27 16:11:45 bash[4775]: pciBusID: 0000:0a:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\r\nFeb 27 16:11:45 bash[4775]: coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.72GiB deviceMemoryBandwidth: 836.37GiB/s\r\nFeb 27 16:11:45 bash[4775]: 2020-02-27 16:11:45.346002: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device\r\n3 with properties:\r\nFeb 27 16:11:45 bash[4775]: pciBusID: 0000:0b:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\r\nFeb 27 16:11:45 bash[4775]: coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.72GiB deviceMemoryBandwidth: 836.37GiB/s\r\nFeb 27 16:11:45 bash[4775]: 2020-02-27 16:11:45.348146: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device\r\n4 with properties:\r\nFeb 27 16:11:45 bash[4775]: pciBusID: 0000:85:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\r\nFeb 27 16:11:45 bash[4775]: coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.72GiB deviceMemoryBandwidth: 836.37GiB/s\r\nFeb 27 16:11:45 bash[4775]: 2020-02-27 16:11:45.350207: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device\r\n5 with properties:\r\nFeb 27 16:11:45 bash[4775]: pciBusID: 0000:86:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\r\nFeb 27 16:11:45 bash[4775]: coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.72GiB deviceMemoryBandwidth: 836.37GiB/s\r\nFeb 27 16:11:45 bash[4775]: 2020-02-27 16:11:45.352268: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device\r\n6 with properties:\r\nFeb 27 16:11:45 bash[4775]: pciBusID: 0000:89:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\r\nFeb 27 16:11:45 bash[4775]: coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.72GiB deviceMemoryBandwidth: 836.37GiB/s\r\nFeb 27 16:11:45 bash[4775]: 2020-02-27 16:11:45.354321: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device\r\n7 with properties:\r\nFeb 27 16:11:45 bash[4775]: pciBusID: 0000:8a:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\r\nFeb 27 16:11:45 bash[4775]: coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.72GiB deviceMemoryBandwidth: 836.37GiB/s\r\nFeb 27 16:11:45 bash[4775]: 2020-02-27 16:11:45.354367: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Succes\r\nsfully opened dynamic library libcudart.so.10.2\r\nFeb 27 16:11:45 bash[4775]: 2020-02-27 16:11:45.354408: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Succes\r\nsfully opened dynamic library libcublas.so.10\r\nFeb 27 16:11:45 bash[4775]: 2020-02-27 16:11:45.359249: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Succes\r\nsfully opened dynamic library libcufft.so.10\r\nFeb 27 16:11:45 bash[4775]: 2020-02-27 16:11:45.362850: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Succes\r\nsfully opened dynamic library libcurand.so.10\r\nFeb 27 16:11:45 bash[4775]: 2020-02-27 16:11:45.373520: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\r\nFeb 27 16:11:45 bash[4775]: 2020-02-27 16:11:45.376601: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\r\nFeb 27 16:11:45 bash[4775]: 2020-02-27 16:11:45.376650: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\nFeb 27 16:11:45 bash[4775]: 2020-02-27 16:11:45.408041: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7\r\nFeb 27 16:11:45 bash[4775]: 2020-02-27 16:11:45.420281: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2194960000 Hz\r\nFeb 27 16:11:45 bash[4775]: 2020-02-27 16:11:45.425679: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x49acb80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\nFeb 27 16:11:45 bash[4775]: 2020-02-27 16:11:45.425704: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\nFeb 27 16:11:47 bash[4775]: 2020-02-27 16:11:47.086025: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f1428005760 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\r\nFeb 27 16:11:47 bash[4775]: 2020-02-27 16:11:47.086061: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0\r\nFeb 27 16:11:47 bash[4775]: 2020-02-27 16:11:47.086071: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): Tesla V100-SXM2-32GB, Compute Capability 7.0\r\nFeb 27 16:11:47 bash[4775]: 2020-02-27 16:11:47.086079: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (2): Tesla V100-SXM2-32GB, Compute Capability 7.0\r\nFeb 27 16:11:47 bash[4775]: 2020-02-27 16:11:47.086087: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (3): Tesla V100-SXM2-32GB, Compute Capability 7.0\r\nFeb 27 16:11:47 bash[4775]: 2020-02-27 16:11:47.086096: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (4): Tesla V100-SXM2-32GB, Compute Capability 7.0\r\nFeb 27 16:11:47 bash[4775]: 2020-02-27 16:11:47.086125: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (5): Tesla V100-SXM2-32GB, Compute Capability 7.0\r\nFeb 27 16:11:47 bash[4775]: 2020-02-27 16:11:47.086151: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (6): Tesla V100-SXM2-32GB, Compute Capability 7.0\r\nFeb 27 16:11:47 bash[4775]: 2020-02-27 16:11:47.086181: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (7): Tesla V100-SXM2-32GB, Compute Capability 7.0\r\nFeb 27 16:11:47 bash[4775]: 2020-02-27 16:11:47.093006: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties:\r\nFeb 27 16:11:47 bash[4775]: pciBusID: 0000:06:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\r\nFeb 27 16:11:47 bash[4775]: coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.72GiB deviceMemoryBandwidth: 836.37GiB/s\r\nFeb 27 16:11:47 bash[4775]: 2020-02-27 16:11:47.095291: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 1 with properties:\r\nFeb 27 16:11:47 bash[4775]: pciBusID: 0000:07:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\r\nFeb 27 16:11:47 bash[4775]: coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.72GiB deviceMemoryBandwidth: 836.37GiB/s\r\nFeb 27 16:11:47 bash[4775]: 2020-02-27 16:11:47.097537: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 2 with properties:\r\nFeb 27 16:11:47 bash[4775]: pciBusID: 0000:0a:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\r\nFeb 27 16:11:47 bash[4775]: coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.72GiB deviceMemoryBandwidth: 836.37GiB/s\r\nFeb 27 16:11:47 bash[4775]: 2020-02-27 16:11:47.099773: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 3 with properties:\r\nFeb 27 16:11:47 bash[4775]: pciBusID: 0000:0b:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\r\nFeb 27 16:11:47 bash[4775]: coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.72GiB deviceMemoryBandwidth: 836.37GiB/s\r\nFeb 27 16:11:47 bash[4775]: 2020-02-27 16:11:47.102139: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 4 with properties:\r\nFeb 27 16:11:47 bash[4775]: pciBusID: 0000:85:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\r\nFeb 27 16:11:47 bash[4775]: coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.72GiB deviceMemoryBandwidth: 836.37GiB/s\r\nFeb 27 16:11:47 bash[4775]: 2020-02-27 16:11:47.104446: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 5 with properties:\r\nFeb 27 16:11:47 bash[4775]: pciBusID: 0000:86:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\r\nFeb 27 16:11:47 bash[4775]: coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.72GiB deviceMemoryBandwidth: 836.37GiB/s\r\nFeb 27 16:11:47 bash[4775]: 2020-02-27 16:11:47.106721: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 6 with properties:\r\nFeb 27 16:11:47 bash[4775]: pciBusID: 0000:89:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\r\nFeb 27 16:11:47 bash[4775]: coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.72GiB deviceMemoryBandwidth: 836.37GiB/s\r\nFeb 27 16:11:47 bash[4775]: 2020-02-27 16:11:47.109273: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 7 with properties:\r\nFeb 27 16:11:47 bash[4775]: pciBusID: 0000:8a:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\r\nFeb 27 16:11:47 bash[4775]: coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.72GiB deviceMemoryBandwidth: 836.37GiB/s\r\nFeb 27 16:11:47 bash[4775]: 2020-02-27 16:11:47.109329: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.2\r\nFeb 27 16:11:47 bash[4775]: 2020-02-27 16:11:47.109349: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\r\nFeb 27 16:11:47 bash[4775]: 2020-02-27 16:11:47.109369: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\r\nFeb 27 16:11:47 bash[4775]: 2020-02-27 16:11:47.109392: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\r\nFeb 27 16:11:47 bash[4775]: 2020-02-27 16:11:47.109409: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\r\nFeb 27 16:11:47 bash[4775]: 2020-02-27 16:11:47.109425: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\r\nFeb 27 16:11:47 bash[4775]: 2020-02-27 16:11:47.109439: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\nFeb 27 16:11:47 bash[4775]: 2020-02-27 16:11:47.146520: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7\r\nFeb 27 16:11:47 bash[4775]: 2020-02-27 16:11:47.146574: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.2\r\nFeb 27 16:11:53 bash[4775]: 2020-02-27 16:11:53.978874: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\r\nFeb 27 16:11:53 bash[4775]: 2020-02-27 16:11:53.978919: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 1 2 3 4 5 6 7\r\nFeb 27 16:11:53 bash[4775]: 2020-02-27 16:11:53.978949: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N Y Y Y Y N N N\r\nFeb 27 16:11:53 bash[4775]: 2020-02-27 16:11:53.978960: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 1:   Y N Y Y N Y N N\r\nFeb 27 16:11:53 bash[4775]: 2020-02-27 16:11:53.978989: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 2:   Y Y N Y N N Y N\r\nFeb 27 16:11:53 bash[4775]: 2020-02-27 16:11:53.978998: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 3:   Y Y Y N N N N Y\r\nFeb 27 16:11:53 bash[4775]: 2020-02-27 16:11:53.979028: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 4:   Y N N N N Y Y Y\r\nFeb 27 16:11:53 bash[4775]: 2020-02-27 16:11:53.979037: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 5:   N Y N N Y N Y Y\r\nFeb 27 16:11:53 bash[4775]: 2020-02-27 16:11:53.979049: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 6:   N N Y N Y Y N Y\r\nFeb 27 16:11:53 bash[4775]: 2020-02-27 16:11:53.979058: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 7:   N N N Y Y Y Y N\r\nFeb 27 16:11:54 bash[4775]: 2020-02-27 16:11:54.009417: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29967 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:06:00.0, compute capability: 7.0)\r\nFeb 27 16:11:54 bash[4775]: 2020-02-27 16:11:54.013256: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 29967 MB memory) -> physical GPU (device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:07:00.0, compute capability: 7.0)\r\nFeb 27 16:11:54 bash[4775]: 2020-02-27 16:11:54.016950: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 29967 MB memory) -> physical GPU (device: 2, name: Tesla V100-SXM2-32GB, pci bus id: 0000:0a:00.0, compute capability: 7.0)\r\nFeb 27 16:11:54 bash[4775]: 2020-02-27 16:11:54.020472: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 29967 MB memory) -> physical GPU (device: 3, name: Tesla V100-SXM2-32GB, pci bus id: 0000:0b:00.0, compute capability: 7.0)\r\nFeb 27 16:11:54 bash[4775]: 2020-02-27 16:11:54.023913: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:4 with 29967 MB memory) -> physical GPU (device: 4, name: Tesla V100-SXM2-32GB, pci bus id: 0000:85:00.0, compute capability: 7.0)\r\nFeb 27 16:11:54 bash[4775]: 2020-02-27 16:11:54.027396: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:5 with 29967 MB memory) -> physical GPU (device: 5, name: Tesla V100-SXM2-32GB, pci bus id: 0000:86:00.0, compute capability: 7.0)\r\nFeb 27 16:11:54 bash[4775]: 2020-02-27 16:11:54.030902: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:6 with 29967 MB memory) -> physical GPU (device: 6, name: Tesla V100-SXM2-32GB, pci bus id: 0000:89:00.0, compute capability: 7.0)\r\nFeb 27 16:11:54 bash[4775]: 2020-02-27 16:11:54.034514: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:7 with 29967 MB memory) -> physical GPU (device: 7, name: Tesla V100-SXM2-32GB, pci bus id: 0000:8a:00.0, compute capability: 7.0)\r\nFeb 27 16:12:48 bash[4775]: 2020-02-27 16:12:48.633652: W tensorflow/core/grappler/optimizers/meta_optimizer.cc:147] TF_ENABLE_AUTO_MIXED_PRECISION has no effect.\r\nFeb 27 16:12:49 bash[4775]: 2020-02-27 16:12:49.700819: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:\r\nFeb 27 16:12:49 bash[4775]: Total processable nodes: 13403\r\nFeb 27 16:12:49 bash[4775]: Recognized nodes available for conversion: 8834\r\nFeb 27 16:12:49 bash[4775]: Total nodes converted: 1104\r\nFeb 27 16:12:49 bash[4775]: Total FP16 Cast ops used (excluding Const and Variable casts): 120\r\nFeb 27 16:12:49 bash[4775]: Whitelisted nodes converted: 272\r\nFeb 27 16:12:49 bash[4775]: Blacklisted nodes blocking conversion: 432\r\nFeb 27 16:12:49 bash[4775]: Nodes blocked from conversion by blacklisted nodes: 1072\r\nFeb 27 16:12:49 bash[4775]: For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:\r\nFeb 27 16:12:49 bash[4775]: https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp\r\nFeb 27 16:12:51 bash[4775]: [I 16:12:51.706 NotebookApp] Saving file at /Notebooks/20200227B.ipynb\r\nFeb 27 16:12:51 bash[4775]: [I 16:12:51.707 NotebookApp] Saving 20200227B.ipynb\r\nFeb 27 16:12:52 bash[4775]: 2020-02-27 16:12:52.343735: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\r\nFeb 27 16:12:54 bash[4775]: 2020-02-27 16:12:54.744883: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\nFeb 27 16:13:08 bash[4775]: libibverbs: Warning: no userspace device-specific driver found for /sys/class/infiniband_verbs/uverbs3\r\nFeb 27 16:13:08 bash[4775]: libibverbs: Warning: no userspace device-specific driver found for /sys/class/infiniband_verbs/uverbs2\r\nFeb 27 16:13:08 bash[4775]: libibverbs: Warning: no userspace device-specific driver found for /sys/class/infiniband_verbs/uverbs1\r\nFeb 27 16:13:08 bash[4775]: libibverbs: Warning: no userspace device-specific driver found for /sys/class/infiniband_verbs/uverbs0\r\nFeb 27 16:13:21 bash[4775]: 2020-02-27 16:13:21.697661: W tensorflow/core/grappler/optimizers/meta_optimizer.cc:147] TF_ENABLE_AUTO_MIXED_PRECISION has no effect.\r\nFeb 27 16:13:21 bash[4775]: 2020-02-27 16:13:21.877836: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:\r\nFeb 27 16:13:21 bash[4775]: Total processable nodes: 2754\r\nFeb 27 16:13:21 bash[4775]: Recognized nodes available for conversion: 1796\r\nFeb 27 16:13:21 bash[4775]: Total nodes converted: 496\r\nFeb 27 16:13:21 bash[4775]: Total FP16 Cast ops used (excluding Const and Variable casts): 64\r\nFeb 27 16:13:21 bash[4775]: Whitelisted nodes converted: 80\r\nFeb 27 16:13:21 bash[4775]: Blacklisted nodes blocking conversion: 64\r\nFeb 27 16:13:21 bash[4775]: Nodes blocked from conversion by blacklisted nodes: 8\r\nFeb 27 16:13:21 bash[4775]: For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:\r\nFeb 27 16:13:21 bash[4775]: https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp\r\nFeb 27 16:13:45 bash[4775]: [I 16:13:45.930 NotebookApp] Kernel interrupted: 5ff3ace7-0cf6-4cd1-8610-1b721b134801\r\nFeb 27 16:14:51 bash[4775]: [I 16:14:51.673 NotebookApp] Saving file at /Notebooks/20200227B.ipynb\r\nFeb 27 16:14:51 bash[4775]: [I 16:14:51.674 NotebookApp] Saving 20200227B.ipynb\r\nFeb 27 16:15:18 bash[4775]: 2020-02-27 16:15:18.903125: W tensorflow/core/grappler/optimizers/meta_optimizer.cc:147] TF_ENABLE_AUTO_MIXED_PRECISION has no effect.\r\nFeb 27 16:15:19 bash[4775]: 2020-02-27 16:15:19.989487: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:\r\nFeb 27 16:15:19 bash[4775]: Total processable nodes: 13403\r\nFeb 27 16:15:19 bash[4775]: Recognized nodes available for conversion: 8834\r\nFeb 27 16:15:19 bash[4775]: Total nodes converted: 1104\r\nFeb 27 16:15:19 bash[4775]: Total FP16 Cast ops used (excluding Const and Variable casts): 120\r\nFeb 27 16:15:19 bash[4775]: Whitelisted nodes converted: 272\r\nFeb 27 16:15:19 bash[4775]: Blacklisted nodes blocking conversion: 432\r\nFeb 27 16:15:19 bash[4775]: Nodes blocked from conversion by blacklisted nodes: 1072\r\nFeb 27 16:15:19 bash[4775]: For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:\r\nFeb 27 16:15:19 bash[4775]: https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp\r\nFeb 27 16:15:33 bash[4775]: 2020-02-27 16:15:33.431854: W tensorflow/core/grappler/optimizers/meta_optimizer.cc:147] TF_ENABLE_AUTO_MIXED_PRECISION has no effect.\r\nFeb 27 16:15:33 bash[4775]: 2020-02-27 16:15:33.612105: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:\r\nFeb 27 16:15:33 bash[4775]: Total processable nodes: 2754\r\nFeb 27 16:15:33 bash[4775]: Recognized nodes available for conversion: 1796\r\nFeb 27 16:15:33 bash[4775]: Total nodes converted: 496\r\nFeb 27 16:15:33 bash[4775]: Total FP16 Cast ops used (excluding Const and Variable casts): 64\r\nFeb 27 16:15:33 bash[4775]: Whitelisted nodes converted: 80\r\nFeb 27 16:15:33 bash[4775]: Blacklisted nodes blocking conversion: 64\r\nFeb 27 16:15:33 bash[4775]: Nodes blocked from conversion by blacklisted nodes: 8\r\nFeb 27 16:15:33 bash[4775]: For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:\r\nFeb 27 16:15:33 bash[4775]: https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp\r\nFeb 27 16:16:51 bash[4775]: [I 16:16:51.865 NotebookApp] Saving file at /Notebooks/20200227B.ipynb\r\nFeb 27 16:16:51 bash[4775]: [I 16:16:51.865 NotebookApp] Saving 20200227B.ipynb\r\nFeb 27 16:18:51 bash[4775]: [I 16:18:51.884 NotebookApp] Saving file at /Notebooks/20200227B.ipynb\r\n...\r\nFeb 27 18:14:51 bash[4775]: [I 18:14:51.705 NotebookApp] Saving file at /Notebooks/20200227B.ipynb\r\nFeb 27 18:14:51 bash[4775]: [I 18:14:51.706 NotebookApp] Saving 20200227B.ipynb\r\nFeb 27 18:15:09 bash[4775]: terminate called after throwing an instance of 'std::system_error'\r\nFeb 27 18:15:09 bash[4775]: what():  Resource temporarily unavailable\r\nFeb 27 18:16:00 bash[4775]: [I 18:16:00.707 NotebookApp] KernelRestarter: restarting kernel (1/5), keep random ports\r\nFeb 27 18:16:00 bash[4775]: WARNING:root:kernel 5ff3ace7-0cf6-4cd1-8610-1b721b134801 restarted\r\nFeb 27 18:16:01 bash[4775]: [IPKernelApp] WARNING | Could not set permissions on /home/xxxxxx/.ipython/profile_default/security\r\nFeb 27 18:16:01 bash[4775]: [IPKernelApp] WARNING | Could not set permissions on /home/xxxxxx/.ipython/profile_default/pid\r\nFeb 27 18:16:01 bash[4775]: [IPKernelApp] WARNING | Could not set permissions on /home/xxxxxx/.ipython/profile_default/security\r\nFeb 27 18:16:01 bash[4775]: [IPKernelApp] WARNING | Could not set permissions on /home/xxxxxx/.ipython/profile_default/pid\r\nFeb 27 18:16:51 bash[4775]: [I 18:16:51.672 NotebookApp] Saving file at /Notebooks/20200227B.ipynb\r\nFeb 27 18:16:51 bash[4775]: [I 18:16:51.672 NotebookApp] Saving 20200227B.ipynb\r\n\r\n```\r\n\r\n**Describe the expected behavior**\r\n\r\nThe notebook runs through 1000 epochs without any problems in TF 2.0. The maximum thread count that is observed with TF2.0 is approx 950.\r\n\r\n", "comments": ["@sowo \r\n\r\nWill it be possible to share colab link or simple standalone code with supporting files to reproduce the issue in our environment.It helps us in localizing the issue faster. Thanks!", "@ravikyram: I cannot share the data publicly. Is there any way how I can share the colab link without posting it here?", "@sowo \r\n\r\nWill it be possible to share colab link with the sample data to reproduce the issue in our environment.Thanks!", "@ravikyram \r\n\r\nWe were able to reproduce the issue with random data as generated by the referenced notebook.\r\nHere is the colab link: https://colab.research.google.com/drive/1HG9d33o0h4e-f2U1ktaoqAirtj_FBdJe\r\n\r\nThis example crashed in epoch 863 with the same error shown in the OP.", "sometimes gpu resource is not released after session closed.", "@sowo Is this still an issue for you? I tried running your colab (with TF1.15.5) and noticing different error. Please check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/a8e55ee57b3bf08fd3098dc26df77045/20200227b.ipynb). Thanks!\r\n\r\nAs your issue is related to `TF2.x`, Can you please share a simple standalone code (`TF2.x`) to reproduce the issue. You could use dummy data or public data. Thanks!", "@jvishnuvardhan We've meanwhile moved on and this project is no longer active. It is therefore not an issue anymore and difficult to reproduce."]}, {"number": 37159, "title": "Plotting Data Using model.predict", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow): **YES**\r\n- OS Platform and Distribution (e.g.,\r\nLinux Ubuntu 16.04): **MacOS CATALINA**\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if\r\nthe issue happens on mobile device: \r\n- TensorFlow installed from (source or\r\nbinary): **BINARY**\r\n- TensorFlow version (use command below): 2.1\r\n- Python version: 3.7.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from\r\nsource): \r\n- CUDA/cuDNN version: 10.2\r\n- GPU model and memory:\r\n\r\n**Describe the current behavior**\r\n\r\nI am attempting to plot the prediction values .  However predictions is 2-D and the data must be one dimensional. \r\n\r\nHere is the predictions code:\r\n```\r\n#Get predicted price values\r\npredictions = model.predict(x_test)\r\npredictions = scaler.inverse_transform(predictions)\r\nprint(predictions.shape)\r\n\r\n#get root mean squared error\r\nrmse = np.sqrt(((predictions - y_test) ** 2).mean())\r\nprint(rmse)\r\n\r\n#Plot the data\r\ntrain = data[:training_data_len]\r\nvalid = data[training_data_len:]\r\nvalid['Predictions'] = predictions\r\n\r\n#Visualize the data\r\nplt.figure(figsize=(16,8))\r\nplt.title('Model')\r\nplt.xlabel('Date', fontsize=18)\r\nplt.ylabel('Close Price USD ($)', fontsize=18)\r\nplt.plot(train['Close'])\r\nplt.plot(valid[['Close', 'Predictions']])\r\nplt.legend(['Train', 'Val', 'Predictions'], loc='lower right')\r\nplt.show()\r\n```\r\n**Describe the expected behavior**\r\n\r\nThis should just return a graph of the predicted values.  Instead I receive the following error.\r\n```\r\nTraceback (most recent call last):\r\n  File \"/Users/owner/Desktop/algo/predict.py\", line 120, in <module>\r\n    valid['Predictions'] = predictions\r\n  File \"/usr/local/lib/python3.7/site-packages/pandas/core/frame.py\", line 3487, in __setitem__\r\n    self._set_item(key, value)\r\n  File \"/usr/local/lib/python3.7/site-packages/pandas/core/frame.py\", line 3563, in _set_item\r\n    self._ensure_valid_index(value)\r\n  File \"/usr/local/lib/python3.7/site-packages/pandas/core/frame.py\", line 3540, in _ensure_valid_index\r\n    value = Series(value)\r\n  File \"/usr/local/lib/python3.7/site-packages/pandas/core/series.py\", line 314, in __init__\r\n    data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True)\r\n  File \"/usr/local/lib/python3.7/site-packages/pandas/core/internals/construction.py\", line 729, in sanitize_array\r\n    raise Exception(\"Data must be 1-dimensional\")\r\nException: Data must be 1-dimensional\r\n```\r\n\r\nHow can I change predictions to make it 1-D?\r\nThank You,\r\nRRR.", "comments": ["@rehanmahmood,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here. Thanks!", "Yess for sure here it is:\r\n```\r\nimport requests\r\nimport math\r\nimport numpy as np\r\nimport pandas as pd\r\nimport pandas_datareader as web\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras import layers\r\nfrom tensorflow.keras.models import Sequential, load_model\r\nfrom tensorflow.keras.layers import LSTM, Embedding\r\nfrom tensorflow.keras.layers import Dense\r\nfrom sklearn.preprocessing import MinMaxScaler\r\nfrom bs4 import BeautifulSoup\r\nimport matplotlib.pyplot as plt\r\nfrom datetime import datetime, date\r\nplt.style.use('fivethirtyeight')\r\ntoday = date.today()\r\n\r\ndf = web.DataReader('GC=F', data_source='yahoo', start='2019-02-14', end=str(today))\r\n\r\n#print(df)\r\n\r\nplt.figure(figsize=(16,8))\r\nplt.title('GOLD PRICE HISTORY')\r\nplt.plot(df['Close'])\r\nplt.xlabel('Date', fontsize=18)\r\nplt.ylabel('Close price USD($)', fontsize=18)\r\n#plt.show()\r\n\r\n#get closing price\r\ndata = df.filter(['Close'])\r\n#get closing price values\r\ndataset = data.values\r\n#set training data length to 91% of total data set\r\ntraining_data_len = math.ceil(len(dataset))\r\nprint(training_data_len)\r\n#Scale the data\r\nscaler = MinMaxScaler(feature_range=(0,1))\r\nscaled_data = scaler.fit_transform(dataset)\r\n\r\n#create training data set\r\n#create the scaled training data set\r\ntrain_data = scaled_data[0: training_data_len , :]\r\n\r\n#split the data into x-train and y-train datasets\r\nx_train = []\r\ny_train = []\r\n\r\nfor i in range(20, len(train_data)):\r\n    x_train.append(train_data[i-20:i, 0])\r\n    y_train.append(train_data[i, 0])\r\n\r\n    if i<= 20:\r\n        \r\n        #print(x_train)\r\n        #print(y_train)\r\n        pass\r\n\r\n#convert x-train and y-train to numpy arrays to train models\r\nx_train, y_train = np.array(x_train), np.array(y_train)\r\n\r\n#reshape the data, LSTM model expects 3D dataset\r\nx_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\r\n\r\n#Build LSTM MODEL\r\nmodel = tf.keras.Sequential([\r\n    #tf.keras.layers.Embedding(encoder.vocab_size, 64),\r\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\r\n    tf.keras.layers.Dense(25, activation='relu'),\r\n    tf.keras.layers.Dense(1, activation='sigmoid')\r\n])\r\n\r\nmodel.compile(loss='mean_squared_error',\r\n              optimizer=tf.keras.optimizers.Adam(1e-4),\r\n              metrics=['accuracy'])\r\n\r\nmodel.fit(x_train, y_train, batch_size=1, epochs=1)\r\n\r\n#create testing data set\r\n#creat new array containing scaled values\r\ntest_data = scaled_data[training_data_len - 20: , :]\r\nprint(test_data.shape)\r\n\r\n#create the datasets x-test and y-test\r\nx_test=[]\r\ny_test=dataset[training_data_len:, :]\r\nfor i in range(20, len(test_data)+1):\r\n    x_test.append(test_data[i-20:i, 0])\r\n\r\n#convert data to numpy array\r\nx_test = np.array(x_test)\r\n\r\n#reshape data to 3D\r\nx_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\r\nprint(x_test.shape)\r\n\r\n#Get predicted price values\r\npredictions = model.predict(x_test)\r\npredictions = scaler.inverse_transform(predictions)\r\nprint(predictions.shape)\r\n\r\n\r\n#get root mean squared error\r\nrmse = np.sqrt(((predictions - y_test) ** 2).mean())\r\nprint(rmse)\r\n\r\n#Plot the data\r\ntrain = data[:training_data_len]\r\nvalid = data[training_data_len:]\r\nvalid['Predictions'] = predictions\r\n\r\n#Visualize the data\r\nplt.figure(figsize=(16,8))\r\nplt.title('Model')\r\nplt.xlabel('Date', fontsize=18)\r\nplt.ylabel('Close Price USD ($)', fontsize=18)\r\nplt.plot(train['Close'])\r\nplt.plot(valid[['Close', 'Predictions']])\r\nplt.legend(['Train', 'Val', 'Predictions'], loc='lower right')\r\nplt.show()\r\n\r\n", " @amahendrakar Any idea mate?", "@rehanmahmood,\r\nI tried to reproduce the issue and looks like the error is related to Pandas. Even the error log shows the same. Please take a look at the gist [here](https://colab.sandbox.google.com/gist/amahendrakar/f33ede73992cee3c941d1625304638d9/37159.ipynb).\r\n\r\nThis question is better asked on StackOverflow since it is not a Tensorflow bug or feature request. There is also a larger community that reads questions there.Thanks!", "How do you know the issue is with pandas?  Am I not using numpy to reshape my variables into different dimensions? ", "@rehanmahmood,\r\n\r\nThe error log you have submitted shows that there is an issue with the line `valid['Predictions'] = predictions`, which is a Pandas operation on the dataframe named `valid`.\r\n\r\nThe stack trace also shows that the error occurred while performing a Pandas operation.   \r\n  File \"/usr/local/lib/python3.7/site-packages/**pandas**/core/frame.py\", line 3487, in __setitem__\r\n    self._set_item(key, value)\r\n  File \"/usr/local/lib/python3.7/site-packages/**pandas**/core/frame.py\", line 3563, in _set_item\r\n    self._ensure_valid_index(value)\r\n  File \"/usr/local/lib/python3.7/site-packages/**pandas**/core/frame.py\", line 3540, in _ensure_valid_index", "Ohh okok yes that makes sense.  Thank you for all your help, much appreciated."]}, {"number": 37158, "title": "Saving and loading nested models fails", "body": "**EDIT:** I adjusted the bug description the bug appears in a different place than I thought before.\r\n\r\n**System information** \r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: -\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): unknown 2.1.0 (Installation from conda repository)\r\n- Python version: 3.7.6\r\n- Bazel version (if compiling from source): -\r\n- GCC/Compiler version (if compiling from source): -\r\n- CUDA/cuDNN version: -\r\n- GPU model and memory: -\r\n\r\n**Describe the current behavior**\r\nI created a simple nested tensorflow.keras model with an input node and sequential model containing two convolutional layers:\r\n```python\r\nimport tensorflow as tf\r\nmodel_inside = tf.keras.models.Sequential([tf.keras.layers.Conv2D(16, 3, input_shape=(None,None,1)),\r\n                                   tf.keras.layers.Conv2D(2, 1, activation='softmax')])\r\n\r\nmodel_outside_input = tf.keras.Input(shape=(256, 256, 1))\r\nmodel_outside = model_inside(model_outside_input)\r\n\r\nmodel_outside = tf.keras.models.Model(inputs=model_outside_input, outputs=model_outside)\r\n```\r\nSaving this model to disk in SavedModel format and loading it again results in a `TypeError: list indices must be integers or slices, not NoneType`.\r\nAccording to my observations this error only occurs with nested models.\r\n\r\n**Describe the expected behavior**\r\nI expect the loaded model to be exactly the same as before saving it and loading should not lead to an error.\r\n\r\n**Standalone code to reproduce the issue** \r\nhttps://colab.research.google.com/drive/1Qu32g7WpH_mVtwEvRToueF_Q8SMNMlf3", "comments": ["@soyers I don't see any issue with `tf-nightly` and saving in `save_format` as `tf`. Please check the [gist here](https://colab.sandbox.google.com/gist/jvishnuvardhan/224c93836dc5265ad42d565b1897e528/tf-2-saving-nested-models-fails.ipynb). Thanks!", "@soyers I ran your code as it is in `tf-nightly` and I don't see any issues. Recently, there were lot of improvements in saving the model. I think this issue was resolved by one of those recent changes. \r\n\r\nI am closing this issue as it was resolved. Feel free to reopen if this was not resolved for you. Thanks! ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37158\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37158\">No</a>\n"]}, {"number": 37157, "title": "Problem with Himax HM01B0 camera on the Sparkfun Edge board", "body": "@tensorflow/micro\r\n\r\n**System information**\r\n- Host OS Platform and Distribution: Linux Ubuntu 18.04\r\n- TensorFlow installed from (source or binary): Cloned from source, but not installed\r\n- TensorFlow version (commit SHA if source): 642708d2121976c8dbc0e8d0ae73fcf1cf027bd8\r\n- Target platform: Sparkfun Edge\r\n\r\nI'm trying to run an image classification model on a Sparkfun Edge, starting from the [person_detection](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/micro/examples/person_detection) example available in this repository. The logic for acquiring and resizing an image from the camera (Himax HM01B0) is included in `himax_driver/HM01B0_optimized.c`. For some reason, if I specify an image size greater than 102x102, the resulting image is padded with zeros in each of its four sides, yet the camera I'm using has a maximum pixel resolution of 320x320, as mentioned in the [official website](https://www.himax.com.tw/products/cmos-image-sensor/image-sensors/hm01b0/). \r\nHere's what I mean:\r\n\r\n### 102x102 image:\r\n![102x102](https://user-images.githubusercontent.com/30210403/75526152-86c19980-5a11-11ea-8bc6-47efdecaa7db.jpg)\r\n\r\n### 320x320 image:\r\n![320x320](https://user-images.githubusercontent.com/30210403/75526193-98a33c80-5a11-11ea-9b9f-171d4564e867.jpg)\r\n\r\n**Please provide the exact sequence of commands/steps when you ran into the problem**\r\nI simply passed `w=320`, `h=320` and `channels=1` to the function `hm01b0_blocking_read_oneframe_scaled` defined in `himax_driver/HM01B0_optimized.c`, printed each pixel value over the serial port and finally parsed such pixels with a Python script, displaying the resulting image.\r\n", "comments": ["Up", "While the sensor is 320x320 the selected output mode seems to be 320*240.\r\nAdditionally kStrideShift (used in hm01b0_blocking_read_oneframe_scaled) reduced the actually used pixels to 160/120 and causes underflow in offset_x and offset_y calculations.\r\nTry setting kStrideShift to 0 and limit w to 320 and h to 240.", "@suphoff Thanks, it worked! By the way, what do you mean that the selected output mode is 320x240? Is there anything I could do to change that to 320x320?", "@anferico : I believe you need to change the sHM01B0InitScript to get the desired resolution (link to camera manual with i2c register description should be on the sparkfun site)  and then adjust HM01B0_PIXEL_Y_NUM to the new Y resolution. Hope this helps - I did not like the camera SW/HW interface (no DMA) and never order it.", "Hi @anferico!\r\nWe are checking to see whether you still need help in this issue . Have you tried above [suggestion](https://github.com/tensorflow/tensorflow/issues/37157#issuecomment-640285359) yet? Please move this issue to [TF forum](https://discuss.tensorflow.org/) for further assistance. Thank you!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37157\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37157\">No</a>\n"]}]