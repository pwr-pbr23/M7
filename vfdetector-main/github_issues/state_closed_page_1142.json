[{"number": 18954, "title": "Escape regex pattern properly before using it", "body": "Without this patch, the function `_ignore_file_path` throws a traceback:\r\n```\r\n  File \"C:\\xxx\\lib\\site-packages\\tensorflow\\contrib\\tensorboard\\plugins\\trace\\trace.py\", line 156, in _ignore_file_path\r\n    if re.search(regex_pattern, fname):\r\n  File \"C:\\xxx\\lib\\re.py\", line 182, in search\r\n    return _compile(pattern, flags).search(string)\r\n  File \"C:\\xxx\\lib\\re.py\", line 301, in _compile\r\n    p = sre_compile.compile(pattern, flags)\r\n  File \"C:\\xxx\\lib\\sre_compile.py\", line 562, in compile\r\n    p = sre_parse.parse(p, flags)\r\n  File \"C:\\xxx\\lib\\sre_parse.py\", line 855, in parse\r\n    p = _parse_sub(source, pattern, flags & SRE_FLAG_VERBOSE, 0)\r\n  File \"C:\\xxx\\lib\\sre_parse.py\", line 416, in _parse_sub\r\n    not nested and not items))\r\n  File \"C:\\xxx\\lib\\sre_parse.py\", line 502, in _parse\r\n    code = _escape(source, this, state)\r\n  File \"C:\\xxx\\lib\\sre_parse.py\", line 401, in _escape\r\n    raise source.error(\"bad escape %s\" % escape, len(escape))\r\nsre_constants.error: bad escape \\p at position 11\r\n```", "comments": ["@nehaljwani Thanks for the PR. Are you sure we want to escape the characters in the filename regex? Does this error appear everytime _ignore_file_path is called? Or just in certain situations? Could you add a test that fails without this change to make this clear.\r\n\r\nThanks again", "@case540 Error appears everytime. See below:\r\n```python\r\n>>> import re\r\n>>> import os\r\n>>> TF_LIB_REGEX_FPATHS = [os.sep + os.path.join('tensorflow', 'python')]\r\n>>> def _ignore_file_path(fname, ignore_regex_fpaths):\r\n...   for regex_pattern in ignore_regex_fpaths:\r\n...     if re.search(regex_pattern, fname):\r\n...       return True\r\n...   return False\r\n...\r\n>>> TF_LIB_REGEX_FPATHS\r\n['\\\\tensorflow\\\\python']\r\n>>> ignore_regex_fpaths = TF_LIB_REGEX_FPATHS\r\n>>> _ignore_file_path(\"C:\\tflow\", ignore_regex_fpaths)\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"<stdin>\", line 3, in _ignore_file_path\r\n  File \"F:\\nwani\\mc3\\lib\\re.py\", line 182, in search\r\n    return _compile(pattern, flags).search(string)\r\n  File \"F:\\nwani\\mc3\\lib\\re.py\", line 301, in _compile\r\n    p = sre_compile.compile(pattern, flags)\r\n  File \"F:\\nwani\\mc3\\lib\\sre_compile.py\", line 562, in compile\r\n    p = sre_parse.parse(p, flags)\r\n  File \"F:\\nwani\\mc3\\lib\\sre_parse.py\", line 855, in parse\r\n    p = _parse_sub(source, pattern, flags & SRE_FLAG_VERBOSE, 0)\r\n  File \"F:\\nwani\\mc3\\lib\\sre_parse.py\", line 416, in _parse_sub\r\n    not nested and not items))\r\n  File \"F:\\nwani\\mc3\\lib\\sre_parse.py\", line 502, in _parse\r\n    code = _escape(source, this, state)\r\n  File \"F:\\nwani\\mc3\\lib\\sre_parse.py\", line 401, in _escape\r\n    raise source.error(\"bad escape %s\" % escape, len(escape))\r\nsre_constants.error: bad escape \\p at position 11\r\n```", "Nagging Assignee @ekelsen: It has been 45 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "This PR is no longer relevant, because of the removal in 5d7d8f9f7500e1b648e62fdd43f6d2999524e833"]}, {"number": 18953, "title": "Update is_windows() to allow mingw shells", "body": "", "comments": ["Nagging Assignee @ekelsen: It has been 15 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @ekelsen: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @ekelsen: It has been 42 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @ekelsen: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @ekelsen: It has been 29 days with no activity and this issue has an assignee. Please update the label and/or status accordingly."]}, {"number": 18952, "title": "Feature request: Option to create dataset from a subset of the columns in the CSV file using tf.contrib.data.make_csv_dataset()", "body": "------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Custom\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows\r\n- **TensorFlow installed from (source or binary)**: Binary\r\n- **TensorFlow version (use command below)**: 1.8\r\n- **Python version**:  3.6\r\n- **Bazel version (if compiling from source)**: NA\r\n- **GCC/Compiler version (if compiling from source)**: NA\r\n- **CUDA/cuDNN version**: NA\r\n- **GPU model and memory**:NA\r\n- **Exact command to reproduce**:\r\ntf.contrib.data.make_csv_dataset()\r\n\r\n### Describe the problem\r\n\r\nThe `tf.contrib.data.make_csv_dataset()` is a very useful feature which allows us to convert CSV files directly into at dataset without having to use Pandas library (like shown [here](https://stackoverflow.com/questions/49116343/dataset-api-flat-map-method-producing-error-for-same-code-which-works-with-ma/49140725#49140725)). However it is missing an important feature which Pandas had, that is to read a subset of the columns in the CSV file.\r\nFor example the following code:\r\n```\r\ndataset=tf.contrib.data.make_csv_dataset(file_pattern='./data/power_data/MISO_power_data1.csv',batch_size=24,shuffle=False)\r\ndataset = dataset.batch(4)\r\nX_iter = dataset.make_one_shot_iterator()\r\nX_batch = X_iter.get_next()\r\nX_batch\r\n```\r\nresults in following dataset:\r\n```\r\n{'Actual_Load_MWh': <tf.Tensor 'IteratorGetNext_9:0' shape=(?, ?) dtype=float32>,\r\n 'Hour_Ending': <tf.Tensor 'IteratorGetNext_9:1' shape=(?, ?) dtype=int32>,\r\n 'Market_Day': <tf.Tensor 'IteratorGetNext_9:2' shape=(?, ?) dtype=int32>,\r\n 'Wind_MWh': <tf.Tensor 'IteratorGetNext_9:3' shape=(?, ?) dtype=float32>}\r\n```\r\nHowever I don't want feature columns for 'Hour_Ending'  and  'Market_Day' in my dataset (since they are not relevant training data) . This could be done in Pandas using code below:\r\n```\r\ndf_input=pd.read_csv('./data/power_data/MISO_power_data1.csv',\r\n                         usecols=['Wind_MWh', 'Actual_Load_MWh'], nrows=24)\r\n```\r\nI know the easy solution would be to create a CSV file having only the feature columns I want. But it would be a great utility feature to add before `make_csv_dataset()` migrates out of contrib into core TF. I can submit a PR for this if required.", "comments": ["@sibyjackgrove Please feel free to create a pull request to add this functionality!", "@angersson Sure, I can do that. I am a little hesitant though because my previous pull request hasn't been reviewed even after 22 days.", "Never mind, after reviewing the code in master it seems a PR to add this functionality has already been merged to master.\r\nhttps://github.com/tensorflow/tensorflow/commit/77bd95ab15bdfa6a821540ce1c826c7eb9c9f0a8#diff-f42e2ca555c47644ae057257e7fbb838\r\n\r\nGuess I'll have to wait till 1.9 to access it. "]}, {"number": 18951, "title": "Fix string issue for temp_export_dir", "body": "Currently, running tensorflow on python3 I get redundant `b` modifier of basename\r\n\r\n```\r\nINFO:tensorflow:SavedModel written to: b\"exported_models/temp-b'1520964906'/saved_model.pb\"\r\nINFO:tensorflow:SavedModel written to: b\"exported_models/temp-b'1520964906'/saved_model.pb\"\r\n```", "comments": ["Wait a sec, seems like I can update a couple more things and double check on this", "anybody to take a look? cc @martinwicke ", "```2 failing and 14 successful checks``` - looks good so far, is there anything we can do with two failing builds?", "There are linter failures, should be easy to fix. The relevant log is here:\r\n\r\nhttps://source.cloud.google.com/results/invocations/09a9636f-b6b5-46a5-a563-e1ac23e651e1/targets/%2F%2Ftensorflow%2Ftools%2Fci_build:gen_ci_sanity_out/log\r\n\r\n(look for \"non-whitelited pylint errors\")", "Should be good now, seems like we need to re-trigger test with `kokoro:force-run`"]}, {"number": 18950, "title": "Fix cmake library path for libpng16.a", "body": "### System information\r\n\r\n- OS: Linux Fedora 26\r\n- Tensorflow: installed from source (master branch)\r\n- GCC 7.3.1\r\n- CMake 3.11\r\n- No GPU\r\n\r\n### Problem\r\nThe CMake build fails on Fedora in normal build. libpng16 is using \r\n\r\n> CMAKE_INSTALL_LIBDIR\r\n\r\n as the library destination for non-WIN32 systems. In some linux distribution like fedora this path corresponds to **_lib64_**\r\n\r\n### Steps to reproduce\r\n```\r\n$ git clone https://github.com/tensorflow/tensorflow\r\n$ cd tensorflow/tensorflow/contrib/cmake\r\n$ mkdir build && cd build\r\n$ cmake  ..\r\n$ make\r\n```\r\n\r\n### Logs\r\n```\r\n[...]\r\nmake[3]: *** No rule to make target 'png/install/lib/libpng16.a', needed by 'proto_text'.\r\nStop.\r\nmake[2]: *** [CMakeFiles/Makefile2:8959: CMakeFiles/proto_text.dir/all] Error 2\r\nmake[1]: *** [CMakeFiles/Makefile2:5441: CMakeFiles/tf_core_framework.dir/rule] Error 2\r\nmake: *** [Makefile:1919: tf_core_framework] Error 2\r\n```", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->", "I signed it!"]}, {"number": 18949, "title": "union if's into one in the ast_util.", "body": "", "comments": ["Nagging Assignee @ekelsen: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @ekelsen: It has been 29 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @ekelsen: It has been 44 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @ekelsen: It has been 59 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @ekelsen: It has been 74 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @ekelsen: It has been 89 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Thanks for the PR. Closing since this change seems unnecessary though"]}, {"number": 18948, "title": "DOC: add more explanation for auxiliary_name_scope", "body": "Fix #18781.\r\n\r\nupdate the documentation of `auxiliary_name_scope` making the intentions clear. cc @lukaszkaiser  ", "comments": ["Thank @lukaszkaiser . Could you help start all tests?", "I think they're running...", "I'm afraid not. I remember that we need to add `kokoro:force-run` label to start all tests. \r\n@ekelsen  Could you take a hand? Thanks.", "Nagging Assignee @ekelsen: It has been 19 days with no activity and this issue has an assignee. Please update the label and/or status accordingly."]}, {"number": 18947, "title": "tf.contrib.data.prefetch_to_device throws an error when used with tf.data.Iterator.from_structure", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nYes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.8.0\r\n- **Python version**: 2.7.12\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nI'm using **tf.data.Iterator.from_structure** mechanism to switch between training/validation datasets during training\r\nHowever, when **tf.contrib.data.prefetch_to_device** is added at the end of the dataset pipeline, the code crashes with the following error:\r\n```NotImplementedError: `prefetch_to_device()` must be the last transformation in a dataset pipeline.```\r\nExplicit one shot iterator works fine\r\n\r\n### Source code / logs\r\n```\r\nwith tf.Graph().as_default():\r\n    with tf.Session() as sess:\r\n        dataset = tf.data.Dataset.range(10).apply(tf.contrib.data.prefetch_to_device('/cpu:0'))\r\n\r\n        # 1) works fine\r\n        iterator = dataset.make_one_shot_iterator()\r\n        print sess.run(iterator.get_next())\r\n        \r\n        # 2) fails\r\n        iterator = tf.data.Iterator.from_structure((tf.int64), ([]))\r\n        sess.run(iterator.make_initializer(dataset))\r\n        print sess.run(iterator.get_next())\r\n```\r\n```\r\n0\r\n\r\n---------------------------------------------------------------------------\r\nNotImplementedError                       Traceback (most recent call last)\r\n<ipython-input-34-dbae58b82de0> in <module>()\r\n      6 \r\n      7         iterator = tf.data.Iterator.from_structure((tf.int64), ([]))\r\n----> 8         sess.run(iterator.make_initializer(dataset))\r\n      9         print sess.run(iterator.get_next())\r\n\r\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/data/ops/iterator_ops.pyc in make_initializer(self, dataset, name)\r\n    306     with ops.colocate_with(self._iterator_resource):\r\n    307       return gen_dataset_ops.make_iterator(\r\n--> 308           dataset._as_variant_tensor(), self._iterator_resource, name=name)  # pylint: disable=protected-access\r\n    309 \r\n    310   def get_next(self, name=None):\r\n\r\n/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/data/python/ops/prefetching_ops.pyc in _as_variant_tensor(self)\r\n    289     # TODO(mrry): Investigate support for chaining further transformations after\r\n    290     # the prefetch, including GPU support.\r\n--> 291     raise NotImplementedError(\"`prefetch_to_device()` must be the last \"\r\n    292                               \"transformation in a dataset pipeline.\")\r\n    293 \r\n\r\nNotImplementedError: `prefetch_to_device()` must be the last transformation in a dataset pipeline.\r\n```\r\n\r\nI guess, prefetching is still under development? Is there a temporary workaround for this kind of scenario?", "comments": ["I tried to handle this by using feedable iterators, but they are not supported either\r\n\r\ntraining_handle = session.run(trainIterator.string_handle())\r\nAttributeError: '_PrefetchToDeviceIterator' object has no attribute 'string_handle'\r\n", "Same with @fogelton \r\n` handle_train, handle_val = session.run([t_iterator.string_handle(), e_iterator.string_handle()])\r\nAttributeError: '_PrefetchToDeviceIterator' object has no attribute 'string_handle'`\r\n\r\nI would greatly appreciate it if it can work with string handles!", "Please use CopyToDevice + Prefetch instead of prefetch_to_device\r\n\r\nds = ...\r\nds = ds.apply(prefetching_ops.copy_to_device(\"/gpu:0\")).prefetch(1)", "We are closing this issue for now due to lack of activity. Please comment if this is still an issue for you. Thanks!"]}, {"number": 18946, "title": "A preliminary issue,Techniques for object detection", "body": "A preliminary issue about tensorflow for Android object tracking technology\r\nIs it using opencv? Thanks for your answer", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 30 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "We are closing this issue for now due to lack of activity. Please comment if this is still an issue for you. Thanks!"]}, {"number": 18945, "title": "How to change batch_size when load a frozen model?", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**: \r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["You have to recreate the freeze model to ensure that the N-channel is \"?\".\r\nRefer to this:[https://stackoverflow.com/questions/40586471/what-is-the-best-way-to-run-saved-model-with-different-batch-size-in-tensorflow?rq=1](url)\r\nSince the graph is appendable-only, I think you must recreate it with desired input dims at the beginning.\r\n\r\nBTW, you'd better take a look at the description before submitting an issue. A rule is a rule.", "Nagging Assignee @aselle: It has been 15 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @aselle: It has been 30 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "@oscarriddle \r\nThank you. It is a possible way to solve the problem, but I haven't try yet."]}, {"number": 18944, "title": "Fix docs rendering in placeholder docs page.", "body": "", "comments": []}, {"number": 18943, "title": "ssd_mobilenet_v2 was slower than ssd_mobilenet_v1 in the tflite ?", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:no\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**:Source\r\n- **TensorFlow version (use command below)**:1.8.0rc0\r\n- **Python version**: 2.7.12\r\n- **Bazel version (if compiling from source)**: 0.12.0\r\n- **GCC/Compiler version (if compiling from source)**: 5.4.0\r\n- **CUDA/cuDNN version**:cuda-9.0/7.0\r\n- **GPU model and memory**:GeForce GTX 1080/8105MiB\r\n- **Phone**: xiaomi5 (Snapdragon 820)\r\n\r\n### Describe the problem\r\nUsing tflite's [benchmark_model](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/tools/benchmark_model.cc) tool, I tested the performance of the ssd_mobilenet_v1 and ssd_mobilenet_v2  models , and found that ssd_mobilenet_v2 was slower than ssd_mobilenet_v1, about 10ms, when setting to 4 threads.\r\n\r\nBut SSDLite presented in [MobileNetV2: Inverted Residuals and Linear Bottlenecks](https://arxiv.org/abs/1801.04381) is 35% faster than Mobilenet V1 SSD on a Google Pixel phone CPU (200ms vs. 270ms) at the same accuracy.\r\n\r\nWho can explain why ?\r\n### Source code / logs\r\nssd_mobilenet_v1 : \r\n```\r\n ./benchmark_model \\\r\n>   --graph=\"mobilenet_ssd_v1_quan.tflite\" \\\r\n>   --input_layer=\"Preprocessor/sub\" \\\r\n>   --input_layer_shape=\"1,300,300,3\" \\\r\n>   --input_layer_type=\"uint8\" \\\r\n>   --run_delay=\"-1.0\" \\\r\n>   --output_layer=\"concat,concat_1\" \\\r\n>   --num_runs=50 \\\r\n>   --num_threads=4 \\\r\n>   --warmup_runs=1 \\\r\n>   --use_nnapi=false\r\nWARNING: linker: /data/local/tmp/benchmark_model: unused DT entry: type 0xf arg 0x82e\r\nGraph: [mobilenet_ssd_v1_quan.tflite]\r\nInput layers: [Preprocessor/sub]\r\nInput shapes: [1,300,300,3]\r\nInput types: [uint8]\r\nOutput layers: [concat,concat_1]\r\nNum runs: [50]\r\nInter-run delay (seconds): [-1.0]\r\nNum threads: [4]\r\nWarmup runs: [1]\r\nUse nnapi : [0]\r\nEnable profiling : [0]\r\nnnapi error: unable to open library libneuralnetworks.so\r\nInitialized session in 0.02646s\r\nRunning benchmark for 1 iterations: \r\ncount=1 min=220752 max=220752 avg=220752 std=0\r\nRunning benchmark for 50 iterations: \r\ncount=50 min=75066 max=193842 avg=82848.9 std=19942\r\nAverage inference timings in us: 82848 , Warmup: 220752,\r\n``` \r\nssd_mobilenet_v2 :\r\n```\r\n./benchmark_model \\\r\n>   --graph=\"mobilenet_ssd_v2_quan.tflite\" \\\r\n>   --input_layer=\"Preprocessor/sub\" \\\r\n>   --input_layer_shape=\"1,300,300,3\" \\\r\n>   --input_layer_type=\"uint8\" \\\r\n>   --run_delay=\"-1.0\" \\\r\n>   --output_layer=\"concat,concat_1\" \\\r\n>   --num_runs=50 \\\r\n>   --num_threads=4 \\\r\n>   --warmup_runs=1 \\\r\n>   --use_nnapi=false\r\nWARNING: linker: /data/local/tmp/benchmark_model: unused DT entry: type 0xf arg 0x82e\r\nGraph: [mobilenet_ssd_v2_quan.tflite]\r\nInput layers: [Preprocessor/sub]\r\nInput shapes: [1,300,300,3]\r\nInput types: [uint8]\r\nOutput layers: [concat,concat_1]\r\nNum runs: [50]\r\nInter-run delay (seconds): [-1.0]\r\nNum threads: [4]\r\nWarmup runs: [1]\r\nUse nnapi : [0]\r\nEnable profiling : [0]\r\nnnapi error: unable to open library libneuralnetworks.so\r\nInitialized session in 0.033135s\r\nRunning benchmark for 1 iterations: \r\ncount=1 min=110434 max=110434 avg=110434 std=0\r\nRunning benchmark for 50 iterations: \r\ncount=50 min=78189 max=285788 avg=90162.9 std=29644\r\nAverage inference timings in us: 90162 , Warmup: 110434, \r\n```", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nExact command to reproduce", "Hello @WenguoLi at the tensorflow models readme: \"For example Mobilenet V2 is faster on mobile devices than Mobilenet V1, but is slightly slower on desktop GPU.\" This might give you an explanation ?", "In my Android device, TF detect running time is around 600ms,but TFLdetect is around 2000ms.", "@Davidnet , ssd_mobilenet_v1 and ssd_mobilenet_v2 models are running on android mobile devices, not on desktop GPU.\r\nI found the reason why kernel size of box_predictor is 1 in the ssd_mobilenet_v1. but kernel size of box_predictor is 3 in the ssd_mobilenet_v2.", "where can download ssd_mobilenet_v2 and ssd_mobilenet_v1 .tflite\r\nThank you very much"]}, {"number": 18942, "title": "Allow tfdbg mouse down scroll in curses UI", "body": "This commit allows users to continuously scroll the screen when the mouse is held down on the scroll bar when using the curses UI for tfdbg.", "comments": ["Yea, the click hold scrolling is pretty wonky outside the arrow buttons. I've added the requested change."]}, {"number": 18941, "title": "question when run distributed tensorflow", "body": "when I run the distributed tensorflow , I met this problem described below on one of the\\ worker:\r\n\r\n\r\nTraceback (most recent call last):\r\n  File \"dis_convae.py\", line 277, in <module>\r\n    _, cost,step = sess.run([train_op_1, model_one_cost,global_step], feed_dict={model_one_X: input_})\r\n  File \"/home/master/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 778, in run\r\n    run_metadata_ptr)\r\n  File \"/home/master/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 982, in _run\r\n    feed_dict_string, options, run_metadata)\r\n  File \"/home/master/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1032, in _do_run\r\n    target_list, options, run_metadata)\r\n  File \"/home/master/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1052, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: NodeDef missing attr 'use_nesterov' from Op<name=ApplyAdam; signature=var:Ref(T), m:Ref(T), v:Ref(T), beta1_power:T, beta2_power:T, lr:T, beta1:T, beta2:T, epsilon:T, grad:T -> out:Ref(T); attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, ..., DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=use_locking:bool,default=false; attr=use_nesterov:bool,default=false>; NodeDef: Adam/update_Variable_1/ApplyAdam = ApplyAdam[T=DT_FLOAT, _class=[\"loc:@Variable_1\"], use_locking=false, _device=\"/job:ps/replica:0/task:0/device:CPU:0\"](Variable_1, Variable_1/Adam, Variable_1/Adam_1, beta1_power/read, beta2_power/read, Adam/learning_rate_S147, Adam/beta1_S149, Adam/beta2_S151, Adam/epsilon_S153, gradients/Add_grad/tuple/control_dependency_1_S155)\r\n\r\nDoes anyone know how to solve it?", "comments": ["This does not seem to be either a bug report or a feature request (or anything that could be helpful for the development of tensorflow). \r\n\r\nPlease, refer to [stackoverflow](https://www.stackoverflow.com) for this kind or questions. I would also advice you to add some more information than what you provided here."]}, {"number": 18940, "title": "Fixing the mock import error for devel docker.", "body": "Same as #18843", "comments": []}, {"number": 18939, "title": "Revised roadmap", "body": "", "comments": ["Good point. Let me fix those.\r\n\r\n", "Revised roadmap"]}, {"number": 18938, "title": "Refactoring: Remove a redundant map from model.h.", "body": "Cherry picking this into r1.8 branch for a compatibility issue.\r\nThe original Piper ID: 194306629", "comments": ["Dropping this request"]}, {"number": 18937, "title": "Docs: fix typo", "body": "Fixes b/78774644", "comments": []}, {"number": 18936, "title": "the problem when downgrading the tensorflow version from 1.7 to 1.6", "body": "I got the following error message when trying to roll back the tensorflow version from 1.7 to 1.6.  What might be the cause?\r\n\r\n`conda install tensorflow==1.6`\r\n\r\n```\r\nFetching package metadata ...........\r\nSolving package specifications: .\r\n\r\nPackage plan for installation in environment /data/virtualE/deeplab:\r\n\r\nThe following packages will be DOWNGRADED:\r\n\r\n    tensorboard:         1.7.0-py36hf484d3e_0 --> 1.6.0-py36hf484d3e_1\r\n    tensorflow:          1.7.0-0              --> 1.6.0-0\r\n    tensorflow-base:     1.7.0-py36hff88cb2_0 --> 1.6.0-py36hff88cb2_0\r\n    tensorflow-gpu:      1.7.0-0              --> 1.6.0-0\r\n    tensorflow-gpu-base: 1.7.0-py36h8a131e3_0 --> 1.6.0-py36h8a131e3_0\r\n\r\ntensorboard-1. 100% |##################################################################################################| Time: 0:00:00  39.64 MB/s\r\ntensorboard-1. 100% |##################################################################################################| Time: 0:00:00 502.27 MB/s\r\ntensorboard-1. 100% |##################################################################################################| Time: 0:00:00 498.78 MB/s\r\n\r\nCondaError: CondaError: Failed to write to /tmp/conda/4/pkgs/tensorboard-1.6.0-py36hf484d3e_1.tar.bz2\r\n  errno: 28\r\nCondaError: CondaError: Failed to write to /tmp/conda/4/pkgs/tensorboard-1.6.0-py36hf484d3e_1.tar.bz2\r\n  errno: 28\r\nCondaError: CondaError: Failed to write to /tmp/conda/4/pkgs/tensorboard-1.6.0-py36hf484d3e_1.tar.bz2\r\n  errno: 28\r\n```", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 15 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "We are closing this issue for now due to lack of activity. Please comment if this is still an issue for you. Thanks!"]}, {"number": 18935, "title": "Branch 194551042", "body": "", "comments": []}, {"number": 18933, "title": "Move CROSSTOOL_nvcc.tpl to c++14 as cuda9 is supporting c++14 now.", "body": "", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->", "Posted Issue instead."]}, {"number": 18932, "title": "is it possible using tf.contrib.model_pruning.masked_conv2d instead of tf.layers.conv2d?", "body": "", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Sorry for late response \r\nno, it is not. ", "Nagging Assignee @rohan100jain: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @rohan100jain: It has been 29 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @rohan100jain: It has been 44 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @rohan100jain: It has been 59 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\nMake sure you also include the exact command if possible to produce the output included in your test case. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new).\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!\r\n", "Also questions like this are better put to StackOverflow than here."]}, {"number": 18931, "title": "CMake build without GRPC and Python bindings fails", "body": "### System information\r\n- OS: Linux Ubuntu 14.04\r\n- Tensorflow: installed from source ([master branch](8a428cdd350a56b9f7de2ed55b3fbe7b6ad6b257))\r\n- GCC 4.8.4\r\n- CMake 3.8.2\r\n- No GPU\r\n\r\n### Problem\r\nThe CMake build fails on Ubuntu when GRPC support is disabled.\r\n\r\n### Command\r\n```\r\ncmake \\\r\n    \t-DCMAKE_INSTALL_PREFIX=../test/ \\\r\n    \t-DCMAKE_BUILD_TYPE=Release \\\r\n        -Dtensorflow_BUILD_SHARED_LIB=ON \\\r\n    \t-Dtensorflow_BUILD_ALL_KERNELS=ON \\\r\n    \t-Dtensorflow_BUILD_CONTRIB_KERNELS=OFF \\\r\n    \t-Dtensorflow_BUILD_CC_EXAMPLE=OFF \\\r\n    \t-Dtensorflow_BUILD_PYTHON_BINDINGS=OFF \\\r\n    \t-Dtensorflow_ENABLE_GRPC_SUPPORT=OFF \\\r\n    \t-Dtensorflow_ENABLE_SSL_SUPPORT=OFF \\\r\n    \t-Dtensorflow_BUILD_CC_TESTS=OFF \\\r\n    \t-Dtensorflow_BUILD_PYTHON_TESTS=OFF \\\r\n        -Dtensorflow_ENABLE_GPU=OFF ..\r\nmake\r\n```\r\n\r\n### Logs\r\n```\r\n[...]\r\nmake[2]: *** No rule to make target `../grpc', needed by `tensorflow/core/debug/debug_service.grpc.pb.cc'.\r\nStop.\r\nmake[1]: *** [CMakeFiles/tf_protos_cc.dir/all] Error 2\r\n```\r\n", "comments": ["Actually it also fails if the python bindings are disabled with `-Dtensorflow_BUILD_PYTHON_BINDINGS=OFF`:\r\n```\r\n[...]\r\nScanning dependencies of target tf_c_python_api\r\n[ 65%] Building CXX object CMakeFiles/tf_c_python_api.dir/tensorflow/tensorflow/c/python_api.cc.o\r\n/tensorflow/tensorflow/c/python_api.cc:19:64: fatal error: tensorflow/python/framework/cpp_shape_inference.pb.h: No such file or directory\r\n #include \"tensorflow/python/framework/ccp_shape_inference.pb.h\"\r\n```\r\nWhy exposing these flags in the `CMakeLists.txt` if GRPC and Python are anyway required to successfully build ?", "This seems to fix the issue with the Python binding:\r\n```diff\r\ndiff --git a/tensorflow/contrib/cmake/tf_core_framework.cmake b/tensorflow/contrib/cmake/tf_core_framework.cmake\r\nindex b47c32f..94dda24 100644\r\n--- a/tensorflow/contrib/cmake/tf_core_framework.cmake\r\n+++ b/tensorflow/contrib/cmake/tf_core_framework.cmake\r\n@@ -127,6 +127,7 @@ file(GLOB_RECURSE tf_protos_cc_srcs RELATIVE ${tensorflow_source_dir}\r\n     \"${tensorflow_source_dir}/tensorflow/core/*.proto\"\r\n     \"${tensorflow_source_dir}/tensorflow/contrib/boosted_trees/proto/*.proto\"\r\n     \"${tensorflow_source_dir}/tensorflow/contrib/tpu/proto/*.proto\"\r\n+    \"${tensorflow_source_dir}/tensorflow/python/framework/*.proto\"\r\n )\r\n \r\n RELATIVE_PROTOBUF_GENERATE_CPP(PROTO_SRCS PROTO_HDRS\r\n```\r\n\r\nRegarding the GRPC dependency, this helps:\r\n```diff\r\ndiff --git a/tensorflow/contrib/cmake/tf_core_framework.cmake b/tensorflow/contrib/cmake/tf_core_framework.cmake\r\nindex b47c32f..34ed324 100644\r\n--- a/tensorflow/contrib/cmake/tf_core_framework.cmake\r\n+++ b/tensorflow/contrib/cmake/tf_core_framework.cmake\r\n@@ -177,13 +177,16 @@ RELATIVE_PROTOBUF_TEXT_GENERATE_CPP(PROTO_TEXT_SRCS PROTO_TEXT_HDRS\r\n if(WIN32)\r\n   add_library(tf_protos_cc ${PROTO_SRCS} ${PROTO_HDRS})\r\n else()\r\n-  file(GLOB_RECURSE tf_protos_grpc_cc_srcs RELATIVE ${tensorflow_source_dir}\r\n-      \"${tensorflow_source_dir}/tensorflow/core/debug/*.proto\"\r\n-  )\r\n-  RELATIVE_PROTOBUF_GENERATE_GRPC_CPP(PROTO_GRPC_SRCS PROTO_GRPC_HDRS\r\n-      ${tensorflow_source_dir} ${tf_protos_grpc_cc_srcs}\r\n-  )\r\n-  add_library(tf_protos_cc ${PROTO_GRPC_SRCS} ${PROTO_GRPC_HDRS} ${PROTO_SRCS} ${PROTO_HDRS})\r\n+  if(tensorflow_ENABLE_GRPC_SUPPORT)\r\n+    file(GLOB_RECURSE tf_protos_grpc_cc_srcs RELATIVE ${tensorflow_source_dir}\r\n+        \"${tensorflow_source_dir}/tensorflow/core/debug/*.proto\"\r\n+    )\r\n+    RELATIVE_PROTOBUF_GENERATE_GRPC_CPP(PROTO_GRPC_SRCS PROTO_GRPC_HDRS\r\n+        ${tensorflow_source_dir} ${tf_protos_grpc_cc_srcs}\r\n+    )\r\n+    add_library(tf_protos_cc ${PROTO_GRPC_SRCS} ${PROTO_GRPC_HDRS})\r\n+  endif(tensorflow_ENABLE_GRPC_SUPPORT)\r\n+  add_library(tf_protos_cc ${PROTO_SRCS} ${PROTO_HDRS})\r\n endif()\r\n```\r\n\r\nHowever some issues remain with [`debug_io_utils.h`](../blob/master/tensorflow/core/debug/debug_io_utils.h) and [`debug_io_utils.cc`](../blob/master/tensorflow/core/debug/debug_io_utils.cc), which require GRPC and are included by  [`debug_ops.h`](../blob/master/tensorflow/core/kernels/debug_ops.h).", "@mrry Can you take a look at this?\r\n\r\n@Skydes Since you already have some fixes, please feel free to make a pull request!", "We don't build with these options in our continuous integration, so this particular options seems to have rotted. Opening it for community contributions.", "@Skydes \r\nIs this still an issue?\r\nCould you please update TensorFlow to the latest stable version v.2.6 and let us know if you are facing the same error. Thanks!", "@tilakrayal I am not using TensorFlow anymore so I won't be able to help on this - closing this issue now.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/18931\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/18931\">No</a>\n"]}, {"number": 18930, "title": "ERROR: in target '//external:cc_toolchain': no such package '", "body": "ERROR: in target '//external:cc_toolchain': no such package '@local_config_cc//': Traceback (most recent call last):\r\n        File \"C:/users/wondercupid/appdata/local/temp/_bazel_wondercupid/dlqxfaaz/external/bazel_tools/tools/cpp/cc_configure.bzl\", line 37\r\n                configure_windows_toolchain(repository_ctx)\r\n        File \"C:/users/wondercupid/appdata/local/temp/_bazel_wondercupid/dlqxfaaz/external/bazel_tools/tools/cpp/windows_cc_configure.bzl\", line 302, in configure_windows_toolchain\r\n                tpl(repository_ctx, \"CROSSTOOL\", {\"%{cpu...}\": \"\"})\r\n        File \"C:/users/wondercupid/appdata/local/temp/_bazel_wondercupid/dlqxfaaz/external/bazel_tools/tools/cpp/windows_cc_configure.bzl\", line 314, in tpl\r\n                _get_escaped_windows_msys_crosstool_content(repository_ctx)\r\n        File \"C:/users/wondercupid/appdata/local/temp/_bazel_wondercupid/dlqxfaaz/external/bazel_tools/tools/cpp/windows_cc_configure.bzl\", line 42, in _get_escaped_windows_msys_crosstool_content\r\n                auto_configure_fail((\"Could not determine MSYS/Cygwi...))\r\n        File \"C:/users/wondercupid/appdata/local/temp/_bazel_wondercupid/dlqxfaaz/external/bazel_tools/tools/cpp/lib_cc_configure.bzl\", line 84, in auto_configure_fail\r\n                fail((\"\\n%sAuto-Configuration Error:%...)))\r\n\r\nAuto-Configuration Error: Could not determine MSYS/Cygwin root from BAZEL_SH (e:/msys32/usr/bin)\r\nINFO: Elapsed time: 7.287s\r\nFAILED: Build did NOT complete successfully (2 packages loaded)", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "which file I will write Gpu modele and momory,TensorFlow version...? Thank you ", "OS Platform and Distribution windows10 msys2\r\nTensorFlow installed from source(git clone --recurse-submodules https://github.com/tensorflow/tensorflow.git)\r\nTensorFlow version (up)\r\nBazel version 0.12.0\r\nCUDA/cuDNN version cuda 9.1 cuDNN 9.10\r\nGPU model and memory NVIDIA GeForce GTX 850\r\nExact command to reproduce.\r\n\r\nplease help me", "Im getting a simillar error. Found any solution so far?", "No\uff0c\uff0c\uff0c\uff0c", "@helloworkcupid this looks like an install/build error. Have you tried the different issues on the Install Tensorflow on Windows page:\r\nhttps://www.tensorflow.org/install/install_windows\r\n\r\nIn particular, have you tried the uninstall/reinstall sequence on StackOverflow:\r\nhttps://stackoverflow.com/questions/42006320/tensorflow-pip-installation-issue-cannot-import-name-descriptor\r\n", "We are closing this issue for now due to lack of activity. Please comment if this is still an issue for you. Thanks!"]}, {"number": 18929, "title": "TensorFlow Tutorials should have a Jupyter notebook friendly option", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: \r\nNope\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nWindows 10 (latest 04/27/2018)\r\n- **TensorFlow installed from (source or binary)**:\r\npython -m pip install tensorflow\r\n- **TensorFlow version (use command below)**:\r\n1.7.0\r\n- **Python version**: \r\n3.6.5\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: 9.0/1.7\r\n- **GPU model and memory**: GeoForce GTX 1050Ti (4GB)\r\n- **Exact command to reproduce**:\r\nI opened jupyter notebook in my main python installation: \r\nC:\\Users\\ (me) \\AppData\\Local\\Programs\\Python\\Python36\\Scripts\\jupyter-notebook.exe\r\nI downloaded the master models folder, put it in my jupyter directory and went to\r\nhttp://localhost:8888/tree/models-master/official/wide_deep\r\nThen I created a new notebook (in the wide_deep directory) and tried to do the very first shell command\r\n\r\n! data_download.py\r\n\r\n\r\n### Describe the problem\r\nThe TensorFlow tutorial code (https://www.tensorflow.org/tutorials/wide) can't be run from Jupyter notebook. TensorFlow is a tool mainly for data scientists and we use Jupyter notebook a lot! The official tutorial/sample code should have a Jupyter friendly option.\r\n\r\n### Source code / logs\r\nTraceback (most recent call last):\r\n  File \"data_download.py\", line 71, in <module>\r\n    tf.app.run(argv=[sys.argv[0]] + unparsed)\r\n  File \"C:\\Users\\shado\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 126, in run\r\n    _sys.exit(main(argv))\r\n  File \"data_download.py\", line 60, in main\r\n    tf.gfile.MkDir(FLAGS.data_dir)\r\n  File \"C:\\Users\\shado\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\", line 358, in create_dir\r\n    pywrap_tensorflow.CreateDir(compat.as_bytes(dirname), status)\r\n  File \"C:\\Users\\shado\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\", line 516, in __exit__\r\n    c_api.TF_GetCode(self.status.status))\r\ntensorflow.python.framework.errors_impl.NotFoundError: Failed to create a directory: /tmp/census_data; No such file or directory\r\n", "comments": ["Nagging Assignee @michaelisard: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @MarkDaoust: It has been 15 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @MarkDaoust: It has been 30 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @MarkDaoust: It has been 45 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "The problem was mostly just a question of setting the python path correctly.\r\n\r\nSee working example here:\r\n\r\nhttps://colab.research.google.com/github/tensorflow/models/blob/master/samples/core/tutorials/estimators/linear.ipynb#scrollTo=-MPr95UccYvL"]}, {"number": 18928, "title": "Disable python/kernel_tests/sparse_reshape_op_test.py on cmake.", "body": "", "comments": []}, {"number": 18927, "title": "R1.0", "body": "learn lower version to match my plan.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->"]}, {"number": 18926, "title": "Add globs from Lambda before building it", "body": "The globals required to build the Lambda weren't loaded correctly. This leads to many problems when cloning a Model.\r\n\r\nI'm not sure how to handle collisions. \r\n\r\nThis PR allows us to avoid using lambda with an inner import.\r\n\r\nSmall note: the latter one is more efficient and does the same thing.\r\n```python\r\nglobs = dict(list(globs.items()) + list(custom_objects.items()))\r\nglobs.update(custom_objects)\r\n```", "comments": ["@fchollet this is a PR for what I talked to you about. ", "Nagging Assignee @ekelsen: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "There are merge conflicts that should be resolved, sorry for the delay. ", "@ekelsen please merge after the checks have run. Thanks!"]}, {"number": 18925, "title": "About newlly added eager_operation.h", "body": "In the latest Eager core update, I see that eager_operation is moved to [tensorflow/core/common_runtime/eager](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/core/common_runtime/eager). However this file require c_api as one of the dependency.\r\n\r\nThe c_api is suppose to be built after cpu_core_lib is generated, I am now a bit confuse as I am trying to rewrite the CMake files in order to fit the new eager structure.\r\n\r\nAny hel?\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "I face this issue as well (Ubuntu 14, latest master head). My current workaround is to disable the build of `transform_graph`, `summarize_graph`, `compare_graphs` and `benchmark_model` (see [here](https://github.com/Skydes/tensorflow_catkin/blob/updated-build/patches/fix_eager_link.patch)).", "I am now separating eager runtime to a new cmake file and build pass.\r\n\r\nThe new eager runtime depends on c_api while eager/c_api depends on the eager runtime\r\n\r\nIn past the eager/c_api can be built simultaneously with c_api, I have modified the cmakelist and build eager dependency at the last moment of tensorflow projects. \r\n\r\nThe modified code can be found [here](https://github.com/tensorflow/tensorflow/pull/16480)", "@akshaym could you look into this and if our dependency graph is healthy?"]}, {"number": 18924, "title": "build Error  Tabulations are not allowed for identation. Use spaces instead.", "body": "ERROR: E:/demoall/demofour/tf/tensorflow/WORKSPACE:60:5: Tabulations are not allowed for identation. Use spaces instead.\r\nERROR: E:/demoall/demofour/tf/tensorflow/WORKSPACE:61:2: Tabulations are not allowed for identation. Use spaces instead.\r\nERROR: E:/demoall/demofour/tf/tensorflow/WORKSPACE:56:2: indentation error\r\nERROR: E:/demoall/demofour/tf/tensorflow/WORKSPACE:61:6: syntax error at 'outdent': expected expression\r\nERROR: error loading package 'external': Failed to parse WORKSPACE file\r\nERROR: error loading package 'external': Failed to parse WORKSPACE file\r\nINFO: Elapsed time: 1.773s\r\nFAILED: Build did NOT complete successfully (0 packages loaded)", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}]