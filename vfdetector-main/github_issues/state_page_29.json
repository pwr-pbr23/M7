[{"number": 49502, "title": "Unable to create TFLite LSTM Model with SND format (time_major = true)", "body": "### 1. System information\r\n\r\n- TF Version - 2.4.1\r\n\r\nI am trying to create model with `return_sequences` set to `false` and `time_major` set to `true`.\r\n\r\nUnable to create `TF model` with these parameters. \r\n\r\nCould you tell me what was the mistake in the code, what are the `ytest` and `ytrain` dimensions to create the TF model.\r\n\r\n In this model , Time steps = 5 , Batch Size - 2, No.of features = 20  and LSTM layer has 128 internal units.\r\n\r\n# 2. Code\r\n\r\n\r\n```\r\n`import numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras import layers\r\nmodel = keras.Sequential()\r\nmodel.add(layers.LSTM(input_shape=(None,20),units= 128, time_major=True, return_sequences=False))\r\nmodel.summary()\r\n\r\n\r\nmodel.compile(optimizer='adam',\r\n              loss='sparse_categorical_crossentropy',\r\n              metrics=['accuracy']);\r\n\r\n       \r\nx_test = np.zeros([5,2,20], dtype=np.float32);\r\nx_train = np.zeros([5,2,20], dtype=np.float32);\r\n\r\ny_test =  np.zeros([2,128], dtype=np.float32);\r\ny_train = np.zeros([2,128], dtype=np.float32);\r\n\r\n\r\nmodel.fit(x_train, y_train, epochs=5)\r\nmodel.evaluate(x_test, y_test)\r\n\r\n`\r\n```\r\n\r\n\r\nOnce it is created, could you confirm the steps of conversion to TFLite . Is the below metioned steps correct\r\n\r\n```\r\n`run_model = tf.function(lambda x: model(x))\r\nBATCH_SIZE = 1\r\nSTEPS = 2\r\nINPUT_SIZE = 20\r\nconcrete_func = run_model.get_concrete_function(\r\n    tf.TensorSpec([ STEPS, BATCH_SIZE, INPUT_SIZE], model.inputs[0].dtype))\r\n\r\nmodel directory.\r\nMODEL_DIR = \"keras_lstm_new\"\r\nmodel.save(MODEL_DIR, save_format=\"tf\", signatures=concrete_func)\r\n\r\nconverter = tf.lite.TFLiteConverter.from_saved_model(MODEL_DIR)\r\ntflite_model = converter.convert()\r\n\r\nwith open('lstmmodelnew.tflite', 'wb') as f:\r\n  f.write(tflite_model) `\r\n```", "comments": ["Could you elaborate more on how the above script did not work for you?\r\n\r\nPlease consider using TF 2.5 and the Select TF option. https://www.tensorflow.org/lite/guide/ops_select", "Could you confirm whether this does not work for v2.4.\r\nI used google collab and just run the steps i mentioned,", "@pranathibl,\r\nThere are 2 parts in your question:\r\n\r\n1. Couldn't build the **`Model`** : I've executed [your code](https://colab.research.google.com/gist/rmothukuru/39495f90260130c2543abe1030921406/gh_49502.ipynb) and it is raising errors related to **`Shape`** (**`Cardinality`**). Please file an issue in Stack Overflow, as it is neither a bug nor a feature request.\r\n2. Couldn't convert that model to TF Lite: Once the error in 1 is resolved, Please follow the steps mentioned in the documentation of [Select Tensorflow Operators](https://www.tensorflow.org/lite/guide/ops_select), and let us know if you need help.", "Created issue in stack overflow - https://stackoverflow.com/questions/67857868/unable-to-create-tflite-model-with-time-major-format ", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Any update ?", "@pranathibl,\r\nAs mentioned, we are receiving a different error when tried to execute your code. Please help us reproduce your issue so that we can try to help you. Thanks! ", "I need an example to build TFLite LSTM model with format(SND). Do you have ?", "Any update"]}, {"number": 49493, "title": "Tensor documentation hints at differences in graph and eager mode without providing details", "body": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/Tensor\r\n\r\n## Description of issue (what needs changing):\r\n\r\nCurrently, the description of what a tensor is is cutoff: \"A tensor is a multidimensional array of elements represented by a\"\r\n\r\nAdditionally, there is a comment about \r\n\r\n> \"Note that during eager execution, you may discover your Tensors are actually of type EagerTensor. This is an internal detail, but it does give you access to a useful function, numpy:\"\r\n\r\n This implies that numpy is not available in graph mode. What else isn't available in graph mode? The documentation should describe the differences in capabilities between the two modes - probably on its own page if required.\r\n\r\nIn my case, I found this out when trying to create a custom loss function, only to find that a number of expected capabilities were not available on the tensor object. It took a long time to find this one line description that hints at the differences. Even then, however, I have no idea what I can use in that mode or where to set the mode so that I can access the data of the tensor.\r\n", "comments": ["@lonerzzz,\r\nThe differences might not be specified in the documentation of [tf.tensor](https://www.tensorflow.org/api_docs/python/tf/Tensor).  Please refer the detailed documentation related to [Eager Execution](https://www.tensorflow.org/guide/eager) and the [Graph Execution](https://www.tensorflow.org/guide/intro_to_graphs) to understand the complete functionalities and the differences between them. Hope this helps. Thanks!", "Thanks for the reference but the Eager Execution page is still vague in too many ways and does not cover tensors in sufficient detail. For example, this sentence \"tf.Variable objects store mutable tf.Tensor-like values accessed during training to make automatic differentiation easier.\" exists without indicating any detail on the implications of this.\r\n\r\nHowever, I can see serious implications. For example, when I attempt to access a number of tensor functions  that would be present on a tensor in a custom loss function, none of them are available. Hence, either the tensor documentation or eager execution documentation needs to be expanded to cover this.\r\n\r\nThe mapping from tf.Variable to tf.Tensor and how to access the real tensor capability would be a key point to describe."]}, {"number": 49492, "title": "micro: Port ABS for int8 and int16 from lite to micro", "body": "@tensorflow/micro\r\n\r\n@advaitjain this issue tracks my work in porting int8 and int16 support for the ABS kernel in Micro\r\n\r\nIt will be delivered as one PR containing the porting of the operator and appropriate tests.\r\n\r\n\r\n\r\n", "comments": ["@patriklaurell,\r\nCan you please mention the link of your PR here so that we can understand that it is being taken care? Thanks!", "@rmothukuru I have not yet uploaded the PR. It is not ready yet. I opened the issue to indicate that I am working on it. Should I close it again until the PR is ready? or should I upload a draft PR?", "@patriklaurell,\r\nWe can leave it open and since you are committed to this repository, I have assigned this issue to you. Thanks!"]}, {"number": 49490, "title": "negative sampling in Word2Vec tutorial", "body": "## URL(s) with the issue:\r\n[negative sampling](https://www.tensorflow.org/tutorials/text/word2vec#negative_sampling_for_one_skip-gram)\r\n[generate training data](https://www.tensorflow.org/tutorials/text/word2vec#generate_training_data)\r\n\r\n## Description of issue (what needs changing):\r\nI was going through the tutorial on skipgram word2vec and I noticed that positive sample candidates are also negative sample candidates too.\r\n\r\n### Clear description\r\nFor example, we have `sentence = \"The wide road shimmered in the hot sun\"` and `window_size = 2` for `tf.keras.preprocessing.sequence.skipgrams`. Therefore positive skip-grams for include `(road, the), (road, wide), (road, shimmered), & (road, in)`. \r\n\r\n**I guess `the, wide, shimmered, & in` should not be later labeled as negative skip-grams for `road`, right?**.\r\n\r\nPS: I'm a newbie", "comments": ["@bizzyvinci \r\nThank you for the request, we will update you on the earliest on this.", "The incorrect negative samples are calculated from `tf.random.log_uniform_candidate_sampler`, which may have bugs. See #44758.", "Thank you @bizzyvinci and @gqqnbig. We'll look into this cc @MarkDaoust ", "Please see my comment https://github.com/tensorflow/tensorflow/issues/44758#issuecomment-916554100 . The phrase \"negative samples\" may have different meanings in different candidate-sampling algorithms. For some algorithms \"negative samples\" can overlap with true classes. \r\n\r\nWe do need to mention this caveat in the tutorial though. "]}, {"number": 49484, "title": "How could I get the correct middle layer output of TFLite quantized models", "body": "### 1. System information\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\n- TensorFlow library (version, if pip package or github SHA, if built from source): 2.6.0-dev20210512\r\n\r\n### 2. Question\r\n\r\nMay I know how could I get the correct middle layer output of TFLite quantized models? I got an answer from https://github.com/tensorflow/tensorflow/issues/49129\r\n\r\nI did something like:\r\ninterpreter = tf.lite.Interpreter(model_path=str(tflite_file), experimental_preserve_all_tensors=True)\r\nlayer_output = interpreter.get_tensor(layer_index)\r\n\r\nI tried the same input and for both quantized and normal TFLite model. I think the middle layers result for normal TFLite model is correct but not for the quantized model. \r\nIs that feature not support TFLite quantized model? \r\n\r\nAlso, since this feature is not supported in 2.4.1 version, what will the interpreter.get_tensor(layer_index) return? Is is just some random number?", "comments": ["@fredrec could you triage this issue?"]}, {"number": 49482, "title": " How to convert TFLite quantization model back to normal TFLite model?", "body": "### 1. System information\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\n- TensorFlow library (version, if pip package or github SHA, if built from source): 2.4.1\r\n\r\n### 2. Question\r\n\r\nHow to convert TFLite quantization model back to normal TFLite model?\r\n\r\nThe models I compared are from https://www.tensorflow.org/lite/guide/hosted_models\r\n1. https://storage.googleapis.com/download.tensorflow.org/models/mobilenet_v1_2018_02_22/mobilenet_v1_0.75_224.tgz\r\n2. https://storage.googleapis.com/download.tensorflow.org/models/mobilenet_v1_2018_08_02/mobilenet_v1_0.75_224_quant.tgz\r\n\r\nI tried to converted the second quantized model back to float model based on the quantization info from interpreter.get_tensor_details(). \r\n\r\nIssue 1:\r\nThe weight/bias info after converted back to float is totally different from those info from the normal tflite model. This is explained in this question that quantized model and normal models are from different training. https://github.com/tensorflow/tensorflow/issues/49119\r\n\r\nIssue 2:\r\nIf I just converted quantized model back to normal model, the model will lack the activation function after each CONV node (RELU6 in this model), which could result in unconstrained range for output after each layer. At the end, the layer result could be extremely big or small (negative).\r\nTherefore I add a 0-6 clip node after each CONV layer to eliminate extreme number. However, the final inference result is still away from the result of normal TFLite model.\r\n\r\nIs there anything I did wrong?\r\nAny suggestion to converted back quantized model to normal TFLite model? \r\n \r\n", "comments": ["We don't have such feature yet. We consider this as a feature request. Thanks"]}, {"number": 49469, "title": "tf.range not works with fixed input parameter on TPU", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): colab \r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): colab\r\n- TensorFlow version (use command below): 2.4.1\r\n- Python version: colab\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\nv2.4.1-0-g85c8b2a817f 2.4.1\r\n\r\n**Describe the current behavior**\r\n`tf.range` function cannot compiled on TPU or xla compile option with fixed input value.\r\n\r\n[The Cloud TPU reference](https://cloud.google.com/tpu/docs/tensorflow-ops) says `tf.range` is available python api with compile-time constant. However, It cannot compiled on TPU using below code sample. You can know the parameter of `tf.range` is constant by printed value and I tried and failed compile using constant number as the argument of `tf.range` directly. It works if I changed `tf.range` to `range`.\r\n\r\n**Describe the expected behavior**\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)** - Do you\r\nwant to contribute a PR? (yes/no): no.. I don't know xla...\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n```python\r\nimport tensorflow as tf\r\n\r\nresolver = tf.distribute.cluster_resolver.TPUClusterResolver()\r\ntf.config.experimental_connect_to_cluster(resolver)\r\ntf.tpu.experimental.initialize_tpu_system(resolver)\r\nstrategy = tf.distribute.TPUStrategy(resolver)\r\n\r\nclass TestModel(tf.keras.Model):\r\n  def __init__(self):\r\n    super().__init__()\r\n\r\n    self.embed = tf.keras.layers.Embedding(vocab_size, 32)\r\n    self.dense = tf.keras.layers.Dense(vocab_size)\r\n\r\n  def call(self, input, training=None):\r\n    embedding = self.embed(input)\r\n    token_length = embedding.shape[1]\r\n    print(\"Token Length:\", token_length)\r\n    outputs = tf.TensorArray(tf.float32, token_length)\r\n\r\n    for i in tf.range(token_length):\r\n    # for i in range(token_length):\r\n      output = self.dense(embedding[:, i, :])\r\n      outputs = outputs.write(i, output)\r\n    \r\n    return tf.transpose(outputs.stack(), [1,0,2])\r\n\r\nwith strategy.scope():\r\n  vocab_size = 1000\r\n  batch_size = 32\r\n  sequence_length = 32\r\n\r\n  model = TestModel()\r\n  model.compile('adam', tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))\r\n  model(tf.keras.Input([sequence_length - 1]))\r\n\r\n  dataset = tf.data.Dataset.from_tensor_slices(tf.random.uniform([10000, sequence_length], 0, vocab_size, dtype=tf.int32)).map(lambda x: (x[:-1], x[1:]))\r\n  dataset = dataset.batch(batch_size)\r\n\r\n  model.fit(dataset)\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\nError logs\r\n```\r\nInvalidArgumentError: 9 root error(s) found.\r\n  (0) Invalid argument: {{function_node __inference_train_function_161299}} Compilation failure: The number of output elements 128 has to equal to number of input elements that are sliced 1 when input indices are not constant.\r\n\t [[{{node test_model_26/while/strided_slice}}]]\r\n\t [[test_model_26/while]]\r\n\tTPU compilation failed\r\n\t [[tpu_compile_succeeded_assert/_1260395280479028058/_5]]\r\n\t [[tpu_compile_succeeded_assert/_1260395280479028058/_5/_197]]\r\n  (1) Invalid argument: {{function_node __inference_train_function_161299}} Compilation failure: The number of output elements 128 has to equal to number of input elements that are sliced 1 when input indices are not constant.\r\n\t [[{{node test_model_26/while/strided_slice}}]]\r\n\t [[test_model_26/while]]\r\n\tTPU compilation failed\r\n\t [[tpu_compile_succeeded_assert/_1260395280479028058/_5]]\r\n\t [[tpu_compile_succeeded_assert/_1260395280479028058/_5/_221]]\r\n  (2) Invalid argument: {{function_node __inference_train_function_161299}} Compilation failure: The number of output elements 128 has to equal to number of input elements that are sliced 1 when input indices are not constant.\r\n\t [[{{node test_model_26/while/strided_slice}}]]\r\n\t [[test_model_26/while]]\r\n\tTPU compilation failed\r\n\t [[tpu_compile_succeeded_assert/_1260395280479028058/_5]]\r\n\t [[tpu_compile_succeeded_assert/_1260395280479028058/_5/_209]]\r\n  (3) Invalid argument: {{function_node __inference_train_function_161299}} Compilation failure: The number of output elements 128 has to equal to number of input elements that are sliced 1 when input indices are not constant.\r\n\t [[{{node test_model_26/while/strided_slice}}]]\r\n\t [[test_model_26/while]]\r\n\tTPU compilation failed\r\n\t [[tpu_compile_succeeded_assert/_1260395280479028058/_5]]\r\n\t [[tpu_compile_succeeded_assert/_1260395280479028058/_5/_185]]\r\n```", "comments": ["@cosmoquester ,\r\n\r\nPlease feel free to close the issue once PR is merged.\r\n\r\nThanks!", "@tilakrayal Umm... Actually the PR is about my model training repository. I changed my model code to use python range on TPU. I mention this issue for my repository because of knowing why I wrote code like that. I'm sorry for the misunderstanding.", "@cosmoquester ,\r\n\r\nOn running the given code snippet, I am facing different errors in v2.5,v2.4 and nightly. Please find the gist of it [here](https://colab.research.google.com/gist/tilakrayal/f22b3d09ed4db3428f0401ac0e0a8943/un49469.ipynb).", "I have run your gist. The all three of versions puts same error of `UnavailableError: Socket closed` on my execution. When I re-run my example code attached also, puts `UnavailableError: Socket closed`. So I don't know why, but the error seems to be changed.", "Yunxing, can you help to take a look? Thanks!", "This is already fixed on internal head a few months ago. Updating TF version should fix the issue. ", "Thanks Yunxing. @cosmoquester can you try it in tf-nightly? ", "I tested with tf-nightly and it fails with same error `UnavailableError: Socket closed`\r\nSee [gist](https://colab.research.google.com/gist/ymodak/fb11c1b9466d3f92842c4fe8a52d83b1/un49469.ipynb)", "I also got `UnavailableError: Socket closed` now", "Something seems broken internally ( I suspect some runtime value) and the error is masked out for confidentiality reasons. It'd be good if someone can port the example to internal codebase then we can resume debugging there. ", "I found out one more thing.\r\n\r\n```python\r\nclass TestModel(tf.keras.Model):\r\n  def __init__(self):\r\n    super().__init__()\r\n\r\n    self.embed = tf.keras.layers.Embedding(vocab_size, 32)\r\n    self.dense = tf.keras.layers.Dense(vocab_size)\r\n    self.dense2 = tf.keras.layers.Dense(vocab_size)\r\n\r\n  def call(self, input, training=None):\r\n    embedding = self.embed(input)\r\n    token_length = embedding.shape[1]\r\n    print(\"Token Length:\", token_length)\r\n\r\n    output = self.dense(tf.reduce_mean(embedding, axis=1))\r\n    for i in tf.range(token_length):\r\n      output = self.dense2(output)\r\n    \r\n    return tf.repeat(output[:, tf.newaxis, :], token_length, 1)\r\n```\r\n When I changed model not to use `tf.TensorArray` like upper example, It works even without tf-nightly version.\r\n\r\n```python\r\nclass TestModel(tf.keras.Model):\r\n  def __init__(self):\r\n    super().__init__()\r\n\r\n    self.embed = tf.keras.layers.Embedding(vocab_size, 32)\r\n    self.dense = tf.keras.layers.Dense(vocab_size)\r\n\r\n  def call(self, input, training=None):\r\n    embedding = self.embed(input)\r\n    token_length = embedding.shape[1]\r\n    print(\"Token Length:\", token_length)\r\n\r\n    def cond(i, outputs):\r\n      return i < token_length\r\n\r\n    def body(i, outputs):\r\n      output = self.dense(embedding[:, i, :])\r\n      outputs = outputs.write(i, output)\r\n      i += 1\r\n      return i, outputs\r\n\r\n    i = 0\r\n    outputs = tf.TensorArray(tf.float32, token_length)\r\n    i, outputs = tf.while_loop(cond, body, [i, outputs], maximum_iterations=token_length)\r\n    \r\n    return tf.transpose(outputs.stack(), [1,0,2])\r\n```\r\nAlso, I tested changing `tf.range` to `tf.while` with `tf.TensorArray`.\r\nI got same error.\r\n```\r\nUnavailableError                          Traceback (most recent call last)\r\n<ipython-input-20-d28793719248> in <module>()\r\n----> 1 model.fit(dataset)\r\n\r\n13 frames\r\n/usr/local/lib/python3.7/dist-packages/six.py in raise_from(value, from_value)\r\n\r\nUnavailableError: Socket closed\r\n```\r\nSo maybe I think this issue occurred when using `tf.while` with `tf.TensorArray`.", "```python\r\nimport tensorflow as tf\r\n\r\nresolver = tf.distribute.cluster_resolver.TPUClusterResolver()\r\ntf.config.experimental_connect_to_cluster(resolver)\r\ntf.tpu.experimental.initialize_tpu_system(resolver)\r\nstrategy = tf.distribute.TPUStrategy(resolver)\r\n\r\nclass TestModel(tf.keras.Model):\r\n  def __init__(self):\r\n    super().__init__()\r\n\r\n    self.embed = tf.keras.layers.Embedding(vocab_size, 32)\r\n    self.dense = tf.keras.layers.Dense(vocab_size)\r\n\r\n  @tf.function\r\n  def train_step(self, inputs):\r\n    input, target = inputs\r\n\r\n    token_length = input.shape[1]\r\n    print(\"Token Length:\", token_length)\r\n\r\n    total_loss = 0.0\r\n    with tf.GradientTape() as tape:\r\n      embedding = self.embed(input)\r\n\r\n      for i in tf.range(token_length):\r\n        output = self.dense(embedding[:, i, :])\r\n        total_loss += self.compiled_loss(target[:, i], output)\r\n  \r\n    variables = self.trainable_variables \r\n    gradients = tape.gradient(total_loss, variables)\r\n    self.optimizer.apply_gradients(zip(gradients, variables))\r\n\r\n    return {\"loss\":total_loss}\r\n    \r\n\r\nwith strategy.scope():\r\n  vocab_size = 1000\r\n  batch_size = 32\r\n  sequence_length = 32\r\n\r\n  model = TestModel()\r\n  model.compile('adam', tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))\r\n\r\n  dataset = tf.data.Dataset.from_tensor_slices(tf.random.uniform([10000, sequence_length], 0, vocab_size, dtype=tf.int32)).map(lambda x: (x[:-1], x[1:]))\r\n  dataset = dataset.batch(batch_size)\r\n\r\n  model.fit(dataset)\r\n```\r\nI found one more. I got error even without `tf.TensorArray` when I tried to train without `Model.call` with `train_step`.\r\n```\r\nToken Length: 31\r\nToken Length: 31\r\n---------------------------------------------------------------------------\r\nUnavailableError                          Traceback (most recent call last)\r\n<ipython-input-1-e4445f47fcd7> in <module>()\r\n     46   dataset = dataset.batch(batch_size)\r\n     47 \r\n---> 48   model.fit(dataset)\r\n\r\n13 frames\r\n/usr/local/lib/python3.7/dist-packages/six.py in raise_from(value, from_value)\r\n\r\nUnavailableError: Socket closed\r\n```"]}, {"number": 49456, "title": "tf.io.serialize_tensor/parse_tensor: ValueError: as_list() is not defined on an unknown TensorShape in model training", "body": "\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nyes\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nSystems are: Ubuntu 20.04.2 LTS; Google Colab\r\n\r\n- TensorFlow installed from (source or binary):\r\nInstalled from conda (Ubuntu), preinstalled (Colab)\r\n\r\n- TensorFlow version (use command below):\r\nTensorflow v2.4.1\r\n\r\n- Python version:\r\nPython 3.8.5 (Ubuntu), Python 3.7.10(Colab)\r\n\r\n**Describe the current behavior**\r\n\r\nTraining a simple toy model on a custom iris TFRecords dataset throws the following error:\r\n`ValueError: as_list() is not defined on an unknown TensorShape.`\r\n\r\nThe custom TFRecord dataset was created by serializing/deserializing the numpy arrays with `tf.io.serialize_tensor/tf.io.parse_tensor` to save/recover the original shapes. Afterwards the tensors were written to TFRecords following the official [Tutorial](https://www.tensorflow.org/tutorials/load_data/tfrecord). Reading and parsing the data seemed to work properly, as the original data was recovered (inspection by eye/shape), but  trying to feed the dataset to `model.fit()` did result in the described error.\r\n\r\n**Describe the expected behavior**\r\n\r\nExpected behavior would be successful training/evaluation, as training with custom records from serialized numpy arrays (`numpy.tobytes()`) and deserialization by tf.io.decode_raw() and subsequent recovery of array shape was possible.\r\n\r\n\r\n**Standalone code to reproduce the issue**\r\nI saved the notebook to a [gist](https://gist.github.com/sroener/e9ca6b870647dcdac3ea8df79fcae9c0) after running it in Colab.\r\nIt contains 3 main sections:\r\n1) train model on raw numpy arrays (sanity check of toy model)\r\n2) train model on TFRecrods created from said data, serialized by numpy.tobytes() and reconstructed afterwards (works, model training from TFRecord dataset possible)\r\n3) train model on TFrecords created from same data, serialized by tf.io.serialize/parse_tensor. (throws error)\r\n\r\n**Other info / logs** \r\n\r\nFull traceback:\r\n\r\n\r\n> Epoch 1/150\r\n> ---------------------------------------------------------------------------\r\n> ValueError                                Traceback (most recent call last)\r\n> <ipython-input-22-4aa7a265b40e> in <module>()\r\n>       7 model_tensor.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\r\n>       8 # fit the model\r\n> ----> 9 history_tensor = model_tensor.fit(parsed_train_dataset_tensor, epochs=150, batch_size=32, verbose=2)\r\n>      10 \r\n>      11 loss, acc = model.evaluate(parsed_test_dataset_tensor, verbose=0)\r\n> \r\n> /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\r\n>    1098                 _r=1):\r\n>    1099               callbacks.on_train_batch_begin(step)\r\n> -> 1100               tmp_logs = self.train_function(iterator)\r\n>    1101               if data_handler.should_sync:\r\n>    1102                 context.async_wait()\r\n> \r\n> /usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)\r\n>     826     tracing_count = self.experimental_get_tracing_count()\r\n>     827     with trace.Trace(self._name) as tm:\r\n> --> 828       result = self._call(*args, **kwds)\r\n>     829       compiler = \"xla\" if self._experimental_compile else \"nonXla\"\r\n>     830       new_tracing_count = self.experimental_get_tracing_count()\r\n> \r\n> /usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)\r\n>     869       # This is the first call of __call__, so we have to initialize.\r\n>     870       initializers = []\r\n> --> 871       self._initialize(args, kwds, add_initializers_to=initializers)\r\n>     872     finally:\r\n>     873       # At this point we know that the initialization is complete (or less\r\n> \r\n> /usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py in _initialize(self, args, kwds, add_initializers_to)\r\n>     724     self._concrete_stateful_fn = (\r\n>     725         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\r\n> --> 726             *args, **kwds))\r\n>     727 \r\n>     728     def invalid_creator_scope(*unused_args, **unused_kwds):\r\n> \r\n> /usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)\r\n>    2967       args, kwargs = None, None\r\n>    2968     with self._lock:\r\n> -> 2969       graph_function, _ = self._maybe_define_function(args, kwargs)\r\n>    2970     return graph_function\r\n>    2971 \r\n> \r\n> /usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py in _maybe_define_function(self, args, kwargs)\r\n>    3359 \r\n>    3360           self._function_cache.missed.add(call_context_key)\r\n> -> 3361           graph_function = self._create_graph_function(args, kwargs)\r\n>    3362           self._function_cache.primary[cache_key] = graph_function\r\n>    3363 \r\n> \r\n> /usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)\r\n>    3204             arg_names=arg_names,\r\n>    3205             override_flat_arg_shapes=override_flat_arg_shapes,\r\n> -> 3206             capture_by_value=self._capture_by_value),\r\n>    3207         self._function_attributes,\r\n>    3208         function_spec=self.function_spec,\r\n> \r\n> /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\r\n>     988         _, original_func = tf_decorator.unwrap(python_func)\r\n>     989 \r\n> --> 990       func_outputs = python_func(*func_args, **func_kwargs)\r\n>     991 \r\n>     992       # invariant: `func_outputs` contains only Tensors, CompositeTensors,\r\n> \r\n> /usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py in wrapped_fn(*args, **kwds)\r\n>     632             xla_context.Exit()\r\n>     633         else:\r\n> --> 634           out = weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n>     635         return out\r\n>     636 \r\n> \r\n> /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)\r\n>     975           except Exception as e:  # pylint:disable=broad-except\r\n>     976             if hasattr(e, \"ag_error_metadata\"):\r\n> --> 977               raise e.ag_error_metadata.to_exception(e)\r\n>     978             else:\r\n>     979               raise\r\n> \r\n> ValueError: in user code:\r\n> \r\n>     /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\r\n>         return step_function(self, iterator)\r\n>     /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\r\n>         outputs = model.distribute_strategy.run(run_step, args=(data,))\r\n>     /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\r\n>         return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\r\n>     /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\r\n>         return self._call_for_each_replica(fn, args, kwargs)\r\n>     /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\r\n>         return fn(*args, **kwargs)\r\n>     /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\r\n>         outputs = model.train_step(data)\r\n>     /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:758 train_step\r\n>         self.compiled_metrics.update_state(y, y_pred, sample_weight)\r\n>     /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/compile_utils.py:387 update_state\r\n>         self.build(y_pred, y_true)\r\n>     /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/compile_utils.py:318 build\r\n>         self._metrics, y_true, y_pred)\r\n>     /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py:1163 map_structure_up_to\r\n>         **kwargs)\r\n>     /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py:1258 map_structure_with_tuple_paths_up_to\r\n>         func(*args, **kwargs) for args in zip(flat_path_gen, *flat_value_gen)\r\n>     /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py:1258 <listcomp>\r\n>         func(*args, **kwargs) for args in zip(flat_path_gen, *flat_value_gen)\r\n>     /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py:1161 <lambda>\r\n>         lambda _, *values: func(*values),  # Discards the path arg.\r\n>     /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/compile_utils.py:418 _get_metric_objects\r\n>         return [self._get_metric_object(m, y_t, y_p) for m in metrics]\r\n>     /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/compile_utils.py:418 <listcomp>\r\n>         return [self._get_metric_object(m, y_t, y_p) for m in metrics]\r\n>     /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/compile_utils.py:439 _get_metric_object\r\n>         y_t_rank = len(y_t.shape.as_list())\r\n>     /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_shape.py:1190 as_list\r\n>         raise ValueError(\"as_list() is not defined on an unknown TensorShape.\")\r\n> \r\n>     ValueError: as_list() is not defined on an unknown TensorShape.", "comments": ["@sroener ,\r\n\r\nPlease take a look at this [link](https://stackoverflow.com/questions/58933151/as-list-is-not-defined-on-an-unknown-tensorshape) with similar error log.It helps.\r\n\r\nThanks", "@tilakrayal\r\n\r\nCan you please explain why this is not a bug? As far as I understand, the official Tutorial points users towards tf.io.serialize_tensor/parse tensor as the go to methods to prepare/parse non-scalar data for/from TFRecords. If these functions don't work as expected (triggering errors), I would categorize this as a bug.\r\n\r\nEven if these methods work as intended, I think it would still be worth an investigation why the .fit() method seems not be able to handle data prepared in this way.\r\n\r\nThe accepted answer in the shared [link](https://stackoverflow.com/a/58934046) is exactly how I solved the problem (tf.io.decode_raw + tf.reshape), but it is still just a workaround.\r\n\r\nThanks", "@rmothukuru,\r\n\r\nI was able to reproduce the issue in TF [v2.4](https://colab.research.google.com/gist/tilakrayal/f9d047fd2178299c3377dffc98c49e13/49456-2-4.ipynb),[v2.5](https://colab.research.google.com/gist/tilakrayal/cdcd49255b0a04716a188c1722a0aa16/tfrecord_parse_tensor_problem2-5.ipynb) and [nightly](https://colab.research.google.com/gist/tilakrayal/198289bf9ad06b2d61a772231817cf1c/tfrecord_parse_tensor_problem-nightly.ipynb).Please find the gist.", "@sroener,\r\nWith respect to your statement, \r\n\r\n> the official Tutorial points users towards tf.io.serialize_tensor/parse tensor as the go to methods to prepare/parse non-scalar data for/from TFRecords. \r\n\r\ncan you please provide the **`reference link of the Tutorial`** that point towards `tf.io.serialize_tensor/parse tensor` so that we can rectify it? Thanks!", "@rmothukuru\r\n\r\nThanks for the reply.\r\n\r\nSure, the [link](https://www.tensorflow.org/tutorials/load_data/tfrecord#tftrainexample) to the tutorial was mentioned in my original post. The Tutorial points to `tf.io.serialize_tensor/parse_tensor` in the note directly below the three list types that are supported by `tf.train.feature`.\r\n\r\n> Note: To stay simple, this example only uses scalar inputs. The simplest way to handle non-scalar features is to use tf.io.serialize_tensor to convert tensors to binary-strings. Strings are scalars in tensorflow. Use tf.io.parse_tensor to convert the binary-string back to a tensor.\r\n", "@qlzh727\r\n\r\nHi, any news on this issue? ", "Hey,\r\n\r\nI just checked the colab notebook for the nightly build. This is still a problem and the documentation still recommends this way of converting non-scalar data.\r\n\r\nAre you planning to do anything about this in the near future?\r\n\r\n"]}, {"number": 49378, "title": "switch_case returns wrong dataset in graph mode", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.5.0\r\n- Python version: 3.6.9\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\n**Describe the expected behavior**\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)** - Do you\r\nwant to contribute a PR? (yes/no): - Briefly describe your candidate solution\r\n(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n```python\r\nimport tensorflow as tf\r\nd1 = tf.data.Dataset.from_tensor_slices([tf.ones((2,2))]*2)\r\nd2 = tf.data.Dataset.from_tensor_slices([tf.ones((4,4))]*2)\r\nv = tf.Variable(0, dtype=tf.int32)\r\nf = tf.function(lambda:tf.switch_case(v.read_value(), {0:(lambda:d1), 1:(lambda:d2)}))\r\nprint(f()) # shape is (2,2)\r\nv.assign_add(1)\r\nprint(f()) # shape also is (2,2), which is wrong and it should be (4,4)\r\n```\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["\r\n```\r\n<_VariantDataset shapes: (2, 2), types: tf.float32>\r\n\r\nWARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7fcb90d723b0> and will run it as-is.\r\nCause: could not parse the source code of <function <lambda> at 0x7fcb90d723b0>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names.\r\nMatch 0:\r\n(lambda : tf.switch_case(v.read_value(), {0: (lambda : d1), 1: (lambda : d2)}))\r\n\r\nMatch 1:\r\n(lambda : d1)\r\n\r\nMatch 2:\r\n(lambda : d2)\r\n\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING: AutoGraph could not transform <function <lambda> at 0x7fcb90d723b0> and will run it as-is.\r\nCause: could not parse the source code of <function <lambda> at 0x7fcb90d723b0>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names.\r\nMatch 0:\r\n(lambda : tf.switch_case(v.read_value(), {0: (lambda : d1), 1: (lambda : d2)}))\r\n\r\nMatch 1:\r\n(lambda : d1)\r\n\r\nMatch 2:\r\n(lambda : d2)\r\n\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\n<_VariantDataset shapes: (2, 2), types: tf.float32>\r\n<_VariantDataset shapes: (2, 2), types: tf.float32>\r\n```\r\n\r\nOn running the provided test case, following output is produced.  Could this be a issue due to the lambda function. Also I think the switch statement is processing 3 cases due to multiple lambda. Would love to contribute on my first issue.\r\n", "I was able to reproduce the issue in TF v2.4,v2.5 and nightly.Please find the [gist](https://colab.research.google.com/gist/tilakrayal/bb9d8bafa03f798d273732d9a895eed7/49378.ipynb) here", "I rewrote the code a little bit to avoid the autograph warnings:\r\n\r\n```\r\nimport tensorflow as tf\r\nd1 = tf.data.Dataset.from_tensor_slices([tf.ones((2,2))]*2)\r\nd2 = tf.data.Dataset.from_tensor_slices([tf.ones((4,4))]*2)\r\nv = tf.Variable(0, dtype=tf.int32)\r\nlam_d1 = lambda: d1\r\nlam_d2 = lambda: d2\r\nf = tf.function(lambda:tf.switch_case(v.read_value(), {0:lam_d1, 1:lam_d2}))\r\nprint(f()) # shape is (2,2)\r\nv.assign_add(1)\r\nprint(f()) # shape also is (2,2), which is wrong and it should be (4,4)\r\n```\r\n\r\nThis appears to be a bug in the shape inference, because attempting to consume the dataset raises a shape error, which means that the correct dataset is indeed being returned, but its shape is incorrect:\r\n\r\n```\r\nimport tensorflow as tf\r\nd1 = tf.data.Dataset.from_tensor_slices([tf.ones((2,2))]*2)\r\nd2 = tf.data.Dataset.from_tensor_slices([tf.ones((4,4))]*2)\r\nv = tf.Variable(0, dtype=tf.int32)\r\nlam_d1 = lambda: d1\r\nlam_d2 = lambda: d2\r\nf = tf.function(lambda:next(iter(tf.switch_case(v.read_value(), {0:lam_d1, 1:lam_d2}))))\r\nprint(f())  # prints a 2x2 tensor\r\nv.assign_add(1)\r\nprint(f())  # errors out\r\n```\r\n\r\n```\r\n...\r\nInvalidArgumentError: {{function_node __inference_<lambda>_421}} Incompatible shapes at component 0: expected [2,2] but got [4,4].\r\n\t [[{{node MakeIterator}}]] [Op:__inference_<lambda>_421]\r\n```", "No, it never returns d2 in graph mode.\r\n```python\r\nimport tensorflow as tf\r\ntf.compat.v1.disable_eager_execution()\r\nwith tf.compat.v1.Session() as sess:\r\n    d1 = tf.data.Dataset.from_tensor_slices([tf.ones((2,2))]*2)\r\n    d2 = tf.data.Dataset.from_tensor_slices([tf.ones((4,4))]*2)\r\n    v = tf.Variable(0, dtype=tf.int32)\r\n    ds = tf.switch_case(v.read_value(), {0:(lambda:d1), 1:(lambda:d2)})\r\n    iterator = tf.compat.v1.data.make_initializable_iterator(ds)\r\n    sess.run(tf.compat.v1.global_variables_initializer())\r\n    sess.run(iterator.initializer)\r\n    item = iterator.get_next()\r\n    print(sess.run(item)) # shape is (2,2)\r\n    sess.run(v.assign_add(1))\r\n    print(sess.run(item))\r\n```"]}, {"number": 49373, "title": "Extremely slow data processing of tensorflow dataset using when using tf.while_loop inside a tf.function or normal function", "body": "**System information:**\r\nTried the code on both - Kaggle and Colab (Both only CPU)\r\n\r\n**Code:**\r\nI am trying to process a dataset containing ~20,000 images, their feature vectors and their masks(image segmentation). Due to the size of data, I can't perform in-memory processing.\r\n\r\nI load the data using this function:\r\n\r\n```\r\n@tf.function\r\ndef get_mask_cum_featvecs_dataset(files_paths):\r\n  paths_ds = tf.data.Dataset.list_files(files_paths)\r\n  ds = paths_ds.interleave(lambda tfrec_path: tf.data.TFRecordDataset(tfrec_path).map(\r\n                                  read_tfrec, num_parallel_calls=AUTO),\r\n                               num_parallel_calls=AUTO)\r\n  return ds\r\n```\r\nThe preprocessing includes getting the euclidean distances between all the images present in the dataset and an input image (fed by the user), and then dividing all the euclidean distances by the max euclidean distance out of all euclidean distances present. For this I use the below given functions:\r\n```\r\n@tf.function\r\ndef euclidean_dist(comp_img_features, img_featvec):\r\n    euclidean_dist = tf.sqrt(tf.reduce_sum(tf.square(img_featvec-comp_img_features), 0))\r\n    return euclidean_dist\r\n\r\n@tf.function\r\ndef preprocess(img_featvec, img_mask, mask_cum_featvecs_paths):\r\n   \r\n    tensor_img_featvec = img_featvec\r\n    tensor_img_mask = img_mask\r\n    tensor_mask_cum_featvecs_paths = mask_cum_featvecs_paths\r\n    \r\n    # the below given statements are used when this function\r\n    # is not wrapped by tf.function decorator:\r\n    #tensor_img_featvec = tf.constant(img_featvec)\r\n    #tensor_img_mask = tf.constant(img_mask)\r\n    #tensor_mask_cum_featvecs_paths = tf.constant(mask_cum_featvecs_paths)\r\n    \r\n    compare_img_ds = get_mask_cum_featvecs_dataset(tensor_mask_cum_featvecs_paths)\r\n    \r\n    get_img_euclidean_dists = partial(euclidean_dist, img_featvec=tensor_img_featvec)\r\n    \r\n    print(\"Calculating Euclidean Distances......\")\r\n    features_n_eucl_ds = compare_img_ds.map(lambda image_name, image, featvec, mask: (image_name, image, featvec, mask,\r\n                                                                           get_img_euclidean_dists(featvec)),\r\n                                 num_parallel_calls=AUTO)\r\n\r\n\r\n    print(\"Finding Maximum Euclidean Distance........\")\r\n    num_of_loops = 2\r\n    eucl_val_ds = features_n_eucl_ds.map(lambda image_name, image, featvec, mask, eucl_val: eucl_val,\r\n                                         num_parallel_calls=AUTO)\r\n   \r\n    def dataset_reduce_max(ds, i):\r\n        ds = ds.batch(5000)\r\n        ds = ds.map(lambda eucl_vals: tf.math.reduce_max(eucl_vals),\r\n                    num_parallel_calls=AUTO)\r\n        i += 1\r\n        return ds, i\r\n    \r\n    def loop_cond(ds, i):\r\n        return tf.less(i, num_of_loops)\r\n    \r\n    eucl_val_ds, _ = tf.while_loop(loop_cond,\r\n                                   dataset_reduce_max,\r\n                                   [eucl_val_ds, tf.constant(0)])\r\n    \r\n    max_eucl_dist = tf.constant(0, dtype=tf.float32)\r\n\r\n    #---------(I)---------#\r\n    for item in eucl_val_ds.take(1):\r\n        max_eucl_dist = item\r\n\r\n    ratio_eucl_ds = features_n_eucl_ds.map(\r\n                        lambda image_name, image, featvec, mask, eucl_val: (image_name,\r\n                                                                            image,\r\n                                                                            featvec,                                                                                             \r\n                                                                            mask,                                                                                            \r\n                                                                            eucl_val/max_eucl_dist),\r\n                                           num_parallel_calls=AUTO)\r\n\r\n\r\n    return ratio_eucl_ds #----------(II)-----------#\r\n\r\n```\r\nThere is no in-built function for finding the maximum element in a particular datastream in tensorflow dataset (here, datastreams = image_names, image, featvecs, masks, eucl_dists) To find the maximum the euclidean distance, I created a separate tf.dataset containing euclidean distances and I used dataset reduction strategy. I created batches of size 5000, and return the maximum element present in them. Using this strategy, I can effectively get the maximum euclidean distance in 2 iterations.\r\n\r\n**The problem:**\r\nWhen I use tf.function decorator then the entire function will execute very fast and then get stuck at \"return ratio_eucl_ds\"(I). If I don't use the tf.function decorator then the function gets stuck at for-loop(II). It takes ~12 mins to execute the code. When I randomly put any value in \"max_eucl_dist\", then the preprocess function executes seamlessly. Hence, I guess the problem is with the way I am trying to extract the value for \"max_eucl_dist\".\r\n\r\nColab Link for reproducing the issue:\r\nhttps://colab.research.google.com/drive/1VFEDdfImcchMYNgA68Bi989EGiHiQ2rC?usp=sharing\r\nThe notebook also contains model building code (required to get the feature vector and mask of the input image) and also two data processing functions, a tf.function decorated function and other not decorated.\r\n\r\n**Current Behaviour:**\r\nNot using tf.function decorator - \r\n```\r\nCPU times: user 9min 35s, sys: 16min 2s, total: 25min 37s\r\nWall time: 13min 15s\r\n```\r\nUsing tf.function decorator - \r\n```\r\nCPU times: user 6min 28s, sys: 7min 42s, total: 14min 11s\r\nWall time: 9min 26s\r\n```\r\n\r\nBut, when I randomly or manually initialize the \"max_eucl_dist\", then the processing the works seamlessly.\r\nNot using tf.function decorator - \r\n```\r\nCPU times: user 1.33 s, sys: 1.83 ms, total: 1.34 s\r\nWall time: 6.36 s\r\n```\r\nUsing tf.function decorator -\r\n```\r\nCPU times: user 1.24 s, sys: 22 ms, total: 1.27 s\r\nWall time: 6.16 s\r\n```\r\n", "comments": ["@prikmm \r\nIn the colab gist shared can you please use Runtime>Change Runtime>gpu and let us know if it helps.", "@Saduf2019 \r\nTried running with GPU, but encountered issue #34112, solved the error using the method provided in issue #34519. I had to remove the tf.function qualifier from both \"_get_mask_cum_featvecs_dataset_\" and \"_preprocess_\" functions:\r\n```\r\ndef get_mask_cum_featvecs_dataset(files_paths):\r\n  .\r\n  .\r\n  .\r\n  return ds\r\n\r\ndef preprocess(img_featvec, img_mask, mask_cum_featvecs_paths):\r\n  .\r\n  .\r\n  .\r\n  return ds\r\n```\r\n\r\nBut, like the issues #34112 and #34519 state, the dataset is a Variant type, which is placed on CPU. I guess, since the dataset is present on CPU and is not allowed to be copied to GPU, even if the GPU is connected it is not being used. All the processing is being done on CPU.\r\nBtw, since the processing only needed 2 iterations, I tried by removing the loop and hardcoding the lines. But, still there was no improvement.", "I am confused that why you use `tf.function` when you build dataset pipelines? I think `tf.function` is not designed for this situation.", "Hey @luozhouyang \r\nAt first, I didn't, but then for each image input, I had to wait too long to get the results, It was extremely frustating:grimacing:, and to get even a sight improvement if possible , I though that since, I am using `tf.while_loop` I should try to use the `tf.function` qualifier. But, it turns out I was wrong. Irrespective of the methods, the processing takes too much of time. I would like to know the why this is happening and if there is also a possible work around?  ", "Hey @rmothukuru,\r\nCan I get an update on this issue? any work around of sort.  "]}, {"number": 49306, "title": "-DCMAKE_INSTALL_PREFIX has no effect when building with CMAKE", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution = Linux Ubuntu 20.04:\r\n- TensorFlow installed from (source or binary): CMake efficient binary generation\r\n- TensorFlow version: latest\r\n- Python version: python 3.8\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source): n/a\r\n- GCC/Compiler version (if compiling from source): 9.3.0\r\n- CUDA/cuDNN version: 11.2\r\n- GPU model and memory: Quadro RTX 4000 - 8GB\r\n\r\n\r\n\r\nWhen following the instructions to build Tensorflow Lite as a cmake package with libraries and header files, it does not install anything to the install prefix. I followed the instructions here:\r\n\r\nhttps://www.tensorflow.org/lite/guide/build_cmake \r\n\r\n\r\nIs there a command I am missing. After successful configuration and build, I try to run:\r\n\r\n```\r\ncmake --install . \r\n\r\n```\r\n\r\nAll that happens is the printout statement:\r\n```\r\n-- Install configuration: \"Release\"\r\n```\r\n\r\nI am trying to install tflite as a cmake package that other projects can use the library and header files. However, it needs to be in a specific install location. Currently I am creating a Cmake project that uses \"ExternalProject\" to clone, configure, build, and install tensorflowlite. The only issue is that it does not install to the location I need it to even when specifying -DCMAKE_INSTALL_PREFIX.\r\n\r\nPreviously I used bazel to build from source, copy all the files, and also generate a cmake package configuration. However, I want to be able to build the entire package with just CMakelists.txt. I would appreciate any help on how to have the libraries and include files installed into a single location throuh Cmake. \r\n\r\nThank you so much! I am sure a lot of users would really like this feature, especially in the robotics community.\r\n\r\n\r\n", "comments": ["@mrawding ,\r\nIs this still an issue?\r\nCould you please update TensorFlow to the latest stable version v.2.6 and let us know if you are facing the same error. Thanks!", "@tilakrayal yes this is still an issue. All the includes and libraries are installed to the build directory, but you still need to search and copy them to another directory to package them. The initial ```cmake``` command does recognize the option for Eigen, but still no libraries are installed. Here are the steps I ran:\r\n\r\n1. Clone tensorflow\r\n2. ```mkdir build```\r\n3. ```mkdir install_space```\r\n4. ```cd build```\r\n5. ``` cmake ../tensorflow/tensorflow/lite -DCMAKE_INSTALL_PREFIX=/home/mike/install_space``` (successful)\r\n6. ``` cmake --build  . -j$(nproc)  ``` (successful) \r\n7. ``` cmake --install . --prefix /home/mike/install_space ```\r\nOutputs: ```-- Install configuration: \"Release\" ```\r\n\r\nNo files installed in /home/mike/install_space\r\n", "@mrawding \r\nCould you please try on the latest tf version as many bugs have been fixed.", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49306\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/49306\">No</a>\n", "Issue persists on v2.9.0"]}, {"number": 49278, "title": "Numpy and dataframe converter", "body": "Addresses issue #43487, coded with @nelsonlin2708968 and @vulkomilev. Previous change from PR https://github.com/tensorflow/tensorflow/pull/45066. \r\n\r\nNumpy feature is located within https://www.tensorflow.org/api_docs/python/tf/make_ndarray/ . \r\n\r\n", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F49278) for more info**.\n\n<!-- need_author_cla -->", "@vulkomilev can you check if you signed the CLA please? ", "@rd16395p Can you please sign CLA. Thanks!", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F49278) for more info**.\n\n<!-- need_author_cla -->", "@gbaned I checked and it looks like I have signed the cla. Are we missing someone else? \r\n\r\n@googlebot I fixed it.\r\n\r\n", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F49278) for more info**.\n\n<!-- need_author_cla -->", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F49278) for more info**.\n\n<!-- need_author_cla -->", "I can't login for some reason\n\n\u041d\u0430 \u0441\u0440, 19.05.2021 \u0433. \u0432 14:34 \u0447. Becca ***@***.***> \u043d\u0430\u043f\u0438\u0441\u0430:\n\n> @gbaned <https://github.com/gbaned> I checked and it looks like I have\n> signed the cla. Are we missing someone else?\n>\n> @googlebot <https://github.com/googlebot> I fixed it.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/49278#issuecomment-844016306>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/ATA3WELBXJEPNL3LQRXAXXTTOOO55ANCNFSM45DQDBRQ>\n> .\n>\n", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F49278) for more info**.\n\n<!-- need_author_cla -->", " @googlebot I fixed it.", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F49278) for more info**.\n\n<!-- need_author_cla -->", "@gbaned It seems that the cla bot is not recognizing @vulkomilev 's agreement, maybe you can check if it exists please? ", "Yeah this shows up when I try to sing it again\n[image: Screenshot from 2021-05-21 15-38-55.png]\n\n\n\u041d\u0430 \u043f\u0442, 21.05.2021 \u0433. \u0432 14:59 \u0447. Becca ***@***.***> \u043d\u0430\u043f\u0438\u0441\u0430:\n\n> @gbaned <https://github.com/gbaned> It seems that the cla bot is not\n> recognizing @vulkomilev <https://github.com/vulkomilev> 's agreement,\n> maybe you can check if it exists please?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/49278#issuecomment-845899873>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/ATA3WELS3KVCX26PFM4UHULTOZDILANCNFSM45DQDBRQ>\n> .\n>\n", "Looks like it passed \ud83d\udc4d ", "Okay so now we just wait to be approved and merged?\n\n\u041d\u0430 \u0441\u0431, 22.05.2021 \u0433. \u0432 20:24 \u0447. Becca ***@***.***> \u043d\u0430\u043f\u0438\u0441\u0430:\n\n> Looks like it passed \ud83d\udc4d\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/49278#issuecomment-846439166>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/ATA3WEL2NYXIQQSEDEGOACDTO7SGVANCNFSM45DQDBRQ>\n> .\n>\n", "Looks like it!", "@aaudiber Can you please review this PR ? Thanks!", "@aaudiber Can you please review this PR ? Thanks!", "@aaudiber Can you please review this PR ? Thanks!", "@aaudiber Can you please review this PR ? Thanks!", "@aaudiber Can you please review this PR ? Thanks!", "@aaudiber Can you please review this PR ? Thanks!", "@aaudiber Can you please review this PR ? Thanks!"]}, {"number": 49257, "title": "tfdbg support dump all op outputs in tf2.x (just like tf1.x) instead of only NANs", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using):2.4.1\r\n- Are you willing to contribute it (Yes/No):No\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nTensorflow 2.x's debugger helps me dump the input data of abnormal operators, which helps me a lot. However, after all, the operator where NAN occurs is not the first site of network anomalies. I often need to observe where the data starts to look abnormal. So I hope that the 2.x debugger can choose to dump the input and output data of any node like the 1.x.\r\n\r\n**Will this change the current api? How?**\r\ntf.debugging.experimental.enable_dump_debug_info()\r\n\r\n**Who will benefit with this feature?**\r\nDevelopers who need to perform network precision commissioning\r\n**Any Other info.**\r\n", "comments": []}, {"number": 49242, "title": "Request: Function (or example) for shuffling a large dataset on disk", "body": "**System information**\r\n- TensorFlow version (you are using): 2.4.1\r\n- Are you willing to contribute it (Yes/No): No\r\n\r\n**Describe the feature and the current behavior/state.**\r\nThere is currently no supported way to shuffle a large tfrecord dataset that does not fit into memory. For example, I am working with the Waymo Open Dataset, which consists of roughly 800 TFRecord files each with 200 frames of data. With 1TB of data it cannot be shuffled even with a very large 128GB memory. Ideally shuffling it would consist of writing to shards small enough to fit in memory, completely shuffling the shards randomly, and then randomly interleaving the shuffled shards. This would be a nice addition to the new experimental tf.data save and load APIs.\r\n\r\n**Will this change the current api? How?**\r\nPossibly? Either dedicated functions could be added, or this could be possibly achieved as a composition of existing tf.data operations.\r\n\r\n**Who will benefit with this feature?**\r\nAnyone using large datasets with tf.data\r\n\r\n", "comments": ["I don't know if using [Waymo TFDS](https://www.tensorflow.org/datasets/catalog/waymo_open_dataset) it can work with [TFDS  `shuffle_files` param](https://www.tensorflow.org/datasets/api_docs/python/tfds/load)", "TFDS would be a great solution but unfortunately the TFDS version is simplified and does not contain the original data format", "I think that this is still valid https://github.com/tensorflow/tensorflow/issues/14857#issuecomment-347261151", "I tried that method but noticed I wasn\u2019t getting truly random data. This is because the data is an ordered time series within each re-record file. Even though all 800 files are shuffled randomly, the data read from them is still in order. The first elements of the files are read first and the last elements are read last. This may seem like an insignificant difference in a large dataset, but I am experiencing loss spikes when I restart the epoch because it isn\u2019t truly random.", "So do you have the inverted use case of https://github.com/tensorflow/datasets/issues/113 ?"]}, {"number": 49241, "title": "LSTM and GRU on cudnn with mask puts different output from CPU or Non-cudnn kernel", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): colab\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): colab\r\n- TensorFlow version (use command below): colab\r\n- Python version: Python 3.7.10 (colab)\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: cuda_11.0_bu  (colab)\r\n- GPU model and memory: colab\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\nv2.4.1-0-g85c8b2a817f 2.4.1\r\n\r\n**Describe the current behavior**\r\n\r\nWhen use LSTM or GRU with parameter `return_sequences=True` and use this layer on cudnn kernel,\r\nThe output values of timesteps on which input is masked is all zero.\r\nAnd this behavior is different from CPU or GPU without cudnn, CPU  environment emit output of last unmasked timestep as masked timestep output.\r\n\r\n**Describe the expected behavior**\r\n\r\nI Think it should work same as it work on CPU or GPU without cudnn.\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)** - Do you\r\nwant to contribute a PR? (yes/no): - Briefly describe your candidate solution\r\n\r\nIf it need python-level correction, I may contribute. But if it need cuda or cudnn something, I cannot contribute.\r\nI Think the solution can be postprocessing for masked timestep simply.\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\nJust run below code using colab on CPU and GPU.\r\nThe result is different.\r\n```python\r\nimport tensorflow as tf\r\n\r\nclass TestModel(tf.keras.Model):\r\n  def __init__(self):\r\n    super().__init__()\r\n\r\n    self.rnn = tf.keras.layers.LSTM(32, return_sequences=True)\r\n  \r\n  def call(self, x, mask=None):\r\n    return self.rnn(x, mask=mask)[:, -1, :]\r\n\r\nbatch_size = 4\r\nseq_len = 7\r\n\r\nx = tf.random.normal([batch_size, seq_len, 32])\r\nmodel = TestModel()\r\nmodel(x, mask = tf.sequence_mask([seq_len - 1] * batch_size, maxlen=seq_len))\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["Was able to reproduce the issue on GPU using TF version 2.4. Please find the gist [here](https://colab.research.google.com/gist/saikumarchalla/140720e835b6c5edc993261502547037/untitled.ipynb).\r\n"]}, {"number": 49237, "title": "MultiHeadAttention padding mask example", "body": "## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/MultiHeadAttention\r\n\r\n## Description of issue:\r\n\r\nI try to implement tranformers layer but there is no example of using this MultiHeadAttention layer with padding mask.\r\nIt is poffible to get one ?\r\n\r\n", "comments": ["@dbouchabou \r\nCould you please check  ,and let us know if it [helps](https://www.tensorflow.org/tutorials/text/transformer#multi-head_attention).Thanks", "Thank you for the link. I've already checked it but the  attention_mask is a boolean mask of shape [B, T, S] in the function tf.keras.layers.MultiHeadAttention. In the link you shared the shape is different [batch_size, 1, 1, seq_len].\r\n\r\nI don't understand how to create a mask with shape [B, T, S]. I suppose B is for batch_size T for Target len and S for source len. But how and where place 1 and 0 in the mask ?\r\n", "Can you check https://www.tensorflow.org/tutorials/text/transformer ?", "@bhack thank but it did not help me because il this tutorial the mask shape is not the same as the native multi head attention of TF 2.5\r\n\r\nmask shape in tutorial: [batch_size, 1, 1, seq_len]\r\nmask shape in tf.keras.layers.MultiHeadAttention: [B, T, S]\r\n\r\nI don't understand how can I create the mask with the shape [B, T, S] ?", "If you want to use the Keras one you can see Mask creation in `test_masked_` tests in https://github.com/tensorflow/tensorflow/blob/v2.5.0/tensorflow/python/keras/layers/multi_head_attention_test.py", "@bhack thanks for this pointer I understand better. But I still one problem. The example in your link use random mask. How can I create a mask for a multi head self attention with the Keras implementation for this sequence for exemple:\r\n\r\nseq= [A,B,C,D,0,0,0,0,0,0]\r\n\r\nif it self attention the source and the target are the same sequence.\r\nT = [A,B,C,D,0,0,0,0,0,0]\r\nS = [A,B,C,D,0,0,0,0,0,0]\r\n\r\nthe mask should be [1,1,1,1,0,0,0,0,0,0] but its not respect the [B, T, S]  shape.\r\nI don't know if the mask must be transform like this:\r\n\r\n[[1,1,1,1,0,0,0,0,0,0] \r\n[1,1,1,1,0,0,0,0,0,0] \r\n[1,1,1,1,0,0,0,0,0,0] \r\n[1,1,1,1,0,0,0,0,0,0] \r\n....\r\n[1,1,1,1,0,0,0,0,0,0] ]\r\n\r\nor like this:\r\n\r\n[[1,1,1,1,0,0,0,0,0,0] \r\n[1,1,1,1,0,0,0,0,0,0] \r\n[1,1,1,1,0,0,0,0,0,0] \r\n[1,1,1,1,0,0,0,0,0,0] \r\n[0,0,0,0,0,0,0,0,0,0] \r\n[0,0,0,0,0,0,0,0,0,0] \r\n...\r\n[0,0,0,0,0,0,0,0,0,0] ]\r\n", "is it a correct function to create a padding mask for the Keras multi head attention implementation ?\r\n\r\n```\r\ndef create_padding_mask(seq):\r\n    att_mask = []\r\n    seq_length = seq.shape[1]\r\n    with tqdm(total=seq.shape[0]+1, desc='Create padding mask') as pbar:\r\n        masks = tf.cast(tf.math.equal(seq, 0), tf.float32)\r\n        pbar.update(1)\r\n\r\n        \r\n        masks = 1 - masks\r\n\r\n\r\n        for m in masks:\r\n            am = np.ones((seq_length,seq_length))\r\n\r\n            m1 = np.expand_dims(m, axis=0)\r\n            m2 = np.expand_dims(m, axis=1)\r\n\r\n\r\n            am = am*m1\r\n            am = am*m2\r\n            att_mask.append(am)\r\n\r\n            pbar.update(1)\r\n\r\n\r\n    att_mask = np.array(att_mask)\r\n\r\n    return att_mask  # (batch_size, seq_len, seq_len)\r\n```\r\n", "Ok as it was already semi-requested in https://github.com/tensorflow/tensorflow/issues/45854 probably we could add something in the documentation or refactor the tutorial with the Keras layer.\r\n\r\n/cc @MarkDaoust to evaluate this.", "Thanks for this answer. I think it could be a good thing to add a new exemple with the Keras implementation in addition of the current one transformer implementation with Tensorflow .\r\n\r\nMaybe in future Tensorflow versions you could provide Tranformers Encoder and Decoder as Keras layers and also a full transformer Keras implementation ?", "@dbouchabou \r\nCould you please confirm if the issue still persist.Thanks", "Issue persists if no official documentation or example is provide", "I've got half a solution being submitted (address this problem for the `nmt_with_attention` tutorial instead of the transformers tutorial)\r\n\r\nThe transformers tutorial should be updated to use MultiHeadAttention, and a lot of the same tricks as the new `nmt_with_attention` (`image_captioning` too.).", "Is it possible to update the transformer tutorial with the MultiHeadAttention function ?", "This is the right thing to do, It's just a matter of finding time."]}, {"number": 49236, "title": "Custom Losses Documentation is Incomplete", "body": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/guide/keras/train_and_evaluate#custom_losses\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nThe current documentation for writing custom loss functions is significantly incomplete. It does not indicate:\r\n\r\n1) how to test compilation of the custom loss function\r\n2) how to debug the custom loss function\r\n3) what data types are expected for the function\r\n4) what data type is expected to be returned from the function\r\n5) what operations can be performed within the function.\r\nFor example. I found when run in the graph, functions like .numpy(), make_ndarray() and to_list() do not work on the tensors when in graph mode. However, these issues seem only to have arisen through raised issues rather than being proactively documented. Likewise, the documentation on how to to reenable these functions is not clearly documented.", "comments": ["Hello there! is this issue open? can I contribute?", "/cc @nikitamaia ", "@a-ma-n if you have any commentary, I personally would appreciate it and any knowledge can help improve the guide going forward so others can benefit.", "Great I'll look into it", "Hey @a-ma-n, Are u still looking into the issue?? If not, then can I work on the same??", "These guides come from the keras-io repo:\r\n\r\nhttps://github.com/keras-team/keras-io\r\n\r\nBe sure to talk with them before undertaking any significant work, the owners are particular about what goes there.\r\n\r\nAlso note that many of the specific questions in this bug can be answered with \"the function should be executable in a `tf.function`: it must be composed of TensorFlow operations\""]}, {"number": 49229, "title": "TensorFlow eager-mode VS PyTorch eager-mode", "body": "### Config:\r\n```\r\nOS: Windows 10\r\nTensorFlow 2.4.1\r\nTorch 1.7.1\r\n```\r\n\r\n### Query\r\n\r\n**We know that **eager mode** is slow compared to graph mode in `TF 2.x`. But how much it can be slow compared to `PyTorch's` eager mode??**\r\n\r\nA question was asked in [SO](https://stackoverflow.com/q/67383458/9215780) regarding this, where the OP used a deep reinforcement learning code example with a custom training loop to compare. In that example, whereas a `pytorch` code takes approximately **`~3` minutes** to complete; and with the same training pipeline a `tf` code takes approximately **`~2` hours** to complete, even with less accuracy comparatively. \r\n\r\nIt probably also brings some other stuff like memory leaks during custom training loops etc. When I run the `pytorch` code, the `CPU` gets uses 100% and the `3D` thread of `GPU` (RTX 2070) was using approximately 20%. But when I run `tf` code, the `CPU` gets uses ~50%, physical **RAM** gets increased over time (possible memory leaks), and **VRAM** gets super high and no use of `3D` thread of `GPU`. Not sure what's the root cause. \r\n\r\nThe only and **significant difference** occurs **after optimizing the `tf` code** and **compile it with graph execution**, as demonstrated in the accepted [answer](https://stackoverflow.com/a/67420239/9215780). The answer is fine but it seems more like the way to optimize `tf` code. \r\n\r\nI'm wondering, let's say we need to run `tf` code in eager mode, in that point, what is the root cause of this **performance and execution gap** between `tf` and `pytorch`. Is it expected behavior? The OP shared the plug-n-play code example, please find them from [here](https://github.com/navi2000/drl_test). \r\n", "comments": ["@rmothukuru please let me know if I need to add any more information. The code (mention above) is plug-n-play type code, you don't need to bother with unnecessary libraries or anything serious basically. ", "@rmothukuru \r\nany update? ", "@rmothukuru \r\nCould you please give some feedback? "]}, {"number": 49164, "title": "Parallel execution operator scheduling seems to be inconsistent across runs", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.5 LTS\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.4.0\r\n- Python version: 3.6.9\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10.2.89\r\n- GPU model and memory: 512-core Volta GPU with Tensor Cores\r\n--\r\n\r\n**Describe the current behavior**\r\nI'm trying to run a small computational graph in parallel on both CPU and GPU. The computational graph is shown below.\r\n![image](https://user-images.githubusercontent.com/23744021/118153973-1cd5ba00-b434-11eb-98cf-d75e3d2b0ee3.png)\r\nI want Conv1, Conv2 and Conv4 to be executed on GPU and Conv3 to be executed on CPU. After mapping the operators to the required device, I'm observing inconsistent operator scheduling when executing the graph across multiple runs. You can observe three different execution trace for the same computational graph. These three traces have different total inference or run times. They vary from 300ms to 400ms.  \r\n![image](https://user-images.githubusercontent.com/23744021/118152724-aa180f00-b432-11eb-8640-4c0a2103fa5e.png)\r\n![image](https://user-images.githubusercontent.com/23744021/118154468-b7ce9400-b434-11eb-9282-928fb6c6c96b.png)\r\n![image](https://user-images.githubusercontent.com/23744021/118154589-dcc30700-b434-11eb-814d-aa2a0d8b6e26.png)\r\n\r\n**Describe the expected behavior**\r\nIts expected to produce the first trace output shown above where both operation on CPU and GPU starts executing in parallel at almost the same time. \r\n\r\n**Standalone code to reproduce the issue**\r\nPlease find the code snippet [here](https://gist.github.com/surya00060/a0bcf49a53353011c36bf5290fa81355)", "comments": ["I see that your gpu setup is not compatible with the TF 2.4 version. You require cuda 11 and cudnn 8.0 with TF 2.4 version.\r\nSo right now all your computation falls on cpu since gpu is not visible to ops. \r\nhttps://www.tensorflow.org/install/gpu#software_requirements", "Actually the computation happens on GPU and it's not falling back onto CPU. I have verified this. Tensorflow is able to detect GPU here. I get the following output when testing whether Tensorflow has access to GPU or not. \r\n```\r\nPython 3.6.9 (default, Jan 26 2021, 15:33:00) \r\n[GCC 8.4.0] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow\r\n2021-05-20 13:27:57.968848: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.2\r\n>>> import tensorflow as tf\r\n>>> tf.test.is_gpu_available()\r\nWARNING:tensorflow:From <stdin>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.config.list_physical_devices('GPU')` instead.\r\n2021-05-20 13:28:40.361773: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2021-05-20 13:28:40.368006: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\r\n2021-05-20 13:28:40.426468: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] ARM64 does not support NUMA - returning NUMA node zero\r\n2021-05-20 13:28:40.426691: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Found device 0 with properties: \r\npciBusID: 0000:00:00.0 name: Xavier computeCapability: 7.2\r\ncoreClock: 1.377GHz coreCount: 8 deviceMemorySize: 31.18GiB deviceMemoryBandwidth: 82.08GiB/s\r\n2021-05-20 13:28:40.427087: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.2\r\n2021-05-20 13:28:40.431546: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\r\n2021-05-20 13:28:40.431722: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\r\n2021-05-20 13:28:40.434559: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\r\n2021-05-20 13:28:40.435209: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\r\n2021-05-20 13:28:40.438365: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\r\n2021-05-20 13:28:40.440915: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\r\n2021-05-20 13:28:40.441452: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\r\n2021-05-20 13:28:40.441717: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] ARM64 does not support NUMA - returning NUMA node zero\r\n2021-05-20 13:28:40.442021: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] ARM64 does not support NUMA - returning NUMA node zero\r\n2021-05-20 13:28:40.442100: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1888] Adding visible gpu devices: 0\r\n2021-05-20 13:28:40.442311: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.2\r\n2021-05-20 13:28:41.909318: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1287] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2021-05-20 13:28:41.909419: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1293]      0 \r\n2021-05-20 13:28:41.909452: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1306] 0:   N \r\n2021-05-20 13:28:41.909804: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] ARM64 does not support NUMA - returning NUMA node zero\r\n2021-05-20 13:28:41.910068: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] ARM64 does not support NUMA - returning NUMA node zero\r\n2021-05-20 13:28:41.910237: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] ARM64 does not support NUMA - returning NUMA node zero\r\n2021-05-20 13:28:41.910367: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Created TensorFlow device (/device:GPU:0 with 22365 MB memory) -> physical GPU (device: 0, name: Xavier, pci bus id: 0000:00:00.0, compute capability: 7.2)\r\nTrue\r\n``` \r\n\r\nI should have pointed it out, I'm working with Nvidia Jetson AGX Xavier. The latest CUDA the device supports as of now is 10.2. \r\nI followed these steps to install Tensorflow. [Link](https://docs.nvidia.com/deeplearning/frameworks/install-tf-jetson-platform/index.html)"]}, {"number": 49158, "title": "Inference with small tflite model does not benefit from warm up", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04.2 LTS (GNU/Linux 5.4.0-73-lowlatency x86_64)\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Desktop\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 2.6.0\r\n- Python version: n/a\r\n- Bazel version (if compiling from source): 4.0.0\r\n- GCC/Compiler version (if compiling from source): GCC 10.2.0\r\n\r\n**Describe the current behavior**\r\nInference with small tflite model does not benefit from warm up. TFlite Benchmarking Tool indicates that it should.\r\n\r\n**Describe the expected behavior**\r\nWhen benchmarking my tflite-model with the TFlite Benchmarking Tool I cleary see a speed up in steady stage after the initial warm ups. `Inference timings in us: Init: 769, First inference: 533, Warmup (avg): 14.6845, Inference (avg): 15.5197`\r\n\r\nWhen I'm running inference in my C++ code, the inference speed is always around 300-500 us. If I read the benchmarking tool output correctly, it should be able to reach well below 100 us after warm up.\r\n\r\nThe result from the benchmarking tool ->\r\n\r\n```\r\nSTARTING!\r\nLog parameter values verbosely: [0]\r\nNum threads: [1]\r\nGraph: [/home/gustaf/cprojects/pacific/nlp/en/model.tflite]\r\n#threads used for CPU inference: [1]\r\nLoaded model /home/gustaf/cprojects/pacific/nlp/en/model.tflite\r\nThe input model file size (MB): 0.367488\r\nInitialized session in 0.769ms.\r\nRunning benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.\r\ncount=33776 first=533 curr=14 min=13 max=533 avg=14.6845 std=3\r\n\r\nRunning benchmark for at least 50 iterations and at least 1 seconds but terminate if exceeding 150 seconds.\r\ncount=63948 first=14 curr=17 min=13 max=90 avg=15.5197 std=2\r\n\r\nInference timings in us: Init: 769, First inference: 533, Warmup (avg): 14.6845, Inference (avg): 15.5197\r\nNote: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.\r\nPeak memory footprint (MB): init=0.574219 overall=0.574219\r\n```\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\nOutput ->\r\n```\r\nPrediction 1: 477 us\r\nPrediction 2: 307 us\r\nPrediction 3: 320 us\r\nPrediction 4: 319 us\r\nPrediction 5: 299 us\r\n```\r\n\r\nCode ->\r\n```\r\n#include <tensorflow/lite/interpreter.h>\r\n#include <tensorflow/lite/model.h>\r\n#include <tensorflow/lite/kernels/register.h>\r\n#include <iomanip>\r\n#include <iostream>\r\n#include <mutex>\r\n#include <fstream>\r\n#include \"tbb/concurrent_unordered_map.h\"\r\n#include <unicode/unistr.h>\r\n#include <unicode/ustream.h>\r\n#include <unicode/locid.h>\r\n#include <chrono>\r\n#include <boost/algorithm/string.hpp>\r\n\r\nstd::mutex mtx;\r\n\r\nusing namespace std;\r\nusing namespace std::chrono_literals;\r\nusing std::chrono::high_resolution_clock;\r\nusing std::chrono::duration_cast;\r\nusing std::chrono::duration;\r\nusing std::chrono::microseconds;\t\r\n\r\ntflite::ops::builtin::BuiltinOpResolver resolver_sv;\r\nstd::unique_ptr<tflite::FlatBufferModel> model_sv;\r\nstd::unique_ptr<tflite::Interpreter> interpreter_sv;\r\ntbb::concurrent_unordered_map<string, int> vocab_sv;\r\n\r\nfloat predict(string ss) {\r\n\tstd::scoped_lock lock{mtx};\r\n\tint* input;\r\n\tfloat* output; \r\n\tstring s;\r\n\ticu::UnicodeString ustr(ss.c_str());\r\n\tustr.toLower();\r\n\tustr.toUTF8String(s);\r\n\t\r\n\tinput = interpreter_sv->typed_input_tensor<int>(0);\r\n\t\r\n\tstd::vector<std::string> result;\r\n\tboost::algorithm::split(result, s, boost::is_any_of(\" *\"), boost::token_compress_on);\r\n\r\n\tint i = 0;\r\n\tfor(auto& word: result) { \r\n\t\ttry {\r\n\t\t\tinput[i] = vocab_sv.at(word);\r\n\t\t\ti = i+1;\r\n\t\t}\r\n\t\tcatch (const std::out_of_range& oor) {\r\n\t\t\tinput[i] = 1;\r\n\t\t\ti = i+1;\r\n\t\t}\r\n\t}\r\n\twhile(i<=20) {\r\n\t\tinput[i] = 0;\r\n\t\ti = i+1;\r\n\t}\r\n\r\n\tinterpreter_sv->Invoke();\r\n\toutput = interpreter_sv->typed_output_tensor<float>(0);\r\n\r\n\treturn output[0];\r\n}\r\n\r\nvoid init_model(){\r\n\r\n\tmodel_sv = tflite::FlatBufferModel::BuildFromFile(\"/home/gustaf/cprojects/pacific/nlp/en/model.tflite\");\r\n\t\t\r\n\tif (model_sv == nullptr) {\r\n\t\t\tstd::cerr << \"Model not found!\" << std::endl;\r\n\t\t}\r\n\tif (tflite::InterpreterBuilder(*model_sv, resolver_sv)(&interpreter_sv) != kTfLiteOk) {\r\n\t\tstd::cerr << \"Failed to build interpreter!\" << std::endl;\r\n\t\t}\r\n\r\n\tinterpreter_sv->SetNumThreads(1);\r\n\r\n\tif (interpreter_sv->AllocateTensors() != kTfLiteOk) {\r\n\t\tstd::cerr << \"Failed to allocate tensors.\" << std::endl;\r\n\t}\r\n\tif (interpreter_sv->Invoke() != kTfLiteOk) {\r\n\t\tstd::cerr << \"Cannot invoke interpreter\" << std::endl;\r\n\t  }\r\n\t \r\n\tifstream infile(\"/home/gustaf/cprojects/pacific/nlp/en/vocab.txt\");\r\n\tstring a;\r\n\tint b;\r\n\twhile (infile >> a >> b) {vocab_sv.insert(pair<string, int>(a, b));}\r\n\r\n}\r\n\r\nint main (){\r\n\t\r\n\tinit_model();\r\n\t\r\n\tauto t1 = high_resolution_clock::now();\r\n\tpredict(\"This is a warmup text\");\r\n\tauto t2 = high_resolution_clock::now();\r\n\tpredict(\"This is another warmup text\");\r\n\tauto t3 = high_resolution_clock::now();\r\n\tpredict(\"This is an example text\");\r\n\tauto t4 = high_resolution_clock::now();\r\n\tpredict(\"This is another example text\");\r\n\tauto t5 = high_resolution_clock::now();\r\n\tpredict(\"This is the final text\");\r\n\tauto t6 = high_resolution_clock::now();\r\n\r\n\r\nauto ms1 = duration_cast<microseconds>(t2 - t1);\r\nauto ms2 = duration_cast<microseconds>(t3 - t2);\r\nauto ms3 = duration_cast<microseconds>(t4 - t3);\r\nauto ms4 = duration_cast<microseconds>(t5 - t4);\r\nauto ms5 = duration_cast<microseconds>(t6 - t5);\r\n\r\ncout << \"Prediction 1: \" << ms1.count() << \" us\" << endl;\r\ncout << \"Prediction 2: \" << ms2.count() << \" us\" << endl;\r\ncout << \"Prediction 3: \" << ms3.count() << \" us\" << endl;\r\ncout << \"Prediction 4: \" << ms4.count() << \" us\" << endl;\r\ncout << \"Prediction 5: \" << ms5.count() << \" us\" << endl;\r\n\r\n}\r\n```\r\n\r\n\r\n", "comments": ["@multiverse-tf could you take a look?", "Rebuilding Tensorflow using Bazel seems to fix the issue. Previously I used `make -f ./tensorflow/lite/tools/make/Makefile` to build and linked the .a file when compiling my code. Now I used `bazel build --config=monolithic -c opt //tensorflow/lite:libtensorflowlite.so` and linked the .so file when compiling.\r\n\r\nSeems to have made all the difference! I have no idea why though...\r\n\r\n```\r\nPrediction 1: 1285 us\r\nPrediction 2: 39 us\r\nPrediction 3: 29 us\r\nPrediction 4: 28 us\r\nPrediction 5: 23 us\r\n```", "A follow up question -> The warmup effect appears to degrade over time. I can do +250k inference runs in 7.2 seconds (about 28 microseconds per prediction in average) which is great, but if i do a single inference a few minutes later with the same model, it takes at least 10x as long time. \r\n\r\nDoes Tensorflow clear the memory after some time? And if so, is there an option to stop that from happening? "]}, {"number": 49150, "title": "Compilation fails on Ubuntu 20.04 when using TensorRT 8. ", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version: 2.4.1, 2.5, etc\r\n- Python version: 3.8\r\n- Installed using virtualenv? pip? conda?: no, built from source\r\n- Bazel version (if compiling from source): 3.1 (for TF 2.4.1), 3.7.2 (for TF 2.5.0-rcx)\r\n- GCC/Compiler version (if compiling from source): gcc (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0\r\n- CUDA/cuDNN version: Cuda 11.1, cudnn8 (8.0.5.39-1+cuda11.1) or Cuda-11-2, libcudnn 8.1.1, 8.2, \r\n- GPU model and memory: GTX-1080ti\r\n- TensorRT (crucial): 8.0.0-1+cuda11.0, or 8.0.0-1+cuda11.3\r\n\r\n**Describe the problem**\r\nWhen compiling with support for TensorRT 8 (via libnvinfer8), compilation fails (log is below). \r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nWhen configuring the build, make sure you build with TensorRT support, and make sure TensorRT version 8 is selected. Build TF as usual. Compilation will fail. \r\n\r\nIf you install  TensorRT version 7 manually (from debs available for Ubuntu 18.04), compilation will complete just fine.\r\n\r\n**Any other info / logs**\r\nRelevant error: \r\n`C++ compilation of rule '//tensorflow/compiler/tf2tensorrt:tensorrt_stub' failed (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command`\r\n\r\n`In file included from bazel-out/k8-opt/bin/external/local_config_tensorrt/_virtual_includes/tensorrt_headers/third_party/tensorrt/NvInfer.h:54,\r\n                 from tensorflow/compiler/tf2tensorrt/stub/nvinfer_stub.cc:17:\r\nbazel-out/k8-opt/bin/external/local_config_tensorrt/_virtual_includes/tensorrt_headers/third_party/tensorrt/NvInferRuntime.h:2264:51: note: from previous declaration 'nvinfer1::IPluginRegistry* getPluginRegistry() noexcept'\r\n 2264 | extern \"C\" TENSORRTAPI nvinfer1::IPluginRegistry* getPluginRegistry() noexcept;`\r\n\r\nFull log here: \r\n[gesdm-tf2.5.0rc3-error.txt](https://github.com/tensorflow/tensorflow/files/6469944/gesdm-tf2.5.0rc3-error.txt)\r\n\r\n", "comments": ["Still present for TF 2.5.0\r\n\r\nWhat are the library requirements for building TF2.5.0? Documentation still reference 2.4.0, and that is outdated.", "TensorFlow 2.5 pip packages are now built with CUDA11.2 and cuDNN 8.1.0\r\nSee https://github.com/tensorflow/tensorflow/releases", "Compiling without TensorRT support works with cuda-11-2 and cudnn (8.0, 8.1, 8,2). The problem is when support for TensorRT is enabled.", "Is the build failing for TF 2.4 as well for you?", "It fails there too, but I need to do more cross testing. I will report as soon as I am done. Thanks for your patience.", "Update: it looks like the issue is with tensorRT version 8, regardless of the version of cuda or cudnn, as well as for TF 2.4 or 2.5. When trying to compile with tensorRT 8 (specifically with libnvinfer8, libnvinfer-dev, libnvinfer-plugin8 libnvinfer-plugin-dev), it fails. However, when using tensorRT version 7, it seems to compile just fine. In fact I managed to compile earlier TF 2.5.0rc just fine.\r\n\r\nI would have no problem using tensorRT 7. Unfortunately it is no longer available for Ubuntu 20.04. The repos and builds in NVidia repos are only version 8. I was able to test version 7 by manually getting the Ubuntu 18.04 debs and installing them manually on 20.04, which is far less than ideal.\r\n\r\nSo it seems there may be issues with TF compatibility with tensorRT 8, and NVidia is quite forcing an upgrade that essentially make impossible to build TF with with tensorrt support using Ubuntu 20.04, unless one uses manual installation of libraries.\r\n\r\nHappy to run more test.", "As the last supported version of cuda and libcudnn for tensorrt 7 are 11.1 and 8.0.5, respectively, I am currently trying a couple of builds:\r\n1. cuda-11-2, libcudnn 8.1.1, while retaining tensorrt 7 built for cuda-11-1.\r\n2. Test build using nightly TF 2.6. ", "Cuda-11-2, libcudnn 8.1.1, while retaining tensorrt 7 built for cuda-11-1, can compile just fine.", "Compiling TF2.6.0-nightly with Cuda-11-2, libcudnn 8.1.1, with TensorRT 8 fails. ", "This is a known issue, as TensorRT has breaking changes. See [work in progress PR 48917](https://github.com/tensorflow/tensorflow/pull/48917).", "If it's a known issue it should be reflected in the release notes. It would have saved me quite some time, if I knew...", "Do you mean include this in the release note of TensorRT 8, which comes after TF 2.5?", "Maybe a line specifying that only TensorRT 7 is supported in the TensorRT section of the Release notes for TF 2.5...\r\n\r\nAlternatively, or in addition, this page is quite outdated (Ubuntu 20.04 is not even mentioned):\r\n\r\nhttps://www.tensorflow.org/install/gpu\r\n\r\nThe point is, the support page could set some very conservative version numbers for the GPU libraries needed. However, those are not available in the current LTS (and supported) version of Ubuntu, which means that someone trying to build TF with it will not be able to successfully complete it. I understand this is less of a problem for TF as much as it is an issue in NVidia repos dropping support for older versions of TensorRT, but a clarification would go a long way.\r\n\r\n", "Interesting point, TensorRT 8 comes after TF 2.5 and we have no ideas that it is not going to work with TF 2.5.\r\n[The tensorRT 8 release note](https://docs.nvidia.com/deeplearning/tensorrt/release-notes/tensorrt-8.html#tensorrt-8) says there is breaking API changes, which can be interpreted as anything that work with TensorRT 7 but released before TensorRT 8 can be broken.", "Indeed. The issue again is with the questionable way NVidia provides packages across major version numbers. To give you a sense, you can actually have both TensorRT 7 and 8 installed through the `libnvinfer8` and `libnvinfer7`packages and related plugins. However, the dev package (`libnvinfer-dev`) is version agnostic, which means that when NVidia updates TensorRT to version 8, it forces the upgrade also on the dev package to version 8. The issue is made worse by the fact that NVidia not only upgraded the packages to 8, but removed all the previous version 7, so there is no way to actively get them through apt. I am using those still available for Ubuntu 18.04, manually installed from packages obtained by decompressing the massive package from NVidia. \r\n\r\nTensorRT has been just released, but Ubuntu20.04 has been around for about a year, which makes this move from NVidia not only questionable, but rather inconsiderate.\r\n", "As to your point about the tensorRT release notes breaking APIs, I can only say that it's fair that is acknowledged. However, that change was done in such a way that it literally breaks people systems with no way to recover them in a usable way. As of now, there is no straightforward way to compile tensorflow with tensorRT on Ubuntu 20.04. Essentially the expectation is for them to move people to the latest and greatest, with the previous version basically losing any support. If it permanently breaks stuff, well too bad.\r\n\r\nThat is why a warning on the TF side of things would be useful, if for no other reason that it would save massive amount of time and effort in people trying to figure out what's wrong. ", "> I would have no problem using tensorRT 7. Unfortunately it is no longer available for Ubuntu 20.04. The repos and builds in NVidia repos are only version 8. I was able to test version 7 by manually getting the Ubuntu 18.04 debs and installing them manually on 20.04, which is far less than ideal.\r\n> \r\n> So it seems there may be issues with TF compatibility with tensorRT 8, and NVidia is quite forcing an upgrade that essentially make impossible to build TF with with tensorrt support using Ubuntu 20.04, unless one uses manual installation of libraries.\r\n> \r\n> Happy to run more test.\r\n\r\nSecond this problem on Ubuntu 21.04 (amd64). \r\nBazel 3.7.2\r\nPython 3.9.5\r\nCUDA 11.3\r\ncuDNN 8\r\nTensorRT 8 (TensorRT from official Nvidia .deb:\r\nnv-tensorrt-repo-ubuntu2004-cuda11.3-trt8.0.0.3-ea-20210423_1-1_amd64.deb)\r\n\r\n\r\n```ERROR: /home/luser/tensorflow/tensorflow/compiler/tf2tensorrt/BUILD:43:11: C++ compilation of rule '//tensorflow/compiler/tf2tensorrt:tensorrt_stub' failed (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -MD -MF bazel-out/k8-opt/bin/tensorflow/compiler/tf2tensorrt/_objs/tensorrt_stub/nvinfer_stub.pic.d ... (remaining 149 argument(s) skipped)\r\nIn file included from tensorflow/compiler/tf2tensorrt/stub/nvinfer_stub.cc:56:\r\n./tensorflow/compiler/tf2tensorrt/stub/NvInfer_5_0.inc:5:7: error: declaration of \u2018void* createInferBuilder_INTERNAL(void*, int)\u2019 has a different exception specifier\r\n    5 | void* createInferBuilder_INTERNAL(void* logger, int version) {\r\n      |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~\r\nIn file included from tensorflow/compiler/tf2tensorrt/stub/nvinfer_stub.cc:17:\r\nbazel-out/k8-opt/bin/external/local_config_tensorrt/_virtual_includes/tensorrt_headers/third_party/tensorrt/NvInfer.h:8083:30: note: from previous declaration \u2018void* createInferBuilder_INTERNAL(void*, int32_t) noexcept\u2019\r\n 8083 | extern \"C\" TENSORRTAPI void* createInferBuilder_INTERNAL(void* logger, int32_t version) noexcept;\r\n      |                              ^~~~~~~~~~~~~~~~~~~~~~~~~~~\r\nIn file included from tensorflow/compiler/tf2tensorrt/stub/nvinfer_stub.cc:56:\r\n./tensorflow/compiler/tf2tensorrt/stub/NvInfer_5_0.inc:12:7: error: declaration of \u2018void* createInferRuntime_INTERNAL(void*, int)\u2019 has a different exception specifier\r\n   12 | void* createInferRuntime_INTERNAL(void* logger, int version) {\r\n      |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~\r\nIn file included from bazel-out/k8-opt/bin/external/local_config_tensorrt/_virtual_includes/tensorrt_headers/third_party/tensorrt/NvInfer.h:54,\r\n                 from tensorflow/compiler/tf2tensorrt/stub/nvinfer_stub.cc:17:\r\nbazel-out/k8-opt/bin/external/local_config_tensorrt/_virtual_includes/tensorrt_headers/third_party/tensorrt/NvInferRuntime.h:2253:30: note: from previous declaration \u2018void* createInferRuntime_INTERNAL(void*, int32_t) noexcept\u2019\r\n 2253 | extern \"C\" TENSORRTAPI void* createInferRuntime_INTERNAL(void* logger, int32_t version) noexcept;\r\n      |                              ^~~~~~~~~~~~~~~~~~~~~~~~~~~\r\nIn file included from tensorflow/compiler/tf2tensorrt/stub/nvinfer_stub.cc:56:\r\n./tensorflow/compiler/tf2tensorrt/stub/NvInfer_5_0.inc:33:28: error: declaration of \u2018nvinfer1::IPluginRegistry* getPluginRegistry()\u2019 has a different exception specifier\r\n   33 | nvinfer1::IPluginRegistry* getPluginRegistry() {\r\n      |                            ^~~~~~~~~~~~~~~~~\r\nIn file included from bazel-out/k8-opt/bin/external/local_config_tensorrt/_virtual_includes/tensorrt_headers/third_party/tensorrt/NvInfer.h:54,\r\n                 from tensorflow/compiler/tf2tensorrt/stub/nvinfer_stub.cc:17:\r\nbazel-out/k8-opt/bin/external/local_config_tensorrt/_virtual_includes/tensorrt_headers/third_party/tensorrt/NvInferRuntime.h:2264:51: note: from previous declaration \u2018nvinfer1::IPluginRegistry* getPluginRegistry() noexcept\u2019\r\n 2264 | extern \"C\" TENSORRTAPI nvinfer1::IPluginRegistry* getPluginRegistry() noexcept;\r\n      |                                                   ^~~~~~~~~~~~~~~~~\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 1411.321s, Critical Path: 125.56s\r\nINFO: 8683 processes: 5111 internal, 3572 local.\r\nFAILED: Build did NOT complete successfully\r\n```\r\n", "> ilds in NVidia repos are only version 8. I was able to test version 7 by manually getting the Ubuntu 18.04 debs and installing them manually on 20.04, which is far less than ideal.\r\n> \r\n> So it seems there may be issues with TF compatibility with tensorRT 8, and NVidia is quite forcing an upgrade that essen\r\n\r\ndid you solve if?", "Yes, this is indeed fixed as of TF version 2.7.0On Dec 13, 2021 8:22 PM, hang_code ***@***.***> wrote:\r\n\r\nilds in NVidia repos are only version 8. I was able to test version 7 by manually getting the Ubuntu 18.04 debs and installing them manually on 20.04, which is far less than ideal.\r\nSo it seems there may be issues with TF compatibility with tensorRT 8, and NVidia is quite forcing an upgrade that essen\r\n\r\ndid you solve if?\r\n\r\n\u2014You are receiving this because you authored the thread.Reply to this email directly, view it on GitHub, or unsubscribe.Triage notifications on the go with GitHub Mobile for iOS or Android.", "thanks  i just modify cmakelist   ,from tensorrt7 to tensorrt 8   fix the problem!", "Which cmakelist did you modify?", "Right, TensorRT has API changes and doesn't work with TF before TF 2.7.", "I faced a similar issue comping TF2.7 with CUDA 11.4, cuDNN 8 and TensorRT 8.2.2 on Python 3.10.1. Unfortunately, I failed to compile due to an unsupported TensorRT version. However, it went almost without issues without it. Except for the bug with Python 3.10.1, which was later fixed with this [commit](https://github.com/tensorflow/tensorflow/commit/14966ee409b89df5b9144a6d1a19359dd0bb1f68?diff=unified).\r\n\r\nThe good thing is that neither of those issues comes out in version TF2.8.0-rc0. So, if you are interested in adding TensorRT support, you should aim for a version higher than the latest 2.7.0. However, I cannot yet vouch that there will not be any other problems along the way. I had to compile TensortRT from the source for my specific hardware. But according to my short observation, TF2.8 with TensorRT had an execution speed boot.\r\n\r\nI used the following code to verify the outcome for my both TF2.7 and TF2.8-RT environments.\r\n```\r\n# %%\r\n# Verefy copiled output\r\nimport tensorflow as tf\r\nfrom tensorflow.compiler.tf2tensorrt._pywrap_py_utils import get_linked_tensorrt_version\r\n\r\nfrom tensorflow.sysconfig import get_build_info\r\n\r\nprint(f\"Compiled TF version {tf.__version__}\")\r\n\r\nprint(f\"Linked TensorRT version {get_linked_tensorrt_version()}\")\r\n\r\nsys_details = get_build_info()\r\ncuda_version = sys_details[\"cuda_version\"]\r\nprint(f\"Build Cuda version {cuda_version}\")\r\n\r\ncudnn_version = sys_details[\"cudnn_version\"]  \r\nprint(f\"Linked cuDNN version {cudnn_version}\")\r\n\r\ncuda_compute_capabilities = sys_details[\"cuda_compute_capabilities\"]  \r\nprint(f\"Supported Compute Score {cuda_compute_capabilities}\")\r\n# %%\r\n```\r\nOutput for TF2.8.0:\r\n```\r\nCompiled TF version 2.8.0-rc0\r\nLinked TensorRT version (8, 2, 2)\r\nBuild Cuda version 11.4\r\nLinked cuDNN version 8\r\nSupported Compute Score ['compute_75']\r\n```\r\n"]}, {"number": 49148, "title": "Implement ragged `tf.gather_nd` with `batch_dims > 0`.", "body": "**System information**\r\n- TensorFlow version (you are using): TF 2.4, TF 2.5rc3, TF-nightly\r\n- Are you willing to contribute it (Yes/No): No\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nCurrently, using ragged `tf.gather_nd` with `batch_dims > 0` does not work:\r\n```python\r\ntf.gather_nd(tf.ragged.constant([[1,2], [3,4]]), tf.ragged.constant([[[0]], [[1]]], ragged_rank=1), batch_dims=1)\r\n```\r\nfails with\r\n```python\r\nValueError: batch_dims != 0 is not supported for ragged gather yet.\r\n```\r\nhttps://colab.research.google.com/drive/10BIgfMaeO_rL3ZBQqXCHuoW0CZxnhh5S?usp=sharing\r\n\r\nI propose for the missing functionality to be implemented.\r\n\r\n**Will this change the current api? How?**\r\n\r\nThe API will stay the same, but an unsupported combination will be implemented.\r\n\r\n**Who will benefit with this feature?**\r\n\r\nUsers using ragged tensors.\r\n\r\n**Any Other info.**\r\n\r\nUsing non-ragged `tf.gather_nd` works\r\n```python\r\ntf.gather_nd(tf.ragged.constant([[1,2], [3,4]]).to_tensor(), tf.ragged.constant([[0], [1]]).to_tensor(), batch_dims=1)\r\n```\r\nas does does ragged `tf.gather_nd` with `batch_dims==0`\r\n```python\r\ntf.gather_nd(tf.ragged.constant([[1,2], [3,4]]), tf.ragged.constant([[[0]], [[1]]], ragged_rank=1), batch_dims=0)\r\n```", "comments": []}, {"number": 49140, "title": "[XLA:GPU] Support integer convolutions", "body": "**System information**\r\n- TensorFlow version (you are using): `2.6.0.dev20210512`\r\n- Are you willing to contribute it (Yes/No): Yes (I am not familiar with that part of the codebase so would need a bit of help)\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nhttps://github.com/tensorflow/tensorflow/commit/89fc1ddd96f25aa9d8eb6a0104ca1fdb11b26753 added support for integer convolutions on `XLA:CPU` which means that `XLA:GPU` is now the only backend unable to run integer convolutions. This came up in https://github.com/google/jax/pull/6467 and it looks like it is already tracked internally in `b/183565702`.\r\n\r\nIs there any timeline for integer convolution support on GPU? As far as I know CUDA and CUDNN have options to execute integer convolutions on NVIDIA GPUs so I don't think anything fundamental should block this conceptually.\r\n\r\n**Who will benefit with this feature?**\r\n\r\nSupport for integer convolutions would bring the GPU backend inline with CPU and TPU which would be great for users as they might expect integer support for convolutions similar to how it currently works in `DotGeneral` which could enable novel research on true integer quantization aware training.", "comments": ["We have an internal PR with int8xint8->int32 convolutions via cuBLAS, I expect it to land shortly. Will that be sufficient?", "> We have an internal PR with int8xint8->int32 convolutions via cuBLAS, I expect it to land shortly. Will that be sufficient?\r\n\r\nThat's great to hear! I think `int8xint8->int32` will probably cover most cases. Although in the future it I think it would be great to have parity between the backends and also support the other datatypes.", "> We have an internal PR with int8xint8->int32 convolutions via cuBLAS, I expect it to land shortly. Will that be sufficient?\r\n\r\n@cheshire I saw the change to add a int8xint8->int32 GEMM landed some time ago. Do you have any plans to expose this to users in order to support int8xint8->int32 XLA convolutions as well?", "It should be exposed, does it work if you do the calculation with int8 type and put it under jit_compile=True?", "Thanks for the fast reply!\r\n\r\nI tried it via JAX and it doesn't seem to work on GPU yet:\r\n```python\r\nfrom jax import numpy as jnp\r\nfrom jax import lax\r\n\r\nlhs = jnp.ones((1, 1, 1), jnp.int8)\r\nrhs = jnp.ones((1, 1, 1), jnp.int8)\r\n\r\nx = lax.conv_general_dilated(\r\n    lhs=lhs,\r\n    rhs=rhs,\r\n    window_strides=(1,),\r\n    padding='SAME',\r\n    dimension_numbers=('NCH', 'HIO', 'NCH'),\r\n    preferred_element_type=jnp.int32,\r\n)\r\n```\r\n```\r\nRuntimeError: Unimplemented: Integer convolutions for CuDNN must have float or int8 output.  Use convert to cast output to float or the following pattern to int8: clamp(broadcast(-128), conv(int8_x, int8_w, ...), broadcast(127)).\r\n```\r\nand similar without setting `preferred_element_type`.\r\n```python\r\nx = lax.conv_general_dilated(\r\n    lhs=lhs,\r\n    rhs=rhs,\r\n    window_strides=(1,),\r\n    padding='SAME',\r\n    dimension_numbers=('NCH', 'HIO', 'NCH'),\r\n)\r\n```\r\n```\r\nRuntimeError: Unimplemented: Integer convolutions for CuDNN must have this pattern: conv<InputT=int32, ResultT=int32>(convert<int32>(int8_x), convert<int32>(int8_y))\r\n```\r\n\r\nThis might be a JAX issue though in which case, I'd be happy to move the discussion to the JAX repo, but the error gets thrown from the TensorFlow XLA code, so I thought this might be the right place.\r\n\r\n> It should be exposed, does it work if you do the calculation with int8 type and put it under jit_compile=True?\r\n\r\nFrom TF directly this seems to fail:\r\n```python\r\nimport tensorflow as tf\r\n\r\nx = tf.ones((1, 5, 5, 1), dtype=tf.int8)\r\nkernel = tf.ones((2, 2, 1, 2), dtype=tf.int8)\r\n\r\n@tf.function(jit_compile=True)\r\ndef conv(x, kernel):\r\n    return tf.nn.conv2d(x, kernel, strides=[1, 1, 1, 1], padding='VALID')\r\n\r\nconv(x, kernel)\r\n```\r\n```\r\nTypeError: Value passed to parameter 'input' has DataType int8 not in list of allowed values: float16, bfloat16, float32, float64, int32\r\n```\r\n\r\nHowever, I think this is expected since the default `tf.nn.conv2d` implementation doesn't support `int8` at all (Not sure if I properly test this since I think colab didn't correctly recognize the GPU with tf-nightly). Is there a way to directly call the XLA op from the Python side?", "@cheshire Did you find a chance to look at my comment above? I'd be happy to move this issue to the JAX repo, if you think this is unrelated to general XLA:GPU support of int8 convolutions."]}, {"number": 49139, "title": "TensorRT Segmentation Fault During Conversion For Debug Mode", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 20.04\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 2.4.1\r\n- Python version: 3.8\r\n- Bazel version (if compiling from source): bazelisk\r\n- GCC/Compiler version (if compiling from source): gcc5\r\n- CUDA/cuDNN version: 11.0\r\n- GPU model and memory: Tesla 4\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nRun the converter with my optimize_pass\r\n\r\n**Describe the expected behavior**\r\n\r\nIn release mode, I get correct result but in Debug mode, I found segmentgraph(in segment.cc) got nullptr for output_edge\r\n\r\n**Other info / logs**\r\n[Thread 0x7fef967fc700 (LWP 51404) exited]\r\n[Thread 0x7ff01e7fc700 (LWP 51369) exited]\r\n[Thread 0x7ff01d7fa700 (LWP 51371) exited]\r\n[Thread 0x7fef1ffff700 (LWP 51422) exited]\r\n[Thread 0x7fef957fa700 (LWP 51406) exited]\r\n[Thread 0x7fef96ffd700 (LWP 51403) exited]\r\n[Thread 0x7ff01ffff700 (LWP 51366) exited]\r\n[Thread 0x7ff016ffd700 (LWP 51375) exited]\r\n[Thread 0x7ff0867fc700 (LWP 51362) exited]\r\n[Thread 0x7fef1d7fa700 (LWP 51427) exited]\r\n[Thread 0x7fef5dffb700 (LWP 51412) exited]\r\n[Thread 0x7fef5e7fc700 (LWP 51411) exited]\r\n[Thread 0x7fef5d7fa700 (LWP 51413) exited]\r\n[Thread 0x7fef9ffff700 (LWP 51394) exited]\r\n[Thread 0x7ff015ffb700 (LWP 51377) exited]\r\n[Thread 0x7fef57fff700 (LWP 51415) exited]\r\n\r\nThread 1 \"python\" received signal SIGSEGV, Segmentation fault.\r\n0x00007ff3cbebf9d8 in tensorflow::Edge::dst (this=0x0) at external/org_tensorflow/tensorflow/core/graph/graph.h:384\r\n384\texternal/org_tensorflow/tensorflow/core/graph/graph.h: No such file or directory.\r\n(gdb) bt\r\n#0  0x00007ff3cbebf9d8 in tensorflow::Edge::dst (this=0x0) at external/org_tensorflow/tensorflow/core/graph/graph.h:384\r\n#1  0x00007ff3cc908839 in tensorflow::(anonymous namespace)::DFSFromHelper<tensorflow::Node*>(const tensorflow::Graph &, tensorflow::gtl::ArraySlice, const std::function<void(tensorflow::Node*)> &, const std::function<void(tensorflow::Node*)> &, const tensorflow::NodeComparator &, const tensorflow::EdgeFilter &) (g=..., start=..., enter=..., leave=..., stable_comparator=..., edge_filter=...)\r\n    at external/org_tensorflow/tensorflow/core/graph/algorithm.cc:81\r\n#2  0x00007ff3cc90779a in tensorflow::DFS(tensorflow::Graph const&, std::function<void (tensorflow::Node*)> const&, std::function<void (tensorflow::Node*)> const&, std::function<bool (tensorflow::Node const*, tensorflow::Node const*)> const&, std::function<bool (tensorflow::Edge const&)> const&) (g=..., enter=..., leave=..., stable_comparator=..., edge_filter=...) at external/org_tensorflow/tensorflow/core/graph/algorithm.cc:93\r\n#3  0x00007ff3cc907a53 in tensorflow::GetPostOrder(tensorflow::Graph const&, std::vector<tensorflow::Node*, std::allocator<tensorflow::Node*> >*, std::function<bool (tensorflow::Node const*, tensorflow::Node const*)> const&, std::function<bool (tensorflow::Edge const&)> const&) (g=..., \r\n    order=0x7ffcdfbe9850, stable_comparator=..., edge_filter=...) at external/org_tensorflow/tensorflow/core/graph/algorithm.cc:207\r\n#4  0x00007ff3cbebc567 in tensorflow::tensorturbo::convert::ConvertAfterShapes (params=...) at convert/tt_convert_graph.cc:578\r\n#5  0x00007ff3cbed5d50 in tensorflow::tensorturbo::convert::TTOptimizationPass::Optimize (this=0x7ffcdfbea910, cluster=0x0, item=..., \r\n    optimized_graph=0x7ffcdfbea6f0) at convert/tt_optimization_pass.cc:97\r\n#6  0x00007ff3cbe6ca82 in <lambda(const pybind11::bytes&, bool, const string&)>::operator()(const pybind11::bytes &, bool, const std::__cxx11::string &) const (__closure=0x55986103aff8, serialized_metagraph=..., verbose=false, graph_id=\"graph_to_optimize\")\r\n    at convert/tt_optimizer_wrapper.cc:63\r\n#7  0x00007ff3cbe6d7a2 in pybind11::detail::argument_loader<pybind11::bytes const&, bool, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&>::call_impl<pybind11::bytes, pybind11_init__pywrap_tt_optimizer(pybind11::module&)::<lambda(const pybind11::bytes&, bool, const string&)>&, 0, 1, 2, pybind11::detail::void_type>(<lambda(const pybind11::bytes&, bool, const string&)> &, std::index_sequence, pybind11::detail::void_type &&) (this=0x7ffcdfbeab50, f=...)\r\n    at bazel-out/k8-dbg/bin/external/pybind11/_virtual_includes/pybind11/pybind11/cast.h:1935\r\n#8  0x00007ff3cbe6d1b6 in pybind11::detail::argument_loader<pybind11::bytes const&, bool, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&>::call<pybind11::bytes, pybind11::detail::void_type, pybind11_init__pywrap_tt_optimizer(pybind11::module&)::<lambda(const pybind11::bytes&, bool, const string&)>&>(<lambda(const pybind11::bytes&, bool, const string&)> &) (this=0x7ffcdfbeab50, f=...)\r\n    at bazel-out/k8-dbg/bin/external/pybind11/_virtual_includes/pybind11/pybind11/cast.h:1912\r\n#9  0x00007ff3cbe6cf01 in pybind11::cpp_function::<lambda(pybind11::detail::function_call&)>::operator()(pybind11::detail::function_call &) const (__closure=0x0, call=...) at bazel-out/k8-dbg/bin/external/pybind11/_virtual_includes/pybind11/pybind11/pybind11.h:159\r\n#10 0x00007ff3cbe6cfae in pybind11::cpp_function::<lambda(pybind11::detail::function_call&)>::_FUN(pybind11::detail::function_call &) ()\r\n    at bazel-out/k8-dbg/bin/external/pybind11/_virtual_includes/pybind11/pybind11/pybind11.h:137\r\n#11 0x00007ff3cbe7724a in pybind11::cpp_function::dispatcher (self=0x7ff3cd9e6f30, args_in=0x7ff33425d640, kwargs_in=0x0)\r\n    at bazel-out/k8-dbg/bin/external/pybind11/_virtual_includes/pybind11/pybind11/pybind11.h:624\r\n#12 0x000055985cdbff76 in cfunction_call_varargs (kwargs=<optimized out>, args=<optimized out>, func=0x7ff3cdcbfbd0)\r\n    at /tmp/build/80754af9/python_1599203911753/work/Objects/call.c:742\r\n\r\n\r\n![image](https://user-images.githubusercontent.com/15120783/117979468-83d86d80-b365-11eb-8fa3-38a03fe74f78.png)\r\n\r\nIn release mode, here is not nullptr, otherwise in Debug mode, the nullptr causes core dump.\r\nWhy?\r\n\r\n", "comments": []}, {"number": 49133, "title": "the input->params.scale must equal to output->params.scale of the pooling node", "body": "Hi,\r\n     Recently, i found that inside the pooling.cc, it will assert the input->params.scale and the output->params.scale,\r\n![image](https://user-images.githubusercontent.com/49855018/117932150-a1d8aa80-b332-11eb-9fa1-237550d923aa.png)\r\nwhen using a quantization model which has a average pool or max pool.\r\n     But when the kernel size of the pooling node is not equal to the input size, the right and the bottom will be discarded with valid padding. When the max value is just at there, then we can make sure the max value of the maxpooling layer is still the same with the input node.\r\n    Also when we use the avg pool, the max value of the output can not be the same with the input, will always be smaller.\r\n   So, i want to ask, why we assert the max value of the input / output scale is same?\r\n\r\nRegards,\r\n    Crist\r\n\r\n\r\n", "comments": ["In order to prevent additional quantization error from re-quantization and improve latency, for pooling operations, we keep the input scale and output scale the same during conversion."]}, {"number": 49043, "title": "Batch segment reduce function", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 1.15 (It's natural to update the feature in tf 2.x. And it's much better if the feature can be added in tf 1.x too)\r\n- Are you willing to contribute it (Yes/No): Yes. I would try.\r\n\r\n**Describe the feature and the current behavior/state.**\r\n   Thanks for providing tensorflow framework and it's quit efficient to use `tf.math.segment_x` for some manipulations. Howerver,  we usually use batch training in deep learning pipeline. So, I'm eager for the function family like `tf.math.batch_segment_x`. Here is the api description for one example:\r\nBatch segment reduce sum:\r\n`tf.math.batch_segment_sum(data, batch_segment_ids, max_seq_len, mask_vals, name)`\r\n- `data`: Tensor whose rank >= 2  \r\n- `batch_segment_ids`: Tensor or list whose rank == 2; Sorted; `batch_segment_ids.shape[0] == data.shape[0]`\r\n- `max_seq_len`: Scalar. Different instances in a batch may have different segmentation. Some length is larger(max value in `batch_segment_ids[i, :]`, some is small. This is for length alignment in a batch.  Clip while length of one instance(`data[i, :, ..., :]`) after op is larger than `max_seq_len`; Mask while smaller.\r\n- `mask_vals`: Scalar or 1D tensor. If it's 1D tensor, it's length must be equal with `data.shape[0]`. Mask vals for instances in a batch. Scalar means all mask value is same. Tensor for different vals with different instances.\r\n\r\n**Will this change the current api? How?**\r\nYes. Some new api will be added into `tf.math`, like `tf.math.batch_segment_sum`, `tf.math.batch_segment_max`, `tf.math.batch_segment_min`, etc.\r\n\r\n**Who will benefit with this feature?**\r\nSomeone who often work with sequence model and need some feature engineering or some  complex manipulation in a model. \r\nHope this feature request issue can be achieved and I appreciate a lot for all the development work about this issue.\r\n\r\n**Any Other info.**\r\nIt would be better if `tf.math.batch_unsorted_segment_x` api can be added.", "comments": ["Have you tried using [tensorflow bucketize op](https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/bucketize)?\r\nDoes it work for your case?\r\n```python\r\nfrom tensorflow.python.ops import math_ops\r\ninput = [[-5, 10000], [150, 10], [5, 100]]\r\nboundaries = [0, 10, 100]\r\nnew_tensor = math_ops._bucketize(input, boundaries=boundaries)\r\nprint(new_tensor)\r\n==>\r\ntf.Tensor(\r\n[[0 3]\r\n [3 2]\r\n [1 3]], shape=(3, 2), dtype=int32)\r\n```", "Well, I learned that `math_ops._bucketize` is for catergorize the batch_data. This op doesn't change the shape of the input tensor. But `math.batch_segment_x`(or `match.batch_unsorted_segment_x`) will change each vector size along the first dimension of the input tensor(batch_size dimension) and do the size alignment. `math.batch_segment_x` is the extension of `math.segment_x` for batch data. \r\n\r\nI've tried to figure out using `math_ops._bucketize` to solve the case but failed.\r\n\r\nActually, I've found the _solution_ using the combination of `tf.while_loop` and `math.segment_x` for the case, loop along the first dimension, do `math.segment_x` for each vector and do size alignment. But this is time-consuming in _forward stage_ during training and prediction, because it will loop along the batch dimension. Thus, I'm eager for the low-level api for the case that can fully utilize fast characteristic of C++ to avoid time-consuming issue.\r\n\r\nHere is the _solution_ code, hope this can help you for logic understanding and development work:\r\n```\r\ndef batch_segment_op(batch_data, \r\n                     batch_segment_ids,\r\n                     align_size,\r\n                     min_data_val = None,\r\n                     max_data_val = None,\r\n                     reduce_type='sum', name=None, **kwargs):\r\n    \"\"\"batch segment reduce operation for seq tensor. \r\n    \r\n    This is the extention of `tf.math.segment_x` in batch scene. Segment reduction along the SECOND dimension(seq dimension) in batch.\r\n    Args:\r\n      batch_data: Tensor; rank>=2; Shape: (N, S0,...Sn)\r\n      batch_segment_ids: Tensor; rank==2; Shape: (N, S)\r\n      align_size: Scalar; max_len after segment reduce for each instance in a batch\r\n      reduce_type: str; x in {'sum','max','min','mean','prod'} for tf.math.segment_x\r\n    \"\"\"\r\n    segment_op = None\r\n    if reduce_type == 'sum':\r\n        segment_op = tf.math.unsorted_segment_sum\r\n    elif reduce_type == 'max':\r\n        if min_data_val is None:\r\n            raise ValueError(\"\"\"You have to specify `min_data_val` when reduce\r\n                              type is 'max' for masking default value(which is numeric_limits<T>::lowest())\r\n                              of missing seg_ids to zero\"\"\")\r\n        segment_op = tf.math.unsorted_segment_max\r\n    elif reduce_type == 'min':\r\n        if max_data_val is None:\r\n            raise ValueError(\"\"\"You have to specify `max_data_val` when reduce\r\n                              type is 'min' for masking default value(which is numeric_limits<T>::max())\r\n                              of missing seg_ids to zero\"\"\")\r\n        segment_op = tf.math.unsorted_segment_min\r\n    elif reduce_type == 'mean':\r\n        segment_op = tf.math.unsorted_segment_mean\r\n    elif reduce_type == 'prod':\r\n        segment_op = tf.math.unsorted_segment_prod\r\n    else:\r\n        raise ValueError(\"Unsupported type for `reduce_type`; Only support in {'sum','max','min','mean','prod'}\")\r\n    \r\n    batch_segid_min = tf.reduce_min(batch_segment_ids, axis=1, keepdims=True)\r\n    batch_segment_ids = batch_segment_ids - batch_segid_min\r\n    batch_num_segments = tf.reduce_max(batch_segment_ids, axis=1)\r\n    batch_num_segments = tf.math.maximum(batch_num_segments, align_size)+1\r\n    \r\n    output_ta = tf.TensorArray(dtype=batch_data.dtype, \r\n                               size = 0,\r\n                               dynamic_size = True)\r\n    def cond(batch_data, \r\n             batch_seg,\r\n             align_size, output, i):\r\n        return tf.less(i, tf.shape(batch_data)[0])\r\n    \r\n    def body(batch_data, \r\n             batch_seg,\r\n             align_size, output, i):\r\n        seg_data = segment_op(batch_data[i], batch_segment_ids[i], batch_num_segments[i])\r\n        seg_data = seg_data[:align_size]\r\n        if reduce_type == 'min':\r\n            seg_data = tf.where(seg_data <= max_data_val, \r\n                                seg_data, \r\n                                tf.zeros_like(seg_data))\r\n        if reduce_type == 'max':\r\n            seg_data = tf.where(seg_data >= min_data_val,\r\n                                seg_data,\r\n                                tf.zeros_like(seg_data))\r\n        output = output.write(i, seg_data)\r\n        return batch_data, batch_seg, align_size, output, i+1\r\n\r\n    _, _, _, output_op, _ = \\\r\n        tf.while_loop(cond, body, \r\n                      [batch_data, \r\n                       batch_segment_ids,\r\n                       align_size, output_ta, 0]\r\n                     )\r\n    return output_op.stack(name=name)\r\n```\r\n\r\n\r\n"]}, {"number": 49012, "title": "MobileBert inference with TFlite GPU delegate", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version: (2.6.0)\r\n- Are you willing to contribute it: (No)\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\n**Requested feature**: Add support for [mobilebert](https://tfhub.dev/tensorflow/lite-model/mobilebert/1/metadata/1) model/operations in [TFlite GPU delegate](https://www.tensorflow.org/lite/performance/gpu)\r\n\r\n\r\n**Current behaviour**: I'm trying to use the TFlite GPU delegate for mobilbert TFlite model inference. I'm using [TFlite benchmark tool](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/tools/benchmark), with the GPU delegate enabled, to run the model. The inference automatically goes to the CPU backend with the following Info/Error:\r\n\r\n```\r\nINFO: Created TensorFlow Lite delegate for GPU.\r\nERROR: tensorflow/lite/core/subgraph.cc:1169 node_index >= 0 was not true.\r\nERROR: Couldn't get node and registration info for op: -1793924896\r\n\r\nINFO: Created 0 GPU delegate kernels.\r\nThough GPU delegate is explicitly applied, the model graph will not be executed by the delegate.\r\n\r\n```\r\nand then continues to run on the CPU.\r\n\r\nI'm not sure what this error means. I know that the TFlite GPU delegate only supports a handful of [models and operations](https://www.tensorflow.org/lite/performance/gpu#supported_models_and_ops). So I guess it is a support issue. However, the error does not seem to me a support issue because, I should have just received a warning as described [here](https://www.tensorflow.org/lite/performance/gpu#non-supported_models_and_ops) reporting the unsupported Ops.\r\n\r\nI could not understand what node_index means and what makes it positive or negative.\r\n\r\nSince the supported models runs perfectly with no errors , I speculated that it's a support issue.\r\n\r\n\r\n\r\n\r\n**Will this change the current api? How?**\r\nNot sure\r\n\r\n**Who will benefit with this feature?**\r\nWho is interested in accelerating BERT on mobile GPUs\r\n\r\n**Any Other info.**\r\n", "comments": ["@renjie-liu could you take a look?", "Please use the gpu version here: https://github.com/mlcommons/mobile_models/blob/main/v0_7/tflite/mobilebert_float_384_gpu.tflite\r\n\r\nThanks", "@renjie-liu  Thanks for the link.  Do you know where I can find the source training code (that trains mobilebert for gpu)? or what I should do differently to have a version working for mobile gpus? \r\n\r\nMuch appreciated. ", "The training code is the same as the other models except the conversion is a little bit different (the conversion tool is not open-sourced yet, will do later)", "@renjie-liu Great to know you will open-source it, could you please just notify me when you do? I need to experiment with different mobilebert configurations and that will help a lot. \r\n\r\nAlso it seems that the gpu model **still has operations that are not supported by the TFlite GPU delegate**  (CAST, GATHER, MUL, RESHAPE, UNPACK), and the model gets split on both CPU and the GPU. \r\n\r\n**Here is the output when I run it with  TFlite GPU delegate with OpenCL backend**:\r\n\r\n```\r\nSTARTING!\r\nLog parameter values verbosely: [0]\r\nMin num runs: [1]\r\n**Graph**: [mobilebert_float_384_gpu.tflite]\r\n**Use gpu**: [1]\r\nLoaded model mobilebert_float_384_gpu.tflite\r\n**INFO**: Created TensorFlow Lite delegate for GPU.\r\n**ERROR**: Following operations are not supported by GPU delegate:\r\nCAST: Not supported cast case\r\nGATHER: Operation is not supported.\r\nMUL: MUL requires one tensor that not less than second in all dimensions.\r\nRESHAPE: OP is supported, but tensor type isn't matched!\r\nUNPACK: Operation is not supported.\r\n**2661 operations will run on the GPU, and the remaining 81 operations will run on the CPU.**\r\nINFO: Initialized OpenCL-based API.\r\nINFO: Created 1 GPU delegate kernels.\r\nExplicitly applied GPU delegate, and the model graph will be partially executed by the delegate w/ 1 delegate kernels.\r\nThe input model file size (MB): 100.239\r\nInitialized session in 2491.9ms.\r\nRunning benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.\r\ncount=2 first=434022 curr=247839 min=247839 max=434022 avg=340930 std=93091\r\n```\r\nDo you get the same when you run it?\r\n\r\nThanks."]}, {"number": 49011, "title": "tflite int8 12x times slower than float32", "body": "Please check this colab to reproduce for huggingface gpt2 model\r\n\r\nhttps://colab.research.google.com/drive/1DNTPR_GgidU8Jve0zoDI1MfoqWQ0L06n?usp=sharing\r\n", "comments": ["@liyunlu0618 could you triage this issue?"]}, {"number": 49000, "title": "Random rotation, flip, translation, and zoom for 3D data? ", "body": "Does TF have any plan to support 3D random transform layers? or why not? Or is there already an experimental version or some other contributions on github related to this? Thanks\r\n", "comments": ["You  can check our repos:\r\nhttps://github.com/tensorflow/graphics\r\nhttps://ai.googleblog.com/2021/02/3d-scene-understanding-with-tensorflow.html\r\nhttps://github.com/google-research/google-research/tree/master/tf3d"]}, {"number": 48967, "title": "Get HLO PROTO from TF (in python)", "body": "Hi,\r\n\r\nI'm using `experimental_get_compiler_ir` to extract the HLO-IR of functions written in TF2. \r\nHowever, hitting some issues and was wondering if there is an API from TF, that exposes the proto format, something similar to what `JAX` does like here:\r\n[xla_computation](https://jax.readthedocs.io/en/latest/jax.html#jax.xla_computation\r\n) with the `as_serialized_hlo_module_proto`. \r\n\r\nThere is probably a better way to go from TF code (in python) to HLO PROTO, but even when I'm using `experimental_get_compiler_ir`, maybe you could just allow this function to not serialize the result:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/jit/get_compiler_ir.cc#L136\r\n\r\nThanks!\r\n", "comments": ["hi @KatiaSN602 , selecting `optimized_hlo_proto_serialized ` (https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/jit/get_compiler_ir.h#L35) should give you back the proto, is that your question?"]}]