[{"number": 39177, "title": "tf.keras.layers.experimental.preprocessing.RandomXXX API is missing \"nearest\" as an option for fill_mode.", "body": "**System information**\r\n- TensorFlow version (you are using): 2.2.0-dev20200504\r\n- Are you willing to contribute it (Yes/No): Yes (but really depends on the technicality)\r\n\r\n**Describe the feature and the current behavior/state.**\r\ntf.keras.layers.experimental.preprocessing.RandomTranslation's argument \"fill_mode\" should accept the value of \"nearest\". This should be available to all relevant data augmentation experimental API that will inherit from Layer. fill_mode of \"nearest\" is the default for tf.keras.preprocessing.image.ImageDataGenerator. \r\n\r\n**Will this change the current api? How?**\r\nThis is about adding an extra fill_mode option for \"nearest\". It should be there since this is the default for the older Keras API (for data augmentation). This will allow apple to apple comparison to reproduce results.\r\n\r\n**Who will benefit with this feature?**\r\n\r\n\r\n**Any Other info.**\r\n", "comments": ["you can set 'nearest' to `interpolation`", "To be more specific:\r\n -- we have `fill_mode` which stands for when the output coordinate is valid, but our compute for  equivalent input coordinate is out of range, so `reflect`, `wrap`, `constant` are valid modes. For example, in order to fill the value for output coordinate (0, 0), the equivalent value from input coordinate should be (-1, -1), since there's not value at (-1, -1), `reflect` mode might tell us (-1, -1) is same as (1, 1), so output[0][0] = input[1][1].\r\n -- we have `interpolation` which stands for when the computed equivalent input coordinate is a float, not int. In this case, `nearest` and `bilinear` are valid modes. -- potential extra mode is spline interpolation, which is what scipy supports today. For example, if output[0][0] should be filled with input[0.5][0.5], using `nearest` it will be same as input[1][1], but using `bilinear` means it will be interpolated from input[0][0], input[0][1], input[1][0], and input[1][1]", "@tanzhenyu I used the old keras data augmentation API for a while now, I am pretty sure I don't want interpolation to \"nearest\". I really want fill_mode to be \"nearest\". The effect is that, for example, if you right shift the image, the \"void\" is filled by copying the edge pixel of the photo over and over until you fill up that void. \r\n\r\nKeras actually used this as the default. I may guess that most ppl find it reasonable choice for most image tasks. So leaving this out of the new API is not ideal.", "> @tanzhenyu I used the old keras data augmentation API for a while now, I am pretty sure I don't want interpolation to \"nearest\". I really want fill_mode to be \"nearest\". The effect is that, for example, if you right shift the image, the \"void\" is filled by copying the edge pixel of the photo over and over until you fill up that void.\r\n> \r\n> Keras actually used this as the default. I may guess that most ppl find it reasonable choice for most image tasks. So leaving this out of the new API is not ideal.\r\n\r\nIn that case you may end up with the `main` content of your image being masked out. `reflect` in this case would honestly work better. ", "@tanzhenyu Not sure what you mean by \"masked out\" exactly. But minor masking out is sometimes what data augmentation intends to do??, e.g. crop out, or randomly obscuring part of object. Also, optimal image augmentation is domain specific, so don't need to say which work better or worse. FYI: I did try \"reflect\" for my task, and i obtained slightly worse accuracy (although I can't robustly attribute it to this choice. \r\n\r\nThis feature is after all in Keras for over 2 years and it is the default. If the broader TF community think it ought to not exist, I am fine with that. I will just have to implement my own... ", "> @tanzhenyu Not sure what you mean by \"masked out\" exactly. But minor masking out is sometimes what data augmentation intends to do??, e.g. crop out, or randomly obscuring part of object. Also, optimal image augmentation is domain specific, so don't need to say which work better or worse. FYI: I did try \"reflect\" for my task, and i obtained slightly worse accuracy (although I can't robustly attribute it to this choice.\r\n> \r\n> This feature is after all in Keras for over 2 years and it is the default. If the broader TF community think it ought to not exist, I am fine with that. I will just have to implement my own...\r\n\r\nWhat do you mean by default for Keras?", "@tanzhenyu \r\n\r\nhttps://keras.io/api/preprocessing/image/#imagedatagenerator-class\r\n\r\ntf.keras.preprocessing.image.ImageDataGenerator(\r\n...\r\nchannel_shift_range=0.0,\r\nfill_mode=\"nearest\",\r\ncval=0.0,\r\n...\r\n)", "> @tanzhenyu\r\n> \r\n> https://keras.io/api/preprocessing/image/#imagedatagenerator-class\r\n> \r\n> tf.keras.preprocessing.image.ImageDataGenerator(\r\n> ...\r\n> channel_shift_range=0.0,\r\n> fill_mode=\"nearest\",\r\n> cval=0.0,\r\n> ...\r\n> )\r\n\r\nMakes sense. We could support this mode, but it wouldn't be default, and probably I wouldn't be able to make it before 2.3. If you need this, contribution welcome!", "@tanzhenyu Thanks. I am not sure when I could spend time on this due to other things I need to do. I actually tried used \"constant\" in my current task and it is performing about the same as \"nearest\", so it isn't a big issue. \r\n\r\nIf I come around to try implement this, I will post a PR. ", "This is fixed by @WindQAQ "]}, {"number": 39176, "title": "Tensorflow lite conversion problem. Zero dimensions output node after conversion", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colaboratory\r\n- TensorFlow installed from (source or binary): Colaboratory default\r\n- TensorFlow version (or github SHA if from source):  2.2.0-rc3, Keras version: 2.3.0-tf\r\n\r\n\r\n**Command used to run the converter or code if you\u2019re using the Python API**\r\nIf possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n```\r\ntflite_model = tf.keras.models.load_model('saved_model/my_model')\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(tflite_model)\r\ntflite_save = converter.convert()\r\nopen(\"greek_smart_reply_model.tflite\", \"wb\").write(tflite_save)\r\n```\r\n**the output from keras model**\r\n\r\n```\r\nprint(new_model.get_input_shape_at(0))\r\nprint(new_model)\r\nfor node in model.outputs:\r\n  print(node)\r\n\r\n(None, 40)\r\n<tensorflow.python.keras.engine.sequential.Sequential object at 0x7f21efbcb240>\r\nTensor(\"dense/Identity:0\", shape=(None, 3), dtype=float32)\r\n\r\n```\r\n\r\n**The output from the converter invocation**\r\n\r\n```\r\ninterpreter = tf.lite.Interpreter('greek_smart_reply_model.tflite')\r\ninterpreter.allocate_tensors()\r\ninterpreter.get_tensor_details()\r\n\r\nOutput node:\r\n{'dtype': numpy.float32,\r\n  'index': 34,\r\n  'name': 'Identity',\r\n  'quantization': (0.0, 0),\r\n  'quantization_parameters': {'quantized_dimension': 0,\r\n   'scales': array([], dtype=float32),\r\n   'zero_points': array([], dtype=int32)},\r\n  'shape': array([], dtype=int32),\r\n  'shape_signature': array([], dtype=int32),\r\n  'sparsity_parameters': {}}\r\n\r\n-----------Shape is empty array and should be [1,3]\r\n```\r\n\r\n**Also, please include a link to the saved model or GraphDef**\r\n\r\n```\r\nhttps://drive.google.com/open?id=1cAUPhmL4OsGUStsLcdFxYoX6c4L7u5aE\r\n```\r\n\r\n**Failure details**\r\nIf the conversion is successful, but the generated model is wrong,\r\nstate what is wrong:\r\n- Producing wrong results: Despite the fact that keras model predicts fine in colaboratory and has exactly output [1,3] when I convert it in .tflite the output node has zero dimensions:\r\n\r\nOutput node:\r\n'dtype': numpy.float32,\r\n  'index': 34,\r\n  'name': 'Identity',\r\n  'quantization': (0.0, 0),\r\n  'quantization_parameters': {'quantized_dimension': 0,\r\n   'scales': array([], dtype=float32),\r\n   'zero_points': array([], dtype=int32)},\r\n  'shape': array([], dtype=int32),\r\n  'shape_signature': array([], dtype=int32),\r\n  'sparsity_parameters': {}}\r\n\r\nAND the same is stated when I load it inside android application:\r\n2020-05-05 09:45:16.036 28527-28748/com.george.fs_korinthias E/INPUT_TENSOR_WHOLE: [1, 40]\r\n2020-05-05 09:45:16.036 28527-28748/com.george.fs_korinthias E/INPUT_DATA_TYPE: FLOAT32\r\n2020-05-05 09:45:16.037 28527-28748/com.george.fs_korinthias E/OUTPUT_TENSOR_SHAPE: []\r\n2020-05-05 09:45:16.037 28527-28748/com.george.fs_korinthias E/OUTPUT_DATA_TYPE: FLOAT32\r\n\r\nWhen I state output of interpreter as [1,3] android gives:\r\n\r\n2020-05-05 09:55:07.570 29331-29421/com.george.fs_korinthias E/INPUT_TENSOR_WHOLE: [1, 40]\r\n2020-05-05 09:55:07.571 29331-29421/com.george.fs_korinthias E/INPUT_DATA_TYPE: FLOAT32\r\n2020-05-05 09:55:07.571 29331-29421/com.george.fs_korinthias E/OUTPUT_TENSOR_SHAPE: []\r\n2020-05-05 09:55:07.571 29331-29421/com.george.fs_korinthias E/OUTPUT_DATA_TYPE: FLOAT32\r\n2020-05-05 09:55:07.571 29331-29421/com.george.fs_korinthias E/DigitClassifier: Initialized TFLite interpreter.\r\n2020-05-05 09:55:07.989 29331-29331/com.george.fs_korinthias E/MainActivity_classifier: Error to setting up smart reply classifier.\r\n    java.lang.IllegalArgumentException: Cannot copy between a TensorFlowLite tensor with shape [] and a Java object with shape [1, 3].\r\n\r\nThank you in advance!!!!!\r\n\r\n\r\n\r\n\r\n**RNN conversion support**\r\nIf converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.\r\n\r\n**Any other info / logs**\r\n\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["Was able to reproduce the issue with TF v2.2.0-rc4 and TF-nightly. Please find the gist [here](https://colab.research.google.com/gist/amahendrakar/794a8c61cc7a4ea4a34fee5113a0c00b/39176.ipynb). Thanks!", "Model summary:\r\n\r\n```\r\n\r\nModel: \"sequential\"\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\nembedding (Embedding)        (None, 40, 20)            245560    \r\n_________________________________________________________________\r\nlstm (LSTM)                  (None, 64)                21760     \r\n_________________________________________________________________\r\ndense (Dense)                (None, 3)                 195       \r\n=================================================================\r\nTotal params: 267,515\r\nTrainable params: 267,515\r\nNon-trainable params: 0\r\n_________________________________________________________________\r\nNone\r\n\r\n```", "@farmaker47 I think this was resolved in recent `tf-nightly`. It printed correct `input_details` and `output_details` as expected and are shown below. Please check [gist here](https://colab.research.google.com/gist/jvishnuvardhan/4a8cb8a660c7289ef6058e4a740694ff/39176.ipynb).   \r\n\r\n#### `input_details` from `input_details = interpreter.get_input_details()`\r\n`[{'name': 'embedding_input', 'index': 0, 'shape': array([ 1, 40], dtype=int32), 'shape_signature': array([-1, 40], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]`\r\n\r\n#### output_details` from `output_details = interpreter.get_output_details()`\r\n`[{'name': 'Identity', 'index': 38, 'shape': array([1, 3], dtype=int32), 'shape_signature': array([-1,  3], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]`\r\n\r\n#### output for `interpreter.get_tensor_details()` is as follows\r\n```\r\n[{'dtype': numpy.float32,\r\n  'index': 0,\r\n  'name': 'embedding_input',\r\n  'quantization': (0.0, 0),\r\n  'quantization_parameters': {'quantized_dimension': 0,\r\n   'scales': array([], dtype=float32),\r\n   'zero_points': array([], dtype=int32)},\r\n  'shape': array([ 1, 40], dtype=int32),\r\n  'shape_signature': array([-1, 40], dtype=int32),\r\n  'sparsity_parameters': {}},\r\n {'dtype': numpy.float32,\r\n  'index': 1,\r\n  'name': 'sequential/dense/BiasAdd/ReadVariableOp/resource',\r\n  'quantization': (0.0, 0),\r\n  'quantization_parameters': {'quantized_dimension': 0,\r\n   'scales': array([], dtype=float32),\r\n   'zero_points': array([], dtype=int32)},\r\n  'shape': array([3], dtype=int32),\r\n  'shape_signature': array([3], dtype=int32),\r\n  'sparsity_parameters': {}},\r\n {'dtype': numpy.float32,\r\n  'index': 2,\r\n  'name': 'sequential/embedding/embedding_lookup/7264',\r\n  'quantization': (0.0, 0),\r\n  'quantization_parameters': {'quantized_dimension': 0,\r\n   'scales': array([], dtype=float32),\r\n   'zero_points': array([], dtype=int32)},\r\n  'shape': array([12278,    20], dtype=int32),\r\n  'shape_signature': array([12278,    20], dtype=int32),\r\n  'sparsity_parameters': {}},\r\n {'dtype': numpy.int32,\r\n  'index': 3,\r\n  'name': 'transpose/perm;sequential/lstm/PartitionedCall/transpose/perm',\r\n  'quantization': (0.0, 0),\r\n  'quantization_parameters': {'quantized_dimension': 0,\r\n   'scales': array([], dtype=float32),\r\n   'zero_points': array([], dtype=int32)},\r\n  'shape': array([3], dtype=int32),\r\n  'shape_signature': array([3], dtype=int32),\r\n  'sparsity_parameters': {}},\r\n {'dtype': numpy.float32,\r\n  'index': 4,\r\n  'name': 'sequential/lstm/Read_2/ReadVariableOp/resource',\r\n  'quantization': (0.0, 0),\r\n  'quantization_parameters': {'quantized_dimension': 0,\r\n   'scales': array([], dtype=float32),\r\n   'zero_points': array([], dtype=int32)},\r\n  'shape': array([256], dtype=int32),\r\n  'shape_signature': array([256], dtype=int32),\r\n  'sparsity_parameters': {}},\r\n {'dtype': numpy.int32,\r\n  'index': 5,\r\n  'name': 'sequential/lstm/zeros/packed/1',\r\n  'quantization': (0.0, 0),\r\n  'quantization_parameters': {'quantized_dimension': 0,\r\n   'scales': array([], dtype=float32),\r\n   'zero_points': array([], dtype=int32)},\r\n  'shape': array([], dtype=int32),\r\n  'shape_signature': array([], dtype=int32),\r\n  'sparsity_parameters': {}},\r\n {'dtype': numpy.int32,\r\n  'index': 6,\r\n  'name': 'TensorArrayV2_1;sequential/lstm/PartitionedCall/TensorArrayV2_1',\r\n  'quantization': (0.0, 0),\r\n  'quantization_parameters': {'quantized_dimension': 0,\r\n   'scales': array([], dtype=float32),\r\n   'zero_points': array([], dtype=int32)},\r\n  'shape': array([2], dtype=int32),\r\n  'shape_signature': array([2], dtype=int32),\r\n  'sparsity_parameters': {}},\r\n {'dtype': numpy.int32,\r\n  'index': 7,\r\n  'name': 'TensorArrayV2_1;sequential/lstm/PartitionedCall/TensorArrayV2_11',\r\n  'quantization': (0.0, 0),\r\n  'quantization_parameters': {'quantized_dimension': 0,\r\n   'scales': array([], dtype=float32),\r\n   'zero_points': array([], dtype=int32)},\r\n  'shape': array([], dtype=int32),\r\n  'shape_signature': array([], dtype=int32),\r\n  'sparsity_parameters': {}},\r\n {'dtype': numpy.float32,\r\n  'index': 8,\r\n  'name': 'TensorArrayV2_1;sequential/lstm/PartitionedCall/TensorArrayV2_12',\r\n  'quantization': (0.0, 0),\r\n  'quantization_parameters': {'quantized_dimension': 0,\r\n   'scales': array([], dtype=float32),\r\n   'zero_points': array([], dtype=int32)},\r\n  'shape': array([], dtype=int32),\r\n  'shape_signature': array([], dtype=int32),\r\n  'sparsity_parameters': {}},\r\n {'dtype': numpy.float32,\r\n  'index': 9,\r\n  'name': 'sequential/dense/MatMul',\r\n  'quantization': (0.0, 0),\r\n  'quantization_parameters': {'quantized_dimension': 0,\r\n   'scales': array([], dtype=float32),\r\n   'zero_points': array([], dtype=int32)},\r\n  'shape': array([ 3, 64], dtype=int32),\r\n  'shape_signature': array([ 3, 64], dtype=int32),\r\n  'sparsity_parameters': {}},\r\n {'dtype': numpy.int32,\r\n  'index': 10,\r\n  'name': 'sequential/lstm/strided_slice',\r\n  'quantization': (0.0, 0),\r\n  'quantization_parameters': {'quantized_dimension': 0,\r\n   'scales': array([], dtype=float32),\r\n   'zero_points': array([], dtype=int32)},\r\n  'shape': array([1], dtype=int32),\r\n  'shape_signature': array([1], dtype=int32),\r\n  'sparsity_parameters': {}},\r\n {'dtype': numpy.int32,\r\n  'index': 11,\r\n  'name': 'sequential/lstm/strided_slice1',\r\n  'quantization': (0.0, 0),\r\n  'quantization_parameters': {'quantized_dimension': 0,\r\n   'scales': array([], dtype=float32),\r\n   'zero_points': array([], dtype=int32)},\r\n  'shape': array([1], dtype=int32),\r\n  'shape_signature': array([1], dtype=int32),\r\n  'sparsity_parameters': {}},\r\n {'dtype': numpy.int32,\r\n  'index': 12,\r\n  'name': 'strided_slice_2;sequential/lstm/PartitionedCall/strided_slice_2',\r\n  'quantization': (0.0, 0),\r\n  'quantization_parameters': {'quantized_dimension': 0,\r\n   'scales': array([], dtype=float32),\r\n   'zero_points': array([], dtype=int32)},\r\n  'shape': array([3], dtype=int32),\r\n  'shape_signature': array([3], dtype=int32),\r\n  'sparsity_parameters': {}},\r\n {'dtype': numpy.int32,\r\n  'index': 13,\r\n  'name': 'strided_slice_2;sequential/lstm/PartitionedCall/strided_slice_21',\r\n  'quantization': (0.0, 0),\r\n  'quantization_parameters': {'quantized_dimension': 0,\r\n   'scales': array([], dtype=float32),\r\n   'zero_points': array([], dtype=int32)},\r\n  'shape': array([3], dtype=int32),\r\n  'shape_signature': array([3], dtype=int32),\r\n  'sparsity_parameters': {}},\r\n {'dtype': numpy.int32,\r\n  'index': 14,\r\n  'name': 'strided_slice_2;sequential/lstm/PartitionedCall/strided_slice_22',\r\n  'quantization': (0.0, 0),\r\n  'quantization_parameters': {'quantized_dimension': 0,\r\n   'scales': array([], dtype=float32),\r\n   'zero_points': array([], dtype=int32)},\r\n  'shape': array([3], dtype=int32),\r\n  'shape_signature': array([3], dtype=int32),\r\n  'sparsity_parameters': {}},\r\n {'dtype': numpy.int32,\r\n  'index': 15,\r\n  'name': 'sequential/embedding/Cast',\r\n  'quantization': (0.0, 0),\r\n  'quantization_parameters': {'quantized_dimension': 0,\r\n   'scales': array([], dtype=float32),\r\n   'zero_points': array([], dtype=int32)},\r\n  'shape': array([ 1, 40], dtype=int32),\r\n  'shape_signature': array([-1, 40], dtype=int32),\r\n  'sparsity_parameters': {}},\r\n {'dtype': numpy.float32,\r\n  'index': 16,\r\n  'name': 'sequential/embedding/embedding_lookup;TensorArrayV2_1;sequential/lstm/PartitionedCall/TensorArrayV2_1',\r\n  'quantization': (0.0, 0),\r\n  'quantization_parameters': {'quantized_dimension': 0,\r\n   'scales': array([], dtype=float32),\r\n   'zero_points': array([], dtype=int32)},\r\n  'shape': array([ 1, 40, 20], dtype=int32),\r\n  'shape_signature': array([-1, 40, 20], dtype=int32),\r\n  'sparsity_parameters': {}},\r\n {'dtype': numpy.int32,\r\n  'index': 17,\r\n  'name': 'sequential/lstm/Shape',\r\n  'quantization': (0.0, 0),\r\n  'quantization_parameters': {'quantized_dimension': 0,\r\n   'scales': array([], dtype=float32),\r\n   'zero_points': array([], dtype=int32)},\r\n  'shape': array([3], dtype=int32),\r\n  'shape_signature': array([3], dtype=int32),\r\n  'sparsity_parameters': {}},\r\n {'dtype': numpy.float32,\r\n  'index': 18,\r\n  'name': 'transpose;sequential/lstm/PartitionedCall/transpose',\r\n  'quantization': (0.0, 0),\r\n  'quantization_parameters': {'quantized_dimension': 0,\r\n   'scales': array([], dtype=float32),\r\n   'zero_points': array([], dtype=int32)},\r\n  'shape': array([40,  1, 20], dtype=int32),\r\n  'shape_signature': array([40, -1, 20], dtype=int32),\r\n  'sparsity_parameters': {}},\r\n {'dtype': numpy.int32,\r\n  'index': 19,\r\n  'name': 'Shape;sequential/lstm/PartitionedCall/Shape',\r\n  'quantization': (0.0, 0),\r\n  'quantization_parameters': {'quantized_dimension': 0,\r\n   'scales': array([], dtype=float32),\r\n   'zero_points': array([], dtype=int32)},\r\n  'shape': array([3], dtype=int32),\r\n  'shape_signature': array([3], dtype=int32),\r\n  'sparsity_parameters': {}},\r\n {'dtype': numpy.int32,\r\n  'index': 20,\r\n  'name': 'strided_slice;sequential/lstm/PartitionedCall/strided_slice',\r\n  'quantization': (0.0, 0),\r\n  'quantization_parameters': {'quantized_dimension': 0,\r\n   'scales': array([], dtype=float32),\r\n   'zero_points': array([], dtype=int32)},\r\n  'shape': array([], dtype=int32),\r\n  'shape_signature': array([], dtype=int32),\r\n  'sparsity_parameters': {}},\r\n {'dtype': numpy.int32,\r\n  'index': 21,\r\n  'name': 'TensorArrayV2_1;sequential/lstm/PartitionedCall/TensorArrayV2_13',\r\n  'quantization': (0.0, 0),\r\n  'quantization_parameters': {'quantized_dimension': 0,\r\n   'scales': array([], dtype=float32),\r\n   'zero_points': array([], dtype=int32)},\r\n  'shape': array([1], dtype=int32),\r\n  'shape_signature': array([1], dtype=int32),\r\n  'sparsity_parameters': {}},\r\n {'dtype': numpy.int32,\r\n  'index': 22,\r\n  'name': 'TensorArrayV2_1;sequential/lstm/PartitionedCall/TensorArrayV2_14',\r\n  'quantization': (0.0, 0),\r\n  'quantization_parameters': {'quantized_dimension': 0,\r\n   'scales': array([], dtype=float32),\r\n   'zero_points': array([], dtype=int32)},\r\n  'shape': array([3], dtype=int32),\r\n  'shape_signature': array([3], dtype=int32),\r\n  'sparsity_parameters': {}},\r\n {'dtype': numpy.float32,\r\n  'index': 23,\r\n  'name': 'TensorArrayV2_1;sequential/lstm/PartitionedCall/TensorArrayV2_15',\r\n  'quantization': (0.0, 0),\r\n  'quantization_parameters': {'quantized_dimension': 0,\r\n   'scales': array([], dtype=float32),\r\n   'zero_points': array([], dtype=int32)},\r\n  'shape': array([1, 1, 1], dtype=int32),\r\n  'shape_signature': array([-1, -1, -1], dtype=int32),\r\n  'sparsity_parameters': {}},\r\n {'dtype': numpy.int32,\r\n  'index': 24,\r\n  'name': 'sequential/lstm/strided_slice2',\r\n  'quantization': (0.0, 0),\r\n  'quantization_parameters': {'quantized_dimension': 0,\r\n   'scales': array([], dtype=float32),\r\n   'zero_points': array([], dtype=int32)},\r\n  'shape': array([], dtype=int32),\r\n  'shape_signature': array([], dtype=int32),\r\n  'sparsity_parameters': {}},\r\n {'dtype': numpy.int32,\r\n  'index': 25,\r\n  'name': 'sequential/lstm/zeros/packed',\r\n  'quantization': (0.0, 0),\r\n  'quantization_parameters': {'quantized_dimension': 0,\r\n   'scales': array([], dtype=float32),\r\n   'zero_points': array([], dtype=int32)},\r\n  'shape': array([2], dtype=int32),\r\n  'shape_signature': array([2], dtype=int32),\r\n  'sparsity_parameters': {}},\r\n {'dtype': numpy.float32,\r\n  'index': 26,\r\n  'name': 'sequential/lstm/zeros',\r\n  'quantization': (0.0, 0),\r\n  'quantization_parameters': {'quantized_dimension': 0,\r\n   'scales': array([], dtype=float32),\r\n   'zero_points': array([], dtype=int32)},\r\n  'shape': array([ 1, 64], dtype=int32),\r\n  'shape_signature': array([-1, 64], dtype=int32),\r\n  'sparsity_parameters': {}},\r\n {'dtype': numpy.int32,\r\n  'index': 27,\r\n  'name': 'while;sequential/lstm/PartitionedCall/while',\r\n  'quantization': (0.0, 0),\r\n  'quantization_parameters': {'quantized_dimension': 0,\r\n   'scales': array([], dtype=float32),\r\n   'zero_points': array([], dtype=int32)},\r\n  'shape': array([], dtype=int32),\r\n  'shape_signature': array([], dtype=int32),\r\n  'sparsity_parameters': {}},\r\n {'dtype': numpy.int32,\r\n  'index': 28,\r\n  'name': 'while;sequential/lstm/PartitionedCall/while1',\r\n  'quantization': (0.0, 0),\r\n  'quantization_parameters': {'quantized_dimension': 0,\r\n   'scales': array([], dtype=float32),\r\n   'zero_points': array([], dtype=int32)},\r\n  'shape': array([], dtype=int32),\r\n  'shape_signature': array([], dtype=int32),\r\n  'sparsity_parameters': {}},\r\n {'dtype': numpy.float32,\r\n  'index': 29,\r\n  'name': 'while;sequential/lstm/PartitionedCall/while2',\r\n  'quantization': (0.0, 0),\r\n  'quantization_parameters': {'quantized_dimension': 0,\r\n   'scales': array([], dtype=float32),\r\n   'zero_points': array([], dtype=int32)},\r\n  'shape': array([1, 1, 1], dtype=int32),\r\n  'shape_signature': array([-1, -1, -1], dtype=int32),\r\n  'sparsity_parameters': {}},\r\n {'dtype': numpy.float32,\r\n  'index': 30,\r\n  'name': 'while;sequential/lstm/PartitionedCall/while3',\r\n  'quantization': (0.0, 0),\r\n  'quantization_parameters': {'quantized_dimension': 0,\r\n   'scales': array([], dtype=float32),\r\n   'zero_points': array([], dtype=int32)},\r\n  'shape': array([ 1, 64], dtype=int32),\r\n  'shape_signature': array([-1, 64], dtype=int32),\r\n  'sparsity_parameters': {}},\r\n {'dtype': numpy.float32,\r\n  'index': 31,\r\n  'name': 'while;sequential/lstm/PartitionedCall/while4',\r\n  'quantization': (0.0, 0),\r\n  'quantization_parameters': {'quantized_dimension': 0,\r\n   'scales': array([], dtype=float32),\r\n   'zero_points': array([], dtype=int32)},\r\n  'shape': array([ 1, 64], dtype=int32),\r\n  'shape_signature': array([-1, 64], dtype=int32),\r\n  'sparsity_parameters': {}},\r\n {'dtype': numpy.int32,\r\n  'index': 32,\r\n  'name': 'while;sequential/lstm/PartitionedCall/while5',\r\n  'quantization': (0.0, 0),\r\n  'quantization_parameters': {'quantized_dimension': 0,\r\n   'scales': array([], dtype=float32),\r\n   'zero_points': array([], dtype=int32)},\r\n  'shape': array([], dtype=int32),\r\n  'shape_signature': array([], dtype=int32),\r\n  'sparsity_parameters': {}},\r\n {'dtype': numpy.float32,\r\n  'index': 33,\r\n  'name': 'while;sequential/lstm/PartitionedCall/while6',\r\n  'quantization': (0.0, 0),\r\n  'quantization_parameters': {'quantized_dimension': 0,\r\n   'scales': array([], dtype=float32),\r\n   'zero_points': array([], dtype=int32)},\r\n  'shape': array([40,  1, 20], dtype=int32),\r\n  'shape_signature': array([40, -1, 20], dtype=int32),\r\n  'sparsity_parameters': {}},\r\n {'dtype': numpy.int32,\r\n  'index': 34,\r\n  'name': 'TensorArrayV2Stack/TensorListStack;sequential/lstm/PartitionedCall/TensorArrayV2Stack/TensorListStack',\r\n  'quantization': (0.0, 0),\r\n  'quantization_parameters': {'quantized_dimension': 0,\r\n   'scales': array([], dtype=float32),\r\n   'zero_points': array([], dtype=int32)},\r\n  'shape': array([3], dtype=int32),\r\n  'shape_signature': array([3], dtype=int32),\r\n  'sparsity_parameters': {}},\r\n {'dtype': numpy.float32,\r\n  'index': 35,\r\n  'name': 'TensorArrayV2Stack/TensorListStack;sequential/lstm/PartitionedCall/TensorArrayV2Stack/TensorListStack1',\r\n  'quantization': (0.0, 0),\r\n  'quantization_parameters': {'quantized_dimension': 0,\r\n   'scales': array([], dtype=float32),\r\n   'zero_points': array([], dtype=int32)},\r\n  'shape': array([1, 1, 1], dtype=int32),\r\n  'shape_signature': array([-1, -1, -1], dtype=int32),\r\n  'sparsity_parameters': {}},\r\n {'dtype': numpy.float32,\r\n  'index': 36,\r\n  'name': 'strided_slice_2;sequential/lstm/PartitionedCall/strided_slice_23',\r\n  'quantization': (0.0, 0),\r\n  'quantization_parameters': {'quantized_dimension': 0,\r\n   'scales': array([], dtype=float32),\r\n   'zero_points': array([], dtype=int32)},\r\n  'shape': array([1, 1], dtype=int32),\r\n  'shape_signature': array([-1, -1], dtype=int32),\r\n  'sparsity_parameters': {}},\r\n {'dtype': numpy.float32,\r\n  'index': 37,\r\n  'name': 'sequential/dense/BiasAdd',\r\n  'quantization': (0.0, 0),\r\n  'quantization_parameters': {'quantized_dimension': 0,\r\n   'scales': array([], dtype=float32),\r\n   'zero_points': array([], dtype=int32)},\r\n  'shape': array([1, 3], dtype=int32),\r\n  'shape_signature': array([-1,  3], dtype=int32),\r\n  'sparsity_parameters': {}},\r\n {'dtype': numpy.float32,\r\n  'index': 38,\r\n  'name': 'Identity',\r\n  'quantization': (0.0, 0),\r\n  'quantization_parameters': {'quantized_dimension': 0,\r\n   'scales': array([], dtype=float32),\r\n   'zero_points': array([], dtype=int32)},\r\n  'shape': array([1, 3], dtype=int32),\r\n  'shape_signature': array([-1,  3], dtype=int32),\r\n  'sparsity_parameters': {}}]\r\n```\r\n\r\nPlease close the issue if this was resolved for you. Thanks!", "@jvishnuvardhan Yes! It works and prints correct output node shape.\r\nI figured during notebook execution that with this tf-nightly it cannot load Tensorboard with the provided code snippet from official Tensorflow documentation\r\n\r\n%load_ext tensorboard\r\n%tensorboard --logdir logs/fit\r\n\r\nIt gives below error:\r\n\r\nERROR: Failed to launch TensorBoard (exited with 1).\r\nContents of stderr:\r\n2020-05-06 04:51:39.908137: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\r\nTraceback (most recent call last):\r\n  File \"/usr/local/bin/tensorboard\", line 8, in <module>\r\n    sys.exit(run_main())\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/main.py\", line 75, in run_main\r\n    app.run(tensorboard.main, flags_parser=tensorboard.configure)\r\n  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\r\n    _run_main(main, args)\r\n  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/program.py\", line 289, in main\r\n    return runner(self.flags) or 0\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/program.py\", line 305, in _run_serve_subcommand\r\n    server = self._make_server()\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/program.py\", line 409, in _make_server\r\n    self.flags, self.plugin_loaders, self.assets_zip_provider\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/backend/application.py\", line 157, in standard_tensorboard_wsgi\r\n    flags, plugin_loaders, data_provider, assets_zip_provider, multiplexer\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/backend/application.py\", line 236, in TensorBoardWSGIApp\r\n    tbplugins, flags.path_prefix, data_provider, experimental_plugins\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/backend/application.py\", line 309, in __init__\r\n    \"Duplicate plugins for name %s\" % plugin.plugin_name\r\nValueError: Duplicate plugins for name projector\r\n\r\n\r\nBut I don't know if this is your responsibility..\r\n\r\nThank you for your time!!", "I changed uninstall tensorflow to below code and Tensorboard shows graph correctly:\r\n\r\n!pip uninstall tensorflow tensorboard\r\n!pip install tf-nightly\r\n\r\nThanks again for your time!\r\nClosing issue!"]}, {"number": 39175, "title": "ImportError: No module named utils using google colab", "body": "Hi i am using google colab to run object_detection_tutorial.ipynb from https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10.I am using tensorflow cpu and anaconda prompt.I have added the utils module to path in anaconda prompt \r\nset PYTHONPATH=C:\\tensorflow2\\models;C:\\tensorflow2\\models\\research;C:\\tensorflow2\\models\\research\\slim;C:\\tensorflow2\\models\\research\\object_detection\\utils.Yet this issue is still continues\r\n\r\nImportErrorTraceback (most recent call last)\r\n<ipython-input-3-aa270cd948af> in <module>()\r\n----> 1 from utils import label_map_util\r\n      2 \r\n      3 from utils import visualization_utils as vis_util\r\n\r\nImportError: No module named utils\r\n", "comments": ["@theman162 \r\nIn order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. \r\nPlease provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. \r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!\r\n\r\n", "*System information**\r\n- OS Platform and Distribution :windows 10\r\n\r\n- TensorFlow version:1.5\r\n- Python version:python 3.7\r\n- Installed using virtualenv? pip? conda?:pip\r\n\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: using tensorflow cpu\r\n- GPU model and memory:using tensorflow cpu\r\n", "\r\n![image](https://user-images.githubusercontent.com/57122013/81046638-691a2000-8eeb-11ea-9921-9d7b867b5e10.png)\r\n\r\n", "@theman162 \r\nIs there any particular reason for using the old version of tensor flow can you please upgrade to latest version and let us know if the problem exist. [ Please try 1.15 or 2.1 ]\r\n\r\n\r\n", "I am running the object detection from this github commit which uses tensorflow 1.5 .he is not that responsive which is why i am asking solution for this issue https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10", "i would like to know if i can  use tensorflow 1.9", "@theman162 \r\nCan you please try in later versions of tensorflow as mentioned and let us know if you face any issues.\r\n", "duplicate https://github.com/tensorflow/models/issues/5852\r\nrefer https://github.com/tensorflow/models/issues/5852#issuecomment-443805036", "@theman162\r\nPlease confirm if we may move this to closed status", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "https://stackoverflow.com/questions/57257530/importerror-no-module-named-in-colab-google\r\nref to this answer got me solved\r\nutils will be found after explicitly changing dir"]}, {"number": 39174, "title": "C API Release", "body": "Not sure if this is the right place to ask this, but I was wondering why the C API precompiled binaries have not been released for TF 2.x yet. Are you planning to release them soon? And I also have the same question for the java proto library.\r\n\r\ncc @alextp ", "comments": ["@gunan do you know what happened to libtensorflow_framework.so?", "fyi, I also tried using the nightly share libraries (v2.1 for mac but only v2.0 for linux for some reason) and I ran into an issue because the mac libraries are not code-signed and so cannot be loaded in MacOS 15 (Catalina).", "@alextp libtensorflow_framework.so is a part of the pip package, but I think here the users are asking for libtensorflow.so release.\r\n\r\nThe issue is, their maintainers have left the team, or google, and noone picked those up.\r\n@av8ramit and @bmzhao will take a look at them before 2.3 release.", "I'm mainly asking about the shared libraries that were distributed independent of the pip package (which includes both libtensorflow.so and libtensorflow_framework.so). But yes, it'd be great if they're picked up again. I'm relying on them for TF Scala, which I'm kind of resurrecting. :)", "Yes we are taking a look at restarting those releases. Hopefully we will have them by the 2.3 release.", "That's great! Thanks @av8ramit!", "Seems like `libtensorflow_framework.so.2` ships with `2.0.0` (inside of `tensorflow_core`) and the size of TensorFlow is dramatically smaller than with versions `2.1.x` and 2.2.x` (now shipped as `tensorflow` and not `tensorflow_core`).\r\n\r\nThis makes a bundle of TensorFlow with its Python dependencies the following sizes (when building against the `amazonlinux:latest` image).\r\n\r\n| TensorFlow version | Original size | Stripped size | Compressed size |\r\n| :- | :-: | :-: | :-: |\r\n| 1.15.3 | 578M | 413M | 115M |\r\n| 2.0.2 | 493M | 350M | 97M |\r\n| 2.1.1 | 1.5G | 1.3G | 433M |\r\n| 2.2.0 | 1.7G | 1.5G | 515M |\r\n| 2.2.0 \u00b7 tf-lite | 91M | 43M | 13M |\r\n| nightly | 1.8G | 1.6G | 524M |\r\n\r\n_*Stripped sizes are calculated after doing `xargs strip` to `.so` files and removing unnecessary `pip`, `pip-`, `wheel`, and `wheel-` folders from the Python packages.\r\n\r\nIn my case, this increase in size makes it impossible to deploy the model (say, in AWS Lambda, which limits the zipped size to around 256M).", "`libtensorflow` seems to be available via Homebrew for Linux and macOS for `2.2.0`.\r\n\r\nhttps://formulae.brew.sh/formula-linux/libtensorflow", "You can find Libtensorflow packages on TF website now. Thanks!\r\nhttps://www.tensorflow.org/install/lang_c#download\r\nClosing this issue now,Feel free to reopen if necessary. "]}, {"number": 39172, "title": "Resubmit of PR 38848 but only support complex64 and complex128", "body": "See related discussion on https://github.com/tensorflow/tensorflow/pull/38848#issuecomment-623758481\r\n\r\n/cc @mihaimaruseac @alextp this PR removes bool from the GPU. let me know if you prefer to revert first instead.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["Oh, the rollback landed so now there are conflicts", "@mihaimaruseac @alextp I have updated the PR with content changed to:\r\n\r\n- Resubmit of PR #38848 but only support complex64 and complex128\r\n\r\nPlease take a look and see if it makes sense."]}, {"number": 39171, "title": "Respect inference type in DefaultQuantParamsPass ", "body": "The `DefaultQuantParamsPass` allows to use fallback to a default quantization range when a tensor doesn't have quantization parameters. This can be useful for latency tests when fake_quant ops might not be correctly placed.\r\nHowever, the pass currently doesn't respect the inferece type and thus will always add `uint8` quantize/dequantize pairs. This PR changes the pass to correctly set the `dtype` depending on `quant_specs.inference_type`.", "comments": ["This looks good to me, but assigning to Feng who knows this pass much better than me.", "Looks like the Windows CI errors are unrelated (`Internal CI infrastructure error.`). Should I rebase onto master or can the failures be ignored?", "Lets try and prod it to see if makes it through Window CI side.", "Looks like the windows tests are still failing due to an unreleated build error in `tensorflow/core/kernels:adjust_contrast_op_gpu`."]}, {"number": 39170, "title": "\"shuffle_and_repeat_fusion\" optimizer content incorrect on s390x arch (big-endian)", "body": "- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): - s390x Ubuntu 18.04\r\n- TensorFlow installed from (source or binary): Source\r\n- TensorFlow version (use command below):  v2.2.0-rc4-0-g70087ab4f4 2.2.0-rc4\r\n- Python version: Python 3.6.9\r\n- Bazel version (if compiling from source): Build label: 2.0.0- (@non-git)\r\nBuild target: bazel-out/s390x-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\n- GCC/Compiler version (if compiling from source): gcc version 7.5.0 (Ubuntu 7.5.0-3ubuntu1~18.04)\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**Describe the current behavior**\r\nWhen running Tensorflow test cases on s390x, several hundred testcase fail with the following error:\r\n\r\n/==========================/\r\n[ RUN      ] \r\n...\r\nShuffleAndRepeatFusionTest.testShuffleAndRepeatFusion_test_mode_eager_tfapiversion_2\r\n2020-04-30 19:20:21.809298: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at optimize_dataset_op.cc:66 : Internal: Tried to register a dataset optimizer that doesn't exist:\r\n/==========================/\r\n\r\n**Describe the expected behavior**\r\n\"shuffle_and_repeat_fusion\" optimizer should be correctly identified on s390x\r\n\r\n**Standalone code to reproduce the issue**\r\nOn s390x system, run the following test case:\r\n\r\n\"python tensorflow/python/data/experimental/kernel_tests/optimization/shuffle_and_repeat_fusion_test.py\"\r\n\r\nThe problem seems to occur when `tensorflow/core/kernels/data/optimize_dataset_op.cc` tries to OptimizeDatasetOp::MakeDataset for \"shuffle_and_repeat_fusion\" optimizer.  On s390x arch, optimization content is incorrect:\r\n\r\nOn s390x:\r\n/================================/\r\n(gdb) p optimizations\r\n$3 = std::vector of length 1, capacity 1 = {{tstr_ = {u = {smll = {**size = 0 '\\000',**\r\n          str = \"\\000\\000\\000\\000\\000\\000e\\000\\000\\000\\000\\000\\000\\000/\\000\\000\\000\\000\\003\\266;`\"}, large = {\r\n          size = 101, cap = 47, ptr = 0x3b63b60 \"shuffle_and_repeat_fusion\"}, offset = {size = 0, offset = 101,\r\n          count = 0}, view = {size = 101, ptr = 0x2f <error: Cannot access memory at address 0x2f>}, raw = {\r\n          raw = \"\\000\\000\\000\\000\\000\\000\\000e\\000\\000\\000\\000\\000\\000\\000/\\000\\000\\000\\000\\003\\266;`\"}}}}}\r\n/================================/\r\n\r\nOn x86:\r\n\r\n/===============================/\r\n(gdb) p optimizations\r\n$65 = {tstr_ = {u = {smll = {**size = 101 'e'**,\r\n        str = \"\\000\\000\\000\\000\\000\\000\\000/\\000\\000\\000\\000\\000\\000\\000`\\250\\202\\004\\000\\000\\000\"}, large = {size = 101,\r\n        cap = 47, ptr = 0x482a860 \"shuffle_and_repeat_fusion\"}, offset = {size = 101, offset = 0, count = 47}, view = {\r\n        size = 101, ptr = 0x2f <error: Cannot access memory at address 0x2f>}, raw = {\r\n        raw = \"e\\000\\000\\000\\000\\000\\000\\000/\\000\\000\\000\\000\\000\\000\\000`\\250\\202\\004\\000\\000\\000\"}}}}\r\n/===============================/\r\n\r\nAs we can see, **size**  is incorrectly extracted on s390x.  It is very likely that optimization contents need to be endian sensitive.  Specifically positioning of \"000e\" looks suspect.\r\n\r\nI looked at shuffle_and_repeat_fusion.cc to get an idea but couldn't nail down where this is set.\r\n\r\nAny pointers appreciated.\r\n\r\nThanks.", "comments": ["@rposts \r\nCan you please share simple stand alone code for us to replicate your issue, or if possible share a colab gist for us to analyse the issue faced", "@Saduf2019 , please see the stripped down version of test case:\r\n```\r\nfrom tensorflow.python.data.kernel_tests import test_base\r\nfrom tensorflow.python.data.ops import dataset_ops\r\nfrom tensorflow.python.platform import test\r\n\r\nclass ShuffleAndRepeatFusionTest(test_base.DatasetTestBase):\r\n\r\n  def testShuffleAndRepeatFusion(self):\r\n    dataset = dataset_ops.Dataset.range(10)\r\n    get_next = self.getNext(dataset)\r\n\r\nif __name__ == \"__main__\":\r\n  test.main()\r\n```\r\n\r\nWhen `get_next` line is executed, following error is thrown on s390x:\r\n\r\n```\r\nroot@3cefe6d659f6:/home/tensorflow# python tensorflow/python/data/experimental/kernel_tests/optimization/shuffle_and_repeat_fusion_test.py\r\nRunning tests under Python 3.6.9: /usr/bin/python\r\n[ RUN      ] ShuffleAndRepeatFusionTest.testShuffleAndRepeatFusion\r\n2020-05-05 12:35:25.925871: W tensorflow/core/platform/profile_utils/cpu_utils.cc:106] Failed to find bogomips or clock in /proc/cpuinfo; cannot determine CPU frequency\r\n2020-05-05 12:35:25.931876: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x414fe030 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-05-05 12:35:25.931914: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2020-05-05 12:35:25.940079: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at optimize_dataset_op.cc:66 : Internal: Tried to register a dataset optimizer that doesn't exist:\r\n[  FAILED  ] ShuffleAndRepeatFusionTest.testShuffleAndRepeatFusion\r\n[ RUN      ] ShuffleAndRepeatFusionTest.test_session\r\n[  SKIPPED ] ShuffleAndRepeatFusionTest.test_session\r\n======================================================================\r\nERROR: testShuffleAndRepeatFusion (__main__.ShuffleAndRepeatFusionTest)\r\ntestShuffleAndRepeatFusion (__main__.ShuffleAndRepeatFusionTest)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"tensorflow/python/data/experimental/kernel_tests/optimization/shuffle_and_repeat_fusion_test.py\", line 25, in testShuffleAndRepeatFusion\r\n    get_next = self.getNext(dataset)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/kernel_tests/test_base.py\", line 109, in getNext\r\n    iterator = iter(dataset)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\", line 404, in __iter__\r\n    return iterator_ops.OwnedIterator(self)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\", line 595, in __init__\r\n    self._create_iterator(dataset)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\", line 601, in _create_iterator\r\n    dataset = dataset._apply_options()\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\", line 375, in _apply_options\r\n    graph_rewrite_configs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\", line 4365, in __init__\r\n    **self._flat_structure)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 3690, in optimize_dataset\r\n    _ops.raise_from_not_ok_status(e, name)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 6653, in raise_from_not_ok_status\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.InternalError: **Tried to register a dataset optimizer that doesn't exist:  [Op:OptimizeDataset]**\r\n\r\n----------------------------------------------------------------------\r\nRan 2 tests in 0.029s\r\n\r\nFAILED (errors=1, skipped=1)\r\n```\r\nIn this case default optimizers are included and as you can see, `shuffle_and_repeat_fusion` entry in the post parse of `OptimizeDatasetOp::MakeDataset`appears to be off which ultimately leads to `Tried to register a dataset optimizer that doesn't exist:` error:\r\n\r\n```\r\n(gdb) p optimizations[0]\r\n$3 = {tstr_ = {u = {smll = {size = 80 'P', str = \"map_and_batch_fusion\\000\\000\"}, large = {\r\n        size = 5795395430760148580, cap = 6873163133832683366,\r\n        ptr = 0x7573696f6e000000 <error: Cannot access memory at address 0x7573696f6e000000>}, offset = {\r\n        size = 1349345648, offset = 1600220772, count = 1600282996}, view = {size = 5795395430760148580,\r\n        ptr = 0x5f62617463685f66 <error: Cannot access memory at address 0x5f62617463685f66>}, raw = {\r\n        raw = \"Pmap_and_batch_fusion\\000\\000\"}}}}\r\n(gdb) p optimizations[1]\r\n$4 = {tstr_ = {u = {smll = {size = 64 '@', str = \"noop_elimination\\000\\000\\000\\000\\000\\000\"}, large = {\r\n        size = 4642770790282913132, cap = 7596844069246232943,\r\n        ptr = 0x6e00000000000000 <error: Cannot access memory at address 0x6e00000000000000>}, offset = {\r\n        size = 1080979311, offset = 1885300076, count = 1768778094}, view = {size = 4642770790282913132,\r\n        ptr = 0x696d696e6174696f <error: Cannot access memory at address 0x696d696e6174696f>}, raw = {\r\n        raw = \"@noop_elimination\\000\\000\\000\\000\\000\\000\"}}}}\r\n(gdb) p optimizations[2]\r\n$5 = {tstr_ = {u = {smll = {size = 0 '\\000',\r\n        str = \"\\000\\000\\000\\000\\000\\000e\\000\\000\\000\\000\\000\\000\\000/\\000\\000\\000\\000\\003\\265\\063\"}, large = {\r\n        size = 101, cap = 47, ptr = 0x3b53300 \"shuffle_and_repeat_fusion\"}, offset = {size = 0, offset = 101,\r\n        count = 0}, view = {size = 101, ptr = 0x2f <error: Cannot access memory at address 0x2f>}, raw = {\r\n        raw = \"\\000\\000\\000\\000\\000\\000\\000e\\000\\000\\000\\000\\000\\000\\000/\\000\\000\\000\\000\\003\\265\\063\"}}}}\r\n\r\n```\r\n\r\nPlease let me know if you need more information.\r\n\r\nThanks.", "@rposts \r\nI ran the code shared by you and face a difference error, please find the [gist here](https://colab.sandbox.google.com/gist/Saduf2019/8b2af10eb69b36123c9f389447566384/untitled163.ipynb)", "This appears to be a colab issue : https://github.com/tensorflow/tensorflow/issues/17702", "@Saduf2019 - I tried this in colab and no longer complains about the error you encountered\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.python.data.kernel_tests import test_base\r\nfrom tensorflow.python.data.ops import dataset_ops\r\nfrom tensorflow.python.platform import test\r\ntf.compat.v1.app.flags.DEFINE_string('f', '', 'kernel')\r\nclass ShuffleAndReplaceFusion(test_base.DatasetTestBase):\r\n  def testShuffleAndRepeatFusion(self):\r\n    dataset = dataset_ops.Dataset.range(10)\r\n    get_next = self.getNext(dataset)\r\n\r\nif __name__ == \"__main__\":\r\n  test.main()\r\n```", "@rposts \r\nI ran the above code and face the error as per [this gist](https://colab.sandbox.google.com/gist/Saduf2019/a7a090504bafa81d2c761e501dd15061/untitled167.ipynb), please confirm.", "Yes - that is correct.  However, the problem here is not that this stripped down version of testcase fails, but that `shuffle_and_repeat_fusion` optimizer content that is retrieved on s390x is incorrect. This content appears to be in little-endian format and needs to be corrected for big-endian.\r\n\r\nI wonder how `dataset_ops` optimization section is built.  Is this a static value that is obtained from pre-existing dataset?  If so, where does it come from.  I looked at `dataset_ops.py` but couldn't spot a section where these optimizations are built.\r\n", "[Here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/data/experimental/ops/optimization_options.py#L215-L257) is the method that computes which static optimizations to use. In particular, `shuffle_and_repeat_fusion` is treated identically to `noop_elimination` and `map_and_batch_fusion`, which makes me think that this is not related to `shuffle_and_repeat_fusion` but to the \"last\" optimization. To double check that, try reordering the `optimizations_to_disable` list and see if the problem still occurs for `shuffle_and_repeat_fusion`.", "Thanks @jsimsa . I already tried that to no avail.  Here are my changes and the resulting output after rebuilding TF and reinstalling the wheel.\r\n```\r\ndiff --git a/tensorflow/python/data/experimental/ops/optimization_options.py b/tensorflow/python/data/experimental/ops/optimization_options.py\r\nindex 5db4db91c1..8ef3ccfa40 100644\r\n--- a/tensorflow/python/data/experimental/ops/optimization_options.py\r\n+++ b/tensorflow/python/data/experimental/ops/optimization_options.py\r\n@@ -222,10 +222,10 @@ class OptimizationOptions(options.OptionsBase):\r\n         \"map_and_batch_fusion\",\r\n         \"map_and_filter_fusion\",\r\n         \"map_parallelization\",\r\n+        \"shuffle_and_repeat_fusion\",\r\n         \"map_fusion\",\r\n         \"noop_elimination\",\r\n         \"parallel_batch\",\r\n-        \"shuffle_and_repeat_fusion\",\r\n     ]\r\n     for optimization in all_optimizations:\r\n       if getattr(self, optimization):\r\n@@ -235,9 +235,9 @@ class OptimizationOptions(options.OptionsBase):\r\n       # The following optimizations are turned on by default, unless the user\r\n       # explicitly disables them.\r\n       optimizations_to_disable = [\r\n+          \"shuffle_and_repeat_fusion\",\r\n           \"map_and_batch_fusion\",\r\n           \"noop_elimination\",\r\n-          \"shuffle_and_repeat_fusion\",\r\n       ]\r\n       for optimization in optimizations_to_disable:\r\n         if getattr(self, optimization) is not False:\r\n```\r\nOptimizations:\r\n```\r\n(gdb) p optimizations[0]\r\n$4 = {tstr_ = {u = {smll = {size = 80 'P', str = \"map_and_batch_fusion\\000\\000\"}, large = {\r\n        size = 5795395430760148580, cap = 6873163133832683366,\r\n        ptr = 0x7573696f6e000000 <error: Cannot access memory at address 0x7573696f6e000000>}, offset = {\r\n        size = 1349345648, offset = 1600220772, count = 1600282996}, view = {size = 5795395430760148580,\r\n        ptr = 0x5f62617463685f66 <error: Cannot access memory at address 0x5f62617463685f66>}, raw = {\r\n        raw = \"Pmap_and_batch_fusion\\000\\000\"}}}}\r\n(gdb) p optimizations[1]\r\n$5 = {tstr_ = {u = {smll = {size = 64 '@', str = \"noop_elimination\\000\\000\\000\\000\\000\\000\"}, large = {\r\n        size = 4642770790282913132, cap = 7596844069246232943,\r\n        ptr = 0x6e00000000000000 <error: Cannot access memory at address 0x6e00000000000000>}, offset = {\r\n        size = 1080979311, offset = 1885300076, count = 1768778094}, view = {size = 4642770790282913132,\r\n        ptr = 0x696d696e6174696f <error: Cannot access memory at address 0x696d696e6174696f>}, raw = {\r\n        raw = \"@noop_elimination\\000\\000\\000\\000\\000\\000\"}}}}\r\n(gdb) p optimizations[2]\r\n$6 = {tstr_ = {u = {smll = {size = 0 '\\000',\r\n        str = \"\\000\\000\\000\\000\\000\\000e\\000\\000\\000\\000\\000\\000\\000/\\000\\000\\000\\000\\003\\265.\\260\"}, large = {\r\n        size = 101, cap = 47, ptr = 0x3b52eb0 \"shuffle_and_repeat_fusion\"}, offset = {size = 0, offset = 101,\r\n        count = 0}, view = {size = 101, ptr = 0x2f <error: Cannot access memory at address 0x2f>}, raw = {\r\n        raw = \"\\000\\000\\000\\000\\000\\000\\000e\\000\\000\\000\\000\\000\\000\\000/\\000\\000\\000\\000\\003\\265.\\260\"}}}}\r\n```\r\nI am beginning to suspect the way `registered_optimizers ` are built -  `registered_optimizers` [here ](https://github.com/tensorflow/tensorflow/blob/53b0f6f7a6d25ce858d03b67ab391865d87ac4eb/tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc#L51)  for `shuffle_and_repeat_fusion`  contain this value:\r\n\r\n```\r\n  [\"shuffle_and_repeat_fusion\"] = {<std::_Maybe_unary_or_binary_function<tensorflow::grappler::CustomGraphOptimizer*>> = {<No data fields>}, <std::_Function_base> = {static _M_max_size = 16, static _M_max_align = 8, _M_functor = {\r\n        _M_unused = {_M_object = 0x1ddd698, _M_const_object = 0x1ddd698, _M_function_pointer = 0x1ddd698,\r\n          _M_member_pointer = (void (std::_Undefined_class::*)(std::_Undefined_class * const)) 0x1ddd698},\r\n        _M_pod_data = \"\\000\\000\\000\\000\\001\\335\\326\\230\\000\\000\\000\\000\\000\\000\\000\"},\r\n      _M_manager = 0x3fff417c080 <std::_Function_base::_Base_manager<tensorflow::grappler::(anonymous namespace)::<lambda()> >::_M_manager(std::_Any_data &, const std::_Any_data &, std::_Manager_operation)>},\r\n    _M_invoker = 0x3fff417c0b8 <std::_Function_handler<tensorflow::grappler::CustomGraphOptimizer*(), tensorflow::grappler::(anonymous namespace)::<lambda()> >::_M_invoke(const std::_Any_data &)>}}\r\n\r\n```", "I think I found the problem ... On big-endian system `TF_TString_GetType` is not being calculated correctly for \"large\" strings. [This ](https://github.com/tensorflow/tensorflow/blob/53b0f6f7a6d25ce858d03b67ab391865d87ac4eb/tensorflow/core/platform/ctstring_internal.h#L184)always gets executed under small string size assumption.\r\n\r\nNow I need to figure out where the fix needs to go.", "@jsimsa - it seems like problem also exist on x86 arch wrt `shuffle_and_repeat_fusion`. However, I suspect it does not surface due to endiness of the architecture.\r\n\r\nIf I am comprehending the code correctly then formation of `TF_TString_Raw raw` for `shuffle_and_repeat_fusion` is incorrect.  `[TF_TString_Raw]`(https://github.com/tensorflow/tensorflow/blob/53b0f6f7a6d25ce858d03b67ab391865d87ac4eb/tensorflow/core/platform/ctstring_internal.h#L101) is defined to hold 24 `uint8_t` type but the length of `shuffle_and_repeat_fusion` is 25 and causes a sort of \"spill\" which is problematic on s390x as the `[raw[0]]`(https://github.com/tensorflow/tensorflow/blob/53b0f6f7a6d25ce858d03b67ab391865d87ac4eb/tensorflow/core/platform/ctstring_internal.h#L139) character is expected to hold the `TF_TString_Type`.  On x86 `str->u.raw.raw[0]` manages to retain the string type marker which causes the test cases to pass.  However, if you compare the `raw` string contents of `shuffle_and_repeat_fusion` on x86 to other optimizers then you will notice that `raw` contents are incorrect.  For example:\r\n```\r\nraw = \"Pmap_and_batch_fusion\\000\\377\\377\"  <--- This is for map_and_batch_fusion optimizer\r\nraw = \"e\\000\\000\\000\\000\\000\\000\\000/\\000\\000\\000\\000\\000\\000\\000`\\250\\202\\004\\000\\000\\000\" <--- This is for shuffle_and_repeat_fusion optimizer\r\n```\r\n\r\nIn my case I have \"fixed\" this discrepancy by extending the `raw` array size to 32 bytes:\r\n```\r\ndiff --git a/tensorflow/core/platform/ctstring_internal.h b/tensorflow/core/platform/ctstring_internal.h\r\nindex 5f9d88d536..cfa58a66ad 100644\r\n--- a/tensorflow/core/platform/ctstring_internal.h\r\n+++ b/tensorflow/core/platform/ctstring_internal.h\r\n@@ -99,7 +99,7 @@ typedef struct TF_TString_View {  // NOLINT\r\n } TF_TString_View; typedef struct TF_TString_Raw {  // NOLINT\r\n-  uint8_t raw[24];\r\n+  uint8_t raw[32];\r\n } TF_TString_Raw; typedef union TF_TString_Union {  // NOLINT\r\n```\r\n\r\nDo you think this change makes sense?\r\n\r\nThanks.", "adding @gharibian as he is more familiar with TensorFlow strings", "> Do you think this change makes sense?\r\n\r\nNo, extending to 32bytes is not an appropriate solution as it would increase the string struct overhead by 33%.  We need to look into why s390x is computing a 25byte struct.  Let me see if I can get access to a s390x machine so that I can recreate the issue.", "@gharibian - I think we may have found the source of these issues. `cstring_internal.h` appears to be using macros incorrectly when determining the endiness.  Following changes have addressed our issues and brought down failures down to 65 as of now:\r\n```\r\ndiff --git a/tensorflow/core/platform/ctstring_internal.h b/tensorflow/core/platform/ctstring_internal.h\r\nindex 5f9d88d536..69338e6e4b 100644\r\n--- a/tensorflow/core/platform/ctstring_internal.h\r\n+++ b/tensorflow/core/platform/ctstring_internal.h\r\n@@ -145,7 +145,7 @@ extern inline TF_TString_Type TF_TString_GetType(const TF_TString *str) {\r\n // and always byte-swapping on big endian, resulting in a simple 'bswap'+'shr'\r\n // (for architectures that have a bswap op).\r\n static inline size_t TF_TString_ToActualSizeT(size_t size) {\r\n-#ifdef TF_TSTRING_LITTLE_ENDIAN\r\n+#if TF_TSTRING_LITTLE_ENDIAN\r\n   return size >> 2;\r\n #else   // TF_TSTRING_LITTLE_ENDIAN\r\n   // 0xFF000000 or 0xFF00000000000000 depending on platform\r\n@@ -157,7 +157,7 @@ static inline size_t TF_TString_ToActualSizeT(size_t size) { static inline size_t TF_TString_ToInternalSizeT(size_t size,\r\n                                                 TF_TString_Type type) {\r\n-#ifdef TF_TSTRING_LITTLE_ENDIAN\r\n+#if TF_TSTRING_LITTLE_ENDIAN\r\n   return (size << 2) | type;\r\n #else   // TF_TSTRING_LITTLE_ENDIAN\r\n   // 0xFF000000 or 0xFF00000000000000 depending on platform\r\n```", "That is definitely a bug, please feel free to submit that patch.  I'm currently blocked on getting bazel bootstrapped on s390x.  In parallel, I'm trying to run the ctstring tests outside of TF on s390x in order to surface any other potential issues..\r\n", "Thank you.  We will proceed with PR.", "> Thank you. We will proceed with PR.\r\n\r\nHi Rishi,\r\n\r\nAny update on getting the 'cstring_internal.h' fix PR? I'd like to get it in as it is a legitimate bug.  Otherwise, I can submit the change on my end and credit you.  Please let me know. ", "Hi @gharibian - we are trying to get master built on s390x before submitting the PR but master build is causing issues.  Please go ahead and submit the PR and credit @cdavoudian.  Thanks so much!", "Closing - fixed by https://github.com/tensorflow/tensorflow/commit/206dc37a33bf34a1a79dd56e19fb7b1c6cdf5dc6. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39170\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39170\">No</a>\n"]}, {"number": 39169, "title": "No gradients provided for any variable", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Arch linux + Gnome\r\n- TensorFlow version: tf-nightly==2.2.0.dev20200504 from `pip install tf-nightly`\r\n- Python version: 3.8.2\r\n\r\n**Describe the current behavior**\r\nWhen running the training on the localhost the error occurs:\r\n\r\n```\r\nEpoch 1/1000\r\nTraceback (most recent call last):\r\n  File \"main.py\", line 155, in <module>\r\n    h = model.fit(x=dtgen.next_train_batch(),\r\n  File \"/home/arthur/Code/handwritten-text-recognition/src/network/model.py\", line 166, in fit\r\n    out = self.model.fit(x=x, y=y, batch_size=batch_size, epochs=epochs, verbose=verbose,\r\n  File \"/home/arthur/Code/handwritten-text-recognition/.venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\", line 72, in _method_wrapper\r\n    return method(self, *args, **kwargs)\r\n  File \"/home/arthur/Code/handwritten-text-recognition/.venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\", line 921, in fit\r\n    tmp_logs = train_function(iterator)\r\n  File \"/home/arthur/Code/handwritten-text-recognition/.venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\", line 695, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"/home/arthur/Code/handwritten-text-recognition/.venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\", line 737, in _call\r\n    self._initialize(args, kwds, add_initializers_to=initializers)\r\n  File \"/home/arthur/Code/handwritten-text-recognition/.venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\", line 616, in _initialize\r\n    self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\r\n  File \"/home/arthur/Code/handwritten-text-recognition/.venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 2902, in _get_concrete_function_internal_garbage_collected\r\n    graph_function, _, _ = self._maybe_define_function(args, kwargs)\r\n  File \"/home/arthur/Code/handwritten-text-recognition/.venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 3232, in _maybe_define_function\r\n    graph_function = self._create_graph_function(args, kwargs)\r\n  File \"/home/arthur/Code/handwritten-text-recognition/.venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 3111, in _create_graph_function\r\n    func_graph_module.func_graph_from_py_func(\r\n  File \"/home/arthur/Code/handwritten-text-recognition/.venv/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\", line 981, in func_graph_from_py_func\r\n    func_outputs = python_func(*func_args, **func_kwargs)\r\n  File \"/home/arthur/Code/handwritten-text-recognition/.venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\", line 528, in wrapped_fn\r\n    return weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n  File \"/home/arthur/Code/handwritten-text-recognition/.venv/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\", line 968, in wrapper\r\n    raise e.ag_error_metadata.to_exception(e)\r\nValueError: in user code:\r\n\r\n    /home/arthur/Code/handwritten-text-recognition/.venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:631 train_function  *\r\n        return step_function(self, iterator)\r\n    /home/arthur/Code/handwritten-text-recognition/.venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:621 step_function  **\r\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\r\n    /home/arthur/Code/handwritten-text-recognition/.venv/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:952 run\r\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\r\n    /home/arthur/Code/handwritten-text-recognition/.venv/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2292 call_for_each_replica\r\n        return self._call_for_each_replica(fn, args, kwargs)\r\n    /home/arthur/Code/handwritten-text-recognition/.venv/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2651 _call_for_each_replica\r\n        return fn(*args, **kwargs)\r\n    /home/arthur/Code/handwritten-text-recognition/.venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:614 run_step  **\r\n        outputs = model.train_step(data)\r\n    /home/arthur/Code/handwritten-text-recognition/.venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:581 train_step\r\n        _minimize(self.distribute_strategy, tape, self.optimizer, loss,\r\n    /home/arthur/Code/handwritten-text-recognition/.venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1946 _minimize\r\n        gradients = optimizer._aggregate_gradients(zip(gradients,  # pylint: disable=protected-access\r\n    /home/arthur/Code/handwritten-text-recognition/.venv/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:554 _aggregate_gradients\r\n        filtered_grads_and_vars = _filter_grads(grads_and_vars)\r\n    /home/arthur/Code/handwritten-text-recognition/.venv/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:1251 _filter_grads\r\n        raise ValueError(\"No gradients provided for any variable: %s.\" %\r\n\r\n    ValueError: No gradients provided for any variable: ['conv2d/kernel:0', 'conv2d/bias:0', 'conv2d_1/kernel:0', 'conv2d_1/bias:0', 'gated_conv2d/kernel:0', 'gated_conv2d/bias:0', 'conv2d_2/kernel:0', 'conv2d_2/bias:0', 'gated_conv2d_1/kernel:0', 'gated_conv2d_1/bias:0', 'conv2d_3/kernel:0', 'conv2d_3/bias:0', 'gated_conv2d_2/kernel:0', 'gated_conv2d_2/bias:0', 'conv2d_4/kernel:0', 'conv2d_4/bias:0', 'bidirectional/forward_lstm/lstm_cell_1/kernel:0', 'bidirectional/forward_lstm/lstm_cell_1/recurrent_kernel:0', 'bidirectional/forward_lstm/lstm_cell_1/bias:0', 'bidirectional/backward_lstm/lstm_cell_2/kernel:0', 'bidirectional/backward_lstm/lstm_cell_2/recurrent_kernel:0', 'bidirectional/backward_lstm/lstm_cell_2/bias:0', 'dense/kernel:0', 'dense/bias:0', 'bidirectional_1/forward_lstm_1/lstm_cell_4/kernel:0', 'bidirectional_1/forward_lstm_1/lstm_cell_4/recurrent_kernel:0', 'bidirectional_1/forward_lstm_1/lstm_cell_4/bias:0', 'bidirectional_1/backward_lstm_1/lstm_cell_5/kernel:0', 'bidirectional_1/backward_lstm_1/lstm_cell_5/recurrent_kernel:0', 'bidirectional_1/backward_lstm_1/lstm_cell_5/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0'].\r\n```\r\n\r\n**Describe the expected behavior**\r\nThis issue didn't happen in previous versions, but I'm having to use python 3.8, thus the tf-nightly version. I also noticed that in the collab the code works, with the TF 2.1 version and python 3.7.\r\n\r\nIn addition, I found issues suggesting using:\r\n````\r\nwith tf.GradientTape as tape:\r\n[...]\r\n````\r\n\r\nHowever, the examples I saw use a customized training function (`train_step()`). In my case, I only use the standard `fit()` function, which is enough for the context.\r\n\r\nMaybe I'm not sure how to use this in new version, or maybe it's an issue. Anyway, if anyone can help, thank you very much.\r\n\r\n**Standalone code to reproduce the issue**\r\n[Project code](https://github.com/arthurflor23/handwritten-text-recognition) and [model class](https://github.com/arthurflor23/handwritten-text-recognition/blob/master/src/network/model.py)", "comments": ["Data generator error. [fixed](https://github.com/tensorflow/tensorflow/issues/38233)", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39169\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39169\">No</a>\n"]}, {"number": 39168, "title": "[INTEL MKL] Adding fix for UT failure in graph_runner_test", "body": "", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F39168) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it! ", "@sshiddib Thank you for your contribution. Can you please sign CLA? Thanks!"]}, {"number": 39166, "title": "Improve GPU BW throughput of transpose by vectorization", "body": "This PR improves the GPU BW throughput of transpose op (specifically the ShuffleInTensor3Simple CUDA kernel) by vectorization.\r\n\r\nThe benchmark code:\r\nhttps://github.com/kaixih/kernel_tests_public/blob/master/transpose/transpose_tf2_bench.py\r\nPerformance comparison on V100 GPU before/after this change:\r\nhttps://docs.google.com/spreadsheets/d/1N2kxw8DYQP8FGbZcORCmj7WUVY7Dh6xISuQR0DruG5Q/edit?usp=sharing\r\n\r\nFYI @nluehr ", "comments": ["Updated. PTAL. @chsigg ", "@chsigg Any more changes that I could do for this PR?"]}, {"number": 39165, "title": "Invalid Argument Error with tf.math.add_n", "body": "I am having an issue with the tf.add_n()/tf.math.add_n() command. I keep on getting an error no matter how I change it. I am using Tensorflow 2.1.0, while using Jupyter Notebook, and am still new to using TensorFlow. Here is my code and the errors that have been produced. It seems like a simple fix but I have no clue what to do.\r\n\r\nimport tensorflow as tf\r\n\r\na = tf.constant(6, name = 'constant_a')\r\nb = tf.constant(3, name = 'constant_b')\r\nc = tf.constant(10, name = 'constant_c')\r\nd = tf.constant(15, name = 'constant_d')\r\n\r\nmul = tf.multiply(a,b, name=\"mul\")\r\ndiv = tf.math.divide(c,d, name=\"div\")\r\naddn = tf.math.add_n([mul,div], name=\"addn\") \r\n     \r\nInvalidArgumentError                      Traceback (most recent call last)\r\n<ipython-input-48-c8061239fcf2> in <module>\r\n      5 #division operation which divides c by d and have the name \"div\"\r\n      6 #tf.add_n sums up the element in an array\r\n----> 7 addn = tf.math.add_n([mul,div], name=\"addn\")\r\n\r\nc:\\users\\galvi\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\util\\dispatch.py in wrapper(*args, **kwargs)\r\n    178     \"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\r\n    179     try:\r\n--> 180       return target(*args, **kwargs)\r\n    181     except (TypeError, ValueError):\r\n    182       # Note: convert_to_eager_tensor currently raises a ValueError, not a\r\n\r\nc:\\users\\galvi\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_ops.py in add_n(inputs, name)\r\n   3051       return array_ops.identity(values, name=name)\r\n   3052     return values\r\n-> 3053   return gen_math_ops.add_n(inputs, name=name)\r\n   3054 \r\n   3055 \r\n\r\nc:\\users\\galvi\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_math_ops.py in add_n(inputs, name)\r\n    410         pass  # Add nodes to the TensorFlow graph.\r\n    411     except _core._NotOkStatusException as e:\r\n--> 412       _ops.raise_from_not_ok_status(e, name)\r\n    413   # Add nodes to the TensorFlow graph.\r\n    414   if not isinstance(inputs, (list, tuple)):\r\n\r\nc:\\users\\galvi\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py in raise_from_not_ok_status(e, name)\r\n   6604   message = e.message + (\" name: \" + name if name is not None else \"\")\r\n   6605   # pylint: disable=protected-access\r\n-> 6606   six.raise_from(core._status_to_exception(e.code, message), None)\r\n   6607   # pylint: enable=protected-access\r\n   6608 \r\n\r\nc:\\users\\galvi\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\six.py in raise_from(value, from_value)\r\n\r\nInvalidArgumentError: cannot compute AddN as input #1(zero-based) was expected to be a int32 tensor but is a double tensor [Op:AddN] name: addn\r\n", "comments": ["I am able to replicate this issue, please find the [gist here](https://colab.sandbox.google.com/gist/Saduf2019/5f7d81fc2d1de66da75e91d6e38a8189/untitled163.ipynb)", "@BattleTaco the behavior is working as expected, tf.math.divide perform a python style divide which will convert to float64 by default:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/math/divide\r\n\r\n\r\nAs `c` and `d` are `int32`, if you expect `//` divide to get `int32` result you could use tf.math.truediv :\r\nhttps://www.tensorflow.org/api_docs/python/tf/math/truediv\r\n"]}, {"number": 39164, "title": "Build error for Android quickstart - Toolchain missing", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- TensorFlow installed from (source or binary): Source\r\n- TensorFlow version: 2.1\r\n- Python version: 3.8\r\n- Bazel version (if compiling from source):  3.1.0\r\n\r\n\r\n**Describe the problem**\r\n\r\nI want to build a shared library that contains the C API for TensorflowLite.\r\nBuilding a .dll with `bazel build -c opt //tensorflow/lite/c:tensorflowlite_c`  was no problem. My goal now is to build the C API on Windows for Android to get a an .so and i was running into some problems, while i followed the instructions on ../g3doc/guide/android.md  under \"Build TensorFlow Lite locally\"\r\n\r\nI am missing some toolchains and i do not know how to get them or how to set the correct Path. According to the tutorial i guess i probably should have them. Maybe the sdk/ndk paths are not set correctly since the ./configure file didn't react as expected (described further down).\r\n\r\n**Build command:**\r\n`bazel build -c opt --fat_apk_cpu=x86,x86_64,arm64-v8a,armeabi-v7a --host_crosstool_top=@bazel_tools//tools/cpp:toolchain //tensorflow/lite/java:tensorflow-lite`\r\n\r\n**ERROR message:**\r\nD:\\ComputerVision\\tensorflow-master3\\tensorflow-master>bazel build -c opt --fat_apk_cpu=x86,x86_64,arm64-v8a,armeabi-v7a --host_crosstool_top=@bazel_tools//tools/cpp:toolchain //tensorflow/lite/java:tensorflow-lite\r\nStarting local Bazel server and connecting to it...\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=120\r\nINFO: Reading rc options for 'build' from d:\\computervision\\tensorflow-master3\\tensorflow-master\\.bazelrc:\r\n  Inherited 'common' options: --experimental_repo_remote_exec\r\nINFO: Options provided by the client:\r\n  'build' options: --python_path=C:/Users/Nutzer/AppData/Local/Programs/Python/Python38/python.exe\r\nINFO: Reading rc options for 'build' from d:\\computervision\\tensorflow-master3\\tensorflow-master\\.bazelrc:\r\n  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=v2\r\nINFO: Reading rc options for 'build' from d:\\computervision\\tensorflow-master3\\tensorflow-master\\.tf_configure.bazelrc:\r\n  'build' options: --action_env PYTHON_BIN_PATH=C:/Users/Nutzer/AppData/Local/Programs/Python/Python38/python.exe --action_env PYTHON_LIB_PATH=C:/Users/Nutzer/AppData/Local/Programs/Python/Python38/lib/site-packages --python_path=C:/Users/Nutzer/AppData/Local/Programs/Python/Python38/python.exe --config=xla --define=override_eigen_strong_inline=true --action_env TF_CONFIGURE_IOS=0\r\nINFO: Found applicable config definition build:v2 in file d:\\computervision\\tensorflow-master3\\tensorflow-master\\.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1\r\nINFO: Found applicable config definition build:xla in file d:\\computervision\\tensorflow-master3\\tensorflow-master\\.bazelrc: --action_env=TF_ENABLE_XLA=1 --define=with_xla_support=true\r\nINFO: Found applicable config definition build:windows in file d:\\computervision\\tensorflow-master3\\tensorflow-master\\.bazelrc: --copt=/w --copt=/D_USE_MATH_DEFINES --host_copt=/D_USE_MATH_DEFINES --cxxopt=/std:c++14 --host_cxxopt=/std:c++14 --config=monolithic --copt=-DWIN32_LEAN_AND_MEAN --host_copt=-DWIN32_LEAN_AND_MEAN --copt=-DNOGDI --host_copt=-DNOGDI --linkopt=/DEBUG --host_linkopt=/DEBUG --linkopt=/OPT:REF --host_linkopt=/OPT:REF --linkopt=/OPT:ICF --host_linkopt=/OPT:ICF --experimental_strict_action_env=true --verbose_failures --distinct_host_configuration=false\r\nINFO: Found applicable config definition build:monolithic in file d:\\computervision\\tensorflow-master3\\tensorflow-master\\.bazelrc: --define framework_shared_object=false\r\nERROR: C:/users/nutzer/_bazel_nutzer/cncesu4u/external/local_config_cc/BUILD:47:1: in cc_toolchain_suite rule @local_config_cc//:toolchain: cc_toolchain_suite '@local_config_cc//:toolchain' does not contain a toolchain for cpu 'x86'\r\nERROR: Analysis of target '//tensorflow/lite/java:tensorflow-lite' failed; build aborted: Analysis of target '@local_config_cc//:toolchain' failed\r\nINFO: Elapsed time: 4.042s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (41 packages loaded, 395 targets configured)\r\n\r\n\r\n\r\n**Steps executed before running into the problem**\r\n\r\nI followed the instructions on ../g3doc/guide/android.md  under \"Build TensorFlow Lite locally\". I already have Bazel, sdk and ndk installed. So i ran ./configure.py but were not asked to to interactively configure the `./WORKSPACE` for Android builds, which seemed wrong according to the guide. Here is the ./configure promt:\r\n\r\n`C:\\Users\\Nutzer\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\r\nPlease input the desired Python library path to use.  Default is [C:\\Users\\Nutzer\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages]\r\n\r\nDo you wish to build TensorFlow with ROCm support? [y/N]:\r\nNo ROCm support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with CUDA support? [y/N]:\r\nNo CUDA support will be enabled for TensorFlow.\r\n\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is /arch:AVX]:\r\n\r\nWould you like to override eigen strong inline for some C++ compilation to reduce the compilation time? [Y/n]:\r\nEigen strong inline overridden.\r\n\r\nPreconfigured Bazel build configs. You can use any of the below by adding \"--config=<>\" to your build command. See .bazelrc for more details.\r\n        --config=mkl            # Build with MKL support.\r\n        --config=monolithic     # Config for mostly static monolithic build.\r\n        --config=ngraph         # Build with Intel nGraph support.\r\n        --config=numa           # Build with NUMA support.\r\n        --config=dynamic_kernels        # (Experimental) Build kernels into separate shared objects.\r\n        --config=v2             # Build TensorFlow 2.x instead of 1.x.\r\nPreconfigured Bazel build configs to DISABLE default on features:\r\n        --config=noaws          # Disable AWS S3 filesystem support.\r\n        --config=nogcp          # Disable GCP support.\r\n        --config=nohdfs         # Disable HDFS support.\r\n        --config=nonccl         # Disable NVIDIA NCCL support.`\r\n\r\n\r\nTo fix the `./configure` problem i already tried:\r\n\r\n1) Setting `ANDROID_SDK_HOME` and`ANDROID_NDK_HOME` in cmd (the highest API level should automatically be used right?)\r\n\r\n2) Manually adding the env entries in `.tf_configure.bazelrc` so it looked like this:\r\n\r\n`build --action_env PYTHON_BIN_PATH=\"C:/Users/Nutzer/AppData/Local/Programs/Python/Python38/python.exe\"\r\nbuild --action_env PYTHON_LIB_PATH=\"C:/Users/Nutzer/AppData/Local/Programs/Python/Python38/lib/site-packages\"\r\nbuild --action_env ANDROID_NDK_HOME=\"C:/Users/Nutzer/AppData/Local/Android/NDK/android-ndk-r17c\"\r\nbuild --action_env ANDROID_NDK_API_LEVEL=\"21\"\r\nbuild --action_env ANDROID_BUILD_TOOLS_VERSION=\"28.0.3\"\r\nbuild --action_env ANDROID_SDK_API_LEVEL=\"29\"\r\nbuild --action_env ANDROID_SDK_HOME=\"C:/Users/Nutzer/AppData/Local/Android/Sdk\"\r\nbuild --python_path=\"C:/Users/Nutzer/AppData/Local/Programs/Python/Python38/python.exe\"\r\nbuild --config=xla\r\nbuild:opt --copt=/arch:AVX\r\nbuild:opt --define with_default_optimizations=true\r\nbuild --define=override_eigen_strong_inline=true\r\ntest --flaky_test_attempts=3\r\ntest --test_size_filters=small,medium\r\ntest:v1 --test_tag_filters=-benchmark-test,-no_oss,-no_windows,-gpu,-oss_serial\r\ntest:v1 --build_tag_filters=-benchmark-test,-no_oss,-no_windows,-gpu\r\ntest:v2 --test_tag_filters=-benchmark-test,-no_oss,-no_windows,-gpu,-oss_serial,-v1only\r\ntest:v2 --build_tag_filters=-benchmark-test,-no_oss,-no_windows,-gpu,-v1only\r\nbuild --action_env TF_CONFIGURE_IOS=\"0\"`\r\n\r\n3) Adding the following sniped to the `WORKSPACE`:\r\n\r\nandroid_sdk_repository(\r\n    name = \"androidsdk\", # Required. Name *must* be \"androidsdk\".\r\n    path = \"C:/Users/Nutzer/AppData/Local/Android/Sdk\", # Optional. Can be omitted if `ANDROID_HOME` environment variable is set.\r\n)\r\nandroid_ndk_repository(\r\n    name = \"androidndk\", # Required. Name *must* be \"androidndk\".\r\n    path = \"C:/Users/Nutzer/AppData/Local/Android/NDK/android-ndk-r17c\", # Optional. Can be omitted if `ANDROID_NDK_HOME` environment variable is set.\r\n)\r\n\r\n\r\n**Thank You for Your time and expertise!**\r\n", "comments": ["Should a file called _toolchain_ normally be in the folder: _bazel_tools//tools/cpp_ ? If so why could mine be missing? Or do i missunderstand `host_crosstool_top=@bazel_tools//tools/cpp:toolchain`", "I figured out that changing `environ_cp['TF_SET_ANDROID_WORKSPACE'] = '0'`  to 1 in configure.py i now get asked for sdk and ndk path. But now i get a new error after running the build command.  After all i still do not know if my real problem even originates in the sdk and ndk settings. Help is still appreciated very much! \r\n\r\nThis is the now generated `.tf_configure.bazelrc` file:\r\n\r\n```\r\nbuild --action_env PYTHON_BIN_PATH=\"C:/Users/Nutzer/AppData/Local/Programs/Python/Python36/python.exe\"\r\nbuild --action_env PYTHON_LIB_PATH=\"C:/Users/Nutzer/AppData/Local/Programs/Python/Python36/lib/site-packages\"\r\nbuild --python_path=\"C:/Users/Nutzer/AppData/Local/Programs/Python/Python36/python.exe\"\r\nbuild --config=xla\r\nbuild:opt --copt=/arch:AVX\r\nbuild:opt --define with_default_optimizations=true\r\nbuild --define=override_eigen_strong_inline=true\r\nbuild --action_env ANDROID_NDK_HOME=\"C:\\Users\\Nutzer\\AppData\\Local\\Android\\Sdk\\ndk\\21.1.6352462\"\r\nbuild --action_env ANDROID_NDK_API_LEVEL=\"21\"\r\nbuild --action_env ANDROID_BUILD_TOOLS_VERSION=\"30.0.0-rc4\"\r\nbuild --action_env ANDROID_SDK_API_LEVEL=\"29\"\r\nbuild --action_env ANDROID_SDK_HOME=\"C:\\Users\\Nutzer\\AppData\\Local\\Android\\Sdk\"\r\ntest --flaky_test_attempts=3\r\ntest --test_size_filters=small,medium\r\ntest:v1 --test_tag_filters=-benchmark-test,-no_oss,-no_windows,-gpu,-oss_serial\r\ntest:v1 --build_tag_filters=-benchmark-test,-no_oss,-no_windows,-gpu\r\ntest:v2 --test_tag_filters=-benchmark-test,-no_oss,-no_windows,-gpu,-oss_serial,-v1only\r\ntest:v2 --build_tag_filters=-benchmark-test,-no_oss,-no_windows,-gpu,-v1only\r\nbuild --action_env TF_CONFIGURE_IOS=\"0\"\r\n```\r\n\r\nAnd this is the resulting error:\r\n\r\nERROR: D:/computervision/tensorflow-master/tensorflow-master/WORKSPACE:65:1: //external:android/sdk depends on @androidsdk//:sdk in repository @androidsdk which failed to fetch. no such package '@androidsdk//': The repository's path is \"C:UsersNutzerAppDataLocalAndroidSdk\" (absolute: \"D:/computervision/tensorflow-master/tensorflow-master/C:UsersNutzerAppDataLocalAndroidSdk\") but a symlink could not be created for it, because: D:/computervision/tensorflow-master/tensorflow-master/C:UsersNutzerAppDataLocalAndroidSdk (No such file or directory)\r\nERROR: Analysis of target '//tensorflow/lite/java:tensorflow-lite' failed; build aborted: Analysis failed\r\nINFO: Elapsed time: 0.436s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (15 packages loaded, 114 targets configured)\r\n", "Did you revert your modification on WORKSPACE ?", "Yes i am testing on a freshly downloaded and unmodified TF Environment. The only thing changed is this part of the configure.py file:\r\n\r\n```\r\n  if is_windows():\r\n    environ_cp['TF_NEED_OPENCL_SYCL'] = '0'\r\n    environ_cp['TF_NEED_COMPUTECPP'] = '0'\r\n    environ_cp['TF_NEED_OPENCL'] = '0'\r\n    environ_cp['TF_CUDA_CLANG'] = '0'\r\n    environ_cp['TF_NEED_TENSORRT'] = '0'\r\n    # TODO(ibiryukov): Investigate using clang as a cpu or cuda compiler on\r\n    # Windows.\r\n    environ_cp['TF_DOWNLOAD_CLANG'] = '0'\r\n    environ_cp['TF_NEED_MPI'] = '0'\r\n    environ_cp['TF_SET_ANDROID_WORKSPACE'] = '1'\r\n```\r\nalso i am running `python configure.py` directly instead of `./configure` but that should not be a problem right?\r\n\r\nThe line 65 in WORKSPACE which results in the error is this one: `android_workspace()`\r\n\r\nWhat also confuses me in the error is the file and path he is searching. What file is he looking for and where should it actually be located?\r\n", "Oh, I didn't know Android configuration is disabled for Windows.\r\nhttps://github.com/tensorflow/tensorflow/blob/master/configure.py#L1390\r\n@jdduke, any idea on this?\r\n", "See also issue #38525.", "Duplicate of #38525", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39164\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39164\">No</a>\n", "I am now building on Linux, where it is working without trouble. I have not tested if the issue would be resolved, but thank you for your help!"]}, {"number": 39163, "title": "Cannot make padded batches from dataset made from ragged tensor slices", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (use command below): 2.2.0-rc4\r\n- Python version: 3.7.6\r\n- Bazel version (if compiling from source): NA\r\n- GCC/Compiler version (if compiling from source): NA\r\n- CUDA/cuDNN version: NA\r\n- GPU model and memory: NA\r\n\r\n**Describe the current behavior**\r\n\r\nI can create a dataset from a ragged tensor using [`tf.data.Dataset.from_tensor_slices`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_tensor_slices), but I cannot make a padded batch from it with [`tf.data.Dataset.padded_batch`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#padded_batch).\r\n\r\n**Describe the expected behavior**\r\n\r\nIf the API is meant to support ragged tensors, then the dataset should allow me to make a padded batch from the ragged tensor slices. Otherwise, the API could be restricted to disallow ragged tensors.\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n```python\r\nimport tensorflow as tf\r\na = tf.ragged.stack([[1, 2], [3, 4, 5], [6], [7, 8, 9, 10]])\r\ndataset = tf.data.Dataset.from_tensor_slices(a)\r\nprint(dataset)\r\n# <TensorSliceDataset shapes: (None,), types: tf.int32>\r\nfor it in dataset:\r\n    print(it.numpy())\r\n# [1 2]\r\n# [3 4 5]\r\n# [6]\r\n# [ 7  8  9 10]\r\nbatches = dataset.padded_batch(batch_size=2, padded_shapes=[5])\r\n# TypeError: ('Padded batching of components of type ', <class 'tensorflow.python.ops.ragged.ragged_tensor.RaggedTensorSpec'>, ' is not supported.')\r\n```\r\n\r\nCompare with a similar working example with a dataset taken from the documentation of [`tf.data.Dataset.from_generator`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_generator):\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport itertools\r\ndef gen():\r\n    for i in itertools.count(1):\r\n        yield (i, [1] * i)\r\ndataset = tf.data.Dataset.from_generator(gen, (tf.int64, tf.int64), (tf.TensorShape([]), tf.TensorShape([None])))\r\nprint(dataset)\r\n# <FlatMapDataset shapes: ((), (None,)), types: (tf.int64, tf.int64)>\r\nfor it1, it2 in dataset.take(3):\r\n    print(it1.numpy(), it2.numpy())\r\n# 1 [1]\r\n# 2 [1 1]\r\n# 3 [1 1 1]\r\nbatches = dataset.padded_batch(batch_size=2, padded_shapes=([], [10]))\r\nfor it1, it2 in batches.take(3):\r\n    print(it1.numpy(), it2.numpy())\r\n# [1 2] [[1 0 0 0 0 0 0 0 0 0]\r\n#  [1 1 0 0 0 0 0 0 0 0]]\r\n# [3 4] [[1 1 1 0 0 0 0 0 0 0]\r\n#  [1 1 1 1 0 0 0 0 0 0]]\r\n# [5 6] [[1 1 1 1 1 0 0 0 0 0]\r\n#  [1 1 1 1 1 1 0 0 0 0]]\r\n```\r\n\r\n\r\n**Other info / logs** NA", "comments": ["Was able to reproduce the issue with [TF v2.1](https://colab.research.google.com/gist/amahendrakar/4cb13e191e75746af4cbd03f9fd266af/39163-2-1-0.ipynb), [TF v2.2.0rc4](https://colab.research.google.com/gist/amahendrakar/a8ff91eafb16f9d9f30b334d5674fed3/39163.ipynb) and [TF-nightly](https://colab.research.google.com/gist/amahendrakar/a232ada6dacbb4850ddb40fd3643df5a/39163-tf-nightly.ipynb#scrollTo=JLIl0PO0fWGD). Please find the attached gist. Thanks!", "Padded batching of ragged tensors is currently not supported (and this is indicated by the error message you get).\r\n\r\n@edloper is there a better option for padded batching of RaggedTensors than converting them DenseTensors?", "For now, the best solution is to convert them to dense tensors.  In your example (where you have a single ragged dimension), you can do this with just:\r\n\r\ndataset = tf.data.Dataset.from_tensor_slices(rt_with_one_ragged_dimension)\r\ndataset = dataset.map(lambda x: x)  # convert ragged -> uniform\r\n\r\nIf you had multiple ragged dimensions, then you'd need to use:\r\n\r\ndataset = tf.data.Dataset.from_tensor_slices(rt_with_multiple_ragged_dimensions)\r\ndataset = dataset.map(lambda x: x.to_tensor())  # convert ragged -> uniform\r\n\r\nIn the future, it would be good to make this work without any need for the user to convert from ragged to uniform.  (In particular, PaddedBatchDataset could do the conversion itself, rather than raising an exception.)", "Thanks for the replies. I just thought it seemed strange to have two datasets with the same data behave differently depending on how they were created, but if this is currently expected behavior then there's no reason to have this as an open issue.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39163\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39163\">No</a>\n"]}, {"number": 39162, "title": "Support for TensorList crossing the XLA/TF boundary is not implemented", "body": "A colab notebook to reproduce the issue: https://colab.research.google.com/drive/1O-ht27_h4d6qf_65nmK52qLTrMyDLMVr\r\n\r\nI am trying to implement a simple RNN compiled with XLA. The code works without XLA, but when I try to compile one tf function with XLA and I get a strange error:\r\n\r\n```\r\nUnimplementedError:  Support for TensorList crossing the XLA/TF boundary is not implemented\r\n\t [[node dummy_name/StatefulPartitionedCall (defined at <ipython-input-12-b36d3a96b1c7>:30) ]] [Op:__inference_simple_train_5054]\r\n\r\nErrors may have originated from an input operation.\r\nInput Source operations connected to node dummy_name/StatefulPartitionedCall:\r\n data (defined at <ipython-input-15-3f954a2dcc35>:38)\r\n```\r\n\r\nI am not sure what goes wrong when experimental_compile is added and if thats an expected behavior?", "comments": ["@EgorLakomkin \r\nI ran your code on tensorflow 2.1 and do not face any issues, please find the [gist here](https://colab.sandbox.google.com/gist/Saduf2019/196583ede82231e3e735f608b6bd154b/2.ipynb).\r\nHowever, i am able to replicate the issue on nightly,please find the [gist here](https://colab.sandbox.google.com/gist/Saduf2019/46d5e3cf5a8c3fed81a49eb7878a6d2d/untitled163.ipynb).\r\nThanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Any additional info is needed from me?", " @EgorLakomkin\r\nAs you have not specified the tf version, we ran the code on 2.1 and nightly. please verify the gist and as the code works fine in 2.1, can we consider this as resolved.", "It fails for me when I run it with tf-nightly. I guess it could indicate a regression from 2.1 -> 2.2?", "@EgorLakomkin \r\nSure we will do so, will working on 2.1 help you for now, meanwhile we will look into nightly issue.", "@EgorLakomkin This is expected behavior, this feature is not implemented.\r\nWe do plan on doing this, but it is non-trivial.\r\n\r\n`TensorArray` is supported in XLA, but not in crossing the TF/XLA boundary. The problem is that taking a derivative from *outside* exposes the TensorArray to the boundary, and the conversion is not implemented.\r\n\r\nThe workaround is to make the outer function compile (your `simple_train`), and potentially remove the inner compiled function (might be not necessary, but to avoid stumbling into your other issue in github.com/tensorflow/tensorflow/issues/39060)", "@EgorLakomkin \r\nPlease update as per above comment.", "@cheshire thank you, then maybe we can close this ticket.", "Moving this to closed status with confirmation.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39162\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39162\">No</a>\n"]}, {"number": 39161, "title": "Fix incorrect usage of tf.broadcast_weights in docstring", "body": "This PR tries to address the issue raised in #33526 where\r\n`tf.broadcast_weights` was used incorrectly in docstring\r\n(`broadcast_weights` is not public).\r\n\r\nSince the docstring uses `broadcast_weights` in a example,\r\nand `broadcast_weights` by itself is just to make sure\r\nit follow a subset of broadcast rules than `tf.multiply`,\r\nit actually makes sense to remove this line as it does not\r\nadd much to be an example in docs:\r\n\r\n```diff\r\n         sample_weight = tf.cast(sample_weight, self.dtype)\r\n-        sample_weight = tf.broadcast_weights(sample_weight, values)\r\n         values = tf.multiply(values, sample_weight)\r\n```\r\n\r\nThis PR fixes #33526\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["It looks like the issue has been addressed by @MarkDaoust 's commit 5dd0b6a \ud83d\udc4d . I will close this PR, but thanks all for the help!", "Sorry about that Yong. Thank you too."]}, {"number": 39160, "title": "Issue in google codelabs handwritten digit classifier code.", "body": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\nhttps://codelabs.developers.google.com/codelabs/digit-classifier-tflite/index.html?index=..%2F..index#7\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nThere is an error in the code of step 4 of the codelabs.\r\nget a null safety error when implementing the code\r\n\r\n", "comments": ["@PatrickPrakash \r\n\r\nIt was moved out of tensorflow GitHub repository to a new repository on GitHub. Link to the new repository is [here.](https://github.com/googlecodelabs/tools/issues) Please file an issue there so that it will be resolved faster. You could also raise a PR to update the docs in that repository. Thanks!\r\n\r\n", "There was a line of code needed to be added on the project. The Google Colab didn't mention in there steps. Anyway the final code is in the finish project of the repository.\r\nIssue Solved"]}, {"number": 39159, "title": "Fix issue in boolean_mask when axis is passed as a tensor", "body": "\r\nThis PR tries to address the issue raised in #32236 where\r\na TypeError was thrown out when axis is passed as a tensor.\r\nIn the docstring axis has been specified as accepting a 1-D tensor.\r\n\r\nThis PR fixes the issue.\r\n\r\nThis PR fixes #32236.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": []}, {"number": 39158, "title": "Added TANH op and test to micro", "body": "see previous pull request:\r\nhttps://github.com/tensorflow/tensorflow/pull/39055", "comments": ["Check out this pull request on&nbsp; <a href=\"https://app.reviewnb.com/tensorflow/tensorflow/pull/39158\"><img align=\"absmiddle\"  alt=\"ReviewNB\" height=\"28\" class=\"BotMessageButtonImage\" src=\"https://raw.githubusercontent.com/ReviewNB/support/master/images/button_reviewnb.png\"/></a> \n\n Review Jupyter notebook visual diffs & provide feedback on notebooks. \n\n---\n\n <i>Powered by <a href='https://www.reviewnb.com'>ReviewNB</a></i>", "> Files changed 1,628\r\n\r\nThis still doesn't look right.\r\n\r\nCan you try remaking this PR with just your changes? \r\n\r\nUpdate your master branch, create your pr branch from there, apply your changes, and submit that.\r\n\r\nIt's impossible to review like this. I've never seen this error before:\r\n\r\n```\r\nCommits that don\u2019t share a common merge base with the base branch are not supported.\r\nYou can view the full commit page here instead.\r\n```"]}, {"number": 39157, "title": "Inference problem using a tflite model java.lang.IllegalArgumentException: Invalid output Tensor index: 1", "body": "[Input and output shape][1]\r\n[Java exception][2]\r\nhow did you solve this exception please\r\njava.lang.IllegalArgumentException: Invalid output Tensor index: 1.\r\ni converted a yolov3-tiny model\r\ni changed the NUM_DETECTION into 2535 (NUM_DETECTION=2535) because the input shape is (1,416,416,6) and the output shape is (1,2535,6).\r\nI ve trained the model on license plates so it can detect them. like i said i've worked with the yolov3-tiny version with darknet, so i converted it to pb file then tflite file so i can use in an android app and detect plates in real time\r\n\r\n\r\n  [1]: https://i.stack.imgur.com/Rhw4R.png\r\n  [2]: https://i.stack.imgur.com/2ekGP.jpg", "comments": ["Please help if you have any suggestion or answer for this exception", "Can you pleas share a a standalone code to reproduce the issue? Thanks!", "@Anasel23 Please try to use `tf-nightly` while converting model to tflite. Please provide a standalone code if this was not resolved for you. \r\n\r\nClosing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks! ", "I'm having the exact same problem with the same error. (Wasn't sure if i should create a new issue)\r\n\r\nI'm using yolov3-tiny that was trained (using transfer learning) with [Alexey](https://github.com/AlexeyAB/darknet)'s implementation to detect 2 custom objects (knife and machete).\r\n\r\n[mystic's](https://github.com/mystic123/tensorflow-yolo-v3) implementation was then used  to convert the .weight file to a .pb\r\n\r\nThen I used the following code to convert the .pb file to .tflite\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\ngraph_def_file = \"frozen_darknet_yolov3_model.pb\"\r\ninput_arrays = [\"inputs\"]\r\noutput_arrays = [\"output_boxes\"]\r\n\r\nconverter = tf.lite.TFLiteConverter.from_frozen_graph(\r\n        graph_def_file, input_arrays, output_arrays)\r\ntflite_model = converter.convert()\r\nopen(\"converted_model.tflite\", \"wb\").write(tflite_model)\r\n```\r\n(I'm using tensorflow 1.15 to run this code)\r\n\r\nThe .tflite that was created is then moved to the assets folder of the object_detection example of tflite https://github.com/tensorflow/examples/tree/master/lite/examples/object_detection/android\r\n\r\nThe tflite and labelfile that I used can be found here https://drive.google.com/file/d/1Av7Q1mjLdOIEE81oNnt8cLENlXykxnEu/view?usp=sharing\r\n\r\nI changed the following on DetectorActivity.java\r\n```\r\nTF_OD_API_INPUT_SIZE from 300 to 416\r\nTF_OD_API_IS_QUANTIZED from true to false\r\n```\r\nThen I changed the following on TFLiteObjectDetectionAPIModel.java\r\n```\r\nNUM_DETECTIONS from 10 to 2535\r\nd.outputLocations = new float[1][NUM_DETECTIONS][4] to d.outputLocations = new float[1][NUM_DETECTIONS][7];\r\n```\r\nHere's the DetectorActivity.java and TFLiteObjectDetectionAPIModel.java that I use [here](https://drive.google.com/file/d/1Zf0i2Y_Tjyh7Li3UcxteKRB_k5Bwhhgt/view?usp=sharing)\r\n\r\nWhen I try to run the app on mobile phone, the app crashed with the following error \r\n```\r\nE/AndroidRuntime: FATAL EXCEPTION: inference\r\n    Process: org.tensorflow.lite.examples.detection, PID: 5535\r\n    java.lang.IllegalArgumentException: Invalid output Tensor index: 1\r\n        at org.tensorflow.lite.NativeInterpreterWrapper.getOutputTensor(NativeInterpreterWrapper.java:292)\r\n        at org.tensorflow.lite.NativeInterpreterWrapper.run(NativeInterpreterWrapper.java:166)\r\n        at org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:314)\r\n        at org.tensorflow.lite.examples.detection.tflite.TFLiteObjectDetectionAPIModel.recognizeImage(TFLiteObjectDetectionAPIModel.java:204)\r\n        at org.tensorflow.lite.examples.detection.DetectorActivity$2.run(DetectorActivity.java:181)\r\n        at android.os.Handler.handleCallback(Handler.java:873)\r\n        at android.os.Handler.dispatchMessage(Handler.java:99)\r\n        at android.os.Looper.loop(Looper.java:214)\r\n        at android.os.HandlerThread.run(HandlerThread.java:65)\r\n```\r\n\r\nAny assistance would be appreciated @jvishnuvardhan ", "@SirTapir Please create a new issue with a standalone code to reproduce the issue. Ping me in that issue. Thanks!", "I am sorry for being late i still have the same problem can you please give me more information about tf-nightly ?\r\nand how i can use it ", "@SirTapir we have the exact same problem i changed everything in the android code exactly like you but still dealing with this issue\r\ndid you solve it ?\r\n", "> @SirTapir Please create a new issue with a standalone code to reproduce the issue. Ping me in that issue. Thanks!\r\n\r\n@jvishnuvardhan\r\nAlright, I'm opening a new issue now\r\n\r\n\r\n\r\n> @SirTapir we have the exact same problem i changed everything in the android code exactly like you but still dealing with this issue\r\n> did you solve it ?\r\n\r\n@Anasel23\r\nNot yet, still facing the same problem", "@SirTapir Too i don't know of it is due to the pb conversion or the TFLite conversion. I am using Netron to visualize the graph and to specify the input_array and output_array. What are the parameters that you used for the TFLite conversion ?\r\n", "@Anasel23 Well, the code that I used to convert the .pb to .tflite is this\r\n```\r\nimport tensorflow as tf\r\n\r\ngraph_def_file = \"frozen_darknet_yolov3_model.pb\"\r\ninput_arrays = [\"inputs\"]\r\noutput_arrays = [\"output_boxes\"]\r\n\r\nconverter = tf.lite.TFLiteConverter.from_frozen_graph(\r\n        graph_def_file, input_arrays, output_arrays)\r\ntflite_model = converter.convert()\r\nopen(\"converted_model.tflite\", \"wb\").write(tflite_model)\r\n```\r\nWhile the input array and output array names are found by running this\r\n```\r\nimport tensorflow as tf\r\ngf = tf.GraphDef()   \r\nm_file = open('frozen_darknet_yolov3_model.pb','rb')\r\ngf.ParseFromString(m_file.read())\r\n\r\nwith open('somefile.txt', 'a') as the_file:\r\n    for n in gf.node:\r\n        the_file.write(n.name+'\\n')\r\n\r\nfile = open('somefile.txt','r')\r\ndata = file.readlines()\r\nprint(\"output name = \")\r\nprint(data[len(data)-1])\r\n\r\nprint(\"Input name = \")\r\nfile.seek ( 0 )\r\nprint(file.readline())\r\n```", "@SirTapir Thank you so much for your reply hope that you solved the problem. If you did can you explain what did you do, stil stuck with this issue. ", "@SirTapir the parameters are the same can i ask you a question please. What is the size of your tflite model ?\r\n", "I'm running into the exact same problem right now .. have you already solved this issue? @SirTapir @Anasel23 ", "@kaunghtetsan275 Yep, I've changed my converter to [hunglc007](https://github.com/hunglc007/tensorflow-yolov4-tflite)'s and used the android example in their repo as a reference to implement yolov3 to work in mobile app.", "@SirTapir thank you so much for this.. i've been having headache for the past few days because of this issue.. i've re-tried using the repo you've mentioned and the conversion and inference now work beautifully", "@kaunghtetsan275 Happy to help"]}, {"number": 39156, "title": "TF-TRT enable BiasAdd op in dynamic shape mode", "body": "Improve the converter of BiasAdd to handle explicit batch mode, and test it both in explicit batch and dynamic shape mode. \r\n\r\nTagging @bixia1 for review. ", "comments": ["@tfeher  Can you please resolve conflicts? Thanks!"]}, {"number": 39155, "title": "TF-TRT test activation converter", "body": "This PR adds dynamic shape and explicit batch tests for the activation ops. \r\n\r\nTagging @bixia1 for review", "comments": ["- Added variants of AsTensor and AddTestWeights where the tf_dtype parameter is a function arg instead of a template parameter. [Initialization of tf_dtype](https://github.com/tensorflow/tensorflow/blob/70e07a478cf84f876c9e819c82baf709e024936e/tensorflow/compiler/tf2tensorrt/convert/convert_nodes_test.cc#L1728) is not a constexpr (in C++11), and that lead to [cumbersome](https://github.com/tensorflow/tensorflow/blob/a65ece1e46d80ed2e4c14fc3c5e4bb048467fd81/tensorflow/compiler/tf2tensorrt/convert/convert_nodes_test.cc#L1756-L1761) instantiation BuildAndRun. This is simplified now.\r\n- Modify BuildAndRun to handle runtime errors.\r\n- Modify BuildAndRun to handle mulitple input/output tensors.\r\n- Moved the AddTesTensor variant with trt_mode attribute into ParameterizedOpConverterTest. The new dynamic shape tests will use that, and this way the trt_mode and tf_dtype args can be set automatically based on the test parameters, no need to explicitly pass them as args to the subroutines.\r\n- AddTestTensor initializes a TF input tensor too, not onle a TRT ITensor. Adding both tensors at one place helps to simplify the unit tests.\r\n", "@tfeher Can you please resolve conflicts? Thanks!"]}, {"number": 39154, "title": "Unbundling sqlite doesn't work with TF_SYSTEM_LIBS", "body": "Unable to use sqlite using TF_SYSTEM_LIBS\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux RHEL 7.7 ppc64le\r\n- TensorFlow installed from (source or binary): Source \r\n- TensorFlow version: 2.2.0-rc4 tag\r\n- Python version: 3.6/3.7\r\n- Installed using virtualenv? pip? conda?: conda\r\n- Bazel version (if compiling from source): 2.0.0\r\n- GCC/Compiler version (if compiling from source): 7.2\r\n- CUDA/cuDNN version: 10.2/7.6.5\r\n\r\n**Describe the problem**\r\nI'm facing an error while using TF_SYSTEM_LIBS=org_sqlite in my environment. I have correctly set PREFIX, INCLUDEDIR and LIBDIR to point to the installed location of sqlite with proper suffixes include and lib to PREFIX. In third_party/systemlibs/sqlite.BUILD, I've also created a genrule to create the symlinks of sqlite's headers which works correctly but somehow my TF's build still fails for not able to find libsqlite.so. For this I've also explicitly set LD_LIBRARY_PATH to point to the location of libsqlite.so. Another attempt was to add --linkopt in the bazel build command but still no luck. Kindly provide some thoughts on this.\r\n\r\nAlso, I believe setting PREFIX, INCLUDEDIR and LIBDIR variables should suffice for TF to locate the headers and libraries for any external dependency, instead of creating symlinks to them or setting any additional variables like LD_LIBRARY_PATH.\r\n\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nBuild flags\r\n```\r\nbuild --action_env TF_SYSTEM_LIBS=\"org_sqlite\"\r\nbuild:linux --define=PREFIX=\"$SYSTEM_LIBS_PREFIX\"\r\nbuild:linux --define=LIBDIR=\"$SYSTEM_LIBS_PREFIX/lib\"\r\nbuild:linux --define=INCLUDEDIR=\"$SYSTEM_LIBS_PREFIX/include\"\r\nbuild --action_env LD_LIBRARY_PATH=\"$LD_LIBRARY_PATH:$SYSTEM_LIBS_PREFIX/lib\"\r\n``` \r\nwhere SYSTEM_LIBS_PREFIX is the path where sqlite is installed in my environment.\r\n\r\nBazel build command - \r\n```\r\nbazel --bazelrc=$SRC_DIR/tensorflow/tensorflow.bazelrc build \\\r\n    --config=opt \\\r\n    --config=numa \\\r\n    --curses=no \\\r\n    --linkopt=\"-L${SQLITE_LIB}\" \\\r\n    //tensorflow/tools/pip_package:build_pip_package\r\n```\r\n\r\nBUILD file changes for sqlite in thirdparty/systemlibs/sqlite.BUILD\r\n```\r\n--- a/third_party/systemlibs/sqlite.BUILD\r\n+++ b/third_party/systemlibs/sqlite.BUILD\r\n@@ -1,12 +1,31 @@\r\n licenses([\"unencumbered\"])  # Public Domain\r\n\r\n+HEADERS = [\r\n+   \"sqlite3.h\",\r\n+   \"sqlite3ext.h\",\r\n+]\r\n+\r\n # Production build of SQLite library that's baked into TensorFlow.\r\n cc_library(\r\n     name = \"org_sqlite\",\r\n+    hdrs = HEADERS,\r\n+    includes = [\".\"],\r\n     linkopts = [\"-lsqlite3\"],\r\n     visibility = [\"//visibility:public\"],\r\n )\r\n\r\n+genrule(\r\n+    name = \"link_headers\",\r\n+    outs = HEADERS,\r\n+    message = \"Printing value of $$(INCLUDEDIR)\",\r\n+    cmd = \"\"\"\r\n+      for i in $(OUTS); do\r\n+        i=$${i##*/}\r\n+        ln -sf $(INCLUDEDIR)/$$i $(@D)/$$i\r\n+      done\r\n+    \"\"\",\r\n+)\r\n```\r\n**Any other info / logs**\r\n```\r\n[[ERROR: [/tmp/tmpTfBuild/work/tensorflow/python/BUILD:5796:1: Linking of rule '//tensorflow/python:_pywrap_tensorflow_internal.so' failed (Exit 1)\r\n/tmp/tmpTfBuild/_build_env/bin/../lib/gcc/powerpc64le-conda_cos7-linux-gnu/7.2.0/../../../../powerpc64le-conda_cos7-linux-gnu/bin/ld: cannot find -lsqlite3\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\n[ERROR: [/tmp/tmpTfBuild/work/tensorflow/tools/pip_package/BUILD:62:1 Linking of rule '//tensorflow/python:_pywrap_tensorflow_internal.so' failed (Exit 1)\r\n```", "comments": ["@perfinion - Any thoughts on this?", "@npanpaliya \r\nIs this still an issue", "@Saduf2019 - No, I've it fixed now.", "moving this to closed status with confirmation", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39154\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39154\">No</a>\n"]}, {"number": 39153, "title": "TF-TRT test ConvertUnary in dynamic shape mode.", "body": "This PR adds explicit batch and dynamic shape tests for the ConvertUnary op converter. \r\n\r\nTagging @bixia1 for review. ", "comments": ["@bixia1 I have put the lambda functions into a single map. Please have another look. "]}, {"number": 39151, "title": "TF-TRT ConvertTranspose in dynamic shape mode", "body": "This PR enables conversion of the Transpose op in dynamic shape mode and tests it. \r\n \r\nAdditionally the ConvertSqueeze test is simplified: the test params are now built in a way that they do not contain invalid combinations. E.g. if trt_mode==kImplicitBatch we do not add dynamic input shapes, only static shapes. This way we can remove the skip_test arg of AddTestTensor.\r\n\r\nTagging @bixia1 for review.", "comments": []}, {"number": 39150, "title": "[TFLite 16x8] Leaky Relu reference kernel for activations in int16", "body": "This PR is one of steps to extend 8-bit quantization to support symmetric 16-bit activations - each activation is of type int16 and symmetric around zero. The weight tensor precision remains at 8-bit signed values. The bias is set to int64 precision.\r\n\r\nIn this PR we enable LEAKY_RELU kernel reference function.\r\nVersioning is added.", "comments": ["Hi Renjie, can you take a look?", "@wwwind Can you please resolve conflicts? Thanks!\r\n", "Hi @renjie-liu , Could you please re-approve this PR ? I had to resolve a conflict."]}, {"number": 39148, "title": "How to enable C++ API usage from AAR builds (and integrate into gradle project)?", "body": "\r\n**System information**\r\n- OS Platform and Distribution: Linux Ubuntu 16.04\r\n- Mobile device: Samsung Galaxy S10\r\n- TensorFlow installed from: pip\r\n- TensorFlow version: 2.1.0\r\n- Python version: 3.5.2\r\n- Installed using: virtualenv / pip\r\n- Bazel version (if compiling from source): 3.0.0\r\n- GCC/Compiler version (if compiling from source): 5.4.0\r\n\r\n**Describe the problem**\r\n\r\nHow to enable C++ API usage from AAR builds (and integrate into gradle project)?\r\nI'm trying to run a simple inference from the C++ API... what am I missing? I've tried following the guides at the TF website, and the Github repositories (minimal / image classification) but I'm missing the part where the TFLite library joins the Android Studio NDK.\r\n\r\nIs there a way to use C++ API the same way I've been using the Java API via gradle? (kindly see attached comment by @jdduke)\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nhttps://www.tensorflow.org/lite/guide/android\r\nhttps://www.tensorflow.org/lite/guide/inference\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/examples/minimal/minimal.cc\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/examples/label_image/label_image.cc\r\nhttps://www.tensorflow.org/lite/guide/build_arm64\r\n\r\n**Any other info / logs**\r\n_Originally posted by @jdduke in https://github.com/tensorflow/tensorflow/issues/34489#issuecomment-558261882_", "comments": ["@orangesomethingorange \r\nPlease refer to these issues and let us know if it helps:\r\n#39120\r\n[link](https://stackoverflow.com/questions/35140809/android-aar-package-for-native-library)\r\n[link2](https://github.com/tensorflow/tensorflow/issues/34489)\r\n[link3](https://medium.com/@yushulx/how-to-build-so-library-files-into-aar-bundle-in-android-studio-a44387c9a012)", "@orangesomethingorange \r\nPlease check this also \r\n[link](https://stackoverflow.com/questions/49834875/problems-with-using-tensorflow-lite-c-api-in-android-studio-project)", "Hi @orangesomethingorange, we currently don't have any plans to expose the C++ API directly from the .aar. Generally speaking, using C++ across shared library boundaries is a tricky affair.\r\n\r\nThat said, we do expose the *C API* for TFLite in the prebuilt .aars. We're working on a sample which downloads the aar from Maven and extracts them via Gradle. The .aar also include the C API headers. See also https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/c.", "> @orangesomethingorange\r\n> Please refer to these issues and let us know if it helps:\r\n> #39120\r\n> [link](https://stackoverflow.com/questions/35140809/android-aar-package-for-native-library)\r\n> [link2](https://github.com/tensorflow/tensorflow/issues/34489)\r\n> [link3](https://medium.com/@yushulx/how-to-build-so-library-files-into-aar-bundle-in-android-studio-a44387c9a012)\r\n\r\nHi @Saduf2019,\r\nThanks for the links ;)\r\n\r\n### Trying to add the flatbuffers libs:\r\nTo use tfilte I need to also add the flatbuffers libraries, if I understand correctly.\r\nI tried following [flatbuffers build guide](https://google.github.io/flatbuffers/flatbuffers_guide_building.html) and compile the libs using Android Studio's CMake.\r\nIndirect path resulted in an error, so I set the directory's full path:\r\n\r\n**CMakeLists.txt**:\r\n```\r\ncmake_minimum_required(VERSION 3.4.1)\r\nset( FLATBUFFERS_SRC_DIR /full/path/to/flatbuffers )\r\nadd_subdirectory(${FLATBUFFERS_SRC_DIR}\r\n                 ${CMAKE_CURRENT_BINARY_DIR}/flatbuffers-build\r\n                 EXCLUDE_FROM_ALL)\r\nadd_library(\r\n             native-lib\r\n             SHARED\r\n             native-lib.cpp )\r\nfind_library(\r\n              log-lib\r\n              log )\r\ntarget_link_libraries(\r\n        native-lib\r\n        PRIVATE flatbuffers\r\n        ${log-lib} )\r\n```\r\n\r\nbut trying to build this with Android Studio results in the following:\r\n\r\n```\r\nFAILED: flatbuffers-build/tests/union_vector/union_vector_generated.h \r\ng\ufffd\ufffd\ufffdd\ufffdC\ufffd\u007f\u001e\ufffd: not found\r\nFAILED: flatbuffers-build/tests/namespace_test/namespace_test2_generated.h \r\ng\ufffd\ufffd\ufffdd\ufffdC\ufffd\u007f\u001e\ufffd: not found\r\nFAILED: flatbuffers-build/tests/arrays_test_generated.h \r\ng\ufffd\ufffd\ufffdd\ufffdC\ufffd\u007f\u001e\ufffd: not found\r\nFAILED: flatbuffers-build/tests/native_type_test_generated.h \r\ng\ufffd\ufffd\ufffdd\ufffdC\ufffd\u007f\u001e\ufffd: not found\r\n...\r\nFAILED: flatbuffers-build/tests/monster_test_bfbs_generated.h \r\ng\ufffd\ufffd\ufffdd\ufffdC\ufffd\u007f\u001e\ufffd: not found\r\nninja: build stopped: subcommand failed.\r\n```\r\n\r\n### Trying to add the tflite libs:\r\nI tried following [TF world's pdf](https://github.com/infil00p/tf_world) and [this question](https://stackoverflow.com/questions/49834875/problems-with-using-tensorflow-lite-c-api-in-android-studio-project) to use a .so library.\r\nAlso I tried using Bazel to build .a files or .aar files - and include them in Android Studio.\r\nI've used Bazel on my server and also within TensorFlow's Docker container.\r\nSo after all these trials I'm left with the .so, .a and .aar files.\r\nThey're all currently located inside my Android app folder, under /app/libs directory, and I've tried to include them in my CMakeLists.txt file in several ways (not all at once, of course):\r\n\r\n**CMakeLists.txt**:\r\n\r\n```\r\n# set(tflite_DIR ../../../libs)\r\n# set(tflite_DIR /full/path/to/app/libs )\r\n# set(TENSORFLOW_DIR /full/path/to/tensorflow/ )\r\n\r\n#add_library(lib_tflite SHARED IMPORTED)\r\n#set_target_properties(lib_tflite PROPERTIES IMPORTED_LOCATION\r\n#        ${tflite_DIR}/tflite/lib/${ANDROID_ABI}/libtensorflowlite_c.so)\r\n#\r\n#add_library(lib_tflite_gpu SHARED IMPORTED)\r\n#set_target_properties(lib_tflite_gpu PROPERTIES IMPORTED_LOCATION\r\n#        ${tflite_DIR}/tflite/lib/${ANDROID_ABI}/libtensorflowlite_gpu_delegate.so)\r\n#\r\n#add_library(lib_nnapi SHARED IMPORTED)\r\n#set_target_properties(lib_nnapi PROPERTIES IMPORTED_LOCATION\r\n#        ${tflite_DIR}/tflite/lib/${ANDROID_ABI}/libnnapi_delegate.so)\r\n#\r\n#target_include_directories(hello-libs PRIVATE\r\n#        ${tflite_DIR}/tflite/include\r\n#        ${tflite_DIR}/tflite/include/tensorflow/lite/tools/make/downloads\r\n#        ${tflite_DIR}/tflite/include/tensorflow/lite/tools/make/downloads/flatbuffers/include\r\n#        )\r\n\r\n#add_library(libtflite SHARED IMPORTED)\r\n#\r\n#set_target_properties(libtflite PROPERTIES IMPORTED_LOCATION\r\n#        ${TENSORFLOW_DIR}bazel-out/arm64-v8a-opt/bin/tensorflow/lite/libtensorflowLite.so)\r\n\r\n#add_library(\r\n#        libtflite\r\n#        SHARED\r\n#        IMPORTED )\r\n#\r\n#set_target_properties(libtflite\r\n#        PROPERTIES IMPORTED_LOCATION\r\n#        ${tflite_DIR}/tensorflow-lite.aar)\r\n\r\n#add_library(libtensorflowLite\r\n#        SHARED\r\n#        IMPORTED)\r\n#\r\n#set_target_properties(\r\n#        libtensorflowLite PROPERTIES IMPORTED_LOCATION\r\n#        ${tflite_DIR}/libtensorflowLite.so)\r\n```\r\n\r\nso for example here is something that builds and compiles without any errors:\r\n```\r\nset(tflite_DIR /full/path/to/app/libs )\r\nadd_library(libtensorflowLite\r\n        SHARED\r\n        IMPORTED)\r\nset_target_properties(\r\n        libtensorflowLite PROPERTIES IMPORTED_LOCATION\r\n        ${tflite_DIR}/libtensorflowLite.so)\r\ntarget_link_libraries(\r\n        native-lib\r\n        libtensorflowLite\r\n        ${log-lib} )\r\n```\r\n\r\nbut when I try to use it in my cpp code - it doesn't seem to recognize any tensorflow library.\r\nI can't `#include` anything or use any functions, ops or headers.\r\nIs there an extra step I'm missing here?", "> @orangesomethingorange\r\n> Please check this also\r\n> [link](https://stackoverflow.com/questions/49834875/problems-with-using-tensorflow-lite-c-api-in-android-studio-project)\r\n\r\nthanks @pranv12,\r\nI checked that link too - see my previous reply.", "> Hi @orangesomethingorange, we currently don't have any plans to expose the C++ API directly from the .aar. Generally speaking, using C++ across shared library boundaries is a tricky affair.\r\n> \r\n> That said, we do expose the _C API_ for TFLite in the prebuilt .aars. We're working on a sample which downloads the aar from Maven and extracts them via Gradle. The .aar also include the C API headers. See also https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/c.\r\n\r\n@jdduke that's great news - I'll check that out now :)\r\nGenerally speaking I'm currently trying to run a simple inference from a .tflite model file. When using the Java API I ran the inference and used the NNAPI and GPU delegates.\r\nFrom the README description I can tell that \"This includes C APIs for common types, like kernels and delegates, as well as an explicit C API for inference\" so I guess that it can work.\r\n\r\nLater on I'll want to do some pre- or post- processing to the inputs / outputs of the image - I assume that's where the C API differs from the C++ one - correct?\r\n\r\nPerhaps including an external library - such as OpenCV - may solve this.\r\nAny thoughts?", "@orangesomethingorange  \r\n\r\nReply for steps you did in [comment](https://github.com/tensorflow/tensorflow/issues/39148#issuecomment-624075335)\r\nWhichever IDE you are using search there for the option to include additional dependencies. And then try adding path to TFlite folder. This will add your TFlite Libraries.\r\nFor flatbuffers please read below.\r\n\r\n\r\nI had same problem. \r\nHere's what I did.\r\n\r\n1. In my workspace, I created a folder `include` (for External dependencies eg. TFlite, flatbuffers, etc)\r\n2. Dowloaded only `tensorflow` folder from [source](https://github.com/tensorflow/tensorflow/tree/master/tensorflow). (You can do it using [svn](https://tortoisesvn.net/docs/release/TortoiseSVN_en/index.html))\r\n3. Similarly downloaded TFLite dependency [flatbuffers](https://github.com/google/flatbuffers/tree/master/include/flatbuffers) folder from the source. \r\n4. Also, TFlite needs absl header files so I downloaded [absl header files](https://github.com/abseil/abseil-cpp/tree/master/absl) from the source.\r\n5. I'm working in Microsoft VS. I added the `path/to/dir/include` in additional dependencies. Whichever IDE you are using search there for the option to include additional dependencies.\r\n\r\nOnly the above folders are necessary no need to clone the complete repo.\r\n\r\nAfter this include folder contains:\r\ninclude:\r\n--tensorflow\r\n    ---- Some Folders (Including lite)\r\n    ---- Some Files\r\n--flatbuffers\r\n   ---- Some Folders\r\n   ---- Some Files\r\n--absl\r\n   ---- Some Folders\r\n   ---- Some Files\r\n\r\n\r\nExtra note: \r\nHow to use svn. [stackoverflow post](https://stackoverflow.com/questions/7106012/download-a-single-folder-or-directory-from-a-github-repo).\r\n\r\n\r\nI hope this help. :)", "> Later on I'll want to do some pre- or post- processing to the inputs / outputs of the image - I assume that's where the C API differs from the C++ one - correct?\r\n\r\nNo, the C and C++ APIs are largely equivalent in terms of functionality. Note that you can still use C++ in your own library when using the C API. Also, the C API is self-contained, and has no absl/flatbuffer dependencies in the public API.", "> Hi @orangesomethingorange, we currently don't have any plans to expose the C++ API directly from the .aar. Generally speaking, using C++ across shared library boundaries is a tricky affair.\r\n> \r\n> That said, we do expose the _C API_ for TFLite in the prebuilt .aars. We're working on a sample which downloads the aar from Maven and extracts them via Gradle. The .aar also include the C API headers. See also https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/c.\r\n\r\n@jdduke I tried to build the C API library for Android like so:\r\n\r\n### On my x86 Linux Ubuntu 16.04 [(following this):](https://www.tensorflow.org/lite/guide/android#build_tensorflow_lite_locally)\r\n\r\n```\r\nuser@ub-16 $ bazel --version\r\nbazel 3.1.0\r\nuser@ub-16 $ cat tensorflow/.tf_configure.bazelrc | grep -ie android\r\nbuild --action_env ANDROID_NDK_HOME=\"/home/user/Android/Sdk/ndk/20.0.5594570/\"\r\nbuild --action_env ANDROID_NDK_API_LEVEL=\"28\"\r\nbuild --action_env ANDROID_BUILD_TOOLS_VERSION=\"29.0.3\"\r\nbuild --action_env ANDROID_SDK_API_LEVEL=\"29\"\r\nbuild --action_env ANDROID_SDK_HOME=\"/home/user/Android/Sdk\"\r\nuser@ub-16 $ bazel build -c opt --cxxopt=--std=c++11 --config=android_arm64 //tensorflow/lite/c:tensorflowlite_c\r\n...\r\nERROR: /home/user/.cache/bazel/_bazel_user/22c116ddaf0b061cb1d24c68b7eae373/external/local_config_cc/BUILD:47:1: in cc_toolchain_suite rule @local_config_cc//:toolchain: cc_toolchain_suite '@local_config_cc//:toolchain' does not contain a toolchain for cpu 'arm64-v8a'\r\nERROR: Analysis of target '//tensorflow/lite/c:tensorflowlite_c' failed; build aborted: Analysis of target '@local_config_cc//:toolchain' failed\r\nINFO: Elapsed time: 0.209s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (9 packages loaded, 131 targets configured)\r\n\r\n```\r\n\r\n\r\n### On TensorFlow's Docker container [(following this):](https://www.tensorflow.org/lite/guide/build_arm64)\r\n\r\n```\r\nuser@ub-16 $ sudo docker run -it --name tflite tensorflow/tensorflow:nightly-devel\r\nroot@148806b57557:~# apt-get update\r\n...\r\nReading package lists... Done\r\nroot@148806b57557:~# apt-get install crossbuild-essential-arm64\r\n...\r\nroot@148806b57557:/home# git clone https://github.com/tensorflow/tensorflow\r\nroot@148806b57557:/home/tensorflow# ./tensorflow/lite/tools/make/download_dependencies.sh\r\n...\r\ndownload_dependencies.sh completed successfully.\r\nroot@148806b57557:/home/tensorflow# bazel build -c opt --cxxopt=--std=c++11 --config=android_arm64 //tensorflow/lite/c:tensorflowlite_c\r\nExtracting Bazel installation...\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=101\r\nINFO: Reading rc options for 'build' from /home/tensorflow/.bazelrc:\r\n  Inherited 'common' options: --experimental_repo_remote_exec\r\nWARNING: while reading option defaults file '/home/tensorflow/.bazelrc':\r\n  invalid command name 'try-import'.\r\nWARNING: while reading option defaults file '/home/tensorflow/.bazelrc':\r\n  invalid command name 'try-import'.\r\nERROR: Unrecognized option: --experimental_repo_remote_exec\r\nWARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command \"bazel shutdown\".\r\n```\r\n\r\nbut it seems I do not have the proper toolchain for that.\r\n\r\n### (Not for Android) on Ubuntu 16.04:\r\n\r\nBuilding with `bazel build -c opt //tensorflow/lite/c:tensorflowlite_c` build ok on x86 Ubuntu 16.04.\r\nBut when I try to include that in Android Studio like so:\r\n\r\n**CMakeLists.txt**:\r\n```\r\ncmake_minimum_required(VERSION 3.4.1)\r\nset(tflite_DIR /home/user/AndroidStudioProjects/tflite/app/libs )\r\nadd_library(\r\n             native-lib\r\n             SHARED\r\n             native-lib.cpp )\r\nadd_library(libTensorflowLiteC\r\n        SHARED\r\n        IMPORTED)\r\nset_target_properties(\r\n        libTensorflowLiteC PROPERTIES IMPORTED_LOCATION\r\n        ${tflite_DIR}/libTensorflowLiteC.so)\r\nfind_library(\r\n              log-lib\r\n              log )\r\ntarget_link_libraries(\r\n        native-lib\r\n        libTensorflowLiteC\r\n        ${log-lib} )\r\n```\r\n\r\nI get the following build error:\r\n\r\n```\r\nBuild command failed.\r\nError while executing process /home/user/Android/Sdk/cmake/3.10.2.4988404/bin/ninja with arguments {-C /home/user/AndroidStudioProjects/tflite/app/.cxx/cmake/debug/arm64-v8a native-lib}\r\nninja: Entering directory `/home/user/AndroidStudioProjects/tflite/app/.cxx/cmake/debug/arm64-v8a'\r\n[1/2] Building CXX object CMakeFiles/native-lib.dir/native-lib.cpp.o\r\n[2/2] Linking CXX shared library /home/user/AndroidStudioProjects/tflite/app/build/intermediates/cmake/debug/obj/arm64-v8a/libnative-lib.so\r\nFAILED: /home/user/AndroidStudioProjects/tflite/app/build/intermediates/cmake/debug/obj/arm64-v8a/libnative-lib.so \r\n: && /home/user/Android/Sdk/ndk/20.0.5594570/toolchains/llvm/prebuilt/linux-x86_64/bin/clang++ --target=aarch64-none-linux-android28 --gcc-toolchain=/home/user/Android/Sdk/ndk/20.0.5594570/toolchains/llvm/prebuilt/linux-x86_64 --sysroot=/home/user/Android/Sdk/ndk/20.0.5594570/toolchains/llvm/prebuilt/linux-x86_64/sysroot -fPIC -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -fno-addrsig -Wa,--noexecstack -Wformat -Werror=format-security   -O0 -fno-limit-debug-info  -Wl,--exclude-libs,libgcc.a -Wl,--exclude-libs,libatomic.a -static-libstdc++ -Wl,--build-id -Wl,--warn-shared-textrel -Wl,--fatal-warnings -Wl,--no-undefined -Qunused-arguments -Wl,-z,noexecstack -shared -Wl,-soname,libnative-lib.so -o /home/user/AndroidStudioProjects/tflite/app/build/intermediates/cmake/debug/obj/arm64-v8a/libnative-lib.so CMakeFiles/native-lib.dir/native-lib.cpp.o  /home/user/AndroidStudioProjects/tflite/app/libs/libTensorflowLiteC.so /home/user/Android/Sdk/ndk/20.0.5594570/toolchains/llvm/prebuilt/linux-x86_64/sysroot/usr/lib/aarch64-linux-android/28/liblog.so -latomic -lm && :\r\n**/home/user/AndroidStudioProjects/tflite/app/libs/libTensorflowLiteC.so: error adding symbols: File in wrong format**\r\nclang++: error: linker command failed with exit code 1 (use -v to see invocation)\r\nninja: build stopped: subcommand failed.\r\n```\r\n\r\nHow should I build the C API to be used in Android Studio?", "> @orangesomethingorange\r\n> \r\n> Reply for steps you did in [comment](https://github.com/tensorflow/tensorflow/issues/39148#issuecomment-624075335)\r\n> Whichever IDE you are using search there for the option to include additional dependencies. And then try adding path to TFlite folder. This will add your TFlite Libraries.\r\n> For flatbuffers please read below.\r\n> \r\n> I had same problem.\r\n> Here's what I did.\r\n> \r\n>     1. In my workspace, I created a folder `include` (for External dependencies eg. TFlite, flatbuffers, etc)\r\n> \r\n>     2. Dowloaded only `tensorflow` folder from [source](https://github.com/tensorflow/tensorflow/tree/master/tensorflow). (You can do it using [svn](https://tortoisesvn.net/docs/release/TortoiseSVN_en/index.html))\r\n> \r\n>     3. Similarly downloaded TFLite dependency [flatbuffers](https://github.com/google/flatbuffers/tree/master/include/flatbuffers) folder from the source.\r\n> \r\n>     4. Also, TFlite needs absl header files so I downloaded [absl header files](https://github.com/abseil/abseil-cpp/tree/master/absl) from the source.\r\n> \r\n>     5. I'm working in Microsoft VS. I added the `path/to/dir/include` in additional dependencies. Whichever IDE you are using search there for the option to include additional dependencies.\r\n> \r\n> \r\n> Only the above folders are necessary no need to clone the complete repo.\r\n> \r\n> After this include folder contains:\r\n> include:\r\n> --tensorflow\r\n> ---- Some Folders (Including lite)\r\n> ---- Some Files\r\n> --flatbuffers\r\n> ---- Some Folders\r\n> ---- Some Files\r\n> --absl\r\n> ---- Some Folders\r\n> ---- Some Files\r\n> \r\n> Extra note:\r\n> How to use svn. [stackoverflow post](https://stackoverflow.com/questions/7106012/download-a-single-folder-or-directory-from-a-github-repo).\r\n> \r\n> I hope this help. :)\r\n\r\n@pranv12,\r\n\r\nMy IDE is Android Studio 3.6.3.\r\nTo include **_flatbuffers_** and **_abseil_** I use their **_CMakeLists.txt_** files, trying to build them with Gradle, which fails with the following error:\r\n\r\n`ninja: error: '../jniLibs/abseilLib/arm64-v8a/lib_abseil.a', needed by '/home/user/AndroidStudioProjects/tflite/app/build/intermediates/cmake/debug/obj/arm64-v8a/libnative-lib.so', missing and no known rule to make it`\r\n", "> (Not for Android) on Ubuntu 16.04:\r\n\r\n@jdduke - continuing from previous\r\n### (Not for Android) on Ubuntu 16.04:\r\n\r\nI created a fresh Android Studio C++ empty project and used the following **CMakeLists.txt**:\r\n```\r\ncmake_minimum_required(VERSION 3.4.1)\r\nset( lib_tflite_DIR ../jniLibs )\r\nfile(MAKE_DIRECTORY ${lib_tflite_DIR})\r\nfile(MAKE_DIRECTORY ${lib_tflite_DIR}/${ANDROID_ABI})\r\nadd_library( tflite-lib\r\n        SHARED\r\n        IMPORTED )\r\nset_target_properties(\r\n        tflite-lib\r\n        PROPERTIES IMPORTED_LOCATION\r\n        app/src/main/jniLibs/x86_64/libtensorflowlite_c.so )\r\nadd_library(\r\n             native-lib\r\n             SHARED\r\n             native-lib.cpp )\r\nfind_library(\r\n              log-lib\r\n              log )\r\ntarget_link_libraries(\r\n        native-lib\r\n        tflite-lib\r\n        ${log-lib} )\r\n```\r\n\r\nand got the following error trying to build:\r\n\r\n```\r\nBuild command failed.\r\nError while executing process /home/user/Android/Sdk/cmake/3.10.2.4988404/bin/ninja with arguments {-C /home/user/AndroidStudioProjects/tflite/app/.cxx/cmake/debug/arm64-v8a native-lib}\r\nninja: Entering directory `/home/user/AndroidStudioProjects/tflite/app/.cxx/cmake/debug/arm64-v8a'\r\n\r\n**ninja: error:** 'app/src/main/jniLibs/x86_64/libtensorflowlite_c.so', **needed by** '/home/user/AndroidStudioProjects/tflite/app/build/intermediates/cmake/debug/obj/arm64-v8a/libnative-lib.so', **missing and no known rule to make it**\r\n```\r\n\r\nTrying to change `BUILD` target in bazel or create a new target did not prove successful either.\r\nIs buildting the C API libs from Gradle's `CMakeLists.txt` an option?\r\n", "In your CMakeLists.txt it looks like you've specified the x86_64 binary, whereas  the build error is looking in the arm64 directory?\r\n\r\n`ninja: Entering directory /home/user/AndroidStudioProjects/tflite/app/.cxx/cmake/debug/arm64-v8a\r\n` ", "I have the same `.so` library file placed in both directories, with architecture-names accordingly, just in case Gradle (or ninja) wants to look for them there (i.e. `app/src/main/jniLibs/arm64-v8a/[LIB].so` and `app/src/main/jniLibs/x86_64/[LIB].so`).\r\n\r\nIn my `CMakeLists.txt` file I have:\r\n```\r\nset_target_properties(\r\n        tflite-lib\r\n        PROPERTIES IMPORTED_LOCATION\r\n        **app/src/main/jniLibs/x86_64/libtensorflowlite_c.so** )\r\n```\r\nso I guess that's why the build error stated that path.\r\n\r\nI specified both architectures at build.\r\nChanging the line to `app/src/main/jniLibs/arm64-v8a/libtensorflowlite_c.so` results in the same error, just with this path:\r\n`ninja: error: 'app/src/main/jniLibs/arm64-v8a/libtensorflowlite_c.so', needed by '/home/user/AndroidStudioProjects/tflite/app/build/intermediates/cmake/debug/obj/arm64-v8a/libnative-lib.so', missing and no known rule to make it`\r\n\r\nAlso, taking the following line as an example:\r\n`bazel build -c opt\r\n--fat_apk_cpu=x86_64,arm64-v8a --cpu=x86_64,arm64-v8a\r\n--host_crosstool_top=@bazel_tools//tools/cpp:toolchain\r\n//tensorflow/lite/java:tensorflow-lite`\r\n\r\nI tried various architecture combinations:\r\n```\r\n--fat_apk_cpu=x86_64,arm64-v8a --cpu=x86_64,arm64-v8a\r\n\r\n--fat_apk_cpu=x86_64 --cpu=x86_64\r\n\r\n--fat_apk_cpu=aarch64 --cpu=aarch64\r\n\r\n--cpu=x86_64,arm64-v8a\r\n\r\n--fat_apk_cpu=x86_64,arm64-v8a\r\n\r\n--fat_apk_cpu=arm64-v8a --cpu=x86_64\r\n```\r\nbut build fails.\r\n\r\nThis line use the CPP toolchain on the `tensorflow/lite/java` library, following [this example](https://www.tensorflow.org/lite/guide/android#build_and_install), but I fail to find the toolchain code in the bazel BUILD files.\r\n\r\nCould this be the issue? I'm only just getting to know bazel now...", "> > Later on I'll want to do some pre- or post- processing to the inputs / outputs of the image - I assume that's where the C API differs from the C++ one - correct?\r\n> \r\n> No, the C and C++ APIs are largely equivalent in terms of functionality. Note that you can still use C++ in your own library when using the C API. Also, the C API is self-contained, and has no absl/flatbuffer dependencies in the public API.\r\n\r\n@jdduke I think I misunderstood your answer. I thought that having the C API being self-contained and free from absl/flatbuffer dependencies means I can just use the files.\r\nAfter failing to build the library as a shared / static library to include in my project, I tried to build and compile the source and header files directly in the IDE. I started from the example in the `c_api.h` file, and added headers one by one, until I got to here:\r\n```\r\n$ tree\r\n.\r\n|-- absl\r\n|   |-- base\r\n|   |   |-- attributes.h\r\n|   |   |-- config.h\r\n|   |   |-- internal\r\n|   |   |   |-- identity.h\r\n|   |   |   |-- inline_variable.h\r\n|   |   |   `-- invoke.h\r\n|   |   |-- macros.h\r\n|   |   |-- optimization.h\r\n|   |   |-- options.h\r\n|   |   |-- policy_checks.h\r\n|   |   `-- port.h\r\n|   |-- memory\r\n|   |   `-- memory.h\r\n|   |-- meta\r\n|   |   `-- type_traits.h\r\n|   |-- types\r\n|   |   |-- bad_optional_access.h\r\n|   |   |-- internal\r\n|   |   |   `-- optional.h\r\n|   |   `-- optional.h\r\n|   `-- utility\r\n|       `-- utility.h\r\n|-- flatbuffers\r\n|   |-- base.h\r\n|   |-- flatbuffers.h\r\n|   `-- stl_emulation.h\r\n`-- tensorflow\r\n    |-- core\r\n    |   `-- public\r\n    |       `-- version.h\r\n    `-- lite\r\n        |-- allocation.h\r\n        |-- c\r\n        |   |-- c_api.h\r\n        |   |-- c_api_internal.h\r\n        |   `-- common.h\r\n        |-- core\r\n        |   |-- api\r\n        |   |   |-- error_reporter.h\r\n        |   |   |-- op_resolver.h\r\n        |   |   `-- profiler.h\r\n        |   |-- macros.h\r\n        |   `-- subgraph.h\r\n        |-- delegates\r\n        |   `-- nnapi\r\n        |       `-- nnapi_delegate.h\r\n        |-- error_reporter.h\r\n        |-- experimental\r\n        |   `-- resource\r\n        |       `-- resource_base.h\r\n        |-- external_cpu_backend_context.h\r\n        |-- interpreter.h\r\n        |-- interpreter_builder.h\r\n        |-- kernels\r\n        |   `-- register.h\r\n        |-- memory_planner.h\r\n        |-- model.h\r\n        |-- model_builder.h\r\n        |-- mutable_op_resolver.h\r\n        |-- nnapi\r\n        |   |-- NeuralNetworksTypes.h\r\n        |   `-- nnapi_implementation.h\r\n        |-- schema\r\n        |   `-- schema_generated.h\r\n        |-- stderr_reporter.h\r\n        |-- string_type.h\r\n        |-- type_to_tflitetype.h\r\n        |-- util.h\r\n        `-- version.h\r\n```\r\nthis was the minimal structure I got to by following header files.\r\nAs you can see - absl/flatbuffer dependencies do exist.\r\n\r\n### Issue 1\r\nTrying to build from this structure results in build errors of the form:\r\n`error: undefined reference to '[FUNCTION]'` which all relate to functions found in `c_api.cc`.\r\n\r\n### Issue 2\r\nTrying to add and build with `c_api.cc` included,\r\n\r\nresults in the following error from `<memory>`:\r\n`.../toolchains/llvm/prebuilt/linux-x86_64/sysroot/usr/include/c++/v1/memory:2339: error: undefined reference to 'tflite::impl::Interpreter::~Interpreter()'`\r\nwhen building for `x86_64`\r\n\r\nand the following errors:\r\n```\r\nc_api.cc:62: undefined reference to `tflite::DefaultErrorReporter()'\r\nc_api.cc:62: undefined reference to `tflite::FlatBufferModel::VerifyAndBuildFromBuffer(char const*, unsigned long, tflite::TfLiteVerifier*, tflite::ErrorReporter*)'\r\n[[ many more \"undefined reference to\" from c_api.cc ]]\r\n...\r\nmutable_op_resolver.h:59: undefined reference to `vtable for tflite::MutableOpResolver'\r\n[[ likewise ]]\r\n...\r\nmemory:2339: undefined reference to `tflite::FlatBufferModel::~FlatBufferModel()'\r\nc_api.cc.o: In function `std::__ndk1::default_delete<tflite::impl::Interpreter>::operator()(tflite::impl::Interpreter*) const':\r\n```\r\nwhen trying to build for `arm64-v8a`.\r\n\r\nThis was done using clang++ in the toolchain.\r\n\r\nHow can I use the C API independently?", ">  I thought that having the C API being self-contained and free from absl/flatbuffer dependencies means I can just use the files.\r\n\r\nSorry if it wasn't clear, what I meant is that the C API *headers* are free from external dependencies. So you can easily drop the shared library + 2-3 lite/c/*.h headers into your project and use them directly, as opposed to also needing flatbuffer headers. The actual C API *implementation* requires all the same libraries as the C++ API.", "> > I thought that having the C API being self-contained and free from absl/flatbuffer dependencies means I can just use the files.\r\n> \r\n> Sorry if it wasn't clear, what I meant is that the C API _headers_ are free from external dependencies. So you can easily drop the shared library + 2-3 lite/c/*.h headers into your project and use them directly, as opposed to also needing flatbuffer headers. The actual C API _implementation_ requires all the same libraries as the C++ API.\r\n\r\nOK, that's great news but how do I use them?\r\nThe only example of running inference with the C-API is the one in the `c_api.h` ([this](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/c/c_api.h)), right?\r\nAnd that gets me back to using the structure including the absl/flatbuffers libraries.\r\n\r\nDo you have an example code for using only the C headers and still running an inference?", "You're right that there's no good end-to-end example using the C API. This is something we're working on, however, the high-level usage and flow should be quite similar to the C++ API.", "Well that's good to hear :) I hope to see them soon.\r\nCurrently I'm having trouble with just using the C/C++ APIs.\r\n\r\nThe main approaches I've been trying so far are:\r\n1. using the TFLite as an external library and load into Android Studio: I used [this](https://www.tensorflow.org/lite/guide/android#build_tensorflow_lite_locally), and [this](https://www.tensorflow.org/lite/guide/build_arm64) and combinations of the two, to get a static (.a) or a shared (.so) library (from either my x86-toolchain or the Docker container), and try to include them in Android Studio using cmake.\r\n2. building the source code from files + headers with Gradle (Android Studio's build system): I used the C source code from lite's directory ([see here](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite)) and tried to build it in Android Studio.\r\n\r\nAny comments / ideas are more than welcome.", "@orangesomethingorange \r\nIs this still an issue, please confirm if we may move this to closed status", "> @orangesomethingorange\r\n> Is this still an issue, please confirm if we may move this to closed status\r\n\r\nHey @Saduf2019, I can't say that I got an answer for this issue.\r\nAlso, I'm still working on investigating this, and I understand from @jdduke that this might be solved in the near future, since work is currently (or very soon will be) in progress.\r\n\r\nI would like to keep the status as open for now, if that's OK with you :)", "I recreated the shared libraries, and compiled with `cmake` normally and now it works OK.\r\n\r\nIn my case the issue was the shared libraries build, which wasn't updated in container versions.\r\nGenerally speaking the Docker Containers simplify the build of shared libraries, but it really depends on the container.\r\nFor example - using the [latest, devel, latest-devel or nightly containers](https://hub.docker.com/r/tensorflow/tensorflow/tags/) made a big difference, and I'm still not sure which one contains what exactly and how configurable each one is.\r\nAlso note the [Docker Container from the Dockerfile](https://raw.githubusercontent.com/tensorflow/tensorflow/master/tensorflow/tools/dockerfiles/tflite-android.Dockerfile).\r\n\r\nOnce I found proper containers for each shared library I could build them with customization (for example [ops](https://www.tensorflow.org/lite/guide/ops_custom) or [custom ops](https://www.tensorflow.org/lite/guide/ops_custom)).\r\n\r\nAfter that the process it's pretty much the same as I described at the beginning of this issue, and it's a great replacement to the use of AARs in the Gradle project.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39148\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39148\">No</a>\n"]}, {"number": 39147, "title": "Possible to get layer from graph?", "body": "I seek to access a layer's attributes from within a model's optimizer; I suppose one way to do so is via the Graph, which is accessible using e.g. `K.get_session()` (Keras/tf.Keras). However, I only find ops and tensors using `.get_operations()` or `._nodes_by_name` - not layer instances themselves. Is it possible to access layers via the default (or other) Graph? [Mirror SO](https://stackoverflow.com/questions/61592020/get-layer-from-graph-tensorflow-keras)\r\n\r\n<hr>\r\n\r\n**Example**: fetch `recurrent_regularizer` of the LSTM layer without accessing `model` (except `model.optimizer`):\r\n\r\n\r\n```python\r\nfrom keras.layers import Input, LSTM\r\nfrom keras.models import Model\r\nfrom keras.regularizers import l2\r\n\r\nipt = Input(shape=(120, 4))\r\nout = LSTM(60, recurrent_regularizer=l2(0), name='lstm_1')(ipt)\r\nmodel = Model(ipt, out)\r\nmodel.compile('adam', loss='mse')\r\n```\r\n```python\r\n>> print(vars(model.layers[1].cell.recurrent_regularizer))\r\n{'l1': array(0., dtype=float32), 'l2': array(1.e-04, dtype=float32)}\r\n```", "comments": ["Found workaround"]}, {"number": 39146, "title": "Loss over a padded and masked sequence", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 19.10\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): v2.1.0-rc2-17-ge5bf8de\r\n- Python version: 3.7\r\n\r\n**Describe the current behavior**\r\nThe data I'm working on is a collection of sequences of different length. I have padded all the sequences to the same length and written an LSTM model that uses masks to ignore the padded part of the data.\r\n\r\nThe loss at each step is given by the sum of the losses at all points in the sequences divided by the total length of the sequences, original + padded part.\r\n\r\n**Describe the expected behavior**\r\nI expected the loss to be given by the sum of the losses at all points in the sequences divided by the total length **of the original sequences**, discarding the padded part.\r\n\r\nIs this the intended behavior? And are the two fundamentally equivalent, from the point of view of the backprop algorithm?\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow.keras import Model\r\nfrom tensorflow.keras.layers import LSTM\r\n\r\n# Config\r\nN = 32\r\nT = 10\r\nn = 2\r\nmask_value = -1.\r\ntf.random.set_seed(1)\r\nnp.random.seed(1)\r\n\r\n# Data creation\r\nX = np.ones((N, T, n)) * mask_value\r\nY = np.ones((N, T, 1)) * mask_value\r\nfor i in range(N):\r\n    l = np.random.randint(1, T)\r\n    value = np.random.random([l, n])\r\n    X[i, :l] = value\r\n    Y[i, :l] = np.array([sum(v) > 0.5 * n for v in value])[:, None]\r\n\r\n\r\nclass MyModel(Model):\r\n    def __init__(self, n, mask_value, *args, **kwargs):\r\n        super().__init__(name='MyModel', *args, **kwargs)\r\n        self.mask_value = mask_value\r\n        self.n = n\r\n        self.LSTM = LSTM(self.n, return_sequences=True, activation='linear')\r\n        return\r\n\r\n    def call(self, inputs, training=None, mask=None):\r\n        mask = tf.cast(tf.reduce_sum(inputs - self.mask_value, axis=-1), tf.bool)\r\n        x = self.LSTM(inputs, mask=mask)\r\n        return x\r\n\r\n\r\nmodel = MyModel(n, mask_value)\r\nmodel.build(input_shape=(N, T, n))\r\nmodel.compile(\r\n    optimizer='adam',\r\n    loss='binary_crossentropy',\r\n    metrics=['accuracy'],\r\n)\r\nmodel.summary()\r\n\r\nmask = 1 - tf.cast(tf.reduce_all(tf.equal(X, mask_value), axis=-1), tf.float32)\r\nloss_unmasked = tf.reduce_mean(tf.keras.losses.binary_crossentropy(Y, model.predict(X)))\r\nloss_masked_1 = tf.reduce_sum(tf.keras.losses.binary_crossentropy(Y, model.predict(X)) * mask) / tf.reduce_sum(mask)\r\nloss_masked_2 = tf.reduce_sum(tf.keras.losses.binary_crossentropy(Y, model.predict(X)) * mask) / (N * T)\r\nprint(f\"model.evaluate(X, Y): {model.evaluate(X, Y)[0]:.2f}\\n\"\r\n      f\"loss_unmasked       : {loss_unmasked:.2f}\\n\"\r\n      f\"loss_masked_1       : {loss_masked_1:.2f}\\n\"\r\n      f\"loss_masked_2       : {loss_masked_2:.2f}\"\r\n      )\r\n```\r\n", "comments": ["Got similar values with [TF v2.1](https://colab.research.google.com/gist/amahendrakar/f82d3f6099c8bd27fbe75e48b32d4c65/39146-2-1.ipynb) and [TF v2.2.0-rc4](https://colab.research.google.com/gist/amahendrakar/ea34587561bf48b61cea45314354f330/39146-2-2.ipynb). Please find the attached gist. Thanks!", "Yes, this is the behavior I see as well: the loss given by the model is equal to `loss_masked_2`. However, I believe it should be equal to `loss_masked_1`. Let me explain why this might be problematic.\r\n\r\nFor example, let's consider two identical data points. With the current implementation their contribution to the loss changes depending on the batch they find themselves in. Let us say that the first one is in a batch which has been padded to length `N` and contributes to the total loss of a quantity `L`; if the second one is padded to length `2N`, its contribution to the loss will be `L / 2`. This seems contradictory with the whole idea of masking.\r\n\r\nAfter delving a bit more into the training loops, I suspect that it doesn't impact the training anyway because the value shown is actually never used. However, it reports incorrect information to the user.", "Was able to reproduce the issue in TF 2.5 and Nightly versions.Please find the gist [here](https://colab.research.google.com/gist/saikumarchalla/f31da23b9d66dac0f32d003e7d9d9b9d/untitled79.ipynb).", "Hi There,\n\n This is a stale issue. As you are using an older version of tensorflow, we are checking to see if you still need help on this issue. Please test the issue with the latest TensorFlow (TF2.7 and tf-nightly). If the issue still persists with the newer versions of TF, please feel free to open it in [keras-team/keras](https://github.com/keras-team/keras/issues) repository by providing details about the issue and a standalone code to reproduce the issue. Thanks! \n\n Please note that Keras development has moved to a separate Keras-team/keras repository to focus entirely on only Keras. Thanks! ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39146\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39146\">No</a>\n"]}, {"number": 39145, "title": "TFLiteConverter", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (or github SHA if from source):\r\n\r\n\r\n**Command used to run the converter or code if you\u2019re using the Python API**\r\nIf possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n```\r\n# Copy and paste here the exact command\r\n```\r\n\r\n**The output from the converter invocation**\r\n\r\n```\r\n# Copy and paste the output here.\r\n```\r\n\r\n**Also, please include a link to the saved model or GraphDef**\r\n\r\n```\r\n# Put link here or attach to the issue.\r\n```\r\n\r\n**Failure details**\r\nIf the conversion is successful, but the generated model is wrong,\r\nstate what is wrong:\r\n- Producing wrong results and/or decrease in accuracy\r\n- Producing correct results, but the model is slower than expected (model generated from old converter)\r\n\r\n\r\n**RNN conversion support**\r\nIf converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.\r\n\r\n**Any other info / logs**\r\n\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": []}, {"number": 39144, "title": "experimental_compile regression in 2.2.rc4", "body": "**System information**\r\n- Have I written custom code: yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Mint 19.3\r\n- TensorFlow installed from: pip\r\n- TensorFlow version 2.2.0-rc4 / v2.2.0-rc3-33-g70087ab4f4\r\n- Python version: 3.6 \r\n\r\nThe following code worked with `experimental_compile=True` in 2.1, but causes an error in 2.2.rc4:\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\n\r\n@tf.function(experimental_compile=True)\r\ndef process_line(line):\r\n    return tf.strings.split(line, \" \")\r\n\r\ntext = tf.data.Dataset.from_tensor_slices([\"1 2\"])\r\ntext = text.map(process_line)\r\n\r\nfor x in text:\r\n    print(x)\r\n\r\n# this one works in neither 2.1 nor 2.2rc4\r\n# process_line(\"1 2\")\r\n```\r\n\r\n**Other info / logs**\r\n```\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Function invoked by the following node is not compilable: {{node PartitionedCall}} = PartitionedCall[Tin=[DT_STRING], Tout=[DT_STRING], _XlaMustCompile=true, _read_only_resource_inputs=[], config=\"\", config_proto=\"\\n\\007\\n\\003GPU\\020\\000\\n\\007\\n\\003CPU\\020\\0012\\002J\\0008\\001\", executor_type=\"\", f=__inference_process_line_84[]](args_0).\r\nUncompilable nodes:\r\nPartitionedCall: could not instantiate call: '__inference_process_line_84'\r\n\tStacktrace:\r\n\t\tNode: PartitionedCall, function: \r\n\r\n\t [[PartitionedCall]] [Op:MakeIterator]\r\n```\r\n", "comments": ["@ngc92 \r\n\r\nLooks like code is incomplete. Request you to share colab link or simple standalone code to reproduce the issue in our environment.It helps us in localizing the issue faster.Thanks!", "I spent some more time looking at my example, and testing in 2.1 and 2.2, and it might be that the code was silently broken in 2.1. I've updated the code above to reflect my new minimal example.\r\n\r\nThe last line that is commented out in my example fails in both 2.1 and 2.2, which indicates that XLA also did not work in 2.1.\r\n\r\nIt seems that in 2.1, when a function with unsupported `experimental_compile` was used in an input pipeline, the error might have been ignored (and the function used without XLA?), but in 2.2 the error bubbles up. If that is an intended change, then my report here does not show a regression.", "I have tried in colab with TF 2.1.0, 2.2-rc4 and was able to reproduce the issue.Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/0db524d427199cd33fe6b193d290dc01/untitled853.ipynb).Thanks!", "Hi, the error message should be improved, but it basically says that the code in `tf.strings.split` is not compilable by XLA. What is the expected behavior here if this is a bug?", "The question is whether there should be a non-XLA fallback. tf 2.1. seems to silently use a non-XLA implementation in this case, whereas tf 2.2 raises the error.", "The contract says that experimental_compile=True should fail explicitly, and not provide a fallback (cf. tensorflow.org/xla)", "so it's a bug in 2.1 that the tf.data pipelines silently fell back to non XLA, i guess.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39144\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39144\">No</a>\n"]}]