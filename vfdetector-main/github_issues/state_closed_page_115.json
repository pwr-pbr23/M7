[{"number": 51565, "title": "setup(python_requires) argument", "body": "**Describe the problem**\r\n\r\n[`setup.py` uses only `setup(classifier)` argument to specify supported Python versions.](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/pip_package/setup.py)\r\n\r\nAccording to [Python Packaging User Guide > Packaging and distributing projects](https://packaging.python.org/guides/distributing-packages-using-setuptools/#classifiers),\r\n> this information is only used for searching & browsing projects on PyPI, not for installing projects. To actually restrict what Python versions a project can be installed on, use the [`python_requires`](https://packaging.python.org/guides/distributing-packages-using-setuptools/#python-requires) argument.\r\n\r\nAdding `python_requires='>=3.7,<3.10'` would help version resolution for installing proper version of tensorflow.", "comments": ["This is not high priority/very relevant as we need to release different wheels for each version of Python we support anyway.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51565\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51565\">No</a>\n"]}, {"number": 51811, "title": "serving doc has error", "body": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\nhttps://www.tensorflow.org/tfx/tutorials/serving/rest_simple\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\nI'm follow upper tutorial and using Google colab in tutorial.\r\nWhen I was run this code that makes error.\r\nHow to fix it?\r\n\r\n```\r\nsaved_model_cli show --dir {export_path} --all\r\n```\r\n\r\n\r\n```\r\nMetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\r\n\r\nsignature_def['__saved_model_init_op']:\r\n  The given SavedModel SignatureDef contains the following input(s):\r\n  The given SavedModel SignatureDef contains the following output(s):\r\n    outputs['__saved_model_init_op'] tensor_info:\r\n        dtype: DT_INVALID\r\n        shape: unknown_rank\r\n        name: NoOp\r\n  Method name is: \r\n\r\nsignature_def['serving_default']:\r\n  The given SavedModel SignatureDef contains the following input(s):\r\n    inputs['Conv1_input'] tensor_info:\r\n        dtype: DT_FLOAT\r\n        shape: (-1, 28, 28, 1)\r\n        name: serving_default_Conv1_input:0\r\n  The given SavedModel SignatureDef contains the following output(s):\r\n    outputs['Dense'] tensor_info:\r\n        dtype: DT_FLOAT\r\n        shape: (-1, 10)\r\n        name: StatefulPartitionedCall:0\r\n  Method name is: tensorflow/serving/predict\r\nWARNING: Logging before flag parsing goes to stderr.\r\nW0819 04:35:50.096211 139702139606912 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling __init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nIf using Keras pass *_constraint arguments to layers.\r\n\r\nDefined Functions:\r\n  Function Name: '__call__'\r\n    Option tensorflow/tensorflow#1\r\n      Callable with:\r\n        Argument tensorflow/tensorflow#1\r\n          inputs: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=u'inputs')\r\n        Argument tensorflow/tensorflow#2\r\n          DType: bool\r\n          Value: True\r\n        Argument tensorflow/tensorflow#3\r\n          DType: NoneType\r\n          Value: None\r\n    Option tensorflow/tensorflow#2\r\n      Callable with:\r\n        Argument tensorflow/tensorflow#1\r\n          Conv1_input: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=u'Conv1_input')\r\n        Argument tensorflow/tensorflow#2\r\n          DType: bool\r\n          Value: True\r\n        Argument tensorflow/tensorflow#3\r\n          DType: NoneType\r\n          Value: None\r\n    Option tensorflow/tensorflow#3\r\n      Callable with:\r\n        Argument tensorflow/tensorflow#1\r\n          inputs: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=u'inputs')\r\n        Argument tensorflow/tensorflow#2\r\n          DType: bool\r\n          Value: False\r\n        Argument tensorflow/tensorflow#3\r\n          DType: NoneType\r\n          Value: None\r\n    Option tensorflow/tensorflow#4\r\n      Callable with:\r\n        Argument tensorflow/tensorflow#1\r\n          Conv1_input: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=u'Conv1_input')\r\n        Argument tensorflow/tensorflow#2\r\n          DType: bool\r\n          Value: False\r\n        Argument tensorflow/tensorflow#3\r\n          DType: NoneType\r\n          Value: None\r\n\r\n  Function Name: '_default_save_signature'\r\nTraceback (most recent call last):\r\n  File \"/usr/local/bin/saved_model_cli\", line 8, in <module>\r\n    sys.exit(main())\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/tools/saved_model_cli.py\", line 990, in main\r\n    args.func(args)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/tools/saved_model_cli.py\", line 691, in show\r\n    _show_all(args.dir)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/tools/saved_model_cli.py\", line 283, in _show_all\r\n    _show_defined_functions(saved_model_dir)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/tools/saved_model_cli.py\", line 186, in _show_defined_functions\r\n    function._list_all_concrete_functions_for_serialization()  # pylint: disable=protected-access\r\nAttributeError: '_WrapperFunction' object has no attribute '_list_all_concrete_functions_for_serialization'\r\n```\r\n\r\n", "comments": ["@hjlee9182 ,\r\nThis issue is more suitable for TensorFlow tfx repo. Please post it on tfx repo from [here](https://github.com/tensorflow/tfx/issues). Thanks!\r\n\r\n\r\n", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "With `TF 2.6.0`, I am able to reproduce the error as reported by @hjlee9182 ,[gist here](https://colab.research.google.com/gist/sanatmpa1/d6062b150ba03aa9f618de5e46d7ad6c/rest_simple.ipynb) and when I tested the same with `TF 2.5.0` it was running fine, [gist](https://colab.research.google.com/gist/sanatmpa1/f7626473cf37291420b742e13f875cba/rest_simple.ipynb) ", "While the documentation is in the Tensorflow Serving repository, the root cause is related to the SavedModel CLI in the Tensorflow repository. Re-assigning to @tilakrayal to triage.", "I don't see the reported issue in Tensorflow 2.7, please find the attached [gist](https://colab.research.google.com/gist/sachinprasadhs/9195eb14688c2f3a05e53d01be05f2fd/rest_simple.ipynb) and confirm. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51811\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51811\">No</a>\n"]}, {"number": 51563, "title": "Karen/r2.6", "body": "update TTP files per legal approval", "comments": ["create by mistake.  Close."]}, {"number": 51560, "title": "Update 20-documentation-issue.md", "body": "Update the broken link", "comments": []}, {"number": 51558, "title": "[XLA] Make replay_computation accept input HLO file with multiple module.", "body": "I needed that today.\r\nIt allow to use replay_computation with hlo tests file.\r\n\r\nThis use the same syntax as hlo_to_llvm_ir use.\r\n\r\n@sanjoy ", "comments": ["I updated this PR and this it is ready to be approved.", "I\u2019d really prefer not to use the \u201c---\u201d trick, could we not use xargs?", "@cheshire\r\n\r\n> I\u2019d really prefer not to use the \u201c---\u201d trick, could we not use xargs?\r\n\r\nThe reason I understood for this request is that the error report are more difficult to understand due to the line numbers being wrong. I also got hit by this, but by using unique hlo module name, it was a little bit better.\r\nIs there other reasons you do not like workflow?\r\n\r\nHaving tons of very small files, even in organized directory, isn't a great alternative to packing many small hlo in the same file.\r\n\r\nWhat about replay_computation printing the line number offset before or after the FileCheck error?\r\nIt could also print the number of HLO passing before the one that error out.\r\nThat will help find where the error come from.\r\n\r\nIf you agree with that, I can implement them easily in this PR.", "I updated this PR with a commit that print the line where the section start.\r\nThis should resolve the hard to understand line number issue you raised."]}, {"number": 51557, "title": "Update setup.py", "body": "Added latest numpy which is compatible with version of all tensorflow's dependencies ", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F51557) for more info**.\n\n<!-- need_sender_cla -->", "> @googlebot I signed it!\r\n\r\n", "#48935"]}, {"number": 51555, "title": "InvalidArgumentError:  indices[15,28] = 22105 is not in [0, 22015)  [[node encoder/embedding/embedding_lookup ", "body": "I am using tf 2.4.1, keras 2.4.3, and python 3.8.10 on CPU. \r\nI have downloaded pretrained GloVe word embeddings to train an Encoder-Decoder Model for abstractive summarization. \r\nI have created two embedding matrices, one to represent the vocabulary of the source input documents and one to represent the summary vocabulary. I am a little unsure if this is the correct practice but the model is able to train on 100 batches until the bug in the title stops training. \r\n\r\n\r\nCurrently, the embedding matrix is of size 22015, 200. The first dimension represents the indices of the word embeddings and the second dimension represents the embedding dimension size for each word. The size of the encoder (source documents) vocabulary is taken directly from the embedding matrix = 22015. The summary vocabulary size is 7932 which is also the size of the first dimension of the summary embedding matrix. I should note that the original vocabulary sizes taken directly from dictionaries are different though come before the implementation of glove. \r\n\r\n\r\nThe Decoder model is expected to output a probability distribution over the summary vocabulary (7932 \"classes\"). It seems that the decoder output head is functioning as intended but the error occurs when the encoder starts to work on its word embeddings\r\n\r\nCODE to SIMULATE issue\r\n`from keras.layers import Embedding`\r\n\r\n```\r\nencoder_vocab_size = 22015\r\nemb_dim = 200\r\n```\r\n\r\n```\r\ninput_dim = encoder_vocab_size \r\noutput_dim = emb_dim\r\n```\r\n- Setting the weights of the Embedding layer to pretrained GloVe matrix (22015x200)\r\n`weights = [embmatrix]`\r\n\r\n- The Encoder uses this embedding layer with exact configuration\r\n`embedding = Embedding(input_dim, output_dim, input_length=200, weights=weights, is_trainable=False)`\r\n\r\n- Training the Encoder-Decoder Model\r\n``for` epoch in range(25):`\r\n\r\n    ``for` batch, (encoder_inp_batch, decoder_input_batch, target_input_batch) in enumerate(generator):`\r\n        - encoder_inp_batch is shape (batch_size, 200)\r\n        - decoder_input_batch is shape (batch_size, 49)\r\n        - target_input_batch is shape (batch_size, 49)\r\n\r\n        with tf.GradientTape() as tape:\r\n            - Code breaks here AFTER successfully training over 100 batches of data\r\n            encoder_output, encoder_hidden_states = encoder(encoder_inp_batch)\r\n\r\n\r\nThe loss used is sparse_categorical_crossentropy as targets are not one-hot encoded. Data is passed to the model in batches of 16. Number of data points used for training ~ 5,000. \r\nStill trying to pinpoint where exactly the embedding index out of bounds error might lie. Is it an issue arising from indices in the encoder embedding matrix or does the index out of bounds occur when feeding sequences of encoder training data where indices might be greater than the allowable range up to 22015\r\n", "comments": ["@EthanIrby8 Thank you for the post!  In order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!", "@sushreebarsa Thanks for the heads up! I added the code you requested. If it's possible, could you add a keras label to the issue as per the embedding layer?", "@EthanIrby8 Thank you for the update! This issue is related to Keras.\r\nPlease post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues), you will get the right help there.\r\nTo know more see;\r\n[https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999](https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999)\r\nThank you!", "@sushreebarsa issue posted on keras-team/keras-repo as of yesterday ", "@EthanIrby8 Thank you for the update! Could you please move this issue to closed status as you have posted this issue in Keras repo ?Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51555\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51555\">No</a>\n"]}, {"number": 51554, "title": "numpy dependency on 1.19.2", "body": "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/pip_package/setup.py#L81\r\n\r\nwhy is there a dependency on 1.19.2 when there are later version of numpy?", "comments": ["See https://github.com/tensorflow/tensorflow/issues/47691", "@ganand1 ,\r\n\r\nAs mentioned in this [link](https://github.com/tensorflow/tensorflow/blob/r2.4/tensorflow/tools/pip_package/setup.py#L84), there is a bound on numpy versions supported by TF2.4 ( ~=1.19.2). Currently numpy version should be >=1.19.2 and < 1.20.\r\n\r\nAlso for future releases please subscribe to #47691\r\n\r\nThanks!", "Closing as duplicate", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51554\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51554\">No</a>\n"]}, {"number": 51553, "title": "replace x86intrin.h to immintrin.h", "body": "MSVC didn't have `x86intrin.h`, it cause build break when use `/arch:AVX2`.", "comments": []}, {"number": 51552, "title": "Tape Gradient ", "body": "How to use Tape gradient in tensorflow/c/eager/gradients in C++ application?\r\n\r\n- Cento 7\r\n- tensorflow 2.6\r\n- Cuda 11.2", "comments": ["Hi!@domGitDev,\r\nThis does not seem to be a bug or feature request, for any further queries you may open this issue in TF discussion [forum ](https://discuss.tensorflow.org/)as there is a larger community there.Thank you!", "Thanks, posted in the forum."]}, {"number": 51551, "title": "esrgan failed on image over 50x50 pixels : error output tensor", "body": null, "comments": ["@budibeta In order to expedite the trouble-shooting process,Could you please fill the issue [template](https://github.com/tensorflow/tensorflow/issues/new/choose).Thanks!\r\n", "> @budibeta In order to expedite the trouble-shooting process,Could you please fill the issue [template](https://github.com/tensorflow/tensorflow/issues/new/choose).Thanks!\r\n\r\ndont picky, if use \"bug issue\" tag, people still dont help my issue", "@budibeta Could you please update the content , it will be helpful for us in order to expedite the trouble-shooting process for the issue reported here.Thank you!\r\n", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 51550, "title": "What architecture do block3 and stack3 from tf.python.keras.applications.resnet correspond to?", "body": "## URL(s) with the issue:\r\n\r\n[https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet](https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet)\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\nThe building blocks provided in `tensorflow.python.keras.applications.resnet` are not well described. I am having a hard time identifying which architecture do block3 and stack3 come from. I posted a related question on StackOverflow hoping someone would know: [https://stackoverflow.com/questions/68815764/what-architecture-do-block3-and-stack3-from-keras-applications-resnet-correspond](https://stackoverflow.com/questions/68815764/what-architecture-do-block3-and-stack3-from-keras-applications-resnet-correspond)\r\n\r\n### Correct links\r\n\r\n[https://github.com/tensorflow/tensorflow/blob/b47b4139710fda407b56e1dc8de84b05779353e6/tensorflow/python/keras/applications/resnet.py#L345-L436](https://github.com/tensorflow/tensorflow/blob/b47b4139710fda407b56e1dc8de84b05779353e6/tensorflow/python/keras/applications/resnet.py#L345-L436)\r\n", "comments": ["@mightestDuck ,\r\n\r\n \r\nWe see that the issue [template](https://github.com/tensorflow/tensorflow/issues/new/choose) has not been filled, could you please do so as it helps us analyse the issue [tf version, steps followed before you ran into this error or stand alone code to reproduce the issue faced] or if possible share a colab gist with the issue reported.Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 51549, "title": "Layer_by_layer Boosting Tree", "body": "<emThe issue related to the performance of the [BoostedTree classifier](https://github.com/tensorflow/estimator/blob/781c0d30c6bf100aa174591dd97cb70fc39d294d/tensorflow_estimator/python/estimator/canned/boosted_trees_test.py#L403) in terms of accuracy.</em>\r\n\r\n**System information**\r\n\r\n- OS Platform and Distribution: Linux Ubuntu 16.04, Windows 10\r\n- TensorFlow installed from (source or binary): pip install TensorFlow\r\n- TensorFlow version (use command below): 2.4.1\r\n- Python version: 3.6\r\n\r\n** Describe the model**\r\nBoostedTree classifier is a model introduced by [N Ponomareva, T Colthurst, G Hendry.2017](https://ieeexplore.ieee.org/abstract/document/8257910).\r\nIt is built over the Xgboost idea and learning is done through building one layer of decision tree regressor over N boosting iteration.\r\n\r\n**Describe the current behavior**\r\nBuild one tree for each boosting epoch\r\n\r\n**Describe the expected behavior**\r\nAs mentioned in its paper, I want to build one tree for all Gradient Boosting Ensemble, and each boosting iteration would be layers of one tree.\r\n\r\n**Standalone code to reproduce the issue**\r\nYou may find an example of the model, [here](https://www.tensorflow.org/tutorials/estimator/boosted_trees_model_understanding)", "comments": ["Hi!@samanemami , \r\nThis does not  seem to be  a bug or feature request, for any further queries you may open this issue in TF discuss [forum ](https://discuss.tensorflow.org/)as there is a larger community there.Thank you!", "Thank you @mohantym \r\nBut my question is about the library performance, as I could not find any related method in the BoostedTree library in the TensorFlow repository regarding the layer_by_layer model.\r\n\r\nAlso, there is no code line regarding the matrix type of the loss function (Diagonal or full hessian)", "Hi @Saduf2019  , Could you please look into this issue?", "Hi @Saduf2019 \r\n**More detail about the method I am looking for in the BoostedTree library**\r\n\r\n- I am looking for the LAYER-BY-LAYER BOOSTING Tree which has explained in SECTION V of the [paper](https://ieeexplore.ieee.org/abstract/document/8257910).\r\n\r\n- But when I reviewed the [library](https://github.com/tensorflow/estimator/blob/master/tensorflow_estimator/python/estimator/canned/boosted_trees.py#L1933-L2102), I could not find any related method, and it works just like other Gradient boosting models.\r\n", "@Saduf2019 \r\nThis [repository](https://git.kot.tools/nk2/syntaxnet_rus/-/blob/caae66a144f1237eb6b5c19fa00c317ca3bed09c/tensorflow/tensorflow/contrib/boosted_trees/examples/mnist.py#L93) is an old lib from tf.BoosteTree, which remains.\r\nThis is the exact code which the [paper](https://ieeexplore.ieee.org/abstract/document/8257910) used, I am looking for the update of this code in your GitHub repository which includes all the paper methods."]}, {"number": 51546, "title": "metric_learning\u7684\u635f\u5931\u51fd\u6570\u5982\u4f55\u5e94\u7528\u5728\u68c0\u7d22\u4e2d\uff0c\u76ee\u524d\u5b9e\u73b0\u4e2d\u90fd\u5b58\u5728\u4f20labels\u7ed9\u5230\u5ea6\u91cf\u635f\u5931\u51fd\u6570", "body": "https://github.com/tensorflow/tensorflow/blob/r1.10/tensorflow/contrib/losses/python/metric_learning/metric_loss_ops_test.py\r\n", "comments": ["Hi!@frostjsy!We see that the issue template has not been filled, could you please do so as it helps us analyse the issue [tf version, steps followed before you ran into this error or stand alone code/colab gist to reproduce the issue faced].Thanks", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 51545, "title": "TFlite GPU Delegate Use input and output ssbo at the same time,the result is error.", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): android ndk 21c\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (or github SHA if from source): 1.15\r\n- Device: qcom snapdragon 855\r\n\r\nMy code step:\r\nimread -> texture -> ssbo1 ->tflite ->ssbo2\r\nI test ssbo1,the input ssbo1 is ok.\r\n```\r\n glActiveTexture(GL_TEXTURE0);\r\n  glBindTexture(GL_TEXTURE_2D, uInput);\r\n  glTexImage2D(GL_TEXTURE_2D, 0, GL_RGB, 256, 256, 0, GL_RGB, GL_FLOAT, data);\r\n\r\n  glBindBufferBase(GL_SHADER_STORAGE_BUFFER, 0, input_buffer);\r\n  glUniform1i(2, 256);\r\n  glUniform1i(3, 256);\r\n  glDispatchCompute(32, 32, 1);\r\n  glMemoryBarrier(GL_SHADER_STORAGE_BARRIER_BIT);\r\n  auto outData = glMapBufferRange(GL_SHADER_STORAGE_BUFFER, 0, 256*256*12, GL_MAP_READ_BIT);\r\n```\r\n\r\n\r\nssbo2 return error.\r\n`coef 0,1,2,3:0.59072,0.842416,0.85824,0.454508`\r\n\r\nWhen I don't use input ssbo:\r\nimread ->tflite ->ssbo\r\nthe result is OK.\r\n`coef 0,1,2,3:0.198929,0.524968,0.660745,0.634005`\r\n\r\nCan I bind input and output ssbo at the same time?\r\nHere is my c++ code.\r\n```\r\n  TfLiteDelegate* gpuDelegate = TfLiteGpuDelegateCreate(&options);\r\n  std::cout<<\"set output buffer handle\"<<std::endl;\r\n  interpreter->SetAllowBufferHandleOutput(true);\r\n  // The buffer must be bound before the delegate is installed.\r\n  std::cout<<\"set tensor bind\"<<std::endl;\r\n  //just like bindBufferBase?\r\n  TfLiteGpuDelegateBindBufferToTensor(gpuDelegate,input_buffer,interpreter->inputs()[0]);\r\n  TfLiteGpuDelegateBindBufferToTensor(gpuDelegate,output_buffer,interpreter->outputs()[0]);\r\n  std::cout<<\"modify delegate\"<<std::endl;\r\n  if(interpreter->ModifyGraphWithDelegate(gpuDelegate) != kTfLiteOk){\r\n    return;\r\n  }\r\n\r\nglUniform1i(2, 256);\r\nglUniform1i(3, 256);\r\n//texture to ssbo \r\nglBindBufferBase(GL_SHADER_STORAGE_BUFFER, 0, input_buffer);\r\nglDispatchCompute(32, 32, 1);\r\n\r\nglMemoryBarrier(GL_SHADER_STORAGE_BARRIER_BIT);\r\n // Run inference; the null input argument indicates use of the bound buffer for input.\r\n if (interpreter->Invoke() != kTfLiteOk) return;\r\n glMemoryBarrier(GL_SHADER_STORAGE_BARRIER_BIT);\r\n```\r\nIt seems like the input_buffer ssbo data is not put into the tflite model,how can I use it?\r\nThanks!\r\n", "comments": ["@yangchengtest We see that you are using older version of tensorflow 1.15 which is not actively supported, We recommend that you upgrade to 2.6.0 the latest version of TF and let us know if the issue still persists in newer versions.Thanks!", "> @yangchengtest We see that you are using older version of tensorflow 1.15 which is not actively supported, We recommend that you upgrade to 2.6.0 the latest version of TF and let us know if the issue still persists in newer versions.Thanks!\r\n\r\nI don't have tf 2.6 models.In my project, the original model is trained by pytorch, use my own tools change to tensorflow model.\r\nMy Input is not huge, I think I will use cpu input first to solve the problem.", "TF 1.X out of the support window. You may try posting this question on [TensorFlow Forum](https://discuss.tensorflow.org/) for community support. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51545\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51545\">No</a>\n"]}, {"number": 51543, "title": "ios demo app version error", "body": "hi, I want to build an object detection ios demo app using tflite model.\r\nbut your code support ios14.4, my ios is 14.6.\r\nApple doesn't assign ios to downgrade 14.6 to14.4.\r\nso did you upgrade for ios 14.6?? \r\n\r\nthanks,", "comments": ["@hyuDev ,\r\n\r\nIn order to expedite the trouble-shooting process, could you please provide the following information\r\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\nTensorFlow installed from (source or binary):\r\nTensorFlow version:\r\nPython version:\r\nInstalled using virtualenv? pip? conda?:\r\nBazel version (if compiling from source):\r\nGCC/Compiler version (if compiling from source):\r\nCUDA/cuDNN version:\r\nGPU model and memory:\r\n \r\nand the exact sequence of commands / steps that you executed before running into the problem\r\n", "OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS\r\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: the IOS device with ios14.6\r\nTensorFlow installed from (source or binary): maybe binary(I install TF with pip3)\r\nTensorFlow version: 1.15.0\r\nPython version:3.6.5\r\nInstalled using virtualenv? pip? conda?: pip3 \r\nBazel version (if compiling from source):\r\nGCC/Compiler version (if compiling from source):\r\nCUDA/cuDNN version: NO CUDA, only CPU\r\nGPU model and memory: NO GPU, only CPU\r\n\r\n\r\nthe project error is\"this device' os is not supported, we support ios 14.4\" ", "@hyuDev ,\r\nWe see that you are using tf version 1.15, 1.x is not actively supported, please update to stable version tf v2.5, v2.6 and let us know if you are facing same issue.Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51543\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51543\">No</a>\n"]}, {"number": 51541, "title": "training accuracy different from history object", "body": "Hi , I am dealing with a problem on the accuracy history.\r\nAs you can see, during training, we have:\r\n\r\n```\r\nEpoch 1/10\r\n597/597 [==============================] - 4s 3ms/step - loss: 0.6822 - accuracy: 0.7007 - val_loss: 0.6607 - val_accuracy: 0.9228\r\nEpoch 2/10\r\n597/597 [==============================] - 1s 2ms/step - loss: 0.6675 - accuracy: 0.7838 - val_loss: 0.6463 - val_accuracy: 0.9228\r\nEpoch 3/10\r\n597/597 [==============================] - 1s 2ms/step - loss: 0.6537 - accuracy: 0.8284 - val_loss: 0.6329 - val_accuracy: 0.9228\r\nEpoch 4/10\r\n597/597 [==============================] - 2s 3ms/step - loss: 0.6408 - accuracy: 0.8598 - val_loss: 0.6204 - val_accuracy: 0.9228\r\nEpoch 5/10\r\n597/597 [==============================] - 1s 2ms/step - loss: 0.6287 - accuracy: 0.8876 - val_loss: 0.6087 - val_accuracy: 0.9228\r\nEpoch 6/10\r\n597/597 [==============================] - 1s 2ms/step - loss: 0.6174 - accuracy: 0.9024 - val_loss: 0.5978 - val_accuracy: 0.9228\r\nEpoch 7/10\r\n597/597 [==============================] - 1s 2ms/step - loss: 0.6068 - accuracy: 0.9103 - val_loss: 0.5875 - val_accuracy: 0.9228\r\nEpoch 8/10\r\n597/597 [==============================] - 1s 2ms/step - loss: 0.5968 - accuracy: 0.9146 - val_loss: 0.5779 - val_accuracy: 0.9228\r\nEpoch 9/10\r\n597/597 [==============================] - 1s 2ms/step - loss: 0.5874 - accuracy: 0.9146 - val_loss: 0.5688 - val_accuracy: 0.9228\r\nEpoch 10/10\r\n597/597 [==============================] - 1s 2ms/step - loss: 0.5785 - accuracy: 0.9146 - val_loss: 0.5603 - val_accuracy: 0.9228\r\n```\r\n\r\nSo, accuracy reaches 0.9146.\r\n\r\nBut, If you see the accuracy values in the history:\r\n\r\n```\r\nhistory.history['accuracy']\r\n\r\n[0.7472780346870422,\r\n 0.7945979833602905,\r\n 0.8073701858520508,\r\n 0.8146985173225403,\r\n 0.82097989320755,\r\n 0.8243299722671509,\r\n 0.8255862593650818,\r\n 0.8262144327163696,\r\n 0.8262144327163696,\r\n 0.8262144327163696]\r\n```\r\n\r\n\r\nare different!\r\n\r\nCode:\r\n\r\n```\r\nimport pandas as pd\r\nimport numpy as np\r\nimport tensorflow as tf\r\nimport matplotlib.pyplot as plt\r\nfrom tensorflow.keras.layers import Dense, LSTM, \\\r\n    Bidirectional, RepeatVector\r\nfrom tensorflow.keras import Sequential\r\n\r\nX_train = np.load('./X_train.npy')\r\nX_val = np.load('./X_val.npy')\r\ny_train = np.load('./y_train.npy')\r\ny_val = np.load('./y_val.npy')\r\n\r\n\r\nmodel = Sequential()\r\nmodel.add(Bidirectional(LSTM(2,\r\n                        return_sequences=False,\r\n                        activation='tanh',\r\n                    input_shape=(12,\r\n                                 10))))\r\nmodel.add(RepeatVector(8))\r\n# Decoder\r\nmodel.add((LSTM(4,\r\n                activation='tanh',\r\n                return_sequences=True)))\r\n\r\nmodel.add((Dense(1, activation='sigmoid')))\r\n                    \r\nmodel.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.0001), \r\n              loss='binary_crossentropy',\r\n              metrics=['accuracy'])\r\n\r\nepochs = 10\r\nbatch_size = 1\r\n\r\nhistory = model.fit(\r\n    X_train,\r\n    y_train, \r\n    validation_data = (X_val, y_val),\r\n    steps_per_epoch=int(len(X_train) / batch_size),\r\n    validation_steps=int(len(X_val) / batch_size),\r\n    epochs=epochs,\r\n    batch_size=batch_size,\r\n    shuffle=False)\r\n\r\n\r\nfig, axes = plt.subplots(figsize=(20, 12))\r\naxes.plot(history.epoch, history.history['accuracy'], label = 'Train acc')\r\naxes.plot(history.epoch, history.history['val_accuracy'], label = 'Val acc')\r\naxes.legend()\r\n```\r\n\r\nYou can download data [here](https://easyupload.io/m/5iv09z)\r\n\r\n\r\n\r\n<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\nYou can see it at the end\r\n\r\n**Describe the current behavior**\r\n\r\n Different training accuracy results between history object and history when printing on screen\r\n\r\n**Describe the expected behavior**\r\n We should have the same results!\r\n\r\n**Standalone code to reproduce the issue**\r\nAt the beginning\r\n\r\n\r\n\r\n                  **System Info**\r\n---------------------------------------------------------------------------------------------------------------------------------------------------------------------------\r\n\r\n== check python ===================================================\r\npython version: 3.8.10\r\npython branch: \r\npython build version: ('default', 'Jun  2 2021 10:49:15')\r\npython compiler version: GCC 9.4.0\r\npython implementation: CPython\r\n\r\n\r\n== check os platform ===============================================\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\nc++ (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0\r\nCopyright (C) 2019 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n\r\n== check pips ===================================================\r\nprotobuf                3.6.1               \r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH is unset\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\nWed Aug 18 09:48:39 2021       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 460.91.03    Driver Version: 460.91.03    CUDA Version: 11.2     |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|                               |                      |               MIG M. |\r\n|===============================+======================+======================|\r\n|   0  GeForce GTX 1650    On   | 00000000:01:00.0  On |                  N/A |\r\n| 24%   37C    P8    10W /  90W |   1096MiB /  3907MiB |      9%      Default |\r\n|                               |                      |                  N/A |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                                  |\r\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n|        ID   ID                                                   Usage      |\r\n|=============================================================================|\r\n|    0   N/A  N/A      1085      G   /usr/lib/xorg/Xorg                275MiB |\r\n|    0   N/A  N/A      1727      G   cinnamon                           74MiB |\r\n|    0   N/A  N/A      3228      G   ...AAAAAAAAA= --shared-files       30MiB |\r\n|    0   N/A  N/A      3715      G   /usr/lib/firefox/firefox          125MiB |\r\n|    0   N/A  N/A      3834      G   /usr/lib/firefox/firefox            1MiB |\r\n|    0   N/A  N/A      4004      G   /usr/lib/firefox/firefox            1MiB |\r\n|    0   N/A  N/A      4518      G   ...onda3/envs/dpl/bin/python        1MiB |\r\n|    0   N/A  N/A      4593      C   ...onda3/envs/dpl/bin/python      577MiB |\r\n+-----------------------------------------------------------------------------+\r\n\r\n== cuda libs  ===================================================\r\n\r\n== tensorflow installed from info ==================\r\n\r\n== python version  ==============================================\r\n(major, minor, micro, releaselevel, serial)\r\n(3, 8, 10, 'final', 0)\r\n\r\n== bazel version  ===============================================\r\n\r\n== check python ===================================================\r\npython version: 3.8.8\r\npython branch: \r\npython build version: ('default', 'Feb 24 2021 21:46:12')\r\npython compiler version: GCC 7.3.0\r\npython implementation: CPython\r\n\r\n\r\n== check os platform ===============================================\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\nc++ (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0\r\nCopyright (C) 2019 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n\r\n== check pips ===================================================\r\nneptune-tensorflow-keras          0.9.1\r\nnumpy                             1.19.2\r\nnumpydoc                          1.1.0\r\nprotobuf                          3.14.0\r\ntensorflow                        2.4.1\r\ntensorflow-datasets               1.2.0\r\ntensorflow-estimator              2.4.0\r\ntensorflow-metadata               0.14.0\r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\ntf.version.VERSION = 2.4.1\r\ntf.version.GIT_VERSION = unknown\r\ntf.version.COMPILER_VERSION = 5.4.0\r\n      8883:\tfind library=libpthread.so.0 [0]; searching\r\n\r\n== nvidia-smi ===================================================\r\nWed Aug 18 09:49:20 2021       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 460.91.03    Driver Version: 460.91.03    CUDA Version: 11.2     |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|                               |                      |               MIG M. |\r\n|===============================+======================+======================|\r\n|   0  GeForce GTX 1650    On   | 00000000:01:00.0  On |                  N/A |\r\n| 24%   36C    P8    10W /  90W |   1107MiB /  3907MiB |      6%      Default |\r\n|                               |                      |                  N/A |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                                  |\r\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n|        ID   ID                                                   Usage      |\r\n|=============================================================================|\r\n|    0   N/A  N/A      1085      G   /usr/lib/xorg/Xorg                284MiB |\r\n|    0   N/A  N/A      1727      G   cinnamon                           77MiB |\r\n|    0   N/A  N/A      3228      G   ...AAAAAAAAA= --shared-files       30MiB |\r\n|    0   N/A  N/A      3715      G   /usr/lib/firefox/firefox          125MiB |\r\n|    0   N/A  N/A      3834      G   /usr/lib/firefox/firefox            1MiB |\r\n|    0   N/A  N/A      4004      G   /usr/lib/firefox/firefox            1MiB |\r\n|    0   N/A  N/A      4518      G   ...onda3/envs/dpl/bin/python        1MiB |\r\n|    0   N/A  N/A      4593      C   ...onda3/envs/dpl/bin/python      577MiB |\r\n+-----------------------------------------------------------------------------+\r\n\r\n== cuda libs  ===================================================\r\n\r\n== tensorflow installed from info ==================\r\nName: tensorflow\r\nVersion: 2.4.1\r\nSummary: TensorFlow is an open source machine learning framework for everyone.\r\nHome-page: https://www.tensorflow.org/\r\nAuthor-email: packages@tensorflow.org\r\nLicense: Apache 2.0\r\nLocation: /home/ggousios/miniconda3/envs/dpl/lib/python3.8/site-packages\r\nRequired-by: neptune-tensorflow-keras, neptune-tensorboard\r\n\r\n== python version  ==============================================\r\n(major, minor, micro, releaselevel, serial)\r\n(3, 8, 8, 'final', 0)\r\n\r\n== bazel version  ===============================================", "comments": ["@ggous In order to expedite the trouble-shooting process,Can you please fill the issue [template](https://github.com/tensorflow/tensorflow/issues/new/choose).Thanks!", "I have updated. I am not sure if this is exactly what you want.\r\nI used the template at the end of comment.", "Just update to tensorflow 2.6......Don't see the same error over there", "@ggous It looks like you are using an older Version of Tensorflow (2.4.1). Could you please execute your code using Latest stable Version of TF (2.6.0) and let us know if the issue still persists? Please refer to the [link](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/SGD) & let us know if it helps?Thanks!", "Yes! It works fine with tf 2.6.0 ! \r\nThanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51541\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51541\">No</a>\n"]}, {"number": 51540, "title": "fix: removed extra blank link at end of last section", "body": null, "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F51540) for more info**.\n\n<!-- need_sender_cla -->", "No changes in files changed. Hence closing this PR. Thanks!"]}, {"number": 51539, "title": "Cannot convert models to tensorflowjs from tf hub by url", "body": "I am using tensorflowjs_converter to convert a tflite model to tensorflowjs model.\r\nThe repository can be download with web browsers but failed when using tensorflowjs_converter.\r\nI just redo the ```pip install tensorflowjs``` to make sure that I am in the latest version.\r\n\r\n```\r\ntensorflowjs_converter --input_format=tf_hub 'https://tfhub.dev/sayakpaul/lite-model/arbitrary-image-stylization-inceptionv3/dr/predict/1' ./web_model\r\n```\r\n\r\nIt outputs an Http 404 but my connection is fine. When I run the example code it works fine and I downloaded it.\r\n```\r\ntensorflowjs_converter --input_format=tf_hub 'https://tfhub.dev/google/imagenet/mobilenet_v1_100_224/classification/1' ./web_model  \r\n```\r\n\r\nIf you can tell me the reason or you can successfully convert tflite model from the following URLs, I will appreciate it a lot. Thank you so much. \r\n\r\nhttps://tfhub.dev/sayakpaul/lite-model/arbitrary-image-stylization-inceptionv3/dr/predict/1\r\n\r\nhttps://tfhub.dev/sayakpaul/lite-model/cartoongan/dr/1\r\n", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51539\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51539\">No</a>\n"]}, {"number": 51538, "title": "Add dynamic variable failing test without guards", "body": "Add an expected failing test for https://github.com/tensorflow/tensorflow/pull/49310#issuecomment-899764850\r\n\r\n/cc \r\n@mdanatg \r\n@mihaimaruseac (as another bug/failing test case) ", "comments": ["@mdanatg Do you want or do you have any other expected failing test for https://github.com/tensorflow/tensorflow/issues/27120 ?\r\nI would like to find a new Github label for issues covered by expected failing tests"]}, {"number": 51537, "title": "Fix minor typos", "body": null, "comments": []}, {"number": 51535, "title": "Internal error: Tried to take gradients (or similar) of a variable without handle data ", "body": "I am finetuning BERT for a binary sentiment analysis class using Tensorflow. I want to use a custom training loop to implement a custom loss function. However, when I try to train the model I get the following error: ValueError: Internal error: Tried to take gradients (or similar) of a variable without handle data: Tensor(\"transformer_encoder/StatefulPartitionedCall:1019\", shape=(), dtype=resource).\r\n\r\nTo debug, I tried simplifying my training loop to just compute standard binary cross entropy, which should be equivalent to if I called model.fit() with binary cross entropy as the loss function (which works completely fine). However, I get the same error as above when running this simplified training loop and I am not sure what's causing it. Note: I am using tensorflow 2.3.0.\r\n\r\nHere is the model:\r\n```\r\ndef create_model():\r\n  max_seq_length = 512\r\n  input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\r\n                                        name=\"input_word_ids\")\r\n  input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\r\n                                     name=\"input_mask\")\r\n  input_type_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\r\n                                      name=\"input_type_ids\")\r\n  \r\n  bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2\", trainable=True)\r\n  pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, input_type_ids])\r\n  drop = tf.keras.layers.Dropout(0.3)(pooled_output)\r\n  output = tf.keras.layers.Dense(1, activation='sigmoid', name=\"output\")(drop)\r\n\r\n  model = tf.keras.Model(\r\n      inputs={\r\n          'input_word_ids': input_word_ids,\r\n          'input_mask': input_mask,\r\n          'input_type_ids': input_type_ids\r\n      },\r\n      outputs= output \r\n  )\r\n\r\n  return model\r\n```\r\nHere is the training loop function. The issue seems to come up when running ypred = model(train_x) inside tf.GradientTape():\r\n```\r\ndef train_step(train_batch):\r\n  train_x, train_y = train_batch\r\n  with tf.GradientTape() as tape:\r\n    ypred = model(train_x, training=True)\r\n    loss = tf.reduce_mean(tf.keras.losses.binary_crossentropy(train_y, ypred))\r\n  grads = tape.gradient(loss, model.trainable_weights)\r\n  optimizer.apply_gradients(zip(grads, model.trainable_weights))\r\n  return loss\r\n```\r\nAgain, this seems to only happen with tf.GradientTape(), since model.fit() does not result in any issues.\r\n```\r\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5),\r\n          loss=tf.keras.losses.BinaryCrossentropy(),\r\n          metrics=[tf.keras.metrics.BinaryAccuracy()])\r\n\r\nmodel.fit(train_data,\r\n          validation_data=valid_data,\r\n          epochs=epochs,\r\n          verbose=1)\r\n```", "comments": ["@preethiseshadri518 Please post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues)\r\nTo know more see;\r\n[https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999](https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999)\r\nThank you!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51535\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51535\">No</a>\n"]}, {"number": 51534, "title": " tf.GradientTape.gradients() does not support graph control flow operations", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1.  It must be a bug, a feature request, or a significant problem with the\r\n    documentation (for small docs fixes please send a PR instead).\r\n2.  The form below must be filled out.\r\n3.  It shouldn't be a TensorBoard issue. Those go\r\n    [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n\r\n-   **Have I written custom code (as opposed to using a stock example script\r\n    provided in TensorFlow)**:\r\n-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue\r\n    happens on a mobile device**:\r\n-   **TensorFlow installed from (source or binary)**:\r\n-   **TensorFlow version (use command below)**:\r\n-   **Python version**:\r\n-   **Bazel version (if compiling from source)**:\r\n-   **GCC/Compiler version (if compiling from source)**:\r\n-   **CUDA/cuDNN version**:\r\n-   **GPU model and memory**:\r\n-   **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with:\r\n\r\n```bash\r\npython -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"\r\n```\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["@259mit ,\r\n\r\nWe see that the issue [template](https://github.com/tensorflow/tensorflow/issues/new/choose) has not been filled, could you please do so as it helps us analyse the issue [tf version, steps followed before you ran into this error or stand alone code to reproduce the issue faced] or if possible share a colab gist with the issue reported.", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 51533, "title": "README-TA.md", "body": "I have translated it to Tamil.", "comments": []}, {"number": 51529, "title": " TensorRT 6.0 is linking to TensorRT 8.0.1.", "body": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue: https://www.tensorflow.org/install/gpu#software_requirements\r\n\r\n\r\nPlease provide a link to the documentation entry, for example: https://www.tensorflow.org/install/gpu#software_requirements\r\n\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nFor example, why should someone use this method? How is it useful?\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n\r\n### Usage example\r\n\r\nIs there a usage example?\r\n\r\nSee the API guide: https://www.tensorflow.org/community/contribute/docs_ref\r\non how to write testable usage examples.\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs,\r\ndocs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n", "comments": ["fixed with https://github.com/tensorflow/docs/pull/1933\r\nthanks!"]}, {"number": 51528, "title": "`tf.GradientTape.batch_jacobian` fails when slicing tensor with `int64` index", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (use command below): 2.5.0\r\n- Python version: 3.7.9\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: 11.1.0\r\n- GPU model and memory: NVIDIA GeForce RTX 2080 Ti\r\n\r\n**Describe the current behavior**\r\nIf the target tensor of `batch_jacobian` is repeated and then sliced using an `int64` index, `batch_jacobian` fails due to concatenating shape vectors of different types. This can happen when `tf.RaggedTensor` is involved in calculation because `tf.RaggedTensor.row_lengths` returns an `int64` tensor.\r\n\r\nThe cause seems to be that `ops\\parallel_for\\pfor.py:2474` concatenates the batch size and the operation shape without checking the types. The batch size is retrieved at `eager\\backprop.py:1293` as an `int32` value, so when the operation involves `int64` indices, it results in an error.\r\n\r\n**Describe the expected behavior**\r\nIt should succeed whatever type is used to slice a tensor.\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no): No\r\n- Briefly describe your candidate solution(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\n```python\r\nimport tensorflow as tf\r\n\r\nx = tf.RaggedTensor.from_row_lengths([[1.0], [2.0], [3.0]], [1, 2])\r\nlength = x.row_lengths();\r\n# length = tf.cast(length, tf.int32)\r\nprint('Type of length is', length.dtype)\r\nx = x.to_tensor()\r\nwith tf.GradientTape() as tape:\r\n    tape.watch(x)\r\n    y = tf.repeat(x, [2], axis=1)\r\n    y = y[:, :tf.math.reduce_max(length), :]\r\ng = tape.batch_jacobian(y, x)\r\nprint('g =', g)\r\n```\r\nRunning the code results in `TypeError: Tensors in list passed to 'values' of 'ConcatV2' Op have types [int32, int64] that don't all match.`\r\nIf I uncomment line 5 it runs correctly.\r\nIf I comment out the `tf.repeat` line it also runs correctly.", "comments": ["@Qrox Could you please refer to the [link](https://www.tensorflow.org/api_docs/python/tf/RaggedTensor?version=nightly), [link1 ](https://www.tensorflow.org/api_docs/python/tf/GradientTape)and let us know if it helps? Please have a look on a similar [issue](https://stackoverflow.com/questions/59193734/typeerror-tensors-in-list-passed-to-values-of-concatv2-op-have-types-bool) . Thanks!", "I've read the first two links multiple times before, so I guess it didn't help. They also don't mention anything about slicing a tensor with different integer types, AFAIK. The third issue has a similar error but it comes from keras and the solution there is not applicable here.\r\n\r\nIn any case, I've already worked it around by casting the result from `row_lengths` to int32. It is still weird that if I comment out the `tf.repeat` line, it doesn't throw an error. If slicing with int64 type is supported for `batch_jacobian`, which I guess it is because it works if `tf.repeat` is not involved and it also works when training a model, it should be supported under any circumstances, thus I report it as a bug.", "@Saduf2019 Was able to replicate the issue on colab using TF [v2.5](https://colab.research.google.com/gist/sushreebarsa/4135b89afc074b2ddeea82d364363b75/untitled392.ipynb#scrollTo=L7huCR5Q5MS-), [2.6.0](https://colab.research.google.com/gist/sushreebarsa/b93a94ebe44d330b226a5b57f4f2b9be/untitled393.ipynb) ,please find the attached gists .Thank you!", "@Qrox \r\nPlease refer to [this issue](https://stackoverflow.com/questions/59193734/typeerror-tensors-in-list-passed-to-values-of-concatv2-op-have-types-bool) and let us know.", "@sushreebarsa already refered me to that issue, and the solution there of adding `mask_zero=True` is not applicable here.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51528\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51528\">No</a>\n"]}, {"number": 51525, "title": "make_early_stopping_hook will always return _MultiWorkerEarlyStoppingHook, no matter what strategy is used", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below): v2.2 ~ v2.6\r\n- Python version: 3.8\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n**Describe the current behavior**\r\n\r\nmake_early_stopping_hook will always return _MultiWorkerEarlyStoppingHook, no matter what strategy is used.( since TF2.2)\r\n\r\nThere is a bug in this line of code(early_stopping.py#L86), because the second condition is an array with two elements, which must be True, which means that this IF judgment is always True, so it will always return _MultiWorkerEarlyStoppingHook\r\n``` python\r\ntrain_distribute = estimator.config.train_distribute\r\nmwms = ['CollectiveAllReduceStrategy', 'MultiWorkerMirroredStrategy']\r\nif train_distribute and (train_distribute.__class__.__name__.startswith(\r\n    strategy) for strategy in mwms): # <--- bug here. [False, False] will be considered TRUE.\r\n  if run_every_secs:\r\n    raise ValueError('run_every_secs should not be set when using '\r\n                     'MultiWorkerMirroredStrategy.')\r\n  return _MultiWorkerEarlyStoppingHook(should_stop_fn, run_every_steps)\r\n\r\nif estimator.config.is_chief:\r\n  return _StopOnPredicateHook(should_stop_fn, run_every_secs, run_every_steps)\r\nelse:\r\n  return _CheckForStoppingHook()\r\n```\r\n\r\nhttps://github.com/tensorflow/estimator/blob/r2.6/tensorflow_estimator/python/estimator/early_stopping.py#L86\r\n\r\n**Describe the expected behavior**\r\n\r\nmake_early_stopping_hook should return the correct hook according to the strategy", "comments": ["In order to expedite the trouble-shooting process, please provide a  sample code snippet to reproduce the issue reported here. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51525\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51525\">No</a>\n"]}, {"number": 51523, "title": "How to fuse tensors of two different dimensions?", "body": "env\uff1atf2.2\r\n\r\nI have two sets of tensors. I want them to merge together as a new input. Which method should I use?\r\n\r\ntensor 1\uff1afrom bert-encoder-hidden: (batch_size, max_len, 768)\r\ntensor 2:   from tensor 1 through tf.Gather(tensor1, position, batch_dim=1): (batch_size, 768)\r\n\r\nTensor 2 is the position tensor extracted from tensor 1 through TF. Gather() method. Now I want to integrate tensor 2 into tensor 1. What should I do?", "comments": ["@1148330040,\r\n\r\nCan you explain your question clearly with a sample data? If you're looking to update the values in tensor based on indices, you can checkout this function `scatter_nd_update`, [link](https://www.tensorflow.org/api_docs/python/tf/tensor_scatter_nd_update). Thanks!", "Sorry, this is an **information extraction** task. **Tensor 1** is the encoder coded output **hidden of Bert** model. I first obtain the **subject** prediction output from **tensor 1** through CRF, and then extract the corresponding tensor 2 (TF. Gather) from **tensor 1** through the obtained **subject location information.** Then I want to integrate **tensor 2** into **tensor 1** as the input of **prediction object**", "The key is fusion, not renewal\uff0cIt is equivalent to an alternative weighting, but here tensor2 is weighted to tensor1", "@1148330040 \r\nPLease refer to these similar links : [link](https://stackoverflow.com/questions/49294326/expanding-a-tensor-by-another-one-with-different-dimensions-in-tensorflow), [link1](https://developpaper.com/question/how-do-tensors-of-different-dimensions-of-tensorflow-merge/),[link2](https://jovian.ai/aiwithsreekanthrshekar/merging-tensors-5-functions-you-should-be-aware-of)\r\n\r\nYou may open an issue in tf discussion forum as its a bigger community to support, kindly move this to closed status as its not a bug or performance issue.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51523\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51523\">No</a>\n", "1"]}, {"number": 51522, "title": "resnet50.onnx --> tflite Convert Error", "body": "### 1. System information\r\npip3 install tensorflow-gpu==2.4.0\r\npip3 install tensorflow-addons==0.13.0\r\nonnx == 1.7.0\r\n\r\nonnx model link (https://github.com/onnx/models/blob/master/vision/classification/resnet/model/resnet50-v1-7.onnx)\r\n\r\nOur model uses backbone as Resnet-50.\r\nThe error occurred in our model, so even if we downloaded the official onnx model and converted it, it shows the same result.\r\nIn 2.2.0 and 2.3.0, the conversion is good.\r\nAnd I have to use version 2.4.0.\r\n\r\nIf converter.allow_custom_ops is True, it is converted, but eventually problems occur at runtime.\r\n\r\n### 2. Code\r\n\r\nProvide code to help us reproduce your issues using one of the following options:\r\n# onnx --> pb\r\nonnx_model = onnx.load(\"./resnet50-v1-7.onnx\")\r\ntf_model_path = \"./saved_model\"\r\ntf_rep = prepare(onnx_model)\r\ntf_rep.export_graph(tf_model_path)\r\n\r\n# pb --> tflite\r\nconverter = tf.lite.TFLiteConverter.from_saved_model(tf_model_path)\r\ntflite_model = converter.convert()\r\ntflite_model_path = \"./onnx_backbone/tf_2.4.0/tflite/backbone_v9_default.tflite\"\r\nwith open(tflite_model_path, 'wb') as f:\r\n    f.write(tflite_model)\r\n\r\n\r\n```\r\n(You can paste links or attach files by dragging & dropping them below)\r\n- Provide links to your updated versions of the above two colab notebooks.\r\n- Provide links to your TensorFlow model and (optionally) TensorFlow Lite Model.\r\n```\r\n\r\n#### Option B: Paste your code here or provide a link to a custom end-to-end colab\r\n\r\n```\r\n(You can paste links or attach files by dragging & dropping them below)\r\n- Include code to invoke the TFLite Converter Python API and the errors.\r\n- Provide links to your TensorFlow model and (optionally) TensorFlow Lite Model.\r\n```\r\n\r\n### 3. Failure after conversion\r\nIn 2.4.0, the following error occurs:\r\n\r\nloc(callsite(callsite(\"MaxPool2d@__inference___call___1278\" at \"PartitionedCall@__inference_signature_wrapper_1497\") at \"PartitionedCall\")): error: 'tf.MaxPool' op is neither a custom op nor a flex op\r\nerror: failed while converting: 'main': Ops that can be supported by the flex runtime (enabled via setting the -emit-select-tf-ops flag):\r\n\ttf.MaxPool {data_format = \"NCHW\", device = \"\", explicit_paddings = [], ksize = [1, 1, 3, 3], padding = \"VALID\", strides = [1, 1, 2, 2]}\r\nTraceback (most recent call last):\r\n  File \"/workspace/venv/tensorflow2_4/lib/python3.6/site-packages/tensorflow/lite/python/convert.py\", line 213, in toco_convert_protos\r\n    enable_mlir_converter)\r\n  File \"/workspace/venv/tensorflow2_4/lib/python3.6/site-packages/tensorflow/lite/python/wrap_toco.py\", line 38, in wrapped_toco_convert\r\n    enable_mlir_converter)\r\nException: <unknown>:0: error: loc(callsite(callsite(\"MaxPool2d@__inference___call___1278\" at \"PartitionedCall@__inference_signature_wrapper_1497\") at \"PartitionedCall\")): 'tf.MaxPool' op is neither a custom op nor a flex op\r\n<unknown>:0: note: loc(\"PartitionedCall\"): called from\r\n<unknown>:0: error: failed while converting: 'main': Ops that can be supported by the flex runtime (enabled via setting the -emit-select-tf-ops flag):\r\n\ttf.MaxPool {data_format = \"NCHW\", device = \"\", explicit_paddings = [], ksize = [1, 1, 3, 3], padding = \"VALID\", strides = [1, 1, 2, 2]}\r\n", "comments": ["Please consider using the Select TF option. https://www.tensorflow.org/lite/guide/ops_select", "TF 2.5.0 is now available on the chip. So we solved it by converting from 2.5.0."]}, {"number": 51520, "title": "Add negative dim support to tf to tosa expand dims", "body": "Also allows for reading tf.expandDims ops with non-scalar dim input. ie 0 vs [0]. \r\nReplaced some asserts with compiler errors.\r\n \r\nAddresses the referenced issue.\r\n\r\n\r\nhttps://github.com/google/iree/issues/6768", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F51520) for more info**.\n\n<!-- need_author_cla -->", "@googlebot I fixed it.", "@rsuderman  Can you please review this PR ? Thanks!", "> @rsuderman Can you please review this PR ? Thanks!\r\n\r\nJust noticed this. Will handle review."]}]