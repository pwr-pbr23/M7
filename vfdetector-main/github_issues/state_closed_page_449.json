[{"number": 40373, "title": "Saving Keras model containing layer returning sparse tensor hits: \"ValueError: If specifying TensorSpec names for nested structures, either zero or all names have to be specified.\"", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes (entirety included below)\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n  - macOS 10.14.5 (18F203)\r\n  - current `tensorflow/tensorflow:latest` docker image (permanent reference: `tensorflow/tensorflow@sha256:08901711826b185136886c7b8271b9fdbe86b8ccb598669781a1f5cb340184eb`)\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): pip on macOS, preinstalled in docker image\r\n- TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b 2.2.0\r\n- Python version: 3.6.9\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**Describe the current behavior**\r\n\r\nSuppose a Keras model that contains a layer that returns a sparse tensor, and that sparse tensor is used as input to a later layer. No `name`s are explicitly specified for any part of the model. Saving the model (with any of the `Model.save` method, `tf.saved_model.save` or `tf.keras.models.save_model`) hits an exception:\r\n\r\n```\r\nValueError: If specifying TensorSpec names for nested structures, either zero or all names have to be specified.\r\n```\r\n\r\nIf this is a problem in the user code, the exception doesn't make it clear:\r\n- what the problem is\r\n- where it is (e.g. which tensors/layers are effected) \r\n- how to fix it\r\n\r\nFor the second point, I ended up having to reduce (using a combination of creduce and manual editing) a much larger model to narrow down the problem from the original report in https://github.com/stellargraph/stellargraph/issues/1251.\r\n\r\n(This may relate to #38465, in particular the ragged tensors mentioned in https://github.com/tensorflow/tensorflow/issues/38465#issuecomment-638542728.)\r\n\r\n**Describe the expected behavior**\r\n\r\nIt would be good for at least one of:\r\n\r\n- the exception message/metadata improved to answer the three points above, so it's easier to fix\r\n- the code to work\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\nclass SqueezedSparseConversion(tf.keras.layers.Layer):\r\n    def call(self, inputs):\r\n        return tf.SparseTensor([(0, 1)], [0.1], (3, 3))\r\n\r\nclass GraphConvolution(tf.keras.layers.Layer):\r\n    def call(self, inputs):\r\n        return inputs[0]\r\n\r\nx_t = tf.keras.Input(0)\r\nsp = SqueezedSparseConversion()(x_t)\r\nout = GraphConvolution()([x_t, sp])\r\n\r\nm = tf.keras.Model([x_t], out)\r\nm.summary()\r\nm.save(\"\")\r\n```\r\n\r\nThis code is very simplified. In the real code, the `tf.SparseTensor` is constructed from data in `inputs`, and `GraphConvolution` does use the sparse tensor in `inputs[1]`, in addition to `inputs[0]`.\r\n\r\nNB: if the sparse tensor is constructed purely within a layer, everything works:\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\nclass GraphConvolution(tf.keras.layers.Layer):\r\n    def call(self, inputs):\r\n        sp = tf.SparseTensor([(0, 1)], [0.1], (3, 3))\r\n        return inputs[0]\r\n\r\nx_t = tf.keras.Input(0)\r\nout = GraphConvolution()([x_t])\r\n\r\nm = tf.keras.Model([x_t], out)\r\nm.summary()\r\nm.save(\"\")\r\n```\r\n\r\n**Other info / logs** \r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py\", line 1052, in save\r\n    signatures, options)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py\", line 138, in save_model\r\n    signatures, options)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/save.py\", line 78, in save\r\n    save_lib.save(model, filepath, signatures, options)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/save.py\", line 951, in save\r\n    obj, export_dir, signatures, options, meta_graph_def)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/save.py\", line 1022, in _build_meta_graph\r\n    _ = _SaveableView(checkpoint_graph_view)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/save.py\", line 204, in __init__\r\n    function._list_all_concrete_functions_for_serialization())  # pylint: disable=protected-access\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\", line 841, in _list_all_concrete_functions_for_serialization\r\n    concrete_functions.append(self.get_concrete_function(*args, **kwargs))\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/save_impl.py\", line 546, in get_concrete_function\r\n    self.call_collection.add_trace(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/save_impl.py\", line 421, in add_trace\r\n    fn.get_concrete_function(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/save_impl.py\", line 547, in get_concrete_function\r\n    return super(LayerCall, self).get_concrete_function(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\", line 959, in get_concrete_function\r\n    concrete = self._get_concrete_function_garbage_collected(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\", line 877, in _get_concrete_function_garbage_collected\r\n    *args, **kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 2496, in _get_concrete_function_garbage_collected\r\n    graph_function, args, kwargs = self._maybe_define_function(args, kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 2777, in _maybe_define_function\r\n    graph_function = self._create_graph_function(args, kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 2667, in _create_graph_function\r\n    capture_by_value=self._capture_by_value),\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\", line 898, in func_graph_from_py_func\r\n    args, arg_names, flat_shapes=arg_shapes)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\", line 1132, in _get_defun_inputs_from_args\r\n    args, names, structure=args, flat_shapes=flat_shapes)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\", line 1196, in _get_defun_inputs\r\n    raise ValueError(\"If specifying TensorSpec names for nested structures, \"\r\nValueError: If specifying TensorSpec names for nested structures, either zero or all names have to be specified.\r\n```", "comments": ["I am able to replicate this issue, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/56d0bb4e22fe010dbd150c6a8def9a54/untitled.ipynb)", "@huonw This is a duplicate of the issue #38465 ", "It does look similar. I added a comment with my reproducer (and the gist) to that issue.", "@huonw Thank you for commenting in the other issue.\r\n@huonw @rlav440 This issue has been fixed in tf-nightly. Please find the gist [here](https://colab.research.google.com/gist/gowthamkpr/02054044d39cd7986950ee10fa740b10/untitled.ipynb)\r\nI am closing this issue now. We can track your issue there as having one instance of the issue helps.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40373\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40373\">No</a>\n"]}, {"number": 40372, "title": "TPUStrategy does not export graph to TensorBoard while TPUEstimator does it", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Both Tested\r\n- OS Platform and Distribution: Linux Ubuntu 18.04 on GCE\r\n- TensorFlow installed from: PyPI, with `tensorflow==2.1.0`\r\n- TensorFlow version: `v2.1.0-rc2-17-ge5bf8de 2.1.0`\r\n- Python version: 3.6\r\n- CUDA/cuDNN version: N/A (Issue from TPU environment)\r\n- GPU model and memory: N/A (Same as above)\r\n- (Additional) TensorBoard version: 2.1.0\r\n\r\n**Describe the current behavior**\r\n\r\nI've found [the official document from Google Cloud](https://cloud.google.com/tpu/docs/cloud-tpu-tools#xla_graphs) says that I can access to the graph by clicking `GRAPHS` tab inside TensorBoard without setting any other configuration to my code, so I constructed the graph and executed the training steps by using `TPUStrategy`. But I failed to find those informations on TensorBoard.\r\n\r\nI additionally tested the official model by using `TPUEstimator` on V1 Compat API, and I could successfully obtain the graph data on TensorBoard. I assume this is a bug, but may need several help if not. Thank you!\r\n\r\n**Describe the expected behavior**\r\n\r\nThe code below successfully export graph data on TensorBoard.\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\nI've tested [the official tutorial using ResNet](https://github.com/tensorflow/tpu/blob/master/models/official/resnet/resnet_main.py), and saw it is successfully working.\r\n\r\nProblem is at the code below:\r\n\r\n> `Model` is very small toy model like `Linear-ReLU-Linear`, and was subclassed using `tf.keras`.\r\n\r\n```python \r\nimport tensorflow as tf\r\nimport os\r\n\r\nfrom project.model import Model\r\n\r\ndef main():\r\n    storage_name = \"google-cloud-storage-name\"\r\n    GRAPH_LOGDIR = f\"{storage_name}/logs/\"\r\n\r\n    writer = tf.summary.create_file_writer(GRAPH_LOGDIR)\r\n\r\n    resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=os.environ[\"TPU_NAME\"])\r\n    tf.config.experimental_connect_to_cluster(resolver)\r\n    tf.tpu.experimental.initialize_tpu_system(resolver)\r\n    strategy = tf.distribute.experimental.TPUStrategy(resolver)\r\n\r\n    with strategy.scope():\r\n        model = Model()\r\n\r\n        @tf.function\r\n        def trace_model(model_input):\r\n            return model(model_input)\r\n\r\n        model_input = tf.ones((3, 48), tf.int64)\r\n\r\n        tf.summary.trace_on(graph=True, profiler=True)\r\n        trace_model(model_input)\r\n        with writer.as_default():\r\n            tf.summary.trace_export(name=\"model_trace\", step=0, profiler_outdir=GRAPH_LOGDIR)\r\n\r\nif __name__ == \"__main__\":\r\n    main()\r\n```\r\n\r\nI estimated this code should work and export graph data to TensorBoard, but no any graph data was found.\r\n\r\n**Other info / logs**\r\n\r\nEvery single examples were tested on Google Cloud, using Cloud TPU, Compute Engine, and Cloud Storage.\r\nCC @ddehun", "comments": ["@harrydrippin \r\n\r\nI tried reproducing the issue in colab and i am seeing error (`ModuleNotFoundError: No module named 'project'`).Request you to procide colab link or simple standalone code with supporting files to reproduce the isse in our environment.It helps us in localizing the issue faster.Thanks!", "@ravikyram , I'm working with @harrydrippin for this issue. We just made the[ issue regeneration step example on Colab.](https://colab.research.google.com/drive/1rDXQacODUQ-ycJM-HIPMcsn_wVgoBZoK?usp=sharing)\r\n\r\nDue to the restriction about file system on Colab environment, **You may need to apply some changes for the appropriate setting to use TPU-based model training and logging.** \r\n\r\nBy the result of this notebook, you can see two log files: one for Estimator-based, and another one for Strategy-based. And, as you can check on the images, Strategy-based code CANNOT generate the graph while Estimator-based code can.\r\n\r\n### Estimator-based\r\n\r\n<img width=\"1501\" alt=\"\u1109\u1173\u110f\u1173\u1105\u1175\u11ab\u1109\u1163\u11ba 2020-06-15 \u110b\u1169\u1112\u116e 9 37 34\" src=\"https://user-images.githubusercontent.com/20228985/84658182-74338780-af50-11ea-81c3-b419ed2c6407.png\">\r\n\r\n### Strategy-based\r\n\r\n<img width=\"1497\" alt=\"\u1109\u1173\u110f\u1173\u1105\u1175\u11ab\u1109\u1163\u11ba 2020-06-15 \u110b\u1169\u1112\u116e 9 38 07\" src=\"https://user-images.githubusercontent.com/20228985/84658211-8281a380-af50-11ea-9ed6-d2ed14873300.png\">\r\n\r\nThank you for your support, and let us know if you need any other information.", "@harrydrippin  It looks like you are using an older Version of Tensorflow. Many bugs have been fixed in the latest version. Could you please execute your code using Latest Version 2.5 and let us know if the issue still persists? Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40372\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40372\">No</a>\n"]}, {"number": 40371, "title": "Sign compare warning fixes batch 1", "body": "warning ids: [ 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 50, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 95, 96, 97, 98, 99 100, 101, 102, 103 ] \r\n\r\n@mihaimaruseac ", "comments": ["Check out this pull request on&nbsp; <a href=\"https://app.reviewnb.com/tensorflow/tensorflow/pull/40371\"><img align=\"absmiddle\"  alt=\"ReviewNB\" height=\"28\" class=\"BotMessageButtonImage\" src=\"https://raw.githubusercontent.com/ReviewNB/support/master/images/button_reviewnb.png\"/></a> \n\n Review Jupyter notebook visual diffs & provide feedback on notebooks. \n\n---\n\n <i>Powered by <a href='https://www.reviewnb.com'>ReviewNB</a></i>", "I changed `quantization_config.cc` because it failed the build.\r\n\r\n@joker-eph ", "@joker-eph "]}, {"number": 40370, "title": "Image Encoding/Decoding and B64 Encoding/Decoding Not Working", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (or github SHA if from source): tf-nightly-gpu\r\n\r\n\r\n**Provide the text output from tflite_convert**\r\n```\r\n2020-06-10 20:13:06.127888: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll\r\n2020-06-10 20:13:08.090537: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library nvcuda.dll\r\n2020-06-10 20:13:08.113383: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1683] Found device 0 with properties:\r\npciBusID: 0000:01:00.0 name: GeForce GTX 1060 computeCapability: 6.1\r\ncoreClock: 1.733GHz coreCount: 10 deviceMemorySize: 6.00GiB deviceMemoryBandwidth: 178.99GiB/s\r\n2020-06-10 20:13:08.113524: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll\r\n2020-06-10 20:13:08.116647: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll\r\n2020-06-10 20:13:08.119646: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll\r\n2020-06-10 20:13:08.122447: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll\r\n2020-06-10 20:13:08.126673: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll\r\n2020-06-10 20:13:08.128467: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_10.dll\r\n2020-06-10 20:13:08.135299: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll\r\n2020-06-10 20:13:08.135697: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1825] Adding visible gpu devices: 0\r\n2020-06-10 20:13:08.136396: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance-critical operations:  AVX2\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2020-06-10 20:13:08.146065: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1eb4c32fa00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-06-10 20:13:08.146205: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2020-06-10 20:13:08.146679: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1683] Found device 0 with properties:\r\npciBusID: 0000:01:00.0 name: GeForce GTX 1060 computeCapability: 6.1\r\ncoreClock: 1.733GHz coreCount: 10 deviceMemorySize: 6.00GiB deviceMemoryBandwidth: 178.99GiB/s\r\n2020-06-10 20:13:08.146785: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll\r\n2020-06-10 20:13:08.146881: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll\r\n2020-06-10 20:13:08.146962: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll\r\n2020-06-10 20:13:08.147058: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll\r\n2020-06-10 20:13:08.147123: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll\r\n2020-06-10 20:13:08.147222: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_10.dll\r\n2020-06-10 20:13:08.147325: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll\r\n2020-06-10 20:13:08.147829: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1825] Adding visible gpu devices: 0\r\n2020-06-10 20:13:08.640614: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1224] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-06-10 20:13:08.640783: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1230]      0\r\n2020-06-10 20:13:08.640915: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1243] 0:   N\r\n2020-06-10 20:13:08.641430: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1369] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4826 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n2020-06-10 20:13:08.644906: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1eb6d09aff0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\r\n2020-06-10 20:13:08.645004: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1060, Compute Capability 6.1\r\nWARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\deblurring-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:467: set_learning_phase (from tensorflow.python.keras.backend) is deprecated and will be removed after 2020-10-11.\r\nInstructions for updating:\r\nSimply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\r\nWARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\deblurring-gpu\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:105: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nThis property should not be used in TensorFlow 2.0, as updates are applied automatically.\r\nWARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\deblurring-gpu\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:105: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nThis property should not be used in TensorFlow 2.0, as updates are applied automatically.\r\n2020-06-10 20:13:09.359436: I tensorflow/core/grappler/devices.cc:69] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\r\n2020-06-10 20:13:09.359812: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\r\n2020-06-10 20:13:09.361503: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1683] Found device 0 with properties:\r\npciBusID: 0000:01:00.0 name: GeForce GTX 1060 computeCapability: 6.1\r\ncoreClock: 1.733GHz coreCount: 10 deviceMemorySize: 6.00GiB deviceMemoryBandwidth: 178.99GiB/s\r\n2020-06-10 20:13:09.361962: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll\r\n2020-06-10 20:13:09.362238: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll\r\n2020-06-10 20:13:09.362494: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll\r\n2020-06-10 20:13:09.362799: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll\r\n2020-06-10 20:13:09.363040: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll\r\n2020-06-10 20:13:09.363260: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_10.dll\r\n2020-06-10 20:13:09.363492: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll\r\n2020-06-10 20:13:09.363870: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1825] Adding visible gpu devices: 0\r\n2020-06-10 20:13:09.364116: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1224] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-06-10 20:13:09.364323: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1230]      0\r\n2020-06-10 20:13:09.364533: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1243] 0:   N\r\n2020-06-10 20:13:09.364959: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1369] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4826 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n2020-06-10 20:13:09.390848: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:810] Optimization results for grappler item: graph_to_optimize\r\n2020-06-10 20:13:09.391281: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:812]   function_optimizer: Graph size after: 24 nodes (21), 27 edges (24), time = 1.991ms.\r\n2020-06-10 20:13:09.391508: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:812]   function_optimizer: Graph size after: 24 nodes (0), 27 edges (0), time = 0.906ms.\r\n2020-06-10 20:13:09.391733: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:810] Optimization results for grappler item: decode_image_cond_jpeg_false_45\r\n2020-06-10 20:13:09.391947: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:812]   function_optimizer: Graph size after: 11 nodes (0), 12 edges (0), time = 0.673ms.\r\n2020-06-10 20:13:09.392162: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:812]   function_optimizer: Graph size after: 11 nodes (0), 12 edges (0), time = 0.593ms.\r\n2020-06-10 20:13:09.392375: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:810] Optimization results for grappler item: decode_image_cond_jpeg_cond_png_cond_gif_false_75\r\n2020-06-10 20:13:09.392602: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:812]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-06-10 20:13:09.392844: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:812]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-06-10 20:13:09.393065: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:810] Optimization results for grappler item: decode_image_cond_jpeg_cond_png_cond_gif_true_74\r\n2020-06-10 20:13:09.393291: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:812]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-06-10 20:13:09.393513: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:812]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-06-10 20:13:09.393738: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:810] Optimization results for grappler item: decode_image_cond_jpeg_cond_png_false_64\r\n2020-06-10 20:13:09.393958: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:812]   function_optimizer: Graph size after: 8 nodes (0), 8 edges (0), time = 0.471ms.\r\n2020-06-10 20:13:09.394159: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:812]   function_optimizer: Graph size after: 8 nodes (0), 8 edges (0), time = 0.402ms.\r\n2020-06-10 20:13:09.394365: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:810] Optimization results for grappler item: decode_image_cond_jpeg_cond_png_true_63\r\n2020-06-10 20:13:09.394570: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:812]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-06-10 20:13:09.394760: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:812]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-06-10 20:13:09.394966: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:810] Optimization results for grappler item: decode_image_cond_jpeg_true_44\r\n2020-06-10 20:13:09.395137: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:812]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-06-10 20:13:09.395308: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:812]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-06-10 20:13:09.497900: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:313] Ignored output_format.\r\n2020-06-10 20:13:09.498161: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:316] Ignored drop_control_dependency.\r\n2020-06-10 20:13:09.503781: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1683] Found device 0 with properties:\r\npciBusID: 0000:01:00.0 name: GeForce GTX 1060 computeCapability: 6.1\r\ncoreClock: 1.733GHz coreCount: 10 deviceMemorySize: 6.00GiB deviceMemoryBandwidth: 178.99GiB/s\r\n2020-06-10 20:13:09.504393: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll\r\n2020-06-10 20:13:09.504750: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll\r\n2020-06-10 20:13:09.504986: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll\r\n2020-06-10 20:13:09.505255: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll\r\n2020-06-10 20:13:09.505510: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll\r\n2020-06-10 20:13:09.505846: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_10.dll\r\n2020-06-10 20:13:09.506091: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll\r\n2020-06-10 20:13:09.506647: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1825] Adding visible gpu devices: 0\r\n2020-06-10 20:13:09.506960: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1224] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-06-10 20:13:09.507198: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1230]      0\r\n2020-06-10 20:13:09.507422: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1243] 0:   N\r\n2020-06-10 20:13:09.507869: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1369] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4826 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\nloc(fused[callsite(\"decode_image/Substr@__inference_call_120\"(\"C:\\ProgramData\\Anaconda3\\envs\\deblurring-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\image_ops_impl.py\":2639:0) at callsite(\"C:\\ProgramData\\Anaconda3\\envs\\deblurring-gpu\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\":201:0 at callsite(\"dev.py\":30:0 at callsite(\"C:\\ProgramData\\Anaconda3\\envs\\deblurring-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\":955:0 at callsite(\"C:\\ProgramData\\Anaconda3\\envs\\deblurring-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\":3722:0 at callsite(\"C:\\ProgramData\\Anaconda3\\envs\\deblurring-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\":600:0 at callsite(\"C:\\ProgramData\\Anaconda3\\envs\\deblurring-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\":979:0 at callsite(\"C:\\ProgramData\\Anaconda3\\envs\\deblurring-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\":3052:0 at callsite(\"C:\\ProgramData\\Anaconda3\\envs\\deblurring-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\":3200:0 at \"C:\\ProgramData\\Anaconda3\\envs\\deblurring-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\":2842:0))))))))), \"image_byte_wrapper/StatefulPartitionedCall/decode_image/Substr\"]): error: 'tf.Substr' op is neither a custom op nor a flex op\r\nloc(fused[callsite(\"decode_image/is_jpeg/Substr@__inference_call_120\"(\"C:\\ProgramData\\Anaconda3\\envs\\deblurring-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\image_ops_impl.py\":2707:0) at callsite(\"C:\\ProgramData\\Anaconda3\\envs\\deblurring-gpu\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\":201:0 at callsite(\"dev.py\":30:0 at callsite(\"C:\\ProgramData\\Anaconda3\\envs\\deblurring-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\":955:0 at callsite(\"C:\\ProgramData\\Anaconda3\\envs\\deblurring-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\":3722:0 at callsite(\"C:\\ProgramData\\Anaconda3\\envs\\deblurring-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\":600:0 at callsite(\"C:\\ProgramData\\Anaconda3\\envs\\deblurring-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\":979:0 at callsite(\"C:\\ProgramData\\Anaconda3\\envs\\deblurring-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\":3052:0 at callsite(\"C:\\ProgramData\\Anaconda3\\envs\\deblurring-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\":3200:0 at \"C:\\ProgramData\\Anaconda3\\envs\\deblurring-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\":2842:0))))))))), \"image_byte_wrapper/StatefulPartitionedCall/decode_image/is_jpeg/Substr\"]): error: 'tf.Substr' op is neither a custom op nor a flex op\r\nloc(\"decode_image/cond_jpeg/is_png/Substr@decode_image_cond_jpeg_false_45\"): error: 'tf.Substr' op is neither a custom op nor a flex op\r\nloc(\"decode_image/cond_jpeg/cond_png/cond_gif/Substr@decode_image_cond_jpeg_cond_png_cond_gif_false_75\"): error: 'tf.Substr' op is neither a custom op nor a flex op\r\nloc(\"decode_image/cond_jpeg/cond_png/cond_gif/DecodeGif@decode_image_cond_jpeg_cond_png_cond_gif_true_74\"): error: 'tf.DecodeGif' op is neither a custom op nor a flex op\r\nloc(\"decode_image/cond_jpeg/cond_png/DecodePng@decode_image_cond_jpeg_cond_png_true_63\"): error: 'tf.DecodePng' op is neither a custom op nor a flex op\r\nloc(\"decode_image/cond_jpeg/DecodeJpeg@decode_image_cond_jpeg_true_44\"): error: 'tf.DecodeJpeg' op is neither a custom op nor a flex op\r\nerror: failed while converting: 'main': Ops that need custom implementation (enabled via setting the -emit-custom-ops flag):\r\n        tf.DecodeGif {device = \"\"}\r\n        tf.DecodeJpeg {acceptable_fraction = 1.000000e+00 : f32, channels = 3 : i64, dct_method = \"\", device = \"\", fancy_upscaling = true, ratio = 1 : i64, try_recover_truncated = false}\r\n        tf.DecodePng {channels = 3 : i64, device = \"\"}\r\n        tf.Substr {T = i32, device = \"\", unit = \"BYTE\"}\r\nTraceback (most recent call last):\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\deblurring-gpu\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py\", line 182, in toco_convert_protos\r\n    model_str = wrap_toco.wrapped_toco_convert(model_flags_str,\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\deblurring-gpu\\lib\\site-packages\\tensorflow\\lite\\python\\wrap_toco.py\", line 32, in wrapped_toco_convert\r\n    return _pywrap_toco_api.TocoConvert(\r\nException: C:\\ProgramData\\Anaconda3\\envs\\deblurring-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\image_ops_impl.py:2639:1: error: 'tf.Substr' op is neither a custom op nor a flex op\r\n    substr = string_ops.substr(contents, 0, 3)\r\n^\r\nC:\\ProgramData\\Anaconda3\\envs\\deblurring-gpu\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201:1: note: called from\r\n      return target(*args, **kwargs)\r\n^\r\ndev.py:30:1: note: called from\r\n        image = tf.io.decode_image(inputs[0][0], channels=3)\r\n^\r\nC:\\ProgramData\\Anaconda3\\envs\\deblurring-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:955:1: note: called from\r\n            return autograph.converted_call(\r\n^\r\nC:\\ProgramData\\Anaconda3\\envs\\deblurring-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3722:1: note: called from\r\n    return wrapped_fn(*args, **kwargs)\r\n^\r\nC:\\ProgramData\\Anaconda3\\envs\\deblurring-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:600:1: note: called from\r\n        return weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n^\r\nC:\\ProgramData\\Anaconda3\\envs\\deblurring-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:979:1: note: called from\r\n      func_outputs = python_func(*func_args, **func_kwargs)\r\n^\r\nC:\\ProgramData\\Anaconda3\\envs\\deblurring-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3052:1: note: called from\r\n        func_graph_module.func_graph_from_py_func(\r\n^\r\nC:\\ProgramData\\Anaconda3\\envs\\deblurring-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3200:1: note: called from\r\n      graph_function = self._create_graph_function(args, kwargs)\r\n^\r\nC:\\ProgramData\\Anaconda3\\envs\\deblurring-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2842:1: note: called from\r\n      graph_function, _, _ = self._maybe_define_function(args, kwargs)\r\n^\r\nC:\\ProgramData\\Anaconda3\\envs\\deblurring-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\image_ops_impl.py:2639:1: note: see current operation: %2 = \"tf.Substr\"(%1, %cst_1, %cst_0) {T = i32, device = \"\", unit = \"BYTE\"} : (tensor<!tf.string>, tensor<i32>, tensor<i32>) -> tensor<!tf.string>\r\n    substr = string_ops.substr(contents, 0, 3)\r\n^\r\nC:\\ProgramData\\Anaconda3\\envs\\deblurring-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\image_ops_impl.py:2707:1: error: 'tf.Substr' op is neither a custom op nor a flex op\r\n        is_jpeg(contents), _jpeg, check_png, name='cond_jpeg')\r\n^\r\nC:\\ProgramData\\Anaconda3\\envs\\deblurring-gpu\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201:1: note: called from\r\n      return target(*args, **kwargs)\r\n^\r\ndev.py:30:1: note: called from\r\n        image = tf.io.decode_image(inputs[0][0], channels=3)\r\n^\r\nC:\\ProgramData\\Anaconda3\\envs\\deblurring-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:955:1: note: called from\r\n            return autograph.converted_call(\r\n^\r\nC:\\ProgramData\\Anaconda3\\envs\\deblurring-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3722:1: note: called from\r\n    return wrapped_fn(*args, **kwargs)\r\n^\r\nC:\\ProgramData\\Anaconda3\\envs\\deblurring-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:600:1: note: called from\r\n        return weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n^\r\nC:\\ProgramData\\Anaconda3\\envs\\deblurring-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:979:1: note: called from\r\n      func_outputs = python_func(*func_args, **func_kwargs)\r\n^\r\nC:\\ProgramData\\Anaconda3\\envs\\deblurring-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3052:1: note: called from\r\n        func_graph_module.func_graph_from_py_func(\r\n^\r\nC:\\ProgramData\\Anaconda3\\envs\\deblurring-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3200:1: note: called from\r\n      graph_function = self._create_graph_function(args, kwargs)\r\n^\r\nC:\\ProgramData\\Anaconda3\\envs\\deblurring-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2842:1: note: called from\r\n      graph_function, _, _ = self._maybe_define_function(args, kwargs)\r\n^\r\nC:\\ProgramData\\Anaconda3\\envs\\deblurring-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\image_ops_impl.py:2707:1: note: see current operation: %3 = \"tf.Substr\"(%1, %cst_1, %cst_0) {T = i32, device = \"\", unit = \"BYTE\"} : (tensor<!tf.string>, tensor<i32>, tensor<i32>) -> tensor<!tf.string>\r\n        is_jpeg(contents), _jpeg, check_png, name='cond_jpeg')\r\n^\r\n<unknown>:0: error: loc(\"decode_image/cond_jpeg/is_png/Substr@decode_image_cond_jpeg_false_45\"): 'tf.Substr' op is neither a custom op nor a flex op\r\n<unknown>:0: note: loc(\"decode_image/cond_jpeg/is_png/Substr@decode_image_cond_jpeg_false_45\"): see current operation: %0 = \"tf.Substr\"(%arg0, %cst_1, %cst_0) {T = i32, device = \"\", unit = \"BYTE\"} : (tensor<!tf.string>, tensor<i32>, tensor<i32>) -> tensor<!tf.string>\r\n<unknown>:0: error: loc(\"decode_image/cond_jpeg/cond_png/cond_gif/Substr@decode_image_cond_jpeg_cond_png_cond_gif_false_75\"): 'tf.Substr' op is neither a custom op nor a flex op\r\n<unknown>:0: note: loc(\"decode_image/cond_jpeg/cond_png/cond_gif/Substr@decode_image_cond_jpeg_cond_png_cond_gif_false_75\"): see current operation: %0 = \"tf.Substr\"(%arg0, %cst_0, %cst) {T = i32, device = \"\", unit = \"BYTE\"} : (tensor<!tf.string>, tensor<i32>, tensor<i32>) -> tensor<!tf.string>\r\n<unknown>:0: error: loc(\"decode_image/cond_jpeg/cond_png/cond_gif/DecodeGif@decode_image_cond_jpeg_cond_png_cond_gif_true_74\"): 'tf.DecodeGif' op is neither a custom op nor a flex op\r\n<unknown>:0: note: loc(\"decode_image/cond_jpeg/cond_png/cond_gif/DecodeGif@decode_image_cond_jpeg_cond_png_cond_gif_true_74\"): see current operation: %0 = \"tf.DecodeGif\"(%arg0) {device = \"\"} : (tensor<!tf.string>) -> tensor<?x?x?x3xui8>\r\n<unknown>:0: error: loc(\"decode_image/cond_jpeg/cond_png/DecodePng@decode_image_cond_jpeg_cond_png_true_63\"): 'tf.DecodePng' op is neither a custom op nor a flex op\r\n<unknown>:0: note: loc(\"decode_image/cond_jpeg/cond_png/DecodePng@decode_image_cond_jpeg_cond_png_true_63\"): see current operation: %0 = \"tf.DecodePng\"(%arg0) {channels = 3 : i64, device = \"\"} : (tensor<!tf.string>) -> tensor<?x?x3xui8>\r\n<unknown>:0: error: loc(\"decode_image/cond_jpeg/DecodeJpeg@decode_image_cond_jpeg_true_44\"): 'tf.DecodeJpeg' op is neither a custom op nor a flex op\r\n<unknown>:0: note: loc(\"decode_image/cond_jpeg/DecodeJpeg@decode_image_cond_jpeg_true_44\"): see current operation: %0 = \"tf.DecodeJpeg\"(%arg0) {acceptable_fraction = 1.000000e+00 : f32, channels = 3 : i64, dct_method = \"\", device = \"\", fancy_upscaling = true, ratio = 1 : i64, try_recover_truncated = false} : (tensor<!tf.string>) -> tensor<?x?x3xui8>\r\n<unknown>:0: error: failed while converting: 'main': Ops that need custom implementation (enabled via setting the -emit-custom-ops flag):\r\n        tf.DecodeGif {device = \"\"}\r\n        tf.DecodeJpeg {acceptable_fraction = 1.000000e+00 : f32, channels = 3 : i64, dct_method = \"\", device = \"\", fancy_upscaling = true, ratio = 1 : i64, try_recover_truncated = false}\r\n        tf.DecodePng {channels = 3 : i64, device = \"\"}\r\n        tf.Substr {T = i32, device = \"\", unit = \"BYTE\"}\r\n<unknown>:0: note: see current operation: \"func\"() ( {\r\n^bb0(%arg0: tensor<?x1x!tf.string>):  // no predecessors\r\n  %cst = \"std.constant\"() {value = dense<\"\\FF\\D8\\FF\"> : tensor<!tf.string>} : () -> tensor<!tf.string>\r\n  %cst_0 = \"std.constant\"() {value = dense<3> : tensor<i32>} : () -> tensor<i32>\r\n  %cst_1 = \"std.constant\"() {value = dense<0> : tensor<i32>} : () -> tensor<i32>\r\n  %cst_2 = \"std.constant\"() {value = dense<0> : tensor<1xi32>} : () -> tensor<1xi32>\r\n  %cst_3 = \"std.constant\"() {value = dense<1> : tensor<1xi32>} : () -> tensor<1xi32>\r\n  %0 = \"tf.StridedSlice\"(%arg0, %cst_2, %cst_3, %cst_3) {begin_mask = 0 : i64, device = \"\", ellipsis_mask = 0 : i64, end_mask = 0 : i64, new_axis_mask = 0 : i64, shrink_axis_mask = 1 : i64} : (tensor<?x1x!tf.string>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<1x!tf.string>\r\n  %1 = \"tf.StridedSlice\"(%0, %cst_2, %cst_3, %cst_3) {begin_mask = 0 : i64, device = \"\", ellipsis_mask = 0 : i64, end_mask = 0 : i64, new_axis_mask = 0 : i64, shrink_axis_mask = 1 : i64} : (tensor<1x!tf.string>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<!tf.string>\r\n  %2 = \"tf.Substr\"(%1, %cst_1, %cst_0) {T = i32, device = \"\", unit = \"BYTE\"} : (tensor<!tf.string>, tensor<i32>, tensor<i32>) -> tensor<!tf.string>\r\n  %3 = \"tf.Substr\"(%1, %cst_1, %cst_0) {T = i32, device = \"\", unit = \"BYTE\"} : (tensor<!tf.string>, tensor<i32>, tensor<i32>) -> tensor<!tf.string>\r\n  %4 = \"tfl.equal\"(%3, %cst) : (tensor<!tf.string>, tensor<!tf.string>) -> tensor<i1>\r\n  %5 = \"tf.If\"(%4, %1, %2) {_lower_using_switch_merge = false, _read_only_resource_inputs = [], device = \"\", else_branch = @decode_image_cond_jpeg_false_450, is_stateless = false, output_shapes = [#tf.shape<*>], then_branch = @decode_image_cond_jpeg_true_440} : (tensor<i1>, tensor<!tf.string>, tensor<!tf.string>) -> tensor<*xui8>\r\n  \"std.return\"(%5) : (tensor<*xui8>) -> ()\r\n}) {sym_name = \"main\", tf.entry_function = {control_outputs = \"\", inputs = \"args_0\", outputs = \"Identity\"}, type = (tensor<?x1x!tf.string>) -> tensor<*xui8>} : () -> ()\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"dev.py\", line 57, in <module>\r\n    tflite = convert(model)\r\n  File \"dev.py\", line 42, in convert\r\n    tflite_model = converter.convert()\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\deblurring-gpu\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py\", line 777, in convert\r\n    return super(TFLiteKerasModelConverterV2,\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\deblurring-gpu\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py\", line 591, in convert\r\n    result = _toco_convert_impl(\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\deblurring-gpu\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py\", line 555, in toco_convert_impl\r\n    data = toco_convert_protos(\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\deblurring-gpu\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py\", line 188, in toco_convert_protos\r\n    raise ConverterError(str(e))\r\ntensorflow.lite.python.convert.ConverterError: C:\\ProgramData\\Anaconda3\\envs\\deblurring-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\image_ops_impl.py:2639:1: error: 'tf.Substr' op is neither a custom op nor a flex op\r\n    substr = string_ops.substr(contents, 0, 3)\r\n^\r\nC:\\ProgramData\\Anaconda3\\envs\\deblurring-gpu\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201:1: note: called from\r\n      return target(*args, **kwargs)\r\n^\r\ndev.py:30:1: note: called from\r\n        image = tf.io.decode_image(inputs[0][0], channels=3)\r\n^\r\nC:\\ProgramData\\Anaconda3\\envs\\deblurring-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:955:1: note: called from\r\n            return autograph.converted_call(\r\n^\r\nC:\\ProgramData\\Anaconda3\\envs\\deblurring-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3722:1: note: called from\r\n    return wrapped_fn(*args, **kwargs)\r\n^\r\nC:\\ProgramData\\Anaconda3\\envs\\deblurring-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:600:1: note: called from\r\n        return weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n^\r\nC:\\ProgramData\\Anaconda3\\envs\\deblurring-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:979:1: note: called from\r\n      func_outputs = python_func(*func_args, **func_kwargs)\r\n^\r\nC:\\ProgramData\\Anaconda3\\envs\\deblurring-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3052:1: note: called from\r\n        func_graph_module.func_graph_from_py_func(\r\n^\r\nC:\\ProgramData\\Anaconda3\\envs\\deblurring-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3200:1: note: called from\r\n      graph_function = self._create_graph_function(args, kwargs)\r\n^\r\nC:\\ProgramData\\Anaconda3\\envs\\deblurring-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2842:1: note: called from\r\n      graph_function, _, _ = self._maybe_define_function(args, kwargs)\r\n^\r\nC:\\ProgramData\\Anaconda3\\envs\\deblurring-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\image_ops_impl.py:2639:1: note: see current operation: %2 = \"tf.Substr\"(%1, %cst_1, %cst_0) {T = i32, device = \"\", unit = \"BYTE\"} : (tensor<!tf.string>, tensor<i32>, tensor<i32>) -> tensor<!tf.string>\r\n    substr = string_ops.substr(contents, 0, 3)\r\n^\r\nC:\\ProgramData\\Anaconda3\\envs\\deblurring-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\image_ops_impl.py:2707:1: error: 'tf.Substr' op is neither a custom op nor a flex op\r\n        is_jpeg(contents), _jpeg, check_png, name='cond_jpeg')\r\n^\r\nC:\\ProgramData\\Anaconda3\\envs\\deblurring-gpu\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201:1: note: called from\r\n      return target(*args, **kwargs)\r\n^\r\ndev.py:30:1: note: called from\r\n        image = tf.io.decode_image(inputs[0][0], channels=3)\r\n^\r\nC:\\ProgramData\\Anaconda3\\envs\\deblurring-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:955:1: note: called from\r\n            return autograph.converted_call(\r\n^\r\nC:\\ProgramData\\Anaconda3\\envs\\deblurring-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3722:1: note: called from\r\n    return wrapped_fn(*args, **kwargs)\r\n^\r\nC:\\ProgramData\\Anaconda3\\envs\\deblurring-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:600:1: note: called from\r\n        return weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n^\r\nC:\\ProgramData\\Anaconda3\\envs\\deblurring-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:979:1: note: called from\r\n      func_outputs = python_func(*func_args, **func_kwargs)\r\n^\r\nC:\\ProgramData\\Anaconda3\\envs\\deblurring-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3052:1: note: called from\r\n        func_graph_module.func_graph_from_py_func(\r\n^\r\nC:\\ProgramData\\Anaconda3\\envs\\deblurring-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3200:1: note: called from\r\n      graph_function = self._create_graph_function(args, kwargs)\r\n^\r\nC:\\ProgramData\\Anaconda3\\envs\\deblurring-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2842:1: note: called from\r\n      graph_function, _, _ = self._maybe_define_function(args, kwargs)\r\n^\r\nC:\\ProgramData\\Anaconda3\\envs\\deblurring-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\image_ops_impl.py:2707:1: note: see current operation: %3 = \"tf.Substr\"(%1, %cst_1, %cst_0) {T = i32, device = \"\", unit = \"BYTE\"} : (tensor<!tf.string>, tensor<i32>, tensor<i32>) -> tensor<!tf.string>\r\n        is_jpeg(contents), _jpeg, check_png, name='cond_jpeg')\r\n^\r\n<unknown>:0: error: loc(\"decode_image/cond_jpeg/is_png/Substr@decode_image_cond_jpeg_false_45\"): 'tf.Substr' op is neither a custom op nor a flex op\r\n<unknown>:0: note: loc(\"decode_image/cond_jpeg/is_png/Substr@decode_image_cond_jpeg_false_45\"): see current operation: %0 = \"tf.Substr\"(%arg0, %cst_1, %cst_0) {T = i32, device = \"\", unit = \"BYTE\"} : (tensor<!tf.string>, tensor<i32>, tensor<i32>) -> tensor<!tf.string>\r\n<unknown>:0: error: loc(\"decode_image/cond_jpeg/cond_png/cond_gif/Substr@decode_image_cond_jpeg_cond_png_cond_gif_false_75\"): 'tf.Substr' op is neither a custom op nor a flex op\r\n<unknown>:0: note: loc(\"decode_image/cond_jpeg/cond_png/cond_gif/Substr@decode_image_cond_jpeg_cond_png_cond_gif_false_75\"): see current operation: %0 = \"tf.Substr\"(%arg0, %cst_0, %cst) {T = i32, device = \"\", unit = \"BYTE\"} : (tensor<!tf.string>, tensor<i32>, tensor<i32>) -> tensor<!tf.string>\r\n<unknown>:0: error: loc(\"decode_image/cond_jpeg/cond_png/cond_gif/DecodeGif@decode_image_cond_jpeg_cond_png_cond_gif_true_74\"): 'tf.DecodeGif' op is neither a custom op nor a flex op\r\n<unknown>:0: note: loc(\"decode_image/cond_jpeg/cond_png/cond_gif/DecodeGif@decode_image_cond_jpeg_cond_png_cond_gif_true_74\"): see current operation: %0 = \"tf.DecodeGif\"(%arg0) {device = \"\"} : (tensor<!tf.string>) -> tensor<?x?x?x3xui8>\r\n<unknown>:0: error: loc(\"decode_image/cond_jpeg/cond_png/DecodePng@decode_image_cond_jpeg_cond_png_true_63\"): 'tf.DecodePng' op is neither a custom op nor a flex op\r\n<unknown>:0: note: loc(\"decode_image/cond_jpeg/cond_png/DecodePng@decode_image_cond_jpeg_cond_png_true_63\"): see current operation: %0 = \"tf.DecodePng\"(%arg0) {channels = 3 : i64, device = \"\"} : (tensor<!tf.string>) -> tensor<?x?x3xui8>\r\n<unknown>:0: error: loc(\"decode_image/cond_jpeg/DecodeJpeg@decode_image_cond_jpeg_true_44\"): 'tf.DecodeJpeg' op is neither a custom op nor a flex op\r\n<unknown>:0: note: loc(\"decode_image/cond_jpeg/DecodeJpeg@decode_image_cond_jpeg_true_44\"): see current operation: %0 = \"tf.DecodeJpeg\"(%arg0) {acceptable_fraction = 1.000000e+00 : f32, channels = 3 : i64, dct_method = \"\", device = \"\", fancy_upscaling = true, ratio = 1 : i64, try_recover_truncated = false} : (tensor<!tf.string>) -> tensor<?x?x3xui8>\r\n<unknown>:0: error: failed while converting: 'main': Ops that need custom implementation (enabled via setting the -emit-custom-ops flag):\r\n        tf.DecodeGif {device = \"\"}\r\n        tf.DecodeJpeg {acceptable_fraction = 1.000000e+00 : f32, channels = 3 : i64, dct_method = \"\", device = \"\", fancy_upscaling = true, ratio = 1 : i64, try_recover_truncated = false}\r\n        tf.DecodePng {channels = 3 : i64, device = \"\"}\r\n        tf.Substr {T = i32, device = \"\", unit = \"BYTE\"}\r\n<unknown>:0: note: see current operation: \"func\"() ( {\r\n^bb0(%arg0: tensor<?x1x!tf.string>):  // no predecessors\r\n  %cst = \"std.constant\"() {value = dense<\"\\FF\\D8\\FF\"> : tensor<!tf.string>} : () -> tensor<!tf.string>\r\n  %cst_0 = \"std.constant\"() {value = dense<3> : tensor<i32>} : () -> tensor<i32>\r\n  %cst_1 = \"std.constant\"() {value = dense<0> : tensor<i32>} : () -> tensor<i32>\r\n  %cst_2 = \"std.constant\"() {value = dense<0> : tensor<1xi32>} : () -> tensor<1xi32>\r\n  %cst_3 = \"std.constant\"() {value = dense<1> : tensor<1xi32>} : () -> tensor<1xi32>\r\n  %0 = \"tf.StridedSlice\"(%arg0, %cst_2, %cst_3, %cst_3) {begin_mask = 0 : i64, device = \"\", ellipsis_mask = 0 : i64, end_mask = 0 : i64, new_axis_mask = 0 : i64, shrink_axis_mask = 1 : i64} : (tensor<?x1x!tf.string>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<1x!tf.string>\r\n  %1 = \"tf.StridedSlice\"(%0, %cst_2, %cst_3, %cst_3) {begin_mask = 0 : i64, device = \"\", ellipsis_mask = 0 : i64, end_mask = 0 : i64, new_axis_mask = 0 : i64, shrink_axis_mask = 1 : i64} : (tensor<1x!tf.string>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<!tf.string>\r\n  %2 = \"tf.Substr\"(%1, %cst_1, %cst_0) {T = i32, device = \"\", unit = \"BYTE\"} : (tensor<!tf.string>, tensor<i32>, tensor<i32>) -> tensor<!tf.string>\r\n  %3 = \"tf.Substr\"(%1, %cst_1, %cst_0) {T = i32, device = \"\", unit = \"BYTE\"} : (tensor<!tf.string>, tensor<i32>, tensor<i32>) -> tensor<!tf.string>\r\n  %4 = \"tfl.equal\"(%3, %cst) : (tensor<!tf.string>, tensor<!tf.string>) -> tensor<i1>\r\n  %5 = \"tf.If\"(%4, %1, %2) {_lower_using_switch_merge = false, _read_only_resource_inputs = [], device = \"\", else_branch = @decode_image_cond_jpeg_false_450, is_stateless = false, output_shapes = [#tf.shape<*>], then_branch = @decode_image_cond_jpeg_true_440} : (tensor<i1>, tensor<!tf.string>, tensor<!tf.string>) -> tensor<*xui8>\r\n  \"std.return\"(%5) : (tensor<*xui8>) -> ()\r\n}) {sym_name = \"main\", tf.entry_function = {control_outputs = \"\", inputs = \"args_0\", outputs = \"Identity\"}, type = (tensor<?x1x!tf.string>) -> tensor<*xui8>} : () -> ()\r\n```\r\n\r\n**Standalone code to reproduce the issue** \r\n```\r\nimport tensorflow as tf\r\n\r\nclass ImageByteWrapper(tf.keras.Model):\r\n    @tf.function(input_signature=[tf.TensorSpec(shape=[None, 1], dtype=tf.string)])\r\n    def call(self, inputs):\r\n        # Decode image into 4D tensor\r\n        return tf.io.decode_image(inputs[0][0], channels=3)\r\n\r\ndef convert(model):\r\n    converter = tf.lite.TFLiteConverter.from_keras_model(model)\r\n    converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\r\n    converter.target_spec.supported_ops = [\r\n        tf.lite.OpsSet.TFLITE_BUILTINS,\r\n        tf.lite.OpsSet.SELECT_TF_OPS,\r\n    ]\r\n    tflite_model = converter.convert()\r\n\r\n    return tflite_model\r\n\r\nmodel = ImageByteWrapper()\r\n\r\ntest_input = tf.random.uniform(shape=[64, 64, 3], minval=0, maxval=255, dtype=tf.int32)\r\ntest_input = tf.cast(test_input, dtype=tf.uint8)\r\ntest_input = tf.io.encode_jpeg(test_input)\r\ntest_input = tf.stack([test_input, test_input])\r\ntest_input = tf.reshape(test_input, [-1, 1])\r\n\r\nwith tf.device('/cpu:0'):\r\n    test_output = model(test_input)\r\n\r\ntflite = convert(model)\r\n```\r\n\r\nMost of the image encoding/decoding ops as well as Base64 encode/decode ops are not working. This is important because in production when deploying to some API is easier to transfer the data under b64 encoding or bytes encoding rather than actual tensors.\r\n\r\nI just supplied the minimal example with tf.decode_image() for minimalism.", "comments": ["Here is the google colab [gist](https://colab.research.google.com/drive/1vGQ-jxqcG7jRApZ1Mg0ABe5vIL4jk94n?usp=sharing)", "Hi @ElPapi42\r\n\r\nCould you try the conversion with Flex? https://www.tensorflow.org/lite/guide/ops_select#converting_the_model\r\n\r\nThe conversion was failed due to missing op support. I think you can use the tf ops directly via flex delegate.\r\n", "Hello @abattery ! if you check the gist, you will actually realize that I already setup it:\r\n```\r\nconverter.target_spec.supported_ops = [\r\n    tf.lite.OpsSet.TFLITE_BUILTINS,\r\n    tf.lite.OpsSet.SELECT_TF_OPS\r\n]\r\n```\r\nIf there is something I'm missing pls let me know", "@thaink could you help adding the missing tf ops into Flex delegate?\r\n\r\n```\r\n<unknown>:0: error: failed while converting: 'main': Ops that need custom implementation (enabled via setting the -emit-custom-ops flag):\r\n        tf.DecodeGif {device = \"\"}\r\n        tf.DecodeJpeg {acceptable_fraction = 1.000000e+00 : f32, channels = 3 : i64, dct_method = \"\", device = \"\", fancy_upscaling = true, ratio = 1 : i64, try_recover_truncated = false}\r\n        tf.DecodePng {channels = 3 : i64, device = \"\"}\r\n        tf.Substr {T = i32, device = \"\", unit = \"BYTE\"}\r\n```", "Can you actually specify to add the reverse op too?\r\n```\r\n<unknown>:0: error: failed while converting: 'main': Ops that need custom implementation (enabled via setting the -emit-custom-ops flag):\r\n        tf.EncodeJpeg {chroma_downsampling = true, density_unit = \"in\", device = \"\", format = \"\", optimize_size = false, progressive = false, quality = 95 : i64, x_density = 300 : i64, xmp_metadata = \"\", y_density = 300 : i64}\r\n```\r\n\r\nPD: And by the way, base64 encoder:\r\n```\r\n<unknown>:0: error: failed while converting: 'main': Ops that need custom implementation (enabled via setting the -emit-custom-ops flag):\r\n        tf.EncodeBase64 {device = \"\", pad = true}\r\n```\r\nThanks in advance!", "Those ops are not in the flex delegate whitelist yet: lite/delegates/flex/whitelisted_flex_ops.cc\r\nI'll add them to the whitelist.", "was there a merge for this?", "There is a build error in my PR, I need to solve it first.", "Awesome @thaink! thanks for your support, don't worry take your time!", "Hello! any advances on this? Thanks, @thaink!", "I have a PR to support EncodeBase64 and DecodeBase64.\r\nHowever, encoding and decoding images ops cause build failure so the internal code structure need be refactored first before supporting them.\r\nAre those Image encoding ops used for any task other than preprocessing? If they are only used for preprocessing, is it possible to use external library to do that for now?", "@thaink right now the project that produces this issue is mostly stale, I have no problem in wait a bit more.\r\n\r\nI'm deploying tflite to Tensorflow Serving, not to edge devices, so i need B64Decoding for transmitting the inference results over the network in relatively small packaging.\r\n\r\nCan you mention something about ```tf.io.decode_image``` and ```tf.io.encode_jpeg``` implementations? maybe i can just transmit the raw bytes for now", "EncodeBase64 and DecodeBase64 is already supported at the head of master.\r\n\r\nFor encode and decode_jpeg, it is a bit more complicated and still under discussion to solve some errors now.", "@thaink got it, this morning I read your comment wrong, thanks for the confirmation! ", "@elpapi42 Could you please let us know if this is still an issue ?Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40370\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40370\">No</a>\n"]}, {"number": 40369, "title": "model.load_weights fails to find matching files in gcs bucket", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nNo\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nLinux - colab\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\nN/A\r\n- TensorFlow installed from (source or binary):\r\ndefault colab installation\r\n- TensorFlow version (use command below):\r\n- Python version:\r\n3.6.9\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\nmodel.load_weights from a gcs bucket fails to find matching files even though they exist\r\n\r\n**Describe the expected behavior**\r\nFind the files and load the weights\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\nhttps://colab.research.google.com/drive/1PVXhopZg5RpKiJ6aUilO0oknsfNFX_Nr?usp=sharing\r\n\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["@CalebEverett \r\nPlease update the tensorflow version used. IN case you are using an old version can you please try on later version and update.", "I have version 2.2 installed. Which version should I upgrade to?", "@CalebEverett \r\nI ran the code shared on tf 2.2 and do not face any error, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/03077653c3302e897c0cbc00160d443e/untitled232.ipynb)", "Ok, I was able to run on 2.2. Thank you.", "Moving to closed status with confirmation.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40369\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40369\">No</a>\n"]}, {"number": 40368, "title": "added sparse.map_values", "body": "Second part of #39507\r\nadds a `sparse.map_values` operation for sparse Tensors in analogy to `ragged.map_flat_values`.\r\n\r\nI've copied the general structure of the code from the ragged analog, in particular the function is currently decorated with `@dispatch.add_dispatch_support`, of which I don't know the purpose.\r\n\r\nWhen multiple sparse Tensors are supplied as part of a `map_values` invocation, the current implementation checks that all indices and shapes match. This test might be a bit more expensive than the corresponding one for ragged tensors, since there are as many indices as there are values, so it might make sense to add an additional parameter to disable checks.\r\nI have opted against this, because \r\n  1) since the function takes arbitrary kwargs, this might introduce incompatibilities\r\n  2) It breaks the interface analogy with the ragged version\r\n  3) I expect that people who really need this last bit of performance, and are able to prove that in their code these checks always success, can write their custom code if this is really necessary.\r\n", "comments": ["@ngc92  Can you please check @edloper's comments and keep us posted. Thanks!", "All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F40368) for more info**.\n\n<!-- need_author_consent -->", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F40368) for more info**.\n\n<!-- ok -->", "Sorry for the git spam, I screwed something up when I merged the tf changes back into my branch.\r\n@edloper All your recommendations, except for the name of the function, should be in the code now\r\nI do think the name is good as it is though, because it keeps the consistency with ragged tensors. And I would expect potential users of this method to have at least a very broad understanding of what a sparse tensor is. \r\n\r\nIt might make sense to highlight the \r\n```\r\nNote in particular that even though `tf.add(0, 5) != 0`, implicit zeros\r\n  will remain unchanged. However, if the sparse tensor contains any explict\r\n  zeros, these will be affected by the mapping!\r\n```\r\nin the documentation, at least I would expect me as a first user of the method to not necessarily think of that, even though it makes perfect sense in hindsight.", "Can you check sanity build please? Looks like a pylint issue", "@ngc92 can you please check build failures.", "Pylint still fails\r\n\r\n```\r\nFAIL: Found 9 non-whitelisted pylint errors:\r\ntensorflow/python/ops/sparse_ops_test.py:193: [W0311(bad-indentation), ] Bad indentation. Found 8 spaces, expected 6\r\n\r\ntensorflow/python/ops/sparse_ops_test.py:194: [C0301(line-too-long), ] Line too long (83/80)\r\n\r\ntensorflow/python/ops/sparse_ops_test.py:194: [W0311(bad-indentation), ] Bad indentation. Found 8 spaces, expected 6\r\n\r\ntensorflow/python/ops/sparse_ops_test.py:195: [C0301(line-too-long), ] Line too long (90/80)\r\n\r\ntensorflow/python/ops/sparse_ops_test.py:195: [W0311(bad-indentation), ] Bad indentation. Found 8 spaces, expected 6\r\n\r\ntensorflow/python/ops/sparse_ops_test.py:205: [W0311(bad-indentation), ] Bad indentation. Found 8 spaces, expected 6\r\n\r\ntensorflow/python/ops/sparse_ops_test.py:206: [W0311(bad-indentation), ] Bad indentation. Found 8 spaces, expected 6\r\n\r\ntensorflow/python/ops/sparse_ops.py:2774: [C0301(line-too-long), ] Line too long (82/80)\r\n\r\ntensorflow/python/ops/sparse_ops.py:2812: [C0330(bad-continuation), ] Wrong continued indentation (add 30 spaces).\r\n```", "```\r\nFailed example:\r\n    tf.sparse.to_dense(tf.sparse.map_values(tf.add, s, 5)).numpy()\r\nExpected:\r\n    [[6 7 0]\r\n     [0 9 0]\r\n     [6 0 0]]\r\nGot:\r\n    array([[6, 7, 0],\r\n           [0, 9, 0],\r\n           [6, 0, 0]], dtype=int32)\r\n```\r\n\r\nThe docstests are failing. Let's remove `numpy()` and consider the output as tensor. You can use `...` to hide parts of the output which are not relevant.", "@ngc92 Can you please check @mihaimaruseac's comments and keep us posted. Thanks!", "@ngc92  Any update on this PR? Please. Thanks!", "> update on this PR? Please. Thanks!\r\n\r\nI'll try fixing it in the merge commit."]}, {"number": 40367, "title": "[ROCm][mlir] Disable mlir saved model test", "body": "Adding `no-rocm` tag to saved model test. There is flaky OOM failures yet to be investigated in the following unit tests in ROCm CI:\r\n\r\n- basic_v1.py.test\r\n- multi_variables_v1.py.test\r\n- shared_variables_v1.py.test\r\n\r\nThe added tag disables those unit tests.", "comments": ["> ROCm backend does not have a working mlir backend yet\r\n\r\nWhat does that mean? These tests are not (mostly?) runtime tests and are intended to be \"backend\" agnostic.", "@jerryyin Can you please check @joker-eph's comments and keep us posted. Thanks!", "Was working on a number of things sorry for the late reply. \r\n> > ROCm backend does not have a working mlir backend yet\r\n> \r\n> What does that mean? These tests are not (mostly?) runtime tests and are intended to be \"backend\" agnostic.\r\n\r\nThat part of story remains a mystery. It *shouldn't* run into any issues into this. To give more details, of the[ two most recent CI runs](https://github.com/ROCmSoftwarePlatform/tensorflow-upstream/pull/1010) in our CI, one of which is failing on all `basic_v1.py.test`, `multi_variables_v1.py.test` and `shared_variables_v1.py.test`. Another is doing all fine. Before we can find time to understand why those tests have flaky OOM failures the easy way ahead is to just disable them. It does not make the situation worse because there's already a `no_rocm` flag when it is an empty list, kind of confirming the existence of flakiness. ", "> Before we can find time to understand why those tests have flaky OOM failures the easy way ahead is to just disable them. It does not make the situation worse because there's already a no_rocm flag when it is an empty list, kind of confirming the existence of flakiness.\r\n\r\nWhat is the plan for investigating and fixing this? Do you have a timeline? I would be concerned to sweep this under the rug and forget it.", "> What is the plan for investigating and fixing this? Do you have a timeline? I would be concerned to sweep this under the rug and forget it.\r\n\r\nThat's reasonable questions to ask. Internally, we do keep track of all `no-rocm` tags, and work to re-enable them. I don't think it can just got forgotten. What this PR does is to minimize diff between upstream and downstream forks and bring the state up to the latest. Speaking of the specific one, it comes as lower priority than the general functionality of mlir ROCm backend. I'm not the right person to comment on the timeline as it has to conform with team's priorities, and is probably out-of-scope for this PR. @deven-amd also for awareness.", "> Speaking of the specific one, it comes as lower priority than the general functionality of mlir ROCm backend\r\n\r\nAs we already established (I think): this is entirely orthogonal to a \"MLIR Backend\" of any sort. \r\n\r\nCan we start by updating the CL description with an accurate description of the problem, including information about what fails and how?", "> Can we start by updating the CL description with an accurate description of the problem\r\n\r\nDone"]}, {"number": 40366, "title": "Raise ValueError when saving a model created in mirroredstrategy", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Yes\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): tf-nightly\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\nThe model is created inside a mirroredstrategy. When I save the model using `model.save(save_path)` after training, it raises `ValueError: SyncOnReadVariable does not support `assign_add` in cross-replica context when aggregation is set to `tf.VariableAggregation.SUM`.` The error is triggered [here](https://github.com/tensorflow/models/blob/master/official/recommendation/ncf_keras_main.py#L85). The related error tracing is:\r\n\r\n```python\r\n  File \"ncf_keras_main.py\", line 85, in call\r\n    self.add_metric(hr_sum, name=\"hr_sum\", aggregation=\"mean\")\r\n  File \"/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 1678, in add_metric\r\n    metric_obj(value)\r\n  File \"/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/metrics.py\", line 231, in __call__\r\n    replica_local_fn, *args, **kwargs)\r\n  File \"/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/distribute/distributed_training_utils.py\", line 1133, in call_replica_local_fn\r\n    return fn(*args, **kwargs)\r\n  File \"/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/metrics.py\", line 211, in replica_local_fn\r\n    update_op = self.update_state(*args, **kwargs)  # pylint: disable=not-callable\r\n  File \"/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/utils/metrics_utils.py\", line 90, in decorated\r\n    update_op = update_state_fn(*args, **kwargs)\r\n  File \"/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/metrics.py\", line 176, in update_state_fn\r\n    return ag_update_state(*args, **kwargs)\r\n  File \"/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 302, in wrapper\r\n    return func(*args, **kwargs)\r\n  File \"/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/metrics.py\", line 373, in update_state\r\n    update_total_op = self.total.assign_add(value_sum)\r\n  File \"/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/distribute/values.py\", line 918, in assign_add\r\n    \"SyncOnReadVariable does not support `assign_add` in \"\r\nValueError: SyncOnReadVariable does not support `assign_add` in cross-replica context when aggregation is set to `tf.VariableAggregation.SUM`.\r\n```\r\nI also attached a complete tracing for your reference.\r\n\r\n**Describe the expected behavior**\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n```python\r\nTraceback (most recent call last):\r\n  File \"ncf_keras_main.py\", line 568, in <module>\r\n    app.run(main)\r\n  File \"/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/absl/app.py\", line 299, in run\r\n    _run_main(main, args)\r\n  File \"/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/absl/app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"ncf_keras_main.py\", line 563, in main\r\n    logging.info(\"Result is %s\", run_ncf(FLAGS))\r\n  File \"ncf_keras_main.py\", line 351, in run_ncf\r\n    keras_model.save(\"save_model\")\r\n  File \"/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\", line 1950, in save\r\n    signatures, options)\r\n  File \"/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/saving/save.py\", line 134, in save_model\r\n    signatures, options)\r\n  File \"/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/save.py\", line 78, in save\r\n    save_lib.save(model, filepath, signatures, options)\r\n  File \"/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/saved_model/save.py\", line 953, in save\r\n    obj, export_dir, signatures, options, meta_graph_def)\r\n  File \"/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/saved_model/save.py\", line 1015, in _build_meta_graph\r\n    checkpoint_graph_view)\r\n  File \"/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/saved_model/signature_serialization.py\", line 75, in find_function_to_export\r\n    functions = saveable_view.list_functions(saveable_view.root)\r\n  File \"/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/saved_model/save.py\", line 144, in list_functions\r\n    self._serialization_cache)\r\n  File \"/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\", line 2543, in _list_functions_for_serialization\r\n    Model, self)._list_functions_for_serialization(serialization_cache)\r\n  File \"/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 3014, in _list_functions_for_serialization\r\n    .list_functions_for_serialization(serialization_cache))\r\n  File \"/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/base_serialization.py\", line 87, in list_functions_for_serialization\r\n    fns = self.functions_to_serialize(serialization_cache)\r\n  File \"/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/layer_serialization.py\", line 77, in functions_to_serialize\r\n    serialization_cache).functions_to_serialize)\r\n  File \"/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/layer_serialization.py\", line 92, in _get_serialized_attributes\r\n    serialization_cache)\r\n  File \"/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/model_serialization.py\", line 51, in _get_serialized_attributes_internal\r\n    default_signature = save_impl.default_save_signature(self.obj)\r\n  File \"/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/save_impl.py\", line 205, in default_save_signature\r\n    fn.get_concrete_function()\r\n  File \"/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 1168, in get_concrete_function\r\n    concrete = self._get_concrete_function_garbage_collected(*args, **kwargs)\r\n  File \"/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 1074, in _get_concrete_function_garbage_collected\r\n    self._initialize(args, kwargs, add_initializers_to=initializers)\r\n  File \"/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 697, in _initialize\r\n    *args, **kwds))\r\n  File \"/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 2842, in _get_concrete_function_internal_garbage_collected\r\n    graph_function, _, _ = self._maybe_define_function(args, kwargs)\r\n  File \"/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 3200, in _maybe_define_function\r\n    graph_function = self._create_graph_function(args, kwargs)\r\n  File \"/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 3062, in _create_graph_function\r\n    capture_by_value=self._capture_by_value),\r\n  File \"/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\", line 979, in func_graph_from_py_func\r\n    func_outputs = python_func(*func_args, **func_kwargs)\r\n  File \"/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 600, in wrapped_fn\r\n    return weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n  File \"/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/saving/saving_utils.py\", line 132, in _wrapped_model\r\n    outputs = model(inputs, training=False)\r\n  File \"/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 961, in __call__\r\n    outputs = call_fn(inputs, *args, **kwargs)\r\n  File \"/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/engine/functional.py\", line 385, in call\r\n    inputs, training=training, mask=mask)\r\n  File \"/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/engine/functional.py\", line 507, in _run_internal_graph\r\n    outputs = node.layer(*args, **kwargs)\r\n  File \"/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 961, in __call__\r\n    outputs = call_fn(inputs, *args, **kwargs)\r\n  File \"/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 302, in wrapper\r\n    return func(*args, **kwargs)\r\n  File \"ncf_keras_main.py\", line 85, in call\r\n    self.add_metric(hr_sum, name=\"hr_sum\", aggregation=\"mean\")\r\n  File \"/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 1678, in add_metric\r\n    metric_obj(value)\r\n  File \"/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/metrics.py\", line 231, in __call__\r\n    replica_local_fn, *args, **kwargs)\r\n  File \"/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/distribute/distributed_training_utils.py\", line 1133, in call_replica_local_fn\r\n    return fn(*args, **kwargs)\r\n  File \"/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/metrics.py\", line 211, in replica_local_fn\r\n    update_op = self.update_state(*args, **kwargs)  # pylint: disable=not-callable\r\n  File \"/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/utils/metrics_utils.py\", line 90, in decorated\r\n    update_op = update_state_fn(*args, **kwargs)\r\n  File \"/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/metrics.py\", line 176, in update_state_fn\r\n    return ag_update_state(*args, **kwargs)\r\n  File \"/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 302, in wrapper\r\n    return func(*args, **kwargs)\r\n  File \"/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/metrics.py\", line 373, in update_state\r\n    update_total_op = self.total.assign_add(value_sum)\r\n  File \"/home/ml/users/jdong25/.conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/distribute/values.py\", line 918, in assign_add\r\n    \"SyncOnReadVariable does not support `assign_add` in \"\r\nValueError: SyncOnReadVariable does not support `assign_add` in cross-replica context when aggregation is set to `tf.VariableAggregation.SUM`.\r\n```", "comments": ["Hi @djdongjin can you please provide a reproducible example? What arguments did you pass when running the script? Thanks\r\n\r\nNote this [section from the docs](https://www.tensorflow.org/api_docs/python/tf/distribute/StrategyExtended): \"We don't allow operations like v.assign_add in a cross-replica context for sync on read variables\" which is essentially the error message you are seeing.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40366\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40366\">No</a>\n", "I hit this error as well, so I created a reproducible example. I also have a [StackOverflow post](https://stackoverflow.com/questions/65413136/tensorflow-cannot-call-tf-keras-model-add-metric-when-tf-distribute-mirrore) about it.\r\n\r\n```py\r\nimport tensorflow as tf\r\n\r\n\r\nclass Sampling(tf.keras.layers.Layer):\r\n    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\r\n\r\n    def call(self, inputs):\r\n        z_mean, z_log_var = inputs\r\n        batch = tf.shape(z_mean)[0]\r\n        dim = tf.shape(z_mean)[1]\r\n        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\r\n        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\r\n\r\n\r\nclass Encoder(tf.keras.layers.Layer):\r\n    \"\"\"Maps MNIST digits to a triplet (z_mean, z_log_var, z).\"\"\"\r\n\r\n    def __init__(self, latent_dim=32, intermediate_dim=64, name=\"encoder\", **kwargs):\r\n        super(Encoder, self).__init__(name=name, **kwargs)\r\n        self.dense_proj = tf.keras.layers.Dense(intermediate_dim, activation=\"relu\")\r\n        self.dense_mean = tf.keras.layers.Dense(latent_dim)\r\n        self.dense_log_var = tf.keras.layers.Dense(latent_dim)\r\n        self.sampling = Sampling()\r\n\r\n    def call(self, inputs):\r\n        x = self.dense_proj(inputs)\r\n        z_mean = self.dense_mean(x)\r\n        z_log_var = self.dense_log_var(x)\r\n        z = self.sampling((z_mean, z_log_var))\r\n        return z_mean, z_log_var, z\r\n\r\n\r\nclass Decoder(tf.keras.layers.Layer):\r\n    \"\"\"Converts z, the encoded digit vector, back into a readable digit.\"\"\"\r\n\r\n    def __init__(self, original_dim, intermediate_dim=64, name=\"decoder\", **kwargs):\r\n        super(Decoder, self).__init__(name=name, **kwargs)\r\n        self.dense_proj = tf.keras.layers.Dense(intermediate_dim, activation=\"relu\")\r\n        self.dense_output = tf.keras.layers.Dense(original_dim, activation=\"sigmoid\")\r\n\r\n    def call(self, inputs):\r\n        x = self.dense_proj(inputs)\r\n        return self.dense_output(x)\r\n\r\n\r\nclass VariationalAutoEncoder(tf.keras.Model):\r\n    \"\"\"Combines the encoder and decoder into an end-to-end model for training.\"\"\"\r\n\r\n    def __init__(self, original_dim, intermediate_dim=64, latent_dim=32, name=\"autoencoder\", **kwargs):\r\n        super(VariationalAutoEncoder, self).__init__(name=name, **kwargs)\r\n        self.original_dim = original_dim\r\n        self.encoder = Encoder(latent_dim=latent_dim, intermediate_dim=intermediate_dim)\r\n        self.decoder = Decoder(original_dim, intermediate_dim=intermediate_dim)\r\n\r\n    def call(self, inputs):\r\n        z_mean, z_log_var, z = self.encoder(inputs)\r\n        reconstructed = self.decoder(z)\r\n        # Add KL divergence regularization loss.\r\n        kl_loss = -0.5 * tf.reduce_mean(\r\n            z_log_var - tf.square(z_mean) - tf.exp(z_log_var) + 1\r\n        )\r\n        self.add_loss(kl_loss)\r\n        self.add_metric([0.], name=\"foo\")\r\n        return reconstructed\r\n\r\n\r\n(x_train, _), _ = tf.keras.datasets.mnist.load_data()\r\nx_train = x_train.reshape(60000, 784).astype(\"float32\") / 255\r\n\r\noriginal_dim = 784\r\n\r\nstrategy = tf.distribute.MirroredStrategy()\r\nwith strategy.scope():\r\n    vae = VariationalAutoEncoder(original_dim, 64, 32)\r\n    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\r\n    vae.compile(optimizer, loss=tf.keras.losses.MeanSquaredError())\r\n\r\nvae.fit(x_train, x_train, epochs=3, batch_size=64)\r\nvae.save(\"vae\")\r\n```\r\n\r\nFor me, if I just remove the `self.add_metric([0.], name=\"foo\")`, then it works. We need our custom metrics though.\r\n\r\nAs for environment, I'm using the Google [AI Platform runtime version 2.3](https://cloud.google.com/ai-platform/training/docs/runtime-version-list#2.3).", "Hi @acarl005, thanks for providing a simple, reproducible example! I took a deeper look at this issue, seems to be a known bug that has been fixed in 2.4. Please [see this gist](https://colab.research.google.com/gist/nikitamaia/b96c8576ff7e6a3f17a8bae1d4fbbcbb/40366.ipynb) that runs without error. You should now be able to export a Keras model trained with a custom metric.\r\n\r\nIf you want to test on AI Platform I think you'll need to use a custom container since the latest runtime version is only 2.3", "Thanks @nikitamaia for the quick response, and for providing the gist. We'll work on upgrading to 2.4.", "This seems to be a problem also with:\r\n`tf.keras.metrics.Mean()`\r\n\r\nUsing TF 2.5.0 and get the same error with MirroredStrategy", "I'm getting this error with tf.keras.metrics.CategoricalAccuracy() (which inherits from Mean) when using MirroredStrategy\r\n\r\nOS Ubuntu 18.04.5\r\nTF 2.4.1\r\nPython 3.8.3\r\nCUDA 11.0\r\n", "I am facing the same issue with Tensorflow 2.7.0  Mirrored Strategy using tf.keras.metrics.mean()", "I am also seeing this issue with Tensorflow 2.7.0 `MirroredStrategy` and `tf.keras.metrics.mean()`"]}, {"number": 40365, "title": "file_hash not validated after downloading in Keras.utils.data_utils.get_file().", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes, but basically excerpted from keras.applications. \r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: \r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b\r\n- Python version: 3.7.3\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n**Describe the current behavior**\r\nThe `file_hash` is checked only when local pre-existing file is found, but not when the file is newly downloaded. \r\n\r\n**Describe the expected behavior**\r\nThe `file_hash` should also be checked once download is complete. \r\n\r\n**Standalone code to reproduce the issue**\r\nAs an example, I take code from `keras.applications` and deliberately have file path and file hash mismatch. In particular, I use the hash for no-top version but provide the path with the full model version. \r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.python.keras.utils import data_utils\r\n\r\nWEIGHTS_PATH_NO_TOP = (\r\n    'https://storage.googleapis.com/tensorflow/keras-applications/'\r\n    'inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels.h5')\r\n\r\nweights_path = data_utils.get_file(\r\n    'inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5',\r\n    WEIGHTS_PATH_NO_TOP,\r\n    cache_subdir='models',\r\n    file_hash='bcbd6486424b2319ff4ef7d526e38f63')\r\n```\r\nIt does not warn about file hash mismatch as it should, and blindly trust the newly downloaded file. \r\n\r\n", "comments": ["Was able to reproduce the issue with [TF v2.2](https://colab.research.google.com/gist/amahendrakar/8676869cc8bf0993532821e0eef093ee/40365.ipynb#scrollTo=2UtD1ZnEXUdr) and [TF-nightly](https://colab.research.google.com/gist/amahendrakar/8a84da6b25cc800cc52ac66deef5a56b/40365-tf-nightly.ipynb). Please find the attached gist. Thanks!", "@yixingfu The issue is fixed in latest TF versions 2.4 and 2.5 and the file_hash is getting validated. Please find the gist [here](https://colab.research.google.com/gist/saikumarchalla/da74f905365ea71973e9da6b05073a5e/untitled84.ipynb).\r\n\r\nClosing the issue since it was resolved.Please feel free to re-open the issue if you have any further queries.Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40365\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40365\">No</a>\n"]}, {"number": 40364, "title": "[INTEL MKL] Enable option to install OpenMPI/Horovod in mkl container", "body": "", "comments": ["All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F40364) for more info**.\n\n<!-- need_author_consent -->", "@googlebot I consent", "@googlebot I consent", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F40364) for more info**.\n\n<!-- ok -->", "Hi @penpornk Thank you for providing feedback. All good suggestions. I have made changes as per your feedback except I was not able to change \"=\" in Dockerfile to \"==\" which gave an error.\r\nPlease review. Thank you."]}, {"number": 40363, "title": "Convert .tflite file to human-readable format", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (or github SHA if from source): 1.15\r\n\r\n-------------------------------------------\r\n\r\nIs there a recommended way to convert a .tflite file into a human-readable format?  I often encounter issues with .tflite models (e.g. poor prediction performance), even though there are no error messages in the TF-->TFL conversion process.  Being able to read the contents of the .tflite file would really help with the debug process.  Thanks.", "comments": ["@mm7721,\r\nCould you please take a look at [this](https://github.com/lutzroeder/netron) tool and let us know if it helps. Thanks!", "Ahhh yes, I use Netron extensively already :)  But it doesn't give quite enough detail, which is why I'm making this request.", "You can use our visualize tool. https://www.tensorflow.org/lite/guide/faq#model_conversion\r\n\r\n```bazel run //tensorflow/lite/tools:visualize model.tflite visualized_model.html```\r\n", "And you can get insights from our benchmark tool as well. https://www.tensorflow.org/lite/performance/benchmarks", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 40362, "title": "Fixing broken links in documentation.", "body": "The all_ops_resolver files were moved in https://github.com/tensorflow/tensorflow/commit/e5dfc3bc38696060922b4d8a04d6e773467b9f08 but not all doc links got updated.", "comments": []}, {"number": 40361, "title": "Bug with keras applications preprocess_input method", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes, attached\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\n- TensorFlow installed from (source or binary): pip installation\r\n- TensorFlow version (use command below): 2.1.1. The bug that lead me to find this out also happened in 1.14.0, 1.15.3, so worth to check them out too.\r\n- Python version: 3.7.7\r\n- CUDA/cuDNN version: 10.1 / 7.6.5\r\n- GPU model and memory: GeForce GTX 1050 Ti\r\n\r\n**Describe the current behavior**\r\n`tf.keras.applications.<model_name>.preprocess_input` behaves inconsistently between numpy arrays and tensorflow tensors, depending on `dtype`.\r\nAlso, there's a difference between working with CPU and GPU in case of tensorflow tensors with dtype `tf.uint8`.\r\n\r\nFor numpy arrays, the below code works for both `uint8` and `float32` dtypes.\r\nHowever, for tensorflow tensors, the below doesn't behave correctly for `uint8` dtype, and behaves differently between GPU and CPU for this dtype.\r\nCurrent output:\r\n```\r\n$ export CUDA_VISIBLE_DEVICES=; python test.py 2> /dev/null\r\nCPU\r\nnumpy, uint8: [[[[ -1.939003 -15.778999 -23.68    ]]]]\r\nnumpy, float32: [[[[ -1.939003 -15.778999 -23.68    ]]]]\r\ntensorflow, uint8: tf.Tensor([[[[255 241 233]]]], shape=(1, 1, 1, 3), dtype=uint8)\r\ntensorflow, float32: tf.Tensor([[[[ -1.939003 -15.778999 -23.68    ]]]], shape=(1, 1, 1, 3), dtype=float32)\r\n\r\n$ export CUDA_VISIBLE_DEVICES=0; python test.py 2> /dev/null\r\nGPU\r\nnumpy, uint8: [[[[ -1.939003 -15.778999 -23.68    ]]]]\r\nnumpy, float32: [[[[ -1.939003 -15.778999 -23.68    ]]]]\r\ntensorflow, uint8: tf.Tensor([[[[102 101 100]]]], shape=(1, 1, 1, 3), dtype=uint8)\r\ntensorflow, float32: tf.Tensor([[[[ -1.939003 -15.778999 -23.68    ]]]], shape=(1, 1, 1, 3), dtype=float32)\r\n```\r\n\r\nThis issue can be traced to `keras_applications.imagenet_utils`'s preprocess_input, which behaves differently for numpy arrays vs. tensorflow tensors, and in case of tensors - doesn't do casting of dtype, unlike in the case of numpy array.\r\n\r\n**Describe the expected behavior**\r\nSame result as numpy array with dtype `float32` for all of the outputs.\r\n\r\n**Standalone code to reproduce the issue**\r\nRun once with `CUDA_VISIBLE_DEVICES=` and once with `CUDA_VISIBLE_DEVICES=0`.\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.applications.resnet50 import preprocess_input\r\n\r\nprint('GPU' if tf.config.list_physical_devices('GPU') else 'CPU')\r\narr = np.array([100, 101, 102], dtype=np.uint8).reshape((1, 1, 1, 3))\r\nprint('numpy, uint8:', preprocess_input(arr))\r\narr = np.array([100, 101, 102], dtype=np.float32).reshape((1, 1, 1, 3))\r\nprint('numpy, float32:', preprocess_input(arr))\r\narr = tf.reshape(tf.constant([100, 101, 102], dtype=tf.uint8), (1, 1, 1, 3))\r\nprint('tensorflow, uint8:', preprocess_input(arr))\r\narr = tf.reshape(tf.constant([100, 101, 102], dtype=tf.float32), (1, 1, 1, 3))\r\nprint('tensorflow, float32:', preprocess_input(arr))\r\n```", "comments": ["I am able to replicate this issue, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/74bbe7061cbb617ff00e3f6b296c03f0/untitled.ipynb)", "Was able to replicate the issue with TF 2.5 in [CPU](https://colab.research.google.com/gist/sushreebarsa/99035248ac1695c2d785e858b79bb6bf/untitled323.ipynb) and [GPU](https://colab.research.google.com/gist/sushreebarsa/071fe6bc00ea58f7a28df8c98edc515d/untitled324.ipynb),please find the gists here for reference ..Thanks!", "Im also having the same problem. \r\n\r\nI see two issues here:\r\n\r\n1. So basically `resnet50.preprocess_input` will change the actual input if the input `x` is numpy array of type float.\r\nIt does not do this for TF tensors or numpy arrays of type int. So this different behaviour can lead to issues downstream when some input arrays are modified in place but sometimes not.\r\n\r\n2. Even if 1 is not an issue (input is not changed) you can still get completely different output for two identical images.\r\n\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.applications.resnet50 import preprocess_input\r\n\r\nimg_array_ints = (np.random.rand(224,224,3)*255).astype(np.uint8)\r\ntensor_ints = tf.convert_to_tensor(img_array_ints)\r\n\r\n# these two arrays below should be the same right? But they are completely different.\r\n# Which means resnet model will give completely different embeddings \r\n# for the same image when first passing through preprocess_input\r\n\r\npreprocess_input(img_array_ints) - preprocess_input(tensor_ints)\r\n\r\n#If working as expected the ^^ should be all zeros\r\n```\r\n\r\nDuplicate issues:\r\n\r\nhttps://github.com/keras-team/keras-applications/issues/128\r\n\r\nhttps://github.com/keras-team/keras-applications/pull/129\r\n\r\nFor those running into the same issue for a quick fix:\r\nINPUT: `img_array = tf.cast(img_array, tf.float32)` before passing to `preprocess_input`.\r\nThe [documentation](https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet50/preprocess_input) does state to pass a float tensor as input.", "Hi There,\n\n This is a stale issue. As you are using an older version of tensorflow, we are checking to see if you still need help on this issue. Please test the issue with the latest TensorFlow (TF2.7 and tf-nightly). If the issue still persists with the newer versions of TF, please feel free to open it in [keras-team/keras](https://github.com/keras-team/keras/issues) repository by providing details about the issue and a standalone code to reproduce the issue. Thanks! \n\n Please note that Keras development has moved to a separate Keras-team/keras repository to focus entirely on only Keras. Thanks! ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40361\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40361\">No</a>\n"]}, {"number": 40360, "title": "same error using tflearn package ==0.3.2 and tenserflow ==1.14", "body": "some error using tflearn package ==0.3.2 and tenserflow ==1.14 \r\n\r\nerror:'tensorflow.python.framework.op_def_registry' has no attribute 'register_op_list'\r\n\r\n_Originally posted by @BV-SS in https://github.com/tensorflow/tensorflow/issues/34762#issuecomment-642140322_", "comments": ["@BV-SS Can you please provide a standalone code to reproduce the issue? You coule use colab or Jupyter notebook. Thanks!", "@jvishnuvardhan running in virtual environment helped. thanks. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40360\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40360\">No</a>\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40360\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40360\">No</a>\n"]}, {"number": 40359, "title": "Seg fault while post quantizing my model", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): OS Linux 18.04.04 LTS\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): python wheel\r\n- TensorFlow version (use command below): 2.2.0-rc4\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:10.1\r\n- GPU model and memory: TitanV , 12 GB\r\n\r\nI am trying to do post training quantization for the EfficientDet-D0 model pre-trained on COCO I got from his repo : https://github.com/google/automl  \r\nDesired quantization is int8 because it needs to be running on a google coral.\r\n\r\nBelow is the code that I use:\r\n\r\n`from PIL import Image\r\nimport numpy as np\r\nexport_dir = \"./savedmodeldir\"\r\n\r\nmodel = tf.saved_model.load(export_dir)\r\n\r\nconcrete_func = model.signatures[tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY]\r\nconcrete_func.inputs[0].set_shape([1, 512, 512, 3])\r\nconverter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])\r\n\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\ndef representative_dataset_gen():\r\n  num_calibration_steps=10\r\n  path_to_img='./img/img.jpg'\r\n  for _ in range(num_calibration_steps):\r\n    # Get sample input data as a numpy array in a method of your choosing.\r\n    im = np.asarray(Image.open(path_to_img).resize((512,512)),dtype=np.uint8)\r\n    im=np.reshape(im, [1,512,512,3])\r\n    with tf.device('/CPU:0'):\r\n      image=tf.convert_to_tensor(im)\r\n    yield [image]\r\nconverter.representative_dataset = representative_dataset_gen\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\r\nconverter.inference_input_type = tf.int8  # or tf.uint8\r\nconverter.inference_output_type = tf.int8  # or tf.uint8\r\n\r\ntflite_quant_model = converter.convert()`\r\n\r\nLink to the savedmodeldir zip file:\r\nhttps://drive.google.com/file/d/1Hsbox0LRm6z9FecnobMP7YK7ZJyFjknt/view?usp=sharing\r\n\r\nThe output I get while running the code:\r\n\r\nWARNING:tensorflow:Importing a function (MetaGraph import) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:Importing a function (MetaGraph import) with ops with custom gradients. Will likely fail if a gradient is requested.\r\nWARNING:tensorflow:From /home/shrey/.local/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nIf using Keras pass *_constraint arguments to layers.\r\nWARNING:tensorflow:Issue encountered when serializing global_step.\r\nType is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\r\nto_proto not supported in EAGER mode.\r\nWARNING:tensorflow:Issue encountered when serializing moving_average_variables.\r\nType is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\r\nto_proto not supported in EAGER mode.\r\nWARNING:tensorflow:Issue encountered when serializing variables.\r\nType is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\r\nto_proto not supported in EAGER mode.\r\nWARNING:tensorflow:Issue encountered when serializing trainable_variables.\r\nType is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\r\nto_proto not supported in EAGER mode.\r\n2020-06-10 11:40:38.281380: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\r\n2020-06-10 11:40:38.281495: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\r\n2020-06-10 11:40:38.432064: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: graph_to_optimize\r\n2020-06-10 11:40:38.432098: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: Graph size after: 3786 nodes (0), 3573 edges (0), time = 21.187ms.\r\n2020-06-10 11:40:38.432102: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: Graph size after: 3786 nodes (0), 3573 edges (0), time = 26.002ms.\r\n2020-06-10 11:40:38.432105: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: __inference_TensorArrayV2Write_cond_true_136_1822\r\n2020-06-10 11:40:38.432109: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-06-10 11:40:38.432112: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-06-10 11:40:38.432115: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: __inference_cond_png_true_83_1595\r\n2020-06-10 11:40:38.432118: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-06-10 11:40:38.432121: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-06-10 11:40:38.432124: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: __inference_while_body_23_4372\r\n2020-06-10 11:40:38.432128: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: Graph size after: 38 nodes (0), 41 edges (0), time = 0.721ms.\r\n2020-06-10 11:40:38.432131: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: Graph size after: 38 nodes (0), 41 edges (0), time = 0.751ms.\r\n2020-06-10 11:40:38.432134: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: __inference_TensorArrayV2Write_cond_false_137_1473\r\n2020-06-10 11:40:38.432137: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-06-10 11:40:38.432140: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-06-10 11:40:38.432143: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: __inference_cond_gif_true_93_2677\r\n2020-06-10 11:40:38.432148: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-06-10 11:40:38.432151: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-06-10 11:40:38.432154: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: __inference_cond_gif_false_94_4320\r\n2020-06-10 11:40:38.432158: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-06-10 11:40:38.432161: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-06-10 11:40:38.432185: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: __inference_decode_image_cond_jpeg_true_65_2555\r\n2020-06-10 11:40:38.432190: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-06-10 11:40:38.432194: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-06-10 11:40:38.432198: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: __inference_decode_image_cond_jpeg_false_66_4339\r\n2020-06-10 11:40:38.432202: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: Graph size after: 10 nodes (0), 10 edges (0), time = 0.32ms.\r\n2020-06-10 11:40:38.432210: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: Graph size after: 10 nodes (0), 10 edges (0), time = 0.316ms.\r\n2020-06-10 11:40:38.432213: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: __inference_while_cond_22_6546\r\n2020-06-10 11:40:38.432219: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-06-10 11:40:38.432222: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-06-10 11:40:38.432227: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: __inference_cond_png_false_84_4328\r\n2020-06-10 11:40:38.432230: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: Graph size after: 7 nodes (0), 6 edges (0), time = 0.234ms.\r\n2020-06-10 11:40:38.432234: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: Graph size after: 7 nodes (0), 6 edges (0), time = 0.248ms.\r\n2020-06-10 11:40:40.776624: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\r\n2020-06-10 11:40:40.776752: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\r\n2020-06-10 11:40:41.366677: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: graph_to_optimize\r\n2020-06-10 11:40:41.366709: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 2739 nodes (-1047), 2330 edges (-1243), time = 481.837ms.\r\n2020-06-10 11:40:41.366713: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 2739 nodes (0), 2330 edges (0), time = 49.056ms.\r\nAborted (core dumped)\r\n\r\n\r\n", "comments": ["@shreymohan,\r\nOn running the code I am facing a different error stating `error: 'tfl.strided_slice' op operand #0 must be tensor of 32-bit float or 32-bit integer or 64-bit integer or 8-bit integer or QI8 type or QUI8 type or 1-bit integer values, but got 'tensor<1x512x512x3x!tf.quint8>'`. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/1ca7851ea1332eac3c8d3142a0fa4842/40359.ipynb). \r\n\r\nCould you please check if you are facing the same error in a virtual environment. Thanks!", "This is weird. Would you suggest trying tf-nightly instead? I have seen people pulling off their conversions using that tf version.", "Was able to reproduce the issue, runtime crashes on running the code with TF-nightly. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/89e524b36c99b36ae2157c55fc81aab0/40359-tf-nightly.ipynb). Thanks!", "@amahendrakar  Hey! thanks for reaching out! Any suggestions on how to solve this issue?", "@shreymohan,\r\n\r\nI tried reproducing the code in TF 2.6.0 and it was throwing RuntimeError  `Failed to quantize: <unknown>:0: error: loc(\"strided_slice_21\"): 'tfl.strided_slice' op quantization parameters violate the same scale constraint: !quant.uniform<i8:f32, 0.81405168771743774:-128> vs. !quant.uniform<i8:f32, 1.4241064786911011:-128>`, whereas in tf-nightly i.e `2.8.0-dev20211020`, it ran successfully. please take a look at the [gist here](https://colab.research.google.com/gist/sanatmpa1/30338cfaba1ab7fb200dccc5b5ac51fd/40359-tf-nightly.ipynb)", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40359\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40359\">No</a>\n"]}, {"number": 40358, "title": "clang error: the clang compiler does not support '-march=native' [TF Lite, Android ARM]", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.14.6\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no\r\n- TensorFlow installed from (source or binary): trying to build\r\n- TensorFlow version: 2.2.0\r\n- Python version: 2.7\r\n- Installed using virtualenv? pip? conda?: not installed\r\n- Bazel version (if compiling from source): 2.0.0\r\n- GCC/Compiler version (if compiling from source): not sure, I'm cross-compiling\r\n- CUDA/cuDNN version: none\r\n- GPU model and memory: none\r\n\r\n**Describe the problem**\r\n\r\nI'm trying to cross-compile TF Lite to Android. I want to create a cc_library that depends on //tensorflow/lite:framework, but it fails for ARM with the message:  \r\n\r\n> clang: error: the clang compiler does not support '-march=native'\r\n\r\nI can reproduce this in a clean TF repo with lite:framework itself,\r\n\r\n```\r\nbazel build -c opt --config=opt --config=android_arm64 --cxxopt=--std=c++11 --jobs=1 -s //tensorflow/lite:framework\r\n```\r\n\r\nIt works fine for x86/x64 targets. It also works fine without --config=opt, which is adding the march=native flag. This `--config=opt` is advertised in many places of the source code, it's even configured in ./configure, so it's quite confusing to see that it does not work with common architectures.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nSee above.\r\n\r\n**Any other info / logs**\r\n\r\n```\r\nSUBCOMMAND: # //tensorflow/lite:framework [action 'Compiling tensorflow/lite/core/subgraph.cc', configuration: 45cc65458d2ef84231c73814ce4897ab5307bd5feffcfb2bfb3a1cf29f72c29c]\r\n(cd /private/var/tmp/_bazel_natario/9e86fd2d24b8ec3357d15a3569d12c31/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    ANDROID_BUILD_TOOLS_VERSION=29.0.2 \\\r\n    ANDROID_NDK_API_LEVEL=18 \\\r\n    ANDROID_NDK_HOME=/Users/natario/Library/Android/sdk/ndk/20.1.5948944 \\\r\n    ANDROID_SDK_API_LEVEL=29 \\\r\n    ANDROID_SDK_HOME=/Users/natario/library/Android/Sdk \\\r\n    PATH=/Library/Frameworks/Python.framework/Versions/3.7/bin:/Users/natario/.rvm/gems/ruby-2.6.3/bin:/Users/natario/.rvm/gems/ruby-2.6.3@global/bin:/Users/natario/.rvm/rubies/ruby-2.6.3/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Users/natario/Library/Android/sdk/emulator:/Users/natario/Library/Android/sdk/tools:/Users/natario/Library/Android/sdk/tools/bin:/Users/natario/Library/Android/sdk/platform-tools:/Users/natario/bin:/Users/natario/.rvm/bin \\\r\n    PWD=/proc/self/cwd \\\r\n    PYTHON_BIN_PATH=/usr/bin/python \\\r\n    PYTHON_LIB_PATH=/Library/Python/2.7/site-packages \\\r\n    TF2_BEHAVIOR=1 \\\r\n    TF_CONFIGURE_IOS=0 \\\r\n    TF_ENABLE_XLA=1 \\\r\n  external/androidndk/ndk/toolchains/llvm/prebuilt/darwin-x86_64/bin/clang -gcc-toolchain external/androidndk/ndk/toolchains/aarch64-linux-android-4.9/prebuilt/darwin-x86_64 -target aarch64-none-linux-android -fpic -isystemexternal/androidndk/ndk/sysroot/usr/include/aarch64-linux-android '-D__ANDROID_API__=18' -no-canonical-prefixes -Wno-invalid-command-line-argument -Wno-unused-command-line-argument -funwind-tables -fstack-protector-strong -fno-addrsig '-Werror=return-type' '-Werror=int-to-pointer-cast' '-Werror=pointer-to-int-cast' '-Werror=implicit-function-declaration' -O2 -g -DNDEBUG -MD -MF bazel-out/arm64-v8a-opt/bin/tensorflow/lite/_objs/framework/subgraph.pic.d '-frandom-seed=bazel-out/arm64-v8a-opt/bin/tensorflow/lite/_objs/framework/subgraph.pic.o' -fPIC -D__CLANG_SUPPORT_DYN_ANNOTATION__ -iquote . -iquote bazel-out/arm64-v8a-opt/bin -iquote external/flatbuffers -iquote bazel-out/arm64-v8a-opt/bin/external/flatbuffers -iquote external/com_google_absl -iquote bazel-out/arm64-v8a-opt/bin/external/com_google_absl -Ibazel-out/arm64-v8a-opt/bin/external/flatbuffers/_virtual_includes/runtime_cc -Ibazel-out/arm64-v8a-opt/bin/external/flatbuffers/_virtual_includes/flatbuffers -Ibazel-out/arm64-v8a-opt/bin/external/flatbuffers/src/_virtual_includes/flatbuffers -isystem tensorflow/lite/schema -isystem bazel-out/arm64-v8a-opt/bin/tensorflow/lite/schema -w '-march=native' -Wno-sign-compare '-std=c++14' '--std=c++11' -DFARMHASH_NO_CXX_STRING -Wno-sign-compare -O3 -ffunction-sections -fdata-sections -fno-exceptions -Wall -Wno-comment -Wno-extern-c-compat '--sysroot=external/androidndk/ndk/platforms/android-28/arch-arm64' -isystem external/androidndk/ndk/sources/cxx-stl/llvm-libc++/include -isystem external/androidndk/ndk/sources/cxx-stl/llvm-libc++abi/include -isystem external/androidndk/ndk/sources/android/support/include -isystemexternal/androidndk/ndk/sysroot/usr/include -c tensorflow/lite/core/subgraph.cc -o bazel-out/arm64-v8a-opt/bin/tensorflow/lite/_objs/framework/subgraph.pic.o)\r\nERROR: /Users/natario/Projects/XXX/tensorflow/tensorflow/lite/BUILD:204:1: C++ compilation of rule '//tensorflow/lite:framework' failed (Exit 1)\r\nclang: error: the clang compiler does not support '-march=native'\r\n```\r\n", "comments": ["Please remove \"--config=opt\" option.\r\n\r\n```\r\nbazel build -c opt --config=android_arm64 --cxxopt=--std=c++11 --jobs=1 -s //tensorflow/lite:framework\r\n```", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40358\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40358\">No</a>\n"]}, {"number": 40357, "title": "[TF Lite] TfLiteGpuDelegate Init: CONV_2D: Unsupported data type for float32 tensor", "body": "**System information**\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04\r\n- TensorFlow installed from (source or binary): `pip install tensorflow`\r\n- TensorFlow version (or github SHA if from source): 2.2.0\r\n- TensorFlow Lite version: `org.tensorflow:tensorflow-lite:2.2.0`, `org.tensorflow:tensorflow-lite-gpu:2.2.0`\r\n\r\n**Command used to run the converter or code if you\u2019re using the Python API**\r\nThe code used to run the converter can be found in this notebook: https://github.com/franksacco/where-is-wally/blob/master/converter.ipynb.\r\n\r\nIn particular, the part of interest is:\r\n```python\r\nfrom tensorflow import lite\r\n\r\nconverter = lite.TFLiteConverter.from_keras_model(model)\r\nconverter.optimizations = [lite.Optimize.DEFAULT]\r\ntflite_model = converter.convert()\r\n\r\nwith open('models/unet_v2.f1lo-b14-e60-lr0.001.44.optimized.tflite', 'wb') as f:\r\n    f.write(tflite_model)\r\n```\r\n\r\n**The output from the converter invocation**\r\n\r\nThe optimized TFLite model is successfully generated.\r\n\r\n**Also, please include a link to the saved model or GraphDef**\r\n\r\n- Trained model: https://github.com/franksacco/where-is-wally/raw/master/models/unet_v2.f1lo-b14-e60-lr0.001.44.hdf5\r\n- Optimized TFLite Model: https://github.com/franksacco/where-is-wally/raw/master/models/unet_v2.f1lo-b14-e60-lr0.001.44.optimized.tflite\r\n\r\nThe model uses [this implementation](https://www.depends-on-the-definition.com/unet-keras-segmenting-images/) of the [U-Net](https://arxiv.org/pdf/1505.04597.pdf) and takes a 256x256x3 image and outputs a 256x256x1 grayscale mask.\r\n\r\n**Failure details**\r\n\r\nThe model without optimizations works perfectly.\\\r\nThe model with optimizations works correctly when executed on the CPU.\r\n\r\nHowever, when I try to initialize the TFLite interpreter with the GPU delegate using the following code, I get the error `java.lang.IllegalArgumentException: Internal error: Failed to apply delegate: TfLiteGpuDelegate Init: CONV_2D: Unsupported data type for float32 tensor`.\r\n```java\r\nMappedByteBuffer model = FileUtil.loadMappedFile(\r\n    activity, \"unet_v2.f1lo-b14-e60-lr0.001.44.optimized.tflite\"\r\n);\r\n\r\nInterpreter.Options options = new Interpreter.Options();\r\noptions.addDelegate(new GpuDelegate());\r\n\r\nInterpreter interpreter = new Interpreter(model, options);\r\n```\r\n\r\n**Any other info / logs**\r\n\r\nTraceback of the exception:\r\n```\r\nI/tflite: Created TensorFlow Lite delegate for GPU.\r\nI/tflite: Initialized TensorFlow Lite runtime.\r\nW/System.err: java.lang.IllegalArgumentException: Internal error: Failed to apply delegate: TfLiteGpuDelegate Init: CONV_2D: Unsupported data type for float32 tensor\r\nW/System.err: TfLiteGpuDelegate Prepare: delegate is not initialized\r\n    Node number 36 (TfLiteGpuDelegateV2) failed to prepare.\r\n    Restored previous execution plan after delegate application failure.\r\nW/System.err:     at org.tensorflow.lite.NativeInterpreterWrapper.applyDelegate(Native Method)\r\n        at org.tensorflow.lite.NativeInterpreterWrapper.applyDelegates(NativeInterpreterWrapper.java:318)\r\nW/System.err:     at org.tensorflow.lite.NativeInterpreterWrapper.init(NativeInterpreterWrapper.java:82)\r\n        at org.tensorflow.lite.NativeInterpreterWrapper.<init>(NativeInterpreterWrapper.java:63)\r\n        at org.tensorflow.lite.Interpreter.<init>(Interpreter.java:237)\r\n        at it.unipr.advmobdev.whereiswally.ModelExecutor.loadInterpreter(ModelExecutor.java:245)\r\n        at it.unipr.advmobdev.whereiswally.ModelExecutor.run(ModelExecutor.java:160)\r\n```\r\n\r\n---\r\n\r\nI noticed that in [this commit](https://github.com/tensorflow/tensorflow/commit/062cf92d066771ab3cf2910f125b0209c305eb2b) was added the [`setQuantizedModelsAllowed()`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/delegates/gpu/java/src/main/java/org/tensorflow/lite/gpu/GpuDelegate.java#L66-L76) method in the `GpuDelegate.Options` class. This method is not available in my current version of the library.\r\n\r\nIs it possible that the optimized / quantized model cannot be run with the GPU delegate? I was unable to find this information in the documentation.", "comments": ["Could you try nightly? It seems that your model works well with GPU on master.\r\n```\r\ndependencies {\r\n    implementation 'org.tensorflow:tensorflow-lite:0.0.0-nightly'\r\n    implementation 'org.tensorflow:tensorflow-lite-gpu:0.0.0-nightly'\r\n}\r\n```", "I changed the version of TensorFlow Lite dependencies, now they are:\r\n- `org.tensorflow:tensorflow-lite:0.0.0-nightly`\r\n- `org.tensorflow:tensorflow-lite-gpu:0.0.0-nightly`\r\n\r\nWith this update, the model works properly with the GPU but performance is worse: latency with GPU is remained pretty much the same but the time required on the CPU is more than twenty times greater than before.\r\n\r\nI report you the latency measured for the execution of the model on a 256x256 image.\r\n\r\n| Model | TFLite version | CPU | GPU |\r\n| :---: | :---: | :---: | :---: |\r\n| Normal (8.6 MB) | `2.2.0` | 1.790 s | 0.404 s |\r\n| Optimized (3.4 MB) | `2.2.0` | 1.023 s | *Not working* |\r\n| Normal | `0.0.0-nightly` | 37.828 s | 0.412 s |\r\n| Optimized | `0.0.0-nightly` | 27.643 s | 0.423 s |\r\n\r\nWhy isn't the latency of the optimized model running on GPU better than that of the normal model? And most importantly, why is CPU latency with the `0.0.0-nightly` version worse?", "You can use benchmark tool with \"--enable_op_profiling=true\" to check how it's executed.\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/tools/benchmark\r\nIt seems that there is a regression on nightly. (I didn't see it when I tested)\r\n\r\nWhat you said optimized model should be integer quantization.\r\nhttps://www.tensorflow.org/lite/performance/post_training_quantization\r\nInteger quantization is mainly for CPU since CPU calculates integer better than float number. When you run it on GPU, it converts integer to float internally. So there is no much benefit except the size of model.", "Thank you for your answer and sorry for the late reply.\r\n\r\n> Integer quantization is mainly for CPU since CPU calculates integer better than float number. When you run it on GPU, it converts integer to float internally. So there is no much benefit except the size of model.\r\n\r\nI didn't know this detail. From now, I won't execute an optimized model on a GPU.\r\nSince I think the problem is solved, I close the issue.\r\n\r\nPS: I think I will use the normal model with the `2.2.0` version of TFLite in my application because I obtained better results with it.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40357\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40357\">No</a>\n"]}, {"number": 40356, "title": "TensorFlow Lite Post-training Integer Quantization predicts identical value always", "body": "**System information**\r\nOS Linux 18.04.04 LTS\r\nTensorFLow nightly 2.3.0-dev20200601\r\nCPU Intel Core i7-855OU\r\nResNet-50 V2\r\n\r\nHi,\r\n\r\nI have been experiencing issues converting ResNet-50 V2 from SavedModel to TensorFlow Lite Post-Training Integer Quantization. I have previously converted it to Tf Lite post-training dynamic range, post-training float16 quantization, and tf lite \"normal\". In all of those cases, it worked and performed as expected. Validation accuracy is 64.15%\r\nI tried the float32 fallback option, the int8, and the uint8 option with identical issues. The conversion works fine but then when during test phase it predicts over and over again the same value.  Moreover, speed is 6s per inference whilst for the other versions is around 40 ms per inference. I also compiled the model for EdgeTPU. The conversion works but then again some issue, only one value is predicted for each image.\r\n\r\nPlease find below a link to a google folder with dataset, savedmodel, conversion code, and converted model. \r\n\r\n\r\nhttps://drive.google.com/drive/folders/11XruNeJzdIm9DTn7FnuIWYaSalqg2F0B?usp=sharing.\r\n\r\n\r\n", "comments": ["@stefano555 Could you please let us know if this is still an issue in TF v2.6.0 ? Please do refer to the [post-training integer quantization](https://www.tensorflow.org/lite/performance/post_training_integer_quant) and let us know if it helps? Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40356\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40356\">No</a>\n"]}, {"number": 40355, "title": "//tensorflow/python/tpu:tpu_test and //tensorflow/python/tpu:datasets_test test case failure", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n**N/A**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n**N/A**\r\n- TensorFlow installed from (source or binary): **both source and binary**\r\n- TensorFlow version (use command below): **v2.2.0-0-g2b96f3662b 2.2.0**\r\n- Python version: **3.6.9**\r\n- Bazel version (if compiling from source): **2.0.0**\r\n- GCC/Compiler version (if compiling from source): **7.5.0**\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\nTest case failure for both test. \r\nFor `//tensorflow/python/tpu:datasets_test`, it fails with:\r\n- RuntimeError: /job:coordinator/replica:0/task:0/device:CPU:0 unknown device.\r\n- See test log for datasets_test [test.log](https://github.com/tensorflow/tensorflow/files/4759420/test.log)\r\n\r\nFor `//tensorflow/python/tpu:tpu_test`, it fails with:\r\n- RuntimeError: Attempting to capture an EagerTensor without building a function.\r\n- See test log for tpu_test [test.log](https://github.com/tensorflow/tensorflow/files/4759392/test.log)\r\n\r\n\r\n**Describe the expected behavior**\r\nBoth test cases should pass. \r\n\r\n**Standalone code to reproduce the issue**\r\n\r\nFor `tpu_test`, I copied the test case into [here](https://colab.research.google.com/drive/1aC8gfkgDfMCbS11JBGxuLFVVwkumSvka?usp=sharing)\r\n\r\nFor `datasets_test`, I copied a portion of the test (till the code section that triggers error as shown in the test log) [here](https://colab.research.google.com/drive/1V97nYdLkzxrJ2QI9g-OmzkIz-lA0fnoK?usp=sharing)\r\n\r\nYou can also run this via bazel test (with `no_oss` tag removed) if you build TensorFlow from source.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\nThe test logs have been attached to the `current behaviour` above.  I think there are also two things worth to note\r\n- Both test cases can pass when eager execution is disabled (via `ops.disable_eager_execution()`), https://github.com/tensorflow/tensorflow/issues/33747 is a different error but could be related. I learned disabling eager execution from there. \r\n- When looking into `datasets_test`, the `unknown device` failure was due to a function call of `LookupDevice`, looks like the device for the context is not in `device_map_`. see below:\r\n```\r\n(gdb) p device_map_\r\n$8 = std::unordered_map with 8 elements = {[{static npos = 18446744073709551615, static kMaxSize = 9223372036854775807, ptr_ = 0x36f3234 \"XLA_CPU:0\", length_ = 9}] = 0x374f740, [{\r\n    static npos = 18446744073709551615, static kMaxSize = 9223372036854775807, ptr_ = 0x36f3223 \"/device:XLA_CPU:0XLA_CPU:0\", length_ = 17}] = 0x374f740, [{static npos = 18446744073709551615,\r\n    static kMaxSize = 9223372036854775807, ptr_ = 0x36f31ec \"/job:localhost/replica:0/task:0/cpu:0/device:CPU:0CPU:0/device:XLA_CPU:0XLA_CPU:0\", length_ = 37}] = 0x1b88f10, [{\r\n    static npos = 18446744073709551615, static kMaxSize = 9223372036854775807, ptr_ = 0x36f3211 \"/device:CPU:0CPU:0/device:XLA_CPU:0XLA_CPU:0\", length_ = 13}] = 0x1b88f10, [{\r\n    static npos = 18446744073709551615, static kMaxSize = 9223372036854775807,\r\n    ptr_ = 0x36f31c0 \"/job:localhost/replica:0/task:0/device:CPU:0/job:localhost/replica:0/task:0/cpu:0/device:CPU:0CPU:0/device:XLA_CPU:0XLA_CPU:0\", length_ = 44}] = 0x1b88f10, [{\r\n    static npos = 18446744073709551615, static kMaxSize = 9223372036854775807, ptr_ = 0x36f321e \"CPU:0/device:XLA_CPU:0XLA_CPU:0\", length_ = 5}] = 0x1b88f10, [{static npos = 18446744073709551615,\r\n    static kMaxSize = 9223372036854775807, ptr_ = 0x3754ad0 \"/job:localhost/replica:0/task:0/device:XLA_CPU:0\", length_ = 48}] = 0x374f740, [{static npos = 18446744073709551615,\r\n    static kMaxSize = 9223372036854775807, ptr_ = 0x3754b10 \"/job:localhost/replica:0/task:0/xla_cpu:0\", length_ = 41}] = 0x374f740}\r\n\r\n(gdb) p name\r\n$9 = {static npos = 18446744073709551615, static kMaxSize = 9223372036854775807, ptr_ = 0x7fffc2f3e300 \"/job:coordinator/replica:0/task:0/device:CPU:0\", length_ = 46}\r\n\r\n2       breakpoint     keep y   0x00007fffd0e10665 in tensorflow::StaticDeviceMgr::LookupDevice(absl::string_view, tensorflow::Device**) const at tensorflow/core/common_runtime/device_mgr.cc:112\r\n        breakpoint already hit 1 time\r\n```\r\n\r\n\r\nThanks,\r\nRuixin", "comments": ["@ruixin-bao\r\nPlease provide with simple standalone code for us to replicate the issue faced.", "@Saduf2019,\r\n\r\nHi, maybe you miss the colab link I shared above? Under **Standalone code to reproduce the issue**.\r\n\r\nFor `tpu_test`, it is https://colab.research.google.com/drive/1aC8gfkgDfMCbS11JBGxuLFVVwkumSvka?usp=sharing\r\n\r\nFor `datasets_test`, it is\r\nhttps://colab.research.google.com/drive/1V97nYdLkzxrJ2QI9g-OmzkIz-lA0fnoK?usp=sharing\r\n", "I am able to replicate the issue, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/371fd98344a1f5bc91fbe1f56a0ac709/untitled231.ipynb), for [dataset](https://colab.research.google.com/gist/Saduf2019/38dc956a07304844e5a5dea39555c5c0/untitled231.ipynb)", "These two tests are actually explicitly disabled in open source, hence the `no_oss` tags.\r\n\r\nIn datasets_test.py, the failing test `testArbitraryReaderFuncFromDatasetGenerator` fails because the Cloud TPU environment does not support generator-based datasets that runs on the TPU workers.\r\n\r\nI have not looked into why the tpu_test.py fails, but I assume it would be for a similar reason.", "Hi,\r\n@frankchn, thank you for the information.\r\n\r\n> These two tests are actually explicitly disabled in open source, hence the no_oss tags.\r\n\r\nWondering if you mind elaborating a bit further? I was building tensorflow from source on both s390x and intel (so I can use intel results as reference), and was running the entire test suite. Specifically, I am wondering the following:\r\n- seems like tests with `no_oss` tag is not too important? If I build tensorflow from source to run tests locally and see tests with `no_oss` tag fail, is it safe to ignore them?\r\n- what would be the recommended `test_tag_filters` if I want to run the complete test suite. I originally used `--test_tag_filters=-gpu,-benchmark-test,-v1only`, but seems like `-no_oss`  should be added  to `test_tag_filters` as well?\r\n\r\n> In datasets_test.py, the failing test testArbitraryReaderFuncFromDatasetGenerator fails because the Cloud TPU environment does not support generator-based datasets that runs on the TPU workers.\r\n\r\nThanks for the explanation.\r\n\r\nBest,\r\nRuixin\r\n\r\n\r\n\r\n", "Yes, tests with `no_oss` means that the test may fail or timeout in the open source build for one reason or another, so it should be safe to ignore those.\r\n\r\nYou may want to look at https://github.com/tensorflow/tensorflow/blob/master/configure.py#L1173 to see what tags we apply. Looks like you might want `-oss_serial` in addition to `-no_oss`", "Thank you for your help and clarification. I think I got the information I needed, will close this issue :).", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40355\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40355\">No</a>\n"]}, {"number": 40354, "title": "Symbol file not loaded when I use C API", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 x64\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: r1.15.0\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source): 0.24.1\r\n- GCC/Compiler version (if compiling from source): VS 2019 x64\r\n\r\nHello, here are two questions.\r\n1. When I use C API downloaded from https://www.tensorflow.org/install/lang_c. When I run my project, VS 2019 shows \"Symbol file not loaded\". Later I user tensorflow_cc.dll, it shows the same error.\r\nI use CMake x64-Release settings.\r\n```\r\n'TestTensorflow.exe' (Win32): Loaded 'D:\\Visual Studio 2019\\repos\\TestTensorflow\\out\\build\\x64-Release\\TestTensorflow\\tensorflow_cc.dll'. Module was built without symbols.\r\nException thrown at 0x00007FFDDA4F3804 (tensorflow_cc.dll) in TestTensorflow.exe: 0xC0000005: Access violation reading location 0x0000000000000000.\r\n```\r\n2. When I use C++ API compiled from source, it shows \"cannot open source file 'google/protobuf/xxxx'\"\r\nDoes it mean I need to install protobuf?\r\nI compile it using\r\n```\r\nbazel build //tensorflow:tensorflow_cc.dll //tensorflow:tensorflow_cc_dll_import_lib //tensorflow:install_headers\r\n```\r\nThen I copy tensorflow_cc.dll, tensorflow_cc.lib, include/ dir in the bazel-out directory.\r\n\r\nThanks for your help.", "comments": ["CMake is not supported for building TF, recommend using Bazel.", "> CMake is not supported for building TF, recommend using Bazel.\r\n\r\nNow I can use C++ API. But I still can't use C API, which is downloaded from https://www.tensorflow.org/install/lang_c. VS shows \"Symbol file not loaded\"\r\n```\r\n'TestTensorflow.exe' (Win32): Loaded 'D:\\Visual Studio 2019\\repos\\TestTensorflow\\out\\build\\x64-Release\\TestTensorflow\\tensorflow.dll'. Module was built without symbols.\r\nException thrown at 0x00007FFDDA4F3804 (tensorflow_cc.dll) in TestTensorflow.exe: 0xC0000005: Access violation reading location 0x0000000000000000.\r\n```\r\nHere I didn't use Cmake to build TF. I just create a CMake project to use TF C library.\r\nHere's settings in CMakeLists.txt\r\n```\r\ninclude_directories(\"D:/libtensorflow-cpu-windows-x86_64-1.15.0/include\")\r\nlink_directories(\"D:/libtensorflow-cpu-windows-x86_64-1.15.0/lib\")\r\n\r\ntarget_link_libraries(TestTensorflow\r\n\ttensorflow\r\n\t# other opencv lib\r\n)\r\n```\r\nWhen code goes to TF_SessionRun(), it cause an error\"Symbol file not loaded\".", "Can you try again with the latest Libtensorflow C nightly or stable packages from here https://www.tensorflow.org/install/lang_c#nightly_libtensorflow_c_packages and let us know the outcome. Thanks! ", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40354\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40354\">No</a>\n"]}, {"number": 40353, "title": "Windows 10 (No GPU): ImportError: DLL load failed: The specified module could not be found. ", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:N/A\r\n- TensorFlow installed from (source or binary): pip install\r\n- TensorFlow version: 2.2.0\r\n- Python version: 3.7.7\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n\r\n\r\n**Describe the problem**\r\nI have had this error for quite a few times now. Initially I faced the same problem on python version 3.8.2 and after downgrading to python 3.7.7, the same problem persists.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n```bash\r\nPS C:\\Users\\Dwij>python\r\n\r\nPython 3.7.7 (tags/v3.7.7:d7c567b08f, Mar 10 2020, 10:41:24) [MSC v.1900 64 bit (AMD64)] on win32\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\n```\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n```bash\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Dwij\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Dwij\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Dwij\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\Dwij\\AppData\\Local\\Programs\\Python\\Python37\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\Dwij\\AppData\\Local\\Programs\\Python\\Python37\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Users\\Dwij\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\__init__.py\", line 41, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"C:\\Users\\Dwij\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 50, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\Dwij\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 69, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\Dwij\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Dwij\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Dwij\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\Dwij\\AppData\\Local\\Programs\\Python\\Python37\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\Dwij\\AppData\\Local\\Programs\\Python\\Python37\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n```", "comments": ["From the template it looks like you are installing **TensorFlow** (TF) prebuilt binaries:\n   * For TF-GPU - See point 1\n   * For TF-CPU - See point 2\n-----------------------------------------------------------------------------------------------\n**1. Installing **TensorFlow-GPU** (TF) prebuilt binaries**\n\nMake sure you are using compatible TF and CUDA versions. Please refer following TF version and CUDA version compatibility table.\n| TF  | CUDA |\n| :-------------: | :-------------: |\n| 2.1.0 - 2.2.0  | 10.1 |\n| 1.13.1 - 2.0  | 10.0  |\n| 1.5.0 - 1.12.0 | 9.0 |\n\n  * If you have above configuration and using _**Windows**_ platform -\n    * Try adding the CUDA, CUPTI, and cuDNN installation directories to the %PATH% environment variable.\n    * Refer [windows setup guide](https://www.tensorflow.org/install/gpu#windows_setup).\n  * If you have above configuration and using _**Ubuntu/Linux**_ platform -\n    * Try adding the CUDA, CUPTI, and cuDNN installation directories to the $LD_LIBRARY_PATH environment variable.\n    * Refer [linux setup guide](https://www.tensorflow.org/install/gpu#linux_setup).\n  * If error still persists then, apparently your CPU model does not support AVX instruction sets.\n    * Refer [hardware requirements](https://www.tensorflow.org/install/pip#hardware-requirements).\n\n-----------------------------------------------------------------------------------------------\n**2. Installing **TensorFlow** (TF) CPU prebuilt binaries**\n\n*TensorFlow release binaries version 1.6 and higher are prebuilt with AVX instruction sets.*\n\nTherefore on any CPU that does not have these instruction sets, either CPU or GPU version of TF will fail to load.\nApparently, your CPU model does not support AVX instruction sets. You can still use TensorFlow with the alternatives given below:\n\n   * Try Google Colab to use TensorFlow.\n      * The easiest way to use TF will be to switch to [google colab](https://colab.sandbox.google.com/notebooks/welcome.ipynb#recent=true). You get pre-installed latest stable TF version. Also you can use ```pip install```  to install any other preferred TF version.\n      * It has an added advantage since you can you easily switch to different hardware accelerators (cpu, gpu, tpu) as per the task.\n      * All you need is a good internet connection and you are all set.\n   * Try to build TF from sources by changing CPU optimization flags.\n\n*Please let us know if this helps.*\n", "I use Intel\u00ae Core\u2122 i7-7500U CPU and it supports Intel AVX2 instruction sets.", "I uninstalled tensorflow using,\r\n```bash\r\npip uninstall tensorflow\r\n```\r\n\r\nAnd reinstalled using conda and now it works.\r\n```bash\r\nconda install tensorflow\r\n```", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40353\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40353\">No</a>\n"]}, {"number": 40352, "title": "error with \"from tensorflow.keras.layers import Dense\"", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): \r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Dell laptop\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version: 2.0\r\n- Python version: 3.8\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source): n/a\r\n- GCC/Compiler version (if compiling from source): n/a\r\n- CUDA/cuDNN version: none\r\n- GPU model and memory: Intel(R) HD Graphics 1696MB\r\n\r\n\r\nI want to use keras in jupyterlab. The installation of tensorflow seemed to have worked fine, no error message occured using the anaconda powershell prompt and pip. When typing \"import tensorflow as tf\" in jupyter lab no error occurs. However, when I enter \"from tensorflow.keras.layers import Dense\" I get a long list of errors with repeated instances of \"dll not loading\" occuring, as shown in the error log below. I can't figure out how to fix this. My CPU is the Intel(R) Core(TM) i5 CPU M 540.\r\n\r\nSequence of commands: \r\nimport tensorflow as tf\r\nfrom tensorflow.keras.layers import Dense\r\n\r\nError log:\r\nERROR:root:Internal Python error in the inspect module.\r\nBelow is the traceback from this internal error.\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: Eine DLL-Initialisierungsroutine ist fehlgeschlagen.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-4-10b08cb426ec>\", line 2, in <module>\r\n    from tensorflow.keras.layers import Dense\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 42, in <module>\r\n    from . _api.v2 import audio\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow_core\\_api\\v2\\audio\\__init__.py\", line 10, in <module>\r\n    from tensorflow.python.ops.gen_audio_ops import decode_wav\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_audio_ops.py\", line 9, in <module>\r\n    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: Eine DLL-Initialisierungsroutine ist fehlgeschlagen.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\r\n    stb = value._render_traceback_()\r\nAttributeError: 'ImportError' object has no attribute '_render_traceback_'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: Eine DLL-Initialisierungsroutine ist fehlgeschlagen.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1151, in get_records\r\n    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\r\n    return f(*args, **kwargs)\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\r\n    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\inspect.py\", line 1502, in getinnerframes\r\n    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\inspect.py\", line 1460, in getframeinfo\r\n    filename = getsourcefile(frame) or getfile(frame)\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\inspect.py\", line 696, in getsourcefile\r\n    if getattr(getmodule(object, filename), '__loader__', None) is not None:\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\inspect.py\", line 733, in getmodule\r\n    if ismodule(module) and hasattr(module, '__file__'):\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 42, in <module>\r\n    from . _api.v2 import audio\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow_core\\_api\\v2\\audio\\__init__.py\", line 10, in <module>\r\n    from tensorflow.python.ops.gen_audio_ops import decode_wav\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_audio_ops.py\", line 9, in <module>\r\n    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: Eine DLL-Initialisierungsroutine ist fehlgeschlagen.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-4-10b08cb426ec>\", line 2, in <module>\r\n    from tensorflow.keras.layers import Dense\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 42, in <module>\r\n    from . _api.v2 import audio\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow_core\\_api\\v2\\audio\\__init__.py\", line 10, in <module>\r\n    from tensorflow.python.ops.gen_audio_ops import decode_wav\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_audio_ops.py\", line 9, in <module>\r\n    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: Eine DLL-Initialisierungsroutine ist fehlgeschlagen.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\r\n    stb = value._render_traceback_()\r\nAttributeError: 'ImportError' object has no attribute '_render_traceback_'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: Eine DLL-Initialisierungsroutine ist fehlgeschlagen.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\nERROR:root:Internal Python error in the inspect module.\r\nBelow is the traceback from this internal error.\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: Eine DLL-Initialisierungsroutine ist fehlgeschlagen.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-4-10b08cb426ec>\", line 2, in <module>\r\n    from tensorflow.keras.layers import Dense\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 42, in <module>\r\n    from . _api.v2 import audio\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow_core\\_api\\v2\\audio\\__init__.py\", line 10, in <module>\r\n    from tensorflow.python.ops.gen_audio_ops import decode_wav\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_audio_ops.py\", line 9, in <module>\r\n    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: Eine DLL-Initialisierungsroutine ist fehlgeschlagen.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\r\n    stb = value._render_traceback_()\r\nAttributeError: 'ImportError' object has no attribute '_render_traceback_'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3254, in run_ast_nodes\r\n    if (await self.run_code(code, result,  async_=asy)):\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3348, in run_code\r\n    self.showtraceback(running_compiled_code=True)\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2047, in showtraceback\r\n    value, tb, tb_offset=tb_offset)\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1418, in structured_traceback\r\n    self, etype, value, tb, tb_offset, number_of_lines_of_context)\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1318, in structured_traceback\r\n    self, etype, value, tb, tb_offset, number_of_lines_of_context\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1186, in structured_traceback\r\n    formatted_exceptions += self.prepare_chained_exception_message(evalue.__cause__)\r\nTypeError: can only concatenate str (not \"list\") to str\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\r\n    stb = value._render_traceback_()\r\nAttributeError: 'TypeError' object has no attribute '_render_traceback_'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: Eine DLL-Initialisierungsroutine ist fehlgeschlagen.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1151, in get_records\r\n    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\r\n    return f(*args, **kwargs)\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\r\n    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\inspect.py\", line 1502, in getinnerframes\r\n    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\inspect.py\", line 1460, in getframeinfo\r\n    filename = getsourcefile(frame) or getfile(frame)\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\inspect.py\", line 696, in getsourcefile\r\n    if getattr(getmodule(object, filename), '__loader__', None) is not None:\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\inspect.py\", line 733, in getmodule\r\n    if ismodule(module) and hasattr(module, '__file__'):\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 42, in <module>\r\n    from . _api.v2 import audio\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow_core\\_api\\v2\\audio\\__init__.py\", line 10, in <module>\r\n    from tensorflow.python.ops.gen_audio_ops import decode_wav\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_audio_ops.py\", line 9, in <module>\r\n    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: Eine DLL-Initialisierungsroutine ist fehlgeschlagen.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-4-10b08cb426ec>\", line 2, in <module>\r\n    from tensorflow.keras.layers import Dense\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 42, in <module>\r\n    from . _api.v2 import audio\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow_core\\_api\\v2\\audio\\__init__.py\", line 10, in <module>\r\n    from tensorflow.python.ops.gen_audio_ops import decode_wav\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_audio_ops.py\", line 9, in <module>\r\n    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: Eine DLL-Initialisierungsroutine ist fehlgeschlagen.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\r\n    stb = value._render_traceback_()\r\nAttributeError: 'ImportError' object has no attribute '_render_traceback_'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3254, in run_ast_nodes\r\n    if (await self.run_code(code, result,  async_=asy)):\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3348, in run_code\r\n    self.showtraceback(running_compiled_code=True)\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2047, in showtraceback\r\n    value, tb, tb_offset=tb_offset)\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1418, in structured_traceback\r\n    self, etype, value, tb, tb_offset, number_of_lines_of_context)\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1318, in structured_traceback\r\n    self, etype, value, tb, tb_offset, number_of_lines_of_context\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1186, in structured_traceback\r\n    formatted_exceptions += self.prepare_chained_exception_message(evalue.__cause__)\r\nTypeError: can only concatenate str (not \"list\") to str\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\r\n    stb = value._render_traceback_()\r\nAttributeError: 'TypeError' object has no attribute '_render_traceback_'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: Eine DLL-Initialisierungsroutine ist fehlgeschlagen.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n---------------------------------------------------------------------------\r\nImportError                               Traceback (most recent call last)\r\n~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py in <module>\r\n     57 \r\n---> 58   from tensorflow.python.pywrap_tensorflow_internal import *\r\n     59   from tensorflow.python.pywrap_tensorflow_internal import __version__\r\n\r\n~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py in <module>\r\n     27             return _mod\r\n---> 28     _pywrap_tensorflow_internal = swig_import_helper()\r\n     29     del swig_import_helper\r\n\r\n~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py in swig_import_helper()\r\n     23             try:\r\n---> 24                 _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n     25             finally:\r\n\r\n~\\anaconda3\\lib\\imp.py in load_module(name, file, filename, details)\r\n    241         else:\r\n--> 242             return load_dynamic(name, filename, file)\r\n    243     elif type_ == PKG_DIRECTORY:\r\n\r\n~\\anaconda3\\lib\\imp.py in load_dynamic(name, path, file)\r\n    341             name=name, loader=loader, origin=path)\r\n--> 342         return _load(spec)\r\n    343 \r\n\r\nImportError: DLL load failed: Eine DLL-Initialisierungsroutine ist fehlgeschlagen.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nAttributeError                            Traceback (most recent call last)\r\n~\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in showtraceback(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\r\n   2043                         # in the engines. This should return a list of strings.\r\n-> 2044                         stb = value._render_traceback_()\r\n   2045                     except Exception:\r\n\r\nAttributeError: 'ImportError' object has no attribute '_render_traceback_'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTypeError                                 Traceback (most recent call last)\r\n~\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self, code_obj, result, async_)\r\n   3346             if result is not None:\r\n   3347                 result.error_in_exec = sys.exc_info()[1]\r\n-> 3348             self.showtraceback(running_compiled_code=True)\r\n   3349         else:\r\n   3350             outflag = False\r\n\r\n~\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in showtraceback(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\r\n   2045                     except Exception:\r\n   2046                         stb = self.InteractiveTB.structured_traceback(etype,\r\n-> 2047                                             value, tb, tb_offset=tb_offset)\r\n   2048 \r\n   2049                     self._showtraceback(etype, value, stb)\r\n\r\n~\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py in structured_traceback(self, etype, value, tb, tb_offset, number_of_lines_of_context)\r\n   1416             self.tb = tb\r\n   1417         return FormattedTB.structured_traceback(\r\n-> 1418             self, etype, value, tb, tb_offset, number_of_lines_of_context)\r\n   1419 \r\n   1420 \r\n\r\n~\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py in structured_traceback(self, etype, value, tb, tb_offset, number_of_lines_of_context)\r\n   1316             # Verbose modes need a full traceback\r\n   1317             return VerboseTB.structured_traceback(\r\n-> 1318                 self, etype, value, tb, tb_offset, number_of_lines_of_context\r\n   1319             )\r\n   1320         elif mode == 'Minimal':\r\n\r\n~\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py in structured_traceback(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\r\n   1184         exception = self.get_parts_of_chained_exception(evalue)\r\n   1185         if exception:\r\n-> 1186             formatted_exceptions += self.prepare_chained_exception_message(evalue.__cause__)\r\n   1187             etype, evalue, etb = exception\r\n   1188         else:\r\n\r\nTypeError: can only concatenate str (not \"list\") to str\r\n", "comments": ["From the template it looks like you are installing **TensorFlow** (TF) prebuilt binaries:\n   * For TF-GPU - See point 1\n   * For TF-CPU - See point 2\n-----------------------------------------------------------------------------------------------\n**1. Installing **TensorFlow-GPU** (TF) prebuilt binaries**\n\nMake sure you are using compatible TF and CUDA versions. Please refer following TF version and CUDA version compatibility table.\n| TF  | CUDA |\n| :-------------: | :-------------: |\n| 2.1.0 - 2.2.0  | 10.1 |\n| 1.13.1 - 2.0  | 10.0  |\n| 1.5.0 - 1.12.0 | 9.0 |\n\n  * If you have above configuration and using _**Windows**_ platform -\n    * Try adding the CUDA, CUPTI, and cuDNN installation directories to the %PATH% environment variable.\n    * Refer [windows setup guide](https://www.tensorflow.org/install/gpu#windows_setup).\n  * If you have above configuration and using _**Ubuntu/Linux**_ platform -\n    * Try adding the CUDA, CUPTI, and cuDNN installation directories to the $LD_LIBRARY_PATH environment variable.\n    * Refer [linux setup guide](https://www.tensorflow.org/install/gpu#linux_setup).\n  * If error still persists then, apparently your CPU model does not support AVX instruction sets.\n    * Refer [hardware requirements](https://www.tensorflow.org/install/pip#hardware-requirements).\n\n-----------------------------------------------------------------------------------------------\n**2. Installing **TensorFlow** (TF) CPU prebuilt binaries**\n\n*TensorFlow release binaries version 1.6 and higher are prebuilt with AVX instruction sets.*\n\nTherefore on any CPU that does not have these instruction sets, either CPU or GPU version of TF will fail to load.\nApparently, your CPU model does not support AVX instruction sets. You can still use TensorFlow with the alternatives given below:\n\n   * Try Google Colab to use TensorFlow.\n      * The easiest way to use TF will be to switch to [google colab](https://colab.sandbox.google.com/notebooks/welcome.ipynb#recent=true). You get pre-installed latest stable TF version. Also you can use ```pip install```  to install any other preferred TF version.\n      * It has an added advantage since you can you easily switch to different hardware accelerators (cpu, gpu, tpu) as per the task.\n      * All you need is a good internet connection and you are all set.\n   * Try to build TF from sources by changing CPU optimization flags.\n\n*Please let us know if this helps.*\n", "Thank you for the bot answer, this helped clarify the problem. Is there a way I can pip install TF 1.5 to mitigate this problem? In the anaconda Powershell Prompt, when I enter pip install tensorflow==1.5.0 it cannot find the matching distributions, all listed available distributions are 1.13 and higher.", "@ki-al-la \r\nWe see that your python version is 3.8 and tensorflow version is 2.0, py 3.8 is not compatible for tf 2.1 and below.\r\nPlease refer to [this issue](https://github.com/tensorflow/tensorflow/issues/40005#issuecomment-636448502)  also #33374 and let us know if it helps.", "I updated tensorflow to the newest version. now if I want to run \"import tensorflow as tf\" I get this error message:\r\n\r\nImportError                               Traceback (most recent call last)\r\n~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py in <module>\r\n     57 \r\n---> 58   from tensorflow.python.pywrap_tensorflow_internal import *\r\n     59 \r\n\r\n~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py in <module>\r\n     27             return _mod\r\n---> 28     _pywrap_tensorflow_internal = swig_import_helper()\r\n     29     del swig_import_helper\r\n\r\n~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py in swig_import_helper()\r\n     23             try:\r\n---> 24                 _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n     25             finally:\r\n\r\n~\\anaconda3\\lib\\imp.py in load_module(name, file, filename, details)\r\n    241         else:\r\n--> 242             return load_dynamic(name, filename, file)\r\n    243     elif type_ == PKG_DIRECTORY:\r\n\r\n~\\anaconda3\\lib\\imp.py in load_dynamic(name, path, file)\r\n    341             name=name, loader=loader, origin=path)\r\n--> 342         return _load(spec)\r\n    343 \r\n\r\nImportError: DLL load failed: Eine DLL-Initialisierungsroutine ist fehlgeschlagen.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nImportError                               Traceback (most recent call last)\r\n<ipython-input-1-64156d691fe5> in <module>\r\n----> 1 import tensorflow as tf\r\n\r\n~\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py in <module>\r\n     39 import sys as _sys\r\n     40 \r\n---> 41 from tensorflow.python.tools import module_util as _module_util\r\n     42 from tensorflow.python.util.lazy_loader import LazyLoader as _LazyLoader\r\n     43 \r\n\r\n~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py in <module>\r\n     48 import numpy as np\r\n     49 \r\n---> 50 from tensorflow.python import pywrap_tensorflow\r\n     51 \r\n     52 # Protocol buffers\r\n\r\n~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py in <module>\r\n     67 for some common reasons and solutions.  Include the entire stack trace\r\n     68 above this error message when asking for help.\"\"\" % traceback.format_exc()\r\n---> 69   raise ImportError(msg)\r\n     70 \r\n     71 # pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\r\n\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\kimal\\anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: Eine DLL-Initialisierungsroutine ist fehlgeschlagen.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.", "@ki-al-la \r\nPlease refer to this [comment](https://github.com/tensorflow/tensorflow/issues/28671#issuecomment-492225800)  and these issues #31690 #28696 #28671 #27788", "Thank you", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40352\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40352\">No</a>\n"]}, {"number": 40351, "title": "Update google cloud cpp to 1.14.0", "body": "@mihaimaruseac \r\nThe new version contains some fixes and features we need.\r\n- Fix build on some versions of MSVC (This PR is made by me) https://github.com/googleapis/google-cloud-cpp/pull/4059\r\n- Check if running inside Google https://github.com/googleapis/google-cloud-cpp/pull/3959\r\n- Implement resumable parallel file uploads https://github.com/googleapis/google-cloud-cpp/pull/3389\r\n\r\nIn fact, I don't update the current version since I don't understand `system_link_files` and `system_build_file` and I think this library is used internally only in Google till now.\r\n\r\nAbout the patch file, I don't add it here because it is related to GCS only. We need that patch file since `google-cloud-cpp` uses `@com_github_curl_curl` instead of `@curl` and we don't want it to download and recompile `curl`. It would be nice if Bazel has a feature that allow us to make an alias of a repository ( e.g `com_github_curl_curl` will be an alias of `curl`). That way we don't need the patch file", "comments": ["There is `bind` in Bazel that could do aliasing. Though I'm not sure if it helps with third party repositories.", "I will take a look at `bind`", "@mihaimaruseac \r\nI found a way without the need of a patch file.\r\nhttps://github.com/bazelbuild/bazel/issues/1952#issuecomment-557726794", "Awesome. Let's try that in the next PR."]}, {"number": 40350, "title": "build tensorflow 1.13 error", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nLinux Ubuntu 16.04\r\n\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version: \r\n1.13\r\n\r\n- Python version:\r\n3.7\r\n\r\n- Installed using virtualenv? pip? conda?:\r\nNo\r\n\r\n- Bazel version (if compiling from source):\r\n0.19.2\r\n\r\n- GCC/Compiler version (if compiling from source):\r\nexternal/androidndk/ndk/toolchains/arm-linux-androideabi-4.9/prebuilt/linux-x86_64/bin/arm-linux-androideabi-gcc \r\n\r\n- CUDA/cuDNN version:\r\nNo\r\n\r\n- GPU model and memory:\r\n\r\nNDK version\uff1a\r\nandroid-ndk-r12b \r\n\r\nconfigure\r\n```\r\n./configure \r\nWARNING: Running Bazel server needs to be killed, because the startup options are different.\r\nWARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command \"bazel shutdown\".\r\nYou have bazel 0.19.2 installed.\r\nPlease specify the location of python. [Default is /home/wushengqi/anaconda3/bin/python]: \r\n\r\n\r\nFound possible Python library paths:\r\n  /home/wushengqi/anaconda3/lib/python3.7/site-packages\r\nPlease input the desired Python library path to use.  Default is [/home/wushengqi/anaconda3/lib/python3.7/site-packages]\r\n\r\nDo you wish to build TensorFlow with XLA JIT support? [Y/n]: N\r\nNo XLA JIT support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with OpenCL SYCL support? [y/N]: N\r\nNo OpenCL SYCL support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with ROCm support? [y/N]: N\r\nNo ROCm support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with CUDA support? [y/N]: N\r\nNo CUDA support will be enabled for TensorFlow.\r\n\r\nDo you wish to download a fresh release of clang? (Experimental) [y/N]: N\r\nClang will not be downloaded.\r\n\r\nDo you wish to build TensorFlow with MPI support? [y/N]: N\r\nNo MPI support will be enabled for TensorFlow.\r\n\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native -Wno-sign-compare]: \r\n\r\n\r\nWould you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Y\r\nSearching for NDK and SDK installations.\r\n\r\nPlease specify the home path of the Android NDK to use. [Default is /home/wushengqi/Android/Sdk/ndk-bundle]: /home/wushengqi/android/android-ndk-r12b\r\n\r\n\r\nPlease specify the home path of the Android SDK to use. [Default is /home/wushengqi/Android/Sdk]: \r\n\r\n\r\nPlease specify the Android SDK API level to use. [Available levels: ['19', '21', '23', '29']] [Default is 29]: 23\r\n\r\n\r\nPlease specify an Android build tools version to use. [Available versions: ['20.0.0', '25.0.2', '28.0.3', '29.0.3']] [Default is 29.0.3]: 25.0.2\r\n\r\n\r\nPreconfigured Bazel build configs. You can use any of the below by adding \"--config=<>\" to your build command. See .bazelrc for more details.\r\n\t--config=mkl         \t# Build with MKL support.\r\n\t--config=monolithic  \t# Config for mostly static monolithic build.\r\n\t--config=gdr         \t# Build with GDR support.\r\n\t--config=verbs       \t# Build with libverbs support.\r\n\t--config=ngraph      \t# Build with Intel nGraph support.\r\n\t--config=dynamic_kernels\t# (Experimental) Build kernels into separate shared objects.\r\nPreconfigured Bazel build configs to DISABLE default on features:\r\n\t--config=noaws       \t# Disable AWS S3 filesystem support.\r\n\t--config=nogcp       \t# Disable GCP support.\r\n\t--config=nohdfs      \t# Disable HDFS support.\r\n\t--config=noignite    \t# Disable Apacha Ignite support.\r\n\t--config=nokafka     \t# Disable Apache Kafka support.\r\n\t--config=nonccl      \t# Disable NVIDIA NCCL support.\r\n```\r\n\r\n```\r\nERROR: /home/wushengqi/.cache/bazel/_bazel_wushengqi/2840f8b2441253bda229f603c535fe4e/external/com_google_absl/absl/strings/BUILD.bazel:32:1: C++ compilation of rule '@com_google_absl//absl/strings:strings' failed (Exit 1): arm-linux-androideabi-gcc failed: error executing command \r\n  (cd /home/wushengqi/.cache/bazel/_bazel_wushengqi/2840f8b2441253bda229f603c535fe4e/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    ANDROID_BUILD_TOOLS_VERSION=25.0.2 \\\r\n    ANDROID_NDK_API_LEVEL=12 \\\r\n    ANDROID_NDK_HOME=/home/wushengqi/android/android-ndk-r12b \\\r\n    ANDROID_SDK_API_LEVEL=23 \\\r\n    ANDROID_SDK_HOME=/home/wushengqi/Android/Sdk \\\r\n    PATH=/home/wushengqi/anaconda3/bin:/home/wushengqi/bin:/home/wushengqi/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/home/wushengqi/wushengqi/bin:/home/wushengqi/android/android-ndk-r12b \\\r\n    PWD=/proc/self/cwd \\\r\n    PYTHON_BIN_PATH=/home/wushengqi/anaconda3/bin/python \\\r\n    PYTHON_LIB_PATH=/home/wushengqi/anaconda3/lib/python3.7/site-packages \\\r\n    TF_DOWNLOAD_CLANG=0 \\\r\n    TF_NEED_CUDA=0 \\\r\n    TF_NEED_OPENCL_SYCL=0 \\\r\n    TF_NEED_ROCM=0 \\\r\n  external/androidndk/ndk/toolchains/arm-linux-androideabi-4.9/prebuilt/linux-x86_64/bin/arm-linux-androideabi-gcc -fstack-protector-strong -fpic -ffunction-sections -funwind-tables -no-canonical-prefixes -fno-canonical-system-headers '-march=armv7-a' '-mfpu=vfpv3-d16' '-mfloat-abi=softfp' -mthumb -Os -g -DNDEBUG -MD -MF bazel-out/armeabi-v7a-opt/bin/external/com_google_absl/absl/strings/_objs/strings/charconv.d '-frandom-seed=bazel-out/armeabi-v7a-opt/bin/external/com_google_absl/absl/strings/_objs/strings/charconv.o' -D__CLANG_SUPPORT_DYN_ANNOTATION__ -iquote external/com_google_absl -iquote bazel-out/armeabi-v7a-opt/genfiles/external/com_google_absl -iquote bazel-out/armeabi-v7a-opt/bin/external/com_google_absl -iquote external/bazel_tools -iquote bazel-out/armeabi-v7a-opt/genfiles/external/bazel_tools -iquote bazel-out/armeabi-v7a-opt/bin/external/bazel_tools '-std=c++11' -Wall -Wextra -Wcast-qual -Wconversion-null -Wmissing-declarations -Woverlength-strings -Wpointer-arith -Wunused-local-typedefs -Wunused-result -Wvarargs -Wvla -Wwrite-strings -Wno-sign-compare '--sysroot=external/androidndk/ndk/platforms/android-12/arch-arm' -isystem external/androidndk/ndk/sources/cxx-stl/gnu-libstdc++/4.9/include -isystem external/androidndk/ndk/sources/cxx-stl/gnu-libstdc++/4.9/libs/armeabi-v7a/include -isystem external/androidndk/ndk/sources/cxx-stl/gnu-libstdc++/4.9/include/backward -c external/com_google_absl/absl/strings/charconv.cc -o bazel-out/armeabi-v7a-opt/bin/external/com_google_absl/absl/strings/_objs/strings/charconv.o)\r\nexternal/com_google_absl/absl/strings/charconv.cc: In static member function 'static double absl::{anonymous}::FloatTraits<double>::MakeNan(const char*)':\r\nexternal/com_google_absl/absl/strings/charconv.cc:89:20: error: 'nan' was not declared in this scope\r\n     return nan(tagp);\r\n                    ^\r\nexternal/com_google_absl/absl/strings/charconv.cc: In static member function 'static float absl::{anonymous}::FloatTraits<float>::MakeNan(const char*)':\r\nexternal/com_google_absl/absl/strings/charconv.cc:143:21: error: 'nanf' was not declared in this scope\r\n     return nanf(tagp);\r\n                     ^\r\nexternal/com_google_absl/absl/strings/charconv.cc: In static member function 'static double absl::{anonymous}::FloatTraits<double>::MakeNan(const char*)':\r\nexternal/com_google_absl/absl/strings/charconv.cc:90:3: warning: control reaches end of non-void function [-Wreturn-type]\r\n   }\r\n   ^\r\nexternal/com_google_absl/absl/strings/charconv.cc: In static member function 'static float absl::{anonymous}::FloatTraits<float>::MakeNan(const char*)':\r\nexternal/com_google_absl/absl/strings/charconv.cc:144:3: warning: control reaches end of non-void function [-Wreturn-type]\r\n   }\r\n   ^\r\nTarget //tensorflow/examples/TensorFlowService:libtensorflow-lib.so failed to build\r\nINFO: Elapsed time: 6.811s, Critical Path: 2.51s, Remote (0.00% of the time): [queue: 0.00%, setup: 0.00%, process: 0.00%]\r\n```\r\n", "comments": ["Recommend trying to build from one of the supported versions (1.15, 2.0, 2.1, 2.2, master) as we don't have enough workforce to cover old releases", "> Recommend trying to build from one of the supported versions (1.15, 2.0, 2.1, 2.2, master) as we don't have enough workforce to cover old releases\r\n\r\nI was able to compile TensorFlow version 2.2, but it is not compatible with Android 4.4. So which version of TensorFlow compilation can support Android 4.4?", "You need TFLite for that, right?", "> You need TFLite for that, right?\r\n\r\nNo,I want to compile the Android so library directly with Tensorflow instead of TFLite.Because my leader thought that TFLite would have operator compatibility problems.Our current approach is to call the tensorFlow native API directly, package it together with the TensorFlow library into a SO library, and finally call it by the Java layer, which is about twice as fast as tensorFlow's Java library.", "> You need TFLite for that, right?\r\n\r\nI would like to ask, what kind of configuration can achieve my above requirements, packaging success?", "At present, I can compile and pass TensorFlow 2.2, but in actual use, an error will be reported in Android 4.4.\r\n\r\n`cannot locate symbol \"fegetround\" referenced by \"libtensorflow-lib.so\"`", "Unfortunately I don't think we have CI to ensure main TF builds on mobile. Since you are building from source, you can grep for `fegetround` in the source code and find a replacement that is available on mobile.", "> Unfortunately I don't think we have CI to ensure main TF builds on mobile. Since you are building from source, you can grep for `fegetround` in the source code and find a replacement that is available on mobile.\r\n\r\nOK\uff0c", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40350\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40350\">No</a>\n"]}, {"number": 40349, "title": "Could not load dynamic library 'libcudnn.so.7'", "body": "**System information**\r\n- OS Platform and Distribution: Ubuntu 20.04 LTS\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version: 2.2.0\r\n- Python version: 3.8.2\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source): 8.4.0\r\n- CUDA/cuDNN version: 10.1\r\n\r\n\r\n\r\nWhen I run the program like:\r\n\r\n`import tensorflow as tf`\r\n\r\nit shows no problem but when i do:\r\n\r\n`import tensorflow as tf\r\n\r\nrank_0_tensor = tf.constant([2.0, 3.0, 4.0])\r\nprint(rank_0_tensor)`\r\n\r\ni get the error showing:\r\n![Screenshot from 2020-06-10 15-10-32](https://user-images.githubusercontent.com/63995679/84252815-ba41b300-ab2c-11ea-9dac-bd225364f492.png)\r\n\r\nCan anybody help?\r\n", "comments": ["@paxth,\r\nThe logs you are seeing on the console are not errors but information and warning messages. You can see the output of your script in the last line of the messages. \r\n\r\nIf you want to disable these logs try changing the log level using the below code\r\n```\r\nimport os\r\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \r\nimport tensorflow as tf\r\n```\r\n\r\nThanks!", "> @paxth,\r\n> The logs you are seeing on the console are not errors but information and warning messages. You can see the output of your script in the last line of the messages.\r\n> \r\n> If you want to disable these logs try changing the log level using the below code\r\n> \r\n> ```\r\n> import os\r\n> os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \r\n> import tensorflow as tf\r\n> ```\r\n> \r\n> Thanks!\r\n\r\nOkay, thanks! It worked but is there a way to permanently get rid of the warnings instead of doing the `import os` everytime?\r\n", "@paxth,\r\nSorry for the delayed response. Could you please try changing the log level in Python itself and check if it works. \r\n\r\nPlease feel free to close the issue if resolved. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n"]}, {"number": 40348, "title": "tf.contrib module's alternative methods in Version 2 of Tensorflow ", "body": "I'm following the documentation to migrate from V1 to V2 mentioned below which states that `tf.contrib` module is removed from the v2 and it can't be made to work even with this line of code: \r\n```\r\nimport tensorflow.compat.v1 as tf \r\ntf.disable_v2_behavior()\r\n```\r\nSo, is the only option left is to remove them manually? If it is can we have a link mentioning the new methods for classes which are now not by supported in V2?\r\n## URL(s) with the issue:\r\nGuide to migration: https://www.tensorflow.org/guide/migrate\r\nOld version's link to the tf.contrib module: https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/contrib\r\n\r\n## Description of the issue (what needs changing):\r\n\r\nThe original documentation mentioned that the modules of `tf.contrib` are adjusted in other classes but no clear mention of where to find them. I can't find the alternative for many old methods like:\r\n`tf.contrib.lookup.index_table_from_file`, `tf.contrib.crf.crf_decode`.\r\nCan we have a link/mention to the new alternative methods for the removed `tf.contrib` classes in either the guide to migration or in the older version page, stating the new alternative, so that it is easier while migrating manually? \r\n", "comments": ["@ishdutt \r\nCan you please refer to these comments and let us know if it helps:\r\n[link](https://stackoverflow.com/questions/56464356/what-is-the-equivalent-in-tensorflow-2-0-of-tf-contrib-framework-nest-flatten-di) [link1](https://www.tensorflow.org/guide/migrate) [link2](https://github.com/tensorflow/models/issues/7036#issuecomment-609461116)", "Hi @Saduf2019 , None of them was useful. I've already checked the official document for migrating to V2 and the link 3 suggests either adding this code (I'm already using it)\r\n```\r\nimport tensorflow.compat.v1 as tf \r\ntf.disable_v2_behavior()\r\n```\r\nor downgrading the TensorFlow version.\r\nSince the problem is not limited to one single function but many functions can't we have it in the official document stating the new alternative of the older non-supportive functions of `tf.contrib` module?", "Take a look at [sunsetting contrib](https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md) guide to know about `tf.contrib` whereabouts.\r\nAlso we have [TensorFlow addons ](https://github.com/tensorflow/addons)module which provides a subset of TF core contrib functionality which is no longer part of TF 2.\r\nHowever there are some functions which are not absorbed by TF core neither covered by TF Addons.\r\nFor such cases you can always raise a feature request on TF addons repository.\r\nHope this helps. Thanks!\r\n", "Hi @ymodak The first link was helpful but they were not complete and haven't been updated too after the V2 release, I guess. There were many empty spaces, some of them were not found in the core module like `tf.contrib.lookup` even though mentioned in their fate. If the migration is still in the process, can I be a part of that SIG as mentioned in that page? Should I update this page [sunsetting contrib](https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md) wherever the predicted fate and original fate mismatch? I'll be happy to contribute to the TensorFlow community :)\r\nThanks!", "Sounds good. You can join SIG Addons using this [guide](https://github.com/tensorflow/community/blob/master/sigs/addons/CHARTER.md#sig-addons)\r\nAlso you can email email `community-team@tensorflow.org` directly."]}, {"number": 40347, "title": "TF_SessionRunCallable in file session.py Crashes", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 7 32-bit\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 1.9.0\r\n- Python version: 3.6.8\r\n- Bazel version (if compiling from source): --------------------\r\n- GCC/Compiler version (if compiling from source):  cmake 3.9.6\r\n- CUDA/cuDNN version: ------------\r\n- GPU model and memory: --------------\r\n\r\n**Describe the current behavior**\r\n\r\nI compiled tensorflow 1.9.0 for target os windows 7 32 bit, I used \r\nwin 10 1709\r\ngit 2.14.1\r\ncmake 3.9.6\r\nanaconda3 5.1.0\r\nvisual studio 2017\r\nswigwin-3.0.10\r\n\r\nI installed the whl file on Virtualbox windows 7 32 bits and run a model, it works fine, but when I installed on the same condition on actual pc it raises an error, The ucrtbase.dll will crash.\r\n\r\nThe error that happens is :\r\n\r\nProblem Event Name: APPCRASH\r\nApplication Name: python.exe\r\nApplication Version: 3.6.8150.1013\r\nApplication Timestamp: 5c201b63\r\nFault Module Name: ucrtbase.DLL\r\nFault Module Version: 10.0.14393.2990\r\nFault Module Timestamp: 5caeb859\r\nException Code: 40000015\r\nException Offset: 000884da\r\nOS Version: 6.1.7601.2.1.0.256.48\r\nLocale ID: 1033\r\nAdditional Information 1: f419\r\nAdditional Information 2: f419a63a49a2df57b723a80593a88e82\r\nAdditional Information 3: e2c1\r\nAdditional Information 4: e2c181b5a2bed9dd090d71f8ac7769de\r\n\r\nHowever I debugged the code and I found that the error raises from this code :\r\n\r\n### file :  \r\n\r\nC:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python36-32\\Lib\\site-packages\\tensorflow\\python\\client\\session.py\r\n\r\n### code : \r\n```\r\ndef call(self, *args):\r\n#TODO(b/74355905): Support argument and return value nested structures,\r\n#and tensor-like objects such as SparseTensors.\r\nwith errors.raise_exception_on_not_ok_status() as status:\r\nif self._session._created_with_new_api:\r\n**return tf_session.TF_SessionRunCallable(\r\nself._session._session, self._handle, args, status, None)**\r\nelse:\r\nreturn tf_session.TF_DeprecatedSessionRunCallable(\r\nself._session._session, self._handle, args, status, None)\r\n```\r\n\r\nLine   causing the error: return tf_session.TF_SessionRunCallable(\r\nself._session._session, self._handle, args, status, None)\r\n\r\nI hope you can help me to fix this issue, Please give me the fixing instruction, because I could not install any fixing patches, I have to compile them for windows 32 bits and it is a painful work.\r\n\r\nThank you so much", "comments": ["@sasansharifipour \r\n\r\nTF version 1.9 is too old .Can you upgrade to TF versions 1.15 or 2.x and see if the problem still persists.I think you build using cmake.The TensorFlow team does not officially support cmake, sorry. Please try out building from source with Bazel.Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40347\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40347\">No</a>\n"]}, {"number": 40346, "title": "Tensorflow dataset loading warning", "body": "### System information\r\n\r\n\r\n-   **OS Platform Windows 8.1\r\n-   **TensorFlow version 2.0\r\n-   **Python version 3.7.7\r\n\r\n### Describe the problem\r\nI tried to load the MNIST dataset from tensorflow datasets. It is giving me the following warning:\r\ni installed gast 0.2.2 still the issue persists\r\nSystem info:\r\nOS: WIndows 8.1\r\nPython 3.7.7\r\nTensorflow 2.0\r\n\r\nWarning:\r\nWARNING:tensorflow:Entity <function _get_dataset_from_filename at 0x00000075305C23A8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, export AUTOGRAPH_VERBOSITY=10) and attach the full output. Cause: module 'gast' has no attribute 'Num'\r\nWARNING:tensorflow:Entity <function _get_dataset_from_filename at 0x00000075305C23A8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, export AUTOGRAPH_VERBOSITY=10) and attach the full output. Cause: module 'gast' has no attribute 'Num'\r\nWARNING: Entity <function _get_dataset_from_filename at 0x00000075305C23A8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, export AUTOGRAPH_VERBOSITY=10) and attach the full output. Cause: module 'gast' has no attribute 'Num'\r\nWARNING:tensorflow:Entity <bound method TopLevelFeature.decode_example of FeaturesDict({\r\n'image': Image(shape=(28, 28, 1), dtype=tf.uint8),\r\n'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\r\n})> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, export AUTOGRAPH_VERBOSITY=10) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\r\nWARNING:tensorflow:Entity <bound method TopLevelFeature.decode_example of FeaturesDict({\r\n'image': Image(shape=(28, 28, 1), dtype=tf.uint8),\r\n'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\r\n})> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, export AUTOGRAPH_VERBOSITY=10) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\r\nWARNING: Entity <bound method TopLevelFeature.decode_example of FeaturesDict({\r\n'image': Image(shape=(28, 28, 1), dtype=tf.uint8),\r\n'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\r\n})> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, export AUTOGRAPH_VERBOSITY=10) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\r\nWARNING:tensorflow:Entity <function _get_dataset_from_filename at 0x00000075305C23A8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, export AUTOGRAPH_VERBOSITY=10) and attach the full output. Cause: module 'gast' has no attribute 'Num'\r\nWARNING:tensorflow:Entity <function _get_dataset_from_filename at 0x00000075305C23A8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, export AUTOGRAPH_VERBOSITY=10) and attach the full output. Cause: module 'gast' has no attribute 'Num'\r\nWARNING: Entity <function _get_dataset_from_filename at 0x00000075305C23A8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, export AUTOGRAPH_VERBOSITY=10) and attach the full output. Cause: module 'gast' has no attribute 'Num'\r\nWARNING:tensorflow:Entity <bound method TopLevelFeature.decode_example of FeaturesDict({\r\n'image': Image(shape=(28, 28, 1), dtype=tf.uint8),\r\n'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\r\n})> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, export AUTOGRAPH_VERBOSITY=10) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\r\nWARNING:tensorflow:Entity <bound method TopLevelFeature.decode_example of FeaturesDict({\r\n'image': Image(shape=(28, 28, 1), dtype=tf.uint8),\r\n'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\r\n})> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, export AUTOGRAPH_VERBOSITY=10) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\r\nWARNING: Entity <bound method TopLevelFeature.decode_example of FeaturesDict({\r\n'image': Image(shape=(28, 28, 1), dtype=tf.uint8),\r\n'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\r\n})> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, export AUTOGRAPH_VERBOSITY=10) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\r\n\r\n\r\nTried after installing gast 0.2.2\r\nstill it is giving me the same error\r\n", "comments": ["@HarshadaShirgaokar,\r\nCould you please update to the latest version of TensorFlow i.e. TF v2.2 and check if you are facing the same issue.\r\nI was able to import the dataset with TF v2.2 without any warnings. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/1025a4599a200f00803e7e5983f820bb/40346.ipynb#scrollTo=uzzb-AisVeBz).\r\n\r\nAlso, please take a look at [this](https://github.com/tensorflow/tensorflow/issues/38691) similar issue and let us know if it helps. Thanks! ", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 40345, "title": "Backward LSTM behavior mismatch", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.2\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\nv2.2.0-0-g2b96f3662b 2.2.0\r\n**Describe the current behavior**\r\nSay input is [a1 a2 a3] and running on GPU\r\nIn reverse LSTM, \r\nreversed_input_to_cudnn = [a3 a2 a1]\r\noutput_from_cudnn = [b3 b2 b1]\r\nfinal output = [b1 b2 b3] \r\n\r\nThis is based on the code and description mentioned here:\r\nhttps://github.com/tensorflow/tensorflow/blob/v2.2.0/tensorflow/python/keras/layers/recurrent_v2.py#L630\r\n  \r\n**Describe the expected behavior**\r\nExpected final output is [b3 b2 b1] based on the description mentioned here:\r\nhttps://github.com/tensorflow/tensorflow/blob/v2.2.0/tensorflow/python/keras/layers/recurrent_v2.py#L1000\r\n\r\nI'm not sure what internally is happening and what is the expected behavior?\r\nOther inference engines like ONNXRuntime will give output [b1 b2 b3] and currently there is mismatch of outputs with ONNXRuntime and TF.\r\n\r\n**Standalone code to reproduce the issue**\r\n[simple_lstm.txt](https://github.com/tensorflow/tensorflow/files/4756947/simple_lstm.txt)\r\n(rename to .h5) \r\nYou can use this sample model to verify the results.\r\n\r\n\r\n", "comments": ["@buddhapuneeth \r\nThe code shared is not in readable format, if possible please share a colab gist for us to analyse the issue faced.", "@Saduf2019 the file I shared (simple_lstm.txt) is not the code. It is the .h5 model. As I am not able to attach .h5, I renamed to .txt. \r\nIt is a simple model with reverse LSTM. You load_model and predict using some random input and verify it.", "> @buddhapuneeth\r\n> The code shared is not in readable format, if possible please share a colab gist for us to analyse the issue faced.\r\n\r\n@Saduf2019 the file I shared (simple_lstm.txt) is not the code. It is the .h5 model. As I am not able to attach .h5, I renamed to .txt.\r\nIt is a simple model with reverse LSTM. You load_model and predict using some random input and verify it.", "@buddhapuneeth Can you please share a simple standalone code to reproduce the issue? You could use google colab or Jupyter notebook. Thanks!", "code for reverse LSTM:\r\n```\r\nmax_features = 10\r\nmaxlen = 10\r\nmodel = Sequential()\r\nmodel.add(Embedding(max_features, 128, input_length=maxlen))\r\n\r\nmodel.add(LSTM(64, go_backwards=True, return_sequences = True))\r\nmodel.add(Dense(1, activation='sigmoid'))\r\nmodel.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\r\n\r\n\r\nfrom keras.models import load_model\r\nmodel.save('simple_rev_lstm.h5')\r\n```\r\n\r\nTo compare results with other inference engines like ONNXRuntime (by converting to ONNX)\r\n\r\n\r\n```\r\n# pip install onnxruntime\r\n#env TF_KERAS=1\r\nimport numpy as np\r\nimport onnxruntime\r\nfrom tensorflow.keras.models import load_model as load_model_tf_keras\r\nnp.random.seed(0)\r\ninput_data = np.random.randint(10, size=(2, 10))\r\n# with CustomObjectScope({'GlorotUniform': glorot_uniform()}):\r\nsess = onnxruntime.InferenceSession(\"simple_rev_lstm.onnx\")\r\nresult = sess.run([\"dense_1\"], {'embedding_1_input': input_data.astype(np.float32)})\r\nprint(\"ONNX Runtime\")\r\nprint(np.asarray(result[0]))\r\n\r\nmodel = load_model_tf_keras('simple_rev_lstm.h5')\r\nresult = model.predict(input_data)\r\nprint(\"TF Runtime\")\r\nprint(result)\r\n```\r\nOUTPUT:\r\n```\r\nONNX Runtime\r\n[[[0.5028585 ]\r\n  [0.51010513]\r\n  [0.5096171 ]\r\n  [0.50567615]\r\n  [0.50046337]\r\n  [0.50202006]\r\n  [0.5010086 ]\r\n  [0.49436894]\r\n  [0.4989641 ]\r\n  [0.50032514]]\r\n\r\n [[0.50235206]\r\n  [0.5045772 ]\r\n  [0.504677  ]\r\n  [0.5032916 ]\r\n  [0.5016299 ]\r\n  [0.50043035]\r\n  [0.4991624 ]\r\n  [0.50064933]\r\n  [0.5028503 ]\r\n  [0.5012636 ]]]\r\n\r\nTF Runtime\r\n[[[0.50032514]\r\n  [0.4989641 ]\r\n  [0.49436894]\r\n  [0.5010086 ]\r\n  [0.50202006]\r\n  [0.50046337]\r\n  [0.50567615]\r\n  [0.5096171 ]\r\n  [0.51010513]\r\n  [0.5028585 ]]\r\n\r\n [[0.5012636 ]\r\n  [0.5028503 ]\r\n  [0.50064933]\r\n  [0.4991624 ]\r\n  [0.50043035]\r\n  [0.5016299 ]\r\n  [0.5032916 ]\r\n  [0.504677  ]\r\n  [0.5045773 ]\r\n  [0.50235206]]]\r\n```\r\nObservation:\r\nThe values are in reverse to each other on axis 1.\r\nNot sure which is correct behavior. Documentation is bit confusing here.\r\n\r\n", "@jvishnuvardhan any update? Let me know if you need more info'.", "@buddhapuneeth Could you please try on latest stable version of tf 2.5 or 2.4.1 and let us know if this is still an issue.Thanks!", "@sushreebarsa \r\nI am seeing same old issue on TF 2.5.0\r\nTried on Mac TF 2.5.0 (installed using pip)", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "@sushreebarsa are you able to reproduce?\r\nI am worried as bot marked this stall. ", "Hi There,\n\n This is a stale issue. As you are using an older version of tensorflow, we are checking to see if you still need help on this issue. Please test the issue with the latest TensorFlow (TF2.7 and tf-nightly). If the issue still persists with the newer versions of TF, please feel free to open it in [keras-team/keras](https://github.com/keras-team/keras/issues) repository by providing details about the issue and a standalone code to reproduce the issue. Thanks! \n\n Please note that Keras development has moved to a separate Keras-team/keras repository to focus entirely on only Keras. Thanks! ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40345\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40345\">No</a>\n"]}, {"number": 40344, "title": "We cannot duplicate the value since it's not constant. Failed to duplicate values for the stateful op.", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (or github SHA if from source): 2.3.0-dev20200609\r\n\r\n\r\n**Command used to run the converter or code if you\u2019re using the Python API**\r\nIf possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.models import Model\r\nfrom tensorflow.keras.layers import Input, Bidirectional, LSTM, Dense\r\n\r\nX = Input(shape=(None, 150), name='input')\r\nXc = Bidirectional(LSTM(20, return_sequences=True))(X)\r\nY = Dense(10, activation=tf.nn.softmax, name='output')(Xc)\r\n\r\nmodel = Model(inputs=X, outputs=Y)\r\nloss = tf.keras.losses.CategoricalCrossentropy()\r\nmodel.compile(optimizer='adam',\r\n              loss=loss,\r\n              metrics=['accuracy'])\r\nmodel.summary()\r\n\r\ninputData = np.ones([100, 200, 150])\r\noutputData = np.ones([100,200,10])\r\n\r\nmodel.fit(x=inputData, y=outputData, epochs=2)\r\n\r\nrun_model = tf.function(lambda x: model(x))\r\nBATCH_SIZE = 1\r\nSTEPS = None # 100\r\nINPUT_SIZE = 150\r\nconcrete_func = run_model.get_concrete_function(\r\n    tf.TensorSpec([BATCH_SIZE, STEPS, INPUT_SIZE], model.inputs[0].dtype))\r\nMODEL_DIR = \"./saved_model\"\r\nmodel.save(MODEL_DIR, save_format=\"tf\", signatures=concrete_func)\r\n\r\nconverter = tf.lite.TFLiteConverter.from_saved_model(MODEL_DIR)\r\ntflite_model = converter.convert() # Error!\r\n```\r\n\r\n**The output from the converter invocation**\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nException                                 Traceback (most recent call last)\r\n~/VirtualEnv/ENV37-TF23NT/lib/python3.7/site-packages/tensorflow/lite/python/convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\r\n    184                                                  debug_info_str,\r\n--> 185                                                  enable_mlir_converter)\r\n    186       return model_str\r\n\r\n~/VirtualEnv/ENV37-TF23NT/lib/python3.7/site-packages/tensorflow/lite/python/wrap_toco.py in wrapped_toco_convert(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\r\n     37       debug_info_str,\r\n---> 38       enable_mlir_converter)\r\n     39 \r\n\r\nException: <unknown>:0: error: loc(callsite(callsite(callsite(unknown at \"functional_1/bidirectional/backward_lstm/PartitionedCall@__inference_<lambda>_6523\") at \"StatefulPartitionedCall@__inference_signature_wrapper_6546\") at \"StatefulPartitionedCall\")): We cannot duplicate the value since it's not constant.\r\n\r\n<unknown>:0: note: loc(\"StatefulPartitionedCall\"): called from\r\n<unknown>:0: note: loc(callsite(callsite(callsite(unknown at \"functional_1/bidirectional/backward_lstm/PartitionedCall@__inference_<lambda>_6523\") at \"StatefulPartitionedCall@__inference_signature_wrapper_6546\") at \"StatefulPartitionedCall\")): see current operation: %5 = \"tfl.unidirectional_sequence_lstm\"(%4, %cst_13, %cst_14, %cst_15, %cst_16, %cst_5, %cst_6, %cst_7, %cst_8, %cst_32, %cst_32, %cst_32, %cst_9, %cst_10, %cst_11, %cst_12, %cst_32, %cst_32, %3, %3, %cst_32, %cst_32, %cst_32, %cst_32) {cell_clip = 1.000000e+01 : f32, fused_activation_function = \"TANH\", proj_clip = 0.000000e+00 : f32, time_major = false} : (tensor<1x?x150xf32>, tensor<20x150xf32>, tensor<20x150xf32>, tensor<20x150xf32>, tensor<20x150xf32>, tensor<20x20xf32>, tensor<20x20xf32>, tensor<20x20xf32>, tensor<20x20xf32>, none, none, none, tensor<20xf32>, tensor<20xf32>, tensor<20xf32>, tensor<20xf32>, none, none, tensor<?x20xf32>, tensor<?x20xf32>, none, none, none, none) -> tensor<1x?x20xf32>\r\n<unknown>:0: error: Failed to duplicate values for the stateful op\r\n\r\n<unknown>:0: note: see current operation: \"func\"() ( {\r\n^bb0(%arg0: tensor<1x?x150xf32>):  // no predecessors\r\n  %cst = \"std.constant\"() {value = dense<[0.00800104905, 8.002180e-03, 0.00801025052, 0.00799552072, 0.00798829272, 0.00801645405, 0.00800046883, 0.00799199379, 0.00802111439, 0.00795717072]> : tensor<10xf32>} : () -> tensor<10xf32>\r\n  %cst_0 = \"std.constant\"() {value = dense<0.000000e+00> : tensor<f32>} : () -> tensor<f32>\r\n  %cst_1 = \"std.constant\"() {value = dense<20> : tensor<i32>} : () -> tensor<i32>\r\n  %cst_2 = \"std.constant\"() {value = dense<10> : tensor<1xi32>} : () -> tensor<1xi32>\r\n  %cst_3 = \"std.constant\"() {value = dense<2> : tensor<1xi32>} : () -> tensor<1xi32>\r\n  %cst_4 = \"std.constant\"() {value = dense<[0, 1]> : tensor<2xi32>} : () -> tensor<2xi32>\r\n  %cst_5 = \"std.constant\"() {value = dense<\"0x43B055BE41EB30BC7CBC073ED64B033EBE556E3C656489BD3DF794BD644D33BDF3AF61BDC7E0DD3C41C3E53CB1A15F3D1102DABCA10234BC40563B3E12127F3D34B0CB3D39A77DBD0517453DDFE1F7BDDF83473CB66DFA3BF23B6BBED780F5BDD89FB43CFAA7FB3D7C449DBD80AB69BB42E56EBDF801553D664AA83C8219073E4759D13D1AA96A3E2B3580BDD08902BE2A3405BECFA8AC3D696411BE89C88ABDE13E093EE903043EC2340B3E6836BD3D623122BCC7B0B1BBDB32BCBD2A6CDABD6517CD3D713F913D2AEF9B3D40CAC93DF5E3D63D703676BECAF9A9BD1F9C1D3D9496273E52D2533CC6B00A3EC863933C6BB56BBEC922CCBD89AA5F3E89AEAEBD0B3A193E3626443E9B07443DA23B1C3C671945BD45112EBCCD87913EB31949BD3EB81D3E2182C43C4164B53D9C74F1BD1C88EEBCF59AD0BCBCBEE6BC9D43D33C4FF6913DF8B692BD271E663E1CC7E73DCC196E3C836EC03D3B91303E0AFA53BB7452F9BD2B8CF23D38CC613DA1F6B43DAEAA68BDD221863CA34B03BEDEFD6FBCA03C45BE6CA8633E4CACA53C0D6CACBC086D883DAC02753B878C99BEC33C14BC1090123BBD892D3EDCE4D43D64E2C7BC44BBC53CC9F8CA3D0670763EB46F24BB9B0B20BD94E4AF3D3CDE65BD8ECD503E9235D13D412F20BE2D648C3D39F6B73C6111323E4841CCBCA8EDB5BDC86956BBB2CA3BBD984065BD906B083EED91923DBF5CABBC9376F73CE42FA03D560D18BDF153CFBC4993A93D0755093EA4F544BEEF01823B8B56013E9D3DE23C3BA71D3EB2BC3CBEDADA243D2818773CF66D073E94D01E3EB463AB3DFC3227BEBC0E0DBE2EA1CFBBD458273DBCD92F3EA507993E47BAC2BDEEB640BD92CA673D254C253DEEA2883C177BC13C29AE1A3D0F6511BAF3D859BEE97216BEB7C9BF3BEAA9BEBD3C95AD3B23F37EBDD18329BD46EF113DDDF18C3EEA04543EC3B81C3EF10615BDCD10CD3CB6\r\n...\r\n...\r\nEBDA94F863E437E6CBEB1F8C9BC29E166BE0A6C7EBEBB491B3E94C1363E308BBC3DE7969A3E3D763ABEC7248D3E30D3623E0F67E73D35859FBE522F913D78492CBE84823A3EBD52163DFA137F3EDC103B3E6D13A23E80CFAB3D1E78B4BD881468BEA37B553E50C436BECFC833BE3113403EC29BACBD2DEB62BCA9EB8A3D3F62AD3E5578843DA76FCE3D895EE5BB95318B3ED4D2F7BD209935BEA21190BE98DA9EBE1693A13E7067A73E3B8A813E813E363E6FBBA5BD5E5E54BECFF6A73EB52769BD9E95A53ED071973DC200E63DD239AFBD86A4A3BEA2E3CA3D1DDA04BE316DCA3D1F459F3D998431BE38311E3EE0D2A83E33F3543E39295D3D2FF682BE7AF0AC3EDA1AAABEFC26A3BEE20D66BEBD3D913E8267A13EEA65793E6ECE44BD951A10BE496502BE2E077FBE6F6AD0BD492369BE7B4E9DBDD86385BE552FB33E64C755BE8BA8B0BEF02B3CBE828D9BBEDE08ECBD53AF07BEF4FC093D44F7ADBDCE144C3EE2313ABD65A4AEBE81A0313E03F398BE305EBEBCAD4B763EE34F8BBE4B29A03CD167903E799B263E11073EBD21791DBD47585D3E102063BE11FA21BD32BA48BE7F3923BE88BD073E3A2F11BDCCA56DBE8FDA623EAD3D583DCA74B83DDE6A8FBCAC2A9CBE400576BD125E03BEEEAB59BC8FFF343E5E83773E\"> : tensor<10x40xf32>} : () -> tensor<10x40xf32>\r\n  %cst_30 = \"std.constant\"() {value = dense<0> : tensor<1xi32>} : () -> tensor<1xi32>\r\n  %cst_31 = \"std.constant\"() {value = dense<1> : tensor<1xi32>} : () -> tensor<1xi32>\r\n  %cst_32 = \"std.constant\"() {value} : () -> none\r\n  %0 = \"tfl.shape\"(%arg0) : (tensor<1x?x150xf32>) -> tensor<3xi32>\r\n  %1 = \"tfl.strided_slice\"(%0, %cst_30, %cst_31, %cst_31) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<3xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<i32>\r\n  %2 = \"tfl.pack\"(%1, %cst_1) {axis = 0 : i32, values_count = 2 : i32} : (tensor<i32>, tensor<i32>) -> tensor<2xi32>\r\n  %3 = \"tfl.fill\"(%2, %cst_0) : (tensor<2xi32>, tensor<f32>) -> tensor<?x20xf32>\r\n  %4 = \"tfl.reverse_v2\"(%arg0, %cst_31) : (tensor<1x?x150xf32>, tensor<1xi32>) -> tensor<1x?x150xf32>\r\n  %5 = \"tfl.unidirectional_sequence_lstm\"(%4, %cst_13, %cst_14, %cst_15, %cst_16, %cst_5, %cst_6, %cst_7, %cst_8, %cst_32, %cst_32, %cst_32, %cst_9, %cst_10, %cst_11, %cst_12, %cst_32, %cst_32, %3, %3, %cst_32, %cst_32, %cst_32, %cst_32) {cell_clip = 1.000000e+01 : f32, fused_activation_function = \"TANH\", proj_clip = 0.000000e+00 : f32, time_major = false} : (tensor<1x?x150xf32>, tensor<20x150xf32>, tensor<20x150xf32>, tensor<20x150xf32>, tensor<20x150xf32>, tensor<20x20xf32>, tensor<20x20xf32>, tensor<20x20xf32>, tensor<20x20xf32>, none, none, none, tensor<20xf32>, tensor<20xf32>, tensor<20xf32>, tensor<20xf32>, none, none, tensor<?x20xf32>, tensor<?x20xf32>, none, none, none, none) -> tensor<1x?x20xf32>\r\n  %6 = \"tfl.reverse_v2\"(%5, %cst_31) : (tensor<1x?x20xf32>, tensor<1xi32>) -> tensor<1x?x20xf32>\r\n  %7 = \"tfl.unidirectional_sequence_lstm\"(%arg0, %cst_25, %cst_26, %cst_27, %cst_28, %cst_17, %cst_18, %cst_19, %cst_20, %cst_32, %cst_32, %cst_32, %cst_21, %cst_22, %cst_23, %cst_24, %cst_32, %cst_32, %3, %3, %cst_32, %cst_32, %cst_32, %cst_32) {cell_clip = 1.000000e+01 : f32, fused_activation_function = \"TANH\", proj_clip = 0.000000e+00 : f32, time_major = false} : (tensor<1x?x150xf32>, tensor<20x150xf32>, tensor<20x150xf32>, tensor<20x150xf32>, tensor<20x150xf32>, tensor<20x20xf32>, tensor<20x20xf32>, tensor<20x20xf32>, tensor<20x20xf32>, none, none, none, tensor<20xf32>, tensor<20xf32>, tensor<20xf32>, tensor<20xf32>, none, none, tensor<?x20xf32>, tensor<?x20xf32>, none, none, none, none) -> tensor<1x?x20xf32>\r\n  %8 = \"tfl.concatenation\"(%7, %6) {axis = 2 : i32, fused_activation_function = \"NONE\"} : (tensor<1x?x20xf32>, tensor<1x?x20xf32>) -> tensor<1x?x40xf32>\r\n  %9 = \"tfl.shape\"(%8) : (tensor<1x?x40xf32>) -> tensor<3xi32>\r\n  %10 = \"tfl.gather\"(%9, %cst_4) {axis = 0 : i32} : (tensor<3xi32>, tensor<2xi32>) -> tensor<2xi32>\r\n  %11 = \"tfl.reduce_prod\"(%10, %cst_30) {keep_dims = false} : (tensor<2xi32>, tensor<1xi32>) -> tensor<i32>\r\n  %12 = \"tfl.concatenation\"(%10, %cst_2) {axis = 0 : i32, fused_activation_function = \"NONE\"} : (tensor<2xi32>, tensor<1xi32>) -> tensor<3xi32>\r\n  %13 = \"tfl.gather\"(%9, %cst_3) {axis = 0 : i32} : (tensor<3xi32>, tensor<1xi32>) -> tensor<1xi32>\r\n  %14 = \"tfl.reduce_prod\"(%13, %cst_30) {keep_dims = false} : (tensor<1xi32>, tensor<1xi32>) -> tensor<i32>\r\n  %15 = \"tfl.pack\"(%11, %14) {axis = 0 : i32, values_count = 2 : i32} : (tensor<i32>, tensor<i32>) -> tensor<2xi32>\r\n  %16 = \"tfl.reshape\"(%8, %15) : (tensor<1x?x40xf32>, tensor<2xi32>) -> tensor<?x?xf32>\r\n  %17 = \"tfl.fully_connected\"(%16, %cst_29, %cst_32) {fused_activation_function = \"NONE\", keep_num_dims = false, weights_format = \"DEFAULT\"} : (tensor<?x?xf32>, tensor<10x40xf32>, none) -> tensor<?x10xf32>\r\n  %18 = \"tfl.reshape\"(%17, %12) : (tensor<?x10xf32>, tensor<3xi32>) -> tensor<?x?x?xf32>\r\n  %19 = \"tfl.add\"(%18, %cst) {fused_activation_function = \"NONE\"} : (tensor<?x?x?xf32>, tensor<10xf32>) -> tensor<?x?x10xf32>\r\n  %20 = \"tfl.softmax\"(%19) {beta = 1.000000e+00 : f32} : (tensor<?x?x10xf32>) -> tensor<?x?x10xf32>\r\n  \"std.return\"(%20) : (tensor<?x?x10xf32>) -> ()\r\n}) {arg0 = {tf_saved_model.index_path = [\"x\"]}, result0 = {tf_saved_model.index_path = [\"output_0\"]}, sym_name = \"serving_default\", tf.entry_function = {control_outputs = \"\", inputs = \"serving_default_x:0\", outputs = \"StatefulPartitionedCall:0\"}, tf_saved_model.exported_names = [\"serving_default\"], type = (tensor<1x?x150xf32>) -> tensor<?x?x10xf32>} : () -> ()\r\n```\r\n\r\n**Failure details**\r\n- Conversion succeeded If I set the STEPS to an integer value (e.g: 100).\r\n- Conversion failed if I set the STEPS to None.", "comments": ["I have tried in colab with TF nightly version and was able to reproduce the issue.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/8b0b90fd1804915af4720029bf7842e4/untitled970.ipynb).Thanks!", "Hi, @ravikyram can you try set the fixed input shape in the concrete function? (In your code, steps are none)\r\n\r\nthanks!", "I got the same error messages on 2.3.0-rc0.", "@invencode As suggested by @renjie-liu , when i changed ` STEPS = None` to ` STEPS = 100`, then there is no error.\r\nPlease check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/c9eaf24c6cf2c87ade6909c469096bbb/untitled970.ipynb). Thanks!\r\n\r\nPlease verify once and close the issue if this was resolved for you. Thanks!", "Hi, @jvishnuvardhan @renjie-liu \r\n\r\n> Failure details\r\n> - Conversion succeeded If I set the STEPS to an integer value (e.g: 100).\r\n> - Conversion failed if I set the STEPS to None.\r\n\r\nI know It works when I set the fixed input shape in the concrete function. \r\nBut, I opened this issue because it doesn't work when I set the dynamic input shape.\r\nI'd like to have tflite model with dynamic input shape.", "> I'd like to have tflite model with dynamic input shape.\r\n\r\nI have the same issue. Is there no way of having a dynamic input shape with an LSTM in tflite...? ", "Only the conversion requires fixed shape, you can resize the input later in the runtime.", "> Only the conversion requires fixed shape, you can resize the input later in the runtime.\r\n\r\nThank you, I was (finally) able to convert it by giving the Input a fixed size before running the converter :-)", "@renjie-liu @JanSo19 I am not able to do this (2.3.0).\r\n\r\nAm I missing something here?\r\n\r\n```python\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras import layers\r\n\r\n\r\ndef get_model():\r\n    inputs = layers.Input(shape=(20, 80))\r\n    outputs, h, c = layers.LSTM(32, return_sequences=True, return_state=True, unroll=True)(inputs)\r\n    return keras.Model(inputs=inputs, outputs=outputs)\r\n\r\n\r\ndef main():\r\n    model_dir = '/tmp/rnnt_toy/model'\r\n    model = get_model()\r\n    model.save(model_dir)\r\n\r\n\r\nif __name__ == '__main__':\r\n    main()\r\n````\r\n\r\nOutput: \r\n\r\n```none\r\nValueError: Unrolling requires a fixed number of timesteps.\r\n````", "Not sure if there was unreported progress made on this issue, but I solved it by going from tensorflow 2.3.0 to 2.4.0.", "@invencode I think this was resolved. I ran your code with `tf-nightly` and everything ran without any issue. Please take a look at the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/19e18d431bc48f6e2b66281639b33ed4/untitled.ipynb). Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40344\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40344\">No</a>\n"]}]