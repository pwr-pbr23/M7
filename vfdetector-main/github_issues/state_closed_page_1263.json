[{"number": 15250, "title": "Batch Norm variance output mismatches with tf 1.4.0", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **TensorFlow installed from  binary**: binary\r\n- **TensorFlow version (use command below)**: 1.4.0\r\n- **Python version**:  2.7.0\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: 8.0/5.0\r\n- **GPU model and memory**: GTX1080 and 8 GB\r\n- **Exact command to reproduce**: python test_google_bn.py\r\n\r\n### Describe the problem\r\nBatch normalization test failed with tensorflow version 1.4.0 but the same test passed with tensorflow version 1.3.0. \r\n\r\n\r\n### Source code / logs\r\n```Python\r\n# test_google_bn.py\r\nimport numpy as np\r\nimport pytest\r\nimport tensorflow as tf\r\nfrom numpy.testing import assert_array_almost_equal\r\nfrom tensorflow.python.ops import control_flow_ops\r\ndef test_delayed_update_moving_vars():\r\n    with tf.Session() as sess:\r\n        height, width = 3, 3\r\n        image_shape = (10, height, width, 3)\r\n        image_values = np.random.rand(*image_shape)\r\n        expected_mean = np.mean(image_values, axis=(0, 1, 2))\r\n        expected_var = np.var(image_values, axis=(0, 1, 2))\r\n        images = tf.constant(image_values, shape=image_shape, dtype=tf.float32)\r\n        decay = 0.1\r\n        epsilon = 1e-5\r\n        output = tf.contrib.layers.batch_norm(images, is_training=True, reuse=None, decay=decay, epsilon=epsilon,\r\n                            updates_collections=tf.GraphKeys.UPDATE_OPS, name='BatchNorm')\r\n        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\r\n        # updates_ops are added to UPDATE_OPS collection.\r\n        assert len(update_ops) == 2\r\n        with tf.control_dependencies(update_ops):\r\n            barrier = tf.no_op(name='barrier')\r\n        output = control_flow_ops.with_dependencies([barrier], output)\r\n        # Initialize all variables\r\n        sess.run(tf.global_variables_initializer())\r\n        moving_mean = tf.contrib.framework.get_variables('BatchNorm/moving_mean')[0]\r\n        moving_variance = tf.contrib.framework.get_variables('BatchNorm/moving_variance')[0]\r\n        mean, variance = sess.run([moving_mean, moving_variance])\r\n        # After initialization moving_mean == 0 and moving_variance == 1.\r\n        assert_array_almost_equal(mean, [0] * 3)\r\n        assert_array_almost_equal(variance, [1] * 3)\r\n        for _ in range(10):\r\n            sess.run([output])\r\n        mean = moving_mean.eval()\r\n        variance = moving_variance.eval()\r\n        # After 10 updates with decay 0.1 moving_mean == expected_mean and\r\n        # moving_variance == expected_var.\r\n        assert_array_almost_equal(mean, expected_mean, decimal=4)\r\n        assert_array_almost_equal(variance, expected_var, decimal=4)\r\n```\r\n\r\n>           assert_array_almost_equal(variance, expected_var, decimal=4)\r\n           AssertionError: \r\n           Arrays are not almost equal to 4 decimals\r\n           \r\n           (mismatch 100.0%)\r\n            x: array([ 0.08  ,  0.0908,  0.0773], dtype=float32)\r\n            y: array([ 0.0792,  0.0898,  0.0764])\r\n\r\n\r\n", "comments": ["Can you try the core version `tf.layers.batch_norm`? This one has stronger support guarantees.", "@drpngx still the tests are falling even if I use `tf.layers.batch_normalization`", "OK, I was confused about the `mismatch=100%` comment, it looks like the numbers are approximately `10%` off. It's not clear to me that after 10 updates you are guaranteed to get that close?", "If I run the same test with tf version `1.3.0`, after 10 updates values are close to 4 decimal points. ", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "I can reproduce the assertion error with TF 1.4.0 CPU. When setting `fused=False` the assertion disappears. TF 1.3.0 has `fused=False` as default.\r\n\r\nThis is sort of an expected behavior that fused operations will have slightly different precision.", "@ppwwyyxx thanks! indeed that was the issue. "]}, {"number": 15249, "title": "fix typo", "body": "", "comments": ["Can one of the admins verify this patch?"]}, {"number": 15248, "title": "Instead of python, use PYTHON_BIN_PATH in pip.sh.", "body": "", "comments": ["Help me understand why this change is necessary. The current approach (https://github.com/tensorflow/tensorflow/pull/15217) works. \r\n`python -m virtualenv` can be used to create virtualenvs containing any desired Python versions, regardless of the Python version of the `python` binary. The desired Python version is specified with the `-p <PATH_TO_PYTHON_BIN>` argument, as in the current approach. For example, if `PATH_TO_PYTHON_BIN` is /usr/bin/python3.6, the created virtualenv will have Python 3.6 inside it, even though the `python` in `python -m virtualenv -p ...` is Python 2.7.\r\n\r\nI verified this with the CPU and GPU builds that we have, e.g.,\r\nhttp://ci.tensorflow.org/view/Experimental/job/experimental-cais-linux-gpu/7/ (the python 3.6 build failure there is unrelated)\r\nhttp://ci.tensorflow.org/view/Tensorflow%20Jenkins%20Monitored%20builds/job/nightly-matrix-linux-gpu/734/ (The no_pip build failure there is unrelated).\r\n\r\nThe approach in this PR has the following problems\r\n1) it is less economical because it requires installation of more packages.\r\n2) `python3.6 -m virtualenv ...` probably doesn't work, because `venv` is required instead.\r\n", "I am more comfortable with using something standard. According to this link:\r\nhttps://stackoverflow.com/questions/41573587/what-is-the-difference-between-venv-pyvenv-pyenv-virtualenv-virtualenvwrappe\r\n`venv` is something that is supposed to be in the core package, but as mentioned in the link \"although for some reason some distros separate it out into a separate distro package, such as  python3-venv on Ubuntu/Debian)\" And we are using ubuntu.\r\nSo it is not guaranteed that venv will always work for us. Which will make things flaky. Once we push our vms to ubuntu 16, we will see flaakes. When we move things to another system, we can see more flakes. Installing virtualenv will just make things stable.\r\n\r\nAs for the economy. Here is the virtualenv package:\r\nhttps://pypi.python.org/pypi/virtualenv\r\nThe size is around 1 MB. docker will compress the images, and this will account to a very small amount.\r\nMoreover, for the docker images this script affects the economy hit is a non-issue because we only use this in CI docker images.", "@gunan, i'm not sure how the comment \"\"although for some reason some distros separate it out into a separate distro package, such as python3-venv on Ubuntu/Debian)\" is relevant here. The comment is about the fact that in some Ubuntu/Debian distros, `venv` is not available in the default python **3** install, but need to be installed separately with the `python3-venv` deb package. This is not relevant to the current working approach of using the virtualenv form python **2** (i.e., the `python-virtualenv` package) to create virtualenvs for whatever target python version desired. `python-virtualenv` is a deb package available on ubuntu 14.04, 16.04, 17.04, and 17.10:\r\n\r\nhttps://packages.ubuntu.com/search?suite=trusty&searchon=names&keywords=python-virtualenv\r\nhttps://packages.ubuntu.com/search?suite=xenial&searchon=names&keywords=python-virtualenv\r\nhttps://packages.ubuntu.com/search?suite=zesty&searchon=names&keywords=python-virtualenv\r\nhttps://packages.ubuntu.com/search?suite=artful&searchon=names&keywords=python-virtualenv\r\n", "Sorry, I realized I missed a key piece of information.\r\nThe current approach does not fully work on all our setups:\r\nhttp://ci.tensorflow.org/view/tf-nightly/job/tf-nightly-linux/\r\n\r\nThis is blocking our nightly binaries for cuda9, which has been a major ask from nvidia and many users.\r\nSo either with this patch, or another I want to roll out a fix today and finally push cuda9 enabled nightlies.", "The specific failure this patch addresses is here:\r\nhttp://ci.tensorflow.org/view/tf-nightly/job/tf-nightly-linux/TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON3.6,label=cpu-slave/150/console", "Ah - that's unfortunate. Sorry I didn't try the PR with tf-nightly jobs. But I'm still not sure if this PR is going to fix all cases. For example, if `$PYTHON_BIN_PATH` points to a python 3 version, the module name used after `-m` should be `venv`, but not `virtualenv`.\r\n", "I have ran the python2 and 3 builds with this PR.\nAfter we do \"pip install virtualenv\" `$PYTHON_BIN_PATH -m virtualenv`\ncommand seems to work on my machine on all the cases I tested.\nIt looks like \"venv\" is just \"commonly together with python3 distros\" but\nwe can always install and use virtualenv.\n\nOn Sun, Dec 10, 2017 at 5:41 PM, Shanqing Cai <notifications@github.com>\nwrote:\n\n> Ah - that's unfortunate. Sorry I didn't try the PR with tf-nightly jobs.\n> But I'm still not sure if this PR is going to fix all cases. For example,\n> if $PYTHON_BIN_PATH points to a python 3 version, the module name used\n> after -m should be venv, but not virtualenv.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/15248#issuecomment-350601816>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AHlCOR0FHrup_WmlQzflQ7YyJ_6gQd3wks5s_IgygaJpZM4Q8aom>\n> .\n>\n", "Done,\r\nSorry, I was looking through the comments, then I realized I misread your first comment, and thought you were aware of the python 3.6 build breakage. My mistake, should have mentioned it in the PR description."]}, {"number": 15247, "title": "Replace `variables.get_global_step()` use `training_util.get_global_step()`", "body": "", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this pleas", "@tensorflow-jeknins test this please", "@izhangzhihao There are test errors: https://ci.tensorflow.org/job/tensorflow-pull-requests-cpu-python3/7544/consoleFull\r\n\r\nCan you please fix them?", "@tensorflow-jenkins test this please", "@caisq All tests passed."]}, {"number": 15246, "title": "Error while running Tensor-Flow examples using Bazel build", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug or a feature request.\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Ubuntu 16.04:\r\n- **TensorFlow installed from source:\r\n- **TensorFlow version 1.4.0:\r\n- **Python 3.5.2: \r\n- **Bazel version 0.8.1:\r\n- gcc version 5.4.1:\r\n- CUDA/cuDNN version:\r\n- GeForce GTX 980M  and 8GB:\r\n- bazel build tensorflow/examples/label_image/...:\r\n\r\n\r\n\r\nI am trying to run this by using the command bazel build tensorflow/examples/label_image/...\r\nbut i am getting the following error:\r\n\r\n```\r\nIn file included from ./tensorflow/core/platform/default/logging.h:24:0,\r\n                 from ./tensorflow/core/platform/logging.h:25,\r\n                 from ./tensorflow/core/lib/core/status.h:25,\r\n                 from ./tensorflow/core/kernels/range_sampler.h:21,\r\n                 from tensorflow/core/kernels/range_sampler.cc:16:\r\n./tensorflow/core/platform/default/logging.h: In instantiation of 'std::__cxx11::string* tensorflow::internal::Check_LEImpl(const T1&, const T2&, const char*) [with T1 = long unsigned int; T2 = long long int; std::__cxx11::string = std::__cxx11::basic_string<char>]':\r\ntensorflow/core/kernels/range_sampler.cc:86:5:   required from here\r\n./tensorflow/core/platform/default/logging.h:230:35: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n TF_DEFINE_CHECK_OP_IMPL(Check_LE, <= )\r\n                                   ^\r\n./tensorflow/core/platform/macros.h:79:29: note: in definition of macro 'TF_PREDICT_TRUE'\r\n #define TF_PREDICT_TRUE(x) (x)\r\n                             ^\r\n./tensorflow/core/platform/default/logging.h:230:1: note: in expansion of macro 'TF_DEFINE_CHECK_OP_IMPL'\r\n TF_DEFINE_CHECK_OP_IMPL(Check_LE, <= )\r\n ^\r\n./tensorflow/core/platform/default/logging.h: In instantiation of 'std::__cxx11::string* tensorflow::internal::Check_EQImpl(const T1&, const T2&, const char*) [with T1 = long long int; T2 = long unsigned int; std::__cxx11::string = std::__cxx11::basic_string<char>]':\r\ntensorflow/core/kernels/range_sampler.cc:244:3:   required from here\r\n./tensorflow/core/platform/default/logging.h:228:25: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n                         == )  // Compilation error with CHECK_EQ(NULL, x)?\r\n                         ^\r\n./tensorflow/core/platform/macros.h:79:29: note: in definition of macro 'TF_PREDICT_TRUE'\r\n #define TF_PREDICT_TRUE(x) (x)\r\n                             ^\r\n./tensorflow/core/platform/default/logging.h:227:1: note: in expansion of macro 'TF_DEFINE_CHECK_OP_IMPL'\r\n TF_DEFINE_CHECK_OP_IMPL(Check_EQ,\r\n ^\r\nERROR: /home/hassaan/Downloads/tensorflow/tensorflow/core/BUILD:1739:1: C++ compilation of rule '//tensorflow/core:framework_internal_impl' failed (Exit 1)\r\nIn file included from ./tensorflow/core/framework/allocator.h:23:0,\r\n                 from ./tensorflow/core/framework/tensor.h:20,\r\n                 from ./tensorflow/core/util/strided_slice_op.h:18,\r\n                 from tensorflow/core/util/strided_slice_op.cc:16:\r\n./tensorflow/core/framework/numeric_types.h: In constructor 'tensorflow::bfloat16::bfloat16(float)':\r\n./tensorflow/core/framework/numeric_types.h:49:16: error: 'isnan' was not declared in this scope\r\n     if (isnan(v)) {\r\n                ^\r\n./tensorflow/core/framework/numeric_types.h:49:16: note: suggested alternatives:\r\nIn file included from /usr/include/c++/5/complex:44:0,\r\n                 from external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/Core:99,\r\n                 from external/eigen_archive/unsupported/Eigen/CXX11/Tensor:14,\r\n                 from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1,\r\n                 from ./tensorflow/core/framework/tensor.h:19,\r\n                 from ./tensorflow/core/util/strided_slice_op.h:18,\r\n                 from tensorflow/core/util/strided_slice_op.cc:16:\r\n/usr/include/c++/5/cmath:641:5: note:   'std::isnan'\r\n     isnan(_Tp __x)\r\n     ^\r\nIn file included from external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/Core:558:0,\r\n                 from external/eigen_archive/unsupported/Eigen/CXX11/Tensor:14,\r\n                 from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1,\r\n                 from ./tensorflow/core/framework/tensor.h:19,\r\n                 from ./tensorflow/core/util/strided_slice_op.h:18,\r\n                 from tensorflow/core/util/strided_slice_op.cc:16:\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/GlobalFunctions.h:88:3: note:   'Eigen::isnan'\r\n   EIGEN_ARRAY_DECLARE_GLOBAL_UNARY(isnan,scalar_isnan_op,not-a-number test,\\sa Eigen::isinf DOXCOMMA Eigen::isfinite DOXCOMMA ArrayBase::isnan)\r\n   ^\r\nIn file included from external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/Core:392:0,\r\n                 from external/eigen_archive/unsupported/Eigen/CXX11/Tensor:14,\r\n                 from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1,\r\n                 from ./tensorflow/core/framework/tensor.h:19,\r\n                 from ./tensorflow/core/util/strided_slice_op.h:18,\r\n                 from tensorflow/core/util/strided_slice_op.cc:16:\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MathFunctions.h:1111:46: note:   'Eigen::numext::isnan'\r\n template<typename T> EIGEN_DEVICE_FUNC bool (isnan)   (const T &x) { return internal::isnan_impl(x); }\r\n                                              ^\r\nIn file included from external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/Core:433:0,\r\n                 from external/eigen_archive/unsupported/Eigen/CXX11/Tensor:14,\r\n                 from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1,\r\n                 from ./tensorflow/core/framework/tensor.h:19,\r\n                 from ./tensorflow/core/util/strided_slice_op.h:18,\r\n                 from tensorflow/core/util/strided_slice_op.cc:16:\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/arch/CUDA/Half.h:380:45: note:   'Eigen::half_impl::isnan'\r\n EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool (isnan)(const half& a) {\r\n```", "comments": ["What options did you specify in your configure step, and are you specifying a `--config` in your build command?", "It looks like `isnan` is missing in both `allocator.h` and `Eigen/Core`. The correct identifier and place to get it in `C++11` is `<cmath>`. Would you mind checking if it's properly included, and if not, send a PR?", "@drpngx  - looks like this was addressed in a PR a few days ago: https://github.com/tensorflow/tensorflow/pull/15189\r\n", "Thanks @quaeler ! @hassaanseeker can you confirm?", "Thanks a lot guys yes the issue was resolved by replacing **if (isnan(v))** with **if (Eigen::numext::isnan(v))** on line 49 in tesnorflow/core/framework/numeric_types.h.", "This should be closed then"]}, {"number": 15245, "title": "add c++ gradient for op: Pow", "body": "Fix  #15239.\r\n\r\n### How to test\r\n\r\n+ [x] add test case.\r\n+ [ ] pass all tests.", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please", "Thanks, @caisq . Git failed to fetch github branch. I think it's an unrelated failure.", "Thank you, @suharshs . I have revised the codes as requested.", "Jenkins, test this please.", "Time out failure:  //tensorflow/python/keras:data_utils_test ", "The test failure is unrelated. Merging PR.", "Looks like this test is flaky.", "This is causing a lot of issues on the dashboard.\r\nI propose a rollback, and then we can figure out if the test is flaky or the new op is."]}, {"number": 15244, "title": "Switched optimization mode for Pi builds to avoid internal compiler error", "body": "The nightly Pi3 builds have been failing with:\r\n\r\n```\r\nIn file included from external/eigen_archive/unsupported/Eigen/MatrixFunctions:57:0,\r\n                 from ./third_party/eigen3/unsupported/Eigen/MatrixFunctions:1,\r\n                 from tensorflow/core/kernels/matrix_exponential_op.cc:19:\r\nexternal/eigen_archive/unsupported/Eigen/src/MatrixFunctions/MatrixFunction.h: In member function 'MatrixType Eigen::internal::MatrixFunctionAtomic<MatrixType>::compute(const MatrixType&) [with MatrixType = Eigen::Matrix<std::complex<float>, -1, -1>]':\r\nexternal/eigen_archive/unsupported/Eigen/src/MatrixFunctions/MatrixFunction.h:101:1: internal compiler error: in decompose_normal_address, at rtlanal.c:5799\r\n }\r\n ^\r\nPlease submit a full bug report,\r\nwith preprocessed source if appropriate.\r\nSee <http://gcc.gnu.org/bugs.html> for instructions.\r\n```\r\n\r\nIt appears to be the same problem that Chrome hit with gcc here:\r\n\r\nhttps://bugs.chromium.org/p/chromium/issues/detail?id=675648\r\n\r\nTheir solution was to change the optimization flags to avoid this, so I've followed their lead and switched to -O3. I hope this won'tl make a big latency or size difference, but it does solve the compiler crash at least.", "comments": ["Jenkins, test this please."]}, {"number": 15243, "title": "Add support for explicit broadcasting in TensorFlow", "body": "This fix tries to adds support for explicit broadcasting in TensorFlow, as was suggested in #14509. This fix adds the op of tf.broadcast_to, which is equivalent to the numpy.broadcast_to in numpy.\r\n\r\nThis fix fixes #14509.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["@rmlarsen Do you want to review this CL? @martinwicke I assume this requires an API review.", "@alextp Thanks for the review. The PR has been updated. Please take a look and let me know if there are any issues.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "@av8ramit Is this nag (wording) appropriate since this has \"awaiting response\"?", "@martinwicke yeah might need to toggle the state machine a bit. ", "@yongtang can you look at the latest comments?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "The doctoring has been updated. Will find a GPU machine to test and enable GPU kernel.", "Is that normal I can't see `tf.broadcast_to` in the last 1.8.0 version?\r\n\r\n", "Yes. The 1.8 branch was cut before this PR was merged. ", "I just compiled the \"r1.9\" branch, but there is still no \"tf.broadcast_to\":\r\n```\r\n>>> tf.__version__\r\n'1.9.0-rc0'\r\n>>> tf.broadcast_to\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\nAttributeError: module 'tensorflow' has no attribute 'broadcast_to'\r\n```\r\nHow can I get a Tensorflow-Version supporting this?", "This PR added the op, but hid it by adding this file: tensorflow/core/api_def/python_api/api_def_BroadcastTo.pbtxt\r\n\r\nNot sure whether that was intentional, but removing that file should make this op visible.", "Removing means deleting it?\r\nAnd then re-compile or just re-package?", "I think that would be sufficient.\u200b\n", "Thank you very much, deleting that file and recompiling everything did the trick!", "@Hoeze The op is exposed as `tf.contrib.framework.broadcast_to` for now (See https://github.com/tensorflow/tensorflow/pull/15243#discussion_r178889285):\r\n```\r\n# python\r\nPython 2.7.12 (default, Dec  4 2017, 14:50:18) \r\n[GCC 5.4.0 20160609] on linux2\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\n>>> tf.__version__\r\n'1.9.0-dev20180604'\r\n>>> tf.contrib.framework.broadcast_to\r\n<function broadcast_to at 0x7f1f8588c230>\r\n>>> \r\n```", "\u200bCould you send a PR? I don't see a reason to hide this op.\n", "@martinwicke @Hoeze The PR #19753 has been created to expose `tf.broadcast_to`.", "@yongtang This patch should be merged to `r1.9` branch as well, shouldn't it?"]}, {"number": 15242, "title": "Error using alexnet with Faster-RCNN?", "body": "Hi everyone, \r\nI am doing object categories detection on COCO dataset using transfer learning (alexnet as a pre-trained with Faster RCNN). However, I am getting this error.\r\n\r\n> Warning: An error occurred while using @(x)d.propose(x,minBoxSize,'MiniBatchSize',miniBatchSize) to process\r\n> /train2014/COCO_train2014_000000256230.jpg:\r\n> Expected input number 2, score, to be of size Mx1, but it is of size 0x0.\r\n> Regions from this image will not be used for training. \r\n> In fastRCNNObjectDetector.invokeRegionProposalFcn (line 268)\r\n  In fastRCNNObjectDetector>@(x,filename)fastRCNNObjectDetector.invokeRegionProposalFcn(fcnCopy,x,filename) (line 158)\r\n  In fastRCNNObjectDetector.extractRegionProposals (line 218)\r\n  In fastRCNNObjectDetector.train (line 168)\r\n  In trainFasterRCNNObjectDetector (line 359)\r\n  In detection (line 75)\r\n\r\n\r\n**Can you please help me? \r\nPlease have a look at the code, and let me know if there is any mistake?\r\n\r\nThank you very much for your help and time in advance**\r\n\r\nP.S. training data (annotation) is stored in a table, where the first column contains paths and file names to images. The remaining columns contain bounding boxes related to the corresponding images. Each column represents a single object class, such as a person, bicycle, car \u2026 etc, as explained on https://uk.mathworks.com/help/vision/ref/trainfasterrcnnobjectdetector.html.\r\n\r\n     \u2018clear all\r\n    close all\r\n    clc\r\n    Train_data= load('************.mat'); %Load vehicle data set\r\n    addpath('************'); % path of the training images\r\n    numClasses = width(Train_data);\r\n    Train_data(1:3,:)% Display first few rows of the data set.\r\n    I = imread(Train_data.imageFilename{6}); % display one of the images with the bbox, \r\n    I = insertShape(I, 'Rectangle', Train_data.person{6});\r\n    I = imresize(I, 3);\r\n    figure\r\n    imshow(I)\r\n    net = alexnet; % loading pre-trained model (alexnet in this case)\r\n    net.Layers\r\n    layersTransfer = net.Layers(1:end-3);\r\n    layers = [\r\n        layersTransfer\r\n        fullyConnectedLayer(numClasses,'WeightLearnRateFactor',20,'BiasLearnRateFactor',20)\r\n        softmaxLayer\r\n        classificationLayer];\r\n    optionsStage1 = trainingOptions('sgdm', ...\r\n        'MaxEpochs', 10, ...\r\n        'InitialLearnRate', 1e-5);% Options for step 1.\r\n    optionsStage2 = trainingOptions('sgdm', ...\r\n        'MaxEpochs', 10, ...\r\n        'InitialLearnRate', 1e-5);% Options for step 2.\r\n    optionsStage3 = trainingOptions('sgdm', ...\r\n        'MaxEpochs', 10, ...\r\n        'InitialLearnRate', 1e-6); % Options for step 3.\r\n    optionsStage4 = trainingOptions('sgdm', ...\r\n        'MaxEpochs', 10, ...\r\n        'InitialLearnRate', 1e-6);% Options for step 4.\r\n    options = [\r\n        optionsStage1\r\n        optionsStage2\r\n        optionsStage3\r\n        optionsStage4\r\n        ];\r\n    doTrainingAndEval = true; % Training network \r\n    if doTrainingAndEval\r\n        rng(0);\r\n        detector = trainFasterRCNNObjectDetector(Train_data, layers, options, ...\r\n            'NegativeOverlapRange', [0 0.3], ...\r\n            'PositiveOverlapRange', [0.6 1], ...\r\n            'BoxPyramidScale', 1.2);\r\n    else\r\n        detector=load('*********.mat').\r\n    end\r\n    Test_data= load('************.mat');% tesing and evaluation  \r\n    addpath('************'); % path of the testing image\r\n    Test_data.imageFilename =Test_data.imageFilename;\r\n    I = imread(Test_data.imageFilename{452}); % Read one of the images.\r\n     [bboxes, scores,label] = detect(detector, I);% Run the detector.\r\n    I = insertObjectAnnotation(I, 'rectangle', bboxes, scores);% Annotate detections in the image.\r\n    figure\r\n    imshow(I)\r\n    if doTrainingAndEval\r\n            resultsStruct = struct([]); % Run detector on each image in the test set and collect results.\r\n        for i = 1:height(Test_data)\r\n             I = imread(Test_data.imageFilename{i});        % Read the image.\r\n            [bboxes, scores, labels] = detect(detector, I);        % Run the detector.\r\n            resultsStruct(i).Boxes = bboxes;        % Collect the results.\r\n            resultsStruct(i).Scores = scores;\r\n           resultsStruct(i).Labels = labels;\r\n       end\r\n         results = struct2table(resultsStruct);    % Convert the results into a table.\r\n    else\r\n        results = data.results;    % Load results from disk.\r\n    end\r\n    expectedResults = testData(:, 2:end); % Extract expected bounding box locations from test data.\r\n     [ap, recall, precision] = evaluateDetectionPrecision(results, expectedResults);% Evaluate the    object detector using Average Precision metric.\r\n    figure;% Plot precision/recall curve\r\n    plot(recall, precision)\r\n    xlabel('Recall')\r\n    ylabel('Precision')\r\n    grid on\r\n    title(sprintf('Average Precision = %.1f', ap))\u2019\r\n\r\n  \r\n\r\n\r\nHave I written custom code: I did the code, following the instructions available on matlab both Faster RCNN detection, and transfer learning webpages (https://uk.mathworks.com/help/vision/examples/object-detection-using-faster-r-cnn-deep-learning.html) and (https://uk.mathworks.com/help/nnet/ug/pretrained-convolutional-neural-networks.html#bvm8b5x) respectively  \r\nOS Platform and Distribution: Linux, MATLAB2017a\r\nCUDA/cuDNN version: 8.0, V8.0.44\r\nGPU model and memory: NVIDIA Tesla K80\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "This seems to be a bug in your code rather than with TensorFlow itself. Due to the huge volume of issues the TensorFlow team isn't able to provide help on this type of situation but only to bugs with TensorFlow or feature requests on Github. This question is better suited for StackOverflow which is also monitored under the TensorFlow tag.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue? Please update the label and/or status accordingly.", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 15241, "title": "Error using Faster RCNN in MATLAB. ", "body": "Hi there, \r\nI am working on a project that is about detecting multiple object classes (object classes detection), where the dataset that I am using is MSCOCO (2014). \r\nThe method that I am using is Faster RCNN detection method, where I am using matlab 2017a\r\nPlease note that all training is done on a machine with a GPU (NVIDIA Tesla K80)\r\nI have wrote the code attached in the zipped file, dropbox link for downloading is presented below. I have done this code by following the instructions available on matlab transfer learning page; it is about using alexnet as a pre-trained mode for Faster RCNN. Can you kindly have a look at the code and let me know, it has any errors, because I am getting an error when doing the evaluation  \r\nError is:  \r\nError using fasterRCNNObjectDetector/parseDetectInputs (line 680)\r\nThe size of I must be larger than [227 227]. The minimum size is defined by the network's image input layer.\r\nError in fasterRCNNObjectDetector/detect (line 447)\r\n            params = this.parseDetectInputs(I, varargin{:});\r\nI have resized the image to [400 400], which passed this errors, but still have another error with plotting the accuracy, IF I use less than 400 (e.g., [300 300]), the error will still appear, which I am not sure why, because alexnet input layer is in the size of [227 227], where 300 is still larger than. \r\nError is: I am getting all the average precision (ap), recall values as zeros (0). \r\n\r\nTo download the code and all materials: https://www.dropbox.com/sh/9u56ragkuz1ltgd/AADKvUXESezWsoaGfgLyE0Exa?dl=0 \r\nPlease note the zipped file contains: \r\n1) the training (transfer learning) code, named as run_20_classes.m\r\n2) .mat file,  named as pre-trained_20_classes.mat that contains the training and testing labels (annotations), stored as a table, where the first column contains paths and file names to images. The remaining columns contain bounding boxes related to the corresponding images. Each column represents a single object class, such as a person, bicycle, car \u2026 etc, as explain on https://uk.mathworks.com/help/vision/ref/trainfasterrcnnobjectdetector.html. This mat file also includes the results of detection, saved as detector  the evaluation results.\r\n3) testing code, named as Testing.m\r\n\r\nTraining images can be downloaded from: http://images.cocodataset.org/zips/train2014.zip \r\nTesting images can be downloaded from: http://images.cocodataset.org/zips/val2014.zip \r\n\r\n**Can you please help me on how to improve the accuracy, or if my code is mistaken, can you please correct it?**\r\nThank you very much for your help and time in advance \r\n\r\n\r\nHave I written custom code: I did the code, following the instructions available on matlab both Faster RCNN detection, and transfer learning webpages (https://uk.mathworks.com/help/vision/examples/object-detection-using-faster-r-cnn-deep-learning.html) and (https://uk.mathworks.com/help/nnet/ug/pretrained-convolutional-neural-networks.html#bvm8b5x) respectively\r\nOS Platform and Distribution: Linux, MATLAB2017a\r\nCUDA/cuDNN version: 8.0, V8.0.44\r\nGPU model and memory: NVIDIA Tesla K80\r\nExact command to reproduce: training code (run_20_classes.m), testing (Testing.m)", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "I already answered a similar question you submitted on your other open issue. Please refer to https://github.com/tensorflow/tensorflow/issues/15242#issuecomment-351159204", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue? Please update the label and/or status accordingly.", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 29 days with no activity and the `awaiting response` label was assigned. Is this still an issue?"]}, {"number": 15240, "title": "in minimize     ([str(v) for _, v in grads_and_vars], loss)) ValueError: No gradients provided for any variable - This error occurs while using minimize for an adam optimizer()", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug or a feature request.\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**: \r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["The code for which I am facing the issue.\r\n\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow.examples.tutorials.mnist import input_data\r\nmnist = input_data.read_data_sets('MNIST_data', one_hot = True)\r\n'''/tmp/data/'''\r\nn_classes = 10\r\nbatch_size = 150\r\n\r\nx = tf.placeholder(tf.float32, shape=[None, 784])\r\ny = tf.placeholder(tf.float32, shape=[None, 10])\r\n\r\nkeep_rate = 0.8\r\nkeep_prob = tf.placeholder(tf.float32)\r\n\r\ndef conv2d(x, W):\r\n    return tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='SAME')\r\n\r\ndef maxpool2d(x):\r\n    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\r\n\r\n\r\n\r\ndef convolutional_neural_network(x):\r\n    weights = {'W_conv1':tf.Variable(tf.random_normal([5,5,1,32])),\r\n               'W_conv2':tf.Variable(tf.random_normal([5,5,32,64])),\r\n               'W_fc':tf.Variable(tf.random_normal([7*7*64,1024])),\r\n               'out':tf.Variable(tf.random_normal([1024, n_classes]))}\r\n\r\n    biases = {'b_conv1':tf.Variable(tf.random_normal([32])),\r\n               'b_conv2':tf.Variable(tf.random_normal([64])),\r\n               'b_fc':tf.Variable(tf.random_normal([1024])),\r\n               'out':tf.Variable(tf.random_normal([n_classes]))}\r\n\r\n    x = tf.reshape(x, shape=[-1, 28, 28, 1])\r\n\r\n    conv1 = tf.nn.relu(conv2d(x, weights['W_conv1']) + biases['b_conv1'])\r\n    conv1 = maxpool2d(conv1)\r\n    \r\n    conv2 = tf.nn.relu(conv2d(conv1, weights['W_conv2']) + biases['b_conv2'])\r\n    conv2 = maxpool2d(conv2)\r\n\r\n    fc = tf.reshape(conv2,[-1, 7*7*64])\r\n    fc = tf.nn.relu(tf.matmul(fc, weights['W_fc'])+biases['b_fc'])\r\n    fc = tf.nn.dropout(fc, keep_rate)\r\n\r\n    output = tf.matmul(fc, weights['out'])+biases['out']\r\n\r\n    return output\r\n\r\ndef train_neural_network(x):\r\n    prediction = convolutional_neural_network(x)\r\n    cost = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits(labels=prediction,logits=y))\r\n    optimizer = tf.train.AdamOptimizer(1e-4).minimize(cost)\r\n    \r\n    hm_epochs = 10\r\n    with tf.Session() as sess:\r\n        sess.run(tf.global_variables_initializer())\r\n\r\n        for epoch in range(hm_epochs):\r\n            epoch_loss = 0\r\n            for _ in range(int(mnist.train.num_examples/batch_size)):\r\n                epoch_x, epoch_y = mnist.train.next_batch(batch_size)\r\n                _, c = sess.run([optimizer, cost], feed_dict={x: epoch_x, y: epoch_y})\r\n                epoch_loss += c\r\n\r\n            print('Epoch', epoch, 'completed out of',hm_epochs,'loss:',epoch_loss)\r\n\r\n        correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\r\n        accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\r\n        print('Accuracy:',accuracy.eval({x:mnist.test.images, y:mnist.test.labels}))\r\n\r\ntrain_neural_network(x)\r\n```\r\n", "Please re-file an issue with the template properly filled out. It takes time for us to support issues and our time is limited. Thank you."]}, {"number": 15239, "title": "No gradient defined for op: Pow", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10 x64\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.4\r\n- **Bazel version**: N/A\r\n- **Python version**: None\r\n- **CUDA/cuDNN version**: None\r\n- **GPU model and memory**: None\r\n- **Exact command to reproduce**: -\r\n\r\n### Describe the problem\r\nIt seems there is no gradient defined for the Pow operation in the C++ API.\r\n\r\nI am actually transferring this issue from https://github.com/migueldeicaza/TensorFlowSharp/issues/187. Similar to the case of Select (#14845), it seems there is also no gradient for the Pow operation in the C++ API.", "comments": ["@cesarsouza I have created a PR  #15245 to resolve the issue.", "Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nBazel version", "Huge thanks @facaiy! Also I've just noticed that I used the wrong title for the issue, probably it seemed confusing at first. Sorry about it, and thanks again for the extremely fast PR!", "Is this issue fixed now. Because i get the same error with 1.9\r\n\r\nC++/C# Tensorflow is useles if you want to build your model.", "The PR has been merged, so I think the issue is fixed. Could you give an example? "]}, {"number": 15238, "title": "CPU usage drops after several steps", "body": "I am running a tensorflow computation graph. The same graph was running fine before but all of a sudden I noticed that after several steps and checkpoint the CPU usage drops from more than 600% to 100% for the rest of the session. It seems like all executors are dying (when saving maybe) and the computation keeps running on only 1 Core shooting up and down from 100 to 200%.\r\n\r\nI also posted the issue on stack overflow: https://stackoverflow.com/questions/47720893/tensor-flow-cpu-usage-drops-after-saving\r\n\r\n  ", "comments": ["Any logs? I'm assuming this is training? Single machine? What does `nvidia-smi` say? Can you fill out the template with system arch etc?", "Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Thank you.\r\nhere are the info\r\n\r\n\r\nHave I written custom code: \r\nYES\r\n\r\nOS Platform and Distribution:\r\nMacBook Pro (Retina, 15-inch, Mid 2015)\r\nProcessor 2.8 GHz Intel Core i7\r\nMemory 16 GB 1600 MHz DDR3\r\n\r\nTensorFlow installed from\r\nusing pip \r\n\r\nTensorFlow version\r\n1.4.1\r\n\r\nBazel version\r\nBuild label: 0.4.4-homebrew\r\nBuild target: bazel-out/local-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Thu Feb 2 01:06:46 2017 (1485997606)\r\nBuild timestamp: 1485997606\r\nBuild timestamp as int: 1485997606\r\n\r\nCUDA/cuDNN version\r\nN/A\r\n\r\nGPU model and memory\r\nN/A\r\n\r\nExact command to reproduce\r\nI provided the code.\r\n\r\nI was running very similar code on jupiter notebook for maybe 1 month. All of a sudden I started having the CPU dropping issues. Those issues are not persistent and I am getting no error message or warning.\r\nAny logs? No or not sure where to get them\r\n\r\n I'm assuming this is training?  Yes\r\n\r\nSingle machine?  Yes\r\n\r\nThank you.\r\n\r\n", "Can you post code that reproduces the problem?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue? Please update the label and/or status accordingly.", "Sorry for not replying earlier. The code producing the drop to 1 core is attached in the first message.\r\nBut regardless please close the issue thread because for whatever reason now it's been working without any issue for more than a week. magic !"]}, {"number": 15237, "title": "[Feature Request]Add SGDR, SGDW, AdamW and AdamWR", "body": "This is a duplicate request from pytorch issue, which I even reuse their issue title\r\nhttps://github.com/pytorch/pytorch/issues/3790\r\n\r\nAnd the fix from the paper seems to be trivial but I'm not sure how TF should approach this, perhaps just adding another parameter?", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Would be great if this added to Tensorflow.", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Yes, this methods still haven't got implementation in tensorflow", "@qianyizhang @NProkoptsev SGDR was added as `tf.train.cosine_decay` and `tf.train.cosine_decay_restarts`\r\nSee https://github.com/tensorflow/tensorflow/blob/9bdb72e124e50e1b12b3286b38cbb1c971552741/tensorflow/python/training/learning_rate_decay.py#L487", "@qianyizhang @NProkoptsev For SGDW and AdamW, just check the code. https://github.com/tensorflow/tensorflow/blob/9bdb72e124e50e1b12b3286b38cbb1c971552741/tensorflow/core/kernels/training_ops.cc#L284 It seems they do not apply weight decay for Adam and Momentum.\r\nI just checked the Apply Gradient part, and I think they won't apply weight decay when calculate gradient.\r\nSo I think nothing to FIX.\r\nIf you want something like AdamW (Adam + weight decay), you can add L2 regularization yourself.\r\nI also checked the implementation of mxnet. They do support weight decay, and with the wrong way (based on that paper).\r\nhttps://github.com/apache/incubator-mxnet/blob/d511d98aeadf4392f8c4c1289d15feecdd98bf81/src/operator/optimizer_op-inl.h#L718\r\nCorrect me if I'm wrong.", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "@iron9light in fact, author states that L2 regularization is not equal to weight decay. He proposes to move weight decay term to update of x_t.\r\nThe paper has updated recently, and it's more clear now.\r\nhttps://arxiv.org/pdf/1711.05101.pdf", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "When will SGDW, AdamW be added to tensorflow??", "Isn't SGDW just SGD with L2 reg?", "Seems so, I don't think there's anything actionable here.  Just add weight decay to the graph yourself.", "Are we as a community saying that L2 regularization works just as well as true weight decay with the ADAM optimizer? The paper argues that it does not.", "I misread.  I don't know anyone working on this; and it sounds like it would need to be implemented at the op level.  The interested implementer will need to write a custom kernel (+ GPU support if possible, + sparse update support) in tf.contrib.", "To clarify: the request is for implementations of AdamW, AdamWR from [this paper](https://arxiv.org/abs/1711.05101).", "@ebrevdo I think #17438 has implemented AdamW, however it updates variable outside.", "@facaiy \r\nI used the fact that the apply_ functions already get the precomputed gradient and Adam + Momentum optimizers don't compute values based on `var`, so it's equivalent to pre-decay. However, I just checked the apply functions of other optimizers and e.g. `Ftrl` computes factors based on `var`, so decoupling decay for such optimizers would indeed need a custom op. I'll leave a comment in the PR.\r\n", "So is this still an open issue? Please let me know if it is I would love to contribute. @ebrevdo ", "Also I would love to implement AMSGrad (I did a tf implementation for fun here: http://bit.ly/2J6MRVb). And I was just wanting to know if this can be added as well. ", "@JaeDukSeo that would be awesome! And as far as I know, it is still very open. I'm looking forward to trying it (but got no time to implement it myself).\r\nAlso, a few TF implementations of AMSGrad already exist. I've been using [this one](https://github.com/taki0112/AMSGrad-Tensorflow), which is significantly slower than \"vanilla\" Adam, but seems to be correct.", "There's an existing PR for  weight decay  (linked above), but I was busy the last few weeks due to ICRA. My plan is to finish this next Sunday. However this doesn't include AMSgrad, but I guess that's a separate issue ;)", "how to use tf.train.cosine_decay_restarts to implement AdamWR? ", "@phybrain I can't have Adam optimizer update learning rate from cosine_decay_restarts. So I what I did was initializing a new optimizer at each training step with the new learning rate from decay as parameter."]}, {"number": 15236, "title": "Error while using cuda-9.0, libcublas.so.8.0: cannot open shared object file: No such file or directory", "body": "Hi,\r\n\r\nI just installed cuda-9.0\r\nand done all the requirements for cuda to run tensorflow like libcudnn7_7.0.5.15-1+cuda9.0_amd64.deb, libcudnn7-dev_7.0.5.15-1+cuda9.0_amd64.deb.\r\nThe test example of libcudnn are working fine.\r\n\r\nI installed tensorflow-gpu, it finished normally while using \"$ sudo pip3 install tensorflow-gpu\" but at the time of import, it gives me  error \" \r\nImportError: libcublas.so.8.0: cannot open shared object file: No such file or directory\"\r\nLook like tensorflow doesn't support Cuda-9.0?\r\n\r\nError is as follows:\r\n\r\n$ ipython\r\nPython 3.5.2 (default, Nov 23 2017, 16:37:01) \r\nType 'copyright', 'credits' or 'license' for more information\r\nIPython 6.2.1 -- An enhanced Interactive Python. Type '?' for help.\r\n\r\nIn [1]: import tensorflow as tf\r\n---------------------------------------------------------------------------\r\nImportError                               Traceback (most recent call last)\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow.py in <module>()\r\n     57 \r\n---> 58   from tensorflow.python.pywrap_tensorflow_internal import *\r\n     59   from tensorflow.python.pywrap_tensorflow_internal import __version__\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py in <module>()\r\n     27             return _mod\r\n---> 28     _pywrap_tensorflow_internal = swig_import_helper()\r\n     29     del swig_import_helper\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py in swig_import_helper()\r\n     23             try:\r\n---> 24                 _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n     25             finally:\r\n\r\n/usr/lib/python3.5/imp.py in load_module(name, file, filename, details)\r\n    241         else:\r\n--> 242             return load_dynamic(name, filename, file)\r\n    243     elif type_ == PKG_DIRECTORY:\r\n\r\n/usr/lib/python3.5/imp.py in load_dynamic(name, path, file)\r\n    341             name=name, loader=loader, origin=path)\r\n--> 342         return _load(spec)\r\n    343 \r\n\r\nImportError: libcublas.so.8.0: cannot open shared object file: No such file or directory\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nImportError                               Traceback (most recent call last)\r\n<ipython-input-1-64156d691fe5> in <module>()\r\n----> 1 import tensorflow as tf\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/__init__.py in <module>()\r\n     22 \r\n     23 # pylint: disable=wildcard-import\r\n---> 24 from tensorflow.python import *\r\n     25 # pylint: enable=wildcard-import\r\n     26 \r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/__init__.py in <module>()\r\n     47 import numpy as np\r\n     48 \r\n---> 49 from tensorflow.python import pywrap_tensorflow\r\n     50 \r\n     51 # Protocol buffers\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow.py in <module>()\r\n     70 for some common reasons and solutions.  Include the entire stack trace\r\n     71 above this error message when asking for help.\"\"\" % traceback.format_exc()\r\n---> 72   raise ImportError(msg)\r\n     73 \r\n     74 # pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\r\n\r\nImportError: Traceback (most recent call last):\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"/usr/lib/python3.5/imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"/usr/lib/python3.5/imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: libcublas.so.8.0: cannot open shared object file: No such file or directory\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\n\r\n\r\nPlease go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug or a feature request.\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: No use pip install tensorflow\r\n- **TensorFlow version (use command below)**: tensorflow_gpu-1.4.1-cp35-cp35m-manylinux1_x86_64.whl \r\n- **Python version**:  Python 3.5.2 (default, Nov 23 2017, 16:37:01)\r\n- **Bazel version (if compiling from source)**:No\r\n- **GCC/Compiler version (if compiling from source)**: No\r\n- **CUDA/cuDNN version**:  cuda-9.0\r\n- **GPU model and memory**: GeForce GT 750M\r\n- **Exact command to reproduce**: No just import tensorflow as tf\r\n                                                         \r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["You are missing that shared library. Can you run `ldconfig -v` to see which one you have? I have seen another report where the cublas `9.0` was installed.", "Hi,\r\nIt look like its there,\r\n\r\nldconfig -v \r\n/sbin/ldconfig.real: Can't stat /lib/i686-linux-gnu: No such file or directory\r\n/sbin/ldconfig.real: Can't stat /usr/lib/i686-linux-gnu: No such file or directory\r\n/sbin/ldconfig.real: Path `/usr/lib/nvidia-384' given more than once\r\n/sbin/ldconfig.real: Path `/usr/lib32/nvidia-384' given more than once\r\n/sbin/ldconfig.real: Path `/lib/x86_64-linux-gnu' given more than once\r\n/sbin/ldconfig.real: Path `/usr/lib/x86_64-linux-gnu' given more than once\r\n/usr/local/cuda-8.0/targets/x86_64-linux/lib:\r\n/sbin/ldconfig.real: /usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudnn.so.5 is not a symbolic link\r\n\r\n\tlibcudnn.so.5 -> libcudnn.so.5.0.5\r\n/usr/local/cuda-9.0/targets/x86_64-linux/lib:\r\n\tlibnppitc.so.9.0 -> libnppitc.so.9.0.176\r\n\tlibcublas.so.9.0 -> libcublas.so.9.0.176\r\n\tlibOpenCL.so.1 -> libOpenCL.so.1.0.0\r\n\tlibcufftw.so.9.0 -> libcufftw.so.9.0.176\r\n\tlibnppicom.so.9.0 -> libnppicom.so.9.0.176\r\n\tlibcusolver.so.9.0 -> libcusolver.so.9.0.176\r\n\tlibnppicc.so.9.0 -> libnppicc.so.9.0.176\r\n\tlibnppial.so.9.0 -> libnppial.so.9.0.176\r\n\tlibnppidei.so.9.0 -> libnppidei.so.9.0.176\r\n\tlibnppig.so.9.0 -> libnppig.so.9.0.176\r\n\tlibnvblas.so.9.0 -> libnvblas.so.9.0.176\r\n\tlibnvrtc.so.9.0 -> libnvrtc.so.9.0.176\r\n\tlibnvrtc-builtins.so.9.0 -> libnvrtc-builtins.so.9.0.176\r\n\tlibnppist.so.9.0 -> libnppist.so.9.0.176\r\n\tlibnppisu.so.9.0 -> libnppisu.so.9.0.176\r\n\tlibcurand.so.9.0 -> libcurand.so.9.0.176\r\n\tlibnvgraph.so.9.0 -> libnvgraph.so.9.0.176\r\n\tlibnpps.so.9.0 -> libnpps.so.9.0.176\r\n\tlibnppc.so.9.0 -> libnppc.so.9.0.176\r\n\tlibcudart.so.9.0 -> libcudart.so.9.0.176\r\n...\r\n...\r\n", "Yeah, it looks like you have `9.0`, not `8.0` that the software is looking for. Please install `8.0` for now.", "Well i found a solution by installation through source code.\r\nin git log file(b43d0f3) \" git log --oneline --decorate\" Is saw **upgrade**!\r\n\r\n(HEAD -> master, origin/master, origin/HEAD) Merge pull request #15233 from ManHyuk/typo\r\n70644fc fix typo\r\n688bc53 Merge pull request #15225 from Androbin/patch-1\r\n8267844 Enable GCS filesystem for Windows (#14856)\r\nd3e35f9 Also install libssl-dev to make pip/py3.6 work properly. (#15226)\r\nc470142 Update .gitignore\r\n3a05c11 Merge pull request #15195 from rongjiecomputer/wav\r\n0e49c54 Merge pull request #15021 from freedomtan/bmp-doc\r\n774f4d3 Merge pull request #15205 from tensorflow/gunan-patch-1\r\ncae2e56 Delete Dockerfile.devel-gpu-cuda9-cudnn7\r\nb43d0f3 **Upgrade cuda to 9 and cudnn version to 7. (#14773)**\r\nf7d392d Merge pull request #15197 from caisq/nomac-tag\r\n28b92cd Fix tag in source_remote_test: no_mac --> nomac\r\n\r\nThan I fallowed the instructions mentioned at \r\nhttps://gist.github.com/Brainiarc7/6d6c3f23ea057775b72c52817759b25c\r\n\r\nAnd done (for python2.7!)\r\n\r\n$ ipython2\r\nPython 2.7.12 (default, Dec  4 2017, 14:50:18) \r\nType \"copyright\", \"credits\" or \"license\" for more information.\r\n\r\nIPython 4.0.1 -- An enhanced Interactive Python.\r\n?         -> Introduction and overview of IPython's features.\r\n%quickref -> Quick reference.\r\nhelp      -> Python's own help system.\r\nobject?   -> Details about 'object', use 'object??' for extra details.\r\n\r\nIn [1]: import tensorflow as tf\r\n\r\nIn [2]: sess = tf.Session()\r\n2017-12-10 13:28:46.568828: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:895] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2017-12-10 13:28:46.569233: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1062] Found device 0 with properties: \r\nname: GeForce GT 750M major: 3 minor: 0 memoryClockRate(GHz): 0.967\r\npciBusID: 0000:04:00.0\r\ntotalMemory: 1.95GiB freeMemory: 1.72GiB\r\n2017-12-10 13:28:46.569263: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1152] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GT 750M, pci bus id: 0000:04:00.0, compute capability: 3.0)\r\n\r\n\r\n\r\n ", "Great!\n\nOn Sat, Dec 9, 2017, 9:39 PM DrSajid <notifications@github.com> wrote:\n\n> Well i found a solution by installation through source code.\n> in git log file(b43d0f3\n> <https://github.com/tensorflow/tensorflow/commit/b43d0f3c98140edfebb8295ea4a4b661e2fc2a85>)\n> \" git log --oneline --decorate\"\n>\n> (HEAD -> master, origin/master, origin/HEAD) Merge pull request #15233\n> <https://github.com/tensorflow/tensorflow/pull/15233> from ManHyuk/typo\n> 70644fc\n> <https://github.com/tensorflow/tensorflow/commit/70644fc0427e77f9a34f538cce5badea2f34b4ae>\n> fix typo\n> 688bc53\n> <https://github.com/tensorflow/tensorflow/commit/688bc53eb1bacec6f9145d35280837414ec3cdea>\n> Merge pull request #15225\n> <https://github.com/tensorflow/tensorflow/pull/15225> from\n> Androbin/patch-1\n> 8267844\n> <https://github.com/tensorflow/tensorflow/commit/826784467ecd0fed8e44645ef1032496fed88ba5>\n> Enable GCS filesystem for Windows (#14856\n> <https://github.com/tensorflow/tensorflow/pull/14856>)\n> d3e35f9\n> <https://github.com/tensorflow/tensorflow/commit/d3e35f9d8a168d2fdb73b6fa9d7f4b4114cc508d>\n> Also install libssl-dev to make pip/py3.6 work properly. (#15226\n> <https://github.com/tensorflow/tensorflow/pull/15226>)\n> c470142\n> <https://github.com/tensorflow/tensorflow/commit/c470142122c47d4ea3d91b2204d5da4f581095dd>\n> Update .gitignore\n> 3a05c11\n> <https://github.com/tensorflow/tensorflow/commit/3a05c119d8499c3b1e0a3ef6520af3e62738a80c>\n> Merge pull request #15195\n> <https://github.com/tensorflow/tensorflow/pull/15195> from\n> rongjiecomputer/wav\n> 0e49c54\n> <https://github.com/tensorflow/tensorflow/commit/0e49c5453145fb9fe60fb08827be27081061620a>\n> Merge pull request #15021\n> <https://github.com/tensorflow/tensorflow/pull/15021> from\n> freedomtan/bmp-doc\n> 774f4d3\n> <https://github.com/tensorflow/tensorflow/commit/774f4d3360f904d878c22e345826c096ec6e9972>\n> Merge pull request #15205\n> <https://github.com/tensorflow/tensorflow/pull/15205> from\n> tensorflow/gunan-patch-1\n> cae2e56\n> <https://github.com/tensorflow/tensorflow/commit/cae2e561003bd04aed0be95aec49fd02adcddeb6>\n> Delete Dockerfile.devel-gpu-cuda9-cudnn7\n> b43d0f3\n> <https://github.com/tensorflow/tensorflow/commit/b43d0f3c98140edfebb8295ea4a4b661e2fc2a85> *Upgrade\n> cuda to 9 and cudnn version to 7. (#14773\n> <https://github.com/tensorflow/tensorflow/pull/14773>)*\n> f7d392d\n> <https://github.com/tensorflow/tensorflow/commit/f7d392da2a455ffcc5e410e9c7c0514a5062c218>\n> Merge pull request #15197\n> <https://github.com/tensorflow/tensorflow/pull/15197> from caisq/nomac-tag\n> 28b92cd\n> <https://github.com/tensorflow/tensorflow/commit/28b92cd5a9ed677b5a2148e24d72f49de3768b23>\n> Fix tag in source_remote_test: no_mac --> nomac\n>\n> Than I fallowed the instructions mentioned at\n> https://gist.github.com/Brainiarc7/6d6c3f23ea057775b72c52817759b25c\n>\n> And done (for python2.7!)\n>\n> $ ipython2\n> Python 2.7.12 (default, Dec 4 2017, 14:50:18)\n> Type \"copyright\", \"credits\" or \"license\" for more information.\n>\n> IPython 4.0.1 -- An enhanced Interactive Python.\n> ? -> Introduction and overview of IPython's features.\n> %quickref -> Quick reference.\n> help -> Python's own help system.\n> object? -> Details about 'object', use 'object??' for extra details.\n>\n> In [1]: import tensorflow as tf\n>\n> In [2]: sess = tf.Session()\n> 2017-12-10 13:28:46.568828: I\n> tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:895] successful NUMA\n> node read from SysFS had negative value (-1), but there must be at least\n> one NUMA node, so returning NUMA node zero\n> 2017-12-10 13:28:46.569233: I\n> tensorflow/core/common_runtime/gpu/gpu_device.cc:1062] Found device 0 with\n> properties:\n> name: GeForce GT 750M major: 3 minor: 0 memoryClockRate(GHz): 0.967\n> pciBusID: 0000:04:00.0\n> totalMemory: 1.95GiB freeMemory: 1.72GiB\n> 2017-12-10 13:28:46.569263: I\n> tensorflow/core/common_runtime/gpu/gpu_device.cc:1152] Creating TensorFlow\n> device (/device:GPU:0) -> (device: 0, name: GeForce GT 750M, pci bus id:\n> 0000:04:00.0, compute capability: 3.0)\n>\n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/15236#issuecomment-350526417>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AT_SbUlyMKLl3Rpw_AXn8I7hJbKeOnC9ks5s-26bgaJpZM4Q8HLC>\n> .\n>\n", "Hi,\r\nI am also having the similar problem. I installed cuda 9.1 and set the path as suggested https://stackoverflow.com/questions/36159194/tensorflow-libcudart-so-7-5-cannot-open-shared-object-file-no-such-file-or-di\r\nShould i install cuda 8.0 for resolving this problem?\r\nThe error is:\r\n\r\n>>> import tensorflow\r\nTraceback (most recent call last):\r\n  File \"/home/honeypot/tensorflow/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"/home/honeypot/tensorflow/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"/home/honeypot/tensorflow/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"/home/honeypot/tensorflow/lib/python3.5/imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"/home/honeypot/tensorflow/lib/python3.5/imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: libcublas.so.8.0: cannot open shared object file: No such file or directory\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/honeypot/tensorflow/lib/python3.5/site-packages/tensorflow/__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"/home/honeypot/tensorflow/lib/python3.5/site-packages/tensorflow/python/__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"/home/honeypot/tensorflow/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 72, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"/home/honeypot/tensorflow/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"/home/honeypot/tensorflow/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"/home/honeypot/tensorflow/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"/home/honeypot/tensorflow/lib/python3.5/imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"/home/honeypot/tensorflow/lib/python3.5/imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: libcublas.so.8.0: cannot open shared object file: No such file or directory\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n>>> \r\n", "Hi, had the same issue. fixed it by verifying if libcublas.so.8.0 is present is $LD_LIBRARY_PATH. in my case, it was in /usr/local/cuda/lib64 instead of /usr/local/cuda/lib.", "Hi all, I had the same issue as @Prajwal1997. My setting is cuda-9.1 with cudnn 7.0. I wonder if there is a way to set TF looking for the right version of cuda, instead of installing cuda 8.0? Thanks! ", "Hi all, \r\nI have the similar problem. I have CUDA 8.0.61 with CudNN 5.1.10 but Tensorflow is searching CUDA 9:\r\n```ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory```\r\nHow I can make Tensorflow understand that I'm using CUDA 8?", "@VeLKerr this is not a configurable setting. You have to use a different version of tensorflow.", "Ok, what version is compatible with CUDA 8.0.61? I'm using the last Tensorflow version (1.5.0).", "Ok, I've installed Tensorflow 1.0.1 and it is working correctly!", "Woohoo!", "i meet the same question\r\n .libcublas.so.9.0: cannot open shared object file: No such file or directory\r\n\r\ni use cuda9.0\r\n\r\nand use this configure  . it can run .\r\n`\r\nexport LD_LIBRARY_PATH=/usr/local/cuda/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}\r\nexport LD_LIBRARY_PATH=/usr/local/cuda/extras/CUPTI/lib64:$LD_LIBRARY_PATH\r\n`", "Looks like you have an incorrect `LD_LIBRARY_PATH`. Try to set the following values:\r\n```\r\nexport PATH=/usr/local/cuda-9.0/bin:${PATH}\r\nexport LD_LIBRARY_PATH=/usr/local/cuda-9.0/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}\r\n```", "Try this:\r\n$ sudo ldconfig /usr/local/cuda/lib64\r\n", "I have **Cuda 9.0 , cudnn 7.0** on Ubuntu 16.04.\r\nI built **Tensorflow 1.6** since the release notes states it has pre-compiled binaries for cuda 9.0 and cudnn 7.0.\r\n\r\nldconfig -v: **libcublas.so.9.0**\r\n\r\nupon running: \r\nimport tensorflow as tf\r\nI still get the error: \r\n`ImportError: libcublas.so.8.0: cannot open shared object file: No such file or directory`\r\n\r\nMy Questions:\r\n1. Shouldn't Tensorflow 1.6 work with cuda 9.0/ cudnn 7.0 ? \r\n2. Is there any way I can **continue using cuda 9.0** ?? I really cannot use 8.0\r\n\r\n\r\n**Complete Error:** \r\n> \r\n> >>> import tensorflow\r\n> Traceback (most recent call last):\r\n>   File \"<stdin>\", line 1, in <module>\r\n>   File \"/home/archana/.local/lib/python2.7/site-packages/tensorflow/__init__.py\", line 24, in <module>\r\n>     from tensorflow.python import *\r\n>   File \"/home/archana/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py\", line 49, in <module>\r\n>     from tensorflow.python import pywrap_tensorflow\r\n>   File \"/home/archana/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 72, in <module>\r\n>     raise ImportError(msg)\r\n> ImportError: Traceback (most recent call last):\r\n>   File \"/home/archana/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\r\n>     from tensorflow.python.pywrap_tensorflow_internal import *\r\n>   File \"/home/archana/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\r\n>     _pywrap_tensorflow_internal = swig_import_helper()\r\n>   File \"/home/archana/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n>     _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n> ImportError: libcublas.so.8.0: cannot open shared object file: No such file or directory\r\n> \r\n> \r\n> Failed to load the native TensorFlow runtime.\r\n> \r\n", "I am using CUDA 9.2 and cudnn 7.1\r\n\r\nthe error on importing tensorflow says:\r\n\r\nImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory\r\n\r\nWhat should I do?", "@shrikant10\r\nYou say you use 9.2 but the error message seems like it is trying to use Cuda 9.0. \r\nCheck what version of Cuda is needed for your tensorflow version.\r\nAccording to the error message, you need Cuda9.0, so use Cuda 9.0. (Not 9.2).\r\n ", "@DrSajid I know this is a closed issue but here is what worked for me:\r\nI was using zsh(oh-my-zsh specifically) instead of bash for my temrinal and, although the lib64 path was set for bash, it wouldn't work for zsh.\r\n\r\nTry ``exec bash`` on terminal to switch to bash and try again."]}, {"number": 15235, "title": "Loss should change depending on the number of epochs chosen even if I set the seed?", "body": "Hi colleagues,\r\n\r\nI am using Keras to train different NNs. I would like to know why if I increment the epochs, the result until the same number of epochs is not the same for the evolution of loss. I am using shuffle=False, and np.random.seed(2017), tf.set_random_seed(2017), and I have check that if I repeat with the same number of epochs, the result is the same, so the random initialization is working. After the epochs training, I am deleting the ANN so the training begins at 0 again.\r\n\r\nHere I attach the picture of the resulting training with 10 epochs:\r\n\r\n<img width=\"676\" alt=\"captura de pantalla 2017-12-09 a las 15 02 25\" src=\"https://user-images.githubusercontent.com/23745991/33796312-05efe5da-dcf2-11e7-9780-09e0be902557.png\">\r\n\r\nAnd here I attach the picture of the resulting training with 8 epochs:\r\n\r\n<img width=\"679\" alt=\"captura de pantalla 2017-12-09 a las 15 02 34\" src=\"https://user-images.githubusercontent.com/23745991/33796313-106a6b34-dcf2-11e7-820c-e5d279665785.png\">\r\n\r\nAlso, I would like to know why the training time is not exactly (8/10) the 10 epochs attempt and how is it possible that some of them have less accuracy with 2 more epochs!\r\n\r\nHere is the link to open code Jupyter Notebook. [GitHub Jupyter Notebook - ANN Comparison](https://github.com/PabloRR100/Pruning-Algorithm-Method/blob/master/NN-Comparison.ipynb)\r\n\r\nThanks a lot!", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "I am sorry, here I attached the required information\r\n\r\n### System information\r\nOS: MacOs High Sierra 10.13.1\r\n\r\nAnaconda Environment\r\n- Python 3.5.4\r\n- Tensorflow installed via pip command from Tensorflow website\r\n- Tensorflow version: v1.4.0-rc1-11-g130a514 1.4.0\r\n- No CUDA. GPU = Intel HD Graphics 530 1536 MB\r\n\r\nI hope this is all the info you need. If not, please let me know,\r\n\r\nThanks!", "This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 15234, "title": "Fix static shape inference for keras.layers.LSTM", "body": "fix #15165\r\n\r\n### How to test\r\n\r\n+ [x] add test case.\r\n+ [ ] pass all tests.", "comments": ["Can one of the admins verify this patch?", "@fchollet WDYT?", "Thanks, I have fixed the failed test.", "MacOS Python2 failed, however it seems unrelated, right?\r\n\r\n```\r\n//tensorflow/python:framework_importer_test \r\n\r\nexec ${PAGER:-/usr/bin/less} \"$0\" || exit 1\r\n-----------------------------------------------------------------------------\r\n.2018-02-01 03:59:46.442363: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.2 AVX\r\n..................................................Terminated: 15\r\n```"]}, {"number": 15233, "title": "fix typo", "body": "", "comments": ["Can one of the admins verify this patch?"]}, {"number": 15232, "title": "Install new TensorFlow via anaconda, but failed", "body": "Hello,\r\n\r\nWhen I tried to install TensorFlow via anaconda.\r\nI`ve searched the suitable cite to submit the issue, but failed to find out it.\r\nIf this is not sorry for it and advice me.\r\n\r\nThe target os is 'windows 10', and via anaconda 5.0.1 For Windows (Python 3.6 version 64bit).\r\nAfter intall anaconda, from my terminal 'cmd.exe',\r\n$ conda create -n tensorflow python=3.6\r\nbut received an error message.\r\n\r\nBut from 'Anaconda Prompt' below 'Anaconda3' of 'start button',it works correctly.\r\n\r\nThus I recommend to include the following description,\r\nstart 'Anaconda Prompt' below 'Anaconda3' of 'start button' between the steps.", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "The step failing here, as you write above, does not involve TensorFlow - so this issue should probably be closed.", "Sorry for bothering you. \r\nI've understood the issue template, but my post is not suitable for here.\r\nThanks."]}, {"number": 15231, "title": "tensorboard doesn't show my graph", "body": "In the morning I can use the following command to open my graph. \r\n`tensorboard --logdir=graph_file_dir`\r\n\r\nHowever, in the evening, I use another PC, I can't see my graph any more. \r\nError Information is \r\n![image](https://user-images.githubusercontent.com/4633426/33793649-ff2545c4-dc6f-11e7-8719-50c8ea543c3a.png)\r\n\r\nThen, I tried to use the following command to inspect the content. \r\n![image](https://user-images.githubusercontent.com/4633426/33793657-1f43ab34-dc70-11e7-9c8b-84dc97190b85.png)\r\n\r\nI know there is only one top node in my graph called \"import\". Could any one help me to diagnose what could be the issue? Thanks in advance. \r\n", "comments": ["This can be closed, should run tensorboard from the same driver. "]}, {"number": 15230, "title": "tensorflow-gpu on mac", "body": "I can use the following to install tensorflow on mac.\r\n\r\nPython 2\r\n\r\n~~~\r\npip install --upgrade https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-1.4.0-py2-none-any.whl\r\n~~~\r\n\r\nPython 3\r\n\r\n~~~\r\npip3 install --upgrade https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-1.4.0-py3-none-any.whl\r\n~~~\r\n\r\nBut I don't find the correponding files for tensorflow-gpu. Can it be generated and posted over there? Thanks.\r\n", "comments": ["As per: https://www.tensorflow.org/install/install_mac - GPUs-on-Macs are not supported by the TensorFlow team (since after version 1.2).\r\n\r\nSome more discussion is here: https://groups.google.com/a/tensorflow.org/d/msg/discuss/BbnxAK9Rc54/XeTIG7JsBQAJ\r\n"]}, {"number": 15229, "title": "[XLA] Fix another XLA/tfcompile compile error on OSX ", "body": "This fixes issue https://github.com/tensorflow/tensorflow/issues/15196 (though that was accidentally closed)\r\n\r\nkernel_support_library.cc:99:5: error: no matching function\r\nfor call to 'transform' std::transform(function->arg_begin(),..\r\n\r\nTEST=build tfcompile on OSX (also requires PR#14893)", "comments": ["Can one of the admins verify this patch?", "@sanjoy @hawkinsp  please review", "I just want to confirm that I repeated the changes made by this PR on my local master (commit 8103945505) and it allowed me to compile with XLA/JIT: Yes.\r\nUsing Mac Sierra with Py3.6.\r\n", "rebased on top of master. @hawkinsp @sanjoy @yifeif. It has been reviewed. Can we please merge before it gets other merge conflicts. It unblocks OSX and Windows users.  ", "Thanks @powderluv. For sure! @tensorflow-jenkins test this please.", "windows cmake rerun at http://ci.tensorflow.org/job/tensorflow-pr-win-cmake-py/5929/"]}, {"number": 15228, "title": "Bug in XLA, if branches optimized by grappler/arithmetic_optimizer", "body": "grappler/arithmetic_optimizer may merge different Const op with same value into one. However, if two Const ops are in different branches (tf.cond, or SwitchOp, user-defined SwitchOp things), XLA will make them into one cluster, which would cause this XlaLaunchOp can't be run forever.\r\n\r\nOne way to walk around this is to disable arithmetic_optimizer.", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Do you perhaps have a repro?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue? Please update the label and/or status accordingly.", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 15227, "title": "MKL: Fixing MKL-DNN convolution filter propagation to backprop", "body": "Added code to propagate the 2D convolution filter to the backward pass.", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please"]}, {"number": 15226, "title": "Also install libssl-dev to make pip/py3.6 work properly.", "body": "", "comments": []}, {"number": 15225, "title": "Update .gitignore", "body": "", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please", "Thanks, @Androbin "]}, {"number": 15224, "title": "Add TensorFlow support for tf.repeat (equivalent to np.repeat)", "body": "This fix tries to address the feature request proposed in #8246 where there was no equivalent of numpy.repeat in TensorFlow.\r\n\r\nThis fix adds the support for tf.repeat that is equivalent to np.repeat.\r\n\r\nNOTE: in order to allow optional `axis` parameter, this fix adds `Repeat` and `RepeatFlat`  ops where one takes `axis` and another does not take `axis`.\r\n\r\nThis fix fixes #8246.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["Looks like there is an ongoing PR #8954 already. Close this PR for now.", "PR https://github.com/tensorflow/tensorflow/pull/8954 was closed as abandoned", "It seems tf.repeat is still not available.", "For anyone else who finds this post looking for a solution: [this](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/ragged/ragged_util.py#L113) is available as of 1.13\r\n\r\n```python\r\nfrom tensorflow.python.ops.ragged.ragged_util import repeat\r\n```", "See PR #26517"]}, {"number": 15223, "title": "stdin", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug or a feature request.\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**: \r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["I apologize but I am having a hard time understanding what the problem is, where the problem is, and what version it affects. Please resubmit and pay attention to the issue template (https://github.com/tensorflow/tensorflow/issues/new) . Please provide all the information it asks. Thank you."]}, {"number": 15222, "title": "tfcompile error - no matching function for call to 'transform'", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No.  This is on a clean checkout of tensorflow.\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  OSX Sierra\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: building from master (command outputs 1.3.0)\r\n- **Python version**:  2.7\r\n- **Bazel version (if compiling from source)**:  0.6.0\r\n- **GCC/Compiler version (if compiling from source)**: \r\nConfigured with: --prefix=/Applications/Xcode.app/Contents/Developer/usr --with-gxx-include-dir=/usr/include/c++/4.2.1\r\nApple LLVM version 9.0.0 (clang-900.0.38)\r\nTarget: x86_64-apple-darwin16.7.0\r\nThread model: posix\r\nInstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin\r\n- **CUDA/cuDNN version**: N/A (ran ./configure without CUDA)\r\n- **GPU model and memory**: N/A (no GPU)\r\n- **Exact command to reproduce**:\r\n1. Check out tensorflow\r\n2. Run ./configure, enable XLA support\r\n3. cd tensorflow/compiler/aot\r\n4.  bazel build :tfcompile\r\n\r\n### Describe the problem\r\n```\r\nERROR: /Users/mattrunchey/gitrepos/tensorflow/tensorflow/compiler/xla/service/llvm_ir/BUILD:171:1: C++ compilation of rule '//tensorflow/compiler/xla/service/llvm_ir:kernel_support_library' failed (Exit 1).\r\ntensorflow/compiler/xla/service/llvm_ir/kernel_support_library.cc:101:5: error: no matching function for call to 'transform'\r\n    std::transform(function->arg_begin(), function->arg_end(),\r\n    ^~~~~~~~~~~~~~\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/algorithm:1922:1: note: candidate template ignored: couldn't infer template argument '_UnaryOperation'\r\ntransform(_InputIterator __first, _InputIterator __last, _OutputIterator __result, _UnaryOperation __op)\r\n^\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/algorithm:1932:1: note: candidate function template not viable: requires 5 arguments, but 4 were provided\r\ntransform(_InputIterator1 __first1, _InputIterator1 __last1, _InputIterator2 __first2,\r\n^\r\n1 error generated.\r\n```\r\nThis happens across multiple OSes, as well (we tried to compile on a unix distro with the same error).  \r\n\r\n### Source code / logs\r\nThis seems to stem from a recent change in kernel_support_library.cc (specifically https://github.com/tensorflow/tensorflow/commit/c572bc4fd7c73f4b8014ae43cdf9da5b99592f59#diff-877daea43ebeb1cd4756f960400ee922 ).  ", "comments": ["This seems like a duplicate of #15196\r\n", "Ah yes, sorry!  I thought I'd looked for the same thing but missed that one.  ", "I have a PR up at https://github.com/tensorflow/tensorflow/pull/15229"]}, {"number": 15221, "title": "Dataset.from_generator doesn't support strings", "body": "I have hit the same problem described in https://stackoverflow.com/questions/47705684/tesnorflow-dataset-generator-does-not-work-with-strings\r\n\r\nI think it is a missing feature instead of a bug?", "comments": ["This bug was fixed in https://github.com/tensorflow/tensorflow/commit/17ba3a69f4c3509711a3da5eff3cb6be99e0936d but hasn't yet made its way into a release. I posted a workaround on the Stack Overflow question."]}]