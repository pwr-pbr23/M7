[{"number": 54106, "title": "Handle invalid inputs instead of crashing.", "body": "PiperOrigin-RevId: 409549744\r\nChange-Id: I7f5935b34b53f7e426a5462fcc027bdbf5dcda24", "comments": []}, {"number": 54104, "title": "adding additional support for completions related to lazy-loaded modules", "body": "fix for pylance/pyright auto completions missing. \r\nhttps://github.com/microsoft/pylance-release/issues/1066\r\n\r\n\r\nThis PR fixes https://github.com/tensorflow/tensorflow/issues/54435.", "comments": ["Please link also this issue so it will be closed when this is merged:\r\nhttps://github.com/tensorflow/tensorflow/issues/54435", "@qlzh727 @gbaned I think the ios build was missing python3.. not sure how to retrigger", "I do not see any tf.data-related imports, is anything missing here?", "tf.data doens't have an issue\r\n![image](https://user-images.githubusercontent.com/1946977/157770196-0556c2b9-3fd3-45f2-8843-0c7dec089907.png)\r\n\r\n\r\ni'm just looking at anything that is loaded with `_LazyLoader`\r\nand adding a `if _typing.TYPE_CHECKING:` only  normal import\r\n\r\n```\r\nlosses = _LazyLoader(\"losses\", globals(), _keras_package + \"losses\")\r\n    metrics = _LazyLoader(\"metrics\", globals(), _keras_package + \"metrics\")\r\n```", "> tf.data doens't have an issue\n> ![image](https://user-images.githubusercontent.com/1946977/157770196-0556c2b9-3fd3-45f2-8843-0c7dec089907.png)\n> \n> \n> i'm just looking at anything that is loaded with `_LazyLoader`\n> and adding a `if _typing.TYPE_CHECKING:` only  normal import\n> \n> ```\n> losses = _LazyLoader(\"losses\", globals(), _keras_package + \"losses\")\n>     metrics = _LazyLoader(\"metrics\", globals(), _keras_package + \"metrics\")\n> ```\n\nDoes `from tensorflow.data import Dataset` work without any problem then?", "`from tensorflow.data import Dataset` is a different issue. I don't think that is expected to ever work since it doesn't match the relative folder structure.  Pycharm and Pylance both dont like it.\r\n\r\n\r\n`from tensorflow._api.v2.data import Dataset` will work however", " the `from tensorflow.data import Dataset` issue seems to be related to dynamic path  `__path__`\r\n\r\n file layout doesn't match the import statement because they mutate tensorflow.__path__\u200b :\r\n\r\n>>> tensorflow.__path__\r\n['/tmp/scratch-venv/lib/python3.10/site-packages/keras/api/_v2', '/tmp/scratch-venv/lib/python3.10/site-packages/tensorflow_estimator/python/estimator/api/_v2', '/tmp/scratch-venv/lib/python3.10/site-packages/tensorboard/summary/_tf', '/tmp/scratch-venv/lib/python3.10/site-packages/tensorflow', '/tmp/scratch-venv/lib/python3.10/site-packages/tensorflow/_api/v2']\r\n\r\nWhen you put a directory on __path__\u200b, it means import will consider those directories as anchored off of that package when trying to resolve a module name. So that means `lib/python3.10/site-packages/tensorflow/_api/v2` on __path__\u200b gets searched the same as `lib/python3.10/site-packages/tensorflow/` for a package\u200b. You can see this in their tensorflow/__init__.py\u200b file starting at line 342:\r\n```\r\n342   \u2502 # Make sure directory containing top level submodules is in\r\n 343   \u2502 # the __path__ so that \"from tensorflow.foo import bar\" works.\r\n 344   \u2502 # We're using bitwise, but there's nothing special about that.\r\n 345   \u2502 _API_MODULE = _sys.modules[__name__].bitwise\r\n 346   \u2502 _tf_api_dir = _os.path.dirname(_os.path.dirname(_API_MODULE.__file__))\r\n 347   \u2502 _current_module = _sys.modules[__name__]\r\n 348   \u2502\r\n 349   \u2502 if not hasattr(_current_module, '__path__'):\r\n 350   \u2502   __path__ = [_tf_api_dir]\r\n 351   \u2502 elif _tf_api_dir not in __path__:\r\n 352   \u2502   __path__.append(_tf_api_dir)\r\n```\r\n\r\nSuggestions:\r\n\r\n- [ ] Get them to change how they structure their repo so their current API version isn't hidden but as at the expected places and only old APIs are hidden away\r\n- [ ] Have them duplicate their code in two different directory structures (which can lead to nasty side-effects due to ending up with duplicate modules for the same thing)\r\n", "> `from tensorflow.data import Dataset` is a different issue. I don't think that is expected to ever work since it doesn't match the relative folder structure. Pycharm and Pylance both dont like it.\r\n> \r\n> `from tensorflow._api.v2.data import Dataset` will work however\r\n\r\nThis is still part of the \"PyLance doesn't work with TensorFlow\" problem so I was thinking maybe we could group up those 2 issues here. PyLance + TF issues already take ages to be fixed so maybe using the momentum we have on this PR to go further could be a good thing?", "> from tensorflow.data import Dataset is a different issue. I don't think that is expected to ever work since it doesn't match the relative folder structure. Pycharm and Pylance both dont like it.\r\n\nI think we cannot simply say that this is a problem with PyLance & Pycharm and leave the problem as-is.\r\n\r\n90% of the users will probably use either Pycharm or VSCode so support should be provided: we cannot close our eyes on the majority of the users just because the directory structure is not the right one; I know this is a big question because the problem has been around for years now, but at some point we should discuss this and decide whether we should patch TF or the language servers\r\n\r\nWhat do you think?", "If there was a new PEP defining away to work around this folder issue then we would support it in Pylance, but as a general policy we don't special case third party library behaviour. ", "> [...] but as a general policy we don't special case third party library behaviour.\r\n\r\n+1 for the rule. Thanks for the explanation. I will stick to the next comment then. (edited)", "This might be a better future proof option for accessing Dataset\r\n```python\r\nimport tensorflow as tf\r\ntf.data.Dataset \r\n```"]}, {"number": 54103, "title": "Prevent `CHECK`-fail when building reference tensor.", "body": "The tensor constructor does not allow reference dtypes, as these should not show up explicitly. However, when passed these invalid types instead of building an invalid object the constructor crashes via a `CHECK`-fail. We have a static builder that properly handles this case but is not applicable given current usage.\r\n\r\nInstead, before calling the constructor, we can check that the dtype is not a reference type and return an error otherwise, given that the dtype is user controlled so malicious users can trigger denial of service.\r\n\r\nPiperOrigin-RevId: 409662503\r\nChange-Id: I5892f831fde7f276cd7ab34519cf6b8061c71a59", "comments": []}, {"number": 54102, "title": "Use `PartialTensorShape` instead of `TensorShape`.", "body": "`TensorShape` constructor throws a CHECK-fail if shape is partial/overflows which the other doesn't. We are only determining the number of elements in the shape and partial shape should be used as it returns negative number when needed.\r\n\r\nPiperOrigin-RevId: 409205384\r\nChange-Id: Ia56542ff9ec758f2c9ffc7e4dcc9fa7eecd86e7b", "comments": []}, {"number": 54101, "title": "Use `PartialTensorShape` instead of `TensorShape`.", "body": "`TensorShape` constructor throws a CHECK-fail if shape is partial/overflows which the other doesn't. We are only determining the number of elements in the shape and partial shape should be used as it returns negative number when needed.\r\n\r\nPiperOrigin-RevId: 409205384\r\nChange-Id: Ia56542ff9ec758f2c9ffc7e4dcc9fa7eecd86e7b", "comments": []}, {"number": 54100, "title": "[oneDNN] Removing eager check for mkl specific passes", "body": "Removing eager check for oneDNN specific passes, as its not needed anymore. This check blocks passes when running saved_models in tensorflow.", "comments": []}, {"number": 54099, "title": "AssignOffsetsToTensors with GREEDY_BY_SIZE causes a segfault on NVidia", "body": "- Calling AssignOffsetsToTensors with MemoryStrategy::GREEDY_BY_SIZE appears to cause a segfault on NVidia OpenCL. See issue https://github.com/tensorflow/tensorflow/issues/53800 for more details.\r\n\r\n- Fixed some undefine/duplicate definition linker error (related to logging classes) when building for Android using CMake.", "comments": ["Please open against `master`. The `nightly` branch is only used to trigger nightly jobs and is always overriden by master"]}, {"number": 54098, "title": "Fixed a segfault on exit on NVidia", "body": "- Calling AssignOffsetsToTensors with MemoryStrategy::GREEDY_BY_SIZE appears to cause a segfault on NVidia OpenCL. See issue https://github.com/tensorflow/tensorflow/issues/53800 for more details.\r\n- Fixed some undefine/duplicate definition linker error (related to logging classes) when building for Android using CMake.", "comments": []}, {"number": 54097, "title": "Use a different mem assign strategy to avoid crash-on-exit on nvidia", "body": "- Calling AssignOffsetsToTensors with MemoryStrategy::GREEDY_BY_SIZE currently results in a segfault on exit on NVidia OpenCL. See https://github.com/tensorflow/tensorflow/issues/53800\r\n\r\n- Fixed some linking errors (undefined/duplicate definitions related to logging classes) when building the TFLite C++ API using CMake for Android.", "comments": []}, {"number": 54096, "title": "Make `IsSimplifiableReshape` return `Status` instead of `bool`.", "body": "This is to allow remove `CHECK`-fails in subsequent commits.\r\n\r\nPiperOrigin-RevId: 409160987\r\nChange-Id: I3f050218a3832271395c4372a0b8ea05f1c03d80", "comments": []}, {"number": 54095, "title": "Make `IsSimplifiableReshape` return `Status` instead of `bool`.", "body": "This is to allow remove `CHECK`-fails in subsequent commits.\r\n\r\nPiperOrigin-RevId: 409160987\r\nChange-Id: I3f050218a3832271395c4372a0b8ea05f1c03d80", "comments": []}, {"number": 54094, "title": "Model.fit() batch_size breaks for some batch_sizes", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 and (RHEL-like (custom distro ran by organization))\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): Tensorflow 2.5.0 on Windows 10 , Tensorflow 2.5.0 AND 2.7.0 on RHEL\r\n- Python version:  Windows 10 -> python 3.7.6    :   RHEL -> python 3.7.2+Tensorflow 2.5.0 AND python 3.8.2+Tensorflow 2.7.0\r\n- CUDA/cuDNN version: CUDA:11.2.0 cuDNN:8.1.1\r\n- GPU model and memory: Windows -> nVidia Quadro RTX 3000 : RHEL -> nVidia P100\r\n\r\n**Describe the current behavior**\r\nWhen utilizing a custom loss function that has been tested to work, it will break with certain batch sizes by claiming that a (None) datatype was received, or rather, the `None` could not be converted to tensor. This is despite the fact that a numpy array of dtype `'float32'` was passed to it.\r\n\r\nThis was first noted in a script that trained two separate autoencoders on two separate datasets, 1- 12800x400 and 1-8000x400, with batch sizes of 128 and 80 respectively. The first would train, but the second would break despite the code for the second autoencoder being a duplicate of the first. The first one in that situation utilized the same custom loss function `ExplainedVar().` This does not occur for the built-in loss functions. The `batch_size` in all cases was smaller than the training set.\r\n\r\nIt should be noted that when it fails, `true` and `pred` reach the loss function as `None`s . This is not a result of the math inside the loss function.\r\n\r\nBelow are the two different errors produced by Tensorflow 2.5.0 and 2.7.0 respectively.\r\n\r\n**Tensorflow 2.5.0**\r\n```\r\nTraceback (most recent call last):\r\n  File \"divided_models.py\", line 218, in <module>\r\n    a_sae.fit(rnd_dat,rnd_dat,epochs=10,batch_size=32,verbose=2)\r\n  File \"/usr/WS2/mvander/py3venv/py3venv/lib/python3.7/site-packages/keras/engine/training.py\", line 1184, in fit\r\n    tmp_logs = self.train_function(iterator)\r\n  File \"/usr/WS2/mvander/py3venv/py3venv/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 885, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"/usr/WS2/mvander/py3venv/py3venv/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 933, in _call\r\n    self._initialize(args, kwds, add_initializers_to=initializers)\r\n  File \"/usr/WS2/mvander/py3venv/py3venv/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 760, in _initialize\r\n    *args, **kwds))\r\n  File \"/usr/WS2/mvander/py3venv/py3venv/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 3066, in _get_concrete_function_internal_garbage_collected\r\n    graph_function, _ = self._maybe_define_function(args, kwargs)\r\n  File \"/usr/WS2/mvander/py3venv/py3venv/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 3463, in _maybe_define_function\r\n    graph_function = self._create_graph_function(args, kwargs)\r\n  File \"/usr/WS2/mvander/py3venv/py3venv/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 3308, in _create_graph_function\r\n    capture_by_value=self._capture_by_value),\r\n  File \"/usr/WS2/mvander/py3venv/py3venv/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\", line 1007, in func_graph_from_py_func\r\n    func_outputs = python_func(*func_args, **func_kwargs)\r\n  File \"/usr/WS2/mvander/py3venv/py3venv/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 668, in wrapped_fn\r\n    out = weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n  File \"/usr/WS2/mvander/py3venv/py3venv/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\", line 994, in wrapper\r\n    raise e.ag_error_metadata.to_exception(e)\r\nTypeError: in user code:\r\n\r\n    /usr/WS2/mvander/py3venv/py3venv/lib/python3.7/site-packages/keras/engine/training.py:853 train_function  *\r\n        return step_function(self, iterator)\r\n    ./custom_loss_funcs.py:117 call  *\r\n        pred_mean = tf.reshape(tf.math.reduce_mean(pred,axis=1),(pred.shape[0],1))\r\n    /usr/WS2/mvander/py3venv/py3venv/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:206 wrapper  **\r\n        return target(*args, **kwargs)\r\n    /usr/WS2/mvander/py3venv/py3venv/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:196 reshape\r\n        result = gen_array_ops.reshape(tensor, shape, name)\r\n    /usr/WS2/mvander/py3venv/py3venv/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py:8404 reshape\r\n        \"Reshape\", tensor=tensor, shape=shape, name=name)\r\n    /usr/WS2/mvander/py3venv/py3venv/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:525 _apply_op_helper\r\n        raise err\r\n    /usr/WS2/mvander/py3venv/py3venv/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:515 _apply_op_helper\r\n        preferred_dtype=default_dtype)\r\n    /usr/WS2/mvander/py3venv/py3venv/lib/python3.7/site-packages/tensorflow/python/profiler/trace.py:163 wrapped\r\n        return func(*args, **kwargs)\r\n    /usr/WS2/mvander/py3venv/py3venv/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:1566 convert_to_tensor\r\n        ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n    /usr/WS2/mvander/py3venv/py3venv/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py:346 _constant_tensor_conversion_function\r\n        return constant(v, dtype=dtype, name=name)\r\n    /usr/WS2/mvander/py3venv/py3venv/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py:272 constant\r\n        allow_broadcast=True)\r\n    /usr/WS2/mvander/py3venv/py3venv/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py:290 _constant_impl\r\n        allow_broadcast=allow_broadcast))\r\n    /usr/WS2/mvander/py3venv/py3venv/lib/python3.7/site-packages/tensorflow/python/framework/tensor_util.py:553 make_tensor_proto\r\n        \"supported type.\" % (type(values), values))\r\n\r\n    TypeError: Failed to convert object of type <class 'tuple'> to Tensor. Contents: (None, 1). Consider casting elements to a supported type.\r\n```\r\n\r\n**Tensorflow 2.7.0**\r\n```\r\nTraceback (most recent call last):\r\n  File \"divided_models3.py\", line 111, in <module>\r\n    a_ae.fit(scaled_aData,scaled_aData,epochs=n_epochs,\r\n  File \"/usr/WS2/mvander/py3_8/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\r\n    raise e.with_traceback(filtered_tb) from None\r\n  File \"/usr/WS2/mvander/py3_8/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\", line 1129, in autograph_handler\r\n    raise e.ag_error_metadata.to_exception(e)\r\nTypeError: in user code:\r\n\r\n    File \"/usr/WS2/mvander/py3_8/lib/python3.8/site-packages/keras/engine/training.py\", line 878, in train_function  *\r\n        return step_function(self, iterator)\r\n    File \"divided_models3.py\", line 23, in call  *\r\n        pred_mean = tf.reshape(tf.math.reduce_mean(pred,axis=1),(pred.shape[0],1))\r\n\r\n    TypeError: Failed to convert elements of (None, 1) to Tensor. Consider casting elements to a supported type. See https://www.tensorflow.org/api_docs/python/tf/dtypes for supported TF dtypes.\r\n\r\n```\r\n\r\n**Describe the expected behavior**\r\n`Model.fit()` should work for any batch_size > 0 and <= dataset size. Alternatively, it should frankly work for any positive dataset size where a batch_size larger than the dataset size would default to the size of the dataset.\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no): No\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nimport os\r\nimport sys\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\n\r\nimport tensorflow as tf\r\nimport tensorflow.keras as krs\r\n\r\nclass ExplainedVar(krs.losses.Loss):\r\n    def __init__(self, reduction = krs.losses.Reduction.AUTO, **kwargs):\r\n        super( ExplainedVar, self).__init__(reduction = reduction, **kwargs)\r\n        # self.counter = 0\r\n\r\n    def call(self,true,pred):\r\n        #print(pred.shape)\r\n        #print(true.shape)\r\n        #if true.shape[0] is None:\r\n        #    raise Exception()\r\n        # self.counter += 1\r\n        # print(self.counter)\r\n        pred = tf.convert_to_tensor(pred)\r\n        true = tf.cast(true, pred.dtype)\r\n\r\n        res = tf.math.reduce_sum( tf.math.square( pred - true ), axis=1 )\r\n        pred_mean = tf.reshape(tf.math.reduce_mean(pred,axis=1),(pred.shape[0],1))\r\n        tot = tf.math.reduce_sum( tf.math.square( pred - pred_mean ),axis=1)\r\n\r\n        return res/tot\r\n\r\n\r\ndef make_auto(in_dim,string):\r\n\r\n    enc_in = krs.Input((in_dim,))\r\n    x = enc_in\r\n\r\n\r\n    x0_0 = krs.layers.Dense(96,activation='elu',kernel_initializer='lecun_normal')(x)\r\n    x1_0 = krs.layers.Dense(48,activation='elu',kernel_initializer='lecun_normal')(x0_0)\r\n    x2_0 = krs.layers.Dense(25,activation='elu',kernel_initializer='lecun_normal')(x1_0)\r\n    x3_0 = krs.layers.Dense(16,activation='elu',kernel_initializer='lecun_normal')(x2_0)\r\n\r\n    x0_1 = krs.layers.Dense(12,activation='elu',kernel_initializer='lecun_normal')(x)\r\n    x1_1 = krs.layers.Dense(10,activation='elu',kernel_initializer='lecun_normal')(x0_0)\r\n    x2_1 = krs.layers.Dense(8,activation='elu',kernel_initializer='lecun_normal')(x1_0)\r\n    x3_1 = krs.layers.Dense(6,activation='elu',kernel_initializer='lecun_normal')(x2_0)\r\n    x4_1 = krs.layers.Dense(4,activation='elu',kernel_initializer='lecun_normal')(x3_0)\r\n\r\n    enc_out = krs.layers.Concatenate(axis=1)([x0_1,x1_1,x2_1,x3_1,x4_1])\r\n\r\n    a_enc = krs.Model( inputs = enc_in, outputs = enc_out, name = \"%s_enc\"%string)\r\n\r\n    dec_in = krs.Input((40,))\r\n    x = dec_in\r\n    x0 = x[:,:4]\r\n    x1 = x[:,4:10]\r\n    x2 = x[:,10:18]\r\n    x3 = x[:,18:28]\r\n    x4 = x[:,28:40]\r\n\r\n    x4 = krs.layers.Dense(16,activation='elu',kernel_initializer='lecun_normal')(x4)\r\n\r\n    x3 = krs.layers.Concatenate()([x3,x4])\r\n    x3 = krs.layers.Dense(25,activation='elu',kernel_initializer='lecun_normal')(x3)\r\n\r\n    x2 = krs.layers.Concatenate()([x2,x3])\r\n    x2 = krs.layers.Dense(48,activation='elu',kernel_initializer='lecun_normal')(x2)\r\n\r\n    x1 = krs.layers.Concatenate()([x1,x2])\r\n    x1 = krs.layers.Dense(96,activation='elu',kernel_initializer='lecun_normal')(x1)\r\n\r\n    x0 = krs.layers.Concatenate()([x0,x1])\r\n    dec_out = krs.layers.Dense(400,activation='elu',kernel_initializer='lecun_normal')(x0)\r\n\r\n    a_dec = krs.Model( inputs = dec_in, outputs = dec_out, name = \"%s_dec\"%string)\r\n\r\n    a_sae = krs.Model( inputs = enc_in, outputs = a_dec( a_enc(enc_in)), name = \"%s_sae\"%string)\r\n\r\n    return a_sae, a_enc, a_dec\r\n\r\n\r\ndef samp_minmax_transform(xmin,xmax,data):\r\n    data = ((data.T - xmin)/(xmax-xmin)).T\r\n    return data\r\n\r\ndef samp_minmax_inverse_transform(xmin,xmax,data):\r\n    data = (data.T*(xmax-xmin)+xmin).T\r\n    return data\r\n\r\ndef scale(x):\r\n    return np.power(x,1./30.)\r\n\r\ndef descale(x):\r\n    return np.power(x,30.)\r\n\r\n\r\n\r\naData = np.random.uniform(0,10.,(5000,400))\r\nbData = np.random.uniform(0,10.,(5000,400))\r\n\r\n\r\nscaled_aData = scale(aData)\r\nscaled_bData = scale(bData)\r\n\r\nprint(\"aData DTYPE :\",aData.dtype)\r\nprint(\"bData DTYPE :\",bData.dtype)\r\n###############################################\r\n\r\n\r\na_ae, a_enc, a_dec = make_auto(400,'a')\r\n\r\nloss = ExplainedVar()\r\n# loss = krs.losses.MSLE #### This works with all batch sizes\r\nopt = krs.optimizers.Adam(.0001)\r\na_ae.compile(optimizer=opt,loss=loss)\r\n\r\n\r\nn_epochs = 10\r\n\r\nbatch_size = int(scaled_aData.shape[0]*.8) ### This will break everything with custom loss function\r\n# batch_size = int(scaled_aData.shape[0]*.05) #### This make it work with custom loss function\r\n\r\na_ae.fit(scaled_aData,scaled_aData,epochs=n_epochs,\r\n        batch_size=batch_size,verbose=2)\r\n\r\n###############################################\r\n## THIS SECTION IS TO VERIFY THAT IT ISN'T THE ARCHITECTURE ITSELF\r\n\r\n# enc_in = krs.Input((400,))\r\n# x = krs.layers.Dense(50,activation='elu')(enc_in)\r\n# enc_out = krs.layers.Dense(10,activation='elu')(x)\r\n# enc = krs.Model(inputs=enc_in,outputs=enc_out,name=\"enc\")\r\n\r\n# dec_in = krs.Input((10,))\r\n# x = krs.layers.Dense(50,activation='elu')(dec_in)\r\n# dec_out = krs.layers.Dense(400,activation='elu')(x)\r\n# dec = krs.Model(inputs=dec_in,outputs=dec_out,name=\"dec\")\r\n\r\n# n_epochs = 10\r\n# batch_size = int(scaled_aData.shape[0]*.8)\r\n# ae = krs.Model(inputs=enc_in, outputs = dec( enc(enc_in)),name='ae')\r\n# loss = ExplainedVar()\r\n# opt = krs.optimizers.Adam(.0001)\r\n# ae.compile(optimizer=opt,loss=loss)\r\n# ae.fit(scaled_aData,scaled_aData,epochs=n_epochs,\r\n#         batch_size=batch_size,verbose=2)\r\n\r\n```\r\n", "comments": ["@EnderWiggin14 \r\nPlease post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues)\r\nTo know more see;\r\n[https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999](https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999)\r\nThank you!", "@sushreebarsa \r\nPosted in Keras github at this link [https://github.com/keras-team/keras/issues/15956](https://github.com/keras-team/keras/issues/15956)", "@EnderWiggin14 Thank you for the update!\r\nCould you please move this ticket to closed status as we will track the other issue in https://github.com/keras-team/keras/issues/15956\r\nThanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54094\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54094\">No</a>\n"]}, {"number": 54093, "title": "[ROCm] Switching Dockerfile.rocm to use python3.9", "body": "Updating dockerfile.rocm to fix community build. ", "comments": ["@chsigg Any comments on this PR? "]}, {"number": 54092, "title": "Fix Null-pointer dereference in BuildXlaCompilationCache", "body": "If ConfigProto is not used, then use the default settings which is to allow all devices.\r\n\r\nPiperOrigin-RevId: 420391800\r\nChange-Id: I88161ad7042990aef678e77b597a2fb2c8f815be", "comments": []}, {"number": 54090, "title": "LSTM model save warning, Tensorflow 2.7.0", "body": "**System information**\r\n- OS Platform and Distribution: Windows10\r\n- TensorFlow installed from: binary\r\n- TensorFlow version: v2.7.0-rc1-69-gc256c071bb2 2.7.0\r\n- Python version: 3.9.10\r\n\r\n\r\n**Describe the current behavior**\r\nWhen model.save called, the below warning message occurred:\r\n```\r\nWARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\r\nWARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000021419A6A820> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\r\n```\r\nI just upgraded python from 3.6 to 3.9, reinstall Tensorflow under Python 3.9.10. I found the LSTM model hard to train to reduce loss value and the previous warning information occurred.\r\n\r\n![image](https://user-images.githubusercontent.com/61686583/151123541-210c3046-b23a-4a09-812d-34bb2dde9ad3.png)\r\n", "comments": ["My model creation code is as follows:\r\n```\r\nfrom tensorflow.keras.layers import Dense, LSTM\r\nfrom tensorflow.keras.models import Sequential\r\nfrom tensorflow.keras import optimizers\r\n\r\ndef createModel(look_back=1):\r\n    model = Sequential()\r\n    model.add(LSTM(100, return_sequences=True, input_shape=(1, look_back)))\r\n    # model.add(LSTM(100, activation='relu', return_sequences=True))\r\n    # model.add(LSTM(50, activation='relu', return_sequences=True))\r\n    model.add(Dense(30, activation='relu'))\r\n    model.add(Dense(20, activation='relu'))\r\n    model.add(Dense(10, activation='relu'))\r\n    model.add(Dense(1))\r\n\r\n    # fixed learning rate\r\n    # lr = 1e-2\r\n\r\n    # learning rate schedule\r\n    lr = optimizers.schedules.ExponentialDecay(initial_learning_rate=1e-5,\r\n                                               decay_steps=10000,\r\n                                               decay_rate=0.99)\r\n\r\n    # opt = optimizers.SGD(learning_rate=lr)\r\n    # opt = optimizers.SGD(learning_rate=lr, momentum=0.8, nesterov=False)\r\n    # opt = optimizers.RMSprop(learning_rate=lr, rho=0.9, epsilon=1e-08)\r\n    opt = optimizers.Adam(learning_rate=lr)\r\n    # opt = optimizers.Adadelta(learning_rate=lr)\r\n    # opt = optimizers.Adagrad(learning_rate=lr)\r\n    # opt = optimizers.Adamax(learning_rate=lr)\r\n    # opt = optimizers.Nadam(learning_rate=lr)\r\n    # opt = optimizers.Ftrl(learning_rate=lr)\r\n\r\n    model.compile(optimizer=opt, loss='mse')\r\n    # model.summary()\r\n    return model\r\n```", "Hi @StevenHuang2020 ! \r\nPlease post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues)\r\nTo know more see;\r\n[https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999](https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999) . Thanks!", "okay, thanks!", "@StevenHuang2020 ! Could you close this issue here then as it will be tracked in Keras repository?", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54090\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54090\">No</a>\n", "ok"]}, {"number": 54089, "title": "Prevent integer overflow in `CalculateTensorSize`.", "body": "In order to not change the API, we return a negative value in case of overflow. A better fix is to change the API to return a status instead.\r\n\r\nPiperOrigin-RevId: 408714915\r\nChange-Id: I110ec4e1c5bbf4d7ca7ef7c068dfd3e8bc7190cd", "comments": []}, {"number": 54088, "title": "Prevent integer overflow in `CalculateTensorSize`.", "body": "In order to not change the API, we return a negative value in case of overflow. A better fix is to change the API to return a status instead.\r\n\r\nPiperOrigin-RevId: 408714915\r\nChange-Id: I110ec4e1c5bbf4d7ca7ef7c068dfd3e8bc7190cd", "comments": []}, {"number": 54087, "title": "no attribute '_register_wrapper_optimizer_cls' in python 3.8.12", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): ubuntu 20.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version: 2.7.0\r\n- Python version: 3.8.12\r\n- Installed using virtualenv? pip? conda?: conda virtualenv\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 11.2/8.1.0\r\n- GPU model and memory: RTX 3090 / 24GB\r\n\r\n\r\n\r\n**Describe the problem**\r\nI installed tensorflow 2.7.0 using pip with python 3.8.12. It imported fine in ubuntu 18.04.\r\nHowever, as a result of doing the same in ubuntu 20.04, the import was not performed with an error such as \"AttributeError: module 'tensorflow.python.training.experimental.mixed_precision' has no attribute '_register_wrapper_optimizer_cls'\".\r\nI tried the same method in python 3.9.7 version just in case, but this time it was imported.\r\nTherefore, I wonder why python 3.8.12 version can be done in ubuntu 18.04, but not in ubuntu 20.04.\r\n\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nenvironment.yaml file\r\n```\r\nname: tf27\r\nchannels:\r\n  - anaconda\r\n  - conda-forge\r\n  - defaults\r\ndependencies:\r\n  - python==3.8.12\r\n  - pip\r\n  - pip:\r\n    - lxml>=4.6.1\r\n    - cython>=0.29.13 \r\n    - absl-py>-0.10.0\r\n    - matplotlib>=3.0.3\r\n    - numpy>=1.19.4\r\n    - Pillow>=6.0.0\r\n    - pycocotools>=2.0\r\n    - PyYAML>=5.1\r\n    - six>=1.15.0\r\n    - tensorflow>=2.7.0\r\n    - tensorflow-addons>=0.15\r\n    - tensorflow-hub>=0.11\r\n    - neural-structured-learning>=1.3.1\r\n    - opencv-python\r\n    - tqdm\r\n```\r\nThen try \r\n```\r\nimport tensorflow\r\n```\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nFull error log below.\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/zeron/anaconda3/envs/tf27/lib/python3.8/site-packages/tensorflow/__init__.py\", line 479, in <module>\r\n    keras._load()\r\n  File \"/home/zeron/anaconda3/envs/tf27/lib/python3.8/site-packages/tensorflow/python/util/lazy_loader.py\", line 45, in _load\r\n    module = importlib.import_module(self.__name__)\r\n  File \"/home/zeron/anaconda3/envs/tf27/lib/python3.8/importlib/__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"/home/zeron/.local/lib/python3.8/site-packages/keras/__init__.py\", line 25, in <module>\r\n    from keras import models\r\n  File \"/home/zeron/.local/lib/python3.8/site-packages/keras/models.py\", line 20, in <module>\r\n    from keras import metrics as metrics_module\r\n  File \"/home/zeron/.local/lib/python3.8/site-packages/keras/metrics.py\", line 27, in <module>\r\n    from keras import activations\r\n  File \"/home/zeron/.local/lib/python3.8/site-packages/keras/activations.py\", line 20, in <module>\r\n    from keras.layers import advanced_activations\r\n  File \"/home/zeron/.local/lib/python3.8/site-packages/keras/layers/__init__.py\", line 24, in <module>\r\n    from keras.engine.input_layer import Input\r\n  File \"/home/zeron/.local/lib/python3.8/site-packages/keras/engine/input_layer.py\", line 21, in <module>\r\n    from keras.engine import base_layer\r\n  File \"/home/zeron/.local/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 41, in <module>\r\n    from keras.mixed_precision import loss_scale_optimizer\r\n  File \"/home/zeron/.local/lib/python3.8/site-packages/keras/mixed_precision/loss_scale_optimizer.py\", line 1180, in <module>\r\n    mixed_precision._register_wrapper_optimizer_cls(optimizer_v2.OptimizerV2,\r\nAttributeError: module 'tensorflow.python.training.experimental.mixed_precision' has no attribute '_register_wrapper_optimizer_cls'\r\n", "comments": ["@jiku100 Could you please check if  your cpu model  support AVX instructions sets?See [hardware requirements](https://www.tensorflow.org/install/pip?lang=python3#hardware-requirements)\r\nMake sure to download the latest [microsoft visual c++ redistributable from here.](https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads)\r\nAlso, please follow the instructions from [Tensorflow website](https://www.tensorflow.org/install/source).\r\nPlease let us know if it helps?\r\nThanks!\r\n", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54087\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54087\">No</a>\n"]}, {"number": 54085, "title": "LSTM slow to calibrate with large observation period", "body": "I am reporting an issue in the calibration speed of LSTM models with large observation period even though none of my resource is saturated (CPU, GPU, RAM, SSD)\r\n\r\n**System information**\r\n- OS Platform and Distribution: Win11\r\n- TensorFlow installed from: `pip install tensorflow`\r\n- TensorFlow version: 2.7 / GPU\r\n- Python version: 3.9\r\n- CUDA/cuDNN version: cuDNN 8201 (installed via `pip install tensorflow`), CUDA 11.4\r\n- GPU model and memory: Geforce GTX 3060 4 Go / RAM 32 Go / CPU AMD Ryzen 5 / SSD\r\n\r\n**Describe the current behavior**\r\nNone of the machine resource is saturated following LSTM calibration\r\n`print(tf.config.list_physical_devices(\"GPU\"))` shows that the calibration runs on the GPU as expected.\r\n\r\n**Describe the expected behavior**\r\nAny of the machine resource should be saturated\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow.keras import layers\r\nfrom tensorflow.keras.models import Sequential\r\n\r\nprint(tf.config.list_physical_devices(\"GPU\"))\r\n\r\nif __name__ == \"__main__\":\r\n\r\n    epoch = 10\r\n    batch_size = 2000\r\n    number_output = 3\r\n    number_features = 5\r\n    backward = 992\r\n    number_node = 40\r\n\r\n    def train_gen():\r\n        for i in range(1000):\r\n            yield np.random.random((batch_size, backward, number_features)),\\\r\n                  np.random.random((batch_size, number_output))\r\n\r\n    train_dataset = tf.data.Dataset.from_generator(train_gen, output_types=(tf.float64, tf.float64))\r\n    train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)\r\n\r\n    drop_ratio = 0.2\r\n    model = Sequential([layers.Input(shape=(backward, number_features))])\r\n    model.add(layers.LSTM(number_node, return_sequences=False))\r\n    model.add(layers.Dropout(drop_ratio))\r\n    model.add(layers.Dense(number_output, activation='sigmoid'))\r\n    model.compile(optimizer='adam', loss='mse')\r\n    model.summary()\r\n\r\n    history = model.fit(train_dataset, epochs=epoch)\r\n```\r\n\r\n\r\n**Other info / logs**\r\n![image](https://user-images.githubusercontent.com/25941523/151064911-8f1ba15f-16d5-4b63-ad9b-ffb19eb9302e.png)\r\n\r\n", "comments": ["Hi @Raa23 ! I was getting a slow processing time but memory usage  increased  and got saturated at end of training . Attaching [gist ](https://colab.sandbox.google.com/gist/mohantym/fac4737d22825e038a35295f898ce084/github_54085.ipynb#scrollTo=VJyqD-tDYQAA) and screenshot for reference. From template, I can also see **dedicated gpu memory usage line** has flattened after a while  and Other devices are expected to work differently.\r\n![image](https://user-images.githubusercontent.com/86464649/151492436-13ed810a-48ed-45f1-9759-d124de245a05.png)\r\n\r\nPlease post on [TF forum ](https://discuss.tensorflow.org/)for further assistance. Thank you!", "Hello, thank you for your feedback but I see in the screenshot that the RAM (system and GPU) is not saturated, though I don't understand the reference.\r\nI have tested the gist and it has the same behavior as in my local machine: nothing is saturated and the process is slow.\r\nIs there any reason why to expect RAM to be saturated as the dataset is not cached ?\r\nAlso, should I request assistance in the Forum instead ?\r\nThanks", "@Raa23 ! \r\nPlease post this issue on [keras-team/keras repo](https://github.com/keras-team/keras/issues) or TF forum.\r\nTo know more see;\r\n[https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999](https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999) . Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 54084, "title": "[ROCm] Update TF to call HipSolver for most LA functions in ROCm 4.5+", "body": null, "comments": ["The AMD ROCm community CI Build failure is not related to this PR. The fix is in https://github.com/tensorflow/tensorflow/pull/54093", "@chsigg Ping on this PR. ", "@gbaned  any updates on this PR?", "The problem why it wasn't merged is that there is an unused variable. This requires either commenting about it on this PR, so you can fix it, or fixing it ourselves. In the future, if you want speedier merges, please compile with -Wunused-variable\r\nI am now fixing the unused variable issue and hopefully then this PR can be merged."]}, {"number": 54083, "title": "iOS app size increasing", "body": "Hey dear TensorFlow team.\r\nI am using  following lib on my iOS application  `pod 'TensorFlowLiteSwift', '~> 0.0.1-nightly', :subspecs => ['Metal','CoreML']`\r\nEvery time when I am trying to read .tflite, my app size is increasing.\r\nI discovered and found some interesting think inside the app container AppData->tmp \r\n<img width=\"1215\" alt=\"Screen Shot 2022-01-25 at 22 45 39\" src=\"https://user-images.githubusercontent.com/34054539/151039294-2bd9033f-f13f-4f39-93e1-ddc5da661d31.png\">\r\n\r\nWhy does it create a Core ML Compiled Model each time and not be deleted after being freed?\r\nPlease  help me , this is a really blocker \ud83d\ude4f", "comments": ["@PahlevanyanSamvel \r\nIn order to expedite the trouble-shooting process here,Could you please fill the issue [template](https://github.com/tensorflow/tensorflow/issues/new/choose), please refer to this similar issues [link](https://stackoverflow.com/questions/61760647/xcode-11-4-why-my-application-size-is-increased-from-8-mb-to-80-mb-with-just-i), [link1](https://stackoverflow.com/questions/41387752/why-is-our-app-size-increasing-drastically-with-little-change-of-function) and let us know if it helps?\r\nThanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54083\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54083\">No</a>\n"]}, {"number": 54082, "title": "[TF:TRT] Add NHWC layout support to FusedBatchNorm converter", "body": "The FusedBatchNorm was originally supporting only NCHW layouts. There are cases, however, where the operations needs to be executed in NHWC format, as a result of not being able to properly convert certain TRT segments to that data layout.\r\n\r\nThis PR adds support for NHWC by implementing two ElementWise layers for the fused scale and offset operations. This is a temporary workaround until a proper layout optimizer is capable of converting all possible segments to NCHW format.", "comments": ["cc: @bixia1", "@bixia1 PR commits have been squashed, so this should be ready to merge now. Thank you."]}, {"number": 54081, "title": "Fix assertion failure on proto decode", "body": "Cherrypick 691f8c040f3589bc2b3ed86c450fa2414f71335f and 14fea662350e7c26eb5fe1be2ac31704e5682ee6 on r2.5", "comments": []}, {"number": 54080, "title": "Fix assertion failure on proto decode", "body": "Cherrypick 691f8c040f3589bc2b3ed86c450fa2414f71335f and 14fea662350e7c26eb5fe1be2ac31704e5682ee6 on r2.6", "comments": []}, {"number": 54079, "title": "Fix assertion failure on proto decode", "body": "Cherrypick 691f8c040f3589bc2b3ed86c450fa2414f71335f and 14fea662350e7c26eb5fe1be2ac31704e5682ee6 on r2.7", "comments": []}, {"number": 54076, "title": "Merge pull request #53695 from yongtang:53660-tf.sparse.split-crash", "body": "PiperOrigin-RevId: 420811652\r\nChange-Id: I83742482770ba0bf7c3ccd57508c40fb9cdbe2f7", "comments": []}, {"number": 54075, "title": "Merge pull request #53695 from yongtang:53660-tf.sparse.split-crash", "body": "PiperOrigin-RevId: 420811652\r\nChange-Id: I83742482770ba0bf7c3ccd57508c40fb9cdbe2f7", "comments": []}, {"number": 54074, "title": "Merge pull request #53695 from yongtang:53660-tf.sparse.split-crash", "body": "PiperOrigin-RevId: 420811652\r\nChange-Id: I83742482770ba0bf7c3ccd57508c40fb9cdbe2f7", "comments": []}, {"number": 54073, "title": "Merge pull request #53695 from yongtang:53660-tf.sparse.split-crash", "body": "PiperOrigin-RevId: 420811652\r\nChange-Id: I83742482770ba0bf7c3ccd57508c40fb9cdbe2f7", "comments": []}, {"number": 54072, "title": "Merge pull request #52707 from elfringham:init_ops_test_fix", "body": "PiperOrigin-RevId: 416941851\r\nChange-Id: Iefa5a9b841b053b36f6b105cd82c9d32d5e47850", "comments": []}]