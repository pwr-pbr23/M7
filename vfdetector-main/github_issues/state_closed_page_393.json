[{"number": 42173, "title": "[INTEL MKL] Matmul + Tanh fusion", "body": "This PR enables Matmul + Tanh fusion in MKL", "comments": ["Thanks for the review."]}, {"number": 42172, "title": "`DepthwiseConv2D` is no faster than `Conv2D`", "body": "I'm reimplementing [MobileNet](https://arxiv.org/abs/1704.04861), but I find the depthwise convolution is no faster than conv2d(I haven't included the 1 by 1 pointwise convolution yet). Here's the test code run on colab: https://colab.research.google.com/drive/1nBuYrmmH5kM0jbtIZdsuiG6uJbU6mpA7?usp=sharing\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport time\r\nx = tf.random.normal((2, 64, 64, 3))\r\nconv = tf.keras.layers.Conv2D(16, 3, strides=1, padding='same')\r\ndw = tf.keras.layers.DepthwiseConv2D(3, padding='same')\r\nstart = time.time()\r\nconv(x)\r\nprint('conv2d:', time.time() - start)    # approximate 0.0036s\r\nstart = time.time()\r\ndw(x)\r\nprint('dw:', time.time() - start)    # approximate 0.0034s\r\n%timeit conv(x)    # 1000 loops, best of 3: 225 \u00b5s per loop\r\n%timeit dw(x)    # 1000 loops, best of 3: 352 \u00b5s per loop\r\n```\r\n\r\nI also try it on my laptop using CPUs only, similar results are spotted. Any idea of how to speed up `DepthwiseConv2D`?\r\n", "comments": ["@xlnwel \r\n\r\nI have tried in colab with TF version 2.3, nightly versions.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/33f43ac514e69990d8e6666d725ddf65/untitled233.ipynb).You are also seeing the same behavior?\r\nThanks!", "Hi @ravikyram \r\n\r\nI ran the link you provide. It runs on CPU and the result is shown in the following figure\r\n\r\n![image](https://user-images.githubusercontent.com/10184153/89783345-5e55d380-db49-11ea-84cf-f9bd336c50cb.png)\r\n\r\n\r\nThe following figure shows the result on GPU\r\n\r\n![image](https://user-images.githubusercontent.com/10184153/89783290-48e0a980-db49-11ea-9a89-6dde23e0f30f.png)\r\n\r\nI also run the code on my laptop. Here's the result\r\n\r\n![image](https://user-images.githubusercontent.com/10184153/89783482-98bf7080-db49-11ea-9731-d114f6689d50.png)\r\n\r\nAnd notice that all the results simply report the comparisons between depthwise convolution and the standard convolution. The depthwise separable convolution consists of depthwise convolution and an additional 1x1 standard convolution. So the depthwise separable convolutions seem slower than the standard convolutions despite the theoretical promise, am I right?", "@xlnwel I agree with you. I think the `dw` is slower when you have smaller dataset. \r\nI checked by increasing dataset to 100 by updating one line of your code to  `x = tf.random.normal((100, 64, 64, 3))`\r\n\r\nWith colab (GPU) I see the following results (with `x = tf.random.normal((100, 64, 64, 3))`)\r\n\r\n> conv2d: 0.0032930374145507812\r\n> dw: 0.0029036998748779297\r\n> 1000 loops, best of 3: 805 \u00b5s per loop\r\n> 1000 loops, best of 3: 339 \u00b5s per loop\r\n\r\nWith colab (GPU) I see the following results (with `x = tf.random.normal((1000, 64, 64, 3))`)\r\n\r\n> conv2d: 0.16669487953186035\r\n> dw: 0.012159109115600586\r\n> 1000 loops, best of 3: 8.34 ms per loop\r\n> 100 loops, best of 3: 2.79 ms per loop\r\n> \r\n\r\n[Here](https://colab.research.google.com/gist/jvishnuvardhan/f44955d2a895365e81c19e4f3348f310/untitled233.ipynb) is the gist for your reference.\r\n\r\nPlease verify once and close the issue if this was resolved for you. Thanks!\r\n", "Hi, @jvishnuvardhan \r\n\r\nThanks for the observation. I see similar results as you reported. I also test the performance using inputs like `x = tf.random.normal((1000, 8, 8, 3))` and find dw is slower:\r\n\r\n> 1000 loops, best of 3: 208 \u00b5s per loop\r\n1000 loops, best of 3: 322 \u00b5s per loop\r\n\r\nI'll be careful to use dw in my research. Thanks again."]}, {"number": 42171, "title": " AttributeError: 'NoneType' object has no attribute 'outer_context'", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\n\r\n**Describe the expected behavior**\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\nEpoch 1/3\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-28-e5e1b2f4217c> in <module>()\r\n      1 history = model.fit([np.array(X_train), GetGazetteersFeatures(X_train)], y_train, validation_split = 0.2,\r\n----> 2                     batch_size=batch_size, epochs=3, verbose=1)\r\n\r\n10 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in _method_wrapper(self, *args, **kwargs)\r\n    106   def _method_wrapper(self, *args, **kwargs):\r\n    107     if not self._in_multi_worker_mode():  # pylint: disable=protected-access\r\n--> 108       return method(self, *args, **kwargs)\r\n    109 \r\n    110     # Running inside `run_distribute_coordinator` already.\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\r\n   1096                 batch_size=batch_size):\r\n   1097               callbacks.on_train_batch_begin(step)\r\n-> 1098               tmp_logs = train_function(iterator)\r\n   1099               if data_handler.should_sync:\r\n   1100                 context.async_wait()\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)\r\n    778       else:\r\n    779         compiler = \"nonXla\"\r\n--> 780         result = self._call(*args, **kwds)\r\n    781 \r\n    782       new_tracing_count = self._get_tracing_count()\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)\r\n    821       # This is the first call of __call__, so we have to initialize.\r\n    822       initializers = []\r\n--> 823       self._initialize(args, kwds, add_initializers_to=initializers)\r\n    824     finally:\r\n    825       # At this point we know that the initialization is complete (or less\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in _initialize(self, args, kwds, add_initializers_to)\r\n    695     self._concrete_stateful_fn = (\r\n    696         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\r\n--> 697             *args, **kwds))\r\n    698 \r\n    699     def invalid_creator_scope(*unused_args, **unused_kwds):\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)\r\n   2853       args, kwargs = None, None\r\n   2854     with self._lock:\r\n-> 2855       graph_function, _, _ = self._maybe_define_function(args, kwargs)\r\n   2856     return graph_function\r\n   2857 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _maybe_define_function(self, args, kwargs)\r\n   3211 \r\n   3212       self._function_cache.missed.add(call_context_key)\r\n-> 3213       graph_function = self._create_graph_function(args, kwargs)\r\n   3214       self._function_cache.primary[cache_key] = graph_function\r\n   3215       return graph_function, args, kwargs\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)\r\n   3073             arg_names=arg_names,\r\n   3074             override_flat_arg_shapes=override_flat_arg_shapes,\r\n-> 3075             capture_by_value=self._capture_by_value),\r\n   3076         self._function_attributes,\r\n   3077         function_spec=self.function_spec,\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\r\n    984         _, original_func = tf_decorator.unwrap(python_func)\r\n    985 \r\n--> 986       func_outputs = python_func(*func_args, **func_kwargs)\r\n    987 \r\n    988       # invariant: `func_outputs` contains only Tensors, CompositeTensors,\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in wrapped_fn(*args, **kwds)\r\n    598         # __wrapped__ allows AutoGraph to swap in a converted function. We give\r\n    599         # the function a weak reference to itself to avoid a reference cycle.\r\n--> 600         return weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n    601     weak_wrapped_fn = weakref.ref(wrapped_fn)\r\n    602 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)\r\n    971           except Exception as e:  # pylint:disable=broad-except\r\n    972             if hasattr(e, \"ag_error_metadata\"):\r\n--> 973               raise e.ag_error_metadata.to_exception(e)\r\n    974             else:\r\n    975               raise\r\n\r\nAttributeError: in user code:\r\n\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\r\n        return step_function(self, iterator)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:796 step_function  **\r\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\r\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\r\n        return self._call_for_each_replica(fn, args, kwargs)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\r\n        return fn(*args, **kwargs)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:789 run_step  **\r\n        outputs = model.train_step(data)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:747 train_step\r\n        y_pred = self(x, training=True)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:985 __call__\r\n        outputs = call_fn(inputs, *args, **kwargs)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:386 call\r\n        inputs, training=training, mask=mask)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:508 _run_internal_graph\r\n        outputs = node.layer(*args, **kwargs)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:985 __call__\r\n        outputs = call_fn(inputs, *args, **kwargs)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:903 call\r\n        result = self.function(inputs, **kwargs)\r\n    <ipython-input-18-c52c410a00c9>:4 ElmoEmbedding\r\n        sequence_len=tf.constant(batch_size*[max_len]))[\"elmo\"]\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py:1655 __call__\r\n        return self._call_impl(args, kwargs)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/wrap_function.py:247 _call_impl\r\n        args, kwargs, cancellation_manager)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py:1673 _call_impl\r\n        return self._call_with_flat_signature(args, kwargs, cancellation_manager)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py:1722 _call_with_flat_signature\r\n        return self._call_flat(args, self.captured_inputs, cancellation_manager)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py:1929 _call_flat\r\n        forward_function, args_with_tangents = forward_backward.forward()\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py:1433 forward\r\n        self._inference_args, self._input_tangents)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py:1189 forward\r\n        self._forward_and_backward_functions(inference_args, input_tangents))\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py:1389 _forward_and_backward_functions\r\n        outputs, inference_args, input_tangents)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py:899 _build_functions_for_outputs\r\n        src_graph=self._func_graph)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:551 _GradientsHelper\r\n        to_ops, from_ops, colocate_gradients_with_ops, func_graphs, xs_set)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:124 _PendingCount\r\n        between_op_list, between_ops, colocate_gradients_with_ops)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_state.py:780 MaybeCreateControlFlowState\r\n        loop_state.AddWhileContext(op, between_op_list, between_ops)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_state.py:577 AddWhileContext\r\n        outer_forward_ctxt = forward_ctxt.outer_context\r\n\r\n    AttributeError: 'NoneType' object has no attribute 'outer_context'\r\n\r\n", "comments": ["@venkatreddyt,\r\nIn order to expedite the trouble-shooting process, could you please provide the TensorFlow version, the complete code and the dataset you are using. Thanks!", "changing version to %tensorflow_version 1.x, solved the issue,\r\nThanks!"]}, {"number": 42170, "title": "Error when trying to run MobileNetV2 on esp32 (abort)", "body": "@tensorflow/micro\r\n\r\n**System information**\r\n- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04 (tensorflow), Windows 10 (microcontroller ide)\r\n- TensorFlow installed from (source or binary): \r\n- Tensorflow version (commit SHA if source): 2.3.0\r\n- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): esp32(with external ram)\r\n\r\n**Describe the problem**\r\n\r\nI am trying to run MobileNetV2 on esp32, the model creation and conversion code is:\r\n\r\n`base_model = tf.keras.applications.MobileNetV2(input_shape=(48, 48, 1), alpha=0.35, weights=None, include_top=False)\r\nx = base_model.output\r\nx = tf.keras.layers.Flatten()(x)\r\nx = tf.keras.layers.Dense(2)(x) #final layer with softmax activation for N classes\r\npreds = tf.keras.layers.Softmax()(x)\r\nmodel = tf.keras.models.Model(inputs=base_model.input,outputs=preds) #specify the inputs and outputs\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\ndef representative_dataset():\r\n  for i in range(500):\r\n    yield([np.random.rand(1,48,48,1).astype(np.float32)])\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\r\nconverter.representative_dataset = representative_dataset\r\ntflite_model = converter.convert()\r\nopen(\"mobilenet_test.tflite\", \"wb\").write(tflite_model)`\r\n\r\nI am loading the tflite into partition called tensorflow_model, the esp32 code:\r\n`    // alloc the tensor data on external RAM\r\n    tensor_arena = (uint8_t *) heap_caps_malloc(kTensorArenaSize, MALLOC_CAP_SPIRAM);\r\n\r\n    printf(\"tesnor arena at addr: %p\\r\\n\", tensor_arena);\r\n\r\n    // Find the cry_model partition in the partition table\r\n    const esp_partition_t *partition = esp_partition_find_first(ESP_PARTITION_TYPE_DATA, \r\n                                                                ESP_PARTITION_SUBTYPE_ANY, \r\n                                                                \"tensorflow_model\");\r\n\r\n    // Map the partition to data memory\r\n    ESP_ERROR_CHECK(esp_partition_mmap(partition, \r\n                                       0, \r\n                                       partition->size, \r\n                                       SPI_FLASH_MMAP_DATA, \r\n                                       &tensorflow_model_data,\r\n                                       &map_handle));\r\n\r\n    ESP_LOGI(TAG, \"Mapped tensorflow_model partition to data memory address %p\", tensorflow_model_data);\r\n\r\n    // Set up logging. Google style is to avoid globals or statics because of\r\n    // lifetime uncertainty, but since this has a trivial destructor it's okay.\r\n    // NOLINTNEXTLINE(runtime-global-variables)\r\n    static tflite::MicroErrorReporter micro_error_reporter;\r\n    error_reporter = &micro_error_reporter;\r\n\r\n    // Map the model into a usable data structure. This doesn't involve any\r\n    // copying or parsing, it's a very lightweight operation.\r\n    model = tflite::GetModel(tensorflow_model_data);\r\n    if (model->version() != TFLITE_SCHEMA_VERSION) \r\n    {\r\n        TF_LITE_REPORT_ERROR(error_reporter,\r\n                             \"Model provided is schema version %d not equal \"\r\n                             \"to supported version %d.\",\r\n                             model->version(), TFLITE_SCHEMA_VERSION);\r\n        return;\r\n    }\r\n\r\n    static tflite::AllOpsResolver resolver;\r\n\r\n    // Build an interpreter to run the model with.\r\n    static tflite::MicroInterpreter static_interpreter(model,\r\n                                                       resolver, \r\n                                                       tensor_arena, \r\n                                                       kTensorArenaSize, \r\n                                                       error_reporter);\r\n    interpreter = &static_interpreter;\r\n\r\n    // Allocate memory from the tensor_arena for the model's tensors.\r\n    TfLiteStatus allocate_status = interpreter->AllocateTensors();\r\n    if (allocate_status != kTfLiteOk) \r\n    {\r\n        ESP_LOGI(TAG, \"AllocateTensors() failed\");\r\n        return;\r\n    }\r\n    TfLiteStatus invoke_status = interpreter->Invoke();\r\n    if (invoke_status != kTfLiteOk) {\r\n      TF_LITE_REPORT_ERROR(error_reporter, \"Invoke failed\\n\");\r\n    }`\r\n\r\nthe code crush in invoke with :\r\nabort() was called at PC 0x401134f7 on core 0\r\n0x401134f7: tflite::PreprocessSoftmaxScaling(double, double, int, int*, int*) at C:\\work\\projects\\rhino\\build/../components/tfmicro/tensorflow/lite/kernels/internal/quantization_util.cc:96\r\n (inlined by) tflite::PreprocessSoftmaxScaling(double, double, int, int*, int*) at C:\\work\\projects\\rhino\\build/../components/tfmicro/tensorflow/lite/kernels/internal/quantization_util.cc:296\r\n\r\n\r\nELF file SHA256: 8bf88518f1fe95d5\r\n\r\nBacktrace: 0x40087ca9:0x3ffb5390 0x40088061:0x3ffb53b0 0x401134f7:0x3ffb53d0 0x400ed948:0x3ffb5400 0x400d93c2:0x3ffb5480 0x400d548d:0x3ffb54a0 0x400d562f:0x3ffb54d0 0x400d0ff0:0x3ffb5610 0x4008c141:0x3ffb5630\r\n0x40087ca9: invoke_abort at C:/work/esp-idf/components/esp32/panic.c:155\r\n\r\n0x40088061: abort at C:/work/esp-idf/components/esp32/panic.c:172\r\n\r\n0x401134f7: tflite::PreprocessSoftmaxScaling(double, double, int, int*, int*) at C:\\work\\projects\\rhino\\build/../components/tfmicro/tensorflow/lite/kernels/internal/quantization_util.cc:96\r\n (inlined by) tflite::PreprocessSoftmaxScaling(double, double, int, int*, int*) at C:\\work\\projects\\rhino\\build/../components/tfmicro/tensorflow/lite/kernels/internal/quantization_util.cc:296\r\n\r\n0x400ed948: tflite::ops::micro::activations::SoftmaxEval(TfLiteContext*, TfLiteNode*) at C:\\work\\projects\\rhino\\build/../components/tfmicro/tensorflow/lite/micro/kernels/softmax.cc:57\r\n (inlined by) tflite::ops::micro::activations::SoftmaxEval(TfLiteContext*, TfLiteNode*) at C:\\work\\projects\\rhino\\build/../components/tfmicro/tensorflow/lite/micro/kernels/softmax.cc:118\r\n\r\n0x400d93c2: tflite::MicroInterpreter::Invoke() at C:\\work\\projects\\rhino\\build/../components/tfmicro/tensorflow/lite/micro/micro_interpreter.cc:285\r\n\r\n0x400d548d: setup_model_data() at C:\\work\\projects\\rhino\\build/../main/main.cc:145\r\n\r\n0x400d562f: app_main at C:\\work\\projects\\rhino\\build/../main/main.cc:232\r\n\r\n0x400d0ff0: main_task at C:/work/esp-idf/components/esp32/cpu_start.c:553\r\n\r\n0x4008c141: vPortTaskWrapper at C:/work/esp-idf/components/freertos/port.c:143\r\n\r\nThanks, \r\n", "comments": ["@YarivCol \r\nPlease refer to [this issue comment](https://github.com/openthread/ot-esp32/issues/3#issuecomment-633198220) and let us know if it helps.", "@Saduf2019 \r\nHi, The crash seems to be related to the Softmax layer, when we remove the layer everything works fine.\r\nThe Softmax fail asserting tfmicro/tensorflow/lite/kernels/internal/quantization_util.cc:96.\r\n", "@YarivCol , cold you specify your Tensorflow **sources** SHA?\r\nYou can use the command: `git rev-parse --short HEAD`", "@mr-goldhands \r\nTensorflow sources SHA: b36436b087bd8e8701ef51718179037cccdfc26e", "@mr-goldhands any updates?\r\n@rockyrhodes \r\n", "@mr-goldhands \r\n@rockyrhodes \r\n@jvishnuvardhan \r\n@Saduf2019 \r\n\r\nAny updates?, I sent the commit SHA:  b36436b087bd8e8701ef51718179037cccdfc26e\r\n", "@YarivCol have you resolved the issue? Could you please check with latest master of TFLu?", "@YarivCol  This is a micro related issue,Please post this in [micro repository](https://github.com/tensorflow/tflite-micro/issues)   and move this issue to close status..Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42170\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42170\">No</a>\n"]}, {"number": 42169, "title": "python2.7", "body": "There is a problem come from ubuntu coding. ", "comments": ["@deadlyaxio \r\n\r\nPlease, fill [issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\n\r\nCan you please elaborate about the issue & the context.Will it be possible to provide related code.Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 42168, "title": "Update TensorFlow docs for a11y", "body": "### Description:\r\n\r\nHey @lamberta @MarkDaoust @yashk2810, \r\n\r\nI've put together a few small commits to update the TensorFlow docs for more inclusive language. It's to do with ~~\u201dNative\u201d~~ -> \u201cBuilt-in\u201d. (Source: an a11y [presentation](https://docs.google.com/presentation/d/1UVHzuMo5Ef1zUCZ3qdFwDQh-aVHpkYnY73TrJ2yHt3E/edit#slide=id.g6fe49527a0_0_334) by @heyawhite\u2014a tech writer at Google). \r\n\r\n[Link to diffs](https://github.com/tensorflow/docs/compare/master...8bitmp3:master).\r\n\r\nIf you're OK with these changes, I can submit a PR.\r\n\r\n### Submit a pull request?\r\n\r\nYes, can do\r\n\r\n### Affected docs:\r\n\r\n- TF testing best practices guide\r\n- TensorFlow (R1) C++ API guide\r\n- TF 1.x Eager mode notebook\r\n- TensorFlow Customization basics notebook\r\n- Build TensorFlow on Windows guide\r\n- TensorFlow 2 migration notebook\r\n- tf.function notebook\r\n- TF create an op in C++ guide\r\n- TF (R1) Adding a new op in C++ guide", "comments": ["Hi @8bitmp3 \r\n\r\nYes, for the most part this looks like a great change. Take a look through the Google dev docs style guide for inclusive language: https://developers.google.com/style/inclusive-documentation\r\n\r\nBut will need to make sure the context fits and it remains technically accurate. For example, \"native code\" has a meaning that \"built-in\" might not account for.", "Would also be useful to add some of these words to the `nblint` style module for Google dev docs: https://github.com/tensorflow/docs/blob/master/tools/tensorflow_docs/tools/nblint/style/google.py", "Added an inclusive language check to `nblint` (https://github.com/tensorflow/docs/commit/1dd9809aaeaab958acd847ae29b4de87c79668fe). Can now use this to find issues in notebooks (wordlist should be easy to update). It's also part of the CI on the tensorflow/docs repo.\r\n\r\n```\r\n$ python3 -m pip install -U --user git+https://github.com/tensorflow/docs\r\n\r\n# Accepts notebooks or directories as arguments\r\n$ python3 -m tensorflow_docs.tools.nblint --arg=repo:tensorflow/docs notebook.ipynb\r\n```", "Also see https://github.com/apps/in-solidarity. I wrote it last week and have it running on the googlemaps org right now.", "> Added an inclusive language check to nblint (tensorflow/docs@1dd9809). \r\n\r\n@lamberta Nice one. For the wordlist in `nblint` (`/tools/tensorflow_docs/tools/nblint/style/google.py`), what do you think about these:\r\n\r\n\u201cturn on\u201d -> \u201ctoggle (the) on (switch)\u201d\r\n\u201cfirst class\u201d -> \u201cfeature, built-in, top-level\u201d\r\n\u201ccripple\u201d -> \u201cnegatively impact\u201d\r\n\u201csimply\u201d -> False (Jim Fisher\u2019s Don\u2019t Say Simply)\r\n\u201cas you can see\u201d -> False\r\n\u201csee\u201d -> \u201cgo to\u201d\r\n\r\nThis is more challenging:\r\n\u201cenable\u201d -> \u201ctoggle/switch on\" or \"allow\u201d\r\n\u201cdisable\u201d -> \u201ctoggle/switch off\" or \"disallow\u201d\r\n(also \"enabled\" and \"disabled\")\r\n\r\ncc @jpoehnelt @heyawhite", "Makes sense. We should create separate lint checks to distinguish between inclusive language versus regular ole' unclear language. Ideally, every lint rule can link to a page in the [Google Dev Docs Style Guide](https://developers.google.com/style/highlights).", "Closing this issue since work was done and there's no specific action item left. Thanks"]}, {"number": 42167, "title": " ValueError: No gradients provided for any variable", "body": "For the code\r\n\r\n    import  tensorflow as tf\r\n    \r\n    y_N= tf.Variable([1., 2., 3.],name=\"dd\")\r\n    cost = -tf.reduce_mean(input_tensor=tf.reduce_sum(input_tensor=tf.math.log(y_N), axis=0))\r\n    \r\n    loss=lambda:cost\r\n    \r\n    train_step = tf.keras.optimizers.Adam(0.5).minimize(loss, var_list=[y_N])\r\n\r\n\r\nI got error\r\n\r\n    ValueError: No gradients provided for any variable: ['dd:0'].", "comments": ["You have to put the computation inside lambda so that it fits in the scope of `GradientTape`.\r\n\r\n```python\r\nimport  tensorflow as tf\r\n\r\ny_N= tf.Variable([1., 2., 3.],name=\"dd\")\r\n\r\nloss=lambda: -tf.reduce_mean(input_tensor=tf.reduce_sum(input_tensor=tf.math.log(y_N), axis=0))\r\n\r\ntrain_step = tf.keras.optimizers.Adam(0.5).minimize(loss, var_list=[y_N])\r\n```\r\n\r\nhttps://colab.research.google.com/drive/1dOxkRdJ2GY31hC7S1rqs00H0Ft26fLBe?usp=sharing", "@tianhuat \r\nI ran the code with the changes and do not face any error, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/2ae0717ccd683507d63bd59b7048a7a8/untitled356.ipynb)", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42167\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42167\">No</a>\n", "Thanks, it works."]}, {"number": 42166, "title": "libcudart.so.10.1 is not included in the cuda 10.2 package", "body": "I'm trying to see enabled GPUs in tensorflow by the following: \r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.python.client import device_lib\r\nimport os\r\nos.environ[\"TF_MIN_GPU_MULTIPROCESSOR_COUNT\"]=\"2\"\r\nos.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\r\nprint(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\r\n```\r\nIt returns 0 GPUs because it is looking for a `cuda` library called 'libcudart.so.10.1'. \r\nWhat I tried to so was rename the latest file `libcudart.so.10.2.89` to `libcudart.so.10.1` with no success.\r\nThe only way we can probably get this to work is by building from source which takes 10 hours on my machine. \r\nCan you make tensorflow to point to libcudart.so.10.2 in tensorflow 2.3?\r\n\r\nThanks,\r\n\r\n", "comments": ["Try installing CUDnn....", "@vinhdiesal \r\n\r\nCan you please see https://github.com/tensorflow/tensorflow/issues/34759#issuecomment-633819017 will help you?\r\nFor using cuda 10.2 you have to install TF from source. \r\nAlso refer https://github.com/tensorflow/tensorflow/issues/38194#issuecomment-629801937, #39247\r\nThanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42166\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42166\">No</a>\n"]}, {"number": 42165, "title": "ES32 Hello World project crashing in the target", "body": "Please go to Stack Overflow for help and support:\r\n\r\n------------------------\r\n\r\n### System information\r\n\r\n-   **Have I written custom code (as opposed to using a stock example script\r\n    provided in TensorFlow)**: No\r\n-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS Catalina\r\n-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue\r\n    happens on a mobile device**: No\r\n-   **TensorFlow installed from (source or binary)**: Source\r\n-   **TensorFlow version (use command below)**: v2.3.0\r\n-   **Python version**: Python 3.7\r\n-   **Bazel version (if compiling from source)**:\r\n-   **GCC/Compiler version (if compiling from source)**:\r\n-   **CUDA/cuDNN version**:\r\n-   **GPU model and memory**:\r\n-   **Exact command to reproduce**:\r\n\r\nmake -f tensorflow/lite/micro/tools/make/Makefile TARGET=esp generate_hello_world_esp_project\r\n\r\ncd tensorflow/lite/micro/tools/make/gen/esp_xtensa-esp32/prj/hello_world/esp-idf\r\n\r\nidf.py build\r\n\r\nidf.py --port /dev/ttyUSB0 flash\r\n\r\nidf.py --port /dev/ttyUSB0 monitor\r\n\r\n### Describe the problem\r\nI am trying the hello world example for tensor flow lite for microcontrollers. I am using an ESP32-CAM board which uses ESP32-S module. I generate the code as mentioned here https://github.com/tensorflow/tensorflow/tree/v2.2.0/tensorflow/lite/micro/examples/hello_world\r\n\r\nAfter flashing the binary the module continuously resets. Please check the idf monitor logs.\r\n\r\n### Source code / logs\r\nRebooting...\r\nets Jun  8 2016 00:22:57\r\n\r\nrst:0xc (SW_CPU_RESET),boot:0x13 (SPI_FAST_FLASH_BOOT)\r\nconfigsip: 0, SPIWP:0xee\r\nclk_drv:0x00,q_drv:0x00,d_drv:0x00,cs0_drv:0x00,hd_drv:0x00,wp_drv:0x00\r\nmode:DIO, clock div:2\r\nload:0x3fff0030,len:4\r\nload:0x3fff0034,len:7176\r\nload:0x40078000,len:13696\r\nho 0 tail 12 room 4\r\nload:0x40080400,len:4000\r\n0x40080400: _init at ??:?\r\n\r\nentry 0x40080688\r\nI (31) boot: ESP-IDF v4.2-dev-1660-g7d7521367 2nd stage bootloader\r\nI (31) boot: compile time 15:00:22\r\nI (31) boot: chip revision: 1\r\nI (35) boot_comm: chip revision: 1, min. bootloader chip revision: 0\r\nI (42) boot.esp32: SPI Speed      : 40MHz\r\nI (47) boot.esp32: SPI Mode       : DIO\r\nI (51) boot.esp32: SPI Flash Size : 2MB\r\nI (56) boot: Enabling RNG early entropy source...\r\nI (61) boot: Partition Table:\r\nI (65) boot: ## Label            Usage          Type ST Offset   Length\r\nI (72) boot:  0 nvs              WiFi data        01 02 00009000 00006000\r\nI (80) boot:  1 phy_init         RF data          01 01 0000f000 00001000\r\nI (87) boot:  2 factory          factory app      00 00 00010000 00100000\r\nI (95) boot: End of partition table\r\nI (99) boot_comm: chip revision: 1, min. application chip revision: 0\r\nI (106) esp_image: segment 0: paddr=0x00010020 vaddr=0x3f400020 size=0x09af0 ( 39664) map\r\nI (130) esp_image: segment 1: paddr=0x00019b18 vaddr=0x3ffb0000 size=0x02854 ( 10324) load\r\nI (135) esp_image: segment 2: paddr=0x0001c374 vaddr=0x40080000 size=0x00404 (  1028) load\r\n0x40080000: _WindowOverflow4 at /Users/sudeep_subi/software/esp-idf/components/freertos/xtensa/xtensa_vectors.S:1730\r\n\r\nI (137) esp_image: segment 3: paddr=0x0001c780 vaddr=0x40080404 size=0x03898 ( 14488) load\r\nI (152) esp_image: segment 4: paddr=0x00020020 vaddr=0x400d0020 size=0x4ea20 (322080) map\r\n0x400d0020: _stext at ??:?\r\n\r\nI (277) esp_image: segment 5: paddr=0x0006ea48 vaddr=0x40083c9c size=0x063ec ( 25580) load\r\n0x40083c9c: prvReceiveGeneric at /Users/sudeep_subi/software/esp-idf/components/esp_ringbuf/ringbuf.c:760\r\n\r\nI (294) boot: Loaded app from partition at offset 0x10000\r\nI (295) boot: Disabling RNG early entropy source...\r\nI (295) cpu_start: Pro cpu up.\r\nI (299) cpu_start: Application information:\r\nI (303) cpu_start: Project name:     hello_world\r\nI (309) cpu_start: App version:      1\r\nI (313) cpu_start: Compile time:     Aug  9 2020 15:00:14\r\nI (319) cpu_start: ELF file SHA256:  242d4cfeca1609d0...\r\nI (325) cpu_start: ESP-IDF:          v4.2-dev-1660-g7d7521367\r\nI (332) cpu_start: Starting app cpu, entry point is 0x400816d4\r\n0x400816d4: call_start_cpu1 at /Users/sudeep_subi/software/esp-idf/components/esp32/cpu_start.c:286\r\n\r\nI (323) cpu_start: App cpu up.\r\nI (342) heap_init: Initializing. RAM available for dynamic allocation:\r\nI (349) heap_init: At 3FFAE6E0 len 00001920 (6 KiB): DRAM\r\nI (355) heap_init: At 3FFB51A0 len 0002AE60 (171 KiB): DRAM\r\nI (361) heap_init: At 3FFE0440 len 00003AE0 (14 KiB): D/IRAM\r\nI (368) heap_init: At 3FFE4350 len 0001BCB0 (111 KiB): D/IRAM\r\nI (374) heap_init: At 4008A088 len 00015F78 (87 KiB): IRAM\r\nI (380) cpu_start: Pro cpu start user code\r\nI (399) spi_flash: detected chip: generic\r\nI (399) spi_flash: flash io: dio\r\nW (399) spi_flash: Detected size(4096k) larger than the size in the binary image header(2048k). Using the size in the binary image header.\r\nI (410) cpu_start: Starting scheduler on PRO CPU.\r\nI (0) cpu_start: Starting scheduler on APP CPU.\r\n8 bytes lost due to alignment. To avoid this loss, please make sure the tensor_arena is 16 bytes aligned.\r\nGuru Meditation Error: Core  0 panic'ed (StoreProhibited). Exception was unhandled.\r\n\r\nCore  0 register dump:\r\nPC      : 0x400d3848  PS      : 0x00060230  A0      : 0x800d3805  A1      : 0x3ffb6fd0  \r\n0x400d3848: loop at /Users/sudeep_subi/junk/esp32_examples/esp-idf/build/../main/main_functions.cc:100\r\n\r\nA2      : 0x00000000  A3      : 0x00000014  A4      : 0x40c90fdb  A5      : 0x383f8000  \r\nA6      : 0x3ffb8fc8  A7      : 0x00000000  A8      : 0x00000000  A9      : 0x3ffb6fc0  \r\nA10     : 0x00000000  A11     : 0x41a00000  A12     : 0x00000001  A13     : 0xffffffff  \r\nA14     : 0x00000005  A15     : 0x00000004  SAR     : 0x00000001  EXCCAUSE: 0x0000001d  \r\nEXCVADDR: 0x00000000  LBEG    : 0x400029ac  LEND    : 0x400029cb  LCOUNT  : 0x00000000  \r\n\r\nBacktrace:0x400d3845:0x3ffb6fd0 0x400d3802:0x3ffb6ff0 0x400d21d6:0x3ffb7010 0x40084719:0x3ffb7040\r\n0x400d3845: loop at /Users/sudeep_subi/junk/esp32_examples/esp-idf/build/../main/main_functions.cc:100\r\n\r\n0x400d3802: app_main at /Users/sudeep_subi/junk/esp32_examples/esp-idf/build/../main/esp/main.cc:21 (discriminator 1)\r\n\r\n0x400d21d6: main_task at /Users/sudeep_subi/software/esp-idf/components/esp32/cpu_start.c:580\r\n\r\n0x40084719: vPortTaskWrapper at /Users/sudeep_subi/software/esp-idf/components/freertos/xtensa/port.c:143\r\n\r\n\r\n\r\nELF file SHA256: 242d4cfeca1609d0", "comments": ["I've hit this as well.\r\n\r\n@dheeptuck Downgrading to tensorflow-2.2.0 worked around the issue for me in the interim.", "Another workaround is to remove TF_LITE_STATIC_MEMORY in the CCFLAGS/CXXFLAGS.\r\nI did a bisect and the first time the problem occurred was in commit fbf407383c93774d10bd7c45cd66788a070b0e07 (Fri Jun 19 10:40:30 2020 -0700).", "A possible fix is #42653", "I am trying to build this possible fix on the top of v2.3.0 but I am getting following error:\r\n\r\n> -- Configuring done\r\n> CMake Error at /home/rafael/esp/esp-idf/tools/cmake/project.cmake:461 (target_link_libraries):\r\n>   Error evaluating generator expression:\r\n> \r\n>     $<IN_LIST:-DTF_LITE_STATIC_MEMORY,$<TARGET_PROPERTY:__idf_tfmicro,COMPILE_OPTIONS>>\r\n> \r\n>   Expression did not evaluate to a known generator expression\r\n> Call Stack (most recent call first):\r\n>   CMakeLists.txt:3 (project)\r\n> \r\n> \r\n> CMake Error in main/CMakeLists.txt:\r\n>   Error evaluating generator expression:\r\n> \r\n>     $<IN_LIST:-DTF_LITE_STATIC_MEMORY,$<TARGET_PROPERTY:__idf_tfmicro,COMPILE_OPTIONS>>\r\n> \r\n>   Expression did not evaluate to a known generator expression\r\n> \r\n> \r\n> -- Generating done\r\n> -- Build files have been written to: /home/rafael/tensorflow/tensorflow/lite/micro/tools/make/gen/esp_xtensa-esp32/prj/hello_world/esp-idf/build\r\n> cmake failed with exit code 1", "> I am trying to build this possible fix on the top of v2.3.0 but I am getting following error:\r\n> \r\n> > -- Configuring done\r\n> > CMake Error at /home/rafael/esp/esp-idf/tools/cmake/project.cmake:461 (target_link_libraries):\r\n> > Error evaluating generator expression:\r\n> > ```\r\n> > $<IN_LIST:-DTF_LITE_STATIC_MEMORY,$<TARGET_PROPERTY:__idf_tfmicro,COMPILE_OPTIONS>>\r\n> > ```\r\n> > \r\n> > \r\n> > Expression did not evaluate to a known generator expression\r\n> > Call Stack (most recent call first):\r\n> > CMakeLists.txt:3 (project)\r\n> > CMake Error in main/CMakeLists.txt:\r\n> > Error evaluating generator expression:\r\n> > ```\r\n> > $<IN_LIST:-DTF_LITE_STATIC_MEMORY,$<TARGET_PROPERTY:__idf_tfmicro,COMPILE_OPTIONS>>\r\n> > ```\r\n> > \r\n> > \r\n> > Expression did not evaluate to a known generator expression\r\n> > -- Generating done\r\n> > -- Build files have been written to: /home/rafael/tensorflow/tensorflow/lite/micro/tools/make/gen/esp_xtensa-esp32/prj/hello_world/esp-idf/build\r\n> > cmake failed with exit code 1\r\n\r\nI met the same issue, how did you resolve it ? \r\nthanks.", "@heqiqi @rafasimionato  I hit the issue with cmake \"Error evaluating generator expression:\". This seems to be caused by the use of the COMPILE_OPTIONS variable. This was introduced in cmake 3.11 which is quite new. You need to upgrade cmake. Alternatively you can try removing the offending line.", "> @heqiqi @rafasimionato I hit the issue with cmake \"Error evaluating generator expression:\". This seems to be caused by the use of the COMPILE_OPTIONS variable. This was introduced in cmake 3.11 which is quite new. You need to upgrade cmake. Alternatively you can try removing the offending line.\r\n\r\nThanks @felixcollins ... this has worked for v2.4.1 ...\r\n\r\nBut if you guys are building this version, just pay attention to https://github.com/tensorflow/tensorflow/issues/46083 too.", "@rafasimionato I met the same issue too. Thank you .Your answers are of great help to me,"]}, {"number": 42164, "title": "Difference between TF2.3 and TF2.2[MKL]", "body": "I am working on project and we are trying to make TF use functions that we have written, these functions are there in the form of a .so file, we managed to get Tensorflow2.2 to use our MatMul function, but it stopped working for TF2.4. We achieved our aim in TF2.2 by using LD_PRELOAD, Any guesses as to why this has happened. An important detail is that both of these TF environments we built from source with MKL support (--config=mkl)\r\nAlso these are the function defined inside our .so file (nm command on the .so file, screenshot)\r\n", "comments": ["> I am working on project and we are trying to make TF use functions that we have written, these functions are there in the form of a .so file, we managed to get Tensorflow2.2 to use our MatMul function, but it stopped working for TF2.4. We achieved our aim in TF2.2 by using LD_PRELOAD, Any guesses as to why this has happened. An important detail is that both of these TF environments we built from source with MKL support (--config=mkl)\r\n> Also these are the function defined inside our .so file (nm command on the .so file, screenshot)\r\n\r\n![Screenshot from 2020-08-08 21-38-06](https://user-images.githubusercontent.com/44555985/89737985-d8775100-da92-11ea-9853-04c082583e95.png)\r\n", "@penpornk can you help please?", "I am assuming you are providing your own implementation of cblas_gemm. We made some changes between 2.2 and 2.3 and no longer call clbas_gemm, instead we use dnnl_sgemm.  If you want TF+MKL to use cblas_gemm you have to change the code.\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/mkl/mkl_matmul_op.cc#L174  and recompile. Note, we will removing the cblas calls soon.", "@agramesh1 Thanks! that helps... I could just change the function name in the .so file (I'll ask my peers to recompile). Also Can you tell me 2 things or point me to resource where I can read abt them\r\n1.   ` ` `\r\nauto eigen_tp =\r\n        MklDnnThreadPoolWrapper::GetInstance().CreateThreadPoolPtr(ctx);\r\n` ` `\r\nwhat does this bit here do? \r\n2. what is the difference b/w dnnl_sgemm and dnnl_sgemm_tp\r\n", "@electricSamarth \r\n\r\nauto eigen_tp = MklDnnThreadPoolWrapper::GetInstance().CreateThreadPoolPtr(ctx);\r\nwhat does this bit here do?\r\nA: it's used for thread pool.\r\n \r\nwhat is the difference b/w dnnl_sgemm and dnnl_sgemm_tp\r\nA: not use thread pool or use.\r\n", "ThankYou @NeoZhangJianyu ! :)"]}, {"number": 42163, "title": "Could not create cudnn handle: CUDNN_STATUS_ALLOC_FAILED", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): I don't really how to tell\r\n- TensorFlow version: 2.1\r\n- Python version: 3.6.10\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source): Im not really sure what that means either\r\n- GCC/Compiler version (if compiling from source): again can't tell\r\n- CUDA/cuDNN version: 10.1 / 7.6.5\r\n- GPU model and memory: Nividia Geforce RTX 2060 4604 MB memory\r\n\r\n\r\n\r\n**Describe the problem**\r\nI ran then ran this code to check if the compiler can discover my gpu and to see the difference in speed between it and cpu:\r\n\r\n```\r\nimport tensorflow as tf\r\ndevice_name = tf.test.gpu_device_name()\r\nif device_name != '/device:GPU:0':\r\n  raise SystemError('GPU device not found')\r\nprint('Found GPU at: {}'.format(device_name))\r\nimport timeit\r\n\r\ndevice_name = tf.test.gpu_device_name()\r\nif device_name != '/device:GPU:0':\r\n  print(\r\n      '\\n\\nThis error most likely means that this notebook is not '\r\n      'configured to use a GPU.  Change this in Notebook Settings via the '\r\n      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\r\n  raise SystemError('GPU device not found')\r\n\r\ndef cpu():\r\n  with tf.device('/cpu:0'):\r\n    random_image_cpu = tf.random.normal((100, 100, 100, 3))\r\n    net_cpu = tf.keras.layers.Conv2D(32, 7)(random_image_cpu)\r\n    return tf.math.reduce_sum(net_cpu)\r\n\r\ndef gpu():\r\n  with tf.device('/device:GPU:0'):\r\n    random_image_gpu = tf.random.normal((100, 100, 100, 3))\r\n    net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\r\n    return tf.math.reduce_sum(net_gpu)\r\n  \r\n# We run each op once to warm up; see: https://stackoverflow.com/a/45067900\r\ncpu()\r\ngpu()\r\n\r\n# Run the op several times.\r\nprint('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\r\n      '(batch x height x width x channel). Sum of ten runs.')\r\nprint('CPU (s):')\r\ncpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\r\nprint(cpu_time)\r\nprint('GPU (s):')\r\ngpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\r\nprint(gpu_time)\r\nprint('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))\r\n\r\n```\r\n\r\nand it returned the following error:\r\n\r\n\r\n```\r\nFound GPU at: /device:GPU:0\r\n---------------------------------------------------------------------------\r\nUnknownError                              Traceback (most recent call last)\r\n<ipython-input-1-121519b30cf2> in <module>\r\n     29 # We run each op once to warm up; see: https://stackoverflow.com/a/45067900\r\n     30 cpu()\r\n---> 31 gpu()\r\n     32 \r\n     33 # Run the op several times.\r\n\r\n<ipython-input-1-121519b30cf2> in gpu()\r\n     24   with tf.device('/device:GPU:0'):\r\n     25     random_image_gpu = tf.random.normal((100, 100, 100, 3))\r\n---> 26     net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\r\n     27     return tf.math.reduce_sum(net_gpu)\r\n     28 \r\n\r\n~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py in __call__(self, inputs, *args, **kwargs)\r\n    820           with base_layer_utils.autocast_context_manager(\r\n    821               self._compute_dtype):\r\n--> 822             outputs = self.call(cast_inputs, *args, **kwargs)\r\n    823           self._handle_activity_regularization(inputs, outputs)\r\n    824           self._set_mask_metadata(inputs, outputs, input_masks)\r\n\r\n~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\convolutional.py in call(self, inputs)\r\n    207       inputs = array_ops.pad(inputs, self._compute_causal_padding())\r\n    208 \r\n--> 209     outputs = self._convolution_op(inputs, self.kernel)\r\n    210 \r\n    211     if self.use_bias:\r\n\r\n~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_ops.py in __call__(self, inp, filter)\r\n   1133           call_from_convolution=False)\r\n   1134     else:\r\n-> 1135       return self.conv_op(inp, filter)\r\n   1136     # copybara:strip_end\r\n   1137     # copybara:insert return self.conv_op(inp, filter)\r\n\r\n~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_ops.py in __call__(self, inp, filter)\r\n    638 \r\n    639   def __call__(self, inp, filter):  # pylint: disable=redefined-builtin\r\n--> 640     return self.call(inp, filter)\r\n    641 \r\n    642 \r\n\r\n~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_ops.py in __call__(self, inp, filter)\r\n    237         padding=self.padding,\r\n    238         data_format=self.data_format,\r\n--> 239         name=self.name)\r\n    240 \r\n    241 \r\n\r\n~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_ops.py in conv2d(input, filter, strides, padding, use_cudnn_on_gpu, data_format, dilations, name, filters)\r\n   2009                            data_format=data_format,\r\n   2010                            dilations=dilations,\r\n-> 2011                            name=name)\r\n   2012 \r\n   2013 \r\n\r\n~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_nn_ops.py in conv2d(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\r\n    931             input, filter, strides=strides, use_cudnn_on_gpu=use_cudnn_on_gpu,\r\n    932             padding=padding, explicit_paddings=explicit_paddings,\r\n--> 933             data_format=data_format, dilations=dilations, name=name, ctx=_ctx)\r\n    934       except _core._SymbolicException:\r\n    935         pass  # Add nodes to the TensorFlow graph.\r\n\r\n~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_nn_ops.py in conv2d_eager_fallback(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name, ctx)\r\n   1020   explicit_paddings, \"data_format\", data_format, \"dilations\", dilations)\r\n   1021   _result = _execute.execute(b\"Conv2D\", 1, inputs=_inputs_flat, attrs=_attrs,\r\n-> 1022                              ctx=ctx, name=name)\r\n   1023   if _execute.must_record_gradient():\r\n   1024     _execute.record_gradient(\r\n\r\n~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\r\n     65     else:\r\n     66       message = e.message\r\n---> 67     six.raise_from(core._status_to_exception(e.code, message), None)\r\n     68   except TypeError as e:\r\n     69     keras_symbolic_tensors = [\r\n\r\n~\\anaconda3\\lib\\site-packages\\six.py in raise_from(value, from_value)\r\n\r\nUnknownError: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. [Op:Conv2D]\r\n```\r\n\r\nI've tried the solutions mentioned here https://forums.developer.nvidia.com/t/could-not-create-cudnn-handle-cudnn-status-alloc-failed/108261/2 but to no avail.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nI've tried using Tensorflow GPU accelerator in google colab with local runtime on my machine, I've followed all the steps precisely on https://www.tensorflow.org/install/gpu \r\n\r\n**Any other info / logs**\r\nthis is the log from the jupyter terminal:\r\n\r\n```\r\n2020-08-09 04:37:22.168805: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n2020-08-09 04:37:24.322956: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\n2020-08-09 04:37:24.329330: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll\r\n2020-08-09 04:37:25.599803: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties:\r\npciBusID: 0000:01:00.0 name: GeForce RTX 2060 computeCapability: 7.5\r\ncoreClock: 1.335GHz coreCount: 30 deviceMemorySize: 6.00GiB deviceMemoryBandwidth: 312.97GiB/s\r\n2020-08-09 04:37:25.607874: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n2020-08-09 04:37:25.616921: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll\r\n2020-08-09 04:37:25.626584: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll\r\n2020-08-09 04:37:25.635135: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll\r\n2020-08-09 04:37:25.650044: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll\r\n2020-08-09 04:37:25.659390: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll\r\n2020-08-09 04:37:25.681098: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\r\n2020-08-09 04:37:25.686397: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\r\n2020-08-09 04:37:26.217444: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-08-09 04:37:26.222044: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0\r\n2020-08-09 04:37:26.225124: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N\r\n2020-08-09 04:37:26.228586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/device:GPU:0 with 4604 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5)\r\n2020-08-09 04:37:26.239786: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties:\r\npciBusID: 0000:01:00.0 name: GeForce RTX 2060 computeCapability: 7.5\r\ncoreClock: 1.335GHz coreCount: 30 deviceMemorySize: 6.00GiB deviceMemoryBandwidth: 312.97GiB/s\r\n2020-08-09 04:37:26.249100: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n2020-08-09 04:37:26.254350: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll\r\n2020-08-09 04:37:26.260971: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll\r\n2020-08-09 04:37:26.265307: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll\r\n2020-08-09 04:37:26.271569: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll\r\n2020-08-09 04:37:26.276251: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll\r\n2020-08-09 04:37:26.281798: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\r\n2020-08-09 04:37:26.287682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\r\n2020-08-09 04:37:26.291846: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-08-09 04:37:26.298235: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0\r\n2020-08-09 04:37:26.300794: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N\r\n2020-08-09 04:37:26.305262: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/device:GPU:0 with 4604 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5)\r\n2020-08-09 04:37:26.313775: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties:\r\npciBusID: 0000:01:00.0 name: GeForce RTX 2060 computeCapability: 7.5\r\ncoreClock: 1.335GHz coreCount: 30 deviceMemorySize: 6.00GiB deviceMemoryBandwidth: 312.97GiB/s\r\n2020-08-09 04:37:26.328318: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n2020-08-09 04:37:26.339994: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll\r\n2020-08-09 04:37:26.345874: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll\r\n2020-08-09 04:37:26.352587: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll\r\n2020-08-09 04:37:26.359694: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll\r\n2020-08-09 04:37:26.365286: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll\r\n2020-08-09 04:37:26.371099: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\r\n2020-08-09 04:37:26.375749: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\r\n2020-08-09 04:37:26.380113: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties:\r\npciBusID: 0000:01:00.0 name: GeForce RTX 2060 computeCapability: 7.5\r\ncoreClock: 1.335GHz coreCount: 30 deviceMemorySize: 6.00GiB deviceMemoryBandwidth: 312.97GiB/s\r\n2020-08-09 04:37:26.393424: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n2020-08-09 04:37:26.403150: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll\r\n2020-08-09 04:37:26.408577: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll\r\n2020-08-09 04:37:26.423141: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll\r\n2020-08-09 04:37:26.428838: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll\r\n2020-08-09 04:37:26.434061: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll\r\n2020-08-09 04:37:26.438479: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\r\n2020-08-09 04:37:26.443288: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\r\n2020-08-09 04:37:26.446511: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-08-09 04:37:26.453204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0\r\n2020-08-09 04:37:26.458931: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N\r\n2020-08-09 04:37:26.463016: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4604 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5)\r\n2020-08-09 04:37:26.823644: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\r\n2020-08-09 04:37:27.877441: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_ALLOC_FAILED\r\n2020-08-09 04:37:27.882143: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_ALLOC_FAILED\r\n```\r\n\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@elarbi93 \r\n\r\nI have tried in colab with TF version 2.1, 2.3 and i am not seeing any issue.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/d7f5458a25c0cf39d6555232e6371cf2/untitled232.ipynb).\r\nThe possible solution which can be found in #24828.Thanks!", "@elarbi93 \r\n\r\nPlease add the CUDA, CUPTI, and cuDNN installation directories to the %PATH% environmental variable.Please refer this [doc](https://www.tensorflow.org/install/gpu#windows_setup). Thanks!", "> @elarbi93\r\n> \r\n> Please add the CUDA, CUPTI, and cuDNN installation directories to the %PATH% environmental variable.Please refer this [doc](https://www.tensorflow.org/install/gpu#windows_setup). Thanks!\r\n\r\nas you can see, I already got those in my environmental variables \r\n![image](https://user-images.githubusercontent.com/63730163/89783962-be2f8880-db0f-11ea-8358-27c584e7e9a7.png)\r\n\r\n\r\n> @elarbi93\r\n> \r\n> I have tried in colab with TF version 2.1, 2.3 and i am not seeing any issue.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/d7f5458a25c0cf39d6555232e6371cf2/untitled232.ipynb).\r\n> The possible solution which can be found in #24828.Thanks!\r\n\r\nI've tried it with TF 2.1, 2.2 and 2.3 and I saw no difference, I've also checked the attached issue before and tried the solutions mentioned there but to no avail.", "I also opened this issue but I don't know some people closed that saying set allow_growth=True and closed it. But that's not permanent solution, so since then trying different things.\r\nLiterally, when I installed only Visual Studio 2019 and created a Virtual Environment with tensorflow-gpu==2.3.0. Trust me on this, I ran a sample code which I get this error in previous which is:\r\n`import tensorflow as tf`\r\n`inp = tf.random.normal([32,10,8])`\r\n`lsmt_out = tf.keras.layers.LSTM(4)(inp)`\r\nI didn't get error, believe me! I thought wow, it worked but then I messed it up or I didn't. I installed Anaconda and installed tensorflow-gpu=2.3.0 same. And run that code, Unfortunately I got error saying this thing. And when i ran this on Visual Studio virtual environment, to my freaking misluck I am getting this error. I will definitely find some solution. Trust me on this one.", "Hi @elarbi93 Tested  the issue with TF v2.5 with no error ,please find the[ gist ](https://colab.research.google.com/gist/mohantym/5d2355b925c3224d82e4ff628c110b59/42163.ipynb#scrollTo=njZFz0-SHTIY)here . It seems to be an environment configuration issue and has occurred  earlier. can you also see this links too  [link1](https://stackoverflow.com/questions/53698035/failed-to-get-convolution-algorithm-this-is-probably-because-cudnn-failed-to-in), [link2](https://github.com/tensorflow/tensorflow/issues/39989#issuecomment-638323417) .Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42163\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42163\">No</a>\n"]}, {"number": 42162, "title": "looking for libcudart.so.10 when  libcudart.so.11 installed", "body": "\r\n\r\nusing anacoda\r\nsetting enviroment,\r\ninstalling pip\r\nusing pip to install tensorflow\r\ntestrun\r\npython\r\nimport tensorflow as tf\r\ngives error \r\n\r\n2020-08-08 23:41:49.327601: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\r\n2020-08-08 23:41:49.327623: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\r\n\r\n\r\nso I dutifully went to nvidia and installed cuda.\r\nTrying again give same error.\r\n\r\nusing updatedb and locate I found \r\nthe following instances.\r\n\r\n/usr/local/cuda-11.0/doc/man/man7/libcudart.so.7\r\n/usr/local/cuda-11.0/targets/x86_64-linux/lib/libcudart.so\r\n/usr/local/cuda-11.0/targets/x86_64-linux/lib/libcudart.so.11.0\r\n/usr/local/cuda-11.0/targets/x86_64-linux/lib/libcudart.so.11.0.221\r\n\r\nso it looks like Nvidia has a newer version out then whats been looked at.\r\n\r\nI'm not sure who's error this is, if it's not yours please redirect me to whomever it is. thanks\r\n\r\n**System information**\r\nlinux mint 20,\r\n", "comments": ["@iplayfast,\r\nCUDA 11 compatibility with TensorFlow is currently a work in progress.\r\n\r\nPlease try installing TensorFlow with CUDA 10.1 and cuDNN 7.6 as per the [tested build configurations](https://www.tensorflow.org/install/source#gpu) and let us know if you are facing the same issue. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "@iplayfast \r\n[tensorflow-nightly-gpu](https://pypi.org/project/tf-nightly-gpu/) was released yesterday!\r\nCUDA-11 support is here!", "@iplayfast,\r\nAutomatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42162\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42162\">No</a>\n", "I follow this guide and it helped to build from source: https://towardsdatascience.com/how-to-compile-tensorflow-2-3-with-cuda-11-1-8cbecffcb8d3\r\n\r\nEdit `third_party/gpus/cudas_configure.bzl`\r\nReplace with \"11.0\" string\r\n\r\n```\"cudart\": _check_cuda_lib_params(\r\n    \"cudart\",\r\n    cpu_value,\r\n    cuda_config.config[\"cuda_library_dir\"],\r\n    # Comment this out since cudart is still on 11.0 instead of\r\n    # the same as cuda 11.1\r\n    # cuda_config.cuda_version,\r\n    \"11.0\"\r\n    static = False,\r\n),\r\n\"cudart_static\": _check_cuda_lib_params(\r\n    \"cudart_static\",\r\n    cpu_value,\r\n    cuda_config.config[\"cuda_library_dir\"],\r\n    # Comment this out since cudart is still on 11.0 instead of\r\n    # the same as cuda 11.1\r\n    # cuda_config.cuda_version,\r\n    \"11.0\"\r\n    static = True,\r\n),```"]}, {"number": 42161, "title": "[INTEL MKL] Adding MPICH partials and Dockerfiles for OneDNN", "body": "This PR adds [OneDNN](https://github.com/oneapi-src/oneDNN) and `MPICH+Horovod` partials and Dockerfiles for 3 most recent versions of `Ubuntu` that are still supported for a while.\r\n\r\nTo build these docker images, simply run:\r\n\r\n```\r\nalias asm_images=\"docker run --rm -v $(pwd):/tf -v /var/run/docker.sock:/var/run/docker.sock tf-tools python3 assembler.py \"\r\n\r\nTF_VERSION=2.2.0 && asm_images --release onednn --repository intel/intel-optimized-tensorflow --arg BAZEL_VERSION=2.0.0 --arg TF_BRANCH=v${TF_VERSION} --arg TF_PACKAGE_VERSION=${TF_VERSION} --arg _TAG_PREFIX=${TF_VERSION}-ubuntu --build_images --only_tags_matching '.*mpich.*'\r\n```\r\nOnce the builds are complete you should have the following images:\r\n```\r\nintel/intel-optimized-tensorflow:2.2.0-ubuntu-16.04-onednn-devel-mpich-horovod\r\nintel/intel-optimized-tensorflow:2.2.0-ubuntu-16.04-onednn-devel-mpich-horovod-jupyter\r\nintel/intel-optimized-tensorflow:2.2.0-ubuntu-16.04-onednn-mpich-horovod\r\nintel/intel-optimized-tensorflow:2.2.0-ubuntu-16.04-onednn-mpich-horovod-jupyter\r\nintel/intel-optimized-tensorflow:2.2.0-ubuntu-18.04-onednn-devel-mpich-horovod\r\nintel/intel-optimized-tensorflow:2.2.0-ubuntu-18.04-onednn-devel-mpich-horovod-jupyter\r\nintel/intel-optimized-tensorflow:2.2.0-ubuntu-18.04-onednn-mpich-horovod\r\nintel/intel-optimized-tensorflow:2.2.0-ubuntu-18.04-onednn-mpich-horovod-jupyter\r\nintel/intel-optimized-tensorflow:2.2.0-ubuntu-20.04-onednn-devel-mpich-horovod\r\nintel/intel-optimized-tensorflow:2.2.0-ubuntu-20.04-onednn-devel-mpich-horovod-jupyter\r\nintel/intel-optimized-tensorflow:2.2.0-ubuntu-20.04-onednn-mpich-horovod\r\nintel/intel-optimized-tensorflow:2.2.0-ubuntu-20.04-onednn-mpich-horovod-jupyter\r\n```", "comments": ["@angerson Please let me know if you have any questions.\r\nThanks."]}, {"number": 42160, "title": "ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): `Nope`\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): `Windows 10`\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: `No`\r\n- TensorFlow installed from (source or binary): `pip`\r\n- TensorFlow version (use command below): `2.3.0`\r\n- Python version: `3.8.5`\r\n- Bazel version (if compiling from source): `N/A`\r\n- GCC/Compiler version (if compiling from source): `N/A`\r\n- CUDA/cuDNN version: `10.1`\r\n- GPU model and memory: `NVIDIA GeForce GTX 970, 4GB`\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\nWhen I import TensorFlow from Python, a message is printed like below.\r\n\r\n> >>> import tensorflow\r\n> Traceback (most recent call last):\r\n>   File \"C:\\Users\\y\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 64, in <module>\r\n>     from tensorflow.python._pywrap_tensorflow_internal import *\r\n> ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.\r\n> \r\n> During handling of the above exception, another exception occurred:\r\n> \r\n> Traceback (most recent call last):\r\n>   File \"<stdin>\", line 1, in <module>\r\n>   File \"C:\\Users\\y\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\tensorflow\\__init__.py\", line 41, in <module>\r\n>     from tensorflow.python.tools import module_util as _module_util\r\n>   File \"C:\\Users\\y\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\tensorflow\\python\\__init__.py\", line 40, in <module>\r\n>     from tensorflow.python.eager import context\r\n>   File \"C:\\Users\\y\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\tensorflow\\python\\eager\\context.py\", line 35, in <module>\r\n>     from tensorflow.python import pywrap_tfe\r\n>   File \"C:\\Users\\y\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\tensorflow\\python\\pywrap_tfe.py\", line 28, in <module>\r\n>     from tensorflow.python import pywrap_tensorflow\r\n>   File \"C:\\Users\\y\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 83, in <module>\r\n>     raise ImportError(msg)\r\n> ImportError: Traceback (most recent call last):\r\n>   File \"C:\\Users\\y\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 64, in <module>\r\n>     from tensorflow.python._pywrap_tensorflow_internal import *\r\n> ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.\r\n> \r\n> \r\n> Failed to load the native TensorFlow runtime.\r\n> \r\n> See https://www.tensorflow.org/install/errors\r\n> \r\n> for some common reasons and solutions.  Include the entire stack trace\r\n> above this error message when asking for help.\r\n\r\nHopefully, it is not that serious matter to resolve.\r\n\r\n**Describe the expected behavior**\r\nImport TensorFlow successfully.\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\nIf environment is equivalent, then the problem may be reproduced.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["@starjasmine \r\nPlease refer to [this comment](https://github.com/tensorflow/tensorflow/issues/38916#issuecomment-619572753), also, refer similar issues:\r\n\r\n#36167 #36151 #36138 #36054 #36045 #36020 #36003 #35988 #35903 #35880 #35865 #35805 #35789 #35773 #35772 #35767 #35766 #35749 #35721 #35618 #35204 #39007\r\nThanks!", "@Saduf2019 Ok, Thanks! \ud83d\ude03 ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42160\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42160\">No</a>\n"]}, {"number": 42159, "title": "ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\n\r\n**Describe the expected behavior**\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42159\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42159\">No</a>\n"]}, {"number": 42158, "title": "C++17 build without linking libc++", "body": "Based on #23561 and #41710, trying to see if this would enable building on C++17 without also linking in `libc++` (which is a Clang lib, does not come from a default GCC install)", "comments": []}, {"number": 42157, "title": "Input shape for converted tflite model is wrong", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Android 10\r\n- TensorFlow installed from (source or binary):binary\r\n- TensorFlow version (or github SHA if from source):2.4.0-dev20200808\r\n\r\n\r\n**Command used to run the converter or code if you\u2019re using the Python API**\r\nIf possible, please share a link to Colab/Jupyter/any notebook.\r\nhttps://colab.research.google.com/drive/117z3RoXIdk-yhptaQIzjuj_WQ5mIO8wP?usp=sharing\r\n\r\n```\r\nconverter = tf.lite.TFLiteConverter.from_saved_model('/content/ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/saved_model/',signature_keys=['serving_default'])\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nconverter.experimental_new_converter = True\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\r\n\r\ntflite_model = converter.convert()\r\n\r\nwith tf.io.gfile.GFile('model.tflite', 'wb') as f:\r\n  f.write(tflite_model)\r\n```\r\n\r\n**The output from the converter invocation**\r\n\r\nTFLite file: https://drive.google.com/file/d/12lFDByC29jYNa-9V4vzm8poJfTH1zNMI/view?usp=sharing\r\n\r\n**Failure details**\r\nAble to produce the TFLite model, after visualizing the generated .tflite with https://lutzroeder.github.io/netron/ found the input shape of the model is [1,1,1,3] instead of [1,640,640,3].\r\nAndroid Object Detection sample fails to run. I have modified TF_OD_API_SIZE, TF_OD_API_IS_QUANTIZED, TF_OD_API_MODEL_FILE accordingly.\r\n\r\n**Any other info / logs**\r\n```\r\nADB logcat: Cannot copy to a TensorFlowLite tensor (serving_default_input_tensor:0) with 3 bytes from a Java Buffer with 4915200 bytes.\r\n```", "comments": ["Looks like a duplicate of [#42153](https://github.com/tensorflow/tensorflow/issues/42153).", "Current tflite has limited dynamic shape support.\r\n\r\nYou can either set a fixed shape during conversion or resize the input shape.", "@abattery Can you provide some example code for convert SSD ResNet model ?", "@raagapranitha \r\nCould you please try on latest version of tf [2.5] or nightly and let us know if you still face the issue.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42157\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42157\">No</a>\n"]}, {"number": 42156, "title": " Could not dlopen library 'libcudnn.so.7' for CUDA9.1", "body": "I'm using CUDA9.1 and tensorflow version 1.14.0.   When I run the code it is not using the GPUs. It seems it started once I've update the Keras version. Anyway I get this error:\r\n\r\n```\r\n2020-08-08 19:17:16.746067: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\r\n2020-08-08 19:17:16.747865: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\r\n2020-08-08 19:17:16.749660: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\r\n2020-08-08 19:17:16.750029: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\r\n2020-08-08 19:17:16.752270: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\r\n2020-08-08 19:17:16.753794: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\r\n2020-08-08 19:17:16.754002: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda-9.0/lib64:/usr/local/cuda/lib64:/usr/local/cuda-9.1/lib64:\r\n2020-08-08 19:17:16.754018: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1663] Cannot dlopen some GPU libraries. Skipping registering GPU devices...\r\n2020-08-08 19:17:16.754071: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-08-08 19:17:16.754089: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 1\r\n2020-08-08 19:17:16.754097: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N Y\r\n2020-08-08 19:17:16.754103: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 1:   Y N\r\n2020-08-08 19:17:16.762468: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e828a90720 executing computations on platform CUDA. Devices:\r\n2020-08-08 19:17:16.762491: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0\r\n2020-08-08 19:17:16.762499: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (1): Tesla V100-SXM2-32GB, Compute Capability 7.0\r\n2020-08-08 19:17:16.961125: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\r\nW0808 19:17:17.188626 140541490861888 deprecation_wrapper.py:119] From /home/shiftone/vsd-shiftone/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\r\n```", "comments": ["Try installing CUDnn....", "Problem is solved! Thank you very much! ", "Thank You....", "@marlon-shiftone \r\nPlease move the issue to closed status if resolved. ", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 42155, "title": "module 'tensorflow' has no attribute 'HistogramProto'", "body": "", "comments": ["pls provide some information regarding the problem!", "@bengadisoufiane \r\n\r\nPlease, fill [issue template.](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\n\r\nPlease, share colab link or simple standalone code to reproduce the issue.\r\n\r\nRefer the [link](https://stackoverflow.com/questions/42012906/create-a-custom-tensorflow-histogram-summary).\r\nHistogramProto is defined here:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/framework/summary.proto\r\n\r\nThanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42155\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42155\">No</a>\n", "This code deprecated and gave me that error\r\n\r\n```\r\ndef histo_summary(self, tag, values, step, bins=1000):\r\n        \"\"\"Log a histogram of the tensor of values.\"\"\"\r\n\r\n        # Create a histogram using numpy\r\n        counts, bin_edges = np.histogram(values, bins=bins)\r\n\r\n        # Fill the fields of the histogram proto\r\n        hist = tf.HistogramProto()\r\n        hist.min = float(np.min(values))\r\n        hist.max = float(np.max(values))\r\n        hist.num = int(np.prod(values.shape))\r\n        hist.sum = float(np.sum(values))\r\n        hist.sum_squares = float(np.sum(values ** 2))\r\n\r\n        # Drop the start of the first bin\r\n        bin_edges = bin_edges[1:]\r\n\r\n        # Add bin edges and counts\r\n        for edge in bin_edges:\r\n            hist.bucket_limit.append(edge)\r\n        for c in counts:\r\n            hist.bucket.append(c)\r\n\r\n        # Create and write Summary\r\n        summary = tf.Summary(value=[tf.Summary.Value(tag=tag, histo=hist)])\r\n        self.writer.add_summary(summary, step)\r\n        self.writer.flush()\r\n```"]}, {"number": 42154, "title": "tensor_diag_part doc fix", "body": "A documentation fix for #38564 which has been closed but not been fixed. \r\nTo restate the problem, there are two shortcoming in the current documentation:\r\n1) The example (https://www.tensorflow.org/api_docs/python/tf/linalg/tensor_diag_part) for the **tensor_diag_part** shows in the code a call to the **diag_part** function, not to `tensor_diag_part`.\r\n2) The numeric example is chosen such that `diag_part` and `tensor_diag_part` would give the same result. This is not really helpful for somebody looking to see what differentiates these two functions.", "comments": ["@ngc92 can you please check sanity build failures ?", "@ngc92  Any update on this PR? Please. Thanks!"]}, {"number": 42153, "title": "Convert saved model - issue generated shapes", "body": "**System information**\r\n- OS: MAC\r\n- TensorFlow version 2.4.0-dev20200805\r\n\r\n\r\n**Command used to run the converter or code if you\u2019re using the Python API**\r\n\r\n```\r\n!pip install tf-nightly\r\n\r\nimport tensorflow as tf\r\nconverter = tf.lite.TFLiteConverter.from_saved_model('ssd_mobilenet_v2_320x320_coco17_tpu-8/saved_model')\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nconverter.experimental_new_converter = True\r\n\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\r\ntflite_model = converter.convert()\r\n\r\nopen(\"m.tflite\", \"wb\").write(tflite_model)\r\n```\r\n\r\n\r\n**Original Model Input & Output shape**\r\n\r\n![image](https://user-images.githubusercontent.com/68266028/89719024-c337ef00-d9cc-11ea-8858-afc169c5237c.png)\r\n\r\n\r\n**Converted Model Input & Output shape**\r\n\r\n![image](https://user-images.githubusercontent.com/68266028/89719032-e367ae00-d9cc-11ea-9ff2-f5700e7c36a7.png)\r\n\r\n\r\n**Also, please include a link to the saved model {{[LINK MODEL](http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz)}}**\r\n\r\n\r\n\r\n**Please let me know if I have missed anything here, I feel that the model has something wrong! (Shapes are not matched)  As I replaced the model in the Android version of object detection, it gives me errors.**\r\n", "comments": ["Was able to reproduce the issue with the latest TF-nightly. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/164b81ed8effbeafc573b41ded1a64c6/42153.ipynb). Thanks!", "@amahendrakar So there is a problem with mismatching the input-output shapes, right?", "Meet the same problem, I tried to convert an LSTM model with input (None, 200), but after the convert, the input shape for the tflite model becomes (1,1)\r\n\r\noriginal model codes:\r\ninputs = keras.Input(shape=(None,), dtype=\"int32\")\r\nx = layers.Embedding(max_features, 128)(inputs)\r\nx = layers.LSTM(64, return_sequences=True)(x)\r\nx = layers.LSTM(64)(x)           \r\noutputs = layers.Dense(1, activation=\"sigmoid\")(x)\r\nmodel = keras.Model(inputs, outputs)\r\nmodel.summary()\r\n\r\noutput of tflite input details:\r\n![image](https://user-images.githubusercontent.com/23717722/90100790-66f60780-dd0b-11ea-89db-2733a3cd23b5.png)\r\n\r\n", "Current tflite has limited dynamic shape support.\r\n\r\nYou can either set a fixed shape or calling resizeInputShape", "I have the same issue trying to convert custom trained ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8 .\r\nThe convert was successful using tf-nightly but when I'm trying to use the model on android app it throws exception\r\n`java.lang.IllegalArgumentException: Cannot copy to a TensorFlowLite tensor (serving_default_input_tensor:0) with 3 bytes from a Java Buffer with 270000 bytes.\r\n        at org.tensorflow.lite.Tensor.throwIfSrcShapeIsIncompatible(Tensor.java:444)`\r\n\r\nAny way around?", "@Paranormaly  I am also facing exact same issue. Have you resolved it?", "I am also facing the problem.\r\nI have modified the data in the code as much as possible", "Having the same issue with an Efficientdet_d0_512x512 model that I converted to tflite with tf-nightly 2.5.00\r\ninput shape is set to [1, 1, 1, 3]", "Have the same issue with ssdmobilenetv2 in tf2.4 and '2.5.0-dev20210114'.\r\nInput shape is set to [1, 1, 1, 3] when try to load de .tflite file.", "I am also having this issue - does anyone have a resolution?", "> I am also having this issue - does anyone have a resolution?\r\n\r\nHi,\r\nI finally solve the issue using export_tflite_graph_tf2.py from OD API.\r\nI used de checkpoints i have trainning before, and the instructions here:\r\npython object_detection/export_tflite_graph_tf2.py\r\n--pipeline_config_path path/to/ssd_model/pipeline.config\r\n--trained_checkpoint_dir path/to/ssd_model/checkpoint\r\n--output_directory path/to/exported_model_directory\r\n\r\npipeline_config_path is the same config file i used to trainning.\r\nMy version: TF 2.4 Gpu\r\n\r\nGood luck!", "> > I am also having this issue - does anyone have a resolution?\r\n> \r\n> Hi,\r\n> I finally solve the issue using export_tflite_graph_tf2.py from OD API.\r\n> I used de checkpoints i have trainning before, and the instructions here:\r\n> python object_detection/export_tflite_graph_tf2.py\r\n> --pipeline_config_path path/to/ssd_model/pipeline.config\r\n> --trained_checkpoint_dir path/to/ssd_model/checkpoint\r\n> --output_directory path/to/exported_model_directory\r\n> \r\n> pipeline_config_path is the same config file i used to trainning.\r\n> My version: TF 2.4 Gpu\r\n> \r\n> Good luck!\r\n\r\nIt worked for SSD Mobilenet v2.", "@hahmad2008 , Hi did the below comment help you resolve your issue?\r\n\r\n> > I am also having this issue - does anyone have a resolution?\r\n> \r\n> Hi,\r\n> I finally solve the issue using export_tflite_graph_tf2.py from OD API.\r\n> I used de checkpoints i have trainning before, and the instructions here:\r\n> python object_detection/export_tflite_graph_tf2.py\r\n> --pipeline_config_path path/to/ssd_model/pipeline.config\r\n> --trained_checkpoint_dir path/to/ssd_model/checkpoint\r\n> --output_directory path/to/exported_model_directory\r\n> \r\n> pipeline_config_path is the same config file i used to trainning.\r\n> My version: TF 2.4 Gpu\r\n> \r\n> Good luck!\r\n\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42153\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42153\">No</a>\n", "Just want to add few info to this. \r\n\r\nCurrently, tflite support unknown input shape, but limited for dynamic shape support. \r\nTo do 'dynamic shape support', you need to resize input shape every time you do inference. \r\n\r\nref: https://github.com/tensorflow/tensorflow/issues/24607#issuecomment-580951962\r\nref: https://stackoverflow.com/questions/55701663/input-images-with-dynamic-dimensions-in-tensorflow-lite\r\n\r\ntf-nightly i am using is `tf-nightly 2.7.0.dev20210806`", "I encountered the same problem. For me, the problem was that I used **tf.saved_model.save()** function to save my model ( which was a custom keras model ), using the **Model.save()** function solved the problem. "]}, {"number": 42152, "title": "floating point exception in `tf.nn.atrous_conv2d` when there is 0 in filters.shape", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below):2.1.0\r\n- Python version:3.6.9\r\n- Bazel version (if compiling from source):N/A\r\n- GCC/Compiler version (if compiling from source):N/A\r\n- CUDA/cuDNN version:N/A\r\n- GPU model and memory:N/A\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\n`tf.nn.atrous_conv2d` throws floating point exception when the shape of `filters` is `[0,*,*,*]`, or there is `0` in the first three dimension of the shape, e.g. `[*,0,*,*]. [*,*,0,*]`\r\n\r\n**Describe the expected behavior**\r\nExpect no floating point exception\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n~~~python\r\nimport tensorflow as tf\r\ntf.nn.atrous_conv2d(filters=tf.ones((0,1,1,1)), value=tf.ones((1,1,1,1)), rate=1, padding=\"SAME\")\r\ntf.nn.atrous_conv2d(filters=tf.ones((1,0,1,1)), value=tf.ones((1,1,1,1)), rate=1, padding=\"SAME\")\r\ntf.nn.atrous_conv2d(filters=tf.ones((1,1,0,1)), value=tf.ones((1,1,1,1)), rate=1, padding=\"SAME\")\r\n~~~\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n~~~python\r\nFloating point exception (core dumped)\r\n~~~", "comments": ["Colab crashes when the code is run on it.", "@DNXie,\r\nSorry for the delayed response. When tried to reproduce your code in [Colab](https://colab.research.google.com/gist/rmothukuru/3ae57aa459e26ab8510f7d8a24c2095b/gh_42152.ipynb), it is **crashing**, instead of the **`Floating Point Exception`** that you mentioned. Can you please help us to reproduce your issue? Thanks! ", "@rmothukuru \r\nHi,\r\nIn the environment I provided, it throws FPE when running the code in the command line. The FPE is thrown from C++ instead of Python. A FPE thrown from C++ will crash the Python session, that's why colab won't report FPE and can only detect a crash of Python. \r\n\r\nIt is also possible that the buggy behavior differs among environments. But as long as it crashes, it is considered abnormal behavior.\r\n\r\nThanks!", "Was able to replicate the issue in TF 2.6.0-dev20210529 in colab & it  crashes,please find the gist [here](https://colab.research.google.com/gist/sushreebarsa/48e57901256f81051ebef4e5555bceea/untitled98.ipynb)..Thanks !", "I believe this issue has been fixed with the latest nightly. Now an error message is thrown (instead of crash):\r\n\r\n```\r\n$ python3\r\nPython 3.8.10 (default, Jun  2 2021, 10:49:15) \r\n[GCC 9.4.0] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\n>>> tf.nn.atrous_conv2d(filters=tf.ones((0,1,1,1)), value=tf.ones((1,1,1,1)), rate=1, padding=\"SAME\")\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\r\n    raise e.with_traceback(filtered_tb) from None\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\", line 59, in quick_execute\r\n    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: filter must not have zero elements (i.e. all dimensions must be non-zero) [Op:Conv2D]\r\n>>> tf.nn.atrous_conv2d(filters=tf.ones((1,0,1,1)), value=tf.ones((1,1,1,1)), rate=1, padding=\"SAME\")\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\r\n    raise e.with_traceback(filtered_tb) from None\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\", line 59, in quick_execute\r\n    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: filter must not have zero elements (i.e. all dimensions must be non-zero) [Op:Conv2D]\r\n>>> tf.nn.atrous_conv2d(filters=tf.ones((1,1,0,1)), value=tf.ones((1,1,1,1)), rate=1, padding=\"SAME\")\r\n2021-08-18 16:39:22.851505: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at conv_ops.cc:666 : INVALID_ARGUMENT: filter depth must be stricly positive, got 0\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\r\n    raise e.with_traceback(filtered_tb) from None\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\", line 59, in quick_execute\r\n    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: filter depth must be stricly positive, got 0 [Op:Conv2D]\r\n>>> \r\n```\r\n\r\nThis issue can be closed now.", "Close as the issue has been resolved in the latest nightly build. Please feel free to re-open if the issue persists.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42152\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42152\">No</a>\n"]}, {"number": 42151, "title": "tf.nn.ctc_beam_search_decoder expects output of softmax whereas documentation says it expects logits", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.3.0\r\n- Python version: 3.7\r\n\r\n**Describe the current behavior**\r\n\r\nCurrently https://www.tensorflow.org/api_docs/python/tf/nn/ctc_beam_search_decoder says it expects input to be logits, whereas it acutally expects softmax already applied.\r\n\r\nSee https://www.tensorflow.org/api_docs/python/tf/keras/backend/ctc_decode, which expects output of softmax, and it directly passes the input to https://www.tensorflow.org/api_docs/python/tf/nn/ctc_beam_search_decoder - see https://github.com/tensorflow/tensorflow/blob/7b301123019d2b4bbd9c597916ba032f05854074/tensorflow/python/keras/backend.py#L6037-L6088\r\n\r\n**Describe the expected behavior**\r\n\r\nThe documentation of https://www.tensorflow.org/api_docs/python/tf/nn/ctc_beam_search_decoder should say it expects softmax output.\r\n", "comments": ["Note that `ctc_beam_search_decoder` performs beam search decoding on the `logits` given in input.\r\nBelow is the code reference.\r\nhttps://github.com/tensorflow/tensorflow/blob/f894368ea586bae5fa15b1d9f6da4b9265cb5ed3/tensorflow/python/ops/ctc_ops.py#L379-L386", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 42149, "title": "hb", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\n\r\n**Describe the expected behavior**\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["Empty issue, closing", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42149\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42149\">No</a>\n"]}, {"number": 42148, "title": "[ROCm] Enabling XLA specific subtests (for ROCm) within the test `def_function_xla_jit_test`", "body": "/cc @cheshire ", "comments": ["@cheshire \r\n\r\npushed out a change to fix the pylint error...please re-approve.\r\n\r\nthanks"]}, {"number": 42147, "title": "XNNPack delegate undefined reference", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Android 10\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: master\r\n- Python version: 3.6\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source): 3.1.0\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nI'm trying to use xnnpack on Android 10 (arm64-v8a). I was able to build xnnpack delegate lib \r\n\r\n```\r\nbazel build -c opt --config=android_arm64 \\\r\n  //tensorflow/lite/delegates/xnnpack:xnnpack_delegate\r\n```\r\n\r\nAnd it produces static lib libs libxnnpack_delegate.a and libxnnpack_delegate.pic.a. But when linking into my Android project, we still have undefined reference errors as following\r\n```\r\n/proc/self/cwd/tensorflow/lite/delegates/xnnpack/xnnpack_delegate.cc:3119: undefined reference to `xnn_initialize'\r\n```\r\n\r\nI am wondering what we are missing in these steps?\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@andreydung Is this still an issue? https://github.com/tensorflow/tensorflow/issues/42277#issuecomment-674723602", "@ymodak Yes I\u2019m still meeting this issue.", "`bazel` doesn't actually produce self-contained static libs. Can you talk more about how you're using TFLite in your project? Are you using a static or shared library for the core TFLite library? Are you using prebuilts or are you building from source?", "Having the same issue, where is ```xnn_initailize``` defined? I've been able to compile the other delegates by searching the file where it is defined seeing the bazel config and compiling and linking to it. Here, however, this function is not defined anywhere? Thoughts? @jdduke ", "Apologies for the delay, looks like the issue wasn't properly labeled, @multiverse-tf can you help with this one?", "> Having the same issue, where is `xnn_initailize` defined? I've been able to compile the other delegates by searching the file where it is defined seeing the bazel config and compiling and linking to it. Here, however, this function is not defined anywhere? Thoughts? @jdduke\r\n\r\nI've fixed my error. \r\n\r\n**Background:** My interest was to create a wrapper around TFLiteInterpreter, feeding and gathering data from it + delegate support in user friendly way. This means, I had to compile and link XNNPACK delegate with my library. Basically, something very similar to [tensorflow lite task library](https://www.tensorflow.org/lite/inference_with_metadata/task_library/overview).\r\n\r\n**What I did**: It's not very intuitive at start, copy all the compiled files from `bazel-bin`, delegate/XNNPACK folder. This itself has some external dependencies. For a more detailed, follow the thread starting from [this comment](https://github.com/tensorflow/tensorflow/issues/44811#issuecomment-749960005) to the end.\r\n\r\n@andreydung Let me know if that helped :D ", "@andreydung Could you please refer to the above [comment](https://github.com/tensorflow/tensorflow/issues/42147#issuecomment-908882374) and let us know if it helps? Thank you!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42147\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42147\">No</a>\n"]}, {"number": 42146, "title": "Dataset sharding in MultiWorker Mirrored Strategy", "body": "Hi, I am relatively new to distributed TensorFlow. I am running a custom CIFAR10 training code from tensorflow website on 2 Azure VMs. I have made key-less ssh connections between them and have set up TF_CONFIG. My training completes successfully. I just want to know, how CIFAR10 data is getting sharded in my code. First it mentions that it is switching to DATA and then it says it cannot find a shardable source but still it proceeds to train my code. A surprising thing is that with all these errors with sharding in my cluster, my training completes more swiftly as compared to getting trained in a single VM. The logs tell that it cannot shard my code, if this is so, why am I getting a speed increase in training, despite dataset not getting sharded? Please help.\r\n\r\n**ERROR:**\r\n\r\n. Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\r\n You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via.\r\n\r\nAnd then :\r\n\r\n2020-08-01 16:29:05.556918: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:521] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\r\nop: \"FlatMapDataset\"\r\ninput: \"PrefetchDataset/_8\"\r\nattr {\r\n  key: \"Targuments\"\r\n  value {\r\n    list {\r\n    }\r\n  }\r\n}\r\nattr {\r\n  key: \"f\"\r\n  value {\r\n    func {\r\n      name: \"__inference_Dataset_flat_map_slice_batch_indices_39847\"\r\n    }\r\n  }\r\n}\r\nattr {\r\n  key: \"output_shapes\"\r\n  value {\r\n    list {\r\n      shape {\r\n        dim {\r\n          size: -1\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\r\nattr {\r\n  key: \"output_types\"\r\n  value {\r\n    list {\r\n      type: DT_INT64\r\n    }\r\n  }\r\n}\r\n. \r\n\r\n### **System information**\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):\r\n- Python version: 3.5.2\r\n- Bazel version (if compiling from source):\r\n- 2 CPU only machines : Azure D2s V3 (2 cores, 8gb ram)\r\n-Tensorflow 2.2\r\n\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n```\r\n`from` __future__ import absolute_import, division, print_function, unicode_literals\r\nimport tensorflow as tf\r\nimport os\t\r\nimport json \t\r\n\r\nfrom tensorflow.keras import datasets, layers, models\r\nimport matplotlib.pyplot as plt\r\n\r\nstrategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\r\n\r\n(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\r\n\r\n\r\ntrain_images, test_images = train_images / 255.0, test_images / 255.0\r\n\r\nclass_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\r\n               'dog', 'frog', 'horse', 'ship', 'truck']\r\n\r\nplt.figure(figsize=(10,10))\r\nfor i in range(25):\r\n    plt.subplot(5,5,i+1)\r\n    plt.xticks([])\r\n    plt.yticks([])\r\n    plt.grid(False)\r\n    plt.imshow(train_images[i], cmap=plt.cm.binary)\r\n    # The CIFAR labels happen to be arrays, \r\n    # which is why you need the extra index\r\n    plt.xlabel(class_names[train_labels[i][0]])\r\nplt.show()\r\n\r\nwith strategy.scope():\r\n\r\n\tmodel = models.Sequential()\r\n\tmodel.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\r\n\tmodel.add(layers.MaxPooling2D((2, 2)))\r\n\tmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\r\n\tmodel.add(layers.MaxPooling2D((2, 2)))\r\n\tmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\r\n\r\n\r\n#model.summary()\r\n\r\n\r\n\tmodel.add(layers.Flatten())\r\n\tmodel.add(layers.Dense(64, activation='relu'))\r\n\tmodel.add(layers.Dense(10))\r\n\r\n\tmodel.compile(optimizer='adam',\r\n\t              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n\t              metrics=['accuracy'])\r\n\r\nhistory = model.fit(train_images, train_labels, epochs=10, \r\n                    validation_data=(test_images, test_labels))\r\n\r\nplt.plot(history.history['accuracy'], label='accuracy')\r\nplt.plot(history.history['val_accuracy'], label = 'val_accuracy')\r\nplt.xlabel('Epoch')\r\nplt.ylabel('Accuracy')\r\nplt.ylim([0.5, 1])\r\nplt.legend(loc='lower right')\r\n\r\ntest_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\r\n\r\n\r\n\r\n\r\n`print(test_acc)`\r\n```\r\n\r\n\r\n****### ** FULL LOGS******\r\n\r\n\r\n2020-08-01 16:22:46.425007: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\r\n2020-08-01 16:22:46.425047: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\r\n2020-08-01 16:22:47.497587: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\r\n2020-08-01 16:22:47.497633: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\r\n2020-08-01 16:22:47.497673: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance1): /proc/driver/nvidia/version does not exist\r\n2020-08-01 16:22:47.497969: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2020-08-01 16:22:47.505592: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2593905000 Hz\r\n2020-08-01 16:22:47.505762: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5a13560 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-08-01 16:22:47.505844: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2020-08-01 16:22:47.513007: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.0.0.4:12345, 1 -> 10.0.0.5:12345}\r\n2020-08-01 16:22:47.513233: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:405] Started server with target: grpc://10.0.0.4:12345\r\nWARNING:tensorflow:`eval_fn` is not passed in. The `worker_fn` will be used if an \"evaluator\" task exists in the cluster.\r\nWARNING:tensorflow:`eval_strategy` is not passed in. No distribution strategy will be used for evaluation.\r\n2020-08-01 16:22:49.618955: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 614400000 exceeds 10% of free system memory.\r\n2020-08-01 16:22:49.916264: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 614400000 exceeds 10% of free system memory.\r\n2020-08-01 16:22:50.285604: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:521] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\r\nop: \"FlatMapDataset\"\r\ninput: \"PrefetchDataset/_8\"\r\nattr {\r\n  key: \"Targuments\"\r\n  value {\r\n    list {\r\n    }\r\n  }\r\n}\r\nattr {\r\n  key: \"f\"\r\n  value {\r\n    func {\r\n      name: \"__inference_Dataset_flat_map_slice_batch_indices_244\"\r\n    }\r\n  }\r\n}\r\nattr {\r\n  key: \"output_shapes\"\r\n  value {\r\n    list {\r\n      shape {\r\n        dim {\r\n          size: -1\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\r\nattr {\r\n  key: \"output_types\"\r\n  value {\r\n    list {\r\n      type: DT_INT64\r\n    }\r\n  }\r\n}\r\n. Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\r\nEpoch 1/10\r\nWARNING:tensorflow:From /home/iamhassaan/venv/lib/python3.7/site-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.data.Iterator.get_next_as_optional()` instead.\r\n1561/1563 [============================>.] - ETA: 0s - loss: 1.5020 - accuracy: 0.45262020-08-01 16:23:27.691909: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:521] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\r\nop: \"FlatMapDataset\"\r\ninput: \"PrefetchDataset/_8\"\r\nattr {\r\n  key: \"Targuments\"\r\n  value {\r\n    list {\r\n    }\r\n  }\r\n}\r\nattr {\r\n  key: \"f\"\r\n  value {\r\n    func {\r\n      name: \"__inference_Dataset_flat_map_slice_batch_indices_4289\"\r\n    }\r\n  }\r\n}\r\nattr {\r\n  key: \"output_shapes\"\r\n  value {\r\n    list {\r\n      shape {\r\n        dim {\r\n          size: -1\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\r\nattr {\r\n  key: \"output_types\"\r\n  value {\r\n    list {\r\n      type: DT_INT64\r\n    }\r\n  }\r\n}\r\n. Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `1563/1563 [==============================] - 38s 25ms/step - loss: 1.5017 - accuracy: 0.4527 - val_loss: 1.2870 - val_accuracy: 0.5304\r\nEpoch 2/10\r\n1563/1563 [==============================] - 37s 24ms/step - loss: 1.1390 - accuracy: 0.5970 - val_loss: 1.0820 - val_accuracy: 0.6155\r\nEpoch 3/10\r\n1563/1563 [==============================] - 37s 24ms/step - loss: 0.9962 - accuracy: 0.6510 - val_loss: 0.9849 - val_accuracy: 0.6546\r\nEpoch 4/10\r\n1563/1563 [==============================] - 37s 24ms/step - loss: 0.8935 - accuracy: 0.6890 - val_loss: 0.9642 - val_accuracy: 0.6618\r\nEpoch 5/10\r\n1563/1563 [==============================] - 37s 24ms/step - loss: 0.8244 - accuracy: 0.7117 - val_loss: 0.9134 - val_accuracy: 0.6870\r\nEpoch 6/10\r\n1563/1563 [==============================] - 37s 24ms/step - loss: 0.7653 - accuracy: 0.7351 - val_loss: 0.8816 - val_accuracy: 0.6953\r\nEpoch 7/10\r\n1563/1563 [==============================] - 37s 24ms/step - loss: 0.7151 - accuracy: 0.7497 - val_loss: 0.8829 - val_accuracy: 0.6986\r\nEpoch 8/10\r\n1563/1563 [==============================] - 37s 24ms/step - loss: 0.6721 - accuracy: 0.7656 - val_loss: 0.9168 - val_accuracy: 0.6910\r\nEpoch 9/10\r\n1563/1563 [==============================] - 37s 24ms/step - loss: 0.6250 - accuracy: 0.7830 - val_loss: 0.9076 - val_accuracy: 0.7012\r\nEpoch 10/10\r\n1563/1563 [==============================] - 37s 24ms/step - loss: 0.5895 - accuracy: 0.7968 - val_loss: 0.9148 - val_accuracy: 0.7039\r\nWARNING:tensorflow:`eval_fn` is not passed in. The `worker_fn` will be used if an \"evaluator\" task exists in the cluster.\r\nWARNING:tensorflow:`eval_strategy` is not passed in. No distribution strategy will be used for evaluation.\r\n2020-08-01 16:29:05.556918: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:521] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\r\nop: \"FlatMapDataset\"\r\ninput: \"PrefetchDataset/_8\"\r\nattr {\r\n  key: \"Targuments\"\r\n  value {\r\n    list {\r\n    }\r\n  }\r\n}\r\nattr {\r\n  key: \"f\"\r\n  value {\r\n    func {\r\n      name: \"__inference_Dataset_flat_map_slice_batch_indices_39847\"\r\n    }\r\n  }\r\n}\r\nattr {\r\n  key: \"output_shapes\"\r\n  value {\r\n    list {\r\n      shape {\r\n        dim {\r\n          size: -1\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\r\nattr {\r\n  key: \"output_types\"\r\n  value {\r\n    list {\r\n      type: DT_INT64\r\n    }\r\n  }\r\n}\r\n. Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\r\n313/313 - 3s - loss: 0.9148 - accuracy: 0.7039\r\n0.7038999795913696\r\n\r\n\r\n\r\n", "comments": ["Hi @iamhassaan, I agree the logs here are a bit confusing. tf.distribute autoshards the input dataset in multi worker training in one of three ways: `AUTO`, `FILE`, `DATA`. By default the `tf.data.experimental.AutoShardPolicy` is set to `AUTO`, which will  first attempt to shard by `FILE` (the assumption here is that if you're doing multi worker training, you probably have a large dataset spread across a number of files, and not something you can easily load into memory). The attempt to shard by `FILE` fails if a file-based dataset is not detected. tf.distribute will then fall back to sharding by `DATA`. If you scroll to the Sharding section and look for the `DATA` section of the [distributed input guide here](https://www.tensorflow.org/tutorials/distribute/input#tfdistributestrategyexperimental_distribute_dataset), you'll find a little more detail on how the sharding happens in the `DATA` case. \r\n\r\nSo to summarize, for your case that warning you're seeing is just that `AUTO` does not detect files and is switching to `DATA`. But each worker is still processing different data on each step and that's why your training completes successfully (and faster) despite the messages you've reported. If you follow the suggestion in the message to set `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` [(docs here) ](https://www.tensorflow.org/api_docs/python/tf/data/experimental/DistributeOptions) then I don't think you'll see this warning anymore. In general, working with a `tf.data.Dataset` is suggested when doing multi worker training. The datasets in Keras load data into numpy arrays, which I suspect is why you're seeing the message `walked to a node which is not a dataset`\r\n\r\nHope this helps clear up any confusion!", "Thank you so much for the detailed response. While running the experiment I was aware regarding usage of tf.distribute api.\r\n\r\n I have tried setting ```\r\noptions.experimental_distribute.auto_shard_policy = AutoShardPolicy.AUTO to \r\noptions.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA\r\n```, I have even tried changing it to `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.OFF`.  But I get the same logs. Even the performance doesnot change at all after changing it from `.DATA to .OFF` (I experimented this with Mnist dataset). I was getting a speed increase as compared to running jobs in one machine only but changing auto shard policy from .Data to .OFF did not seem to make a difference at all on the cluster I was working on. I got the same training time and both methods produced this error `walked to a node which is not a dataset`. \r\n\r\nAs you mentioned in the above answer Keras loads data into numpy arrays, are you sure that splitting NumPy arrays (datasets) is supported in tf.distribute?\r\n\r\nBy doing several experiments on the API, I think toy datasets are not sharded by tf.distribute regardless of auto_shard_policy.  But computation efficiency is increased since there are 2 machines working to process each batch rather than just 1 machine ? Especially in the cases of toy datasets (numpy, cifar10) ? I will really appreciate your response. Thanks.\r\n\r\n\r\n", "To clarify, you have to use use a `tf.data.Dataset` in order to set the policy. If you haven't converted your numpy data into a `tf.data.Dataset`, you can't set the policy so you'll still see the messages. When I converted your numpy arrays to a `tf.data.Dataset`, and set the `DATA` policy, the message goes away. \r\n\r\n```\r\nstrategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\r\noptions = tf.data.Options()\r\noptions.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.DATA\r\n(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\r\ntrain_images, test_images = train_images / 255.0, test_images / 255.0\r\ntrain_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\r\ntrain_dataset = train_dataset.with_options(options)\r\ntrain_dataset = train_dataset.batch(32)\r\n```\r\n\r\nThe `walked to a node which is not a dataset` you're seeing is also because you're passing in a numpy array and not a `tf.data.Dataset`.\r\n\r\nAs for the behavior of numpy arrays, I believe they get sharded but it's not really a common use case. Generally with multi worker training you use `tf.data` so you can efficiently pipeline the data. Let me do some investigation on the behavior with numpy arrays.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Thank you so much Nikita, I tried your snippet of code. I am really happy that it managed to clear the verbose logs. Please let me know if you are sure whether numpy arrays get sharded or not?  I replicated your code with Numpy dataset. I got rid of messages. But I cannot see any speedup in training? It is almost the same. I used a global batch size of 32000. I utilized two workers. In my first experiment I turned of data sharding to `.OFF` . In the second experiment I turned data sharding to `.DATA` . The training time stays the same. Will really appreciate any final clarifications.\r\n\r\nAlso please let me know how I can set an eval_strategy. As there is one last warning:  `tensorflow:`eval_strategy` is not passed in. No distribution strategy will be used for evaluation. You can then close this :). Thank you for your time\r\n`\r\n\r\n\r\n", "Under the hood, keras `model.fit` converts numpy arrays to a `tf.data.dataset`. This happens regardless of whether you're using a distribution strategy or not. So the behavior should be same if you pass numpy data or a `tf.data.dataset`. The benefit of converting your data to a `tf.data.dataset` first before passing to `model.fit` is that you can add additional transformations to make your input pipeline more efficient, which would help speed your training up if your program is input bound ([more details here](https://www.tensorflow.org/guide/data_performance)). If your batch size stays the same then I would expect the time for a step on each machine to be equivalent for the`.DATA` and `.OFF` sharding because both machines are still processing `GLOBAL_BATCH_SIZE//2` amount of data in each step for both cases. However, in the `.DATA` case the data is different on each machine. So I don't think you should expect a speed up in the time per step, but `.DATA` should converge faster since different data is being seen on both machines. The difference might not be too noticible because your model and dataset are not too large.\r\n\r\nAs for the eval_strategy, that warning is a little confusing unfortunately. It's a legacy warning that has to do with the eval_strategy when using an estimator. A change has just been submitted so that warning should not exist in future versions. You can ignore the warning for now. if you are using `model.fit` then the same distribution strategy will be used for evaluation when you pass in a validation dataset. `MultiWorkerMirroredStrategy` is still in experimental, so as we move it out of experimental some of these confusing warnings will also be removed. ", "I'm getting the same kind of error here. Having read the excellent comments made by @nikitamaia, I made sure that all my datasets (train and val) have auto_shard_policy set to tf.data.experimental.AutoShardPolicy.DATA. Now I'm training with a callback that evaluates the model on each epoch end to calculate recall and precision metrics. So somewhere in my eval code I have something like:\r\n\r\n```\r\ndef eval(model,dataset):\r\n # dataset at this point has auto_shard_policy to DATA\r\n for images,values in dataset:\r\n   truths = values.numpy()\r\n   preds = model.predict_on_batch(images)\r\n   ...\r\n```\r\nAs soon as predict_on_batch is called, I get the warning \r\n\r\n```\r\nIn AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding \r\nas we cannot find appropriate reader dataset op(s) to shard. Error: Found an unshardable \r\nsource dataset: \"TensorDataset/_1\" ...\r\n```\r\n\r\nNormal or not? Is it because of the for loop over my dataset?", "Hi @aginpatrick, seems to be related to #45157. That thread is about `train_on_batch` but I think the same applies for `predict_on_batch`. [Specifically this comment.](https://github.com/tensorflow/tensorflow/issues/45157#issuecomment-788376526)", "Oh I see. I understand that there is nothing to do except ignore this warning right? It's very annoying because in my case I'm training with Google AI Platform and the logs are literally overwhelmed by the multiple outputs of this warning and it's then very difficult to see my \"real\" logs. Anyway, thanks again @nikitamaia for your excellent explanations.", "Happy to help! \r\nYou'll have to ignore the warning for now. I think longterm it would make sense to set the autopolicy to DATA for train and predict on batch, which would get rid of the warning, but I suspect that won't be prioritized any time soon. If anything changes, I'll keep these threads updated.", "Hi @nikitamaia thanks for your valuable comments. I am also getting the same error/warning: tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Found an unsharable source dataset: name: \"TensorDataset/_1\"\r\n\r\nYou told to ignore this warning right? but due to this warning computation speed is very slow. I am working on 3D MRI dataset. Please suggest to improve computational speed. Thanks", "Hi @nikitamaia\r\n\r\nI am getting the same warning, however, I am using instances of ``tf.keras.utils.Sequence`` subclasses to train and validate my model using ``model.fit()``.\r\n\r\nWhat would be the recommended solution? I could in principle wrap my sequences in ``tf.data.Dataset`` objects, but the problem is that the ``on_epoch_end()`` method of my ``tf.keras.utils.Sequence`` subclass will not be called.\r\n\r\nShould I infer from this that ``tf.keras.utils.Sequence`` will be deprecated in the future? or at least deprecated in the case of distributed training?\r\n\r\nThanks.", "With MultiWorkerMirroredStrategy, there are two ways to shard data. Either by FILE, or by DATA. As the name suggests, the FILE policy only works when your data is in files (eg TF Records). If your data is not file based, then you must shard by the DATA policy. This is explained in the [Sharding section of the Distributed Input guide.](https://www.tensorflow.org/tutorials/distribute/input#tfdistributestrategyexperimental_distribute_dataset) There are pros and cons of each policy, and you can see that explained more in detail in the guide.\r\n\r\nIf you are seeing this warning it means that you have not set an autoshardpolicy. That is okay! The default AUTO policy is smart enough to pick the correct policy for you (either FILE or DATA).[ You can see here in the code](https://github.com/tensorflow/tensorflow/blob/r2.4/tensorflow/core/grappler/optimizers/data/auto_shard.cc#L652), that if the defult AUTO Policy is on, it will first try to `ShardByFile`. if your data is not file based, it will issue this warning you are seeing and then `ShardByData`. \r\n```\r\n    case AutoShardPolicy::AUTO:\r\n    default:\r\n      Status s = ShardByFile(*sink_node, num_workers, index, &flib, &graph);\r\n      if (errors::IsNotFound(s)) {\r\n        LOG(WARNING) << \"In AUTO-mode, and switching to DATA-based sharding, \"\r\n                        \"instead of FILE-based sharding as we cannot find \"\r\n                        \"appropriate reader dataset op(s) to shard. Error: \"\r\n                     << s.error_message();\r\n        return ShardByData(*sink_node, num_workers, index, num_replicas,\r\n                           &graph);\r\n      }\r\n      return s;\r\n```\r\n\r\nThe end result is equivalent as to if you had explicitly set the policy to DATA, which is also easily seen a [few lines earlier in the code](https://github.com/tensorflow/tensorflow/blob/r2.4/tensorflow/core/grappler/optimizers/data/auto_shard.cc#L649). Whether you set the policy yourself or use the default AUTO policy, if you do not have file based data then the policy will `ShardByData`\r\n```\r\n    case AutoShardPolicy::DATA:\r\n      return ShardByData(*sink_node, num_workers, index, num_replicas, &graph);\r\n```\r\n\r\nIf you're having performance issues, it is not directly because of this warning. If your data is not file based, the only way to shard is to `ShardByData`, and as shown in the code snippets above, that is precisely what is happening when you see this warning. Feel free to open a new issue if you'd like to pursue any performance debugging, but again this warning is not directly causing slow performance. \r\n\r\nPlease note also that I have modified the wording on this warning in 92bd8e1 and removed the word \"Error\".\r\n", "This warning doesn't seem to serve any apparent purpose and appears to be substantially annoying to anyone who encounters it.", "I have successfully removed this warning on TensorFlow 2.5.2 by dynamically replacing the default autosharding policy, in case anyone is interested.\r\n\r\n```[python]\r\nfrom tensorflow.python.data.util import options as options_lib\r\nfrom tensorflow.data.experimental import DistributeOptions, AutoShardPolicy\r\n\r\nDistributeOptions.auto_shard_policy = options_lib.create_option(\r\n    name=\"auto_shard_policy\",\r\n    ty=AutoShardPolicy,\r\n    docstring=\"The type of sharding to use. See \"\r\n    \"`tf.data.experimental.AutoShardPolicy` for additional information.\",\r\n    default_factory=lambda: AutoShardPolicy.DATA,\r\n)\r\n```"]}, {"number": 42145, "title": "how to make tensorflow2.1.0 to rpm \uff0cor even have some git  link can also", "body": "I want to build tensorflow to rpm is there have any tools to compile ?\r\n\r\nThank U very much", "comments": ["@ibz-james\r\nPlease refer to [this link](https://www.tensorflow.org/install/source) and confirm once done.", "> @ibz-james\r\n> Please refer to [this link](https://www.tensorflow.org/install/source) and confirm once done.\r\nThank you but i don`t want to install tf by pip wheel ,I want to make the source code to rpm . for linux like centos7", "@lzb-James \r\nPlease refer to this [link for build from source](https://www.tensorflow.org/install/source) and let us know.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42145\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42145\">No</a>\n"]}, {"number": 42143, "title": "Fix segmentation fault in tf.image.crop_and_resize when boxes is inf or nan", "body": "This fix tries to address the issue raised in #42129 where segmentation fault\r\nhappened in tf.image.crop_and_resize when boxes is inf or nan.\r\n\r\nThis fix adds the check to make sure boxes is not inf or nan (isfinite)\r\n\r\nThis fix fixes #42129.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["@yongtang Can you please resolve conflicts? Thanks!", "@yongtang, Any update on this PR? Please. Thanks!", "Due to the way GPU/CPU pipeline works in the kernel, it looks like to do a nan check on GPU is not exactly straightforward. That was causing the GPU test failure.\r\n\r\nLet me take another look and see how to resolve this issue.", "@yongtang  Can you please check @sanjoy's comments and keep us posted ? Thanks!", "The test added by the PR does not fail in CUDA if I remove the C++ check that causes the segfaults", "I think I got this fully fixed internally. Running a full suite of tests and sending for review tomorrow."]}, {"number": 42142, "title": "saving a large kersa model through exception", "body": "**saving checkpoint or tf.kersa.models.save_model in non eager mode throws the following exception:\r\nI am using Ubuntu 18 and tried different versions of tensorflow (1.15,2.2,2.4, nightly built) the exceptiong ramdomly changed and complain about different variables ** \r\ntensorflow.python.framework.errors_impl.FailedPreconditionError: Error while reading resource variable voxelnet/rpn/deconv3/deconv3-BatchNorm2d-0/beta from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/voxelnet/rpn/deconv3/deconv3-BatchNorm2d-0/beta/N10tensorflow3VarE does not exist.\r\n\t [[{{node voxelnet/rpn/deconv3/deconv3-BatchNorm2d-0/beta/Read/ReadVariableOp}}]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 632, in <module>\r\n    train(cfgPath,modelPath) \r\n  File \"train.py\", line 566, in train\r\n    raise e\r\n  File \"train.py\", line 391, in train\r\n    save_path = manager.save()\r\n  File \"/home/babak/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/checkpoint_management.py\", line 807, in save\r\n    save_path = self._checkpoint.write(prefix)\r\n  File \"/home/babak/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/tracking/util.py\", line 1543, in write\r\n    output = self._saver.save(file_prefix=file_prefix, session=session)\r\n  File \"/home/babak/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/tracking/util.py\", line 1216, in save\r\n    return session.run(save_path, feed_dict=feed_dict)\r\n  File \"/home/babak/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\", line 958, in run\r\n    run_metadata_ptr)\r\n  File \"/home/babak/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\", line 1181, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/home/babak/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\", line 1359, in _do_run\r\n    run_metadata)\r\n  File \"/home/babak/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\", line 1384, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.FailedPreconditionError: Error while reading resource variable voxelnet/rpn/deconv3/deconv3-BatchNorm2d-0/beta from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/voxelnet/rpn/deconv3/deconv3-BatchNorm2d-0/beta/N10tensorflow3VarE does not exist.\r\n\t [[node voxelnet/rpn/deconv3/deconv3-BatchNorm2d-0/beta/Read/ReadVariableOp (defined at /home/babak/pp/tfpp/models/voxelnet.py:303) ]]\r\n\r\n   **My code sample**\r\n   with sess.as_default():\r\n        with graph.as_default():     \r\n                init = tf.global_variables_initializer()                \r\n                sess.run(init)                                              \r\n                \r\n                model_dir = pathlib.Path(model_dir)  \r\n                \r\n                result_path = model_dir / result_name\r\n                    \r\n                config = pipeline_pb2.TrainEvalPipelineConfig()    \r\n                with open(config_path, \"r\") as f:\r\n                    proto_str = f.read()\r\n                    text_format.Merge(proto_str, config)\r\n            \r\n                #nput_cfg = config.eval_input_reader\r\n                input_cfg = config.train_input_reader\r\n                model_cfg = config.model.second\r\n                train_cfg = config.train_config\r\n                class_names = list(input_cfg.class_names)\r\n                center_limit_range = model_cfg.post_center_limit_range\r\n                \r\n                voxel_generator = voxel_builder.build(model_cfg.voxel_generator)\r\n                bv_range = voxel_generator.point_cloud_range[[0, 1, 3, 4]]\r\n                box_coder = box_coder_builder.build(model_cfg.box_coder)\r\n                target_assigner_cfg = model_cfg.target_assigner\r\n                target_assigner = target_assigner_builder.build(target_assigner_cfg,    \r\n                                                               bv_range, box_coder)\r\n                \r\n                \r\n                net = voxelnet_builder.build(model_cfg, voxel_generator, target_assigner,sess)\r\n                \r\n             \r\n                optimizer_cfg = train_cfg.optimizer\r\n                \r\n                dataset = input_reader_builder.build(\r\n                    input_cfg,\r\n                    model_cfg,\r\n                    training=True,\r\n                    voxel_generator=voxel_generator,\r\n                    target_assigner=target_assigner)    \r\n                eval_dataset = input_reader_builder.build(\r\n                    input_cfg,\r\n                    model_cfg,\r\n                    training=False,\r\n                    voxel_generator=voxel_generator,\r\n                    target_assigner=target_assigner)\r\n                \r\n                def _worker_init_fn(worker_id):\r\n                    time_seed = np.array(time.time(), dtype=np.int32)\r\n                    np.random.seed(time_seed + worker_id)\r\n                    print(f\"WORKER {worker_id} seed:\", np.random.get_state()[1][0])\r\n                    \r\n                dataloader = DataLoader(\r\n                    dataset,\r\n                    batch_size=input_cfg.batch_size,\r\n                    shuffle=False, #True,\r\n                    #num_workers= input_cfg.num_workers,\r\n                    num_workers= 0,\r\n                    pin_memory=False,\r\n                    collate_fn=merge_second_batch)\r\n                    #worker_init_fn=_worker_init_fn)\r\n                \r\n                eval_dataloader = DataLoader(\r\n                    eval_dataset,\r\n                    batch_size=input_cfg.batch_size,\r\n                    shuffle=False,\r\n                    #num_workers=input_cfg.num_workers,\r\n                    num_workers=0,\r\n                    pin_memory=False,\r\n                    collate_fn=merge_second_batch)\r\n                \r\n            \r\n                if train_cfg.enable_mixed_precision:\r\n                    float_dtype = tf.float16\r\n                else:\r\n                    float_dtype = tf.float32\r\n            \r\n                #data_iter = iter(dataloader)\r\n            \r\n                ######################\r\n                # TRAINING\r\n                ######################\r\n                log_path = 'log.txt'\r\n                logf = open(log_path, 'a')\r\n                logf.write(proto_str)\r\n                logf.write(\"\\n\")\r\n                summary_dir = model_dir / 'summary'\r\n                summary_dir.mkdir(parents=True, exist_ok=True)\r\n                writer = SummaryWriter(str(summary_dir))\r\n            \r\n                total_step_elapsed = 0\r\n                #remain_steps = train_cfg.steps - net.get_global_step()\r\n                t = time.time()\r\n                ckpt_start_time = t\r\n            \r\n                total_loop = train_cfg.steps // train_cfg.steps_per_eval + 1\r\n               \r\n                clear_metrics_every_epoch = train_cfg.clear_metrics_every_epoch\r\n            \r\n                if train_cfg.steps % train_cfg.steps_per_eval == 0:\r\n                    total_loop -= 1\r\n                \r\n                initial_learning_rate = \r\n                optimizer_cfg.adam_optimizer.learning_rate.exponential_decay_learning_rate.initial_learning_rate\r\n                decay_steps = optimizer_cfg.adam_optimizer.learning_rate.exponential_decay_learning_rate.decay_steps\r\n                decay_factor = optimizer_cfg.adam_optimizer.learning_rate.exponential_decay_learning_rate.decay_factor\r\n                staircase = optimizer_cfg.adam_optimizer.learning_rate.exponential_decay_learning_rate.staircase\r\n             \r\n                loss_norm_type_dict = {\r\n                        0: LossNormType.NormByNumExamples,\r\n                        1: LossNormType.NormByNumPositives,\r\n                        2: LossNormType.NormByNumPosNeg,\r\n                    }\r\n                \r\n                loss_norm_type = loss_norm_type_dict[model_cfg.loss_norm_type]\r\n                    \r\n                losses = losses_builder.build(model_cfg.loss)\r\n                encode_rad_error_by_sin = model_cfg.encode_rad_error_by_sin\r\n                cls_loss_ftor, loc_loss_ftor, cls_weight, loc_weight, _ = losses\r\n                pos_cls_weight = model_cfg.pos_class_weight\r\n                neg_cls_weight = model_cfg.neg_class_weight\r\n                direction_loss_weight = model_cfg.direction_loss_weight    \r\n                box_code_size=target_assigner.box_coder.code_size\r\n                \r\n                ppLoss = PPLoss(\r\n                    num_class=1,\r\n                    cls_loss_weight=cls_weight,\r\n                    loc_loss_weight=loc_weight,\r\n                    pos_cls_weight=pos_cls_weight,\r\n                    neg_cls_weight=neg_cls_weight,\r\n                    direction_loss_weight=direction_loss_weight,\r\n                    loss_norm_type=loss_norm_type,\r\n                    encode_rad_error_by_sin=encode_rad_error_by_sin,\r\n                    loc_loss_ftor=loc_loss_ftor,\r\n                    cls_loss_ftor=cls_loss_ftor,\r\n                    box_code_size=box_code_size,\r\n                    use_direction_classifier=model_cfg.use_direction_classifier)\r\n                \r\n                         \r\n                try:  \r\n                    global_step = tf.Variable(0, trainable=False)                    \r\n                    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate, decay_steps=decay_steps, \r\n                   decay_rate=decay_factor,staircase=staircase)\r\n                    optimizer = Adam(learning_rate=lr_schedule)    \r\n                    ckpt = tf.train.Checkpoint(step=tf.Variable(1),model=net)##optimizer=optimizer)#, model=model)        \r\n                    manager = tf.train.CheckpointManager(ckpt, \"./tf_ckpts\", max_to_keep=3)      \r\n                    ckpt.restore(manager.latest_checkpoint)\r\n                    if manager.latest_checkpoint:\r\n                        print(\"Restored from {}\".format(manager.latest_checkpoint))\r\n                    else:\r\n                        print(\"Initializing from scratch.\")\r\n                    \r\n                    initv = tf.global_variables_initializer()\r\n                    sess.run(initv)\r\n                    \r\n                    for _ in range(total_loop):\r\n                        if total_step_elapsed + train_cfg.steps_per_eval > train_cfg.steps:\r\n                            steps = train_cfg.steps % train_cfg.steps_per_eval\r\n                        else:\r\n                            steps = train_cfg.steps_per_eval\r\n                        for step in range(steps):\r\n                     \r\n                            example = next(iter(dataloader))\r\n                                                      \r\n                            example_tf = example_convert_to_tf(example, float_dtype)\r\n            \r\n                            batch_size = example[\"anchors\"].shape[0]\r\n                            \r\n                            with tf.GradientTape() as tape:\r\n                                ret_dict = net(example_tf,training=True)\r\n                                loss_value = ppLoss.call(example_tf, ret_dict)\r\n                                \r\n                            gradients = tape.gradient(loss_value[\"loss\"], net.trainable_weights)\r\n                            \r\n                            optimizer.apply_gradients(zip(gradients, net.trainable_weights))\r\n                            \r\n                            print(\"step {} is done!\".format(step))\r\n                            global_step.assign_add(1)\r\n                            if step % 10 == 0 and step != 0:                            \r\n                                    save_path = manager.save()\r\n                                    print(\"Saved checkpoint for step {}: {}\".format(step, save_path))\r\n                                    #print(\"Saving Model for step {}\".format(step))\r\n                                    #print(\"loss {:1.2f}\".format(loss_value[\"loss\"])) \r\n                                    #net._set_inputs(example_tf)\r\n                                    #net.save('./PPModels/ppModel'+str(step),save_format='tf')\r\n                   except Exception as e:\r\n                \r\n                    logf.close()\r\n                    raise e        \r\n            \r\n    logf.close()\r\n\r\n\r\n", "comments": ["@bsaravi,\r\nI was not able to reproduce the issue from the given code. \r\n\r\nCould you please provide the complete code or share the `.py/.ipynb` file you are running along with the dataset? Thanks!", "Thanks for your reply.\r\nPlease look at the zip file the code. the dataset is too huge too upload I have pickled 6 batches which will show you the exception.\r\nPlease run:\r\n      python bugTrain.py\r\nLet me know if you need anything else\r\nThanks again for you help.\r\nBabak\r\n", "@bsaravi,\r\nOn running the `bugTrain.py` file, I am facing an error stating `ModuleNotFoundError: No module named 'fire'`.\r\n\r\nCommenting out that line throws the error `subprocess.CalledProcessError: Command 'python3 -m pybind11 --includes' returned non-zero exit status 1.`. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/e969cb328cab44d46437f813bb6c1b6b/42142.ipynb). \r\n\r\nAlso, the example you have given is fairly complex and it is hard for us to pinpoint the source of the error. Can you remove the dependencies and get the example down to the simplest possible repro so that it will be easy for us to debug the error. Thanks!", "I have corrected the errors you can see the exception on running the files\r\nI just uploaded. The error happened when there is quite complex model\r\nplease let me know if you need anything else.\r\nThanks,\r\nBabak\r\nhttps://colab.research.google.com/gist/amahendrakar/e969cb328cab44d46437f813bb6c1b6b/42142.ipynb\r\n\r\n", "@bsaravi,\r\nI am still facing the same error. Could you please share the updated code/files again?\r\n\r\nAlternatively, you can run your code on Google colab and share the notebook with us. Thanks!", "Also, please take a look at [this similar](https://github.com/tensorflow/tensorflow/issues/28287#issuecomment-495005162) issue and let us know if it helps. Thanks!", "I saw this before it does not help.  I tried to minimize the code. please see the attachment. \r\nI have traced the issue inside the tensorflow as well. The issue is, Checkpoint reads the graph in graph_view.py and create the save operation and sent it to the session to be run.  session can not retrieve the value of the nodes with the names came from graph before there should be a prefix mismatch in the nodes naming.\r\n\r\n[tfbug.zip](https://github.com/tensorflow/tensorflow/files/5068991/tfbug.zip)\r\n. ", "Hi Abhilash,\r\n   Do you have any update?\r\nThanks,\r\nBabak", "> [tfbug.zip](https://github.com/tensorflow/tensorflow/files/5068991/tfbug.zip)\r\n\r\n@bsaravi,\r\nOn running the `bugTrain.py` from the zip file, I am facing an error stating `FileNotFoundError: [Errno 2] No such file or directory: './configs/pointpillars/car/xyres_16.proto'`. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/3aef973b381de4aee79055579585f319/42142.ipynb).\r\n\r\nPlease provide all the dependencies to run the code. Alternatively, you can run your code on [Google Colab](https://colab.research.google.com/notebook#create=true&language=python3) and share the notebook with us. Thanks!", "I guess you are running outside the code folder. Paths are relative to the\r\nroot of the code. you need to cd to the code root.\r\nif you unzip in tfbug do a %cd tfbug\r\nthanks,\r\nBabak\r\n\r\nOn Tue, Aug 18, 2020 at 6:42 AM Abhilash Mahendrakar <\r\nnotifications@github.com> wrote:\r\n\r\n> tfbug.zip\r\n> <https://github.com/tensorflow/tensorflow/files/5068991/tfbug.zip>\r\n>\r\n> @bsaravi <https://github.com/bsaravi>,\r\n> On running the bugTrain.py from the zip file, I am facing an error\r\n> stating FileNotFoundError: [Errno 2] No such file or directory:\r\n> './configs/pointpillars/car/xyres_16.proto'.\r\n>\r\n> Please provide all the dependencies to run the code. Alternatively, you\r\n> can run your code on Google Colab\r\n> <https://colab.research.google.com/notebook#create=true&language=python3>\r\n> and share the notebook with us. Thanks!\r\n>\r\n> \u2014\r\n> You are receiving this because you were mentioned.\r\n> Reply to this email directly, view it on GitHub\r\n> <https://github.com/tensorflow/tensorflow/issues/42142#issuecomment-675404271>,\r\n> or unsubscribe\r\n> <https://github.com/notifications/unsubscribe-auth/AKGK3L3AFRXV3JPIO6AMITLSBJLJLANCNFSM4PYHEKEA>\r\n> .\r\n>\r\n", "just add a %cd tfbug\\ (not a !cd) before runing.\r\nThanks,\r\nBabak", "Is there any update on this?", "Was able to reproduce the issue with TF v2.3 and TF-nightly. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/82767507c9006717de2409b73ae8db67/42142.ipynb). Thanks!", "Is there any update on this? \r\nThis bug shows up even in very small network like the following code with or without subclass the keras layers:\r\n\r\nimport tensorflow.compat.v1 as tf\r\nfrom tensorflow.compat.v1.keras import layers,Model\r\nfrom tensorflow.compat.v1.keras.models import Sequential\r\nfrom tensorflow.compat.v1.keras.backend import set_session\r\n\"\"\"\r\nclass TModel(Model):\r\n   def __init__(self):\r\n      super(TModel, self).__init__()\r\n      self.layer = Sequential(\r\n          [\r\n              layers.Dense(2, activation=\"relu\", name=\"layer1\"),\r\n              layers.Dense(3, activation=\"relu\", name=\"layer2\"),\r\n              layers.Dense(4, name=\"layer3\"),\r\n          ]\r\n      )\r\n   def call(self,inp):\r\n      return self.layer(inp)\r\n  \r\n\"\"\"\r\nmodel = Sequential(\r\n    [\r\n        layers.Dense(2, activation=\"relu\", name=\"layer1\"),\r\n        layers.Dense(3, activation=\"relu\", name=\"layer2\"),\r\n        layers.Dense(4, name=\"layer3\"),\r\n    ]\r\n)\r\n\r\nsess = tf.Session()#config=tf_config)\r\ngraph = tf.get_default_graph()\r\n\r\nset_session(sess)\r\nwith sess.as_default():\r\n   with graph.as_default():\r\n      #model = TModel()\r\n      x = tf.ones((3, 3))\r\n      y = model(x)\r\n      model.save(\"./m1\")\r\n", "Hi @bsaravi, in TF2 the preferred way to use graph mode is with `tf.function` and not `tf.Session`. The recommendation in this case would be to migrate to TF2 syntax instead of using `tf.Session`. Is there a specific reason you need to still use TF1 syntax?", "Thanks Nikita for your reply.\n   When I submitted the bug 6 month ago. I was using openvino 2020.4 which\ndoes not support TF2 and I found a work around for this issue. but openvino\n2021 is supporting TF2.\nBest,\nBabak\n\nOn Tue, Feb 2, 2021 at 7:32 PM Nikita Namjoshi <notifications@github.com>\nwrote:\n\n> Hi @bsaravi <https://github.com/bsaravi>, in TF2 the preferred way to use\n> graph mode is with tf.function and not tf.Session. The recommendation in\n> this case would be to migrate to TF2 syntax instead of using tf.Session.\n> Is there a specific reason you need to still use TF1 syntax?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/42142#issuecomment-772113354>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AKGK3L4QWMQNMVN7WCQAU4LS5CKTDANCNFSM4PYHEKEA>\n> .\n>\n", "Ah makes sense, sorry for the late response here! Closing this issue now since you found a work around and V2 syntax is preferred. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42142\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42142\">No</a>\n"]}]