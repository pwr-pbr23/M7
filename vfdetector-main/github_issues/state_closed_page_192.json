[{"number": 48973, "title": "save and load specific keras/tensorflow layers", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 2.4.1\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nextract layer of one model with weights and use in another model. For example, using an embedding layer weights of one transformer model in another transformer model. Compared to glove embeddings and word2vec embeddings, it's difficult to map the embedding weights of a transformer.\r\n\r\n**Will this change the current api? How?**\r\nMost probably no.\r\n\r\n**Who will benefit with this feature?**\r\nthose who need to export only embeddings layer (or any other layer) and use in another model.\r\n\r\n**Any Other info.**\r\n", "comments": ["Do you meant something like https://keras.io/examples/nlp/pretrained_word_embeddings/ ?", "Closing this. exported the weights in pickle file. Thanks @bhack "]}, {"number": 48972, "title": "[CherryPick 2.5]Validate `MatrixDiagV{2,3}` arguments to prevent breakage.", "body": "PiperOrigin-RevId: 369056033\nChange-Id: Ic2018c297d3dd6f252dc1dd3667f1ed5cb1eaa42", "comments": []}, {"number": 48971, "title": "Update legalizations for TOSA v0.22 Part 2", "body": "Update Concat Legalization to support variadic\r\nFix negative axis issue for concatenate legalization\r\n- add rank(input) if axis is negative\r\n- cleanup on axis check\r\n- run clang-format\r\nFix numerical issue for 8-bit sigmoid/tanh\r\n- softmax numerical behavior is improved but still not bit exact yet since we don't know what TFLite reference we should match against\r\nSupport 16-bit TOSA legalization for Add and Conv2D\r\nSigned-off-by: Kevin Cheng <kevin.cheng@arm.com>\r\nSupport more 16 bits legalization\r\nSigned-off-by: Kevin Cheng <kevin.cheng@arm.com>\r\nFix quantized resize_bilinear legalization\r\n- tosa.resize doesn't need input zp shifted, so shouldn't shift output zp as well\r\nImplement bit exact 8-bit tfl.softmax lowering\r\nUpdated TF and TFL legalization tests\r\nRewrite PackOp to use variadic Concat\r\n\r\nChange-Id: Ia3827d3f6d6d43fe2b8d6f2c5e9da7b5d3d3edc8\r\nSigned-off-by: Suraj Sudhir <suraj.sudhir@arm.com>", "comments": ["@stellaraccident and @rsuderman , this updates legalizations to the latest versions aligned to a near complete v0.22 TOSA spec. \r\n\r\n1. Adds variadic concat legalization\r\n2. Quantized activation function modeling precision\r\n3. Fixes quantized resize_bilinear \r\n4. Additional 16-bit legalizations ", "Just to add a few to make things clear. The commit message above was a bit out of date.\r\n> softmax numerical behavior is improved but still not bit exact yet since we don't know what TFLite reference we should match against\r\n\r\nThis should be already resolved by @Tessil PR here: https://github.com/tensorflow/tensorflow/pull/48506\r\nAnd 8-bit softmax legalization here in this PR has the clear reference target, and is bit exact matching that now.\r\n\r\nAlso 16-bit softmax legalization is introduced in this PR as well."]}, {"number": 48970, "title": "[Cherrypick:2.5]Fix `tf.raw_ops.ResourceCountUpTo` null pointer dereference.", "body": "PiperOrigin-RevId: 368294347\nChange-Id: I2c16fbfc9b4966c402c3d8e311f0d665a9c852d8", "comments": []}, {"number": 48969, "title": "[CherryPick:2.5]Fix an invalid address vulnerability in `tf.raw_ops.RaggedBincount`.", "body": "PiperOrigin-RevId: 368293153\nChange-Id: I4b4e493d3fd05e7dc55a55de3a041a80a4f275c3", "comments": []}, {"number": 48968, "title": "Update legalizations for TOSA v0.22 Part 2", "body": "Update Concat Legalization to support variadic\r\nFix negative axis issue for concatenate legalization\r\n- add rank(input) if axis is negative\r\n- cleanup on axis check\r\n- run clang-format\r\nFix numerical issue for 8-bit sigmoid/tanh\r\n- softmax numerical behavior is improved but still not bit exact yet since we don't know what TFLite reference we should match against\r\nSupport 16-bit TOSA legalization for Add and Conv2D\r\nSigned-off-by: Kevin Cheng <kevin.cheng@arm.com>\r\nSupport more 16 bits legalization\r\nSigned-off-by: Kevin Cheng <kevin.cheng@arm.com>\r\nFix quantized resize_bilinear legalization\r\n- tosa.resize doesn't need input zp shifted, so shouldn't shift output zp as well\r\nImplement bit exact 8-bit tfl.softmax lowering\r\nUpdated TF and TFL legalization tests\r\nRewrite PackOp to use variadic Concat\r\n\r\nChange-Id: Ia3827d3f6d6d43fe2b8d6f2c5e9da7b5d3d3edc8\r\nSigned-off-by: Suraj Sudhir <suraj.sudhir@arm.com>", "comments": ["Closing temporarily until failing MLIR tests resolved. "]}, {"number": 48966, "title": "Compilation time regression: 4 straglers", "body": "With TF container: tensorflow/tensorflow:devel-gpu  and this commit:\r\n\r\ncommit 38dc3cc0278a0e91247c872799e2c49bce831bb2 (HEAD -> master, origin/master, origin/HEAD)\r\nAuthor: Adrian Kuegel <akuegel@google.com>\r\nDate:   Tue May 4 03:35:01 2021 -0700\r\n\r\n    Add MLIR generated Relu kernel.\r\n\r\n    It is still disabled by default.\r\n\r\n    PiperOrigin-RevId: 371881143\r\n    Change-Id: I1216d77978cf6d1b9e128ef63bc0d52b5c55a3e2\r\n\r\nWe have 4 new compilation stragler. I still haven't finished compiling, but 4 rules are taking over 1h to compile...\r\n\r\n```\r\n[41,044 / 41,048] 4 actions running\r\n    Executing genrule //tensorflow/lite/python/testdata:permute_float; 3615s local\r\n    Executing genrule //tensorflow/lite/python/testdata:gather_string; 3615s local\r\n    Executing genrule //tensorflow/lite/python/testdata:permute_uint8; 3615s local\r\n    Executing genrule //tensorflow/lite/python/testdata:gather_string_0d; 3615s local\r\n```\r\n\r\nFull repro steps:\r\nThe command used to compile:\r\n```\r\ndocker run --gpus=all -it tensorflow/tensorflow:devel-gpu /bin/bash\r\ncd /tensorflow_src\r\nbazel build -c opt --config cuda //tensorflow/tools/pip_package:build_pip_package\r\n```", "comments": ["Note, I think commit 4656afe7a57deacdc706c0d26f60a366b5e620a6 doesn't have that problem.\r\n\r\nI was also able to grab this output before it finish to compile:\r\n\r\n```\r\n[41,046 / 41,048] 2 actions running\r\n    Executing genrule //tensorflow/lite/python/testdata:permute_float; 4127s local\r\n    Executing genrule //tensorflow/lite/python/testdata:permute_uint8; 4127s local\r\n```", "Can you please try whether you can reproduce the problem also with ce227000bdf0dd4b6c1a9dd456a60f4627c54cbc\r\n?\r\nFrom the range of commits, this looks to me the most suspicious, because it changes the pip build (if I understand it correctly). And if it can be reproduced, does it work with eaa0c588cf44e0c436560738ec361cbc4861cb2d (the commit one before)? If yes, we would have verified the culprit.", "```\r\ndocker run --gpus=all -it tensorflow/tensorflow:devel-gpu /bin/bash\r\ncd /tensorflow_src\r\ngit checkout ce22700\r\nbazel build -c opt --config cuda //tensorflow/tools/pip_package:build_pip_package\r\n[41,044 / 41,048] 4 actions running\r\n    Executing genrule //tensorflow/lite/python/testdata:permute_float; 289s local\r\n    Executing genrule //tensorflow/lite/python/testdata:gather_string_0d; 289s local\r\n    Executing genrule //tensorflow/lite/python/testdata:gather_string; 289s local\r\n    Executing genrule //tensorflow/lite/python/testdata:permute_uint8; 289s local\r\n\r\n[killed]\r\ngit checkout eaa0c58\r\nbazel build -c opt --config cuda //tensorflow/tools/pip_package:build_pip_package\r\n[There is tons of recompilation like:\r\n...\r\n    Compiling tensorflow/core/kernels/conv_2d_gpu_int_spatial_convolution.cu.cc [for host]; 146s local\r\n    Compiling tensorflow/core/kernels/conv_2d_gpu_int_spatial_convolution_backward.cu.cc [for host]; 146s local\r\n    Compiling tensorflow/core/kernels/unique_op_gpu_2.cu.cc [for host]; 136s local\r\n    Compiling tensorflow/core/kernels/argmax_op.cc [for host]; 135s local\r\n    Compiling tensorflow/core/kernels/matmul_op_real.cc [for host]; 124s local\r\n    Compiling tensorflow/compiler/mlir/xla/transforms/legalize_tf.cc [for host]; 99s\r\n...\r\n    Compiling tensorflow/core/kernels/matmul_op_real.cc [for host]; 289s local\r\n    Compiling tensorflow/core/kernels/cwise_op_gpu_div.cu.cc [for host]; 100s local\r\n    Compiling tensorflow/core/kernels/reduction_ops_gpu_float.cu.cc [for host]; 99s local\r\n    Compiling tensorflow/core/kernels/reduction_ops_gpu_double.cu.cc [for host]; 99s local\r\n    Compiling tensorflow/core/kernels/reduction_ops_gpu_int.cu.cc [for host]; 99s local\r\n    Compiling tensorflow/core/kernels/reduction_ops_half_prod_max_min.cu.cc [for host]; 98s local\r\n    Compiling tensorflow/core/kernels/sparse_xent_op_gpu.cu.cc [for host]; 92s local\r\n    Compiling tensorflow/core/kernels/bias_op.cc [for host]; 91s local ...\r\n\r\n[And some stuff outside the kernels directory. I'm not sure if this is expected]\r\n\r\n[42,467 / 42,471] 4 actions running\r\n    Executing genrule //tensorflow/lite/python/testdata:gather_string; 550s local\r\n    Executing genrule //tensorflow/lite/python/testdata:permute_uint8; 550s local\r\n    Executing genrule //tensorflow/lite/python/testdata:gather_string_0d; 550s local\r\n    Executing genrule //tensorflow/lite/python/testdata:permute_float; 550s local\r\n```\r\n\r\nSo the problem was introduced before ce22700.\r\nIs it normal that tf-lite is compiled by default?", "This is the first bad commit that mostly double the compilation time.\r\n```\r\nroot@a0db5d6a1fff:/tensorflow_src# git bisect good\r\n154a8891cea1dc97881725b74304be237b04e5ba is the first bad commit\r\ncommit 154a8891cea1dc97881725b74304be237b04e5ba\r\nAuthor: Karim Nosir karimnosseir@google.com\r\nDate:   Tue Nov 17 00:41:36 2020 -0800\r\n\r\n    Update DEPRECATED_tf_to_tflite to tf_to_tflite for lite testdata.\r\n    TOCO is deprecated and this migrates to use tflite converter.\r\n\r\n    PiperOrigin-RevId: 342809252\r\n    Change-Id: Ided3a52c75a4fbf564deb9183cab214d41acd0ce\r\n\r\n```", "https://github.com/tensorflow/tensorflow/commit/ea5f098c242c28ae58417a26c3c39efc0204a832\r\nFixed the problem. So closing. Thanks for the quick fix.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48966\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48966\">No</a>\n"]}, {"number": 48963, "title": "recipe for target 'CMakeFiles/tensorflow-lite.dir/all' failed     issue while cross-compile tflite.", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution : Linux Ubuntu 16:\r\n\r\n\r\n- TensorFlow  Lite version--Latest:\r\n- Python version:3.7\r\n\r\n\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nHi I am new to tensorflow. I try to cross-compile and generate the python wheel for  the tensorflow-lite for aarch64. i followed the steps which given in the official tensorflow-lite website. https://www.tensorflow.org/lite/guide/build_cmake_pip. But I cannot able to cross compile it. \r\n\r\nThe steps which I follow:\r\n1. Git clone the tensorflow source code.\r\n2. Execute the below command from the tensorflow src folder.\r\n\r\n**tensorflow/tools/ci_build/ci_build.sh PI-PYTHON37 \\\r\n  tensorflow/lite/tools/pip_package/build_pip_package_with_cmake.sh aarch64**\r\n \r\nThen the program execute with some following error.\r\n\r\n**Any other info / logs**\r\n\r\nCMakeFiles/Makefile2:1139: recipe for target 'CMakeFiles/tensorflow-lite.dir/all' failed\r\nmake[2]: *** [CMakeFiles/tensorflow-lite.dir/all] Error 2\r\nmake[2]: Leaving directory '/workspace/tensorflow/lite/tools/pip_package/gen/tflite_pip/python3.7/cmake_build'\r\nCMakeFiles/Makefile2:1247: recipe for target 'CMakeFiles/_pywrap_tensorflow_interpreter_wrapper.dir/rule' failed\r\nmake[1]: *** [CMakeFiles/_pywrap_tensorflow_interpreter_wrapper.dir/rule] Error 2\r\nmake[1]: Leaving directory '/workspace/tensorflow/lite/tools/pip_package/gen/tflite_pip/python3.7/cmake_build'\r\nMakefile:215: recipe for target '_pywrap_tensorflow_interpreter_wrapper' failed\r\nmake: *** [_pywrap_tensorflow_interpreter_wrapper] Error 2\r\n\r\n \r\n", "comments": ["@terryheo Could you take a look?", "Did you run the command in one line?\r\n```\r\ntensorflow/tools/ci_build/ci_build.sh PI-PYTHON37 tensorflow/lite/tools/pip_package/build_pip_package_with_cmake.sh aarch64\r\n```\r\n\r\nIf you did, could you share more error message? (like 50 lines)", "Hi @terryheo Thankyou for your reply! \r\n[error_log.txt](https://github.com/tensorflow/tensorflow/files/6456372/error_log.txt)\r\n\r\nYes, I tried with the above command in one line, but again the same error raises. Here I attached the detailed error log. Please find it.", "```\r\nCMakeFiles/tensorflow-lite.dir/build.make:1157: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/lstm_eval.cc.o' failed\r\naarch64-linux-gnu-g++: fatal error: Killed signal terminated program cc1plus\r\ncompilation terminated.\r\n```\r\nThanks for the information. It seems that your Docker has OOM issue.\r\nWhat's the host OS? You'd better assign more memory to your Docker.\r\n", "@terryheo Thank you for your guidence! My host OS  is Ubuntu 18, And also Please guide me to increase the memory of the Docker while cross-compiling.", "@terryheo Also I remember one thing  I was able to cross-compile the tflite without any error at the one week before. ", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48963\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48963\">No</a>\n", "@migod35 How did you solve the problem?"]}, {"number": 48962, "title": "Mixed precision Mask in GlobalAveragePooling1D", "body": "fix https://github.com/tensorflow/tensorflow/issues/48961", "comments": []}, {"number": 48961, "title": "GlobalAveragePooling1D does not work with a mask when mixed precision policy is set.", "body": "**System information**\r\n- OS: colab (Ubuntu 18.04.5)\r\n- TensorFlow installed from : pre-installed in colab\r\n- TensorFlow version: 2.4.1\r\n- Python version: 3.7.10\r\n- GPU model and memory: Tesla K80, 12GB\r\n\r\n**Describe the current behavior**\r\nWhen setting the mixed precision policy and using a `GlobalAveragePooling1D` layer with a mask, the mask is wrongly cast with `backend.floatx()` (=`float32` even with mixed precision) and this raises an issue of un-matching types for the forward pass.\r\n\r\n**Describe the expected behavior**\r\nWe can use `GlobalAveragePooling1D` with a mask and mixed precision set.\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)** \r\n- Do you want to contribute a PR? Yes\r\n- Briefly describe your candidate solution:\r\nin `GlobalAveragePooling1D::call()` (/tensorflow/python/keras/layers/pooling.py::L795): `mask = math_ops.cast(mask, inputs.dtype)`\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nfrom tensorflow.keras import mixed_precision\r\nmixed_precision.set_global_policy('mixed_float16')\r\n\r\ninputs1 = keras.Input(shape=(36, 512), name='digits', dtype=\"float16\")\r\ninputs2 = keras.Input(shape=(36,), name='digits', dtype=\"bool\")\r\naverage_layer = layers.GlobalAveragePooling1D()\r\nx = average_layer(inputs1, inputs2)\r\n```\r\n\r\nThis yields the issue. Setting `tf.keras.backend.set_floatx('float16')` solves the issue, but this might be better to directly cast the `mask` to `inputs.dtype` in `GlobalAveragePooling1D::call()`\r\n```\r\ndef call(self, inputs, mask=None):\r\n    steps_axis = 1 if self.data_format == 'channels_last' else 2\r\n    if mask is not None:\r\n      mask = math_ops.cast(mask, backend.floatx())\r\n      mask = array_ops.expand_dims(\r\n          mask, 2 if self.data_format == 'channels_last' else 1)\r\n      inputs *= mask\r\n      return backend.sum(inputs, axis=steps_axis) / math_ops.reduce_sum(\r\n          mask, axis=steps_axis)\r\n    else:\r\n      return backend.mean(inputs, axis=steps_axis)\r\n```\r\n\r\n\r\n\r\n**Other info / logs** \r\nError trace:\r\n```\r\n/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/pooling.py in call(self, inputs, mask)\r\n    796       mask = array_ops.expand_dims(\r\n    797           mask, 2 if self.data_format == 'channels_last' else 1)\r\n--> 798       inputs *= mask\r\n    799       return backend.sum(inputs, axis=steps_axis) / math_ops.reduce_sum(\r\n    800           mask, axis=steps_axis)\r\n...\r\nTypeError: Input 'y' of 'Mul' Op has type float32 that does not match type float16 of argument 'x'.\r\n```\r\n", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48961\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48961\">No</a>\n"]}, {"number": 48960, "title": "Both pip and conda versions of numpy and six required to load tensorflow 2.4.1?", "body": "I am running tensorflow 2.4.1 in a conda environment using Python 3.8.8 on a Windows 10 x64 system.  GPU support is working.  My conda channel setup is:\r\n\r\n```\r\n> conda config --env --show channels\r\nchannels:\r\n      - conda-forge\r\n      - defaults\r\n> conda config --env --show channel_priority\r\nchannel_priority: flexible\r\n```\r\n\r\nI installed tensorflow and related packages using pip:\r\n\r\n> pip install tensorflow tensorflow_io python-dotenv\r\n\r\nI don't really know if python-dotenv is needed here, but I heard that it was.  (?????)\r\n\r\nI also have several conda-forge packages installed, such as pandas, scikit-learn, matplotlib, ipympl, seaborn, jupyterlab, notebook, nodejs, and scipy.\r\n\r\nHere is a list of packages in the env:\r\n\r\n```\r\n> conda list\r\n# packages in environment at C:\\Users\\me\\Miniconda3\\envs\\tf38:\r\n#\r\n# Name                    Version                   Build  Channel\r\nabsl-py                   0.12.0                   pypi_0    pypi\r\nanyio                     2.2.0            py38haa244fe_0    conda-forge\r\nargon2-cffi               20.1.0           py38h294d835_2    conda-forge\r\nastunparse                1.6.3                    pypi_0    pypi\r\nasync_generator           1.10                       py_0    conda-forge\r\nattrs                     21.2.0             pyhd8ed1ab_0    conda-forge\r\nbabel                     2.9.1              pyh44b312d_0    conda-forge\r\nbackcall                  0.2.0              pyh9f0ad1d_0    conda-forge\r\nbackports                 1.0                        py_2    conda-forge\r\nbackports.functools_lru_cache 1.6.4              pyhd8ed1ab_0    conda-forge\r\nbleach                    3.3.0              pyh44b312d_0    conda-forge\r\nbrotlipy                  0.7.0           py38h294d835_1001    conda-forge\r\nca-certificates           2020.12.5            h5b45459_0    conda-forge\r\ncachetools                4.2.2                    pypi_0    pypi\r\ncertifi                   2020.12.5        py38haa244fe_1    conda-forge\r\ncffi                      1.14.5           py38hd8c33c5_0    conda-forge\r\nchardet                   4.0.0            py38haa244fe_1    conda-forge\r\ncolorama                  0.4.4              pyh9f0ad1d_0    conda-forge\r\ncryptography              3.4.7            py38hd7da0ea_0    conda-forge\r\ncycler                    0.10.0                     py_2    conda-forge\r\ndecorator                 5.0.7              pyhd8ed1ab_0    conda-forge\r\ndefusedxml                0.7.1              pyhd8ed1ab_0    conda-forge\r\ndeprecation               2.1.0              pyh9f0ad1d_0    conda-forge\r\nentrypoints               0.3             pyhd8ed1ab_1003    conda-forge\r\nflatbuffers               1.12                     pypi_0    pypi\r\nfreetype                  2.10.4               h546665d_1    conda-forge\r\ngast                      0.3.3                    pypi_0    pypi\r\ngoogle-auth               1.30.0                   pypi_0    pypi\r\ngoogle-auth-oauthlib      0.4.4                    pypi_0    pypi\r\ngoogle-pasta              0.2.0                    pypi_0    pypi\r\ngrpcio                    1.32.0                   pypi_0    pypi\r\nh5py                      2.10.0                   pypi_0    pypi\r\nicu                       68.1                 h0e60522_0    conda-forge\r\nidna                      2.10               pyh9f0ad1d_0    conda-forge\r\nimportlib-metadata        4.0.1            py38haa244fe_0    conda-forge\r\nintel-openmp              2021.2.0           h57928b3_616    conda-forge\r\nipykernel                 5.5.4            py38h43734a8_0    conda-forge\r\nipympl                    0.7.0              pyhd8ed1ab_0    conda-forge\r\nipython                   7.23.1           py38h43734a8_0    conda-forge\r\nipython_genutils          0.2.0                      py_1    conda-forge\r\nipywidgets                7.6.3              pyhd3deb0d_0    conda-forge\r\njedi                      0.18.0           py38haa244fe_2    conda-forge\r\njinja2                    2.11.3             pyh44b312d_0    conda-forge\r\njoblib                    1.0.1              pyhd8ed1ab_0    conda-forge\r\njpeg                      9d                   h8ffe710_0    conda-forge\r\njson5                     0.9.5              pyh9f0ad1d_0    conda-forge\r\njsonschema                3.2.0              pyhd8ed1ab_3    conda-forge\r\njupyter-packaging         0.10.1             pyhd8ed1ab_0    conda-forge\r\njupyter_client            6.1.12             pyhd8ed1ab_0    conda-forge\r\njupyter_core              4.7.1            py38haa244fe_0    conda-forge\r\njupyter_server            1.6.4            py38haa244fe_0    conda-forge\r\njupyterlab                3.0.14             pyhd8ed1ab_0    conda-forge\r\njupyterlab_pygments       0.1.2              pyh9f0ad1d_0    conda-forge\r\njupyterlab_server         2.5.0              pyhd8ed1ab_0    conda-forge\r\njupyterlab_widgets        1.0.0              pyhd8ed1ab_1    conda-forge\r\nkeras-preprocessing       1.1.2                    pypi_0    pypi\r\nkiwisolver                1.3.1            py38hbd9d945_1    conda-forge\r\nlcms2                     2.12                 h2a16943_0    conda-forge\r\nlibblas                   3.9.0                     9_mkl    conda-forge\r\nlibcblas                  3.9.0                     9_mkl    conda-forge\r\nlibclang                  11.1.0          default_h5c34c98_0    conda-forge\r\nliblapack                 3.9.0                     9_mkl    conda-forge\r\nlibpng                    1.6.37               h1d00b33_2    conda-forge\r\nlibsodium                 1.0.18               h8d14728_1    conda-forge\r\nlibtiff                   4.2.0                hc10be44_1    conda-forge\r\nlz4-c                     1.9.3                h8ffe710_0    conda-forge\r\nm2w64-gcc-libgfortran     5.3.0                         6    conda-forge\r\nm2w64-gcc-libs            5.3.0                         7    conda-forge\r\nm2w64-gcc-libs-core       5.3.0                         7    conda-forge\r\nm2w64-gmp                 6.1.0                         2    conda-forge\r\nm2w64-libwinpthread-git   5.0.0.4634.697f757               2    conda-forge\r\nmarkdown                  3.3.4                    pypi_0    pypi\r\nmarkupsafe                1.1.1            py38h294d835_3    conda-forge\r\nmatplotlib                3.4.1            py38haa244fe_0    conda-forge\r\nmatplotlib-base           3.4.1            py38heae8d8c_0    conda-forge\r\nmatplotlib-inline         0.1.2              pyhd8ed1ab_2    conda-forge\r\nmistune                   0.8.4           py38h294d835_1003    conda-forge\r\nmkl                       2021.2.0           hb70f87d_389    conda-forge\r\nmsys2-conda-epoch         20160418                      1    conda-forge\r\nnbclassic                 0.2.7              pyhd8ed1ab_0    conda-forge\r\nnbclient                  0.5.3              pyhd8ed1ab_0    conda-forge\r\nnbconvert                 6.0.7            py38haa244fe_3    conda-forge\r\nnbformat                  5.1.3              pyhd8ed1ab_0    conda-forge\r\nnest-asyncio              1.5.1              pyhd8ed1ab_0    conda-forge\r\nnodejs                    15.14.0              h57928b3_0    conda-forge\r\nnotebook                  6.3.0              pyha770c72_1    conda-forge\r\nnumpy                     1.19.5                   pypi_0    pypi\r\noauthlib                  3.1.0                    pypi_0    pypi\r\nolefile                   0.46               pyh9f0ad1d_1    conda-forge\r\nopenjpeg                  2.4.0                h48faf41_0    conda-forge\r\nopenssl                   1.1.1k               h8ffe710_0    conda-forge\r\nopt-einsum                3.3.0                    pypi_0    pypi\r\npackaging                 20.9               pyh44b312d_0    conda-forge\r\npandas                    1.2.4            py38h60cbd38_0    conda-forge\r\npandoc                    2.13                 h8ffe710_0    conda-forge\r\npandocfilters             1.4.2                      py_1    conda-forge\r\nparso                     0.8.2              pyhd8ed1ab_0    conda-forge\r\npatsy                     0.5.1                      py_0    conda-forge\r\npickleshare               0.7.5                   py_1003    conda-forge\r\npillow                    8.2.0                    pypi_0    pypi\r\npip                       21.1.1             pyhd8ed1ab_0    conda-forge\r\nprometheus_client         0.10.1             pyhd8ed1ab_0    conda-forge\r\nprompt-toolkit            3.0.18             pyha770c72_0    conda-forge\r\nprotobuf                  3.15.8                   pypi_0    pypi\r\npyasn1                    0.4.8                    pypi_0    pypi\r\npyasn1-modules            0.2.8                    pypi_0    pypi\r\npycparser                 2.20               pyh9f0ad1d_2    conda-forge\r\npygments                  2.9.0              pyhd8ed1ab_0    conda-forge\r\npyopenssl                 20.0.1             pyhd8ed1ab_0    conda-forge\r\npyparsing                 2.4.7              pyh9f0ad1d_0    conda-forge\r\npyqt                      5.12.3           py38haa244fe_7    conda-forge\r\npyqt-impl                 5.12.3           py38h885f38d_7    conda-forge\r\npyqt5-sip                 4.19.18          py38h885f38d_7    conda-forge\r\npyqtchart                 5.12             py38h885f38d_7    conda-forge\r\npyqtwebengine             5.12.1           py38h885f38d_7    conda-forge\r\npyrsistent                0.17.3           py38h294d835_2    conda-forge\r\npysocks                   1.7.1            py38haa244fe_3    conda-forge\r\npython                    3.8.8           h7840368_0_cpython    conda-forge\r\npython-dateutil           2.8.1                      py_0    conda-forge\r\npython-dotenv             0.17.1                   pypi_0    pypi\r\npython_abi                3.8                      1_cp38    conda-forge\r\npytz                      2021.1             pyhd8ed1ab_0    conda-forge\r\npywin32                   300              py38h294d835_0    conda-forge\r\npywinpty                  1.0.1            py38hd3f51b4_0    conda-forge\r\npyzmq                     22.0.3           py38h09162b1_1    conda-forge\r\nqt                        5.12.9               h5909a2a_4    conda-forge\r\nrequests                  2.25.1             pyhd3deb0d_0    conda-forge\r\nrequests-oauthlib         1.3.0                    pypi_0    pypi\r\nrsa                       4.7.2                    pypi_0    pypi\r\nscikit-learn              0.24.2           py38h5d5d464_0    conda-forge\r\nscipy                     1.6.3            py38he847743_0    conda-forge\r\nseaborn                   0.11.1               hd8ed1ab_1    conda-forge\r\nseaborn-base              0.11.1             pyhd8ed1ab_1    conda-forge\r\nsend2trash                1.5.0                      py_0    conda-forge\r\nsetuptools                49.6.0           py38haa244fe_3    conda-forge\r\nsix                       1.15.0                   pypi_0    pypi\r\nsniffio                   1.2.0            py38haa244fe_1    conda-forge\r\nsqlite                    3.35.5               h8ffe710_0    conda-forge\r\nstatsmodels               0.12.2           py38h347fdf6_0    conda-forge\r\ntbb                       2021.2.0             h2d74725_0    conda-forge\r\ntensorboard               2.5.0                    pypi_0    pypi\r\ntensorboard-data-server   0.6.0                    pypi_0    pypi\r\ntensorboard-plugin-wit    1.8.0                    pypi_0    pypi\r\ntensorflow                2.4.1                    pypi_0    pypi\r\ntensorflow-estimator      2.4.0                    pypi_0    pypi\r\ntensorflow-io             0.17.1                   pypi_0    pypi\r\ntermcolor                 1.1.0                    pypi_0    pypi\r\nterminado                 0.9.4            py38haa244fe_0    conda-forge\r\ntestpath                  0.4.4                      py_0    conda-forge\r\nthreadpoolctl             2.1.0              pyh5ca1d4c_0    conda-forge\r\ntk                        8.6.10               h8ffe710_1    conda-forge\r\ntomlkit                   0.7.0            py38haa244fe_3    conda-forge\r\ntornado                   6.1              py38h294d835_1    conda-forge\r\ntraitlets                 5.0.5                      py_0    conda-forge\r\ntyping-extensions         3.7.4.3                  pypi_0    pypi\r\nurllib3                   1.26.4             pyhd8ed1ab_0    conda-forge\r\nvc                        14.2                 hb210afc_4    conda-forge\r\nvs2015_runtime            14.28.29325          h5e1d092_4    conda-forge\r\nwcwidth                   0.2.5              pyh9f0ad1d_2    conda-forge\r\nwebencodings              0.5.1                      py_1    conda-forge\r\nwerkzeug                  1.0.1                    pypi_0    pypi\r\nwheel                     0.36.2             pyhd3deb0d_0    conda-forge\r\nwidgetsnbextension        3.5.1            py38haa244fe_4    conda-forge\r\nwin_inet_pton             1.1.0            py38haa244fe_2    conda-forge\r\nwincertstore              0.2             py38haa244fe_1006    conda-forge\r\nwinpty                    0.4.3                         4    conda-forge\r\nwrapt                     1.12.1                   pypi_0    pypi\r\nxlrd                      2.0.1              pyhd8ed1ab_3    conda-forge\r\nxz                        5.2.5                h62dcd97_1    conda-forge\r\nzeromq                    4.3.4                h0e60522_0    conda-forge\r\nzipp                      3.4.1              pyhd8ed1ab_0    conda-forge\r\nzlib                      1.2.11            h62dcd97_1010    conda-forge\r\nzstd                      1.4.9                h6255e5f_0    conda-forge\r\n```\r\n\r\n**Problem:**\r\n\r\nWhen I update tensorflow using this command:\r\n\r\n`pip install --upgrade tensorflow tensorflow_io python-dotenv`\r\n\r\nthe upgrade works, but pip removes conda numpy and six and replaces them with PyPi (pip) versions.  After that, tensorflow will not load in a Jupyter notebook, throwing this error:\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nFileNotFoundError                         Traceback (most recent call last)\r\n<ipython-input-2-ac1231bd92eb> in <module>\r\n----> 1 import tensorflow as tf\r\n      2 print(tf.__version__)\r\n      3 # tf 2.4.1 used in course\r\n\r\n~\\Miniconda3\\envs\\tf38\\lib\\site-packages\\tensorflow\\__init__.py in <module>\r\n     39 import sys as _sys\r\n     40 \r\n---> 41 from tensorflow.python.tools import module_util as _module_util\r\n     42 from tensorflow.python.util.lazy_loader import LazyLoader as _LazyLoader\r\n     43 \r\n\r\n~\\Miniconda3\\envs\\tf38\\lib\\site-packages\\tensorflow\\python\\__init__.py in <module>\r\n     46 from tensorflow.python import data\r\n     47 from tensorflow.python import distribute\r\n---> 48 from tensorflow.python import keras\r\n     49 from tensorflow.python.feature_column import feature_column_lib as feature_column\r\n     50 from tensorflow.python.layers import layers\r\n\r\n~\\Miniconda3\\envs\\tf38\\lib\\site-packages\\tensorflow\\python\\keras\\__init__.py in <module>\r\n     25 \r\n     26 # See b/110718070#comment18 for more details about this import.\r\n---> 27 from tensorflow.python.keras import models\r\n     28 \r\n     29 from tensorflow.python.keras.engine.input_layer import Input\r\n\r\n~\\Miniconda3\\envs\\tf38\\lib\\site-packages\\tensorflow\\python\\keras\\models.py in <module>\r\n     24 from tensorflow.python.keras import metrics as metrics_module\r\n     25 from tensorflow.python.keras import optimizer_v1\r\n---> 26 from tensorflow.python.keras.engine import functional\r\n     27 from tensorflow.python.keras.engine import sequential\r\n     28 from tensorflow.python.keras.engine import training\r\n\r\n~\\Miniconda3\\envs\\tf38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py in <module>\r\n     36 from tensorflow.python.keras.engine import keras_tensor\r\n     37 from tensorflow.python.keras.engine import node as node_module\r\n---> 38 from tensorflow.python.keras.engine import training as training_lib\r\n     39 from tensorflow.python.keras.engine import training_utils\r\n     40 from tensorflow.python.keras.saving.saved_model import network_serialization\r\n\r\n~\\Miniconda3\\envs\\tf38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py in <module>\r\n     50 from tensorflow.python.keras.engine import base_layer_utils\r\n     51 from tensorflow.python.keras.engine import compile_utils\r\n---> 52 from tensorflow.python.keras.engine import data_adapter\r\n     53 from tensorflow.python.keras.engine import training_utils\r\n     54 from tensorflow.python.keras.mixed_precision import loss_scale_optimizer as lso\r\n\r\n~\\Miniconda3\\envs\\tf38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py in <module>\r\n     59 \r\n     60 try:\r\n---> 61   from scipy import sparse as scipy_sparse  # pylint: disable=g-import-not-at-top\r\n     62 except ImportError:\r\n     63   scipy_sparse = None\r\n\r\n~\\Miniconda3\\envs\\tf38\\lib\\site-packages\\scipy\\__init__.py in <module>\r\n    128 \r\n    129     # Allow distributors to run custom init code\r\n--> 130     from . import _distributor_init\r\n    131 \r\n    132     from scipy._lib import _pep440\r\n\r\n~\\Miniconda3\\envs\\tf38\\lib\\site-packages\\scipy\\_distributor_init.py in <module>\r\n     57             os.chdir(libs_path)\r\n     58             for filename in glob.glob(os.path.join(libs_path, '*dll')):\r\n---> 59                 WinDLL(os.path.abspath(filename))\r\n     60         finally:\r\n     61             os.chdir(owd)\r\n\r\n~\\Miniconda3\\envs\\tf38\\lib\\ctypes\\__init__.py in __init__(self, name, mode, handle, use_errno, use_last_error, winmode)\r\n    371 \r\n    372         if handle is None:\r\n--> 373             self._handle = _dlopen(self._name, mode)\r\n    374         else:\r\n    375             self._handle = handle\r\n\r\nFileNotFoundError: Could not find module 'C:\\Users\\me\\Miniconda3\\envs\\tf38\\lib\\site-packages\\scipy\\.libs\\libbanded5x.EHDKC2XVYTQQ5MALRS6XN2CUSS6SRL6P.gfortran-win_amd64.dll' (or one of its dependencies). Try using the full path with constructor syntax.\r\n```\r\n\r\nThe only way to fix the problem is to keep running\r\n\r\n`conda update --all`\r\n\r\nuntil conda detects package inconsistencies in the env and installs conda versions of numpy and six.  After that, tensorflow will import and run normally, and the pip version of numpy (1.19.5) shows when I list packages.  The conda version of numpy (1.20.2) does not show in 'conda list', but is apparently there, and required for tf to load and run.\r\n\r\n**Question:**\r\n\r\nHow can I stop the package inconsistencies from happening every time I upgrade tensorflow using pip install --upgrade?\r\n\r\nPerhaps my setup of mixed conda/pip packages is a bad idea?  I would MUCH rather avoid pip completely, but the version of tensorflow in conda pkgs/main is way outdated (2.3.0), and stopped working anyway (that is another issue: running conda tf suddenly started killing jupyter kernels).\r\n\r\nIs there a better way to get tensorflow 2.4.1 running in a stable manner on my system?  Is there a tf install bug involved here?  Obviously tf 2.4.1 requires numpy 1.19.5.  I tried pinning the env to numpy 1.19.5, but that didn't seem to work.\r\n\r\nAny advice would be greatly appreciated.  Thanks in advance.\r\n\r\n\r\n\r\n", "comments": ["@pythonic2020 Yes, it is a bad idea to mix `conda install` and `pip install`, it's better if you stick to a single type, else you may run into the issues like you have mentioned.\r\nYou can prefer conda install since it has the conda adopted packages within conda environment.\r\nBut, if you have any package dependencies across your projects, you can create virtual environment and install packages using pip which will takes less time and space compared to conda and usually latest packages will be made available in pip first.", "Thank you.  I am unfamiliar with virtual envs.  Should I create one thus:\r\n\r\nconda create -n tfenv pip python=3.8\r\n\r\nand then use 'pip install tensorflow' within it?  And then use pip install for pandas and the other packages I need?\r\n\r\nI cannot use conda install tensorflow at all since tf 2.4.1 isn't available in conda, correct?", "@pythonic2020 Yes, you can use `conda create -n env-name python=x.x`, and in the virtual env, for all the package installation for that env you can use only pip, the reason being not to mix up pip with conda install.", "Ok, thanks again, I'll try that.", "You can close the issue if the above solution answers your question, Thanks!", "I did what you suggested, and installed jupyterlab and notebook from pip.  However, I cannot start jupyterlab.  Jupyter notebook kernels won't start either.  pywin32 is installed.  So I'm dead in the water.  Any ideas?", "Conda it is not supported in this repo. \r\nIf you need Conda it is supported by third-party.\r\nYou could try to ask or open a ticket at:\r\nhttps://docs.anaconda.com/anaconda/user-guide/tasks/tensorflow/\r\nhttps://github.com/AnacondaRecipes/tensorflow_recipes", "Ok, thanks.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48960\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48960\">No</a>\n", "I had success with this env setup:\r\n\r\n```\r\nconda create -n tfenv -c conda-forge python=3.8\r\nconda activate tfenv\r\nconda config --env --add channels conda-forge\r\nconda config --env --set channel_priority flexible\r\nconda install pywin32\r\npip install --upgrade tensorflow tensorflow_io python-dotenv pandas matplotlib scikit-learn seaborn jupyterlab notebook nodejs ipympl jupyterthemes\r\n```"]}, {"number": 48958, "title": "add support for xtensa vision P6 support for person detect usecase.", "body": "this is first minor change, which adds following aspects.\r\n- make script changes to download 3rd party Vision P6 library \r\n- overloaded pooling.cc to start with. conv and depthwise_conv will follow\r\n\r\nTesting\r\n- all tests are passing with command  :\r\n`make -f tensorflow/lite/micro/tools/make/Makefile person_detection_test_int8 TARGET=xtensa TARGET_ARCH=visionp6_ao OPTIMIZED_KERNEL_DIR=xtensa`\r\n", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n", "@advaitjain please review.", "@kpraving Can you please resolve conflicts? Thanks!", "Check out this pull request on&nbsp; <a href=\"https://app.reviewnb.com/tensorflow/tensorflow/pull/48958\"><img align=\"absmiddle\"  alt=\"ReviewNB\" height=\"28\" class=\"BotMessageButtonImage\" src=\"https://raw.githubusercontent.com/ReviewNB/support/master/images/button_reviewnb.png\"/></a> \n\n See visual diffs & provide feedback on Jupyter Notebooks. \n\n---\n\n <i>Powered by <a href='https://www.reviewnb.com/?utm_source=gh'>ReviewNB</a></i>", "All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F48958) for more info**.\n\n<!-- need_author_consent -->", "With TFLM moving to its own GitHub repository, we are not going to be merging any TFLM specific pull requests in the TensorFlow repository starting today.\r\n\r\nI am closing the current PR but please feel free to open a new PR in https://github.com/tensorflow/tflite-micro/.\r\n\r\nhttps://groups.google.com/a/tensorflow.org/g/micro/c/W4DACgjPmOE\r\n"]}, {"number": 48957, "title": "ParameterServerStrategy - generators support", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using):\r\n  - Im using nightly version while the stable is 2.4.1 \r\n- Are you willing to contribute it (Yes/No):\r\n  - No, I have no idea how to do this \r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nIf I pass to `strategy.distribute_datasets_from_function` a fully created dataset (`Dataset.from_tensor_slices`) it works correctly. But while using `Dataset.from_generator` the training seems to get stuck in some infinite recursion or loop.\r\n\r\nI get this error infinitely:\r\n```\r\nERROR:tensorflow:Worker /job:worker/replica:0/task:0 failed with UnavailableError():2 root error(s) found.\r\n  (0) Unavailable:  failed to connect to all addresses\r\nAdditional GRPC error information from remote target /job:chief/replica:0/task:0/device:CPU:0:\r\n:{\"created\":\"@1620307041.224861224\",\"description\":\"Failed to pick subchannel\",\"file\":\"external/com_github_grpc_grpc/src/core/ext/filters/client_channel/client_channel.cc\",\"file_line\":3941,\"referenced_errors\":[{\"created\":\"@1620307041.224860264\",\"description\":\"failed to connect to all addresses\",\"file\":\"external/com_github_grpc_grpc/src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc\",\"file_line\":393,\"grpc_status\":14}]}\r\n\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\r\n\t [[RemoteCall]]\r\n\t [[IteratorGetNextAsOptional]]\r\n  (1) Unavailable:  failed to connect to all addresses\r\nAdditional GRPC error information from remote target /job:chief/replica:0/task:0/device:CPU:0:\r\n:{\"created\":\"@1620307041.224861224\",\"description\":\"Failed to pick subchannel\",\"file\":\"external/com_github_grpc_grpc/src/core/ext/filters/client_channel/client_channel.cc\",\"file_line\":3941,\"referenced_errors\":[{\"created\":\"@1620307041.224860264\",\"description\":\"failed to connect to all addresses\",\"file\":\"external/com_github_grpc_grpc/src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc\",\"file_line\":393,\"grpc_status\":14}]}\r\n\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\r\n\t [[RemoteCall]]\r\n\t [[IteratorGetNextAsOptional]]\r\n\t [[OptionalHasValue/_2]]\r\n0 successful operations.\r\n0 derived errors ignored.\r\nAdditional GRPC error information from remote target /job:worker/replica:0/task:0:\r\n:{\"created\":\"@1620307041.225796166\",\"description\":\"Error received from peer ipv4:192.168.88.111:10001\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"2 root error(s) found.\\n  (0) Unavailable:  failed to connect to all addresses\\nAdditional GRPC error information from remote target /job:chief/replica:0/task:0/device:CPU:0:\\n:{\"created\":\"@1620307041.224861224\",\"description\":\"Failed to pick subchannel\",\"file\":\"external/com_github_grpc_grpc/src/core/ext/filters/client_channel/client_channel.cc\",\"file_line\":3941,\"referenced_errors\":[{\"created\":\"@1620307041.224860264\",\"description\":\"failed to connect to all addresses\",\"file\":\"external/com_github_grpc_grpc/src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc\",\"file_line\":393,\"grpc_status\":14}]}\\n\\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\\n\\t [[RemoteCall]]\\n\\t [[IteratorGetNextAsOptional]]\\n  (1) Unavailable:  failed to connect to all addresses\\nAdditional GRPC error information from remote target /job:chief/replica:0/task:0/device:CPU:0:\\n:{\"created\":\"@1620307041.224861224\",\"description\":\"Failed to pick subchannel\",\"file\":\"external/com_github_grpc_grpc/src/core/ext/filters/client_channel/client_channel.cc\",\"file_line\":3941,\"referenced_errors\":[{\"created\":\"@1620307041.224860264\",\"description\":\"failed to connect to all addresses\",\"file\":\"external/com_github_grpc_grpc/src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc\",\"file_line\":393,\"grpc_status\":14}]}\\n\\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\\n\\t [[RemoteCall]]\\n\\t [[IteratorGetNextAsOptional]]\\n\\t [[OptionalHasValue/_2]]\\n0 successful operations.\\n0 derived errors ignored.\",\"grpc_status\":14} [Op:__inference_fun_178]\r\n\r\nFunction call stack:\r\nfun -> fun -> fun -> fun\r\n\r\n2021-05-06 15:17:21.226996: W tensorflow/core/common_runtime/eager/context_distributed_manager.cc:671] Device filters can only be specified when initializing the cluster. Any changes in device filters are ignored when updating the server def.\r\n2021-05-06 15:17:21.227082: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job ps -> {0 -> 192.168.88.110:10000}\r\n2021-05-06 15:17:21.227095: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 192.168.88.111:10001}\r\n2021-05-06 15:17:21.227101: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job chief -> {0 -> localhost:55849}\r\n2021-05-06 15:17:21.228992: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job ps -> {0 -> 192.168.88.110:10000}\r\n2021-05-06 15:17:21.229009: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 192.168.88.111:10001}\r\n2021-05-06 15:17:21.229017: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job chief -> {0 -> localhost:55849}\r\n```\r\n[This tutorial](https://www.tensorflow.org/tutorials/distribute/parameter_server_training#known_limitations) elaborates on this limitation if I understand correctly.\r\n\r\nIt's very important to be able to train on large datasets while using data-parallel training. It's obvious behavior.\r\n\r\n**Will this change the current api? How?**\r\nProbably no.\r\n\r\n**Who will benefit with this feature?**\r\n\r\n**Any Other info.**\r\n", "comments": ["@wojciechp6 \r\n\r\n In order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!\r\n", "Hi, here is gist for reproduction: https://gist.github.com/wojciechp6/6c9926f7b4b51927c3071610d4579451. I hope it will be helpful.", "It is likely that your workers cannot access the chief where the generator is placed. Could you add chief to the cluster_spec?", "@yuefengz Thanks, it works! It was only lack of chief node in cluster_spec. But I think it is important to mention this requirement in documentation for future. Thanks for help!"]}, {"number": 48956, "title": "Fix dtype of \"global_batch_size\"", "body": "Dtype of \"global_batch_size\" should always same as \"per_example_loss\" to avoid failure on division.", "comments": []}, {"number": 48955, "title": "Missing libtensorflow builds for 2.3.2", "body": "There don't appear to be prebuilt binaries for libtensorflow (https://www.tensorflow.org/install/lang_c) for `2.3.2`.\r\n\r\nhttps://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow-cpu-linux-x86_64-2.3.2.tar.gz actually yields the `darwin` build, which is missing at its own URI. \r\n\r\nThese are missing entirely:\r\n- https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow-gpu-linux-x86_64-2.3.2.tar.gz\r\n- https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow-cpu-darwin-x86_64-2.3.2.tar.gz\r\n\r\nWould it be possible to push those binaries/trigger CI builds to generate them? Thanks!\r\n\r\nRelated: #48550", "comments": ["Hi @JustinWick, thanks for your report. Please take a look at https://github.com/tensorflow/tensorflow/issues/48550#issuecomment-839988395 for more context on this. There was an error that has been fixed (and safeguarded against for future) so I believe I can trigger re-uploads for this version. Have you noticed any versions aside from 2.3.2 that have the same issue?", "I wrote a script to test availability for cpu-linux, gpu-linux and cpu-darwin, and when I ran it for all full releases starting with 2.3.0, only 2.3.2 seems to be affected by this issue, so I think a re-upload will do it.\r\n\r\nI noted something interesting when looking at HTTP response headers, that only 2.3.1 binaries have the \"content-language: en\" entry in their headers. It probably doesn't mean anything, but it could indicate the upload process was different for that particular release.\r\n\r\nI'll check the files as soon as you have them re-uploaded, thanks so much.", "I re-uploaded all these binaries in `gs://tensorflow/libtensorflow`\r\n\r\n```                                                                                                                                \r\nlibtensorflow-cpu-linux-x86_64-2.3.2.tar.gz\r\nlibtensorflow-gpu-linux-x86_64-2.3.2.tar.gz\r\nlibtensorflow_jni-cpu-linux-x86_64-2.3.2.tar.gz\r\nlibtensorflow_jni-gpu-linux-x86_64-2.3.2.tar.gz\r\nlibtensorflow-cpu-darwin-x86_64-2.3.2.tar.gz\r\nlibtensorflow_jni-cpu-darwin-x86_64-2.3.2.tar.gz\r\nlibtensorflow-cpu-linux-x86_64-2.3.2.zip\r\nlibtensorflow-gpu-linux-x86_64-2.3.2.zip\r\nlibtensorflow_jni-cpu-linux-x86_64-2.3.2.zip\r\nlibtensorflow_jni-gpu-linux-x86_64-2.3.2.zip\r\nlibtensorflow-2.3.2.jar\r\nlibtensorflow-src-2.3.2.jar\r\nlibtensorflow_proto-2.3.2.zip\r\n```\r\n\r\nCan you confirm that things look good from your end, please?", "Can we support CentOS7? Build failed with more times trying, if can pls release the centos .so, thks!", "Closing this issue since the binaries are now available. Thanks!\r\n@xwi88 You may want to raise a Feature Request in new issue thread for your case. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48955\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48955\">No</a>\n"]}, {"number": 48954, "title": "Sanity Tests & Unity Test checking fails ", "body": "Commands:\r\n- `tensorflow/tools/ci_build/ci_build.sh CPU tensorflow/tools/ci_build/ci_sanity.sh`\r\n- `tensorflow/tools/ci_build/ci_build.sh CPU bazel test //tensorflow/...`\r\nWhile running above two commands, the test fails and stop because of pip package installation error as shown below.\r\n```\r\n2021-05-07 06:26:49 (1.75 MB/s) - 'get-pip.py' saved [1937346/1937346]\r\n\r\n/install/install_pip_packages.sh: line 21: python3.6: command not found\r\n```", "comments": ["Yes it is a known bug. \r\nSee https://github.com/tensorflow/tensorflow/issues/47989 and the PR at https://github.com/tensorflow/tensorflow/pull/48371 \r\n/cc @theadactyl @angerson", "Closing this issue since its being tracked already. \r\nMarking as a duplicate. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48954\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48954\">No</a>\n"]}, {"number": 48953, "title": "The speed performance of validation_batch_size does not work.", "body": "I assume that the `validation_batch_size` could help speed up the validation process at each epoch. However, this contradict with the experiments.\r\n\r\n> In [15]: x_train.shape\r\n> Out[15]: (128, 1)\r\n> \r\n> In [16]: x_test.shape\r\n> Out[16]: (7600, 1)\r\n\r\nHere is my experiments that I run several times, tf version: 2.3.1\r\n```\r\nmodel = get_model_transormer(num_classes)\r\nfor b in [8, 32, 64, 256, 512, 1024]:\r\n    t1 = time.time()\r\n    history = model.fit(\r\n        x_train, y_train, batch_size=8, epochs=1, \\\r\n        validation_batch_size=b,\r\n        validation_data=(x_test, y_test), verbose=1,\r\n        callbacks = [EarlyStopping(monitor='val_acc', patience=3, mode='max')]\r\n    )\r\n    t2 = time.time()\r\n    print('b:',b,  ' diff:', t2-t1)\r\n```\r\nHere is the report:\r\n\r\n> 16/16 [==============================] - 12s 734ms/step - loss: 0.6992 - acc: 0.7812 - val_loss: 1.1789 - val_acc: 0.4779\r\n> b: 8  diff: 11.802898168563843\r\n> 16/16 [==============================] - 7s 468ms/step - loss: 0.5877 - acc: 0.7891 - val_loss: 1.4876 - val_acc: 0.3555\r\n> b: 32  diff: 7.545728445053101\r\n> 16/16 [==============================] - 7s 420ms/step - loss: 0.4992 - acc: 0.8594 - val_loss: 1.4072 - val_acc: 0.3999\r\n> b: 64  diff: 6.773781061172485\r\n> 16/16 [==============================] - 12s 731ms/step - loss: 0.3447 - acc: 0.9062 - val_loss: 1.1698 - val_acc: 0.5408\r\n> b: 256  diff: 11.749623537063599\r\n> 16/16 [==============================] - 27s 2s/step - loss: 0.2456 - acc: 0.9453 - val_loss: 1.0378 - val_acc: 0.5968\r\n> b: 512  diff: 26.67411971092224\r\n> 16/16 [==============================] - 52s 3s/step - loss: 0.1412 - acc: 0.9922 - val_loss: 1.1378 - val_acc: 0.5218\r\n> b: 1024  diff: 52.29804968833923\r\n\r\nIt seems that setting validation_batch_size to 64 is the optimal option. That's quite weird.\r\nAny explanation ?", "comments": ["@yananchen1989 \r\n\r\nWe see that the issue template has not been filled, could you please do so as it helps us analyse the issue [tf version, steps followed before you ran into this error or stand alone code to reproduce the issue faced]\r\nThanks\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48953\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48953\">No</a>\n"]}, {"number": 48952, "title": "How to add the dependency of TensorFlow 2.5.1-rc1 in my build.gradle file?", "body": "Hey y'all I am working on an android application. The tensor flow version I was using had couple of error, so I switched to nightly builds. However, the latest nightly build does not support my application. I am trying to switch to a newer version of pre-release probably 2.5.1. The TF 2.5.1 can be found in the link https://github.com/tensorflow/tensorflow/tags. How do I add this version of TF to my application in the build.gradle file? \r\n\r\nCurrently, I am using 2.4.0 (stable release), and it looks like this: \r\n```\r\ndependencies {\r\n    implementation 'androidx.appcompat:appcompat:1.2.0'\r\n    implementation 'com.google.android.material:material:1.3.0'\r\n    implementation 'androidx.constraintlayout:constraintlayout:2.0.4'\r\n    implementation 'com.google.firebase:firebase-auth:20.0.3'\r\n    implementation 'com.google.firebase:firebase-database:19.7.0'\r\n    implementation 'androidx.lifecycle:lifecycle-livedata-ktx:2.2.0'\r\n    implementation 'androidx.lifecycle:lifecycle-viewmodel-ktx:2.2.0'\r\n    implementation \"org.tensorflow:tensorflow-lite:2.4.0\"\r\n    implementation group:'org.tensorflow',name:'tensorflow-lite-select-tf-ops',version:'2.4.0'\r\n    implementation 'com.google.firebase:firebase-ml-model-interpreter:22.0.3'\r\n//    implementation 'org.tensorflow:tensorflow-lite:2.6.0.dev20210427-nightly-SNAPSHOT'\r\n//    implementation 'org.tensorflow:tensorflow-lite-select-tf-ops:0.0.0-nightly-SNAPSHOT'\r\n    testImplementation 'junit:junit:4.+'\r\n    implementation 'com.github.PhilJay:MPAndroidChart:v3.1.0'\r\n    androidTestImplementation 'androidx.test.ext:junit:1.1.2'\r\n    androidTestImplementation 'androidx.test.espresso:espresso-core:3.3.0'\r\n}\r\n```\r\n I tried searching for the dependency on https://search.maven.org/, however I could not find the implementation. ", "comments": ["@karundawadi ,\r\n\r\nLooks like this is duplicate of issue #48946.Can you please close this issue, since it is already being tracked there? Thanks!", "Duplicated.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48952\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48952\">No</a>\n"]}, {"number": 48951, "title": "Use static variable for checking TF_CUDNN_USE_FRONTEND", "body": "This PR avoid checking TF_CUDNN_USE_FRONTEND every time we call the CudnnUseFrontend().\r\n\r\ncc. @nluehr ", "comments": ["@kaixih  Can you please address Ubuntu Sanity errors? Thanks!", "I don't think the Ubuntu Sanity failed because of my change. From the log, I didn't find related info. @timshen91 can you advise?"]}, {"number": 48950, "title": "[TF-TRT] CombinedNms Deactivated due to bug", "body": "@bixia1 @tfeher \r\n\r\nThis PR temporarily deactivate the Combined NMS convertor, it seems to have issues in numerous versions of TRT.\r\nFor safety, I deactivate it. Let's reactivate it when stable.\r\n\r\nFYI this bug was found on: `TRT_VERSION: 7.2.3.4`\r\n\r\n```bash\r\n[ RUN      ] OpConvTestInstantiation/OpConverter_FP32_Test.ConvertCombinedNMS/0\r\n2021-05-05 22:34:41.995244: I tensorflow/compiler/tf2tensorrt/convert/convert_nodes_test.cc:1798] %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n2021-05-05 22:34:41.995253: I tensorflow/compiler/tf2tensorrt/convert/convert_nodes_test.cc:1799] tf_type_: DT_FLOAT\r\n2021-05-05 22:34:41.995256: I tensorflow/compiler/tf2tensorrt/convert/convert_nodes_test.cc:1800] trt_mode_: kImplicitBatch\r\n2021-05-05 22:34:41.995260: I tensorflow/compiler/tf2tensorrt/convert/convert_nodes_test.cc:1801] converter_precision_: TrtPrecisionMode::FP32\r\n2021-05-05 22:34:41.995263: I tensorflow/compiler/tf2tensorrt/convert/convert_nodes_test.cc:1802] %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\ntensorflow/compiler/tf2tensorrt/convert/convert_nodes_test.cc:1933: Failure\r\nValue of: GetDataAsFloat(output_data[i])\r\nExpected: has 2 elements where\r\nelement #0 is equal to 0.7,\r\nelement #1 is equal to 0.4\r\n  Actual: { 0.700195, 0.399902 }, whose element #0 doesn't match\r\nGoogle Test trace:\r\ntensorflow/compiler/tf2tensorrt/convert/convert_nodes_test.cc:3670: Test 1: Original test\r\ntensorflow/compiler/tf2tensorrt/convert/convert_nodes_test.cc:1933: Failure\r\nValue of: GetDataAsFloat(output_data[i])\r\nExpected: has 4 elements where\r\nelement #0 is equal to 5,\r\nelement #1 is equal to 3,\r\nelement #2 is equal to 1,\r\nelement #3 is equal to 0\r\n  Actual: { 1.99902, 1.99902, 1, 0 }, whose element #0 doesn't match\r\nGoogle Test trace:\r\ntensorflow/compiler/tf2tensorrt/convert/convert_nodes_test.cc:3670: Test 2: clip_boxes\r\ntensorflow/compiler/tf2tensorrt/convert/convert_nodes_test.cc:1933: Failure\r\nValue of: GetDataAsFloat(output_data[i])\r\nExpected: has 4 elements where\r\nelement #0 is equal to 5,\r\nelement #1 is equal to 3,\r\nelement #2 is equal to 0,\r\nelement #3 is equal to 0\r\n  Actual: { 1.99902, 1.99902, 0, 0 }, whose element #0 doesn't match\r\nGoogle Test trace:\r\ntensorflow/compiler/tf2tensorrt/convert/convert_nodes_test.cc:3670: Test 3: score threshold\r\ntensorflow/compiler/tf2tensorrt/convert/convert_nodes_test.cc:1933: Failure\r\nValue of: GetDataAsFloat(output_data[i])\r\nExpected: has 4 elements where\r\nelement #0 is equal to 5,\r\nelement #1 is equal to 3,\r\nelement #2 is equal to 1,\r\nelement #3 is equal to 0\r\n  Actual: { 1.99902, 1.99902, 1, 0 }, whose element #0 doesn't match\r\nGoogle Test trace:\r\ntensorflow/compiler/tf2tensorrt/convert/convert_nodes_test.cc:3670: Test 4: max coord first\r\n[  FAILED  ] OpConvTestInstantiation/OpConverter_FP32_Test.ConvertCombinedNMS/0, where GetParam() = (4-byte object <00-00 00-00>, 1, 4-byte object <00-00 00-00>) (49 ms)\r\n[ RUN      ] OpConvTestInstantiation/OpConverter_FP32_Test.ConvertCombinedNMS/1\r\n2021-05-05 22:34:42.044405: I tensorflow/compiler/tf2tensorrt/convert/convert_nodes_test.cc:1798] %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n2021-05-05 22:34:42.044415: I tensorflow/compiler/tf2tensorrt/convert/convert_nodes_test.cc:1799] tf_type_: DT_FLOAT\r\n2021-05-05 22:34:42.044418: I tensorflow/compiler/tf2tensorrt/convert/convert_nodes_test.cc:1800] trt_mode_: kExplicitBatch\r\n2021-05-05 22:34:42.044421: I tensorflow/compiler/tf2tensorrt/convert/convert_nodes_test.cc:1801] converter_precision_: TrtPrecisionMode::FP32\r\n2021-05-05 22:34:42.044424: I tensorflow/compiler/tf2tensorrt/convert/convert_nodes_test.cc:1802] %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\ntensorflow/compiler/tf2tensorrt/convert/convert_nodes_test.cc:1933: Failure\r\nValue of: GetDataAsFloat(output_data[i])\r\nExpected: has 2 elements where\r\nelement #0 is equal to 0.7,\r\nelement #1 is equal to 0.4\r\n  Actual: { 0.700195, 0.399902 }, whose element #0 doesn't match\r\nGoogle Test trace:\r\ntensorflow/compiler/tf2tensorrt/convert/convert_nodes_test.cc:3670: Test 1: Original test\r\ntensorflow/compiler/tf2tensorrt/convert/convert_nodes_test.cc:1933: Failure\r\nValue of: GetDataAsFloat(output_data[i])\r\nExpected: has 4 elements where\r\nelement #0 is equal to 5,\r\nelement #1 is equal to 3,\r\nelement #2 is equal to 1,\r\nelement #3 is equal to 0\r\n  Actual: { 1.99902, 1.99902, 1, 0 }, whose element #0 doesn't match\r\nGoogle Test trace:\r\ntensorflow/compiler/tf2tensorrt/convert/convert_nodes_test.cc:3670: Test 2: clip_boxes\r\ntensorflow/compiler/tf2tensorrt/convert/convert_nodes_test.cc:1933: Failure\r\nValue of: GetDataAsFloat(output_data[i])\r\nExpected: has 4 elements where\r\nelement #0 is equal to 5,\r\nelement #1 is equal to 3,\r\nelement #2 is equal to 0,\r\nelement #3 is equal to 0\r\n  Actual: { 1.99902, 1.99902, 0, 0 }, whose element #0 doesn't match\r\nGoogle Test trace:\r\ntensorflow/compiler/tf2tensorrt/convert/convert_nodes_test.cc:3670: Test 3: score threshold\r\ntensorflow/compiler/tf2tensorrt/convert/convert_nodes_test.cc:1933: Failure\r\nValue of: GetDataAsFloat(output_data[i])\r\nExpected: has 4 elements where\r\nelement #0 is equal to 5,\r\nelement #1 is equal to 3,\r\nelement #2 is equal to 1,\r\nelement #3 is equal to 0\r\n  Actual: { 1.99902, 1.99902, 1, 0 }, whose element #0 doesn't match\r\nGoogle Test trace:\r\ntensorflow/compiler/tf2tensorrt/convert/convert_nodes_test.cc:3670: Test 4: max coord first\r\n[  FAILED  ] OpConvTestInstantiation/OpConverter_FP32_Test.ConvertCombinedNMS/1, where GetParam() = (4-byte object <01-00 00-00>, 1, 4-byte object <00-00 00-00>) (49 ms)\r\n[ RUN      ] OpConvTestInstantiation/OpConverter_FP32_Test.ConvertCombinedNMS/2\r\n2021-05-05 22:34:42.093225: I tensorflow/compiler/tf2tensorrt/convert/convert_nodes_test.cc:1798] %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n2021-05-05 22:34:42.093234: I tensorflow/compiler/tf2tensorrt/convert/convert_nodes_test.cc:1799] tf_type_: DT_FLOAT\r\n2021-05-05 22:34:42.093237: I tensorflow/compiler/tf2tensorrt/convert/convert_nodes_test.cc:1800] trt_mode_: kDynamicShape\r\n2021-05-05 22:34:42.093241: I tensorflow/compiler/tf2tensorrt/convert/convert_nodes_test.cc:1801] converter_precision_: TrtPrecisionMode::FP32\r\n2021-05-05 22:34:42.093251: I tensorflow/compiler/tf2tensorrt/convert/convert_nodes_test.cc:1802] %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\r\n[       OK ] OpConvTestInstantiation/OpConverter_FP32_Test.ConvertCombinedNMS/2 (7 ms)\r\n[  FAILED  ] 2 tests, listed below:\r\n[  FAILED  ] OpConvTestInstantiation/OpConverter_FP32_Test.ConvertCombinedNMS/0, where GetParam() = (4-byte object <00-00 00-00>, 1, 4-byte object <00-00 00-00>)\r\n[  FAILED  ] OpConvTestInstantiation/OpConverter_FP32_Test.ConvertCombinedNMS/1, where GetParam() = (4-byte object <01-00 00-00>, 1, 4-byte object <00-00 00-00>)\r\n```", "comments": ["We just got combinedNMS back to work not long ago, see https://github.com/tensorflow/tensorflow/pull/47698.\r\nCombinedNMS affects a few important customers for some reasons. So, it would be much nice if we can find out the problem and fix the problem. In particular, which TensorRT versions have such a problem? Within google, we may not even be using the relevant TensorRT version. If the problem is due to tactics selection in TensorRT, maybe a better way is to disable the problematic tactics?\r\n\r\nWould you please also create an issue to report the problem, and provide a reproducer and the environment to reproduce it?", "@DEKHTIARJonathan  Any update on this PR? Please. Thanks!", "Closing in favor of #50450 "]}, {"number": 48949, "title": "TF 2.4.1 SavedModel.load() gives -Error: Expected these arguments to match one of the following Options", "body": "Hi,\r\n\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): `No custom code`\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): `Linux Ubuntu 16.04`\r\n- TensorFlow installed from (source or binary): `Binary`\r\n- TensorFlow version (use command below): `v2.4.0-49-g85c8b2a817f 2.4.1`\r\n- Python version: `3.6.8`\r\n- Running on `CPU`\r\n\r\n**Describe the current behavior**\r\n\r\nI'm running simple text boundary detection model. I have saved this model using ONNX functions available for TensorFlow conversions (`onnx_tf.backend.prepare` and `onnx_tf.backend.export_graph`). [Repo Link](https://github.com/onnx/onnx-tensorflow/blob/master/onnx_tf/backend_rep.py) for reference\r\n\r\nTF Model by itself runs fine but when exported and saved with `SavedModel` type gives error. I see that this is an old and common issue folks are running into. Some suggested updating versions, however I'm already using 2.4.1 which does not help in this case.\r\n \r\nSavelModel - [here ](https://1drv.ms/u/s!Astr8XJs2VCYge03AifwF6EiFItolg?e=IWRX3n)\r\n\r\n\r\nCommand to reproduce - \r\n\r\n```python\r\nimport tensorflow as tf\r\n# Load saved model and build the detection function\r\ndetect_fn = tf.saved_model.load('detect/')\r\n\r\ninput_tensor = tf.convert_to_tensor(np.array(any_input_image) # Any google image of sizable width and height [1x3xHxW] should work\r\n\r\ndetections,features = detect_fn(input_tensor)  # <-- Gives error on this line\r\n\r\n```\r\n\r\n\r\n**Stack Trace:**\r\n\r\n```python\r\n\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-109-35d1f70160c5> in <module>\r\n----> 1 detections,features = detect_fn(input_tensor)\r\n      2 # print(detect_fn)\r\n\r\n~/anaconda3/envs/textdet/lib/python3.6/site-packages/tensorflow/python/saved_model/load.py in _call_attribute(instance, *args, **kwargs)\r\n    666 \r\n    667 def _call_attribute(instance, *args, **kwargs):\r\n--> 668   return instance.__call__(*args, **kwargs)\r\n    669 \r\n    670 \r\n\r\n~/anaconda3/envs/textdet/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)\r\n    822     if RUN_FUNCTIONS_EAGERLY:\r\n    823       with trace.Trace(self._name, tf_function_call=\"eager\"):\r\n--> 824         return self._python_function(*args, **kwds)\r\n    825 \r\n    826     tracing_count = self.experimental_get_tracing_count()\r\n\r\n~/anaconda3/envs/textdet/lib/python3.6/site-packages/tensorflow/python/saved_model/function_deserialization.py in restored_function_body(*args, **kwargs)\r\n    271         .format(_pretty_format_positional(args), kwargs,\r\n    272                 len(saved_function.concrete_functions),\r\n--> 273                 \"\\n\\n\".join(signature_descriptions)))\r\n    274 \r\n    275   concrete_function_objects = []\r\n\r\nValueError: Could not find matching function to call loaded from the SavedModel. Got:\r\n  Positional arguments (1 total):\r\n    * tf.Tensor(\r\n[[[[ 2.2317834  2.2317834  2.2317834 ... -2.117904  -2.117904\r\n    -2.117904 ]\r\n   [ 2.2317834  2.2317834  2.2317834 ... -2.117904  -2.117904\r\n    -2.117904 ]\r\n   [ 2.2317834  2.2317834  2.2317834 ... -2.117904  -2.117904\r\n    -2.117904 ]\r\n   ...\r\n   [ 2.2146587  2.2317834  2.2489083 ... -2.117904  -2.117904\r\n    -2.117904 ]\r\n   [ 2.2146587  2.2317834  2.2489083 ... -2.117904  -2.117904\r\n    -2.117904 ]\r\n   [ 2.2146587  2.2317834  2.2489083 ... -2.117904  -2.117904\r\n    -2.117904 ]]\r\n\r\n  [[ 2.4110644  2.4110644  2.4110644 ... -2.0357144 -2.0357144\r\n    -2.0357144]\r\n   [ 2.4110644  2.4110644  2.4110644 ... -2.0357144 -2.0357144\r\n    -2.0357144]\r\n   [ 2.4110644  2.4110644  2.4110644 ... -2.0357144 -2.0357144\r\n    -2.0357144]\r\n   ...\r\n   [ 2.3935575  2.4110644  2.4285715 ... -2.0357144 -2.0357144\r\n    -2.0357144]\r\n   [ 2.3935575  2.4110644  2.4285715 ... -2.0357144 -2.0357144\r\n    -2.0357144]\r\n   [ 2.3935575  2.4110644  2.4285715 ... -2.0357144 -2.0357144\r\n    -2.0357144]]\r\n\r\n  [[ 2.6225708  2.6225708  2.6225708 ... -1.8044444 -1.8044444\r\n    -1.8044444]\r\n   [ 2.6225708  2.6225708  2.6225708 ... -1.8044444 -1.8044444\r\n    -1.8044444]\r\n   [ 2.6225708  2.6225708  2.6225708 ... -1.8044444 -1.8044444\r\n    -1.8044444]\r\n   ...\r\n   [ 2.6051416  2.6225708  2.64      ... -1.8044444 -1.8044444\r\n    -1.8044444]\r\n   [ 2.6051416  2.6225708  2.64      ... -1.8044444 -1.8044444\r\n    -1.8044444]\r\n   [ 2.6051416  2.6225708  2.64      ... -1.8044444 -1.8044444\r\n    -1.8044444]]]], shape=(1, 3, 1280, 960), dtype=float32)\r\n  Keyword arguments: {}\r\n\r\nExpected these arguments to match one of the following 2 option(s):\r\n\r\nOption 1:\r\n  Positional arguments (0 total):\r\n    * \r\n  Keyword arguments: {'input.1': TensorSpec(shape=(1, 3, 1280, 960), dtype=tf.float32, name='input.1')}\r\n\r\nOption 2:\r\n  Positional arguments (0 total):\r\n    * \r\n  Keyword arguments: {'input.1': TensorSpec(shape=(1, 3, 768, 768), dtype=tf.float32, name='input.1')}\r\n```\r\n\r\nAlso why is my `keywords arguments` dictionary showing empty ?\r\n\r\nAny help appreciated.", "comments": [" Was able to reproduce the issue in TF 2.4 Version. Please find the gist [here](https://colab.research.google.com/gist/saikumarchalla/d304d7d50f6f403edbbd8000cbdb8f77/untitled.ipynb).Thanks!", "@mohammedayub44, The issue seems to be with the `input_tensor`.\r\nThe model expects batch of images instead of single image input, you can change it by adding `tf.newaxis` like below.\r\n`input_tensor = tf.convert_to_tensor(image_np) `\r\n`input_tensor = input_tensor[tf.newaxis, ...]`\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "@sachinprasadhs I add the the batch dimension with tf.newaxis. I still get the error. If you happen to run it successfully, can you share the code snippet, ill try on my end.\r\n\r\nThanks !", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48949\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48949\">No</a>\n", "@sachinprasadhs  just a reminder that the suggestion still throws error. If you please check. Thanks for the help. ", "Can you please save and load the model using [this](https://www.tensorflow.org/guide/keras/save_and_serialize#how_to_save_and_load_a_model) method and try again.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48949\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48949\">No</a>\n"]}, {"number": 48948, "title": "Removing some nonsense in AddNodeWithParameters", "body": "Removing some nonsense in AddNodeWithParameters dealing with extra 'free' calls on empty node.", "comments": []}, {"number": 48946, "title": "How to add the dependency of TensorFlow 2.5.1-rc1 in my build.gradle file?", "body": "Hey y'all I am working on an android application. The tensor flow version I was using had couple of error, so I switched to nightly builds. However, the latest nightly build does not support my application. I am trying to switch to a newer version of pre-release probably 2.5.1. The TF 2.5.1 can be found in the link https://github.com/tensorflow/tensorflow/tags. How do I add this version of TF to my application in the build.gradle file? \r\n\r\nCurrently I am using 2.4.0 (stable release), and it looks like this: \r\n```\r\ndependencies {\r\n    implementation 'androidx.appcompat:appcompat:1.2.0'\r\n    implementation 'com.google.android.material:material:1.3.0'\r\n    implementation 'androidx.constraintlayout:constraintlayout:2.0.4'\r\n    implementation 'com.google.firebase:firebase-auth:20.0.3'\r\n    implementation 'com.google.firebase:firebase-database:19.7.0'\r\n    implementation 'androidx.lifecycle:lifecycle-livedata-ktx:2.2.0'\r\n    implementation 'androidx.lifecycle:lifecycle-viewmodel-ktx:2.2.0'\r\n    implementation \"org.tensorflow:tensorflow-lite:2.4.0\"\r\n    implementation group:'org.tensorflow',name:'tensorflow-lite-select-tf-ops',version:'2.4.0'\r\n    implementation 'com.google.firebase:firebase-ml-model-interpreter:22.0.3'\r\n//    implementation 'org.tensorflow:tensorflow-lite:2.6.0.dev20210427-nightly-SNAPSHOT'\r\n//    implementation 'org.tensorflow:tensorflow-lite-select-tf-ops:0.0.0-nightly-SNAPSHOT'\r\n    testImplementation 'junit:junit:4.+'\r\n    implementation 'com.github.PhilJay:MPAndroidChart:v3.1.0'\r\n    androidTestImplementation 'androidx.test.ext:junit:1.1.2'\r\n    androidTestImplementation 'androidx.test.espresso:espresso-core:3.3.0'\r\n}\r\n```\r\n I tried searching for the dependency on https://search.maven.org/, however I could not find the implementation. ", "comments": ["\"the latest nightly build does not support my application\" What is the exact error you got here?\r\nI think it is better to just fix the issue since there is no guarantee it will not happen in the new release.\r\n\r\nThe pre-release is not hosted on Maven. If if you want to give it a try, you can build it following https://www.tensorflow.org/lite/guide/build_android", "I think this issue was resolved in another issue thank you. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48946\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48946\">No</a>\n"]}, {"number": 48945, "title": "Ragged factory Extra check item len", "body": "Explore a fix for https://github.com/tensorflow/tensorflow/issues/48941\r\n\r\nFixes #48941", "comments": ["@gbaned Can you connect this PR with https://github.com/tensorflow/tensorflow/issues/48941?", "Do you need anything else here?", "Seems auto-merge is not happening but the changes are merged into master now, so we can close this. Thank you for the PR.\r\n"]}, {"number": 48944, "title": "Expose TF_NewOperationLocked, TF_FinishOperationLocked, and ToOperation", "body": "Expose `TF_NewOperationLocked`, `TF_FinishOperationLocked`, and `ToOperation` to the C API.  `ToOperation` is in `c_api_internal.h`.\r\n\r\nFixes #48767\r\nFixes #48815", "comments": ["I can't see details for the failing test, can someone check it or force a re-run?", "From the log:\r\n```\r\nERROR: T:/src/github/tensorflow/tensorflow/python/BUILD:370:27: Linking of rule '//tensorflow/python:_pywrap_toco_api.so' failed (Exit 1120): link.exe failed: error executing command\r\n  cd T:/tmp/bigvaudl/execroot/org_tensorflow\r\n  SET LIB=C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.27.29110\\lib\\x64;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.8\\lib\\um\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.18362.0\\ucrt\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.18362.0\\um\\x64\r\n    SET PATH=C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\IDE\\\\Extensions\\Microsoft\\IntelliCode\\CLI;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.27.29110\\bin\\HostX64\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\IDE\\VC\\VCPackages;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\TestWindow;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\TeamFoundation\\Team Explorer;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\MSBuild\\Current\\bin\\Roslyn;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Team Tools\\Performance Tools\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Team Tools\\Performance Tools;C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Common\\VSPerfCollectionTools\\vs2019\\\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Common\\VSPerfCollectionTools\\vs2019\\;C:\\Program Files (x86)\\Microsoft SDKs\\Windows\\v10.0A\\bin\\NETFX 4.8 Tools\\x64\\;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\Tools\\devinit;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\10.0.18362.0\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\\\MSBuild\\Current\\Bin;C:\\Windows\\Microsoft.NET\\Framework64\\v4.0.30319;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\IDE\\;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\Tools\\;;C:\\Windows\\system32;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\CMake\\CMake\\bin;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\CMake\\Ninja\r\n    SET PWD=/proc/self/cwd\r\n    SET PYTHON_BIN_PATH=C:/Python37/python.exe\r\n    SET PYTHON_LIB_PATH=C:/Python37/lib/site-packages\r\n    SET RUNFILES_MANIFEST_ONLY=1\r\n    SET TEMP=T:\\tmp\r\n    SET TF2_BEHAVIOR=1\r\n    SET TMP=T:\\tmp\r\n  C:/Program Files (x86)/Microsoft Visual Studio/2019/Community/VC/Tools/MSVC/14.27.29110/bin/HostX64/x64/link.exe @bazel-out/x64_windows-opt/bin/tensorflow/python/_pywrap_toco_api.so-2.params\r\nExecution platform: @local_execution_config_platform//:platform\r\n   Creating library bazel-out/x64_windows-opt/bin/tensorflow/python/_pywrap_toco_api.so.if.lib and object bazel-out/x64_windows-opt/bin/tensorflow/python/_pywrap_toco_api.so.if.exp\r\ntoco_python_api_wrapper.obj : error LNK2019: unresolved external symbol \"class std::vector<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,class std::allocator<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > > > const __cdecl toco::RetrieveCollectedErrors(void)\" (?RetrieveCollectedErrors@toco@@YA?BV?$vector@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@V?$allocator@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@@std@@XZ) referenced in function \"public: class pybind11::list __cdecl <lambda_a6fa55ed908e737f35e4ed64cca3f463>::operator()(void)const \" (??R<lambda_a6fa55ed908e737f35e4ed64cca3f463>@@QEBA?AVlist@pybind11@@XZ)\r\nbazel-out\\x64_windows-opt\\bin\\tensorflow\\python\\_pywrap_toco_api.so : fatal error LNK1120: 1 unresolved externals\r\n```\r\nDoes not seem to be related to my changes."]}, {"number": 48942, "title": "Building tensorflow for SSE4.2, cannot find proper option in configure.py", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>![image](https://user-images.githubusercontent.com/34324909/117359506-80387880-ae85-11eb-9821-290f3ddb3ee0.png)\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 1.15.0\r\n- Python version: 3.7.9\r\n- Installed using virtualenv? pip? conda?: build\r\n- Bazel version (if compiling from source): 0.26.1\r\n- GCC/Compiler version (if compiling from source): not sure\r\n- CUDA/cuDNN version: 10, 7.4\r\n- GPU model and memory: 4gb, 1050ti and 1650 super, 6.1,7.5\r\n\r\n\r\n\r\n**Describe the problem**\r\nBuilding for SSE4.2. No suggestion on how to specify in ./configure.py\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n![image](https://user-images.githubusercontent.com/34324909/117359540-8c243a80-ae85-11eb-87f6-96d12a76cc09.png)\r\n\r\n**Any other info / logs**\r\n![image](https://user-images.githubusercontent.com/34324909/117359577-96463900-ae85-11eb-9df2-ba5a2fd241f0.png)", "comments": ["These are the available options:\r\nhttps://github.com/tensorflow/tensorflow/blob/4bdae6bb3b3a31de0e7adc111e6ed4a83c9341a0/.bazelrc#L23-L33\r\n\r\nYou can use the native one if the SSE4.2 is the same where you are compiling TF.", "I'm on windows, and it's an SSE4.2 server. I meant in ./configure.py where it suggests /arch:AVX. Do you mean I can use /arc:native or just use /arc:AVX?", "Generally I don't compile on win I think that these are the available ones https://docs.microsoft.com/it-it/cpp/build/reference/arch-x64?view=msvc-160", "It might be /arch:SSE2, I'll post an update here for any future people that need to do this.", "![image](https://user-images.githubusercontent.com/34324909/117366373-a7477800-ae8e-11eb-95df-73f9918e8237.png)\r\nNo idea what this error is.", "Having issues once I downgraded to VS2017 from VS2019 build tools, since bazel wants you to use 2013 to 2017 and build fails. When downgrading, the above error occurs? no idea what to do.", "Sorry but we don't support TF 1.x anymore.", "That is a BS move to be fair... we should be able to compile older versions without issue. Forcing visual studio 2019 for compilation while bazel demands 2017 or below makes absolutely no sense. The r1.15 branch has it's own configure.py, so why is this even happening in the first place?", "TF on win is tested with Visual studio 2019 https://www.tensorflow.org/install/source_windows?hl=en#install_visual_c_build_tools_2019\r\n\r\nWhat I meant is that we don't support in general tickets on TF 1.x as it is defacto EOL", "I just mean that both bazel and the tester should use the SAME visual studio code version. I guess I'll try using a higher bazel version though that'd 100% fail.\r\n", "> I just mean that both bazel and the tester should use the SAME visual studio code version. I guess I'll try using a higher bazel version though that'd 100% fail.\r\n\r\nHave you found this in the master branch?", "I believe so...", "In your template I see `TensorFlow version: 1.15.0` we don't suypport TF 1.x please use a recent Tensorflow version.", "I've tried five different branches including master. Master is the most recent version. I've tried now r1.15,r2.3,r1.14, and r1.13 as well as master. What more can I do?", "> since bazel wants you to use 2013 to 2017 \r\n\r\nIn master,  where do you have evidence of this request?", "Compiling again to reach the final error, give me a few. Although, I think that error came bec I was using the wrong version of bazel for tf2... so you are probably right. Still, not supporting earlier builds compilation is heavily frowned upon...", "Any updates? bazel issue is still ongoing.", "What Is the bazel issue with master?", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48942\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48942\">No</a>\n"]}, {"number": 48941, "title": "tf.ragged.constant fails on list of np.array", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): OSX Catalina 10.15\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): 2.5.0rc2\r\n- Python version: 3.9.2\r\n\r\n**Describe the current behavior**\r\n\r\nPassing a list of Numpy arrays of rank > 1 one breaks tf.ragged.constant. Happens in both tf 2.4 and 2.5\r\n\r\n**Describe the expected behavior**\r\n\r\nThat it would create the requests multidimensional ragged constant. I think this is a pretty common use case; for example, I have N variable-sized lists of xyz points, shape (None, 3), and want to turn them into one ragged constant of shape (N, None, 3).\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\nhttps://colab.research.google.com/drive/1Zi40gL5IdARNeKid_7R_2b7_JcnWDW0T?usp=sharing \r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\n`Traceback (most recent call last):\r\n  File \"/Users/user1/Desktop/CS/ML/trees/trees-pointnet/test.py\", line 31, in <module>\r\n    b = tf.ragged.constant(a, ragged_rank=1)\r\n  File \"/Users/user1/anaconda3/envs/tf2.5/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\", line 206, in wrapper\r\n    return target(*args, **kwargs)\r\n  File \"/Users/user1/anaconda3/envs/tf2.5/lib/python3.9/site-packages/tensorflow/python/ops/ragged/ragged_factory_ops.py\", line 86, in constant\r\n    return _constant_value(ragged_factory, constant_op.constant, pylist, dtype,\r\n  File \"/Users/user1/anaconda3/envs/tf2.5/lib/python3.9/site-packages/tensorflow/python/ops/ragged/ragged_factory_ops.py\", line 218, in _constant_value\r\n    inner_shape = _default_inner_shape_for_pylist(pylist, ragged_rank)\r\n  File \"/Users/user1/anaconda3/envs/tf2.5/lib/python3.9/site-packages/tensorflow/python/ops/ragged/ragged_factory_ops.py\", line 311, in _default_inner_shape_for_pylist\r\n    inner_shape = get_inner_shape(flat_values)\r\n  File \"/Users/user1/anaconda3/envs/tf2.5/lib/python3.9/site-packages/tensorflow/python/ops/ragged/ragged_factory_ops.py\", line 285, in get_inner_shape\r\n    return (len(item),) + get_inner_shape(item[0])\r\n  File \"/Users/user1/anaconda3/envs/tf2.5/lib/python3.9/site-packages/tensorflow/python/ops/ragged/ragged_factory_ops.py\", line 284, in get_inner_shape\r\n    elif item:\r\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()`\r\n", "comments": ["Can you check with https://github.com/tensorflow/tensorflow/pull/48945?", "That looks like it should do it", "@JRice15 ,\r\n\r\nPlease close this issue once PR is merged.Thanks", "@Saduf2019 ,\r\n\r\nI was able to reproduce the issue in tf v2.4,v2.5 and nightly.Please find the [gist](https://colab.research.google.com/gist/tilakrayal/002794e031c0d95a282f4f108bcd7511/48941.ipynb) here.", "Please close this. The PR Is merged.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48941\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48941\">No</a>\n"]}, {"number": 48940, "title": "TF 1.15.0 GPU, 1050ti & 1650 super, CUDNN 7.4.2 CUDA 10.0.130", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version: 1.15.0 gpu\r\n- Python version: 3.7.9\r\n- Installed using virtualenv? pip? conda?: conda, pip\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10.0.130, 7.4.2\r\n- GPU model and memory: 1050ti, 4gb, 1650 super, 4gb\r\n\r\n\r\n\r\n**Describe the problem**\r\n![image](https://user-images.githubusercontent.com/34324909/117342305-13b37e80-ae71-11eb-9eb5-16e74c168067.png)\r\n\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nInstalled CUDA and CUDNN. Used conda to create new env with python 3.7.9, attempted 3.7.10 and lower versions too\r\nincluding 3.6\r\npython\r\nimport tensorflow as tf\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\nThis exact installation worked on my other computer, and I was using it to test out a completely new rig. ", "comments": ["What is make/model of your machine? Does it support AVX instruction sets?", "Dual xeon x5690, DDR3 96GB 1333mhz RAM, dell r710 ", "Ah it seems AVX isn't supported. However, I have ran previous tensorflow versions on it without issues.", "TF 1.6 and above pre built binaries require systems to support AVX instructions set.\r\nSee https://www.tensorflow.org/install/pip#hardware-requirements\r\nYour other option is to build TF by source by enabling CPU optimization flags or you can switch to google colab to use TF-here all you need is internet connection and google colab hosts latest stable TF version where you can also utilize gpu, tpu accelerators as well.\r\n", "Weird, I clearly remember running tensorflow gpu 1.14.0 without issues however.", "Are there specific instructions for building without AVX for versions prior to 2.0?", "I am afraid that the documentation is scarce on that front. You can refer previous [thread](https://github.com/tensorflow/tensorflow/issues/19584) which discuss building TF without AVX support or try using [community supported ](https://github.com/fo40225/tensorflow-windows-wheel)TF wheels.", "Interesting.\r\n![image](https://user-images.githubusercontent.com/34324909/117345914-1a43f500-ae75-11eb-9de3-edd8f33897e5.png)\r\nI got it working... am very confused. Did not install any separate wheel.\r\nI will have to check the version of tensorflow to confirm.", "Never mind. Code doesn't run, crashed right after without any log.", "I found a nice wheel that lets me even use a higher version of CUDA and CUDNN, so that would hopefully work! Thank you.", "Awesome. Will close this thread now that you have found a potential workaround. Feel free to reopen if have further questions. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48940\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48940\">No</a>\n", "![image](https://user-images.githubusercontent.com/34324909/117359176-086a4e00-ae85-11eb-8749-6bf52558bf7e.png)\r\nI am not sure what config I am supposed to use for SSE4.2."]}, {"number": 48939, "title": "couldn't install tensorflow with poetry", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Mint 20.1 (based on Ubuntu 20.04)\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No.\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version: 2.4.1\r\n- Python version: 3.8\r\n- Installed using virtualenv? pip? conda?: poetry\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10.1\r\n- GPU model and memory: Nvidia RTX 2080\r\n\r\n\r\n\r\n**Describe the problem**\r\nTensorflow finds the GPU but it isn't listed under `tf.config.list_physical_devices()`.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n```console\r\n(base) lukas@Makushin:~$ cd ~/Desktop\r\n(base) lukas@Makushin:~/Desktop$ poetry new poetry-demo\r\nCreated package poetry_demo in poetry-demo\r\n```\r\n\r\nAt this point I replaced the `pyproject.toml` file with the following file:\r\n\r\n```\r\n[tool.poetry]\r\nname = \"poetry_demo\"\r\nversion = \"0.1.0\"\r\ndescription = \"\"\r\nauthors = [\"xxx <xxx@xxx.xx>\"]\r\n\r\n[tool.poetry.dependencies]\r\n# python\r\npython = \"3.8.8\"\r\n# data science\r\nnumpy = \"*\"\r\npandas = \"*\"\r\ngeopandas = \"*\"\r\nmatplotlib = \"*\"\r\nsklearn = \"*\"\r\ntensorflow = \"^2.4.1\"\r\n# image processing\r\nPillow = \"*\"\r\nrasterio = \"*\"\r\n\r\n```\r\n\r\n```console\r\n(base) lukas@Makushin:~/Desktop$ cd poetry-demo\r\n(base) lukas@Makushin:~/Desktop/poetry-demo$ poetry install\r\nCreating virtualenv poetry-demo-bLNYl46S-py3.8 in /home/lukas/.cache/pypoetry/virtualenvs\r\nUpdating dependencies\r\nResolving dependencies... (6.6s)\r\n\r\nWriting lock file\r\n\r\nPackage operations: 86 installs, 0 updates, 0 removals\r\n\r\n  \u2022 Installing certifi (2020.12.5)\r\n  \u2022 Installing chardet (4.0.0)\r\n  \u2022 Installing idna (2.10)\r\n```\r\n\r\n<details>\r\n  <summary>...</summary>\r\n\r\n```console\r\n  \u2022 Installing pyasn1 (0.4.8)\r\n  \u2022 Installing urllib3 (1.26.4)\r\n  \u2022 Installing cachetools (4.2.2)\r\n  \u2022 Installing oauthlib (3.1.0)\r\n  \u2022 Installing pyasn1-modules (0.2.8)\r\n  \u2022 Installing requests (2.25.1)\r\n  \u2022 Installing rsa (4.7.2)\r\n  \u2022 Installing six (1.15.0)\r\n  \u2022 Installing click (7.1.2)\r\n  \u2022 Installing google-auth (1.30.0)\r\n  \u2022 Installing numpy (1.19.5)\r\n  \u2022 Installing requests-oauthlib (1.3.0)\r\n  \u2022 Installing absl-py (0.12.0)\r\n  \u2022 Installing attrs (21.1.0)\r\n  \u2022 Installing click-plugins (1.1.1)\r\n  \u2022 Installing cligj (0.7.1)\r\n  \u2022 Installing google-auth-oauthlib (0.4.4)\r\n  \u2022 Installing grpcio (1.32.0)\r\n  \u2022 Installing joblib (1.0.1)\r\n  \u2022 Installing markdown (3.3.4)\r\n  \u2022 Installing markupsafe (1.1.1)\r\n  \u2022 Installing munch (2.5.0)\r\n  \u2022 Installing protobuf (3.15.8)\r\n  \u2022 Installing pyparsing (2.4.7)\r\n  \u2022 Installing python-dateutil (2.8.1)\r\n  \u2022 Installing pytz (2021.1)\r\n  \u2022 Installing scipy (1.6.3)\r\n  \u2022 Installing tensorboard-data-server (0.6.1)\r\n  \u2022 Installing tensorboard-plugin-wit (1.8.0)\r\n  \u2022 Installing threadpoolctl (2.1.0)\r\n  \u2022 Installing werkzeug (1.0.1)\r\n  \u2022 Installing affine (2.3.0)\r\n  \u2022 Installing alabaster (0.7.12)\r\n  \u2022 Installing appdirs (1.4.4)\r\n  \u2022 Installing astunparse (1.6.3)\r\n  \u2022 Installing babel (2.9.1): Installing...\r\n  \u2022 Installing cycler (0.10.0)\r\n  \u2022 Installing docutils (0.16): Installing...\r\n  \u2022 Installing fiona (1.8.19): Installing...\r\n  \u2022 Installing flatbuffers (1.12)\r\n  \u2022 Installing gast (0.3.3)\r\n  \u2022 Installing google-pasta (0.2.0)\r\n  \u2022 Installing h5py (2.10.0): Installing...\r\n  \u2022 Installing imagesize (1.2.0)\r\n  \u2022 Installing imagesize (1.2.0)\r\n  \u2022 Installing h5py (2.10.0)\r\n  \u2022 Installing imagesize (1.2.0)\r\n  \u2022 Installing iniconfig (1.1.1)\r\n  \u2022 Installing flatbuffers (1.12)\r\n  \u2022 Installing gast (0.3.3)\r\n  \u2022 Installing google-pasta (0.2.0)\r\n  \u2022 Installing h5py (2.10.0)\r\n  \u2022 Installing imagesize (1.2.0)\r\n  \u2022 Installing iniconfig (1.1.1)\r\n  \u2022 Installing fiona (1.8.19)\r\n  \u2022 Installing flatbuffers (1.12)\r\n  \u2022 Installing gast (0.3.3)\r\n  \u2022 Installing google-pasta (0.2.0)\r\n  \u2022 Installing h5py (2.10.0)\r\n  \u2022 Installing imagesize (1.2.0)\r\n  \u2022 Installing iniconfig (1.1.1)\r\n  \u2022 Installing cycler (0.10.0)\r\n  \u2022 Installing docutils (0.16): Installing...\r\n  \u2022 Installing fiona (1.8.19)\r\n  \u2022 Installing flatbuffers (1.12)\r\n  \u2022 Installing gast (0.3.3)\r\n  \u2022 Installing google-pasta (0.2.0)\r\n  \u2022 Installing h5py (2.10.0)\r\n  \u2022 Installing imagesize (1.2.0)\r\n  \u2022 Installing iniconfig (1.1.1)\r\n  \u2022 Installing babel (2.9.1)\r\n  \u2022 Installing cycler (0.10.0)\r\n  \u2022 Installing docutils (0.16): Installing...\r\n  \u2022 Installing fiona (1.8.19)\r\n  \u2022 Installing flatbuffers (1.12)\r\n  \u2022 Installing gast (0.3.3)\r\n  \u2022 Installing google-pasta (0.2.0)\r\n  \u2022 Installing h5py (2.10.0)\r\n  \u2022 Installing imagesize (1.2.0)\r\n  \u2022 Installing iniconfig (1.1.1)\r\n  \u2022 Installing fiona (1.8.19)\r\n  \u2022 Installing flatbuffers (1.12)\r\n  \u2022 Installing gast (0.3.3)\r\n  \u2022 Installing google-pasta (0.2.0)\r\n  \u2022 Installing h5py (2.10.0)\r\n  \u2022 Installing imagesize (1.2.0)\r\n  \u2022 Installing iniconfig (1.1.1)\r\n  \u2022 Installing docutils (0.16)\r\n  \u2022 Installing fiona (1.8.19)\r\n  \u2022 Installing flatbuffers (1.12)\r\n  \u2022 Installing gast (0.3.3)\r\n  \u2022 Installing google-pasta (0.2.0)\r\n  \u2022 Installing h5py (2.10.0)\r\n  \u2022 Installing imagesize (1.2.0)\r\n  \u2022 Installing iniconfig (1.1.1)\r\n  \u2022 Installing jinja2 (2.11.3)\r\n  \u2022 Installing keras-preprocessing (1.1.2)\r\n  \u2022 Installing kiwisolver (1.3.1)\r\n  \u2022 Installing mypy-extensions (0.4.3)\r\n  \u2022 Installing opt-einsum (3.3.0)\r\n  \u2022 Installing packaging (20.9)\r\n  \u2022 Installing pandas (1.2.4): Installing...\r\n  \u2022 Installing pandas (1.2.4)\r\n  \u2022 Installing pathspec (0.8.1)\r\n  \u2022 Installing pillow (8.2.0)\r\n  \u2022 Installing pluggy (0.13.1)\r\n  \u2022 Installing py (1.10.0)\r\n  \u2022 Installing pygments (2.9.0)\r\n  \u2022 Installing pyproj (3.0.1)\r\n  \u2022 Installing regex (2021.4.4)\r\n  \u2022 Installing scikit-learn (0.24.2)\r\n  \u2022 Installing snowballstemmer (2.1.0)\r\n  \u2022 Installing shapely (1.7.1)\r\n  \u2022 Installing snuggs (1.4.7)\r\n  \u2022 Installing sphinxcontrib-applehelp (1.0.2)\r\n  \u2022 Installing sphinxcontrib-devhelp (1.0.2)\r\n  \u2022 Installing sphinxcontrib-htmlhelp (1.0.3)\r\n  \u2022 Installing sphinxcontrib-jsmath (1.0.1)\r\n  \u2022 Installing sphinxcontrib-qthelp (1.0.3)\r\n  \u2022 Installing tensorboard (2.5.0)\r\n  \u2022 Installing tensorflow-estimator (2.4.0)\r\n  \u2022 Installing sphinxcontrib-serializinghtml (1.1.4)\r\n  \u2022 Installing termcolor (1.1.0)\r\n  \u2022 Installing toml (0.10.2)\r\n  \u2022 Installing typing-extensions (3.7.4.3)\r\n  \u2022 Installing wrapt (1.12.1)\r\n  \u2022 Installing black (21.5b0)\r\n  \u2022 Installing geopandas (0.9.0)\r\n  \u2022 Installing matplotlib (3.4.1)\r\n  \u2022 Installing pytest (6.2.4)\r\n  \u2022 Installing rasterio (1.2.3)\r\n```\r\n\r\n</details>\r\n\r\n```console\r\n  \u2022 Installing sklearn (0.0)\r\n  \u2022 Installing sphinx (3.5.4)\r\n  \u2022 Installing tensorflow (2.4.1)\r\n\r\nInstalling the current project: poetry_demo (0.1.0)\r\n(base) lukas@Makushin:~/Desktop/poetry-demo$ poetry run python\r\nPython 3.8.8 (default, Apr 13 2021, 19:58:26) \r\n[GCC 7.3.0] :: Anaconda, Inc. on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\n2021-05-06 17:51:27.535624: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\r\n2021-05-06 17:51:27.535643: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\r\n>>> tf.config.list_physical_devices()\r\n2021-05-06 17:51:57.675020: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2021-05-06 17:51:57.675844: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\r\n2021-05-06 17:51:57.701899: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2021-05-06 17:51:57.702606: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \r\npciBusID: 0000:2d:00.0 name: NVIDIA GeForce RTX 2080 computeCapability: 7.5\r\ncoreClock: 1.725GHz coreCount: 46 deviceMemorySize: 7.77GiB deviceMemoryBandwidth: 417.23GiB/s\r\n2021-05-06 17:51:57.702710: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\r\n2021-05-06 17:51:57.702793: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\r\n2021-05-06 17:51:57.702866: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\r\n2021-05-06 17:51:57.704592: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\r\n2021-05-06 17:51:57.704887: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\r\n2021-05-06 17:51:57.706566: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\r\n2021-05-06 17:51:57.706678: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\r\n2021-05-06 17:51:57.706759: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\r\n2021-05-06 17:51:57.706778: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\r\nSkipping registering GPU devices...\r\n[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\r\n>>> \r\n\r\n```\r\n\r\n\r\n**Any other info / logs**\r\nAnother way I tried was to install Tensorflow into a fresh Anaconda environment using `conda create --name tf_gpu tensorflow-gpu`. That way the GPU was listed in `tf.config.list_physical_devices()`. However I would like to avoid Anaconda if posibble because it has other, unrelated drawbacks.\r\n", "comments": ["I solved this by combining environment management from Anaconda and Poetry like so:\r\n\r\n```console\r\npoetry update\r\npoetry run conda create -y --name tf_gpu tensorflow-gpu\r\npoetry run conda activate tf_gpu\r\npoetry run python\r\n```\r\n\r\nThen the GPU was recognized.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48939\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48939\">No</a>\n", "@joooeey  How is this closed? that's a clear workaround rather than a solution", "@thoughtfuldata I'm happy with this workaround but you're right, Poetry should be able to handle this on its own.", "Hi @joooeey ! \r\nWe are checking to see whether you still need help in this issue . Have you tried same after installing Cuda tool kit separately? Attaching a [thread ](https://towardsdatascience.com/installing-tensorflow-with-cuda-cudnn-and-gpu-support-on-windows-10-60693e46e781)as a reference to installation of Cuda tool kit. Thank you!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48939\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48939\">No</a>\n", "> Hi @joooeey ! We are checking to see whether you still need help in this issue . Have you tried same after installing Cuda tool kit separately? Attaching a [thread ](https://towardsdatascience.com/installing-tensorflow-with-cuda-cudnn-and-gpu-support-on-windows-10-60693e46e781)as a reference to installation of Cuda tool kit. Thank you!\r\n\r\nThat would not be a practical solution as installing the Cuda toolkit separately is more effort than installing `tensorflow-gpu` with conda. I guess combining conda and Poetry is the way to go as long as Poetry can't install the Cuda toolkit for us. If I remember correctly, the advantage of using conda is that it takes care of installing the Cuda toolkit."]}, {"number": 48938, "title": "Issue tensorflow#33840 in tf.image.ssim_multiscale", "body": "Fix for issue [tensorflow#33840](https://github.com/tensorflow/tensorflow/issues/33840) on tf.image.ssim_multiscale. #33840 ", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F48938) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "The issue (https://github.com/tensorflow/tensorflow/issues/33840) was reportedly fixed in the 2.5 release.  \r\n\r\nI think we can abandon this pull request then -- but just let us know otherwise. Thanks!", "@aakash30jan Can you please check @jsmeredith's comments and keep us posted ? Thanks!", "@gbaned @jsmeredith, I just checked the gist mentioned by @sachinprasadhs in the issue ([#33840](https://github.com/tensorflow/tensorflow/issues/33840#issuecomment-845018896)) . The issue was reported to be closed based on this wrong gist. The issue still persists in Tensorflow 2.5,  [here](https://colab.research.google.com/gist/aakash30jan/7add0e61ea973844360cf569bf8dcffc/issue_33840.ipynb) is a proper gist to replicate the issue from what OP @AravindGanesh had mentioned.  ", "@jsmeredith  Can you please take a look on above comments from @aakash30jan. Thanks!", "@jsmeredith @gbaned The issue was re-opened by @sachinprasadhs a few weeks ago. The problem still persists with TF v2.5 as confirmed by a [recent ](https://github.com/tensorflow/tensorflow/issues/33840#issuecomment-887361360) comment on the issue.", "Acknowledged -- looks like I have some notifications yet to set up.  Thanks so much for pinging again, I'll take a look!", "Hi!  I see some tests failing with this change, would you be able to fix those and update the CL?   (And double-check things like formatting, if it's possible to add a test which targets this fix, etc.)  Thanks!", "@aakash30jan Can you please check @jsmeredith's comments and keep us posted ? Thanks!", "@aakash30jan Any update on this PR? Please. Thanks!"]}]