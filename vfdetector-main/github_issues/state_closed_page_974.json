[{"number": 24194, "title": "R1.12", "body": "    When I was interested in running TfLite on Rapeberry Pi for embedded system or IoT, I was hungry for finding guide to build apps, after which I could exert my energy. With googling, I noticed that many developers met the same bottleneck. Now, I created the \"pull request\" in order to contribute community 2 TfLite apps that are able to run at Raspberry Pi 3. Here are the steps to build/run the apps.\r\n\r\n    1, Follow https://www.raspberrypi.org/learning/software-guide/quickstart/, to install Raspbian onto a Raspberry Pi 3 board. \r\n    #sudo apt install build-essential\r\n    Follow https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/pi_examples to install camera. \r\n    Verify if the camera works or not:\r\n    #raspistill -v\r\n\r\n    2, git clone -b r1.12 https://github.com/huaxiaozhong1/tensorflow.git. (The best, this is done within the latest docker container of Ubuntu 18.04).\r\n    It will clone 6 static libraries into /tensorflow/tensorflow/contrib/lite/examples/camera/libs:\r\n    libjpeg.a librt.a libv4l1.a libv4l2.a libv4l2rds.a libv4lconvert.a.\r\n    Actually they are from Pi environment prepared at step 1:\r\n\r\n    3, In the container of host: \r\n    #apt update\r\n    #apt upgrade\r\n    #apt install crossbuild-essential-armhf\r\n    #cd /tensorflow\r\n    #./tensorflow/contrib/lite/tools/make/download_dependencies.sh\r\n    #apt install -y libjpeg-dev\r\n    #apt install libv4l-dev\r\n    #./tensorflow/contrib/lite/tools/make/build_rpi_lib.sh\r\n    Now, you could find ./tensorflow/contrib/lite/tools/make/gen/rpi_armv7l/lib/libtensorflow-lite.a, /tensorflow/tensorflow/contrib/lite/tools/make/gen/rpi_armv7l/bin/label_image and /tensorflow/tensorflow/contrib/lite/tools/make/gen/rpi_armv7l/bin/camera. \r\n\r\n    4, Copy label_image and camera, the Linux executables, to Raspeberry board. \r\n    Copy grace_hopper.bmp from /tensorflow/tensorflow/contrib/lite/examples/label_image/testdata of host\u2019s container to the board.\r\n    Copy labels.txt from /tensorflow/tensorflow/contrib/lite/java/ovic/src/testdata of host\u2019s container to the board.\r\n    Download Mobilenet_v2_1.0_224_quant.tflite from https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/models.md to the board.\r\n    The 3 data files and 2 Linux executables should be inside the same folder.\r\n\r\n    5, Run the 2 apps one by one. \r\n\r\n    Note: the base branch that I added the 2 apps into is r1.12. Now TfLite has been announced to move out of contrib. But when I ran build_rpi_lib.sh in the latest tensorflow/tensorflow:nightly-devel, it didn\u2019t get success. So, may I submit the pull-request based at r1.12 right now? I could add the same feature on r1.13+ as soon as it succeeds in building libtensorflow-lite.a.\r\n\r\n    Thank you so much, and looking forward to hearing from you,\r\n\r\n                                                     Xiaozhong(Jim) Hua\r\n\r\n", "comments": ["Having updated to v0.16 with files changed:\r\n./tensorflow/contrib/lite/tools/make/Makefile,\r\n./tensorflow/contrib/lite/tools/make/build_rpi_lib.sh.\r\nWith the update, a new environment variable, TfLite_RPI_APPS, is added. It could be set in build_rpi_lib.sh. If it is not set as true, the 2 apps won't be generated. The building process won't be blocked on that case. \r\nPlease don't hesitate to let me know if more tests are needed, or more consideration needs to be taken into.\r\nThanks,\r\n--Jim", "Nagging Reviewer @petewarden: You have been added as a reviewer to this pull request. Please add your review or reassign. It has been 41 days with no activity and the `awaiting review` label has been applied.", "Unfortunately we can't take binary files (like .a libs) into the repository. I'd be happy to add documentation links to point to your example if you wanted to host it as a standalone github project though? Thanks for this, and sorry for the delay in responding."]}, {"number": 24193, "title": "#21745: set timeout for closing worker session", "body": "#21745: set timeout for closing worker session", "comments": ["Transferring this PR to @saeta, since it affects things he is interested in, and I'm not going to have time to look at it.", "This has been reverted in 148047be4e1b8ca9968cadd10bc56dc627f17f62. Anything broken by this?\r\n\r\nPing @saeta ", "@saeta +1, why this patch is reverted?", "The patch was causing segfaults, I think because of a use-after-free bug: the callbacks would still be called after the function returned, accessing the stack-allocated `workers` vector."]}, {"number": 24192, "title": "Add tf.metrics.std or tf.metrics.var", "body": "**System information**\r\n- TensorFlow version (you are using): 1.12\r\n- Are you willing to contribute it (Yes/No): Maybe, it depends on the complexity\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nCurrently the module tf.metrics does not contain tf.metrics.std or tf.metrics.var for the calculation of standard deviation and variance over multiple batches, respectively. It would be very useful to have these type of metrics.\r\n\r\n**Will this change the current api? How?**\r\nThis will change the current api by adding two more apis: tf.metrics.std  and  tf.metrics.var\r\n\r\n**Who will benefit with this feature?**\r\nEveryone who wants to calculate statistics over multiple batches.\r\n\r\n**Any Other info.**\r\nCurrently it is possible to use tf.nn.moments and perform some basic math in order to calculate the std over multiple batches. However tf.metrics is a simple way to obtain the same result.", "comments": ["You can use [tf.nn.moments](https://www.tensorflow.org/api_docs/python/tf/nn/moments) to calculate variance and mean.", "As I said, it is possible to use tf.nn.moments but it calculates the mean and the variance only for a batch and it does not consider multiple batches. Tf.metrics provides a standard way to calculate metrics over multiple batches but tf.metrics.var is not present.", "> **System information**\r\n> \r\n> * TensorFlow version (you are using): 1.12\r\n> * Are you willing to contribute it (Yes/No): Maybe, it depends on the complexity\r\n> \r\n> **Describe the feature and the current behavior/state.**\r\n> Currently the module tf.metrics does not contain tf.metrics.std or tf.metrics.var for the calculation of standard deviation and variance over multiple batches, respectively. It would be very useful to have these type of metrics.\r\n> \r\n> **Will this change the current api? How?**\r\n> This will change the current api by adding two more apis: tf.metrics.std and tf.metrics.var\r\n> \r\n> **Who will benefit with this feature?**\r\n> Everyone who wants to calculate statistics over multiple batches.\r\n> \r\n> **Any Other info.**\r\n> Currently it is possible to use tf.nn.moments and perform some basic math in order to calculate the std over multiple batches. However tf.metrics is a simple way to obtain the same result.\r\n\r\nI have a idea: It is possible to use tf.metric.mean(tensor^2) calculate the average of square,  and use tf.metric.mean(tensor) to calculate the average. \r\nThen you can use the other form of variance:\r\nvar(X) =1/N *[ (x1- avg)^2+(x2-avg)^2+...+(xn-avg)^2]\r\n           =1/N *[ (x1^2 - 2*x1*avg+ avg^2) + (x2^2 - 2*x2*avg+ avg^2) +...+(xn^2 - 2*xn*avg+ avg^2) ]\r\n           = 1/N *[(x1^2 + x2^2 + ... + xn^2) - 2 *(x1+x2+...+xn)*avg + N * avg^2]\r\n           = 1/N *[(x1^2 + x2^2 + ... + xn^2)  - 2 * N * avg *avg + N*avg^2]\r\n           =1/N *[(x1^2 + x2^2 + ... + xn^2)  -  N*avg^2]\r\n           =1/N *(x1^2 + x2^2 + ... + xn^2) - avg^2", "@EmanueleGhelfi,\r\nThe solution mentioned in [this comment](https://github.com/tensorflow/tensorflow/issues/24192#issuecomment-565336012) can be implemented either in the [**`on_epoch_begin`**](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/Callback#on_epoch_begin) or in the [**`on_epoch_end`**](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/Callback#on_epoch_end) function of [Custom Callback](https://www.tensorflow.org/guide/keras/custom_callback#usage_of_logs_dict).\r\n\r\nOr you can use [Custom Metrics](https://www.tensorflow.org/guide/keras/train_and_evaluate#custom_metrics) to design the **`metrics`** of your choice.\r\n\r\nThanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 24191, "title": "tensorflow for golang did not use GPU to speed up", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n```\r\npackage main\r\n\r\nimport (\r\n\t\"flag\"\r\n\t\"fmt\"\r\n\t\"time\"\r\n\r\n\ttf \"github.com/tensorflow/tensorflow/tensorflow/go\"\r\n\t\"github.com/tensorflow/tensorflow/tensorflow/go/op\"\r\n)\r\n\r\nfunc main() {\r\n        fmt.Println(tf.Version())\r\n\ttotal := flag.Int(\"total\", 10000, \"\")\r\n\tbatch := flag.Int(\"batch\", 1000, \"\")\r\n\tflag.Parse()\r\n\r\n\tconst inerSize = 10000\r\n\troot := op.NewScope()\r\n\tA := op.Placeholder(root.SubScope(\"input\"), tf.Int32, op.PlaceholderShape(tf.MakeShape(-1, inerSize)))\r\n\tx := op.Placeholder(root.SubScope(\"input\"), tf.Int32, op.PlaceholderShape(tf.MakeShape(inerSize, 1)))\r\n\tproduct := op.MatMul(root, A, x)\r\n\r\n\tgraph, err := root.Finalize()\r\n\tif err != nil {\r\n\t\tpanic(err.Error())\r\n\t}\r\n\r\n\tvar sess *tf.Session\r\n\tsess, err = tf.NewSession(graph, &tf.SessionOptions{})\r\n\tif err != nil {\r\n\t\tpanic(err.Error())\r\n\t}\r\n\r\n\tmatrix := make([][inerSize]int32, *total)\r\n\tcolumn := [inerSize][1]int32{}\r\n\r\n\ttx, _ := tf.NewTensor(column)\r\n\r\n\tt1 := time.Now()\r\n\tfor i := 0; i*(*batch) < *total; i++ {\r\n\t\tstart, end := i*(*batch), (i+1)*(*batch)\r\n\t\tif end > *total {\r\n\t\t\tend = *total\r\n\t\t}\r\n\t\ttA, _ := tf.NewTensor(matrix[start:end])\r\n\t\t_, err = sess.Run(\r\n\t\t\tmap[tf.Output]*tf.Tensor{A: tA, x: tx},\r\n\t\t\t[]tf.Output{product},\r\n\t\t\tnil,\r\n\t\t)\r\n\t\tif err != nil {\r\n\t\t\tpanic(err.Error())\r\n\t\t}\r\n\t}\r\n\r\n\tfmt.Println(\"cost:\", time.Since(t1))\r\n}\r\n```\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nUbuntu 16.04.5 LTS\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\nbinary\r\n- TensorFlow version (use command below):\r\n1.5.0\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\ncuda-9.2\r\ncudnn-7.2.1\r\n- GPU model and memory:\r\nGeForce GTX 1080 Ti 11GB\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n**Describe the current behavior**\r\nsession Run cost 4s on GPU:\r\n```\r\n2018-12-06 17:03:14.781911: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX\r\n2018-12-06 17:03:14.985388: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:895] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2018-12-06 17:03:14.985940: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105] Found device 0 with properties: \r\nname: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.62\r\npciBusID: 0000:83:00.0\r\ntotalMemory: 10.92GiB freeMemory: 10.61GiB\r\n2018-12-06 17:03:14.985972: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:83:00.0, compute capability: 6.1)\r\ncost: 4.133031516s\r\n```\r\nsession Run cost 4s on CPU:\r\n```\r\n2018-12-06 17:03:30.681019: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX\r\ncost: 4.23027643s\r\n```\r\n\r\n**Describe the expected behavior**\r\nrunning on GPU should be much faster than on CPU\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n```\r\n1, Download tensorflow binary of both CPU and GPU version\r\n2, Set LD_LIBRARY_PATH to /tensorflow-cpu/lib and run the above golang code\r\n3, Set LD_LIBRARY_PATH to /tensorflow-gpu/lib and run the above golang code\r\n``` \r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": []}, {"number": 24190, "title": "Cannot convert between a TensorFlowLite buffer with 1072812 bytes and a ByteBuffer with 270000 bytes.", "body": "**Train model:**\r\n`python3 /Users/tianchuangxin1/hub/examples/image_retraining/retrain.py     \r\n--image_dir /Users/tianchuangxin1/tensorflow_image    \r\n--how_many_training_steps=2000   \r\n----model_dir=/Users/tianchuangxin1/tensorflow_image  \r\n--output_graph  /Users/tianchuangxin1/tensorflow_image/output_graph.pb  \r\n--output_labels /Users/tianchuangxin1/tensorflow_image/output_labels.txt `\r\n**Test model:**\r\n`python3 /Users/tianchuangxin1/tensorflow/tensorflow/examples/label_image/label_image.py \\\r\n--graph=/Users/tianchuangxin1/tensorflow_image/output_graph.pb --labels=/Users/tianchuangxin1/tensorflow_image/output_labels.txt \\\r\n--input_layer=Placeholder \\\r\n--output_layer=final_result \\\r\n--image=/Users/tianchuangxin1/tensorflow_image/apple/apple5.jpg\r\n`\r\n**Get the result:**\r\n`2018-12-06 15:16:48.733220: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\napple 0.99963677\r\nwatch 0.0003632232`\r\n\r\n**Turn to tflite format:**\r\n`tflite_convert \\\r\n  --graph_def_file=/Users/tianchuangxin1/tensorflow_image/output_graph.pb \\\r\n  --output_file=/Users/tianchuangxin1/tensorflow_image/output_graph.tflite \\\r\n  --output_format=TFLITE \\\r\n  --input_shape=1,299,299,3 \\\r\n  --input_array=Placeholder \\\r\n  --output_array=final_result \\\r\n  --inference_type=FLOAT \\\r\n  --input_data_type=FLOAT `\r\n\r\n**All above have none error.**\r\n\r\n**But, i got the crash on Android device:**\r\n\r\n`java.lang.IllegalArgumentException: Cannot convert between a TensorFlowLite buffer with 1072812 bytes and a ByteBuffer with 270000 bytes.\r\n        at org.tensorflow.lite.Tensor.throwExceptionIfTypeIsIncompatible(Tensor.java:221)\r\n        at org.tensorflow.lite.Tensor.setTo(Tensor.java:93)\r\n        at org.tensorflow.lite.NativeInterpreterWrapper.run(NativeInterpreterWrapper.java:141)\r\n        at org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:229)\r\n        at org.tensorflow.demo.TFLiteObjectDetectionAPIModel.recognizeImage(TFLiteObjectDetectionAPIModel.java:194)\r\n        at org.tensorflow.demo.DetectorActivity$3.run(DetectorActivity.java:249)\r\n        at android.os.Handler.handleCallback(Handler.java:751)\r\n        at android.os.Handler.dispatchMessage(Handler.java:95)\r\n        at android.os.Looper.loop(Looper.java:159)\r\n        at android.os.HandlerThread.run(HandlerThread.java:61)\r\n`\r\n\r\n**Which step wrong , i have no idea! And spend for a long time!!!!**\r\n\r\n\r\n", "comments": ["**Aha, I changer the  --input_shape=1,299,299,3  to --input_shape=1,300,300,3 ,the error gone!  But I i got another question:**\r\n\r\n`java.lang.IllegalArgumentException: Cannot copy between a TensorFlowLite tensor with shape [1, 2] and a Java object with shape [1, 10, 4].\r\n        at org.tensorflow.lite.Tensor.throwExceptionIfTypeIsIncompatible(Tensor.java:240)\r\n        at org.tensorflow.lite.Tensor.copyTo(Tensor.java:116)\r\n        at org.tensorflow.lite.NativeInterpreterWrapper.run(NativeInterpreterWrapper.java:157)\r\n        at org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:229)\r\n        at com.jd.tianchuangxin1.tensorflow_android_demo.TFLiteObjectDetectionAPIModel.recognizeImage(TFLiteObjectDetectionAPIModel.java:198)\r\n        at com.jd.tianchuangxin1.tensorflow_android_demo.DetectorActivity$3.run(DetectorActivity.java:250)\r\n        at android.os.Handler.handleCallback(Handler.java:751)\r\n        at android.os.Handler.dispatchMessage(Handler.java:95)\r\n        at android.os.Looper.loop(Looper.java:159)\r\n        at android.os.HandlerThread.run(HandlerThread.java:61)`\r\n\r\n\r\nI do not know what meaning of  `Java object with shape [1, 10, 4]` anyone can help me ?", "@T-chuangxin  Can you please take a look at #23940 ? Please keep us posted if it doesn't help. Thanks !", "Closing this as it is in \"awaiting response\" status for more than 7 days. Feel free to add your comments and we will reopen(if required).", "Try to set the QUANT as FALSE and give a try & Instead of using byte[][] use the Float[][] in your Classifier class. I had a similar issue and its fixed now.\r\ni.e;\r\n    private static final boolean QUANT = false;\r\n                                   &\r\n    float[][] result = new float[1][labelList.size()];\r\n    interpreter.run(byteBuffer, result);\r\n    return getSortedResultFloat(result);\r\n\r\nThe input type is INT32 so its multiplied with 4.\r\nbyteBuffer = ByteBuffer.allocateDirect(4 * BATCH_SIZE * inputSize * inputSize * PIXEL_SIZE);", "I try all the above steps but not working  \r\njava.lang.IllegalArgumentException: Cannot convert between a TensorFlowLite buffer with 3136 bytes and a Java Buffer with 9408 bytes.\r\n![image](https://user-images.githubusercontent.com/37452506/74107330-a1cc8680-4b94-11ea-86d2-30c186816dbb.png)\r\nI have  changed the model , labels and input size ...\r\n@T-chuangxin @AkshaykumarA @Harshini-Gadige @lmoroney \r\n\r\n", "I know I'm late to the party but this might help someone.\r\n\r\nI was getting the same error while trying to implement tflite's objects detection model into another java android app. \r\nI was going wrong by setting ByteBuffer imgData to 300*300 when the model was expecting an image of 300x300 pixels.  \r\nIt should have been set to just 300.\r\n\r\nThe same thing can probably be said about other tflite models that take images as input.\r\n\r\nFind more related info at https://www.tensorflow.org/lite/models/object_detection/overview", "@physine \r\n\r\nI didn't get what are you trying to say.\r\nI have attached a screenshot. Please tell me what to change here.\r\n\r\n![err](https://user-images.githubusercontent.com/42910418/87653102-ae23c380-c772-11ea-9619-02de418954b4.jpg)\r\n", "I have same error, please help me\r\nError\r\nCannot copy to a TensorFlowLite tensor (image_tensor) with 270000 bytes from a Java Buffer with 1080000 bytes.\r\n        at org.tensorflow.lite.Tensor.throwIfSrcShapeIsIncompatible(Tensor.java:423)\r\n        at org.tensorflow.lite.Tensor.setTo(Tensor.java:189)\r\n        at org.tensorflow.lite.NativeInterpreterWrapper.run(NativeInterpreterWrapper.java:154)\r\n        at org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:343)\r\n        at org.tensorflow.lite.examples.detection.tflite.TFLiteObjectDetectionAPIModel.recognizeImage(TFLiteObjectDetectionAPIModel.java:196)\r\n        at org.tensorflow.lite.examples.detection.DetectorActivity$2.run(DetectorActivity.java:181)\r\n        at android.os.Handler.handleCallback(Handler.java:790)\r\n        at android.os.Handler.dispatchMessage(Handler.java:99)\r\n        at android.os.Looper.loop(Looper.java:164)\r\n        at android.os.HandlerThread.run(HandlerThread.java:65)", "> I have same error, please help me\r\n> Error\r\n> Cannot copy to a TensorFlowLite tensor (image_tensor) with 270000 bytes from a Java Buffer with 1080000 bytes.\r\n> at org.tensorflow.lite.Tensor.throwIfSrcShapeIsIncompatible(Tensor.java:423)\r\n> at org.tensorflow.lite.Tensor.setTo(Tensor.java:189)\r\n> at org.tensorflow.lite.NativeInterpreterWrapper.run(NativeInterpreterWrapper.java:154)\r\n> at org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:343)\r\n> at org.tensorflow.lite.examples.detection.tflite.TFLiteObjectDetectionAPIModel.recognizeImage(TFLiteObjectDetectionAPIModel.java:196)\r\n> at org.tensorflow.lite.examples.detection.DetectorActivity$2.run(DetectorActivity.java:181)\r\n> at android.os.Handler.handleCallback(Handler.java:790)\r\n> at android.os.Handler.dispatchMessage(Handler.java:99)\r\n> at android.os.Looper.loop(Looper.java:164)\r\n> at android.os.HandlerThread.run(HandlerThread.java:65)\r\n\r\nTry to set the QUANT as FALSE and give a try & Instead of using byte[][] use the Float[][] in your Classifier class.", "@AkshaykumarA \r\ntflite's object detection model is quantized so you need to keep it as true.\r\nread this , specifically the part about input, I might help. https://www.tensorflow.org/lite/models/object_detection/overview\r\n\r\n@aryanjain28 \r\nthat image doesn't help.  What are you trying to do?  Are you trying to add tflite functionallity from scratch into another app or what?\r\nWhat is the value you [imgData ](https://github.com/tensorflow/examples/blob/1f1ff5b2807ba5f2beccf362aef79332d7cc6216/lite/examples/object_detection/android/app/src/main/java/org/tensorflow/lite/examples/detection/tflite/TFLiteObjectDetectionAPIModel.java#L78)at run time?  \r\n\r\nDo this and see if it works.\r\nprivate ByteBuffer imgData = 300;", "@physine private ByteBuffer imgData = 300 ;\r\nrequired java.nio.ByteBuffer", "i got same error\r\ni have model with this  step\r\nhttps://colab.research.google.com/github/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/tutorials/model_maker_image_classification.ipynb\r\n\r\nwhat should i do for clear the error \"\r\n```\r\n    java.lang.IllegalArgumentException: Cannot copy to a TensorFlowLite tensor (input_2) with 602112 bytes from a Java Buffer with 270000 bytes.\r\n        at org.tensorflow.lite.Tensor.throwIfSrcShapeIsIncompatible(Tensor.java:444)\r\n        at org.tensorflow.lite.Tensor.setTo(Tensor.java:189)\r\n        at org.tensorflow.lite.NativeInterpreterWrapper.run(NativeInterpreterWrapper.java:154)\r\n        at org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:347)\r\n        at org.tensorflow.lite.examples.detection.tflite.TFLiteObjectDetectionAPIModel.recognizeImage(TFLiteObjectDetectionAPIModel.java:196)\r\n        at org.tensorflow.lite.examples.detection.DetectorActivity$2.run(DetectorActivity.java:181)\r\n```", "Not too sure if it helps, but I managed to solve the issue (thanks to all your hints) by changing the parameter in the DetectorActivity.java\r\n\r\n1) private static final int TF_OD_API_INPUT_SIZE = 320; (from 300 to 320 as it was the parameter of the model)\r\n2) private static final boolean TF_OD_API_IS_QUANTIZED = false; (from true to false)\r\n\r\nI have also made the following changes:\r\n-Change line 122 from to 132 with the below code on TFLiteObjectDetectionAPIModel.java there are two files in this same name open the interpreter one and not the task one.\r\npress alt+enter to resove error on InputStream then save it\r\n\r\n```\r\n    AssetManager am = context.getAssets();\r\n    try (InputStream is = am.open(labelFilename);\r\n         BufferedReader br = new BufferedReader(new InputStreamReader(is))) {\r\n      String line;\r\n      while ((line = br.readLine()) != null) {\r\n        Log.w(TAG, line); d.labels.add(line);\r\n      }\r\n    }\r\n```\r\nfollowing the tutorial by https://www.youtube.com/watch?v=syTKGY-H44E&t=366s (although I am not too sure how it affect the app to run)\r\n\r\nI build the model using tensor flow 2 instead of tensor flow 1.\r\n"]}, {"number": 24189, "title": "Fix typos", "body": "that that -> that\r\n\r\nsucessful -> successful\r\n\r\nrequrires -> requires", "comments": []}, {"number": 24188, "title": "LSTM's .h5 to .tflite", "body": "thanks for your reading.\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):source\r\n- TensorFlow version (use command below):1.12.0\r\n- Python version:3.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n**Describe the problem**\r\n1.used the tf.keras to train the LSTM's model, and get the model.h5 file.\r\n2.want convert the .h5 file to .tflite file ,and coded:\r\n```\r\nconverter = tf.lite.TFLiteConverter.from_keras_model_file(\"model.h5\")\r\ntflite_model = converter.convert()\r\nopen(\"_model.tflite\", \"wb\").write(tflite_model)\r\n```\r\nand get the error:\r\n```\r\nWARNING:tensorflow:From D:\\python\\python3\\lib\\site-packages\\tensorflow\\python\\framework\\graph_util_impl.py:245: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse tf.compat.v1.graph_util.extract_sub_graph\r\nTraceback (most recent call last):\r\n  File \"D:/code/load_forecast/test/test1.py\", line 5, in <module>\r\n    tflite_model = converter.convert()\r\n  File \"D:\\python\\python3\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py\", line 456, in convert\r\n    **converter_kwargs)\r\n  File \"D:\\python\\python3\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py\", line 397, in toco_convert_impl\r\n    input_data.SerializeToString())\r\n  File \"D:\\python\\python3\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py\", line 172, in toco_convert_protos\r\n    \"TOCO failed. See console for info.\\n%s\\n%s\\n\" % (stdout, stderr))\r\ntensorflow.lite.python.convert.ConverterError: TOCO failed. See console for info.\r\n2018-12-06 13:41:26.456495: I tensorflow/lite/toco/import_tensorflow.cc:1280] Converting unsupported operation: TensorArrayV3\r\n.........\r\n2018-12-06 13:41:26.495220: I tensorflow/lite/toco/import_tensorflow.cc:1329] Unable to determine output type for op: TensorArrayGatherV3\r\n2018-12-06 13:41:26.506452: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 120 operators, 212 arrays (0 quantized)\r\n2018-12-06 13:41:26.508258: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 120 operators, 212 arrays (0 quantized)\r\n2018-12-06 13:41:26.513681: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 106 operators, 194 arrays (0 quantized)\r\n2018-12-06 13:41:26.515613: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 106 operators, 194 arrays (0 quantized)\r\n2018-12-06 13:41:26.517624: F tensorflow/lite/toco/tooling_util.cc:625] Check failed: dim >= 1 (0 vs. 1)\r\n```\r\n3.but success to convert the linear's and cnn's .h5 file to .tflite \r\n\r\nwant to ask the question: Did someone successfully transform the .h5 model to .tflite?\r\n\r\nlook forward to your answer.", "comments": ["How about adding the line:\r\n\r\n```python\r\nconverter.allow_custom_ops=True\r\n```", "> How about adding the line:\r\n> \r\n> ```python\r\n> converter.allow_custom_ops=True\r\n> ```\r\n\r\nget the same error...@t-kuha", "Same problem here @JamesZhangjp  . Trying to convert a CRNN using LSTM layers .h5 model (saved with keras) to .tflite and also getting \r\n`F tensorflow/lite/toco/tooling_util.cc:627] Check failed: dim >= 1 (0 vs. 1)`\r\n\r\nAny suggestion yet ?", "Hi everyone,\r\n\r\nA quick search and I guess I found the reason of this error. The LSTM layer is not yet supported for custom models \r\nhttps://www.tensorflow.org/lite/tf_ops_compatibility\r\nbottom of the page.", "@AntoineWeber tk, I have asked some people to give me the same reply before, but I hope to support LSTM as soon as possible.", "@AntoineWeber , to be precise, it is tf.tanh not supported or LSTM, you can use it but need to fall back on Linear? Is my understanding correct?", "> @AntoineWeber , to be precise, it is tf.tanh not supported or LSTM, you can use it but need to fall back on Linear? Is my understanding correct?\r\n\r\nany updates on which part isn't supported?", "@nparikhsfn \r\nI don't understand what you mean by linear case. But I guess you could reimplement yourself an lstm layer trying to dodge the use of tanh layers. GRU is not listed on this list (?) and it also contains tanh.\r\nHaven't retried since then to convert models to tflite. If you really need to use layers which are not supported you can always try to compile Tensorflow for your embedded platform if your memory permits but this can be a pain.\r\n\r\n@pigubaoza I guess you should stick to the list on this link : https://www.tensorflow.org/lite/tf_ops_compatibility", "@JamesZhangjp This is a stale issue. If anyone looking for `LSTM` example, you can check this [`TF resource`](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/experimental/examples/lstm) where you can find couple of examples.\r\n\r\nI am providing one complete example with recent `tf-nightly`. Please take a look at the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/45719f8614338f24ac3e2b6d6a3b42a7/untitled.ipynb). Thanks!\r\n\r\nI am closing this issue. Feel free to reopen if there is any issue. Thanks!"]}, {"number": 24187, "title": "Load multiple tflite models in APP", "body": "Hi experts,\r\nI got some errors\uff08it seems to be the APP crash or collapse\uff09 when I load multiple SSD_mobilenet tflite models for object detection in a APP with sufficient memory,where these models have different the number of classes.  However, APP work well when I only load a model. So, Could I load multiple tflite models in a APP? Could you please give my advises and instruction of solving this problem? Thanks.", "comments": ["Do you create different interpreter objects? You should be able to create different interpreter instances linked to each model file and run it in the java app.\r\nPlease provide code samples and Android Debugger log details to reproduce the issues you are seeing.\r\n\r\nThanks", "Thank you for your instruction.This problem has been solved.", "I have two models .tflite, the face_detector and a custom model for classification of the image. I want that my app detects the boxes of the face then classifies the face with the label. Can someone help me with this please", "I also have two models .tflite for object detection and face recognition and want to use these in a single code with single camera view. Please tell me how can i achieve it?", "> Thank you for your instruction.This problem has been solved.\r\n\r\nPlease guide us or share the usable code to solve this problem.", "My research work is ultimately developing an app to record sensor data on board a smart phone such as accelerometer, gyroscope etc and classify the type also use camera for object detection. Both of these needs to be on the same android app. Can someone please guide me to any resources on th same.\r\nThanks in advance!", "@xiaogangLi Hi ,\r\nSounds like an interseting work. Could you please guide me how did you make it work?\r\n\r\nThanks", "> > \u0421\u043f\u0430\u0441\u0438\u0431\u043e \u0437\u0430 \u0438\u043d\u0441\u0442\u0440\u0443\u043a\u0446\u0438\u044e. \u041f\u0440\u043e\u0431\u043b\u0435\u043c\u0430 \u0440\u0435\u0448\u0435\u043d\u0430.\r\n> \r\n> \u041f\u043e\u0436\u0430\u043b\u0443\u0439\u0441\u0442\u0430, \u043f\u043e\u043c\u043e\u0433\u0438\u0442\u0435 \u043d\u0430\u043c \u0438\u043b\u0438 \u043f\u043e\u0434\u0435\u043b\u0438\u0442\u0435\u0441\u044c \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u043c\u044b\u043c \u043a\u043e\u0434\u043e\u043c, \u0447\u0442\u043e\u0431\u044b \u0440\u0435\u0448\u0438\u0442\u044c \u044d\u0442\u0443 \u043f\u0440\u043e\u0431\u043b\u0435\u043c\u0443.\r\n\r\nhave you solved this problem?", "> Hi experts, I got some errors\uff08it seems to be the APP crash or collapse\uff09 when I load multiple SSD_mobilenet tflite models for object detection in a APP with sufficient memory,where these models have different the number of classes. However, APP work well when I only load a model. So, Could I load multiple tflite models in a APP? Could you please give my advises and instruction of solving this problem? Thanks.\r\n\r\nCan you explain how you solved your issue, please?", "> I have two models .tflite, the face_detector and a custom model for classification of the image. I want that my app detects the boxes of the face then classifies the face with the label. Can someone help me with this please\r\n\r\nHi, I have the same problem as you, did you have a solution?\r\nCan you help me?"]}, {"number": 24186, "title": "Merge 1.12 branch to master", "body": "", "comments": ["So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored or co-authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of all the commit author(s), set the `cla` label to `yes` (if enabled on your project), and then merge this pull request when appropriate.*\n\n<!-- need_author_consent -->", "A Googler has manually verified that the CLAs look good.\n\n(Googler, please make sure the reason for overriding the CLA status is clearly documented in these comments.)\n\n<!-- cla_yes -->"]}, {"number": 24185, "title": "Problem importing Tensorflow with Python 3.6.7", "body": "Hi experts,\r\n    I've installed Anaconda 3 64-bit and Python 3.6.7 on my Windows 10 laptop, also I've installed Tensorflow, however when I try to import Tensorflow, it fails, messages are appended below, could you please give my advises and instruction of solving this problem? Thanks.\r\n\r\n\r\n\r\n```\r\n(tensorflow) C:\\Users\\user>python\r\nPython 3.6.7 |Anaconda custom (64-bit)| (default, Oct 28 2018, 19:44:12) [MSC v.1915 64 bit (AMD64)] on win32\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n\r\n\r\n>>> import tensorflow as tf\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\user\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 18, in swig_import_helper\r\n    fp, pathname, description = imp.find_module('_pywrap_tensorflow_internal', [dirname(__file__)])\r\n  File \"C:\\Users\\user\\Anaconda3\\envs\\tensorflow\\lib\\imp.py\", line 297, in find_module\r\n    raise ImportError(_ERR_MSG.format(name), name=name)\r\nImportError: No module named '_pywrap_tensorflow_internal'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\user\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\user\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\user\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 20, in swig_import_helper\r\n    import _pywrap_tensorflow_internal\r\nModuleNotFoundError: No module named '_pywrap_tensorflow_internal'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Users\\user\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *  # pylint: disable=redefined-builtin\r\n  File \"C:\\Users\\user\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\user\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\user\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 18, in swig_import_helper\r\n    fp, pathname, description = imp.find_module('_pywrap_tensorflow_internal', [dirname(__file__)])\r\n  File \"C:\\Users\\user\\Anaconda3\\envs\\tensorflow\\lib\\imp.py\", line 297, in find_module\r\n    raise ImportError(_ERR_MSG.format(name), name=name)\r\nImportError: No module named '_pywrap_tensorflow_internal'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\user\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\user\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\user\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 20, in swig_import_helper\r\n    import _pywrap_tensorflow_internal\r\nModuleNotFoundError: No module named '_pywrap_tensorflow_internal'\r\n```", "comments": ["Probably a duplicate of #23286\r\n", "> Probably a duplicate of #23286\r\n\r\nThanks a lot, I could import tensorflow after doing:\r\n`pip install --upgrade https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-1.11.0-cp36-cp36m-win_amd64.whl `", "Are you satisfied with the resolution of your issue?\r\n[Yes](https://goo.gl/forms/Oe0tEvODFRoI2gJF3)\r\n[No](https://goo.gl/forms/fUjzOfrtkFbrOT8d2)"]}, {"number": 24184, "title": "[ppc64le] Building tf 1.8 from source fails on power9 machine", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nLSB Version:\t:core-4.1-noarch:core-4.1-ppc64le\r\nDistributor ID:\tRedHatEnterpriseServer\r\nDescription:\tRed Hat Enterprise Linux Server release 7.5 (Maipo)\r\nRelease:\t7.5\r\nCodename:\tMaipo\r\n\r\n- TensorFlow installed from (source or binary): Source\r\n- TensorFlow version: 1.8\r\n- Python version: 3.6.5\r\n- Installed using virtualenv? pip? conda?: conda 5.2\r\n- Bazel version (if compiling from source): 0.11.1\r\n- GCC/Compiler version (if compiling from source): 4.8.5\r\n- CUDA/cuDNN version: 9.2.148/ 7.1.4\r\n- GPU model and memory: Nvidia Tesla V100\r\n\r\n\r\n\r\n**Describe the problem**\r\nBuilding tensorflow 1.8 from source fails with the following error.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n```\r\nCUDA_VER=9.2\r\nCUDNN_VER=7.1.4\r\nNCCL_VER=2.3.7-1\r\nBAZEL_VER=0.11.1\r\nTF_VER=1.8.0\r\nCONDA_VER=5.2.0\r\nPY_VER=3.6\r\n\r\n#module load cuda/9.2.148\r\nCUDA_DIR=$(pwd)/9.2.148\r\n#install pre-built anaconda\r\nwget https://repo.anaconda.com/archive/Anaconda3-$CONDA_VER-Linux-ppc64le.sh -O anaconda3.sh\r\nbash ./anaconda3.sh -b -p anaconda3\r\nexport PATH=$(pwd)/anaconda3/bin:$PATH\r\npip install --upgrade pip\r\nconda install -y keras-applications --no-deps\r\nconda install -y keras-preprocessing --no-deps\r\n#install bazel \r\nwget https://github.com/bazelbuild/bazel/releases/download/$BAZEL_VER/bazel-$BAZEL_VER-dist.zip\r\nunzip bazel-$BAZEL_VER-dist.zip -d bazel\r\ncd bazel\r\n./compile.sh\r\nexport PATH=$(pwd)/output:$PATH\r\ncd ../\r\n\r\n#workaround for nccl2 \r\ngit clone https://github.com/NVIDIA/nccl\r\ncd nccl\r\ngit checkout v$NCCL_VER\r\nmake -j160 src.build CUDA_HOME=$CUDA_DIR\r\nmake pkg.txz.build CUDA_HOME=$CUDA_DIR\r\ntar -xf  build/pkg/txz/* -C ..\r\ncd ..\r\nln -s nccl_$NCCL_VER* nccl2\r\ncd nccl2\r\nln -s LICENSE.txt NCCL-SLA.txt\r\ncd ..\r\n\r\nCUDNN_DIR=$CUDA_DIR\r\n\r\n#setup env var\r\nexport PYTHON_BIN_PATH=$(pwd)/anaconda3/bin/python3\r\nexport PYTHON_LIB_PATH=$(pwd)/anaconda3/lib/python$PY_VER/site-packages\r\nexport TF_NEED_MKL=0\r\nexport CC_OPT_FLAGS=\"-march=native\"\r\nexport TF_NEED_JEMALLOC=1\r\nexport TF_NEED_GCP=0\r\nexport TF_NEED_HDFS=0\r\nexport TF_ENABLE_XLA=0\r\nexport TF_NEED_OPENCL=0\r\nexport TF_NEED_CUDA=1\r\nexport TF_CUDA_CLANG=0\r\nexport TF_CUDA_VERSION=$CUDA_VER\r\nexport CUDA_TOOLKIT_PATH=$CUDA_DIR\r\nexport TF_CUDNN_VERSION=$CUDNN_VER\r\nexport CUDNN_INSTALL_PATH=$CUDNN_DIR\r\nexport TF_CUDA_COMPUTE_CAPABILITIES=\"7.0\"\r\nexport TF_NEED_VERBS=0\r\nexport TF_NEED_AWS=0\r\nexport TF_NEED_NGRAPH=0\r\nexport TF_NEED_S3=0\r\nexport TF_NEED_GDR=0\r\nexport TF_NEED_OPENCL_SYCL=0\r\nexport GCC_HOST_COMPILER_PATH=/usr/bin/gcc\r\nexport TF_NEED_MPI=0\r\nexport TF_NEED_KAFKA=0\r\nexport TF_NEED_ROCM=0\r\nexport TF_NEED_IGNITE=0\r\nexport TF_NEED_TENSORRT=0\r\nexport TF_SET_ANDROID_WORKSPACE=0\r\nexport TF_NCCL_VERSION=$(echo $NCCL_VER | cut -d. -f1,2)\r\nexport NCCL_INSTALL_PATH=\"$(pwd)/nccl2\"\r\nexport LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:$CUDA_DIR/lib64/stubs\r\n\r\n#build tensorflow\r\ngit clone --recursive https://github.com/tensorflow/tensorflow\r\ncd tensorflow\r\ngit checkout v$TF_VER\r\nwget https://github.com/tensorflow/tensorflow/commit/8f8a3c5.patch\r\npatch -p1 third_party/png.BUILD 8f8a3c5.patch\r\n#bug fix commit\r\n#git cherry-pick 5aefa441\r\n./configure\r\nbazel build -c opt --config=cuda tensorflow/tools/pip_package:build_pip_package\r\nbazel-bin/tensorflow/tools/pip_package/build_pip_package ../tensorflow_pkg\r\n```\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n```\r\nWARNING: /autofs/nccs-svm1_home1/shubhankar/.cache/bazel/_bazel_shubhankar/7ed9dc3ce0223066bb07a37deb908baa/external/protobuf_archive/WORKSPACE:1: Workspace name in /autofs/nccs-svm1_home1/shubhankar/.cache/bazel/_bazel_shubhankar/7ed9dc3ce0223066bb07a37deb908baa/external/protobuf_archive/WORKSPACE (@com_google_protobuf) does not match the name given in the repository's definition (@protobuf_archive); this will cause a build error in future versions\r\nERROR: /autofs/nccs-svm1_home1/shubhankar/summit/tensorflow/tensorflow/tools/pip_package/BUILD:117:1: no such package '@aws//': /autofs/nccs-svm1_home1/shubhankar/.cache/bazel/_bazel_shubhankar/7ed9dc3ce0223066bb07a37deb908baa/external/aws/.nfs000000000e4cb4e200000242 (Device or resource busy) and referenced by '//tensorflow/tools/pip_package:licenses'\r\nERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: no such package '@aws//': /autofs/nccs-svm1_home1/shubhankar/.cache/bazel/_bazel_shubhankar/7ed9dc3ce0223066bb07a37deb908baa/external/aws/.nfs000000000e4cb4e200000242 (Device or resource busy)\r\nINFO: Elapsed time: 2.634s\r\nFAILED: Build did NOT complete successfully (46 packages loaded)\r\n```", "comments": ["`external/aws/.nfs000000000e4cb4e200000242 (Device or resource busy)` looks like an NFS error? There should be no difference between building on Power8 and Power9.\r\n\r\nFYI @jayfurmanek ", "@gunan @wdirons I was able to build tf 1.8 from source using bazel v0.18. Can it pose issues later as the recommended bazel version for tf 1.8 is 0.10", "@ghltshubh , it shouldn't be an issue. 0.10.0 was the minimal version of bazel needed to build tf 1.8", "Closing this issue since it has been resolved. Thanks!"]}, {"number": 24183, "title": "Add @smit-hinsu and @azaks2 to tensorrt CODEOWNERS", "body": "", "comments": []}, {"number": 24182, "title": "Apollo3 source files for Micro Lite", "body": "This pull request adds support for the Apollo3 microcontroller for the Micro Lite project. \r\n\r\nThe maintainer of this portion of the Tensorflow repo is @petewarden ", "comments": []}, {"number": 24180, "title": "Add support for ppc64le_dockerfiles", "body": "Add support for ppc64le dockerfiles with newest assembler changes.\r\n\r\nThe `LIB_DIR_PREFIX` arg could be removed by adding a couple `if` to `nvidia-devel.partial`\r\nMoved the tools.Dockerfile to ubuntu:16.04 because all of the architectures in get.docker.com support ubuntu:xenial, but not all of them support debian:stretch.", "comments": ["@jayfurmanek @wdirons @angersson ", "Nvidia's cuda packages historically have used the naming:\r\n\r\n```\r\n[package]-[cuda version major]-[cuda version minor]\r\n```\r\nAnd then the version of the package has the full version number.\r\nFor example:\r\n```\r\ncuda-toolkit-10-0-10.0.130-1.ppc64le\r\n```\r\n\r\nSo the cuda expansion vars look ok to me. \r\nI'd also say we just move these to cuda10 since, as just discussed in the build SIG mtg, it sounds like cuda10 is the target for 1.13.", "Some other notes from discussing with @gunan:\r\n\r\n- I'm going to make some quick changes to support output directories, so that the ppc dockerfiles all go in a subdirectory.\r\n- Are you planning to use the builder-assembler features to build these images? We're not planning to host them on tensorflow/tensorflow (which is what `nightly` and `release` are for), so if you're planning to build the resulting Dockerfiles yourself, you can mark them as dockerfiles-only. Otherwise, you can make your own release for easier filtering (I'll update the docs, too).", "Once I see an update for output directories, I'll update my patch.\r\nUpdated patch will use cuda 10.0 for both x86 and ppc64le docker files, create an \"ubuntu-ppc64le\" slice_set, and \"ubuntu-ppc64le-dockerfiles\" release.\r\n\r\nWe don't plan on using the assembler to build/publish the images (yet).", "I made https://github.com/tensorflow/tensorflow/pull/24206 to support subdirectories.", "I added a new ARG (CACHE_STOP) before we pull down tensorflow (either in .whl or git clone).\r\nWithout this, docker will cache the RUN command, and you will get the same version of tensorflow for each build.\r\n@angersson How are you planning on getting around this issue when you pip install tensorflow (and other packages)?", "@tjakob our CI does everything from scratch and doesn't have a cache from previous builds, so I don't think it's an issue on our end.", "@angersson Was there anything else that you and/or @gunan wanted changed?", "@tjakob Sorry for making you wait; our build infra has been finicky. I'm working on verifying that our new CI for Docker works before accepting new Docker-related PRs; it'll take a bit longer before I can get back to this.", "This looks better now, thanks. Can you pull in the latest changes and rebuild?", "@angersson Is there any update on when you'll be ready to merge this PR?", "Sorry for the wait. This looks good, but I'd like to wait until the 1.13 release is complete to make sure there's only one thing going on with the Dockerfiles at once.", "Finally merged. Thanks for your patience, @tjakob!"]}, {"number": 24179, "title": "[Feature Request] Batch size scheduler to speed up training", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 1.12\r\n- Are you willing to contribute it (Yes/No): Yes, but never contributed on TensorFlow code before.\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nI am looking for a batch size scheduler. Some recent papers like this one from Google (https://openreview.net/pdf?id=B1Yy1BxCZ) show that increasing batch size during training may have the same impact as decreasing the learning rate on validation accuracy. The advantage of increasing the batch size during training is that it requires less iterations per epoch, therefore reducing training time.\r\n\r\n**Will this change the current api? How?**\r\nNot sure.\r\n\r\n**Who will benefit with this feature?**\r\nEveryone in the TensorFlow community which are willing to train Neural Networks faster.\r\n\r\n**Any Other info.**\r\n\r\n**Reference paper:** *Don't Decay the Learning Rate, Increase the Batch Size \r\nSamuel L. Smith, Pieter-Jan Kindermans, Chris Ying, Quoc V. Le*\r\nLink: https://openreview.net/pdf?id=B1Yy1BxCZ ", "comments": ["I think that we can close this.", "@felipheggaliza,\r\nCan you please let us know if the workaround mentioned in [this Comment](https://github.com/keras-team/keras/issues/10143#issuecomment-452144227) is what you are looking for? Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 24178, "title": "Add gradient for tf.extract_volume_patches", "body": "This implementation is based on tf.extract_image_patches.", "comments": ["Nagging Reviewer @drpngx: You have been added as a reviewer to this pull request. Please add your review or reassign. It has been 44 days with no activity and the `awaiting review` label has been applied.", "Sorry I didn't realize I was a reviewer here. Please find another reviewer for now."]}, {"number": 24177, "title": "Calculate the output size instead of using hardcoded value in the iOS Camera Example", "body": "[The Tensorflow Lite Camera example](https://www.tensorflow.org/lite/demo_ios) hardcodes the output tensor size to `1000`. If you test the example with a retrained model having a smaller number of outputs, the iOS app crashes. The PR fixes the problem by reading the output size from the model output tensor dimensions.", "comments": []}, {"number": 24176, "title": "HELP!Compile tensorflow source code WITH cuda10.0(2080ti),CUDNN 7.4.1,bazel0.15 anaconda2", "body": "ERROR: /home/xhs/XHS/tensorflow-master/tensorflow/BUILD:573:1: Executing genrule //tensorflow:tf_python_api_gen_v1 failed (Exit 1)\r\nTraceback (most recent call last):\r\n  File \"/home/xhs/.cache/bazel/_bazel_xhs/1843eb251a57c74a19c1281e427cacbd/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/tools/api/generator/create_python_api.py\", line 27, in <module>\r\n    from tensorflow.python.tools.api.generator import doc_srcs\r\n  File \"/home/xhs/.cache/bazel/_bazel_xhs/1843eb251a57c74a19c1281e427cacbd/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/__init__.py\", line 81, in <module>\r\n    from tensorflow.python import keras\r\n  File \"/home/xhs/.cache/bazel/_bazel_xhs/1843eb251a57c74a19c1281e427cacbd/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/keras/__init__.py\", line 29, in <module>\r\n    from tensorflow.python.keras import datasets\r\n  File \"/home/xhs/.cache/bazel/_bazel_xhs/1843eb251a57c74a19c1281e427cacbd/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/keras/datasets/__init__.py\", line 25, in <module>\r\n    from tensorflow.python.keras.datasets import imdb\r\n  File \"/home/xhs/.cache/bazel/_bazel_xhs/1843eb251a57c74a19c1281e427cacbd/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/keras/datasets/imdb.py\", line 25, in <module>\r\n    from tensorflow.python.keras.preprocessing.sequence import _remove_long_seq\r\n  File \"/home/xhs/.cache/bazel/_bazel_xhs/1843eb251a57c74a19c1281e427cacbd/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/keras/preprocessing/__init__.py\", line 21, in <module>\r\n    import keras_preprocessing\r\nImportError: No module named keras_preprocessing\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 6674.103s, Critical Path: 2867.88s\r\nINFO: 10631 processes: 10631 local.\r\nFAILED: Build did NOT complete successfully\r\n\r\n\r\n\r\nThis is the part I chose to get the error. Please help me to see how it can be compiled.", "comments": ["You have to install keras_preprocessing in your virtual environment. \r\n\r\nSee the first section here : https://www.tensorflow.org/install/source\r\n", "Tensorflow prebuilt binaries are tested against CUDA 9.0. If you want to use cuda 10, you have to build TF from sources yourself. Thanks!\r\nAlso can you please provide following information:\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version:\r\n- Python version:\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.", "thank you @ymodak \r\nYes , I build Tensorflow from source,but I encountered an error.\r\nThe system inforflow is described below\uff1a\r\nubuntu16.04\r\ntensorflow source\r\nTensorflow source version : 1.12\r\npython version 2.7\r\nconda\r\nbazel version 0.15\r\ngcc version 5.4.0 \r\nCUDA version 10.0\r\nCudnn version 7.4.1\r\nGPU model RTX 2080ti,11GB\r\n\r\n- Describe the problem\uff1a\r\nFirst I installed bazel, the installed version is 0.15.0.\r\nDownload tensorflow source code by git clone --recurse-submodules https://github.com/tensorflow/tensorflow\r\n./configure .In this step , I have chosen no except cuda related options.\r\nFinally, I executed \r\nbazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\r\nthere was an error  mentioned above .\r\nThank you for your help.\r\n", "Take a look at the [attempt](https://medium.com/@vitali.usau/install-cuda-10-0-cudnn-7-3-and-build-tensorflow-gpu-from-source-on-ubuntu-18-04-3daf720b83fe) done by other users. Probably this will help.", "Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 24175, "title": "Expose underlying operation in op wrappers", "body": "Little tweaks in the Java API here:\r\n\r\n1) Expose the underlying operation of an op wrapper because some ops don't have any outputs (e.g. `WriteSummary`), which makes it harder to refer them after creation. So now, we can do:\r\n```\r\nWriteSummary summary = WriteSummary.create(...);\r\nSession.runner.addTarget(summary.op()).run();\r\n```\r\n\r\n2) Allow feeding input tensors by referring an operand directly. ex:\r\n```\r\nPlaceholder<Float> inputs = ops.placeholder(...);\r\ntry (Tensor<Float> inputTensors = Tensors.create(...)) {\r\n    Session.runner.feed(inputs, inputTensors).run();\r\n}\r\n```\r\n\r\n@asimshankar if you agree with those changes, is it possible to merge them for 1.13? I have some pending examples that I would like to add to `tensorflow/models` which depends on them. Thanks!", "comments": ["@karllessard : Was just following up on this and noticed that the tests were failing.\r\nCould you take a look and update the PR?\r\n\r\nFor example, the following is the log for `//tensorflow/java:GradientsTest`\r\n\r\n```\r\ntensorflow/java/src/test/java/org/tensorflow/op/core/GradientsTest.java:56: error: reference to feed is ambiguous\r\n                  sess.runner().feed(x, c).fetch(grads.dy(0)).fetch(grads.dy(1)).run())) {\r\n                               ^\r\n  both method feed(Output<?>,Tensor<?>) in Session.Runner and method <T>feed(Operand<T>,Tensor<T>) in Session.Runner match\r\n  where T is a type-variable:\r\n    T extends Object declared in method <T>feed(Operand<T>,Tensor<T>)\r\ntensorflow/java/src/test/java/org/tensorflow/op/core/GradientsTest.java:82: error: reference to feed is ambiguous\r\n              new TestUtil.AutoCloseableList<>(sess.runner().feed(x, c).fetch(grads.dy(0)).run())) {\r\n                                                            ^\r\n  both method feed(Output<?>,Tensor<?>) in Session.Runner and method <T>feed(Operand<T>,Tensor<T>) in Session.Runner match\r\n  where T is a type-variable:\r\n    T extends Object declared in method <T>feed(Operand<T>,Tensor<T>)\r\ntensorflow/java/src/test/java/org/tensorflow/op/core/GradientsTest.java:109: error: reference to feed is ambiguous\r\n                  sess.runner().feed(x, c).fetch(grads1.dy(0)).run())) {\r\n                               ^\r\n  both method feed(Output<?>,Tensor<?>) in Session.Runner and method <T>feed(Operand<T>,Tensor<T>) in Session.Runner match\r\n  where T is a type-variable:\r\n    T extends Object declared in method <T>feed(Operand<T>,Tensor<T>)\r\n```", "@asimshankar : oops, I missed that too! Fixed it by keeping only the new method, which is compatible with the old one."]}, {"number": 24174, "title": "bazel 0.15.0 cuda10", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version:\r\n- Python version:\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["Please provide following information to proceed further. Thanks!\r\nSystem information\r\n\r\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\nTensorFlow installed from (source or binary):\r\nTensorFlow version:\r\nPython version:\r\nInstalled using virtualenv? pip? conda?:\r\nBazel version (if compiling from source):\r\nGCC/Compiler version (if compiling from source):\r\nCUDA/cuDNN version:\r\nGPU model and memory:\r\nDescribe the problem\r\n\r\nProvide the exact sequence of commands / steps that you executed before running into the problem\r\n\r\nAny other info / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.", "Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 24173, "title": "Add example to import_meta_graph docstring", "body": "Same change as the PR: https://github.com/tensorflow/tensorflow/pull/23742\r\nCreated new PR due to merging into a different branch. \r\n\r\nDetails: Based on the super insightful example by @mrry on Stackoverflow (https://stackoverflow.com/a/38834095/1063607), which many users suggested should be in the official documentation.\r\n", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n<!-- need_author_cla -->", "CLA test", "@vidakDK Can you please sign the CLA to move ahead with this PR? Thanks!", "@vidakDK Thanks for updating your change to master!\r\n\r\nI think the CLA bot is confused because one of the commits doesn't use your GitHub username, but is still your name. It should be safe to override.", "A Googler has manually verified that the CLAs look good.\n\n(Googler, please make sure the reason for overriding the CLA status is clearly documented in these comments.)\n\n<!-- cla_yes -->", "If it\u2019s possible to override please do so, I don\u2019t know how to sign CLA\nwith that account, it\u2019s just my local host name :) I tried to commit with\nmy GitHub username afterward, but the bot still isn\u2019t happy. :D\nOn Wed 5. Dec 2018 at 20:03, Austin Anderson <notifications@github.com>\nwrote:\n\n> @vidakDK <https://github.com/vidakDK> Thanks for updating your change to\n> master!\n>\n> I think the CLA bot is confused because one of the commits doesn't use\n> your GitHub username, but is still your name. It should be safe to override.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/24173#issuecomment-444600546>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AJsvvMJ9PSV_Fk-F_vzA8ukTT7yPOk2pks5u2BhlgaJpZM4ZCxRQ>\n> .\n>\n"]}, {"number": 24172, "title": "Importing tensorflow changes CPU affinity to single core on main thread ", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux CentOS 6.5\r\n- TensorFlow installed from (source or binary): Anaconda3\r\n- TensorFlow version (use command below): 1.10.0 (1.10.0-mkl_py36hdb377fd_0)\r\n- Python version: 3.6.6\r\n\r\n**Describe the current behavior**\r\nImporting tensorflow causes Cpus allowed list to single core on main thread. That is, when I import tensorflow (even not using it). It will break down multi-thread computing of numpy and gensim (only using single core for matrix multiplication or learning model)\r\n\r\n**Describe the expected behavior**\r\nImporting tensorflow should not influence the behavior of other toolkits.\r\n\r\n**Code to reproduce the issue**\r\n1. Install tensorflow using anaconda and run ipython:\r\n    ```bash\r\n    conda create -n test tensorflow==1.10.0 gensim ipython\r\n    conda activate test\r\n    ipython\r\n    ```\r\n\r\n2. Run the following code in ipython:\r\n    ```python\r\n    import tensorflow\r\n    import numpy as np\r\n    from gensim.models import Word2Vec\r\n    ```\r\n\r\n3. Check Cpus allowed list for main thread(in another bash):\r\n    ```bash\r\n    cat /proc/<pid>/status | grep Cpus_allowed_list\r\n    ```\r\n    Output (may vary):\r\n    ```bash\r\n    Cpus_allowed_list:      55-72,108-125\r\n    ```\r\n\r\n4. Perform matrix multiplication in ipython:\r\n    ```python\r\n    A = np.random.rand(10000, 10000)\r\n    A = A.dot(A.T)\r\n    del A\r\n    ```\r\n\r\n5. Check again Cpus allowed list for main thread:\r\n    ```bash\r\n    cat /proc/<pid>/status | grep Cpus_allowed_list\r\n    ```\r\n    \r\n    Output (may vary):\r\n    \r\n    ```bash\r\n    Cpus_allowed_list:      108\r\n    ```\r\n    \r\n    It become single core! **Note if we do not import tensorflow in step 2. Then the output here will be the same as step 3**. Actually the computing in step 4 can be paralleled. But as we will see in step 6, the other toolkit such as gensim will not work using multicore.\r\n\r\n6. Run the following code (make sure you have already run the ipython code above):\r\n    ```python\r\n    cpus = 32 # change it depending on your machine setting\r\n    B = np.random.randint(1,100, size=(5000,5000)).astype('str').tolist()\r\n    model = Word2Vec(B, workers=cpus)\r\n    del model\r\n    ```\r\n    \r\n    You can check in top or htop that ipython will only use one core in executing the third line. **However, if we do not import tensorflow, then it will use 32 cpus and all thing will work fine.**\r\n\r\n\r\n**Other info**\r\nI don't know whether it is a tensorflow issue or numpy issue (since if we exchange S4 and S6, then it will work fine) or just MKL issue (since if we do not use mkl, but use tensorflow-gpu for numpy without mkl, then it cannot doing parallel matrix computing but gensim will work fine). But I considering that it is importing tensorflow that causes the issue, so I hope someone can give me some idea about this problem.\r\n", "comments": ["@dizzam  I'm so sorry for the delay, and thank you for the detailed description!\r\n\r\nJust a side note: I got this error `ModuleNotFoundError: No module named 'google_compute_engine` from \r\n```Python\r\nfrom gensim.models import Word2Vec\r\n```\r\nI got rid of it with `pip install google_compute_engine`. \r\n\r\nI could reproduce the issues on CentOS 7 and Ubuntu 16.04 with both python and ipython. The issue also persists in the latest release (1.12.0). Interestingly, `Cpus_allowed_list` doesn't change if I call `A.dot(A.T)` once before importing TensorFlow. \r\n\r\nI think you are right that this is related to MKL. The issue disappeared when I switched to TensorFlow CPU without MKL.\r\n```\r\nconda install tensorflow-base==1.12.0=eigen_py36h4dcebc2_0\r\n```\r\n\r\nI'll see if this also happens outside Anaconda. ", "The issue doesn't happen when I use my manually-compiled TF --config=mkl wheel. \r\nLooping in @agramesh1.", "Also looping in @claynerobison since I just remembered @agramesh1 is on vacation.", "@dizzam I did a quick test on Ubuntu and was able to reproduce your issue. The TensorFlow and numpy builds you are using are built by Anaconda community. Could you please try the tensorflow and numpy build from Intel's channel in Anaconda? I was able to see all the CPU cores being utilized with Intel' builds. Here is the command\r\n```bash\r\nconda install tensorflow numpy -c intel\r\n```\r\nIn the meantime we'll try to work with Anaconda team to investigate this issue", "When imported the Anaconda mkl tensorflow packages will set the `KMP_BLOCKTIME` and `OMP_PROC_BIND` environment variables, if they are not already set, to values which have been found to give good performance with an MKL enabled Tensorflow.  These variable may have effects on other libraries which use OpenMP or MKL. \r\n\r\nIf these default values are not desired either set them before importing tensorflow to a preferred value or unset them after importing tensorflow using:\r\n```Python\r\nimport tensorflow # this sets KMP_BLOCKTIME and OMP_PROC_BIND\r\nimport os\r\ndel os.environ['OMP_PROC_BIND']\r\ndel os.environ['KMP_BLOCKTIME']\r\n```\r\n\r\nThe specific patch which does this can be found in the [tensorflow_recipes repository](https://github.com/AnacondaRecipes/tensorflow_recipes/blob/06ffb0b8bdb099e83411b80bf01042eb2da7d5f2/tensorflow-base-cpu/0008-set-default-openmp-variables.patch).  Note that the \"eigen\" and \"gpu\" variants of the tensorflow package do not include this patch.", "Thanks for @preethivenkatesh and @jjhelmus . I have solved this issue by your suggestion."]}, {"number": 24171, "title": "bazel build tensorflow/python/tools:freeze_graph error", "body": "ERROR: /root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/external/grpc/BUILD:1515:1: C++ compilation of rule '@grpc//:grpc_resolver_dns_ares' failed (Exit 1) gcc failed: error executing command /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG ... (remaining 62 argument(s) skipped)\r\n\r\nUse --sandbox_debug to see verbose messages from the sandbox\r\nexternal/grpc/src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc:56:30: error: field 'dns_server_addr' has incomplete type 'ares_addr_port_node'\r\n   struct ares_addr_port_node dns_server_addr;\r\n                              ^\r\nexternal/grpc/src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc:56:10: note: forward declaration of 'struct ares_addr_port_node'\r\n   struct ares_addr_port_node dns_server_addr;\r\n          ^\r\nexternal/grpc/src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc: In function 'void on_txt_done_locked(void*, int, int, unsigned char*, int)':\r\nexternal/grpc/src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc:313:53: error: 'ares_parse_txt_reply_ext' was not declared in this scope\r\n   status = ares_parse_txt_reply_ext(buf, len, &reply);\r\n                                                     ^\r\nexternal/grpc/src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc:316:58: error: invalid use of incomplete type 'struct on_txt_done_locked(void*, int, int, unsigned char*, int)::ares_txt_ext'\r\n   for (result = reply; result != nullptr; result = result->next) {\r\n                                                          ^\r\nexternal/grpc/src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc:309:10: note: forward declaration of 'struct on_txt_done_locked(void*, int, int, unsigned char*, int)::ares_txt_ext'\r\n   struct ares_txt_ext* result = nullptr;\r\n          ^\r\nexternal/grpc/src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc:317:15: error: invalid use of incomplete type 'struct on_txt_done_locked(void*, int, int, unsigned char*, int)::ares_txt_ext'\r\n     if (result->record_start &&\r\n               ^\r\nexternal/grpc/src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc:309:10: note: forward declaration of 'struct on_txt_done_locked(void*, int, int, unsigned char*, int)::ares_txt_ext'\r\n   struct ares_txt_ext* result = nullptr;\r\n          ^\r\nexternal/grpc/src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc:318:22: error: invalid use of incomplete type 'struct on_txt_done_locked(void*, int, int, unsigned char*, int)::ares_txt_ext'\r\n         memcmp(result->txt, g_service_config_attribute_prefix, prefix_len) ==\r\n                      ^\r\nexternal/grpc/src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc:309:10: note: forward declaration of 'struct on_txt_done_locked(void*, int, int, unsigned char*, int)::ares_txt_ext'\r\n   struct ares_txt_ext* result = nullptr;\r\n          ^\r\nexternal/grpc/src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc:325:39: error: invalid use of incomplete type 'struct on_txt_done_locked(void*, int, int, unsigned char*, int)::ares_txt_ext'\r\n     size_t service_config_len = result->length - prefix_len;\r\n                                       ^\r\nexternal/grpc/src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc:309:10: note: forward declaration of 'struct on_txt_done_locked(void*, int, int, unsigned char*, int)::ares_txt_ext'\r\n   struct ares_txt_ext* result = nullptr;\r\n          ^\r\nexternal/grpc/src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc:328:47: error: invalid use of incomplete type 'struct on_txt_done_locked(void*, int, int, unsigned char*, int)::ares_txt_ext'\r\n     memcpy(*r->service_config_json_out, result->txt + prefix_len,\r\n                                               ^\r\nexternal/grpc/src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc:309:10: note: forward declaration of 'struct on_txt_done_locked(void*, int, int, unsigned char*, int)::ares_txt_ext'\r\n   struct ares_txt_ext* result = nullptr;\r\n          ^\r\nexternal/grpc/src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc:330:25: error: invalid use of incomplete type 'struct on_txt_done_locked(void*, int, int, unsigned char*, int)::ares_txt_ext'\r\n     for (result = result->next; result != nullptr && !result->record_start;\r\n                         ^\r\nexternal/grpc/src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc:309:10: note: forward declaration of 'struct on_txt_done_locked(void*, int, int, unsigned char*, int)::ares_txt_ext'\r\n   struct ares_txt_ext* result = nullptr;\r\n          ^\r\nexternal/grpc/src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc:330:61: error: invalid use of incomplete type 'struct on_txt_done_locked(void*, int, int, unsigned char*, int)::ares_txt_ext'\r\n     for (result = result->next; result != nullptr && !result->record_start;\r\n                                                             ^\r\nexternal/grpc/src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc:309:10: note: forward declaration of 'struct on_txt_done_locked(void*, int, int, unsigned char*, int)::ares_txt_ext'\r\n   struct ares_txt_ext* result = nullptr;\r\n          ^\r\nexternal/grpc/src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc:331:25: error: invalid use of incomplete type 'struct on_txt_done_locked(void*, int, int, unsigned char*, int)::ares_txt_ext'\r\n          result = result->next) {\r\n                         ^\r\nexternal/grpc/src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc:309:10: note: forward declaration of 'struct on_txt_done_locked(void*, int, int, unsigned char*, int)::ares_txt_ext'\r\n   struct ares_txt_ext* result = nullptr;\r\n          ^\r\nexternal/grpc/src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc:334:50: error: invalid use of incomplete type 'struct on_txt_done_locked(void*, int, int, unsigned char*, int)::ares_txt_ext'\r\n                       service_config_len + result->length + 1));\r\n                                                  ^\r\nexternal/grpc/src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc:309:10: note: forward declaration of 'struct on_txt_done_locked(void*, int, int, unsigned char*, int)::ares_txt_ext'\r\n   struct ares_txt_ext* result = nullptr;\r\n          ^\r\nexternal/grpc/src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc:335:70: error: invalid use of incomplete type 'struct on_txt_done_locked(void*, int, int, unsigned char*, int)::ares_txt_ext'\r\n       memcpy(*r->service_config_json_out + service_config_len, result->txt,\r\n                                                                      ^\r\nexternal/grpc/src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc:309:10: note: forward declaration of 'struct on_txt_done_locked(void*, int, int, unsigned char*, int)::ares_txt_ext'\r\n   struct ares_txt_ext* result = nullptr;\r\n          ^\r\nexternal/grpc/src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc:336:20: error: invalid use of incomplete type 'struct on_txt_done_locked(void*, int, int, unsigned char*, int)::ares_txt_ext'\r\n              result->length);\r\n                    ^\r\nexternal/grpc/src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc:309:10: note: forward declaration of 'struct on_txt_done_locked(void*, int, int, unsigned char*, int)::ares_txt_ext'\r\n   struct ares_txt_ext* result = nullptr;\r\n          ^\r\nexternal/grpc/src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc:337:35: error: invalid use of incomplete type 'struct on_txt_done_locked(void*, int, int, unsigned char*, int)::ares_txt_ext'\r\n       service_config_len += result->length;\r\n                                   ^\r\nexternal/grpc/src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc:309:10: note: forward declaration of 'struct on_txt_done_locked(void*, int, int, unsigned char*, int)::ares_txt_ext'\r\n   struct ares_txt_ext* result = nullptr;\r\n          ^\r\nexternal/grpc/src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc: In function 'void grpc_dns_lookup_ares_continue_after_check_localhost_and_ip_literals_locked(grpc_ares_request*, const char*, const char*, const char*, grpc_pollset_set*, bool, grpc_combiner*)':\r\nexternal/grpc/src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc:420:70: error: 'ares_set_servers_ports' was not declared in this scope\r\n     int status = ares_set_servers_ports(*channel, &r->dns_server_addr);\r\n                                                                      ^\r\nTarget //tensorflow/python/tools:freeze_graph failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 827.444s, Critical Path: 131.84s, Remote (0.00% of the time): [queue: 0.00%, setup: 0.00%, process: 0.00%]\r\nINFO: 2143 processes: 2142 linux-sandbox, 1 local.\r\nFAILED: Build did NOT complete successfully\r\n", "comments": ["root@swsrv03:~/tensorflow# bazel version\r\nWARNING: The following rc files are no longer being read, please transfer their contents or import their path into one of the standard rc files:\r\n/root/tensorflow/tools/bazel.rc\r\nBuild label: 0.19.2\r\nBuild target: bazel-out/k8-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Mon Nov 19 16:25:09 2018 (1542644709)\r\nBuild timestamp: 1542644709\r\nBuild timestamp as int: 1542644709\r\n", "Please provide following information. Thanks!\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version:\r\n- Python version:\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.", "System information\r\n\r\nOS Platform and Distribution - Linux Ubuntu 16.04\r\nTensorFlow installed from binary\r\nTensorFlow version: 1.9\r\nPython version: 3.6\r\nInstalled using conda \r\nBazel version (if compiling from source): 0.19\r\nGCC/Compiler version (if compiling from source): 5.4\r\nCUDA/cuDNN version: 9.0/7.1\r\nGPU model and memory: p5000 nvidia\r\n\r\nDescribe the problem\r\nerror when trying to build the freeze graph module \r\n\r\n sequence of commands / steps that you executed before running into the problem :\r\nbazel build tensorflow/python/tools:freeze_graph \r\nfrom tensorflow directory\r\n\r\n", "                from ./tensorflow/core/graph/costmodel.h:25,\r\n                 from ./tensorflow/core/common_runtime/costmodel_manager.h:22,\r\n                 from ./tensorflow/core/distributed_runtime/graph_mgr.h:22,\r\n                 from tensorflow/core/distributed_runtime/graph_mgr.cc:16:\r\n./tensorflow/core/util/tensor_format.h: In instantiation of 'T tensorflow::GetTensorDim(tensorflow::gtl::ArraySlice<T>, tensorflow::TensorFormat, char) [with T = long long int; tensorflow::gtl::ArraySlice<T> = absl::Span<const long long int>]':\r\n./tensorflow/core/util/tensor_format.h:452:47:   required from here\r\n./tensorflow/core/util/tensor_format.h:420:29: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   CHECK(index >= 0 && index < dimension_attributes.size())\r\n                             ^\r\n./tensorflow/core/platform/macros.h:87:47: note: in definition of macro 'TF_PREDICT_FALSE'\r\n #define TF_PREDICT_FALSE(x) (__builtin_expect(x, 0))\r\n                                               ^\r\n./tensorflow/core/util/tensor_format.h:420:3: note: in expansion of macro 'CHECK'\r\n   CHECK(index >= 0 && index < dimension_attributes.size())\r\n   ^\r\n./tensorflow/core/util/tensor_format.h: In instantiation of 'T tensorflow::GetFilterDim(tensorflow::gtl::ArraySlice<T>, tensorflow::FilterTensorFormat, char) [with T = long long int; tensorflow::gtl::ArraySlice<T> = absl::Span<const long long int>]':\r\n./tensorflow/core/util/tensor_format.h:461:54:   required from here\r\n./tensorflow/core/util/tensor_format.h:435:29: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   CHECK(index >= 0 && index < dimension_attribute.size())\r\n                             ^\r\n./tensorflow/core/platform/macros.h:87:47: note: in definition of macro 'TF_PREDICT_FALSE'\r\n #define TF_PREDICT_FALSE(x) (__builtin_expect(x, 0))\r\n                                               ^\r\n./tensorflow/core/util/tensor_format.h:435:3: note: in expansion of macro 'CHECK'\r\n   CHECK(index >= 0 && index < dimension_attribute.size())\r\n   ^\r\nINFO: From Compiling tensorflow/core/kernels/data/prefetch_dataset_op.cc [for host]:\r\ntensorflow/core/kernels/data/prefetch_dataset_op.cc: In member function 'virtual void tensorflow::data::PrefetchDatasetOp::MakeDataset(tensorflow::OpKernelContext*, tensorflow::data::DatasetBase*, tensorflow::data::DatasetBase**)':\r\ntensorflow/core/kernels/data/prefetch_dataset_op.cc:37:33: warning: 'buffer_size' may be used uninitialized in this function [-Wmaybe-uninitialized]\r\n         buffer_size_(buffer_size) {\r\n                                 ^\r\ntensorflow/core/kernels/data/prefetch_dataset_op.cc:385:9: note: 'buffer_size' was declared here\r\n   int64 buffer_size;\r\n         ^\r\nINFO: From Compiling tensorflow/core/grappler/costs/graph_properties.cc [for host]:\r\nIn file included from ./tensorflow/core/grappler/graph_view.h:29:0,\r\n                 from ./tensorflow/core/grappler/mutable_graph_view.h:19,\r\n                 from tensorflow/core/grappler/costs/graph_properties.cc:34:\r\n./tensorflow/core/grappler/utils.h: In function 'int tensorflow::grappler::NodePositionIfSameNode(const string&, const string&)':\r\n./tensorflow/core/grappler/utils.h:126:49: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n       std::distance(input_it, input_name.end()) < node_name.size()) {\r\n                                                 ^\r\ntensorflow/core/grappler/costs/graph_properties.cc: In member function 'tensorflow::Status tensorflow::grappler::SymbolicShapeRefiner::UpdateFunction(const tensorflow::NodeDef*)':\r\ntensorflow/core/grappler/costs/graph_properties.cc:519:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n     for (int i = 0; i < grappler_function_item.inputs().size(); ++i) {\r\n                       ^\r\ntensorflow/core/grappler/costs/graph_properties.cc:573:50: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n       } else if (ctx->input_tensor_protos.size() > i &&\r\n                                                  ^\r\ntensorflow/core/grappler/costs/graph_properties.cc:579:55: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n       } else if (ic->input_tensors_as_shapes().size() > i &&\r\n                                                       ^\r\ntensorflow/core/grappler/costs/graph_properties.cc:622:30: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n       if (out_tensor.index() >= output_properties.size()) {\r\n                              ^\r\ntensorflow/core/grappler/costs/graph_properties.cc: In member function 'tensorflow::Status tensorflow::grappler::SymbolicShapeRefiner::UpdateNode(const tensorflow::NodeDef*, bool*)':\r\ntensorflow/core/grappler/costs/graph_properties.cc:692:48: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n         if (c->output_tensors_as_shapes.size() > src_output) {\r\n                                                ^\r\ntensorflow/core/grappler/costs/graph_properties.cc:697:44: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n         if (c->output_tensor_protos.size() > src_output) {\r\n                                            ^\r\ntensorflow/core/grappler/costs/graph_properties.cc: In member function 'bool tensorflow::grappler::SymbolicShapeRefiner::EquivalentShapesAndTypes(const std::vector<tensorflow::shape_inference::ShapeAndType>&, const std::vector<tensorflow::shape_inference::ShapeAndType>&) const':\r\ntensorflow/core/grappler/costs/graph_properties.cc:906:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n     for (int i = 0; i < st1.size(); ++i) {\r\n                       ^\r\ntensorflow/core/grappler/costs/graph_properties.cc: In member function 'tensorflow::Status tensorflow::grappler::SymbolicShapeRefiner::AddFunction(const tensorflow::NodeDef*)':\r\ntensorflow/core/grappler/costs/graph_properties.cc:933:48: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n     if (grappler_function_item.inputs().size() > function_node->input_size()) {\r\n                                                ^\r\ntensorflow/core/grappler/costs/graph_properties.cc: In static member function 'static tensorflow::Status tensorflow::grappler::GraphProperties::UpdateEnqueue(const tensorflow::NodeDef*, const std::unordered_map<const tensorflow::NodeDef*, const tensorflow::NodeDef*>&, tensorflow::grappler::SymbolicShapeRefiner*, bool*)':\r\ntensorflow/core/grappler/costs/graph_properties.cc:1630:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   for (int i = 1; i < ctx->input_types.size(); ++i) {\r\n                     ^\r\ntensorflow/core/grappler/costs/graph_properties.cc: In member function 'tensorflow::Status tensorflow::grappler::GraphProperties::InferStatically(bool)':\r\ntensorflow/core/grappler/costs/graph_properties.cc:1816:52: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n         } else if (ctx->input_tensor_protos.size() > i &&\r\n                                                    ^\r\ntensorflow/core/grappler/costs/graph_properties.cc:1819:57: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n         } else if (ic->input_tensors_as_shapes().size() > i &&\r\n                                                         ^\r\ntensorflow/core/grappler/costs/graph_properties.cc:1845:53: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n         } else if (ctx->output_tensor_protos.size() > i &&\r\n                                                     ^\r\ntensorflow/core/grappler/costs/graph_properties.cc:1848:57: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n         } else if (ctx->output_tensors_as_shapes.size() > i &&\r\n                                                         ^\r\nIn file included from ./tensorflow/core/platform/default/logging.h:24:0,\r\n                 from ./tensorflow/core/platform/logging.h:25,\r\n                 from ./tensorflow/core/lib/core/status.h:25,\r\n                 from ./tensorflow/core/lib/core/errors.h:21,\r\n                 from ./tensorflow/core/framework/tensor_shape.h:23,\r\n                 from ./tensorflow/core/framework/partial_tensor_shape.h:20,\r\n                 from ./tensorflow/core/framework/attr_value_util.h:23,\r\n                 from ./tensorflow/core/framework/node_def_util.h:22,\r\n                 from ./tensorflow/core/framework/shape_inference.h:20,\r\n                 from ./tensorflow/core/grappler/costs/graph_properties.h:21,\r\n                 from tensorflow/core/grappler/costs/graph_properties.cc:16:\r\n./tensorflow/core/util/tensor_format.h: In instantiation of 'T tensorflow::GetTensorDim(tensorflow::gtl::ArraySlice<T>, tensorflow::TensorFormat, char) [with T = long long int; tensorflow::gtl::ArraySlice<T> = absl::Span<const long long int>]':\r\n./tensorflow/core/util/tensor_format.h:452:47:   required from here\r\n./tensorflow/core/util/tensor_format.h:420:29: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   CHECK(index >= 0 && index < dimension_attributes.size())\r\n                             ^\r\n./tensorflow/core/platform/macros.h:87:47: note: in definition of macro 'TF_PREDICT_FALSE'\r\n #define TF_PREDICT_FALSE(x) (__builtin_expect(x, 0))\r\n                                               ^\r\n./tensorflow/core/util/tensor_format.h:420:3: note: in expansion of macro 'CHECK'\r\n   CHECK(index >= 0 && index < dimension_attributes.size())\r\n   ^\r\n./tensorflow/core/util/tensor_format.h: In instantiation of 'T tensorflow::GetFilterDim(tensorflow::gtl::ArraySlice<T>, tensorflow::FilterTensorFormat, char) [with T = long long int; tensorflow::gtl::ArraySlice<T> = absl::Span<const long long int>]':\r\n./tensorflow/core/util/tensor_format.h:461:54:   required from here\r\n./tensorflow/core/util/tensor_format.h:435:29: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   CHECK(index >= 0 && index < dimension_attribute.size())\r\n                             ^\r\n./tensorflow/core/platform/macros.h:87:47: note: in definition of macro 'TF_PREDICT_FALSE'\r\n #define TF_PREDICT_FALSE(x) (__builtin_expect(x, 0))\r\n                                               ^\r\n./tensorflow/core/util/tensor_format.h:435:3: note: in expansion of macro 'CHECK'\r\n   CHECK(index >= 0 && index < dimension_attribute.size())\r\n   ^\r\nINFO: From Compiling tensorflow/core/grappler/utils/functions.cc [for host]:\r\nIn file included from tensorflow/core/grappler/utils/functions.cc:30:0:\r\n./tensorflow/core/grappler/utils.h: In function 'int tensorflow::grappler::NodePositionIfSameNode(const string&, const string&)':\r\n./tensorflow/core/grappler/utils.h:126:49: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n       std::distance(input_it, input_name.end()) < node_name.size()) {\r\n                                                 ^\r\ntensorflow/core/grappler/utils/functions.cc: In member function 'void tensorflow::grappler::GrapplerFunctionConnectivity::RegisterInputArgExpansion(tensorflow::grappler::InputArgExpansion)':\r\ntensorflow/core/grappler/utils/functions.cc:94:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   for (int i = 0; i < placeholders.size(); ++i) {\r\n                     ^\r\ntensorflow/core/grappler/utils/functions.cc: In member function 'tensorflow::Status tensorflow::grappler::GrapplerFunctionConnectivity::ExpandFunctionDefInput(const string&, std::vector<std::__cxx11::basic_string<char> >*) const':\r\ntensorflow/core/grappler/utils/functions.cc:169:22: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n         if (position > input_arg_expansion.placeholders.size() - 1) {\r\n                      ^\r\ntensorflow/core/grappler/utils/functions.cc: In function 'tensorflow::Status tensorflow::grappler::ReplaceInputWithConst(const tensorflow::NodeDef&, int, tensorflow::grappler::GrapplerFunctionItem*)':\r\ntensorflow/core/grappler/utils/functions.cc:663:25: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n     if (placeholder_idx < input.placeholders.size()) {\r\n                         ^\r\ntensorflow/core/grappler/utils/functions.cc: In function 'tensorflow::Status tensorflow::grappler::RemoveUnusedOutputs(const tensorflow::gtl::FlatSet<int>&, tensorflow::grappler::GrapplerFunctionItem*, std::vector<std::pair<int, int> >*)':\r\ntensorflow/core/grappler/utils/functions.cc:709:44: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n     if (active_output < 0 || active_output >= item->output_size()) {\r\n                                            ^\r\ntensorflow/core/grappler/utils/functions.cc:722:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   for (int i = 0; i < item->output_size(); ++i) {\r\n                     ^\r\nINFO: From Compiling tensorflow/core/distributed_runtime/rpc/grpc_master_service.cc [for host]:\r\nIn file included from ./tensorflow/core/platform/default/logging.h:24:0,\r\n                 from ./tensorflow/core/platform/logging.h:25,\r\n                 from ./tensorflow/core/lib/core/refcount.h:22,\r\n                 from ./tensorflow/core/platform/tensor_coding.h:21,\r\n                 from ./tensorflow/core/framework/resource_handle.h:19,\r\n                 from ./tensorflow/core/framework/allocator.h:24,\r\n                 from ./tensorflow/core/common_runtime/device.h:35,\r\n                 from ./tensorflow/core/distributed_runtime/master.h:21,\r\n                 from tensorflow/core/distributed_runtime/rpc/grpc_master_service.cc:36:\r\n./tensorflow/core/util/tensor_format.h: In instantiation of 'T tensorflow::GetTensorDim(tensorflow::gtl::ArraySlice<T>, tensorflow::TensorFormat, char) [with T = long long int; tensorflow::gtl::ArraySlice<T> = absl::Span<const long long int>]':\r\n./tensorflow/core/util/tensor_format.h:452:47:   required from here\r\n./tensorflow/core/util/tensor_format.h:420:29: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   CHECK(index >= 0 && index < dimension_attributes.size())\r\n                             ^\r\n./tensorflow/core/platform/macros.h:87:47: note: in definition of macro 'TF_PREDICT_FALSE'\r\n #define TF_PREDICT_FALSE(x) (__builtin_expect(x, 0))\r\n                                               ^\r\n./tensorflow/core/util/tensor_format.h:420:3: note: in expansion of macro 'CHECK'\r\n   CHECK(index >= 0 && index < dimension_attributes.size())\r\n   ^\r\n./tensorflow/core/util/tensor_format.h: In instantiation of 'T tensorflow::GetFilterDim(tensorflow::gtl::ArraySlice<T>, tensorflow::FilterTensorFormat, char) [with T = long long int; tensorflow::gtl::ArraySlice<T> = absl::Span<const long long int>]':\r\n./tensorflow/core/util/tensor_format.h:461:54:   required from here\r\n./tensorflow/core/util/tensor_format.h:435:29: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   CHECK(index >= 0 && index < dimension_attribute.size())\r\n                             ^\r\n./tensorflow/core/platform/macros.h:87:47: note: in definition of macro 'TF_PREDICT_FALSE'\r\n #define TF_PREDICT_FALSE(x) (__builtin_expect(x, 0))\r\n                                               ^\r\n./tensorflow/core/util/tensor_format.h:435:3: note: in expansion of macro 'CHECK'\r\n   CHECK(index >= 0 && index < dimension_attribute.size())\r\n   ^\r\nINFO: From Compiling tensorflow/core/kernels/conv_grad_ops.cc [for host]:\r\nIn file included from ./tensorflow/core/kernels/conv_grad_ops.h:167:0,\r\n                 from tensorflow/core/kernels/conv_grad_ops.cc:21:\r\n./tensorflow/core/util/tensor_format.h: In function 'int tensorflow::GetTensorSpatialDims(int, tensorflow::TensorFormat)':\r\n./tensorflow/core/util/tensor_format.h:124:1: warning: control reaches end of non-void function [-Wreturn-type]\r\n }\r\n ^\r\nINFO: From Compiling tensorflow/cc/gradients/image_grad.cc [for host]:\r\nIn file included from tensorflow/cc/gradients/image_grad.cc:17:0:\r\n./tensorflow/cc/framework/grad_op_registry.h:70:15: warning: 'tensorflow::ops::{anonymous}::unused_ret_val_0' defined but not used [-Wunused-variable]\r\n   static bool unused_ret_val_##ctr =             \\\r\n               ^\r\n./tensorflow/cc/framework/grad_op_registry.h:67:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ'\r\n   REGISTER_GRADIENT_OP_UNIQ(ctr, name, fn)\r\n   ^\r\n./tensorflow/cc/framework/grad_op_registry.h:61:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ_HELPER'\r\n   REGISTER_GRADIENT_OP_UNIQ_HELPER(__COUNTER__, name, fn)\r\n   ^\r\ntensorflow/cc/gradients/image_grad.cc:42:1: note: in expansion of macro 'REGISTER_GRADIENT_OP'\r\n REGISTER_GRADIENT_OP(\"ResizeNearestNeighbor\", ResizeNearestNeighborGradHelper);\r\n ^\r\n./tensorflow/cc/framework/grad_op_registry.h:70:15: warning: 'tensorflow::ops::{anonymous}::unused_ret_val_1' defined but not used [-Wunused-variable]\r\n   static bool unused_ret_val_##ctr =             \\\r\n               ^\r\n./tensorflow/cc/framework/grad_op_registry.h:67:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ'\r\n   REGISTER_GRADIENT_OP_UNIQ(ctr, name, fn)\r\n   ^\r\n./tensorflow/cc/framework/grad_op_registry.h:61:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ_HELPER'\r\n   REGISTER_GRADIENT_OP_UNIQ_HELPER(__COUNTER__, name, fn)\r\n   ^\r\ntensorflow/cc/gradients/image_grad.cc:56:1: note: in expansion of macro 'REGISTER_GRADIENT_OP'\r\n REGISTER_GRADIENT_OP(\"ResizeBilinear\", ResizeBilinearGradHelper);\r\n ^\r\n./tensorflow/cc/framework/grad_op_registry.h:70:15: warning: 'tensorflow::ops::{anonymous}::unused_ret_val_2' defined but not used [-Wunused-variable]\r\n   static bool unused_ret_val_##ctr =             \\\r\n               ^\r\n./tensorflow/cc/framework/grad_op_registry.h:67:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ'\r\n   REGISTER_GRADIENT_OP_UNIQ(ctr, name, fn)\r\n   ^\r\n./tensorflow/cc/framework/grad_op_registry.h:61:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ_HELPER'\r\n   REGISTER_GRADIENT_OP_UNIQ_HELPER(__COUNTER__, name, fn)\r\n   ^\r\ntensorflow/cc/gradients/image_grad.cc:70:1: note: in expansion of macro 'REGISTER_GRADIENT_OP'\r\n REGISTER_GRADIENT_OP(\"ResizeBicubic\", ResizeBicubicGradHelper);\r\n ^\r\nINFO: From Compiling tensorflow/core/kernels/sparse_to_dense_op.cc [for host]:\r\nIn file included from tensorflow/core/kernels/sparse_to_dense_op.cc:38:0:\r\n./tensorflow/core/util/sparse/sparse_tensor.h: In static member function 'static tensorflow::Status tensorflow::sparse::SparseTensor::Create(tensorflow::Tensor, tensorflow::Tensor, const tensorflow::TensorShape&, tensorflow::sparse::SparseTensor::VarDimArray, tensorflow::sparse::SparseTensor*)':\r\n./tensorflow/core/util/sparse/sparse_tensor.h:68:22: warning: 'dims' may be used uninitialized in this function [-Wmaybe-uninitialized]\r\n     if (order.size() != dims) {\r\n                      ^\r\n./tensorflow/core/util/sparse/sparse_tensor.h:66:9: note: 'dims' was declared here\r\n     int dims;\r\n         ^\r\nINFO: From Compiling tensorflow/core/grappler/clusters/virtual_cluster.cc [for host]:\r\nIn file included from ./tensorflow/core/platform/default/logging.h:24:0,\r\n                 from ./tensorflow/core/platform/logging.h:25,\r\n                 from ./tensorflow/core/lib/core/refcount.h:22,\r\n                 from ./tensorflow/core/platform/tensor_coding.h:21,\r\n                 from ./tensorflow/core/framework/resource_handle.h:19,\r\n                 from ./tensorflow/core/framework/allocator.h:24,\r\n                 from ./tensorflow/core/common_runtime/device.h:35,\r\n                 from ./tensorflow/core/common_runtime/device_set.h:23,\r\n                 from ./tensorflow/core/grappler/clusters/virtual_cluster.h:21,\r\n                 from tensorflow/core/grappler/clusters/virtual_cluster.cc:16:\r\n./tensorflow/core/util/tensor_format.h: In instantiation of 'T tensorflow::GetTensorDim(tensorflow::gtl::ArraySlice<T>, tensorflow::TensorFormat, char) [with T = long long int; tensorflow::gtl::ArraySlice<T> = absl::Span<const long long int>]':\r\n./tensorflow/core/util/tensor_format.h:452:47:   required from here\r\n./tensorflow/core/util/tensor_format.h:420:29: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   CHECK(index >= 0 && index < dimension_attributes.size())\r\n                             ^\r\n./tensorflow/core/platform/macros.h:87:47: note: in definition of macro 'TF_PREDICT_FALSE'\r\n #define TF_PREDICT_FALSE(x) (__builtin_expect(x, 0))\r\n                                               ^\r\n./tensorflow/core/util/tensor_format.h:420:3: note: in expansion of macro 'CHECK'\r\n   CHECK(index >= 0 && index < dimension_attributes.size())\r\n   ^\r\n./tensorflow/core/util/tensor_format.h: In instantiation of 'T tensorflow::GetFilterDim(tensorflow::gtl::ArraySlice<T>, tensorflow::FilterTensorFormat, char) [with T = long long int; tensorflow::gtl::ArraySlice<T> = absl::Span<const long long int>]':\r\n./tensorflow/core/util/tensor_format.h:461:54:   required from here\r\n./tensorflow/core/util/tensor_format.h:435:29: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   CHECK(index >= 0 && index < dimension_attribute.size())\r\n                             ^\r\n./tensorflow/core/platform/macros.h:87:47: note: in definition of macro 'TF_PREDICT_FALSE'\r\n #define TF_PREDICT_FALSE(x) (__builtin_expect(x, 0))\r\n                                               ^\r\n./tensorflow/core/util/tensor_format.h:435:3: note: in expansion of macro 'CHECK'\r\n   CHECK(index >= 0 && index < dimension_attribute.size())\r\n   ^\r\nINFO: From Compiling tensorflow/core/util/proto/descriptors.cc [for host]:\r\nIn file included from ./tensorflow/core/platform/default/logging.h:24:0,\r\n                 from ./tensorflow/core/platform/logging.h:25,\r\n                 from ./tensorflow/core/lib/core/refcount.h:22,\r\n                 from ./tensorflow/core/platform/tensor_coding.h:21,\r\n                 from ./tensorflow/core/framework/resource_handle.h:19,\r\n                 from ./tensorflow/core/framework/allocator.h:24,\r\n                 from ./tensorflow/core/framework/op_kernel.h:23,\r\n                 from tensorflow/core/util/proto/descriptors.cc:16:\r\n./tensorflow/core/util/tensor_format.h: In instantiation of 'T tensorflow::GetTensorDim(tensorflow::gtl::ArraySlice<T>, tensorflow::TensorFormat, char) [with T = long long int; tensorflow::gtl::ArraySlice<T> = absl::Span<const long long int>]':\r\n./tensorflow/core/util/tensor_format.h:452:47:   required from here\r\n./tensorflow/core/util/tensor_format.h:420:29: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   CHECK(index >= 0 && index < dimension_attributes.size())\r\n                             ^\r\n./tensorflow/core/platform/macros.h:87:47: note: in definition of macro 'TF_PREDICT_FALSE'\r\n #define TF_PREDICT_FALSE(x) (__builtin_expect(x, 0))\r\n                                               ^\r\n./tensorflow/core/util/tensor_format.h:420:3: note: in expansion of macro 'CHECK'\r\n   CHECK(index >= 0 && index < dimension_attributes.size())\r\n   ^\r\n./tensorflow/core/util/tensor_format.h: In instantiation of 'T tensorflow::GetFilterDim(tensorflow::gtl::ArraySlice<T>, tensorflow::FilterTensorFormat, char) [with T = long long int; tensorflow::gtl::ArraySlice<T> = absl::Span<const long long int>]':\r\n./tensorflow/core/util/tensor_format.h:461:54:   required from here\r\n./tensorflow/core/util/tensor_format.h:435:29: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   CHECK(index >= 0 && index < dimension_attribute.size())\r\n                             ^\r\n./tensorflow/core/platform/macros.h:87:47: note: in definition of macro 'TF_PREDICT_FALSE'\r\n #define TF_PREDICT_FALSE(x) (__builtin_expect(x, 0))\r\n                                               ^\r\n./tensorflow/core/util/tensor_format.h:435:3: note: in expansion of macro 'CHECK'\r\n   CHECK(index >= 0 && index < dimension_attribute.size())\r\n   ^\r\nINFO: From Compiling tensorflow/core/grappler/graph_analyzer/sig_node.cc [for host]:\r\nIn file included from ./tensorflow/core/platform/default/logging.h:24:0,\r\n                 from ./tensorflow/core/platform/logging.h:25,\r\n                 from ./tensorflow/core/lib/core/status.h:25,\r\n                 from ./tensorflow/core/grappler/graph_analyzer/gen_node.h:26,\r\n                 from ./tensorflow/core/grappler/graph_analyzer/sig_node.h:25,\r\n                 from tensorflow/core/grappler/graph_analyzer/sig_node.cc:16:\r\ntensorflow/core/grappler/graph_analyzer/sig_node.cc: In member function 'void tensorflow::grappler::graph_analyzer::SigNode::ComputeTopoHash(int)':\r\ntensorflow/core/grappler/graph_analyzer/sig_node.cc:116:27: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   CHECK(topo_hash_.size() == distance);\r\n                           ^\r\n./tensorflow/core/platform/macros.h:87:47: note: in definition of macro 'TF_PREDICT_FALSE'\r\n #define TF_PREDICT_FALSE(x) (__builtin_expect(x, 0))\r\n                                               ^\r\ntensorflow/core/grappler/graph_analyzer/sig_node.cc:116:3: note: in expansion of macro 'CHECK'\r\n   CHECK(topo_hash_.size() == distance);\r\n   ^\r\ntensorflow/core/grappler/graph_analyzer/sig_node.cc: In member function 'size_t tensorflow::grappler::graph_analyzer::SigNode::GetTopoHash(int) const':\r\ntensorflow/core/grappler/graph_analyzer/sig_node.cc:157:16: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   if (distance >= topo_hash_.size()) {\r\n                ^\r\ntensorflow/core/grappler/graph_analyzer/sig_node.cc: In member function 'void tensorflow::grappler::graph_analyzer::Signature::OrderLinks()':\r\ntensorflow/core/grappler/graph_analyzer/sig_node.cc:396:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n     for (idx = 0; idx < node->hashed_peers_.size(); ++idx) {\r\n                       ^\r\nINFO: From Compiling tensorflow/core/kernels/boosted_trees/stats_ops.cc [for host]:\r\nIn file included from tensorflow/core/kernels/boosted_trees/stats_ops.cc:20:0:\r\n./tensorflow/core/kernels/boosted_trees/tree_helper.h:22:13: warning: 'bool tensorflow::GainsAreEqual(float, float)' defined but not used [-Wunused-function]\r\n static bool GainsAreEqual(const float g1, const float g2) {\r\n             ^\r\nINFO: From Compiling tensorflow/core/grappler/optimizers/data/filter_fusion.cc [for host]:\r\nIn file included from ./tensorflow/core/grappler/graph_view.h:29:0,\r\n                 from ./tensorflow/core/grappler/mutable_graph_view.h:19,\r\n                 from tensorflow/core/grappler/optimizers/data/filter_fusion.cc:22:\r\n./tensorflow/core/grappler/utils.h: In function 'int tensorflow::grappler::NodePositionIfSameNode(const string&, const string&)':\r\n./tensorflow/core/grappler/utils.h:126:49: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n       std::distance(input_it, input_name.end()) < node_name.size()) {\r\n                                                 ^\r\nIn file included from ./tensorflow/core/platform/default/logging.h:24:0,\r\n                 from ./tensorflow/core/platform/logging.h:25,\r\n                 from ./tensorflow/core/lib/core/status.h:25,\r\n                 from ./tensorflow/core/grappler/optimizers/graph_optimizer.h:21,\r\n                 from ./tensorflow/core/grappler/optimizers/custom_graph_optimizer.h:19,\r\n                 from ./tensorflow/core/grappler/optimizers/data/filter_fusion.h:19,\r\n                 from tensorflow/core/grappler/optimizers/data/filter_fusion.cc:16:\r\n./tensorflow/core/util/tensor_format.h: In instantiation of 'T tensorflow::GetTensorDim(tensorflow::gtl::ArraySlice<T>, tensorflow::TensorFormat, char) [with T = long long int; tensorflow::gtl::ArraySlice<T> = absl::Span<const long long int>]':\r\n./tensorflow/core/util/tensor_format.h:452:47:   required from here\r\n./tensorflow/core/util/tensor_format.h:420:29: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   CHECK(index >= 0 && index < dimension_attributes.size())\r\n                             ^\r\n./tensorflow/core/platform/macros.h:87:47: note: in definition of macro 'TF_PREDICT_FALSE'\r\n #define TF_PREDICT_FALSE(x) (__builtin_expect(x, 0))\r\n                                               ^\r\n./tensorflow/core/util/tensor_format.h:420:3: note: in expansion of macro 'CHECK'\r\n   CHECK(index >= 0 && index < dimension_attributes.size())\r\n   ^\r\n./tensorflow/core/util/tensor_format.h: In instantiation of 'T tensorflow::GetFilterDim(tensorflow::gtl::ArraySlice<T>, tensorflow::FilterTensorFormat, char) [with T = long long int; tensorflow::gtl::ArraySlice<T> = absl::Span<const long long int>]':\r\n./tensorflow/core/util/tensor_format.h:461:54:   required from here\r\n./tensorflow/core/util/tensor_format.h:435:29: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   CHECK(index >= 0 && index < dimension_attribute.size())\r\n                             ^\r\n./tensorflow/core/platform/macros.h:87:47: note: in definition of macro 'TF_PREDICT_FALSE'\r\n #define TF_PREDICT_FALSE(x) (__builtin_expect(x, 0))\r\n                                               ^\r\n./tensorflow/core/util/tensor_format.h:435:3: note: in expansion of macro 'CHECK'\r\n   CHECK(index >= 0 && index < dimension_attribute.size())\r\n   ^\r\nINFO: From Compiling tensorflow/core/grappler/utils/frame.cc [for host]:\r\nIn file included from ./tensorflow/core/grappler/utils/frame.h:21:0,\r\n                 from tensorflow/core/grappler/utils/frame.cc:16:\r\n./tensorflow/core/grappler/utils.h: In function 'int tensorflow::grappler::NodePositionIfSameNode(const string&, const string&)':\r\n./tensorflow/core/grappler/utils.h:126:49: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n       std::distance(input_it, input_name.end()) < node_name.size()) {\r\n                                                 ^\r\nINFO: From Compiling tensorflow/core/platform/cloud/oauth_client.cc [for host]:\r\ntensorflow/core/platform/cloud/oauth_client.cc: In member function 'virtual tensorflow::Status tensorflow::OAuthClient::ParseOAuthResponse(tensorflow::StringPiece, tensorflow::uint64, std::__cxx11::string*, tensorflow::uint64*)':\r\ntensorflow/core/platform/cloud/oauth_client.cc:272:16: warning: 'Reader' is deprecated: Use CharReader and CharReaderBuilder instead [-Wdeprecated-declarations]\r\n   Json::Reader reader;\r\n                ^\r\nIn file included from external/jsoncpp_git/include/json/json.h:11:0,\r\n                 from ./tensorflow/core/platform/cloud/oauth_client.h:20,\r\n                 from tensorflow/core/platform/cloud/oauth_client.cc:16:\r\nexternal/jsoncpp_git/include/json/reader.h:35:83: note: declared here\r\n class JSONCPP_DEPRECATED(\"Use CharReader and CharReaderBuilder instead\") JSON_API Reader {\r\n                                                                                   ^\r\ntensorflow/core/platform/cloud/oauth_client.cc:285:53: warning: 'expires_in' may be used uninitialized in this function [-Wmaybe-uninitialized]\r\n   *expiration_timestamp_sec = request_timestamp_sec + expires_in;\r\n                                                     ^\r\nINFO: From Compiling tensorflow/core/kernels/data/experimental/threadpool_dataset_op.cc [for host]:\r\ntensorflow/core/kernels/data/experimental/threadpool_dataset_op.cc: In member function 'virtual void tensorflow::data::{anonymous}::PrivateThreadPoolDatasetOp::MakeDataset(tensorflow::OpKernelContext*, tensorflow::data::DatasetBase*, tensorflow::data::DatasetBase**)':\r\ntensorflow/core/kernels/data/experimental/threadpool_dataset_op.cc:355:50: warning: 'num_threads' may be used uninitialized in this function [-Wmaybe-uninitialized]\r\n     *output = new Dataset(ctx, input, num_threads);\r\n                                                  ^\r\ntensorflow/core/kernels/data/experimental/threadpool_dataset_op.cc: In member function 'virtual void tensorflow::data::{anonymous}::MaxIntraOpParallelismDatasetOp::MakeDataset(tensorflow::OpKernelContext*, tensorflow::data::DatasetBase*, tensorflow::data::DatasetBase**)':\r\ntensorflow/core/kernels/data/experimental/threadpool_dataset_op.cc:256:61: warning: 'max_intra_op_parallelism' may be used uninitialized in this function [-Wmaybe-uninitialized]\r\n           max_intra_op_parallelism_(max_intra_op_parallelism) {\r\n                                                             ^\r\ntensorflow/core/kernels/data/experimental/threadpool_dataset_op.cc:239:11: note: 'max_intra_op_parallelism' was declared here\r\n     int64 max_intra_op_parallelism;\r\n           ^\r\nINFO: From Compiling tensorflow/core/kernels/spacetodepth_op.cc [for host]:\r\nIn file included from ./tensorflow/core/kernels/spacetodepth_op.h:22:0,\r\n                 from tensorflow/core/kernels/spacetodepth_op.cc:24:\r\n./tensorflow/core/util/tensor_format.h: In function 'int tensorflow::GetTensorDimsFromSpatialDims(int, tensorflow::TensorFormat)':\r\n./tensorflow/core/util/tensor_format.h:148:1: warning: control reaches end of non-void function [-Wreturn-type]\r\n }\r\n ^\r\n./tensorflow/core/util/tensor_format.h: In function 'int tensorflow::GetTensorSpatialDims(int, tensorflow::TensorFormat)':\r\n./tensorflow/core/util/tensor_format.h:124:1: warning: control reaches end of non-void function [-Wreturn-type]\r\n }\r\n ^\r\nINFO: From Compiling tensorflow/cc/gradients/data_flow_grad.cc [for host]:\r\nIn file included from tensorflow/cc/gradients/data_flow_grad.cc:20:0:\r\n./tensorflow/cc/framework/grad_op_registry.h:70:15: warning: 'tensorflow::ops::{anonymous}::unused_ret_val_0' defined but not used [-Wunused-variable]\r\n   static bool unused_ret_val_##ctr =             \\\r\n               ^\r\n./tensorflow/cc/framework/grad_op_registry.h:67:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ'\r\n   REGISTER_GRADIENT_OP_UNIQ(ctr, name, fn)\r\n   ^\r\n./tensorflow/cc/framework/grad_op_registry.h:64:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ_HELPER'\r\n   REGISTER_GRADIENT_OP_UNIQ_HELPER(__COUNTER__, name, nullptr)\r\n   ^\r\ntensorflow/cc/gradients/data_flow_grad.cc:27:1: note: in expansion of macro 'REGISTER_NO_GRADIENT_OP'\r\n REGISTER_NO_GRADIENT_OP(\"Queue\");\r\n ^\r\n./tensorflow/cc/framework/grad_op_registry.h:70:15: warning: 'tensorflow::ops::{anonymous}::unused_ret_val_1' defined but not used [-Wunused-variable]\r\n   static bool unused_ret_val_##ctr =             \\\r\n               ^\r\n./tensorflow/cc/framework/grad_op_registry.h:67:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ'\r\n   REGISTER_GRADIENT_OP_UNIQ(ctr, name, fn)\r\n   ^\r\n./tensorflow/cc/framework/grad_op_registry.h:64:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ_HELPER'\r\n   REGISTER_GRADIENT_OP_UNIQ_HELPER(__COUNTER__, name, nullptr)\r\n   ^\r\ntensorflow/cc/gradients/data_flow_grad.cc:28:1: note: in expansion of macro 'REGISTER_NO_GRADIENT_OP'\r\n REGISTER_NO_GRADIENT_OP(\"QueueEnqueue\");\r\n ^\r\n./tensorflow/cc/framework/grad_op_registry.h:70:15: warning: 'tensorflow::ops::{anonymous}::unused_ret_val_2' defined but not used [-Wunused-variable]\r\n   static bool unused_ret_val_##ctr =             \\\r\n               ^\r\n./tensorflow/cc/framework/grad_op_registry.h:67:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ'\r\n   REGISTER_GRADIENT_OP_UNIQ(ctr, name, fn)\r\n   ^\r\n./tensorflow/cc/framework/grad_op_registry.h:64:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ_HELPER'\r\n   REGISTER_GRADIENT_OP_UNIQ_HELPER(__COUNTER__, name, nullptr)\r\n   ^\r\ntensorflow/cc/gradients/data_flow_grad.cc:29:1: note: in expansion of macro 'REGISTER_NO_GRADIENT_OP'\r\n REGISTER_NO_GRADIENT_OP(\"QueueEnqueueMany\");\r\n ^\r\n./tensorflow/cc/framework/grad_op_registry.h:70:15: warning: 'tensorflow::ops::{anonymous}::unused_ret_val_3' defined but not used [-Wunused-variable]\r\n   static bool unused_ret_val_##ctr =             \\\r\n               ^\r\n./tensorflow/cc/framework/grad_op_registry.h:67:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ'\r\n   REGISTER_GRADIENT_OP_UNIQ(ctr, name, fn)\r\n   ^\r\n./tensorflow/cc/framework/grad_op_registry.h:64:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ_HELPER'\r\n   REGISTER_GRADIENT_OP_UNIQ_HELPER(__COUNTER__, name, nullptr)\r\n   ^\r\ntensorflow/cc/gradients/data_flow_grad.cc:30:1: note: in expansion of macro 'REGISTER_NO_GRADIENT_OP'\r\n REGISTER_NO_GRADIENT_OP(\"QueueDequeue\");\r\n ^\r\n./tensorflow/cc/framework/grad_op_registry.h:70:15: warning: 'tensorflow::ops::{anonymous}::unused_ret_val_4' defined but not used [-Wunused-variable]\r\n   static bool unused_ret_val_##ctr =             \\\r\n               ^\r\n./tensorflow/cc/framework/grad_op_registry.h:67:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ'\r\n   REGISTER_GRADIENT_OP_UNIQ(ctr, name, fn)\r\n   ^\r\n./tensorflow/cc/framework/grad_op_registry.h:64:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ_HELPER'\r\n   REGISTER_GRADIENT_OP_UNIQ_HELPER(__COUNTER__, name, nullptr)\r\n   ^\r\ntensorflow/cc/gradients/data_flow_grad.cc:31:1: note: in expansion of macro 'REGISTER_NO_GRADIENT_OP'\r\n REGISTER_NO_GRADIENT_OP(\"QueueDequeueMany\");\r\n ^\r\n./tensorflow/cc/framework/grad_op_registry.h:70:15: warning: 'tensorflow::ops::{anonymous}::unused_ret_val_5' defined but not used [-Wunused-variable]\r\n   static bool unused_ret_val_##ctr =             \\\r\n               ^\r\n./tensorflow/cc/framework/grad_op_registry.h:67:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ'\r\n   REGISTER_GRADIENT_OP_UNIQ(ctr, name, fn)\r\n   ^\r\n./tensorflow/cc/framework/grad_op_registry.h:64:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ_HELPER'\r\n   REGISTER_GRADIENT_OP_UNIQ_HELPER(__COUNTER__, name, nullptr)\r\n   ^\r\ntensorflow/cc/gradients/data_flow_grad.cc:32:1: note: in expansion of macro 'REGISTER_NO_GRADIENT_OP'\r\n REGISTER_NO_GRADIENT_OP(\"QueueDequeueUpTo\");\r\n ^\r\n./tensorflow/cc/framework/grad_op_registry.h:70:15: warning: 'tensorflow::ops::{anonymous}::unused_ret_val_6' defined but not used [-Wunused-variable]\r\n   static bool unused_ret_val_##ctr =             \\\r\n               ^\r\n./tensorflow/cc/framework/grad_op_registry.h:67:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ'\r\n   REGISTER_GRADIENT_OP_UNIQ(ctr, name, fn)\r\n   ^\r\n./tensorflow/cc/framework/grad_op_registry.h:64:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ_HELPER'\r\n   REGISTER_GRADIENT_OP_UNIQ_HELPER(__COUNTER__, name, nullptr)\r\n   ^\r\ntensorflow/cc/gradients/data_flow_grad.cc:33:1: note: in expansion of macro 'REGISTER_NO_GRADIENT_OP'\r\n REGISTER_NO_GRADIENT_OP(\"QueueClose\");\r\n ^\r\n./tensorflow/cc/framework/grad_op_registry.h:70:15: warning: 'tensorflow::ops::{anonymous}::unused_ret_val_7' defined but not used [-Wunused-variable]\r\n   static bool unused_ret_val_##ctr =             \\\r\n               ^\r\n./tensorflow/cc/framework/grad_op_registry.h:67:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ'\r\n   REGISTER_GRADIENT_OP_UNIQ(ctr, name, fn)\r\n   ^\r\n./tensorflow/cc/framework/grad_op_registry.h:64:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ_HELPER'\r\n   REGISTER_GRADIENT_OP_UNIQ_HELPER(__COUNTER__, name, nullptr)\r\n   ^\r\ntensorflow/cc/gradients/data_flow_grad.cc:34:1: note: in expansion of macro 'REGISTER_NO_GRADIENT_OP'\r\n REGISTER_NO_GRADIENT_OP(\"QueueSize\");\r\n ^\r\n./tensorflow/cc/framework/grad_op_registry.h:70:15: warning: 'tensorflow::ops::{anonymous}::unused_ret_val_8' defined but not used [-Wunused-variable]\r\n   static bool unused_ret_val_##ctr =             \\\r\n               ^\r\n./tensorflow/cc/framework/grad_op_registry.h:67:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ'\r\n   REGISTER_GRADIENT_OP_UNIQ(ctr, name, fn)\r\n   ^\r\n./tensorflow/cc/framework/grad_op_registry.h:64:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ_HELPER'\r\n   REGISTER_GRADIENT_OP_UNIQ_HELPER(__COUNTER__, name, nullptr)\r\n   ^\r\ntensorflow/cc/gradients/data_flow_grad.cc:35:1: note: in expansion of macro 'REGISTER_NO_GRADIENT_OP'\r\n REGISTER_NO_GRADIENT_OP(\"Stack\");\r\n ^\r\n./tensorflow/cc/framework/grad_op_registry.h:70:15: warning: 'tensorflow::ops::{anonymous}::unused_ret_val_9' defined but not used [-Wunused-variable]\r\n   static bool unused_ret_val_##ctr =             \\\r\n               ^\r\n./tensorflow/cc/framework/grad_op_registry.h:67:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ'\r\n   REGISTER_GRADIENT_OP_UNIQ(ctr, name, fn)\r\n   ^\r\n./tensorflow/cc/framework/grad_op_registry.h:64:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ_HELPER'\r\n   REGISTER_GRADIENT_OP_UNIQ_HELPER(__COUNTER__, name, nullptr)\r\n   ^\r\ntensorflow/cc/gradients/data_flow_grad.cc:36:1: note: in expansion of macro 'REGISTER_NO_GRADIENT_OP'\r\n REGISTER_NO_GRADIENT_OP(\"StackPush\");\r\n ^\r\n./tensorflow/cc/framework/grad_op_registry.h:70:15: warning: 'tensorflow::ops::{anonymous}::unused_ret_val_10' defined but not used [-Wunused-variable]\r\n   static bool unused_ret_val_##ctr =             \\\r\n               ^\r\n./tensorflow/cc/framework/grad_op_registry.h:67:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ'\r\n   REGISTER_GRADIENT_OP_UNIQ(ctr, name, fn)\r\n   ^\r\n./tensorflow/cc/framework/grad_op_registry.h:64:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ_HELPER'\r\n   REGISTER_GRADIENT_OP_UNIQ_HELPER(__COUNTER__, name, nullptr)\r\n   ^\r\ntensorflow/cc/gradients/data_flow_grad.cc:37:1: note: in expansion of macro 'REGISTER_NO_GRADIENT_OP'\r\n REGISTER_NO_GRADIENT_OP(\"StackPop\");\r\n ^\r\n./tensorflow/cc/framework/grad_op_registry.h:70:15: warning: 'tensorflow::ops::{anonymous}::unused_ret_val_11' defined but not used [-Wunused-variable]\r\n   static bool unused_ret_val_##ctr =             \\\r\n               ^\r\n./tensorflow/cc/framework/grad_op_registry.h:67:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ'\r\n   REGISTER_GRADIENT_OP_UNIQ(ctr, name, fn)\r\n   ^\r\n./tensorflow/cc/framework/grad_op_registry.h:64:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ_HELPER'\r\n   REGISTER_GRADIENT_OP_UNIQ_HELPER(__COUNTER__, name, nullptr)\r\n   ^\r\ntensorflow/cc/gradients/data_flow_grad.cc:38:1: note: in expansion of macro 'REGISTER_NO_GRADIENT_OP'\r\n REGISTER_NO_GRADIENT_OP(\"StackClose\");\r\n ^\r\n./tensorflow/cc/framework/grad_op_registry.h:70:15: warning: 'tensorflow::ops::{anonymous}::unused_ret_val_12' defined but not used [-Wunused-variable]\r\n   static bool unused_ret_val_##ctr =             \\\r\n               ^\r\n./tensorflow/cc/framework/grad_op_registry.h:67:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ'\r\n   REGISTER_GRADIENT_OP_UNIQ(ctr, name, fn)\r\n   ^\r\n./tensorflow/cc/framework/grad_op_registry.h:64:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ_HELPER'\r\n   REGISTER_GRADIENT_OP_UNIQ_HELPER(__COUNTER__, name, nullptr)\r\n   ^\r\ntensorflow/cc/gradients/data_flow_grad.cc:39:1: note: in expansion of macro 'REGISTER_NO_GRADIENT_OP'\r\n REGISTER_NO_GRADIENT_OP(\"GetSessionHandle\");\r\n ^\r\n./tensorflow/cc/framework/grad_op_registry.h:70:15: warning: 'tensorflow::ops::{anonymous}::unused_ret_val_13' defined but not used [-Wunused-variable]\r\n   static bool unused_ret_val_##ctr =             \\\r\n               ^\r\n./tensorflow/cc/framework/grad_op_registry.h:67:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ'\r\n   REGISTER_GRADIENT_OP_UNIQ(ctr, name, fn)\r\n   ^\r\n./tensorflow/cc/framework/grad_op_registry.h:64:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ_HELPER'\r\n   REGISTER_GRADIENT_OP_UNIQ_HELPER(__COUNTER__, name, nullptr)\r\n   ^\r\ntensorflow/cc/gradients/data_flow_grad.cc:40:1: note: in expansion of macro 'REGISTER_NO_GRADIENT_OP'\r\n REGISTER_NO_GRADIENT_OP(\"GetSessionHandleV2\");\r\n ^\r\n./tensorflow/cc/framework/grad_op_registry.h:70:15: warning: 'tensorflow::ops::{anonymous}::unused_ret_val_14' defined but not used [-Wunused-variable]\r\n   static bool unused_ret_val_##ctr =             \\\r\n               ^\r\n./tensorflow/cc/framework/grad_op_registry.h:67:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ'\r\n   REGISTER_GRADIENT_OP_UNIQ(ctr, name, fn)\r\n   ^\r\n./tensorflow/cc/framework/grad_op_registry.h:64:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ_HELPER'\r\n   REGISTER_GRADIENT_OP_UNIQ_HELPER(__COUNTER__, name, nullptr)\r\n   ^\r\ntensorflow/cc/gradients/data_flow_grad.cc:41:1: note: in expansion of macro 'REGISTER_NO_GRADIENT_OP'\r\n REGISTER_NO_GRADIENT_OP(\"GetSessionTensor\");\r\n ^\r\n./tensorflow/cc/framework/grad_op_registry.h:70:15: warning: 'tensorflow::ops::{anonymous}::unused_ret_val_15' defined but not used [-Wunused-variable]\r\n   static bool unused_ret_val_##ctr =             \\\r\n               ^\r\n./tensorflow/cc/framework/grad_op_registry.h:67:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ'\r\n   REGISTER_GRADIENT_OP_UNIQ(ctr, name, fn)\r\n   ^\r\n./tensorflow/cc/framework/grad_op_registry.h:64:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ_HELPER'\r\n   REGISTER_GRADIENT_OP_UNIQ_HELPER(__COUNTER__, name, nullptr)\r\n   ^\r\ntensorflow/cc/gradients/data_flow_grad.cc:42:1: note: in expansion of macro 'REGISTER_NO_GRADIENT_OP'\r\n REGISTER_NO_GRADIENT_OP(\"DeleteSessionTensor\");\r\n ^\r\n./tensorflow/cc/framework/grad_op_registry.h:70:15: warning: 'tensorflow::ops::{anonymous}::unused_ret_val_16' defined but not used [-Wunused-variable]\r\n   static bool unused_ret_val_##ctr =             \\\r\n               ^\r\n./tensorflow/cc/framework/grad_op_registry.h:67:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ'\r\n   REGISTER_GRADIENT_OP_UNIQ(ctr, name, fn)\r\n   ^\r\n./tensorflow/cc/framework/grad_op_registry.h:61:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ_HELPER'\r\n   REGISTER_GRADIENT_OP_UNIQ_HELPER(__COUNTER__, name, fn)\r\n   ^\r\ntensorflow/cc/gradients/data_flow_grad.cc:107:1: note: in expansion of macro 'REGISTER_GRADIENT_OP'\r\n REGISTER_GRADIENT_OP(\"DynamicPartition\", DynamicPartitionGrad);\r\n ^\r\n./tensorflow/cc/framework/grad_op_registry.h:70:15: warning: 'tensorflow::ops::{anonymous}::unused_ret_val_17' defined but not used [-Wunused-variable]\r\n   static bool unused_ret_val_##ctr =             \\\r\n               ^\r\n./tensorflow/cc/framework/grad_op_registry.h:67:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ'\r\n   REGISTER_GRADIENT_OP_UNIQ(ctr, name, fn)\r\n   ^\r\n./tensorflow/cc/framework/grad_op_registry.h:61:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ_HELPER'\r\n   REGISTER_GRADIENT_OP_UNIQ_HELPER(__COUNTER__, name, fn)\r\n   ^\r\ntensorflow/cc/gradients/data_flow_grad.cc:150:1: note: in expansion of macro 'REGISTER_GRADIENT_OP'\r\n REGISTER_GRADIENT_OP(\"DynamicStitch\", DynamicStitchGrad);\r\n ^\r\n./tensorflow/cc/framework/grad_op_registry.h:70:15: warning: 'tensorflow::ops::{anonymous}::unused_ret_val_18' defined but not used [-Wunused-variable]\r\n   static bool unused_ret_val_##ctr =             \\\r\n               ^\r\n./tensorflow/cc/framework/grad_op_registry.h:67:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ'\r\n   REGISTER_GRADIENT_OP_UNIQ(ctr, name, fn)\r\n   ^\r\n./tensorflow/cc/framework/grad_op_registry.h:61:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ_HELPER'\r\n   REGISTER_GRADIENT_OP_UNIQ_HELPER(__COUNTER__, name, fn)\r\n   ^\r\ntensorflow/cc/gradients/data_flow_grad.cc:151:1: note: in expansion of macro 'REGISTER_GRADIENT_OP'\r\n REGISTER_GRADIENT_OP(\"ParallelDynamicStitch\", DynamicStitchGrad);\r\n ^\r\nINFO: From Compiling tensorflow/python/lib/core/py_seq_tensor.cc [for host]:\r\ntensorflow/python/lib/core/py_seq_tensor.cc: In function 'tensorflow::Status tensorflow::PySeqToTensor(PyObject*, PyObject*, tensorflow::Tensor*)':\r\ntensorflow/python/lib/core/py_seq_tensor.cc:499:3: warning: 'infer_dtype' may be used uninitialized in this function [-Wmaybe-uninitialized]\r\n   switch (infer_dtype) {\r\n   ^\r\nINFO: From Compiling tensorflow/python/lib/core/ndarray_tensor.cc [for host]:\r\ntensorflow/python/lib/core/ndarray_tensor.cc: In function 'tensorflow::Status tensorflow::{anonymous}::CopyTF_TensorStringsToPyArray(const TF_Tensor*, tensorflow::uint64, PyArrayObject*)':\r\ntensorflow/python/lib/core/ndarray_tensor.cc:243:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   for (int64 i = 0; i < nelems; ++i) {\r\n                       ^\r\nINFO: From Compiling tensorflow/core/grappler/optimizers/loop_optimizer.cc [for host]:\r\nIn file included from ./tensorflow/core/grappler/optimizers/loop_optimizer.h:22:0,\r\n                 from tensorflow/core/grappler/optimizers/loop_optimizer.cc:16:\r\n./tensorflow/core/grappler/utils.h: In function 'int tensorflow::grappler::NodePositionIfSameNode(const string&, const string&)':\r\n./tensorflow/core/grappler/utils.h:126:49: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n       std::distance(input_it, input_name.end()) < node_name.size()) {\r\n                                                 ^\r\ntensorflow/core/grappler/optimizers/loop_optimizer.cc: In member function 'tensorflow::Status tensorflow::grappler::LoopOptimizer::RemoveDeadBranches(const std::unordered_set<std::__cxx11::basic_string<char> >&, const tensorflow::grappler::NodeMap&, tensorflow::GraphDef*)':\r\ntensorflow/core/grappler/optimizers/loop_optimizer.cc:787:57: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n           if (local_dead_merge_inputs[dead.node].size() ==\r\n                                                         ^\r\nIn file included from ./tensorflow/core/platform/default/logging.h:24:0,\r\n                 from ./tensorflow/core/platform/logging.h:25,\r\n                 from ./tensorflow/core/lib/core/status.h:25,\r\n                 from ./tensorflow/core/lib/core/errors.h:21,\r\n                 from ./tensorflow/core/framework/tensor_shape.h:23,\r\n                 from ./tensorflow/core/framework/partial_tensor_shape.h:20,\r\n                 from ./tensorflow/core/framework/attr_value_util.h:23,\r\n                 from ./tensorflow/core/framework/node_def_util.h:22,\r\n                 from ./tensorflow/core/framework/shape_inference.h:20,\r\n                 from ./tensorflow/core/grappler/costs/graph_properties.h:21,\r\n                 from ./tensorflow/core/grappler/optimizers/loop_optimizer.h:20,\r\n                 from tensorflow/core/grappler/optimizers/loop_optimizer.cc:16:\r\n./tensorflow/core/util/tensor_format.h: In instantiation of 'T tensorflow::GetTensorDim(tensorflow::gtl::ArraySlice<T>, tensorflow::TensorFormat, char) [with T = long long int; tensorflow::gtl::ArraySlice<T> = absl::Span<const long long int>]':\r\n./tensorflow/core/util/tensor_format.h:452:47:   required from here\r\n./tensorflow/core/util/tensor_format.h:420:29: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   CHECK(index >= 0 && index < dimension_attributes.size())\r\n                             ^\r\n./tensorflow/core/platform/macros.h:87:47: note: in definition of macro 'TF_PREDICT_FALSE'\r\n #define TF_PREDICT_FALSE(x) (__builtin_expect(x, 0))\r\n                                               ^\r\n./tensorflow/core/util/tensor_format.h:420:3: note: in expansion of macro 'CHECK'\r\n   CHECK(index >= 0 && index < dimension_attributes.size())\r\n   ^\r\n./tensorflow/core/util/tensor_format.h: In instantiation of 'T tensorflow::GetFilterDim(tensorflow::gtl::ArraySlice<T>, tensorflow::FilterTensorFormat, char) [with T = long long int; tensorflow::gtl::ArraySlice<T> = absl::Span<const long long int>]':\r\n./tensorflow/core/util/tensor_format.h:461:54:   required from here\r\n./tensorflow/core/util/tensor_format.h:435:29: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   CHECK(index >= 0 && index < dimension_attribute.size())\r\n                             ^\r\n./tensorflow/core/platform/macros.h:87:47: note: in definition of macro 'TF_PREDICT_FALSE'\r\n #define TF_PREDICT_FALSE(x) (__builtin_expect(x, 0))\r\n                                               ^\r\n./tensorflow/core/util/tensor_format.h:435:3: note: in expansion of macro 'CHECK'\r\n   CHECK(index >= 0 && index < dimension_attribute.size())\r\n   ^\r\ntensorflow/core/grappler/optimizers/loop_optimizer.cc:661:3: warning: 'constant_switch_value' may be used uninitialized in this function [-Wmaybe-uninitialized]\r\n   if (constant_switch_value == false) {\r\n   ^\r\ntensorflow/core/grappler/optimizers/loop_optimizer.cc:657:8: note: 'constant_switch_value' was declared here\r\n   bool constant_switch_value;\r\n        ^\r\nINFO: From Compiling tensorflow/core/kernels/data/experimental/dense_to_sparse_batch_dataset_op.cc [for host]:\r\ntensorflow/core/kernels/data/experimental/dense_to_sparse_batch_dataset_op.cc: In member function 'virtual void tensorflow::data::{anonymous}::DenseToSparseBatchDatasetOp::MakeDataset(tensorflow::OpKernelContext*, tensorflow::data::DatasetBase*, tensorflow::data::DatasetBase**)':\r\ntensorflow/core/kernels/data/experimental/dense_to_sparse_batch_dataset_op.cc:86:23: warning: 'batch_size' may be used uninitialized in this function [-Wmaybe-uninitialized]\r\n           input_(input) {\r\n                       ^\r\ntensorflow/core/kernels/data/experimental/dense_to_sparse_batch_dataset_op.cc:41:11: note: 'batch_size' was declared here\r\n     int64 batch_size;\r\n           ^\r\nINFO: From Compiling external/icu/icu4c/source/common/rbbitblb.cpp [for host]:\r\nexternal/icu/icu4c/source/common/rbbitblb.cpp: In member function 'bool icu_62::RBBITableBuilder::findDuplCharClassFrom(icu_62::IntPair*)':\r\nexternal/icu/icu4c/source/common/rbbitblb.cpp:1097:14: warning: 'table_dupl' may be used uninitialized in this function [-Wmaybe-uninitialized]\r\n              if (table_base == table_dupl) {\r\n              ^\r\nexternal/icu/icu4c/source/common/rbbitblb.cpp:1097:14: warning: 'table_base' may be used uninitialized in this function [-Wmaybe-uninitialized]\r\nINFO: From Compiling tensorflow/core/grappler/graph_view.cc [for host]:\r\nIn file included from ./tensorflow/core/grappler/graph_view.h:29:0,\r\n                 from tensorflow/core/grappler/graph_view.cc:16:\r\n./tensorflow/core/grappler/utils.h: In function 'int tensorflow::grappler::NodePositionIfSameNode(const string&, const string&)':\r\n./tensorflow/core/grappler/utils.h:126:49: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n       std::distance(input_it, input_name.end()) < node_name.size()) {\r\n                                                 ^\r\nINFO: From Compiling tensorflow/core/kernels/data/parallel_map_iterator.cc [for host]:\r\ntensorflow/core/kernels/data/parallel_map_iterator.cc: In member function 'virtual tensorflow::Status tensorflow::data::{anonymous}::ParallelMapIterator::RestoreInternal(tensorflow::data::IteratorContext*, tensorflow::data::IteratorStateReader*)':\r\ntensorflow/core/kernels/data/parallel_map_iterator.cc:140:26: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n     for (size_t i = 0; i < invocation_results_size; i++) {\r\n                          ^\r\ntensorflow/core/kernels/data/parallel_map_iterator.cc:151:31: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n         if (num_return_values != size) {\r\n                               ^\r\ntensorflow/core/kernels/data/parallel_map_iterator.cc: In lambda function:\r\ntensorflow/core/kernels/data/parallel_map_iterator.cc:258:41: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n              invocation_results_.size() >= num_parallel_calls;\r\n                                         ^\r\nIn file included from ./tensorflow/core/platform/default/logging.h:24:0,\r\n                 from ./tensorflow/core/platform/logging.h:25,\r\n                 from ./tensorflow/core/lib/core/status.h:25,\r\n                 from ./tensorflow/core/lib/core/errors.h:21,\r\n                 from ./tensorflow/core/framework/tensor_shape.h:23,\r\n                 from ./tensorflow/core/framework/partial_tensor_shape.h:20,\r\n                 from ./tensorflow/core/framework/attr_value_util.h:23,\r\n                 from ./tensorflow/core/framework/dataset.h:23,\r\n                 from ./tensorflow/core/kernels/data/parallel_map_iterator.h:20,\r\n                 from tensorflow/core/kernels/data/parallel_map_iterator.cc:15:\r\n./tensorflow/core/util/tensor_format.h: In instantiation of 'T tensorflow::GetTensorDim(tensorflow::gtl::ArraySlice<T>, tensorflow::TensorFormat, char) [with T = long long int; tensorflow::gtl::ArraySlice<T> = absl::Span<const long long int>]':\r\n./tensorflow/core/util/tensor_format.h:452:47:   required from here\r\n./tensorflow/core/util/tensor_format.h:420:29: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   CHECK(index >= 0 && index < dimension_attributes.size())\r\n                             ^\r\n./tensorflow/core/platform/macros.h:87:47: note: in definition of macro 'TF_PREDICT_FALSE'\r\n #define TF_PREDICT_FALSE(x) (__builtin_expect(x, 0))\r\n                                               ^\r\n./tensorflow/core/util/tensor_format.h:420:3: note: in expansion of macro 'CHECK'\r\n   CHECK(index >= 0 && index < dimension_attributes.size())\r\n   ^\r\n./tensorflow/core/util/tensor_format.h: In instantiation of 'T tensorflow::GetFilterDim(tensorflow::gtl::ArraySlice<T>, tensorflow::FilterTensorFormat, char) [with T = long long int; tensorflow::gtl::ArraySlice<T> = absl::Span<const long long int>]':\r\n./tensorflow/core/util/tensor_format.h:461:54:   required from here\r\n./tensorflow/core/util/tensor_format.h:435:29: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   CHECK(index >= 0 && index < dimension_attribute.size())\r\n                             ^\r\n./tensorflow/core/platform/macros.h:87:47: note: in definition of macro 'TF_PREDICT_FALSE'\r\n #define TF_PREDICT_FALSE(x) (__builtin_expect(x, 0))\r\n                                               ^\r\n./tensorflow/core/util/tensor_format.h:435:3: note: in expansion of macro 'CHECK'\r\n   CHECK(index >= 0 && index < dimension_attribute.size())\r\n   ^\r\nINFO: From Compiling tensorflow/core/distributed_runtime/rpc/rpc_rendezvous_mgr.cc [for host]:\r\nIn file included from ./tensorflow/core/platform/default/logging.h:24:0,\r\n                 from ./tensorflow/core/platform/logging.h:25,\r\n                 from ./tensorflow/core/framework/control_flow.h:20,\r\n                 from ./tensorflow/core/framework/rendezvous.h:21,\r\n                 from ./tensorflow/core/distributed_runtime/rendezvous_mgr_interface.h:22,\r\n                 from ./tensorflow/core/distributed_runtime/base_rendezvous_mgr.h:22,\r\n                 from ./tensorflow/core/distributed_runtime/rpc/rpc_rendezvous_mgr.h:19,\r\n                 from tensorflow/core/distributed_runtime/rpc/rpc_rendezvous_mgr.cc:16:\r\n./tensorflow/core/util/tensor_format.h: In instantiation of 'T tensorflow::GetTensorDim(tensorflow::gtl::ArraySlice<T>, tensorflow::TensorFormat, char) [with T = long long int; tensorflow::gtl::ArraySlice<T> = absl::Span<const long long int>]':\r\n./tensorflow/core/util/tensor_format.h:452:47:   required from here\r\n./tensorflow/core/util/tensor_format.h:420:29: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   CHECK(index >= 0 && index < dimension_attributes.size())\r\n                             ^\r\n./tensorflow/core/platform/macros.h:87:47: note: in definition of macro 'TF_PREDICT_FALSE'\r\n #define TF_PREDICT_FALSE(x) (__builtin_expect(x, 0))\r\n                                               ^\r\n./tensorflow/core/util/tensor_format.h:420:3: note: in expansion of macro 'CHECK'\r\n   CHECK(index >= 0 && index < dimension_attributes.size())\r\n   ^\r\n./tensorflow/core/util/tensor_format.h: In instantiation of 'T tensorflow::GetFilterDim(tensorflow::gtl::ArraySlice<T>, tensorflow::FilterTensorFormat, char) [with T = long long int; tensorflow::gtl::ArraySlice<T> = absl::Span<const long long int>]':\r\n./tensorflow/core/util/tensor_format.h:461:54:   required from here\r\n./tensorflow/core/util/tensor_format.h:435:29: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   CHECK(index >= 0 && index < dimension_attribute.size())\r\n                             ^\r\n./tensorflow/core/platform/macros.h:87:47: note: in definition of macro 'TF_PREDICT_FALSE'\r\n #define TF_PREDICT_FALSE(x) (__builtin_expect(x, 0))\r\n                                               ^\r\n./tensorflow/core/util/tensor_format.h:435:3: note: in expansion of macro 'CHECK'\r\n   CHECK(index >= 0 && index < dimension_attribute.size())\r\n   ^\r\nINFO: From Compiling tensorflow/core/kernels/conv_ops_3d.cc [for host]:\r\nIn file included from ./tensorflow/core/kernels/conv_2d.h:23:0,\r\n                 from tensorflow/core/kernels/conv_ops_3d.cc:19:\r\n./tensorflow/core/util/tensor_format.h: In function 'int tensorflow::GetTensorSpatialDims(int, tensorflow::TensorFormat)':\r\n./tensorflow/core/util/tensor_format.h:124:1: warning: control reaches end of non-void function [-Wreturn-type]\r\n }\r\n ^\r\n./tensorflow/core/util/tensor_format.h: In function 'int tensorflow::GetTensorDimsFromSpatialDims(int, tensorflow::TensorFormat)':\r\n./tensorflow/core/util/tensor_format.h:148:1: warning: control reaches end of non-void function [-Wreturn-type]\r\n }\r\n ^\r\nINFO: From Compiling tensorflow/contrib/tensorboard/db/summary_converter.cc [for host]:\r\ntensorflow/contrib/tensorboard/db/summary_converter.cc: In function 'tensorflow::Status tensorflow::AddTensorAsHistogramToSummary(const tensorflow::Tensor&, const string&, tensorflow::Summary*)':\r\ntensorflow/contrib/tensorboard/db/summary_converter.cc:230:26: warning: 'double_val' may be used uninitialized in this function [-Wmaybe-uninitialized]\r\n     histo.Add(double_val);\r\n                          ^\r\nIn file included from ./tensorflow/contrib/tensorboard/db/summary_converter.h:18:0,\r\n                 from tensorflow/contrib/tensorboard/db/summary_converter.cc:15:\r\nbazel-out/host/genfiles/tensorflow/core/framework/summary.pb.h: In function 'tensorflow::Status tensorflow::AddTensorAsScalarToSummary(const tensorflow::Tensor&, const string&, tensorflow::Summary*)':\r\nbazel-out/host/genfiles/tensorflow/core/framework/summary.pb.h:2654:31: warning: 'value' may be used uninitialized in this function [-Wmaybe-uninitialized]\r\n   value_.simple_value_ = value;\r\n                               ^\r\ntensorflow/contrib/tensorboard/db/summary_converter.cc:210:9: note: 'value' was declared here\r\n   float value;\r\n         ^\r\nINFO: From Compiling tensorflow/core/grappler/optimizers/model_pruner.cc [for host]:\r\nIn file included from ./tensorflow/core/grappler/graph_view.h:29:0,\r\n                 from ./tensorflow/core/grappler/mutable_graph_view.h:19,\r\n                 from tensorflow/core/grappler/optimizers/model_pruner.cc:29:\r\n./tensorflow/core/grappler/utils.h: In function 'int tensorflow::grappler::NodePositionIfSameNode(const string&, const string&)':\r\n./tensorflow/core/grappler/utils.h:126:49: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n       std::distance(input_it, input_name.end()) < node_name.size()) {\r\n                                                 ^\r\ntensorflow/core/grappler/optimizers/model_pruner.cc: In function 'tensorflow::Status tensorflow::grappler::SplitIdentityNInputs(tensorflow::GraphDef*, const std::vector<std::__cxx11::basic_string<char> >&, bool*)':\r\ntensorflow/core/grappler/optimizers/model_pruner.cc:388:32: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n         terminal.second.size() >= num_non_control_inputs) {\r\n                                ^\r\nINFO: From Compiling tensorflow/core/profiler/internal/tfprof_code.cc [for host]:\r\nIn file included from ./tensorflow/core/profiler/internal/tfprof_show.h:32:0,\r\n                 from ./tensorflow/core/profiler/internal/tfprof_show_multi.h:32,\r\n                 from ./tensorflow/core/profiler/internal/tfprof_code.h:31,\r\n                 from tensorflow/core/profiler/internal/tfprof_code.cc:16:\r\n./tensorflow/core/profiler/internal/tfprof_tensor.h: In member function 'bool tensorflow::tfprof::TFProfTensor::AddValue(const T&, tensorflow::tfprof::TFProfTensorProto*)':\r\n./tensorflow/core/profiler/internal/tfprof_tensor.h:79:3: warning: no return statement in function returning non-void [-Wreturn-type]\r\n   }\r\n   ^\r\ntensorflow/core/profiler/internal/tfprof_code.cc: In member function 'virtual void tensorflow::tfprof::TFCode::AddNode(tensorflow::tfprof::TFGraphNode*)':\r\ntensorflow/core/profiler/internal/tfprof_code.cc:413:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   for (int i = 0; i < node->call_stack()->traces().size(); ++i) {\r\n                     ^\r\ntensorflow/core/profiler/internal/tfprof_code.cc:420:11: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n     if (i == node->call_stack()->traces().size() - 1) {\r\n           ^\r\ntensorflow/core/profiler/internal/tfprof_code.cc: In member function 'virtual void tensorflow::tfprof::TFCode::Build()':\r\ntensorflow/core/profiler/internal/tfprof_code.cc:438:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n     for (int i = 0; i < fn->call_stack()->traces().size(); ++i) {\r\n                       ^\r\ntensorflow/core/profiler/internal/tfprof_code.cc:443:13: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n       if (i == fn->call_stack()->traces().size() - 1) {\r\n             ^\r\nINFO: From Compiling tensorflow/core/kernels/sparse_split_op.cc [for host]:\r\nIn file included from tensorflow/core/kernels/sparse_split_op.cc:21:0:\r\n./tensorflow/core/util/sparse/sparse_tensor.h: In static member function 'static tensorflow::Status tensorflow::sparse::SparseTensor::Create(tensorflow::Tensor, tensorflow::Tensor, const tensorflow::TensorShape&, tensorflow::sparse::SparseTensor*)':\r\n./tensorflow/core/util/sparse/sparse_tensor.h:68:22: warning: 'dims' may be used uninitialized in this function [-Wmaybe-uninitialized]\r\n     if (order.size() != dims) {\r\n                      ^\r\n./tensorflow/core/util/sparse/sparse_tensor.h:66:9: note: 'dims' was declared here\r\n     int dims;\r\n         ^\r\nINFO: From Compiling tensorflow/core/kernels/queue_base.cc [for host]:\r\nIn file included from ./tensorflow/core/platform/default/logging.h:24:0,\r\n                 from ./tensorflow/core/platform/logging.h:25,\r\n                 from ./tensorflow/core/lib/core/refcount.h:22,\r\n                 from ./tensorflow/core/platform/tensor_coding.h:21,\r\n                 from ./tensorflow/core/framework/resource_handle.h:19,\r\n                 from ./tensorflow/core/framework/allocator.h:24,\r\n                 from ./tensorflow/core/framework/op_kernel.h:23,\r\n                 from ./tensorflow/core/kernels/queue_base.h:23,\r\n                 from tensorflow/core/kernels/queue_base.cc:16:\r\n./tensorflow/core/util/tensor_format.h: In instantiation of 'T tensorflow::GetTensorDim(tensorflow::gtl::ArraySlice<T>, tensorflow::TensorFormat, char) [with T = long long int; tensorflow::gtl::ArraySlice<T> = absl::Span<const long long int>]':\r\n./tensorflow/core/util/tensor_format.h:452:47:   required from here\r\n./tensorflow/core/util/tensor_format.h:420:29: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   CHECK(index >= 0 && index < dimension_attributes.size())\r\n                             ^\r\n./tensorflow/core/platform/macros.h:87:47: note: in definition of macro 'TF_PREDICT_FALSE'\r\n #define TF_PREDICT_FALSE(x) (__builtin_expect(x, 0))\r\n                                               ^\r\n./tensorflow/core/util/tensor_format.h:420:3: note: in expansion of macro 'CHECK'\r\n   CHECK(index >= 0 && index < dimension_attributes.size())\r\n   ^\r\n./tensorflow/core/util/tensor_format.h: In instantiation of 'T tensorflow::GetFilterDim(tensorflow::gtl::ArraySlice<T>, tensorflow::FilterTensorFormat, char) [with T = long long int; tensorflow::gtl::ArraySlice<T> = absl::Span<const long long int>]':\r\n./tensorflow/core/util/tensor_format.h:461:54:   required from here\r\n./tensorflow/core/util/tensor_format.h:435:29: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   CHECK(index >= 0 && index < dimension_attribute.size())\r\n                             ^\r\n./tensorflow/core/platform/macros.h:87:47: note: in definition of macro 'TF_PREDICT_FALSE'\r\n #define TF_PREDICT_FALSE(x) (__builtin_expect(x, 0))\r\n                                               ^\r\n./tensorflow/core/util/tensor_format.h:435:3: note: in expansion of macro 'CHECK'\r\n   CHECK(index >= 0 && index < dimension_attribute.size())\r\n   ^\r\nINFO: From Compiling tensorflow/core/kernels/sparse_tensors_map_ops.cc [for host]:\r\nIn file included from tensorflow/core/kernels/sparse_tensors_map_ops.cc:34:0:\r\n./tensorflow/core/util/sparse/sparse_tensor.h: In static member function 'static tensorflow::Status tensorflow::sparse::SparseTensor::Create(tensorflow::Tensor, tensorflow::Tensor, tensorflow::sparse::SparseTensor::VarDimArray, tensorflow::sparse::SparseTensor::VarDimArray, tensorflow::sparse::SparseTensor*)':\r\n./tensorflow/core/util/sparse/sparse_tensor.h:68:22: warning: 'dims' may be used uninitialized in this function [-Wmaybe-uninitialized]\r\n     if (order.size() != dims) {\r\n                      ^\r\n./tensorflow/core/util/sparse/sparse_tensor.h: In member function 'tensorflow::Status tensorflow::SparseTensorsMap::RetrieveAndClearSparseTensors(tensorflow::OpKernelContext*, const ConstVec&, std::vector<tensorflow::sparse::SparseTensor>*)':\r\n./tensorflow/core/util/sparse/sparse_tensor.h:68:22: warning: 'dims' may be used uninitialized in this function [-Wmaybe-uninitialized]\r\n./tensorflow/core/util/sparse/sparse_tensor.h:66:9: note: 'dims' was declared here\r\n     int dims;\r\n         ^\r\nINFO: From Compiling tensorflow/core/distributed_runtime/scheduler.cc [for host]:\r\nIn file included from ./tensorflow/core/platform/default/logging.h:24:0,\r\n                 from ./tensorflow/core/platform/logging.h:25,\r\n                 from ./tensorflow/core/lib/core/refcount.h:22,\r\n                 from ./tensorflow/core/platform/tensor_coding.h:21,\r\n                 from ./tensorflow/core/framework/resource_handle.h:19,\r\n                 from ./tensorflow/core/framework/allocator.h:24,\r\n                 from ./tensorflow/core/common_runtime/device.h:35,\r\n                 from ./tensorflow/core/distributed_runtime/scheduler.h:25,\r\n                 from tensorflow/core/distributed_runtime/scheduler.cc:16:\r\n./tensorflow/core/util/tensor_format.h: In instantiation of 'T tensorflow::GetTensorDim(tensorflow::gtl::ArraySlice<T>, tensorflow::TensorFormat, char) [with T = long long int; tensorflow::gtl::ArraySlice<T> = absl::Span<const long long int>]':\r\n./tensorflow/core/util/tensor_format.h:452:47:   required from here\r\n./tensorflow/core/util/tensor_format.h:420:29: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   CHECK(index >= 0 && index < dimension_attributes.size())\r\n                             ^\r\n./tensorflow/core/platform/macros.h:87:47: note: in definition of macro 'TF_PREDICT_FALSE'\r\n #define TF_PREDICT_FALSE(x) (__builtin_expect(x, 0))\r\n                                               ^\r\n./tensorflow/core/util/tensor_format.h:420:3: note: in expansion of macro 'CHECK'\r\n   CHECK(index >= 0 && index < dimension_attributes.size())\r\n   ^\r\n./tensorflow/core/util/tensor_format.h: In instantiation of 'T tensorflow::GetFilterDim(tensorflow::gtl::ArraySlice<T>, tensorflow::FilterTensorFormat, char) [with T = long long int; tensorflow::gtl::ArraySlice<T> = absl::Span<const long long int>]':\r\n./tensorflow/core/util/tensor_format.h:461:54:   required from here\r\n./tensorflow/core/util/tensor_format.h:435:29: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   CHECK(index >= 0 && index < dimension_attribute.size())\r\n                             ^\r\n./tensorflow/core/platform/macros.h:87:47: note: in definition of macro 'TF_PREDICT_FALSE'\r\n #define TF_PREDICT_FALSE(x) (__builtin_expect(x, 0))\r\n                                               ^\r\n./tensorflow/core/util/tensor_format.h:435:3: note: in expansion of macro 'CHECK'\r\n   CHECK(index >= 0 && index < dimension_attribute.size())\r\n   ^\r\nINFO: From Compiling tensorflow/core/kernels/padding_fifo_queue.cc [for host]:\r\nIn file included from ./tensorflow/core/platform/default/logging.h:24:0,\r\n                 from ./tensorflow/core/platform/logging.h:25,\r\n                 from ./tensorflow/core/lib/core/refcount.h:22,\r\n                 from ./tensorflow/core/platform/tensor_coding.h:21,\r\n                 from ./tensorflow/core/framework/resource_handle.h:19,\r\n                 from ./tensorflow/core/framework/register_types.h:21,\r\n                 from tensorflow/core/kernels/padding_fifo_queue.cc:22:\r\n./tensorflow/core/util/tensor_format.h: In instantiation of 'T tensorflow::GetTensorDim(tensorflow::gtl::ArraySlice<T>, tensorflow::TensorFormat, char) [with T = long long int; tensorflow::gtl::ArraySlice<T> = absl::Span<const long long int>]':\r\n./tensorflow/core/util/tensor_format.h:452:47:   required from here\r\n./tensorflow/core/util/tensor_format.h:420:29: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   CHECK(index >= 0 && index < dimension_attributes.size())\r\n                             ^\r\n./tensorflow/core/platform/macros.h:87:47: note: in definition of macro 'TF_PREDICT_FALSE'\r\n #define TF_PREDICT_FALSE(x) (__builtin_expect(x, 0))\r\n                                               ^\r\n./tensorflow/core/util/tensor_format.h:420:3: note: in expansion of macro 'CHECK'\r\n   CHECK(index >= 0 && index < dimension_attributes.size())\r\n   ^\r\n./tensorflow/core/util/tensor_format.h: In instantiation of 'T tensorflow::GetFilterDim(tensorflow::gtl::ArraySlice<T>, tensorflow::FilterTensorFormat, char) [with T = long long int; tensorflow::gtl::ArraySlice<T> = absl::Span<const long long int>]':\r\n./tensorflow/core/util/tensor_format.h:461:54:   required from here\r\n./tensorflow/core/util/tensor_format.h:435:29: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   CHECK(index >= 0 && index < dimension_attribute.size())\r\n                             ^\r\n./tensorflow/core/platform/macros.h:87:47: note: in definition of macro 'TF_PREDICT_FALSE'\r\n #define TF_PREDICT_FALSE(x) (__builtin_expect(x, 0))\r\n                                               ^\r\n./tensorflow/core/util/tensor_format.h:435:3: note: in expansion of macro 'CHECK'\r\n   CHECK(index >= 0 && index < dimension_attribute.size())\r\n   ^\r\nINFO: From Compiling tensorflow/core/kernels/training_op_helpers.cc [for host]:\r\nIn file included from ./tensorflow/core/platform/default/logging.h:24:0,\r\n                 from ./tensorflow/core/platform/logging.h:25,\r\n                 from ./tensorflow/core/lib/core/refcount.h:22,\r\n                 from ./tensorflow/core/platform/tensor_coding.h:21,\r\n                 from ./tensorflow/core/framework/resource_handle.h:19,\r\n                 from ./tensorflow/core/framework/allocator.h:24,\r\n                 from ./tensorflow/core/framework/op_kernel.h:23,\r\n                 from ./tensorflow/core/kernels/training_op_helpers.h:19,\r\n                 from tensorflow/core/kernels/training_op_helpers.cc:16:\r\n./tensorflow/core/util/tensor_format.h: In instantiation of 'T tensorflow::GetTensorDim(tensorflow::gtl::ArraySlice<T>, tensorflow::TensorFormat, char) [with T = long long int; tensorflow::gtl::ArraySlice<T> = absl::Span<const long long int>]':\r\n./tensorflow/core/util/tensor_format.h:452:47:   required from here\r\n./tensorflow/core/util/tensor_format.h:420:29: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   CHECK(index >= 0 && index < dimension_attributes.size())\r\n                             ^\r\n./tensorflow/core/platform/macros.h:87:47: note: in definition of macro 'TF_PREDICT_FALSE'\r\n #define TF_PREDICT_FALSE(x) (__builtin_expect(x, 0))\r\n                                               ^\r\n./tensorflow/core/util/tensor_format.h:420:3: note: in expansion of macro 'CHECK'\r\n   CHECK(index >= 0 && index < dimension_attributes.size())\r\n   ^\r\n./tensorflow/core/util/tensor_format.h: In instantiation of 'T tensorflow::GetFilterDim(tensorflow::gtl::ArraySlice<T>, tensorflow::FilterTensorFormat, char) [with T = long long int; tensorflow::gtl::ArraySlice<T> = absl::Span<const long long int>]':\r\n./tensorflow/core/util/tensor_format.h:461:54:   required from here\r\n./tensorflow/core/util/tensor_format.h:435:29: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   CHECK(index >= 0 && index < dimension_attribute.size())\r\n                             ^\r\n./tensorflow/core/platform/macros.h:87:47: note: in definition of macro 'TF_PREDICT_FALSE'\r\n #define TF_PREDICT_FALSE(x) (__builtin_expect(x, 0))\r\n                                               ^\r\n./tensorflow/core/util/tensor_format.h:435:3: note: in expansion of macro 'CHECK'\r\n   CHECK(index >= 0 && index < dimension_attribute.size())\r\n   ^\r\nINFO: From Compiling tensorflow/core/profiler/internal/tfprof_scope.cc [for host]:\r\nIn file included from ./tensorflow/core/profiler/internal/tfprof_show.h:32:0,\r\n                 from ./tensorflow/core/profiler/internal/tfprof_scope.h:32,\r\n                 from tensorflow/core/profiler/internal/tfprof_scope.cc:16:\r\n./tensorflow/core/profiler/internal/tfprof_tensor.h: In member function 'bool tensorflow::tfprof::TFProfTensor::AddValue(const T&, tensorflow::tfprof::TFProfTensorProto*)':\r\n./tensorflow/core/profiler/internal/tfprof_tensor.h:79:3: warning: no return statement in function returning non-void [-Wreturn-type]\r\n   }\r\n   ^\r\nINFO: From Compiling tensorflow/cc/gradients/nn_grad.cc [for host]:\r\nIn file included from tensorflow/cc/gradients/nn_grad.cc:20:0:\r\n./tensorflow/cc/framework/grad_op_registry.h:70:15: warning: 'tensorflow::ops::{anonymous}::unused_ret_val_0' defined but not used [-Wunused-variable]\r\n   static bool unused_ret_val_##ctr =             \\\r\n               ^\r\n./tensorflow/cc/framework/grad_op_registry.h:67:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ'\r\n   REGISTER_GRADIENT_OP_UNIQ(ctr, name, fn)\r\n   ^\r\n./tensorflow/cc/framework/grad_op_registry.h:61:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ_HELPER'\r\n   REGISTER_GRADIENT_OP_UNIQ_HELPER(__COUNTER__, name, fn)\r\n   ^\r\ntensorflow/cc/gradients/nn_grad.cc:48:1: note: in expansion of macro 'REGISTER_GRADIENT_OP'\r\n REGISTER_GRADIENT_OP(\"Softmax\", SoftmaxGrad);\r\n ^\r\n./tensorflow/cc/framework/grad_op_registry.h:70:15: warning: 'tensorflow::ops::{anonymous}::unused_ret_val_1' defined but not used [-Wunused-variable]\r\n   static bool unused_ret_val_##ctr =             \\\r\n               ^\r\n./tensorflow/cc/framework/grad_op_registry.h:67:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ'\r\n   REGISTER_GRADIENT_OP_UNIQ(ctr, name, fn)\r\n   ^\r\n./tensorflow/cc/framework/grad_op_registry.h:61:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ_HELPER'\r\n   REGISTER_GRADIENT_OP_UNIQ_HELPER(__COUNTER__, name, fn)\r\n   ^\r\ntensorflow/cc/gradients/nn_grad.cc:113:1: note: in expansion of macro 'REGISTER_GRADIENT_OP'\r\n REGISTER_GRADIENT_OP(\"SoftmaxCrossEntropyWithLogits\",\r\n ^\r\n./tensorflow/cc/framework/grad_op_registry.h:70:15: warning: 'tensorflow::ops::{anonymous}::unused_ret_val_2' defined but not used [-Wunused-variable]\r\n   static bool unused_ret_val_##ctr =             \\\r\n               ^\r\n./tensorflow/cc/framework/grad_op_registry.h:67:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ'\r\n   REGISTER_GRADIENT_OP_UNIQ(ctr, name, fn)\r\n   ^\r\n./tensorflow/cc/framework/grad_op_registry.h:61:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ_HELPER'\r\n   REGISTER_GRADIENT_OP_UNIQ_HELPER(__COUNTER__, name, fn)\r\n   ^\r\ntensorflow/cc/gradients/nn_grad.cc:126:1: note: in expansion of macro 'REGISTER_GRADIENT_OP'\r\n REGISTER_GRADIENT_OP(\"LogSoftmax\", LogSoftmaxGrad);\r\n ^\r\n./tensorflow/cc/framework/grad_op_registry.h:70:15: warning: 'tensorflow::ops::{anonymous}::unused_ret_val_3' defined but not used [-Wunused-variable]\r\n   static bool unused_ret_val_##ctr =             \\\r\n               ^\r\n./tensorflow/cc/framework/grad_op_registry.h:67:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ'\r\n   REGISTER_GRADIENT_OP_UNIQ(ctr, name, fn)\r\n   ^\r\n./tensorflow/cc/framework/grad_op_registry.h:61:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ_HELPER'\r\n   REGISTER_GRADIENT_OP_UNIQ_HELPER(__COUNTER__, name, fn)\r\n   ^\r\ntensorflow/cc/gradients/nn_grad.cc:135:1: note: in expansion of macro 'REGISTER_GRADIENT_OP'\r\n REGISTER_GRADIENT_OP(\"Relu\", ReluGradHelper);\r\n ^\r\n./tensorflow/cc/framework/grad_op_registry.h:70:15: warning: 'tensorflow::ops::{anonymous}::unused_ret_val_4' defined but not used [-Wunused-variable]\r\n   static bool unused_ret_val_##ctr =             \\\r\n               ^\r\n./tensorflow/cc/framework/grad_op_registry.h:67:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ'\r\n   REGISTER_GRADIENT_OP_UNIQ(ctr, name, fn)\r\n   ^\r\n./tensorflow/cc/framework/grad_op_registry.h:61:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ_HELPER'\r\n   REGISTER_GRADIENT_OP_UNIQ_HELPER(__COUNTER__, name, fn)\r\n   ^\r\ntensorflow/cc/gradients/nn_grad.cc:144:1: note: in expansion of macro 'REGISTER_GRADIENT_OP'\r\n REGISTER_GRADIENT_OP(\"Relu6\", Relu6GradHelper);\r\n ^\r\n./tensorflow/cc/framework/grad_op_registry.h:70:15: warning: 'tensorflow::ops::{anonymous}::unused_ret_val_5' defined but not used [-Wunused-variable]\r\n   static bool unused_ret_val_##ctr =             \\\r\n               ^\r\n./tensorflow/cc/framework/grad_op_registry.h:67:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ'\r\n   REGISTER_GRADIENT_OP_UNIQ(ctr, name, fn)\r\n   ^\r\n./tensorflow/cc/framework/grad_op_registry.h:61:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ_HELPER'\r\n   REGISTER_GRADIENT_OP_UNIQ_HELPER(__COUNTER__, name, fn)\r\n   ^\r\ntensorflow/cc/gradients/nn_grad.cc:157:1: note: in expansion of macro 'REGISTER_GRADIENT_OP'\r\n REGISTER_GRADIENT_OP(\"LeakyRelu\", LeakyReluGradHelper);\r\n ^\r\n./tensorflow/cc/framework/grad_op_registry.h:70:15: warning: 'tensorflow::ops::{anonymous}::unused_ret_val_6' defined but not used [-Wunused-variable]\r\n   static bool unused_ret_val_##ctr =             \\\r\n               ^\r\n./tensorflow/cc/framework/grad_op_registry.h:67:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ'\r\n   REGISTER_GRADIENT_OP_UNIQ(ctr, name, fn)\r\n   ^\r\n./tensorflow/cc/framework/grad_op_registry.h:61:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ_HELPER'\r\n   REGISTER_GRADIENT_OP_UNIQ_HELPER(__COUNTER__, name, fn)\r\n   ^\r\ntensorflow/cc/gradients/nn_grad.cc:171:1: note: in expansion of macro 'REGISTER_GRADIENT_OP'\r\n REGISTER_GRADIENT_OP(\"LeakyReluGrad\", LeakyReluGradGradHelper);\r\n ^\r\n./tensorflow/cc/framework/grad_op_registry.h:70:15: warning: 'tensorflow::ops::{anonymous}::unused_ret_val_7' defined but not used [-Wunused-variable]\r\n   static bool unused_ret_val_##ctr =             \\\r\n               ^\r\n./tensorflow/cc/framework/grad_op_registry.h:67:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ'\r\n   REGISTER_GRADIENT_OP_UNIQ(ctr, name, fn)\r\n   ^\r\n./tensorflow/cc/framework/grad_op_registry.h:61:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ_HELPER'\r\n   REGISTER_GRADIENT_OP_UNIQ_HELPER(__COUNTER__, name, fn)\r\n   ^\r\ntensorflow/cc/gradients/nn_grad.cc:180:1: note: in expansion of macro 'REGISTER_GRADIENT_OP'\r\n REGISTER_GRADIENT_OP(\"Elu\", EluGradHelper);\r\n ^\r\n./tensorflow/cc/framework/grad_op_registry.h:70:15: warning: 'tensorflow::ops::{anonymous}::unused_ret_val_8' defined but not used [-Wunused-variable]\r\n   static bool unused_ret_val_##ctr =             \\\r\n               ^\r\n./tensorflow/cc/framework/grad_op_registry.h:67:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ'\r\n   REGISTER_GRADIENT_OP_UNIQ(ctr, name, fn)\r\n   ^\r\n./tensorflow/cc/framework/grad_op_registry.h:61:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ_HELPER'\r\n   REGISTER_GRADIENT_OP_UNIQ_HELPER(__COUNTER__, name, fn)\r\n   ^\r\ntensorflow/cc/gradients/nn_grad.cc:189:1: note: in expansion of macro 'REGISTER_GRADIENT_OP'\r\n REGISTER_GRADIENT_OP(\"Selu\", SeluGradHelper);\r\n ^\r\n./tensorflow/cc/framework/grad_op_registry.h:70:15: warning: 'tensorflow::ops::{anonymous}::unused_ret_val_9' defined but not used [-Wunused-variable]\r\n   static bool unused_ret_val_##ctr =             \\\r\n               ^\r\n./tensorflow/cc/framework/grad_op_registry.h:67:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ'\r\n   REGISTER_GRADIENT_OP_UNIQ(ctr, name, fn)\r\n   ^\r\n./tensorflow/cc/framework/grad_op_registry.h:61:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ_HELPER'\r\n   REGISTER_GRADIENT_OP_UNIQ_HELPER(__COUNTER__, name, fn)\r\n   ^\r\ntensorflow/cc/gradients/nn_grad.cc:197:1: note: in expansion of macro 'REGISTER_GRADIENT_OP'\r\n REGISTER_GRADIENT_OP(\"L2Loss\", L2LossGrad);\r\n ^\r\n./tensorflow/cc/framework/grad_op_registry.h:70:15: warning: 'tensorflow::ops::{anonymous}::unused_ret_val_10' defined but not used [-Wunused-variable]\r\n   static bool unused_ret_val_##ctr =             \\\r\n               ^\r\n./tensorflow/cc/framework/grad_op_registry.h:67:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ'\r\n   REGISTER_GRADIENT_OP_UNIQ(ctr, name, fn)\r\n   ^\r\n./tensorflow/cc/framework/grad_op_registry.h:61:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ_HELPER'\r\n   REGISTER_GRADIENT_OP_UNIQ_HELPER(__COUNTER__, name, fn)\r\n   ^\r\ntensorflow/cc/gradients/nn_grad.cc:211:1: note: in expansion of macro 'REGISTER_GRADIENT_OP'\r\n REGISTER_GRADIENT_OP(\"BiasAdd\", BiasAddGradHelper);\r\n ^\r\n./tensorflow/cc/framework/grad_op_registry.h:70:15: warning: 'tensorflow::ops::{anonymous}::unused_ret_val_11' defined but not used [-Wunused-variable]\r\n   static bool unused_ret_val_##ctr =             \\\r\n               ^\r\n./tensorflow/cc/framework/grad_op_registry.h:67:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ'\r\n   REGISTER_GRADIENT_OP_UNIQ(ctr, name, fn)\r\n   ^\r\n./tensorflow/cc/framework/grad_op_registry.h:61:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ_HELPER'\r\n   REGISTER_GRADIENT_OP_UNIQ_HELPER(__COUNTER__, name, fn)\r\n   ^\r\ntensorflow/cc/gradients/nn_grad.cc:238:1: note: in expansion of macro 'REGISTER_GRADIENT_OP'\r\n REGISTER_GRADIENT_OP(\"Conv2D\", Conv2DGrad);\r\n ^\r\n./tensorflow/cc/framework/grad_op_registry.h:70:15: warning: 'tensorflow::ops::{anonymous}::unused_ret_val_12' defined but not used [-Wunused-variable]\r\n   static bool unused_ret_val_##ctr =             \\\r\n               ^\r\n./tensorflow/cc/framework/grad_op_registry.h:67:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ'\r\n   REGISTER_GRADIENT_OP_UNIQ(ctr, name, fn)\r\n   ^\r\n./tensorflow/cc/framework/grad_op_registry.h:61:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ_HELPER'\r\n   REGISTER_GRADIENT_OP_UNIQ_HELPER(__COUNTER__, name, fn)\r\n   ^\r\ntensorflow/cc/gradients/nn_grad.cc:258:1: note: in expansion of macro 'REGISTER_GRADIENT_OP'\r\n REGISTER_GRADIENT_OP(\"MaxPool\", MaxPoolGradHelper);\r\n ^\r\n./tensorflow/cc/framework/grad_op_registry.h:70:15: warning: 'tensorflow::ops::{anonymous}::unused_ret_val_13' defined but not used [-Wunused-variable]\r\n   static bool unused_ret_val_##ctr =             \\\r\n               ^\r\n./tensorflow/cc/framework/grad_op_registry.h:67:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ'\r\n   REGISTER_GRADIENT_OP_UNIQ(ctr, name, fn)\r\n   ^\r\n./tensorflow/cc/framework/grad_op_registry.h:61:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ_HELPER'\r\n   REGISTER_GRADIENT_OP_UNIQ_HELPER(__COUNTER__, name, fn)\r\n   ^\r\ntensorflow/cc/gradients/nn_grad.cc:276:1: note: in expansion of macro 'REGISTER_GRADIENT_OP'\r\n REGISTER_GRADIENT_OP(\"MaxPoolV2\", MaxPoolGradV2Helper);\r\n ^\r\n./tensorflow/cc/framework/grad_op_registry.h:70:15: warning: 'tensorflow::ops::{anonymous}::unused_ret_val_14' defined but not used [-Wunused-variable]\r\n   static bool unused_ret_val_##ctr =             \\\r\n               ^\r\n./tensorflow/cc/framework/grad_op_registry.h:67:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ'\r\n   REGISTER_GRADIENT_OP_UNIQ(ctr, name, fn)\r\n   ^\r\n./tensorflow/cc/framework/grad_op_registry.h:61:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ_HELPER'\r\n   REGISTER_GRADIENT_OP_UNIQ_HELPER(__COUNTER__, name, fn)\r\n   ^\r\ntensorflow/cc/gradients/nn_grad.cc:297:1: note: in expansion of macro 'REGISTER_GRADIENT_OP'\r\n REGISTER_GRADIENT_OP(\"MaxPool3D\", MaxPool3DGradHelper);\r\n ^\r\n./tensorflow/cc/framework/grad_op_registry.h:70:15: warning: 'tensorflow::ops::{anonymous}::unused_ret_val_15' defined but not used [-Wunused-variable]\r\n   static bool unused_ret_val_##ctr =             \\\r\n               ^\r\n./tensorflow/cc/framework/grad_op_registry.h:67:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ'\r\n   REGISTER_GRADIENT_OP_UNIQ(ctr, name, fn)\r\n   ^\r\n./tensorflow/cc/framework/grad_op_registry.h:61:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ_HELPER'\r\n   REGISTER_GRADIENT_OP_UNIQ_HELPER(__COUNTER__, name, fn)\r\n   ^\r\ntensorflow/cc/gradients/nn_grad.cc:318:1: note: in expansion of macro 'REGISTER_GRADIENT_OP'\r\n REGISTER_GRADIENT_OP(\"AvgPool\", AvgPoolGradHelper);\r\n ^\r\n./tensorflow/cc/framework/grad_op_registry.h:70:15: warning: 'tensorflow::ops::{anonymous}::unused_ret_val_16' defined but not used [-Wunused-variable]\r\n   static bool unused_ret_val_##ctr =             \\\r\n               ^\r\n./tensorflow/cc/framework/grad_op_registry.h:67:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ'\r\n   REGISTER_GRADIENT_OP_UNIQ(ctr, name, fn)\r\n   ^\r\n./tensorflow/cc/framework/grad_op_registry.h:61:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ_HELPER'\r\n   REGISTER_GRADIENT_OP_UNIQ_HELPER(__COUNTER__, name, fn)\r\n   ^\r\ntensorflow/cc/gradients/nn_grad.cc:339:1: note: in expansion of macro 'REGISTER_GRADIENT_OP'\r\n REGISTER_GRADIENT_OP(\"AvgPool3D\", AvgPool3DGradHelper);\r\n ^\r\n./tensorflow/cc/framework/grad_op_registry.h:70:15: warning: 'tensorflow::ops::{anonymous}::unused_ret_val_17' defined but not used [-Wunused-variable]\r\n   static bool unused_ret_val_##ctr =             \\\r\n               ^\r\n./tensorflow/cc/framework/grad_op_registry.h:67:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ'\r\n   REGISTER_GRADIENT_OP_UNIQ(ctr, name, fn)\r\n   ^\r\n./tensorflow/cc/framework/grad_op_registry.h:61:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ_HELPER'\r\n   REGISTER_GRADIENT_OP_UNIQ_HELPER(__COUNTER__, name, fn)\r\n   ^\r\ntensorflow/cc/gradients/nn_grad.cc:348:1: note: in expansion of macro 'REGISTER_GRADIENT_OP'\r\n REGISTER_GRADIENT_OP(\"LRN\", LRNGradHelper);\r\n ^\r\n./tensorflow/cc/framework/grad_op_registry.h:70:15: warning: 'tensorflow::ops::{anonymous}::unused_ret_val_18' defined but not used [-Wunused-variable]\r\n   static bool unused_ret_val_##ctr =             \\\r\n               ^\r\n./tensorflow/cc/framework/grad_op_registry.h:67:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ'\r\n   REGISTER_GRADIENT_OP_UNIQ(ctr, name, fn)\r\n   ^\r\n./tensorflow/cc/framework/grad_op_registry.h:61:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ_HELPER'\r\n   REGISTER_GRADIENT_OP_UNIQ_HELPER(__COUNTER__, name, fn)\r\n   ^\r\ntensorflow/cc/gradients/nn_grad.cc:357:1: note: in expansion of macro 'REGISTER_GRADIENT_OP'\r\n REGISTER_GRADIENT_OP(\"Softplus\", SoftplusGradHelper);\r\n ^\r\n./tensorflow/cc/framework/grad_op_registry.h:70:15: warning: 'tensorflow::ops::{anonymous}::unused_ret_val_19' defined but not used [-Wunused-variable]\r\n   static bool unused_ret_val_##ctr =             \\\r\n               ^\r\n./tensorflow/cc/framework/grad_op_registry.h:67:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ'\r\n   REGISTER_GRADIENT_OP_UNIQ(ctr, name, fn)\r\n   ^\r\n./tensorflow/cc/framework/grad_op_registry.h:61:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ_HELPER'\r\n   REGISTER_GRADIENT_OP_UNIQ_HELPER(__COUNTER__, name, fn)\r\n   ^\r\ntensorflow/cc/gradients/nn_grad.cc:366:1: note: in expansion of macro 'REGISTER_GRADIENT_OP'\r\n REGISTER_GRADIENT_OP(\"Softsign\", SoftsignGradHelper);\r\n ^\r\n./tensorflow/cc/framework/grad_op_registry.h:70:15: warning: 'tensorflow::ops::{anonymous}::unused_ret_val_20' defined but not used [-Wunused-variable]\r\n   static bool unused_ret_val_##ctr =             \\\r\n               ^\r\n./tensorflow/cc/framework/grad_op_registry.h:67:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ'\r\n   REGISTER_GRADIENT_OP_UNIQ(ctr, name, fn)\r\n   ^\r\n./tensorflow/cc/framework/grad_op_registry.h:61:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ_HELPER'\r\n   REGISTER_GRADIENT_OP_UNIQ_HELPER(__COUNTER__, name, fn)\r\n   ^\r\ntensorflow/cc/gradients/nn_grad.cc:381:1: note: in expansion of macro 'REGISTER_GRADIENT_OP'\r\n REGISTER_GRADIENT_OP(\"FractionalAvgPool\", FractionalAvgPoolGradHelper);\r\n ^\r\n./tensorflow/cc/framework/grad_op_registry.h:70:15: warning: 'tensorflow::ops::{anonymous}::unused_ret_val_21' defined but not used [-Wunused-variable]\r\n   static bool unused_ret_val_##ctr =             \\\r\n               ^\r\n./tensorflow/cc/framework/grad_op_registry.h:67:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ'\r\n   REGISTER_GRADIENT_OP_UNIQ(ctr, name, fn)\r\n   ^\r\n./tensorflow/cc/framework/grad_op_registry.h:61:3: note: in expansion of macro 'REGISTER_GRADIENT_OP_UNIQ_HELPER'\r\n   REGISTER_GRADIENT_OP_UNIQ_HELPER(__COUNTER__, name, fn)\r\n   ^\r\ntensorflow/cc/gradients/nn_grad.cc:395:1: note: in expansion of macro 'REGISTER_GRADIENT_OP'\r\n REGISTER_GRADIENT_OP(\"FractionalMaxPool\", FractionalMaxPoolGradHelper);\r\n ^\r\nINFO: From Compiling tensorflow/core/kernels/tensor_forest/prediction_ops.cc [for host]:\r\nIn file included from ./tensorflow/core/platform/tensor_coding.h:21:0,\r\n                 from ./tensorflow/core/framework/resource_handle.h:19,\r\n                 from ./tensorflow/core/framework/allocator.h:24,\r\n                 from ./tensorflow/core/framework/op_kernel.h:23,\r\n                 from tensorflow/core/kernels/tensor_forest/prediction_ops.cc:12:\r\n./tensorflow/core/lib/core/refcount.h: In member function 'virtual void tensorflow::TensorForestTreePredictOp::Compute(tensorflow::OpKernelContext*)':\r\n./tensorflow/core/lib/core/refcount.h:104:12: warning: 'decision_tree_resource' may be used uninitialized in this function [-Wmaybe-uninitialized]\r\n     delete this;\r\n            ^\r\ntensorflow/core/kernels/tensor_forest/prediction_ops.cc:32:31: note: 'decision_tree_resource' was declared here\r\n     TensorForestTreeResource* decision_tree_resource;\r\n                               ^\r\nINFO: From Compiling tensorflow/core/ops/nn_grad.cc [for host]:\r\nIn file included from ./tensorflow/core/platform/default/logging.h:24:0,\r\n                 from ./tensorflow/core/platform/logging.h:25,\r\n                 from ./tensorflow/core/lib/core/status.h:25,\r\n                 from ./tensorflow/core/lib/core/errors.h:21,\r\n                 from ./tensorflow/core/framework/tensor_shape.h:23,\r\n                 from ./tensorflow/core/framework/partial_tensor_shape.h:20,\r\n                 from ./tensorflow/core/framework/attr_value_util.h:23,\r\n                 from ./tensorflow/core/framework/function.h:21,\r\n                 from tensorflow/core/ops/nn_grad.cc:16:\r\n./tensorflow/core/util/tensor_format.h: In instantiation of 'T tensorflow::GetTensorDim(tensorflow::gtl::ArraySlice<T>, tensorflow::TensorFormat, char) [with T = long long int; tensorflow::gtl::ArraySlice<T> = absl::Span<const long long int>]':\r\n./tensorflow/core/util/tensor_format.h:452:47:   required from here\r\n./tensorflow/core/util/tensor_format.h:420:29: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   CHECK(index >= 0 && index < dimension_attributes.size())\r\n                             ^\r\n./tensorflow/core/platform/macros.h:87:47: note: in definition of macro 'TF_PREDICT_FALSE'\r\n #define TF_PREDICT_FALSE(x) (__builtin_expect(x, 0))\r\n                                               ^\r\n./tensorflow/core/util/tensor_format.h:420:3: note: in expansion of macro 'CHECK'\r\n   CHECK(index >= 0 && index < dimension_attributes.size())\r\n   ^\r\n./tensorflow/core/util/tensor_format.h: In instantiation of 'T tensorflow::GetFilterDim(tensorflow::gtl::ArraySlice<T>, tensorflow::FilterTensorFormat, char) [with T = long long int; tensorflow::gtl::ArraySlice<T> = absl::Span<const long long int>]':\r\n./tensorflow/core/util/tensor_format.h:461:54:   required from here\r\n./tensorflow/core/util/tensor_format.h:435:29: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   CHECK(index >= 0 && index < dimension_attribute.size())\r\n                             ^\r\n./tensorflow/core/platform/macros.h:87:47: note: in definition of macro 'TF_PREDICT_FALSE'\r\n #define TF_PREDICT_FALSE(x) (__builtin_expect(x, 0))\r\n                                               ^\r\n./tensorflow/core/util/tensor_format.h:435:3: note: in expansion of macro 'CHECK'\r\n   CHECK(index >= 0 && index < dimension_attribute.size())\r\n   ^\r\nERROR: /root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/external/grpc/BUILD:1515:1: C++ compilation of rule '@grpc//:grpc_resolver_dns_ares' failed (Exit 1) gcc failed: error executing command /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG ... (remaining 62 argument(s) skipped)\r\n\r\nUse --sandbox_debug to see verbose messages from the sandbox\r\nexternal/grpc/src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc:56:30: error: field 'dns_server_addr' has incomplete type 'ares_addr_port_node'\r\n   struct ares_addr_port_node dns_server_addr;\r\n                              ^\r\nexternal/grpc/src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc:56:10: note: forward declaration of 'struct ares_addr_port_node'\r\n   struct ares_addr_port_node dns_server_addr;\r\n          ^\r\nexternal/grpc/src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc: In function 'void on_txt_done_locked(void*, int, int, unsigned char*, int)':\r\nexternal/grpc/src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc:313:53: error: 'ares_parse_txt_reply_ext' was not declared in this scope\r\n   status = ares_parse_txt_reply_ext(buf, len, &reply);\r\n                                                     ^\r\nexternal/grpc/src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc:316:58: error: invalid use of incomplete type 'struct on_txt_done_locked(void*, int, int, unsigned char*, int)::ares_txt_ext'\r\n   for (result = reply; result != nullptr; result = result->next) {\r\n                                                          ^\r\nexternal/grpc/src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc:309:10: note: forward declaration of 'struct on_txt_done_locked(void*, int, int, unsigned char*, int)::ares_txt_ext'\r\n   struct ares_txt_ext* result = nullptr;\r\n          ^\r\nexternal/grpc/src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc:317:15: error: invalid use of incomplete type 'struct on_txt_done_locked(void*, int, int, unsigned char*, int)::ares_txt_ext'\r\n     if (result->record_start &&\r\n               ^\r\nexternal/grpc/src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc:309:10: note: forward declaration of 'struct on_txt_done_locked(void*, int, int, unsigned char*, int)::ares_txt_ext'\r\n   struct ares_txt_ext* result = nullptr;\r\n          ^\r\nexternal/grpc/src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc:318:22: error: invalid use of incomplete type 'struct on_txt_done_locked(void*, int, int, unsigned char*, int)::ares_txt_ext'\r\n         memcmp(result->txt, g_service_config_attribute_prefix, prefix_len) ==\r\n                      ^\r\nexternal/grpc/src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc:309:10: note: forward declaration of 'struct on_txt_done_locked(void*, int, int, unsigned char*, int)::ares_txt_ext'\r\n   struct ares_txt_ext* result = nullptr;\r\n          ^\r\nexternal/grpc/src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc:325:39: error: invalid use of incomplete type 'struct on_txt_done_locked(void*, int, int, unsigned char*, int)::ares_txt_ext'\r\n     size_t service_config_len = result->length - prefix_len;\r\n                                       ^\r\nexternal/grpc/src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc:309:10: note: forward declaration of 'struct on_txt_done_locked(void*, int, int, unsigned char*, int)::ares_txt_ext'\r\n   struct ares_txt_ext* result = nullptr;\r\n          ^\r\nexternal/grpc/src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc:328:47: error: invalid use of incomplete type 'struct on_txt_done_locked(void*, int, int, unsigned char*, int)::ares_txt_ext'\r\n     memcpy(*r->service_config_json_out, result->txt + prefix_len,\r\n                                               ^\r\nexternal/grpc/src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc:309:10: note: forward declaration of 'struct on_txt_done_locked(void*, int, int, unsigned char*, int)::ares_txt_ext'\r\n   struct ares_txt_ext* result = nullptr;\r\n          ^\r\nexternal/grpc/src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc:330:25: error: invalid use of incomplete type 'struct on_txt_done_locked(void*, int, int, unsigned char*, int)::ares_txt_ext'\r\n     for (result = result->next; result != nullptr && !result->record_start;\r\n                         ^\r\nexternal/grpc/src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc:309:10: note: forward declaration of 'struct on_txt_done_locked(void*, int, int, unsigned char*, int)::ares_txt_ext'\r\n   struct ares_txt_ext* result = nullptr;\r\n          ^\r\nexternal/grpc/src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc:330:61: error: invalid use of incomplete type 'struct on_txt_done_locked(void*, int, int, unsigned char*, int)::ares_txt_ext'\r\n     for (result = result->next; result != nullptr && !result->record_start;\r\n                                                             ^\r\nexternal/grpc/src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc:309:10: note: forward declaration of 'struct on_txt_done_locked(void*, int, int, unsigned char*, int)::ares_txt_ext'\r\n   struct ares_txt_ext* result = nullptr;\r\n          ^\r\nexternal/grpc/src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc:331:25: error: invalid use of incomplete type 'struct on_txt_done_locked(void*, int, int, unsigned char*, int)::ares_txt_ext'\r\n          result = result->next) {\r\n                         ^\r\nexternal/grpc/src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc:309:10: note: forward declaration of 'struct on_txt_done_locked(void*, int, int, unsigned char*, int)::ares_txt_ext'\r\n   struct ares_txt_ext* result = nullptr;\r\n          ^\r\nexternal/grpc/src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc:334:50: error: invalid use of incomplete type 'struct on_txt_done_locked(void*, int, int, unsigned char*, int)::ares_txt_ext'\r\n                       service_config_len + result->length + 1));\r\n                                                  ^\r\nexternal/grpc/src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc:309:10: note: forward declaration of 'struct on_txt_done_locked(void*, int, int, unsigned char*, int)::ares_txt_ext'\r\n   struct ares_txt_ext* result = nullptr;\r\n          ^\r\nexternal/grpc/src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc:335:70: error: invalid use of incomplete type 'struct on_txt_done_locked(void*, int, int, unsigned char*, int)::ares_txt_ext'\r\n       memcpy(*r->service_config_json_out + service_config_len, result->txt,\r\n                                                                      ^\r\nexternal/grpc/src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc:309:10: note: forward declaration of 'struct on_txt_done_locked(void*, int, int, unsigned char*, int)::ares_txt_ext'\r\n   struct ares_txt_ext* result = nullptr;\r\n          ^\r\nexternal/grpc/src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc:336:20: error: invalid use of incomplete type 'struct on_txt_done_locked(void*, int, int, unsigned char*, int)::ares_txt_ext'\r\n              result->length);\r\n                    ^\r\nexternal/grpc/src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc:309:10: note: forward declaration of 'struct on_txt_done_locked(void*, int, int, unsigned char*, int)::ares_txt_ext'\r\n   struct ares_txt_ext* result = nullptr;\r\n          ^\r\nexternal/grpc/src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc:337:35: error: invalid use of incomplete type 'struct on_txt_done_locked(void*, int, int, unsigned char*, int)::ares_txt_ext'\r\n       service_config_len += result->length;\r\n                                   ^\r\nexternal/grpc/src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc:309:10: note: forward declaration of 'struct on_txt_done_locked(void*, int, int, unsigned char*, int)::ares_txt_ext'\r\n   struct ares_txt_ext* result = nullptr;\r\n          ^\r\nexternal/grpc/src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc: In function 'void grpc_dns_lookup_ares_continue_after_check_localhost_and_ip_literals_locked(grpc_ares_request*, const char*, const char*, const char*, grpc_pollset_set*, bool, grpc_combiner*)':\r\nexternal/grpc/src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc:420:70: error: 'ares_set_servers_ports' was not declared in this scope\r\n     int status = ares_set_servers_ports(*channel, &r->dns_server_addr);\r\n                                                                      ^\r\nTarget //tensorflow/python/tools:freeze_graph failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 717.681s, Critical Path: 145.04s, Remote (0.00% of the time): [queue: 0.00%, setup: 0.00%, process: 0.00%]\r\nINFO: 1861 processes: 1861 linux-sandbox.\r\nFAILED: Build did NOT complete successfully\r\nroot@swsrv03:~/tensorflow#\r\n\r\n\r\n", "Is this an issue with the latest version of TF?", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 24170, "title": "'TensorBoard' object has no attribute 'sess'", "body": "\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac Os\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):binary\r\n- TensorFlow version (use command below):1.12\r\n- Python version:3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:N/A\r\n- GPU model and memory:N/A\r\n\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\nv1.12.0-rc2-3-ga6d8ffae09 1.12.0\r\n**Describe the current behavior**\r\nI want to use the tensorboard callback in keras to show the embeddings in the projector view\r\n**Describe the expected behavior**\r\nI'm getting an error while training.\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n```\r\n    tensorboard = keras.callbacks.TensorBoard(\r\n        log_dir='./logs',\r\n        batch_size=128,\r\n        histogram_freq=1,\r\n        embeddings_freq=1,\r\n        embeddings_metadata='./metadata.tsv',\r\n        embeddings_data=X_Test\r\n    )\r\n    history = model.fit(ready_data, ready_labels, batch_size=128, epochs=20,validation_data=(X_Test,Y_test),callbacks=[tensorboard])\r\n```\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n```\r\nTraceback (most recent call last):\r\n  File \"/Users/alcaljos/Projects/issue-classifer-ml/src/main.py\", line 193, in <module>\r\n    history = model.fit(ready_data, ready_labels, batch_size=128, epochs=20,validation_data=(X_Test,Y_test),callbacks=[tensorboard,checkpointer])\r\n  File \"/Users/alcaljos/anaconda/envs/issue-classifier/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 1639, in fit\r\n    validation_steps=validation_steps)\r\n  File \"/Users/alcaljos/anaconda/envs/issue-classifier/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\", line 239, in fit_loop\r\n    callbacks.on_epoch_end(epoch, epoch_logs)\r\n  File \"/Users/alcaljos/anaconda/envs/issue-classifier/lib/python3.6/site-packages/tensorflow/python/keras/callbacks.py\", line 214, in on_epoch_end\r\n    callback.on_epoch_end(epoch, logs)\r\n  File \"/Users/alcaljos/anaconda/envs/issue-classifier/lib/python3.6/site-packages/tensorflow/python/keras/callbacks.py\", line 1144, in on_epoch_end\r\n    self.sess.run(self.assign_embeddings, feed_dict=feed_dict)\r\nAttributeError: 'TensorBoard' object has no attribute 'sess'\r\n```\r\n", "comments": ["This issue is more suitable for [Tensorboard repo](https://github.com/tensorflow/tensorboard). I apologize for the redundant work you have to do, but please post this issue on [Tensorboard repo](https://github.com/tensorflow/tensorboard/issues). Thanks!", "This issue is actually with Tensorboard Callback, not with Tensorboard itself. In on_epoch_end, the callback attempts to run a Session from the attribute self.sess but self.sess has never been set.\r\nThis portion of the callback code that set this attribute was reworked for the 1.12rc but there is no unit test for using embeddings with this callback: \r\n```\r\n      # TODO(psv): Add integration tests to test embedding visualization\r\n      # with TensorBoard callback. We are unable to write a unit test for this\r\n      # because TensorBoard dependency assumes TensorFlow package is installed.\r\n```\r\nCould we re-open this?\r\n\r\nUpdate\r\n   Checked with TF 1.11 on Colaboratory: same error. Tried 1.10 but Callback API had changed\r\nAlso\r\n"]}, {"number": 24169, "title": "Improve performance of LRNGrad on CPU builds", "body": "This PR improves the performance of the CPU version of LRNGrad by moving a number of computations out of its innermost loop.  The extent of the resulting performance gains is dependent on the depth_radius, the compiler and the number of CPUs available.  The BM_LRNGrad benchmark is showing a 1.48x performance gain for a depth_radius of 4 and a 1.31x gain for a depth_radius of 2 when built with gcc 7.3.0 and run on a single core machine.  With gcc 5.4.0 the results on a single core machine are less impressive but are nonetheless significant;  1.13x for a depth radius of 4 and 1.10x with a depth radius of 2. With gcc 7.3.0 on a 16 core machine speed ups of 1.4x and 1.2x can be observed using a depth radius of 4 and 2 respectively.\r\n\r\nThe PR also includes a new benchmark for LRNGradOp, used to measure the performance gains, and fixes some formatting issues with the lrn_op.cc file.", "comments": ["Thank you @markdryan and sorry for the delay.\r\n\r\n@ymodak I'm happy to review, but I don't have the ability to approve PRs.", "@markdryan was clang-format required? I'm surprised there were differences, since all internal changes to TensorFlow require clang-format to be applied. I just ran clang-format on lrn_op.cc and there were no changes, so I suspect you're either using a different version or it didn't end up using our [.clang-format](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/.clang-format) file.", "@rryan Thanks for your review.\r\n\r\nI re-ran the benchmarks on both single core xenial and bionic machines with two different versions of my LRNGrad kernel patch and compared the results to those generated by the benchmark on an unpatched LRNGrad kernel, i.e., the one in master right now.  The results of the first version, my original patch, can be seen in the second column of the tables below.   The results of the second version, in which divide has been moved back inside the loop, are shown in the third column.   The columns show the speedup provided by each patch as compared to the current LRNGrad kernel.\r\n\r\nBionic 18.04 ( 5.4.0)\r\n```\r\nBM_LRNGrad_cpu_128_12_12_64_4   1.511x  1.476x\r\nBM_LRNGrad_cpu_128_56_56_64_2   1.346x  1.330x\r\nBM_LRNGrad_cpu_128_27_27_192_2  1.350x  1.329x\r\n```\r\n\r\nUbuntu 16.04 (gcc 5.4.0)\r\n```\r\nBM_LRNGrad_cpu_128_12_12_64_4  1.201x 1.189x\r\nBM_LRNGrad_cpu_128_56_56_64_2  1.159x 1.151x\r\nBM_LRNGrad_cpu_128_27_27_192_2 1.156x 1.147x\r\n```\r\n\r\nAs you can see, moving the divide out of the loop does speed the kernel up but this optimisation is only responsible for a small portion of the overall performance gains provided by the patch.  Consequently, I've updated my pull request to move the division back inside the loop.\r\n\r\nI've also dropped the clang-format commit.  Incidentally, I was following the formatting instructions [here](https://github.com/markdryan/tensorflow/blob/master/CONTRIBUTING.md#c-coding-style) using clang-format 3.8.0 on Ubuntu.  What is the recommended version of clang-format to use?", "@rryan Could you PTAL and approve."]}, {"number": 24168, "title": "What version of Tensorflow  to install with CUDA 9.2 and libcudnn 6.0 ?", "body": "Im upgrading from tensorflow-gpu 1.4 to a recent version but when i try to run tensorflow-gpu 1.12.0 on a cluster which contains Cuda 9.2, i get this error : \r\n\r\n`ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory`\r\n\r\nI've tried even tensorflow-gpu 1.10 but it keeps the same error , so i would like to know which version can i install so it can run perfectly with Cuda 9.2 \r\n\r\nThank you", "comments": []}, {"number": 24167, "title": "Import Error", "body": "Using TensorFlow backend.\r\n---------------------------------------------------------------------------\r\nImportError                               Traceback (most recent call last)\r\n~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py in <module>()\r\n     57 \r\n---> 58   from tensorflow.python.pywrap_tensorflow_internal import *\r\n     59   from tensorflow.python.pywrap_tensorflow_internal import __version__\r\n\r\n~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py in <module>()\r\n     27             return _mod\r\n---> 28     _pywrap_tensorflow_internal = swig_import_helper()\r\n     29     del swig_import_helper\r\n\r\n~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py in swig_import_helper()\r\n     23             try:\r\n---> 24                 _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n     25             finally:\r\n\r\n~\\AppData\\Local\\Continuum\\anaconda3\\lib\\imp.py in load_module(name, file, filename, details)\r\n    242         else:\r\n--> 243             return load_dynamic(name, filename, file)\r\n    244     elif type_ == PKG_DIRECTORY:\r\n\r\n~\\AppData\\Local\\Continuum\\anaconda3\\lib\\imp.py in load_dynamic(name, path, file)\r\n    342             name=name, loader=loader, origin=path)\r\n--> 343         return _load(spec)\r\n    344 \r\n\r\nImportError: Module use of python36.dll conflicts with this version of Python.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nImportError                               Traceback (most recent call last)\r\n<ipython-input-7-3222c6a3cf4e> in <module>()\r\n      7 from sklearn.preprocessing import LabelEncoder\r\n      8 from sklearn.metrics import mean_squared_error\r\n----> 9 from keras.wrappers.scikit_learn import KerasClassifier\r\n     10 from sklearn.model_selection import KFold\r\n     11 from sklearn.model_selection import cross_val_score\r\n\r\n~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\__init__.py in <module>()\r\n      1 from __future__ import absolute_import\r\n      2 \r\n----> 3 from . import utils\r\n      4 from . import activations\r\n      5 from . import applications\r\n\r\n~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\utils\\__init__.py in <module>()\r\n      4 from . import data_utils\r\n      5 from . import io_utils\r\n----> 6 from . import conv_utils\r\n      7 \r\n      8 # Globally-importable utils.\r\n\r\n~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\utils\\conv_utils.py in <module>()\r\n      7 from six.moves import range\r\n      8 import numpy as np\r\n----> 9 from .. import backend as K\r\n     10 \r\n     11 \r\n\r\n~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\__init__.py in <module>()\r\n     87 elif _BACKEND == 'tensorflow':\r\n     88     sys.stderr.write('Using TensorFlow backend.\\n')\r\n---> 89     from .tensorflow_backend import *\r\n     90 else:\r\n     91     # Try and load external backend.\r\n\r\n~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py in <module>()\r\n      3 from __future__ import print_function\r\n      4 \r\n----> 5 import tensorflow as tf\r\n      6 from tensorflow.python.framework import ops as tf_ops\r\n      7 from tensorflow.python.training import moving_averages\r\n\r\n~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py in <module>()\r\n     22 \r\n     23 # pylint: disable=g-bad-import-order\r\n---> 24 from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n     25 \r\n     26 try:\r\n\r\n~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py in <module>()\r\n     47 import numpy as np\r\n     48 \r\n---> 49 from tensorflow.python import pywrap_tensorflow\r\n     50 \r\n     51 from tensorflow.python.tools import component_api_helper\r\n\r\n~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py in <module>()\r\n     72 for some common reasons and solutions.  Include the entire stack trace\r\n     73 above this error message when asking for help.\"\"\" % traceback.format_exc()\r\n---> 74   raise ImportError(msg)\r\n     75 \r\n     76 # pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\r\n\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\EURIPAB\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\EURIPAB\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\EURIPAB\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\EURIPAB\\AppData\\Local\\Continuum\\anaconda3\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\EURIPAB\\AppData\\Local\\Continuum\\anaconda3\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: Module use of python36.dll conflicts with this version of Python.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.", "comments": ["I installed Anaconda with python 3.7 and then installed python 3.6\r\nI dowloaded tensorflow for keras but I'm aving this problem", "Is this still an issue for you? Can you please uninstall the python 3.7 version and confirm?", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 24166, "title": "Fix ClusterSpec.as_dict with only chief and ps", "body": "If the worker num is zero, continue the loop.", "comments": ["this fix  #24165 ", "reply @mrry  All right, I would add a unittest later.", "@mrry Hi, mrry, would you please take a review, thanks very much.", "@harshini-gadige Hi, harshini, the Windows Bazel checks get failed, but there is no any details. Would you please tell me how to deal with it.  Thank you very much!", "> @harshini-gadige Hi, harshini, the Windows Bazel checks get failed, but there is no any details. Would you please tell me how to deal with it. Thank you very much!\r\n\r\nI've bypassed those 2 failures and proceeding to get this merged."]}, {"number": 24165, "title": "Initiate ClusterSpec.as_dict failed with only chief and ps", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nNo\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nLinux 4.4.95.x86_64 #1 SMP Tue Jun 5 16:07:34 CST 2018 x86_64 x86_64 x86_64 GNU/Linux\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\nNo\r\n- TensorFlow installed from (source or binary):\r\n Binary by pip\r\n- TensorFlow version (use command below):\r\n1.11\r\n- Python version:\r\n2.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n9.0.176\r\n- GPU model and memory:\r\nTesla V100, 32G\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n**Describe the current behavior**\r\n\r\nWhen initiate the RunConfig in the following code with only chief and ps, a error happends.\r\n\r\nINFO:tensorflow:TF_CONFIG environment variable: {u'environment': u'cloud', u'cluster': {u'ps': [u'10.50.219.105:2222'], u'chief': [u'10.50.219.11:2222'], u'worker': []}, u'task': {u'index': 0, u'type': u'ps'}}\r\n\r\n```\r\n    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.8, allow_growth=True)\r\n    config = tf.ConfigProto(gpu_options=gpu_options,\r\n                            log_device_placement=True)\r\n    run_config = tf.estimator.RunConfig(save_checkpoints_steps=FLAGS.train_step / 10,\r\n                                        keep_checkpoint_max=FLAGS.train_epochs * 100,\r\n                                        log_step_count_steps=int(FLAGS.train_step / 400),\r\n                                        save_summary_steps=int(FLAGS.train_step / 10),\r\n                                        session_config=config\r\n                                        )\r\n```\r\n\r\n\r\nError tracing,\r\n\r\n```\r\nTraceback (most recent call last):\r\nFile \"DCN/wide_dcn_onehot.py\", line 490, in\r\ntf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\nFile \"/app/python_venv/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 125, in run\r\n_sys.exit(main(argv))\r\nFile \"DCN/wide_dcn_onehot.py\", line 464, in main\r\nmodel = build_estimator(FLAGS.model_dir)\r\nFile \"DCN/wide_dcn_onehot.py\", line 412, in build_estimator\r\nsave_summary_steps=int(FLAGS.train_step / 10)\r\nFile \"/app/python_venv/lib/python2.7/site-packages/tensorflow/python/estimator/run_config.py\", line 528, in __init__\r\nself._init_distributed_setting_from_environment_var(tf_config)\r\nFile \"/app/python_venv/lib/python2.7/site-packages/tensorflow/python/estimator/run_config.py\", line 597, in _init_distributed_setting_from_environment_var\r\nself._num_ps_replicas = _count_ps(self._cluster_spec)\r\nFile \"/app/python_venv/lib/python2.7/site-packages/tensorflow/python/estimator/run_config.py\", line 136, in _count_ps\r\nreturn len(cluster_spec.as_dict().get(TaskType.PS, []))\r\nFile \"/app/python_venv/lib/python2.7/site-packages/tensorflow/python/training/server_lib.py\", line 335, in as_dict\r\nif max(task_indices) + 1 == len(task_indices):\r\nValueError: max() arg is an empty sequence\r\n```\r\n\r\n**Describe the expected behavior**\r\n\r\nInitiate success.\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["This has been fixed, please close."]}, {"number": 24164, "title": "change to ANSI C style for loop", "body": "", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->", "@luxupu  Request you to sign the CLA in order to proceed further steps in merging this PR. Thanks !", "I signed it! Thanks.", "I signed it!", "> I signed it!\r\n\r\nSorry that the CLA is not auto changing its status to YES. Hence we cannot proceed to help this get merged. I request you to close this and open a new PR by signing the CLA again. Thank you and apologies for the inconvenience. ", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "Sorry to say but we cannot proceed until CLA reflects YES. Could you please open a new PR(which may resolve the CLA issue) and try. Closing this."]}]