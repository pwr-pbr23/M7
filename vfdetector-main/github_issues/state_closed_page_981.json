[{"number": 23978, "title": "add tensorFlow visualization toolkit links", "body": "", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "Add Mark for doc review. "]}, {"number": 23977, "title": "pyhton code with tensorflow code throws execption in xampp server.", "body": "I have a python code in server root folder which has a tensorflow code, when compiled using exec() php command in php, it is throwing exception.\r\n\r\nBut when executed normally through console it excutes.\r\n\r\nI have attached text file which has the exception thrown while executing.\r\nCurrently I'm using postman to test the php file.\r\n\r\n[output.txt](https://github.com/tensorflow/tensorflow/files/2615237/output.txt)\r\n ", "comments": ["@dranandrao  You need to use newer version of the library C++ ABI than your system libstdc++ has. Request you to provide the information asked as per [this](https://github.com/tensorflow/tensorflow/issues/new?template=10-build-installation-issue.md) template in order to look into this issue.\r\n\r\nAlso please refer below links which may help to resolve. Thanks !\r\n#15777\r\n[SO issue](https://stackoverflow.com/questions/23494103/version-cxxabi-1-3-8-not-found-required-by)"]}, {"number": 23976, "title": "ImportError: cannot import name cloud", "body": "**System information**\r\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04, 18.04 s390x\r\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA\r\nTensorFlow installed from (source or binary): source\r\nTensorFlow version: v1.12.0\r\nPython version: 2.7.x\r\nInstalled using virtualenv? pip? conda?: Building from source\r\nBazel version (if compiling from source): v0.15.0\r\nGCC/Compiler version (if compiling from source): 7.3.0 (Ubuntu 18.04)\r\nCUDA/cuDNN version: NA\r\nGPU model and memory: NA  \r\n\r\n\r\n**Describe the problem**\r\n\r\nWe have build TensorFlow v1.12.0 from source on Ubuntu 16.04, 18.04 on s390x platform. Observed test failures with an error: \"ImportError: cannot import name cloud\"\r\n\r\n\r\n", "comments": ["For v1.12.0, we have disabled Apache Ignite support through ./configure and could build TensorFlow on s390x Ubuntu platform.\r\n\r\n`./configure`\r\n```\r\nWARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command \"bazel shutdown\".\r\nYou have bazel 0.15.0- (@non-git) installed.\r\nPlease specify the location of python. [Default is /usr/bin/python]:\r\n\r\n\r\nFound possible Python library paths:\r\n  /usr/local/lib/python2.7/dist-packages\r\n  /usr/lib/python2.7/dist-packages\r\nPlease input the desired Python library path to use.  Default is [/usr/local/lib/python2.7/dist-packages]\r\n\r\nDo you wish to build TensorFlow with Apache Ignite support? [Y/n]: N\r\nNo Apache Ignite support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with XLA JIT support? [Y/n]: N\r\nNo XLA JIT support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with OpenCL SYCL support? [y/N]: N\r\nNo OpenCL SYCL support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with ROCm support? [y/N]: N\r\nNo ROCm support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with CUDA support? [y/N]: N\r\nNo CUDA support will be enabled for TensorFlow.\r\n\r\nDo you wish to download a fresh release of clang? (Experimental) [y/N]: N\r\nClang will not be downloaded.\r\n\r\nDo you wish to build TensorFlow with MPI support? [y/N]: N\r\nNo MPI support will be enabled for TensorFlow.\r\n\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native]:\r\n\r\n\r\nWould you like to interactively configure ./WORKSPACE for Android builds? [y/N]: N\r\nNot configuring the WORKSPACE for Android builds.\r\n\r\nPreconfigured Bazel build configs. You can use any of the below by adding \"--config=<>\" to your build command. See tools/bazel.rc for more details.\r\n        --config=mkl            # Build with MKL support.\r\n        --config=monolithic     # Config for mostly static monolithic build.\r\n        --config=gdr            # Build with GDR support.\r\n        --config=verbs          # Build with libverbs support.\r\n        --config=ngraph         # Build with Intel nGraph support.\r\nConfiguration finished\r\n```\r\n**Executed tests using command:** \r\n`bazel --host_jvm_args=\"-Xms512m\" --host_jvm_args=\"-Xmx1024m\" test --test_timeout 300,450,1200,3600 --build_tests_only -- //tensorflow/... -//tensorflow/compiler/... -//tensorflow/core/platform/cloud/... -//tensorflow/contrib/lite/... -//tensorflow/contrib/cloud/... -//tensorflow/java/... `\r\n\r\n* Excluding` //tensorflow/java` as it fails with an error '`Building Java resource jar failed`' [#19770]\r\n* Excluding `//tensorflow/core/platform/cloud/` and `//tensorflow/contrib/cloud/` as it gives Boringssl issue for s390x. \r\n\r\nHowerver few tests are failing with an error:  `ImportError:   cannot import name cloud`\r\n\r\nFailing Tests : \r\n```\r\n//tensorflow/contrib/sparsemax:sparsemax_loss_test\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\n//tensorflow/contrib/sparsemax:sparsemax_test\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\n//tensorflow/contrib/timeseries/examples:known_anomaly_test\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\n//tensorflow/contrib/timeseries/examples:lstm_test\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\n//tensorflow/contrib/timeseries/examples:multivariate_test\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\n//tensorflow/contrib/timeseries/examples:predict_test\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\r\n\r\nAll tests from //tensorflow/contrib/eager/python\r\n```\r\n\r\n\r\n\r\n\r\n\r\n", "Could you please let us know if we need to enable some features here? Or any package to install.", "@gunan  -  As per the chat in #23758, could you please post which commit fixes this issue ?", "I think the same commits mentioned in #23771 should fix this\r\nhttps://github.com/tensorflow/tensorflow/commit/3437098ba5b111817ef6ac5906d86934168704b7 and https://github.com/tensorflow/tensorflow/commit/3914ff714ba4561ecff329012d02c3de027ee4a5", "@gunan Thanks for your inputs. \r\nToday I have built master branch with steps mentioned in my earlier [comment](https://github.com/tensorflow/tensorflow/issues/23976#issuecomment-441598067)  , however facing same issue. \r\nTest `//tensorflow/contrib/eager/python/examples/densenet:densenet_test `failed with an error \r\n```\r\nTraceback (most recent call last):\r\n  File \"/execroot/org_tensorflow/bazel-out/s390x-opt/bin/tensorflow/contrib/eager/python/examples/densenet/densenet_test.runfiles/org_tensorflow/tensorflow/contrib/eager/python/examples/densenet/densenet_test.py\", line 24, in <module>\r\n    import tensorflow.contrib.eager as tfe\r\n  File \"/execroot/org_tensorflow/bazel-out/s390x-opt/bin/tensorflow/contrib/eager/python/examples/densenet/densenet_test.runfiles/org_tensorflow/tensorflow/contrib/__init__.py\", line 30, in <module>\r\n    from tensorflow.contrib import cloud\r\nImportError: cannot import name cloud\r\n```", "@gunan Could you please  suggest some workaround here?", "I think we need to change this line to add checks for platform s390x:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/__init__.py#L29\r\n\r\nWould you like to create a PR and assign it to me?", "Closing this issue as https://github.com/tensorflow/tensorflow/pull/24201 is merged ", "Thanks @gunan @meteorcloudy ", "This still seems to be an issue in the latest 1.13.1 and trunk code. If you build TF from source with `--nogcp`, that causes `tensorflow/contrib/cloud` NOT to be added to the pip package, but `tensorflow/contrib/__init__.py` will still try to run `from tensorflow.contrib import cloud`, which leads to the `ImportError: cannot import name 'cloud'` error.\r\n\r\nFiled https://github.com/tensorflow/tensorflow/issues/29617 for this."]}, {"number": 23975, "title": "Fix typo", "body": "fix typo\r\n\r\nis is -> is\r\n\r\nthe the -> the", "comments": ["Thanks for the fix."]}, {"number": 23974, "title": "TypeError: Type already registered for SparseTensorValue when running 2nd script ", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): N/a\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/a\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 1.12\r\n- Python version: 3.6.5\r\n- Bazel version (if compiling from source): 0.17.2\r\n- GCC/Compiler version (if compiling from source): 5.4.0\r\n- CUDA/cuDNN version: 9.0/7.0\r\n- GPU model and memory: GTX 1080 TI (11 GB)\r\n\r\n**Describe the current behavior**\r\nWhen I run a certain script in Spyder at the 1st time, everything flows smoothly. However, when I continue to run another script, following errors occur (which didn't happen at previously built tf 1.10):\r\n\r\n> File \"/home/haohua/tf_env/lib/python3.6/site-packages/tensorflow/init.py\", line 24, in from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import\r\n\r\n> File \"/home/haohua/tf_env/lib/python3.6/site-packages/tensorflow/python/init.py\", line 70, in from tensorflow.python.framework.framework_lib import * # pylint: disable=redefined-builtin\r\n\r\n> File \"/home/haohua/tf_env/lib/python3.6/site-packages/tensorflow/python/framework/framework_lib.py\", line 30, in from tensorflow.python.framework.sparse_tensor import SparseTensor\r\n\r\n> File \"/home/haohua/tf_env/lib/python3.6/site-packages/tensorflow/python/framework/sparse_tensor.py\", line 248, in pywrap_tensorflow.RegisterType(\"SparseTensorValue\", SparseTensorValue)\r\n\r\n> TypeError: Type already registered for SparseTensorValue\r\n\r\nMy temporary solution is restart the kernel before continuing to run the next script.\r\n\r\nBut restarting kernel at every single step of running a script (from the 2nd run) is not comfortable. Thus, I would like to ask for a critical solution for such kind of issue.\r\n\r\nP/S: [https://stackoverflow.com/questions/53477005/tensorflow-r1-12-typeerror-type-already-registered-for-sparsetensorvalue-when](url) is my question on Stackoverflow. However, I think it is still proper to put this issue here.", "comments": ["Apparently it is IDE related issue. Are you able to execute your code in jupyter notebook?", "@ymodak Yes, it works well without restarting kernel in jupyter notebook. Thank you very much. \r\nBtw, do you have any ideas of fixing the IDE (spyder) itself to avoid such issue?", "Awesome. Glad it worked. Unfortunately I have know idea for the spyder ide. You can try posting this issue on [spyder repo](https://github.com/spyder-ide/spyder/issues/new), folks there might know more. I will close this issue now since it has fixed your tf related problem. ", "Are you satisfied with the resolution of your issue?\r\n[Yes](https://goo.gl/forms/Oe0tEvODFRoI2gJF3)\r\n[No](https://goo.gl/forms/fUjzOfrtkFbrOT8d2)"]}, {"number": 23973, "title": "Update ExternalOptimizerInterface for use with Eager Execution", "body": "**System information**\r\n- TensorFlow version (you are using): 1.12\r\n- Are you willing to contribute it (Yes/No):\r\nI suppose yes...although i'm not confident i can produce a general code framework for this in any reasonable time.\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nCurrently the external scipy optimizer interface is coded to work with delayed [graph model] execution only.  Would like it updated for eager inclusion.\r\n\r\n**Will this change the current api? How?**\r\nJust need an option for eager.\r\n\r\n**Who will benefit with this feature?**\r\nEveryone that wants to user eager execution and the scipy optimizer in tensorflow\r\n", "comments": ["yeah, it's doable, we need to use  `tf.GradientTape` to watch the variables. \r\n\r\nSome inspiration from here https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/optimizer.py#L459-L520\r\n\r\nI'll put up some pull request :)  just notice \r\n\r\n> although i'm not confident i can produce a general code framework for this in any reasonable time.\r\n\r\n", "Thanks!  Dumb question -- I take it the \"pull request\" is a way to collaborate on the modifications on github?  Are you saying you'll post a link to a fork here that i should watch for?\r\n\r\nNote -- I've currently got a hack for early stopping for that optimizer as well that leverages the extra step callback and raises an error (since by default the optimizer doesn't have any way to early stop based on validation).  Would this be something to add as a separate issue or tie in to update the package all at once?  For anything that fits in memory this package crushes it on optimization -- since TF doesn't have anything similar native.", "yes..\r\n\r\nand do you mind paste a gist link demonstrate your hack ? ", "Sure and thank you!  Note this is my first time collaborating on code so please let me know if there's anything i can do to make my \"hack\" more easily understandable (or clarify anything).  \r\n\r\nMy hack was only applied to the LBFGS option since I had to raise a flag in the optimization loop (there was already a hook for a callback, but still had to add the code to stop it in the LBFGSB.py file), but ideally this solution would be more general in some way that doesn't require modifying or somehow overriding the relevant parts of the Scipy package.  Also would like it to work with all the different optimizer options from Scipy.\r\n\r\n[TFexternalOptimizer_earlyStoppingHack](https://gist.github.com/johnpjust/8629b36ecbe4387d39da821a5aeb2d3c)", "Hey, I would be very interested to have a working optimizer interface with eager execution. What's the status of this so far?", "@johnpjust,\r\nSorry for the delayed response. Can you please refer this [Stack Overflow Answer](https://stackoverflow.com/a/60443339) and let us know if this is what you are looking for? Thanks! ", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 23972, "title": "ERROR: undeclared inclusion(s) in rule '//tensorflow/python/eager:pywrap_tfe_lib'", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 1.12.0\r\n- Python version: 3.7.0\r\n- Installed using virtualenv? pip? conda?: conda\r\n- Bazel version (if compiling from source): 0.18\r\n- GCC/Compiler version (if compiling from source): 7.3.0\r\n- CUDA/cuDNN version: 10.0\r\n- GPU model and memory: GTX 1080 and 8GB\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nERROR: /home/ylzhao/project/tensorflow/tensorflow/python/eager/BUILD:10:1: undeclared inclusion(s) in rule '//tensorflow/python/eager:pywrap_tfe_lib':\r\nthis rule is missing dependency declarations for the following files included by 'tensorflow/python/eager/pywrap_tensor.cc':\r\n  'bazel-out/k8-opt/genfiles/external/local_config_python/python_include/numpy/arrayobject.h'\r\n  'bazel-out/k8-opt/genfiles/external/local_config_python/python_include/numpy/ndarrayobject.h'\r\n  'bazel-out/k8-opt/genfiles/external/local_config_python/python_include/numpy/ndarraytypes.h'\r\n  'bazel-out/k8-opt/genfiles/external/local_config_python/python_include/numpy/npy_common.h'\r\n  'bazel-out/k8-opt/genfiles/external/local_config_python/python_include/numpy/numpyconfig.h'\r\n  'bazel-out/k8-opt/genfiles/external/local_config_python/python_include/numpy/_numpyconfig.h'\r\n  'bazel-out/k8-opt/genfiles/external/local_config_python/python_include/numpy/npy_endian.h'\r\n  'bazel-out/k8-opt/genfiles/external/local_config_python/python_include/numpy/npy_cpu.h'\r\n  'bazel-out/k8-opt/genfiles/external/local_config_python/python_include/numpy/utils.h'\r\n  'bazel-out/k8-opt/genfiles/external/local_config_python/python_include/numpy/_neighborhood_iterator_imp.h'\r\n  'bazel-out/k8-opt/genfiles/external/local_config_python/python_include/numpy/__multiarray_api.h'\r\n  'bazel-out/k8-opt/genfiles/external/local_config_python/python_include/numpy/npy_interrupt.h'\r\n  'bazel-out/k8-opt/genfiles/external/local_config_python/python_include/numpy/ufuncobject.h'\r\n  'bazel-out/k8-opt/genfiles/external/local_config_python/python_include/numpy/npy_math.h'\r\n  'bazel-out/k8-opt/genfiles/external/local_config_python/python_include/numpy/npy_common.h'\r\n  'bazel-out/k8-opt/genfiles/external/local_config_python/python_include/numpy/arrayobject.h'\r\n  'bazel-out/k8-opt/genfiles/external/local_config_python/python_include/numpy/__ufunc_api.h'\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\n\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@panovr  Hi, please use the following combination to resolve this. \r\n\r\nPython - 3.6\r\nBazel - 0.15\r\nCUDA/cuDNN - 9/7\r\nGCC - 4.8", "Is this still not fixed with 1.13?\r\n\r\n**System information**\r\n\r\n* OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n* Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n* TensorFlow installed from (source or binary): source\r\n* TensorFlow version: 1.13.0rc2\r\n* Python version: 3.7.2\r\n* Installed using virtualenv? pip? conda?: pip\r\n* Bazel version (if compiling from source): 0.22\r\n* GCC/Compiler version (if compiling from source): 6.5.0\r\n* CUDA/cuDNN version: 10.0\r\n* GPU model and memory: RTX 2070 and 8GB\r\n\r\n**Describe the problem**\r\n\r\nERROR: /home/max/tensorflow/tensorflow/python/eager/BUILD:10:1: undeclared inclusion(s) in rule '//tensorflow/python/eager:pywrap_tfe_lib':\r\nthis rule is missing dependency declarations for the following files included by 'tensorflow/python/eager/pywrap_tensor.cc':\r\n  'bazel-out/host/genfiles/external/local_config_python/python_include/numpy/arrayobject.h'\r\n  'bazel-out/host/genfiles/external/local_config_python/python_include/numpy/ndarrayobject.h'\r\n  'bazel-out/host/genfiles/external/local_config_python/python_include/numpy/ndarraytypes.h'\r\n  'bazel-out/host/genfiles/external/local_config_python/python_include/numpy/npy_common.h'\r\n  'bazel-out/host/genfiles/external/local_config_python/python_include/numpy/numpyconfig.h'\r\n  'bazel-out/host/genfiles/external/local_config_python/python_include/numpy/_numpyconfig.h'\r\n  'bazel-out/host/genfiles/external/local_config_python/python_include/numpy/npy_endian.h'\r\n  'bazel-out/host/genfiles/external/local_config_python/python_include/numpy/npy_cpu.h'\r\n  'bazel-out/host/genfiles/external/local_config_python/python_include/numpy/utils.h'\r\n  'bazel-out/host/genfiles/external/local_config_python/python_include/numpy/_neighborhood_iterator_imp.h'\r\n  'bazel-out/host/genfiles/external/local_config_python/python_include/numpy/__multiarray_api.h'\r\n  'bazel-out/host/genfiles/external/local_config_python/python_include/numpy/npy_interrupt.h'\r\n  'bazel-out/host/genfiles/external/local_config_python/python_include/numpy/ufuncobject.h'\r\n  'bazel-out/host/genfiles/external/local_config_python/python_include/numpy/npy_math.h'\r\n  'bazel-out/host/genfiles/external/local_config_python/python_include/numpy/npy_common.h'\r\n  'bazel-out/host/genfiles/external/local_config_python/python_include/numpy/arrayobject.h'\r\n  'bazel-out/host/genfiles/external/local_config_python/python_include/numpy/__ufunc_api.h'\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\n", "Same issue in 1.13", "@lorenzesz  any solution found?", "any solutions? I tried to compile for python 3.6, and 3.7, but it did not work for neither of them.", "Still the same problem for r1.14 (c407b045b8802f9eded430ef48be18cd85e4788c) with Python 3.6.8, (Ubuntu 18.04, CUDA 10.1)", "Same here", "@jannispriesnitz I got this fixed by sorting out my numpy install (it's possible to have in three places: system-wide via apt, system-wide via pip, and in your user account). Try uninstalling from as many of these as possible and uninstall just the one you need (user is certainly easiest) to manipulate.\r\n\r\nOnce I was down to a single, consistent version of NumPy, I had no problem.", "I also encountered this error after switching the python version I was building against without doing a `bazel clean` in between"]}, {"number": 23971, "title": "Aborted (core dumped)", "body": "\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):       UBUNTU 18.04 LTS\r\n\r\n- TensorFlow installed from (source or binary): \r\n      https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-1.12.0-cp36-cp36m-linux_x86_64.whl\r\n\r\n- Python version: 3.6\r\n- Installed using virtualenv? pip? conda?:   conda\r\n\r\n\r\n2018-11-26 10:47:27.577247: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use SSE4.2 instructions, but these aren't available on your machine.\r\n\r\n\r\ncannot import tensorflow installation is successful but its unable to run. need some help!!\r\n", "comments": ["You've got 2 options.  \r\n\r\n- You can compile TF yourself.  Follow the instructions to install from source.  If you use the flag -march=native, gcc will apply all the correct flags for your CPU.\r\n- You can try to find an unofficial repository that supports your machine and download a wheel from there.  Take a look at [TF Optimized Wheels](https://github.com/mind/wheels) or [TF Community wheels](https://github.com/yaroslavvb/tensorflow-community-wheels).  These are just the first one I found.  There are others out there.  Please check for compatibility with Python version, CUDA version, gcc version, etc ...", "\"You can compile TF yourself. Follow the instructions to install from source. If you use the flag -march=native, gcc will apply all the correct flags for your CPU.\"\r\n\r\n\r\n can u please explain . I am new with Tensorflow. \r\n", "In that case I would highly recommend finding a pre-built wheel as suggested above.  If instead, you decide to compile from source, instructions can be found at [Build From Source](https://www.tensorflow.org/install/source) ."]}, {"number": 23970, "title": "yolo-v3 has correctness issue at tf-nightly", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):NA\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Centos 7.5\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:NA\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below):  tf-nightly==1.13.0.dev20181115\r\n- Python version: 3.4\r\n- Bazel version (if compiling from source): NA\r\n- GCC/Compiler version (if compiling from source): NA\r\n- CUDA/cuDNN version: NA\r\n- GPU model and memory: NA\r\n\r\n**Describe the current behavior**\r\n Start from tf-nightly==1.13.0.dev20181115, yolo-v3(https://github.com/mystic123/tensorflow-yolo-v3) meet correctness issue, the TF output did not consistent with the previous version\r\n**Describe the expected behavior**\r\nWith same command, tf-nightly==1.13.0.dev20181114 can get the right result and plot the bounding box.\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\nhttps://github.com/mystic123/tensorflow-yolo-v3#how-to-run-the-demo\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["We have seen similar issue with Resnet50 where accuracy drops to a very low number. This commit 0c1eb8861624d6d17c797b70d25330711df5eb2f seems to be causing the issue.", "@mahmoud-abuzaina the commit your provided is not the root cause for yolov3, after check, this commit https://github.com/tensorflow/tensorflow/commit/89fa3c5ed66a4e543ba01c31febf3edb417808d0 should be the yolov3 correctness regression commit. this commit update the Eigen version.", "Any updates?", "something new about it?\r\n", "Hello @martinwicke , can you please check this accuracy issue? Thanks.", "@rmlarsen, @guizili0 pointed at the Eigen update leading to a regression in YOLO quality. \r\n\r\nThis is sadly a very ill-defined regression -- @guizili0 do you have any hints as to where this regression may manifest itself, i.e., where (which op) results start to differ?", "@guizili0 did you find this commit via bisection?", "@martinwicke the commit shoule be https://github.com/tensorflow/tensorflow/commit/89fa3c5ed66a4e543ba01c31febf3edb417808d0\r\ncan you check it? thanks.", "@guizili0 this is a commit updating Eigen. Since Eigen underlies almost all (CPU) computations in TensorFlow, the commit unfortunately doesn't help much in narrowing it down.", "@martinwicke it is hard for me to find the regression commit in Eigen, do you have any suggestion about this?  ", "@guizili0 , we need to track down the contributor of this regression commit.", "@rmlarsen may have some pointers for where to start.", "Hi @rmlarsen , we would like to track down the correctness issue for yolo-v3 that this regression commit seems to have introduced.\r\nhttps://bitbucket.org/eigen/eigen/commits/af207140728002141ce3ff17f6f14cc159965f93\r\nThanks.\r\n", "Is this problem still being observed in recently nightly builds?", "@willbattel yes, still failed. ", "@guizili0 \r\nIs this still an issue.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/23970\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/23970\">No</a>\n"]}, {"number": 23969, "title": "inactive tensor board at safari", "body": "when I want to access my tensor board summary with commands ... \r\nand listening on localhost:6060\r\nThe same address would be inactive on safari , but ok on chrome browser.\r\nI wonder if it's general problem... \r\n![2018-11-26 12 57 10](https://user-images.githubusercontent.com/42016485/48994110-c81b2780-f184-11e8-8801-702fd48fc351.png)\r\n\r\nI uploaded screenshots ( the left one is chrome, and the active one is on safari\r\n\r\n\r\n\r\nThis template is for miscellaneous issues not covered by the other issue categories.\r\n\r\nFor questions on how to work with TensorFlow, or support for problems that are not verified bugs in \r\n\r\n\r\n\r\nTensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).`\r\nIf you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).\r\n\r\nFor high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.\r\n", "comments": ["Closing since TensorBoard issues should be filed at http://github.com/tensorflow/tensorboard/issues/new with the corresponding template details.\r\n\r\nHowever, I'm not sure that the behavior you've described is a bug in TensorBoard - it sounds like this could also be an issue with your Safari configuration or local network.  Please confirm that you can reproduce the issue on more than once machine, with the latest version of TensorBoard, before re-filing the issue."]}, {"number": 23968, "title": "[I tensorflow/contrib/lite/toco/import_tensorflow.cc:1080] Converting unsupported operation: ReadVariableOp", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\nSystem information\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nNo\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nMac\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\nbinary\r\n- TensorFlow version (use command below):\r\n1.12.0\r\n- Python version:\r\nPython 3.6.5 :: Anaconda, Inc.\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\nN/A\r\n- GPU model and memory:\r\nN/A\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n**Describe the current behavior**\r\n\r\n--------------------------------------\r\nI am trying to convert a graph from .pb to .lite format using toco, but I get this error:\r\n2018-11-26 03:31:18.511856: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1080] Converting unsupported operation: ReadVariableOp\r\n\r\nI think ReadVariableOp is the basic op, Lite shoud support it.\r\n\r\n---------------------------------------", "comments": ["@jason9693  Please add it here #21526. This issue tracks information about new ops which are to be added to TFLite. Please post here with your explanation. "]}, {"number": 23967, "title": "[ppc64le] Error installing custom build tensorflow 1.12 wheel with python 3.6", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): \r\n\r\nLSB Version:\t:core-4.1-noarch:core-4.1-ppc64le\r\nDistributor ID:\tRedHatEnterpriseServer\r\nDescription:\tRed Hat Enterprise Linux Server release 7.5 (Maipo)\r\nRelease:\t7.5\r\nCodename:\tMaipo\r\n\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 1.12\r\n- Python version: 3.6.7\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source): 0.15.0\r\n- GCC/Compiler version (if compiling from source): 4.8.5\r\n- CUDA/cuDNN version: 9.2/7.1\r\n- GPU model and memory: NVIDIA Pascal V100 16GB\r\n\r\n\r\n\r\n**Describe the problem**\r\nTrying to install a custom tensorflow 1.12 wheel on ppc64le IBM Power9 system with NVIDIA Pascal V100 but the installation breaks while installing h5py with the error shown below. \r\n\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nBuild tensorflow wheel from source using standard procedure described: [here](https://developer.ibm.com/tutorials/install-tensorflow-on-power/) (though modified as required) and install using pip. \r\n\r\n**Any other info / logs**\r\n```\r\ngcc -pthread -B /ccs/home/shubhankar/miniconda3/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -DH5_USE_16_API -I./h5py -I/tmp/pip-install-d__8pdpg/h5py/lzf -I/opt/local/include -I/usr/local/include -I/ccs/home/shubhankar/miniconda3/lib/python3.6/site-packages/numpy/core/include -I/ccs/home/shubhankar/miniconda3/include/python3.6m -c /tmp/pip-install-d__8pdpg/h5py/h5py/defs.c -o build/temp.linux-ppc64le-3.6/tmp/pip-install-d__8pdpg/h5py/h5py/defs.o\r\n    In file included from /ccs/home/shubhankar/miniconda3/lib/python3.6/site-packages/numpy/core/include/numpy/ndarraytypes.h:1821:0,\r\n                     from /ccs/home/shubhankar/miniconda3/lib/python3.6/site-packages/numpy/core/include/numpy/ndarrayobject.h:18,\r\n                     from /ccs/home/shubhankar/miniconda3/lib/python3.6/site-packages/numpy/core/include/numpy/arrayobject.h:4,\r\n                     from /tmp/pip-install-d__8pdpg/h5py/h5py/api_compat.h:26,\r\n                     from /tmp/pip-install-d__8pdpg/h5py/h5py/defs.c:657:\r\n    /ccs/home/shubhankar/miniconda3/lib/python3.6/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:15:2: warning: #warning \"Using deprecated NumPy API, disable it by \" \"#defining NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [-Wcpp]\r\n     #warning \"Using deprecated NumPy API, disable it by \" \\\r\n      ^\r\n    In file included from /tmp/pip-install-d__8pdpg/h5py/h5py/defs.c:657:0:\r\n    /tmp/pip-install-d__8pdpg/h5py/h5py/api_compat.h:27:18: fatal error: hdf5.h: No such file or directory\r\n     #include \"hdf5.h\"\r\n                      ^\r\n    compilation terminated.\r\n    error: command 'gcc' failed with exit status 1\r\n\r\n    ----------------------------------------\r\n  Rolling back uninstall of h5py\r\nCommand \"/ccs/home/shubhankar/miniconda3/bin/python -u -c \"import setuptools, tokenize;__file__='/tmp/pip-install-d__8pdpg/h5py/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record /tmp/pip-record-5_3ofwib/install-record.txt --single-version-externally-managed --compile\" failed with error code 1 in /tmp/pip-install-d__8pdpg/h5py/\r\n```\r\nIt breaks at the installation of h5py for some reason. It all starts with a warning message. I am not sure if it is related to it.\r\n\r\n```\r\nCythonizing /tmp/pip-install-d__8pdpg/h5py/h5py/h5z.pyx\r\n    /tmp/pip-install-d__8pdpg/h5py/.eggs/Cython-0.29.1-py3.6-linux-ppc64le.egg/Cython/Compiler/Main.py:367: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /tmp/pip-install-d__8pdpg/h5py/h5py/h5z.pxd\r\n```\r\nAnd finally\r\n\r\n```\r\nRolling back uninstall of h5py\r\nCommand \"/ccs/home/shubhankar/miniconda3/bin/python -u -c \"import setuptools, tokenize;__file__='/tmp/pip-install-d__8pdpg/h5py/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record /tmp/pip-record-5_3ofwib/install-record.txt --single-version-externally-managed --compile\" failed with error code 1 in /tmp/pip-install-d__8pdpg/h5py/\r\n```\r\n\r\nEDIT: Using miniconda for package management.", "comments": ["pip install of h5py fails on power because it has to be compiled from source. (The same error would happen on x86 also if pip installing h5py from source.)\r\n\r\nTo install h5py run:\r\nyum install hdf5-devel\r\npip install --global-option=build_ext --global-option=-I/usr/include/hdf5/serial/ --global-option=-L/usr/lib/powerpc64le-linux-gnu/hdf5/serial h5py\r\n\r\nThen install tensorflow.\r\n\r\n", "@wdirons But I am using miniconda for package management.", "if using conda, then try conda install h5py", "No it doesn't help either. It actually gives exactly the same error.\r\n", "@wdirons @gunan Are there any known issues with tf installation on miniconda? I tried installing using anaconda and it worked fine but the same installation steps are causing h5py error in miniconda.", "I have not used miniconda myself, I will try to recreate this problem.", "I also have not used miniconda.\r\n@jjhelmus are you aware of issues with miniconda h5py on ppc64le ?", "h5py can be install into a miniconda environment on ppc64le using the command `conda install h5py`.  Doing this before installing the tensorflow wheel should prevent pip from trying to build h5py from source.  Note that h5py is included in the Anaconda distribution which is likely why the install into that environment succeeded.  ", "@ghltshubh could you try running `sudo apt-get install libhdf5-dev` first, then `conda install h5py`, finally install tensorflow?", "@gunan I am on a shared system. Don't have sudo access.", "On my system, I had to do that first to make the header \"hdf5.h\" available.\r\nIn this case, if you cannot ask your administrator to install this, you may need to build h5py from sources manually following these instructions:\r\nhttp://docs.h5py.org/en/latest/build.html#source-installation-on-linux-other-unix\r\n\r\nYou will need to download and unpack libhdf5 locally, and point the python package to that.", "It's a lot of work. I will have to use anaconda instead. Just to mention I tried building tf 1.8 initially on power8 and P100 system which is little outdated now but the build installed fine using the same miniconda with python 3.5. But when I tried to install the tf 1.12 build on a newer system using same miniconda on power9 and V100 with python 3.6 it failed. Does it have something to do with the version of either python, tf or both?", "This actually looks rather like a bug in the h5py package (missing a header it needs). I suggest taking it up with them. \r\n\r\nThe reason it worked on 1.8 is probably because TensorFlow didn't have the h5py dependency back then. Note that TensorFlow will still work fine *except for loading/saving Keras models in Keras' native format* if h5py is not installed. So worst case, you could tell pip to not install h5py at all.\r\n\r\n", "(I will close this, feel free to reopen if it turns out we can do something more about this on the TensorFlow side)", "@wdirons @gunan @martinwicke What should be the values of optimization -mcpu  flags for bazel build command for power9 since gcc 4.8.5 doesn't support power9.", "@ghltshubh , `-mcpu=power8 -mtune=power8` can be used.\r\n\r\n@jayfurmanek - FYI", "Correct. gcc 4.8.5 is too old to know about Power9, but you can add the flags that @wdirons posted above to get a pretty good optimized build. We generally recommend building with `-O3` as well."]}, {"number": 23966, "title": "tensorflow lite, interpreter.get_tensor(output_details[o_index]['index'])) IndexError: list index out of range", "body": "------------------------\r\n\r\n### System information\r\n- **Linux raspberrypi 4.14.71-v7+**:\r\n- **raspberrypi 3b**:\r\n- **TensorFlow installed from binary**:\r\n- **TensorFlow version : 1.11.0**:\r\n- **Python version : 3.5.3**:\r\n\r\n### Describe the problem\r\nI'm trying the objection_detection for tflite. \r\n\r\nAnd I'm following [this guide](https://github.com/freedomtan/tensorflow/blob/deeplab_tflite_python/tensorflow/contrib/lite/examples/python/object_detection_ssd_coco.md). @freedomtan\r\n\r\nWhen I run `python3 /home/pi/tensorflow/tensorflow/lite/examples/python/object_detection.py --graph /home/pi/tmp/mobilenet_v1_0.5_192.tflite   --image /home/pi/tmp/image2.jpg  --show_image True`,\r\n\r\nit comes error that\r\n\r\n```\r\ntime spent: 135.03503799438477\r\nTraceback (most recent call last):\r\n  File \"/home/pi/tensorflow/tensorflow/lite/examples/python/object_detection.py\", line 182, in <module>\r\n    interpreter.get_tensor(output_details[o_index]['index']))\r\nIndexError: list index out of range\r\n```\r\n\r\n### Source code / logs\r\n```\r\npi@raspberrypi:~/tmp $ ls -l\r\ntotal 7588\r\n-rw-r--r-- 1 pi pi   76932 Nov 25 08:55 box_priors.txt\r\n-rw-r--r-- 1 pi pi     665 Nov 25 08:54 coco_labels_list.txt\r\n-rw-r--r-- 1 pi pi  940650 Nov 25 08:56 grace_hopper.bmp\r\n-rw-r--r-- 1 pi pi 1415684 Nov 26 02:41 image2.jpg\r\n-rw-r----- 1 pi pi 5319064 Nov 25 09:03 mobilenet_v1_0.5_192.tflite\r\n```\r\n* **object_detection.py**\r\n```\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\n\r\nimport argparse\r\nimport math\r\nimport time\r\nfrom heapq import heappush, nlargest\r\n\r\nimport numpy as np\r\nfrom PIL import Image\r\nimport matplotlib.pyplot as plt\r\nimport matplotlib.patches as patches\r\n\r\nfrom tensorflow.contrib.lite.python import interpreter as interpreter_wrapper\r\n\r\nNUM_RESULTS = 1917\r\nNUM_CLASSES = 91\r\n\r\nX_SCALE = 10.0\r\nY_SCALE = 10.0\r\nH_SCALE = 5.0\r\nW_SCALE = 5.0\r\n\r\ndef load_box_priors(filename):\r\n  with open(filename) as f:\r\n    count = 0\r\n    for line in f:\r\n      row = line.strip().split(' ')\r\n      box_priors.append(row)\r\n      #print(box_priors[count][0])\r\n      count = count + 1\r\n      if count == 4:\r\n        return\r\n\r\ndef load_labels(filename):\r\n  my_labels = []\r\n  input_file = open(filename, 'r')\r\n  for l in input_file:\r\n    my_labels.append(l.strip())\r\n  return my_labels\r\n\r\ndef decode_center_size_boxes(locations):\r\n  \"\"\"calculate real sizes of boxes\"\"\"\r\n  for i in range(0, NUM_RESULTS):\r\n    ycenter = locations[i][0] / Y_SCALE * np.float(box_priors[2][i]) \\\r\n            + np.float(box_priors[0][i])\r\n    xcenter = locations[i][1] / X_SCALE * np.float(box_priors[3][i]) \\\r\n            + np.float(box_priors[1][i])\r\n    h = math.exp(locations[i][2] / H_SCALE) * np.float(box_priors[2][i])\r\n    w = math.exp(locations[i][3] / W_SCALE) * np.float(box_priors[3][i])\r\n\r\n    ymin = ycenter - h / 2.0\r\n    xmin = xcenter - w / 2.0\r\n    ymax = ycenter + h / 2.0\r\n    xmax = xcenter + w / 2.0\r\n\r\n    locations[i][0] = ymin\r\n    locations[i][1] = xmin\r\n    locations[i][2] = ymax\r\n    locations[i][3] = xmax\r\n  return locations\r\n\r\ndef iou(box_a, box_b):\r\n  x_a = max(box_a[0], box_b[0])\r\n  y_a = max(box_a[1], box_b[1])\r\n  x_b = min(box_a[2], box_b[2])\r\n  y_b = min(box_a[3], box_b[3])\r\n\r\n  intersection_area = (x_b - x_a + 1) * (y_b - y_a + 1)\r\n\r\n  box_a_area = (box_a[2] - box_a[0] + 1) * (box_a[3] - box_a[1] + 1)\r\n  box_b_area = (box_b[2] - box_b[0] + 1) * (box_b[3] - box_b[1] + 1)\r\n\r\n  iou = intersection_area / float(box_a_area + box_b_area - intersection_area)\r\n  return iou\r\n\r\ndef nms(p, iou_threshold, max_boxes):\r\n  sorted_p = sorted(p, reverse=True)\r\n  selected_predictions = []\r\n  for a in sorted_p:\r\n    if len(selected_predictions) > max_boxes:\r\n      break\r\n    should_select = True\r\n    for b in selected_predictions:\r\n      if iou(a[3], b[3]) > iou_threshold:\r\n        should_select = False\r\n        break\r\n    if should_select:\r\n      selected_predictions.append(a)\r\n\r\n  return selected_predictions\r\n\r\nif __name__ == \"__main__\":\r\n  file_name = \"/home/pi/tmp/image2.jpg\"\r\n  model_file = \"/home/pi/tmp/mobilenet_ssd.tflite\"\r\n  label_file = \"/home/pi/tmp/coco_labels_list.txt\"\r\n  box_prior_file = \"/home/pi/tmp/box_priors.txt\"\r\n  input_mean = 127.5\r\n  input_std = 127.5\r\n  min_score = 20.0\r\n  max_boxes = 10\r\n  floating_model = False\r\n  show_image = False\r\n  alt_output_order = False\r\n\r\n  parser = argparse.ArgumentParser()\r\n  parser.add_argument(\"--image\", help=\"image to be classified\")\r\n  parser.add_argument(\"--graph\", help=\".tflite model to be executed\")\r\n  parser.add_argument(\"--labels\", help=\"name of file containing labels\")\r\n  parser.add_argument(\"--input_mean\", help=\"input_mean\")\r\n  parser.add_argument(\"--input_std\", help=\"input standard deviation\")\r\n  parser.add_argument(\"--min_score\", help=\"show only > min_score\")\r\n  parser.add_argument(\"--max_boxes\", help=\"max boxes to show\")\r\n  parser.add_argument(\"--show_image\", help=\"show image\")\r\n  parser.add_argument(\"--alt_output_order\", help=\"alternative output index\")\r\n  args = parser.parse_args()\r\n\r\n  if args.graph:\r\n    model_file = args.graph\r\n  if args.image:\r\n    file_name = args.image\r\n  if args.labels:\r\n    label_file = args.labels\r\n  if args.input_mean:\r\n    input_mean = float(args.input_mean)\r\n  if args.input_std:\r\n    input_std = float(args.input_std)\r\n  if args.min_score:\r\n    min_score = float(args.min_score)\r\n  if args.max_boxes:\r\n    max_boxes = int(args.max_boxes)\r\n  if args.show_image:\r\n    show_image = args.show_image\r\n  if args.alt_output_order:\r\n    alt_output_order = args.alt_output_order\r\n\r\n  interpreter = interpreter_wrapper.Interpreter(model_path=model_file)\r\n  interpreter.allocate_tensors()\r\n\r\n  input_details = interpreter.get_input_details()\r\n  output_details = interpreter.get_output_details()\r\n  #print(input_details)\r\n  #print(output_details)\r\n\r\n  # check the type of the input tensor\r\n  if input_details[0]['dtype'] == type(np.float32(1.0)):\r\n    floating_model = True\r\n\r\n  # NxHxWxC, H:1, W:2\r\n  height = input_details[0]['shape'][1]\r\n  width = input_details[0]['shape'][2]\r\n  img = Image.open(file_name)\r\n  img = img.resize((width, height))\r\n\r\n  # add N dim\r\n  input_data = np.expand_dims(img, axis=0)\r\n\r\n  if floating_model:\r\n    input_data = (np.float32(input_data) - input_mean) / input_std\r\n\r\n  interpreter.set_tensor(input_details[0]['index'], input_data)\r\n\r\n  start_time = time.time()\r\n  interpreter.invoke()\r\n  finish_time = time.time()\r\n  print(\"time spent:\", ((finish_time - start_time) * 1000))\r\n\r\n  box_priors = []\r\n  load_box_priors(box_prior_file)\r\n  labels = load_labels(label_file)\r\n\r\n  p_index = 0\r\n  o_index = 1\r\n  if alt_output_order:\r\n    p_index = 1\r\n    o_index = 0\r\n\r\n  predictions = np.squeeze( \\\r\n                  interpreter.get_tensor(output_details[p_index]['index']))\r\n  output_classes = np.squeeze( \\\r\n                     interpreter.get_tensor(output_details[o_index]['index']))\r\n  if not floating_model:\r\n    p_scale, p_mean = output_details[p_index]['quantization']\r\n    o_scale, o_mean = output_details[o_index]['quantization']\r\n\r\n    predictions = (predictions - p_mean * 1.0) * p_scale\r\n    output_classes = (output_classes - o_mean * 1.0) * o_scale\r\n\r\n  decode_center_size_boxes(predictions)\r\n\r\n  pruned_predictions = [[],]\r\n  for c in range(1, NUM_CLASSES):\r\n    pruned_predictions.append([])\r\n    for r in range(0, NUM_RESULTS):\r\n      score = 1. / (1. + math.exp(-output_classes[r][c]))\r\n      if score > 0.01:\r\n        rect = (predictions[r][1] * width, predictions[r][0] * width, \\\r\n                predictions[r][3] * width, predictions[r][2] * width)\r\n\r\n        pruned_predictions[c].append((output_classes[r][c], r, labels[c], rect))\r\n\r\n  final_predictions = []\r\n  for c in range(1, NUM_CLASSES):\r\n    predictions_for_class = pruned_predictions[c]\r\n    suppressed_predictions = nms(predictions_for_class, 0.5, max_boxes)\r\n    final_predictions = final_predictions +  suppressed_predictions\r\n\r\n  if show_image:\r\n    fig, ax = plt.subplots(1)\r\n\r\n  final_predictions = sorted(final_predictions, reverse=True)[:max_boxes]\r\n  for e in final_predictions:\r\n    score = 100. / (1. + math.exp(-e[0]))\r\n    score_string = '{0:2.0f}%'.format(score)\r\n    print(score_string, e[2], e[3])\r\n    if score < min_score:\r\n      break\r\n    left, top, right, bottom = e[3]\r\n    rect = patches.Rectangle((left, top), (right - left), (bottom - top), \\\r\n             linewidth=1, edgecolor='r', facecolor='none')\r\n\r\n    if show_image:\r\n      # Add the patch to the Axes\r\n      ax.add_patch(rect)\r\n      ax.text(left, top, e[2]+': '+score_string, fontsize=6,\r\n              bbox=dict(facecolor='y', edgecolor='y', alpha=0.5))\r\n\r\n  if show_image:\r\n    ax.imshow(img)\r\n    plt.title(model_file)\r\n    plt.show()\r\n```\r\n\r\n", "comments": ["there are two problems\r\n1. the script was for older version of TFLite, yet it should still work if you convert your model as described. You may want to use the newer one (with post-processing in TFLite) by reading [the instruction](https://medium.com/tensorflow/training-and-serving-a-realtime-mobile-object-detector-in-30-minutes-with-cloud-tpus-b78971cf1193) by @achowdhery and check #15633. And for script to handle newer object-detection tflite file, check [this one](https://github.com/freedomtan/tensorflow/blob/freedom/object_detection_tflite_object_dtection_python_w_postprocessing/tensorflow/contrib/lite/examples/python/object_detection.py)\r\n2. my script was for MobileNet_SSD, object-detection network, but you use MobileNet, which is classifier", "@achowdhery, PTAL. ", "I updated my script, added some description, and sent a PR https://github.com/tensorflow/tensorflow/pull/23994", "@freedomtan Thanks for your answer and your update! It is worked now! \r\nAnd after this, I plan to run the MobileNet_SSD, object-detection network using tflite in my raspberrypi to detect object with the raspberrypi camara, \r\nIt is my temporary idea. Before I knew of tflite, I had already used tensorflow+opencv+ssd_mobilenet_v1_coco in my raspberrypi to detect object using raspberrypi camara without any gpu or computer supported and it worked. But it takes about 3~4s to detect object and present its results.  It is too slow for me.\r\nAnd now my goal is using tflite to reduce the time it cost without any gpu or computer supported.\r\nI would be very gratful if you give me more advice about my job now.\r\nThanks very much\uff01", "We have recently released the script to build the TF Lite target on Raspberry Pi\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/tools/make/build_rpi_lib.sh\r\n\r\nPlease let us know if you are stuck in any step there.", "@Wade129 With [benchmark_model for TF Lite](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/tools/benchmark), you can see that, with num_threads=4, it takes about 150 ms to do [ssd_mobilenet_v1_quantized_300x300_coco1](http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_quantized_300x300_coco14_sync_2018_07_18.tar.gz) inference for earch frame. If the number (~ 150 ms) is not good enough, then what you could do on CPUs is to  improve CONV_2D and DEPTHWISE_CONV_2D.", "@Wade129 Is your bug resolved at this time? Thanks", "@achowdhery yes, resolved alredy!", "Hi @Wade129 Have you successfully reduce the time cost by using tflite on raspberry pi? I'm having hard time to use tflite on raspberry pi after successfully generate libtensorflow-lite.a, didn't what to do next. Can you please suggest me what to do until i can successfully running tflite on raspberry pi? Thanks."]}, {"number": 23965, "title": "add metrics to Estimator ( not canned estimators)", "body": "I just changed my code from `tf.contrib.learn.Estimator` to `tf.estimator.Estimator` in TensorFlow version 1.11.0. In previous version there was an option to use other metrics like accuracy while evaluating the estimator by passing `metrics` to `evaluate` function. In current version if there is a canned estimator, we can define the metrics with `tf.contrib.estimator.add_metrics`, but when I define my estimator and want to use `add_metrics` it says there is no such wrapper. The error is as follow:\r\n`raise TypeError('{!r} is not a Python function'.format(func))\r\nTypeError: <method-wrapper '__call__' of type object at 0x7fff9cb37530> is not a Python function`\r\n\r\nI don't know whether it's because I'm not using canned estimator or something else is wrong with my code. I want to know how I can add metrics to estimator which is not a canned estimator.", "comments": ["Hello @MHDBST , this Stack Overflow post answers your query about metrics with custom estimators:\r\nhttps://stackoverflow.com/questions/50120073/tensorflow-metrics-with-custom-estimator\r\nPlease let us know. Thanks.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "I think that post will solve the problem. Thanks ", "@MHDBST , Thanks, this issue is closed now."]}, {"number": 23964, "title": "Math ops with Tensorflow Lite C++ and Android NDK", "body": "I have successfully installed Tensorflow Lite (C++/so) into an Android product (NDK). I'm looking for the tensorflow math operations, do they exist in tensorflow lite? Or is the sole purpose of tensorflow lite to run inference on models? I also can't seem to find array_ops.h in the tensorflow repository, is this cross complied from some other language?\r\n\r\nTLDR: Does tensorflow lite lack math ops and in order to use them you need the full tensorflow?", "comments": ["In short, YES and NO, there are some math ops in TF Lite. And, no, there is no full tensorflow on Android (as far as I can remember previous TensorFlow Mobile is a subset of TF). For those ops not directly supported by TF Lite you can use something like [flex](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/delegates/flexl) in TFLite to use TF ops. Check this [doc](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/using_select_tf_ops.md) for flex and thie one for  [op list](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/tf_ops_compatibility.md)", "Closing this issue since explanation given by @freedomtan is correct. Feel free to reopen the issue if have any follow up questions. Thanks!", "Are you satisfied with the resolution of your issue?\r\n[Yes](https://goo.gl/forms/Oe0tEvODFRoI2gJF3)\r\n[No](https://goo.gl/forms/fUjzOfrtkFbrOT8d2)"]}, {"number": 23963, "title": "fatal error LNK1120: 4 unresolved externals when using bazel to build transform-graph", "body": "**System information**\r\n- OS Platform and Distribution: Windows 10\r\n- TensorFlow installed from: source\r\n- TensorFlow version: 1.12.0\r\n- Python version: 3.5\r\n- Bazel version (if compiling from source): 0.19.2\r\n- CUDA/cuDNN version: No\r\n- GPU model and memory: No\r\n\r\n**Problem**\r\nI have a build problem when using bazel to build transform-graph. The error is `fatal error LNK1120: 4 unresolved externals`\r\n\r\n**Commands executed before running into the problem**\r\nI've already done `set BAZEL_VC=C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC`\r\nthen `bazel build tensorflow/tools/graph_transforms:transform_graph --local_resources 2048,.5,1.0`\r\n\r\n**Full error log:**\r\n \r\nERROR: C:/users/administrator/desktop/tensorflow-build/tensorflow/tensorflow/tools/graph_transforms/BUILD:219:1: Linking of rule '//tensorflow/tools/graph_transforms:transform_graph' failed (Exit 1120): link.exe failed: error executing command\r\n  cd C:/users/administrator/_bazel_administrator/x7v2faqn/execroot/org_tensorflow\r\n  SET LIB=C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\LIB\\amd64;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\ATLMFC\\LIB\\amd64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.17763.0\\ucrt\\x64;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.6.1\\lib\\um\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.17763.0\\um\\x64;\r\n    SET PATH=C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\amd64;C:\\WINDOWS\\Microsoft.NET\\Framework64\\v4.0.30319;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\VCPackages;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Common7\\IDE;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Common7\\Tools;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Team Tools\\Performance Tools\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Team Tools\\Performance Tools;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\x86;C:\\Program Files (x86)\\Microsoft SDKs\\Windows\\v10.0A\\bin\\NETFX 4.6.1 Tools\\x64\\;;C:\\WINDOWS\\system32\r\n    SET PWD=/proc/self/cwd\r\n    SET PYTHON_BIN_PATH=C:/Anaconda/envs/tensor/python.exe\r\n    SET PYTHON_LIB_PATH=C:/Anaconda/envs/tensor/lib/site-packages\r\n    SET TEMP=C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\r\n    SET TF_DOWNLOAD_CLANG=0\r\n    SET TF_NEED_CUDA=0\r\n    SET TF_NEED_OPENCL_SYCL=0\r\n    SET TF_NEED_ROCM=0\r\n    SET TMP=C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\r\n  C:/Program Files (x86)/Microsoft Visual Studio 14.0/VC/bin/amd64/link.exe /nologo /OUT:bazel-out/x64_windows-opt/bin/tensorflow/tools/graph_transforms/transform_graph.exe /SUBSYSTEM:CONSOLE -DEFAULTLIB:advapi32.lib /MACHINE:X64 @bazel-out/x64_windows-opt/bin/tensorflow/tools/graph_transforms/transform_graph.exe-2.params /OPT:ICF /OPT:REF\r\nLINK : warning LNK4044: unrecognized option '/lpthread'; ignored\r\n   Creating library bazel-out/x64_windows-opt/bin/tensorflow/tools/graph_transforms/transform_graph.lib and object bazel-out/x64_windows-opt/bin/tensorflow/tools/graph_transforms/transform_graph.exp\r\nbatch_kernels.lo.lib(batch_kernels.obj) : warning LNK4217: locally defined symbol ?DEVICE_CPU@tensorflow@@3QEBDEB (char const * const tensorflow::DEVICE_CPU) imported in function \"void __cdecl tensorflow::`dynamic initializer for 'registrar__body__0__object''(void)\" (??__Eregistrar__body__0__object@tensorflow@@YAXXZ)\r\ncaptured_function.lib(captured_function.obj) : warning LNK4049: locally defined symbol ?DEVICE_CPU@tensorflow@@3QEBDEB (char const * const tensorflow::DEVICE_CPU) imported\r\narithmetic_optimizer.lib(arithmetic_optimizer.obj) : warning LNK4049: locally defined symbol ?DEVICE_CPU@tensorflow@@3QEBDEB (char const * const tensorflow::DEVICE_CPU) imported\r\npin_to_host_optimizer.lib(pin_to_host_optimizer.obj) : warning LNK4049: locally defined symbol ?DEVICE_CPU@tensorflow@@3QEBDEB (char const * const tensorflow::DEVICE_CPU) imported\r\narithmetic_optimizer.lib(arithmetic_optimizer.obj) : warning LNK4217: locally defined symbol ?DEVICE_GPU@tensorflow@@3QEBDEB (char const * const tensorflow::DEVICE_GPU) imported in function \"private: bool __cdecl tensorflow::grappler::`anonymous namespace'::ReorderCastAndTranspose::NodeIsOnCpuOrGpu(class tensorflow::NodeDef const *)const \" (?NodeIsOnCpuOrGpu@ReorderCastAndTranspose@?A0x2ef8a95a@grappler@tensorflow@@AEBA_NPEBVNodeDef@4@@Z)\r\nlayout_optimizer.lib(layout_optimizer.obj) : warning LNK4049: locally defined symbol ?DEVICE_GPU@tensorflow@@3QEBDEB (char const * const tensorflow::DEVICE_GPU) imported\r\npin_to_host_optimizer.lib(pin_to_host_optimizer.obj) : warning LNK4049: locally defined symbol ?DEVICE_GPU@tensorflow@@3QEBDEB (char const * const tensorflow::DEVICE_GPU) imported\r\nunicode_script_op.lo.lib(unicode_script_op.obj) : error LNK2019: unresolved external symbol \"__declspec(dllimport) public: virtual __cdecl icu_62::ErrorCode::~ErrorCode(void)\" (__imp_??1ErrorCode@icu_62@@UEAA@XZ) referenced in function \"public: virtual void __cdecl tensorflow::UnicodeScriptOp::Compute(class tensorflow::OpKernelContext *)\" (?Compute@UnicodeScriptOp@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)\r\nunicode_script_op.lo.lib(unicode_script_op.obj) : error LNK2019: unresolved external symbol \"__declspec(dllimport) public: signed char __cdecl icu_62::ErrorCode::isSuccess(void)const \" (__imp_?isSuccess@ErrorCode@icu_62@@QEBACXZ) referenced in function \"public: virtual void __cdecl tensorflow::UnicodeScriptOp::Compute(class tensorflow::OpKernelContext *)\" (?Compute@UnicodeScriptOp@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)\r\nunicode_script_op.lo.lib(unicode_script_op.obj) : error LNK2019: unresolved external symbol \"__declspec(dllimport) public: enum UErrorCode __cdecl icu_62::ErrorCode::reset(void)\" (__imp_?reset@ErrorCode@icu_62@@QEAA?AW4UErrorCode@@XZ) referenced in function \"public: virtual void __cdecl tensorflow::UnicodeScriptOp::Compute(class tensorflow::OpKernelContext *)\" (?Compute@UnicodeScriptOp@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)\r\nunicode_script_op.lo.lib(unicode_script_op.obj) : error LNK2019: unresolved external symbol \"__declspec(dllimport) const icu_62::ErrorCode::`vftable'\" (__imp_??_7ErrorCode@icu_62@@6B@) referenced in function \"public: virtual void __cdecl tensorflow::UnicodeScriptOp::Compute(class tensorflow::OpKernelContext *)\" (?Compute@UnicodeScriptOp@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)\r\nbazel-out/x64_windows-opt/bin/tensorflow/tools/graph_transforms/transform_graph.exe : fatal error LNK1120: 4 unresolved externals\r\nTarget //tensorflow/tools/graph_transforms:transform_graph failed to build\r\nINFO: Elapsed time: 569.319s, Critical Path: 237.59s, Remote (0.00% of the time): [queue: 0.00%, setup: 0.00%, process: 0.00%]\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully\r\n\r\n", "comments": ["Assigning to Pete, since this is about the `transform_graph` tool.", "this is a similar error to what i described in #23955.\r\nalso got a link error while bazel build the transform_graph tool on a windows 10 os.", "Getting same error. Has any progress been made? ", "I've tried some other versions of tensorflow and bazel, but it seems to be a problem with windows 10. I've just simply changed to ubuntu and no more error. ", "Thanks, ubuntu works indeed", "but i only use windows 10 , how can i solve it ? thanks. @habom2310  the same error", "Sorry for the slow response. I haven't had a chance to look at this yet, so keeping it open, but I'm not sure when we will be able to debug it, so adding contributions welcome.", "Also hitting the same error on r1.12 branch, even after applying https://github.com/tensorflow/tensorflow/commit/7e090f6a5412fd5f22b5b75ca7ae7844c3d025e9 :[", "@petewarden Actually, it did fix it, one should just make sure the ` #define U_STATIC_IMPLEMENTATION ` is **before** the other includes, at least on my `r1.12` branch.", "Hello and Thanks all for your comments on this post \r\nAny update on this issue guys ?\r\n@lissyx I tried your suggested solution but still stuck and unable to build transform_graph on windows \r\nIs there any pre-built binaries that we can use instead ?\r\n\r\nThanks and Regards", "@RaniemAR I can't speak for TensorFlow team regarding prebuilt binaries, but make sure you place the define at the right place.\r\nHere: https://github.com/mozilla/tensorflow/commit/ebd1a0ff1a0ed3e211ced4033a42326fd25c8661", "Thanks a lot you were absolutely right, I thought I made sure I added it above the includes but when I double checked i found out that I was wrong. Fixed it and it now builds \r\nThanks a million ", "@petewarden Since our backport of the upstream fix works, I've opened a PR: https://github.com/tensorflow/tensorflow/pull/26845", "Closing as a duplicate of #23955 "]}, {"number": 23962, "title": "[tensorflow/contrib/lite/toco/tflite/export.cc:192] Unsupported operator: MirrorPad", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\nSystem information\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nNo\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nMac\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\nbinary\r\n- TensorFlow version (use command below):\r\n1.12.0\r\n- Python version:\r\nPython 3.6.5 :: Anaconda, Inc.\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\nN/A\r\n- GPU model and memory:\r\nN/A\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n**Describe the current behavior**\r\n\r\n--------------------------------------\r\nI am trying to convert a graph from .pb to .lite format using toco, but I get this error:\r\n2018-11-25 21:58:56.811762: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1080] Converting unsupported operation: MirrorPad\r\n\r\nI think MirrorPad is the basic op, Lite shoud support it.\r\n\r\n---------------------------------------\r\n", "comments": ["You need to build from source or use the nightly pip to get htis op. It was just added 11/20/18.\r\n"]}, {"number": 23961, "title": "Problem installing tensorflow-gpu  (dll load faliure)", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version: tensorflow-1.12.0 (installed via pip3)\r\n- Python version: python 3.6.7\r\n- CUDA/cuDNN version: CUDA==10.0.130 cuDNN==7.4.1\r\n- GPU model and memory: NVIDIA GTX 1050 Ti with Max-Q Design\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nAfter starting python 3.6 in cmd and trying to execute `import tensorflow` I get the following stack trace:\r\n\r\n'>>> import tensorflow\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Sunny Nagam\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Sunny Nagam\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Sunny Nagam\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\Sunny Nagam\\AppData\\Local\\Programs\\Python\\Python36\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\Sunny Nagam\\AppData\\Local\\Programs\\Python\\Python36\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Users\\Sunny Nagam\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"C:\\Users\\Sunny Nagam\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\Sunny Nagam\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\Sunny Nagam\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Sunny Nagam\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Sunny Nagam\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\Sunny Nagam\\AppData\\Local\\Programs\\Python\\Python36\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\Sunny Nagam\\AppData\\Local\\Programs\\Python\\Python36\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.'\r\n\r\n\r\nI have tried installing the CUDA toolkit and cuDNN and adding to my PATH. Here is my current PATH: \r\n\r\n'PATH=C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.0\\extras\\CUPTI\\libx64;C:\\cuda\\bin;C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.0\\bin;C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.0\\libnvvp;C:\\Program Files (x86)\\Common Files\\Oracle\\Java\\javapath;C:\\Program Files (x86)\\Intel\\Intel(R) Management Engine Components\\iCLS\\;C:\\Program Files\\Intel\\Intel(R) Management Engine Components\\iCLS\\;C:\\Windows\\system32;C:\\Windows;C:\\Windows\\System32\\Wbem;C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\;C:\\Windows\\System32\\OpenSSH\\;C:\\Program Files (x86)\\Intel\\Intel(R) Management Engine Components\\DAL;C:\\Program Files\\Intel\\Intel(R) Management Engine Components\\DAL;C:\\Program Files (x86)\\NVIDIA Corporation\\PhysX\\Common;C:\\Users\\Sunny Nagam\\AppData\\Local\\Programs\\Python\\Python36\\Scripts\\;C:\\Users\\Sunny Nagam\\AppData\\Local\\Programs\\Python\\Python36\\;C:\\Users\\Sunny Nagam\\AppData\\Local\\Microsoft\\WindowsApps;'\r\n\r\nI'm unsure if this infromation is helpful but my \\cuda\\bin contains \"cudnn_64_7.dll\" and my CUDA\\v10.0\\bin contains \"cudart64_100.dll\"", "comments": ["I'm experiencing the same problem.\r\n\r\nSystem information\r\n- OS Platform and Distribution: Windows 10 Pro 64bit (Build 17134)\r\n- TensorFlow version: 1.12.0\r\n- TensorFlow-GPU version: 1.12.0\r\n- Python version: 3.6.7\r\n- CUDA version: 10.0.130\r\n- cuDNN version: 7.4.1\r\n- GPU model and memory: GTX 1080 (16243MB)\r\n\r\nTried TensorFlow 1.10.0, but it didn't help.\r\nAccording to https://www.tensorflow.org/install/source_windows, TensorFlow 1.12.0 should work fine with Python 3.6, Microsoft Visual C++ 2015 Update 3, cuDNN 7 and CUDA 9 on Windows 10.\r\nI will try this configuration tonight and let you know.", "Hmm maybe I'll try downgrading to CUDA 9", "Just tried getting CUDA 9 and replacing all the CUDA 10 paths in my PATH with the corresponding CUDA 9 path. Still no luck.\r\n\r\nMy path now is: \"C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.0\\extras\\CUPTI\\libx64;C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.0\\bin;C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.0\\bin;C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.0\\libnvvp;C:\\Program Files (x86)\\Common Files\\Oracle\\Java\\javapath;C:\\Program Files (x86)\\Intel\\Intel(R) Management Engine Components\\iCLS\\;C:\\Program Files\\Intel\\Intel(R) Management Engine Components\\iCLS\\;C:\\Windows\\system32;C:\\Windows;C:\\Windows\\System32\\Wbem;C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\;C:\\Windows\\System32\\OpenSSH\\;C:\\Program Files (x86)\\Intel\\Intel(R) Management Engine Components\\DAL;C:\\Program Files\\Intel\\Intel(R) Management Engine Components\\DAL;C:\\Program Files (x86)\\NVIDIA Corporation\\PhysX\\Common;C:\\Users\\Sunny Nagam\\AppData\\Local\\Programs\\Python\\Python36\\Scripts\\;C:\\Users\\Sunny Nagam\\AppData\\Local\\Programs\\Python\\Python36\\;C:\\Users\\Sunny Nagam\\AppData\\Local\\Microsoft\\WindowsApps;\"", "This issue is a duplicate of #23726", "Downgrading to CUDA==9 and tensorflow-gpu==1.10 has fixed my problem. Thank you for the help!", "You mean downgrading to CUDA 9.0 right?", "Yes i did sorry", "Can confirm. Tensorflow-GPU 1.10 with CUDA 9.0 works for me as well.", "Are you satisfied with the resolution of your issue?\r\n[Yes](https://goo.gl/forms/Oe0tEvODFRoI2gJF3)\r\n[No](https://goo.gl/forms/fUjzOfrtkFbrOT8d2)", "I have same problem.\r\nHow to downgrade Tensorflow-GPU and CUDA ?\r\nthankyou", "I have the same porblem too.\r\n\r\nSystem information:\r\nOS Platform and Distribution: Windows 10\r\nTensorFlow version: tensorflow-1.14.0 (installed via pip3)\r\nPython version: python 3.7.4\r\nCUDA/cuDNN version: CUDA==10.1.0 cuDNN==7.6\r\nGPU model and memory: NVIDIA GTX 1050 3GB", "> Can confirm. Tensorflow-GPU 1.10 with CUDA 9.0 works for me as well.\r\n\r\nC:\\Users\\Saagaa>pip install tensorflow-gpu==1.1\r\nCollecting tensorflow-gpu==1.1\r\n  ERROR: Could not find a version that satisfies the requirement tensorflow-gpu==1.1 (from versions: 1.13.0rc1, 1.13.0rc2, 1.13.1, 1.13.2, 1.14.0rc0, 1.14.0rc1, 1.14.0, 1.15.0rc0, 2.0.0a0, 2.0.0b0, 2.0.0b1, 2.0.0rc0, 2.0.0rc1)\r\nERROR: No matching distribution found for tensorflow-gpu==1.1\r\n\r\nwhat version did you use?\r\n", "> > Can confirm. Tensorflow-GPU 1.10 with CUDA 9.0 works for me as well.\r\n> \r\n> C:\\Users\\Saagaa>pip install tensorflow-gpu==1.1\r\n> Collecting tensorflow-gpu==1.1\r\n> ERROR: Could not find a version that satisfies the requirement tensorflow-gpu==1.1 (from versions: 1.13.0rc1, 1.13.0rc2, 1.13.1, 1.13.2, 1.14.0rc0, 1.14.0rc1, 1.14.0, 1.15.0rc0, 2.0.0a0, 2.0.0b0, 2.0.0b1, 2.0.0rc0, 2.0.0rc1)\r\n> ERROR: No matching distribution found for tensorflow-gpu==1.1\r\n> \r\n> what version did you use?\r\n\r\nThe reason behind it is maybe it has been discontinued, the post is from more than 8 months older than yours"]}, {"number": 23960, "title": "Trying to optimize graph with optimize_for_inference too many positional arguments", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n\r\n- OS Platform and Distribution : windows 10 X64\r\n- TensorFlow installed from (source or binary): pip install\r\n- TensorFlow version  : 1.7.1\r\n- Python version: 36\r\n- CUDA/cuDNN version: cuda v9.0\r\n- GPU model and memory: Nvidia 1070\r\n\r\n\r\n**Describe the current behavior**\r\n\r\n\r\nI'm doing some\u00a0image recognition\u00a0with\u00a0tensorflow. I retrained a\u00a0CNN\u00a0based on\u00a0Inception V3\u00a0with my onw data. \r\n\r\nMy results are pretty good, I'm now trying to optimize the protobuf in order to use it with TFmobile.\r\nSo I'm using optimize_for_inference like this :\r\npython optimize_for_inference.py \r\n--input=\"C:\\Users\\project\\Documents\\peinture\\learn\\retrained_graphpeinture.pb\" \r\n--output=\"C:\\Users\\project\\Documents\\peinture\\learn\\optimized_graph.pb\" \r\n--frozen_graph=\"True\" --input_names=\"Placeholder\" \r\n--output_names=\"final_result\"\r\n\r\nI have in return a message error : File \"optimize_for_inference.py\", line 92, in main FLAGS.toco_compatible) TypeError: optimize_for_inference() takes 4 positional arguments but 5 were given \r\n\r\nI understand that there are too many arg in the py file. \r\nI looked at the file line 92, and there is indeed 5 arguments :\r\noutput_graph_def = optimize_for_inference_lib.optimize_for_inference(  \r\ninput_graph_def,   \r\nFLAGS.input_names.split(\",\"),   \r\nFLAGS.output_names.split(\",\"),   \r\n_parse_placeholder_types(FLAGS.placeholder_type_enum),   \r\nFLAGS.toco_compatible) \r\n\r\nIs my file not the good one ? I don't understand why it doesn't work. I'm pretty sure I'm using the good file (clone form Github). I followed step by step the well known Tensorflow for poets 2 tutorial.Best regards\r\n--\r\n\r\n\r\n\r\nThanks :)", "comments": ["Please help me", "Can you use the latest version of TensorFlow and test again?", "Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 23959, "title": " Commonization of return value's type \u200b\u200bof  tf.image.resize_image_with_crop_or_pad and tf.image.resize_images", "body": "# system \r\ntensorflow ver.  tensorflow-gpu == 1.12.0\r\n\r\n# rough source code\r\n    \r\n    from PIL import Image\r\n    import tensorflow as tf \r\n\r\n    im = Image.open(\"hogehoge.jpeg\")\r\n    w, h = im.size\r\n\r\n    raw_image = tf.read_file(\"hogehoge.jpeg\")\r\n    image = tf.image.decode_jpeg(raw_image, channels = 3) # rgb color image\r\n    print(image.dtype) # => dtype : uint8\r\n    image = tf.image.resize_image_with_crop_or_pad(image, w, w)\r\n    print(image.dtype) # => dtype : unit8\r\n    image = tf.image.resize_images(image, [128, 128])\r\n    print(image.dtype) # => dtype : float32    ??????????????????????????????????????????\r\n\r\n\r\nSo, I want to commonization of return value's type of them. (I want  tf.image.resize_images will return value of dtype : uint8)\r\n     \r\n", "comments": ["This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new). Thanks!\r\n", "Oh, thanks. But I wandering that your [document](https://www.tensorflow.org/api_docs/python/tf/image/resize_image_with_crop_or_pad) says that these function (resize_images_with_crop_or_pad and resize_images) return a float tensor? (\r\nIn fact it is found that resize_images_with_crop_or_pad  is returning different values.)I think this problem cannot be resolved in StackOverflow and other cite.\r\n\r\n(I'm sorry that I cannot descrive more information because this is not program or system problem.)", "Agree!\r\n\r\nRecently I have encounter this issue too...changing the dtype of the returned tensor is so confusing!"]}, {"number": 23958, "title": "pip install tf-nightly-gpu Does not work", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS X El Capitan\r\n- Anaconda\r\n- Pip v.18.1\r\n- Python v.3.6.6 \r\n\r\n**Describe the problem**\r\nCould not find a version that satisfies the requirement tf-nightly-gpu (from versions: )\r\nNo matching distribution found for tf-nightly-gpu\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nFollowing steps on this:\r\nhttps://www.youtube.com/watch?v=xQ4i6sDt-Tk&t=120s", "comments": ["As you can see from https://pypi.org/project/tf-nightly-gpu/#files, the `tf-nightly-gpu` only contains builds for Linux based systems."]}, {"number": 23957, "title": "Inconsistent results between estimator and graph/session", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10.0.17134\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below):1.12.0\r\n- Python version:3.5\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:9.0\r\n- GPU model and memory: GTX1070, 8Gb\r\n\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n**Describe the current behavior**\r\nI implemented the same model (2-layer fully-connected neural network + batch norm to reduce initialization effects) using \r\n1. Low level APIs (graphs and sessions), and\r\n2. High level APIs (estimators)\r\nI tested the two implementation and tested it on the MNIST dataset. The Estimator shows a much slower training and a significantly lower final recognition error. (Estimator: First epoch~92%, Final~96%,  Sess+Graph: First epoch~96%, Final>98%)\r\n**Describe the expected behavior**\r\nThe performance should be similar.\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\nThe High-Level API\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\n#Data\r\nfrom tensorflow.examples.tutorials.mnist import input_data\r\ndata = input_data.read_data_sets(\"/tmp/data/\", one_hot = True)\r\nn_inputs = 784\r\nn_classes = 10\r\n'''Input Function'''\r\ntrain_input_fn = tf.estimator.inputs.numpy_input_fn(\r\n    x={\"x\":np.array(data.train.images)},\r\n    y=np.array(data.train.labels),\r\n    num_epochs=1,\r\n    shuffle=True)\r\n'''Test Function'''\r\ntest_input_fn = tf.estimator.inputs.numpy_input_fn(\r\n    x={\"x\":np.array(data.test.images)},\r\n    y=np.array(data.test.labels),\r\n    num_epochs=1,\r\n    shuffle=False)\r\n\r\n#Training Parameters\r\nparams={\"lr_init\" :0.1,\r\n        \"n_neurons\":200}\r\n\r\n\r\n#Model function\r\ndef model_fn(features, labels, mode, params):\r\n    '''Model Graph'''\r\n    x = features[\"x\"]\r\n    prediction=tf.layers.dense(x, units=params[\"n_neurons\"], activation=None, use_bias=False)\r\n    prediction=tf.layers.batch_normalization(prediction, training=(mode == tf.estimator.ModeKeys.TRAIN))\r\n    prediction=tf.nn.relu(prediction)\r\n    prediction=tf.layers.dense(prediction, units=n_classes, activation=None)\r\n    \r\n    if(mode==tf.estimator.ModeKeys.PREDICT):\r\n        '''If Evaluation, then simply return predictions'''\r\n        spec = tf.estimator.EstimatorSpec(mode=mode, predictions=prediction)\r\n    else:\r\n        '''If Training or Testing, compute loss and accuracy'''\r\n        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=labels))\r\n        metrics = {\"acuracy\":tf.metrics.accuracy(tf.argmax(labels, 1), tf.argmax(prediction, 1))}        \r\n        '''Training Operation'''\r\n        with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\r\n            optimizer = tf.train.MomentumOptimizer(learning_rate=params[\"lr_init\"], momentum=0.9)\r\n        train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())        \r\n        '''Specs for Training and Evaluation'''\r\n        spec=tf.estimator.EstimatorSpec(\r\n            mode=mode,\r\n            loss=loss,\r\n            train_op=train_op,\r\n            eval_metric_ops=metrics)\r\n    \r\n    return spec\r\n\r\nmodel=tf.estimator.Estimator(model_fn=model_fn,\r\n                             params=params,\r\n                             model_dir='./estimator_out/')\r\nfor i in range(100):\r\n    model.train(input_fn=train_input_fn)\r\n    result = model.evaluate(input_fn=test_input_fn)\r\n    print(result)\r\n\r\n```\r\nThe Low-Level API:\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\n#Data\r\nfrom tensorflow.examples.tutorials.mnist import input_data\r\nmnist = input_data.read_data_sets(\"/tmp/data/\", one_hot = True)\r\nn_inputs=784\r\nn_classes=10\r\n\r\n'''Training Parameters'''\r\nparams={\"lr_init\" :0.1,\r\n        \"n_neurons\":200}\r\ntrain_batch=128\r\n\r\n'''Model graph'''                      \r\nx = tf.placeholder(tf.float32, shape=[None, n_inputs])\r\ny = tf.placeholder(tf.float32, shape=[None, n_classes])\r\nlearning_rate = tf.placeholder(tf.float32)\r\ntraining = tf.placeholder(tf.bool)\r\nprediction=tf.layers.dense(x, units=params[\"n_neurons\"], activation=None, use_bias=False)\r\nprediction=tf.layers.batch_normalization(prediction, training=training)\r\nprediction=tf.nn.relu(prediction)\r\nprediction=tf.layers.dense(prediction, units=n_classes, activation=None)\r\n\r\n'''loss and accuracy'''\r\nloss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=y))\r\nwith tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\r\n    optimizer = tf.train.MomentumOptimizer(learning_rate, momentum=0.9).minimize(loss)\r\ncorrect = tf.equal(tf.argmax(prediction, 1), tf.argmax(y,1))\r\naccuracy = tf.reduce_mean(tf.cast(correct, 'float'))\r\n\r\nwith tf.Session() as sess:\r\n    sess.run(tf.global_variables_initializer())\r\n    for epoch in range(100):\r\n        for batch in range(int(mnist.train.num_examples/train_batch)):\r\n            epoch_x, epoch_y=mnist.train.next_batch(train_batch, shuffle=True)\r\n            sess.run(optimizer, feed_dict = {x:epoch_x, y:epoch_y, learning_rate:params[\"lr_init\"], training:True})\r\n        acc = sess.run(accuracy, feed_dict = {x:mnist.test.images, y:mnist.test.labels, learning_rate:0, training:False})\r\n        print('accuracy:',acc)\r\n```", "comments": []}, {"number": 23956, "title": "Tensorflow In Anaconda not found", "body": "Good evening. As I understand tensorflow and keras couldn't be installed in python 3.7 (keras is not used without tensorflow). So I just copy all folders of tensorflow and keras in site-package of anaconda. But system is proceeding with error \"No module named 'tensorflow.python' when I try to import tensorflow (folder tensorflow and folder python exist in directory Local\\Continuum\\anaconda3\\Lib\\site-packages\\). Is there any other opportunity to use module tensorflow and keras in python 3.7?", "comments": ["You could try building from source but it would be easier to just use Python 3.5/3.6 instead. Is there anything that is stopping you from doing that?", "Unfortunately python 3.7 is not yet officially supported. However you can take a look at the work done by the users [here](https://github.com/tensorflow/tensorflow/issues/20517#issuecomment-437324356) which got it working for them. Hope this helps you too. I would also like to recommend you to switch to compatible python version if possible. Thanks!", "Are you satisfied with the resolution of your issue?\r\n[Yes](https://goo.gl/forms/Oe0tEvODFRoI2gJF3)\r\n[No](https://goo.gl/forms/fUjzOfrtkFbrOT8d2)"]}, {"number": 23955, "title": "graph_transforms tool link error in windows 10", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nwindows 10 pro\r\n- TensorFlow installed from (source or binary):\r\nsource\r\n- TensorFlow version:\r\n1.12\r\n- Python version:\r\n3.6\r\n- Installed using virtualenv? pip? conda?:\r\nconda\r\n- Bazel version (if compiling from source):\r\n0.15.2\r\n- GCC/Compiler version (if compiling from source):\r\nvs2015 build tools\r\n- CUDA/cuDNN version:\r\n9.0/7\r\n- GPU model and memory:\r\n2 X pascal6000, 24GB\r\n\r\n\r\n**Describe the problem**\r\n\r\nHi,\r\ni have installed tf 1.12 from source using bazel according to the instruction on site and the build was successful. now i tried building the graph_transforms tool (the reason why i installed tf from source in the first place) but i get the link error in the logs below. i tried following the suggestions in #23655 but i was still getting link errors.\r\nany help on this would be really appreciated, i really want to start using the graph_transforms tool.\r\nthanks\r\n \r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nbazel build tensorflow/tools/graph_transforms:transform_graph\r\n\r\n**Any other info / logs**\r\n\r\n```\r\nERROR: C:/deep/tensorflow/tf-1.12/tensorflow/tensorflow/tools/graph_transforms/BUILD:219:1: Linking of rule '//tensorflow/tools/graph_transforms:transform_graph' failed (Exit 1120): link.exe failed: error executing command\r\n  cd C:/users/iariav/_bazel_iariav/6fo6vxbr/execroot/org_tensorflow\r\n  SET CUDA_TOOLKIT_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v9.0\r\n    SET CUDNN_INSTALL_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v9.0\r\n    SET INCLUDE=C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\ATLMFC\\INCLUDE;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\ucrt;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.6.1\\include\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\shared;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17134.0\\winrt;\r\n    SET LIB=C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\LIB\\amd64;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\ATLMFC\\LIB\\amd64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.17134.0\\ucrt\\x64;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.6.1\\lib\\um\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.17134.0\\um\\x64;\r\n    SET PATH=C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Common7\\IDE\\CommonExtensions\\Microsoft\\TestWindow;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\amd64;C:\\windows\\Microsoft.NET\\Framework64\\v4.0.30319;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\VCPackages;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Common7\\IDE;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Common7\\Tools;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Team Tools\\Performance Tools\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Team Tools\\Performance Tools;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\x86;C:\\Program Files (x86)\\Microsoft SDKs\\Windows\\v10.0A\\bin\\NETFX 4.6.1 Tools\\x64\\;;C:\\WINDOWS\\system32\r\n    SET PWD=/proc/self/cwd\r\n    SET PYTHON_BIN_PATH=C:/Users/iariav/Anaconda3/envs/tensorflow-v1.12/python.exe\r\n    SET PYTHON_LIB_PATH=C:/Users/iariav/Anaconda3/envs/tensorflow-v1.12/lib/site-packages\r\n    SET TEMP=C:\\Users\\iariav\\AppData\\Local\\Temp\r\n    SET TF_CUDA_CLANG=0\r\n    SET TF_CUDA_COMPUTE_CAPABILITIES=6.1\r\n    SET TF_CUDA_VERSION=9.0\r\n    SET TF_CUDNN_VERSION=7\r\n    SET TF_NEED_CUDA=1\r\n    SET TF_NEED_OPENCL_SYCL=0\r\n    SET TF_NEED_ROCM=0\r\n    SET TMP=C:\\Users\\iariav\\AppData\\Local\\Temp\r\n  C:/Program Files (x86)/Microsoft Visual Studio 14.0/VC/bin/amd64/link.exe /nologo /OUT:bazel-out/x64_windows-opt/bin/tensorflow/tools/graph_transforms/transform_graph /SUBSYSTEM:CONSOLE -DEFAULTLIB:advapi32.lib -Wl,-rpath,../local_config_cuda/cuda/lib64 -Wl,-rpath,../local_config_cuda/cuda/extras/CUPTI/lib64 /MACHINE:X64 @bazel-out/x64_windows-opt/bin/tensorflow/tools/graph_transforms/transform_graph-2.params\r\nLINK : warning LNK4044: unrecognized option '/Wl,-rpath,../local_config_cuda/cuda/lib64'; ignored\r\nLINK : warning LNK4044: unrecognized option '/Wl,-rpath,../local_config_cuda/cuda/extras/CUPTI/lib64'; ignored\r\nLINK : warning LNK4044: unrecognized option '/lpthread'; ignored\r\n   Creating library bazel-out/x64_windows-opt/bin/tensorflow/tools/graph_transforms/transform_graph.lib and object bazel-out/x64_windows-opt/bin/tensorflow/tools/graph_transforms/transform_graph.exp\r\nlibbatch_kernels.lo(batch_kernels.o) : warning LNK4217: locally defined symbol ?DEVICE_CPU@tensorflow@@3QEBDEB (char const * const tensorflow::DEVICE_CPU) imported in function \"void __cdecl tensorflow::`dynamic initializer for 'registrar__body__0__object''(void)\" (??__Eregistrar__body__0__object@tensorflow@@YAXXZ)\r\nlibcaptured_function.a(captured_function.o) : warning LNK4049: locally defined symbol ?DEVICE_CPU@tensorflow@@3QEBDEB (char const * const tensorflow::DEVICE_CPU) imported\r\nlibarithmetic_optimizer.a(arithmetic_optimizer.o) : warning LNK4049: locally defined symbol ?DEVICE_CPU@tensorflow@@3QEBDEB (char const * const tensorflow::DEVICE_CPU) imported\r\nlibpin_to_host_optimizer.a(pin_to_host_optimizer.o) : warning LNK4049: locally defined symbol ?DEVICE_CPU@tensorflow@@3QEBDEB (char const * const tensorflow::DEVICE_CPU) imported\r\nlibcuda_platform.lo(cuda_dnn.o) : warning LNK4217: locally defined symbol ?ThenBlasGemm@Stream@stream_executor@@QEAAAEAV12@W4Transpose@blas@2@0_K11MAEBV?$DeviceMemory@M@2@H2HMPEAV52@H@Z (public: class stream_executor::Stream & __cdecl stream_executor::Stream::ThenBlasGemm(enum stream_executor::blas::Transpose,enum stream_executor::blas::Transpose,unsigned __int64,unsigned __int64,unsigned __int64,float,class stream_executor::DeviceMemory<float> const &,int,class stream_executor::DeviceMemory<float> const &,int,float,class stream_executor::DeviceMemory<float> *,int)) imported in function \"public: virtual bool __cdecl stream_executor::cuda::CudnnSupport::DoMatMul(class stream_executor::Stream *,class stream_executor::DeviceMemory<float> const &,class stream_executor::DeviceMemory<float> const &,class stream_executor::dnn::BatchDescriptor const &,class stream_executor::dnn::BatchDescriptor const &,class stream_executor::DeviceMemory<float> *)\" (?DoMatMul@CudnnSupport@cuda@stream_executor@@UEAA_NPEAVStream@3@AEBV?$DeviceMemory@M@3@1AEBVBatchDescriptor@dnn@3@2PEAV53@@Z)\r\nlibarithmetic_optimizer.a(arithmetic_optimizer.o) : warning LNK4217: locally defined symbol ?DEVICE_GPU@tensorflow@@3QEBDEB (char const * const tensorflow::DEVICE_GPU) imported in function \"private: bool __cdecl tensorflow::grappler::`anonymous namespace'::ReorderCastAndTranspose::NodeIsOnCpuOrGpu(class tensorflow::NodeDef const *)const \" (?NodeIsOnCpuOrGpu@ReorderCastAndTranspose@?A0xbb50fe50@grappler@tensorflow@@AEBA_NPEBVNodeDef@4@@Z)\r\nliblayout_optimizer.a(layout_optimizer.o) : warning LNK4049: locally defined symbol ?DEVICE_GPU@tensorflow@@3QEBDEB (char const * const tensorflow::DEVICE_GPU) imported\r\nlibpin_to_host_optimizer.a(pin_to_host_optimizer.o) : warning LNK4049: locally defined symbol ?DEVICE_GPU@tensorflow@@3QEBDEB (char const * const tensorflow::DEVICE_GPU) imported\r\nlibunicode_script_op.lo(unicode_script_op.o) : error LNK2019: unresolved external symbol \"__declspec(dllimport) public: virtual __cdecl icu_62::ErrorCode::~ErrorCode(void)\" (__imp_??1ErrorCode@icu_62@@UEAA@XZ) referenced in function \"public: virtual void __cdecl tensorflow::UnicodeScriptOp::Compute(class tensorflow::OpKernelContext *)\" (?Compute@UnicodeScriptOp@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)\r\nlibunicode_script_op.lo(unicode_script_op.o) : error LNK2019: unresolved external symbol \"__declspec(dllimport) public: signed char __cdecl icu_62::ErrorCode::isSuccess(void)const \" (__imp_?isSuccess@ErrorCode@icu_62@@QEBACXZ) referenced in function \"public: virtual void __cdecl tensorflow::UnicodeScriptOp::Compute(class tensorflow::OpKernelContext *)\" (?Compute@UnicodeScriptOp@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)\r\nlibunicode_script_op.lo(unicode_script_op.o) : error LNK2019: unresolved external symbol \"__declspec(dllimport) public: enum UErrorCode __cdecl icu_62::ErrorCode::reset(void)\" (__imp_?reset@ErrorCode@icu_62@@QEAA?AW4UErrorCode@@XZ) referenced in function \"public: virtual void __cdecl tensorflow::UnicodeScriptOp::Compute(class tensorflow::OpKernelContext *)\" (?Compute@UnicodeScriptOp@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)\r\nlibunicode_script_op.lo(unicode_script_op.o) : error LNK2019: unresolved external symbol \"__declspec(dllimport) const icu_62::ErrorCode::`vftable'\" (__imp_??_7ErrorCode@icu_62@@6B@) referenced in function \"public: virtual void __cdecl tensorflow::UnicodeScriptOp::Compute(class tensorflow::OpKernelContext *)\" (?Compute@UnicodeScriptOp@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)\r\nbazel-out/x64_windows-opt/bin/tensorflow/tools/graph_transforms/transform_graph : fatal error LNK1120: 4 unresolved externals\r\nTarget //tensorflow/tools/graph_transforms:transform_graph failed to build\r\nINFO: Elapsed time: 782.281s, Critical Path: 295.06s\r\nINFO: 1858 processes: 1858 local.\r\nFAILED: Build did NOT complete successfully\r\n```\r\n", "comments": ["I'm having the exact same problem while trying to build example from:\r\nhttps://www.tensorflow.org/guide/extend/cc\r\n\r\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nWindows 10\r\nTensorFlow installed from (source or binary):\r\nsource\r\nTensorFlow version:\r\n1.12\r\nPython version:\r\n3.6\r\nInstalled using virtualenv? pip? conda?:\r\npip\r\nBazel version (if compiling from source):\r\n0.18.1\r\nGCC/Compiler version (if compiling from source):\r\nvs2017 build tools\r\n\r\n`unicode_script_op.lo.lib(unicode_script_op.obj) : error LNK2019: nierozpoznany zewn\u251c\u00actrzny symbol \"__declspec(dllimport) public: virtual __cdecl icu_62::ErrorCode::~ErrorCode(void)\" (__imp_??1ErrorCode@icu_62@@UEAA@XZ) przywo\u252c\u2502any w funkcji \"public: virtual void __cdecl tensorflow::UnicodeScriptOp::Compute(class tensorflow::OpKernelContext *)\" (?Compute@UnicodeScriptOp@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)\r\nunicode_script_op.lo.lib(unicode_script_op.obj) : error LNK2019: nierozpoznany zewn\u251c\u00actrzny symbol \"__declspec(dllimport) public: signed char __cdecl icu_62::ErrorCode::isSuccess(void)const \" (__imp_?isSuccess@ErrorCode@icu_62@@QEBACXZ) przywo\u252c\u2502any w funkcji \"public: virtual void __cdecl tensorflow::UnicodeScriptOp::Compute(class tensorflow::OpKernelContext *)\" (?Compute@UnicodeScriptOp@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)\r\nunicode_script_op.lo.lib(unicode_script_op.obj) : error LNK2019: nierozpoznany zewn\u251c\u00actrzny symbol \"__declspec(dllimport) public: enum UErrorCode __cdecl icu_62::ErrorCode::reset(void)\" (__imp_?reset@ErrorCode@icu_62@@QEAA?AW4UErrorCode@@XZ) przywo\u252c\u2502any w funkcji \"public: virtual void __cdecl tensorflow::UnicodeScriptOp::Compute(class tensorflow::OpKernelContext *)\" (?Compute@UnicodeScriptOp@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)\r\nunicode_script_op.lo.lib(unicode_script_op.obj) : error LNK2019: nierozpoznany zewn\u251c\u00actrzny symbol \"__declspec(dllimport) const icu_62::ErrorCode::``vftable'\" (__imp_??_7ErrorCode@icu_62@@6B@) przywo\u252c\u2502any w funkcji \"public: virtual void __cdecl tensorflow::UnicodeScriptOp::Compute(class tensorflow::OpKernelContext *)\" (?Compute@UnicodeScriptOp@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)\r\nbazel-out/x64_windows-opt/bin/tensorflow/cc/example/example.exe : fatal error LNK1120: liczba nierozpoznanych element\u251c\u2502w zewn\u251c\u00actrznych: 4\r\nTarget //tensorflow/cc/example:example failed to build\r\nINFO: Elapsed time: 74,327s, Critical Path: 26,13s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully\r\nFAILED: Build did NOT complete successfully`\r\n\r\nSorry for some Polish text inside, the error is the same:)", "@meteorcloudy please let me know if you're not the right person to look at these kinds of issues.", "@skye sorry, I don't have time to look into this. This issue is related to https://github.com/tensorflow/tensorflow/issues/23655.\r\nThere is an internal CL trying to fix #23655 (cl/229464102). However, it didn't fix the issue but broke the Windows build. Can you ping the related people?", "Pete, could you redirect to the owners of the graph transform tool?", "The GTT is deprecated and going away in 2.0, so I'm closing this as infeasible, unfortunately."]}, {"number": 23954, "title": "number of detections in the tflite graph", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 1.12.0\r\n- Python version: 2.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: CUDA Version 9.0.176\r\n\r\n- GPU model and memory:\r\n00:02.0 VGA compatible controller [0300]: Intel Corporation Device [8086:591b] (rev 04) (prog-if 00 [VGA controller])\r\n\tDeviceName:  Onboard IGD\r\n\tSubsystem: Dell Device [1028:0802]\r\n\tFlags: bus master, fast devsel, latency 0, IRQ 130\r\n\tMemory at db000000 (64-bit, non-prefetchable) [size=16M]\r\n\tMemory at 70000000 (64-bit, prefetchable) [size=256M]\r\n\tI/O ports at f000 [size=64]\r\n\t[virtual] Expansion ROM at 000c0000 [disabled] [size=128K]\r\n\tCapabilities: <access denied>\r\n\tKernel driver in use: i915\r\n\tKernel modules: i915\r\n\r\n\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n**Describe the current behavior**\r\n\r\n**Describe the expected behavior**\r\nHi\r\n\r\nI'm trying to detect more than 10 objects in the image ( which is default )\r\nI'm usin the following commands:\r\nbazel run -c opt tensorflow/contrib/lite/toco:toco -- --input_file=$OUTPUT_DIR/tflite_graph.pb --output_file=$OUTPUT_DIR/mobile_net_500.tflite --input_shapes=1,300,300,3 --input_arrays=normalized_input_image_tensor --output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' --inference_type=FLOAT --max_detections=500 --max_classes_per_detection=1 --allow_custom_ops\r\n\r\nI also modified\r\nexport_tflite_ssd_graph.py\r\nflags.DEFINE_integer('max_detections', 500 <--- instead of 10,\r\n'Maximum number of detections (boxes) to show.')\r\nflags.DEFINE_integer('max_classes_per_detection', 1,\r\n'Number of classes to display per detection box.')\r\n\r\nbut still giving 10 objects as output in the android [1,10,4].\r\n\r\nany idea?\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\nbazel run -c opt tensorflow/contrib/lite/toco:toco -- --input_file=$OUTPUT_DIR/tflite_graph.pb --output_file=$OUTPUT_DIR/mobile_net_500.tflite --input_shapes=1,300,300,3 --input_arrays=normalized_input_image_tensor --output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' --inference_type=FLOAT --max_detections=500 --max_classes_per_detection=1 --allow_custom_ops\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\n", "comments": ["Edit TFLiteObjectDetectionAPIModel.java NUM_DETECTIONS to be something bigger.\r\n\r\n\r\n", "@SteveIb Is your bug resolved now?", "Closing this, feel free to open if issue still persists.", "@achowdhery yes thanks "]}, {"number": 23953, "title": "Runs out of memory after 3 epochs", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below): ('v1.11.0-0-gc19e29306c', '1.11.0')\r\n\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n('v1.11.0-0-gc19e29306c', '1.11.0')\r\n\r\n**Describe the current behavior**\r\nMy model runs out of memory, but just after 3 epochs.\r\n**Describe the expected behavior**\r\nIt should run out of memory in the first epoch or never.\r\n\r\n**Code to reproduce the issue**\r\n```import numpy as np\r\nimport librosa\r\nimport tensorflow as tf\r\nwave, sr = librosa.load('/home/viktor/PycharmProjects/Record_Audio/all.wav', mono=True, sr=None)\r\nsr = 44032 / 4\r\ndef generator(batch_size):\r\n    while True:\r\n        # start_positions = np.random.randint(0, len(wave) - sr, size=batch_size)\r\n        # batch = []\r\n        batch = []\r\n        for start_position in range(0, len(wave) - sr, 100):\r\n            batch.append(np.expand_dims(np.expand_dims(wave[start_position:start_position + sr], axis=-1), axis=-1))\r\n            # batch1 = np.expand_dims(np.array(batch),axis=-1)\r\n            # batch2 = np.expand_dims(batch1, axis=-1)\r\n            if start_position % batch_size == 0:\r\n                yield np.array(batch), np.array(batch)\r\ndef get_model(input_n):\r\n    input1 = tf.keras.layers.Input(shape=(input_n, 1, 1))\r\n    x_a = input1\r\n    for i in [0,1,2,3,3]:#range(7):\r\n        x_a = tf.keras.layers.Conv2D(8 * (2 ** i), (3, 1), padding='same')(x_a)\r\n        # x_a = tf.keras.layers.BatchNormalization()(x_a)\r\n        x_a = tf.keras.layers.Activation('relu')(x_a)\r\n        x_a = tf.keras.layers.MaxPooling2D(pool_size=(2, 1), padding='same')(\r\n            x_a)  # muss same sein, da wird danach GLOBAL pooling nehmen\r\n    latent = x_a\r\n    x_d = latent\r\n    for i in [3,3,2,1,0]:#range(6, -1, -1):\r\n        x_d = tf.keras.layers.Conv2D(8 * (2 ** i), (3, 1), padding='same')(x_d)\r\n        x_d = tf.keras.layers.Activation('relu')(x_d)\r\n        x_d = tf.keras.layers.UpSampling2D(size=(2, 1))(x_d)\r\n    decoded = tf.keras.layers.Conv2D(1, (3, 1), padding='same')(x_d)\r\n    model_encoder = tf.keras.models.Model(inputs=input1, outputs=latent)\r\n    model = tf.keras.models.Model(inputs=input1, outputs=decoded)\r\n    my_loss = tf.keras.losses.mean_squared_error\r\n    my_opt = tf.keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\r\n    my_metric1 = tf.keras.metrics.binary_accuracy\r\n    my_metric2 = tf.keras.metrics.mean_squared_error\r\n    model.compile(loss=my_loss,\r\n                  optimizer=my_opt,\r\n                  metrics=[my_metric1, my_metric2])\r\n    return model, model_encoder\r\ncallbacks_list = [tf.keras.callbacks.TensorBoard(log_dir='', histogram_freq=0, write_graph=True,\r\n                         write_images=True),\r\n                  tf.keras.callbacks.ModelCheckpoint(monitor='loss',\r\n                                  filepath='weights.{epoch:02d}-{loss:.4f}.hdf5',\r\n                                  save_weights_only=False,\r\n                                  mode='min')]\r\nconfig = tf.ConfigProto()\r\nconfig.gpu_options.allow_growth = True\r\nmy_gen = generator(batch_size=1)\r\nprint 1\r\nwith tf.Session(config=config) as sess:\r\n    print 2\r\n    model, model_encoder = get_model(sr)\r\n    print 3\r\n    model.summary()\r\n\r\n    model.fit_generator(my_gen, steps_per_epoch=100, epochs=400, verbose=1, callbacks=callbacks_list)\r\n\r\n    model_encoder.save('my_encoder_ls_kleiner3_epoch400.h5')\r\n    model.save('my_autocoder_ls_kleiner3_epoch400.h5')\r\n    del model, model_encoder\r\n```\r\n\r\n**Other info / logs**\r\n\r\n> /home/viktor/venv/bin/python2.7 /home/viktor/PycharmProjects/Autoencoder_Project/autio_autoencoder.py\r\n> /home/viktor/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\r\n>   from ._conv import register_converters as _register_converters\r\n> 1\r\n> 2018-11-25 18:59:27.573029: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n> 2018-11-25 18:59:27.650961: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2018-11-25 18:59:27.651531: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: \r\n> name: GeForce 940MX major: 5 minor: 0 memoryClockRate(GHz): 1.189\r\n> pciBusID: 0000:01:00.0\r\n> totalMemory: 1.96GiB freeMemory: 1.74GiB\r\n> 2018-11-25 18:59:27.651542: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0\r\n> 2018-11-25 18:59:28.207185: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n> 2018-11-25 18:59:28.207225: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 \r\n> 2018-11-25 18:59:28.207229: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N \r\n> 2018-11-25 18:59:28.207358: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1493 MB memory) -> physical GPU (device: 0, name: GeForce 940MX, pci bus id: 0000:01:00.0, compute capability: 5.0)\r\n> 2\r\n> 3\r\n> _________________________________________________________________\r\n> Layer (type)                 Output Shape              Param #   \r\n> =================================================================\r\n> input_1 (InputLayer)         (None, 11008, 1, 1)       0         \r\n> _________________________________________________________________\r\n> conv2d (Conv2D)              (None, 11008, 1, 8)       32        \r\n> _________________________________________________________________\r\n> activation (Activation)      (None, 11008, 1, 8)       0         \r\n> _________________________________________________________________\r\n> max_pooling2d (MaxPooling2D) (None, 5504, 1, 8)        0         \r\n> _________________________________________________________________\r\n> conv2d_1 (Conv2D)            (None, 5504, 1, 16)       400       \r\n> _________________________________________________________________\r\n> activation_1 (Activation)    (None, 5504, 1, 16)       0         \r\n> _________________________________________________________________\r\n> max_pooling2d_1 (MaxPooling2 (None, 2752, 1, 16)       0         \r\n> _________________________________________________________________\r\n> conv2d_2 (Conv2D)            (None, 2752, 1, 32)       1568      \r\n> _________________________________________________________________\r\n> activation_2 (Activation)    (None, 2752, 1, 32)       0         \r\n> _________________________________________________________________\r\n> max_pooling2d_2 (MaxPooling2 (None, 1376, 1, 32)       0         \r\n> _________________________________________________________________\r\n> conv2d_3 (Conv2D)            (None, 1376, 1, 64)       6208      \r\n> _________________________________________________________________\r\n> activation_3 (Activation)    (None, 1376, 1, 64)       0         \r\n> _________________________________________________________________\r\n> max_pooling2d_3 (MaxPooling2 (None, 688, 1, 64)        0         \r\n> _________________________________________________________________\r\n> conv2d_4 (Conv2D)            (None, 688, 1, 64)        12352     \r\n> _________________________________________________________________\r\n> activation_4 (Activation)    (None, 688, 1, 64)        0         \r\n> _________________________________________________________________\r\n> max_pooling2d_4 (MaxPooling2 (None, 344, 1, 64)        0         \r\n> _________________________________________________________________\r\n> conv2d_5 (Conv2D)            (None, 344, 1, 64)        12352     \r\n> _________________________________________________________________\r\n> activation_5 (Activation)    (None, 344, 1, 64)        0         \r\n> _________________________________________________________________\r\n> up_sampling2d (UpSampling2D) (None, 688, 1, 64)        0         \r\n> _________________________________________________________________\r\n> conv2d_6 (Conv2D)            (None, 688, 1, 64)        12352     \r\n> _________________________________________________________________\r\n> activation_6 (Activation)    (None, 688, 1, 64)        0         \r\n> _________________________________________________________________\r\n> up_sampling2d_1 (UpSampling2 (None, 1376, 1, 64)       0         \r\n> _________________________________________________________________\r\n> conv2d_7 (Conv2D)            (None, 1376, 1, 32)       6176      \r\n> _________________________________________________________________\r\n> activation_7 (Activation)    (None, 1376, 1, 32)       0         \r\n> _________________________________________________________________\r\n> up_sampling2d_2 (UpSampling2 (None, 2752, 1, 32)       0         \r\n> _________________________________________________________________\r\n> conv2d_8 (Conv2D)            (None, 2752, 1, 16)       1552      \r\n> _________________________________________________________________\r\n> activation_8 (Activation)    (None, 2752, 1, 16)       0         \r\n> _________________________________________________________________\r\n> up_sampling2d_3 (UpSampling2 (None, 5504, 1, 16)       0         \r\n> _________________________________________________________________\r\n> conv2d_9 (Conv2D)            (None, 5504, 1, 8)        392       \r\n> _________________________________________________________________\r\n> activation_9 (Activation)    (None, 5504, 1, 8)        0         \r\n> _________________________________________________________________\r\n> up_sampling2d_4 (UpSampling2 (None, 11008, 1, 8)       0         \r\n> _________________________________________________________________\r\n> conv2d_10 (Conv2D)           (None, 11008, 1, 1)       25        \r\n> =================================================================\r\n> Total params: 53,409\r\n> Trainable params: 53,409\r\n> Non-trainable params: 0\r\n> _________________________________________________________________\r\n> Epoch 1/400\r\n>   1/100 [..............................] - ETA: 3:01 - loss: 5.6426e-08 - binary_accuracy: 0.0614 - mean_squared_error: 5.6426e-08\r\n>   2/100 [..............................] - ETA: 1:41 - loss: 6.8449e-07 - binary_accuracy: 0.0615 - mean_squared_error: 3.5635e-07\r\n>   3/100 [..............................] - ETA: 1:15 - loss: 6.0687e-06 - binary_accuracy: 0.0616 - mean_squared_error: 2.1083e-06\r\n>   4/100 [>.............................] - ETA: 1:02 - loss: 4.7172e-06 - binary_accuracy: 0.0617 - mean_squared_error: 1.6227e-06\r\n>   5/100 [>.............................] - ETA: 54s - loss: 3.9497e-06 - binary_accuracy: 0.0617 - mean_squared_error: 1.3333e-06 \r\n>   6/100 [>.............................] - ETA: 49s - loss: 3.4188e-06 - binary_accuracy: 0.0618 - mean_squared_error: 1.1323e-06\r\n>   7/100 [=>............................] - ETA: 45s - loss: 3.3364e-06 - binary_accuracy: 0.0619 - mean_squared_error: 1.0286e-06\r\n>   8/100 [=>............................] - ETA: 43s - loss: 3.5565e-06 - binary_accuracy: 0.0620 - mean_squared_error: 9.7965e-07\r\n>   9/100 [=>............................] - ETA: 41s - loss: 3.5066e-06 - binary_accuracy: 0.0621 - mean_squared_error: 9.0916e-07\r\n>  10/100 [==>...........................] - ETA: 39s - loss: 3.2021e-06 - binary_accuracy: 0.0622 - mean_squared_error: 8.2287e-07\r\n>  11/100 [==>...........................] - ETA: 38s - loss: 3.2835e-06 - binary_accuracy: 0.0623 - mean_squared_error: 7.8192e-07\r\n>  12/100 [==>...........................] - ETA: 37s - loss: 3.4868e-06 - binary_accuracy: 0.0623 - mean_squared_error: 7.5651e-07\r\n>  13/100 [==>...........................] - ETA: 36s - loss: 3.3766e-06 - binary_accuracy: 0.0624 - mean_squared_error: 7.1047e-07\r\n>  14/100 [===>..........................] - ETA: 35s - loss: 3.2299e-06 - binary_accuracy: 0.0624 - mean_squared_error: 6.6647e-07\r\n>  15/100 [===>..........................] - ETA: 34s - loss: 3.3325e-06 - binary_accuracy: 0.0625 - mean_squared_error: 6.4324e-07\r\n>  16/100 [===>..........................] - ETA: 34s - loss: 3.2538e-06 - binary_accuracy: 0.0626 - mean_squared_error: 6.1113e-07\r\n>  17/100 [====>.........................] - ETA: 33s - loss: 3.1276e-06 - binary_accuracy: 0.0626 - mean_squared_error: 5.7902e-07\r\n>  18/100 [====>.........................] - ETA: 33s - loss: 3.1739e-06 - binary_accuracy: 0.0627 - mean_squared_error: 5.5907e-07\r\n>  19/100 [====>.........................] - ETA: 33s - loss: 3.1019e-06 - binary_accuracy: 0.0627 - mean_squared_error: 5.3465e-07\r\n>  20/100 [=====>........................] - ETA: 32s - loss: 3.0120e-06 - binary_accuracy: 0.0628 - mean_squared_error: 5.1118e-07\r\n>  21/100 [=====>........................] - ETA: 32s - loss: 3.0295e-06 - binary_accuracy: 0.0628 - mean_squared_error: 4.9450e-07\r\n>  22/100 [=====>........................] - ETA: 32s - loss: 2.9529e-06 - binary_accuracy: 0.0629 - mean_squared_error: 4.7480e-07\r\n>  23/100 [=====>........................] - ETA: 32s - loss: 2.9013e-06 - binary_accuracy: 0.0629 - mean_squared_error: 4.5749e-07\r\n>  24/100 [======>.......................] - ETA: 31s - loss: 2.8980e-06 - binary_accuracy: 0.0630 - mean_squared_error: 4.4333e-07\r\n>  25/100 [======>.......................] - ETA: 31s - loss: 2.8224e-06 - binary_accuracy: 0.0630 - mean_squared_error: 4.2721e-07\r\n>  26/100 [======>.......................] - ETA: 31s - loss: 2.8057e-06 - binary_accuracy: 0.0631 - mean_squared_error: 4.1431e-07\r\n>  27/100 [=======>......................] - ETA: 31s - loss: 2.7728e-06 - binary_accuracy: 0.0631 - mean_squared_error: 4.0160e-07\r\n>  28/100 [=======>......................] - ETA: 30s - loss: 2.7213e-06 - binary_accuracy: 0.0632 - mean_squared_error: 3.8895e-07\r\n>  29/100 [=======>......................] - ETA: 30s - loss: 2.7131e-06 - binary_accuracy: 0.0632 - mean_squared_error: 3.7849e-07\r\n>  30/100 [========>.....................] - ETA: 30s - loss: 2.6618e-06 - binary_accuracy: 0.0633 - mean_squared_error: 3.6718e-07\r\n>  31/100 [========>.....................] - ETA: 30s - loss: 2.6473e-06 - binary_accuracy: 0.0633 - mean_squared_error: 3.5764e-07\r\n>  32/100 [========>.....................] - ETA: 29s - loss: 2.6142e-06 - binary_accuracy: 0.0633 - mean_squared_error: 3.4801e-07\r\n>  33/100 [========>.....................] - ETA: 29s - loss: 2.5874e-06 - binary_accuracy: 0.0634 - mean_squared_error: 3.3906e-07\r\n>  34/100 [=========>....................] - ETA: 29s - loss: 2.5688e-06 - binary_accuracy: 0.0634 - mean_squared_error: 3.3078e-07\r\n>  35/100 [=========>....................] - ETA: 29s - loss: 2.5371e-06 - binary_accuracy: 0.0634 - mean_squared_error: 3.2252e-07\r\n>  36/100 [=========>....................] - ETA: 29s - loss: 2.5250e-06 - binary_accuracy: 0.0635 - mean_squared_error: 3.1518e-07\r\n>  37/100 [==========>...................] - ETA: 29s - loss: 2.4949e-06 - binary_accuracy: 0.0635 - mean_squared_error: 3.0769e-07\r\n>  38/100 [==========>...................] - ETA: 29s - loss: 2.4849e-06 - binary_accuracy: 0.0635 - mean_squared_error: 3.0106e-07\r\n>  39/100 [==========>...................] - ETA: 29s - loss: 2.4585e-06 - binary_accuracy: 0.0635 - mean_squared_error: 2.9430e-07\r\n>  40/100 [===========>..................] - ETA: 28s - loss: 2.4495e-06 - binary_accuracy: 0.0636 - mean_squared_error: 2.8825e-07\r\n>  41/100 [===========>..................] - ETA: 28s - loss: 2.4269e-06 - binary_accuracy: 0.0636 - mean_squared_error: 2.8213e-07\r\n>  42/100 [===========>..................] - ETA: 28s - loss: 2.4186e-06 - binary_accuracy: 0.0636 - mean_squared_error: 2.7659e-07\r\n>  43/100 [===========>..................] - ETA: 28s - loss: 2.3995e-06 - binary_accuracy: 0.0636 - mean_squared_error: 2.7102e-07\r\n>  44/100 [============>.................] - ETA: 28s - loss: 2.3915e-06 - binary_accuracy: 0.0637 - mean_squared_error: 2.6592e-07\r\n>  45/100 [============>.................] - ETA: 28s - loss: 2.3764e-06 - binary_accuracy: 0.0637 - mean_squared_error: 2.6085e-07\r\n>  46/100 [============>.................] - ETA: 27s - loss: 2.3676e-06 - binary_accuracy: 0.0637 - mean_squared_error: 2.5611e-07\r\n>  47/100 [=============>................] - ETA: 27s - loss: 2.3571e-06 - binary_accuracy: 0.0637 - mean_squared_error: 2.5151e-07\r\n>  48/100 [=============>................] - ETA: 27s - loss: 2.3469e-06 - binary_accuracy: 0.0637 - mean_squared_error: 2.4708e-07\r\n>  49/100 [=============>................] - ETA: 26s - loss: 2.3409e-06 - binary_accuracy: 0.0637 - mean_squared_error: 2.4290e-07\r\n>  50/100 [==============>...............] - ETA: 26s - loss: 2.3305e-06 - binary_accuracy: 0.0638 - mean_squared_error: 2.3877e-07\r\n>  51/100 [==============>...............] - ETA: 26s - loss: 2.3262e-06 - binary_accuracy: 0.0638 - mean_squared_error: 2.3490e-07\r\n>  52/100 [==============>...............] - ETA: 25s - loss: 2.3192e-06 - binary_accuracy: 0.0638 - mean_squared_error: 2.3111e-07\r\n>  53/100 [==============>...............] - ETA: 25s - loss: 2.3130e-06 - binary_accuracy: 0.0638 - mean_squared_error: 2.2745e-07\r\n>  54/100 [===============>..............] - ETA: 25s - loss: 2.3104e-06 - binary_accuracy: 0.0638 - mean_squared_error: 2.2399e-07\r\n>  55/100 [===============>..............] - ETA: 24s - loss: 2.3047e-06 - binary_accuracy: 0.0638 - mean_squared_error: 2.2057e-07\r\n>  56/100 [===============>..............] - ETA: 24s - loss: 2.3013e-06 - binary_accuracy: 0.0638 - mean_squared_error: 2.1731e-07\r\n>  57/100 [================>.............] - ETA: 24s - loss: 2.3000e-06 - binary_accuracy: 0.0639 - mean_squared_error: 2.1418e-07\r\n>  58/100 [================>.............] - ETA: 23s - loss: 2.2966e-06 - binary_accuracy: 0.0639 - mean_squared_error: 2.1112e-07\r\n>  59/100 [================>.............] - ETA: 23s - loss: 2.2944e-06 - binary_accuracy: 0.0639 - mean_squared_error: 2.0816e-07\r\n>  60/100 [=================>............] - ETA: 22s - loss: 2.2947e-06 - binary_accuracy: 0.0639 - mean_squared_error: 2.0533e-07\r\n>  61/100 [=================>............] - ETA: 22s - loss: 2.2942e-06 - binary_accuracy: 0.0639 - mean_squared_error: 2.0257e-07\r\n>  62/100 [=================>............] - ETA: 22s - loss: 2.2929e-06 - binary_accuracy: 0.0639 - mean_squared_error: 1.9988e-07\r\n>  63/100 [=================>............] - ETA: 21s - loss: 2.2933e-06 - binary_accuracy: 0.0639 - mean_squared_error: 1.9729e-07\r\n>  64/100 [==================>...........] - ETA: 21s - loss: 2.2954e-06 - binary_accuracy: 0.0639 - mean_squared_error: 1.9480e-07\r\n>  65/100 [==================>...........] - ETA: 20s - loss: 2.2974e-06 - binary_accuracy: 0.0639 - mean_squared_error: 1.9238e-07\r\n>  66/100 [==================>...........] - ETA: 20s - loss: 2.2985e-06 - binary_accuracy: 0.0639 - mean_squared_error: 1.9001e-07\r\n>  67/100 [===================>..........] - ETA: 20s - loss: 2.2998e-06 - binary_accuracy: 0.0639 - mean_squared_error: 1.8771e-07\r\n>  68/100 [===================>..........] - ETA: 19s - loss: 2.3021e-06 - binary_accuracy: 0.0639 - mean_squared_error: 1.8548e-07\r\n>  69/100 [===================>..........] - ETA: 19s - loss: 2.3059e-06 - binary_accuracy: 0.0639 - mean_squared_error: 1.8333e-07\r\n>  70/100 [====================>.........] - ETA: 18s - loss: 2.3117e-06 - binary_accuracy: 0.0639 - mean_squared_error: 1.8126e-07\r\n>  71/100 [====================>.........] - ETA: 18s - loss: 2.3200e-06 - binary_accuracy: 0.0639 - mean_squared_error: 1.7928e-07\r\n>  72/100 [====================>.........] - ETA: 17s - loss: 2.3317e-06 - binary_accuracy: 0.0639 - mean_squared_error: 1.7740e-07\r\n>  73/100 [====================>.........] - ETA: 17s - loss: 2.3489e-06 - binary_accuracy: 0.0639 - mean_squared_error: 1.7565e-07\r\n>  74/100 [=====================>........] - ETA: 16s - loss: 2.3727e-06 - binary_accuracy: 0.0639 - mean_squared_error: 1.7402e-07\r\n>  75/100 [=====================>........] - ETA: 16s - loss: 2.4025e-06 - binary_accuracy: 0.0639 - mean_squared_error: 1.7252e-07\r\n>  76/100 [=====================>........] - ETA: 15s - loss: 2.4302e-06 - binary_accuracy: 0.0639 - mean_squared_error: 1.7103e-07\r\n>  77/100 [======================>.......] - ETA: 15s - loss: 2.4468e-06 - binary_accuracy: 0.0639 - mean_squared_error: 1.6944e-07\r\n>  78/100 [======================>.......] - ETA: 14s - loss: 2.4526e-06 - binary_accuracy: 0.0639 - mean_squared_error: 1.6774e-07\r\n>  79/100 [======================>.......] - ETA: 14s - loss: 2.4577e-06 - binary_accuracy: 0.0639 - mean_squared_error: 1.6608e-07\r\n>  80/100 [=======================>......] - ETA: 13s - loss: 2.4705e-06 - binary_accuracy: 0.0639 - mean_squared_error: 1.6454e-07\r\n>  81/100 [=======================>......] - ETA: 13s - loss: 2.4939e-06 - binary_accuracy: 0.0639 - mean_squared_error: 1.6318e-07\r\n>  82/100 [=======================>......] - ETA: 12s - loss: 2.5245e-06 - binary_accuracy: 0.0639 - mean_squared_error: 1.6193e-07\r\n>  83/100 [=======================>......] - ETA: 12s - loss: 2.5491e-06 - binary_accuracy: 0.0639 - mean_squared_error: 1.6064e-07\r\n>  84/100 [========================>.....] - ETA: 11s - loss: 2.5604e-06 - binary_accuracy: 0.0639 - mean_squared_error: 1.5923e-07\r\n>  85/100 [========================>.....] - ETA: 10s - loss: 2.5653e-06 - binary_accuracy: 0.0639 - mean_squared_error: 1.5777e-07\r\n>  86/100 [========================>.....] - ETA: 10s - loss: 2.5760e-06 - binary_accuracy: 0.0639 - mean_squared_error: 1.5640e-07\r\n>  87/100 [=========================>....] - ETA: 9s - loss: 2.5959e-06 - binary_accuracy: 0.0639 - mean_squared_error: 1.5517e-07 \r\n>  88/100 [=========================>....] - ETA: 8s - loss: 2.6178e-06 - binary_accuracy: 0.0639 - mean_squared_error: 1.5399e-07\r\n>  89/100 [=========================>....] - ETA: 8s - loss: 2.6327e-06 - binary_accuracy: 0.0639 - mean_squared_error: 1.5276e-07\r\n>  90/100 [==========================>...] - ETA: 7s - loss: 2.6398e-06 - binary_accuracy: 0.0639 - mean_squared_error: 1.5147e-07\r\n>  91/100 [==========================>...] - ETA: 6s - loss: 2.6464e-06 - binary_accuracy: 0.0639 - mean_squared_error: 1.5020e-07\r\n>  92/100 [==========================>...] - ETA: 6s - loss: 2.6586e-06 - binary_accuracy: 0.0639 - mean_squared_error: 1.4901e-07\r\n>  93/100 [==========================>...] - ETA: 5s - loss: 2.6763e-06 - binary_accuracy: 0.0639 - mean_squared_error: 1.4790e-07\r\n>  94/100 [===========================>..] - ETA: 4s - loss: 2.6945e-06 - binary_accuracy: 0.0639 - mean_squared_error: 1.4683e-07\r\n>  95/100 [===========================>..] - ETA: 3s - loss: 2.7082e-06 - binary_accuracy: 0.0639 - mean_squared_error: 1.4572e-07\r\n>  96/100 [===========================>..] - ETA: 3s - loss: 2.7168e-06 - binary_accuracy: 0.0639 - mean_squared_error: 1.4459e-07\r\n>  97/100 [============================>.] - ETA: 2s - loss: 2.7235e-06 - binary_accuracy: 0.0639 - mean_squared_error: 1.4346e-07\r\n>  98/100 [============================>.] - ETA: 1s - loss: 2.7323e-06 - binary_accuracy: 0.0639 - mean_squared_error: 1.4237e-07\r\n>  99/100 [============================>.] - ETA: 0s - loss: 2.7451e-06 - binary_accuracy: 0.0639 - mean_squared_error: 1.4134e-07\r\n> 100/100 [==============================] - 81s 808ms/step - loss: 2.7638e-06 - binary_accuracy: 0.0639 - mean_squared_error: 1.3951e-07\r\n> Epoch 2/400\r\n>   1/100 [..............................] - ETA: 2:13 - loss: 4.6511e-06 - binary_accuracy: 0.0641 - mean_squared_error: 4.6050e-08\r\n>   2/100 [..............................] - ETA: 2:11 - loss: 4.6505e-06 - binary_accuracy: 0.0641 - mean_squared_error: 4.5819e-08\r\n>   3/100 [..............................] - ETA: 2:10 - loss: 4.5782e-06 - binary_accuracy: 0.0641 - mean_squared_error: 4.4894e-08\r\n>   4/100 [>.............................] - ETA: 2:09 - loss: 4.4568e-06 - binary_accuracy: 0.0641 - mean_squared_error: 4.3509e-08\r\n>   5/100 [>.............................] - ETA: 2:09 - loss: 4.3280e-06 - binary_accuracy: 0.0641 - mean_squared_error: 4.2070e-08\r\n>   6/100 [>.............................] - ETA: 2:12 - loss: 4.2212e-06 - binary_accuracy: 0.0641 - mean_squared_error: 4.0855e-08\r\n>   7/100 [=>............................] - ETA: 2:15 - loss: 4.1498e-06 - binary_accuracy: 0.0642 - mean_squared_error: 3.9987e-08\r\n>   8/100 [=>............................] - ETA: 2:16 - loss: 4.1162e-06 - binary_accuracy: 0.0642 - mean_squared_error: 3.9481e-08\r\n>   9/100 [=>............................] - ETA: 2:17 - loss: 4.1209e-06 - binary_accuracy: 0.0642 - mean_squared_error: 3.9333e-08\r\n>  10/100 [==>...........................] - ETA: 2:18 - loss: 4.1703e-06 - binary_accuracy: 0.0642 - mean_squared_error: 3.9595e-08\r\n>  11/100 [==>...........................] - ETA: 2:18 - loss: 4.2791e-06 - binary_accuracy: 0.0642 - mean_squared_error: 4.0391e-08\r\n>  12/100 [==>...........................] - ETA: 2:18 - loss: 4.4724e-06 - binary_accuracy: 0.0642 - mean_squared_error: 4.1935e-08\r\n>  13/100 [==>...........................] - ETA: 2:18 - loss: 4.7454e-06 - binary_accuracy: 0.0643 - mean_squared_error: 4.4170e-08\r\n>  14/100 [===>..........................] - ETA: 2:18 - loss: 5.0277e-06 - binary_accuracy: 0.0643 - mean_squared_error: 4.6464e-08\r\n>  15/100 [===>..........................] - ETA: 2:17 - loss: 5.1614e-06 - binary_accuracy: 0.0643 - mean_squared_error: 4.7444e-08\r\n>  16/100 [===>..........................] - ETA: 2:16 - loss: 5.1270e-06 - binary_accuracy: 0.0643 - mean_squared_error: 4.6963e-08\r\n>  17/100 [====>.........................] - ETA: 2:16 - loss: 5.0722e-06 - binary_accuracy: 0.0643 - mean_squared_error: 4.6310e-08\r\n>  18/100 [====>.........................] - ETA: 2:14 - loss: 5.1136e-06 - binary_accuracy: 0.0643 - mean_squared_error: 4.6476e-08\r\n>  19/100 [====>.........................] - ETA: 2:12 - loss: 5.2091e-06 - binary_accuracy: 0.0643 - mean_squared_error: 4.7094e-08\r\n>  20/100 [=====>........................] - ETA: 2:10 - loss: 5.2402e-06 - binary_accuracy: 0.0644 - mean_squared_error: 4.7169e-08\r\n>  21/100 [=====>........................] - ETA: 2:08 - loss: 5.1967e-06 - binary_accuracy: 0.0644 - mean_squared_error: 4.6626e-08\r\n>  22/100 [=====>........................] - ETA: 2:07 - loss: 5.1680e-06 - binary_accuracy: 0.0644 - mean_squared_error: 4.6207e-08\r\n>  23/100 [=====>........................] - ETA: 2:05 - loss: 5.1954e-06 - binary_accuracy: 0.0644 - mean_squared_error: 4.6248e-08\r\n>  24/100 [======>.......................] - ETA: 2:03 - loss: 5.2299e-06 - binary_accuracy: 0.0644 - mean_squared_error: 4.6345e-08\r\n>  25/100 [======>.......................] - ETA: 2:01 - loss: 5.2190e-06 - binary_accuracy: 0.0644 - mean_squared_error: 4.6077e-08\r\n>  26/100 [======>.......................] - ETA: 2:00 - loss: 5.1851e-06 - binary_accuracy: 0.0644 - mean_squared_error: 4.5629e-08\r\n>  27/100 [=======>......................] - ETA: 1:58 - loss: 5.1754e-06 - binary_accuracy: 0.0645 - mean_squared_error: 4.5375e-08\r\n>  28/100 [=======>......................] - ETA: 1:57 - loss: 5.1923e-06 - binary_accuracy: 0.0645 - mean_squared_error: 4.5330e-08\r\n>  29/100 [=======>......................] - ETA: 1:55 - loss: 5.2030e-06 - binary_accuracy: 0.0645 - mean_squared_error: 4.5239e-08\r\n>  30/100 [========>.....................] - ETA: 1:54 - loss: 5.1889e-06 - binary_accuracy: 0.0645 - mean_squared_error: 4.4956e-08\r\n>  31/100 [========>.....................] - ETA: 1:52 - loss: 5.1672e-06 - binary_accuracy: 0.0645 - mean_squared_error: 4.4618e-08\r\n>  32/100 [========>.....................] - ETA: 1:51 - loss: 5.1605e-06 - binary_accuracy: 0.0645 - mean_squared_error: 4.4396e-08\r\n>  33/100 [========>.....................] - ETA: 1:49 - loss: 5.1693e-06 - binary_accuracy: 0.0645 - mean_squared_error: 4.4292e-08\r\n>  34/100 [=========>....................] - ETA: 1:48 - loss: 5.1775e-06 - binary_accuracy: 0.0646 - mean_squared_error: 4.4185e-08\r\n>  35/100 [=========>....................] - ETA: 1:47 - loss: 5.1730e-06 - binary_accuracy: 0.0646 - mean_squared_error: 4.3986e-08\r\n>  36/100 [=========>....................] - ETA: 1:46 - loss: 5.1600e-06 - binary_accuracy: 0.0646 - mean_squared_error: 4.3725e-08\r\n>  37/100 [==========>...................] - ETA: 1:45 - loss: 5.1500e-06 - binary_accuracy: 0.0646 - mean_squared_error: 4.3488e-08\r\n>  38/100 [==========>...................] - ETA: 1:44 - loss: 5.1495e-06 - binary_accuracy: 0.0646 - mean_squared_error: 4.3322e-08\r\n>  39/100 [==========>...................] - ETA: 1:44 - loss: 5.1570e-06 - binary_accuracy: 0.0646 - mean_squared_error: 4.3215e-08\r\n>  40/100 [===========>..................] - ETA: 1:43 - loss: 5.1657e-06 - binary_accuracy: 0.0646 - mean_squared_error: 4.3117e-08\r\n>  41/100 [===========>..................] - ETA: 1:42 - loss: 5.1702e-06 - binary_accuracy: 0.0646 - mean_squared_error: 4.2992e-08\r\n>  42/100 [===========>..................] - ETA: 1:40 - loss: 5.1690e-06 - binary_accuracy: 0.0647 - mean_squared_error: 4.2827e-08\r\n>  43/100 [===========>..................] - ETA: 1:39 - loss: 5.1643e-06 - binary_accuracy: 0.0647 - mean_squared_error: 4.2638e-08\r\n>  44/100 [============>.................] - ETA: 1:38 - loss: 5.1592e-06 - binary_accuracy: 0.0647 - mean_squared_error: 4.2449e-08\r\n>  45/100 [============>.................] - ETA: 1:37 - loss: 5.1566e-06 - binary_accuracy: 0.0647 - mean_squared_error: 4.2278e-08\r\n>  46/100 [============>.................] - ETA: 1:35 - loss: 5.1580e-06 - binary_accuracy: 0.0647 - mean_squared_error: 4.2137e-08\r\n>  47/100 [=============>................] - ETA: 1:34 - loss: 5.1646e-06 - binary_accuracy: 0.0647 - mean_squared_error: 4.2031e-08\r\n>  48/100 [=============>................] - ETA: 1:32 - loss: 5.1776e-06 - binary_accuracy: 0.0647 - mean_squared_error: 4.1971e-08\r\n>  49/100 [=============>................] - ETA: 1:31 - loss: 5.1990e-06 - binary_accuracy: 0.0648 - mean_squared_error: 4.1967e-08\r\n>  50/100 [==============>...............] - ETA: 1:29 - loss: 5.2322e-06 - binary_accuracy: 0.0648 - mean_squared_error: 4.2042e-08\r\n>  51/100 [==============>...............] - ETA: 1:27 - loss: 5.2805e-06 - binary_accuracy: 0.0648 - mean_squared_error: 4.2217e-08\r\n>  52/100 [==============>...............] - ETA: 1:26 - loss: 5.3460e-06 - binary_accuracy: 0.0648 - mean_squared_error: 4.2504e-08\r\n>  53/100 [==============>...............] - ETA: 1:24 - loss: 5.4203e-06 - binary_accuracy: 0.0648 - mean_squared_error: 4.2847e-08\r\n>  54/100 [===============>..............] - ETA: 1:22 - loss: 5.4860e-06 - binary_accuracy: 0.0648 - mean_squared_error: 4.3132e-08\r\n>  55/100 [===============>..............] - ETA: 1:21 - loss: 5.5213e-06 - binary_accuracy: 0.0648 - mean_squared_error: 4.3219e-08\r\n>  56/100 [===============>..............] - ETA: 1:19 - loss: 5.5272e-06 - binary_accuracy: 0.0648 - mean_squared_error: 4.3117e-08\r\n>  57/100 [================>.............] - ETA: 1:17 - loss: 5.5249e-06 - binary_accuracy: 0.0649 - mean_squared_error: 4.2964e-08\r\n>  58/100 [================>.............] - ETA: 1:16 - loss: 5.5362e-06 - binary_accuracy: 0.0649 - mean_squared_error: 4.2897e-08\r\n>  59/100 [================>.............] - ETA: 1:14 - loss: 5.5663e-06 - binary_accuracy: 0.0649 - mean_squared_error: 4.2950e-08\r\n>  60/100 [=================>............] - ETA: 1:13 - loss: 5.6027e-06 - binary_accuracy: 0.0649 - mean_squared_error: 4.3042e-08\r\n>  61/100 [=================>............] - ETA: 1:11 - loss: 5.6289e-06 - binary_accuracy: 0.0649 - mean_squared_error: 4.3069e-08\r\n>  62/100 [=================>............] - ETA: 1:10 - loss: 5.6372e-06 - binary_accuracy: 0.0649 - mean_squared_error: 4.2986e-08\r\n>  63/100 [=================>............] - ETA: 1:08 - loss: 5.6366e-06 - binary_accuracy: 0.0649 - mean_squared_error: 4.2849e-08\r\n>  64/100 [==================>...........] - ETA: 1:07 - loss: 5.6406e-06 - binary_accuracy: 0.0649 - mean_squared_error: 4.2741e-08\r\n>  65/100 [==================>...........] - ETA: 1:05 - loss: 5.6555e-06 - binary_accuracy: 0.0649 - mean_squared_error: 4.2699e-08\r\n>  66/100 [==================>...........] - ETA: 1:03 - loss: 5.6778e-06 - binary_accuracy: 0.0650 - mean_squared_error: 4.2703e-08\r\n>  67/100 [===================>..........] - ETA: 1:02 - loss: 5.6985e-06 - binary_accuracy: 0.0650 - mean_squared_error: 4.2697e-08\r\n>  68/100 [===================>..........] - ETA: 1:00 - loss: 5.7110e-06 - binary_accuracy: 0.0650 - mean_squared_error: 4.2642e-08\r\n>  69/100 [===================>..........] - ETA: 59s - loss: 5.7153e-06 - binary_accuracy: 0.0650 - mean_squared_error: 4.2540e-08 \r\n>  70/100 [====================>.........] - ETA: 57s - loss: 5.7170e-06 - binary_accuracy: 0.0650 - mean_squared_error: 4.2422e-08\r\n>  71/100 [====================>.........] - ETA: 55s - loss: 5.7216e-06 - binary_accuracy: 0.0650 - mean_squared_error: 4.2323e-08\r\n>  72/100 [====================>.........] - ETA: 54s - loss: 5.7319e-06 - binary_accuracy: 0.0650 - mean_squared_error: 4.2257e-08\r\n>  73/100 [====================>.........] - ETA: 52s - loss: 5.7473e-06 - binary_accuracy: 0.0650 - mean_squared_error: 4.2221e-08\r\n>  74/100 [=====================>........] - ETA: 50s - loss: 5.7650e-06 - binary_accuracy: 0.0650 - mean_squared_error: 4.2198e-08\r\n>  75/100 [=====================>........] - ETA: 48s - loss: 5.7820e-06 - binary_accuracy: 0.0650 - mean_squared_error: 4.2172e-08\r\n>  76/100 [=====================>........] - ETA: 46s - loss: 5.7958e-06 - binary_accuracy: 0.0651 - mean_squared_error: 4.2128e-08\r\n>  77/100 [======================>.......] - ETA: 45s - loss: 5.8058e-06 - binary_accuracy: 0.0651 - mean_squared_error: 4.2062e-08\r\n>  78/100 [======================>.......] - ETA: 43s - loss: 5.8125e-06 - binary_accuracy: 0.0651 - mean_squared_error: 4.1979e-08\r\n>  79/100 [======================>.......] - ETA: 41s - loss: 5.8174e-06 - binary_accuracy: 0.0651 - mean_squared_error: 4.1886e-08\r\n>  80/100 [=======================>......] - ETA: 39s - loss: 5.8219e-06 - binary_accuracy: 0.0651 - mean_squared_error: 4.1791e-08\r\n>  81/100 [=======================>......] - ETA: 37s - loss: 5.8271e-06 - binary_accuracy: 0.0651 - mean_squared_error: 4.1701e-08\r\n>  82/100 [=======================>......] - ETA: 35s - loss: 5.8339e-06 - binary_accuracy: 0.0651 - mean_squared_error: 4.1620e-08\r\n>  83/100 [=======================>......] - ETA: 33s - loss: 5.8430e-06 - binary_accuracy: 0.0651 - mean_squared_error: 4.1553e-08\r\n>  84/100 [========================>.....] - ETA: 31s - loss: 5.8556e-06 - binary_accuracy: 0.0651 - mean_squared_error: 4.1504e-08\r\n>  85/100 [========================>.....] - ETA: 29s - loss: 5.8737e-06 - binary_accuracy: 0.0652 - mean_squared_error: 4.1486e-08\r\n>  86/100 [========================>.....] - ETA: 27s - loss: 5.9012e-06 - binary_accuracy: 0.0652 - mean_squared_error: 4.1519e-08\r\n>  87/100 [=========================>....] - ETA: 26s - loss: 5.9436e-06 - binary_accuracy: 0.0652 - mean_squared_error: 4.1631e-08\r\n>  88/100 [=========================>....] - ETA: 24s - loss: 6.0074e-06 - binary_accuracy: 0.0652 - mean_squared_error: 4.1857e-08\r\n>  89/100 [=========================>....] - ETA: 22s - loss: 6.0908e-06 - binary_accuracy: 0.0652 - mean_squared_error: 4.2185e-08\r\n>  90/100 [==========================>...] - ETA: 20s - loss: 6.1760e-06 - binary_accuracy: 0.0652 - mean_squared_error: 4.2521e-08\r\n>  91/100 [==========================>...] - ETA: 18s - loss: 6.2324e-06 - binary_accuracy: 0.0652 - mean_squared_error: 4.2704e-08\r\n>  92/100 [==========================>...] - ETA: 16s - loss: 6.2507e-06 - binary_accuracy: 0.0652 - mean_squared_error: 4.2688e-08\r\n>  93/100 [==========================>...] - ETA: 14s - loss: 6.2549e-06 - binary_accuracy: 0.0652 - mean_squared_error: 4.2599e-08\r\n>  94/100 [===========================>..] - ETA: 12s - loss: 6.2718e-06 - binary_accuracy: 0.0652 - mean_squared_error: 4.2576e-08\r\n>  95/100 [===========================>..] - ETA: 10s - loss: 6.3854e-06 - binary_accuracy: 0.0652 - mean_squared_error: 4.3049e-08\r\n>  96/100 [===========================>..] - ETA: 8s - loss: 6.8662e-06 - binary_accuracy: 0.0653 - mean_squared_error: 4.5393e-08 \r\n>  97/100 [============================>.] - ETA: 6s - loss: 7.3806e-06 - binary_accuracy: 0.0653 - mean_squared_error: 4.7896e-08\r\n>  98/100 [============================>.] - ETA: 4s - loss: 7.3750e-06 - binary_accuracy: 0.0653 - mean_squared_error: 4.7759e-08\r\n>  99/100 [============================>.] - ETA: 2s - loss: 7.8195e-06 - binary_accuracy: 0.0653 - mean_squared_error: 4.9885e-08\r\n> 100/100 [==============================] - 207s 2s/step - loss: 7.9570e-06 - binary_accuracy: 0.0653 - mean_squared_error: 5.0452e-08\r\n> Epoch 3/400\r\n>   1/100 [..............................] - ETA: 4:18 - loss: 2.4469e-05 - binary_accuracy: 0.0661 - mean_squared_error: 1.2174e-07\r\n>   2/100 [..............................] - ETA: 4:14 - loss: 2.7106e-05 - binary_accuracy: 0.0661 - mean_squared_error: 1.3449e-07\r\n>   3/100 [..............................] - ETA: 4:13 - loss: 2.1926e-05 - binary_accuracy: 0.0661 - mean_squared_error: 1.0865e-07\r\n>   4/100 [>.............................] - ETA: 4:12 - loss: 2.3737e-05 - binary_accuracy: 0.0661 - mean_squared_error: 1.1723e-07\r\n>   5/100 [>.............................] - ETA: 4:10 - loss: 2.0573e-05 - binary_accuracy: 0.0661 - mean_squared_error: 1.0151e-07\r\n>   6/100 [>.............................] - ETA: 4:10 - loss: 2.2641e-05 - binary_accuracy: 0.0661 - mean_squared_error: 1.1128e-07\r\n>   7/100 [=>............................] - ETA: 4:09 - loss: 2.0556e-05 - binary_accuracy: 0.0661 - mean_squared_error: 1.0094e-07\r\n>   8/100 [=>............................] - ETA: 4:07 - loss: 2.0933e-05 - binary_accuracy: 0.0661 - mean_squared_error: 1.0248e-07\r\n>   9/100 [=>............................] - ETA: 4:04 - loss: 1.9599e-05 - binary_accuracy: 0.0661 - mean_squared_error: 9.5842e-08\r\n>  10/100 [==>...........................] - ETA: 4:02 - loss: 1.9594e-05 - binary_accuracy: 0.0661 - mean_squared_error: 9.5566e-08\r\n>  11/100 [==>...........................] - ETA: 4:00 - loss: 1.8655e-05 - binary_accuracy: 0.0661 - mean_squared_error: 9.0869e-08\r\n>  12/100 [==>...........................] - ETA: 3:59 - loss: 1.8528e-05 - binary_accuracy: 0.0661 - mean_squared_error: 9.0033e-08\r\n>  13/100 [==>...........................] - ETA: 3:56 - loss: 1.7757e-05 - binary_accuracy: 0.0661 - mean_squared_error: 8.6177e-08\r\n>  14/100 [===>..........................] - ETA: 3:54 - loss: 1.7610e-05 - binary_accuracy: 0.0661 - mean_squared_error: 8.5263e-08\r\n>  15/100 [===>..........................] - ETA: 3:55 - loss: 1.6979e-05 - binary_accuracy: 0.0661 - mean_squared_error: 8.2105e-082018-11-25 19:04:59.501703: W tensorflow/core/common_runtime/bfc_allocator.cc:215] Allocator (GPU_0_bfc) ran out of memory trying to allocate 217.69MiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n> \r\n>  16/100 [===>..........................] - ETA: 4:00 - loss: 1.6821e-05 - binary_accuracy: 0.0661 - mean_squared_error: 8.1152e-082018-11-25 19:05:02.936137: W tensorflow/core/common_runtime/bfc_allocator.cc:215] Allocator (GPU_0_bfc) ran out of memory trying to allocate 218.70MiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n> \r\n>  17/100 [====>.........................] - ETA: 4:00 - loss: 1.6288e-05 - binary_accuracy: 0.0661 - mean_squared_error: 7.8482e-082018-11-25 19:05:06.861676: W tensorflow/core/common_runtime/bfc_allocator.cc:215] Allocator (GPU_0_bfc) ran out of memory trying to allocate 219.70MiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n> \r\n>  18/100 [====>.........................] - ETA: 4:04 - loss: 1.6132e-05 - binary_accuracy: 0.0661 - mean_squared_error: 7.7558e-082018-11-25 19:05:10.940344: W tensorflow/core/common_runtime/bfc_allocator.cc:215] Allocator (GPU_0_bfc) ran out of memory trying to allocate 220.71MiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n> \r\n>  19/100 [====>.........................] - ETA: 4:04 - loss: 1.5687e-05 - binary_accuracy: 0.0661 - mean_squared_error: 7.5320e-082018-11-25 19:05:14.366659: W tensorflow/core/common_runtime/bfc_allocator.cc:215] Allocator (GPU_0_bfc) ran out of memory trying to allocate 221.72MiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n> \r\n>  20/100 [=====>........................] - ETA: 4:00 - loss: 1.5526e-05 - binary_accuracy: 0.0661 - mean_squared_error: 7.4390e-082018-11-25 19:05:17.314344: W tensorflow/core/common_runtime/bfc_allocator.cc:215] Allocator (GPU_0_bfc) ran out of memory trying to allocate 222.73MiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n> \r\n>  21/100 [=====>........................] - ETA: 3:57 - loss: 1.5154e-05 - binary_accuracy: 0.0661 - mean_squared_error: 7.2510e-082018-11-25 19:05:20.200250: W tensorflow/core/common_runtime/bfc_allocator.cc:215] Allocator (GPU_0_bfc) ran out of memory trying to allocate 223.73MiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n> \r\n>  22/100 [=====>........................] - ETA: 3:53 - loss: 1.4995e-05 - binary_accuracy: 0.0661 - mean_squared_error: 7.1600e-082018-11-25 19:05:23.086283: W tensorflow/core/common_runtime/bfc_allocator.cc:215] Allocator (GPU_0_bfc) ran out of memory trying to allocate 224.74MiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n> \r\n>  23/100 [=====>........................] - ETA: 3:50 - loss: 1.4684e-05 - binary_accuracy: 0.0661 - mean_squared_error: 7.0018e-082018-11-25 19:05:26.003008: W tensorflow/core/common_runtime/bfc_allocator.cc:215] Allocator (GPU_0_bfc) ran out of memory trying to allocate 225.75MiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n> \r\n>  24/100 [======>.......................] - ETA: 3:48 - loss: 1.4525e-05 - binary_accuracy: 0.0661 - mean_squared_error: 6.9119e-082018-11-25 19:05:29.164767: W tensorflow/core/common_runtime/bfc_allocator.cc:215] Allocator (GPU_0_bfc) ran out of memory trying to allocate 226.76MiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n> \r\n>  25/100 [======>.......................] - ETA: 3:45 - loss: 1.4266e-05 - binary_accuracy: 0.0661 - mean_squared_error: 6.7787e-08\r\n>  26/100 [======>.......................] - ETA: 3:42 - loss: 1.4110e-05 - binary_accuracy: 0.0661 - mean_squared_error: 6.6917e-08\r\n>  27/100 [=======>......................] - ETA: 3:38 - loss: 1.3893e-05 - binary_accuracy: 0.0661 - mean_squared_error: 6.5783e-08\r\n>  28/100 [=======>......................] - ETA: 3:35 - loss: 1.3742e-05 - binary_accuracy: 0.0661 - mean_squared_error: 6.4949e-08\r\n>  29/100 [=======>......................] - ETA: 3:32 - loss: 1.3558e-05 - binary_accuracy: 0.0661 - mean_squared_error: 6.3977e-08\r\n>  30/100 [========>.....................] - ETA: 3:29 - loss: 1.3416e-05 - binary_accuracy: 0.0661 - mean_squared_error: 6.3188e-08\r\n>  31/100 [========>.....................] - ETA: 3:26 - loss: 1.3258e-05 - binary_accuracy: 0.0661 - mean_squared_error: 6.2341e-08\r\n>  32/100 [========>.....................] - ETA: 3:24 - loss: 1.3125e-05 - binary_accuracy: 0.0661 - mean_squared_error: 6.1603e-08\r\n>  33/100 [========>.....................] - ETA: 3:21 - loss: 1.2988e-05 - binary_accuracy: 0.0661 - mean_squared_error: 6.0857e-08\r\n>  34/100 [=========>....................] - ETA: 3:18 - loss: 1.2865e-05 - binary_accuracy: 0.0661 - mean_squared_error: 6.0173e-08\r\n>  35/100 [=========>....................] - ETA: 3:15 - loss: 1.2745e-05 - binary_accuracy: 0.0661 - mean_squared_error: 5.9507e-08\r\n>  36/100 [=========>....................] - ETA: 3:13 - loss: 1.2632e-05 - binary_accuracy: 0.0661 - mean_squared_error: 5.8876e-08\r\n>  37/100 [==========>...................] - ETA: 3:10 - loss: 1.2526e-05 - binary_accuracy: 0.0661 - mean_squared_error: 5.8277e-08\r\n>  38/100 [==========>...................] - ETA: 3:08 - loss: 1.2423e-05 - binary_accuracy: 0.0661 - mean_squared_error: 5.7697e-08\r\n>  39/100 [==========>...................] - ETA: 3:05 - loss: 1.2328e-05 - binary_accuracy: 0.0661 - mean_squared_error: 5.7152e-08\r\n>  40/100 [===========>..................] - ETA: 3:03 - loss: 1.2235e-05 - binary_accuracy: 0.0661 - mean_squared_error: 5.6621e-08\r\n>  41/100 [===========>..................] - ETA: 3:00 - loss: 1.2149e-05 - binary_accuracy: 0.0661 - mean_squared_error: 5.6122e-08\r\n>  42/100 [===========>..................] - ETA: 2:57 - loss: 1.2065e-05 - binary_accuracy: 0.0661 - mean_squared_error: 5.5634e-08\r\n>  43/100 [===========>..................] - ETA: 2:55 - loss: 1.1988e-05 - binary_accuracy: 0.0661 - mean_squared_error: 5.5176e-08\r\n>  44/100 [============>.................] - ETA: 2:52 - loss: 1.1912e-05 - binary_accuracy: 0.0661 - mean_squared_error: 5.4728e-08\r\n>  45/100 [============>.................] - ETA: 2:49 - loss: 1.1842e-05 - binary_accuracy: 0.0661 - mean_squared_error: 5.4305e-08\r\n>  46/100 [============>.................] - ETA: 2:46 - loss: 1.1773e-05 - binary_accuracy: 0.0661 - mean_squared_error: 5.3894e-08\r\n>  47/100 [=============>................] - ETA: 2:43 - loss: 1.1709e-05 - binary_accuracy: 0.0661 - mean_squared_error: 5.3502e-08\r\n>  48/100 [=============>................] - ETA: 2:40 - loss: 1.1648e-05 - binary_accuracy: 0.0661 - mean_squared_error: 5.3123e-08\r\n>  49/100 [=============>................] - ETA: 2:38 - loss: 1.1589e-05 - binary_accuracy: 0.0661 - mean_squared_error: 5.2759e-08\r\n>  50/100 [==============>...............] - ETA: 2:35 - loss: 1.1534e-05 - binary_accuracy: 0.0661 - mean_squared_error: 5.2409e-08\r\n>  51/100 [==============>...............] - ETA: 2:32 - loss: 1.1480e-05 - binary_accuracy: 0.0661 - mean_squared_error: 5.2070e-08\r\n>  52/100 [==============>...............] - ETA: 2:29 - loss: 1.1430e-05 - binary_accuracy: 0.0661 - mean_squared_error: 5.1746e-08\r\n>  53/100 [==============>...............] - ETA: 2:26 - loss: 1.1382e-05 - binary_accuracy: 0.0661 - mean_squared_error: 5.1429e-08\r\n>  54/100 [===============>..............] - ETA: 2:23 - loss: 1.1337e-05 - binary_accuracy: 0.0661 - mean_squared_error: 5.1129e-082018-11-25 19:07:16.149663: W tensorflow/core/common_runtime/bfc_allocator.cc:271] Allocator (GPU_0_bfc) ran out of memory trying to allocate 85.66MiB.  Current allocation summary follows.\r\n> 2018-11-25 19:07:16.149714: I tensorflow/core/common_runtime/bfc_allocator.cc:610] Bin (256): \tTotal Chunks: 162, Chunks in use: 161. 40.5KiB allocated for chunks. 40.2KiB in use in bin. 10.6KiB client-requested in use in bin.\r\n> 2018-11-25 19:07:16.149724: I tensorflow/core/common_runtime/bfc_allocator.cc:610] Bin (512): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n> 2018-11-25 19:07:16.149731: I tensorflow/core/common_runtime/bfc_allocator.cc:610] Bin (1024): \tTotal Chunks: 10, Chunks in use: 10. 15.2KiB allocated for chunks. 15.2KiB in use in bin. 14.5KiB client-requested in use in bin.\r\n> 2018-11-25 19:07:16.149735: I tensorflow/core/common_runtime/bfc_allocator.cc:610] Bin (2048): \tTotal Chunks: 3, Chunks in use: 3. 7.5KiB allocated for chunks. 7.5KiB in use in bin. 4.5KiB client-requested in use in bin.\r\n> 2018-11-25 19:07:16.149739: I tensorflow/core/common_runtime/bfc_allocator.cc:610] Bin (4096): \tTotal Chunks: 10, Chunks in use: 10. 63.2KiB allocated for chunks. 63.2KiB in use in bin. 60.0KiB client-requested in use in bin.\r\n> 2018-11-25 19:07:16.149743: I tensorflow/core/common_runtime/bfc_allocator.cc:610] Bin (8192): \tTotal Chunks: 2, Chunks in use: 2. 18.5KiB allocated for chunks. 18.5KiB in use in bin. 12.0KiB client-requested in use in bin.\r\n> 2018-11-25 19:07:16.149747: I tensorflow/core/common_runtime/bfc_allocator.cc:610] Bin (16384): \tTotal Chunks: 12, Chunks in use: 11. 302.0KiB allocated for chunks. 273.0KiB in use in bin. 264.0KiB client-requested in use in bin.\r\n> 2018-11-25 19:07:16.149752: I tensorflow/core/common_runtime/bfc_allocator.cc:610] Bin (32768): \tTotal Chunks: 14, Chunks in use: 13. 677.2KiB allocated for chunks. 624.8KiB in use in bin. 600.0KiB client-requested in use in bin.\r\n> 2018-11-25 19:07:16.149756: I tensorflow/core/common_runtime/bfc_allocator.cc:610] Bin (65536): \tTotal Chunks: 4, Chunks in use: 4. 314.2KiB allocated for chunks. 314.2KiB in use in bin. 192.0KiB client-requested in use in bin.\r\n> 2018-11-25 19:07:16.149759: I tensorflow/core/common_runtime/bfc_allocator.cc:610] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n> 2018-11-25 19:07:16.149763: I tensorflow/core/common_runtime/bfc_allocator.cc:610] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n> 2018-11-25 19:07:16.149766: I tensorflow/core/common_runtime/bfc_allocator.cc:610] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n> 2018-11-25 19:07:16.149769: I tensorflow/core/common_runtime/bfc_allocator.cc:610] Bin (1048576): \tTotal Chunks: 1, Chunks in use: 0. 1.59MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n> 2018-11-25 19:07:16.149772: I tensorflow/core/common_runtime/bfc_allocator.cc:610] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n> 2018-11-25 19:07:16.149776: I tensorflow/core/common_runtime/bfc_allocator.cc:610] Bin (4194304): \tTotal Chunks: 1, Chunks in use: 0. 4.00MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n> 2018-11-25 19:07:16.149780: I tensorflow/core/common_runtime/bfc_allocator.cc:610] Bin (8388608): \tTotal Chunks: 2, Chunks in use: 1. 18.71MiB allocated for chunks. 10.71MiB in use in bin. 10.71MiB client-requested in use in bin.\r\n> 2018-11-25 19:07:16.149784: I tensorflow/core/common_runtime/bfc_allocator.cc:610] Bin (16777216): \tTotal Chunks: 5, Chunks in use: 3. 101.54MiB allocated for chunks. 58.83MiB in use in bin. 53.54MiB client-requested in use in bin.\r\n> 2018-11-25 19:07:16.149789: I tensorflow/core/common_runtime/bfc_allocator.cc:610] Bin (33554432): \tTotal Chunks: 10, Chunks in use: 9. 448.83MiB allocated for chunks. 406.00MiB in use in bin. 385.49MiB client-requested in use in bin.\r\n> 2018-11-25 19:07:16.149794: I tensorflow/core/common_runtime/bfc_allocator.cc:610] Bin (67108864): \tTotal Chunks: 7, Chunks in use: 7. 577.49MiB allocated for chunks. 577.49MiB in use in bin. 513.98MiB client-requested in use in bin.\r\n> 2018-11-25 19:07:16.149798: I tensorflow/core/common_runtime/bfc_allocator.cc:610] Bin (134217728): \tTotal Chunks: 2, Chunks in use: 2. 339.68MiB allocated for chunks. 339.68MiB in use in bin. 171.33MiB client-requested in use in bin.\r\n> 2018-11-25 19:07:16.149801: I tensorflow/core/common_runtime/bfc_allocator.cc:610] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n> 2018-11-25 19:07:16.149805: I tensorflow/core/common_runtime/bfc_allocator.cc:626] Bin for 85.66MiB was 64.00MiB, Chunk State: \r\n> 2018-11-25 19:07:16.149810: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020c0000 of size 1280\r\n> 2018-11-25 19:07:16.149813: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020c0500 of size 256\r\n> 2018-11-25 19:07:16.149815: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020c0600 of size 256\r\n> 2018-11-25 19:07:16.149817: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020c0700 of size 256\r\n> 2018-11-25 19:07:16.149820: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020c0800 of size 256\r\n> 2018-11-25 19:07:16.149822: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020c0900 of size 256\r\n> 2018-11-25 19:07:16.149825: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020c0a00 of size 256\r\n> 2018-11-25 19:07:16.149827: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020c0b00 of size 256\r\n> 2018-11-25 19:07:16.149830: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020c0c00 of size 256\r\n> 2018-11-25 19:07:16.149832: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020c0d00 of size 256\r\n> 2018-11-25 19:07:16.149835: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020c0e00 of size 256\r\n> 2018-11-25 19:07:16.149837: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020c0f00 of size 256\r\n> 2018-11-25 19:07:16.149840: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020c1000 of size 256\r\n> 2018-11-25 19:07:16.149842: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020c1100 of size 256\r\n> 2018-11-25 19:07:16.149845: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020c1200 of size 256\r\n> 2018-11-25 19:07:16.149847: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020c1300 of size 256\r\n> 2018-11-25 19:07:16.149849: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020c1400 of size 256\r\n> 2018-11-25 19:07:16.149852: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020c1500 of size 256\r\n> 2018-11-25 19:07:16.149854: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020c1600 of size 256\r\n> 2018-11-25 19:07:16.149857: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020c1700 of size 256\r\n> 2018-11-25 19:07:16.149859: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020c1800 of size 256\r\n> 2018-11-25 19:07:16.149861: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020c1900 of size 256\r\n> 2018-11-25 19:07:16.149864: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020c1a00 of size 256\r\n> 2018-11-25 19:07:16.149866: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020c1b00 of size 256\r\n> 2018-11-25 19:07:16.149868: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020c1c00 of size 256\r\n> 2018-11-25 19:07:16.149871: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020c1d00 of size 256\r\n> 2018-11-25 19:07:16.149874: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020c1e00 of size 256\r\n> 2018-11-25 19:07:16.149879: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020c1f00 of size 256\r\n> 2018-11-25 19:07:16.149882: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020c2000 of size 256\r\n> 2018-11-25 19:07:16.149886: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020c2100 of size 256\r\n> 2018-11-25 19:07:16.149890: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020c2200 of size 256\r\n> 2018-11-25 19:07:16.149895: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020c2300 of size 256\r\n> 2018-11-25 19:07:16.149899: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020c2400 of size 256\r\n> 2018-11-25 19:07:16.149903: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020c2500 of size 256\r\n> 2018-11-25 19:07:16.149907: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020c2600 of size 256\r\n> 2018-11-25 19:07:16.149911: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020c2700 of size 49152\r\n> 2018-11-25 19:07:16.149915: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020ce700 of size 49152\r\n> 2018-11-25 19:07:16.149918: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Free  at 0x7020da700 of size 53760\r\n> 2018-11-25 19:07:16.149920: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020e7900 of size 256\r\n> 2018-11-25 19:07:16.149923: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020e7a00 of size 256\r\n> 2018-11-25 19:07:16.149926: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020e7b00 of size 1536\r\n> 2018-11-25 19:07:16.149928: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020e8100 of size 1536\r\n> 2018-11-25 19:07:16.149931: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020e8700 of size 256\r\n> 2018-11-25 19:07:16.149933: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020e8800 of size 6400\r\n> 2018-11-25 19:07:16.149936: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020ea100 of size 256\r\n> 2018-11-25 19:07:16.149938: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020ea200 of size 256\r\n> 2018-11-25 19:07:16.149941: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020ea300 of size 24832\r\n> 2018-11-25 19:07:16.149943: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020f0400 of size 256\r\n> 2018-11-25 19:07:16.149946: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020f0500 of size 256\r\n> 2018-11-25 19:07:16.149949: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020f0600 of size 256\r\n> 2018-11-25 19:07:16.149951: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020f0700 of size 256\r\n> 2018-11-25 19:07:16.149953: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020f0800 of size 256\r\n> 2018-11-25 19:07:16.149956: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020f0900 of size 256\r\n> 2018-11-25 19:07:16.149958: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020f0a00 of size 256\r\n> 2018-11-25 19:07:16.149961: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020f0b00 of size 256\r\n> 2018-11-25 19:07:16.149963: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020f0c00 of size 256\r\n> 2018-11-25 19:07:16.149965: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020f0d00 of size 256\r\n> 2018-11-25 19:07:16.149968: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020f0e00 of size 6144\r\n> 2018-11-25 19:07:16.149970: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Free  at 0x7020f2600 of size 256\r\n> 2018-11-25 19:07:16.149973: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020f2700 of size 256\r\n> 2018-11-25 19:07:16.149975: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020f2800 of size 256\r\n> 2018-11-25 19:07:16.149978: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020f2900 of size 6144\r\n> 2018-11-25 19:07:16.149980: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020f4100 of size 256\r\n> 2018-11-25 19:07:16.149983: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020f4200 of size 256\r\n> 2018-11-25 19:07:16.149985: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020f4300 of size 256\r\n> 2018-11-25 19:07:16.149988: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020f4400 of size 256\r\n> 2018-11-25 19:07:16.149990: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020f4500 of size 256\r\n> 2018-11-25 19:07:16.149992: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020f4600 of size 256\r\n> 2018-11-25 19:07:16.149995: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020f4700 of size 256\r\n> 2018-11-25 19:07:16.149997: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020f4800 of size 256\r\n> 2018-11-25 19:07:16.149999: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020f4900 of size 256\r\n> 2018-11-25 19:07:16.150002: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020f4a00 of size 256\r\n> 2018-11-25 19:07:16.150004: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020f4b00 of size 256\r\n> 2018-11-25 19:07:16.150007: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020f4c00 of size 256\r\n> 2018-11-25 19:07:16.150009: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020f4d00 of size 256\r\n> 2018-11-25 19:07:16.150011: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020f4e00 of size 256\r\n> 2018-11-25 19:07:16.150014: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020f4f00 of size 256\r\n> 2018-11-25 19:07:16.150016: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020f5000 of size 256\r\n> 2018-11-25 19:07:16.150019: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020f5100 of size 1536\r\n> 2018-11-25 19:07:16.150021: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020f5700 of size 256\r\n> 2018-11-25 19:07:16.150023: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020f5800 of size 256\r\n> 2018-11-25 19:07:16.150026: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020f5900 of size 256\r\n> 2018-11-25 19:07:16.150028: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020f5a00 of size 256\r\n> 2018-11-25 19:07:16.150030: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020f5b00 of size 256\r\n> 2018-11-25 19:07:16.150033: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020f5c00 of size 256\r\n> 2018-11-25 19:07:16.150035: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020f5d00 of size 256\r\n> 2018-11-25 19:07:16.150037: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020f5e00 of size 256\r\n> 2018-11-25 19:07:16.150040: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020f5f00 of size 256\r\n> 2018-11-25 19:07:16.150042: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020f6000 of size 256\r\n> 2018-11-25 19:07:16.150045: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020f6100 of size 256\r\n> 2018-11-25 19:07:16.150047: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020f6200 of size 256\r\n> 2018-11-25 19:07:16.150049: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020f6300 of size 256\r\n> 2018-11-25 19:07:16.150052: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020f6400 of size 1536\r\n> 2018-11-25 19:07:16.150054: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020f6a00 of size 24576\r\n> 2018-11-25 19:07:16.150057: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020fca00 of size 6144\r\n> 2018-11-25 19:07:16.150059: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020fe200 of size 256\r\n> 2018-11-25 19:07:16.150062: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020fe300 of size 6144\r\n> 2018-11-25 19:07:16.150064: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7020ffb00 of size 1536\r\n> 2018-11-25 19:07:16.150067: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x702100100 of size 256\r\n> 2018-11-25 19:07:16.150069: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x702100200 of size 256\r\n> 2018-11-25 19:07:16.150072: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x702100300 of size 256\r\n> 2018-11-25 19:07:16.150074: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x702100400 of size 24576\r\n> 2018-11-25 19:07:16.150076: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x702106400 of size 256\r\n> 2018-11-25 19:07:16.150079: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x702106500 of size 49152\r\n> 2018-11-25 19:07:16.150081: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x702112500 of size 256\r\n> 2018-11-25 19:07:16.150084: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x702112600 of size 256\r\n> 2018-11-25 19:07:16.150086: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x702112700 of size 256\r\n> 2018-11-25 19:07:16.150088: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x702112800 of size 256\r\n> 2018-11-25 19:07:16.150091: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x702112900 of size 256\r\n> 2018-11-25 19:07:16.150093: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x702112a00 of size 256\r\n> 2018-11-25 19:07:16.150096: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x702112b00 of size 256\r\n> 2018-11-25 19:07:16.150098: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x702112c00 of size 256\r\n> 2018-11-25 19:07:16.150101: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x702112d00 of size 256\r\n> 2018-11-25 19:07:16.150103: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x702112e00 of size 256\r\n> 2018-11-25 19:07:16.150105: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x702112f00 of size 1536\r\n> 2018-11-25 19:07:16.150108: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x702113500 of size 24576\r\n> 2018-11-25 19:07:16.150110: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x702119500 of size 6144\r\n> 2018-11-25 19:07:16.150113: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x70211ad00 of size 24576\r\n> 2018-11-25 19:07:16.150115: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x702120d00 of size 256\r\n> 2018-11-25 19:07:16.150118: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x702120e00 of size 256\r\n> 2018-11-25 19:07:16.150120: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x702120f00 of size 256\r\n> 2018-11-25 19:07:16.150122: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x702121000 of size 256\r\n> 2018-11-25 19:07:16.150125: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x702121100 of size 256\r\n> 2018-11-25 19:07:16.150127: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x702121200 of size 256\r\n> 2018-11-25 19:07:16.150130: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Free  at 0x702121300 of size 29696\r\n> 2018-11-25 19:07:16.150132: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x702128700 of size 256\r\n> 2018-11-25 19:07:16.150134: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x702128800 of size 49408\r\n> 2018-11-25 19:07:16.150137: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x702134900 of size 51200\r\n> 2018-11-25 19:07:16.150139: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x702141100 of size 256\r\n> 2018-11-25 19:07:16.150142: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x702141200 of size 27904\r\n> 2018-11-25 19:07:16.150145: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x702147f00 of size 24576\r\n> 2018-11-25 19:07:16.150147: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x70214df00 of size 29184\r\n> 2018-11-25 19:07:16.150150: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x702155100 of size 1536\r\n> 2018-11-25 19:07:16.150152: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x702155700 of size 256\r\n> 2018-11-25 19:07:16.150155: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x702155800 of size 256\r\n> 2018-11-25 19:07:16.150157: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x702155900 of size 256\r\n> 2018-11-25 19:07:16.150159: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x702155a00 of size 256\r\n> 2018-11-25 19:07:16.150162: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x702155b00 of size 256\r\n> 2018-11-25 19:07:16.150164: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x702155c00 of size 256\r\n> 2018-11-25 19:07:16.150167: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x702155d00 of size 1792\r\n> 2018-11-25 19:07:16.150169: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x702156400 of size 256\r\n> 2018-11-25 19:07:16.150171: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x702156500 of size 1792\r\n> 2018-11-25 19:07:16.150175: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x702156c00 of size 256\r\n> 2018-11-25 19:07:16.150179: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x702156d00 of size 6144\r\n> 2018-11-25 19:07:16.150183: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x702158500 of size 10496\r\n> 2018-11-25 19:07:16.150187: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x70215ae00 of size 256\r\n> 2018-11-25 19:07:16.150191: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x70215af00 of size 256\r\n> 2018-11-25 19:07:16.150195: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x70215b000 of size 256\r\n> 2018-11-25 19:07:16.150200: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x70215b100 of size 256\r\n> 2018-11-25 19:07:16.150204: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x70215b200 of size 2816\r\n> 2018-11-25 19:07:16.150208: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x70215bd00 of size 7424\r\n> 2018-11-25 19:07:16.150212: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x70215da00 of size 49152\r\n> 2018-11-25 19:07:16.150216: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x702169a00 of size 24576\r\n> 2018-11-25 19:07:16.150220: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x70216fa00 of size 24576\r\n> 2018-11-25 19:07:16.150225: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x702175a00 of size 49152\r\n> 2018-11-25 19:07:16.150229: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x702181a00 of size 95488\r\n> 2018-11-25 19:07:16.150233: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x702198f00 of size 49152\r\n> 2018-11-25 19:07:16.150237: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7021a4f00 of size 49152\r\n> 2018-11-25 19:07:16.150241: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7021b0f00 of size 61696\r\n> 2018-11-25 19:07:16.150246: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7021c0000 of size 49920\r\n> 2018-11-25 19:07:16.150250: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7021cc300 of size 74496\r\n> 2018-11-25 19:07:16.150255: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7021de600 of size 25600\r\n> 2018-11-25 19:07:16.150259: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7021e4a00 of size 34048\r\n> 2018-11-25 19:07:16.150263: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7021ecf00 of size 49408\r\n> 2018-11-25 19:07:16.150267: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7021f9000 of size 69888\r\n> 2018-11-25 19:07:16.150271: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x70220a100 of size 256\r\n> 2018-11-25 19:07:16.150274: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x70220a200 of size 81920\r\n> 2018-11-25 19:07:16.150278: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x70221e200 of size 256\r\n> 2018-11-25 19:07:16.150282: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x70221e300 of size 256\r\n> 2018-11-25 19:07:16.150286: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x70221e400 of size 256\r\n> 2018-11-25 19:07:16.150290: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x70221e500 of size 256\r\n> 2018-11-25 19:07:16.150294: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x70221e600 of size 256\r\n> 2018-11-25 19:07:16.150299: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x70221e700 of size 256\r\n> 2018-11-25 19:07:16.150302: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x70221e800 of size 256\r\n> 2018-11-25 19:07:16.150304: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x70221e900 of size 256\r\n> 2018-11-25 19:07:16.150307: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x70221ea00 of size 256\r\n> 2018-11-25 19:07:16.150309: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x70221eb00 of size 256\r\n> 2018-11-25 19:07:16.150311: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x70221ec00 of size 256\r\n> 2018-11-25 19:07:16.150314: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x70221ed00 of size 256\r\n> 2018-11-25 19:07:16.150316: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x70221ee00 of size 256\r\n> 2018-11-25 19:07:16.150319: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x70221ef00 of size 256\r\n> 2018-11-25 19:07:16.150321: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x70221f000 of size 256\r\n> 2018-11-25 19:07:16.150324: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x70221f100 of size 256\r\n> 2018-11-25 19:07:16.150326: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x70221f200 of size 256\r\n> 2018-11-25 19:07:16.150329: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x70221f300 of size 256\r\n> 2018-11-25 19:07:16.150331: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x70221f400 of size 256\r\n> 2018-11-25 19:07:16.150333: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x70221f500 of size 256\r\n> 2018-11-25 19:07:16.150336: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x70221f600 of size 256\r\n> 2018-11-25 19:07:16.150338: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x70221f700 of size 256\r\n> 2018-11-25 19:07:16.150340: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x70221f800 of size 256\r\n> 2018-11-25 19:07:16.150343: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x70221f900 of size 256\r\n> 2018-11-25 19:07:16.150345: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x70221fa00 of size 256\r\n> 2018-11-25 19:07:16.150347: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x70221fb00 of size 256\r\n> 2018-11-25 19:07:16.150350: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x70221fc00 of size 256\r\n> 2018-11-25 19:07:16.150352: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x70221fd00 of size 256\r\n> 2018-11-25 19:07:16.150354: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x70221fe00 of size 256\r\n> 2018-11-25 19:07:16.150357: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x70221ff00 of size 256\r\n> 2018-11-25 19:07:16.150359: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x702220000 of size 2816\r\n> 2018-11-25 19:07:16.150362: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x702220b00 of size 256\r\n> 2018-11-25 19:07:16.150364: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x702220c00 of size 256\r\n> 2018-11-25 19:07:16.150366: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x702220d00 of size 256\r\n> 2018-11-25 19:07:16.150369: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x702220e00 of size 256\r\n> 2018-11-25 19:07:16.150371: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x702220f00 of size 256\r\n> 2018-11-25 19:07:16.150373: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x702221000 of size 256\r\n> 2018-11-25 19:07:16.150376: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x702221100 of size 256\r\n> 2018-11-25 19:07:16.150378: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x702221200 of size 256\r\n> 2018-11-25 19:07:16.150380: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x702221300 of size 256\r\n> 2018-11-25 19:07:16.150383: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x702221400 of size 256\r\n> 2018-11-25 19:07:16.150385: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x702221500 of size 256\r\n> 2018-11-25 19:07:16.150388: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x702221600 of size 256\r\n> 2018-11-25 19:07:16.150390: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x702221700 of size 256\r\n> 2018-11-25 19:07:16.150392: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x702221800 of size 256\r\n> 2018-11-25 19:07:16.150395: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x702221900 of size 2048\r\n> 2018-11-25 19:07:16.150398: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x702222100 of size 8448\r\n> 2018-11-25 19:07:16.150400: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x702224200 of size 6144\r\n> 2018-11-25 19:07:16.150403: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x702225a00 of size 7936\r\n> 2018-11-25 19:07:16.150405: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x702227900 of size 256\r\n> 2018-11-25 19:07:16.150407: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Free  at 0x702227a00 of size 1672704\r\n> 2018-11-25 19:07:16.150410: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Free  at 0x7028c0000 of size 4194304\r\n> 2018-11-25 19:07:16.150412: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Free  at 0x702cc0000 of size 8388608\r\n> 2018-11-25 19:07:16.150415: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7034c0000 of size 16777216\r\n> 2018-11-25 19:07:16.150418: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7044c0000 of size 11228160\r\n> 2018-11-25 19:07:16.150420: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Free  at 0x704f75400 of size 22326272\r\n> 2018-11-25 19:07:16.150422: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7064c0000 of size 67108864\r\n> 2018-11-25 19:07:16.150425: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x70a4c0000 of size 44912640\r\n> 2018-11-25 19:07:16.150428: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x70cf95000 of size 89305088\r\n> 2018-11-25 19:07:16.150430: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7124c0000 of size 89825280\r\n> 2018-11-25 19:07:16.150433: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x717a6a000 of size 178610176\r\n> 2018-11-25 19:07:16.150435: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7224c0000 of size 44912640\r\n> 2018-11-25 19:07:16.150438: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x724f95000 of size 44912640\r\n> 2018-11-25 19:07:16.150440: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x727a6a000 of size 89825280\r\n> 2018-11-25 19:07:16.150443: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x72d014000 of size 44912640\r\n> 2018-11-25 19:07:16.150445: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Free  at 0x72fae9000 of size 44912640\r\n> 2018-11-25 19:07:16.150447: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7325be000 of size 89825280\r\n> 2018-11-25 19:07:16.150450: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x737b68000 of size 177569792\r\n> 2018-11-25 19:07:16.150452: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7424c0000 of size 44912640\r\n> 2018-11-25 19:07:16.150455: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x744f95000 of size 22456320\r\n> 2018-11-25 19:07:16.150457: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Free  at 0x7464ff800 of size 22456320\r\n> 2018-11-25 19:07:16.150460: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x747a6a000 of size 89825280\r\n> 2018-11-25 19:07:16.150462: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x74d014000 of size 89825280\r\n> 2018-11-25 19:07:16.150465: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7525be000 of size 44912640\r\n> 2018-11-25 19:07:16.150467: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x755093000 of size 22456320\r\n> 2018-11-25 19:07:16.150470: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7565fd800 of size 44912640\r\n> 2018-11-25 19:07:16.150472: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x7590d2800 of size 44912640\r\n> 2018-11-25 19:07:16.150474: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Chunk at 0x75bba7800 of size 66422784\r\n> 2018-11-25 19:07:16.150478: I tensorflow/core/common_runtime/bfc_allocator.cc:651]      Summary of in-use Chunks by size: \r\n> 2018-11-25 19:07:16.150485: I tensorflow/core/common_runtime/bfc_allocator.cc:654] 161 Chunks of size 256 totalling 40.2KiB\r\n> 2018-11-25 19:07:16.150491: I tensorflow/core/common_runtime/bfc_allocator.cc:654] 1 Chunks of size 1280 totalling 1.2KiB\r\n> 2018-11-25 19:07:16.150497: I tensorflow/core/common_runtime/bfc_allocator.cc:654] 7 Chunks of size 1536 totalling 10.5KiB\r\n> 2018-11-25 19:07:16.150502: I tensorflow/core/common_runtime/bfc_allocator.cc:654] 2 Chunks of size 1792 totalling 3.5KiB\r\n> 2018-11-25 19:07:16.150507: I tensorflow/core/common_runtime/bfc_allocator.cc:654] 1 Chunks of size 2048 totalling 2.0KiB\r\n> 2018-11-25 19:07:16.150512: I tensorflow/core/common_runtime/bfc_allocator.cc:654] 2 Chunks of size 2816 totalling 5.5KiB\r\n> 2018-11-25 19:07:16.150517: I tensorflow/core/common_runtime/bfc_allocator.cc:654] 7 Chunks of size 6144 totalling 42.0KiB\r\n> 2018-11-25 19:07:16.150522: I tensorflow/core/common_runtime/bfc_allocator.cc:654] 1 Chunks of size 6400 totalling 6.2KiB\r\n> 2018-11-25 19:07:16.150527: I tensorflow/core/common_runtime/bfc_allocator.cc:654] 1 Chunks of size 7424 totalling 7.2KiB\r\n> 2018-11-25 19:07:16.150533: I tensorflow/core/common_runtime/bfc_allocator.cc:654] 1 Chunks of size 7936 totalling 7.8KiB\r\n> 2018-11-25 19:07:16.150538: I tensorflow/core/common_runtime/bfc_allocator.cc:654] 1 Chunks of size 8448 totalling 8.2KiB\r\n> 2018-11-25 19:07:16.150543: I tensorflow/core/common_runtime/bfc_allocator.cc:654] 1 Chunks of size 10496 totalling 10.2KiB\r\n> 2018-11-25 19:07:16.150548: I tensorflow/core/common_runtime/bfc_allocator.cc:654] 7 Chunks of size 24576 totalling 168.0KiB\r\n> 2018-11-25 19:07:16.150554: I tensorflow/core/common_runtime/bfc_allocator.cc:654] 1 Chunks of size 24832 totalling 24.2KiB\r\n> 2018-11-25 19:07:16.150557: I tensorflow/core/common_runtime/bfc_allocator.cc:654] 1 Chunks of size 25600 totalling 25.0KiB\r\n> 2018-11-25 19:07:16.150560: I tensorflow/core/common_runtime/bfc_allocator.cc:654] 1 Chunks of size 27904 totalling 27.2KiB\r\n> 2018-11-25 19:07:16.150563: I tensorflow/core/common_runtime/bfc_allocator.cc:654] 1 Chunks of size 29184 totalling 28.5KiB\r\n> 2018-11-25 19:07:16.150566: I tensorflow/core/common_runtime/bfc_allocator.cc:654] 1 Chunks of size 34048 totalling 33.2KiB\r\n> 2018-11-25 19:07:16.150569: I tensorflow/core/common_runtime/bfc_allocator.cc:654] 7 Chunks of size 49152 totalling 336.0KiB\r\n> 2018-11-25 19:07:16.150572: I tensorflow/core/common_runtime/bfc_allocator.cc:654] 2 Chunks of size 49408 totalling 96.5KiB\r\n> 2018-11-25 19:07:16.150575: I tensorflow/core/common_runtime/bfc_allocator.cc:654] 1 Chunks of size 49920 totalling 48.8KiB\r\n> 2018-11-25 19:07:16.150578: I tensorflow/core/common_runtime/bfc_allocator.cc:654] 1 Chunks of size 51200 totalling 50.0KiB\r\n> 2018-11-25 19:07:16.150581: I tensorflow/core/common_runtime/bfc_allocator.cc:654] 1 Chunks of size 61696 totalling 60.2KiB\r\n> 2018-11-25 19:07:16.150584: I tensorflow/core/common_runtime/bfc_allocator.cc:654] 1 Chunks of size 69888 totalling 68.2KiB\r\n> 2018-11-25 19:07:16.150587: I tensorflow/core/common_runtime/bfc_allocator.cc:654] 1 Chunks of size 74496 totalling 72.8KiB\r\n> 2018-11-25 19:07:16.150590: I tensorflow/core/common_runtime/bfc_allocator.cc:654] 1 Chunks of size 81920 totalling 80.0KiB\r\n> 2018-11-25 19:07:16.150593: I tensorflow/core/common_runtime/bfc_allocator.cc:654] 1 Chunks of size 95488 totalling 93.2KiB\r\n> 2018-11-25 19:07:16.150596: I tensorflow/core/common_runtime/bfc_allocator.cc:654] 1 Chunks of size 11228160 totalling 10.71MiB\r\n> 2018-11-25 19:07:16.150599: I tensorflow/core/common_runtime/bfc_allocator.cc:654] 1 Chunks of size 16777216 totalling 16.00MiB\r\n> 2018-11-25 19:07:16.150602: I tensorflow/core/common_runtime/bfc_allocator.cc:654] 2 Chunks of size 22456320 totalling 42.83MiB\r\n> 2018-11-25 19:07:16.150605: I tensorflow/core/common_runtime/bfc_allocator.cc:654] 8 Chunks of size 44912640 totalling 342.66MiB\r\n> 2018-11-25 19:07:16.150608: I tensorflow/core/common_runtime/bfc_allocator.cc:654] 1 Chunks of size 66422784 totalling 63.35MiB\r\n> 2018-11-25 19:07:16.150611: I tensorflow/core/common_runtime/bfc_allocator.cc:654] 1 Chunks of size 67108864 totalling 64.00MiB\r\n> 2018-11-25 19:07:16.150614: I tensorflow/core/common_runtime/bfc_allocator.cc:654] 1 Chunks of size 89305088 totalling 85.17MiB\r\n> 2018-11-25 19:07:16.150618: I tensorflow/core/common_runtime/bfc_allocator.cc:654] 5 Chunks of size 89825280 totalling 428.32MiB\r\n> 2018-11-25 19:07:16.150621: I tensorflow/core/common_runtime/bfc_allocator.cc:654] 1 Chunks of size 177569792 totalling 169.34MiB\r\n> 2018-11-25 19:07:16.150624: I tensorflow/core/common_runtime/bfc_allocator.cc:654] 1 Chunks of size 178610176 totalling 170.34MiB\r\n> 2018-11-25 19:07:16.150627: I tensorflow/core/common_runtime/bfc_allocator.cc:658] Sum Total of in-use chunks: 1.36GiB\r\n> 2018-11-25 19:07:16.150632: I tensorflow/core/common_runtime/bfc_allocator.cc:660] Stats: \r\n> Limit:                  1565786112\r\n> InUse:                  1461751552\r\n> MaxInUse:               1494473216\r\n> NumAllocs:                  110326\r\n> MaxAllocSize:            375537664\r\n> \r\n> 2018-11-25 19:07:16.150646: W tensorflow/core/common_runtime/bfc_allocator.cc:275] ***_***********xx************xxxxx***************__************xxxxx*****_*************************x\r\n> 2018-11-25 19:07:16.150663: W tensorflow/core/framework/op_kernel.cc:1273] OP_REQUIRES failed at image_resizer_state.h:115 : Resource exhausted: OOM when allocating tensor with shape[255,11008,1,8] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n> Traceback (most recent call last):\r\n>   File \"/home/viktor/PycharmProjects/Autoencoder_Project/autio_autoencoder.py\", line 98, in <module>\r\n>     model.fit_generator(my_gen, steps_per_epoch=100, epochs=400, verbose=1, callbacks=callbacks_list)\r\n>   File \"/home/viktor/venv/local/lib/python2.7/site-packages/tensorflow/python/keras/engine/training.py\", line 2065, in fit_generator\r\n>     initial_epoch=initial_epoch)\r\n>   File \"/home/viktor/venv/local/lib/python2.7/site-packages/tensorflow/python/keras/engine/training_generator.py\", line 171, in fit_generator\r\n>     x, y, sample_weight=sample_weight, class_weight=class_weight)\r\n>   File \"/home/viktor/venv/local/lib/python2.7/site-packages/tensorflow/python/keras/engine/training.py\", line 1828, in train_on_batch\r\n>     outputs = self.train_function(ins)\r\n>   File \"/home/viktor/venv/local/lib/python2.7/site-packages/tensorflow/python/keras/backend.py\", line 2978, in __call__\r\n>     run_metadata=self.run_metadata)\r\n>   File \"/home/viktor/venv/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1399, in __call__\r\n>     run_metadata_ptr)\r\n>   File \"/home/viktor/venv/local/lib/python2.7/site-packages/tensorflow/python/framework/errors_impl.py\", line 526, in __exit__\r\n>     c_api.TF_GetCode(self.status.status))\r\n> tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[255,11008,1,8] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n> \t [[{{node up_sampling2d_4/ResizeNearestNeighbor}} = ResizeNearestNeighbor[T=DT_FLOAT, _class=[\"loc:@train...ighborGrad\"], align_corners=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](activation_9/Relu-0-0-TransposeNCHWToNHWC-LayoutOptimizer, up_sampling2d_4/mul)]]\r\n> Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n> \r\n> \t [[{{node metrics/mean_squared_error/Mean_1/_215}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1731_metrics/mean_squared_error/Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\r\n> Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n> \r\n> \r\n> Process finished with exit code 1\r\n> \r\n", "comments": ["It looks like you are falling short of GPU memory for your computation.\r\nTry reducing the batch size and shut down all other processes which engages gpu memory.", "I have the same OOM when use tf.data. GPU memory increased after some epoch, but front several epoch is no problem. if dont use tf.data, there is no this issue.", "@mrry Can you please take a look? Thanks!", "Regarding the original issue from @corner100, I'm not sure what the cause is, but it could be an issue in Keras, or in the lower level GPU code, neither of which is my area.\r\n\r\n@IMLHF It sounds like you might be running into a different problem... or at least, it's hard to tell because it's not clear how exactly you're using tf.data. Can you please post a separate issue with details of how to reproduce your problem?", "@mrry Sorry, my fault. it's caused by memory leak, I fix it by finalize my graph to find the bug. \r\n@corner100 I never use tf.keras, may be you should try to finalize your compute-graph to test if there are memory leak. emmmmm....forgive my badly english. Thanks.", "@IMLHF Thanks for confirming and thanks for the suggestion!", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Closing due to lack of recent activity from the original author. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 23952, "title": "Tensorflow dense_image_warp Failed to convert object of type <type 'list'> to Tensor", "body": "Using up-to-date Keras and Tensorflow r1.12 on Ubuntu 16.04 and 14.04. For the following code:\r\n   \r\n    img2D = Input(shape=(100, 100, 3))\r\n    refPosX = Input(shape=(100, 100, 1))\r\n    refPosY = Input(shape=(100, 100, 1))\r\n\r\n    depth_map = depth_net(dFeatures)\r\n    curX = tf.multiply(depth_map, refPosX)\r\n    curY = tf.multiply(depth_map, refPosY)\r\n    dMove = tf.concat([curX, curY], axis=3)\r\n\r\n    warped = tfc.image.dense_image_warp(img2D, dMove)\r\n\r\nI'm receiving the error output:\r\n\r\n    Using TensorFlow backend.\r\n    Traceback (most recent call last):\r\n    File \"/home/carson/ws/dla/test_network_5/depth_and_color_nets.py\", line 89, in <module>\r\n    File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/image/python/ops/dense_image_warp.py\", line 195, in dense_image_warp\r\n    [batch_size, height * width, 2])\r\n     File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 6482, in reshape\r\n    \"Reshape\", tensor=tensor, shape=shape, name=name)\r\n    File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 513, in _apply_op_helper\r\n    raise err\r\n    TypeError: Failed to convert object of type <type 'list'> to Tensor. Contents: [None, 10000, 2]. Consider casting elements to a supported type.\r\n\r\nThis seems to only be happening with this function, so unless I've missed something in the documentation, I'm not sure what's going on here :/", "comments": ["So, I've tracked it so far just to array_ops (from tensorflow.python.ops import array_ops)\r\n\r\n    batch_size, height, width, channels = img2D.get_shape().as_list()\r\n    query_flat = array_ops.reshape(img2D, (batch_size, height*width, 2))\r\n\r\nThis returns the same error, but the type is now of course of type 'tuple' that throws the error. I don't quite understand what's happening in the reshape function in array ops.\r\n", "Now I've noticed that the most recent version of dense_image_warp changes the way in which shapes are obtained, going from \r\n\r\n    batch_size, height, width, channels = image.get_shape().as_list()\r\n\r\nto \r\n\r\n    batch_size, height, width, channels = (array_ops.shape(image)[0],\r\n                                  array_ops.shape(image)[1],\r\n                                  array_ops.shape(image)[2],\r\n                                  array_ops.shape(image)[3])\r\n\r\nHowever, no shapes seem to be returned... just (?, ?, ?, ?)\r\n\r\nEdit 1:\r\nI've also just realized there's a good chance that array_ops might also have been changed, so now installing/building most recent version of tensorflow, though it seems like it should have worked fine before...\r\n\r\nEdit 2:\r\nTried with newest version, the only return is (?, ?, ?, ?)", "Got it, define batch_shape. :/"]}, {"number": 23951, "title": "During config, please provide an error or warning if too low of a computer capability is set.", "body": "During config, we can request the required computer capabilties to be compiled to. For the newer tensorflows >1.10 we can request using cuda computer capabilities 3.0, but after tensorflow is built it is not usable unless there is a compute capabilties >=3.5.\r\n\r\nSeems like a warning would be appropriate especially considering the 4+ hours of compiling afterwards will succeed, but fail when actually attempting to use the built packages.", "comments": ["@gunan  Can this be added as a feature ?", "I think it does make a lot of sense.\r\nIt should be quite straightforward to add it in configure.py\r\nIf anyone would like to contribute this, I am happy to review\r\n", "@gunan I can submit a patch for this. Can you please suggest a good warning message? I have framed this one based on what @odinsbane said, but I'm not sure if its good enough `Warning: CUDA compute capabilities >= 3.5 are required for TensorFlow to work.`", "Thanks for the offer to help, @Sudeepam97! We appreciate it. :smile: \r\n\r\n@gunan, @martinwicke - Should the error message shown above be modified to reflect CUDA requirements in TF 2.0 vs TF 1.12?", "No, compute capabilities are independent of the CUDA version. The message is great.", "Hi @dynamicwebpaige and @martinwicke. I have submitted a PR for this issue. You can check it out.", "Thank you, @Sudeepam97! :smile_cat: We appreciate it."]}, {"number": 23950, "title": "tensorflow 1.10.0 build error", "body": "when i use \"bazel build --config=opt --config=cuda //tensorflow:libtensorflow_cc.so\" to build tensorflow c++ API\uff0c I got this error: tensorflow/cc/BUILD:477:1: Linking of rule '//tensorflow/cc:ops/random_ops_gen_cc' failed (Exit 1)", "comments": ["@Roython  We encourage you to use the latest 2 versions of tensorflow. (i.e 1.11 or 1.12).\r\n@gunan  Please add your thoughts.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Closing as there is no response received from the user for more than 7 days. Feel free to add comments if any, we will reopen. Thanks !"]}, {"number": 23949, "title": "Feature Request: Derivative-Free Optimization", "body": "**System information**\r\n- TensorFlow version (you are using): 1.12\r\n- Are you willing to contribute it (Yes/No): Yes\r\nYes but I'm not sure exactly how to get it done right now.\r\n\r\n**Describe the feature and the current behavior/state.**\r\nOften we need to optimize dense nets without derivatives/gradients. It would be excellent to have some built-in derivative-free optimization tools!\r\nhttps://en.wikipedia.org/wiki/Derivative-free_optimization\r\n\r\n**Will this change the current api? How?**\r\nYes, we could use derivative free optimization without gradients, gradient tape.\r\nThere's one example in Tensorflow Probability but the docs aren't super clear on how to implement this:\r\nhttps://github.com/tensorflow/probability/blob/master/tensorflow_probability/python/optimizer/nelder_mead.py\r\n\r\n**Who will benefit with this feature?**\r\nUsers who want to do RL can use this if the objective function is difficult / impossible to differentiate, or other situations where gradient calculation doesn't work.\r\n\r\n**Any Other info.**\r\nEager + tf.keras.Model support would be excellent", "comments": ["Here's a review on methods for derivative free optimization:\r\n\r\nhttp://thales.cheme.cmu.edu/dfo/comparison/dfo.pdf", "One potential strategy scales well as proven by OpenAI\r\nhttps://blog.openai.com/evolution-strategies/", "Evolving Stable Strategies by David Ha\r\nhttp://blog.otoro.net/2017/11/12/evolving-stable-strategies/", "Sure, that sounds like a good idea. I'm not totally sure if that has enough usage to warrant going into tensorflow itself or if it should be in its standalone repo.", "This seems like something implementable on top of tensorflow. If you have a prototype it should live somewhere in the ecosystem, but we'd like to wait until something is fairly mature to add it to core tensorflow.", "http://www.jmlr.org/papers/volume15/wierstra14a/wierstra14a.pdf", "I stumbled in a problem of time series forecast to which it would be good to have a custom loss function which depends on iterating over the series sequentially and using state-dependent logic to calculate an accumulation function. I couldn't find a way to do it with TensorFlow symbolic operations, thus my intended loss function is non-differentiable by TensorFlow and hence cannot be used. "]}]