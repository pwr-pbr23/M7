[{"number": 1240, "title": "Cherry-pick into r0.7: Add community projects to the resources page", "body": "This supercedes some pull requests requesting to put these on the from page. We will only include what's included in the repo itself in the top-level readme, and add a pointer here instead.\n\nCloses #995, closes #1223.\n", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request) and all commit authors, but as best as we can tell these commits were authored by someone else.  If that's the case,  please add them to this pull request and have them confirm that they're okay with these commits being contributed to Google.  If we're mistaken and you did author these commits, just reply here to confirm.\n\n<!-- need_author_consent -->\n", "Am I added to this pull request? Just wondering how the CLA thing works\n", "It's a bug in the CLA checker -- it doesn't look for the commits in other branches of the same repo (e.g., master).\n"]}, {"number": 1239, "title": "Merge branch from 0.7.1 into master", "body": "", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request) and all commit authors, but as best as we can tell these commits were authored by someone else.  If that's the case,  please add them to this pull request and have them confirm that they're okay with these commits being contributed to Google.  If we're mistaken and you did author these commits, just reply here to confirm.\n\n<!-- need_author_consent -->\n", "lgtm\n", "@tensorflow-jenkins: test this please\n"]}, {"number": 1238, "title": "Update RELEASE.md for 0.7.1", "body": "", "comments": []}, {"number": 1237, "title": "Go bindings", "body": "This adds initial support for go via swig.\n", "comments": ["Can one of the admins verify this patch?\n", "Thanks so much for contributing this, Travis!  I've put some code comments above;  most are nitpicky, but some should be given a bit of thought (such as the Right Way(tm) to represent sizes, and adding more tests -- we depend heavily upon having good test coverage to not accidentally break things during refactoring.)\n", "Final final question (i hope):  What's the story for memory management w.r.t. calling Data on a tensor, and did you verify that the C allocations are getting properly deleted when the Go objects are destroyed?  (This may be obvious to someone with more recent swig experience than I!)\n", "Thank you for the insightful comments and review. Great suggestions. I'll get the PR amended.\n", "Also, can you move the whole tree to contrib/go please? We'd like for fast-moving code to live in contrib.\n", "@martinwicke I was considering the aesthetics of the import path on use\n", "I don't actually know much about how that would look like from the go side. We're giving guarantees about the API stability for things not in contrib, so we need to be confident things will stay as they are, and for large chunks like this one, I'd rather have them live in contrib for a while until things have settled with some actual use.\n\nAnother alternative would be a tensorflow/tensorflow-go repo which could point to tensorflow/tensorflow as a submodule. \n", "Agreed.  I think a final question for this - perhaps one that's deferrable, particularly if we put it in contrib - is:  What to do with Tensors once they're in Go?  A quick check doesn't suggest that there are immediately obvious libraries to use beyond 2D matrices, but I might be missing something.\n\nServing in many cases can probably get by with extracting arrays of basic types, but it's worth thinking a bit about what the better general solution is.  I don't have a great idea yet.\n\nIn chewing on this more, I'd probably go with something like:\nUnmarshalTensor(t Tensor *, v interface{})\n\nin an analogous way to Go marshaling for other 'foreign' types.  It should be relatively straightforward to reflect upon the tensor and unmarshal it into [][]floats, etc.\n\nThis seems like something that could be added later - this binding is enough to at least let one do that by hand for now.  That said, _having_ the unmarshal interface available might make testing a lot easier. :)\n", "Hi, tmc - just wanted to check on this, and note that if you'd like, I'm happy to help with some of the additional test code.  LMK.  I'd love to see this happen. :)\n", "(Looks like tmc responded to feedback but didn't know that other folks don't get notified when code is pushed up or just forgot to drop a comment.)\n", "(Indeed, GitHub is quite annoying.  We'll try to get to this soon!)\n", "Agh - I fail github 101 and didn't have my notifications configured properly.  I'll get on this towards the end of this week - I'm OOO.  Very sorry about that.\n", "Reviewing and checking now!\n", "Looks good aside from a few very minor typos, Martin's suggestion of moving to contrib/, and probably needing a few more tests.  Could you add some of the tests noted earlier, and we can get it merged?\n", "Great work, @tmc ! Hope that will be merged soon. \n\nIt would be great if someone, who successfully used TF with Go add a tiny how-to text about start using it (in tensorflow/go/README.md just description what it is, and test just verify bindings as I see). I am not as good with Python as with Go, but would like to start experimenting (and if I can, contribute some more docs). \n\nThnx in advance!\n", "Hello,\nI've opened this PR today: https://github.com/tensorflow/tensorflow/pull/1771/\nIt includes most of the modifications commented here:\n- All the code is now contained into contrib/go\n- Improved test coverage\n- Added methods to create tensors, populate them, read the content, etc.\n- Graph generation, now it is possible to build the Graph from Go\n- Modified the \"Image Recognition\" tutorial to include a section similar to the C++ API section but using the Go API, also the code was ported to Go\n- Code updated to work with the 7.1 version\n- Code commented, GoLint doesn't complains\n\nThanks,\n", "@alonsovidales - got it, moving my attention over there.  thank you!\n", "Updated my goog CLA with my github username. Commenting to hopefully trigger the bot.\n", "Can one of the admins verify this patch?\n", "Closing this as @alonsovidales has continued building on this at #1771 \n"]}, {"number": 1236, "title": "Error while running fully_connected_feed.py of the tutorial \"TensorFlow Mechanics\"", "body": "Hello, \n\nwhile running fully_connected_feed.py i had this error. I was trying the TensorFlow Mechanics 101 Tutorial\n\nI attach the whole execution of the py file.\n\n$ python3 fully_connected_feed.py \nExtracting data/train-images-idx3-ubyte.gz\nExtracting data/train-labels-idx1-ubyte.gz\nExtracting data/t10k-images-idx3-ubyte.gz\nExtracting data/t10k-labels-idx1-ubyte.gz\nStep 0: loss = 2.32 (0.010 sec)\nStep 100: loss = 2.17 (0.005 sec)\nStep 200: loss = 1.96 (0.004 sec)\nStep 300: loss = 1.73 (0.004 sec)\nStep 400: loss = 1.46 (0.004 sec)\nStep 500: loss = 1.01 (0.005 sec)\nStep 600: loss = 0.85 (0.009 sec)\nStep 700: loss = 0.75 (0.004 sec)\nStep 800: loss = 0.78 (0.004 sec)\nStep 900: loss = 0.62 (0.004 sec)\nTraceback (most recent call last):\n  File \"fully_connected_feed.py\", line 228, in <module>\n    tf.app.run()\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/platform/default/_app.py\", line 30, in run\n    sys.exit(main(sys.argv))\n  File \"fully_connected_feed.py\", line 224, in main\n    run_training()\n  File \"fully_connected_feed.py\", line 199, in run_training\n    saver.save(sess, FLAGS.train_dir, global_step=step)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 970, in save\n    self.export_meta_graph(meta_graph_file_name)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 990, in export_meta_graph\n    as_text=as_text)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1315, in export_meta_graph\n    os.path.basename(filename), as_text=as_text)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/training/training_util.py\", line 70, in write_graph\n    gfile.MakeDirs(logdir)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/platform/default/_gfile.py\", line 295, in MakeDirs\n    os.makedirs(path, mode)\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/os.py\", line 241, in makedirs\n    mkdir(name, mode)\nFileNotFoundError: [Errno 2] No such file or directory: ''\n\nMy Operating System is OSX ElCapitan Upgrade. \nI installed tensorflow from pip package. \nThe same error happens for both python2.7 and python3.5\n\nThanks a lot in advance for your help.\n\nSilvio\n", "comments": ["This is fixed in 0.7.1, which we will release soon.\n", "We just released 0.7.1 -- let us know if it still happens there.\n"]}, {"number": 1235, "title": "No module 'sparse_softmax_cross_entropy_with_logits' in cifar10_train.py on master", "body": "For bugs/issues, please fill in the following.  The more information you\nprovide, the more likely we can help you.\n### Environment info\n\nOperating System: Ubuntu 15.10\n\nI have the following issue when running cifar10_train.py on master\n\n```\npython cifar10_train.py\nFilling queue with 20000 CIFAR images before starting to train. This will take a few minutes.\nTraceback (most recent call last):\n  File \"cifar10_train.py\", line 101, in <module>\n    tf.app.run()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/default/_app.py\", line 11, in run\n    sys.exit(main(sys.argv))\n  File \"cifar10_train.py\", line 98, in main\n    train()\n  File \"cifar10_train.py\", line 41, in train\n    loss = cifar10.loss(logits, labels)\n  File \"/home/kde/Code/tf/cifar10/cifar10.py\", line 244, in loss\n    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\nAttributeError: 'module' object has no attribute 'sparse_softmax_cross_entropy_with_logits'\n```\n", "comments": ["Are you using tf compiled from git? If so, how recent?\n", "@ebrevdo No, I installed TensorFlow via the following command\n\n```\n# Ubuntu/Linux 64-bit, CPU only:\n$ sudo pip install --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.7.1-cp27-none-linux_x86_64.whl\n```\n", "That version may not have the function. Try building the package from HEAD.\n", "Did that solve the problem?\n", "I had the same problem. I tried building Tensorflow from the latest source (cloned on March 23 2016). However, the build fails with the following error, so we are still stuck:\nERROR: /Users/ron/Documents/Software/Neural/tensorflow-git-repository/tensorflow/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@plottable//': Error cloning repository: Unexpected end of file from server caused by Unexpected end of file from server caused by Unexpected end of file from server and referenced by '//tensorflow/tensorboard/bower:bower'.\nERROR: Loading failed; build aborted.\n", "@danmane This looks like a tensorboard dependency, can you verify?\n", "Yes, that is a TensorBoard dependency. It looks like something went wrong in the connection to GitHub while Bazel was downloading plottable (unexpected end of file from server).\n\nCan you try re-building and see if it works? If it still doesn't work try `bazel clean` and try again?\n", "I rebuilt succesfully with Bazel. However, installation broke something:\n\n```\nImportError: No module named protobuf\nError importing tensorflow.  Unless you are using bazel, you should not try to import tensorflow from its source directory; please exit the tensorflow source tree, and relaunch your python interpreter\nfrom there.\n```\n\nOthers reported this also, see issue 498. Will keep at it.\n", "Closing since the original issue is fixed.\n"]}, {"number": 1234, "title": "Update documentation for softmax-with-cross-entropy loss functions", "body": "`softmax_cross_entropy_with_logits` and `sparse_softmax_cross_entropy_with_logits` both have useful  behavior that conflicts with current documentation.\n\nIn `softmax_cross_entropy_with_logits`: \"All that is required is that each row of `labels` is\na valid probability distribution.\" In `sparse_softmax_cross_entropy_with_logits`: \"labels: Each entry `labels[i]` must be an index in `[0, num_classes)`.\"\n\nNeither of these statements is true, and using all 0s in the case of `softmax_cross_entropy_with_logits` or -1s in the case of `sparse_softmax_cross_entropy_with_logits` is useful when signals include entries for which we don't want to compute loss.\n\n`softmax_cross_entropy_with_logits` example:\n\n```\nlogits_list = [tf.Variable([[0.0, 0.0, 0.0]]), tf.Variable([[99.0, 0.0, 0.0]])]\nlabels = tf.Variable([[0.0, 0.0, 0.0]])\nloss_list = [tf.nn.softmax_cross_entropy_with_logits(logits, labels)\n             for logits in logits_list]\n\nwith tf.Session() as sess:\n    sess.run(tf.initialize_all_variables())\n    print(sess.run(loss_list))\n\n# [array([ 0.], dtype=float32), array([ 0.], dtype=float32)]\n```\n\n`sparse_softmax_cross_entropy_with_logits` example:\n\n```\nlogits_list = [tf.Variable([[0.0, 0.0, 0.0]]), tf.Variable([[99.0, 0.0, 0.0]])]\nlabels = tf.cast(tf.Variable([-1]), tf.int64)\nloss_list = [tf.nn.sparse_softmax_cross_entropy_with_logits(logits, labels)\n             for logits in logits_list]\n\nwith tf.Session() as sess:\n    sess.run(tf.initialize_all_variables())\n    print(sess.run(loss_list))\n\n# [array([ 0.], dtype=float32), array([ 0.], dtype=float32)]\n```\n\nWe could filter invalid entries out before computing logits/loss, but in my use cases this would add a lot of boilerplate code and make only a negligible difference performance wise. (RNNs with long sequences, a fairly small number of time steps, multiple predictions per time step, and batch entries with varying `sequence_length`s. Using this trick lets us avoid having to break up logits/targets etc. into valid chunks vs. invalid chunks.\n\nEdit: I ended up applying a boolean mask anyway since I wanted to view the loss over time (not just take gradients and minimize). In any case I like the current behavior so that I can apply masks after I obtain loss values over all targets, both valid and invalid.\n", "comments": ["This seems like reasonable behavior to preserve, since we're unlikely to ever add any kind of checking to these ops (doing so is problematic due to numerical error) and we're unlikely to normalize due to speed.  Documentation contributions welcome!\n", "The described convenient behavior has changed somewhere between versions 0.9 and 0.10.\nThe snippet with `sparse_softmax_cross_entropy_with_logits` now results in:\n\n```\n[array([ nan], dtype=float32), array([ nan], dtype=float32)]\n```\n\nCross entropy for padding logits became `nan` instead of `0.0`. Looks like a breaking change: in my case forward pass is still okay (with masking), but gradients are now stuffed with `nan`s . It took some time to realize that new behavior is version dependent.\n\nVersions with \"0\" behavior:\n[linux/gpu/tensorflow-0.9.0-cp27-none-linux_x86_64.whl](https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.9.0-cp27-none-linux_x86_64.whl)\n\nVersions with \"nan\" behavior:\n[linux/gpu/tensorflow-0.10.0rc0-cp27-none-linux_x86_64.whl](https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.10.0rc0-cp27-none-linux_x86_64.whl)\n[linux/gpu/tensorflow-0.10.0-cp27-none-linux_x86_64.whl](https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.10.0-cp27-none-linux_x86_64.whl)\n\nShould we open a new issue or is this new behavior by design?\n", "Can you open a new bug for this, explaining what behavior you think is correct?\n", "I let ivan create the bug issue but I confirm that the new behavior can cause some troubles. I am using `sparse_softmax_cross_entropy_with_logits` and, in my opinion, the best behavior would be to return a loss of _0.0_ and null gradients when the label is not in the range _[0, num_classes)_; never return _nan_.\n", "This is only going to get more strict.  Passing labels that are out of range is a sign of a hidden bug; one that may have model builders searching for a long time before figuring out the true problem.  Starting in a few days, this op will raise exceptions when passed invalid labels on CPU.  On GPU it will continue to return NaNs because we can't easily pass error flags back from the GPU.\n"]}, {"number": 1233, "title": "python \"import tensorfow\" fail after source build", "body": "TF 0.7 built from source on Ubuntu 15.10, PIP package built and installed.  python import fails.\n\n```\nPython 2.7.10 (default, Oct 14 2015, 16:09:02) \n[GCC 5.2.1 20151010] on linux2\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>> import tensorflow\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py\", line 23, in <module>\n    from tensorflow.python import *\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py\", line 35, in <module>\n    from tensorflow.core.framework.graph_pb2 import *\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py\", line 16, in <module>\n    from tensorflow.core.framework import attr_value_pb2 as tensorflow_dot_core_dot_framework_dot_attr__value__pb2\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/attr_value_pb2.py\", line 16, in <module>\n    from tensorflow.core.framework import tensor_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__pb2\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/tensor_pb2.py\", line 16, in <module>\n    from tensorflow.core.framework import tensor_shape_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__shape__pb2\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/tensor_shape_pb2.py\", line 22, in <module>\n    serialized_pb=_b('\\n,tensorflow/core/framework/tensor_shape.proto\\x12\\ntensorflow\\\"z\\n\\x10TensorShapeProto\\x12-\\n\\x03\\x64im\\x18\\x02 \\x03(\\x0b\\x32 .tensorflow.TensorShapeProto.Dim\\x12\\x14\\n\\x0cunknown_rank\\x18\\x03 \\x01(\\x08\\x1a!\\n\\x03\\x44im\\x12\\x0c\\n\\x04size\\x18\\x01 \\x01(\\x03\\x12\\x0c\\n\\x04name\\x18\\x02 \\x01(\\tB/\\n\\x18org.tensorflow.frameworkB\\x11TensorShapeProtosP\\x01\\x62\\x06proto3')\nTypeError: __init__() got an unexpected keyword argument 'syntax'\n\n```\n", "comments": ["The root of this is a protobuf library version mismatch, you appear to be using an older version that 3.0. There's more information, and some possible solutions, in #11.\n", "Try updating to 0.7.1 (cleanly -- uninstall tensorflow, probably even protobuf, and then reinstall 0.7.1).  Let us know if you still have problems.\n", "Ok - well this worked but I thought it didn't - so maybe to avoid others being as slow-witted as I am:\n I uninstalled, removed the repo, cloned, bazel build, pip install, got the same error.  \nThe problem is I went root to bazel build and install.  If I invoke python from root tensorflow imports.  If I invoke python as a user - TF import fails.  \n"]}, {"number": 1232, "title": "Add list of community created projects", "body": "... and point to it from the README. This addresses #995, #1223. We'd like to link only to things in this repo from the README, but it's a good idea to add a place for projects using or enhancing TensorFlow.\n", "comments": ["Merged\n"]}, {"number": 1231, "title": "sampled softmax vs regular softmax", "body": "For the seq2seq example, sampled softmax is 2-3 times slower than regular softmax, is it because sampled softmax is on CPU while regular softmax is on GPU? Then why do we need sampled softmax, it saves gpu memory?\n\nBut the convergence speed of sampled softmax (in terms of iterations) is much faster then regular softmax? Any mathematical reasons?\n\nMany thanks!\n", "comments": ["This is a question best suited for stackoverflow. Please ask it there to get a good answer. Regular softmax isn't a good idea for very large vocabularies.\n", "bring this up since I find the loss calculated with sampled softmax is significant lower than regular softmax, this explains why the perplexity is low while the model is not reasonable here #550\n"]}, {"number": 1230, "title": "Imagenet example error", "body": "### Environment info\n\nOperating System: Windows with latest docker image (only cpu)\n\nafter running: python classify_image.py and loading the model I got the folling error:\n\n`Succesfully downloaded inception-2015-12-05.tgz 88931400 bytes.                                                                                                    [libprotobuf ERROR google/protobuf/src/google/protobuf/io/coded_stream.cc:207] A protocol message was rejected because it was too big (more than 67108864 bytes).  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.                             Traceback (most recent call last):                                                                                                                                   File \"classify_image.py\", line 213, in <module>                                                                                                                      tf.app.run()                                                                                                                                                     File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/default/_app.py\", line 30, in run                                                            sys.exit(main(sys.argv))                                                                                                                                         File \"classify_image.py\", line 209, in main                                                                                                                          run_inference_on_image(image)                                                                                                                                    File \"classify_image.py\", line 159, in run_inference_on_image                                                                                                        create_graph()                                                                                                                                                   File \"classify_image.py\", line 141, in create_graph                                                                                                                  graph_def.ParseFromString(f.read())                                                                                                                            google.protobuf.message.DecodeError: Error parsing message`   \n\nwhat can I do ?\n", "comments": ["This is likely the same issue as issue [582](https://github.com/tensorflow/tensorflow/issues/582).\n", "For a quick solution type the following before running tensorflow\n\n`export PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python`\n", "Were you using a precompiled version or building from source? \n\nI used to see the same problem. If you are building from source, updating to the latest code and doing a rebuild should solve the problem (it seems to be fixed in 2f756013f5bcc39ee288eed9da8d27cf4ec16f7e). \n", "@ritsu1228 I'm experiencing this with the official prebuilt 0.7.0 development docker image.\n", "@tmaila Seems like 0.7.0 was released before commit 2f756013f5bcc39ee288eed9da8d27cf4ec16f7e. So I think 0.7.0 should have this problem and your solution works perfect. If you upgrade to 0.7.1, you won't need to do `export`.\n", "yeah with the latest image I get no errors anymore. Sry for the late response.\nThanks for your help guys!\n"]}, {"number": 1229, "title": "Conditional logging for core platform flow", "body": "Conditional logging for core platform flow(skeletal), quick take as i find users needing this.This pull is based on using re2 flags and allowing severity check before the logging.Please let me know your thoughts.\n", "comments": ["Can one of the admins verify this patch?\n", "Thanks for this contribution @rekhajoshm, but we don't want to introduce command line flags to our library like this -- most options should be passed via ConfigProto or another proto.  We could maybe add a LogOptions structure to hold options related to logging.\n\nFeel free to file an issue asking for a way to control log message output and we'll try to get it done.\n", "ok thanks @vrv raised #1258 for library handling the log control.thanks\n"]}, {"number": 1228, "title": "sequence2sequence model padding ", "body": "In the seq2seq models, paddings are applied to make all sequences in a bucket have the same lengths. And apart from this, it looks like no special handling is applied to the paddings: \n- the encoder encodes the paddings as well\n- the basic decoder w/o attention decodes using the last encoding which encodes the paddings\n- the decoder with attention attends to the hidden states of the padding inputs too\n\nIt would be really helpful if this could be clarified: is it true that, basically the paddings are just a special id/embedding, and the current seq2seq implementation treats them just like other embeddings? And no special mechanism is needed to ignore these padding, for example when encoding a sequence containing paddings; or to decode a sequence containing paddings using the attention-based decoder? So after padding, nothing special is done to the paddings, we can just pretend a padding is just another embedding  (apart from maybe when doing the weighted x-entropy using target_weights)?\n\nIf the above is true, then when testing a trained model, is padding needed at all (since at test time, each sentence is decoded separately and not in a batch)? --- It looks like from the code, at test time an input sentence is still bucketed first and then padded?\n", "comments": ["This is a question better suited to StackOverflow, since it is not a bug / feature request.\n"]}, {"number": 1227, "title": "bazel build //tensorflow/examples/android:tensorflow_demo missing dependency declarations", "body": "For bugs/issues, please fill in the following.  The more information you\nprovide, the more likely we can help you.\n### Environment info\n\nOperating System: Mac OS X (10.10.5)\n\nIf installed from binary pip package, provide:\n1. Which pip package you installed.\n2. The output from python -c \"import tensorflow; print(tensorflow.**version**)\".\n\nIf installed from sources, provide the commit hash:  3b8f0df34b80f2b0019e24dd91e099e0e6874bd6\n### Steps to reproduce\n1. Build TensorFlow from source following [these instructions](https://gist.github.com/ageitgey/819a51afa4613649bd18) for building with CUDA support on Mac\n2. Tested TensorFlow installed correctly\n3. Attempted to build Android demo following [these instructions](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android)\n### What have you tried?\n1. Tried adding the missing dependencies into this [BUILD file](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/android/BUILD) between lines 14 and 15.  Added lines that looked like:\n   `\"tensorflow/core/platform/default/logging.h\", \"tensorflow/core/platform/macros.h\",`\n   - My thought was that maybe adding the asked for dependencies might do the trick.\n   - My thought when that didn't work was maybe I need to use the \"deps\" option instead of the \"srcs\" option, but since I have NO familiarity with Bazel that seems problematic. :-/\n### Logs or other output that would be helpful\n\n(If logs are large, please upload as attachment).\n`bazel build //tensorflow/examples/android:tensorflow_demo --verbose_failures\nINFO: Found 1 target...\nERROR: /Users/[USERNAME]/Documents/Dev/tensorflow/tensorflow/examples/android/BUILD:10:1: undeclared inclusion(s) in rule '//tensorflow/examples/android:libtensorflow_demo.so':\nthis rule is missing dependency declarations for the following files included by 'tensorflow/examples/android/jni/jni_utils.cc':\n  '/Users/[USERNAME]/Documents/Dev/tensorflow/tensorflow/core/platform/default/logging.h'\n  '/Users/[USERNAME]/Documents/Dev/tensorflow/tensorflow/core/platform/macros.h'.\nTarget //tensorflow/examples/android:tensorflow_demo failed to build\nINFO: Elapsed time: 2.053s, Critical Path: 1.93s\n`\n", "comments": ["Looks like the arrangement of some items in the header files in the core framework got moved around and the target for the android build didn't get updated.  Working on finding all of the wandering .h files now. :-/\n", "Actually, looking into this more it looks like the issue is the pull request I'm basing from doesn't have all of the Android bits built like the current master does. :-/\n"]}, {"number": 1226, "title": "MNIST example using TFRecordWriter context manager.", "body": "The `TFRecordWriter` wasn't being explicitly closed. Updated the example to use the context while writing the examples.\n\n**NOTE**: This code will throw an error on any install of TensorFlow before [this commit](https://github.com/tensorflow/tensorflow/commit/67b2abcd673f466d32c4017ad8bab0d0b9ac86c5). The exception will likely be `AttributeError: 'NoneType' object has no attribute 'write'`.\n\nWould it be better to call `TFRecordWriter#close()` explicitly on this example code since that would work with older version of TF as well?\n", "comments": ["Can one of the admins verify this patch?\n", "My recollection is that when I put logging statements into the C++, I observed that the file was being closed properly.  This may have been a result of the Python object being unreferenced, though, and I suspect this is a better approach.  However, given that [the commit you mention](https://github.com/tensorflow/tensorflow/commit/67b2abcd673f466d32c4017ad8bab0d0b9ac86c5) does not appear to have been included in 0.7, I am a little worried about causing trouble for people who get the example from master but installed 0.7 via PiP or something.\n", "Updated to explicitly close the writer in the example. (this should work on 0.7)\n\nI wouldn't doubt that the file is properly closed on the Python object being dereferenced. I'm afraid of people copying the pattern and leading to unintentional leaks.\n\nI'm OK with this being closed and not merged but I think it'd be good to highlight that `TFRecordWriter` should be closed.\n", "Can you update to master and ping this thread when ready?\n", "Actually looks like there's no conflict.\n\n@tensorflow-jenkins: test this please.\n", "Merged\n"]}, {"number": 1225, "title": "resize_image_with_crop_or_pad() for a batch of images", "body": "`resize_image_with_crop_or_pad()` should work for multiple images (batch of images) similar to `tf.image.resize_images()`\n", "comments": ["Duplicate of #521.\n"]}, {"number": 1224, "title": "dynamic_rnn gradients unable to be applied", "body": "Operating System: Ubuntu 14.04.3 LTS\nInstallation: 0.7.0 via pip\nOutput from `python -c \"import tensorflow; print(tensorflow.__version__)\"`: 0.7.0\n\nI realize `dynamic_rnn` isn't official yet, but I'm hoping to see whether I'm using it correctly / whether there's a bug.\n\nIf I use `rnn.rnn`, `optimizer.apply_gradients(grad_var_pairs)` works with no issues. If I use rnn.dynamic_rnn, with the only change being how inputs must be handled, I get an error: `ValueError: Shapes () and (276, 1024) must have the same rank`\n\nSo I looked at the gradients. All gradients have identical shapes/names except two.\n\nIn the `rnn.rnn` case, we have\n\n`<tf.Tensor 'gradients/AddN_596:0' shape=(?, ?) dtype=float32>\n<tf.Tensor 'gradients/AddN_595:0' shape=<unknown> dtype=float32>`\n\nWhereas in the `rnn.dynamic_rnn` case, we have\n\n`<tf.Tensor 'gradients/model/model/rnn_fw/RNN/While/cond/LSTMCell/MatMul/Enter_grad/b_acc_3:0' shape=() dtype=float32>\n<tf.Tensor 'gradients/model/model/rnn_fw/RNN/While/cond/LSTMCell/BiasAdd/Enter_grad/b_acc_3:0' shape=() dtype=float32>`\n\nDo I have to manipulate these in some way before applying them?\n", "comments": ["Looks like a bug.  Will take a look.\n", "Should be fixed in the next push.\n", "We pushed, but I don't know which commit fixed this.  Assuming it was fixed :)\n", "commit b1496f6.\n"]}, {"number": 1223, "title": "Added skflow link to README", "body": "", "comments": ["Can one of the admins verify this patch?\n", "I'm adding a section to the website in #1232, and pointing to it from the README. There's a number of them I still have to add, and I'd like to keep the README for resources contained inside the repo.\n", "Thanks!\n"]}, {"number": 1222, "title": "Check failed: params_->device->RequiresRecordingAccessedTensors() == record_tensor_accesses_ ", "body": "The code used to run ok on both CPU or  GPU mode, but I don't know what happend , now it will fail whether cpu or gpu version\npython -c \"import tensorflow; print(tensorflow.**version**)\"\n\nF /usr/local/lib/python2.7/dist-packages/tensorflow/include/tensorflow/core/framework/op_kernel.h:1087] Check failed: params_->device->RequiresRecordingAccessedTensors() == record_tensor_accesses_ \n", "comments": ["Jeff, it looks like this check was recently added. Can you add some background on why it might be triggered? Thanks!\n", "I find the problem associates with user defined op(I write one auc.cc -> auc.so), which used to work.\nIf remove auc op from running graph, then the script can run. \n", "Hi, now after rebuilding auc.so on centos platform, everything is fine, might due to mismatch of platform(auc.so was generated on another ubuntu platform before).\n@jeffreyadean Close this if not an issue.\n", "Thanks for the update! I'll close this.\n"]}, {"number": 1221, "title": "Edit train.exponential_decay sample code", "body": "", "comments": ["Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "I signed it!\n", "CLAs look good, thanks!\n\n<!-- ok -->\n", "Thanks, you'll also need to make the same modification to https://github.com/tensorflow/tensorflow/blob/f2bd0fc399606d14b55f3f7d732d013f32b33dd5/tensorflow/python/training/learning_rate_decay.py#L53 -- our MD files are generated from the original source documentation.\n", "Thanks, can you address any merge conflicts and squash the changes?  (Sorry, github doesn't notify me when you push changes without commenting on this thread).\n", "@vrv, commits are squashed and there are no merge conflicts.\n", "@tensorflow-jenkins: test this please\n", "Merged\n"]}, {"number": 1220, "title": "Add ability to specify which gcc to use", "body": "Some versions of gcc is incompatible with cuda (e.g. gcc 5.X.X and cuda 7.5). In such situation a compatible gcc version can be specified when running `./configure`.\n", "comments": ["Can one of the admins verify this patch?\n", "@tensorflow-jenkins: test this please\n", "I think this looks good, someone with more bash-fu want to double check before merging?\n", "Assigning to @girving since he is also touching ./configure :)\n", "Can you squash your commits?  We'll then test and merge\n", "Apologies for the delay, @vrv.  I can do the rest.\n", "The rest not including squashing, that is.\n", "Still waiting for the squash.\n", "Merged\n"]}, {"number": 1219, "title": "Fixed bug in example: s/len(num_steps)/num_steps/g", "body": "num_steps is a value (an integer), not a list, so it was a typo to take `len(num_steps)`.\n\nThis fixes that typo.\n", "comments": ["Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "I signed it!\n", "CLAs look good, thanks!\n\n<!-- ok -->\n", "Merged\n"]}, {"number": 1218, "title": "Add nightly binaries to README.md", "body": "Merging this should wait until our Mac nightlies successfully built at least once (otherwise we'll have dead links). \n", "comments": ["merged.\n"]}, {"number": 1217, "title": "upgrade pip links for 0.7.1", "body": "", "comments": ["@vrv can you merge this please?\n"]}, {"number": 1216, "title": "Android demo fails to build due to protobuf visibility error", "body": "When running the instructions to build the Android demo with the latest open-source repo, a protobuf visibility error causes the build to fail.\n\nSteps to reproduce:\n- On an Ubuntu system, git clone the repo following the install instructions.\n- Run `bazel build //tensorflow/examples/android:tensorflow_demo`.\n\nResults:\n\n```\nERROR: /usr/local/google/home/petewarden/projects/tensorflow/tensorflow/core/BUILD:77:1: Target '//google/protobuf:cc_wkt_protos' is not visible from target '//tensorflow/core:protos_all_cc'. Check the visibility declaration of the former target if you think the dependency is legitimate.\n```\n\nNotes:\nI think this might be a protobuf Bazel rule problem. I was able to fix it by patching google/protobuf/protobuf.bzl like so:\n\n```\n+++ b/protobuf.bzl\n@@ -132,6 +132,11 @@ def cc_proto_library(\n   if include != None:\n     includes = [include]\n\n+  if \"visibility\" in kargs:\n+    visibility = kargs[\"visibility\"]\n+  else:\n+    visibility = None\n+\n   if internal_bootstrap_hack:\n     # For pre-checked-in generated files, we add the internal_bootstrap_hack\n     # which will skip the codegen action.\n@@ -141,6 +146,7 @@ def cc_proto_library(\n         deps=[s + \"_genproto\" for s in deps],\n         includes=includes,\n         protoc=protoc,\n+        visibility=visibility,\n     )\n     # An empty cc_library to make rule dependency consistent.\n     native.cc_library(\n@@ -157,6 +163,7 @@ def cc_proto_library(\n       protoc=protoc,\n       gen_cc=1,\n       outs=outs,\n+      visibility=visibility,\n   )\n\n   if default_runtime and not default_runtime in cc_libs:\n```\n", "comments": ["@davidzchen, @damienmg \n", "https://github.com/google/protobuf/blob/master/protobuf.bzl hasn't changed in a month -- did a change in bazel cause this?\n", "there is no change in Bazel that could explain the situation. Is it reproducible? Which version of bazel fails?\n", "Also the applied patch is not agains protobuf.bzl master: see https://github.com/google/protobuf/blob/master/protobuf.bzl#L141\n", "Thanks - from inspection it looks like it's been fixed in a newer protobuf than we're pinned to in TensorFlow. I'll talk to Vijay about how we upgrade the submodule reference.\n", "Our submodule is pinned to https://github.com/google/protobuf/tree/c40f8c1f54f028b1ca73f3fb2dfdde500f94918f from 3 days ago, so I suspect it's something with your local config .\n", "For posterity I've confirmed that this does work at head when I do a clean git clone. It turns out the problem was due to doing a 'git pull origin master' from the main tensorflow directory that was synced to an older build. The protobuf submodule didn't update, hence the compilation problems.\n\nFrom searching, it seems like I should be using more than just a `git pull` to update the submodules:\nhttp://stackoverflow.com/questions/1030169/easy-way-pull-latest-of-all-submodules\n", "FYI, the complexity around updating the protobuf submodule will go away once we switch to using a Bazel external repository rather than a submodule for the protobuf dependency. #1069 is the tracking bug for that change.\n", "I'm extremely excited about #1069.\n"]}, {"number": 1215, "title": "Retraining Example with Notebook", "body": "The code from the retraining demo morphed into a IPython Notebook to make it easier to use interactively.\n", "comments": ["Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "I signed it!\n", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for the commit author(s).  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\n\n<!-- need_author_cla -->\n", "CLA check still fails :(  Closing for now but comment here and fix the CLA issue and we can take a look.\n"]}, {"number": 1214, "title": "Unable to build from source with Bazel 1.4", "body": "I'm running linux x86_64, OpenSuse 13.1\n\nI am trying to compile from the repo master branch 875a67f with Bazel 1.4, installed from `bazel-0.1.4-installer-linux-x86_64.sh`\n\nI was getting dependency errors and had to make the modifications described in [this stack overflow post](http://stackoverflow.com/questions/35256110/tensorflow-build-fails-with-missing-dependency-error) to my Bazel setup\n\nThis got me past my initial dependency errors (described exactly in detail by StackOverflow OP in above post), but now I've got another error when trying to run this command:\n\n`bazel build --verbose_failures -c opt //tensorflow/tools/pip_package:build_pip_package\n`\n\nThe relevant output:\n\n```\nINFO: From Compiling tensorflow/python/lib/core/py_func.cc:\ntensorflow/python/lib/core/py_func.cc:19:31: fatal error: numpy/arrayobject.h: No such file or directory\n #include \"numpy/arrayobject.h\"\n                               ^\ncompilation terminated.\nERROR: /home/personal/files/learning/tensorflow/tensorflow/tensorflow/python/BUILD:75:1: C++ compilation of rule '//tensorflow/python:py_func_lib' failed: gcc failed: error executing command\n  (cd /root/.cache/bazel/_bazel_root/f202f08f55600b1b30922b1248222df1/tensorflow && \\\n  exec env - \\\n    PATH=/usr/lib64/mpi/gcc/openmpi/bin:/sbin:/usr/sbin:/usr/local/sbin:/root/bin:/usr/local/bin:/usr/bin:/bin:/usr/bin/X11:/usr/X11R6/bin:/usr/games:/opt/cross/bin:/usr/local/go/bin \\\n  /usr/bin/gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections '-std=c++0x' -iquote . -iquote bazel-out/local_linux-opt/genfiles -iquote external/bazel_tools -iquote bazel-out/local_linux-opt/genfiles/external/bazel_tools -iquote external/jpeg_archive -iquote bazel-out/local_linux-opt/genfiles/external/jpeg_archive -iquote external/png_archive -iquote bazel-out/local_linux-opt/genfiles/external/png_archive -iquote external/re2 -iquote bazel-out/local_linux-opt/genfiles/external/re2 -iquote external/eigen_archive -iquote bazel-out/local_linux-opt/genfiles/external/eigen_archive -isystem google/protobuf/src -isystem bazel-out/local_linux-opt/genfiles/google/protobuf/src -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/jpeg_archive/jpeg-9a -isystem bazel-out/local_linux-opt/genfiles/external/jpeg_archive/jpeg-9a -isystem external/png_archive/libpng-1.2.53 -isystem bazel-out/local_linux-opt/genfiles/external/png_archive/libpng-1.2.53 -isystem external/re2 -isystem bazel-out/local_linux-opt/genfiles/external/re2 -isystem third_party/eigen3 -isystem bazel-out/local_linux-opt/genfiles/third_party/eigen3 -isystem external/eigen_archive/eigen-eigen-70505a059011 -isystem bazel-out/local_linux-opt/genfiles/external/eigen_archive/eigen-eigen-70505a059011 -isystem third_party/py/numpy/numpy_include -isystem bazel-out/local_linux-opt/genfiles/third_party/py/numpy/numpy_include -isystem util/python/python_include -isystem bazel-out/local_linux-opt/genfiles/util/python/python_include -no-canonical-prefixes -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' '-frandom-seed=bazel-out/local_linux-opt/bin/tensorflow/python/_objs/py_func_lib/tensorflow/python/lib/core/py_func.pic.o' -MD -MF bazel-out/local_linux-opt/bin/tensorflow/python/_objs/py_func_lib/tensorflow/python/lib/core/py_func.pic.d -fPIC -c tensorflow/python/lib/core/py_func.cc -o bazel-out/local_linux-opt/bin/tensorflow/python/_objs/py_func_lib/tensorflow/python/lib/core/py_func.pic.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1: gcc failed: error executing command\n  (cd /root/.cache/bazel/_bazel_root/f202f08f55600b1b30922b1248222df1/tensorflow && \\\n  exec env - \\\n```\n\nCan anyone offer assistance with building?\n", "comments": ["Hmm I thought maybe updating numpy would fix this given that last error, and it did.\n\nLooks like there is a version requirement on numpy.\n\nI tried to compile again and now I'm not so sure what is still wrong:\n\n```\nINFO: From Compiling tensorflow/core/kernels/matrix_solve_ls_op.cc:\ntensorflow/core/kernels/matrix_solve_ls_op.cc: In member function 'void tensorflow::MatrixSolveLsOp<Scalar, SupportsBatchOperationT>::ComputeMatrix(tensorflow::OpKernelContext*, const typename tensorflow::BinaryLinearAlgebraOp<Scalar, SupportsBatchOperationT>::ConstMatrixMap&, const typename tensorflow::BinaryLinearAlgebraOp<Scalar, SupportsBatchOperationT>::ConstMatrixMap&, typename tensorflow::BinaryLinearAlgebraOp<Scalar, SupportsBatchOperationT>::MatrixMap*)':\ntensorflow/core/kernels/matrix_solve_ls_op.cc:111:41: error: 'Matrix' is not a class, namespace, or enumeration\n               (Scalar(l2_regularizer) * Matrix::Ones(cols, 1)).asDiagonal();\n                                         ^\ntensorflow/core/kernels/matrix_solve_ls_op.cc:131:41: error: 'Matrix' is not a class, namespace, or enumeration\n               (Scalar(l2_regularizer) * Matrix::Ones(rows, 1)).asDiagonal();\n                                         ^\nIn file included from ./tensorflow/core/framework/op_kernel.h:22:0,\n                 from tensorflow/core/kernels/matrix_solve_ls_op.cc:23:\n./tensorflow/core/framework/allocator.h: In member function 'virtual std::size_t tensorflow::Allocator::RequestedSize(void*)':\n./tensorflow/core/framework/allocator.h:146:3: warning: control reaches end of non-void function [-Wreturn-type]\n   }\n   ^\nIn file included from ./tensorflow/core/framework/op_kernel.h:25:0,\n                 from tensorflow/core/kernels/matrix_solve_ls_op.cc:23:\n./tensorflow/core/framework/device_base.h: In member function 'virtual tensorflow::Allocator* tensorflow::DeviceBase::GetAllocator(tensorflow::AllocatorAttributes)':\n./tensorflow/core/framework/device_base.h:149:3: warning: control reaches end of non-void function [-Wreturn-type]\n   }\n   ^\n./tensorflow/core/framework/device_base.h: In member function 'virtual const tensorflow::DeviceAttributes& tensorflow::DeviceBase::attributes() const':\n./tensorflow/core/framework/device_base.h:179:3: warning: control reaches end of non-void function [-Wreturn-type]\n   }\n   ^\nERROR: /home/personal/files/learning/tensorflow/tensorflow/tensorflow/core/BUILD:359:1: C++ compilation of rule '//tensorflow/core:kernel_lib' failed: gcc failed: error executing command\n  (cd /root/.cache/bazel/_bazel_root/f202f08f55600b1b30922b1248222df1/tensorflow && \\\n  exec env - \\\n    PATH=/usr/lib64/mpi/gcc/openmpi/bin:/sbin:/usr/sbin:/usr/local/sbin:/root/bin:/usr/local/bin:/usr/bin:/bin:/usr/bin/X11:/usr/X11R6/bin:/usr/games:/opt/cross/bin:/usr/local/go/bin \\\n  /usr/bin/gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections '-std=c++0x' -iquote . -iquote bazel-out/local_linux-opt/genfiles -iquote external/bazel_tools -iquote bazel-out/local_linux-opt/genfiles/external/bazel_tools -iquote external/jpeg_archive -iquote bazel-out/local_linux-opt/genfiles/external/jpeg_archive -iquote external/png_archive -iquote bazel-out/local_linux-opt/genfiles/external/png_archive -iquote external/re2 -iquote bazel-out/local_linux-opt/genfiles/external/re2 -iquote external/eigen_archive -iquote bazel-out/local_linux-opt/genfiles/external/eigen_archive -isystem google/protobuf/src -isystem bazel-out/local_linux-opt/genfiles/google/protobuf/src -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/jpeg_archive/jpeg-9a -isystem bazel-out/local_linux-opt/genfiles/external/jpeg_archive/jpeg-9a -isystem external/png_archive/libpng-1.2.53 -isystem bazel-out/local_linux-opt/genfiles/external/png_archive/libpng-1.2.53 -isystem external/re2 -isystem bazel-out/local_linux-opt/genfiles/external/re2 -isystem third_party/eigen3 -isystem bazel-out/local_linux-opt/genfiles/third_party/eigen3 -isystem external/eigen_archive/eigen-eigen-70505a059011 -isystem bazel-out/local_linux-opt/genfiles/external/eigen_archive/eigen-eigen-70505a059011 -isystem third_party/gpus/cuda -isystem bazel-out/local_linux-opt/genfiles/third_party/gpus/cuda -isystem third_party/gpus/cuda/include -isystem bazel-out/local_linux-opt/genfiles/third_party/gpus/cuda/include -fno-exceptions -DEIGEN_AVOID_STL_ARRAY -pthread -no-canonical-prefixes -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' '-frandom-seed=bazel-out/local_linux-opt/bin/tensorflow/core/_objs/kernel_lib/tensorflow/core/kernels/matrix_solve_ls_op.pic.o' -MD -MF bazel-out/local_linux-opt/bin/tensorflow/core/_objs/kernel_lib/tensorflow/core/kernels/matrix_solve_ls_op.pic.d -fPIC -c tensorflow/core/kernels/matrix_solve_ls_op.cc -o bazel-out/local_linux-opt/bin/tensorflow/core/_objs/kernel_lib/tensorflow/core/kernels/matrix_solve_ls_op.pic.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1: gcc failed: error executing command\n```\n", "additional info: \n\n```\n gcc --version\ngcc (SUSE Linux) 4.8.1 20130909 [gcc-4_8-branch revision 202388]\nCopyright (C) 2013 Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.  There is NO\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n```\n", "I tried the advice in #349 as it seemed to be a similar issue, but still have the same problem.\n", "I tried to isolate the failing compile command and it the error is clearer:\n\n```\ntensorflow/core/kernels/matrix_solve_ls_op.cc:111:41: error: 'Matrix' is not a class, namespace, or enumeration\n               (Scalar(l2_regularizer) * Matrix::Ones(cols, 1)).asDiagonal();\n```\n\nI'm not sure why that is happening...\n\nI see on line 66 of [matrix_solve_ls_op.cc](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/matrix_solve_ls_op.cc):\n\n```\n  using typename BinaryLinearAlgebraOp<Scalar, SupportsBatchOperationT>::Matrix;\n```\n\nThen for some reason using that `typename` fails on line 111:\n\n```\n gramian +=\n              (Scalar(l2_regularizer) * Matrix::Ones(cols, 1)).asDiagonal();\n```\n\nIt seems to be related to the fact that `MatrixSolveLsOp` is `using typename` on a template class member that is declared with `using`...\n\nAs far as I can tell, this should all be OK C++11. (related [discussion of this style on stackoverflow](http://stackoverflow.com/questions/23847774/are-using-typename-directives-not-implemented-by-compilers))\n\nI found 2 closely related bugs in gcc:\n-  [Older bug with recent comments](https://gcc.gnu.org/bugzilla/show_bug.cgi?id=14258)\n-  [Comments point to this one in gcc 4.8](https://gcc.gnu.org/bugzilla/show_bug.cgi?id=58047)\n\nThis could be it... I suspect gcc 4.8.1 is not supported. I have to break for now but will try to update GCC and report back..\n", "It was gcc version -- a duplicate has appeared: #1362\n"]}, {"number": 1213, "title": "Revert \"Fix tensorboard import path\"", "body": "This reverts commit 4b3069401fde5ba8a6a01d1aab95cc31e2169626.\n\nThis cherry-pick was not necessary -- the change to tensorboard\npaths was done after 0.7.0.\n", "comments": []}, {"number": 1212, "title": "Using ln -sf in python_config.sh", "body": "", "comments": ["Can one of the admins verify this patch?\n", "Merged\n"]}, {"number": 1211, "title": "Removing --upgrade and numpy-1.8.2 from pip.sh", "body": "Consolidating the two steps into one.\n", "comments": ["Can one of the admins verify this patch?\n"]}]