[{"number": 36937, "title": "Tensorflow 2.1.0 2.1.0-rc0 2.1.0-rc2 causes SIGSEGV when is used with textgenrnn", "body": "Hi All,\r\n\r\nI have a problem when I build TensorFlow 2.1.0 2.1.0-rc0 2.1.0-rc2 from sources on CentOS 7\r\nbuild is successfully compiled without any problems but when trying to learn from a text file with textgenrnn package\r\nit causes SIGSEGV error, you can see the log from gdb same on mentioned versions\r\n\r\n```\r\nMissing separate debuginfos, use: debuginfo-install python3-3.6.8-10.el7.x86_64\r\n(gdb) run ./train-sources.py -k p\u016fj\u010dky-limited\r\nStarting program: /usr/bin/python3 ./train-sources.py -k p\u016fj\u010dky-limited\r\n[Thread debugging using libthread_db enabled]\r\nUsing host libthread_db library \"/lib64/libthread_db.so.1\".\r\n[New Thread 0x7fffecf3f700 (LWP 27545)]\r\n[New Thread 0x7fffec73e700 (LWP 27546)]\r\n[New Thread 0x7fffe9f3d700 (LWP 27547)]\r\nwarning: File \"/usr/lib64/libstdc++.so.6.0.27-gdb.py\" auto-loading has been declined by your `auto-load safe-path' set to \"$debugdir:$datadir/auto-load:/usr/bin/mono-gdb.py\".\r\nTo enable execution of this file add\r\n        add-auto-load-safe-path /usr/lib64/libstdc++.so.6.0.27-gdb.py\r\nline to your configuration file \"/home/jpuchky/.gdbinit\".\r\nTo completely disable this security protection add\r\n        set auto-load safe-path /\r\nline to your configuration file \"/home/jpuchky/.gdbinit\".\r\nFor more information about this security protection see the\r\n\"Auto-loading safe path\" section in the GDB manual.  E.g., run from the shell:\r\n        info \"(gdb)Auto-loading safe path\"\r\n[Thread 0x7fffec73e700 (LWP 27546) exited]\r\n[Thread 0x7fffe9f3d700 (LWP 27547) exited]\r\n[Thread 0x7fffecf3f700 (LWP 27545) exited]\r\nDetaching after fork from child process 27777.\r\nDetaching after fork from child process 27779.\r\n[New Thread 0x7fffe9f3d700 (LWP 27893)]\r\n[New Thread 0x7fffec73e700 (LWP 27894)]\r\n[New Thread 0x7fffecf3f700 (LWP 27895)]\r\n[New Thread 0x7fffb95aa700 (LWP 27896)]\r\n[New Thread 0x7fffb8da9700 (LWP 27897)]\r\n[New Thread 0x7fffa3fff700 (LWP 27898)]\r\n[New Thread 0x7fffa37fe700 (LWP 27899)]\r\n[New Thread 0x7fffa2ffd700 (LWP 27900)]\r\n2020-02-20 19:06:27.583250: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2594220000 Hz\r\n[Thread 0x7fffa37fe700 (LWP 27899) exited]\r\n[New Thread 0x7fffa37fe700 (LWP 27901)]\r\n[New Thread 0x7fffa27fc700 (LWP 27902)]\r\n[New Thread 0x7fffa1ffb700 (LWP 27903)]\r\n[New Thread 0x7fffa17fa700 (LWP 27904)]\r\n2020-02-20 19:06:27.588578: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x34fe630 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-02-20 19:06:27.588620: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n[New Thread 0x7fffa0ff9700 (LWP 27905)]\r\n[New Thread 0x7fff83fff700 (LWP 27906)]\r\n[New Thread 0x7fff837fe700 (LWP 27907)]\r\n[New Thread 0x7fff82ffd700 (LWP 27908)]\r\n[New Thread 0x7fff827fc700 (LWP 27909)]\r\n\r\nProgram received signal SIGSEGV, Segmentation fault.\r\n---Type <return> to continue, or q <return> to quit---\r\n[Switching to Thread 0x7fffb8da9700 (LWP 27897)]\r\n0x00007fffd8967b20 in Eigen::internal::TensorBlockIOV2<unsigned int, long, 2, 1>::Copy(Eigen::internal::TensorBlockIOV2<unsigned int, long, 2, 1>::Dst const&, Eigen::internal::TensorBlockIOV2<unsigned int, long, 2, 1>::Src const&, Eigen::DSizes<int, 2> const&) ()\r\n   from /usr/local/lib64/python3.6/site-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so\r\n(gdb) \r\n```", "comments": ["@sjurajpuchky,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here. Thanks!", "@amahendrakar \r\n```python\r\n#!/usr/bin/python3\r\n\r\nfrom textgenrnn import textgenrnn\r\nimport sys\r\nimport getopt\r\nimport os\r\n\r\n\r\ndef usage():\r\n    print('train-sources.py -k <keyword>')\r\n\r\n\r\ndef main(argv):\r\n    keyword = ''\r\n    epochs = 10\r\n    try:\r\n        opts, args = getopt.getopt(argv, \"hk:e:\", [\"keyword=\", \"epochs=\"])\r\n    except getopt.GetoptError:\r\n        usage()\r\n        sys.exit(2)\r\n    for opt, arg in opts:\r\n        if opt == '-h':\r\n            usage()\r\n            sys.exit()\r\n        elif opt in (\"-k\", \"--keyword\"):\r\n            keyword = arg\r\n        elif opt in (\"-e\", \"--epochs\"):\r\n            epochs = arg\r\n\r\n    srcfile = os.path.dirname(os.path.realpath(__file__)) + '/sources/' + keyword + '.txt'\r\n    wfile = os.path.dirname(os.path.realpath(__file__)) + '/weights/' + keyword + '.hdf5'\r\n    textgen = textgenrnn(weights_path=wfile)\r\n    textgen.train_from_file(srcfile, new_model=True, num_epochs=int(epochs))\r\n    textgen.save()\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    main(sys.argv[1:])\r\n```\r\n\r\n`srcfile` is plain text file\r\n\r\n", "```\r\nabsl-py (0.9.0)\r\nastor (0.8.1)\r\ncached-property (1.5.1)\r\ncachetools (4.0.0)\r\ncertifi (2019.11.28)\r\nchardet (3.0.4)\r\ncycler (0.10.0)\r\ndocker (2.6.1)\r\ndocker-pycreds (0.2.1)\r\ndockerpty (0.4.1)\r\ndocopt (0.6.2)\r\nfuture (0.18.2)\r\ngast (0.2.2)\r\ngoogle-auth (1.11.2)\r\ngoogle-auth-oauthlib (0.4.1)\r\ngoogle-pasta (0.1.8)\r\ngrpcio (1.27.2)\r\nh5py (2.10.0)\r\nidna (2.9)\r\njoblib (0.14.1)\r\njsonschema (2.5.1)\r\nKeras-Applications (1.0.8)\r\nKeras-Preprocessing (1.1.0)\r\nkiwisolver (1.1.0)\r\nMarkdown (3.2.1)\r\nmatplotlib (3.1.3)\r\nmock (4.0.1)\r\nnumpy (1.18.1)\r\noauthlib (3.1.0)\r\nopt-einsum (3.1.0)\r\npip (9.0.3)\r\nprotobuf (3.11.3)\r\npyasn1 (0.4.8)\r\npyasn1-modules (0.2.8)\r\npyparsing (2.4.6)\r\npypi-install (0.0.5)\r\nPySocks (1.6.8)\r\npython-dateutil (2.8.1)\r\nPyYAML (3.11)\r\nrequests (2.23.0)\r\nrequests-oauthlib (1.3.0)\r\nrsa (4.0)\r\nscikit-learn (0.22.1)\r\nscipy (1.4.1)\r\nsetuptools (45.2.0)\r\nsix (1.14.0)\r\ntensorboard (2.0.2)\r\ntensorflow (2.1.0rc0)\r\ntensorflow-estimator (2.0.1)\r\ntermcolor (1.1.0)\r\ntextgenrnn (2.0.0)\r\ntexttable (1.4.0)\r\ntqdm (4.42.1)\r\nurllib3 (1.25.8)\r\nwebsocket-client (0.47.0)\r\nWerkzeug (1.0.0)\r\nwheel (0.34.2)\r\nwrapt (1.12.0)\r\nyoutube-dl (2019.9.28)\r\n```\r\n\r\nThanks a lot", "System\r\n`Linux localhost.localdomain 3.10.0-957.21.3.el7.x86_64 #1 SMP Tue Jun 18 16:35:19 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux`\r\nCentOS 7", "@sjurajpuchky,\r\nI was unable to reproduce the issue due to the missing .hdf5 file. You can take a look at the gist [here](https://colab.sandbox.google.com/gist/amahendrakar/0fe49e16e5bbd1de283b7cd98cb9cf3c/36937.ipynb). Could you please provide all the supporting files needed to run your code.\r\n\r\nAlso, please add ``` before and after your code to preserve the indentation of the code. Thanks!", "You have to install which contains all required files\r\nI do not have hdf5 file I train network from text file\r\nalso have to mention that my version of tensorflow is 2.1.0-rc2 builded from source on centos 7.1\r\nwhat i suggest is common problem \r\n\r\nsee attached WHL file which is my build\r\n\r\n[WHL](https://www.baba.bj/tensorflow-2.1.0rc2-cp36-cp36m-linux_x86_64.whl)\r\n\r\n```\r\nfrom textgenrnn import textgenrnn\r\nimport sys\r\nimport getopt\r\nimport os\r\n\r\n\r\ndef usage():\r\n    print('train-sources.py -k <keyword>')\r\n\r\n\r\ndef main(argv):\r\n    keyword = ''\r\n    epochs = 10\r\n    try:\r\n        opts, args = getopt.getopt(argv, \"hk:e:\", [\"keyword=\", \"epochs=\"])\r\n    except getopt.GetoptError:\r\n        usage()\r\n        sys.exit(2)\r\n    for opt, arg in opts:\r\n        if opt == '-h':\r\n            usage()\r\n            sys.exit()\r\n        elif opt in (\"-k\", \"--keyword\"):\r\n            keyword = arg\r\n        elif opt in (\"-e\", \"--epochs\"):\r\n            epochs = arg\r\n\r\n    srcfile = os.path.dirname(os.path.realpath(__file__)) + '/sources/' + keyword + '.txt'\r\n    wfile = os.path.dirname(os.path.realpath(__file__)) + '/weights/' + keyword + '.hdf5'\r\n    textgen = textgenrnn(weights_path=wfile)\r\n    textgen.train_from_file(srcfile, new_model=True, num_epochs=int(epochs))\r\n    textgen.save()\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    main(sys.argv[1:])\r\n```\r\n\r\n```\r\nName: textgenrnn\r\nVersion: 2.0.0\r\nSummary: Easily train your own text-generating neural network of any size and complexity\r\nHome-page: https://github.com/minimaxir/textgenrnn\r\nAuthor: Max Woolf\r\nAuthor-email: max@minimaxir.com\r\nLicense: MIT\r\nLocation: /usr/local/lib/python3.6/site-packages/textgenrnn-2.0.0-py3.6.egg\r\nRequires: h5py, scikit-learn, tqdm, tensorflow\r\nMetadata-Version: 2.1\r\nInstaller: \r\nClassifiers:\r\nEntry-points:\r\n```\r\n\r\n", "@sjurajpuchky Please add ` ``` ` before and after your code blocks. Otherwise, the things you post are unreadable and if you don't invest some time into the issue to make it easier to understand other contributors will just move over the issue and look at other ones.", "@mihaimaruseac I have fixed it but it's not working properly", "It's 3 backticks, not two", "Can you check if the two packages (TF and textgenrnn) are built using the same toolchains?", "@sjurajpuchky,\r\nI was able to run the above code without any issues using TF-nightly. Please find the output attached to this message.\r\n![36937 output](https://user-images.githubusercontent.com/57165142/76084435-e56cb180-5fd5-11ea-8817-b515f7b4fb88.png)\r\n\r\n\r\nI had used the sample `hacker_news.hdf5` and `hacker_news_2000.txt` files given in the [documentation](https://github.com/minimaxir/textgenrnn) of textgenrnn as the input. Thanks!\r\n\r\n[36937 full_output.txt](https://github.com/tensorflow/tensorflow/files/4298364/36937.full_output.txt)\r\n", "Thanks a lot i will try tommorow", "Its working with version r2.2 build on CentOS 7 Python 3.6\r\nThanks a lot", "Happy to help @sjurajpuchky. Closing this issue as resolved."]}, {"number": 36936, "title": "Does passing 'training' flag to tf.keras.Sequential do anything?", "body": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/tutorials/customization/custom_training_walkthrough#define_the_loss_and_gradient_function\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/Sequential\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/Model\r\n## Description of issue (what needs changing):\r\nIt is unclear whether the Sequential class makes use a 'training' flag fed into it during training/inference, as the tutorial above implies. \r\n\r\n### Clear description\r\nWhen building a custom model subclassing from tf.keras.Model, the standard signature for writing the `call` is as follows: `def call(self, inputs, training=None, mask=None):`\r\n\r\nIf my class includes submodels of the form Sequential, I am able to pass this flag forward but I'm unaware whether it's doing anything, as documentation from the class doesn't mention this flag.\r\nLooking at the customization tutorial above, however, the flag is passed into a Sequential model that does not include layers whose behavior change during training/inference. So I don't know if that flag is doing anything.\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n\r\n### Usage example\r\n\r\nIs there a usage example?\r\n\r\nSee the API guide: https://www.tensorflow.org/community/contribute/docs_ref\r\non how to write testable usage examples.\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs,\r\ndocs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n", "comments": ["> If my class includes submodels of the form Sequential, I am able to pass this flag forward but I'm unaware whether it's doing anything\r\n\r\nAny `training` boolean flag passed to a `Sequential` model will be passed to each and every of its layers, which will trigger training-only behaviours _if any is implemented_. Typically, one will have dropout applied conditionally on this flag, in which case passing it will indeed have an effect.\r\nNote that using the default keras training loop (_i.e._ the `fit` method) will automatically pass this flag along (while it will be set to False in `evaluate` and `predict`).", "Thank you for your answer. Can you please point me towards a source code file where I can see this behavior? Perhaps the docs should include this information as well since it's not very clear in my opinion.", "You can see in the definition of `tf.keras.Sequential.call` [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/engine/sequential.py#L269) that it expects a `training` flag, and that it will indeed be passed to any sublayer whose `call` signature includes that keyword.\r\n\r\nAs for the use of `training` itself, you can notably read about it [here](https://www.tensorflow.org/guide/keras/custom_layers_and_models#privileged_training_argument_in_the_call_method) in the Keras guide :)", "@milongo, Does the @pandrey-fr's comment help in resolving your issue?", "@gadagashwini , @pandrey-fr's comments do answer my questions, but I still feel the documentation for `tf.keras.Sequential` should include the `training` flag somewhere in the arguments i.e. \r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/Sequential#arguments_21 and make it explicit that the flag is passed to subsequent layers and made use of *if* those layers have it defined in their behavior, whether they're custom or not. ", "@milongo To be clear, the flag is passed _by default_ as part of `tf.keras.Model.fit`, `tf.keras.Model.evaluate` and `tf.keras.Model.predict`. The fact that a model's call may accept a `training` argument is documented [here](https://www.tensorflow.org/api_docs/python/tf/keras/Model) :\r\n> If you subclass Model, you can optionally have a training argument (boolean) in call, which you can use to specify a different behavior in training and inference:\r\n\r\nThe fact that `Layer` instances may accept it (and will receive it if so) is part of their API, as indicated [here](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer#__call__).\r\n\r\nThat being said, it may be worth to augment the existing documentation of `Sequential` as you suggest it.", "@pandrey-fr what is the behavior if the model is called in a custom training loop? Such as the following:\r\n\r\n```\r\n    for epoch in range(epochs):\r\n        for step, (x_batch, y_batch) in enumerate(train_dataset):\r\n\r\n            if epoch > mlp.warm_up:\r\n                for layer in mlp.mean.layers:\r\n                    layer.trainable = False\r\n                for layer in mlp.variance.layers:\r\n                    layer.trainable = True\r\n            with tf.GradientTape() as tape:\r\n                output = mlp(x_batch)\r\n                loss = loss_fn(y_batch, output)\r\n            grads = tape.gradient(loss, mlp.trainable_weights)\r\n            optimizer.apply_gradients(zip(grads, mlp.trainable_weights))\r\n            mean_preds, _ = output\r\n```\r\n\r\nHere, `mlp` is a custom class subclassed from `tf.keras.Model`, whose's `call` function is as follows:\r\n\r\n```\r\n    def call(self, inputs, training=None, mask=None):\r\n\r\n        mean_predictions = []\r\n        variance_predictions = []\r\n        for idx in range(self.num_models):\r\n            mean_predictions.append(self.mean[idx](inputs))\r\n            variance_predictions.append(self.variance[idx](inputs))\r\n        mean_stack = tf.stack(mean_predictions)\r\n        variance_stack = tf.stack(variance_predictions)\r\n\r\n        return mean_stack, variance_stack\r\n```\r\nYou can see that I do not bother to pass the `training` flag anywhere.\r\n\r\n(For clarity, `mlp` has two sets of ensembles, one in `self.mean` and another in `self.variance`, where each ensemble is defined as a list of `tf.keras.Sequential` modules):\r\n```\r\nself.mean = [\r\n            tf.keras.Sequential([\r\n                layers.Dense(512, activation='relu', input_shape=(self.input_dim,)),\r\n                layers.Dropout(0.5),\r\n                layers.Dense(256, activation='relu'),\r\n                layers.Dropout(0.5),\r\n                layers.Dense(self.output_dim)\r\n            ])\r\n            for _ in range(self.num_models)\r\n        ]\r\n```\r\nInterestingly enough, my models train just fine, so I'm guessing the default internal value for the flag is `training=True`, even if the headers have it as `training=None`. I.e. somewhere, that flag's value is actually set to `True`. ", "As far as I know, if you do not pass `training=True` explicitly, your model should run without dropout. This may not be prejudicial to training, but if you meant to make use of it it would probably be worth it to pass the flag within your custom training loop.", "Ahh I think you are correct. Passing the flag explicitly drastically affected training. \r\nThank you! \r\nI could close this now, but what about the documentation issues I mentioned? ", "You are welcome; I am glad this was helpful. Regarding documentation, perhaps @gadagashwini could assign the arbitration to a tensorflower; otherwise, maybe you could submit a PR to the tensorflow-docs repository?", "@milongo Are you planning to create any PR to update the docs? Thanks!", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 36935, "title": "DepthwiseConv1D: implementation, check and warning message", "body": "**System information** \r\n- Have I written custom code:\r\n- OS Platform and Distribution: Windows 10 Enterprise 1803 (build 17134.1246)\r\n- TensorFlow backend: yes\r\n- TensorFlow version: 2.0.0\r\n- Keras version: '2.2.4-tf' (called from tensorflow.keras)\r\n- Python version: 3.7\r\n- CUDA/cuDNN version: -\r\n- GPU model and memory: -\r\n\r\nFor a project I'm working on, I needed a Depthwise Convolutional Layer 1D.\r\nUnfortunately, keras at the moment does not include this layer (despite including `Conv1D`, `SeparableConv1D` and `DepthwiseConv2D`). Merging the codes of these three layers, I developed a version of `DepthwiseConv1D` that you can see below.\r\n\r\n1. I think that keras should have this layer available in its standard library since `DepthwiseConv` is the only convolutional layer missing a 1D version. I'm quite sure of what I did, but I don't know keras code well enough to guarantee this to be 100% bug-free. How can I check this and would someone help me making a pull request with this code?\r\n\r\n2. When using this layer I get the following warning:\r\n```\r\nWARNING:tensorflow:Entity <bound method DepthwiseConv1D.call of <__main__.DepthwiseConv1D object at 0x0000028580FB0D08>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: \r\nWARNING: Entity <bound method DepthwiseConv1D.call of <__main__.DepthwiseConv1D object at 0x0000028580FB0D08>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause:\r\n```\r\nlooking at #32377 and #32319, but I already have `gast` 0.2.2 installed. Should I be concerned? Does \"will be executed as-is\" means that the layer won't be trained?\r\n\r\n3.  `SeparableConv1D` at lines [1681-1684](https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/keras/layers/convolutional.py#L1555-L1702) does\r\n```\r\n    if self.data_format == 'channels_last':\r\n      strides = (1,) + self.strides + (1,)\r\n    else:\r\n      strides = (1, 1) + self.strides\r\n```\r\nsince `self.strides` is a 2-elements tuple, this cause `strides` to be a 4-elements tuple. This was causing me an error in `nn.separable_conv2d` so I changed this to simply `strides = self.strides*2` (note that in a 1D conv, `strides` is a 1-element tuple).\r\nWas this a bug in `SeparableConv1D`? Or is there a reason for this? Or what I did is wrong?\r\n\r\n```\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\n\r\nfrom tensorflow.python.framework import tensor_shape\r\nfrom tensorflow.python.keras import backend\r\nfrom tensorflow.python.keras import constraints\r\nfrom tensorflow.python.keras import initializers\r\nfrom tensorflow.python.keras import regularizers\r\nfrom tensorflow.python.keras.engine.input_spec import InputSpec\r\nfrom tensorflow.python.keras.layers.convolutional import Conv1D\r\n# imports for backwards namespace compatibility\r\n# pylint: disable=unused-import\r\n# pylint: enable=unused-import\r\nfrom tensorflow.python.keras.utils import conv_utils\r\nfrom tensorflow.python.keras.utils import tf_utils\r\nfrom tensorflow.python.ops import array_ops\r\nfrom tensorflow.python.util.tf_export import keras_export\r\n\r\n\r\n@keras_export('keras.layers.DepthwiseConv1D')\r\nclass DepthwiseConv1D(Conv1D):\r\n  \"\"\"Depthwise separable 1D convolution.\r\n  Depthwise Separable convolutions consist of performing\r\n  just the first step in a depthwise spatial convolution\r\n  (which acts on each input channel separately).\r\n  The `depth_multiplier` argument controls how many\r\n  output channels are generated per input channel in the depthwise step.\r\n  Arguments:\r\n    kernel_size: A single integer specifying the spatial\r\n      dimensions of the filters.\r\n    strides: A single integer specifying the strides\r\n      of the convolution.\r\n      Specifying any `stride` value != 1 is incompatible with specifying\r\n      any `dilation_rate` value != 1.\r\n    padding: one of `'valid'` or `'same'` (case-insensitive).\r\n    depth_multiplier: The number of depthwise convolution output channels\r\n      for each input channel.\r\n      The total number of depthwise convolution output\r\n      channels will be equal to `filters_in * depth_multiplier`.\r\n    data_format: A string,\r\n      one of `channels_last` (default) or `channels_first`.\r\n      The ordering of the dimensions in the inputs.\r\n      `channels_last` corresponds to inputs with shape\r\n      `(batch, length, channels)` while `channels_first`\r\n      corresponds to inputs with shape\r\n      `(batch, channels, length)`.\r\n      The default is 'channels_last'.\r\n    activation: Activation function to use.\r\n      If you don't specify anything, no activation is applied\r\n      (ie. 'linear' activation: `a(x) = x`).\r\n    use_bias: Boolean, whether the layer uses a bias vector.\r\n    depthwise_initializer: Initializer for the depthwise kernel matrix.\r\n    bias_initializer: Initializer for the bias vector.\r\n    depthwise_regularizer: Regularizer function applied to\r\n      the depthwise kernel matrix.\r\n    bias_regularizer: Regularizer function applied to the bias vector.\r\n    activity_regularizer: Regularizer function applied to\r\n      the output of the layer (its 'activation').\r\n    depthwise_constraint: Constraint function applied to\r\n      the depthwise kernel matrix.\r\n    bias_constraint: Constraint function applied to the bias vector.\r\n  Input shape:\r\n    3D tensor with shape:\r\n    `[batch, channels, length]` if data_format='channels_first'\r\n    or 4D tensor with shape:\r\n    `[batch, length, channels]` if data_format='channels_last'.\r\n  Output shape:\r\n    3D tensor with shape:\r\n    `[batch, filters, new_length]` if data_format='channels_first'\r\n    or 3D tensor with shape:\r\n    `[batch, new_length, filters]` if data_format='channels_last'.\r\n    `length` values might have changed due to padding.\r\n  \"\"\"\r\n\r\n  def __init__(self,\r\n               kernel_size,\r\n               strides=1,\r\n               padding='valid',\r\n               depth_multiplier=1,\r\n               data_format=None,\r\n               activation=None,\r\n               use_bias=True,\r\n               depthwise_initializer='glorot_uniform',\r\n               bias_initializer='zeros',\r\n               depthwise_regularizer=None,\r\n               bias_regularizer=None,\r\n               activity_regularizer=None,\r\n               depthwise_constraint=None,\r\n               bias_constraint=None,\r\n               **kwargs):\r\n    super(DepthwiseConv1D, self).__init__(\r\n        filters=None,\r\n        kernel_size=kernel_size,\r\n        strides=strides,\r\n        padding=padding,\r\n        data_format=data_format,\r\n        activation=activation,\r\n        use_bias=use_bias,\r\n        bias_regularizer=bias_regularizer,\r\n        activity_regularizer=activity_regularizer,\r\n        bias_constraint=bias_constraint,\r\n        # autocast=False,\r\n        **kwargs)\r\n    self.depth_multiplier = depth_multiplier\r\n    self.depthwise_initializer = initializers.get(depthwise_initializer)\r\n    self.depthwise_regularizer = regularizers.get(depthwise_regularizer)\r\n    self.depthwise_constraint = constraints.get(depthwise_constraint)\r\n    self.bias_initializer = initializers.get(bias_initializer)\r\n\r\n  def build(self, input_shape):\r\n    if len(input_shape) < 3:\r\n      raise ValueError('Inputs to `DepthwiseConv1D` should have rank 3. '\r\n                       'Received input shape:', str(input_shape))\r\n    input_shape = tensor_shape.TensorShape(input_shape)\r\n\r\n    #TODO(pj1989): replace with channel_axis = self._get_channel_axis()\r\n    if self.data_format == 'channels_last':\r\n        channel_axis = -1\r\n    elif self.data_format == 'channels_first':\r\n        channel_axis = 1\r\n\r\n    if input_shape.dims[channel_axis].value is None:\r\n      raise ValueError('The channel dimension of the inputs to '\r\n                       '`DepthwiseConv1D` '\r\n                       'should be defined. Found `None`.')\r\n    input_dim = int(input_shape[channel_axis])\r\n    depthwise_kernel_shape = (self.kernel_size[0],\r\n                              input_dim,\r\n                              self.depth_multiplier)\r\n\r\n    self.depthwise_kernel = self.add_weight(\r\n        shape=depthwise_kernel_shape,\r\n        initializer=self.depthwise_initializer,\r\n        name='depthwise_kernel',\r\n        regularizer=self.depthwise_regularizer,\r\n        constraint=self.depthwise_constraint)\r\n\r\n    if self.use_bias:\r\n      self.bias = self.add_weight(shape=(input_dim * self.depth_multiplier,),\r\n                                  initializer=self.bias_initializer,\r\n                                  name='bias',\r\n                                  regularizer=self.bias_regularizer,\r\n                                  constraint=self.bias_constraint)\r\n    else:\r\n      self.bias = None\r\n    # Set input spec.\r\n    self.input_spec = InputSpec(ndim=3, axes={channel_axis: input_dim})\r\n    self.built = True\r\n\r\n  def call(self, inputs):\r\n    if self.padding == 'causal':\r\n      inputs = array_ops.pad(inputs, self._compute_causal_padding())\r\n    if self.data_format == 'channels_last':\r\n      spatial_start_dim = 1\r\n    else:\r\n      spatial_start_dim = 2\r\n\r\n    # Explicitly broadcast inputs and kernels to 4D.\r\n    # TODO(fchollet): refactor when a native depthwise_conv2d op is available.\r\n    strides = self.strides * 2\r\n    inputs = array_ops.expand_dims(inputs, spatial_start_dim)\r\n    depthwise_kernel = array_ops.expand_dims(self.depthwise_kernel, 0)\r\n    dilation_rate = (1,) + self.dilation_rate\r\n\r\n    outputs = backend.depthwise_conv2d(\r\n        inputs,\r\n        depthwise_kernel,\r\n        strides=strides,\r\n        padding=self.padding,\r\n        dilation_rate=dilation_rate,\r\n        data_format=self.data_format)\r\n\r\n    if self.use_bias:\r\n      outputs = backend.bias_add(\r\n          outputs,\r\n          self.bias,\r\n          data_format=self.data_format)\r\n\r\n    outputs = array_ops.squeeze(outputs, [spatial_start_dim])\r\n\r\n    if self.activation is not None:\r\n      return self.activation(outputs)\r\n\r\n    return outputs\r\n\r\n  @tf_utils.shape_type_conversion\r\n  def compute_output_shape(self, input_shape):\r\n    if self.data_format == 'channels_first':\r\n      length = input_shape[2]\r\n      out_filters = input_shape[1] * self.depth_multiplier\r\n    elif self.data_format == 'channels_last':\r\n      length = input_shape[1]\r\n      out_filters = input_shape[2] * self.depth_multiplier\r\n\r\n    length = conv_utils.conv_output_length(length, self.kernel_size,\r\n                                           self.padding,\r\n                                           self.strides)\r\n    if self.data_format == 'channels_first':\r\n      return (input_shape[0], out_filters, length)\r\n    elif self.data_format == 'channels_last':\r\n      return (input_shape[0], length, out_filters)\r\n\r\n  def get_config(self):\r\n    config = super(DepthwiseConv1D, self).get_config()\r\n    config.pop('filters')\r\n    config.pop('kernel_initializer')\r\n    config.pop('kernel_regularizer')\r\n    config.pop('kernel_constraint')\r\n    config['depth_multiplier'] = self.depth_multiplier\r\n    config['depthwise_initializer'] = initializers.serialize(\r\n        self.depthwise_initializer)\r\n    config['depthwise_regularizer'] = regularizers.serialize(\r\n        self.depthwise_regularizer)\r\n    config['depthwise_constraint'] = constraints.serialize(\r\n        self.depthwise_constraint)\r\n    return config\r\n```\r\n", "comments": [" +1. This is a much needed layer.", "+1. I am also trying to build a depthwise Conv1D for a project. Hope it Depthwise layer is considered to be added to keras soon.", "\\+1. I am currently trying to build a depthwise Conv1D for a project. and would also benefit from this layer being added to Keras.", "Comment re-edited to fix a complete mess in the markup", "+1. ", "Side note: there was a proposal for an official DepthwiseConv1D PR at https://github.com/tensorflow/tensorflow/issues/48557", "DepthwiseConv1D is added in TF 2.6\r\nSee https://www.tensorflow.org/api_docs/python/tf/keras/layers/DepthwiseConv1D\r\nThanks!"]}, {"number": 36934, "title": "For loop variable 'tensor_value' is not used in the loop body", "body": "Hello, I'm curious about this. The for loop I mentioned is using variable `tensor_values`, but the variable `tensor_value` is never be used in the loop itself. Is it necessary?\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/aadf705c858014a168d1a582accc81b7cc774d68/tensorflow/python/debug/lib/dumping_callback_test.py#L1131-L1136", "comments": []}, {"number": 36933, "title": "API break between TF2.0.0 and TF2.1.0 on simple Keras code", "body": "- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.13.6\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v2.1.0-rc2-17-ge5bf8de410 2.1.0\r\n- Python version: v3.6.7:6ec5cf24b7, Oct 20 2018, 03:02:14\r\n\r\n**Describe the current behavior**\r\nI have written a piece of code to answer [this stackoverflow question](https://stackoverflow.com/questions/48309322/keras-multiply-layer-in-functional-api) (the code of `make_model`), and it worked well with tf2.0.0. But today I tested it coincidentally on tf2.1.0 and it raised an error. From the error message, the root cause seems to be that I didn't provide a `name` argument on my `tf.keras.Input` calls.\r\n\r\nNote that the second piece of code that I wrote in my stackoverflow answer, `make_model_2`, works with both tf2.0.0 and tf2.1.0.\r\n\r\n**Describe the expected behavior**\r\nThere shouldn't be any backward incompatibility between tf2.1.0 and tf2.0.0.\r\n\r\n**Standalone code to reproduce the issue** \r\n```\r\nimport tensorflow as tf\r\n\r\nprint(tf.version.VERSION)\r\n\r\ntoy_data = {'movie': [[0], [1], [0], [1]], 'user': [[10], [12], [12], [10]]}\r\ndataset = tf.data.Dataset.from_tensor_slices(toy_data).batch(2)\r\n\r\nfor x in dataset:\r\n    print(x)\r\n\r\ndef make_model():\r\n    inp_movie = tf.keras.Input(shape=(1,))\r\n    inp_user = tf.keras.Input(shape=(1,))\r\n    movie_embedding = tf.keras.layers.Dense(\r\n            units=40, activation=tf.keras.layers.Activation(\"relu\"))(inp_movie)\r\n    user_embedding = tf.keras.layers.Dense(\r\n            units=40, activation=tf.keras.layers.Activation(\"relu\"))(inp_user)\r\n    combined = tf.concat([movie_embedding, user_embedding], 1)\r\n    output = tf.keras.layers.Dense(\r\n            units=1, activation=tf.keras.layers.Activation(\"sigmoid\"))(combined)\r\n    model = tf.keras.Model(inputs=[inp_movie, inp_user], outputs=output)\r\n    return model\r\n\r\nmodel = make_model()\r\n\r\nfor x in dataset:\r\n    print(model(x))\r\n```\r\n\r\n**Other info / logs** \r\n```\r\n---------------------------------------------------------------------------\r\nKeyError                                  Traceback (most recent call last)\r\n<ipython-input-1-cf28ddc4e239> in <module>\r\n     25 \r\n     26 for x in dataset:\r\n---> 27     print(model(x))\r\n\r\n~/path/to/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py in __call__(self, inputs, *args, **kwargs)\r\n    820           with base_layer_utils.autocast_context_manager(\r\n    821               self._compute_dtype):\r\n--> 822             outputs = self.call(cast_inputs, *args, **kwargs)\r\n    823           self._handle_activity_regularization(inputs, outputs)\r\n    824           self._set_mask_metadata(inputs, outputs, input_masks)\r\n\r\n~/path/to/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py in call(self, inputs, training, mask)\r\n    715     return self._run_internal_graph(\r\n    716         inputs, training=training, mask=mask,\r\n--> 717         convert_kwargs_to_constants=base_layer_utils.call_context().saving)\r\n    718 \r\n    719   def compute_output_shape(self, input_shape):\r\n\r\n~/path/to/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py in _run_internal_graph(self, inputs, training, mask, convert_kwargs_to_constants)\r\n    820       # list. Matches dict keys to input names.\r\n    821       inputs = [\r\n--> 822           inputs[inp._keras_history.layer.name] for inp in self._nested_inputs\r\n    823       ]\r\n    824     else:\r\n\r\n~/path/to/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py in <listcomp>(.0)\r\n    820       # list. Matches dict keys to input names.\r\n    821       inputs = [\r\n--> 822           inputs[inp._keras_history.layer.name] for inp in self._nested_inputs\r\n    823       ]\r\n    824     else:\r\n\r\nKeyError: 'input_1'\r\n```", "comments": ["please find code run on [TF2.0](https://colab.sandbox.google.com/gist/Saduf2019/6fb4ef7e0a9c09e6d63bfd5e7dc3467f/untitled58.ipynb#scrollTo=BKeM8-zXlC5V) [where it runs fine] and [nightly](https://colab.sandbox.google.com/gist/Saduf2019/5c01898963a04578dc23874d7cb708fc/untitled59.ipynb), the error persist in nightly.", "@durandg12 This is was resolved in recent `tf-nightly`. I ran your code with `tf-nightly` and I don't see any issues. Please check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/189e26ad5f4b25fc34774cfe68142ead/untitled59.ipynb). Thanks!\r\n\r\nPlease close the issue if this was resolved for you. Thanks!", "Hello, I have tried your notebook and the issue  seems indeed closed. Thanks.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36933\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36933\">No</a>\n"]}, {"number": 36932, "title": "Issue while using \"drop_remainder=True\" on validation set with TPU", "body": "**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow): Yes\r\n- Tensorflow version: `2.1.0`\r\n\r\nAbout hardware and software system information I'm using Kaggle kernels so more information can be found here: https://github.com/Kaggle/docker-python\r\n\r\n**Describe the current behavior**\r\nI'm getting errors like the ones below, when I use the argument `drop_remainder=True` on the `dataset.batch()` function, but this happens only with the validation set:\r\n![tpu erros](https://user-images.githubusercontent.com/16668746/74946458-18a92100-53d8-11ea-85ad-d9a2aaa1d0bc.PNG)\r\n\r\nThe issue was further discussed in [this thread on the Kaggle forum](https://www.kaggle.com/c/flower-classification-with-tpus/discussion/130717)\r\n\r\n**Describe the expected behavior**\r\nThe model was supposed to train normally like when I don't use the `drop_remainder=True` argument.\r\n\r\n**Standalone code to reproduce the issue** \r\nLink for the Kaggle kernel: https://www.kaggle.com/dimitreoliveira/flower-classification-with-tpus-eda-and-baseline\r\n\r\n**Other info / logs** \r\nHere is a quick summary of the experiments:\r\n- [Version 32](https://www.kaggle.com/dimitreoliveira/flower-classification-with-tpus-eda-and-baseline?scriptVersionId=28912464): I've not used `drop_remainder=True` on any set and got no error.\r\n- [Version 33](https://www.kaggle.com/dimitreoliveira/flower-classification-with-tpus-eda-and-baseline?scriptVersionId=28930091): I've used `drop_remainder=True` on train and validation sets and got error.\r\n- [Version 34](https://www.kaggle.com/dimitreoliveira/flower-classification-with-tpus-eda-and-baseline?scriptVersionId=28931447): I've used `drop_remainder=True` only on train and got no error.\r\n- [Version 35](https://www.kaggle.com/dimitreoliveira/flower-classification-with-tpus-eda-and-baseline/notebook?scriptVersionId=28932681): I've used `drop_remainder=True` only on validation and got error.\r\n\r\nSo it seems the errors are related to using `drop_remainder=True` on the validation set.\r\n", "comments": ["Is this still an issue?", "Hi @ymodak , this was mostly related to memory issues, so it is no longer an issue, I'm closing.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36932\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36932\">No</a>\n"]}, {"number": 36931, "title": "Bazel build cannot access private member.. windows", "body": "Im trying to build tensorflow from source on windows 10\r\nI cant use pip install tensorflow coz i want to add user_ops in the build.\r\n(Please let me know if that is possible any other way than source build)\r\n\r\n------------------------------------------------------------------------\r\n\r\nSo I'm using these for build:\r\n      Python = 3.7.6\r\n      TF = Currently On Github (2/20/20)\r\n      Bazel = 2.0.0\r\n      MSVC = 14.15.26726 (VS 2017)\r\n      Windows 10\r\n      AMD Ryzen 1700\r\n      CPU Build\r\n\r\nDuring configuration, I selected:\r\n      JIT = Yes\r\n      ROCM = No\r\n      CUDA = No\r\n      Eigen overrides = No\r\n\r\n------------------------------------------------------------------------\r\n\r\nI get different errors every single time I run this build.\r\nI did follow every single step on the https://www.tensorflow.org/install/source_windows#configure_the_build\r\n\r\nEverytime, it says it cant access some private member from some class.\r\nHere I got class ThreadPool, sometimes its TraceMe, sometimes something else I dont remember.\r\nIts different everytime.\r\nThis is after 5-10min into build so the entire trace is huge.\r\nI'll just put the ERROR part in here.\r\n\r\nHELPPPPPPPPP........ I need user_ops....\r\n\r\n```\r\n**ERROR: D:/production/tensorflow-master/tensorflow/compiler/xla/BUILD:411:1: C++ compilation of rule '//tensorflow/compiler/xla:literal' failed (Exit 2)\r\nexternal/com_google_absl\\absl/meta/type_traits.h(121): error C2248: 'tensorflow::thread::ThreadPool::operator =': cannot access private member declared in class 'tensorflow::thread::ThreadPool'**\r\n\r\n.\\tensorflow/core/platform/threadpool.h(237): note: see declaration of 'tensorflow::thread::ThreadPool::operator ='\r\n.\\tensorflow/core/platform/threadpool.h(42): note: see declaration of 'tensorflow::thread::ThreadPool'\r\nexternal/com_google_absl\\absl/meta/type_traits.h(150): note: see reference to class template instantiation 'absl::type_traits_internal::is_detected<absl::type_traits_internal::IsCopyAssignableImpl,T>' being compiled\r\n        with\r\n        [\r\n            T=tensorflow::thread::ThreadPool\r\n        ]\r\nexternal/com_google_absl\\absl/meta/type_traits.h(430): note: see reference to class template instantiation 'absl::is_copy_assignable<T>' being compiled\r\n        with\r\n        [\r\n            T=tensorflow::thread::ThreadPool\r\n        ]\r\n\r\n..\r\n..\r\n..\r\n\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 1058.548s, Critical Path: 969.86s\r\nINFO: 2855 processes: 2855 local.\r\nFAILED: Build did NOT complete successfully\r\n```", "comments": ["@kitepro,\r\nCould you please try building TensorFlow using Bazel version 0.27.1.\r\nAlso, if you are using a virtual environment, please check if you have entered the correct Python path while configuring the build. Thanks!", "Any updates regarding this issue? Thanks!", "Oh I forgot...\r\nI did try 0.27.1 didnt work.. same error..\r\nI ended up installing fedora as a dual boot.. worked there..\r\nClosing the issue I guess,", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36931\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36931\">No</a>\n"]}, {"number": 36930, "title": "TFLu: Update filtered tests for stm32f4", "body": "Removing depthwise_conv_test and conv_test from filter list as they are\r\nnow working with Renode.", "comments": []}, {"number": 36929, "title": "(Solved and Not BUG)No module named 'tensorflow_core.compat' when import tensorflow_datasets in VSCode", "body": "Sorry, I think I should check my code again, this problem may be caused by my mistakenly import other dependent files. Don't spend your precious time on my issue.\r\nThe problem is that when I downloaded the .py file from the tensorflow website, the default file name is csv.py which contradicted with other files in packages.\r\n\r\nSystem: Window10 Pro 1909 zh-cn\r\nPython version: 3.7.6\r\nTensorflow version: 2.1\r\nCUDA version: 10.01\r\nVisual Studio Code version: 1.42.1 with extension of zh-cn\r\n\r\nI'm a beginner in Tensorflow studying. And now I'm studying with the tutorial from tensorflow official website, https://www.tensorflow.org/tutorials/load_data/csv.\r\n\r\nI tried to test the code from the tutotial above line by line and had a strange phenonmenon at start.\r\n\r\nWhen I tried the order of importing dependent files in the document, I got an error \"No module named 'tensorflow_core.compat' \".\r\n\r\nThe code \"import_bug.py\": \r\nimport tensorflow\r\nimport tensorflow_datasets\r\n\r\nThe error information:\r\n\r\nFailed to import TensorFlow. Please note that TensorFlow is not installed by default when you install TensorFlow Datasets. This is so that users can decide whether to install the GPU-enabled TensorFlow package. To use TensorFlow Datasets, please install the most recent version of TensorFlow, by following instructions at https://tensorflow.org/install.\r\n\r\nTraceback (most recent call last):\r\n  File \"~/Tensorflow/import_bug.py\", line 1, in <module>\r\n    import tensorflow\r\n  File \"~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\__init__.py\", line 101, in <module>\r\n    from tensorflow_core import *\r\n  File \"~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 40, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 75, in <module>\r\n    from tensorflow.python.framework.framework_lib import *  # pylint: disable=redefined-builtin\r\n  File \"~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_core\\python\\framework\\framework_lib.py\", line 25, in <module>\r\n    from tensorflow.python.framework.ops import Graph\r\n  File \"~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 41, in <module>\r\n    from tensorflow.python.eager import context\r\n  File \"~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_core\\python\\eager\\context.py\", line 25, in <module>\r\n    from absl import logging\r\n  File \"~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\absl\\logging\\__init__.py\", line 91, in <module>\r\n    from absl import flags\r\n  File \"~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\absl\\flags\\__init__.py\", line 40, in <module>\r\n    from absl.flags import _argument_parser\r\n  File \"~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\absl\\flags\\_argument_parser.py\", line 25, in <module>\r\n    import csv\r\n  File \"~\\Tensorflow\\csv.py\", line 8, in <module>\r\n    import tensorflow_datasets as tfds\r\n  File \"~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_datasets\\__init__.py\", line 46, in <module>\r\n    from tensorflow_datasets.core import tf_compat\r\n  File \"~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_datasets\\core\\__init__.py\", line 21, in <module>\r\n    tf_compat.ensure_tf_install()\r\n  File \"~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_datasets\\core\\tf_compat.py\", line 46, in ensure_tf_install\r\n    import tensorflow.compat.v2 as tf\r\n  File \"~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nModuleNotFoundError: No module named 'tensorflow_core.compat'\r\n\r\nBut interestingly, when I tried the second line code of \"import_bug.py\" only (\"import tensorflow_datasets) or the reverse order of the two-line code(\"import tensorflow_datasets \\n import tensorflow), there was no warning about the error above.\r\n\r\nI want to know whether there is some setup mistakes in my computer environment or this is a common problem. I guess there maybe some dated \"import\" statementss in the related packages.", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36929\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36929\">No</a>\n"]}, {"number": 36928, "title": "if GPU available, raise Exception \"Cholesky decomposition was not successful. The input might not be valid\" ,otherwise, in CPU mode, The Official Unittest is ok", "body": "**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow):  No\r\n- OS Platform and Distribution (e.g.,\r\nLinux Ubuntu 16.04): Linux Ubuntu 16.04\r\n- TensorFlow installed from (source or\r\nbinary):  pip install tensorflow-gpu==1.15.0\r\n\r\n[tf_env.txt](https://github.com/tensorflow/tensorflow/files/4230518/tf_env.txt)\r\n\r\n```\r\npython -c \"import tensorflow as tf ;print (tf.__version__)\"\r\n1.15.0\r\n```\r\n```\r\npython -c \"import tensorflow as tf ;print ( tf.test.gpu_device_name())\"  \r\n\r\n Found device 0 with properties: \r\nname: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\r\n\r\nCreated TensorFlow device (/device:GPU:0 with 30555 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:8a:00.0, compute capability: 7.0)\r\n```\r\n\r\n**Describe the current behavior**\r\n```\r\nCUDA_VISIBLE_DEVICES=-1 python gmm_test.py  GMMTest.test_fit\r\nok!\r\n```\r\n```\r\nCUDA_VISIBLE_DEVICES=0 python gmm_test.py  GMMTest.test_fit\r\n\r\nerror:Original stack trace for 'Cholesky': \r\n```\r\n\r\n**Describe the expected behavior**\r\nexpect  The Official code([gem_test.py](https://github.com/tensorflow/tensorflow/blob/r1.15/tensorflow/contrib/factorization/python/ops/gmm_test.py)) should  pass  the Unit-test in GPU mode\r\n```\r\nCUDA_VISIBLE_DEVICES=0 python gmm_test.py  GMMTest.test_fit\r\nok!\r\n```\r\n**Standalone code to reproduce the issue** \r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n```\r\nwget https://raw.githubusercontent.com/tensorflow/tensorflow/r1.15/tensorflow/contrib/factorization/python/ops/gmm_test.py -O \"gmm_test.py\"\r\n\r\nCUDA_VISIBLE_DEVICES=0 python gmm_test.py  GMMTest.test_fit\r\n\r\n```\r\n\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n[python_trace_err.log ](https://github.com/tensorflow/tensorflow/files/4230533/python_trace_err.log), which is python back_trace info\r\n", "comments": ["+1 may this problem be focused", "FWIW, see https://github.com/GPflow/GPflow/issues/553 for similar discussion.", "close ,as GPflow instead of\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36928\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36928\">No</a>\n"]}, {"number": 36927, "title": "Invalid output for MobileNet SSD with Hexagon Delegate and QCS605", "body": "Hi there!\r\n\r\nI have been using Tensorflow Lite and Coco SSD MobileNet for some time now in my Android (API 27) application and I decided to add a Hexagon Delegate. There is an unprecedented improvement in prediction time but prediction itself is full of false positives. I am using custom board with QCS605 on it. \r\n\r\n![Prediction without Hexagon delegate](https://user-images.githubusercontent.com/19536019/74928964-d208f600-53da-11ea-8594-ba3ce491402d.png)\r\nPrediction without Hexagon delegate\r\n![Prediction with Hexagon Delegate](https://user-images.githubusercontent.com/19536019/74928969-d59c7d00-53da-11ea-9b63-24623a560ee2.png)\r\nPrediction with Hexagon Delegate\r\n\r\nYou can notice that with Hexagon Delegate there is the same confidence score for every box and some boxes are invalid (negative coordinates etc...)\r\n\r\nThe difference between these two interpreters is only in the delegate:\r\n`       \r\n\r\n        try {\r\n            HexagonDelegate hexagonDelegate = new HexagonDelegate(c);\r\n            options.addDelegate(hexagonDelegate);\r\n        } catch (UnsupportedOperationException e) {\r\n            Log.e(\"TFLITE DELEGATE\", \"Hexagon delegate is not supported on this device\");\r\n        }\r\n\r\n         mModel = new Interpreter(ResourceHelper.loadModelFile(c.getAssets(), modelFileName), \r\n\r\n`\r\nI get info \"Hexagon delegate: 61 nodes delegated out of 64 nodes.\"\r\nAny suggestions as what might be happening here? At first I thought that maybe my input is invalid but I guess delegate should not have any impact on that.... Difference in prediction time is  huge - 300ms/40ms as for CPU/DSP\r\n\r\nI would really appreciate your help :) \r\n\r\nThank you!\r\n\r\n\r\n", "comments": ["Fixed by #36804 . Thank you @srjoglekar246  !"]}, {"number": 36926, "title": "Array Relu, which is an input to the Conv operator producing the output array conv2d_1/BiasAdd, is lacking min/max data, which is necessary for quantization", "body": "Hi,\r\nI am facing the following issue while converting my Frozen graph(.pb) to tflite \r\n\r\nArray Relu, which is an input to the Conv operator producing the output array conv2d_1/BiasAdd, is lacking min/max data, which is necessary for quantization. If accuracy matters, either target a non-quantized output format, or run quantized training with your model from a floating point checkpoint to change the input graph to contain min/max information. If you don't care about accuracy, you can pass --default_ranges_min= and --default_ranges_max= for easy experimentation.\r\nFatal Python error: Aborted\r\n\r\nCurrent thread 0x00007f637125f740 (most recent call first):\r\n  File \"/home/shubhamsingh/miniconda3/lib/python3.7/site-packages/tensorflow/lite/toco/python/toco_from_protos.py\", line 33 in execute\r\n  File \"/home/shubhamsingh/miniconda3/lib/python3.7/site-packages/absl/app.py\", line 250 in _run_main\r\n  File \"/home/shubhamsingh/miniconda3/lib/python3.7/site-packages/absl/app.py\", line 299 in run\r\n  File \"/home/shubhamsingh/miniconda3/lib/python3.7/site-packages/tensorflow/python/platform/app.py\", line 40 in run\r\n  File \"/home/shubhamsingh/miniconda3/lib/python3.7/site-packages/tensorflow/lite/toco/python/toco_from_protos.py\", line 59 in main\r\n  File \"/home/shubhamsingh/miniconda3/bin/toco_from_protos\", line 8 in <module>\r\nAborted (core dumped)\r\n\r\n\r\nI have used following script to convert the model\r\ntflite_convert --output_file=mode_new_yoyo1.tflite --graph_def_file=frozen_model.pb --inference_type=QUANTIZED_UINT8 --input_arrays=input_1 --output_arrays=Dense1/Softmax,Dense2/Softmax --mean_values=0 --std_dev_values=255\r\n\r\n\r\nI have used WideResnet model with two output node.", "comments": ["@shubham894, Can you provide the Tensorflow version that you are using. Thanks!", "@gadagashwini  I am using Tensorflow 1.14.0 .", "Are you converting a quantization-aware trained tf model? Can you try post-training integer [quantization](https://blog.tensorflow.org/2019/06/tensorflow-integer-quantization.html) instead?", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36926\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36926\">No</a>\n"]}, {"number": 36925, "title": "Import module as -- gives error", "body": "I am experiencing some strange behavior:\r\n\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nprint(tf.__version__)\r\nprint(tf.keras.__version__)\r\n\r\nfrom tf.keras.utils import to_categorical\r\n```\r\ngives the following output:\r\n\r\n```\r\n2.1.0\r\n2.2.4-tf\r\n---------------------------------------------------------------------------\r\nModuleNotFoundError                       Traceback (most recent call last)\r\n<ipython-input-12-45d6753a0084> in <module>\r\n      5 print(tf.keras.__version__)\r\n      6 \r\n----> 7 from tf.keras.utils import to_categorical\r\n      8 \r\n      9 one_hot_train_labels = to_categorical(train_labels)\r\n\r\nModuleNotFoundError: No module named 'tf'\r\n```\r\n\r\nHowever, if I changes it to\r\n\r\n```from tensorflow.keras.utils import to_categorical```\r\n\r\nit works fine. \r\n\r\nWith other modules it works fine. For example, no problem with:\r\n\r\n```from matplotlib import pyplot\r\npyplot.plot()```\r\n\r\n", "comments": ["@oeyvindds \r\n\r\nYou can use from `tensorflow.keras.utils import to_categorical` instead of `from tf.keras.utils import to_categorical` or you can use `tf.keras.utils.to_categorical` directly without importing. Thanks!", "@oeyvindds \r\n\r\n Please close this thread if it solves your question. Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "Getting error\r\nraceback (most recent call last):\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The file cannot be accessed by the system.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-32-8cbede223489>\", line 1, in <module>\r\n    from keras.utils import to_categorical\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\keras\\__init__.py\", line 3, in <module>\r\n    from . import utils\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\keras\\utils\\__init__.py\", line 6, in <module>\r\n    from . import conv_utils\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\keras\\utils\\conv_utils.py\", line 9, in <module>\r\n    from .. import backend as K\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\keras\\backend\\__init__.py\", line 1, in <module>\r\n    from .load_backend import epsilon\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\keras\\backend\\load_backend.py\", line 90, in <module>\r\n    from .tensorflow_backend import *\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 6, in <module>\r\n    from tensorflow.python.eager import context\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\context.py\", line 29, in <module>\r\n    from tensorflow.core.protobuf import config_pb2\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 42, in <module>\r\n    from . _api.v2 import audio\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\_api\\v2\\audio\\__init__.py\", line 10, in <module>\r\n    from tensorflow.python.ops.gen_audio_ops import decode_wav\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_audio_ops.py\", line 9, in <module>\r\n    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The file cannot be accessed by the system.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\r\n    stb = value._render_traceback_()\r\nAttributeError: 'ImportError' object has no attribute '_render_traceback_'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The file cannot be accessed by the system.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1148, in get_records\r\n    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\r\n    return f(*args, **kwargs)\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\r\n    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\inspect.py\", line 1502, in getinnerframes\r\n    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\inspect.py\", line 1460, in getframeinfo\r\n    filename = getsourcefile(frame) or getfile(frame)\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\inspect.py\", line 696, in getsourcefile\r\n    if getattr(getmodule(object, filename), '__loader__', None) is not None:\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\inspect.py\", line 733, in getmodule\r\n    if ismodule(module) and hasattr(module, '__file__'):\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 42, in <module>\r\n    from . _api.v2 import audio\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\_api\\v2\\audio\\__init__.py\", line 10, in <module>\r\n    from tensorflow.python.ops.gen_audio_ops import decode_wav\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_audio_ops.py\", line 9, in <module>\r\n    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The file cannot be accessed by the system.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-32-8cbede223489>\", line 1, in <module>\r\n    from keras.utils import to_categorical\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\keras\\__init__.py\", line 3, in <module>\r\n    from . import utils\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\keras\\utils\\__init__.py\", line 6, in <module>\r\n    from . import conv_utils\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\keras\\utils\\conv_utils.py\", line 9, in <module>\r\n    from .. import backend as K\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\keras\\backend\\__init__.py\", line 1, in <module>\r\n    from .load_backend import epsilon\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\keras\\backend\\load_backend.py\", line 90, in <module>\r\n    from .tensorflow_backend import *\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 6, in <module>\r\n    from tensorflow.python.eager import context\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\context.py\", line 29, in <module>\r\n    from tensorflow.core.protobuf import config_pb2\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 42, in <module>\r\n    from . _api.v2 import audio\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\_api\\v2\\audio\\__init__.py\", line 10, in <module>\r\n    from tensorflow.python.ops.gen_audio_ops import decode_wav\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_audio_ops.py\", line 9, in <module>\r\n    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The file cannot be accessed by the system.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\r\n    stb = value._render_traceback_()\r\nAttributeError: 'ImportError' object has no attribute '_render_traceback_'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The file cannot be accessed by the system.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The file cannot be accessed by the system.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-32-8cbede223489>\", line 1, in <module>\r\n    from keras.utils import to_categorical\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\keras\\__init__.py\", line 3, in <module>\r\n    from . import utils\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\keras\\utils\\__init__.py\", line 6, in <module>\r\n    from . import conv_utils\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\keras\\utils\\conv_utils.py\", line 9, in <module>\r\n    from .. import backend as K\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\keras\\backend\\__init__.py\", line 1, in <module>\r\n    from .load_backend import epsilon\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\keras\\backend\\load_backend.py\", line 90, in <module>\r\n    from .tensorflow_backend import *\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 6, in <module>\r\n    from tensorflow.python.eager import context\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\context.py\", line 29, in <module>\r\n    from tensorflow.core.protobuf import config_pb2\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 42, in <module>\r\n    from . _api.v2 import audio\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\_api\\v2\\audio\\__init__.py\", line 10, in <module>\r\n    from tensorflow.python.ops.gen_audio_ops import decode_wav\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_audio_ops.py\", line 9, in <module>\r\n    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The file cannot be accessed by the system.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\r\n    stb = value._render_traceback_()\r\nAttributeError: 'ImportError' object has no attribute '_render_traceback_'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3254, in run_ast_nodes\r\n    if (await self.run_code(code, result,  async_=asy)):\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3348, in run_code\r\n    self.showtraceback(running_compiled_code=True)\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2047, in showtraceback\r\n    value, tb, tb_offset=tb_offset)\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1415, in structured_traceback\r\n    self, etype, value, tb, tb_offset, number_of_lines_of_context)\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1315, in structured_traceback\r\n    self, etype, value, tb, tb_offset, number_of_lines_of_context\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1183, in structured_traceback\r\n    formatted_exceptions += self.prepare_chained_exception_message(evalue.__cause__)\r\nTypeError: can only concatenate str (not \"list\") to str\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\r\n    stb = value._render_traceback_()\r\nAttributeError: 'TypeError' object has no attribute '_render_traceback_'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The file cannot be accessed by the system.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1148, in get_records\r\n    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\r\n    return f(*args, **kwargs)\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\r\n    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\inspect.py\", line 1502, in getinnerframes\r\n    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\inspect.py\", line 1460, in getframeinfo\r\n    filename = getsourcefile(frame) or getfile(frame)\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\inspect.py\", line 696, in getsourcefile\r\n    if getattr(getmodule(object, filename), '__loader__', None) is not None:\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\inspect.py\", line 733, in getmodule\r\n    if ismodule(module) and hasattr(module, '__file__'):\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 42, in <module>\r\n    from . _api.v2 import audio\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\_api\\v2\\audio\\__init__.py\", line 10, in <module>\r\n    from tensorflow.python.ops.gen_audio_ops import decode_wav\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_audio_ops.py\", line 9, in <module>\r\n    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The file cannot be accessed by the system.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-32-8cbede223489>\", line 1, in <module>\r\n    from keras.utils import to_categorical\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\keras\\__init__.py\", line 3, in <module>\r\n    from . import utils\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\keras\\utils\\__init__.py\", line 6, in <module>\r\n    from . import conv_utils\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\keras\\utils\\conv_utils.py\", line 9, in <module>\r\n    from .. import backend as K\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\keras\\backend\\__init__.py\", line 1, in <module>\r\n    from .load_backend import epsilon\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\keras\\backend\\load_backend.py\", line 90, in <module>\r\n    from .tensorflow_backend import *\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 6, in <module>\r\n    from tensorflow.python.eager import context\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\context.py\", line 29, in <module>\r\n    from tensorflow.core.protobuf import config_pb2\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 42, in <module>\r\n    from . _api.v2 import audio\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\_api\\v2\\audio\\__init__.py\", line 10, in <module>\r\n    from tensorflow.python.ops.gen_audio_ops import decode_wav\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_audio_ops.py\", line 9, in <module>\r\n    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The file cannot be accessed by the system.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\r\n    stb = value._render_traceback_()\r\nAttributeError: 'ImportError' object has no attribute '_render_traceback_'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3254, in run_ast_nodes\r\n    if (await self.run_code(code, result,  async_=asy)):\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3348, in run_code\r\n    self.showtraceback(running_compiled_code=True)\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2047, in showtraceback\r\n    value, tb, tb_offset=tb_offset)\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1415, in structured_traceback\r\n    self, etype, value, tb, tb_offset, number_of_lines_of_context)\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1315, in structured_traceback\r\n    self, etype, value, tb, tb_offset, number_of_lines_of_context\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1183, in structured_traceback\r\n    formatted_exceptions += self.prepare_chained_exception_message(evalue.__cause__)\r\nTypeError: can only concatenate str (not \"list\") to str\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\r\n    stb = value._render_traceback_()\r\nAttributeError: 'TypeError' object has no attribute '_render_traceback_'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\Amlan\\Anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The file cannot be accessed by the system.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n---------------------------------------------------------------------------\r\nImportError                               Traceback (most recent call last)\r\n~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py in <module>\r\n     57 \r\n---> 58   from tensorflow.python.pywrap_tensorflow_internal import *\r\n     59   from tensorflow.python.pywrap_tensorflow_internal import __version__\r\n\r\n~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py in <module>\r\n     27             return _mod\r\n---> 28     _pywrap_tensorflow_internal = swig_import_helper()\r\n     29     del swig_import_helper\r\n\r\n~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py in swig_import_helper()\r\n     23             try:\r\n---> 24                 _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n     25             finally:\r\n\r\n~\\Anaconda3\\lib\\imp.py in load_module(name, file, filename, details)\r\n    241         else:\r\n--> 242             return load_dynamic(name, filename, file)\r\n    243     elif type_ == PKG_DIRECTORY:\r\n\r\n~\\Anaconda3\\lib\\imp.py in load_dynamic(name, path, file)\r\n    341             name=name, loader=loader, origin=path)\r\n--> 342         return _load(spec)\r\n    343 \r\n\r\nImportError: DLL load failed: The file cannot be accessed by the system.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nAttributeError                            Traceback (most recent call last)\r\n~\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in showtraceback(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\r\n   2043                         # in the engines. This should return a list of strings.\r\n-> 2044                         stb = value._render_traceback_()\r\n   2045                     except Exception:\r\n\r\nAttributeError: 'ImportError' object has no attribute '_render_traceback_'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTypeError                                 Traceback (most recent call last)\r\n~\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self, code_obj, result, async_)\r\n   3346             if result is not None:\r\n   3347                 result.error_in_exec = sys.exc_info()[1]\r\n-> 3348             self.showtraceback(running_compiled_code=True)\r\n   3349         else:\r\n   3350             outflag = False\r\n\r\n~\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in showtraceback(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\r\n   2045                     except Exception:\r\n   2046                         stb = self.InteractiveTB.structured_traceback(etype,\r\n-> 2047                                             value, tb, tb_offset=tb_offset)\r\n   2048 \r\n   2049                     self._showtraceback(etype, value, stb)\r\n\r\n~\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py in structured_traceback(self, etype, value, tb, tb_offset, number_of_lines_of_context)\r\n   1413             self.tb = tb\r\n   1414         return FormattedTB.structured_traceback(\r\n-> 1415             self, etype, value, tb, tb_offset, number_of_lines_of_context)\r\n   1416 \r\n   1417 \r\n\r\n~\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py in structured_traceback(self, etype, value, tb, tb_offset, number_of_lines_of_context)\r\n   1313             # Verbose modes need a full traceback\r\n   1314             return VerboseTB.structured_traceback(\r\n-> 1315                 self, etype, value, tb, tb_offset, number_of_lines_of_context\r\n   1316             )\r\n   1317         elif mode == 'Minimal':\r\n\r\n~\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py in structured_traceback(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\r\n   1181         exception = self.get_parts_of_chained_exception(evalue)\r\n   1182         if exception:\r\n-> 1183             formatted_exceptions += self.prepare_chained_exception_message(evalue.__cause__)\r\n   1184             etype, evalue, etb = exception\r\n   1185         else:\r\n\r\nTypeError: can only concatenate str (not \"list\") to str\r\n", "@jashiag \r\n\r\nCan you please raise a new issue by filling [issue template.](https://github.com/tensorflow/tensorflow/issues/new/choose).Thanks!"]}, {"number": 36924, "title": "How collect gradients with two and more losses?", "body": "```py\r\n@tf.function\r\ndef train(dataset, epochs=5):\r\n    for i in range(epochs):\r\n        dataset = dataset.shuffle(1000)\r\n        for images, boxes, labels in tqdm(dataset, desc='Epoch {} of {}'.format(i + 1, epochs)):\r\n            with tf.GradientTape() as tape:\r\n                localization, classification = model(images, training=True)\r\n                loss_smooth = smooth_l1(boxes, localization)\r\n                loss_focal  = focal(labels, classification)\r\n            gradients = tape.gradient([loss_smooth, loss_focal], model.trainable_variables)\r\n            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\r\n        print('Localization loss: {}, classification loss: {}'.format(loss_smooth, loss_focal))\r\n```\r\nHow to can train model with two and more losses? Help?", "comments": ["@open-v \r\n\r\nCan you please go through the [link](https://www.pyimagesearch.com/2018/06/04/keras-multiple-outputs-and-multiple-losses/) and see if it helps you. If you still need support please fill [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new/choose). Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, include simple standalone code to reproduce the issue in our environment. It helps us in localizing the issue faster. Thanks!\r\n\r\n", "You should combine the multi losses to one.\r\n\r\n```python\r\ntotal_loss = loss_smooth + loss_focal\r\n```\r\n\r\nor with a factor:\r\n\r\n```python\r\ntotal_loss = loss_smooth * 0.6 + loss_focal * 0.4\r\n```", "Thanks"]}, {"number": 36923, "title": "how to install tensorflow in python 3.7.2 in 32 bit system", "body": "hi....\r\n im trying to install tensorflow and keras for my project execution. Im able to install keras. But im unable to install tensorflow. \r\ncan any one please tell me? \r\n", "comments": ["@ravikanth076 \r\n\r\nTensorflow will not support in 32 bits architecture.Please, refer #32315 . Thanks!\r\n\r\n\r\n\r\n", "is there any other alternate  method to install Tensorflow? because i have this system only....\r\nplease help me..", "@ravikanth076 \r\nPlease use colab to import tensorflow on 32 bit machine. Thanks!", "I am closing the issue since the query is been answered. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36923\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36923\">No</a>\n"]}, {"number": 36921, "title": "tensorflow:AutoGraph could not transform", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information** \r\nDownloading and preparing dataset imdb_reviews (80.23 MiB) to /root/tensorflow_datasets/imdb_reviews/subwords8k/1.0.0...\r\nShuffling and writing examples to /root/tensorflow_datasets/imdb_reviews/subwords8k/1.0.0.incomplete7ZTMSY/imdb_reviews-train.tfrecord\r\nShuffling and writing examples to /root/tensorflow_datasets/imdb_reviews/subwords8k/1.0.0.incomplete7ZTMSY/imdb_reviews-test.tfrecord\r\nShuffling and writing examples to /root/tensorflow_datasets/imdb_reviews/subwords8k/1.0.0.incomplete7ZTMSY/imdb_reviews-unsupervised.tfrecord\r\nDataset imdb_reviews downloaded and prepared to /root/tensorflow_datasets/imdb_reviews/subwords8k/1.0.0. Subsequent calls will reuse this data.\r\nWARNING:tensorflow:AutoGraph could not transform <function _get_dataset_from_filename at 0x7f9503308d08> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: module 'gast' has no attribute 'Num'\r\nWARNING:tensorflow:AutoGraph could not transform <function _get_dataset_from_filename at 0x7f9503308d08> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: module 'gast' has no attribute 'Num'\r\nWARNING: AutoGraph could not transform <function _get_dataset_from_filename at 0x7f9503308d08> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: module 'gast' has no attribute 'Num'\r\nWARNING:tensorflow:AutoGraph could not transform <bound method TopLevelFeature.decode_example of FeaturesDict({\r\n    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\r\n    'text': Text(shape=(None,), dtype=tf.int64, encoder=<SubwordTextEncoder vocab_size=8185>),\r\n})> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: Bad argument number for Name: 3, expecting 4\r\nWARNING:tensorflow:AutoGraph could not transform <bound method TopLevelFeature.decode_example of FeaturesDict({\r\n    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\r\n    'text': Text(shape=(None,), dtype=tf.int64, encoder=<SubwordTextEncoder vocab_size=8185>),\r\n})> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: Bad argument number for Name: 3, expecting 4\r\nWARNING: AutoGraph could not transform <bound method TopLevelFeature.decode_example of FeaturesDict({\r\n    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\r\n    'text': Text(shape=(None,), dtype=tf.int64, encoder=<SubwordTextEncoder vocab_size=8185>),\r\n})> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: Bad argument number for Name: 3, expecting 4\r\nWARNING:tensorflow:AutoGraph could not transform <function _get_dataset_from_filename at 0x7f9503308d08> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: module 'gast' has no attribute 'Num'\r\nWARNING:tensorflow:AutoGraph could not transform <function _get_dataset_from_filename at 0x7f9503308d08> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: module 'gast' has no attribute 'Num'\r\nWARNING: AutoGraph could not transform <function _get_dataset_from_filename at 0x7f9503308d08> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: module 'gast' has no attribute 'Num'\r\nWARNING:tensorflow:AutoGraph could not transform <bound method TopLevelFeature.decode_example of FeaturesDict({\r\n    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\r\n    'text': Text(shape=(None,), dtype=tf.int64, encoder=<SubwordTextEncoder vocab_size=8185>),\r\n})> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: Bad argument number for Name: 3, expecting 4\r\nWARNING:tensorflow:AutoGraph could not transform <bound method TopLevelFeature.decode_example of FeaturesDict({\r\n    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\r\n    'text': Text(shape=(None,), dtype=tf.int64, encoder=<SubwordTextEncoder vocab_size=8185>),\r\n})> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: Bad argument number for Name: 3, expecting 4\r\nWARNING: AutoGraph could not transform <bound method TopLevelFeature.decode_example of FeaturesDict({\r\n    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\r\n    'text': Text(shape=(None,), dtype=tf.int64, encoder=<SubwordTextEncoder vocab_size=8185>),\r\n})> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: Bad argument number for Name: 3, expecting 4", "comments": ["@dynamor2019,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here and also the TensorFlow version you are using. Thanks!", "I just followed the tutorials of tensorflow @ tensorflow.google.cn,\r\n\r\n\r\ni try to learn&nbsp;\r\n\r\nText classification with preprocessed text: Movie reviews\r\nwith colab,&nbsp;\r\n\r\n\r\nafter&nbsp;\r\ntry:\r\n&nbsp;&nbsp;#&nbsp;%tensorflow_version&nbsp;only&nbsp;exists&nbsp;in&nbsp;Colab.\r\n&nbsp;&nbsp;!pip&nbsp;install&nbsp;-q&nbsp;tf-nightly\r\nexcept&nbsp;Exception:\r\n&nbsp;&nbsp;pass\r\nimport&nbsp;tensorflow&nbsp;as&nbsp;tf\r\n\r\n\r\ni can not get tf 2.2.0 but 2.1.0\r\n\r\n\r\nexcept the bug i submit, there is another bug appeard,as following:\r\n\r\n\r\ntrain_batches&nbsp;=&nbsp;(\r\n&nbsp;&nbsp;&nbsp;&nbsp;train_data\r\n&nbsp;&nbsp;&nbsp;&nbsp;.shuffle(BUFFER_SIZE)\r\n&nbsp;&nbsp;&nbsp;&nbsp;.padded_batch(32))\r\n\r\ntest_batches&nbsp;=&nbsp;(\r\n&nbsp;&nbsp;&nbsp;&nbsp;test_data\r\n&nbsp;&nbsp;&nbsp;&nbsp;.padded_batch(32))\r\n\r\n\r\n\r\n\r\n---------------------------------------------------------------------------TypeError                                 Traceback (most recent call last)\"><ipython-input-41-9a5275a8cbf1&gt; in <module&gt;()      4     train_data      5     .shuffle(BUFFER_SIZE)----&gt; 6     .padded_batch(32))      7       8 test_batches = (TypeError: padded_batch() missing 1 required positional argument: 'padded_shapes'\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n------------------&nbsp;\u539f\u59cb\u90ae\u4ef6&nbsp;------------------\r\n\u53d1\u4ef6\u4eba:&nbsp;\"amahendrakar\"<notifications@github.com&gt;;\r\n\u53d1\u9001\u65f6\u95f4:&nbsp;2020\u5e742\u670820\u65e5(\u661f\u671f\u56db) \u665a\u4e0a6:08\r\n\u6536\u4ef6\u4eba:&nbsp;\"tensorflow/tensorflow\"<tensorflow@noreply.github.com&gt;;\r\n\u6284\u9001:&nbsp;\"\u674e\u6653\u4eae\"<9370611@qq.com&gt;;\"Mention\"<mention@noreply.github.com&gt;;\r\n\u4e3b\u9898:&nbsp;Re: [tensorflow/tensorflow] tensorflow:AutoGraph could not transform (#36921)\r\n\r\n\r\n\r\n\r\n@dynamor2019,\r\n In order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here and also the TensorFlow version you are using. Thanks!\r\n \r\n\u2014\r\nYou are receiving this because you were mentioned.\r\nReply to this email directly, view it on GitHub, or unsubscribe.", "@dynamor2019,\r\nI was able to run the code from the tutorial without any issues, please find the Gist of it [here](https://colab.research.google.com/gist/amahendrakar/f55d81960b26817ca4e247f6632d3dee/36921.ipynb).\r\n\r\nRegarding the TensorFlow version, looks like you have TF 2.1 installed. If you want to install TF 2.2, which is the nightly version, please use the command `pip install tf-nightly`.\r\n\r\nThanks!", "Any updates regarding this issue? Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36921\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36921\">No</a>\n", "I have tensorflow 2.4.1 ,I came with the same problem,but my problem hasn't been solved."]}, {"number": 36918, "title": "Using trademarked word \"TensorFlow\" in the name of a C# binding", "body": "My company is developing a proprietary TensorFlow binding for .NET called [Gradient](https://losttech.software/gradient.html). We are considering to rename it to clearly indicate, that it is designed to work with TensorFlow: into `CompanyName.TensorFlow`. I could not find any information if it is OK to use `TensorFlow` as part of the name in such manner. We will correctly only refer to Google as the owner of the trademark as requested in the [Brand Guidelines](https://www.tensorflow.org/extras/tensorflow_brand_guidelines.pdf).", "comments": ["We'll get you an answer here. => @theadactyl ", "(OK there is a very annoying bug in the assignee UI, sorry for the noise)", "What is the \"CompanyName.\" part of the name here?", "(I'm seeking advice on the answer to this, btw, sorry for the delay.)\r\ncc/ @theadactyl\r\n", "@martinwicke [Lost Tech](https://losttech.software/gradient.html). Based in Bellevue. So it would be `LostTech.TensorFlow`.", "This usage is fine.  We ask for attribution in our brand guidelines, so please note that \"TensorFlow is a trademark of Google LLC\"  in your documentation."]}, {"number": 36917, "title": "input_details shape is mismatching when converting Estimator to tflite", "body": "**System information**\r\n- OS Platform and Distribution :Ubuntu 18.04\r\n- TensorFlow installed from : pip\r\n- TensorFlow version : '2.2.0-dev20200218'\r\n\r\n\r\n**Command used to run the converter or code if you\u2019re using the Python API**\r\nIf possible, please share a link to Colab/Jupyter/any notebook.\r\n```python\r\nimport pandas as pd\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\ndftrain = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/train.csv')\r\ndfeval = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/eval.csv')\r\ny_train = dftrain.pop('survived')\r\ny_eval = dfeval.pop('survived')\r\n\r\n#create feature columns. For testing I am using only numeric ones\r\nNUMERIC_COLUMNS = ['age', 'fare']\r\nfeature_columns = []\r\nfor feature_name in NUMERIC_COLUMNS:\r\n    feature_columns.append(tf.feature_column.numeric_column(key=feature_name))\r\n\r\n# Use entire batch since this is such a small dataset.\r\nNUM_EXAMPLES = len(y_train)\r\n\r\ndef make_input_fn(X, y, n_epochs=None, shuffle=False):\r\n    def input_fn():\r\n        dataset = tf.data.Dataset.from_tensor_slices((dict(X), y))\r\n        \r\n        if shuffle:\r\n            dataset = dataset.shuffle(NUM_EXAMPLES)\r\n        \r\n        # For training, cycle thru dataset as many times as need (n_epochs=None).\r\n        dataset = dataset.repeat(n_epochs)\r\n        # In memory training doesn't use batching.\r\n        dataset = dataset.batch(NUM_EXAMPLES)\r\n        return dataset\r\n    return input_fn\r\n\r\n# Training and evaluation input functions.\r\ntrain_input_fn = make_input_fn(dftrain[NUMERIC_COLUMNS], y_train)\r\neval_input_fn = make_input_fn(dfeval[NUMERIC_COLUMNS], y_eval, shuffle=False, n_epochs=1)\r\n\r\nlinear_est = tf.estimator.LinearClassifier(feature_columns)\r\n\r\n# Train model.\r\nlinear_est.train(train_input_fn, max_steps=100)\r\n\r\n# Evaluation.\r\nresult = linear_est.evaluate(eval_input_fn)\r\n\r\nserving_input_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(\r\n  tf.feature_column.make_parse_example_spec(feature_columns))\r\n\r\nmodel_dir = 'model_data'\r\npath = linear_est.export_saved_model(model_dir, serving_input_fn)\r\n\r\nsaved_model_obj = tf.saved_model.load(export_dir=path)\r\nprint(saved_model_obj.signatures.keys())\r\n\r\n# Load the specific concrete function from the SavedModel.\r\nconcrete_func = saved_model_obj.signatures['serving_default']\r\n\r\n\r\n# Convert the model to a TFLite model.\r\nconverter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nconverter.experimental_new_converter = True\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,\r\n                               tf.lite.OpsSet.SELECT_TF_OPS]\r\ntflite_model = converter.convert()\r\n\r\nopen(\"converted.tflite\", \"wb\").write(tflite_model)\r\n# Load TFLite model and allocate tensors.\r\ninterpreter = tf.lite.Interpreter(model_path=\"converted.tflite\")\r\n\r\n# Get input and output tensors.\r\ninput_details = interpreter.get_input_details()\r\noutput_details = interpreter.get_output_details()\r\n\r\nprint(input_details)\r\n```\r\n**Output is**\r\n```\r\n[{'name': 'input_example_tensor',\r\n  'index': 0,\r\n  'shape': array([1], dtype=int32),\r\n  'shape_signature': array([], dtype=int32),\r\n  'dtype': numpy.bytes_,\r\n  'quantization': (0.0, 0),\r\n  'quantization_parameters': {'scales': array([], dtype=float32),\r\n   'zero_points': array([], dtype=int32),\r\n   'quantized_dimension': 0},\r\n  'sparsity_parameters': {}}]\r\n```\r\nwhy shape is [1] if I am passing 2 feature column to train. And if it is correct, how can I predict the loaded model\r\n\r\n", "comments": ["@gurugaurav  Could you please try on latest stable version of tf 2.5 or 2.4.1 and let us know if this is still an issue.\r\nI tried to run the code  on Colab with TF v2.5 and got different output , please find the gist [here](https://colab.research.google.com/gist/sushreebarsa/8c3dfb8e8256b0926112d0c1cb6dbfd7/untitled314.ipynb)..  Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36917\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36917\">No</a>\n"]}, {"number": 36916, "title": "ValueError: Unable to save the object ListWrapper(...) (a list wrapper constructed to track trackable TensorFlow objects) when calling the method tf.keras.Model.save_weights", "body": "**System information** \r\n- Have I written custom code:  yes\r\n- OS Platform and Distribution: macOS Catalina Version 10.15.3 \r\n- TensorFlow installed from: binary (using pip in conda)\r\n- TensorFlow version (use command below): v2.1.0-rc2-17-ge5bf8de410 2.1.0\r\n- Python version: Python 3.6.10 :: Anaconda, Inc.\r\n\r\nNote: probably related to this closed issue https://github.com/tensorflow/tensorflow/issues/35075\r\n\r\n**Describe the current behavior**\r\nWhile saving a model `tf.keras.Model` with the function `save_weights`, the program raises the following error (full trace in the log section):\r\n\r\n> ValueError: Unable to save the object ListWrapper([ListWrapper([<tf.Variable 'model_32/dense_4/kernel:0' ...)>,  ...]), ListWrapper([<tf.Variable 'model_32/dense_6/kernel:0' ...)>, ...])]) (a list wrapper constructed to track trackable TensorFlow objects). A list element was replaced (\\_\\_setitem__, \\_\\_setslice__), deleted (\\_\\_delitem__, \\_\\_delslice__), or moved (sort). In order to support restoration on object creation, tracking is exclusively for append-only data structures.\r\n>\r\n>If you don't need this list checkpointed, wrap it in a tf.contrib.checkpoint.NoDependency object; it will be automatically un-wrapped and subsequently ignored.\r\n\r\nNote that the model can be saved before updating the model's variables and the update works as expected. However once updated, if I try to save the model, it will crash.\r\n\r\n**Describe the expected behavior**\r\n\r\n1. The model should be saved without raising error\r\n2. There shouldn't be any reference to `tf.contrib.checkpoint.NoDependency` as contrib is not available in TF2.\r\n\r\n**Standalone code to reproduce the issue** \r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\nclass Model(tf.keras.Model):\r\n    \r\n    @property\r\n    def groupedVariables(self):\r\n        if self._var is None:\r\n            self._var = []\r\n            for denses in self._denses:\r\n                self._var.append([])\r\n                for d in denses:\r\n                    self._var[-1] = self._var[-1] + d.trainable_variables                    \r\n        return self._var\r\n    ## ------------------------------------------------------------------------\r\n    def __init__(self, ** kwargs):\r\n        super(Model, self).__init__(** kwargs)\r\n\r\n        self._optimizers = []\r\n        self._denses     = []\r\n        self._var        = None\r\n        for copy in range(2):\r\n            self._optimizers.append(tf.keras.optimizers.Adam())\r\n            self._denses    .append([ tf.keras.layers.Dense(s) for s in [2,1]])\r\n    ## ------------------------------------------------------------------------\r\n    def call(self, x):\r\n        y = []    \r\n        for denses in self._denses:\r\n            yy = x\r\n            for d in denses: yy = d(yy)\r\n            y.append(yy) \r\n        return y\r\n    ## ------------------------------------------------------------------------\r\n    def update(self, x, t):\r\n        loss = []\r\n        with tf.GradientTape() as tape:\r\n            yy   = self(x)\r\n            for y in zip(yy):\r\n                y = y[0]\r\n                l = tf.reduce_mean((t - y) ** 2)\r\n                loss.append(l)\r\n\r\n        var  = self.groupedVariables\r\n        grad = tape.gradient(loss, var) \r\n        for g,v,o in zip(grad, var, self._optimizers):\r\n            o.apply_gradients(zip(g,v))\r\n## ----------------------------------------------------------------------------\r\nm = Model()        \r\nx = tf.zeros(shape = [1, 2], dtype = tf.float32)\r\n\r\nprint(\"Simple run then save ... \", end = \"\")\r\nm(x)\r\nm.save_weights(\"TMP/model\") ## <== This works\r\nprint(\"done\")\r\n\r\nprint(\"Update then save ....... \", end = \"\")\r\nm.update(x, 0)\r\nm.save_weights(\"TMP/model\") ## <== This craches\r\nprint(\"done\")\r\n```\r\n\r\n**Other info / logs**\r\n```\r\nThe full error trace\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-62-6d7f6f1860e7> in <module>\r\n     60 print(\"Update then save ....... \", end = \"\")\r\n     61 m.update(x, 0)\r\n---> 62 m.save_weights(\"TMP/model\") ## <== This craches\r\n     63 print(\"done\")\r\n\r\n~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/network.py in save_weights(self, filepath, overwrite, save_format)\r\n   1121              'saved.\\n\\nConsider using a TensorFlow optimizer from `tf.train`.')\r\n   1122             % (optimizer,))\r\n-> 1123       self._trackable_saver.save(filepath, session=session)\r\n   1124       # Record this checkpoint so it's visible from tf.train.latest_checkpoint.\r\n   1125       checkpoint_management.update_checkpoint_state_internal(\r\n\r\n~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/tracking/util.py in save(self, file_prefix, checkpoint_number, session)\r\n   1166     file_io.recursive_create_dir(os.path.dirname(file_prefix))\r\n   1167     save_path, new_feed_additions = self._save_cached_when_graph_building(\r\n-> 1168         file_prefix=file_prefix_tensor, object_graph_tensor=object_graph_tensor)\r\n   1169     if new_feed_additions:\r\n   1170       feed_dict.update(new_feed_additions)\r\n\r\n~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/tracking/util.py in _save_cached_when_graph_building(self, file_prefix, object_graph_tensor)\r\n   1106     (named_saveable_objects, graph_proto,\r\n   1107      feed_additions) = self._gather_saveables(\r\n-> 1108          object_graph_tensor=object_graph_tensor)\r\n   1109     if (self._last_save_object_graph != graph_proto\r\n   1110         # When executing eagerly, we need to re-create SaveableObjects each time\r\n\r\n~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/tracking/util.py in _gather_saveables(self, object_graph_tensor)\r\n   1074     \"\"\"Wraps _serialize_object_graph to include the object graph proto.\"\"\"\r\n   1075     (named_saveable_objects, graph_proto,\r\n-> 1076      feed_additions) = self._graph_view.serialize_object_graph()\r\n   1077     if object_graph_tensor is None:\r\n   1078       with ops.device(\"/cpu:0\"):\r\n\r\n~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/tracking/graph_view.py in serialize_object_graph(self)\r\n    377       ValueError: If there are invalid characters in an optimizer's slot names.\r\n    378     \"\"\"\r\n--> 379     trackable_objects, path_to_root = self._breadth_first_traversal()\r\n    380     return self._serialize_gathered_objects(\r\n    381         trackable_objects, path_to_root)\r\n\r\n~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/tracking/graph_view.py in _breadth_first_traversal(self)\r\n    197             % (current_trackable,))\r\n    198       bfs_sorted.append(current_trackable)\r\n--> 199       for name, dependency in self.list_dependencies(current_trackable):\r\n    200         if dependency not in path_to_root:\r\n    201           path_to_root[dependency] = (\r\n\r\n~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/tracking/graph_view.py in list_dependencies(self, obj)\r\n    157     # pylint: disable=protected-access\r\n    158     obj._maybe_initialize_trackable()\r\n--> 159     return obj._checkpoint_dependencies\r\n    160     # pylint: enable=protected-access\r\n    161 \r\n\r\n~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/tracking/data_structures.py in _checkpoint_dependencies(self)\r\n    507            \"\\n\\nIf you don't need this list checkpointed, wrap it in a \"\r\n    508            \"tf.contrib.checkpoint.NoDependency object; it will be \"\r\n--> 509            \"automatically un-wrapped and subsequently ignored.\" % (self,)))\r\n    510     if self._external_modification:\r\n    511       raise ValueError(\r\n\r\nValueError: Unable to save the object ListWrapper([ListWrapper([<tf.Variable 'model_34/dense_12/kernel:0' shape=(2, 2) dtype=float32, numpy=\r\narray([[ 0.4429444,  1.1044892],\r\n       [ 0.515365 , -1.0957527]], dtype=float32)>, <tf.Variable 'model_34/dense_12/bias:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>, <tf.Variable 'model_34/dense_13/kernel:0' shape=(2, 1) dtype=float32, numpy=\r\narray([[0.5423187 ],\r\n       [0.27255356]], dtype=float32)>, <tf.Variable 'model_34/dense_13/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>]), ListWrapper([<tf.Variable 'model_34/dense_14/kernel:0' shape=(2, 2) dtype=float32, numpy=\r\narray([[-0.85178864,  1.0104183 ],\r\n       [ 1.1649271 ,  1.1087018 ]], dtype=float32)>, <tf.Variable 'model_34/dense_14/bias:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>, <tf.Variable 'model_34/dense_15/kernel:0' shape=(2, 1) dtype=float32, numpy=\r\narray([[-0.2449851 ],\r\n       [ 0.84787834]], dtype=float32)>, <tf.Variable 'model_34/dense_15/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>])]) (a list wrapper constructed to track trackable TensorFlow objects). A list element was replaced (__setitem__, __setslice__), deleted (__delitem__, __delslice__), or moved (sort). In order to support restoration on object creation, tracking is exclusively for append-only data structures.\r\n\r\nIf you don't need this list checkpointed, wrap it in a tf.contrib.checkpoint.NoDependency object; it will be automatically un-wrapped and subsequently ignored.\r\n```", "comments": ["**Update**\r\n\r\nApparently, it comes from the member `self._var` that is initialized in the `update` function. If I change the property `groupedVariables` to have it to recompute the list every time, it seems to solve the issue. I still think it is a bug as initializing a member as `self._var` shouldn't, in my opinion, affect the behaviour of the `save_weights` function.", "I have tried on colab with TF version 2.1.0 , 2.2.0-dev20200218 and was able to reproduce the issue.Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/157e5efbaf9f0c985083bb3a0d8f3df5/untitled654.ipynb). Thanks!", "I have the same wrong error... I save the model with 'h5' no problem but save with 'tf' will cause this problem", "Hi,\r\n\r\nI have been encountering the same issue, and found out by reading the [source code](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/tracking/data_structures.py) for tracking data structures that the issue arises from `Layer` subclasses' `list` attributes being automatically converted to `ListWrapper` at attribute setting time.\r\n\r\nThe solution, as documented per the source code, is to wrap non-trackable list attributes with the `NonDependency` class (which effectively results in an actual Python list being assigned as attribute instead of a `ListWrapper` object). That being said, this class is not part of the public TensorFlow API, so that using it requires importing from `tensorflow.python`, which is not something users are supposed to do (since this is not considered an open, stable API).\r\n\r\nAnother ugly solution is to force the assignment of a list attribute directly in the instance's `__dict__`, instead of passing through its `__setattr__` dunder method (which is where the conversion to a trackable `ListWrapper` happens). _I.e._ an alternative to doing `self.my_list = NoDependency([])` is `self.__dict__['my_list'] = []`, but this feels like the kind of hack we should not want to promote.\r\n\r\nI hope someone in the tensorflow team can either come up with a better solution than those above, or evaluate the pertinence of making (part of) the tracking data structures part of the public API, so that this issue may be solved.", "I have the same problem too. When I use ` tf.keras.models.save_model(model, filepath, save_format='tf')`  to save a model, it shows an error :\r\n `ValueError: Unable to save the object ListWrapper([]) (a list wrapper constructed to track trackable TensorFlow objects). A list element was replaced (__setitem__, __setslice__), deleted (__delitem__, __delslice__), or moved (sort). In order to support restoration on object creation, tracking is exclusively for append-only data structures.`\r\n`If you don't need this list checkpointed, wrap it in a tf.contrib.checkpoint.NoDependency object; it will be automatically un-wrapped and subsequently ignored.`\r\n\r\nWhen I use ` tf.keras.models.save_model(model, filepath, save_format='h5')`,  it shows : \r\n`NotImplementedError: Saving the model to HDF5 format requires the model to be a Functional model or a Sequential model. It does not work for subclassed models, because such models are defined via the body of a Python method, which isn't safely serializable. Consider saving to the Tensorflow SavedModel format (by setting save_format=\"tf\") or using \"save_weights\".`\r\n\r\nIs there any way to save my trained model?\r\n", "@pandrey-fr \r\nHi, how to solve it ? can you show some example code??", "@taki0112 \r\nAs mentioned in my former reply, if you assign a list as attribute of a `tf.keras.layers.Layer`-inheriting instance, it will automatically be wrapped through a `ListWrapper` object, which as you notices causes some issues when said list does not comprise keras components. Note that when you want to store your model's layers in a list attribute you _do_ want it to be wrapped through this automatic behaviour!\r\n\r\nI found two distinct workarounds for assigning a list without having it converted:\r\n\r\n(1) Instead of assigning through dot syntax (`self.my_list = []`), directly manipulate the object's `__dict__`, so that the conversion code is not triggered; _i.e._ use `self.__dict__['my_list'] = []`.\r\n\r\n(2) Run `from tensorflow.python.training.tracking.data_structures import NonDependency`, then when assigning a list through dot syntax, wrap it with that wrapper first; _i.e._ use `self.my_list = NonDependency(my_list)`.\r\n\r\nNow, you should note that **both these work-arounds are problematic**.\r\n(1) has you access your object's `__dict__` directly, which in general is not something you want to do: it makes code harder to read, and it could have undesirable side effects, notably because you may be skipping desirable code from `__setattr__`.\r\n(2) has you import stuff from `tensorflow.python` which you should normally _never_ do, since it is not part of the API and may change without warnings, making your code much harder to maintain.\r\n\r\nThus, I would actually be looking forward for someone in the TensorFlow dev team to give an eye on this issue, and either come out with a better solution or some future updates that allow users to have a workable and safe workaround.", "I get the same problem while i try to write a configurable UNet through parameters.\r\nSo my up-sample is a list refer to the config file.\r\n\r\njust simply change list to dictionary like:\r\n\r\n`    \r\nself.rect_list = [\r\n      tf.keras.layers.Conv2D(\r\n        filters = self.feature_model.outputs[i].shape[-1],\r\n        kernel_size=(1, 1),\r\n        activation=tf.nn.relu,\r\n        name=\"{}_to_{}_1x1_conv\".format(i+1,i),\r\n      )\r\n      for i in range(f_layer_num-2,-1,-1)]\r\n`\r\nto\r\n`\r\n    rect_list = [\r\n      tf.keras.layers.Conv2D(\r\n        filters = self.feature_model.outputs[i].shape[-1],\r\n        kernel_size=(1, 1),\r\n        activation=tf.nn.relu,\r\n        name=\"{}_to_{}_1x1_conv\".format(i+1,i),\r\n      )\r\n      for i in range(f_layer_num-2,-1,-1)]\r\nfor i in range(len(rect_list)):\r\n    self.rect_dirt['some_calling_name_format_like_l{}'.format(i)] = rect_list[i]\r\n`\r\nand change calling like rect_list[i] to self.rect_dirt['some_calling_name_format_like_l{}'.format(i)]\r\nthen it can be save", "I had a similar problem with a subclassed `Model`.\r\n\r\nThe problem was that, as noted in the error, I was creating a list of layers and then replacing a layer in this list using list-assignment. Apparently it's not possible to do this if you want the list to be saved.", "Issue is replicating with TF 2.4.0-dev20200916 .Please, find the [gist here](https://colab.research.google.com/gist/Saduf2019/c30147a708ee25655ef55e928d264c6a/untitled415.ipynb).Thanks!", "@Nimoab @Saduf2019 You can not modify the `tf.keras.layers.Layer` list(`self._var`), only change to append the `Layer` list like the following pseudo-code:\r\n`self._var.append(self._var[-1] + d.trainable_variables)`", "@Nimoab \r\nPlease update as per above comment.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36916\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36916\">No</a>\n", "Still the same issue in TF 1.15. Any suggestions?", "> Still the same issue in TF 1.15. Any suggestions?\r\n\r\n @jingw222 look at my reply on this issue, ref: https://github.com/tensorflow/tensorflow/issues/36916#issuecomment-801702378", "Here is my experience, and I hope that the following workaround could be of help.\r\nAs for a custom model, at least model.saving_weights(...) and load_weights work for .h5 format. Version tf 2.1. But they work in the following way:\r\n1. Initialise the model and train it;\r\n2. save_weights(...);\r\n3. Quit Python environment (I use Spyder);\r\n4. Re-launch the environment;\r\n5. Re-initialise the model;\r\n6. Loda_weights(...);\r\nPlease note that I tried to re-initialise the model followed by loading the weights without quitting the environment, it did not work.  The error was\r\n`\r\n          File \"<ipython-input-5-4e4fb518c257>\", line 1, in <module>\r\n            EncModel.load_weights(encoderSaveString)\r\n        \r\n          File \"D:\\TProgramFiles\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 234, in load_weights\r\n            return super(Model, self).load_weights(filepath, by_name, skip_mismatch)\r\n        \r\n          File \"D:\\TProgramFiles\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\", line 1222, in load_weights\r\n            hdf5_format.load_weights_from_hdf5_group(f, self.layers)\r\n        \r\n          File \"D:\\TProgramFiles\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\saving\\hdf5_format.py\", line 677, in load_weights_from_hdf5_group\r\n            ' layers.')\r\n        \r\n        ValueError: You are trying to load a weight file containing 5 layers into a model with 6 layers.\r\n`"]}, {"number": 36915, "title": "tf.keras.applications.ResNet50 is not working", "body": "<em>I am working on transfer learning and used the ResNet50 model to predict 10 classes of my dataset. The losss went to 0.7 and acc=99% during training phase, but when i evaluate the model on test dataset, it gave me acc=10% and loss=2.275. The most panicking thing was that model was predicting only one class during test phase.  I tried every solution , even for over fitting but in vain. Then, i used ResNet50V2 model instead. This model is predicting every class now and acc=88% during test phase. </em>\r\n\r\n**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g.,\r\nLinux Ubuntu 16.04): Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if\r\nthe issue happens on mobile device:  No\r\n- TensorFlow installed from (source or\r\nbinary): - TensorFlow version (use command below):  Command version\r\n- Python version: - Bazel\r\nversion (if compiling from source):\r\n- GCC/Compiler version (if compiling from\r\nsource): \r\n- CUDA/cuDNN version: - GPU model and memory: 10.1 and cuDNN 7.6\r\n\r\n\r\n Please can you check the ResNet50 code as i think there is some problem in it as same code of mine is working with tf.keras.application.ResNet50V2?\r\n\r\nThank you", "comments": ["@irum,\r\nI tried transfer learning from [this](https://www.tensorflow.org/tutorials/images/transfer_learning) Tensorflow tutorial using ResNet50 and was able to run the code without any issues. Please find the Gist [here](https://colab.research.google.com/gist/amahendrakar/2c4720f92ec19824d324ef2434f6b250/36915.ipynb). Thanks!", "I have done the coding in the same way by using the above mentioned tutorial but the model was predicting only one class . I used tape.gradient loop to train the model . Then I used model.fit as well to train the model but for my dataset this resent model was not working at all.", "@irum,\r\nCould you please provide the complete code to reproduce the issue reported here. Thanks!", "`import tensorflow as tf\r\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\r\nfrom tensorflow.keras import optimizers,regularizers\r\nimport os\r\nfrom PIL import Image\r\nimport numpy as np\r\n\r\nDir = \"/media/irum/DATA/Dataset\"\r\nDir_test=\"/media/irum/DATA/Dataset\"\r\n\r\ncatogories = ['bottles', 'cans', 'chain', 'cloth', 'gloves', 'metal_objects', 'pipe_joints', 'plastic_pipes', 'sponges',\r\n              'wood']\r\n\r\nclass_names = catogories\r\n\r\n\r\ntrain_dir = os.path.join(Dir ,'train')\r\nvalidation_dir = os.path.join(Dir_test, 'test')\r\n\r\nbatch_size = 32\r\nepochs =50\r\nIMG_HEIGHT = 224\r\nIMG_WIDTH = 224\r\n\r\ntotal_train= 2000\r\ntotal_val=1494\r\n\r\ntrain_image_generator = ImageDataGenerator(rescale=1./255) # Generator for our training data\r\nvalidation_image_generator = ImageDataGenerator(rescale=1./255) # Generator for our validation data\r\n\r\ntrain_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\r\n                                                           directory=train_dir,\r\n                                                           shuffle=True,\r\n                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\r\n                                                           class_mode='categorical')\r\n\r\nval_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\r\n                                                              directory=validation_dir,\r\n                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\r\n                                                              class_mode='categorical')\r\n\r\nbase_model = tf.keras.applications.resnet50.ResNet50(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\r\n\r\nfeature_batch = base_model.output\r\n\r\n\r\nglobal_average_layer = tf.keras.layers.GlobalAveragePooling2D()\r\nfeature_batch_average = global_average_layer(feature_batch)\r\nfeature_batch_average=tf.keras.layers.Dropout(0.9)(feature_batch_average)\r\nprediction_layer = tf.keras.layers.Dense(10,activation='softmax', kernel_regularizer=regularizers.l2(0.01))\r\nprediction_batch = prediction_layer(feature_batch_average)\r\n\r\nmodel = tf.keras.Sequential([\r\n    base_model,\r\n    global_average_layer,\r\n    prediction_layer\r\n])\r\n\r\nbase_learning_rate = 0.0001\r\nmodel.compile(optimizer=tf.keras.optimizers.RMSprop(lr=base_learning_rate),\r\n              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\r\n              metrics=['accuracy'])\r\n\r\nhistory = model.fit_generator(\r\n    train_data_gen,\r\n    steps_per_epoch=total_train // batch_size,\r\n    epochs=epochs,\r\n    validation_data=val_data_gen,\r\n    validation_steps=total_val // batch_size\r\n)\r\n\r\n\r\nimg_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\r\nimages, labels = next(img_gen.flow_from_directory(validation_dir))\r\nimages=tf.image.resize(images,[224,224])\r\nlabels[0]\r\nprobability_model = tf.keras.Sequential([model,\r\n                                         tf.keras.layers.Softmax()])\r\npredictions = probability_model.predict(images)\r\nnp.argmax(predictions[1])\r\n\r\n\r\nimage_batch = images\r\nlabel_batch = labels\r\n\r\npredicted_batch = model.predict(image_batch)\r\npredicted_batch = tf.squeeze(predicted_batch).numpy()\r\n\r\npredicted_ids = np.argmax(predicted_batch, axis=-1)\r\npredicted_ids-np.array(predicted_ids)\r\nprint(predicted_ids)\r\nfor i in predicted_ids:\r\n    predicted_class_names = class_names[i]\r\n    print(\"{} ,\\t{}\".format(predicted_class_names, class_names[np.argmax(labels)])) `\r\n\r\n\r\nThe results after predictions are\r\n[0 1 9 1 0 5 6 6 4 6 5 7 8 8 3 3 7 5 8 0 5 5 1 4 3 7 0 3 8 2 8 4]\r\nbottles ,\tbottles\r\ncans ,\tbottles\r\nwood ,\tbottles\r\ncans ,\tbottles\r\nbottles ,\tbottles\r\nmetal_objects ,\tbottles\r\npipe_joints ,\tbottles\r\npipe_joints ,\tbottles\r\ngloves ,\tbottles\r\npipe_joints ,\tbottles\r\nmetal_objects ,\tbottles\r\nplastic_pipes ,\tbottles\r\nsponges ,\tbottles\r\nsponges ,\tbottles\r\ncloth ,\tbottles\r\ncloth ,\tbottles\r\nplastic_pipes ,\tbottles\r\nmetal_objects ,\tbottles\r\nsponges ,\tbottles\r\nbottles ,\tbottles\r\nmetal_objects ,\tbottles\r\nmetal_objects ,\tbottles\r\ncans ,\tbottles\r\ngloves ,\tbottles\r\ncloth ,\tbottles\r\nplastic_pipes ,\tbottles\r\nbottles ,\tbottles\r\ncloth ,\tbottles\r\nsponges ,\tbottles\r\nchain ,\tbottles\r\nsponges ,\tbottles\r\ngloves ,\tbottles\r\n\r\nAs you can see all predictions are equal to bottles only . \r\nP.S I had added before dropout layers and regularization layers but the results were same, So no overfitting problem fits here.", "Was able to reproduce the issue with sample dataset. Please find the Gist [here](https://colab.sandbox.google.com/gist/amahendrakar/b643887f3e32ecb0267dfe4da6e2f4c3/36915.ipynb). Thanks!", "Thank you! I may have encountered a similar problem and succeeded after I changed basenet.\r\nWhen I am using mobilenetv2, everything is normal during training, but the embed is all the same during validation, and the predict is also the same (all use the same samples)", "@liuxingbaoyu   \r\nNo worries. I am happy that this post was helpful .I already explained to tensorflow team that the base models have some ii sues.", "This may be related to BatchNormalization.\r\nI use the model without any BatchNormalization and it will be very good.", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\nThanks!\r\n\r\n", "@ymodak Maybe related to [this](https://github.com/tensorflow/tensorflow/issues/36700)", "@irum  try this [solution ](https://github.com/tensorflow/tensorflow/issues/36366#issuecomment-601985968) as BatchNorm might be the issue here", "@raghavab1992 \r\nThank you Raghav. It is  working in this way.", "it is working but training is very slow in this way. After 500 epochs , i am getting 64% accuracy on training dataset. ", "@ymodak , please can you use any other custom dataset for Resnet50. It may work well for cats and dogs dataset. ", "@raghavab1992 Thank you!!! I've been struggling with this for days and thought my data was corrupted or the head I was putting was existentially wrong. The solution you mentioned worked for me!"]}, {"number": 36914, "title": "Models with tf.lite.Optimize cause abort() when interpreter->Invoke()", "body": "@tensorflow/micro\r\n\r\n**System information**\r\n- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS Catalina 10.15.2\r\n- TensorFlow installed from (source or binary): Installed with pip `pip install --upgrade tensorflow`\r\n- Tensorflow version (commit SHA if source): Version 2.1.0 and TFLITE_SCHEMA_VERSION (3)\r\n- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): ESP32\r\n\r\n**Describe the problem**\r\n\r\nWhen using a Tensorflow Lite converted model with `tf.lite.Optimize` the ESP32 will reboot (abort()) if `interpreter->Invoke()` is called for inference. \r\n\r\nHowever if we convert the exact same model without using `tf.lite.Optimize` the inference will run just fine.\r\n\r\n**Please provide the exact sequence of commands/steps when you ran into the problem**\r\n\r\nTraining and converting a model:\r\n\r\n```python\r\n#Converting a simple model.\r\nmodel = Sequential()\r\nmodel.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(10,6)))\r\nmodel.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\r\nmodel.add(Dropout(0.5))\r\nmodel.add(MaxPooling1D(pool_size=2))\r\nmodel.add(Flatten())\r\nmodel.add(Dense(100, activation='relu'))\r\nmodel.add(Dense(y_train.shape[1], activation='softmax'))\r\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\r\nmodel.fit(X_train, y_train, epochs=5, batch_size=32, verbose=2)\r\n\r\nconverter = lite.TFLiteConverter.from_keras_model(model)\r\n\r\n#The problem is caused by the following line\r\nconverter.optimizations = [lite.Optimize.DEFAULT]\r\n\r\ntfmodel = converter.convert()\r\nopen(PATH+'/model.tflite',\"wb\").write(tfmodel)\r\n```\r\n\r\nConverting to C array:\r\n`xxd -i converted_model.tflite > model_data.cc`\r\n\r\nIn ESP32:\r\n\r\n```c\r\n//abort() when:\r\nif(interpreter->Invoke() != kTfLiteOk) {\r\n        Serial.println(\"There was an error invoking the interpreter!\");\r\n        return;\r\n        }\r\n```\r\n\r\nThe inference will run just fine if we convert the same model without `converter.optimizations = [lite.Optimize.DEFAULT]`\r\n\r\nI tried 'DEFAULT', 'OPTIMIZE_FOR_SIZE', and 'OPTIMIZE_FOR_LATENCY' same problem every time.\r\nI also tried using `converter.experimental_new_converter = True` but it did not work.\r\n\r\nHere is the trace from the ESP32:\r\n```\r\nabort() was called at PC 0x400ddd39 on core 1\r\n\r\nBacktrace: 0x4008c49c:0x3ffb1e00 0x4008c6cd:0x3ffb1e20 0x400ddd39:0x3ffb1e40 0x400de09d:0x3ffb1e90 0x400e60ca:0x3ffb1f70 0x400d2a0d:0x3ffb1f90 0x400edf0d:0x3ffb1fb0 0x40088bd9:0x3ffb1fd0\r\n\r\nRebooting...\r\nets Jun  8 2016 00:22:57\r\n\r\nrst:0xc (SW_CPU_RESET),boot:0x13 (SPI_FAST_FLASH_BOOT)\r\nconfigsip: 0, SPIWP:0xee\r\nclk_drv:0x00,q_drv:0x00,d_drv:0x00,cs0_drv:0x00,hd_drv:0x00,wp_drv:0x00\r\nmode:DIO, clock div:1\r\nload:0x3fff0018,len:4\r\nload:0x3fff001c,len:1216\r\nho 0 tail 12 room 4\r\nload:0x40078000,len:9720\r\nho 0 tail 12 room 4\r\nload:0x40080400,len:6352\r\nentry 0x400806b8\r\n```\r\nEdit: Adding decoded stack result\r\n\r\n```\r\nDecoding stack results\r\n0x4008c49c: invoke_abort at /home/runner/work/esp32-arduino-lib-builder/esp32-arduino-lib-builder/esp-idf/components/esp32/panic.c line 155\r\n0x4008c6cd: abort at /home/runner/work/esp32-arduino-lib-builder/esp32-arduino-lib-builder/esp-idf/components/esp32/panic.c line 170\r\n\r\n# Error comes from here:\r\n0x400ddd39: tflite::reference_integer_ops::FullyConnected(tflite::FullyConnectedParams const&, tflite::RuntimeShape const&, signed char const*, tflite::RuntimeShape const&, signed char const*, tflite::RuntimeShape const&, int const*, tflite::RuntimeShape const&, signed char*) at lib/tfmicro/tensorflow/lite/kernels/internal/reference/integer_ops/fully_connected.h line 35\r\n0x400de09d: tflite::ops::micro::fully_connected::Eval(TfLiteContext*, TfLiteNode*) at lib/tfmicro/tensorflow/lite/micro/kernels/fully_connected.cc line 102\r\n0x400e60ca: tflite::MicroInterpreter::Invoke() at lib/tfmicro/tensorflow/lite/micro/micro_interpreter.cc line 190\r\n\r\n0x400d2a0d: loop() at /Users/vdouet/Deep Learning/HAR_ESP32_Tensorflow/Firmware/src/main.ino line 560\r\n0x400edf0d: loopTask(void*) at /Users/vdouet/.platformio/packages/framework-arduinoespressif32/cores/esp32/main.cpp line 17\r\n0x40088bd9: vPortTaskWrapper at /home/runner/work/esp32-arduino-lib-builder/esp32-arduino-lib-builder/esp-idf/components/freertos/port.c line 143\r\n```\r\n\r\nI tried using different models with different input shapes, even the same one from `examples/magic_wand` but every time the ESP32 will abort() when it reaches `interpreter->Invoke()`.\r\n\r\nEdit for completeness:\r\n\r\nThe optimized converted models work absolutely fine using Tensorflow Lite with Python3:\r\n```python\r\ninterpreter = tf.lite.Interpreter(model_path=PATH+\"/model.tflite\")\r\ninterpreter.allocate_tensors()\r\n\r\ninput_details = interpreter.get_input_details()\r\noutput_details = interpreter.get_output_details()\r\n\r\ninput_shape = input_details[0]['shape']\r\ninput_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\r\n\r\ninterpreter.set_tensor(input_details[0]['index'], input_data)\r\ninterpreter.invoke()\r\n```\r\n\r\nBest regards,\r\nVictor", "comments": ["After cloning the newest version of the Tensorflow repository I got the same error but with a new information before abort():\r\n`assertion \"exponent <= 31\" failed: file \"lib/tfmicro/fixedpoint/fixedpoint.h\", line 359, function: IntegerType gemmlowp::RoundingDivideByPOT(IntegerType, int) [with IntegerType = int]`\r\n\r\nESP32 trace:\r\n```Decoding stack results\r\n0x4008cc88: invoke_abort at /home/runner/work/esp32-arduino-lib-builder/esp32-arduino-lib-builder/esp-idf/components/esp32/panic.c line 155\r\n0x4008ceb9: abort at /home/runner/work/esp32-arduino-lib-builder/esp32-arduino-lib-builder/esp-idf/components/esp32/panic.c line 170\r\n0x40128297: scalbn at ../../../.././newlib/libm/common/s_scalbn.c line 101\r\n0x400de2c2: tflite::reference_ops::Conv(tflite::ConvParams const&, tflite::RuntimeShape const&, float const*, tflite::RuntimeShape const&, float const*, tflite::RuntimeShape const&, float const*, tflite::RuntimeShape const&, float*, tflite::RuntimeShape const&, float*) at lib/tfmicro/tensorflow/lite/kernels/internal/reference/conv.h line 52\r\n0x400e0acd: tflite::ops::micro::fully_connected::Eval(TfLiteContext*, TfLiteNode*) at lib/tfmicro/tensorflow/lite/micro/kernels/fully_connected.cc line 64\r\n0x400e0da1: tflite::ops::micro::fully_connected::Eval(TfLiteContext*, TfLiteNode*) at lib/tfmicro/tensorflow/lite/micro/kernels/fully_connected.cc line 136\r\n0x400e8d07: tflite::MicroInterpreter::Invoke() at lib/tfmicro/tensorflow/lite/micro/micro_interpreter.cc line 186\r\n0x400d4282: loop() at /Users/TotoryDort/Lassena/Projects/IDEaS/IbNav/Deep Learning/HAR_ESP32_Tensorflow/Firmware/src/main.ino line 229\r\n0x400f23c5: uartDetectBaudrate at /Users/TotoryDort/.platformio/packages/framework-arduinoespressif32/cores/esp32/esp32-hal-uart.c line 563\r\n0x4008939d: vPortTaskWrapper at /home/runner/work/esp32-arduino-lib-builder/esp32-arduino-lib-builder/esp-idf/components/freertos/port.c line 143\r\n```\r\n\r\nThis seems to be related to the issue #36943 \r\n\r\nEdit: \r\nI'm trying to use a representative dataset as mentionned here: https://github.com/tensorflow/tensorflow/issues/36943#issuecomment-589887984\r\nBut with this my ESP32 gives me another error when I use 'AllOpsResolver':\r\n\r\n```\r\nDidn't find op for builtin opcode 'MAX_POOL_2D' version '2'\r\n\r\nFailed to get registration from op code  d\r\n\r\nAllocateTensors() failed\r\nGuru Meditation Error: Core  1 panic'ed (LoadProhibited). Exception was unhandled.\r\n```\r\nI don't know if it matter but I only use a MaxPooling1D in my model.\r\n\r\nHowever if I use 'MicroOpResolver' like this:\r\n```python\r\ntflite::MicroOpResolver<6> micro_op_resolver;\r\n    micro_op_resolver.AddBuiltin(tflite::BuiltinOperator_FULLY_CONNECTED,\r\n                              tflite::ops::micro::Register_FULLY_CONNECTED(), 1, 4);\r\n    micro_op_resolver.AddBuiltin(tflite::BuiltinOperator_SOFTMAX,\r\n                              tflite::ops::micro::Register_SOFTMAX());\r\n    micro_op_resolver.AddBuiltin(tflite::BuiltinOperator_RELU,\r\n                              tflite::ops::micro::Register_RELU());\r\n    micro_op_resolver.AddBuiltin(tflite::BuiltinOperator_QUANTIZE,\r\n                              tflite::ops::micro::Register_QUANTIZE());\r\n    micro_op_resolver.AddBuiltin(tflite::BuiltinOperator_RESHAPE,\r\n                              tflite::ops::micro::Register_RESHAPE());\r\n    micro_op_resolver.AddBuiltin(tflite::BuiltinOperator_CONV_2D,\r\n                              tflite::ops::micro::Register_CONV_2D(), 1, 3);\r\n````\r\nI get the following error:\r\n```\r\nDidn't find op for builtin opcode 'QUANTIZE' version '1'\r\n\r\nFailed to get registration from op code  d\r\n\r\nAllocateTensors() failed\r\n```\r\n\r\nI tried with the latest version of Tensorflow and tf-nightly and it did not make a difference.", "We're looking into this and will let you know once we have an update!", "I did some more testing and successfully made the inference work by removing the `MaxPooling1D` layer in my model and by using  `AllOpsResolver`.\r\n\r\nPreviously when I was using a `MaxPooling1D` layer with `AllOpsResolver` I got the error message:\r\n```\r\nDidn't find op for builtin opcode 'MAX_POOL_2D' version '2'\r\nFailed to get registration from op code  d\r\n``` \r\n\r\nThe model I am using:\r\n```python\r\nmodel = Sequential()\r\n        model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(n_timestep,6)))\r\n        model.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\r\n        model.add(Dropout(0.5))\r\n        #model.add(MaxPooling1D(pool_size=2))\r\n        model.add(Flatten())\r\n        model.add(Dense(100, activation='relu'))\r\n        model.add(Dense(3, activation='softmax'))\r\n        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n```\r\n\r\nThe converter:\r\n```python\r\nconverter = lite.TFLiteConverter.from_keras_model(model)\r\n    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]#, tf.lite.OpsSet.SELECT_TF_OPS]\r\n    converter.optimizations = [lite.Optimize.DEFAULT]\r\n    converter.experimental_new_converter = True\r\n    converter.representative_dataset = representative_dataset_gen\r\n    tfmodel = converter.convert()\r\n    open(PATH+'/model.tflite',\"wb\").write(tfmodel)\r\n```", "Hi, the same happens with my setup with Arduino ESP32, TensorFlowLite library v2.1.0-ALPHA, and generating the tflite model in colab with TF version 2.1.0\r\nWhen i convert to TFLite with optimization = tf.lite.Optimize.OPTIMIZE_FOR_SIZE, the ESP32 crashes at inference (see [trace](https://github.com/tensorflow/tensorflow/issues/37088#issuecomment-593812080)). Without optimizer, it works perfectly. The model.tflite is 260KB. With optimizer it is 258KB so seems not worth it.\r\nI'm using the Fashion MNIST dataset with 28x28 images, and my model is as follows:\r\n```\r\nmodel = tf.keras.Sequential([\r\n  tf.keras.layers.Conv2D(16, 3, activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)),\r\n  tf.keras.layers.MaxPooling2D(),\r\n  tf.keras.layers.Conv2D(16, 3, activation='relu'),\r\n  tf.keras.layers.Flatten(),\r\n  tf.keras.layers.Dense(32, activation='relu'),\r\n  tf.keras.layers.Dense(10, activation='softmax')\r\n])\r\n```", "@tomtobback Can you try optimizing your model again using the [updated hello_world example](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/examples/hello_world/train/train_hello_world_model.ipynb) and let us know if you face this issue.\r\n\r\nWe recommend testing with `tf.float32` input and output type as given in the example and then update it to `tf.int8` as given in [this code snippet](https://www.tensorflow.org/lite/performance/post_training_quantization#integer_only). For int8/uint8 input/output type, you need TF Version >= 2.3\r\n\r\n\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36914\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36914\">No</a>\n", "> I did some more testing and successfully made the inference work by removing the `MaxPooling1D` layer in my model and by using `AllOpsResolver`.\r\n> \r\n> Previously when I was using a `MaxPooling1D` layer with `AllOpsResolver` I got the error message:\r\n> \r\n> ```\r\n> Didn't find op for builtin opcode 'MAX_POOL_2D' version '2'\r\n> Failed to get registration from op code  d\r\n> ```\r\n> \r\n> The model I am using:\r\n> \r\n> ```python\r\n> model = Sequential()\r\n>         model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(n_timestep,6)))\r\n>         model.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\r\n>         model.add(Dropout(0.5))\r\n>         #model.add(MaxPooling1D(pool_size=2))\r\n>         model.add(Flatten())\r\n>         model.add(Dense(100, activation='relu'))\r\n>         model.add(Dense(3, activation='softmax'))\r\n>         model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n> ```\r\n> \r\n> The converter:\r\n> \r\n> ```python\r\n> converter = lite.TFLiteConverter.from_keras_model(model)\r\n>     converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]#, tf.lite.OpsSet.SELECT_TF_OPS]\r\n>     converter.optimizations = [lite.Optimize.DEFAULT]\r\n>     converter.experimental_new_converter = True\r\n>     converter.representative_dataset = representative_dataset_gen\r\n>     tfmodel = converter.convert()\r\n>     open(PATH+'/model.tflite',\"wb\").write(tfmodel)\r\n> ```\r\n\r\nthanks for your share. help me a lot."]}, {"number": 36913, "title": "Fix Bazel not building anymore with the commit 09fe958f", "body": "Bazel is not building anymore with a change just introduced in master.\r\n\r\nhttps://github.com/tensorflow/tensorflow/commit/09fe958feebec0405ccac225c94fc130304fc2f4#diff-f55b2f358053ad76fb5ac3f776f78ef8R322-R325\r\n\r\n#### .bazelrc\r\n```\r\n# Flag to enable remote config\r\ncommon --experimental_repo_remote_exec\r\n```\r\n\r\nUpdating _TF_MIN_BAZEL_VERSION to 2.0.0 should do the trick, otherwise the commit above should be rollback\r\n\r\n### Error with Bazel 1.2.1:\r\n```shell\r\nNFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=207\r\nINFO: Reading rc options for 'version' from /opt/tensorflow/tensorflow-source/.bazelrc:\r\n  Inherited 'common' options: --experimental_repo_remote_exec\r\nERROR: Unrecognized option: --experimental_repo_remote_exec\r\nWARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command \"bazel shutdown\".\r\n```", "comments": ["@gunan WDYT?", "bmzhao@ has more context about this than me.\r\nI will trigger the kokoro tests to see if our CI is ready for this.", "According to the commit https://github.com/bazelbuild/bazel/commit/755e29dfb21d7abfc2bab8dc30813fd5e340d930, the experimental_repo_remote_exec flag was only introduced in bazel 2.0.0, meaning any older bazel versions will error out when they see the flag. \r\n\r\nSince this change bumps the minimal bazel version to 2.0.0, this change LGTM!"]}, {"number": 36912, "title": "lower accuracy when model.compile() inside strategy.scope() (TPU)", "body": "**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g.,\r\nLinux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if\r\nthe issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or\r\nbinary): - TensorFlow version (use command below): TF 2.1.0\r\n- Python version: - Bazel\r\nversion (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from\r\nsource): N/A\r\n- CUDA/cuDNN version: - GPU model and memory: N/A\r\n\r\n**Describe the current behavior**\r\n\r\nI am running model training in a GCP VM by using TPU v3-8.\r\n\r\nWhen compiling a model outside `strategy.scope()`, during training, the validation 'sparse_categorical_accuracy' is always about 2 ~ 3 % higher than compiling the model inside `strategy.scope()`.\r\n\r\nThe log provided below is for sequential models (created along with some pre-trained image classification models). However, I also tried to use subclassed model of `tf.keras.models.Model `.\r\nThis time, compiling inside / outside `strategy.scope()` gives almost the same results, which is equivalent to sequential models with compiling inside `strategy.scope()` --> That means, a lower accuracy than sequential models with compiling outside `strategy.scope()`.\r\n\r\nFor subclassed model, I also tried to use custom distributed training loop, which also gives the lower accuracy.\r\n\r\nI can provide the logs for using `subclassed class`, if you think it's helpful. (I need to re-run the test for this part.)\r\n\r\n**Describe the expected behavior**\r\n\r\nI expect both compiling inside or outside `strategy.scope()` having the same performance.\r\n\r\n**Standalone code to reproduce the issue** \r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n(If necessary, I can provide the whole script. It's some python code for the Kaggle competition [https://www.kaggle.com/c/flower-classification-with-tpus](https://www.kaggle.com/c/flower-classification-with-tpus).\r\n\r\nFor compiling outside `strategy.scope()`\r\n\r\n    from tensorflow.keras.applications import Xception\r\n    from tensorflow.keras.applications import DenseNet201\r\n    from tensorflow.keras.applications import ResNet152V2\r\n\r\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=TPU_WORKER, zone=ZONE, project=PROJECT)  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\r\n    print('Running on TPU ', tpu.master())\r\n\r\n    tf.config.experimental_connect_to_cluster(tpu)\r\n    tf.tpu.experimental.initialize_tpu_system(tpu)\r\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\r\n\r\n    backend_model_name = \"ResNet152V2\"\r\n\r\n    with strategy.scope():\r\n\r\n        flower_classifier = tf.keras.Sequential(\r\n            [\r\n                backend_model(weights='imagenet', include_top=False ,input_shape=(*IMAGE_SIZE, 3)),\r\n                tf.keras.layers.GlobalAveragePooling2D(),\r\n                tf.keras.layers.Dense(len(CLASSES), activation='softmax', name='prob_dist')\r\n            ]\r\n        )\r\n\r\n    flower_classifier.compile(\r\n        optimizer=tf.keras.optimizers.Adam(lr=0.00001),\r\n        loss = 'sparse_categorical_crossentropy',\r\n        metrics=['sparse_categorical_accuracy']\r\n    )\r\n\r\n    history = flower_classifier.fit(\r\n        get_training_dataset(),\r\n        steps_per_epoch=STEPS_PER_EPOCH,\r\n        epochs=epochs,\r\n        validation_data=get_validation_dataset(ordered=True),\r\n        validation_steps=eval_steps\r\n    )\r\n\r\nFor compiling inside `strategy.scope()`\r\n\r\n    with strategy.scope():\r\n\r\n        flower_classifier = tf.keras.Sequential(\r\n            [\r\n                backend_model(weights='imagenet', include_top=False ,input_shape=(*IMAGE_SIZE, 3)),\r\n                tf.keras.layers.GlobalAveragePooling2D(),\r\n                tf.keras.layers.Dense(len(CLASSES), activation='softmax', name='prob_dist')\r\n            ]\r\n        )\r\n\r\n        flower_classifier.compile(\r\n            optimizer=tf.keras.optimizers.Adam(lr=0.00001),\r\n            loss = 'sparse_categorical_crossentropy',\r\n            metrics=['sparse_categorical_accuracy']\r\n        )\r\n\r\nFor subclassed model, it's like\r\n\r\nclass Flower_Classifier(tf.keras.models.Model):\r\n\r\n    def __init__(self, backend_model):\r\n\r\n        super(Flower_Classifier, self).__init__()\r\n\r\n        self.image_embedding_layer = backend_model(weights='imagenet', include_top=False ,input_shape=(*IMAGE_SIZE, 3))\r\n        self.pooling_layer = tf.keras.layers.GlobalAveragePooling2D()\r\n        self.prob_dist_layer = tf.keras.layers.Dense(len(CLASSES), activation='softmax', name='prob_dist')\r\n\r\n    def call(self, inputs, training=False):\r\n\r\n        embedding = self.image_embedding_layer(inputs, training=training)\r\n        pooling = self.pooling_layer(embedding)\r\n        prob_dist = self.prob_dist_layer(pooling)\r\n\r\n        return prob_dist\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\nI run test on 3 models (DenseNet201, Xception, ResNet152V2). Each is model run 3 times for both compiling inside/outside `strategy.scope()`.\r\nEach run is a training of 30 epochs. The following are the best 10 validation accuracy for each run.\r\n\r\n    DenseNet201:\r\n\r\n        compile inside strategy.scope():\r\n\r\n            run 1: val_acc = [0.9094828, 0.90921336, 0.90921336, 0.90894395, 0.90867454, 0.9081358, 0.9059806, 0.90113145, 0.90005386, 0.89897627]\r\n            run 2: val_acc = [0.90894395, 0.90894395, 0.90678877, 0.9040948, 0.9038254, 0.9038254, 0.9016703, 0.9016703, 0.9005927, 0.90005386]\r\n            run 3: val_acc = [0.907597, 0.9073276, 0.9070582, 0.90678877, 0.9065194, 0.904903, 0.9038254, 0.90328664, 0.90005386, 0.8981681]\r\n\r\n        compile outside strategy.scope():\r\n\r\n            run 1: val_acc = [0.9288793, 0.92672414, 0.92672414, 0.92672414, 0.92456895, 0.92456895, 0.92456895, 0.92456895, 0.92241377, 0.92241377]\r\n            run 2: val_acc = [0.92672414, 0.92456895, 0.92456895, 0.92456895, 0.92241377, 0.92241377, 0.92025864, 0.92025864, 0.91810346, 0.91810346]\r\n            run 3: val_acc = [0.93318963, 0.93318963, 0.9288793, 0.9288793, 0.92672414, 0.92672414, 0.92456895, 0.92241377, 0.92241377, 0.92025864]\r\n\r\n    ResNet152V2:\r\n\r\n        compile inside strategy.scope():\r\n\r\n            run 1: val_acc = [0.828125, 0.8270474, 0.8248922, 0.82435346, 0.82408404, 0.82408404, 0.82300645, 0.82300645, 0.8211207, 0.8200431]\r\n            run 2: val_acc = [0.8278556, 0.8273168, 0.8257004, 0.8235453, 0.82327586, 0.82327586, 0.82192886, 0.8213901, 0.8189655, 0.8184267]\r\n            run 3: val_acc = [0.828125, 0.8262392, 0.82543105, 0.82516164, 0.82462287, 0.8224677, 0.8221983, 0.81977373, 0.81869614, 0.8146552]\r\n\r\n        compile outside strategy.scope():\r\n\r\n            run 1: [0.85775864, 0.85775864, 0.8512931, 0.8491379, 0.8469828, 0.8448276, 0.8426724, 0.8405172, 0.8405172, 0.83836204]\r\n            run 2: [0.8448276, 0.8426724, 0.8405172, 0.83836204, 0.8362069, 0.8340517, 0.8340517, 0.8340517, 0.83189654, 0.8275862]\r\n            run 3: [0.86422414, 0.86206895, 0.86206895, 0.85991377, 0.85775864, 0.85560346, 0.85560346, 0.85560346, 0.85560346, 0.8534483]\r\n\r\n    Xception:\r\n\r\n        compile inside strategy.scope():\r\n\r\n            run 1: val_acc = [0.8445582, 0.8418642, 0.83943963, 0.83432114, 0.83162713, 0.83081895, 0.82327586, 0.81869614, 0.8125, 0.80630386]\r\n            run 2: val_acc = [0.8504849, 0.84886855, 0.8448276, 0.8445582, 0.83943963, 0.8356681, 0.8313578, 0.8213901, 0.81977373, 0.8127694]\r\n            run 3: val_acc = [0.8507543, 0.8483297, 0.84428877, 0.83863145, 0.8370151, 0.8292026, 0.82273704, 0.8170797, 0.80953664, 0.8036099]\r\n\r\n        compile outside strategy.scope():\r\n\r\n            run 1: val_acc = [0.8836207, 0.8771552, 0.8728448, 0.8685345, 0.8663793, 0.86206895, 0.85991377, 0.8491379, 0.83836204, 0.8362069]\r\n            run 2: val_acc = [0.8814655, 0.8771552, 0.875, 0.8728448, 0.8663793, 0.85991377, 0.85560346, 0.8491379, 0.8405172, 0.82974136]\r\n            run 3: val_acc = [0.87068963, 0.86422414, 0.86206895, 0.85775864, 0.8512931, 0.8426724, 0.8426724, 0.8426724, 0.83189654, 0.8125]\r\n", "comments": ["Hi @chiapas, could you try this with nightly and see if you're still running into an issue where the two get different accuracy results?", "Hi @tomerk , I confirmed that, for tf-nightly on 2020/03/01, the accuracy results are very closed, no matter where I call model.compile().\r\n\r\nWould you mind to share what caused the issue in the previous versions, and what have been done to fix it, please? Thank you!", "Hi @chiapas , it was a mix of issues:\r\n\r\n1. Metrics have to be used in the same strategy they were created in, or it can cause issues with TPUStrategy (because if you do it wrong you'll only get the metric result from one replica instead of the overall metric aggregated across all of your replicas). Nightly should throw an error if it detects this now (on TPUStrategy). It did not use to before.\r\n\r\n2. Even if a model was created in a distribution strategy scope (and captures that distribution strategy), compile wasn't entering the captured scope. Because compile sometimes creates metrics (if you pass in string names), this meant the metrics compile created were not in the model's distribution strategy scope.\r\n\r\nWe've now made it so that:\r\n* compile enters the distribution strategy scope the model was created in, allowing the metrics to be created with the correct distribution strategy\r\n* If you explicitly pass in a pre-constructed metric to compile that was created in the wrong scope, compile will raise an error."]}, {"number": 36910, "title": "Cannot Convert Tensor Object to Numpy Array", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information** - \r\nHave I written custom code - YES \r\n OS Platform and Distribution - macOS Catalina 10.15.2 \r\n TensorFlow installed from - Conda \r\nTensorFlow version (use command below): 2.0.0\r\n - Python version: 3.6.7\r\nCPU\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nI am writing a custom layer where I need a kernel to be element-wise multiplied on the input. I am trying to convert the input tensor into a Numpy array using K.eval(input) but I get the following error: \r\n\r\nAttributeError: 'Tensor' object has no attribute '_numpy'\r\n\r\n**Describe the expected behavior**\r\n\r\n**Code to reproduce the issue** Provide a reproducible test case that is the\r\nbare minimum necessary to generate the problem.\r\n\r\nHere is the custom layer that I am trying to implement: \r\n\r\n```python\r\nimport numpy as np\r\nimport tensorflow\r\nfrom tensorflow.keras import backend as K\r\nfrom tensorflow.keras.layers import InputSpec, Layer, Dense, Conv2D, Lambda, Multiply\r\nfrom tensorflow.keras import constraints\r\nfrom tensorflow.keras import initializers\r\n\r\nfrom binary_ops import binarize\r\n\r\n\r\nclass BinaryConv2D(Conv2D):\r\n    '''Binarized Convolution2D layer\r\n    References: \r\n    \"BinaryNet: Training Deep Neural Networks with Weights and Activations Constrained to +1 or -1\" [http://arxiv.org/abs/1602.02830]\r\n    '''\r\n\r\n    def __init__(self, filters, kernel_lr_multiplier='Glorot',\r\n                 bias_lr_multiplier=None, H=1., **kwargs):\r\n        super(BinaryConv2D, self).__init__(filters, **kwargs)\r\n        self.H = H\r\n        self.kernel_lr_multiplier = kernel_lr_multiplier\r\n        self.bias_lr_multiplier = bias_lr_multiplier\r\n\r\n    def build(self, input_shape):\r\n        if self.data_format == 'channels_first':\r\n            channel_axis = 1\r\n        else:\r\n            channel_axis = -1\r\n        if input_shape[channel_axis] is None:\r\n            raise ValueError('The channel dimension of the inputs '\r\n                             'should be defined. Found `None`.')\r\n\r\n        input_dim = input_shape[channel_axis]\r\n        kernel_shape = self.kernel_size + (input_dim, self.filters)\r\n\r\n        base = self.kernel_size[0] * self.kernel_size[1]\r\n        if self.H == 'Glorot':\r\n            nb_input = int(input_dim * base)\r\n            nb_output = int(self.filters * base)\r\n            self.H = np.float32(np.sqrt(1.5 / (nb_input + nb_output)))\r\n            # print('Glorot H: {}'.format(self.H))\r\n\r\n        if self.kernel_lr_multiplier == 'Glorot':\r\n            nb_input = int(input_dim * base)\r\n            nb_output = int(self.filters * base)\r\n            self.kernel_lr_multiplier = np.float32(1. / np.sqrt(1.5 / (nb_input + nb_output)))\r\n            # print('Glorot learning rate multiplier: {}'.format(self.lr_multiplier))\r\n\r\n        self.kernel_constraint = Clip(-self.H, self.H)\r\n        self.kernel_initializer = initializers.RandomUniform(-self.H, self.H)\r\n        self.kernel = self.add_weight(shape=kernel_shape,\r\n                                      initializer=self.kernel_initializer,\r\n                                      name='kernel',\r\n                                      regularizer=self.kernel_regularizer,\r\n                                      constraint=self.kernel_constraint)\r\n\r\n        if self.use_bias:\r\n            self.lr_multipliers = [self.kernel_lr_multiplier, self.bias_lr_multiplier]\r\n            self.bias = self.add_weight((self.output_dim,),\r\n                                        initializer=self.bias_initializers,\r\n                                        name='bias',\r\n                                        regularizer=self.bias_regularizer,\r\n                                        constraint=self.bias_constraint)\r\n\r\n        else:\r\n            self.lr_multipliers = [self.kernel_lr_multiplier]\r\n            self.bias = None\r\n\r\n        # Set input spec.\r\n        self.input_spec = InputSpec(ndim=4, axes={channel_axis: input_dim})\r\n        self.built = True\r\n\r\n    def call(self, inputs):\r\n        binary_kernel = binarize(self.kernel, H=self.H)\r\n\r\n        print(type(K.eval(binary_kernel)))\r\n        \r\n        bk_temp = np.reshape(K.eval(binary_kernel[:,:,:,0]), (-1,self.kernel_size[0],self.kernel_size[0],1))\r\n        bk_cube = np.zeros((30,30,30,1))\r\n        bk_cube[:] = bk_temp\r\n        outputs = inputs * bk_cube\r\n       \r\n\r\n        if self.use_bias:\r\n            outputs = K.bias_add(\r\n                outputs,\r\n                self.bias,\r\n                data_format=self.data_format)\r\n\r\n        \r\n        if self.activation is not None:\r\n            return self.activation(outputs) \r\n        return outputs\r\n\r\n    def get_config(self):\r\n        config = {'H': self.H,\r\n                  'kernel_lr_multiplier': self.kernel_lr_multiplier,\r\n                  'bias_lr_multiplier': self.bias_lr_multiplier}\r\n        base_config = super(BinaryConv2D, self).get_config()\r\n        return dict(list(base_config.items()) + list(config.items()))\r\n\r\n```\r\n\r\nI should add that this error comes up only when I try to compile this into a model. If I just call build then it works fine\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["@matthewp14 I am unable to replicate your code in my local to help you resolve your issue due to the binary_ops dependency used by you in the code, please refer to the [gist](https://colab.sandbox.google.com/gist/Saduf2019/4e2c57e65ddebdf66c7ed194f3f6d7ee/36910.ipynb), and share all dependencies to replicate your issue.", "Hey @matthewp14  could you provide a gist or code, if possible, for your binarize method?", "@Saduf2019 @Joey155 I was able to figure out a workaround for the first problem that I was having but now I am having another issue. I am trying to compile my model using some custom lambda functions that I wrote in the lambda_layers.py file. For one of them I need to iterate through the input tensor but I am getting the following error message: \r\n\r\nTypeError: You are attempting to use Python control flow in a layer that was not declared to be dynamic. Pass `dynamic=True` to the class constructor.\r\nEncountered error:\r\n\"\"\"\r\nin converted code:\r\n\r\n    /CUP-Net/src/lambda_layers.py:45 streak  *\r\n        shape = list(x)\r\n    opt/miniconda3/envs/engs89/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py:396 converted_call\r\n        return py_builtins.overload_of(f)(*args)\r\n    opt/miniconda3/envs/engs89/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:547 __iter__\r\n        self._disallow_iteration()\r\n    opt/miniconda3/envs/engs89/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:540 _disallow_iteration\r\n        self._disallow_when_autograph_enabled(\"iterating over `tf.Tensor`\")\r\n    opt/miniconda3/envs/engs89/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:518 _disallow_when_autograph_enabled\r\n        \" decorating it directly with @tf.function.\".format(task))\r\n\r\n    OperatorNotAllowedInGraphError: iterating over `tf.Tensor` is not allowed: AutoGraph did not convert this function. Try decorating it directly with @tf.function.\r\n\r\n\"\"\"\r\n\r\nI decorated my function with @tf.function but still no luck. This seems to be related to the same issue that I was having before where tf/keras are stuck in graph mode while they should be in eager mode. Any help with this would be great. \r\n\r\nHere is a link to the [gist](https://gist.github.com/matthewp14/1275eb95c72dddf85483fadbcdcb913c)", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36910\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36910\">No</a>\n"]}, {"number": 36909, "title": "Source build of TensorFlow 2.0 with 0.26.1 bazel fails at C++ compilation of rule '@nccl_archive//:device_lib'.", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): centos6\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: r2.0\r\n- Python version: py3.6\r\n- Installed using virtualenv? pip? conda?: pip \r\n- Bazel version (if compiling from source): 0.26.1\r\n- GCC/Compiler version (if compiling from source): 7.3.1 (devtoolset-7) \r\n- CUDA/cuDNN version: 10.0 / cudnn 7\r\n- GPU model and memory:\r\n\r\n**Describe the problem**\r\nI m trying to build TensorFlow from source, with TF_CUDA_NEED=1 and TF_CUDA_PATHS set to the `/usr/local/cuda` which points to Cuda 10.0, NO environment variable for nccl were set TF_NCCL_VERSION, NCCL_INSTALL_PATHS. when the bazel build command is run is fails with * C++ compilation of rule '@nccl_archive//:device_lib' failed* error output.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n- Install packages centos-release-scl \r\n- Install devtoolset and python\r\n`yum install -y rh-python36 devtoolset-7`\r\n- install pip packages\r\n- build bazel 0.26.1 from source.\r\n- clone TensorFlow from branch r2.0 and run configure script.\r\n- execute bazel build.\r\n\r\n**Any other info / logs**\r\n```\r\nERROR: /home/default/.cache/bazel/_bazel_root/2c92b5569ddded7b3a6bd5e139451b60/external/nccl_archive/BUILD.bazel:53:1: C++ compilation of rule '@nccl_archive//:device_lib' failed (Exit 1) gcc failed: error executing command \r\n  (cd /home/default/.cache/bazel/_bazel_root/2c92b5569ddded7b3a6bd5e139451b60/sandbox/processwrapper-sandbox/2437/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    LD_LIBRARY_PATH=/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64/stubs:/opt/rh/rh-python36/root/usr/lib64/:/opt/rh/rh-python36/root/usr/include:/opt/rh/rh-python36/root/usr/include/python3.6m/:/usr/local/lib:/opt/rh/devtoolset-7/root/usr/lib64:/opt/rh/devtoolset-7/root/usr/lib:/opt/rh/devtoolset-7/root/usr/lib64/dyninst:/opt/rh/devtoolset-7/root/usr/lib/dyninst:/opt/rh/devtoolset-7/root/usr/lib64:/opt/rh/devtoolset-7/root/usr/lib:/usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \\\r\n    PATH=/opt/app-root/output/:/home/default/bin:/opt/rh/rh-python36/root/usr/bin:/opt/rh/devtoolset-7/root/usr/bin:/opt/app-root/bin:/usr/local/bin:/opt/app-root/src/.local/bin/:/usr/local/nvidia/bin:/usr/local/cuda/bin:/opt/app-root/src/bin:/opt/app-root/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/home/default/.local/bin \\\r\n    PWD=/proc/self/cwd \\\r\n  /opt/rh/devtoolset-7/root/usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections '-std=c++0x' -MD -MF bazel-out/k8-opt/bin/external/nccl_archive/_objs/device_lib/max_f16_all_gather.cu.d '-frandom-seed=bazel-out/k8-opt/bin/external/nccl_archive/_objs/device_lib/max_f16_all_gather.cu.o' -iquote external/nccl_archive -iquote bazel-out/k8-opt/bin/external/nccl_archive -iquote external/local_config_cuda -iquote bazel-out/k8-opt/bin/external/local_config_cuda -Ibazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs -Ibazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/include_hdrs -Ibazel-out/k8-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual -Ibazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/src_hdrs -isystem external/local_config_cuda/cuda -isystem bazel-out/k8-opt/bin/external/local_config_cuda/cuda -isystem external/local_config_cuda/cuda/cuda/include -isystem bazel-out/k8-opt/bin/external/local_config_cuda/cuda/cuda/include -mavx -mavx512f -mavx2 -mfma '-mfpmath=both' -msse4.2 '-D_GLIBCXX_USE_CXX11_ABI=0' -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -c bazel-out/k8-opt/bin/external/nccl_archive/src/collectives/device/max_f16_all_gather.cu.cc -o bazel-out/k8-opt/bin/external/nccl_archive/_objs/device_lib/max_f16_all_gather.cu.o)\r\nExecution platform: @bazel_tools//platforms:host_platform\r\n\r\nUse --sandbox_debug to see verbose messages from the sandbox: gcc failed: error executing command \r\n  (cd /home/default/.cache/bazel/_bazel_root/2c92b5569ddded7b3a6bd5e139451b60/sandbox/processwrapper-sandbox/2437/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    LD_LIBRARY_PATH=/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64/stubs:/opt/rh/rh-python36/root/usr/lib64/:/opt/rh/rh-python36/root/usr/include:/opt/rh/rh-python36/root/usr/include/python3.6m/:/usr/local/lib:/opt/rh/devtoolset-7/root/usr/lib64:/opt/rh/devtoolset-7/root/usr/lib:/opt/rh/devtoolset-7/root/usr/lib64/dyninst:/opt/rh/devtoolset-7/root/usr/lib/dyninst:/opt/rh/devtoolset-7/root/usr/lib64:/opt/rh/devtoolset-7/root/usr/lib:/usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \\\r\n    PATH=/opt/app-root/output/:/home/default/bin:/opt/rh/rh-python36/root/usr/bin:/opt/rh/devtoolset-7/root/usr/bin:/opt/app-root/bin:/usr/local/bin:/opt/app-root/src/.local/bin/:/usr/local/nvidia/bin:/usr/local/cuda/bin:/opt/app-root/src/bin:/opt/app-root/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/home/default/.local/bin \\\r\n    PWD=/proc/self/cwd \\\r\n  /opt/rh/devtoolset-7/root/usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections '-std=c++0x' -MD -MF bazel-out/k8-opt/bin/external/nccl_archive/_objs/device_lib/max_f16_all_gather.cu.d '-frandom-seed=bazel-out/k8-opt/bin/external/nccl_archive/_objs/device_lib/max_f16_all_gather.cu.o' -iquote external/nccl_archive -iquote bazel-out/k8-opt/bin/external/nccl_archive -iquote external/local_config_cuda -iquote bazel-out/k8-opt/bin/external/local_config_cuda -Ibazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs -Ibazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/include_hdrs -Ibazel-out/k8-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual -Ibazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/src_hdrs -isystem external/local_config_cuda/cuda -isystem bazel-out/k8-opt/bin/external/local_config_cuda/cuda -isystem external/local_config_cuda/cuda/cuda/include -isystem bazel-out/k8-opt/bin/external/local_config_cuda/cuda/cuda/include -mavx -mavx512f -mavx2 -mfma '-mfpmath=both' -msse4.2 '-D_GLIBCXX_USE_CXX11_ABI=0' -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -c bazel-out/k8-opt/bin/external/nccl_archive/src/collectives/device/max_f16_all_gather.cu.cc -o bazel-out/k8-opt/bin/external/nccl_archive/_objs/device_lib/max_f16_all_gather.cu.o)\r\nExecution platform: @bazel_tools//platforms:host_platform\r\n\r\nUse --sandbox_debug to see verbose messages from the sandbox\r\nIn file included from bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/reduce_kernel.h:11:0,\r\n                 from bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/primitives.h:11,\r\n                 from bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/all_gather.h:8,\r\n                 from bazel-out/k8-opt/bin/external/nccl_archive/src/collectives/device/max_f16_all_gather.cu.cc:10:\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/common_kernel.h:254:0: warning: ignoring #pragma unroll  [-Wunknown-pragmas]\r\n     #pragma unroll\r\n \r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/common_kernel.h:256:0: warning: ignoring #pragma unroll  [-Wunknown-pragmas]\r\n     #pragma unroll 1\r\n \r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/common_kernel.h:259:0: warning: ignoring #pragma unroll  [-Wunknown-pragmas]\r\n     #pragma unroll\r\n \r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/common_kernel.h:261:0: warning: ignoring #pragma unroll  [-Wunknown-pragmas]\r\n     #pragma unroll 1\r\n \r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/common_kernel.h:290:0: warning: ignoring #pragma unroll  [-Wunknown-pragmas]\r\n     #pragma unroll 1\r\n \r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/common_kernel.h:301:0: warning: ignoring #pragma unroll  [-Wunknown-pragmas]\r\n     #pragma unroll 1\r\n \r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/common_kernel.h:327:0: warning: ignoring #pragma unroll  [-Wunknown-pragmas]\r\n   #pragma unroll\r\n \r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/common_kernel.h:330:0: warning: ignoring #pragma unroll  [-Wunknown-pragmas]\r\n   #pragma unroll\r\n \r\nIn file included from bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/all_gather.h:8:0,\r\n                 from bazel-out/k8-opt/bin/external/nccl_archive/src/collectives/device/max_f16_all_gather.cu.cc:10:\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/primitives.h:154:0: warning: ignoring #pragma unroll  [-Wunknown-pragmas]\r\n     #pragma unroll 1\r\n \r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/primitives.h:456:0: warning: ignoring #pragma unroll  [-Wunknown-pragmas]\r\n     #pragma unroll 2\r\n \r\nIn file included from bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/reduce_kernel.h:11:0,\r\n                 from bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/primitives.h:11,\r\n                 from bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/all_gather.h:8,\r\n                 from bazel-out/k8-opt/bin/external/nccl_archive/src/collectives/device/max_f16_all_gather.cu.cc:10:\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/common_kernel.h: In member function 'PackType MULTI<FUNC, double>::operator()(PackType, PackType) const':\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/common_kernel.h:170:24: error: there are no arguments to '__longlong_as_double' that depend on a template parameter, so a declaration of '__longlong_as_double' must be available [-fpermissive]\r\n     double rv = FUNC()(__longlong_as_double(x), __longlong_as_double(y));\r\n                        ^~~~~~~~~~~~~~~~~~~~\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/common_kernel.h:170:24: note: (if you use '-fpermissive', G++ will accept your code, but allowing the use of an undeclared name is deprecated)\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/common_kernel.h:170:49: error: there are no arguments to '__longlong_as_double' that depend on a template parameter, so a declaration of '__longlong_as_double' must be available [-fpermissive]\r\n     double rv = FUNC()(__longlong_as_double(x), __longlong_as_double(y));\r\n                                                 ^~~~~~~~~~~~~~~~~~~~\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/common_kernel.h:171:12: error: there are no arguments to '__double_as_longlong' that depend on a template parameter, so a declaration of '__double_as_longlong' must be available [-fpermissive]\r\n     return __double_as_longlong(rv);\r\n            ^~~~~~~~~~~~~~~~~~~~\r\nIn file included from bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/primitives.h:11:0,\r\n                 from bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/all_gather.h:8,\r\n                 from bazel-out/k8-opt/bin/external/nccl_archive/src/collectives/device/max_f16_all_gather.cu.cc:10:\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/reduce_kernel.h: In member function 'uint32_t FuncMax<signed char>::operator()(uint32_t, uint32_t) const':\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/reduce_kernel.h:137:14: error: 'max' was not declared in this scope\r\n     cr.a.x = max(cx.a.x, cy.a.x);\r\n              ^~~\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/reduce_kernel.h: In member function 'uint32_t FuncMax<unsigned char>::operator()(uint32_t, uint32_t) const':\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/reduce_kernel.h:160:14: error: 'max' was not declared in this scope\r\n     cr.a.x = max(cx.a.x, cy.a.x);\r\n              ^~~\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/reduce_kernel.h: In member function 'half2 FuncSum<__half>::operator()(half2, half2) const':\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/reduce_kernel.h:226:10: error: '__half22float2' was not declared in this scope\r\n     fx = __half22float2(x);\r\n          ^~~~~~~~~~~~~~\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/reduce_kernel.h:226:10: note: suggested alternative: '__half2float'\r\n     fx = __half22float2(x);\r\n          ^~~~~~~~~~~~~~\r\n          __half2float\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/reduce_kernel.h:230:12: error: '__float22half2_rn' was not declared in this scope\r\n     return __float22half2_rn(fr);\r\n            ^~~~~~~~~~~~~~~~~\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/reduce_kernel.h:230:12: note: suggested alternative: '__floats2half2_rn'\r\n     return __float22half2_rn(fr);\r\n            ^~~~~~~~~~~~~~~~~\r\n            __floats2half2_rn\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/reduce_kernel.h: In member function 'half2 FuncProd<__half>::operator()(half2, half2) const':\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/reduce_kernel.h:249:10: error: '__half22float2' was not declared in this scope\r\n     fx = __half22float2(x);\r\n          ^~~~~~~~~~~~~~\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/reduce_kernel.h:249:10: note: suggested alternative: '__half2float'\r\n     fx = __half22float2(x);\r\n          ^~~~~~~~~~~~~~\r\n          __half2float\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/reduce_kernel.h:253:12: error: '__float22half2_rn' was not declared in this scope\r\n     return __float22half2_rn(fr);\r\n            ^~~~~~~~~~~~~~~~~\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/reduce_kernel.h:253:12: note: suggested alternative: '__floats2half2_rn'\r\n     return __float22half2_rn(fr);\r\n            ^~~~~~~~~~~~~~~~~\r\n            __floats2half2_rn\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/reduce_kernel.h: In member function 'half2 FuncMax<__half>::operator()(half2, half2) const':\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/reduce_kernel.h:269:10: error: '__half22float2' was not declared in this scope\r\n     fx = __half22float2(x);\r\n          ^~~~~~~~~~~~~~\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/reduce_kernel.h:269:10: note: suggested alternative: '__half2float'\r\n     fx = __half22float2(x);\r\n          ^~~~~~~~~~~~~~\r\n          __half2float\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/reduce_kernel.h:271:12: error: 'fmaxf' was not declared in this scope\r\n     fr.x = fmaxf(fx.x, fy.x);\r\n            ^~~~~\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/reduce_kernel.h:273:12: error: '__float22half2_rn' was not declared in this scope\r\n     return __float22half2_rn(fr);\r\n            ^~~~~~~~~~~~~~~~~\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/reduce_kernel.h:273:12: note: suggested alternative: '__floats2half2_rn'\r\n     return __float22half2_rn(fr);\r\n            ^~~~~~~~~~~~~~~~~\r\n            __floats2half2_rn\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/reduce_kernel.h: In member function 'half FuncMax<__half>::operator()(half, half) const':\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/reduce_kernel.h:279:10: error: 'fmaxf' was not declared in this scope\r\n     fm = fmaxf(fx, fy);\r\n          ^~~~~\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/reduce_kernel.h: In member function 'half2 FuncMin<__half>::operator()(half2, half2) const':\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/reduce_kernel.h:288:10: error: '__half22float2' was not declared in this scope\r\n     fx = __half22float2(x);\r\n          ^~~~~~~~~~~~~~\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/reduce_kernel.h:288:10: note: suggested alternative: '__half2float'\r\n     fx = __half22float2(x);\r\n          ^~~~~~~~~~~~~~\r\n          __half2float\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/reduce_kernel.h:290:12: error: 'fminf' was not declared in this scope\r\n     fr.x = fminf(fx.x, fy.x);\r\n            ^~~~~\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/reduce_kernel.h:290:12: note: suggested alternative: 'min'\r\n     fr.x = fminf(fx.x, fy.x);\r\n            ^~~~~\r\n            min\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/reduce_kernel.h:292:12: error: '__float22half2_rn' was not declared in this scope\r\n     return __float22half2_rn(fr);\r\n            ^~~~~~~~~~~~~~~~~\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/reduce_kernel.h:292:12: note: suggested alternative: '__floats2half2_rn'\r\n     return __float22half2_rn(fr);\r\n            ^~~~~~~~~~~~~~~~~\r\n            __floats2half2_rn\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/reduce_kernel.h: In member function 'half FuncMin<__half>::operator()(half, half) const':\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/reduce_kernel.h:298:10: error: 'fminf' was not declared in this scope\r\n     fm = fminf(fx, fy);\r\n          ^~~~~\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/reduce_kernel.h:298:10: note: suggested alternative: 'min'\r\n     fm = fminf(fx, fy);\r\n          ^~~~~\r\n          min\r\nIn file included from bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/primitives.h:12:0,\r\n                 from bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/all_gather.h:8,\r\n                 from bazel-out/k8-opt/bin/external/nccl_archive/src/collectives/device/max_f16_all_gather.cu.cc:10:\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/common.h: In function 'void load_parallel(void*, void*, size_t, int)':\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/common.h:37:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   for (int o = tid; o < (size/sizeof(int)); o += blockDim.x) d[o] = s[o];\r\n                     ~~^~~~~~~~~~~~~~~~~~~~\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/common.h:37:50: error: 'blockDim' was not declared in this scope\r\n   for (int o = tid; o < (size/sizeof(int)); o += blockDim.x) d[o] = s[o];\r\n                                                  ^~~~~~~~\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/common.h:37:50: note: suggested alternative: 'flockfile'\r\n   for (int o = tid; o < (size/sizeof(int)); o += blockDim.x) d[o] = s[o];\r\n                                                  ^~~~~~~~\r\n                                                  flockfile\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/common.h:38:3: error: '__syncthreads' was not declared in this scope\r\n   __syncthreads();\r\n   ^~~~~~~~~~~~~\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/common.h:38:3: note: suggested alternative: '__thread__'\r\n   __syncthreads();\r\n   ^~~~~~~~~~~~~\r\n   __thread__\r\nIn file included from bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/all_gather.h:8:0,\r\n                 from bazel-out/k8-opt/bin/external/nccl_archive/src/collectives/device/max_f16_all_gather.cu.cc:10:\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/primitives.h: In member function 'void ncclPrimitives<UNROLL, SLICESPERCHUNK, SLICESTEPS, T, NRECV, NSEND, FUNC>::GenericOp(const T*, T*, int, int)':\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/primitives.h:156:22: error: there are no arguments to 'max' that depend on a template parameter, so a declaration of 'max' must be available [-fpermissive]\r\n       int realSize = max(0, min(sliceSize, nelem-offset));\r\n                      ^~~\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/primitives.h:175:19: error: there are no arguments to '__threadfence_system' that depend on a template parameter, so a declaration of '__threadfence_system' must be available [-fpermissive]\r\n         if (SEND) __threadfence_system();\r\n                   ^~~~~~~~~~~~~~~~~~~~\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/primitives.h: In member function 'void ncclPrimitives<UNROLL, SLICESPERCHUNK, SLICESTEPS, T, NRECV, NSEND, FUNC>::loadSendConn(ncclConnInfo*, int, T*)':\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/primitives.h:218:7: error: there are no arguments to '__syncthreads' that depend on a template parameter, so a declaration of '__syncthreads' must be available [-fpermissive]\r\n       __syncthreads();\r\n       ^~~~~~~~~~~~~\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/primitives.h: In member function 'void ncclPrimitives<UNROLL, SLICESPERCHUNK, SLICESTEPS, T, NRECV, NSEND, FUNC>::saveRecvConn(int)':\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/primitives.h:227:7: error: there are no arguments to '__threadfence_system' that depend on a template parameter, so a declaration of '__threadfence_system' must be available [-fpermissive]\r\n       __threadfence_system();\r\n       ^~~~~~~~~~~~~~~~~~~~\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/primitives.h: In member function 'void ncclPrimitives<UNROLL, SLICESPERCHUNK, SLICESTEPS, T, NRECV, NSEND, FUNC>::saveSendConn(int)':\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/primitives.h:235:7: error: there are no arguments to '__threadfence_system' that depend on a template parameter, so a declaration of '__threadfence_system' must be available [-fpermissive]\r\n       __threadfence_system();\r\n       ^~~~~~~~~~~~~~~~~~~~\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/primitives.h: In constructor 'ncclPrimitives<UNROLL, SLICESPERCHUNK, SLICESTEPS, T, NRECV, NSEND, FUNC>::ncclPrimitives(int, int, int*, int*, T*, int, ncclChannel*, ncclDevComm*, uint64_t)':\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/primitives.h:245:5: error: there are no arguments to '__syncthreads' that depend on a template parameter, so a declaration of '__syncthreads' must be available [-fpermissive]\r\n     __syncthreads();\r\n     ^~~~~~~~~~~~~\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/primitives.h: In member function 'void ncclLLPrimitives<T, FUNC, NRECV, NSEND>::saveRecvConn(int)':\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/primitives.h:514:7: error: there are no arguments to '__threadfence_block' that depend on a template parameter, so a declaration of '__threadfence_block' must be available [-fpermissive]\r\n       __threadfence_block();\r\n       ^~~~~~~~~~~~~~~~~~~\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/primitives.h: In member function 'void ncclLLPrimitives<T, FUNC, NRECV, NSEND>::saveSendConn(int)':\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/primitives.h:522:7: error: there are no arguments to '__threadfence_block' that depend on a template parameter, so a declaration of '__threadfence_block' must be available [-fpermissive]\r\n       __threadfence_block();\r\n       ^~~~~~~~~~~~~~~~~~~\r\nIn file included from bazel-out/k8-opt/bin/external/nccl_archive/src/collectives/device/max_f16_all_gather.cu.cc:10:0:\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/all_gather.h: In function 'void ncclAllGatherRingKernel(CollectiveArgs*)':\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/all_gather.h:13:19: error: 'threadIdx' was not declared in this scope\r\n   const int tid = threadIdx.x;\r\n                   ^~~~~~~~~\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/all_gather.h:14:24: error: 'blockDim' was not declared in this scope\r\n   const int nthreads = blockDim.x - 1;\r\n                        ^~~~~~~~\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/all_gather.h:14:24: note: suggested alternative: 'flockfile'\r\n   const int nthreads = blockDim.x - 1;\r\n                        ^~~~~~~~\r\n                        flockfile\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/all_gather.h:17:48: error: 'blockIdx' was not declared in this scope\r\n   struct ncclChannel* channel = comm->channels+blockIdx.x;\r\n                                                ^~~~~~~~\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/all_gather.h: In function 'void ncclAllGatherRingLLKernel(CollectiveArgs*)':\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/all_gather.h:74:19: error: 'threadIdx' was not declared in this scope\r\n   const int tid = threadIdx.x;\r\n                   ^~~~~~~~~\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/all_gather.h:78:48: error: 'blockIdx' was not declared in this scope\r\n   struct ncclChannel* channel = comm->channels+blockIdx.x;\r\n                                                ^~~~~~~~\r\nIn file included from bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/primitives.h:12:0,\r\n                 from bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/all_gather.h:8,\r\n                 from bazel-out/k8-opt/bin/external/nccl_archive/src/collectives/device/max_f16_all_gather.cu.cc:10:\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/common.h: At global scope:\r\nbazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/common.h:40:24: warning: 'void load_coll(ncclColl*, ncclColl*, int)' defined but not used [-Wunused-function]\r\n static __device__ void load_coll(struct ncclColl* localColl, struct ncclColl* hostColl, int tid) {\r\n```", "comments": ["If it helps, here is the configuration set:\r\n```\r\nYou have bazel 0.26.1- (@non-git) installed.\r\nFound CUDA 10.0 in:\r\n    /usr/local/cuda/lib64\r\n    /usr/local/cuda/include\r\nFound cuDNN 7 in:\r\n    /usr/local/cuda/lib64\r\n    /usr/local/cuda/include\r\n\r\n\r\nWARNING: XLA does not support CUDA compute capabilities lower than 3.5. Disable XLA when running on older GPUs.\r\nPreconfigured Bazel build configs. You can use any of the below by adding \"--config=<>\" to your build command. See .bazelrc for more details.\r\n\t--config=mkl         \t# Build with MKL support.\r\n\t--config=monolithic  \t# Config for mostly static monolithic build.\r\n\t--config=gdr         \t# Build with GDR support.\r\n\t--config=verbs       \t# Build with libverbs support.\r\n\t--config=ngraph      \t# Build with Intel nGraph support.\r\n\t--config=numa        \t# Build with NUMA support.\r\n\t--config=dynamic_kernels\t# (Experimental) Build kernels into separate shared objects.\r\n\t--config=v2          \t# Build TensorFlow 2.x instead of 1.x.\r\nPreconfigured Bazel build configs to DISABLE default on features:\r\n\t--config=noaws       \t# Disable AWS S3 filesystem support.\r\n\t--config=nogcp       \t# Disable GCP support.\r\n\t--config=nohdfs      \t# Disable HDFS support.\r\n\t--config=noignite    \t# Disable Apache Ignite support.\r\n\t--config=nokafka     \t# Disable Apache Kafka support.\r\n\t--config=nonccl      \t# Disable NVIDIA NCCL support.\r\n```", "@harshad16 \r\n\r\nCan you please let us know GPU model.May be your GPU model is not compatible with CUDA/cuDNN versions. Thanks!", "> @harshad16\r\n> \r\n> Can you please let us know GPU model.May be your GPU model is not compatible with CUDA/cuDNN versions. Thanks!\r\n\r\nThe GPU model is NVIDIA Corporation GP100GL [Tesla P100 PCIe 12GB]. ", "@angerson Any idea and suggestions, how I can fix this?", "We're unable to provide support for building old versions of TensorFlow, sorry. Can you reproduce this at master HEAD?", "hey i m trying to build the master in the same scenario, there is problem bazel 2.0.0 seems to have issue on centos6. i will let you lknow about the result soon.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36909\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36909\">No</a>\n", "docker + ubuntu16.04\r\n`   struct ares_txt_ext* result = nullptr;\r\n          ^\r\nexternal/grpc/src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc: In function 'void grpc_dns_lookup_ares_continue_after_check_localhost_and_ip_literals_locked(grpc_ares_request*, const char*, const char*, const char*, grpc_pollset_set*, bool, int, grpc_combiner*)':\r\nexternal/grpc/src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc:410:70: error: 'ares_set_servers_ports' was not declared in this scope\r\n     int status = ares_set_servers_ports(*channel, &r->dns_server_addr);\r\n                                                                      ^\r\nTarget //tensorflow:libtensorflow_cc.so failed to build\r\nINFO: Elapsed time: 307.047s, Critical Path: 70.95s\r\nINFO: 83 processes: 83 processwrapper-sandbox.\r\nFAILED: Build did NOT complete successfully`"]}, {"number": 36908, "title": "Update Session.py", "body": "The [current example](https://www.tensorflow.org/api_docs/python/tf/compat/v1/Session) provided in TF website throws an error in TF2.x as we need to disable eager to build a graph and run in session.\r\nPlease check the colab [gist here](https://colab.sandbox.google.com/gist/jvishnuvardhan/01e01bd71653f6566c68f5210fabdf65/untitled827.ipynb). Thanks!", "comments": []}, {"number": 36904, "title": "TFLite: static library: fix benchmark build issue", "body": "Since the commit ee7642b2670e33a45cc3a6f6585cfab7f7d4f8f6, the benchmark\r\napplication is no more building due to the fact that some functions have\r\nbeen moved.\r\nAdd profile_summary_formatter.cc in the PROFILE_SUMMARIZER_SRCS.\r\n", "comments": []}, {"number": 36903, "title": "Executing genrule //tensorflow/python/keras/api:keras_python_api_gen failed ", "body": "**System information**\r\n- Dockerimage: nvidia/cuda-ppc64le:10.1-cudnn7-devel-ubuntu18.04\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: r2.1 (branch)\r\n- Python version: Python 3.6.9 (also setted /usr/bin/python3 while ./configure)\r\n- Installed using virtualenv? pip? conda?: no, github repository and build\r\n- Bazel version (if compiling from source): 0.27\r\n- GCC/Compiler version (if compiling from source): gcc (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0\r\n- CUDA/cuDNN version: 10.1, 7.0 \r\n- GPU model and memory: compute capability 6.0 nvidia tesla P100, GPU Memory 12GB, RAM 256GB\r\n\r\n\r\n\r\nWhile building it throws a error.\r\n```bash\r\n bazel build --config=opt --config=cuda --discard_analysis_cache --nokeep_state_after_build --notrack_incremental_state //tensorflow/tools/pip_package:build_pip_package\r\n```\r\nError:\r\n```bash\r\nERROR: /root/tensorflow/tensorflow/python/keras/api/BUILD:102:1: Executing genrule //tensorflow/python/keras/api:keras_python_api_gen failed (Exit 1)\r\nTraceback (most recent call last):\r\n  File \"/root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_1_keras_python_api_gen.runfiles/org_tensorflow/tensorflow/python/tools/api/generator/create_python_api.py\", line 777, in <module>\r\n    main()\r\n  File \"/root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_1_keras_python_api_gen.runfiles/org_tensorflow/tensorflow/python/tools/api/generator/create_python_api.py\", line 756, in main\r\n    importlib.import_module(package)\r\n  File \"/usr/lib/python3.6/importlib/__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"/root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_1_keras_python_api_gen.runfiles/org_tensorflow/tensorflow/python/keras/datasets/imdb.py\", line 25, in <module>\r\n    from tensorflow.python.keras.preprocessing.sequence import _remove_long_seq\r\n  File \"/root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_1_keras_python_api_gen.runfiles/org_tensorflow/tensorflow/python/keras/preprocessing/__init__.py\", line 23, in <module>\r\n    import keras_preprocessing\r\nModuleNotFoundError: No module named 'keras_preprocessing'\r\n----------------\r\nNote: The failure of target //tensorflow/python/keras/api:create_tensorflow.python_api_1_keras_python_api_gen (with exit code 1) may have been caused by the fact that it is a Python 2 program that was built in the host configuration, which uses Python 3. You can change the host configuration (for the entire build) to instead use Python 2 by setting --host_force_python=PY2.\r\n\r\nIf this error started occurring in Bazel 0.27 and later, it may be because the Python toolchain now enforces that targets analyzed as PY2 and PY3 run under a Python 2 and Python 3 interpreter, respectively. See https://github.com/bazelbuild/bazel/issues/7899 for more information.\r\n----------------\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nERROR: /root/tensorflow/tensorflow/tools/pip_package/BUILD:49:1 Executing genrule //tensorflow/python/keras/api:keras_python_api_gen failed (Exit 1)\r\nINFO: Elapsed time: 480.332s, Critical Path: 366.40s\r\nINFO: 2627 processes: 2627 local.\r\nFAILED: Build did NOT complete successfully\r\n```\r\n\r\n\r\n", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36903\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36903\">No</a>\n", "@Tockra : What was your solution to this issue?", "It was stupid. I hadn't install \"keras_preprocessing\". ", "> It was stupid. I hadn't install \"keras_preprocessing\".\r\n\r\nI have the same error, and keras_preprocessing is in tensorflow/python/keras/preprocessing/\r\nBecause when I  ls this directory I get:\r\n\r\n ls tensorflow/python/keras/preprocessing/\r\nBUILD              image_pipeline_test.py  image_test.py  sequence.py       text.py\r\nimage_pipeline.py  image.py                __init__.py    sequence_test.py  text_test.py\r\n\r\n\r\nWhat do you mean you hadn't installed?\r\n", "The error I got is actually:\r\n-----------------------------------------------------------------------------------------------------------------------\r\n/home/msky/tensorflow/tensorflow/python/keras/api/BUILD:104:1: Executing genrule //tensorflow/python/keras/api:keras_python_api_gen failed (Exit 1)\r\nTraceback (most recent call last):\r\n  File \"/root/.cache/bazel/_bazel_root/349bb11648069f0a9b13bec970961d74/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen.runfiles/org_tensorflow/tensorflow/python/tools/api/generator/create_python_api.py\", line 776, in <module>\r\n    main()\r\n  File \"/root/.cache/bazel/_bazel_root/349bb11648069f0a9b13bec970961d74/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen.runfiles/org_tensorflow/tensorflow/python/tools/api/generator/create_python_api.py\", line 755, in main\r\n    importlib.import_module(package)\r\n  File \"/usr/lib64/python3.6/importlib/__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"/root/.cache/bazel/_bazel_root/349bb11648069f0a9b13bec970961d74/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen.runfiles/org_tensorflow/tensorflow/python/keras/datasets/imdb.py\", line 25, in <module>\r\n    from tensorflow.python.keras.preprocessing.sequence import _remove_long_seq\r\n  File \"/root/.cache/bazel/_bazel_root/349bb11648069f0a9b13bec970961d74/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen.runfiles/org_tensorflow/tensorflow/python/keras/preprocessing/__init__.py\", line 23, in <module>\r\n    import keras_preprocessing\r\nModuleNotFoundError: No module named 'keras_preprocessing'\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nERROR: /home/msnky/tensorflow/tensorflow/tools/pip_package/BUILD:62:1 Executing genrule //tensorflow/python/keras/api:keras_python_api_gen_compat_v2 failed (Exit 1)\r\nINFO: Elapsed time: 56.888s, Critical Path: 40.18s\r\n\r\nI have bazel 2.0, and python3.6.10. \r\n\r\nCould you please get me an idea of what is the problem?\r\n", "@minsky-1,\r\nCould you please submit a new issue from [this link](https://github.com/tensorflow/tensorflow/issues/new/choose) and fill in the template, so that we can track the issue there. Thanks!"]}, {"number": 36902, "title": "[TFLite 16x8] Small tidy up for FULLY_CONNECTED operator.", "body": "This is a small tidy up for the operator FULLY_CONNECTED that has been merged [here](https://github.com/tensorflow/tensorflow/pull/36131).\r\nIn case of 16-bit activations zero_point is zero.\r\nI check this here and remove from the kernel.", "comments": []}, {"number": 36901, "title": "tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] layout failed: Invalid argument: MutableGraphView::SortTopologically error:", "body": "Hi! I have the following message whenever I train a ConvLSTM with attention, after the samples are loaded in the buffer. The training goes on, but I haven't found anything on the internet related to this. I am not sure if its a bug, or I've made a mistake. \r\n\r\nThe complete code I am using is from [here](https://github.com/dtransposed/Paper-Implementation/tree/master/action_recognition_using_visual_attention). I suspect one of the last 3 lines of the function leads to this error. I tried debugging, but it didn't helped much.\r\n\r\n**System information**\r\nOS: Ubuntu 16.04\r\nTensorflow 2.1 installed from pip\r\nPython 3.6\r\nCUDA 10.2\r\nGPU Tesla K80, 12GB memory\r\n\r\n\r\n    `@tf.function\r\n\r\n    def train_step(self, images, labels):\r\n\r\n        loss = 0\r\n\r\n        with tf.GradientTape() as tape:\r\n\r\n            if self.network_name == 'ALSTM':\r\n                batch_feature_cube_sequence = self.network.get_batch_feature_cube_sequence(images)\r\n                hidden_state, cell_state = self.network.reset_hidden_and_cell_state(batch_feature_cube_sequence)\r\n                self.network.lstm1.initial_state = cell_state\r\n                all_attention_weights = tf.zeros((0,\r\n                                                  self.batch_size,\r\n                                                  batch_feature_cube_sequence.shape[2],\r\n                                                  batch_feature_cube_sequence.shape[2]))\r\n\r\n                for i in range(0, images.shape[1]):\r\n                    input_image = images[:, i, :, :, :]\r\n                    predictions, hidden_state, attention_weights = self.network(input_image, hidden_state)\r\n\r\n                    self.train_accuracy.update_state(labels, predictions)\r\n                    self.train_precision.update_state(labels, predictions)\r\n                    self.train_recall.update_state(labels, predictions)\r\n\r\n                    loss = loss + self.loss_object(labels, predictions)\r\n                    attention_weights = tf.expand_dims(attention_weights, 0)\r\n                    all_attention_weights = tf.concat([all_attention_weights, attention_weights], 0)\r\n\r\n                classification_loss = loss / int(images.shape[1])\r\n                attention_loss = self.attention_penalty(all_attention_weights)/ int(images.shape[1])*self.batch_size\r\n                regularization_term = tf.add_n([tf.nn.l2_loss(v) for v in self.network.trainable_variables if 'bias' not in v.name])\r\n\r\n                total_loss = classification_loss + self.penalty_coefficient*attention_loss + self.weight_decay*regularization_term\r\n\r\n            elif self.network_name == 'ConvALSTM':\r\n\r\n                hidden_state = self.network.get_initial_hidden_state(self.batch_size)\r\n                for i in range(0, images.shape[1]):\r\n                    input_image = images[:, i, :, :, :]\r\n                    predictions, hidden_state, attention_weights = self.network(input_image, hidden_state)\r\n\r\n                    self.train_accuracy.update_state(labels, predictions)\r\n                    self.train_precision.update_state(labels, predictions)\r\n                    self.train_recall.update_state(labels, predictions)\r\n\r\n                    loss = loss + self.loss_object(labels, predictions)\r\n\r\n                classification_loss = loss / int(images.shape[1])\r\n                total_loss = classification_loss\r\n\r\n        gradients = tape.gradient(total_loss, self.network.trainable_variables)\r\n        self.optimizer.apply_gradients(zip(gradients, self.network.trainable_variables))\r\n        self.train_loss.update_state(total_loss)\r\n        return total_loss`\r\n\r\n\r\n`2020-02-19 14:50:31.311596: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:150] Filling up shuffle buffer (this may take a while): 464 of 1000\r\n2020-02-19 14:50:41.318354: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:150] Filling up shuffle buffer (this may take a while): 926 of 1000\r\n2020-02-19 14:50:42.932254: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:199] Shuffle buffer filled.\r\n2020-02-19 14:52:10.425158: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] layout failed: Invalid argument: MutableGraphView::SortTopologically error: detected edge(s) creating cycle(s) {'Func/conv_alstm_7/conv_lst_m2d/while_grad/body/_15513/input/_27997' -> 'conv_alstm_7/conv_lst_m2d/while_grad/body/_15513/gradients/AddN', 'Func/conv_alstm_6/conv_lst_m2d/while_grad/body/_15704/input/_28113' -> 'conv_alstm_6/conv_lst_m2d/while_grad/body/_15704/gradients/AddN', 'Func/conv_alstm_5/conv_lst_m2d/while_grad/body/_15895/input/_28229' -> 'conv_alstm_5/conv_lst_m2d/while_grad/body/_15895/gradients/AddN', 'Func/conv_alstm_4/conv_lst_m2d/while_grad/body/_16086/input/_28345' -> 'conv_alstm_4/conv_lst_m2d/while_grad/body/_16086/gradients/AddN', 'Func/conv_alstm_3/conv_lst_m2d/while_grad/body/_16277/input/_28461' -> 'conv_alstm_3/conv_lst_m2d/while_grad/body/_16277/gradients/AddN', 'Func/conv_alstm_2/conv_lst_m2d/while_grad/body/_16468/input/_28577' -> 'conv_alstm_2/conv_lst_m2d/while_grad/body/_16468/gradients/AddN', 'Func/conv_alstm_1/conv_lst_m2d/while_grad/body/_16659/input/_28693' -> 'conv_alstm_1/conv_lst_m2d/while_grad/body/_16659/gradients/AddN', 'conv_alstm/conv_lst_m2d/while_grad/body/_16850/gradients/AddN_2' -> 'conv_alstm/conv_lst_m2d/while_grad/next_iteration/_17007', 'Func/conv_alstm_33/conv_lst_m2d/while_grad/body/_10547/input/_24981' -> 'conv_alstm_33/conv_lst_m2d/while_grad/body/_10547/gradients/AddN', 'Func/conv_alstm_32/conv_lst_m2d/while_grad/body/_10738/input/_25097' -> 'conv_alstm_32/conv_lst_m2d/while_grad/body/_10738/gradients/AddN', 'Func/conv_alstm_31/conv_lst_m2d/while_grad/body/_10929/input/_25213' -> 'conv_alstm_31/conv_lst_m2d/while_grad/body/_10929/gradients/AddN', 'Func/conv_alstm_30/conv_lst_m2d/while_grad/body/_11120/input/_25329' -> 'conv_alstm_30/conv_lst_m2d/while_grad/body/_11120/gradients/AddN', 'Func/conv_alstm_29/conv_lst_m2d/while_grad/body/_11311/input/_25445' -> 'conv_alstm_29/conv_lst_m2d/while_grad/body/_11311/gradients/AddN', 'Func/conv_alstm_28/conv_lst_m2d/while_grad/body/_11502/input/_25561' -> 'conv_alstm_28/conv_lst_m2d/while_grad/body/_11502/gradients/AddN', 'Func/conv_alstm_27/conv_lst_m2d/while_grad/body/_11693/input/_25677' -> 'conv_alstm_27/conv_lst_m2d/while_grad/body/_11693/gradients/AddN', 'Func/conv_alstm_26/conv_lst_m2d/while_grad/body/_11884/input/_25793' -> 'conv_alstm_26/conv_lst_m2d/while_grad/body/_11884/gradients/AddN', 'Func/conv_alstm_25/conv_lst_m2d/while_grad/body/_12075/input/_25909' -> 'conv_alstm_25/conv_lst_m2d/while_grad/body/_12075/gradients/AddN', 'Func/conv_alstm_24/conv_lst_m2d/while_grad/body/_12266/input/_26025' -> 'conv_alstm_24/conv_lst_m2d/while_grad/body/_12266/gradients/AddN', 'Func/conv_alstm_23/conv_lst_m2d/while_grad/body/_12457/input/_26141' -> 'conv_alstm_23/conv_lst_m2d/while_grad/body/_12457/gradients/AddN', 'Func/conv_alstm_21/conv_lst_m2d/while_grad/body/_12839/input/_26373' -> 'conv_alstm_21/conv_lst_m2d/while_grad/body/_12839/gradients/AddN', 'Func/conv_alstm_20/conv_lst_m2d/while_grad/body/_13030/input/_26489' -> 'conv_alstm_20/conv_lst_m2d/while_grad/body/_13030/gradients/AddN', 'Func/conv_alstm_19/conv_lst_m2d/while_grad/body/_13221/input/_26605' -> 'conv_alstm_19/conv_lst_m2d/while_grad/body/_13221/gradients/AddN', 'Func/conv_alstm_18/conv_lst_m2d/while_grad/body/_13412/input/_26721' -> 'conv_alstm_18/conv_lst_m2d/while_grad/body/_13412/gradients/AddN', 'Func/conv_alstm_17/conv_lst_m2d/while_grad/body/_13603/input/_26837' -> 'conv_alstm_17/conv_lst_m2d/while_grad/body/_13603/gradients/AddN', 'Func/conv_alstm_16/conv_lst_m2d/while_grad/body/_13794/input/_26953' -> 'conv_alstm_16/conv_lst_m2d/while_grad/body/_13794/gradients/AddN', 'Func/conv_alstm_15/conv_lst_m2d/while_grad/body/_13985/input/_27069' -> 'conv_alstm_15/conv_lst_m2d/while_grad/body/_13985/gradients/AddN', 'Func/conv_alstm_14/conv_lst_m2d/while_grad/body/_14176/input/_27185' -> 'conv_alstm_14/conv_lst_m2d/while_grad/body/_14176/gradients/AddN', 'Func/conv_alstm_13/conv_lst_m2d/while_grad/body/_14367/input/_27301' -> 'conv_alstm_13/conv_lst_m2d/while_grad/body/_14367/gradients/AddN', 'Func/conv_alstm_12/conv_lst_m2d/while_grad/body/_14558/input/_27417' -> 'conv_alstm_12/conv_lst_m2d/while_grad/body/_14558/gradients/AddN', 'Func/conv_alstm_11/conv_lst_m2d/while_grad/body/_14749/input/_27533' -> 'conv_alstm_11/conv_lst_m2d/while_grad/body/_14749/gradients/AddN', 'Func/conv_alstm_10/conv_lst_m2d/while_grad/body/_14940/input/_27649' -> 'conv_alstm_10/conv_lst_m2d/while_grad/body/_14940/gradients/AddN', 'Func/conv_alstm_9/conv_lst_m2d/while_grad/body/_15131/input/_27765' -> 'conv_alstm_9/conv_lst_m2d/while_grad/body/_15131/gradients/AddN', 'Func/conv_alstm_8/conv_lst_m2d/while_grad/body/_15322/input/_27881' -> 'conv_alstm_8/conv_lst_m2d/while_grad/body/_15322/gradients/AddN', 'conv_alstm_22/conv_lst_m2d/while_grad/body/_12648/gradients/convolution_4_grad/Conv2DBackpropInput' -> 'conv_alstm_22/conv_lst_m2d/while_grad/body/_12648/gradients/AddN_2', 'conv_alstm_22/conv_lst_m2d/while_grad/body/_12648/gradients/convolution_5_grad/Conv2DBackpropInput' -> 'conv_alstm_22/conv_lst_m2d/while_grad/body/_12648/gradients/AddN_2', 'conv_alstm_22/conv_lst_m2d/while_grad/body/_12648/gradients/convolution_6_grad/Conv2DBackpropInput' -> 'conv_alstm_22/conv_lst_m2d/while_grad/body/_12648/gradients/AddN_2', 'conv_alstm_22/conv_lst_m2d/while_grad/body/_12648/gradients/convolution_7_grad/Conv2DBackpropInput-2-TransposeNHWCToNCHW-LayoutOptimizer' -> 'conv_alstm_22/conv_lst_m2d/while_grad/body/_12648/gradients/convolution_7_grad/Conv2DBackpropInput', 'Func/conv_alstm_34/conv_lst_m2d/while_grad/body/_10356/input/_24865' -> 'conv_alstm_34/conv_lst_m2d/while_grad/body/_10356/gradients/AddN', 'Func/conv_alstm_35/conv_lst_m2d/while_grad/body/_10165/input/_24749' -> 'conv_alstm_35/conv_lst_m2d/while_grad/body/_10165/gradients/AddN', 'Func/conv_alstm_36/conv_lst_m2d/while_grad/body/_9974/input/_24633' -> 'conv_alstm_36/conv_lst_m2d/while_grad/body/_9974/gradients/AddN', 'conv_alstm_21/conv_lst_m2d/while/body/_5240/clip_by_value' -> 'conv_alstm_21/conv_lst_m2d/while/body/_5240/mul_3', 'conv_alstm_21/conv_lst_m2d/while/body/_5240/mul_2' -> 'conv_alstm_21/conv_lst_m2d/while/body/_5240/add_5', 'conv_alstm_21/conv_lst_m2d/while/body/_5240/clip_by_value_2' -> 'conv_alstm_21/conv_lst_m2d/while/body/_5240/mul_5', 'conv_alstm_21/conv_lst_m2d/while/body/_5240/convolution_6' -> 'conv_alstm_21/conv_lst_m2d/while/body/_5240/add_4', 'conv_alstm_22/conv_lst_m2d/while/body/_5459/clip_by_value_2' -> 'conv_alstm_22/conv_lst_m2d/while/body/_5459/mul_5', 'conv_alstm_22/conv_lst_m2d/while/body/_5459/convolution_6' -> 'conv_alstm_22/conv_lst_m2d/while/body/_5459/add_4', 'conv_alstm_22/conv_lst_m2d/while/body/_5459/clip_by_value' -> 'conv_alstm_22/conv_lst_m2d/while/body/_5459/mul_3', 'conv_alstm_22/conv_lst_m2d/while/body/_5459/mul_2' -> 'conv_alstm_22/conv_lst_m2d/while/body/_5459/add_5', 'conv_alstm_23/conv_lst_m2d/while/body/_5678/clip_by_value_2' -> 'conv_alstm_23/conv_lst_m2d/while/body/_5678/mul_5', 'conv_alstm_23/conv_lst_m2d/while/body/_5678/convolution_6' -> 'conv_alstm_23/conv_lst_m2d/while/body/_5678/add_4', 'conv_alstm_23/conv_lst_m2d/while/body/_5678/clip_by_value' -> 'conv_alstm_23/conv_lst_m2d/while/body/_5678/mul_3', 'conv_alstm_23/conv_lst_m2d/while/body/_5678/mul_2' -> 'conv_alstm_23/conv_lst_m2d/while/body/_5678/add_5', 'conv_alstm_24/conv_lst_m2d/while/body/_5897/clip_by_value_2' -> 'conv_alstm_24/conv_lst_m2d/while/body/_5897/mul_5', 'conv_alstm_24/conv_lst_m2d/while/body/_5897/convolution_6' -> 'conv_alstm_24/conv_lst_m2d/while/body/_5897/add_4', 'conv_alstm_24/conv_lst_m2d/while/body/_5897/clip_by_value' -> 'conv_alstm_24/conv_lst_m2d/while/body/_5897/mul_3', 'conv_alstm_24/conv_lst_m2d/while/body/_5897/mul_2' -> 'conv_alstm_24/conv_lst_m2d/while/body/_5897/add_5', 'conv_alstm_25/conv_lst_m2d/while/body/_6116/clip_by_value_2' -> 'conv_alstm_25/conv_lst_m2d/while/body/_6116/mul_5', 'conv_alstm_25/conv_lst_m2d/while/body/_6116/convolution_6' -> 'conv_alstm_25/conv_lst_m2d/while/body/_6116/add_4', 'conv_alstm_25/conv_lst_m2d/while/body/_6116/clip_by_value' -> 'conv_alstm_25/conv_lst_m2d/while/body/_6116/mul_3', 'conv_alstm_25/conv_lst_m2d/while/body/_6116/mul_2' -> 'conv_alstm_25/conv_lst_m2d/while/body/_6116/add_5', 'conv_alstm_26/conv_lst_m2d/while/body/_6335/clip_by_value' -> 'conv_alstm_26/conv_lst_m2d/while/body/_6335/mul_3', 'conv_alstm_26/conv_lst_m2d/while/body/_6335/mul_2' -> 'conv_alstm_26/conv_lst_m2d/while/body/_6335/add_5', 'conv_alstm_26/conv_lst_m2d/while/body/_6335/clip_by_value_2' -> 'conv_alstm_26/conv_lst_m2d/while/body/_6335/mul_5', 'conv_alstm_26/conv_lst_m2d/while/body/_6335/convolution_6' -> 'conv_alstm_26/conv_lst_m2d/while/body/_6335/add_4', 'conv_alstm_27/conv_lst_m2d/while/body/_6554/convolution_6' -> 'conv_alstm_27/conv_lst_m2d/while/body/_6554/add_4', 'conv_alstm_27/conv_lst_m2d/while/body/_6554/clip_by_value' -> 'conv_alstm_27/conv_lst_m2d/while/body/_6554/mul_3', 'conv_alstm_27/conv_lst_m2d/while/body/_6554/mul_2' -> 'conv_alstm_27/conv_lst_m2d/while/body/_6554/add_5', 'conv_alstm_27/conv_lst_m2d/while/body/_6554/clip_by_value_2' -> 'conv_alstm_27/conv_lst_m2d/while/body/_6554/mul_5', 'conv_alstm_28/conv_lst_m2d/while/body/_6773/mul_2' -> 'conv_alstm_28/conv_lst_m2d/while/body/_6773/add_5', 'conv_alstm_29/conv_lst_m2d/while/body/_6992/clip_by_value_2' -> 'conv_alstm_29/conv_lst_m2d/while/body/_6992/mul_5', 'conv_alstm_29/conv_lst_m2d/while/body/_6992/convolution_6' -> 'conv_alstm_29/conv_lst_m2d/while/body/_6992/add_4', 'conv_alstm_29/conv_lst_m2d/while/body/_6992/clip_by_value' -> 'conv_alstm_29/conv_lst_m2d/while/body/_6992/mul_3', 'conv_alstm_29/conv_lst_m2d/while/body/_6992/mul_2' -> 'conv_alstm_29/conv_lst_m2d/while/body/_6992/add_5', 'conv_alstm_30/conv_lst_m2d/while/body/_7211/clip_by_value_2' -> 'conv_alstm_30/conv_lst_m2d/while/body/_7211/mul_5', 'conv_alstm_30/conv_lst_m2d/while/body/_7211/convolution_6' -> 'conv_alstm_30/conv_lst_m2d/while/body/_7211/add_4', 'conv_alstm_30/conv_lst_m2d/while/body/_7211/clip_by_value' -> 'conv_alstm_30/conv_lst_m2d/while/body/_7211/mul_3', 'conv_alstm_30/conv_lst_m2d/while/body/_7211/mul_2' -> 'conv_alstm_30/conv_lst_m2d/while/body/_7211/add_5', 'conv_alstm_31/conv_lst_m2d/while/body/_7430/mul_2' -> 'conv_alstm_31/conv_lst_m2d/while/body/_7430/add_5', 'conv_alstm_32/conv_lst_m2d/while/body/_7649/mul_2' -> 'conv_alstm_32/conv_lst_m2d/while/body/_7649/add_5', 'conv_alstm_33/conv_lst_m2d/while/body/_7868/clip_by_value' -> 'conv_alstm_33/conv_lst_m2d/while/body/_7868/mul_3', 'conv_alstm_33/conv_lst_m2d/while/body/_7868/mul_2' -> 'conv_alstm_33/conv_lst_m2d/while/body/_7868/add_5', 'conv_alstm_33/conv_lst_m2d/while/body/_7868/clip_by_value_2' -> 'conv_alstm_33/conv_lst_m2d/while/body/_7868/mul_5', 'conv_alstm_33/conv_lst_m2d/while/body/_7868/convolution_6' -> 'conv_alstm_33/conv_lst_m2d/while/body/_7868/add_4', 'conv_alstm_34/conv_lst_m2d/while/body/_8087/mul_2' -> 'conv_alstm_34/conv_lst_m2d/while/body/_8087/add_5', 'conv_alstm_35/conv_lst_m2d/while/body/_8306/clip_by_value' -> 'conv_alstm_35/conv_lst_m2d/while/body/_8306/mul_3', 'conv_alstm_35/conv_lst_m2d/while/body/_8306/mul_2' -> 'conv_alstm_35/conv_lst_m2d/while/body/_8306/add_5', 'conv_alstm_35/conv_lst_m2d/while/body/_8306/clip_by_value_2' -> 'conv_alstm_35/conv_lst_m2d/while/body/_8306/mul_5', 'conv_alstm_35/conv_lst_m2d/while/body/_8306/convolution_6' -> 'conv_alstm_35/conv_lst_m2d/while/body/_8306/add_4', 'conv_alstm_36/conv_lst_m2d/while/body/_8525/convolution_6' -> 'conv_alstm_36/conv_lst_m2d/while/body/_8525/add_4', 'conv_alstm_36/conv_lst_m2d/while/body/_8525/clip_by_value' -> 'conv_alstm_36/conv_lst_m2d/while/body/_8525/mul_3', 'conv_alstm_36/conv_lst_m2d/while/body/_8525/mul_2' -> 'conv_alstm_36/conv_lst_m2d/while/body/_8525/add_5', 'conv_alstm_36/conv_lst_m2d/while/body/_8525/clip_by_value_2' -> 'conv_alstm_36/conv_lst_m2d/while/body/_8525/mul_5', 'conv_alstm_37/conv_lst_m2d/while/body/_8744/convolution_6' -> 'conv_alstm_37/conv_lst_m2d/while/body/_8744/add_4', 'conv_alstm_37/conv_lst_m2d/while/body/_8744/clip_by_value' -> 'conv_alstm_37/conv_lst_m2d/while/body/_8744/mul_3', 'conv_alstm_37/conv_lst_m2d/while/body/_8744/mul_2' -> 'conv_alstm_37/conv_lst_m2d/while/body/_8744/add_5', 'conv_alstm_37/conv_lst_m2d/while/body/_8744/clip_by_value_2' -> 'conv_alstm_37/conv_lst_m2d/while/body/_8744/mul_5', 'conv_alstm_38/conv_lst_m2d/while/body/_8963/clip_by_value_2' -> 'conv_alstm_38/conv_lst_m2d/while/body/_8963/mul_5', 'conv_alstm_38/conv_lst_m2d/while/body/_8963/convolution_6' -> 'conv_alstm_38/conv_lst_m2d/while/body/_8963/add_4', 'conv_alstm_38/conv_lst_m2d/while/body/_8963/clip_by_value' -> 'conv_alstm_38/conv_lst_m2d/while/body/_8963/mul_3', 'conv_alstm_38/conv_lst_m2d/while/body/_8963/mul_2' -> 'conv_alstm_38/conv_lst_m2d/while/body/_8963/add_5', 'conv_alstm_39/conv_lst_m2d/while/body/_9182/mul_2' -> 'conv_alstm_39/conv_lst_m2d/while/body/_9182/add_5', 'conv_alstm_39/conv_lst_m2d/while/body/_9182/convolution_6' -> 'conv_alstm_39/conv_lst_m2d/while/body/_9182/add_4', 'conv_alstm_39/conv_lst_m2d/while/body/_9182/clip_by_value' -> 'conv_alstm_39/conv_lst_m2d/while/body/_9182/mul_3', 'conv_alstm_39/conv_lst_m2d/while/body/_9182/clip_by_value_2' -> 'conv_alstm_39/conv_lst_m2d/while/body/_9182/mul_5', 'Func/conv_alstm_38/conv_lst_m2d/while_grad/body/_9592/input/_24401' -> 'conv_alstm_38/conv_lst_m2d/while_grad/body/_9592/gradients/AddN', 'Func/conv_alstm_37/conv_lst_m2d/while_grad/body/_9783/input/_24517' -> 'conv_alstm_37/conv_lst_m2d/while_grad/body/_9783/gradients/AddN', 'conv_alstm_39/conv_lst_m2d/while_grad/body/_9401/gradients/AddN_2' -> 'conv_alstm_39/conv_lst_m2d/while_grad/next_iteration/_9558', 'conv_alstm_34/conv_lst_m2d/while/body/_8087/convolution_6' -> 'conv_alstm_34/conv_lst_m2d/while/body/_8087/add_4', 'conv_alstm_34/conv_lst_m2d/while/body/_8087/clip_by_value' -> 'conv_alstm_34/conv_lst_m2d/while/body/_8087/mul_3', 'conv_alstm_34/conv_lst_m2d/while/body/_8087/clip_by_value_2' -> 'conv_alstm_34/conv_lst_m2d/while/body/_8087/mul_5', 'conv_alstm_32/conv_lst_m2d/while/body/_7649/clip_by_value_2' -> 'conv_alstm_32/conv_lst_m2d/while/body/_7649/mul_5', 'conv_alstm_32/conv_lst_m2d/while/body/_7649/convolution_6' -> 'conv_alstm_32/conv_lst_m2d/while/body/_7649/add_4', 'conv_alstm_32/conv_lst_m2d/while/body/_7649/clip_by_value' -> 'conv_alstm_32/conv_lst_m2d/while/body/_7649/mul_3', 'conv_alstm_31/conv_lst_m2d/while/body/_7430/clip_by_value_2' -> 'conv_alstm_31/conv_lst_m2d/while/body/_7430/mul_5', 'conv_alstm_31/conv_lst_m2d/while/body/_7430/convolution_6' -> 'conv_alstm_31/conv_lst_m2d/while/body/_7430/add_4', 'conv_alstm_31/conv_lst_m2d/while/body/_7430/clip_by_value' -> 'conv_alstm_31/conv_lst_m2d/while/body/_7430/mul_3', 'conv_alstm_28/conv_lst_m2d/while/body/_6773/clip_by_value' -> 'conv_alstm_28/conv_lst_m2d/while/body/_6773/mul_3', 'conv_alstm_28/conv_lst_m2d/while/body/_6773/clip_by_value_2' -> 'conv_alstm_28/conv_lst_m2d/while/body/_6773/mul_5', 'conv_alstm_28/conv_lst_m2d/while/body/_6773/convolution_6' -> 'conv_alstm_28/conv_lst_m2d/while/body/_6773/add_4', 'conv_alstm_3/conv_lst_m2d/while/body/_1298/clip_by_value' -> 'conv_alstm_3/conv_lst_m2d/while/body/_1298/mul_3', 'conv_alstm_3/conv_lst_m2d/while/body/_1298/mul_2' -> 'conv_alstm_3/conv_lst_m2d/while/body/_1298/add_5', 'conv_alstm_3/conv_lst_m2d/while/body/_1298/clip_by_value_2' -> 'conv_alstm_3/conv_lst_m2d/while/body/_1298/mul_5', 'conv_alstm_3/conv_lst_m2d/while/body/_1298/convolution_6' -> 'conv_alstm_3/conv_lst_m2d/while/body/_1298/add_4', 'conv_alstm_4/conv_lst_m2d/while/body/_1517/mul_2' -> 'conv_alstm_4/conv_lst_m2d/while/body/_1517/add_5', 'conv_alstm_5/conv_lst_m2d/while/body/_1736/clip_by_value' -> 'conv_alstm_5/conv_lst_m2d/while/body/_1736/mul_3', 'conv_alstm_5/conv_lst_m2d/while/body/_1736/mul_2' -> 'conv_alstm_5/conv_lst_m2d/while/body/_1736/add_5', 'conv_alstm_5/conv_lst_m2d/while/body/_1736/clip_by_value_2' -> 'conv_alstm_5/conv_lst_m2d/while/body/_1736/mul_5', 'conv_alstm_5/conv_lst_m2d/while/body/_1736/convolution_6' -> 'conv_alstm_5/conv_lst_m2d/while/body/_1736/add_4', 'conv_alstm_6/conv_lst_m2d/while/body/_1955/convolution_6' -> 'conv_alstm_6/conv_lst_m2d/while/body/_1955/add_4', 'conv_alstm_6/conv_lst_m2d/while/body/_1955/clip_by_value' -> 'conv_alstm_6/conv_lst_m2d/while/body/_1955/mul_3', 'conv_alstm_6/conv_lst_m2d/while/body/_1955/mul_2' -> 'conv_alstm_6/conv_lst_m2d/while/body/_1955/add_5', 'conv_alstm_6/conv_lst_m2d/while/body/_1955/clip_by_value_2' -> 'conv_alstm_6/conv_lst_m2d/while/body/_1955/mul_5', 'conv_alstm_7/conv_lst_m2d/while/body/_2174/mul_2' -> 'conv_alstm_7/conv_lst_m2d/while/body/_2174/add_5', 'conv_alstm_8/conv_lst_m2d/while/body/_2393/mul_2' -> 'conv_alstm_8/conv_lst_m2d/while/body/_2393/add_5', 'conv_alstm_9/conv_lst_m2d/while/body/_2612/clip_by_value' -> 'conv_alstm_9/conv_lst_m2d/while/body/_2612/mul_3', 'conv_alstm_9/conv_lst_m2d/while/body/_2612/mul_2' -> 'conv_alstm_9/conv_lst_m2d/while/body/_2612/add_5', 'conv_alstm_9/conv_lst_m2d/while/body/_2612/clip_by_value_2' -> 'conv_alstm_9/conv_lst_m2d/while/body/_2612/mul_5', 'conv_alstm_9/conv_lst_m2d/while/body/_2612/convolution_6' -> 'conv_alstm_9/conv_lst_m2d/while/body/_2612/add_4', 'conv_alstm_10/conv_lst_m2d/while/body/_2831/clip_by_value_2' -> 'conv_alstm_10/conv_lst_m2d/while/body/_2831/mul_5', 'conv_alstm_10/conv_lst_m2d/while/body/_2831/convolution_6' -> 'conv_alstm_10/conv_lst_m2d/while/body/_2831/add_4', 'conv_alstm_10/conv_lst_m2d/while/body/_2831/clip_by_value' -> 'conv_alstm_10/conv_lst_m2d/while/body/_2831/mul_3', 'conv_alstm_10/conv_lst_m2d/while/body/_2831/mul_2' -> 'conv_alstm_10/conv_lst_m2d/while/body/_2831/add_5', 'conv_alstm_11/conv_lst_m2d/while/body/_3050/mul_2' -> 'conv_alstm_11/conv_lst_m2d/while/body/_3050/add_5', 'conv_alstm_11/conv_lst_m2d/while/body/_3050/clip_by_value_2' -> 'conv_alstm_11/conv_lst_m2d/while/body/_3050/mul_5', 'conv_alstm_11/conv_lst_m2d/while/body/_3050/convolution_6' -> 'conv_alstm_11/conv_lst_m2d/while/body/_3050/add_4', 'conv_alstm_11/conv_lst_m2d/while/body/_3050/clip_by_value' -> 'conv_alstm_11/conv_lst_m2d/while/body/_3050/mul_3', 'conv_alstm_12/conv_lst_m2d/while/body/_3269/clip_by_value' -> 'conv_alstm_12/conv_lst_m2d/while/body/_3269/mul_3', 'conv_alstm_12/conv_lst_m2d/while/body/_3269/mul_2' -> 'conv_alstm_12/conv_lst_m2d/while/body/_3269/add_5', 'conv_alstm_12/conv_lst_m2d/while/body/_3269/clip_by_value_2' -> 'conv_alstm_12/conv_lst_m2d/while/body/_3269/mul_5', 'conv_alstm_12/conv_lst_m2d/while/body/_3269/convolution_6' -> 'conv_alstm_12/conv_lst_m2d/while/body/_3269/add_4', 'conv_alstm_13/conv_lst_m2d/while/body/_3488/clip_by_value' -> 'conv_alstm_13/conv_lst_m2d/while/body/_3488/mul_3', 'conv_alstm_13/conv_lst_m2d/while/body/_3488/mul_2' -> 'conv_alstm_13/conv_lst_m2d/while/body/_3488/add_5', 'conv_alstm_13/conv_lst_m2d/while/body/_3488/clip_by_value_2' -> 'conv_alstm_13/conv_lst_m2d/while/body/_3488/mul_5', 'conv_alstm_13/conv_lst_m2d/while/body/_3488/convolution_6' -> 'conv_alstm_13/conv_lst_m2d/while/body/_3488/add_4', 'conv_alstm_14/conv_lst_m2d/while/body/_3707/clip_by_value' -> 'conv_alstm_14/conv_lst_m2d/while/body/_3707/mul_3', 'conv_alstm_14/conv_lst_m2d/while/body/_3707/mul_2' -> 'conv_alstm_14/conv_lst_m2d/while/body/_3707/add_5', 'conv_alstm_14/conv_lst_m2d/while/body/_3707/clip_by_value_2' -> 'conv_alstm_14/conv_lst_m2d/while/body/_3707/mul_5', 'conv_alstm_14/conv_lst_m2d/while/body/_3707/convolution_6' -> 'conv_alstm_14/conv_lst_m2d/while/body/_3707/add_4', 'conv_alstm_15/conv_lst_m2d/while/body/_3926/convolution_6' -> 'conv_alstm_15/conv_lst_m2d/while/body/_3926/add_4', 'conv_alstm_15/conv_lst_m2d/while/body/_3926/clip_by_value' -> 'conv_alstm_15/conv_lst_m2d/while/body/_3926/mul_3', 'conv_alstm_15/conv_lst_m2d/while/body/_3926/mul_2' -> 'conv_alstm_15/conv_lst_m2d/while/body/_3926/add_5', 'conv_alstm_15/conv_lst_m2d/while/body/_3926/clip_by_value_2' -> 'conv_alstm_15/conv_lst_m2d/while/body/_3926/mul_5', 'conv_alstm_16/conv_lst_m2d/while/body/_4145/clip_by_value_2' -> 'conv_alstm_16/conv_lst_m2d/while/body/_4145/mul_5', 'conv_alstm_16/conv_lst_m2d/while/body/_4145/convolution_6' -> 'conv_alstm_16/conv_lst_m2d/while/body/_4145/add_4', 'conv_alstm_16/conv_lst_m2d/while/body/_4145/clip_by_value' -> 'conv_alstm_16/conv_lst_m2d/while/body/_4145/mul_3', 'conv_alstm_16/conv_lst_m2d/while/body/_4145/mul_2' -> 'conv_alstm_16/conv_lst_m2d/while/body/_4145/add_5', 'conv_alstm_17/conv_lst_m2d/while/body/_4364/clip_by_value_2' -> 'conv_alstm_17/conv_lst_m2d/while/body/_4364/mul_5', 'conv_alstm_17/conv_lst_m2d/while/body/_4364/convolution_6' -> 'conv_alstm_17/conv_lst_m2d/while/body/_4364/add_4', 'conv_alstm_17/conv_lst_m2d/while/body/_4364/clip_by_value' -> 'conv_alstm_17/conv_lst_m2d/while/body/_4364/mul_3', 'conv_alstm_17/conv_lst_m2d/while/body/_4364/mul_2' -> 'conv_alstm_17/conv_lst_m2d/while/body/_4364/add_5', 'conv_alstm_18/conv_lst_m2d/while/body/_4583/clip_by_value_2' -> 'conv_alstm_18/conv_lst_m2d/while/body/_4583/mul_5', 'conv_alstm_18/conv_lst_m2d/while/body/_4583/convolution_6' -> 'conv_alstm_18/conv_lst_m2d/while/body/_4583/add_4', 'conv_alstm_18/conv_lst_m2d/while/body/_4583/clip_by_value' -> 'conv_alstm_18/conv_lst_m2d/while/body/_4583/mul_3', 'conv_alstm_18/conv_lst_m2d/while/body/_4583/mul_2' -> 'conv_alstm_18/conv_lst_m2d/while/body/_4583/add_5', 'conv_alstm_19/conv_lst_m2d/while/body/_4802/mul_2' -> 'conv_alstm_19/conv_lst_m2d/while/body/_4802/add_5', 'conv_alstm_20/conv_lst_m2d/while/body/_5021/mul_2' -> 'conv_alstm_20/conv_lst_m2d/while/body/_5021/add_5', 'conv_alstm_20/conv_lst_m2d/while/body/_5021/clip_by_value_2' -> 'conv_alstm_20/conv_lst_m2d/while/body/_5021/mul_5', 'conv_alstm_20/conv_lst_m2d/while/body/_5021/convolution_6' -> 'conv_alstm_20/conv_lst_m2d/while/body/_5021/add_4', 'conv_alstm_20/conv_lst_m2d/while/body/_5021/clip_by_value' -> 'conv_alstm_20/conv_lst_m2d/while/body/_5021/mul_3', 'conv_alstm_19/conv_lst_m2d/while/body/_4802/clip_by_value_2' -> 'conv_alstm_19/conv_lst_m2d/while/body/_4802/mul_5', 'conv_alstm_19/conv_lst_m2d/while/body/_4802/convolution_6' -> 'conv_alstm_19/conv_lst_m2d/while/body/_4802/add_4', 'conv_alstm_19/conv_lst_m2d/while/body/_4802/clip_by_value' -> 'conv_alstm_19/conv_lst_m2d/while/body/_4802/mul_3', 'conv_alstm_8/conv_lst_m2d/while/body/_2393/clip_by_value_2' -> 'conv_alstm_8/conv_lst_m2d/while/body/_2393/mul_5', 'conv_alstm_8/conv_lst_m2d/while/body/_2393/convolution_6' -> 'conv_alstm_8/conv_lst_m2d/while/body/_2393/add_4', 'conv_alstm_8/conv_lst_m2d/while/body/_2393/clip_by_value' -> 'conv_alstm_8/conv_lst_m2d/while/body/_2393/mul_3', 'conv_alstm_7/conv_lst_m2d/while/body/_2174/clip_by_value_2' -> 'conv_alstm_7/conv_lst_m2d/while/body/_2174/mul_5', 'conv_alstm_7/conv_lst_m2d/while/body/_2174/convolution_6' -> 'conv_alstm_7/conv_lst_m2d/while/body/_2174/add_4', 'conv_alstm_7/conv_lst_m2d/while/body/_2174/clip_by_value' -> 'conv_alstm_7/conv_lst_m2d/while/body/_2174/mul_3', 'conv_alstm_4/conv_lst_m2d/while/body/_1517/convolution_6' -> 'conv_alstm_4/conv_lst_m2d/while/body/_1517/add_4', 'conv_alstm_4/conv_lst_m2d/while/body/_1517/clip_by_value' -> 'conv_alstm_4/conv_lst_m2d/while/body/_1517/mul_3', 'conv_alstm_4/conv_lst_m2d/while/body/_1517/clip_bdy/_3488/mul_3', 'conv_alstm_13/conv_lst_m2d/while/body/_3488/mul_2' -> 'conv_alstm_13/conv_lst_m2d/while/body/_3488/add_5', 'conv_alstm_13/conv_lst_m2d/while/body/_3488/clip_by_value_2' -> 'conv_alstm_13/conv_lst_m2d/while/body/_3488/mul_5', 'conv_alstm_13/conv_lst_m2d/while/body/_3488/convolution_6' -> 'conv_alstm_13/conv_lst_m2d/while/body/_3488/add_4', 'conv_alstm_14/conv_lst_m2d/while/body/_3707/clip_by_value' -> 'conv_alstm_14/conv_lst_m2d/while/body/_3707/mul_3', 'conv_alstm_14/conv_lst_m2d/while/body/_3707/mul_2' -> 'conv_alstm_14/conv_lst_m2d/while/body/_3707/add_5', 'conv_alstm_14/conv_lst_m2d/while/body/_3707/clip_by_value_2' -> 'conv_alstm_14/conv_lst_m2d/while/body/_3707/mul_5', 'conv_alstm_14/conv_lst_m2d/while/body/_3707/convolution_6' -> 'conv_alstm_14/conv_lst_m2d/while/body/_3707/add_4', 'conv_alstm_15/conv_lst_m2d/while/body/_3926/convolution_6' -> 'conv_alstm_15/conv_lst_m2d/while/body/_3926/add_4', 'conv_alstm_15/conv_lst_m2d/while/body/_3926/clip_by_value' -> 'conv_alstm_15/conv_lst_m2d/while/body/_3926/mul_3', 'conv_alstm_15/conv_lst_m2d/while/body/_3926/mul_2' -> 'conv_alstm_15/conv_lst_m2d/while/body/_3926/add_5', 'conv_alstm_15/conv_lst_m2d/while/body/_3926/clip_by_value_2' -> 'conv_alstm_15/conv_lst_m2d/while/body/_3926/mul_5', 'conv_alstm_16/conv_lst_m2d/while/body/_4145/clip_by_value_2' -> 'conv_alstm_16/conv_lst_m2d/while/body/_4145/mul_5', 'conv_alstm_16/conv_lst_m2d/while/body/_4145/convolution_6' -> 'conv_alstm_16/conv_lst_m2d/while/body/_4145/add_4', 'conv_alstm_16/conv_lst_m2d/while/body/_4145/clip_by_value' -> 'con\r\nv_alstm_16/conv_lst_m2d/while/body/_4145/mul_3', 'conv_alstm_16/conv_lst_m2d/while/body/_4145/mul_2' -> 'conv_alstm_16/conv_lst_m2d/while/body/_4145/add_5', 'conv_alstm_17/conv_lst_m2d/while/body/_\r\n4364/clip_by_value_2' -> 'conv_alstm_17/conv_lst_m2d/while/body/_4364/mul_5', 'conv_alstm_17/conv_lst_m2d/while/body/_4364/convolution_6' -> 'conv_alstm_17/conv_lst_m2d/while/body/_4364/add_4', 'co\r\nnv_alstm_17/conv_lst_m2d/while/body/_4364/clip_by_value' -> 'conv_alstm_17/conv_lst_m2d/while/body/_4364/mul_3', 'conv_alstm_17/conv_lst_m2d/while/body/_4364/mul_2' -> 'conv_alstm_17/conv_lst_m2d/w\r\nhile/body/_4364/add_5', 'conv_alstm_18/conv_lst_m2d/while/body/_4583/clip_by_value_2' -> 'conv_alstm_18/conv_lst_m2d/while/body/_4583/mul_5', 'conv_alstm_18/conv_lst_m2d/while/body/_4583/convolutio\r\nn_6' -> 'conv_alstm_18/conv_lst_m2d/while/body/_4583/add_4', 'conv_alstm_18/conv_lst_m2d/while/body/_4583/clip_by_value' -> 'conv_alstm_18/conv_lst_m2d/while/body/_4583/mul_3', 'conv_alstm_18/conv_\r\nlst_m2d/while/body/_4583/mul_2' -> 'conv_alstm_18/conv_lst_m2d/while/body/_4583/add_5', 'conv_alstm_19/conv_lst_m2d/while/body/_4802/mul_2' -> 'conv_alstm_19/conv_lst_m2d/while/body/_4802/add_5', '\r\nconv_alstm_20/conv_lst_m2d/while/body/_5021/mul_2' -> 'conv_alstm_20/conv_lst_m2d/while/body/_5021/add_5', 'conv_alstm_20/conv_lst_m2d/while/body/_5021/clip_by_value_2' -> 'conv_alstm_20/conv_lst_m\r\n2d/while/body/_5021/mul_5', 'conv_alstm_20/conv_lst_m2d/while/body/_5021/convolution_6' -> 'conv_alstm_20/conv_lst_m2d/while/body/_5021/add_4', 'conv_alstm_20/conv_lst_m2d/while/body/_5021/clip_by_\r\nvalue' -> 'conv_alstm_20/conv_lst_m2d/while/body/_5021/mul_3', 'conv_alstm_19/conv_lst_m2d/while/body/_4802/clip_by_value_2' -> 'conv_alstm_19/conv_lst_m2d/while/body/_4802/mul_5', 'conv_alstm_19/c\r\nonv_lst_m2d/while/body/_4802/convolution_6' -> 'conv_alstm_19/conv_lst_m2d/while/body/_4802/add_4', 'conv_alstm_19/conv_lst_m2d/while/body/_4802/clip_by_value' -> 'conv_alstm_19/conv_lst_m2d/while/\r\nbody/_4802/mul_3', 'conv_alstm_8/conv_lst_m2d/while/body/_2393/clip_by_value_2' -> 'conv_alstm_8/conv_lst_m2d/while/body/_2393/mul_5', 'conv_alstm_8/conv_lst_m2d/while/body/_2393/convolution_6' -> \r\n'conv_alstm_8/conv_lst_m2d/while/body/_2393/add_4', 'conv_alstm_8/conv_lst_m2d/while/body/_2393/clip_by_value' -> 'conv_alstm_8/conv_lst_m2d/while/body/_2393/mul_3', 'conv_alstm_7/conv_lst_m2d/whil\r\ne/body/_2174/clip_by_value_2' -> 'conv_alstm_7/conv_lst_m2d/while/body/_2174/mul_5', 'conv_alstm_7/conv_lst_m2d/while/body/_2174/convolution_6' -> 'conv_alstm_7/conv_lst_m2d/while/body/_2174/add_4'\r\n, 'conv_alstm_7/conv_lst_m2d/while/body/_2174/clip_by_value' -> 'conv_alstm_7/conv_lst_m2d/while/body/_2174/mul_3', 'conv_alstm_4/conv_lst_m2d/while/body/_1517/convolution_6' -> 'conv_alstm_4/conv_\r\nlst_m2d/while/body/_1517/add_4', 'conv_alstm_4/conv_lst_m2d/while/body/_1517/clip_by_value' -> 'conv_alstm_4/conv_lst_m2d/while/body/_1517/mul_3', 'conv_alstm_4/conv_lst_m2d/while/body/_1517/clip_b\r\ny_value_2' -> 'conv_alstm_4/conv_lst_m2d/while/body/_1517/mul_5', 'conv_alstm_1/conv_lst_m2d/while/body/_860/clip_by_value' -> 'conv_alstm_1/conv_lst_m2d/while/body/_860/mul_3', 'conv_alstm_1/conv_\r\nlst_m2d/while/body/_860/mul_2' -> 'conv_alstm_1/conv_lst_m2d/while/body/_860/add_5', 'conv_alstm_1/conv_lst_m2d/while/body/_860/clip_by_value_2' -> 'conv_alstm_1/conv_lst_m2d/while/body/_860/mul_5'\r\n, 'conv_alstm_1/conv_lst_m2d/while/body/_860/convolution_6' -> 'conv_alstm_1/conv_lst_m2d/while/body/_860/add_4', 'conv_alstm_2/conv_lst_m2d/while/body/_1079/clip_by_value' -> 'conv_alstm_2/conv_ls\r\nt_m2d/while/body/_1079/mul_3', 'conv_alstm_2/conv_lst_m2d/while/body/_1079/mul_2' -> 'conv_alstm_2/conv_lst_m2d/while/body/_1079/add_5', 'conv_alstm_2/conv_lst_m2d/while/body/_1079/clip_by_value_2'\r\n -> 'conv_alstm_2/conv_lst_m2d/while/body/_1079/mul_5', 'conv_alstm_2/conv_lst_m2d/while/body/_1079/convolution_6' -> 'conv_alstm_2/conv_lst_m2d/while/body/_1079/add_4', 'conv_alstm/conv_lst_m2d/wh\r\nile/body/_641/mul_2' -> 'conv_alstm/conv_lst_m2d/while/body/_641/add_5', 'conv_alstm/conv_lst_m2d/while/body/_641/clip_by_value' -> 'conv_alstm/conv_lst_m2d/while/body/_641/mul_3', 'conv_alstm/conv\r\n_lst_m2d/while/body/_641/clip_by_value_2' -> 'conv_alstm/conv_lst_m2d/while/body/_641/mul_5', 'conv_alstm/conv_lst_m2d/while/body/_641/convolution_6' -> 'conv_alstm/conv_lst_m2d/while/body/_641/add\r\n_4'}.`\r\n\r\n\r\n\r\n", "comments": ["I'm facing same issue.", "I have the same problem too", "Same issue with ConvLSTM layer", "I have the same issue with **TimeDistributed** method", "I have similar error\r\n\r\nTensorFlow 2.2 installed using pip\r\nKeras 2.4.3 installed using pip\r\nRTX 2060, cuda 10.1, windows 10\r\nPython 3.8.3\r\nhappens during first fit on ConvLSTM2D, but seems to be working fine after that\r\nI'm using custom code for reinforcement learning\r\n\r\n\"lr0.001\" is the name of input (ConvLSTM2D) layer\r\n\r\n```\r\n2020-07-30 15:47:18.867612: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:563] layout failed: Invalid argument: MutableGraphView::SortTopologically error: detected edge(s) creating cycle(s) {'sequential/lr0.001/while/body/_1/Relu_1' -> 'sequential/lr0.001/while/body/_1/mul_5', 'sequential/lr0.001/while/body/_1/mul_2' -> 'sequential/lr0.001/while/body/_1/add_5', 'sequential/lr0.001/while/body/_1/convolution_7' -> 'sequential/lr0.001/while/body/_1/add_6'}.\r\n2020-07-30 15:47:20.296325: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:563] layout failed: Invalid argument: MutableGraphView::SortTopologically error: detected edge(s) creating cycle(s) {'Func/gradient_tape/sequential/lr0.001/while/sequential/lr0.001/while_grad/body/_179/input/_529' -> 'gradient_tape/sequential/lr0.001/while/sequential/lr0.001/while_grad/body/_179/gradients/AddN', 'Func/sequential/lr0.001/while/body/_1/input/_414' -> 'sequential/lr0.001/while/body/_1/mul_2', 'sequential/lr0.001/while/body/_1/mul_5' -> 'sequential/lr0.001/while/next_iteration/_148'}.\r\nepisode: 1/1000, steps: 10, reward: 2.04, highest reward: 2.04, last 20 average: 2.04, e: 1.0, memory: 10\r\n2020-07-30 15:47:27.284583: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:563] layout failed: Invalid argument: MutableGraphView::SortTopologically error: detected edge(s) creating cycle(s) {'sequential/lr0.001/while/body/_1/Relu_1' -> 'sequential/lr0.001/while/body/_1/mul_5', 'sequential/lr0.001/while/body/_1/mul_2' -> 'sequential/lr0.001/while/body/_1/add_5', 'sequential/lr0.001/while/body/_1/convolution_7' -> 'sequential/lr0.001/while/body/_1/add_6'}.\r\n```", "I am also seeing this issue, regardless of layer.stateful. \r\nIt happens for all calls to `fit` or `apply_gradients` on a model that includes `ConvLSTM2D`. \r\nThe presence of a `TimeDistributed` layer seems not to influence it.\r\nThe model is extremely slow, even compared to much larger models.\r\n\r\nI am not completely sure, but it seems using CPU-only does not show this behaviour.\r\nCan someone else check this too?\r\n\r\nBut apart from being really slow, it seems the layers are doing whatever they are supposed to do and produce results.\r\n\r\nTF: 2.3.0\r\nPython: 3.6.9\r\nUbuntu: 18.04\r\nGPU: RTX2060S 8GB driver: 450.66\r\nCUDA: 11.0\r\n\r\n", "Facing the same problem. Fix or advice on workaround would be desirable. Thank you \ud83d\ude4f ", "A small example that on GPU reproduces this (works on CPU for me):\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\nprint(tf.__version__)\r\n\r\nx_input = tf.keras.Input((8,8,8,1),batch_size=1)\r\nx = tf.keras.layers.ConvLSTM2D(4,(2,2),return_sequences=True)(x_input)\r\nx = tf.keras.layers.MaxPooling3D((1, 2, 2))(x)\r\nx = tf.keras.layers.Flatten()(x)\r\nx_output = tf.keras.layers.Dense(1)(x)\r\nmodel = tf.keras.Model(inputs=x_input,outputs=x_output)\r\n\r\nmodel.compile(loss='mse',optimizer='adam')\r\n\r\ndata_in = np.random.rand(1,8,8,8,1).astype(np.float32)\r\ndata_out = np.random.rand(1,1).astype(np.float32)\r\n\r\nr = model.fit(data_in,data_out)\r\nprint(r)\r\n\r\n```", "Seems the problem lies within Grappler's layout optimizer [or the layer breaking it]- as the the error message states. You can disable it like this:\r\n`tf.config.optimizer.set_experimental_options({'layout_optimizer': False})`\r\nHowever, this basically hides the error, and the performance penalty of not having the layout optimized remains.\r\n\r\nEdit: Also the issue still appears on today's tf-nightly.", "In my setup, the error is linked to `tf.random.set_seed`. If I use the stateless versions of the random functions, the error only occurs once and works for subsequent batches. If I call `set_seed `every time, the error occurs at every call of the `tf.function`.", "ninnghazad is correct. After adding the line of code, the error is hided with TensorFlow 2.2. So it is the bug of TF2.2 ", "Just to note that I am having the same warning/error.  I am using TF 2.3.1.\r\n\r\nThe strange thing is that some code I have using ConvLSTM2D doesnt spit it out, it only happens when I set the initial state, but it also happens with the code from @ninnghazad , which is strange, because it is quite a simple code, and some of my other convlstm2d with no error are more complex.", "Hi all,\r\nI have the same error. while I am running the same code in windows(tensorflow1.14 and 2.1) doesn't get that error. but I got it when I run on HPC using the Linux platform(tensorflow2.3).\r\nI added the line \r\ntf.config.optimizer.set_experimental_options({'layout_optimizer': False}) , it hides the error but not solve the problem, and learning is not improved and the loss increase. any advice?\r\n", "I have the same issue.\r\nMicrosoft Windows [Version 10.0.18363.1198]\r\nPython 3.7.9\r\nTensorflow 2.1.0 and 2.3.1 - Installed with pip\r\nConvLSTM2D\r\n\r\nThe error disapear when GPU is disabled with\r\nos.environ['CUDA_VISIBLE_DEVICES'] = '-1'", "I got the same issue.\r\nMicrosoft Windows 10 Pro, build 19042.746\r\nPython 3.7.7\r\nTensorflow 2.4.1 - installed with pip\r\n\r\nUsing ConvLSTM2D produces this error. The training seems to be unusually slow.", "> I have the same issue.\r\n> Microsoft Windows [Version 10.0.18363.1198]\r\n> Python 3.7.9\r\n> Tensorflow 2.1.0 and 2.3.1 - Installed with pip\r\n> ConvLSTM2D\r\n> \r\n> The error disapear when GPU is disabled with\r\n> os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\r\n\r\nAny news regarding this?", "Experiencing the same issue.\r\n\r\n- ubuntu 16.04\r\n- gcc (GCC) 8.2.1 20180905\r\n- python 3.7.10\r\n- tensorflow v2.5.0-rc1\r\n- cuda 11.1\r\n- cudnn 8\r\n\r\nAs others have stated, it occurs when using ConvLSTM2D and seems to be accompanied by a massive drop in performance.\r\n\r\n[This](https://github.com/tensorflow/tensorflow/issues/38279) seems to reference a similar issue.", "> A small example that on GPU reproduces this (works on CPU for me):\r\n> \r\n> ```\r\n> import tensorflow as tf\r\n> import numpy as np\r\n> print(tf.__version__)\r\n> \r\n> x_input = tf.keras.Input((8,8,8,1),batch_size=1)\r\n> x = tf.keras.layers.ConvLSTM2D(4,(2,2),return_sequences=True)(x_input)\r\n> x = tf.keras.layers.MaxPooling3D((1, 2, 2))(x)\r\n> x = tf.keras.layers.Flatten()(x)\r\n> x_output = tf.keras.layers.Dense(1)(x)\r\n> model = tf.keras.Model(inputs=x_input,outputs=x_output)\r\n> \r\n> model.compile(loss='mse',optimizer='adam')\r\n> \r\n> data_in = np.random.rand(1,8,8,8,1).astype(np.float32)\r\n> data_out = np.random.rand(1,1).astype(np.float32)\r\n> \r\n> r = model.fit(data_in,data_out)\r\n> print(r)\r\n> ```\r\n\r\n@ninnghazad I did not face any error in Tensorflow 2.4 GPU, please find the gist [here](https://colab.research.google.com/gist/sachinprasadhs/2f4972c2463a6e64cf1246148443fffc/35650.ipynb).Thanks!", "Was able to run the code successfully without any error using Tensorflow GPU 2.5, please find the gist [here](https://colab.research.google.com/gist/sachinprasadhs/90cb989dde90cb0375472c3fea315b33/36901.ipynb) and confirm if we are good to close this issue. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36901\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36901\">No</a>\n"]}]