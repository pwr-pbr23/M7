[{"number": 1690, "title": "'Graph' object has no attribute 'SerializeToString' when run 'sudo python cifar10_train.py'", "body": "### Environment info\n\nOperating System:\nMac os 10.10.5\n\nI install the Tensorflow with `sudo pip install --upgrade https://storage.googleapis.com/tensorflow/mac/tensorflow-0.7.1-cp27-none-any.whl`\n\nand run\n`sudo python cifar10_train.py`\n\nI got an error.\n### ERROR in shell\n\n```\n$ sudo python cifar10_train.py \nFilling queue with 20000 CIFAR images before starting to train. This will take a few minutes.\nTraceback (most recent call last):\n  File \"cifar10_train.py\", line 134, in <module>\n    tf.app.run()\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/platform/default/_app.py\", line 30, in run\n    sys.exit(main(sys.argv))\n  File \"cifar10_train.py\", line 130, in main\n    train()\n  File \"cifar10_train.py\", line 96, in train\n    summary_writer = tf.train.SummaryWriter(FLAGS.train_dir, sess.graph)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/summary_io.py\", line 104, in __init__\n    self.add_graph(graph_def)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/summary_io.py\", line 168, in add_graph\n    graph_bytes = graph_def.SerializeToString()\nAttributeError: 'Graph' object has no attribute 'SerializeToString'\n```\n\nPlease help.\n", "comments": ["Check out the github repo at the r0.7 branch if you want to run code using 0.7.1 -- github master may introduce incompatibilities with the pip installs until we reach 1.0\n", "@vrv well this dont solve the question.\nIf we follow the instruction [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md) get this error because you say that version 0.7.1 make some incompatibilities for pip.\nSo I try to follow your advice cloning from 0.7 branch, but there are the problem of `ImportError: No module named tensorflow`.\n", "Has anyone resolved this issue? \n\nI've tried changing my version to 7.1 using:\n\n`sudo pip install --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.7.1-cp27-none-linux_x86_64.whl`\n\nAs well as changing the branch of tensorflow to the r0.7 branch:\nthe output of `git branch`\n\n`* (HEAD detached at origin/r0.7)\n  master\n`\nHowever I still receive `AttributeError: 'Graph' object has no attribute 'SerializeToString'` upon running `sudo python cifar10_train.py`\n\n@vrv Is there anything I'm missing to run the old version of the example here? \n\nEDIT\nI'm running ubuntu 14.04\n", "I would try upgrading to 0.8 now, there might have been some fixes since then.\n\nIf not, can you paste the entire stack trace, so we can see where this might be coming from?\n", "Thanks for your timely response @vrv ! :) Upgrading to 8.0 did the trick. \n\nJust in case anyone doesn't feel like going to the site, here's the command to upgrade:\n`sudo pip install --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.8.0rc0-cp27-none-linux_x86_64.whl`\n", "This problem has been solved by upgrading to 8.0. Thanks for everyone.\n", "File \"cifar10_train.py\", line 96, in train\n`summary_writer = tf.train.SummaryWriter(FLAGS.train_dir, sess.graph)\n`\nthis should be \n\n`summary_writer = tf.train.SummaryWriter(FLAGS.train_dir, sess.graph.as_graph_def())\n`\nIt should solve the problem without upgrading Tensorflow.\n", "Thanks, updating tensorflow to 0.8 could solve the problem indeed.\n"]}, {"number": 1689, "title": "The time cost of Tensorflow is confused", "body": "I want to improve the speed of the convolution layer. I measure the cost of two different filters.\nthe shape of these two filters are [1,5,3,64] and[5,5,3,64]. The computation of the latter one is five times   as much as the former one, however, the time cost are almost the same  of these two convolution layer. \nconv = tf.nn.conv2d(images, kernel1, [1, 1, 1, 1], padding='SAME') \nconv = tf.nn.conv2d(images, kernel2, [1, 1, 1, 1], padding='SAME')\nwhat is the reason that the cost can not be improved?\n", "comments": ["What do you mean by \"time cost\"? Do you mean the time to run the operation? If so, how are you measuring it? Can you please provide some more details?\n", "@keveman  That is right, I mean the time to run the operation. The way which I used to measure it is just like the example of  alexnet_benchmark.py, here is the code: \n\n``` python\ndef inference(images, sep_kernels):\n        conv_sepf = tf.nn.conv2d(images, sep_kernelf, [1, 1, 1, 1], padding='SAME')\n\n        return conv_sepf\n```\n\n``` python\ndef time_tensorflow_run(target,session):\n    num_steps_burn_in = 10\n    total_duration = 0.0\n    for i in xrange(100 + num_steps_burn_in):\n        start_time = time.time()\n        _ = session.run(target)\n        duration = time.time() - start_time\n        if i > num_steps_burn_in:\n          if not i % 10:\n            print ('%s: step %d, duration = %.5f' %\n               (datetime.now(), i - num_steps_burn_in, duration))\n          total_duration += duration\n    mn = total_duration / 100\n    print ('%s:  100 steps, %.5f sec' %\n         (datetime.now(),mn))\n```\n\n``` python\ndef run_benchmark():\n    with tf.Graph().as_default():\n        images = np.load(\"iamges_value.npy\")\n        sep_kernels = np.load(\"sep_value2.npy\")\n        conv = inference(images, sep_kernels)\n\n        init = tf.initialize_all_variables()\n        sess = tf.Session()\n        sess.run(init)\n\n        time_tensorflow_run(conv, sess)\n    print(\"job done!\")\n\n\ndef main(_):\n    run_benchmark()\n\n\nif __name__ == '__main__':\n    tf.app.run()\n```\n\nThanks`\n", "Thanks for the details. Your methodology looks good. You are running on the CPU, yes? TensorFlow uses Eigen for CPU convolutions and cuDNN for GPU convolutions. It's quite possible that the implementation used for 1,1,3,64 convolution is not as efficient as the larger one, hence your observation. Can you try it on as GPU?\n", "@keveman  No , I am running on GPU gtx970. Now I also try it on CPU. The time cost of the small filter is less than the large filter on CPU.\n", "Unless I'm missing something, your timing loop appears to fetch the result of the convolution each time and discard it? Depending on the image sizes you may just be measuring serialization overheads. (though I may be missing something since the function inference() in your  code snippet appears to have some typos?)\n\nTo benchmark the cost of just the convolution, do session.run(target.op)  \n", "@MisayaZ, it is true that the filter size [5, 5, 3, 64] entails five times more computation than [1, 5, 3, 64]. However, the actual run times depend heavily on the implementation, memory access to computation ratio etc. So there is no way to guarantee any correlation between actual computation and run times. Also, we make use of external implementation such as cuDNN for the kernels. Hopefully those libraries will keep getting better. I am closing this issue as we don't plan to do anything special in TensorFlow for this.\n", "@prb12 sorry, I have fix the function inference().\n"]}, {"number": 1688, "title": "A small bug in tutorials/mnist/mnist_with_summaries.py", "body": "Please fix the bug in **Line 85** of file _tensorflow/tensorflow/examples/tutorials/mnist/mnist_with_summaries.py_\nthe code \n`writer = tf.train.SummaryWriter(FLAGS.summaries_dir, sess.graph)` \nshould be changed to \n`writer = tf.train.SummaryWriter(FLAGS.summaries_dir, sess.graph.as_graph_def())`,\notherwise there will be an error `'Graph' object has no attribute 'SerializeToString'`\n", "comments": ["I look at the history of this file and find that the line 85 is changed to fit for the new API, which is somehow not consistent with the API in 0.7.1. Maybe some comments  here should be added in this file as it is linked in the tutorial of the official website.\n", "The link from the website actually points to the r0.7 version of the branch: https://github.com/tensorflow/tensorflow/blob/r0.7/tensorflow/examples/tutorials/mnist/mnist_with_summaries.py, so I'm not sure what else we can do here -- it is generally recommended (for all software), to match the binary install you are using with the branch that matches it.\n"]}, {"number": 1687, "title": "replace googlemock source from google site to github", "body": "@vrv , this is to replace #1673\n\ngoogle site is blocked for people under the wall, we could help them by using official fedora's site\nThis should work since the SHA256 are the same\n", "comments": ["Can one of the admins verify this patch?\n", "@vrv \nI upadted to \"https://archive.openswitch.net/gmock-1.7.0.zip\", should work\nopenswitch is Community-Based, Open Source Operating System, should be trusty, and it should be safe as long as the SHA256 is unchanged\n", "@martinwicke: why don't we just host this ourselves on tensorflow.org instead?\n", "No reason apart from fear of accumulating things requiring maintenance.\nGmock is stable enough. We can add this along with our hooks.\nOn Mon, Mar 28, 2016 at 20:17 Vijay Vasudevan notifications@github.com\nwrote:\n\n> @martinwicke https://github.com/martinwicke: why don't we just host\n> this ourselves on tensorflow.org instead?\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> \n> Reply to this email directly or view it on GitHub\n> https://github.com/tensorflow/tensorflow/pull/1687#issuecomment-202686300\n", "@fayeshine: can you try accessing https://storage.googleapis.com/download.tensorflow.org/deps/gmock-1.7.0.zip or is that also blocked?\n", "@vrv , this link (https://storage.googleapis.com/download.tensorflow.org/deps/gmock-1.7.0.zip) is blocked for me, :(\nbesides, \"tensorflow.org\" is very slow here, sometimes unreachable\n", "Well that's unfortunate.  I think openswitch is okay for now, but we should probably find a better long-term solution.  One option to use: https://github.com/google/googletest, if that works, since that's the more-or-less official github one now\n", "(Specifically, using git_repository instead of http_archive, and changing the build_file to something that works for that github repo, rather than the hardcoded 1.7 paths)\n", "@tensorflow-jenkins: test this please\n"]}, {"number": 1686, "title": "Distributed cluster manager support: Slurm", "body": "Per the comment on [this introduction](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/how_tos/distributed/index.md), i.e. \n\n> N.B. Manually specifying these cluster specifications can be tedious, especially for large clusters. We are working on tools for launching tasks programmatically, e.g. using a cluster manager like Kubernetes. If there are particular cluster managers for which you'd like to see support, please raise a GitHub issue.\n\nIs there is any possibility of supporting [Slurm](http://slurm.schedmd.com/)? Forgive my ignorance but I've really only played around with TensorFlow and I've only used Slurm for fairly simple MPI projects, but I recently got access to a cluster with some GPU nodes and I'd like to incorporate TF in my research project. It would be great if I was able to use all the resources I could to speed things along.\n\nIf it helps, specific info about the setup can be found [here](https://wiki.auckland.ac.nz/display/CER/Centre+for+eResearch+User+Documentation+Start).\n", "comments": ["From a quick look at the Slurm docs, it looks like it could well support running TensorFlow, since (i) there's [decent support for running Python jobs](https://support.nesi.org.nz/hc/en-gb/articles/207782537-Python). I don't have access to a Slurm cluster, so I'm going to tag this \"Contributions welcome\", but I'd be happy to work with you on this Issue to get your cluster running on Slurm.\n\nHere's how you could get started:\n1. Create a Slurm job that sets up a Python virtualenv, installs a recent nightly PIP package, and runs a Python script. (Version 0.8 should include distributed cluster support.)\n2. In your Python script, parse the `$SLURM_NODELIST` environment variable to get a list of the hosts involved in the computation.\n3. Similarly, extract the [`$SLURM_STEP_RESV_PORTS` environment variable](https://computing.llnl.gov/linux/slurm/mpi_guide.html#open_mpi) and somehow decide what port to use in that range.\n4. Create a `tf.ClusterSpec` based on the information from the environment variables, and use that to create a `tf.GrpcServer` (documentation coming soon; see [`server_lib.py`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/client/server_lib.py)) in each process.\n5. Define a TensorFlow graph that is distributed across the nodes in your Slurm job.\n\nLet me know if you have any questions!\n", "Awesome, thanks for the quick reply. I will definitely try that out with one of the TF tutorial programs when I can, probably tomorrow, and post updates.\n", "Well after a ton of struggling I am unable to fully test this solution due to the issue outlined in #527, i.e. the cluster has an older glibc version and I can't build TF manually or run it from pip. I'll e-mail the cluster admins but I don't know if they would be willing to do that update. I'll update this issue if I can get anything figured out. \n", "About your issue with #527 I was able to get tensorflow running on the cluster by fully installing myself, see attach script if it can help you.\n\nAbout clustering myself, I do not see how to as I have but experience in using distributed tf over several machines, any help appreciated: will it work with a clusterspec that specifies several localhost:<port> mappings then attaching one task to each cpu and listen on a different port?\n\n[pip_setup.txt](https://github.com/tensorflow/tensorflow/files/331412/pip_setup.txt)\n", "@cgorman, have you made any progress?  I'm thinking of taking a stab at it soon but didn't want to duplicate any work.\n", "@jhollowayj Not really, no. After 0.9 came out I tried again but still wasn't able to get it installed on the cluster. I asked the support staff to try and they weren't able to either, so I just gave up. \n", "Sounds good.  We got it installed here just a little bit ago, so I'll take a stab at it sometime.  \n\nIn case I don't, the slurm manager here pointed me to two scripts he wrote to parse out the slurm nodelist in perl that may be helpful for generating that list:\nhttps://github.com/SchedMD/slurm/blob/slurm-16.05/contribs/torque/generate_pbs_nodefile.pl\nhttps://github.com/SchedMD/slurm/blob/78bb5093c37da90ab4206639d6028b358a296370/contribs/torque/generate_pbs_nodefile.pl\nHe said the second might be easier to use, since it wasn't using the slurm perl API that the first link uses.\n\nAlso, this [SO post](http://stackoverflow.com/questions/34826736/running-tensorflow-on-a-slurm-cluster has a few pointers) has some tips.\n", "I've spent some time reading up on slurm and it's allocation stuff.  What I have so far is [here](https://github.com/jhollowayj/tensorflow_slurm_manager/blob/master/slurm_manager.py) (still a work in progress).  \n\nI've been trying to figure out how to best support all possible slurm clusters (slurm adds environment variables, but not everyone runs the same version of slurm) as well as possible run configurations (x Nodes running y processes, each process on it's own exclusive node, etc.). \n\nSome Questions I have are:\n- Do other cluster managers force each process on it's own physical node, or do multiple processes occasionally get put on the same node?\n  - Note: our setup here will probably be the later as we only have a few GPU nodes.  However, I wanted to try and be consistent across other cluster managers like Kubernetes.\n- Are there any benefits to having multiple PS on the same physical node?  I've set it up to limit PS to one per node if the user has multiple processes on the same physical node.\n  - Do PS use multiple cores?  If so, I feel like network bandwidth will be the bottle neck over CPU usage.  If not, I can try to write a better assigner.\n- Are there any rules for importing pip packages once the manager is included in TF?  (I used python-hostlist to help parse slurm's list of hostnames)\n- Where would this file go in the Tensorflow repo once it's accepted?  (i.e. /tf/tf/contrib/cluster_managers/slurm.py ?)\n", "Some work has been done on this here:\r\nhttps://github.com/jhollowayj/tensorflow_slurm_manager/", "Sharing physical nodes across ps is usually a bad idea as ps is very network-heavy. PS also can use multiple cores (most tf code does) when updating variables.\r\n\r\nThe suggested file location is good.\r\n\r\nI'll close this issue for now since it's old, but please reopen as a pull request if you want to contribute.", "FYI I'm pretty sure this is achievable with https://github.com/uber/horovod in combination with a standard SLURM launch shell script, assuming all the proper software is installed."]}, {"number": 1685, "title": "Re-add ability to check for a specific bazel version", "body": "I tested this by upgrading to bazel master -- when i set minimum version to 0.2.1, it failed, and when I set it to 0.2.0, it passed.  Setting it to 0.1.4 currently also passes.\n", "comments": ["FYI to @damienmg, @petewarden @martinwicke and @fayeshine \n"]}, {"number": 1684, "title": "Update os_setup.md", "body": "Actually these two lines are still `bash` commands,\nalthough it has `python convolutional.py`, but `python setup.py develop` at before is also defined as `bash`\nbesides, using `python` make the `$` becomes red which is not consistent with other commands\n", "comments": ["Can one of the admins verify this patch?\n"]}, {"number": 1683, "title": "Revert \"Add ability to check for a specific bazel version. Supports\"", "body": "Reverts tensorflow/tensorflow#1679\n", "comments": []}, {"number": 1682, "title": "Upstream changes from internal for March 28", "body": "", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request) and all commit authors, but as best as we can tell these commits were authored by someone else.  If that's the case,  please add them to this pull request and have them confirm that they're okay with these commits being contributed to Google.  If we're mistaken and you did author these commits, just reply here to confirm.\n\n<!-- need_author_consent -->\n"]}, {"number": 1681, "title": "solve a building bug on bazel version requirement", "body": "@vrv \ntoday I also update bazel to newest master version, and when I rebuild tensorflow, I got this:\n\n```\nbazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\nERROR: /home/wenjian/pkgs/tensorflow/WORKSPACE:21:1: Traceback (most recent call last):\n        File \"/home/wenjian/pkgs/tensorflow/WORKSPACE\", line 21\n                check_version(\"1.4\")\n        File \"/home/wenjian/pkgs/tensorflow/tensorflow/tensorflow.bzl\", line 6, in check_version\n                fail(\"\nCurrent Bazel version is {}, e...))\n\nCurrent Bazel version is 0.2.0-2016-03-29 (@6b3294b), expected at least 1.4\n.\nERROR: Error evaluating WORKSPACE file.\nERROR: no such package 'external': Package 'external' contains errors.\nINFO: Elapsed time: 0.263s\n```\n\nSo I found that the bazel's version number should be 0.x.x, not x.x\nI changed `check_version(\"1.4\")` to `check_version(\"0.14\")` and the problem solved\n", "comments": ["Can one of the admins verify this patch?\n", "Rolled back in #1683 -- the version string was not what I expected it to be.  I'll roll it forward with the correct change soon.\n", "@vrv , thanks\n", "#1685 for the improved version that works\n", "@vrv #1685  worked for me, thanks for acting quick to solve bugs. I'll remove my branch.\n"]}, {"number": 1680, "title": "solve a serious bug which cause you fail to build", "body": "last day's update on `third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc` made me failed to build tensorflow.\nThe error is as follow: \n\n```\nERROR: /home/wenjian/pkgs/tensorflow/tensorflow/core/BUILD:985:1: C++ compilation of rule '//tensorflow/core:gpu_runtime' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object ... (remaining 85 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\nTraceback (most recent call last):\n  File \"third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc\", line 49, in <module>\n    PREFIX_DIR = os.path.dirname(GCC_HOST_COMPILER_PATH)\nNameError: name 'GCC_HOST_COMPILER_PATH' is not defined\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\nUse --verbose_failures to see the command lines of failed build steps.\n```\n\nI found the `GCC_HOST_COMPILER_PATH` is defined behind where it is used. This is the reason why it can't work.\nI moved it before the usage and configure again, the problem solved.\n", "comments": ["Can one of the admins verify this patch?\n", "+1. The same change worked for me.\n", "@tensorflow-jenkins: test this please\n", "Thanks, I'll merge after testing.  Unclear to me why the existing commit passed our tests :(\n", "I also failed to build due to this file. The first line:\n    !/usr/bin/env python\nassumes that the default python is the version that we are using to build. On CentOS7, I have 2 python2.7 versions side-by-side, and I wanted to build using the not-default version. However, this line used the default python2.7 which caused an error importing argparse. Can we change this invocation to use the python specified by ./configure ?\n"]}, {"number": 1679, "title": "Add ability to check for a specific bazel version. Supports", "body": "bazel versions pre-the ability to check for versions.\n", "comments": ["@damienmg fyi\n", "I thought we needed 2.0?\n", "We currently don't need 2.0 as checked in:\n\n2.0 is needed for protobuf as a submodule\nThe next pending release is needed for iOS support.\n\nSo this is just encoding the requirements at HEAD\n"]}, {"number": 1678, "title": "Fix broken links in distributed_runtime README.me", "body": "", "comments": ["Can one of the admins verify this patch?\n"]}, {"number": 1677, "title": "Upstream changes from internal", "body": "", "comments": ["@tensorflow-jenkins: test this please\n", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for the commit author(s).  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\n\n<!-- need_author_cla -->\n"]}, {"number": 1676, "title": "Update os_setup.md", "body": "add \"build with GPU support\" in \"Setting up TensorFlow for Development\", otherwise it is quite easy to wrongly build a CPU-only version.\nI didn't noticed that there's a \"build with GPU support\" option at first, so I wrongly built a CPU-only version.\n", "comments": ["Can one of the admins verify this patch?\n"]}, {"number": 1675, "title": "ImportError libcudart.so.7.5 in Pycharm console not in Terminal python console", "body": "sorry for my ignorant... simple linux problem...\n", "comments": []}, {"number": 1674, "title": "install  mac os by pip3", "body": "### Environment info\n\nOperating System:\nMac OS 10.11.1\ni try:\nsudo pip3 install --upgrade https://storage.googleapis.com/tensorflow/mac/tensorflow-0.7.1-cp35-none-any.whl\n### Logs or other output that would be helpful\n\n(If logs are large, please upload as attachment).\nbogon:~ liu$ sudo pip3 install --upgrade https://storage.googleapis.com/tensorflow/mac/tensorflow-0.7.1-cp35-none-any.whl\nThe directory '/Users/liu/Library/Caches/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\nThe directory '/Users/liu/Library/Caches/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\ntensorflow-0.7.1-cp35-none-any.whl is not a supported wheel on this platform.\nYou are using pip version 7.1.2, however version 8.1.1 is available.\nYou should consider upgrading via the 'pip install --upgrade pip' command.\nbogon:~ liu$ \n", "comments": ["There seems to be 2 issues, one is directory permissions, and the other is that the whl file is not compatible on your platform. Do you mind trying the pip install under a virtualenv to eliminate the first problem?\n\n```\n$ virtualenv -p `which python3` py3env\n$ source py3env/bin/activate\n# No sudo\n$ pip3 install --upgrade https://storage.googleapis.com/tensorflow/mac/tensorflow-0.7.1-cp35-none-any.whl\n```\n", "I'm also getting this issue but on Linux. I've tried installing tensorflow both on AWS EC2 and through herokus python buildpack but in both instances got the error `tensorflow-0.7.1-cp27-none-linux_x86_64.whl is not a supported wheel on this platform.` Was able to get it on the EC2 using [this guys conda package](https://conda.anaconda.org/jjhelmus) but still can't get it on heroku.\n", "What's your python3 version? also try upgrade your pip and setuptool?.\n\n`% pip3 install --upgrade pip setuptools`\n", "I ended up getting it working on the EC2 using a a conda install and on heroku by switching from python 3.5.1 to 3.4.0\n", "i use python3.4.4 and upgrade pip to the newset,try virtulenviroment. but still not work...\n", "Can you try execute and print python3 with the following command?\n\n`import pip; print(pip.pep425tags.get_supported())`\n\nExample:\n\n> $ python3\n> Python 3.5.1 (default, Dec  7 2015, 21:59:08)\n> [GCC 4.2.1 Compatible Apple LLVM 7.0.0 (clang-700.1.76)] on darwin\n> Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n> import pip; print(pip.pep425tags.get_supported())\n> [('cp35', 'cp35m', 'macosx_10_10_x86_64'), ('cp35', 'cp35m', 'macosx_10_10_intel'), ('cp35', 'cp35m', 'macosx_10_10_fat64'), ('cp35', 'cp35m', 'macosx_10_10_fat32'),.....\n", "As an alternative, I'll suggest that you can download  tensorflow-0.7.1-py3-none-any.whl by via [Nightly Build](http://ci.tensorflow.org/view/Nightly/job/nightly-matrix-cpu/TF_BUILD_CONTAINER_TYPE=CPU,TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON3,label=mac-slave/)\n", "thx,it finally work successfully!!!\n\n2016-04-01 19:45 GMT+08:00 Cheng-Lung Sung notifications@github.com:\n\n> As an alternative, I'll suggest that you can download\n> tensorflow-0.7.1-py3-none-any.whl by via Nightly Build\n> http://ci.tensorflow.org/view/Nightly/job/nightly-matrix-cpu/TF_BUILD_CONTAINER_TYPE=CPU,TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON3,label=mac-slave/\n> \n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly or view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/1674#issuecomment-204360706\n", "I also had this same issue, .**..is not a supported wheel on this platform.**.  when trying to install with python 3.4.3 and pip 8.1\n\nTo fix issue:\n- used pyenv to pull down upgraded to python 3.5.1, switched it to be my global python\n- Created a virtual env via pyvenv (not virtualenv, but I think this is irrelevant) \n- Ran  `pip install --upgrade https://storage.googleapis.com/tensorflow/mac/tensorflow-0.7.1-cp35-none-any.whl`\n\nWorked!!!\n"]}, {"number": 1673, "title": "replace googlemock source from google site to github", "body": "google site is blocked for people under the wall, we could help them by using official google github repo\n", "comments": ["Can one of the admins verify this patch?\n", "Jenkins, test this please.\nCan I tell jenkins to run tests?\n", "@tensorflow-jenkins test this please\n\n(no, sadly only we can kick off tests)\n", "well, that didn't work :(\n", "@vrv , oh, there's some files missing in the github version of gmock, I'll see how to solve this.\n"]}, {"number": 1672, "title": "Shape information is not preserved through sampling", "body": "When I create a sample from a normal based on the shape of another tensor, that shape information is not retained.\n\nUsing Tensorflow 0.7.1:\n\n```\n>>> import tensorflow as tf\n>>> x = tf.placeholder(tf.float32, (None, 12))\n>>> y = tf.random_normal(tf.shape(x))\n>>> y.get_shape()\nTensorShape([Dimension(None), Dimension(None)])\n```\n\nI would have expected `TensorShape([Dimension(None), Dimension(12)])` instead.\n", "comments": ["This is intended behaviour. The shape input you are passing to `tf.random_normal`, namely, the output of `tf.shape` function, is only available at runtime. Hence the static analysis is unable to infer the shape. You can consider setting the shape of `y` explicitly using the [`set_shape`](https://www.tensorflow.org/versions/r0.7/api_docs/python/framework.html#Tensor.set_shape) function.\n", "Is there an easy way to find the size of the second dimension in the above example then?\n", "`x.get_shape()[1]` ?\n", "Sorry, I was not clear enough. `x` is not available, only `y`.\n"]}, {"number": 1671, "title": "Tensorboard does not list any event", "body": "Tensorboard does not list any event stored in disk.\n### Environment info\n\nOperating System: Docker on Windows 10\n\nTensorflow version 0.7.1\n### Steps to reproduce\n\n```\ngraph = tf.Graph()\nwith graph.as_default(), tf.device('/cpu:0'):\n  a = tf.constant(5.0)\n  b = tf.constant(6.0)\n  c = a * b\n\n  # Enter data into summary.\n  c_summary = tf.scalar_summary(\"c\", c)\n  merged = tf.merge_all_summaries()\n\nwith tf.Session(graph=graph) as session:\n  writer = tf.train.SummaryWriter(\"log/test_logs\", session.graph_def)\n\n  result = session.run([merged])\n  tf.initialize_all_variables().run()\n  writer.add_summary(result[0], 0)\n```\n\nI then ran `tensorboard --logdir={absolute path to log/test_logs}` but no event was listed there. Is there anything I should have written differently in the code maybe?\n\nNote that `log/test_logs` does contain files like `events.out.tfevents.1459102927.0a8840dee548`.\n### What have you tried?\n\nRunning `https://github.com/tensorflow/tensorflow/blob/r0.7/tensorflow/examples/tutorials/mnist/mnist_with_summaries.py` did not correct this (despite the events correctly outputted to disk).\n", "comments": ["Just a quick suggestion: have you tried adding `writer.flush()` or `writer.close()` after `writer.add_summary(...)`? The `tf.train.SummaryWriter` class writes events to a file asynchronously, so if you exist immediately after writing the event, it may not appear in the log.\n", "Yeah, I have tried `writer.flush()`, did not do anything. Thing is the logs are already there, in file format, so I think the problem lies in tensorboard not reading them properly, somehow.\n", "You could try using a [`tf.train.summary_iterator(filename)`] in a separate Python program to scan over the contents of your event files, and check that the expected events are in the file.\n", "Yes, that works, it shows reports like:\n\n```\nwall_time: 1459102927.0\nfile_version: \"brain.Event:2\"\n\nwall_time: 1459102927.88\ngraph_def: \"\\nK\\n\\013Placeholder\\022\\013Placeholder\\\"\\r/device:CPU:0*\\013\\n\\005dtype\\022\\0020\\001*\\023\\n\\005shape\\022\\n:\\010\\022\\002\\010\\002\\022\\002\\010\\002\\nU\\n\\005Const\\022\\005Const\\\"\\r/device:CPU:0*\\013\\n\\005dtype\\022\\0020\\001*)\\n\\005value\\022 B\\036\\010\\001\\022\\010\\022\\002\\010\\002\\022\\002\\010\\002\\\"\\020\\000\\000\\200?\\000\\000\\200?\\000\\000\\000@\\000\\000\\000@\\nb\\n\\006MatMul\\022\\006MatMul\\032\\013Placeholder\\032\\005Const\\\"\\r/device:CPU:0*\\021\\n\\013transpose_b\\022\\002(\\000*\\021\\n\\013transpose_a\\022\\002(\\000*\\007\\n\\001T\\022\\0020\\001\\nM\\n\\024HistogramSummary/tag\\022\\005Const\\\"\\r/device:CPU:0*\\013\\n\\005dtype\\022\\0020\\007*\\022\\n\\005value\\022\\tB\\007\\010\\007\\022\\000B\\001c\\nZ\\n\\020HistogramSummary\\022\\020HistogramSummary\\032\\024HistogramSummary/tag\\032\\006MatMul\\\"\\r/device:CPU:0*\\007\\n\\001T\\022\\0020\\001\\nS\\n\\031MergeSummary/MergeSummary\\022\\014MergeSummary\\032\\020HistogramSummary\\\"\\r/device:CPU:0*\\007\\n\\001N\\022\\002\\030\\001\\\"\\002\\010\\010\"\n```\n\nI'm suspicious that the problem is with `--logdir={$PWD}` where somehow logdir does not get sent to tensorboard. How to test this?\n", "When you run the `tf.train.summary_iterator()` does it only show those two records, or do you see any records that contain `wall_time:` and `summary:`? (The log you showed doesn't contain summaries, and so TensorBoard would not generate any plots, but it should show the graph visualization.)\n", "@jaycode: If you think the logdir isn't getting through properly, you can test that by launching TensorBoard with the --debug flag. [See details here.](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tensorboard/README.md#my-tensorboard-isnt-showing-any-data-whats-wrong)\n\nI think this might be a duplicate of [#1421](https://github.com/tensorflow/tensorflow/issues/1421). It seems that there's an issue with open-source TensorBoard sometimes not loading any data from events files. The trouble is, I've never been able to reproduce this on any of my machines. A co-worker had it reproducing once, but it disappeared when he re-installed the package. I now think it might be consistently repro'ing on docker, so I plan to look into that next.\n", "@danmane Aha! This is where the issue was:\n\n> INFO:tensorflow:TensorBoard path_to_run is: {'/notebooks/learn/udacity/nanodegree_ml_engineer/Deep Learning/assignments/Research/log/mnist_logs/{/notebooks/learn/udacity/nanodegree_ml_engineer/Deep': None}\n\nTurns out there was a problem with `{$PWD}` variable that was provided. I changed the command to `tensorboard --logdir='mnist_logs' --debug` (from `logs` directory) and everything works perfectly.\n\nMore than anything, thanks for pointing out `--debug` option, wouldn't have find out without it.\n"]}, {"number": 1670, "title": "What is the best way to max pool top k elements instead of 1?", "body": "I would like to know if there is a convenient way to pool top k elements instead of just one.\n\nThe tf.nn.top_k seems not for this kind of job, because for each window, I want the top k elements.\n", "comments": ["TensorFlow doesn't have this operation currently, and doing it with existing ops is probably going to be clunky. Do you mind describing the operation slightly more formally, so that it can act as a specification for someone who can pick it up to implement it? Also, please post it to StackOverflow, in case someone in the larger community has an idea to implement it using existing TensorFlow operations.\n", "Now the max pooling function in tensorflow is\n\n<pre>\ntf.nn.max_pool(value, ksize, strides, padding, name=None)\nReturns:\nA Tensor with type tf.float32. The max pooled output tensor.\n</pre>\n\nI would like to have an extend version of max_pool, like\n\n<pre>\ntf.nn.top_k_pool(value, ksize, strides, padding, k=1, name=None)\nPerforms the top k pooling on the input.\nArgs:\nvalue: A 4-D Tensor with shape [batch, height, width, channels] and type tf.float32.\nksize: A list of ints that has length >= 4. The size of the window for each dimension of the input tensor.\nstrides: A list of ints that has length >= 4. The stride of the sliding window for each dimension of the input tensor.\npadding: A string, either 'VALID' or 'SAME'. The padding algorithm.\nk: 0-D int32 Tensor. Number of top elements to look in each pool.\nname: Optional name for the operation.\nReturns:\nA Tensor with type tf.float32. The max pooled output tensor. There will be an additional dimension saving the top k values.\n</pre>\n\nI know that I can expend the tensorflow operation following https://www.tensorflow.org/versions/r0.7/how_tos/adding_an_op/index.html\n\nI would like to know if there is an easier way to achieve that.\n\nAlso asking in [stackoverflow](http://stackoverflow.com/questions/36272502/what-is-the-best-way-to-top-k-pool-elements-instead-of-only-the-max-one-in-tenso).\n", "I think you probably need to write a custom op for this, if you want it to be at all fast.\n\nIn any case, stackoverflow is probably the right venue for this question. Thanks!\n", "Have you solved this issue? I want to max pool top k elements too,but tf.nn.top_k only search on the last dimension."]}, {"number": 1669, "title": "Function for flexible access to the content of a saver / checkpoint file", "body": "As far as I am aware, the only ways to interact with a saver file through API are (from https://www.tensorflow.org/versions/r0.7/how_tos/variables/index.html , I also looked at the API documentation online):\n- to restore a full model into exactly the same computational graph\n- to restore variables 'one at a time' through an op.\n  Am I right or did I miss something?\n\nWould it be possible to release additional API functions giving more flexible access to a saver file? Like making it possible to:\n- list all tensors saved and their size, name etc contained in a saver file\n- access a tensor saved in a saver file by just reading its content and outputting it as a series of numpy arrays (for easy post processing), instead of needing to add an op, run it etc.\n", "comments": ["2966fcd adds support for most of what you want. Assigning to @sherrym for further updates.\n", "286c5a4 added support to print the content of a tensor.\n", "c85b942 added a python-based tool for inspecting checkpoint.\n\nTo print shape information:\n  inspect_checkpoint --file_name=model.ckpt-4971\n\nTo print contents of a particular tensor:\n  inspect_checkpoint --file_name=model.ckpt-4971 \\\n    --tensor_name=mixed_17x17x768e/branch7x7dbl/Conv_2/weights/ExponentialMovingAverage\n\nNOTE: If you see this message, it's likely that your checkpoint file\nhas been compressed with SNAPPY:\n\n  \"Data loss: Unable to open table file /tmp/model.ckpt-4971: Data\n  loss: corrupted compressed block contents: perhaps your file is in a\n  different file format and you need to use a different restore operator?\n  It's likely that your checkpoint file has been compressed with SNAPPY.\"\n\nTo work around this issue without regenerating the\ncheckpoint files for now, you can rebuild by defining SNAPPY in\ntensorflow/core/platform/posix/port.cc and link \"lib_internal\" with snappy\n(-lsnappy) in tensorflow/core/BUILD.\n", "I got the same error with the \"Data loss, etc.\", but could not readily figure out how this could be fixed @sherrym ?\n\nI mean fine-tuning from `inception_resnet_v2_2016_08_30.ckpt` works using TF-Slim. The evaluation of the fine-tuned model works too, but when I try to do inference using the newly created checkpoint I got the same error (same with `inspect_checkpoint`)\n\nThe demo inference from there works fine as well: [https://github.com/tensorflow/models/blob/master/slim/slim_walkthough.ipynb](https://github.com/tensorflow/models/blob/master/slim/slim_walkthough.ipynb)\n\nIn other words, how to save the checkpoints with compatible compression?\n"]}, {"number": 1668, "title": "Getting Attention Activations to Visualize Attention in Seq2Seq", "body": "All attention papers feature some visualization of the attention weights on some input. Has anyone been able to run a sample through the Seq2Seq Attention Decoder model in `translate.py` and get the attention activations to do such a visualization?\n", "comments": ["The attention mask is available as a tensor here : \nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/seq2seq.py#L522\n\nIt should be easy to fetch it out during a run call and visualize it. You can try posting this to StackOverflow  to see if someone in the general community has done this visualization. I am closing this issue, since we have the required functionality in TensorFlow.\n", "The link is broken. What is the correct link?", "same problem"]}, {"number": 1667, "title": "Update fully_connected_feed.py", "body": "\"os.path\" and \"numpy\" was unused, so I removed it.\nThe tfevents-output-file was not completely written in IPython, so I Added \"summary_writer.flush()\" to fix it.\n", "comments": ["Can one of the admins verify this patch?\n", "This is a useful change, but can you make it to the master branch instead of r0.7 ? \n", "Thanks for reminded me, I will create a pull request to master branch.\n"]}, {"number": 1666, "title": "There is no log10 function in tensorflow, only the loge exist.", "body": "", "comments": ["`log10` can be constructed by composing existing TensorFlow operations, as below : \n\n```\ndef log10(x):\n  numerator = tf.log(x)\n  denominator = tf.log(tf.constant(10, dtype=numerator.dtype))\n  return numerator / denominator\n```\n\nClosing this issue as we don't plan to support this natively.\n", "log10 and log2 are pretty common things to use, it'd be nice to have them (and would help to match the numpy api).  Or at least `log(x, base)`", "```log(x, base)``` :+1: ", "Just out of curiosity: Would you lose a lot of performance if someone implements `base` as an optional attribute?", "> Just out of curiosity: Would you lose a lot of performance if someone implements `base` as an optional attribute?\r\n\r\nNo. It would get compiled as a tf.function the first time it runs with said base."]}, {"number": 1665, "title": "Added implementation for GridRNN", "body": "As discussed here: https://github.com/tensorflow/tensorflow/issues/1453\n\nThe implementation is generic, users can specify the number of dimensions and various configurations for those dimensions (input/output/priority/non-recurrent). The type of the cells along dimensions can also be selected among LSTM, GRU, vanilla RNN.\n\nCome with unittests for basic types: 2LSTM (tied weights, non-recurrent), 2BasicLSTM and 2RNN.\n\nI made a simple test of Grid2LSTM for character-level language modeling: https://github.com/phvu/grid-lstm-tensorflow/tree/master/char-rnn.\n", "comments": ["Can one of the admins verify this patch?\n", "Will take a look tomorrow.\n", "Thanks for the hard work!  Some comments.\n", "@ebrevdo Thanks for the comments. I updated the code.\n- Good to know about `input_size` and `output_size`, I updated the code to not depend on those.\n  However as the `LSTMCell` is still accepting `input_size`, I still keep `input_size` as a parameter in the `cell_fn` callback. Should it be also removed?\n- The tests are real. I computed the values using [this](https://docs.google.com/spreadsheets/d/18bkheoJbmMUqdRFrviUy_TiooSjvvpDqiti7hm2EASY/edit#gid=0). Since the initializer is fixed in the tests (weights are initialized to 0.5 or 0.2, depending on the tests; bias are initialized to zero), the output are deterministic. But of course I can switch to lightweight asserts if that is preferred.\n", "Without a unit test that calls tf.nn.rnn or tf.nn.dynamic_rnn, it's not clear that these cells interact correctly with those methods.  Can you add such a test for your classes?\n", "ok will do.\n", "I added the tests for `Grid1LSTM`, `Grid2LSTM`, `Grid3LSTM` (with ReLU), trained with `tf.nn.rnn`. Can you take a look?\n", "Will look tomorrow-thanks!\nOn Apr 6, 2016 11:36 AM, \"Vu Pham\" notifications@github.com wrote:\n\n> I added the tests for Grid1LSTM, Grid2LSTM, Grid3LSTM (with ReLU),\n> trained with tf.nn.rnn. Can you take a look?\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly or view it on GitHub\n> https://github.com/tensorflow/tensorflow/pull/1665#issuecomment-206506910\n", "Jenkins, test this please?\n", "Can one of the admins verify this patch?\n", "Sorry for not reviewing earlier.  Let's retest this and we can get it merged.\n", "@phvu can you rebase on HEAD and run the tests?\n", "@ebrevdo: why does he have to rebase to HEAD?  Do you think there will be a conflict in doing so?\n\nAlso, only we can trigger tests.\n", "@tensorflow-jenkins: test this please\n", "Cool, tests passed. So I don't need to rebase master for now?\n", "Excellent, we're good to go.  Thanks for the contribution!  If you have any example code using this we can consider adding it elsewhere in the repo (e.g. under models).\n", "Cool, thanks for all the help.\nUnfortunately I can't share what I am working on with this yet. I have an application of this to character-level modeling (https://github.com/phvu/grid-lstm-tensorflow/tree/master/char-rnn) but it isn't entirely my code so I put it in a separated repo.\n\nI think at some point I can try reproducing some experiments in the paper. Will submit PRs by then.\n", "Hi @phvu,\n\nThanks very much for your work. I'm a little confused as to how this can be applied generally. For example, in the paper a 3-LSTM network was applied to image patches of the MNIST dataset where each patch is c \\* m units long (which is equal to the depth dimension). So we have a 3D grid of c \\* m vectors. But in your implementation of `__call__`, we are expecting a tensor of size batch \\* c \\* m \\* num_dims. For MNIST, shouldn't it support b \\* c \\* m \\* dim1_size \\* dim2_size ? This would require input_dims to be something like `[1, 2]` (where dim 0 is batch); but I don't see any tests covering cases besides input_dim=0. Am I missing something?\n", "Hi @jstaker7,\nThere are some nuances here.\nFirst, the `__call__` method expects the state tensor of `batch_size * ( (c + m) * num_dims)`. When c=m=2 then c*m = c+m. Sorry for the bad test case, I should have used other values.\n\nSecond, in the MNIST case, (as far as I understand) I suppose you could use Grid3LSTMCell (https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/grid_rnn/python/ops/grid_rnn_cell.py#L242). This cells receives input and gives output in the first dimension (index 0), and uses LSTM in the other 2 dimensions.\nIn order to replicate Figure 11 in the paper, you will need to construct 4 3-LSTM cells, each cell will handle 1 scan direction of the input image. However the first hidden LSTM layer receives original pixels as input, while other hidden LSTM layers receives the output of the LSTM just below it.\nHow to do that is up to you. One simple way is to have a loop to scan the image in a given scan direction (say left-to-right top-to-bottom), which will give a sequence of vectors, and then feed that sequence into the corresponding 3-LSTM cell for that scan direction. For bigger images, you might want to use `tf.scan()`\n\nSo your assumption that input_dims should be `[1,2]` is not true. The cells should receive input at dimension 0. For me this is the only reasonable interpretation of the paper, which also take 1-LSTM and 2-LSTM cells into account. (unless the authors release their implementation so that we can do a comparison).\n", "Hi @phvu,\n\nThank you, this helps quite a lot. Since each dimension will always have its own LSTM, does that mean we will never use an `input_dims` other than 0?\n", "To replicate the experiments in the paper, yes. But I am not sure about that generally.\n\nWhen we set dimension i to be input_dims, it simply means for each `__call__`, the cell expects an input tensor for dimension i. For non-input dimensions, the cell will take the recurrent values (extracted from the state tensor) as input.\n\nSo I guess we can be creative and feed inputs into more than one dimension. I used dimension 0 as input and output dimensions just as a convention. You can as well construct your own GridRNNCell with any configuration.\n", "Perfect, thanks so much for the clarification. Super helpful and makes a lot of sense.\n\nThis might also be interesting to look into in the future. Grid LSTMs were mentioned and it looks like there was a recent merge: https://github.com/tensorflow/tensorflow/issues/2560\n"]}, {"number": 1664, "title": "Update InitGPU() to return if VisibleDeviceCount() <=0.", "body": "When CUDA_VISIBLE_DEVICES is empty, VisibleDeviceCount() returns -1, so we should check for <= 0.\n", "comments": []}, {"number": 1663, "title": "Nightly debian CPU build fails during docker build ", "body": "For example, see:\nhttp://ci.tensorflow.org/view/Nightly/job/nightly-debian-cpu/28/console\n\nThe error happens during the step: RUN /install/install_deb_packages.sh\n", "comments": ["Is this still a problem? It looks like that particular nightly is passing now, so do we need to keep this issue open?\n", "No, this is fixed.\n"]}, {"number": 1662, "title": "Tag mismatch! ", "body": "envy@ub1404:~/os_pri/github/tensorflow$ bazel build -c opt //tensorflow/tools/pip_package:build_pip_package\nERROR: /home/envy/os_pri/github/tensorflow/tensorflow/core/distributed_runtime/rpc/BUILD:207:1: no such package '@grpc//': Tag mismatch! and referenced by '//tensorflow/core/distributed_runtime/rpc:grpc_server_lib'.\nERROR: Loading failed; build aborted.\nINFO: Elapsed time: 221.272s\nenvy@ub1404:~/os_pri/github/tensorflow$ \n", "comments": ["Did you try git submodule update --recursive?\n", "Yes, you need an updated version of the protobuf submodule to support grpc at head.\n"]}, {"number": 1661, "title": "conv4d and higher dimension generalization", "body": "Are there some plans to include a 4D (and possibly higher dimension generalization) convolution op? Would be nice for doing 3D + time processing for example (for the 4D version).\n\nAlso, should something be done to offer the user the possibility to choose the shape of the kernel? For example allowing both the natural hyper cube kernel nodes location or a hyper thetrahedron location? Could have consequences on the computing power requested:\n\nhttp://arxiv.org/pdf/1505.02890v2.pdf\n", "comments": ["@jerabaul29, generalizing convolutions to higher dimensions would be a great addition to TensorFlow, especially the GPU implementation. It will be great if someone in the community can take this up.\n", "I think that this impact Eigen upstream\n", "I'm no expert, but I think that Eigen supports tensors with arbitrary dimensions (albeit compilation gets really slow when it's more than 8 or something), and judging by the cuDNN manual, it can also take 5D Tensors (as in 3D+1D-color+1D-batchsize) or maybe even higher-dimensional.\n\nThe code in tensorflow/core/kernels/conv_ops.cc looks fairly generic, and might even be extensible to include higher-dimensional and GPU-accelerated convolutions.\n\nI'm afraid it would require a serious amount of digging, though.\n", "https://github.com/tensorflow/tensorflow/commit/6a187ccddaebb741ea77fc3201c6e36625f0aadb for an example of adding 3d convolutions, which uses cudnn Nd tensor interface and eigen for CPU.  Something similar could be done for conv4d, conv1d, etc.\n\nIf someone wants to tackle this, please let us know (cc @rewonc), since we now have conv2d and conv3d to provide a template for generalization.  We may still be missing something though, so no guarantees it will be straightforward.\n", "@vrv Cool -- definitely seems like there's an opportunity to generalize a template. Will take a look and let you \n", "Are there any news on this?\nA 4D operation would be a really nice feature. Especially now that more and more people from other fields, where 4D (3D + time)  is the common use case (i.e. physics), are jumping in on deep learning.\nEven if the n-dimensional generalization is not easily implementable, I think a separate conv4d would be very helpful.\n", "I know it hasn't been long but is there any news on this ? We are currently using Caffe for 4D light-fields convolutions but would love to shift to tensorflow. ", "@vincentvanhoucke know anyone at Google that likes 4D convolutions?", "@yaroslavvb not that I know of. I think it would be a perfectly good feature for a motivated contributor to pick up. Note that in my experience, treating the time dimension convolutionally is not always a good idea. It makes you throw a lot of parameters at a dimension that comparatively has a lot less semantic content than the spatial dimensions. YMMV.", "Any word on this? I am working with volumetric spectral scans, and a 4D convolution would make a great tool for what I need.", "I've plugged a conv4d equivalent together in python. It's just on python level, so most likely not the fastest, but if you want to start with that you can find it here:\r\nhttps://github.com/mhuen/TFScripts\r\nIf you do decide to give it a try, let me know if you have any suggestions or if you come across any bugs as I haven't extensively tested it yet. ", "vote for the improvement too", "I think this is unlikely to happen in a way that makes anyone happy, so closing.  All applications of 4D convs that I know of will almost certainly be forced to use special factorizations for efficiency.", "nD convolutions can be realized by summing a sequence of (n-1)D convolutions. See [here](https://github.com/funkey/conv4d) for an implementation of a 4D convolution layer using TensorFlow's `conv3d` layer. Details can be found in the [docstring](https://github.com/funkey/conv4d/blob/master/conv4d.py#L27).", "Any news on this? I am working on human action recognition and I could greatly benefit from 4D convolutions since my representation is in the format (x,y,z,t).", "@josuerocha, is there any reason the [4D convolution](https://github.com/funkey/conv4d) linked above would not work for your use case?", "+1 to the need of Conv4D and higher dimensions.\r\nEspecially in fields other than traditional machine learning topics, like physics. \r\n\r\nHere, the time dimension can often be treated the same as the spatial dimensions such that a Conv4D would be very useful. I know several people in particle physics that have actually switched to other ML frameworks like CNTK just because of the lack of 4D Convs. ", "@vrv It might be late, may I ask if there is any plan recently to add n-d conv? We are working on a pure math problem, already get it worked under 3d, but really need to give evidence that this can work on arbitary dimensional data to finish the paper. Or anyone else is working on this can work together? If not a very huge task, we may try do it by our team people\u2026\u2026", "Any news on this? If this is not available we will have to shift to another framework for one of our upcoming project, which would be a bit sad. If the 4D conv as a sum of 3D convs is the solution you want to keep for now, could this be added natively to tensorflow - nothing would prevent changes in the implementation later on anyways as long as the API choice is good?"]}]