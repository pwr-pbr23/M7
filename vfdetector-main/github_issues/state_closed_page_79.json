[{"number": 52809, "title": "Cherrypick fixes for ImmutableConst op vuln", "body": null, "comments": []}, {"number": 52808, "title": "Add shape checks to FusedBatchNorm kernels.", "body": "PiperOrigin-RevId: 399755576\r\nChange-Id: If8049fde109cc33badb5509d174b9b95aee1ea5e", "comments": []}, {"number": 52807, "title": "Add shape checks to FusedBatchNorm kernels.", "body": "PiperOrigin-RevId: 399755576\r\nChange-Id: If8049fde109cc33badb5509d174b9b95aee1ea5e", "comments": []}, {"number": 52806, "title": "Add shape checks to FusedBatchNorm kernels.", "body": "PiperOrigin-RevId: 399755576\r\nChange-Id: If8049fde109cc33badb5509d174b9b95aee1ea5e", "comments": []}, {"number": 52805, "title": "Remove use of `eval` when evaluating the input example.", "body": "Use `ast.eval_literal` instead which safely evaluates the expression.\r\n\r\nPiperOrigin-RevId: 400012249\r\nChange-Id: I5ff98608ea2d736d093aa488af723ff4f6707e02", "comments": []}, {"number": 52804, "title": "Mm cp e3a672333b56f6281f2e7a40fc06b2233f0c5663 on r2.4", "body": null, "comments": ["(clicked too early)", "All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F52804) for more info**.\n\n<!-- need_author_consent -->"]}, {"number": 52803, "title": "Remove use of `eval` when evaluating the input example.", "body": "Use `ast.eval_literal` instead which safely evaluates the expression.\r\n\r\nPiperOrigin-RevId: 400012249\r\nChange-Id: I5ff98608ea2d736d093aa488af723ff4f6707e02", "comments": []}, {"number": 52802, "title": "Merge pull request #52209 from k-w-w/cherrypicks_KM7DE", "body": "Remove use of `eval` when evaluating the input example.", "comments": []}, {"number": 52801, "title": "[tf.data] Fix memory leak in to_tf_record_op.", "body": "PiperOrigin-RevId: 396400385\r\nChange-Id: I13951a206ebff8fa0887f42cd9218f07e9ff27dc", "comments": []}, {"number": 52800, "title": "Merge pull request #51733 from yongtang:46888-tf.math.segment_", "body": "PiperOrigin-RevId: 406020083\r\nChange-Id: I179a9a8fe548ed324fc97363e81a46be28aa19b8", "comments": []}, {"number": 52799, "title": "Merge pull request #51733 from yongtang:46888-tf.math.segment_", "body": "PiperOrigin-RevId: 406020083\r\nChange-Id: I179a9a8fe548ed324fc97363e81a46be28aa19b8", "comments": []}, {"number": 52798, "title": "Merge pull request #51733 from yongtang:46888-tf.math.segment_", "body": "PiperOrigin-RevId: 406020083\r\nChange-Id: I179a9a8fe548ed324fc97363e81a46be28aa19b8", "comments": []}, {"number": 52797, "title": "[ROCm] Fix for invalid llvm ir on AMDGPU in reduction", "body": "Address Space Casting initial value addr to generic space for a fix for the llvm ir generated on AMD GPU. This is a fix for the invalid llvm IR generated following fc9df104fdbbda6ee9096b40186a50badb147ac7. ", "comments": ["cc @cheshire @chsigg gentle ping", "@cheshire CastSharedToGlobal was reinstated. Can you rereview this PR please?"]}, {"number": 52796, "title": "Title: Input shape compatibility of ZIP-object of (image and image ImageDataGenerator objects) and CNN", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1.  It must be a bug, a feature request, or a significant problem with the\r\n    documentation (for small docs fixes please send a PR instead).\r\n2.  The form below must be filled out.\r\n3.  It shouldn't be a TensorBoard issue. Those go\r\n    [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n\r\n-   **Have I written custom code (as opposed to using a stock example script\r\n    provided in TensorFlow)**: custom code \r\n-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows10\r\n-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue\r\n    happens on a mobile device**: NA\r\n-   **TensorFlow installed from (source or binary)**: binary (added as library to Anaconda )\r\n-   **TensorFlow version (use command below)**: 2.1.0\r\n-   **Python version**: 3.7\r\n-   **Bazel version (if compiling from source)**: NA\r\n-   **GCC/Compiler version (if compiling from source)**: NA\r\n-   **CUDA/cuDNN version**: 10.1 \r\n-   **GPU model and memory**:\r\n- \tNVIDIA GeForce RTX 2070 with Max-Q Design\r\n\tDriver version:\t30.0.14.7196\r\n\tDriver date:\t8/27/2021\r\n\tDirectX version:\t12 (FL 12.1)\r\n\tPhysical location:\tPCI bus 1, device 0, function 0\r\n\tUtilization\t0%\r\n\tDedicated GPU memory\t0.0/8.0 GB\r\n\tShared GPU memory\t0.1/7.9 GB\r\n\tGPU Memory\t0.1/15.9 GB-   **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with:\r\n\r\n```bash\r\npython -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"\r\n```\r\n\r\n### Describe the problem\r\nI have 64 RGB images with their corresponding masks. I use ImageDataGenerator and flow_from_directory function to read the images and masks from the directory folder.\r\nThe folder structures are as follows:\r\nImages\r\n---- imgs\r\n-------- ---ROI\r\n----------------1.tiff\r\n----------------2.tiff\r\nMasks\r\n------imgs\r\n------- -----ROI\r\n------------------1.tiff\r\n------------------2.tiff\r\nImages and masks are stored with the same file names. In my case, ImageDataGenerator is an Iterator of size 2 with a batch size of 32. I did the following:\r\n\r\nI read the images and masks into lists named as \u201cimages\u201d and \u2018\u2019masks\u2019\u2019 respectively.\r\nsize = 231 \r\nimages = []\r\n\r\nfor directory_path in glob.glob(\u201c. /Images/imgs/ROI/\"):\r\n    for img_path in glob.glob(os.path.join(directory_path, \"*.tiff\"):\r\n        img = cv2.imread(img_path, cv2.IMREAD_COLOR)       \r\n        img = cv2.resize(img, (size, size))\r\n        images.append(img)\r\n        images = np.array(images)\r\n\r\nmasks = [] \r\nfor directory_path in glob.glob(\u201c. /Masks/imgs/ROI/\"):\r\n    for mask_path in glob.glob(os.path.join(directory_path, \"*.tiff\"):\r\n        mask = cv2.imread(mask_path, 0)       \r\n        mask = cv2.resize(mask, (size, size))\r\n        masks.append(mask)     \r\nmasks = np.array(masks)\r\nmasks = np.expand_dims(masks, axis=3)\r\nNote: I obtained images of shape (64, 231,231,3) and masks of shape (64, 231, 231, 1)\r\n\r\nI then used keras documentation the process of transforming the images and masks together as follows:\r\n\r\n  a.\tI created a dict to specify the augmentation parameters as follows for both images and masks.\r\n  data_gen_args_imgs = dict rotation range=90,\r\n                       rescale = 1. /255.)\r\n  data_gen_args_masks = dict rotation range=90)\r\n               \r\n  b.\tThe I created ImageDataGenerator objects for both images and masks as follows:\r\n  ```\r\n  image_datagen = ImageDataGenerator(**data_gen_args_imgs)\r\n  mask_datagen = ImageDataGenerator(**data_gen_args_masks)\r\n  ```\r\n  \r\n  c.\tI use the fit and flow functions using the same seeds and keyword arguments for images and masks as follows: \r\n  ```\r\n  seed = 1\r\n  \r\n  image_datagen.fit(images, augment=True, seed=seed)\r\n  mask_datagen.fit(masks, augment=True, seed=seed)\r\n  \r\n  image_generator = image_datagen.flow_from_directory(\r\n      'data/images',\r\n      class_mode=None,\r\n      shuffle= False,\r\n      seed=seed)\r\n  \r\n  mask_generator = mask_datagen.flow_from_directory(\r\n      \u201c. /Images/imgs/\u201d,\r\n      class_mode=None,\r\n      shuffle= False,\r\n      seed=seed)\r\n  ```\r\n  \r\n  d.\tThen I created an iterator on the zip object to return a matched pair of images and corresponding masks as follows:\r\n  \r\n  `train_generator = (pair for pair in zip (image_generator, mask_generator))`\r\n  \r\n  e.      Then I build a CNN model as follows: \r\n  ```\r\n  \r\n  activation= 'relu'\r\n  model = Sequential()\r\n  model.add (Conv2D(16, kernel_size=(3, 3),activation='relu',input_shape=(231,231,3),padding='same'))\r\n  model.add (Conv2D(16, kernel_size=(3, 3),activation= activation,    padding='same'))\r\n  model.add (Flatten())\r\n  model.add (Dense(5))\r\n  model.add (Dense(3))\r\n  model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\r\n  model.summary()\r\n  \r\n  ```\r\n  \r\n  e.\tThen I used fit_generator to fit the model as follows: \r\n  \r\n  `model.fit_generator (train_generator, steps_per_epoch= 15, epochs=2, verbose=1)`\r\n\r\n### Source code / logs\r\nimport numpy as np \r\nimport pandas as pd \r\nimport matplotlib.pyplot as plt\r\nimport glob\r\nimport cv2\r\nimport os\r\nimport glob\r\nimport tensorflow as tf\r\nimport pickle\r\nfrom scipy import ndimage as nd\r\nfrom tensorflow.keras.models import Sequential\r\nfrom tensorflow.keras.layers import Conv2D\r\nfrom tensorflow.keras.layers import BatchNormalization\r\nfrom tensorflow.keras.layers import MaxPooling2D\r\nfrom tensorflow.keras.layers import Dense\r\nfrom tensorflow.keras.layers import Flatten\r\nfrom tensorflow .keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\r\nimport sklearn.utils \r\nfrom tensorflow.keras.optimizers import Adadelta, RMSprop,SGD,Adam\r\n\r\nprint(tf.__version__)\r\n\r\ntrain_path=\"C://Users//Tusneem//Documents//Untitled Folder//Tusneem_Seg//SEG_OBJ1//BAS//ROI_1//\"\r\nmask_path=\"C://Users//Tusneem//Documents//Untitled Folder//Tusneem_Seg//SEG_OBJ1//BAS//ROI_2//\"\r\n\r\n############################################################################\r\nsize = 231 \r\nimages = []\r\n\r\nfor directory_path in glob.glob(\"C://Users//Tusneem//Documents//Untitled Folder//Tusneem_Seg//SEG_OBJ1//BAS//ROI_1//ROI_train//\"):\r\n    for img_path in glob.glob(os.path.join(directory_path, \"*.tiff\")):\r\n        img = cv2.imread(img_path, cv2.IMREAD_COLOR)       \r\n        img = cv2.resize(img, (size, size))\r\n        #img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\r\n        images.append(img)\r\n        #train_labels.append(label)\r\n        \r\nimages = np.array(images)\r\n\r\nmasks = [] \r\nfor directory_path in glob.glob(\"C://Users//Tusneem//Documents//Untitled Folder//Tusneem_Seg//SEG_OBJ1//BAS//ROI_2//ROI_train//\"):\r\n    for mask_path in glob.glob(os.path.join(directory_path, \"*.tiff\")):\r\n        mask = cv2.imread(mask_path, 0)       \r\n        mask = cv2.resize(mask, (size, size))\r\n        #mask = cv2.cvtColor(mask, cv2.COLOR_RGB2BGR)\r\n        masks.append(mask)\r\n        #train_labels.append(label)\r\n        \r\nmasks = np.array(masks)\r\nmasks=np.expand_dims(masks, axis=3)\r\n\r\n#######################Example of transforming images and masks together.\r\nimport tensorflow as tf\r\n\r\n# we create two instances with the same arguments\r\ndata_gen_args = dict(featurewise_center=True,\r\n                     featurewise_std_normalization=True,\r\n                     rotation_range=90)\r\n                    \r\nimage_datagen = ImageDataGenerator(data_gen_args)\r\nmask_datagen = ImageDataGenerator(data_gen_args)\r\n# Provide the same seed and keyword arguments to the fit and flow methods\r\nseed = 1\r\nimage_datagen.fit(images, augment=True, seed=seed)\r\nmask_datagen.fit(masks, augment=True, seed=seed)\r\n\r\nimage_generator = image_datagen.flow_from_directory(\r\n    train_path,\r\n    class_mode=None,\r\n    shuffle= False,\r\n    seed=seed)\r\n\r\nmask_generator = mask_datagen.flow_from_directory(\r\n    \"C://Users//Tusneem//Documents//Untitled Folder//Tusneem_Seg//SEG_OBJ1//BAS//ROI_2//\",\r\n    class_mode=None,\r\n    shuffle= False,\r\n    seed=seed)\r\n# combine generators into one which yields image and masks\r\n#train_generator = zip(image_generator, mask_generator)\r\ntrain_generator = (pair for pair in zip(image_generator, mask_generator))\r\n\r\nactivation= 'relu'\r\n\r\nmodel = Sequential()\r\nmodel.add(Conv2D(16, kernel_size=(3, 3),activation='relu',input_shape=(231,231,3),padding='same'))\r\nmodel.add(Conv2D(16, kernel_size=(3, 3),activation='relu',padding='same'))\r\nmodel.add(Flatten())\r\nmodel.add(Dense(5))\r\nmodel.add(Dense(3))\r\nmodel.compile( loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\r\nmodel.summary()\r\n\r\nmodel.fit_generator(train_generator, steps_per_epoch= 15, epochs=2, verbose=1)\r\n\r\n**But I got the following error regarding input dimensionality:**\r\n\r\n```\r\nInvalidArgumentError:  Input to reshape is a tensor with 33554432 values, but the requested shape requires a multiple of 853776\r\n [[node sequential_8/flatten_8/Reshape (defined at <ipython-input-91-2871596287c2>:12) ]] [Op:__inference_distributed_function_7252]\r\n\r\nFunction call stack:\r\ndistributed_function\r\n```\r\n\r\n**my question is: How can I fix the problem of train_generator and CNN input shapes??**\r\n### attachments\r\n[summary of ImageDataGenarator_ZIP object_CNN.docx](https://github.com/tensorflow/tensorflow/files/7432552/summary.of.ImageDataGenarator_ZIP.object_CNN.docx)\r\n[The code.txt](https://github.com/tensorflow/tensorflow/files/7432554/The.code.txt)\r\n.\r\n", "comments": ["@tusneemA  We could see  this issue is a duplicate of #52705 , Could you please close this ticket as we will be tracking the other one ? Thank you!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52796\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52796\">No</a>\n", "I updated issue #52705 with the same information so you can track it.\r\nI also closed this issue as requested.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52796\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52796\">No</a>\n", "@tusneemA Thank you for the update! We will track the other ticket and get you the right help .Thanks!", "you are welcome\n\nOn Fri, Oct 29, 2021 at 9:13 AM sushreebarsa ***@***.***>\nwrote:\n\n> @tusneemA <https://github.com/tusneemA> Thank you for the update! We will\n> track the other ticket and get you the right help .Thanks!\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/52796#issuecomment-954458481>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/APP3NUNHF7YL2LWDC4H6Z33UJI3RFANCNFSM5G5HFE3Q>\n> .\n> Triage notifications on the go with GitHub Mobile for iOS\n> <https://apps.apple.com/app/apple-store/id1477376905?ct=notification-email&mt=8&pt=524675>\n> or Android\n> <https://play.google.com/store/apps/details?id=com.github.android&referrer=utm_campaign%3Dnotification-email%26utm_medium%3Demail%26utm_source%3Dgithub>.\n>\n>\n"]}, {"number": 52795, "title": "Unnormal low gpu usage: MobileNetV3", "body": "System information\r\n\r\n- Have I written custom code: Custom\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- TensorFlow version (use command below): 2.4.0\r\n- Python version: 3.6.10\r\n- CUDA/cuDNN version: 11.1\r\n- GPU model and memory: RTX 2080 ti *4\r\n\r\nI'm training my classifier with 4 RTX 2080 ti with MobileNetV3.\r\nUsing Pytorch, GPU utility could be up to 97%, however, it is only ~25% with Tensorflow, which costs much time for one epoch.\r\n\r\n```\r\n+-------------------------------+----------------------+----------------------+\r\n| 31%   42C    P2    80W / 250W |   9021MiB / 11019MiB |     24%      Default |\r\n|                               |                      |                  N/A |\r\n+-------------------------------+----------------------+----------------------+\r\n|   7  GeForce RTX 208...  On   | 00000000:3F:00.0 Off |                  N/A |\r\n| 32%   42C    P2    93W / 250W |   9085MiB / 11019MiB |     26%      Default |\r\n|                               |                      |                  N/A |\r\n+-------------------------------+----------------------+----------------------+\r\n|   8  GeForce RTX 208...  On   | 00000000:40:00.0 Off |                  N/A |\r\n| 32%   42C    P2    82W / 250W |   9193MiB / 11019MiB |     24%      Default |\r\n|                               |                      |                  N/A |\r\n+-------------------------------+----------------------+----------------------+\r\n|   9  GeForce RTX 208...  On   | 00000000:41:00.0 Off |                  N/A |\r\n| 31%   42C    P2    99W / 250W |   9135MiB / 11019MiB |     24%      Default |\r\n|                               |                      |                  N/A |\r\n+-------------------------------+----------------------+----------------------+\r\n```\r\n\r\n\r\ntraining code\r\n```\r\ndef mbv3(weight='imagenet', input_shape=(224, 224, 3), num_classes=6):\r\n    base_model = tf.keras.applications.MobileNetV3Large(input_shape=input_shape,\r\n                                            include_top=False,\r\n                                            weights=weight)\r\n\r\n    base_model.trainable = True\r\n    preprocess_input = tf.keras.applications.mobilenet_v3.preprocess_input\r\n    global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\r\n    prediction_layer = tf.keras.layers.Dense(num_classes)\r\n    batch_normalize_layer = tf.keras.layers.BatchNormalization()\r\n\r\n    inputs = tf.keras.Input(input_shape)\r\n    x = inputs\r\n    x = preprocess_input(x)\r\n    x = base_model(x, training=True)\r\n    x = global_average_layer(x)\r\n    x = batch_normalize_layer(x)\r\n\r\n    outputs = prediction_layer(x)\r\n    model = tf.keras.Model(inputs, outputs)\r\n    return model\r\n\r\nif __name__ == '__main__':\r\n    \r\n    gpus = tf.config.experimental.list_physical_devices('GPU')\r\n    if gpus:\r\n        for gpu in gpus:\r\n            tf.config.experimental.set_memory_growth(gpu, True)\r\n\r\n    policy = mixed_precision.experimental.Policy('mixed_float16')\r\n\r\n    mixed_precision.experimental.set_policy(policy)\r\n\r\n    mixed_precision.set_global_policy('mixed_float16')\r\n    train_ds = image_dataset_from_directory(\r\n        directory = '../data/train/',\r\n        batch_size = 512,\r\n        image_size = (224, 224))\r\n    val_ds = image_dataset_from_directory(\r\n        directory = '../data/test/',\r\n        batch_size = 512,\r\n        image_size = (224,224))\r\n\r\n    class_names = val_ds.class_names\r\n    files_path = val_ds.file_paths\r\n\r\n    AUTOTUNE = tf.data.AUTOTUNE\r\n    train_ds = train_ds.prefetch(buffer_size = AUTOTUNE)\r\n    val_ds = val_ds.prefetch(buffer_size = AUTOTUNE)\r\n\r\n    strategy = tf.distribute.MirroredStrategy([\"/GPU:0\", \"/GPU:1\", \"/GPU:2\", \"/GPU:3\"])\r\n    print('train with gpu:0,1,2,3')\r\n\r\n    with strategy.scope():\r\n        model = mbv3(weight = 'imagenet', input_shape=(224, 224, 3), num_classes = 6)\r\n        model.compile(\r\n            optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\r\n            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n            metrics=['accuracy']\r\n        )\r\n\r\n\r\n    Callbacks =[\r\n        CustomCallback(val_ds, start_time)\r\n    ]\r\n\r\n    history = model.fit(train_ds, epochs=40, verbose = 1, callbacks=Callbacks, validation_data=val_ds)\r\n```\r\nlogs\r\n```\r\n2021-10-28 14:31:09.721686: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\r\n2021-10-28 14:31:11.827415: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2021-10-28 14:31:11.828413: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\r\n2021-10-28 14:31:11.971195: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \r\npciBusID: 0000:3e:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\r\ncoreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\r\n2021-10-28 14:31:11.972475: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \r\npciBusID: 0000:3f:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\r\ncoreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\r\n2021-10-28 14:31:11.973679: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 2 with properties: \r\npciBusID: 0000:40:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\r\ncoreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\r\n2021-10-28 14:31:11.974897: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 3 with properties: \r\npciBusID: 0000:41:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\r\ncoreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\r\n2021-10-28 14:31:11.974921: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\r\n2021-10-28 14:31:11.977826: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\r\n2021-10-28 14:31:11.977892: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\r\n2021-10-28 14:31:11.978888: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\r\n2021-10-28 14:31:11.979151: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\r\n2021-10-28 14:31:11.982171: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\r\n2021-10-28 14:31:11.982859: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\r\n2021-10-28 14:31:11.983011: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\r\n2021-10-28 14:31:11.992158: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1, 2, 3\r\n2021-10-28 14:31:11.992337: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2021-10-28 14:31:11.993638: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2021-10-28 14:31:11.994873: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2021-10-28 14:31:11.996082: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\nWARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/mixed_precision/loss_scale.py:56: DynamicLossScale.__init__ (from tensorflow.python.training.experimental.loss_scale) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse tf.keras.mixed_precision.LossScaleOptimizer instead. LossScaleOptimizer now has all the functionality of DynamicLossScale\r\n2021-10-28 14:31:11.998462: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2021-10-28 14:31:12.000512: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2021-10-28 14:31:12.622385: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \r\npciBusID: 0000:3e:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\r\ncoreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\r\n2021-10-28 14:31:12.624492: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \r\npciBusID: 0000:3f:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\r\ncoreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\r\n2021-10-28 14:31:12.627911: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 2 with properties: \r\npciBusID: 0000:40:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\r\ncoreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\r\n2021-10-28 14:31:12.631088: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 3 with properties: \r\npciBusID: 0000:41:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\r\ncoreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\r\n2021-10-28 14:31:12.631116: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\r\n2021-10-28 14:31:12.631149: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\r\n2021-10-28 14:31:12.631161: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\r\n2021-10-28 14:31:12.631174: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\r\n2021-10-28 14:31:12.631187: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\r\n2021-10-28 14:31:12.631199: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\r\n2021-10-28 14:31:12.631212: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\r\n2021-10-28 14:31:12.631228: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\r\n2021-10-28 14:31:12.645693: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1, 2, 3\r\n2021-10-28 14:31:12.645739: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\r\n2021-10-28 14:31:14.550404: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2021-10-28 14:31:14.550446: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1 2 3 \r\n2021-10-28 14:31:14.550453: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N N N N \r\n2021-10-28 14:31:14.550457: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   N N N N \r\n2021-10-28 14:31:14.550461: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 2:   N N N N \r\n2021-10-28 14:31:14.550465: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 3:   N N N N \r\n2021-10-28 14:31:14.557474: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10066 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:3e:00.0, compute capability: 7.5)\r\n2021-10-28 14:31:14.561911: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10066 MB memory) -> physical GPU (device: 1, name: GeForce RTX 2080 Ti, pci bus id: 0000:3f:00.0, compute capability: 7.5)\r\n2021-10-28 14:31:14.566345: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 10066 MB memory) -> physical GPU (device: 2, name: GeForce RTX 2080 Ti, pci bus id: 0000:40:00.0, compute capability: 7.5)\r\n2021-10-28 14:31:14.570745: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 10066 MB memory) -> physical GPU (device: 3, name: GeForce RTX 2080 Ti, pci bus id: 0000:41:00.0, compute capability: 7.5)\r\nFound 1384696 files belonging to 6 classes.\r\nFound 466757 files belonging to 6 classes.\r\ntrain with gpu:0,1,2,3\r\n2021-10-28 14:32:20.799831: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Found an unshardable source dataset: name: \"TensorSliceDataset/_1\"\r\nop: \"TensorSliceDataset\"\r\ninput: \"Placeholder/_0\"\r\nattr {\r\n  key: \"Toutput_types\"\r\n  value {\r\n    list {\r\n      type: DT_STRING\r\n    }\r\n  }\r\n}\r\nattr {\r\n  key: \"output_shapes\"\r\n  value {\r\n    list {\r\n      shape {\r\n      }\r\n    }\r\n  }\r\n}\r\n\r\n2021-10-28 14:32:21.192299: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\r\n2021-10-28 14:32:21.211929: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2200000000 Hz\r\nEpoch 1/40\r\n2021-10-28 14:33:35.383104: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\r\n2021-10-28 14:33:35.885437: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\r\n2021-10-28 14:33:45.923277: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:177] Filling up shuffle buffer (this may take a while): 1760 of 4096\r\n2021-10-28 14:33:55.919233: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:177] Filling up shuffle buffer (this may take a while): 3318 of 4096\r\n2021-10-28 14:34:00.473165: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:230] Shuffle buffer filled.\r\n2021-10-28 14:34:04.182122: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\r\n  32/2705 [..............................] - ETA: 2:20:49 - loss: 1.2214 - accuracy: 0.5887\r\n```\r\nI've been stuck for weeks, please help.", "comments": ["@YingYuChen97 ,\r\nCan you please try to execute the code in new virtual environment with latest stable tensorflow version v2.6 and let us know if the issue still persists.Thanks!", "@tilakrayal Our device couldn't update Cuda to match V2.6, V2.4 is the latest version I could use.", "First problem is solved after I update to Tensorflow V2.6.\r\n\r\nAnother problem: I rewrite my training code and it seems totally the same as the original one. However, it couldn't run.\r\n```\r\n1/2705 [..............................] - ETA: 80:12:40 - loss: 2.5381 - accuracy: 0.16022021-10-29 11:56:27.498761: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\r\n2021-10-29 11:56:27.498799: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\r\n2/2705 [..............................] - ETA: 3:58:41 - loss: 2.4550 - accuracy: 0.1821 2021-10-29 11:56:30.014593: I tensorflow/core/profiler/lib/profiler_session.cc:71] Profiler session collecting data.\r\n2021-10-29 11:56:30.016501: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1487] CUPTI activity buffer flushed\r\nSegmentation fault (core dumped)\r\n```\r\n```\r\nfrom absl import app, flags, logging\r\nfrom absl.flags import FLAGS\r\nimport time\r\nimport numpy as np\r\nimport os\r\nimport tensorflow as tf\r\nimport pdb\r\nimport datetime\r\n\r\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory\r\nfrom tensorflow.keras import mixed_precision\r\n\r\nfrom modules.utils import load_yaml, set_memory_growth\r\nfrom modules.callback import CustomCallback, checkpoint_callback, tb_callback\r\nfrom modules.models import MBN3_Model\r\nfrom modules.lr_scheduler import scheduler\r\n\r\n\r\nif __name__ == '__main__':\r\n    cfg = load_yaml('./configs/mbn3.yaml')\r\n    set_memory_growth()\r\n\r\n    policy = mixed_precision.experimental.Policy(cfg['mixed_precision'])\r\n    mixed_precision.experimental.set_policy(policy)\r\n\r\n    mixed_precision.set_global_policy(cfg['mixed_precision'])\r\n\r\n    time_now = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\r\n\r\n    image_size = (cfg['image_size'], cfg['image_size'])\r\n\r\n    train_dataset = image_dataset_from_directory(\r\n        directory = cfg['train_dataset']['path'],\r\n        batch_size = cfg['batch_size'],\r\n        image_size = image_size,\r\n        shuffle=True)\r\n    validation_dataset = image_dataset_from_directory(\r\n        directory = cfg['test_dataset']['path'],\r\n        batch_size = cfg['batch_size'],\r\n        image_size = image_size,\r\n        shuffle=False)\r\n\r\n\r\n    files_path = validation_dataset.file_paths\r\n    class_names = validation_dataset.class_names\r\n    result = {}\r\n    for f in files_path:\r\n        result[f] = {}\r\n        result[f]['label'] = f.split('/')[-2]\r\n\r\n    AUTOTUNE = tf.data.AUTOTUNE\r\n    train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\r\n    validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\r\n\r\n    strategy = tf.distribute.MirroredStrategy(cfg['gpu'])\r\n    print('train with ',cfg['gpu'])\r\n\r\n    with strategy.scope():\r\n        model = MBN3_Model()\r\n        model.compile(\r\n            optimizer=tf.keras.optimizers.Adam(lr=cfg['learning_rate']),\r\n            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n            metrics=['accuracy'])\r\n\r\n    model_checkpoint_callback = checkpoint_callback(time_now,cfg['model_save_path'], cfg['test_name'])\r\n\r\n    log_dir = cfg['tensorboard_path'] + cfg['test_name']+ \"_\" + time_now\r\n    tensorboard_callback = tb_callback(log_dir)\r\n\r\n    print('start training...')\r\n    \r\n    history = model.fit(train_dataset,\r\n                        epochs=cfg['epoch'],\r\n                        callbacks=[model_checkpoint_callback,\r\n                                CustomCallback(validation_dataset, result, files_path, class_names),\r\n                                tensorboard_callback],\r\n                                validation_data = validation_dataset)\r\n```\r\n\r\nwhy is there difference...", "@YingYuChen97 What was difference between old code (that was working) and new code? Was there any change in `mixed_precision` Policy? Was there any difference in the inputs and their sizes? Can you share the error log? Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Using version 2.6 is fine, but don't know where's the difference.\r\nThank you.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52795\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52795\">No</a>\n"]}, {"number": 52793, "title": "Add all the averaging methods available for Precion, Recall and F-score in sklearn, natively in tensorflow or tensorflow-addons", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 2.4.3\r\n- Are you willing to contribute it (Yes/No): Yes, but I have very little knowledge on tensorflow's graph execution works. So, I can't contribute.\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nCurrently the [Recall](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Recall)/[Precision ](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Precision)metric available in tensorflow only provides binary averaged score; and [F1Score](https://www.tensorflow.org/addons/api_docs/python/tfa/metrics/F1Score) and [FBetaScore](https://www.tensorflow.org/addons/api_docs/python/tfa/metrics/FBetaScore). It would be very convenient and avoids the need to write (half-baked, at least in my case) custom metrics from user side, if other averaging methods available in sklearn, that is 'macro', 'micro' and 'samples'(for multi-label problems), are also implemented in either tensorflow or tensorflow-addons.\r\n\r\n**Will this change the current api? How?**\r\nI presume, No.\r\n\r\n**Who will benefit with this feature?**\r\nevery one working on multi-class and multi-label classification problems, who like to use those averaging methods.\r\n\r\n**Any Other info.**\r\nAll aforementioned metrics from sklearn's API docs are hyperlinked below: \r\n[sklearn's Recall](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html#sklearn.metrics.recall_score), [sklearn's Precision](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html#sklearn.metrics.precision_score), [sklearn's F1Score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score) and [sklearn's FBeta Score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.fbeta_score.html#sklearn.metrics.fbeta_score)", "comments": ["@naveen-marthala This is a feature request for Keras.\r\n\r\nPlease note that Keras development moved to another repository to focus entirely on only keras. Could you please repost this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues). Thanks!", "ok @jvishnuvardhan ", "@jvishnuvardhan, opened it [here in keras repo](https://github.com/keras-team/keras/issues/15808)."]}, {"number": 52792, "title": "PR #51732: Fix crash of tf.image.crop_and_resize when input is large \u2026", "body": "\u2026number\r\n\r\nImported from GitHub PR https://github.com/tensorflow/tensorflow/pull/51732\r\n\r\nThis PR is part of the effort in #46890 where\r\ntf.image.crop_and_resize will crash if shape consists of large number.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>\r\nCopybara import of the project:\r\n\r\n--\r\nc8d87055a56d8740d27ad8bdc74a7459ede6900e by Yong Tang <yong.tang.github@outlook.com>:\r\n\r\nFix crash of tf.image.crop_and_resize when input is large number\r\n\r\nThis PR is part of the effort in 46890 where\r\ntf.image.crop_and_resize will crash if shape consists of large number.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>\r\nCOPYBARA_INTEGRATE_REVIEW=https://github.com/tensorflow/tensorflow/pull/51732 from yongtang:46890-tf.image.crop_and_resize c8d87055a56d8740d27ad8bdc74a7459ede6900e\r\nPiperOrigin-RevId: 394109830\r\nChange-Id: If049dad0844df9353722029ee95bc76819eda1f4", "comments": ["#52843"]}, {"number": 52791, "title": "PR #51732: Fix crash of tf.image.crop_and_resize when input is large \u2026", "body": "\u2026number\r\n\r\nImported from GitHub PR https://github.com/tensorflow/tensorflow/pull/51732\r\n\r\nThis PR is part of the effort in #46890 where\r\ntf.image.crop_and_resize will crash if shape consists of large number.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>\r\nCopybara import of the project:\r\n\r\n--\r\nc8d87055a56d8740d27ad8bdc74a7459ede6900e by Yong Tang <yong.tang.github@outlook.com>:\r\n\r\nFix crash of tf.image.crop_and_resize when input is large number\r\n\r\nThis PR is part of the effort in 46890 where\r\ntf.image.crop_and_resize will crash if shape consists of large number.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>\r\nCOPYBARA_INTEGRATE_REVIEW=https://github.com/tensorflow/tensorflow/pull/51732 from yongtang:46890-tf.image.crop_and_resize c8d87055a56d8740d27ad8bdc74a7459ede6900e\r\nPiperOrigin-RevId: 394109830\r\nChange-Id: If049dad0844df9353722029ee95bc76819eda1f4", "comments": ["#52842"]}, {"number": 52790, "title": "Merge pull request #51658 from yongtang:51618-tf.image.extract_glimpse", "body": "PiperOrigin-RevId: 401246064\r\nChange-Id: I9e64ab662b1a0bc8c6be4dcc4f0e620db6708d22", "comments": []}, {"number": 52789, "title": "Merge pull request #51658 from yongtang:51618-tf.image.extract_glimpse", "body": "PiperOrigin-RevId: 401246064\r\nChange-Id: I9e64ab662b1a0bc8c6be4dcc4f0e620db6708d22", "comments": []}, {"number": 52788, "title": "Merge pull request #51658 from yongtang:51618-tf.image.extract_glimpse", "body": "PiperOrigin-RevId: 401246064\r\nChange-Id: I9e64ab662b1a0bc8c6be4dcc4f0e620db6708d22", "comments": []}, {"number": 52787, "title": "Merge pull request #51717 from yongtang:46890-tf.image.pad_to_boundin\u2026", "body": "\u2026g_box\r\n\r\nPiperOrigin-RevId: 398351034\r\nChange-Id: Ia11abe3ab57683ca2efea786fd095338d0c8c3b7", "comments": []}, {"number": 52786, "title": "Merge pull request #51717 from yongtang:46890-tf.image.pad_to_boundin\u2026", "body": "\u2026g_box\r\n\r\nPiperOrigin-RevId: 398351034\r\nChange-Id: Ia11abe3ab57683ca2efea786fd095338d0c8c3b7", "comments": []}, {"number": 52785, "title": "Merge pull request #51717 from yongtang:46890-tf.image.pad_to_boundin\u2026", "body": "\u2026g_box\r\n\r\nPiperOrigin-RevId: 398351034\r\nChange-Id: Ia11abe3ab57683ca2efea786fd095338d0c8c3b7", "comments": []}, {"number": 52784, "title": "Fixing security fixes in boosted trees ops", "body": "PiperOrigin-RevId: 405669548\r\nChange-Id: Iae224d240d1779bcc02405c2fff99785644fbd0d", "comments": ["#52822"]}, {"number": 52783, "title": "Fix null pointer exception in shape inference function when tf.ragged\u2026", "body": "\u2026.cross() is called with invalid inputs.\r\n\r\nPiperOrigin-RevId: 400045848\r\nChange-Id: Ia65501583b85cf1ec14a252d83fbdd716817a516", "comments": []}, {"number": 52782, "title": "Fix null pointer exception in shape inference function when tf.ragged\u2026", "body": "\u2026.cross() is called with invalid inputs.\r\n\r\nPiperOrigin-RevId: 400045848\r\nChange-Id: Ia65501583b85cf1ec14a252d83fbdd716817a516", "comments": []}, {"number": 52781, "title": "Adding more validation checks to _ParallelConcatUpdate to avoid NPE.", "body": "PiperOrigin-RevId: 402569467\r\nChange-Id: I2db122dab68be2a5e4e8dd3375f5a70c4d2307ec", "comments": ["#52832"]}, {"number": 52780, "title": "Fix out-of-bounds memory error in tf.ragged.cross shape inference whe\u2026", "body": "\u2026n it is called with invalid inputs.\r\n\r\nPiperOrigin-RevId: 400049589\r\nChange-Id: Icd535f4c6b96b3c926befb70a0e44e6d2b004c0a", "comments": []}, {"number": 52779, "title": "Fix out-of-bounds memory error in tf.ragged.cross shape inference whe\u2026", "body": "\u2026n it is called with invalid inputs.\r\n\r\nPiperOrigin-RevId: 400049589\r\nChange-Id: Icd535f4c6b96b3c926befb70a0e44e6d2b004c0a", "comments": []}]