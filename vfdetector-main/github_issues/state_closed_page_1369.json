[{"number": 11999, "title": "Update tensor_util.py", "body": "np.array makes a copy of the object which is not required so usage of np.asarray would be more efficient", "comments": ["Can one of the admins verify this patch?", "@gautam1858, thanks for your PR! By analyzing the history of the files in this pull request, we identified @keveman, @vrv and @girving to be potential reviewers.", "I don't think so ?", "This message was created automatically by mail delivery software.\n\nA message that you sent could not be delivered to one or more of its\nrecipients. This is a temporary error. The following address(es) deferred:\n\n  mazecreator@gmail.com\n    Domain mazecreator.com has exceeded the max emails per hour (26/25 (104%)) allowed.  Message will be reattempted later\n\n------- This is a copy of the message, including all the headers. ------\nReceived: from github-smtp2-ext3.iad.github.net ([192.30.252.194]:50011 helo=github-smtp2b-ext-cp1-prd.iad.github.net)\n\tby server2.lowesthostingrates.com with esmtps (TLSv1.2:ECDHE-RSA-AES256-GCM-SHA384:256)\n\t(Exim 4.89)\n\t(envelope-from <noreply@github.com>)\n\tid 1ddIOq-0008RC-6f\n\tfor mazecreator@mazecreator.com; Thu, 03 Aug 2017 10:51:30 -0500\nDate: Thu, 03 Aug 2017 09:01:42 -0700\nDKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=github.com;\n\ts=pf2014; t=1501776102;\n\tbh=m9q4A+a+t7t0GTTEfP39jWPSAP3IGsn2ML3n1NxkcFc=;\n\th=From:Reply-To:To:Cc:In-Reply-To:References:Subject:List-ID:\n\t List-Archive:List-Post:List-Unsubscribe:From;\n\tb=aPGxa8hEZ548LId0etnFnKvS5UvCgMzIdnG83ZYXODyPkYeJEf7vIvf0VQA2wqEUQ\n\t iqplHq6xOowTxoEiPIpjvzQ4arR/X5R+8/2MjwSjqJwyNpTn/U+1m99z199Y6/yO2q\n\t kJJlIikFkg0qXNy6H/Sy1sW5DaXzN0tw5cv6XMOo=\nFrom: Gautam <notifications@github.com>\nReply-To: tensorflow/tensorflow <reply@reply.github.com>\nTo: tensorflow/tensorflow <tensorflow@noreply.github.com>\nCc: Subscribed <subscribed@noreply.github.com>\nMessage-ID: <tensorflow/tensorflow/pull/11999/c320013178@github.com>\nIn-Reply-To: <tensorflow/tensorflow/pull/11999@github.com>\nReferences: <tensorflow/tensorflow/pull/11999@github.com>\nSubject: Re: [tensorflow/tensorflow] Update tensor_util.py (#11999)\nMime-Version: 1.0\nContent-Type: multipart/alternative;\n boundary=\"--==_mimepart_598348e67e612_4f543ff9b29d1c3c323785\";\n charset=UTF-8\nContent-Transfer-Encoding: 7bit\nPrecedence: list\nX-GitHub-Sender: gautam1858\nX-GitHub-Recipient: Mazecreator\nX-GitHub-Reason: subscribed\nList-ID: tensorflow/tensorflow <tensorflow.tensorflow.github.com>\nList-Archive: https://github.com/tensorflow/tensorflow\nList-Post: <mailto:reply@reply.github.com>\nList-Unsubscribe: <mailto:unsub+0118f3a0664dfe4376a4f179ac5d9178252bebd4015914d692cf00000001159b0ae692a169ce0ec318d0@reply.github.com>,\n <https://github.com/notifications/unsubscribe/ARjzoJSpDahIMvzH__bHt5wcS99gV26Zks5sUe7mgaJpZM4OsRcW>\nX-Auto-Response-Suppress: All\nX-GitHub-Recipient-Address: mazecreator@mazecreator.com\nX-Spam-Status: No, score=\nX-Spam-Score:\nX-Spam-Bar:\nX-Ham-Report:\nX-Spam-Flag: NO\n\n\n----==_mimepart_598348e67e612_4f543ff9b29d1c3c323785\nContent-Type: text/plain;\n charset=UTF-8\nContent-Transfer-Encoding: 7bit\n\nI don't think so ?\n\n-- \nYou are receiving this because you are subscribed to this thread.\nReply to this email directly or view it on GitHub:\nhttps://github.com/tensorflow/tensorflow/pull/11999#issuecomment-320013178\n----==_mimepart_598348e67e612_4f543ff9b29d1c3c323785\nContent-Type: text/html;\n charset=UTF-8\nContent-Transfer-Encoding: 7bit\n\n<p>I don't think so ?</p>\n\n<p style=\"font-size:small;-webkit-text-size-adjust:none;color:#666;\">&mdash;<br />You are receiving this because you are subscribed to this thread.<br />Reply to this email directly, <a href=\"https://github.com/tensorflow/tensorflow/pull/11999#issuecomment-320013178\">view it on GitHub</a>, or <a href=\"https://github.com/notifications/unsubscribe-auth/ARjzoOFTiBMVkVFenHBk3PHejdxuL_S8ks5sUe7mgaJpZM4OsRcW\">mute the thread</a>.<img alt=\"\" height=\"1\" src=\"https://github.com/notifications/beacon/ARjzoEOxY3RDiOPMT6zcwIwit3l68Ondks5sUe7mgaJpZM4OsRcW.gif\" width=\"1\" /></p>\n<div itemscope itemtype=\"http://schema.org/EmailMessage\">\n<div itemprop=\"action\" itemscope itemtype=\"http://schema.org/ViewAction\">\n  <link itemprop=\"url\" href=\"https://github.com/tensorflow/tensorflow/pull/11999#issuecomment-320013178\"></link>\n  <meta itemprop=\"name\" content=\"View Pull Request\"></meta>\n</div>\n<meta itemprop=\"description\" content=\"View this Pull Request on GitHub\"></meta>\n</div>\n\n<script type=\"application/json\" data-scope=\"inboxmarkup\">{\"api_version\":\"1.0\",\"publisher\":{\"api_key\":\"05dde50f1d1a384dd78767c55493e4bb\",\"name\":\"GitHub\"},\"entity\":{\"external_key\":\"github/tensorflow/tensorflow\",\"title\":\"tensorflow/tensorflow\",\"subtitle\":\"GitHub repository\",\"main_image_url\":\"https://cloud.githubusercontent.com/assets/143418/17495839/a5054eac-5d88-11e6-95fc-7290892c7bb5.png\",\"avatar_image_url\":\"https://cloud.githubusercontent.com/assets/143418/15842166/7c72db34-2c0b-11e6-9aed-b52498112777.png\",\"action\":{\"name\":\"Open in GitHub\",\"url\":\"https://github.com/tensorflow/tensorflow\"}},\"updates\":{\"snippets\":[{\"icon\":\"PERSON\",\"message\":\"@gautam1858 in #11999: I don't think so ?\"}],\"action\":{\"name\":\"View Pull Request\",\"url\":\"https://github.com/tensorflow/tensorflow/pull/11999#issuecomment-320013178\"}}}</script>\n----==_mimepart_598348e67e612_4f543ff9b29d1c3c323785--\n", "> I don't think so ?\r\n\r\nI believe any ndarray passed to this function will be handled by that case.\r\n\r\n```python\r\n>>> a = np.array([1, 2, 3, 4])\r\n>>> callable(getattr(a, '__array__'))\r\nTrue\r\n```", "Yup got it :) Thank you \ud83d\udc4d "]}, {"number": 11998, "title": "tensorflow multi label classification", "body": "How does tensorflow CNN implement multi label classification, specifically how to input multi tags and output multi label prediction results?", "comments": ["You could have a look at this https://github.com/tensorflow/skflow/issues/113", "This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 11997, "title": "Merge pull request #1 from tensorflow/master", "body": "update from tensorflow_master", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->", "update from master", "Can one of the admins verify this patch?"]}, {"number": 11996, "title": "tensorflow Makefile build does not support building arm64-v8a static library for Android", "body": "Currently tensorflow has only support build static library in `armeabi-v7a` for Android.  \r\n\r\nAnd the build script has not support the other platforms yet as we can see in:\r\n [`tensorflow/tensorflow/contrib/makefile/Makefile`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/makefile/Makefile#L219)\r\n\r\nOur team would like to build all the architecture for Android if possible, and we tried to fixed the `makefile` that expect to link with our Android project but got many linking errors except `armeabi-v7a`.\r\n\r\nSo, I was just wondering if tensorflow will support those platform: `arm64-v8a`, `x86`, `x88_64`?\r\n\r\n", "comments": ["Tensorflow supports these architecture : arm64-v8a armeabi armeabi-v7a armeabi-v7a-hard mips mips64 x86 x86_64", "@gautam1858 There is a TODO tips comment in makefile says: it will support all architectures but currently only supported `armeabi-v7a`. I mean, the static libraries.", "@AngryPowman It had worked for me, I had built the object file with bazel and --cpu=arm64-v8a architecture", "@AngryPowman As @gautam1858 notes, you can build TF for all supported mobile architectures, including arm64-v8a, with Bazel.\r\n\r\nThese libraries are also published in the [prebuilt nightly libs](https://ci.tensorflow.org/view/Nightly/job/nightly-android/) and the TensorFlow AAR also contains them (usage described [here](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/android)), which is the recommended way of integrating TF if you don't need custom functionality.\r\n\r\nWe don't have build support for architectures other than armeabi-v7a using the Makefile build yet, but user contributions are welcome to remedy that."]}, {"number": 11995, "title": "Errors", "body": "Hi I am running a simple tensor flow script and I am getting the following errors\r\n - OS is macOS\r\n-Tensorflow binary 1.2.1 version\r\n-python version 3.5 \r\n\r\nThe thing is it runs on the Jupyter notebook buy when I run python add.py I get the following errors\r\n\r\n```\r\n`File \"trail1.py\", line 4, in <module>\r\n    import tensorflow as tf\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/__init__.py\", line 52, in <module>\r\n    from tensorflow.core.framework.graph_pb2 import *\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/core/framework/graph_pb2.py\", line 6, in <module>\r\n    from google.protobuf import descriptor as _descriptor\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/google/protobuf/descriptor.py\", line 37, in <module>\r\n    import six\r\n  File \"/Users/neutrino/six.py\", line 1, in <module>\r\n    from tensorflow.contrib.tensorboard.plugins import projector\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/contrib/__init__.py\", line 22, in <module>\r\n    from tensorflow.contrib import bayesflow\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/contrib/bayesflow/__init__.py\", line 24, in <module>\r\n    from tensorflow.contrib.bayesflow.python.ops import entropy\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/contrib/bayesflow/python/ops/entropy.py\", line 23, in <module>\r\n    from tensorflow.contrib.bayesflow.python.ops.entropy_impl import *\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/contrib/bayesflow/python/ops/entropy_impl.py\", line 29, in <module>\r\n    from tensorflow.contrib.bayesflow.python.ops import monte_carlo_impl as monte_carlo\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/contrib/bayesflow/python/ops/monte_carlo_impl.py\", line 28, in <module>\r\n    from tensorflow.python.framework import ops\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 30, in <module>\r\n    from tensorflow.core.framework import attr_value_pb2\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/core/framework/attr_value_pb2.py\", line 8, in <module>\r\n    from google.protobuf import reflection as _reflection\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/google/protobuf/reflection.py\", line 58, in <module>\r\n    from google.protobuf.internal import python_message as message_impl\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/google/protobuf/internal/python_message.py\", line 62, in <module>\r\n    from google.protobuf.internal import decoder\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/google/protobuf/internal/decoder.py\", line 87, in <module>\r\n    if six.PY3:\r\nAttributeError: module 'six' has no attribute 'PY3'`\r\n```", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 11994, "title": "tensorflow-1.2.1\uff1aTypeError: sampled_loss() got an unexpected keyword argument 'logits'", "body": "# the code is:\r\n    def sampled_loss(labels, inputs):\r\n            labels = tf.reshape(labels, [-1, 1])\r\n            # We need to compute the sampled_softmax_loss using 32bit floats to\r\n            # avoid numerical instabilities.\r\n            local_w_t = tf.cast(w_t, tf.float32)\r\n            local_b = tf.cast(b, tf.float32)\r\n            local_inputs = tf.cast(inputs, tf.float32)\r\n            return tf.cast(\r\n                tf.nn.sampled_softmax_loss(\r\n                    weights=local_w_t,\r\n                    biases=local_b,\r\n                    labels=labels,\r\n                    inputs=local_inputs,\r\n                    num_sampled=num_samples,\r\n                    num_classes=self.target_vocab_size),tf.float32)\r\n      \r\n           softmax_loss_function = sampled_loss\r\n\r\n\r\nTraceback (most recent call last):\r\n  File \"predict.py\", line 177, in <module>\r\n    tf.app.run()\r\n  File \"/home/amax/tensorflow/1.2.1/local/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 48, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"predict.py\", line 159, in main\r\n    decode()\r\n  File \"predict.py\", line 40, in decode\r\n    model = create_model(sess, True)\r\n  File \"/home/BD/bd_chenyi/nlp_code/textsum/textsum.py\", line 144, in create_model\r\n    forward_only=forward_only)\r\n  File \"/home/BD/bd_chenyi/nlp_code/textsum/seq2seq_model.py\", line 167, in __init__\r\n    softmax_loss_function=softmax_loss_function)\r\n  File \"/home/amax/tensorflow/1.2.1/local/lib/python2.7/site-packages/tensorflow/contrib/legacy_seq2seq/python/ops/seq2seq.py\", line 1221, in model_with_buckets\r\n    softmax_loss_function=softmax_loss_function))\r\n  File \"/home/amax/tensorflow/1.2.1/local/lib/python2.7/site-packages/tensorflow/contrib/legacy_seq2seq/python/ops/seq2seq.py\", line 1134, in sequence_loss\r\n    softmax_loss_function=softmax_loss_function))\r\n  File \"/home/amax/tensorflow/1.2.1/local/lib/python2.7/site-packages/tensorflow/contrib/legacy_seq2seq/python/ops/seq2seq.py\", line 1089, in sequence_loss_by_example\r\n    crossent = softmax_loss_function(labels=target, logits=logit)\r\nTypeError: sampled_loss() got an unexpected keyword argument 'logits'", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!", "Why isn't this a bug?  The bug seems to be in `tensorflow/contrib/legacy_seq2seq/python/ops/seq2seq.py`.", "Have you solved this problem? I also encountered this problem, the code is the same as yours, can you tell me how to solve it? Thank you very much!", "you can try to modify the first line to \"def sampled_loss(labels, logits):\".Of course, you need to modify the corresponding code below.I don't know why,but my code can working by this modify"]}, {"number": 11993, "title": "Update parameterized_docker_build.sh", "body": "typo : Dockerilfe > Dockerfile", "comments": ["@fxfabre, thanks for your PR! By analyzing the history of the files in this pull request, we identified @caisq, @Androbin and @tensorflower-gardener to be potential reviewers.", "Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "Jenkins, test this please.", "Jenkins, test this please.", "This message was created automatically by mail delivery software.\n\nA message that you sent could not be delivered to one or more of its\nrecipients. This is a temporary error. The following address(es) deferred:\n\n  mazecreator@gmail.com\n    Domain mazecreator.com has exceeded the max emails per hour (27/25 (108%)) allowed.  Message will be reattempted later\n\n------- This is a copy of the message, including all the headers. ------\nReceived: from github-smtp2-ext2.iad.github.net ([192.30.252.193]:55315 helo=github-smtp2b-ext-cp1-prd.iad.github.net)\n\tby server2.lowesthostingrates.com with esmtps (TLSv1.2:ECDHE-RSA-AES256-GCM-SHA384:256)\n\t(Exim 4.89)\n\t(envelope-from <noreply@github.com>)\n\tid 1ddNok-0006k4-2c\n\tfor mazecreator@mazecreator.com; Thu, 03 Aug 2017 16:38:36 -0500\nDate: Thu, 03 Aug 2017 14:48:49 -0700\nDKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=github.com;\n\ts=pf2014; t=1501796929;\n\tbh=PYfZZ6XQbKPrrt9qwGh/6g85uMoCPPc1Ofw+zne71Uk=;\n\th=From:Reply-To:To:Cc:In-Reply-To:References:Subject:List-ID:\n\t List-Archive:List-Post:List-Unsubscribe:From;\n\tb=AFfQJ2S4iDjHCE9OiOySZbqvx1oCUfMy76I2Vz7zPgCfnbEYVuf2QY4V8z4cf4mRE\n\t Pi3tnxhLkV7TDtfMUE2KVG3QU2pVgsrVWu00+3ma5CbSgpM2D/YmBolN0G2d5JyzGU\n\t tUSo9hLxUQrEbbBPPtY7i6MnddLN+87X9PqheGTo=\nFrom: Benoit Steiner <notifications@github.com>\nReply-To: tensorflow/tensorflow <reply@reply.github.com>\nTo: tensorflow/tensorflow <tensorflow@noreply.github.com>\nCc: Subscribed <subscribed@noreply.github.com>\nMessage-ID: <tensorflow/tensorflow/pull/11993/c320099099@github.com>\nIn-Reply-To: <tensorflow/tensorflow/pull/11993@github.com>\nReferences: <tensorflow/tensorflow/pull/11993@github.com>\nSubject: Re: [tensorflow/tensorflow] Update parameterized_docker_build.sh\n (#11993)\nMime-Version: 1.0\nContent-Type: multipart/alternative;\n boundary=\"--==_mimepart_59839a4185d4_15d13f896193dc384352ae\";\n charset=UTF-8\nContent-Transfer-Encoding: 7bit\nPrecedence: list\nX-GitHub-Sender: benoitsteiner\nX-GitHub-Recipient: Mazecreator\nX-GitHub-Reason: subscribed\nList-ID: tensorflow/tensorflow <tensorflow.tensorflow.github.com>\nList-Archive: https://github.com/tensorflow/tensorflow\nList-Post: <mailto:reply@reply.github.com>\nList-Unsubscribe: <mailto:unsub+0118f3a00cf1675a00f02704ffe5ca03c1bd9d5c2c9c1e3a92cf00000001159b5c4192a169ce0ec2667c@reply.github.com>,\n <https://github.com/notifications/unsubscribe/ARjzoNRx5OWojLgwRp2wr44Tsyp8Uk7-ks5sUkBBgaJpZM4OsFG9>\nX-Auto-Response-Suppress: All\nX-GitHub-Recipient-Address: mazecreator@mazecreator.com\nX-Spam-Status: No, score=\nX-Spam-Score:\nX-Spam-Bar:\nX-Ham-Report:\nX-Spam-Flag: NO\n\n\n----==_mimepart_59839a4185d4_15d13f896193dc384352ae\nContent-Type: text/plain;\n charset=UTF-8\nContent-Transfer-Encoding: 7bit\n\nJenkins, test this please.\n\n-- \nYou are receiving this because you are subscribed to this thread.\nReply to this email directly or view it on GitHub:\nhttps://github.com/tensorflow/tensorflow/pull/11993#issuecomment-320099099\n----==_mimepart_59839a4185d4_15d13f896193dc384352ae\nContent-Type: text/html;\n charset=UTF-8\nContent-Transfer-Encoding: 7bit\n\n<p>Jenkins, test this please.</p>\n\n<p style=\"font-size:small;-webkit-text-size-adjust:none;color:#666;\">&mdash;<br />You are receiving this because you are subscribed to this thread.<br />Reply to this email directly, <a href=\"https://github.com/tensorflow/tensorflow/pull/11993#issuecomment-320099099\">view it on GitHub</a>, or <a href=\"https://github.com/notifications/unsubscribe-auth/ARjzoLCGswFKIDj9-tDg36PEr5cA-xyhks5sUkBBgaJpZM4OsFG9\">mute the thread</a>.<img alt=\"\" height=\"1\" src=\"https://github.com/notifications/beacon/ARjzoPmaBM40gSLli1yQZTrqsAJBh7Kvks5sUkBBgaJpZM4OsFG9.gif\" width=\"1\" /></p>\n<div itemscope itemtype=\"http://schema.org/EmailMessage\">\n<div itemprop=\"action\" itemscope itemtype=\"http://schema.org/ViewAction\">\n  <link itemprop=\"url\" href=\"https://github.com/tensorflow/tensorflow/pull/11993#issuecomment-320099099\"></link>\n  <meta itemprop=\"name\" content=\"View Pull Request\"></meta>\n</div>\n<meta itemprop=\"description\" content=\"View this Pull Request on GitHub\"></meta>\n</div>\n\n<script type=\"application/json\" data-scope=\"inboxmarkup\">{\"api_version\":\"1.0\",\"publisher\":{\"api_key\":\"05dde50f1d1a384dd78767c55493e4bb\",\"name\":\"GitHub\"},\"entity\":{\"external_key\":\"github/tensorflow/tensorflow\",\"title\":\"tensorflow/tensorflow\",\"subtitle\":\"GitHub repository\",\"main_image_url\":\"https://cloud.githubusercontent.com/assets/143418/17495839/a5054eac-5d88-11e6-95fc-7290892c7bb5.png\",\"avatar_image_url\":\"https://cloud.githubusercontent.com/assets/143418/15842166/7c72db34-2c0b-11e6-9aed-b52498112777.png\",\"action\":{\"name\":\"Open in GitHub\",\"url\":\"https://github.com/tensorflow/tensorflow\"}},\"updates\":{\"snippets\":[{\"icon\":\"PERSON\",\"message\":\"@benoitsteiner in #11993: Jenkins, test this please.\"}],\"action\":{\"name\":\"View Pull Request\",\"url\":\"https://github.com/tensorflow/tensorflow/pull/11993#issuecomment-320099099\"}}}</script>\n----==_mimepart_59839a4185d4_15d13f896193dc384352ae--\n"]}, {"number": 11992, "title": "Add SerializeTensor operator", "body": "The opposite of ParseTensor, this operator takes a tensor as input and outputs a serialized TensorProto.", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->", "I signed it.", "CLAs look good, thanks!\n\n<!-- ok -->", "This needs API-review first, and it passes API-review, then you should add tests to validate its correctness. ", "Test code added.", "Would this work?", "@tensorflow-jenkins test this please", "Jenkins, test this please", "Can you update the goldens as part of the API compatibility test? See the Linux CPU Tests failure.", "Goldens updated.", "Jenkins, test this please", "Jenkins, test this please.", "There seem to be build failures and I cannot rule out that this is the cause on the face of it.", "The failure information is quite strange, and I couldn't see the relationship to my modification.", "It looks like some clang compile error, take a look at https://ci.tensorflow.org/job/tensorflow-pull-requests-mac/6161/consoleFull\r\n\r\nBelow:\r\n\r\nbazel-out/darwin_x86_64-opt/bin/tensorflow/core/kernels/_objs/parse_tensor_test/tensorflow/core/kernels/parse_tensor_test.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\r\ntensorflow/core/kernels/parse_tensor_test.cc:173:25: error: non-constant-expression cannot be narrowed from type 'double' to 'float' in initializer list [-Wc++11-narrowing]\r\n      return complex64{ x / 8., x / 2. };\r\n                        ^~~~~~\r\ntensorflow/core/kernels/parse_tensor_test.cc:173:25: note: insert an explicit cast to silence this issue\r\n      return complex64{ x / 8., x / 2. };\r\n                        ^~~~~~\r\n                        static_cast<float>( )\r\ntensorflow/core/kernels/parse_tensor_test.cc:173:33: error: non-constant-expression cannot be narrowed from type 'double' to 'float' in initializer list [-Wc++11-narrowing]\r\n      return complex64{ x / 8., x / 2. };\r\n                                ^~~~~~\r\ntensorflow/core/kernels/parse_tensor_test.cc:173:33: note: insert an explicit cast to silence this issue\r\n      return complex64{ x / 8., x / 2. };\r\n                                ^~~~~~\r\n                                static_cast<float>( )", "Jenkins, test this please.", "Thanks for all the help!"]}, {"number": 11991, "title": " ERROR: Skipping '//tensorflow/tools/pip_package:build_pip_package': error loading package 'tensorflow/tools/pip_package': Encountered error while reading extension file 'cuda/build_defs.bzl': no such package '@local_config_cuda//cuda'", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04.4\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**: \r\n- **Bazel version (if compiling from source)**: 0.5.3\r\n- **CUDA/cuDNN version**: 6.0.21\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**: bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\r\n\r\n### Describe the problem\r\n\r\nI know someone had reported the same issue. Their solution is to roll back bazel to 0.5.2. But it does not work on my machine. Does anyone know how to fix this problem without the need of rolling back bazel? Thx!\r\n\r\n> tensorflow-git$ sudo bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package \r\n> WARNING: ignoring http_proxy in environment.\r\n> .......\r\n> ERROR: Skipping '//tensorflow/tools/pip_package:build_pip_package': error loading package 'tensorflow/tools/pip_package': Encountered error while reading extension file 'cuda/build_defs.bzl': no such package '@local_config_cuda//cuda': Traceback (most recent call last):\r\n> \tFile \"/home/intel/DevLib/tensorflow-git/third_party/gpus/cuda_configure.bzl\", line 1039\r\n> \t\t_create_local_cuda_repository(repository_ctx)\r\n> \tFile \"/home/intel/DevLib/tensorflow-git/third_party/gpus/cuda_configure.bzl\", line 976, in _create_local_cuda_repository\r\n> \t\t_host_compiler_includes(repository_ctx, cc)\r\n> \tFile \"/home/intel/DevLib/tensorflow-git/third_party/gpus/cuda_configure.bzl\", line 145, in _host_compiler_includes\r\n> \t\tget_cxx_inc_directories(repository_ctx, cc)\r\n> \tFile \"/home/intel/DevLib/tensorflow-git/third_party/gpus/cuda_configure.bzl\", line 120, in get_cxx_inc_directories\r\n> \t\tset(includes_cpp)\r\n> depsets cannot contain mutable items\r\n> WARNING: Target pattern parsing failed.\r\n> ERROR: error loading package 'tensorflow/tools/pip_package': Encountered error while reading extension file 'cuda/build_defs.bzl': no such package '@local_config_cuda//cuda': Traceback (most recent call last):\r\n> \tFile \"/home/intel/DevLib/tensorflow-git/third_party/gpus/cuda_configure.bzl\", line 1039\r\n> \t\t_create_local_cuda_repository(repository_ctx)\r\n> \tFile \"/home/intel/DevLib/tensorflow-git/third_party/gpus/cuda_configure.bzl\", line 976, in _create_local_cuda_repository\r\n> \t\t_host_compiler_includes(repository_ctx, cc)\r\n> \tFile \"/home/intel/DevLib/tensorflow-git/third_party/gpus/cuda_configure.bzl\", line 145, in _host_compiler_includes\r\n> \t\tget_cxx_inc_directories(repository_ctx, cc)\r\n> \tFile \"/home/intel/DevLib/tensorflow-git/third_party/gpus/cuda_configure.bzl\", line 120, in get_cxx_inc_directories\r\n> \t\tset(includes_cpp)\r\n> depsets cannot contain mutable items\r\n> INFO: Elapsed time: 4.064s\r\n> FAILED: Build did NOT complete successfully (0 packages loaded)\r\n>     currently loading: tensorflow/tools/pip_package\r\n> \r\n", "comments": ["duplicate of #11859", "Hi, @poxvoculi I know it is a duplicate of #11859 and I hope there could have other solutions which are different from \"rolling back bazel\". Thanks!", "I am very happy to see this issue had been solved without the need of \"rolling back bazel\". Thanks!", "Hi @poxvoculi , I still have this issue with **r1.2** branch or **v1.2.1** tag. \r\nFor reasons I have to use 1.2.x, is there any solution?\r\n\r\nFixed by downgrading bazel to 0.5.2, as described in #11859.\r\n", "hello , i'm trying to build bazel with CPU by this command: \r\nbazel build --config=opt //tensorflow/tools/pip_package:build_pip_package\r\ni followed the instructions here as well : https://www.tensorflow.org/install/source_windows , \r\nthe error: \r\nERROR: Skipping '//tensorflow/tools/pip_package:build_pip_package': error loading package 'tensorflow/tools/pip_package': Unable to load package for '@local_config_syslibs//:build_defs.bzl': The repository could not be resolved\r\nWARNING: Target pattern parsing failed.\r\nERROR: error loading package 'tensorflow/tools/pip_package': Unable to load package for '@local_config_syslibs//:build_defs.bzl': The repository could not be resolved\r\nINFO: Elapsed time: 0.480s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (0 packages loaded)\r\n    currently loading: tensorflow/tools/pip_package\r\n  \r\n\r\ncould anyone help me to fix this problem ?! i tried to roll back bezel but it didn't work ", "When I build   tf2.0\uff0cI met the  same issue.\r\ni use bazel version is 0.24.1 \r\ntf2.0 request bazel version is :\r\n`_TF_MIN_BAZEL_VERSION = '0.24.1'\r\n_TF_MAX_BAZEL_VERSION = '0.26.1'`\r\n\r\ni think my bazel version is right?? \r\ni want to know other method to solve the issue without   \"rolling back bazel\"", "Same issue when compiling tensforflow r1.15 with bazel 0.25.1, which looks right in configure.py."]}, {"number": 11990, "title": "Python crashes with \"Check failed\" error when fitting TensorForestEstimator", "body": "### Problem\r\n\r\nI am experiencing an issue trying to use `TensorForestEstimator`. I am trying to predict 7 output labels by inputting 7 features. That is, my `num_classes=7` and `num_features=7` in my hyperparameters. The shape of `features` and `labels` is `(484876, 7)`.\r\n\r\nHere is an example of the format of my input data:\r\n\r\n```\r\nf1       f2     f3    f4      f5    f6    f7   l1       l2       l3       l4       l5       l6       l7\r\n39000.0  120.0  65.0  1000.0  25.0  0.69  3.94 39000.0  39959.0  42099.0  46153.0  49969.0  54127.0  55911.0\r\n32000.0  185.0  65.0  1000.0  75.0  0.46  2.19 32000.0  37813.0  43074.0  48528.0  54273.0  60885.0  63810.0 \r\n30000.0  185.0  65.0  1000.0  25.0  0.41  1.80 30000.0  32481.0  35409.0  39145.0  42750.0  46678.0  48595.0\r\n```\r\n\r\nWhen calling `fit()`,  each of the trees get properly trained (see logs below), but when it goes to the`CheckpointSaverHook` phase, Python crashes with the following error:\r\n\r\n```\r\n2017-08-02 22:55:00.690746: F tensorflow/contrib/tensor_forest/kernels/count_extremely_random_stats_op.cc:404] \r\nCheck failed: column < num_classes_ (39001 vs. 7)\r\n\r\nProcess finished with exit code 134 (interrupted by signal 6: SIGABRT)\r\n```\r\n\r\nI might be wrong, but this seems like a bug since TensorFlow is training each the `TensorForestEstimator` trees, but crashing upon saving. Also the number 39001 is not related to my data since the  shape for both `feature` and `label` is `(484876, 7)`.\r\n\r\nHere is the code to reproduce:\r\n\r\n```\r\nimport tensorflow as tf\r\nimport os\r\n\r\nfrom tensorflow.contrib.tensor_forest.client.random_forest import TensorForestEstimator, TensorForestLossHook\r\nfrom tensorflow.contrib.tensor_forest.python.tensor_forest import ForestHParams, RandomForestGraphs\r\n\r\ntf.logging.set_verbosity('INFO')\r\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\r\n\r\ndef get_training_data():\r\n    training_file = \"data.txt\"\r\n    data = pd.read_csv(training_file, sep='\\t')\r\n\r\n    X = np.array(data.drop('Result', axis=1), dtype=np.float32)\r\n\r\n    y = []\r\n    # All 7 labels are stored in a string initially, so we parse each label to float and store in an array\r\n    for e in data.ResultStr:\r\n        y.append(list(np.array(str(e).replace('[', '').replace(']', '').split(','))))\r\n\r\n    y = np.array(y, dtype=np.float32)\r\n\r\n    features = tf.constant(X) # Also tried with tf.Variable\r\n    labels = tf.constant(y) # Also tried with tf.Variable\r\n\r\n    return features, labels\r\n\r\n# Main\r\nhyperparameters = ForestHParams(\r\n    num_trees=100,\r\n    max_nodes=10000,\r\n    bagging_fraction=1.0,\r\n    num_splits_to_consider=7,\r\n    feature_bagging_fraction=1.0,\r\n    max_fertile_nodes=0,\r\n    split_after_samples=250,\r\n    min_split_samples=5,\r\n    valid_leaf_threshold=1,\r\n    dominate_method='bootstrap',\r\n    dominate_fraction=0.99,\r\n    num_classes=7, \r\n    num_features=7\r\n)\r\n\r\nestimator = TensorForestEstimator(\r\n    params=hyperparameters,\r\n    device_assigner=None,\r\n    model_dir=None,\r\n    graph_builder_class=RandomForestGraphs,\r\n    config=None,\r\n    weights_name=None,\r\n    keys_name=None,\r\n    feature_engineering_fn=None,\r\n    early_stopping_rounds=100,\r\n    num_trainers=1,\r\n    trainer_id=0,\r\n    report_feature_importances=False,\r\n    local_eval=False\r\n)\r\n\r\nestimator.fit(\r\n    input_fn=lambda: get_training_data(),\r\n    max_steps=100,\r\n    monitors=[\r\n        TensorForestLossHook(\r\n            early_stopping_rounds=30\r\n        )\r\n    ]\r\n)\r\n```\r\nHere is the verbose logging output:\r\n```\r\nINFO:tensorflow:Using default config.\r\nWARNING:tensorflow:Using temporary folder as model directory: /var/folders/s3/k08tc0v94j10xn6fk3wz79zh0000gn/T/tmp2RnVSx\r\nINFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1121fe390>, '_model_dir': '/var/folders/s3/k08tc0v94j10xn6fk3wz79zh0000gn/T/tmp2RnVSx', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_session_config': None, '_tf_random_seed': None, '_environment': 'local', '_num_worker_replicas': 0, '_task_id': 0, '_save_summary_steps': 100, '_tf_config': gpu_options {\r\n  per_process_gpu_memory_fraction: 1\r\n}\r\n, '_evaluation_master': '', '_master': ''}\r\nINFO:tensorflow:Constructing forest with params = \r\nINFO:tensorflow:{'valid_leaf_threshold': 1, 'split_after_samples': 250, 'num_output_columns': 7, 'feature_bagging_fraction': 1.0, 'split_initializations_per_input': 1, 'bagged_features': None, 'min_split_samples': 5, 'max_nodes': 10000, 'num_features': 7, 'num_trees': 100, 'num_splits_to_consider': 7, 'base_random_seed': 0, 'num_outputs': 1, 'dominate_fraction': 0.99, 'max_fertile_nodes': 5000, 'bagged_num_features': 7, 'dominate_method': 'bootstrap', 'bagging_fraction': 1.0, 'regression': False, 'num_classes': 6}\r\nINFO:tensorflow:training graph for tree: 0\r\nINFO:tensorflow:training graph for tree: 1\r\n...\r\nINFO:tensorflow:training graph for tree: 98\r\nINFO:tensorflow:training graph for tree: 99\r\nINFO:tensorflow:Create CheckpointSaverHook.\r\n2017-08-02 22:53:25.218258: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-08-02 22:53:25.218298: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-08-02 22:53:25.218304: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-08-02 22:53:25.218308: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-08-02 22:55:00.690746: F tensorflow/contrib/tensor_forest/kernels/count_extremely_random_stats_op.cc:404] Check failed: column < num_classes_ (39001 vs. 7)\r\n\r\nProcess finished with exit code 134 (interrupted by signal 6: SIGABRT)\r\n```\r\n\r\n### System information: tf_env.txt\r\n\r\n```\r\n\r\n== cat /etc/issue ===============================================\r\nDarwin 127001.local 16.6.0 Darwin Kernel Version 16.6.0: Fri Apr 14 16:21:16 PDT 2017; root:xnu-3789.60.24~6/RELEASE_X86_64 x86_64\r\nMac OS X 10.12.5\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\nApple LLVM version 8.1.0 (clang-802.0.42)\r\nTarget: x86_64-apple-darwin16.6.0\r\nThread model: posix\r\nInstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin\r\n\r\n== uname -a =====================================================\r\nDarwin 127001.local 16.6.0 Darwin Kernel Version 16.6.0: Fri Apr 14 16:21:16 PDT 2017; root:xnu-3789.60.24~6/RELEASE_X86_64 x86_64\r\n\r\n== check pips ===================================================\r\nnumpy (1.12.1)\r\nprotobuf (3.3.0)\r\ntensorflow (1.2.1)\r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\ntf.VERSION = 1.2.1\r\ntf.GIT_VERSION = v1.2.0-5-g435cdfc\r\ntf.COMPILER_VERSION = v1.2.0-5-g435cdfc\r\nSanity check: array([1], dtype=int32)\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH is unset\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\n./tf.sh: line 105: nvidia-smi: command not found\r\n\r\n== cuda libs  ===================================================\r\n```", "comments": ["`regression=True` needed to be specified in the `ForestHParams` because `TensorForestEstimator` by default assumes a classification problem. There is an implicit `num_outputs` variable created upon initialization of the estimator and it is set to `False` if `regression` was not specified. If `regression` is specified, then `num_outputs = num_classes` and checkpoints are saved normally. "]}, {"number": 11989, "title": "Upgrade protobuf version to fix \"A protocol message was rejected because it was too big (more than 67108864 bytes).\" error", "body": "custom package 3.1.0 still get this \"A protocol message was rejected because it was too big (more than 67108864 bytes).\" error, but 3.2.0 get it fixed", "comments": ["@yjmade, thanks for your PR! By analyzing the history of the files in this pull request, we identified @tensorflower-gardener, @av8ramit and @Androbin to be potential reviewers.", "Can one of the admins verify this patch?", "@martinwicke Do we support the 3.2 version of the protobuf library ? If yes we should merge this.", "I think we upgraded, but just missed the install doc. \r\n\r\n@jhseu @jart can you confirm?", "We should delete these instructions now that the protobuf team supplies optimized builds on pypi.", "These were for when we were building our own protobuf packages and asking users to install them for performance reasons.", "@jhseu the problem of using official c protobuf library is it has the limitation of max size of a message is 64MB. For a exported graph, it's very easy to bigger than that size. The package provide by Tensorflow  has extend this limitation.", "@yjmade Don't install this package. Use the pip installed protobuf package. It removes that limit and is optimized.", "Ok , just close this."]}, {"number": 11988, "title": "AttentionWrapper is not compatible with dynamic_rnn", "body": "### System information\r\n- **TensorFlow version (v1.2.0-rc2-21-g12f033d 1.2.0)**:\r\n- **Python 3**\r\n\r\n### Describe the problem\r\n\r\nThe return of `zero_state` function of  `tensorflow.contrib.seq2seq.AttentionWrapper` is not compatible with `tensorflow.nn.dynamic_rnn` function.  It seems that `if output.shape.ndims == 0:` in `_copy_one_through` function does not work. Once those scalar elements in return tuple are modified to have the shape like [batch_size, ...] the error disappears.\r\n\r\n### Code to reproduce the bug\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\nbatch_size=2\r\nhidden_units = 3\r\nattention_size = 4\r\nmax_len = 5\r\n\r\ninputs = tf.constant(1.,shape=(batch_size,max_len,hidden_units))\r\ncontext = tf.constant(1.,shape=(batch_size,max_len,hidden_units))\r\ninput_lens = (2,4)\r\n\r\ncell = tf.contrib.rnn.LSTMCell(hidden_units)\r\nam = tf.contrib.seq2seq.BahdanauAttention(attention_size, context)\r\nwrapper = tf.contrib.seq2seq.AttentionWrapper(cell,am)\r\ntf.nn.dynamic_rnn(wrapper,inputs,input_lens,dtype=tf.float32)\r\n```\r\n### Log\r\n```\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 15, in <module>\r\n    tf.nn.dynamic_rnn(wrapper,inputs,input_lens,dtype=tf.float32)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn.py\", line 574, in dynamic_rnn\r\n    dtype=dtype)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn.py\", line 737, in _dynamic_rnn_loop\r\n    swap_memory=swap_memory)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2770, in while_loop\r\n    result = context.BuildLoop(cond, body, loop_vars, shape_invariants)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2599, in BuildLoop\r\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2549, in _BuildLoop\r\n    body_result = body(*packed_vars_for_body)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn.py\", line 720, in _time_step\r\n    skip_conditionals=True)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn.py\", line 210, in _rnn_step\r\n    final_output_and_state = _copy_some_through(new_output, new_state)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn.py\", line 182, in _copy_some_through\r\n    for state, new_state in zip(flat_state, flat_new_state)]\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn.py\", line 182, in <listcomp>\r\n    for state, new_state in zip(flat_state, flat_new_state)]\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn.py\", line 171, in _copy_one_through\r\n    return array_ops.where(copy_cond, output, new_output)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/array_ops.py\", line 2328, in where\r\n    return gen_math_ops._select(condition=condition, t=x, e=y, name=name)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 2145, in _select\r\n    name=name)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 2508, in create_op\r\n    set_shapes_for_outputs(ret)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1873, in set_shapes_for_outputs\r\n    shapes = shape_func(op)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1823, in call_with_requiring\r\n    return call_cpp_shape_fn(op, require_shape_fn=True)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/common_shapes.py\", line 610, in call_cpp_shape_fn\r\n    debug_python_shape_fn, require_shape_fn)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/common_shapes.py\", line 676, in _call_cpp_shape_fn_impl\r\n    raise ValueError(err.message)\r\nValueError: Shapes must be equal rank, but are 0 and 1 for 'rnn/while/Select_4' (op: 'Select') with input shapes: [2], [], [].\r\n```", "comments": ["@lukaszkaiser could you please take a look.", "Sorry, I got lost with the changes in recent months, will have to ask Thang or Eugene.", "Hi, I'm having exactly the same problem like @jingxil. Is there any workaround to get around the issue other than implementing it myself? Thanks a lot!", "I am having the same issue as well. It would be great if the Tensorflow team could give feedback on this. ", "One ad-hoc workaround I've found out is not to supply sequence_length in dynamic_rnn. You will have to mask out the outputs manually however to have a correct final loss.", "I have found similar error while I use `AttentionWrapper` at `raw_rnn`. It seems that the problem came from the function `_copy_some_through` when it try to copy `next_state` to `state` conditioned on `elements_finished`. I think it is the consequence of `time` attribute of `AttentionWrapperState` can not be copied through by the code `tf.where(elements_finished, cur_i, cand_i)` inside function `_copy_some_through` implementation, since `time` is just a scalar but `elements_finished` is a tensor shaped like `[batch_size]`.", "One could add a special case for scalar state that just passes it through.\n\nOn Sep 4, 2017 12:33 AM, \"Lee\" <notifications@github.com> wrote:\n\n> I have found similar error while I use AttentionWrapper at raw_rnn. It\n> seems that the problem came from the function _copy_some_through when it\n> try to copy next_state to state conditioned on elements_finished. I think\n> it is the consequence of time attribute of AttentionWrapperState can not\n> be copied through by the code tf.where(elements_finished, cur_i, cand_i)\n> inside _copy_some_through, since time is just a scalar but\n> elements_finished is a tensor shaped like [batch_size].\n>\n> \u2014\n> You are receiving this because you were assigned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/11988#issuecomment-326887212>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtim2TiNfp4R-5_vpD8j6cm8RI0jSa9ks5se6fOgaJpZM4Or7y3>\n> .\n>\n", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly."]}, {"number": 11987, "title": "Simplify tensorflow/core/BUILD", "body": "Fix #11985", "comments": ["Can one of the admins verify this patch?", "@snnn, thanks for your PR! By analyzing the history of the files in this pull request, we identified @tensorflower-gardener, @josh11b and @vrv to be potential reviewers.", "I also think we can remove LIB_INTERNAL_WINDOWS_DEPS , but this change also removed \r\n```\r\n\"framework/variant_tensor_data.h\",        \r\n\"framework/variant_tensor_data.cc\",\r\n```\r\n@gunan Where do you think is the right place to put them?\r\n\r\nRelated commit: https://github.com/tensorflow/tensorflow/commit/7ed4beea18c2aecaa0a1f600427e8452933df7b3", "@tensorflow-jenkins test this please", "Jenkins, test this please.\r\nAs long as the build passes, I am OK with the change.\r\nMy later tests showed that the addition of the files were not fully needed, but forgot to remove the lines when I was rolling my change forward."]}, {"number": 11986, "title": "The FixedLenFeature of parse_example?", "body": "View[ API DOC](https://www.tensorflow.org/versions/master/api_docs/python/tf/parse_example).\r\n\r\nThe description maybe wrong?\r\n`Each FixedLenFeature df maps to a Tensor of the specified type (or tf.float32 if not specified) and shape (serialized.size(),) + df.shape.`\r\n\r\nBut the example shows:\r\nFor dense results in two serialized Examples:\r\n\r\n```\r\n[\r\n  features {\r\n    feature { key: \"age\" value { int64_list { value: [ 0 ] } } }\r\n    feature { key: \"gender\" value { bytes_list { value: [ \"f\" ] } } }\r\n   },\r\n   features {\r\n    feature { key: \"age\" value { int64_list { value: [] } } }\r\n    feature { key: \"gender\" value { bytes_list { value: [ \"f\" ] } } }\r\n  }\r\n]\r\n```\r\nWe can use arguments:\r\n\r\n```\r\nexample_names: [\"input0\", \"input1\"],\r\nfeatures: {\r\n    \"age\": FixedLenFeature([], dtype=tf.int64, default_value=-1),\r\n    \"gender\": FixedLenFeature([], dtype=tf.string),\r\n}\r\n```\r\nAnd the expected output is:\r\n```\r\n\r\n{\r\n  \"age\": [[0], [-1]],\r\n  \"gender\": [[\"f\"], [\"f\"]],\r\n}\r\n```\r\nThe shape of output is (2, 1) not equal to (2, ) + (), where  (2,) is `(serialized.size(),)` and () is `df.shape`.\r\n", "comments": ["@honkentuber, could you fix these documents?", "@ispirmustafa, could you take a look?", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "A member of the TensorFlow organization has replied after the stat:awaiting tensorflower label was applied.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly."]}, {"number": 11985, "title": "windows bazel build failed: undeclared inclusion ", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nNo\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nWindows 10\r\n- **TensorFlow installed from (source or binary)**:\r\nsource\r\n- **TensorFlow version (use command below)**:\r\n2ab9cb209babf905091dcff2f7cdce38da616cfe\r\n- **Python version**: \r\n3.5.3\r\n- **Bazel version (if compiling from source)**:\r\n0.5.3\r\n- **CUDA/cuDNN version**:\r\nNone\r\n- **GPU model and memory**:\r\nNone\r\n- **Exact command to reproduce**:\r\nbazel --output_base C:\\t  build  //tensorflow/tools/pip_package:build_pip_package\r\n\r\n\r\n### Describe the problem\r\nERROR: C:/os/tensorflow/tensorflow/core/BUILD:1271:1: undeclared inclusion(s) in rule '//tensorflow/core:lib_internal':\r\nthis rule is missing dependency declarations for the following files included by 'tensorflow/core/framework/variant_tensor_data.cc':\r\n  'C:/os/tensorflow/tensorflow/core/framework/tensor.h'\r\n  'C:/os/tensorflow/tensorflow/core/framework/allocator.h'\r\n  'C:/os/tensorflow/tensorflow/core/framework/numeric_types.h'\r\n  'C:/os/tensorflow/tensorflow/core/framework/type_traits.h'\r\n  'C:/os/tensorflow/tensorflow/core/framework/variant.h'\r\n  'C:/os/tensorflow/tensorflow/core/framework/type_index.h'\r\n  'C:/os/tensorflow/tensorflow/core/framework/tensor_shape.h'\r\n  'C:/os/tensorflow/tensorflow/core/framework/tensor_types.h'\r\n  'C:/os/tensorflow/tensorflow/core/framework/types.h'\r\n  'C:/os/tensorflow/tensorflow/core/framework/bfloat16.h'\r\n\r\n### Source code / logs", "comments": ["If no one is working on this, I'll take it.", "Culprit is https://github.com/tensorflow/tensorflow/commit/7ed4beea18c2aecaa0a1f600427e8452933df7b3\r\n\r\nI've commented on the internal change.", "Looks like fix is on its way.  Assigning to @gunan for tracking."]}, {"number": 11984, "title": "Save seq2seq model error (tensowflow 1.0.0)", "body": "1. I had trained a seq2seq model with tensorflow 1.0.0 (cpu version)\r\n\r\n  install: pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-1.0.0-cp35-cp35m-win_amd64.whl \r\n\r\n2. Save the model. \r\nsave_path = saver.save(session, 'model/model.ckpt')\r\n\r\n3. load the model. \r\nnew_saver = tf.train.import_meta_graph('model/model.ckpt.meta')\r\n\r\n\r\nwhen I load the model,there is a error as follows:\r\n\r\nFile \"D:\\python3.5.2\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1577, in import_meta_graph**kwargs)\r\nFile \"D:\\python3.5.2\\lib\\site-packages\\tensorflow\\python\\framework\\meta_graph.py\", line 498, in import_scoped_meta_graphproducer_op_list=producer_op_list)\r\nFile \"D:\\python3.5.2\\lib\\site-packages\\tensorflow\\python\\framework\\importer.py\", line 259, in import_graph_def raise ValueError('No op named %s in defined operations.' % node.op) ValueError: No op named attn_mul_fun_f32f32 in defined operations.\r\nwhat's the reason for the error?\r\n\r\nI found the function(attn_mul_fun) from the file D:\\python3.5.2\\Lib\\site-packages\\tensorflow\\contrib\\seq2seq\\python\\ops\\attention_decoder_fn.py\r\n\r\nI don't know what's the connection between attn_mul_fun_f32f32 and attn_mul_fun, how to fix the error when loading the model?", "comments": ["Your problem is that the file is an auto-generated file and you failed to generate it during the build. Please try either with install from binary or follow the \"Install From Source\" instructions carefully.", "@gautam1858 \r\nWhat's the difference between \"auto-generated file\" and \"Install From Source\"?", "This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 11983, "title": "Remove tfserve page which is soon to be outdated.", "body": "We are in the process of serving tfserve documentation in a different way, so this file needs to be removed.  1.2 is the current \"root\" branch on tensorflow.org, so we need to cut it from r1.2, and we were not able to cherrypick the change back from master (where it is already gone).", "comments": ["Can one of the admins verify this patch?"]}, {"number": 11982, "title": "Feature Request: Kill session->run process", "body": "For mobile & embedded devices `session->run` is typically initiated through a user interaction. If the user presses the back button or continues to another screen before `session->run` finishes, the process is still lingering in the background wasting resources. Since these devices are relatively low powered, it would be great if we could cancel/kill the process when it's not needed anymore.\r\n\r\n\r\n", "comments": ["Can you kill the whole process that contains TensorFlow using OS-level tools (ie, sending kill signal)? Interrupting a `session.run` call without restarting a process was brought up in https://github.com/tensorflow/tensorflow/issues/11303", "For iOS, I'm not aware of a way to kill a process other than for the end-user to kill the entire app.\r\nThe paradigm for long running processes is to subclass `NSOperation` and periodically check the `cancelled` property.\r\n```\r\nclass TFSession: NSOperation {\r\n    override func main() {\r\n        if self.cancelled {\r\n            return\r\n        }\r\n        // Do some work\r\n        if self.cancelled {\r\n            return\r\n        }\r\n        // Do more work\r\n        // ...\r\n    }\r\n}\r\n```\r\nThis obviously isn't a good solution since iOS is such a small part of Tensorflow, but what about a `cancel_op` that a developer can sprinkle throughout their graph? This has a different challenge of accepting a pointer in the `feed_dict` though.  ", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "I'm not sure how this would easily fit into the current TensorFlow Session::Run() architecture, since it seems like it would require at least some modifications to the inner loop of the executor and careful testing to ensure that nothing was left in an inconsistent state during the interrupt. I can definitely see how useful it would be, but for now I'll have to close this as infeasible. Pull requests, or more information about why we should reopen it would be welcome of course!"]}, {"number": 11981, "title": "Updating version to rc2.", "body": "", "comments": []}, {"number": 11980, "title": "Fix formatting problems in \"Adding an Op\" doc", "body": "I noticed some minor code formatting issues while reading through [https://www.tensorflow.org/extend/adding_an_op]:\r\n1. At line 181 of the Markdown file, there is some non-working HTML to show/hide a code listing.\r\n2. At line 766 of the Markdown file, there is a code listing that ends up with a bunch of extra backslashes when rendered to HTML.\r\n3. At line 1113 of the Markdown file, there is a code listing (a `REGISTER_OP` macro) that does not display properly in the HTML version of the document.\r\n\r\nThis PR fixes 1 and 2 above. The third problem appears to be a bug in the script that generates the HTML, and I wasn't able to find that script anywhere in the source tree.", "comments": ["Can one of the admins verify this patch?", "@frreiss, thanks for your PR! By analyzing the history of the files in this pull request, we identified @keveman, @tensorflower-gardener and @dandelionmane to be potential reviewers.", "Jenkins, test this please.", "This message was created automatically by mail delivery software.\n\nA message that you sent could not be delivered to one or more of its\nrecipients. This is a temporary error. The following address(es) deferred:\n\n  mazecreator@gmail.com\n    Domain mazecreator.com has exceeded the max emails per hour (28/25 (112%)) allowed.  Message will be reattempted later\n\n------- This is a copy of the message, including all the headers. ------\nReceived: from github-smtp2-ext2.iad.github.net ([192.30.252.193]:35115 helo=github-smtp2b-ext-cp1-prd.iad.github.net)\n\tby server2.lowesthostingrates.com with esmtps (TLSv1.2:ECDHE-RSA-AES256-GCM-SHA384:256)\n\t(Exim 4.89)\n\t(envelope-from <noreply@github.com>)\n\tid 1ddNpB-0006mQ-6v\n\tfor mazecreator@mazecreator.com; Thu, 03 Aug 2017 16:39:03 -0500\nDate: Thu, 03 Aug 2017 14:49:16 -0700\nDKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=github.com;\n\ts=pf2014; t=1501796956;\n\tbh=DxNj/4V0kzFU6E/kOlfrMyh/E3Ei3Jafn+LK/5TBSf0=;\n\th=From:Reply-To:To:Cc:In-Reply-To:References:Subject:List-ID:\n\t List-Archive:List-Post:List-Unsubscribe:From;\n\tb=xJwVcJjp59p7s5/ve37/iERy0tfyqjIzIL0Y/GByy1Mubh4dZQdeZL2pDNaGDbEKq\n\t OiWva0Cv70TtW2GQklzLn9atH9IiLuTXM0Ib4seDXaY+cfJ4H9ZGV0P8sngLiD4gTA\n\t HbLVtPIvKJKckSRugio2y6B3Rn3EHZmOK1p9dFxY=\nFrom: Benoit Steiner <notifications@github.com>\nReply-To: tensorflow/tensorflow <reply@reply.github.com>\nTo: tensorflow/tensorflow <tensorflow@noreply.github.com>\nCc: Subscribed <subscribed@noreply.github.com>\nMessage-ID: <tensorflow/tensorflow/pull/11980/issue_event/1192226066@github.com>\nIn-Reply-To: <tensorflow/tensorflow/pull/11980@github.com>\nReferences: <tensorflow/tensorflow/pull/11980@github.com>\nSubject: Re: [tensorflow/tensorflow] Fix formatting problems in \"Adding an Op\"\n doc (#11980)\nMime-Version: 1.0\nContent-Type: multipart/alternative;\n boundary=\"--==_mimepart_59839a5c22d79_1d3443ffb3fe4fc303329b0\";\n charset=UTF-8\nContent-Transfer-Encoding: 7bit\nPrecedence: list\nX-GitHub-Sender: benoitsteiner\nX-GitHub-Recipient: Mazecreator\nX-GitHub-Reason: subscribed\nList-ID: tensorflow/tensorflow <tensorflow.tensorflow.github.com>\nList-Archive: https://github.com/tensorflow/tensorflow\nList-Post: <mailto:reply@reply.github.com>\nList-Unsubscribe: <mailto:unsub+0118f3a06865739f76fc44e15125877c4074085d7dd67db292cf00000001159b5c5c92a169ce0ec0b15c@reply.github.com>,\n <https://github.com/notifications/unsubscribe/ARjzoKtNCq-YUEmwCnbsloIo-xtVeJIRks5sUkBcgaJpZM4Ormj6>\nX-Auto-Response-Suppress: All\nX-GitHub-Recipient-Address: mazecreator@mazecreator.com\nX-Spam-Status: No, score=\nX-Spam-Score:\nX-Spam-Bar:\nX-Ham-Report:\nX-Spam-Flag: NO\n\n\n----==_mimepart_59839a5c22d79_1d3443ffb3fe4fc303329b0\nContent-Type: text/plain;\n charset=UTF-8\nContent-Transfer-Encoding: 7bit\n\nMerged #11980.\n\n-- \nYou are receiving this because you are subscribed to this thread.\nReply to this email directly or view it on GitHub:\nhttps://github.com/tensorflow/tensorflow/pull/11980#event-1192226066\n----==_mimepart_59839a5c22d79_1d3443ffb3fe4fc303329b0\nContent-Type: text/html;\n charset=UTF-8\nContent-Transfer-Encoding: 7bit\n\n<p>Merged <a href=\"https://github.com/tensorflow/tensorflow/pull/11980\" class=\"issue-link js-issue-link\" data-url=\"https://github.com/tensorflow/tensorflow/issues/11980\" data-id=\"247509340\" data-error-text=\"Failed to load issue title\" data-permission-text=\"Issue title is private\">#11980</a>.</p>\n\n<p style=\"font-size:small;-webkit-text-size-adjust:none;color:#666;\">&mdash;<br />You are receiving this because you are subscribed to this thread.<br />Reply to this email directly, <a href=\"https://github.com/tensorflow/tensorflow/pull/11980#event-1192226066\">view it on GitHub</a>, or <a href=\"https://github.com/notifications/unsubscribe-auth/ARjzoD71zBThhyVmNDnWhJWOxzIs_PjGks5sUkBcgaJpZM4Ormj6\">mute the thread</a>.<img alt=\"\" height=\"1\" src=\"https://github.com/notifications/beacon/ARjzoGEjSyAg2gfICOWzXWkuqbI4awqgks5sUkBcgaJpZM4Ormj6.gif\" width=\"1\" /></p>\n<div itemscope itemtype=\"http://schema.org/EmailMessage\">\n<div itemprop=\"action\" itemscope itemtype=\"http://schema.org/ViewAction\">\n  <link itemprop=\"url\" href=\"https://github.com/tensorflow/tensorflow/pull/11980#event-1192226066\"></link>\n  <meta itemprop=\"name\" content=\"View Pull Request\"></meta>\n</div>\n<meta itemprop=\"description\" content=\"View this Pull Request on GitHub\"></meta>\n</div>\n\n<script type=\"application/json\" data-scope=\"inboxmarkup\">{\"api_version\":\"1.0\",\"publisher\":{\"api_key\":\"05dde50f1d1a384dd78767c55493e4bb\",\"name\":\"GitHub\"},\"entity\":{\"external_key\":\"github/tensorflow/tensorflow\",\"title\":\"tensorflow/tensorflow\",\"subtitle\":\"GitHub repository\",\"main_image_url\":\"https://cloud.githubusercontent.com/assets/143418/17495839/a5054eac-5d88-11e6-95fc-7290892c7bb5.png\",\"avatar_image_url\":\"https://cloud.githubusercontent.com/assets/143418/15842166/7c72db34-2c0b-11e6-9aed-b52498112777.png\",\"action\":{\"name\":\"Open in GitHub\",\"url\":\"https://github.com/tensorflow/tensorflow\"}},\"updates\":{\"snippets\":[{\"icon\":\"DESCRIPTION\",\"message\":\"Merged #11980.\"}],\"action\":{\"name\":\"View Pull Request\",\"url\":\"https://github.com/tensorflow/tensorflow/pull/11980#event-1192226066\"}}}</script>\n----==_mimepart_59839a5c22d79_1d3443ffb3fe4fc303329b0--\n"]}, {"number": 11979, "title": "Turn off grappler for 1.3", "body": "Tested with tf_cnn_benchmark suite and regression caused by the changes is resolved according to the tests.  \r\n\r\nThis change should not be pulled back into master as a fix for the feature has been done that also needs tested.  ", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please.", "Jenkins, test this please.", "This message was created automatically by mail delivery software.\n\nA message that you sent could not be delivered to one or more of its\nrecipients. This is a temporary error. The following address(es) deferred:\n\n  mazecreator@gmail.com\n    Domain mazecreator.com has exceeded the max emails per hour (28/25 (112%)) allowed.  Message will be reattempted later\n\n------- This is a copy of the message, including all the headers. ------\nReceived: from github-smtp2-ext2.iad.github.net ([192.30.252.193]:60015 helo=github-smtp2b-ext-cp1-prd.iad.github.net)\n\tby server2.lowesthostingrates.com with esmtps (TLSv1.2:ECDHE-RSA-AES256-GCM-SHA384:256)\n\t(Exim 4.89)\n\t(envelope-from <noreply@github.com>)\n\tid 1dd0jY-0002ot-Nn\n\tfor mazecreator@mazecreator.com; Wed, 02 Aug 2017 15:59:42 -0500\nDate: Wed, 02 Aug 2017 14:09:52 -0700\nDKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=github.com;\n\ts=pf2014; t=1501708192;\n\tbh=g9OojTsMYZ6NfTHMWg9bg6LFXMGvEi8XG4fy4fNdU+0=;\n\th=From:Reply-To:To:Cc:In-Reply-To:References:Subject:List-ID:\n\t List-Archive:List-Post:List-Unsubscribe:From;\n\tb=aFVaufZJVD0iMeN1S2hbQu+yhG+mqKrXkvRfp3YR97lf4Y7iqnE3OHUwjUuWaEY37\n\t vffZdHP/OOB7vu8gI4IP4+0ELhh50qTxFZFxpDgp9lpDg6F/oVxWmCHFdYVGPlRzBL\n\t 9xo4roCZsm3BXvhQUVY1eQmO7ZlMEiSrxnKO4nTQ=\nFrom: Amit Patankar <notifications@github.com>\nReply-To: tensorflow/tensorflow <reply@reply.github.com>\nTo: tensorflow/tensorflow <tensorflow@noreply.github.com>\nCc: Subscribed <subscribed@noreply.github.com>\nMessage-ID: <tensorflow/tensorflow/pull/11979/c319799087@github.com>\nIn-Reply-To: <tensorflow/tensorflow/pull/11979@github.com>\nReferences: <tensorflow/tensorflow/pull/11979@github.com>\nSubject: Re: [tensorflow/tensorflow] Turn off grappler for 1.3 (#11979)\nMime-Version: 1.0\nContent-Type: multipart/alternative;\n boundary=\"--==_mimepart_59823fa0e0325_1cbd03fc1520b9c3c28902\";\n charset=UTF-8\nContent-Transfer-Encoding: 7bit\nPrecedence: list\nX-GitHub-Sender: av8ramit\nX-GitHub-Recipient: Mazecreator\nX-GitHub-Reason: subscribed\nList-ID: tensorflow/tensorflow <tensorflow.tensorflow.github.com>\nList-Archive: https://github.com/tensorflow/tensorflow\nList-Post: <mailto:reply@reply.github.com>\nList-Unsubscribe: <mailto:unsub+0118f3a0862b62b3f99e3106d39f20c5af5a18ddb478554c92cf00000001159a01a092a169ce0ec0932d@reply.github.com>,\n <https://github.com/notifications/unsubscribe/ARjzoD_fTcRr1pF27zOHCkxzWAle5VrOks5sUOWggaJpZM4Orkcv>\nX-Auto-Response-Suppress: All\nX-GitHub-Recipient-Address: mazecreator@mazecreator.com\nX-Spam-Status: No, score=\nX-Spam-Score:\nX-Spam-Bar:\nX-Ham-Report:\nX-Spam-Flag: NO\n\n\n----==_mimepart_59823fa0e0325_1cbd03fc1520b9c3c28902\nContent-Type: text/plain;\n charset=UTF-8\nContent-Transfer-Encoding: 7bit\n\nJenkins, test this please.\n\n-- \nYou are receiving this because you are subscribed to this thread.\nReply to this email directly or view it on GitHub:\nhttps://github.com/tensorflow/tensorflow/pull/11979#issuecomment-319799087\n----==_mimepart_59823fa0e0325_1cbd03fc1520b9c3c28902\nContent-Type: text/html;\n charset=UTF-8\nContent-Transfer-Encoding: 7bit\n\n<p>Jenkins, test this please.</p>\n\n<p style=\"font-size:small;-webkit-text-size-adjust:none;color:#666;\">&mdash;<br />You are receiving this because you are subscribed to this thread.<br />Reply to this email directly, <a href=\"https://github.com/tensorflow/tensorflow/pull/11979#issuecomment-319799087\">view it on GitHub</a>, or <a href=\"https://github.com/notifications/unsubscribe-auth/ARjzoE1lVVv9pL8-vTZv0g0_6eVtQeuaks5sUOWggaJpZM4Orkcv\">mute the thread</a>.<img alt=\"\" height=\"1\" src=\"https://github.com/notifications/beacon/ARjzoJpQIpS8hGokNAjqVmDPOS0SMATJks5sUOWggaJpZM4Orkcv.gif\" width=\"1\" /></p>\n<div itemscope itemtype=\"http://schema.org/EmailMessage\">\n<div itemprop=\"action\" itemscope itemtype=\"http://schema.org/ViewAction\">\n  <link itemprop=\"url\" href=\"https://github.com/tensorflow/tensorflow/pull/11979#issuecomment-319799087\"></link>\n  <meta itemprop=\"name\" content=\"View Pull Request\"></meta>\n</div>\n<meta itemprop=\"description\" content=\"View this Pull Request on GitHub\"></meta>\n</div>\n\n<script type=\"application/json\" data-scope=\"inboxmarkup\">{\"api_version\":\"1.0\",\"publisher\":{\"api_key\":\"05dde50f1d1a384dd78767c55493e4bb\",\"name\":\"GitHub\"},\"entity\":{\"external_key\":\"github/tensorflow/tensorflow\",\"title\":\"tensorflow/tensorflow\",\"subtitle\":\"GitHub repository\",\"main_image_url\":\"https://cloud.githubusercontent.com/assets/143418/17495839/a5054eac-5d88-11e6-95fc-7290892c7bb5.png\",\"avatar_image_url\":\"https://cloud.githubusercontent.com/assets/143418/15842166/7c72db34-2c0b-11e6-9aed-b52498112777.png\",\"action\":{\"name\":\"Open in GitHub\",\"url\":\"https://github.com/tensorflow/tensorflow\"}},\"updates\":{\"snippets\":[{\"icon\":\"PERSON\",\"message\":\"@av8ramit in #11979: Jenkins, test this please.\"}],\"action\":{\"name\":\"View Pull Request\",\"url\":\"https://github.com/tensorflow/tensorflow/pull/11979#issuecomment-319799087\"}}}</script>\n----==_mimepart_59823fa0e0325_1cbd03fc1520b9c3c28902--\n"]}, {"number": 11978, "title": " tf.nn.weighted_cross_entropy_with_logits  is bad", "body": " tf.nn.weighted_cross_entropy_with_logits\r\n(1 - z) * x + l * (log(1 + exp(-abs(x))) + max(-x, 0)) \r\nwhere l = (1 + (q - 1) * z)\r\n\r\nbut tf.nn.sigmoid_cross_entropy_with_logits\r\nmax(x, 0) - x * z + log(1 + exp(-abs(x)))\r\n\r\nif q=1 weighted_cross_entropy_with_logits is equvalent sigmoid_cross_entropy_with_logits\r\n\r\n\r\n(1 - z) * x + l * (log(1 + exp(-abs(x))) + max(-x, 0)) {l=1}- (max(x, 0) - x * z + log(1 + exp(-abs(x)))) ==\r\nx+max(-x, 0)-max(x, 0) <> 0\r\n\r\n\r\n tf.nn.weighted_cross_entropy_with_logits must be\r\n   (- z * x) + l * (log(1 + exp(-abs(x))) + max(x, 0) ", "comments": ["may error"]}, {"number": 11977, "title": "Multiple runs of Configure with MKL enabled leads to cyclic symlinks", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Centos 7\r\n- **TensorFlow installed from (source or binary)**: Compilation from source\r\n- **TensorFlow version (use command below)**: v1.2.1 and v1.3.0-r1\r\n- **Python version**: Python 3.5.2\r\n- **Bazel version (if compiling from source)**: 0.5.2\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: ./configure [enter] [enter] y y [enter till complete], twice\r\n\r\n### Describe the problem\r\nCurrently the way the configure script is written for the MKL decision branch it does not ensure no cyclic symbolic links are created for libdl.so.2\r\n\r\nThis becomes a problem if MKL has been downloaded already upon a re-run of the configure script and the first line of the locate output happens to be the symlink located in the third_party/mkl directory. If that occurs then the `ln -sf` command will create a cyclic symlink.\r\n\r\nThis can be fixed either by checking that \"$loc\" is not the same string as \"$PWD\"/third_party/mkl/libdl.so.2 or by checking for the existence of the symlink before the `ln` command.\r\n\r\n\r\n### Source code / logs\r\nconfigure, line 276, 277.\r\n`loc=$(locate -e libdl.so.2 | sed -n 1p)` <- can end up returning the destination file if it already exists\r\n\r\n`ln -sf $loc third_party/mkl/libdl.so.2` <- if \"$loc\" == \"$PWD\"/third_party/mkl/libdl.so.2, creates cyclic link.", "comments": ["I have seen elsewhere in the issue tracker mention that this section of configure code may change soon, so rather than making a pull request immediately I will just say here how I fixed the script for this specific problem. This would also fix Issue #11029\r\n\r\nInstead of using `locate` use `whereis`, which checks the $PATH alone.\r\n\r\nLine 276 becomes\r\n`loc=\"$(whereis libdl.so.2 | awk '{print $2}')\"`\r\n\r\nUnfortunately whereis has no easy to detect failure status, so there should be an empty check for $loc to make the script more robust (though not having libdl is a very bad sign).", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "This issue is most likely obsolete due to changes in recent months. If it's still an issue, let me know and I'll reopen."]}, {"number": 11976, "title": "How to Retrain Final Layer for New Categories", "body": "Could there be another or newer classification algorithm for image classification like ResNet etc? There are a lot of new neural nets with less classification error than Inception. ImageNet results: [http://image-net.org/challenges/LSVRC/2017/results](INCR)", "comments": ["Tensorflow has a model \"zoo\" accessible here: https://github.com/tensorflow/models including ResNet. There is a great collection of models old and new there.\r\n\r\np.s. your link appears to be broken.", "Closing this issue. Feel free to reopen with follow up questions."]}, {"number": 11975, "title": "CMake build with -Dtensorflow_BUILD_ALL_KERNELS=OFF does not work", "body": "Problem:\r\n\r\nWhen building Tensorflow via CMake, specifying option tensorflow_BUILD_ALL_KERNELS=OFF leads to failed linker step due to unresolved external functions, because many important files (that are not kernels, but are necessary) are not included in build's list of sources (like ops_util.cc, but also other files).\r\n\r\nReproduction:\r\n\r\nFollow instruction in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/cmake/README.md, specify -Dtensorflow_BUILD_ALL_KERNELS=OFF to cmake.", "comments": ["We'd welcome fixes to the CMake build that make this work!", "Created a PR #13722 to fix the error in CMAKE + `Dtensorflow_BUILD_ALL_KERNELS=OFF`. With the PR, the cmake with `-Dtensorflow_BUILD_ALL_KERNELS=OFF` should work now (tested on Linux)."]}, {"number": 11974, "title": "tf.reshape does not accept Dimension objects for the shape parameter", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug or a feature request.\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10 x64\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**:  1.2.1\r\n- **Python version**: 3.6.1 (Anaconda 4.4.0 64-bit)\r\n- **Bazel version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: \r\n- **GPU model and memory**: GTX 780\r\n- **Exact command to reproduce**: tf.reshape()\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\ntf.reshape does not accept a list with mixed Integer and Dimension() as elements for the shape parameter. It should accept shapes that have Dimension as elements since tensor shapes consist of dimensions. Specifically, tf.tensor.shape returns a list of Dimensions, therefore using a similar object to specify a shape in tf.reshape should not cause an error.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\nExample code:\r\n\r\n```\r\nX = tf.placeholder(\"float\", [1,784])\r\nX = tf.reshape(X, [1, X.shape[-1]])\r\n```\r\n\r\nresults in\r\n\r\n```\r\nTypeError: Failed to convert object of type <class 'list'> to Tensor. Contents: [1, Dimension(784)]. Consider casting elements to a supported type.\r\n```\r\n\r\nThis is rectified by casting X.shape[-1] to int before passing to tf.reshape.\r\n\r\n\r\nA similar unrelated issue is that X.shape returns (784,) while it should return (1,784). This requires reshaping to turn the placeholder back into a 2D tensor. I haven't determined if this is a bug but it occurs when the tensor is explicitly specified as a 2D tensor so it is probably worth changing.\r\n\r\n", "comments": ["One fix could be to add some code before [this line](https://github.com/tensorflow/tensorflow/blob/42ca99b5aae03a8122ba0db94abfe1f3f5c257dc/tensorflow/python/framework/tensor_util.py#L377) that casts all tf.Dimension objects in the list to Python int", "We currently don't have anybody working on this. It would be great if you could help us by working on this and submitting a PR. Let us know if you need further clarification. Thanks!", "I'd be interested in working on this, might take a few days to figure out dev workflow.", "I think you basically need to do something along the lines of:\r\n\r\n```\r\nif hasattr(arr, \"__len__\") and len(arr)<=8:\r\n  for i in range(len(arr)):\r\n    arr[i] = int(arr[i]) if instanceof(arr[i], Dimension) else arr[i]\r\n```\r\nAnd then run the tests and see if something breaks. The `len` restriction is because this only really matters for shapes and TF has rank limit of 8\r\n\r\n", "Hi, @pmccarter . Because `tf.reshape` is generated automatically, and the implementation is written by C++, hence the question is more difficult to debug than I expected. I opened a PR #12127 to take a try to fix it. If your work has not been started yet, is it OK to link the PR to the issue? Thanks.", "@facaiy this is a Python specific issue so it needs to be at Python side. Look at the stack trace of failing reshape to see where it's happening. The Python layer calls tensor_util.make_tensor_proto which calls numpy.asarray on the result. Numpy asarray tries to figure out dtype of the list, and because it doesn't know about tf.Dimension, it makes it type \"np.object\" which corresponds to \"tf.string\".\r\n\r\nThe ideal way to fix it would be to figure out how to modify tf.Dimension object so that np.asarray would recognize them as integer. IE, you want\r\n\r\n`np.asarray([1,tf.Dimension(1)])\r\n`\r\n\r\nto return\r\n\r\n`array([1, 1]`\r\n\r\ninstead of\r\n\r\n`array([1, Dimension(1)], dtype=object)`\r\n\r\nIf that's not possible, the next best thing would be to have special case for tf.Dimension object to convert them to int just before `np.asarray` call. You would want to special-case this for length <=8  since we don't need larger ranks for shape calculations, and this would avoid performance penalty for more general arrays", "@yaroslavvb Thanks for your suggestion! Yes, I agree with you that casting object to string is a really awkward solution. \r\n\r\nAs for the two solutions you advised, I will take a try:\r\n\r\n1. Find a way to make `np.asarray` recognize tf.Dimension as int,  or\r\n2. Cast tf.Dimension to int before `np.asarray` call.", "Hi, @yaroslavvb . \r\n\r\nIf I understand correctly, `[1, Dimension(1)]` doesn't go `np.asarray` route, \r\n\r\n```python\r\n  if isinstance(values, (np.ndarray, np.generic)):\r\n    if dtype:\r\n      nparray = values.astype(dtype.as_numpy_dtype)\r\n    else:\r\n      nparray = values\r\n  elif callable(getattr(values, \"__array__\", None)):\r\n    # If a class has the __array__ method, then it is possible to convert\r\n    # to numpy array.\r\n    nparray = np.asarray(values, dtype=dtype)\r\n  else:\r\n```\r\n\r\nIn fact, it goes the last branch. In the route, `[1, Dimension(1)]` is treated as a list of objects. Then each object is treated as string, see:\r\n\r\n```python\r\n  if numpy_dtype == dtypes.string and not isinstance(values, np.ndarray):\r\n    proto_values = _FlattenToStrings(values)\r\n\r\n    # At this point, values may be a list of objects that we could not\r\n    # identify a common type for (hence it was inferred as\r\n    # np.object/dtypes.string).  If we are unable to convert it to a\r\n    # string, we raise a more helpful error message.\r\n    #\r\n    # Ideally, we'd be able to convert the elements of the list to a\r\n    # common type, but this type inference requires some thinking and\r\n    # so we defer it for now.\r\n    try:\r\n      str_values = [compat.as_bytes(x) for x in proto_values]\r\n    except TypeError:\r\n      raise TypeError(\"Failed to convert object of type %s to Tensor. \"\r\n                      \"Contents: %s. Consider casting elements to a \"\r\n                      \"supported type.\" % (type(values), values))\r\n    tensor_proto.string_val.extend(str_values)\r\n    return tensor_proto\r\n```\r\n\r\nThat's why I think obj.str() might fix the issue. However, the solution is worse in performance. Do you have a better suggestion? Thanks.", "Hm, I may be missing where `obj.str` is turned into `int`. Anyway, the performance should be OK if you restrict it to tensors of length <= 8", "np.array([1, tf.Dimension(784)], dtype=tf.int32) returns array([1, 2], dtype=int32), so maybe a solution would be to set the dtype to int if it is None and values is a list mix of numbers and Dimensions?", "Thanks, all.\r\n\r\n@pmccarter 's advice sounds attractive, I'd like to dig deeper.\r\n\r\n```python\r\nIn [5]: np.array([1, tf.Dimension(784)], dtype=np.int32)\r\nOut[5]: array([  1, 784], dtype=int32)\r\n```", "What about defining a thin ungenerated reshape() function that delegates to the generated function, and coerces the shape to a 2d int list if possible?", "@pmccarter actually I like that idea . It would have much less side-effects. We already have Python ops which are essentially 1 line wrappers over underlying generated ops, like reduce sum\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/2cd08105bd961ca125483f2076c7f301c1020da3/tensorflow/python/ops/math_ops.py#L1274", "Cool I can probably get a pull request in tomorrow.", "X.get_shape().as_list()[-1]", "I am using tensorflow 1.4.1, and I am still having the same problem with models/official/resnet/resnet.py\r\n\r\n`TypeError: Failed to convert object of type <class 'tensorflow.python.data.ops.dataset_ops.PrefetchDataset'> to Tensor. Contents: <PrefetchDataset shapes: ((?, 32, 32, 3), (?, 10)), types: (tf.float32, tf.float32)>. Consider casting elements to a supported type.`\r\n\r\nWhen will this be fixed? I would not want to spend time fixing this myself, please", "@RoboEvangelist The bug has been fixed. And about your problem,  I don't think so. As the exception said, you mistake Dataset as Tensor. ", "@facaiy I just upgraded to tensorflow 1.6.0, and I don't have the problem anymore. It is still a bug in tensorflow 1.4.1 due to my experience ", "@yaroslavvb  @mrry  I have a completely different error that says \r\n\r\nFailed to convert object of type <class 'werkzeug.datastructures.File.Storage> to tensor.\r\n\r\n>TypeError: Failed to convert object of type (class'werkzeug.datastructures.File.Storage') to tensor. Contents: (Filestorage: u'File.txt' ('text/plain')). Consider casting elements to a supported type\r\n\r\nbelow is the client file with flask framework for tensorflow serving running inside a docker.  [https://github.com/tensorflow/tensorflow/issues/18157](url)\r\n```\r\n\r\ntf.app.flags.DEFINE_string('server', 'localhost:9000', 'PredictionService host:port')\r\nFLAGS = tf.app.flags.FLAGS\r\n\r\napp = Flask(__name__)\r\n\r\nclass mainSessRunning():\r\n    \r\n    def __init__(self):\r\n        host, port = FLAGS.server.split(':')\r\n        channel = implementations.insecure_channel(host, int(port))\r\n        self.stub = prediction_service_pb2.beta_create_PredictionService_stub(channel)\r\n\r\n        self.request = predict_pb2.PredictRequest()\r\n        self.request.model_spec.name = 'example_model'\r\n        self.request.model_spec.signature_name = 'prediction'\r\n\r\n    def inference(self, val_x):\r\n        #temp_data = numpy.random.randn(100, 3).astype(numpy.float32)\r\n        #temp_data = val_x.astype(np.float32).reshape(-1, 3)\r\n        data = val_x\r\n        self.request.inputs['input'].CopyFrom(tf.contrib.util.make_tensor_proto(data))\r\n        result = self.stub.Predict(self.request, 5.0)\r\n        return result\r\n\r\nrun = mainSessRunning()\r\n\r\nprint(\"Initialization done. \")\r\n\r\n# Define a route for the default URL, which loads the form\r\n@app.route('/inference', methods=['POST'])\r\ndef inference():\r\n    request_data = request.files['file']\r\n    result = run.inference(request_data)\r\n    r = json_format.MessageToJson(result)\r\n    return jsonify({'result':r})\r\n```", "I still have this issue, using tensorflow 1.7", "i also have this issue", "def read_and_decode(filename):\r\n    filename_quece = tf.train.string_input_producer([filename])#\u8bfb\u5165\u6d41\u4e2d\r\n    \r\n    reader = tf.TFRecordReader()\r\n    _,serialized_example = reader.read(filename_quece)#\u8fd4\u56de\u6587\u4ef6\u540d\u548c\u6587\u4ef6\r\n    features = tf.parse_single_example(serialized_example,features={\r\n        'label':tf.FixedLenFeature([],tf.int64),\r\n        'img_raw' : tf.FixedLenFeature([],tf.string),\r\n    })\r\n    img = tf.decode_raw(features['img_raw'],tf.uint8)\r\n    img = tf.reshape(img,[256,256,3])\r\n    img = tf.cast(img,tf.float32)*(1./255) - 0.5\r\n    label = tf.cast(features['label'],tf.int32)\r\n\r\n    return img,label\r\nif __name__ == '__main__':\r\n    img,label = read_and_decode(\"train_data.tfrecords\")\r\n#     print(img.shape)\r\n#     print(img[0])\r\n    img_batch,label_batch = tf.train.shuffle_batch([img,label],batch_size=32,capacity=200000,\r\n                                                   min_after_dequeue=100)\r\n    \r\n    \r\n#     img_batch = tf.reshape(img_batch,[None,256*256*3])\r\n    x = tf.placeholder(tf.float32,[None,256*256*3])\r\n    \r\n    w = tf.Variable(tf.zeros([256*256*3,45]))\r\n    b = tf.Variable(tf.zeros([45]))\r\n    \r\n    y = tf.nn.softmax(tf.matmul(x,w)+b)\r\n    y_ = tf.placeholder(tf.float32,[None])\r\n    \r\n    cross_entropy = -tf.reduce_sum(y_*tf.log(y))\r\n    \r\n    train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\r\n    \r\n\r\n    #\u521d\u59cb\u5316\u6240\u6709\u7684op\r\n    init = tf.global_variables_initializer()\r\n#     \r\n    with tf.Session() as sess:\r\n        sess.run(init)\r\n        coord=tf.train.Coordinator()#\u521b\u5efa\u4e00\u4e2a\u534f\u8c03\u5668\uff0c\u7ba1\u7406\u7ebf\u7a0b\r\n        #\u542f\u52a8\u961f\u5217\r\n\r\n        threads = tf.train.start_queue_runners(sess=sess,coord=coord,start=True)\r\n        for i in range(10):\r\n            X_train_batch,y_train_batch = sess.run([img_batch,label_batch])\r\n           \r\n            sess.run(train_step,feed_dict={x:X_train_batch,y_:y_train_batch})\r\n            print(X_train_batch.shape,y_train_batch.shape)\r\n            print(X_train_batch)\r\n        \r\n        coord.request_stop()\r\n        coord.join(threads)\r\n\r\n\r\n\r\nValueError: Cannot feed value of shape (32, 256, 256, 3) for Tensor 'Placeholder_2:0', which has shape '(?, 196608)'\r\nI can't  deal with this issue\r\n"]}, {"number": 11973, "title": "[Java] Build rules and skeleton for operation wrappers generator", "body": "In this PR, Bazel rules to generate operation wrappers in Java at build-time and a very minimal implementation of the generator (in C++) are added.\r\n\r\nFor now, the generator only create empty packages (one package per op-library) and combine them into a source archive (.srcjar) that is added as a source dependency of the tensorflow Java library target.\r\n\r\nThe goal of this PR is to make sure that everything is setup properly and agreed on before starting to generate for real the operation wrappers.", "comments": ["Can one of the admins verify this patch?", "So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored by someone other than the pull request submitter.  We need to confirm that they're okay with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this State. It's up to you to confirm consent of the commit author(s) and merge this pull request when appropriate.*\n\n<!-- need_author_consent -->", "Jenkins, test this please", "@tensorflow-jenkins test this please", "This is good to merge. All tests passed (and I, the \"other author\" in the PR consent :)", "Hi @asimshankar , just to make sure everything has been approved correctly for merging this PR, the previous checks are still complaining about the missing CLA. Thanks!", "Jenkins, test this please.", "Do my last 2 changes really caused the tests to fail? Anything I can do to fix it?", "No, it shouldn't have. I believe there are some flaky tests that are being looked into. In the mean time, will try again", "Jenkins, test this please", "Jenkins, test this please"]}, {"number": 11972, "title": "Branch 163983198", "body": "", "comments": []}, {"number": 11971, "title": "API request: MonitoredSession.run_without_hooks", "body": "Currently it is not possible to run a `MonitoredSession` without also calling the `before_run` and `after_run` methods of session hooks. But sometimes it is necessary. For example, I want to modify certain variables in the graph, but sometimes the `SummarySaverHook` decides it is time to collect summary, right when I am loading new values into the dependent variables, and then `Tensorboad` shows inconsistent results.\r\n\r\nA `run_without_hooks` method will be immensely helpful. ", "comments": ["As a workaround you can call `monitored_session._tf_sess()` to get the underlying `tf.Session` object.\r\nBut I also hope there is a public API for it.", "If I access the raw session object, I lose the ability to auto recover session from errors.", "We added MonitoredSession.run_step_fn.  We hope it satisfies the use case. "]}, {"number": 11970, "title": "Error when using dataset.map() with num_threads != None", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes (code attached below)\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.2.1\r\n- **Python version**: 3.5\r\n- **Bazel version (if compiling from source)**: --\r\n- **CUDA/cuDNN version**: 8/5.1\r\n- **GPU model and memory**: GeForce GTX 1080, 8GB\r\n- **Exact command to reproduce**: just run the script below\r\n\r\n### Describe the problem\r\nWhen using the `tf.contrib.data` API and applying a function to a dataset via `dataset.map(my_function, num_threads=2)`, the following error occurs:\r\n>TypeError: Input 'output_buffer_size' of 'ParallelMapDataset' Op has type int32 that does not match expected type of int64.\r\n\r\nPlease note that `num_threads=2` is necessary to cause the error.\r\nFrom what I can see, in `MapDataset::make_dataset_resource()` (file `dataset_ops.py`) the `if self._num_threads is None:` triggers the call to `gen_dataset_ops.parallel_map_dataset` which then raises the error. I suspect a cast from int32 to int64 got lost somewhere in that function.\r\n\r\n### Source code / logs\r\n\r\n```\r\nimport tensorflow as tf\r\nfrom functools import partial\r\n\r\nfiles = [ 'some_filename' ]\r\n\r\nkeys_to_features = {\r\n    'image/encoded': tf.FixedLenFeature((), tf.string, default_value=''),\r\n    'image/format': tf.FixedLenFeature((), tf.string, default_value='jpg'),\r\n    'image/class/label': tf.FixedLenFeature([], tf.int64, default_value=-1),\r\n    'image/height': tf.FixedLenFeature([], tf.int64),\r\n    'image/width': tf.FixedLenFeature([], tf.int64),\r\n}\r\n\r\nitems_to_handlers = {\r\n    'image': tf.contrib.slim.tfexample_decoder.Image('image/encoded', 'image/format'),\r\n    'label': tf.contrib.slim.tfexample_decoder.Tensor('image/class/label'),\r\n}\r\n\r\ndecoder = tf.contrib.slim.tfexample_decoder.TFExampleDecoder(keys_to_features, items_to_handlers)\r\nmap_decode = partial(decoder.decode, items=['label', 'image'])\r\n\r\ndataset = tf.contrib.data.TFRecordDataset(files)\r\ndataset = dataset.map(map_decode, num_threads=2)\r\nit = dataset.make_one_shot_iterator()\r\n```\r\n\r\nFull traceback:\r\n```\r\nTraceback (most recent call last):\r\n\r\n  File \"<ipython-input-8-7ba67ea47c21>\", line 44, in <module>\r\n    it = dataset.make_one_shot_iterator()\r\n\r\n  File \"C:\\Users\\1\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\data\\python\\ops\\dataset_ops.py\", line 413, in make_one_shot_iterator\r\n    _make_dataset.add_to_graph(ops.get_default_graph())\r\n\r\n  File \"C:\\Users\\1\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\function.py\", line 619, in add_to_graph\r\n    self._create_definition_if_needed()\r\n\r\n  File \"C:\\Users\\1\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\data\\python\\framework\\function.py\", line 167, in _create_definition_if_needed\r\n    outputs = self._func(*inputs)\r\n\r\n  File \"C:\\Users\\1\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\data\\python\\ops\\dataset_ops.py\", line 411, in _make_dataset\r\n    return self.make_dataset_resource()\r\n\r\n  File \"C:\\Users\\1\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\data\\python\\ops\\dataset_ops.py\", line 1466, in make_dataset_resource\r\n    output_shapes=nest.flatten(self.output_shapes))\r\n\r\n  File \"C:\\Users\\1\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\", line 414, in parallel_map_dataset\r\n    output_shapes=output_shapes, name=name)\r\n\r\n  File \"C:\\Users\\1\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 513, in apply_op\r\n    (prefix, dtypes.as_dtype(input_arg.type).name))\r\n\r\nTypeError: Input 'output_buffer_size' of 'ParallelMapDataset' Op has type int32 that does not match expected type of int64.\r\n```", "comments": ["Thank you for pointing that out. This bug has been fixed in TensorFlow 1.3.0-rc1.\r\n\r\n"]}]