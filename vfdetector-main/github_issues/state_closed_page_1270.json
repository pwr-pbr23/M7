[{"number": 15037, "title": "Support \"causal\" padding in tf.layers.convolutional.Conv1D", "body": "Because #15000 is closed by mistake, hence the PR is reopened to resolve #14933 issue.\r\n\r\nBecause we don't see causal padding in other use cases expect of NTC, we choose to modify code at Conv1D, instead of tf.nn.convolution.\r\n\r\nRef: [conv1d implementation](https://github.com/fchollet/keras/blob/d956d19fccf6de6344c282218f1b027453785fa9/keras/backend/tensorflow_backend.py#L3141-3145) in keras.\r\n\r\n### How to test\r\n\r\n+ [x] add test for layers.Conv1D\r\n+ [x] add test for keras.layers.Conv1D\r\n+ [ ] pass all tests.", "comments": ["Can one of the admins verify this patch?", "cc @martinwicke @lukaszkaiser @fchollet who I think might be interested.", "Thanks for review, @fchollet . I agree that `self.padding` should be `causal`, and there are two ways I can think:\r\n1. Modify code of `_Conv` and `Conv1D`: only support causal for NTC format. Easy, but a little tricky.\r\n2. As suggested by @lukaszkaiser in #15000,  Support LEFT padding in `tf.nn.convolution`: More general, however I'm not sure whether cudnn supports left-justified padding. Need time to make an investigation.\r\n> In general, it'd be very very good to have causal=\"LEFT\" padding in TF. This is the one reason why both T2T and Sonet re-implement conv layers...\r\n\r\nI think the second way sounds unified. What do you think about the idea?", "We can add `padding='causal'` in `tf.nn.convolution` indeed. Having support only in the layers in a bit restricted (although it is still pretty good, since most people just use the layers).", "@fchollet I'd like to implement the specific case at first, \r\n\r\nReply:\r\n+ Clean double quote: done.\r\n+ `layer.padding` should return \"causal\": done.\r\n     create a private method `_get_padding`, which can be removed if `nn_ops.convolution` support causal padding in the future.\r\n+ incorporate the code for output shape computation: not yet.\r\n    Because both `build` and `_compute_out_shape` need correct `input_shape`, I cannot find an appropriate way to incorporate it. So I leave the `inputs_fn` and `shape_fn`. The solution might look awkward, however it doesn't modify `_Conv` codes and underline the preprocessing. I think it's clear for understand and a little change for `_Conv`.\r\n\r\nOthers:\r\n+ Leave comments: remind us to remove those codes if `nn_ops.convolution` support causal padding in the future.\r\n+ Handle unknown dimension case, thanks @szpssky .\r\n\r\nIf anyone has a good idea, don't hesitate to tell me. Thanks very much.", "@fchollet WDYT?", "@fchollet WDYT?", "Close it since it has been a long time without any feedback."]}, {"number": 15036, "title": "error while importing", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug or a feature request.\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**: \r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\nTraceback (most recent call last):\r\nFile \"\", line 1, in \r\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/init.py\", line 24, in \r\nfrom tensorflow.python import *\r\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/init.py\", line 51, in \r\nfrom tensorflow.python import pywrap_tensorflow\r\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py\", line 52, in \r\nraise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py\", line 41, in \r\nfrom tensorflow.python.pywrap_tensorflow_internal import *\r\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in \r\n_pywrap_tensorflow_internal = swig_import_helper()\r\nFile \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n_mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\nImportError: libcudnn.so.5: cannot open shared object file: No such file or directory\r\nFailed to load the native TensorFlow runtime.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": []}, {"number": 15035, "title": "NadamOptimizer does not work with sparse gradients", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: pip\r\n- **TensorFlow version (use command below)**: v1.4.0-rc1-11-g130a514 1.4.0\r\n- **Python version**: 3.6.3\r\n\r\nCode:\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.contrib.opt import NadamOptimizer\r\n\r\noptimizer = NadamOptimizer(learning_rate=0.001)\r\n# optimizer = tf.train.AdamOptimizer(learning_rate=0.001)  # this works\r\nw = tf.get_variable(\"w\", shape=(100, 10))\r\nidxs = tf.placeholder(tf.int32, shape=(None,))\r\nemb = tf.gather(w, idxs)\r\nloss = tf.reduce_sum(emb ** 2)\r\nminimize = optimizer.minimize(loss)\r\n\r\nwith tf.Session() as sess:\r\n  sess.run(tf.global_variables_initializer())\r\n  sess.run(minimize, feed_dict={idxs: [1, 2, 3]})\r\n```\r\n\r\nThis fails with:\r\n```\r\n...\r\n  File \"/u/zeyer/.local/lib/python3.6/site-packages/tensorflow/contrib/opt/python/training/nadam_optimizer.py\", line 83, in _apply_sparse_shared\r\n    m_bar = m_scaled_g_values + beta1_t * m_t\r\n...\r\n\r\nInvalidArgumentError (see above for traceback): Incompatible shapes: [3,10] vs. [100,10]\r\n         [[Node: Adam/update_w/add = Add[T=DT_FLOAT, _class=[\"loc:@w\"], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Adam/update_w/mul_1, Adam/update_w/mul_3)]]\r\n```\r\n\r\nThe bug is pretty obvious in `nadam_optimizer.py`. The fix would be to do it like in `adam.py`:\r\n```\r\nm_t = state_ops.assign(m, m * beta1_t, use_locking=self._use_locking)\r\nwith ops.control_dependencies([m_t]):\r\n  m_t = scatter_add(m, indices, m_scaled_g_values)\r\n```\r\n\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: N/A\r\n", "@alextp can you fix this?\r\n\r\nAlso, @albertz, feel free to submit a PR to address this.", "I'm not the maintainer of this contrib optimizer so I think this is contributions welcome.", "I created a PR for this, please feel free to review #15665", "@albertz Please see the TensorFlow v1 to TensorFlow v2 [migration guide](https://www.tensorflow.org/guide/migrate).We see that you are using TF v1.x which is not actively supported and please try to upgrade to TF v2.4 or later.Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 15034, "title": "Optimize graph & graph transform tools do not support NCHW", "body": "I tried optimizing graph using both [Graph transform tool](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/graph_transforms/README.md) and [Optimize graph for inference](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/optimize_for_inference.py). Both cases produced the same error because the fused batchnorm used not NCHW, but NHWC. I've got the error like this:\r\n\r\n```\r\nInvalidArgumentError (see above for traceback): Must provide as many biases as the channel dimension of the input tensor: [256] vs. 19 in [1,256,19,19]\r\n\t [[Node: prefix/convblock/BatchNorm/FusedBatchNorm = BiasAdd[T=DT_FLOAT, data_format=\"NHWC\", _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](prefix/convblock/Conv2D, prefix/convblock/Conv2D_bn_offset)]\r\n```\r\n\r\nAlthough NCHW is faster than NHWC in GPU environment, why the tools do not support NCHW?\r\n\r\n", "comments": ["Could you provide a reproducible test case of what exactly you tried to do? Generally speaking, I think a lot of the tooling after training requires NHWC, as that was the only format when those were written. If you could provide a reproducible test case, we could work to improve it. @petewarden, do you have any other comments?\r\n", "I tried:\r\n\r\n```\r\npython tensorflow/python/tools/optimize_for_inference.py \\\r\n--input ./ckpt/frozen_model.pb \\\r\n--output ./ckpt/optimized_model.pb \\\r\n--frozen_graph true \\\r\n--input_names Placeholder \\\r\n--output_names policy_head/softmax,value_head/value/Tanh\r\n```\r\n\r\nand\r\n\r\n```\r\ntensorflow/bazel-bin/tensorflow/tools/graph_transforms/transform_graph \\\r\n--in_graph='./ckpt/frozen_model.pb' \\\r\n--out_graph='./ckpt/transformed_model.pb' \\\r\n--inputs='Placeholder' \\\r\n--outputs='policy_head/softmax,value_head/value/Tanh' \\\r\n--transforms='\r\nfold_constants(ignore_errors=true)\r\nfold_batch_norms\r\nfold_old_batch_norms\r\nfuse_pad_and_conv\r\nfuse_resize_and_conv\r\nfuse_resize_pad_and_conv\r\n'\r\n```\r\n\r\nIn both cases, the error occurred in fused batchnorm. The frozen model worked well, but the optimized model and transformed model emitted error.", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "Nagging Assigneee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly."]}, {"number": 15033, "title": "cuDNN on windows will speed up image retraining?", "body": "If  I'll do 4 steps from http://docs.nvidia.com/deeplearning/sdk/cudnn-install/index.html#installwindows\r\n\r\nit will speed up tensorflow image retraining? (https://www.tensorflow.org/versions/r0.12/how_tos/image_retraining/)\r\n\r\n![screenshot_7](https://user-images.githubusercontent.com/8851301/33477760-8eea082a-d68f-11e7-89d3-f8386ada70b2.png)\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue? Please update the label and/or status accordingly.", "gpu isn't working on windows anyway"]}, {"number": 15032, "title": "Error while implementing the feature requested in  #10767", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nYes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nRHEL 6.8 \r\n- **TensorFlow installed from (source or binary)**:\r\nbinary\r\n- **TensorFlow version (use command below)**:\r\n'v1.3.0-rc1-5326-gcae852a', '1.4.0'\r\n- **Python version**: \r\n2.7.14\r\n- **Bazel version (if compiling from source)**:\r\nBuild label: 0.5.4- (@non-git)\r\n- **GCC/Compiler version (if compiling from source)**:\r\n4.8.5\r\n- **CUDA/cuDNN version**:\r\nNot installed\r\n- **GPU model and memory**:\r\nUsing tensorflow for CPU\r\n- **Exact command to reproduce**:\r\nI want to implement _in_top_k_ operation with options to specify what to do when a tie occurs for [CIFAR-10](https://github.com/tensorflow/models/tree/master/tutorials/image/cifar10) data-set. I came across this feature request in #10767, modified the 6-files as shown [here](https://github.com/nolanliou/tensorflow/commit/681724f94e025bbd8377c5406eec4047d58fc31b), and rebuilt from source. When I run _eval_CIFAR10.py_ which contains the _in_top_k_ op, I get the following error.\r\n\r\n  File \"eval_CIFAR10.py\", line 146, in <module>\r\n    tf.app.run()\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 129, in run\r\n    _sys.exit(main(argv))\r\n  File \"eval_CIFAR10.py\", line 141, in main\r\n    evaluate()\r\n  File \"eval_CIFAR10.py\", line 130, in evaluate\r\n    eval_once(saver, summary_writer, top_k_op, summary_op)\r\n  File \"eval_CIFAR10.py\", line 63, in eval_once\r\n    saver.restore(sess, ckpt.model_checkpoint_path)\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1686, in restore\r\n    {self.saver_def.filename_tensor_name: save_path})\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 889, in run\r\n    run_metadata_ptr)\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1120, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1317, in _do_run\r\n    options, run_metadata)\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1336, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Multiple OpKernel registrations match NodeDef 'in_top_k/InTopKV2 = InTopKV2[T=DT_INT32, handle_ties=\"SAMPLE\"](softmax_linear/softmax_linear, Reshape_2, in_top_k/InTopKV2/k)': 'op: \"InTopKV2\" device_type: \"CPU\" constraint { name: \"T\" allowed_values { list { type: DT_INT32 } } } host_memory_arg: \"predictions\" host_memory_arg: \"targets\" host_memory_arg: \"k\" host_memory_arg: \"precision\"' and 'op: \"InTopKV2\" device_type: \"CPU\" constraint { name: \"T\" allowed_values { list { type: DT_INT32 } } } host_memory_arg: \"predictions\" host_memory_arg: \"targets\" host_memory_arg: \"k\" host_memory_arg: \"precision\"'\r\n\t [[Node: in_top_k/InTopKV2 = InTopKV2[T=DT_INT32, handle_ties=\"SAMPLE\"](softmax_linear/softmax_linear, Reshape_2, in_top_k/InTopKV2/k)]]\r\n\r\nCaused by op u'in_top_k/InTopKV2', defined at:\r\n  File \"eval_CIFAR10.py\", line 146, in <module>\r\n    tf.app.run()\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 129, in run\r\n    _sys.exit(main(argv))\r\n  File \"eval_CIFAR10.py\", line 141, in main\r\n    evaluate()\r\n  File \"eval_CIFAR10.py\", line 116, in evaluate\r\n    top_k_op = tf.nn.in_top_k(logits, labels, 1, handle_ties=\"SAMPLE\")\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/nn_ops.py\", line 2523, in in_top_k\r\n    return gen_nn_ops._in_top_kv2(predictions, targets, k, handle_ties, name=name)\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 2536, in _in_top_kv2\r\n    handle_ties=handle_ties, name=name)\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 3101, in create_op\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1583, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\nInvalidArgumentError (see above for traceback): Multiple OpKernel registrations match NodeDef 'in_top_k/InTopKV2 = InTopKV2[T=DT_INT32, handle_ties=\"SAMPLE\"](softmax_linear/softmax_linear, Reshape_2, in_top_k/InTopKV2/k)': 'op: \"InTopKV2\" device_type: \"CPU\" constraint { name: \"T\" allowed_values { list { type: DT_INT32 } } } host_memory_arg: \"predictions\" host_memory_arg: \"targets\" host_memory_arg: \"k\" host_memory_arg: \"precision\"' and 'op: \"InTopKV2\" device_type: \"CPU\" constraint { name: \"T\" allowed_values { list { type: DT_INT32 } } } host_memory_arg: \"predictions\" host_memory_arg: \"targets\" host_memory_arg: \"k\" host_memory_arg: \"precision\"'\r\n\t [[Node: in_top_k/InTopKV2 = InTopKV2[T=DT_INT32, handle_ties=\"SAMPLE\"](softmax_linear/softmax_linear, Reshape_2, in_top_k/InTopKV2/k)]]\r\n\r\nIf you can kindly look into the matter I shall be much helped. Thank you. ", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!", "The issue is related to a new feature request (added option to deal with ties in _in_top_k_ op). Is the feature requested in  #10767  part of the latest tensorflow? I cloned the latest tensorflow version from github and could not find the change. Just wondering if anyone has implemented the [changes](https://github.com/nolanliou/tensorflow/commit/681724f94e025bbd8377c5406eec4047d58fc31b) done by @nolanliou and others and became successful to add _handle_ties_ argument to the _in_top_k_ op. ", "Right, implementing a new feature is also a kind of usage question. It's best to share your experience so we can build the knowledge base on stackoverflow..", "I have asked the question [here](https://stackoverflow.com/questions/47706810/dealing-with-ties-in-in-top-k-op-of-tensorflow) in StackOverflow.", "Thanks!\n\nOn Thu, Dec 7, 2017, 6:35 PM rezwan16 <notifications@github.com> wrote:\n\n> I have asked the question here\n> <https://stackoverflow.com/questions/47706810/dealing-with-ties-in-in-top-k-op-of-tensorflow>\n> in StackOverflow.\n>\n> \u2014\n> You are receiving this because you modified the open/close state.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/15032#issuecomment-350155127>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AT_SbVnZ6nBHdA-g2Lny3tgVNouZTckOks5s-KBagaJpZM4QyFdp>\n> .\n>\n"]}, {"number": 15031, "title": "Fix error message of WhereOpCPU", "body": "", "comments": ["Can one of the admins verify this patch?", "@ebrevdo any luck with this?", "Jenkins, test this please.", "For some reason, the build failure has no log. Trying again."]}, {"number": 15030, "title": "Could not find a version that satisfies the requirement tensorflow-gpu (from versions: )", "body": "Can't install tensorflow on Windows using Aconda method:\r\n\r\n> Could not find a version that satisfies the requirement tensorflow-gpu (from versions: )\r\n\r\n```\r\nThe following NEW packages will be INSTALLED:\r\n\r\n    certifi:        2017.11.5-py35_0 conda-forge\r\n    pip:            9.0.1-py35_0     conda-forge\r\n    python:         3.5.4-1          conda-forge\r\n    setuptools:     37.0.0-py35_0    conda-forge\r\n    vs2015_runtime: 14.0.25420-0     conda-forge\r\n    wheel:          0.30.0-py_1      conda-forge\r\n    wincertstore:   0.2-py35_0       conda-forge\r\n\r\nProceed ([y]/n)? y\r\n\r\nFetching packages ...\r\nvs2015_runtime 100% |###############################| Time: 0:00:21  95.29 kB/s\r\npython-3.5.4-1 100% |###############################| Time: 0:01:48 162.13 kB/s\r\ncertifi-2017.1 100% |###############################| Time: 0:00:00 298.32 kB/s\r\nwincertstore-0 100% |###############################| Time: 0:00:00  10.92 kB/s\r\nsetuptools-37. 100% |###############################| Time: 0:00:01 404.06 kB/s\r\nwheel-0.30.0-p 100% |###############################| Time: 0:00:00 135.42 kB/s\r\npip-9.0.1-py35 100% |###############################| Time: 0:00:03 570.48 kB/s\r\nExtracting packages ...\r\n[      COMPLETE      ]|##################################################| 100%\r\nLinking packages ...\r\n[      COMPLETE      ]|##################################################| 100%\r\n#\r\n# To activate this environment, use:\r\n# > activate tensorflow\r\n#\r\n# To deactivate this environment, use:\r\n# > deactivate tensorflow\r\n#\r\n# * for power-users using bash, you must source\r\n#\r\n\r\nPS C:\\Windows\\system32>\r\nPS C:\\Windows\\system32> activate tensorflow\r\nPS C:\\Windows\\system32> pip install --ignore-installed --upgrade tensorflow-gpu\r\nCollecting tensorflow-gpu\r\n  Could not find a version that satisfies the requirement tensorflow-gpu (from versions: )\r\nNo matching distribution found for tensorflow-gpu\r\n```", "comments": ["finally worked with  https://www.python.org/ftp/python/3.6.3/python-3.6.3-amd64.exe\r\n\r\nand `pip3 install --upgrade tensorflow-gpu`"]}, {"number": 15029, "title": "build tensorflow Image Recognition with c++", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**: \r\n- **Bazel version (if compiling from source)**: 0.6.1\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:8.0\r\n- **GPU model and memory**:5.4.0\r\n- **Exact command to reproduce**:\r\n\r\n\r\n\r\nI follow this [tutorial](https://tensorflow.google.cn/tutorials/image_recognition#usage_with_the_c_api) try to build a a c++ tensorflow program.\r\n\r\nHere is the steps:\r\n\r\n1. build tensorflow from source. I am sure this step is right, because I can install python tensorflow with the whl file built by this step.\r\n2. in the tensorflow source code directory, I run this command:\r\n\r\n`bazel build tensorflow/examples/label_image/...`\r\n\r\nthe build failed with following logs(partial, because whole log is too big)\r\n\r\n\r\n\r\n> WARNING: /home/scott/github/tensorflow/tensorflow/tensorflow/core/BUILD:1781:1: in includes attribute of cc_library rule //tensorflow/core:framework_headers_lib: '../../external/nsync/public' resolves to 'external/nsync/public' not below the relative path of its package 'tensorflow/core'. This will be an error in the future. Since this rule was created by the macro 'cc_header_only_library', the error might have been caused by the macro implementation in /home/scott/github/tensorflow/tensorflow/tensorflow/tensorflow.bzl:1044:30\r\n> INFO: Analysed 2 targets (0 packages loaded).\r\n> INFO: Found 2 targets...\r\n> INFO: From ProtoCompile tensorflow/core/example/example.pb.cc:\r\n> bazel-out/local_linux-py3-opt/genfiles/external/protobuf_archive/src: warning: directory does not exist.\r\n> INFO: From ProtoCompile tensorflow/core/grappler/costs/op_performance_data.pb.cc:\r\n> bazel-out/local_linux-py3-opt/genfiles/external/protobuf_archive/src: warning: directory does not exist.\r\n> bazel-out/local_linux-py3-opt/genfiles/external/protobuf_archive/src: warning: directory does not exist.\r\n> INFO: From ProtoCompile tensorflow/contrib/cloud/kernels/bigquery_table_partition.pb.cc:\r\n> bazel-out/local_linux-py3-opt/genfiles/external/protobuf_archive/src: warning: directory does not exist.\r\n> INFO: From Executing genrule //tensorflow/cc:array_ops_genrule:\r\n> 2017-12-01 15:02:52.546440: W tensorflow/core/framework/op_gen_lib.cc:372] Squeeze can't find input squeeze_dims to rename\r\n> ERROR: /home/scott/github/tensorflow/tensorflow/tensorflow/examples/label_image/BUILD:14:1: Linking of rule '//tensorflow/examples/label_image:label_image' failed (Exit 1)\r\n> /usr/bin/ld: warning: libcudnn.so.6, needed by bazel-out/local_linux-py3-opt/bin/_solib_local/_U_S_Stensorflow_Sexamples_Slabel_Uimage_Clabel_Uimage___Utensorflow/libtensorflow_framework.so, not found (try using -rpath or -rpath-link)\r\n> bazel-out/local_linux-py3-opt/bin/_solib_local/_U_S_Stensorflow_Sexamples_Slabel_Uimage_Clabel_Uimage___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetConvolutionBackwardDataAlgorithm'\r\n", "comments": ["I found the cause. I need configure LPATH to include path of  libcudnn.so. Although I put the lib at the standard location. I am not familiar with bazel, so get confused at start.", "Hello,\r\n\r\nI have exactly the same problem, but I didn't get how you solved it. Can you give me more details, please? I tried to export the path to libcudnn.so, with export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda/lib64 , but it didn't work."]}, {"number": 15027, "title": "Tutorial wrong code  cifar10_multi_gpu_train.py", "body": "when I run \r\n`python cifar10_multi_gpu_train.py --num_gpus=2`\r\nreported a error\r\n\r\n```\r\nusage: cifar10_multi_gpu_train.py [-h] [--batch_size BATCH_SIZE]\r\n                                  [--data_dir DATA_DIR] [--use_fp16 USE_FP16]\r\ncifar10_multi_gpu_train.py: error: unrecognized arguments: --num_gpus=2\r\n```\r\n\r\nSo what is `[--use_fp16 USE_FP16]` ,it didn;a appear at anywhere in this code file", "comments": ["You can close this issue because this file has been moved to tensorflow/models(https://github.com/tensorflow/models/tree/master/tutorials/image/cifar10) and a discuss about this problem can be found at tensorflow/models#2481."]}, {"number": 15026, "title": "tensorflow 1.4 tf.keras gives different result compared with using keras directly", "body": "I have tensorflow 1.4, when running the following code, the accuracy is different (78% vs. 34.90%) when I import Sequential, Dense, and model_from_json directly from keras (uncomment first 3 lines) compared with import from tensorflow.python.keras. Why is the big discrepancy? \r\n \r\n(the data pima-indians-diabetes.csv is available at http://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data)\r\n\r\n#from keras.models import Sequential\r\n#from keras.layers import Dense\r\n#from keras.models import model_from_json\r\n\r\nfrom tensorflow.python.keras.layers import Dense\r\nfrom tensorflow.python.keras.models import Sequential, model_from_json\r\n\r\nimport numpy\r\nimport os\r\n# fix random seed for reproducibility\r\nnumpy.random.seed(7)\r\n# load pima indians dataset\r\ndataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\r\n# split into input (X) and output (Y) variables\r\nX = dataset[:,0:8]\r\nY = dataset[:,8]\r\n# create model\r\nmodel = Sequential()\r\nmodel.add(Dense(12, input_dim=8, kernel_initializer='uniform', activation='relu'))\r\nmodel.add(Dense(8, kernel_initializer='uniform', activation='relu'))\r\nmodel.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\r\n# Compile model\r\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n# Fit the model\r\nmodel.fit(X, Y, epochs=150, batch_size=10, verbose=0)\r\n# evaluate the model\r\nscores = model.evaluate(X, Y, verbose=0)\r\nprint(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\r\n\r\n# serialize model to JSON\r\nmodel_json = model.to_json()\r\nwith open(\"model.json\", \"w\") as json_file:\r\n    json_file.write(model_json)\r\n# serialize weights to HDF5\r\nmodel.save_weights(\"model.h5\")\r\nprint(\"Saved model to disk\")", "comments": ["I have no idea, but note that tf.keras is a tensorflow-specific re-implementation of the Keras API. AFAIK the two implementations are very different.", "@bchu The re-implementation is expected to achieve the same functionality as keras, though the implementation is different. I actually tried on multiple datasets, the resulting accuracies of the two are very different  (78% vs. 34.90%; 98% vs. 50%). ", "seems critical if it's true. cc @fchollet ", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "Nagging Assigneee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "@fchollet Do you have any update on this?", "No. Can anybody reproduce, with the same code/model, but with a different dataset?", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Unless anybody can share a script to reproduce the issue, this is a user error.\r\n\r\nI can attest that the following model behaves in the same way on test data in tf.keras and external Keras:\r\n\r\n```python\r\nmodel = Sequential()\r\nmodel.add(Dense(12, input_dim=8, kernel_initializer='uniform', activation='relu'))\r\nmodel.add(Dense(8, kernel_initializer='uniform', activation='relu'))\r\nmodel.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\r\n```\r\n\r\nHowever you may see differences due to the randomness of different initialization runs. Note that using \"uniform\" as initialization increases variance across runs.", "Dear @fchollet , I got a similar issue by using your method(tensorFlow 1.14.0, keras 2.2.4).  Here is my code.\r\n\r\n### **Source code(pure keras import)**\uff1a\r\n```\r\nimport keras\r\nfrom keras.datasets import mnist\r\nfrom keras.models import Sequential\r\nfrom keras.layers import Dense, Dropout, Flatten\r\nfrom keras.layers import Conv2D, MaxPooling2D\r\nfrom keras import backend as K\r\n\r\n```\r\n### **Source code(tf.keras import)**:\r\n\r\n```\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras.datasets import mnist\r\nfrom tensorflow.keras.models import Sequential\r\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten\r\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\r\nfrom tensorflow.keras import backend as K\r\n\r\n```\r\n### **commom parts**:\r\n\r\n```\r\nimport numpy as np\r\nimport random as rn\r\nimport tensorflow as tf\r\n\r\nnp.random.seed(2019)\r\nrn.seed(2019)\r\ntf.compat.v1.set_random_seed(2019)\r\n\r\n\r\nbatch_size = 128\r\nnum_classes = 10\r\nepochs = 12\r\n\r\n# input image dimensions\r\nimg_rows, img_cols = 28, 28\r\n\r\n# the data, split between train and test sets\r\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\r\n\r\nif K.image_data_format() == 'channels_first':\r\n    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\r\n    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\r\n    input_shape = (1, img_rows, img_cols)\r\nelse:\r\n    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\r\n    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\r\n    input_shape = (img_rows, img_cols, 1)\r\n\r\nx_train = x_train.astype('float32')\r\nx_test = x_test.astype('float32')\r\nx_train /= 255\r\nx_test /= 255\r\nprint('x_train shape:', x_train.shape)\r\nprint(x_train.shape[0], 'train samples')\r\nprint(x_test.shape[0], 'test samples')\r\n\r\n# convert class vectors to binary class matrices\r\ny_train = keras.utils.to_categorical(y_train, num_classes)\r\ny_test = keras.utils.to_categorical(y_test, num_classes)\r\n\r\nmodel = Sequential()\r\nmodel.add(Conv2D(32, kernel_size=(3, 3),\r\n                 activation='relu',\r\n                 strides=(1, 1),\r\n                 padding='valid',\r\n                 dilation_rate=(1, 1), \r\n                 use_bias=True, \r\n                 kernel_initializer='glorot_uniform',\r\n                 bias_initializer='zeros',\r\n                 input_shape=input_shape))\r\nmodel.add(Conv2D(64, (3, 3),\r\n                strides=(1, 1),\r\n                 padding='valid',\r\n                 dilation_rate=(1, 1), \r\n                 use_bias=True, \r\n                 kernel_initializer='glorot_uniform',\r\n                 bias_initializer='zeros', \r\n                 activation='relu'))\r\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\r\nmodel.add(Dropout(0.25))\r\nmodel.add(Flatten())\r\nmodel.add(Dense(128, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', activation='relu'))\r\nmodel.add(Dropout(0.5))\r\nmodel.add(Dense(num_classes, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', activation='softmax'))\r\n\r\nmodel.compile(loss=keras.losses.categorical_crossentropy,\r\n              optimizer=keras.optimizers.Adadelta(),\r\n              metrics=['accuracy'])\r\n\r\nmodel.fit(x_train, y_train,\r\n          batch_size=batch_size,\r\n          epochs=epochs,\r\n          verbose=1,\r\n          validation_data=(x_test, y_test))\r\nscore = model.evaluate(x_test, y_test, verbose=0)\r\nprint('Test loss:', score[0])\r\nprint('Test accuracy:', score[1])\r\n\r\n```\r\n### **Result(pure keras)\uff1a**\r\n\r\n```\r\nEpoch 1/12\r\n60000/60000 [==============================] - 10s 161us/step - loss: 0.2684 - acc: 0.9177 - val_loss: 0.0599 - val_acc: 0.9812\r\nEpoch 2/12\r\n60000/60000 [==============================] - 6s 95us/step - loss: 0.0893 - acc: 0.9731 - val_loss: 0.0408 - val_acc: 0.9859\r\nEpoch 3/12\r\n60000/60000 [==============================] - 6s 92us/step - loss: 0.0658 - acc: 0.9797 - val_loss: 0.0344 - val_acc: 0.9884\r\nEpoch 4/12\r\n60000/60000 [==============================] - 6s 93us/step - loss: 0.0534 - acc: 0.9843 - val_loss: 0.0315 - val_acc: 0.9888\r\nEpoch 5/12\r\n60000/60000 [==============================] - 6s 93us/step - loss: 0.0471 - acc: 0.9859 - val_loss: 0.0297 - val_acc: 0.9903\r\nEpoch 6/12\r\n60000/60000 [==============================] - 6s 93us/step - loss: 0.0431 - acc: 0.9869 - val_loss: 0.0273 - val_acc: 0.9910\r\nEpoch 7/12\r\n60000/60000 [==============================] - 6s 94us/step - loss: 0.0379 - acc: 0.9881 - val_loss: 0.0258 - val_acc: 0.9911\r\nEpoch 8/12\r\n60000/60000 [==============================] - 6s 93us/step - loss: 0.0338 - acc: 0.9896 - val_loss: 0.0253 - val_acc: 0.9917\r\nEpoch 9/12\r\n60000/60000 [==============================] - 6s 93us/step - loss: 0.0315 - acc: 0.9902 - val_loss: 0.0282 - val_acc: 0.9911\r\nEpoch 10/12\r\n60000/60000 [==============================] - 6s 94us/step - loss: 0.0277 - acc: 0.9908 - val_loss: 0.0262 - val_acc: 0.9920\r\nEpoch 11/12\r\n60000/60000 [==============================] - 6s 93us/step - loss: 0.0275 - acc: 0.9910 - val_loss: 0.0253 - val_acc: 0.9918\r\nEpoch 12/12\r\n60000/60000 [==============================] - 6s 92us/step - loss: 0.0252 - acc: 0.9921 - val_loss: 0.0273 - val_acc: 0.9916\r\nTest loss: 0.02725972963081831\r\nTest accuracy: 0.9916\r\n\r\n```\r\n### **Result(tf.keras):**\r\n\r\n```\r\nEpoch 1/12\r\n60000/60000 [==============================] - 7s 118us/sample - loss: 2.2976 - acc: 0.1186 - val_loss: 2.2629 - val_acc: 0.3077\r\nEpoch 2/12\r\n60000/60000 [==============================] - 4s 70us/sample - loss: 2.2391 - acc: 0.2488 - val_loss: 2.1936 - val_acc: 0.5507\r\nEpoch 3/12\r\n60000/60000 [==============================] - 4s 70us/sample - loss: 2.1677 - acc: 0.3645 - val_loss: 2.0994 - val_acc: 0.6332\r\nEpoch 4/12\r\n60000/60000 [==============================] - 4s 70us/sample - loss: 2.0664 - acc: 0.4451 - val_loss: 1.9656 - val_acc: 0.6864\r\nEpoch 5/12\r\n60000/60000 [==============================] - 4s 70us/sample - loss: 1.9266 - acc: 0.5110 - val_loss: 1.7900 - val_acc: 0.7180\r\nEpoch 6/12\r\n60000/60000 [==============================] - 4s 70us/sample - loss: 1.7591 - acc: 0.5528 - val_loss: 1.5817 - val_acc: 0.7464\r\nEpoch 7/12\r\n60000/60000 [==============================] - 4s 70us/sample - loss: 1.5767 - acc: 0.5961 - val_loss: 1.3670 - val_acc: 0.7686\r\nEpoch 8/12\r\n60000/60000 [==============================] - 4s 70us/sample - loss: 1.4031 - acc: 0.6257 - val_loss: 1.1722 - val_acc: 0.7870\r\nEpoch 9/12\r\n60000/60000 [==============================] - 4s 70us/sample - loss: 1.2534 - acc: 0.6560 - val_loss: 1.0119 - val_acc: 0.8047\r\nEpoch 10/12\r\n60000/60000 [==============================] - 4s 70us/sample - loss: 1.1304 - acc: 0.6804 - val_loss: 0.8855 - val_acc: 0.8194\r\nEpoch 11/12\r\n60000/60000 [==============================] - 4s 71us/sample - loss: 1.0355 - acc: 0.6964 - val_loss: 0.7891 - val_acc: 0.8317\r\nEpoch 12/12\r\n60000/60000 [==============================] - 4s 70us/sample - loss: 0.9585 - acc: 0.7164 - val_loss: 0.7156 - val_acc: 0.8390\r\nTest loss: 0.7156027168273926\r\nTest accuracy: 0.839\r\n\r\n```\r\nIt has a different result. Any resolution\uff1f @hhao89 @bchu @shivaniag ", "@wangyexiang The gap of performance between tf.keras and external keras in your example is because of the default learning rate of Adadelta. tf.keras uses 1e-3 while keras uses 1.0. Once you use 1.0 in tf.keras, you can still achieve the same performance obtained by external keras.\r\n\r\nref1: https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adadelta\r\nref2: https://keras.io/optimizers/\r\n\r\nNotebook: https://colab.research.google.com/drive/1UI-QlfR6_sCmJu5XY8yH3397OM7EGXon", "> Once you use 1.0 in tf.keras, you can still achieve the same performance obtained by external keras.\r\n\r\nI see. Thank you very much.  @WindQAQ \r\n", "Hi, I get difference as well with the same model, but one done with Keras and the other with TensorFlow.\r\nI check the default parameter (for the loss), but until now, I do not have found an explanation.\r\nMaybe using \"tf.compat.v1.RMSPropOptimizer\"  is not the same than using optimizer=\"rmsprop\" within model.compile (for keras) ?"]}, {"number": 15025, "title": "Revert \"Arbitrary dim for slice (#11140)\"", "body": "This reverts commit 8011eda4b70faac6025c6b0553c3d95474adb5fe.\r\n\r\nCheck if tests pass.", "comments": ["Note for others reading this revert: we had to revert this change because it has caused some issues internally."]}, {"number": 15024, "title": "Branch 177545934", "body": "", "comments": ["@gunan @yifeif the build is stuck: https://kokoro2.corp.google.com/job/tensorflow/job/github/job/ubuntu/job/cc/job/presubmit/1132/ and https://kokoro2.corp.google.com/job/tensorflow/job/github/job/ubuntu/job/contrib/job/presubmit/1054/"]}, {"number": 15023, "title": "Fix a BUILD file bug in `tensorflow/contrib/cloud/BUILD`", "body": "In `tensorflow/contrib/cloud`, invoking `bigquery_reader_ops_test` will fail.\r\n\r\nThe error is caused by the the fact that `bigquery_reader_ops_test` depends on `:bigquery_reader_ops_op_lib` and `:bigquery_reader_ops`.\r\n\r\nHowever, bigquery_reader_ops_test is in python, `:bigquery_reader_ops_op_lib` and `:bigquery_reader_ops` are cc libraries. So they shouldn't be the dependencies of bigquery_reader_ops_test.\r\n\r\nThis fix removes the above two dependencies so that `bigquery_reader_ops_test` could run successfully.\r\n\r\nBelow is the full error message before this PR.\r\n\r\n```\r\nubuntu@ubuntu:~/tensorflow$ bazel test -s --config=opt //tensorflow/contrib/cloud:bigquery_reader_ops_test\r\n..........\r\nWARNING: /home/ubuntu/tensorflow/tensorflow/core/BUILD:1815:1: in includes attribute of cc_library rule //tensorflow/core:framework_headers_lib: '../../external/nsync/public' resolves to 'external/nsync/public' not below the relative path of its package 'tensorflow/core'. This will be an error in the future. Since this rule was created by the macro 'cc_header_only_library', the error might have been caused by the macro implementation in /home/ubuntu/tensorflow/tensorflow/tensorflow.bzl:1127:30\r\nERROR: /home/ubuntu/tensorflow/tensorflow/contrib/cloud/BUILD:58:1: in deps attribute of py_test rule //tensorflow/contrib/cloud:bigquery_reader_ops_test: '//tensorflow/contrib/cloud:bigquery_reader_ops_op_lib' does not have mandatory providers: 'py'. Since this rule was created by the macro 'tf_py_test', the error might have been caused by the macro implementation in /home/ubuntu/tensorflow/tensorflow/tensorflow.bzl:1368:12\r\nERROR: /home/ubuntu/tensorflow/tensorflow/contrib/cloud/BUILD:58:1: in deps attribute of py_test rule //tensorflow/contrib/cloud:bigquery_reader_ops_test: '//tensorflow/contrib/cloud/kernels:bigquery_reader_ops' does not have mandatory providers: 'py'. Since this rule was created by the macro 'tf_py_test', the error might have been caused by the macro implementation in /home/ubuntu/tensorflow/tensorflow/tensorflow.bzl:1368:12\r\nERROR: Analysis of target '//tensorflow/contrib/cloud:bigquery_reader_ops_test' failed; build aborted: Analysis of target '//tensorflow/contrib/cloud:bigquery_reader_ops_test' failed; build aborted\r\nINFO: Elapsed time: 10.083s\r\nFAILED: Build did NOT complete successfully (105 packages loaded)\r\nERROR: Couldn't start the build. Unable to run tests\r\nubuntu@ubuntu:~/tensorflow$\r\n```\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["Jenkins, test this please.", "@gunan is there a problem with the build? I am seeing a lot of these, either fail to fetch the repo, start the docker, or just build aborted.", "In this case, the sanity build failed and that terminated every other build. This change is OK to merge. I will go ahead and merge.", "@gunan Thanks! It's a bit more than this one. I tried a bunch yesterday, and pretty much all of those that I checked failed. You can take a look at those: https://github.com/tensorflow/tensorflow/pulls?utf8=%E2%9C%93&q=is%3Apr+is%3Aopen+no%3Aassignee+label%3A%22cla%3A+yes%22+label%3A%22awaiting+testing+%28then+merge%29%22"]}, {"number": 15022, "title": "update label_image.py", "body": "1. add build rule for label_image.py\r\n2. remove extraneous semicolons", "comments": ["Can one of the admins verify this patch?", "@gunan the buildifier error seems to be suggesting a noop. What does that mean?\r\n", "Jenkins, test this please.", "Jenkins, test this please.", "@gunan good to go if build passes?", "Jenkins, test this please.", "@caisq looks like there are some failures on master, right?", "Some of the failures do not seem to be existing on master. For example this one:\r\nhttp://ci.tensorflow.org/job/tensorflow-pull-requests-cpu-python3/7941/consoleFull\r\n\r\nThis one points to a nonexistent page:\r\nhttps://ci.tensorflow.org/job/tensorflow-pull-requests-xla/4108/\r\n\r\nThese looks strange, but I don't see them on Jenkins:\r\nhttps://source.cloud.google.com/results/invocations/c8affece-3a4b-4eae-af9b-2593c0ffcae1/targets\r\n\r\nTriggering test again. \r\n\r\n@tensorflow-jenkins test this please\r\n\r\n", " If the test doesn't refresh and the link is broken then it's probably an old Jenkins target that was moved to kokoro.", "Some tests appear to fail. I'm not sure they are related. Could you check?", "I don't think those failures are relevant. Anything I can do to clarify it?", "@freedomtan The test failures are unrelated. Mergin PR. Thanks."]}, {"number": 15021, "title": "add link to decode_bmp", "body": "add link to decode_bmp to image api guide", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please."]}, {"number": 15020, "title": "Fix deprecated function", "body": "```\r\nWARNING:tensorflow:From train.py:163: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nPlease switch to tf.train.get_or_create_global_step\r\n```\r\ntf.contrib.framework.get_or_create_global_step() -> tf.train.get_or_create_global_step()", "comments": ["Can one of the admins verify this patch?"]}, {"number": 15019, "title": "Tensorflow: how to save/restore tf.data.Dataset?", "body": "I made a model with `tf.data.Dataset()` as a data IO function\r\n\r\nthen i exported the graph and tried to restore it with meta_graph file But it failed and following error messages occurred.\r\n\r\nI think that `tf.data.Dataset()` made a C++ object instead of python queue used before.\r\n\r\nAnd the graph_def only has a C++ object handler reference, so the graph_def alone without real C++ object can't load complete graph.\r\n\r\nHow can I load a executable graph with `tf.data.Dataset()`? Or is it impossible for now?\r\n\r\n```\r\nFile \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\nNotFoundError (see above for traceback): Function\r\n_make_dataset_5150cb86 is not defined.\r\n         [[Node: batch_processing/OneShotIterator = OneShotIterator[container=\"\", dataset_factory=_make_dataset_5150cb86[], output_shapes=[[?,1], [?,299,299,3]], output_types=[DT_INT32, DT_FLOAT], shared_name=\"\",\r\n_device=\"/job:workers/replica:0/task:0/device:CPU:0\"]()]]\r\n```\r\n\r\nIn short, all the tensorflow graphs without` tf.data.Dataset` work, when i add following codes. \r\n```\r\ngraph = tf.train.export_meta_graph()\r\ntf.reset_default_graph()\r\ntf.train.import_meta_graph(graph)\r\n\r\n```\r\nBut the graphs with` tf.data.Dataset `make a error message above\r\n\r\n\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "I have a similar issue - \r\nI'm trying to load a trained model for inference. In the code snippet below, `features:0` is the name of one of the tensors returned by dataset iterator. Is it possible to directly feed the tensor without having to initialize the iterator ?\r\n\r\nCode \r\n```python\r\nwith tf.Session(graph=tf.Graph()) as session:\r\n    graph_meta = tf.train.latest_checkpoint(model_dir) + '.meta'\r\n    saver = tf.train.import_meta_graph(os.path.join(model_dir, graph_meta))\r\n    saver.restore(session, tf.train.latest_checkpoint(model_dir))\r\n    feed_dict = {\r\n        'features:0': x_test # shape 102x13\r\n    }\r\n    predictions = session.run('logits:0', feed_dict)\r\n    print(predictions.shape)\r\n```\r\nError\r\n```\r\nFailedPreconditionError: GetNext() failed because the iterator has not been initialized. Ensure that you have run the initializer operation for this iterator before getting the next element.\r\n\t [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[?,13], [?], [?]], output_types=[DT_DOUBLE, DT_DOUBLE, DT_DOUBLE], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Iterator)]]\r\n```\r\n", "@taehyunkim1527 Can you share a complete reproducible example of the problem? I was unable to reproduce the problem with the code fragment in your example, although it was possible to reproduce it by adding arguments to `tf.train.export_meta_graph()`. I am in the process of fixing the latter problems, but it would be great to confirm that the fix works for your issue too.\r\n\r\n@suryasumukh I think you're running into a different problem. You certainly can feed values over the tensors returned from `Iterator.get_next()`, but you need to ensure that you feed *all* of the tensors returned by the iterator that might be used in the `run()` call. If you continue to have problems with this, please post a question on Stack Overflow.", "@mrry When i use that series of code of 'exporting and importing' in tensorflow/benchmarks's ImageNet tasks, I experienced this error message.\r\nI tried to implement a simple code to make the same error message today, but it failed.\r\nI think it is not a problem of tf.data.Dataset() and let me debug again.\r\nThank you for your kindness.\r\n\r\n", "Thanks for confirming that the problem doesn't arise with that exact code! I have a change in the pipeline that will make this path work in more cases (e.g. when using `clear_devices=True` or a scope prefix), so I'll reopen this issue until it lands.", "@mrry \r\nHi, I'm who opened this question formerly.\r\nAnd i found what was the problem.\r\nif we give arg '`clear_devices`' as True for the function '`export_scoped_meta_graph(`)' of `python\\framework\\meta_graph.py`\r\nIt starts to make empty graph_def and copy previous node_defs newly.\r\nIn this process, this code does not consider about `graph_def.library`.\r\nBut the information about '`map_function'` resides in graph_def.library", "@suryasumukh In order to retrain the pre-trained model, the initializer of data iterator can be declared as a tf.operation with a name while training for the first time. \r\n```\r\n    data_iter = dataset.make_initializable_iterator()\r\n    data_iter_init = data_iter.make_initializer(dataset, name='Data_itr_init')\r\n    next_batch = data_iter.get_next()\r\n``` \r\nThen, it can be sess.run with the name and fed with training data.\r\n`sess.run('Data_itr_init', feed_dict={\"Model_in:0\": train_X, \"Model_out:0\": train_Y})`", "> @suryasumukh In order to retrain the pre-trained model, the initializer of data iterator can be declared as a tf.operation with a name while training for the first time.\r\n> \r\n> ```\r\n>     data_iter = dataset.make_initializable_iterator()\r\n>     data_iter_init = data_iter.make_initializer(dataset, name='Data_itr_init')\r\n>     next_batch = data_iter.get_next()\r\n> ```\r\n> \r\n> Then, it can be sess.run with the name and fed with training data.\r\n> `sess.run('Data_itr_init', feed_dict={\"Model_in:0\": train_X, \"Model_out:0\": train_Y})`\r\n\r\nNot the point"]}, {"number": 15018, "title": "Introduce tf_http_archive", "body": "I decided to give https://github.com/tensorflow/tensorflow/pull/14813 another try.", "comments": ["PTAL", "Jenkins, test this please.", "I see this error is breaking all the builds:\r\n```\r\nERROR: /tmpfs/tmp/bazel/external/grpc/BUILD:539:1: no such target '//external:zlib': target 'zlib' not declared in package 'external' defined by /tmpfs/src/github/tensorflow/WORKSPACE and referenced by '@grpc//:grpc_base_c'\r\nWARNING: /tmpfs/src/github/tensorflow/tensorflow/core/BUILD:1815:1: in includes attribute of cc_library rule //tensorflow/core:framework_headers_lib: '../../external/nsync/public' resolves to 'external/nsync/public' not below the relative path of its package 'tensorflow/core'. This will be an error in the future. Since this rule was created by the macro 'cc_header_only_library', the error might have been caused by the macro implementation in /tmpfs/src/github/tensorflow/tensorflow/tensorflow.bzl:1127:30\r\nAnalyzing: 503 targets (343 packages loaded)\r\n```\r\n\r\nMaybe we missed one of the bind statements?", "Added.", "It looks like this time we have a problem with this script:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/makefile/download_dependencies.sh\r\nIt parses the workspace.bzl file to get the links to our dependencies.", "Third time's a charm. test this please", "Build failures now appear to be unrelated.", "Yes, all failures are known issues.\r\nMerging."]}, {"number": 15017, "title": "Update freeze_graph.py", "body": "If there are spaces in multiple parameters, a parameter is not recognized.\r\nex) \"hypothesis, cost\" (X)  => \"hypothesis,cost\" (O)\r\n\r\nSo   initializer_nodes.split(\",\")   =>  initializer_nodes.replace(' ','').split(\",\")\r\n       variable_names_whitelist.split(\",\") => variable_names_whitelist.replace(' ','').split(\",\")\r\n       output_node_names.split(\",\") => output_node_names.replace(' ','').split(\",\")", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->", "I signed it!\nThank you.\n\n2017-12-01 9:00 GMT+09:00 googlebot <notifications@github.com>:\n\n> Thanks for your pull request. It looks like this may be your first\n> contribution to a Google open source project. Before we can look at your\n> pull request, you'll need to sign a Contributor License Agreement (CLA).\n>\n> \ud83d\udcdd *Please visit https://cla.developers.google.com/\n> <https://cla.developers.google.com/> to sign.*\n>\n> Once you've signed, please reply here (e.g. I signed it!) and we'll\n> verify. Thanks.\n> ------------------------------\n>\n>    - If you've already signed a CLA, it's possible we don't have your\n>    GitHub username or you're using a different email address. Check your\n>    existing CLA data <https://cla.developers.google.com/clas> and verify\n>    that your email is set on your git commits\n>    <https://help.github.com/articles/setting-your-email-in-git/>.\n>    - If your company signed a CLA, they designated a Point of Contact who\n>    decides which employees are authorized to participate. You may need to\n>    contact the Point of Contact for your company and ask to be added to the\n>    group of authorized contributors. If you don't know who your Point of\n>    Contact is, direct the project maintainer to go/cla#troubleshoot.\n>    - In order to pass this check, please resolve this problem and have\n>    the pull request author add another comment and the bot will run again.\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/15017#issuecomment-348359866>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AE6FtI8e0I9XpGgqwM62YS0jL0DRypmyks5s70GsgaJpZM4QxqkE>\n> .\n>\n", "CLAs look good, thanks!\n\n<!-- ok -->", "@petewarden WDYT?", "@nalsil please pull rebase and push again."]}, {"number": 15016, "title": "no such package 'tensorflow/examples/image_retraining': BUILD file not found on package path. for Virtual Environment on mac. ", "body": "**Template ignored**", "comments": [" I followed the tensorflow tutorial for retraining inception but when typed retrain this occured. I am running it on a virtual env on a macbook pro.  How do i get the build file on a virtual env.\r\n\r\n\r\nbazel build tensorflow/examples/image_retraining:retrain\r\nERROR: no such package 'tensorflow/examples/image_retraining': BUILD file not found on package path.\r\nINFO: Elapsed time: 1.469s", "I apologize but I am having a hard time understanding what the problem is, where the problem is, and what version it affects. Please resubmit and pay attention to the issue template (https://github.com/tensorflow/tensorflow/issues/new) . Please provide all the information it asks. Thank you.\r\n\r\ni.e. What version of tensorflow? What tutorial URL? Where are you running this command from?\r\nHowever, my guess is you are not running this from within the downloaded source tree of tensorflow.\r\n\r\n"]}, {"number": 15015, "title": "Add additional linkopts argument to tf_custom_op_library.", "body": "This will help a repository that uses tensorflow as a submoudle to use existing tensorflow bazel rules in tensorflow.bzl", "comments": ["Can one of the admins verify this patch?"]}, {"number": 15014, "title": "Extend Dataset API to support writing to files (not just reading)", "body": "Just as we have a pipeline to read from files and convert them to output vectors/data via some model, It would be very useful to have a pipeline to take data and write it to files.\r\n\r\nOtherwise, we have to use TFRecordWriters and a bit more code, but really much of this can be abstracted away, simplifying the data creation process, especially when writing to shards (as one might do using distributed Tensorflow).", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue? Please update the label and/or status accordingly.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue? Please update the label and/or status accordingly.", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 29 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 15 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "We are closing this issue for now due to lack of activity. Please comment if this is still an issue for you. Thanks!"]}, {"number": 15013, "title": "GPU visual studio dependecies ", "body": "I build tensorflow 1.4.0 for windows with GPU usage. But when I run my program in visual studio 2015 I get these error:\r\n```\r\n1>tf_core_kernels.lib(cudnn_rnn_ops.cc.obj) : error LNK2001: unresolved external symbol \"public: virtual __cdecl perftools::gputools::ScratchAllocator::~ScratchAllocator(void)\" (??1ScratchAllocator@gputools@perftools@@UEAA@XZ)\r\n1>tf_core_kernels.lib(fft_ops.obj) : error LNK2001: unresolved external symbol \"public: virtual __cdecl perftools::gputools::ScratchAllocator::~ScratchAllocator(void)\" (??1ScratchAllocator@gputools@perftools@@UEAA@XZ)\r\n1>tf_core_kernels.lib(conv_ops_3d.obj) : error LNK2001: unresolved external symbol \"public: virtual __cdecl perftools::gputools::ScratchAllocator::~ScratchAllocator(void)\" (??1ScratchAllocator@gputools@perftools@@UEAA@XZ)\r\n1>tf_core_kernels.lib(conv_ops.obj) : error LNK2001: unresolved external symbol \"public: virtual __cdecl perftools::gputools::ScratchAllocator::~ScratchAllocator(void)\" (??1ScratchAllocator@gputools@perftools@@UEAA@XZ)\r\n1>tf_core_kernels.lib(cudnn_rnn_ops.cc.obj) : error LNK2001: unresolved external symbol \"public: class perftools::gputools::Stream & __cdecl perftools::gputools::Stream::ThenRnnForward(class perftools::gputools::dnn::RnnDescriptor const &,class perftools::gputools::dnn::RnnSequenceTensorDescriptor const &,class perftools::gputools::DeviceMemory<float> const &,class perftools::gputools::dnn::RnnStateTensorDescriptor const &,class perftools::gputools::DeviceMemory<float> const &,class perftools::gputools::dnn::RnnStateTensorDescriptor const &,class perftools::gputools::DeviceMemory<float> const &,class perftools::gputools::DeviceMemory<float> const &,class perftools::gputools::dnn::RnnSequenceTensorDescriptor const &,class perftools::gputools::DeviceMemory<float> *,class perftools::gputools::dnn::RnnStateTensorDescriptor const &,class perftools::gputools::DeviceMemory<float> *,class perftools::gputools::dnn::RnnStateTensorDescriptor const &,class perftools::gputools::DeviceMemory<float> *,bool,class perftools::gputools::ScratchAllocator *,class perftools::gputools::ScratchAllocator *)\" (?ThenRnnForward@Stream@gputools@perftools@@QEAAAEAV123@AEBVRnnDescriptor@dnn@23@AEBVRnnSequenceTensorDescriptor@523@AEBV?$DeviceMemory@M@23@AEBVRnnStateTensorDescriptor@523@23221PEAV723@3434_NPEAVScratchAllocator@23@6@Z)\r\n1>tf_core_kernels.lib(cudnn_rnn_ops.cc.obj) : error LNK2001: unresolved external symbol \"public: class perftools::gputools::Stream & __cdecl perftools::gputools::Stream::ThenRnnForward(class perftools::gputools::dnn::RnnDescriptor const &,class perftools::gputools::dnn::RnnSequenceTensorDescriptor const &,class perftools::gputools::DeviceMemory<double> const &,class perftools::gputools::dnn::RnnStateTensorDescriptor const &,class perftools::gputools::DeviceMemory<double> const &,class perftools::gputools::dnn::RnnStateTensorDescriptor const &,class perftools::gputools::DeviceMemory<double> const &,class perftools::gputools::DeviceMemory<double> const &,class perftools::gputools::dnn::RnnSequenceTensorDescriptor const &,class perftools::gputools::DeviceMemory<double> *,class perftools::gputools::dnn::RnnStateTensorDescriptor const &,class perftools::gputools::DeviceMemory<double> *,class perftools::gputools::dnn::RnnStateTensorDescriptor const &,class perftools::gputools::DeviceMemory<double> *,bool,class perftools::gputools::ScratchAllocator *,class perftools::gputools::ScratchAllocator *)\" (?ThenRnnForward@Stream@gputools@perftools@@QEAAAEAV123@AEBVRnnDescriptor@dnn@23@AEBVRnnSequenceTensorDescriptor@523@AEBV?$DeviceMemory@N@23@AEBVRnnStateTensorDescriptor@523@23221PEAV723@3434_NPEAVScratchAllocator@23@6@Z)\r\n1>tf_core_kernels.lib(cudnn_rnn_ops.cc.obj) : error LNK2001: unresolved external symbol \"public: class perftools::gputools::Stream & __cdecl perftools::gputools::Stream::ThenRnnBackward(class perftools::gputools::dnn::RnnDescriptor const &,class perftools::gputools::dnn::RnnSequenceTensorDescriptor const &,class perftools::gputools::DeviceMemory<float> const &,class perftools::gputools::dnn::RnnStateTensorDescriptor const &,class perftools::gputools::DeviceMemory<float> const &,class perftools::gputools::dnn::RnnStateTensorDescriptor const &,class perftools::gputools::DeviceMemory<float> const &,class perftools::gputools::DeviceMemory<float> const &,class perftools::gputools::dnn::RnnSequenceTensorDescriptor const &,class perftools::gputools::DeviceMemory<float> const &,class perftools::gputools::dnn::RnnStateTensorDescriptor const &,class perftools::gputools::DeviceMemory<float> const &,class perftools::gputools::dnn::RnnStateTensorDescriptor const &,class perftools::gputools::DeviceMemory<float> const &,class perftools::gputools::DeviceMemory<float> const &,class perftools::gputools::DeviceMemory<float> const &,class perftools::gputools::DeviceMemory<float> const &,class perftools::gputools::DeviceMemory<float> *,class perftools::gputools::DeviceMemory<float> *,class perftools::gputools::DeviceMemory<float> *,class perftools::gputools::DeviceMemory<float> *,class perftools::gputools::DeviceMemory<unsigned char> *,class perftools::gputools::ScratchAllocator *)\" (?ThenRnnBackward@Stream@gputools@perftools@@QEAAAEAV123@AEBVRnnDescriptor@dnn@23@AEBVRnnSequenceTensorDescriptor@523@AEBV?$DeviceMemory@M@23@AEBVRnnStateTensorDescriptor@523@2322123232222PEAV723@444PEAV?$DeviceMemory@E@23@PEAVScratchAllocator@23@@Z)\r\n1>tf_core_kernels.lib(cudnn_rnn_ops.cc.obj) : error LNK2001: unresolved external symbol \"public: class perftools::gputools::Stream & __cdecl perftools::gputools::Stream::ThenRnnBackward(class perftools::gputools::dnn::RnnDescriptor const &,class perftools::gputools::dnn::RnnSequenceTensorDescriptor const &,class perftools::gputools::DeviceMemory<double> const &,class perftools::gputools::dnn::RnnStateTensorDescriptor const &,class perftools::gputools::DeviceMemory<double> const &,class perftools::gputools::dnn::RnnStateTensorDescriptor const &,class perftools::gputools::DeviceMemory<double> const &,class perftools::gputools::DeviceMemory<double> const &,class perftools::gputools::dnn::RnnSequenceTensorDescriptor const &,class perftools::gputools::DeviceMemory<double> const &,class perftools::gputools::dnn::RnnStateTensorDescriptor const &,class perftools::gputools::DeviceMemory<double> const &,class perftools::gputools::dnn::RnnStateTensorDescriptor const &,class perftools::gputools::DeviceMemory<double> const &,class perftools::gputools::DeviceMemory<double> const &,class perftools::gputools::DeviceMemory<double> const &,class perftools::gputools::DeviceMemory<double> const &,class perftools::gputools::DeviceMemory<double> *,class perftools::gputools::DeviceMemory<double> *,class perftools::gputools::DeviceMemory<double> *,class perftools::gputools::DeviceMemory<double> *,class perftools::gputools::DeviceMemory<unsigned char> *,class perftools::gputools::ScratchAllocator *)\" (?ThenRnnBackward@Stream@gputools@perftools@@QEAAAEAV123@AEBVRnnDescriptor@dnn@23@AEBVRnnSequenceTensorDescriptor@523@AEBV?$DeviceMemory@N@23@AEBVRnnStateTensorDescriptor@523@2322123232222PEAV723@444PEAV?$DeviceMemory@E@23@PEAVScratchAllocator@23@@Z)\r\n1>tf_core_kernels.lib(cudnn_rnn_ops.cc.obj) : error LNK2001: unresolved external symbol \"public: class perftools::gputools::port::StatusOr<class std::unique_ptr<class perftools::gputools::dnn::RnnDescriptor,struct std::default_delete<class perftools::gputools::dnn::RnnDescriptor> > > __cdecl perftools::gputools::StreamExecutor::createRnnDescriptor(int,int,int,enum perftools::gputools::dnn::RnnInputMode,enum perftools::gputools::dnn::RnnDirectionMode,enum perftools::gputools::dnn::RnnMode,enum perftools::gputools::dnn::DataType,float,unsigned __int64,class perftools::gputools::ScratchAllocator *)\" (?createRnnDescriptor@StreamExecutor@gputools@perftools@@QEAA?AV?$StatusOr@V?$unique_ptr@VRnnDescriptor@dnn@gputools@perftools@@U?$default_delete@VRnnDescriptor@dnn@gputools@perftools@@@std@@@std@@@port@23@HHHW4RnnInputMode@dnn@23@W4RnnDirectionMode@723@W4RnnMode@723@W4DataType@723@M_KPEAVScratchAllocator@23@@Z)\r\n1>tf_core_kernels.lib(cudnn_rnn_ops.cc.obj) : error LNK2001: unresolved external symbol \"public: class perftools::gputools::port::StatusOr<class std::unique_ptr<class perftools::gputools::dnn::RnnSequenceTensorDescriptor,struct std::default_delete<class perftools::gputools::dnn::RnnSequenceTensorDescriptor> > > __cdecl perftools::gputools::StreamExecutor::createRnnSequenceTensorDescriptor(int,int,int,enum perftools::gputools::dnn::DataType)\" (?createRnnSequenceTensorDescriptor@StreamExecutor@gputools@perftools@@QEAA?AV?$StatusOr@V?$unique_ptr@VRnnSequenceTensorDescriptor@dnn@gputools@perftools@@U?$default_delete@VRnnSequenceTensorDescriptor@dnn@gputools@perftools@@@std@@@std@@@port@23@HHHW4DataType@dnn@23@@Z)\r\n1>tf_core_kernels.lib(cudnn_rnn_ops.cc.obj) : error LNK2001: unresolved external symbol \"public: class perftools::gputools::port::StatusOr<class std::unique_ptr<class perftools::gputools::dnn::RnnStateTensorDescriptor,struct std::default_delete<class perftools::gputools::dnn::RnnStateTensorDescriptor> > > __cdecl perftools::gputools::StreamExecutor::createRnnStateTensorDescriptor(int,int,int,enum perftools::gputools::dnn::DataType)\" (?createRnnStateTensorDescriptor@StreamExecutor@gputools@perftools@@QEAA?AV?$StatusOr@V?$unique_ptr@VRnnStateTensorDescriptor@dnn@gputools@perftools@@U?$default_delete@VRnnStateTensorDescriptor@dnn@gputools@perftools@@@std@@@std@@@port@23@HHHW4DataType@dnn@23@@Z)\r\n1>tf_core_gpu_kernels.lib(tf_core_gpu_kernels_generated_avgpooling_op_gpu.cu.cc.obj) : error LNK2001: unresolved external symbol cudaMemcpyAsync\r\n1>tf_core_gpu_kernels.lib(tf_core_gpu_kernels_generated_argmax_op_gpu.cu.cc.obj) : error LNK2001: unresolved external symbol cudaMemcpyAsync\r\n1>tf_core_gpu_kernels.lib(tf_core_gpu_kernels_generated_adjust_contrast_op_gpu.cu.cc.obj) : error LNK2001: unresolved external symbol cudaMemcpyAsync\r\n1>tf_core_gpu_kernels.lib(tf_core_gpu_kernels_generated_concat_lib_gpu_impl.cu.cc.obj) : error LNK2001: unresolved external symbol cudaMemcpyAsync\r\n```\r\n\r\nMy system:\r\nWindows 10\r\nCuda 8.0\r\nCudnn 6\r\ncmake cmake-3.9.4-win64-x64\r\nPython 3.5.2\r\nVS2015", "comments": ["@cuevas1208  Does the advice in #13448 help?", "I pretty much added all the .lib from tensorflow and cuda. It works now if anyone has a better way let me know.\r\n\r\nThank you "]}, {"number": 15012, "title": "Fix dataset tests broken on HEAD", "body": "@gunan PTAL", "comments": []}, {"number": 15011, "title": "Fix export_test failure as test wasn't updated", "body": "@gunan PTAL", "comments": []}, {"number": 15010, "title": "feeding_functions._GeneratorFeedFn does not return correct num of batches", "body": "feeding_functions._GeneratorFeedFn does not return correct #samples in mini batch. It actually returns mini batches with batch_size/key_size (key size is the length of dict yielded by the generator func). \r\n```python\r\ngff = feeding_functions._GeneratorFeedFn(\r\n    placeholders=placeholders,\r\n    generator=generator_fn, # yields { 'feature_set_1': [] (shape 1x13), 'feature_set_2': [] (shape 1x20) }\r\n    batch_size=32,\r\n    random_start=False,\r\n    seed=None,\r\n    num_epochs=1,\r\n    pad_value=None\r\n)\r\nactual = gff()\r\nfor k in actual:\r\n    print(actual[k].shape)\r\n# (16, 1, 13)\r\n# (16, 1, 20)\r\n```\r\nhttps://github.com/tensorflow/tensorflow/blob/r1.4/tensorflow/python/estimator/inputs/queues/feeding_functions.py\r\n`list_dict_size` compared with `self._batch_size` in `_GeneratorFeedFn.__call__`\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes, snippet above\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac OS X 10.13.1\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.4.0\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: Code snippet above", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue? Please update the label and/or status accordingly.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue? Please update the label and/or status accordingly.", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "This is still an issue.", "The original poster has replied to this issue after the stat:awaiting response label was applied.", "We're trying to deprecate the queues. Could you try the `contrib.data` API instead?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 15009, "title": "Train and release quantized models for other input sizes of mobilenet", "body": "Trying to run /tensorflow/examples/image_retraining/retrain.py, getting the following error: \r\n\r\n```\r\n  File \"/home/burjanviktor/DeepLearning/dog_breed/retraining.py\", line 1032, in main\r\n    maybe_download_and_extract(model_info['data_url'])\r\n  File \"/home/burjanviktor/DeepLearning/dog_breed/retraining.py\", line 344, in maybe_download_and_extract\r\n    filepath, _ = urllib.request.urlretrieve(data_url, filepath, _progress)\r\n... \r\n  File \"/home/burjanviktor/anaconda3/lib/python3.6/urllib/request.py\", line 650, in http_error_default\r\n    raise HTTPError(req.full_url, code, msg, hdrs, fp)\r\nurllib.error.HTTPError: HTTP Error 403: Forbidden\r\n```\r\n\r\nI am trying to use MobileNet for retraining, but the following url: \r\n\r\n'http://download.tensorflow.org/models/mobilenet_v1_1.0_160_quantized_frozen.tgz'\r\n\r\ngives the following error: \r\n\r\n```\r\n<Error>\r\n<Code>AccessDenied</Code>\r\n<Message>Access denied.</Message>\r\n<Details>Anonymous users does not have storage.objects.get access to download.tensorflow.org/models/mobilenet_v1_1.0_160_quantized_frozen.tgz.</Details>\r\n</Error>\r\n```\r\n\r\nThe 1.0_220 version works, but 1.0_190 does not work also.\r\n\r\nCould you advise on this issue please? ", "comments": ["It looks like the only quantized model we have available is this one:\r\nhttp://download.tensorflow.org/models/mobilenet_v1_1.0_224_quantized_frozen.tgz\r\n\r\nNon-quantized models are available for all other sizes (as described in `retrain.py`).  E.g. the non-quantized version of 1.0_160 is available:\r\nhttp://download.tensorflow.org/models/mobilenet_v1_1.0_160_frozen.tgz\r\n\r\nThis corresponds to the following argument to `retrain.py`:\r\n```\r\n--architecture mobilenet_1.0_160\r\n```\r\n\r\n@suharshs might have more details on whether we plan to make more quantized models available.", "Thanks Todd. We currently only have size 224 image mobilenet quantized model available. We haven't yet prioritized getting trained quantized models for the other inputs sizes. I'll rename this issue as a feature request to help us prioritized training the other models, thanks!", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "Hi @suharshs .  Are there any new quantized models available / in the works?  Perhaps some of the tiny 0.25 models ;).  Thanks!", "In the works :) Will keep you posted!", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "We should have updated models available next week.\r\nThanks!", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Hi, we have published the new quantized models at https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v1.md\r\n\r\nThanks!", "I have pushed changes to the retrain.py script to support these, once the next sync happens.\r\n\r\nCommands like\r\n```\r\npython tensorflow/examples/image_retraining/retrain.py \\\r\n    --image_dir ~/flower_photos/   --architecture mobilenet_1.0_224_quant\r\n```\r\nshould work for all depth multipliers and image sizes.\r\n\r\nPlease create a new issue if things don't work once github pulls in the changes to retrain.py", "Is this correct way to re-train quantized mobilenet? I mean use re-train.py?", "Yes.  Retrain.py architecture switch supports the quant models, as it is described above.  Just make sure you are using a somewhat recent version of TensorFlow with a recent version of the retrain.py script."]}, {"number": 15008, "title": "Document iOS demo app in TF Lite Readme", "body": "See the rendered markdown here: https://github.com/miaout17/tensorflow/blob/ios-example-readme/tensorflow/contrib/lite/README.md#ios-demo-app\r\n\r\nI think the demo app is already well-explained for the Android, so it just require a few lines to describe how to build the iOS version. ", "comments": ["Can one of the admins verify this patch?", "@Sarahs1 FYI\r\n"]}, {"number": 15007, "title": "Change bazel-mirror to mirror.bazel", "body": "", "comments": []}]