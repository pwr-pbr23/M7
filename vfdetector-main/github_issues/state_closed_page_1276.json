[{"number": 14852, "title": "tensorflow lite build for iOS", "body": "error \uff1a./download_dependencies.sh: line 50: 1: Usage: download_and_extract URL DIR\r\nhow to do it\uff1f", "comments": ["Please fill and read [ISSUE_TEMPLATE](https://github.com/tensorflow/tensorflow/blob/master/ISSUE_TEMPLATE.md) before raising an issue.", "do you have the newest version? [this](https://github.com/tensorflow/tensorflow/pull/14734) addresses some issues with download_dependencies", "I just tried it - the script fails when being outside of the root folder of tensorflow... when I cd into tensorflow - it all works out", "Closing for now. Making a more user friendly error message here #14949.\r\n\r\n-A\r\n"]}, {"number": 14851, "title": "Got NAN when calling embedding_lookup_sparse with weights and \"mean\" combiner", "body": "### System information\r\n- **OS Platform and Distribution**: Win7 64bit\r\n- **TensorFlow installed from**: anaconda binary\r\n- **TensorFlow version**: 1.2.1\r\n- **Python version**: 3.6\r\n\r\n### Describe the problem\r\nI always got nan when I call embedding_lookup_sparse with weights and \"mean\" combiner.\r\nCode pieces are listed below:\r\n\r\n### Source code / logs\r\nfrom __future__ import absolute_import\r\nfrom __future__ import print_function\r\nimport os\r\nimport numpy as np\r\nimport tensorflow as tf\r\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\r\n\r\na = np.arange(192).reshape(24, 8)\r\nprint(a)\r\n\r\na = tf.Variable(a, dtype=tf.float32)\r\nids = tf.SparseTensor(\r\n    indices=[[1, 0], [2, 0], [2, 1], [2, 2], [3, 0], [9, 1]],\r\n    values=[10, 1, 2, 3, 4, 5],\r\n    dense_shape=[1, 1])\r\nweights = tf.SparseTensor(\r\n    indices=[[1, 0], [2, 0], [2, 1], [2, 2], [3, 0], [9, 1]],\r\n    values=[1, 0.2, 0.4, 0.4, 1, 1],\r\n    dense_shape=[1, 1])\r\nb = tf.nn.embedding_lookup_sparse(\r\n    a, ids, weights, partition_strategy='mod', combiner='sum')\r\nc = tf.pad(b, [[0, 16 - tf.shape(b)[0]], [0, 0]], mode='CONSTANT')\r\n\r\nsess = tf.Session()\r\nsess.run(tf.global_variables_initializer())\r\n[value] = sess.run([c])\r\nprint(value)\r\n", "comments": ["`[\r\n[  0.           0.           0.           0.           0.           0.\r\n    0.           0.        ]\r\n [ 80.          81.          82.          83.          84.          85.\r\n   86.          87.        ]\r\n [ 17.60000038  18.60000038  19.60000229  20.60000038  21.59999847\r\n   22.60000229  23.60000038  24.60000038]\r\n [ 32.          33.          34.          35.          36.          37.\r\n   38.          39.        ]\r\n [  0.           0.           0.           0.           0.           0.\r\n    0.           0.        ]\r\n [  0.           0.           0.           0.           0.           0.\r\n    0.           0.        ]\r\n [  0.           0.           0.           0.           0.           0.\r\n    0.           0.        ]\r\n [  0.           0.           0.           0.           0.           0.\r\n    0.           0.        ]\r\n [  0.           0.           0.           0.           0.           0.\r\n    0.           0.        ]\r\n [ 40.          41.          42.          43.          44.          45.\r\n   46.          47.        ]\r\n [  0.           0.           0.           0.           0.           0.\r\n    0.           0.        ]\r\n [  0.           0.           0.           0.           0.           0.\r\n    0.           0.        ]\r\n [  0.           0.           0.           0.           0.           0.\r\n    0.           0.        ]\r\n [  0.           0.           0.           0.           0.           0.\r\n    0.           0.        ]\r\n [  0.           0.           0.           0.           0.           0.\r\n    0.           0.        ]\r\n [  0.           0.           0.           0.           0.           0.\r\n    0.           0.        ]\r\n]`\r\n\r\nIs above output correct?", "sorry, use combiner=\"mean\", and retry.", "I think `np.nan` is reasonable, because some lines, say 0, 4, 5, 6, 7, 8, are missing in\r\n` indices=[[1, 0], [2, 0], [2, 1], [2, 2], [3, 0], [9, 1]],`. For those lines, value is 0, and sum is 0, so `0 / 0 = np.nan`. In all, for missing line, `sum` is zeros, and `mean` and `sqrtn` are `np.nan`.\r\n\r\nHowever, I understand that `np.nan` might be an unexpected result, perhaps zeros is better, right? If yes, this is a feature request.", "```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\na = np.arange(192).reshape(24, 8)\r\nprint(a)\r\n\r\na = tf.Variable(a, dtype=tf.float32)\r\nids = tf.SparseTensor(\r\nindices=[[1, 0], [2, 0], [2, 1], [2, 2], [3, 0], [9, 1]],\r\nvalues=[10, 1, 2, 3, 4, 5],\r\ndense_shape=[1, 1])\r\nweights = tf.SparseTensor(\r\nindices=[[1, 0], [2, 0], [2, 1], [2, 2], [3, 0], [9, 1]],\r\nvalues=[1, 0.2, 0.4, 0.4, 1, 1],\r\ndense_shape=[1, 1])\r\nb = tf.nn.embedding_lookup_sparse(\r\na, ids, weights, partition_strategy='mod', combiner='mean')\r\n\r\nsess = tf.Session()\r\nsess.run(tf.global_variables_initializer())\r\n[value] = sess.run([b])\r\n\r\nnp.set_printoptions(precision=2)\r\nprint(value)\r\nprint(value.shape)\r\n```\r\n\r\n```bash\r\n[[  nan   nan   nan   nan   nan   nan   nan   nan]\r\n [ 80.   81.   82.   83.   84.   85.   86.   87. ]\r\n [ 17.6  18.6  19.6  20.6  21.6  22.6  23.6  24.6]\r\n [ 32.   33.   34.   35.   36.   37.   38.   39. ]\r\n [  nan   nan   nan   nan   nan   nan   nan   nan]\r\n [  nan   nan   nan   nan   nan   nan   nan   nan]\r\n [  nan   nan   nan   nan   nan   nan   nan   nan]\r\n [  nan   nan   nan   nan   nan   nan   nan   nan]\r\n [  nan   nan   nan   nan   nan   nan   nan   nan]\r\n [ 40.   41.   42.   43.   44.   45.   46.   47. ]]\r\n(10, 8)\r\n```", "facaiy, exactly right.\r\n\r\nas its name \"sparse\", missing values are common cases.\r\n\r\nhow can nan be spread everywhere?", "`tf.where` can help you clean all `np.nan`:\r\n```python\r\na, ids, weights, partition_strategy='mod', combiner='mean')\r\n# clean np.nan\r\nb = tf.where(tf.is_nan(b), tf.zeros_like(b), b)\r\nc = tf.pad(b, [[0, 16 - tf.shape(b)[0]], [0, 0]], mode='CONSTANT')\r\n```", "@facaiy    thanks.\r\n\r\ntf.where is not an elegant way, but better than nothing.", "@facaiy Please update this bug when your PR #14865 lands.  And thanks for your help and PRs!  :)", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue? Please update the label and/or status accordingly.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue? Please update the label and/or status accordingly.", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "You seem to be using older version(1.x) of Tensorflow which is not supported anymore. Please try the latest [Tensorflow version](https://www.tensorflow.org/install/pip) and let us know if the problem still persists.\r\nCheck the `[tf.nn.embedding_lookup_sparse](https://www.tensorflow.org/api_docs/python/tf/nn/embedding_lookup_sparse)` in Tensorflow 2 version for the changes. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 14850, "title": "Tensorflow v1.4.0 rpc crash", "body": "I built tensorflow v1.4.0 from source code, sometimes it crashed inside kernel. This happened on both Linux and Windows platform.\r\n\r\nLinux call stack:\r\n```\r\nC  [_pywrap_tensorflow_internal.so+0x1117eef]  cc_destroy_call_elem+0xdf\r\nC  [_pywrap_tensorflow_internal.so+0x1138c77]  grpc_call_stack_destroy+0x57\r\nC  [_pywrap_tensorflow_internal.so+0x114b2fc]  grpc_exec_ctx_flush+0x5c\r\nC  [_pywrap_tensorflow_internal.so+0x115d8ad]  grpc_call_unref+0xed\r\nC  [_pywrap_tensorflow_internal.so+0x10fa9ae]  grpc::ClientContext::~ClientContext()+0x1e\r\nC  [_pywrap_tensorflow_internal.so+0x1027e07]  tensorflow::GrpcRemoteWorker::RPCState<tensorflow::TensorResponse>::~RPCState()+0x197\r\nC  [_pywrap_tensorflow_internal.so+0x103180e]  tensorflow::GrpcRemoteWorker::RPCState<tensorflow::TensorResponse>::OnCompleted(bool)+0x29e\r\n```\r\n\r\nWindows call stack:\r\n```\r\n00 00000042`801ef5c0 00007ffa`737e3c67 ucrtbase!abort+0x4e [d:\\rs1\\minkernel\\crts\\ucrt\\src\\appcrt\\startup\\abort.cpp @ 77]\r\n01 00000042`801ef5f0 00007ffa`737a96d8 _pywrap_tensorflow_internal!tensorflow::Allocator::AllocatedSize+0x227d7\r\n02 00000042`801ef630 00007ffa`737ba61f _pywrap_tensorflow_internal!tensorflow::lookup::SubtleMustCopyUnlessStringOrFloat<__int64>+0x10ee8\r\n03 00000042`801ef660 00007ffa`737cc5ac _pywrap_tensorflow_internal!tensorflow::lookup::SubtleMustCopyUnlessStringOrFloat<__int64>+0x21e2f\r\n04 00000042`801ef6a0 00007ffa`737a4eb7 _pywrap_tensorflow_internal!tensorflow::Allocator::AllocatedSize+0xb11c\r\n05 00000042`801ef6d0 00007ffa`7379111e _pywrap_tensorflow_internal!tensorflow::lookup::SubtleMustCopyUnlessStringOrFloat<__int64>+0xc6c7\r\n06 00000042`801ef740 00007ffa`737964ca _pywrap_tensorflow_internal!std::vector<std::unique_ptr<tensorflow::NodeDef,std::default_delete<tensorflow::NodeDef> >,std::allocator<std::unique_ptr<tensorflow::NodeDef,std::default_delete<tensorflow::NodeDef> > > >::~vector<std::unique_ptr<tensorflow::NodeDef,std::default_delete<tensorflow::NodeDef> >,std::allocator<std::unique_ptr<tensorflow::NodeDef,std::default_delete<tensorflow::NodeDef> > > >+0x1244e\r\n07 00000042`801ef790 00007ffa`73785fb2 _pywrap_tensorflow_internal!std::vector<std::unique_ptr<tensorflow::NodeDef,std::default_delete<tensorflow::NodeDef> >,std::allocator<std::unique_ptr<tensorflow::NodeDef,std::default_delete<tensorflow::NodeDef> > > >::~vector<std::unique_ptr<tensorflow::NodeDef,std::default_delete<tensorflow::NodeDef> >,std::allocator<std::unique_ptr<tensorflow::NodeDef,std::default_delete<tensorflow::NodeDef> > > >+0x177fa\r\n08 00000042`801ef810 00007ffa`72077041 _pywrap_tensorflow_internal!std::vector<std::unique_ptr<tensorflow::NodeDef,std::default_delete<tensorflow::NodeDef> >,std::allocator<std::unique_ptr<tensorflow::NodeDef,std::default_delete<tensorflow::NodeDef> > > >::~vector<std::unique_ptr<tensorflow::NodeDef,std::default_delete<tensorflow::NodeDef> >,std::allocator<std::unique_ptr<tensorflow::NodeDef,std::default_delete<tensorflow::NodeDef> > > >+0x72e2\r\n09 00000042`801ef860 00007ffa`720778b4 _pywrap_tensorflow_internal!tensorflow::GrpcRemoteWorker::RPCState<google::protobuf::Message>::~RPCState<google::protobuf::Message>+0xf1\r\n0a 00000042`801ef8a0 00007ffa`72078803 _pywrap_tensorflow_internal!tensorflow::WorkerInterface::~WorkerInterface+0x574\r\n0b 00000042`801ef8d0 00007ffa`72082cf0 _pywrap_tensorflow_internal!tensorflow::GrpcRemoteWorker::RPCState<google::protobuf::Message>::OnCompleted+0x283\r\n0c 00000042`801efa10 00007ffa`71b8ae25 _pywrap_tensorflow_internal!tensorflow::WorkerCachePartial::~WorkerCachePartial+0xf0\r\n```\r\nBoth indicating that tensorflow rpc framework may have some bug.", "comments": ["Please provide reproduction instructions. It is unclear what you are running.", "@aselle i also have the same question\r\ni run dist. Estimator using `train_and_eval()` API on Tensorlfow 1.4.0, 90ps 90worker \r\nsometime ps node coredump, sometimes worker node coredumo\r\nbut, they core in the same callback, as below:\r\n```\r\n#0  0x000000000000002e in ?? ()\r\n#1  0x00007fb9cfc5bf19 in cc_destroy_call_elem () from /usr/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#2  0x00007fb9cfc7da77 in grpc_call_stack_destroy () from /usr/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#3  0x00007fb9cfc9016f in grpc_exec_ctx_flush () from /usr/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#4  0x00007fb9cfca2aad in grpc_call_unref () from /usr/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#5  0x00007fb9cfc3c8ee in grpc::ClientContext::~ClientContext() () from /usr/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#6  0x00007fb9cfb67b79 in tensorflow::GrpcRemoteWorker::RPCState<tensorflow::TensorResponse>::~RPCState() () from /usr/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#7  0x00007fb9cfb6d698 in tensorflow::GrpcRemoteWorker::RPCState<tensorflow::TensorResponse>::OnCompleted(bool) () from /usr/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#8  0x00007fb9cfb6334e in std::_Function_handler<void (), tensorflow::(anonymous namespace)::GrpcWorkerCache::GrpcWorkerCache(tensorflow::GrpcChannelCache*, tensorflow::WorkerInterface*, std::string const&)::{lambda()#1}>::_M_invoke(std::_Any_data const&) () from /usr/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#9  0x00007fb9cdcaf220 in ?? () from /lib64/libstdc++.so.6\r\n#10 0x00007fba7eea0dc5 in start_thread () from /lib64/libpthread.so.0\r\n#11 0x00007fba7e4c4ced in clone () from /lib64/libc.so.6\r\n```", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue? Please update the label and/or status accordingly.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue? Please update the label and/or status accordingly.", "I'm also seeing this issue for 40 ps 400 workers with the same call stack mentioned by @fesun. Following the call stack:\r\nhttps://github.com/tensorflow/tensorflow/blob/cddf8d82dec9fff526f5c064add725b7f35f95fa/tensorflow/core/distributed_runtime/rpc/grpc_worker_cache.cc#L47\r\nhttps://github.com/tensorflow/tensorflow/blob/cddf8d82dec9fff526f5c064add725b7f35f95fa/tensorflow/core/distributed_runtime/rpc/grpc_remote_worker.cc#L278\r\n\r\nEventually it ends up in GRPC code [cc_destroy_call_elem](https://github.com/grpc/grpc/blob/31e99d0788f99189008f854265b1582a6ae888c5/src/core/ext/filters/client_channel/client_channel.cc#L1444)\r\nEither GRPC has issue destroying call element properly or TensorFlow 1.4.0 does not use GRPC properly (in particular not handling GRPC error/exception properly in this case)\r\n", "@mrry Is there any chance for you to take a look?", "TensorFlow 1.4.0 used a version of gRPC with some known bugs. TensorFlow 1.5 uses an upgraded version of gRPC, which may have fixed this problem. If you can reproduce the problem with TensorFlow 1.5, and share code for reproducing the problem, someone on the team can take a look.", "Thanks @mrry , I will try version 1.5. By the way, does current implementation have any retry logic for network communication? For example the connection between worker and server is somehow closed abnormally, will worker reconnect to server without throwing any user aware exceptions? It should be able to do this as long as the server is still alive, right?", "The original poster has replied to this issue after the stat:awaiting response label was applied.", "> By the way, does current implementation have any retry logic for network communication?\r\n\r\nYes, we use gRPC in \"non-fail-fast\" (or [\"wait-for-ready\"](https://github.com/grpc/grpc/blob/master/doc/wait-for-ready.md)) mode, which means that RPCs sent while in a transient failure state will be retried.", "@fesun are you still seeing the issue with the latest code?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Closing this issue due to lack of response. If this is still a problem with TensorFlow 1.5 or later, please feel free to reopen the bug."]}, {"number": 14849, "title": "TFLite: Add unsupported op Equal and ExpandDims", "body": "", "comments": ["Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->", "Can one of the admins verify this patch?", "I signed it!", "u need to pass cla ~ i was there, now i passed , just follow me:\r\n#14867"]}, {"number": 14848, "title": "HistogramSummary  not support fp16 \uff1f", "body": "There is a issue when I train my model with adm optimizer (tf.train.AdamOptimizer),  It seems HistogramSummary not support DT_HALF.   \r\n\r\n2017-11-24 09:19:36.954820: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: Infinity in summary histogram for: local4/BatchNorm/beta_1\r\n         [[Node: local4/BatchNorm/beta_1 = HistogramSummary[T=DT_HALF, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](local4/BatchNorm/beta_1/tag, local4/BatchNorm/beta/read/_171)]]\r\n\r\n\r\nBut if i use the other optimizer such as GradientDescentOptimizer or RMSPropOptimizer\uff0c there is no the issue above.  I don't know why,  Is there anyone meet this error\r\n", "comments": ["Does it work fine if you use a 10th of the learning rate. It looks like you are hitting infinities in your optimization. That can happen if the optimization is at the edge of stability. Using reduced precision makes numerics less stable. ", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue? Please update the label and/or status accordingly.", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 14847, "title": "Add label_wav_dir.py", "body": "Predicts all wave files in a directory.\r\n\r\n```\r\npython tensorflow/examples/speech_commands/label_wav_dir.py \\\r\n --graph=/tmp/my_frozen_graph.pb \\\r\n --labels=/tmp/speech_commands_train/conv_labels.txt \\\r\n --wav_dir=/tmp/speech_dataset/left\r\n```\r\n\r\n> 93ec8b84_nohash_0.wav\r\n> no (score = 0.10860)\r\n> go (score = 0.09965)\r\n> on (score = 0.09433)\r\n> \r\n> a7545b9f_nohash_1.wav\r\n> off (score = 0.10953)\r\n> right (score = 0.10349)\r\n> _unknown_ (score = 0.10015)\r\n> \r\n> 6272b231_nohash_1.wav\r\n> right (score = 0.10766)\r\n> yes (score = 0.10450)\r\n> left (score = 0.09779)\r\n> \r\n> 439c84f4_nohash_1.wav\r\n> no (score = 0.11556)\r\n> right (score = 0.10160)\r\n> go (score = 0.09805)\r\n> \r\n> 2f813234_nohash_1.wav\r\n> no (score = 0.12223)\r\n> go (score = 0.11225)\r\n> on (score = 0.10878)", "comments": ["Can one of the admins verify this patch?", "@petewarden WDYT?"]}, {"number": 14846, "title": "Branch 176796142", "body": "", "comments": []}, {"number": 14845, "title": "No gradient defined for op: Select", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10 x64\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.4\r\n- **Python version**: None\r\n- **CUDA/cuDNN version**: None\r\n- **GPU model and memory**: None\r\n- **Exact command to reproduce**: -\r\n\r\n### Describe the problem\r\nIt seems there is no gradient defined for the Select operation in the C++ API.\r\n\r\nI am actually getting this issue while using the C++ API through the C# bindings provided by the TensorFlowSharp project, and for this reason I didn't fill the \"exact command to reproduce\" field above. However, seeing that [```@ops.RegisterGradient(\"Select\")``` is placed in math.grad.py](https://github.com/tensorflow/tensorflow/blob/27767d8e9c1325979cf32ff5b81c10df9006fd57/tensorflow/python/ops/math_grad.py#L919), and given that there is no analogous ```REGISTER_GRADIENT_OP(\"Select\", SelectGrad)``` instruction in [math_grad.cc](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/cc/gradients/math_grad.cc), tells me that the gradient for the ```Select``` op is indeed still missing from the C++ API.\r\n\r\nHope its not a false alarm given that I didn't test libtensorflow.dll directly.\r\n\r\n\r\n", "comments": ["@cesarsouza Hi, I open a PR #14862 to add SelectGrad op.", "Thanks @facaiy!  Please update this bug when your PR #14862 lands.", "Is the problem fixed?\r\nI see that there's a pr but I'm still getting this error with TensorFlowSharp 1.7.0 (which supports TensorFlow 1.7.0).", "@gundamMC SelectGrad has been merged into master branch. Could you give a reproducible example?", "@facaiy Yep,\r\nhttps://github.com/gundamMC/Neural-Network-GUI-Demo/blob/master/NeuralNetwork/Network.cs\r\nYou can pretty much ignore everything else in the repo as all the TensorFlowSharp stuff is in Network.cs.", "Thank you, @gundamMC . Sorry that I don't know TensorFlowSharp (and .Net environment), could you report the issue to TensorFlowSharp, or give an example in native tensorflow code? "]}, {"number": 14844, "title": "Revert \"Only install enum34 on Python <3.4 versions\"", "body": "Reverts tensorflow/tensorflow#14730 to address #14779", "comments": []}, {"number": 14843, "title": "Fix crash on closing the app when classifier failed to initialize", "body": "When testing on an API 21 emulator, the classifier fails to initialize.\r\n`E/TfLiteCameraDemo: Failed to initialize an image classifier.`\r\n\r\nIn this situation, the app crashes when pressing Back to exit.  Here's the cause:\r\n```\r\njava.lang.NullPointerException: Attempt to invoke virtual method 'void com.example.android.tflitecamerademo.ImageClassifier.close()' on a null object reference\r\n                                                                                        at com.example.android.tflitecamerademo.Camera2BasicFragment.onDestroy(Camera2BasicFragment.java:331)\r\n                                                                                        at android.app.Fragment.performDestroy(Fragment.java:2266)\r\n```\r\nThe fix is to check for null before calling `.close()`.\r\n\r\nI'll investigate why the classifier is failing to initialize separately. :-)  FTR, the UI does report the error nicely:\r\n![screen shot 2017-11-23 at 12 58 23 pm](https://user-images.githubusercontent.com/739125/33185236-3e6cbb68-d04f-11e7-9deb-c1bf90a46e50.png)\r\n", "comments": ["Jenkins, test this please.", "Can one of the admins verify this patch?", "Failed to fetch repo again. Jenkins, test this please.", "@aselle WDYT?", "@aselle Request your input on this PR", "@aselle please can you review this one line crash fix?  It gives a better experience when using the demo app. :-)", "@aselle ping?", "Re-running tests, to get the error log.", "Can you please look at the failing tests and fix them ?", "It looks like the Jenkins links are dead, presumably because the artifacts have now been deleted.  Somebody will need to re-run the tests to capture the stack trace.\r\n\r\nI ran `./gradlew testDebugUnitTest` and `./gradlew connectedAndroidTest` for my branch and Gradle reported `BUILD SUCCESSFUL`.\r\n\r\nIf there is anything else I need to do (I didn't see anything in the README), then please let me know.", "Looks like something is wrong with the test as the artifacts are deleted.", "You might need to rebase, as we migrated out from tensorflow/contrib/lite to tensorflow/lite.", "Rebase done as requested.\r\n\r\nFTR, this pull request was already reviewed and approved, but the force push (for the rebase) auto dismissed the review.\r\n\r\nI tested launching the app in an emulator.  To be able to test, I needed to update the build.  I've opened https://github.com/tensorflow/tensorflow/pull/24255 to share the changes I needed to make.", "Nagging Reviewer @aselle, @jdduke: You have been added as a reviewer to this pull request. Please add your review or reassign. It has been 14 days with no activity and the `awaiting review` label has been applied."]}, {"number": 14842, "title": "Update .gitignore files for Android Studio", "body": "Without these, Git shows lots of noisy build/IDE config files.\r\n\r\nThese files are based on these two sources (plus the list of added files that Git shows when I build in Android Studio):\r\nhttps://github.com/github/gitignore/blob/master/Android.gitignore\r\nhttps://github.com/github/gitignore/pull/2103/files\r\n\r\nTested in Android Studio 3.0 Beta 2.", "comments": ["Can one of the admins verify this patch?", "@aselle is this necessary?", "@aselle Is this change necessary?", "Nagging Reviewer @aselle: It has been 41 days with no activity and the `awaiting review` label was assigned. Can you please take a look?", "Nagging Reviewer @aselle: It has been 14 days with no activity and the `awaiting review` label was assigned. Can you please take a look?", "aselle@ do you think these changes are necessary or should we close this PR?", "Nagging Reviewer @aselle: It has been 14 days with no activity and the `awaiting review` label was assigned. Can you please take a look?", "Nagging Reviewer @aselle: It has been 29 days with no activity and the `awaiting review` label was assigned. Can you please take a look?", "Nagging Reviewer @aselle: You have been added as a reviewer to this pull request. Please add your review or reassign. It has been 45 days with no activity and the `awaiting review` label has been applied.", "Nagging Reviewer @aselle: You have been added as a reviewer to this pull request. Please add your review or reassign. It has been 59 days with no activity and the `awaiting review` label has been applied."]}, {"number": 14841, "title": "Estimators cause Out of range warning on FIFOQueue and fail to run all training steps", "body": "### System information\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: 4.13.12-1-ARCH\r\n- **TensorFlow installed from (source or binary)**: Binary\r\n- **TensorFlow version (use command below)**: 1.4.0\r\n- **Python version**: 3.6.3\r\n- **CUDA/cuDNN version**: 9.0.176-4/7.0.3-1\r\n- **GPU model and memory**: 1080/1070\r\n\r\n### Describe the problem\r\nTrying to use estimators with a trivially small network fails to train for more than one step due to FIFOQueue closing with insufficient elements.\r\n\r\n### Source code / logs\r\nIn the following example I try to train a single neuron for 1000 steps at a time.  set_size changes the training set's size.  With set_size=1000 I would expect training to complete 1000 steps however only 8 steps are completed and an Out of range warning is printed.  Setting set_size to 10 leads to only a single step being completed, I would expect at least 10 steps to complete, possible all 1000 if the input_fn is called repeatedly to fill a queue(not sure what default behaviour is supposed to be).  Setting set_size=1000000 allows the entire 1k training steps to complete.\r\n\r\ncode:\r\n\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\nimport models\r\n\r\nset_size = 1000\r\n\r\nparams = {\"learning_rate\":0.00001}\r\n\r\ndef model_fn(features, labels, mode, params):\r\n    \"\"\"Build model for Estimator here\"\"\"\r\n    ####Build graph\r\n    input_layer = tf.reshape(features[\"x\"],[-1,1])\r\n    hidden_layer = tf.layers.dense(input_layer,1,activation=tf.nn.relu)\r\n    output_layer = hidden_layer\r\n    \r\n    ####Prediction mode\r\n    if mode == tf.estimator.ModeKeys.PREDICT:\r\n        predictions = {\"y\":output_layer}\r\n        return tf.estimator.EstimatorSpec(mode=mode,predictions=predictions)\r\n    \r\n    loss = tf.losses.mean_squared_error(labels,output_layer)\r\n    \r\n    ####Training mode\r\n    if mode == tf.estimator.ModeKeys.TRAIN:\r\n        optimizer = tf.train.GradientDescentOptimizer(learning_rate=params[\"learning_rate\"])\r\n        train_op = optimizer.minimize(loss=loss,global_step=tf.train.get_global_step())\r\n        return tf.estimator.EstimatorSpec(\r\n            mode=mode,\r\n            loss=loss,\r\n            train_op=train_op)\r\n    \r\n    ####Eval mode\r\n    elif mode == tf.estimator.ModeKeys.EVAL:\r\n        eval_metric_ops = {\"rmse\":tf.metrics.root_mean_squared_error(labels,output_layer)}\r\n        return tf.estimator.EstimatorSpec(\r\n            mode=mode,\r\n            loss=loss,\r\n            eval_metric_ops=eval_metric_ops)\r\n        \r\n\r\ninput_fn = tf.estimator.inputs.numpy_input_fn(\r\n    x={'x':np.array([[float(x)] for x in range(set_size)])},\r\n    y=np.array([[float(x*2)] for x in range(set_size)]),\r\n    shuffle=False\r\n)\r\n\r\n\r\ndef test():\r\n    nn = tf.estimator.Estimator(model_fn=model_fn, params=params)\r\n    for x in range(5):\r\n        print('START LOOP:',x)\r\n        a = nn.train(input_fn=input_fn,steps=1000)\r\n        print('--------')\r\n        b = nn.evaluate(input_fn=input_fn)\r\n        print(\"----STATS----\",b)\r\n    print('Done loop')\r\n    c = nn.predict(input_fn=input_fn)\r\n    #print('Predictions:',[x for x in c])\r\n\r\nif __name__ == \"__main__\":\r\n    test()\r\n```\r\nwarning:\r\n> 2017-11-23 11:23:52.370395: W tensorflow/core/framework/op_kernel.cc:1192] Out of range: FIFOQueue '_2_enqueue_input/fifo_queue' is closed and has insufficient elements (requested 128, current size 0)\r\n> \t [[Node: fifo_queue_DequeueUpTo = QueueDequeueUpToV2[component_types=[DT_INT64, DT_DOUBLE, DT_DOUBLE], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](enqueue_input/fifo_queue, fifo_queue_DequeueUpTo/n)]]\r\n\r\nEdit: This may be due to something in tf.estimator.inputs.numpy_input_fn as creating the input_fn manually does not cause the warning and early termination of training.", "comments": ["@ispirmustafa might have some ideas here.", "there is a `batch_size` parameter of `numpy_input_fn`. num steps you'll get will be `set_size/batch_size`."]}, {"number": 14840, "title": "Change path", "body": "change path ", "comments": ["Can one of the admins verify this patch?"]}, {"number": 14839, "title": "Typo fix", "body": "Typo fix : uniqified -> uniquified", "comments": ["Can one of the admins verify this patch?", "Closing as duplicate of #14840"]}, {"number": 14838, "title": "Typo fixing", "body": "typo fixed : libaries -> libraries", "comments": ["Can one of the admins verify this patch?", "Closing as duplicate of #14840"]}, {"number": 14837, "title": "Fix missing __sincos in XLA on macOS", "body": "Building XLA on macOS failed due to missing `__sincos` and `__sincosf`. \r\n\r\n```\r\ntensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:285:3: error: use of undeclared identifier 'sincosf'; did you mean '__sincosf'?\r\ntensorflow/compiler/xla/service/cpu/simple_orc_jit.cc:285:24: error: use of undeclared identifier 'sincos'; did you mean '__sincos'?\r\n```\r\n\r\nhttps://github.com/tensorflow/tensorflow/pull/14288 tried to fix the issue but still needs https://github.com/tensorflow/tensorflow/pull/14137 too.", "comments": ["Can one of the admins verify this patch?", "/CC @jlebar @learyg \r\n\r\n@sanjoy mind taking a look? Thanks", "This overlaps with https://github.com/tensorflow/tensorflow/pull/14893 -- I've started reviewing #14893 as the canonical fix.", "Closing this then, since it is obsolete. Please re-open if I misunderstood."]}, {"number": 14836, "title": "Update datasets.md", "body": "There is omission of tf.data in front of Iterator.from_structure(~). I found it, When I read and tested \r\n\r\nSo For some other people who read this article. I ask for pull request.  ", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "Closing as got fixed in https://github.com/tensorflow/tensorflow/pull/14941"]}, {"number": 14835, "title": "tensorflow_serving build error on Windows, bazel 0.7, tensorflow 1.4", "body": "C:\\serving>bazel build //tensorflow_serving/example:mnist_saved_model\r\nERROR: error loading package 'tensorflow_serving/example': Encountered error while reading extension file 'protobuf.bzl': no such package '@protobuf_archive//': Traceback (most recent call last):\r\nFile \"C:/users/akhil/appdata/local/temp/_bazel_akhil/-8r_kqmg/external/org_tensorflow/tensorflow/workspace.bzl\", line 119\r\n_apply_patch(repo_ctx, repo_ctx.attr.patch_file)\r\nFile \"C:/users/akhil/appdata/local/temp/_bazel_akhil/-8r_kqmg/external/org_tensorflow/tensorflow/workspace.bzl\", line 111, in _apply_patch\r\n_execute_and_check_ret_code(repo_ctx, cmd)\r\nFile \"C:/users/akhil/appdata/local/temp/_bazel_akhil/-8r_kqmg/external/org_tensorflow/tensorflow/workspace.bzl\", line 92, in _execute_and_check_ret_code\r\nfail(\"Non-zero return code({1}) when ...))\r\nNon-zero return code(127) when executing 'C:\\msys64\\usr\\bin\\bash.exe -l -c patch -p1 -d C:/users/akhil/appdata/local/temp/_bazel_akhil/-8r_kqmg/external/protobuf_archive -i C:/users/akhil/appdata/local/temp/_bazel_akhil/-8r_kqmg/external/org_tensorflow/third_party/protobuf/add_noinlines.patch':\r\nStdout:\r\nStderr: /usr/bin/bash: patch: command not found\r\n.\r\nINFO: Elapsed time: 42.062s", "comments": ["Bazel build command trying to download\r\nhttps://mirror.bazel.build/github.com/google/protobuf/archive/b04e5cba356212e4e8c66c61bbe0c3a20537c5\\b9.tar.gz\r\nand this file is not accessible.", "@nfiedel might have some ideas here.", "I think the problem is that the 'patch' command is not installed (see [this thread](https://github.com/tensorflow/tensorflow/issues/8919)).\r\n\r\nIt looks like you're trying to build on Windows and though we never tried it, I think TensorFlow Serving is likely not to compile there. You may want to use a Docker container.", "@kirilg  yes I am trying on windows and its not possible. Tensorflow serving is also not compatible.", "Perhaps not natively, but you can try compiling in a docker container - https://www.tensorflow.org/serving/docker\r\n\r\nIf you're going to use a docker container that sets up a linux environment, you can also just `apt-get install` the ModelServer (v1.4 uses TF 1.4), unless you wanted to compile from source. Apt-get instructions can be found [here](https://www.tensorflow.org/serving/setup).", "@kirilg thanks I was just asking like in anyway it possible on windows. But I dont think so its possible. I hope they make tensorflow serving compatible to python 3.5 and later. because tensorflow need python 3.5 and serving need python 2.7. ", "Closing this issue due to staleness. Please use the latest version of TensorFlow and build again.\r\nFeel free to report any issues you encounter with latest TensorFlow. Thanks!"]}, {"number": 14834, "title": "[AUC] result of tf.metrics.auc doesnot match with sklearn's", "body": "My tensorflow version is ('v1.3.0-rc1-4263-gc81acfb', '1.4.0-rc1'), and the system is Rehat with gcc version 4.8.5 20150623 (Red Hat 4.8.5-16). I run the program use CPU only.\r\n\r\nI wrote a NN  use tensorflow for binary classification. I create the an `auc_op` in the following way:\r\n \r\n```python\r\nnet = input_layer(features,) # get dense input layer from features\r\nfor layer_id in xrange(1, num_layer):\r\n    net  = tf.add(tf.matmul(net, self._weights[layer_id]), self._bias[layer_id])\r\n    if layer_id < num_layer - 1: # output layer without activation function to get `wx + b`\r\n        net =tf.nn.relu(net)\r\nlogits = net\r\nlabels = tf.expand_dims(tf.cast(tf.convert_to_tensor(labels), dtype = tf.float32), axis = -1)\r\nauc_op = tf.metrics.auc(labels = labels, predictions = tf.sigmoid(logits), num_thresholds = 102400)\r\n```\r\n\r\nI run the `auc_op` like this:\r\n```python\r\nfor step in xrange(1, self._max_steps + 1):\r\n    auc = self._sess.run(auc_op)\r\n```\r\n\r\nI also keep all the logits and labels in each step and concatenate them, then call sklearn like this:\r\n```python\r\nfrom sklearn.metrics import roc_auc_score\r\nroc_auc_score(labels, sigmoid(logits))\r\n```\r\n\r\nAre there anything wrong in the way I use tf.metrics.auc? When I run the `auc_op`, it returns a tuple with two values and I don't which one is the correct auc. But both of them are not equal with sklearn's. \r\nI once wrote an program to calculate auc and it was exactly the same with sklearn's even in 1M data, thus I tend to think sklearn's result is the ground truth. ", "comments": ["The API of `tf.metrics.auc` says that it is an **approximate** AUC via a Riemann sum. So I expect that the results will be a slightly different:\r\n\r\n```python\r\nimport numpy as np\r\nfrom sklearn.metrics import roc_auc_score\r\ny_true = np.array([0, 0, 1, 1])\r\ny_scores = np.array([0.1, 0.4, 0.35, 0.8])\r\nprint(\"sklearn auc: {}\".format(roc_auc_score(y_true, y_scores)))\r\n\r\nimport tensorflow as tf\r\nauc, update_op = tf.metrics.auc(y_true, y_scores)\r\nwith tf.Session() as sess:\r\n    sess.run(tf.local_variables_initializer())\r\n    print(\"tf auc: {}\".format(sess.run([auc, update_op])))\r\n```\r\n\r\n```bash\r\n~/Downloads \u276f\u276f\u276f python test.py\r\nsklearn auc: 0.75\r\ntf auc: [0.74999976, 0.74999976]\r\n```", "Thanks for your help. \r\nBut on my dataset, the result from tensorflow and sklearn are quite different, the gap is about 0.5%-1%. I think this is a gap we cannot ignore...", "@maybeluo I agree that 1% gap is unsatisfied. It could be useful if you can provide some data for test (or benchmark report) , for example, a numpy array or csv file.", "I'll do more experiments and look at the approximation method. Thanks.", "I got auc 0.78 on tensorflow,while I got 0.89 with sklearn", "Sklearn auc appears to be uniformly higher on all the datasets I've tested, perhaps using more accurate quadrature when calculating the AUC would be good.", "Was the problem solved somehow? In my case i got AUC 0.82 on tensorflow and 0.90 in `sklearn.metrics.auc_score`.", "got the same problem", "Another issue with ``` tf.metrics.auc ``` is, it doesn't give the same result when using one hot encoding and [0, 1] encoding. For example, ```target = [1, 1, 0, 1, 0] and one hot encoding of target is targ_one_hot=[[0, 1], [0, 1], [1, 0], [0, 1], [1, 0]] ``` if we these different representation   ``` tf.metrics.auc ``` gives different results where as ```sklearn.metrics.auc_score``` results are similar.", "Just ran into similar problems and found this thread. If anyone else find here as well, hope this can help.\r\n\r\nIf your model's predictions are generally very small, say something less than 0.001, try increasing the **num_thresholds** argument in your auc call. The default value is set to 200, which in my case is too small and cause huge approximation error(as high as 0.2).\r\n\r\nThis is actually clearly stated in the [doc](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/AUC) as a caveat, but I do think auc metric in a future version should have better default behaviors or warning message for such cases.\r\n\r\n> The num_thresholds variable controls the degree of discretization with larger numbers of thresholds more closely approximating the true AUC. The quality of the approximation may vary dramatically depending on num_thresholds. The thresholds parameter can be used to manually specify thresholds which split the predictions more evenly.\r\n\r\n> For best results, predictions should be distributed approximately uniformly in the range [0, 1] and not peaked around 0 or 1. The quality of the AUC approximation may be poor if this is not the case. Setting summation_method to 'minoring' or 'majoring' can help quantify the error in the approximation by providing lower or upper bound estimate of the AUC.\r\n\r\n"]}, {"number": 14833, "title": "Fix of issue #10479", "body": "Fixes issue #10479", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->", "I signed it", "CLAs look good, thanks!\n\n<!-- ok -->", "@smksyj any luck with this?", "@smksyj ping.", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "@smksyj any chance you'll finish this up?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Please reopen when you've had a chance to finish this PR."]}, {"number": 14832, "title": "Error building with cmake - on Win10, Python3.5 ,Tensorflow 1.4 (Pywrap_tensorflow Issue)", "body": "Hi , I m trying to build tensorflow with cmake. Firstly my system information is here; \r\n### System information\r\n- Windows 10\r\n- Tensorflow 1.4.0\r\n- Anaconda 3 (Python3.5)\r\n- I used swingwin Version: 2.0.0 (2 June 2010)\r\n- CUDA 8 CuDnn 5.1\r\n- Quadro P3000 ,  NVIDIA-SMI 382.16 - Driver Version: 382.16\r\n\r\n I followed  the instruction here : https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/cmake/README.md   \r\n\r\n- Install  the pre-requisites detailed above, and set up your environment. \u2713\r\n- Clone  the TensorFlow repository and create a working directory for your build:    \u2713\r\n- Invoke  CMake to create Visual Studio solution and project files. \u2713\r\n- Invoke  MSBuild to build TensorFlow   (Errors :( )\r\n\r\nThe errors here ;\r\nC:\\...\\tensorflow\\tensorflow\\contrib\\cmake\\build\\pywrap_tensorflow_internal.cc(4143): error C3861: 'PyString_FromString': identifier not found [C:\\...\\tensorflow\\tensorflow\\contrib\\cmake\\build\\pywrap_tensorflow_internal_static.vcxproj]\r\n\r\nC:\\..\\tensorflow\\tensorflow\\contrib\\cmake\\build\\pywrap_tensorflow_internal.cc(4154): error C3861: 'PyString_FromString': identifier not found [C:\\..\\tensorflow\\tensorflow\\contrib\\cmake\\build\\pywrap_tensorflow_internal_static.vcxproj]\r\n\r\nC:\\..\\tensorflow\\tensorflow\\contrib\\cmake\\build\\pywrap_tensorflow_internal.cc(4246): error C3861: 'PyString_FromString': identifier not found [C:\\...\\tensorflow\\tensorflow\\contrib\\cmake\\build\\pywrap_tensorflow_internal_static.vcxproj]\r\n\r\nC:\\..\\tensorflow\\tensorflow\\contrib\\cmake\\build\\pywrap_tensorflow_internal.cc(4246): error C2661: 'tensorflow::internal::Check_EQImpl': no overloaded function takes 2 arguments [C:\\..\\tensorflow\\tensorflow\\contrib\\cmake\\build\\pywrap_tensorflow_internal_static.vcxproj]\r\n\r\nC:\\..\\tensorflow\\tensorflow\\contrib\\cmake\\build\\pywrap_tensorflow_internal.cc(4246): error C2512: 'tensorflow::internal::CheckOpString': no appropriate default constructor available [C:\\..\\tensorflow\\tensorflow\\contrib\\cmake\\build\\pywrap_tensorflow_internal_static.vcxproj]\r\n\r\nI found this page https://github.com/tensorflow/tensorflow/issues/5949 about the issue, It is not building with cmake -maybe cosofthat it is another issue but  , Main solution is to update   Microsoft Visual C++ 2015 Redistributable Update 3 (x64 version) and I uninstalled,then installed it ,just in case.\r\nBut It didnot work.  \r\n\r\nDo you have any idea?\r\n", "comments": ["It happens to me as well. \r\nIn my case, I ran the following cmake command:\r\n\r\n```sh\r\ncmake .. -A x64 -DCMAKE_BUILD_TYPE=Release -DSWIG_EXECUTABLE=C:\\tools\\swigwin-3.0.10\\swig.exe -DPYTHON_EXECUTABLE=C:\\Users\\Pesquisa\\Anaconda3\\python.exe -DPYTHON_LIBRARIES=C:\\Users\\Pesquisa\\Anaconda3\\libs\\python35.lib -Dtensorflow_BUILD_PYTHON_BINDINGS=OFF -Dtensorflow_ENABLE_GRPC_SUPPORT=OFF\r\n```\r\n\r\nAnd I got the error:\r\n\r\n```sh\r\nCMake Error: The source directory \"C:/tensorflow/tensorflow/contrib\" does not appear to contain CMakeLists.txt.\r\n```", "The issue was the version of swig , I guess. I changed with 3.0.12 and Now facing with another errors :) @arnaldog12 I think you are building in wrong folder.  ", "Glad you got it resolved Did you open another issue for the other errors?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue? Please update the label and/or status accordingly.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue? Please update the label and/or status accordingly.", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 14831, "title": "fixed bug that Dropout support_masking gets reset to False", "body": "fix #14819.", "comments": ["Can one of the admins verify this patch?", "Looks good. Let's wait for review from tensorflowers, perhaps @fchollet would be interested. ", "Build aborted. Jenkins, test this please.", "@tensorflow-jenkins test this please"]}, {"number": 14830, "title": "Feature request: Tensorflow lite on memory constrained bare-metal systems", "body": "I'm interested in running Tensorflow Lite on devices with limited memory resources and possibly no operating systems abstractions available. \r\n\r\nThis means removing any dependencies on file systems, threads, synchronization primitives, etc. and keeping the binary size as small as possible. I don't know if you discuss your roadmap openly here, but I'm wondering whether this is something that is planned for TFLite? If not, I may go ahead and try to implement this myself.", "comments": ["Considering how one of the frequently mentioned advantages of TensorFlow Lite (interpreter) over XLA (compiler) is that you can update models without changing app code, I assume the intention is to require a file system.\r\n\r\nRaspberry Pi seems to be on the roadmap though: https://github.com/tensorflow/tensorflow/issues/14589\r\n\r\nPerhaps you could try to compile a frozen GraphDef with tfcompile (LLVM based) for your target though?", "Thanks for your comment.\r\n\r\nI initially thought it would be possible for me to read the models from a region in memory reserved in the binary itself for storing models. I could then use flatbuffers to load the model from a pointer instead of a file path. \r\n\r\nUnfortunately, XLA backends are not available for the platforms I'm targetting.\r\n", "@shaurya0 The updating of model is independent of the core TF Lite interpreter and operations themselves. The core library and most kernels (op implementations) have very few dependencies and likely not the ones you list here. \r\n\r\nThe goal is for the core to be very portable so keeping low dependencies is important.\r\n \r\nCertain kernels do leverage multi-threading/synchronization, but we often have single threaded versions as well, or you could easily rewrite just those while taking advantage of the rest of the pieces.\r\n\r\nBest thing to do is to try TF Lite out for your device and let us know what issues you run into. Do not hesitate to send across improvements to reduce/separate out dependencies where feasible - it will help many others as well.\r\n", "Thanks for your comment.", "@shaurya0 I have upstreamed some changes to make it possible to build tfcompile on Windows via Bazel, tracking bug at #15213, instruction at https://github.com/rongjiecomputer/tensorflow-xla-aot-windows. Very hacky as I need to build LLVM with CMake then import the binaries to Tensorflow to build with Bazel\r\n\r\nIf you can port the Bazel build script of XLA/AOT to CMake, it will be possible to build LLVM and Tensorflow together. I can't do/test this as I cannot use CMake + MSBuild, and Tensorflow can't be built with CMake + Ninja."]}, {"number": 14829, "title": "Visualizing Embeddings", "body": "https://www.tensorflow.org/programmers_guide/embedding#projections\r\nn the visual for data exploration there are 2 options for distance. One of them should be \"Euclidean\" as against \"Euclidian\"", "comments": ["Oh, a typo, right? However, I'm afraid that we should submit the issue to tensor board: https://github.com/tensorflow/tensorboard", "I don't see any typo at \"https://www.tensorflow.org/programmers_guide/embedding#projections\", could you please redirect to the correct link unless it has already been fixed.", "If I understand you correctly, you point out the \"Euclidian\" is not correct name here in the screenshot. And we should correct it to \"Euclidean\", right?\r\n\r\n<img width=\"277\" alt=\"image\" src=\"https://user-images.githubusercontent.com/1112263/33304540-700729da-d444-11e7-8210-6154886f6e36.png\">\r\n", "That's correct. Sorry all for a delayed response.\n\nOn Nov 28, 2017 11:36, \"Yan Facai (\u989c\u53d1\u624d)\" <notifications@github.com> wrote:\n\n> If I understand you correctly, you point out the \"Euclidian\" is not\n> correct name here in the screenshot. And we should correct it to\n> \"Euclidean\", right?\n>\n> [image: image]\n> <https://user-images.githubusercontent.com/1112263/33304540-700729da-d444-11e7-8210-6154886f6e36.png>\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/14829#issuecomment-347422960>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AUDM-imxzdl1AkmA-xh4TgujqY0pPt45ks5s66LxgaJpZM4QogjP>\n> .\n>\n", "@jyoti59n thanks for reply. I think it is a typo, however we should report the issue to tensor board repository.", "@jart could you please fix this?", "The typo is fixed in TensorBoard. Fixing the minor typo in the screenshot would require monkey patching the PNG in Photoshop and uploading it directly to the documentation web server. Re-assigning to @dr4b.", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "We've done this change internally and it just has to propagate out in the next release, sorry.  Closing for now."]}, {"number": 14828, "title": "Eager: Can't take gradient of element-wise tf functions", "body": "Maybe I'm missing something, but taking the gradient of functions like `tf.sin` and `tf.log` in eager mode is failing on a recent master (80e7c9f45c):\r\n\r\n```python\r\nIn [1]: import tensorflow as tf\r\n\r\nIn [2]: import tensorflow.contrib.eager as tfe\r\n\r\nIn [3]: tfe.enable_eager_execution()\r\n\r\nIn [4]: g=tfe.gradients_function(tf.sin)\r\n\r\nIn [5]: g([1.0])\r\n```\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nIndexError                                Traceback (most recent call last)\r\n<ipython-input-5-e4ceb6f55b16> in <module>()\r\n----> 1 g([1.0])\r\n\r\n~/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/backprop.py in decorated(*args, **kwds)\r\n    509     \"\"\"Computes the gradient of the decorated function.\"\"\"\r\n    510\r\n--> 511     _, grad = val_and_grad_function(f, params=params)(*args, **kwds)\r\n    512     return grad\r\n    513\r\n\r\n~/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/backprop.py in decorated(*args, **kwds)\r\n    608       raise ValueError(\"Functions to be differentiated cannot \"\r\n    609                        \"receive keyword arguments.\")\r\n--> 610     val, vjp = make_vjp(f, params)(*args, **kwds)\r\n    611     return val, vjp(dy=dy)\r\n    612\r\n\r\n~/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/backprop.py in decorated(*args, **kwds)\r\n    660       args = _ensure_unique_tensor_objects(parameter_positions, args)\r\n    661       for i in parameter_positions:\r\n--> 662         sources.append(args[i])\r\n    663         tape.watch(args[i])\r\n    664       result = f(*args)\r\n\r\nIndexError: list index out of range\r\n```", "comments": ["We should specify `params=[\"x\"]`,  otherwise `gradients_function` will use all arguments, see its [API](https://www.tensorflow.org/versions/master/api_docs/python/tf/contrib/eager/gradients_function):\r\n\r\n> params: list of parameter names of f or list of integers indexing the parameters with respect to which we'll differentiate. Passing None differentiates with respect to all parameters.\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport tensorflow.contrib.eager as tfe\r\n\r\ntfe.enable_eager_execution()\r\n\r\ng=tfe.gradients_function(tf.sin, params=[\"x\"])\r\nprint(\"g res: {}\".format(g([1.0])))\r\n```", "Yup, as @facaiy pointed out, `tfe.gradients_function` attempts to return the gradient with respect to all the parameters of the function, which in the case of `tf.sin` are two (`x` and the string `name`).\r\n\r\nThe following should work:\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport tensorflow.contrib.eager as tfe\r\n\r\ntfe.enable_eager_execution()\r\ng = tfe.gradients_function(tf.sin, [0])\r\ng([1.0])\r\n```\r\n\r\nas would the following:\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport tensorflow.contrib.eager as tfe\r\n\r\ntfe.enable_eager_execution()\r\n\r\ndef f(x): return tf.sin(x)\r\n\r\ng = tfe.gradients_function(f)\r\ng([1.0])\r\n```\r\n\r\nThe error message could be nicer of course :)\r\n\r\nFYI: @alextp @akshayka as they may be touching that code right now and might have ideas on the mechanics of improving the error message.\r\n\r\nHope that helps. Feel free to reopen if I have misunderstood. Thanks.", "Thanks, that clarifies things!"]}, {"number": 14827, "title": "how to make shear transform in tensorflow like tensorflow.image.random_flip_left_right(image) ?", "body": "in keras, you can make shear transform by **random_shear** in keras.preprocessing.image.\r\n\r\nbut how to make shear transform in tensorflow?\r\n\r\nwhat I want is something like **tensorflow.image.random_flip_left_right(image)** in tensorflow.\r\n\r\nit will be done by **tf.contrib.image.transform**", "comments": []}, {"number": 14826, "title": "bug about tensorflow can not call opencv imread properly", "body": "\r\n------------------------\r\n\r\n### System information\r\n**- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: ubuntu 14.04\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: 1.4\r\n- **Python version**: 2.7(but actually i am talking about c++ code)\r\n- **Bazel version (if compiling from source)**: 0.5.4/0.7.0 all tried\r\n- **GCC/Compiler version (if compiling from source)**:  4.8.4\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: CPU mode\r\n- **Exact command to reproduce**: bazel run -c opt //tensorflow/cc/face:face**\r\n\r\n### Describe the problem\r\ni add opencv as a third party lib to tensorflow, and modify the workspace and BUILD file to include it to the project. it works well when i use tensorflow 1.2.1 or version before it. recently i update my tensorflow to the newest version, it recommand i must update my bazel at least 0.5.4(i use 0.5.2 with jdk7 before).\r\nand when i update bazel, and move my own code to the new project, compiling seems ok. but when i run the binary, it seems not right. i can not load a jpeg file when i use cv::imread, it doesn't crash, but return a cv::Mat with size 0. in the new project, i can load a bmp file properly, so i guess it is because the project does not link the libjpeg.\r\nbut i never need to link the libjpeg manually, because it is included in the opencv library. so i guess there is a bug in the new version of tensorflow.\r\ni have tried the linkopt with -ljpeg, but it does not work.\r\n\r\n### Source code / logs\r\nWORKSPACE File:\r\nnew_local_repository(\r\n  name = \"opencv\",\r\n  path = \"/usr/local\",\r\n  build_file = \"opencv.BUILD\",\r\n)\r\nBUILD file of opencv:\r\ncc_library(\r\n    name = \"opencv\",\r\n    srcs = glob([\"lib/*.so*\"]),\r\n    hdrs = glob([\"include/**/*.hpp\"]),\r\n    includes = [\"include\"],\r\n    visibility = [\"//visibility:public\"], \r\n    linkstatic = 1,\r\n)\r\nBUILD file of my code\r\ntf_cc_binary(\r\n    name = \"face\",\r\n    srcs = [\"face.cc\"],\r\n    includes = [\".\"],\r\n    deps = [\r\n        \"//tensorflow/cc:cc_ops\",\r\n        \"//tensorflow/cc:client_session\",\r\n        \"//tensorflow/core:tensorflow\",\r\n        \"@opencv//:opencv\",\r\n    ],\r\n    copts = [\"-fopenmp\"],\r\n    linkopts = [\"-lgomp\", \"-ljpeg\"],\r\n)\r\nmy code:\r\n        cv::Mat img = cv::imread(\"pic.jpg\");\r\n        std::cout<<line<<\" \"<<img.channels()<<\" \"<<img.cols<<\" \"<<img.rows<<endl;\r\nthe log will be: pic.jpg 1 0 0\r\nbut if i read a bmp file:\r\n        cv::Mat img = cv::imread(\"pic.bmp\");\r\n        std::cout<<line<<\" \"<<img.channels()<<\" \"<<img.cols<<\" \"<<img.rows<<endl;\r\nthe log will be: pic.bmp 3 500 355\r\n", "comments": ["can you do an ldd on the openmp library and the tensorflow dso libraries? Does it work if you don't link tensorflow and only link opencv?\r\n ", "Both TF (via bazel) and OpenCV include libjpeg and build it from source as part of their build. It is conceivable that, if they use different versions, or even if they don't, that there might be global state that is confused between the two. \r\n\r\nI also don't know what OpenCV does if the jpeg decoder is not available, do you have to configure OpenCV to use jpeg manually, i.e. define some compiler defines? The test @aselle suggested should clear that up.", "Hi! I meet the same problem.\r\nI'm using opencv3.1 tensorflow1.4 in ubuntu14.04. When I included tensorflow headers like #include <tensorflow/core/public/session.h> or #include \"tensorflow/cc/ops/standard_ops.h\", cv::imread can not read images encoded by JPEG, but can read other encoding images like Uncompressed 8-bit RGB. When I commented TF headers, I can read any images by cv::imread. Is there any solution? Thanks a lot!!! @martinwicke @aselle  How can I configure OpenCV to use jpeg manually? I will try that.", "I got same issue when I compile the[ mtcnn face detector with OpenCV](https://github.com/cyberfire/tensorflow-mtcnn/tree/master/cpp/tf_embedded).\r\nI just use OpenCV3.3 and tensorflow 1.4.0.", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "I rebuild libtensorflow_cc.so using command bazel build --config=monolithic :libtensorflow_cc.so , and can read any images successfully. \r\nsee  #14267[](https://github.com/tensorflow/tensorflow/issues/14267#issuecomment-351914635)", "That means that most likely the cause is a version mismatch of some dependent library (most likely libjpg): TF builds against the version pointed to by its bazel workspace, but links dynamically against what's installed. If those don't match, bad things happen. If you build --config=monolithic, you link statically and everything is fine. \r\n\r\nThe other fix for this is to change the bazel workspace dependency to use the same version that is used by opencv (which I think *also* distributes a version in their sources). \r\n\r\nI'll close this issue as I don't see how we can fix this, but a viable workaround exists."]}, {"number": 14825, "title": "how to extract parameters of sim.batch_norm", "body": "using slim.batch_norm for normalize and here are the batch_norm_params:\r\n\r\n\r\n![image](https://user-images.githubusercontent.com/31264567/33162735-1b13082c-d066-11e7-918c-62bec95e328c.png)\r\n\r\n\r\nin this way, i think all the trainable variables (beta, gamma, moving_mean, moving_variance) was stored. and when i print elements in tf.trainable_variables, here is the result. \r\n\r\n\r\n\r\n![image](https://user-images.githubusercontent.com/31264567/33162835-8c4c091c-d066-11e7-96c9-da7f9b85865e.png)\r\n\r\n\r\nmissing gamma, \r\ni extracted the output tensor of the first layer, and manually calculate correspond feature map through these parameters.  its not the same, but can be transformed into the same through linear transformation.\r\nso, i'm sure there's something wrong with batch_norm params. where can i find the correct ones. ", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 14824, "title": "'output' does not exist in model 'file:///android_asset/retrained_graph.pb'", "body": "I was retrain a inception model with food images,i got the final test prediction and retrained_graph.pb ,retrained_labels.txt file.i check the prediction using command prompt in windows and its work.but i was put the retrained_graph.ph and retrained_labels.txt files into android studio asset folder for deploying mobile,i got the exception like:\r\noutput' does not exist in model 'file:///android_asset/retrained_graph.pb\r\n\r\nCan anyone help me solve this issue.", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 14823, "title": "TFlite readme.md add mobilenet frozen_graph.pb link", "body": "add mobilenet frozen_graph.pb link", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->", " I signed it!\n\n2017-11-23 14:42 GMT+08:00 Tensorflow Jenkins <notifications@github.com>:\n\n> Can one of the admins verify this patch?\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/14823#issuecomment-346540681>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ANqSgSm3OSvpJSQSR5HDs4-zGsQtvSy9ks5s5RPzgaJpZM4QoUrS>\n> .\n>\n", "CLAs look good, thanks!\n\n<!-- ok -->", "/CC @MarkDaoust ", "Jenkins, test this please."]}]