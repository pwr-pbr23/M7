[{"number": 46130, "title": "ValueError: Invalid checkpoint state loaded from", "body": "Running Tensorflow 1.13.0  through Anaconda on Ubuntu 16.04 (Full install on external SSD)\r\nPython 3.6.11\r\n\r\n```\r\nimport tensorflow as tf\r\nresult = tf.train.get_checkpoint_state('')\r\n```\r\nI booted to Ubuntu 16.04 installed on external SSD from my Windows PC. When I run the above commands in my PC Internal drive path in anaconda environment, I get a warning \r\n```\r\nWARNING:tensorflow:FailedPreconditionError: checkpoint; Is a directory\r\nWARNING:tensorflow:checkpoint: Checkpoint ignored\r\n```\r\n\r\nBut when I run the exact commands in my external SSD drive path in the same anaconda environment, I get a `ValueError: Invalid checkpoint state loaded from`\r\n\r\nWhat's the cause for this and how can I fix it?", "comments": ["@JohnG0024,\r\nTensorFlow 1.x is not actively supported. Could you please update TensorFlow to the latest stable version v2.4 and check if you are facing the same issue. Thanks!", "It's the same with latest tensorflow. I found the problem, something to do with the ` - ` in path, somehow tensorflow is able to recognize '-' in internal SSD path (Windows), but not in external SSD path (Ubuntu). Not sure why.  ", "@JohnG0024 \r\nIn order to expedite the trouble-shooting process, could you please provide a minimal code snippet to reproduce the issue reported here and also the files required to run the code. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46130\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46130\">No</a>\n"]}, {"number": 46129, "title": "\"Table not initialized\" when loading model in Java", "body": "- TensorFlow version (use command below):2.3.0\r\n- Python version:3.7\r\n\r\nI am trying to use the tensorflow model in java,I convert a text classification model (with tf.lookup) to fomat .pb and want to load it in JAVA.But got \"Table not initialized\" error.\r\n```\r\n2021-01-04 14:00:10.713588: W tensorflow/core/framework/op_kernel.cc:1651] OP_REQUIRES failed at lookup_table_op.cc:809 : Failed precondition: Table not initialized.\r\nException in thread \"main\" java.lang.IllegalStateException: Table not initialized.\r\n\t [[{{node graph/hash_table_Lookup/LookupTableFindV2}}]]\r\n\tat org.tensorflow.Session.run(Native Method)\r\n\tat org.tensorflow.Session.access$100(Session.java:48)\r\n\tat org.tensorflow.Session$Runner.runHelper(Session.java:326)\r\n\tat org.tensorflow.Session$Runner.run(Session.java:276)\r\n\tat ctest.Ttest.predict(Ttest.java:32)\r\n\tat ctest.Ttest.main(Ttest.java:13)\r\n```\r\n\r\n**here is my code:**\r\n***In PYTHON***\r\n\r\n```\r\nimport os\r\nimport tensorflow.compat.v1 as tf\r\ntf.disable_v2_behavior()\r\nfrom tensorflow.python.framework.graph_util import convert_variables_to_constants\r\nfrom tensorflow.python.ops.lookup_ops import HashTable, KeyValueTensorInitializer\r\n\r\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\r\nOUTPUT_FOLDER = ''\r\nOUTPUT_NAME = 'hash_table.pb'\r\nOUTPUT_NAMES = ['graph/output', 'init_all_tables']\r\n\r\n\r\ndef build_graph():\r\n    d = {'a': 1, 'b': 2, 'c': 3, 'd': 4}\r\n    init = KeyValueTensorInitializer(list(d.keys()), list(d.values()))\r\n    hash_table = HashTable(init, default_value=-1)\r\n    data = tf.placeholder(tf.string, (None,), name='data')\r\n    values = hash_table.lookup(data)\r\n    output = tf.identity(values * 2, 'output')\r\n\r\ndef freeze_graph():\r\n    with tf.Graph().as_default() as graph:\r\n        with tf.name_scope('graph'):\r\n            build_graph()\r\n\r\n        with tf.Session(graph=graph) as sess:\r\n            sess.run(tf.tables_initializer())\r\n            print(sess.run('graph/output:0', feed_dict={'graph/data:0': ['a', 'b', 'c', 'd', 'e']}))\r\n            frozen_graph = convert_variables_to_constants(sess, sess.graph_def, OUTPUT_NAMES)\r\n            tf.train.write_graph(frozen_graph, OUTPUT_FOLDER, OUTPUT_NAME, as_text=False)\r\n\r\ndef load_frozen_graph():\r\n    with open(os.path.join(OUTPUT_FOLDER, OUTPUT_NAME), 'rb') as f:\r\n        output_graph_def = tf.GraphDef()\r\n        output_graph_def.ParseFromString(f.read())\r\n\r\n    with tf.Graph().as_default() as graph:\r\n        tf.import_graph_def(output_graph_def, name='')\r\n        with tf.Session(graph=graph) as sess:\r\n            try:\r\n                sess.run(graph.get_operation_by_name('init_all_tables'))\r\n            except KeyError:\r\n                pass\r\n            print(sess.run('graph/output:0', feed_dict={'graph/data:0': ['a', 'b', 'c', 'd', 'e']}))\r\n\r\n\r\nif __name__ == '__main__':\r\n    freeze_graph()\r\n    load_frozen_graph()\r\n```\r\n\r\n***In JAVA***\r\n\r\n```\r\npackage ctest;\r\n\r\nimport org.tensorflow.Graph;\r\nimport org.tensorflow.Session;\r\nimport org.tensorflow.Tensor;\r\nimport java.nio.file.Files;\r\nimport java.nio.file.Paths;\r\n\r\npublic class Ttest {\r\n    public static void main(String[] args) throws Exception {\r\n        predict();\r\n    }\r\n    public static void predict() throws Exception {\r\n        try (Graph graph = new Graph()) {\r\n            graph.importGraphDef(Files.readAllBytes(Paths.get(\r\n                    \"/opt/resources/hash_table.pb\"\r\n            )));\r\n            try (Session sess = new Session(graph)) {\r\n                byte[][] matrix = new byte[1][];\r\n                matrix[0] = \"a\".getBytes(\"UTF-8\");\r\n                Tensor< ? > out = sess.runner()\r\n                        .feed(\"graph/data:0\", Tensor.create(matrix)).fetch(\"graph/output:0\").run().get(0);\r\n                float[][] output = new float[1][(int) out.shape()[1]];\r\n                out.copyTo(output);\r\n                for(float i:output[0])\r\n                    System.out.println(i);\r\n\r\n\r\n            }\r\n        }\r\n    }\r\n}\r\n```\r\n\r\nAny suggestions would be greatly appreciated.\r\n\r\n", "comments": ["@WittyLLL \r\npleaze open this issue in correct repo of tfjs and move this to close status.", "> @WittyLLL\r\n> pleaze open this issue in correct repo of tfjs and move this to close status.\r\n\r\nI'm not sure if it is reasonable to open this issue in tfjs. I use the java api not the java script.\r\nhere is my maven ```pom.xml```\r\n```\r\n        <dependency>\r\n            <groupId>org.tensorflow</groupId>\r\n            <artifactId>tensorflow</artifactId>\r\n            <scope>compile</scope>\r\n        </dependency>\r\n```\r\nI found related issues in tensorflow/tensorflow/java/.\r\n\r\nThank you for you patience.", "@WittyLLL,\r\nI think [Tensorflow/Java Repository](https://github.com/tensorflow/java/issues) is the correct place for such issues and please post it in [Stack Overflow](http://stackoverflow.com/questions/tagged/tensorflow) as well. Thanks!\r\n", "> @WittyLLL,\r\n> I think [Tensorflow/Java Repository](https://github.com/tensorflow/java/issues) is the correct place for such issues and please post it in [Stack Overflow](http://stackoverflow.com/questions/tagged/tensorflow) as well. Thanks!\r\n\r\nThank you for you suggestion, i will post it in stack overflow as well.Thanks", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46129\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46129\">No</a>\n"]}, {"number": 46128, "title": "This throws ERROR: features = tf.io.parse_example(..., features=make_parse_example_spec(columns))", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 20.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): Source\r\n- TensorFlow version (use command below): Latest from this week\r\n- Python version: 3.8.x\r\n- Bazel version (if compiling from source): 3.1.0\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 11.2\r\n- GPU model and memory: \r\n\r\n**Describe the current behavior**\r\nI was trying this code, but it throws exception\r\n\r\n```https://www.tensorflow.org/api_docs/python/tf/keras/experimental/SequenceFeatures```\r\n\r\n```return ops.EagerTensor(value, ctx.device_name, dtype)\r\nValueError: Attempt to convert a value (Ellipsis) with an unsupported type (<class 'ellipsis'>) to a Tensor.```\r\n\r\n\r\nHere is the full code from that page,\r\n\r\n\r\n```# Behavior of some cells or feature columns may depend on whether we are in\r\n# training or inference mode, e.g. applying dropout.\r\ntraining = True\r\nrating = sequence_numeric_column('rating')\r\nwatches = sequence_categorical_column_with_identity(\r\n    'watches', num_buckets=1000)\r\nwatches_embedding = embedding_column(watches, dimension=10)\r\ncolumns = [rating, watches_embedding]\r\n\r\nsequence_input_layer = SequenceFeatures(columns)\r\nfeatures = tf.io.parse_example(...,\r\n                               features=make_parse_example_spec(columns))\r\nsequence_input, sequence_length = sequence_input_layer(\r\n   features, training=training)\r\nsequence_length_mask = tf.sequence_mask(sequence_length)\r\n\r\nrnn_cell = tf.keras.layers.SimpleRNNCell(hidden_size, training=training)\r\nrnn_layer = tf.keras.layers.RNN(rnn_cell, training=training)\r\noutputs, state = rnn_layer(sequence_input, mask=sequence_length_mask)\r\n```", "comments": ["@summa-code \r\n\r\nPlease share colab link or simple standalone code with supporting files to reproduce the issue. It helps us in localizing the issue faster.I am seeing the error message(`NameError: name 'sequence_numeric_column' is not defined`) while trying to reproduce the issue. Thanks!", "That is what i have given in the description, and also is in this link !!!!!!!\r\nAnd Did you include the tensor packages ?\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/experimental/SequenceFeatures\r\n\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.keras import layers\r\nfrom tensorflow import feature_column\r\n\r\ntraining = True\r\nrating = feature_column.sequence_numeric_column('rating')\r\nwatches = feature_column.sequence_categorical_column_with_identity(\r\n    'watches', num_buckets=1000)\r\nwatches_embedding = feature_column.embedding_column(watches, dimension=10)\r\ncolumns = [rating, watches_embedding]\r\n\r\nsequence_input_layer = tf.keras.experimental.SequenceFeatures(columns)\r\nfeatures = tf.io.parse_example(...,\r\n                               features=feature_column.make_parse_example_spec(columns))\r\nsequence_input, sequence_length = sequence_input_layer(\r\n   features, training=training)\r\nsequence_length_mask = tf.sequence_mask(sequence_length)\r\n\r\nrnn_cell = tf.keras.layers.SimpleRNNCell(hidden_size, training=training)\r\nrnn_layer = tf.keras.layers.RNN(rnn_cell, training=training)\r\noutputs, state = rnn_layer(sequence_input, mask=sequence_length_mask) \r\n\r\n```", "I have tried in colab with TF version [2.4 gist](https://colab.research.google.com/gist/ravikyram/445470fd54502d56b948ebc76743b505/untitled594.ipynb) and Nightly version(`2.5.0-dev20210104`) [gist](https://colab.research.google.com/gist/ravikyram/9b2cc481b9c9390d2abdd3e516f43a84/untitled593.ipynb) and was able to reproduce the issue. Thanks!", "> `ValueError: Attempt to convert a value (Ellipsis) with an unsupported type (<class 'ellipsis'>) to a Tensor.`\r\n\r\nYeah, often people put `...` in examples to say \"fill this in with the necessary code\". it's too bad that `...` is also valid python.\r\n\r\n Anyway, this whole line: `tf.io.parse_example(..., features=feature_column.make_parse_example_spec(columns))` is a distraction from the function being documented here. This thing doesn't need `Examples` or parser specifications. It needs a dictionary of `SparseTensors`.\r\n \r\n If you actually do want to parse some tensors using that construct, `...` is where you's pass some `SerializeToString` serialized `tf.Examples`.\r\n \r\n Now, we encourage people to use doctest format `>>>` which we do test. But this doc is likely low enough traffic that we may never come back to fix this.", "I am little bit confused. So the example given looks like self contained. We are trying to extract the inputs. In the example given above what do you think goes in ... ? There is one numeric and and one categorical feature. ", "This line:\r\n\r\n```\r\nfeatures = tf.io.parse_example(...,\r\n                               features=feature_column.make_parse_example_spec(columns))\r\n ```\r\n \r\n Should be something like:\r\n \r\n ```\r\nfeatures = {\r\n  'rating': tf.sparse.from_dense([[1.0,1.1, 0, 0, 0],[2.0,2.1,2.2, 2.3, 2.5]])\r\n  'watches': tf.sparse.from_dense([[2, 85, 61, 0, 0, 0],[33,92, 2, 73, 1]])\r\n}\r\n```", "So this looks like feeding the actual sequence for building the model. And should there be a \",\" between ratings and watches ? There was a dimension issue in the watches array, Now it is throwing some other error.\r\n\r\nfeatures = {\r\n 'rating': tf.sparse.from_dense([[1.0, 1.1, 0, 0, 0], [2.0, 2.1, 2.2, 2.3, 2.5]]),\r\n 'watches': tf.sparse.from_dense([[2, 85, 61, 0, 0, 0], [33, 92, 2, 73, 1, 3]])\r\n}\r\nsequence_input, sequence_length = sequence_input_layer(features, training=training)\r\n\r\n\r\n\r\n\r\nraise errors.InvalidArgumentError(\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Condition x == y did not hold.\r\nIndices of first 2 different values:\r\n[[0]\r\n [1]]\r\nCorresponding x values:\r\n[2 5]\r\nCorresponding y values:\r\n[3 6]\r\nFirst 2 elements of x:\r\n[2 5]\r\nFirst 2 elements of y:\r\n[3 6]\r\npython-BaseException\r\n\r\nProcess finished with exit code 1", "I am just looking for a simple usage example for SequenceFeatures with couple of different sequence columns. ", "All sets of sequences need the same shapes. In my earlier post they didn't match.\r\n\r\nThis works:\r\n\r\n```\r\ntraining = True\r\nrating = feature_column.sequence_numeric_column('rating')\r\nwatches = feature_column.sequence_categorical_column_with_identity(\r\n    'watches', num_buckets=1000)\r\nwatches_embedding = feature_column.embedding_column(watches, dimension=10)\r\ncolumns = [rating, watches_embedding]\r\n\r\nfeatures = {\r\n 'rating': tf.sparse.from_dense([[1.0,1.1, 0, 0, 0],[2.0,2.1,2.2, 2.3, 2.5]]),\r\n 'watches': tf.sparse.from_dense([[2, 85, 0, 0, 0],[33,78, 2, 73, 1]])\r\n}\r\n\r\nsequence_input_layer = tf.keras.experimental.SequenceFeatures(columns)\r\nsequence_input, sequence_length = sequence_input_layer(\r\n   features, training=training)\r\n   \r\nsequence_length_mask = tf.sequence_mask(sequence_length)\r\n```", "Oops i missed that one. Ok, can we create \"features\" variable without using the real inputs ? something like this ?\r\n\r\nfeatures['rating'] = tf.keras.Input(shape=(?,), name='rating', dtype=tf.float32)\r\nfeatures['watches'] = tf.keras.Input(shape=(?,), name='watches', dtype=tf.float32)\r\n\r\nIs the shape here just one dimensional for the feature or should it have the windowed shape ?\r\n\r\nThe timeseries example given does not do justice without using these \"Sequence\" functions. Since LSTM takes in 3 dimensional data, without knowing a working example, it is a bit hard.\r\nhttps://www.tensorflow.org/tutorials/structured_data/time_series\r\n\r\n", "I came across this one,\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/31240\r\n\r\nIt is remarkable how durandg12 came back after almost a year after first he used it.\r\n", "And how do i create an input to LSTMCell, because i want to use CuDNN with GPU,\r\n\r\nI am using \"tf.keras.preprocessing.timeseries_dataset_from_array\" to create dataset that has the shape(batch, time sequence, features) format ? I am having sliding window dataset. It is crazy that with the lack of documentation, there is much we could do with SequenceFeature API.\r\n\r\nWhat i wanted is a slidingwindow dataset with a categorical column that is fed into LSTM network. The examples is shown everything except this crucial part. Pytorch has nice way of doing this. Wish Tensorflow has something simple to implement categorical feature for timeseries.\r\n\r\n", "And then i came across this one,\r\n\r\nhttps://github.com/tensorflow/community/blob/master/rfcs/20191212-keras-categorical-inputs.md\r\n\r\nThis all leads to One hot encoding, even the hashing Trick does not do the trick. I am just lost here.", "???? Why was it closed ?", "The linked commit updates that example:\r\n\r\n 2cc955f\r\n \r\n```python\r\n    import tensorflow as tf\r\n    # Behavior of some cells or feature columns may depend on whether we are in\r\n    # training or inference mode, e.g. applying dropout.\r\n    training = True\r\n    rating = tf.feature_column.sequence_numeric_column('rating')\r\n    watches = tf.feature_column.sequence_categorical_column_with_identity(\r\n        'watches', num_buckets=1000)\r\n    watches_embedding = tf.feature_column.embedding_column(watches,\r\n                                                dimension=10)\r\n    columns = [rating, watches_embedding]\r\n    features = {\r\n     'rating': tf.sparse.from_dense([[1.0,1.1, 0, 0, 0],\r\n                                                 [2.0,2.1,2.2, 2.3, 2.5]]),\r\n     'watches': tf.sparse.from_dense([[2, 85, 0, 0, 0],[33,78, 2, 73, 1]])\r\n    }\r\n    sequence_input_layer = tf.keras.experimental.SequenceFeatures(columns)\r\n    sequence_input, sequence_length = sequence_input_layer(\r\n       features, training=training)\r\n    sequence_length_mask = tf.sequence_mask(sequence_length)\r\n    hidden_size = 32\r\n    rnn_cell = tf.keras.layers.SimpleRNNCell(hidden_size)\r\n    rnn_layer = tf.keras.layers.RNN(rnn_cell)\r\n    outputs, state = rnn_layer(sequence_input, mask=sequence_length_mask)\r\n```"]}, {"number": 46127, "title": "Installing", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): windows 10 enterprise\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version: nightly or 2.4\r\n- Python version: 3.8.6\r\n- Installed using virtualenv? pip? conda?: normal pip\r\n- Bazel version (if compiling from source): n/a\r\n- GCC/Compiler version (if compiling from source): n/a\r\n- CUDA/cuDNN version: 11.0 (Recomemded\r\n- GPU model and memory: gtx 1060 6gb\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nI run pip install tf-nightly or pip install tensorflow and get the following error\r\n ERROR: Command errored out with exit status 1:\r\n     command: 'c:\\users\\kai\\appdata\\local\\programs\\python\\python38\\python.exe' -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\kai\\\\AppData\\\\Local\\\\Temp\\\\pip-install-w2yenss2\\\\wrapt\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\kai\\\\AppData\\\\Local\\\\Temp\\\\pip-install-w2yenss2\\\\wrapt\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base 'C:\\Users\\kai\\AppData\\Local\\Temp\\pip-pip-egg-info-bql118ug'\r\n         cwd: C:\\Users\\kai\\AppData\\Local\\Temp\\pip-install-w2yenss2\\wrapt\\\r\n    Complete output (26 lines):\r\n    Traceback (most recent call last):\r\n      File \"c:\\users\\kai\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pkg_resources\\__init__.py\", line 2866, in get_entry_map\r\n        ep_map = self._ep_map\r\n      File \"c:\\users\\kai\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pkg_resources\\__init__.py\", line 2824, in __getattr__\r\n        raise AttributeError(attr)\r\n    AttributeError: _ep_map\r\n\r\n    During handling of the above exception, another exception occurred:\r\n\r\n    Traceback (most recent call last):\r\n      File \"<string>\", line 1, in <module>\r\n      File \"C:\\Users\\kai\\AppData\\Local\\Temp\\pip-install-w2yenss2\\wrapt\\setup.py\", line 102, in <module>\r\n        run_setup(with_extensions=True)\r\n      File \"C:\\Users\\kai\\AppData\\Local\\Temp\\pip-install-w2yenss2\\wrapt\\setup.py\", line 72, in run_setup\r\n        setup(**setup_kwargs_tmp)\r\n      File \"c:\\users\\kai\\appdata\\local\\programs\\python\\python38\\lib\\distutils\\core.py\", line 108, in setup\r\n        _setup_distribution = dist = klass(attrs)\r\n      File \"c:\\users\\kai\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\setuptools\\dist.py\", line 427, in __init__\r\n        for ep in pkg_resources.iter_entry_points('distutils.setup_keywords'):\r\n      File \"c:\\users\\kai\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pkg_resources\\__init__.py\", line 655, in <genexpr>\r\n        for entry in dist.get_entry_map(group).values()\r\n      File \"c:\\users\\kai\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pkg_resources\\__init__.py\", line 2868, in get_entry_map\r\n        ep_map = self._ep_map = EntryPoint.parse_map(\r\n      File \"c:\\users\\kai\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pkg_resources\\__init__.py\", line 2549, in parse_map\r\n        raise ValueError(\"Entry points must be listed in groups\")\r\n    ValueError: Entry points must be listed in groups\r\n    ----------------------------------------\r\nERROR: Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n", "comments": ["This looks like your setup of python tools is broken, the error does not come from TF.", "how would i fix this then? ", "This is a on a fresh install of python so not sure.", "Did you install python from the Windows marketplace or from the official site?", "official site 3.8.7 to be exact", "I fixed that issue now i just have to figure out why tf is loading due to numpy  ** On entry to DGEBAL parameter number  3 had an illegal value\r\n ** On entry to DGEHRD  parameter number  2 had an illegal value\r\n ** On entry to DORGHR DORGQR parameter number  2 had an illegal value\r\n ** On entry to DHSEQR parameter number  4 had an illegal value\r\n  File \"C:\\Users\\kai\\Desktop\\test.py\", line 1, in <module>\r\n    import tensorflow as tf\r\n  File \"C:\\Users\\kai\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\__init__.py\", line 41, in <module>\r\n  File \"C:\\Users\\kai\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 40, in <module>\r\n    from tensorflow.python.eager import context\r\n  File \"C:\\Users\\kai\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\context.py\", line 29, in <module>\r\n    import numpy as np\r\n  File \"C:\\Users\\kai\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\numpy\\__init__.py\", line 305, in <module>\r\n    _win_os_check()\r\nheck\r\n    raise RuntimeError(msg.format(__file__)) from None\r\nRuntimeError: The current Numpy installation ('C:\\\\Users\\\\kai\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python38\\\\lib\\\\site-packages\\\\numpy\\\\__init__.py') fails to pass a sanity check due to a bug in the windows runtime. See this issue for more information: https://tinyurl.com/y3dm3h86\r\nim on numpy 1.9.4 so not sure.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46127\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46127\">No</a>\n"]}, {"number": 46126, "title": "Performance 5x degradation after converting numpy to tf.function equivalent", "body": "<em>Please make sure that this is an issue related to performance of TensorFlow.\r\nAs per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:performance_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Custom code\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu (Google colab) & macOs 11.1\r\n- TensorFlow installed from (source or binary): pip installation.\r\n- TensorFlow version (use command below): 2.3.1 / 2.4\r\n- Python version: 3.6+\r\n- CUDA/cuDNN version: 10.1\r\n- GPU model and memory: Varies\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\nI converted this function, that performs gradient updates for a DQN agent. It takes a batch of numpy arrays, calculates target values and updates gradients using `model.fit()` for 1 epoch, it usually processes 90-100 frames per second on google colab.\r\n\r\n    def update(self, batch):\r\n        \"\"\"\r\n        Update gradients given a batch.\r\n        Args:\r\n            batch: A batch of observations in the form of\r\n                [[states], [actions], [rewards], [dones], [next states]]\r\n    \r\n        Returns:\r\n            None\r\n        \"\"\"\r\n        states, actions, rewards, dones, new_states = batch\r\n        q_states = self.main_model.predict(states)\r\n        if self.double:\r\n            new_state_actions = np.argmax(self.main_model.predict(new_states), 1)\r\n            new_state_q_values = self.target_model.predict(new_states)\r\n            new_state_values = new_state_q_values[\r\n                np.arange(self.batch_size), new_state_actions\r\n            ]\r\n        else:\r\n            new_state_values = self.target_model.predict(new_states).max(1)\r\n        new_state_values[dones] = 0\r\n        target_values = np.copy(q_states)\r\n        target_value_update = new_state_values * self.gamma ** self.n_steps + rewards\r\n        state_action_values = target_values[np.arange(self.batch_size), actions]\r\n        target_values[np.arange(self.batch_size), actions] = target_value_update\r\n        self.main_model.fit(states, target_values, verbose=0)\r\n        if self.buffer.priorities:\r\n            squared_loss = (state_action_values - target_value_update) ** 2\r\n            priorities = (\r\n                self.buffer.current_weights * squared_loss + self.buffer.priority_bias\r\n            )\r\n            self.buffer.update_priorities(priorities)\r\n\r\n**After the conversion:**\r\n\r\n    @tf.function\r\n    def get_targets(self, batch):\r\n        \"\"\"\r\n        Get target values for gradient updates.\r\n        Args:\r\n            batch: A batch of observations in the form of\r\n                [[states], [actions], [rewards], [dones], [next states]]\r\n        Returns:\r\n            None\r\n        \"\"\"\r\n        states, actions, rewards, dones, new_states = batch\r\n        q_states = self.main_model(states)\r\n        if self.double:\r\n            new_state_actions = tf.argmax(self.main_model(new_states), 1)\r\n            new_state_q_values = self.target_model(new_states)\r\n            a = self.get_action_indices(new_state_actions)\r\n            new_state_values = tf.gather_nd(new_state_q_values, a)\r\n        else:\r\n            new_state_values = tf.reduce_max(self.target_model(new_states), axis=1)\r\n        new_state_values *= tf.cast(~dones, tf.float32)\r\n        target_values = tf.identity(q_states)\r\n        target_value_update = new_state_values * self.gamma ** self.n_steps + tf.cast(\r\n            rewards, tf.float32\r\n        )\r\n        indices = self.get_action_indices(actions)\r\n        state_action_values = tf.gather_nd(target_values, indices)\r\n        tf.tensor_scatter_nd_update(target_values, indices, target_value_update)\r\n        if self.buffer.priorities:\r\n            squared_loss = (state_action_values - target_value_update) ** 2\r\n            priorities = (\r\n                self.buffer.current_weights * squared_loss + self.buffer.priority_bias\r\n            )\r\n            self.buffer.update_priorities(priorities)\r\n        return target_values\r\n\r\nAnd I get `model.fit()` outside the method which results in a severe performance degradation ~= 20 frames per seconds.\r\n\r\n**Describe the expected behavior**\r\n\r\n**Standalone code to reproduce the issue**\r\nHere's the colab [notebook](https://colab.research.google.com/drive/1PNSURh-Hhd2CtQ5vn82lG0rsJjYkYPqR?usp=sharing) for the original version(numpy, no `tf.function`)\r\n\r\nHere's the less performant / worse version colab [notebook](https://colab.research.google.com/drive/1qSzJSepVSYyA3dRpdpgHo2cRWeOg2nSJ?usp=sharing)\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["@emadboctorx \r\nI ran the code shared in the notebook but do not face any errors please find [gist here](https://colab.research.google.com/gist/Saduf2019/9ded64a8ca6d8fab5827772d5afa7729/untitled491.ipynb).", "@Saduf2019 That's because you ran the good version, now try running the bad [version](https://colab.research.google.com/drive/1qSzJSepVSYyA3dRpdpgHo2cRWeOg2nSJ?usp=sharing) which I included in the description above, you should experience a severe slowdown (no errors)", "@emadboctorx Try this. https://colab.research.google.com/drive/1JjEcnSnGCd_Jkqw-6LYNtJ7PcEs0FTgH?usp=sharing", "@WindQAQ I remember telling you a couple of days back you're a life saver! what was the problem? the speed almost doubled with your version, can you tell me how did you fix it, in order for me to follow the same steps in the future?", "@emadboctorx  I find two points\r\n\r\n1. `tf.keras.Model.train_on_batch()` introduces incredible overhead in your case. Using custom training loop can be much faster.\r\n2. In `get_action`, you are using `tf.keras.Model.predict` on a single batch of data. Using `tf.keras.Model.predict_on_batch` is much faster.\r\n\r\nI haven't digged into why though.", "Thanks anyway, that totally fixes the problem. Also you added this line in the model creation method, I never have seen it before.\r\n\r\n```\r\n    model.call = tf.function(model.call)\r\n```", "It's used to decorate the call function with `tf.function`. It does not matter if your outer function is decorated with `tf.function` though. If you are using `{train,test,predict}` or `{train,test,predict}_on_batch`, it is natively decorated with `tf.function` because you are compiling the model with `run_eagerly=False`. However, nested `tf.function` might or might not improve the performance. It depends on if the function is inlined.", "The problem is that `train_on_batch` will generate a `tf.data.Dataset` placed on CPU (actutally this is always located on CPU). Therefore, it will first create a tensor on CPU, and then transfer to GPU for training. The data transferring cost from host to device is not negligible especially for large tensor (in your case (32, 84, 84, 1)). Note that this is not going to say `tf.data.Dataset` is bad. It's super powerful to hide the latency of loading data when it comes to large dataset.\r\n\r\nTensorFlow enables soft device placement by default. So if you are using GPU for training, make sure that the ops are computed on the correct device :-)\r\n\r\nhttps://colab.research.google.com/drive/1s6O4MyfqyCFI8uEM6JlTVNF18BLvYfka?usp=sharing", "That's almost 3x the speed of `model.train_on_batch()`. And yes I'm familiar with `tf.data.Dataset` I totally rely on the api for training supervised learning models using tfrecords, it's ultra-convenient, flexible and efficient, but unfortunately, this cannot be applied to online learning which is the case here, because the dataset constantly changes as the training progresses. I want to improve the performance and maybe parallelize the training process, I'm trying to figure out how. "]}, {"number": 46125, "title": "Unhandled Rejecting Error ~ Implicit Shape Can't Be a Fractional Number", "body": "Hello everyone, sos\r\n\r\nI am following an online tutorial on how to run gesture recognition using react and tensor flow. However, I am always seeing this error whenever I play around with the webcam in chrome.\r\n\r\nHere is my github for what I am working on btw. And here is the tutorial video I'm watching. I got stuck right around minute 10\r\n\r\nhttps://github.com/riccrdo5/help\r\n\r\nhttps://youtu.be/f7uBsb-0sGQ\r\n\r\nTy and happy holidays\r\n\r\n![ErrorVSC](https://user-images.githubusercontent.com/67179440/103488631-02733c00-4dc3-11eb-81d1-70c75b9f9ffa.png)\r\n![ErrorWeb](https://user-images.githubusercontent.com/67179440/103488632-043cff80-4dc3-11eb-8446-0a80b0258b26.jpg)\r\n", "comments": ["@riccrdo5 \r\n\r\nPlease, refer this SO [link](https://stackoverflow.com/questions/63421470/the-implicit-shape-cant-be-a-fractional-number) and see if it helps you.\r\nIf the issue still persists please share the exact sequence of commands / steps that you executed before running into the problem and complete error log. Thanks!", "I looked over that stackoverflow page before and it did not provide me with any insight.  All I really did was import react and tensorflow. Here is my js:\r\n\r\n![image](https://user-images.githubusercontent.com/67179440/103801583-c7f7e200-5002-11eb-9599-2d522e5bae4d.png)\r\n\r\nThanks", "@riccrdo5 \r\nThis issue is more suitable for TFjs repo. Please post it on TFjs repo from [here.](https://github.com/tensorflow/tfjs/issues/new) Thanks!", "thanks for the advice. best wishes", "@riccrdo5 \r\n\r\nCan we close the issue here and track the issue in [TFjs repo](https://github.com/tensorflow/tfjs/issues/new).Thanks!", "Yess, thanks for the help\n\nOn Thu, Jan 7, 2021 at 12:13 AM ravikyram <notifications@github.com> wrote:\n\n> @riccrdo5 <https://github.com/riccrdo5>\n>\n> Can we close the issue here and track the issue in TFjs repo\n> <https://github.com/tensorflow/tfjs/issues/new>.Thanks!\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/46125#issuecomment-755958950>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AQARHMGQDMFPWRTPGVSZTZ3SYVULRANCNFSM4VSFL7OQ>\n> .\n>\n", "I am closing the issue here and the issue can be tracked in TFjs repo. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46125\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46125\">No</a>\n"]}, {"number": 46124, "title": "Installation/Import issue. Help required.", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n  -  OS Name:                   Microsoft Windows 10 Home Single Language\r\n  -  OS Version:                10.0.18363 N/A Build 18363\r\n  -  OS Manufacturer:           Microsoft Corporation\r\n  -  OS Configuration:          Standalone Workstation\r\n  -  OS Build Type:             Multiprocessor Free\r\n\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version: 2.x\r\n- Python version: 3.7.3\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source): NA\r\n- GCC/Compiler version (if compiling from source): NA\r\n- CUDA/cuDNN version: NA\r\n- GPU model and memory: NA\r\n\r\n\r\n\r\n**Installed without any issue. But when trying to import, ImportError occurs.**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n 1. ```pip install tensorflow --verbose --user```\r\n 2. Then opened a .py file with first and only line as : ```import tensorflow```\r\n 3. Saved the .py file and opened a new cmd window in the same directory.\r\n 4. Executed ```python name_of_the_file.py```\r\n\r\n\r\n**Any other info / logs**\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\ddsme\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 64, in <\r\nmodule>\r\n    from tensorflow.python._pywrap_tensorflow_internal import *\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Users\\ddsme\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\__init__.py\", line 41, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"C:\\Users\\ddsme\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\__init__.py\", line 39, in <module>\r\n    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\r\n  File \"C:\\Users\\ddsme\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 83, in <\r\nmodule>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\ddsme\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 64, in <\r\nmodule>\r\n    from tensorflow.python._pywrap_tensorflow_internal import *\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.", "comments": ["**Update**\r\nInstalling _'Microsoft Visual C++ Redistributable for Visual Studio 2015, 2017 and 2019'_ solved the issue.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46124\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46124\">No</a>\n"]}, {"number": 46122, "title": "Update README.md", "body": "modified README.md of benchmark as default value of disable_nnapi_cpu parameter changed to true", "comments": []}, {"number": 46121, "title": "always got the time out when try to download upb file. ", "body": "Firstly try to build TP  2.3 branch in windows 10 using the following command, always got the time out when download upb file. \r\ncan I manully download the file or disable the download operation? or modify the connect_time_out option?\r\nbazel build //tensorflow/tools/pip_package:build_pip_package\r\nERROR: no such package '@upb//bazel': java.io.IOException: Error downloading [https://github.com/protocolbuffers/upb/archive/9effcbcb27f0a665f9f345030188c0b291e32482.tar.gz] to C:/users/86178/_bazel_86178/26orbg4z/external/upb/9effcbcb27f0a665f9f345030188c0b291e32482.tar.gz: connect timed out\r\nINFO: Elapsed time: 69.014s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (0 packages loaded)", "comments": ["system information\r\n\r\n    OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n    TensorFlow installed from (source or binary): source\r\n    TensorFlow version: v2.3.0\r\n    Python version: CPython 3.8\r\n    Installed using virtualenv? pip? conda?: conda\r\n    Bazel version (if compiling from source): download bazel-3.1.0-windows-x86_64.exe\r\n \r\n", "I tried to download https://github.com/protocolbuffers/upb/archive/9effcbcb27f0a665f9f345030188c0b291e32482.tar.gz directly using IE, got the file- upb-9effcbcb27f0a665f9f345030188c0b291e32482.tar.gz. Then put to the filefolder - C:/users/86178/_bazel_86178/26orbg4z/external/upb.\r\nbut after type the command - bazel build //tensorflow/tools/pip_package:build_pip_package,\r\nit will automatically delete the files in filefolder - C:/users/86178/_bazel_86178/26orbg4z/external/upb. \r\nquestoin: How to disable the \"delete\" behaviour?\r\n", "The tf supporters are probably all on Christmas or new years break because they are not responding to any of the latest issues being raised. ", "> \r\n> \r\n> The tf supporters are probably all on Christmas or new years break because they are not responding to any of the latest issues being raised.\r\n\r\nHappy new year. I am not familar with bazel command options.......", "INFO: Found applicable config definition build:windows in file d:\\tensorflow\\.bazelrc: --copt=/w --copt=/D_USE_MATH_DEFINES --host_copt=/D_USE_MATH_DEFINES --cxxopt=/std:c++14 --host_cxxopt=/std:c++14 --config=monolithic --copt=-DWIN32_LEAN_AND_MEAN --host_copt=-DWIN32_LEAN_AND_MEAN --copt=-DNOGDI --host_copt=-DNOGDI --linkopt=/DEBUG --host_linkopt=/DEBUG --linkopt=/OPT:REF --host_linkopt=/OPT:REF --linkopt=/OPT:ICF --host_linkopt=/OPT:ICF --experimental_strict_action_env=true --verbose_failures --distinct_host_configuration=false\r\nINFO: Found applicable config definition build:monolithic in file d:\\tensorflow\\.bazelrc: --define framework_shared_object=false\r\nINFO: Repository upb instantiated at:\r\n  no stack (--record_rule_instantiation_callstack not enabled)\r\nRepository rule http_archive defined at:\r\n  C:/users/86178/_bazel_86178/26orbg4z/external/bazel_tools/tools/build_defs/repo/http.bzl:336:16: in <toplevel>\r\nWARNING: Download from https://github.com/protocolbuffers/upb/archive/9effcbcb27f0a665f9f345030188c0b291e32482.tar.gz failed: class java.io.IOException connect timed out\r\nERROR: An error occurred during the fetch of repository 'upb':\r\n   java.io.IOException: Error downloading [https://github.com/protocolbuffers/upb/archive/9effcbcb27f0a665f9f345030188c0b291e32482.tar.gz] to C:/users/86178/_bazel_86178/26orbg4z/external/upb/9effcbcb27f0a665f9f345030188c0b291e32482.tar.gz: connect timed out\r\nERROR: no such package '@upb//bazel': java.io.IOException: Error downloading [https://github.com/protocolbuffers/upb/archive/9effcbcb27f0a665f9f345030188c0b291e32482.tar.gz] to C:/users/86178/_bazel_86178/26orbg4z/external/upb/9effcbcb27f0a665f9f345030188c0b291e32482.tar.gz: connect timed out\r\nINFO: Elapsed time: 56.606s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (0 packages loaded)\r\n\r\n(base) D:\\tensorflow>", "@huangyhg \r\n\r\nPlease, refer similar issues #37811 , [link](https://github.com/bazelbuild/bazel/issues/3737) and see if it helps you. Thanks!", "> \r\n> \r\n> @huangyhg\r\n> \r\n> Please, refer similar issues #37811 , [link](https://github.com/bazelbuild/bazel/issues/3737) and see if it helps you. Thanks!\r\n\r\nyw, what is \" .netrc setup\"?\r\n I need use IE with one proxy to download the file manully .", "https://raw.githubusercontent.com/vokins/yhosts/master/hosts\r\nsolved", "@huangyhg,\r\nClosing this issue as it is resolved. Thanks! ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46121\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46121\">No</a>\n", "yw, please close it, thanks."]}, {"number": 46120, "title": "Bazel out of memory at checking cache actions when building for ARMv8", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n### System information\r\n- OS Platform and Distribution: Ubuntu 20.04\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: v2.4.0\r\n- Python version: 3.8\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source): 3.7.2\r\n- GCC/Compiler version (if compiling from source): 9.3.0\r\n- CUDA/cuDNN version: None\r\n- GPU model and memory: None\r\n\r\n### Describe the problem\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nHello.\r\n\r\nI am tried to build tensorflow v2.4.0 from source for aarch64 / ARMv8 devices. I did this on a quad core A53 single board with 1GB RAM.\r\n\r\nThe process was always terminated at the time when about 3000 targets were done. At that moment, Bazel showed **Checking cache actions**, stuck for a while and raise java out of memory error.\r\n\r\nI thought that the RAM and swap might be not enough, so I picked a 8GB USB drive and use it as swap. But the building process still crashed.\r\n\r\nSo, how much memory does it need when building tensorflow? Should I at least double the swap size, or any step is wrong?\r\n\r\nThank you.\r\n", "comments": ["Can you try to test with https://docs.bazel.build/versions/3.1.0/memory-saving-mode.html?", "> Can you try to test with https://docs.bazel.build/versions/3.1.0/memory-saving-mode.html?\r\n\r\nThank you. \r\n\r\nI've tried `--host_jvm_args=-Xmx512m` before and failed. I'll try `--host_jvm_args=-Xmx8g` now...", "Note that likely this is not a TF bug.", "@mihaimaruseac many people want to have this Documented. E.g. see https://github.com/tensorflow/tensorflow/issues/42066", "### Status Update\r\n\r\nSince 3 days ago I have been trying to build with this flag. \r\n\r\n`bazel --host_jvm_args=-Xmx8g build //tensorflow/tools/pip_package:build_pip_package --local_cpu_resources=1`\r\n\r\nThe building process has crushed for roughly 10 times, but only one of them is **`java.lang.OutOfMemoryError: Java heap space`**:\r\n\r\n```\r\nroot@cacd588b8a9d:~/tensorflow/tf# bazel build //tensorflow/tools/pip_package:build_pip_package\r\nStarting local Bazel server and connecting to it...\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=156\r\nINFO: Reading rc options for 'build' from /root/tensorflow/tf/.bazelrc:\r\n  Inherited 'common' options: --experimental_repo_remote_exec\r\nINFO: Reading rc options for 'build' from /root/tensorflow/tf/.bazelrc:\r\n  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=tensorflow_enable_mlir_generated_gpu_kernels=0 --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=short_logs --config=v2\r\nINFO: Reading rc options for 'build' from /root/tensorflow/tf/.tf_configure.bazelrc:\r\n  'build' options: --action_env PYTHON_BIN_PATH=/usr/bin/python3 --action_env PYTHON_LIB_PATH=/usr/lib/python3/dist-packages --python_path=/usr/bin/python3 --config=xla --action_env TF_CONFIGURE_IOS=0\r\nINFO: Found applicable config definition build:short_logs in file /root/tensorflow/tf/.bazelrc: --output_filter=DONT_MATCH_ANYTHING\r\nINFO: Found applicable config definition build:v2 in file /root/tensorflow/tf/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1\r\nINFO: Found applicable config definition build:xla in file /root/tensorflow/tf/.bazelrc: --define=with_xla_support=true\r\nINFO: Found applicable config definition build:linux in file /root/tensorflow/tf/.bazelrc: --copt=-w --host_copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels\r\nINFO: Found applicable config definition build:dynamic_kernels in file /root/tensorflow/tf/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS\r\nINFO: Analyzed target //tensorflow/tools/pip_package:build_pip_package (404 packages loaded, 30546 targets configured).\r\nINFO: Found 1 target...\r\nERROR: /root/tensorflow/tf/tensorflow/python/BUILD:733:27: C++ compilation of rule '//tensorflow/python:_pywrap_tfprof.so' failed (Exit 1): gcc failed: error executing command /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections ... (remaining 119 argument(s) skipped)\r\ntensorflow/python/util/tfprof_wrapper.cc: In constructor 'pybind11::cpp_function::cpp_function(Func&&, const Extra& ...) [with Func = pybind11::detail::all_type_info_get_cache(PyTypeObject*)::<lambda(pybind11::handle)>; Extra = {}; <template-parameter-1-3> = void]':\r\ntensorflow/python/util/tfprof_wrapper.cc:46:1: internal compiler error: Segmentation fault\r\n   46 | }\r\n      | ^\r\nPlease submit a full bug report,\r\nwith preprocessed source if appropriate.\r\nSee <file:///usr/share/doc/gcc-9/README.Bugs> for instructions.\r\nInternal error thrown during build. Printing stack trace: java.lang.OutOfMemoryError: Java heap space\r\n        at java.base/java.util.Arrays.copyOfRange(Unknown Source)\r\n        at java.base/java.lang.StringCoding.decodeLatin1(Unknown Source)\r\n        at java.base/java.lang.StringCoding.decode(Unknown Source)\r\n        at java.base/java.lang.String.<init>(Unknown Source)\r\n        at java.base/java.lang.String.<init>(Unknown Source)\r\n        at com.google.devtools.build.lib.analysis.actions.FileWriteAction$CompressedString.toString(FileWriteAction.java:210)\r\n        at com.google.devtools.build.lib.analysis.actions.FileWriteAction.getFileContents(FileWriteAction.java:231)\r\n        at com.google.devtools.build.lib.analysis.actions.FileWriteAction.computeKey(FileWriteAction.java:261)\r\n        at com.google.devtools.build.lib.actions.ActionKeyCacher.computeActionKey(ActionKeyCacher.java:52)\r\n        at com.google.devtools.build.lib.actions.ActionKeyCacher.getKey(ActionKeyCacher.java:41)\r\n        at com.google.devtools.build.lib.actions.ActionCacheChecker.mustExecute(ActionCacheChecker.java:343)\r\n        at com.google.devtools.build.lib.actions.ActionCacheChecker.getTokenIfNeedToExecute(ActionCacheChecker.java:292)\r\n        at com.google.devtools.build.lib.skyframe.SkyframeActionExecutor.checkActionCache(SkyframeActionExecutor.java:576)\r\n        at com.google.devtools.build.lib.skyframe.ActionExecutionFunction.checkCacheAndExecuteIfNeeded(ActionExecutionFunction.java:765)\r\n        at com.google.devtools.build.lib.skyframe.ActionExecutionFunction.compute(ActionExecutionFunction.java:314)\r\n        at com.google.devtools.build.skyframe.AbstractParallelEvaluator$Evaluate.run(AbstractParallelEvaluator.java:438)\r\n        at com.google.devtools.build.lib.concurrent.AbstractQueueVisitor$WrappedRunnable.run(AbstractQueueVisitor.java:398)\r\n        at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n        at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n        at java.base/java.lang.Thread.run(Unknown Source)\r\n\r\nERROR: bazel crash in async thread:\r\njava.lang.OutOfMemoryError: Java heap space\r\n        at com.google.common.io.ByteStreams.toByteArrayInternal(ByteStreams.java:176)\r\n        at com.google.common.io.ByteStreams.toByteArray(ByteStreams.java:221)\r\n        at com.google.common.io.ByteSource.read(ByteSource.java:286)\r\n        at com.google.devtools.build.lib.vfs.FileSystemUtils.readContent(FileSystemUtils.java:820)\r\n        at com.google.devtools.build.lib.vfs.FileSystemUtils.readContentAsLatin1(FileSystemUtils.java:789)\r\n        at com.google.devtools.build.lib.server.PidFileWatcher.pidFileValid(PidFileWatcher.java:100)\r\n        at com.google.devtools.build.lib.server.PidFileWatcher.runPidFileChecks(PidFileWatcher.java:77)\r\n        at com.google.devtools.build.lib.server.PidFileWatcher.run(PidFileWatcher.java:68)\r\n[2,595 / 2,848] checking cached actions\r\n\r\nServer terminated abruptly (error code: 14, error message: 'Socket closed', log file: '/root/.cache/bazel/_bazel_root/2e11e70b086253c0d6d49f106d1e85c5/server/jvm.out')\r\n```\r\n\r\nAnd the rest are **`internal compiler error: Segmentation fault`**:\r\n\r\n```\r\nINFO: Deleting stale sandbox base /root/.cache/bazel/_bazel_root/2e11e70b086253c0d6d49f106d1e85c5/sandbox\r\n[5,864 / 7,381] 4 actions, 1 running\r\n    Compiling tensorflow/core/grappler/optimizers/function_optimizer.cc; 427s local\r\n    [Sched] Compiling tensorflow/core/grappler/optimizers/dependency_optimizer.cc; 427s\r\n    [Sched] Compiling aws/aws-cpp-sdk-core/source/auth/AWSCredentialsProvider.cpp; 426s\r\n    [Sched] Compiling tensorflow/core/grappler/utils/transitive_fanin.cc; 426s\r\n  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=tensorflow_enable_mlir_generated_gpu_kernels=0 --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=short_logs --config=v2\r\nINFO: Reading rc options for 'build' from /root/tensorflow/tf/.tf_configure.bazelrc:\r\n  'build' options: --action_env PYTHON_BIN_PATH=/usr/bin/python3 --action_env PYTHON_LIB_PATH=/usr/lib/python3.8/dist-packages --python_path=/usr/bin/python3 --config=xla --action_env TF_CONFIGURE_IOS=0\r\nINFO: Found applicable config definition build:short_logs in file /root/tensorflow/tf/.bazelrc: --output_filter=DONT_MATCH_ANYTHING\r\nINFO: Found applicable config definition build:v2 in file /root/tensorflow/tf/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1\r\nINFO: Found applicable config definition build:xla in file /root/tensorflow/tf/.bazelrc: --define=with_xla_support=true\r\nINFO: Found applicable config definition build:linux in file /root/tensorflow/tf/.bazelrc: --copt=-w --host_copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels\r\nINFO: Found applicable config definition build:dynamic_kernels in file /root/tensorflow/tf/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS\r\nINFO: Analyzed target //tensorflow/tools/pip_package:build_pip_package (404 packages loaded, 30546 targets configured).\r\nINFO: Found 1 target...\r\nINFO: Deleting stale sandbox base /root/.cache/bazel/_bazel_root/2e11e70b086253c0d6d49f106d1e85c5/sandbox\r\nERROR: /root/tensorflow/tf/tensorflow/core/grappler/optimizers/BUILD:159:11: C++ compilation of rule '//tensorflow/core/grappler/optimizers:function_optimizer' failed (Exit 1): gcc failed: error executing command /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections ... (remaining 95 argument(s) skipped)\r\ntensorflow/core/grappler/optimizers/function_optimizer.cc: In member function 'tensorflow::Status tensorflow::grappler::FunctionOptimizer::RunFunctionOptimizerPass(const tensorflow::grappler::GrapplerItem&, tensorflow::GraphDef*) const':\r\ntensorflow/core/grappler/optimizers/function_optimizer.cc:1429:8: internal compiler error: Segmentation fault\r\n 1429 | Status FunctionOptimizer::RunFunctionOptimizerPass(\r\n      |        ^~~~~~~~~~~~~~~~~\r\nPlease submit a full bug report,\r\nwith preprocessed source if appropriate.\r\nSee <file:///usr/share/doc/gcc-9/README.Bugs> for instructions.\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 6347.840s, Critical Path: 568.99s\r\nINFO: 588 processes: 17 internal, 571 local.\r\nFAILED: Build did NOT complete successfully\r\n```\r\n\r\n```\r\nroot@cacd588b8a9d:~/tensorflow/tf# bazel --host_jvm_args=-Xmx8g build //tensorflow/tools/pip_package:build_pip_package --local_cpu_resources=1\r\nKilled non-responsive server process (pid=35)\r\nStarting local Bazel server and connecting to it...\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=111\r\nINFO: Reading rc options for 'build' from /root/tensorflow/tf/.bazelrc:\r\n  Inherited 'common' options: --experimental_repo_remote_exec\r\nINFO: Reading rc options for 'build' from /root/tensorflow/tf/.bazelrc:\r\n  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=tensorflow_enable_mlir_generated_gpu_kernels=0 --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=short_logs --config=v2\r\nINFO: Reading rc options for 'build' from /root/tensorflow/tf/.tf_configure.bazelrc:\r\n  'build' options: --action_env PYTHON_BIN_PATH=/usr/bin/python3 --action_env PYTHON_LIB_PATH=/usr/lib/python3.8/dist-packages --python_path=/usr/bin/python3 --config=xla --action_env TF_CONFIGURE_IOS=0\r\nINFO: Found applicable config definition build:short_logs in file /root/tensorflow/tf/.bazelrc: --output_filter=DONT_MATCH_ANYTHING\r\nINFO: Found applicable config definition build:v2 in file /root/tensorflow/tf/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1\r\nINFO: Found applicable config definition build:xla in file /root/tensorflow/tf/.bazelrc: --define=with_xla_support=true\r\nINFO: Found applicable config definition build:linux in file /root/tensorflow/tf/.bazelrc: --copt=-w --host_copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels\r\nINFO: Found applicable config definition build:dynamic_kernels in file /root/tensorflow/tf/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS\r\nINFO: Analyzed target //tensorflow/tools/pip_package:build_pip_package (404 packages loaded, 30546 targets configured).\r\nINFO: Found 1 target...\r\nERROR: /root/tensorflow/tf/tensorflow/core/grappler/optimizers/BUILD:659:11: C++ compilation of rule '//tensorflow/core/grappler/optimizers:meta_optimizer' failed (Exit 1): gcc failed: error executing command /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections ... (remaining 109 argument(s) skipped)\r\nIn file included from external/com_google_absl/absl/container/flat_hash_map.h:41,\r\n                 from ./tensorflow/core/framework/function.h:26,\r\n                 from ./tensorflow/core/graph/graph.h:45,\r\n                 from ./tensorflow/core/framework/device.h:44,\r\n                 from ./tensorflow/core/common_runtime/device.h:18,\r\n                 from ./tensorflow/core/common_runtime/device_set.h:23,\r\n                 from ./tensorflow/core/grappler/optimizers/meta_optimizer.h:19,\r\n                 from tensorflow/core/grappler/optimizers/meta_optimizer.cc:16:\r\nexternal/com_google_absl/absl/container/internal/raw_hash_map.h: In instantiation of 'std::pair<typename absl::lts_2020_02_25::container_internal::raw_hash_map<Policy, Hash, Eq, Alloc>::raw_hash_set::iterator, bool> absl::lts_2020_02_25::container_internal::raw_hash_map<Policy, Hash, Eq, Alloc>::try_emplace_impl(K&&, Args&& ...) [with K = std::__cxx11::basic_string<char>; Args = {}; Policy = absl::lts_2020_02_25::container_internal::NodeHashMapPolicy<std::__cxx11::basic_string<char>, absl::lts_2020_02_25::flat_hash_set<tensorflow::NodeDef*> >; Hash = absl::lts_2020_02_25::container_internal::StringHash; Eq = absl::lts_2020_02_25::container_internal::StringHashEq::Eq; Alloc = std::allocator<std::pair<const std::__cxx11::basic_string<char>, absl::lts_2020_02_25::flat_hash_set<tensorflow::NodeDef*> > >; typename absl::lts_2020_02_25::container_internal::raw_hash_map<Policy, Hash, Eq, Alloc>::raw_hash_set::iterator = absl::lts_2020_02_25::container_internal::raw_hash_set<absl::lts_2020_02_25::container_internal::NodeHashMapPolicy<std::__cxx11::basic_string<char>, absl::lts_2020_02_25::flat_hash_set<tensorflow::NodeDef*> >, absl::lts_2020_02_25::container_internal::StringHash, absl::lts_2020_02_25::container_internal::StringHashEq::Eq, std::allocator<std::pair<const std::__cxx11::basic_string<char>, absl::lts_2020_02_25::flat_hash_set<tensorflow::NodeDef*> > > >::iterator]':\r\nexternal/com_google_absl/absl/container/internal/raw_hash_map.h:121:76:   required from 'std::pair<typename absl::lts_2020_02_25::container_internal::raw_hash_map<Policy, Hash, Eq, Alloc>::raw_hash_set::iterator, bool> absl::lts_2020_02_25::container_internal::raw_hash_map<Policy, Hash, Eq, Alloc>::try_emplace(absl::lts_2020_02_25::container_internal::raw_hash_map<Policy, Hash, Eq, Alloc>::key_arg<K>&&, Args&& ...) [with K = std::__cxx11::basic_string<char>; Args = {}; typename std::enable_if<(! std::is_convertible<K, typename absl::lts_2020_02_25::container_internal::raw_hash_map<Policy, Hash, Eq, Alloc>::raw_hash_set::const_iterator>::value), int>::type <anonymous> = 0; K* <anonymous> = 0; Policy = absl::lts_2020_02_25::container_internal::NodeHashMapPolicy<std::__cxx11::basic_string<char>, absl::lts_2020_02_25::flat_hash_set<tensorflow::NodeDef*> >; Hash = absl::lts_2020_02_25::container_internal::StringHash; Eq = absl::lts_2020_02_25::container_internal::StringHashEq::Eq; Alloc = std::allocator<std::pair<const std::__cxx11::basic_string<char>, absl::lts_2020_02_25::flat_hash_set<tensorflow::NodeDef*> > >; typename absl::lts_2020_02_25::container_internal::raw_hash_map<Policy, Hash, Eq, Alloc>::raw_hash_set::iterator = absl::lts_2020_02_25::container_internal::raw_hash_set<absl::lts_2020_02_25::container_internal::NodeHashMapPolicy<std::__cxx11::basic_string<char>, absl::lts_2020_02_25::flat_hash_set<tensorflow::NodeDef*> >, absl::lts_2020_02_25::container_internal::StringHash, absl::lts_2020_02_25::container_internal::StringHashEq::Eq, std::allocator<std::pair<const std::__cxx11::basic_string<char>, absl::lts_2020_02_25::flat_hash_set<tensorflow::NodeDef*> > > >::iterator; absl::lts_2020_02_25::container_internal::raw_hash_map<Policy, Hash, Eq, Alloc>::key_arg<K> = std::__cxx11::basic_string<char>]'\r\nexternal/com_google_absl/absl/container/internal/raw_hash_map.h:163:62:   required from 'absl::lts_2020_02_25::container_internal::raw_hash_map<Policy, Hash, Eq, Alloc>::MappedReference<P> absl::lts_2020_02_25::container_internal::raw_hash_map<Policy, Hash, Eq, Alloc>::operator[](absl::lts_2020_02_25::container_internal::raw_hash_map<Policy, Hash, Eq, Alloc>::key_arg<K>&&) [with K = std::__cxx11::basic_string<char>; P = absl::lts_2020_02_25::container_internal::NodeHashMapPolicy<std::__cxx11::basic_string<char>, absl::lts_2020_02_25::flat_hash_set<tensorflow::NodeDef*> >; K* <anonymous> = 0; Policy = absl::lts_2020_02_25::container_internal::NodeHashMapPolicy<std::__cxx11::basic_string<char>, absl::lts_2020_02_25::flat_hash_set<tensorflow::NodeDef*> >; Hash = absl::lts_2020_02_25::container_internal::StringHash; Eq = absl::lts_2020_02_25::container_internal::StringHashEq::Eq; Alloc = std::allocator<std::pair<const std::__cxx11::basic_string<char>, absl::lts_2020_02_25::flat_hash_set<tensorflow::NodeDef*> > >; absl::lts_2020_02_25::container_internal::raw_hash_map<Policy, Hash, Eq, Alloc>::MappedReference<P> = absl::lts_2020_02_25::flat_hash_set<tensorflow::NodeDef*>&; typename absl::lts_2020_02_25::container_internal::raw_hash_map<Policy, Hash, Eq, Alloc>::reference = std::pair<const std::__cxx11::basic_string<char>, absl::lts_2020_02_25::flat_hash_set<tensorflow::NodeDef*> >&; absl::lts_2020_02_25::container_internal::raw_hash_map<Policy, Hash, Eq, Alloc>::key_arg<K> = std::__cxx11::basic_string<char>]'\r\n./tensorflow/core/grappler/utils.h:126:17:   required from 'tensorflow::grappler::internal::NodeMapInternal<GraphDefT, NodeDefT>::NodeMapInternal(GraphDefT*) [with GraphDefT = tensorflow::GraphDef; NodeDefT = tensorflow::NodeDef]'\r\n./tensorflow/core/grappler/utils.h:235:60:   required from here\r\nexternal/com_google_absl/absl/container/internal/raw_hash_map.h:190:3: internal compiler error: Segmentation fault\r\n  190 |   }\r\n      |   ^\r\nPlease submit a full bug report,\r\nwith preprocessed source if appropriate.\r\nSee <file:///usr/share/doc/gcc-9/README.Bugs> for instructions.\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 2289.998s, Critical Path: 678.29s\r\nINFO: 40 processes: 5 internal, 35 local.\r\nFAILED: Build did NOT complete successfully\r\n```\r\n\r\nEach time the file that raised error are not same.\r\n\r\nThis might not be caused by out of memory, as far as I think. So this issue could be closed. I'll try to find solutions or create a new issue about that. Thank you!\r\n\r\n---\r\n\r\nP.S.: Every time I start building, `bazel` seems to start building from the beginning. I've seen some components to be compiled for more than 3 times. That's weird and different from most compilers, which could be continued from where they stops, as I know.", "For that board board It Is more the case to build and use TF lite:\n\nhttps://www.tensorflow.org/lite/guide/build_arm64?hl=en", "> For that board board It Is more the case to build and use TF lite:\r\n> \r\n> https://www.tensorflow.org/lite/guide/build_arm64?hl=en\r\n\r\nThank you. Tensorflow Lite could be successfully built on the board, and I just want to try if the whole package can be built. \r\n\r\nI've found this nice repo [lhelontra/tensorflow-on-arm](https://github.com/lhelontra/tensorflow-on-arm) and successfully cross-compiled a working `whl` of `tensorflow` v2.4.0.\r\n\r\nI would conclude this issue as an impossibile trial due to hardware restrictions. Thanks for the help again!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46120\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46120\">No</a>\n"]}, {"number": 46119, "title": "Will TensorFlow update new optimizer?: Adabelief", "body": "**System information**\r\n- TensorFlow version (you are using): 2.3.1\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\nI have read this article and it is quite interesting? At this time, I use Adam optimizer in TensorFlow but the current accuracy is just 88%. The Adabelief gave me an idea about getting the model accuracy to be over 90% which inspires me. Thus I am wondering will TensorFlow will update this? Thank you\r\n\r\nhttps://medium.com/the-dl/understanding-the-new-adabelief-optimizer-2db70ef6de1e\r\nhttps://arxiv.org/pdf/1412.6980.pdf\r\n", "comments": ["Check:\r\nhttps://github.com/tensorflow/addons/issues/2203\r\nhttps://github.com/tensorflow/addons/pull/2234\r\n\r\n/cc @tomerk ", "I think we can close this feature from here and track the progress in `addons` as that is the right repo for new optimizers. Thanks!\r\n"]}, {"number": 46118, "title": "[Build] Building on Windows 10 fails with Bad address error", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): _Windows 10_\r\n- TensorFlow installed from (source or binary): _source_\r\n- TensorFlow version: _v2.3.0_\r\n- Python version: _CPython 3.8_\r\n- Installed using virtualenv? pip? conda?: _pip_\r\n- Bazel version (if compiling from source): _3.7.0_\r\n- CUDA version: _10.1_\r\n- cuDNN version: _7.6.5_\r\n- GPU model and memory: _GeForce GTX 760_\r\n\r\n\r\n**Describe the problem**\r\nFailed with error _Bad address_\r\n\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n```console\r\nPS C:\\tensorflow> python.exe .\\configure.py\r\nYou have bazel 3.7.0 installed.\r\nPlease specify the location of python. [Default is C:\\Python\\CPython38\\python.exe]:\r\n\r\nFound possible Python library paths:\r\n  C:\\Python\\CPython38\\lib\\site-packages\r\nPlease input the desired Python library path to use.  Default is [C:\\Python\\CPython38\\lib\\site-packages]\r\n\r\nDo you wish to build TensorFlow with ROCm support? [y/N]:\r\nNo ROCm support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with CUDA support? [y/N]: Y\r\nCUDA support will be enabled for TensorFlow.\r\n\r\nCould not find any cudnn.h, cudnn_version.h matching version '' in any subdirectory:\r\n        ''\r\n        'include'\r\n        'include/cuda'\r\n        'include/*-linux-gnu'\r\n        'extras/CUPTI/include'\r\n        'include/cuda/CUPTI'\r\n        'local/cuda/extras/CUPTI/include'\r\nof:\r\n        'C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.1'\r\nAsking for detailed CUDA configuration...\r\n\r\nPlease specify the CUDA SDK version you want to use. [Leave empty to default to CUDA 10]: 10.1\r\n\r\nPlease specify the cuDNN version you want to use. [Leave empty to default to cuDNN 7]: 7.6.5\r\n\r\nPlease specify the comma-separated list of base paths to look for CUDA libraries and headers. [Leave empty to use the default]: C:/tools/cuda,C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1\r\n\r\nFound CUDA 10.1 in:\r\n    C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1/lib/x64\r\n    C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1/include\r\nFound cuDNN 7 in:\r\n    C:/tools/cuda/lib/x64\r\n    C:/tools/cuda/include\r\n\r\nPlease specify a list of comma-separated CUDA compute capabilities you want to build with.\r\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus. Each capability can be specified as \"x.y\" or \"compute_xy\" to include both virtual and binary GPU code, or as \"sm_xy\" to only include the binary code.\r\nPlease note that each additional compute capability significantly increases your build time and binary size, and that TensorFlow only supports compute capabilities >= 3.5 [Default is: 3.5,7.0]: 3.8\r\n\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is /arch:AVX]:\r\n\r\nWould you like to override eigen strong inline for some C++ compilation to reduce the compilation time? [Y/n]:\r\nEigen strong inline overridden.\r\n\r\nWould you like to interactively configure ./WORKSPACE for Android builds? [y/N]:\r\nNot configuring the WORKSPACE for Android builds.\r\n\r\nPreconfigured Bazel build configs. You can use any of the below by adding \"--config=<>\" to your build command. See .bazelrc for more details.\r\n        --config=mkl            # Build with MKL support.\r\n        --config=mkl_aarch64    # Build with oneDNN support for Aarch64.\r\n        --config=monolithic     # Config for mostly static monolithic build.\r\n        --config=ngraph         # Build with Intel nGraph support.\r\n        --config=numa           # Build with NUMA support.\r\n        --config=dynamic_kernels        # (Experimental) Build kernels into separate shared objects.\r\n        --config=v2             # Build TensorFlow 2.x instead of 1.x.\r\nPreconfigured Bazel build configs to DISABLE default on features:\r\n        --config=noaws          # Disable AWS S3 filesystem support.\r\n        --config=nogcp          # Disable GCP support.\r\n        --config=nohdfs         # Disable HDFS support.\r\n        --config=nonccl         # Disable NVIDIA NCCL support.\r\nPS C:\\tensorflow> bazel build //tensorflow/tools/pip_package:build_pip_package\r\nStarting local Bazel server and connecting to it...\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=120\r\nINFO: Reading rc options for 'build' from c:\\tensorflow\\.bazelrc:\r\n  Inherited 'common' options: --experimental_repo_remote_exec\r\nINFO: Options provided by the client:\r\n  'build' options: --python_path=C:/Python/CPython38/python.exe\r\nINFO: Reading rc options for 'build' from c:\\tensorflow\\.bazelrc:\r\n  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=tensorflow_enable_mlir_generated_gpu_kernels=0 --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=short_logs --config=v2\r\nINFO: Reading rc options for 'build' from c:\\tensorflow\\.tf_configure.bazelrc:\r\n  'build' options: --action_env PYTHON_BIN_PATH=C:/Python/CPython38/python.exe --action_env PYTHON_LIB_PATH=C:/Python/CPython38/lib/site-packages --python_path=C:/Python/CPython38/python.exe --config=xla --action_env TF_CUDA_VERSION=10.1 --action_env TF_CUDNN_VERSION=7.6.5 --action_env TF_CUDA_PATHS=C:/tools/cuda,C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1 --action_env CUDA_TOOLKIT_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1 --action_env TF_CUDA_COMPUTE_CAPABILITIES=3.8 --config=cuda --define=override_eigen_strong_inline=true --action_env TF_CONFIGURE_IOS=0\r\nINFO: Found applicable config definition build:short_logs in file c:\\tensorflow\\.bazelrc: --output_filter=DONT_MATCH_ANYTHING\r\nINFO: Found applicable config definition build:v2 in file c:\\tensorflow\\.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1\r\nINFO: Found applicable config definition build:xla in file c:\\tensorflow\\.bazelrc: --define=with_xla_support=true\r\nINFO: Found applicable config definition build:cuda in file c:\\tensorflow\\.bazelrc: --config=using_cuda --define=using_cuda_nvcc=true\r\nINFO: Found applicable config definition build:using_cuda in file c:\\tensorflow\\.bazelrc: --define=using_cuda=true --action_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain --define=tensorflow_enable_mlir_generated_gpu_kernels=1\r\nINFO: Found applicable config definition build:windows in file c:\\tensorflow\\.bazelrc: --copt=/W0 --copt=/D_USE_MATH_DEFINES --host_copt=/D_USE_MATH_DEFINES --cxxopt=/std:c++14 --host_cxxopt=/std:c++14 --config=monolithic --copt=-DWIN32_LEAN_AND_MEAN --host_copt=-DWIN32_LEAN_AND_MEAN --copt=-DNOGDI --host_copt=-DNOGDI --copt=/experimental:preprocessor --host_copt=/experimental:preprocessor --linkopt=/DEBUG --host_linkopt=/DEBUG --linkopt=/OPT:REF --host_linkopt=/OPT:REF --linkopt=/OPT:ICF --host_linkopt=/OPT:ICF --experimental_strict_action_env=true --verbose_failures --distinct_host_configuration=false\r\nINFO: Found applicable config definition build:monolithic in file c:\\tensorflow\\.bazelrc: --define framework_shared_object=false\r\nINFO: Analyzed target //tensorflow/tools/pip_package:build_pip_package (412 packages loaded, 26538 targets configured).\r\nINFO: Found 1 target...\r\nERROR: C:/users/{User}/_bazel_{User}/xv6zejqw/external/libjpeg_turbo/BUILD.bazel:394:8: Executing genrule @libjpeg_turbo//:simd_win_x86_64_assemble failed (Exit 126): bash.exe failed: error executing command\r\n  cd C:/users/{User}/_bazel_{User}/xv6zejqw/execroot/org_tensorflow\r\n  SET CUDA_TOOLKIT_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1\r\n    SET PATH=C:\\msys64\\usr\\bin;C:\\msys64\\bin;C:\\WINDOWS;C:\\WINDOWS\\System32;C:\\WINDOWS\\System32\\WindowsPowerShell\\v1.0\r\n    SET PYTHON_BIN_PATH=C:/Python/CPython38/python.exe\r\n    SET PYTHON_LIB_PATH=C:/Python/CPython38/lib/site-packages\r\n    SET RUNFILES_MANIFEST_ONLY=1\r\n    SET TF2_BEHAVIOR=1\r\n    SET TF_CONFIGURE_IOS=0\r\n    SET TF_CUDA_COMPUTE_CAPABILITIES=3.8\r\n    SET TF_CUDA_PATHS=C:/tools/cuda,C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1\r\n    SET TF_CUDA_VERSION=10.1\r\n    SET TF_CUDNN_VERSION=7.6.5\r\n    SET TF_NEED_CUDA=1\r\n  C:/msys64/usr/bin/bash.exe -c source external/bazel_tools/tools/genrule/genrule-setup.sh; for out in bazel-out/x64_windows-opt/bin/external/libjpeg_turbo/simd/x86_64/jccolor-avx2.obj bazel-out/x64_windows-opt/bin/external/libjpeg_turbo/simd/x86_64/jccolor-sse2.obj bazel-out/x64_windows-opt/bin/external/libjpeg_turbo/simd/x86_64/jcgray-avx2.obj bazel-out/x64_windows-opt/bin/external/libjpeg_turbo/simd/x86_64/jcgray-sse2.obj bazel-out/x64_windows-opt/bin/external/libjpeg_turbo/simd/x86_64/jchuff-sse2.obj bazel-out/x64_windows-opt/bin/external/libjpeg_turbo/simd/x86_64/jcphuff-sse2.obj bazel-out/x64_windows-opt/bin/external/libjpeg_turbo/simd/x86_64/jcsample-avx2.obj bazel-out/x64_windows-opt/bin/external/libjpeg_turbo/simd/x86_64/jcsample-sse2.obj bazel-out/x64_windows-opt/bin/external/libjpeg_turbo/simd/x86_64/jdcolor-avx2.obj bazel-out/x64_windows-opt/bin/external/libjpeg_turbo/simd/x86_64/jdcolor-sse2.obj bazel-out/x64_windows-opt/bin/external/libjpeg_turbo/simd/x86_64/jdmerge-avx2.obj bazel-out/x64_windows-opt/bin/external/libjpeg_turbo/simd/x86_64/jdmerge-sse2.obj bazel-out/x64_windows-opt/bin/external/libjpeg_turbo/simd/x86_64/jdsample-avx2.obj bazel-out/x64_windows-opt/bin/external/libjpeg_turbo/simd/x86_64/jdsample-sse2.obj bazel-out/x64_windows-opt/bin/external/libjpeg_turbo/simd/x86_64/jfdctflt-sse.obj bazel-out/x64_windows-opt/bin/external/libjpeg_turbo/simd/x86_64/jfdctfst-sse2.obj bazel-out/x64_windows-opt/bin/external/libjpeg_turbo/simd/x86_64/jfdctint-avx2.obj bazel-out/x64_windows-opt/bin/external/libjpeg_turbo/simd/x86_64/jfdctint-sse2.obj bazel-out/x64_windows-opt/bin/external/libjpeg_turbo/simd/x86_64/jidctflt-sse2.obj bazel-out/x64_windows-opt/bin/external/libjpeg_turbo/simd/x86_64/jidctfst-sse2.obj bazel-out/x64_windows-opt/bin/external/libjpeg_turbo/simd/x86_64/jidctint-avx2.obj bazel-out/x64_windows-opt/bin/external/libjpeg_turbo/simd/x86_64/jidctint-sse2.obj bazel-out/x64_windows-opt/bin/external/libjpeg_turbo/simd/x86_64/jidctred-sse2.obj bazel-out/x64_windows-opt/bin/external/libjpeg_turbo/simd/x86_64/jquantf-sse2.obj bazel-out/x64_windows-opt/bin/external/libjpeg_turbo/simd/x86_64/jquanti-avx2.obj bazel-out/x64_windows-opt/bin/external/libjpeg_turbo/simd/x86_64/jquanti-sse2.obj bazel-out/x64_windows-opt/bin/external/libjpeg_turbo/simd/x86_64/jsimdcpu.obj; do\r\n  bazel-out/x64_windows-opt/bin/external/nasm/nasm.exe -fwin64 -DWIN64 -D__x86_64__    -I $(dirname external/libjpeg_turbo/simd/x86_64/jccolext-sse2.asm)/    -I $(dirname external/libjpeg_turbo/simd/nasm/jdct.inc)/    -I $(dirname external/libjpeg_turbo/simd/nasm/jdct.inc)/../../win/    -o $out    $(dirname external/libjpeg_turbo/simd/x86_64/jccolext-sse2.asm)/$(basename ${out%.obj}.asm)\r\ndone\r\nExecution platform: @local_execution_config_platform//:platform\r\n/usr/bin/bash: line 1: bazel-out/x64_windows-opt/bin/external/nasm/nasm.exe: Bad address\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nERROR: C:/users/{User}/_bazel_{User}/xv6zejqw/external/libjpeg_turbo/BUILD.bazel:347:11 Executing genrule @libjpeg_turbo//:simd_win_x86_64_assemble failed (Exit 126): bash.exe failed: error executing command\r\n  cd C:/users/{User}/_bazel_{User}/xv6zejqw/execroot/org_tensorflow\r\n  SET CUDA_TOOLKIT_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1\r\n    SET PATH=C:\\msys64\\usr\\bin;C:\\msys64\\bin;C:\\WINDOWS;C:\\WINDOWS\\System32;C:\\WINDOWS\\System32\\WindowsPowerShell\\v1.0\r\n    SET PYTHON_BIN_PATH=C:/Python/CPython38/python.exe\r\n    SET PYTHON_LIB_PATH=C:/Python/CPython38/lib/site-packages\r\n    SET RUNFILES_MANIFEST_ONLY=1\r\n    SET TF2_BEHAVIOR=1\r\n    SET TF_CONFIGURE_IOS=0\r\n    SET TF_CUDA_COMPUTE_CAPABILITIES=3.8\r\n    SET TF_CUDA_PATHS=C:/tools/cuda,C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1\r\n    SET TF_CUDA_VERSION=10.1\r\n    SET TF_CUDNN_VERSION=7.6.5\r\n    SET TF_NEED_CUDA=1\r\n  C:/msys64/usr/bin/bash.exe -c source external/bazel_tools/tools/genrule/genrule-setup.sh; for out in bazel-out/x64_windows-opt/bin/external/libjpeg_turbo/simd/x86_64/jccolor-avx2.obj bazel-out/x64_windows-opt/bin/external/libjpeg_turbo/simd/x86_64/jccolor-sse2.obj bazel-out/x64_windows-opt/bin/external/libjpeg_turbo/simd/x86_64/jcgray-avx2.obj bazel-out/x64_windows-opt/bin/external/libjpeg_turbo/simd/x86_64/jcgray-sse2.obj bazel-out/x64_windows-opt/bin/external/libjpeg_turbo/simd/x86_64/jchuff-sse2.obj bazel-out/x64_windows-opt/bin/external/libjpeg_turbo/simd/x86_64/jcphuff-sse2.obj bazel-out/x64_windows-opt/bin/external/libjpeg_turbo/simd/x86_64/jcsample-avx2.obj bazel-out/x64_windows-opt/bin/external/libjpeg_turbo/simd/x86_64/jcsample-sse2.obj bazel-out/x64_windows-opt/bin/external/libjpeg_turbo/simd/x86_64/jdcolor-avx2.obj bazel-out/x64_windows-opt/bin/external/libjpeg_turbo/simd/x86_64/jdcolor-sse2.obj bazel-out/x64_windows-opt/bin/external/libjpeg_turbo/simd/x86_64/jdmerge-avx2.obj bazel-out/x64_windows-opt/bin/external/libjpeg_turbo/simd/x86_64/jdmerge-sse2.obj bazel-out/x64_windows-opt/bin/external/libjpeg_turbo/simd/x86_64/jdsample-avx2.obj bazel-out/x64_windows-opt/bin/external/libjpeg_turbo/simd/x86_64/jdsample-sse2.obj bazel-out/x64_windows-opt/bin/external/libjpeg_turbo/simd/x86_64/jfdctflt-sse.obj bazel-out/x64_windows-opt/bin/external/libjpeg_turbo/simd/x86_64/jfdctfst-sse2.obj bazel-out/x64_windows-opt/bin/external/libjpeg_turbo/simd/x86_64/jfdctint-avx2.obj bazel-out/x64_windows-opt/bin/external/libjpeg_turbo/simd/x86_64/jfdctint-sse2.obj bazel-out/x64_windows-opt/bin/external/libjpeg_turbo/simd/x86_64/jidctflt-sse2.obj bazel-out/x64_windows-opt/bin/external/libjpeg_turbo/simd/x86_64/jidctfst-sse2.obj bazel-out/x64_windows-opt/bin/external/libjpeg_turbo/simd/x86_64/jidctint-avx2.obj bazel-out/x64_windows-opt/bin/external/libjpeg_turbo/simd/x86_64/jidctint-sse2.obj bazel-out/x64_windows-opt/bin/external/libjpeg_turbo/simd/x86_64/jidctred-sse2.obj bazel-out/x64_windows-opt/bin/external/libjpeg_turbo/simd/x86_64/jquantf-sse2.obj bazel-out/x64_windows-opt/bin/external/libjpeg_turbo/simd/x86_64/jquanti-avx2.obj bazel-out/x64_windows-opt/bin/external/libjpeg_turbo/simd/x86_64/jquanti-sse2.obj bazel-out/x64_windows-opt/bin/external/libjpeg_turbo/simd/x86_64/jsimdcpu.obj; do\r\n  bazel-out/x64_windows-opt/bin/external/nasm/nasm.exe -fwin64 -DWIN64 -D__x86_64__    -I $(dirname external/libjpeg_turbo/simd/x86_64/jccolext-sse2.asm)/    -I $(dirname external/libjpeg_turbo/simd/nasm/jdct.inc)/    -I $(dirname external/libjpeg_turbo/simd/nasm/jdct.inc)/../../win/    -o $out    $(dirname external/libjpeg_turbo/simd/x86_64/jccolext-sse2.asm)/$(basename ${out%.obj}.asm)\r\ndone\r\nExecution platform: @local_execution_config_platform//:platform\r\nINFO: Elapsed time: 81.600s, Critical Path: 16.20s\r\nINFO: 322 processes: 41 internal, 281 local.\r\nFAILED: Build did NOT complete successfully\r\n```\r\n", "comments": ["@redradist \r\n\r\nPlease, see tested build configurations from [here](https://www.tensorflow.org/install/source_windows#gpu).Please, make sure you have followed this [guide](https://www.tensorflow.org/install/gpu#windows_setup)  and see all software and hardware requirements are met. Thanks!", "> @redradist\r\n> \r\n> Please, see tested build configurations from [here](https://www.tensorflow.org/install/source_windows#gpu).Please, make sure you have followed this [guide](https://www.tensorflow.org/install/gpu#windows_setup) and see all softeare and hardware requirements ate met. Thanks!\r\n\r\n@ravikyram Yes, I got this error using this guide ... But I tried to compile from sources from **PowerShell** and **Cmd**", "@ravikyram @rmothukuru THe same issue happens with `MSYS Shell`:\r\n```console\r\nExecution platform: @local_execution_config_platform//:platform\r\n: bazel-out/x64_windows-opt-ST-e0f78fafe98f/bin/tensorflow/tools/git/gen_git_source.exe: Bad address\r\n```", "Can you tell us more about your platform? Could the compiler be trying mixing up 32-bit and 64-bit or something?", "@angerson My architecture is x64\r\n\r\nRegarding mixing the 32-bit and 64-bit ... I do not think so, as I read on the web seems like it related to `\\\\` and `/` in paths ...\r\nBut I am not sure", "@redradist\r\nI had the same issue. I wasted a few days trying to figure out why it was happening, and still couldn't find the cause. It would fail with `Bad address` during bazel build, but when I tried running the command manually it always finished successfully. Setting `MSYS2_ARG_CONV_EXCL` had no effect even when I passed it as `action_env` to bazel.\r\n\r\nThe workaround is to use a single directory for CUDA and cuDNN so that `TF_CUDA_PATHS` does not contain a comma in it.", "@angerson @itmo153277 \r\n\r\nSeems like I have figured out the issue with Bad address ... most of the time it happens because some third party is not available in google storage or through google mirror ...\r\n\r\nWhen I switch to github, package downloaded properly and build proceed\r\n\r\nProbably that is why all works on Google's side, because they have access to their mirrors ... (", "@angerson \r\n\r\nAlso I got the following error for flatbuffer:\r\n```console\r\nERROR: Traceback (most recent call last):\r\n        File \"C:/tensorflow/tensorflow/lite/python/BUILD\", line 1, column 40, in <toplevel>\r\n                load(\"@flatbuffers//:build_defs.bzl\", \"flatbuffer_py_library\")\r\nError: file '@flatbuffers//:build_defs.bzl' does not contain symbol 'flatbuffer_py_library' (did you mean 'flatbuffer_cc_library'?)\r\nERROR: C:/tensorflow/tensorflow/tools/pip_package/BUILD:286:10: no such target '//tensorflow/lite/python:tflite_convert': target 'tflite_convert' not declared in package 'tensorflow/lite/python' defined by C:/tensorflow/tensorflow/lite/python/BUILD and referenced by '//tensorflow/tools/pip_package:build_pip_package'\r\nERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: Analysis failed\r\nINFO: Elapsed time: 2.536s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (1 packages loaded, 0 targets configured)\r\nFAILED: Build did NOT complete successfully (1 packages loaded, 0 targets configured)\r\n\r\n```", "Could you please try again with latest build configurations with Tensorflow 2.8 and Bazel 4.2.1 for Windows by following the guide here https://www.tensorflow.org/install/source_windows. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46118\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46118\">No</a>\n"]}, {"number": 46117, "title": "Update version_check.bzl", "body": "Update the version", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F46117) for more info**.\n\n<!-- need_sender_cla -->", "@pshroff04 please don't spam reviews, especially since you didn't look at the code at all and have no approval power. This is spam and can result in you getting banned from GitHub.\r\n\r\nThis entire PR is spam."]}, {"number": 46116, "title": "How to convert this numpy to tf.function compatible code?", "body": "I'm trying to convert numpy to tensorflow equivalent code to be compatible with `tf.function` ...\r\n\r\nGiven have a `(32, 6)` numpy array `target_values` that looks like this:\r\n\r\n    array([[-0.01656106,  0.04762066,  0.05735449, -0.0284767 , -0.02237438,\r\n            -0.00042562],\r\n           [-0.01420249,  0.0477839 ,  0.0563598 , -0.02971786, -0.02367548,\r\n             0.00001262],\r\n           [-0.01695916,  0.04826669,  0.05893629, -0.03067053, -0.02261235,\r\n             0.00345904],\r\n           [-0.01953977,  0.04540274,  0.05829531, -0.02759781, -0.02390759,\r\n            -0.00487727],\r\n           [-0.01708016,  0.04894669,  0.0606699 , -0.02576046, -0.02461138,\r\n            -0.00068538],\r\n           [-0.01604217,  0.04770135,  0.05761468, -0.02858265, -0.02624938,\r\n            -0.00084356],\r\n           [-0.01527106,  0.04699571,  0.05959677, -0.02956396, -0.02510098,\r\n            -0.00223234],\r\n           [-0.01448676,  0.04620824,  0.05775366, -0.03008122, -0.02655901,\r\n            -0.00159649],\r\n           [-0.0172577 ,  0.04814827,  0.05807308, -0.02916523, -0.02367857,\r\n            -0.00100602],\r\n           [-0.01690523,  0.0484785 ,  0.05807881, -0.02960616, -0.02560546,\r\n            -0.00065042],\r\n           [-0.0166171 ,  0.0488232 ,  0.05776291, -0.03231864, -0.02132723,\r\n            -0.00033605],\r\n           [-0.01541627,  0.04840397,  0.0580376 , -0.02927143, -0.02461101,\r\n             0.00121263],\r\n           [-0.01685588,  0.047661  ,  0.05873172, -0.02989979, -0.02574112,\r\n            -0.00126612],\r\n           [-0.01333553,  0.05043796,  0.05915743, -0.02990219, -0.02657976,\r\n            -0.0007656 ],\r\n           [-0.01531163,  0.04781894,  0.05637252, -0.02968849, -0.02225551,\r\n            -0.00151382],\r\n           [-0.01357749,  0.04807179,  0.05955081, -0.02748637, -0.02498721,\r\n            -0.00040934],\r\n           [-0.01606943,  0.04768877,  0.05455931, -0.03136749, -0.02475093,\r\n             0.00245846],\r\n           [-0.01609829,  0.04687681,  0.05982678, -0.02886578, -0.02608151,\r\n             0.00015348],\r\n           [-0.01503662,  0.04740106,  0.05958583, -0.03141545, -0.02522127,\r\n            -0.00063602],\r\n           [-0.01697148,  0.04910276,  0.05744712, -0.02858391, -0.02481578,\r\n            -0.00072039],\r\n           [-0.01503395,  0.04843756,  0.05773868, -0.03061879, -0.02586869,\r\n            -0.00025573],\r\n           [-0.0152991 ,  0.04847359,  0.05739099, -0.0299796 , -0.02552593,\r\n            -0.00334571],\r\n           [-0.01324895,  0.04529134,  0.05534273, -0.03109139, -0.02304241,\r\n            -0.00143186],\r\n           [-0.01280282,  0.05004944,  0.05856398, -0.0314032 , -0.02394999,\r\n            -0.00030306],\r\n           [-0.01677033,  0.04876196,  0.05794405, -0.02888608, -0.02658239,\r\n            -0.00015171],\r\n           [-0.01572544,  0.04779808,  0.05939355, -0.03048976, -0.02896303,\r\n            -0.00090334],\r\n           [-0.01542805,  0.04709881,  0.05839922, -0.02894112, -0.02240603,\r\n            -0.00188624],\r\n           [-0.01493233,  0.0476524 ,  0.0581631 , -0.0297201 , -0.02485022,\r\n            -0.00087418],\r\n           [-0.01804641,  0.04739738,  0.06070606, -0.02981704, -0.02543145,\r\n            -0.00115484],\r\n           [-0.01518638,  0.04843838,  0.05744548, -0.02980216, -0.02420005,\r\n             0.00036349],\r\n           [-0.01442349,  0.04673778,  0.05804737, -0.03062913, -0.02476445,\r\n            -0.00066772],\r\n           [-0.01598305,  0.04622466,  0.0588723 , -0.03096713, -0.02364032,\r\n            -0.00005574]])\r\n\r\nGiven another `(32,)` array of indices `actions` with values being in range(5) inclusive:\r\n\r\n    array([0, 2, 5, 5, 1, 1, 3, 4, 0, 5, 4, 3, 4, 5, 1, 0, 3, 0, 0, 2, 2, 2,\r\n           0, 1, 4, 1, 4, 4, 0, 4, 1, 0])\r\n\r\nI'm expecting this result:\r\n\r\n    array([-0.01656106,  0.0563598 ,  0.00345904, -0.00487727,  0.04894669,\r\n            0.04770135, -0.02956396, -0.02655901, -0.0172577 , -0.00065042,\r\n           -0.02132723, -0.02927143, -0.02574112, -0.0007656 ,  0.04781894,\r\n           -0.01357749, -0.03136749, -0.01609829, -0.01503662,  0.05744712,\r\n            0.05773868,  0.05739099, -0.01324895,  0.05004944, -0.02658239,\r\n            0.04779808, -0.02240603, -0.02485022, -0.01804641, -0.02420005,\r\n            0.04673778, -0.01598305], dtype=float32)\r\n\r\nFor `self.batch_size == 32`, I'm able to achieve what I need in numpy using:\r\n\r\n    state_action_values = target_values[np.arange(self.batch_size), actions]\r\n\r\nFor `target_value_update` being another `(32,)` array of new values, I will need to assign the new values to this slice using:\r\n\r\n    target_values[np.arange(self.batch_size), actions] = target_value_update\r\n\r\nHowever in tensorflow under `tf.function`, this is not possible and I get the following error:\r\n\r\n    TypeError: Only integers, slices (`:`), ellipsis (`...`), tf.newaxis (`None`) and scalar tf.int32/tf.int64 tensors are valid indices, got array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\r\n           17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])\r\n\r\nSo I try:\r\n\r\n    target_values = tf.Variable(target_values)\r\n    state_action_values = tf.gather(target_values, actions, axis=1)\r\n\r\nHowever here's the value of `state_action_values` which should be `(32,)` not `(32, 32)`\r\n\r\n    Tensor(\"GatherV2:0\", shape=(32, 32), dtype=float32)\r\n\r\n\r\n  [1]: https://www.tensorflow.org/api_docs/python/tf/function\r\n", "comments": ["Hi @emadboctorx, I think it can be solved with `tf.gather_nd`. Please take a look at [colab link](https://colab.research.google.com/drive/1eTLuBQoI41ginhyF8BiAIvV3KuugT1OP?usp=sharing). Thank you.", "@WindQAQ thanks, that is exactly what I'm looking for. Is there a way to assign new values at the given positions in the following fashion usually achieved in numpy?\r\n\r\n    target_values[indices] = new_values", "Unfortunately, TF does not support this syntax, but you can achieve it with\r\n\r\n```python\r\n# If target_value is a tf.Variable\r\ntarget_values.scatter_nd_update(indices, new_values)\r\n```\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/Variable?version=nightly#scatter_nd_update", "@WindQAQ Thanks again, you're a life saver"]}, {"number": 46115, "title": "Add ReadVariableOp gradient to C++", "body": "Fixes #46114.\r\n\r\nAdds the ResourceVariableOp gradient to the C++ API and removes it from the Python API.", "comments": ["@suharshs I'm attempting to add the C++ gradient for `ReadVariableOp` following the instructions you laid out in [the /tensorflow/cc/gradients README](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/cc/gradients/README.md), which matches past PRs such as #25467.  However, it does not appear to be registered, as seen in `//tensorflow/python/kernel_tests:cond_v2_test` and other tests.  It doesn't appear to be related to using a new file as it happens even if I move the new gradient to `array_grad.cc`.  Thoughts?", "@allenlavoie we (i.e. SIG JVM) are going to need to add a number of gradients to bring the Java API to parity, can you check my understanding of where things live (or tell me if there's a nice guide somewhere I missed)?  I can't test eager and function myself, since there's no C tape api and the `SymbolicGradient` doesn't have a gradient registered with how we're doing graph gradients (`TF_AddGradientsWithPrefix` in the C API).\r\n\r\n* Functions are differentiated with the `SymbolicGradient` op, where gradients are registered with `REGISTER_OP_GRADIENT` and live in `core/ops` like [this](https://github.com/tensorflow/tensorflow/blob/c7e7f49228444f1a024fbd9266d60252009fee0a/tensorflow/core/ops/resource_variable_ops.cc#L161).\r\n\r\n* Graph gradients, at least those done through the C API's `TF_AddGradientsWithPrefix`, are registered with `REGISTER_GRADIENT_OP` and live in `cc/gradients`.  I assume if there was a way to do this using `SymbolicGradient`/`REGISTER_OP_GRADIENT` you already would be?\r\n\r\n* Eager gradients live in `c/experimental/gradients` and registered by adding them to tape's [`RegisterGradients`](https://github.com/tensorflow/tensorflow/blob/4e25cac495909450b42094f7f6c85d49bbed1c2f/tensorflow/python/framework/experimental/tape.cc#L30).\r\n\r\nI don't suppose there's any attempts to unify some or all of these?", "I see. Yes, if you're using SymbolicGradient/TF_AddGradientsWithPrefix then cc/gradients sounds right for adding new definitions. SymbolicGradient isn't used much from Python anymore for function gradients, since there isn't really a way to get higher-order gradients with it. I'd like to put a replacement for function gradients in C (based on replaying the function) and use it from Python, but it's not something I'll get to soon. And similarly an eager GradientTape doesn't do higher-order gradients if the gradient functions it runs are opaque, which makes re-using the graph-building gradient definitions pretty hard; they need to be written using the same API the tape is watching.\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/c/experimental/gradients is the effort to unify Python/C++/eager/graph to use one set of gradients. The gradient definitions are written with an eager/graph agnostic C++ API (with a C option likely for ABI stability), and the plan is to use them from Python early (something we didn't manage for most of these other projects). I'm not sure it's far enough along to have a registry via static initializers; looks like the tests are still manually adding definitions to a registry. And there is some uncertainty as we figure out what kind of C++ API we want going forward.", "> https://github.com/tensorflow/tensorflow/tree/master/tensorflow/c/experimental/gradients is the effort to unify Python/C++/eager/graph to use one set of gradients.\r\n\r\nOk, thanks, that's good to know.  I assume `TF_AddGradientsWithPrefix` will use them eventually?  And is there an issue or PR I can watch to keep up to date on progress with them?\r\n\r\nAlso related: I'm looking at adding `cc/gradients` gradients for `PartitionedCall` (and Stateful), is calling the `SymbolicGradient` op still the right way to do that or should I look at using `SymbolicGradientBuilder` (I know you said it's obsolete, but we don't have a c++ level alternative and it's still used as a fallback [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/gradients_util.py#L308-L308))", "Sure, fine to use it for now. I don't know of an issue tracking the eager/graph agnostic C++ gradients (@saxenasaurabh might).\r\n\r\nSymbolicGradient is OK for first-order gradients of functions. Do you need functions and function gradients if there's no tape / eager-compatible gradient API?", "> SymbolicGradient is OK for first-order gradients of functions. Do you need functions and function gradients if there's no tape / eager-compatible gradient API?\r\n\r\nYeah, we're supporting functions in graphs as well as eager mode.  Eventually we'll point people towards the eager API, but without gradients it's not functional yet.", "All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F46115) for more info**.\n\n<!-- need_author_consent -->", "Had to add an Identity to the gradient to prevent \"fetching and feeding the same op\" issues.  Test passes locally now, I expect everything to work.", "@rnett can you please check for sanity build failures ?", "Should be fixed, it passes locally.", "@rnett can you please fix sanity builds ?", "@rnett we still see sanity build errors , can you please check ?", "It keeps reporting new errors each time.  When I try running the [`tensorflow/tools/ci_build/ci_sanity.sh`](tensorflow/tools/ci_build/ci_sanity.sh) it hangs while looking for CUDA dirs in the configure script (which works fine normally).  Let me see if I can run just the buildifier.", "Is it complaining about the type of whitespace this time? I agree that's a pretty confusing error and it's probably easier to run buildifier. That looks like the only thing that's been failing.\r\n\r\n```\r\nFAIL: buildifier found errors and/or warnings in above BUILD files.\r\nbuildifier suggested the following changes:\r\ntensorflow/cc/BUILD:\r\n555,557d554\r\n<         \"//tensorflow/core:test\",\r\n<         \"//tensorflow/core:test_main\",\r\n<         \"//tensorflow/core:testlib\",\r\n560a558,560\r\n>         \"//tensorflow/core:test\",\r\n>         \"//tensorflow/core:test_main\",\r\n>         \"//tensorflow/core:testlib\",\r\nexit status 1\r\n```\r\n", "Looks like it just changed the order again, the diff seems wrong wrt what it changed.  It passes `buildifier -v -mode=check BUILD` now though, locally.", "Ah, that makes sense, \"core\" comes after \"cc\" alphabetically and the diff was just saying the lines stay in the same order but move down.", "Can you resolve the conflicts? (I'm guessing with your other change)", "Can you run clang_tidy?\r\n\r\nSpecifically it wants the three C-style `(float)1` casts in resource_variable_grad_test.cc to be C++-style `static_cast<float>(1)`, although you can also just write `1.0f` (or `1f`?)"]}, {"number": 46114, "title": "C++ Gradient for ReadVariableOp", "body": "**System information**\r\n- TensorFlow version (you are using): `master`\r\n- Are you willing to contribute it: Yes\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nCurrently, `ReadVariableOp`'s gradient is implemented in Python, making using resource variables for training from the C++ API or other APIs based on it impossible.\r\n\r\n**Will this change the current api? How?**\r\n\r\nNo.\r\n\r\n**Who will benefit with this feature?**\r\n\r\nAnyone using resource variables from the C++ API or APIs based on it.\r\n", "comments": []}, {"number": 46113, "title": "RPi Zero(ARMv6l) _FusedConv2D <no registered kernels>", "body": "**System information**\r\n- Using Keras MobileNet model\r\n- Platform: RPi Zero (armv6l)\r\n- Tested on binaries: v1.14.0 from piwheel / v2.4.0 from [https://github.com/lhelontra/tensorflow-on-arm/releases/tag/v2.4.0](url)\r\n- Python version: 3.7\r\n\r\n**Describe the current behavior**\r\nError when attempting model.predict on RPi zero using keras.apps MobileNet model\r\nAttempting _FusedConv2D calculation via a non existing kernel\r\n\r\n**Describe the expected behavior**\r\nAttempted unfused conv2D + relu since armv6l doesnt support it\r\nSuccessful forward pass calculation of model\r\n\r\n**Standalone code to reproduce the issue**\r\nhttps://pastebin.com/4syM43S1\r\n\r\nReproducable when applied on RPi Zero \r\nlibs:\r\n- atlasbase\r\n- hdf5\r\n- openjp2\r\n- tiff5\r\n\r\npip: \r\n- tf\r\n- keras\r\n- h5py\r\n- pillow\r\n\r\n**Other info / logs**\r\nTrace (TF v2.4.0): https://pastebin.com/QNFsJjkJ\r\n\r\nHaving same issue as open:  https://github.com/tensorflow/tensorflow/issues/24732\r\n\r\nCould a possible work around for this issue be to enter the TFLite path?\r\nOr can FusedConv2D be disabled before building binary?\r\n\r\nThank you.\r\n\r\n**EDIT**: TFLite path was great \r\nhttps://github.com/google-coral/pycoral/issues/7\r\nhttps://github.com/google-coral/edgetpu/issues/229\r\nhttps://drive.google.com/file/d/1mW8QGmhfk4kRYXqUTEH1ckPUNIsl7S3d/view\r\nhttps://www.tensorflow.org/lite/guide/inference#load_and_run_a_model_in_python", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46113\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46113\">No</a>\n"]}, {"number": 46112, "title": "ImageDataGenerator().batch_index starts from zero even though manually setting it", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (use command below): 2.4.0\r\n- Python version: 3.7.9\r\n- Bazel version (if compiling from source): n/a\r\n- GCC/Compiler version (if compiling from source): n/a\r\n- CUDA/cuDNN version: Cuda 11.0 update 1 + cudnn 8.0.5\r\n- GPU model and memory: RTX 3080 10GB\r\n\r\n\r\n**Describe the current behavior**\r\nI define my datagenerator by `ImageDataGenerator(preprocessing_function=preprocess_input)` then I define the generator:        \r\n\r\n```\r\n generator = datagen.flow_from_directory(\r\n            directory=data_dir,\r\n            target_size=(112, 112),\r\n            color_mode=\"rgb\",\r\n            class_mode=None,\r\n            batch_size=batch_size,\r\n            shuffle=False,\r\n        )\r\n```\r\nI want to **start at a particular batch_index**, so I set the `generator.batch_index = 500`. When I loop for the first time over the generator, it will ignore this set batch_index and start at zero:  \r\n```\r\nfor batch, label in generator:\r\n    pred = model.predict(batch, verbose=0)\r\n    features.append(scipy.sparse.csr_matrix(pred))\r\n```\r\n\r\nBut if just loop over it once with \r\n```\r\nfor batch, label in generator:\r\n    break\r\n```\r\n and then set the `generator.batch_index = 500`, and then loop over it again with the previous code it will start at the correct index.\r\n\r\nI don't know if this is a feature or not. But if it is, it's not very practical to loop over it once before being able to adjust the batch_index.\r\n\r\n**Describe the expected behavior**\r\nI should be able to change the batch_index before looping over the generator. \r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n", "comments": ["@ion-elgreco,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here and also the dataset you are using. Thanks!", "> @ion-elgreco,\r\n> In order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here and also the dataset you are using. Thanks!\r\n\r\nYou can run everything, I included comments and you can see the behaviour as I have previously described.\r\n\r\nhttps://deepnote.com/project/018372c1-db6c-4f31-90a4-54d7a3500f33#%2Fnotebook.ipynb\r\n\r\nPS \r\nI used a dummy dataset. It exhibits this behavior with my original private dataset too.", "Was able to reproduce the issue with TF v2.3, TF v2.4 and TF-nightly. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/b11b4ac0a11295b05518adcdb25d6ad6/46112.ipynb). Thanks!", "`ImageDataGenerator` is not intended for subclassing. You could either reimplement your own version of it (by copying the code), or instead write a tf.data pipeline (recommended).", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46112\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46112\">No</a>\n", "> `ImageDataGenerator` is not intended for subclassing. You could either reimplement your own version of it (by copying the code), or instead write a tf.data pipeline (recommended).\r\n\r\nAlright, I'll just use this workaround by calling the generator first and then changing the batch_index. "]}, {"number": 46111, "title": "Resource exhausted:  OOM when allocating tensor with TF 2.4.0", "body": "### System information\r\n\r\n-   **Have I written custom code (as opposed to using a stock example script\r\n    provided in TensorFlow)**: The code is from PyImageSearch.com, it runs fine on TF 2.3.1\r\n-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10 Pro, version 20H2, OS build: 19042.685\r\n-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue\r\n    happens on a mobile device**: -\r\n-   **TensorFlow installed from (source or binary)**: binary\r\n-   **TensorFlow version (use command below)**: 2.4.0 (sorry, 2.4 is uninstalled now, I cannot run that command)\r\n-   **Python version**: 3.7.5\r\n-   **Bazel version (if compiling from source)**: -\r\n-   **GCC/Compiler version (if compiling from source)**: -\r\n-   **CUDA/cuDNN version**: 11.0.2_451.48 / 11.0\r\n-   **GPU model and memory**: NVIDIA GeForce RTX 2060, 6 GB RAM\r\n-   **Exact command to reproduce**: run my python script with my data, after around 940-960 epochs it runs out of memory\r\n\r\n\r\n### Describe the problem\r\nThere is a bug around TensorFlow 2.4.0: the exact same code runs fine with the following components in python:\r\ntensorflow==2.3.1\r\ntensorflow-gpu==2.3.1\r\ncuda_10.1.105_418.96_win10.exe\r\ncudnn-10.1-windows10-x64-v7.6.5.32.zip\r\n\r\nBut give a \"Resource exhausted:  OOM when allocating tensor\" error after 900 and some epochs with TF 2.4.0:\r\ntensorflow==2.4.0\r\ntensorflow-gpu==2.4.0\r\ncuda_11.0.2_451.48_win10.exe\r\ncudnn-11.0-windows-x64-v8.0.5.39.zip\r\n\r\nIn the logs, I found this:\r\n/job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\r\n\r\nCan it be, that TF is switching to cpu instead of gpu at one point?\r\n\r\n### Source code / logs\r\nLogs of two runs:\r\n[bug.txt](https://github.com/tensorflow/tensorflow/files/5760806/bug.txt)\r\n[bug2.txt](https://github.com/tensorflow/tensorflow/files/5760807/bug2.txt)\r\n", "comments": ["@lmocsi \r\n\r\nPlease share stand alone indented code and dependencies to replicate or if possible share a colab gist with error reported.", "1. What do you mean by \"stand alone indented code and dependencies\"? All the code and the 8000 images?\r\n2. What is a \"colab gist with error reported\"?", "@lmocsi \r\nCode simple enough to replicate the issue faced, for us to replicate the issue reported.", "I'm not sure if I can simplify the code for you to be able to reproduce the problem, since it is running on 8000 images, and the problem arises only above 900 iterations.\r\nCould you instead compare the codes of TF 2.3.1 and 2.4.0 with respect to the errors described in the bug txt files?\r\nPython37\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py, line 60 seems to be the starting point.", "Have you tried using smaller batch size for your training?", "No. The exact same batch size works perfectly on TF 2.3.1.", "Please try to provide a simple minimal reproducer code so that people can use it to bisect the issue and then create a regression test to prevent the issue from appearing in the future.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "As I've said, creating a \"simple minimal reproducer code\" is extremely difficult in this case, almost at the level of solving the problem.", "Hello.\r\nTagging myself into this issue and keeping it alive.\r\n\r\nI believe that I might be facing this issue too.\r\nI have upgraded from tf1.14 to 2.4 recently and I think my code is good, although I need to generate some small generic standalone code in the process of debugging my code. \r\nIt will take me a few weeks to get some code in a Colab to see if I can replicate it there.\r\nWill let you know the outcome.\r\nPlease advise if anyone resolves this.", "Similar issue here. OOM exception during a call to model.fit() while it is trying to allocate a tensor.\r\n\r\n(0) Resource exhausted:  OOM when allocating tensor with shape[3072,768] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n\r\nThe recommendation I have seen everywhere on github and stackoverflow is to reduce the minibatch size. I don't think the batch size is the issue in my case since:\r\n1. error occurs only in the 13th trials. Each trial uses a new instance of the same model architecture. batch size = 8. Previous instance is discarded each time. Why would first 12 trials fit comfortably into GPU memory and not the 13th?\r\n2. I can run 12 trials with batch size = 16. Also crashes at 13th.\r\n3. nvidia-smi logs shows the GPU RAM utilisation doesn't exceeds 58% (batch size = 8) and returns to 0% before each trial (indicating that there is no GPU memory leak).\r\n\r\nReproduced with tensorflow 2.3.1, 2.4.0, 2.4.1; 1080 ti; ubuntu 20.04.\r\n", "@geoffroy-noel-ddh are you using python generators with a tf.keras.Model() and fit()", "@normanheckscher Thanks for asking. No, the model is instantiated and trained in a method which is called by a loop. I managed to fix the issue, which was due to my training callback (to implement early stopping) being a class instance. By instantiating the callback within the loop, the memory error disappeared. I assume that persistent instance of the callback was somehow holding resources from being freed.", "Have you considered limiting gpu memory growth?\r\nMake sure you close all python sessions and exit python interpreter to free up memory and try running script as:\r\n```python\r\n#On top of your script\r\nimport tensorflow as tf\r\ngpu = tf.config.list_physical_devices('GPU')\r\ntf.config.experimental.set_memory_growth(gpu[0], True) #limits gpu memory\r\n# Rest of your code\r\n```\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "I have the same issue. @ymodak memory growth does not help. I still get an OOM with keras and tensorflow 2.4 while it was working with 2.3 and 2.2. The memory growth option should not help here. Correct me if I am wrong, but it's only enable / disable that tensorflow reserves all memory in front up vs. when needed. ", "Closing as stale. Please reopen if you'd like to work on this further.\n", "any updates?", "> any updates?\n\nI'm short on time to commit to this, so I'll probably never get to the bottom of it. My conclusion is that the source of this problem is within the tensorflow/cuda code interface or its a python incompatibility.\n\nUltimately, I'm just going to revert my codebase back to tensorflow 1.1x, an older version of cuda and import keras as a separate python library. This worked for me in the past and it should work again. "]}, {"number": 46110, "title": "what CUDA 11 and cuDNN i have to install to use TF 2.4?", "body": "Hello i just want know what CUDA 11 and cuDNN i have to install to use TF 2.4\r\nI'ts not clear in doc\r\n![image](https://user-images.githubusercontent.com/73416709/103465568-4885bc80-4d3d-11eb-8438-4ccf6f940133.png)\r\nThanks\r\n\r\n", "comments": ["Hi\r\nCUDA Toolkit 11.0 (May 2020)", "You can install Cuda toolkit 11.0 update 1 and cudnn 8.0.5.", "thanks all!"]}, {"number": 46109, "title": "tensorflow lite model hangs in tflite.run in android emulator", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1.  It must be a bug, a feature request, or a significant problem with the\r\n    documentation (for small docs fixes please send a PR instead).\r\n2.  The form below must be filled out.\r\n3.  It shouldn't be a TensorBoard issue. Those go\r\n    [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n\r\n-   **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n     \r\n-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: \r\n     Linux Ubuntu 20.04\r\n-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on a mobile device**:\r\n     Android emulator.\r\n-   **TensorFlow installed from (source or binary)**:\r\n    Installed from source\r\n-   **TensorFlow version (use command below)**:\r\n    Tensorflow version used to convert tf model to tflite: 2.5.0\r\n    Tensorflow version and tf op version:  2.3.0\r\n\r\n-   **Python version**: 3.8.0\r\n-   **Bazel version (if compiling from source)**:\r\n-   **GCC/Compiler version (if compiling from source)**:\r\n-   **CUDA/cuDNN version**:\r\n-   **GPU model and memory**:\r\n-   **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with:\r\n\r\n```bash\r\npython -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"\r\n```\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["@Emmanuel357,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here and also provide the exact sequence of commands / steps that you executed before running into the problem. Thanks!", "Thank you very much for responding. The exact model I tried to run inference on can be found here -> https://drive.google.com/file/d/1ofRpHnwcy3mJmEIBm2ACa48x6M2_8PU4/view?usp=sharing\r\n\r\nThe model successfully loaded in java on the android emulator but it got stuck in tflite.run(z_vector, output). The exact code I used to run the inference is below.\r\n\r\n```\r\npublic static float randInt() {\r\n        Random rand = new Random();\r\n        float randomNum = (float) rand.nextGaussian();\r\n        return randomNum;\r\n}\r\n\r\npublic static float[][] getZ(int batchSize, int latentDim){\r\n    float[][] newNoise = new float[batchSize][latentDim];\r\n    for (int i=0; i< latentDim * batchSize; ++i){\r\n        float numb = (float) randInt();\r\n        newNoise[0][i] = numb;\r\n    }\r\n    return newNoise;\r\n}\r\n\r\nprivate MappedByteBuffer loadModelFile(String fileName) throws IOException {\r\n        AssetFileDescriptor fileDescriptor = this.getAssets().openFd(fileName);\r\n        FileInputStream inputStream = new FileInputStream(fileDescriptor.getFileDescriptor());\r\n        FileChannel fileChannel = inputStream.getChannel();\r\n        long startOffset = fileDescriptor.getStartOffset();\r\n        long declaredLength = fileDescriptor.getDeclaredLength();\r\n        return fileChannel.map(FileChannel.MapMode.READ_ONLY, startOffset, declaredLength);\r\n}\r\n\r\n// I was able to load the model successfully but model got stuck when running inference.\r\ntry {\r\n    FlexDelegate delegate = new FlexDelegate();\r\n    Interpreter.Options options = new Interpreter.Options().addDelegate(delegate);\r\n    Interpreter tflite = new Interpreter(loadModelFile(\"nn.tflite\"), options);\r\n} catch (Exception ex){\r\n    android.util.Log.d(\"norm\", \"Error when loading model: \"+ex);\r\n}\r\n\r\nfloat[][] z_vector = getZ(1,512);\r\nfloat[][][][] output = new float[1][1024][1024][3];\r\ntflite.run(z_vector, output);  //STUCK HERE\r\n\r\n```\r\nNote: The tflite model worked well when tested with python tflite interpreter.", "@Emmanuel357,\r\nI do not have access to the link you have provided. Could you please provide the required permissions to view the files. Thanks!", "> I do not have access to the link you have provided. Could you please provide the required permissions to view the files. Thanks!\r\n\r\nYou should be able to view the files now, thank you.", "Could you try using same TensorFlow version in android application and TensorFlow Python version used for TFLite model conversion?", "If i'm correct, The latest tensorflow lite version in android is 2.4.0 and the latest in python is 2.5.0 . There is no tensorflow lite version of 2.5.0 for android. \r\n\r\nDo you want me to convert the model using tensorflow version of 2.4.0?", "I tried using tensorflow version of 2.4.0 for both python and java but model still hangs.\r\nThis is how I converted the keras model to .tflite version.\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport torch\r\nfrom torchvision.utils import save_image\r\n\r\nloaded_model = tf.keras.models.load_model('nn') #keras.models.load_model\r\nz = np.random.randn(1, 512).astype('float32')\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(loaded_model) # path to the SavedModel directory\r\nsupported_ops = [tf.lite.OpsSet.SELECT_TF_OPS] #tf.lite.OpsSet.TFLITE_BUILTINS,\r\nconverter.target_spec.supported_ops = supported_ops\r\ntflite_model = converter.convert()\r\n\r\n# Save the model.\r\nwith open('nn.tflite', 'wb') as f:\r\n  f.write(tflite_model)\r\n```", "No solution to this problem?", "Can you test this on a real device? And try to allocate more memory to the emulator?\r\nYour model is big and has high memory consumption so there might be an out of memory problem.", "When I tried to run your model. The peak memory footprint is overall=6541MB. You might need to slim down your model to fit into mobile phone. Not a lot of phones have more than 6GB of RAM.", "BTW, \"org.tensorflow:tensorflow-lite:0.0.0-nightly\" is actually 2.5.0 which isn't published yet\r\n\r\n> If i'm correct, The latest tensorflow lite version in android is 2.4.0 and the latest in python is 2.5.0 . There is no tensorflow lite version of 2.5.0 for android.", "Slimming down the model actually works. I'm closing the issue now.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46109\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46109\">No</a>\n"]}, {"number": 46108, "title": "Illegal instruction (core dumped) using tensorflow==2.4.0 with AVX instruction when importing", "body": "**System information**\r\n- OS Platform and Distribution: Linux Ubuntu 18.04)\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): 2.4.0\r\n- Python version: 3.7.9\r\n- CUDA/cuDNN version: 11.0/8.0.5\r\n- GPU model and memory: GTX 2080Ti\r\n\r\n\r\n**Describe the current behavior**\r\n\r\nAttempting to import tensorflow produces an \"Illegal instruction(core dumped)\" error.\r\n\r\n**Describe the expected behavior**\r\n\r\nImport tensorflow without error.\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nconda create -n test-tf2.4 python=3.7\r\nconda activate test-tf2.4\r\npip install tensorflow==2.4.0\r\n```\r\nThe following command exits with an \"Illegal instruction\" error:\r\n```\r\npython -c \"import tensorflow as tf\"\r\n```\r\n\r\n**Other info / logs** \r\nThis will be not an issue with the last development version of 2.5.0 (tf-nightly 2.5.0.dev20210102) from tf-nightly, installed with:\r\n```\r\npip install tf-nightly\r\n```\r\n\r\nMOST IMPORTANTLY, My machine has AVX instructions. So this is not the same as the previous \"old cpu\", while it is THE SAME AS the [#44668 ](https://github.com/tensorflow/tensorflow/issues/44668)problem  which your team has NOT SOLVED.", "comments": ["I can confirm the problem.  I have i7-3770 which supports AVX (but not AVX2) and gt1030.  \r\n \r\n    python -m tensorflow\r\n\r\n(tf 2.4.0 installed with pip in venv) crashes with \"illegal instruction\" while the same works when installing tf-nightly.  Otherwise running in ubuntu 20.04, python 3.8.5.  Nvidia-smi reports cuda 11 while nvcc reports cuda 10.1, so there seems to be some sort of mismatch.\r\n\r\ngdb suggests the issue happens with `vcvtsi2sd` instruction in the middle row below (but I know too little of gdb and assembly to actually tell).\r\n\r\n    KSt8functionIFNS_6StatusERKNS_7VariantEPS7_S5_IFS6_RKNS_6TensorEPSB_EEEE+520>    shlx   %r14d,%edx,%eax\r\n    KSt8functionIFNS_6StatusERKNS_7VariantEPS7_S5_IFS6_RKNS_6TensorEPSB_EEEE+525>    vcvtsi2sd %rax,%xmm0,%xmm0\r\n    KSt8functionIFNS_6StatusERKNS_7VariantEPS7_S5_IFS6_RKNS_6TensorEPSB_EEEE+530>    vmulsd %xmm2,%xmm0,%xmm0\r\n", "Duplicate of #45744 #45866 and a few more. We already have a fix, cherrypicked to the 2.4 branch and waiting for patch release.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46108\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46108\">No</a>\n"]}, {"number": 46107, "title": "TFlite interpreter stuck after call to invoke()", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): example code + adaptations\r\n- OS Platform and Distribution: Linux Ubuntu 18.04\r\n- TensorFlow installed from: binary\r\n- TensorFlow version: tf-nightly 2.5.0.dev20210102\r\n- Python version: 3.6.9\r\n- GPU model and memory: no GPU\r\n\r\n**Describe the current behavior**\r\nTFlite interpreter invoke() method never returns\r\n\r\n**Describe the expected behavior**\r\ninvoke() method returns with results\r\n\r\nHi,\r\ni've successfully trained an object detection model using tensorflow 2.3.0 with SSD ResNet50 V1 FPN pretrained model.\r\nBy loading the model as a saved_model format i can run it as expected on my PC and on raspberry pi 4 as well.\r\n\r\nBecause performance on the rasperryPI was not good i looked into TFLite optimiziations and got some issues with the conversion from saved_model to .tflite format. The model was trained with the keep_aspect_ratio_resizer imge_resizer that required dynamic input size support from tflite. This is when i've moved to tf-nightly as suggested in a discussion found here on github. After the update the conversion was successfull, this is the code:\r\n```\r\nimport tensorflow as tf\r\n\r\n# Convert the model\r\nconverter = tf.lite.TFLiteConverter.from_saved_model(\"./1024PRE_v2/saved_model\") # path to the SavedModel directory\r\nconverter.experimental_new_converter = True\r\nconverter.allow_custom_ops = True\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\n\r\ntflite_model = converter.convert()\r\n\r\n# Save the model\r\nwith open('model.tflite', 'wb') as f:\r\n  f.write(tflite_model)\r\n```\r\n\r\nIn the object detection code i added a call to resize_tensor_input as suggested but the execution never gets past the invoke() method:\r\n\r\n ```\r\n  interpreter = interpreter_wrapper.Interpreter(model_path=model_file)\r\n  interpreter.resize_tensor_input(0, [1, 1024, 1024, 3])\r\n  interpreter.allocate_tensors()\r\n\r\n  input_details = interpreter.get_input_details()\r\n  output_details = interpreter.get_output_details()\r\n\r\n  category_index = label_map_util.create_category_index_from_labelmap(label_file, use_display_name=True)\r\n\r\n  # Load a 1024x1024 image\r\n  img = cv2.imread(file_name)\r\n\r\n  # add N dim\r\n  input_data = np.expand_dims(img, axis=0)\r\n\r\n  interpreter.set_tensor(input_details[0]['index'], input_data)\r\n\r\n  interpreter.invoke()\r\n  \r\n # Code never reaches this point\r\n ```\r\n\r\nThanks in advance for the support", "comments": ["Forgot to mention that there's no output/log on the console coming from the invoke() method", "try upgrading your python version to 3.8", "You need to use [this method](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_on_mobile_tf2.md) of converting to TFLite, since SSD models (as-is from TF) don't work well on-device. We usually require an intermediate step to generate a TFLite-compatible SavedModel before using the converter API. For an end-to-end example, see [this](https://github.com/tensorflow/models/blob/master/research/object_detection/colab_tutorials/eager_few_shot_od_training_tflite.ipynb). Also, for TFLite we only support the [fixed size resizer](https://github.com/tensorflow/models/blob/master/research/object_detection/export_tflite_graph_lib_tf2.py#L94), so you can do the pre-processing outside of TFLite & keep the model input size constant.", "@Emmanuel357: tested on Ubuntu 20.4, using default python installation (3.8.5) i get the same result.\r\n\r\n@srjoglekar246: ok, i will try that. Hopefully i can keep my checkpoint without having to train the model from the beginning.\r\n\r\nThanks,", "I carried on my work on ubuntu 20.4, python 3.8.5 and last stable tensorflow release 2.4.0. I followed @srjoglekar246 suggestions and regenerated the tflite file from the new model but i got the same issue again.\r\n\r\nI've however now found that everything works if from my tflite conversion code i remove this line:\r\n`converter.optimizations = [tf.lite.Optimize.DEFAULT]`\r\n\r\nThat line was expected to have no effect anyway, furthermore it looks like the use of tf.lite.Optimize is depracated now.\r\n\r\nThanks for your support.\r\n", "It turns out that i can leave this line:\r\n`converter.optimizations = [tf.lite.Optimize.DEFAULT]`\r\n\r\nonly if i also set \"converter.target_spec.supported_ops\". This is actually done in the first link @srjoglekar246 gave me, and that make it work. The reason i didn't set it in the first place was because in the example full integer quantiziation was enabled requiring me to set representative_dataset which i didn't understand and according to the documentation was optional.\r\n\r\nSo maybe the issue was related to dynamic range quantiziation?\r\n\r\nNow i'm facing another issue where the tflite model is giving me completely wrong results compared to the saved_model. This looks like could be the same as what reported in issue #46142\r\n", "@N1ckx BTW, could you share how to get rasperryPI runtime?\r\nFYI, if you can use 64bit OS (such as https://ubuntu.com/download/raspberry-pi), aarch64 binary gives better performance than armhf binary.\r\n\r\n> Because performance on the rasperryPI was not good i looked into TFLite optimiziations and got some issues with the conversion from saved_model to .tflite format. ", "@terryheo I'm using a prebuilt arm 32bit wheel found here:\r\nhttps://github.com/PINTO0309/Tensorflow-bin\r\n\r\nI'm using raspbian 32bit, i will try ubuntu 64bit as you suggested.\r\n \r\nThanks,", "@N1ckx Could you please let us know if you have tried as per [this comment](https://github.com/tensorflow/tensorflow/issues/46107#issuecomment-758466789) and  this issue still persists ? Thanks! ", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46107\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46107\">No</a>\n"]}, {"number": 46105, "title": "Fix MobileNetV3 Preprocess", "body": "I measured Top1-Acc of ImageNet pretrained MobileNetV3Large model in `tensorflow/tensorflow/python/keras/applications/mobilenet_v3.py` , but 65% is measured.\r\n\r\nAfter changing preprocess layer\r\n```python\r\nx = layers.Rescaling(1. / 255.)(x)\r\n```\r\nto\r\n```python\r\nx = layers.Rescaling(scale=1./127.5, offset=-1.)(x)\r\n```\r\ncan measure 72.5% Top1-Acc.\r\n\r\n\r\n", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F46105) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!"]}, {"number": 46104, "title": "Hello guys , does any one know how to solve this issue ? Thanks in advance!", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\n\r\n**Describe the expected behavior**\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["My code is here :+1: #!sur/bin/python3\r\n# -*-coding:utf-8 -*-\r\n# Author: Wang Quan\r\n# @Time:2021/1/2 7:46\r\n\r\nimport tensorflow as tf\r\nimport matplotlib.pyplot as plt\r\nfrom tensorflow import keras\r\n# from tensorflow.keras.models import Sequential\r\nimport numpy as np\r\nimport math\r\n\r\n(x_train,y_train),(x_test,y_test)=keras.datasets.mnist.load_data()\r\n# print(len(x_train))\r\n# print(len(x_test))\r\n# print(x_train[0].shape)\r\n# plt.matshow(x_train[0])\r\n# plt.show()\r\n# print(y_train[0])\r\n# print(x_train.shape)\r\nx_train=x_train/255.0\r\nx_test=x_test/255.0\r\n\r\nx_train_flattened= x_train.reshape(len(x_train),28*28)\r\nx_test_flattened= x_test.reshape(len(x_test),28*28)\r\n# print(x_train_flattened.shape)\r\n# print(x_test_flattened.shape)\r\n# print(x_train[2])\r\n# print(x_train_flattened[2])\r\n\r\nmodel=keras.Sequential([\r\n    keras.layers.Dense(10,input_shape=(784,),activation='sigmoid')\r\n])\r\n\r\nmodel.compile(optimizer='adam',\r\n              loss='sparse_categorical_crossentropy',\r\n              metrics=['accuracy'])\r\nmodel.fit(x_train_flattened,y_train,epochs=5)\r\nmodel.evaluate(x_test_flattened,y_test)\r\n\r\n# plt.matshow(x_test[2])\r\n# plt.show()\r\ny_predict=model.predict(x_test_flattened)\r\nprint(np.argmax(y_predict[2]))   #\u6253\u53707\r\n\r\ny_predicted_labels = [np.argmax(i) for i in y_predict]\r\n# print(y_predicted_labels[:5])\r\n# # y_test[:5]\r\ncm=tf.math.confusion_matrix(labels=y_test,predictions=y_predicted_labels)\r\nprint(cm)\r\nimport seaborn as sn\r\nplt.figure(figsize=(10,7))\r\nsn.heatmap(cm,annot=True,fmt='d')\r\nplt.xlabel('predicted')\r\nplt.ylabel('truth')\r\nplt.show()\r\n\r\nI got error :Tensor(\"confusion_matrix/SparseTensorDenseAdd:0\", shape=(10, 10), dtype=int32)\r\nTraceback (most recent call last):\r\n  File \"C:/Users/Administrator/Desktop/\u5149\u5b66\u7cfb\u7edf/Keras Code/mnist read.py\", line 53, in <module>\r\n    sn.heatmap(cm,annot=True,fmt='d')\r\n  File \"C:\\Users\\Administrator\\Anaconda3\\envs\\pythonProject\\lib\\site-packages\\seaborn\\_decorators.py\", line 46, in inner_f\r\n    return f(**kwargs)\r\n  File \"C:\\Users\\Administrator\\Anaconda3\\envs\\pythonProject\\lib\\site-packages\\seaborn\\matrix.py\", line 537, in heatmap\r\n    yticklabels, mask)\r\n  File \"C:\\Users\\Administrator\\Anaconda3\\envs\\pythonProject\\lib\\site-packages\\seaborn\\matrix.py\", line 101, in __init__\r\n    plot_data = np.asarray(data)\r\n  File \"C:\\Users\\Administrator\\Anaconda3\\envs\\pythonProject\\lib\\site-packages\\numpy\\core\\_asarray.py\", line 83, in asarray\r\n    return array(a, dtype, copy=False, order=order)\r\n  File \"C:\\Users\\Administrator\\Anaconda3\\envs\\pythonProject\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 736, in __array__\r\n    \" array.\".format(self.name))\r\nNotImplementedError: Cannot convert a symbolic Tensor (confusion_matrix/SparseTensorDenseAdd:0) to a numpy array.\r\n\r\n", "Please:\r\n\r\n1. Fill in issue template\r\n2. Use proper markdown formatting so code and error are easy to read\r\n3. Give a minimal reproducing example, not a large piece of code\r\n4. Give the issue a relevant title.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46104\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46104\">No</a>\n"]}, {"number": 46103, "title": "ProfilerNotRunningError: Cannot stop profiling. No profiler is running. raised using profiler in tf.function", "body": "Hello. I'm trying to use profiling in my custom tf.function, but I'm getting the following error calling `tf.summary.trace_export` \r\n\r\n`tensorflow.python.eager.profiler.ProfilerNotRunningError: Cannot stop profiling. No profiler is running.`\r\n\r\nI followed the tutorial in [https://www.tensorflow.org/tensorboard/graphs](https://www.tensorflow.org/tensorboard/graphs) and I realized the error is raised in the tutorial too in line `tf.summary.trace_export(\r\n      name=\"my_func_trace\",\r\n      step=0,\r\n      profiler_outdir=logdir)`. I ran it using google colab in remote enviroment so I guess is a bug in version 2.4\r\n\r\nDoes anybody another way to achieve it?\r\n", "comments": ["I've just tried the google colab script using tensorflow 2.2 with `!pip install tensorflow==2.2` and it runs perfectly, it also works well in 2.3, when I come back to tensorflow 2.4 it fails again so it's a problem in the 2.4 version.", "@JacdDev \r\n\r\nThe issue was fixed in TF nightly version. Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/6d100b4fcd1f33709b9eac13d29a6a4f/untitled592.ipynb).Please, verify once and close the issue. Thanks!", "@ravikyram \r\n\r\nThe code runs perfectly using tf-nightly, but when I try to visualize the tensorboard panel running `%tensorboard --logdir logs/func` it trows the following error, I don't know if they are related or it is a different issue:\r\n\r\nERROR: Failed to launch TensorBoard (exited with 1).\r\nContents of stderr:\r\n2021-01-04 08:57:20.911634: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\r\n2021-01-04 08:57:20.911700: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\r\nTraceback (most recent call last):\r\n  File \"/usr/local/bin/tensorboard\", line 8, in <module>\r\n    sys.exit(run_main())\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/main.py\", line 71, in run_main\r\n    app.run(tensorboard.main, flags_parser=tensorboard.configure)\r\n  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 300, in run\r\n    _run_main(main, args)\r\n  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 251, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/program.py\", line 283, in main\r\n    return runner(self.flags) or 0\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/program.py\", line 299, in _run_serve_subcommand\r\n    server = self._make_server()\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/program.py\", line 436, in _make_server\r\n    deprecated_multiplexer,\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/backend/application.py\", line 149, in TensorBoardWSGIApp\r\n    experimental_middlewares,\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/backend/application.py\", line 257, in __init__\r\n    \"Duplicate plugins for name %s\" % plugin.plugin_name\r\nValueError: Duplicate plugins for name projector", "@JacdDev \r\n\r\nPlease, refer the [link](https://github.com/tensorflow/tensorboard/issues/3443), [link1](https://stackoverflow.com/questions/57228487/valueerror-duplicate-plugins-for-name-projector) and see if it helps you. Thanks!", "@ravikyram \r\n\r\nThanks, the problem was solved unistalling tensorboard before installing tf-nighlty as said in [this comment](https://github.com/tensorflow/tensorboard/issues/3443#issuecomment-618114726)", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46103\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46103\">No</a>\n"]}, {"number": 46102, "title": "ImportError: cannot import name 'function_pb2' from 'tensorflow.core.framework' (unknown location)", "body": "**System information**\r\n- ubuntu20.04\r\n- build tf from source\r\n- TensorFlow version (use command below):2.5\r\n- Python version:3.8.5\r\n- Bazel version (if compiling from source):3.7.2\r\n- GCC/Compiler version (if compiling from source):gcc-9\r\n- CUDA/cuDNN version:11.1\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py\", line 41, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py\", line 40, in <module>\r\n    from tensorflow.python.eager import context\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py\", line 35, in <module>\r\n    from tensorflow.python import pywrap_tfe\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/pywrap_tfe.py\", line 28, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/pywrap_tensorflow.py\", line 83, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/pywrap_tensorflow.py\", line 64, in <module>\r\n    from tensorflow.python._pywrap_tensorflow_internal import *\r\nImportError: libtensorflow_framework.so.2: cannot open shared object file: No such file or directory\r\n", "comments": ["first: coundn't run python -c \"import tensorflow as tf; print(tf.__version__)\" in tensorflow source code directory.\r\nsecond, shoud build libtensorflow target and copy all *.so file to library search path", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46102\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46102\">No</a>\n"]}, {"number": 46101, "title": "Building TF 2.3.1 with CUDA 11.1 fails with undefined protobuf symbol", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution: Ubuntu 20.04 LTS\r\n- TensorFlow installed from: Trying to build from source\r\n- TensorFlow version: 2.3.1\r\n- Python version: 3.8 with pip\r\n- Bazel version: 3.1.0 (also tried with 3.7.2)\r\n- GCC/Compiler version: 7.5.0 (also tried with 8.x, 9.x)\r\n- CUDA/cuDNN version: CUDA 11.1 / cuDNN 8 / TensorRT 7\r\n- GPU model and memory: RTX 3070 8GB\r\n<br>\r\n\r\n**Describe the problem**\r\nI've tried to build Tensorflow 2.3.1 with CUDA 11.1 to support RTX 3070,\r\nbut it always fails because of the problem related to undefined symbol in protobuf.\r\n(I need to use 2.3.1 instead of 2.4.0 or 2.5.0 because of the compatibility with other framework now.)\r\n<br>\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nThese are my commands which were used to build TF.\r\n```\r\n$ cd ~/utils/tensorflow\r\n$ bazel clean\r\n$ ./configure\r\nYou have bazel 3.1.0 installed.\r\nPlease specify the location of python. [Default is /usr/bin/python3]: \r\n\r\n\r\nFound possible Python library paths:\r\n  /usr/local/lib/python3.8/dist-packages\r\n  /usr/lib/python3.8/dist-packages\r\n  /home/sjlee/utils/tvm/python\r\n  /usr/lib/python3/dist-packages\r\nPlease input the desired Python library path to use.  Default is [/usr/local/lib/python3.8/dist-packages]\r\n\r\nDo you wish to build TensorFlow with OpenCL SYCL support? [y/N]: n\r\nNo OpenCL SYCL support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with ROCm support? [y/N]: n\r\nNo ROCm support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with CUDA support? [y/N]: y\r\nCUDA support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with TensorRT support? [y/N]: y\r\nTensorRT support will be enabled for TensorFlow.\r\n\r\nFound CUDA 11.1 in:\r\n    /usr/local/cuda-11.1/targets/x86_64-linux/lib\r\n    /usr/local/cuda-11.1/targets/x86_64-linux/include\r\nFound cuDNN 8 in:\r\n    /usr/lib/x86_64-linux-gnu\r\n    /usr/include\r\nFound TensorRT 7 in:\r\n    /usr/lib/x86_64-linux-gnu\r\n    /usr/include/x86_64-linux-gnu\r\n\r\n\r\nPlease specify a list of comma-separated CUDA compute capabilities you want to build with.\r\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus. Each capability can be specified as \"x.y\" or \"compute_xy\" to include both virtual and binary GPU code, or as \"sm_xy\" to only include the binary code.\r\nPlease note that each additional compute capability significantly increases your build time and binary size, and that TensorFlow only supports compute capabilities >= 3.5 [Default is: 8.6]: 8.6,7.5,6.1\r\n\r\n\r\nDo you want to use clang as CUDA compiler? [y/N]: n\r\nnvcc will be used as CUDA compiler.\r\n\r\nPlease specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: \r\n\r\n\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native -Wno-sign-compare]: \r\n\r\n\r\nWould you like to interactively configure ./WORKSPACE for Android builds? [y/N]: n\r\nNot configuring the WORKSPACE for Android builds.\r\n\r\nPreconfigured Bazel build configs. You can use any of the below by adding \"--config=<>\" to your build command. See .bazelrc for more details.\r\n        --config=mkl            # Build with MKL support.\r\n        --config=monolithic     # Config for mostly static monolithic build.\r\n        --config=ngraph         # Build with Intel nGraph support.\r\n        --config=numa           # Build with NUMA support.\r\n        --config=dynamic_kernels        # (Experimental) Build kernels into separate shared objects.\r\n        --config=v2             # Build TensorFlow 2.x instead of 1.x.\r\nPreconfigured Bazel build configs to DISABLE default on features:\r\n        --config=noaws          # Disable AWS S3 filesystem support.\r\n        --config=nogcp          # Disable GCP support.\r\n        --config=nohdfs         # Disable HDFS support.\r\n        --config=nonccl         # Disable NVIDIA NCCL support.\r\nConfiguration finished\r\n\r\n$ bazel build -c opt --copt=-mavx --copt=-mavx2 --copt=-mfma --copt=-mfpmath=both --copt=-msse4.2 //tensorflow/tools/pip_package:build_pip_package\r\n```\r\n<br>\r\n\r\n**Any other info / logs**\r\nBuild fails with these error messages. It says there are undefined symbol named \"fixed_address_empty_string\".\r\nI've referenced other issues related to my case, but nothing helped for me.\r\nI think sources for protobuf were already compiled before tensorflow kernels, so I cannot understand why the error occurs.\r\n```\r\nERROR: /home/sjlee/utils/tensorflow/tensorflow/python/BUILD:2823:29: Executing genrule //tensorflow/python:clustering_ops_pygenrule failed (Exit 127): bash failed: error executing command /bin/bash bazel-out/k8-opt/bin/tensorflow/python/clustering_ops_pygenrule.genrule_script.sh\r\nbazel-out/k8-opt-exec-50AE0418/bin/tensorflow/python/gen_clustering_ops_py_wrappers_cc: symbol lookup error: bazel-out/k8-opt-exec-50AE0418/bin/tensorflow/python/gen_clustering_ops_py_wrappers_cc: undefined symbol: _ZN6google8protobuf8internal26fixed_address_empty_stringB5cxx11E\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 2049.987s, Critical Path: 94.77s\r\nINFO: 26147 processes: 11918 internal, 14229 local.\r\nFAILED: Build did NOT complete successfully\r\n```\r\n<br>\r\n\r\nThese info messages also can be found during build process.\r\nCould these ones be related to the error above?\r\n```\r\nINFO: From ProtoCompile tensorflow/core/protobuf/saved_object_graph.pb.h [for host]:\r\nbazel-out/host/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/protobuf/queue_runner.pb.h [for host]:\r\nbazel-out/host/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/protobuf/graph_debug_info.pb.h [for host]:\r\nbazel-out/host/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/protobuf/tensor_bundle.pb.h [for host]:\r\nbazel-out/host/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/protobuf/saver.pb.h [for host]:\r\nbazel-out/host/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/protobuf/trackable_object_graph.pb.h [for host]:\r\nbazel-out/host/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/protobuf/transport_options.pb.h [for host]:\r\nbazel-out/host/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/grappler/costs/op_performance_data.pb.h:\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/protobuf/device_filters.pb.h [for host]:\r\nbazel-out/host/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/framework/node_def.pb.h [for host]:\r\nbazel-out/host/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\n```\r\n<br>\r\n\r\nThank you :)", "comments": ["@lsj1213m \r\nCan you please downgrade to cuda 11.0 and let us know, also try to upgrade tf version to 2.4 stable and let us know if you still face any issues.", "@Saduf2019\r\nThere were no differences even though cuda version is downgraded to 11.0.\r\nI've used anaconda environment for python this time.\r\n\r\nI'll try to upgrade TF version to 2.4 (which is meaningless to me since I need to use some frameworks which depend on TF < 2.4), but will it show any better results? I'll let you know after try it.\r\n\r\nHere are my error logs below. Have you any suggestions for me?\r\nThanks in advance :>\r\n\r\n```\r\nERROR: /home/sjlee/utils/tensorflow/tensorflow/python/BUILD:2752:1: Executing genrule //tensorflow/python:array_ops_pygenrule failed (Exit 127): bash failed: error executing command \r\n  (cd /home/sjlee/.cache/bazel/_bazel_sjlee/89c17407a125e0baea0a2b2ceea6ee6a/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    LD_LIBRARY_PATH=:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/home/sjlee/utils/TensorRT-7.2.1.6/lib:/usr/local/lib:/usr/lib::/usr/local/lib/x86_64-linux-gnu/gstreamer-1.0:/usr/lib/python3.8/config-3.8-x86_64-linux-gnu \\\r\n    PATH=/home/sjlee/anaconda3/envs/py38/bin:/home/sjlee/anaconda3/condabin:/home/sjlee/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/home/sjlee/.local/bin:/usr/local/bin:/usr/local/cuda/bin \\\r\n  /bin/bash bazel-out/host/bin/tensorflow/python/array_ops_pygenrule.genrule_script.sh)\r\nExecution platform: @local_execution_config_platform//:platform\r\nbazel-out/host/bin/tensorflow/python/gen_array_ops_py_wrappers_cc: symbol lookup error: bazel-out/host/bin/tensorflow/python/gen_array_ops_py_wrappers_cc: undefined symbol: _ZN6google8protobuf8internal26fixed_address_empty_stringB5cxx11E\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nERROR: /home/sjlee/utils/tensorflow/tensorflow/python/tools/BUILD:82:1 Executing genrule //tensorflow/python:array_ops_pygenrule failed (Exit 127): bash failed: error executing command \r\n  (cd /home/sjlee/.cache/bazel/_bazel_sjlee/89c17407a125e0baea0a2b2ceea6ee6a/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    LD_LIBRARY_PATH=:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/home/sjlee/utils/TensorRT-7.2.1.6/lib:/usr/local/lib:/usr/lib::/usr/local/lib/x86_64-linux-gnu/gstreamer-1.0:/usr/lib/python3.8/config-3.8-x86_64-linux-gnu \\\r\n    PATH=/home/sjlee/anaconda3/envs/py38/bin:/home/sjlee/anaconda3/condabin:/home/sjlee/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/home/sjlee/.local/bin:/usr/local/bin:/usr/local/cuda/bin \\\r\n  /bin/bash bazel-out/host/bin/tensorflow/python/array_ops_pygenrule.genrule_script.sh)\r\nExecution platform: @local_execution_config_platform//:platform\r\nINFO: Elapsed time: 4782.271s, Critical Path: 293.27s\r\nINFO: 18834 processes: 18834 local.\r\nFAILED: Build did NOT complete successfully\r\n```", "I've tried to build TF 2.4 + CUDA 11.1 within my environment, but it also shows same error messages.\r\nHere are my error messages.\r\n\r\n```\r\nbazel build --config=opt --config=mkl --copt=-mavx --copt=-mavx2 --copt=-mfma --copt=-mfpmath=both --copt=-msse4.2 //tensorflow/tools/pip_package:build_pip_package --verbose_failures\r\nStarting local Bazel server and connecting to it...\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=90\r\nINFO: Reading rc options for 'build' from /home/sjlee/utils/tensorflow-2.4/.bazelrc:\r\n  Inherited 'common' options: --experimental_repo_remote_exec\r\nINFO: Reading rc options for 'build' from /home/sjlee/utils/tensorflow-2.4/.bazelrc:\r\n  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=tensorflow_enable_mlir_generated_gpu_kernels=0 --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=short_logs --config=v2\r\nINFO: Reading rc options for 'build' from /home/sjlee/utils/tensorflow-2.4/.tf_configure.bazelrc:\r\n  'build' options: --action_env PYTHON_BIN_PATH=/home/sjlee/anaconda3/envs/py38/bin/python3 --action_env PYTHON_LIB_PATH=/home/sjlee/anaconda3/envs/py38/lib/python3.8/site-packages --python_path=/home/sjlee/anaconda3/envs/py38/bin/python3 --config=xla --config=tensorrt --action_env CUDA_TOOLKIT_PATH=/usr/local/cuda-11.1 --action_env TF_CUDA_COMPUTE_CAPABILITIES=8.6,7.5,6.1 --action_env LD_LIBRARY_PATH=:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/home/sjlee/utils/TensorRT-7.2.1.6/lib:/usr/local/lib:/usr/lib::/usr/local/lib/x86_64-linux-gnu/gstreamer-1.0:/usr/lib/python3.8/config-3.8-x86_64-linux-gnu --action_env GCC_HOST_COMPILER_PATH=/usr/bin/x86_64-linux-gnu-gcc-7 --config=cuda --action_env TF_CONFIGURE_IOS=0\r\nINFO: Found applicable config definition build:short_logs in file /home/sjlee/utils/tensorflow-2.4/.bazelrc: --output_filter=DONT_MATCH_ANYTHING\r\nINFO: Found applicable config definition build:v2 in file /home/sjlee/utils/tensorflow-2.4/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1\r\nINFO: Found applicable config definition build:xla in file /home/sjlee/utils/tensorflow-2.4/.bazelrc: --define=with_xla_support=true\r\nINFO: Found applicable config definition build:tensorrt in file /home/sjlee/utils/tensorflow-2.4/.bazelrc: --action_env TF_NEED_TENSORRT=1\r\nINFO: Found applicable config definition build:cuda in file /home/sjlee/utils/tensorflow-2.4/.bazelrc: --config=using_cuda --define=using_cuda_nvcc=true\r\nINFO: Found applicable config definition build:using_cuda in file /home/sjlee/utils/tensorflow-2.4/.bazelrc: --define=using_cuda=true --action_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain --define=tensorflow_enable_mlir_generated_gpu_kernels=1\r\nINFO: Found applicable config definition build:opt in file /home/sjlee/utils/tensorflow-2.4/.tf_configure.bazelrc: --copt=-march=native --copt=-Wno-sign-compare --host_copt=-march=native --define with_default_optimizations=true\r\nINFO: Found applicable config definition build:mkl in file /home/sjlee/utils/tensorflow-2.4/.bazelrc: --define=build_with_mkl=true --define=enable_mkl=true --define=tensorflow_mkldnn_contraction_kernel=0 --define=build_with_openmp=true -c opt\r\nINFO: Found applicable config definition build:linux in file /home/sjlee/utils/tensorflow-2.4/.bazelrc: --copt=-w --host_copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels\r\nINFO: Found applicable config definition build:dynamic_kernels in file /home/sjlee/utils/tensorflow-2.4/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS\r\nDEBUG: Rule 'io_bazel_rules_go' indicated that a canonical reproducible form can be obtained by modifying arguments shallow_since = \"1557349968 -0400\"\r\nDEBUG: Repository io_bazel_rules_go instantiated at:\r\n  no stack (--record_rule_instantiation_callstack not enabled)\r\nRepository rule git_repository defined at:\r\n  /home/sjlee/.cache/bazel/_bazel_sjlee/dc5364fb96d178712b85bb0d5a043304/external/bazel_tools/tools/build_defs/repo/git.bzl:195:18: in <toplevel>\r\nDEBUG: Rule 'io_bazel_rules_docker' indicated that a canonical reproducible form can be obtained by modifying arguments shallow_since = \"1556410077 -0400\"\r\nDEBUG: Repository io_bazel_rules_docker instantiated at:\r\n  no stack (--record_rule_instantiation_callstack not enabled)\r\nRepository rule git_repository defined at:\r\n  /home/sjlee/.cache/bazel/_bazel_sjlee/dc5364fb96d178712b85bb0d5a043304/external/bazel_tools/tools/build_defs/repo/git.bzl:195:18: in <toplevel>\r\nWARNING: Download from https://storage.googleapis.com/mirror.tensorflow.org/github.com/llvm/llvm-project/archive/f402e682d0ef5598eeffc9a21a691b03e602ff58.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found\r\nINFO: Analyzed target //tensorflow/tools/pip_package:build_pip_package (416 packages loaded, 33315 targets configured).\r\nINFO: Found 1 target...\r\nERROR: /home/sjlee/utils/tensorflow-2.4/tensorflow/python/BUILD:3274:1: Executing genrule //tensorflow/python:sdca_ops_pygenrule failed (Exit 127): bash failed: error executing command \r\n  (cd /home/sjlee/.cache/bazel/_bazel_sjlee/dc5364fb96d178712b85bb0d5a043304/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    LD_LIBRARY_PATH=:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/home/sjlee/utils/TensorRT-7.2.1.6/lib:/usr/local/lib:/usr/lib::/usr/local/lib/x86_64-linux-gnu/gstreamer-1.0:/usr/lib/python3.8/config-3.8-x86_64-linux-gnu \\\r\n    PATH=/home/sjlee/anaconda3/envs/py38/bin:/home/sjlee/anaconda3/condabin:/home/sjlee/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/home/sjlee/.local/bin:/usr/local/bin:/usr/local/cuda/bin \\\r\n  /bin/bash bazel-out/host/bin/tensorflow/python/sdca_ops_pygenrule.genrule_script.sh)\r\nExecution platform: @local_execution_config_platform//:platform\r\nbazel-out/host/bin/tensorflow/python/gen_sdca_ops_py_wrappers_cc: symbol lookup error: bazel-out/host/bin/tensorflow/python/gen_sdca_ops_py_wrappers_cc: undefined symbol: _ZN6google8protobuf8internal26fixed_address_empty_stringB5cxx11E\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nERROR: /home/sjlee/utils/tensorflow-2.4/tensorflow/tools/pip_package/BUILD:69:1 Executing genrule //tensorflow/python:sdca_ops_pygenrule failed (Exit 127): bash failed: error executing command \r\n  (cd /home/sjlee/.cache/bazel/_bazel_sjlee/dc5364fb96d178712b85bb0d5a043304/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    LD_LIBRARY_PATH=:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/home/sjlee/utils/TensorRT-7.2.1.6/lib:/usr/local/lib:/usr/lib::/usr/local/lib/x86_64-linux-gnu/gstreamer-1.0:/usr/lib/python3.8/config-3.8-x86_64-linux-gnu \\\r\n    PATH=/home/sjlee/anaconda3/envs/py38/bin:/home/sjlee/anaconda3/condabin:/home/sjlee/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/home/sjlee/.local/bin:/usr/local/bin:/usr/local/cuda/bin \\\r\n  /bin/bash bazel-out/host/bin/tensorflow/python/sdca_ops_pygenrule.genrule_script.sh)\r\nExecution platform: @local_execution_config_platform//:platform\r\nINFO: Elapsed time: 4441.157s, Critical Path: 387.54s\r\nINFO: 14989 processes: 14989 local.\r\nFAILED: Build did NOT complete successfully\r\n```", "@rmothukuru @Saduf2019\r\nI've reinstalled whole Ubuntu 20.04 and tried to rebuild TF 2.3.1 with CUDA 11.1 in a clean state, then it succeeded!\r\nI don't know what was actually problematic, but I expect there were misleading library files related with protobuffer somewhere..\r\n\r\nThanks for your care :)", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46101\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46101\">No</a>\n"]}, {"number": 46100, "title": "Exported TFLite Inference Graph (Step 1), but can't Convert to TFLite (Step 2)", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- TensorFlow installed from (source or binary): from Anaconda command using pip install\r\n- TensorFlow version (or github SHA if from source): 2.4.0\r\n\r\n**What I did**\r\n\r\nBased on:\r\n[https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_on_mobile_tf2.md](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_on_mobile_tf2.md)\r\n\r\n### Step 1 : Export TFLite inference graph\r\n**Step 1.1 : Input via Anaconda command**\r\n```\r\ncd D:\\Documents\\AI\\Github Trials\\models-master\\research\r\n\r\nset PYTHONPATH=`pwd`:`pwd`/slim\r\npython setup.py build\r\npython setup.py install\r\npip install tf-slim\r\nprotoc object_detection/protos/*.proto --python_out=.\r\npip install .\r\npip install tf-models-official\r\n\r\npython object_detection/export_tflite_graph_tf2.py  --pipeline_config_path object_detection/ssd_mobilenet_v2_320x320_coco17_tpu-8/pipeline.config  --trained_checkpoint_dir object_detection/ssd_mobilenet_v2_320x320_coco17_tpu-8/checkpoint  --output_directory object_detection/ssd_mobilenet_v2_320x320_coco17_tpu-8/tflite_inference_graph\r\n```\r\n**Step 1.2 : Output from Anaconda Command**\r\nEmphasis on the following part of the Output\r\n```\r\nWARNING:tensorflow:AutoGraph could not transform <bound method SSDModule.inference_fn of <tensorflow.python.eager.functi\r\non.TfMethodTarget object at 0x00000236A95C61C8>> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: module 'gast' has no attribute 'Constant'\r\n```\r\nFull version of the **same** Output\r\n```\r\nRequirement already satisfied: tf-models-official in d:\\anaconda3\\envs\\tf\\lib\\site-packages (2.3.0)\r\nRequirement already satisfied: kaggle>=1.3.9 in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from tf-models-official) (1.5.10\r\n)\r\nRequirement already satisfied: tensorflow-model-optimization>=0.2.1 in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from tf-m\r\nodels-official) (0.5.0)\r\nRequirement already satisfied: py-cpuinfo>=3.3.0 in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from tf-models-official) (7.\r\n0.0)\r\nRequirement already satisfied: opencv-python-headless in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from tf-models-official\r\n) (4.4.0.46)\r\nRequirement already satisfied: pandas>=0.22.0 in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from tf-models-official) (1.1.4\r\n)\r\nRequirement already satisfied: six in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from tf-models-official) (1.15.0)\r\nRequirement already satisfied: tensorflow-hub>=0.6.0 in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from tf-models-official)\r\n (0.10.0)\r\nRequirement already satisfied: scipy>=0.19.1 in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from tf-models-official) (1.4.1)\r\n\r\nRequirement already satisfied: tensorflow-addons in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from tf-models-official) (0.\r\n12.0)\r\nRequirement already satisfied: pyyaml in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from tf-models-official) (5.3.1)\r\nRequirement already satisfied: psutil>=5.4.3 in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from tf-models-official) (5.7.2)\r\n\r\nRequirement already satisfied: matplotlib in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from tf-models-official) (3.3.3)\r\nRequirement already satisfied: google-cloud-bigquery>=0.31.0 in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from tf-models-o\r\nfficial) (2.6.1)\r\nRequirement already satisfied: tensorflow-datasets in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from tf-models-official) (\r\n4.1.0)\r\nRequirement already satisfied: dataclasses in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from tf-models-official) (0.6)\r\nRequirement already satisfied: tf-slim>=1.1.0 in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from tf-models-official) (1.1.0\r\n)\r\nRequirement already satisfied: google-api-python-client>=1.6.7 in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from tf-models\r\n-official) (1.12.8)\r\nRequirement already satisfied: Cython in d:\\anaconda3\\envs\\tf\\lib\\site-packages\\cython-3.0a6-py3.7-win-amd64.egg (from t\r\nf-models-official) (3.0a6)\r\nRequirement already satisfied: numpy>=1.15.4 in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from tf-models-official) (1.19.4\r\n)\r\nRequirement already satisfied: Pillow in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from tf-models-official) (8.0.1)\r\nRequirement already satisfied: gin-config in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from tf-models-official) (0.4.0)\r\nRequirement already satisfied: tensorflow>=2.3.0 in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from tf-models-official) (2.\r\n4.0)\r\nRequirement already satisfied: sentencepiece in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from tf-models-official) (0.1.94\r\n)\r\nRequirement already satisfied: urllib3 in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from kaggle>=1.3.9->tf-models-official\r\n) (1.25.11)\r\nRequirement already satisfied: python-slugify in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from kaggle>=1.3.9->tf-models-o\r\nfficial) (4.0.1)\r\nRequirement already satisfied: requests in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from kaggle>=1.3.9->tf-models-officia\r\nl) (2.24.0)\r\nRequirement already satisfied: python-dateutil in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from kaggle>=1.3.9->tf-models-\r\nofficial) (2.8.1)\r\nRequirement already satisfied: certifi in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from kaggle>=1.3.9->tf-models-official\r\n) (2020.6.20)\r\nRequirement already satisfied: tqdm in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from kaggle>=1.3.9->tf-models-official) (\r\n4.54.0)\r\nRequirement already satisfied: dm-tree~=0.1.1 in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from tensorflow-model-optimizat\r\nion>=0.2.1->tf-models-official) (0.1.5)\r\nRequirement already satisfied: pytz>=2017.2 in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from pandas>=0.22.0->tf-models-of\r\nficial) (2020.1)\r\nRequirement already satisfied: protobuf>=3.8.0 in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from tensorflow-hub>=0.6.0->tf\r\n-models-official) (3.13.0)\r\nRequirement already satisfied: typeguard>=2.7 in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from tensorflow-addons->tf-mode\r\nls-official) (2.10.0)\r\nRequirement already satisfied: cycler>=0.10 in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from matplotlib->tf-models-offici\r\nal) (0.10.0)\r\nRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from\r\nmatplotlib->tf-models-official) (2.4.7)\r\nRequirement already satisfied: kiwisolver>=1.0.1 in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from matplotlib->tf-models-o\r\nfficial) (1.3.1)\r\nRequirement already satisfied: google-api-core[grpc]<2.0.0dev,>=1.23.0 in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from g\r\noogle-cloud-bigquery>=0.31.0->tf-models-official) (1.24.1)\r\nRequirement already satisfied: proto-plus>=1.10.0 in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from google-cloud-bigquery>\r\n=0.31.0->tf-models-official) (1.13.0)\r\nRequirement already satisfied: google-resumable-media<2.0dev,>=0.6.0 in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from goo\r\ngle-cloud-bigquery>=0.31.0->tf-models-official) (1.2.0)\r\nRequirement already satisfied: google-cloud-core<2.0dev,>=1.4.1 in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from google-c\r\nloud-bigquery>=0.31.0->tf-models-official) (1.5.0)\r\nRequirement already satisfied: termcolor in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from tensorflow-datasets->tf-models-\r\nofficial) (1.1.0)\r\nRequirement already satisfied: typing-extensions; python_version < \"3.8\" in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from\r\n tensorflow-datasets->tf-models-official) (3.7.4.3)\r\nRequirement already satisfied: importlib-resources; python_version < \"3.9\" in d:\\anaconda3\\envs\\tf\\lib\\site-packages (fr\r\nom tensorflow-datasets->tf-models-official) (3.3.0)\r\nRequirement already satisfied: dill in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from tensorflow-datasets->tf-models-offic\r\nial) (0.3.3)\r\nRequirement already satisfied: absl-py in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from tensorflow-datasets->tf-models-of\r\nficial) (0.11.0)\r\nRequirement already satisfied: attrs>=18.1.0 in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from tensorflow-datasets->tf-mod\r\nels-official) (20.3.0)\r\nRequirement already satisfied: future in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from tensorflow-datasets->tf-models-off\r\nicial) (0.18.2)\r\nRequirement already satisfied: promise in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from tensorflow-datasets->tf-models-of\r\nficial) (2.3)\r\nRequirement already satisfied: tensorflow-metadata in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from tensorflow-datasets->\r\ntf-models-official) (0.25.0)\r\nRequirement already satisfied: uritemplate<4dev,>=3.0.0 in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from google-api-pytho\r\nn-client>=1.6.7->tf-models-official) (3.0.1)\r\nRequirement already satisfied: google-auth-httplib2>=0.0.3 in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from google-api-py\r\nthon-client>=1.6.7->tf-models-official) (0.0.4)\r\nRequirement already satisfied: httplib2<1dev,>=0.15.0 in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from google-api-python-\r\nclient>=1.6.7->tf-models-official) (0.18.1)\r\nRequirement already satisfied: google-auth>=1.16.0 in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from google-api-python-cli\r\nent>=1.6.7->tf-models-official) (1.23.0)\r\nRequirement already satisfied: wheel~=0.35 in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from tensorflow>=2.3.0->tf-models-\r\nofficial) (0.35.1)\r\nRequirement already satisfied: gast==0.3.3 in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from tensorflow>=2.3.0->tf-models-\r\nofficial) (0.3.3)\r\nRequirement already satisfied: tensorboard~=2.4 in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from tensorflow>=2.3.0->tf-mo\r\ndels-official) (2.4.0)\r\nRequirement already satisfied: google-pasta~=0.2 in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from tensorflow>=2.3.0->tf-m\r\nodels-official) (0.2.0)\r\nRequirement already satisfied: astunparse~=1.6.3 in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from tensorflow>=2.3.0->tf-m\r\nodels-official) (1.6.3)\r\nRequirement already satisfied: grpcio~=1.32.0 in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from tensorflow>=2.3.0->tf-mode\r\nls-official) (1.32.0)\r\nRequirement already satisfied: wrapt~=1.12.1 in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from tensorflow>=2.3.0->tf-model\r\ns-official) (1.12.1)\r\nRequirement already satisfied: keras-preprocessing~=1.1.2 in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from tensorflow>=2.\r\n3.0->tf-models-official) (1.1.2)\r\nRequirement already satisfied: h5py~=2.10.0 in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from tensorflow>=2.3.0->tf-models\r\n-official) (2.10.0)\r\nRequirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0rc0 in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from ten\r\nsorflow>=2.3.0->tf-models-official) (2.4.0)\r\nRequirement already satisfied: flatbuffers~=1.12.0 in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from tensorflow>=2.3.0->tf\r\n-models-official) (1.12)\r\nRequirement already satisfied: opt-einsum~=3.3.0 in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from tensorflow>=2.3.0->tf-m\r\nodels-official) (3.3.0)\r\nRequirement already satisfied: text-unidecode>=1.3 in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from python-slugify->kaggl\r\ne>=1.3.9->tf-models-official) (1.3)\r\nRequirement already satisfied: chardet<4,>=3.0.2 in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from requests->kaggle>=1.3.9\r\n->tf-models-official) (3.0.4)\r\nRequirement already satisfied: idna<3,>=2.5 in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from requests->kaggle>=1.3.9->tf-\r\nmodels-official) (2.10)\r\nRequirement already satisfied: setuptools in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from protobuf>=3.8.0->tensorflow-hu\r\nb>=0.6.0->tf-models-official) (50.3.1.post20201107)\r\nRequirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from g\r\noogle-api-core[grpc]<2.0.0dev,>=1.23.0->google-cloud-bigquery>=0.31.0->tf-models-official) (1.52.0)\r\nRequirement already satisfied: google-crc32c<2.0dev,>=1.0; python_version >= \"3.5\" in d:\\anaconda3\\envs\\tf\\lib\\site-pack\r\nages (from google-resumable-media<2.0dev,>=0.6.0->google-cloud-bigquery>=0.31.0->tf-models-official) (1.1.0)\r\nRequirement already satisfied: zipp>=0.4; python_version < \"3.8\" in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from importl\r\nib-resources; python_version < \"3.9\"->tensorflow-datasets->tf-models-official) (3.4.0)\r\nRequirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.5\" in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from go\r\nogle-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official) (4.6)\r\nRequirement already satisfied: pyasn1-modules>=0.2.1 in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from google-auth>=1.16.0\r\n->google-api-python-client>=1.6.7->tf-models-official) (0.2.8)\r\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from google-auth>=1.16.\r\n0->google-api-python-client>=1.6.7->tf-models-official) (4.1.1)\r\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from tensorboard\r\n~=2.4->tensorflow>=2.3.0->tf-models-official) (1.6.0)\r\nRequirement already satisfied: markdown>=2.6.8 in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from tensorboard~=2.4->tensorf\r\nlow>=2.3.0->tf-models-official) (3.3.2)\r\nRequirement already satisfied: werkzeug>=0.11.15 in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from tensorboard~=2.4->tenso\r\nrflow>=2.3.0->tf-models-official) (0.16.1)\r\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from tensorbo\r\nard~=2.4->tensorflow>=2.3.0->tf-models-official) (0.4.2)\r\nRequirement already satisfied: cffi>=1.0.0 in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from google-crc32c<2.0dev,>=1.0; p\r\nython_version >= \"3.5\"->google-resumable-media<2.0dev,>=0.6.0->google-cloud-bigquery>=0.31.0->tf-models-official) (1.14.\r\n3)\r\nRequirement already satisfied: pyasn1>=0.1.3 in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from rsa<5,>=3.1.4; python_versi\r\non >= \"3.5\"->google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official) (0.4.8)\r\nRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in d:\\anaconda3\\envs\\tf\\lib\\site-packages (fro\r\nm markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.3.0->tf-models-official) (2.0.0)\r\nRequirement already satisfied: requests-oauthlib>=0.7.0 in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from google-auth-oaut\r\nhlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.3.0->tf-models-official) (1.3.0)\r\nRequirement already satisfied: pycparser in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from cffi>=1.0.0->google-crc32c<2.0d\r\nev,>=1.0; python_version >= \"3.5\"->google-resumable-media<2.0dev,>=0.6.0->google-cloud-bigquery>=0.31.0->tf-models-offic\r\nial) (2.20)\r\nRequirement already satisfied: oauthlib>=3.0.0 in d:\\anaconda3\\envs\\tf\\lib\\site-packages (from requests-oauthlib>=0.7.0-\r\n>google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.3.0->tf-models-official) (3.1.0)\r\n\r\n(tf) D:\\Documents\\AI\\Github Trials\\models-master\\research>python object_detection/export_tflite_graph_tf2.py  --pipeline\r\n_config_path object_detection/ssd_mobilenet_v2_320x320_coco17_tpu-8/pipeline.config  --trained_checkpoint_dir object_det\r\nection/ssd_mobilenet_v2_320x320_coco17_tpu-8/checkpoint  --output_directory object_detection/ssd_mobilenet_v2_320x320_co\r\nco17_tpu-8/tflite_inference_graph\r\n2021-01-01 15:35:13.672770: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic\r\nlibrary cudart64_110.dll\r\n2021-01-01 15:36:02.206834: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_\r\ndevices not set\r\n2021-01-01 15:36:02.245547: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic\r\nlibrary nvcuda.dll\r\n2021-01-01 15:36:02.586806: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:\r\npciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1\r\ncoreClock: 1.62GHz coreCount: 6 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 104.43GiB/s\r\n2021-01-01 15:36:02.607594: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic\r\nlibrary cudart64_110.dll\r\n2021-01-01 15:36:03.530245: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic\r\nlibrary cublas64_11.dll\r\n2021-01-01 15:36:03.532987: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic\r\nlibrary cublasLt64_11.dll\r\n2021-01-01 15:36:03.896998: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic\r\nlibrary cufft64_10.dll\r\n2021-01-01 15:36:04.091753: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic\r\nlibrary curand64_10.dll\r\n2021-01-01 15:36:04.663251: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic\r\nlibrary cusolver64_10.dll\r\n2021-01-01 15:36:05.073078: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic\r\nlibrary cusparse64_11.dll\r\n2021-01-01 15:36:05.093508: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic\r\nlibrary cudnn64_8.dll\r\n2021-01-01 15:36:05.218116: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\r\n2021-01-01 15:36:05.287330: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized wit\r\nh oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:\r\n AVX2\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2021-01-01 15:36:05.334165: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:\r\npciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1\r\ncoreClock: 1.62GHz coreCount: 6 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 104.43GiB/s\r\n2021-01-01 15:36:05.339857: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic\r\nlibrary cudart64_110.dll\r\n2021-01-01 15:36:05.342356: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic\r\nlibrary cublas64_11.dll\r\n2021-01-01 15:36:05.351041: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic\r\nlibrary cublasLt64_11.dll\r\n2021-01-01 15:36:05.353842: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic\r\nlibrary cufft64_10.dll\r\n2021-01-01 15:36:05.356236: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic\r\nlibrary curand64_10.dll\r\n2021-01-01 15:36:05.358652: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic\r\nlibrary cusolver64_10.dll\r\n2021-01-01 15:36:05.362098: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic\r\nlibrary cusparse64_11.dll\r\n2021-01-01 15:36:05.370079: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic\r\nlibrary cudnn64_8.dll\r\n2021-01-01 15:36:05.373200: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\r\n2021-01-01 15:36:13.128203: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor\r\nwith strength 1 edge matrix:\r\n2021-01-01 15:36:13.131097: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0\r\n2021-01-01 15:36:13.132404: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N\r\n2021-01-01 15:36:13.161953: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:loc\r\nalhost/replica:0/task:0/device:GPU:0 with 2982 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus\r\n id: 0000:01:00.0, compute capability: 6.1)\r\n2021-01-01 15:36:13.202675: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_\r\ndevices not set\r\nWARNING:tensorflow:AutoGraph could not transform <bound method SSDModule.inference_fn of <tensorflow.python.eager.functi\r\non.TfMethodTarget object at 0x00000236A95C61C8>> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: module 'gast' has no attribute 'Constant'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:36:14.384240 10772 ag_logging.py:146] AutoGraph could not transform <bound method SSDModule.inference_fn of <te\r\nnsorflow.python.eager.function.TfMethodTarget object at 0x00000236A95C61C8>> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: module 'gast' has no attribute 'Constant'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <bound method FreezableBatchNorm.call of <object_detection.core.freezab\r\nle_batch_norm.FreezableBatchNorm object at 0x00000236B5ACB608>> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:36:14.768384 10772 ag_logging.py:146] AutoGraph could not transform <bound method FreezableBatchNorm.call of <o\r\nbject_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x00000236B5ACB608>> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <bound method SSDKerasFeatureExtractor.call of <object_detection.models\r\n.ssd_mobilenet_v2_keras_feature_extractor.SSDMobileNetV2KerasFeatureExtractor object at 0x00000236A2F5BE08>> and will ru\r\nn it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:36:16.034504 10772 ag_logging.py:146] AutoGraph could not transform <bound method SSDKerasFeatureExtractor.call\r\n of <object_detection.models.ssd_mobilenet_v2_keras_feature_extractor.SSDMobileNetV2KerasFeatureExtractor object at 0x00\r\n000236A2F5BE08>> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <bound method KerasMultiResolutionFeatureMaps.call of <object_detection\r\n.models.feature_map_generators.KerasMultiResolutionFeatureMaps object at 0x00000236C7AAA248>> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: module 'gast' has no attribute 'Constant'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:36:16.354562 10772 ag_logging.py:146] AutoGraph could not transform <bound method KerasMultiResolutionFeatureMa\r\nps.call of <object_detection.models.feature_map_generators.KerasMultiResolutionFeatureMaps object at 0x00000236C7AAA248>\r\n> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: module 'gast' has no attribute 'Constant'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nINFO:tensorflow:depth of additional conv before box predictor: 0\r\nI0101 15:36:17.339918 10772 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\r\nINFO:tensorflow:depth of additional conv before box predictor: 0\r\nI0101 15:36:17.342931 10772 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\r\nINFO:tensorflow:depth of additional conv before box predictor: 0\r\nI0101 15:36:17.347878 10772 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\r\nINFO:tensorflow:depth of additional conv before box predictor: 0\r\nI0101 15:36:17.350869 10772 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\r\nINFO:tensorflow:depth of additional conv before box predictor: 0\r\nI0101 15:36:17.357949 10772 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\r\nINFO:tensorflow:depth of additional conv before box predictor: 0\r\nI0101 15:36:17.358946 10772 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\r\nWARNING:tensorflow:AutoGraph could not transform <bound method KerasBoxPredictor.call of <object_detection.predictors.co\r\nnvolutional_keras_box_predictor.ConvolutionalBoxPredictor object at 0x00000236A9538508>> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:36:17.366203 10772 ag_logging.py:146] AutoGraph could not transform <bound method KerasBoxPredictor.call of <ob\r\nject_detection.predictors.convolutional_keras_box_predictor.ConvolutionalBoxPredictor object at 0x00000236A9538508>> and\r\n will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <bound method KerasHead.call of <object_detection.predictors.heads.kera\r\ns_box_head.ConvolutionalBoxHead object at 0x00000236A9165D48>> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:36:17.366203 10772 ag_logging.py:146] AutoGraph could not transform <bound method KerasHead.call of <object_det\r\nection.predictors.heads.keras_box_head.ConvolutionalBoxHead object at 0x00000236A9165D48>> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\n2021-01-01 15:36:17.494573: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:\r\npciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1\r\ncoreClock: 1.62GHz coreCount: 6 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 104.43GiB/s\r\n2021-01-01 15:36:17.501030: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic\r\nlibrary cudart64_110.dll\r\n2021-01-01 15:36:17.507623: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic\r\nlibrary cublas64_11.dll\r\n2021-01-01 15:36:17.513051: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic\r\nlibrary cublasLt64_11.dll\r\n2021-01-01 15:36:17.516730: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic\r\nlibrary cufft64_10.dll\r\n2021-01-01 15:36:17.519172: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic\r\nlibrary curand64_10.dll\r\n2021-01-01 15:36:17.521521: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic\r\nlibrary cusolver64_10.dll\r\n2021-01-01 15:36:17.523880: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic\r\nlibrary cusparse64_11.dll\r\n2021-01-01 15:36:17.533205: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic\r\nlibrary cudnn64_8.dll\r\n2021-01-01 15:36:17.536259: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\r\n2021-01-01 15:36:17.537924: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor\r\nwith strength 1 edge matrix:\r\n2021-01-01 15:36:17.540286: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0\r\n2021-01-01 15:36:17.541693: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N\r\n2021-01-01 15:36:17.543160: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:loc\r\nalhost/replica:0/task:0/device:GPU:0 with 2982 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus\r\n id: 0000:01:00.0, compute capability: 6.1)\r\n2021-01-01 15:36:17.553303: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_\r\ndevices not set\r\n2021-01-01 15:36:17.618925: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:196] None of the MLIR optimizatio\r\nn passes are enabled (registered 0 passes)\r\nWARNING:tensorflow:AutoGraph could not transform <function SSDModule._get_postprocess_fn.<locals>.dummy_post_processing\r\nat 0x00000236C7D27798> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:36:19.335623 10772 ag_logging.py:146] AutoGraph could not transform <function SSDModule._get_postprocess_fn.<lo\r\ncals>.dummy_post_processing at 0x00000236C7D27798> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\n2021-01-01 15:36:20.775396: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:\r\npciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1\r\ncoreClock: 1.62GHz coreCount: 6 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 104.43GiB/s\r\n2021-01-01 15:36:20.780405: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic\r\nlibrary cudart64_110.dll\r\n2021-01-01 15:36:20.783048: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic\r\nlibrary cublas64_11.dll\r\n2021-01-01 15:36:20.785961: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic\r\nlibrary cublasLt64_11.dll\r\n2021-01-01 15:36:20.788581: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic\r\nlibrary cufft64_10.dll\r\n2021-01-01 15:36:20.790940: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic\r\nlibrary curand64_10.dll\r\n2021-01-01 15:36:20.793317: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic\r\nlibrary cusolver64_10.dll\r\n2021-01-01 15:36:20.795926: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic\r\nlibrary cusparse64_11.dll\r\n2021-01-01 15:36:20.798359: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic\r\nlibrary cudnn64_8.dll\r\n2021-01-01 15:36:20.801092: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\r\n2021-01-01 15:36:20.802806: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor\r\nwith strength 1 edge matrix:\r\n2021-01-01 15:36:20.811645: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0\r\n2021-01-01 15:36:20.814407: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N\r\n2021-01-01 15:36:20.816910: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:loc\r\nalhost/replica:0/task:0/device:GPU:0 with 2982 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus\r\n id: 0000:01:00.0, compute capability: 6.1)\r\n2021-01-01 15:36:20.821653: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_\r\ndevices not set\r\nWARNING:tensorflow:AutoGraph could not transform <function SSDModule._get_postprocess_fn.<locals>.dummy_post_processing\r\nat 0x000002377C7D3EE8> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:36:20.924464 10772 ag_logging.py:146] AutoGraph could not transform <function SSDModule._get_postprocess_fn.<lo\r\ncals>.dummy_post_processing at 0x000002377C7D3EE8> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000\r\n2377E245E58> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:36:21.259392 10772 ag_logging.py:146] AutoGraph could not transform <function canonicalize_signatures.<locals>.\r\nsignature_wrapper at 0x000002377E245E58> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMeta\r\nArch object at 0x00000236A956D4C8>, because it is not built.\r\nW0101 15:36:21.489312 10772 save_impl.py:78] Skipping full serialization of Keras layer <object_detection.meta_architect\r\nures.ssd_meta_arch.SSDMetaArch object at 0x00000236A956D4C8>, because it is not built.\r\n2021-01-01 15:36:33.415476: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this\r\nmay change in the future, so consider avoiding using them.\r\n2021-01-01 15:36:56.497517: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:\r\npciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1\r\ncoreClock: 1.62GHz coreCount: 6 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 104.43GiB/s\r\n2021-01-01 15:36:56.502998: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic\r\nlibrary cudart64_110.dll\r\n2021-01-01 15:36:56.506094: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic\r\nlibrary cublas64_11.dll\r\n2021-01-01 15:36:56.508562: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic\r\nlibrary cublasLt64_11.dll\r\n2021-01-01 15:36:56.511047: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic\r\nlibrary cufft64_10.dll\r\n2021-01-01 15:36:56.514148: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic\r\nlibrary curand64_10.dll\r\n2021-01-01 15:36:56.522609: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic\r\nlibrary cusolver64_10.dll\r\n2021-01-01 15:36:56.525053: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic\r\nlibrary cusparse64_11.dll\r\n2021-01-01 15:36:56.527458: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic\r\nlibrary cudnn64_8.dll\r\n2021-01-01 15:36:56.530278: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\r\n2021-01-01 15:36:56.533155: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor\r\nwith strength 1 edge matrix:\r\n2021-01-01 15:36:56.541155: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0\r\n2021-01-01 15:36:56.543258: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N\r\n2021-01-01 15:36:56.544827: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:loc\r\nalhost/replica:0/task:0/device:GPU:0 with 2982 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus\r\n id: 0000:01:00.0, compute capability: 6.1)\r\n2021-01-01 15:36:56.550138: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_\r\ndevices not set\r\nWARNING:tensorflow:AutoGraph could not transform <function SSDModule._get_postprocess_fn.<locals>.dummy_post_processing\r\nat 0x0000023794F6BAF8> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:36:56.624512 10772 ag_logging.py:146] AutoGraph could not transform <function SSDModule._get_postprocess_fn.<lo\r\ncals>.dummy_post_processing at 0x0000023794F6BAF8> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x00000236B8372708> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:08.904431 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x00000236B8372708> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x00000236A2F54DC8> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:08.924087 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x00000236A2F54DC8> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x00000236B8372D38> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:08.934363 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x00000236B8372D38> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x00000236B83728B8> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:08.950443 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x00000236B83728B8> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x00000236BDC27048> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:08.964281 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x00000236BDC27048> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x00000236BDC27948> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:08.974267 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x00000236BDC27948> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x00000236BDC27C18> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:08.989209 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x00000236BDC27C18> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x00000236BDC891F8> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:09.003207 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x00000236BDC891F8> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x00000236BDC27798> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:09.014103 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x00000236BDC27798> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x00000236BDC27168> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:09.024310 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x00000236BDC27168> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x00000236B8372C18> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:09.039472 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x00000236B8372C18> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x00000236A2D0B4C8> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:09.054223 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x00000236A2D0B4C8> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x00000236A2D04F78> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:09.064049 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x00000236A2D04F78> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x00000236BDC89A68> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:09.080380 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x00000236BDC89A68> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x00000236BDC89438> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:09.094172 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x00000236BDC89438> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x00000236C0D98318> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:09.104253 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x00000236C0D98318> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x00000236BDC89F78> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:09.119428 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x00000236BDC89F78> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x00000236BDC89708> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:09.129079 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x00000236BDC89708> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x00000236BDC27EE8> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:09.139221 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x00000236BDC27EE8> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x00000236BDC273A8> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:09.154466 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x00000236BDC273A8> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x00000236C0D984C8> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:09.164408 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x00000236C0D984C8> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x00000236C0D988B8> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:09.178624 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x00000236C0D988B8> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x00000236C0D98D38> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:09.193627 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x00000236C0D98D38> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x00000236C277D0D8> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:09.206599 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x00000236C277D0D8> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x00000236C0D98948> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:09.218703 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x00000236C0D98948> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x00000236C0D98B88> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:09.229380 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x00000236C0D98B88> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x00000236B83729D8> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:09.249172 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x00000236B83729D8> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x00000236BDC89948> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:09.259261 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x00000236BDC89948> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x00000236C277D4C8> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:09.274536 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x00000236C277D4C8> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x00000236C277D168> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:09.284113 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x00000236C277D168> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x00000236C277D5E8> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:09.299229 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x00000236C277D5E8> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x00000236BDC89048> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:09.313076 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x00000236BDC89048> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x00000236C277D948> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:09.329065 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x00000236C277D948> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x00000236C277DB88> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:09.342951 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x00000236C277DB88> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x00000236BDC278B8> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:09.354170 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x00000236BDC278B8> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x00000236BDC274C8> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:09.364410 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x00000236BDC274C8> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x00000236C4C393A8> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:09.374466 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x00000236C4C393A8> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x00000236C4C39168> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:09.384218 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x00000236C4C39168> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x00000236C4C39C18> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:09.394142 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x00000236C4C39C18> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x00000236C0D98558> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:09.414140 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x00000236C0D98558> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x00000236C4C398B8> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:09.424285 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x00000236C4C398B8> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x00000236C4C39438> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:09.444151 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x00000236C4C39438> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x00000236C0D981F8> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:09.454444 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x00000236C0D981F8> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x00000236C277DF78> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:09.464429 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x00000236C277DF78> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x00000236C4C39678> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:09.480985 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x00000236C4C39678> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x00000236C7649678> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:09.494034 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x00000236C7649678> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x00000236C277DE58> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:09.504319 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x00000236C277DE58> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x00000236C7649EE8> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:09.514178 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x00000236C7649EE8> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x00000236C7649B88> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:09.524438 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x00000236C7649B88> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x00000236C7649DC8> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:09.544341 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x00000236C7649DC8> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x00000236BDC89E58> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:09.554081 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x00000236BDC89E58> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x00000236C0D985E8> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:09.564515 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x00000236C0D985E8> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x00000236C7C83E58> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:09.604518 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x00000236C7C83E58> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x00000236C7CA7288> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:09.614604 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x00000236C7CA7288> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x00000236C7CA7798> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:09.624274 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x00000236C7CA7798> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x00000236C7CCD048> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:09.644068 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x00000236C7CCD048> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x00000236C7CCD3A8> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:09.654093 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x00000236C7CCD3A8> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x00000236C7CCDA68> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:09.664325 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x00000236C7CCDA68> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x00000236C7CFE168> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:09.681007 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x00000236C7CFE168> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x00000236C7CFE9D8> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:09.684165 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x00000236C7CFE9D8> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x00000236C7D27E58> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:10.666164 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x00000236C7D27E58> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x00000236C7D27B88> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:10.689193 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x00000236C7D27B88> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x000002377A9EF948> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:10.704203 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x000002377A9EF948> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x000002377A9EFDC8> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:10.714448 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x000002377A9EFDC8> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x000002377AA1B708> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:10.734195 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x000002377AA1B708> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x000002377AA1BDC8> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:10.757413 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x000002377AA1BDC8> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x00000236C7D27AF8> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:10.779386 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x00000236C7D27AF8> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x000002377A9EF4C8> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:10.795366 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x000002377A9EF4C8> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x000002377A9EFB88> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:10.809165 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x000002377A9EFB88> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x000002377AA1B288> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:10.827819 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x000002377AA1B288> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x000002377AA1B948> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:10.844805 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x000002377AA1B948> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variab\r\nle at 0x000002377AA1BEE8> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:10.860762 10772 ag_logging.py:146] AutoGraph could not transform <function Layer._handle_weight_regularizati\r\non.<locals>._loss_for_variable at 0x000002377AA1BEE8> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VER\r\nBOSITY=10`) and attach the full output.\r\nCause: 'arguments' object has no attribute 'posonlyargs'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nW0101 15:37:12.150229 10772 save.py:241] Found untraced functions such as BoxPredictor_layer_call_and_return_conditional\r\n_losses, BoxPredictor_layer_call_fn, BoxPredictor_layer_call_fn, BoxPredictor_layer_call_and_return_conditional_losses,\r\nBoxPredictor_layer_call_and_return_conditional_losses while saving (showing 5 of 125). These functions will not be direc\r\ntly callable after loading.\r\nW0101 15:37:13.090939 10772 save.py:241] Found untraced functions such as BoxPredictor_layer_call_and_return_conditional\r\n_losses, BoxPredictor_layer_call_fn, BoxPredictor_layer_call_fn, BoxPredictor_layer_call_and_return_conditional_losses,\r\nBoxPredictor_layer_call_and_return_conditional_losses while saving (showing 5 of 125). These functions will not be direc\r\ntly callable after loading.\r\nINFO:tensorflow:Assets written to: object_detection/ssd_mobilenet_v2_320x320_coco17_tpu-8/tflite_inference_graph\\saved_m\r\nodel\\assets\r\nI0101 15:37:27.996973 10772 builder_impl.py:775] Assets written to: object_detection/ssd_mobilenet_v2_320x320_coco17_tpu\r\n-8/tflite_inference_graph\\saved_model\\assets\r\n\r\n```\r\n\r\n**Also, please include a link to the saved model or GraphDef**\r\n\r\n```\r\n# Put link here or attach to the issue.\r\n```\r\n\r\n### Step 2 : Convert to TFLite (via Spyder)\r\n\r\nin D:\\Documents\\AI\\Github Trials\\models-master\\research\\object_detection\\ssd_mobilenet_v2_320x320_coco17_tpu-8\\step2_convert_to_tflite.py\r\n```\r\nimport tensorflow as tf\r\n\r\nsaved_model_dir = 'D:\\Documents\\AI\\Github Trials\\models-master\\research\\object_detection\\ssd_mobilenet_v2_320x320_coco17_tpu-8\\tflite_inference_graph\\saved_model'\r\n\r\nconverter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\r\ntflite_model = converter.convert()\r\n\r\nwith open('model.tflite', 'wb') as f:\r\n  f.write(tflite_model)\r\n```\r\n**Failure details**\r\n\r\nStep 2 above could not find {saved_model.pbtxt|saved_model.pb} in the folder.\r\nBelow is the full Traceback:\r\n```\r\nTraceback (most recent call last):\r\n\r\n  File \"D:\\Documents\\AI\\Github Trials\\models-master\\research\\object_detection\\ssd_mobilenet_v2_320x320_coco17_tpu-8\\step2_convert_to_tflite.py\", line 6, in <module>\r\n    converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\r\n\r\n  File \"D:\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py\", line 1069, in from_saved_model\r\n    saved_model = _load(saved_model_dir, tags)\r\n\r\n  File \"D:\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py\", line 859, in load\r\n    return load_internal(export_dir, tags, options)[\"root\"]\r\n\r\n  File \"D:\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py\", line 871, in load_internal\r\n    loader_impl.parse_saved_model_with_debug_info(export_dir))\r\n\r\n  File \"D:\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py\", line 56, in parse_saved_model_with_debug_info\r\n    saved_model = _parse_saved_model(export_dir)\r\n\r\n  File \"D:\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py\", line 114, in parse_saved_model\r\n    constants.SAVED_MODEL_FILENAME_PB))\r\n\r\nesearch\\object_detection\\ssd_mobilenet_v2_320x320_coco17_tpu-8\tflite_inference_graph\\saved_model/{saved_model.pbtxt|saved_model.pb}\r\n```\r\n\r\nAny help is **greatly** appreciated!", "comments": ["@stephentandjiria could you make sure that the saved model directory, which is object_detection/ssd_mobilenet_v2_320x320_coco17_tpu-8/tflite_inference_graph, has the valid saved model files, such as saved_model.pb?\r\n\r\nCould you share the result of the 'dir' command towards the above saved model directory?", "> @stephentandjiria could you make sure that the saved model directory, which is object_detection/ssd_mobilenet_v2_320x320_coco17_tpu-8/tflite_inference_graph, has the valid saved model files, such as saved_model.pb?\r\n> \r\n> Could you share the result of the 'dir' command towards the above saved model directory?\r\n\r\nHi @abattery sure, here it is:\r\n\r\n![image](https://user-images.githubusercontent.com/75295743/103594541-8c3e1900-4f2b-11eb-9876-fd61424290a3.png)\r\n\r\nIt indeed has saved_model.pb under saved_model folder, strange right?", "@stephentandjiria strange, could you put your saved model directory under the same directory, which is used for the Python script and use the relative path instead? It looks like that this problem is more like an permission or file access problem.", "> @stephentandjiria strange, could you put your saved model directory under the same directory, which is used for the Python script and use the relative path instead? It looks like that this problem is more like an permission or file access problem.\r\n\r\n@abattery It works thanks to your suggestion! I was able to create a .tflite file but the inputs and outputs are different from standard .tflite. However, the shapes and structures are kind of similar.\r\n\r\nHere is what I mean:\r\n![image](https://user-images.githubusercontent.com/75295743/103623423-b82cbf00-4f6a-11eb-8eb4-7183a5b07cb4.png)\r\n\r\n![image](https://user-images.githubusercontent.com/75295743/103623226-64ba7100-4f6a-11eb-94ba-2618484223b2.png)", "In the nightly version, you can use the consistent names through the saved model's signature definitions. @karimnosseir could you help us here regarding the name issue?", "> In the nightly version, you can use the consistent names through the saved model's signature definitions. @karimnosseir could you help us here regarding the name issue?\r\n\r\nAlright, let me try it besides attempting quantization for Flutter.\r\nThanks a lot for your help @abattery !", "@stephentandjiria Assuming your saved model has a SignatureDef defined.\r\nThen use the nightly for converting to tflite. The generated tflite file will have the SignatureDef details.\r\nUsing Python API (as an example) you can do something like\r\n\r\nmy_signature = interpreter.get_signature_runner(\"my_method\")\r\nresults = my_signature(input_1=input_tensor_1, input_2=input_tensor_2)\r\nprint(results[\"my_output\"])\r\n", "Hi @karimnosseir , thanks for your suggestion.\r\n\r\nApologies if this question seems silly since I am new, but do the signatures (normalized_input_image_tensor, TFLite_Detection_PostProcess, TFLite_Detection_PostProcess:1, TFLite_Detection_PostProcess:2, TFLite_Detection_PostProcess:3) function only as a \"name\" or is there an inherently different use in having such signatures?\r\n\r\nIf it is relevant, the purpose is to use it for [tflite_flutter](https://pub.dev/packages/tflite_flutter), which [implementation examples](https://github.com/am15h/tflite_flutter_plugin/issues/29) always include .tflite with normalized_input_image_tensor and TFLite_Detection_PostProcess.", "SignatureDef provides meaningful/generic names for inputs/outputs which doesn't rely on specific model details. More on SignatureDefs [here](https://www.tensorflow.org/tfx/serving/signature_defs).\r\nIf your saved model has a defined signatureDef then it will be exported during conversion to TFLite and then you can use the Signature inputs/outputs for inference and not relying on inputs/outputs order or tensor names.\r\n\r\nI am not familiar with tflite_flutter, but SignatureDef support is new thing available in nightly and will be available in 2.5", "> SignatureDef provides meaningful/generic names for inputs/outputs which doesn't rely on specific model details. More on SignatureDefs [here](https://www.tensorflow.org/tfx/serving/signature_defs).\r\n> If your saved model has a defined signatureDef then it will be exported during conversion to TFLite and then you can use the Signature inputs/outputs for inference and not relying on inputs/outputs order or tensor names.\r\n> \r\n> I am not familiar with tflite_flutter, but SignatureDef support is new thing available in nightly and will be available in 2.5\r\n\r\nAlright got it, thanks for the help @karimnosseir @abattery , I really appreciate it!", "Closing since using SignatureDef resolves the issue.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46100\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46100\">No</a>\n"]}, {"number": 46099, "title": "Expose class_id parameter on subclasses of SensitivitySpecificityBase", "body": "This PR addresses https://github.com/tensorflow/tensorflow/issues/46017 by simply exposing the `class_id` parameter on all subclasses of `SensitivitySpecificityBase`.\r\n\r\nI've added tests to confirm this works on 3-way multi-label data and also added a guard for a test from `tensorflow/python/keras:metrics_confusion_matrix_test` that wasn't working locally due to requiring scipy (seems this pattern is used elsewhere in the codebase for running tests locally).", "comments": []}]