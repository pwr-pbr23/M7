[{"number": 17272, "title": "Using tf.estimator.Estimator with save_checkpoint_steps leads to Tensorboard warnings", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux 4.4.0-104-generic\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: v1.4.0-rc1-11-g130a514 1.4.0\r\n- **Python version**: 3.6.4\r\n- **CUDA/cuDNN version**: 8.0.61\r\n- **GPU model and memory**: GeForce GTX TITAN X\r\n\r\n### Describe the problem\r\nWhen using `tf.estimator.train_and_evaluate(...)` with an `tf.estimator.Estimator` configurated with `tf.contrib.learn.RunConfig(save_checkpoints_steps=10, ...)`, a `CheckpointSaverHook` will be created automatically. This `CheckpointSaverHook` will save the graph and graph_def to the summary writer every time it is triggered (see [CheckpointSaverHook.before_run](https://github.com/tensorflow/tensorflow/blob/36b83257287148ddb4aab02c641d1ac9e192a136/tensorflow/python/training/basic_session_run_hooks.py#L440)). \r\n\r\n### Basic code example:\r\n\r\n<!-- language: lang-py -->\r\n\r\n    estimator = tf.estimator.Estimator(\r\n        model_fn, model_dir, params,\r\n        config=tf.estimator.RunConfig(\r\n            save_checkpoints_steps=100, \r\n            save_summary_steps=100\r\n        )\r\n    )\r\n    train_spec = tf.estimator.TrainSpec(train_fn)\r\n    eval_spec = tf.estimator.TrainSpec(eval_fn)\r\n    tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\r\n\r\nWhen starting Tensorboard on the written summary, it will output a hundreds of warnings because of multiple graph defs in the summary which I guess slows it down a lot on startup:\r\n\r\n<!-- language: lang-none -->\r\n\r\n    W0117 18:47:30.278879 Reloader tf_logging.py:86] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\r\n    W0117 18:47:30.279753 Reloader tf_logging.py:86] Found more than one metagraph event per run. Overwriting the metagraph with the newest event.\r\n\r\nI see there might be issues when using multiple graphs, but for a single graph this seems unpracticable.\r\n\r\nRelated stack overflow discussion: https://stackoverflow.com/questions/48316888", "comments": ["I don't think there's enough information here to identify a TF bug. Consider asking another question on Stack Overflow with the `tensorboard` tag.", "I am having the same issue, is it possible some workaround or to understand what this is due to?\r\ntf version == 1.11.0\r\n\r\nI tried to use all three possible MonitoredSessions (that I know of..) and the result is always the same, that is why I think it is a problem of the CheckpointSaverHook\r\nIt seems like more processes are writing on the event for saving the graph maybe.\r\nI am not sure how many processes are launched under the hood, but only the chief should write the tf.summaries I think, isn't this the default behaviour or what is the suspected issue here?\r\n\r\nFor all the 3 following cases the model is saved, and together with is the graph in a tb event I guess...\r\nwhen I read the respective folder with tensorboard I obtain:\r\n```\r\nW1011 18:27:17.685001 Reloader tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\r\nW1011 18:27:17.685001 140617855026944 tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\r\nW1011 18:27:17.920676 Reloader tf_logging.py:120] Found more than one metagraph event per run. Overwriting the metagraph with the newest event.\r\nW1011 18:27:17.920676 140617855026944 tf_logging.py:120] Found more than one metagraph event per run. Overwriting the metagraph with the newest event.\r\n```\r\n\r\nA simple code presenting the issue:\r\n```\r\nhooks = [\r\n    tf.train.StopAtStepHook(last_step=300)\r\n]\r\n\r\nsessioncode = args.session\r\nSAVE_STEPS = 50\r\n\r\nif sessioncode == 'mts':\r\n    print(\"I am using a MonitoredTrainingSession!!\")\r\n    basedir = \"tempMonitoredTrainingSession\"\r\n    checkpoint_dir = basedir\r\n \r\n    sess = tf.train.MonitoredTrainingSession(checkpoint_dir=checkpoint_dir,\r\n                                            save_checkpoint_steps = SAVE_STEPS,\r\n                                            hooks=hooks,\r\n                                            config=sess_config)\r\n\r\nelif sessioncode == 'ms':\r\n    print(\"I am using a MonitoredSession!!\")\r\n    basedir = \"tempMonitoredSession\"\r\n    checkpoint_dir = basedir\r\n    hooks.append(tf.train.CheckpointSaverHook(checkpoint_dir, save_steps = SAVE_STEPS))\r\n    \r\n    chiefsess_creator = tf.train.ChiefSessionCreator(config=sess_config, checkpoint_dir=checkpoint_dir)\r\n    sess = tf.train.MonitoredSession(session_creator=chiefsess_creator, hooks=hooks)\r\n\r\nelif sessioncode == 'sms':\r\n    print(\"I am using a SingularMonitoredSession!!\")\r\n    basedir = \"tempSingularMonitoredSession\"\r\n    checkpoint_dir = basedir\r\n    hooks.append(tf.train.CheckpointSaverHook(checkpoint_dir, save_steps = SAVE_STEPS))\r\n    \r\n    sess = tf.train.SingularMonitoredSession(checkpoint_dir=checkpoint_dir,\r\n                                            hooks=hooks,\r\n                                            config=sess_config)\r\n\r\nelse:\r\n    raise ValueError(\"the session code passed is not contemplated!\")\r\n\r\n\r\nwith sess:\r\n    while not sess.should_stop():\r\n        _, g_step = sess.run([training_op, global_step])\r\n        print(\"global step: \", g_step)\r\n\r\n```", "I have the same issue when using tf.estimator, running the simplest iris code."]}, {"number": 17271, "title": "Fix some breakages in TensorFlow Windows build", "body": "Working towards https://github.com/tensorflow/tensorflow/issues/17268", "comments": ["@gunan ", "Could you look into the test failures?", "Looks like the problem is resolved."]}, {"number": 17270, "title": "same code, tensorflow/contribe/android works, but tensorflow/contribe/lite/java/src/main/native doesn't, with error: No implementation found", "body": "tensorflow r1.4\r\nubuntu 14.04\r\narmv7 platform\r\nfor short, the same code witch can be used in tensorflow/cotribe/android/jni, when move to tensorflow/contribe/lite/java/src/main/native, the java code cannot find the implementation.\r\nuse the command line:\r\nbazel build -c opt --cxxopt='-std=c++11' //tensorflow/contrib/android:libtensorflow_inference.so    --crosstool_top=//external:android/crosstool    --host_crosstool_top=@bazel_tools//tools/cpp:toolchain    --cpu=armeabi-v7a\r\nto build an android so file, it is ok.\r\nand i modify the BUILD file to add my own code:\r\ncc_library(\r\n    name = \"native_framework_only\",\r\n    srcs = [\r\n        #\"run_stats_jni.cc\",\r\n        #\"exception_jni.cc\",\r\n        #\"nativeinterpreterwrapper_jni.cc\",\r\n        #\"tensor_jni.cc\",\r\n        #\"tensorflow_lite_jni.cc\",\r\n        #\"run_stats_lite_jni.cc\",\r\n    ] + select({\r\n        # The Android toolchain makes \"jni.h\" available in the include path.\r\n        # For non-Android toolchains, generate jni.h and jni_md.h.\r\n        \"//tensorflow:android\": [],\r\n        \"//conditions:default\": [\r\n            \":jni.h\",\r\n            \":jni_md.h\",\r\n        ],\r\n    }),\r\n    hdrs = [\r\n        \"run_stats_jni.h\",\r\n        #\"exception_jni.h\",\r\n        #\"nativeinterpreterwrapper_jni.h\",\r\n        #\"tensor_jni.h\",\r\n        #\"tensorflow_lite_jni.h\",\r\n        #\"run_stats_lite_jni.h\",\r\n        #\"testlite.h\",\r\n    ],\r\n    copts = tflite_copts(),\r\n    includes = select({\r\n        \"//tensorflow:android\": [],\r\n        \"//conditions:default\": [\".\"],\r\n    }),\r\n    linkopts = [\r\n        \"-lm\",\r\n        \"-ldl\",\r\n        \"-llog\",\r\n    ],\r\n    tags = [\r\n        \"manual\",\r\n    ],\r\n    deps = [\r\n        \"//tensorflow/contrib/lite:context\",\r\n        \"//tensorflow/contrib/lite:framework\",\r\n        \"//tensorflow/contrib/lite:schema_fbs_version\",\r\n        \"//tensorflow/contrib/lite/kernels:builtin_ops\",\r\n        \"@dlib_arm_v7//:dlib\",\r\n        \"@seeta_arm_v7//:seeta\",\r\n        \"@opencv_jni//:opencv_jni\",\r\n    ],\r\n    alwayslink = 1,\r\n)\r\nthe file run_stats_jni.h is just from tensorflow/contribe/android/jni, the function i want to call from native is:\r\nJNIEXPORT jint RUN_STATS_METHOD(jniSetInterval)(JNIEnv* env, jclass clazz, jint interval)\r\n{\r\n    int val = (int)interval;\r\n    return JNI_OK;\r\n}\r\nand using the command line:\r\nbazel build -c opt --cxxopt='-std=c++11' //tensorflow/contrib/lite/java:libtensorflowlite_jni.so    --crosstool_top=//external:android/crosstool    --host_crosstool_top=@bazel_tools//tools/cpp:toolchain    --cpu=armeabi-v7a\r\nand when i using nm -D command to check the libtensorflowlite_jni.so and libtensorflow_inference.so, they all have the same name Java_org_tensorflow_jniSetInterval. but libtensorflow_inference.so works, but libtensorflowlite_jni.so does not.\r\nthe error is: \r\nNo implementation found for int org_tensorflow.jniSetInterval(int) (tried Java_org_tensorflow_jniSetInterval and Java_org_tensorflow_jniSetInterval__I)\r\n\r\nlack of document to tell us how to add own code to tensorflow lite, and it is wierd, may be a bug.", "comments": ["I apologize but I am having a hard time understanding what the problem is, where the problem is, and what version it affects. Please resubmit and pay attention to the issue template (https://github.com/tensorflow/tensorflow/issues/new) . Please provide all the information it asks. Thank you."]}, {"number": 17269, "title": "Can't load model file", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nYes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n   env from [google colab](https://colab.research.google.com/)\r\n- **TensorFlow installed from (source or binary)**:\r\n  env from [google colab](https://colab.research.google.com/)\r\n- **TensorFlow version (use command below)**:\r\n``` 1.6.0-rc1  ```\r\n- **Python version**: \r\n```python 3.6```\r\n\r\n### Describe the problem\r\nI have code like this:\r\n\r\n```\r\nslim.assign_from_checkpoint_fn(\r\n        pretrained_model_file,\r\n        variables_to_restore,\r\n        ignore_missing_vars=True)\r\n```\r\n\r\nwhen  `pretrained_model_file = \"vgg_19.ckpt\"`, where vgg_19.ckpt is a checkpoint file from pre-trained model, it raise Exception:\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-29-b803c1b9c409> in <module>()\r\n     10 \r\n     11 \r\n---> 12 demo()\r\n\r\n<ipython-input-29-b803c1b9c409> in demo()\r\n      7             \"1000\", \"--network\", \"/content/vgg_19.ckpt\",\r\n      8             \"--checkpoint-iterations\", \"10\", \"--checkpoint-output\", \"/content/tmp-tv-%s.jpg\"]\r\n----> 9     neural_style_main(args)\r\n     10 \r\n     11 \r\n\r\n/usr/local/lib/python3.6/dist-packages/neural_style_demo/neural_style.py in main(args)\r\n    178         pooling=options.pooling,\r\n    179         print_iterations=options.print_iterations,\r\n--> 180         checkpoint_iterations=options.checkpoint_iterations\r\n    181     ):\r\n    182         output_file = None\r\n\r\n/usr/local/lib/python3.6/dist-packages/neural_style_demo/stylize.py in stylize(network, initial, initial_noiseblend, content, styles, preserve_colors, iterations, content_weight, content_weight_blend, style_weight, style_layer_weight_exp, style_blend_weights, tv_weight, learning_rate, beta1, beta2, epsilon, pooling, print_iterations, checkpoint_iterations)\r\n     77                                                     naming=\"style-{}\".format(i),\r\n     78                                                     pretrained_model_file=pretrained_model_file,\r\n---> 79                                                     checkpoint_exclude_scopes=checkpoint_exclude_scopes)\r\n     80 \r\n     81         for index, layer in enumerate(STYLE_LAYERS):\r\n\r\n/usr/local/lib/python3.6/dist-packages/neural_style_demo/losses.py in get_style_features(model_name, style_image, image_size, style_layers, naming, pretrained_model_file, checkpoint_exclude_scopes)\r\n     97                 break\r\n     98         if not excluded:\r\n---> 99             variables_to_restore.append(var)\r\n    100 \r\n    101     return assign_from_checkpoint_fn(\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/framework/python/ops/variables.py in callback(session)\r\n    688     saver = tf_saver.Saver(var_list, reshape=reshape_variables)\r\n    689     def callback(session):\r\n--> 690       saver.restore(session, model_path)\r\n    691     return callback\r\n    692   else:\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py in restore(self, sess, save_path)\r\n   1754       raise ValueError(\"The specified path: %s is a file.\"\r\n   1755                        \" Please specify only the path prefix\"\r\n-> 1756                        \" to the checkpoint files.\" % save_path)\r\n   1757     logging.info(\"Restoring parameters from %s\", save_path)\r\n   1758     if context.in_graph_mode():\r\n\r\nValueError: The specified path: /content/vgg_19.ckpt is a file. Please specify only the path prefix to the checkpoint files.\r\n```\r\n\r\nIf I change pretained_model_file to the folder contains checkpoint file, it raise ` Exception: No checkpoint found... `.\r\n\r\nIf I force to change tensorflow from 1.6 to 1.4, and  `pretrained_model_file = \"vgg_19.ckpt\"`, this code can work!\r\n\r\n\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "I am having the same problem. \r\n\r\nThe issue was introduced in:\r\nhttps://github.com/tensorflow/tensorflow/commit/d90054e7c0f41f4bab81df0548577a73b939a87a#diff-ebe39eb12501b7ce2eb92ffd71b9acac\r\n\r\nand reversed in:\r\nhttps://github.com/tensorflow/tensorflow/commit/dce9a49c19f406ba45919e8c94474e55dc5ccd54#diff-ebe39eb12501b7ce2eb92ffd71b9acac\r\n\r\nI'm using `colaboratory`: Is there any way to reload tensorflow after updating?\r\n\r\n```\r\nprint('tensorflow v={}'.format(tf.__version__))\r\n!pip install tensorflow==1.6.0  --upgrade\r\n!pip show tensorflow # shows v1.6.0\r\nimport importlib\r\nimportlib.reload(tf) # raises NameError: name 'python' is not defined\r\nprint('tensorflow v={}'.format(tf.__version__)) # shows v.1.6.0-rc1\r\n```\r\n\r\n** updated** I just manually `kill -9` every python process and `colaboratory` just restarted", "now I'm updated to `v1.6.0` and I get the same error at a different spot\r\n\r\n```\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/framework/python/ops/variables.py in callback(session)\r\n    688     saver = tf_saver.Saver(var_list, reshape=reshape_variables)\r\n    689     def callback(session):\r\n--> 690       saver.restore(session, model_path)\r\n    691     return callback\r\n    692   else:\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py in restore(self, sess, save_path)\r\n   1754       sess.run(self.saver_def.restore_op_name,\r\n   1755                {self.saver_def.filename_tensor_name: save_path})\r\n-> 1756     else:\r\n   1757       self._build_eager(save_path, build_save=False, build_restore=True)\r\n   1758 \r\n\r\nValueError: The specified path: /content/nima/ckpt/inception_resnet_v2_2016_08_30.ckpt is a file. Please specify only the path prefix to the checkpoint files.\r\n```\r\n\r\nthen I downgraded to `v1.4.1` and everything is fine.", "Bug was fixed now!\r\n\r\nNote:\r\n\r\n- this is a bug from tensorflow, coder add bug to resp [#14341](https://github.com/tensorflow/tensorflow/pull/14341)\r\n- bug was fixed by coder, but [colab](https://colab.research.google.com) not update their tensorflow\r\n- I fixed bug in colab by [this method](https://frkhit.github.io/2018/02/28/fix_tf_bug_in_colaboratory/)."]}, {"number": 17268, "title": "CI: TensorFlow build is failing on Windows", "body": "Before merging #16659, we should fix the TF build on Windows first.\r\n\r\nCurrent failure:\r\n```\r\nsubprocess.CalledProcessError: Command '['bazel', '--batch', 'version']' returned non-zero exit status 36\r\n```\r\nCulprit is https://github.com/tensorflow/tensorflow/commit/671baf080238025da9698ea980cd9504005f727c\r\nbecause `f.write('import %s\\n' % _TF_BAZELRC)` writes backslash into bazelrc file without escaping.\r\nI'll send a fix.\r\nFYI, @gunan @martinwicke @case540 \r\n", "comments": ["By the way, is this related to https://github.com/tensorflow/tensorflow/issues/16138 ? Or are you referring to a build with VS 2015?", "Sorry for the confusion, I meant the build on TF CI.\r\nSee http://ci.tensorflow.org/job/tf-master-win-bzl/2577/"]}, {"number": 17267, "title": "CMP0002 error when building TensorFlow cc unit tests", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Window 10\r\n- **TensorFlow installed from (source or binary)**:source\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:VS2015 x64\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nWhen I tried to do TensorFlow CMake build on Window 10 like [this](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/cmake),there is no error.\r\n\r\nThen I tried to build cc unit tests. I added -Dtensorflow_BUILD_CC_TESTS=ON to the command\r\n\r\n`cmake .. -A x64 -DCMAKE_BUILD_TYPE=Release -DSWIG_EXECUTABLE=C:\\swigwin-3.0.12\\swigwin-3.0.12\\swig.exe -DPYTHON_EXECUTABLE=D:\\Local\\anaconda3\\python.exe -DPYTHON_LIBRARIES=D:\\Local\\anaconda3\\libs\\python36.lib -Dtensorflow_BUILD_SHARED_LIB=ON -Dtensorflow_BUILD_CC_TESTS=ON`\r\n\r\nThe cmake infomation is as following:\r\n\r\n```\r\n-- Building for: Visual Studio 14 2015\r\n-- Selecting Windows SDK version 10.0.14393.0 to target Windows 10.0.16299.\r\n-- The C compiler identification is MSVC 19.0.24215.1\r\n-- The CXX compiler identification is MSVC 19.0.24215.1\r\n-- Check for working C compiler: C:/Program Files (x86)/Microsoft Visual Studio 14.0/VC/bin/x86_amd64/cl.exe\r\n-- Check for working C compiler: C:/Program Files (x86)/Microsoft Visual Studio 14.0/VC/bin/x86_amd64/cl.exe -- works\r\n-- Detecting C compiler ABI info\r\n-- Detecting C compiler ABI info - done\r\n-- Check for working CXX compiler: C:/Program Files (x86)/Microsoft Visual Studio 14.0/VC/bin/x86_amd64/cl.exe\r\n-- Check for working CXX compiler: C:/Program Files (x86)/Microsoft Visual Studio 14.0/VC/bin/x86_amd64/cl.exe -- works\r\n-- Detecting CXX compiler ABI info\r\n-- Detecting CXX compiler ABI info - done\r\n-- Detecting CXX compile features\r\n-- Detecting CXX compile features - done\r\n-- Performing Test COMPILER_OPT_ARCH_NATIVE_SUPPORTED\r\n-- Performing Test COMPILER_OPT_ARCH_NATIVE_SUPPORTED - Failed\r\n-- Found PythonInterp: D:/Local/anaconda3/python.exe (found version \"3.6.3\")\r\n-- Found PythonLibs: D:/Local/anaconda3/libs/python36.lib (found version \"3.6.3\")\r\n-- Found SWIG: C:/swigwin-3.0.12/swigwin-3.0.12/swig.exe (found version \"3.0.12\")\r\n\r\n```\r\nbut I got several errors like the following\r\n\r\n```\r\nCMake Error at tf_tests.cmake:73 (add_executable):\r\n  add_executable cannot create target\r\n  \"tensorflow_core_profiler_internal_tfprof_show_test\" because another target\r\n  with the same name already exists.  The existing target is an executable\r\n  created in source directory \"D:/yinb_6/1.4/tensorflow/contrib/cmake\".  See\r\n  documentation for policy CMP0002 for more details.\r\nCall Stack (most recent call first):\r\n  tf_tests.cmake:46 (AddTest)\r\n  tf_tests.cmake:529 (AddTests)\r\n  CMakeLists.txt:325 (include)\r\n```\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["@mrry, can you take a look?", "Unfortunately the CMake cc_tests are an unsupported community contribution, which we don't run regularly, and so they're subject to bitrot.\r\n\r\nMarking this as Contributions Welcome.", "So, is there any other methods to build cc unit tests in Window?", "The Bazel build for Windows supports building many of the C++ tests. It's getting more complete every week, and we intend for it to replace the CMake build as soon as possible.\r\n\r\n/cc @meteorcloudy ", "Thank you, I will try the Bazel later.", "@baozi-lala Could you please let us know if this is still an issue and  can we close this issue with the PR #17610 ? Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/17267\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/17267\">No</a>\n"]}, {"number": 17265, "title": "[WIP] Clean shell scripts", "body": "Hi,\r\n\r\nI started to fix various things spotted by ShellCheck.\r\n\r\nI used the following command: `find -O3 . -type f -name '*.sh' -exec shellcheck -x {} \\;`.\r\n\r\nThere are quite a lot of things remaining:\r\n\r\n```sh\r\nfind -O3 . -type f -name '*.sh' -exec shellcheck -x {} \\; | wc -l\r\n3731\r\n```\r\n\r\nI'll fix all of them in a few days. But to ease the process of reviewing, I open the PR now, and will add a new commit each time. At the end, I'll merge all of them in a single commit.", "comments": ["@aselle, @protoget, in some cases where shellcheck raises false positives, I can silence them by [adding a comment](https://github.com/koalaman/shellcheck/wiki/Directive). It would makes things easier for me here as there are a lot of warnings... but I'd like to know if that would be a problem to add such comments to the source code ?", "These changes look generally good. Could you rebase as some conflicts have appeared", "@aselle, yes sure I'll rebase when it's ready, but it's far from being finished. I still don't know what's your answer to my previous question:\r\n\r\n> in some cases where shellcheck raises false positives, I can silence them by adding a comment. It would makes things easier for me here as there are a lot of warnings... but I'd like to know if that would be a problem to add such comments to the source code ?\r\n", "I'm not super thrilled with this, honestly.\r\n```\r\n# shellcheck disable=SC2059\r\n```\r\n@martinwicke, how do you feel about tools specific warning disables for shell script cleanliness?", "I'd feel better without the comments (just take them out, I guess), since we're not using shellcheck. The changes the tool suggested/made all look good though.", "@zapashcanon  can you please re base your branch"]}, {"number": 17264, "title": "Add index to plugin_name of Tags table", "body": "Added index to plugin_name of Tags table in TensorBoard DB schema to potentially help query performance (e.g.,  `SELECT 1 FROM Tags WHERE Tags.plugin_name = ?`) in histograms_plugin.", "comments": ["Nagging Assignee @protoget: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly."]}, {"number": 17263, "title": "A good and practical feature is removed", "body": "```\r\nbatch_size = tf.placeholder([],dtype=tf.int32) \r\nlstm_cell = rnn.BasicLSTMCell(num_units=hidden_size, forget_bias=1.0, state_is_tuple=True)\r\ninit_state = lstm_cell.zero_state(batch_size, dtype=tf.float32)\r\n\r\nValueError: prefix tensor must be either a scalar or vector, but saw tensor\r\n```\r\nWhen training and test, I want to use the different batch size. But in `zero_state` function, the first parameter doesn't support a tensor as input. To my knowledge, I don't meet the error with the version of tensorflow before 1.2. Now I update tensorflow to 1.2.1. I think that using the different batch size is a practical function. \r\nIn stackoverflow, a same problem is post, but it is not solved.\r\n[https://stackoverflow.com/questions/44961181/drqn-prefix-tensor-must-be-either-a-scalar-or-vector-but-saw-tensor](url)\r\nHow can I solve this problem? Thanks!\r\n", "comments": []}, {"number": 17262, "title": "Add go_package to proto definition files", "body": "This fix tries to address the issue raised in #16282 by add go_package to proto files, so that generated go files have correct path.\r\n\r\nThis fix fixes #16282.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["Nagging Reviewer @asimshankar: It has been 14 days with no activity and the `awaiting review` label was assigned. Can you please take a look?"]}, {"number": 17261, "title": "add _div_metric, sensitivity, specificity", "body": "### This PR propose the following changes:\r\n#### 1. Add two new metrics: `tf.metrics.sensitivity` and `tf.metrics.specificity`.\r\n`tf.metrics.sensitivity` is identical to `tf.metrics.recall`. These two metrics accept `labels` and `predictions` as parameters, cast `predictions` to boolean, and then do the computation according to formula:\r\nsensitivity = true_positive / (true_positive + false_negative)\r\nspecificity = true_negative / (true_negative + false_positive)\r\n\r\n#### 2. Add a helper function `_div_metric`\r\nThis helper function can be used to compute all metrics that is defined as the quotient of two metrics. This helper function simplifies the computation of a couple of metrics.\r\n\r\n### Further comments:\r\n1. Would it be beneficial if we rename `_div_metric` to `div_metric` and make it public?\r\n2. I don't see any unit test for `tf.metrics`, do I miss something?\r\n\r\n", "comments": ["Hi @zasdfgbnm\r\nCould you please review tf.contrib.metrics.* to see whether what you're looking for is there or not?\r\nWe have sensitivity, and specificity metrics defined there.", "@ispirmustafa I don't find sensitivity and specificity there either, do I miss something? However, I find `streaming_false_negative_rate` and `streaming_false_positive_rate`, which is 1 - (what I want). I'm totally happy with these two functions, so you can close this PR if you want. Thank you!\r\n\r\nBy the way, the metric API of tensorflow looks a bit odd to me: we have true positive(TP), true negative(TN), false positive(FP) and false negative(FN). There are various ways to combine these four metrics:\r\nTP/(TP+FP)\r\nFP/(TP+FP)\r\nTP/(TP+FN)\r\nFN/(TP+FN)\r\nTN/(TN+FP)\r\nFP/(TN+FP)\r\n.....\r\nThere are a lot of useful functions like above. The set of functions that tensorflow currently have is not complete and it is hard for users to memorize the name of these functions. If further a \"at_threshold\" mode is supported, this doubles the amount. There is also a \"top_k\" version.... Would it be nice if we have user code that looks like:\r\n```python\r\ndef model_fn(...):\r\n  ......\r\n  tp = tf.metrics.true_positive(label, prediction)  # an object of type tf.metrics.Metric\r\n  fn = tf.metrics.false_negative(label, prediction)\r\n  sensitivity = tp / (tp + fn)  # safe div of two tf.metrics.Metric object\r\n  ......\r\n  return tf.estimator.EstimatorSpec(mode, loss=loss, eval_metric_ops={\"dict of string->tf.metrics.Metric\"})\r\n```", "Hi @zasdfgbnm ,\r\nI was thinking `specificity_at_sensitivity` but you're right that's not what you're looking for.\r\nI understand your example. But in reality things are not that simple. For example you can look at the implementation of any *_at_threshold which is not that simple. IMHO, providing common metrics as functions helps many users to have metrics in a clean way.", "@protoget How do we set that this PR needs API review? I've add the labels. is that it?", "That should be it. I'd like to change the assignee to you since you're reviewing.", "@ispirmustafa I have updated the files. For the convenience of your review, below is the diff between recall and specificity obtained using the following command (on fish shell):\r\n```fish\r\ngit diff -w (sed -n '1978,2067p' metrics_impl.py|psub) (sed -n '2084,2176p' metrics_impl.py|psub)\r\n```\r\n\r\n```diff\r\n@@ -1,23 +1,26 @@\r\n-@tf_export('metrics.recall')\r\n-def recall(labels,\r\n+@tf_export('metrics.specificity')\r\n+def specificity(labels,\r\n                 predictions,\r\n                 weights=None,\r\n                 metrics_collections=None,\r\n                 updates_collections=None,\r\n                 name=None):\r\n-  \"\"\"Computes the recall of the predictions with respect to the labels.\r\n+  \"\"\"Computes the specificity of the predictions with respect to the labels.\r\n \r\n-  The `recall` function creates two local variables, `true_positives`\r\n-  and `false_negatives`, that are used to compute the recall. This value is\r\n-  ultimately returned as `recall`, an idempotent operation that simply divides\r\n-  `true_positives` by the sum of `true_positives`  and `false_negatives`.\r\n+  The `specificity` function creates two local variables, `true_negatives`\r\n+  and `false_positives`, that are used to compute the specificity. This value\r\n+  is ultimately returned as `specificity`, an idempotent operation that simply\r\n+  divides `true_negatives` by the sum of `true_negatives` and `false_positives`.\r\n \r\n   For estimation of the metric over a stream of data, the function creates an\r\n-  `update_op` that updates these variables and returns the `recall`. `update_op`\r\n-  weights each prediction by the corresponding value in `weights`.\r\n+  `update_op` that updates these variables and returns the `specificity`.\r\n+  `update_op` weights each prediction by the corresponding value in `weights`.\r\n \r\n   If `weights` is `None`, weights default to 1. Use weights of 0 to mask values.\r\n \r\n+  For additional information about specificity and sensitivity, see the\r\n+  following: https://en.wikipedia.org/wiki/Sensitivity_and_specificity\r\n+\r\n   Args:\r\n     labels: The ground truth values, a `Tensor` whose dimensions must match\r\n       `predictions`. Will be cast to `bool`.\r\n@@ -26,18 +29,18 @@ def recall(labels,\r\n     weights: Optional `Tensor` whose rank is either 0, or the same rank as\r\n       `labels`, and must be broadcastable to `labels` (i.e., all dimensions must\r\n       be either `1`, or the same as the corresponding `labels` dimension).\r\n-    metrics_collections: An optional list of collections that `recall` should\r\n-      be added to.\r\n+    metrics_collections: An optional list of collections that `specificity`\r\n+      should be added to.\r\n     updates_collections: An optional list of collections that `update_op` should\r\n       be added to.\r\n     name: An optional variable_scope name.\r\n \r\n   Returns:\r\n-    recall: Scalar float `Tensor` with the value of `true_positives` divided\r\n-      by the sum of `true_positives` and `false_negatives`.\r\n-    update_op: `Operation` that increments `true_positives` and\r\n-      `false_negatives` variables appropriately and whose value matches\r\n-      `recall`.\r\n+    specificity: Scalar float `Tensor` with the value of `true_negatives`\r\n+      divided by the sum of `true_negatives` and `false_positives`.\r\n+    update_op: `Operation` that increments `true_negatives` and\r\n+      `false_positives` variables appropriately and whose value matches\r\n+      `specificity`.\r\n \r\n   Raises:\r\n     ValueError: If `predictions` and `labels` have mismatched shapes, or if\r\n@@ -50,21 +53,21 @@ def recall(labels,\r\n     raise RuntimeError('tf.metrics.recall is not supported is not '\r\n                        'supported when eager execution is enabled.')\r\n \r\n-  with variable_scope.variable_scope(name, 'recall',\r\n+  with variable_scope.variable_scope(name, 'specificity',\r\n                                      (predictions, labels, weights)):\r\n     predictions, labels, weights = _remove_squeezable_dimensions(\r\n         predictions=math_ops.cast(predictions, dtype=dtypes.bool),\r\n         labels=math_ops.cast(labels, dtype=dtypes.bool),\r\n         weights=weights)\r\n \r\n-    true_p, true_positives_update_op = true_positives(\r\n+    true_n, true_negatives_update_op = true_negatives(\r\n         labels,\r\n         predictions,\r\n         weights,\r\n         metrics_collections=None,\r\n         updates_collections=None,\r\n         name=None)\r\n-    false_n, false_negatives_update_op = false_negatives(\r\n+    false_p, false_positives_update_op = false_positives(\r\n         labels,\r\n         predictions,\r\n         weights,\r\n@@ -72,19 +75,19 @@ def recall(labels,\r\n         updates_collections=None,\r\n         name=None)\r\n \r\n-    def compute_recall(true_p, false_n, name):\r\n+    def compute_specificity(true_n, false_p, name):\r\n       return array_ops.where(\r\n-          math_ops.greater(true_p + false_n, 0),\r\n-          math_ops.div(true_p, true_p + false_n), 0, name)\r\n+          math_ops.greater(true_n + false_p, 0),\r\n+          math_ops.div(true_n, true_n + false_p), 0, name)\r\n \r\n-    rec = compute_recall(true_p, false_n, 'value')\r\n-    update_op = compute_recall(true_positives_update_op,\r\n-                               false_negatives_update_op, 'update_op')\r\n+    specificity = compute_specificity(true_n, false_p, 'value')\r\n+    update_op = compute_specificity(true_negatives_update_op,\r\n+                                    false_positives_update_op, 'update_op')\r\n \r\n     if metrics_collections:\r\n-      ops.add_to_collections(metrics_collections, rec)\r\n+      ops.add_to_collections(metrics_collections, specificity)\r\n \r\n     if updates_collections:\r\n       ops.add_to_collections(updates_collections, update_op)\r\n \r\n-    return rec, update_op\r\n+    return specificity, update_op\r\n```", "@ispirmustafa I added a unit test for `specificity`. ~~I think this is the only unit test for metrics.~~", "@ispirmustafa I have changed and resolved the conflicts. And the tests pass on my computer.", "@tensorflow-jenkins test this please", "I think someone might need to trigger the test bot.", "@josh11b could you double-check that the API is OK?", "@josh11b Done", "All the two fails are `api_compatibility_test`, so it should be OK now.", "`api_compatibility_test` seems to be failing. could you regenerate the goldens?\r\n\r\nThe `metrics_test` also fails. \r\n\r\n\r\n```\r\n......ERROR:tensorflow:Attempting to use uninitialized value recall_at_5_class8/false_negative_at_5_class8\r\n\t [[node recall_at_5_class8/false_negative_at_5_class8/read (defined at /usr/lib/python2.7/unittest/case.py:329)  = Identity[T=DT_DOUBLE, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](recall_at_5_class8/false_negative_at_5_class8)]]\r\nCaused by op u'recall_at_5_class8/false_negative_at_5_class8/read', defined at:\r\n  File \"/b/f/w/run/bazel-out/k8-opt/bin/tensorflow/python/kernel_tests/metrics_test.runfiles/org_tensorflow/tensorflow/python/kernel_tests/metrics_test.py\", line 4355, in <module>\r\n    test.main()\r\n```", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "It has been 28 days that this pull-request has stalled. Please create a new pull-request with the requested changes."]}, {"number": 17260, "title": "Running on DLAMI ", "body": "I've got this error when running this script on Amazon aws. \r\n\r\nI just want to know if this error is related to the memory space on the aws or within my installation of the project? If this is possible on first sight. \r\nSo that I now where to ask the more specific questions.\r\n\r\n\r\nERROR OUTPUT:\r\n```\r\n\r\n2018-02-25 16:31:13.224347: W tensorflow/core/common_runtime/bfc_allocator.cc:217] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.56GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.\r\n2018-02-25 16:31:14.783453: W tensorflow/core/common_runtime/bfc_allocator.cc:217] Allocator (GPU_0_bfc) ran out of memory trying to allocate 800.00MiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.\r\n2018-02-25 16:31:27.854629: W tensorflow/core/common_runtime/bfc_allocator.cc:273] Allocator (GPU_0_bfc) ran out of memory trying to allocate 128.00MiB.  Current allocation summary follows.\r\n2018-02-25 16:31:27.854710: I tensorflow/core/common_runtime/bfc_allocator.cc:628] Bin (256): \tTotal Chunks: 84, Chunks in use: 84. 21.0KiB allocated for chunks. 21.0KiB in use in bin. 6.8KiB client-requested in use in bin.\r\n2018-02-25 16:31:27.854733: I tensorflow/core/common_runtime/bfc_allocator.cc:628] Bin (512): \tTotal Chunks: 41, Chunks in use: 41. 20.5KiB allocated for chunks. 20.5KiB in use in bin. 20.5KiB client-requested in use in bin.\r\n2018-02-25 16:31:27.854752: I tensorflow/core/common_runtime/bfc_allocator.cc:628] Bin (1024): \tTotal Chunks: 35, Chunks in use: 35. 35.2KiB allocated for chunks. 35.2KiB in use in bin. 35.0KiB client-requested in use in bin.\r\n2018-02-25 16:31:27.854770: I tensorflow/core/common_runtime/bfc_allocator.cc:628] Bin (2048): \tTotal Chunks: 30, Chunks in use: 30. 60.0KiB allocated for chunks. 60.0KiB in use in bin. 60.0KiB client-requested in use in bin.\r\n2018-02-25 16:31:27.854787: I tensorflow/core/common_runtime/bfc_allocator.cc:628] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-02-25 16:31:27.854804: I tensorflow/core/common_runtime/bfc_allocator.cc:628] Bin (8192): \tTotal Chunks: 1, Chunks in use: 0. 8.5KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-02-25 16:31:27.854821: I tensorflow/core/common_runtime/bfc_allocator.cc:628] Bin (16384): \tTotal Chunks: 8, Chunks in use: 8. 150.0KiB allocated for chunks. 150.0KiB in use in bin. 150.0KiB client-requested in use in bin.\r\n2018-02-25 16:31:27.854832: I tensorflow/core/common_runtime/bfc_allocator.cc:628] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-02-25 16:31:27.854843: I tensorflow/core/common_runtime/bfc_allocator.cc:628] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-02-25 16:31:27.854854: I tensorflow/core/common_runtime/bfc_allocator.cc:628] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-02-25 16:31:27.854869: I tensorflow/core/common_runtime/bfc_allocator.cc:628] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-02-25 16:31:27.854883: I tensorflow/core/common_runtime/bfc_allocator.cc:628] Bin (524288): \tTotal Chunks: 17, Chunks in use: 16. 11.51MiB allocated for chunks. 11.01MiB in use in bin. 10.25MiB client-requested in use in bin.\r\n2018-02-25 16:31:27.854904: I tensorflow/core/common_runtime/bfc_allocator.cc:628] Bin (1048576): \tTotal Chunks: 2, Chunks in use: 1. 2.70MiB allocated for chunks. 1.14MiB in use in bin. 800.0KiB client-requested in use in bin.\r\n2018-02-25 16:31:27.854918: I tensorflow/core/common_runtime/bfc_allocator.cc:628] Bin (2097152): \tTotal Chunks: 8, Chunks in use: 7. 25.00MiB allocated for chunks. 21.88MiB in use in bin. 21.88MiB client-requested in use in bin.\r\n2018-02-25 16:31:27.854935: I tensorflow/core/common_runtime/bfc_allocator.cc:628] Bin (4194304): \tTotal Chunks: 2, Chunks in use: 1. 10.25MiB allocated for chunks. 4.00MiB in use in bin. 3.12MiB client-requested in use in bin.\r\n2018-02-25 16:31:27.854955: I tensorflow/core/common_runtime/bfc_allocator.cc:628] Bin (8388608): \tTotal Chunks: 8, Chunks in use: 7. 103.46MiB allocated for chunks. 90.96MiB in use in bin. 87.50MiB client-requested in use in bin.\r\n2018-02-25 16:31:27.854973: I tensorflow/core/common_runtime/bfc_allocator.cc:628] Bin (16777216): \tTotal Chunks: 2, Chunks in use: 1. 41.00MiB allocated for chunks. 16.00MiB in use in bin. 12.50MiB client-requested in use in bin.\r\n2018-02-25 16:31:27.854990: I tensorflow/core/common_runtime/bfc_allocator.cc:628] Bin (33554432): \tTotal Chunks: 5, Chunks in use: 4. 228.00MiB allocated for chunks. 180.00MiB in use in bin. 180.00MiB client-requested in use in bin.\r\n2018-02-25 16:31:27.855008: I tensorflow/core/common_runtime/bfc_allocator.cc:628] Bin (67108864): \tTotal Chunks: 9, Chunks in use: 6. 657.16MiB allocated for chunks. 448.78MiB in use in bin. 340.00MiB client-requested in use in bin.\r\n2018-02-25 16:31:27.855025: I tensorflow/core/common_runtime/bfc_allocator.cc:628] Bin (134217728): \tTotal Chunks: 8, Chunks in use: 8. 1.21GiB allocated for chunks. 1.21GiB in use in bin. 1.00GiB client-requested in use in bin.\r\n2018-02-25 16:31:27.855042: I tensorflow/core/common_runtime/bfc_allocator.cc:628] Bin (268435456): \tTotal Chunks: 5, Chunks in use: 5. 1.30GiB allocated for chunks. 1.30GiB in use in bin. 1.25GiB client-requested in use in bin.\r\n2018-02-25 16:31:27.855079: I tensorflow/core/common_runtime/bfc_allocator.cc:644] Bin for 128.00MiB was 128.00MiB, Chunk State: \r\n2018-02-25 16:31:27.855099: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702680000 of size 1280\r\n2018-02-25 16:31:27.855114: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702680500 of size 256\r\n2018-02-25 16:31:27.855128: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702680600 of size 256\r\n2018-02-25 16:31:27.855142: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702680700 of size 1046784\r\n2018-02-25 16:31:27.855157: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702780000 of size 2048\r\n2018-02-25 16:31:27.855168: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702780800 of size 2048\r\n2018-02-25 16:31:27.855178: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702781000 of size 2048\r\n2018-02-25 16:31:27.855190: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702781800 of size 2048\r\n2018-02-25 16:31:27.855201: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702782000 of size 256\r\n2018-02-25 16:31:27.855214: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702782100 of size 256\r\n2018-02-25 16:31:27.855228: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702782200 of size 1024\r\n2018-02-25 16:31:27.855243: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702782600 of size 1024\r\n2018-02-25 16:31:27.855258: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702782a00 of size 1024\r\n2018-02-25 16:31:27.855272: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702782e00 of size 1024\r\n2018-02-25 16:31:27.855286: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702783200 of size 1024\r\n2018-02-25 16:31:27.855300: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702783600 of size 256\r\n2018-02-25 16:31:27.855313: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702783700 of size 256\r\n2018-02-25 16:31:27.855327: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702783800 of size 512\r\n2018-02-25 16:31:27.855341: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702783a00 of size 512\r\n2018-02-25 16:31:27.855354: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702783c00 of size 512\r\n2018-02-25 16:31:27.855368: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702783e00 of size 512\r\n2018-02-25 16:31:27.855382: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702784000 of size 512\r\n2018-02-25 16:31:27.855396: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702784200 of size 256\r\n2018-02-25 16:31:27.855409: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702784300 of size 256\r\n2018-02-25 16:31:27.855423: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702784400 of size 256\r\n2018-02-25 16:31:27.855436: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702784500 of size 256\r\n2018-02-25 16:31:27.855450: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702784600 of size 256\r\n2018-02-25 16:31:27.855463: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702784700 of size 256\r\n2018-02-25 16:31:27.855476: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702784800 of size 256\r\n2018-02-25 16:31:27.855489: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702784900 of size 256\r\n2018-02-25 16:31:27.855502: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702784a00 of size 256\r\n2018-02-25 16:31:27.855516: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702784b00 of size 256\r\n2018-02-25 16:31:27.855531: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702784c00 of size 256\r\n2018-02-25 16:31:27.855544: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702784d00 of size 256\r\n2018-02-25 16:31:27.855558: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702784e00 of size 256\r\n2018-02-25 16:31:27.855572: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702784f00 of size 256\r\n2018-02-25 16:31:27.855585: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702785000 of size 256\r\n2018-02-25 16:31:27.855601: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702785100 of size 512\r\n2018-02-25 16:31:27.855615: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702785300 of size 512\r\n2018-02-25 16:31:27.855628: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702785500 of size 512\r\n2018-02-25 16:31:27.855642: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702785700 of size 512\r\n2018-02-25 16:31:27.855655: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702785900 of size 512\r\n2018-02-25 16:31:27.855668: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702785b00 of size 256\r\n2018-02-25 16:31:27.855682: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702785c00 of size 256\r\n2018-02-25 16:31:27.855700: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702785d00 of size 1024\r\n2018-02-25 16:31:27.855723: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702786100 of size 1024\r\n2018-02-25 16:31:27.855749: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702786500 of size 1024\r\n2018-02-25 16:31:27.855765: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702786900 of size 1024\r\n2018-02-25 16:31:27.855778: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702786d00 of size 1024\r\n2018-02-25 16:31:27.855797: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702787100 of size 256\r\n2018-02-25 16:31:27.855820: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702787200 of size 256\r\n2018-02-25 16:31:27.855843: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702787300 of size 2048\r\n2018-02-25 16:31:27.855864: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702787b00 of size 2048\r\n2018-02-25 16:31:27.855875: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702788300 of size 2048\r\n2018-02-25 16:31:27.855888: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702788b00 of size 2048\r\n2018-02-25 16:31:27.855898: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702789300 of size 2048\r\n2018-02-25 16:31:27.855911: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702789b00 of size 256\r\n2018-02-25 16:31:27.855927: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702789c00 of size 256\r\n2018-02-25 16:31:27.855949: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702789d00 of size 256\r\n2018-02-25 16:31:27.855969: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702789e00 of size 256\r\n2018-02-25 16:31:27.855991: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702789f00 of size 256\r\n2018-02-25 16:31:27.856011: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x70278a000 of size 19200\r\n2018-02-25 16:31:27.856035: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x70278eb00 of size 819200\r\n2018-02-25 16:31:27.856055: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702856b00 of size 19200\r\n2018-02-25 16:31:27.856077: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x70285b600 of size 512\r\n2018-02-25 16:31:27.856096: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x70285b800 of size 512\r\n2018-02-25 16:31:27.856118: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x70285ba00 of size 1024\r\n2018-02-25 16:31:27.856138: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x70285be00 of size 1196544\r\n2018-02-25 16:31:27.856162: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702980000 of size 4194304\r\n2018-02-25 16:31:27.856182: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702d80000 of size 16777216\r\n2018-02-25 16:31:27.856205: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x703d80000 of size 2048\r\n2018-02-25 16:31:27.856224: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x703d80800 of size 524288\r\n2018-02-25 16:31:27.856247: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x703e00800 of size 256\r\n2018-02-25 16:31:27.856267: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x703e00900 of size 256\r\n2018-02-25 16:31:27.856289: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x703e00a00 of size 2048\r\n2018-02-25 16:31:27.856308: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x703e01200 of size 16248320\r\n2018-02-25 16:31:27.856332: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x704d80000 of size 67108864\r\n2018-02-25 16:31:27.856351: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x708d80000 of size 256\r\n2018-02-25 16:31:27.856373: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x708d80100 of size 1024\r\n2018-02-25 16:31:27.856393: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x708d80500 of size 3276800\r\n2018-02-25 16:31:27.856416: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7090a0500 of size 819200\r\n2018-02-25 16:31:27.856435: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x709168500 of size 819200\r\n2018-02-25 16:31:27.856457: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x709230500 of size 512\r\n2018-02-25 16:31:27.856476: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x709230700 of size 512\r\n2018-02-25 16:31:27.856498: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x709230900 of size 3276800\r\n2018-02-25 16:31:27.856518: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x709550900 of size 3276800\r\n2018-02-25 16:31:27.856539: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x709870900 of size 512\r\n2018-02-25 16:31:27.856558: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x709870b00 of size 512\r\n2018-02-25 16:31:27.856580: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x709870d00 of size 19200\r\n2018-02-25 16:31:27.856600: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x709875800 of size 1024\r\n2018-02-25 16:31:27.856622: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x709875c00 of size 1024\r\n2018-02-25 16:31:27.856646: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x709876000 of size 13107200\r\n2018-02-25 16:31:27.856669: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x70a4f6000 of size 13107200\r\n2018-02-25 16:31:27.856688: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x70b176000 of size 819200\r\n2018-02-25 16:31:27.856711: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x70b23e000 of size 819200\r\n2018-02-25 16:31:27.856730: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x70b306000 of size 2048\r\n2018-02-25 16:31:27.856751: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x70b306800 of size 2048\r\n2018-02-25 16:31:27.856775: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x70b307000 of size 524288\r\n2018-02-25 16:31:27.856798: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x70b387000 of size 524288\r\n2018-02-25 16:31:27.856813: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x70b407000 of size 256\r\n2018-02-25 16:31:27.856828: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x70b407100 of size 256\r\n2018-02-25 16:31:27.856844: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x70b407200 of size 2048\r\n2018-02-25 16:31:27.856866: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x70b407a00 of size 2048\r\n2018-02-25 16:31:27.856885: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x70b408200 of size 13107200\r\n2018-02-25 16:31:27.856909: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x70c088200 of size 13598208\r\n2018-02-25 16:31:27.856929: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x70cd80000 of size 52428800\r\n2018-02-25 16:31:27.856952: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x70ff80000 of size 81788928\r\n2018-02-25 16:31:27.856972: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x714d80000 of size 256\r\n2018-02-25 16:31:27.856994: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x714d80100 of size 1024\r\n2018-02-25 16:31:27.857013: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x714d80500 of size 1024\r\n2018-02-25 16:31:27.857035: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x714d80900 of size 256\r\n2018-02-25 16:31:27.857054: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x714d80a00 of size 3276800\r\n2018-02-25 16:31:27.857076: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7150a0a00 of size 3276800\r\n2018-02-25 16:31:27.857099: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7153c0a00 of size 13107200\r\n2018-02-25 16:31:27.857119: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x716040a00 of size 13107200\r\n2018-02-25 16:31:27.857130: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7185c0a00 of size 524288\r\n2018-02-25 16:31:27.857143: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x718640a00 of size 524288\r\n2018-02-25 16:31:27.857153: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7186c0a00 of size 524288\r\n2018-02-25 16:31:27.857165: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x718740a00 of size 2048\r\n2018-02-25 16:31:27.857180: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x718741200 of size 2048\r\n2018-02-25 16:31:27.857203: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x718741a00 of size 2048\r\n2018-02-25 16:31:27.857222: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x718742200 of size 2048\r\n2018-02-25 16:31:27.857244: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x718742a00 of size 2048\r\n2018-02-25 16:31:27.857263: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x718743200 of size 2048\r\n2018-02-25 16:31:27.857285: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x718743a00 of size 3276800\r\n2018-02-25 16:31:27.857308: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x718a63a00 of size 3276800\r\n2018-02-25 16:31:27.857328: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7193c3a00 of size 1024\r\n2018-02-25 16:31:27.857339: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7193c3e00 of size 1024\r\n2018-02-25 16:31:27.857352: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7193c4200 of size 1024\r\n2018-02-25 16:31:27.857362: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7193c4600 of size 1024\r\n2018-02-25 16:31:27.857375: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7193c4a00 of size 1024\r\n2018-02-25 16:31:27.857390: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7193c4e00 of size 1024\r\n2018-02-25 16:31:27.857412: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7193c5200 of size 1024\r\n2018-02-25 16:31:27.857434: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7193c5600 of size 1024\r\n2018-02-25 16:31:27.857453: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7193c5a00 of size 1024\r\n2018-02-25 16:31:27.857464: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7193c5e00 of size 819200\r\n2018-02-25 16:31:27.857477: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x71948de00 of size 819200\r\n2018-02-25 16:31:27.857487: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7196e5e00 of size 512\r\n2018-02-25 16:31:27.857500: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7196e6000 of size 512\r\n2018-02-25 16:31:27.857515: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7196e6200 of size 512\r\n2018-02-25 16:31:27.857538: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7196e6400 of size 512\r\n2018-02-25 16:31:27.857560: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7196e6600 of size 512\r\n2018-02-25 16:31:27.857579: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7196e6800 of size 512\r\n2018-02-25 16:31:27.857590: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7196e6a00 of size 512\r\n2018-02-25 16:31:27.857604: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7196e6c00 of size 512\r\n2018-02-25 16:31:27.857618: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7196e6e00 of size 512\r\n2018-02-25 16:31:27.857631: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7196e7000 of size 19200\r\n2018-02-25 16:31:27.857648: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7196ebb00 of size 800000\r\n2018-02-25 16:31:27.857670: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197af000 of size 256\r\n2018-02-25 16:31:27.857698: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197af100 of size 256\r\n2018-02-25 16:31:27.857717: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197af200 of size 256\r\n2018-02-25 16:31:27.857727: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197af300 of size 256\r\n2018-02-25 16:31:27.857740: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197af400 of size 256\r\n2018-02-25 16:31:27.857750: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197af500 of size 256\r\n2018-02-25 16:31:27.857762: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197af600 of size 256\r\n2018-02-25 16:31:27.857777: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197af700 of size 256\r\n2018-02-25 16:31:27.857800: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197af800 of size 256\r\n2018-02-25 16:31:27.857822: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197af900 of size 19200\r\n2018-02-25 16:31:27.857842: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b4400 of size 256\r\n2018-02-25 16:31:27.857860: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b4500 of size 256\r\n2018-02-25 16:31:27.857874: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b4600 of size 256\r\n2018-02-25 16:31:27.857887: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b4700 of size 256\r\n2018-02-25 16:31:27.857897: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b4800 of size 256\r\n2018-02-25 16:31:27.857910: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b4900 of size 256\r\n2018-02-25 16:31:27.857924: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b4a00 of size 256\r\n2018-02-25 16:31:27.857947: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b4b00 of size 256\r\n2018-02-25 16:31:27.857970: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b4c00 of size 256\r\n2018-02-25 16:31:27.857989: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b4d00 of size 256\r\n2018-02-25 16:31:27.858000: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b4e00 of size 256\r\n2018-02-25 16:31:27.858012: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b4f00 of size 256\r\n2018-02-25 16:31:27.858022: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b5000 of size 256\r\n2018-02-25 16:31:27.858035: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b5100 of size 256\r\n2018-02-25 16:31:27.858050: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b5200 of size 256\r\n2018-02-25 16:31:27.858072: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b5300 of size 256\r\n2018-02-25 16:31:27.858091: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b5400 of size 256\r\n2018-02-25 16:31:27.858113: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b5500 of size 256\r\n2018-02-25 16:31:27.858132: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b5600 of size 256\r\n2018-02-25 16:31:27.858153: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b5700 of size 256\r\n2018-02-25 16:31:27.858176: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b5800 of size 256\r\n2018-02-25 16:31:27.858195: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b5900 of size 256\r\n2018-02-25 16:31:27.858206: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b5a00 of size 256\r\n2018-02-25 16:31:27.858219: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b5b00 of size 256\r\n2018-02-25 16:31:27.858229: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b5c00 of size 256\r\n2018-02-25 16:31:27.858242: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b5d00 of size 256\r\n2018-02-25 16:31:27.858257: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b5e00 of size 256\r\n2018-02-25 16:31:27.858279: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b5f00 of size 256\r\n2018-02-25 16:31:27.858299: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b6000 of size 512\r\n2018-02-25 16:31:27.858321: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b6200 of size 256\r\n2018-02-25 16:31:27.858343: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b6300 of size 256\r\n2018-02-25 16:31:27.858363: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b6400 of size 512\r\n2018-02-25 16:31:27.858373: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b6600 of size 512\r\n2018-02-25 16:31:27.858386: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b6800 of size 512\r\n2018-02-25 16:31:27.858396: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b6a00 of size 512\r\n2018-02-25 16:31:27.858409: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b6c00 of size 512\r\n2018-02-25 16:31:27.858425: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b6e00 of size 512\r\n2018-02-25 16:31:27.858447: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b9200 of size 256\r\n2018-02-25 16:31:27.858470: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b9300 of size 819200\r\n2018-02-25 16:31:27.858489: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x719881300 of size 512\r\n2018-02-25 16:31:27.858500: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x719881500 of size 512\r\n2018-02-25 16:31:27.858513: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x719881700 of size 512\r\n2018-02-25 16:31:27.858523: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x719881900 of size 512\r\n2018-02-25 16:31:27.858536: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x719881b00 of size 512\r\n2018-02-25 16:31:27.858550: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x719881d00 of size 512\r\n2018-02-25 16:31:27.858573: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x719881f00 of size 512\r\n2018-02-25 16:31:27.858595: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x719882100 of size 512\r\n2018-02-25 16:31:27.858615: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x719882300 of size 512\r\n2018-02-25 16:31:27.858626: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x719ba2500 of size 1024\r\n2018-02-25 16:31:27.858638: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x719ba2900 of size 1024\r\n2018-02-25 16:31:27.858648: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x719ba2d00 of size 1024\r\n2018-02-25 16:31:27.858661: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x719ba3100 of size 1024\r\n2018-02-25 16:31:27.858676: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x719ba3500 of size 1024\r\n2018-02-25 16:31:27.858698: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x719ba3900 of size 1024\r\n2018-02-25 16:31:27.858718: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x719ba3d00 of size 1024\r\n2018-02-25 16:31:27.858740: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x719ba4100 of size 1024\r\n2018-02-25 16:31:27.858768: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x719ba4500 of size 1024\r\n2018-02-25 16:31:27.858791: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x71a824900 of size 2048\r\n2018-02-25 16:31:27.858810: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x71a825100 of size 2048\r\n2018-02-25 16:31:27.858821: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x71a825900 of size 2048\r\n2018-02-25 16:31:27.858834: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x71a826100 of size 2048\r\n2018-02-25 16:31:27.858845: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x71a826900 of size 2048\r\n2018-02-25 16:31:27.858858: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x71a827100 of size 2048\r\n2018-02-25 16:31:27.858872: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x71a827900 of size 2048\r\n2018-02-25 16:31:27.858889: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x71a828100 of size 2048\r\n2018-02-25 16:31:27.858915: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x71a828900 of size 2048\r\n2018-02-25 16:31:27.858935: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x71a8a9100 of size 256\r\n2018-02-25 16:31:27.858956: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x71a8a9200 of size 256\r\n2018-02-25 16:31:27.858978: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x71a8a9300 of size 256\r\n2018-02-25 16:31:27.858998: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x71a8a9400 of size 256\r\n2018-02-25 16:31:27.859014: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x71a8a9500 of size 256\r\n2018-02-25 16:31:27.859036: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x71a8a9600 of size 19200\r\n2018-02-25 16:31:27.859076: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x71a8ae100 of size 19200\r\n2018-02-25 16:31:27.859093: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x71a8b2c00 of size 19200\r\n2018-02-25 16:31:27.859108: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x71a8b7700 of size 256\r\n2018-02-25 16:31:27.859123: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x71a8b7800 of size 256\r\n2018-02-25 16:31:27.859145: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x71a8b7900 of size 52428800\r\n2018-02-25 16:31:27.859169: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x71dab7900 of size 120358656\r\n2018-02-25 16:31:27.859189: I tensorflow/core/common_runtime/bfc_allocator.cc:671] Free at 0x716cc0a00 of size 26214400\r\n2018-02-25 16:31:27.859201: I tensorflow/core/common_runtime/bfc_allocator.cc:671] Free at 0x718d83a00 of size 6553600\r\n2018-02-25 16:31:27.859214: I tensorflow/core/common_runtime/bfc_allocator.cc:671] Free at 0x719555e00 of size 1638400\r\n2018-02-25 16:31:27.859224: I tensorflow/core/common_runtime/bfc_allocator.cc:671] Free at 0x7197b7000 of size 8704\r\n2018-02-25 16:31:27.859237: I tensorflow/core/common_runtime/bfc_allocator.cc:671] Free at 0x719882500 of size 3276800\r\n2018-02-25 16:31:27.859253: I tensorflow/core/common_runtime/bfc_allocator.cc:671] Free at 0x719ba4900 of size 13107200\r\n2018-02-25 16:31:27.859271: I tensorflow/core/common_runtime/bfc_allocator.cc:671] Free at 0x71a829100 of size 524288\r\n2018-02-25 16:31:27.859295: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x724d80000 of size 268435456\r\n2018-02-25 16:31:27.859315: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x734d80000 of size 134217728\r\n2018-02-25 16:31:27.859338: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x73cd80000 of size 33554432\r\n2018-02-25 16:31:27.859359: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x73ed80000 of size 50331648\r\n2018-02-25 16:31:27.859381: I tensorflow/core/common_runtime/bfc_allocator.cc:671] Free at 0x741d80000 of size 50331648\r\n2018-02-25 16:31:27.859400: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x744f80000 of size 268435456\r\n2018-02-25 16:31:27.859422: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x759fe0300 of size 134217728\r\n2018-02-25 16:31:27.859441: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x765fe0300 of size 67108864\r\n2018-02-25 16:31:27.859463: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x769fe0300 of size 67108864\r\n2018-02-25 16:31:27.859482: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x771fe0300 of size 318373120\r\n2018-02-25 16:31:27.859505: I tensorflow/core/common_runtime/bfc_allocator.cc:671] Free at 0x754f80000 of size 84280064\r\n2018-02-25 16:31:27.859524: I tensorflow/core/common_runtime/bfc_allocator.cc:671] Free at 0x761fe0300 of size 67108864\r\n2018-02-25 16:31:27.859546: I tensorflow/core/common_runtime/bfc_allocator.cc:671] Free at 0x76dfe0300 of size 67108864\r\n2018-02-25 16:31:27.859565: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x785280000 of size 272646144\r\n2018-02-25 16:31:27.859588: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x795684000 of size 134217728\r\n2018-02-25 16:31:27.859621: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x79d684000 of size 189252352\r\n2018-02-25 16:31:27.859642: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7a8b00300 of size 67108864\r\n2018-02-25 16:31:27.859661: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7acb00300 of size 268435456\r\n2018-02-25 16:31:27.859683: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7bcb00300 of size 260734976\r\n2018-02-25 16:31:27.859703: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7cc3a8300 of size 134217728\r\n2018-02-25 16:31:27.859724: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7d43a8300 of size 134217728\r\n2018-02-25 16:31:27.859744: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7dc3a8300 of size 182811904\r\n2018-02-25 16:31:27.859767: I tensorflow/core/common_runtime/bfc_allocator.cc:677]      Summary of in-use Chunks by size: \r\n2018-02-25 16:31:27.859792: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 84 Chunks of size 256 totalling 21.0KiB\r\n2018-02-25 16:31:27.859821: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 41 Chunks of size 512 totalling 20.5KiB\r\n2018-02-25 16:31:27.859847: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 34 Chunks of size 1024 totalling 34.0KiB\r\n2018-02-25 16:31:27.859869: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 1 Chunks of size 1280 totalling 1.2KiB\r\n2018-02-25 16:31:27.859893: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 30 Chunks of size 2048 totalling 60.0KiB\r\n2018-02-25 16:31:27.859915: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 8 Chunks of size 19200 totalling 150.0KiB\r\n2018-02-25 16:31:27.859940: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 6 Chunks of size 524288 totalling 3.00MiB\r\n2018-02-25 16:31:27.859971: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 1 Chunks of size 800000 totalling 781.2KiB\r\n2018-02-25 16:31:27.859997: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 8 Chunks of size 819200 totalling 6.25MiB\r\n2018-02-25 16:31:27.860019: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 1 Chunks of size 1046784 totalling 1022.2KiB\r\n2018-02-25 16:31:27.860043: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 1 Chunks of size 1196544 totalling 1.14MiB\r\n2018-02-25 16:31:27.860065: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 7 Chunks of size 3276800 totalling 21.88MiB\r\n2018-02-25 16:31:27.860089: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 1 Chunks of size 4194304 totalling 4.00MiB\r\n2018-02-25 16:31:27.860111: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 5 Chunks of size 13107200 totalling 62.50MiB\r\n2018-02-25 16:31:27.860135: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 1 Chunks of size 13598208 totalling 12.97MiB\r\n2018-02-25 16:31:27.860157: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 1 Chunks of size 16248320 totalling 15.50MiB\r\n2018-02-25 16:31:27.860182: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 1 Chunks of size 16777216 totalling 16.00MiB\r\n2018-02-25 16:31:27.860203: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 1 Chunks of size 33554432 totalling 32.00MiB\r\n2018-02-25 16:31:27.860229: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 1 Chunks of size 50331648 totalling 48.00MiB\r\n2018-02-25 16:31:27.860251: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 2 Chunks of size 52428800 totalling 100.00MiB\r\n2018-02-25 16:31:27.860275: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 4 Chunks of size 67108864 totalling 256.00MiB\r\n2018-02-25 16:31:27.860297: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 1 Chunks of size 81788928 totalling 78.00MiB\r\n2018-02-25 16:31:27.860322: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 1 Chunks of size 120358656 totalling 114.78MiB\r\n2018-02-25 16:31:27.860343: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 5 Chunks of size 134217728 totalling 640.00MiB\r\n2018-02-25 16:31:27.860368: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 1 Chunks of size 182811904 totalling 174.34MiB\r\n2018-02-25 16:31:27.860395: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 1 Chunks of size 189252352 totalling 180.48MiB\r\n2018-02-25 16:31:27.860417: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 1 Chunks of size 260734976 totalling 248.66MiB\r\n2018-02-25 16:31:27.860442: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 3 Chunks of size 268435456 totalling 768.00MiB\r\n2018-02-25 16:31:27.860464: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 1 Chunks of size 272646144 totalling 260.02MiB\r\n2018-02-25 16:31:27.860488: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 1 Chunks of size 318373120 totalling 303.62MiB\r\n2018-02-25 16:31:27.860509: I tensorflow/core/common_runtime/bfc_allocator.cc:684] Sum Total of in-use chunks: 3.27GiB\r\n2018-02-25 16:31:27.860535: I tensorflow/core/common_runtime/bfc_allocator.cc:686] Stats: \r\nLimit:                  3832020992\r\nInUse:                  3511868160\r\nMaxInUse:               3571212544\r\nNumAllocs:                     528\r\nMaxAllocSize:            419430400\r\n\r\n2018-02-25 16:31:27.860578: W tensorflow/core/common_runtime/bfc_allocator.cc:277] **************x*************_********_****_*************x****************************xxx***********x\r\n2018-02-25 16:31:27.860631: W tensorflow/core/framework/op_kernel.cc:1198] Resource exhausted: OOM when allocating tensor with shape[64,128,64,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n2018-02-25 16:31:27.860635: W tensorflow/core/common_runtime/bfc_allocator.cc:273] Allocator (GPU_0_bfc) ran out of memory trying to allocate 256.00MiB.  Current allocation summary follows.\r\n2018-02-25 16:31:27.860691: I tensorflow/core/common_runtime/bfc_allocator.cc:628] Bin (256): \tTotal Chunks: 84, Chunks in use: 84. 21.0KiB allocated for chunks. 21.0KiB in use in bin. 6.8KiB client-requested in use in bin.\r\n2018-02-25 16:31:27.860714: I tensorflow/core/common_runtime/bfc_allocator.cc:628] Bin (512): \tTotal Chunks: 41, Chunks in use: 41. 20.5KiB allocated for chunks. 20.5KiB in use in bin. 20.5KiB client-requested in use in bin.\r\n2018-02-25 16:31:27.860733: I tensorflow/core/common_runtime/bfc_allocator.cc:628] Bin (1024): \tTotal Chunks: 35, Chunks in use: 35. 35.2KiB allocated for chunks. 35.2KiB in use in bin. 35.0KiB client-requested in use in bin.\r\n2018-02-25 16:31:27.860753: I tensorflow/core/common_runtime/bfc_allocator.cc:628] Bin (2048): \tTotal Chunks: 30, Chunks in use: 30. 60.0KiB allocated for chunks. 60.0KiB in use in bin. 60.0KiB client-requested in use in bin.\r\n2018-02-25 16:31:27.860770: I tensorflow/core/common_runtime/bfc_allocator.cc:628] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-02-25 16:31:27.860786: I tensorflow/core/common_runtime/bfc_allocator.cc:628] Bin (8192): \tTotal Chunks: 1, Chunks in use: 0. 8.5KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-02-25 16:31:27.860804: I tensorflow/core/common_runtime/bfc_allocator.cc:628] Bin (16384): \tTotal Chunks: 8, Chunks in use: 8. 150.0KiB allocated for chunks. 150.0KiB in use in bin. 150.0KiB client-requested in use in bin.\r\n2018-02-25 16:31:27.860819: I tensorflow/core/common_runtime/bfc_allocator.cc:628] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-02-25 16:31:27.860834: I tensorflow/core/common_runtime/bfc_allocator.cc:628] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-02-25 16:31:27.860849: I tensorflow/core/common_runtime/bfc_allocator.cc:628] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-02-25 16:31:27.860865: I tensorflow/core/common_runtime/bfc_allocator.cc:628] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\r\n2018-02-25 16:31:27.860882: I tensorflow/core/common_runtime/bfc_allocator.cc:628] Bin (524288): \tTotal Chunks: 17, Chunks in use: 16. 11.51MiB allocated for chunks. 11.01MiB in use in bin. 10.25MiB client-requested in use in bin.\r\n2018-02-25 16:31:27.860899: I tensorflow/core/common_runtime/bfc_allocator.cc:628] Bin (1048576): \tTotal Chunks: 2, Chunks in use: 1. 2.70MiB allocated for chunks. 1.14MiB in use in bin. 800.0KiB client-requested in use in bin.\r\n2018-02-25 16:31:27.860917: I tensorflow/core/common_runtime/bfc_allocator.cc:628] Bin (2097152): \tTotal Chunks: 8, Chunks in use: 7. 25.00MiB allocated for chunks. 21.88MiB in use in bin. 21.88MiB client-requested in use in bin.\r\n2018-02-25 16:31:27.860934: I tensorflow/core/common_runtime/bfc_allocator.cc:628] Bin (4194304): \tTotal Chunks: 2, Chunks in use: 1. 10.25MiB allocated for chunks. 4.00MiB in use in bin. 3.12MiB client-requested in use in bin.\r\n2018-02-25 16:31:27.860951: I tensorflow/core/common_runtime/bfc_allocator.cc:628] Bin (8388608): \tTotal Chunks: 8, Chunks in use: 7. 103.46MiB allocated for chunks. 90.96MiB in use in bin. 87.50MiB client-requested in use in bin.\r\n2018-02-25 16:31:27.860968: I tensorflow/core/common_runtime/bfc_allocator.cc:628] Bin (16777216): \tTotal Chunks: 2, Chunks in use: 1. 41.00MiB allocated for chunks. 16.00MiB in use in bin. 12.50MiB client-requested in use in bin.\r\n2018-02-25 16:31:27.860986: I tensorflow/core/common_runtime/bfc_allocator.cc:628] Bin (33554432): \tTotal Chunks: 5, Chunks in use: 4. 228.00MiB allocated for chunks. 180.00MiB in use in bin. 180.00MiB client-requested in use in bin.\r\n2018-02-25 16:31:27.861003: I tensorflow/core/common_runtime/bfc_allocator.cc:628] Bin (67108864): \tTotal Chunks: 9, Chunks in use: 6. 657.16MiB allocated for chunks. 448.78MiB in use in bin. 340.00MiB client-requested in use in bin.\r\n2018-02-25 16:31:27.861020: I tensorflow/core/common_runtime/bfc_allocator.cc:628] Bin (134217728): \tTotal Chunks: 8, Chunks in use: 8. 1.21GiB allocated for chunks. 1.21GiB in use in bin. 1.00GiB client-requested in use in bin.\r\n2018-02-25 16:31:27.861036: I tensorflow/core/common_runtime/bfc_allocator.cc:628] Bin (268435456): \tTotal Chunks: 5, Chunks in use: 5. 1.30GiB allocated for chunks. 1.30GiB in use in bin. 1.25GiB client-requested in use in bin.\r\n2018-02-25 16:31:27.861053: I tensorflow/core/common_runtime/bfc_allocator.cc:644] Bin for 256.00MiB was 256.00MiB, Chunk State: \r\n2018-02-25 16:31:27.861068: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702680000 of size 1280\r\n2018-02-25 16:31:27.861082: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702680500 of size 256\r\n2018-02-25 16:31:27.861096: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702680600 of size 256\r\n2018-02-25 16:31:27.861110: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702680700 of size 1046784\r\n2018-02-25 16:31:27.861125: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702780000 of size 2048\r\n2018-02-25 16:31:27.861139: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702780800 of size 2048\r\n2018-02-25 16:31:27.861153: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702781000 of size 2048\r\n2018-02-25 16:31:27.861167: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702781800 of size 2048\r\n2018-02-25 16:31:27.861181: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702782000 of size 256\r\n2018-02-25 16:31:27.861194: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702782100 of size 256\r\n2018-02-25 16:31:27.861208: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702782200 of size 1024\r\n2018-02-25 16:31:27.861222: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702782600 of size 1024\r\n2018-02-25 16:31:27.861235: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702782a00 of size 1024\r\n2018-02-25 16:31:27.861248: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702782e00 of size 1024\r\n2018-02-25 16:31:27.861261: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702783200 of size 1024\r\n2018-02-25 16:31:27.861274: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702783600 of size 256\r\n2018-02-25 16:31:27.861288: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702783700 of size 256\r\n2018-02-25 16:31:27.861302: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702783800 of size 512\r\n2018-02-25 16:31:27.861316: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702783a00 of size 512\r\n2018-02-25 16:31:27.861329: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702783c00 of size 512\r\n2018-02-25 16:31:27.861342: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702783e00 of size 512\r\n2018-02-25 16:31:27.861356: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702784000 of size 512\r\n2018-02-25 16:31:27.861369: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702784200 of size 256\r\n2018-02-25 16:31:27.861382: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702784300 of size 256\r\n2018-02-25 16:31:27.861396: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702784400 of size 256\r\n2018-02-25 16:31:27.861410: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702784500 of size 256\r\n2018-02-25 16:31:27.861424: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702784600 of size 256\r\n2018-02-25 16:31:27.861437: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702784700 of size 256\r\n2018-02-25 16:31:27.861450: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702784800 of size 256\r\n2018-02-25 16:31:27.861463: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702784900 of size 256\r\n2018-02-25 16:31:27.861476: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702784a00 of size 256\r\n2018-02-25 16:31:27.861487: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702784b00 of size 256\r\n2018-02-25 16:31:27.861497: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702784c00 of size 256\r\n2018-02-25 16:31:27.861509: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702784d00 of size 256\r\n2018-02-25 16:31:27.861523: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702784e00 of size 256\r\n2018-02-25 16:31:27.861536: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702784f00 of size 256\r\n2018-02-25 16:31:27.861549: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702785000 of size 256\r\n2018-02-25 16:31:27.861563: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702785100 of size 512\r\n2018-02-25 16:31:27.861576: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702785300 of size 512\r\n2018-02-25 16:31:27.861589: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702785500 of size 512\r\n2018-02-25 16:31:27.861603: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702785700 of size 512\r\n2018-02-25 16:31:27.861616: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702785900 of size 512\r\n2018-02-25 16:31:27.861630: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702785b00 of size 256\r\n2018-02-25 16:31:27.861644: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702785c00 of size 256\r\n2018-02-25 16:31:27.861657: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702785d00 of size 1024\r\n2018-02-25 16:31:27.861674: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702786100 of size 1024\r\n2018-02-25 16:31:27.861688: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702786500 of size 1024\r\n2018-02-25 16:31:27.861702: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702786900 of size 1024\r\n2018-02-25 16:31:27.861715: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702786d00 of size 1024\r\n2018-02-25 16:31:27.861728: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702787100 of size 256\r\n2018-02-25 16:31:27.861742: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702787200 of size 256\r\n2018-02-25 16:31:27.861756: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702787300 of size 2048\r\n2018-02-25 16:31:27.861769: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702787b00 of size 2048\r\n2018-02-25 16:31:27.861782: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702788300 of size 2048\r\n2018-02-25 16:31:27.861798: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702788b00 of size 2048\r\n2018-02-25 16:31:27.861811: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702789300 of size 2048\r\n2018-02-25 16:31:27.861824: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702789b00 of size 256\r\n2018-02-25 16:31:27.861838: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702789c00 of size 256\r\n2018-02-25 16:31:27.861851: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702789d00 of size 256\r\n2018-02-25 16:31:27.861864: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702789e00 of size 256\r\n2018-02-25 16:31:27.861878: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702789f00 of size 256\r\n2018-02-25 16:31:27.861891: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x70278a000 of size 19200\r\n2018-02-25 16:31:27.861905: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x70278eb00 of size 819200\r\n2018-02-25 16:31:27.861919: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702856b00 of size 19200\r\n2018-02-25 16:31:27.861933: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x70285b600 of size 512\r\n2018-02-25 16:31:27.861947: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x70285b800 of size 512\r\n2018-02-25 16:31:27.861960: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x70285ba00 of size 1024\r\n2018-02-25 16:31:27.861974: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x70285be00 of size 1196544\r\n2018-02-25 16:31:27.861989: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702980000 of size 4194304\r\n2018-02-25 16:31:27.862003: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x702d80000 of size 16777216\r\n2018-02-25 16:31:27.862017: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x703d80000 of size 2048\r\n2018-02-25 16:31:27.862032: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x703d80800 of size 524288\r\n2018-02-25 16:31:27.862045: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x703e00800 of size 256\r\n2018-02-25 16:31:27.862059: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x703e00900 of size 256\r\n2018-02-25 16:31:27.862073: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x703e00a00 of size 2048\r\n2018-02-25 16:31:27.862087: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x703e01200 of size 16248320\r\n2018-02-25 16:31:27.862101: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x704d80000 of size 67108864\r\n2018-02-25 16:31:27.862115: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x708d80000 of size 256\r\n2018-02-25 16:31:27.862129: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x708d80100 of size 1024\r\n2018-02-25 16:31:27.862143: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x708d80500 of size 3276800\r\n2018-02-25 16:31:27.862156: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7090a0500 of size 819200\r\n2018-02-25 16:31:27.862169: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x709168500 of size 819200\r\n2018-02-25 16:31:27.862183: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x709230500 of size 512\r\n2018-02-25 16:31:27.862197: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x709230700 of size 512\r\n2018-02-25 16:31:27.862210: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x709230900 of size 3276800\r\n2018-02-25 16:31:27.862224: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x709550900 of size 3276800\r\n2018-02-25 16:31:27.862238: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x709870900 of size 512\r\n2018-02-25 16:31:27.862251: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x709870b00 of size 512\r\n2018-02-25 16:31:27.862265: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x709870d00 of size 19200\r\n2018-02-25 16:31:27.862278: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x709875800 of size 1024\r\n2018-02-25 16:31:27.862292: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x709875c00 of size 1024\r\n2018-02-25 16:31:27.862305: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x709876000 of size 13107200\r\n2018-02-25 16:31:27.862319: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x70a4f6000 of size 13107200\r\n2018-02-25 16:31:27.862332: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x70b176000 of size 819200\r\n2018-02-25 16:31:27.862345: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x70b23e000 of size 819200\r\n2018-02-25 16:31:27.862358: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x70b306000 of size 2048\r\n2018-02-25 16:31:27.862372: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x70b306800 of size 2048\r\n2018-02-25 16:31:27.862385: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x70b307000 of size 524288\r\n2018-02-25 16:31:27.862399: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x70b387000 of size 524288\r\n2018-02-25 16:31:27.862407: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x70b407000 of size 256\r\n2018-02-25 16:31:27.862420: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x70b407100 of size 256\r\n2018-02-25 16:31:27.862434: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x70b407200 of size 2048\r\n2018-02-25 16:31:27.862444: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x70b407a00 of size 2048\r\n2018-02-25 16:31:27.862457: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x70b408200 of size 13107200\r\n2018-02-25 16:31:27.862472: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x70c088200 of size 13598208\r\n2018-02-25 16:31:27.862486: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x70cd80000 of size 52428800\r\n2018-02-25 16:31:27.862497: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x70ff80000 of size 81788928\r\n2018-02-25 16:31:27.862510: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x714d80000 of size 256\r\n2018-02-25 16:31:27.862524: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x714d80100 of size 1024\r\n2018-02-25 16:31:27.862537: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x714d80500 of size 1024\r\n2018-02-25 16:31:27.862548: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x714d80900 of size 256\r\n2018-02-25 16:31:27.862560: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x714d80a00 of size 3276800\r\n2018-02-25 16:31:27.862574: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7150a0a00 of size 3276800\r\n2018-02-25 16:31:27.862584: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7153c0a00 of size 13107200\r\n2018-02-25 16:31:27.862593: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x716040a00 of size 13107200\r\n2018-02-25 16:31:27.862603: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7185c0a00 of size 524288\r\n2018-02-25 16:31:27.862612: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x718640a00 of size 524288\r\n2018-02-25 16:31:27.862625: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7186c0a00 of size 524288\r\n2018-02-25 16:31:27.862638: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x718740a00 of size 2048\r\n2018-02-25 16:31:27.862649: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x718741200 of size 2048\r\n2018-02-25 16:31:27.862658: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x718741a00 of size 2048\r\n2018-02-25 16:31:27.862667: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x718742200 of size 2048\r\n2018-02-25 16:31:27.862676: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x718742a00 of size 2048\r\n2018-02-25 16:31:27.862685: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x718743200 of size 2048\r\n2018-02-25 16:31:27.862697: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x718743a00 of size 3276800\r\n2018-02-25 16:31:27.862707: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x718a63a00 of size 3276800\r\n2018-02-25 16:31:27.862724: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7193c3a00 of size 1024\r\n2018-02-25 16:31:27.862738: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7193c3e00 of size 1024\r\n2018-02-25 16:31:27.862748: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7193c4200 of size 1024\r\n2018-02-25 16:31:27.862757: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7193c4600 of size 1024\r\n2018-02-25 16:31:27.862767: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7193c4a00 of size 1024\r\n2018-02-25 16:31:27.862776: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7193c4e00 of size 1024\r\n2018-02-25 16:31:27.862786: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7193c5200 of size 1024\r\n2018-02-25 16:31:27.862793: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7193c5600 of size 1024\r\n2018-02-25 16:31:27.862806: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7193c5a00 of size 1024\r\n2018-02-25 16:31:27.862820: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7193c5e00 of size 819200\r\n2018-02-25 16:31:27.862829: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x71948de00 of size 819200\r\n2018-02-25 16:31:27.862842: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7196e5e00 of size 512\r\n2018-02-25 16:31:27.862858: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7196e6000 of size 512\r\n2018-02-25 16:31:27.862868: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7196e6200 of size 512\r\n2018-02-25 16:31:27.862878: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7196e6400 of size 512\r\n2018-02-25 16:31:27.862887: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7196e6600 of size 512\r\n2018-02-25 16:31:27.862897: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7196e6800 of size 512\r\n2018-02-25 16:31:27.862906: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7196e6a00 of size 512\r\n2018-02-25 16:31:27.862915: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7196e6c00 of size 512\r\n2018-02-25 16:31:27.862925: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7196e6e00 of size 512\r\n2018-02-25 16:31:27.862934: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7196e7000 of size 19200\r\n2018-02-25 16:31:27.862944: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7196ebb00 of size 800000\r\n2018-02-25 16:31:27.862957: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197af000 of size 256\r\n2018-02-25 16:31:27.862967: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197af100 of size 256\r\n2018-02-25 16:31:27.862981: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197af200 of size 256\r\n2018-02-25 16:31:27.862990: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197af300 of size 256\r\n2018-02-25 16:31:27.863004: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197af400 of size 256\r\n2018-02-25 16:31:27.863026: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197af500 of size 256\r\n2018-02-25 16:31:27.863051: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197af600 of size 256\r\n2018-02-25 16:31:27.863088: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197af700 of size 256\r\n2018-02-25 16:31:27.863099: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197af800 of size 256\r\n2018-02-25 16:31:27.863112: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197af900 of size 19200\r\n2018-02-25 16:31:27.863126: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b4400 of size 256\r\n2018-02-25 16:31:27.863136: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b4500 of size 256\r\n2018-02-25 16:31:27.863146: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b4600 of size 256\r\n2018-02-25 16:31:27.863156: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b4700 of size 256\r\n2018-02-25 16:31:27.863165: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b4800 of size 256\r\n2018-02-25 16:31:27.863178: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b4900 of size 256\r\n2018-02-25 16:31:27.863196: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b4a00 of size 256\r\n2018-02-25 16:31:27.863222: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b4b00 of size 256\r\n2018-02-25 16:31:27.863240: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b4c00 of size 256\r\n2018-02-25 16:31:27.863254: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b4d00 of size 256\r\n2018-02-25 16:31:27.863268: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b4e00 of size 256\r\n2018-02-25 16:31:27.863278: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b4f00 of size 256\r\n2018-02-25 16:31:27.863287: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b5000 of size 256\r\n2018-02-25 16:31:27.863295: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b5100 of size 256\r\n2018-02-25 16:31:27.863305: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b5200 of size 256\r\n2018-02-25 16:31:27.863318: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b5300 of size 256\r\n2018-02-25 16:31:27.863333: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b5400 of size 256\r\n2018-02-25 16:31:27.863346: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b5500 of size 256\r\n2018-02-25 16:31:27.863356: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b5600 of size 256\r\n2018-02-25 16:31:27.863368: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b5700 of size 256\r\n2018-02-25 16:31:27.863381: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b5800 of size 256\r\n2018-02-25 16:31:27.863394: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b5900 of size 256\r\n2018-02-25 16:31:27.863408: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b5a00 of size 256\r\n2018-02-25 16:31:27.863421: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b5b00 of size 256\r\n2018-02-25 16:31:27.863431: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b5c00 of size 256\r\n2018-02-25 16:31:27.863441: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b5d00 of size 256\r\n2018-02-25 16:31:27.863450: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b5e00 of size 256\r\n2018-02-25 16:31:27.863459: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b5f00 of size 256\r\n2018-02-25 16:31:27.863472: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b6000 of size 512\r\n2018-02-25 16:31:27.863485: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b6200 of size 256\r\n2018-02-25 16:31:27.863495: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b6300 of size 256\r\n2018-02-25 16:31:27.863505: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b6400 of size 512\r\n2018-02-25 16:31:27.863514: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b6600 of size 512\r\n2018-02-25 16:31:27.863523: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b6800 of size 512\r\n2018-02-25 16:31:27.863536: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b6a00 of size 512\r\n2018-02-25 16:31:27.863544: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b6c00 of size 512\r\n2018-02-25 16:31:27.863554: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b6e00 of size 512\r\n2018-02-25 16:31:27.863564: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b9200 of size 256\r\n2018-02-25 16:31:27.863573: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7197b9300 of size 819200\r\n2018-02-25 16:31:27.863586: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x719881300 of size 512\r\n2018-02-25 16:31:27.863599: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x719881500 of size 512\r\n2018-02-25 16:31:27.863610: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x719881700 of size 512\r\n2018-02-25 16:31:27.863619: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x719881900 of size 512\r\n2018-02-25 16:31:27.863632: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x719881b00 of size 512\r\n2018-02-25 16:31:27.863646: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x719881d00 of size 512\r\n2018-02-25 16:31:27.863660: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x719881f00 of size 512\r\n2018-02-25 16:31:27.863670: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x719882100 of size 512\r\n2018-02-25 16:31:27.863682: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x719882300 of size 512\r\n2018-02-25 16:31:27.863696: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x719ba2500 of size 1024\r\n2018-02-25 16:31:27.863706: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x719ba2900 of size 1024\r\n2018-02-25 16:31:27.863715: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x719ba2d00 of size 1024\r\n2018-02-25 16:31:27.863724: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x719ba3100 of size 1024\r\n2018-02-25 16:31:27.863734: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x719ba3500 of size 1024\r\n2018-02-25 16:31:27.863747: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x719ba3900 of size 1024\r\n2018-02-25 16:31:27.863761: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x719ba3d00 of size 1024\r\n2018-02-25 16:31:27.863778: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x719ba4100 of size 1024\r\n2018-02-25 16:31:27.863792: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x719ba4500 of size 1024\r\n2018-02-25 16:31:27.863802: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x71a824900 of size 2048\r\n2018-02-25 16:31:27.863811: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x71a825100 of size 2048\r\n2018-02-25 16:31:27.863821: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x71a825900 of size 2048\r\n2018-02-25 16:31:27.863830: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x71a826100 of size 2048\r\n2018-02-25 16:31:27.863843: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x71a826900 of size 2048\r\n2018-02-25 16:31:27.863856: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x71a827100 of size 2048\r\n2018-02-25 16:31:27.863866: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x71a827900 of size 2048\r\n2018-02-25 16:31:27.863876: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x71a828100 of size 2048\r\n2018-02-25 16:31:27.863889: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x71a828900 of size 2048\r\n2018-02-25 16:31:27.863904: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x71a8a9100 of size 256\r\n2018-02-25 16:31:27.863914: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x71a8a9200 of size 256\r\n2018-02-25 16:31:27.863927: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x71a8a9300 of size 256\r\n2018-02-25 16:31:27.863940: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x71a8a9400 of size 256\r\n2018-02-25 16:31:27.863949: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x71a8a9500 of size 256\r\n2018-02-25 16:31:27.863959: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x71a8a9600 of size 19200\r\n2018-02-25 16:31:27.863972: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x71a8ae100 of size 19200\r\n2018-02-25 16:31:27.863985: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x71a8b2c00 of size 19200\r\n2018-02-25 16:31:27.863999: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x71a8b7700 of size 256\r\n2018-02-25 16:31:27.864008: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x71a8b7800 of size 256\r\n2018-02-25 16:31:27.864022: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x71a8b7900 of size 52428800\r\n2018-02-25 16:31:27.864036: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x71dab7900 of size 120358656\r\n2018-02-25 16:31:27.864050: I tensorflow/core/common_runtime/bfc_allocator.cc:671] Free at 0x716cc0a00 of size 26214400\r\n2018-02-25 16:31:27.864063: I tensorflow/core/common_runtime/bfc_allocator.cc:671] Free at 0x718d83a00 of size 6553600\r\n2018-02-25 16:31:27.864077: I tensorflow/core/common_runtime/bfc_allocator.cc:671] Free at 0x719555e00 of size 1638400\r\n2018-02-25 16:31:27.864087: I tensorflow/core/common_runtime/bfc_allocator.cc:671] Free at 0x7197b7000 of size 8704\r\n2018-02-25 16:31:27.864097: I tensorflow/core/common_runtime/bfc_allocator.cc:671] Free at 0x719882500 of size 3276800\r\n2018-02-25 16:31:27.864106: I tensorflow/core/common_runtime/bfc_allocator.cc:671] Free at 0x719ba4900 of size 13107200\r\n2018-02-25 16:31:27.864115: I tensorflow/core/common_runtime/bfc_allocator.cc:671] Free at 0x71a829100 of size 524288\r\n2018-02-25 16:31:27.864129: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x724d80000 of size 268435456\r\n2018-02-25 16:31:27.864140: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x734d80000 of size 134217728\r\n2018-02-25 16:31:27.864153: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x73cd80000 of size 33554432\r\n2018-02-25 16:31:27.864168: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x73ed80000 of size 50331648\r\n2018-02-25 16:31:27.864179: I tensorflow/core/common_runtime/bfc_allocator.cc:671] Free at 0x741d80000 of size 50331648\r\n2018-02-25 16:31:27.864192: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x744f80000 of size 268435456\r\n2018-02-25 16:31:27.864205: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x759fe0300 of size 134217728\r\n2018-02-25 16:31:27.864219: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x765fe0300 of size 67108864\r\n2018-02-25 16:31:27.864229: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x769fe0300 of size 67108864\r\n2018-02-25 16:31:27.864242: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x771fe0300 of size 318373120\r\n2018-02-25 16:31:27.864256: I tensorflow/core/common_runtime/bfc_allocator.cc:671] Free at 0x754f80000 of size 84280064\r\n2018-02-25 16:31:27.864266: I tensorflow/core/common_runtime/bfc_allocator.cc:671] Free at 0x761fe0300 of size 67108864\r\n2018-02-25 16:31:27.864276: I tensorflow/core/common_runtime/bfc_allocator.cc:671] Free at 0x76dfe0300 of size 67108864\r\n2018-02-25 16:31:27.864289: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x785280000 of size 272646144\r\n2018-02-25 16:31:27.864303: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x795684000 of size 134217728\r\n2018-02-25 16:31:27.864317: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x79d684000 of size 189252352\r\n2018-02-25 16:31:27.864327: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7a8b00300 of size 67108864\r\n2018-02-25 16:31:27.864340: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7acb00300 of size 268435456\r\n2018-02-25 16:31:27.864354: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7bcb00300 of size 260734976\r\n2018-02-25 16:31:27.864364: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7cc3a8300 of size 134217728\r\n2018-02-25 16:31:27.864374: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7d43a8300 of size 134217728\r\n2018-02-25 16:31:27.864387: I tensorflow/core/common_runtime/bfc_allocator.cc:662] Chunk at 0x7dc3a8300 of size 182811904\r\n2018-02-25 16:31:27.864401: I tensorflow/core/common_runtime/bfc_allocator.cc:677]      Summary of in-use Chunks by size: \r\n2018-02-25 16:31:27.864418: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 84 Chunks of size 256 totalling 21.0KiB\r\n2018-02-25 16:31:27.864434: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 41 Chunks of size 512 totalling 20.5KiB\r\n2018-02-25 16:31:27.864450: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 34 Chunks of size 1024 totalling 34.0KiB\r\n2018-02-25 16:31:27.864465: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 1 Chunks of size 1280 totalling 1.2KiB\r\n2018-02-25 16:31:27.864477: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 30 Chunks of size 2048 totalling 60.0KiB\r\n2018-02-25 16:31:27.864492: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 8 Chunks of size 19200 totalling 150.0KiB\r\n2018-02-25 16:31:27.864507: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 6 Chunks of size 524288 totalling 3.00MiB\r\n2018-02-25 16:31:27.864523: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 1 Chunks of size 800000 totalling 781.2KiB\r\n2018-02-25 16:31:27.864538: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 8 Chunks of size 819200 totalling 6.25MiB\r\n2018-02-25 16:31:27.864553: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 1 Chunks of size 1046784 totalling 1022.2KiB\r\n2018-02-25 16:31:27.864568: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 1 Chunks of size 1196544 totalling 1.14MiB\r\n2018-02-25 16:31:27.864583: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 7 Chunks of size 3276800 totalling 21.88MiB\r\n2018-02-25 16:31:27.864598: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 1 Chunks of size 4194304 totalling 4.00MiB\r\n2018-02-25 16:31:27.864609: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 5 Chunks of size 13107200 totalling 62.50MiB\r\n2018-02-25 16:31:27.864623: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 1 Chunks of size 13598208 totalling 12.97MiB\r\n2018-02-25 16:31:27.864639: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 1 Chunks of size 16248320 totalling 15.50MiB\r\n2018-02-25 16:31:27.864654: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 1 Chunks of size 16777216 totalling 16.00MiB\r\n2018-02-25 16:31:27.864669: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 1 Chunks of size 33554432 totalling 32.00MiB\r\n2018-02-25 16:31:27.864684: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 1 Chunks of size 50331648 totalling 48.00MiB\r\n2018-02-25 16:31:27.864695: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 2 Chunks of size 52428800 totalling 100.00MiB\r\n2018-02-25 16:31:27.864706: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 4 Chunks of size 67108864 totalling 256.00MiB\r\n2018-02-25 16:31:27.864721: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 1 Chunks of size 81788928 totalling 78.00MiB\r\n2018-02-25 16:31:27.864736: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 1 Chunks of size 120358656 totalling 114.78MiB\r\n2018-02-25 16:31:27.864751: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 5 Chunks of size 134217728 totalling 640.00MiB\r\n2018-02-25 16:31:27.864766: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 1 Chunks of size 182811904 totalling 174.34MiB\r\n2018-02-25 16:31:27.864778: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 1 Chunks of size 189252352 totalling 180.48MiB\r\n2018-02-25 16:31:27.864794: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 1 Chunks of size 260734976 totalling 248.66MiB\r\n2018-02-25 16:31:27.864810: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 3 Chunks of size 268435456 totalling 768.00MiB\r\n2018-02-25 16:31:27.864825: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 1 Chunks of size 272646144 totalling 260.02MiB\r\n2018-02-25 16:31:27.864840: I tensorflow/core/common_runtime/bfc_allocator.cc:680] 1 Chunks of size 318373120 totalling 303.62MiB\r\n2018-02-25 16:31:27.864851: I tensorflow/core/common_runtime/bfc_allocator.cc:684] Sum Total of in-use chunks: 3.27GiB\r\n2018-02-25 16:31:27.864868: I tensorflow/core/common_runtime/bfc_allocator.cc:686] Stats: \r\nLimit:                  3832020992\r\nInUse:                  3511868160\r\nMaxInUse:               3571212544\r\nNumAllocs:                     528\r\nMaxAllocSize:            419430400\r\n\r\n2018-02-25 16:31:27.864895: W tensorflow/core/common_runtime/bfc_allocator.cc:277] **************x*************_********_****_*************x****************************xxx***********x\r\n2018-02-25 16:31:27.864926: W tensorflow/core/framework/op_kernel.cc:1198] Resource exhausted: OOM when allocating tensor with shape[64,64,128,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\nTraceback (most recent call last):\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1350, in _do_call\r\n    return fn(*args)\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1329, in _run_fn\r\n    status, run_metadata)\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\", line 473, in __exit__\r\n    c_api.TF_GetCode(self.status.status))\r\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[64,64,128,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n\t [[Node: gradients/discriminator_1/d_h1_conv/Conv2D_grad/Conv2DBackpropInput = Conv2DBackpropInput[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](gradients/discriminator/Maximum_grad/Shape, discriminator/d_h1_conv/w/read, gradients/discriminator_1/d_h1_conv/BiasAdd_grad/tuple/control_dependency)]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"main.py\", line 100, in <module>\r\n    tf.app.run()\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 124, in run\r\n    _sys.exit(main(argv))\r\n  File \"main.py\", line 83, in main\r\n    dcgan.train(FLAGS)\r\n  File \"/home/ubuntu/DCGAN-tensorflow/model.py\", line 258, in train\r\n    feed_dict={ self.inputs: batch_images, self.z: batch_z })\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 895, in run\r\n    run_metadata_ptr)\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1128, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1344, in _do_run\r\n    options, run_metadata)\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1363, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[64,64,128,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n\t [[Node: gradients/discriminator_1/d_h1_conv/Conv2D_grad/Conv2DBackpropInput = Conv2DBackpropInput[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](gradients/discriminator/Maximum_grad/Shape, discriminator/d_h1_conv/w/read, gradients/discriminator_1/d_h1_conv/BiasAdd_grad/tuple/control_dependency)]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n\r\nCaused by op 'gradients/discriminator_1/d_h1_conv/Conv2D_grad/Conv2DBackpropInput', defined at:\r\n  File \"main.py\", line 100, in <module>\r\n    tf.app.run()\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 124, in run\r\n    _sys.exit(main(argv))\r\n  File \"main.py\", line 83, in main\r\n    dcgan.train(FLAGS)\r\n  File \"/home/ubuntu/DCGAN-tensorflow/model.py\", line 147, in train\r\n    .minimize(self.d_loss, var_list=self.d_vars)\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 355, in minimize\r\n    grad_loss=grad_loss)\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 456, in compute_gradients\r\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\", line 609, in gradients\r\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\", line 375, in _MaybeCompile\r\n    return grad_fn()  # Exit early\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\", line 609, in <lambda>\r\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/nn_grad.py\", line 499, in _Conv2DGrad\r\n    data_format=data_format),\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 817, in conv2d_backprop_input\r\n    dilations=dilations, name=name)\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3160, in create_op\r\n    op_def=op_def)\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1625, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\n...which was originally created as op 'discriminator_1/d_h1_conv/Conv2D', defined at:\r\n  File \"main.py\", line 100, in <module>\r\n    tf.app.run()\r\n[elided 0 identical lines from previous traceback]\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 124, in run\r\n    _sys.exit(main(argv))\r\n  File \"main.py\", line 78, in main\r\n    sample_dir=FLAGS.sample_dir)\r\n  File \"/home/ubuntu/DCGAN-tensorflow/model.py\", line 86, in __init__\r\n    self.build_model()\r\n  File \"/home/ubuntu/DCGAN-tensorflow/model.py\", line 111, in build_model\r\n    self.D_, self.D_logits_ = self.discriminator(self.G, self.y, reuse=True)\r\n  File \"/home/ubuntu/DCGAN-tensorflow/model.py\", line 318, in discriminator\r\n    h1 = lrelu(self.d_bn1(conv2d(h0, self.df_dim*2, name='d_h1_conv')))\r\n  File \"/home/ubuntu/DCGAN-tensorflow/ops.py\", line 58, in conv2d\r\n    conv = tf.nn.conv2d(input_, w, strides=[1, d_h, d_w, 1], padding='SAME')\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 639, in conv2d\r\n    data_format=data_format, dilations=dilations, name=name)\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3160, in create_op\r\n    op_def=op_def)\r\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1625, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[64,64,128,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n\t [[Node: gradients/discriminator_1/d_h1_conv/Conv2D_grad/Conv2DBackpropInput = Conv2DBackpropInput[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](gradients/discriminator/Maximum_grad/Shape, discriminator/d_h1_conv/w/read, gradients/discriminator_1/d_h1_conv/BiasAdd_grad/tuple/control_dependency)]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n```\r\n", "comments": ["Your machine doesn't have enough GPU memory to run this neural network"]}, {"number": 17259, "title": "after restore trained model checkpoint, the prefetch capacity become 500 which is 5 during training", "body": "when I restore my trained model and do predict it out of memory problem, how can I restore the original capacity? or how can I reset the capacity after restore?\r\nI am using python-gpu 1.5\r\nbelow is the operation information:\r\nwhen training:\r\nname: \"prefetch_queue\"\r\nop: \"PaddingFIFOQueueV2\"\r\ndevice: \"/device:CPU:0\"\r\nattr {\r\n  key: \"capacity\"\r\n  value {\r\n    i: 5\r\n  }\r\n}\r\n\r\nafter restore:\r\nname: \"prefetch_queue\"\r\nop: \"PaddingFIFOQueueV2\"\r\nattr {\r\n  key: \"capacity\"\r\n  value {\r\n    i: 500\r\n  }\r\n}\r\n", "comments": ["My fault. I just found the prefetch queue is created when restore the model and the capacity is hardcoded.\r\nThanks."]}, {"number": 17258, "title": "Fix typo", "body": "fix typo", "comments": []}, {"number": 17257, "title": "Saver: Don't fail on restoring variables not present in a checkpoint.", "body": "This is a feature request.\r\n\r\nLet's consider a scenario where one trains multiple models and uses them in combination (like it is done in GANs).\r\n\r\nTo simplify the process of saving and restoring variables that are partly shared across the models (Pretraining Model, Training Model, Evaluation Model, Infer Model) one could instantiate the whole graph, containing all operations and variables, and save it.\r\n\r\nThen in order to do pre-training only the subset of graph elements that is required for pretraining is used.\r\n\r\nThis results in the overhead of having to build the whole model (which might consist of multiple sub models) the first time the model is run even though only a smaller part (e.g. Pretraining Model) is required.\r\n\r\nAnother issue arises when using different optimizers in different training stages (e.g. SGD first then Adam). As Adam creates additional variables Adam has to be instantiated during the first training stage so restoring from a checkpoint does not fail when restoring with Adam instead of SGD.\r\n\r\nThis restriction of having to build everything despite parts not being required results in more complicated code. If it would be possible to silently fail when a variable is not found in a checkpoint, so it can be initialized with `tf.global_variables_initializer()` instead, would allow better structuring of code.\r\n\r\nI have looked through all current issues regarding this problem and I have found a couple that face a similar problem and where a `QuietlyFailRestoringSaver` could solve this problem:\r\nhttps://github.com/tensorflow/tensorflow/issues/12032\r\nhttps://github.com/tensorflow/tensorflow/issues/16781\r\n\r\nI might consider building this if there is enough support for it. I am open for feedback.", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Yes it is", "@allenlavoie Do you have any thoughts on this?", "Interesting. It's not exactly a drop-in replacement for `tf.train.Saver`, but we've been developing an object-based save/restore API in part for compatibility with eager execution, [tfe.Checkpoint](https://www.tensorflow.org/api_docs/python/tf/contrib/eager/Checkpoint).\r\n\r\nIt more or less accidentally has the lazy error checking you're interested in. When executing eagerly the `restore` request may come before some variables have been created, so it won't complain unless you manually run one of its assertions (`restore` returns a status object).\r\n\r\nThe caveat is that it doesn't use global variable names like `tf.train.Saver`, and requires that the objects you use come from [`Checkpointable`](https://www.tensorflow.org/api_docs/python/tf/contrib/eager/Checkpointable) classes. This is almost all of TensorFlow's objects at this point (`Layer`s, `Optimizer`s, `tf.keras.Model`, `make_template`, most RNN cells, etc.), but may require some refactoring to use. The [eager examples](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/eager/python/examples) have been converted; those run with eager execution enabled, but everything will work fine with graph building if you add a `checkpoint.restore(...).run_restore_ops()` call to run the restore ops in a `Session`.\r\n\r\nSo that's the direction I'd like checkpointing to be headed in. The APIs are not in core yet, but should get there in another release or two. Happy to take feature requests / bug reports. ", "Looks interesting. So how exactly would I transfer my code over to this new approach (I do not use any high-level APIs). I currently don't see the locality of variables to be a disadvantage. I am going to use multiple savers in my GAN anyways to swap out different trained generator and discriminator stages.", "Inheriting from `tf.keras.Model` is a nice way to manage `Layer`s ([example](https://github.com/tensorflow/tensorflow/blob/5d33c1e49178aedbb459da7ce58eca710102c06b/tensorflow/contrib/eager/python/examples/gan/mnist.py#L95)) and you get Checkpointability for free. But if you want something lower level, you can inherit from `tfe.Checkpointable` directly. In either case the `__setattr__` override takes your attribute names and builds up a graph of objects with named edges; the trick is just making sure there's a path from the object you're saving to your variables.", "So basically all objects that I attach to a `tf.keras.Model`  with `self.x` that implement `tfe.Checkpointable` will be saved/restored when building a `tfe.Checkpoint(model)`?\r\nWhen a custom object implements `tfe.Checkpointable` all variables that I assign to it and all `tfe.Checkpointable`s will be recursively saved?\r\n\r\nI'll have to test out `Checkpoint` when I get some more spare time.\r\nThanks for the input.\r\n\r\nDo you think this issue is still relevant with your introduction of `tfe.Checkpoint`? I cannot tell as I haven't used the new approach yet.", "That sounds right. I'll close this for now, but feel free to comment or open something else if object-based checkpointing is missing something you need (or if you decide it's awful and want the original name-based request open again :).", "@allenlavoie What happens internally when I assign the same variable multiple times to `self`? E.g.:\r\n```\r\n({'model/embedding/.ATTRIBUTES/VARIABLE_VALUE': <tf.Variable 'embedding:0' shape=(1, 1) dtype=float32_ref>}, nodes {\r\n  children {\r\n    node_id: 1\r\n    local_name: \"model\"\r\n  }\r\n}\r\nnodes {\r\n  children {\r\n    node_id: 2\r\n    local_name: \"embedding\"\r\n  }\r\n  children {\r\n    node_id: 2\r\n    local_name: \"test\"\r\n  }\r\n}\r\nnodes {\r\n  attributes {\r\n    name: \"VARIABLE_VALUE\"\r\n    full_name: \"embedding\"\r\n    checkpoint_key: \"model/embedding/.ATTRIBUTES/VARIABLE_VALUE\"\r\n  }\r\n}\r\n)\r\n```\r\nOutput of `checkpointable_utils._serialize_object_graph`.", "It should just overwrite the dependency. I've considered making that a warning (or queuing up the warning for save/restore time?). A restore() after the second assignment should restore the second object, but otherwise it will (only) restore the first: self.test = foo, restore(), self.test = bar will only restore foo.\r\n\r\nIs that not what's happening?", "Thank you for your reply. My question wasn't about assigning two different objects to the same `self.<key>` but rather assign the same variable multiple times to self with different keys. I was confused if that would somehow duplicate the variable or would cause multiple restores for the same variable.\r\nI found the internal documentation for `_track_checkpointable`. That already explains the assignment part but I am still unsure if I would cause multiple restores for the same variable.", "Is it correct, that restoring works based on the `self.<key>` and not based on the global variable name?\r\n+ Is there a way to get all variables assigned to a `Checkpointable`?", "Oh, yes, multiple dependencies on the same object are fine/expected. It will only restore once.\r\n\r\nRestoring does work on dependency names rather than global variable names. If you want to inspect dependencies manually, I'd use [dot_graph_from_checkpoint](https://github.com/tensorflow/tensorflow/blob/c8731009708d4694fc553562a267d75064fc5ab4/tensorflow/contrib/checkpoint/python/visualize.py#L25). Or programatically you can inspect checkpoints with [tf.contrib.checkpoint.object_metadata](https://github.com/tensorflow/tensorflow/blob/c8731009708d4694fc553562a267d75064fc5ab4/tensorflow/python/training/checkpointable_utils.py#L162).\r\n\r\nI haven't added a tf.contrib.checkpoint API for listing variables yet. Do you have a use-case in mind?", "Currently I would only use it for debugging purposes.\r\nMaybe for visualization outside of tensorboard it would be useful as well, but I haven't spent much thought about it.", "@allenlavoie Is there a way to get all uninitialized variables for a Checkpoint or Checkpointable? All those that did not get initialized by a restore.\r\n\r\nThere seems to be a \"solution\" for global variables https://stackoverflow.com/questions/44268206/how-to-get-the-list-of-uninitialized-variables-from-tf-report-uninitialized-vari", "`initialize_or_restore()` on the status object returned by `restore()` will initialize anything that wasn't restored (assuming it's in the dependency graph). Does that work for you?\r\n\r\nExample usage: https://github.com/tensorflow/tensorflow/blob/2b42a0620f45cc40c3cc96552c565271bfed0c82/tensorflow/python/training/checkpointable_utils.py#L954\r\n\r\n`initialize_or_restore` documentation: https://github.com/tensorflow/tensorflow/blob/2b42a0620f45cc40c3cc96552c565271bfed0c82/tensorflow/python/training/checkpointable_utils.py#L531", "I cannot paste you my whole code right now but that does not seem to work for me when using Adam. It somehow does not restore the variables Adam creates for variables.\r\nI'll see if I can reproduce it in a smaller example.", "Small example:\r\n```python\r\nimport tensorflow as tf\r\nimport tensorflow.contrib.eager as tfe\r\nfrom tensorflow.python.training import checkpointable\r\nfrom tensorflow.contrib.eager.python import checkpointable_utils\r\n\r\n\r\nclass MyModel(checkpointable.Checkpointable):\r\n\r\n  def __init__(self):\r\n    self.optimizer = tf.train.GradientDescentOptimizer(0.1)\r\n    self.var = tf.get_variable('var', [])\r\n\r\n  def optimizer_to_adam(self):\r\n    self.optimizer = tf.train.AdamOptimizer()\r\n\r\n\r\ncheckpoint_path = 'modeldir/test/'\r\n\r\nwith tf.Graph().as_default():\r\n  model = MyModel()\r\n  checkpoint = tfe.Checkpoint(model=model)\r\n  train_op = model.optimizer.minimize(model.var * model.var)\r\n  print(checkpointable_utils._serialize_object_graph(checkpoint))\r\n  session = tf.Session()\r\n  session.run(tf.global_variables_initializer())\r\n  checkpoint.save(checkpoint_path, session)\r\n  session.run(train_op)\r\n  print('Finished Model with SGD')\r\n\r\nwith tf.Graph().as_default():\r\n  model = MyModel()\r\n  model.optimizer_to_adam()\r\n  latest = tf.train.latest_checkpoint(checkpoint_path)\r\n  train_op = model.optimizer.minimize(model.var * model.var)\r\n  checkpoint = tfe.Checkpoint(model=model)\r\n  print(checkpointable_utils._serialize_object_graph(checkpoint))\r\n  session = tf.Session()\r\n  checkpoint.restore(latest).initialize_or_restore(session)\r\n  session.run(train_op)\r\n  print('Finished Model with Adam')\r\n```\r\n\r\nI would expect that the second graph (`Finished Model with Adam`) works.\r\nBut it throws `Attempting to use uninitialized value beta2_power`.\r\nI expected the `.initialize_or_restore` to initialize the `Adam` variables but that does not happen.\r\n\r\nThey are printed by `print(checkpointable_utils._serialize_object_graph(checkpoint))` though.\r\n\r\nIf you think that's a bug I can open up a new issue to track it. I hope I am not using the API incorrectly.", "I think just a version issue? The initialization changes I mentioned are relatively recent. Your awesome repro snippet works for me with `v1.8.0-1386-g2dc7575123` (from `python3.5 -c \"import tensorflow as tf; print(tf.__git_version__)\"`).\r\n\r\nThe change is https://github.com/tensorflow/tensorflow/commit/eb31cf8a62739d4df4c84b8edeccbe756b70616d so anything built with that should work (theoretically any nightly, although some of those have been stretching \"nightly\").", "Good to know :)\r\nSadly there are no windows nightly builds right now, for whatever reason, so I'll have to wait until they get fixed.", "@allenlavoie Do Checkpoints only support lower case names?\r\nWhen I do `tfe.Checkpoint(**{'TEST': MyModel()})` it silently consumes it but it is not attached to the checkpoint afterwards.", "I know of at least one user of mixed-case names.\r\n\r\nYour example works for me assuming I build/use `checkpoint.TEST`. Your `tfe.Checkpoint` line is adding a new `MyModel` instance; are you just using a different instance?", "So you do?\r\n```\r\nckpt = tfe.Checkpoint()\r\nckpt.TEST = MyModel()\r\n```", "Usually I'd do something like\r\nhttps://github.com/tensorflow/models/blob/0344c5503ee55e24f0de7f37336a6e08f10976fd/official/mnist/mnist_eager.py#L146\r\n\r\nor https://github.com/tensorflow/tensorflow/blob/d2297c8571ea485898851420de9f8368f0c869fd/tensorflow/contrib/eager/python/examples/gan/mnist.py#L275 for a dictionary example\r\n\r\nSo the model object gets constructed and used, and `tf.train.Checkpoint` just gets a reference to it. But to be clear, there's nothing wrong with `Checkpoint(**{'TEST': MyModel()})` as long as you use the instance of `MyModel` created on that line. In order to do that you'd need to do something like:\r\n\r\n```\r\ncheckpoint = tf.train.Checkpoint(**{'TEST': MyModel()})\r\noutput = checkpoint.TEST(tf.constant([[1.]]))\r\n```\r\n\r\nor \r\n\r\n```\r\ncheckpoint = tf.train.Checkpoint(**{'TEST': MyModel()})\r\nmodel = checkpoint.TEST\r\noutput = model(tf.constant([[1.]]))\r\n```", "Oh, maybe that got fixed in some commit. I was on an older 1.8 nightly", "@allenlavoie initialize_or_restore doesn't work for me, I am at v1.8.0-0-g93bc2e2072", "@dhingratul are you looking for the behavior in https://github.com/tensorflow/tensorflow/commit/eb31cf8a62739d4df4c84b8edeccbe756b70616d#diff-dbbfcd46840cb910643decf863dc00a6 ?\r\n\r\nLooks like that first appeared in 1.9. Could you try upgrading and see if the new behavior works for you?", "@dhingratul What exactly does not work? Doesn't it restore the variables or are they not initialized?", "I was at 1.8, so it doesn't recognize it. I will check with 1.9"]}, {"number": 17256, "title": "Download the training images", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**: \r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["![capture](https://user-images.githubusercontent.com/36357656/36640529-abc8a4c4-1a46-11e8-871a-cae6b3449d64.JPG)\r\nI am unable to download the images from the terminal ", "Have you tried running with the `-k` or `--insecure` option? More details [here](https://stackoverflow.com/a/20843514)", "maybe the internet is blocked.  you can download it by chrome via a proxy. and extract zip files to the right path.", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", " No sir.I was replied to my query.\nThank You\n    On Tuesday, 13 March, 2018, 8:56:57 PM IST, Alfred Sorten Wolf <notifications@github.com> wrote:  \n \n \nNagging Awaiting Response: It has been 14 days with no activityand the awaiting response label was assigned. Is this still an issue?\n\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n    "]}, {"number": 17255, "title": "tensorflow suddenly cannot detect my GPUs", "body": "I was working with tensorflow-gpu, and it worked properly before. But just now, suddenly my Tensorflow cannot run on GPU anymore and when I query my devices with `list_local_devices()`, it shows that I don't have any GPU! But my nvidia-smi properly displayed the info of my 2 GPUs. It's very weird since I did't do anything.", "comments": ["Maybe you can check your CUDA is already installed, and with the correct version?"]}, {"number": 17254, "title": "DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead 1.6rc0", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- Ubuntu 16.04\r\n- Tensorflow installed from source, latest HEAD from master (CPU)\r\n- 1.6rc0\r\n- Python 3.5.2\r\n- Bazel 0.10.1\r\n- gcc-5\r\n\r\n\r\n### Describe the problem\r\nWhen using tensorflow, I got hundred of DeprecationWarnings: This message exactly \r\n\r\n> /home/jerome/.local/lib/python3.5/site-packages/tensorflow/python/framework/tensor_util.py:560: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\r\n  return np.fromstring(tensor.tensor_content, dtype=dtype).reshape(shape)\r\n\r\nEDIT : fixed replacing line 560 in tensor_util.py by : \r\n\r\n`return np.frombuffer(tensor.tensor_content, dtype=dtype).reshape(shape)`\r\n\r\nThanks for any kind of help :)\r\n\r\n", "comments": ["```\r\nimport warnings\r\nwarnings.simplefilter(\"ignore\", DeprecationWarning)\r\n```\r\n\r\nI used this at the start of my code which suppresses the warning.", "I assume this is a duplicate issue of #17020, which was fixed already.", "Since the issue has been fixed in https://github.com/tensorflow/tensorflow/commit/f5c581f0f4649898ed00650fe98c7ef344e0f240. Let me close this one. Feel free to reopen if the issue persists. Thanks for the contribution!", "Which version of tensorflow should I to fix this?", "Follow the link by yongtang. There is says it is fixed since version v1.7.0-rc0.", "> ```\r\n> import warnings\r\n> warnings.simplefilter(\"ignore\", DeprecationWarning)\r\n> ```\r\n> \r\n> I used this at the start of my code which suppresses the warning.\r\n\r\nwhere to use this particularly\r\n", "> > ```\r\n> > import warnings\r\n> > warnings.simplefilter(\"ignore\", DeprecationWarning)\r\n> > ```\r\n> > \r\n> > \r\n> > I used this at the start of my code which suppresses the warning.\r\n> \r\n> where to use this particularly\r\n\r\nbefore all the imports in your script file."]}, {"number": 17253, "title": " Higher level C++ API feature request", "body": "Hi,\r\nI seems the C++ API only have frontend API to access tensorflow core, is there a plan to make higher level APIs, such as various algorithms and the estimator API, thanks.\r\n\r\nI am sorry if this is not the right place to post this.", "comments": ["Hi ,\r\n\r\nCan someone throw light on this ? \r\n\r\nAs most of the example code are written in Python, it is not possible to execute it directly on Android device.\r\n\r\n", "Nagging Assignee @tatatodd: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @tatatodd: It has been 15 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Assigning to @asimshankar for his thoughts.", "At this time, this is not something that the TensorFlow maintainers have the bandwidth to develop and support. In general, creating the graph in Python and then exporting it for execution in C++/other languages is what we recommend.\r\n\r\nIt is _possible_ to use this method to even train models in C++ (e.g., [this gist](https://gist.github.com/asimshankar/5c96acd1280507940bad9083370fe8dc)).\r\nThe C++ API is complete enough to build higher level constructs on. So, if there are community efforts to build those (like for other languages like [C#](https://github.com/migueldeicaza/TensorFlowSharp), [Haskell](https://github.com/tensorflow/haskell), [Julia](https://github.com/malmaud/TensorFlow.jl), [Ruby](https://github.com/somaticio/tensorflow.rb), [Rust](https://github.com/tensorflow/rust), and [Scala](https://github.com/eaplatanios/tensorflow_scala)), that would be great to see.\r\n\r\nBut alas, nope, the TensorFlow maintainers do not have plans to build or support those right now."]}, {"number": 17252, "title": "Retrain.py script failing with nan-error at random without any code changes", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Working on a notebook with MacOS High Sierra v10.13.1 in a Docker container using Ubuntu 16.04.3\r\n- **TensorFlow installed from (source or binary)**: Source\r\n- **TensorFlow version (use command below)**: 1.5\r\n- **Python version**: 2.7\r\n- **Bazel version (if compiling from source)**: -\r\n- **GCC/Compiler version (if compiling from source)**: -\r\n- **CUDA/cuDNN version**: Using CPU \r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**: \r\n\r\n```\r\npython -m scripts.retrain \\\r\n  --bottleneck_dir=tf_files/bottlenecks \\\r\n  --summaries_dir=tf_files/training_summaries/ \\\r\n  --output_graph=tf_files/retrained_graph.pb \\\r\n  --output_labels=tf_files/retrained_labels.txt \\\r\n  --image_dir=/ml/data/images\r\n```\r\n\r\n### Describe the problem\r\n\r\nMy set up is based on the tensorflow-for-poets tutorial. To test if everything is working I use the contained flower dataset. I tried to train the default inceptionV3 as well as the mobilenet architectures. However, training fails at some random point with the below listed error. This error does not seem to appear (or at least not as regular) if I train 500 or less training steps.\r\n\r\nBased on what I read here the thrown error is indicating model instability. Since I changed neither code nor data this seems a bit strange. I think it might be a bug but you can probably help me figuring out if this is the case.\r\n\r\n### Source code / logs\r\n\r\nThis is the error:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\r\n    \"__main__\", fname, loader, pkg_name)\r\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\r\n    exec code in run_globals\r\n  File \"/ml/tensorflow-for-poets/scripts/retrain.py\", line 1296, in <module>\r\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 124, in run\r\n    _sys.exit(main(argv))\r\n  File \"/ml/tensorflow-for-poets/scripts/retrain.py\", line 1041, in main\r\n    ground_truth_input: train_ground_truth})\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 895, in run\r\n    run_metadata_ptr)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1128, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1344, in _do_run\r\n    options, run_metadata)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1363, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Nan in summary histogram for: activations\r\n\t [[Node: activations = HistogramSummary[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](activations/tag, final_result)]]\r\n\r\nCaused by op u'activations', defined at:\r\n  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\r\n    \"__main__\", fname, loader, pkg_name)\r\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\r\n    exec code in run_globals\r\n  File \"/ml/tensorflow-for-poets/scripts/retrain.py\", line 1296, in <module>\r\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 124, in run\r\n    _sys.exit(main(argv))\r\n  File \"/ml/tensorflow-for-poets/scripts/retrain.py\", line 1001, in main\r\n    model_info['bottleneck_tensor_size'], model_info['quantize_layer'])\r\n  File \"/ml/tensorflow-for-poets/scripts/retrain.py\", line 754, in add_final_training_ops\r\n    tf.summary.histogram('activations', final_tensor)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/summary/summary.py\", line 193, in histogram\r\n    tag=tag, values=values, name=scope)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_logging_ops.py\", line 189, in _histogram_summary\r\n    \"HistogramSummary\", tag=tag, values=values, name=name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 3160, in create_op\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1625, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\nInvalidArgumentError (see above for traceback): Nan in summary histogram for: activations\r\n\t [[Node: activations = HistogramSummary[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](activations/tag, final_result)]]\r\n```", "comments": ["@petewarden Is there a bug on our end here?", "A post on Stackoverflow helped me fix this. Switching from Python 2.7.12 to Python 3.4.6 removes the issue. So perhaps this is not a tensorflow issue - but it probably deserves a note in the docs because numeric instability is in general a common problem.\r\n\r\n**Details on the issue**\r\n\r\nIt turns out the error originated mostly from the calculation of the softmax activation layer, it sometimes occurred later during cross entropy calculation. I used `tf.losses.sparse_softmax_cross_entropy` to calculate the loss.\r\n\r\nTensorflow uses some normalization in order to produce inf values due to large exponents in the softmax calculation by replacing e^x with e^(x-c) where c = max(0,x). Usually this should mitigate the issue and it obviously works in Python 3. \r\n\r\nLet me know if I can provide any additional info. Luckily for me: issue solved :-)"]}, {"number": 17251, "title": "Update version string to 1.6.0", "body": "", "comments": ["Looks like it might need to be\r\nI have 2 more cherrypicks, will update this line too.", "That's a fairly new file. I'll ask the owner if I should just automatically update that line using our script."]}, {"number": 17250, "title": "What defines the output tensor shape of tf.layers.conv2d_transpose?", "body": "When using `tf.layers.conv2d_transpose` what defines the output tensor shape?\r\nFor example: if the input was 4x4x512, for the output to be 8x8x256 the filters can be given, but how are is the height and width defined? Or else is it always two times the input height and width?\r\n\r\nThanks. ", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 17249, "title": "TypeError: Failed to convert object of type <type 'list'> to Tensor.", "body": "\r\nI want to construct a dataset in which each element is a list of tensors with different shapes, because I need a dataset to contain my parsed image informations with different shapes. If I run the code like below:\r\n\r\n`dataset = tf.data.Dataset.from_tensor_slices([[np.array([1]),np.array([1,2])],[np.array([2]), np.array([4, 5])]])`\r\n\r\nIt reports `TypeError: Failed to convert object of type <type 'list'> to Tensor.`. How should I resolve this? Thanks!\r\n", "comments": ["How did you resolve this? Having a similar issue :/"]}, {"number": 17248, "title": "The labels do not appear on android app screen", "body": "------------------------\r\n\r\n### System information\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 17.10\r\n- **TensorFlow installed from (source or binary)**: Tensorflow For Poets 2 \r\n- **Python version**: 3\r\nYou can obtain the TensorFlow version with\r\nv1.5.0-0-g37aa430d84 1.5.0\r\n\r\n### Describe the problem\r\n\r\nHello dear friends,\r\nI literally followed all instructions in Tenforflow For Poets.\r\nand for Tensorflow For Poets Mobile.\r\n\r\nI visited all the sites, blogs and forums, but I could not find any solution or similar of this problem.\r\n\r\nThe first android application was not opened, it was resolved in some way.\r\nNow it opens but the labels do not appear.\r\n\r\nI trained with Inception v3. I optimized it, stripped it, tried it on all emulators, tried it on my own phone.\r\n\r\nI'm adding a screenshot so you can look at it.\r\n\r\nThank you in advance for your answers ...\r\n\r\n![screenshot from 2018-02-25 05-58-19](https://user-images.githubusercontent.com/26048237/36637916-358ee1dc-19f7-11e8-96d4-59d5eac06c93.png)\r\n\r\n\r\n### Source code / logs\r\n02-25 06:23:37.531 4375-4375/? I/zygote: Not late-enabling -Xcheck:jni (already on)\r\n02-25 06:23:37.538 4375-4375/? W/zygote: Unexpected CPU variant for X86 using defaults: x86\r\n02-25 06:23:37.582 4375-4382/? I/zygote: Debugger is no longer active\r\n02-25 06:23:37.810 4375-4375/? I/InstantRun: starting instant run server: is main process\r\n02-25 06:23:37.852 4375-4375/? D/tensorflow: CameraActivity: onCreate org.tensorflow.demo.ClassifierActivity@e5ff96d\r\n02-25 06:23:38.025 4375-4375/? D/tensorflow: CameraActivity: onStart org.tensorflow.demo.ClassifierActivity@e5ff96d\r\n02-25 06:23:38.025 4375-4375/? D/tensorflow: CameraActivity: onResume org.tensorflow.demo.ClassifierActivity@e5ff96d\r\n02-25 06:23:38.029 4375-4394/? D/OpenGLRenderer: HWUI GL Pipeline\r\n02-25 06:23:38.048 4375-4375/? D/tensorflow: CameraActivity: onPause org.tensorflow.demo.ClassifierActivity@e5ff96d\r\n02-25 06:23:38.048 4375-4375/? D/tensorflow: CameraActivity: Requesting finish\r\n02-25 06:23:38.119 4375-4394/? I/OpenGLRenderer: Initialized EGL, version 1.4\r\n02-25 06:23:38.119 4375-4394/? D/OpenGLRenderer: Swap behavior 1\r\n02-25 06:23:38.120 4375-4394/? W/OpenGLRenderer: Failed to choose config with EGL_SWAP_BEHAVIOR_PRESERVED, retrying without...\r\n02-25 06:23:38.120 4375-4394/? D/OpenGLRenderer: Swap behavior 0\r\n02-25 06:23:38.180 4375-4394/? D/EGL_emulation: eglCreateContext: 0xab032640: maj 2 min 0 rcv 2\r\n02-25 06:23:38.686 4375-4394/org.tensorflow.demo D/EGL_emulation: eglMakeCurrent: 0xab032640: ver 2 0 (tinfo 0xab00b1d0)\r\n02-25 06:23:38.711 4375-4375/org.tensorflow.demo I/Choreographer: Skipped 35 frames!  The application may be doing too much work on its main thread.\r\n02-25 06:23:38.882 4375-4394/org.tensorflow.demo D/EGL_emulation: eglMakeCurrent: 0xab032640: ver 2 0 (tinfo 0xab00b1d0)\r\n02-25 06:23:39.475 4375-4394/org.tensorflow.demo D/EGL_emulation: eglMakeCurrent: 0xab032640: ver 2 0 (tinfo 0xab00b1d0)\r\n02-25 06:23:39.677 4375-4375/org.tensorflow.demo D/tensorflow: CameraActivity: onStop org.tensorflow.demo.ClassifierActivity@e5ff96d\r\n02-25 06:23:39.678 4375-4375/org.tensorflow.demo D/tensorflow: CameraActivity: onDestroy org.tensorflow.demo.ClassifierActivity@e5ff96d\r\n02-25 06:23:45.425 4375-4375/org.tensorflow.demo D/tensorflow: CameraActivity: onCreate org.tensorflow.demo.ClassifierActivity@186f2a1\r\n02-25 06:23:45.436 4375-4375/org.tensorflow.demo I/CameraManagerGlobal: Connecting to camera service\r\n02-25 06:23:45.447 4375-4375/org.tensorflow.demo I/tensorflow: CameraActivity: Camera API lv2?: false\r\n02-25 06:23:45.467 4375-4375/org.tensorflow.demo D/tensorflow: CameraActivity: onStart org.tensorflow.demo.ClassifierActivity@186f2a1\r\n02-25 06:23:45.467 4375-4375/org.tensorflow.demo D/tensorflow: CameraActivity: onResume org.tensorflow.demo.ClassifierActivity@186f2a1\r\n02-25 06:23:45.773 4375-4375/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Desired size: 640x480, min size: 480x480\r\n02-25 06:23:45.774 4375-4375/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Valid preview sizes: [640x480]\r\n02-25 06:23:45.774 4375-4375/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Rejected preview sizes: []\r\n02-25 06:23:45.774 4375-4375/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Exact size match found.\r\n02-25 06:23:45.844 4375-4394/org.tensorflow.demo D/EGL_emulation: eglMakeCurrent: 0xab032640: ver 2 0 (tinfo 0xab00b1d0)\r\n02-25 06:23:46.007 4375-4375/org.tensorflow.demo I/TensorFlowImageClassifier: Reading labels from: retrained_labels.txt\r\n02-25 06:23:46.009 4375-4375/org.tensorflow.demo I/TensorFlowInferenceInterface: Checking to see if TensorFlow native methods are already loaded\r\n02-25 06:23:46.009 4375-4375/org.tensorflow.demo E/zygote: No implementation found for long org.tensorflow.contrib.android.RunStats.allocate() (tried Java_org_tensorflow_contrib_android_RunStats_allocate and Java_org_tensorflow_contrib_android_RunStats_allocate__)\r\n02-25 06:23:46.009 4375-4375/org.tensorflow.demo I/TensorFlowInferenceInterface: TensorFlow native methods not found, attempting to load via tensorflow_inference\r\n02-25 06:23:46.022 4375-4375/org.tensorflow.demo W/native: cpu_feature_guard.cc:34 The TensorFlow library was compiled to use SSE instructions, but these aren't available on your machine.\r\n02-25 06:23:46.022 4375-4375/org.tensorflow.demo W/native: cpu_feature_guard.cc:34 The TensorFlow library was compiled to use SSE2 instructions, but these aren't available on your machine.\r\n02-25 06:23:46.022 4375-4375/org.tensorflow.demo W/native: cpu_feature_guard.cc:34 The TensorFlow library was compiled to use SSE3 instructions, but these aren't available on your machine.\r\n02-25 06:23:46.024 4375-4375/org.tensorflow.demo I/TensorFlowInferenceInterface: Successfully loaded TensorFlow native methods (RunStats error may be ignored)\r\n02-25 06:23:46.596 4375-4375/org.tensorflow.demo E/tensorflow: CameraActivity: Exception!\r\n                                                               java.lang.RuntimeException: Failed to load model from 'file:///android_asset/rounded_graph_str.pb'\r\n                                                                   at org.tensorflow.contrib.android.TensorFlowInferenceInterface.<init>(TensorFlowInferenceInterface.java:113)\r\n                                                                   at org.tensorflow.demo.TensorFlowImageClassifier.create(TensorFlowImageClassifier.java:103)\r\n                                                                   at org.tensorflow.demo.ClassifierActivity.onPreviewSizeChosen(ClassifierActivity.java:113)\r\n                                                                   at org.tensorflow.demo.CameraActivity.onPreviewFrame(CameraActivity.java:119)\r\n                                                                   at android.hardware.Camera$EventHandler.handleMessage(Camera.java:1124)\r\n                                                                   at android.os.Handler.dispatchMessage(Handler.java:105)\r\n                                                                   at android.os.Looper.loop(Looper.java:164)\r\n                                                                   at android.app.ActivityThread.main(ActivityThread.java:6541)\r\n                                                                   at java.lang.reflect.Method.invoke(Native Method)\r\n                                                                   at com.android.internal.os.Zygote$MethodAndArgsCaller.run(Zygote.java:240)\r\n                                                                   at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:767)\r\n                                                                Caused by: java.io.IOException: Not a valid TensorFlow Graph serialization: NodeDef mentions attr 'dilations' not in Op<name=Conv2D; signature=input:T, filter:T -> output:T; attr=T:type,allowed=[DT_HALF, DT_FLOAT]; attr=strides:list(int); attr=use_cudnn_on_gpu:bool,default=true; attr=padding:string,allowed=[\"SAME\", \"VALID\"]; attr=data_format:string,default=\"NHWC\",allowed=[\"NHWC\", \"NCHW\"]>; NodeDef: conv/Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], padding=\"VALID\", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true](Mul, conv/conv2d_params). (Check whether your GraphDef-interpreting binary is up to date with your GraphDef-generating binary.).\r\n                                                                   at org.tensorflow.contrib.android.TensorFlowInferenceInterface.loadGraph(TensorFlowInferenceInterface.java:535)\r\n                                                                   at org.tensorflow.contrib.android.TensorFlowInferenceInterface.<init>(TensorFlowInferenceInterface.java:105)\r\n                                                                   at org.tensorflow.demo.TensorFlowImageClassifier.create(TensorFlowImageClassifier.java:103)\u00a0\r\n                                                                   at org.tensorflow.demo.ClassifierActivity.onPreviewSizeChosen(ClassifierActivity.java:113)\u00a0\r\n                                                                   at org.tensorflow.demo.CameraActivity.onPreviewFrame(CameraActivity.java:119)\u00a0\r\n                                                                   at android.hardware.Camera$EventHandler.handleMessage(Camera.java:1124)\u00a0\r\n                                                                   at android.os.Handler.dispatchMessage(Handler.java:105)\u00a0\r\n                                                                   at android.os.Looper.loop(Looper.java:164)\u00a0\r\n                                                                   at android.app.ActivityThread.main(ActivityThread.java:6541)\u00a0\r\n                                                                   at java.lang.reflect.Method.invoke(Native Method)\u00a0\r\n                                                                   at com.android.internal.os.Zygote$MethodAndArgsCaller.run(Zygote.java:240)\u00a0\r\n                                                                   at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:767)\u00a0\r\n02-25 06:23:49.350 4375-4380/org.tensorflow.demo I/zygote: Do partial code cache collection, code=20KB, data=21KB\r\n02-25 06:23:49.350 4375-4380/org.tensorflow.demo I/zygote: After code cache collection, code=20KB, data=21KB\r\n02-25 06:23:49.350 4375-4380/org.tensorflow.demo I/zygote: Increasing code cache capacity to 128KB\r\n02-25 06:23:55.613 4375-4380/org.tensorflow.demo I/zygote: Do partial code cache collection, code=61KB, data=49KB\r\n02-25 06:23:55.614 4375-4380/org.tensorflow.demo I/zygote: After code cache collection, code=61KB, data=49KB\r\n02-25 06:23:55.614 4375-4380/org.tensorflow.demo I/zygote: Increasing code cache capacity to 256KB\r\n\r\n", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 17247, "title": "Update nn.py", "body": "adding missing quantized_relu which was missing before.", "comments": ["\nThanks for your pull request. t looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to `go/cla#troubleshoot`.\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "Adding @asimshankar as a reviewer as it's an API change", "Good for API addition.\r\nYou'll have to update the API goldens (details in the failing tests, but basically run:\r\n\r\n```shell\r\n    $ bazel build tensorflow/tools/api/tests:api_compatibility_test\r\n    $ bazel-bin/tensorflow/tools/api/tests/api_compatibility_test \\\r\n          --update_goldens True\r\n```", "Nagging Assignee @protoget: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @protoget: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Can you fix the test failures? We'd like to merge this"]}, {"number": 17246, "title": "Fetching value of Variable unnecessarily slow", "body": "Doing sess.run(var) is about 5x slower than sess.run(var+1). \r\n\r\npython [variable_fetch_bug_report.py](https://github.com/diux-dev/cluster/blob/26f8e01bd79e49fe2d1dac342dd90493f693b85c/yuxin_numpy/variable_fetch_bug_report.py)\r\n\r\n100MB variable\r\nfetch_cpu_variable  : 2.5 GB/sec, min: 40.74, median: 41.33, mean: 42.08\r\nfetch_cpu_variable_add: 12.6 GB/sec, min: 7.96, median: 8.54, mean: 8.71\r\nfetch_cpu_variable_concat: 14.0 GB/sec, min: 7.12, median: 8.14, mean: 8.28\r\n\r\nTensorFlow version info:\r\nversion: 1.7.0-dev20180221\r\n__git_version__: v1.6.0-rc1-337-gd100729\r\nhttps://github.com/tensorflow/tensorflow/commit/d100729\r\n", "comments": ["@mrry Any clue what's going on here?", "Presumably it's copying when it doesn't (?) need to. @alextp added the optimizations for the fetch path, so might know what could be going on here.", "Does the problem also happen with resource variables? (tfe.Variable or tf.get_variable(..., use_resource=True)", "Yes, same speed is with resource variables. I also get fast fetch speed if I turn off all optimizers and fetch `var+0`\r\n\r\n[tf_numpy_benchmark.py](https://github.com/diux-dev/cluster/blob/37d069c20fae6aeac10a53e3f801d29aebc5d6b4/yuxin_numpy/tf_numpy_benchmark.py)\r\n\r\n```\r\npython tf_numpy_benchmark.py --benchmark=fetch_cpu_variable_add --size-mb=1024 --num-iters=31\r\nfetch_cpu_variable_add        :  21.0 GB/sec, min: 48.83, median: 56.08, mean: 55.69\r\n\r\npython tf_numpy_benchmark.py --benchmark=fetch_cpu_resource_variable --num-iters=11 --size-mb=1024\r\nfetch_cpu_variable            :   2.6 GB/sec, min: 401.36, median: 404.02, mean: 403.63\r\n```\r\n\r\nI suspect that fetching variable triggers a single threaded memcpy. Meanwhile fetching \"var+0\" uses multiple cores, so it's essentially a multi-threaded memory copy", "The code which fetches tensors is https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/lib/core/ndarray_tensor.cc#L331 which calls https://github.com/tensorflow/tensorflow/blob/master/tensorflow/c/c_api.cc#L227 which triggers a copy if the refcount is not 1 (and it's never 1 for variables). It does the copy with normal memcpy. \r\n\r\nI remember people caring passionately about us not simply forwarding the memory when tensorflow still holds a reference to it as it can break some py_func use cases and some multithreaded use cases.\r\n\r\nSo I guess we should use a faster memcpy?\r\n", "Yes, faster memcpy would also resolve https://github.com/tensorflow/tensorflow/issues/17233 , until there are better tools to create 64-byte aligned numpy arrays.\r\n\r\n(PS: I wonder if this alignment requirement is moot in a first place. In PyTorch, I can inititialize tensors from unaligned numpy arrays, with memory reuse, and add them at 20 GB/second on CPU, there's no benefit in starting with aligned memory.)", "Having faster memcpy in TF also could be later worked into open-source distributed TensorFlow. Right now sending messages locally in Open-Source distributed TF is done at speed of single-threaded memcpy, so TF process can't take advantage of faster network cards (ie, AWS instances have 25 Gbps)", "BTW, here's an example of multi-threaded memcpy with some performance numbers on the same system. The time for 100MB chunk goes from 40ms to 5ms on the same system\r\n\r\nhttps://github.com/diux-dev/cluster/blob/master/psbench/memcpy.cc", "On dual XeonV4\r\n\r\n```\r\nwget https://raw.githubusercontent.com/diux-dev/cluster/master/psbench/memcpy.cc\r\ng++ -std=c++0x memcpy.cc -pthread -march=native -O6\r\n./a.out 1000 32\r\n\r\nStream copy 32 threads: 4.8 ms, 20.98 GB/sec\r\nStream copy 32 threads: 4.9 ms, 20.53 GB/sec\r\nStream copy 32 threads: 4.8 ms, 20.87 GB/sec\r\nStream copy 32 threads: 4.9 ms, 20.36 GB/sec\r\nStream copy 32 threads: 4.8 ms, 20.74 GB/sec\r\nStream copy 32 threads: 4.7 ms, 21.39 GB/sec\r\n\r\n```", "A single threaded call to the system memcpy should be able to hit the memory bandwidth of the system except in two cases:\r\n\r\n1) there are many small copies (not the case here)\r\n\r\n2) A single large copy will normally hit the memcpy path that avoids polluting the cache (the copies will be done using streaming memory instructions), this is known to decrease absolute performance but avoids cache pollution on multiprocessor machines.  This is hardcoded behavior of glibc.  The latest versions of glibc should expose this parameter as a tunable value (I put them there, see https://www.gnu.org/software/libc/manual/html_node/Hardware-Capability-Tunables.html#Hardware-Capability-Tunables).   Can you try making the non-temporal threshold larger than your copy size?\r\n\r\nI suspect what's happening is that when you shard the copy 32 times it drops below the hard-coded non temporal threshold and you're hitting the faster path (but blowing out the caches).", "That benchmark was done using a loop with calls to `_mm256_stream_load_si256` and `_mm256_stream_si256` rather than memcpy. \r\n\r\nI tried using [regular memcpy](https://github.com/diux-dev/cluster/blob/master/psbench/memcpy_classic.cc) and the performance is very close, so I think stock memcpy is already using stream version.\r\n\r\nHowever, single threaded performance is quite far from multi-threaded performance. Here's an experiment on AWS c5.18xlarge instance (dual 18-core Skylake), it runs 6x faster than single-threaded memcpy, copying 100MB array in 2.7ms. Skylakes [supposedly have](https://www.anandtech.com/show/11544/intel-skylake-ep-vs-amd-epyc-7000-cpu-battle-of-the-decade/12) 200 GB/second memory bandwidth\r\n\r\n```\r\nwget -N https://raw.githubusercontent.com/diux-dev/cluster/master/psbench/memcpy_fast.cc\r\ng++ -std=c++0x memcpy_fast.cc -pthread -march=native -O6 -o memcpy_fast\r\nnumactl --cpunodebind 0 --membind 0 ./memcpy_fast 100 16\r\nStream copy 16 threads: 2.7 ms, 37.33 GB/sec\r\nStream copy 16 threads: 2.7 ms, 37.41 GB/sec\r\nStream copy 16 threads: 2.7 ms, 37.19 GB/sec\r\nStream copy 16 threads: 2.7 ms, 37.27 GB/sec\r\n```\r\n\r\nThis [article](http://web.archive.org/web/20131223174037/http://software.intel.com/en-us/articles/memcpy-performance/) talks limitations of default `memcpy`. Since it's precompiled, it doesn't use the latest instructions (ie, Skylakes have AVX512). Apparently `icc` replaces `memcpy` with machine optimized version", "That tunable didn't seem to make any difference for me, maybe glibc is too old (version 2.23)\r\n\r\n```\r\nexport GLIBC_TUNABLES=glibc.tune.x86_non_temporal_threshold=100000000000\r\nwget -N https://raw.githubusercontent.com/diux-dev/cluster/master/psbench/memcpy_classic.cc\r\ng++ -std=c++0x memcpy_classic.cc -pthread -march=native -O6 -o memcpy_classic\r\n./memcpy_classic 100 \r\nmemcpy: 23.1 ms, 4.34 GB/sec\r\nmemcpy: 23.1 ms, 4.34 GB/sec\r\nmemcpy: 23.0 ms, 4.34 GB/sec\r\nmemcpy: 23.0 ms, 4.34 GB/sec\r\n```", "Yes that's before it went in; 2.25 or 2.26 I believe.\r\n\r\nThat article is nearly a decade old and out of date.  The memcpy maintainer in glibc works for Intel.  There are assembly routines for every specialized architecture variant including AVX 512 in the latest versions (but AVX2 is preferred because of the large down clocks associated with using AVX 512).\r\n\r\nI think your bandwidth calculation is off by a factor of 2, it only includes bytes read.\r\n\r\nThat being said, it does seem like I was incorrect and multi-threading does provide a benefit, especially on skylake.  However, 2.5 GB/sec from single threaded system memcpy seems way too low (even lowly skylake should get 10 GB/sec), so I don't know that we completely understand what's going on here.", "I see.\r\n\r\nTo summarize, currently tensorflow takes 40ms to fetch a 100MB variable on CPU, whereas copying 100MB on same machine is possible to do in 2.7ms.\r\n\r\nThis delay is an issue when integrating TensorFlow with other systems. For instance resnet-50 backprop is 120ms, if you use something like Ray to synchronize parameter values between machines, this extra 40ms delay is significant", "cc @tatianashp ", "I believe that https://github.com/tensorflow/tensorflow/commit/879fc3440495d9388754cb7d1878caf034d03d61 should solve this issue (or at least make it slightly better). Though solution is CPU/platform/glibc dependent, on my CPU (Intel Broadwell with HyperThreading (6 cores) dL1:32KB dL2:256KB dL3:15MB) I see ~1.7x improvement.", "Weird, is memmove doing multi-threaded copy? \r\n\r\nBTW, here's the code that does 100MB copy in 2.7 ms on Skylake. Besides multi-threading, it uses stream instructions to turn off cache, cache just slows things down on large copies\r\n\r\n```\r\nwget -N https://raw.githubusercontent.com/diux-dev/cluster/master/psbench/memcpy_fast.cc\r\ng++ -std=c++0x memcpy_fast.cc -pthread -march=native -O6 -o memcpy_fast\r\nnumactl --cpunodebind 0 --membind 0 ./memcpy_fast 100 16\r\nStream copy 16 threads: 2.7 ms, 37.33 GB/sec\r\nStream copy 16 threads: 2.7 ms, 37.41 GB/sec\r\n```\r\n", "Nope, they both are single threaded, but memmove is using sse3 instruction to copy memory, while memcpy is using sse2 (that's what I see in perf). This \"fix\" is more like an ugly workaround for the old glibc versions.\r\n\r\nThere is a discussion in Eigen (https://bitbucket.org/eigen/eigen/pull-requests/292/adds-a-fast-memcpy-function-to-eigen/diff), but that change was later rolled back because it's not _always_ guaranteed to be faster.", "I'm closing this issue now since I think @ezhulenev 's change fixed the problem. Please reopen if that's not the case.", "From the discussion in the eigen thread (by @rmlarsen ), looks like the above fix is only a workaround for suckiness in certain version of glibc (where memmove is even faster than memcpy). ", "The change improves single threaded copy, but it's still much faster to fetch a+0 instead of a on Skylake, because the former does multi-threaded", "BTW, I just did a benchmark with TF on DLAMI v11 (with MKL) on Skylake 18 core, and I'm seeing 10x improvement if I fetch \"var+0\" instead of var. Could try with nightly because of https://github.com/tensorflow/tensorflow/issues/20887\r\n```\r\n# fetching variable is slow from TF, because its single threaded\r\npython tf_numpy_benchmark.py --benchmark=fetch_cpu_variable --num-iters=200\r\nfetch_cpu_variable            :   2.0 GB/sec, min: 50.75, median: 50.89, mean: 50.94\r\n\r\n# however, there's a trick, adding 0 to variable makes it multithreaded 10x faster\r\npython tf_numpy_benchmark.py --benchmark=fetch_cpu_variable_plus0 --num-iters=200\r\nfetch_cpu_variable            :  33.1 GB/sec, min:  3.02, median:  3.21, mean:  3.22\r\n\r\n```", "Still present in tf_nightly (\"b'v1.9.0-rc2-572-geadcdf91aa'\")", "@yaroslavvb Mkl has it's own kernel for Add, if it's easy for you to do the same test with default Tensorflow, I'd be very interested to know if it's any significant difference between MKL and Eigen for such simple kernel", "Doing `pip install tf_nightly` I get about 8x speed-up instead of 10x by using +0 trick (tfnightly points to this commit https://github.com/tensorflow/tensorflow/commit/eadcdf91aa)\r\n\r\n```\r\n# regular fetching\r\npython tf_numpy_benchmark.py --benchmark=fetch_cpu_variable\r\nfetch_cpu_variable            :   2.0 GB/sec, min: 49.50, median: 49.62, mean: 49.68\r\n\r\n# stock tensorflow\r\npython tf_numpy_benchmark.py --benchmark=fetch_cpu_variable_plus0\r\nfetch_cpu_variable_plus0      :  16.2 GB/sec, min:  6.19, median:  6.94, mean:  6.94\r\n\r\n# DLAMI version\r\npython tf_numpy_benchmark.py --benchmark=fetch_cpu_variable_plus0\r\nfetch_cpu_variable_plus0      :  25.8 GB/sec, min:  3.87, median:  4.03, mean:  4.04\r\n```", "@yaroslavvb Please let us know if this this still an issue with latest TF or can we close this issue? Thanks!", "Closing due to lack of recent activity. Please open a new ticket when new information becomes available. Thanks!"]}, {"number": 17245, "title": "Disambiguate documentation in `multi_class_labels` of `losses.sigmoid_cross_entropy`", "body": "from continuous (0, 1) to categorical set {0, 1} according to @drpngx \r\nin https://github.com/tensorflow/tensorflow/issues/17021", "comments": ["\nThanks for your pull request. t looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to `go/cla#troubleshoot`.\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "welcome :) "]}, {"number": 17244, "title": "Change repository command to valid value", "body": "When running the example command I got an error from docker saying: `docker: invalid reference format: repository name must be lowercase.` \r\n\r\nIt seems that the repository name is written with capital letters. This confused me and might confuse others. By replacing `TensorFlowImage` with a valid repository the first command can also be run.", "comments": []}, {"number": 17243, "title": "Would a vector field layer be a welcome addition?", "body": "Here is a [paper](https://arxiv.org/pdf/1802.08235v1.pdf) I stumbled upon yesterday. It describes an interesting, visual approach of separation of mixed set of points in high dimensional spaces into linearly separable set of points by learning a vector field that carries input points to new locations.\r\n\r\nCoupled with Tensorboard, such a layer would provide intuition as to what the network is doing. We would \"see\" how it warps the space to provide linear separability. \r\n\r\nI have started coding up such a layer to run some visualizations. Note that this would be a first contribution to the code base, so excuse any dumb things as I am learning the code base. \r\nand I am wondering if anyone wants to collaborate on the implementation, and if upon successful implementation and tests, such a layer could be accepted into the code base.\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?"]}, {"number": 17242, "title": "Getting ValueError: setting an array element with a sequence from tf.contrib.keras.preprocessing.image.ImageDatagenerator.flow", "body": "\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution**:  Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: 1.6.0-rc0\r\n- **Python version**: 2.7.12\r\n- **Bazel version (if compiling from source)**: 0.10.0\r\n- **GCC/Compiler version (if compiling from source)**: 5,4.0\r\n\r\nI am trying to do Data Augmentation in Tensorflow. I have written this code.\r\n\r\n    import numpy as np\r\n    import tensorflow as tf\r\n    import tensorflow.contrib.keras as keras\r\n    import time, random\r\n    \r\n    def get_image_data_generator():\r\n    \treturn keras.preprocessing.image.ImageDataGenerator(\r\n        rotation_range=get_random_rotation_angle(),\\\r\n        width_shift_range=get_random_wh_shift(),\\\r\n        height_shift_range=get_random_wh_shift(),\\\r\n        shear_range=get_random_shear(),\\\r\n        zoom_range=get_random_zoom(),\\\r\n        horizontal_flip=get_random_flip(),\\\r\n        vertical_flip=get_random_flip(),\\\r\n        preprocessing_function=get_random_function())\r\n        \r\n    def augment_data(image_array,label_array):\r\n    \tprint image_array.shape\r\n    \timages_array = image_array.copy()\r\n    \tlabels_array = label_array.copy()\r\n    \t#Create a list of various datagenerators with different arguments\r\n    \tdatagenerators = []\r\n    \tndg = 10\r\n        #Creating 10 different generators\r\n    \tfor ndata in xrange(ndg):\r\n    \t\tdatagenerators.append(get_image_data_generator())\r\n        #Setting batch_size to be equal to no.of images\r\n    \tbsize = image_array.shape[0]\r\n    \tprint bsize\r\n        #Obtaining the augmented data\r\n    \tfor dgen in datagenerators:\r\n    \t\tdgen.fit(image_array)\r\n    \t\t(aug_img,aug_label) = dgen.flow(image_array,label_array,batch_size=bsize,shuffle=True)\r\n    \t\tprint aug_img.shape\r\n            #Concatenating with the original data\r\n    \t\timages_array = np.concatenate([images_array,aug_img],axis=0)\r\n    \t\tlabels_array = np.concatenate([labels_array,aug_label],axis=0)\r\n    \treturn (images_array,labels_array)\r\n   \r\nWhen I run the code using\r\n\r\n`augment_data(image_array,label_array)`\r\n\r\nI get an error which says\r\n\r\n    Traceback (most recent call last):\r\n      File \"cnn_model.py\", line 40, in <module>\r\n        images_array,labels_array = augment_data(image_array,label_array)\r\n      File \"/media/siladittya/d801fb13-809a-41b4-8f2e-d617ba103aba/ISI/code/2. known_object_detection/aug_data.py\", line 47, in augment_data\r\n        (aug_img,aug_label) = dgen.flow(image_array,label_array,batch_size=10000,shuffle=True)\r\n      File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/_impl/keras/preprocessing/image.py\", line 1018, in next\r\n        return self._get_batches_of_transformed_samples(index_array)\r\n      File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/_impl/keras/preprocessing/image.py\", line 991, in _get_batches_of_transformed_samples\r\n        batch_x[i] = x\r\n    ValueError: setting an array element with a sequence.\r\n\r\nEdit :: I am getting this error even if I pass a single image as argument.\r\n\r\nWhat am I doing wrong here? I can't understand. Please help.", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}]