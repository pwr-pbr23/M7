[{"number": 21888, "title": "TensorFlow for AGI", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**:\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": []}, {"number": 21887, "title": "R1.10", "body": "", "comments": ["So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored or co-authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of all the commit author(s), set the `cla` label to `yes` (if enabled on your project), and then merge this pull request when appropriate.*\n\n<!-- need_author_consent -->"]}, {"number": 21886, "title": "Tensorflow 1.10.0 MKL build (win-64) with bazel throws linker error", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: N/A\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: 1.10.0\r\n- **Python version**: 3.6 (doesn't really matter)\r\n- **Bazel version (if compiling from source)**: 0.15.2\r\n- **GCC/Compiler version (if compiling from source)**: VS2015 Update 3\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: <sigh>\r\n\r\n### Describe the problem\r\nTried compiling tensorflow from source, cpu version, with mkl.\r\n\r\n### Source code / logs\r\nBuild fails with the following output:\r\n```\r\nERROR: C:/ci/tensorflow-base_1535347248498/work/tensorflow/python/BUILD:3627:1: Linking of rule '//tensorflow/python:_pywrap_tensorflow_internal.so' failed (Exit 1000): link.exe failed: error executing command\r\n  cd C:/users/nwani/_bazel_nwani/ozaxfmyw/execroot/org_tensorflow\r\n  SET INCLUDE=C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\ATLMFC\\INCLUDE;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.10240.0\\ucrt;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.6.1\\include\\um;C:\\Program Files (x86)\\Windows Kits\\8.1\\include\\\\shared;C:\\Program Files (x86)\\Windows Kits\\8.1\\include\\\\um;C:\\Program Files (x86)\\Windows Kits\\8.1\\include\\\\winrt;\r\n    SET LIB=C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\LIB\\amd64;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\ATLMFC\\LIB\\amd64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.10240.0\\ucrt\\x64;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.6.1\\lib\\um\\x64;C:\\Program Files (x86)\\Windows Kits\\8.1\\lib\\winv6.3\\um\\x64;\r\n    SET PATH=C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Common7\\IDE\\CommonExtensions\\Microsoft\\TestWindow;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\amd64;C:\\WINDOWS\\Microsoft.NET\\Framework64\\v4.0.30319;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\VCPackages;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Common7\\IDE;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Common7\\Tools;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Team Tools\\Performance Tools\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Team Tools\\Performance Tools;C:\\Program Files (x86)\\Windows Kits\\8.1\\bin\\x64;C:\\Program Files (x86)\\Windows Kits\\8.1\\bin\\x86;C:\\Program Files (x86)\\Microsoft SDKs\\Windows\\v10.0A\\bin\\NETFX 4.6.1 Tools\\x64\\;;C:\\WINDOWS\\system32\r\n    SET PWD=/proc/self/cwd\r\n    SET TEMP=C:\\Users\\nwani\\AppData\\Local\\Temp\r\n    SET TMP=C:\\Users\\nwani\\AppData\\Local\\Temp\r\n    SET USE_LINKER=1\r\n  C:/Program Files (x86)/Microsoft Visual Studio 14.0/VC/bin/amd64/link.exe /nologo /DLL /SUBSYSTEM:CONSOLE -DEFAULTLIB:advapi32.lib /MACHINE:X64 @bazel-out/host/bin/tensorflow/python/_pywrap_tensorflow_internal.so-2.params /DEF:bazel-out/host/genfiles/tensorflow/python/pywrap_tensorflow_filtered_def_file.def /ignore:4070\r\nLINK : warning LNK4044: unrecognized option '/lpthread'; ignored\r\nLINK : warning LNK4044: unrecognized option '/lm'; ignored\r\nLINK : warning LNK4044: unrecognized option '/ldl'; ignored\r\nLINK : warning LNK4044: unrecognized option '/lpthread'; ignored\r\nLINK : warning LNK4044: unrecognized option '/lpthread'; ignored\r\nLINK : warning LNK4044: unrecognized option '/lm'; ignored\r\nLINK : warning LNK4044: unrecognized option '/ldl'; ignored\r\nLINK : warning LNK4044: unrecognized option '/lm'; ignored\r\nLINK : warning LNK4044: unrecognized option '/lm'; ignored\r\n\r\nbazel-out/host/bin/external/nsync/nsync_cpp.lib : fatal error LNK1000: Internal error during CImplib::EmitThunk\r\n\r\n  Version 14.00.24215.1\r\n\r\n  ExceptionCode            = C0000005\r\n  ExceptionFlags           = 00000000\r\n  ExceptionAddress         = 00007FF7EF196896 (00007FF7EF180000) \"C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\bin\\amd64\\link.exe\"\r\n  NumberParameters         = 00000002\r\n  ExceptionInformation[ 0] = 0000000000000000\r\n  ExceptionInformation[ 1] = 0000000000000008\r\n\r\nCONTEXT:\r\n  Rax    = 0000000000000000  R8     = 00007FF7EF27FBE0\r\n  Rbx    = 0000000000000000  R9     = 00007FF7EF27E9F0\r\n  Rcx    = 0000000000000000  R10    = 0000000000000000\r\n  Rdx    = 00007FF7EF27FBD8  R11    = 0000000000000000\r\n  Rsp    = 000000A6F5B2DE28  R12    = 00007FF7EF24D950\r\n  Rbp    = 0000023D587FA330  E13    = 0000000000000000\r\n  Rsi    = 0000000000008000  R14    = 0000000000000000\r\n  Rdi    = 0000023D59249700  R15    = 0000000000000000\r\n  Rip    = 00007FF7EF196896  EFlags = 0000000000010246\r\n  SegCs  = 0000000000000033  SegDs  = 000000000000002B\r\n  SegSs  = 000000000000002B  SegEs  = 000000000000002B\r\n  SegFs  = 0000000000000053  SegGs  = 000000000000002B\r\n  Dr0    = 0000000000000000  Dr3    = 0000000000000000\r\n  Dr1    = 0000000000000000  Dr6    = 0000000000000000\r\n  Dr2    = 0000000000000000  Dr7    = 0000000000000000\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 2226.356s, Critical Path: 254.23s\r\nINFO: 4537 processes: 4537 local.\r\nFAILED: Build did NOT complete successfully\r\n+ exit 1\r\n```\r\n", "comments": ["i thought that bazel si currently not stable in windows", "Related to https://github.com/tensorflow/tensorflow/issues/6396", "While the build was running, I found the path to the parameter files and edited some lines to fix the problem:\r\n\r\n```\r\nsed -i 's,^/WHOLEARCHIVE:\\(.*external.*\\),\\1,'  /c/users/nwani/_bazel_nwani/2womniv5/execroot/org_tensorflow/bazel-out/x64_windows-opt/bin/tensorflow/python/_pywrap_tensorflow_internal.so-2.params\r\n```\r\n\r\n```\r\nsed -i 's,^/WHOLEARCHIVE:\\(.*external.*\\),\\1,'  /c/users/nwani/_bazel_nwani/2womniv5/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/_pywrap_tensorflow_internal.so-2.params\r\n```\r\nBasically, drop the `/WHOLEARCHIVE` option for all the 'external' dependencies.", "@tatianashp Could you reroute this issue to Intel?", "Adding @agramesh1. \r\nRamesh - can you help here?", "addressed in comments to [23420](https://github.com/tensorflow/tensorflow/issues/23420)\r\nclosing"]}, {"number": 21885, "title": "add LU operation and return factorized matrices, related to issue #6992", "body": "related to #6992 and\r\nreopen for pull request https://github.com/tensorflow/tensorflow/pull/16185\r\n", "comments": ["The differences between this pull request and previous https://github.com/tensorflow/tensorflow/pull/16185\r\n- change FullPivLU to PartialPivLU\r\n- change full matrix of permutation to an index array.\r\n- use tf.gather instead of p^-1 lu\r\n- Ops derived from OpKernel, instead of LinearAlgebraOp \r\n- An integer INFO is returned with L, U, P. INFO is the index of the first zero diagonal in U, like INFO argument in LAPACK function xGETRF. ", "Nagging Assignee @aaroey: It has been 90 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "An LU op was contributed by Google, and should be available on github. Thanks for working on this."]}, {"number": 21884, "title": "Adding regularizer causes crash when using eager w/ make_template", "body": "### System information\r\n- Ubuntu 16.04\r\n- Tensorflow installed from binary: v1.9.0.138\r\n- Python 2.7.12\r\n- CUDA: Version 9.0.252\r\n- GPU: GeForce GTX 1080 Ti\r\n\r\nCode to reproduce:\r\n```python\r\nimport tensorflow as tf\r\nimport tensorflow.contrib.eager as tfe\r\nimport tensorflow.contrib.layers as layers\r\n\r\ntf.enable_eager_execution()\r\n\r\ndef make_network(input_images, include_regularizer):\r\n    weights_initializer = tf.variance_scaling_initializer(scale=1.)\r\n    l2_regularizer = layers.l2_regularizer(scale=0.000004)\r\n\r\n    convolution_args = dict(\r\n        weights_initializer=weights_initializer,\r\n        biases_initializer=tf.zeros_initializer(),\r\n        activation_fn=tf.nn.leaky_relu,\r\n        kernel_size=(3, 3), stride=1,\r\n        padding='SAME',\r\n        weights_regularizer=l2_regularizer if include_regularizer else None,\r\n    )\r\n    return layers.conv2d(inputs=input_images,\r\n                         num_outputs=3,\r\n                         scope='my_layer',\r\n                         **convolution_args)\r\n\r\nif __name__ == '__main__':\r\n    images = tf.ones([2, 240, 320, 3], dtype=tf.float32)\r\n    the_template = tfe.make_template(\r\n        'custom_network', make_network,\r\n        create_graph_function_=True,\r\n    )\r\n    # execute the template\r\n    foo = the_template(images, include_regularizer=True)\r\n```\r\n\r\nThe above code fails with `UnboundLocalError` when `include_regularizer=True`. Setting `include_regularizer=False` runs normally. The crash occurs in `base.py`:\r\n\r\n```\r\n/usr/local/lib/python2.7/dist-packages/tensorflow/python/layers/base.py in add_weight(self, name, shape, dtype, initializer, regularizer, trainable, constraint, use_resource, synchronization, aggregation, partitioner)\r\n    278         if regularizer:\r\n    279           if context.executing_eagerly() or _should_add_regularizer(\r\n--> 280               variable, existing_variables):\r\n    281             self._handle_weight_regularization(name, variable, regularizer)\r\n    282 \r\n\r\nUnboundLocalError: local variable 'existing_variables' referenced before assignment\r\n```\r\n\r\nUpon closer inspection, it appears `context.executing_eagerly()` is `False` here, resulting in the `_should_add_regularizer` statement being evaluated. Based on a cursory inspection, it seems like `existing_variables` should be set on line 246 of `base.py`, but this does not occur because within the scope of `ops`, `executing_eagerly()` evaluates to `True`. \r\n\r\nSee https://github.com/tensorflow/tensorflow/blob/09792df012c22622324f085f46edde33006c7355/tensorflow/python/layers/base.py#L236-L250\r\n\r\nI'm unclear what the expected behavior of this code is - am I doing something wrong or is this a bug?\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "@tensorflowbutler The additional info:\r\n\r\nHave I written custom code: Yes, see above\r\nOS Platform and distribution: Ubuntu 16.04\r\nTensorFlow version: v1.9.0.138\r\nBazel version: n/a\r\nCUDA/cuDNN version: Version 9.0.252\r\nGPU model and memory: GeForce GTX 1080 Ti 12GB\r\nExact command to reproduce: See code above\r\nMobile device: n/a", "Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?"]}, {"number": 21883, "title": "Fix incorrect link in `dockerfiles/README.md`", "body": "This fix fixes incorrect link in `dockerfiles/README.md`.", "comments": []}, {"number": 21882, "title": "How can I solve the problem ?", "body": "\r\njiangnanqiao@jiangnanqiao-Lenovo-B40-80:~$ which pip\r\n/home/jiangnanqiao/.local/bin/pip\r\njiangnanqiao@jiangnanqiao-Lenovo-B40-80:~$ export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-1.3.0-cp27-none-linux_x86_64.whl\r\njiangnanqiao@jiangnanqiao-Lenovo-B40-80:~$ sudo pip install $TF_BINARY_URL[sudo] password for jiangnanqiao: \r\nThe directory '/home/jiangnanqiao/.cache/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\r\nThe directory '/home/jiangnanqiao/.cache/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\r\ntensorflow-1.3.0-cp27-none-linux_x86_64.whl is not a supported wheel on this platform.\r\n\r\nMy os is 64 bits,windows&ubuntu16.04.I know little about this and I want to solve the problem.\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new). Thanks!\r\n"]}, {"number": 21881, "title": "Tensorflow nearly 2 times slower than Pytorch in training!", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: -\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.7.0 and 1.10.1\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**:-\r\n- **GCC/Compiler version (if compiling from source)**:-\r\n- **CUDA/cuDNN version**:9.0/7.0 and 7.1\r\n- **GPU model and memory**: GTX1080/8Gig\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nI was trying to train the same network on both `Tensorflow` and `Pytorch` frameworks and noticed `Tensorflow` is nearly **2x slower** than `Pytorch`!  \r\nWhile each epoch in `Pytorch` takes roughly about **50** seconds, in `Tensorflow` it takes **90** seconds!     \r\nI initially tried Stackoverflow, but after seeing a similar issue (https://github.com/tensorflow/tensorflow/issues/7187)from around a year ago, which reported the same performance issues and ultimately got solved, I changed my mind and thought it should be a bug.  \r\nI uploaded the code snippets regarding Tensorflow (which are taken from [official TF model repository-resnet ][1] and changed to be used with the new architecture(nearly everything is intact except minor changes needed to use the new architecture (simpleNet, which is a very simple convolutional architecture)).  \r\nIt should be noted that, the points in the previous similar issue that solved the performance discrepancy are not valid in this one. since the code base is changed and has been updated according to the latest improvements in TF. \r\nThings such as not using feed_dict, or offloading the input on to the CPU instead of GPU and setting `TF_ENABLE_WINOGRAD_NONFUSED `flags are already addressed in the new example which is used for this case, however the performance issue still persists. \r\n\r\n### Source code / logs \r\n\r\nHere are the code snippets :     \r\n\r\n> [simple_model.py][2]   \r\n> [cifar10_main.py][3]      \r\n> [simplenet_run_loop.py][4]\r\n\r\nHere are the logs for Pytorch and tensorflow respectively :\r\n\r\n**Pytorch (v0.4)** :\r\n\r\n    ==>>[2018-08-19 00:00:26] [Epoch=000/450] [Need: 00:00:00] [learning_rate=0.100000] [Best : Accuracy=0.00, Error=100.00]\r\n      Epoch: [000][000/500]   Time 1.345 (1.345)   Data 0.089 (0.089)   Loss 4.8846 (4.8846)   Prec@1 0.000 (0.000)   Prec@5 4.000 (4.000)   [2018-08-19 00:00:28]\r\n      Epoch: [000][200/500]   Time 0.089 (0.096)   Data 0.000 (0.001)   Loss 4.0047 (4.3586)   Prec@1 6.000 (3.771)   Prec@5 28.000 (14.930)   [2018-08-19 00:00:46]\r\n      Epoch: [000][400/500]   Time 0.089 (0.093)   Data 0.000 (0.000)   Loss 3.9328 (4.1781)   Prec@1 9.000 (5.519)   Prec@5 26.000 (20.142)   [2018-08-19 00:01:04]\r\n      **Train** Prec@1 6.352 Prec@5 22.334 Error@1 93.648\r\n      **Test** Prec@1 8.520 Prec@5 31.600 Error@1 91.480\r\n    \r\n    ==>>[2018-08-19 00:01:17] [Epoch=001/450] [Need: 06:07:54] [learning_rate=0.100000] [Best : Accuracy=8.52, Error=91.48]\r\n      Epoch: [001][000/500]   Time 0.128 (0.128)   Data 0.086 (0.086)   Loss 3.7810 (3.7810)   Prec@1 9.000 (9.000)   Prec@5 34.000 (34.000)   [2018-08-19 00:01:17]\r\n      Epoch: [001][200/500]   Time 0.090 (0.090)   Data 0.000 (0.001)   Loss 3.5385 (3.7109)   Prec@1 18.000 (11.517)   Prec@5 39.000 (34.861)   [2018-08-19 00:01:35]\r\n      Epoch: [001][400/500]   Time 0.088 (0.090)   Data 0.000 (0.000)   Loss 3.6088 (3.6151)   Prec@1 11.000 (13.274)   Prec@5 34.000 (38.102)   [2018-08-19 00:01:54]\r\n      **Train** Prec@1 14.048 Prec@5 39.416 Error@1 85.952\r\n      **Test** Prec@1 19.110 Prec@5 45.950 Error@1 80.890\r\n    \r\n    ==>>[2018-08-19 00:02:07] [Epoch=002/450] [Need: 06:10:38] [learning_rate=0.100000] [Best : Accuracy=19.11, Error=80.89]\r\n      Epoch: [002][000/500]   Time 0.133 (0.133)   Data 0.086 (0.086)   Loss 3.4438 (3.4438)   Prec@1 17.000 (17.000)   Prec@5 45.000 (45.000)   [2018-08-19 00:02:07]\r\n      Epoch: [002][200/500]   Time 0.089 (0.091)   Data 0.000 (0.001)   Loss 3.1025 (3.2688)   Prec@1 26.000 (19.721)   Prec@5 56.000 (48.085)   [2018-08-19 00:02:26]\r\n      Epoch: [002][400/500]   Time 0.092 (0.091)   Data 0.000 (0.000)   Loss 2.9271 (3.1983)   Prec@1 24.000 (20.998)   Prec@5 57.000 (50.125)   [2018-08-19 00:02:44]\r\n      **Train** Prec@1 21.658 Prec@5 50.980 Error@1 78.342\r\n      **Test** Prec@1 26.430 Prec@5 56.030 Error@1 73.570\r\n    \r\n    ==>>[2018-08-19 00:02:57] [Epoch=003/450] [Need: 06:10:40] [learning_rate=0.100000] [Best : Accuracy=26.43, Error=73.57]\r\n      Epoch: [003][000/500]   Time 0.136 (0.136)   Data 0.087 (0.087)   Loss 2.8432 (2.8432)   Prec@1 23.000 (23.000)   Prec@5 55.000 (55.000)   [2018-08-19 00:02:57]\r\n      Epoch: [003][200/500]   Time 0.092 (0.091)   Data 0.000 (0.001)   Loss 2.8233 (2.8715)   Prec@1 33.000 (26.567)   Prec@5 62.000 (58.433)   [2018-08-19 00:03:16]\r\n      Epoch: [003][400/500]   Time 0.092 (0.091)   Data 0.000 (0.000)   Loss 2.6975 (2.8040)   Prec@1 29.000 (28.047)   Prec@5 58.000 (60.125)   [2018-08-19 00:03:34]\r\n      **Train** Prec@1 28.784 Prec@5 60.932 Error@1 71.216\r\n      **Test** Prec@1 30.960 Prec@5 61.810 Error@1 69.040\r\n\r\n\r\n\r\n**Tensorflow( v1.7.0)** :\r\n\r\n    totalMemory: 7.93GiB freeMemory: 7.38GiB\r\n    2018-08-26 09:06:38.766280: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0\r\n    2018-08-26 09:06:38.929447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n    2018-08-26 09:06:38.929480: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 \r\n    2018-08-26 09:06:38.929484: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N \r\n    2018-08-26 09:06:38.929650: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/device:GPU:0 with 7131 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n    INFO:tensorflow:Benchmark run: {'model_name': 'simpnet', 'machine_config': {'cpu_info': {'num_cores': 8, 'cpu_info': 'Intel(R) Core(TM) i7-4790K CPU @ 4.00GHz', 'mhz_per_cpu': 4000.0}, 'gpu_info': {'count': 1, 'model': 'GeForce GTX 1080'}, 'memory_total': 20986626048, 'memory_available': 14860541952}, 'run_date': '2018-08-26T04:36:38.596702Z', 'tensorflow_version': {'version': '1.7.0', 'git_hash': 'v1.7.0-3-g024aecf414'}, 'tensorflow_environment_variables': [{'name': 'TF_ENABLE_WINOGRAD_NONFUSED', 'value': '1'}]}\r\n    INFO:tensorflow:Starting a training cycle: 0/250\r\n    INFO:tensorflow:Calling model_fn.\r\n    data_format:  channels_first\r\n    INFO:tensorflow:Done calling model_fn.\r\n    INFO:tensorflow:Create CheckpointSaverHook.\r\n    INFO:tensorflow:Graph was finalized.\r\n    2018-08-26 09:06:40.685552: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0\r\n    2018-08-26 09:06:40.685610: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n    2018-08-26 09:06:40.685617: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 \r\n    2018-08-26 09:06:40.685630: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N \r\n    2018-08-26 09:06:40.685744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7131 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n    INFO:tensorflow:Running local_init_op.\r\n    INFO:tensorflow:Done running local_init_op.\r\n    INFO:tensorflow:Saving checkpoints for 1 into /tmp/cifar10_model/model.ckpt.\r\n    INFO:tensorflow:learning_rate = 0.1, cross_entropy = 7.7181897, train_accuracy = 0.09\r\n    INFO:tensorflow:loss = 20.531982, step = 0\r\n    INFO:tensorflow:global_step/sec: 5.5106\r\n    INFO:tensorflow:learning_rate = 0.1, cross_entropy = 2.26069, train_accuracy = 0.105 (18.147 sec)\r\n    INFO:tensorflow:loss = 13.960868, step = 100 (18.147 sec)\r\n    INFO:tensorflow:global_step/sec: 5.42846\r\n    INFO:tensorflow:learning_rate = 0.1, cross_entropy = 2.291137, train_accuracy = 0.10666667 (18.421 sec)\r\n    INFO:tensorflow:loss = 12.874262, step = 200 (18.421 sec)\r\n    INFO:tensorflow:global_step/sec: 5.62853\r\n    INFO:tensorflow:learning_rate = 0.1, cross_entropy = 2.1555672, train_accuracy = 0.1175 (17.767 sec)\r\n    INFO:tensorflow:loss = 11.73109, step = 300 (17.767 sec)\r\n    INFO:tensorflow:global_step/sec: 5.45977\r\n    INFO:tensorflow:learning_rate = 0.1, cross_entropy = 2.0706115, train_accuracy = 0.122 (18.316 sec)\r\n    INFO:tensorflow:loss = 10.739094, step = 400 (18.316 sec)\r\n    INFO:tensorflow:Saving checkpoints for 500 into /tmp/cifar10_model/model.ckpt.\r\n    INFO:tensorflow:Loss for final step: 9.72249.\r\n    INFO:tensorflow:Starting to evaluate.\r\n    INFO:tensorflow:Calling model_fn.\r\n    data_format:  channels_first\r\n    INFO:tensorflow:Done calling model_fn.\r\n    INFO:tensorflow:Starting evaluation at 2018-08-26-04:38:16\r\n    INFO:tensorflow:Graph was finalized.\r\n    2018-08-26 09:08:16.838937: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0\r\n    2018-08-26 09:08:16.838968: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n    2018-08-26 09:08:16.838986: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 \r\n    2018-08-26 09:08:16.838989: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N \r\n    2018-08-26 09:08:16.839099: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7131 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n    INFO:tensorflow:Restoring parameters from /tmp/cifar10_model/model.ckpt-500\r\n    INFO:tensorflow:Running local_init_op.\r\n    INFO:tensorflow:Done running local_init_op.\r\n    INFO:tensorflow:Finished evaluation at 2018-08-26-04:38:22\r\n    INFO:tensorflow:Saving dict for global step 500: accuracy = 0.2181, global_step = 500, loss = 9.815871\r\n    INFO:tensorflow:Benchmark metric: Name accuracy, value 0, unit None, global_step 500, extras []\r\n    INFO:tensorflow:Benchmark metric: Name loss, value 9, unit None, global_step 500, extras []\r\n    INFO:tensorflow:Starting a training cycle: 1/250\r\n    INFO:tensorflow:Calling model_fn.\r\n    data_format:  channels_first\r\n    INFO:tensorflow:Done calling model_fn.\r\n    INFO:tensorflow:Create CheckpointSaverHook.\r\n    INFO:tensorflow:Graph was finalized.\r\n    2018-08-26 09:08:23.994577: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0\r\n    2018-08-26 09:08:23.994610: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n    2018-08-26 09:08:23.994625: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 \r\n    2018-08-26 09:08:23.994630: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N \r\n    2018-08-26 09:08:23.994726: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7131 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n    INFO:tensorflow:Restoring parameters from /tmp/cifar10_model/model.ckpt-500\r\n    INFO:tensorflow:Running local_init_op.\r\n    INFO:tensorflow:Done running local_init_op.\r\n    INFO:tensorflow:Saving checkpoints for 501 into /tmp/cifar10_model/model.ckpt.\r\n    INFO:tensorflow:learning_rate = 0.1, cross_entropy = 1.831348, train_accuracy = 0.23\r\n    INFO:tensorflow:loss = 9.679985, step = 500\r\n    INFO:tensorflow:global_step/sec: 5.3539\r\n    INFO:tensorflow:learning_rate = 0.1, cross_entropy = 1.8214886, train_accuracy = 0.25 (18.678 sec)\r\n    INFO:tensorflow:loss = 8.9299, step = 600 (18.678 sec)\r\n    INFO:tensorflow:global_step/sec: 5.49204\r\n    INFO:tensorflow:learning_rate = 0.1, cross_entropy = 1.7747709, train_accuracy = 0.26666668 (18.208 sec)\r\n    INFO:tensorflow:loss = 8.215595, step = 700 (18.208 sec)\r\n    INFO:tensorflow:global_step/sec: 5.48954\r\n    INFO:tensorflow:learning_rate = 0.1, cross_entropy = 1.7076583, train_accuracy = 0.275 (18.216 sec)\r\n    INFO:tensorflow:loss = 7.5460052, step = 800 (18.216 sec)\r\n    INFO:tensorflow:global_step/sec: 5.65214\r\n    INFO:tensorflow:learning_rate = 0.1, cross_entropy = 1.6106825, train_accuracy = 0.286 (17.692 sec)\r\n    INFO:tensorflow:loss = 6.904671, step = 900 (17.692 sec)\r\n    INFO:tensorflow:Saving checkpoints for 1000 into /tmp/cifar10_model/model.ckpt.\r\n    INFO:tensorflow:Loss for final step: 6.5854077.\r\n    INFO:tensorflow:Starting to evaluate.\r\n    INFO:tensorflow:Calling model_fn.\r\n    data_format:  channels_first\r\n    INFO:tensorflow:Done calling model_fn.\r\n    INFO:tensorflow:Starting evaluation at 2018-08-26-04:39:57\r\n    INFO:tensorflow:Graph was finalized.\r\n    2018-08-26 09:09:57.431671: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0\r\n    2018-08-26 09:09:57.431702: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n    2018-08-26 09:09:57.431718: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 \r\n    2018-08-26 09:09:57.431722: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N \r\n    2018-08-26 09:09:57.431814: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7131 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n    INFO:tensorflow:Restoring parameters from /tmp/cifar10_model/model.ckpt-1000\r\n    INFO:tensorflow:Running local_init_op.\r\n    INFO:tensorflow:Done running local_init_op.\r\n    INFO:tensorflow:Finished evaluation at 2018-08-26-04:40:02\r\n    INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.264, global_step = 1000, loss = 6.684446\r\n    INFO:tensorflow:Benchmark metric: Name accuracy, value 0, unit None, global_step 1000, extras []\r\n    INFO:tensorflow:Benchmark metric: Name loss, value 6, unit None, global_step 1000, extras []\r\n    INFO:tensorflow:Starting a training cycle: 2/250\r\n    INFO:tensorflow:Calling model_fn.\r\n    data_format:  channels_first\r\n    INFO:tensorflow:Done calling model_fn.\r\n    INFO:tensorflow:Create CheckpointSaverHook.\r\n    INFO:tensorflow:Graph was finalized.\r\n    2018-08-26 09:10:04.247883: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0\r\n    2018-08-26 09:10:04.247914: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n    2018-08-26 09:10:04.247930: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 \r\n    2018-08-26 09:10:04.247934: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N \r\n    2018-08-26 09:10:04.248028: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7131 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n    INFO:tensorflow:Restoring parameters from /tmp/cifar10_model/model.ckpt-1000\r\n    INFO:tensorflow:Running local_init_op.\r\n    INFO:tensorflow:Done running local_init_op.\r\n    INFO:tensorflow:Saving checkpoints for 1001 into /tmp/cifar10_model/model.ckpt.\r\n    INFO:tensorflow:learning_rate = 0.1, cross_entropy = 1.7071365, train_accuracy = 0.32\r\n    INFO:tensorflow:loss = 6.5100193, step = 1000\r\n    INFO:tensorflow:global_step/sec: 5.54579\r\n    INFO:tensorflow:learning_rate = 0.1, cross_entropy = 1.5869155, train_accuracy = 0.335 (18.032 sec)\r\n    INFO:tensorflow:loss = 5.9459677, step = 1100 (18.032 sec)\r\n    INFO:tensorflow:global_step/sec: 5.69552\r\n    INFO:tensorflow:learning_rate = 0.1, cross_entropy = 1.754588, train_accuracy = 0.31 (17.558 sec)\r\n    INFO:tensorflow:loss = 5.7136836, step = 1200 (17.558 sec)\r\n    INFO:tensorflow:global_step/sec: 5.69235\r\n    INFO:tensorflow:learning_rate = 0.1, cross_entropy = 1.6495434, train_accuracy = 0.3225 (17.568 sec)\r\n    INFO:tensorflow:loss = 5.2463627, step = 1300 (17.568 sec)\r\n    INFO:tensorflow:global_step/sec: 5.60754\r\n    INFO:tensorflow:learning_rate = 0.1, cross_entropy = 1.6227012, train_accuracy = 0.326 (17.833 sec)\r\n    INFO:tensorflow:loss = 4.8923674, step = 1400 (17.833 sec)\r\n    INFO:tensorflow:Saving checkpoints for 1500 into /tmp/cifar10_model/model.ckpt.\r\n    INFO:tensorflow:Loss for final step: 4.7713437.\r\n    INFO:tensorflow:Starting to evaluate.\r\n    INFO:tensorflow:Calling model_fn.\r\n    data_format:  channels_first\r\n    INFO:tensorflow:Done calling model_fn.\r\n    INFO:tensorflow:Starting evaluation at 2018-08-26-04:41:36\r\n    INFO:tensorflow:Graph was finalized.\r\n    2018-08-26 09:11:36.521245: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0\r\n    2018-08-26 09:11:36.521277: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n    2018-08-26 09:11:36.521285: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 \r\n    2018-08-26 09:11:36.521290: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N \r\n    2018-08-26 09:11:36.521385: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7131 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n    INFO:tensorflow:Restoring parameters from /tmp/cifar10_model/model.ckpt-1500\r\n    INFO:tensorflow:Running local_init_op.\r\n    INFO:tensorflow:Done running local_init_op.\r\n    INFO:tensorflow:Finished evaluation at 2018-08-26-04:41:41\r\n    INFO:tensorflow:Saving dict for global step 1500: accuracy = 0.3168, global_step = 1500, loss = 4.7169304\r\n    INFO:tensorflow:Benchmark metric: Name accuracy, value 0, unit None, global_step 1500, extras []\r\n    INFO:tensorflow:Benchmark metric: Name loss, value 4, unit None, global_step 1500, extras []\r\n    INFO:tensorflow:Starting a training cycle: 3/250\r\n    INFO:tensorflow:Calling model_fn.\r\n    data_format:  channels_first\r\n    INFO:tensorflow:Done calling model_fn.\r\n    INFO:tensorflow:Create CheckpointSaverHook.\r\n    INFO:tensorflow:Graph was finalized.\r\n\r\n**Extra info** :  \r\nOs: Ubuntu 16.04  \r\nGPU: GTX1080  \r\nCPU: Intel 4790K  \r\nRAM : 20Gig  \r\nGPU Utilization : 99%    \r\n\r\n  [1]: https://github.com/tensorflow/models/tree/master/official/resnet\r\n  [2]: https://paste.ee/p/pN07i#s=2\r\n  [3]: https://paste.ee/p/pN07i#section0\r\n  [4]: https://paste.ee/p/pN07i#s=1", "comments": ["Estimator is not really my area but I have been looking into possible issues with estimator.  I have a few questions before I can look into this:\r\n\r\n- Can you link the PyTorch code?  Maybe I missed that link.  When I looked into this before I had easy to reproduce code with command lines.  Nothing is more frustrating than using my free time to figure something out to find out I am not using the exact same code.  \r\n-  How are you doing the timing?  I was glancing at the logs and I was not sure where the 50 and 90 seconds came from.   Once I have the code I want to first repro and verify the same amount of work is being done.\r\n\r\nI am not remotely refuting your situation.  I need exact information or I end up using up a lot of time not having enough details.  With no information and not being very experienced my guess is it may be the checkpoints, again that does not change the outcome and with epochs that are so fast anything will have a huge impact.  Again that does not change your experience with estimator and I want to end up with an action item if I am going to do the work.  I am some what looking into this with the ResNetV1 (V1.5) test on 1 GPU but this may be equally interesting and useful.  ", "Ideally, github repos rather than pasted bucket code, but I can build out my own app with the parts if needed.", "@tfboyd : Thanks a lot for the interest. here is what you asked for  : [TF_Pytorch_testbed](https://github.com/Coderx7/TF_Pytorch_testbed )  \r\nFor the  timing just look at the  elapsed time since the previous epoch consider these two: \r\n```\r\n==>>[2018-08-19 00:00:26] [Epoch=000/450] [Need: 00:00:00] [learning_rate=0.100000] [Best : Accuracy=0.00, Error=100.00]\r\n  Epoch: [000][000/500]   Time 1.345 (1.345)   Data 0.089 (0.089)   Loss 4.8846 (4.8846)   Prec@1 0.000 (0.000)   Prec@5 4.000 (4.000)   [2018-08-19 00:00:28]\r\n  Epoch: [000][200/500]   Time 0.089 (0.096)   Data 0.000 (0.001)   Loss 4.0047 (4.3586)   Prec@1 6.000 (3.771)   Prec@5 28.000 (14.930)   [2018-08-19 00:00:46]\r\n  Epoch: [000][400/500]   Time 0.089 (0.093)   Data 0.000 (0.000)   Loss 3.9328 (4.1781)   Prec@1 9.000 (5.519)   Prec@5 26.000 (20.142)   [2018-08-19 00:01:04]\r\n  **Train** Prec@1 6.352 Prec@5 22.334 Error@1 93.648\r\n  **Test** Prec@1 8.520 Prec@5 31.600 Error@1 91.480\r\n\r\n==>>[2018-08-19 00:01:17] [Epoch=001/450] [Need: 06:07:54] [learning_rate=0.100000] [Best : Accuracy=8.52, Error=91.48]\r\n  Epoch: [001][000/500]   Time 0.128 (0.128)   Data 0.086 (0.086)   Loss 3.7810 (3.7810)   Prec@1 9.000 (9.000)   Prec@5 34.000 (34.000)   [2018-08-19 00:01:17]\r\n  Epoch: [001][200/500]   Time 0.090 (0.090)   Data 0.000 (0.001)   Loss 3.5385 (3.7109)   Prec@1 18.000 (11.517)   Prec@5 39.000 (34.861)   [2018-08-19 00:01:35]\r\n  Epoch: [001][400/500]   Time 0.088 (0.090)   Data 0.000 (0.000)   Loss 3.6088 (3.6151)   Prec@1 11.000 (13.274)   Prec@5 34.000 (38.102)   [2018-08-19 00:01:54]\r\n  **Train** Prec@1 14.048 Prec@5 39.416 Error@1 85.952\r\n  **Test** Prec@1 19.110 Prec@5 45.950 Error@1 80.890\r\n```\r\n\r\nhere : \r\n```\r\n==>>[2018-08-19 00:00:26] [Epoch=000/450]  \r\n==>>[2018-08-19 00:01:17] [Epoch=001/450]  \r\n```\r\nfrom `00:00:26 ` to `00:01:17` which is 51 seconds.\r\n", "I will try to dig in but I suspect my crazy guess is that checkpoints will be a big part of it.  For the eval Estimator writes a checkpoint and then reads it back in, this would be really noticeable for fast epochs. \r\nJust a guess and I hope I find time to add in some print statements and timings to break the timing out.\r\n\r\nAnd if that is true, I also find that a bit frustrating and that is why I am interested as if I don't want that I would like the option to turn it off.  :-)  With pure session.run you would not have that or if using Eager.\r\n\r\nAnd Thank you for the nice sandbox.  I know it is work but it gives me a clean place to work knowing it is what you are using.  ", "@Coderx7 would you double-check that this script below has the same architecture as your \"simpnet\" (https://github.com/Coderx7/TF_Pytorch_testbed/blob/master/Pytorch/models/simpnet.py), uses the same input size of 32 and batch size of 100 ?\r\n\r\n<details><summary>code</summary>      \r\n\r\n```python\r\n\r\n#!/usr/bin/env python\r\n# -*- coding: utf-8 -*-\r\nimport tensorflow as tf\r\nimport argparse\r\nimport os\r\n\r\nfrom tensorpack import *\r\nfrom tensorpack.tfutils.summary import *\r\nfrom tensorpack.dataflow import dataset\r\n\r\n\r\nclass Model(ModelDesc):\r\n    def __init__(self, cifar_classnum):\r\n        super(Model, self).__init__()\r\n        self.cifar_classnum = cifar_classnum\r\n\r\n    def inputs(self):\r\n        return [tf.placeholder(tf.float32, (None, 32, 32, 3), 'input'),\r\n                tf.placeholder(tf.int32, (None,), 'label')]\r\n\r\n    def build_graph(self, image, label):\r\n        is_training = get_current_tower_context().is_training\r\n\r\n        image = tf.transpose(image, [0, 3, 1, 2])\r\n        data_format = 'channels_first'\r\n\r\n        with argscope(Conv2D, activation=BNReLU, use_bias=False, kernel_size=3), \\\r\n                argscope([Conv2D, MaxPooling, BatchNorm, GlobalAvgPooling], data_format=data_format):\r\n            logits = LinearWrap(image) \\\r\n                .Conv2D('conv1.1', filters=66) \\\r\n                .Conv2D('conv1.2', filters=128) \\\r\n                .Conv2D('conv2.1', filters=128) \\\r\n                .Conv2D('conv2.2', filters=128) \\\r\n                .Conv2D('conv2.3', filters=192) \\\r\n                .MaxPooling('pool2', 2, stride=2, padding='SAME') \\\r\n                .tf.nn.dropout(0.95) \\\r\n                .Conv2D('conv4.1', filters=192) \\\r\n                .Conv2D('conv4.2', filters=192) \\\r\n                .Conv2D('conv4.3', filters=192) \\\r\n                .Conv2D('conv4.4', filters=192) \\\r\n                .Conv2D('conv4.5', filters=288) \\\r\n                .MaxPooling('pool2', 2, stride=2, padding='SAME') \\\r\n                .tf.nn.dropout(0.95) \\\r\n                .Conv2D('conv5.1', filters=288) \\\r\n                .Conv2D('conv5.2', filters=355) \\\r\n                .Conv2D('conv5.3', filters=432) \\\r\n                .GlobalAvgPooling('gap') \\\r\n                .FullyConnected('linear', out_dim=self.cifar_classnum)()\r\n\r\n        cost = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=label)\r\n        cost = tf.reduce_mean(cost, name='cross_entropy_loss')\r\n\r\n        correct = tf.to_float(tf.nn.in_top_k(logits, label, 1), name='correct')\r\n        # monitor training error\r\n        add_moving_summary(tf.reduce_mean(correct, name='accuracy'))\r\n\r\n        # weight decay on all W of fc layers\r\n        wd_cost = regularize_cost('fc.*/W', l2_regularizer(4e-4), name='regularize_loss')\r\n        add_moving_summary(cost, wd_cost)\r\n\r\n        add_param_summary(('.*/W', ['histogram']))   # monitor W\r\n        return tf.add_n([cost, wd_cost], name='cost')\r\n\r\n    def optimizer(self):\r\n        lr = tf.get_variable('learning_rate', initializer=1e-2, trainable=False)\r\n        tf.summary.scalar('lr', lr)\r\n        return tf.train.AdamOptimizer(lr, epsilon=1e-3)\r\n\r\n\r\ndef get_data(train_or_test, cifar_classnum):\r\n    isTrain = train_or_test == 'train'\r\n    if cifar_classnum == 10:\r\n        ds = dataset.Cifar10(train_or_test)\r\n    else:\r\n        ds = dataset.Cifar100(train_or_test)\r\n    if isTrain:\r\n        augmentors = [\r\n            imgaug.RandomCrop((32, 32)),\r\n            imgaug.Flip(horiz=True),\r\n            imgaug.Brightness(63),\r\n            imgaug.Contrast((0.2, 1.8)),\r\n            imgaug.MeanVarianceNormalize(all_channel=True)\r\n        ]\r\n    else:\r\n        augmentors = [\r\n            imgaug.CenterCrop((32, 32)),\r\n            imgaug.MeanVarianceNormalize(all_channel=True)\r\n        ]\r\n    ds = AugmentImageComponent(ds, augmentors)\r\n    ds = BatchData(ds, 100, remainder=not isTrain)\r\n    if isTrain:\r\n        ds = PrefetchDataZMQ(ds, 5)\r\n    return ds\r\n\r\n\r\ndef get_config(cifar_classnum):\r\n    # prepare dataset\r\n    dataset_train = get_data('train', cifar_classnum)\r\n    dataset_test = get_data('test', cifar_classnum)\r\n    return TrainConfig(\r\n        model=Model(cifar_classnum),\r\n        data=QueueInput(dataset_train),\r\n        callbacks=[\r\n            ModelSaver(),\r\n            InferenceRunner(dataset_test,\r\n                            ScalarStats(['accuracy', 'cost'])),\r\n        ],\r\n        max_epoch=150,\r\n    )\r\n\r\n\r\nif __name__ == '__main__':\r\n    with tf.Graph().as_default():\r\n        logger.set_logger_dir(os.path.join('train_log', 'cifar' + str(10)))\r\n        config = get_config(10)\r\n\r\n        trainer = SimpleTrainer()\r\n        launch_train_with_config(config, trainer)\r\n```\r\n </details>\r\n\r\n\r\nI only copied an existing cifar10 training script and modify the relevant parts. It would take you some time but at least it's only 100 lines to read. https://github.com/Coderx7/TF_Pytorch_testbed/tree/master/TF/simpnet has much more lines of code for me to read on the other hand.\r\n\r\nYou can run it by `pip install git+https://github.com/tensorpack/tensorpack.git; python thisfile.py`. On my machine it does run faster (30 seconds per epoch) than your pytorch code (37 seconds with `bash train_cifar10.sh`), ignoring the first epoch.", "@ppwwyyxx : Thanks for the code, except for a couple of differences, it's the same architecture(it needs `GlobalMaxPoling` instead of the `GlobalAvgPooling` and also biases needed to be enabled, the preprocessing and optimization policy are not considered that important for the moment and the overall architecture seems correct). \r\nThe speed is significantly faster than our TF example! it has nearly the same speed of Pytorch( its only 2-3 seconds slower). \r\nAfter setting `use_bias=True`, and changing Adam to SGD for both scripts, I get 47 to 48 seconds an epoch in Pytorch and 50-51 seconds in your code! \r\n\r\n<details>\r\n<summary>Code</summary>\r\n\r\n```python\r\n#!/usr/bin/env python\r\n# -*- coding: utf-8 -*-\r\nimport tensorflow as tf\r\nimport argparse\r\nimport os\r\n\r\nfrom tensorpack import *\r\nfrom tensorpack.tfutils.summary import *\r\nfrom tensorpack.dataflow import dataset\r\nimport tflearn\r\n\r\nclass Model(ModelDesc):\r\n    def __init__(self, cifar_classnum):\r\n        super(Model, self).__init__()\r\n        self.cifar_classnum = cifar_classnum\r\n\r\n    def inputs(self):\r\n        return [tf.placeholder(tf.float32, (None, 32, 32, 3), 'input'),\r\n                tf.placeholder(tf.int32, (None,), 'label')]\r\n\r\n    def build_graph(self, image, label):\r\n        is_training = get_current_tower_context().is_training\r\n\r\n        image = tf.transpose(image, [0, 3, 1, 2])\r\n        data_format = 'channels_first'\r\n\r\n        with argscope(Conv2D, activation=BNReLU, use_bias=True, kernel_size=3), \\\r\n                argscope([Conv2D, MaxPooling, BatchNorm], data_format=data_format):\r\n            logits = LinearWrap(image) \\\r\n                .Conv2D('conv1.1', filters=66) \\\r\n                .Conv2D('conv1.2', filters=128) \\\r\n                .Conv2D('conv2.1', filters=128) \\\r\n                .Conv2D('conv2.2', filters=128) \\\r\n                .Conv2D('conv2.3', filters=192) \\\r\n                .MaxPooling('pool2', 2, stride=2, padding='SAME') \\\r\n                .tf.nn.dropout(0.95) \\\r\n                .Conv2D('conv4.1', filters=192) \\\r\n                .Conv2D('conv4.2', filters=192) \\\r\n                .Conv2D('conv4.3', filters=192) \\\r\n                .Conv2D('conv4.4', filters=192) \\\r\n                .Conv2D('conv4.5', filters=288) \\\r\n                .MaxPooling('pool2', 2, stride=2, padding='SAME') \\\r\n                .tf.nn.dropout(0.95) \\\r\n                .Conv2D('conv5.1', filters=288) \\\r\n                .Conv2D('conv5.2', filters=355) \\\r\n                .Conv2D('conv5.3', filters=432)() \r\n            logits = tflearn.layers.conv.global_max_pool (logits, name='GlobalMaxPool')\r\n            logits = LinearWrap(logits) \\\r\n                .FullyConnected('linear', out_dim=self.cifar_classnum)()\r\n\r\n        cost = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=label)\r\n        cost = tf.reduce_mean(cost, name='cross_entropy_loss')\r\n\r\n        correct = tf.to_float(tf.nn.in_top_k(logits, label, 1), name='correct')\r\n        # monitor training error\r\n        add_moving_summary(tf.reduce_mean(correct, name='accuracy'))\r\n\r\n        # weight decay on all W of fc layers\r\n        wd_cost = regularize_cost('fc.*/W', l2_regularizer(4e-4), name='regularize_loss')\r\n        add_moving_summary(cost, wd_cost)\r\n\r\n        add_param_summary(('.*/W', ['histogram']))   # monitor W\r\n        return tf.add_n([cost, wd_cost], name='cost')\r\n\r\n    def optimizer(self):\r\n        lr = tf.get_variable('learning_rate', initializer=1e-2, trainable=False)\r\n        tf.summary.scalar('lr', lr)\r\n        return tf.train.GradientDescentOptimizer(lr)\r\n\r\n\r\ndef get_data(train_or_test, cifar_classnum):\r\n    isTrain = train_or_test == 'train'\r\n    if cifar_classnum == 10:\r\n        ds = dataset.Cifar10(train_or_test)\r\n    else:\r\n        ds = dataset.Cifar100(train_or_test)\r\n    if isTrain:\r\n        augmentors = [\r\n            imgaug.RandomCrop((32, 32)),\r\n            imgaug.Flip(horiz=True),\r\n            imgaug.Brightness(63),\r\n            imgaug.Contrast((0.2, 1.8)),\r\n            imgaug.MeanVarianceNormalize(all_channel=True)\r\n        ]\r\n    else:\r\n        augmentors = [\r\n            imgaug.CenterCrop((32, 32)),\r\n            imgaug.MeanVarianceNormalize(all_channel=True)\r\n        ]\r\n    ds = AugmentImageComponent(ds, augmentors)\r\n    ds = BatchData(ds, 100, remainder=not isTrain)\r\n    if isTrain:\r\n        ds = PrefetchDataZMQ(ds, 5)\r\n    return ds\r\n\r\n\r\ndef get_config(cifar_classnum):\r\n    # prepare dataset\r\n    dataset_train = get_data('train', cifar_classnum)\r\n    dataset_test = get_data('test', cifar_classnum)\r\n    return TrainConfig(\r\n        model=Model(cifar_classnum),\r\n        data=QueueInput(dataset_train),\r\n        callbacks=[\r\n            ModelSaver(),\r\n            InferenceRunner(dataset_test,\r\n                            ScalarStats(['accuracy', 'cost'])),\r\n        ],\r\n        max_epoch=150,\r\n    )\r\n\r\n\r\nif __name__ == '__main__':\r\n    with tf.Graph().as_default():\r\n        logger.set_logger_dir(os.path.join('train_log', 'cifar' + str(10)))\r\n        config = get_config(10)\r\n\r\n        trainer = SimpleTrainer()\r\n        launch_train_with_config(config, trainer)\r\n```\r\n</details>\r\n\r\nHere is the log for tensorpack snippet: \r\n```\r\n100%|###################################################################################################|500/500[00:47<00:00,10.60it/s]\r\n[0831 13:28:01 @base.py:260] Epoch 3 (global_step 1500) finished, time:47.2 seconds.\r\n[0831 13:28:01 @saver.py:77] Model saved to train_log/cifar10/model-1500.\r\n100%|###################################################################################################|100/100[00:04<00:00,22.37it/s]\r\n[0831 13:28:06 @monitor.py:435] QueueInput/queue_size: 50\r\n[0831 13:28:06 @monitor.py:435] accuracy: 0.62778\r\n[0831 13:28:06 @monitor.py:435] cross_entropy_loss: 1.0565\r\n[0831 13:28:06 @monitor.py:435] lr: 0.01\r\n[0831 13:28:06 @monitor.py:435] regularize_loss_internals/empty_regularize_loss: 0\r\n[0831 13:28:06 @monitor.py:435] validation_accuracy: 0.6072\r\n[0831 13:28:06 @monitor.py:435] validation_cost: 1.1003\r\n[0831 13:28:06 @group.py:48] Callbacks took 4.524 sec in total. InferenceRunner: 4.47 seconds\r\n[0831 13:28:06 @base.py:250] Start Epoch 4 ...\r\n100%|###################################################################################################|500/500[00:46<00:00,10.69it/s]\r\n[0831 13:28:53 @base.py:260] Epoch 4 (global_step 2000) finished, time:46.8 seconds.\r\n[0831 13:28:53 @saver.py:77] Model saved to train_log/cifar10/model-2000.\r\n100%|###################################################################################################|100/100[00:04<00:00,22.46it/s]\r\n[0831 13:28:57 @monitor.py:435] QueueInput/queue_size: 50\r\n[0831 13:28:57 @monitor.py:435] accuracy: 0.664\r\n[0831 13:28:57 @monitor.py:435] cross_entropy_loss: 0.9451\r\n[0831 13:28:57 @monitor.py:435] lr: 0.01\r\n[0831 13:28:57 @monitor.py:435] regularize_loss_internals/empty_regularize_loss: 0\r\n[0831 13:28:57 @monitor.py:435] validation_accuracy: 0.6025\r\n[0831 13:28:57 @monitor.py:435] validation_cost: 1.0947\r\n[0831 13:28:57 @group.py:48] Callbacks took 4.505 sec in total. InferenceRunner: 4.45 seconds\r\n[0831 13:28:57 @base.py:250] Start Epoch 5 ...\r\n100%|###################################################################################################|500/500[00:46<00:00,10.68it/s]\r\n[0831 13:29:44 @base.py:260] Epoch 5 (global_step 2500) finished, time:46.8 seconds.\r\n[0831 13:29:44 @saver.py:77] Model saved to train_log/cifar10/model-2500.\r\n100%|###################################################################################################|100/100[00:04<00:00,22.10it/s]\r\n[0831 13:29:49 @monitor.py:435] QueueInput/queue_size: 50\r\n[0831 13:29:49 @monitor.py:435] accuracy: 0.69861\r\n[0831 13:29:49 @monitor.py:435] cross_entropy_loss: 0.86407\r\n[0831 13:29:49 @monitor.py:435] lr: 0.01\r\n[0831 13:29:49 @monitor.py:435] regularize_loss_internals/empty_regularize_loss: 0\r\n[0831 13:29:49 @monitor.py:435] validation_accuracy: 0.6526\r\n[0831 13:29:49 @monitor.py:435] validation_cost: 0.99593\r\n[0831 13:29:49 @group.py:48] Callbacks took 4.584 sec in total. InferenceRunner: 4.53 seconds\r\n```\r\nand here is pytorchs.  taking 47~48 seconds per each epoch!: \r\n```\r\n==>>[2018-08-31 13:32:02] [Epoch=002/450] [Need: 06:01:19] [learning_rate=0.010000] [Best : Accuracy=67.96, Error=32.04]\r\n  Epoch: [002][000/500]   Time 0.124 (0.124)   Data 0.088 (0.088)   Loss 0.9159 (0.9159)   Prec@1 63.000 (63.000)   Prec@5 98.000 (98.000)   [2018-08-31 13:32:02]\r\n  Epoch: [002][200/500]   Time 0.086 (0.088)   Data 0.000 (0.001)   Loss 0.8868 (0.8391)   Prec@1 75.000 (70.204)   Prec@5 97.000 (97.532)   [2018-08-31 13:32:19]\r\n  Epoch: [002][400/500]   Time 0.089 (0.088)   Data 0.000 (0.000)   Loss 0.7823 (0.8075)   Prec@1 74.000 (71.436)   Prec@5 99.000 (97.701)   [2018-08-31 13:32:37]\r\n  **Train** Prec@1 72.076 Prec@5 97.844 Error@1 27.924\r\n  **Test** Prec@1 72.950 Prec@5 98.340 Error@1 27.050\r\n---- save figure the accuracy/loss curve of train/val into ./snapshots/simpnet/plot_simpnet_cifar10_2018-08-31_13-30-12.png\r\n\r\n==>>[2018-08-31 13:32:49] [Epoch=003/450] [Need: 05:59:12] [learning_rate=0.010000] [Best : Accuracy=72.95, Error=27.05]\r\n  Epoch: [003][000/500]   Time 0.128 (0.128)   Data 0.093 (0.093)   Loss 0.7271 (0.7271)   Prec@1 71.000 (71.000)   Prec@5 99.000 (99.000)   [2018-08-31 13:32:50]\r\n  Epoch: [003][200/500]   Time 0.087 (0.089)   Data 0.000 (0.001)   Loss 0.6078 (0.6848)   Prec@1 77.000 (76.075)   Prec@5 99.000 (98.478)   [2018-08-31 13:33:07]\r\n  Epoch: [003][400/500]   Time 0.089 (0.089)   Data 0.000 (0.000)   Loss 0.5587 (0.6702)   Prec@1 80.000 (76.571)   Prec@5 99.000 (98.539)   [2018-08-31 13:33:25]\r\n  **Train** Prec@1 76.814 Prec@5 98.574 Error@1 23.186\r\n  **Test** Prec@1 76.680 Prec@5 98.350 Error@1 23.320\r\n---- save figure the accuracy/loss curve of train/val into ./snapshots/simpnet/plot_simpnet_cifar10_2018-08-31_13-30-12.png\r\n\r\n==>>[2018-08-31 13:33:37] [Epoch=004/450] [Need: 05:58:06] [learning_rate=0.010000] [Best : Accuracy=76.68, Error=23.32]\r\n  Epoch: [004][000/500]   Time 0.125 (0.125)   Data 0.090 (0.090)   Loss 0.6046 (0.6046)   Prec@1 82.000 (82.000)   Prec@5 98.000 (98.000)   [2018-08-31 13:33:38]\r\n  Epoch: [004][200/500]   Time 0.088 (0.088)   Data 0.000 (0.001)   Loss 0.5484 (0.5916)   Prec@1 83.000 (79.104)   Prec@5 99.000 (98.716)   [2018-08-31 13:33:55]\r\n  Epoch: [004][400/500]   Time 0.088 (0.088)   Data 0.000 (0.000)   Loss 0.7405 (0.5849)   Prec@1 76.000 (79.536)   Prec@5 98.000 (98.778)   [2018-08-31 13:34:13]\r\n  **Train** Prec@1 79.616 Prec@5 98.822 Error@1 20.384\r\n  **Test** Prec@1 80.310 Prec@5 98.710 Error@1 19.690\r\n---- save figure the accuracy/loss curve of train/val into ./snapshots/simpnet/plot_simpnet_cifar10_2018-08-31_13-30-12.png\r\n\r\n```\r\nThis is indeed a massive speed up compared to the 2 times slower original TF implementation!!! \r\n", "Huge thank you to @ppwwyyxx.  I need to catch up on this thread in a couple of days in detail.  I will leave it open until I can process everything and looking through all the code.  I want to see if there is anything we can do to the stock example.  ", "I experience a similar problem with TF Eager (2-3x times slower than PyTorch for similar code):\r\n\r\noriginal PyTorch code: https://github.com/sfujim/TD3\r\n\r\nmy TFE port:  https://github.com/ikostrikov/TD3\r\n\r\n```bash\r\npython main.py --env HalfCheetah-v1 --eval_fraq 1000000\r\n```\r\n", "@tfboyd : any luck on finding some spare time working on this ? \r\nany feedback is greatly appreciated.", "@ikostrikov   You will want to open a new issue to get it assigned, there are people that specialize in the TFEager and can look over the port. For this issue it seems closed as the difference for the original issue is a few seconds and a small percentage.  ", "@tfboyd I still dont know which part of the code in the original tf implementation is responsible for such drastic performance degeradation! and the whole story around that issue still presists. \r\nthe new example shows the TF foundation is pretty fast and reliable however, there is definitely something wrong with the current implementation. \r\n", "@Coderx7 are there any good practices for TFEager?", "@ikostrikov Can you please open a new issue?  It is frustrating that you are treating this issue like an open forum.  This is kind of rude to Coderx7 as it takes away from discussion from the issue.\r\n\r\n@Coderx7   I monitor and the ImageNet pipeline in this example but I do not do much with the CIFAR10 aspect.  At 50 seconds or even 2 minutes for an epoch it is interesting but with a large number of things to sort out it does not bubble to the top as doing this deeply means not doing something else.  We are working on the pipeline and I will try to start monitoring both cifar10 and imagennet performance going forward.  It also may not be the input pipeline at all but I like to start there as that has a big impact.", "@tfboyd I appreciate that, thank you very much for your efforts on this.\r\n@ikostrikov: sorry, I have no clue concerning that.", "really need group conv", "HI there, I just found that using `use_bias=False` in a very small LSTM network caused SIGNIFICANT slowdowns. Possibly related? (Tf2) (2 layers LSTM, went from 10s to 9 minutes per epoch)", "@Coderx7 \r\nplease let us know if the issue still persist", "@Coderx7\r\ncould you please update on the above comment", "@Saduf2019 : sorry for replying late. \r\nI gave up on TF after oct 24 2018 as I couldnt get this to work. ", "In fact the issue that \"Tensorflow nearly 2 times slower than Pytorch in training\" never exists in this thread, to some extent. As shown by comments above https://github.com/tensorflow/tensorflow/issues/21881#issuecomment-417670550, the reported model can train in TensorFlow as fast as pytorch, if implemented in a better way. \r\n\r\nThe problem was actually about a bad implementation in tensorflow/models that's 2x slower. If the problem still exists it should have been an issue of tensorflow/models instead.", "@Coderx7\r\nPlease confirm if we may move this to closed status", "it might be a good idea to run it again and make it clear what the underlying issue was and if it still persists. As ppwwyyxx said, using tensorpack, we achieved great speed, however, the example from the official tensorflow repository was extremely slow. \r\nWhich operations/api calls made it that slow is not yet apparent. \r\nwe didnt solve the original issue, since we didnt use the very same ops/api calls in that example. \r\nif you think its worth checking out, then by all means give it a go all the scripts are previously posted and can be run. otherwise I'm fine with closing this as I no longer develop using TF. \r\nHave a great day ", "with confirmation moving the issue to closed status"]}, {"number": 21880, "title": "no such package '@png_archive//", "body": "When I compile tensorflow 1.10 from source code on windows10, it reported the error \"no such package '@png_archive//\"\r\nI have installed the bazel, msys2, vs2017 and set the environment of PAHT,bazel_sh,bazel_vc.", "comments": ["@meteorcloudy \r\n\r\nPlease provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\nMake sure you also include the exact command if possible to produce the output included in your test case. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new).\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!\r\n", "@yanhaiming56 Can you provide information about which Bazel version you are using and the exact error message? \r\nAlthough you shouldn't have to, but did you try run `bazel clean --expunge` before running the build command?", "@gunan @meteorcloudy \r\n\r\nOS                   centos 7\r\ntf version         1.9.0\r\nbazel version   0.15.2\r\ncuda version    9.0\r\ncudnn version  7201\r\nnccl version      2.2.13\r\n\r\nI compiled tf-serving 1.9.0 , and this error occured while loading @org_tensorflow. Here is my compiling comand\r\n\r\n`bazel build -c opt --color=yes --curses=yes --config=cuda  --verbose_failures --local_resources=4096,1.0,1.0 --output_filter=DONT_MATCH_ANYTHING --copt=-mavx --cxxopt=-D_GLIBCXX_USE_CXX11_ABI=0 tensorflow_serving/model_servers:tensorflow_model_server`  \r\n\r\nActually, there was nothing happened while using ubuntu. But our project forced us to use centos, and I met this error. ", "@elvys-zhang Can you provide the exact error message Bazel output? I'm not able to reproduce the same issue on my Linux machine.", "Having the same problem. \r\nWindows 10\r\nbazel 0.16.1\r\ntensorflow 1.10.1\r\n\r\n`bazel --output_user_root=build_temp build -c opt --copt=/arch:AVX tensorflow:libtensorflow_cc.so`\r\n\r\ngot this command from the \\tensorflow\\tools\\ci_build\\windows\\libtensorflow_cpu.sh\r\nError message:\r\n> Stdout:\r\n> Stderr: /usr/bin/bash: patch: Could not find command\r\n>  and referenced by '//tensorflow/core/platform/default/build_config:png'", "@meteorcloudy Have figured it out. I missed some info before. After installing patch by \"yum install -y patch\", it worked fine. Thx.", "@PinkySan Please refer to this doc to build TF on windows:\r\nhttps://www.tensorflow.org/install/install_sources_windows\r\n\r\nYou should not be building libtensorflow_cc.so on windows.\r\nHowever, the problem you are facing is due to missing packages on your system\r\n`/usr/bin/bash: patch: Could not find command`\r\nPlease see the bazel installation instructions, and make sure you follow all the steps.\r\n\r\nLooks like the initial report is missing vital information, and later reported issues do not seem to fully relate to the original issue.\r\nClosing until we get the detailed information we need to debug.", "@gunan \r\n\r\n> You should not be building libtensorflow_cc.so on windows.\r\n\r\nHow can we use C++ Tensorflow on Windows therefore?", "@meteorcloudy @asimshankar to include in the discussion.\r\nBut the \".so\" file extensions are the shared object extensions for linux.\r\nUnless bazel intelligently replaces the \"so\" with \"dll\", your OS would be confused trying to load the resulting \"so\" file.\r\n\r\nIf bazel does this intelligently, still our build target should not have the \"so\" extension.\r\nIt should just be libtensorflow, and on macos the result will be a dylib, on windows it will be a dll, on linux it will be a so.", "@UndeadBlow You might find this script useful:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/ci_build/windows/libtensorflow_cpu.sh\r\n\r\nAs pointed out by @gunan, the .so file built is actually a .dll file on Windows, you'll have to rename it to .dll to make it work on Windows.", "Do you rename the generated file from *.so into *.dll or do you rename it in the sh-file? Why does bazel not provide an OS independent target? \r\n\r\n@UndeadBlow That is the big question. ", "@PinkySan you can just rename the generated file. The reason it's still generating a .so file on Windows is because the .so extension is embedded in the target name. This issue will be resolved in the future. Sorry for the trouble.", "@meteorcloudy That is a very uncommon behaviour. If it is a known problem, i can totally live with that. But does bazel support an installing target? It is pretty simple in CMake to create an INSTALL-Target, which contains the relevant binaries, includes, etc.\r\n\r\nI therefore cannot understand the release note in 1.10, which discontinues the CMake support. Especially the integration of c++ tensorflow into another c++ project with CMake is really simple\r\n\r\n`find_package(Tensorflow)`\r\n`add_executable(myExe ...)`\r\n`target_link_libraries(myExe PRIVATE tensorflow)`\r\n\r\n#21409", "@PinkySan I totally understand your concern. I'll be working on a solution to make the C++ library easier to use on Windows.", "I used following command to fix the issue on windows.\r\npip install png", "install patch", "pacman -S msys/patch", "I solved this problem by using a VPN network.If the problem is different when you're trying , I guess  you like me the problem is due to the local network of your operator or country . "]}, {"number": 21879, "title": "Failed to test mpi_allreduce_test.py", "body": "Have I written custom code: None\r\nOS Platform and Distribution: Linux Centos 7.0\r\nOpen MPI version: 3.1.1\r\nTensorFlow installed from: r1.8\r\nBazel version: 0.10.1\r\nPython version: 2.7\r\nGCC version:  4.9.2\r\nCUDA/cuDNN version: N/A\r\nGPU model and memory: N/A\r\nExact command to reproduce: mpirun -np 4 python mpi_allreduce_test.py under directory tensorflow/tensorflow/contrib/mpi_collectives\r\n\r\nmpirun -np 1 python mpi_allgather_test.py ;the test pass.\r\nmpirun -np 3 python mpi_allgather_test.py ;the test pass.\r\nmpirun -np 1 python mpi_allreduce_test.py ;the test pass.\r\nbut when I run mpirun -np 3 python mpi_allreduce_test.py, the test failed\r\n\r\n```\r\n1: iter 0\r\nrank 2: My output is 330772870.0\r\nrank 2: Our output is 170543409.0\r\nrank 0: My output is 11908270.0\r\nrank 0: Our output is 170543409.0\r\n2: iter 0\r\n0: iter 0\r\n[e92e09614.em21:08680] Read -1, expected 2362084, errno = 38\r\n[e92e09614.em21:08681] Read -1, expected 2362080, errno = 38\r\n[e92e09614.em21:08679] Read -1, expected 2362080, errno = 38\r\n[e92e09614.em21:08680] Read -1, expected 2362080, errno = 38\r\n[e92e09614.em21:08681] Read -1, expected 2362084, errno = 38\r\n[e92e09614.em21:08679] Read -1, expected 2362080, errno = 38\r\n[e92e09614.em21:08680] Read -1, expected 2362080, errno = 38\r\n```", "comments": ["@jthestness I have created a new issue from here https://github.com/tensorflow/tensorflow/issues/18092. Appleciate for your help.", "Hi @chengdianxuezi: It looks like this is likely an issue related to handling of environment variables in the test. OpenMPI has changed the way it exports local variables for the communicator size and the worker's rank ID. The code in `mpi_allreduce_test.py`, lines 55-56, read the rank and size from these environment variables. I believe OpenMPI 3.x exports these variables to the ranks using variable names `OMPI_COMM_WORLD_RANK` and `OMPI_COMM_WORLD_SIZE` rather than `PMI_RANK` and `PMI_SIZE` as defined in the code. You can try changing the way the test reads these variables.\r\n\r\nTo be sure of how your MPI installation exports these variables, run the following test (which should work with any MPI distribution or version):\r\n```\r\n$~ mpirun -np 3 python3 -c \"import os;print(os.environ)\"\r\n```\r\nIt will print the environment dictionary, including the MPI-defined variables.", "Hi @jthestness  before run the test, I have changed these variables name,\r\n```\r\n    # Get MPI rank\r\n    #my_rank = int(os.environ['PMI_RANK'])\r\n    #num_ranks = int(os.environ['PMI_SIZE'])\r\n\r\n    my_rank = int(os.environ[\"OMPI_COMM_WORLD_RANK\"])\r\n    MPI_LOCAL_RANK = int(os.environ[\"OMPI_COMM_WORLD_LOCAL_RANK\"])\r\n    num_ranks = int(os.environ[\"OMPI_COMM_WORLD_SIZE\"])\r\n```\r\nthe result of mpirun -np 3 python3 -c \"import os;print(os.environ)\" as follow:\r\n````\r\n 'OMPI_APP_CTX_NUM_PROCS': '3'\r\n 'OMPI_APP_CTX_NUM_PROCS': '3'\r\n 'OMPI_APP_CTX_NUM_PROCS': '3'\r\n 'OMPI_ARGV': '-c import os;print(os.environ)'\r\n 'OMPI_ARGV': '-c import os;print(os.environ)'\r\n 'OMPI_ARGV': '-c import os;print(os.environ)'\r\n 'OMPI_COMMAND': 'python'\r\n 'OMPI_COMMAND': 'python'\r\n 'OMPI_COMMAND': 'python'\r\n 'OMPI_COMM_WORLD_LOCAL_RANK': '0'\r\n 'OMPI_COMM_WORLD_LOCAL_RANK': '1'\r\n 'OMPI_COMM_WORLD_LOCAL_RANK': '2'\r\n 'OMPI_COMM_WORLD_LOCAL_SIZE': '3'\r\n 'OMPI_COMM_WORLD_LOCAL_SIZE': '3'\r\n 'OMPI_COMM_WORLD_LOCAL_SIZE': '3'\r\n 'OMPI_COMM_WORLD_NODE_RANK': '0'\r\n 'OMPI_COMM_WORLD_NODE_RANK': '1'\r\n 'OMPI_COMM_WORLD_NODE_RANK': '2'\r\n 'OMPI_COMM_WORLD_RANK': '0'\r\n 'OMPI_COMM_WORLD_RANK': '1'\r\n 'OMPI_COMM_WORLD_RANK': '2'\r\n 'OMPI_COMM_WORLD_SIZE': '3'\r\n 'OMPI_COMM_WORLD_SIZE': '3'\r\n 'OMPI_COMM_WORLD_SIZE': '3'\r\n 'OMPI_FILE_LOCATION': '/tmp/ompi.e92e09614.130324/pid.24691/0/0'\r\n 'OMPI_FILE_LOCATION': '/tmp/ompi.e92e09614.130324/pid.24691/0/0'\r\n 'OMPI_FILE_LOCATION': '/tmp/ompi.e92e09614.130324/pid.24691/0/0'\r\n 'OMPI_FIRST_RANKS': '0'\r\n 'OMPI_FIRST_RANKS': '0'\r\n 'OMPI_FIRST_RANKS': '0'\r\n 'OMPI_MCA_ess_base_jobid': '2824536065'\r\n 'OMPI_MCA_ess_base_jobid': '2824536065'\r\n 'OMPI_MCA_ess_base_jobid': '2824536065'\r\n 'OMPI_MCA_ess_base_vpid': '0'\r\n 'OMPI_MCA_ess_base_vpid': '1'\r\n 'OMPI_MCA_ess_base_vpid': '2'\r\n 'OMPI_MCA_ess': '^singleton'\r\n 'OMPI_MCA_ess': '^singleton'\r\n 'OMPI_MCA_ess': '^singleton'\r\n 'OMPI_MCA_initial_wdir': '/home/xiangqin.oxq/test/tensorflow_mpi/tensorflow/contrib/mpi_collectives'\r\n 'OMPI_MCA_initial_wdir': '/home/xiangqin.oxq/test/tensorflow_mpi/tensorflow/contrib/mpi_collectives'\r\n 'OMPI_MCA_initial_wdir': '/home/xiangqin.oxq/test/tensorflow_mpi/tensorflow/contrib/mpi_collectives'\r\n 'OMPI_MCA_mpi_yield_when_idle': '0'\r\n 'OMPI_MCA_mpi_yield_when_idle': '0'\r\n 'OMPI_MCA_mpi_yield_when_idle': '0'\r\n 'OMPI_MCA_orte_app_num': '0'\r\n 'OMPI_MCA_orte_app_num': '0'\r\n 'OMPI_MCA_orte_app_num': '0'\r\n 'OMPI_MCA_orte_bound_at_launch': '1'\r\n 'OMPI_MCA_orte_bound_at_launch': '1'\r\n 'OMPI_MCA_orte_bound_at_launch': '1'\r\n 'OMPI_MCA_orte_ess_node_rank': '0'\r\n 'OMPI_MCA_orte_ess_node_rank': '1'\r\n 'OMPI_MCA_orte_ess_node_rank': '2'\r\n 'OMPI_MCA_orte_ess_num_procs': '3'\r\n 'OMPI_MCA_orte_ess_num_procs': '3'\r\n 'OMPI_MCA_orte_ess_num_procs': '3'\r\n 'OMPI_MCA_orte_hnp_uri': '2824536064.0;tcp://11.251.181.233\r\n 'OMPI_MCA_orte_hnp_uri': '2824536064.0;tcp://11.251.181.233\r\n 'OMPI_MCA_orte_hnp_uri': '2824536064.0;tcp://11.251.181.233\r\n 'OMPI_MCA_orte_jobfam_session_dir': '/tmp/ompi.e92e09614.130324/pid.24691'}\r\n 'OMPI_MCA_orte_jobfam_session_dir': '/tmp/ompi.e92e09614.130324/pid.24691'}\r\n 'OMPI_MCA_orte_jobfam_session_dir': '/tmp/ompi.e92e09614.130324/pid.24691'}\r\n 'OMPI_MCA_orte_launch': '1'\r\n 'OMPI_MCA_orte_launch': '1'\r\n 'OMPI_MCA_orte_launch': '1'\r\n 'OMPI_MCA_orte_local_daemon_uri': '2824536064.0;tcp://11.251.181.233\r\n 'OMPI_MCA_orte_local_daemon_uri': '2824536064.0;tcp://11.251.181.233\r\n 'OMPI_MCA_orte_local_daemon_uri': '2824536064.0;tcp://11.251.181.233\r\n 'OMPI_MCA_orte_num_nodes': '1'\r\n 'OMPI_MCA_orte_num_nodes': '1'\r\n 'OMPI_MCA_orte_num_nodes': '1'\r\n 'OMPI_MCA_orte_precondition_transports': '06998b4baaf1c143-656e40a9edb68e84'\r\n 'OMPI_MCA_orte_precondition_transports': '06998b4baaf1c143-656e40a9edb68e84'\r\n 'OMPI_MCA_orte_precondition_transports': '06998b4baaf1c143-656e40a9edb68e84'\r\n 'OMPI_MCA_orte_tmpdir_base': '/tmp'\r\n 'OMPI_MCA_orte_tmpdir_base': '/tmp'\r\n 'OMPI_MCA_orte_tmpdir_base': '/tmp'\r\n 'OMPI_MCA_orte_top_session_dir': '/tmp/ompi.e92e09614.130324'\r\n 'OMPI_MCA_orte_top_session_dir': '/tmp/ompi.e92e09614.130324'\r\n 'OMPI_MCA_orte_top_session_dir': '/tmp/ompi.e92e09614.130324'\r\n 'OMPI_MCA_pmix': '^s1\r\n 'OMPI_MCA_pmix': '^s1\r\n 'OMPI_MCA_pmix': '^s1\r\n 'OMPI_MCA_shmem_RUNTIME_QUERY_hint': 'mmap'\r\n 'OMPI_MCA_shmem_RUNTIME_QUERY_hint': 'mmap'\r\n 'OMPI_MCA_shmem_RUNTIME_QUERY_hint': 'mmap'\r\n 'OMPI_NUM_APP_CTX': '1'\r\n 'OMPI_NUM_APP_CTX': '1'\r\n 'OMPI_NUM_APP_CTX': '1'\r\n 'OMPI_UNIVERSE_SIZE': '32'\r\n 'OMPI_UNIVERSE_SIZE': '32'\r\n 'OMPI_UNIVERSE_SIZE': '32'\r\n\r\n````\r\n\r\nwhen I run: mpirun -np 3 python mpi_allreduce_test.py,also have the error message.but the test past finally.\r\nI am not sure if this is normal\r\n\r\n```\r\n[e92e09614.em21:29605] Read -1, expected 2362080, errno = 38\r\n[e92e09614.em21:29603] Read -1, expected 2362080, errno = 38\r\n[e92e09614.em21:29604] Read -1, expected 2362084, errno = 38\r\n[e92e09614.em21:29603] Read -1, expected 2362080, errno = 38\r\n[e92e09614.em21:29604] Read -1, expected 2362084, errno = 38\r\n[e92e09614.em21:29605] Read -1, expected 2362080, errno = 38\r\n[e92e09614.em21:29603] Read -1, expected 2362080, errno = 38\r\n[e92e09614.em21:29604] Read -1, expected 2362080, errno = 38\r\n.....            ......         .....\r\n[e92e09614.em21:29605] Read -1, expected 2362084, errno = 38\r\n[e92e09614.em21:29603] Read -1, expected 2362084, errno = 38\r\n[e92e09614.em21:29604] Read -1, expected 2362080, errno = 38\r\n[e92e09614.em21:29605] Read -1, expected 2362080, errno = 38\r\n[e92e09614.em21:29603] Read -1, expected 2362080, errno = 38\r\n[e92e09614.em21:29604] Read -1, expected 2362084, errno = 38\r\n[e92e09614.em21:29605] Read -1, expected 2362080, errno = 38\r\n..\r\n----------------------------------------------------------------------\r\nRan 2 tests in 15.022s\r\n\r\nOK\r\n....\r\n\r\n----------------------------------------------------------------------\r\n----------------------------------------------------------------------\r\nRan 2 tests in 14.998s\r\n\r\nRan 2 tests in 14.998s\r\n\r\nOK\r\nOK\r\n\r\n```", "Hi @chengdianxuezi: I see. Thanks for the update.\r\n\r\nI'm not exactly sure why the tests pass (that's very strange). However, I suspect this issue has to do with how you have built or configured OpenMPI. I would recommend searching around for the error message: `Read _, expected _, errno = 38`, and testing some of the config changes that you find. For instance, this result pops up related to configuration of CMA: https://github.com/open-mpi/ompi/issues/3270 . Many MPI configuration changes can be made by exporting environment variables to test if they work (and if so, you can reconfigure your build and re-build if desired).", "@jthestness Thank you! when I try to run as follow, the error message will not show up\r\n```\r\nOMPI_MCA_btl_vader_single_copy_mechanism=none /usr/local/mpi/bin/mpirun -n 3 python mpi_allreduce_test.py\r\n```"]}, {"number": 21878, "title": "assert d in name_to_node, \"%s is not in graph\" % d", "body": "When I convert the keras model to pb file, it reports an error that :\r\n\r\nassert d in name_to_node, \"%s is not in graph\" % d\r\n\r\nDoes anyone know any solution of this issue? Thank you.\r\n\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "It has been 20 days with no activity and the `awaiting response` label was assigned. Is this still an issue?"]}, {"number": 21877, "title": "Add `ENV LANG C.UTF-8` to dockerfiles for Python", "body": "This fix tries to address the issue raised in #20380 where `LANG` env was not set in Docker images, and was causing issues with python 3 (see related bug https://bugs.python.org/issue19846).\r\n\r\nThis fix adds `ENV LANG C.UTF-8` to Dockerfiles which matches the official python images.\r\n\r\nThis fix fixes #20380.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["@angersson The PR will fix issue #20380. Please take a look and see if there are any issues.", "Thanks for the PR.\r\n\r\nI have encountered this problem myself (I've been setting `export PYTHONIOENCODING=utf8`).\r\n\r\nBut I'm no docker expert, so I'll leave this review to @angersson.", "Ping @angersson to see if the proposed changes make sense."]}, {"number": 21876, "title": "Replace tf.Variable with tfe.Variable in eager guide", "body": "The current code produces this error:\r\n`RuntimeError: tf.Variable not supported when eager execution is enabled. Please use tf.contrib.eager.Variable instead`\r\n\r\n`tf.contrib.eager` is defined as `tfe` early here, so this replaces `tf.Variable` with `tfe.Variable`. Here's a [colab notebook](https://colab.research.google.com/drive/1tC8ykDqzcWhVLfMnCXk9i9XOvoNwX5Xg) showing that it works (a lot of it doesn't work since the code isn't fully reproducible).\r\n\r\nThis also fixes a couple of >80char lines.", "comments": ["Thanks for the PR, but this should not be required. See  https://github.com/tensorflow/tensorflow/pull/21512#issuecomment-412281227 and the follow up comment there. \r\n\r\nThe website should be linking to versions of the notebook in the release branch. If you found a link that incorrectly points to the master branch, please do let us know. \r\n\r\nThanks!", "This example doesn't link to a notebook, I put it together myself. So seems like this is a frictional issue until Colab updates its version of Tensorflow (it's currently 1.10.0).", "Yeah, for 1.10 and before you'll need `tf.contrib.eager.Variable`. In 1.11 onwards, `tf.Variable` will work (as part of a general theme of moving from `tf.contrib` to `tf` as things become stable)"]}, {"number": 21875, "title": "Incompatible shapes between op input and calculated input gradient for nn.conv3d_transpose", "body": "This is code:\r\n\r\n```\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\nfrom utils import init_weight\r\nimport tensorflow as tf\r\n\r\nslim = tf.contrib.slim\r\n\r\n\r\n@tf.contrib.framework.add_arg_scope\r\ndef conv3d_transpose(inputs,\r\n                     num_outputs,\r\n                     kernel_size,\r\n                     weights,\r\n                     biases,\r\n                     stride,\r\n                     padding,\r\n                     activation_fn=tf.nn.relu,\r\n                     weights_initializer=tf.contrib.layers.xavier_initializer(),\r\n                     biases_initializer=tf.zeros_initializer(),\r\n                     reuse=None,\r\n                     trainable=True,\r\n                     scope=None):\r\n\r\n  with tf.variable_scope(\r\n      scope, 'Conv3d_transpose', [inputs], reuse=reuse):\r\n    dtype = inputs.dtype.base_dtype\r\n    kernel_d, kernel_h, kernel_w = kernel_size[0:3]\r\n    num_filters_in = inputs.get_shape()[4]\r\n    weights_shape = [kernel_d, kernel_h, kernel_w, num_outputs, num_filters_in]\r\n    \r\n    weights = tf.get_variable('weights',\r\n                              shape=weights_shape,\r\n                              dtype=dtype,\r\n                              initializer=tf.constant_initializer(weights),\r\n                              trainable=trainable)\r\n    \r\n    tf.contrib.framework.add_model_variable(weights)\r\n    \r\n    input_shape = inputs.get_shape().as_list()\r\n    batch_size = input_shape[0]\r\n    depth = input_shape[1]\r\n    height = input_shape[2]\r\n    width = input_shape[3]\r\n\r\n    def get_deconv_dim(dim_size, stride_size,pading,kernel):\r\n      if isinstance(dim_size, tf.Tensor):\r\n        sub = tf.subtract(dim_size,1)\r\n        dim_size = tf.multiply(dim_size,sub)\r\n        dim_size = tf.subtract(dim_size, 2*pading)\r\n        dim_size = tf.add(dim_size,kernel)\r\n        \r\n      elif dim_size is not None:\r\n        dim_size  = (dim_size -1)*stride_size - 2*pading + kernel\r\n      return dim_size\r\n   \r\n    pad = 1\r\n    if padding == 'VALID':\r\n      pad = 0\r\n    out_depth = get_deconv_dim(depth, stride,pad,weights.get_shape().as_list()[0])\r\n    out_height = get_deconv_dim(height, stride,pad,weights.get_shape().as_list()[1])\r\n    out_width = get_deconv_dim(width, stride,pad,weights.get_shape().as_list()[2])\r\n\r\n    out_shape = [batch_size, out_depth, out_height, out_width, num_outputs]\r\n    outputs = tf.nn.conv3d_transpose(inputs, weights, out_shape,\r\n                                     [1, stride, stride, stride, 1],\r\n                                     padding)\r\n\r\n    biases = tf.get_variable('biases',\r\n                               shape=[num_outputs,],\r\n                               dtype=dtype,\r\n                               initializer=tf.constant_initializer(biases),\r\n                               trainable=trainable)\r\n    tf.contrib.framework.add_model_variable(biases)\r\n    outputs = tf.nn.bias_add(outputs, biases)\r\n    \r\n    if activation_fn:\r\n      outputs = activation_fn(outputs)\r\n    return outputs\r\n\r\n\r\ndef model(identities, params, is_training):\r\n  \"\"\"Model transforming embedding to voxels.\"\"\"\r\n  del is_training  # Unused\r\n  f_dim = params.f_dim\r\n  with slim.arg_scope(\r\n      [slim.fully_connected, conv3d_transpose]):\r\n    w0 = init_weight(\"DecoderWeights/Layer1_13824_512_w.txt\",[13824,512],\"w\")\r\n    print(identities.get_shape().as_list())\r\n    h0 = slim.fully_connected(\r\n        identities, 3 * 3 * 3 * f_dim * 8, weights_initializer = tf.constant_initializer(w0), activation_fn=tf.nn.relu)\r\n    b0 = init_weight(\"DecoderWeights/Layer1_13824_b.txt\",[13824],\"b\")\r\n    b0 = tf.get_variable('db0',shape=[13824], initializer=tf.constant_initializer(b0),trainable=True)\r\n    h0 = tf.nn.bias_add(h0,b0)\r\n\r\n    h1 = tf.reshape(h0, [-1, 3, 3, 3, f_dim * 8])\r\n    print(h1.get_shape().as_list())\r\n    w1 = init_weight(\"DecoderWeights/Layer2_512_256_4_4_4_w.txt\",[512,256,4,4,4],\"w\")\r\n    b1 = init_weight(\"DecoderWeights/Layer2_256_b.txt\",[256],\"b\")\r\n    h1 = conv3d_transpose(\r\n        h1, f_dim * 4, [4, 4, 4],w1, b1,stride=1, padding= 'VALID',activation_fn=tf.nn.relu)\r\n    print(h1.get_shape().as_list())\r\n    w2 = init_weight(\"DecoderWeights/Layer3_256_96_5_5_5_w.txt\",[256,96,5,5,5],\"w\")\r\n    b2 = init_weight(\"DecoderWeights/Layer3_96_b.txt\",[96],\"b\")\r\n    h2 = conv3d_transpose(\r\n        h1, int(f_dim * 3 / 2), [5, 5, 5],w2 , b2, stride=2,padding ='VALID' ,activation_fn=tf.nn.relu)\r\n    print(h2.get_shape().as_list())\r\n    w3 = init_weight(\"DecoderWeights/Layer4_96_1_6_6_6_w.txt\",[96,1,6,6,6],\"w\")\r\n    b3 = init_weight(\"DecoderWeights/Layer4_1_b.txt\",[1],\"b\")\r\n    h3 = conv3d_transpose(\r\n        h2, 1, [6, 6, 6], w3,b3, stride=2, padding ='SAME' ,activation_fn=tf.nn.sigmoid)\r\n    print(h3.get_shape().as_list())\r\n  return h3\r\n```\r\n\r\nThis is error:\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 81, in <module>\r\n    epsilon=1e-08).minimize(loss, global_step=global_step)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py\", line 343, in minimize\r\n    grad_loss=grad_loss)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py\", line 414, in compute_gradients\r\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py\", line 609, in gradients\r\n    % (op.name, i, t_in.shape, in_grad.shape))\r\nValueError: Incompatible shapes between op input and calculated input gradient.  Forward operation: decoder/Conv3d_transpose_2/conv3d_transpose.  Input index: 2. Original input shape: (6, 15, 15, 15, 96).  Calculated input gradient shape: (6, 16, 16, 16, 96)\r\n\r\nTf version : 1.4.1\r\n\r\nI have 4 layers, 1 fc and 3 conv3d_transpose.\r\n\r\nLayer shape as follows:\r\n\r\n[6, 512]\r\n[6, 3, 3, 3, 512]\r\n[6, 6, 6, 6, 256]\r\n[6, 15, 15, 15, 96]\r\n[6, 32, 32, 32, 1]\r\n\r\nI calculated conv3d_tranpose output shape as follows:\r\n```\r\n def get_deconv_dim(dim_size, stride_size,pading,kernel):\r\n      if dim_size is not None:\r\n        dim_size  = (dim_size -1)*stride_size - 2*pading + kernel\r\n      return dim_size\r\n   \r\n   pad = 1\r\n   if padding == 'VALID':\r\n     pad = 0\r\n   out_depth = get_deconv_dim(depth, stride,pad,weights.get_shape().as_list()[0])\r\n   out_height = get_deconv_dim(height, stride,pad,weights.get_shape().as_list()[1])\r\n   out_width = get_deconv_dim(width, stride,pad,weights.get_shape().as_list()[2])\r\n   out_shape = [batch_size, out_depth, out_height, out_width, num_outputs]\r\n   outputs = tf.nn.conv3d_transpose(inputs, weights, out_shape,\r\n                                     [1, stride, stride, stride, 1],\r\n                                     padding)\r\n```\r\nIn the last conv3d_transpose layer, while its output is calculated as (6,15,15,15,96), input gradient is calculated as (6,16,16,16,96). Therefore, this leads to error.\r\n\r\nWhen i call last conv3d_transpose layer with padding=\"SAME\", it didn't gives error.\r\n\r\nedit:\r\n\r\nEnvironment:\r\nOs: Ubuntu 16.04.3 LTS\r\nbazel: N/a\r\nTensorflow : 1.4.1 via pip install\r\ncuda: 9.0.176\r\nGPU: tesla k40, memory: 12gb\r\ncommand: I uploaded only erroneous python script, just run \"python blabla.py\".  If you want, i can upload all python scripts.", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "@tensorflowbutler , sorry for missing information. I updated my post.", "> @tensorflowbutler\uff0c\u5bf9\u4e0d\u8d77\uff0c\u6240\u6709\u6743\u4fe1\u606f\u3002\u6211\u66f4\u65b0\u4e86\u6211\u7684\u5e16\u5b50\u3002\r\n\r\n\u4f60\u597d\uff0c\u6211\u60f3\u8bf7\u6559\u4e00\u4e0b\u8fd9\u4e2a\u5e94\u8be5\u600e\u4e48\u6539\uff0c\u6211\u4e5f\u9047\u5230\u4e86\u8fd9\u79cd\u95ee\u9898\uff0c\u4f46\u662f\u6211\u6beb\u65e0\u5934\u7eea\r\n`<python>'\r\n        with tf.variable_scope('Decoder'):\r\n            print('self.masked_v',self.masked_v.get_shape())\r\n            vector_j= tf.reshape(self.masked_v, shape=(cfg.batch_size, 2, 16, 1, 1))\r\n            kernel2 = tf.constant(1.0, shape=[3, 3, 2, 1, 1])  # \u53cd\u5411\u5377\u79ef\u6838\r\n            kernel3 = tf.constant(1.0, shape=[3, 1, 29, 1, 1])  # \u53cd\u5411\u5377\u79ef\u6838\r\n            deconv11 = tf.nn.conv3d_transpose(vector_j, kernel2, output_shape=[cfg.batch_size,3, 16, 18, 1],\r\n                                        strides=[1, 2, 2, 2, 1], padding=\"SAME\")\r\n            print('deconv1',deconv11.get_shape())\r\n\r\n            self.decoded= tf.nn.conv3d_transpose(deconv11, kernel3, output_shape=[cfg.batch_size, 9, 32, 32, 1],\r\n                                        strides=[1, 2, 1, 2, 1], padding=\"SAME\")\r\n            print('self.decoded',self.decoded.get_shape())   #self.decoded (20, 9, 32, 32, 1)\r\n", "@Bedrettin-Cetinkaya  It looks like you are using an older Version of Tensorflow which is out of support window. Many bugs have been fixed in the latest version. Can you please execute your code using Latest Version (2.6.0) and let us know if the issue still persists? Please refer to the similar[ issue](https://stackoverflow.com/questions/49809177/getting-incompatible-shapes-between-op-input-and-calculated-input-gradient-when). Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/21875\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/21875\">No</a>\n"]}, {"number": 21874, "title": "Windows docker documentation", "body": "### System information\r\n- Win 10\r\n- Latest version of docker\r\n- docker run -p 8888:8888 --name tensorflow-udacity -it gcr.io/tensorflow/udacity-assignments:1.0.0\r\n\r\n### Describe the problem\r\nAt https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/udacity. It does not say what command to use for windows.\r\n\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "We do not have docker images/containers for windows.\r\nThat's why they are not there.\r\n\r\nThat may be an interesting community contribution though.", "I can take a look at this!", "@chuhanuman, \r\nCould you please mention your Windows edition. Docker has different implementation for Windows Home/Personal and (Pro, enterprise, and education) edition.", "Have updated the document and mentioned the command for Windows. Have submitted PR 22944 for it.", "This issue has been resolved. "]}, {"number": 21873, "title": "Feature Request: Keras method to extract the graph", "body": "Several parts of the Tensorflow documentation suggest to the reader to use the higher level APIs (Keras / Estimators) when there is no explicit need if the low level API. \r\n\r\nOf the high level APIs, there are some upwards mobility between the levels. For example, a custom Keras model can be converted into an Estimator. \r\n\r\nHowever, getting access to the lower level APIs from the higher level apis is not so simple.\r\n\r\nIt would be nice - at least for visualization purposes - to allow users to see the automatically generated graph produced by the higher level APIs. \r\n\r\nTaking a Keras model, converting it to an estimator, defining the `serving_input_receiver_fn`, and then exporting the estimator via `export_savedmodel` to see the graph is a bit convoluted for \"high level\" apis.\r\n\r\nA subclassed Keras model, once compiled, could have a method `as_graph` to convert to the computational graph.\r\n\r\n", "comments": ["Could [ tf.keras.callbacks.TensorBoard ](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/TensorBoard)  solve your problem ?", "@SumNeuron can you please comment on @facaiy 's suggestion?", "@cy89 does solve the graph issue, still playing around with it to see if I can do everything that I can with a TF Graph", "Nagging Assignee @cy89: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "I'll close the issue, please be free to reopen it if new information becomes available.", "hi @facaiy -- it doesn't seem possible to add keras model graph to tensorboard if you're using GradientTape... all the instructions involve use of callbacks and model.fit. If this is possible, how? If not, can we add an easy way to submit keras model graph to tensorboard for visualization? \r\n\r\ntf.summary.FileWriter doesn't work in eager mode in 1.14... but tf.contrib is going away and tf.contrib.ResourceSummaryWriter cannot seemingly submit graph, and we can't get the graph session inside @tf.function to send to tensorboard. \r\n\r\nPlease advise how do you add tensorboard keras graph when not using model.fit?", "@bionicles bion, can you file a new issue for it?"]}, {"number": 21872, "title": "tf.enable_eager_execution() bug?", "body": "\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:window10\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: 1.10\r\n- **Python version**:3.6\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\ni used the` tf.enable_eager_execution()` and create InceptionResNetV2 mode will be error and only InceptionResNetV2 have. I need use  `tf.enable_eager_execution()` can't without. \r\n\r\nhow to fix it?\r\n\r\n### Source code / logs\r\n`import tensorflow as tf`\r\n`tf.enable_eager_execution()`\r\n`image_model =tf.keras.applications.InceptionResNetV2(include_top=False, weights='imagenet')\r\n`\r\n--error---\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-2-b40bb13774b9> in <module>()\r\n----> 1 image_model =tf.keras.applications.InceptionResNetV2(include_top=False, weights='imagenet')\r\n\r\nD:\\anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\applications\\inception_resnet_v2.py in InceptionResNetV2(include_top, weights, input_tensor, input_shape, pooling, classes)\r\n    304   for block_idx in range(1, 11):\r\n    305     x = inception_resnet_block(\r\n--> 306         x, scale=0.17, block_type='block35', block_idx=block_idx)\r\n    307 \r\n    308   # Mixed 6a (Reduction-A block): 17 x 17 x 1088\r\n\r\nD:\\anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\applications\\inception_resnet_v2.py in inception_resnet_block(x, scale, block_type, block_idx, activation)\r\n    187       output_shape=K.int_shape(x)[1:],\r\n    188       arguments={'scale': scale},\r\n--> 189       name=block_name)([x, up])\r\n    190   if activation is not None:\r\n    191     x = Activation(activation, name=block_name + '_ac')(x)\r\n\r\nD:\\anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py in __call__(self, inputs, *args, **kwargs)\r\n    745           input_shapes = nest.map_structure(lambda x: x.shape, inputs)\r\n    746 \r\n--> 747         output_shapes = self.compute_output_shape(input_shapes)\r\n    748         output_shapes = nest.flatten(output_shapes)\r\n    749         outputs = [\r\n\r\nD:\\anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py in compute_output_shape(self, input_shape)\r\n    678 \r\n    679   def compute_output_shape(self, input_shape):\r\n--> 680     input_shape = tuple(tensor_shape.TensorShape(input_shape).as_list())\r\n    681 \r\n    682     if self._output_shape is None:\r\n\r\nD:\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py in __init__(self, dims)\r\n    539       else:\r\n    540         # Got a list of dimensions\r\n--> 541         self._dims = [as_dimension(d) for d in dims_iter]\r\n    542     self._ndims = None\r\n    543 \r\n\r\nD:\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py in <listcomp>(.0)\r\n    539       else:\r\n    540         # Got a list of dimensions\r\n--> 541         self._dims = [as_dimension(d) for d in dims_iter]\r\n    542     self._ndims = None\r\n    543 \r\n\r\nD:\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py in as_dimension(value)\r\n    480     return value\r\n    481   else:\r\n--> 482     return Dimension(value)\r\n    483 \r\n    484 \r\n\r\nD:\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py in __init__(self, value)\r\n     35       raise TypeError(\"Cannot convert %s to Dimension\" % value)\r\n     36     else:\r\n---> 37       self._value = int(value)\r\n     38       if (not isinstance(value, compat.bytes_or_text_types) and\r\n     39           self._value != value):\r\n\r\nTypeError: int() argument must be a string, a bytes-like object or a number, not 'TensorShape'\r\n", "comments": ["@Q82822 I am able to reproduce with 1.10 but not the latest nightly build. Can you try with tf-nightly and see if the issue has been resolved?", "it is still not work\r\nhave the same problem", "I am working on a Linux machine. With tf-nightly (`1.11.0-dev20180826`) it seems to be working:\r\n```\r\n# python\r\nPython 2.7.12 (default, Dec  4 2017, 14:50:18) \r\n[GCC 5.4.0 20160609] on linux2\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\n>>> tf.VERSION\r\n'1.11.0-dev20180826'\r\n>>> tf.enable_eager_execution()\r\n>>> image_model =tf.keras.applications.InceptionResNetV2(include_top=False, weights='imagenet')\r\n2018-08-26 17:47:03.515629: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\nDownloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.7/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\r\n219062272/219055592 [==============================] - 2s 0us/step\r\n219070464/219055592 [==============================] - 2s 0us/step\r\n>>> \r\n```", "i change to use linux and python 2.7 but still have problem\r\ncan you talk to me about what you CUDA/cuDNN version??\r\n```\r\nPython 2.7.14 |Intel Corporation| (default, May  4 2018, 04:27:35) \r\n[GCC 4.8.2 20140120 (Red Hat 4.8.2-15)] on linux2\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\nIntel(R) Distribution for Python is brought to you by Intel Corporation.\r\nPlease check out: https://software.intel.com/en-us/python-distribution\r\n>>> import tensorflow as tf\r\n>>> tf.enable_eager_execution()\r\n>>> image_model =tf.keras.applications.InceptionResNetV2(include_top=False, weights='imagenet')\r\n2018-08-27 20:16:09.499244: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2018-08-27 20:16:09.581371: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:897] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2018-08-27 20:16:09.581668: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 0 with properties: \r\nname: GeForce GTX 1070 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.683\r\npciBusID: 0000:01:00.0\r\ntotalMemory: 7.92GiB freeMemory: 248.25MiB\r\n2018-08-27 20:16:09.581682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 0\r\n2018-08-27 20:16:09.758566: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-08-27 20:16:09.758595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      0 \r\n2018-08-27 20:16:09.758615: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 0:   N \r\n2018-08-27 20:16:09.758753: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 184 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n2018-08-27 20:16:09.759830: E tensorflow/stream_executor/cuda/cuda_driver.cc:903] failed to allocate 184.25M (193200128 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/keras/applications/inception_resnet_v2.py\", line 306, in InceptionResNetV2\r\n    x, scale=0.17, block_type='block35', block_idx=block_idx)\r\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/keras/applications/inception_resnet_v2.py\", line 189, in inception_resnet_block\r\n    name=block_name)([x, up])\r\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 747, in __call__\r\n    output_shapes = self.compute_output_shape(input_shapes)\r\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/keras/layers/core.py\", line 680, in compute_output_shape\r\n    input_shape = tuple(tensor_shape.TensorShape(input_shape).as_list())\r\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/tensor_shape.py\", line 541, in __init__\r\n    self._dims = [as_dimension(d) for d in dims_iter]\r\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/tensor_shape.py\", line 482, in as_dimension\r\n    return Dimension(value)\r\n  File \"/home/user/anaconda3/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/tensor_shape.py\", line 37, in __init__\r\n    self._value = int(value)\r\nTypeError: int() argument must be a string or a number, not 'TensorShape'\r\n```\r\n", "@Q82822 Which version are you using? Can you check:\r\n```\r\n>>> import tensorflow as tf\r\n>>> tf.VERSION\r\n'1.11.0-dev20180826'\r\n```", "my tensorflow version is 1.10 and  CUDA/cuDNN version: 9.0/7.1\r\n```\r\n>>> import tensorflow as tf\r\n>>> print(tf.__version__)\r\n1.10.1\r\n```\r\nand I have installed the tnesorflow again\r\ni don't know why you tf.version was 1.11.0 ", "@Q82822 Can you uninstall tensorflow and reinstall with `pip install tf-nightly` to get the nightly build?", "very appreciate you help. i can build mode now", "@yongtang thank you for helping out!\r\n@Q82822 closing since it seems that you have a solution."]}, {"number": 21871, "title": "tf.float16 not in allowed list?", "body": "when i call dynamic_rnn,  i counter a TypeError: Value passed to parameter 'x' has DataType float16 not in list of allowed values: float32. the dynamic_rnn only support the type of float32?", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "It has been 21 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "@lizaigaoge550 Is this still an issue?. By interpreting the error message, workaround for this will be to convert your data type to float.32. This can be done by using tf.cast function https://www.tensorflow.org/api_docs/python/tf/cast", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 21870, "title": "Missing quantized implementation of TopK_V2", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Fedora 27\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: N/A\r\n- **TensorFlow installed from (source or binary)**: `pip install tensorflow-gpu`\r\n- **TensorFlow version (use command below)**: v1.9.0-0-g25c197e023\r\n- **Python version**: 3.6.6\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: 9.0 / 7.1.4\r\n- **GPU model and memory**: 940MX, 2GB VRAM\r\n- **Exact command to reproduce**: see code below\r\n\r\n### Describe the problem\r\nI am trying to quantize my network.\r\nThere is a special logic in one layer which takes the k highest activations and sets all other to zero.\r\nIt is implemented using the following code:\r\n```python\r\ntop = tf.nn.top_k(intermediate, k, sorted=True)\r\nmin_indices = top.indices[..., -1]\r\nbatch_indices = tf.range(intermediate.shape[0], dtype=tf.int32)\r\ntotal_indices = tf.stack([batch_indices, min_indices], axis=1)\r\nmins = tf.reshape(tf.gather_nd(intermediate, total_indices), [-1, 1])\r\nselection = intermediate >= mins\r\nzeros = tf.zeros(intermediate.shape, dtype=intermediate.dtype)\r\nintermediate = tf.where(selection, x=intermediate, y=zeros)\r\n```\r\nWhere `k` is a `int32` placeholder and `intermediate` a Tensor containing the activations of a fully connected layer. It is shaped `[batch_size, nodes]`.\r\n\r\nI then call `tf.contrib.quantize.create_training_graph()`, train using Adam and save the weights as a checkpoint. After a reset of the graph I create the eval graph and rewrite it using `tf.contrib.quantize.create_eval_graph()`. That one is saved to a graph definition file. After that I run the following commands:\r\n\r\n```\r\nfreeze_graph --input_graph definition.pb --input_checkpoint lastcheckpoint --output_graph frozen_graph.pb --output_node=out\r\n```\r\n\r\n```\r\ntflite_convert --output_file model.tflite --graph_def_file frozen_graph.pb --inference_type QUANTIZED_UINT8 --input_arrays input/in,density --output_arrays out --mean_values 1,1 --std_dev_values 1,1\r\n```\r\n\r\nThe second command fails with the following log:\r\n\r\n```\r\n2018-08-25 12:39:14.510582: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2018-08-25 12:39:14.605698: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:897] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2018-08-25 12:39:14.606404: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1392] Found device 0 with properties: \r\nname: GeForce 940MX major: 5 minor: 0 memoryClockRate(GHz): 0.8605\r\npciBusID: 0000:01:00.0\r\ntotalMemory: 1.96GiB freeMemory: 1.71GiB\r\n2018-08-25 12:39:14.606429: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0\r\n2018-08-25 12:39:15.293534: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-08-25 12:39:15.293568: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 \r\n2018-08-25 12:39:15.293576: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N \r\n2018-08-25 12:39:15.293738: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1465 MB memory) -> physical GPU (device: 0, name: GeForce 940MX, pci bus id: 0000:01:00.0, compute capability: 5.0)\r\nTraceback (most recent call last):\r\n  File \"/home/t/development/projects/nncompression/JugendForscht2019/venv/bin/tflite_convert\", line 11, in <module>\r\n    sys.exit(main())\r\n  File \"/home/t/development/projects/nncompression/JugendForscht2019/venv/lib/python3.6/site-packages/tensorflow/contrib/lite/python/tflite_convert.py\", line 320, in main\r\n    app.run(main=run_main, argv=sys.argv[:1])\r\n  File \"/home/t/development/projects/nncompression/JugendForscht2019/venv/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"/home/t/development/projects/nncompression/JugendForscht2019/venv/lib/python3.6/site-packages/tensorflow/contrib/lite/python/tflite_convert.py\", line 316, in run_main\r\n    _convert_model(tflite_flags)\r\n  File \"/home/t/development/projects/nncompression/JugendForscht2019/venv/lib/python3.6/site-packages/tensorflow/contrib/lite/python/tflite_convert.py\", line 121, in _convert_model\r\n    output_data = converter.convert()\r\n  File \"/home/t/development/projects/nncompression/JugendForscht2019/venv/lib/python3.6/site-packages/tensorflow/contrib/lite/python/lite.py\", line 309, in convert\r\n    allow_custom_ops=self.allow_custom_ops)\r\n  File \"/home/t/development/projects/nncompression/JugendForscht2019/venv/lib/python3.6/site-packages/tensorflow/contrib/lite/python/convert.py\", line 225, in toco_convert\r\n    input_data.SerializeToString())\r\n  File \"/home/t/development/projects/nncompression/JugendForscht2019/venv/lib/python3.6/site-packages/tensorflow/contrib/lite/python/convert.py\", line 107, in toco_convert_protos\r\n    (stdout, stderr))\r\nRuntimeError: TOCO failed see console for info.\r\nb'2018-08-25 12:39:18.308856: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: GatherNd\r\n2018-08-25 12:39:18.308926: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1366] Converting unsupported operation: Round\r\n2018-08-25 12:39:18.309390: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 57 operators, 96 arrays (0 quantized)\r\n2018-08-25 12:39:18.309831: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 57 operators, 96 arrays (0 quantized)\r\n2018-08-25 12:39:18.312078: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 28 operators, 55 arrays (1 quantized)\r\n2018-08-25 12:39:18.312642: W tensorflow/contrib/lite/toco/tooling_util.cc:1639] Dropping MinMax information in array model/conv1/weights_quant/FakeQuantWithMinMaxVars. Expect inaccuracy in quantized inference.\r\n2018-08-25 12:39:18.312788: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 2: 26 operators, 51 arrays (1 quantized)\r\n2018-08-25 12:39:18.312907: W tensorflow/contrib/lite/toco/graph_transformations/propagate_fixed_sizes.cc:1304] Skipping StridedSlice op with output \"model/sparsity/strided_slice_1\". ellipsis_mask is not supported (mask=1)\r\n2018-08-25 12:39:18.313073: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 3: 25 operators, 49 arrays (1 quantized)\r\n2018-08-25 12:39:18.313173: W tensorflow/contrib/lite/toco/graph_transformations/propagate_fixed_sizes.cc:1304] Skipping StridedSlice op with output \"model/sparsity/strided_slice_1\". ellipsis_mask is not supported (mask=1)\r\n2018-08-25 12:39:18.313322: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before pre-quantization graph transformations: 25 operators, 49 arrays (1 quantized)\r\n2018-08-25 12:39:18.313431: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After pre-quantization graph transformations pass 1: 22 operators, 46 arrays (1 quantized)\r\n2018-08-25 12:39:18.313573: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before quantization graph transformations: 22 operators, 46 arrays (1 quantized)\r\n2018-08-25 12:39:18.313591: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:87] Constant array model/conv1/weights_quant/FakeQuantWithMinMaxVars lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\r\n2018-08-25 12:39:18.315866: F tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:456] Unimplemented: this graph contains an operator of type TopK_V2 for which the quantized form is not yet implemented. Sorry, and patches welcome (that\\'s a relatively fun patch to write, mostly providing the actual quantized arithmetic code for this op).\\n'\r\nNone\r\n```\r\nThe main problem seems to be the missing implementation of TopK_V2. Although it is suggested as a \"fun patch to write\", I only have little knowledge of C/C++ and don't know the tensorflow internals. So I'm opening this issue here to show the need for a quantized implementation of TopK_V2. Maybe somebody can help with that.\r\n\r\nI'm unsure if the other warnings are coming from this issue, too.\r\nIf you know why they show up, please tell me.", "comments": ["It seems that it's already supported on Aug 30\r\n\r\ncommit: https://github.com/tensorflow/tensorflow/commit/0278712da34922ec9fd5e2a4484b3b3243f7784c#diff-ef90f22f58f3bf2d3d6d3baa471f24b6", "The fix should be in the next TensorFlow binary release."]}, {"number": 21869, "title": "remove warnings when compiling this as a c header.", "body": "There are some compile errors with visual studio 2017.\r\nThese consts are not c compatible", "comments": ["We can't commit this change because it breaks the semantics of TF_WhileParams (e.g. changing `TF_Graph* const` to `const TF_Graph*` means you can no longer edit the graph, but can change the pointer value). I'm surprised the compiler is complaining, what errors are you seeing? ", "Nagging Assignee @rmlarsen: It has been 61 days with no activity and this issue has an assignee. Please update the label and/or status accordingly."]}, {"number": 21868, "title": "upgraded protobuf to v.3.6.1", "body": "", "comments": ["Nagging Assignee @yifeif: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly."]}, {"number": 21867, "title": "tf.seq2seq has not attribute prepare attention even in version 1.0", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **I have written code in tensorflow for a chatbot.**:\r\n- **OS Platform is windows 10**\r\n- **TensorFlow installed from source **:\r\n- **TensorFlow version (both version 1.0 and 1.1.0)**:\r\n- **Python version 3.6**\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\ntf.seq2seq has not attribute prepare attention even in version 1.0\r\n\r\n\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nMobile device", "(Closing due to lack of information. Please feel free to reopen/re-file a new issue with more information. Specifically, I didn't quite follow what attribute is being referred to, on what API)"]}, {"number": 21866, "title": "tensorflow 1.10.1 requires numpy 1.14.5?", "body": "I have successfully built tensorflow  1.10.1 from source but when  I installed the whl with pip3 it downloaded and installed numpy-1.14.5 and removed numpy-1.15.1. \r\n\r\nAfter tensorflow was installed I manually uninstalled numpy-1.14.5 and reinstalled numpy-1.15.1, pip gave a warning that tensorflow-1.10.1 requires numpy <= 1.14.5 but went ahead anyway. Afterwards I ran some tests on tensorflow and it works just fine with numpy 1.15.1 so this requirement appears to be unnecessary. **Edited:** there is no complaint about incompatibility with numpy-1.15.1 for tensorflow-1.9\r\n\r\nIs there a file I can edit to get rid of this requirement? I am ok with compiling again.\r\n\r\nOS Ubuntu 16.04.5 LTS 64 bits , python3.5 (cuda-9.2)\r\n", "comments": ["@av8ramit The restriction seems introduced in f9410ac2, could you explain why we need it?\r\n\r\n@beew I think you can modify the line below and take a try, good luck:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/90209afabc187da3ef7157352eea3b901c84e03d/tensorflow/tools/pip_package/setup.py#L56", "Link to #21700", "I've removed the restriction in https://github.com/tensorflow/tensorflow/commit/6729cd7d1c07e547298fa2a02d1e36390dc62f0a and 1.11 should support the latest numpy. cc: @angersson \r\n", "@av8ramit Good news! Could you close all those related issue? ", "I believe I did, did I miss any?"]}, {"number": 21865, "title": "initializer should support TensorShape", "body": "Fix #21838.", "comments": ["@fchollet Could you take a look? Thanks", "@martinwicke excuse me, could you help assign the PR? Thanks.", "@fchollet this may be redundant if we remove TensorShape (or make it more tuple-like) and Dimension, but for now, this seems nice, no?", "Will TensorShape and Dimension be deprecated in the future? ", "We hope to make TensorShape much more like a tuple of ints, such that manual conversions like this would not be necessary any more.", "Sounds great if TensorShape could be more like a tuple of ints, but I'm afraid it might not be easy to make Dimension totally consistent with Int. Would there be a RFC later?\r\n\r\nI really like TensorShape and Dimension (plus `as_list`) than list of ints for shape argument, actually.", "@fchollet Hi, could you make a clarification? Thanks.", "@facaiy \"CL\" is Google jargon for Change List which is our internal version of PR.", "Thanks for your explanation. Could you help review? ", "@fchollet can you take another look, please?", "@fchollet Friendly ping :-)", "@martinwicke Hi, Martin. Would you mind giving me a hand? I think the PR has been delayed for a long time :-) Any help will be appreciated, thanks.", "@facaiy sorry for the delay. As previously noted, this PR makes a change in `init_ops` but only adds a unit test about Keras layers' `add_weight`. Please add a unit test for precisely testing the change you're making, not a high-level integration test.", "@rmlarsen Hi, Rasmus. I think the PR is stalled. Could you help me? Thanks :-)", "Hi, is there any update?", "I think there may be conflicts. Sorry we let this linger. Can you resolve the conflicts?", "Thanks very much for your help, Martin."]}, {"number": 21864, "title": "Performance of TFLite custom AAR is lower than AAR release", "body": "When I build TFLite custom library for v1.9.0 using tip of v1.9 branch Android performance is lower by ~10-20% compared to a standard AAR release.\r\nBuild command used is bazel build --cxxopt='--std=c++11' -c opt --fat_apk_cpu=armeabi-v7a tensorflow/contrib/lite/java:tensorflow-lite\r\n\r\nIs there anything I am missing in the build procedure?", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "Can you sure which Android NDK and compiler you're using?", "Hi @jdduke  Thanks for your response. What is the recommended NDK version? Bazel is picking up clang.", "Any of r14, r15 or r16 should work. Are you by chance using NDK r17? See also issue https://github.com/tensorflow/tensorflow/issues/20830 for a related report about performance degradation with NDK r17. ", "I am using r15b, still I see this degradation.\n\nOn Mon, Sep 10, 2018, 8:47 AM Jared Duke <notifications@github.com> wrote:\n\n> Any of r14, r15 or r16 should work. Are you by chance using NDK r17? See\n> also issue #20830 <https://github.com/tensorflow/tensorflow/issues/20830>\n> for a related report about performance degradation with NDK r17.\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/21864#issuecomment-419959688>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AP_CtUo_mt_hY0GCmfRCaThwVfpJUnWZks5uZomqgaJpZM4WMLht>\n> .\n>\n", "What is also not clear is the commit id used with the release. I am using the tip of r1.9 branch.", "@jdduke Do you have any updates about this? Thanks in advance!", "Have you tried building a fat library that includes both arm/arm64 binaries? The arm64 binary (which is included in the official release) should provide improved performance on arm64 devices.\r\n\r\n```\r\nbazel build --cxxopt='--std=c++11' -c opt --fat_apk_cpu=arm64-v8a,armeabi-v7a ...\r\n```\r\n\r\n", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "Is the official Tensorflow Lite AAR(nightly version) release includes arm/arm64 binaries?", "Yes, the official AAR release should include both arm and arm64 binaries."]}, {"number": 21863, "title": "tf.crop_and_resize very slow", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: N/a\r\n- **TensorFlow installed from (source or binary)**: pip\r\n- **TensorFlow version (use command below)**: 1.10\r\n- **Python version**: 3.5\r\n- **Bazel version (if compiling from source)**: n/a\r\n- **GCC/Compiler version (if compiling from source)**: n/a\r\n- **CUDA/cuDNN version**: 9/7.1\r\n- **GPU model and memory**:1080ti/11gb dual\r\n- **Exact command to reproduce**:\r\n\r\nCrop and Resize takes too long to run, please see the attachment\r\n![1](https://user-images.githubusercontent.com/4759327/44611642-eb36e380-a7f1-11e8-8fd6-7e681e124529.png)\r\n![2](https://user-images.githubusercontent.com/4759327/44611643-ebcf7a00-a7f1-11e8-8d16-79f2ca1846c5.png)\r\n\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["@dhingratul -- this is hard to help debug without further information. Can you replicate this with open data and a minimal example? What does using separate ops look like (crop, then resize)?", "I believe the issue is with the timeline, as it shows crop_and_resize as one big block of operation, after inspecting with nvidia visual profiler, I have more clarity, and the issue is non-reproducible. Its actually faster than a few other custom ops I tried."]}, {"number": 21862, "title": "op_resolver documentation update", "body": "Hello,\r\n\r\nI am having problems converting my frozen graphs to tflite models. I could do it without problems with v1.8.0-rc0, but the latest version adds an extra input to the FindOp function of the MutableOpResolver (see lines 34 and 31 of op_resolver.h). Here is what they look like\r\n\r\n  virtual const TfLiteRegistration* FindOp(tflite::BuiltinOperator op,\r\n                                           int version) const = 0;\r\n  // Finds the op registration of a custom operator by op name.\r\n  virtual const TfLiteRegistration* FindOp(const char* op,\r\n                                           int version) const = 0;\r\n\r\nWhat should be the value of 'version'? How can I figure that out? The documentation does not mention that variable or how to do any sort of mapping.\r\n\r\nThanks,\r\nJuan", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "It has been 21 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 21861, "title": "Add compression support for FixedLengthRecordDataset", "body": "This fix tries to address the issue in #21680 where there were no compression type support for FixedLengthRecordDataset. This fix enables the ability to pass a compression type for FixedLengthRecordDataset.\r\n\r\nThis fix fixes #21680.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["Thanks @mrry for the review. The PR has been updated and pushed. All tests passed except `Windows Bazel GPU`. It looks like this is a known issue and is unrelated.\r\n\r\nPlease take a look and let me know if there are any issues.", "@yongtang Looks like there are a couple more tests didn't pass. Could you check if all the files pushed are up to date? ", "Thanks @wt-huang. The PR has been rebased with all tests passed. Please take a look and let me know if there are any issues.", "@yongtang Glad to help and thanks for the fixes! In `CompressedIterator` after mutex lock, if the last `record` is out of range, may be an error should be thrown as well. Also, possibly adding `zip` to compression types?", "@wt-huang Thanks for the help and sorry for the late reply as I missed the email notification.\r\n\r\nIn the implementation,\r\n- If `OutOfRange` is encountered and no data is available (`record.empty()`), then the implementation will move to the next file as we consider this is the end of file as expected.\r\n- If `OutOfRange` is encountered and there are partial data (`!record.empty()`), then the implementation will consider this case as `errors::DataLoss`:\r\nhttps://github.com/tensorflow/tensorflow/pull/21861/files#diff-543e4ff75a82c917f5d7ee97efb31112R536\r\n\r\nI think the scenarios may have been covered in the implementation.\r\n", "@wt-huang For zip compression, I am wondering if this could be deferred, as I didn't find a zip compression processing in other Dataset ops? Other Dataset ops seems to only support `ZLIB` and `GZIP` for compression options.", "@yongtang no worries. Thanks for the clarification. I think most of the edge cases are covered. \r\nAgreed that zip compression can be deferred to a later date.", "Thanks @wt-huang. Wondering if the PR is ready to be pulled?", "Thanks @yongtang\r\n\r\n@mrry Could you take another look?", "@yongtang Looks like some of  the tests didn't pass this time. Could you rebase then submit the code changes again?", "Thanks @wt-huang. The PR has been rebased and updated. Looks like all tests passed now. Please take a look and let me know if there are any issues.", "Thanks @yongtang LGTM. \r\n@mrry could you check if anything is missed? "]}, {"number": 21860, "title": "[Intel MKL] Adding cc tests to the MKL public CI tests.", "body": "@tatianashp @gunan This brings the number of tests in the MKL public CI up to 1069.\r\n\r\n> Executed 1069 out of 1069 tests: 1069 tests pass.\r\n> INFO: Build completed successfully, 17493 total actions", "comments": ["Hi @gunan Would you mind reviewing/approving this? It is a really simple change (3 chars) that adds cc tests to the MKL public CI."]}, {"number": 21859, "title": "Accumulated Gradient Normalization Optimizer", "body": "Accumulated Gradient Normalization for distributed training\r\n\r\nOriginal Paper:\r\nhttps://arxiv.org/abs/1710.02368\r\n\r\nCode logic similar to elastic_average_optimizer.py.\r\nVerified on two internal models, see good improvements on convergence time.", "comments": ["Seems the newly checked in file has issue, introduced by [this change](https://github.com/tensorflow/tensorflow/commit/5aaebe06b476d7b7484d6eb2b68440654557018a#diff-9e0adc7e0583204daa34a1f6da5d536a).\r\n\r\n\r\n> === Sanity check step 3 of 13: do_check_futures_test (Check that python files have certain __future__ imports) ===\r\n> \r\n> Traceback (most recent call last):\r\n>   File \"check_futures_test.py\", line 107, in <module>\r\n>     main()\r\n>   File \"check_futures_test.py\", line 103, in main\r\n>     raise AssertionError('Error in %s: %s' % (short_path, str(e)))\r\n> AssertionError: Error in contrib/lite/tools/accuracy/ilsvrc/generate_validation_labels.py: Missing futures: division absolute_import print_function\r\n\r\n", "Yes, you need to \"from __future__ import  ...\" (copy from the other tf\nfiles)\n\nOn Tue, Aug 28, 2018 at 11:56 AM Weidan Kong <notifications@github.com>\nwrote:\n\n> Seems the newly checked in file has issue, introduced by this change\n> <https://github.com/tensorflow/tensorflow/commit/5aaebe06b476d7b7484d6eb2b68440654557018a#diff-9e0adc7e0583204daa34a1f6da5d536a>\n> .\n>\n> === Sanity check step 3 of 13: do_check_futures_test (Check that python\n> files have certain *future* imports) ===\n>\n> Traceback (most recent call last):\n> File \"check_futures_test.py\", line 107, in\n> main()\n> File \"check_futures_test.py\", line 103, in main\n> raise AssertionError('Error in %s: %s' % (short_path, str(e)))\n> AssertionError: Error in\n> contrib/lite/tools/accuracy/ilsvrc/generate_validation_labels.py: Missing\n> futures: division absolute_import print_function\n>\n> \u2014\n> You are receiving this because your review was requested.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/21859#issuecomment-416700364>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAATxRy7pyLygh9LOWBAPEpzOM0fMrNqks5uVZJZgaJpZM4WL1jf>\n> .\n>\n\n\n-- \n - Alex\n", "Sorry, I mean, this seems introduced by @shashishekhar with file([tensorflow/contrib/lite/tools/accuracy/ilsvrc/generate_validation_labels.py)](https://github.com/tensorflow/tensorflow/commits/master/tensorflow/contrib/lite/tools/accuracy/ilsvrc/generate_validation_labels.py)\r\n", "Ah if it's an unrelated file then we need to wait until the build goes\ngreen.\n\nOn Tue, Aug 28, 2018 at 12:16 PM Weidan Kong <notifications@github.com>\nwrote:\n\n> Sorry, I mean, this seems introduced by @shashishekhar\n> <https://github.com/shashishekhar> with file(\n> tensorflow/contrib/lite/tools/accuracy/ilsvrc/generate_validation_labels.py)\n> <https://github.com/tensorflow/tensorflow/commits/master/tensorflow/contrib/lite/tools/accuracy/ilsvrc/generate_validation_labels.py>\n>\n> \u2014\n> You are receiving this because your review was requested.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/21859#issuecomment-416706115>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAATxaDUHfTn-xihn-SwF8L0MNF9vxfVks5uVZcKgaJpZM4WL1jf>\n> .\n>\n\n\n-- \n - Alex\n", "see the file being rolled back.\r\nhttps://github.com/tensorflow/tensorflow/commits/master/tensorflow/contrib/lite/tools/accuracy/ilsvrc/generate_validation_labels.py", "@alextp do we need an 'Assignees' to get this 'import/copybara' test being processed?", "We shouldn't need you to do anything at this point.", "Thanks, I will wait :)", "Nagging Assignee @alextp: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Checked \"XLA\" failure, not related to my change.\r\nFor \"feedback/copybara\", can't see the details,  @qlzh727  could you help share the details? Thanks.\r\n"]}]