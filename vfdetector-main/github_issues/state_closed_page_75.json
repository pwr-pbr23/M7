[{"number": 52942, "title": "[TF-TRT] Add DataFormatVecPermute converter", "body": "Adds a TF-TRT converter for the [DataFormatVecPermute](https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/data-format-vec-permute) operation.\r\n\r\nExample of a model which can benefit from this: Inception v4 with dynamic shapes (2 candidate segments previously, 1 with this change).", "comments": ["@bixia1 I have squashed the commits.", "@Nyrio Can you check my comment and fix the #if line?", "@bixia1 I've fixed this line and squashed again."]}, {"number": 52941, "title": "tf.keras.backend.set_floatx does not change the default dtype in tensor initialisation", "body": "I would like to change the default float precision for initialising tensors and found the [tf.keras.backend.set_floatx](https://www.tensorflow.org/api_docs/python/tf/keras/backend/set_floatx) function in the documentation. \r\nWhen I use this function, `tf.keras.backend.floatx()` shows the configured float type but unexpectedly this type does not affect the type of created tensors:\r\n```python3\r\npython3 -c 'import tensorflow as tf; tf.keras.backend.set_floatx(\"float64\"); print(tf.keras.backend.floatx(), tf.constant(1.0))'\r\n```\r\nThe command outputs `float64 tf.Tensor(1.0, shape=(), dtype=float32)` when I execute it.\r\nI have tested it with intel_tensorflow 2.6.0, tensorflow 2.6.0 from conda-forge, tensorflow-gpu 2.4.1 from conda-forge and tensorflow 2.6.1 from pip3. The type of the created tensor never matched the configured default type.\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): I didn't execute an official example script.\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Arch Linux and Ubuntu 20.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: not applicable\r\n- TensorFlow installed from (source or binary): conda-forge and pip3\r\n- TensorFlow version (use command below): intel_tensorflow 2.6.0, tensorflow 2.6.0 from conda-forge, tensorflow-gpu 2.4.1 from conda-forge and tensorflow 2.6.1 from pip3\r\n- Python version: 3.9.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: CUDA does not yet work for me\r\n- GPU model and memory: no nvidia GPU and Nvidia GeForce RTX 3080\r\n\r\n**Describe the current behavior**\r\n\r\nThe default float precision is used when creating a tensor.\r\n\r\n\r\n**Describe the expected behavior**\r\n\r\nIf I don't explicitly specify a dtype argument, the dtype is float32 and not the current keras backend floatx.\r\n\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no): no\r\n- Briefly describe your candidate solution(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n```python3\r\npython3 -c 'import tensorflow as tf; tf.keras.backend.set_floatx(\"float64\"); print(tf.keras.backend.floatx(), tf.constant(1.0))'\r\n```\r\n\r\n**Other info / logs**", "comments": ["@FHof \r\nPlease post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues)\r\nTo know more see;\r\n[https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999](https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999)\r\nThank you!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52941\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52941\">No</a>\n"]}, {"number": 52940, "title": "ppc: remove the special condition for ppc on convolutions", "body": "After a recent change on Eigen Altivec package, we don't need this special condition on convolutions anymore\r\n\r\nhttps://gitlab.com/libeigen/eigen/-/commit/9cf34ee0aed25a7464e6ec14f977cfa940f48f1b", "comments": ["FYI, this PR fixes these 4 tests that are failing on PPC:\r\n\r\n//tensorflow/core/kernels:conv_ops_test\r\n//tensorflow/core/kernels:eigen_backward_cuboid_convolutions_test\r\n//tensorflow/core/kernels:eigen_backward_spatial_convolutions_test\r\n//tensorflow/core/kernels:eigen_spatial_convolutions_test", "Hi @ezhulenev, this patch is related to this bug https://github.com/tensorflow/tensorflow/issues/44626 that was fixed here https://github.com/tensorflow/tensorflow/pull/47768 and here https://github.com/tensorflow/tensorflow/pull/50677\r\n\r\nEigen on Power was changed recently and we don't need to handle the remaining columns differently for PPC."]}, {"number": 52938, "title": "session config conflict with server_def_", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Centos 7\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: None\r\n- TensorFlow installed from (source or binary): source \r\n- TensorFlow version (use command below): master\r\n- Python version:3.8\r\n- Bazel version (if compiling from source): 3.7.2\r\n- GCC/Compiler version (if compiling from source): Apple LLVM version 10.0.1 (clang-1001.0.46.4)\r\n- CUDA/cuDNN version: None\r\n- GPU model and memory: None\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n```zsh: command not found: v1.12.1-54214-gb51e7cff1aa```\r\n\r\ncode:\r\n```\r\nconfig0 = tf.ConfigProto(intra_op_parallelism_threads=0)\r\nconfig1 = tf.ConfigProto(intra_op_parallelism_threads=1)\r\nserver = tf.train.Server.create_local_server(config=config0)\r\nsess0 = tf.Session(server.target, config=config0)\r\nsess1 = tf.Session(server.target, config=config1)\r\n```\r\n**Describe the current behavior**\r\nsess1 have config0\r\n**Describe the expected behavior**\r\nsess1 have config1\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n- Do you want to contribute a PR? (yes/no): yes\r\n- Briefly describe your candidate solution(if contributing):\r\n-     https://github.com/tensorflow/tensorflow/pull/52939\r\n\r\nsession config in server to session: https://github.com/tensorflow/tensorflow/issues/8982 \r\nbackground:\r\n1. We use two sessions to run two graphs in two thread.\r\n2. two graph share a resource-mgr, because we hope save a checkpoint .", "comments": ["Could you please fill the issue template https://github.com/tensorflow/tensorflow/issues/new/choose to expedite the process. Thanks", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52938\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52938\">No</a>\n"]}, {"number": 52937, "title": "tf.keras import raises an AlreadyExistsError with keras 2.7", "body": "\r\nHello there :wave:\r\n\r\nI encountered a CI problem with a build job today that wasn't happening yesterday. So I checked the difference in terms of dependency and the only difference was keras. So I inspected the traceback and ended up tracking the import from keras that causes trouble. I already reported this to the keras team in https://github.com/keras-team/keras/issues/15585 but I figured it might be of importance to you folks considering this impacts several imports from tensorflow itself!\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04 LTS\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.6.0\r\n- Python version: 3.8.10\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: CUDA 11.4.100 & cuDNN 8.2.2 \r\n- GPU model and memory: NVIDIA GeForce RTX 2070 with Max-Q Design\r\n\r\n**Describe the current behavior**\r\n\r\nRunning the standalone code throws an `AlreadyExistsError`\r\n\r\n**Describe the expected behavior**\r\n\r\nNot raising any error.\r\n\r\n- Do you want to contribute a PR? (yes/no): happy to do so, but I'm not sure how to solve this\r\n- Briefly describe your candidate solution(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n```python\r\nfrom tensorflow.keras.utils import img_to_array\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nAlreadyExistsError                        Traceback (most recent call last)\r\n<ipython-input-1-a2ab22b98110> in <module>\r\n----> 1 from tensorflow.keras.utils import img_to_array\r\n\r\n~/miniconda3/lib/python3.8/site-packages/keras/api/_v2/keras/__init__.py in <module>\r\n      8 import sys as _sys\r\n      9 \r\n---> 10 from keras import __version__\r\n     11 from keras.api._v2.keras import __internal__\r\n     12 from keras.api._v2.keras import activations\r\n\r\n~/miniconda3/lib/python3.8/site-packages/keras/__init__.py in <module>\r\n     23 \r\n     24 # See b/110718070#comment18 for more details about this import.\r\n---> 25 from keras import models\r\n     26 \r\n     27 from keras.engine.input_layer import Input\r\n\r\n~/miniconda3/lib/python3.8/site-packages/keras/models.py in <module>\r\n     18 import tensorflow.compat.v2 as tf\r\n     19 from keras import backend\r\n---> 20 from keras import metrics as metrics_module\r\n     21 from keras import optimizer_v1\r\n     22 from keras.engine import functional\r\n\r\n~/miniconda3/lib/python3.8/site-packages/keras/metrics.py in <module>\r\n     24 \r\n     25 import numpy as np\r\n---> 26 from keras import activations\r\n     27 from keras import backend\r\n     28 from keras.engine import base_layer\r\n\r\n~/miniconda3/lib/python3.8/site-packages/keras/activations.py in <module>\r\n     18 \r\n     19 from keras import backend\r\n---> 20 from keras.layers import advanced_activations\r\n     21 from keras.utils.generic_utils import deserialize_keras_object\r\n     22 from keras.utils.generic_utils import serialize_keras_object\r\n\r\n~/miniconda3/lib/python3.8/site-packages/keras/layers/__init__.py in <module>\r\n     21 \r\n     22 # Generic layers.\r\n---> 23 from keras.engine.input_layer import Input\r\n     24 from keras.engine.input_layer import InputLayer\r\n     25 from keras.engine.input_spec import InputSpec\r\n\r\n~/miniconda3/lib/python3.8/site-packages/keras/engine/input_layer.py in <module>\r\n     19 from keras import backend\r\n     20 from keras.distribute import distributed_training_utils\r\n---> 21 from keras.engine import base_layer\r\n     22 from keras.engine import keras_tensor\r\n     23 from keras.engine import node as node_module\r\n\r\n~/miniconda3/lib/python3.8/site-packages/keras/engine/base_layer.py in <module>\r\n     41 from keras.engine import node as node_module\r\n     42 from keras.mixed_precision import autocast_variable\r\n---> 43 from keras.mixed_precision import loss_scale_optimizer\r\n     44 from keras.mixed_precision import policy\r\n     45 from keras.saving.saved_model import layer_serialization\r\n\r\n~/miniconda3/lib/python3.8/site-packages/keras/mixed_precision/loss_scale_optimizer.py in <module>\r\n     16 \r\n     17 from keras import backend\r\n---> 18 from keras import optimizers\r\n     19 from keras.mixed_precision import loss_scale as keras_loss_scale_module\r\n     20 from keras.optimizer_v2 import optimizer_v2\r\n\r\n~/miniconda3/lib/python3.8/site-packages/keras/optimizers.py in <module>\r\n     24 from keras.optimizer_v1 import Optimizer\r\n     25 from keras.optimizer_v1 import TFOptimizer\r\n---> 26 from keras.optimizer_v2 import adadelta as adadelta_v2\r\n     27 from keras.optimizer_v2 import adagrad as adagrad_v2\r\n     28 from keras.optimizer_v2 import adam as adam_v2\r\n\r\n~/miniconda3/lib/python3.8/site-packages/keras/optimizer_v2/adadelta.py in <module>\r\n     20 import numpy as np\r\n     21 from keras import backend_config\r\n---> 22 from keras.optimizer_v2 import optimizer_v2\r\n     23 from tensorflow.python.util.tf_export import keras_export\r\n     24 \r\n\r\n~/miniconda3/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py in <module>\r\n     34 \r\n     35 \r\n---> 36 keras_optimizers_gauge = tf.__internal__.monitoring.BoolGauge(\r\n     37     \"/tensorflow/api/keras/optimizers\", \"keras optimizer usage\", \"method\")\r\n     38 \r\n\r\n~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/monitoring.py in __init__(self, name, description, *labels)\r\n    358       *labels: The label list of the new metric.\r\n    359     \"\"\"\r\n--> 360     super(BoolGauge, self).__init__('BoolGauge', _bool_gauge_methods,\r\n    361                                     len(labels), name, description, *labels)\r\n    362 \r\n\r\n~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/monitoring.py in __init__(self, metric_name, metric_methods, label_length, *args)\r\n    133           self._metric_name, len(self._metric_methods)))\r\n    134 \r\n--> 135     self._metric = self._metric_methods[self._label_length].create(*args)\r\n    136 \r\n    137   def __del__(self):\r\n\r\nAlreadyExistsError: Another metric with the same name already exists.\r\n```\r\n", "comments": ["see https://github.com/tensorflow/tensorflow/issues/52922\r\n\r\nkeras 2.7 is not compatible with tf 2.6.x but the dependency specification in tensorflow 2.6.0 and 2.6.1 for keras `~=2.6` allows keras 2.7 to be installed. \r\n\r\n", "I see, so I guess this shouldn't be an issue anymore with TF 2.6.2 patch release?", "seems to be the case, 2.6.2 is installing the correct versions of the dependencies in my builds", "This issue broke some of my team's production pipelines. We specify a dependency on `tensorflow==2.6.0`, but didn't specify a pinned version of Keras, so we automatically got 2.7.0 yesterday.\r\n\r\nI think this is a bug with either:\r\n1. [tensorflow's requirements specification](https://github.com/tensorflow/tensorflow/blob/v2.6.0/tensorflow/tools/pip_package/setup.py#L106) (eg for TF 2.6, I think the dependency should be `'keras == 2.6.*'` instead of `'keras ~= 2.6'`), or\r\n2. Keras versioning not following [semver](https://semver.org/), since a minor version release was not backwards compatible.\r\n\r\nLooks like TF's setup.py on master has been updated for this, so hopefully we won't see similar issues in the future: https://github.com/tensorflow/tensorflow/blob/8a2a4c3ca06a622989823c7dfa58e01044244935/tensorflow/tools/pip_package/setup.py#L102", "Should be fixed by TF 2.6.2 and TF 2.7", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52937\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52937\">No</a>\n", "Hi @frgfm ! This issue is not replicating with TF 2.6  or TF-nightly in Colab Environment.  Attaching [Gist](https://colab.research.google.com/gist/mohantym/0e6f734312f9b78b0f2760a5cc136800/github_52937.ipynb) for reference . Could you try again with TF 2.6 and Keras 2.6 ?", "Hi @mohantym,\r\nI'm sure not sure this is related? The bottom of this issue is that there was a loose version constraint for keras on the TF side up until 2.6.2 and 2.7. So yes, if you manually install keras 2.6, it does work as expected :)\r\nMy point was that if you had installed one of the release before 2.6.2 (say 2.6.0), the installer might be tempted to install keras 2.7 which was not compatible. I haven't had time to test whether the issue still happens with TF 2.6.2 but this appears to have been solved :+1: ", "Ok @frgfm ! Thanks for confirming the same .You can also test with TF 2.7 and Keras 2.7. Closing this issue as it seems to be resolved.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52937\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52937\">No</a>\n"]}, {"number": 52936, "title": "@mihaimaruseac I'm working in colab and  changed `tf.gfile.GFile` to `tf.io.gfile.GFile` but still get this error", "body": "@mihaimaruseac I'm working in colab and  changed `tf.gfile.GFile` to `tf.io.gfile.GFile` but still get this error\r\n`AttributeError: module 'tensorflow' has no attribute 'gfile'\r\n`\r\n\r\n_Originally posted by @mitramir55 in https://github.com/tensorflow/tensorflow/issues/31315#issuecomment-643277101_", "comments": ["> @mihaimaruseac I'm working in colab and changed `tf.gfile.GFile` to `tf.io.gfile.GFile` but still get this error `AttributeError: module 'tensorflow' has no attribute 'gfile' `\r\n> \r\n> _Originally posted by @mitramir55 in [#31315 (comment)](https://github.com/tensorflow/tensorflow/issues/31315#issuecomment-643277101)_\r\n\r\nI'm also getting the same ..how to figure it out?", "@161019733305 \r\nI tried https://www.tensorflow.org/io/tutorials/avro tutorial which shows tf.io.gfile.GFile usage example. I didn't see AttributeError raised. [also please fill in the issue template and share the tf version and verify the system requirements for compatibility issues]\r\n\r\nschema = tf.io.gfile.GFile('train.avsc').read()\r\n\r\nPerhaps you can confirm at your end. [please find the [gist](https://colab.research.google.com/gist/Saduf2019/343a29e9fa6b969520d959cb61ea7ea2/untitled.ipynb) for your reference]Thanks!", "Duplicate of #31315 which is already resolved.\r\n\r\nPlease make sure you environment only uses packages that are build for TF 2.x", "Sorry, misread. But please fill in issue template and provide a minimal reproducer", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 52935, "title": "TFlite model always have fixed dimensions output", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):all the platform:(win10 ubuntu android)\r\n- TensorFlow installed from (source or binary):(colab default)\r\n- TensorFlow version:2.6.0(colab default)\r\n\r\nI try to add some postprocess layers after [a Keras model](https://drive.google.com/file/d/1yKLW5F7-6x9ylH65MgVxH5N5oQJgK8wq/view?usp=sharing) which can detect faces in an image, then I convert it to Savedmodel format and the savedmodel also works well.After that I convert it to[ a tflite model](https://drive.google.com/file/d/1i1fLQTQGA7V8tcihyWhldoIswOaEe0tq/view?usp=sharing), but no matter what image I input, the tflite model alway has a fixed dimensions and it equals to a parameter [**max_output_size**,17] which I set in  \r\n`out_boxes = tf.image.non_max_suppression(box_tlbr, scores, max_output_size=5,\r\n                                                 score_threshold=0.5, iou_threshold=0.3)`\r\neg:\r\n![no_face](https://user-images.githubusercontent.com/32239722/140266840-bab3021e-548f-4b28-8079-5d8902cf5c57.PNG)\r\ntflite model output:\r\n`[[ 4.5394583e+00  3.3936653e+00  2.9001554e+01  2.9001198e+01\r\n   3.2894442e+00 -1.5875316e+00  9.0569210e+00 -7.6022291e-01\r\n   5.5141363e+00  2.7957358e+00  3.5612986e+00  8.0328922e+00\r\n  -3.7986336e+00  9.2154026e-02  1.3225850e+01  2.9794626e+00\r\n   4.5634112e-03]\r\n [ 4.5394583e+00  3.3936653e+00  2.9001554e+01  2.9001198e+01\r\n   3.2894442e+00 -1.5875316e+00  9.0569210e+00 -7.6022291e-01\r\n   5.5141363e+00  2.7957358e+00  3.5612986e+00  8.0328922e+00\r\n  -3.7986336e+00  9.2154026e-02  1.3225850e+01  2.9794626e+00\r\n   4.5634112e-03]\r\n [ 4.5394583e+00  3.3936653e+00  2.9001554e+01  2.9001198e+01\r\n   3.2894442e+00 -1.5875316e+00  9.0569210e+00 -7.6022291e-01\r\n   5.5141363e+00  2.7957358e+00  3.5612986e+00  8.0328922e+00\r\n  -3.7986336e+00  9.2154026e-02  1.3225850e+01  2.9794626e+00\r\n   4.5634112e-03]\r\n [ 4.5394583e+00  3.3936653e+00  2.9001554e+01  2.9001198e+01\r\n   3.2894442e+00 -1.5875316e+00  9.0569210e+00 -7.6022291e-01\r\n   5.5141363e+00  2.7957358e+00  3.5612986e+00  8.0328922e+00\r\n  -3.7986336e+00  9.2154026e-02  1.3225850e+01  2.9794626e+00\r\n   4.5634112e-03]\r\n [ 4.5394583e+00  3.3936653e+00  2.9001554e+01  2.9001198e+01\r\n   3.2894442e+00 -1.5875316e+00  9.0569210e+00 -7.6022291e-01\r\n   5.5141363e+00  2.7957358e+00  3.5612986e+00  8.0328922e+00\r\n  -3.7986336e+00  9.2154026e-02  1.3225850e+01  2.9794626e+00\r\n   4.5634112e-03]]`\r\nand \r\n![friends](https://user-images.githubusercontent.com/32239722/140267008-b24ebde3-66b3-431c-b9bb-31a1fbd36e9d.jpg)\r\ntflite model output:\r\n`[[ 26.30391     45.815998    15.318579    15.318455    25.36796\r\n   41.83495     29.585167    45.42548     25.27378     46.95403\r\n   23.45119     49.55304     22.601065    40.5007      32.286842\r\n   48.044865     0.7468504 ]\r\n [ 78.23201     51.20295     19.179186    19.179142    78.84692\r\n   47.8986      83.48271     50.48215     80.6107      52.646446\r\n   78.44246     54.880447    72.91944     45.85292     83.785065\r\n   51.694183     0.6747569 ]\r\n [ 53.54354     47.331875    19.37531     19.375237    50.628742\r\n   43.143784    55.891808    45.867424    51.231808    47.359013\r\n   50.78139     50.537304    49.22387     43.62208     60.94362\r\n   48.629707     0.6197063 ]\r\n [101.9684      49.856655    19.639782    19.639744    98.39309\r\n   46.63186    104.05909     46.658813   100.23142     49.016006\r\n  100.64084     52.422737    96.56004     47.981262   109.495316\r\n   47.874664     0.5907868 ]\r\n [ 43.294758    48.23123     18.912622    18.91256     41.17029\r\n   45.106667    45.666157    46.91061     41.867565    48.94021\r\n   41.34953     51.683       38.825493    43.775955    50.385445\r\n   47.55902      0.57340574]]`\r\nThe last column means the face confidence, I know I can filter some boxes,  just out of curiosity\uff0c  does it have to be a fixed dimension output or it is some bug in tflite's nms\r\n\r\n\r\n\r\n\r\n\r\n\r\nCodes I use for add some layers:\r\n```\r\nblazeface_tf_model = tf.keras.models.load_model(r\"/content/blazeface_tf.h5\")\r\nclass FaceDetetor(layers.Layer):\r\n    def __init__(self):\r\n        super(FaceDetetor, self).__init__()\r\n        self.classifier = blazeface_tf_model\r\n\r\n\r\n    def call(self, inputs):\r\n        input_tensor = (inputs / 127.5) - 1\r\n        temp_tensor = self.classifier(input_tensor)\r\n        \r\n        reshape_tensor = tf.reshape(temp_tensor, [-1, temp_tensor.shape[2]])\r\n        final_boxes = tf.slice(reshape_tensor, [0, 0], [-1, 4])\r\n        \r\n        temp_boxex_1 = tf.slice(final_boxes, [0, 0], [-1, 2])  # \u4e2d\u5fc3 y_x\r\n        temp_boxex_2 = tf.slice(final_boxes, [0, 2], [-1, 2])  # w_h\r\n        temp_boxex_2_1 = temp_boxex_2 / 2\r\n        \r\n        ts_sub1 = tf.subtract(temp_boxex_1, temp_boxex_2_1, name=None)\r\n        temp_clip = tf.clip_by_value(ts_sub1, 0, 100000000)\r\n        \r\n        ts_add1 = tf.add(temp_boxex_1, temp_boxex_2_1, name=None)\r\n        \r\n        yx1_columns = tf.unstack(temp_clip, axis=-1)\r\n        xy1_columns = tf.stack([yx1_columns[1], yx1_columns[0]], axis=-1)\r\n        yx2_columns = tf.unstack(ts_add1, axis=-1)\r\n        xy2_columns = tf.stack([yx2_columns[1], yx2_columns[0]], axis=-1)\r\n        box_tlbr = tf.concat([xy1_columns, xy2_columns], 1)\r\n        #### xywh_to_tlbr ####\r\n        raw_scores = tf.slice(reshape_tensor, [0, temp_tensor.shape[2] - 1], [-1, 1])\r\n        scores = tf.reshape(raw_scores, [-1])\r\n        out_boxes = tf.image.non_max_suppression(box_tlbr, scores, max_output_size=5,\r\n                                                 score_threshold=0.5, iou_threshold=0.3)\r\n       \r\n        rows = tf.gather(reshape_tensor, out_boxes, axis=0)\r\n        final_boxes = tf.slice(rows, [0, 0], [-1, temp_tensor.shape[2] - 1])\r\n        if len(final_boxes.shape) == 1:\r\n            final_boxes = tf.expand_dims(final_boxes, axis=0)\r\n        orig_points = final_boxes * 128\r\n        final_scores = tf.gather(raw_scores, out_boxes, axis=0)\r\n        final_result = tf.concat([orig_points, final_scores], 1)\r\n        return final_result\r\nmax_output_size = 5\r\nscore_threshold = 0.75\r\niou_threshold = 0.5\r\ninputs_0 = keras.Input(batch_shape=((1, 128, 128, 3)), dtype=tf.float32, name=\"input_images\")\r\n# inputs_1 = keras.Input(shape=(1), dtype=tf.int32, name=\"max_output_size\")\r\n# inputs_2 = keras.Input(shape=(1), dtype=tf.float32, name=\"score_threshold\")\r\n# inputs_3 = keras.Input(shape=(1), dtype=tf.float32, name=\"iou_threshold\")\r\noutputs = FaceDetetor()(inputs_0)\r\n\r\nmodel_folder_path = r\"/content/face_detector_inputs3\"\r\nmodel = keras.Model(inputs_0, outputs=outputs)\r\nmodel.save(model_folder_path, save_format='tf')\r\nprint(\"saved model!\")\r\n```\r\n\r\nCodes I use for savedmodel convert to tflite:\r\n```\r\nconverter = tf.lite.TFLiteConverter.from_saved_model(model_folder_path)\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nconverter.experimental_new_converter = True\r\nconverter.target_spec.supported_types = [tf.float16]\r\nconverter.target_spec.supported_ops = [\r\n    tf.lite.OpsSet.TFLITE_BUILTINS,\r\n    tf.lite.OpsSet.SELECT_TF_OPS\r\n    ]\r\ntflite_model = converter.convert()\r\noutput_tflite_path_float = r'/content/face_detector_float16.tflite'\r\nwith open(output_tflite_path_float, 'wb') as f:\r\n    f.write(tflite_model)\r\n```\r\n\r\n**Standalone code to reproduce the issue** \r\nFor more  details: [colab ](https://colab.research.google.com/drive/12fIvXNJvrtgeUvgfwVbUwISQdWStmStz?usp=sharing)\r\n\r\n", "comments": ["@whalefa1I ,\r\nOn running the given code, I was facing different error. Please find the gist of it [here](https://colab.research.google.com/gist/tilakrayal/cd328e6d5a60e8148c4826f15aa36622/52935.ipynb).Please provide all the dependencies to reproduce the issue.Thanks!", "Also please refer this [issue](https://github.com/tensorflow/tensorflow/issues/41391) with the similar error.It helps.Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52935\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52935\">No</a>\n"]}, {"number": 52934, "title": "[TF-TRT] - TRTEngineOP do not show output shape", "body": "TRTEngineOP node attribute `_output_shapes` returns an empty list. We need to fix that.\r\n\r\n@bixia1 @tfeher  FYI", "comments": ["Hi @Saduf2019 ! Could you please look at this feature request . PR has been created  for this issue in #52625 ", "@mohantym a PR has not been created for the feature. It's left as a TODO. @bixia1 requested to create a GH issue to track it.", "@DEKHTIARJonathan \r\nplease verify the PR and move this to closed status.", "I specifically implemented the PR to fix this issue, so I don't need to check anything"]}, {"number": 52932, "title": "[TF:TRT] Enable support for TensorRT 8.2", "body": "Add support for TensorRT 8.2.\r\n\r\nAdd plugin stubs for TensorRT 8.2.\r\nModify tests to hold an IBuilder to prevent TensorRT 8.2 from releasing builder resources when running parameterized tests.", "comments": ["Request review from @bixia1 ", "I edited the PR description with details on what the PR does. Please check.", "> I edited the PR description with details on what the PR does. Please check.\r\n\r\nMade small correction, but looks good.\r\n\r\nPushed up changes to address comments.", "within google, we use TensorRT 7, and here is the error:\r\n```\r\nIn file included from third_party/tensorflow/compiler/tf2tensorrt/convert/convert_nodes_test.cc:16:\r\nIn file included from ./third_party/tensorflow/compiler/tf2tensorrt/convert/convert_nodes.h:19:\r\nIn file included from third_party/stl/cxx17/set:16:\r\nIn file included from third_party/crosstool/v18/stable/toolchain/bin/../include/c++/v1/set:439:\r\nIn file included from third_party/crosstool/v18/stable/toolchain/bin/../include/c++/v1/__node_handle:63:\r\nIn file included from third_party/stl/cxx17/memory:4:\r\nIn file included from third_party/crosstool/v18/stable/toolchain/bin/../include/c++/v1/memory:682:\r\nIn file included from third_party/crosstool/v18/stable/toolchain/bin/../include/c++/v1/__memory/shared_ptr.h:25:\r\nthird_party/crosstool/v18/stable/toolchain/bin/../include/c++/v1/__memory/unique_ptr.h:60:12: error: calling a protected destructor of class 'nvinfer1::IBuilder'\r\n    delete __ptr;\r\n           ^\r\nthird_party/crosstool/v18/stable/toolchain/bin/../include/c++/v1/__memory/unique_ptr.h:282:7: note: in instantiation of member function 'std::default_delete<nvinfer1::IBuilder>::operator()' requested here\r\n      __ptr_.second()(__tmp);\r\n      ^\r\nthird_party/tensorflow/compiler/tf2tensorrt/convert/convert_nodes_test.cc:155:61: note: in instantiation of member function 'std::unique_ptr<nvinfer1::IBuilder>::~unique_ptr' requested here\r\n  static std::unique_ptr<nvinfer1::IBuilder> hold_builder = nullptr;\r\n                                                            ^\r\nblaze-out/k8-cuda11-opt/bin/third_party/tensorrt/_virtual_includes/nv_infer_static_cuda_11_0/third_party/tensorrt/NvInfer.h:7097:13: note: declared protected here\r\n    virtual ~IBuilder()\r\n            ^\r\n```", "I pushed a change that should fix the issue."]}, {"number": 52931, "title": "[ROCm] skip gpu_binary_ops_test", "body": "This test failed since commit 7de9cf4 from upstream. Disabling for now to keep the CI from complaining. Investigation underway.\r\n\r\n@cheshire @chsigg @deven-amd @reza-amd\r\n", "comments": ["All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F52931) for more info**.\n\n<!-- need_author_consent -->", "@googlebot I consent."]}, {"number": 52930, "title": "Update version numbers for TensorFlow 2.6.2", "body": "Before merging this PR, please double check that it has correctly updated\n`core/public/version.h`, `tools/pip_package/setup.py`, and\n`tensorflow/tensorflow.bzl`. Also review the execution notes below:\n\n```\nMajor: 2 -> 2\nMinor: 6 -> 6\nPatch: 1 -> 2\n\nWARNING: Below are potentially instances of lingering old version string \n\"2.6.1\" in source directory \"tensorflow/\" that are not updated by this script. \nPlease check them manually!\ntensorflow/lite/toco/logging/template.html:142:2.6.1\ntensorflow/lite/toco/logging/testdata/generated.html:142:2.6.1\ntensorflow/tools/ci_build/linux/mkl/Dockerfile.devel-mkl:90:2.6.1\n\nWARNING: Below are potentially instances of lingering old version string \n\"2.6.1\" in source directory \"tensorflow/\" that are not updated by this script. \nPlease check them manually!\ntensorflow/lite/toco/logging/template.html:142:2.6.1\ntensorflow/lite/toco/logging/testdata/generated.html:142:2.6.1\ntensorflow/tools/ci_build/linux/mkl/Dockerfile.devel-mkl:90:2.6.1\n```", "comments": []}, {"number": 52929, "title": "Update the version on estimator and tensorboard", "body": "Add an upper bound to keras and tensorboard", "comments": []}, {"number": 52928, "title": "Update release notes for TensorFlow 2.6.2", "body": "This PR is intentionally incomplete. One of the Release Owners for 2.6.2\nneeds to fill in the internal release notes for this version before the PR gets\nsubmitted. Click on the :pencil2: icon in the header for `RELEASE.md` under\n\"Files Changed\" above.", "comments": []}, {"number": 52927, "title": "Update the keras version used by tf 2.6 release", "body": "Since Keras 2.7 is not compatible with tf 2.6, we should limit the Keras version used in tf.\r\n\r\nThis change has been done for tf 2.7 and all the future releases.", "comments": ["@qlzh727 as a follow up to this fix, should we yank https://pypi.org/project/tensorflow/2.6.1/?", "> @qlzh727 as a follow up to this fix, should we yank https://pypi.org/project/tensorflow/2.6.1/?\r\n\r\nnvm, older versions would suffer the same issue. Maybe the best solution is to release 2.6.2 soon with this fix.", "Yes, we are building a new tf 2.6 (should be 2.6.2).", "> Yes, we are building a new tf 2.6 (should be 2.6.2).\r\n\r\nThank you very much for doing this so fast! It is highly appreciated. :+1: ", "Would it be possible to install the 2.6.2 using pip install?", "> Would it be possible to install the 2.6.2 using pip install?\r\n\r\nYes. [TensorFlow `v2.6.2`](https://github.com/tensorflow/tensorflow/releases/tag/v2.6.2) was _just_ cut (minutes ago :rocket:) so it should be up on PyPI soon I would assume.", "@idohi and now less than 30 minutes later [`v2.6.2` is up on PyPI](https://pypi.org/project/tensorflow/2.6.2/). :tada: ", "TF 2.6.1 is also relevant, we shouldn't yank it.\r\n\r\nTF 2.6.2 has all the fixes", "Facing this issue with tf 2.6.0 on colab. 2.6.1 and 2.6.2 work fine and show keras version 2.6.0."]}, {"number": 52926, "title": "[TF-TRT] trt_utils.versionTupleToString didn't exist, changing to trt_utils.version_tuple_to_string", "body": "Replace the use of versionTupleToString with version_tuple_to_string to fix a bug introduced by a previous change.", "comments": []}, {"number": 52925, "title": "Generate bias with correct type when tfl.fully_connected bias isn't provided", "body": "Fix legalization bug when tfl.fully_connected isn't provided with bias and generate incorrect type of const tensor tensor.", "comments": []}, {"number": 52924, "title": "[ROCm] Skip xla_ops_tests", "body": "Invalid bitcast in xla_ops_test and xla_ops_test_gpu_mlir_bridge_test, and filecheck error in gpu_index_test. \r\nInvestigation underway, but skip for now.\r\n\r\n@cheshire @chsigg @deven-amd @stevenireeves ", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F52924) for more info**.\n\n<!-- need_author_cla -->", "All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F52924) for more info**.\n\n<!-- need_author_consent -->", "@googlebot I fixed it", "All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F52924) for more info**.\n\n<!-- need_author_consent -->", "@googlebot I consent."]}, {"number": 52923, "title": "Restoring a model with frozen TimeDistributed layers onto an unfrozen model does not work", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 21H1\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): v2.6.0-0-g919f693420e 2.6.0\r\n- Python version: 3.7.12\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**Describe the current behavior**\r\nThe following (minimal) implementation of the model and weight saving and loading fails with the timedistributed layer but works without it.\r\n\r\n```\r\nimport os\r\nfrom tensorflow.keras.layers import Dense, Input, TimeDistributed\r\nfrom tensorflow.keras.activations import sigmoid\r\nfrom tensorflow.keras.metrics import BinaryAccuracy\r\nfrom tensorflow.keras.models import Model\r\nfrom tensorflow.keras.optimizers import Adam\r\nfrom tensorflow.keras.applications import MobileNetV2\r\n\r\ndef get_model(working_dir, finetune):\r\n\r\n    base_model = MobileNetV2(weights='imagenet',\r\n                             include_top=False,\r\n                             alpha=1.4,\r\n                             input_shape=(224, 224, 3),\r\n                             pooling='avg')\r\n\r\n    inp = Input((10, 224, 224, 3))\r\n    x = TimeDistributed(base_model)(inp)\r\n\r\n    # Comment out the previous two lines\r\n    # and uncomment these next two lines to see the expected behavior\r\n\r\n    # inp = base_model.input\r\n    # x = base_model.output\r\n\r\n    predictions = Dense(1, activation=sigmoid)(x)\r\n\r\n    model = Model(inputs=inp, outputs=predictions)\r\n\r\n    if not finetune:\r\n        for layer in base_model.layers:\r\n            layer.trainable = False\r\n        learning_rate = 0.001\r\n    else:\r\n        saved_model_path = os.path.join(working_dir, \"saved_model.h5\")\r\n        model.load_weights(saved_model_path)\r\n        learning_rate = 0.00001\r\n\r\n    binacc = BinaryAccuracy(name=\"binary_accuracy\")\r\n    adam = Adam(lr=learning_rate, epsilon=1e-09, clipnorm=0.001)\r\n\r\n    model.compile(optimizer=adam,\r\n                    loss='binary_crossentropy',\r\n                    metrics=[binacc])\r\n    model.summary()\r\n\r\n    return model\r\n\r\nworking = \"/content/test\"\r\n\r\nmodel = get_model(working, False)\r\nmodel.save(os.path.join(working, \"saved_model.h5\"))\r\nmodel = get_model(working, True)\r\n```\r\n\r\nI'm trying to finetune a model that I'm working on. I'm initially creating a model with a pretrained model connected to some new layers. The pretrained model is frozen for the first round of training and the model is saved. I then create the same model with the pretrained model unfrozen and try to restore the weights using model.load_weights. This results in the following error on my local pc running tensorflow 2.4.0.\r\n\r\n\"ValueError: Cannot assign to variable expanded_conv_depthwise/depthwise_kernel:0 due to variable shape (3, 3, 48, 1) and value shape (48,) are incompatible\" and \r\n\r\nOn Google Colab running tensorflow 2.6.0, I get\r\n\r\n\"ValueError: axes don't match array\"\r\n\r\n**Describe the expected behavior**\r\n\r\nWeights should be restored correctly.\r\n\r\n**Standalone code to reproduce the issue**\r\nhttps://colab.research.google.com/drive/1X92pRi4yqNhOO0l_AAbpbSpaGidwytlP\r\n", "comments": ["@brandon-wu76,\r\n\r\nI modified your code to save the model in `SavedModel` format and not on `h5 format`, which is working fine and I am able to load the model. Can you take a look at this [gist here](https://colab.sandbox.google.com/gist/sanatmpa1/51357fe30394b38a564a41286fadecc9/untitled3.ipynb). Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52923\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52923\">No</a>\n"]}, {"number": 52922, "title": "TensorFlow 2.6 installs Keras 2.7", "body": "**System information**\r\n- OS Platform and Distribution: Ubuntu 18.04\r\n- TensorFlow installed from: binary\r\n- TensorFlow version: 2.6.1\r\n- Python version: 3.6.9\r\n- Installed using virtualenv? pip? conda?: virtualenv + pip\r\n\r\n**Describe the problem**\r\n\r\nTensorFlow 2.6 installs Keras 2.7, but it should install Keras 2.6 instead.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n```bash\r\npip install tensorflow==2.6.*\r\n```\r\n\r\n**Any other info / logs**\r\n\r\nSee `keras-2.7.0` in the list of installed packages:\r\n\r\n> `Successfully installed absl-py-0.15.0 astunparse-1.6.3 cached-property-1.5.2 cachetools-4.2.4 certifi-2021.10.8 charset-normalizer-2.0.7 clang-5.0 dataclasses-0.8 flatbuffers-1.12 gast-0.4.0 google-auth-2.3.3 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.41.1 h5py-3.1.0 idna-3.3 importlib-metadata-4.8.1 keras-2.7.0 keras-preprocessing-1.1.2 markdown-3.3.4 numpy-1.19.5 oauthlib-3.1.1 opt-einsum-3.3.0 protobuf-3.19.1 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-2.26.0 requests-oauthlib-1.3.0 rsa-4.7.2 six-1.15.0 tensorboard-2.7.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.6.1 tensorflow-estimator-2.6.0 termcolor-1.1.0 typing-extensions-3.7.4.3 urllib3-1.26.7 werkzeug-2.0.2 wrapt-1.12.1 zipp-3.6.0`\r\n", "comments": ["Don't know if it's related but I'm seeing things like this in my own pip installation logs:\r\n\r\n```\r\n#9 70.10 Collecting tensorflow-estimator~=2.6\r\n#9 70.15   Downloading tensorflow_estimator-2.7.0-py2.py3-none-any.whl (463 kB)\r\n#9 74.69 Collecting tensorboard~=2.6\r\n#9 74.72   Downloading tensorboard-2.7.0-py3-none-any.whl (5.8 MB)\r\n```\r\n\r\nI've noticed that `keras~=2.6` is also resolving to 2.7\r\n\r\nAre these other dependencies being installed incorrectly as well?", "The above linked PR is merged, now you should be able to see the compatible versions, please check [this](https://colab.research.google.com/gist/sachinprasadhs/3e16aa2c6b60c12bb3902957e9175b9d/52922.ipynb) gist for reference which is working as expected.Thanks.", "@sachinprasadhs Your notebook is wrong as a Colab instance has a preinstalled env with Tensorflow and Keras that was prepared before Keras TF 2.7 was available so you cannot test in this way.\r\n\r\nYou need something like:\r\n```\r\n!pip uninstall -y tensorflow keras\r\n!pip install tensorflow==2.6\r\n```\r\nor on a local instance:\r\n\r\n```\r\ndocker run --rm -it python:3.9 pip install tensorflow==2.6\r\n```\r\n\r\n\r\n", "This is also against the official claimed Keras-TF versions compatibilities at:\r\n\r\nhttps://github.com/keras-team/keras#release-and-compatibility", "This would be fixed in ~12 hours by a release of TF 2.6.2 patch release and TF 2.7.0 release.\r\n\r\nThe issue is a bug in TF 2.6 where we specified Keras dependency as `~= 2.6` instead of `~= 2.6.0`. The `~=` semantic is \"take the version on the right, keep all the numbers specified there except the last one, that's the only one that can chance\". So `~= 2.6` means that `keras == 2.99` would also be viable for the dependency resolution, clearly a bug.\r\n\r\nThis is not an issue with the stated Keras-TF compatibility. Just the `~=` semantic being buggy as it needs to specify `major.minor.patch` for these versions that are always in sync.", "Yes exaclty as they claim:\n\n> Keras 2.6 with TF >= 2.6 < 2.7", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "This should be fixed with the release of TF 2.6.2", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52922\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52922\">No</a>\n"]}, {"number": 52921, "title": "ValueError: input resource[0] expected type resource != float, the type of embeddings_sharded_0[0]", "body": "Hi,\r\nI'm going to optimize my model and convert it to FP16. When using trt_conver, this error raises:\r\n```\r\nValueError: input resource[0] expected type resource != float, the type of embeddings_sharded_0[0]\r\n        In {{node EncoderTransformer/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup/Gather}}\r\n```", "comments": ["@farzanehnakhaee70 \r\nIn order to expedite the trouble-shooting process here,Could you please fill the issue [template](https://github.com/tensorflow/tensorflow/issues/new/choose),\r\nThanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52921\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52921\">No</a>\n"]}, {"number": 52920, "title": "Bazel build tensorflow error - C++ compilation of rule", "body": "**System information**\r\n- OS Platform and Distribution: Debian buster Raspbian 10 \r\n- TensorFlow installed from source\r\n- TensorFlow version: 2.6.0\r\n- Python version: 3.7.3\r\n- Bazel version: 3.7.2 \r\n- GCC/Compiler version: 8.3.0\r\n- CUDA/cuDNN version: No CUDA\r\n- GPU model and memory: No GPU\r\n\r\n\r\nI am trying to build tensorflow using bazel (3.7.2). But when I run:\r\n`bazel build //tensorflow/tools/pip_package:build_pip_package`\r\n\r\nI got this error after ~13 hours running.\r\n\r\n```\r\nERROR: /home/pi/tensorflow/tensorflow/compiler/xla/service/llvm_ir/BUILD:64:11: C++ compilation of rule '//tensorflow/compiler/xla/service/llvm_ir:llvm_util' failed (Exit 1): gcc failed: error executing command /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections ... (remaining 141 argument(s) skipped)\r\nIn file included from external/com_google_absl/absl/base/internal/endian.h:29,\r\n                 from external/com_google_absl/absl/strings/cord.h:73,\r\n                 from ./tensorflow/core/platform/default/cord.h:22,\r\n                 from ./tensorflow/core/platform/cord.h:25,\r\n                 from ./tensorflow/core/platform/tstring.h:24,\r\n                 from ./tensorflow/core/platform/types.h:23,\r\n                 from ./tensorflow/core/platform/logging.h:20,\r\n                 from ./tensorflow/core/platform/status.h:25,\r\n                 from ./tensorflow/core/lib/core/status.h:19,\r\n                 from ./tensorflow/compiler/xla/status.h:19,\r\n                 from ./tensorflow/compiler/xla/array.h:33,\r\n                 from ./tensorflow/compiler/xla/array2d.h:29,\r\n                 from ./tensorflow/compiler/xla/literal.h:32,\r\n                 from ./tensorflow/compiler/xla/service/llvm_ir/llvm_util.h:35,\r\n                 from tensorflow/compiler/xla/service/llvm_ir/llvm_util.cc:16:\r\nexternal/com_google_absl/absl/base/casts.h: In instantiation of 'Dest absl::lts_20210324::bit_cast(const Source&) [with Dest = long long int; Source = void (*)(const char*, long long int); typename std::enable_if<(! absl::lts_20210324::internal_casts::is_bitcastable<Dest, Source>::value), int>::type <anonymous> = 0]':\r\ntensorflow/compiler/xla/service/llvm_ir/llvm_util.cc:382:76:   required from here\r\nexternal/com_google_absl/absl/base/casts.h:176:30: error: static assertion failed: Source and destination types should have equal sizes.\r\n   static_assert(sizeof(Dest) == sizeof(Source),\r\n                 ~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~\r\nexternal/com_google_absl/absl/base/casts.h: In instantiation of 'Dest absl::lts_20210324::bit_cast(const Source&) [with Dest = long long int; Source = const char*; typename std::enable_if<(! absl::lts_20210324::internal_casts::is_bitcastable<Dest, Source>::value), int>::type <anonymous> = 0]':\r\ntensorflow/compiler/xla/service/llvm_ir/llvm_util.cc:384:55:   required from here\r\nexternal/com_google_absl/absl/base/casts.h:176:30: error: static assertion failed: Source and destination types should have equal sizes.\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 48965.078s, Critical Path: 1635.76s\r\nINFO: 7815 processes: 954 internal, 6861 local.\r\nFAILED: Build did NOT complete successfully\r\n```\r\n\r\n", "comments": ["@pedromtelho ,\r\nCan you please if you are following this [link](https://www.tensorflow.org/lite/guide/build_arm) for the installation of tensorflow?Thanks", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52920\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52920\">No</a>\n"]}, {"number": 52919, "title": "change license to gplv3", "body": null, "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F52919) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "@googlebot I signed it!\r\n\r\n"]}, {"number": 52918, "title": "[INTEL oneDNN] Refactor TF Framework and oneDNN integration", "body": "This PR did the following refactoring:\r\n\r\n1. oneDNN namespace change: from \"mkldnn\" to \"dnnl\", as oneDNN will not support \"mkldnn\" namespace soon (in v2.5).\r\n\r\n2. In ALL comments, replace old product names (MKL, MKL-DNN, or MKL DNN) with the new one \"oneDNN\".\r\n\r\n3. Put TODO items under under a common name \"intel-tf\" as specific developers may leave the project\r\n\r\n4. Remove dangling methods and/or data members  (due to original integration with old MKL DNN product).\r\n\r\n5. Remove unnecessary header file inclusion.\r\n\r\nThis PR has been tested with oneDNN 2.5 (dev version).  It works with oneDNN 2.4 (current integration in TF master branch).", "comments": ["@penpornk Thank you for the review suggestions. I will follow up and take actions!  -GZ", "Committed code changes based on all review suggestions except for using full path \"dnnl.hpp\". ", "@gzmkl Could you please help resolve conflicts? Sorry for the delay!", "@gzmkl  Any update on this PR? Please. Thanks!\r\n", "@gbaned @penpornk  I am sorry for the late response as I was off last week. Somehow, the \"Resolve conflicts\" button is grayed out for this PR. Please help.", "@gbaned merge conflicts have been addressed. Thanks!", "> @gzmkl Any update on this PR? Please. Thanks!\r\n\r\n@gbaned Hi, merge conflicts have been updated and @penpornk approved this PR. Please help to merge if there is no open.\r\nThanks!\r\n", "@penpornk   Hi Penporn, is @gbaned waiting for your review (on addressing merge conflicts) again? \r\n\r\nI am asking because this PR is important because many other oneDNN related PR may have conflicts due to namespace change). \r\n\r\nThanks", "Still getting an import error. Would you mind helping rebase the PR (in case it helps)?", "> Still getting an import error. Would you mind helping rebase the PR (in case it helps)?\r\n\r\nI will try to rebase today and will let you know once it is done\r\n", "> Still getting an import error. Would you mind helping rebase the PR (in case it helps)?\r\n\r\nHi @penpornk PR has been rebased. Thanks.", "@penpornk @gbaned  Many THANKS!"]}, {"number": 52917, "title": "TensorFlow", "body": "<em>Please make sure that this is a bug. As per our\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\nwe only address code/doc bugs, performance issues, feature requests and\nbuild/installation issues on GitHub. tag:bug_template</em>\n\n**System information**\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\n- TensorFlow installed from (source or binary):\n- TensorFlow version (use command below):\n- Python version:\n- Bazel version (if compiling from source):\n- GCC/Compiler version (if compiling from source):\n- CUDA/cuDNN version:\n- GPU model and memory:\n\nYou can collect some of this information using our environment capture\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\nYou can also obtain the TensorFlow version with:\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\n\n**Describe the current behavior**\n\n**Describe the expected behavior**\n\n**[Contributing](https://www.tensorflow.org/community/contribute)**\n\n- Do you want to contribute a PR? (yes/no):\n- Briefly describe your candidate solution(if contributing):\n\n**Standalone code to reproduce the issue**\nProvide a reproducible test case that is the bare minimum necessary to generate\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\n\n**Other info / logs** Include any logs or source code that would be helpful to\ndiagnose the problem. If including tracebacks, please include the full\ntraceback. Large logs and files should be attached.", "comments": ["@tariqMH22 \r\nIn order to expedite the trouble-shooting process here,Could you please fill the issue [template](https://github.com/tensorflow/tensorflow/issues/new/choose),\r\nThanks!", "Template not filled, nothing actionable", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52917\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52917\">No</a>\n"]}, {"number": 52916, "title": "Missing libtensorflow builds for 2.6.1, 2.5.2 and 2.4.4", "body": "There don't appear to be prebuilt binaries for libtensorflow (https://www.tensorflow.org/install/lang_c) for 2.6.1, 2.5.2 and 2.4.4.\r\n\r\nThese binaries exist for earlier point releases for those minor versions on https://storage.googleapis.com/tensorflow/libtensorflow/, but none exist for the above point releases.\r\n\r\nhttps://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow-cpu-linux-x86_64-2.6.1.tar.gz is one of the missing files.\r\n\r\nSee #48550 for a similar occurrence.\r\n\r\nWould it be possible to push those binaries/trigger CI builds to generate them?\r\n\r\nThanks!", "comments": ["Unfortunately automation for these releases has been broken and we had to do it manually. Will release these artifacts and publish them soon. Apologies for the delay", "I think all should be uploaded now. Please let us know if something is missing.\r\n\r\nThank you!", "I've confirmed the availability of linux x86_64, presumably you've got the rest. My teams and I appreciate the quick turnaround time on this!\r\n\r\nI'd say you can close the ticket now.", "Closing this,, since the issue was resolved. Thanks.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52916\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52916\">No</a>\n"]}, {"number": 52915, "title": "Installing tensorflow in python", "body": "<em>hi, i'm trying to install tensorflow for python but i get two errors installing it, and i google but every solution dosn't work</em>\r\n\r\n### **CODE**\r\n`pip3 install tensorflow`\r\n\r\noutput: \r\n```\r\nERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none)\r\nERROR: No matching distribution found for tensorflow\r\n```\r\n\r\n### **2\u00b0 TRIAL**\r\n`pip install --upgrade https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-1.2.0-py2-none-any.whl`\r\n\r\noutput\r\n```\r\nDefaulting to user installation because normal site-packages is not writeable\r\nERROR: tensorflow-1.2.0-py2-none-any.whl is not a supported wheel on this platform.\r\n\r\n```\r\n\r\n\r\n**_IT DOESN'T WORK_**\r\nwhat shall i do??\r\n\r\n", "comments": ["just wanted to say that on the other computer it works, but on this one not\r\n\r\n_can i transfer it somehow_ ?", "Hi @LordFenny !\r\nCould you please fill the [template](https://github.com/tensorflow/tensorflow/issues/new/choose)  as it helps us analyse the issue. You can also refer these threads for installing Tensorflow in macos . [link1](https://developer.apple.com/forums/thread/683757)[,link2](https://medium.com/riow/install-tensorflow-on-mac-a42526b96e72),[link3](https://www.pyimagesearch.com/2019/12/09/how-to-install-tensorflow-2-0-on-macos/).Thanks!", "Could you please open this issue in https://developer.apple.com/forums/. Thanks", "Please fill in issue template.\r\n\r\nPlease make sure you are running on a 64 bit computer, have the newest pip package.\r\n\r\nPlease make sure your Python version is 3.7, 3.8 or 3.9. TF is not yet ready for Python 3.10 and versions below 3.7 are deprecated.\r\n\r\nPlease make sure you are installing TF 2.4 or later. Older versions are no longer supported", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52915\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52915\">No</a>\n"]}, {"number": 52912, "title": "[feature request & discuss] observe tensor execution efficiency by eBPF tracepoints.", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using):\r\n- Are you willing to contribute it (Yes/No):\r\n\r\nNONE\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nHave you guys ever think about expose tensor processing efficiency in large scale distributed training leveraging eBPF? The traced metrics can be consumed by other components, e.g. resource scheduler and infers the execution quality of each worker and find straggler worker (one of thousands scenarios, just a casual thinking)\r\n\r\n**Will this change the current api? How?**\r\n\r\n**Who will benefit with this feature?**\r\n\r\n**Any Other info.**\r\n", "comments": ["@SimonCqk ,\r\nCan you please elaborate about your Feature. Also, please specify the Use Cases for this feature. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 52911, "title": "Restore missing comma to fix build", "body": "Fixes https://github.com/tensorflow/tensorflow/issues/52910", "comments": ["@sanjoy @pkanwar23 Can you please review and merge this PR.\r\nIt's currently impossible to build TensorFlow because of this bug.\r\n\r\n@elfringham thanks for the PR \r\n ", "@elfringham Can you please resolve conflicts? Thanks!", "Made moot by https://github.com/tensorflow/tensorflow/commit/ad8a18eaab4bf0b6e18272c9e54d8818e5875ac0"]}, {"number": 52910, "title": "Build broken by incorrectly dropped comma", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux RHEL 8.4\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: git HEAD\r\n- Python version: 3.6.8\r\n- Installed using virtualenv? pip? conda?: n/a\r\n- Bazel version (if compiling from source): 3.7.2\r\n- GCC/Compiler version (if compiling from source): 10.3.0\r\n- CUDA/cuDNN version: n/a\r\n- GPU model and memory: n/a\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nBuild breaks with -\r\nerror in tensorflow_aarch64 setup command: 'install_requires' must be a string or list of strings containing valid project/version requirement specifiers; Parse error at \"'< 2.8'\": Expected stringEnd\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nbazel build --config=nonccl //tensorflow/tools/pip_package:build_pip_package --verbose_failures\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nSee https://ci.linaro.org/job/ldcg-python-manylinux-tensorflow-nightly/156/console\r\n\r\nProblem commit is https://github.com/tensorflow/tensorflow/commit/3e842b053711f2d81cd775037875a8d744d79ed5\r\n", "comments": ["Hi @elfringham! Thanks for the PR .This issue will be closed once PR[ #52911](https://github.com/tensorflow/tensorflow/pull/52911) is merged.", "Thanks, this indeed fix the issue", "The pending PR was ignored and the fix applied directly by @tensorflower-gardener  https://github.com/tensorflow/tensorflow/commit/ad8a18eaab4bf0b6e18272c9e54d8818e5875ac0", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52910\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52910\">No</a>\n"]}, {"number": 52909, "title": "Re-enable building as a standalone submodule", "body": "The pattern used to detect if to build via the LLVM external project\r\nmechanism prevented to build MLIR-HLO as a standalone project when added\r\nas a submodule.", "comments": ["FYI, @silvasean.", "Thanks! LGTM"]}]