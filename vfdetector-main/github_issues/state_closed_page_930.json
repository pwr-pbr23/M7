[{"number": 25548, "title": "Tensorflow AOT compilation error: No registered 'DecodeJpeg' OpKernel for XLA_CPU_JIT ", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 1.12.0 (tensorflow-gpu, tensorflow-base)\r\n- Python version: 3.6.8\r\n- Bazel version (if compiling from source): 0.21.0\r\n- GCC/Compiler version (if compiling from source): 5.4.0 20160609\r\n- CUDA/cuDNN version: 7.1.2\r\n- GPU model and memory: GeForce GTX 1080, 8GB\r\n\r\n**Describe the current behavior**\r\nI am trying to compile a pretrained InceptionV4 model from TF models repository. The last layer is modified to produce our custom set of classes (we're doing transfer learning). I successfully produced both graph.pb and graph.pb.txt files. When I tried to compile the graph, I received an error (see logs below).\r\n\r\n* I have managed to successfully compile and run Keras ResNet50 and MobileNetV2 models before.\r\n* I disabled XLA & CUDA when compiling TF from source.\r\n\r\n**Other info / logs**\r\n```\r\nINVALID ARGUMENTS: Detected unsupported operations when trying to compile graph tfcompile on XLA_CPU_JIT: DecodeJpeg (No registered 'DecodeJpeg' OpKernel for XLA_CPU_JIT devices compatible with node {{node DecodeJpeg}}\r\n\t.  Registered:  <no registered kernels>\r\n){{node DecodeJpeg}}\r\n\r\n```", "comments": ["@Kwander I have couple of questions. \r\n1) You mentioned that you are able to successfully compiled for two models before. Did you disable XLA and CUDA while you compiled them? \r\n2) What is the reason behind the disabling XLA & CUDA? Want to understand context. Thanks! ", "@jvishnuvardhan Hey!\r\n\r\n1. Yes, I have.\r\n2. I thought this might help, as I later discovered that GPU compiling was not supported by TF AOT then.", "@Kwander Iam not sure what will be the root cause of the issue. Could you share a code to reproduce the issue? I just want to make sure that there is nothing wrong from the coding side. Thanks!", "I believe this is working as intended.\r\n\r\nIf you want to use tfcompile to do AOT compilation on CPU, all of the ops in the compiled graph must be supported on XLA:CPU.\r\n\r\nXLA:CPU does not support JPEG decoding.", "> I disabled XLA & CUDA when compiling TF from source.\r\n\r\nNote that tfcompile AOT *requires XLA*.  So if you disable XLA in the build and try to use tfcompile...I'm not sure what's supposed to happen.  :)", "Eagerly closing this, but please reopen if you have other questions / need more assistance."]}, {"number": 25547, "title": "Update bits.h", "body": "__buitin_clzll  >> __builtin_clzll", "comments": []}, {"number": 25546, "title": "local_conv1d and local_conv2d are missing from the tensorflow.keras.backend namespace.", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 1.13\r\n- Are you willing to contribute it (Yes/No): No\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nKeras-team/keras provides `local_conv1d` and `local_conv2d` in `keras.backend`. tf.keras doesn't expose them. It's a compatibility issue between keras and tensorflow.keras. See https://keras.io/backend/ .\r\n\r\n**Will this change the current api? How?**\r\n\r\nIt will add two functions to `tensorflow.keras.backend`\r\n\r\n**Who will benefit with this feature?**\r\n\r\nIn keras-contrib, we expect keras and tf.keras to have the same public API. If the two are not compatibles, there are things that we can't do. \r\n\r\n**Any Other info.**\r\n", "comments": ["@gabrieldemarmiesse Added a PR #25556 to export `local_conv1d` and `local_conv2d` in `tf.keras.backend`."]}, {"number": 25545, "title": "Update ring.h", "body": "accumululated -> accumulated", "comments": []}, {"number": 25544, "title": "typo Update depthwise_conv.h & conv.h", "body": "accumation -> accumulation", "comments": []}, {"number": 25543, "title": " tf.train.ExponentialMovingAverage scope issue", "body": "I copied the tower_loss method from https://github.com/tensorflow/tensorflow/blob/r0.7/tensorflow/models/image/cifar10/cifar10_multi_gpu_train.py and I have a problem with the scope of the `loss_averages` variable. What is wrong and how can I fix it??\r\n```\r\n    def tower_loss(scope, img_batch, label_batch):\r\n        # Calculate the total loss on a single tower running the model.\r\n        # scope: unique prefix string identifying the tower, e.g. 'tower_0'\r\n        # returns total loss for a batch of data\r\n    \r\n        # Build inference Graph.\r\n        logits = inference(img_batch)\r\n    \r\n        # Build the portion of the Graph calculating the losses. Note that we will\r\n        # assemble the total_loss using a custom function below.\r\n        _ = model_loss(logits, label_batch)\r\n    \r\n        # Assemble all of the losses for the current tower only.\r\n        losses = tf.get_collection('losses', scope)\r\n    \r\n        # Calculate the total loss for the current tower.\r\n        total_loss = tf.add_n(losses, name='total_loss')\r\n     \r\n        loss_averages = tf.train.ExponentialMovingAverage(0.9, name='avg')\r\n    \r\n        print(\"current scope:\", scope)# tower_name_1/\r\n        print(\"loss_averages:\", loss_averages.name) # avg\r\n        print(\"total_loss:\", total_loss.name) # tower_name_1/total_loss_1:0\r\n        print()\r\n        # need scope:  tower_name_1/mean_sq_error/avg/\r\n        loss_averages_op = loss_averages.apply(losses + [total_loss])\r\n    \r\n        \r\n        with tf.control_dependencies([loss_averages_op]):\r\n            total_loss = tf.identity(total_loss)\r\n            \r\n        return total_loss\r\n```\r\n\r\n\r\n\r\nTrace:\r\n```\r\n    total_loss: tower_name_0/total_loss_1:0\r\n    curr scope: tower_name_0/\r\n    loss_averages: avg\r\n    \r\n    Tensor(\"tower_name_1/IteratorGetNext:0\", shape=(?, 227, 227, 3), dtype=float32, device=/device:GPU:1)\r\n    Tensor(\"tower_name_1/IteratorGetNext:1\", shape=(?,), dtype=float32, device=/device:GPU:1)\r\n    total_loss: tower_name_1/total_loss_1:0\r\n    curr scope: tower_name_1/\r\n    loss_averages: avg\r\n    \r\n    Traceback (most recent call last):\r\n      File \"new_FCN-LSTM.py\", line 363, in <module>\r\n        train()\r\n      File \"new_FCN-LSTM.py\", line 259, in train\r\n        loss = tower_loss(scope, img_batch, label_batch)\r\n      File \"new_FCN-LSTM.py\", line 165, in tower_loss\r\n        loss_averages_op = loss_averages.apply(losses + [total_loss])\r\n      File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\training\\moving_averages.py\", line 415, in apply\r\n        \"VarHandleOp\"]))\r\n      File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\training\\slot_creator.py\", line 183, in create_zeros_slot\r\n        colocate_with_primary=colocate_with_primary)\r\n      File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\training\\slot_creator.py\", line 160, in create_slot_with_initializer\r\n        dtype)\r\n      File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\training\\slot_creator.py\", line 65, in _create_slot_var\r\n        validate_shape=validate_shape)\r\n      File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 1487, in get_variable\r\n        aggregation=aggregation)\r\n      File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 1237, in get_variable\r\n        aggregation=aggregation)\r\n      File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 540, in get_variable\r\n        aggregation=aggregation)\r\n      File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 492, in _true_getter\r\n        aggregation=aggregation)\r\n      File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 879, in _get_single_variable\r\n        \"reuse=tf.AUTO_REUSE in VarScope?\" % name)\r\n    ValueError: Variable tower_name_1/mean_sq_error/avg/ does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=tf.AUTO_REUSE in VarScope?\r\n```", "comments": ["Please post this kind of support questions at [Stackoverflow](https://stackoverflow.com/questions/tagged/tensorflow). There is a big community to support and learn from your questions. Github is mainly for addressing bugs in installation and performance. Thanks!", "Closing this support issue. Please post this kind of support questions at [Stackoverflow](https://stackoverflow.com/questions/tagged/tensorflow). Thanks!"]}, {"number": 25542, "title": "Issues when training with keras.callbacks.tensorboard", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:Np\r\n- TensorFlow installed from (source or binary):Through anaconda\r\n- TensorFlow version (use command below):latest\r\n- Python version:3.6\r\n- Bazel version (if compiling from source):No\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:No\r\n- GPU model and memory:Nvidia 920m\r\n\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n**Code-Begins**\r\nfrom nltk.tokenize import word_tokenize\r\nfrom tensorflow import keras\r\nimport tensorflow as tf\r\nimport pandas as pd\r\nimport re\r\nall_words = []\r\n#importing the data\r\ndataset = pd.read_csv('Restaurant_Reviews.tsv', delimiter = '\\t', quoting = 3)\r\n\r\n#converting words present in each review to arrays\r\nfor i in range(0, 1000):\r\n    review = re.sub('[^a-zA-Z]', ' ', dataset['Review'][i])\r\n    review = review.lower()\r\n    review = review.split()\r\n    review = ' '.join(review)\r\n    all_words.append(word_tokenize(review))\r\n\r\n#reading each word from all the reviews\r\nwords = []\r\nfor i in range(len(all_words)):\r\n    for word in all_words[i]:\r\n        words.append(word)\r\n\r\n#removing repeated words\r\nclean_words = []\r\nfor word in words:\r\n    if word not in clean_words:\r\n        clean_words.append(word)\r\n\r\n#assigning a number to each word and creating sequence of words\r\ncount = []\r\nfor i in range(0,len(clean_words)):\r\n    count.append(i)\r\nsequence_of_words = dict(zip(clean_words,count))\r\n\r\nwith open('metadata.tsv', 'w') as metadata_file:\r\n            metadata_file.write('ID\\tWord\\n')\r\n            for Key, Value in sequence_of_words.items():\r\n                metadata_file.write('{}\\t{}\\n'.format(Value, Key)) \r\n\r\n#saving the sequence of words\r\nimport pickle \r\nwith open('sequenceofwords' , 'wb') as fid:\r\n    pickle.dump(sequence_of_words , fid)\r\n#reading the labels into an array\r\nlabels =[]\r\nfor i in range(0,1000):\r\n    labels.append(dataset.Liked[i])\r\n\r\n#converting each review to sequence of words\r\nreverse_mapping=[]\r\nfor i in range(0, 1000):\r\n    lop = []\r\n    review = re.sub('[^a-zA-Z]', ' ', dataset['Review'][i])\r\n    review = review.lower()\r\n    for text in review.split():\r\n        if text not in sequence_of_words.keys():\r\n            lop.append('0')\r\n        if text in sequence_of_words.keys():\r\n            lop.append(sequence_of_words[text])\r\n    reverse_mapping.append(lop)   \r\n\r\n#deviding the data for training and testing\r\ntrainer_data = list(reverse_mapping[:700])\r\ntrain_labels = [labels[:700]]\r\ntester_data = list(reverse_mapping[700:])\r\ntest_labels = [labels[700:]]\r\n\r\ntrain_data = keras.preprocessing.sequence.pad_sequences(trainer_data,\r\n                                                        value=0,\r\n                                                        padding='post',\r\n                                                        maxlen=256)\r\ntest_data = keras.preprocessing.sequence.pad_sequences(tester_data, value = 0 , padding = 'post' , maxlen = 256)\r\n\r\n#creating the neural network\r\nvocab_size = 2021\r\nmodel = keras.Sequential()\r\nmodel.add(keras.layers.Embedding(vocab_size, 16, input_length = 256))\r\nmodel.add(keras.layers.GlobalAveragePooling1D())\r\nmodel.add(keras.layers.Dense(16, activation=tf.nn.relu))\r\nmodel.add(keras.layers.Dense(1, activation=tf.nn.sigmoid))\r\n\r\n#configuring the model\r\nmodel.compile(optimizer='adam',\r\n              loss='binary_crossentropy',\r\n              metrics=['accuracy'])\r\n#creating a meta file for tensorboard.\r\nmeta_file = open(r'E:\\ENTERTAINMENT\\OneDrive\\Desktop\\NLTK - Workspace\\NLP\\Natural_Language_Processing\\review classifier\\Tensorflow classifier\\ML-\\Training\\metadata.tsv')\r\ncb = keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=5, batch_size=256, write_graph=True, write_grads=True, write_images=False, embeddings_freq=5, embeddings_layer_names=None, embeddings_metadata=None, embeddings_data=train_data)\r\n\r\n#training the model\r\nmodel.fit(train_data, train_labels ,epochs = 40, batch_size=6,validation_data=(test_data,test_labels) ,verbose= 1,callbacks = [cb])\r\n\r\nmodel.summary()\r\n\r\nresults = model.evaluate(test_data, test_labels)\r\n\r\nprint(results)\r\n\r\n#saving the model\r\nkeras_file = \"training.h5\"\r\nkeras.models.save_model(model, keras_file)\r\n\r\n**Code-Ends**\r\n\r\n**Describe the expected behavior**\r\nCreate log files to run tensorboard. But gives error.\r\n\r\n**Error-Begins**\r\n\r\nInvalidArgumentError: Tensor embedding_6_input:0, specified in either feed_devices or fetch_devices was not found in the Graph\r\n\r\n**Error-Ends**\r\n\r\n\r\n", "comments": ["I have had the same problem and I have solved it setting `write_graph=False` inside the callback creation, i.e.:\r\n`cb = keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=5, batch_size=256, write_graph=False, write_grads=True, write_images=False, embeddings_freq=5, embeddings_layer_names=None, embeddings_metadata=None, embeddings_data=train_data)`. \r\nThis should be because the different use of graphs in eager_mode (used by TF2). \r\n\r\nAnyway, I'm interested in this behavior because now I don't have the problem anymore. Maybe I missed something in a recent update?\r\nI would anyway ask to know how Keras works inside TF2, in particular how it manages the graphs.\r\n\r\nThank you.", "@chandanchinta Please try solution provided by @iLeW, if the solution works then close this issue and open another issue for TF2.0. Thanks!", "Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 25541, "title": "install tensoflow in python 3.6 but after that my code given an error no module name tensorflow", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version:\r\n- Python version:\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["What command did you use to install? ", "Please provide all the information asked by the template above. Thanks!", "pip install tensorflow\nthis command work for me.\n\nOn Wed, Feb 6, 2019 at 9:18 PM Vidur Satija <notifications@github.com>\nwrote:\n\n> What command did you use to install?\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/25541#issuecomment-461071279>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/Are1Qisq-PmU1IzpjNdHmOHtge6NBJe1ks5vKvllgaJpZM4ak7Fy>\n> .\n>\n", "That's right. I will close this issue since its resolved. Feel free to reopen if have any additional questions. Thanks!"]}, {"number": 25540, "title": "tensorflow.python.framework.errors_impl.AlreadyExistsError while importing freezed graph", "body": "- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): YES\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):Binary\r\n- TensorFlow version (use command below):1.12.0\r\n- Python version:3.5.2\r\n\r\n**Describe the current behavior**\r\nThe functions used to freeze graph, I don't receive any error while freezing the graph        \r\n```\r\ntmp_g = tf.graph_util.convert_variables_to_constants(\r\n          sess, tmp_g, [n.name[:-2] for n in output_tensors]\r\n)\r\n```   \r\n```\r\nwith tf.gfile.GFile(\"inference_graph\", \"wb\") as f:\r\n    f.write(tmp_g.SerializeToString())\r\n```       \r\nThe functions used to load graph        \r\n``` \r\nwith tf.gfile.GFile(\"inference_graph\", \"rb\") as f:\r\n            graph_def = tf.GraphDef()\r\n            graph_def.ParseFromString(f.read())```\r\nstart_logits, end_logits = tf.import_graph_def(                                                                                        \r\n                graph_def,\r\n                input_map={k: features[k[:-2]] for k in input_names},\r\n                return_elements=[\"unstack:0\", \"unstack:1\"],\r\n            )\r\n```    \r\nThe error,        \r\n```\r\nINFO:tensorflow:Calling model_fn.\r\nINFO:tensorflow:Done calling model_fn.\r\nINFO:tensorflow:Graph was finalized.\r\n2019-02-06 15:26:25.816370: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not c$\r\nmpiled to use: AVX512F\r\nINFO:tensorflow:Running local_init_op.\r\nINFO:tensorflow:Done running local_init_op.\r\n2019-02-06 15:26:40.501236: W tensorflow/core/framework/op_kernel.cc:1273] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_\r\nstep_6/import/magic/while/embeddings/ArithmeticOptimizer/AddOpsRewrite_add_1/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE\r\nTraceback (most recent call last):\r\n  File \"/home/dj/.local/share/virtualenvs/bert-squeeze-test12-a8EWmLrd/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1334, in\r\n _do_call\r\n    return fn(*args)\r\n  File \"/home/dj/.local/share/virtualenvs/bert-squeeze-test12-a8EWmLrd/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1319, in\r\n _run_fn\r\n    options, feed_dict, fetch_list, target_list, run_metadata)\r\n  File \"/home/dj/.local/share/virtualenvs/bert-squeeze-test12-a8EWmLrd/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1407, in\r\n _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.AlreadyExistsError: Resource __per_step_6/import/magic/while/embeddings/ArithmeticOptimizer/AddOpsRewrite_add_\r\n1/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE\r\n         [[{{node import/magic/while/embeddings/ArithmeticOptimizer/AddOpsRewrite_add_1/tmp_var}} = TemporaryVariable[dtype=DT_FLOAT, shape=[1,384,768\r\n], var_name=\"import/magic/while/embeddings/ArithmeticOptimizer/AddOpsRewrite_add_1/tmp_var\", _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](^\r\nimport/magic/while/embeddings/Reshape_3)]]\r\n\r\ntensorflow.python.framework.errors_impl.AlreadyExistsError: Resource __per_step_6/import/magic/while/embeddings/ArithmeticOptimizer/AddOpsRewrite_add$\r\n1/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE\r\n         [[{{node import/magic/while/embeddings/ArithmeticOptimizer/AddOpsRewrite_add_1/tmp_var}} = TemporaryVariable[dtype=DT_FLOAT, shape=[1,384,76$\r\n], var_name=\"import/magic/while/embeddings/ArithmeticOptimizer/AddOpsRewrite_add_1/tmp_var\", _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](^\r\nimport/magic/while/embeddings/Reshape_3)]]\r\n```", "comments": ["@dchatterjee172  Could you try TF2.0 and let us know whether the bug persists? Thanks!\r\n ", "I assume that you found a solution for the issue. Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will open a new issue. Thanks!", "I have this same issue in tf 2.0 beta0 when training with Keras. This is my error:\r\n```\r\n2019-06-14 15:50:47.135616: W tensorflow/core/framework/op_kernel.cc:1546] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_0/training/gradients/lstm/while_grad/lstm/while_grad/body/_437/gradients/AddN_8/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE\r\n2019-06-14 15:50:47.135640: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Already exists: Resource __per_step_0/training/gradients/lstm/while_grad/lstm/while_grad/body/_437/gradients/AddN_8/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE\r\n\t [[{{node training/gradients/lstm/while_grad/lstm/while_grad/body/_437/gradients/AddN_8/tmp_var}}]]\r\n2019-06-14 15:50:47.136076: W tensorflow/core/framework/op_kernel.cc:1546] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_0/training/gradients/lstm/while_grad/lstm/while_grad/body/_437/gradients/AddN_8/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE\r\nTraceback (most recent call last):\r\n  File \"/anaconda3/envs/py36tf2/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3291, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-3-d5d4b32b3ef3>\", line 2, in <module>\r\n    model.fit(dd, np.zeros(len(data)), batch_size=150, verbose=1)\r\n  File \"/anaconda3/envs/py36tf2/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 643, in fit\r\n    use_multiprocessing=use_multiprocessing)\r\n  File \"/anaconda3/envs/py36tf2/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\", line 664, in fit\r\n    steps_name='steps_per_epoch')\r\n  File \"/anaconda3/envs/py36tf2/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\", line 383, in model_iteration\r\n    batch_outs = f(ins_batch)\r\n  File \"/anaconda3/envs/py36tf2/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\", line 3510, in __call__\r\n    outputs = self._graph_fn(*converted_inputs)\r\n  File \"/anaconda3/envs/py36tf2/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 572, in __call__\r\n    return self._call_flat(args)\r\n  File \"/anaconda3/envs/py36tf2/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 671, in _call_flat\r\n    outputs = self._inference_function.call(ctx, args)\r\n  File \"/anaconda3/envs/py36tf2/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 445, in call\r\n    ctx=ctx)\r\n  File \"/anaconda3/envs/py36tf2/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\", line 67, in quick_execute\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.AlreadyExistsError:  Resource __per_step_0/training/gradients/lstm/while_grad/lstm/while_grad/body/_437/gradients/AddN_8/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE\r\n\t [[{{node training/gradients/lstm/while_grad/lstm/while_grad/body/_437/gradients/AddN_8/tmp_var}}]] [Op:__inference_keras_scratch_graph_3658]\r\nFunction call stack:\r\nkeras_scratch_graph\r\n```\r\n\r\nI can't reproduce with small example though.\r\nLooks similar to this issue https://github.com/tensorflow/tensorflow/issues/23780\r\n", "@pekaalto Please open a new issue by filling template and providing a standalone code to reproduce the issue. Thanks!", "Hi @jvishnuvardhan unfortunately I haven't been able to reproduce with small example and I can't publish my full data/model. However, my issue seems to be the same as in the open issue linked above, except I'm using TF 2.0.  \r\n\r\nSo maybe in this case opening a new issue is not necessary, right?  Thanks.", "@pekaalto I have requested you to open a new issue considering \"users\" who can get benefited from your issue. But I will open the issue. Could you share a standalone code to reproduce your issue? Thanks!", "Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=25540\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=25540\">No</a>\n"]}, {"number": 25539, "title": "Tensorflow AOT compiled graph does not use GPU", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 1.12.0 (tensorflow-gpu, tensorflow-base)\r\n- Python version: 3.6.8\r\n- Bazel version (if compiling from source): 0.21.0\r\n- GCC/Compiler version (if compiling from source): 5.4.0 20160609\r\n- CUDA/cuDNN version: 7.1.2\r\n- GPU model and memory: GeForce GTX 1080, 8GB\r\n\r\n**Describe the current behavior**\r\nFollowing the https://gist.github.com/carlthome/6ae8a570e21069c60708017e3f96c9fd tutorial, which is based on https://www.tensorflow.org/xla/tfcompile, all the compilation steps succeed. I am also able to invoke the compiled graph, producing correct prediction results. A non-compiled predict of a single image using RestNet50 takes 5ms, a compiled version takes ~140ms.\r\n\r\nNote: I have ran ./configure via a terminal to use force CUDA support (such option is not accepted in the example).\r\n\r\n**Describe the expected behavior**\r\nThe compiled version prediction of a single image should be as fast as a non-compiled prediction. I suspect the compiled graph uses CPU for the inference.\r\n\r\n**Code to reproduce the issue**\r\nFollow the https://gist.github.com/carlthome/6ae8a570e21069c60708017e3f96c9fd tutorial. To evaluate the compiled and the non-compiled graph prediction of a single image duration, add these two lines to the end of the notebook:\r\n\r\n`%timeit -n 20 predict(x)`\r\n`%timeit -n 20 model.predict(x)`\r\n", "comments": ["@Kwander Is this related to [this](https://github.com/tensorflow/tensorflow/issues/25548). If it is duplicate, please close this. If it is not duplicate, did you enable/disable XLA here. Thanks!", "> Tensorflow AOT compiled graph does not use GPU\r\n\r\nThis behavior is WAI.  AOT compilation only uses the CPU.  If you want to use the GPU, you can't use AOT compilation.", "I think it was resolved. I am closing this issue. Thanks!", "> > Tensorflow AOT compiled graph does not use GPU\r\n> \r\n> This behavior is WAI. AOT compilation only uses the CPU. If you want to use the GPU, you can't use AOT compilation.\r\n\r\nSorry to bother. I just did something similar to this issue. Since I can't find what WAI is, could you please tell me what it is?\r\nBesides, do you know is there another way to use pure GPU acceleration for compiled DL model since AOT won't use GPU and JIT requires compiling every time the model runs. Just Thank you!", "WAI = working as intended.\n\nThere is no way today to use XLA:GPU without recompiling every time.  It's\nnot something on our roadmap.\n\nOn Sat, Apr 27, 2019 at 8:52 PM mati1994 <notifications@github.com> wrote:\n\n> Tensorflow AOT compiled graph does not use GPU\n>\n> This behavior is WAI. AOT compilation only uses the CPU. If you want to\n> use the GPU, you can't use AOT compilation.\n>\n> Sorry to bother. I just did something similar to this issue. Since I can't\n> find what WAI is, could you please tell me what it is?\n> Besides, do you know is there another way to use pure GPU acceleration for\n> compiled DL model since AOT won't use GPU and JIT requires compiling every\n> time the model runs. Just Thank you!\n>\n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/25539#issuecomment-487340068>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AABEZBYJT3PGMSW5XAR6AWDPSUNRNANCNFSM4GUTF6UQ>\n> .\n>\n", "@jlebar Just wonder is there any progress to improve the every recompiling?", "Hi, happy holidays.\n\nI left the project a few months ago, you'll want to check with sanjoy@.\n\nOn Thu, Dec 26, 2019, 1:57 AM Colin <notifications@github.com> wrote:\n\n> @jlebar <https://github.com/jlebar> Just wonder is there any progress to\n> improve the every recompiling?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/25539?email_source=notifications&email_token=AABEZB6O2JMUBY7AOZOWLR3Q2RIWJA5CNFSM4GUTF6U2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEHVB55Q#issuecomment-568991478>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AABEZB5OI25TJICZTMCTENLQ2RIWJANCNFSM4GUTF6UQ>\n> .\n>\n"]}, {"number": 25538, "title": "Fix misleading comment in layer normalization", "body": "Comment states that moments are calculated across the last dimension, however this is not true for convolutional layers, where the moments are calculated on all dimensions except the one with index 0.\r\n\r\nI changed the comment from \"Calculate the moments on the last axis (layer activations).\" to \"By default, compute the moments across all the dimensions except the one with index 0.\"", "comments": ["Why did the tests fail? This PR did not modify any code."]}, {"number": 25537, "title": "TFLite model performance on Android is worse than the one on TFLite Model Benchmark Tool", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.14.2\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (or github SHA if from source): 1.13.0.dev20190126\r\n- Android Studio version: 3.3\r\n- TensorFlow Lite version on Android: 0.0.0-gpu-experimental\r\n\r\n**Descrive the current behavior**\r\nI tried running my custom classify model on Android Studio. This model works well, but the performance is bad. It takes about **300 msec** to classify a 224 x 224 image on Simulator. I measured the run time of `Interpreter.run()` method.   \r\nWhen I benchmark this model with TFLite Model Benchmark Tool, it takes about **34 msec** on desktop.  \r\nWhat is the difference between these performances?\r\n\r\n**The output of TFLite Model Benchmark Tool**\r\n\r\n```\r\nSTARTING!\r\nMin num runs: [50]\r\nMin runs duration (seconds): [1]\r\nInter-run delay (seconds): [-1]\r\nNum threads: [1]\r\nBenchmark name: []\r\nOutput prefix: []\r\nMin warmup runs: [1]\r\nMin warmup runs duration (seconds): [0.5]\r\nGraph: [../tensorflow_lite/classify.tflite]\r\nInput layers: []\r\nInput shapes: []\r\nUse nnapi : [0]\r\nLoaded model ../tensorflow_lite/classify.tflite\r\nresolved reporter\r\nInitialized session in 5.725ms\r\nRunning benchmark for at least 1 iterations and at least 0.5 seconds\r\ncount=11 first=53892 curr=34948 min=34948 max=55623 avg=45455.3 std=6945\r\n\r\nRunning benchmark for at least 50 iterations and at least 1 seconds\r\ncount=50 first=34139 curr=33605 min=32515 max=44607 avg=33959.3 std=1682\r\n\r\n============================== Run Order ==============================\r\n\t             [node type]\t          [start]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\r\n\t                 CONV_2D\t            0.000\t    3.337\t    3.394\t  9.996%\t  9.996%\t     0.000\t        1\t[conv2d_1/BiasAdd]\r\n\t                   PRELU\t            3.395\t    0.849\t    0.796\t  2.344%\t 12.340%\t     0.000\t        1\t[p_re_lu_1/add]\r\n\t                 CONV_2D\t            4.191\t    9.352\t    9.059\t 26.678%\t 39.019%\t     0.000\t        1\t[conv2d_2/BiasAdd]\r\n\t                   PRELU\t           13.250\t    0.795\t    0.798\t  2.350%\t 41.369%\t     0.000\t        1\t[p_re_lu_2/add]\r\n\t                 CONV_2D\t           14.048\t    9.383\t    9.081\t 26.741%\t 68.110%\t     0.000\t        1\t[conv2d_3/BiasAdd]\r\n\t                   PRELU\t           23.129\t    0.754\t    0.797\t  2.347%\t 70.458%\t     0.000\t        1\t[p_re_lu_3/add]\r\n\t                 CONV_2D\t           23.926\t    8.803\t    9.133\t 26.895%\t 97.353%\t     0.000\t        1\t[conv2d_4/BiasAdd]\r\n\t         AVERAGE_POOL_2D\t           33.060\t    0.863\t    0.898\t  2.644%\t 99.997%\t     0.000\t        1\t[average_pooling2d_1/AvgPool]\r\n\t         FULLY_CONNECTED\t           33.958\t    0.001\t    0.001\t  0.003%\t100.000%\t     0.000\t        1\t[dense_1/BiasAdd]\r\n\r\n============================== Top by Computation Time ==============================\r\n\t             [node type]\t          [start]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[times called]\t[Name]\r\n\t                 CONV_2D\t           23.926\t    8.803\t    9.133\t 26.895%\t 26.895%\t     0.000\t        1\t[conv2d_4/BiasAdd]\r\n\t                 CONV_2D\t           14.048\t    9.383\t    9.081\t 26.741%\t 53.637%\t     0.000\t        1\t[conv2d_3/BiasAdd]\r\n\t                 CONV_2D\t            4.191\t    9.352\t    9.059\t 26.678%\t 80.315%\t     0.000\t        1\t[conv2d_2/BiasAdd]\r\n\t                 CONV_2D\t            0.000\t    3.337\t    3.394\t  9.996%\t 90.311%\t     0.000\t        1\t[conv2d_1/BiasAdd]\r\n\t         AVERAGE_POOL_2D\t           33.060\t    0.863\t    0.898\t  2.644%\t 92.955%\t     0.000\t        1\t[average_pooling2d_1/AvgPool]\r\n\t                   PRELU\t           13.250\t    0.795\t    0.798\t  2.350%\t 95.305%\t     0.000\t        1\t[p_re_lu_2/add]\r\n\t                   PRELU\t           23.129\t    0.754\t    0.797\t  2.347%\t 97.653%\t     0.000\t        1\t[p_re_lu_3/add]\r\n\t                   PRELU\t            3.395\t    0.849\t    0.796\t  2.344%\t 99.997%\t     0.000\t        1\t[p_re_lu_1/add]\r\n\t         FULLY_CONNECTED\t           33.958\t    0.001\t    0.001\t  0.003%\t100.000%\t     0.000\t        1\t[dense_1/BiasAdd]\r\n\r\nNumber of nodes executed: 9\r\n============================== Summary by node type ==============================\r\n\t             [Node type]\t  [count]\t  [avg ms]\t    [avg %]\t    [cdf %]\t  [mem KB]\t[times called]\r\n\t                 CONV_2D\t        4\t    30.665\t    90.316%\t    90.316%\t     0.000\t        4\r\n\t                   PRELU\t        3\t     2.390\t     7.039%\t    97.355%\t     0.000\t        3\r\n\t         AVERAGE_POOL_2D\t        1\t     0.897\t     2.642%\t    99.997%\t     0.000\t        1\r\n\t         FULLY_CONNECTED\t        1\t     0.001\t     0.003%\t   100.000%\t     0.000\t        1\r\n\r\nTimings (microseconds): count=50 first=34137 curr=33603 min=32513 max=44604 avg=33957.1 std=1682\r\nMemory (bytes): count=0\r\n9 nodes observed\r\n\r\n\r\nAverage inference timings in us: Warmup: 45455.3, Init: 5725, no stats: 33959.3\r\n```\r\n\r\n**Model file**\r\n[classify.tflite.zip](https://github.com/tensorflow/tensorflow/files/2835017/classify.tflite.zip)\r\n", "comments": ["Additional info.  \r\nI tried runnnig my custom model on Galaxy S8. It takes about **150 msec** to run inference.  \r\nIt is faster than on Simulator, but slower than on Benchmark Tool.  \r\n\r\nI expect that my custom model should run much faster than [mobilenet on official tutorial](https://www.tensorflow.org/lite/performance/benchmarks) because it is very light model compared to mobilenet.", "@ksekine : Are you are running the tool on your Mac? You can run TFLite benchmark tool on Android, just compile for Android arm64. You should see comparable numbers on Android.\r\n", "@ksekine : Please reopen if you are seeing the issue on Android.", "@ksekine \r\nDid you find the reason?\r\nI have the same issue when testing on Android with TFLite and TFlite Benchmark tool.\r\n", "Sorry, I have not found the reason... Please let me know about it if you have any updates."]}, {"number": 25536, "title": "I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2", "body": "I have installed tensorflow in my CPU based system using command:      \r\npip install tensorflow  \r\n\r\nInstallation completed without any error and as part of some initial verification I am able to see the tensorflow version installed:      \r\n>>> import tensorflow     \r\n>>> tensorflow.__version__    \r\n '1.5.0'\r\nOperating system used : Ubuntu 16.04  \r\n\r\nNow, when I tried running a python file having code to deal with a tensorflow model, I am getting the following error and the file did not execute:      \r\nI tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2  \r\n\r\nI checked online for solution and could see the discussions mostly around: TensorFlow binary was not compiled to use: 'AVX AVX2'(where in my case it is: 'SSE4.1 SSE4.2')  I am new to tensorflow and finding the solutions bit overwhelming. \r\nCould you please help me to resolve this specific issue?  \r\nThanks in advance", "comments": ["This is not an error, but Tensorflow may run with reduced performance due to this. It seems the precompiled binary available from Pip for this version was not compiled with SSE. Try updating Tensorflow to the latest stable (1.12).\r\n\r\nThe recommended way to install Tensorflow is through Anaconda rather than PIP, as it is usually better optimised.", "@Summa2802 Please try @harrismirza suggestion and let us know if the error persists. Here is a resource to install TF through [conda](https://towardsdatascience.com/tensorflow-gpu-installation-made-easy-use-conda-instead-of-pip-52e5249374bc). Please keep in mind about tested build [configurations](https://www.tensorflow.org/install/source#linux). Thanks!", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 25535, "title": "Bug: Remove reciprocal from monotonic decreasing ops", "body": "`1 / x` has an infinite discontinuity at `x = 0` (https://www.wolframalpha.com/input/?i=1+%2F+x). Thus it is not monotonic on the entire real line.\r\n\r\nThe algorithmic optimizer would optimize the case `Max(Inv(x)) => Inv(Min(x))`. But this is only true for `x > 0` or `x < 0`. E.g.:\r\n```python\r\nx = tf.constant([-1.5, 1., 2.])\r\ntf.reduce_max(tf.reciprocal(x))  # 1.0\r\ntf.reciprocal(tf.reduce_min(x))  # -0.6666667\r\n```\r\n\r\nThis PR removes `Inv` and `Reciprocal` ops from the list of elementwise monotonic ops.\r\nFixes https://github.com/tensorflow/tensorflow/pull/25330#issuecomment-460858086\r\n\r\n/cc @ezhulenev", "comments": ["Whoah, that's scary."]}, {"number": 25534, "title": "Disable additional tests for 1.13 ", "body": "", "comments": []}, {"number": 25533, "title": "[INTEl MKL]: Quantized Concat to replace #25146", "body": "@penpornk Can you please review? ", "comments": ["@rthadur This is a PR to bring back the rolled-back PR https://github.com/tensorflow/tensorflow/pull/25146. Could you please help be the assignee for this PR too?", "Thank you, @rthadur ! :)"]}, {"number": 25532, "title": "Skip testNonMatchingVariableCreation.", "body": "PiperOrigin-RevId: 232547857", "comments": []}, {"number": 25531, "title": "TFTRT: Support Slice op. Use TRT ISliceLayer for TRT 5.1+", "body": "For TRT 5.1+, we now use the new ISliceLayer which allows us to support slices in more situations and with strides > 1. We will fall back to the previous implementation which used the IPaddingLayer for earlier TRT versions. At the moment, negative strides are not supported but can be added later.\r\n\r\nBoth TF ops Slice and StridedSlice are supported.", "comments": ["@smit-hinsu Could you review this when you get a chance? Thanks!", "Thanks @trevor-m for the fix. Please take a look at the unresolved conversations. Once they're all resolved we're good to go.", "@aaroey Thanks for the reminder and again for reviewing! I think I've resolved the rest."]}, {"number": 25530, "title": "ImportError: cannot import name 'toco_flags_pb2'", "body": "**System information**\r\n- OS Platform : Windows 10 Home x64 version 1809\r\n- TensorFlow installed from : pip\r\n- TensorFlow version 1.12.0\r\n\r\n\r\n**text output from tflite_convert**\r\n\r\n```\r\n# tflite_convert \\ --output_file=/tmp/model.tflite \\ --graph_def_file=/tmp/output_graph.pb \\ --input_arrays=input \\ --output_arrays=MobilenetV1/Predictions/Reshape_1\r\nTraceback (most recent call last):\r\n  File \"c:\\users\\somesh\\appdata\\local\\programs\\python\\python36\\lib\\runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"c:\\users\\somesh\\appdata\\local\\programs\\python\\python36\\lib\\runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"C:\\Users\\somesh\\AppData\\Local\\Programs\\Python\\Python36\\Scripts\\tflite_convert.exe\\__main__.py\", line 5, in <module>\r\n  File \"c:\\users\\somesh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\contrib\\__init__.py\", line 103, in <module>\r\n    from tensorflow.contrib.lite.python import lite\r\n  File \"c:\\users\\somesh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\contrib\\lite\\python\\lite.py\", line 40, in <module>\r\n    from tensorflow.lite.python import lite_constants as constants\r\n  File \"c:\\users\\somesh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\lite\\python\\lite_constants.py\", line 21, in <module>\r\n    from tensorflow.lite.toco import toco_flags_pb2 as _toco_flags_pb2\r\nImportError: cannot import name 'toco_flags_pb2 \r\n```\r\n", "comments": ["@someshbhalsing Could you mention more details about the context and steps leading to this error? It is better if you can provide any code to reproduce the error. Thanks!", "The issue is solved.\r\nI installed tensorflow-nightly and then used the tflite convertor.\r\n", "I am closing this as it was resolved. Thanks!", "Are you satisfied with the resolution of your issue?\r\n[Yes](https://goo.gl/forms/Oe0tEvODFRoI2gJF3)\r\n[No](https://goo.gl/forms/fUjzOfrtkFbrOT8d2)"]}, {"number": 25529, "title": "Fix/Enable keras.utils.metrics_utils AUCCurve api", "body": "PR enabling AUCCurve API that is needed by https://github.com/tensorflow/estimator, particularly PR https://github.com/tensorflow/estimator/pull/27", "comments": ["AUC metric accepts string inputs, we have added the enums for internal usage only. I see that there are some tests which are passing the enum values as inputs, we will update them to the string values. If you see any test like please feel free to update it to the string values.", "@pavithrasv for me it was supposed to be mainly a fix of the bug that started to occur, probably at the time when tf.estimator was detached from the tensorflow repo:\r\n```\r\nFile \"/anaconda2/envs/research36/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/head/binary_class_head.py\", line 24, in <module> from tensorflow.python.keras.utils import metrics_utils ImportError: cannot import name 'metrics_utils'\r\n```\r\nplease see https://github.com/tensorflow/estimator/pull/27\r\nFor sure there are other ways to solve the issue, eg. importing whole `metric_utils` module (this one seemed to me less consistent)", "Looks to me that the PR is not needed since the issue with imports has disappeared in the last `tf-nightly` for me."]}, {"number": 25528, "title": "where is tensor_forest ?  i cannot find it  from API ?", "body": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version:\r\n- Doc Link:\r\n\r\n\r\n**Describe the documentation issue**\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\n", "comments": []}, {"number": 25527, "title": "ROCm build doesn't detect GPU", "body": "\r\n**System information**\r\n- OS Platform and Distribution  Ubuntu 18.10\r\n- TensorFlow installed from source\r\n- TensorFlow version tensorflow-1.13.0rc0-cp36-cp36m-linux_x86_64.whl\r\n- Python version: 3.6\r\n- Installed using pip with wheel built from source:\r\n- Bazel version 0.21:\r\n- GCC/Compiler version 8.2:\r\n- CUDA/cuDNN version N/A:\r\n- GPU model and memory: AMD Vega RX 64 \r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nSelecting ROCm in \"./configure\" doesn't find GPU in \"tf.session()\"\r\n", "comments": ["@Dekken Were you able to successfully install tf_gpu? I have followed the following [resource](https://github.com/rnreich/ubuntu-tensorflow-gpu-all-versions) and installed tf_gpu successfully. Could you try it. You might need to modify few things like CUDA version and drivers etc. Please let me know how it progresses. Thanks!", "I can install the ROCM deb file and it's fine, but I think that link is sure for Nvidia GPUs no?", "logic for ROCm in upstream TensorFlow is not complete yet, to the very least we need #25596 in.\r\nFor now please use downstream fork from AMD at: https://github.com/ROCmSoftwarePlatform/tensorflow-upstream", "fair enough, just seems a bit odd to have the config option IMO"]}, {"number": 25526, "title": "ModuleNotFoundError: No module named 'tensorflow_estimator' in bazel tests", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution: 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: master\r\n- Python version: Python 3.6.6\r\n- Installed using virtualenv? pip? conda?: N/A\r\n- Bazel version (if compiling from source): 0.20.0\r\n- GCC/Compiler version (if compiling from source): 7.3.0\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n\r\n\r\n**Describe the problem**\r\nAccording to https://www.tensorflow.org/install/source after downloading I should be able to run tests via:\r\nbazel test -c opt -- //tensorflow/... -//tensorflow/compiler/... -//tensorflow/lite/...\r\nBut when I run this command a lot of tests fail like this one\r\nbazel test tensorflow/contrib/eager/python/examples/gan:mnist_graph_test_gpu\r\nfail on No module named 'tensorflow_estimator' even though later I've installed estimator.\r\n\r\nDo I need to have some special environment? I've been even testing tensorflow/tensorflow docker image and it also fails with this error\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\ngit clone https://github.com/tensorflow/tensorflow.git\r\ncd tensorflow\r\nbazel test tensorflow/contrib/eager/python/examples/gan:mnist_graph_test_gpu\r\n**Any other info / logs**\r\n\r\nexec ${PAGER:-/usr/bin/less} \"$0\" || exit 1\r\nExecuting tests from //tensorflow/contrib/eager/python/examples/gan:mnist_graph_test_gpu\r\n-----------------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/home/tclbot/.cache/bazel/_bazel_tclbot/eee9defa2fa4c4fc557baa005719ebd9/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/contrib/eager/python/examples/gan/mnist_graph_test_gpu.runfiles/org_tensorflow/tensorflow/contrib/eager/python/examples/gan/mnist_graph_test.py\", line 26, in <module>\r\n    from tensorflow.contrib.eager.python.examples.gan import mnist\r\n  File \"/home/tclbot/.cache/bazel/_bazel_tclbot/eee9defa2fa4c4fc557baa005719ebd9/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/contrib/eager/python/examples/gan/mnist_graph_test_gpu.runfiles/org_tensorflow/tensorflow/contrib/__init__.py\", line 41, in <module>\r\n    from tensorflow.contrib import distribute\r\n  File \"/home/tclbot/.cache/bazel/_bazel_tclbot/eee9defa2fa4c4fc557baa005719ebd9/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/contrib/eager/python/examples/gan/mnist_graph_test_gpu.runfiles/org_tensorflow/tensorflow/contrib/distribute/__init__.py\", line 33, in <module>\r\n    from tensorflow.contrib.distribute.python.tpu_strategy import initialize_tpu_system\r\n  File \"/home/tclbot/.cache/bazel/_bazel_tclbot/eee9defa2fa4c4fc557baa005719ebd9/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/contrib/eager/python/examples/gan/mnist_graph_test_gpu.runfiles/org_tensorflow/tensorflow/contrib/distribute/python/tpu_strategy.py\", line 27, in <module>\r\n    from tensorflow.contrib.tpu.python.ops import tpu_ops\r\n  File \"/home/tclbot/.cache/bazel/_bazel_tclbot/eee9defa2fa4c4fc557baa005719ebd9/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/contrib/eager/python/examples/gan/mnist_graph_test_gpu.runfiles/org_tensorflow/tensorflow/contrib/tpu/__init__.py\", line 73, in <module>\r\n    from tensorflow.contrib.tpu.python.tpu.keras_support import tpu_model as keras_to_tpu_model\r\n  File \"/home/tclbot/.cache/bazel/_bazel_tclbot/eee9defa2fa4c4fc557baa005719ebd9/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/contrib/eager/python/examples/gan/mnist_graph_test_gpu.runfiles/org_tensorflow/tensorflow/contrib/tpu/python/tpu/keras_support.py\", line 62, in <module>\r\n    from tensorflow.contrib.tpu.python.tpu import tpu\r\n  File \"/home/tclbot/.cache/bazel/_bazel_tclbot/eee9defa2fa4c4fc557baa005719ebd9/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/contrib/eager/python/examples/gan/mnist_graph_test_gpu.runfiles/org_tensorflow/tensorflow/contrib/tpu/python/tpu/tpu.py\", line 25, in <module>\r\n    from tensorflow.contrib.compiler import xla\r\n  File \"/home/tclbot/.cache/bazel/_bazel_tclbot/eee9defa2fa4c4fc557baa005719ebd9/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/contrib/eager/python/examples/gan/mnist_graph_test_gpu.runfiles/org_tensorflow/tensorflow/contrib/compiler/xla.py\", line 28, in <module>\r\n    from tensorflow.python.estimator import model_fn as model_fn_lib\r\n  File \"/home/tclbot/.cache/bazel/_bazel_tclbot/eee9defa2fa4c4fc557baa005719ebd9/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/contrib/eager/python/examples/gan/mnist_graph_test_gpu.runfiles/org_tensorflow/tensorflow/python/estimator/__init__.py\", line 26, in <module>\r\n    from tensorflow_estimator.python import estimator\r\nModuleNotFoundError: No module named 'tensorflow_estimator'\r\n", "comments": ["could you try running `pip install tensorflow-estimator --pre` before running tests?", "even though later I've installed estimator.\r\n\r\nSo of course I've tried to rerun with tensorflow-estimator installed but it didn't help\r\nInside ipython `from tensorflow_estimator.python import estimator` runs fine", "Maybe this was the issue that I've tried to work with python3?\r\nAfter installing python2 and tensorflow-estimator for python2 problem has disappeared"]}, {"number": 25525, "title": "tf.layers.batch_normalization deprecation is a regression", "body": "**System information**\r\n- TensorFlow version (use command below):\r\n('v1.12.0-7360-g5076adf64a', '1.13.0-dev20190204')\r\n\r\n**Describe the behaviour**\r\n[tensorflow/tensorflow/python/layers/normalization.py](https://github.com/tensorflow/tensorflow/blob/r1.13/tensorflow/python/layers/base.py) has a deprecation warning: (Use keras.layers.batch_normalization instead.')\r\n\r\nHowever, the BatchNormalization class in that file also inherits from base.Layer. In particular, this means it updates UPDATE_OPS which the keras layer doesn't. \r\n\r\nThe workaround is cumbersome. One is use the following code:\r\n    \r\n    def batch_norm(net_input, is_training, trainable=True, momentum=0.99,\r\n               name=\"BatchNorm\"):\r\n    layer = tf.keras.layers.BatchNormalization(\r\n        epsilon=1E-5, center=True, scale=True, momentum=momentum,\r\n        trainable=trainable, name=name)\r\n    add_elements_to_collection(layer.updates, tf.GraphKeys.UPDATE_OPS)\r\n\r\n    return layer.apply(net_input, training=is_training)\r\n\r\nWith a separate method\r\n\r\n    def add_elements_to_collection(elements, collection_list):\r\n        elements = tf.nest.flatten(elements)\r\n        collection_list = tf.nest.flatten(collection_list)\r\n        for name in collection_list:\r\n           collection = tf.get_collection_ref(name)\r\n           collection_set = set(collection)\r\n           for element in elements:\r\n               if element not in collection_set:\r\n                    collection.append(element)\r\n\r\n\r\nThe other workaround is to create a separate list, to be used instead of tf.GraphKeys.UPDATE_OPS.\r\n\r\nIn my view, this is a regression bug as avoiding the use of the deprecated methods involves the loss of useful feature and requirement of extra code.  The canned model such as [ResNet](https://github.com/tensorflow/models/blob/master/official/resnet/resnet_model.py) will be affected by this. ", "comments": ["In TensorFlow 2.0, there will be no collections, as these represent global state that we are moving away from. The keras layers operate in the way that 2.0 at large will operate-- objects like variables and ops should be tracked and passed around explicitly using their Python handles. \r\n\r\nThere are a couple of ways to think about the above: \r\n* Simplify the workaround using tf.add_to_collection.\r\n* Ignore the deprecation warning and stick with the old batch_norm-- this will work for the life of TF 1.x\r\n* Update to the Keras layers and don't rely on collections to run update ops, as this will help prepare you for the future with 2.0. It's hard to advise on how to do this given the code snippet above, but with more context about the systems/APIs/needs of what your doing, I could give more pointers as to how such code would look in the new world.\r\n\r\nLet me know if the above makes sense.", "So how does this work with estimator and model_fn? Will users have to move away from having a model_fn as an actual function which calls functions and have to create a class whose only purpose is to additionally keep track of update_ops? ", "Keras APIs handle layer update ops as part of their fit and evaluate loops. However if you use the Estimator API with a Keras model as part of your model function or any low level TensorFlow APIs, you will need to add these layer updates explicitly in your training loop to the train_op. For example, consider this example which uses the Estimator API:\r\n\r\n```\r\ndef model_fn(features, labels):\r\n  inputs = tf.keras.layers.Input(shape=...)\r\n  output = tf.keras.layers.BatchNormalization(..., name=...)(inputs, training=....)\r\n \r\n  model = tf.keras.models.Model(inputs, output, name=....)\r\n  logits = model(features)\r\n  ...\r\n  \r\n  # Find the layer in the model corresponding to the batchnorm layer and add the    \r\n  # layer updates explicitly.\r\n  update_ops = batch_norm_layer.get_updates_for(features) \r\n  \r\n  minimize_op =  optimizer.apply_gradients(...)\r\n  train_op = tf.group(minimize_op, update_ops)\r\n \r\n  return EstimatorSpec(... train_op=train_op)\r\n```\r\n\r\nThe new Estimator Head that is being worked on will also take update_ops as an explicit kwarg.\r\n\r\nNote that if you use model_to_estimator to convert your existing Keras model to an Estimator then layer updates are handled for you by the API, and you do not need to add anything extra.\r\n\r\nDoes that make sense?", "CC @dynamicwebpaige -- this is a FAQ; is there a place we are compiling FAQs?", "Thanks for the reply.\r\n\r\nI think my use case is the use of a model_fn without Keras rather than using a Keras model in an estimator. Currently, users are being told that the use of batch_normalization is deprecated and being directed to the Keras layer. The problems are two fold:\r\n\r\n1. (communication \"gotcha\") The alternative does not change UPDATE_OPS but there is no warning in the deprecation message.\r\n2. The alternative is not a drop in replacement as some users (like me), will have avoided using class and simply calling nested functions such that the model_fn is used as a pure function. (I understand it isn't due to the global state.) \r\n\r\nSo I can think of two solutions.\r\n1. Pass in a list to add update_ops, into every method which might have batch normalized in the function nest. (Use a decorator?)\r\n2. Use something akin to tf.variable_scope and tf.device. However, are these being deprecated as part of the same changes?\r\n\r\nWhat is the recommended solution for those not using Keras and who are using functions rather than trying to build the model in a class? ", "Re: (1) I agree that additional notes in the error would be helpful-- would you be interested in sending a PR that reflects your preferred messaging?\r\n\r\nWith regard to making sure these are called, one option is to use the @tf.function decorator. This decorator introduces implied control dependencies, so update ops inside should run as expected. There are restrictions on the decorator-- ie, variables can only be created during the first pass of the function, and otherwise must be passed in as parameters-- but you can read more and consider whether this is useful for you here: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/eager/def_function.py#L703", "It has been 29 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will open a new issue. Thanks!", "Apologies for the delay. I am still puzzled with the use of Keras, having previously relied on estimator. \r\n\r\nPlease can I refer to [the official Keras resnet model](https://github.com/tensorflow/models/blob/master/official/resnet/keras/resnet_model.py):\r\n\r\n    x = layers.BatchNormalization(axis=bn_axis,\r\n                                  momentum=BATCH_NORM_DECAY,\r\n                                  epsilon=BATCH_NORM_EPSILON,\r\n                                  name=bn_name_base + '2a')(x)\r\n    x = layers.Activation('relu')(x)\r\n\r\n Is this a mistake because the updates from the BatchNormalisation layer are not updated? Is the training script in effect cheating and relying on training-like BatchNormlisation for evaluation?", "If `Model.fit()` or `Model.evaluate()` API is used then the updates are being taken care of.", "> Keras APIs handle layer update ops as part of their fit and evaluate loops. However if you use the Estimator API with a Keras model as part of your model function or any low level TensorFlow APIs, you will need to add these layer updates explicitly in your training loop to the train_op. For example, consider this example which uses the Estimator API:\r\n> \r\n> ```\r\n> def model_fn(features, labels):\r\n>   inputs = tf.keras.layers.Input(shape=...)\r\n>   output = tf.keras.layers.BatchNormalization(..., name=...)(inputs, training=....)\r\n>  \r\n>   model = tf.keras.models.Model(inputs, output, name=....)\r\n>   logits = model(features)\r\n>   ...\r\n>   \r\n>   # Find the layer in the model corresponding to the batchnorm layer and add the    \r\n>   # layer updates explicitly.\r\n>   update_ops = batch_norm_layer.get_updates_for(features) \r\n>   \r\n>   minimize_op =  optimizer.apply_gradients(...)\r\n>   train_op = tf.group(minimize_op, update_ops)\r\n>  \r\n>   return EstimatorSpec(... train_op=train_op)\r\n> ```\r\n> \r\n> The new Estimator Head that is being worked on will also take update_ops as an explicit kwarg.\r\n> \r\n> Note that if you use model_to_estimator to convert your existing Keras model to an Estimator then layer updates are handled for you by the API, and you do not need to add anything extra.\r\n> \r\n> Does that make sense?\r\n\r\n\r\n@karmel On the part where using model_to_estimator handles the update ops for the user. Just to clarify, while training a user will directly runs train_and_evaluate() and the \"update_ops\" get handled automatically ?", "my solution to make BatchNormalization works properly , i.e. updating moving_mean and moving_variance, if you are using K.function API\r\n\r\n```\r\ndef xor_list(lst1, lst2): \r\n    return  [value for value in lst1+lst2 if (value not in lst1) or (value not in lst2)  ]  \r\n\r\n#decoder - is keras model\r\ndecoder_def_updates = decoder._updates.copy()\r\nloss = decoder (code)\r\n\r\n#fetching only new appeared updates \r\ndecoder_updates = xor_list (decoder_def_updates, self.decoder._updates)\r\n\r\n#now we gathered all updates of inner layers in decoder model\r\n...\r\n#pass these updates together with optimizer updates\r\nK.function ([...inputs...],[loss], optimizer.get_updates(loss, weights) + decoder_updates )\r\n```"]}, {"number": 25524, "title": "Tensorboard Keras fit callback error with TensorFlow 2.0", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Arch Linux\r\n- Tensorflow installed from (source or binary): pip\r\n- Tensorflow version (use command below): tf-nightly-gpu-2.0-preview | 2.0.0.dev20190204 |\r\n- Python version: 3.6.8\r\n- CUDA/cuDNN version: 10.0, V10.0.130\r\n- GPU model and memory: GeForce RTX 2018 Ti 11GB\r\n\r\n**Describe the current behavior**\r\nDuring the training of a simple \"toy-example\" classificator using TensorFlow 2.0 and tfds, I'm trying to use the Keras callback in order to log the results and to be able to use TensorBoard. When the first epoch of training ends I get the following error: `tensorflow.python.framework.errors_impl.NotFoundError: Resource localhost/logdir:./log/N10tensorflow22SummaryWriterInterfaceE does not exist. [Op:WriteScalarSummary] name: epoch_loss/\r\n`\r\n\r\n**Describe the expected behavior**\r\nI expect to be able to use the TensorBoard callback without issues.\r\n\r\n**Code to reproduce the issue**\r\n\r\n**Classificator:**\r\nThis is a toy example based on the inception architecture and it is written inside a _model.py_ file using Keras Functional API.\r\n\r\n```\r\ndef inception(input_shape: Tuple[int, int, int]) -> k.Model:\r\n    # set the input\r\n    input_img = k.layers.Input(shape=input_shape)\r\n\r\n    tower_1 = k.layers.Conv2D(64, (1, 1), padding=\"same\", activation=\"relu\")(input_img)\r\n    tower_1 = k.layers.Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\")(tower_1)\r\n\r\n    tower_2 = k.layers.Conv2D(64, (1, 1), padding=\"same\", activation=\"relu\")(input_img)\r\n    tower_2 = k.layers.Conv2D(64, (5, 5), padding=\"same\", activation=\"relu\")(tower_2)\r\n\r\n    tower_3 = k.layers.MaxPooling2D((3, 3), strides=(1, 1), padding=\"same\")(input_img)\r\n    tower_3 = k.layers.Conv2D(64, (1, 1), padding=\"same\", activation=\"relu\")(tower_3)\r\n\r\n    output = k.layers.concatenate([tower_1, tower_2, tower_3], axis=3)\r\n\r\n    output = k.layers.Flatten()(output)\r\n    out = k.layers.Dense(10, activation=\"softmax\")(output)\r\n\r\n    model = k.models.Model(inputs=[input_img], outputs=[out])\r\n\r\n    print(model.summary())\r\n\r\n    return model\r\n```\r\n\r\n**Training code:** \r\nThe training code it is inside a _test.py_ file and use the `tfds` to import the datasets and the Keras `fit` function to train.\r\n\r\n```\r\nimport tensorflow_datasets as tfds\r\nimport tensorflow as tf\r\nfrom tensorflow import keras as k\r\n\r\nimport multiprocessing\r\nimport model\r\n\r\nDATADIR = \"/run/media/federico/XData/tensorflow_datasets\"\r\nCLASSES = 10\r\nEPOCHS = 25\r\nBATCH = 128\r\nLRATE = 0.01\r\nDECAY = LRATE / EPOCHS\r\n\r\n# this is applied to every single data passed\r\ndef process_features(feature):\r\n    image, label = feature[\"image\"], feature[\"label\"]\r\n\r\n    # image conversion into [0, 1]\r\n    image = image / 255\r\n    image = tf.cast(image, tf.float32)\r\n    feature[\"image\"] = image\r\n\r\n    # label conversion into one-hot\r\n    print(label)\r\n    label = tf.one_hot(label, CLASSES)\r\n    feature[\"label\"] = label\r\n\r\n    return feature\r\n\r\n# print(tfds.list_builders())\r\n\r\ndataset, dataset_info = tfds.load(name=\"cifar10\", data_dir=DATADIR, with_info=True)\r\ntrain_dataset, test_dataset = dataset[\"train\"], dataset[\"test\"]\r\n\r\n# process features\r\ntrain_dataset = (\r\n    train_dataset.map(process_features, num_parallel_calls=multiprocessing.cpu_count())\r\n    .shuffle(1000)\r\n    .batch(BATCH)\r\n    .repeat(EPOCHS)\r\n    # .prefetch(10)\r\n)\r\n\r\n\r\ntest_dataset = test_dataset.map(\r\n    process_features, num_parallel_calls=multiprocessing.cpu_count()\r\n).batch(dataset_info.splits[\"test\"].get_proto().statistics.num_examples)\r\n\r\nfor f in test_dataset:\r\n    images_t, labels_t = f[\"image\"], f[\"label\"]\r\n\r\nmodel = model.inception(dataset_info.features[\"image\"].shape)\r\n\r\n# compile the model\r\nmodel.compile(\r\n    optimizer=k.optimizers.RMSprop(learning_rate=LRATE, decay=DECAY),\r\n    loss=k.losses.categorical_crossentropy,\r\n    metrics=[k.metrics.categorical_accuracy],\r\n)\r\n\r\ntbCallback = [\r\n    k.callbacks.TensorBoard(\r\n        log_dir=\"./log\", histogram_freq=0, write_graph=False, write_images=False\r\n    )\r\n]\r\n# tbCallback = [k.callbacks.TensorBoard(log_dir='./log')]\r\n\r\nstep = 0\r\nfor f in train_dataset:\r\n    images, labels = f[\"image\"], f[\"label\"]\r\n    step += 1\r\n    model.fit(\r\n        images,\r\n        labels,\r\n        validation_data=(images_t, labels_t),\r\n        steps_per_epoch=100,\r\n        epochs=1,\r\n        batch_size=BATCH,\r\n        callbacks=tbCallback,\r\n    )\r\n\r\n```\r\n\r\n**Other info / logs**\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/run/media/federico/XData/PycharmProjectsXData/classificator/test.py\", line 105, in <module>\r\n    callbacks=tbCallback,\r\n  File \"/run/media/federico/XData/virtualenvs/python36_tf2preview/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 963, in fit\r\n    steps_name='steps_per_epoch')\r\n  File \"/run/media/federico/XData/virtualenvs/python36_tf2preview/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\", line 386, in model_iteration\r\n    callbacks.on_epoch_end(epoch, epoch_logs)\r\n  File \"/run/media/federico/XData/virtualenvs/python36_tf2preview/lib/python3.6/site-packages/tensorflow/python/keras/callbacks.py\", line 261, in on_epoch_end\r\n    callback.on_epoch_end(epoch, logs)\r\n  File \"/run/media/federico/XData/virtualenvs/python36_tf2preview/lib/python3.6/site-packages/tensorflow/python/keras/callbacks.py\", line 1389, in on_epoch_end\r\n    self._write_custom_summaries(step, logs)\r\n  File \"/run/media/federico/XData/virtualenvs/python36_tf2preview/lib/python3.6/site-packages/tensorflow/python/keras/callbacks.py\", line 1335, in _write_custom_summaries\r\n    summary_ops_v2.scalar(name, value, step=step)\r\n  File \"/run/media/federico/XData/virtualenvs/python36_tf2preview/lib/python3.6/site-packages/tensorflow/python/ops/summary_ops_v2.py\", line 564, in scalar\r\n    return summary_writer_function(name, tensor, function, family=family)\r\n  File \"/run/media/federico/XData/virtualenvs/python36_tf2preview/lib/python3.6/site-packages/tensorflow/python/ops/summary_ops_v2.py\", line 508, in summary_writer_function\r\n    should_record_summaries(), record, _nothing, name=\"\")\r\n  File \"/run/media/federico/XData/virtualenvs/python36_tf2preview/lib/python3.6/site-packages/tensorflow/python/framework/smart_cond.py\", line 54, in smart_cond\r\n    return true_fn()\r\n  File \"/run/media/federico/XData/virtualenvs/python36_tf2preview/lib/python3.6/site-packages/tensorflow/python/ops/summary_ops_v2.py\", line 501, in record\r\n    with ops.control_dependencies([function(tag, scope)]):\r\n  File \"/run/media/federico/XData/virtualenvs/python36_tf2preview/lib/python3.6/site-packages/tensorflow/python/ops/summary_ops_v2.py\", line 562, in function\r\n    name=scope)\r\n  File \"/run/media/federico/XData/virtualenvs/python36_tf2preview/lib/python3.6/site-packages/tensorflow/python/ops/gen_summary_ops.py\", line 727, in write_scalar_summary\r\n    writer, step, tag, value, name=name, ctx=_ctx)\r\n  File \"/run/media/federico/XData/virtualenvs/python36_tf2preview/lib/python3.6/site-packages/tensorflow/python/ops/gen_summary_ops.py\", line 763, in write_scalar_summary_eager_fallback\r\n    attrs=_attrs, ctx=_ctx, name=name)\r\n  File \"/run/media/federico/XData/virtualenvs/python36_tf2preview/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\", line 66, in quick_execute\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.NotFoundError: Resource localhost/logdir:./log/N10tensorflow22SummaryWriterInterfaceE does not exist. [Op:WriteScalarSummary] name: epoch_loss/\r\n```\r\n", "comments": ["Potentially of interest: #24632 ", "Duplicate of #25707", "Thanks for the report!  I've opened #25707 for the root cause, which is independent of Keras.  We can either leave this open for the manifestation of the bug within the TensorBoard Keras callback, or close it and just track the root cause.", "Should be fixed by 059ea3ba68db861e40d750eba688281011d2735f.", "hi\r\nAttributeError: 'TensorBoard' object has no attribute '_log_write_dir'\r\nHow to fix it??", "I am getting a different error when trying to use a callback with `mode.fit()`\r\n\r\n```\r\nAn op outside of the function building code is being passed\r\na \"Graph\" tensor. It is possible to have Graph tensors\r\nleak out of the function building context by including a\r\ntf.init_scope in your function building code.\r\n```\r\n\r\nCode : \r\n```\r\n        log_dir = os.path.join(PARENT_DIR, 'data', 'tensorboard', RUN_ID)\r\n        tboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir,\r\n                                                         histogram_freq=1,\r\n                                                         profile_batch=1)\r\n\r\n        history = self.model.fit(\r\n            np.array(batch_train_x),\r\n            np.array(batch_train_y),\r\n            batch_size=len(batch_train_x),\r\n            epochs=5,\r\n            verbose=False,\r\n            callbacks=[tboard_callback])\r\n```\r\n"]}, {"number": 25523, "title": "TF Framework regularizers_test missing test case add", "body": "1. test_regularization_shared_layer\r\n2. test_regularization_shared_model\r\n3. test_regularization_shared_layer_in_different_models\r\ntest cases added", "comments": ["@fchollet \r\n\r\nthanks for quick reiew, changes done as per comments, please review the new changes.", "@Dayananda-V could you please resolve the conflicts? Thanks!", "Closing this PR due to write perssion denied, same changes will be track with new PR #28542. "]}, {"number": 25522, "title": "MATLAB and CUDNN: Could not create cudnn handle CUDNN_STATUS_NOT_INITIALIZED", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (use command below): 1.12\r\n- Python version: 3.6.8\r\n- Bazel version (if compiling from source): No\r\n- GCC/Compiler version (if compiling from source): No\r\n- CUDA/cuDNN version: 9.0\r\n- GPU model and memory: Titan Xp\r\n\r\n\r\nI have a CNN developed in PyCharm IDE that runs smoothly. Now I am trying to run the network through MATLAB system command by invoking the Python script and I am getting the following error:\r\n\r\n`...\r\n2019-02-05 12:37:45.681913: E tensorflow/stream_executor/cuda/cuda_dnn.cc:373] Could not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZED\r\n2019-02-05 12:37:45.682038: E tensorflow/stream_executor/cuda/cuda_dnn.cc:377] Error retrieving driver version: Unimplemented: kernel reported driver version not implemented on Windows\r\n2019-02-05 12:37:45.682192: E tensorflow/stream_executor/cuda/cuda_dnn.cc:373] Could not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZED\r\n2019-02-05 12:37:45.682306: E tensorflow/stream_executor/cuda/cuda_dnn.cc:377] Error retrieving driver version: Unimplemented: kernel reported driver version not implemented on Windows\r\n...\r\ntensorflow.python.framework.errors_impl.UnknownError: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\r\n...`\r\n\r\nIt is so weird because if I launch exactly the same command through the Windows cmd or through the PyCharm IDE all works perfectly. But if I launch it inside MATLAB, through the system command, it returns this error.\r\n\r\nSome idea?\r\n\r\nThank you very much.\r\n\r\nJavier.\r\n", "comments": ["@JavierJuan This is not Build/Installation or Bug/Performance issue. Please post this kind of support questions at [Stackoverflow](https://stackoverflow.com/questions/tagged/tensorflow). There is a big community to support and learn from your questions. GitHub is mainly for addressing bugs in installation and performance. Specifically, this is a good question to ask MATLAB community. Thanks!", "Are you satisfied with the resolution of your issue?\r\n[Yes](https://goo.gl/forms/Oe0tEvODFRoI2gJF3)\r\n[No](https://goo.gl/forms/fUjzOfrtkFbrOT8d2)"]}, {"number": 25521, "title": "Keras floor ceil operators added", "body": "Keras backend operator floor and ceil is added", "comments": ["Assigning members of the Keras team proper as this is an additive API change. \r\n\r\nJust a drive-by comment: I think you need to add unit tests in backend_test.py.", "Never mind the last comment. You already have unit tests added.", "Thanks for the PR.\r\n\r\nThe backend operations exposed in `tf.keras.backend` are just meant to mirror the API in the Keras API spec. Since we don't have these 2 ops in the Keras spec at this time, we won't replicate them here. TF users can just use e.g. `math_ops.floor`."]}, {"number": 25520, "title": "Normal.log_cdf raises exception when called with float64", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nYes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): \r\nLinux Ubuntu 16.04\r\n- TensorFlow installed from (source or binary): \r\nBinary (pip)\r\n- TensorFlow version (use command below): \r\nv1.12.0-0-ga6d8ffae09 1.12.0\r\n- Python version: \r\nPython 3.6.4 :: Anaconda, Inc.\r\n\r\n\r\n**Describe the current behavior**\r\n\r\nCalling Normal.log_cdf(x) with a float64 raises a TypeError exception.\r\n\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\nnormal = tf.distributions.Normal(loc=0.0, scale=1.0)\r\nnormal.log_cdf(tf.constant(3.5, dtype=tf.float32))  # Operation created successfully as expected\r\nnormal.log_cdf(tf.constant(3.5, dtype=tf.float64))  # Exception\r\n```\r\n\r\nException is:\r\n\r\n> TypeError: Input 'y' of 'Sub' Op has type float32 that does not match type float64 of argument 'x'.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n[trace.txt](https://github.com/tensorflow/tensorflow/files/2831779/trace.txt)\r\n", "comments": ["(probably you want loc=np.float64(0.0), scale=np.float(1.0)) to make the Normal distribution's dtype float64.", "Please reopen if that doesn't work.", "Are you satisfied with the resolution of your issue?<br> [Yes](https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=25520)<br> [No](https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=25520)\r\n"]}, {"number": 25519, "title": "Please offer binary without SSE4.1 instructions", "body": "Some machines don't have SSE4.1 CPU instructions, resulting in this error:\r\nhttps://github.com/tensorflow/tensorflow/issues/7138\r\n\r\nInstead of forcing users to manually compile their version of tensorflow you should offer a compiled binary (on pip) with SSE4.1 instructions disabled.", "comments": ["Marking as duplicate of https://github.com/tensorflow/tensorflow/issues/19584\r\nI understand your pain, and we are working on a system to enable custom build and delivery of binaries to users. But that is still a few months away."]}]