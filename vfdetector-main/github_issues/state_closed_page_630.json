[{"number": 34734, "title": "tensor_diag_part does not vectorize?", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS 10.15.1\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.0.0\r\n- Python version: 3.7\r\n\r\n**Describe the current behavior**\r\nThis code throws an error, despite `tf.linalg.tensor_diag_part` works on each of the two matrices:\r\n\r\n```python\r\n    k = tf.convert_to_tensor(np.arange(8).reshape((2,2,2)))\r\n    tf.vectorized_map(tf.linalg.tensor_diag_part, k)\r\n```\r\n\r\n> UnrecognizedFlagError: Unknown command line flag 'f'\r\n\r\nIt should return the diagonal of each of the two submatrices.", "comments": ["I have tried on colab with TF version 2.0, 2.1.0-dev20191201 and was able to reproduce the issue.Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/fecdecc2fcfd23ef317022ead88bef0d/untitled433.ipynb). Thanks!", "Hello, any progress? I have found this is not the only case, see https://github.com/tensorflow/tensorflow/issues/35579", "This is fixed with tf-nightly version '2.2.0-dev20200218' .Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34734\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34734\">No</a>\n"]}, {"number": 34733, "title": "loss=tf.keras.backend.sparse_categorical_crossentropy is different than loss='sparse_categorical_crossentropy'", "body": "So they run differently, with the version from the backend performing significantly worse.\r\nThis was performed on a google colab notebook reset each time, with GPU acceleration.\r\n\r\n**Code 1**\r\n`\r\n%tensorflow_version 2.x\r\n\r\nimport tensorflow as tf\r\n\r\nprint(tf.__version__)\r\n\r\nmnist = tf.keras.datasets.fashion_mnist\r\n\r\n(training_images,training_labels),(test_images,test_labels)=mnist.load_data()\r\n\r\ntraining_images=training_images/255.0\r\n\r\n#training_images=tf.reshape(training_images,(training_images.shape+(1,)))\r\n\r\ntest_images=test_images/255.0\r\n\r\n#test_images=tf.reshape(test_images,(test_images.shape+(1,)))\r\n\r\nmodel = tf.keras.models.Sequential([\r\n\r\n  tf.keras.layers.InputLayer(input_shape=(28, 28)),\r\n\r\n  tf.keras.layers.Reshape((28, 28, 1)),\r\n\r\n  tf.keras.layers.Conv2D(64,(3,3),activation=tf.nn.leaky_relu,input_shape=(28,28,1)),\r\n\r\n  tf.keras.layers.MaxPooling2D(2,2),\r\n\r\n  tf.keras.layers.Conv2D(64,(3,3),activation=tf.nn.leaky_relu),\r\n\r\n  tf.keras.layers.MaxPooling2D(2,2),\r\n\r\n  tf.keras.layers.Flatten(),\r\n\r\n  tf.keras.layers.Dense(128,activation=tf.nn.leaky_relu),\r\n\r\n  tf.keras.layers.Dense(10,activation='softmax')\r\n\r\n])\r\n\r\nmodel.compile(optimizer='adam',loss=tf.keras.backend.sparse_categorical_crossentropy,metrics=\r\n['accuracy'])\r\n\r\n#model.summary()\r\n\r\nmodel.fit(training_images,training_labels,epochs=5)\r\n\r\ntest_loss=model.evaluate(test_images,test_labels)\r\n\r\n`\r\n\r\nResults 1\r\n\r\n`\r\n\r\nTensorFlow 2.x selected.\r\n\r\n2.0.0\r\n\r\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-\r\nidx1-ubyte.gz\r\n\r\n32768/29515 [=================================] - 0s 0us/step\r\n\r\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-\r\nidx3-ubyte.gz\r\n\r\n26427392/26421880 [==============================] - 0s 0us/step\r\n\r\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-\r\nidx1-ubyte.gz\r\n\r\n8192/5148 [===============================================] - 0s 0us/step\r\n\r\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-\r\nidx3-ubyte.gz\r\n\r\n4423680/4422102 [==============================] - 0s 0us/step\r\n\r\nTrain on 60000 samples\r\n\r\nEpoch 1/5\r\n\r\n60000/60000 [==============================] - 24s 392us/sample - loss: 0.4204 - \r\naccuracy: 0.1043\r\n\r\nEpoch 2/5\r\n\r\n60000/60000 [==============================] - 18s 301us/sample - loss: 0.2878 - \r\naccuracy: 0.1026\r\n\r\nEpoch 3/5\r\n\r\n60000/60000 [==============================] - 18s 307us/sample - loss: 0.2474 - \r\naccuracy: 0.1016\r\n\r\nEpoch 4/5\r\n\r\n60000/60000 [==============================] - 18s 293us/sample - loss: 0.2156 - \r\naccuracy: 0.1011\r\n\r\nEpoch 5/5\r\n\r\n60000/60000 [==============================] - 18s 296us/sample - loss: 0.1936 - \r\naccuracy: 0.1011\r\n\r\n`\r\n\r\n**Code 2**\r\n\r\n`\r\n\r\n%tensorflow_version 2.x\r\n\r\nimport tensorflow as tf\r\n\r\nprint(tf.__version__)\r\n\r\nmnist = tf.keras.datasets.fashion_mnist\r\n\r\n(training_images,training_labels),(test_images,test_labels)=mnist.load_data()\r\n\r\ntraining_images=training_images/255.0\r\n\r\n#training_images=tf.reshape(training_images,(training_images.shape+(1,)))\r\n\r\ntest_images=test_images/255.0\r\n\r\n#test_images=tf.reshape(test_images,(test_images.shape+(1,)))\r\n\r\nmodel = tf.keras.models.Sequential([\r\n\r\n  tf.keras.layers.InputLayer(input_shape=(28, 28)),\r\n\r\n  tf.keras.layers.Reshape((28, 28, 1)),\r\n\r\n  tf.keras.layers.Conv2D(64,(3,3),activation=tf.nn.leaky_relu,input_shape=(28,28,1)),\r\n\r\n  tf.keras.layers.MaxPooling2D(2,2),\r\n\r\n  tf.keras.layers.Conv2D(64,(3,3),activation=tf.nn.leaky_relu),\r\n\r\n  tf.keras.layers.MaxPooling2D(2,2),\r\n\r\n  tf.keras.layers.Flatten(),\r\n\r\n  tf.keras.layers.Dense(128,activation=tf.nn.leaky_relu),\r\n\r\n  tf.keras.layers.Dense(10,activation='softmax')\r\n\r\n])\r\n\r\nmodel.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\r\n\r\n#model.summary()\r\n\r\nmodel.fit(training_images,training_labels,epochs=5)\r\n\r\ntest_loss=model.evaluate(test_images,test_labels)\r\n\r\n`\r\n\r\nResults 2\r\n\r\n`\r\n\r\nTensorFlow 2.x selected.\r\n\r\n2.0.0\r\n\r\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-\r\nidx1-ubyte.gz\r\n\r\n32768/29515 [=================================] - 0s 0us/step\r\n\r\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-\r\nidx3-ubyte.gz\r\n\r\n26427392/26421880 [==============================] - 0s 0us/step\r\n\r\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-\r\nidx1-ubyte.gz\r\n\r\n8192/5148 [===============================================] - 0s 0us/step\r\n\r\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-\r\nidx3-ubyte.gz\r\n\r\n4423680/4422102 [==============================] - 0s 0us/step\r\n\r\nTrain on 60000 samples\r\n\r\nEpoch 1/5\r\n\r\n60000/60000 [==============================] - 11s 186us/sample - loss: 0.4279 - \r\naccuracy: 0.8448\r\n\r\nEpoch 2/5\r\n\r\n60000/60000 [==============================] - 6s 92us/sample - loss: 0.2905 - \r\naccuracy: 0.8934\r\n\r\nEpoch 3/5\r\n60000/60000 [==============================] - 6s 92us/sample - loss: 0.2466 - accuracy: 0.9096\r\nEpoch 4/5\r\n60000/60000 [==============================] - 6s 92us/sample - loss: 0.2177 - accuracy: 0.9183\r\nEpoch 5/5\r\n60000/60000 [==============================] - 5s 91us/sample - loss: 0.1942 - accuracy: 0.9271\r\n`", "comments": ["I have tried on colab with TF version 2.0  and was able to reproduce the issue.Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/30c0346fd136e1b76963fa6235326846/untitled426.ipynb). Thanks!", "@Emnolope You should have used `tf.keras.losses.sparse_categorical_crossentropy` instead of `loss=tf.keras.backend.sparse_categorical_crossentropy`. Please check the TF [website](https://www.tensorflow.org/api_docs/python/tf/keras/losses/sparse_categorical_crossentropy) for more details on accessing this loss function.\r\n\r\nWhen I used `tf.keras.losses.sparse_categorical_crossentropy` inplace of  `loss=tf.keras.backend.sparse_categorical_crossentropy`, the results were very similar. Please take a look at the [gist here](https://colab.sandbox.google.com/gist/jvishnuvardhan/4a001b4776ec4233e30a7e23ec2aee51/untitled426.ipynb). \r\n\r\nI am closing this issue as it was resolved. Please feel free to reopen if the issue persists again. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34733\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34733\">No</a>\n"]}, {"number": 34732, "title": "Bug with embedding layer for position of sequence using tf.cumsum", "body": "Greetings,\r\n\r\nI wanted to create an embedding layer for token position along with an embedding layer for token\r\nin the sequence.\r\n\r\nThe first way I did was that I create a pos_ids input tensor, and feed an numpy array of position into the input. I then use embedding layer for the input as usual:\r\n\r\n`word_ids = Input(dtype='int32', batch_shape=(batch_size, max_seq_length), name='word_ids')\r\npos_ids = Input(dtype='int32', batch_shape=(batch_size, max_seq_length), name='pos_ids')\r\npos_embedding_layer = tensorflow.keras.layers.Embedding(input_dim=(max_seq_length+1), \r\n            output_dim=word_embedding_size, \r\n            input_length=max_seq_length, mask_zero=True, trainable=True)\r\nembedding_layer = tensorflow.keras.layers.Embedding(input_dim=(len(d)+1), \r\n            output_dim=word_embedding_size, \r\n            input_length=max_seq_length, mask_zero=True, trainable=True)\r\npos_ids_embeddings = pos_embedding_layer(pos_ids)`\r\n\r\nWith this I noticed the network is as usual, with parameters (18432) for the embedding layer. Here is what I get when I print the model summary.\r\n\r\n![image](https://user-images.githubusercontent.com/8759715/69912311-129b4800-145a-11ea-98c2-b9947e0c6bb9.png)\r\n\r\n\r\nHowever, I wanted to use tf.cumsum as another way to create the index of position. By doing that I can avoid having pos_ids as the another Input. My code is as follows, which I believe it is correct.\r\n\r\n`word_ids = Input(dtype='int32', batch_shape=(batch_size, max_seq_length), name='word_ids')\r\npos_embedding_layer = tensorflow.keras.layers.Embedding(input_dim=(max_seq_length+1), \r\n            output_dim=word_embedding_size, \r\n            input_length=max_seq_length, mask_zero=True, trainable=True)\r\nembedding_layer = tensorflow.keras.layers.Embedding(input_dim=(len(d)+1), \r\n            output_dim=word_embedding_size, \r\n            input_length=max_seq_length, mask_zero=True, trainable=True)\r\npos_tensor = tf.cumsum(tf.ones_like(word_ids, 'int32'), axis=-1)\r\npos_ids_embeddings = pos_embedding_layer(pos_tensor)`\r\n\r\nHowever, with this, I noticed pos_embedding_layer does not have any param when I print the model summary (model.summary()). The layer also does not connect to anything in the network.\r\n\r\n![image](https://user-images.githubusercontent.com/8759715/69912147-cb13bc80-1457-11ea-8ca5-833821041199.png)\r\n\r\nI guess this is a bug, and please correct me if it is the case. Also, how to fix this problem?\r\nThx.\r\n\r\n", "comments": ["@hoangcuong2011, Please provide the complete standalone code to reproduce the reported issue and also include the Tensorflow version. Thanks!", "@gadagashwini: Thx. Trying to create a minimal version of this, I found 2 versions as below.\r\nversion 1 - no parameters\r\nversion 2 - having parameters.\r\n\r\nThe only difference between them is the way I declare Input ( batch_shape=(32, max_seq_length), or shape(max_seq_length,). Why is this the case?\r\n\r\n\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\ndef main():\r\n    max_seq_length = 35\r\n    learning_rate = 2e-4\r\n    word_embedding_size = 512\r\n    def compile_new_model():\r\n        optimizer = tf.keras.optimizers.Adam(lr = learning_rate, clipnorm=1.0)\r\n        word_ids = tf.keras.layers.Input(dtype='int32', \r\n            batch_shape=(32, max_seq_length),\r\n            name='word_ids')\r\n\r\n        pos_embedding_layer = tf.keras.layers.Embedding(input_dim=(max_seq_length+1), \r\n            output_dim=word_embedding_size, \r\n            input_length=max_seq_length, trainable=True)\r\n        pos_idss = tf.cumsum(tf.ones_like(word_ids, 'int32'), axis=-1)\r\n        pos_ids_embeddings = pos_embedding_layer(pos_idss)\r\n        model = tf.keras.models.Model(inputs=[word_ids], outputs=pos_ids_embeddings)\r\n        model.compile(\r\n            optimizer,\r\n            loss=tf.keras.losses.sparse_categorical_crossentropy)\r\n        return model\r\nmodel = compile_new_model()\r\nprint(model.summary())\r\n```\r\n\r\n\r\n    \r\n-> output:\r\n![image](https://user-images.githubusercontent.com/38926056/69945429-168f9e80-151c-11ea-861f-b518641af2bd.png)\r\n\r\n\r\nVersion 2:\r\n\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\ndef main():\r\n    max_seq_length = 35\r\n    learning_rate = 2e-4\r\n    word_embedding_size = 512\r\n    def compile_new_model():\r\n        optimizer = tf.keras.optimizers.Adam(lr = learning_rate, clipnorm=1.0)\r\n        word_ids = tf.keras.layers.Input(dtype='int32', \r\n            shape=(max_seq_length,), \r\n            name='word_ids')\r\n\r\n        pos_embedding_layer = tf.keras.layers.Embedding(input_dim=(max_seq_length+1), \r\n            output_dim=word_embedding_size, \r\n            input_length=max_seq_length, trainable=True)\r\n        pos_idss = tf.cumsum(tf.ones_like(word_ids, 'int32'), axis=-1)\r\n        pos_ids_embeddings = pos_embedding_layer(pos_idss)\r\n        model = tf.keras.models.Model(inputs=[word_ids], outputs=pos_ids_embeddings)\r\n        model.compile(\r\n            optimizer,\r\n            loss=tf.keras.losses.sparse_categorical_crossentropy)\r\n        return model\r\nmodel = compile_new_model()\r\nprint(model.summary())\r\n```\r\n\r\n-> output:\r\n\r\n![image](https://user-images.githubusercontent.com/38926056/69945474-27d8ab00-151c-11ea-8c7e-2ded24a0f323.png)\r\n\r\n\r\n\r\n\r\n", "I could replicate the issue with Tensorflow 1.15 on colab.\r\nPlease find the colab gist [here](https://colab.sandbox.google.com/gist/gadagashwini/ee879e7ae5672c214ae3c674d0728b9a/untitled289.ipynb). Thanks!", "Assigning to Tom who worked on tf ops layer. Also, please note that we are not going to fix anything in 1.x since there won't be any new releases. We will still fix the issue if the same error happens in 2.x as well.", "@hoangcuong2011 Thanks for the issue!\r\n\r\nTested this and it is fixed in the latest tf-nightly\r\n\r\n```pip install -U tf-nightly```", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34732\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34732\">No</a>\n"]}, {"number": 34731, "title": "ValueError: Unknown loss function:smooth_l1_loss", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution: Linux Ubuntu 18.04\r\n- TensorFlow installed from (source or binary):  anaconda\r\n- TensorFlow version (use command below): 2.0\r\n- Python version: 3.7.5\r\n- CUDA/cuDNN version: 10.1\r\n\r\n**Error info**\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/lxz/PycharmProjects/PoseREN_tf2/src/train_baseline.py\", line 115, in <module>\r\n    baseline_model_load = tf.keras.models.load_model(MODEL_DIR, 'baseline.h5')\r\n  File \"/home/lxz/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/save.py\", line 150, in load_model\r\n    return saved_model_load.load(filepath, compile)\r\n  File \"/home/lxz/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/load.py\", line 93, in load\r\n    model._training_config))  # pylint: disable=protected-access\r\n  File \"/home/lxz/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/base.py\", line 457, in _method_wrapper\r\n    result = method(self, *args, **kwargs)\r\n  File \"/home/lxz/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\", line 336, in compile\r\n    self.loss, self.output_names)\r\n  File \"/home/lxz/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py\", line 1351, in prepare_loss_functions\r\n    loss_functions = [get_loss_function(loss) for _ in output_names]\r\n  File \"/home/lxz/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py\", line 1351, in <listcomp>\r\n    loss_functions = [get_loss_function(loss) for _ in output_names]\r\n  File \"/home/lxz/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py\", line 1087, in get_loss_function\r\n    loss_fn = losses.get(loss)\r\n  File \"/home/lxz/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/keras/losses.py\", line 1183, in get\r\n    return deserialize(identifier)\r\n  File \"/home/lxz/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/keras/losses.py\", line 1174, in deserialize\r\n    printable_module_name='loss function')\r\n  File \"/home/lxz/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/generic_utils.py\", line 210, in deserialize_keras_object\r\n    raise ValueError('Unknown ' + printable_module_name + ':' + object_name)\r\nValueError: Unknown loss function:smooth_l1_loss\r\n```\r\n\r\n**Code crop**\r\n```\r\n# Loss func\r\n@tf.function\r\ndef smooth_l1_loss(y_true, y_pred):\r\n    return tf.compat.v1.losses.huber_loss(y_true, y_pred)\r\n\r\n\r\nbaseline_model.compile(optimizer=keras.optimizers.SGD(learning_rate=LEARNING_RATE, momentum=MOMENTUM, decay=DECAY),\r\n                           loss=smooth_l1_loss, \r\n                           metrics=['MeanAbsoluteError'])  \r\n\r\nhistory = baseline_model.fit(x=train_images, y=train_labels, validation_data=(vali_images, vali_labels),\r\n                                 steps_per_epoch=np.ceil(train_images.shape[0] / BATCH_SIZE),\r\n                                 validation_steps=np.ceil(vali_images.shape[0] / BATCH_SIZE),\r\n                                 epochs=EPOCHS, batch_size=BATCH_SIZE,\r\n                                 callbacks=callbacks)\r\n\r\nbaseline_model.save(MODEL_DIR, 'baseline.h5')\r\n\r\nbaseline_model_load = tf.keras.models.load_model(MODEL_DIR, 'baseline.h5')\r\n\r\ntest_data = np.random.random((1, 96, 96)).reshape((-1, 96, 96, 1))\r\nprint(baseline_model_load.predict(test_data))\r\n```\r\n\r\n", "comments": ["@lxz1104 ,\r\nHi,can you please provide complete code to reproduce the error ?Thanks!", "@lxz1104 ,\r\nAny update on the issue ?Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34731\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34731\">No</a>\n"]}, {"number": 34730, "title": "Fix misformatted markdown in Model.fit docstring", "body": "The current documentation of `tf.keras.models.Model.fit` contains misformatted markdown in the description of the `validation_data` attribute: it is missing a line break after the list enumerating the possible types of accepted arguments, which hurts legibility upon rendering.\r\n\r\nSee [keras documentation](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit).\r\n\r\nThis commit fixes that problem.", "comments": []}, {"number": 34727, "title": "AttributeError: module 'tensorflow_datasets' has no attribute 'load'", "body": "This problem is usually caused by the mismatch between cuda and NVIDIA drivers, but my environment should be compatible. When I use tf2.0 to do other things, everything is normal, but when testing the transformers (https://github.com/huggingface/ transformers) encountered an error.\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- TensorFlow installed from (pip):\r\n- TensorFlow version (2.0):\r\n- Python version: 3.6\r\n- cuda: release 10.0, V10.0.130\r\n- cudnn: 7.6.4\r\n- driver version: Driver Version: 415.27\r\n\r\n**Code to reproduce the issue**\r\ncd transformers/\r\npython -m pytest -sv ./examples/\r\n\r\nI noticed that This repo((https://github.com/huggingface/ transformers)) is tested on Python 2.7 and 3.5+ (examples are tested only on python 3.5+), but i use python 3.6? Is this the cause?", "comments": ["@catqaq what was the problem? How did you find the solution? I have the same error", "Try upgrading tensorflow-dataset may help. \r\n\r\npip install --upgrade tensorflow-dataset\r\n\r\n\r\n", "I have the same error, tensorflow version is 2.3.0, python 3.7, is it because of the version problem?", "You can try to  upgrade tensorflow-dataset or downgrade python. Good luck!", "I tried to make a change and I didn't solve the problem.I downgraded the python version to 3.6 and try to upgrade tensorflow-dataset. And even I changed tensorflow version to 2.1.0\r\nAttributeError: module 'tensorflow_datasets' has no attribute 'load'"]}, {"number": 34725, "title": "Support for Python 3.8", "body": "", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F34725) for more info**.\n\n<!-- need_sender_cla -->", "@reliefs Could you please sign cla ? Thank you.", "@reliefs  Gentle ping to sign CLA. Thanks!", "In any case, just adding that line won't bring support for python 3.8. Hence, closing PR.", "yes that was a mistake a truely a lack of understanding from my part.. Still using tensorflow i love it.. \r\n\r\nI now just never use it for other people to install :P "]}, {"number": 34724, "title": "Can't accept a 2d array", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 (latest version)\r\n- TensorFlow installed from (source or binary): PIP\r\n- TensorFlow version (use command below): 1.14\r\n- Python version: 3.7.4\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**When feeding the fully connected layer my last 2d rnn matrix even though the documentation says that it should be able to accept a 2d matrix**\r\n\r\n**It should take a 2d matrix**\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n```python\r\nimport tensorflow as tf\r\n\r\ninputs = tf.placeholder(tf.int32, shape=(None, 750), name=\"inputs\")\r\nquestions = tf.placeholder(tf.int32, shape=(None, 750), name=\"inputs\")\r\n\r\ngru_cell = tf.nn,rnn_cell.GRUCell(64) # Units= 64\r\noutput, (state_c, state_h) = gru_cell(inputs, questions)\r\n# Both output & both states dimension is 2\r\nlogits = tf.contrib.layers.fully_connected(output, num_outputs=100, activation_fn=None) # vocab_size = 100\r\n# We don't have to run the session since Tensorflow will check the tensors for the right shape\r\n```\r\n", "comments": ["@mariusjohan, Please provide the complete standalone code to replicate the reported issue here. Thanks!", "@gadagashwini Is that enough?", "@mariusjohan, Please find the gist [here](https://colab.sandbox.google.com/gist/gadagashwini/d4440b9d05dca338f3e86df94a92bd3b/untitled290.ipynb) and let us know the expected output. Thanks!", "Sorry for taking so long, I've been really busy in school so I could not find any time. But here I am!\r\n\r\nFor some reason i could not run the gist, but i copy-pasted the code into my terminal and for some reason it worked there even with at 2d tensor.\r\n\r\nSorry for wasting your time :) But it doesnt work in own project for some reason. But i think i can solve it myself."]}, {"number": 34723, "title": "2.1.0rc0 cudart64_101.dll not found", "body": "**System information**\r\n- OS Platform: Windows 10\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 2.1.0rc0\r\n- Python version: 3.7\r\n- Installed using virtualenv? pip? conda?: virtualenv\r\n- CUDA/cuDNN version: 10.0\r\n- GPU model and memory: rtx 2060\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nWhen I tried to install tensorflow 2.1.0rc0, It didn't recognize my gpu and gave me this error:\r\n\r\nCould not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found\r\n\r\nIs that mean 2.1.0rc0 support cuda 10.1 now? It doesn't mention on release notes?\r\n\r\n\r\n", "comments": []}, {"number": 34722, "title": "ModuleNotFoundError tensorflow.python' is not a package", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 Home\r\n- TensorFlow version (use command below): 2.0\r\n- Python version: 3.6.7 and 3.7.4\r\n\r\n**Describe the current behavior**\r\nWhen trying to import Tensorflow using this line:\r\n`import tensorflow as tf`\r\n\r\nI get this error:\r\n\r\n> Traceback (most recent call last):\r\n  File \"singlestock/code.py\", line 1, in <module>\r\n    import tensorflow as tf\r\n  File \"D:\\documenten\\programs\\Python\\3.6.7\\lib\\site-packages\\tensorflow\\__init__.py\", line 98, in <module>\r\n    from tensorflow_core import *\r\n  File \"D:\\documenten\\programs\\Python\\3.6.7\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 40, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\nModuleNotFoundError: No module named 'tensorflow.python.tools'; 'tensorflow.python' is not a package\r\n\r\n**Describe the expected behavior**\r\nI shouldn't get this error. I should just be able to import tensorflow and then use it.\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\nThis is the code which doesn't work for me:\r\nI've tried this in python 3.7 and 3.6.\r\n```\r\nimport tensorflow as tf\r\n\r\ntensor = tf.convert_to_tensor([[1, 2, 3, 4], [2, 3, 4, 5]], tf.int32)\r\nprint(\"hello\")\r\n```\r\n\r\nI don't think the issue is in the code though, but I have no idea what the problem could be.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nerror:\r\n> Traceback (most recent call last):\r\n  File \"singlestock/code.py\", line 1, in <module>\r\n    import tensorflow as tf\r\n  File \"D:\\documenten\\programs\\Python\\3.6.7\\lib\\site-packages\\tensorflow\\__init__.py\", line 98, in <module>\r\n    from tensorflow_core import *\r\n  File \"D:\\documenten\\programs\\Python\\3.6.7\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 40, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\nModuleNotFoundError: No module named 'tensorflow.python.tools'; 'tensorflow.python' is not a package\r\n\r\ncode:\r\n```\r\nimport tensorflow as tf\r\n\r\ntensor = tf.convert_to_tensor([[1, 2, 3, 4], [2, 3, 4, 5]], tf.int32)\r\nprint(\"hello\")\r\n```\r\n", "comments": ["@R0b4 ,\r\nPlease try reinstalling Tensorflow by\r\nUninstall tensorflow:\r\n`pip uninstall tensorflow`\r\n\r\nThen reinstall it:\r\n`pip install tensorflow`\r\nAlso refer this [link](https://stackoverflow.com/questions/41415629/importerror-no-module-named-tensorflow-python).\r\nThanks!", "I already tried this. I also tried installing it in different versions of python (3.7.4, 3.6.7, 3.6.2). This didn't work.", "I just found something out. Tensorflow apparently does work when importing it in the console like this:\r\n```\r\nPS C:\\Users\\user> py\r\nPython 3.6.2 (v3.6.2:5fd33b5, Jul  8 2017, 04:57:36) [MSC v.1900 64 bit (AMD64)] on win32\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\n>>> print(tf.constant([1, 2, 3, 4]))\r\n2019-12-02 14:39:53.575123: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\ntf.Tensor([1 2 3 4], shape=(4,), dtype=int32)\r\n>>>\r\n```\r\n\r\nBut it doesn't work when executing a file like this:\r\n`py folder/code.py`\r\n\r\nThen I get this error:\r\n\r\n> Traceback (most recent call last):\r\n>   File \"code.py\", line 1, in <module>\r\n>     import tensorflow as tf\r\n>   File \"D:\\documenten\\programs\\Python\\3.6.2\\lib\\site-packages\\tensorflow\\__init__.py\", line 98, in <module>\r\n>     from tensorflow_core import *\r\n>   File \"D:\\documenten\\programs\\Python\\3.6.2\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 40, in <module>\r\n>     from tensorflow.python.tools import module_util as _module_util\r\n> ModuleNotFoundError: No module named 'tensorflow.python.tools'; 'tensorflow.python' is not a package", "@R0b4 ,\r\ncan you please make sure that both `python` and `tensorflow` are installed in the same path where you are trying to execute `py folder/code.py` ?Thanks! ", "@R0b4,\r\nI had the same problem when I unimaginatively named file for the tutorial I was following ``csv.py``.\r\n\r\nIt broke the execution of another tutorial ``example.py`` in the same directory with described symptomes.\r\n\r\nAfter renaming ``csv.py`` problem resolved.", "Apparently alexander was right. The problem was the name, so this begs the question why can't i name my script \"code.py\"?", "@R0b4 Both ``csv.py`` and ``code.py`` clash with modules from python standard library.\r\nPlacing them in the working directory messes ``tensorflow`` import.", "@R0b4 ,\r\nIs the solution provided by @alexander-travov  resolves the issue ?Please close the issue if it is works fine.Thanks!", "faced the same problem, changed filename from code.py ... Solved the problem!", "> @R0b4 Both `csv.py` and `code.py` clash with modules from python standard library.\r\n> Placing them in the working directory messes `tensorflow` import.\r\n\r\n\u5de8\u611f\u8c22\uff0c\u76ee\u5f55\u6709\u4e2acsv.py\u6539\u540d\u540e\uff0c\u6211\u53c8\u53ef\u4ee5\u6109\u5feb\u7684\u73a9\u800d\u4e86", "I can confirm issue with import statements. Just installed tensorflow on the clean system using pip (Python 3.7.0), this installs tensorflow 2.0.\r\n\r\nWhen I try to execute my code I get\r\n\r\n```\r\nModuleNotFoundError: No module named 'tensorflow.python.tools'; 'tensorflow.python' is not a package\r\n```\r\n\r\nLooking in the site-packages, it seems directory layout in tensorflow 2.0 was changed and now there is no `tensorflow.python` but there is `tensorflow_core.python`. And this is the reason for this import error.", "There is supposed to be mapping between `tensorflow.python` and `tensorflow_core.python` to make thie layout change transparent.\r\n\r\nI implemented that, so I'll try to see why it doesn't work, if I can reproduce.", "I have the same problem and by adding some prints and breakpoints observe that _LazyLoader for `tensorflow.python` kicks in and starts executing `tensorflow_core/python/__init__.py` it gets to the following line:\r\n```\r\nfrom tensorflow.python import keras\r\n```\r\nWhich throws `AttributeError(\"type object 'scipy.interpolate.interpnd.array' has no attribute '__reduce_cython__'\")` But this exception is not preserved or logged and instead we see `ModuleNotFoundError: No module named 'tensorflow.python.tools'; 'tensorflow.python' is not a package`.\r\n\r\nI see two problems here:\r\n\r\n * _LazyLoader does not handle import errors properly. They need to be delivered to the CLI. We need to see original error.\r\n * Something wrong with `scipy`. May be a version mismatch.\r\n", "In my case the problem was solved by `sudo apt install --reinstall python*-decorator`. It was induced by a corrupted scipy. But this does not cancel the fact that tensorflow does not report an underlying error properly.\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34722\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34722\">No</a>\n", "I do not think that the problem has been resolved. The error reporting is still broken and investigation of a simple problem has cost me hours of my life.", "Reopened to have TF work on better error messages. But the root cause is not a TF failure.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "> @R0b4 ,\r\n> can you please make sure that both `python` and `tensorflow` are installed in the same path where you are trying to execute `py folder/code.py` ?Thanks!\r\n\r\ni can't believe that filename is the problem :laughing: \r\nbut it was !!!", "You may have different paths for your python package. One from AppData/Local/Programs and the other is from AppData/Roaming. Removing the python package in AppData/Roaming solves my problem.", "> @R0b4 Both `csv.py` and `code.py` clash with modules from python standard library.\r\n> Placing them in the working directory messes `tensorflow` import.\r\n\r\nThanks a bunch! Though in my case, it was Google Colab that allowed me to download \"csv.py\" from their example library and thus cause this unnecessary mess.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34722\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34722\">No</a>\n", "I had the same issue but soon resolved it.\r\nI have realized that the problem existed because I have a file named imp.py in the same directory where I have my main.py (where I have imported keras module).\r\nI have renamed my imp.py to impxyz.py and the problem disappeared.", "Definitely, the error is due to the usage of a file name that is already used in tensorflow. Just change your file names.\r\nI had a similar error since I had used a file names signal.py that numpy also uses.", "Hey all, \r\nI just had a similar issue due to completely different causes - mainly versioning and pip binary aliases - so I figured I'll share what worked for me :\r\n\r\n```bash\r\npython3 --version\r\npython3 -m pip install --upgrade pip\r\npython3 -m pip install tensorflow\r\n```\r\nOn my system `python3` links to version `3.6.9`, just be sure to have a compatible one.\r\n\r\nCheers :+1: ", "Still having this issue. None of my files are named something generic that could conflict (unless lr_finder.py??). ", "@bhavints I prefer change all your files name and see if you get some result.", "As mentioned above, renaming my files worked for me. I had a file named 'cmd.py' that caused the issue.", "> @R0b4,\r\n> I had the same problem when I unimaginatively named file for the tutorial I was following `csv.py`.\r\n> \r\n> It broke the execution of another tutorial `example.py` in the same directory with described symptomes.\r\n> \r\n> After renaming `csv.py` problem resolved.\r\n\r\nYes! Thanks. renaming the file solved the problem"]}, {"number": 34721, "title": "Missing information: embedding_lookup automatically returns 0 for an out-of-vocab index", "body": "Greetings,\r\n\r\nI expected embedding layer gives an error when a word id is beyond the fixed pre-determined vocab size. Nonetheless, it is not the case as tf.nn.embedding_lookup automatically return 0 for an out-of-vocab index. While this is nice, it is risky because there is no information or anything like that from the website https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding. I personally did not know that until digging to the code carefully.\r\n\r\nSo I think more information at the website should be updated.\r\n\r\nExample code to see how embedding_lookup returns output:\r\n\r\n>>> sess = tf.compat.v1.InteractiveSession()\r\n>>> params = tf.constant([10,20,30,40])\r\n>>> ids = tf.constant([0,1,2,3,4,5])\r\n>>> tf.nn.embedding_lookup(params,ids).eval()\r\narray([10, 20, 30, 40,  0,  0], dtype=int32)", "comments": ["Thanks @hoangcuong2011 . Since you recently investigated, would you be able to make a pull request to update the docstring or add a snippet? That file should be here: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/layers/embeddings.py#L35\r\nTo add a testable docstring, please see this guide: https://www.tensorflow.org/community/contribute/docs_ref", "Hi @hoangcuong2011, is this request still relevant? If so are you interested in submitting a PR?", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 34720, "title": "Bug in person_detection tf-lite example ", "body": "tf==1.15\r\nI just follow the step in [person_detection example](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/experimental/micro/examples/person_detection/training_a_model.md), after i get `vww_96_grayscale_frozen.pb`, when i want to generate `vww_96_grayscale_quantized.tflite`, I get a error `ValueError: Cannot set tensor: Dimension mismatch`, can you see it  @dansitu \r\n\r\n```\r\nTraceback (most recent call last):                                                                    \r\n  File \"get_tflite.py\", line 32, in <module>                                                          \r\n    tflite_quant_model = converter.convert()                                                          \r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/lite.py\", line 993, in conv\r\nert                                                                                                   \r\n    inference_output_type)                                                                            \r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/lite.py\", line 239, in _cal\r\nibrate_quantize_model                                                                                 \r\n    inference_output_type, allow_float)                                                               \r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/optimize/calibrator.py\", li\r\nne 75, in calibrate_and_quantize                                                                      \r\n    self._calibrator.FeedTensor(calibration_sample)                                                   \r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/optimize/tensorflow_lite_wr\r\nap_calibration_wrapper.py\", line 112, in FeedTensor                                                   \r\n    return _tensorflow_lite_wrap_calibration_wrapper.CalibrationWrapper_FeedTensor(self, input_value) \r\nValueError: Cannot set tensor: Dimension mismatch\r\n```", "comments": ["@MeghnaNatraj, can you take a look?", "I'm currently looking into this issue and I'll post an update soon.\r\n", "I was able to reproduce the issue. The reason that you're currently facing this issue is because of a [pending PR](https://github.com/tensorflow/models/pull/7609/commits) to merge the greyscale changes. As a result of this, the current code does not utilize the `--input_greyscale` flag and the model only accepts RGB/color images. To verify this, you can visualize the `vww_96_grayscale_frozen.pb1` file by uploading it to [netron](https://lutzroeder.github.io/netron/) to see the dimensions of the input which is: (batch=?, height=96, width=96, num_channels=3)\r\n\r\n_Note: Netron is a useful tool for visualizing many other model formats as well, source: [https://github.com/lutzroeder/netron](https://github.com/lutzroeder/netron)_\r\n\r\nUntil the PR is merged, with a temporary fix, you can train a person_detection model that accepts color images by making two updates while converting the `vww_96_grayscale_frozen.pb` file to `vww_96_grayscale_quantized.tflite` as follows: (the 2 updates are mentioned in comments below)\r\n\r\n```\r\nimport tensorflow as tf\r\nimport io\r\nimport PIL\r\nimport numpy as np\r\n\r\ndef representative_dataset_gen():\r\n    record_iterator = tf.python_io.tf_record_iterator(path='coco/processed/val.record-00000-of-00010')\r\n    count = 0\r\n    for string_record in record_iterator:\r\n        example = tf.train.Example()\r\n        example.ParseFromString(string_record)\r\n        image_stream = io.BytesIO(example.features.feature['image/encoded'].bytes_list.value[0])\r\n        image = PIL.Image.open(image_stream)\r\n        image = image.resize((96, 96))\r\n        image = image.convert('RGB') # Update 1: Replace'L' with 'RGB' \r\n        array = np.array(image)\r\n        # array = np.expand_dims(array, axis=2) # Update 2: Comment this line as with RGB, an extra dimension is \r\n                                                # already present to represent the num_channels with value=3\r\n        array = np.expand_dims(array, axis=0)\r\n        array = ((array / 127.5) - 1.0).astype(np.float32)\r\n        yield([array])\r\n        count += 1\r\n        if count > 300:\r\n            break\r\n\r\nconverter = tf.lite.TFLiteConverter.from_frozen_graph('vww_96_grayscale_frozen.pb',\r\n['input'], ['MobilenetV1/Predictions/Reshape_1'])\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nconverter.representative_dataset = representative_dataset_gen\r\n\r\ntflite_quant_model = converter.convert()\r\nopen(\"vww_96_grayscale_quantized.tflite\", \"wb\").write(tflite_quant_model)\r\n```\r\n\r\nThe size of this model is ~260KB and not <250KB as mentioned in the tutorial as this model accepts color images. Let us know if this works for you, and we'll post an update once we get the greyscale version checked in as well.", "@MeghnaNatraj Thanks for your Detailed explanation\uff0c i will try after the pr merged;\r\nNow my compromise solution is:\r\n```\r\ndelete the line # image = image.convert('L')\r\nand # array = np.expand_dims(array, axis=2)\r\n```", "Sorry for the problems! I looked into the PR, and we did merge the changes through a separate mechanism, though the flag is now called `use_grayscale` instead of `input_grayscale`:\r\nhttps://github.com/tensorflow/models/blob/master/research/slim/eval_image_classifier.py#L133\r\n\r\nDoes specifying that help?", "Closing the issue as it is resolved.  Either a user can update the training instructions by replacing `use_grayscale` with `input_grayscale` OR the user can update the inference instructions by the solution posted earlier in this page. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34720\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34720\">No</a>\n"]}, {"number": 34719, "title": "Docker build for TensorFlow GPU taking too long(Up 45 hours!) ", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.3 LTS\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): Docker image (tensorflow/tensorflow:devel-gpu-py3)\r\n- TensorFlow version: 2.0\r\n- Python version: 3\r\n- Installed using virtualenv? pip? conda?: Docker \r\n- Bazel version (if compiling from source): default for docker image\r\n- GCC/Compiler version (if compiling from source): default for docker image\r\n- CUDA/cuDNN version: 10.0\r\n- GPU model and memory: GT 750m\r\n- CPU: Intel\u00ae Core\u2122 i7-4500U CPU @ 1.80GHz \u00d7 4 \r\n\r\n\r\n**Describe the problem**\r\nI'm trying to build TensorFlow for my GPU with CUDA compute capability 3.0. The build seems to take forever to complete.\r\nI'm following these guides:\r\n[Build from source using Docker](https://www.tensorflow.org/install/source#gpu_support_3)\r\n[Setup Docker for TensorFlow ](https://www.tensorflow.org/install/docker)\r\n\r\nI can't figure out if I did something wrong.\r\n\r\n\r\n**Provide the exact sequence of commands/steps that you executed before running into the problem**\r\n\r\nFollowing Docker commands were used to run the container:\r\n```\r\ndocker pull tensorflow/tensorflow:devel-gpu-py3\r\ndocker run --gpus all -it -w /tensorflow -v $PWD:/mnt -e HOST_PERMS=\"$(id -u):$(id -g)\" tensorflow/tensorflow:devel-gpu-py3 bash\r\n```\r\n\r\nThen navigating to `tensorflow_src`,  `./configure` the command was run setting all values to defaults and \"No\" to all features(CUDA and CUdnn were automatically detected)\r\n\r\nFinally, the following command was run to start the build process:\r\n```\r\nbazel build --config=v2 --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\r\n```\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nCurrently, the container has been up for 45 hours!. It doesn't seem like it is coming to end anytime soon. At the time of writing Bazel build is on action 29,910/29,333.\r\n```\r\nCONTAINER ID        IMAGE                                 COMMAND             CREATED             STATUS              PORTS               NAMES\r\n9bcd8e96c6ce        tensorflow/tensorflow:devel-gpu-py3   \"bash\"              45 hours ago        Up 45 hours                             cool_spence\r\n```\r\n", "comments": ["use the update and the upgrade and then run the code in the docker cloud.", "@TeammakS Thanks for the response I'll try it out.\r\nA few more questions: \r\n1. During the configuration procedure, I am not prompted to specify a list of CUDA compute capabilities or if I want TensorRT or not like many tutorials point out. All these seem to be automatically set.\r\nopening up `.tf_configure.bazelrc ` I see `TF_CUDA_COMPUTE_CAPABILITIES=\"3.5,5.2,6.0,6.1,7.0` and `--config=tensorrt` already set.\r\n\r\n2. Any idea how I can install the resulting wheel file into a conda environment? Can't seem to get gpu up and running.(Installed `conda install -c anaconda cudnn` and \r\n`conda install -c anaconda cudatoolkit=10.0`)   ", "Following is the log when I try to execute `tf.test.is_gpu_available()`:\r\n```\r\nWARNING:tensorflow:From <stdin>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.config.experimental.list_physical_devices('GPU')` instead.\r\n2019-12-01 21:56:33.548107: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\r\n2019-12-01 21:56:33.682574: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-12-01 21:56:33.684118: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1546] Found device 0 with properties: \r\nname: GeForce GT 750M major: 3 minor: 0 memoryClockRate(GHz): 0.967\r\npciBusID: 0000:04:00.0\r\n2019-12-01 21:56:33.684692: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory\r\n2019-12-01 21:56:33.684925: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10.0'; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory\r\n2019-12-01 21:56:33.685130: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10.0'; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory\r\n2019-12-01 21:56:33.685326: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10.0'; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory\r\n2019-12-01 21:56:33.685525: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10.0'; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory\r\n2019-12-01 21:56:33.685724: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory\r\n2019-12-01 21:56:33.685966: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory\r\n2019-12-01 21:56:33.686020: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1569] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\r\nSkipping registering GPU devices...\r\n2019-12-01 21:56:33.779228: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1087] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-12-01 21:56:33.779302: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1093]      0 \r\n2019-12-01 21:56:33.779333: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1106] 0:   N \r\nFalse\r\n```", "@RafayAK, Follow the instructions mentioned [here](https://www.tensorflow.org/install/gpu#ubuntu_1804_cuda_10) to install CUDA and cuDNN.\r\nGPU support Tensorflow uses nvidia-docker. Please install nvidia-docker and try again. Thanks!", "@gadagashwini did follow that. Unfortunately, some of the instructions do not apply to legacy hardware. Nvidia Docker is installed. Secondly, can you help answer the following questions?\r\n\r\n> @TeammakS Thanks for the response I'll try it out.\r\n> A few more questions:\r\n> \r\n> 1. During the configuration procedure, I am not prompted to specify a list of CUDA compute capabilities or if I want TensorRT or not like many tutorials point out. All these seem to be automatically set.\r\n>    opening up `.tf_configure.bazelrc ` I see `TF_CUDA_COMPUTE_CAPABILITIES=\"3.5,5.2,6.0,6.1,7.0` and `--config=tensorrt` already set.\r\n> 2. Any idea how I can install the resulting wheel file into a conda environment? Can't seem to get gpu up and running.(Installed `conda install -c anaconda cudnn` and\r\n>    `conda install -c anaconda cudatoolkit=10.0`)\r\n\r\n", "@RafayAK, Could you include ./configure output here. ", "This is how I set up my config file:\r\n```\r\nroot@ba5c2e5a2d2b:/tensorflow_src# ./configure \r\nExtracting Bazel installation...\r\nWARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command \"bazel shutdown\".\r\nYou have bazel 0.26.1 installed.\r\nPlease specify the location of python. [Default is /usr/local/bin/python]: \r\n\r\n\r\nFound possible Python library paths:\r\n  /usr/local/lib/python3.6/dist-packages\r\n  /usr/lib/python3/dist-packages\r\nPlease input the desired Python library path to use.  Default is [/usr/local/lib/python3.6/dist-packages]\r\n\r\nDo you wish to build TensorFlow with XLA JIT support? [Y/n]: n\r\nNo XLA JIT support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with OpenCL SYCL support? [y/N]: N\r\nNo OpenCL SYCL support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with ROCm support? [y/N]: N\r\nNo ROCm support will be enabled for TensorFlow.\r\n\r\nFound CUDA 10.0 in:\r\n    /usr/local/cuda-10.0/lib64\r\n    /usr/local/cuda-10.0/include\r\nFound cuDNN 7 in:\r\n    /usr/lib/x86_64-linux-gnu\r\n    /usr/include\r\nFound TensorRT 5 in:\r\n    /usr/lib/x86_64-linux-gnu\r\n    /usr/include/x86_64-linux-gnu\r\n\r\n\r\nDo you want to use clang as CUDA compiler? [y/N]: N\r\nnvcc will be used as CUDA compiler.\r\n\r\nPlease specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: \r\n\r\n\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native -Wno-sign-compare]: \r\n\r\n\r\nWould you like to interactively configure ./WORKSPACE for Android builds? [y/N]: N\r\nNot configuring the WORKSPACE for Android builds.\r\n\r\nPreconfigured Bazel build configs. You can use any of the below by adding \"--config=<>\" to your build command. See .bazelrc for more details.\r\n\t--config=mkl         \t# Build with MKL support.\r\n\t--config=monolithic  \t# Config for mostly static monolithic build.\r\n\t--config=ngraph      \t# Build with Intel nGraph support.\r\n\t--config=numa        \t# Build with NUMA support.\r\n\t--config=dynamic_kernels\t# (Experimental) Build kernels into separate shared objects.\r\n\t--config=v2          \t# Build TensorFlow 2.x instead of 1.x.\r\nPreconfigured Bazel build configs to DISABLE default on features:\r\n\t--config=noaws       \t# Disable AWS S3 filesystem support.\r\n\t--config=nogcp       \t# Disable GCP support.\r\n\t--config=nohdfs      \t# Disable HDFS support.\r\n\t--config=nonccl      \t# Disable NVIDIA NCCL support.\r\nConfiguration finished\r\n\r\n```\r\n", "Also here is the build configuration, as set in the `.tf_configure.bazelrc` (notice how `build:xla` is set to true, even after its 'No' in the `.configure` file)\r\n\r\n```\r\nbuild --action_env PYTHON_BIN_PATH=\"/usr/local/bin/python\"\r\nbuild --action_env PYTHON_LIB_PATH=\"/usr/local/lib/python3.6/dist-packages\"\r\nbuild --python_path=\"/usr/local/bin/python\"\r\nbuild:xla --define with_xla_support=true\r\nbuild --config=tensorrt\r\nbuild --action_env TF_CUDA_VERSION=\"10.0\"\r\nbuild --action_env TF_CUDNN_VERSION=\"7\"\r\nbuild --action_env CUDA_TOOLKIT_PATH=\"/usr/local/cuda-10.0\"\r\nbuild --action_env TF_CUDA_COMPUTE_CAPABILITIES=\"3.5,5.2,6.0,6.1,7.0\"\r\nbuild --action_env LD_LIBRARY_PATH=\"/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\"\r\nbuild --action_env GCC_HOST_COMPILER_PATH=\"/usr/bin/gcc\"\r\nbuild --config=cuda\r\nbuild:opt --copt=-march=native\r\nbuild:opt --copt=-Wno-sign-compare\r\nbuild:opt --host_copt=-march=native\r\nbuild:opt --define with_default_optimizations=true\r\ntest --flaky_test_attempts=3\r\ntest --test_size_filters=small,medium\r\ntest --test_tag_filters=-benchmark-test,-no_oss,-oss_serial\r\ntest --build_tag_filters=-benchmark-test,-no_oss\r\ntest --test_tag_filters=-no_gpu\r\ntest --build_tag_filters=-no_gpu\r\ntest --test_env=LD_LIBRARY_PATH\r\nbuild --action_env TF_CONFIGURE_IOS=\"0\"\r\n``` \r\n", "Added the .configue output, 8 days ago", "Looks like the tensorflow/tensorflow:devel-gpu-py3 image is stale and is no longer being updated.\r\n( last update > 2 month ago )", "@suphoff any idea what I should do then?", "@RafayAK : I would just use \"tensorflow/tensorflow:devel-gpu\" and add python3 + (required python packages) as this is a lot easier then gathering the cuda requirements. Additionally I would open a new issue about the missing updates of  the \"tensorflow/tensorflow:devel-gpu-py3\" image.", "@RafayAK : FYI: Docker files for creating your own images are now in tensorflow/tools/dockerfiles/dockerfiles", "@suphoff Thanks! I'll check it out", "I think that we could track this in https://github.com/tensorflow/build/issues/5", "@RafayAK,\r\n\r\nWe are checking to see if you still need help on this issue. We recommend that you upgrade to `2.6` which is latest stable version of TF and let us know if the issue still persists in newer versions. \r\n\r\nYou can use this [guide](https://www.tensorflow.org/install/docker) for your reference.Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34719\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34719\">No</a>\n"]}, {"number": 34718, "title": "explicit GPU device placement failed due to runtime error \"unknown CPU\"", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04 LTS\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): tf2.0\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: 10\r\n- GPU model and memory: NV V100 32GB\r\n\r\n**Describe the current behavior**\r\nThe graphic memory of the specified GPU has been allocated, but a runtime error occurred, saying `RuntimeError: /job:localhost/replica:0/task:0/device:CPU:1 unknown device.`\r\n**Describe the expected behavior**\r\nSuccessfully deploy the model to the specified GPU\r\n**Code to reproduce the issue**\r\n```python\r\nwith tf.device('GPU:1'):\r\n    mobile_net_local_path = \"/mobilenet\" # the local model is the same as the one on https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4, which is runnable on GPU:0\r\n    mobile_net = hub.KerasLayer(mobile_net_local_path,output_shape = [1280] , trainable=True)\r\n```\r\n\r\n**Other info / logs**\r\nThe logical devices(given by `tf.config.experimental.list_logical_devices()`) are below:\r\n```python\r\n[LogicalDevice(name='/job:localhost/replica:0/task:0/device:CPU:0', device_type='CPU'),\r\n LogicalDevice(name='/job:localhost/replica:0/task:0/device:XLA_CPU:0', device_type='XLA_CPU'),\r\n LogicalDevice(name='/job:localhost/replica:0/task:0/device:GPU:0', device_type='GPU'),\r\n LogicalDevice(name='/job:localhost/replica:0/task:0/device:GPU:1', device_type='GPU'),\r\n LogicalDevice(name='/job:localhost/replica:0/task:0/device:GPU:2', device_type='GPU'),\r\n LogicalDevice(name='/job:localhost/replica:0/task:0/device:GPU:3', device_type='GPU'),\r\n LogicalDevice(name='/job:localhost/replica:0/task:0/device:GPU:4', device_type='GPU'),\r\n LogicalDevice(name='/job:localhost/replica:0/task:0/device:XLA_GPU:0', device_type='XLA_GPU'),\r\n LogicalDevice(name='/job:localhost/replica:0/task:0/device:XLA_GPU:1', device_type='XLA_GPU'),\r\n LogicalDevice(name='/job:localhost/replica:0/task:0/device:XLA_GPU:2', device_type='XLA_GPU'),\r\n LogicalDevice(name='/job:localhost/replica:0/task:0/device:XLA_GPU:3', device_type='XLA_GPU'),\r\n LogicalDevice(name='/job:localhost/replica:0/task:0/device:XLA_GPU:4', device_type='XLA_GPU')]\r\n```\r\nand physical devices are below:\r\n```python\r\n[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\r\n PhysicalDevice(name='/physical_device:XLA_CPU:0', device_type='XLA_CPU'),\r\n PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\r\n PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'),\r\n PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'),\r\n PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU'),\r\n PhysicalDevice(name='/physical_device:GPU:4', device_type='GPU'),\r\n PhysicalDevice(name='/physical_device:XLA_GPU:0', device_type='XLA_GPU'),\r\n PhysicalDevice(name='/physical_device:XLA_GPU:1', device_type='XLA_GPU'),\r\n PhysicalDevice(name='/physical_device:XLA_GPU:2', device_type='XLA_GPU'),\r\n PhysicalDevice(name='/physical_device:XLA_GPU:3', device_type='XLA_GPU'),\r\n PhysicalDevice(name='/physical_device:XLA_GPU:4', device_type='XLA_GPU')]\r\n```\r\n\r\nthe error is \r\n```\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-4-f31b7e9deb50> in <module>\r\n      3 with tf.device('GPU:1'):\r\n      4     mobile_net_local_path = \"HandGestureRecognizer/tf2models/mobilenet\"\r\n----> 5     mobile_net = hub.KerasLayer(mobile_net_local_path,output_shape = [1280] , trainable=True)\r\n\r\n~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_hub/keras_layer.py in __init__(self, handle, trainable, arguments, **kwargs)\r\n    102       self._func = handle\r\n    103     else:\r\n--> 104       self._func = module_v2.load(handle)\r\n    105       if not callable(self._func):\r\n    106         raise ValueError(\"Non-callable result from hub.load('%s')\" %\r\n\r\n~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_hub/module_v2.py in load(handle, tags)\r\n     75   if hasattr(tf_v1.saved_model, \"load_v2\"):\r\n     76     module_handle = resolve(handle)\r\n---> 77     return tf_v1.saved_model.load_v2(module_handle, tags=tags)\r\n     78   else:\r\n     79     raise NotImplementedError(\"hub.load() is not implemented for TF < 1.14.x, \"\r\n\r\n~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/saved_model/load.py in load(export_dir, tags)\r\n    515     ValueError: If `tags` don't match a MetaGraph in the SavedModel.\r\n    516   \"\"\"\r\n--> 517   return load_internal(export_dir, tags)\r\n    518 \r\n    519 \r\n\r\n~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/saved_model/load.py in load_internal(export_dir, tags, loader_cls)\r\n    539       loader = loader_cls(object_graph_proto,\r\n    540                           saved_model_proto,\r\n--> 541                           export_dir)\r\n    542       root = loader.get(0)\r\n    543     root.tensorflow_version = meta_graph_def.meta_info_def.tensorflow_version\r\n\r\n~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/saved_model/load.py in __init__(self, object_graph_proto, saved_model_proto, export_dir)\r\n    126     self._setup_functions_structures()\r\n    127     self._setup_functions_captures()\r\n--> 128     self._restore_checkpoint()\r\n    129 \r\n    130     for node in self._nodes:\r\n\r\n~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/saved_model/load.py in _restore_checkpoint(self)\r\n    277     saver = util.TrackableSaver(graph_view.ObjectGraphView(self.get(0)))\r\n    278     with ops.device(\"CPU\"):\r\n--> 279       saver._file_prefix_placeholder = constant_op.constant(variables_path)\r\n    280     load_status = saver.restore(variables_path)\r\n    281     load_status.assert_existing_objects_matched()\r\n\r\n~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py in constant(value, dtype, shape, name)\r\n    225   \"\"\"\r\n    226   return _constant_impl(value, dtype, shape, name, verify_shape=False,\r\n--> 227                         allow_broadcast=True)\r\n    228 \r\n    229 \r\n\r\n~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py in _constant_impl(value, dtype, shape, name, verify_shape, allow_broadcast)\r\n    233   ctx = context.context()\r\n    234   if ctx.executing_eagerly():\r\n--> 235     t = convert_to_eager_tensor(value, ctx, dtype)\r\n    236     if shape is None:\r\n    237       return t\r\n\r\n~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py in convert_to_eager_tensor(value, ctx, dtype)\r\n     94       dtype = dtypes.as_dtype(dtype).as_datatype_enum\r\n     95   ctx.ensure_initialized()\r\n---> 96   return ops.EagerTensor(value, ctx.device_name, dtype)\r\n     97 \r\n     98 \r\n\r\nRuntimeError: /job:localhost/replica:0/task:0/device:CPU:1 unknown device.\r\n```\r\nAfter executing the python codes above, it can be seen in `nvidia-smi` that the graphic memory of the specified GPU (GPU:1) has been allocated.\r\n```\r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID   Type   Process name                             Usage      |\r\n|=============================================================================|\r\n|    0     12253      C   ...user/anaconda3/envs/tf2/bin/python   307MiB |\r\n|    0     20120      C   python3                                     2617MiB |\r\n|    0     27393      C   python3                                     1701MiB |\r\n|    0     68670      C   python3                                      941MiB |\r\n|    0     73404      C   python3                                     1209MiB |\r\n|    1     12253      C   ...user/anaconda3/envs/tf2/bin/python 31009MiB |\r\n|    2     12253      C   ...user/anaconda3/envs/tf2/bin/python   307MiB |\r\n|    3     12253      C   ...user/anaconda3/envs/tf2/bin/python   307MiB |\r\n|    4     12253      C   ...user/anaconda3/envs/tf2/bin/python   307MiB |\r\n+-----------------------------------------------------------------------------+\r\n```\r\n", "comments": ["Dis you use `pip install tensorflow-gpu==2.0 or `pip install tensorflow == 2.0 ` If you have installed tensorflow using the later command, this might cause this error.", "> Dis you use `pip install tensorflow-gpu==2.0 or `pip install tensorflow == 2.0 ` If you have installed tensorflow using the later command, this might cause this error.\r\n\r\nI didn't. I just used conda to install tensorflow-gpu.", "@tomhennigan I noticed you added the explicit `with ops.device(\"CPU\")` in `_restore_checkpoint` (internal CL 244133653).  Do you think we need to have a more specific `CPU:0` device setting?", "Sorry I didn't notice this bug. CPU:0 sounds fine, although I can't reproduce this in a colab. The following snippet prints `CPU:0`:\r\n\r\n```python\r\nwith tf.device(\"/device:TPU:1\"):\r\n  with tf.device(\"CPU\"):\r\n    print(tf.ones([]).device)\r\n```", "@ifsheldon It looks like you are using an older Version of Tensorflow 2.0. Many bugs have been fixed in the latest version. Could you please execute your code using Latest Version 2.5 and let us know if the issue still persists? Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34718\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34718\">No</a>\n"]}, {"number": 34717, "title": "How to boost speed for cpu in TF2?", "body": "I am running a program based on tensorflow2.0 and do not use GPU, i use the 'top' command, i found the CPU's usage is strange:\r\n%Cpu0  : 21.0 us,  1.0 sy,  0.0 ni, 78.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st\r\n%Cpu1  : 15.7 us,  0.0 sy,  0.0 ni, 84.3 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st\r\n%Cpu2  : 13.8 us,  1.3 sy,  0.0 ni, 84.8 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st\r\n%Cpu3  : 15.2 us,  1.3 sy,  0.0 ni, 83.4 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st\r\n%Cpu4  : 18.1 us,  1.3 sy,  0.0 ni, 80.6 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st\r\n%Cpu5  : 14.9 us,  1.4 sy,  0.0 ni, 83.8 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st\r\n%Cpu6  :  3.7 us,  1.3 sy,  0.0 ni, 95.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st\r\n%Cpu7  :  5.0 us,  0.7 sy,  0.0 ni, 94.4 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st\r\n%Cpu8  :  5.0 us,  0.7 sy,  0.0 ni, 94.3 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st\r\n%Cpu9  :  5.0 us,  1.3 sy,  0.0 ni, 93.7 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st\r\n%Cpu10 :  5.0 us,  1.3 sy,  0.0 ni, 93.7 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st\r\n%Cpu11 :  4.4 us,  1.0 sy,  0.0 ni, 94.6 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st\r\n\r\nIn 12 cores, why just 6 cores are running at high load and 6cores is low high load? How can i boost speed with 12 core at high speed just like blas etc. parallel? Note i run this program in the environment where no other programs affect as i reboot my server.\r\nThanks!", "comments": ["The result of tf.config.threading.get_intra_op_parallelism_threads() is 0, i know this means that tf will pick  an appropriate number, Is there any mechanism to pick the number in TF? If not, is there any guidence for select the number according to the graph and the server condition? I can only trial and error?", "Here is the clear explanation on how the parameters controls the multithreading in Tensorflow. \r\nhttps://stackoverflow.com/questions/41233635/meaning-of-inter-op-parallelism-threads-and-intra-op-parallelism-threads . \r\nPlease, see if it helps you. Thanks!"]}, {"number": 34716, "title": "tf.map_fn does not execute in parallel", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nNo\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nWindows\r\n- TensorFlow installed from (source or binary):\r\nbinary\r\n- TensorFlow version (use command below):\r\n2.0.0\r\n- Python version:\r\n3.7.4\r\n- CUDA/cuDNN version:\r\n10.1/7.6.5\r\n- GPU model and memory:\r\nGTX 1070\r\n\r\n\r\n**Describe the current behavior**\r\nThe [documentation ](https://www.tensorflow.org/api_docs/python/tf/map_fn) for `map_fn` specifies that \r\n\r\n> When executing eagerly, map_fn does not execute in parallel even if parallel_iterations is set to a value > 1. You can still get the performance benefits of running a function in parallel by using the tf.contrib.eager.defun decorator,\r\n\r\nHowever, `tf.contrib.eager.defun` no longer is available in TensorFlow 2.0. Hence, `map_fn` would only run on a single thread. \r\n\r\nHow can I parallelize `map_fn ` in TensorFlow 2.0?\r\n", "comments": ["@haideraltahan \r\n\r\nCan you please go through the [link ](https://stackoverflow.com/questions/52774351/how-to-run-parallel-map-fn-when-eager-execution-enabled)and see if it helps you.Thanks!", "```python\r\nimport tensorflow as tf\r\nimport time\r\n\r\nx = tf.ones(shape=(100,))\r\ndef op1(i):\r\n    for _ in range(1000):\r\n        i ** 2\r\n    return i\r\n\r\n@tf.function\r\ndef op(i):\r\n    for _ in range(1000):\r\n        i ** 2\r\n    return i\r\na = time.time()\r\n_ = tf.map_fn(op1, x, parallel_iterations=100) # this takes ~15 seconds to compute\r\nprint(f\"Sequential : {time.time() - a}s\")\r\n\r\na = time.time()\r\n_ = tf.map_fn(op, x, parallel_iterations=100) # this takes ~1 second to compute\r\nprint(f\"Parallel : {time.time() - a}s\")\r\n```\r\n\r\n@ravikyram\r\nThis works for Tensorflow 2.0.\r\nInstead of using `tf.contrib.eager.defun`, we need to use `tf.function`\r\n", "Hi @haideraltahan, testing your code I don't see any big difference when I change the number of iterations from 100 to just 1, I guess then that the difference of execution is because of the call to tf.function and not due to parallelism.  \r\nI added a input_signature to tf.function and increased the size of x and the results don't depend on the parameter parallel_iterations.\r\n\r\nHow then can I confirm that multiple threads are being used?\r\n\r\n```python\r\nIn [2]: import tensorflow as tf\r\n   ...: import time\r\n   ...: \r\n   ...: x = tf.ones(shape=(100,))\r\n   ...: def op1(i):\r\n   ...:     for _ in range(1000):\r\n   ...:         i ** 2\r\n   ...:     return i\r\n   ...: \r\n   ...: @tf.function\r\n   ...: def op(i):\r\n   ...:     for _ in range(1000):\r\n   ...:         i ** 2\r\n   ...:     return i\r\n   ...: a = time.time()\r\n   ...: _ = tf.map_fn(op1, x, parallel_iterations=100) # this takes ~15 seconds to compute\r\n   ...: print(f\"Sequential : {time.time() - a}s\")\r\n   ...: \r\n   ...: a = time.time()\r\n   ...: _ = tf.map_fn(op, x, parallel_iterations=100) # this takes ~1 second to compute\r\n   ...: print(f\"Parallel : {time.time() - a}s\")\r\n\r\nSequential : 3.5768771171569824s\r\nParallel : 1.2645704746246338s\r\n\r\nIn [3]: \r\n\r\nIn [3]: import tensorflow as tf\r\n   ...: import time\r\n   ...: \r\n   ...: x = tf.ones(shape=(100,))\r\n   ...: def op1(i):\r\n   ...:     for _ in range(1000):\r\n   ...:         i ** 2\r\n   ...:     return i\r\n   ...: \r\n   ...: @tf.function\r\n   ...: def op(i):\r\n   ...:     for _ in range(1000):\r\n   ...:         i ** 2\r\n   ...:     return i\r\n   ...: a = time.time()\r\n   ...: _ = tf.map_fn(op1, x, parallel_iterations=10) # this takes ~15 seconds to compute\r\n   ...: print(f\"Sequential : {time.time() - a}s\")\r\n   ...: \r\n   ...: a = time.time()\r\n   ...: _ = tf.map_fn(op, x, parallel_iterations=10) # this takes ~1 second to compute\r\n   ...: print(f\"Parallel : {time.time() - a}s\")\r\n\r\nSequential : 3.592731237411499s\r\nParallel : 1.1762580871582031s\r\n\r\nIn [4]: \r\n\r\nIn [4]: import tensorflow as tf\r\n   ...: import time\r\n   ...: \r\n   ...: x = tf.ones(shape=(100,))\r\n   ...: def op1(i):\r\n   ...:     for _ in range(1000):\r\n   ...:         i ** 2\r\n   ...:     return i\r\n   ...: \r\n   ...: @tf.function\r\n   ...: def op(i):\r\n   ...:     for _ in range(1000):\r\n   ...:         i ** 2\r\n   ...:     return i\r\n   ...: a = time.time()\r\n   ...: _ = tf.map_fn(op1, x, parallel_iterations=1) # this takes ~15 seconds to compute\r\n   ...: print(f\"Sequential : {time.time() - a}s\")\r\n   ...: \r\n   ...: a = time.time()\r\n   ...: _ = tf.map_fn(op, x, parallel_iterations=1) # this takes ~1 second to compute\r\n   ...: print(f\"Parallel : {time.time() - a}s\")\r\nSequential : 3.608123302459717s\r\nParallel : 1.2272813320159912s\r\n```"]}, {"number": 34714, "title": "TensorFlow 1.15.0 fails to build .so files in contrib ", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS Catalina, Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 1.15\r\n- Python version: 3\r\n- Installed using virtualenv? pip? conda?: conda\r\n- Bazel version (if compiling from source): 0.26.1\r\n- GCC/Compiler version (if compiling from source): \r\nmacOS: Apple clang version 11.0.0 (clang-1100.0.33.12)\r\nUbuntu 18.04: 7.x\r\nUbuntu 16.04: 5.x\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\nOnly the machine with Ubuntu 16.04 has Tesla and CUDA\r\n\r\n**Describe the problem**\r\nI am trying to generate two `.so` files from contrib in TensorFlow `1.15.0`. I understand this version comes without contrib, so when it's installed via `pip` or `conda` I cannot find my two `.so` files like previous versions (1.12.0, 1.13.1): `_lstm_ops.so` and `_sparse_feature_cross_op.so`. However, if I build from the source of TF 1.15.0 in Ubuntu 16.04 I can see these two files for Linux. Since I need these two for macOS as well I tried to build from the source on my macOS. \r\n\r\nThe build goes until the end without any problem, however, I cannot find these two `.so` files on my macOS. I have tried to replicate the same thing on Ubuntu 18.04, but I cannot find the `.so` files there neither. It seems the only place I can build from the source and get my `.so` files is in Ubuntu 16.04. \r\n\r\nHow is it possible that Ubuntu 16.04 can build TF 1.15 from source and produce those two `.so` files, but it fails in macOS Catalina and Ubuntu 18.04? Is it because these two are newer systems? Is there a requirement for contrib to be a lower version?\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n- git clone TensorFlow\r\n- git checkout r1.15\r\n- ./configure (no gpu or anything extra - no to all questions)\r\n- bazel build for java\r\n\r\nThe mentioned steps will produce the `.so` files I required in Ubuntu 16.04 but fail to do so in macOS (Catalina) nor in Ubuntu 18.04. \r\n\r\nThe command to build from source for Java:\r\n```bash\r\nbazel build //tensorflow/java:tensorflow //tensorflow/java:libtensorflow_jni\r\n```\r\n\r\n**Any other info / logs**\r\nNo, there is no error in any of the builds (Java, Python) in any of the three OS.", "comments": ["I appreciate your help @angerson! Please let me know if you need more info or any test you need me to do.", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34714\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34714\">No</a>\n"]}, {"number": 34713, "title": "Keras multi-output has array-like behaviour despite using dictionaries in output of dataset!", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nYes, I've tweaked some example code from the docs. See below.\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nUbuntu 16.04\r\n- TensorFlow installed from (source or binary):\r\npip install --user tensorflow\r\n- TensorFlow version (use command below):\r\n('v2.0.0-rc2-26-g64c3d38', '2.0.0')\r\n- Python version:\r\n2.7\r\n\r\n**Describe the current behavior**\r\nIf you set up a multi-output model with a loss attached to a single output, keras appears to create a loss for other heads anyhow, depending on the ordering of the outputs in the list argument. I believe that keras is utilizing some list-like behaviour where it shouldn't. Please see the example code and traceback below. \r\n**Describe the expected behavior**\r\nIn principle, the code should do as the [docs](https://www.tensorflow.org/guide/keras/train_and_evaluate#passing_data_to_multi-input_multi-output_models) appear to indicate and do things in a dictionary-based manner, not an array-based manner. For example, see the warning in the traceback: it indicates that other outputs besides the one that is tagged with a loss will be ignored, yet this does not appear to happen.\r\n\r\n**Code to reproduce the issue**\r\nI have taken bits of code from the docs linked above and tweaked it to reproduce the bug: \r\n\r\nHere is the tweaked code:\r\n```from tensorflow import keras\r\nimport tensorflow as tf\r\nimport numpy as np\r\nfrom tensorflow.keras import layers\r\n\r\nimage_input = keras.Input(shape=(32, 32, 3), name='img_input')\r\ntimeseries_input = keras.Input(shape=(None, 10), name='ts_input')\r\n\r\nx1 = layers.Conv2D(3, 3)(image_input)\r\nx1pool = layers.GlobalMaxPooling2D()(x1)\r\n\r\nx2 = layers.Conv1D(3, 3)(timeseries_input)\r\nx2pool = layers.GlobalMaxPooling1D(name='x2pool')(x2)\r\n\r\nx = layers.concatenate([x1pool, x2pool])\r\n\r\n# score_output = layers.Dense(1, name='score_output')(x)\r\nclass_output = layers.Dense(5, activation='softmax', name='class_output')(x)\r\n\r\n# original outputs from docs example code\r\n# outputs = [class_output, score_output]\r\n\r\n# the commented one works (only by coincidence!), but the uncommented one doesnt\r\n# outputs = [class_output, x2pool]\r\noutputs = [x2pool, class_output]\r\n\r\nmodel = keras.Model(inputs=[image_input, timeseries_input],\r\n                    outputs=outputs)\r\n\r\nmodel.compile(\r\n    optimizer=keras.optimizers.Adam(),\r\n    loss={'class_output': keras.losses.CategoricalCrossentropy()})\r\n\r\n\r\nimg_data = np.random.random_sample(size=(100, 32, 32, 3))\r\nts_data = np.random.random_sample(size=(100, 20, 10))\r\nscore_targets = np.random.random_sample(size=(100, 1))\r\nclass_targets = np.random.random_sample(size=(100, 5))\r\n\r\n\r\n# we supply the targets for the loss that we tagged to the class_output head.\r\ntrain_dataset = tf.data.Dataset.from_tensor_slices(\r\n    ({'img_input': img_data, 'ts_input': ts_data},\r\n     {'class_output': class_targets}))\r\ntrain_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\r\n\r\nmodel.fit(train_dataset, epochs=3)\r\n```\r\n\r\n**Other info / logs**\r\nHere's the traceback below. Notice it indicates that it will ignore x2pool in the warning, which is the behaviour that I want...but then it appears to have a loss for this at the end of the traceback and also connects the wrong output data to it!:\r\n\r\n```2019-11-29 12:21:14.905823: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2019-11-29 12:21:14.930454: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3792445000 Hz\r\n2019-11-29 12:21:14.931532: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5c00230 executing computations on platform Host. Devices:\r\n2019-11-29 12:21:14.931573: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\r\nWARNING:tensorflow:Output x2pool missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to x2pool.\r\nEpoch 1/3\r\n      1/Unknown - 0s 27ms/stepTraceback (most recent call last):\r\n  File \"tftest.py\", line 48, in <module>\r\n    model.fit(train_dataset, epochs=3)\r\n  File \"/home/ghwatson/.local/lib/python2.7/site-packages/tensorflow_core/python/keras/engine/training.py\", line 728, in fit\r\n    use_multiprocessing=use_multiprocessing)\r\n  File \"/home/ghwatson/.local/lib/python2.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 324, in fit\r\n    total_epochs=epochs)\r\n  File \"/home/ghwatson/.local/lib/python2.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 123, in run_one_epoch\r\n    batch_outs = execution_function(iterator)\r\n  File \"/home/ghwatson/.local/lib/python2.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\", line 86, in execution_function\r\n    distributed_function(input_fn))\r\n  File \"/home/ghwatson/.local/lib/python2.7/site-packages/tensorflow_core/python/eager/def_function.py\", line 457, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"/home/ghwatson/.local/lib/python2.7/site-packages/tensorflow_core/python/eager/def_function.py\", line 503, in _call\r\n    self._initialize(args, kwds, add_initializers_to=initializer_map)\r\n  File \"/home/ghwatson/.local/lib/python2.7/site-packages/tensorflow_core/python/eager/def_function.py\", line 408, in _initialize\r\n    *args, **kwds))\r\n  File \"/home/ghwatson/.local/lib/python2.7/site-packages/tensorflow_core/python/eager/function.py\", line 1848, in _get_concrete_function_internal_garbage_collected\r\n    graph_function, _, _ = self._maybe_define_function(args, kwargs)\r\n  File \"/home/ghwatson/.local/lib/python2.7/site-packages/tensorflow_core/python/eager/function.py\", line 2150, in _maybe_define_function\r\n    graph_function = self._create_graph_function(args, kwargs)\r\n  File \"/home/ghwatson/.local/lib/python2.7/site-packages/tensorflow_core/python/eager/function.py\", line 2041, in _create_graph_function\r\n    capture_by_value=self._capture_by_value),\r\n  File \"/home/ghwatson/.local/lib/python2.7/site-packages/tensorflow_core/python/framework/func_graph.py\", line 915, in func_graph_from_py_func\r\n    func_outputs = python_func(*func_args, **func_kwargs)\r\n  File \"/home/ghwatson/.local/lib/python2.7/site-packages/tensorflow_core/python/eager/def_function.py\", line 358, in wrapped_fn\r\n    return weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n  File \"/home/ghwatson/.local/lib/python2.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\", line 73, in distributed_function\r\n    per_replica_function, args=(model, x, y, sample_weights))\r\n  File \"/home/ghwatson/.local/lib/python2.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py\", line 760, in experimental_run_v2\r\n    return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\r\n  File \"/home/ghwatson/.local/lib/python2.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py\", line 1787, in call_for_each_replica\r\n    return self._call_for_each_replica(fn, args, kwargs)\r\n  File \"/home/ghwatson/.local/lib/python2.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py\", line 2132, in _call_for_each_replica\r\n    return fn(*args, **kwargs)\r\n  File \"/home/ghwatson/.local/lib/python2.7/site-packages/tensorflow_core/python/autograph/impl/api.py\", line 292, in wrapper\r\n    return func(*args, **kwargs)\r\n  File \"/home/ghwatson/.local/lib/python2.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\", line 264, in train_on_batch\r\n    output_loss_metrics=model._output_loss_metrics)\r\n  File \"/home/ghwatson/.local/lib/python2.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py\", line 311, in train_on_batch\r\n    output_loss_metrics=output_loss_metrics))\r\n  File \"/home/ghwatson/.local/lib/python2.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py\", line 252, in _process_single_batch\r\n    training=training))\r\n  File \"/home/ghwatson/.local/lib/python2.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py\", line 166, in _model_loss\r\n    per_sample_losses = loss_fn.call(targets[i], outs[i])\r\n  File \"/home/ghwatson/.local/lib/python2.7/site-packages/tensorflow_core/python/keras/losses.py\", line 221, in call\r\n    return self.fn(y_true, y_pred, **self._fn_kwargs)\r\n  File \"/home/ghwatson/.local/lib/python2.7/site-packages/tensorflow_core/python/keras/losses.py\", line 971, in categorical_crossentropy\r\n    return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits)\r\n  File \"/home/ghwatson/.local/lib/python2.7/site-packages/tensorflow_core/python/keras/backend.py\", line 4468, in categorical_crossentropy\r\n    return -math_ops.reduce_sum(target * math_ops.log(output), axis)\r\n  File \"/home/ghwatson/.local/lib/python2.7/site-packages/tensorflow_core/python/ops/math_ops.py\", line 899, in binary_op_wrapper\r\n    return func(x, y, name=name)\r\n  File \"/home/ghwatson/.local/lib/python2.7/site-packages/tensorflow_core/python/ops/math_ops.py\", line 1206, in _mul_dispatch\r\n    return gen_math_ops.mul(x, y, name=name)\r\n  File \"/home/ghwatson/.local/lib/python2.7/site-packages/tensorflow_core/python/ops/gen_math_ops.py\", line 6701, in mul\r\n    \"Mul\", x=x, y=y, name=name)\r\n  File \"/home/ghwatson/.local/lib/python2.7/site-packages/tensorflow_core/python/framework/op_def_library.py\", line 793, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/home/ghwatson/.local/lib/python2.7/site-packages/tensorflow_core/python/framework/func_graph.py\", line 548, in create_op\r\n    compute_device)\r\n  File \"/home/ghwatson/.local/lib/python2.7/site-packages/tensorflow_core/python/framework/ops.py\", line 3429, in _create_op_internal\r\n    op_def=op_def)\r\n  File \"/home/ghwatson/.local/lib/python2.7/site-packages/tensorflow_core/python/framework/ops.py\", line 1773, in __init__\r\n    control_input_ops)\r\n  File \"/home/ghwatson/.local/lib/python2.7/site-packages/tensorflow_core/python/framework/ops.py\", line 1613, in _create_c_op\r\n    raise ValueError(str(e))\r\nValueError: Dimensions must be equal, but are 5 and 3 for 'loss/x2pool_loss/mul' (op: 'Mul') with input shapes: [?,5], [?,3].\r\n```\r\n", "comments": ["Issue is replicating with Tensorflow 2.0.\r\nPlease see the gist [here](https://colab.sandbox.google.com/gist/gadagashwini/4cf87dc282425b24a19bf1bfeb8d165a/untitled285.ipynb). Thanks!", "@ghwatson This was resolve in recent `tf-nightly`. Please find the [gist](https://colab.research.google.com/gist/jvishnuvardhan/aaf4013171e14b7ed15c4236e2492640/untitled285.ipynb) for your reference.\r\n\r\nI am closing this issue as it was resolved. Please note that Python2 is not supported anymore. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34713\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34713\">No</a>\n"]}, {"number": 34712, "title": "Please fix the example section of tf.constant_initialize", "body": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\nhttps://www.tensorflow.org/api_docs/python/tf/constant_initializer#used_in_the_tutorials\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/api_docs/python/tf/constant_initializer#used_in_the_tutorials\r\n\r\n## Description of issue (what needs changing):\r\nPlease fix the example section of tf.constant_initialize\r\n### Clear description\r\nExamples section of the page is not properly compiled making it unreadable\r\nFor example, why should someone use this method? How is it useful?\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n\r\n### Usage example\r\n\r\nIs there a usage example?\r\n\r\nSee the API guide: https://www.tensorflow.org/community/contribute/docs_ref\r\non how to write testable usage examples.\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs,\r\ndocs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style", "comments": ["I made a pull request can you once check if it is correct or not. In the docs_ref it is given to remove the ``` and put >>> and to keep ... for indentation.\r\n@dynamicwebpaige  can you once check this.", "@jvishnuvardhan Code is  fine in the master branch but, the url at the top of the page which on documentation page which shows the code location on github is pointing to the r2.0 branch which has some error in it.", "what does awaiting tensorflower mean\r\n", "@vinayapathak I think this was resolved. I can see couple of examples, arguments, error raises, `Used in the notebooks` etc.\r\n\r\nThe document page url also referring to correct location.\r\n\r\nI am closing this issue as this was already resolved. Please feel free to reopen I am mistaken. thanks!"]}, {"number": 34711, "title": "Expose parallel_iterations for tf.keras.backend.map_fn.", "body": "This PR exposes the option 'parallel_iterations' for 'map_fn' in 'tf.keras.backend'.\r\n\r\nThis parameter was already exposed in 'keras'.", "comments": []}, {"number": 34710, "title": "Multiple inputs multiple outputs support for tensorflow serving", "body": "Hi I cannot deploy my keras-TF model via tensorflow serving because I have 4 inputs. Is there any chance to do it in other ways?", "comments": ["This issue is more suitable for TensorFlow Serving repo. Please post it on Serving repo from [here.](https://github.com/tensorflow/serving/issues) Thanks!", "It has been 15 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 34709, "title": "allow_growth not working when using estimator and MirroredStrategy distribution", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.3 LTS\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 1.14.0\r\n- Python version: 3.6.8\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10.0.130/7.6.4\r\n- GPU model and memory: 8 * Tesla P40, 22919MiB\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\nWhen I use estimator and distribute.MirroredStrategy, it will allocate all GPU memory, even if I just use one GPU.\r\n\r\n```\r\nimport tensorflow as tf\r\nsession_config = tf.ConfigProto()\r\nsession_config.gpu_options.allow_growth = True\r\nsession_config.allow_soft_placement = True\r\nstrategy = tf.contrib.distribute.MirroredStrategy(num_gpus=num_gpus)\r\nconfig = tf.estimator.RunConfig(session_config=session_config, train_distribute=strategy)\r\nestimator = tf.estimator.Estimator(model_fn, model_dir, config, params)\r\nestimator.train()\r\n```\r\n\r\nIf I set `os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\"`, GPU memory will be correctly allocated. \r\n\r\nI don't know if it's related to `session_config.allow_soft_placement = True`, but if I don't set this value, it will raise error \"cannot assign a device for operation argmax\".\r\n\r\n**Describe the expected behavior**\r\n\r\nMake \"allow_growth\" working when using estimator and MirroredStrategy distribution.\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n```\r\nimport os\r\nimport tensorflow as tf\r\nimport tensorflow.keras.layers as layers\r\nimport numpy as np\r\n\r\n\r\ndef model_fn(features, labels, mode):\r\n  \"\"\"A simple 2-classify model.\r\n  \r\n  \"\"\"\r\n  model = tf.keras.Sequential([layers.Dense(80, activation=\"relu\"), layers.Dense(2)])\r\n  logits = model(features)\r\n  loss = tf.losses.softmax_cross_entropy(labels, logits)\r\n\r\n  if mode == tf.estimator.ModeKeys.TRAIN:\r\n    optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\r\n    train_op = optimizer.minimize(loss, tf.train.get_global_step())\r\n    return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\r\n\r\n\r\ndef input_fn():\r\n  \"\"\"dataset that return feature and label.\r\n\r\n  \"\"\"\r\n  features_mat = np.random.randn(10, 10) \r\n  labels_mat = np.random.randint(0, 2, size=(10, 2)) \r\n  dataset = tf.data.Dataset.from_tensor_slices((features_mat, labels_mat))\r\n  return dataset.batch(1)\r\n\r\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # Set available GPU id. \r\nsession_config = tf.ConfigProto()\r\nsession_config.gpu_options.allow_growth = True\r\n\r\nsession_config.allow_soft_placement = True\r\nstrategy = tf.contrib.distribute.MirroredStrategy(num_gpus=1)\r\nconfig = tf.estimator.RunConfig(session_config=session_config, train_distribute=strategy)\r\n# If disable above 3 lines and using following line, GPU memory allocation will be correct.\r\n#config = tf.estimator.RunConfig(session_config=session_config)\r\n\r\nestimator = tf.estimator.Estimator(model_fn, config=config)\r\n\r\nwhile True:\r\n  estimator.train(input_fn)\r\n```\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34709\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34709\">No</a>\n"]}, {"number": 34708, "title": "Can not convert a TF2 saved model to a TensorRT engine and save it.", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): nightly\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10.0\r\n- GPU model and memory: 2070Ti 8GB\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nI want to convert a TF2 saved model to a TensorRT engine (already built). I following the instruction [here](https://github.com/tensorflow/tensorflow/blob/99cb9fd68d1b8c6f0857c0775c366234537bacf5/tensorflow/python/compiler/tensorrt/trt_convert.py#L823). However, it only gives me errors. I would give my code and log in following part.\r\n\r\nBTW, I installed TensorRT 6.0.1 in my PC.\r\n\r\n\r\n**Describe the expected behavior**\r\n\r\nConvert saved model to a TensorRT engine and save it.\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow.python.compiler.tensorrt import trt_convert as trt\r\n\r\nmodel = tf.keras.applications.MobileNetV2(input_shape=[128, 128, 3], include_top=False)\r\nmodel.save(\"dir1/\")\r\n\r\ninput_saved_model_dir = \"dir1/\"\r\noutput_saved_model_dir = \"dir2/\"\r\n\r\nparams = DEFAULT_TRT_CONVERSION_PARAMS._replace(precision_mode='FP16', maximum_cached_engines=16, is_dynamic_op=True)\r\nconverter = trt.TrtGraphConverterV2(input_saved_model_dir=input_saved_model_dir, conversion_params=params)\r\nconverter.convert()\r\n# converter.save(output_saved_model_dir)\r\n\r\ndef my_input_fn():\r\n    num_runs = 10\r\n    for _ in range(num_runs):\r\n        inp1,inp2 = np.random.random([4, 128, 128, 3]), np.random.random([4, 128, 128, 1])\r\n        yield inp1,inp2\r\n        \r\nconverter.build(input_fn=my_input_fn)  # Generate corresponding TRT engines\r\nconverter.save(output_saved_model_dir)  # Generated engines will be saved.\r\n```\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n```bash\r\nWARNING:tensorflow:From /home/shl666/anaconda3/envs/tf-nightly/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1788: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nIf using Keras pass *_constraint arguments to layers.\r\n\r\n[11/29/2019 21:46:27 WARNING] From /home/shl666/anaconda3/envs/tf-nightly/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1788: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nIf using Keras pass *_constraint arguments to layers.\r\n\r\nINFO:tensorflow:Assets written to: inference/sample/saved_model/assets\r\n\r\n[11/29/2019 21:46:28 INFO] Assets written to: inference/sample/saved_model/assets\r\n\r\nINFO:tensorflow:Linked TensorRT version: (6, 0, 1)\r\nINFO:tensorflow:Loaded TensorRT version: (6, 0, 1)\r\n\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-5-9b2262c7c046> in <module>\r\n     14         yield inp1, inp2\r\n     15 \r\n---> 16 converter.build(input_fn=my_input_fn)  # Generate corresponding TRT engines\r\n     17 converter.save(output_saved_model_dir)  # Generated engines will be saved.\r\n\r\n~/anaconda3/envs/tf-nightly/lib/python3.7/site-packages/tensorflow_core/python/compiler/tensorrt/trt_convert.py in build(self, input_fn)\r\n   1049     \"\"\"\r\n   1050     for inp in input_fn():\r\n-> 1051       self._converted_func(*map(ops.convert_to_tensor, inp))\r\n   1052 \r\n   1053   def save(self, output_saved_model_dir):\r\n\r\n~/anaconda3/envs/tf-nightly/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in __call__(self, *args, **kwargs)\r\n   1549       TypeError: For invalid positional/keyword argument combinations.\r\n   1550     \"\"\"\r\n-> 1551     return self._call_impl(args, kwargs)\r\n   1552 \r\n   1553   def _call_impl(self, args, kwargs, cancellation_manager=None):\r\n\r\n~/anaconda3/envs/tf-nightly/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in _call_impl(self, args, kwargs, cancellation_manager)\r\n   1568            \"of {}), got {}. When calling a concrete function, positional \"\r\n   1569            \"arguments may not be bound to Tensors within nested structures.\"\r\n-> 1570           ).format(self._num_positional_args, self._arg_keywords, args))\r\n   1571     args = list(args)\r\n   1572     for keyword in self._arg_keywords[len(args):]:\r\n\r\nTypeError: Expected at most 1 positional arguments (and the rest keywords, of ['input_3']), got (<tf.Tensor: shape=(4, 128, 128, 3), dtype=float64, numpy=\r\narray([[[[0.37694877, 0.14433618, 0.15041287],\r\n         [0.28948027, 0.52537459, 0.51882755],\r\n         [0.48836555, 0.45480828, 0.0779434 ],\r\n....\r\n....\r\n....\r\n        [0.02064168, 0.76855384, 0.64690949],\r\n         [0.98667418, 0.9156569 , 0.58136711],\r\n         [0.84539588, 0.7338271 , 0.15894349]],\r\n\r\n        [[0.03578103, 0.24472914, 0.62393987],\r\n         [0.51681037, 0.75395885, 0.83268599],\r\n         [0.81616645, 0.4863684 , 0.25114351],\r\n         ...,\r\n         [0.08293289, 0.90668744, 0.94976784],\r\n         [0.39264721, 0.33914333, 0.58584557],\r\n         [0.57539905, 0.29829974, 0.33732885]]]])>, <tf.Tensor: shape=(4, 128, 128, 1), dtype=float64, numpy=\r\narray([[[[0.55649055],\r\n         [0.97303716],\r\n         [0.90465544],\r\n         ...,\r\n         [0.76755675],\r\n         [0.07142947],\r\n         [0.80021061]],\r\n....\r\n....\r\n....\r\n        [[0.88080569],\r\n         [0.53601004],\r\n         [0.69139559],\r\n         ...,\r\n         [0.89977499],\r\n         [0.73776336],\r\n         [0.65023825]]]])>). When calling a concrete function, positional arguments may not be bound to Tensors within nested structures.\r\n\r\n\r\n```\r\n", "comments": ["Hi @pooyadavoodi this seems to be similar to the issue you described before, did you get that resolved?", "For my example, I think the workaround was to append a comma to the yield statement: `yield inp1,inp2,` in the input function.\r\n\r\n@roborocklsm could you try this.\r\n", "Are you sure your model has two placeholder inputs? I think input_fn is expecting a list/tuple of input data with same length as the number of inputs in the model. In your case:\r\n\r\n```\r\ndef my_input_fn():\r\n    num_runs = 10\r\n    for _ in range(num_runs):\r\n        inp = np.random.random([4, 128, 128, 3])\r\n        yield [inp]\r\n```\r\n\r\nthis will ensure that an engine with batch_size=4 is created and cached, according to the documentation.\r\n", "@hardsetting this solved my similar issue with the converter.build(input_fn=my_input_fn). Thank you ", "may I know any progress on this issue? or any commit already fix this problem?\r\nI try to convert my resnet model, it shows this error. \r\nis these ops still not support by tensorrRT 6 or even tensorrRT 7?\r\n```\r\nThere are 10 ops of 7 different types in the graph that are not converted to TensorRT: Identity, Placeholder, NoOp, Pack, Shape, StridedSlice, Reshape, (For more information see https://docs.nvidia.com/deeplearning/frameworks/tf-trt-user-guide/index.html#supported-ops).\r\n```", "Hi @luvwinnie, do you have a repro for your case? Could you enable vlog for this [line](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/tf2tensorrt/segment/segment.cc#L439) to see why those ops are not accepted?", "@aaroey thank you for reply, sorry for not familiar with vlog, does it means by settings the following to print out?\r\n\r\n```\r\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '0' \r\nos.environ['TF_CPP_MIN_VLOG_LEVEL'] = '0' \r\n```\r\nEven i set with these environment variables, the convertion show is at following.\r\nI used tensorflow 2.1 built from source with TensorRT 7 CUDA10.1, cuDNN 7.6.5, or even with normal tensorflow installation with pip which built with tensorRT 6. Both environments show the same log results.\r\n```\r\n2020-04-21 13:29:14.883005: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14303 MB memory) -> physical GPU (device: 0, name: TITAN RTX, pci bus id: 0000:17:00.0, compute capability: 7.5)\r\n2020-04-21 13:29:14.884302: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 22587 MB memory) -> physical GPU (device: 1, name: TITAN RTX, pci bus id: 0000:65:00.0, compute capability: 7.5)\r\n2020-04-21 13:29:37.182215: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:460] There are 10 ops of 7 different types in the graph that are not converted to TensorRT: Identity, Placeholder, NoOp, Pack, Shape, StridedSlice, Reshape, (For more information see https://docs.nvidia.com/deeplearning/frameworks/tf-trt-user-guide/index.html#supported-ops).\r\n2020-04-21 13:29:37.197544: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:636] Number of TensorRT candidate segments: 1\r\n2020-04-21 13:29:38.667799: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:737] Replaced segment 0 consisting of 266 nodes by TRTEngineOp_0.\r\n```", "@luvwinnie could you try setting TF_CPP_VMODULE=segment=1", "@aaroey Thank you for replying. The below is the logs with VLOG.\r\n\r\n```\r\n2020-04-21 14:45:35.078737: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:439] Not a TF-TRT candidate, (Op type: NoOp), (Op name: _SOURCE), (Reason: Unimplemented: Op type NoOp is not supported.)\r\n2020-04-21 14:45:35.078792: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:439] Not a TF-TRT candidate, (Op type: NoOp), (Op name: _SINK), (Reason: Unimplemented: Op type NoOp is not supported.)\r\n2020-04-21 14:45:35.078799: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:429] Not a TF-TRT candidate, (Op type: Placeholder), (Op name: input_1), (Reason: excluded by segmenter option)\r\n2020-04-21 14:45:35.779594: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:439] Not a TF-TRT candidate, (Op type: NoOp), (Op name: Func/StatefulPartitionedCall/input_control_node/_0), (Reason: Unimplemented: Op type NoOp is not supported.)\r\n2020-04-21 14:45:36.472911: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:439] Not a TF-TRT candidate, (Op type: NoOp), (Op name: Func/StatefulPartitionedCall/output_control_node/_155), (Reason: Unimplemented: Op type NoOp is not supported.)\r\n2020-04-21 14:45:37.159434: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:439] Not a TF-TRT candidate, (Op type: Shape), (Op name: StatefulPartitionedCall/model_1/reshape/Shape), (Reason: Unimplemented: Op type Shape is not supported.)\r\n2020-04-21 14:45:37.159509: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:439] Not a TF-TRT candidate, (Op type: StridedSlice), (Op name: StatefulPartitionedCall/model_1/reshape/strided_slice), (Reason: Unimplemented: TensorRT does not allow modifications to the batch dimension, at StatefulPartitionedCall/model_1/reshape/strided_slice)\r\n2020-04-21 14:45:37.159520: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:439] Not a TF-TRT candidate, (Op type: Pack), (Op name: StatefulPartitionedCall/model_1/reshape/Reshape/shape), (Reason: Internal: Failed to convert input StatefulPartitionedCall/model_1/reshape/strided_slice to a TRT_TensorOrWeights: Scalar input tensor is not supported since the first dimension is treated as batch dimension by TRT)\r\n2020-04-21 14:45:37.159530: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:439] Not a TF-TRT candidate, (Op type: Reshape), (Op name: StatefulPartitionedCall/model_1/reshape/Reshape), (Reason: Unimplemented: The input \"shape\" for Reshape must be a constant, at StatefulPartitionedCall/model_1/reshape/Reshape)\r\n2020-04-21 14:45:37.159541: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:429] Not a TF-TRT candidate, (Op type: Identity), (Op name: Identity), (Reason: excluded by segmenter option)\r\n2020-04-21 14:45:37.159548: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:460] There are 10 ops of 7 different types in the graph that are not converted to TensorRT: Identity, Placeholder, NoOp, Pack, Shape, StridedSlice, Reshape, (For more information see https://docs.nvidia.com/deeplearning/frameworks/tf-trt-user-guide/index.html#supported-ops).\r\n2020-04-21 14:45:37.173607: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 2\r\n2020-04-21 14:45:37.173636: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 2\r\n2020-04-21 14:45:37.173641: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 266\r\n2020-04-21 14:45:37.173739: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 266\r\n2020-04-21 14:45:37.173745: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.173751: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 0\r\n2020-04-21 14:45:37.173755: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.173759: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 0\r\n2020-04-21 14:45:37.173763: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.173767: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 0\r\n2020-04-21 14:45:37.173770: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.173774: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 0\r\n2020-04-21 14:45:37.173788: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.173793: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 0\r\n2020-04-21 14:45:37.173796: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.173801: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.173804: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.173808: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.173811: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.173815: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.173818: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.173822: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.173825: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.173829: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.173832: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.173836: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.173839: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.173843: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.173846: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.173850: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.173854: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.173857: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.173860: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.173864: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.173867: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.173871: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.173874: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.173878: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.173881: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.173885: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.173888: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.173891: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.173895: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.173898: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.173902: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.173905: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.173909: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.173913: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.173916: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.173921: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.173924: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.173928: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.173931: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.173935: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.173938: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.173942: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.173945: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.173949: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.173952: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.173956: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.173959: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.173962: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.173966: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.173970: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.173973: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.173976: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.173980: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.173983: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.173986: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.173990: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.173993: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.173997: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174000: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174004: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174007: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174010: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174014: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174018: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174021: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174025: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174028: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174031: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174035: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174038: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174041: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174045: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174048: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174053: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174057: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174060: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174064: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174067: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174071: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174074: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174078: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174081: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174084: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174088: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174091: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174095: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174098: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174102: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174105: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174108: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174112: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174115: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174119: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174123: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174126: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174129: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174133: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174136: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174140: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174143: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174147: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174150: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174153: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174157: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174160: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174164: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174167: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174170: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174174: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174178: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174181: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174186: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174189: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174193: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174196: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174199: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174203: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174206: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174210: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174213: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174216: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174220: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174223: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174227: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174230: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174234: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174237: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174241: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174244: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174247: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174251: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174254: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174257: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174261: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174264: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174268: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174271: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174275: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174278: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174282: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174285: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174288: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174292: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174295: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174299: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174302: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174305: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174309: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174312: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174317: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174321: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174324: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174327: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174331: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174334: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174338: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174341: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174345: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174348: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174351: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174355: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174358: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174362: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174365: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174369: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174372: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174375: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174379: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174382: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174385: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174389: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174392: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174396: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174399: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174403: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174406: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174409: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174413: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174416: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174419: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174423: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174426: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174429: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174433: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174436: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174440: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174445: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174448: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174452: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174455: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174459: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174462: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174465: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174469: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174472: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174475: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174479: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174482: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174486: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174489: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174492: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174496: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174500: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174503: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174506: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174510: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174513: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174517: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174520: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174523: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174527: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174530: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174534: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174537: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174540: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174544: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174547: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174550: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174554: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174557: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174561: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174565: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174568: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174571: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174576: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174580: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174583: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174587: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174590: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174594: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174597: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174600: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174604: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174607: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174610: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174614: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174617: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174621: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174624: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174627: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174631: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174634: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174637: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174641: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174644: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174648: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174651: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174655: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174658: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174661: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174665: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174668: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174672: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174675: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174678: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174682: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174685: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174689: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174692: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174695: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174699: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174702: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174707: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174711: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174714: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174717: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174721: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174724: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174727: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174731: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174734: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174738: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174741: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174744: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174748: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174751: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174755: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174758: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174761: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174765: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174768: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174772: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174775: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174778: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174782: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174785: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174788: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174792: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174795: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174799: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174802: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174805: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174809: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174812: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174815: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174819: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174822: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174825: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174829: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174832: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174837: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174841: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174844: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:587] Segment original size: 1\r\n2020-04-21 14:45:37.174848: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:666] Segment new size: 1\r\n2020-04-21 14:45:37.174854: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 0 with parent=StatefulPartitionedCall/Identity:\r\n[Op type: Identity] Func/StatefulPartitionedCall/output/_154\r\n[Op type: Identity] StatefulPartitionedCall/Identity\r\n2020-04-21 14:45:37.174865: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 0 has only 0 effective nodes, dropping\r\n2020-04-21 14:45:37.174949: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 0 with parent=StatefulPartitionedCall/model_1/add_9/add-0-0-PermConstNCHWToNHWC-LayoutOptimizer:\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_16/FusedBatchNormV3/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_16/FusedBatchNormV3/ReadVariableOp_1\r\n[Op type: Const] StatefulPartitionedCall/model_1/res4a_branch2b/Conv2D/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/res4a_branch2b/BiasAdd/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_18/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_18/ReadVariableOp_1\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_18/FusedBatchNormV3/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_18/FusedBatchNormV3/ReadVariableOp_1\r\n[Op type: Const] StatefulPartitionedCall/model_1/res4b_branch2a/Conv2D/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/res4b_branch2a/BiasAdd/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_19/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_19/ReadVariableOp_1\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_19/FusedBatchNormV3/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_19/FusedBatchNormV3/ReadVariableOp_1\r\n[Op type: Const] StatefulPartitionedCall/model_1/res4b_branch2b/Conv2D/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/res4b_branch2b/BiasAdd/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/conv2d_5/Conv2D/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/conv2d_5/BiasAdd/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_22/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_22/ReadVariableOp_1\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_22/FusedBatchNormV3/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_22/FusedBatchNormV3/ReadVariableOp_1\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_20/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_20/ReadVariableOp_1\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_20/FusedBatchNormV3/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_20/FusedBatchNormV3/ReadVariableOp_1\r\n[Op type: Const] StatefulPartitionedCall/model_1/res5a_branch2a/Conv2D/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/res5a_branch2a/BiasAdd/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_21/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_21/ReadVariableOp_1\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_21/FusedBatchNormV3/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_21/FusedBatchNormV3/ReadVariableOp_1\r\n[Op type: Const] StatefulPartitionedCall/model_1/res5a_branch2b/Conv2D/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/res5a_branch2b/BiasAdd/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_23/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_23/ReadVariableOp_1\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_23/FusedBatchNormV3/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_23/FusedBatchNormV3/ReadVariableOp_1\r\n[Op type: Identity] Func/StatefulPartitionedCall/input/_1\r\n[Op type: Const] StatefulPartitionedCall/model_1/conv2d/Conv2D/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/conv2d/BiasAdd/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization/ReadVariableOp_1\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization/FusedBatchNormV3/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization/FusedBatchNormV3/ReadVariableOp_1\r\n[Op type: Const] StatefulPartitionedCall/model_1/conv2d_1/Conv2D/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/conv2d_1/BiasAdd/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_2/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_2/ReadVariableOp_1\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_2/FusedBatchNormV3/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_2/FusedBatchNormV3/ReadVariableOp_1\r\n[Op type: Const] StatefulPartitionedCall/model_1/res1a_branch2a/Conv2D/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/res1a_branch2a/BiasAdd/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_1/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_1/ReadVariableOp_1\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_1/FusedBatchNormV3/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_1/FusedBatchNormV3/ReadVariableOp_1\r\n[Op type: Const] StatefulPartitionedCall/model_1/res1a_branch2b/Conv2D/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/res1a_branch2b/BiasAdd/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_3/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_3/ReadVariableOp_1\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_3/FusedBatchNormV3/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_3/FusedBatchNormV3/ReadVariableOp_1\r\n[Op type: Const] StatefulPartitionedCall/model_1/res1b_branch2a/Conv2D/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/res1b_branch2a/BiasAdd/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_4/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_4/ReadVariableOp_1\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_4/FusedBatchNormV3/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_4/FusedBatchNormV3/ReadVariableOp_1\r\n[Op type: Const] StatefulPartitionedCall/model_1/res1b_branch2b/Conv2D/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/res1b_branch2b/BiasAdd/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/conv2d_2/Conv2D/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/conv2d_2/BiasAdd/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_7/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_7/ReadVariableOp_1\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_7/FusedBatchNormV3/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_7/FusedBatchNormV3/ReadVariableOp_1\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_5/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_5/ReadVariableOp_1\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_5/FusedBatchNormV3/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_5/FusedBatchNormV3/ReadVariableOp_1\r\n[Op type: Const] StatefulPartitionedCall/model_1/res2a_branch2a/Conv2D/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/res2a_branch2a/BiasAdd/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_6/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_6/ReadVariableOp_1\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_6/FusedBatchNormV3/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_6/FusedBatchNormV3/ReadVariableOp_1\r\n[Op type: Const] StatefulPartitionedCall/model_1/res2a_branch2b/Conv2D/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/res2a_branch2b/BiasAdd/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_8/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_8/ReadVariableOp_1\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_8/FusedBatchNormV3/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_8/FusedBatchNormV3/ReadVariableOp_1\r\n[Op type: Const] StatefulPartitionedCall/model_1/res2b_branch2a/Conv2D/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/res2b_branch2a/BiasAdd/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_9/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_9/ReadVariableOp_1\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_9/FusedBatchNormV3/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_9/FusedBatchNormV3/ReadVariableOp_1\r\n[Op type: Const] StatefulPartitionedCall/model_1/res2b_branch2b/Conv2D/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/res2b_branch2b/BiasAdd/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/conv2d_3/Conv2D/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/conv2d_3/BiasAdd/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_12/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_12/ReadVariableOp_1\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_12/FusedBatchNormV3/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_12/FusedBatchNormV3/ReadVariableOp_1\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_10/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/res5b_branch2a/Conv2D/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/res5b_branch2a/BiasAdd/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_24/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_24/ReadVariableOp_1\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_24/FusedBatchNormV3/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_24/FusedBatchNormV3/ReadVariableOp_1\r\n[Op type: Const] StatefulPartitionedCall/model_1/res5b_branch2b/Conv2D/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/res5b_branch2b/BiasAdd/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/conv2d/Conv2D-0-PermConstNHWCToNCHW-LayoutOptimizer\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_10/ReadVariableOp_1\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_10/FusedBatchNormV3/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_10/FusedBatchNormV3/ReadVariableOp_1\r\n[Op type: Const] StatefulPartitionedCall/model_1/res3a_branch2a/Conv2D/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/res3a_branch2a/BiasAdd/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_11/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_11/ReadVariableOp_1\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_11/FusedBatchNormV3/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_11/FusedBatchNormV3/ReadVariableOp_1\r\n[Op type: Const] StatefulPartitionedCall/model_1/res3a_branch2b/Conv2D/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/res3a_branch2b/BiasAdd/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_13/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_13/ReadVariableOp_1\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_13/FusedBatchNormV3/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_13/FusedBatchNormV3/ReadVariableOp_1\r\n[Op type: Const] StatefulPartitionedCall/model_1/res3b_branch2a/Conv2D/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/res3b_branch2a/BiasAdd/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_14/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_14/ReadVariableOp_1\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_14/FusedBatchNormV3/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_14/FusedBatchNormV3/ReadVariableOp_1\r\n[Op type: Const] StatefulPartitionedCall/model_1/res3b_branch2b/Conv2D/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/res3b_branch2b/BiasAdd/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/conv2d_4/Conv2D/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/conv2d_4/BiasAdd/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_17/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_17/ReadVariableOp_1\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_17/FusedBatchNormV3/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_17/FusedBatchNormV3/ReadVariableOp_1\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_15/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_15/ReadVariableOp_1\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_15/FusedBatchNormV3/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_15/FusedBatchNormV3/ReadVariableOp_1\r\n[Op type: Const] StatefulPartitionedCall/model_1/res4a_branch2a/Conv2D/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/res4a_branch2a/BiasAdd/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_16/ReadVariableOp\r\n[Op type: Const] StatefulPartitionedCall/model_1/batch_normalization_16/ReadVariableOp_1\r\n[Op type: Transpose] StatefulPartitionedCall/model_1/conv2d/Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer\r\n[Op type: Conv2D] StatefulPartitionedCall/model_1/conv2d/Conv2D\r\n[Op type: BiasAdd] StatefulPartitionedCall/model_1/conv2d/BiasAdd\r\n[Op type: FusedBatchNormV3] StatefulPartitionedCall/model_1/batch_normalization/FusedBatchNormV3\r\n[Op type: Relu] StatefulPartitionedCall/model_1/re_lu/Relu\r\n[Op type: MaxPool] StatefulPartitionedCall/model_1/max_pooling2d/MaxPool\r\n[Op type: Conv2D] StatefulPartitionedCall/model_1/conv2d_1/Conv2D\r\n[Op type: BiasAdd] StatefulPartitionedCall/model_1/conv2d_1/BiasAdd\r\n[Op type: FusedBatchNormV3] StatefulPartitionedCall/model_1/batch_normalization_2/FusedBatchNormV3\r\n[Op type: Conv2D] StatefulPartitionedCall/model_1/res1a_branch2a/Conv2D\r\n[Op type: BiasAdd] StatefulPartitionedCall/model_1/res1a_branch2a/BiasAdd\r\n[Op type: FusedBatchNormV3] StatefulPartitionedCall/model_1/batch_normalization_1/FusedBatchNormV3\r\n[Op type: Relu] StatefulPartitionedCall/model_1/re_lu_1/Relu\r\n[Op type: Conv2D] StatefulPartitionedCall/model_1/res1a_branch2b/Conv2D\r\n[Op type: BiasAdd] StatefulPartitionedCall/model_1/res1a_branch2b/BiasAdd\r\n[Op type: AddV2] StatefulPartitionedCall/model_1/add/add\r\n[Op type: FusedBatchNormV3] StatefulPartitionedCall/model_1/batch_normalization_3/FusedBatchNormV3\r\n[Op type: Relu] StatefulPartitionedCall/model_1/re_lu_2/Relu\r\n[Op type: Conv2D] StatefulPartitionedCall/model_1/res1b_branch2a/Conv2D\r\n[Op type: BiasAdd] StatefulPartitionedCall/model_1/res1b_branch2a/BiasAdd\r\n[Op type: FusedBatchNormV3] StatefulPartitionedCall/model_1/batch_normalization_4/FusedBatchNormV3\r\n[Op type: Relu] StatefulPartitionedCall/model_1/re_lu_3/Relu\r\n[Op type: Conv2D] StatefulPartitionedCall/model_1/res1b_branch2b/Conv2D\r\n[Op type: BiasAdd] StatefulPartitionedCall/model_1/res1b_branch2b/BiasAdd\r\n[Op type: AddV2] StatefulPartitionedCall/model_1/add_1/add\r\n[Op type: FusedBatchNormV3] StatefulPartitionedCall/model_1/batch_normalization_5/FusedBatchNormV3\r\n[Op type: Relu] StatefulPartitionedCall/model_1/re_lu_4/Relu\r\n[Op type: Conv2D] StatefulPartitionedCall/model_1/res2a_branch2a/Conv2D\r\n[Op type: BiasAdd] StatefulPartitionedCall/model_1/res2a_branch2a/BiasAdd\r\n[Op type: FusedBatchNormV3] StatefulPartitionedCall/model_1/batch_normalization_6/FusedBatchNormV3\r\n[Op type: Relu] StatefulPartitionedCall/model_1/re_lu_5/Relu\r\n[Op type: Conv2D] StatefulPartitionedCall/model_1/res2a_branch2b/Conv2D\r\n[Op type: BiasAdd] StatefulPartitionedCall/model_1/res2a_branch2b/BiasAdd\r\n[Op type: Conv2D] StatefulPartitionedCall/model_1/conv2d_2/Conv2D\r\n[Op type: BiasAdd] StatefulPartitionedCall/model_1/conv2d_2/BiasAdd\r\n[Op type: FusedBatchNormV3] StatefulPartitionedCall/model_1/batch_normalization_7/FusedBatchNormV3\r\n[Op type: AddV2] StatefulPartitionedCall/model_1/add_2/add\r\n[Op type: FusedBatchNormV3] StatefulPartitionedCall/model_1/batch_normalization_8/FusedBatchNormV3\r\n[Op type: Relu] StatefulPartitionedCall/model_1/re_lu_6/Relu\r\n[Op type: Conv2D] StatefulPartitionedCall/model_1/res2b_branch2a/Conv2D\r\n[Op type: BiasAdd] StatefulPartitionedCall/model_1/res2b_branch2a/BiasAdd\r\n[Op type: FusedBatchNormV3] StatefulPartitionedCall/model_1/batch_normalization_9/FusedBatchNormV3\r\n[Op type: Relu] StatefulPartitionedCall/model_1/re_lu_7/Relu\r\n[Op type: Conv2D] StatefulPartitionedCall/model_1/res2b_branch2b/Conv2D\r\n[Op type: BiasAdd] StatefulPartitionedCall/model_1/res2b_branch2b/BiasAdd\r\n[Op type: AddV2] StatefulPartitionedCall/model_1/add_3/add\r\n[Op type: Conv2D] StatefulPartitionedCall/model_1/conv2d_3/Conv2D\r\n[Op type: BiasAdd] StatefulPartitionedCall/model_1/conv2d_3/BiasAdd\r\n[Op type: FusedBatchNormV3] StatefulPartitionedCall/model_1/batch_normalization_12/FusedBatchNormV3\r\n[Op type: FusedBatchNormV3] StatefulPartitionedCall/model_1/batch_normalization_10/FusedBatchNormV3\r\n[Op type: Relu] StatefulPartitionedCall/model_1/re_lu_8/Relu\r\n[Op type: Conv2D] StatefulPartitionedCall/model_1/res3a_branch2a/Conv2D\r\n[Op type: BiasAdd] StatefulPartitionedCall/model_1/res3a_branch2a/BiasAdd\r\n[Op type: FusedBatchNormV3] StatefulPartitionedCall/model_1/batch_normalization_11/FusedBatchNormV3\r\n[Op type: Relu] StatefulPartitionedCall/model_1/re_lu_9/Relu\r\n[Op type: Conv2D] StatefulPartitionedCall/model_1/res3a_branch2b/Conv2D\r\n[Op type: BiasAdd] StatefulPartitionedCall/model_1/res3a_branch2b/BiasAdd\r\n[Op type: AddV2] StatefulPartitionedCall/model_1/add_4/add\r\n[Op type: FusedBatchNormV3] StatefulPartitionedCall/model_1/batch_normalization_13/FusedBatchNormV3\r\n[Op type: Relu] StatefulPartitionedCall/model_1/re_lu_10/Relu\r\n[Op type: Conv2D] StatefulPartitionedCall/model_1/res3b_branch2a/Conv2D\r\n[Op type: BiasAdd] StatefulPartitionedCall/model_1/res3b_branch2a/BiasAdd\r\n[Op type: FusedBatchNormV3] StatefulPartitionedCall/model_1/batch_normalization_14/FusedBatchNormV3\r\n[Op type: Relu] StatefulPartitionedCall/model_1/re_lu_11/Relu\r\n[Op type: Conv2D] StatefulPartitionedCall/model_1/res3b_branch2b/Conv2D\r\n[Op type: BiasAdd] StatefulPartitionedCall/model_1/res3b_branch2b/BiasAdd\r\n[Op type: AddV2] StatefulPartitionedCall/model_1/add_5/add\r\n[Op type: FusedBatchNormV3] StatefulPartitionedCall/model_1/batch_normalization_15/FusedBatchNormV3\r\n[Op type: Relu] StatefulPartitionedCall/model_1/re_lu_12/Relu\r\n[Op type: Conv2D] StatefulPartitionedCall/model_1/res4a_branch2a/Conv2D\r\n[Op type: BiasAdd] StatefulPartitionedCall/model_1/res4a_branch2a/BiasAdd\r\n[Op type: FusedBatchNormV3] StatefulPartitionedCall/model_1/batch_normalization_16/FusedBatchNormV3\r\n[Op type: Relu] StatefulPartitionedCall/model_1/re_lu_13/Relu\r\n[Op type: Conv2D] StatefulPartitionedCall/model_1/res4a_branch2b/Conv2D\r\n[Op type: BiasAdd] StatefulPartitionedCall/model_1/res4a_branch2b/BiasAdd\r\n[Op type: Conv2D] StatefulPartitionedCall/model_1/conv2d_4/Conv2D\r\n[Op type: BiasAdd] StatefulPartitionedCall/model_1/conv2d_4/BiasAdd\r\n[Op type: FusedBatchNormV3] StatefulPartitionedCall/model_1/batch_normalization_17/FusedBatchNormV3\r\n[Op type: AddV2] StatefulPartitionedCall/model_1/add_6/add\r\n[Op type: FusedBatchNormV3] StatefulPartitionedCall/model_1/batch_normalization_18/FusedBatchNormV3\r\n[Op type: Relu] StatefulPartitionedCall/model_1/re_lu_14/Relu\r\n[Op type: Conv2D] StatefulPartitionedCall/model_1/res4b_branch2a/Conv2D\r\n[Op type: BiasAdd] StatefulPartitionedCall/model_1/res4b_branch2a/BiasAdd\r\n[Op type: FusedBatchNormV3] StatefulPartitionedCall/model_1/batch_normalization_19/FusedBatchNormV3\r\n[Op type: Relu] StatefulPartitionedCall/model_1/re_lu_15/Relu\r\n[Op type: Conv2D] StatefulPartitionedCall/model_1/res4b_branch2b/Conv2D\r\n[Op type: BiasAdd] StatefulPartitionedCall/model_1/res4b_branch2b/BiasAdd\r\n[Op type: AddV2] StatefulPartitionedCall/model_1/add_7/add\r\n[Op type: FusedBatchNormV3] StatefulPartitionedCall/model_1/batch_normalization_20/FusedBatchNormV3\r\n[Op type: Relu] StatefulPartitionedCall/model_1/re_lu_16/Relu\r\n[Op type: Conv2D] StatefulPartitionedCall/model_1/res5a_branch2a/Conv2D\r\n[Op type: BiasAdd] StatefulPartitionedCall/model_1/res5a_branch2a/BiasAdd\r\n[Op type: FusedBatchNormV3] StatefulPartitionedCall/model_1/batch_normalization_21/FusedBatchNormV3\r\n[Op type: Relu] StatefulPartitionedCall/model_1/re_lu_17/Relu\r\n[Op type: Conv2D] StatefulPartitionedCall/model_1/res5a_branch2b/Conv2D\r\n[Op type: BiasAdd] StatefulPartitionedCall/model_1/res5a_branch2b/BiasAdd\r\n[Op type: Conv2D] StatefulPartitionedCall/model_1/conv2d_5/Conv2D\r\n[Op type: BiasAdd] StatefulPartitionedCall/model_1/conv2d_5/BiasAdd\r\n[Op type: FusedBatchNormV3] StatefulPartitionedCall/model_1/batch_normalization_22/FusedBatchNormV3\r\n[Op type: AddV2] StatefulPartitionedCall/model_1/add_8/add\r\n[Op type: FusedBatchNormV3] StatefulPartitionedCall/model_1/batch_normalization_23/FusedBatchNormV3\r\n[Op type: Relu] StatefulPartitionedCall/model_1/re_lu_18/Relu\r\n[Op type: Conv2D] StatefulPartitionedCall/model_1/res5b_branch2a/Conv2D\r\n[Op type: BiasAdd] StatefulPartitionedCall/model_1/res5b_branch2a/BiasAdd\r\n[Op type: FusedBatchNormV3] StatefulPartitionedCall/model_1/batch_normalization_24/FusedBatchNormV3\r\n[Op type: Relu] StatefulPartitionedCall/model_1/re_lu_19/Relu\r\n[Op type: Conv2D] StatefulPartitionedCall/model_1/res5b_branch2b/Conv2D\r\n[Op type: BiasAdd] StatefulPartitionedCall/model_1/res5b_branch2b/BiasAdd\r\n[Op type: AddV2] StatefulPartitionedCall/model_1/add_9/add\r\n[Op type: Const] StatefulPartitionedCall/model_1/add_9/add-0-0-PermConstNCHWToNHWC-LayoutOptimizer\r\n[Op type: Transpose] StatefulPartitionedCall/model_1/add_9/add-0-0-TransposeNCHWToNHWC-LayoutOptimizer\r\n[Op type: Squeeze] StatefulPartitionedCall/model_1/lambda/Squeeze\r\n2020-04-21 14:45:37.174990: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 0 effective nodes, dropping\r\n2020-04-21 14:45:37.174994: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 0 effective nodes, dropping\r\n2020-04-21 14:45:37.174998: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 0 effective nodes, dropping\r\n2020-04-21 14:45:37.175001: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 0 effective nodes, dropping\r\n2020-04-21 14:45:37.175005: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 0 effective nodes, dropping\r\n2020-04-21 14:45:37.175009: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown:\r\n[Op type: Const] unknown\r\n2020-04-21 14:45:37.175014: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175018: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_0:\r\n[Op type: Const] unknown_0\r\n2020-04-21 14:45:37.175021: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175025: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_1:\r\n[Op type: Const] unknown_1\r\n2020-04-21 14:45:37.175028: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175032: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_10:\r\n[Op type: Const] unknown_10\r\n2020-04-21 14:45:37.175036: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175040: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_100:\r\n[Op type: Const] unknown_100\r\n2020-04-21 14:45:37.175043: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175047: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_101:\r\n[Op type: Const] unknown_101\r\n2020-04-21 14:45:37.175051: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175054: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_102:\r\n[Op type: Const] unknown_102\r\n2020-04-21 14:45:37.175058: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175062: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_103:\r\n[Op type: Const] unknown_103\r\n2020-04-21 14:45:37.175065: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175069: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_104:\r\n[Op type: Const] unknown_104\r\n2020-04-21 14:45:37.175072: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175076: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_105:\r\n[Op type: Const] unknown_105\r\n2020-04-21 14:45:37.175080: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175083: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_106:\r\n[Op type: Const] unknown_106\r\n2020-04-21 14:45:37.175087: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175091: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_107:\r\n[Op type: Const] unknown_107\r\n2020-04-21 14:45:37.175094: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175098: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_108:\r\n[Op type: Const] unknown_108\r\n2020-04-21 14:45:37.175101: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175105: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_109:\r\n[Op type: Const] unknown_109\r\n2020-04-21 14:45:37.175109: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175112: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_11:\r\n[Op type: Const] unknown_11\r\n2020-04-21 14:45:37.175116: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175121: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_110:\r\n[Op type: Const] unknown_110\r\n2020-04-21 14:45:37.175125: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175129: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_111:\r\n[Op type: Const] unknown_111\r\n2020-04-21 14:45:37.175132: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175136: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_112:\r\n[Op type: Const] unknown_112\r\n2020-04-21 14:45:37.175139: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175143: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_113:\r\n[Op type: Const] unknown_113\r\n2020-04-21 14:45:37.175146: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175150: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_114:\r\n[Op type: Const] unknown_114\r\n2020-04-21 14:45:37.175154: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175157: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_115:\r\n[Op type: Const] unknown_115\r\n2020-04-21 14:45:37.175161: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175165: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_116:\r\n[Op type: Const] unknown_116\r\n2020-04-21 14:45:37.175168: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175172: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_117:\r\n[Op type: Const] unknown_117\r\n2020-04-21 14:45:37.175175: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175179: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_118:\r\n[Op type: Const] unknown_118\r\n2020-04-21 14:45:37.175183: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175186: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_119:\r\n[Op type: Const] unknown_119\r\n2020-04-21 14:45:37.175190: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175194: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_12:\r\n[Op type: Const] unknown_12\r\n2020-04-21 14:45:37.175197: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175201: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_120:\r\n[Op type: Const] unknown_120\r\n2020-04-21 14:45:37.175204: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175208: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_121:\r\n[Op type: Const] unknown_121\r\n2020-04-21 14:45:37.175212: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175215: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_122:\r\n[Op type: Const] unknown_122\r\n2020-04-21 14:45:37.175219: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175224: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_123:\r\n[Op type: Const] unknown_123\r\n2020-04-21 14:45:37.175228: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175232: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_124:\r\n[Op type: Const] unknown_124\r\n2020-04-21 14:45:37.175235: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175239: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_125:\r\n[Op type: Const] unknown_125\r\n2020-04-21 14:45:37.175242: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175246: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_126:\r\n[Op type: Const] unknown_126\r\n2020-04-21 14:45:37.175249: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175253: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_127:\r\n[Op type: Const] unknown_127\r\n2020-04-21 14:45:37.175257: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175261: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_128:\r\n[Op type: Const] unknown_128\r\n2020-04-21 14:45:37.175265: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175268: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_129:\r\n[Op type: Const] unknown_129\r\n2020-04-21 14:45:37.175272: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175275: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_13:\r\n[Op type: Const] unknown_13\r\n2020-04-21 14:45:37.175279: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175283: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_130:\r\n[Op type: Const] unknown_130\r\n2020-04-21 14:45:37.175286: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175290: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_131:\r\n[Op type: Const] unknown_131\r\n2020-04-21 14:45:37.175293: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175297: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_132:\r\n[Op type: Const] unknown_132\r\n2020-04-21 14:45:37.175301: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175305: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_133:\r\n[Op type: Const] unknown_133\r\n2020-04-21 14:45:37.175308: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175312: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_134:\r\n[Op type: Const] unknown_134\r\n2020-04-21 14:45:37.175315: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175319: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_135:\r\n[Op type: Const] unknown_135\r\n2020-04-21 14:45:37.175322: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175328: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_136:\r\n[Op type: Const] unknown_136\r\n2020-04-21 14:45:37.175331: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175335: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_137:\r\n[Op type: Const] unknown_137\r\n2020-04-21 14:45:37.175338: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175342: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_138:\r\n[Op type: Const] unknown_138\r\n2020-04-21 14:45:37.175345: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175349: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_139:\r\n[Op type: Const] unknown_139\r\n2020-04-21 14:45:37.175353: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175356: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_14:\r\n[Op type: Const] unknown_14\r\n2020-04-21 14:45:37.175360: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175364: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_140:\r\n[Op type: Const] unknown_140\r\n2020-04-21 14:45:37.175367: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175371: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_141:\r\n[Op type: Const] unknown_141\r\n2020-04-21 14:45:37.175374: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175378: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_142:\r\n[Op type: Const] unknown_142\r\n2020-04-21 14:45:37.175382: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175385: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_143:\r\n[Op type: Const] unknown_143\r\n2020-04-21 14:45:37.175389: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175393: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_144:\r\n[Op type: Const] unknown_144\r\n2020-04-21 14:45:37.175396: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175400: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_145:\r\n[Op type: Const] unknown_145\r\n2020-04-21 14:45:37.175403: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175407: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_146:\r\n[Op type: Const] unknown_146\r\n2020-04-21 14:45:37.175411: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175414: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_147:\r\n[Op type: Const] unknown_147\r\n2020-04-21 14:45:37.175418: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175422: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_148:\r\n[Op type: Const] unknown_148\r\n2020-04-21 14:45:37.175425: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175430: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_149:\r\n[Op type: Const] unknown_149\r\n2020-04-21 14:45:37.175434: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175438: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_15:\r\n[Op type: Const] unknown_15\r\n2020-04-21 14:45:37.175441: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175445: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_150:\r\n[Op type: Const] unknown_150\r\n2020-04-21 14:45:37.175448: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175452: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_16:\r\n[Op type: Const] unknown_16\r\n2020-04-21 14:45:37.175456: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175459: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_17:\r\n[Op type: Const] unknown_17\r\n2020-04-21 14:45:37.175463: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175467: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_18:\r\n[Op type: Const] unknown_18\r\n2020-04-21 14:45:37.175470: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175474: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_19:\r\n[Op type: Const] unknown_19\r\n2020-04-21 14:45:37.175477: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175481: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_2:\r\n[Op type: Const] unknown_2\r\n2020-04-21 14:45:37.175485: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175488: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_20:\r\n[Op type: Const] unknown_20\r\n2020-04-21 14:45:37.175492: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175495: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_21:\r\n[Op type: Const] unknown_21\r\n2020-04-21 14:45:37.175499: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175503: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_22:\r\n[Op type: Const] unknown_22\r\n2020-04-21 14:45:37.175506: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175510: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_23:\r\n[Op type: Const] unknown_23\r\n2020-04-21 14:45:37.175514: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175518: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_24:\r\n[Op type: Const] unknown_24\r\n2020-04-21 14:45:37.175521: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175525: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_25:\r\n[Op type: Const] unknown_25\r\n2020-04-21 14:45:37.175529: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175534: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_26:\r\n[Op type: Const] unknown_26\r\n2020-04-21 14:45:37.175537: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175541: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_27:\r\n[Op type: Const] unknown_27\r\n2020-04-21 14:45:37.175545: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175548: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_28:\r\n[Op type: Const] unknown_28\r\n2020-04-21 14:45:37.175552: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175556: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_29:\r\n[Op type: Const] unknown_29\r\n2020-04-21 14:45:37.175559: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175563: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_3:\r\n[Op type: Const] unknown_3\r\n2020-04-21 14:45:37.175566: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175570: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_30:\r\n[Op type: Const] unknown_30\r\n2020-04-21 14:45:37.175573: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175577: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_31:\r\n[Op type: Const] unknown_31\r\n2020-04-21 14:45:37.175581: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175584: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_32:\r\n[Op type: Const] unknown_32\r\n2020-04-21 14:45:37.175588: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175591: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_33:\r\n[Op type: Const] unknown_33\r\n2020-04-21 14:45:37.175595: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175599: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_34:\r\n[Op type: Const] unknown_34\r\n2020-04-21 14:45:37.175602: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175606: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_35:\r\n[Op type: Const] unknown_35\r\n2020-04-21 14:45:37.175609: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175613: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_36:\r\n[Op type: Const] unknown_36\r\n2020-04-21 14:45:37.175616: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175620: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_37:\r\n[Op type: Const] unknown_37\r\n2020-04-21 14:45:37.175624: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175627: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_38:\r\n[Op type: Const] unknown_38\r\n2020-04-21 14:45:37.175631: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175636: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_39:\r\n[Op type: Const] unknown_39\r\n2020-04-21 14:45:37.175640: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175643: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_4:\r\n[Op type: Const] unknown_4\r\n2020-04-21 14:45:37.175647: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175650: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_40:\r\n[Op type: Const] unknown_40\r\n2020-04-21 14:45:37.175654: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175658: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_41:\r\n[Op type: Const] unknown_41\r\n2020-04-21 14:45:37.175661: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175665: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_42:\r\n[Op type: Const] unknown_42\r\n2020-04-21 14:45:37.175669: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175672: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_43:\r\n[Op type: Const] unknown_43\r\n2020-04-21 14:45:37.175676: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175680: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_44:\r\n[Op type: Const] unknown_44\r\n2020-04-21 14:45:37.175683: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175687: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_45:\r\n[Op type: Const] unknown_45\r\n2020-04-21 14:45:37.175691: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175694: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_46:\r\n[Op type: Const] unknown_46\r\n2020-04-21 14:45:37.175698: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175702: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_47:\r\n[Op type: Const] unknown_47\r\n2020-04-21 14:45:37.175705: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175709: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_48:\r\n[Op type: Const] unknown_48\r\n2020-04-21 14:45:37.175712: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175716: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_49:\r\n[Op type: Const] unknown_49\r\n2020-04-21 14:45:37.175720: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175723: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_5:\r\n[Op type: Const] unknown_5\r\n2020-04-21 14:45:37.175727: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175731: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_50:\r\n[Op type: Const] unknown_50\r\n2020-04-21 14:45:37.175734: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175738: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_51:\r\n[Op type: Const] unknown_51\r\n2020-04-21 14:45:37.175743: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175747: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_52:\r\n[Op type: Const] unknown_52\r\n2020-04-21 14:45:37.175750: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175754: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_53:\r\n[Op type: Const] unknown_53\r\n2020-04-21 14:45:37.175757: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175761: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_54:\r\n[Op type: Const] unknown_54\r\n2020-04-21 14:45:37.175765: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175768: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_55:\r\n[Op type: Const] unknown_55\r\n2020-04-21 14:45:37.175772: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175776: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_56:\r\n[Op type: Const] unknown_56\r\n2020-04-21 14:45:37.175779: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175783: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_57:\r\n[Op type: Const] unknown_57\r\n2020-04-21 14:45:37.175786: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175790: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_58:\r\n[Op type: Const] unknown_58\r\n2020-04-21 14:45:37.175794: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175797: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_59:\r\n[Op type: Const] unknown_59\r\n2020-04-21 14:45:37.175801: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175805: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_6:\r\n[Op type: Const] unknown_6\r\n2020-04-21 14:45:37.175808: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175812: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_60:\r\n[Op type: Const] unknown_60\r\n2020-04-21 14:45:37.175815: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175819: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_61:\r\n[Op type: Const] unknown_61\r\n2020-04-21 14:45:37.175822: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175826: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_62:\r\n[Op type: Const] unknown_62\r\n2020-04-21 14:45:37.175830: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175834: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_63:\r\n[Op type: Const] unknown_63\r\n2020-04-21 14:45:37.175837: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175841: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_64:\r\n[Op type: Const] unknown_64\r\n2020-04-21 14:45:37.175846: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175850: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_65:\r\n[Op type: Const] unknown_65\r\n2020-04-21 14:45:37.175853: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175857: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_66:\r\n[Op type: Const] unknown_66\r\n2020-04-21 14:45:37.175861: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175864: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_67:\r\n[Op type: Const] unknown_67\r\n2020-04-21 14:45:37.175868: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175872: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_68:\r\n[Op type: Const] unknown_68\r\n2020-04-21 14:45:37.175875: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175879: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_69:\r\n[Op type: Const] unknown_69\r\n2020-04-21 14:45:37.175882: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175886: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_7:\r\n[Op type: Const] unknown_7\r\n2020-04-21 14:45:37.175889: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175893: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_70:\r\n[Op type: Const] unknown_70\r\n2020-04-21 14:45:37.175897: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175900: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_71:\r\n[Op type: Const] unknown_71\r\n2020-04-21 14:45:37.175904: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175908: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_72:\r\n[Op type: Const] unknown_72\r\n2020-04-21 14:45:37.175911: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175915: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_73:\r\n[Op type: Const] unknown_73\r\n2020-04-21 14:45:37.175918: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175922: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_74:\r\n[Op type: Const] unknown_74\r\n2020-04-21 14:45:37.175926: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175929: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_75:\r\n[Op type: Const] unknown_75\r\n2020-04-21 14:45:37.175933: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175937: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_76:\r\n[Op type: Const] unknown_76\r\n2020-04-21 14:45:37.175940: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175944: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_77:\r\n[Op type: Const] unknown_77\r\n2020-04-21 14:45:37.175949: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175953: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_78:\r\n[Op type: Const] unknown_78\r\n2020-04-21 14:45:37.175956: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175960: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_79:\r\n[Op type: Const] unknown_79\r\n2020-04-21 14:45:37.175963: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175967: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_8:\r\n[Op type: Const] unknown_8\r\n2020-04-21 14:45:37.175970: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175974: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_80:\r\n[Op type: Const] unknown_80\r\n2020-04-21 14:45:37.175978: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175982: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_81:\r\n[Op type: Const] unknown_81\r\n2020-04-21 14:45:37.175985: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175989: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_82:\r\n[Op type: Const] unknown_82\r\n2020-04-21 14:45:37.175992: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.175996: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_83:\r\n[Op type: Const] unknown_83\r\n2020-04-21 14:45:37.175999: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.176003: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_84:\r\n[Op type: Const] unknown_84\r\n2020-04-21 14:45:37.176007: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.176010: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_85:\r\n[Op type: Const] unknown_85\r\n2020-04-21 14:45:37.176014: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.176018: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_86:\r\n[Op type: Const] unknown_86\r\n2020-04-21 14:45:37.176021: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.176025: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_87:\r\n[Op type: Const] unknown_87\r\n2020-04-21 14:45:37.176029: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.176032: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_88:\r\n[Op type: Const] unknown_88\r\n2020-04-21 14:45:37.176036: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.176040: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_89:\r\n[Op type: Const] unknown_89\r\n2020-04-21 14:45:37.176043: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.176047: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_9:\r\n[Op type: Const] unknown_9\r\n2020-04-21 14:45:37.176052: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.176056: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_90:\r\n[Op type: Const] unknown_90\r\n2020-04-21 14:45:37.176060: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.176064: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_91:\r\n[Op type: Const] unknown_91\r\n2020-04-21 14:45:37.176067: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.176071: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_92:\r\n[Op type: Const] unknown_92\r\n2020-04-21 14:45:37.176074: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.176078: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_93:\r\n[Op type: Const] unknown_93\r\n2020-04-21 14:45:37.176082: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.176085: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_94:\r\n[Op type: Const] unknown_94\r\n2020-04-21 14:45:37.176089: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.176093: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_95:\r\n[Op type: Const] unknown_95\r\n2020-04-21 14:45:37.176096: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.176100: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_96:\r\n[Op type: Const] unknown_96\r\n2020-04-21 14:45:37.176104: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.176107: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_97:\r\n[Op type: Const] unknown_97\r\n2020-04-21 14:45:37.176111: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.176115: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_98:\r\n[Op type: Const] unknown_98\r\n2020-04-21 14:45:37.176118: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.176122: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:680] Nodes in segment 1 with parent=unknown_99:\r\n[Op type: Const] unknown_99\r\n2020-04-21 14:45:37.176125: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:693] Segment 1 has only 1 effective nodes, dropping\r\n2020-04-21 14:45:37.176130: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:719] Devices Segment : 'StatefulPartitionedCall/model_1/add_9/add-0-0-PermConstNCHWToNHWC-LayoutOptimizer' /job:localhost/replica:0/task:0/device:GPU:0,\r\n2020-04-21 14:45:37.177497: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:638] Number of TensorRT candidate segments: 1\r\n```", "@luvwinnie it's weird that there is no log like `Not a TF-TRT candidate ...`. In your case [`num_unsupported_ops`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/tf2tensorrt/segment/segment.cc#L434) is 10 but it should be increased only after logging the non-candidates.", "@aaroey sorry, i have updated the logs.", "@luvwinnie thanks, now you can see the reason why those ops are not supported. For example:\r\n```\r\n2020-04-21 14:45:37.159520: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:439] Not a TF-TRT candidate, (Op type: Pack), (Op name: StatefulPartitionedCall/model_1/reshape/Reshape/shape), (Reason: Internal: Failed to convert input StatefulPartitionedCall/model_1/reshape/strided_slice to a TRT_TensorOrWeights: Scalar input tensor is not supported since the first dimension is treated as batch dimension by TRT)\r\n```\r\nFor this Pack op, it's because its input is a scalar and cannot be converted (TF-TRT requires at least rank 1 at the moment).", "@aaroey This StatefulPartitionedCall i think it is suppose to be my Bidirectinoal GRU Cell, i thought that TensorRT 7 already support GRUCell?", "TF doesn't fully support TRT7 yet. @bixia1 may know more details", "I tried to run the code in colab with TF v2.5 & faced a different error ,please find the gist [here](https://colab.research.google.com/gist/sushreebarsa/5ad60a6fcb95d3c7ff25067da929943c/untitled94.ipynb)..Thanks !", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34708\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34708\">No</a>\n"]}, {"number": 34707, "title": "Cannot deploy Tensorflow 2.0.0 to Google cloud functions", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google cloud functions\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version: 2.0.0\r\n- Python version: 3.7\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\nWe are getting following error while trying to deploy Tensorflow 2.0.0. \r\n\r\n```\r\ngcloud functions deploy matchProbability --runtime python37 --trigger-http --memory 2048MB --timeout=540 --set-env-vars TEMP=/tmp/\r\n```\r\n\r\n```\r\nDeploying function (may take a while - up to 2 minutes)...failed.                                                                                                                         \r\nERROR: (gcloud.functions.deploy) OperationError: code=3, message=Build failed: {\"error\": {\"canonicalCode\": \"INVALID_ARGUMENT\", \"errorMessage\": \"'pip_download_wheels' had stderr output:\\n \r\n Could not find a version that satisfies the requirement tensorflow==2.0.0 (from -r requirements.txt (line 53)) (from versions: 1.13.0rc1, 1.13.0rc2, 1.13.1, 1.13.2, 1.14.0rc0, 1.14.0rc1,\r\n 1.14.0, 2.0.0a0, 2.0.0b0, 2.0.0b1)\\nNo matching distribution found for tensorflow==2.0.0 (from -r requirements.txt (line 53))\\n\\nerror: 'pip_download_wheels' returned code: 1\", \"errorTyp\r\ne\": \"InternalError\", \"errorId\": \"72357014\"}}\r\n```\r\n\r\nNot sure what are next steps should be, only [article](https://cloud.google.com/blog/products/ai-machine-learning/how-to-serve-deep-learning-models-using-tensorflow-2-0-with-cloud-functions) describing deploying Tensorflow to google cloud functions is using version 2.0.0b1. Should we downgrade?\r\n", "comments": ["I know we changed TensorFlow 2.0 official to be [manylinux2010](https://www.python.org/dev/peps/pep-0571/) compliant between beta and official which requires an updated pip. Could that potentially be the issue?\r\n\r\nThere is definitely a [Python3.7 binary](https://pypi.org/project/tensorflow/#files) for tensorflow==2.0.0.", "Required pip version is 19.0 or later for TF 2.0.0\r\nSee https://www.tensorflow.org/install/pip?lang=python3#system-requirements", "Hi, I can confirm this is problem with Google Cloud Function. That article is just wrong and should not exists...\r\n\r\nThey are still running on PIP 18.0, thats why Tensorflow 2.0.0 (and any newer software) cannot be installed. Obviously, same will be true for TF 2.1.0 when it will be released.\r\n\r\nWhats worse according to private support they have no plan to update and marked it as \"feature request\", so it has no resolution time.\r\n\r\nHere is public support ticket created for this issue, you can consider staring it: https://issuetracker.google.com/145374253\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34707\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34707\">No</a>\n", "> Hi, I can confirm this is problem with Google Cloud Function. That article is just wrong and should not exists...\r\n> \r\n> They are still running on PIP 18.0, thats why Tensorflow 2.0.0 (and any newer software) cannot be installed. Obviously, same will be true for TF 2.1.0 when it will be released.\r\n> \r\n> Whats worse according to private support they have no plan to update and marked it as \"feature request\", so it has no resolution time.\r\n> \r\n> Here is public support ticket created for this issue, you can consider staring it: https://issuetracker.google.com/145374253\r\n\r\nAt this moment, GCF supports latest version of pip, which is `20.0.2`.\r\n\r\nYou could verify via this GCF. \r\n\r\n```python\r\ndef pip_version(_):\r\n  import pip\r\n  print(pip.__version__)\r\n```\r\n\r\nDeploy and test. `gcloud functions deploy pip_version --runtime python37 --trigger-http`\r\n\r\nMoreover, your statement about TF2 is also not true. From [GCP blog](https://cloud.google.com/blog/products/ai-machine-learning/how-to-serve-deep-learning-models-using-tensorflow-2-0-with-cloud-functions), TF2 was supported to run via GCF since July 2019.\r\n", "@northtree You are correct. However GCF fails to install any version of TF2 > 2.0.0b0 . I had been trying to deploy a GCF with TF 2.1.0 and it was failing. Downgrading to 2.0.0b0 seems to fix the issue for now. But any hints on what is preventing GCF from deploying newer versions of TF2?", "@northtree No, Google Cloud Function has never supported (and does not today) TF >2.0.0.b. \r\nTheir build is simply run with old PIP. \r\n\r\nWe have spent over week of dev time trying and failing, and then another week trying to get whats wrong through paid support channels, because we have believed the docs & marketing... just like you.. \r\nThat blog is just false (its using 2.0.0b while claiming 2.0), documentation is false (referring to 2.0 when its 2.0.0b) and even tech support was false for first 3 days (until we have documented everything and only thing left was to acknowledge that they have a problem).\r\n\r\nBeyond that, similar problems can be found in their other products claiming TF support, its either old Python, old pip or size restrictions...", "@m4recek That's not true. \r\n\r\n[2.0.0](https://github.com/tensorflow/tensorflow/releases/tag/v2.0.0) was released on Oct 2019 which is newer than [2.0.0b0](https://github.com/tensorflow/tensorflow/releases/tag/v2.0.0-beta0). \r\n\r\nCurrently, I could deploy GCF with `tensorflow==2.0.0` in requirements.txt. \r\n\r\n@bonaventura-p You are right. TF 2.1 is not supported and will return `Build Error` on deployment.", "@northtree I think you are missing the timeline of the original issue.\r\n- June 7, 2019 - 2.0.0b0 beta release\r\n- July 9, 2019 - Blog is published, presumably docs updated (thats why its using 2.0.0b0)\r\n- Sept 30, 2019 - 2.0.0 stable release\r\n- Nov 29, 2019 - this thread, public & private bug reports created (google cloud functions were running pip 19)\r\n- April 2, 2020 - last comment in public tracker asking for help https://issuetracker.google.com/issues/145374253\r\n\r\nWhich means Blog, Marketing & Doc were all wrong... for 10 months?\r\nIts great if 2.0 was finally fixed in last few weeks. I guess the marketing announcement didn't happened this time and bug tickets were not updated. Also TF is on 2.1, almost 2.2 now..\r\n\r\nIt seems that TF is iterating too quickly for GCP to keep up \ud83d\ude04 \r\n\r\nOff topic: We have tried Google's AI platform with similarly mixed results in terms of docs & marketing accuracy. Right now it seems like the best way to run TF models in production apps is in custom build containers in Cloud Run or Kubernetes."]}, {"number": 34706, "title": "Complete support for LSTM/GRU for TFLite", "body": "\r\n**System information**\r\n- TensorFlow version (you are using): 2.0\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nReading the [roadmap](https://www.tensorflow.org/lite/guide/roadmap) of Tensorflow Lite for 2019 there should be full LSTM/GRU support by the end of this year, but I don't seen anything done, also no recent update of the state of the roadmap. At the moment there are two [workarounds](https://www.tensorflow.org/lite/convert/rnn) that work suboptimally. I have never been able to reproduce nearly the results I had with plain TF.\r\n\r\n\r\n**Who will benefit with this feature?**\r\n\r\nI think having LSTM/GRU is crucial since a lot of architectures are using them and mobile/embedded DL development is a big topic right now.\r\n\r\n", "comments": ["You may try using ```experimental_new_converter``` in latest tf-nightly builds to convert your lstm models in TF Lite.\r\nSee https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/examples/experimental_new_converter/keras_lstm.ipynb\r\n", "Hmm yeah that's another workaround I guess. If there is a way to help with the implementation I would be willing to do it if I get some guidance from a person that worked on it a bit and has a rough idea what has to be done.", "hey what is the status on this? I proposed (with another account) to work on this issue as a part of a GSoC project but didnt get any answers as for mentorship yet. Anyone has a clue who I could contact directly in this matter?", "@justlike-prog  We recently announce TF 2.0 Keras to TFLite fused LSTM conversion support.\r\n\r\nPlease see below:\r\nhttps://groups.google.com/a/tensorflow.org/g/tflite/c/Ub4apUvblN8\r\n\r\nWould you be interested in trying this out? this is an e2e solution, once you get the fused LSTM in Tflite, that can also be quantized.\r\n", "TensorFlow RNN conversion to TensorFlow Lite is supported from TF 2.3 release.\r\nSee https://www.tensorflow.org/lite/convert/rnn#tensorflow_rnns_apis_supported\r\nThanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34706\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34706\">No</a>\n"]}, {"number": 34705, "title": "cuDNN error initializing ", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOs 7\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 1.15.0\r\n- Python version: 3.5.2\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 9.0 \r\n- GPU model and memory: 4 * K80 - 24GB GDDR5 ECC\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n```\r\ntensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found.\r\n  (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\r\n\t [[node FeatureExtractor/MobilenetV2/Conv/Conv2D (defined at apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/framework/ops.py:1748) ]]\r\n\t [[total_loss/_9637]]\r\n  (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\r\n\t [[node FeatureExtractor/MobilenetV2/Conv/Conv2D (defined at apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/framework/ops.py:1748) ]]\r\n0 successful operations.\r\n0 derived errors ignored.\r\n```\r\n**Describe the expected behavior**\r\nThe training should proceed smoothly.\r\nActually I'm using object detection API, use ssd_mobilenet_v2_coco_2018_03_29\r\n\r\n**Code to reproduce the issue**\r\nOn PBS system launch script code:\r\n```\r\n#!/bin/bash\r\n\r\n# 'select' set number node\r\n# 'ncpus' set number cpu\r\n# 'mem' set RAM value * node = total\r\n#PBS -l select=8:ncpus=4:mem=16gb\r\n\r\n# set run queue\r\n\r\n# specify qgpu resource\r\n#PBS -q common_gpuQ\r\n\r\n# set maximum exectuion time\r\n#PBS -l walltime=1500:00:0\r\n\r\n# set mail\r\n#PBS -M francesco.argentieri@studenti.unitn.it\r\n\r\n# send mail when start and end job\r\n#PBS -m be\r\n# write error log\r\n#PBS -e error_dronelanding352.log\r\n\r\n# write out log\r\n#PBS -o result_dronelanding352.log\r\n\r\n# show module\r\nmodule avail\r\n\r\n# load moudle\r\nmodule load python-3.5.2 cuda-9.0\r\n\r\n# show loaded module\r\nmodule list\r\n\r\n##############################################################################\r\n# setup environmnet\r\n##############################################################################\r\ngit clone -b develop https://github.com/frank1789/ProjectThesis.git\r\ncd ProjectThesis\r\nrm -rf train_labels.csv\r\nrm -rf validate_labels.csv\r\ngit reset --hard\r\ngit pull\r\nrm -rf models\r\npython3 -c \"import tensorflow as tf; print('tensorflow version installed', tf.__version__)\"\r\n# run script\r\nsh setup_tf.sh ssd_coco\r\n```\r\nmy code is available at https://github.com/frank1789/ProjectThesis.git -> branch develop\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n```\r\n[francesco.argentieri@hpc-head-n1 ~]$ cat error_dronelanding352.log\r\n\r\n------------------------------ /apps/Modules/apps ------------------------------\r\natlas-3.10.3                    Magma\r\nBertiniMPI_v1.5                 magma-2.24\r\nBertini_v1.5.1                  matlab_R2018b\r\nBLAS                            matlab_runtime_91\r\ncmake-3.10.2                    miniconda\r\ncmake-3.15.4                    mpfr-3.1.5\r\ncuda-10.0                       mpich-3.2\r\ncuda-8.0                        mpich-3.2.1--gcc-9.1.0\r\ncuda-9.0                        mpich-3.2.1--intel-xe-2019u1\r\nespresso                        mpichtest\r\nfftw-3.3.8                      ncview-1.93g\r\nfiji                            netcdf-4.7.0--gcc-9.1.0\r\ngcc54                           netCDF-Fortran-4.4.5--gcc-9.1.0\r\ngcc91                           numactl\r\ngmp-6.1.1                       OpenBLAS-0.3.7\r\nhdf5-1.10.5--gcc-9.1.0          openmpi-3.0.0\r\nhdf5-1.8.18                     python-2.7.12\r\nhwloc-2.0.4                     python-3.5.2\r\nImageJ-1.5                      python-3.7.2\r\nIntel_parallel_studio_xe2018u2  R-3.3.1\r\nIntel_parallel_studio_xe2019u1  R-3.4.3\r\njdk-11.0.1                      R-3.6.1\r\njre1.8.0_161                    singularity\r\nlammps                          singularity-2.4\r\nlapack-3.7.0                    valgrind-3.15.0\r\nlapack-3.8.0                    zlib-1.2.11--gcc-9.1.0\r\nlikwid-4.3.4\r\nCurrently Loaded Modulefiles:\r\n  1) python-3.5.2   2) cuda-9.0\r\nWARNING:tensorflow:\r\nThe TensorFlow contrib module will not be included in TensorFlow 2.0.\r\nFor more information, please see:\r\n  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\r\n  * https://github.com/tensorflow/addons\r\n  * https://github.com/tensorflow/io (for I/O related ops)\r\nIf you depend on functionality not listed there, please file an issue.\r\n\r\nWARNING:tensorflow:From /home/francesco.argentieri/ProjectThesis/tf-models/research/slim/nets/inception_resnet_v2.py:374: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\r\n\r\nWARNING:tensorflow:From /home/francesco.argentieri/ProjectThesis/tf-models/research/slim/nets/mobilenet/mobilenet.py:397: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\r\n\r\nRunning tests under Python 3.5.2: /apps/python-3.5.2/bin/python3\r\n[ RUN      ] ModelBuilderTest.test_create_experimental_model\r\n[       OK ] ModelBuilderTest.test_create_experimental_model\r\n[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_model_from_config_with_example_miner\r\n[       OK ] ModelBuilderTest.test_create_faster_rcnn_model_from_config_with_example_miner\r\n[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\r\n[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\r\n[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\r\n[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\r\n[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\r\n[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\r\n[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\r\n[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\r\n[ RUN      ] ModelBuilderTest.test_create_rfcn_model_from_config\r\n[       OK ] ModelBuilderTest.test_create_rfcn_model_from_config\r\n[ RUN      ] ModelBuilderTest.test_create_ssd_fpn_model_from_config\r\n[       OK ] ModelBuilderTest.test_create_ssd_fpn_model_from_config\r\n[ RUN      ] ModelBuilderTest.test_create_ssd_models_from_config\r\n[       OK ] ModelBuilderTest.test_create_ssd_models_from_config\r\n[ RUN      ] ModelBuilderTest.test_invalid_faster_rcnn_batchnorm_update\r\n[       OK ] ModelBuilderTest.test_invalid_faster_rcnn_batchnorm_update\r\n[ RUN      ] ModelBuilderTest.test_invalid_first_stage_nms_iou_threshold\r\n[       OK ] ModelBuilderTest.test_invalid_first_stage_nms_iou_threshold\r\n[ RUN      ] ModelBuilderTest.test_invalid_model_config_proto\r\n[       OK ] ModelBuilderTest.test_invalid_model_config_proto\r\n[ RUN      ] ModelBuilderTest.test_invalid_second_stage_batch_size\r\n[       OK ] ModelBuilderTest.test_invalid_second_stage_batch_size\r\n[ RUN      ] ModelBuilderTest.test_session\r\n[  SKIPPED ] ModelBuilderTest.test_session\r\n[ RUN      ] ModelBuilderTest.test_unknown_faster_rcnn_feature_extractor\r\n[       OK ] ModelBuilderTest.test_unknown_faster_rcnn_feature_extractor\r\n[ RUN      ] ModelBuilderTest.test_unknown_meta_architecture\r\n[       OK ] ModelBuilderTest.test_unknown_meta_architecture\r\n[ RUN      ] ModelBuilderTest.test_unknown_ssd_feature_extractor\r\n[       OK ] ModelBuilderTest.test_unknown_ssd_feature_extractor\r\n----------------------------------------------------------------------\r\nRan 17 tests in 0.217s\r\n\r\nOK (skipped=1)\r\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n                                 Dload  Upload   Total   Spent    Left  Speed\r\n100  179M  100  179M    0     0  74.3M      0  0:00:02  0:00:02 --:--:-- 74.3M\r\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n                                 Dload  Upload   Total   Spent    Left  Speed\r\n100  4097  100  4097    0     0  19941      0 --:--:-- --:--:-- --:--:-- 19985\r\n/home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/utils/visualization_utils.py:29: UserWarning:\r\nThis call to matplotlib.use() has no effect because the backend has already\r\nbeen chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\r\nor matplotlib.backends is imported for the first time.\r\n\r\nThe backend was *originally* set to 'TkAgg' by the following code:\r\n  File \"/home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/model_main.py\", line 26, in <module>\r\n    from object_detection import model_lib\r\n  File \"/home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/model_lib.py\", line 27, in <module>\r\n    from object_detection import eval_util\r\n  File \"/home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/eval_util.py\", line 33, in <module>\r\n    from object_detection.metrics import coco_evaluation\r\n  File \"/home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/metrics/coco_evaluation.py\", line 25, in <module>\r\n    from object_detection.metrics import coco_tools\r\n  File \"/home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/metrics/coco_tools.py\", line 51, in <module>\r\n    from pycocotools import coco\r\n  File \"/home/francesco.argentieri/ProjectThesis/tf-models/research/pycocotools/coco.py\", line 49, in <module>\r\n    import matplotlib.pyplot as plt\r\n  File \"/apps/python-3.5.2/lib/python3.5/site-packages/matplotlib/pyplot.py\", line 72, in <module>\r\n    from matplotlib.backends import pylab_setup\r\n  File \"/apps/python-3.5.2/lib/python3.5/site-packages/matplotlib/backends/__init__.py\", line 14, in <module>\r\n    line for line in traceback.format_stack()\r\n\r\n\r\n  import matplotlib; matplotlib.use('Agg')  # pylint: disable=multiple-statements\r\nWARNING:tensorflow:\r\nThe TensorFlow contrib module will not be included in TensorFlow 2.0.\r\nFor more information, please see:\r\n  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\r\n  * https://github.com/tensorflow/addons\r\n  * https://github.com/tensorflow/io (for I/O related ops)\r\nIf you depend on functionality not listed there, please file an issue.\r\n\r\nWARNING:tensorflow:From /home/francesco.argentieri/ProjectThesis/tf-models/research/slim/nets/inception_resnet_v2.py:374: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\r\n\r\nWARNING:tensorflow:From /home/francesco.argentieri/ProjectThesis/tf-models/research/slim/nets/mobilenet/mobilenet.py:397: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\r\n\r\nWARNING:tensorflow:From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/model_main.py:109: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\r\n\r\nWARNING:tensorflow:From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/utils/config_util.py:102: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\r\n\r\nW1129 13:11:00.107400 46916307045888 module_wrapper.py:139] From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/utils/config_util.py:102: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\r\n\r\nWARNING:tensorflow:From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/model_lib.py:628: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\r\n\r\nW1129 13:11:00.114970 46916307045888 module_wrapper.py:139] From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/model_lib.py:628: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\r\n\r\nWARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\r\nW1129 13:11:00.115096 46916307045888 model_lib.py:629] Forced number of epochs for all eval validations to be 1.\r\nWARNING:tensorflow:From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/utils/config_util.py:488: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\r\n\r\nW1129 13:11:00.115231 46916307045888 module_wrapper.py:139] From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/utils/config_util.py:488: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\r\n\r\nINFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\r\nI1129 13:11:00.115335 46916307045888 config_util.py:488] Maybe overwriting sample_1_of_n_eval_examples: 1\r\nINFO:tensorflow:Maybe overwriting eval_num_epochs: 1\r\nI1129 13:11:00.115433 46916307045888 config_util.py:488] Maybe overwriting eval_num_epochs: 1\r\nINFO:tensorflow:Maybe overwriting use_bfloat16: False\r\nI1129 13:11:00.115521 46916307045888 config_util.py:488] Maybe overwriting use_bfloat16: False\r\nINFO:tensorflow:Maybe overwriting train_steps: 50000\r\nI1129 13:11:00.115603 46916307045888 config_util.py:488] Maybe overwriting train_steps: 50000\r\nINFO:tensorflow:Maybe overwriting load_pretrained: True\r\nI1129 13:11:00.115684 46916307045888 config_util.py:488] Maybe overwriting load_pretrained: True\r\nINFO:tensorflow:Ignoring config override key: load_pretrained\r\nI1129 13:11:00.115762 46916307045888 config_util.py:498] Ignoring config override key: load_pretrained\r\nWARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\r\nW1129 13:11:00.116141 46916307045888 model_lib.py:645] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\r\nINFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu False\r\nI1129 13:11:00.116248 46916307045888 model_lib.py:680] create_estimator_and_inputs: use_tpu False, export_to_tpu False\r\nINFO:tensorflow:Using config: {'_keep_checkpoint_max': 5, '_task_id': 0, '_evaluation_master': '', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aac11329438>, '_experimental_distribute': None, '_is_chief': True, '_session_creation_timeout_secs': 7200, '_device_fn': None, '_tf_random_seed': None, '_task_type': 'worker', '_save_checkpoints_steps': None, '_train_distribute': None, '_num_worker_replicas': 1, '_model_dir': '/home/francesco.argentieri/ProjectThesis/models/ssd_mobilenet_v2_coco_2018_03_29', '_log_step_count_steps': 100, '_save_checkpoints_secs': 600, '_master': '', '_experimental_max_worker_delay_secs': None, '_protocol': None, '_save_summary_steps': 100, '_global_id_in_cluster': 0, '_service': None, '_keep_checkpoint_every_n_hours': 10000, '_num_ps_replicas': 0, '_eval_distribute': None, '_session_config': allow_soft_placement: true\r\ngraph_options {\r\n  rewrite_options {\r\n    meta_optimizer_iterations: ONE\r\n  }\r\n}\r\n}\r\nI1129 13:11:00.116693 46916307045888 estimator.py:212] Using config: {'_keep_checkpoint_max': 5, '_task_id': 0, '_evaluation_master': '', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x2aac11329438>, '_experimental_distribute': None, '_is_chief': True, '_session_creation_timeout_secs': 7200, '_device_fn': None, '_tf_random_seed': None, '_task_type': 'worker', '_save_checkpoints_steps': None, '_train_distribute': None, '_num_worker_replicas': 1, '_model_dir': '/home/francesco.argentieri/ProjectThesis/models/ssd_mobilenet_v2_coco_2018_03_29', '_log_step_count_steps': 100, '_save_checkpoints_secs': 600, '_master': '', '_experimental_max_worker_delay_secs': None, '_protocol': None, '_save_summary_steps': 100, '_global_id_in_cluster': 0, '_service': None, '_keep_checkpoint_every_n_hours': 10000, '_num_ps_replicas': 0, '_eval_distribute': None, '_session_config': allow_soft_placement: true\r\ngraph_options {\r\n  rewrite_options {\r\n    meta_optimizer_iterations: ONE\r\n  }\r\n}\r\n}\r\nWARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x2aac11338598>) includes params argument, but params are not passed to Estimator.\r\nW1129 13:11:00.116895 46916307045888 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x2aac11338598>) includes params argument, but params are not passed to Estimator.\r\nINFO:tensorflow:Not using Distribute Coordinator.\r\nI1129 13:11:00.117480 46916307045888 estimator_training.py:186] Not using Distribute Coordinator.\r\nINFO:tensorflow:Running training and evaluation locally (non-distributed).\r\nI1129 13:11:00.117681 46916307045888 training.py:612] Running training and evaluation locally (non-distributed).\r\nINFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\r\nI1129 13:11:00.117958 46916307045888 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\r\nWARNING:tensorflow:From /apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\r\nW1129 13:11:00.123463 46916307045888 deprecation.py:323] From /apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\r\nWARNING:tensorflow:From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/data_decoders/tf_example_decoder.py:182: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\r\n\r\nW1129 13:11:00.134167 46916307045888 module_wrapper.py:139] From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/data_decoders/tf_example_decoder.py:182: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\r\n\r\nWARNING:tensorflow:From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/data_decoders/tf_example_decoder.py:197: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\r\n\r\nW1129 13:11:00.134382 46916307045888 module_wrapper.py:139] From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/data_decoders/tf_example_decoder.py:197: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\r\n\r\nWARNING:tensorflow:From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/builders/dataset_builder.py:64: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\r\n\r\nW1129 13:11:00.156062 46916307045888 module_wrapper.py:139] From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/builders/dataset_builder.py:64: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\r\n\r\nWARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\r\nW1129 13:11:00.157456 46916307045888 dataset_builder.py:72] num_readers has been reduced to 1 to match input file shards.\r\nWARNING:tensorflow:From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/builders/dataset_builder.py:86: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.data.experimental.parallel_interleave(...)`.\r\nW1129 13:11:00.163085 46916307045888 deprecation.py:323] From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/builders/dataset_builder.py:86: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.data.experimental.parallel_interleave(...)`.\r\nWARNING:tensorflow:From /apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\r\nW1129 13:11:00.163222 46916307045888 deprecation.py:323] From /apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\r\nWARNING:tensorflow:From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/builders/dataset_builder.py:155: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.data.Dataset.map()\r\nW1129 13:11:00.186017 46916307045888 deprecation.py:323] From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/builders/dataset_builder.py:155: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.data.Dataset.map()\r\nWARNING:tensorflow:From /apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.logging.warn is deprecated. Please use tf.compat.v1.logging.warn instead.\r\n\r\nW1129 13:11:01.717208 46916307045888 module_wrapper.py:139] From /apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.logging.warn is deprecated. Please use tf.compat.v1.logging.warn instead.\r\n\r\nWARNING:tensorflow:From /apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.is_nan is deprecated. Please use tf.math.is_nan instead.\r\n\r\nW1129 13:11:10.354478 46916307045888 module_wrapper.py:139] From /apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.is_nan is deprecated. Please use tf.math.is_nan instead.\r\n\r\nWARNING:tensorflow:From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse tf.where in 2.0, which has the same broadcast rule as np.where\r\nW1129 13:11:10.452341 46916307045888 deprecation.py:323] From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse tf.where in 2.0, which has the same broadcast rule as np.where\r\nWARNING:tensorflow:From /apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\r\n\r\nW1129 13:11:13.191320 46916307045888 module_wrapper.py:139] From /apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\r\n\r\nWARNING:tensorflow:From /apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/autograph/operators/control_flow.py:1004: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\n`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\r\nW1129 13:11:17.294937 46916307045888 api.py:332] From /apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/autograph/operators/control_flow.py:1004: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\n`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\r\nWARNING:tensorflow:From /apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\r\n\r\nW1129 13:11:21.228440 46916307045888 module_wrapper.py:139] From /apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\r\n\r\nWARNING:tensorflow:From /apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\r\n\r\nW1129 13:11:21.229693 46916307045888 module_wrapper.py:139] From /apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\r\n\r\nWARNING:tensorflow:From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/inputs.py:166: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.cast` instead.\r\nW1129 13:11:21.742646 46916307045888 deprecation.py:323] From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/inputs.py:166: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.cast` instead.\r\nWARNING:tensorflow:From /apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.string_to_hash_bucket_fast is deprecated. Please use tf.strings.to_hash_bucket_fast instead.\r\n\r\nW1129 13:11:23.752529 46916307045888 module_wrapper.py:139] From /apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.string_to_hash_bucket_fast is deprecated. Please use tf.strings.to_hash_bucket_fast instead.\r\n\r\nWARNING:tensorflow:From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/builders/dataset_builder.py:158: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.data.Dataset.batch(..., drop_remainder=True)`.\r\nW1129 13:11:24.356604 46916307045888 deprecation.py:323] From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/builders/dataset_builder.py:158: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.data.Dataset.batch(..., drop_remainder=True)`.\r\nINFO:tensorflow:Calling model_fn.\r\nI1129 13:11:24.371528 46916307045888 estimator.py:1148] Calling model_fn.\r\nWARNING:tensorflow:From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/meta_architectures/ssd_meta_arch.py:597: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\r\n\r\nW1129 13:11:24.739926 46916307045888 module_wrapper.py:139] From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/meta_architectures/ssd_meta_arch.py:597: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\r\n\r\nWARNING:tensorflow:From /apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nPlease use `layer.__call__` method instead.\r\nW1129 13:11:24.742907 46916307045888 deprecation.py:323] From /apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nPlease use `layer.__call__` method instead.\r\nWARNING:tensorflow:From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\r\n\r\nW1129 13:11:27.975720 46916307045888 module_wrapper.py:139] From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\r\n\r\nINFO:tensorflow:depth of additional conv before box predictor: 0\r\nI1129 13:11:27.987807 46916307045888 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\r\nINFO:tensorflow:depth of additional conv before box predictor: 0\r\nI1129 13:11:28.023709 46916307045888 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\r\nINFO:tensorflow:depth of additional conv before box predictor: 0\r\nI1129 13:11:28.059213 46916307045888 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\r\nINFO:tensorflow:depth of additional conv before box predictor: 0\r\nI1129 13:11:28.095044 46916307045888 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\r\nINFO:tensorflow:depth of additional conv before box predictor: 0\r\nI1129 13:11:28.130629 46916307045888 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\r\nINFO:tensorflow:depth of additional conv before box predictor: 0\r\nI1129 13:11:28.166254 46916307045888 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\r\nWARNING:tensorflow:From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/utils/variables_helper.py:179: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\r\n\r\nW1129 13:11:28.207245 46916307045888 module_wrapper.py:139] From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/utils/variables_helper.py:179: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\r\n\r\nWARNING:tensorflow:From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/utils/variables_helper.py:139: The name tf.train.NewCheckpointReader is deprecated. Please use tf.compat.v1.train.NewCheckpointReader instead.\r\n\r\nW1129 13:11:28.208312 46916307045888 module_wrapper.py:139] From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/utils/variables_helper.py:139: The name tf.train.NewCheckpointReader is deprecated. Please use tf.compat.v1.train.NewCheckpointReader instead.\r\n\r\nWARNING:tensorflow:From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/model_lib.py:353: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\r\n\r\nW1129 13:11:28.217204 46916307045888 module_wrapper.py:139] From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/model_lib.py:353: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\r\n\r\nWARNING:tensorflow:From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/box_coders/faster_rcnn_box_coder.py:82: The name tf.log is deprecated. Please use tf.math.log instead.\r\n\r\nW1129 13:11:29.469171 46916307045888 module_wrapper.py:139] From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/box_coders/faster_rcnn_box_coder.py:82: The name tf.log is deprecated. Please use tf.math.log instead.\r\n\r\nWARNING:tensorflow:From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/meta_architectures/ssd_meta_arch.py:1163: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\r\n\r\nW1129 13:11:33.735143 46916307045888 module_wrapper.py:139] From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/meta_architectures/ssd_meta_arch.py:1163: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\r\n\r\nWARNING:tensorflow:From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/core/losses.py:177: The name tf.losses.huber_loss is deprecated. Please use tf.compat.v1.losses.huber_loss instead.\r\n\r\nW1129 13:11:33.741652 46916307045888 module_wrapper.py:139] From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/core/losses.py:177: The name tf.losses.huber_loss is deprecated. Please use tf.compat.v1.losses.huber_loss instead.\r\n\r\nWARNING:tensorflow:From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/core/losses.py:183: The name tf.losses.Reduction is deprecated. Please use tf.compat.v1.losses.Reduction instead.\r\n\r\nW1129 13:11:33.742920 46916307045888 module_wrapper.py:139] From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/core/losses.py:183: The name tf.losses.Reduction is deprecated. Please use tf.compat.v1.losses.Reduction instead.\r\n\r\nWARNING:tensorflow:From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/meta_architectures/ssd_meta_arch.py:1275: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\r\n\r\nW1129 13:11:34.359708 46916307045888 module_wrapper.py:139] From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/meta_architectures/ssd_meta_arch.py:1275: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\r\n\r\nWARNING:tensorflow:From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/model_lib.py:380: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\r\n\r\nW1129 13:11:34.362771 46916307045888 module_wrapper.py:139] From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/model_lib.py:380: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\r\n\r\nWARNING:tensorflow:From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/utils/learning_schedules.py:66: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\r\n\r\nW1129 13:11:34.363040 46916307045888 module_wrapper.py:139] From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/utils/learning_schedules.py:66: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\r\n\r\nWARNING:tensorflow:From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/builders/optimizer_builder.py:47: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\r\n\r\nW1129 13:11:34.372650 46916307045888 module_wrapper.py:139] From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/builders/optimizer_builder.py:47: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\r\n\r\nWARNING:tensorflow:From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/model_lib.py:398: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\r\n\r\nW1129 13:11:34.372868 46916307045888 module_wrapper.py:139] From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/model_lib.py:398: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\r\n\r\nWARNING:tensorflow:From /apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nCall initializer instance with the dtype argument instead of passing it to the constructor\r\nW1129 13:11:36.890684 46916307045888 deprecation.py:506] From /apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nCall initializer instance with the dtype argument instead of passing it to the constructor\r\nWARNING:tensorflow:From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/model_lib.py:515: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\r\n\r\nW1129 13:11:43.759206 46916307045888 module_wrapper.py:139] From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/model_lib.py:515: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\r\n\r\nWARNING:tensorflow:From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/model_lib.py:519: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\r\n\r\nW1129 13:11:44.819307 46916307045888 module_wrapper.py:139] From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/model_lib.py:519: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\r\n\r\nWARNING:tensorflow:From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/model_lib.py:520: The name tf.train.Scaffold is deprecated. Please use tf.compat.v1.train.Scaffold instead.\r\n\r\nW1129 13:11:44.819580 46916307045888 module_wrapper.py:139] From /home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/model_lib.py:520: The name tf.train.Scaffold is deprecated. Please use tf.compat.v1.train.Scaffold instead.\r\n\r\nINFO:tensorflow:Done calling model_fn.\r\nI1129 13:11:44.820056 46916307045888 estimator.py:1150] Done calling model_fn.\r\nINFO:tensorflow:Create CheckpointSaverHook.\r\nI1129 13:11:44.821458 46916307045888 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\r\nINFO:tensorflow:Graph was finalized.\r\nI1129 13:11:50.663527 46916307045888 monitored_session.py:240] Graph was finalized.\r\nINFO:tensorflow:Running local_init_op.\r\nI1129 13:11:57.670931 46916307045888 session_manager.py:500] Running local_init_op.\r\nINFO:tensorflow:Done running local_init_op.\r\nI1129 13:11:58.240870 46916307045888 session_manager.py:502] Done running local_init_op.\r\nINFO:tensorflow:Saving checkpoints for 0 into /home/francesco.argentieri/ProjectThesis/models/ssd_mobilenet_v2_coco_2018_03_29/model.ckpt.\r\nI1129 13:12:13.180183 46916307045888 basic_session_run_hooks.py:606] Saving checkpoints for 0 into /home/francesco.argentieri/ProjectThesis/models/ssd_mobilenet_v2_coco_2018_03_29/model.ckpt.\r\nTraceback (most recent call last):\r\n  File \"/apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/client/session.py\", line 1365, in _do_call\r\n    return fn(*args)\r\n  File \"/apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/client/session.py\", line 1350, in _run_fn\r\n    target_list, run_metadata)\r\n  File \"/apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/client/session.py\", line 1443, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found.\r\n  (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\r\n\t [[{{node FeatureExtractor/MobilenetV2/Conv/Conv2D}}]]\r\n\t [[total_loss/_9637]]\r\n  (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\r\n\t [[{{node FeatureExtractor/MobilenetV2/Conv/Conv2D}}]]\r\n0 successful operations.\r\n0 derived errors ignored.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/model_main.py\", line 109, in <module>\r\n    tf.app.run()\r\n  File \"/apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/platform/app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"/apps/python-3.5.2/lib/python3.5/site-packages/absl/app.py\", line 299, in run\r\n    _run_main(main, args)\r\n  File \"/apps/python-3.5.2/lib/python3.5/site-packages/absl/app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"/home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/model_main.py\", line 105, in main\r\n    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])\r\n  File \"/apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_estimator/python/estimator/training.py\", line 473, in train_and_evaluate\r\n    return executor.run()\r\n  File \"/apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_estimator/python/estimator/training.py\", line 613, in run\r\n    return self.run_local()\r\n  File \"/apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_estimator/python/estimator/training.py\", line 714, in run_local\r\n    saving_listeners=saving_listeners)\r\n  File \"/apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 370, in train\r\n    loss = self._train_model(input_fn, hooks, saving_listeners)\r\n  File \"/apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1161, in _train_model\r\n    return self._train_model_default(input_fn, hooks, saving_listeners)\r\n  File \"/apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1195, in _train_model_default\r\n    saving_listeners)\r\n  File \"/apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1494, in _train_with_estimator_spec\r\n    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\r\n  File \"/apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/training/monitored_session.py\", line 754, in run\r\n    run_metadata=run_metadata)\r\n  File \"/apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/training/monitored_session.py\", line 1259, in run\r\n    run_metadata=run_metadata)\r\n  File \"/apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/training/monitored_session.py\", line 1360, in run\r\n    raise six.reraise(*original_exc_info)\r\n  File \"/apps/python-3.5.2/lib/python3.5/site-packages/six.py\", line 693, in reraise\r\n    raise value\r\n  File \"/apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/training/monitored_session.py\", line 1345, in run\r\n    return self._sess.run(*args, **kwargs)\r\n  File \"/apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/training/monitored_session.py\", line 1418, in run\r\n    run_metadata=run_metadata)\r\n  File \"/apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/training/monitored_session.py\", line 1176, in run\r\n    return self._sess.run(*args, **kwargs)\r\n  File \"/apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/client/session.py\", line 956, in run\r\n    run_metadata_ptr)\r\n  File \"/apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/client/session.py\", line 1180, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/client/session.py\", line 1359, in _do_run\r\n    run_metadata)\r\n  File \"/apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/client/session.py\", line 1384, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found.\r\n  (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\r\n\t [[node FeatureExtractor/MobilenetV2/Conv/Conv2D (defined at apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/framework/ops.py:1748) ]]\r\n\t [[total_loss/_9637]]\r\n  (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\r\n\t [[node FeatureExtractor/MobilenetV2/Conv/Conv2D (defined at apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/framework/ops.py:1748) ]]\r\n0 successful operations.\r\n0 derived errors ignored.\r\n\r\nOriginal stack trace for 'FeatureExtractor/MobilenetV2/Conv/Conv2D':\r\n  File \"home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/model_main.py\", line 109, in <module>\r\n    tf.app.run()\r\n  File \"apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/platform/app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"apps/python-3.5.2/lib/python3.5/site-packages/absl/app.py\", line 299, in run\r\n    _run_main(main, args)\r\n  File \"apps/python-3.5.2/lib/python3.5/site-packages/absl/app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/model_main.py\", line 105, in main\r\n    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])\r\n  File \"apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_estimator/python/estimator/training.py\", line 473, in train_and_evaluate\r\n    return executor.run()\r\n  File \"apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_estimator/python/estimator/training.py\", line 613, in run\r\n    return self.run_local()\r\n  File \"apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_estimator/python/estimator/training.py\", line 714, in run_local\r\n    saving_listeners=saving_listeners)\r\n  File \"apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 370, in train\r\n    loss = self._train_model(input_fn, hooks, saving_listeners)\r\n  File \"apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1161, in _train_model\r\n    return self._train_model_default(input_fn, hooks, saving_listeners)\r\n  File \"apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1191, in _train_model_default\r\n    features, labels, ModeKeys.TRAIN, self.config)\r\n  File \"apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1149, in _call_model_fn\r\n    model_fn_results = self._model_fn(features=features, **kwargs)\r\n  File \"home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/model_lib.py\", line 308, in model_fn\r\n    features[fields.InputDataFields.true_image_shape])\r\n  File \"home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/meta_architectures/ssd_meta_arch.py\", line 600, in predict\r\n    preprocessed_inputs)\r\n  File \"home/francesco.argentieri/ProjectThesis/tf-models/research/object_detection/models/ssd_mobilenet_v2_feature_extractor.py\", line 132, in extract_features\r\n    scope=scope)\r\n  File \"apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/contrib/framework/python/ops/arg_scope.py\", line 182, in func_with_args\r\n    return func(*args, **current_args)\r\n  File \"home/francesco.argentieri/ProjectThesis/tf-models/research/slim/nets/mobilenet/mobilenet_v2.py\", line 210, in mobilenet_base\r\n    base_only=True, **kwargs)\r\n  File \"apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/contrib/framework/python/ops/arg_scope.py\", line 182, in func_with_args\r\n    return func(*args, **current_args)\r\n  File \"home/francesco.argentieri/ProjectThesis/tf-models/research/slim/nets/mobilenet/mobilenet_v2.py\", line 184, in mobilenet\r\n    **kwargs)\r\n  File \"apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/contrib/framework/python/ops/arg_scope.py\", line 182, in func_with_args\r\n    return func(*args, **current_args)\r\n  File \"home/francesco.argentieri/ProjectThesis/tf-models/research/slim/nets/mobilenet/mobilenet.py\", line 366, in mobilenet\r\n    net, end_points = mobilenet_base(inputs, scope=scope, **mobilenet_args)\r\n  File \"apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/contrib/framework/python/ops/arg_scope.py\", line 182, in func_with_args\r\n    return func(*args, **current_args)\r\n  File \"home/francesco.argentieri/ProjectThesis/tf-models/research/slim/nets/mobilenet/mobilenet.py\", line 285, in mobilenet_base\r\n    net = opdef.op(net, **params)\r\n  File \"apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/contrib/framework/python/ops/arg_scope.py\", line 182, in func_with_args\r\n    return func(*args, **current_args)\r\n  File \"apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/contrib/layers/python/layers/layers.py\", line 1159, in convolution2d\r\n    conv_dims=2)\r\n  File \"apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/contrib/framework/python/ops/arg_scope.py\", line 182, in func_with_args\r\n    return func(*args, **current_args)\r\n  File \"apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/contrib/layers/python/layers/layers.py\", line 1057, in convolution\r\n    outputs = layer.apply(inputs)\r\n  File \"apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/util/deprecation.py\", line 324, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 1700, in apply\r\n    return self.__call__(inputs, *args, **kwargs)\r\n  File \"apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/layers/base.py\", line 548, in __call__\r\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\r\n  File \"apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 854, in __call__\r\n    outputs = call_fn(cast_inputs, *args, **kwargs)\r\n  File \"apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/autograph/impl/api.py\", line 234, in wrapper\r\n    return converted_call(f, options, args, kwargs)\r\n  File \"apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/autograph/impl/api.py\", line 439, in converted_call\r\n    return _call_unconverted(f, args, kwargs, options)\r\n  File \"apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/autograph/impl/api.py\", line 330, in _call_unconverted\r\n    return f(*args, **kwargs)\r\n  File \"apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/keras/layers/convolutional.py\", line 197, in call\r\n    outputs = self._convolution_op(inputs, self.kernel)\r\n  File \"apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/ops/nn_ops.py\", line 1134, in __call__\r\n    return self.conv_op(inp, filter)\r\n  File \"apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/ops/nn_ops.py\", line 639, in __call__\r\n    return self.call(inp, filter)\r\n  File \"apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/ops/nn_ops.py\", line 238, in __call__\r\n    name=self.name)\r\n  File \"apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/ops/nn_ops.py\", line 2010, in conv2d\r\n    name=name)\r\n  File \"apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/ops/gen_nn_ops.py\", line 1071, in conv2d\r\n    data_format=data_format, dilations=dilations, name=name)\r\n  File \"apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\r\n    attrs, op_def, compute_device)\r\n  File \"apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\r\n    op_def=op_def)\r\n  File \"apps/python-3.5.2/lib/python3.5/site-packages/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n```\r\n", "comments": ["@frank1789, Will it be possible to provide the minimum code snippet  which generates reported issue. Thanks!", "```\r\n#!usr/bin/sh\r\n\r\n##############################################################################\r\n# Download pre-trained model\r\n##############################################################################\r\necho $PWD\r\nremote_link_model=http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_coco_2018_03_29.tar.gz\r\ncurl -L $remote_link_model -o ssd_mobilenet_v2_coco.tar.gz\r\ntar -xvf ssd_mobilenet_v2_coco.tar.gz\r\nrm ssd_mobilenet_v2_coco.tar.gz\r\ncd ssd_mobilenet_v2_coco_2018_03_29\r\necho $PWD\r\nremote_config=https://raw.githubusercontent.com/frank1789/ProjectThesis/develop/models/ssd_mobilenet_v2_coco_2018_03_29/pipeline.config\r\ncurl -OL $remote_config\r\nrm checkpoint\r\nexport MODEL_DIR=$PROJECT_DIR/models/ssd_mobilenet_v2_coco_2018_03_29\r\ncd ..\r\ncd ..\r\necho $PWD\r\n\r\n##############################################################################\r\n# Running the Training Job\r\n##############################################################################\r\n\r\nexport PIPELINE_CONFIG_PATH=$MODEL_DIR/pipeline.config\r\nexport TF_RESEARCH_MODEL_DIR=$PROJECT_DIR/tf-models/research\r\n\r\nexport NUM_TRAIN_STEPS=50000\r\nexport SAMPLE_1_OF_N_EVAL_EXAMPLES=1\r\n\r\n# From the project/tf-models/research/ directory\r\n# Make sure you've updated PYTHONPATH\r\npython3 ${TF_API_DIR}/object_detection/model_main.py \\\r\n    --pipeline_config_path=${PIPELINE_CONFIG_PATH} \\\r\n    --model_dir=${MODEL_DIR} \\\r\n    --num_train_steps=${NUM_TRAIN_STEPS} \\\r\n    --sample_1_of_n_eval_examples=$SAMPLE_1_OF_N_EVAL_EXAMPLES \\\r\n    --alsologtostderr\r\n```", "At the moment I am unable to provide a snippet to repeat the error, I suggest running the whole project to understand how to solve the problem on both sides.\r\nIn fact I cannot operate directly on the cluster, but I will have to communicate the solution to the system that manages the cluster.\r\nThe directory indicated as _\"tf-models\"_ is git module deriving from the [Object Detection API](https://github.com/tensorflow/models/tree/master/research/object_detection).\r\n\r\nThanks in advance", "@frank1789 I think version mismatch is the root-cause. You have installed `TF1.15` through binary and those binaries are built using `cuda 10` where as you have installed `cuda9.0`. Two ways you can resolve this issue. \r\n1. Easy and Best Approach: uninstall `cuda9.0` and install `cuda10.0`\r\n2. Build `TF1.15` from source (not binary) so that, it uses `cuda9.0`\r\n\r\nThanks. Please close the issue if it is resolved. Thanks!", "@frank1789 Do you have any comments on my previous response. If this was resolved, please close the issue. Thanks!", "thanks for the support, I forwarded the suggested solution to those who manage HPC, currently I have not received a reply and I am waiting to try the script.\r\nI ask you to be patient as soon as I have news that I will comment or if everything will be fine, I will close the issue.\r\n", "@frank1789 Did you had time to check this issue? Thanks!", "I solicited the cluster manager, but I am still not getting a response and the error persists", "Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 34704, "title": "Program aborted after use tf.io.gfile.makedirs", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- TensorFlow installed from (source or binary): pip install tensorflow==1.14.0\r\n- TensorFlow version (use command below): 1.14.0\r\n- Python version: 3.6.8\r\n```\r\nLSB Version:\t:core-4.1-amd64:core-4.1-noarch\r\nDistributor ID:\tCentOS\r\nDescription:\tCentOS Linux release 7.6.1810 (Core) \r\nRelease:\t7.6.1810\r\nCodename:\tCore\r\n```\r\n\r\n\r\n**Describe the current behavior**\r\nI follow this [link](https://github.com/tensorflow/examples/blob/master/community/en/docs/deploy/hadoop.md) to set up Hadoop environment \r\nAfter execute below snippet of code, my terminal aborted \r\n\r\n**Describe the expected behavior**\r\nshould create test directory in hdfs file system\r\n\r\n**Code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\ntf.io.gfile.makedirs(\"hdfs://kevin0:8020/user/root/test\")\r\n```\r\n\r\n**Other info / logs**\r\n```\r\nFileSystem: loadFileSystems failed error:\r\n(unable to get root cause for java.lang.NoClassDefFoundError)\r\n(unable to get stack trace for java.lang.NoClassDefFoundError)\r\n#\r\n# A fatal error has been detected by the Java Runtime Environment:\r\n#\r\n#  SIGSEGV (0xb) at pc=0x00007f6be49c64f1, pid=61570, tid=0x00007f6ca07c0740\r\n#\r\n# JRE version: Java(TM) SE Runtime Environment (8.0_221-b11) (build 1.8.0_221-b11)\r\n# Java VM: Java HotSpot(TM) 64-Bit Server VM (25.221-b11 mixed mode linux-amd64 compressed oops)\r\n# Problematic frame:\r\n# C  [libhdfs.so+0xa4f1]\r\n#\r\n# Failed to write core dump. Core dumps have been disabled. To enable core dumping, try \"ulimit -c unlimited\" before starting Java again\r\n#\r\n# An error report file with more information is saved as:\r\n# /root/hs_err_pid61570.log\r\n#\r\n# If you would like to submit a bug report, please visit:\r\n#   http://bugreport.java.com/bugreport/crash.jsp\r\n# The crash happened outside the Java Virtual Machine in native code.\r\n# See problematic frame for where to report the bug.\r\n```\r\n", "comments": ["I resolve this issue, my latest Hadoop compile from source code that don't have libhdfs in lib/native, I download Hadoop-3.2.1, it works for me", "Thanks for sharing the solution. Closing this issue. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34704\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34704\">No</a>\n"]}, {"number": 34703, "title": "How to view CI build history of master branch", "body": "Hi team,\r\nHow can I view the CI build history in ci systems internal to Google or in Jenkins ?\r\nI did not find the url of the build history of tensorflow master branch.\r\nAny ideas ? Thank you.\r\n\r\n", "comments": ["From the raised pull request after approval from reviewer you may see build tests populating. If you click on the details link on any of the completed tests you should be able to see all results of CI builds.\r\nSee https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/ci_build#view-ci-results", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34703\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34703\">No</a>\n"]}, {"number": 34702, "title": "Where do i get the better accurate model for image segmentation?", "body": "Hi,I am using tensor flow lite for Image segmentation within my app.I am using the following gradle dependency for tensor flow lite\"    implementation 'org.tensorflow:tensorflow-lite:0.0.0-gpu-experimental'\".With this implementation the accuracy of the resultant cutout is not up to the mark .How can i improve the accuracy of image with tensor flow lite?And is there any pre-trained model other than deeplab v3+ for tensor flow.Please Help\r\n", "comments": ["Hi Charlize,\r\n\r\nFrom your question, it's unclear if the issue is with model accuracy or with the GPU implementation? Can you run your model on CPU and confirm whether you are getting the same accuracy or not.\r\n\r\nIf it's not the same, we can investigate why the GPU delegate results are different. (Please attach the model in that case.)\r\n\r\nDeepLab is currently the latest available image segmentation model.\r\n", "It has been 15 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "@charlizesmith \r\n\r\nAny update on this issue please. Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 34701, "title": "std::uniform_int_distribution<int8_t> is undefined in the C++17 standard, but TFLite violates this limitation.", "body": "As [the C++ reference](https://en.cppreference.com/w/cpp/numeric/random/uniform_int_distribution) mentioned, std::uniform_int_distribution<int8_t> is undefined in the C++17.\r\nTherefore microsoft visual C++ 2017 will give the following build error when the code includes [benchmark_tflite_model.cc #L496]( https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/tools/benchmark/benchmark_tflite_model.cc#L496).\r\n\r\nIn fact, the recent TFLite model benchmark couldn't build on windows as [my CI environment](https://dev.azure.com/mlops/tensorflow/_build/results?buildId=548&view=logs&j=e1e4dfe0-fc62-5ca1-9c02-b15972c8e9c4&t=9da95ac0-03a9-5448-4a9d-063bdd2c2605&l=1058) shows.\r\n\r\n```sh\r\nbazel build -c opt --verbose_failures //tensorflow/lite/tools/benchmark:benchmark_model\r\n```\r\n\r\n```\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\VC\\Tools\\MSVC\\14.16.27023\\include\\random(2401): error C2338: invalid template argument for uniform_int_distribution: N4659 29.6.1.1 [rand.req.genl]/1e requires one of short, int, long, long long, unsigned short, unsigned int, unsigned long, or unsigned long long\r\ntensorflow/lite/tools/benchmark/benchmark_tflite_model.cc(496): note: see reference to class template instantiation 'std::uniform_int_distribution<uint8_t>' being compiled\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\VC\\Tools\\MSVC\\14.16.27023\\include\\random(2401): error C2338: note: char, signed char, unsigned char, int8_t, and uint8_t are not allowed\r\n```\r\n\r\nWould you like to modify benchmark_tflite_model.cc?\r\n", "comments": ["@lrdxgm can you fix? We can just use a cast from the proper min/max range.", "Sure. On vacation, will be back on Wednesday.\n\nOn Mon, Dec 2, 2019, 9:05 AM Jared Duke <notifications@github.com> wrote:\n\n> @lrdxgm <https://github.com/lrdxgm> can you fix? We can just use a cast\n> from the proper min/max range.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/34701?email_source=notifications&email_token=AATL3TNWOIPXJRMHHARRLT3QWU545A5CNFSM4JS6CSCKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEFUFU2I#issuecomment-560487017>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AATL3TMHR2MCVEEA3EU3VY3QWU545ANCNFSM4JS6CSCA>\n> .\n>\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34701\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34701\">No</a>\n"]}]