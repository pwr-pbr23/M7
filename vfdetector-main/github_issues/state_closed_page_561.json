[{"number": 36869, "title": "Fixes typo (missing space) in padded_batch error", "body": "The error message used to read \"... if any component of its inputhas an unknown rank\"", "comments": []}, {"number": 36868, "title": "Cadence HiFi4 Neural Network (NN) Library", "body": "HI Pete,Nick,\r\n\r\nPlease take code changes for optimized Cadence NN HIFi 4 lib \r\n\r\nThanks,\r\nNiranjan\r\nOptimized HiFi4 NN library to run ops for TensorFlowLite for Micro\r\n\r\nSigned-off-by: Prasad Nikam <pnikam@cadence.com>\r\nSigned-off-by: Pramod Kumar Surana <pramods@cadence.com>\r\nSigned-off-by: Niranjan Yadla <nyadla@cadence.com>\r\nSigned-off-by: Ranjit Kumar Voruganti <ranjitv@cadence.com>", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F36868) for more info**.\n\n<!-- need_sender_cla -->", "@niruyadla thank you for your contribution, please sign CLA.", "We have submitted CLA and please release it our changes for merge", "Adding a comment to trigger CLA checking again.", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F36868) for more info**.\n\n<!-- ok -->", "@nyadla-sys small nit , can you also change wherever `context->ReportError` referenced to `TF_LITE_KERNEL_LOG` , thank you", "@nyadla-sys sorry got few more errors internally , can you please fix them "]}, {"number": 36867, "title": "Why i have same value in confusion matrix always 12% even after 17000 lerning rate?", "body": "Model after train don,t work and Confusion matrix have one column value other column 0\r\n", "comments": ["@konradqweleg,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here and also the TensorFlow version you are using. Thanks!", "I used the default train.py in  Speech commands project", "@konradqweleg,\r\nCould you please send a link of the project or share the notebook of your python code? Thanks!", "https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/speech_commands", "@konradqweleg,\r\nThis was the final output on running the above code. I have attached the complete log as a file.\r\n```\r\nINFO:tensorflow:Step 18000: Validation accuracy = 88.3% (N=4445)\r\nI0303 22:32:58.230043 139990098704192 train.py:289] Step 18000: Validation accuracy = 88.3% (N=4445)\r\nINFO:tensorflow:Saving to \"/tmp/speech_commands_train/conv.ckpt-18000\"\r\nI0303 22:32:58.230095 139990098704192 train.py:297] Saving to \"/tmp/speech_commands_train/conv.ckpt-18000\"\r\nINFO:tensorflow:set_size=4890\r\nI0303 22:32:58.251442 139990098704192 train.py:301] set_size=4890\r\nWARNING:tensorflow:Confusion Matrix:\r\n [[407   0   0   0   0   0   0   0   0   0   1   0]\r\n [  3 272   7   7  16  16  25  21  13   6   9  13]\r\n [  1   6 396   4   0   0   9   0   0   0   2   1]\r\n [  0   8   8 345   1  12   8   1   0   0   1  21]\r\n [  2   4   0   1 392   1   3   0   5   6   9   2]\r\n [  1  10   7  27   2 341   4   0   2   0   0  12]\r\n [  2   2  15   0   4   0 384   3   0   0   2   0]\r\n [  3  16   1   1   0   0  11 362   1   1   0   0]\r\n [  1   9   0   0   9   8   1   1 348  17   2   0]\r\n [  2   8   0   0  38   1   4   1  10 332   3   3]\r\n [  2   1   1   0  12   2   1   0   0   2 388   2]\r\n [  4  13   1  54   8  10   5   4   0   2   1 300]]\r\nW0303 22:33:23.295454 139990098704192 train.py:320] Confusion Matrix:\r\n [[407   0   0   0   0   0   0   0   0   0   1   0]\r\n [  3 272   7   7  16  16  25  21  13   6   9  13]\r\n [  1   6 396   4   0   0   9   0   0   0   2   1]\r\n [  0   8   8 345   1  12   8   1   0   0   1  21]\r\n [  2   4   0   1 392   1   3   0   5   6   9   2]\r\n [  1  10   7  27   2 341   4   0   2   0   0  12]\r\n [  2   2  15   0   4   0 384   3   0   0   2   0]\r\n [  3  16   1   1   0   0  11 362   1   1   0   0]\r\n [  1   9   0   0   9   8   1   1 348  17   2   0]\r\n [  2   8   0   0  38   1   4   1  10 332   3   3]\r\n [  2   1   1   0  12   2   1   0   0   2 388   2]\r\n [  4  13   1  54   8  10   5   4   0   2   1 300]]\r\nWARNING:tensorflow:Final test accuracy = 87.3% (N=4890)\r\n```\r\n[output.txt](https://github.com/tensorflow/tensorflow/files/4287692/output.txt)\r\n\r\nCould you please compare this output with yours and if the issue persists, send us the reproducible code with the output. Thanks!", "Any updates regarding this issue? Thanks!", "So My final output is  same to\r\n [[407   0   0   0   0   0   0   0   0   0  0   0]\r\n [  272  0  0  0  0  0  0   0   0  0   0   0]\r\neverywhere \r\nI will give the results tomorrow\r\n", "@konradqweleg,\r\nAny updates regarding the results? Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 36866, "title": "missing ops", "body": "**System information**\r\n- MacOS Mojave: 10.14.6\r\n- TensorFlow installed from binary\r\n- TensorFlow version: 2.1.0\r\n\r\n\r\n**Provide the text output from tflite_convert**\r\n\r\n```\r\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: CONV_2D, FULLY_CONNECTED, RESHAPE, SOFTMAX, STRIDED_SLICE, TANH. Here is a list of operators for which you will need custom implementations: TensorListFromTensor, TensorListReserve, TensorListStack, While.\r\n```\r\n\r\nAlso, please include a link to a GraphDef or the model if possible.\r\n\r\n**Any other info / logs**\r\n\r\nFull output:\r\n```\r\n2020-02-18 12:08:47.613890: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2020-02-18 12:08:47.641459: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb45f7d55d0 executing computations on platform Host. Devices:\r\n2020-02-18 12:08:47.641499: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\r\nWARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\r\nW0218 12:08:48.275663 4679718336 hdf5_format.py:198] Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\r\n2020-02-18 12:08:48.596718: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)\r\n2020-02-18 12:08:48.596828: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\r\n2020-02-18 12:08:48.620729: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:716] Optimization results for grappler item: graph_to_optimize\r\n2020-02-18 12:08:48.620755: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   function_optimizer: Graph size after: 125 nodes (0), 151 edges (0), time = 7.053ms.\r\n2020-02-18 12:08:48.620760: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   function_optimizer: Graph size after: 125 nodes (0), 151 edges (0), time = 3.511ms.\r\n2020-02-18 12:08:48.620765: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:716] Optimization results for grappler item: sequential_gru_while_cond_1874\r\n2020-02-18 12:08:48.620769: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   function_optimizer: function_optimizer did nothing. time = 0.005ms.\r\n2020-02-18 12:08:48.620773: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-02-18 12:08:48.620778: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:716] Optimization results for grappler item: sequential_gru_while_body_1875\r\n2020-02-18 12:08:48.620871: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2020-02-18 12:08:48.620884: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-02-18 12:08:48.704099: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)\r\n2020-02-18 12:08:48.704194: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\r\n2020-02-18 12:08:48.742007: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:716] Optimization results for grappler item: graph_to_optimize\r\n2020-02-18 12:08:48.742026: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   constant folding: Graph size after: 60 nodes (-5), 70 edges (-9), time = 19.624ms.\r\n2020-02-18 12:08:48.742030: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   constant folding: Graph size after: 60 nodes (0), 70 edges (0), time = 4.102ms.\r\n2020-02-18 12:08:48.742033: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:716] Optimization results for grappler item: sequential_gru_while_body_1875_frozen\r\n2020-02-18 12:08:48.742035: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   constant folding: Graph size after: 79 nodes (0), 98 edges (0), time = 1.601ms.\r\n2020-02-18 12:08:48.742038: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   constant folding: Graph size after: 79 nodes (0), 98 edges (0), time = 1.559ms.\r\n2020-02-18 12:08:48.742040: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:716] Optimization results for grappler item: sequential_gru_while_cond_1874_frozen\r\n2020-02-18 12:08:48.742144: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   constant folding: Graph size after: 14 nodes (0), 4 edges (0), time = 0.29ms.\r\n2020-02-18 12:08:48.742148: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   constant folding: Graph size after: 14 nodes (0), 4 edges (0), time = 0.202ms.\r\nTraceback (most recent call last):\r\n  File \"/usr/local/bin/tflite_convert\", line 10, in <module>\r\n    sys.exit(main())\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/lite/python/tflite_convert.py\", line 515, in main\r\n    app.run(main=run_main, argv=sys.argv[:1])\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/platform/app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"/usr/local/lib/python3.7/site-packages/absl/app.py\", line 299, in run\r\n    _run_main(main, args)\r\n  File \"/usr/local/lib/python3.7/site-packages/absl/app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/lite/python/tflite_convert.py\", line 502, in run_main\r\n    _convert_tf2_model(tflite_flags)\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/lite/python/tflite_convert.py\", line 221, in _convert_tf2_model\r\n    tflite_model = converter.convert()\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/lite/python/lite.py\", line 446, in convert\r\n    **converter_kwargs)\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/lite/python/convert.py\", line 449, in toco_convert_impl\r\n    enable_mlir_converter=enable_mlir_converter)\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/lite/python/convert.py\", line 200, in toco_convert_protos\r\n    raise ConverterError(\"See console for info.\\n%s\\n%s\\n\" % (stdout, stderr))\r\ntensorflow.lite.python.convert.ConverterError: See console for info.\r\n2020-02-18 12:08:52.222650: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2020-02-18 12:08:52.242018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd921cfa1b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-02-18 12:08:52.242031: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2020-02-18 12:08:52.271859: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListFromTensor\r\n2020-02-18 12:08:52.271902: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21\r\n2020-02-18 12:08:52.271961: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListReserve\r\n2020-02-18 12:08:52.271971: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21\r\n2020-02-18 12:08:52.272009: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: While\r\n2020-02-18 12:08:52.272030: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21\r\n2020-02-18 12:08:52.272035: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21\r\n2020-02-18 12:08:52.272059: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListStack\r\n2020-02-18 12:08:52.274986: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 26 operators, 67 arrays (0 quantized)\r\n2020-02-18 12:08:52.279519: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 26 operators, 67 arrays (0 quantized)\r\n2020-02-18 12:08:52.281200: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 22 operators, 65 arrays (0 quantized)\r\n2020-02-18 12:08:52.281569: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 2: 21 operators, 63 arrays (0 quantized)\r\n2020-02-18 12:08:52.282014: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 3: 12 operators, 45 arrays (0 quantized)\r\n2020-02-18 12:08:52.282246: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 4: 11 operators, 43 arrays (0 quantized)\r\n2020-02-18 12:08:52.282451: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 11 operators, 43 arrays (0 quantized)\r\n2020-02-18 12:08:52.282591: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 11 operators, 43 arrays (0 quantized)\r\n2020-02-18 12:08:52.282698: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Identify nearest upsample.: 11 operators, 43 arrays (0 quantized)\r\n2020-02-18 12:08:52.282938: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 2304 bytes, theoretical optimal value: 1920 bytes.\r\n2020-02-18 12:08:52.283040: I tensorflow/lite/toco/toco_tooling.cc:471] Number of parameters: 401825\r\n2020-02-18 12:08:52.287920: E tensorflow/lite/toco/toco_tooling.cc:498] We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md\r\n and pasting the following:\r\n\r\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: CONV_2D, FULLY_CONNECTED, RESHAPE, SOFTMAX, STRIDED_SLICE, TANH. Here is a list of operators for which you will need custom implementations: TensorListFromTensor, TensorListReserve, TensorListStack, While.\r\nTraceback (most recent call last):\r\n  File \"/Users/grady/work/tensorflow/venv/bin/toco_from_protos\", line 8, in <module>\r\n    sys.exit(main())\r\n  File \"/Users/grady/work/tensorflow/venv/lib/python3.7/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 93, in main\r\n    app.run(main=execute, argv=[sys.argv[0]] + unparsed)\r\n  File \"/Users/grady/work/tensorflow/venv/lib/python3.7/site-packages/tensorflow_core/python/platform/app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"/usr/local/lib/python3.7/site-packages/absl/app.py\", line 299, in run\r\n    _run_main(main, args)\r\n  File \"/usr/local/lib/python3.7/site-packages/absl/app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"/Users/grady/work/tensorflow/venv/lib/python3.7/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 56, in execute\r\n    enable_mlir_converter)\r\nException: We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md\r\n and pasting the following:\r\n\r\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: CONV_2D, FULLY_CONNECTED, RESHAPE, SOFTMAX, STRIDED_SLICE, TANH. Here is a list of operators for which you will need custom implementations: TensorListFromTensor, TensorListReserve, TensorListStack, While.\r\n```\r\n\r\n", "comments": ["@steven807,You may try converting your model using `Select TensorFlow Ops`\r\nPlease take a look at similar [#35605](https://github.com/tensorflow/tensorflow/issues/35605#issuecomment-571737987) issue comment. Thanks!", "@steven807, any update?", "Sorry, I didn't realize you were waiting a response.  I just tried running the converter (from the command line) as:\r\n`tflite_convert --output_file=/tmp/foo.tflite --keras_model_file=model.hdf5 --target_ops=`_options_\r\nwith _options_ as all three recommended possibilities:\r\n\r\n* TFLITE_BUILTINS\r\n* TFLITE_BUILTINS,SELECT_TF_OPS\r\n* SELECT_TF_OPS\r\n\r\nand got the same result in each case:\r\n`Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: CONV_2D, FULLY_CONNECTED, RESHAPE, SOFTMAX, STRIDED_SLICE, TANH. Here is a list of operators for which you will need custom implementations: TensorListFromTensor, TensorListReserve, TensorListStack, While.`", "Set`experimental_new_converter` flag to `True` to for `implementations: TensorListFromTensor, TensorListReserve, TensorListStack, While`.\r\nSee https://www.tensorflow.org/api_docs/python/tf/lite/TFLiteConverter?version=nightly#attributes\r\n```python\r\n# Assuming converting a tf.Keras model to a TensorFlow Lite model.\r\nconverter = lite.TFLiteConverter.from_keras_model(model)\r\nconverter.experimental_new_converter = True  #Set`experimental_new_converter` flag to `True`\r\ntflite_model = converter.convert()\r\n```", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36866\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36866\">No</a>\n"]}, {"number": 36865, "title": "TensorFlow Lite Op Request", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (or github SHA if from source): 2.1.0\r\n\r\n**Code** (https://www.tensorflow.org/lite/performance/post_training_quantization#weight_quantization)\r\n```python\r\nimport tensorflow as tf\r\nsaved_model_dir = '/opt/model/my_model'\r\nconverter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\r\nconverter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\r\ntflite_quant_model = converter.convert()\r\n```\r\n\r\n**Provide the text output from tflite_convert**\r\n\r\n```\r\n2020-02-18 19:24:22.977058: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer.so.6\r\n2020-02-18 19:24:22.978737: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer_plugin.so.6\r\n2020-02-18 19:24:24.105775: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2020-02-18 19:24:24.128869: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300070000 Hz\r\n2020-02-18 19:24:24.129146: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5567cc4fa770 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-02-18 19:24:24.129174: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2020-02-18 19:24:24.131587: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\r\n2020-02-18 19:24:24.187720: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-02-18 19:24:24.188106: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5567cc57c4f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\r\n2020-02-18 19:24:24.188130: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla M60, Compute Capability 5.2\r\n2020-02-18 19:24:24.188279: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-02-18 19:24:24.188558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \r\npciBusID: 0000:00:1e.0 name: Tesla M60 computeCapability: 5.2\r\ncoreClock: 1.1775GHz coreCount: 16 deviceMemorySize: 7.44GiB deviceMemoryBandwidth: 149.31GiB/s\r\n2020-02-18 19:24:24.188610: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\r\n2020-02-18 19:24:24.188649: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\r\n2020-02-18 19:24:24.189979: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\r\n2020-02-18 19:24:24.190280: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\r\n2020-02-18 19:24:24.192086: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\r\n2020-02-18 19:24:24.193471: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\r\n2020-02-18 19:24:24.193524: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2020-02-18 19:24:24.193599: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-02-18 19:24:24.193921: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-02-18 19:24:24.194179: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\r\n2020-02-18 19:24:24.194214: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\r\n2020-02-18 19:24:24.541245: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-02-18 19:24:24.541292: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 \r\n2020-02-18 19:24:24.541301: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N \r\n2020-02-18 19:24:24.541515: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-02-18 19:24:24.541855: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-02-18 19:24:24.542145: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 159 MB memory) -> physical GPU (device: 0, name: Tesla M60, pci bus id: 0000:00:1e.0, compute capability: 5.2)\r\n2020-02-18 19:24:24.589548: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListFromTensor\r\n2020-02-18 19:24:24.589614: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21\r\n2020-02-18 19:24:24.589679: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListFromTensor\r\n2020-02-18 19:24:24.589696: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21\r\n2020-02-18 19:24:24.589715: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListReserve\r\n2020-02-18 19:24:24.589729: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21\r\n2020-02-18 19:24:24.589746: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListReserve\r\n2020-02-18 19:24:24.589759: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21\r\n2020-02-18 19:24:24.589789: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: While\r\n2020-02-18 19:24:24.589820: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21\r\n2020-02-18 19:24:24.589832: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21\r\n2020-02-18 19:24:24.589853: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: While\r\n2020-02-18 19:24:24.589876: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21\r\n2020-02-18 19:24:24.589888: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21\r\n2020-02-18 19:24:24.589899: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListStack\r\n2020-02-18 19:24:24.589916: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListStack\r\n2020-02-18 19:24:24.592612: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 79 operators, 169 arrays (0 quantized)\r\n2020-02-18 19:24:24.593771: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 79 operators, 169 arrays (0 quantized)\r\n2020-02-18 19:24:24.595059: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 44 operators, 121 arrays (0 quantized)\r\n2020-02-18 19:24:24.595863: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 44 operators, 121 arrays (0 quantized)\r\n2020-02-18 19:24:24.596433: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 44 operators, 121 arrays (0 quantized)\r\n2020-02-18 19:24:24.596939: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Identify nearest upsample.: 44 operators, 121 arrays (0 quantized)\r\n2020-02-18 19:24:24.597844: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 18048 bytes, theoretical optimal value: 12032 bytes.\r\n2020-02-18 19:24:24.598043: I tensorflow/lite/toco/toco_tooling.cc:471] Number of parameters: 5372617\r\n2020-02-18 19:24:24.598566: E tensorflow/lite/toco/toco_tooling.cc:498] We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md\r\n and pasting the following:\r\n\r\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime. \r\nIf those are native TensorFlow operators, you might be able to use the extended runtime by \r\npassing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS \r\nwhen calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them \r\nyou can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True \r\nwhen calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: \r\nADD, CONCATENATION, CONV_2D, EXPAND_DIMS, FULLY_CONNECTED, GATHER, \r\nMAX_POOL_2D, MUL, REDUCE_MAX, RESHAPE, REVERSE_V2, SOFTMAX, SQUEEZE, \r\nTRANSPOSE. Here is a list of operators for which you will need custom implementations:\r\nTensorListFromTensor, TensorListReserve, TensorListStack, While.\r\n\r\nTraceback (most recent call last):\r\n  File \"/opt/anaconda3/bin/toco_from_protos\", line 8, in <module>\r\n    sys.exit(main())\r\n  File \"/opt/anaconda3/lib/python3.6/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 93, in main\r\n    app.run(main=execute, argv=[sys.argv[0]] + unparsed)\r\n  File \"/opt/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/platform/app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"/opt/anaconda3/lib/python3.6/site-packages/absl/app.py\", line 299, in run\r\n    _run_main(main, args)\r\n  File \"/opt/anaconda3/lib/python3.6/site-packages/absl/app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"/opt/anaconda3/lib/python3.6/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 56, in execute\r\n    enable_mlir_converter)\r\n```\r\n", "comments": ["Solved:\r\n\r\n**Updated code:**\r\n\r\n```python\r\nimport tensorflow as tf\r\nsaved_model_dir = '/opt/model/my_model'\r\nconverter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\r\nconverter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\r\n\r\n# update\r\nconverter.allow_custom_ops = True\r\n\r\ntflite_quant_model = converter.convert()\r\n```"]}, {"number": 36864, "title": "Tensorflow 2.1.0 is not using GPU", "body": "**System information**\r\n- OS Platform: - Google Cloud Linux Ubuntu 16.04 \r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version: 2.1\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10.01\r\n- GPU model and memory: Tesla P100, 16GB\r\n\r\nWhen I train any model using TensorFlow using 2.1 it runs on CPU only even it shows on GPU, but GPU utilization becomes always 0% and CPU utilization is very high. \r\n\r\n", "comments": ["@akanyaani \r\nIt looks like you haven't used a template to create this issue. Please resubmit your issue using a template from [here](https://github.com/tensorflow/tensorflow/issues/new/choose). We ask users to use the template because it reduces overall time to resolve a new issue by avoiding extra communication to get to the root of the issue. We will close this issue in lieu of the new one you will create from the template. Thank you for your cooperation.\r\n\r\n\r\nCould you please elaborate the issue faced, share the steps just before you encountered the error/ share simple stand alone code for us to replicate in our environment. Also please share error logs for us to help you resolve the issue.\r\n", "Hi @Saduf2019 \r\n\r\nI updated the issue using the format which you suggested.\r\n\r\nThanks", "@akanyaani please share a simple stand alone code for us to replicate the issue faced by you, along with the error logs.", "@akanyaani\r\n please update on the above comment", "I have the same issue, in that TensorFlow recognises my GPU, but does not utilise it when I run scripts. I have been stuck on this for days, any help would be greatly appreciated.", "@georgeparry12 \r\nplease share a simple stand alone code for us to replicate the issue faced by you, along with the error logs.", "@akanyaani \r\nAutomatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36864\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36864\">No</a>\n", "@Saduf2019 \r\n\r\nI have the same issue.\r\nQuick note: I'm fairly new to both Python and Tensorflow. It might be just an issue on my side. Feel free to point it out.\r\n\r\n**Specs:**\r\n* OS Platform: Windows 10 Pro Version 1903\r\n* TensorFlow installed from (source or binary): binary\r\n* TensorFlow version: 2.1\r\n* Python version: 3.7.4\r\n* Bazel version (if compiling from source): /\r\n* GCC/Compiler version (if compiling from source): /\r\n* CUDA/cuDNN version: 10.02\r\n* GPU model and memory: GeForce GTX 1050 Ti with Max-Q Design, 4GB\r\n\r\n**Sample code:** \r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nprint(tf.__version__)                         # -> 2.1.0\r\nprint(tf.config.list_physical_devices('GPU')) # -> [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\r\nprint(tf.test.is_built_with_cuda())           # -> True\r\n\r\n@tf.function\r\ndef test(a, b):\r\n  iteration = tf.constant(0)\r\n  c = a ** b\r\n  while tf.math.less(iteration, 10000):\r\n    c = a ** b\r\n    iteration = tf.math.add(iteration, 1)\r\n  return c\r\n\r\na = tf.constant(np.random.randint(1, 100, (100, 100, 100)))\r\nb = tf.constant(np.random.randint(1, 100, (100, 100, 100)))\r\n\r\nwith tf.device('/GPU:0'):\r\n  c = test(a, b)\r\n```\r\n\r\n**Output:**\r\n```\r\n2020-03-12 13:47:02.007394: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n2.1.0\r\n2020-03-12 13:47:08.040305: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll\r\n2020-03-12 13:47:08.069849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \r\npciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti with Max-Q Design computeCapability: 6.1\r\ncoreClock: 1.4175GHz coreCount: 6 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 104.43GiB/s\r\n2020-03-12 13:47:08.070446: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n2020-03-12 13:47:08.077507: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll\r\n2020-03-12 13:47:08.084393: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll\r\n2020-03-12 13:47:08.086996: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll\r\n2020-03-12 13:47:08.094550: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll\r\n2020-03-12 13:47:08.098863: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll\r\n2020-03-12 13:47:08.113160: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\r\n2020-03-12 13:47:08.114555: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\r\n[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\r\nTrue\r\n2020-03-12 13:47:08.130597: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\n2020-03-12 13:47:08.132545: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \r\npciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti with Max-Q Design computeCapability: 6.1\r\ncoreClock: 1.4175GHz coreCount: 6 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 104.43GiB/s\r\n2020-03-12 13:47:08.133135: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n2020-03-12 13:47:08.133426: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll\r\n2020-03-12 13:47:08.133703: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll\r\n2020-03-12 13:47:08.133978: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll\r\n2020-03-12 13:47:08.134255: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll\r\n2020-03-12 13:47:08.134537: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll\r\n2020-03-12 13:47:08.134813: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\r\n2020-03-12 13:47:08.135979: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\r\n2020-03-12 13:47:09.025458: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-03-12 13:47:09.025762: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 \r\n2020-03-12 13:47:09.025944: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N \r\n2020-03-12 13:47:09.027095: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2992 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n```", "Restart the machine after installing tensorflow gpu it will work because in case some previous version of cuda is there there may be some temp file  causing that.Restarting will make it work.\r\nI was having the same issue.after restrt the output.\r\n![image](https://user-images.githubusercontent.com/20940800/81128154-0ada5500-8f5e-11ea-9f4d-8d9f9fc8a159.png)\r\n\r\n"]}, {"number": 36863, "title": "trouble importing tensorflow_hub", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Microsoft Windows 10 pro\r\n- TensorFlow installed from (source or binary): binary (?) pip install\r\n- TensorFlow version: tensorflow - 2.1.0,   tensorflow-hub       0.7.0 \r\n- Python version: 3.7.6\r\n- Installed using virtualenv? pip? conda?: Installed using pip within virtualenv.\r\n\r\n\r\n**Describe the problem**\r\nCannot import tensorflow_hub due to the error in the output below. tensorflow_hub is installed successfully and tensorflow is able to import.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nimport tensorflow_hub as hub\r\n\r\n**Any other info / logs**\r\n\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\n```ImportError                               Traceback (most recent call last)\r\n~\\AppData\\Local\\Continuum\\miniconda3\\envs\\pya\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py in <module>\r\n     57 \r\n---> 58   from tensorflow.python.pywrap_tensorflow_internal import *\r\n     59 \r\n\r\n~\\AppData\\Local\\Continuum\\miniconda3\\envs\\pya\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py in <module>\r\n     27             return _mod\r\n---> 28     _pywrap_tensorflow_internal = swig_import_helper()\r\n     29     del swig_import_helper\r\n\r\n~\\AppData\\Local\\Continuum\\miniconda3\\envs\\pya\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py in swig_import_helper()\r\n     23             try:\r\n---> 24                 _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n     25             finally:\r\n\r\n~\\AppData\\Local\\Continuum\\miniconda3\\envs\\pya\\lib\\imp.py in load_module(name, file, filename, details)\r\n    241         else:\r\n--> 242             return load_dynamic(name, filename, file)\r\n    243     elif type_ == PKG_DIRECTORY:\r\n\r\n~\\AppData\\Local\\Continuum\\miniconda3\\envs\\pya\\lib\\imp.py in load_dynamic(name, path, file)\r\n    341             name=name, loader=loader, origin=path)\r\n--> 342         return _load(spec)\r\n    343 \r\n\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nImportError                               Traceback (most recent call last)\r\n<ipython-input-22-85533c25c7ee> in <module>\r\n----> 1 import tensorflow_hub as hub\r\n      2 #import tensorflow as tf\r\n      3 \r\n      4 #elmo = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=True)\r\n\r\n~\\AppData\\Local\\Continuum\\miniconda3\\envs\\pya\\lib\\site-packages\\tensorflow_hub\\__init__.py in <module>\r\n     21 from absl import logging\r\n     22 from distutils.version import LooseVersion\r\n---> 23 import tensorflow as tf\r\n     24 \r\n     25 # pylint: disable=g-import-not-at-top\r\n\r\n~\\AppData\\Local\\Continuum\\miniconda3\\envs\\pya\\lib\\site-packages\\tensorflow\\__init__.py in <module>\r\n     39 import sys as _sys\r\n     40 \r\n---> 41 from tensorflow.python.tools import module_util as _module_util\r\n     42 from tensorflow.python.util.lazy_loader import LazyLoader as _LazyLoader\r\n     43 \r\n\r\n~\\AppData\\Local\\Continuum\\miniconda3\\envs\\pya\\lib\\site-packages\\tensorflow\\python\\__init__.py in <module>\r\n     48 import numpy as np\r\n     49 \r\n---> 50 from tensorflow.python import pywrap_tensorflow\r\n     51 from tensorflow.python import _pywrap_utils\r\n     52 from tensorflow.python import _pywrap_tfprof\r\n\r\n~\\AppData\\Local\\Continuum\\miniconda3\\envs\\pya\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py in <module>\r\n     67 for some common reasons and solutions.  Include the entire stack trace\r\n     68 above this error message when asking for help.\"\"\" % traceback.format_exc()\r\n---> 69   raise ImportError(msg)\r\n     70 \r\n     71 # pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\r\n\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\myname\\AppData\\Local\\Continuum\\miniconda3\\envs\\pya\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\myname\\AppData\\Local\\Continuum\\miniconda3\\envs\\pya\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\myname\\AppData\\Local\\Continuum\\miniconda3\\envs\\pya\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\myname\\AppData\\Local\\Continuum\\miniconda3\\envs\\pya\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\myname\\AppData\\Local\\Continuum\\miniconda3\\envs\\pya\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.```\r\n\r\n\r\n", "comments": ["@mshmsh1234 \r\nWhat is make/model of your cpu?. Does your cpu supports AVX instructions sets.Thanks!\r\n\r\nMake sure to download the latest microsoft visual c++ redistributable from here.\r\n Make sure if there is a library that is in a different location/not installed on your system that cannot be loaded.Also, please follow the instructions from Tensorflow website.\r\n\r\nPlease, refer #36167 and see if it helps you. Thanks!\r\nAlso please include \"import tensorflow as tf\" in your code and let us know if it helps resolve the issue.", "@mshmsh1234\r\nplease update on the above comment.", "@mshmsh1234 \r\nAutomatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36863\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36863\">No</a>\n"]}, {"number": 36862, "title": "[Features] DLPack functions", "body": "Related discussion: https://github.com/tensorflow/community/pull/180\r\nFinished Functionality:\r\n- `TFE_ToDlpackCapsule` and `TFE_FromDlpackCapsule`\r\n\r\nToDLPack\r\n```python\r\nimport tensorflow as tf \r\na = tf.constant([1,20])\r\nfrom tensorflow.python import pywrap_tfe\r\ncap = pywrap_tfe.TFE_ToDlpackCapsule(a)\r\n\r\nfrom torch.utils.dlpack import from_dlpack \r\n\r\nth_tensor = from_dlpack(cap) # works well\r\n```\r\n\r\nFromDLPack\r\n```python\r\nimport torch as th\r\nfrom torch.utils.dlpack import to_dlpack \r\n\r\na = th.tensor([1,5,2])\r\ncap = to_dlpack(a)\r\n\r\nimport tensorflow as tf \r\nfrom tensorflow.python import pywrap_tfe\r\n\r\ntf_tensor = pywrap_tfe.TFE_FromDlpackCapsule(cap)\r\n```\r\n\r\nThings welcome ideas and TODO:\r\n- Tests: how to test DLPack in TF's test system? Just test only TF<->cap<->TF? How to test Interoperability with other framework? And seems hard to test C++ API, can I only to Python Test?\r\n- Device Type: What's custom device? How is this related to DLPack's device flag? How about AMD's GPU?\r\n- Whether TF's Tensor has strides and byte offsets? \r\n- Naming: How should I name the API? `tf.to_dlpack`? or make it under some sub namespaces?\r\n\r\nAnd I have to say I'm not familiar with TF's codebase, but I tried to make it consistent with other codes as much as possible. Please feel free to point out any misuse in my codes. ", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F36862) for more info**.\n\n<!-- need_author_cla -->", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F36862) for more info**.\n\n<!-- ok -->", "> * Tests: how to test DLPack in TF's test system? Just test only TF<->cap<->TF? How to test Interoperability with other framework? And seems hard to test C++ API, can I only to Python Test?\r\n\r\nA might relevant question is shall we test on TF 1.0? Such discussion seems to be missing in the RFC. Is the current solution applicable to TF 1.0?", "@jermainewang this is a PR to the TF repo and we're not cutting any new releases of TF 1.x from this repo, so no need to support 1.x.", "I've addressed the comment above. Feel free to leave more suggestions.", "I just remembered another issue, that the alignment requirement is not checked in `TFE_NewTensorHandleFromDeviceMemory`. Based on our previous test, gather op on CPU sometimes may failed due to the misalignment. Other than that, in most cases it works fine even with misalignment.", "Addressed the issues above", "Addressed issue above", "Fixed the python symbol problem. Now it's available at `tf.experimental.dlpack.to_dlpack` and `tf.experimental.dlpack.from_dlpack`", "One potential bug I found is that tf didn't initialize gpu device when `import tensorflow as tf`. Therefore if directly call `from_dlpack`, there will raise error `Unhandled exception in event loop:`. It works well if the device is already initialized. Is there any tensorflow api to do the initialization? ", "Could you explain more? TF should not be initializing the GPUs `import tensorflow as tf` this in because we need to give an opportunity to users to call the various configuration APIs in `tf.config` prior to initialization. We right now initialize the GPUs implicitly as part of executing the first op or creating a tensor.", "@jaingaurav It didn't show more information other than `Unhandled exception in event loop`. And what I'm thinking is just to mention it in the documentation, that you need to initialize the device before using dlpack. Is there any API to ensure the device readiness? Or just say user could execute something like `with tf.device(\"gpu:0\"): tf.constant([1.1])` to initialize it?", "> And what I'm thinking is just to mention it in the documentation, that you need to initialize the device before using dlpack.\r\n\r\nSince this is a documentation change, I'd suggest doing that in a separate PR that we can land separately.", "I've fixed the pylint error and updated the golden rule prototxt. Hope this could fixed the ci error above.", "Hi,\r\n\r\nI already manually merged this PR at https://github.com/tensorflow/tensorflow/commit/9cd1a63a74655a95bf7036248a6a8b328d4a2f68 since I didn't want to wait for a round-trip.  I fixed the lint and other minor issues myself.", "Thanks and glad to see this merged! When will tf release 2.2?", "> Thanks and glad to see this merged! When will tf release 2.2?\r\n\r\nYes, unless we have to roll it back for some reason.", "Awesome news, and great work everyone.  I've merged the RFC changes as well.  Looking forward to seeing this in 2.2!  We should coordinate some press around this.  Is there an expected release date you can share?", "> Looking forward to seeing this in 2.2! We should coordinate some press around this. Is there an expected release date you can share?\r\n\r\nCC @goldiegadde @wolffg ", "> > Looking forward to seeing this in 2.2! We should coordinate some press around this. Is there an expected release date you can share?\r\n> \r\n> CC @goldiegadde @wolffg\r\n\r\nAny word here?  We've got our Tensorflow pipeline and accelerated tabular dataloader fully working using dlpack now.  We've got plans to share this in a blog post.  Not sure the timing of that but we would love to coordinate promotion if possible."]}, {"number": 36861, "title": "saves everything: The optimizer configuration... it is not able to save TensorFlow optimizers", "body": "\r\n## URL(s) with the issue: \r\nhttps://www.tensorflow.org/tutorials/keras/save_and_load\r\n\r\n## Description of issue (what needs changing):\r\n\r\nThe first reference to \"optimizer configuration\" is unqualified.\r\nThe second reference to \"optimizers\" is kind of qualified with \"(from tf.train)\".\r\nDoes this mean, tf.keras.optimizer states are stored but not tf.optimizer or does this mean no optimizer states are stored?\r\n\r\nfull text as follows:\r\n\r\n```\r\nThis technique saves everything:\r\n\r\n- The weight values\r\n- The model's configuration(architecture)\r\n- The optimizer configuration\r\n\r\nKeras saves models by inspecting the architecture. Currently, it is not able to save TensorFlow optimizers (from tf.train). When using those you will need to re-compile the model after loading, and you will lose the state of the optimizer.\r\n```", "comments": ["@johngrabner Correct. tf.keras.optimizer (v2 optimizers) states are stored but not tf.optimizer (v1 optimizers) as they are not compatible with `checkpoints`. I am updating the tutorial. May be check tomorrow and let me know if anything is not clear to you. Thanks!", "@jvishnuvardhan and @johngrabner , Please close this issue if above PR has included what you wanted.", "thanks a lot."]}, {"number": 36860, "title": "Tensorflow 2.0.0 - DLL load failed - windows cpu", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 64 bit\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:  n/a\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version: 2.0.0\r\n- Python version: 3.7.6\r\n- Installed using virtualenv? pip? conda?:  pip and conda\r\n- Bazel version (if compiling from source): n/a\r\n- GCC/Compiler version (if compiling from source):  n/a\r\n- CUDA/cuDNN version:  n/a\r\n- GPU model and memory:  n/a\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nInstallation of TensorFlow 2.0.0 using pip was successful, but TensorFlow import failed.\r\nOn the contrary, installation of TensorFlow 2.0.0 using conda was successful and in addition TensorFlow import was successful.\r\n**Why does conda env work fine but pip env don't?**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nI created 2 conda environments: one for conda release and the other for pip release, both dedicated to tensorflow 2.0.0. \r\n\r\n1. tensorflow2_0_conda environment:\r\nconda installation using\r\n`conda install python=3.7 tensorflow=2.0`\r\n\r\n2. tensorflow2_0_pip environment:\r\npip installation using\r\n`conda install python=3.7`\r\n`pip install tensorflow==2.0.0`\r\n\r\nBoth installations completed without any error.\r\n\r\nImport test:\r\n`python -c \"import tensorflow as tf\"`\r\n\r\nad 1) conda env works fine\r\nad 2) pip env failed with error message (detail see logs entry)\r\n`ImportError: DLL load failed ...`\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n```\r\n(tensorflow2_0_pip)>python -c \"import tensorflow as tf\"\r\nTraceback (most recent call last):\r\n  File \"C:\\Anaconda3\\envs\\tensorflow2_0_pip\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Anaconda3\\envs\\tensorflow2_0_pip\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Anaconda3\\envs\\tensorflow2_0_pip\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Anaconda3\\envs\\tensorflow2_0_pip\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Anaconda3\\envs\\tensorflow2_0_pip\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\n  File \"C:\\Anaconda3\\envs\\tensorflow2_0_pip\\lib\\site-packages\\tensorflow\\__init__.py\", line 98, in <module>\r\n    from tensorflow_core import *\r\n  File \"C:\\Anaconda3\\envs\\tensorflow2_0_pip\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 40, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"C:\\Anaconda3\\envs\\tensorflow2_0_pip\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Anaconda3\\envs\\tensorflow2_0_pip\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Anaconda3\\envs\\tensorflow2_0_pip\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"C:\\Anaconda3\\envs\\tensorflow2_0_pip\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Anaconda3\\envs\\tensorflow2_0_pip\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Anaconda3\\envs\\tensorflow2_0_pip\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Anaconda3\\envs\\tensorflow2_0_pip\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Anaconda3\\envs\\tensorflow2_0_pip\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Anaconda3\\envs\\tensorflow2_0_pip\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Anaconda3\\envs\\tensorflow2_0_pip\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\n(tensorflow2_0_pip)>\r\n```", "comments": ["Any chance this comment helps:\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/36167#issuecomment-577886156", "@tessy1234 \r\n\r\nWhat is make/model of your cpu?\r\nI suspect your cpu model does not support AVX instructions sets.See [hardware requirements](https://www.tensorflow.org/install/pip?lang=python3#hardware-requirements)\r\nMake sure to download the [latest microsoft visual c++ redistributable from here](https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads).\r\n.Also, please follow the instructions from to install from pip [Tensorflow website](https://www.tensorflow.org/install/pip).\r\nPlease, check Your CPU/Python is on 32 bits?Please, refer #36167 and see if it helps you. Thanks!", "I am running Intel\u00ae Core\u2122 i7-820QM Processor (8M Cache, 1.73 GHz).\r\nInstalled:\r\n\r\n- Microsoft Visual C++ 2015-2019 Redistributable (x64) - 14.24.28127\r\n\r\n- pip version 20.0.2\r\n\r\n- Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)]\r\n\r\nOpen question: @av8ramit, @ravikyram\r\nIs there a library that is in a different location/not installed on the system that cannot be loaded?\r\n\r\nsupport: installed packages\r\nconda list\r\n```\r\n# packages in environment at C:\\Anaconda3\\envs\\tensorflow2_0_pip:\r\n#\r\n# Name                    Version                   Build  Channel\r\nabsl-py                   0.9.0                    pypi_0    pypi\r\nastor                     0.8.1                    pypi_0    pypi\r\nca-certificates           2020.1.1                      0\r\ncachetools                4.0.0                    pypi_0    pypi\r\ncertifi                   2019.11.28               py37_0\r\nchardet                   3.0.4                    pypi_0    pypi\r\ngast                      0.2.2                    pypi_0    pypi\r\ngoogle-auth               1.11.2                   pypi_0    pypi\r\ngoogle-auth-oauthlib      0.4.1                    pypi_0    pypi\r\ngoogle-pasta              0.1.8                    pypi_0    pypi\r\ngrpcio                    1.27.2                   pypi_0    pypi\r\nh5py                      2.10.0                   pypi_0    pypi\r\nidna                      2.8                      pypi_0    pypi\r\nkeras-applications        1.0.8                    pypi_0    pypi\r\nkeras-preprocessing       1.1.0                    pypi_0    pypi\r\nmarkdown                  3.2.1                    pypi_0    pypi\r\nnumpy                     1.18.1                   pypi_0    pypi\r\noauthlib                  3.1.0                    pypi_0    pypi\r\nopenssl                   1.1.1d               he774522_4\r\nopt-einsum                3.1.0                    pypi_0    pypi\r\npip                       20.0.2                   py37_1\r\npipdeptree                0.13.2                   pypi_0    pypi\r\nprotobuf                  3.11.3                   pypi_0    pypi\r\npyasn1                    0.4.8                    pypi_0    pypi\r\npyasn1-modules            0.2.8                    pypi_0    pypi\r\npython                    3.7.6                h60c2a47_2\r\nrequests                  2.22.0                   pypi_0    pypi\r\nrequests-oauthlib         1.3.0                    pypi_0    pypi\r\nrsa                       4.0                      pypi_0    pypi\r\nsetuptools                45.2.0                   py37_0\r\nsix                       1.14.0                   pypi_0    pypi\r\nsqlite                    3.31.1               he774522_0\r\ntensorboard               2.0.2                    pypi_0    pypi\r\ntensorflow                2.0.0                    pypi_0    pypi\r\ntensorflow-estimator      2.0.1                    pypi_0    pypi\r\ntermcolor                 1.1.0                    pypi_0    pypi\r\nurllib3                   1.25.8                   pypi_0    pypi\r\nvc                        14.1                 h0510ff6_4\r\nvs2015_runtime            14.16.27012          hf0eaf9b_1\r\nwerkzeug                  1.0.0                    pypi_0    pypi\r\nwheel                     0.34.2                   py37_0\r\nwincertstore              0.2                      py37_0\r\nwrapt                     1.11.2                   pypi_0    pypi\r\n```", "The dependency walker confirms that all DLLs could be loaded:\r\n\r\npath for dependency walker:\r\n`C:\\Anaconda3\\envs\\tensorflow2_0_pip\\Lib\\site-packages\\tensorflow_core\\python\\_pywrap_tensorflow_internal.pyd`\r\n\r\ndependency trace:\r\n\r\n![image](https://user-images.githubusercontent.com/41914070/74852267-a0d9e880-533c-11ea-806f-bb695497408b.png)\r\n", "the answer to your question, why does conda instlal load is successful but pip one was not:\r\nConda packages are built by conda community, and pip packages are the official ones built by us.\r\nThe reason pip package cannot start on your system is, packages in pypi require AVX instruction set.\r\nYour CPU (i7 -820 QM) does not have this instruction set. Anaconda packages use MKL to be more compatible, and use older CPUs. The reason official TF builds do not use MKL in the binaries in pypi is, while providing compatibility, at graph level MKL is not as fast as non-mkl solutions for TF.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36860\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36860\">No</a>\n", "In the comment above you (@av8ramit ) referred to [#36167 (comment)](https://github.com/tensorflow/tensorflow/issues/36167#issuecomment-577886156) and one requirement was that the cpu must support AVX instructions. You (@av8ramit, @gunan) are absolutely right.\r\n\r\nHere is a utility to check the AVX feature on the computer:\r\n-------------------\r\npip install cpufeature \r\n[cpufeature](https://pypi.org/project/cpufeature/)\r\n\r\nPrerequisite:\r\nInstall Microsoft Visual C++ Build Tools\r\n\r\n1. Download Microsoft Visual C++ Build Tools from this link: https://visualstudio.microsoft.com/downloads/\r\nand explicitly download from \"Tools for Visual Studio 2019\" -> \"Build Tools for Visual Studio 2019\"\r\n\r\n2. Select: Workloads -> Desktop and Mobile -> C++ Build Tools, then for Individual Components, select only:\r\n\r\n\tMSVC v142 - VS 2019 C++ x64/x86 build tools\r\n\tWindows 10 SDK\r\n\r\ncheck cpu AVX feature:\r\n----------------------\r\npython -c \"import cpufeature; cpufeature.print_features()\"\r\n```\r\n(base)>python -c \"import cpufeature; cpufeature.print_features()\"\r\n=== CPU FEATURES ===\r\n    VendorId                : GenuineIntel\r\n    num_virtual_cores       : 8\r\n    num_physical_cores      : 4\r\n    num_threads_per_core    : 2\r\n    cache_line_size         : 64\r\n    cache_L1_size           : 32768\r\n    cache_L2_size           : 262144\r\n    cache_L3_size           : 8388608\r\n    OS_x64                  : True\r\n    OS_AVX                  : False\r\n    OS_AVX512               : False\r\n    MMX                     : True\r\n    x64                     : True\r\n    ABM                     : False\r\n    RDRAND                  : False\r\n    BMI1                    : False\r\n    BMI2                    : False\r\n    ADX                     : False\r\n    PREFETCHWT1             : False\r\n    MPX                     : False\r\n    SSE                     : True\r\n    SSE2                    : True\r\n    SSE3                    : True\r\n    SSSE3                   : True\r\n    SSE4.1                  : True\r\n    SSE4.2                  : True\r\n    SSE4.a                  : False\r\n    AES                     : False\r\n    SHA                     : False\r\n    AVX                     : False\r\n    XOP                     : False\r\n    FMA3                    : False\r\n    FMA4                    : False\r\n    AVX2                    : False\r\n    AVX512f                 : False\r\n    AVX512pf                : False\r\n    AVX512er                : False\r\n    AVX512cd                : False\r\n    AVX512vl                : False\r\n    AVX512bw                : False\r\n    AVX512dq                : False\r\n    AVX512ifma              : False\r\n    AVX512vbmi              : False\r\n(base)>\r\n```\r\nconclusion:\r\n------------\r\nThe query result clearly states that my processor supports neither AVX nor AVX2.\r\nTherefore the tensorflow pip package could not be installed or to be more precise the tensorflow package could not be imported.\r\n", "If official TF would support both SSE- and AVX-prebuild-binaries that would be of great benefit for the whole TF community. \r\nThere is an evolution of SIMD (x86) instruction sets: SSE4 (2006), AVX2 (2013) and AVX-512 (2015).\r\nI guess AVX-512 is not downward-compatible to AVX2 thus even AVX2-cpu may be soon out-of-date.\r\n\r\n**Why not supporting SSE-prebuild-binaries for tensorflow in addition?**\r\n\r\n**Why are default builds (ones from pip install tensorflow) not intended to be compatible with as** **many CPUs as possible?**\r\n\r\nOfficial TF could provide:\r\n\r\n- default: cpu acceleration (SSE)\r\n\r\n- cpu acceleration (AVX)\r\n\r\n- gpu acceleration\r\n\r\nI think the infrastructure and prioritization argument should be rethought.", "The interim solution for legacy & low-end CPU without AVX support is to install SSE-prebuild-binaries for tensorflow.\r\nGo to [ tensorflow-windows-wheel](https://github.com/fo40225/tensorflow-windows-wheel) and follow instruction to install either **tensorflow 2.0.0 or 2.1.0**.", "May you (@gunan,@mihaimaruseac)  leave your opinion on my thought?", "At the moment, pypi or pip doed not have a mechanism to deliver different packages based on CPU instruction sets.\r\nOne potential option is to create a package that has all three, and TF python code picks whichever it can use.\r\nHowever, we are well over pypi package size limit, and we are not allowed to upload anything larger at the moment.\r\n\r\nTherefore, it is infeasible for us to deliver what you recommended using pypi, without degrading user experience."]}, {"number": 36859, "title": "Tensorflow-gpu 2.1 Cuda 10.2, ImportError: DLL load failed: The specified module could not be found.", "body": "**System information**\r\n- OS Platform and Distribution: Windows 10\r\n- TensorFlow installed from: pip install tensorflow-gpu\r\n- TensorFlow version: tensorflow-gpu-2.1.0\r\n- Python version: python 3.7.6\r\n- Visual_Studio_Community 2019\r\n- CUDA/cuDNN version: Cuda 10.2.89, cudnn-10.2-windows10-x64-v7.6.5.32\r\n- GPU model and memory: NVIDIA GeForce 940MX 2GB\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nI followed all the steps to install tensroflow-gpu today.\r\nI downloaded Visual Studio 2019 and installed it.\r\nThen I downloaded and installed NVIDIA CUDA 10.2 Toolkit and NVIDIA cuDNN 7.6.5.32 following compatibilities recommendations.\r\nCUDA and CUDANN are in my environment variables, so no problems with that.\r\nI installed today python 3.7.6 and tensorflow-gpu with pip inside a virtual environment, which took automatically version 2.1.\r\nPip install tensorflow-gpu runs smoothly but I get an error when I try to import it.\r\nI open a new post because, in the opened one, the proposed solutions are:\r\n* Downloading and installing visual studio 2015-2019 x86 and x64: it wouldn't work for me as I have already installed it.\r\n* Downgrade to tensorflow 2.0: I would like to keep tensorflow 2.1, on top of this, even downgrading I get another run-time error, which is solvable by downgrading to CUDA 10.1, which I don't want to do.\r\n\r\n\r\n**Any other info / logs**\r\n\r\nThis is the errror message: \r\n```\r\n>>> import tensorflow as tf\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\apaladini\\OneDrive - Amadeus Workplace\\Desktop\\Work\\2020\\Tensorflow-gpu\\venvs\\py37\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\apaladini\\OneDrive - Amadeus Workplace\\Desktop\\Work\\2020\\Tensorflow-gpu\\venvs\\py37\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\apaladini\\OneDrive - Amadeus Workplace\\Desktop\\Work\\2020\\Tensorflow-gpu\\venvs\\py37\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\apaladini\\AppData\\Local\\Programs\\Python\\Python37\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\apaladini\\AppData\\Local\\Programs\\Python\\Python37\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Users\\apaladini\\OneDrive - Amadeus Workplace\\Desktop\\Work\\2020\\Tensorflow-gpu\\venvs\\py37\\lib\\site-packages\\tensorflow\\__init__.py\", line 101, in <module>\r\n    from tensorflow_core import *\r\n  File \"C:\\Users\\apaladini\\OneDrive - Amadeus Workplace\\Desktop\\Work\\2020\\Tensorflow-gpu\\venvs\\py37\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 40, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"C:\\Users\\apaladini\\OneDrive - Amadeus Workplace\\Desktop\\Work\\2020\\Tensorflow-gpu\\venvs\\py37\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\apaladini\\OneDrive - Amadeus Workplace\\Desktop\\Work\\2020\\Tensorflow-gpu\\venvs\\py37\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\apaladini\\AppData\\Local\\Programs\\Python\\Python37\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"C:\\Users\\apaladini\\OneDrive - Amadeus Workplace\\Desktop\\Work\\2020\\Tensorflow-gpu\\venvs\\py37\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\apaladini\\OneDrive - Amadeus Workplace\\Desktop\\Work\\2020\\Tensorflow-gpu\\venvs\\py37\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\apaladini\\OneDrive - Amadeus Workplace\\Desktop\\Work\\2020\\Tensorflow-gpu\\venvs\\py37\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\apaladini\\OneDrive - Amadeus Workplace\\Desktop\\Work\\2020\\Tensorflow-gpu\\venvs\\py37\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\apaladini\\OneDrive - Amadeus Workplace\\Desktop\\Work\\2020\\Tensorflow-gpu\\venvs\\py37\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\apaladini\\AppData\\Local\\Programs\\Python\\Python37\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\apaladini\\AppData\\Local\\Programs\\Python\\Python37\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n```\r\nI didn't find a way to find out what dll file the error is referring to.\r\n\r\nHow can I make this work?\r\nThanks in advance!", "comments": ["Any chance this comment helps:\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/36167#issuecomment-577886156\r\n\r\nI notice you already have Visual_Studio_Community 2019.", "@Anto95, Did you get a chance to look at @av8ramit's comment.Thanks", "Closing as duplicate.\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/36167#issuecomment-577886156\r\n\r\n#36167 #36151 #36138 #36054 #36045 #36020 #36003 #35988 #35903 #35880 #35865 #35805 #35789 #35773 #35772 #35767 #35766 #35749 #35721 #35618 #35204", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36859\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36859\">No</a>\n"]}, {"number": 36858, "title": "Securing models before sending it to client for inference", "body": "We have Tensorflow Saved model format (.pb file  )that we want to ship in an offline application. \r\nIs there a way to secure the model such that, it is not exposed to the client?\r\n\r\nWe understand that any logic that is running on the client-side is exposed by definition but wondering whether there are best practices to mitigate this risk? ", "comments": ["Please do some searches, there are a variety of ways to accomplish this goal with varying degrees of risk.", "@dtsmith2001 \r\nI have done my research but didn't find anything convincing.\r\nCan you please share some resources?\r\nAny help would be appreciated.\r\n", "I don't think this is a question for tensorflow.\r\n\r\nAre you using Python or some other language in the remote app?", "Yes @dtsmith2001 , we are using python in the app.", "@aayusharora \r\n\r\nThis question is better asked on StackOverflow since it is not a bug or feature request. There is also a larger community that reads questions there and provide better and faster support for such issues. Thanks!", "@aayusharora \r\n\r\nAs this issue not related to bug or feature request I am closing this issue.Please, ask this question in Stackoverflow. Thanks!", "Please consult the [security guidelines](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md)"]}, {"number": 36857, "title": "Key error message doesn't print the new line in Estimator", "body": "output in the concole:\r\n```\r\nKeyError: \"The dictionary passed into features does not have the expected inputs keys defined in \r\nthe keras model.\\n\\tExpected keys: {'input_1', 'input_2'}\\n\\tfeatures keys: {'feat_ids', \r\n'feat_vals'}\\n\\tDifference: {'input_1', 'feat_ids', 'feat_vals', 'input_2'}\"\r\n```\r\nThe link to the code snippet:\r\nhttps://github.com/tensorflow/estimator/blob/6915557cef8bfc86f29f87e4467d601e4553b957/tensorflow_estimator/python/estimator/keras.py#L119-L129\r\n\r\nThe key error message doesn't print the new line, we should update it.\r\nIt's related to https://stackoverflow.com/questions/46892261/new-line-on-error-message-in-keyerror-python-3-3", "comments": ["@pingsutw \r\nCan you please let us know which TensorFlow version you are using?.Please, share the colab link or simple standalone code to reproduce the issue in our environment. It helps in localizing the issue faster. Thanks!", "@ravikyram thanks for the reply\r\nhere is my colab [link](https://colab.research.google.com/drive/1B_0Vbnk3EkNFfkKkmZK9gG8NbKxUqHxP) to reproduce problem\r\nActually it's keyErorr Exception bug, they don't support `\\n` in the error message\r\nyou can see this [link](https://stackoverflow.com/questions/46892261/new-line-on-error-message-in-keyerror-python-3-3)  for reference", "@omalleyt12 , Please review PR [#51](https://github.com/tensorflow/estimator/pull/51) for this issue. Check if it is useful.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36857\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36857\">No</a>\n"]}, {"number": 36856, "title": "[TFLite] Fix for the segmentation fault. when quantize CONV_2D with dilation != 1.", "body": "This change fixes the crash \"segmentation fault\" raised here:\r\nhttps://github.com/tensorflow/tensorflow/issues/36692\r\nThe issue contains the script that reproduces the crash. The crash is in the Python subprocess that has been launched in convert.py, when binary toco_from_proto is called. I listed the script here as well.\r\n\r\nI have not added a test, but I am happy to do this - please let me know where it should be added. \r\n\r\n```\r\nimport numpy\r\nimport tensorflow as tf\r\n\r\nimport os\r\nprint(\"ID is {}\".format(os.getpid()))\r\n\r\ndef representative_dataset_gen():\r\n    yield [numpy.random.uniform(low=-1, high=1, size=(1,28,28,16)).astype(numpy.float32)]\r\n\r\nmodel=tf.keras.Sequential()\r\nmodel.add(\r\n    tf.keras.layers.Conv2D(\r\n        filters=16, kernel_size=7, dilation_rate=(2,2), input_shape=(28,28,16),\r\n        use_bias=True, bias_initializer='ones'\r\n    )\r\n)\r\n\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\r\nconverter.representative_dataset = representative_dataset_gen\r\nconverter.experimental_new_converter = False\r\n\r\ntflite_model = converter.convert()\r\n\r\n```", "comments": []}, {"number": 36855, "title": "How the Frozen model from tensorflow audio recognition is made and converted to tensorflow lite model?", "body": "After following the steps train.py and freeze.py from the [tutorial](https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/audio_recognition.md) ,the structure of my frozen model looks like(https://imgur.com/a/JtNVkHw) which is different from the official frozen model conv_actions_frozen.pb(https://imgur.com/a/KJXExbV).\r\n\r\nWhen I Converted Frozen model to Tensorflow lite using the steps:\r\n\r\n```\r\nimport tensorflow as tf\r\nconverter = tf.compat.v1.lite.TFLiteConverter.from_frozen_graph(\"./my_frozen_graph.pb\", input_arrays=['decoded_sample_data', 'decoded_sample_data:1'], output_arrays=['labels_softmax'])\r\nconverter.allow_custom_ops=True\r\ntflite_model = converter.convert()\r\nopen(\"output.tflite\", \"wb\").write(tflite_model)\r\n```\r\n\r\nThe structure of my tflite model (https://imgur.com/a/uceoHlo) is also different from the original speech commands tflite model(https://imgur.com/a/lWmxl9d). Also, When i am testing my tflite model on android studio, it is getting crashed.\r\n\r\nI suspect something went wrong in the creation of frozen model from the [tutorial](https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/audio_recognition.md). Could someone kindly help in generating the frozen model for speech commands.\r\n\r\nTensorflow version-2.1.0\r\n\r\npython version - 3.7.3", "comments": ["@petewarden Kindly go through the question once", "@vihari1729 Can you please provide a standalone code to reproduce the issue? Thanks!", "Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 36853, "title": "The minimum required Cuda capability is 6.0 for the binary C-API releases 1.14.0 and 1.15.0", "body": "**System information**\r\n- OS Platform and Distribution: Ubuntu 18.04\r\n- TensorFlow installed from: binary C-API release (https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow-gpu-linux-x86_64-1.14.0.tar.gz)\r\n- TensorFlow version: `1.14.0`\r\n- Docker image: `tensorflow/tensorflow:1.14.0-gpu-py3`\r\n- GPU model and memory:\r\n\r\n```\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 440.59       Driver Version: 440.59       CUDA Version: 10.2     |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  GeForce GTX 960M    Off  | 00000000:01:00.0 Off |                  N/A |\r\n| N/A   36C    P8    N/A /  N/A |      0MiB /  2004MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID   Type   Process name                             Usage      |\r\n|=============================================================================|\r\n|  No running processes found                                                 |\r\n+-----------------------------------------------------------------------------+\r\n```\r\n\r\n\r\n**Describe the problem**\r\nUsing the C-API, the following error occurs when attempting to run inferences with the above GPU setup. \r\n\r\n```\r\n2020-02-18 09:42:51.504548: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2020-02-18 09:42:51.529888: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599990000 Hz\r\n2020-02-18 09:42:51.530480: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x555dbf23f760 executing computations on platform Host. Devices:\r\n2020-02-18 09:42:51.530508: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\r\n2020-02-18 09:42:51.531487: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\r\n2020-02-18 09:42:51.541446: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-02-18 09:42:51.542021: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \r\nname: GeForce GTX 960M major: 5 minor: 0 memoryClockRate(GHz): 1.0975\r\npciBusID: 0000:01:00.0\r\n2020-02-18 09:42:51.542289: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\r\n2020-02-18 09:42:51.543592: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\r\n2020-02-18 09:42:51.544681: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\r\n2020-02-18 09:42:51.545006: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\r\n2020-02-18 09:42:51.546594: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\r\n2020-02-18 09:42:51.547771: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\r\n2020-02-18 09:42:51.551039: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\r\n2020-02-18 09:42:51.551147: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-02-18 09:42:51.552024: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-02-18 09:42:51.552531: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1717] Ignoring visible gpu device (device: 0, name: GeForce GTX 960M, pci bus id: 0000:01:00.0, compute capability: 5.0) with Cuda compute capability 5.0. The minimum required Cuda capability is 6.0.\r\n2020-02-18 09:42:51.585097: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-02-18 09:42:51.585122: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \r\n2020-02-18 09:42:51.585128: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \r\n```\r\n\r\nThis issue has previously been raised and fixed in https://github.com/tensorflow/tensorflow/issues/25329 for another setup, but the error remains when using the C-API.\r\n\r\nI have also confirmed the same issue when using the `1.15.0` binary release.\r\n", "comments": ["I am using tfjs-node-gpu, which uses the binary C-API release (https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow-gpu-linux-x86_64-1.14.0.tar.gz)\u3002         My GPU is Titan X, which has cuda capacity 5.2.\r\n\r\nI got exactly the same error: \r\n\r\n`I tensorflow/core/common_runtime/gpu/gpu_device.cc:1717] Ignoring visible gpu device (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:02:00.0, compute capability: 5.2) with Cuda compute capability 5.2. The minimum required Cuda capability is 6.0.`", "@johan-andersson01,\r\nCould you please provide the exact sequence of commands that you executed before running into this issue? Thanks!", "Any updates regarding this issue? Thanks!", "Unfortunately I can't publish the original code, but I'll try to create a simpler working example when I find the time. Thanks for your patience. :)", "@johan-andersson01,\r\nDid you get the time to work on the example? Thanks!", "Any updates regarding this issue? Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36853\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36853\">No</a>\n", "@amahendrakar I am having the same issue.\r\nWith\r\n`{\"dependencies\": {\"@tensorflow/tfjs-node-gpu\": \"^1.7.3\"}}` as `package.json`\r\nfollowed by `npm install` and importing tfjs-node-gpu\r\n`const tf = require('@tensorflow/tfjs-node-gpu');`\r\nI get the error @johan-andersson01 printed. I am using GeForce GTX 960M as well, tensorflow 1.15.0.", "@MitskiP,\r\nCould you please create a new issue from [this link](https://github.com/tensorflow/tensorflow/issues/new/choose) and fill in the issue template, so that we can track it there. Thanks!"]}, {"number": 36852, "title": "Enable preventing engine build at runtime", "body": "(This PR is the same as #34919, moved here to prevent a technical issue with CLA.)\r\n\r\nThis PR adds a new API argument allow_build_at_runtime which allows users to prevent building TRT engines at runtime if desired. The existing behavior can be achieved by setting this argument to True which is also the default value.\r\n\r\nThis argument is useful for users of the build() method that try to build all the engines offline before doing any inference, and then want to avoid any optimization during inference, keeping low latency. In such cases, if there is no engine found in the cache, then native TF is used instead.", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F36852) for more info**.\n\n<!-- need_author_cla -->", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F36852) for more info**.\n\n<!-- ok -->"]}, {"number": 36851, "title": "TypeError: Tensor is unhashable if Tensor equality is enabled. Instead, use tensor.experimental_ref() as the key. in colab", "body": "When tryig to build the following model, I get error Tensor is unhashable (see figure)\r\ninput_data = Input(name='the_input', shape=(208, 224,224, 3), dtype=dtype)\r\n layer1 =        TimeDistributed(\r\n            MobileNet(weights='imagenet',include_top=False))(input_data)\r\n    \r\nlayer2 =  TimeDistributed(GlobalAveragePooling2D())(layer1)\r\n##********************************* Create Bidirectional LSTM*************************************\r\nfor i in range(0, n_layers):\r\n     x = Bidirectional(CuDNNLSTM(20, kernel_initializer=kernel_init_rnn, bias_initializer=bias_init_rnn,\r\n                                        unit_forget_bias=True, return_sequences=True),\r\n                              merge_mode='sum', name='CuDNN_bi_lstm'+str(i+1))(layer2)\r\n\r\nx = TimeDistributed(Dense(units=20, kernel_initializer=kernel_init_dense, bias_initializer=bias_init_dense,\r\n                              activation='relu'), name='fc_4')(x)\r\nx = TimeDistributed(Dropout(dropout), name='dropout_4')(x)\r\n    # Output layer with softmax\r\ny_pred = TimeDistributed(Dense(units=30, kernel_initializer=kernel_init_dense,\r\n                                   bias_initializer=bias_init_dense, activation='softmax'), name='softmax')(x)\r\nModel(inputs=input_data, outputs=y_pred).summary()\r\n![colab issue](https://user-images.githubusercontent.com/17008416/74722702-63ebf400-525f-11ea-804d-283b4016d6fe.JPG)\r\n\r\n", "comments": ["@neenaloysius, Can you please provide complete code to reproduce the reported issue or share the colab gist. Also provide the Tensorflow version. Thanks!", "#**%tensorflow_version 2.x**\r\nimport tensorflow as tf\r\nfrom tensorflow.python.keras import Sequential\r\nfrom tensorflow.python.keras.layers import LSTM, Bidirectional,Lambda\r\nfrom tensorflow.python.keras.layers import Dense, TimeDistributed,Input,CuDNNLSTM\r\nfrom tensorflow.python.keras.layers import Dropout, GlobalAveragePooling2D\r\nfrom tensorflow.python.keras import optimizers\r\nfrom tensorflow.keras.applications.mobilenet import MobileNet\r\nfrom tensorflow.python.keras import backend as K\r\nfrom keras.models import Model\r\n\r\n\r\ndtype = 'float32'\r\nn_layers=1\r\ndropout=0.2\r\n\r\nkernel_init_rnn = 'glorot_uniform'\r\nbias_init_rnn = 'random_normal'\r\n\r\nkernel_init_dense = 'random_normal'\r\nbias_init_dense = 'random_normal'\r\n\r\n\r\nkernel_init_conv = 'glorot_uniform'\r\nbias_init_conv = 'random_normal'\r\nsample_shape = (208, 224,224, 3)\r\ninput_data = Input(name='the_input', shape=(208, 224,224, 3), dtype=dtype)\r\n \r\nlayer1 =        TimeDistributed(\r\n            MobileNet(weights='imagenet',include_top=False))(input_data)\r\n    \r\nlayer2 =  TimeDistributed(GlobalAveragePooling2D())(layer1)\r\n\r\nfor i in range(0, n_layers):\r\n     x = Bidirectional(CuDNNLSTM(20, kernel_initializer=kernel_init_rnn, bias_initializer=bias_init_rnn,\r\n                                        unit_forget_bias=True, return_sequences=True),\r\n                              merge_mode='sum', name='CuDNN_bi_lstm'+str(i+1))(layer2)\r\n\r\nx = TimeDistributed(Dense(units=20, kernel_initializer=kernel_init_dense, bias_initializer=bias_init_dense,\r\n                              activation='relu'), name='fc_4')(x)\r\nx = TimeDistributed(Dropout(dropout), name='dropout_4')(x)\r\n\r\n \r\ny_pred = TimeDistributed(Dense(units=30, kernel_initializer=kernel_init_dense,\r\n                                   bias_initializer=bias_init_dense, activation='softmax'), name='softmax')(x)\r\n\r\nModel(inputs=input_data, outputs=y_pred).summary()", "Was able to replicate the issue with Tf 2.1.\r\nPlease find the gist [here](https://colab.sandbox.google.com/gist/gadagashwini/81dc9ecd6c0756e951d7f0e3ddc72d88/untitled396.ipynb). Thanks!", "Problem solved. In my case it was mistake on importing libraries when using tensorflow 2.x ,\r\nI was having error\r\n\r\n>  TypeError: Tensor is unhashable if Tensor equality is enabled. Instead, use tensor.experimental_ref() as the key.\r\n\r\nsolution was:\r\nusing\r\n`from tensorflow.keras.models import Model\r\n`Instead of\r\n`from keras.models import Model`", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36851\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36851\">No</a>\n", "from keras.applications.vgg16 import VGG16\r\nfrom keras.applications.vgg16 import preprocess_input, decode_predictions\r\nimport numpy as np\r\nimport shap\r\nimport keras.backend as K\r\nimport json\r\n\r\n# load pre-trained model and choose two images to explain\r\nmodel2 = VGG16(weights='imagenet', include_top=True)\r\nX,y = shap.datasets.imagenet50()\r\nto_explain = X[[39,41]]\r\n\r\n# load the ImageNet class names\r\nurl = \"https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json\"\r\nfname = shap.datasets.cache(url)\r\nwith open(fname) as f:\r\n    class_names = json.load(f)\r\n\r\n# explain how the input to the 7th layer of the model explains the top two classes\r\ndef map2layer(x, layer):\r\n    feed_dict = dict(zip([model2.layers[0].input], [preprocess_input(x.copy())]))\r\n    return K.get_session().run(model2.layers[layer].input, feed_dict)\r\ne = shap.GradientExplainer((model2.layers[7].input, model2.layers[-1].output), map2layer(preprocess_input(X.copy()), 7))\r\nshap_values,indexes = e.shap_values(map2layer(to_explain, 7), ranked_outputs=2)\r\n\r\n# get the names for the classes\r\nindex_names = np.vectorize(lambda x: class_names[str(x)][1])(indexes)\r\n\r\n# plot the explanations\r\nshap.image_plot(shap_values, to_explain, index_names)\r\n\r\n\r\n![image](https://user-images.githubusercontent.com/39588932/120801799-45e2f980-c55f-11eb-89da-3c80f657ad48.png)\r\n", "_\r\n\r\n> I'm facing the same error, I resolved the error by importing these commands -\r\n\r\n_ \r\n\r\n**import tensorflow.compat.v1.keras.backend as K\r\nimport tensorflow as tf\r\ntf.compat.v1.disable_eager_execution()**", "> from keras.applications.vgg16 import VGG16\r\n> from keras.applications.vgg16 import preprocess_input, decode_predictions\r\n> import numpy as np\r\n> import shap\r\n> import keras.backend as K\r\n> import json\r\n> \r\n> # load pre-trained model and choose two images to explain\r\n> model2 = VGG16(weights='imagenet', include_top=True)\r\n> X,y = shap.datasets.imagenet50()\r\n> to_explain = X[[39,41]]\r\n> \r\n> # load the ImageNet class names\r\n> url = \"https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json\"\r\n> fname = shap.datasets.cache(url)\r\n> with open(fname) as f:\r\n> class_names = json.load(f)\r\n> \r\n> # explain how the input to the 7th layer of the model explains the top two classes\r\n> def map2layer(x, layer):\r\n> feed_dict = dict(zip([model2.layers[0].input], [preprocess_input(x.copy())]))\r\n> return K.get_session().run(model2.layers[layer].input, feed_dict)\r\n> e = shap.GradientExplainer((model2.layers[7].input, model2.layers[-1].output), map2layer(preprocess_input(X.copy()), 7))\r\n> shap_values,indexes = e.shap_values(map2layer(to_explain, 7), ranked_outputs=2)\r\n> \r\n> # get the names for the classes\r\n> index_names = np.vectorize(lambda x: class_names[str(x)][1])(indexes)\r\n> \r\n> # plot the explanations\r\n> shap.image_plot(shap_values, to_explain, index_names)\r\n> \r\n> ![image](https://user-images.githubusercontent.com/39588932/120801799-45e2f980-c55f-11eb-89da-3c80f657ad48.png)\r\n\r\nIt will work by this - \r\n```\r\nimport tensorflow.compat.v1.keras.backend as K\r\nimport tensorflow as tf\r\ntf.compat.v1.disable_eager_execution()\r\n```"]}, {"number": 36850, "title": "dlpack support", "body": "", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F36850) for more info**.\n\n<!-- need_author_cla -->"]}, {"number": 36849, "title": "Use case clarification comments #36785", "body": "Changes in comments for learning rate =1.0 and epsilon =1e-6 following PR #36785. Added description to suit the use cases where the modifications are required as mentioned in the sections if the paper by M. D. Zeiler", "comments": ["Hi @tanzhenyu ,changes are made. Can you review it ? Thanks", "@abhilash1910 Can you please address Ubuntu Sanity errors? Thanks!", "Hi @gbaned, according to the summary results for sanity check ,there is FAIl mentioned for do_pylint: Python 3 pylint(1 failed and 14 passed) . I am not sure how to resolve this as it is pretty much the same for all the other accepted PRs.Since the additions are only in form of comments. Can you suggest ways to resolve this? Thanks", "@tanzhenyu Can you please assist with build failures. Thanks!", "> Hi @gbaned, according to the summary results for sanity check ,there is FAIl mentioned for do_pylint: Python 3 pylint(1 failed and 14 passed) . I am not sure how to resolve this as it is pretty much the same for all the other accepted PRs.Since the additions are only in form of comments. Can you suggest ways to resolve this? Thanks\r\n\r\nIt seems a temporary failure due to connection errors. Can you re-try?", "Hi @tanzhenyu ,reuploaded the changes.", "@abhilash1910 Can you please resolve conflicts? Thanks!", "Resolved @gbaned .Thanks!", "@abhilash1910 Can you please address Ubuntu Sanity errors? Thanks!", "> > Hi @gbaned, according to the summary results for sanity check ,there is FAIl mentioned for do_pylint: Python 3 pylint(1 failed and 14 passed) . I am not sure how to resolve this as it is pretty much the same for all the other accepted PRs.Since the additions are only in form of comments. Can you suggest ways to resolve this? Thanks\r\n> \r\n> It seems a temporary failure due to connection errors. Can you re-try?\r\n\r\nI can try re-uploading since CI build logs indicate failure on PyLint 3. It is the same issue which was happening previously.", "@abhilash1910 Can you please resolve conflicts? Thanks!", "> @abhilash1910 Can you please resolve conflicts? Thanks!\r\nHi @gbaned ,merge conflict resolved.", "Seems auto-merge is not happening but the changes are now committed so we can close this. Thank you for the PR.", "Yep I resolved all conflicts internally and mark it contributed by @abhilash1910 ", "Thank you @tanzhenyu @gbaned @rthadur."]}, {"number": 36848, "title": "Not able to use 'training' argument in the call method for a custom layer.", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information** :\r\n\r\nOS - CentOs\r\ntensorflow-gpu = 2.1.0\r\ntensorflow = 2.0.0\r\ninstalled in the conda version - conda version : 4.8.1\r\nusing cuda - CUDA Version: 10.1\r\nGpu - Tesla K80\r\npython - 3.6\r\n\r\n\r\n**Describe the current behavior**\r\nNot able to use the 'training' flag when designing a custom layer. Getting error saying that \r\n```\r\noperatorNotAllowedInGraphError            Traceback (most recent call last)\r\n~/miniconda3/envs/CbrainCustomLayer/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py in __call__(self, inputs, *args, **kwargs)\r\n    841                   with auto_control_deps.AutomaticControlDependencies() as acd:\r\n--> 842                     outputs = call_fn(cast_inputs, *args, **kwargs)\r\n    843                     # Wrap Tensors in `outputs` in `tf.identity` to avoid\r\n\r\n~/miniconda3/envs/CbrainCustomLayer/lib/python3.6/site-packages/tensorflow_core/python/autograph/impl/api.py in wrapper(*args, **kwargs)\r\n    236         if hasattr(e, 'ag_error_metadata'):\r\n--> 237           raise e.ag_error_metadata.to_exception(e)\r\n    238         else:\r\n\r\nOperatorNotAllowedInGraphError: in converted code:\r\n\r\n    <ipython-input-26-3ff47d389914>:43 call\r\n        if not training:\r\n    /home/ankitesh/miniconda3/envs/CbrainCustomLayer/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py:765 __bool__\r\n        self._disallow_bool_casting()\r\n    /home/ankitesh/miniconda3/envs/CbrainCustomLayer/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py:534 _disallow_bool_casting\r\n        self._disallow_in_graph_mode(\"using a `tf.Tensor` as a Python `bool`\")\r\n    /home/ankitesh/miniconda3/envs/CbrainCustomLayer/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py:523 _disallow_in_graph_mode\r\n        \" this function with @tf.function.\".format(task))\r\n\r\n    OperatorNotAllowedInGraphError: using a `tf.Tensor` as a Python `bool` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function.\r\n```\r\n**Describe the expected behavior**\r\nIt should not give an error\r\n\r\n**Code to reproduce the issue** Provide a reproducible test case that is the\r\nbare minimum necessary to generate the problem.\r\n\r\nThis is the class that I made\r\n\r\n```python\r\nfrom tensorflow.keras import initializers\r\nfrom tensorflow.keras import layers\r\n\r\n\r\nclass CustomBatchNormalization(layers.Layer):\r\n    def __init__(self, momentum=0.99, epsilon=1e-3,beta_initializer='zeros',\r\n                 gamma_initializer='ones', moving_mean_initializer='zeros',\r\n                 moving_range_initializer='ones',**kwargs):\r\n        self.momentum = momentum\r\n        self.epsilon = epsilon\r\n        self.beta_initializer = initializers.get(beta_initializer)\r\n        self.gamma_initializer = initializers.get(gamma_initializer)\r\n        self.moving_mean_initializer = initializers.get(moving_mean_initializer)\r\n        self.moving_range_initializer = (\r\n            initializers.get(moving_range_initializer))\r\n        \r\n        super().__init__(**kwargs)\r\n    \r\n    def build(self,input_shape):\r\n        dim = input_shape[-1]\r\n        shape = (dim,)\r\n        self.gamma = self.add_weight(shape=shape,\r\n                             name='gamma',\r\n                             initializer=self.gamma_initializer,trainable=True)\r\n        self.beta = self.add_weight(shape=shape,\r\n                            name='beta',\r\n                            initializer=self.beta_initializer,\r\n                                   trainable=True)\r\n        \r\n        self.moving_mean = self.add_weight(\r\n            shape=shape,\r\n            name='moving_mean',\r\n            initializer=self.moving_mean_initializer,\r\n            trainable=False)\r\n        \r\n        self.moving_range = self.add_weight(\r\n            shape=shape,\r\n            name='moving_range',\r\n            initializer=self.moving_range_initializer,\r\n            trainable=False)\r\n\r\n\r\n\r\n    def call(self, inputs, training=None):\r\n        input_shape = inputs.shape\r\n        \r\n        if not training:\r\n            scaled = (inputs-self.moving_mean)/(self.moving_range+self.epsilon)\r\n            return self.gamma*scaled + self.beta\r\n        \r\n        mean = tf.math.reduce_mean(inputs,axis=0)\r\n        maxr = tf.math.reduce_max(inputs,axis=0)\r\n        minr = tf.math.reduce_min(inputs,axis=0)\r\n        \r\n        range_diff = tf.math.subtract(maxr,minr)\r\n        self.moving_mean = tf.math.add(self.momentum*self.moving_mean, (1-self.momentum)*mean)\r\n        self.moving_range = tf.math.add(self.momentum*self.moving_range,(1-self.momentum)*range_diff)\r\n        scaled = tf.math.divide(tf.math.subtract(inputs,mean),(range_diff+self.epsilon))\r\n        return tf.math.add(tf.math.multiply(self.gamma,scaled),self.beta)\r\n    \r\n    def get_config(self):\r\n        config = {\r\n            'momentum': self.momentum,\r\n            'epsilon': self.epsilon,\r\n            'beta_initializer': initializers.serialize(self.beta_initializer),\r\n            'gamma_initializer': initializers.serialize(self.gamma_initializer),\r\n            'moving_mean_initializer':\r\n                initializers.serialize(self.moving_mean_initializer),\r\n            'moving_range_initializer':\r\n                initializers.serialize(self.moving_range_initializer)\r\n        }\r\n        base_config = super(CustomBatchNormalization, self).get_config()\r\n        return dict(list(base_config.items()) + list(config.items()))\r\n    \r\n    def compute_output_shape(self, input_shape):\r\n        return input_shape\r\n\r\n\r\n\r\n\r\n##Below is the network \r\n\r\ninp = Input(shape=(64,))\r\nbatch_norm_1 = CustomBatchNormalization()(inp)\r\ndensout = Dense(128, activation='linear')(batch_norm_1)\r\ndensout = LeakyReLU(alpha=0.3)(densout)\r\nfor i in range (6):\r\n    batch_norm_i = CustomBatchNormalization()(densout)\r\n    densout = Dense(128, activation='linear')(batch_norm_i)\r\n    densout = LeakyReLU(alpha=0.3)(densout)\r\nbatch_norm_out = CustomBatchNormalization()(densout)\r\nout = Dense(64, activation='linear')(batch_norm_out)\r\nInp_RH_CBN = tf.keras.models.Model(inp, out)\r\n```\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\n\r\nHere is the full log error\r\n```\r\nOperatorNotAllowedInGraphError            Traceback (most recent call last)\r\n~/miniconda3/envs/CbrainCustomLayer/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py in __call__(self, inputs, *args, **kwargs)\r\n    841                   with auto_control_deps.AutomaticControlDependencies() as acd:\r\n--> 842                     outputs = call_fn(cast_inputs, *args, **kwargs)\r\n    843                     # Wrap Tensors in `outputs` in `tf.identity` to avoid\r\n\r\n~/miniconda3/envs/CbrainCustomLayer/lib/python3.6/site-packages/tensorflow_core/python/autograph/impl/api.py in wrapper(*args, **kwargs)\r\n    236         if hasattr(e, 'ag_error_metadata'):\r\n--> 237           raise e.ag_error_metadata.to_exception(e)\r\n    238         else:\r\n\r\nOperatorNotAllowedInGraphError: in converted code:\r\n\r\n    <ipython-input-26-3ff47d389914>:43 call\r\n        if not training:\r\n    /home/ankitesh/miniconda3/envs/CbrainCustomLayer/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py:765 __bool__\r\n        self._disallow_bool_casting()\r\n    /home/ankitesh/miniconda3/envs/CbrainCustomLayer/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py:534 _disallow_bool_casting\r\n        self._disallow_in_graph_mode(\"using a `tf.Tensor` as a Python `bool`\")\r\n    /home/ankitesh/miniconda3/envs/CbrainCustomLayer/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py:523 _disallow_in_graph_mode\r\n        \" this function with @tf.function.\".format(task))\r\n\r\n    OperatorNotAllowedInGraphError: using a `tf.Tensor` as a Python `bool` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function.\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-27-3d2d9055924b> in <module>\r\n      1 inp = Input(shape=(64,))\r\n----> 2 batch_norm_1 = CustomBatchNormalization()(inp)\r\n      3 densout = Dense(128, activation='linear')(batch_norm_1)\r\n      4 densout = LeakyReLU(alpha=0.3)(densout)\r\n      5 for i in range (6):\r\n\r\n~/miniconda3/envs/CbrainCustomLayer/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py in __call__(self, inputs, *args, **kwargs)\r\n    852                               'dynamic. Pass `dynamic=True` to the class '\r\n    853                               'constructor.\\nEncountered error:\\n\"\"\"\\n' +\r\n--> 854                               str(e) + '\\n\"\"\"')\r\n    855           else:\r\n    856             # We will use static shape inference to return symbolic tensors\r\n\r\nTypeError: You are attempting to use Python control flow in a layer that was not declared to be dynamic. Pass `dynamic=True` to the class constructor.\r\nEncountered error:\r\n\"\"\"\r\nin converted code:\r\n\r\n    <ipython-input-26-3ff47d389914>:43 call\r\n        if not training:\r\n    /home/ankitesh/miniconda3/envs/CbrainCustomLayer/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py:765 __bool__\r\n        self._disallow_bool_casting()\r\n    /home/ankitesh/miniconda3/envs/CbrainCustomLayer/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py:534 _disallow_bool_casting\r\n        self._disallow_in_graph_mode(\"using a `tf.Tensor` as a Python `bool`\")\r\n    /home/ankitesh/miniconda3/envs/CbrainCustomLayer/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py:523 _disallow_in_graph_mode\r\n        \" this function with @tf.function.\".format(task))\r\n\r\n    OperatorNotAllowedInGraphError: using a `tf.Tensor` as a Python `bool` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function.\r\n```\r\n\r\n\r\n", "comments": ["@ankitesh97 \r\n\r\nI tried to reproduce the issue in colab with Tensorflow-gpu = 2.1.0.However i am seeing the error message` NameError: name 'Input' is not defined`. Can you please help me with colab link or simple standalone code to reproduce the issue in our environment. It helps us in localizing the issue faster.Thanks!", "Checkout the code below may helpful.\r\n\r\n\r\n\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.keras import layers\r\nfrom tensorflow.python.ops import math_ops\r\nfrom tensorflow.python.keras.utils import tf_utils\r\nfrom tensorflow.python.keras import backend as K\r\nLayer = layers.Layer\r\n\r\nclass SyncsBatchNormalization(Layer):\r\n    def __init__(self,\r\n                 axis: int = -1,\r\n                 momentum=0.99,\r\n                 epsilon: float = 1e-3,\r\n                 center: bool = True,\r\n                 scale: bool = True,\r\n                 beta_initializer='zeros',\r\n                 gamma_initializer='ones',\r\n                 moving_mean_initializer='zeros',\r\n                 moving_variance_initializer='ones',\r\n                 beta_regularizer=None,\r\n                 gamma_regularizer=None,\r\n                 beta_constraint = None,\r\n                 gamma_constraint = None,\r\n                 trainable = True,\r\n                 name: str = 'BatchNorm',\r\n                 **kwargs):\r\n\r\n        super(SyncsBatchNormalization, self).__init__(name=name, **kwargs)\r\n\r\n        self.axis = axis\r\n        self.center = center\r\n        self.scale = scale\r\n        self.epsilon = epsilon\r\n        self.momentum = momentum\r\n        self.trainable = trainable\r\n\r\n        self.beta_initializer = beta_initializer\r\n        self.gamma_initializer = gamma_initializer\r\n\r\n        self.moving_mean_initializer = moving_mean_initializer\r\n        self.moving_variance_initializer = moving_variance_initializer\r\n\r\n        self.beta_regularizer = beta_regularizer\r\n        self.gamma_regularizer = gamma_regularizer\r\n\r\n        self.beta_constraint = beta_constraint\r\n        self.gamma_constraint = gamma_constraint\r\n\r\n\r\n    def build(self, input_shape: list):\r\n\r\n        self.feature_dim = input_shape[self.axis]\r\n        axes = list(range(len(input_shape)))\r\n        axes.pop(self.axis)\r\n\r\n        self.axes = axes\r\n\r\n        if self.scale:\r\n            self.gamma = self.add_weight(\r\n                shape=(self.feature_dim,),\r\n                name='gamma',\r\n                initializer=self.gamma_initializer,\r\n                regularizer = self.gamma_regularizer,\r\n                constraint = self.gamma_constraint\r\n            )\r\n\r\n        if self.center:\r\n            self.beta = self.add_weight(\r\n                shape=(self.feature_dim,),\r\n                name='beta',\r\n                initializer=self.beta_initializer,\r\n                regularizer = self.beta_regularizer,\r\n                constraint = self.beta_constraint\r\n            )\r\n\r\n        self.moving_mean = self.add_weight(\r\n            name='moving_mean',\r\n            shape=(self.feature_dim,),\r\n            initializer=self.moving_mean_initializer,\r\n            synchronization=tf.VariableSynchronization.ON_READ,\r\n            trainable=False,\r\n            aggregation=tf.VariableAggregation.MEAN,\r\n            experimental_autocast=False)\r\n\r\n        self.moving_variance = self.add_weight(\r\n            name='moving_variance',\r\n            shape=(self.feature_dim,),\r\n            initializer=self.moving_variance_initializer,\r\n            synchronization=tf.VariableSynchronization.ON_READ,\r\n            trainable=False,\r\n            aggregation=tf.VariableAggregation.MEAN,\r\n            experimental_autocast=False)\r\n\r\n        super(SyncsBatchNormalization, self).build(input_shape)\r\n\r\n    def _assign_moving_average(self, variable: tf.Tensor, value: tf.Tensor):\r\n        return variable.assign(variable * (1.0 - self.momentum)\r\n                               + value * self.momentum)\r\n\r\n    def _get_training_value(self, training=None):\r\n\r\n        if training is None:\r\n            training = K.learning_phase()\r\n\r\n        if isinstance(training, int):\r\n            training = bool(training)\r\n\r\n        return training\r\n\r\n    def call(self, inputs, training = None, **kwargs):\r\n\r\n        x = inputs\r\n\r\n        training = self._get_training_value(training)\r\n        training_value = tf_utils.constant_value(training)\r\n\r\n        training_value = training_value and self.trainable\r\n\r\n        if training_value:\r\n            ctx = tf.distribute.get_replica_context()\r\n            n = ctx.num_replicas_in_sync * 1.0\r\n\r\n            mean = tf.reduce_mean(x, axis=self.axes)\r\n            mean_square = tf.reduce_mean(tf.square(x), axis=self.axes)\r\n            \r\n            mean, mean_square = ctx.all_reduce(tf.distribute.ReduceOp.SUM, [mean, mean_square])\r\n            \r\n            mean = mean / n\r\n            mean_square = mean_square / n\r\n\r\n            variance = mean_square - tf.square(mean)\r\n\r\n            mean_update = self._assign_moving_average(self.moving_mean, mean)\r\n            variance_update = self._assign_moving_average(self.moving_variance, variance)\r\n\r\n            self.add_update(mean_update)\r\n            self.add_update(variance_update)\r\n        else:\r\n            mean = self.moving_mean\r\n            variance = self.moving_variance\r\n\r\n        return tf.nn.batch_normalization(x, mean=mean, variance=variance, offset=self.beta,\r\n                                         scale=self.gamma,\r\n                                         variance_epsilon=self.epsilon)\r\n```", "Hi,\r\nyou just need to import the library, below is the code to regenerate the issue\r\n\r\n```python\r\nfrom __future__ import absolute_import, division, print_function, unicode_literals\r\nfrom tensorflow.keras import initializers\r\nfrom tensorflow.keras import layers\r\nfrom tensorflow.keras.layers import Input, Dense, LeakyReLU\r\n\r\n\r\nclass CustomBatchNormalization(layers.Layer):\r\n    def __init__(self, momentum=0.99, epsilon=1e-3,beta_initializer='zeros',\r\n                 gamma_initializer='ones', moving_mean_initializer='zeros',\r\n                 moving_range_initializer='ones',**kwargs):\r\n        super(CustomBatchNormalization, self).__init__(**kwargs)\r\n        self.supports_masking = True\r\n        self.momentum = momentum\r\n        self.epsilon = epsilon\r\n        self.beta_initializer = initializers.get(beta_initializer)\r\n        self.gamma_initializer = initializers.get(gamma_initializer)\r\n        self.moving_mean_initializer = initializers.get(moving_mean_initializer)\r\n        self.moving_range_initializer = (\r\n            initializers.get(moving_range_initializer))\r\n\r\n    \r\n    def build(self,input_shape):\r\n        dim = input_shape[-1]\r\n        shape = (dim,)\r\n        self.gamma = self.add_weight(shape=shape,\r\n                             name='gamma',\r\n                             initializer=self.gamma_initializer,trainable=True)\r\n        self.beta = self.add_weight(shape=shape,\r\n                            name='beta',\r\n                            initializer=self.beta_initializer,\r\n                                   trainable=True)\r\n        \r\n        self.moving_mean = self.add_weight(\r\n            shape=shape,\r\n            name='moving_mean',\r\n            initializer=self.moving_mean_initializer,\r\n            trainable=False)\r\n        \r\n        self.moving_range = self.add_weight(\r\n            shape=shape,\r\n            name='moving_range',\r\n            initializer=self.moving_range_initializer,\r\n            trainable=False)\r\n\r\n\r\n\r\n    def call(self, inputs,training=None):\r\n        input_shape = inputs.shape\r\n        \r\n        if training == False:\r\n            scaled = (inputs-self.moving_mean)/(self.moving_range+self.epsilon)\r\n            return self.gamma*scaled + self.beta\r\n        \r\n        mean = tf.math.reduce_mean(inputs,axis=0)\r\n        maxr = tf.math.reduce_max(inputs,axis=0)\r\n        minr = tf.math.reduce_min(inputs,axis=0)\r\n        \r\n        range_diff = tf.math.subtract(maxr,minr)\r\n        self.moving_mean = tf.math.add(self.momentum*self.moving_mean, (1-self.momentum)*mean)\r\n        self.moving_range = tf.math.add(self.momentum*self.moving_range,(1-self.momentum)*range_diff)\r\n        scaled = tf.math.divide(tf.math.subtract(inputs,mean),(range_diff+self.epsilon))\r\n        return tf.math.add(tf.math.multiply(self.gamma,scaled),self.beta)\r\n    \r\n    def get_config(self):\r\n        config = {\r\n            'momentum': self.momentum,\r\n            'epsilon': self.epsilon,\r\n            'beta_initializer': initializers.serialize(self.beta_initializer),\r\n            'gamma_initializer': initializers.serialize(self.gamma_initializer),\r\n            'moving_mean_initializer':\r\n                initializers.serialize(self.moving_mean_initializer),\r\n            'moving_range_initializer':\r\n                initializers.serialize(self.moving_range_initializer)\r\n        }\r\n        base_config = super(CustomBatchNormalization, self).get_config()\r\n        return dict(list(base_config.items()) + list(config.items()))\r\n    \r\n    def compute_output_shape(self, input_shape):\r\n        return input_shape\r\n\r\n\r\ninp = Input(shape=(64,))\r\nbatch_norm_1 = CustomBatchNormalization()(inp)\r\ndensout = Dense(128, activation='linear')(batch_norm_1)\r\ndensout = LeakyReLU(alpha=0.3)(densout)\r\nfor i in range (6):\r\n    batch_norm_i = CustomBatchNormalization()(densout)\r\n    densout = Dense(128, activation='linear')(batch_norm_i)\r\n    densout = LeakyReLU(alpha=0.3)(densout)\r\nbatch_norm_out = CustomBatchNormalization()(densout)\r\nout = Dense(64, activation='linear')(batch_norm_out)\r\nInp_RH_CBN = tf.keras.models.Model(inp, out)\r\n```\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36848\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36848\">No</a>\n", "@ankitesh97 \r\n\r\nI have tried on colab with TF version 2.1.0 and i am not seeing any issue.Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/ab298a28ea90e251d46e56dc838bb7dd/untitled651.ipynb). Thanks!", "Hi, thanks for the reply.\r\nIf you check this part of the code \r\n```python\r\n    def build(self,input_shape):\r\n        dim = input_shape[-1]\r\n        shape = (dim,)\r\n        self.gamma = self.add_weight(shape=shape,\r\n                             name='gamma',\r\n                             initializer=self.gamma_initializer,trainable=True)\r\n        self.beta = self.add_weight(shape=shape,\r\n                            name='beta',\r\n                            initializer=self.beta_initializer,\r\n                                   trainable=True)\r\n        \r\n        self.moving_mean = self.add_weight(\r\n            shape=shape,\r\n            name='moving_mean',\r\n            initializer=self.moving_mean_initializer,\r\n            trainable=False)\r\n        \r\n        self.moving_range = self.add_weight(\r\n            shape=shape,\r\n            name='moving_range',\r\n            initializer=self.moving_range_initializer,\r\n            trainable=False)\r\n\r\n```\r\n\r\nThere are 4 params 2 trainable and 2 non trainable. so basically there are 4 params for each feature\r\nin the batch norm layer. so if I have x features in some layer it will have 4*x params for the corresponding batch norm layer. However, if you see the summary of the Model in you gist (I have attached a screen shot)\r\n<img width=\"1092\" alt=\"Screen Shot 2020-02-19 at 12 47 58 AM\" src=\"https://user-images.githubusercontent.com/16163706/74817373-a2aa9a00-52b1-11ea-9dae-0078791d89eb.png\">\r\nYou can only see 128 params in the batchnorm layer but there should be 64x4 (128 trainable and 128 non traniable ).\r\n\r\nThanks,", "@jvishnuvardhan any updates?", "[Here](https://colab.research.google.com/gist/jvishnuvardhan/6d88fcaf01ca394e9823c8de835a1f6f/36848.ipynb) is gist with `TF2.2` for our reference. Thanks!", "What's happening here is that the `call` method is re-assigning the python attributes `self.moving_mean` and `self.moving_range`, rather than assigning to the weights stored in those attributes. This makes the custom layer no longer have access to original weights added to `moving_mean` and `moving_range`, and they are dropped from the custom_layer's weights.\r\n\r\nYou can fix this by changing the code to assign to the weight instead of replacing the weight object itself with a tensor:\r\n```\r\nself.moving_mean.assign(tf.math.add(self.momentum*self.moving_mean, (1-self.momentum)*mean))\r\nself.moving_range.assign(tf.math.add(self.momentum*self.moving_range,(1-self.momentum)*range_diff))\r\n```", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36848\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36848\">No</a>\n"]}, {"number": 36847, "title": "Unable to run \"Classifying CIFAR-10 with XLA\" Experiment: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.          [[{{node conv2d/Conv2D}}]]", "body": "Hi All,\r\nI am trying to run an example from [https://www.tensorflow.org/xla/tutorials/autoclustering_xla](https://www.tensorflow.org/xla/tutorials/autoclustering_xla) in my local. \r\n\r\nConfiguration is: Conda End, TF2.1, cuDNN 7.6, cuda 10.1 and I have tried out various combination from [https://www.tensorflow.org/install/source#tested_build_configurations](https://www.tensorflow.org/install/source#tested_build_configurations) like for TF1.14, TF1.11 but it is throwing the same error as below:\r\n\r\n\r\nI have followed solutions from [Stack Overflow](https://stackoverflow.com/questions/50622525/which-tensorflow-and-cuda-version-combinations-are-compatible); [https://www.tensorflow.org/install/gpu](https://www.tensorflow.org/install/gpu) and numerous other sources. Can someone please help me with this? I am using GeForce RTX 2080.\r\n\r\n\r\n![image](https://user-images.githubusercontent.com/48321602/74702298-96520e80-51d7-11ea-89b7-43acabff54e7.png)", "comments": ["I have referred [#28326 ](https://github.com/tensorflow/tensorflow/issues/28326) but not of much help! It is working fine on Colab but I am trying in my local server.", "@xintin \r\n\r\nPlease provide details about what platform you are using (operating system, architecture). \r\n\r\nProvide the exact sequence of commands / steps that you executed before running into the problem.Thanks!\r\n", "@ravikyram Please find the details below:\r\n\r\n18.04.1-Ubuntu x86_64 GNU/Linux\r\n\r\nuser: nvidia-smi -L\r\nGPU 0: GeForce RTX 2080 \r\nGPU 1: GeForce RTX 2080 \r\n\r\nuser: lscpu |grep 'Model name'\r\nModel name:          Intel(R) Xeon(R) Gold 5115 CPU @ 2.40GHz\r\n\r\nRegarding steps, I have tried installing TensorFlow and proceeded with the usual steps but now I am trying with the conda env. So, I created an env and installed tnesorflow, cuda and cudnn as below:\r\n\r\n(tf1_11enc)$ conda list cudnn\r\nWARNING: The conda.compat module is deprecated and will be removed in a future release.\r\n#\r\n### Name                    Version                   Build  Channel\r\ncudnn                     7.3.1                cuda10.0_0\r\n\r\n(tf1_11enc)$ conda list cuda\r\nWARNING: The conda.compat module is deprecated and will be removed in a future release.\r\n#\r\n### Name                    Version                   Build  Channel\r\ncudatoolkit               10.0.130                      0\r\n\r\n(tf1_11enc)$ conda list tensorflow\r\nWARNING: The conda.compat module is deprecated and will be removed in a future release.\r\n#\r\n### Name                    Version                   Build  Channel\r\ntensorflow                1.14.0          gpu_py37h4491b45_0\r\ntensorflow-base           1.14.0          gpu_py37h8d69cac_0\r\ntensorflow-estimator      1.14.0                     py_0\r\ntensorflow-gpu            1.14.0               h0d30ee6_0\r\n\r\nAnother configuration I am using is: TF2.0.0; cuda 10.0.130; cuDNN 7.6\r\n\r\nAfter these installations, I am trying to run the example from [ https://www.tensorflow.org/xla/tutorials/autoclustering_xla](https://www.tensorflow.org/xla/tutorials/autoclustering_xla)", "@ravikyram I have tried tf 2.1, 2.0 and 1.14 combinations from [https://www.tensorflow.org/install/source#tested_build_configurations](https://www.tensorflow.org/install/source#tested_build_configurations). Still facing the same issue! Can you help?", "I am closing this issue as it is resolved. For the reference, the issue was with the GPU memory. Please refer the below post from [Stackoverflow](https://stackoverflow.com/questions/43147983/could-not-create-cudnn-handle-cudnn-status-internal-error) to fix it:\r\n\r\nconfig = tf.ConfigProto()\r\nconfig.gpu_options.per_process_gpu_memory_fraction = 0.9\r\ntf.keras.backend.set_session(tf.Session(config=config));\r\n\r\nThank you!\r\n\r\n"]}, {"number": 36846, "title": "There aren't enough elements in this dataset for each shard to have at least one element (# elems = 1, # shards = 2)", "body": "**Environment**\r\nPython 3.7.3 (default, Dec 20 2019, 18:57:59)\r\n[GCC 8.3.0] on linux\r\ntensorflow(cpu) 2.1.0\r\ntensorflow_datasets 2.0.0\r\nDescription:    Raspbian GNU/Linux 10 (buster)\r\n\r\n**Using code the example from**\r\nhttps://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras\r\n\r\n**TFConfig below**\r\n\r\n`\r\n{'cluster': {'worker': ['RpiCluster1:2222', 'RpiCluster2:2222']}, 'task': {'type': 'worker', 'index': 0}}\r\n{'cluster': {'worker': ['RpiCluster1:2222', 'RpiCluster2:2222']}, 'task': {'type': 'worker', 'index': 1}}\r\n`\r\n\r\n**Error below seems to suggest sharding is not working**\r\n2020-02-18 03:41:12.788327: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:300] Initialize GrpcChannelCache for job worker -> {0 -> RpiCluster1:2222, 1 -> localhost:2222}\r\n2020-02-18 03:41:12.789117: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:390] Started server with target: grpc://localhost:2222\r\n2020-02-18 03:41:21.023441: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:300] Initialize GrpcChannelCache for job worker -> {0 -> localhost:2222, 1 -> RpiCluster2:2222}\r\n2020-02-18 03:41:21.024802: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:390] Started server with target: grpc://localhost:2222\r\nWARNING:tensorflow:`eval_fn` is not passed in. The `worker_fn` will be used if an \"evaluator\" task exists in the cluster.\r\nWARNING:tensorflow:`eval_fn` is not passed in. The `worker_fn` will be used if an \"evaluator\" task exists in the cluster.\r\nWARNING:tensorflow:`eval_strategy` is not passed in. No distribution strategy will be used for evaluation.\r\nWARNING:tensorflow:`eval_strategy` is not passed in. No distribution strategy will be used for evaluation.\r\nWARNING:tensorflow:`eval_fn` is not passed in. The `worker_fn` will be used if an \"evaluator\" task exists in the cluster.\r\nWARNING:tensorflow:`eval_fn` is not passed in. The `worker_fn` will be used if an \"evaluator\" task exists in the cluster.\r\nWARNING:tensorflow:`eval_strategy` is not passed in. No distribution strategy will be used for evaluation.\r\nWARNING:tensorflow:`eval_strategy` is not passed in. No distribution strategy will be used for evaluation.\r\n2020-02-18 03:41:34.450011: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\r\n         [[{{node IteratorGetNext}}]]\r\nWARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 15 batches). You may need to use the repeat() function when building your dataset.\r\nWARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 15 batches). You may need to use the repeat() function when building your dataset.\r\n2020-02-18 03:41:35.775198: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Invalid argument: There aren't enough elements in this dataset for each shard to have at least one element (# elems = 1, # shards = 2). If you are using datasets with distribution strategy, considering setting the auto sharding policy to either DATA or OFF using the `experimental_distribute.auto_shard_policy` optionof `tf.data.Options()`.\r\n         [[{{node MultiDeviceIteratorGetNextFromShard}}]]\r\n         [[RemoteCall]]\r\n         [[IteratorGetNext]]\r\n2020-02-18 03:41:35.795862: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.\r\nFound Cluster spec  {'worker': ['RpiCluster1:2222', 'RpiCluster2:2222']}\r\nFound TFConfig {'cluster': {'worker': ['RpiCluster1:2222', 'RpiCluster2:2222']}, 'task': {'type': 'worker', 'index': 0}}\r\nCreated strategy  <tensorflow.python.distribute.collective_all_reduce_strategy.CollectiveAllReduceStrategy object at 0x66fb7e70>\r\nNumber of workers  2\r\nCreating datasets inside scope...\r\nCreating model inside scope...\r\nStarting to fit model....\r\nTrain for 5 steps\r\nEpoch 1/3\r\n2020-02-18 03:41:36.589112: W tensorflow/python/util/util.cc:319] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\r\nWARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nIf using Keras pass *_constraint arguments to layers.\r\nWARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nIf using Keras pass *_constraint arguments to layers.\r\n2020-02-18 03:41:39.502892: W tensorflow/python/util/util.cc:319] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\r\n2020-02-18 03:41:39.615315: E tensorflow/core/common_runtime/ring_alg.cc:279] Aborting RingReduce with Cancelled: RPC Request was cancelled\r\n2020-02-18 03:41:39.615446: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Cancelled: RPC Request was cancelled\r\n2020-02-18 03:41:39.615763: W tensorflow/core/framework/op_kernel.cc:1655] OP_REQUIRES failed at collective_ops.cc:253 : Cancelled: RPC Request was cancelled\r\n2020-02-18 03:41:39.615850: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Cancelled: RPC Request was cancelled\r\n         [[{{node CollectiveReduce}}]]\r\nFound Cluster spec  {'worker': ['RpiCluster1:2222', 'RpiCluster2:2222']}\r\nFound TFConfig {'cluster': {'worker': ['RpiCluster1:2222', 'RpiCluster2:2222']}, 'task': {'type': 'worker', 'index': 1}}\r\nCreated strategy  <tensorflow.python.distribute.collective_all_reduce_strategy.CollectiveAllReduceStrategy object at 0x670a3c10>\r\nNumber of workers  2\r\nCreating datasets inside scope...\r\nCreating model inside scope...\r\nStarting to fit model....\r\nTrain for 5 steps\r\nEpoch 1/3\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 753, in on_start\r\n    yield\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 397, in fit\r\n    prefix='val_')\r\n  File \"/usr/lib/python3.7/contextlib.py\", line 130, in __exit__\r\n    self.gen.throw(type, value, traceback)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 771, in on_epoch\r\n    self.callbacks.on_epoch_end(epoch, epoch_logs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/callbacks.py\", line 302, in on_epoch_end\r\n    callback.on_epoch_end(epoch, logs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/callbacks.py\", line 990, in on_epoch_end\r\n    self._save_model(epoch=epoch, logs=logs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/callbacks.py\", line 1040, in _save_model\r\n    self.model.save(filepath, overwrite=True)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/network.py\", line 1008, in save\r\n    signatures, options)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/saving/save.py\", line 115, in save_model\r\n    signatures, options)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/saving/saved_model/save.py\", line 78, in save\r\n    save_lib.save(model, filepath, signatures, options)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/saved_model/save.py\", line 916, in save\r\n    object_saver.save(utils_impl.get_variables_path(export_dir))\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/tracking/util.py\", line 1168, in save\r\n    file_prefix=file_prefix_tensor, object_graph_tensor=object_graph_tensor)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/tracking/util.py\", line 1116, in _save_cached_when_graph_building\r\n    save_op = saver.save(file_prefix)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/saving/functional_saver.py\", line 230, in save\r\n    sharded_saves.append(saver.save(shard_prefix))\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/saving/functional_saver.py\", line 69, in save\r\n    tensors.append(spec.tensor)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/saving/saveable_object.py\", line 52, in tensor\r\n    return self._tensor() if callable(self._tensor) else self._tensor\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/values.py\", line 1252, in tensor\r\n    return strategy.extended.read_var(sync_on_read_variable)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/mirrored_strategy.py\", line 769, in read_var\r\n    return replica_local_var._get_cross_replica()  # pylint: disable=protected-access\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/values.py\", line 1347, in _get_cross_replica\r\n    self, axis=None)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/distribute_lib.py\", line 808, in reduce\r\n    return self._extended._reduce(reduce_op, value)  # pylint: disable=protected-access\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/distribute_lib.py\", line 1449, in _reduce\r\n    device_util.current() or \"/device:CPU:0\"))[0]\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/collective_all_reduce_strategy.py\", line 528, in _reduce_to\r\n    reduce_op, value, destinations=destinations)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/cross_device_ops.py\", line 282, in reduce\r\n    destinations)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/cross_device_ops.py\", line 1038, in reduce_implementation\r\n    all_reduced = self._batch_all_reduce(reduce_op, [per_replica_value])[0]\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/cross_device_ops.py\", line 1118, in _batch_all_reduce\r\n    dense_results = self._do_batch_all_reduce_dense(reduce_op, dense_values)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/cross_device_ops.py\", line 1160, in _do_batch_all_reduce_dense\r\n    \"Id\", communication_hint)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/cross_device_utils.py\", line 368, in build_collective_reduce\r\n    return collective_all_reduce()\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/def_function.py\", line 568, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/def_function.py\", line 638, in _call\r\n    return self._concrete_stateful_fn._filtered_call(canon_args, canon_kwds)  # pylint: disable=protected-access\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/function.py\", line 1611, in _filtered_call\r\n    self.captured_inputs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/function.py\", line 1692, in _call_flat\r\n    ctx, args, cancellation_manager=cancellation_manager))\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/function.py\", line 545, in call\r\n    ctx=ctx)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/execute.py\", line 67, in quick_execute\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.CancelledError:  RPC Request was cancelled\r\n         [[node CollectiveReduce (defined at /usr/lib/python3.7/contextlib.py:130) ]] [Op:__inference_collective_all_reduce_1457]\r\n\r\nFunction call stack:\r\ncollective_all_reduce\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"main_2.py\", line 98, in <module>\r\n    multi_worker_model.fit(x=train_datasets, epochs=3, steps_per_epoch=5, callbacks = callbacks)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training.py\", line 819, in fit\r\n    use_multiprocessing=use_multiprocessing)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_distributed.py\", line 790, in fit\r\n    *args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_distributed.py\", line 777, in wrapper\r\n    mode=dc.CoordinatorMode.INDEPENDENT_WORKER)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/distribute_coordinator.py\", line 853, in run_distribute_coordinator\r\n    task_id, session_config, rpc_layer)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/distribute_coordinator.py\", line 360, in _run_single_worker\r\n    return worker_fn(strategy)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_distributed.py\", line 772, in _worker_fn\r\n    return method(model, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 397, in fit\r\n    prefix='val_')\r\n  File \"/usr/lib/python3.7/contextlib.py\", line 130, in __exit__\r\n    self.gen.throw(type, value, traceback)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 757, in on_start\r\n    self.callbacks._call_end_hook(mode)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/callbacks.py\", line 262, in _call_end_hook\r\n    self.on_train_end()\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/callbacks.py\", line 379, in on_train_end\r\n    callback.on_train_end(logs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/callbacks.py\", line 966, in on_train_end\r\n    self._training_state.delete_backup()\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/distribute/multi_worker_training_state.py\", line 173, in delete_backup\r\n    tracking.AutoTrackable.__delattr__(self._model, CKPT_SAVED_EPOCH)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/tracking/tracking.py\", line 94, in __delattr__\r\n    super(AutoTrackable, self).__delattr__(name)\r\nAttributeError: _ckpt_saved_epoch\r\nWARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nIf using Keras pass *_constraint arguments to layers.\r\nWARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nIf using Keras pass *_constraint arguments to layers.\r\n2020-02-18 03:41:41.376299: W tensorflow/core/common_runtime/eager/context.cc:349] Unable to destroy server_ object, so releasing instead. Servers don't support clean shutdown.\r\nsrun: error: RpiCluster2: task 1: Exited with exit code 1\r\n2020-02-18 03:41:45.023032: E tensorflow/core/common_runtime/ring_alg.cc:279] Aborting RingReduce with Invalid argument: [_Derived_]There aren't enough elements in this dataset for each shard to have at least one element (# elems = 1, # shards = 2). If you are using datasets with distribution strategy, considering setting the auto sharding policy to either DATA or OFF using the `experimental_distribute.auto_shard_policy` optionof `tf.data.Options()`.\r\n         [[{{node MultiDeviceIteratorGetNextFromShard}}]]\r\n         [[RemoteCall]]\r\n         [[IteratorGetNext]]\r\n2020-02-18 03:41:45.023246: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Invalid argument: [_Derived_]There aren't enough elements in this dataset for each shard to have at least one element (# elems = 1, # shards = 2). If you are using datasets with distribution strategy, considering setting the auto sharding policy to either DATA or OFF using the `experimental_distribute.auto_shard_policy` optionof `tf.data.Options()`.\r\n         [[{{node MultiDeviceIteratorGetNextFromShard}}]]\r\n         [[RemoteCall]]\r\n         [[IteratorGetNext]]\r\n2020-02-18 03:41:45.023715: W tensorflow/core/framework/op_kernel.cc:1655] OP_REQUIRES failed at collective_ops.cc:253 : Invalid argument: [_Derived_]There aren't enough elements in this dataset for each shard to have at least one element (# elems = 1, # shards = 2). If you are using datasets with distribution strategy, considering setting the auto sharding policy to either DATA or OFF using the `experimental_distribute.auto_shard_policy` optionof `tf.data.Options()`.\r\n         [[{{node MultiDeviceIteratorGetNextFromShard}}]]\r\n         [[RemoteCall]]\r\n         [[IteratorGetNext]]\r\n2020-02-18 03:41:45.024006: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Invalid argument: [_Derived_]There aren't enough elements in this dataset for each shard to have at least one element (# elems = 1, # shards = 2). If you are using datasets with distribution strategy, considering setting the auto sharding policy to either DATA or OFF using the `experimental_distribute.auto_shard_policy` optionof `tf.data.Options()`.\r\n         [[{{node MultiDeviceIteratorGetNextFromShard}}]]\r\n         [[RemoteCall]]\r\n         [[IteratorGetNext]]\r\n         [[CollectiveReduce]]\r\nTraceback (most recent call last):\r\n  File \"main_2.py\", line 98, in <module>\r\n    multi_worker_model.fit(x=train_datasets, epochs=3, steps_per_epoch=5, callbacks = callbacks)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training.py\", line 819, in fit\r\n    use_multiprocessing=use_multiprocessing)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_distributed.py\", line 790, in fit\r\n    *args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_distributed.py\", line 777, in wrapper\r\n    mode=dc.CoordinatorMode.INDEPENDENT_WORKER)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/distribute_coordinator.py\", line 853, in run_distribute_coordinator\r\n    task_id, session_config, rpc_layer)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/distribute_coordinator.py\", line 360, in _run_single_worker\r\n    return worker_fn(strategy)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_distributed.py\", line 772, in _worker_fn\r\n    return method(model, **kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 397, in fit\r\n    prefix='val_')\r\n  File \"/usr/lib/python3.7/contextlib.py\", line 130, in __exit__\r\n    self.gen.throw(type, value, traceback)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 771, in on_epoch\r\n    self.callbacks.on_epoch_end(epoch, epoch_logs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/callbacks.py\", line 302, in on_epoch_end\r\n    callback.on_epoch_end(epoch, logs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/callbacks.py\", line 990, in on_epoch_end\r\n    self._save_model(epoch=epoch, logs=logs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/callbacks.py\", line 1040, in _save_model\r\n    self.model.save(filepath, overwrite=True)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/network.py\", line 1008, in save\r\n    signatures, options)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/saving/save.py\", line 115, in save_model\r\n    signatures, options)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/saving/saved_model/save.py\", line 78, in save\r\n    save_lib.save(model, filepath, signatures, options)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/saved_model/save.py\", line 916, in save\r\n    object_saver.save(utils_impl.get_variables_path(export_dir))\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/tracking/util.py\", line 1168, in save\r\n    file_prefix=file_prefix_tensor, object_graph_tensor=object_graph_tensor)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/tracking/util.py\", line 1116, in _save_cached_when_graph_building\r\n    save_op = saver.save(file_prefix)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/saving/functional_saver.py\", line 230, in save\r\n    sharded_saves.append(saver.save(shard_prefix))\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/saving/functional_saver.py\", line 69, in save\r\n    tensors.append(spec.tensor)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/saving/saveable_object.py\", line 52, in tensor\r\n    return self._tensor() if callable(self._tensor) else self._tensor\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/values.py\", line 1252, in tensor\r\n    return strategy.extended.read_var(sync_on_read_variable)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/mirrored_strategy.py\", line 769, in read_var\r\n    return replica_local_var._get_cross_replica()  # pylint: disable=protected-access\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/values.py\", line 1347, in _get_cross_replica\r\n    self, axis=None)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/distribute_lib.py\", line 808, in reduce\r\n    return self._extended._reduce(reduce_op, value)  # pylint: disable=protected-access\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/distribute_lib.py\", line 1449, in _reduce\r\n    device_util.current() or \"/device:CPU:0\"))[0]\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/collective_all_reduce_strategy.py\", line 528, in _reduce_to\r\n    reduce_op, value, destinations=destinations)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/cross_device_ops.py\", line 282, in reduce\r\n    destinations)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/cross_device_ops.py\", line 1038, in reduce_implementation\r\n    all_reduced = self._batch_all_reduce(reduce_op, [per_replica_value])[0]\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/cross_device_ops.py\", line 1118, in _batch_all_reduce\r\n    dense_results = self._do_batch_all_reduce_dense(reduce_op, dense_values)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/cross_device_ops.py\", line 1160, in _do_batch_all_reduce_dense\r\n    \"Id\", communication_hint)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/cross_device_utils.py\", line 368, in build_collective_reduce\r\n    return collective_all_reduce()\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/def_function.py\", line 568, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/def_function.py\", line 638, in _call\r\n    return self._concrete_stateful_fn._filtered_call(canon_args, canon_kwds)  # pylint: disable=protected-access\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/function.py\", line 1611, in _filtered_call\r\n    self.captured_inputs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/function.py\", line 1692, in _call_flat\r\n    ctx, args, cancellation_manager=cancellation_manager))\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/function.py\", line 545, in call\r\n    ctx=ctx)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/execute.py\", line 67, in quick_execute\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError:  [_Derived_]There aren't enough elements in this dataset for each shard to have at least one element (# elems = 1, # shards = 2). If you are using datasets with distribution strategy, considering setting the auto sharding policy to either DATA or OFF using the `experimental_distribute.auto_shard_policy` optionof `tf.data.Options()`.\r\n         [[{{node MultiDeviceIteratorGetNextFromShard}}]]\r\n         [[RemoteCall]]\r\n         [[IteratorGetNext]]\r\n         [[CollectiveReduce]] [Op:__inference_collective_all_reduce_1477]\r\n\r\nFunction call stack:\r\ncollective_all_reduce\r\n\r\n2020-02-18 03:41:47.749541: W tensorflow/core/common_runtime/eager/context.cc:349] Unable to destroy server_ object, so releasing instead. Servers don't support clean shutdown.\r\n1/5 [=====>........................] - ETA: 22ssrun: error: RpiCluster1: task 0: Exited with exit code 1\r\n\r\n", "comments": ["I have the exact same issue using `tensorflow/tensorflow:2.0.0-py3`", "Hi - this error suggests that your input dataset is reading from one file? When you use Multi worker strategy with keras model.fit, we try to automatically shard your input dataset at the file level across workers. but if you have 2 workers and only one file, it's not possible to shard that. Hence this error - the recommendation is to set `experimental_distribute.auto_shard_policy` on your input dataset and that will turn automatic sharding off. (in absence of sharding, make sure you have shuffle in your input dataset. You can read more about this here: https://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras#dataset_sharding_and_batch_size\r\n\r\nIf this is not the case in your dataset, please provide code to repro the problem. \r\n\r\n", "I get this error when I used a TensorFlow Dataset, which is supposed to support automatic sharding...", "How to manage the files, is that the work of TDFS and why it needs to be within the strategy scope?\n________________________________\nFrom: Karl Schriek <notifications@github.com>\nSent: Monday, February 24, 2020 2:55:39 AM\nTo: tensorflow/tensorflow <tensorflow@noreply.github.com>\nCc: Ian Ferreira <ianferreira@hotmail.com>; Author <author@noreply.github.com>\nSubject: Re: [tensorflow/tensorflow] There aren't enough elements in this dataset for each shard to have at least one element (# elems = 1, # shards = 2) (#36846)\n\n\nI get this error when I used a TensorFlow Dataset, which is supposed to support automatic sharding...\n\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub<https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fissues%2F36846%3Femail_source%3Dnotifications%26email_token%3DAABIJ47SOJ2DEJQVCKBSBCDREORSXA5CNFSM4KW4OCPKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEMXLYGI%23issuecomment-590265369&data=02%7C01%7C%7C2ff945fa548c4e531cdf08d7b918167d%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637181385407681783&sdata=iBjHcGCJJucA3Fug1oefHiq5usiErPFftcUx3xAvpt0%3D&reserved=0>, or unsubscribe<https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fnotifications%2Funsubscribe-auth%2FAABIJ45IOA4VJLXA5XJKTH3REORSXANCNFSM4KW4OCPA&data=02%7C01%7C%7C2ff945fa548c4e531cdf08d7b918167d%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637181385407691778&sdata=P8gwSgW4ZMqQvLVSYjAGSA%2Bi6VVzhFz%2BBv0NqqHMSUE%3D&reserved=0>.\n", "@karlschriek if the TFDS dataset you are using is reading from only one file, then it will have the same problem. Please try out https://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras#dataset_sharding_and_batch_size which you can set on the dataset object you get from TFDS.\r\n\r\n@ianferreira Currently the dataset needs to be created after the strategy object is created due to some limitation in the TF2 runtime, we are actively working on removing this restriction. It doesn't need to be in the scope, but putting it in the scope is an easy way to ensure you're creating it after the strategy. Please try it outside the scope and let us know if that doesn't work. \r\n\r\n", "@guptapriya same error outside scope. There is something really weird going on the TFDS.\r\n\r\n`\r\nBUFFER_SIZE = 10000\r\nBATCH_SIZE = 10000\r\n\r\n\r\ndef make_datasets_unbatched():\r\n  def scale(image, label):\r\n    image = tf.cast(image, tf.float32)\r\n    image /= 255\r\n    return image, label\r\n\r\n  datasets, info = tfds.load(name='mnist',\r\n                            with_info=True,\r\n                            as_supervised=True)\r\n  if my_task_index == 0:\r\n    print(info)\r\n  assert info.features['image'].shape == (28, 28, 1)\r\n  assert info.features['label'].num_classes == 10\r\n  assert info.splits['train'].num_examples == 60000\r\n  ds = datasets['train'].repeat().batch(BATCH_SIZE)\r\n  return ds\r\n\r\ndef build_and_compile_cnn_model():\r\n  model = tf.keras.Sequential([\r\n      tf.keras.layers.Flatten(input_shape=(28,28,1)),\r\n      tf.keras.layers.Dense(128, activation='relu'),\r\n      tf.keras.layers.Dropout(0.5),\r\n      tf.keras.layers.Dense(10, activation='softmax')\r\n\r\n  ])\r\n  model.compile(\r\n      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n      optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),\r\n      metrics=['accuracy'])\r\n  return model\r\n\r\ncallbacks = [tf.keras.callbacks.TensorBoard(log_dir='logs')]\r\n\r\n\r\nstrategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\r\n\r\n\r\nprint(\"Created strategy \" , strategy)\r\nNUM_WORKERS = strategy.num_replicas_in_sync\r\nprint(\"Number of workers \" ,NUM_WORKERS )\r\n\r\nGLOBAL_BATCH_SIZE = 16 * NUM_WORKERS\r\nwith strategy.scope():\r\n  print(\"Creating model inside scope...\")\r\n  model = build_and_compile_cnn_model()\r\n  print(model.summary())\r\n  print(\"Creating datasets inside scope...\")\r\n  train_datasets = make_datasets_unbatched()\r\n  print(\"Created datasets \" , train_datasets)\r\n\r\n\r\nprint(\"Starting to fit model....\")\r\nverbose = 1 if my_task_index == 0 else 0\r\nmodel.fit(train_datasets, epochs=3, steps_per_epoch=5, callbacks = callbacks, verbose=verbose)\r\nprint(\"Model fit completed\")\r\n`\r\n**ERRORS like so**\r\n`\r\nFound Cluster spec  {'worker': ['RpiCluster1:2222', 'RpiCluster2:2222', 'RpiCluster3:2222']}\r\nFound TFConfig {'cluster': {'worker': ['RpiCluster1:2222', 'RpiCluster2:2222', 'RpiCluster3:2222']}, 'task': {'type': 'worker', 'index': 0}}\r\nCreated strategy  <tensorflow.python.distribute.collective_all_reduce_strategy.CollectiveAllReduceStrategy object at 0x767012b0>\r\nNumber of workers  3\r\nCreating model inside scope...\r\nModel: \"sequential\"\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #\r\n=================================================================\r\nflatten (Flatten)            (None, 784)               0\r\n_________________________________________________________________\r\ndense (Dense)                (None, 128)               100480\r\n_________________________________________________________________\r\ndropout (Dropout)            (None, 128)               0\r\n_________________________________________________________________\r\ndense_1 (Dense)              (None, 10)                1290\r\n=================================================================\r\nTotal params: 101,770\r\nTrainable params: 101,770\r\nNon-trainable params: 0\r\n_________________________________________________________________\r\nNone\r\nCreating datasets inside scope...\r\ntfds.core.DatasetInfo(\r\n    name='mnist',\r\n    version=3.0.0,\r\n    description='The MNIST database of handwritten digits.',\r\n    homepage='http://yann.lecun.com/exdb/mnist/',\r\n    features=FeaturesDict({\r\n        'image': Image(shape=(28, 28, 1), dtype=tf.uint8),\r\n        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\r\n    }),\r\n    total_num_examples=70000,\r\n    splits={\r\n        'test': 10000,\r\n        'train': 60000,\r\n    },\r\n    supervised_keys=('image', 'label'),\r\n    citation=\"\"\"@article{lecun2010mnist,\r\n      title={MNIST handwritten digit database},\r\n      author={LeCun, Yann and Cortes, Corinna and Burges, CJ},\r\n      journal={ATT Labs [Online]. Available: http://yann. lecun. com/exdb/mnist},\r\n      volume={2},\r\n      year={2010}\r\n    }\"\"\",\r\n    redistribution_info=,\r\n)\r\n\r\nCreated datasets  <DatasetV1Adapter shapes: ((None, 28, 28, 1), (None,)), types: (tf.uint8, tf.int64)>\r\nStarting to fit model....\r\nTrain for 5 steps\r\nEpoch 1/3\r\nWARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 15 batches). You may need to use the repeat() function when building your dataset.\r\nWARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 15 batches). You may need to use the repeat() function when building your dataset.\r\nWARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 15 batches). You may need to use the repeat() function when building your dataset.\r\nWARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 15 batches). You may need to use the repeat() function when building your dataset.\r\n`", "I meet the same problem when I use this tutorial:\r\nhttps://tensorflow.google.cn/tutorials/distribute/multi_worker_with_keras?hl=en\r\nI fixed this according to the doc:\r\nhttps://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras#dataset_sharding_and_batch_size\r\nAs a newcomer to use Tensorflow, this problem cost a lot of my time, to help others who meet the same problem, I paste the runnable code with some annotations.\r\n\r\n```\r\nfrom __future__ import absolute_import, division, print_function, unicode_literals\r\n\r\nimport json\r\nimport tensorflow_datasets as tfds\r\nimport tensorflow as tf\r\nimport os\r\n\r\nBUFFER_SIZE = 10000\r\nBATCH_SIZE = 32\r\n\r\n\r\nos.environ['TF_CONFIG'] = json.dumps({\r\n    'cluster': {\r\n        'worker': [\"worker1:12345\", \"worker2:23456\"]\r\n    },\r\n    'task': {'type': 'worker', 'index': 0}      # the index is the first machine, the second machine's index should be 1\r\n})\r\n\r\nstrategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\r\n\r\ndef make_datasets_unbatched():\r\n  #Scaling MNIST data from (0, 255] to (0., 1.]\r\n  def scale(image, label):\r\n    image = tf.cast(image, tf.float32)\r\n    image /= 255\r\n    return image, label\r\n\r\n  datasets, info = tfds.load(name='mnist', with_info=True, as_supervised=True)\r\n\r\n  return datasets['train'].map(scale, num_parallel_calls=tf.data.experimental.AUTOTUNE).cache().shuffle(BUFFER_SIZE)\r\n\r\ndef build_and_compile_cnn_model():\r\n  model = tf.keras.Sequential([\r\n      tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\r\n      tf.keras.layers.MaxPooling2D(),\r\n      tf.keras.layers.Flatten(),\r\n      tf.keras.layers.Dense(64, activation='relu'),\r\n      tf.keras.layers.Dense(10)\r\n  ])\r\n  model.compile(\r\n      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n      optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),\r\n      metrics=['accuracy'])\r\n  return model\r\n  \r\n#single_worker_model = build_and_compile_cnn_model()\r\n#single_worker_model.fit(x=train_datasets, epochs=3, steps_per_epoch=5)\r\n\r\nNUM_WORKERS = 2\r\n#Here the batch size scales up by number of workers since \r\n#`tf.data.Dataset.batch` expects the global batch size. Previously we used 64, \r\n#and now this becomes 128.\r\nGLOBAL_BATCH_SIZE = 64 * NUM_WORKERS\r\n\r\n#Creation of dataset needs to be after MultiWorkerMirroredStrategy object\r\n#is instantiated.\r\ntrain_datasets = make_datasets_unbatched().batch(GLOBAL_BATCH_SIZE)\r\n\r\n#next three line is the key point to fix this problem\r\noptions = tf.data.Options()\r\noptions.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.DATA  # AutoShardPolicy.OFF can work too.\r\ntrain_datasets_no_auto_shard = train_datasets.with_options(options)\r\n\r\nwith strategy.scope():\r\n  #Model building/compiling need to be within `strategy.scope()`.\r\n  multi_worker_model = build_and_compile_cnn_model()\r\n\r\n#Keras' `model.fit()` trains the model with specified number of epochs and\r\n#number of steps per epoch. Note that the numbers here are for demonstration\r\n#purposes only and may not sufficiently produce a model with good quality.\r\n\r\n#attention:   x=train_datasets_no_auto_shard , not x = train_datasets\r\nmulti_worker_model.fit(x=train_datasets_no_auto_shard, epochs=3, steps_per_epoch=5)\r\n\r\n```", "@maqy1995 Good job! And I would like to add a few more explanations for this issue. In multi worker training modes, the distribution strategy will \"shard\" the dataset, i.e., splitting the dataset and sending each worker a different part.\r\n\r\nAccording to [documentation of `tf.data.experimental.DistributeOptions`](https://www.tensorflow.org/api_docs/python/tf/data/experimental/DistributeOptions), `auto_shard_policy` defaults to `AUTO`, which first tries to shard the files. If the `tf.data.Dataset` is created from TFRecord files, then the TFRecord files will be split into groups of number of workers. However, for a very small dataset (like MNIST), the whole dataset is stored in only one TFRecord file, and this is why the file-based auto sharding will fail and throw an exception saying \"There aren't enough elements in this dataset for each shard to have at least one element\"!\r\n\r\nTherefore, when using a multi-worker strategy to train on a very small dataset, we need to manually set the `auto_shard_policy` to `DATA` or `OFF`. Though, multi-worker strategies are designed for accelerating the training of huge datasets that are supposed to contain enough number of files!", "@BinyanHu  please update your examples, because the example uses MNIST :) ", "@ianferreira in your pasted code, you have `BATCH_SIZE=10000`. is that intentional? MNIST only has 60k examples, which is probably why it is running out of data when you try to run a few steps. The tutorial shows BATCH_SIZE=64. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36846\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36846\">No</a>\n", "Is there a reason why this has been closed? I don't see that the problem has been resolved!", "@zhuzilin in that example, only the buffer size is 10000, not batch size. Those are 2 very different things. \r\n@karlschriek please provide reproducible code if you're still seeing this issue with latest TF nightly.", "@ianferreira I also used MNIST to test and I applied exactly the same solution as\u00a0@maqy1995. I was just adding some explainations. ", "This should still be open because the tutorial doesn't explicitly mention needing this for the tutorial to work: \r\nhttps://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras#dataset_sharding_and_batch_size\r\n\r\nCan we fix the documentation to explicitly add this?", "Agreed, @rchao can you help update the tutorial?"]}, {"number": 36845, "title": "tf.keras.losses.SparseCategoricalCrossentropy within the multi-GPU strategy.scope() generates NAN value", "body": "", "comments": ["In the single-gpu case, I have\r\n```\r\nepoch:0, batch:0, loss:1.0988747737\r\nepoch:0, batch:1, loss:0.9993420934\r\nepoch:0, batch:2, loss:0.9823420342\r\n```\r\n\r\nIn the multi-gpu case, I have the result\r\n```\r\nepoch:0, batch:0, loss:11783.943359375\r\nepoch:0, batch:1, loss:inf\r\nepoch:0, batch:2, loss:inf\r\nepoch:0, batch:3, loss:inf\r\n```", "@YINWIZHANG \r\n\r\nPlease provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. \r\nRequest you to fill the [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).Thanks!\r\n\r\n\r\n", "> @YINWIZHANG\r\n> \r\n> Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version.\r\n> Request you to fill the [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).Thanks!\r\n\r\nI am using ubuntu 18.04 and tensorflow 2.0.0. My PC is a Lambda stack which has 4 RTX8000 GPUs. ", "@YINWIZHANG In order to help us investigate this issue, can you provide the following extra bits of information:\r\n- Details of your `resnet_fcn1`\r\n- Details of your training dataset, `train_ds`.\r\n\r\nIf there can be actual code that forms a minimal reproduction case it'll be great.", "@YINWIZHANG I experienced a similar problem. At first the loss exploded, after some day the loss stalled and at some point, everything just started crashing. In the end is was a defective GPU.\r\nIt doesn't mean you have the same problem, but maybe those tipps will help you narrow it down :\r\n\r\n- Does every GPU work fine? Did you try using `tf.device('device:GPU:1'):` or 2,3. ?\r\n\r\n- Test with [gpu-burn](https://github.com/wilicc/gpu-burn) to check, if all GPUs work properly. \r\n", "> @YINWIZHANG I experienced a similar problem. At first the loss exploded, after some day the loss stalled and at some point, everything just started crashing. In the end is was a defective GPU.\r\n> It doesn't mean you have the same problem, but maybe those tipps will help you narrow it down :\r\n> \r\n>     * Does every GPU work fine? Did you try using `tf.device('device:GPU:1'):` or 2,3. ?\r\n> \r\n>     * Test with [gpu-burn](https://github.com/wilicc/gpu-burn) to check, if all GPUs work properly.\r\n\r\nThanks for your comments! It turns out that I have all my GPUs working fine. A really strange thing is that, even when I use above multiGPU code in a machine with single GPU, the loss value explodes. ", "@YINWIZHANG \r\n\r\nCan you try modifying your loss function under the MirroredStrategy as follows:\r\n\r\n```py\r\ndef compute_loss(labels, predictions):\r\n  per_example_loss = loss_object(labels, predictions)\r\n  per_example_loss /= tf.cast(\r\n      tf.shape(labels)[1] * tf.shape(labels)[2], tf.float32)  # <--- See if this fixes the NaNs.\r\n  return tf.nn.compute_average_loss(\r\n      per_example_loss, global_batch_size=GLOBAL_BATCH_SIZE)\r\n```", "> @YINWIZHANG\r\n> \r\n> Can you try modifying your loss function under the MirroredStrategy as follows:\r\n> \r\n> ```python\r\n> def compute_loss(labels, predictions):\r\n>   per_example_loss = loss_object(labels, predictions)\r\n>   per_example_loss /= tf.cast(\r\n>       tf.shape(labels)[1] * tf.shape(labels)[2], tf.float32)  # <--- See if this fixes the NaNs.\r\n>   return tf.nn.compute_average_loss(\r\n>       per_example_loss, global_batch_size=GLOBAL_BATCH_SIZE)\r\n> ```\r\n\r\nThanks! It solves the problem!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36845\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36845\">No</a>\n"]}, {"number": 36844, "title": "Documentation is very unclear. It lacks formulas in many APIs.", "body": "For example, in SparseCategoricalAccuracy(), the words in this API does not help to give a clear picture to understand what it is doing. Why not give a formula. A formula, associated with an example, is clear enough for this API.", "comments": ["@FrankYinXF \r\n\r\nCan you please provide the links you are referring to.Thanks!", "Can you please mention which formula you need exactly,I might probably be able to help you with that.", "@FrankYinXF \r\nI can relate to you on this ... Let me clarfiy it for you.\r\nThe SparseCategoricalEntropy is similar to the CategoricalCrossentropy Function.\r\nThe only difference being that the y_true need not be one-hot columns instead they are integer values denoting class number.\r\n\r\n**Let's try it with an example:\r\nYou have a 3 class prediction example namely cat, dog and monkey.\r\ncat is assigned as your first label        --> 0\r\ndog is assigned as your second label --> 1\r\nmonkey as your third label                  --> 2**\r\n\r\nNow while predicting through any network the output logits must have a shape of 3 with one for each of the above mentioned class. When you keep the parameter **logits=True** in the SparseCategoricalCrossEntropy function we feed this layer directly in the loss function as y_pred.\r\nHere the y_true which the loss function expects is not a one-hot column of shape (3,) instead a single integer value corresponding to the class i.e. \r\n0-> cat\r\n1-> dog\r\n2-> monkey\r\n\r\nWhat the above function does is that it first applies a softmax function(if logits=True) and computes class probailities and on these probabilites it applies a crossentropy function. Now the crossentropy here expects inputs of the same shape so sparsecategoricalcrossEntropy makes a one-hot column in a optimized way to compute the loss instead of feeding a one-hot ourself.\r\n\r\nIt saves us 2 things , first the burden of making a one-hot column every time and also reduces memory usage as we don't need to save labels as one-hot columns. This is especially useful when the number of classes is extremely high say **>1000**.\r\n\r\nNow if **logits=False** the function expects softmax probabilities instead of the logits as input.\r\n\r\nPlease reply if you need any more clarifications.\r\nHappy to help.", "> @FrankYinXF\r\n> \r\n> Can you please provide the links you are referring to.Thanks!\r\n\r\nAny updates regarding this issue? Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 36843, "title": "Pass full input_shape to cell.build()", "body": "`step_input_shape` unnecessarily deprives `Cell` instances of potentially necessary information - namely, custom architectures may require the layer's `timesteps` at build time (before `call()`). There are no performance or memory gains from trimming a list by one, nor really in clarity as this isn't being passed to `call` where the input shape does omit the time dimension (and in that case `input_shape` as opposed to `step_input_shape` is misleading anyway).\r\n\r\nThis commit does not require changing any other code in `recurrent` or `recurrent_v2`, as `input_shape` is indexed via `[-1]` - though unsure for the rest of the repository; either way, nothing is lost with this commit.", "comments": ["This breaks the API contract that layers.build() method will get the shape of input tensor, which should be same as the one passed in when call() is invoked. So far the cell only rely on the last dim of the inputs to build the weights, but this might not be true for other customized cells, eg if the cell somehow rely on the batch size to do certain behavior, in the time_major input case, the first dim is no longer batch, but timestep if we pass the full input shape.", "@qlzh727 Is [recurrent_v2](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/layers/recurrent_v2.py#L1118) exempt from this contract, then? `timesteps` is extracted from `input_shape`, so its `call()` has a different `input_shape` than its `build()` (via `super()`).", "I am not sure what you mean. In LSTM v2, the call() and build() will get same input_shape. Could u be more specific about the different shape here?", "@qlzh727 `input_shape` isn't actually passed in, but extracted as [`K.int_shape(inputs)`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/layers/recurrent_v2.py#L1117), and the layer doesn't define its own `build()`,  but inherits it from `recurrent.LSTM` - so basically a \"trick\" to circumvent the contract. Well, such tricks are quite inconvenient to implement for custom RNN layers - one's via re-implementing the base class (`RNN`), another is to pass `timesteps` to each layer in the model by fetching it manually from preceding layers.\r\n\r\nI'm guessing regardless of who oversees this 'contract', the process for possibly changing it will take months - so instead, how about this: pass full `input_shape` to _both_, `build()` and `call()` of all recurrent layers. Would that work?", "> I'm guessing regardless of who oversees this 'contract', the process for possibly changing it will take months - so instead, how about this: pass full input_shape to both, build() and call() of all recurrent layers. Would that work?\r\n\r\nAll the recurrent layer IS currently getting full input_shape for both build() and call(). All the recurrent cells is getting input shapes without the timestep dimension. I don't think this contract need to be changed for RNN.\r\n\r\nMy question, however, is why the cell need timestep in the build() method. A cell should handle the input one timestep by one timestep, and it shouldn't care how many timesteps there will be for the whole sequence. Can u be more specific about why the timestep is needed? (Is it related to https://github.com/tensorflow/tensorflow/issues/36559?)\r\n", "@qlzh727 I include the time dimension in the \"full\" input shape, as that's what the layer is fed in the model network. And you are correct, this is about recurrent batch normalization - but also [IndRNNs](https://arxiv.org/abs/1803.04831), which require `timesteps` at build time for `recurrent_kernel` initialization. I've implemented the layer in `tf.keras` in TF 1 & 2 without publishing - and for the record, it easily dominates LSTMs and GRUs in my application, and I may PR it in the future.\r\n\r\nThis said, while TF currently doesn't have any layers that need `timesteps` at build time, some users (like myself) may need it for custom functionality. Nothing is lost from passing it instead of \"step input shape\" - so omitting the time dimension is unnecessarily prohibitive.", "Sorry for the late reply. If your cell need to be timestep aware, then it is no longer a cell, but a RNN layer, since the cell only exposed to one timestep at a time. Maybe you should create subclass RNN layer instead of a cell?", "@qlzh727 `build()` belongs to cells, and `RNN` base class never passes the full input shape to either the layer or the cell. Hence, since all RNNs inherit `RNN` - either (1) `RNN` must be re-implemented, or (2) `timesteps` must be passed to the layer as an argument. Both add much redundancy.\r\n\r\n`call()` could also be `timesteps`-dependent, and _is_ for recurrent batchnorm; at inference time, generalizing to `timesteps` longer than trained uses the last train step's moving average.\r\n\r\nCan you suggest an 'API-friendly' means of injecting `timesteps` information into a cell at build time? If so, I'll consider this resolved - but whatever I thought of so far is overly hackish.", "I would suggest you to sub class RNN layer for your normalization case.\r\n\r\n1. Even we pass the full input_shape from RNN layer to cell.build(), it is also very likely that the timestep dimention is None. It is very common for user to build a model with dynamic timestep size. I don't think you can build weights with None as any part of the shape.\r\n\r\n2. In the case of normalization, eg, you will have mean and variance for the batch of the data in your RNN layer, why those value has to aware of the length of timestep? especially at each individual step? I would expect the mean and variance are calculate against the feature dim (which is the last axis, rather than the timestep axis).\r\n\r\n3. For IndRNNs, I check the existing implementation in TF contrib. The IndRNNCell also build with (batch, feature) as input shape,  and doesn't need timestep. The code was in contrib, which is not visible on HEAD, but you can get it from TF 1.15 release. Here is some snippet from the it:\r\n\r\n```\r\nclass IndRNNCell(rnn_cell_impl.LayerRNNCell):\r\n  \"\"\"Independently Recurrent Neural Network (IndRNN) cell\r\n    (cf. https://arxiv.org/abs/1803.04831).\r\n\r\n  Args:\r\n    num_units: int, The number of units in the RNN cell.\r\n    activation: Nonlinearity to use.  Default: `tanh`.\r\n    reuse: (optional) Python boolean describing whether to reuse variables\r\n     in an existing scope.  If not `True`, and the existing scope already has\r\n     the given variables, an error is raised.\r\n    name: String, the name of the layer. Layers with the same name will\r\n      share weights, but to avoid mistakes we require reuse=True in such\r\n      cases.\r\n    dtype: Default dtype of the layer (default of `None` means use the type\r\n      of the first input). Required when `build` is called before `call`.\r\n  \"\"\"\r\n\r\n  def __init__(self,\r\n               num_units,\r\n               activation=None,\r\n               reuse=None,\r\n               name=None,\r\n               dtype=None):\r\n    super(IndRNNCell, self).__init__(_reuse=reuse, name=name, dtype=dtype)\r\n\r\n    # Inputs must be 2-dimensional.\r\n    self.input_spec = input_spec.InputSpec(ndim=2)\r\n\r\n    self._num_units = num_units\r\n    self._activation = activation or math_ops.tanh\r\n\r\n  @property\r\n  def state_size(self):\r\n    return self._num_units\r\n\r\n  @property\r\n  def output_size(self):\r\n    return self._num_units\r\n\r\n  def build(self, inputs_shape):\r\n    if tensor_shape.dimension_value(inputs_shape[1]) is None:\r\n      raise ValueError(\r\n          \"Expected inputs.shape[-1] to be known, saw shape: %s\" % inputs_shape)\r\n\r\n    input_depth = tensor_shape.dimension_value(inputs_shape[1])\r\n    # pylint: disable=protected-access\r\n    self._kernel_w = self.add_variable(\r\n        \"%s_w\" % rnn_cell_impl._WEIGHTS_VARIABLE_NAME,\r\n        shape=[input_depth, self._num_units])\r\n    self._kernel_u = self.add_variable(\r\n        \"%s_u\" % rnn_cell_impl._WEIGHTS_VARIABLE_NAME,\r\n        shape=[1, self._num_units],\r\n        initializer=init_ops.random_uniform_initializer(\r\n            minval=-1, maxval=1, dtype=self.dtype))\r\n    self._bias = self.add_variable(\r\n        rnn_cell_impl._BIAS_VARIABLE_NAME,\r\n        shape=[self._num_units],\r\n        initializer=init_ops.zeros_initializer(dtype=self.dtype))\r\n    # pylint: enable=protected-access\r\n\r\n    self.built = True\r\n\r\n  def call(self, inputs, state):\r\n    \"\"\"IndRNN: output = new_state = act(W * input + u * state + B).\"\"\"\r\n\r\n    gate_inputs = math_ops.matmul(inputs, self._kernel_w) + (\r\n        state * self._kernel_u)\r\n    gate_inputs = nn_ops.bias_add(gate_inputs, self._bias)\r\n    output = self._activation(gate_inputs)\r\n    return output, output\r\n```", "@qlzh727 Thanks for the suggestions.\r\n\r\n 1. It is even more likely for `batch_size` to be `None`, yet we require it for `stateful=True`; personally I've yet to see a `None` for `timesteps`, but just as for `stateful`, we can require `timesteps` to be defined for recurrent batchnorm.\r\n 2. I'll clarify; the bottom of page 3 of the [paper](https://arxiv.org/abs/1603.09025) reads: \r\n\r\n> ... we estimate the population statistics separately for each timestep `1, ..., Tmax`, where `Tmax` is the length of the longest training sequence. When at test time we need to generalize beyond `Tmax`, we use the population statistics of time `Tmax` for all time steps beyond it.\r\n\r\nThus, the population statistics variables will be shaped `(Tmax, units)` - requiring the knowledge of `Tmax` _at build time_.\r\n\r\n 3. The implementation is flawed; authors note the need for careful weight clipping for a certain range of timesteps to avoid exploding/vanishing gradients - and is shown in the [official implementation](https://github.com/Sunnydreamrain/IndRNN_Theano_Lasagne/blob/master/adding/adding.py#L51) (alias `seq_len`). That implementation uses a safe default for several cases, but not all (and `_kernel_w` also lacks an initializer).", "If the intention for this PR is trying to address your BN RNN issue, then I would suggest take the subclass RNN layer approach, but this will require some work.\r\n\r\n1. In your BN RNN layer, each step has to aware that what the current step number is, and find the corresponding BN variable to use. The current RNN API doesn't pass any step number information to the cell, so finding the corresponding BN variable will be tricky. The implementation in your https://github.com/tensorflow/tensorflow/issues/36559 might not be correct since the step function is called once first to calculate the output shape when creating the output TensorArray. The result of that is ignored. \r\n\r\n2. The step information is available in the loop function in the keras backend.rnn() while iterating through the time sequence, we don't pass that info to the cell since the cell doesn't need to aware of it. In you case, you probably want to create a BN variable in your RNN layer. At the time when calling the cell, you need to reconstruct you input into a nested structure, with the BN variable. The backend.rnn should handle the nested input correctly by sliding on the BN with timestep dim, same as the input. You cell should get real input and the slide of BN variable in the call() as the first parameter, and you might want to return the value for the BN variable in the result as well.\r\n\r\n3. At the end of BN RNN layer call() body, you probably want to gather the result of BN and add update to the original variable. Your cell probably shouldn't worry about updating the BN since they are just using the value. \r\n\r\nWith that I think your cell don't need to worry about the timestep information since it really shouldn't, and the layer will handle it.", "@qlzh727 I suppose I haven't sufficiently considered a `_v2`-like approach, utilizing `K.rnn` directly via the layer's `call()`; since it recieves the complete input, I should be able to build variables at call time, with `if not self.bn_built`-like logic. I've just been trying to stick to `tf.keras` layer structuring, as I presume it's more stable and optimized - but this does seem fitting. You are also correct regarding `step` - I've re-implemented it since and confirmed it works via `tf.print`.\r\n\r\nThe intent wasn't just to get RBN working, but that the current policy adds redundancy that's easy to change. Regardless, I've suspended my works on RBN per performance and correctness [concerns](https://github.com/tensorflow/tensorflow/issues/36797); perhaps my mistake is trying to use the exact loop function that `tf.keras` uses, where something else might be more appropriate. I may look into it again in some future, only if TF Profiler's fixed in 2.1+.\r\n\r\nIn any case, though I've yet to try it, your approach seems promising, and I don't have much else to add on the issue for now - so I'll close the PR. Also, thanks for following through, here and on other threads - you are the most responsive TF developer I've seen."]}, {"number": 36842, "title": "Tensorlfow with Pycharm", "body": "\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- TensorFlow installed from (source or binary): Source\r\n- TensorFlow version: Latest to today\r\n- Python version:3.7\r\n- Installed using virtualenv? pip? conda?:Conda\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: idk\r\n- GPU model and memory: 16gb intel core i5\r\n\r\n\r\nConda create -n tensor python=3.7\r\ny\r\nactivate tensor\r\npip install tensorflow\r\npip install keras\r\n\r\nlogs\r\nC:\\Users\\HP\\Anaconda3\\envs\\tensor\\pythonw.exe C:/Users/HP/PycharmProjects/TensorENV/Test.py\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\HP\\Anaconda3\\envs\\tensor\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\HP\\Anaconda3\\envs\\tensor\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\HP\\Anaconda3\\envs\\tensor\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\HP\\Anaconda3\\envs\\tensor\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\HP\\Anaconda3\\envs\\tensor\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:/Users/HP/PycharmProjects/TensorENV/Test.py\", line 1, in <module>\r\n    import tensorflow\r\n  File \"C:\\Users\\HP\\Anaconda3\\envs\\tensor\\lib\\site-packages\\tensorflow\\__init__.py\", line 101, in <module>\r\n    from tensorflow_core import *\r\n  File \"C:\\Users\\HP\\Anaconda3\\envs\\tensor\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 40, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"C:\\Users\\HP\\Anaconda3\\envs\\tensor\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\HP\\Anaconda3\\envs\\tensor\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\HP\\Anaconda3\\envs\\tensor\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"C:\\Users\\HP\\Anaconda3\\envs\\tensor\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\HP\\Anaconda3\\envs\\tensor\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\HP\\Anaconda3\\envs\\tensor\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\HP\\Anaconda3\\envs\\tensor\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\HP\\Anaconda3\\envs\\tensor\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\HP\\Anaconda3\\envs\\tensor\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\HP\\Anaconda3\\envs\\tensor\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n", "comments": ["@HelpMePlz1234,\r\nTensorFlow release binaries version 1.6 and higher are prebuilt with AVX instruction sets.\r\nTherefore on any CPU that does not have these instruction sets, either CPU or GPU version of TF will fail to load. Please check does your CPU supports AVX instruction sets or not. Thanks!\r\n", "It is an i5-6300u. Also it is a Q3 so I think it supports it.", "@HelpMePlz1234, Did you install the Microsoft Visual C++ Redistributable for Visual Studio 2015, 2017, and 2019. Starting with the TensorFlow 2.1.0 version, the msvcp140_1.dll file is required from this package (which may not be provided from older redistributable packages). The redistributable comes with Visual Studio 2019 but can be installed separately from https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads. Thanks!", "Thank you I will do this now and see what happens\r\n", "It works now but I got two new errors\r\n\r\n2020-02-19 21:54:58.529308: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found\r\n2020-02-19 21:54:58.529658: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\r\n\r\n", "@HelpMePlz1234,Are you installing GPU support tensorflow with CUDA and cuDNN? as \r\n`pip install tensorflow-gpu==2.1`\r\nThanks!", "no just cup", "CPU", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36842\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36842\">No</a>\n"]}, {"number": 36841, "title": "DockerHub tag 2.1.0-py3 includes GPU support", "body": "**System information**\r\n\r\nDockerHub: [tensorflow/tensorflow:2.1.0-py3](https://hub.docker.com/layers/tensorflow/tensorflow/2.1.0-py3/images/sha256-14ec674cefd622aa9d45f07485500da254acaf8adfef80bd0f279db03c735689?context=explore)\r\n\r\n**Describe the problem**\r\n\r\nThis Docker image seems to have the pip `tensorflow` package installed, rather than the `tensorflow-cpu` package. As of version 2.1.0, the `tensorflow` package includes GPU support (see the first bullet point in the [changelog](https://github.com/tensorflow/tensorflow/releases/tag/v2.1.0)).\r\n\r\nSince [tensorflow/tensorflow:2.1.0-gpu-py3](https://hub.docker.com/layers/tensorflow/tensorflow/2.1.0-gpu-py3/images/sha256-1010e051dde4a9b62532a80f4a9a619013eafc78491542d5ef5da796cc2697ae?context=explore) is also provided, it seems to me like [tensorflow/tensorflow:2.1.0-py3](https://hub.docker.com/layers/tensorflow/tensorflow/2.1.0-py3/images/sha256-14ec674cefd622aa9d45f07485500da254acaf8adfef80bd0f279db03c735689?context=explore) should not include GPU support. If you believe that it should, would it be possible to publish e.g. tensorflow/tensorflow:2.1.0-cpu-py3 to DockerHub?\r\n\r\n**Additional context**\r\n\r\nThe reason I noticed this is because I started seeing these warnings when running on CPU: \r\n\r\n```\r\nW tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory\r\nW tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory\r\nW tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\r\n```\r\n\r\nIn addition to removing these warnings, having a cpu-only version would reduce the image size.", "comments": ["@angerson @ravikyram I was just wondering if you had any updates regarding this, or an estimate for when it might be addressed", "Thanks for the report. I can see why this is confusing, although (unless I'm mistaken) there are no actual errors, just warnings. It would be nice to use `tensorflow-cpu` instead, since it would improve the image size slightly, but I'm afraid I don't have the time to work on the cleanup right now because it's not a breakage.\r\n\r\nYou're welcome to update our Dockerfiles, however, and I'd be happy to review a PR to adjust which package gets installed. See [here](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/dockerfiles) for instructions (and https://github.com/tensorflow/tensorflow/pull/36971 for a notable upcoming PR).", "@angerson thanks for your response.\r\n\r\nSince it it seems to me like it would make sense to not include the GPU dependencies (since there is a `-gpu` set of images and also since that was the behavior prior to v2.1), do you think it would make sense to update [this line](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/dockerfiles/dockerfiles/cpu.Dockerfile#L55) to `ARG TF_PACKAGE=tensorflow-cpu`? My concern is that if this arg is not overwritten, and `TF_PACKAGE_VERSION` < 2.1, then the `pip install` will fail ([pypi](https://pypi.org/project/tensorflow-cpu/#history) only seems to have v1.15 and v2.1).\r\n\r\nAlternatively, is it possible to update the script that generates the Dockerfiles to pass in `TF_PACKAGE=tensorflow-cpu` for versions >= 2.1?", "@deliahu Could you please let us know if you still need help on this ? We recommend that you upgrade to 2.6 which is latest stable version of TF and let us know if the issue still persists in newer versions. If it is resolved then please feel free to move this issue to close status ? Thanks!", "I no longer use this image, but after taking a quick look at the command and size of layer 10 in [tensorflow/tensorflow:2.6.0](https://hub.docker.com/layers/tensorflow/tensorflow/2.6.0/images/sha256-773d5ce09e4ce003db02740c6a372a8a9f43be2bac23544d8f452bfec5347c53?context=explore), yes, I do believe this has been resolved :+1:", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36841\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36841\">No</a>\n"]}, {"number": 36840, "title": "Connecting to invalid output X of source node Y which has Z outputs [TF2.1-nightly]", "body": "Occurs in Graph execution (not Eager) with a `return_sequences=True` followed by `return_sequences=False` (but not either on its own) custom RNN layer; the layer involves `nn.moments` and `nn.batch_normalization` ops in `call`, as described [here](https://github.com/tensorflow/tensorflow/issues/36797). The error occurs upon:\r\n\r\n - `model.train_on_batch()` -- `.fit()` -- `.save_weights()` -- `.save()`\r\n\r\nI tried `tf.compat.v1.experimental.output_all_intermediates(True)` and `False`, didn't help. Doesn't occur with built-in `LSTM` layer. \r\n\r\nAny resolution?\r\n\r\n<hr>\r\n\r\n**Error trace**:\r\n\r\n```python\r\nFile \"C:\\DL_code\\dev_bn_indrnn\\main2.py\", line 29, in <module>\r\n  model.train_on_batch(x, y)\r\nFile \"D:\\Anaconda\\envs\\tf2n_env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 1083, in train_on_batch\r\n  outputs = self.train_function(ins)  # pylint: disable=not-callable\r\nFile \"D:\\Anaconda\\envs\\tf2n_env\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\", line 3597, in __call__\r\n  session = get_session(inputs)\r\nFile \"D:\\Anaconda\\envs\\tf2n_env\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\", line 528, in get_session\r\n  _initialize_variables(session)\r\nFile \"D:\\Anaconda\\envs\\tf2n_env\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\", line 943, in _initialize_variables\r\n  [variables_module.is_variable_initialized(v) for v in candidate_vars])\r\nFile \"D:\\Anaconda\\envs\\tf2n_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 958, in run\r\n  run_metadata_ptr)\r\nFile \"D:\\Anaconda\\envs\\tf2n_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1181, in _run\r\n  feed_dict_tensor, options, run_metadata)\r\nFile \"D:\\Anaconda\\envs\\tf2n_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1359, in _do_run\r\n  run_metadata)\r\nFile \"D:\\Anaconda\\envs\\tf2n_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1384, in _do_call\r\n  raise type(e)(node_def, op, message)\r\n\r\nInvalidArgumentError: Node 'training/Nadam/gradients/gradients/ind_rnn/while_grad/ind_rnn/while_grad': \r\nConnecting to invalid output 46 of source node ind_rnn/while which has 46 outputs. \r\nTry using tf.compat.v1.experimental.output_all_intermediates(True).\r\n```\r\n\r\n<hr>\r\n\r\n**Update**: while there aren't errors in Eager, the gradients are extremely small: `1e-9` to `1e-19`, whereas usually the same layers have `1e-6` to `1e-2`. This may or may not be a design rather than a bug problem.", "comments": ["@OverLordGoldDragon \r\n\r\nCan you please provide simple standalone code to reproduce the issue in our environment. It helps us in localizing the issue faster. Thanks!\r\n", "I'm no longer working on this, so no example coming anytime soon - will reopen if relevant again.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36840\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36840\">No</a>\n", "May be it will help someone...\r\nIn my case the same issue was caused by the fact that I was setting learning rate BEFORE 1st call of fit(). It is somehow related to not initialized variables...\r\n`\r\n# TF: 2.2.0\r\nimport tensorflow.keras.backend as K\r\nK.set_value( model.optimizer.lr, 0.01 )\r\nmodel.fit(...)\r\n`\r\nSetting learning rate after fit() or in callback works just fine."]}, {"number": 36839, "title": "Add step argument to SummaryWriter.(set_)as_default.", "body": "As a followup to #26406, here is a simple proposed solution which adds `step` argument to `SummaryWriter.as_default` and `SummaryWriter.set_as_default`. The default value is `None` which means the argument is ignored, so the change is backward compatible.\r\n\r\nThe current code is extremely simple, yet useful. Given lack of response in #26406, I submitted this PR, but I am happy to update it (or scrap it) if a different consensus is reached. For reasons to this change, see #26406.\r\n\r\nBTW, the `get_step` and `set_step` methods could be used inside the implementation instead of manual manipulation with `_summary_state`.", "comments": ["@foxik it is struck with internal error , can you please fix this? Thanks!\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"<embedded stdlib>/unittest/case.py\", line 59, in testPartExecutor\r\n    yield\r\n  File \"<embedded stdlib>/unittest/case.py\", line 605, in run\r\n    testMethod()\r\n  File \"/third_party/tensorflow/tools/api/tests/api_compatibility_test.py\", line 410, in testAPIBackwardsCompatibility\r\n    omit_golden_symbols_map=omit_golden_symbols_map)\r\n  File \"/third_party/tensorflow/tools/api/tests/api_compatibility_test.py\", line 387, in _checkBackwardsCompatibility\r\n    api_version=api_version)\r\n  File \"/third_party/tensorflow/tools/api/tests/api_compatibility_test.py\", line 307, in _AssertProtoDictEquals\r\n    self.fail('%d differences found between API and golden.' % diff_count)\r\n  File \"/third_party/py/absl/testing/absltest.py\", line 1767, in fail\r\n    return super(TestCase, self).fail(self._formatMessage(prefix, msg))\r\n  File \"<embedded stdlib>/unittest/case.py\", line 670, in fail\r\n    raise self.failureException(msg)\r\nAssertionError: 1 differences found between API and golden.\r\n\r\nTraceback (most recent call last):\r\n  File \"<embedded stdlib>/unittest/case.py\", line 59, in testPartExecutor\r\n    yield\r\n  File \"<embedded stdlib>/unittest/case.py\", line 605, in run\r\n    testMethod()\r\n  File \"/third_party/tensorflow/tools/api/tests/api_compatibility_test.py\", line 443, in testAPIBackwardsCompatibilityV2\r\n    omit_golden_symbols_map=omit_golden_symbols_map)\r\n  File \"/third_party/tensorflow/tools/api/tests/api_compatibility_test.py\", line 387, in _checkBackwardsCompatibility\r\n    api_version=api_version)\r\n  File \"/third_party/tensorflow/tools/api/tests/api_compatibility_test.py\", line 307, in _AssertProtoDictEquals\r\n    self.fail('%d differences found between API and golden.' % diff_count)\r\n  File \"/third_party/py/absl/testing/absltest.py\", line 1767, in fail\r\n    return super(TestCase, self).fail(self._formatMessage(prefix, msg))\r\n  File \"<embedded stdlib>/unittest/case.py\", line 670, in fail\r\n    raise self.failureException(msg)\r\nAssertionError: 1 differences found between API and golden.\r\n```\r\n\r\n\r\n", "@gbaned I updated the API files and the test now passes. I modified the original commit, which invalidated the review -- should I in the future not modify commits that have been already reviewed and create new ones instead?", "@jsimsa  Any update on this PR? Please. Thanks!", "@gbaned please work with @nfelt and @foxik on adding tests for the new functionality.", "@jsimsa @gbaned I was waiting for @nfelt guidance, but I will instead implement the tests by myself.\r\n\r\nI just found https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/kernel_tests/summary_ops_test.py, which performs SummaryWriter tests with all the functionality needed (i.e., loging a summary using a SummaryWriter and then reading back the `step` number). Should send something in a day or two.", "@jsimsa @gbaned I added tests that check both the `as_default` and `set_as_default` methods, checking both constants and variables as `step` values. Furthermore, for the `as_default` I check that the step value is restored if and only if a non-None `step` was passed.", "I am sorry, but two lines in the tests were 81 characters long :-( I commited a fix.", "@gbaned Just a gentle reminder, the pull request seems ready (the requested changes on my part are implemented). Cheers!", "> @gbaned Just a gentle reminder, the pull request seems ready (the requested changes on my part are implemented). Cheers!\r\n\r\n@foxik  Sorry for the delay. It is on internal processing.  ", "For curiosity, any chance this can get in before the TF 2.3 branch cut? Or maybe it is held back to allow more time to discuss public API changes?", "Sorry I have been out of the loop on this PR, I haven't had bandwidth to work on the summary API in a while.  Thanks for your contribution in suggesting this change.\r\n\r\nI'm not sure what the current thoughts of the TF API approvers are, but I'm a little reluctant to introduce the `step` argument as a permanent non-experimental part of the `as_default()`/`set_as_default()` API since we hadn't fully resolved some questions about how to handle step tracking in the long run, and I'm not sure that part of the API is the best place for it to live long-term [*].  I would be open to introducing it as something like `experimental_step` if that gives us flexibility to deprecate it before TF 3.0 if we do find an alternate approach, but I'm not sure if TF typically does experimental parameters like that?\r\n\r\n[*]: Just to elaborate slightly, it's possible that we want to integrate step tracking a little tighter into the summary writers so that e.g. each writer maintains an internal step count, in which case it makes more sense to have something like a `writer.advance_step()` API rather than allowing `as_default()` to temporarily reassign the step.", "@nfelt Thanks for your comment! Having per-writer summary step would be great.\r\n\r\nI understand that you want to keep open possibility for API changes/redesign. However, I do not think having a `step` argument of `as_default()/set_as_default()` would prevent that:\r\n- `step` argument is already part of the individual `tf.summary` calls\r\n- even if `step` is per-writer, it will surely be changeable\r\n\r\nSo the current pull request does not seem to introduce additional invariants or concepts to the API.\r\n\r\nBut maybe it would make sense to change the comments to something like\r\n> The `as_default()/set_as_default()` is guaranteed to change the `step` argument only for the calls regarding the summary writer in question. Currently, it changes the global `step`, but it could change in the future."]}]