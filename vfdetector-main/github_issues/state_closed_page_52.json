[{"number": 53785, "title": "Providing different results of FLOPS calculation when using tf.compat.v1.profiler.profile on Mac M1 chip and on NVIDIA 1650 ", "body": "<em>Please make sure that this is an issue related to performance of TensorFlow.\r\nAs per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:performance_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nWhen use the following function for FLOPS calculation on mac M1 \r\n`def get_flops(model: Union[Model, Sequential], batch_size: Optional[int] = None) -> int:\r\n    \"\"\"\r\n    Calculate FLOPS for tf.keras.Model or tf.keras.Sequential .\r\n    Ignore operations used in only training mode such as Initialization.\r\n    Use tf.profiler of tensorflow v1 api.\r\n    \"\"\"\r\n    if not isinstance(model, (Sequential, Model)):\r\n        raise KeyError(\r\n            \"model arguments must be tf.keras.Model or tf.keras.Sequential instanse\"\r\n        )\r\n\r\n    if batch_size is None:\r\n        batch_size = 1\r\n        \r\n    inputs = [tf.TensorSpec([batch_size] + inp.shape[1:], inp.dtype) for inp in model.inputs]\r\n    \r\n    # print(\"@@@@@@@@@@@@@\",inputs)\r\n    real_model = tf.function(model).get_concrete_function(inputs)\r\n    # frozen_func, _ = convert_variables_to_constants_v2_as_graph(real_model)\r\n\r\n    # Calculate FLOPS with tf.profiler\r\n    run_meta = tf.compat.v1.RunMetadata()\r\n    opts = tf.compat.v1.profiler.ProfileOptionBuilder.float_operation()\r\n    flops = tf.compat.v1.profiler.profile(\r\n        graph=real_model.graph, run_meta=run_meta, cmd=\"scope\", options=opts\r\n    )\r\n    \r\n    return flops.total_float_ops`\r\n\r\ngive wrong FLOPS as output: **2632160**\r\n\r\n**Describe the expected behavior**\r\n\r\nWhile the same code gives the correct calculation when tried on NVIDIA enabled machine. **VGGNET-16 FLOPS: 4587547104**\r\nExpecting the same result to be calculated when done on Mac M1 machine.\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["Hi @shujaat81 ! Could you please attach the above code as a Colab gist? Thank you!", "Hi @mohantym Please find the link for colab\r\n[https://colab.research.google.com/drive/1Hw3HuAa2vOEM6VxwnorV5pdToqx3mlJB?usp=sharing](url)", "@shujaat81 ! Could you please confirm your Tensorflow version too?  I got different results in [Colab ](https://colab.sandbox.google.com/gist/mohantym/0c0f600648c497a7dec8ea499aa48fd9/untitled0.ipynb#scrollTo=Y_xs6aFoaYDn)environment.", "@mohantym Iam using \"2.4.0-rc0\" version", "Hi @Saduf2019 ! Could you please look at this issue? Attaching [gist](https://colab.sandbox.google.com/gist/mohantym/0c0f600648c497a7dec8ea499aa48fd9/untitled0.ipynb#scrollTo=XzJQ-fothZQk) for reference.", "Could you please try this in Tensorflow 2.7 as mentioned in the above gist and let us know what is the expected flops and the outcome flops you are getting. Thanks", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 53783, "title": "`tf.scatter_nd` document refers to deprecated apis", "body": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/versions/r2.7/api_docs/python/tf/scatter_nd\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n Here is a paragraph describing the relationship between `tf.scatter_nd` and `tf.tensor_scatter_add`:\r\n\r\n> This operation is similar to tf.tensor_scatter_add, except that the tensor is zero-initialized. Calling tf.scatter_nd(indices, values, shape) is identical to calling tf.tensor_scatter_add(tf.zeros(shape, values.dtype), indices, values).\r\n\r\nHowever,  `tf.tensor_scatter_add` does not exist in TensorFlow 2.7, `tf.tensor_scatter_add` should be replaced with [`tf.tensor_scatter_nd_add`](https://www.tensorflow.org/api_docs/python/tf/tensor_scatter_nd_add). \r\n", "comments": ["I can fix this", "@ArrowIntoTheSky , @Cheril311 ,\r\nPlease feel free to submit a PR for the requested change or share the link where requested change is to be made.", "@tilakrayal cannot find the source file for the mentioned issue, can you help me a bit?", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\r\n[Yes](https://goo.gl/forms/Oe0tEvODFRoI2gJF3)\r\n[No](https://goo.gl/forms/fUjzOfrtkFbrOT8d2)", "@ArrowIntoTheSky Thanks for raising this issue. This was merged internally and will show up soon on the TF website. Thanks again."]}, {"number": 53782, "title": "Fix casting in vdotq_four_lane_s32() in TFLite", "body": "When building with GCC and dotprod ARM extension enabled,\r\nvreinterpret_s32_s8() casts int8x8_t to int32x2_t. However, third\r\nargument of vdotq_lane_s32() expects parameter of type int8x8_t.", "comments": []}, {"number": 53780, "title": "Fix the GraphFloat32::outputs() problem in TFLite", "body": "Hi TFers,\r\nI just found the problem that I was getting wrong data output from my model having multi-headers. For example, if the graph my model is like `0 -> 1 -> 2 -> 3` and the model inputs is `[0]` outputs is `[2, 3]`, I will only get correct answer from 3 but 2 is not, because our `GraphFloat32::outputs()` only believe the value with no consumer, the `3` above, is an output value. However, our tflite::Interpreter still tell us the outputs is `[2, 3]` and it's right. So, I try to fix with this PR, please take a check.", "comments": ["Hi all, anything new here?", "Sorry, I didn't realize I was assigned this.\r\n\r\nYour fix may work (sorry, didn't check too closely) when the full graph is run on the GPU, but may not work when only a subgraph is delegated.  We are aware of this issue but it doesn't have an easy fix the way GraphFloat32 works with the rest of the system.  We have broken Google multiple times with various fixes (and I'm dealing with one right now).\r\n\r\nNow having said that, I suggest that you insert a dummy x = ADD(x, 1e-6) at the second node and consume the output of that.", "Well, thanks for your reply.\r\n\r\nSounds bad that I have to accept workaround inserting the ADD op now. By the way, would you mind share test cases about the subgraph problems you just mentioned? Maybe I have other idea to try. Otherwise, from your descriptions, I'm just think about the cases that nodes which the part of subgraph in GPU need shortcut to later nodes in other devices. Do they also output the wrong answers? ", "@impjdi  Can you please assist on above comments from @SunAriesCN. Thank you!", "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/delegates/gpu/delegate.cc#L98 \r\nFixed!"]}, {"number": 53779, "title": "keras.layers.SimpleRNN/LSTM output NaN when setting \"activation\" to \"exponential\"", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.7.0\r\n- Python version: 3.7.12\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**Describe the current behavior**\r\n`keras.layers.SimpleRNN` and `keras.layers.LSTM` output `NaN` when setting the `activation` parameter to `exponential` if the shape of input is larger than 3.\r\n\r\n**Describe the expected behavior**\r\n`keras.layers.SimpleRNN` and `keras.layer.LSTM` should not output `NaN` under this setting.\r\n\r\n- Do you want to contribute a PR? (yes/no): no\r\n- Briefly describe your candidate solution(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nfrom tensorflow import keras\r\nx = keras.layers.Input((6,3))\r\nbuggy_layer = keras.layers.SimpleRNN(50, activation=\"exponential\")\r\ny = buggy_layer(x)\r\nmodel = keras.Model(x, y)\r\nimport numpy as np\r\ninput = np.random.rand(10,6,3)\r\nres = model.predict(input)\r\nmodel_path = \"simple_rnn_exponential.h5\"\r\nmodel.save(model_path)\r\nprint(res)\r\n```\r\nYou may also access the code here:\r\nhttps://colab.research.google.com/drive/1mVBIPF79kiIYggZUUkvs1IEB1GdxeoJC?usp=sharing\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\nTo help you identify this issue, I have tried several ways to construct the buggy layer.\r\n\r\nTrial 1:\r\nUse `linear` as the activation while adding an additional exponential activation after the SimpleRNN. In this way, the `res` will not output `NaN`\r\n```\r\nfrom tensorflow import keras\r\nx = keras.layers.Input((6,3))\r\nbuggy_layer = keras.layers.SimpleRNN(50, activation=\"linear\")\r\ny = buggy_layer(x)\r\nz = keras.activations.exponential(y)\r\nmodel = keras.Model(x, z)\r\nimport numpy as np\r\ninput = np.random.rand(10,6,3)\r\nres = model.predict(input)\r\nprint(res)\r\n```\r\n\r\nTrial 2:\r\nI tried converting the generated model which will output `NaN` to PyTorch using ONNX, I find that: after converting to PyTorch, the output will contain `Inf` and `0` but no `NaN`. Please see this link for more details about this trial:\r\nhttps://colab.research.google.com/drive/1mVBIPF79kiIYggZUUkvs1IEB1GdxeoJC?usp=sharing\r\n", "comments": ["@mazeltovlee \r\nPlease post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues)\r\nTo know more see;\r\n[https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999](https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999)\r\nThank you!", "Thanks for your response, I will pass this issue to keras", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53779\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53779\">No</a>\n"]}, {"number": 53778, "title": "The speed of training is reduced using a custom method in tensorflow.keras.layers", "body": "I'm using `tensorflow.data` and `custom layers` to solve the bottleneck of data augmentation, but I found that using `tensorflow.data` alone is faster than mixing, I don't know what's going on in the `custom layers`, can someone please tell me?\r\n\r\nThanks in advance!\r\n\r\nThis is my data augmentation code, mainly to do standardization and resize.\r\n```\r\ndef random_normalization(data, mean, std):\r\n    mean = tf.multiply(mean, tf.random.uniform(shape=(), minval=0.5,maxval=0.9, dtype=tf.float64))\r\n    std = tf.multiply(std, tf.random.uniform(shape=(), minval=0.5,maxval=0.9, dtype=tf.float64))\r\n    return tf.divide((tf.subtract(data, mean)), std)\r\n\r\ndef random_resize(data):\r\n    def resizing(index, data, choice, enable, new_data, number, overlap):        \r\n        FrontEnd = tf.cond(tf.math.greater_equal(tf.subtract(index, overlap), tf.constant(0)),\r\n                           lambda: tf.subtract(index, overlap),\r\n                           lambda: index)\r\n        \r\n        BackEnd = tf.cond(tf.math.less(tf.add(tf.add(index, 10),overlap),tf.constant(2000)),\r\n                          lambda: tf.add(tf.add(index, 10),overlap),\r\n                          lambda: index)\r\n        \r\n        z1 = tf.gather(data, indices=[0], axis=1)\r\n        z1 = tf.gather(z1, indices=tf.range(FrontEnd, BackEnd), axis=0)\r\n        \r\n        z2 = tf.gather(data, indices=[1], axis=1)\r\n        z2 = tf.gather(z2, indices=tf.range(FrontEnd, BackEnd), axis=0)\r\n        \r\n        z3 = tf.gather(data, indices=[2], axis=1)\r\n        z3 = tf.gather(z3, indices=tf.range(FrontEnd, BackEnd), axis=0)\r\n        \r\n        z4 = tf.gather(data, indices=[3], axis=1)\r\n        z4 = tf.gather(z4, indices=tf.range(FrontEnd, BackEnd), axis=0)\r\n        \r\n        z5 = tf.gather(data, indices=[4], axis=1)\r\n        z5 = tf.gather(z5, indices=tf.range(FrontEnd, BackEnd), axis=0)\r\n        \r\n        z6 = tf.gather(data, indices=[5], axis=1)\r\n        z6 = tf.gather(z6, indices=tf.range(FrontEnd, BackEnd), axis=0)\r\n        \r\n        \r\n        new_data = tf.tensor_scatter_nd_update(new_data, [[number, 0], [number, 1], [number, 2],\r\n                                                          [number, 3], [number, 4], [number, 5]], \r\n                                               [tf.math.reduce_mean(z1), tf.math.reduce_mean(z2),\r\n                                                tf.math.reduce_mean(z3), tf.math.reduce_mean(z4),\r\n                                                tf.math.reduce_mean(z5), tf.math.reduce_mean(z6)])\r\n        \r\n        \r\n        return tf.add(index, 10), data, choice, enable, new_data, tf.add(number, 1), overlap\r\n    \r\n    choice = tf.random.uniform(shape=(), minval=0,maxval=4,dtype=tf.int32)\r\n    enable = tf.random.uniform(shape=(), minval=0,maxval=1,dtype=tf.float64)\r\n    overlap = tf.random.uniform(shape=(), minval=5,maxval=21,dtype=tf.int32)\r\n    \r\n    new_data = tf.zeros((200,6), dtype=tf.float64)\r\n    index = tf.constant(0)\r\n    number = tf.constant(0)\r\n    condition = lambda index, data, choice, enable, new_data, number, overlap: tf.less(index, 2000)\r\n    r = tf.while_loop(condition, resizing, loop_vars=(index, data, choice, enable, new_data, number, overlap))\r\n    return r[4]\r\n\r\ndef normal_resize(data):\r\n    data = tf.reshape(data, (2000,6,1))\r\n    data = tf.image.resize(data, size=[200,6])\r\n    return tf.cast(tf.reshape(data, (200,6)),dtype=tf.float64)\r\n\r\ndef augmentation(data, labels):\r\n    mean = tf.math.reduce_mean(data,axis=0)\r\n    std = tf.math.reduce_std(data,axis=0)\r\n    data = tf.cond(tf.random.uniform(shape=(), minval=0, maxval=1,dtype=tf.float64) < tf.constant(0.8,dtype=tf.float64), \r\n                   lambda: random_normalization(data, mean, std), \r\n                   lambda: tf.divide((tf.subtract(data, mean)), std))\r\n    \r\n    # 2000 resize to 200\r\n    data = tf.cond(tf.random.uniform(shape=(), minval=0, maxval=1,dtype=tf.float64) < tf.constant(0.8,dtype=tf.float64), \r\n                   lambda: random_resize(data), \r\n                   lambda: normal_resize(data))\r\n\r\n    return data, labels\r\n```\r\n\r\nMain code, including `tf.data` and model\r\n```\r\nif __name__ == '__main__':\r\n    trainDS = tf.data.Dataset.from_tensor_slices((np.random.rand(3000,2000,6),\r\n                                                  np.concatenate((np.zeros((1500)),np.ones((1500))))))\r\n    trainDS = (\r\n        trainDS\r\n        .cache()\r\n        .shuffle(1000, reshuffle_each_iteration=False)\r\n        .map(augmentation, num_parallel_calls=tf.data.AUTOTUNE)\r\n        .batch(128, drop_remainder=True)\r\n        .prefetch(tf.data.AUTOTUNE))\r\n    \r\n    input = Input((200,6))\r\n    x = LSTM(64, return_sequences=True)(input)\r\n    output = Dense(1,activation='sigmoid')(x)\r\n    model = Model(input, output)\r\n    model.compile(optimizer='adam', loss='BinaryCrossentropy')\r\n    model.fit(trainDS, epochs=3)\r\n```\r\nThen this is the code of my custom layer, although it is a bit cumbersome, it still achieves the result I want.\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.layers import LSTM, Dense, Input\r\nfrom tensorflow.keras.models import Model\r\nfrom tensorflow.keras.layers import Layer\r\nimport numpy as np\r\n\r\nclass CustomLayer(Layer):\r\n    def __init__(self, **kwargs):\r\n        super().__init__(**kwargs)\r\n    \r\n    def execute(self, data, batch_size, new_data, _type):\r\n        def _fun(index, data, _type, new_data):\r\n            resized = tf.cond(_type,\r\n                              lambda:augmentation(tf.reshape(tf.gather(data,[index]), (2000,6))),\r\n                              lambda:normal_resize(tf.reshape(tf.gather(data,[index]), (2000,6))))\r\n            values = tf.reshape(resized, (1,-1))[0]\r\n            _Indices = self.createIndices(index)\r\n            new_data = tf.tensor_scatter_nd_update(new_data, _Indices, values)\r\n            return tf.add(index,1), data, _type, new_data\r\n        \r\n        index = tf.constant(0)\r\n        condition = lambda index, data, _type, new_data: tf.less(index, batch_size)\r\n        r = tf.while_loop(condition, _fun, loop_vars=(index, data, _type, new_data))\r\n        return r[-1]\r\n    \r\n    def createIndices(self, BatchSizeIndex):\r\n        def loop1(_i, BatchSizeIndex, col_num, _Indices):\r\n            def loop2(_i, _j, BatchSizeIndex, col_num, _Indices):\r\n                _Indices = tf.tensor_scatter_nd_update(_Indices, [[col_num, 0], [col_num, 1], [col_num, 2]], \r\n                                                        [BatchSizeIndex, _i, _j])\r\n                return _i, tf.add(_j,1), BatchSizeIndex, tf.add(col_num,1), _Indices\r\n            \r\n            _j = tf.constant(0)\r\n            condition_loop2 = lambda _i, _j, BatchSizeIndex, col_num, _Indices: tf.less(_j, 6)\r\n            r_loop2 = tf.while_loop(condition_loop2, loop2, loop_vars=(_i, _j, BatchSizeIndex, col_num, _Indices))  \r\n            return tf.add(_i,1), BatchSizeIndex, r_loop2[3], r_loop2[4]\r\n\r\n        _Indices = tf.zeros((1200,3), dtype=tf.int32)\r\n        col_num = tf.constant(0)\r\n        _i = tf.constant(0)\r\n        condition_loop1 = lambda _i, BatchSizeIndex, col_num, _Indices: tf.less(_i, 200)\r\n        r_loop1 = tf.while_loop(condition_loop1, loop1, loop_vars=(_i, BatchSizeIndex, col_num, _Indices))\r\n        return r_loop1[-1]\r\n    \r\n    def call(self, images, training):\r\n        batch_size = tf.shape(images)[0]\r\n        new_data = tf.zeros((batch_size, 200, 6), dtype=tf.float64)\r\n        images = tf.cast(images, dtype=tf.float64)\r\n        if training:\r\n            data = self.execute(images, batch_size, new_data, tf.constant(True))\r\n        else:\r\n            data = self.execute(images, batch_size, new_data, tf.constant(False))\r\n        \r\n        return data\r\n```\r\n\r\nThe final code can be modified to execute like this.\r\n```\r\ndef augmentation(data):\r\n    .....\r\n    return data\r\n\r\nif __name__ == '__main__':\r\n    trainDS = tf.data.Dataset.from_tensor_slices((np.random.rand(3000,2000,6),\r\n                                                  np.concatenate((np.zeros((1500)),np.ones((1500))))))\r\n    trainDS = (\r\n        trainDS\r\n        .cache()\r\n        .shuffle(1000, reshuffle_each_iteration=False)\r\n        .batch(128, drop_remainder=True)\r\n        .prefetch(tf.data.AUTOTUNE))\r\n    \r\n    input = Input((2000,6))\r\n    x = CustomLayer()(input)\r\n    x = LSTM(64, return_sequences=True)(x)\r\n    output = Dense(1,activation='sigmoid')(x)\r\n    model = Model(input, output)\r\n    model.compile(optimizer='adam', loss='BinaryCrossentropy')\r\n    model.fit(trainDS, epochs=3)\r\n```\r\n\r\nResults: Alone `tf.data` spend about `18s`, `tf.data`+`CustomLayer` spend about `38s`.\r\n\r\nThe thing I want to clarify is that the use of `map` in `tf.data` to run augmentation is on the `CPU`, but if I write augmentation in the `Layer`, it should theoretically run on the `GPU`. Why is there such a big gap between the two?\r\n\r\nEnvironment: python3.6, tensorflow2.4.0", "comments": ["@Minxiangliu ,\r\nI was facing different error while trying to execute the given code.Please find the gist [here](https://colab.research.google.com/gist/tilakrayal/577e28dc13582f063aefeedfcbe2ab16/untitled187.ipynb).Also could you please try to test your code in  latest stable version v.2.7 and let us know if you are facing the same error. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 53775, "title": "A spelling mistake in gpu_delegate_serialization doc.", "body": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\nhttps://tensorflow.google.cn/lite/performance/gpu_advanced#gpu_delegate_serialization\r\n\r\n## Description of issue (what needs changing):\r\n \"ThThis improvement is is achieved by exchanging disk space for time savings.\" -> \"This improvement is is achieved by exchanging disk space for time savings.\"\r\n\r\n\r\n", "comments": ["Moving this to closed status as this has bee fixed."]}, {"number": 53774, "title": "JIT Compile too slow ", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NO\r\n- TensorFlow installed from (source or binary): source \r\n- TensorFlow version (use command below): master\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source): 4.4.4\r\n- GCC/Compiler version (if compiling from source): 7.3.1\r\n- CUDA/cuDNN version: cuda 11\r\n- GPU model and memory: yes 80GB\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n![image](https://user-images.githubusercontent.com/33950866/149608623-f2e6ed39-b587-4015-afbd-954bc491ba06.png)\r\nI run 1+1=2, TF cost 30mins...\r\nIt really compile 30 mins every times.\r\n\r\n**Describe the expected behavior**\r\nI don't want to wait 30mins ...\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no): yes\r\n- Briefly describe your candidate solution(if contributing):\r\nturn off ```TensorFlow was not built with CUDA kernel binaries compatible with compute capability 8.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.```\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\ntf.compat.v1.disable_eager_execution()\r\n\r\n#@tf.function(experimental_compile=False,autograph=True)\r\n#def zz_sm():\r\n#  # I don't want to use xla .\r\n#  input_a = tf.random.uniform([1024000], dtype=tf.int32, maxval=1024000)\r\n#  uniq_a, uniq_idx = tf.unique(input_a)\r\n#  uniq_a_shape = tf.shape(uniq_a)\r\n#  #uniq_a_shape_print = tf.Print(uniq_a_shape, [uniq_a_shape], \"zz:\", 10, 10)\r\n#  source_a = tf.gather(uniq_a, uniq_idx)\r\n#  source_a = source_a + source_a\r\n#  source_a = source_a * source_a\r\n#  source_a = source_a * source_a\r\n#  source_a = source_a * source_a\r\n#  source_a = source_a * source_a\r\n#  source_a = source_a * source_a\r\n#  source_a = source_a * source_a\r\n#  source_a = source_a * source_a\r\n#  source_a = source_a * source_a\r\n#  source_a = source_a * source_a\r\n#  source_a = source_a * source_a\r\n#  source_a = source_a * source_a\r\n#  source_a = source_a * source_a\r\n#  return source_a\r\n#\r\n#source_a = zz_sm()\r\nwith tf.xla.experimental.jit_scope(compile_ops=False):\r\n  input_a = tf.random.uniform([1024000], dtype=tf.int32, maxval=1024000)\r\n  uniq_a, uniq_idx = tf.unique(input_a)\r\n  uniq_a_shape = tf.shape(uniq_a)\r\n  #uniq_a_shape_print = tf.Print(uniq_a_shape, [uniq_a_shape], \"zz:\", 10, 10)\r\n  source_a = tf.gather(uniq_a, uniq_idx)\r\n  source_a = source_a + source_a\r\n  source_a = source_a * source_a\r\n  source_a = source_a * source_a\r\n  source_a = source_a * source_a\r\n  source_a = source_a * source_a\r\n  source_a = source_a * source_a\r\n  source_a = source_a * source_a\r\n  source_a = source_a * source_a\r\n  source_a = source_a * source_a\r\n  source_a = source_a * source_a\r\n  source_a = source_a * source_a\r\n  source_a = source_a * source_a\r\n  source_a = source_a * source_a\r\n\r\n#  I want to use xla .\r\nres_a_1 = source_a * source_a\r\nres_a_2 = res_a_1 + res_a_1\r\nres_a_3 = res_a_2 + res_a_2\r\nres_a_4 = res_a_3 + res_a_3\r\nres_a_5 = res_a_4 + res_a_4\r\nres_a_6 = res_a_5 + res_a_5\r\n\r\n\r\nsession_config = tf.compat.v1.ConfigProto(allow_soft_placement=True,\r\n                             log_device_placement=True)\r\n#session_config.graph_options.rewrite_options.disable_meta_optimizer=True\r\nsession_config.graph_options.optimizer_options.global_jit_level = tf.compat.v1.OptimizerOptions.ON_1\r\n\r\n\r\nwith tf.compat.v1.Session(config = session_config) as sess:\r\n    for i in range(16384) :\r\n      _ = sess.run([res_a_6]);\r\n      #print(res)\r\n```\r\n", "comments": ["Hi @zhaozheng09 ! Can you please refer this [thread](https://www.tensorflow.org/install/source) to build from using Bazel 3.7.2 ? [Reference](https://www.tensorflow.org/install/gpu#hardware_requirements). Thank you.", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53774\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53774\">No</a>\n"]}, {"number": 53773, "title": "Setup OSSF Security scorecards", "body": null, "comments": []}, {"number": 53770, "title": "Inference from frozen_graph yields all black result despite deeplab/vis.py works as intended (frozen_graph uses the same checkpoint)", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Stock code\r\n- Both on Windows 10 and Google colab\r\n- TensorFlow 1.x on google colab.\r\n- TensorFlow 2.6.2\r\n- TensorFlow version (use command below):\r\n\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\nI used the deeplabibrary to train my models. This is the script i used to create the checkpoint\r\n` %tensorflow_version 1.x\r\n!pip install tf_slim\r\nfrom google.colab import drive\r\ndrive.mount('/content/drive')\r\n!python /content/drive/MyDrive/models/research/deeplab/train.py --logtostderr \\\r\n   --training_number_of_steps=30000 \\\r\n   --train_split=\"train\" \\\r\n   --model_variant=\"xception_65\" \\\r\n   --atrous_rates=6 \\\r\n   --atrous_rates=12 \\\r\n   --atrous_rates=18 \\\r\n   --output_stride=16 \\\r\n   --decoder_output_stride=4 \\\r\n  --train_crop_size=\"513,513\" \\\r\n   --train_batch_size=1 \\\r\n   --dataset=\"pascal_voc_seg\" \\\r\n   --tf_initial_checkpoint=\"/content/drive/MyDrive/models/deeplabv3_pascal_train_aug/model.ckpt\" \\\r\n   --train_logdir=\"/content/drive/MyDrive/models/checkpoint_exc_all2\" \\\r\n   --dataset_dir=\"/content/drive/MyDrive/models/tfrecord_all\" \\\r\n   --fine_tune_batch_norm=false \\\r\n   --initialize_last_layer=true \\\r\n   --last_layers_contain_logits_only=false`\r\n\r\nThen, this is the working vis.py:\r\n\r\n`%tensorflow_version 1.x\r\n!pip install tf_slim\r\nfrom google.colab import drive\r\ndrive.mount('/content/drive')\r\n!python /content/drive/MyDrive/models/research/deeplab/vis.py --logtostderr \\\r\n  --vis_split=\"val\" \\\r\n  --model_variant=\"xception_65\" \\\r\n  --output_stride=16 \\\r\n    --atrous_rates=6 \\\r\n   --atrous_rates=12 \\\r\n   --atrous_rates=18 \\\r\n   --output_stride=16 \\\r\n  --decoder_output_stride=4 \\\r\n  --vis_crop_size=\"513,513\" \\\r\n  --min_resize_value=513 \\\r\n  --max_resize_value=513 \\\r\n  --dataset=\"pascal_voc_seg\" \\\r\n  --checkpoint_dir=\"/content/drive/MyDrive/models/checkpoint_exc_all2\" \\\r\n  --vis_logdir=\"/content/drive/MyDrive/models/Result_img_exc_final\" \\\r\n  --dataset_dir=\"/content/drive/MyDrive/models/tfrecord_all\" \\\r\n  --train_crop_size=513 \\\r\n  --max_number_of_iterations=1 --eval_interval_secs=0`\r\n\r\n\r\nAs stated i visualize correctly the segmentated output with vis.py.\r\n\r\nI tried to export the checkpoint using this:\r\n`%tensorflow_version 1.x\r\n!pip install tf_slim\r\nfrom google.colab import drive\r\ndrive.mount('/content/drive',force_remount=True)\r\n!python /content/drive/MyDrive/models/research/deeplab/export_model.py --logtostderr \\\r\n  --model_variant=\"xception_65\" \\\r\n   --atrous_rates=6 \\\r\n   --atrous_rates=12 \\\r\n   --atrous_rates=18 \\\r\n   --output_stride=16 \\\r\n   --crop_size=513 \\\r\n--crop_size=513\\\r\n   --num_classes=21\\\r\n   --export_path=\"/content/drive/MyDrive/models/frozen_graph/prova21.pb\"\\\r\n   --checkpoint_path=\"/content/drive/MyDrive/models/checkpoint_exc_all2/model.ckpt-30000\" \\`\r\nBut when loading and using the model for inference i get an all blank(0) result. This is the script i use:\r\n`import os\r\n\r\nfrom matplotlib import gridspec\r\nfrom matplotlib import pyplot as plt\r\nimport numpy as np\r\nfrom PIL import Image\r\nimport time\r\nimport cv2\r\nfrom tqdm import tqdm\r\n\r\nimport tensorflow as tf\r\n\r\n# Needed to show segmentation colormap labels\r\n\r\nflags = tf.compat.v1.app.flags\r\n\r\nFLAGS = flags.FLAGS\r\n\r\nflags.DEFINE_string('model_dir', r\"C:\\Users\\User\\PycharmProjects\\test_model_seg\\models\\exc65.pb\", 'Where the model is')\r\nflags.DEFINE_string('image_dir', \"0000631.jpg\", 'Where the image is')\r\nflags.DEFINE_string('save_dir', None, 'Dir for saving results')\r\nflags.DEFINE_string('image_name', None, 'Image name')\r\nclass DeepLabModel(object):\r\n    \"\"\"Class to load deeplab model and run inference.\"\"\"\r\n\r\n    INPUT_TENSOR_NAME = 'ImageTensor:0'\r\n    OUTPUT_TENSOR_NAME = 'SemanticPredictions:0'\r\n    INPUT_SIZE = 513\r\n\r\n    def __init__(self, model_dir):\r\n        \"\"\"Creates and loads pretrained deeplab model.\"\"\"\r\n        self.graph = tf.Graph()\r\n\r\n        graph_def = None\r\n        # Extract frozen graph from tar archive.\r\n        model_filename = FLAGS.model_dir\r\n        with tf.compat.v1.gfile.FastGFile(model_filename, 'rb') as f:\r\n            graph_def = tf.compat.v1.GraphDef()\r\n            graph_def.ParseFromString(open(\"models\\exc65.pb\", \"rb\").read())\r\n\r\n        if graph_def is None:\r\n            raise RuntimeError('Cannot find inference graph in tar archive.')\r\n\r\n        with self.graph.as_default():\r\n            tf.import_graph_def(graph_def, name='')\r\n\r\n        self.sess = tf.compat.v1.Session(graph=self.graph)\r\n\r\n    def run(self, image):\r\n        \"\"\"Runs inference on a single image.\r\n\r\n        Args:\r\n            image: A PIL.Image object, raw input image.\r\n\r\n        Returns:\r\n            resized_image: RGB image resized from original input image.\r\n            seg_map: Segmentation map of `resized_image`.\r\n        \"\"\"\r\n        width, height = image.size\r\n        resize_ratio = 1.0 * self.INPUT_SIZE / max(width, height)\r\n        target_size = (int(resize_ratio * width), int(resize_ratio * height))\r\n        resized_image = image.convert('RGB').resize(target_size, Image.ANTIALIAS)\r\n        print('Image resized')\r\n        start_time = time.time()\r\n        batch_seg_map = self.sess.run(\r\n            self.OUTPUT_TENSOR_NAME,\r\n            feed_dict={self.INPUT_TENSOR_NAME: [np.asarray(resized_image)]})\r\n        print('Image processing finished')\r\n        print('Elapsed time : ' + str(time.time() - start_time))\r\n        seg_map = batch_seg_map[0]\r\n        return resized_image, seg_map\r\n\r\n\r\nmodel = DeepLabModel(FLAGS.model_dir)\r\nprint('Model created successfully')\r\n\r\nimg = Image.open(\"0000631.jpg\")\r\n\r\nor_img, seg = model.run(img)\r\n\r\n\r\nfor x in seg:\r\n    print(x)`\r\nSome side notes that may be usefull:\r\n\r\nI used transfer training to segment the skin. My dataset is composed of nearly 32k images/segmented mask. I only have 2 classes in the segmented mask.(skin and background). I don't really know whats wrong with my code, perhaps is the way i import it?\r\n\r\nThanks in advance\r\n\r\n\r\n\r\n", "comments": ["Hi @Tix00! Could you please share the model file or update the error trace in above template? Thanks!", "> Hi @Tix00! Could you please share the model file or update the error trace in above template? Thanks!\r\n\r\nDo you need the .pb file or the checkpoint?\r\nAnd there is no error trace. It simply output and all blank(zeros) result. While it is working with the checkpoint model.\r\n\r\nhttps://drive.google.com/file/d/1-5ad_AcTyfEmUWh5Gu7_JCm-Vu7ZPa8P/view?usp=sharing", "> Hi @Tix00! Could you please share the model file or update the error trace in above template? Thanks!\r\n\r\nAm i missing something? Do you need more information?", "@Tix00 !  Its 1.x code actually which you might be trying to run compatibility mode in 2.6 which might be cause of issue. Can you upgrade your code base to 2.7 version and let us know ? Thanks!", "The whole code base(so redoing the preprocessing/training/export_graph) or\njust trying to use model .pb file?\n Because otherwise I already tried using the latest version of tensor flow\nwhile trying to make an inference Frome the .pb\nDoes it gives different results to you?\n\nIl mar 18 gen 2022, 05:10 mohantym ***@***.***> ha scritto:\n\n> @Tix00 <https://github.com/Tix00> ! Its 1.x code actually which you might\n> be trying to run compatibility mode in 2.6 which might be cause of issue.\n> Can you upgrade your code base to 2.7 version and let us know ? Thanks!\n>\n> \u2014\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/53770#issuecomment-1015054820>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AF6SGBIWM63VO2RXMY2WKD3UWTR5DANCNFSM5L7XSYTA>\n> .\n> Triage notifications on the go with GitHub Mobile for iOS\n> <https://apps.apple.com/app/apple-store/id1477376905?ct=notification-email&mt=8&pt=524675>\n> or Android\n> <https://play.google.com/store/apps/details?id=com.github.android&referrer=utm_campaign%3Dnotification-email%26utm_medium%3Demail%26utm_source%3Dgithub>.\n>\n> You are receiving this because you were mentioned.Message ID:\n> ***@***.***>\n>\n", "Can you please share the colab gist with results? Thank you!", "Yes of course.\nhttps://gist.github.com/Tix00/156ab9226f951475d9684d3f4e7708c6\n\nThank you for your help\n\nOn Tue, Jan 18, 2022 at 12:29 PM mohantym ***@***.***> wrote:\n\n> Can you please share the colab gist with results? Thank you!\n>\n> \u2014\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/53770#issuecomment-1015322280>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AF6SGBO5NRBOFB5EXO7VZWDUWVFJFANCNFSM5L7XSYTA>\n> .\n> Triage notifications on the go with GitHub Mobile for iOS\n> <https://apps.apple.com/app/apple-store/id1477376905?ct=notification-email&mt=8&pt=524675>\n> or Android\n> <https://play.google.com/store/apps/details?id=com.github.android&referrer=utm_campaign%3Dnotification-email%26utm_medium%3Demail%26utm_source%3Dgithub>.\n>\n> You are receiving this because you were mentioned.Message ID:\n> ***@***.***>\n>\n", "Did I miss anything? Should I provide something else?\n\nIl mar 18 gen 2022, 13:03 Angelo Italiano ***@***.***> ha\nscritto:\n\n> Yes of course.\n> https://gist.github.com/Tix00/156ab9226f951475d9684d3f4e7708c6\n>\n> Thank you for your help\n>\n> On Tue, Jan 18, 2022 at 12:29 PM mohantym ***@***.***>\n> wrote:\n>\n>> Can you please share the colab gist with results? Thank you!\n>>\n>> \u2014\n>> Reply to this email directly, view it on GitHub\n>> <https://github.com/tensorflow/tensorflow/issues/53770#issuecomment-1015322280>,\n>> or unsubscribe\n>> <https://github.com/notifications/unsubscribe-auth/AF6SGBO5NRBOFB5EXO7VZWDUWVFJFANCNFSM5L7XSYTA>\n>> .\n>> Triage notifications on the go with GitHub Mobile for iOS\n>> <https://apps.apple.com/app/apple-store/id1477376905?ct=notification-email&mt=8&pt=524675>\n>> or Android\n>> <https://play.google.com/store/apps/details?id=com.github.android&referrer=utm_campaign%3Dnotification-email%26utm_medium%3Demail%26utm_source%3Dgithub>.\n>>\n>> You are receiving this because you were mentioned.Message ID:\n>> ***@***.***>\n>>\n>\n", "@Saduf2019 ! Could you please look at this issue ? Attaching [gist](https://colab.sandbox.google.com/gist/mohantym/301704959531d6c6e0cf193928689803/github_53770.ipynb#scrollTo=08ddp6sq1Erk) for reference. ", "@Tix00 Session is `deprecated`. We see that you're using Session which does not work with  eager execution\r\n (TF V2). To migrate code that uses sessions to TF2, rewrite the code without it. Please see the [migration guide](https://www.tensorflow.org/guide/migrate#1_replace_v1sessionrun_calls) to migrate from 1.x to 2.x.\r\ntf.compat.v1.GraphDef   is also designed for TensorFlow v1. Please refer [this ](https://www.tensorflow.org/api_docs/python/tf/compat/v1/GraphDef)  .\r\n\r\n\r\nTF v1.x is currently  not actively supported so please try to upgrade to TF v2.4 or later versions.\r\nFor any further queries regarding TF v1.x specific issues please post it in [TF forum](https://discuss.tensorflow.org/) where there is a larger community to get you the right help.\r\nThanks! ", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Thanks for your concern. I resolved the issue. \r\n\r\n--save_inference_graph=True \\\r\n\r\nAdding this flag in the export model script will do the trick.\r\n\r\nHave a nice day and thanks for your time", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53770\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53770\">No</a>\n"]}, {"number": 53769, "title": "i64 index def in build_defs", "body": "Enabling JIT indexing within the build pipeline.\r\nThis PR is continuation on the pull req: 53622.\r\nCC: @frgossen  :)", "comments": ["@frgossen can you look again?", "Hi Kushan, the failing test is `//tensorflow/core/kernels/mlir_generated:atanh_gpu_atanh_kernels_experimental_gpu_f16_f16_gen_test`. ", "> Hi Kushan, the failing test is `//tensorflow/core/kernels/mlir_generated:atanh_gpu_atanh_kernels_experimental_gpu_f16_f16_gen_test`.\r\n\r\nThanks Frederik, I didn't have access to see the internal tests. Looking into it."]}, {"number": 53768, "title": "Added missing 'return true'", "body": "When evaluating particularly sized uint8 quantized AveragPool2D operations, it's broken due to missing 'return true' statement here:\r\nhttps://github.com/tensorflow/tensorflow/blob/v2.4.4/tensorflow/lite/kernels/internal/optimized/optimized_ops.h#L3424\r\n\r\nThis regression was originated here:\r\nhttps://github.com/tensorflow/tensorflow/commit/a5ceb2445d37d9d89a13de3fd0d0d991f4962522#diff-d7e3b0af29f6e121b2c30e4fc932dcb6c67ab073d759bd9786b60d4069637e78R3293\r\n\r\nWhich appears change specific for the r2.4 branch, master branch doesn't have this code any longer:\r\n\r\nhttps://github.com/tensorflow/tensorflow/commit/b44dd5e97df2f9aec5ad71e8122be98a59a35057", "comments": ["We no longer patch TF 2.4. Please make this against master branch if needed."]}, {"number": 53765, "title": "systemlibs: unbundle abseil-cpp", "body": "This unbundles abseil-cpp, tested and works on Gentoo Linux. It was helpful when building with std=c++17 since there are some quite significant differences in how abseil works between c++14/17.\r\n\r\n(NB: This is not sufficient for building with C++17, there are a few targets in `tensorflow/compiler/mlir/lite/BUILD` which hardcode c++14 currently)", "comments": ["I'm removing the hardcoding as we speak, turns out some were added before TF supported C++14 and then the others were just copy-paste.", "> I'm removing the hardcoding as we speak, turns out some were added before TF supported C++14 and then the others were just copy-paste.\r\n\r\nAha! that makes sense! thanks for fixing! :)"]}, {"number": 53764, "title": "Cherrypick python3.10 windows on r2.8", "body": "Cherry Picked commits for R 2.8 to resolve Python 3.10 build errors on Windows - \r\n\r\n1. cl/421654465 - Disable debug pyreadline test (Needs to be cherry picked) - 93d09ee4ac3a44925595884390be6eb48103e840\r\n2. cl/421576429 - Patch Protobuf (Needs to be Cherry Picked) - abfc5731b3b98f11f1bbbcffc2be97a74628901e\r\n3. cl/421044747 - Update grpc, protobuf in ci_build (Needs to be Cherry Picked) - 99514f053019fe06ba26cb0d3faea06eacc1a57f", "comments": []}, {"number": 53762, "title": "TF2MLIR  tf Dialect -> hlo Dialect", "body": "\r\n**System information**\r\n- Linux ubuntu 18.04\r\n- TensorFlow installed from source\r\n- TensorFlow version: r2.6\r\n- Python version: 3.8\r\n- Bazel version: 4.2.2\r\n- GCC/Compiler version: 9.4.0\r\n\r\nI am ready to lowering the Tensorflow model to linalg Dialect\r\n\r\nFirst, I use the bazel build the tf-opt and tf-mlir-translate.\r\n\r\n\r\nTensorflow model ssd is from Tensorflow Hub\r\nAnd use the tools:\r\ntf-mlir-translate :  savedmodel -> mlir    --ok\r\n`./tf-mlir-translate --savedmodel-signaturedefs-to-mlir ./ssd  -o ssd.mlir`\r\n\r\ntf-opt :  tf_executor Dialect -> tf Dialect   --ok\r\n`./tf-opt -tf-executor-to-functional-conversion ssd.mlir -o ssd-func.mlir `\r\n\r\ntf-opt :  tf Dialect -> hlo Dialect  -- error\r\n`$ ./tf-opt --tf-to-hlo-pipeline ssd-func.mlir -o ssd-mhlo.mlir`\r\nI got the error \r\n\r\n```\r\nremark: lowering requires static shaped tensor operands\r\n    %1136 = \"tf.ResizeBilinear\"(%1135, %cst_3579) {align_corners = false, device = \"\", half_pixel_centers = false} : (tensor<*xf32>, tensor<2xi32>) -> tensor<*xf32>\r\n\r\n```\r\nThe TF model is ssd-mobilenet, does it not support dynamic shape? or i used it wrong.\r\ntensorflow version r2.6\r\n\r\nthe full  output log:\r\n\r\n```\r\n2022-01-17 08:31:23.118405: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\nssd-func.mlir:5099:13: remark: lowering requires static shaped tensor operands\r\n    %1136 = \"tf.ResizeBilinear\"(%1135, %cst_3579) {align_corners = false, device = \"\", half_pixel_centers = false} : (tensor<*xf32>, tensor<2xi32>) -> tensor<*xf32>\r\n            ^\r\nssd-func.mlir:356:12: note: called from\r\n    %0:8 = \"tf.StatefulPartitionedCall\"(%arg0, %arg173, %arg175, %arg174, %arg176, %arg177, %arg178, %arg200, %arg199, %arg201, %arg202, %arg243, %arg265, %arg264, %arg266, %arg267, %arg203, %arg205, %arg204, %arg206, %arg207, %arg268, %arg270, %arg269, %arg271, %arg272, %arg208, %arg210, %arg209, %arg211, %arg212, %arg273, %arg275, %arg274, %arg276, %arg277, %arg213, %arg215, %arg214, %arg216, %arg217, %arg278, %arg280, %arg279, %arg281, %arg282, %arg218, %arg220, %arg219, %arg221, %arg222, %arg283, %arg285, %arg284, %arg286, %arg287, %arg223, %arg225, %arg224, %arg226, %arg227, %arg288, %arg290, %arg289, %arg291, %arg292, %arg228, %arg230, %arg229, %arg231, %arg232, %arg293, %arg295, %arg294, %arg296, %arg297, %arg233, %arg235, %arg234, %arg236, %arg237, %arg298, %arg300, %arg299, %arg301, %arg302, %arg238, %arg240, %arg239, %arg241, %arg242, %arg303, %arg305, %arg304, %arg306, %arg307, %arg179, %arg181, %arg180, %arg182, %arg183, %arg244, %arg246, %arg245, %arg247, %arg248, %arg184, %arg186, %arg185, %arg187, %arg188, %arg249, %arg251, %arg250, %arg252, %arg253, %arg189, %arg191, %arg190, %arg192, %arg193, %arg254, %arg256, %arg255, %arg257, %arg258, %arg194, %arg196, %arg195, %arg197, %arg198, %arg259, %arg261, %arg260, %arg262, %arg263, %arg313, %arg312, %arg311, %arg310, %arg323, %arg320, %arg319, %arg321, %arg322, %arg309, %arg308, %arg318, %arg315, %arg314, %arg316, %arg317, %arg328, %arg325, %arg324, %arg326, %arg327, %arg333, %arg330, %arg329, %arg331, %arg332, %cst, %cst_0, %cst_6, %cst_7, %cst_8, %cst_9, %cst_10, %cst_11, %cst_12, %cst_13, %cst_1, %cst_2, %cst_3, %cst_4, %cst_5, %arg21, %arg2, %arg1, %arg3, %arg4, %arg42, %arg23, %arg22, %arg24, %arg25, %arg63, %arg44, %arg43, %arg45, %arg46, %arg84, %arg65, %arg64, %arg66, %arg67, %arg170, %arg169, %arg105, %arg86, %arg85, %arg87, %arg88, %arg126, %arg107, %arg106, %arg108, %arg109, %arg147, %arg128, %arg127, %arg129, %arg130, %arg168, %arg149, %arg148, %arg150, %arg151, %arg172, %arg171, %arg6, %arg5, %arg7, %arg8, %arg27, %arg26, %arg28, %arg29, %arg48, %arg47, %arg49, %arg50, %arg69, %arg68, %arg70, %arg71, %arg90, %arg89, %arg91, %arg92, %arg111, %arg110, %arg112, %arg113, %arg132, %arg131, %arg133, %arg134, %arg153, %arg152, %arg154, %arg155, %arg10, %arg9, %arg11, %arg12, %arg31, %arg30, %arg32, %arg33, %arg52, %arg51, %arg53, %arg54, %arg73, %arg72, %arg74, %arg75, %arg94, %arg93, %arg95, %arg96, %arg115, %arg114, %arg116, %arg117, %arg136, %arg135, %arg137, %arg138, %arg157, %arg156, %arg158, %arg159, %arg14, %arg13, %arg15, %arg16, %arg35, %arg34, %arg36, %arg37, %arg56, %arg55, %arg57, %arg58, %arg77, %arg76, %arg78, %arg79, %arg98, %arg97, %arg99, %arg100, %arg119, %arg118, %arg120, %arg121, %arg140, %arg139, %arg141, %arg142, %arg161, %arg160, %arg162, %arg163, %arg18, %arg17, %arg19, %arg20, %arg39, %arg38, %arg40, %arg41, %arg60, %arg59, %arg61, %arg62, %arg81, %arg80, %arg82, %arg83, %arg102, %arg101, %arg103, %arg104, %arg123, %arg122, %arg124, %arg125, %arg144, %arg143, %arg145, %arg146, %arg165, %arg164, %arg166, %arg167) {_collective_manager_ids = [], _read_only_resource_inputs = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348], config = \"\", config_proto = \"\\0A\\07\\0A\\03CPU\\10\\01\\0A\\07\\0A\\03GPU\\10\\002\\02J\\008\\01\\82\\01\\00\", device = \"\", executor_type = \"\", f = @__inference_signature_wrapper_236900} : (tensor<1x?x?x3xui8>, tensor<!tf_type.resource<tensor<3x3x3x32xf32>>>, tensor<!tf_type.resource<tensor<32xf32>>>, tensor<!tf_type.resource<tensor<32xf32>>>, tensor<!tf_type.resource<tensor<32xf32>>>, tensor<!tf_type.resource<tensor<32xf32>>>, tensor<!tf_type.resource<tensor<3x3x32x1xf32>>>, tensor<!tf_type.resource<tensor<32xf32>>>, tensor<!tf_type.resource<tensor<32xf32>>>, tensor<!tf_type.resource<tensor<32xf32>>>, tensor<!tf_type.resource<tensor<32xf32>>>, tensor<!tf_type.resource<tensor<1x1x32x64xf32>>>, tensor<!tf_type.resource<tensor<64xf32>>>, tensor<!tf_type.resource<tensor<64xf32>>>, tensor<!tf_type.resource<tensor<64xf32>>>, tensor<!tf_type.resource<tensor<64xf32>>>, tensor<!tf_type.resource<tensor<3x3x64x1xf32>>>, tensor<!tf_type.resource<tensor<64xf32>>>, tensor<!tf_type.resource<tensor<64xf32>>>, tensor<!tf_type.resource<tensor<64xf32>>>, tensor<!tf_type.resource<tensor<64xf32>>>, tensor<!tf_type.resource<tensor<1x1x64x128xf32>>>, tensor<!tf_type.resource<tensor<128xf32>>>, tensor<!tf_type.resource<tensor<128xf32>>>, tensor<!tf_type.resource<tensor<128xf32>>>, tensor<!tf_type.resource<tensor<128xf32>>>, tensor<!tf_type.resource<tensor<3x3x128x1xf32>>>, tensor<!tf_type.resource<tensor<128xf32>>>, tensor<!tf_type.resource<tensor<128xf32>>>, tensor<!tf_type.resource<tensor<128xf32>>>, tensor<!tf_type.resource<tensor<128xf32>>>, tensor<!tf_type.resource<tensor<1x1x128x128xf32>>>, tensor<!tf_type.resource<tensor<128xf32>>>, tensor<!tf_type.resource<tensor<128xf32>>>, tensor<!tf_type.resource<tensor<128xf32>>>, tensor<!tf_type.resource<tensor<128xf32>>>, tensor<!tf_type.resource<tensor<3x3x128x1xf32>>>, tensor<!tf_type.resource<tensor<128xf32>>>, tensor<!tf_type.resource<tensor<128xf32>>>, tensor<!tf_type.resource<tensor<128xf32>>>, tensor<!tf_type.resource<tensor<128xf32>>>, tensor<!tf_type.resource<tensor<1x1x128x256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<3x3x256x1xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<1x1x256x256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<3x3x256x1xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<1x1x256x512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<3x3x512x1xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<1x1x512x512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<3x3x512x1xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<1x1x512x512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<3x3x512x1xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<1x1x512x512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<3x3x512x1xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<1x1x512x512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<3x3x512x1xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<1x1x512x512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<3x3x512x1xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<1x1x512x1024xf32>>>, tensor<!tf_type.resource<tensor<1024xf32>>>, tensor<!tf_type.resource<tensor<1024xf32>>>, tensor<!tf_type.resource<tensor<1024xf32>>>, tensor<!tf_type.resource<tensor<1024xf32>>>, tensor<!tf_type.resource<tensor<3x3x1024x1xf32>>>, tensor<!tf_type.resource<tensor<1024xf32>>>, tensor<!tf_type.resource<tensor<1024xf32>>>, tensor<!tf_type.resource<tensor<1024xf32>>>, tensor<!tf_type.resource<tensor<1024xf32>>>, tensor<!tf_type.resource<tensor<1x1x1024x1024xf32>>>, tensor<!tf_type.resource<tensor<1024xf32>>>, tensor<!tf_type.resource<tensor<1024xf32>>>, tensor<!tf_type.resource<tensor<1024xf32>>>, tensor<!tf_type.resource<tensor<1024xf32>>>, tensor<!tf_type.resource<tensor<1x1x1024x256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<1x1x512x256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<3x3x256x256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<1x1x256x256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<3x3x256x256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<3x3x256x256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<3x3x256x256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<2xf32>, tensor<2xf32>, tensor<2xf32>, tensor<2xf32>, tensor<2xf32>, tensor<2xf32>, tensor<2xf32>, tensor<2xf32>, tensor<2xf32>, tensor<2xf32>, tensor<2xf32>, tensor<2xf32>, tensor<2xf32>, tensor<2xf32>, tensor<2xf32>, tensor<!tf_type.resource<tensor<3x3x256x256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<3x3x256x256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<3x3x256x256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<3x3x256x256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<3x3x256x24xf32>>>, tensor<!tf_type.resource<tensor<24xf32>>>, tensor<!tf_type.resource<tensor<3x3x256x256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<3x3x256x256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<3x3x256x256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<3x3x256x256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<3x3x256x546xf32>>>, tensor<!tf_type.resource<tensor<546xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>) -> (tensor<*xf32>, tensor<*xf32>, tensor<*xf32>, tensor<*xf32>, tensor<*xf32>, tensor<*xf32>, tensor<*xf32>, tensor<*xf32>)\r\n           ^\r\nssd-func.mlir:5099:13: note: see current operation: %169 = \"tf.ResizeBilinear\"(%168, %cst_118) {align_corners = false, device = \"\", half_pixel_centers = false} : (tensor<1x?x?x3xf32>, tensor<2xi32>) -> tensor<1x640x640x3xf32>\r\n    %1136 = \"tf.ResizeBilinear\"(%1135, %cst_3579) {align_corners = false, device = \"\", half_pixel_centers = false} : (tensor<*xf32>, tensor<2xi32>) -> tensor<*xf32>\r\n            ^\r\nssd-func.mlir:5099:13: remark: lowering requires static shaped tensor operands\r\n    %1136 = \"tf.ResizeBilinear\"(%1135, %cst_3579) {align_corners = false, device = \"\", half_pixel_centers = false} : (tensor<*xf32>, tensor<2xi32>) -> tensor<*xf32>\r\n            ^\r\nssd-func.mlir:356:12: note: called from\r\n    %0:8 = \"tf.StatefulPartitionedCall\"(%arg0, %arg173, %arg175, %arg174, %arg176, %arg177, %arg178, %arg200, %arg199, %arg201, %arg202, %arg243, %arg265, %arg264, %arg266, %arg267, %arg203, %arg205, %arg204, %arg206, %arg207, %arg268, %arg270, %arg269, %arg271, %arg272, %arg208, %arg210, %arg209, %arg211, %arg212, %arg273, %arg275, %arg274, %arg276, %arg277, %arg213, %arg215, %arg214, %arg216, %arg217, %arg278, %arg280, %arg279, %arg281, %arg282, %arg218, %arg220, %arg219, %arg221, %arg222, %arg283, %arg285, %arg284, %arg286, %arg287, %arg223, %arg225, %arg224, %arg226, %arg227, %arg288, %arg290, %arg289, %arg291, %arg292, %arg228, %arg230, %arg229, %arg231, %arg232, %arg293, %arg295, %arg294, %arg296, %arg297, %arg233, %arg235, %arg234, %arg236, %arg237, %arg298, %arg300, %arg299, %arg301, %arg302, %arg238, %arg240, %arg239, %arg241, %arg242, %arg303, %arg305, %arg304, %arg306, %arg307, %arg179, %arg181, %arg180, %arg182, %arg183, %arg244, %arg246, %arg245, %arg247, %arg248, %arg184, %arg186, %arg185, %arg187, %arg188, %arg249, %arg251, %arg250, %arg252, %arg253, %arg189, %arg191, %arg190, %arg192, %arg193, %arg254, %arg256, %arg255, %arg257, %arg258, %arg194, %arg196, %arg195, %arg197, %arg198, %arg259, %arg261, %arg260, %arg262, %arg263, %arg313, %arg312, %arg311, %arg310, %arg323, %arg320, %arg319, %arg321, %arg322, %arg309, %arg308, %arg318, %arg315, %arg314, %arg316, %arg317, %arg328, %arg325, %arg324, %arg326, %arg327, %arg333, %arg330, %arg329, %arg331, %arg332, %cst, %cst_0, %cst_6, %cst_7, %cst_8, %cst_9, %cst_10, %cst_11, %cst_12, %cst_13, %cst_1, %cst_2, %cst_3, %cst_4, %cst_5, %arg21, %arg2, %arg1, %arg3, %arg4, %arg42, %arg23, %arg22, %arg24, %arg25, %arg63, %arg44, %arg43, %arg45, %arg46, %arg84, %arg65, %arg64, %arg66, %arg67, %arg170, %arg169, %arg105, %arg86, %arg85, %arg87, %arg88, %arg126, %arg107, %arg106, %arg108, %arg109, %arg147, %arg128, %arg127, %arg129, %arg130, %arg168, %arg149, %arg148, %arg150, %arg151, %arg172, %arg171, %arg6, %arg5, %arg7, %arg8, %arg27, %arg26, %arg28, %arg29, %arg48, %arg47, %arg49, %arg50, %arg69, %arg68, %arg70, %arg71, %arg90, %arg89, %arg91, %arg92, %arg111, %arg110, %arg112, %arg113, %arg132, %arg131, %arg133, %arg134, %arg153, %arg152, %arg154, %arg155, %arg10, %arg9, %arg11, %arg12, %arg31, %arg30, %arg32, %arg33, %arg52, %arg51, %arg53, %arg54, %arg73, %arg72, %arg74, %arg75, %arg94, %arg93, %arg95, %arg96, %arg115, %arg114, %arg116, %arg117, %arg136, %arg135, %arg137, %arg138, %arg157, %arg156, %arg158, %arg159, %arg14, %arg13, %arg15, %arg16, %arg35, %arg34, %arg36, %arg37, %arg56, %arg55, %arg57, %arg58, %arg77, %arg76, %arg78, %arg79, %arg98, %arg97, %arg99, %arg100, %arg119, %arg118, %arg120, %arg121, %arg140, %arg139, %arg141, %arg142, %arg161, %arg160, %arg162, %arg163, %arg18, %arg17, %arg19, %arg20, %arg39, %arg38, %arg40, %arg41, %arg60, %arg59, %arg61, %arg62, %arg81, %arg80, %arg82, %arg83, %arg102, %arg101, %arg103, %arg104, %arg123, %arg122, %arg124, %arg125, %arg144, %arg143, %arg145, %arg146, %arg165, %arg164, %arg166, %arg167) {_collective_manager_ids = [], _read_only_resource_inputs = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348], config = \"\", config_proto = \"\\0A\\07\\0A\\03CPU\\10\\01\\0A\\07\\0A\\03GPU\\10\\002\\02J\\008\\01\\82\\01\\00\", device = \"\", executor_type = \"\", f = @__inference_signature_wrapper_236900} : (tensor<1x?x?x3xui8>, tensor<!tf_type.resource<tensor<3x3x3x32xf32>>>, tensor<!tf_type.resource<tensor<32xf32>>>, tensor<!tf_type.resource<tensor<32xf32>>>, tensor<!tf_type.resource<tensor<32xf32>>>, tensor<!tf_type.resource<tensor<32xf32>>>, tensor<!tf_type.resource<tensor<3x3x32x1xf32>>>, tensor<!tf_type.resource<tensor<32xf32>>>, tensor<!tf_type.resource<tensor<32xf32>>>, tensor<!tf_type.resource<tensor<32xf32>>>, tensor<!tf_type.resource<tensor<32xf32>>>, tensor<!tf_type.resource<tensor<1x1x32x64xf32>>>, tensor<!tf_type.resource<tensor<64xf32>>>, tensor<!tf_type.resource<tensor<64xf32>>>, tensor<!tf_type.resource<tensor<64xf32>>>, tensor<!tf_type.resource<tensor<64xf32>>>, tensor<!tf_type.resource<tensor<3x3x64x1xf32>>>, tensor<!tf_type.resource<tensor<64xf32>>>, tensor<!tf_type.resource<tensor<64xf32>>>, tensor<!tf_type.resource<tensor<64xf32>>>, tensor<!tf_type.resource<tensor<64xf32>>>, tensor<!tf_type.resource<tensor<1x1x64x128xf32>>>, tensor<!tf_type.resource<tensor<128xf32>>>, tensor<!tf_type.resource<tensor<128xf32>>>, tensor<!tf_type.resource<tensor<128xf32>>>, tensor<!tf_type.resource<tensor<128xf32>>>, tensor<!tf_type.resource<tensor<3x3x128x1xf32>>>, tensor<!tf_type.resource<tensor<128xf32>>>, tensor<!tf_type.resource<tensor<128xf32>>>, tensor<!tf_type.resource<tensor<128xf32>>>, tensor<!tf_type.resource<tensor<128xf32>>>, tensor<!tf_type.resource<tensor<1x1x128x128xf32>>>, tensor<!tf_type.resource<tensor<128xf32>>>, tensor<!tf_type.resource<tensor<128xf32>>>, tensor<!tf_type.resource<tensor<128xf32>>>, tensor<!tf_type.resource<tensor<128xf32>>>, tensor<!tf_type.resource<tensor<3x3x128x1xf32>>>, tensor<!tf_type.resource<tensor<128xf32>>>, tensor<!tf_type.resource<tensor<128xf32>>>, tensor<!tf_type.resource<tensor<128xf32>>>, tensor<!tf_type.resource<tensor<128xf32>>>, tensor<!tf_type.resource<tensor<1x1x128x256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<3x3x256x1xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<1x1x256x256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<3x3x256x1xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<1x1x256x512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<3x3x512x1xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<1x1x512x512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<3x3x512x1xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<1x1x512x512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<3x3x512x1xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<1x1x512x512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<3x3x512x1xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<1x1x512x512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<3x3x512x1xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<1x1x512x512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<3x3x512x1xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<1x1x512x1024xf32>>>, tensor<!tf_type.resource<tensor<1024xf32>>>, tensor<!tf_type.resource<tensor<1024xf32>>>, tensor<!tf_type.resource<tensor<1024xf32>>>, tensor<!tf_type.resource<tensor<1024xf32>>>, tensor<!tf_type.resource<tensor<3x3x1024x1xf32>>>, tensor<!tf_type.resource<tensor<1024xf32>>>, tensor<!tf_type.resource<tensor<1024xf32>>>, tensor<!tf_type.resource<tensor<1024xf32>>>, tensor<!tf_type.resource<tensor<1024xf32>>>, tensor<!tf_type.resource<tensor<1x1x1024x1024xf32>>>, tensor<!tf_type.resource<tensor<1024xf32>>>, tensor<!tf_type.resource<tensor<1024xf32>>>, tensor<!tf_type.resource<tensor<1024xf32>>>, tensor<!tf_type.resource<tensor<1024xf32>>>, tensor<!tf_type.resource<tensor<1x1x1024x256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<1x1x512x256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<3x3x256x256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<1x1x256x256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<3x3x256x256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<3x3x256x256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<3x3x256x256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<2xf32>, tensor<2xf32>, tensor<2xf32>, tensor<2xf32>, tensor<2xf32>, tensor<2xf32>, tensor<2xf32>, tensor<2xf32>, tensor<2xf32>, tensor<2xf32>, tensor<2xf32>, tensor<2xf32>, tensor<2xf32>, tensor<2xf32>, tensor<2xf32>, tensor<!tf_type.resource<tensor<3x3x256x256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<3x3x256x256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<3x3x256x256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<3x3x256x256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<3x3x256x24xf32>>>, tensor<!tf_type.resource<tensor<24xf32>>>, tensor<!tf_type.resource<tensor<3x3x256x256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<3x3x256x256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<3x3x256x256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<3x3x256x256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<3x3x256x546xf32>>>, tensor<!tf_type.resource<tensor<546xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>) -> (tensor<*xf32>, tensor<*xf32>, tensor<*xf32>, tensor<*xf32>, tensor<*xf32>, tensor<*xf32>, tensor<*xf32>, tensor<*xf32>)\r\n           ^\r\nssd-func.mlir:5099:13: note: see current operation: %50 = \"tf.ResizeBilinear\"(%49, %20) {align_corners = false, device = \"\", half_pixel_centers = false} : (tensor<1x?x?x3xf32>, tensor<2xi32>) -> tensor<1x640x640x3xf32>\r\n    %1136 = \"tf.ResizeBilinear\"(%1135, %cst_3579) {align_corners = false, device = \"\", half_pixel_centers = false} : (tensor<*xf32>, tensor<2xi32>) -> tensor<*xf32>\r\n            ^\r\nssd-func.mlir:340:3: error: The following operations cannot be legalized: tf.NonMaxSuppressionV5 (count: 90); tf.ReadVariableOp (count: 381); tf.ResizeBilinear (count: 1); tf.TopKV2 (count: 2); tf.Where (count: 1). These legalization failure(s) may be due to missing TF to HLO lowerings and/or unsupported attributes, etc.\r\n  func @serving_default(%arg0: tensor<1x?x?x3xui8> {tf_saved_model.index_path = [\"input_tensor\"]}, %arg1: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_0/BatchNorm/feature_0/beta\"}, %arg2: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_0/BatchNorm/feature_0/gamma\"}, %arg3: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_0/BatchNorm/feature_0/moving_mean\"}, %arg4: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_0/BatchNorm/feature_0/moving_variance\"}, %arg5: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_0/BatchNorm/feature_1/beta\"}, %arg6: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_0/BatchNorm/feature_1/gamma\"}, %arg7: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_0/BatchNorm/feature_1/moving_mean\"}, %arg8: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_0/BatchNorm/feature_1/moving_variance\"}, %arg9: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_0/BatchNorm/feature_2/beta\"}, %arg10: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_0/BatchNorm/feature_2/gamma\"}, %arg11: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_0/BatchNorm/feature_2/moving_mean\"}, %arg12: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_0/BatchNorm/feature_2/moving_variance\"}, %arg13: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_0/BatchNorm/feature_3/beta\"}, %arg14: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_0/BatchNorm/feature_3/gamma\"}, %arg15: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_0/BatchNorm/feature_3/moving_mean\"}, %arg16: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_0/BatchNorm/feature_3/moving_variance\"}, %arg17: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_0/BatchNorm/feature_4/beta\"}, %arg18: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_0/BatchNorm/feature_4/gamma\"}, %arg19: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_0/BatchNorm/feature_4/moving_mean\"}, %arg20: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_0/BatchNorm/feature_4/moving_variance\"}, %arg21: tensor<!tf_type.resource<tensor<3x3x256x256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_0/kernel\"}, %arg22: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_1/BatchNorm/feature_0/beta\"}, %arg23: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_1/BatchNorm/feature_0/gamma\"}, %arg24: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_1/BatchNorm/feature_0/moving_mean\"}, %arg25: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_1/BatchNorm/feature_0/moving_variance\"}, %arg26: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_1/BatchNorm/feature_1/beta\"}, %arg27: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_1/BatchNorm/feature_1/gamma\"}, %arg28: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_1/BatchNorm/feature_1/moving_mean\"}, %arg29: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_1/BatchNorm/feature_1/moving_variance\"}, %arg30: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_1/BatchNorm/feature_2/beta\"}, %arg31: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_1/BatchNorm/feature_2/gamma\"}, %arg32: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_1/BatchNorm/feature_2/moving_mean\"}, %arg33: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_1/BatchNorm/feature_2/moving_variance\"}, %arg34: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_1/BatchNorm/feature_3/beta\"}, %arg35: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_1/BatchNorm/feature_3/gamma\"}, %arg36: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_1/BatchNorm/feature_3/moving_mean\"}, %arg37: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_1/BatchNorm/feature_3/moving_variance\"}, %arg38: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_1/BatchNorm/feature_4/beta\"}, %arg39: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_1/BatchNorm/feature_4/gamma\"}, %arg40: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_1/BatchNorm/feature_4/moving_mean\"}, %arg41: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_1/BatchNorm/feature_4/moving_variance\"}, %arg42: tensor<!tf_type.resource<tensor<3x3x256x256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_1/kernel\"}, %arg43: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_2/BatchNorm/feature_0/beta\"}, %arg44: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_2/BatchNorm/feature_0/gamma\"}, %arg45: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_2/BatchNorm/feature_0/moving_mean\"}, %arg46: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_2/BatchNorm/feature_0/moving_variance\"}, %arg47: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_2/BatchNorm/feature_1/beta\"}, %arg48: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_2/BatchNorm/feature_1/gamma\"}, %arg49: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_2/BatchNorm/feature_1/moving_mean\"}, %arg50: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_2/BatchNorm/feature_1/moving_variance\"}, %arg51: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_2/BatchNorm/feature_2/beta\"}, %arg52: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_2/BatchNorm/feature_2/gamma\"}, %arg53: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_2/BatchNorm/feature_2/moving_mean\"}, %arg54: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_2/BatchNorm/feature_2/moving_variance\"}, %arg55: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_2/BatchNorm/feature_3/beta\"}, %arg56: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_2/BatchNorm/feature_3/gamma\"}, %arg57: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_2/BatchNorm/feature_3/moving_mean\"}, %arg58: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_2/BatchNorm/feature_3/moving_variance\"}, %arg59: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_2/BatchNorm/feature_4/beta\"}, %arg60: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_2/BatchNorm/feature_4/gamma\"}, %arg61: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_2/BatchNorm/feature_4/moving_mean\"}, %arg62: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_2/BatchNorm/feature_4/moving_variance\"}, %arg63: tensor<!tf_type.resource<tensor<3x3x256x256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_2/kernel\"}, %arg64: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_3/BatchNorm/feature_0/beta\"}, %arg65: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_3/BatchNorm/feature_0/gamma\"}, %arg66: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_3/BatchNorm/feature_0/moving_mean\"}, %arg67: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_3/BatchNorm/feature_0/moving_variance\"}, %arg68: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_3/BatchNorm/feature_1/beta\"}, %arg69: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_3/BatchNorm/feature_1/gamma\"}, %arg70: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_3/BatchNorm/feature_1/moving_mean\"}, %arg71: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_3/BatchNorm/feature_1/moving_variance\"}, %arg72: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_3/BatchNorm/feature_2/beta\"}, %arg73: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_3/BatchNorm/feature_2/gamma\"}, %arg74: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_3/BatchNorm/feature_2/moving_mean\"}, %arg75: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_3/BatchNorm/feature_2/moving_variance\"}, %arg76: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_3/BatchNorm/feature_3/beta\"}, %arg77: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_3/BatchNorm/feature_3/gamma\"}, %arg78: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_3/BatchNorm/feature_3/moving_mean\"}, %arg79: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_3/BatchNorm/feature_3/moving_variance\"}, %arg80: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_3/BatchNorm/feature_4/beta\"}, %arg81: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_3/BatchNorm/feature_4/gamma\"}, %arg82: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_3/BatchNorm/feature_4/moving_mean\"}, %arg83: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_3/BatchNorm/feature_4/moving_variance\"}, %arg84: tensor<!tf_type.resource<tensor<3x3x256x256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_3/kernel\"}, %arg85: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_0/BatchNorm/feature_0/beta\"}, %arg86: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_0/BatchNorm/feature_0/gamma\"}, %arg87: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_0/BatchNorm/feature_0/moving_mean\"}, %arg88: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_0/BatchNorm/feature_0/moving_variance\"}, %arg89: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_0/BatchNorm/feature_1/beta\"}, %arg90: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_0/BatchNorm/feature_1/gamma\"}, %arg91: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_0/BatchNorm/feature_1/moving_mean\"}, %arg92: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_0/BatchNorm/feature_1/moving_variance\"}, %arg93: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_0/BatchNorm/feature_2/beta\"}, %arg94: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_0/BatchNorm/feature_2/gamma\"}, %arg95: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_0/BatchNorm/feature_2/moving_mean\"}, %arg96: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_0/BatchNorm/feature_2/moving_variance\"}, %arg97: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_0/BatchNorm/feature_3/beta\"}, %arg98: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_0/BatchNorm/feature_3/gamma\"}, %arg99: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_0/BatchNorm/feature_3/moving_mean\"}, %arg100: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_0/BatchNorm/feature_3/moving_variance\"}, %arg101: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_0/BatchNorm/feature_4/beta\"}, %arg102: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_0/BatchNorm/feature_4/gamma\"}, %arg103: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_0/BatchNorm/feature_4/moving_mean\"}, %arg104: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_0/BatchNorm/feature_4/moving_variance\"}, %arg105: tensor<!tf_type.resource<tensor<3x3x256x256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_0/kernel\"}, %arg106: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_1/BatchNorm/feature_0/beta\"}, %arg107: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_1/BatchNorm/feature_0/gamma\"}, %arg108: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_1/BatchNorm/feature_0/moving_mean\"}, %arg109: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_1/BatchNorm/feature_0/moving_variance\"}, %arg110: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_1/BatchNorm/feature_1/beta\"}, %arg111: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_1/BatchNorm/feature_1/gamma\"}, %arg112: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_1/BatchNorm/feature_1/moving_mean\"}, %arg113: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_1/BatchNorm/feature_1/moving_variance\"}, %arg114: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_1/BatchNorm/feature_2/beta\"}, %arg115: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_1/BatchNorm/feature_2/gamma\"}, %arg116: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_1/BatchNorm/feature_2/moving_mean\"}, %arg117: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_1/BatchNorm/feature_2/moving_variance\"}, %arg118: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_1/BatchNorm/feature_3/beta\"}, %arg119: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_1/BatchNorm/feature_3/gamma\"}, %arg120: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_1/BatchNorm/feature_3/moving_mean\"}, %arg121: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_1/BatchNorm/feature_3/moving_variance\"}, %arg122: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_1/BatchNorm/feature_4/beta\"}, %arg123: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_1/BatchNorm/feature_4/gamma\"}, %arg124: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_1/BatchNorm/feature_4/moving_mean\"}, %arg125: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_1/BatchNorm/feature_4/moving_variance\"}, %arg126: tensor<!tf_type.resource<tensor<3x3x256x256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_1/kernel\"}, %arg127: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_2/BatchNorm/feature_0/beta\"}, %arg128: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_2/BatchNorm/feature_0/gamma\"}, %arg129: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_2/BatchNorm/feature_0/moving_mean\"}, %arg130: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_2/BatchNorm/feature_0/moving_variance\"}, %arg131: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_2/BatchNorm/feature_1/beta\"}, %arg132: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_2/BatchNorm/feature_1/gamma\"}, %arg133: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_2/BatchNorm/feature_1/moving_mean\"}, %arg134: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_2/BatchNorm/feature_1/moving_variance\"}, %arg135: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_2/BatchNorm/feature_2/beta\"}, %arg136: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_2/BatchNorm/feature_2/gamma\"}, %arg137: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_2/BatchNorm/feature_2/moving_mean\"}, %arg138: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_2/BatchNorm/feature_2/moving_variance\"}, %arg139: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_2/BatchNorm/feature_3/beta\"}, %arg140: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_2/BatchNorm/feature_3/gamma\"}, %arg141: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_2/BatchNorm/feature_3/moving_mean\"}, %arg142: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_2/BatchNorm/feature_3/moving_variance\"}, %arg143: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_2/BatchNorm/feature_4/beta\"}, %arg144: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_2/BatchNorm/feature_4/gamma\"}, %arg145: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_2/BatchNorm/feature_4/moving_mean\"}, %arg146: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_2/BatchNorm/feature_4/moving_variance\"}, %arg147: tensor<!tf_type.resource<tensor<3x3x256x256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_2/kernel\"}, %arg148: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_3/BatchNorm/feature_0/beta\"}, %arg149: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_3/BatchNorm/feature_0/gamma\"}, %arg150: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_3/BatchNorm/feature_0/moving_mean\"}, %arg151: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_3/BatchNorm/feature_0/moving_variance\"}, %arg152: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_3/BatchNorm/feature_1/beta\"}, %arg153: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_3/BatchNorm/feature_1/gamma\"}, %arg154: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_3/BatchNorm/feature_1/moving_mean\"}, %arg155: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_3/BatchNorm/feature_1/moving_variance\"}, %arg156: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_3/BatchNorm/feature_2/beta\"}, %arg157: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_3/BatchNorm/feature_2/gamma\"}, %arg158: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_3/BatchNorm/feature_2/moving_mean\"}, %arg159: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_3/BatchNorm/feature_2/moving_variance\"}, %arg160: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_3/BatchNorm/feature_3/beta\"}, %arg161: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_3/BatchNorm/feature_3/gamma\"}, %arg162: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_3/BatchNorm/feature_3/moving_mean\"}, %arg163: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_3/BatchNorm/feature_3/moving_variance\"}, %arg164: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_3/BatchNorm/feature_4/beta\"}, %arg165: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_3/BatchNorm/feature_4/gamma\"}, %arg166: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_3/BatchNorm/feature_4/moving_mean\"}, %arg167: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_3/BatchNorm/feature_4/moving_variance\"}, %arg168: tensor<!tf_type.resource<tensor<3x3x256x256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_3/kernel\"}, %arg169: tensor<!tf_type.resource<tensor<24xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalBoxHead/BoxPredictor/bias\"}, %arg170: tensor<!tf_type.resource<tensor<3x3x256x24xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalBoxHead/BoxPredictor/kernel\"}, %arg171: tensor<!tf_type.resource<tensor<546xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/ClassPredictor/bias\"}, %arg172: tensor<!tf_type.resource<tensor<3x3x256x546xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/ClassPredictor/kernel\"}, %arg173: tensor<!tf_type.resource<tensor<3x3x3x32xf32>>> {tf_saved_model.bound_input = @\"conv1/kernel\"}, %arg174: tensor<!tf_type.resource<tensor<32xf32>>> {tf_saved_model.bound_input = @\"conv1_bn/beta\"}, %arg175: tensor<!tf_type.resource<tensor<32xf32>>> {tf_saved_model.bound_input = @\"conv1_bn/gamma\"}, %arg176: tensor<!tf_type.resource<tensor<32xf32>>> {tf_saved_model.bound_input = @\"conv1_bn/moving_mean\"}, %arg177: tensor<!tf_type.resource<tensor<32xf32>>> {tf_saved_model.bound_input = @\"conv1_bn/moving_variance\"}, %arg178: tensor<!tf_type.resource<tensor<3x3x32x1xf32>>> {tf_saved_model.bound_input = @\"conv_dw_1/depthwise_kernel\"}, %arg179: tensor<!tf_type.resource<tensor<3x3x512x1xf32>>> {tf_saved_model.bound_input = @\"conv_dw_10/depthwise_kernel\"}, %arg180: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_dw_10_bn/beta\"}, %arg181: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_dw_10_bn/gamma\"}, %arg182: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_dw_10_bn/moving_mean\"}, %arg183: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_dw_10_bn/moving_variance\"}, %arg184: tensor<!tf_type.resource<tensor<3x3x512x1xf32>>> {tf_saved_model.bound_input = @\"conv_dw_11/depthwise_kernel\"}, %arg185: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_dw_11_bn/beta\"}, %arg186: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_dw_11_bn/gamma\"}, %arg187: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_dw_11_bn/moving_mean\"}, %arg188: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_dw_11_bn/moving_variance\"}, %arg189: tensor<!tf_type.resource<tensor<3x3x512x1xf32>>> {tf_saved_model.bound_input = @\"conv_dw_12/depthwise_kernel\"}, %arg190: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_dw_12_bn/beta\"}, %arg191: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_dw_12_bn/gamma\"}, %arg192: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_dw_12_bn/moving_mean\"}, %arg193: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_dw_12_bn/moving_variance\"}, %arg194: tensor<!tf_type.resource<tensor<3x3x1024x1xf32>>> {tf_saved_model.bound_input = @\"conv_dw_13/depthwise_kernel\"}, %arg195: tensor<!tf_type.resource<tensor<1024xf32>>> {tf_saved_model.bound_input = @\"conv_dw_13_bn/beta\"}, %arg196: tensor<!tf_type.resource<tensor<1024xf32>>> {tf_saved_model.bound_input = @\"conv_dw_13_bn/gamma\"}, %arg197: tensor<!tf_type.resource<tensor<1024xf32>>> {tf_saved_model.bound_input = @\"conv_dw_13_bn/moving_mean\"}, %arg198: tensor<!tf_type.resource<tensor<1024xf32>>> {tf_saved_model.bound_input = @\"conv_dw_13_bn/moving_variance\"}, %arg199: tensor<!tf_type.resource<tensor<32xf32>>> {tf_saved_model.bound_input = @\"conv_dw_1_bn/beta\"}, %arg200: tensor<!tf_type.resource<tensor<32xf32>>> {tf_saved_model.bound_input = @\"conv_dw_1_bn/gamma\"}, %arg201: tensor<!tf_type.resource<tensor<32xf32>>> {tf_saved_model.bound_input = @\"conv_dw_1_bn/moving_mean\"}, %arg202: tensor<!tf_type.resource<tensor<32xf32>>> {tf_saved_model.bound_input = @\"conv_dw_1_bn/moving_variance\"}, %arg203: tensor<!tf_type.resource<tensor<3x3x64x1xf32>>> {tf_saved_model.bound_input = @\"conv_dw_2/depthwise_kernel\"}, %arg204: tensor<!tf_type.resource<tensor<64xf32>>> {tf_saved_model.bound_input = @\"conv_dw_2_bn/beta\"}, %arg205: tensor<!tf_type.resource<tensor<64xf32>>> {tf_saved_model.bound_input = @\"conv_dw_2_bn/gamma\"}, %arg206: tensor<!tf_type.resource<tensor<64xf32>>> {tf_saved_model.bound_input = @\"conv_dw_2_bn/moving_mean\"}, %arg207: tensor<!tf_type.resource<tensor<64xf32>>> {tf_saved_model.bound_input = @\"conv_dw_2_bn/moving_variance\"}, %arg208: tensor<!tf_type.resource<tensor<3x3x128x1xf32>>> {tf_saved_model.bound_input = @\"conv_dw_3/depthwise_kernel\"}, %arg209: tensor<!tf_type.resource<tensor<128xf32>>> {tf_saved_model.bound_input = @\"conv_dw_3_bn/beta\"}, %arg210: tensor<!tf_type.resource<tensor<128xf32>>> {tf_saved_model.bound_input = @\"conv_dw_3_bn/gamma\"}, %arg211: tensor<!tf_type.resource<tensor<128xf32>>> {tf_saved_model.bound_input = @\"conv_dw_3_bn/moving_mean\"}, %arg212: tensor<!tf_type.resource<tensor<128xf32>>> {tf_saved_model.bound_input = @\"conv_dw_3_bn/moving_variance\"}, %arg213: tensor<!tf_type.resource<tensor<3x3x128x1xf32>>> {tf_saved_model.bound_input = @\"conv_dw_4/depthwise_kernel\"}, %arg214: tensor<!tf_type.resource<tensor<128xf32>>> {tf_saved_model.bound_input = @\"conv_dw_4_bn/beta\"}, %arg215: tensor<!tf_type.resource<tensor<128xf32>>> {tf_saved_model.bound_input = @\"conv_dw_4_bn/gamma\"}, %arg216: tensor<!tf_type.resource<tensor<128xf32>>> {tf_saved_model.bound_input = @\"conv_dw_4_bn/moving_mean\"}, %arg217: tensor<!tf_type.resource<tensor<128xf32>>> {tf_saved_model.bound_input = @\"conv_dw_4_bn/moving_variance\"}, %arg218: tensor<!tf_type.resource<tensor<3x3x256x1xf32>>> {tf_saved_model.bound_input = @\"conv_dw_5/depthwise_kernel\"}, %arg219: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"conv_dw_5_bn/beta\"}, %arg220: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"conv_dw_5_bn/gamma\"}, %arg221: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"conv_dw_5_bn/moving_mean\"}, %arg222: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"conv_dw_5_bn/moving_variance\"}, %arg223: tensor<!tf_type.resource<tensor<3x3x256x1xf32>>> {tf_saved_model.bound_input = @\"conv_dw_6/depthwise_kernel\"}, %arg224: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"conv_dw_6_bn/beta\"}, %arg225: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"conv_dw_6_bn/gamma\"}, %arg226: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"conv_dw_6_bn/moving_mean\"}, %arg227: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"conv_dw_6_bn/moving_variance\"}, %arg228: tensor<!tf_type.resource<tensor<3x3x512x1xf32>>> {tf_saved_model.bound_input = @\"conv_dw_7/depthwise_kernel\"}, %arg229: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_dw_7_bn/beta\"}, %arg230: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_dw_7_bn/gamma\"}, %arg231: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_dw_7_bn/moving_mean\"}, %arg232: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_dw_7_bn/moving_variance\"}, %arg233: tensor<!tf_type.resource<tensor<3x3x512x1xf32>>> {tf_saved_model.bound_input = @\"conv_dw_8/depthwise_kernel\"}, %arg234: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_dw_8_bn/beta\"}, %arg235: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_dw_8_bn/gamma\"}, %arg236: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_dw_8_bn/moving_mean\"}, %arg237: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_dw_8_bn/moving_variance\"}, %arg238: tensor<!tf_type.resource<tensor<3x3x512x1xf32>>> {tf_saved_model.bound_input = @\"conv_dw_9/depthwise_kernel\"}, %arg239: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_dw_9_bn/beta\"}, %arg240: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_dw_9_bn/gamma\"}, %arg241: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_dw_9_bn/moving_mean\"}, %arg242: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_dw_9_bn/moving_variance\"}, %arg243: tensor<!tf_type.resource<tensor<1x1x32x64xf32>>> {tf_saved_model.bound_input = @\"conv_pw_1/kernel\"}, %arg244: tensor<!tf_type.resource<tensor<1x1x512x512xf32>>> {tf_saved_model.bound_input = @\"conv_pw_10/kernel\"}, %arg245: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_pw_10_bn/beta\"}, %arg246: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_pw_10_bn/gamma\"}, %arg247: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_pw_10_bn/moving_mean\"}, %arg248: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_pw_10_bn/moving_variance\"}, %arg249: tensor<!tf_type.resource<tensor<1x1x512x512xf32>>> {tf_saved_model.bound_input = @\"conv_pw_11/kernel\"}, %arg250: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_pw_11_bn/beta\"}, %arg251: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_pw_11_bn/gamma\"}, %arg252: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_pw_11_bn/moving_mean\"}, %arg253: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_pw_11_bn/moving_variance\"}, %arg254: tensor<!tf_type.resource<tensor<1x1x512x1024xf32>>> {tf_saved_model.bound_input = @\"conv_pw_12/kernel\"}, %arg255: tensor<!tf_type.resource<tensor<1024xf32>>> {tf_saved_model.bound_input = @\"conv_pw_12_bn/beta\"}, %arg256: tensor<!tf_type.resource<tensor<1024xf32>>> {tf_saved_model.bound_input = @\"conv_pw_12_bn/gamma\"}, %arg257: tensor<!tf_type.resource<tensor<1024xf32>>> {tf_saved_model.bound_input = @\"conv_pw_12_bn/moving_mean\"}, %arg258: tensor<!tf_type.resource<tensor<1024xf32>>> {tf_saved_model.bound_input = @\"conv_pw_12_bn/moving_variance\"}, %arg259: tensor<!tf_type.resource<tensor<1x1x1024x1024xf32>>> {tf_saved_model.bound_input = @\"conv_pw_13/kernel\"}, %arg260: tensor<!tf_type.resource<tensor<1024xf32>>> {tf_saved_model.bound_input = @\"conv_pw_13_bn/beta\"}, %arg261: tensor<!tf_type.resource<tensor<1024xf32>>> {tf_saved_model.bound_input = @\"conv_pw_13_bn/gamma\"}, %arg262: tensor<!tf_type.resource<tensor<1024xf32>>> {tf_saved_model.bound_input = @\"conv_pw_13_bn/moving_mean\"}, %arg263: tensor<!tf_type.resource<tensor<1024xf32>>> {tf_saved_model.bound_input = @\"conv_pw_13_bn/moving_variance\"}, %arg264: tensor<!tf_type.resource<tensor<64xf32>>> {tf_saved_model.bound_input = @\"conv_pw_1_bn/beta\"}, %arg265: tensor<!tf_type.resource<tensor<64xf32>>> {tf_saved_model.bound_input = @\"conv_pw_1_bn/gamma\"}, %arg266: tensor<!tf_type.resource<tensor<64xf32>>> {tf_saved_model.bound_input = @\"conv_pw_1_bn/moving_mean\"}, %arg267: tensor<!tf_type.resource<tensor<64xf32>>> {tf_saved_model.bound_input = @\"conv_pw_1_bn/moving_variance\"}, %arg268: tensor<!tf_type.resource<tensor<1x1x64x128xf32>>> {tf_saved_model.bound_input = @\"conv_pw_2/kernel\"}, %arg269: tensor<!tf_type.resource<tensor<128xf32>>> {tf_saved_model.bound_input = @\"conv_pw_2_bn/beta\"}, %arg270: tensor<!tf_type.resource<tensor<128xf32>>> {tf_saved_model.bound_input = @\"conv_pw_2_bn/gamma\"}, %arg271: tensor<!tf_type.resource<tensor<128xf32>>> {tf_saved_model.bound_input = @\"conv_pw_2_bn/moving_mean\"}, %arg272: tensor<!tf_type.resource<tensor<128xf32>>> {tf_saved_model.bound_input = @\"conv_pw_2_bn/moving_variance\"}, %arg273: tensor<!tf_type.resource<tensor<1x1x128x128xf32>>> {tf_saved_model.bound_input = @\"conv_pw_3/kernel\"}, %arg274: tensor<!tf_type.resource<tensor<128xf32>>> {tf_saved_model.bound_input = @\"conv_pw_3_bn/beta\"}, %arg275: tensor<!tf_type.resource<tensor<128xf32>>> {tf_saved_model.bound_input = @\"conv_pw_3_bn/gamma\"}, %arg276: tensor<!tf_type.resource<tensor<128xf32>>> {tf_saved_model.bound_input = @\"conv_pw_3_bn/moving_mean\"}, %arg277: tensor<!tf_type.resource<tensor<128xf32>>> {tf_saved_model.bound_input = @\"conv_pw_3_bn/moving_variance\"}, %arg278: tensor<!tf_type.resource<tensor<1x1x128x256xf32>>> {tf_saved_model.bound_input = @\"conv_pw_4/kernel\"}, %arg279: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"conv_pw_4_bn/beta\"}, %arg280: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"conv_pw_4_bn/gamma\"}, %arg281: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"conv_pw_4_bn/moving_mean\"}, %arg282: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"conv_pw_4_bn/moving_variance\"}, %arg283: tensor<!tf_type.resource<tensor<1x1x256x256xf32>>> {tf_saved_model.bound_input = @\"conv_pw_5/kernel\"}, %arg284: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"conv_pw_5_bn/beta\"}, %arg285: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"conv_pw_5_bn/gamma\"}, %arg286: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"conv_pw_5_bn/moving_mean\"}, %arg287: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"conv_pw_5_bn/moving_variance\"}, %arg288: tensor<!tf_type.resource<tensor<1x1x256x512xf32>>> {tf_saved_model.bound_input = @\"conv_pw_6/kernel\"}, %arg289: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_pw_6_bn/beta\"}, %arg290: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_pw_6_bn/gamma\"}, %arg291: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_pw_6_bn/moving_mean\"}, %arg292: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_pw_6_bn/moving_variance\"}, %arg293: tensor<!tf_type.resource<tensor<1x1x512x512xf32>>> {tf_saved_model.bound_input = @\"conv_pw_7/kernel\"}, %arg294: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_pw_7_bn/beta\"}, %arg295: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_pw_7_bn/gamma\"}, %arg296: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_pw_7_bn/moving_mean\"}, %arg297: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_pw_7_bn/moving_variance\"}, %arg298: tensor<!tf_type.resource<tensor<1x1x512x512xf32>>> {tf_saved_model.bound_input = @\"conv_pw_8/kernel\"}, %arg299: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_pw_8_bn/beta\"}, %arg300: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_pw_8_bn/gamma\"}, %arg301: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_pw_8_bn/moving_mean\"}, %arg302: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_pw_8_bn/moving_variance\"}, %arg303: tensor<!tf_type.resource<tensor<1x1x512x512xf32>>> {tf_saved_model.bound_input = @\"conv_pw_9/kernel\"}, %arg304: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_pw_9_bn/beta\"}, %arg305: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_pw_9_bn/gamma\"}, %arg306: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_pw_9_bn/moving_mean\"}, %arg307: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_pw_9_bn/moving_variance\"}, %arg308: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"ssd_mobile_net_v1fpn_keras_feature_extractor/FeatureMaps/top_down/projection_1/bias\"}, %arg309: tensor<!tf_type.resource<tensor<1x1x256x256xf32>>> {tf_saved_model.bound_input = @\"ssd_mobile_net_v1fpn_keras_feature_extractor/FeatureMaps/top_down/projection_1/kernel\"}, %arg310: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"ssd_mobile_net_v1fpn_keras_feature_extractor/FeatureMaps/top_down/projection_2/bias\"}, %arg311: tensor<!tf_type.resource<tensor<1x1x512x256xf32>>> {tf_saved_model.bound_input = @\"ssd_mobile_net_v1fpn_keras_feature_extractor/FeatureMaps/top_down/projection_2/kernel\"}, %arg312: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"ssd_mobile_net_v1fpn_keras_feature_extractor/FeatureMaps/top_down/projection_3/bias\"}, %arg313: tensor<!tf_type.resource<tensor<1x1x1024x256xf32>>> {tf_saved_model.bound_input = @\"ssd_mobile_net_v1fpn_keras_feature_extractor/FeatureMaps/top_down/projection_3/kernel\"}, %arg314: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"ssd_mobile_net_v1fpn_keras_feature_extractor/FeatureMaps/top_down/smoothing_1_batchnorm/beta\"}, %arg315: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"ssd_mobile_net_v1fpn_keras_feature_extractor/FeatureMaps/top_down/smoothing_1_batchnorm/gamma\"}, %arg316: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"ssd_mobile_net_v1fpn_keras_feature_extractor/FeatureMaps/top_down/smoothing_1_batchnorm/moving_mean\"}, %arg317: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"ssd_mobile_net_v1fpn_keras_feature_extractor/FeatureMaps/top_down/smoothing_1_batchnorm/moving_variance\"}, %arg318: tensor<!tf_type.resource<tensor<3x3x256x256xf32>>> {tf_saved_model.bound_input = @\"ssd_mobile_net_v1fpn_keras_feature_extractor/FeatureMaps/top_down/smoothing_1_conv/kernel\"}, %arg319: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"ssd_mobile_net_v1fpn_keras_feature_extractor/FeatureMaps/top_down/smoothing_2_batchnorm/beta\"}, %arg320: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"ssd_mobile_net_v1fpn_keras_feature_extractor/FeatureMaps/top_down/smoothing_2_batchnorm/gamma\"}, %arg321: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"ssd_mobile_net_v1fpn_keras_feature_extractor/FeatureMaps/top_down/smoothing_2_batchnorm/moving_mean\"}, %arg322: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"ssd_mobile_net_v1fpn_keras_feature_extractor/FeatureMaps/top_down/smoothing_2_batchnorm/moving_variance\"}, %arg323: tensor<!tf_type.resource<tensor<3x3x256x256xf32>>> {tf_saved_model.bound_input = @\"ssd_mobile_net_v1fpn_keras_feature_extractor/FeatureMaps/top_down/smoothing_2_conv/kernel\"}, %arg324: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"ssd_mobile_net_v1fpn_keras_feature_extractor/bottom_up_Conv2d_14_batchnorm/beta\"}, %arg325: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"ssd_mobile_net_v1fpn_keras_feature_extractor/bottom_up_Conv2d_14_batchnorm/gamma\"}, %arg326: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"ssd_mobile_net_v1fpn_keras_feature_extractor/bottom_up_Conv2d_14_batchnorm/moving_mean\"}, %arg327: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"ssd_mobile_net_v1fpn_keras_feature_extractor/bottom_up_Conv2d_14_batchnorm/moving_variance\"}, %arg328: tensor<!tf_type.resource<tensor<3x3x256x256xf32>>> {tf_saved_model.bound_input = @\"ssd_mobile_net_v1fpn_keras_feature_extractor/bottom_up_Conv2d_14_conv/kernel\"}, %arg329: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"ssd_mobile_net_v1fpn_keras_feature_extractor/bottom_up_Conv2d_15_batchnorm/beta\"}, %arg330: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"ssd_mobile_net_v1fpn_keras_feature_extractor/bottom_up_Conv2d_15_batchnorm/gamma\"}, %arg331: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"ssd_mobile_net_v1fpn_keras_feature_extractor/bottom_up_Conv2d_15_batchnorm/moving_mean\"}, %arg332: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"ssd_mobile_net_v1fpn_keras_feature_extractor/bottom_up_Conv2d_15_batchnorm/moving_variance\"}, %arg333: tensor<!tf_type.resource<tensor<3x3x256x256xf32>>> {tf_saved_model.bound_input = @\"ssd_mobile_net_v1fpn_keras_feature_extractor/bottom_up_Conv2d_15_conv/kernel\"}) -> (tensor<*xf32> {tf_saved_model.index_path = [\"raw_detection_boxes\"]}, tensor<*xf32> {tf_saved_model.index_path = [\"detection_anchor_indices\"]}, tensor<*xf32> {tf_saved_model.index_path = [\"num_detections\"]}, tensor<*xf32> {tf_saved_model.index_path = [\"raw_detection_scores\"]}, tensor<*xf32> {tf_saved_model.index_path = [\"detection_boxes\"]}, tensor<*xf32> {tf_saved_model.index_path = [\"detection_classes\"]}, tensor<*xf32> {tf_saved_model.index_path = [\"detection_scores\"]}, tensor<*xf32> {tf_saved_model.index_path = [\"detection_multiclass_scores\"]}) attributes {tf.entry_function = {control_outputs = \"\", inputs = \"serving_default_input_tensor:0\", outputs = \"StatefulPartitionedCall:6,StatefulPartitionedCall:0,StatefulPartitionedCall:5,StatefulPartitionedCall:7,StatefulPartitionedCall:1,StatefulPartitionedCall:2,StatefulPartitionedCall:4,StatefulPartitionedCall:3\"}, tf_saved_model.exported_names = [\"serving_default\"]} {\r\n  ^\r\nssd-func.mlir:340:3: error: Emitting more detail about one op that failed to legalize...\r\n  func @serving_default(%arg0: tensor<1x?x?x3xui8> {tf_saved_model.index_path = [\"input_tensor\"]}, %arg1: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_0/BatchNorm/feature_0/beta\"}, %arg2: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_0/BatchNorm/feature_0/gamma\"}, %arg3: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_0/BatchNorm/feature_0/moving_mean\"}, %arg4: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_0/BatchNorm/feature_0/moving_variance\"}, %arg5: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_0/BatchNorm/feature_1/beta\"}, %arg6: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_0/BatchNorm/feature_1/gamma\"}, %arg7: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_0/BatchNorm/feature_1/moving_mean\"}, %arg8: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_0/BatchNorm/feature_1/moving_variance\"}, %arg9: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_0/BatchNorm/feature_2/beta\"}, %arg10: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_0/BatchNorm/feature_2/gamma\"}, %arg11: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_0/BatchNorm/feature_2/moving_mean\"}, %arg12: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_0/BatchNorm/feature_2/moving_variance\"}, %arg13: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_0/BatchNorm/feature_3/beta\"}, %arg14: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_0/BatchNorm/feature_3/gamma\"}, %arg15: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_0/BatchNorm/feature_3/moving_mean\"}, %arg16: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_0/BatchNorm/feature_3/moving_variance\"}, %arg17: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_0/BatchNorm/feature_4/beta\"}, %arg18: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_0/BatchNorm/feature_4/gamma\"}, %arg19: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_0/BatchNorm/feature_4/moving_mean\"}, %arg20: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_0/BatchNorm/feature_4/moving_variance\"}, %arg21: tensor<!tf_type.resource<tensor<3x3x256x256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_0/kernel\"}, %arg22: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_1/BatchNorm/feature_0/beta\"}, %arg23: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_1/BatchNorm/feature_0/gamma\"}, %arg24: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_1/BatchNorm/feature_0/moving_mean\"}, %arg25: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_1/BatchNorm/feature_0/moving_variance\"}, %arg26: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_1/BatchNorm/feature_1/beta\"}, %arg27: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_1/BatchNorm/feature_1/gamma\"}, %arg28: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_1/BatchNorm/feature_1/moving_mean\"}, %arg29: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_1/BatchNorm/feature_1/moving_variance\"}, %arg30: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_1/BatchNorm/feature_2/beta\"}, %arg31: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_1/BatchNorm/feature_2/gamma\"}, %arg32: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_1/BatchNorm/feature_2/moving_mean\"}, %arg33: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_1/BatchNorm/feature_2/moving_variance\"}, %arg34: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_1/BatchNorm/feature_3/beta\"}, %arg35: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_1/BatchNorm/feature_3/gamma\"}, %arg36: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_1/BatchNorm/feature_3/moving_mean\"}, %arg37: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_1/BatchNorm/feature_3/moving_variance\"}, %arg38: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_1/BatchNorm/feature_4/beta\"}, %arg39: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_1/BatchNorm/feature_4/gamma\"}, %arg40: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_1/BatchNorm/feature_4/moving_mean\"}, %arg41: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_1/BatchNorm/feature_4/moving_variance\"}, %arg42: tensor<!tf_type.resource<tensor<3x3x256x256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_1/kernel\"}, %arg43: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_2/BatchNorm/feature_0/beta\"}, %arg44: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_2/BatchNorm/feature_0/gamma\"}, %arg45: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_2/BatchNorm/feature_0/moving_mean\"}, %arg46: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_2/BatchNorm/feature_0/moving_variance\"}, %arg47: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_2/BatchNorm/feature_1/beta\"}, %arg48: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_2/BatchNorm/feature_1/gamma\"}, %arg49: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_2/BatchNorm/feature_1/moving_mean\"}, %arg50: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_2/BatchNorm/feature_1/moving_variance\"}, %arg51: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_2/BatchNorm/feature_2/beta\"}, %arg52: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_2/BatchNorm/feature_2/gamma\"}, %arg53: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_2/BatchNorm/feature_2/moving_mean\"}, %arg54: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_2/BatchNorm/feature_2/moving_variance\"}, %arg55: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_2/BatchNorm/feature_3/beta\"}, %arg56: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_2/BatchNorm/feature_3/gamma\"}, %arg57: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_2/BatchNorm/feature_3/moving_mean\"}, %arg58: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_2/BatchNorm/feature_3/moving_variance\"}, %arg59: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_2/BatchNorm/feature_4/beta\"}, %arg60: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_2/BatchNorm/feature_4/gamma\"}, %arg61: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_2/BatchNorm/feature_4/moving_mean\"}, %arg62: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_2/BatchNorm/feature_4/moving_variance\"}, %arg63: tensor<!tf_type.resource<tensor<3x3x256x256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_2/kernel\"}, %arg64: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_3/BatchNorm/feature_0/beta\"}, %arg65: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_3/BatchNorm/feature_0/gamma\"}, %arg66: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_3/BatchNorm/feature_0/moving_mean\"}, %arg67: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_3/BatchNorm/feature_0/moving_variance\"}, %arg68: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_3/BatchNorm/feature_1/beta\"}, %arg69: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_3/BatchNorm/feature_1/gamma\"}, %arg70: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_3/BatchNorm/feature_1/moving_mean\"}, %arg71: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_3/BatchNorm/feature_1/moving_variance\"}, %arg72: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_3/BatchNorm/feature_2/beta\"}, %arg73: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_3/BatchNorm/feature_2/gamma\"}, %arg74: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_3/BatchNorm/feature_2/moving_mean\"}, %arg75: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_3/BatchNorm/feature_2/moving_variance\"}, %arg76: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_3/BatchNorm/feature_3/beta\"}, %arg77: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_3/BatchNorm/feature_3/gamma\"}, %arg78: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_3/BatchNorm/feature_3/moving_mean\"}, %arg79: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_3/BatchNorm/feature_3/moving_variance\"}, %arg80: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_3/BatchNorm/feature_4/beta\"}, %arg81: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_3/BatchNorm/feature_4/gamma\"}, %arg82: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_3/BatchNorm/feature_4/moving_mean\"}, %arg83: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_3/BatchNorm/feature_4/moving_variance\"}, %arg84: tensor<!tf_type.resource<tensor<3x3x256x256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_3/kernel\"}, %arg85: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_0/BatchNorm/feature_0/beta\"}, %arg86: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_0/BatchNorm/feature_0/gamma\"}, %arg87: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_0/BatchNorm/feature_0/moving_mean\"}, %arg88: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_0/BatchNorm/feature_0/moving_variance\"}, %arg89: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_0/BatchNorm/feature_1/beta\"}, %arg90: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_0/BatchNorm/feature_1/gamma\"}, %arg91: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_0/BatchNorm/feature_1/moving_mean\"}, %arg92: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_0/BatchNorm/feature_1/moving_variance\"}, %arg93: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_0/BatchNorm/feature_2/beta\"}, %arg94: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_0/BatchNorm/feature_2/gamma\"}, %arg95: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_0/BatchNorm/feature_2/moving_mean\"}, %arg96: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_0/BatchNorm/feature_2/moving_variance\"}, %arg97: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_0/BatchNorm/feature_3/beta\"}, %arg98: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_0/BatchNorm/feature_3/gamma\"}, %arg99: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_0/BatchNorm/feature_3/moving_mean\"}, %arg100: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_0/BatchNorm/feature_3/moving_variance\"}, %arg101: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_0/BatchNorm/feature_4/beta\"}, %arg102: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_0/BatchNorm/feature_4/gamma\"}, %arg103: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_0/BatchNorm/feature_4/moving_mean\"}, %arg104: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_0/BatchNorm/feature_4/moving_variance\"}, %arg105: tensor<!tf_type.resource<tensor<3x3x256x256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_0/kernel\"}, %arg106: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_1/BatchNorm/feature_0/beta\"}, %arg107: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_1/BatchNorm/feature_0/gamma\"}, %arg108: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_1/BatchNorm/feature_0/moving_mean\"}, %arg109: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_1/BatchNorm/feature_0/moving_variance\"}, %arg110: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_1/BatchNorm/feature_1/beta\"}, %arg111: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_1/BatchNorm/feature_1/gamma\"}, %arg112: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_1/BatchNorm/feature_1/moving_mean\"}, %arg113: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_1/BatchNorm/feature_1/moving_variance\"}, %arg114: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_1/BatchNorm/feature_2/beta\"}, %arg115: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_1/BatchNorm/feature_2/gamma\"}, %arg116: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_1/BatchNorm/feature_2/moving_mean\"}, %arg117: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_1/BatchNorm/feature_2/moving_variance\"}, %arg118: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_1/BatchNorm/feature_3/beta\"}, %arg119: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_1/BatchNorm/feature_3/gamma\"}, %arg120: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_1/BatchNorm/feature_3/moving_mean\"}, %arg121: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_1/BatchNorm/feature_3/moving_variance\"}, %arg122: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_1/BatchNorm/feature_4/beta\"}, %arg123: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_1/BatchNorm/feature_4/gamma\"}, %arg124: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_1/BatchNorm/feature_4/moving_mean\"}, %arg125: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_1/BatchNorm/feature_4/moving_variance\"}, %arg126: tensor<!tf_type.resource<tensor<3x3x256x256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_1/kernel\"}, %arg127: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_2/BatchNorm/feature_0/beta\"}, %arg128: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_2/BatchNorm/feature_0/gamma\"}, %arg129: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_2/BatchNorm/feature_0/moving_mean\"}, %arg130: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_2/BatchNorm/feature_0/moving_variance\"}, %arg131: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_2/BatchNorm/feature_1/beta\"}, %arg132: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_2/BatchNorm/feature_1/gamma\"}, %arg133: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_2/BatchNorm/feature_1/moving_mean\"}, %arg134: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_2/BatchNorm/feature_1/moving_variance\"}, %arg135: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_2/BatchNorm/feature_2/beta\"}, %arg136: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_2/BatchNorm/feature_2/gamma\"}, %arg137: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_2/BatchNorm/feature_2/moving_mean\"}, %arg138: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_2/BatchNorm/feature_2/moving_variance\"}, %arg139: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_2/BatchNorm/feature_3/beta\"}, %arg140: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_2/BatchNorm/feature_3/gamma\"}, %arg141: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_2/BatchNorm/feature_3/moving_mean\"}, %arg142: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_2/BatchNorm/feature_3/moving_variance\"}, %arg143: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_2/BatchNorm/feature_4/beta\"}, %arg144: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_2/BatchNorm/feature_4/gamma\"}, %arg145: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_2/BatchNorm/feature_4/moving_mean\"}, %arg146: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_2/BatchNorm/feature_4/moving_variance\"}, %arg147: tensor<!tf_type.resource<tensor<3x3x256x256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_2/kernel\"}, %arg148: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_3/BatchNorm/feature_0/beta\"}, %arg149: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_3/BatchNorm/feature_0/gamma\"}, %arg150: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_3/BatchNorm/feature_0/moving_mean\"}, %arg151: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_3/BatchNorm/feature_0/moving_variance\"}, %arg152: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_3/BatchNorm/feature_1/beta\"}, %arg153: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_3/BatchNorm/feature_1/gamma\"}, %arg154: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_3/BatchNorm/feature_1/moving_mean\"}, %arg155: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_3/BatchNorm/feature_1/moving_variance\"}, %arg156: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_3/BatchNorm/feature_2/beta\"}, %arg157: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_3/BatchNorm/feature_2/gamma\"}, %arg158: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_3/BatchNorm/feature_2/moving_mean\"}, %arg159: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_3/BatchNorm/feature_2/moving_variance\"}, %arg160: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_3/BatchNorm/feature_3/beta\"}, %arg161: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_3/BatchNorm/feature_3/gamma\"}, %arg162: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_3/BatchNorm/feature_3/moving_mean\"}, %arg163: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_3/BatchNorm/feature_3/moving_variance\"}, %arg164: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_3/BatchNorm/feature_4/beta\"}, %arg165: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_3/BatchNorm/feature_4/gamma\"}, %arg166: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_3/BatchNorm/feature_4/moving_mean\"}, %arg167: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_3/BatchNorm/feature_4/moving_variance\"}, %arg168: tensor<!tf_type.resource<tensor<3x3x256x256xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_3/kernel\"}, %arg169: tensor<!tf_type.resource<tensor<24xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalBoxHead/BoxPredictor/bias\"}, %arg170: tensor<!tf_type.resource<tensor<3x3x256x24xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalBoxHead/BoxPredictor/kernel\"}, %arg171: tensor<!tf_type.resource<tensor<546xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/ClassPredictor/bias\"}, %arg172: tensor<!tf_type.resource<tensor<3x3x256x546xf32>>> {tf_saved_model.bound_input = @\"WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/ClassPredictor/kernel\"}, %arg173: tensor<!tf_type.resource<tensor<3x3x3x32xf32>>> {tf_saved_model.bound_input = @\"conv1/kernel\"}, %arg174: tensor<!tf_type.resource<tensor<32xf32>>> {tf_saved_model.bound_input = @\"conv1_bn/beta\"}, %arg175: tensor<!tf_type.resource<tensor<32xf32>>> {tf_saved_model.bound_input = @\"conv1_bn/gamma\"}, %arg176: tensor<!tf_type.resource<tensor<32xf32>>> {tf_saved_model.bound_input = @\"conv1_bn/moving_mean\"}, %arg177: tensor<!tf_type.resource<tensor<32xf32>>> {tf_saved_model.bound_input = @\"conv1_bn/moving_variance\"}, %arg178: tensor<!tf_type.resource<tensor<3x3x32x1xf32>>> {tf_saved_model.bound_input = @\"conv_dw_1/depthwise_kernel\"}, %arg179: tensor<!tf_type.resource<tensor<3x3x512x1xf32>>> {tf_saved_model.bound_input = @\"conv_dw_10/depthwise_kernel\"}, %arg180: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_dw_10_bn/beta\"}, %arg181: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_dw_10_bn/gamma\"}, %arg182: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_dw_10_bn/moving_mean\"}, %arg183: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_dw_10_bn/moving_variance\"}, %arg184: tensor<!tf_type.resource<tensor<3x3x512x1xf32>>> {tf_saved_model.bound_input = @\"conv_dw_11/depthwise_kernel\"}, %arg185: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_dw_11_bn/beta\"}, %arg186: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_dw_11_bn/gamma\"}, %arg187: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_dw_11_bn/moving_mean\"}, %arg188: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_dw_11_bn/moving_variance\"}, %arg189: tensor<!tf_type.resource<tensor<3x3x512x1xf32>>> {tf_saved_model.bound_input = @\"conv_dw_12/depthwise_kernel\"}, %arg190: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_dw_12_bn/beta\"}, %arg191: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_dw_12_bn/gamma\"}, %arg192: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_dw_12_bn/moving_mean\"}, %arg193: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_dw_12_bn/moving_variance\"}, %arg194: tensor<!tf_type.resource<tensor<3x3x1024x1xf32>>> {tf_saved_model.bound_input = @\"conv_dw_13/depthwise_kernel\"}, %arg195: tensor<!tf_type.resource<tensor<1024xf32>>> {tf_saved_model.bound_input = @\"conv_dw_13_bn/beta\"}, %arg196: tensor<!tf_type.resource<tensor<1024xf32>>> {tf_saved_model.bound_input = @\"conv_dw_13_bn/gamma\"}, %arg197: tensor<!tf_type.resource<tensor<1024xf32>>> {tf_saved_model.bound_input = @\"conv_dw_13_bn/moving_mean\"}, %arg198: tensor<!tf_type.resource<tensor<1024xf32>>> {tf_saved_model.bound_input = @\"conv_dw_13_bn/moving_variance\"}, %arg199: tensor<!tf_type.resource<tensor<32xf32>>> {tf_saved_model.bound_input = @\"conv_dw_1_bn/beta\"}, %arg200: tensor<!tf_type.resource<tensor<32xf32>>> {tf_saved_model.bound_input = @\"conv_dw_1_bn/gamma\"}, %arg201: tensor<!tf_type.resource<tensor<32xf32>>> {tf_saved_model.bound_input = @\"conv_dw_1_bn/moving_mean\"}, %arg202: tensor<!tf_type.resource<tensor<32xf32>>> {tf_saved_model.bound_input = @\"conv_dw_1_bn/moving_variance\"}, %arg203: tensor<!tf_type.resource<tensor<3x3x64x1xf32>>> {tf_saved_model.bound_input = @\"conv_dw_2/depthwise_kernel\"}, %arg204: tensor<!tf_type.resource<tensor<64xf32>>> {tf_saved_model.bound_input = @\"conv_dw_2_bn/beta\"}, %arg205: tensor<!tf_type.resource<tensor<64xf32>>> {tf_saved_model.bound_input = @\"conv_dw_2_bn/gamma\"}, %arg206: tensor<!tf_type.resource<tensor<64xf32>>> {tf_saved_model.bound_input = @\"conv_dw_2_bn/moving_mean\"}, %arg207: tensor<!tf_type.resource<tensor<64xf32>>> {tf_saved_model.bound_input = @\"conv_dw_2_bn/moving_variance\"}, %arg208: tensor<!tf_type.resource<tensor<3x3x128x1xf32>>> {tf_saved_model.bound_input = @\"conv_dw_3/depthwise_kernel\"}, %arg209: tensor<!tf_type.resource<tensor<128xf32>>> {tf_saved_model.bound_input = @\"conv_dw_3_bn/beta\"}, %arg210: tensor<!tf_type.resource<tensor<128xf32>>> {tf_saved_model.bound_input = @\"conv_dw_3_bn/gamma\"}, %arg211: tensor<!tf_type.resource<tensor<128xf32>>> {tf_saved_model.bound_input = @\"conv_dw_3_bn/moving_mean\"}, %arg212: tensor<!tf_type.resource<tensor<128xf32>>> {tf_saved_model.bound_input = @\"conv_dw_3_bn/moving_variance\"}, %arg213: tensor<!tf_type.resource<tensor<3x3x128x1xf32>>> {tf_saved_model.bound_input = @\"conv_dw_4/depthwise_kernel\"}, %arg214: tensor<!tf_type.resource<tensor<128xf32>>> {tf_saved_model.bound_input = @\"conv_dw_4_bn/beta\"}, %arg215: tensor<!tf_type.resource<tensor<128xf32>>> {tf_saved_model.bound_input = @\"conv_dw_4_bn/gamma\"}, %arg216: tensor<!tf_type.resource<tensor<128xf32>>> {tf_saved_model.bound_input = @\"conv_dw_4_bn/moving_mean\"}, %arg217: tensor<!tf_type.resource<tensor<128xf32>>> {tf_saved_model.bound_input = @\"conv_dw_4_bn/moving_variance\"}, %arg218: tensor<!tf_type.resource<tensor<3x3x256x1xf32>>> {tf_saved_model.bound_input = @\"conv_dw_5/depthwise_kernel\"}, %arg219: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"conv_dw_5_bn/beta\"}, %arg220: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"conv_dw_5_bn/gamma\"}, %arg221: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"conv_dw_5_bn/moving_mean\"}, %arg222: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"conv_dw_5_bn/moving_variance\"}, %arg223: tensor<!tf_type.resource<tensor<3x3x256x1xf32>>> {tf_saved_model.bound_input = @\"conv_dw_6/depthwise_kernel\"}, %arg224: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"conv_dw_6_bn/beta\"}, %arg225: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"conv_dw_6_bn/gamma\"}, %arg226: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"conv_dw_6_bn/moving_mean\"}, %arg227: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"conv_dw_6_bn/moving_variance\"}, %arg228: tensor<!tf_type.resource<tensor<3x3x512x1xf32>>> {tf_saved_model.bound_input = @\"conv_dw_7/depthwise_kernel\"}, %arg229: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_dw_7_bn/beta\"}, %arg230: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_dw_7_bn/gamma\"}, %arg231: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_dw_7_bn/moving_mean\"}, %arg232: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_dw_7_bn/moving_variance\"}, %arg233: tensor<!tf_type.resource<tensor<3x3x512x1xf32>>> {tf_saved_model.bound_input = @\"conv_dw_8/depthwise_kernel\"}, %arg234: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_dw_8_bn/beta\"}, %arg235: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_dw_8_bn/gamma\"}, %arg236: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_dw_8_bn/moving_mean\"}, %arg237: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_dw_8_bn/moving_variance\"}, %arg238: tensor<!tf_type.resource<tensor<3x3x512x1xf32>>> {tf_saved_model.bound_input = @\"conv_dw_9/depthwise_kernel\"}, %arg239: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_dw_9_bn/beta\"}, %arg240: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_dw_9_bn/gamma\"}, %arg241: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_dw_9_bn/moving_mean\"}, %arg242: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_dw_9_bn/moving_variance\"}, %arg243: tensor<!tf_type.resource<tensor<1x1x32x64xf32>>> {tf_saved_model.bound_input = @\"conv_pw_1/kernel\"}, %arg244: tensor<!tf_type.resource<tensor<1x1x512x512xf32>>> {tf_saved_model.bound_input = @\"conv_pw_10/kernel\"}, %arg245: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_pw_10_bn/beta\"}, %arg246: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_pw_10_bn/gamma\"}, %arg247: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_pw_10_bn/moving_mean\"}, %arg248: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_pw_10_bn/moving_variance\"}, %arg249: tensor<!tf_type.resource<tensor<1x1x512x512xf32>>> {tf_saved_model.bound_input = @\"conv_pw_11/kernel\"}, %arg250: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_pw_11_bn/beta\"}, %arg251: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_pw_11_bn/gamma\"}, %arg252: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_pw_11_bn/moving_mean\"}, %arg253: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_pw_11_bn/moving_variance\"}, %arg254: tensor<!tf_type.resource<tensor<1x1x512x1024xf32>>> {tf_saved_model.bound_input = @\"conv_pw_12/kernel\"}, %arg255: tensor<!tf_type.resource<tensor<1024xf32>>> {tf_saved_model.bound_input = @\"conv_pw_12_bn/beta\"}, %arg256: tensor<!tf_type.resource<tensor<1024xf32>>> {tf_saved_model.bound_input = @\"conv_pw_12_bn/gamma\"}, %arg257: tensor<!tf_type.resource<tensor<1024xf32>>> {tf_saved_model.bound_input = @\"conv_pw_12_bn/moving_mean\"}, %arg258: tensor<!tf_type.resource<tensor<1024xf32>>> {tf_saved_model.bound_input = @\"conv_pw_12_bn/moving_variance\"}, %arg259: tensor<!tf_type.resource<tensor<1x1x1024x1024xf32>>> {tf_saved_model.bound_input = @\"conv_pw_13/kernel\"}, %arg260: tensor<!tf_type.resource<tensor<1024xf32>>> {tf_saved_model.bound_input = @\"conv_pw_13_bn/beta\"}, %arg261: tensor<!tf_type.resource<tensor<1024xf32>>> {tf_saved_model.bound_input = @\"conv_pw_13_bn/gamma\"}, %arg262: tensor<!tf_type.resource<tensor<1024xf32>>> {tf_saved_model.bound_input = @\"conv_pw_13_bn/moving_mean\"}, %arg263: tensor<!tf_type.resource<tensor<1024xf32>>> {tf_saved_model.bound_input = @\"conv_pw_13_bn/moving_variance\"}, %arg264: tensor<!tf_type.resource<tensor<64xf32>>> {tf_saved_model.bound_input = @\"conv_pw_1_bn/beta\"}, %arg265: tensor<!tf_type.resource<tensor<64xf32>>> {tf_saved_model.bound_input = @\"conv_pw_1_bn/gamma\"}, %arg266: tensor<!tf_type.resource<tensor<64xf32>>> {tf_saved_model.bound_input = @\"conv_pw_1_bn/moving_mean\"}, %arg267: tensor<!tf_type.resource<tensor<64xf32>>> {tf_saved_model.bound_input = @\"conv_pw_1_bn/moving_variance\"}, %arg268: tensor<!tf_type.resource<tensor<1x1x64x128xf32>>> {tf_saved_model.bound_input = @\"conv_pw_2/kernel\"}, %arg269: tensor<!tf_type.resource<tensor<128xf32>>> {tf_saved_model.bound_input = @\"conv_pw_2_bn/beta\"}, %arg270: tensor<!tf_type.resource<tensor<128xf32>>> {tf_saved_model.bound_input = @\"conv_pw_2_bn/gamma\"}, %arg271: tensor<!tf_type.resource<tensor<128xf32>>> {tf_saved_model.bound_input = @\"conv_pw_2_bn/moving_mean\"}, %arg272: tensor<!tf_type.resource<tensor<128xf32>>> {tf_saved_model.bound_input = @\"conv_pw_2_bn/moving_variance\"}, %arg273: tensor<!tf_type.resource<tensor<1x1x128x128xf32>>> {tf_saved_model.bound_input = @\"conv_pw_3/kernel\"}, %arg274: tensor<!tf_type.resource<tensor<128xf32>>> {tf_saved_model.bound_input = @\"conv_pw_3_bn/beta\"}, %arg275: tensor<!tf_type.resource<tensor<128xf32>>> {tf_saved_model.bound_input = @\"conv_pw_3_bn/gamma\"}, %arg276: tensor<!tf_type.resource<tensor<128xf32>>> {tf_saved_model.bound_input = @\"conv_pw_3_bn/moving_mean\"}, %arg277: tensor<!tf_type.resource<tensor<128xf32>>> {tf_saved_model.bound_input = @\"conv_pw_3_bn/moving_variance\"}, %arg278: tensor<!tf_type.resource<tensor<1x1x128x256xf32>>> {tf_saved_model.bound_input = @\"conv_pw_4/kernel\"}, %arg279: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"conv_pw_4_bn/beta\"}, %arg280: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"conv_pw_4_bn/gamma\"}, %arg281: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"conv_pw_4_bn/moving_mean\"}, %arg282: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"conv_pw_4_bn/moving_variance\"}, %arg283: tensor<!tf_type.resource<tensor<1x1x256x256xf32>>> {tf_saved_model.bound_input = @\"conv_pw_5/kernel\"}, %arg284: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"conv_pw_5_bn/beta\"}, %arg285: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"conv_pw_5_bn/gamma\"}, %arg286: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"conv_pw_5_bn/moving_mean\"}, %arg287: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"conv_pw_5_bn/moving_variance\"}, %arg288: tensor<!tf_type.resource<tensor<1x1x256x512xf32>>> {tf_saved_model.bound_input = @\"conv_pw_6/kernel\"}, %arg289: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_pw_6_bn/beta\"}, %arg290: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_pw_6_bn/gamma\"}, %arg291: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_pw_6_bn/moving_mean\"}, %arg292: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_pw_6_bn/moving_variance\"}, %arg293: tensor<!tf_type.resource<tensor<1x1x512x512xf32>>> {tf_saved_model.bound_input = @\"conv_pw_7/kernel\"}, %arg294: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_pw_7_bn/beta\"}, %arg295: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_pw_7_bn/gamma\"}, %arg296: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_pw_7_bn/moving_mean\"}, %arg297: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_pw_7_bn/moving_variance\"}, %arg298: tensor<!tf_type.resource<tensor<1x1x512x512xf32>>> {tf_saved_model.bound_input = @\"conv_pw_8/kernel\"}, %arg299: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_pw_8_bn/beta\"}, %arg300: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_pw_8_bn/gamma\"}, %arg301: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_pw_8_bn/moving_mean\"}, %arg302: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_pw_8_bn/moving_variance\"}, %arg303: tensor<!tf_type.resource<tensor<1x1x512x512xf32>>> {tf_saved_model.bound_input = @\"conv_pw_9/kernel\"}, %arg304: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_pw_9_bn/beta\"}, %arg305: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_pw_9_bn/gamma\"}, %arg306: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_pw_9_bn/moving_mean\"}, %arg307: tensor<!tf_type.resource<tensor<512xf32>>> {tf_saved_model.bound_input = @\"conv_pw_9_bn/moving_variance\"}, %arg308: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"ssd_mobile_net_v1fpn_keras_feature_extractor/FeatureMaps/top_down/projection_1/bias\"}, %arg309: tensor<!tf_type.resource<tensor<1x1x256x256xf32>>> {tf_saved_model.bound_input = @\"ssd_mobile_net_v1fpn_keras_feature_extractor/FeatureMaps/top_down/projection_1/kernel\"}, %arg310: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"ssd_mobile_net_v1fpn_keras_feature_extractor/FeatureMaps/top_down/projection_2/bias\"}, %arg311: tensor<!tf_type.resource<tensor<1x1x512x256xf32>>> {tf_saved_model.bound_input = @\"ssd_mobile_net_v1fpn_keras_feature_extractor/FeatureMaps/top_down/projection_2/kernel\"}, %arg312: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"ssd_mobile_net_v1fpn_keras_feature_extractor/FeatureMaps/top_down/projection_3/bias\"}, %arg313: tensor<!tf_type.resource<tensor<1x1x1024x256xf32>>> {tf_saved_model.bound_input = @\"ssd_mobile_net_v1fpn_keras_feature_extractor/FeatureMaps/top_down/projection_3/kernel\"}, %arg314: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"ssd_mobile_net_v1fpn_keras_feature_extractor/FeatureMaps/top_down/smoothing_1_batchnorm/beta\"}, %arg315: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"ssd_mobile_net_v1fpn_keras_feature_extractor/FeatureMaps/top_down/smoothing_1_batchnorm/gamma\"}, %arg316: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"ssd_mobile_net_v1fpn_keras_feature_extractor/FeatureMaps/top_down/smoothing_1_batchnorm/moving_mean\"}, %arg317: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"ssd_mobile_net_v1fpn_keras_feature_extractor/FeatureMaps/top_down/smoothing_1_batchnorm/moving_variance\"}, %arg318: tensor<!tf_type.resource<tensor<3x3x256x256xf32>>> {tf_saved_model.bound_input = @\"ssd_mobile_net_v1fpn_keras_feature_extractor/FeatureMaps/top_down/smoothing_1_conv/kernel\"}, %arg319: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"ssd_mobile_net_v1fpn_keras_feature_extractor/FeatureMaps/top_down/smoothing_2_batchnorm/beta\"}, %arg320: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"ssd_mobile_net_v1fpn_keras_feature_extractor/FeatureMaps/top_down/smoothing_2_batchnorm/gamma\"}, %arg321: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"ssd_mobile_net_v1fpn_keras_feature_extractor/FeatureMaps/top_down/smoothing_2_batchnorm/moving_mean\"}, %arg322: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"ssd_mobile_net_v1fpn_keras_feature_extractor/FeatureMaps/top_down/smoothing_2_batchnorm/moving_variance\"}, %arg323: tensor<!tf_type.resource<tensor<3x3x256x256xf32>>> {tf_saved_model.bound_input = @\"ssd_mobile_net_v1fpn_keras_feature_extractor/FeatureMaps/top_down/smoothing_2_conv/kernel\"}, %arg324: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"ssd_mobile_net_v1fpn_keras_feature_extractor/bottom_up_Conv2d_14_batchnorm/beta\"}, %arg325: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"ssd_mobile_net_v1fpn_keras_feature_extractor/bottom_up_Conv2d_14_batchnorm/gamma\"}, %arg326: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"ssd_mobile_net_v1fpn_keras_feature_extractor/bottom_up_Conv2d_14_batchnorm/moving_mean\"}, %arg327: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"ssd_mobile_net_v1fpn_keras_feature_extractor/bottom_up_Conv2d_14_batchnorm/moving_variance\"}, %arg328: tensor<!tf_type.resource<tensor<3x3x256x256xf32>>> {tf_saved_model.bound_input = @\"ssd_mobile_net_v1fpn_keras_feature_extractor/bottom_up_Conv2d_14_conv/kernel\"}, %arg329: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"ssd_mobile_net_v1fpn_keras_feature_extractor/bottom_up_Conv2d_15_batchnorm/beta\"}, %arg330: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"ssd_mobile_net_v1fpn_keras_feature_extractor/bottom_up_Conv2d_15_batchnorm/gamma\"}, %arg331: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"ssd_mobile_net_v1fpn_keras_feature_extractor/bottom_up_Conv2d_15_batchnorm/moving_mean\"}, %arg332: tensor<!tf_type.resource<tensor<256xf32>>> {tf_saved_model.bound_input = @\"ssd_mobile_net_v1fpn_keras_feature_extractor/bottom_up_Conv2d_15_batchnorm/moving_variance\"}, %arg333: tensor<!tf_type.resource<tensor<3x3x256x256xf32>>> {tf_saved_model.bound_input = @\"ssd_mobile_net_v1fpn_keras_feature_extractor/bottom_up_Conv2d_15_conv/kernel\"}) -> (tensor<*xf32> {tf_saved_model.index_path = [\"raw_detection_boxes\"]}, tensor<*xf32> {tf_saved_model.index_path = [\"detection_anchor_indices\"]}, tensor<*xf32> {tf_saved_model.index_path = [\"num_detections\"]}, tensor<*xf32> {tf_saved_model.index_path = [\"raw_detection_scores\"]}, tensor<*xf32> {tf_saved_model.index_path = [\"detection_boxes\"]}, tensor<*xf32> {tf_saved_model.index_path = [\"detection_classes\"]}, tensor<*xf32> {tf_saved_model.index_path = [\"detection_scores\"]}, tensor<*xf32> {tf_saved_model.index_path = [\"detection_multiclass_scores\"]}) attributes {tf.entry_function = {control_outputs = \"\", inputs = \"serving_default_input_tensor:0\", outputs = \"StatefulPartitionedCall:6,StatefulPartitionedCall:0,StatefulPartitionedCall:5,StatefulPartitionedCall:7,StatefulPartitionedCall:1,StatefulPartitionedCall:2,StatefulPartitionedCall:4,StatefulPartitionedCall:3\"}, tf_saved_model.exported_names = [\"serving_default\"]} {\r\n  ^\r\nssd-func.mlir:6156:74: error: 'tf.NonMaxSuppressionV5' op is not legalizable\r\n    %selected_indices_4039, %selected_scores_4040, %valid_outputs_4041 = \"tf.NonMaxSuppressionV5\"(%1931, %2111, %773, %cst_1735, %cst_1736, %cst_1737) {device = \"\", pad_to_max_output_size = false} : (tensor<*xf32>, tensor<*xf32>, tensor<*xi32>, tensor<f32>, tensor<f32>, tensor<f32>) -> (tensor<*xi32>, tensor<*xf32>, tensor<*xi32>)\r\n                                                                         ^\r\nssd-func.mlir:356:12: note: called from\r\n    %0:8 = \"tf.StatefulPartitionedCall\"(%arg0, %arg173, %arg175, %arg174, %arg176, %arg177, %arg178, %arg200, %arg199, %arg201, %arg202, %arg243, %arg265, %arg264, %arg266, %arg267, %arg203, %arg205, %arg204, %arg206, %arg207, %arg268, %arg270, %arg269, %arg271, %arg272, %arg208, %arg210, %arg209, %arg211, %arg212, %arg273, %arg275, %arg274, %arg276, %arg277, %arg213, %arg215, %arg214, %arg216, %arg217, %arg278, %arg280, %arg279, %arg281, %arg282, %arg218, %arg220, %arg219, %arg221, %arg222, %arg283, %arg285, %arg284, %arg286, %arg287, %arg223, %arg225, %arg224, %arg226, %arg227, %arg288, %arg290, %arg289, %arg291, %arg292, %arg228, %arg230, %arg229, %arg231, %arg232, %arg293, %arg295, %arg294, %arg296, %arg297, %arg233, %arg235, %arg234, %arg236, %arg237, %arg298, %arg300, %arg299, %arg301, %arg302, %arg238, %arg240, %arg239, %arg241, %arg242, %arg303, %arg305, %arg304, %arg306, %arg307, %arg179, %arg181, %arg180, %arg182, %arg183, %arg244, %arg246, %arg245, %arg247, %arg248, %arg184, %arg186, %arg185, %arg187, %arg188, %arg249, %arg251, %arg250, %arg252, %arg253, %arg189, %arg191, %arg190, %arg192, %arg193, %arg254, %arg256, %arg255, %arg257, %arg258, %arg194, %arg196, %arg195, %arg197, %arg198, %arg259, %arg261, %arg260, %arg262, %arg263, %arg313, %arg312, %arg311, %arg310, %arg323, %arg320, %arg319, %arg321, %arg322, %arg309, %arg308, %arg318, %arg315, %arg314, %arg316, %arg317, %arg328, %arg325, %arg324, %arg326, %arg327, %arg333, %arg330, %arg329, %arg331, %arg332, %cst, %cst_0, %cst_6, %cst_7, %cst_8, %cst_9, %cst_10, %cst_11, %cst_12, %cst_13, %cst_1, %cst_2, %cst_3, %cst_4, %cst_5, %arg21, %arg2, %arg1, %arg3, %arg4, %arg42, %arg23, %arg22, %arg24, %arg25, %arg63, %arg44, %arg43, %arg45, %arg46, %arg84, %arg65, %arg64, %arg66, %arg67, %arg170, %arg169, %arg105, %arg86, %arg85, %arg87, %arg88, %arg126, %arg107, %arg106, %arg108, %arg109, %arg147, %arg128, %arg127, %arg129, %arg130, %arg168, %arg149, %arg148, %arg150, %arg151, %arg172, %arg171, %arg6, %arg5, %arg7, %arg8, %arg27, %arg26, %arg28, %arg29, %arg48, %arg47, %arg49, %arg50, %arg69, %arg68, %arg70, %arg71, %arg90, %arg89, %arg91, %arg92, %arg111, %arg110, %arg112, %arg113, %arg132, %arg131, %arg133, %arg134, %arg153, %arg152, %arg154, %arg155, %arg10, %arg9, %arg11, %arg12, %arg31, %arg30, %arg32, %arg33, %arg52, %arg51, %arg53, %arg54, %arg73, %arg72, %arg74, %arg75, %arg94, %arg93, %arg95, %arg96, %arg115, %arg114, %arg116, %arg117, %arg136, %arg135, %arg137, %arg138, %arg157, %arg156, %arg158, %arg159, %arg14, %arg13, %arg15, %arg16, %arg35, %arg34, %arg36, %arg37, %arg56, %arg55, %arg57, %arg58, %arg77, %arg76, %arg78, %arg79, %arg98, %arg97, %arg99, %arg100, %arg119, %arg118, %arg120, %arg121, %arg140, %arg139, %arg141, %arg142, %arg161, %arg160, %arg162, %arg163, %arg18, %arg17, %arg19, %arg20, %arg39, %arg38, %arg40, %arg41, %arg60, %arg59, %arg61, %arg62, %arg81, %arg80, %arg82, %arg83, %arg102, %arg101, %arg103, %arg104, %arg123, %arg122, %arg124, %arg125, %arg144, %arg143, %arg145, %arg146, %arg165, %arg164, %arg166, %arg167) {_collective_manager_ids = [], _read_only_resource_inputs = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348], config = \"\", config_proto = \"\\0A\\07\\0A\\03CPU\\10\\01\\0A\\07\\0A\\03GPU\\10\\002\\02J\\008\\01\\82\\01\\00\", device = \"\", executor_type = \"\", f = @__inference_signature_wrapper_236900} : (tensor<1x?x?x3xui8>, tensor<!tf_type.resource<tensor<3x3x3x32xf32>>>, tensor<!tf_type.resource<tensor<32xf32>>>, tensor<!tf_type.resource<tensor<32xf32>>>, tensor<!tf_type.resource<tensor<32xf32>>>, tensor<!tf_type.resource<tensor<32xf32>>>, tensor<!tf_type.resource<tensor<3x3x32x1xf32>>>, tensor<!tf_type.resource<tensor<32xf32>>>, tensor<!tf_type.resource<tensor<32xf32>>>, tensor<!tf_type.resource<tensor<32xf32>>>, tensor<!tf_type.resource<tensor<32xf32>>>, tensor<!tf_type.resource<tensor<1x1x32x64xf32>>>, tensor<!tf_type.resource<tensor<64xf32>>>, tensor<!tf_type.resource<tensor<64xf32>>>, tensor<!tf_type.resource<tensor<64xf32>>>, tensor<!tf_type.resource<tensor<64xf32>>>, tensor<!tf_type.resource<tensor<3x3x64x1xf32>>>, tensor<!tf_type.resource<tensor<64xf32>>>, tensor<!tf_type.resource<tensor<64xf32>>>, tensor<!tf_type.resource<tensor<64xf32>>>, tensor<!tf_type.resource<tensor<64xf32>>>, tensor<!tf_type.resource<tensor<1x1x64x128xf32>>>, tensor<!tf_type.resource<tensor<128xf32>>>, tensor<!tf_type.resource<tensor<128xf32>>>, tensor<!tf_type.resource<tensor<128xf32>>>, tensor<!tf_type.resource<tensor<128xf32>>>, tensor<!tf_type.resource<tensor<3x3x128x1xf32>>>, tensor<!tf_type.resource<tensor<128xf32>>>, tensor<!tf_type.resource<tensor<128xf32>>>, tensor<!tf_type.resource<tensor<128xf32>>>, tensor<!tf_type.resource<tensor<128xf32>>>, tensor<!tf_type.resource<tensor<1x1x128x128xf32>>>, tensor<!tf_type.resource<tensor<128xf32>>>, tensor<!tf_type.resource<tensor<128xf32>>>, tensor<!tf_type.resource<tensor<128xf32>>>, tensor<!tf_type.resource<tensor<128xf32>>>, tensor<!tf_type.resource<tensor<3x3x128x1xf32>>>, tensor<!tf_type.resource<tensor<128xf32>>>, tensor<!tf_type.resource<tensor<128xf32>>>, tensor<!tf_type.resource<tensor<128xf32>>>, tensor<!tf_type.resource<tensor<128xf32>>>, tensor<!tf_type.resource<tensor<1x1x128x256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<3x3x256x1xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<1x1x256x256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<3x3x256x1xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<1x1x256x512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<3x3x512x1xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<1x1x512x512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<3x3x512x1xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<1x1x512x512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<3x3x512x1xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<1x1x512x512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<3x3x512x1xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<1x1x512x512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<3x3x512x1xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<1x1x512x512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<3x3x512x1xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<512xf32>>>, tensor<!tf_type.resource<tensor<1x1x512x1024xf32>>>, tensor<!tf_type.resource<tensor<1024xf32>>>, tensor<!tf_type.resource<tensor<1024xf32>>>, tensor<!tf_type.resource<tensor<1024xf32>>>, tensor<!tf_type.resource<tensor<1024xf32>>>, tensor<!tf_type.resource<tensor<3x3x1024x1xf32>>>, tensor<!tf_type.resource<tensor<1024xf32>>>, tensor<!tf_type.resource<tensor<1024xf32>>>, tensor<!tf_type.resource<tensor<1024xf32>>>, tensor<!tf_type.resource<tensor<1024xf32>>>, tensor<!tf_type.resource<tensor<1x1x1024x1024xf32>>>, tensor<!tf_type.resource<tensor<1024xf32>>>, tensor<!tf_type.resource<tensor<1024xf32>>>, tensor<!tf_type.resource<tensor<1024xf32>>>, tensor<!tf_type.resource<tensor<1024xf32>>>, tensor<!tf_type.resource<tensor<1x1x1024x256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<1x1x512x256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<3x3x256x256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<1x1x256x256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<3x3x256x256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<3x3x256x256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<3x3x256x256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<2xf32>, tensor<2xf32>, tensor<2xf32>, tensor<2xf32>, tensor<2xf32>, tensor<2xf32>, tensor<2xf32>, tensor<2xf32>, tensor<2xf32>, tensor<2xf32>, tensor<2xf32>, tensor<2xf32>, tensor<2xf32>, tensor<2xf32>, tensor<2xf32>, tensor<!tf_type.resource<tensor<3x3x256x256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<3x3x256x256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<3x3x256x256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<3x3x256x256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<3x3x256x24xf32>>>, tensor<!tf_type.resource<tensor<24xf32>>>, tensor<!tf_type.resource<tensor<3x3x256x256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<3x3x256x256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<3x3x256x256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<3x3x256x256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<3x3x256x546xf32>>>, tensor<!tf_type.resource<tensor<546xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>, tensor<!tf_type.resource<tensor<256xf32>>>) -> (tensor<*xf32>, tensor<*xf32>, tensor<*xf32>, tensor<*xf32>, tensor<*xf32>, tensor<*xf32>, tensor<*xf32>, tensor<*xf32>)\r\n           ^\r\nssd-func.mlir:6156:74: note: see current operation: %986:3 = \"tf.NonMaxSuppressionV5\"(%755, %985, %34, %40, %39, %3) {device = \"\", pad_to_max_output_size = false} : (tensor<51150x4xf32>, tensor<51150xf32>, tensor<i32>, tensor<f32>, tensor<f32>, tensor<f32>) -> (tensor<?xi32>, tensor<?xf32>, tensor<i32>)\r\n    %selected_indices_4039, %selected_scores_4040, %valid_outputs_4041 = \"tf.NonMaxSuppressionV5\"(%1931, %2111, %773, %cst_1735, %cst_1736, %cst_1737) {device = \"\", pad_to_max_output_size = false} : (tensor<*xf32>, tensor<*xf32>, tensor<*xi32>, tensor<f32>, tensor<f32>, tensor<f32>) -> (tensor<*xi32>, tensor<*xf32>, tensor<*xi32>)\r\n                                                                         ^\r\n\r\n```\r\n\r\n \r\nno longer exists on the new branch.", "comments": ["@blacklong28 \r\nIn order to expedite the trouble-shooting process here,Could you please fill the issue [template](https://github.com/tensorflow/tensorflow/issues/new/choose),\r\nThanks!", "@sushreebarsa Update describe. Thanks.", "@blacklong28 \r\nIn order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53762\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53762\">No</a>\n"]}, {"number": 53761, "title": "print_selective_registration_header: No module named 'tensorflow.python.platform' in Offical Lastest Docker", "body": "### 1. System information\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 20.04\r\n- TensorFlow installation (pip package or built from source): source \r\n- TensorFlow library (version, if pip package or github SHA, if built from source): source\r\n\r\n### 2. Code\r\n\r\nProvide code to help us reproduce your issues using one of the following options:\r\n\r\nHi, as this issue #53732  mention, i meet this issue again even in lastest offical docker.\r\nThanks!\r\n\r\nhere is the code to reproduce the errror.\r\n```\r\n# docker pull\r\ndocker pull tensorflow/tensorflow:latest-devel\r\n\r\n# in the docker\r\ncd <tensorflow-src-path>\r\nLINE_IDX_TO_ADD=$(grep -n '\":tflite_version_script.lds\",' tensorflow/lite/BUILD | awk -F ':' '{print $1}')\r\nsed -i \"${LINE_IDX_TO_ADD}s/^/\\t\\\"\\/\\/tensorflow\\/lite\\/delegates\\/flex:delegate\\\",\\n/\" ./tensorflow/lite/BUILD\r\n\r\nbazel build --define=no_tensorflow_py_deps=true tensorflow/python/tools:print_selective_registration_header\r\nbazel-bin/tensorflow/python/tools/print_selective_registration_header\r\n```\r\nhere is the config.\r\n```\r\nbuild --action_env PYTHON_BIN_PATH=\"/usr/bin/python3\"\r\nbuild --action_env PYTHON_LIB_PATH=\"/usr/lib/python3/dist-packages\"\r\nbuild --python_path=\"/usr/bin/python3\"\r\nbuild:opt --copt=-Wno-sign-compare\r\nbuild:opt --host_copt=-Wno-sign-compare\r\ntest --flaky_test_attempts=3\r\ntest --test_size_filters=small,medium\r\ntest:v1 --test_tag_filters=-benchmark-test,-no_oss,-gpu,-oss_serial\r\ntest:v1 --build_tag_filters=-benchmark-test,-no_oss,-gpu\r\ntest:v2 --test_tag_filters=-benchmark-test,-no_oss,-gpu,-oss_serial,-v1only\r\ntest:v2 --build_tag_filters=-benchmark-test,-no_oss,-gpu,-v1only\r\nroot@f912083c6c87:/tensorflow_src# LINE_IDX_TO_ADD=$(grep -n '\":tflite_version_script.lds\",' tensorflow/lite/BUILD | awk -F ':' '{print $1}')\r\nroot@f912083c6c87:/tensorflow_src# sed -i \"${LINE_IDX_TO_ADD}s/^/\\t\\\"\\/\\/tensorflow\\/lite\\/delegates\\/flex:delegate\\\",\\n/\" ./tensorflow/lite/BUILD\r\nroot@f912083c6c87:/tensorflow_src# tail ./tensorflow/lite/BUILD\r\n    deps = [\r\n        \":framework\",\r\n        \":tflite_exported_symbols.lds\",\r\n        \"//tensorflow/lite/delegates/flex:delegate\",\r\n        \":tflite_version_script.lds\",\r\n        \"//tensorflow/lite/kernels:builtin_ops_all_linked\",\r\n    ],\r\n)\r\n\r\ntflite_portable_test_suite()\r\n```\r\n\r\nhere is the log.\r\n```\r\nroot@f912083c6c87:/tensorflow_src# bazel clean\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=186\r\nINFO: Reading rc options for 'clean' from /tensorflow_src/.bazelrc:\r\n  Inherited 'common' options: --experimental_repo_remote_exec\r\nINFO: Reading rc options for 'clean' from /tensorflow_src/.bazelrc:\r\n  Inherited 'build' options: --define framework_shared_object=true --java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --host_java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2 --define=no_aws_support=true --define=no_hdfs_support=true --experimental_cc_shared_library\r\nINFO: Reading rc options for 'clean' from /tensorflow_src/.tf_configure.bazelrc:\r\n  Inherited 'build' options: --action_env PYTHON_BIN_PATH=/usr/bin/python3 --action_env PYTHON_LIB_PATH=/usr/lib/python3/dist-packages --python_path=/usr/bin/python3\r\nINFO: Reading rc options for 'clean' from /tensorflow_src/.bazelrc:\r\n  Inherited 'build' options: --deleted_packages=tensorflow/compiler/mlir/tfrt,tensorflow/compiler/mlir/tfrt/benchmarks,tensorflow/compiler/mlir/tfrt/jit/python_binding,tensorflow/compiler/mlir/tfrt/jit/transforms,tensorflow/compiler/mlir/tfrt/python_tests,tensorflow/compiler/mlir/tfrt/tests,tensorflow/compiler/mlir/tfrt/tests/analysis,tensorflow/compiler/mlir/tfrt/tests/jit,tensorflow/compiler/mlir/tfrt/tests/lhlo_to_tfrt,tensorflow/compiler/mlir/tfrt/tests/tf_to_corert,tensorflow/compiler/mlir/tfrt/tests/tf_to_tfrt_data,tensorflow/compiler/mlir/tfrt/tests/saved_model,tensorflow/compiler/mlir/tfrt/transforms/lhlo_gpu_to_tfrt_gpu,tensorflow/core/runtime_fallback,tensorflow/core/runtime_fallback/conversion,tensorflow/core/runtime_fallback/kernel,tensorflow/core/runtime_fallback/opdefs,tensorflow/core/runtime_fallback/runtime,tensorflow/core/runtime_fallback/util,tensorflow/core/tfrt/common,tensorflow/core/tfrt/eager,tensorflow/core/tfrt/eager/backends/cpu,tensorflow/core/tfrt/eager/backends/gpu,tensorflow/core/tfrt/eager/core_runtime,tensorflow/core/tfrt/eager/cpp_tests/core_runtime,tensorflow/core/tfrt/gpu,tensorflow/core/tfrt/run_handler_thread_pool,tensorflow/core/tfrt/runtime,tensorflow/core/tfrt/saved_model,tensorflow/core/tfrt/graph_executor,tensorflow/core/tfrt/saved_model/tests,tensorflow/core/tfrt/tpu,tensorflow/core/tfrt/utils\r\nINFO: Found applicable config definition build:short_logs in file /tensorflow_src/.bazelrc: --output_filter=DONT_MATCH_ANYTHING\r\nINFO: Found applicable config definition build:v2 in file /tensorflow_src/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1\r\nINFO: Found applicable config definition build:linux in file /tensorflow_src/.bazelrc: --copt=-w --host_copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels --distinct_host_configuration=false --experimental_guard_against_concurrent_changes\r\nINFO: Found applicable config definition build:dynamic_kernels in file /tensorflow_src/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS\r\nINFO: Starting clean (this may take a while). Consider using --async if the clean takes more than several minutes.\r\nroot@f912083c6c87:/tensorflow_src# bazel build --define=no_tensorflow_py_deps=true tensorflow/python/tools:print_selective_registration_header\r\nroot@f912083c6c87:/tensorflow_src# bazel build --define=no_tensorflow_py_deps=true tensorflow/python/tools:print_selective_registration_header\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=186\r\nINFO: Reading rc options for 'build' from /tensorflow_src/.bazelrc:\r\n  Inherited 'common' options: --experimental_repo_remote_exec\r\nINFO: Reading rc options for 'build' from /tensorflow_src/.bazelrc:\r\n  'build' options: --define framework_shared_object=true --java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --host_java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2 --define=no_aws_support=true --define=no_hdfs_support=true --experimental_cc_shared_library\r\nINFO: Reading rc options for 'build' from /tensorflow_src/.tf_configure.bazelrc:\r\n  'build' options: --action_env PYTHON_BIN_PATH=/usr/bin/python3 --action_env PYTHON_LIB_PATH=/usr/lib/python3/dist-packages --python_path=/usr/bin/python3\r\nINFO: Reading rc options for 'build' from /tensorflow_src/.bazelrc:\r\n  'build' options: --deleted_packages=tensorflow/compiler/mlir/tfrt,tensorflow/compiler/mlir/tfrt/benchmarks,tensorflow/compiler/mlir/tfrt/jit/python_binding,tensorflow/compiler/mlir/tfrt/jit/transforms,tensorflow/compiler/mlir/tfrt/python_tests,tensorflow/compiler/mlir/tfrt/tests,tensorflow/compiler/mlir/tfrt/tests/analysis,tensorflow/compiler/mlir/tfrt/tests/jit,tensorflow/compiler/mlir/tfrt/tests/lhlo_to_tfrt,tensorflow/compiler/mlir/tfrt/tests/tf_to_corert,tensorflow/compiler/mlir/tfrt/tests/tf_to_tfrt_data,tensorflow/compiler/mlir/tfrt/tests/saved_model,tensorflow/compiler/mlir/tfrt/transforms/lhlo_gpu_to_tfrt_gpu,tensorflow/core/runtime_fallback,tensorflow/core/runtime_fallback/conversion,tensorflow/core/runtime_fallback/kernel,tensorflow/core/runtime_fallback/opdefs,tensorflow/core/runtime_fallback/runtime,tensorflow/core/runtime_fallback/util,tensorflow/core/tfrt/common,tensorflow/core/tfrt/eager,tensorflow/core/tfrt/eager/backends/cpu,tensorflow/core/tfrt/eager/backends/gpu,tensorflow/core/tfrt/eager/core_runtime,tensorflow/core/tfrt/eager/cpp_tests/core_runtime,tensorflow/core/tfrt/gpu,tensorflow/core/tfrt/run_handler_thread_pool,tensorflow/core/tfrt/runtime,tensorflow/core/tfrt/saved_model,tensorflow/core/tfrt/graph_executor,tensorflow/core/tfrt/saved_model/tests,tensorflow/core/tfrt/tpu,tensorflow/core/tfrt/utils\r\nINFO: Found applicable config definition build:short_logs in file /tensorflow_src/.bazelrc: --output_filter=DONT_MATCH_ANYTHING\r\nINFO: Found applicable config definition build:v2 in file /tensorflow_src/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1\r\nINFO: Found applicable config definition build:linux in file /tensorflow_src/.bazelrc: --copt=-w --host_copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels --distinct_host_configuration=false --experimental_guard_against_concurrent_changes\r\nINFO: Found applicable config definition build:dynamic_kernels in file /tensorflow_src/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS\r\nWARNING: Download from https://storage.googleapis.com/mirror.tensorflow.org/github.com/tensorflow/runtime/archive/a2385f745b4b64729008fd892cfb4763dadf535b.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found\r\nWARNING: Download from http://mirror.tensorflow.org/github.com/bazelbuild/bazel-toolchains/archive/dfc67056200b674accd08d8f9a21e328098c07e2.tar.gz failed: class java.io.IOException Proxy address 10.71.254.21:8888 is not a valid URL\r\nWARNING: Download from https://mirror.bazel.build/github.com/bazelbuild/rules_cc/archive/081771d4a0e9d7d3aa0eed2ef389fa4700dfb23e.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found\r\nDEBUG: Rule 'io_bazel_rules_docker' indicated that a canonical reproducible form can be obtained by modifying arguments shallow_since = \"1596824487 -0400\"\r\nDEBUG: Repository io_bazel_rules_docker instantiated at:\r\n  /tensorflow_src/WORKSPACE:23:14: in <toplevel>\r\n  /tensorflow_src/tensorflow/workspace0.bzl:108:34: in workspace\r\n  /root/.cache/bazel/_bazel_root/43801f1e35f242fb634ebbc6079cf6c5/external/bazel_toolchains/repositories/repositories.bzl:35:23: in repositories\r\nRepository rule git_repository defined at:\r\n  /root/.cache/bazel/_bazel_root/43801f1e35f242fb634ebbc6079cf6c5/external/bazel_tools/tools/build_defs/repo/git.bzl:199:33: in <toplevel>\r\nINFO: Analyzed target //tensorflow/python/tools:print_selective_registration_header (29 packages loaded, 161 targets configured).\r\nINFO: Found 1 target...\r\nTarget //tensorflow/python/tools:print_selective_registration_header up-to-date:\r\n  bazel-bin/tensorflow/python/tools/print_selective_registration_header\r\nINFO: Elapsed time: 120.679s, Critical Path: 0.03s\r\nINFO: 4 processes: 4 internal.\r\nINFO: Build completed successfully, 4 total actions\r\n\r\n\r\nroot@f912083c6c87:/tensorflow_src# bazel-bin/tensorflow/python/tools/print_selective_registration_header\r\nTraceback (most recent call last):\r\n  File \"/tensorflow_src/bazel-bin/tensorflow/python/tools/print_selective_registration_header.runfiles/org_tensorflow/tensorflow/python/tools/print_selective_registration_header.py\", line 38, in <module>\r\n    from tensorflow.python.tools import selective_registration_header_lib\r\nImportError: cannot import name 'selective_registration_header_lib' from 'tensorflow.python.tools' (/tensorflow_src/bazel-bin/tensorflow/python/tools/print_selective_registration_header.runfiles/org_tensorflow/tensorflow/python/tools/__init__.py)\r\n```\r\n", "comments": ["@groovemaxRong ,\r\nLooks like this is duplicate of issue #53732 .Can you please close this issue, since it is already being tracked there? Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53761\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53761\">No</a>\n"]}, {"number": 53760, "title": "[TF:TRT] Fix the AlgorithmSelector", "body": "This change allows the algorithm selection mechanism to be used in TensorRT 7.1. Previously, the code disabled the algorithm selector unless the TRT version is greater than 7.2. However, the true issue is that TRT7.1 has a bug when the algorithm selector is used in conjunction with calibration and INT8 mode.\r\n\r\nIn addition, this change cleans up the `TfTrtAlgorithmSelector` class. It removes all `assert` and `CHECK` statements and refactors the code to conform with standards in the rest of the code base. Use of the preprocessor for conditionals is reduced to only necessary cases.", "comments": ["@christopherbate  This PR is in draft, any update on this? Please. Thanks!", "@bixia1 This is ready for your review.", "Applied fixes and squashed, thanks", "Getting these errors:\r\nIn file included from [third_party/tensorflow/compiler/tf2tensorrt/convert/algorithm_selector.cc:16](https://cs.corp.google.com/piper///depot/google3/third_party/tensorflow/compiler/tf2tensorrt/convert/algorithm_selector.cc?l=16&ws=tap-prod-presubmit/174564036&snapshot=2):\r\n[./third_party/tensorflow/compiler/tf2tensorrt/convert/algorithm_selector.h:64](https://cs.corp.google.com/piper///depot/google3/third_party/tensorflow/compiler/tf2tensorrt/convert/algorithm_selector.h?l=64&ws=tap-prod-presubmit/174564036&snapshot=2):14: error: implicit instantiation of undefined template 'std::array<int, 4>'\r\n  TRTVersion version_;\r\n             ^\r\n[third_party/crosstool/v18/stable/toolchain/bin/../include/c++/v1/__tuple:219](https://cs.corp.google.com/piper///depot/google3/third_party/crosstool/v18/stable/toolchain/include/c%2B%2B/v1/__tuple?l=219&ws=tap-prod-presubmit/174564036&snapshot=2):64: note: template is declared here\r\ntemplate <class _Tp, size_t _Size> struct _LIBCPP_TEMPLATE_VIS array;\r\n                                                               ^\r\nIn file included from [third_party/tensorflow/compiler/tf2tensorrt/convert/algorithm_selector.cc:16](https://cs.corp.google.com/piper///depot/google3/third_party/tensorflow/compiler/tf2tensorrt/convert/algorithm_selector.cc?l=16&ws=tap-prod-presubmit/174564036&snapshot=2):\r\n[./third_party/tensorflow/compiler/tf2tensorrt/convert/algorithm_selector.h:44](https://cs.corp.google.com/piper///depot/google3/third_party/tensorflow/compiler/tf2tensorrt/convert/algorithm_selector.h?l=44&ws=tap-prod-presubmit/174564036&snapshot=2):35: error: implicit instantiation of undefined template 'std::array<int, 4>'\r\n      const TRTVersion& version = CompileTimeTRTVersion())\r\n                                  ^\r\n[third_party/crosstool/v18/stable/toolchain/bin/../include/c++/v1/__tuple:219](https://cs.corp.google.com/piper///depot/google3/third_party/crosstool/v18/stable/toolchain/include/c%2B%2B/v1/__tuple?l=219&ws=tap-prod-presubmit/174564036&snapshot=2):64: note: template is declared here\r\ntemplate <class _Tp, size_t _Size> struct _LIBCPP_TEMPLATE_VIS array;\r\n                                                               ^\r\nIn file included from [third_party/tensorflow/compiler/tf2tensorrt/convert/algorithm_selector.cc:16](https://cs.corp.google.com/piper///depot/google3/third_party/tensorflow/compiler/tf2tensorrt/convert/algorithm_selector.cc?l=16&ws=tap-prod-presubmit/174564036&snapshot=2):\r\n[./third_party/tensorflow/compiler/tf2tensorrt/convert/algorithm_selector.h:38](https://cs.corp.google.com/piper///depot/google3/third_party/tensorflow/compiler/tf2tensorrt/convert/algorithm_selector.h?l=38&ws=tap-prod-presubmit/174564036&snapshot=2):31: error: implicit instantiation of undefined template 'std::array<int, 4>'\r\n  static constexpr TRTVersion CompileTimeTRTVersion() {\r\n                              ^\r\n[third_party/crosstool/v18/stable/toolchain/bin/../include/c++/v1/__tuple:219](https://cs.corp.google.com/piper///depot/google3/third_party/crosstool/v18/stable/toolchain/include/c%2B%2B/v1/__tuple?l=219&ws=tap-prod-presubmit/174564036&snapshot=2):64: note: template is declared here\r\ntemplate <class _Tp, size_t _Size> struct _LIBCPP_TEMPLATE_VIS array;\r\n                                                               ^\r\nIn file included from [third_party/tensorflow/compiler/tf2tensorrt/convert/algorithm_selector.cc:16](https://cs.corp.google.com/piper///depot/google3/third_party/tensorflow/compiler/tf2tensorrt/convert/algorithm_selector.cc?l=16&ws=tap-prod-presubmit/174564036&snapshot=2):\r\n[./third_party/tensorflow/compiler/tf2tensorrt/convert/algorithm_selector.h:39](https://cs.corp.google.com/piper///depot/google3/third_party/tensorflow/compiler/tf2tensorrt/convert/algorithm_selector.h?l=39&ws=tap-prod-presubmit/174564036&snapshot=2):12: error: implicit instantiation of undefined template 'std::array<int, 4>'\r\n    return TRTVersion{NV_TENSORRT_MAJOR, NV_TENSORRT_MINOR, NV_TENSORRT_PATCH,\r\n           ^\r\n[third_party/crosstool/v18/stable/toolchain/bin/../include/c++/v1/__tuple:219](https://cs.corp.google.com/piper///depot/google3/third_party/crosstool/v18/stable/toolchain/include/c%2B%2B/v1/__tuple?l=219&ws=tap-prod-presubmit/174564036&snapshot=2):64: note: template is declared here\r\ntemplate <class _Tp, size_t _Size> struct _LIBCPP_TEMPLATE_VIS array;\r\n                                                               ^\r\nIn file included from [third_party/tensorflow/compiler/tf2tensorrt/convert/algorithm_selector.cc:16](https://cs.corp.google.com/piper///depot/google3/third_party/tensorflow/compiler/tf2tensorrt/convert/algorithm_selector.cc?l=16&ws=tap-prod-presubmit/174564036&snapshot=2):\r\n[./third_party/tensorflow/compiler/tf2tensorrt/convert/algorithm_selector.h:39](https://cs.corp.google.com/piper///depot/google3/third_party/tensorflow/compiler/tf2tensorrt/convert/algorithm_selector.h?l=39&ws=tap-prod-presubmit/174564036&snapshot=2):12: error: implicit instantiation of undefined template 'std::array<int, 4>'\r\n    return TRTVersion{NV_TENSORRT_MAJOR, NV_TENSORRT_MINOR, NV_TENSORRT_PATCH,\r\n           ^\r\n[third_party/crosstool/v18/stable/toolchain/bin/../include/c++/v1/__tuple:219](https://cs.corp.google.com/piper///depot/google3/third_party/crosstool/v18/stable/toolchain/include/c%2B%2B/v1/__tuple?l=219&ws=tap-prod-presubmit/174564036&snapshot=2):64: note: template is declared here\r\ntemplate <class _Tp, size_t _Size> struct _LIBCPP_TEMPLATE_VIS array;\r\n                                                               ^", "OK looks like a `libstdc++` vs `libc++` error. With GCC7/8 and `libstdc++` it builds fine.\r\n\r\n It looks like we just need to include `<array>` at the top of `algorithm_selector.h`.", "I pushed up the inclusion of `<array>` ", "[third_party/tensorflow/compiler/tf2tensorrt/convert/algorithm_selector_test.cc:85](https://cs.corp.google.com/piper///depot/google3/third_party/tensorflow/compiler/tf2tensorrt/convert/algorithm_selector_test.cc?l=85&ws=tap-prod-presubmit/174786210&snapshot=2):67: error: no member named 'kHWC16' in 'nvinfer1::TensorFormat'\r\n                                          nvinfer1::TensorFormat::kHWC16));\r\n                                          ~~~~~~~~~~~~~~~~~~~~~~~~^\r\n[./third_party/googletest/googletest/include/gtest/gtest.h:1814](https://cs.corp.google.com/piper///depot/google3/third_party/googletest/googletest/include/gtest/gtest.h?l=1814&ws=tap-prod-presubmit/174786210&snapshot=2):50: note: expanded from macro 'EXPECT_TRUE'\r\n#define EXPECT_TRUE(condition) GTEST_EXPECT_TRUE(condition)\r\n                                                 ^~~~~~~~~\r\n[./third_party/googletest/googletest/include/gtest/gtest.h:1798](https://cs.corp.google.com/piper///depot/google3/third_party/googletest/googletest/include/gtest/gtest.h?l=1798&ws=tap-prod-presubmit/174786210&snapshot=2):23: note: expanded from macro 'GTEST_EXPECT_TRUE'\r\n  GTEST_TEST_BOOLEAN_(condition, #condition, false, true, \\\r\n                      ^~~~~~~~~\r\n[./third_party/googletest/googletest/include/gtest/internal/gtest-internal.h:1504](https://cs.corp.google.com/piper///depot/google3/third_party/googletest/googletest/include/gtest/internal/gtest-internal.h?l=1504&ws=tap-prod-presubmit/174786210&snapshot=2):34: note: expanded from macro 'GTEST_TEST_BOOLEAN_'\r\n      ::testing::AssertionResult(expression)) \\\r\n                                 ^~~~~~~~~~", "@christopherbate Can you please check @bixia1's comments and keep us posted ? Thanks!\r\n", "fixed TRT 7 build", "the tests still failed, see log\r\n[alg.log](https://github.com/tensorflow/tensorflow/files/8201762/alg.log)", "Sorry stupid mistake. Those should have been removed. I pushed up the fix, but I won't be able to re-run with TRT7 from my end until late today", "TensorRT7_2 still fails with the same message.", "I am still running tests, will let you know when I am done, thanks!", "Everything passes on my end. Did you use the commit `54c6ee5ed4f3d99f739f34a86f10b5e447ecc960`? I might have pushed that one up after you tested."]}, {"number": 53759, "title": "why does tensorflow use multi threads to launch gpu kernels?", "body": "I noticed that when I launch kernel to the same GPU with multi threads, cudaLaunchKernel  api will get much slower. \r\nBut seems it's the case in tensorflow. why not use a single thread to communicate with GPU?\r\n\r\nHere is my test\uff0cwhen thread_num is larger, cuda api cost will be huge.\r\n![image](https://user-images.githubusercontent.com/26128514/149446536-06d6117a-d348-4b0d-a2a8-8ebf81299c5a.png)\r\n\r\n`#include <thread>\r\n#include <vector>\r\n\r\nusing namespace std;\r\n\r\nbool running = true;\r\nconst int thread_num = 20;\r\nconst int launch_num = 25;\r\n\r\n__global__ void task_kernel(int x) {\r\n    int ans = 1024;\r\n    for(int i = 0; i < x; i++) {\r\n        if(ans > 0) {\r\n            ans *= (x + 2);\r\n        }\r\n    }\r\n}\r\n\r\nvoid task(int x) {\r\n    while(running) {\r\n        for(int i = 0; i < launch_num; i++) {\r\n            task_kernel<<<1, 1>>>(x);\r\n        }\r\n        this_thread::sleep_for(1ms);\r\n    }\r\n}\r\n\r\nvoid test() {\r\n    vector<thread> threads;\r\n    for(int i = 0; i < thread_num; i++) {\r\n        thread t(task, i);\r\n        threads.push_back(std::move(t));\r\n    }\r\n    this_thread::sleep_for(100ms);\r\n    running = false;\r\n    for(auto& t: threads) {\r\n        t.join();\r\n    }\r\n}\r\n\r\nint main() {\r\n    cudaFree(0);\r\n    test();\r\n    return 0;\r\n}`", "comments": ["Hi @Saduf2019 ! Could you please look at this issue?", "@sleepwalker2017 \r\nWe see that you have not filled the issue template without the important information like tf version and gpu card used, its hard to help you.\r\nMay be you have to fine tune your cuda configurations for TF.\r\nThis does not seem like a bug or feature request as this repo is for them, can you open this in discussion forum for further queries as there is a large community to guide there.", "> discussion forum\r\n\r\nOK, I'll go to the forum for some more discuss. thank you.", "@sleepwalker2017 \r\nCan you move this to closed status", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 53758, "title": "movenet fp16 not executed by TFLITE NNAPI DELEGATE", "body": "<em>Please make sure that this is an issue related to performance of TensorFlow.\r\nAs per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:performance_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): aarch64 Android 11\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below): 2.8\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n**Describe the current behavior**\r\nI have issues while working with movenet tflite models on android 11 NNAPI 1.3\r\nthe movenet models used are sourced from tfhub:\r\n\r\nhttps://tfhub.dev/google/lite-model/movenet/singlepose/lightning/tflite/float16/4\r\nhttps://tfhub.dev/google/lite-model/movenet/singlepose/lightning/tflite/int8/4\r\n\r\nthe above two singlepose movenet lighting tflite models are float16 and INT8 respectively, and I was trying to perform benchmarking of the same using the prebuilt benchmark model for android_aarch64 sourced from tflite website (v 2.8):\r\nhttps://storage.googleapis.com/tensorflow-nightly-public/prod/tensorflow/release/lite/tools/nightly/latest/android_aarch64_benchmark_model\r\n\r\nWhen I run lite-model_movenet_singlepose_lightning_tflite_int8_4.tflite model on NNAPI using the following command:\r\n\r\n> ./benchmark_model --graph=lite-model_movenet_singlepose_lightning_tflite_int8_4.tflite --use_nnapi=1 --nnapi_accelerator_name=nnapi-reference\r\nSTARTING!\r\nLog parameter values verbosely: [0]\r\nGraph: [lite-model_movenet_singlepose_lightning_tflite_int8_4.tflite]\r\nUse NNAPI: [1]\r\nNNAPI accelerator name: [nnapi-reference]\r\nNNAPI accelerators available: [nnapi-reference]\r\nLoaded model lite-model_movenet_singlepose_lightning_tflite_int8_4.tflite\r\nINFO: Initialized TensorFlow Lite runtime.\r\nINFO: Created TensorFlow Lite delegate for NNAPI.\r\nNNAPI delegate created.\r\nINFO: Replacing 141 node(s) with delegate (TfLiteNnapiDelegate) node, yielding 15 partitions.\r\nExplicitly applied NNAPI delegate, and the model graph will be partially executed by the delegate w/ 8 delegate kernels.\r\nINFO: Created TensorFlow Lite XNNPACK delegate for CPU.\r\nThe input model file size (MB): 2.89484\r\nInitialized session in 59.758ms.\r\n\r\n the NNAPI delegate is created and the model is partially executed by NNAPI CPU.\r\n\r\nwhereas when I run float16 lite-model_movenet_singlepose_lightning_tflite_float16_4.tflite model as follows:\r\n\r\n> $ ./benchmark_model --graph=lite-model_movenet_singlepose_lightning_tflite_float16_4.tflite --use_nnapi=1 --nnapi_accelerator_name=nnapi-reference\r\nSTARTING!\r\nLog parameter values verbosely: [0]\r\nGraph: [lite-model_movenet_singlepose_lightning_tflite_float16_4.tflite]\r\nUse NNAPI: [1]\r\nNNAPI accelerator name: [nnapi-reference]\r\nNNAPI accelerators available: [nnapi-reference]\r\nLoaded model lite-model_movenet_singlepose_lightning_tflite_float16_4.tflite\r\nINFO: Initialized TensorFlow Lite runtime.\r\nINFO: Created TensorFlow Lite delegate for NNAPI.\r\nNNAPI delegate created.\r\nThough NNAPI delegate is explicitly applied, the model graph will not be executed by the delegate.\r\nINFO: Created TensorFlow Lite XNNPACK delegate for CPU.\r\nINFO: Replacing 269 node(s) with delegate (TfLiteXNNPackDelegate) node, yielding 13 partitions.\r\nThe input model file size (MB): 4.75851\r\nInitialized session in 109.192ms.\r\n\r\nthe float16 model is not at all executed by the NNAPI delegate even though I am explicitly applying NNAPI CPU\r\n\r\nI face the same issue if i run this model https://tfhub.dev/sayakpaul/lite-model/mobilenetv2-coco/fp16/1?lite-format=tflite, i see the same message as before for fp16 models:\r\n\r\n> Graph: [lite-model_mobilenetv2-coco_fp16_1.tflite]\r\nUse NNAPI: [1]\r\nNNAPI accelerator name: [nnapi-reference]\r\nNNAPI accelerators available: [nnapi-reference]\r\nLoaded model lite-model_mobilenetv2-coco_fp16_1.tflite\r\nINFO: Initialized TensorFlow Lite runtime.\r\nINFO: Created TensorFlow Lite delegate for NNAPI.\r\nNNAPI delegate created.\r\nThough NNAPI delegate is explicitly applied, the model graph will not be executed by the delegate.\r\nINFO: Created TensorFlow Lite XNNPACK delegate for CPU.\r\nINFO: Replacing 211 node(s) with delegate (TfLiteXNNPackDelegate) node, yielding 43 partitions.\r\nThe input model file size (MB): 4.2551\r\nInitialized session in 133.522ms.\r\n\r\nI even used the --disable_nnapi_cpu=0 argument, and yet still got the same result with nightly\r\ny\r\nis it the same for every fp16 model that it won't be supported on NNAPI?\r\n\r\n\r\n\r\n**Describe the expected behavior**\r\nthe model should be executed by NNAPI CPU\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["@suyash-narain \r\nCan you please confirm the tensorflow version you are using?\r\nIn order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here.Thanks!", "i was using the tf version 2.8-rc0 and tf nightly benchmark model for date 1/13/2022\r\n\r\nsince the issue occurred during benchmarking the models using tflite benchmark model\r\nthe command used for benchmarking was:\r\n\r\n$chmod +x android_aarch64_benchmark_model\r\n$./android_aarch64_benchmark_model --graph=lite-model_movenet_singlepose_lightning_tflite_float16_4.tflite --use_nnapi=1 --nnapi_accelerator_name=nnapi-reference", "Hi @sushreebarsa,\r\n\r\nWe faced the same issue when trying to emulate pose estimation on Android Studio for Movenet Thunder/Lightning fp16 on NNAPI using tflite nightly build.\r\n\r\nTo reproduce the error,\r\n1)  Clone https://github.com/SuhridS/examples.git -b suhrids/update_pose_estimation\r\n2) Open \"https://github.com/SuhridS/examples/tree/suhrids/update_pose_estimation/lite/examples/pose_estimation/android\" on Android Studio and build.\r\n3) Create an AVD for Pixel 5, API 30 and run pose estimation app on it.\r\n\r\nObservation:\r\n| Model             | Type | CPU   | GPU             | NNAPI       |\r\n|-------------------|------|-------|-----------------|-------------|\r\n| Movenet Lightning | FP16 | Works | Works           | App crashes |\r\n| Movenet Lightning | INT8 | Works | Works           | Works       |\r\n| Movenet Thunder   | FP16 | Works | Works           | App crashes |\r\n| Movenet Thunder   | INT8 | Works | Works           | Works       |\r\n| Movenet Multipose | FP16 | Works | Fallback to CPU | Works       |\r\n| Posenet           | FP16 | Works | Works           | Works       |\r\n\r\n\r\n", "@karimnosseir could you help take a look? thanks!", "Miao, can you please take a look.", "Thanks for reporting the issue. The fix has been submitted and you should be able to build benchmark_model and run the fp16 one. (There are still ops like GatherNd not supported by NNAPI delegate, causing the model being partitioned into several sub models though)", "Hi,\r\n\r\nI built the benchmark model using master branch of tensorflow. Steps followed were:\r\n1. git clone https://github.com/tensorflow/tensorflow.git\r\n2. bazel build -c opt \\\r\n  --config=android_arm64 \\\r\n  tensorflow/lite/tools/benchmark:benchmark_model\r\n3. adb push benchmark_model /data/local/tmp\r\n4. adb push lite-model_movenet_singlepose_lightning_tflite_float16_4.tflite /data/local/tmp\r\n5. adb shell\r\n6. chmod +x benchmark_model\r\n7. ./benchmark_model --graph=lite-model_movenet_singlepose_lightning_tflite_float16_4.tflite --use_nnapi=1 --use_xnnpack=false \r\n\r\noutput:\r\n\r\n```\r\nSTARTING!\r\nLog parameter values verbosely: [0]\r\nGraph: [lite-model_movenet_singlepose_lightning_tflite_float16_4_new.tflite]\r\nUse NNAPI: [1]\r\nNNAPI accelerator name: [nnapi-reference]\r\nNNAPI accelerators available: [nnapi-reference]\r\nUse xnnpack: [0]\r\nLoaded model lite-model_movenet_singlepose_lightning_tflite_float16_4_new.tflite\r\nINFO: Initialized TensorFlow Lite runtime.\r\nINFO: Created TensorFlow Lite delegate for NNAPI.\r\nNNAPI delegate created.\r\nThough NNAPI delegate is explicitly applied, the model graph will not be executed by the delegate.\r\nThe input model file size (MB): 4.75851\r\nInitialized session in 4.179ms.\r\nRunning benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.\r\ncount=4 first=162423 curr=139562 min=139562 max=162423 avg=145326 std=9871\r\nRunning benchmark for at least 50 iterations and at least 1 seconds but terminate if exceeding 150 seconds.\r\ncount=50 first=139294 curr=139520 min=139111 max=139730 avg=139417 std=148\r\nInference timings in us: Init: 4179, First inference: 162423, Warmup (avg): 145326, Inference (avg): 139417\r\nNote: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.\r\nMemory footprint delta from the start of the tool (MB): init=4.73438 overall=22.4023\r\n```\r\nI got the same results using the nightly (dated:2/10/2022)\r\n\r\nBut when i use the nightly (date 2/17/2022), the fp16 model seems to partially execute on NNAPI. Have the changes not been pushed to tensorflow-master?\r\n\r\nthanks"]}, {"number": 53757, "title": "Issue with AdamW optimizer in tensorflow 1.15.5", "body": "<em>Please make sure that this is an issue related to performance of TensorFlow.\r\nAs per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:performance_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):  yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 1.15.5\r\n- Python version: 3.6.8\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: cuda_11.5.r11.5,  nvidia docker image\r\n- GPU model and memory: Nvidia 2080, 8 GB\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\n Training object detection model with \"SSD_INCEPTION_V2\" as backbone. Updated AdamW optimizer from contrib module using following code in optimizer_buider.py.\r\n    \"\"\"\r\n    config = optimizer_config.adamw_optimizer\r\n    learning_rate = _create_learning_rate(config.learning_rate) (# learning rate type: exponential_decay_learning_rate)\r\n    summary_vars.append(learning_rate)\r\n    optimizer = tf.contrib.opt.AdamWOptimizer(weight_decay=4e-05, learning_rate=learning_rate)\r\n    \"\"\"\r\n\r\n   PROBLEM: \r\n  When I use Adam optimizer, I can see progress in learning from coco metrics and it reaches 0.16 mAP for \"0.50 IOU area ALL\" \r\n  after 8 epochs and both training loss and validation loss decrease with small difference in values (good generalization). but when I changed to AdamW optimizer using described code, coco metric (almost 0.0) as well as loss (which is stationary) not changing at all (no generalization). \r\n\r\n**Describe the expected behavior**\r\n  As per paper (https://arxiv.org/abs/1711.05101) and also from documentation, it suppose to train better and converge faster. \r\n Am i missing here something? Let me know if you need any additional information.\r\n\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["@purvang3 ,\r\nWe see that you are using tf version 1.15, 1.x is not actively supported, please update to tf v2.7 and let us know if you are using same issue.Also please take a look at this [link](https://www.tensorflow.org/guide/migrate).It helps.Thanks"]}, {"number": 53756, "title": "Exploding gradient after network has converged", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Implemented a custom distribution. It is in the jupyter notebook provided at the end.\r\n- OS Platform and Distribution: \r\nNAME=\"CentOS Linux\"\r\nVERSION=\"7 (Core)\"\r\nID=\"centos\"\r\nID_LIKE=\"rhel fedora\"\r\nVERSION_ID=\"7\"\r\nPRETTY_NAME=\"CentOS Linux 7 (Core)\"\r\nANSI_COLOR=\"0;31\"\r\nCPE_NAME=\"cpe:/o:centos:centos:7\"\r\nHOME_URL=\"https://www.centos.org/\"\r\nBUG_REPORT_URL=\"https://bugs.centos.org/\"\r\n\r\nCENTOS_MANTISBT_PROJECT=\"CentOS-7\"\r\nCENTOS_MANTISBT_PROJECT_VERSION=\"7\"\r\nREDHAT_SUPPORT_PRODUCT=\"centos\"\r\nREDHAT_SUPPORT_PRODUCT_VERSION=\"7\"\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version :  2.3.1\r\n- Python version:  Python 3.8.5\r\n- GCC/Compiler version : gcc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-44)\r\n- CUDA/cuDNN version:  CUDA Version: 11.0\r\n- GPU model and memory:\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 450.142.00   Driver Version: 450.142.00   CUDA Version: 11.0     |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|                               |                      |               MIG M. |\r\n|===============================+======================+======================|\r\n|   0  Tesla V100-SXM3...  Off  | 00000000:34:00.0 Off |                    0 |\r\n| N/A   27C    P0    66W / 350W |   3358MiB / 32510MiB |      0%      Default |\r\n|                               |                      |                  N/A |\r\n+-------------------------------+----------------------+----------------------+\r\n|   1  Tesla V100-SXM3...  Off  | 00000000:36:00.0 Off |                    0 |\r\n| N/A   26C    P0    50W / 350W |      7MiB / 32510MiB |      0%      Default |\r\n|                               |                      |                  N/A |\r\n+-------------------------------+----------------------+----------------------+\r\n|   2  Tesla V100-SXM3...  Off  | 00000000:39:00.0 Off |                    0 |\r\n| N/A   31C    P0    49W / 350W |      7MiB / 32510MiB |      0%      Default |\r\n|                               |                      |                  N/A |\r\n+-------------------------------+----------------------+----------------------+\r\n|   3  Tesla V100-SXM3...  Off  | 00000000:3B:00.0 Off |                    0 |\r\n| N/A   64C    P0   273W / 350W |  25960MiB / 32510MiB |    100%      Default |\r\n|                               |                      |                  N/A |\r\n+-------------------------------+----------------------+----------------------+\r\n|   4  Tesla V100-SXM3...  Off  | 00000000:57:00.0 Off |                    0 |\r\n| N/A   23C    P0    48W / 350W |      5MiB / 32510MiB |      0%      Default |\r\n|                               |                      |                  N/A |\r\n+-------------------------------+----------------------+----------------------+\r\n|   5  Tesla V100-SXM3...  Off  | 00000000:59:00.0 Off |                    0 |\r\n| N/A   29C    P0    49W / 350W |      5MiB / 32510MiB |      0%      Default |\r\n|                               |                      |                  N/A |\r\n+-------------------------------+----------------------+----------------------+\r\n|   6  Tesla V100-SXM3...  Off  | 00000000:5C:00.0 Off |                    0 |\r\n| N/A   26C    P0    49W / 350W |      5MiB / 32510MiB |      0%      Default |\r\n|                               |                      |                  N/A |\r\n+-------------------------------+----------------------+----------------------+\r\n|   7  Tesla V100-SXM3...  Off  | 00000000:5E:00.0 Off |                    0 |\r\n| N/A   28C    P0    48W / 350W |      5MiB / 32510MiB |      0%      Default |\r\n|                               |                      |                  N/A |\r\n+-------------------------------+----------------------+----------------------+\r\n|   8  Tesla V100-SXM3...  Off  | 00000000:B7:00.0 Off |                    0 |\r\n| N/A   24C    P0    48W / 350W |      5MiB / 32510MiB |      0%      Default |\r\n|                               |                      |                  N/A |\r\n+-------------------------------+----------------------+----------------------+\r\n|   9  Tesla V100-SXM3...  Off  | 00000000:B9:00.0 Off |                    0 |\r\n| N/A   25C    P0    49W / 350W |      5MiB / 32510MiB |      0%      Default |\r\n|                               |                      |                  N/A |\r\n+-------------------------------+----------------------+----------------------+\r\n|  10  Tesla V100-SXM3...  Off  | 00000000:BC:00.0 Off |                    0 |\r\n| N/A   30C    P0    49W / 350W |      5MiB / 32510MiB |      0%      Default |\r\n|                               |                      |                  N/A |\r\n+-------------------------------+----------------------+----------------------+\r\n|  11  Tesla V100-SXM3...  Off  | 00000000:BE:00.0 Off |                    0 |\r\n| N/A   30C    P0    46W / 350W |      5MiB / 32510MiB |      0%      Default |\r\n|                               |                      |                  N/A |\r\n+-------------------------------+----------------------+----------------------+\r\n|  12  Tesla V100-SXM3...  Off  | 00000000:E0:00.0 Off |                    0 |\r\n| N/A   25C    P0    47W / 350W |      5MiB / 32510MiB |      0%      Default |\r\n|                               |                      |                  N/A |\r\n+-------------------------------+----------------------+----------------------+\r\n|  13  Tesla V100-SXM3...  Off  | 00000000:E2:00.0 Off |                    0 |\r\n| N/A   25C    P0    47W / 350W |      5MiB / 32510MiB |      0%      Default |\r\n|                               |                      |                  N/A |\r\n+-------------------------------+----------------------+----------------------+\r\n|  14  Tesla V100-SXM3...  Off  | 00000000:E5:00.0 Off |                    0 |\r\n| N/A   31C    P0    49W / 350W |      5MiB / 32510MiB |      0%      Default |\r\n|                               |                      |                  N/A |\r\n+-------------------------------+----------------------+----------------------+\r\n|  15  Tesla V100-SXM3...  Off  | 00000000:E7:00.0 Off |                    0 |\r\n| N/A   29C    P0    50W / 350W |      5MiB / 32510MiB |      0%      Default |\r\n|                               |                      |                  N/A |\r\n+-------------------------------+----------------------+----------------------+\r\n\r\n**Describe the current behavior**\r\nThe multinomial distribution has multiple variables where each variable takes a value that equals the probability of an unique action.\r\nWhen the network converges, as some of the probabilities are very small, the resulting gradient becomes NaN.\r\n\r\n**Describe the expected behavior**\r\nIt should provide the actual result instead of NaN.\r\n\r\n**Standalone code to reproduce the issue**\r\n[The jupyter notebook can produce the situation where the gradient becomes NaN](https://colab.research.google.com/drive/1IVb0s5Tt2BmibgKqLVojj3SoCi2TJctL?usp=sharing).", "comments": ["Hi @biplavc ! I was getting a different error in [2.7](https://colab.sandbox.google.com/gist/mohantym/9f0e30116a7ec36e9fb99ebff946eee6/uniquemultonomialdist.ipynb#scrollTo=cb795b94) . ", "Hello @mohantym and @biplavc !\r\n\r\nThe error for TF2.7 is fixed in the jupyter notebook.", "@prasenjit52282! The above Jupyter notebook is not updated yet.Hi @Saduf2019 ! Could you please look at this issue? Thank you.", "@prasenjit52282 \r\nCould you please try on colab and let us know,please share the gist for us to help you.", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53756\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53756\">No</a>\n"]}, {"number": 53755, "title": "Tensorflow 2.5  no work with RTX3070", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):ubuntu-18.04 from nvidia/cuda:11.2.2-cudnn8-devel-ubuntu18.04 dockers images\r\n- TensorFlow installed from (source or binary):tensorflow-gpu==2.5\r\n- TensorFlow version (use command below):2.5\r\n- Python version: 3.6.9\r\n\r\n- CUDA/cuDNN version:   11.2.2/8.1.1.33\r\n- GPU model and memory: GeForce RTX 3070 7982MiB \r\n- Driver Version: 460.73.01    CUDA Version: 11.2\r\n\r\nDescribe the current behavior\r\n\r\n\r\nthis model (ssdlite_mobilenet_v2_coco_2018_05_09) was trained and worked perfectly on the pascal architecture (P4000, P2200,620) , tensorfflow 2.1.0\r\n\r\nNow,  this model no works with  ampere architecture.  \r\ndo I have to train another model( more  recent )  to make it work ( objection detection) on this card? I admit being disappointed\r\n\r\n2022-01-13 15:06:05.231427: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\r\nDEBUG  | tensorflow           | 13.01 15:06:05.592 | MainThread | Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.\r\nDEBUG  | h5py._conv           | 13.01 15:06:05.756 | MainThread | Creating converter from 7 to 5\r\nDEBUG  | h5py._conv           | 13.01 15:06:05.757 | MainThread | Creating converter from 5 to 7\r\nDEBUG  | h5py._conv           | 13.01 15:06:05.757 | MainThread | Creating converter from 7 to 5\r\nDEBUG  | h5py._conv           | 13.01 15:06:05.757 | MainThread | Creating converter from 5 to 7\r\n2022-01-13 15:06:06.913294: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\r\nDEBUG  | tensorflow           | 13.01 15:06:07.238 | MainThread | Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.\r\nDEBUG  | h5py._conv           | 13.01 15:06:07.384 | MainThread | Creating converter from 7 to 5\r\nDEBUG  | h5py._conv           | 13.01 15:06:07.384 | MainThread | Creating converter from 5 to 7\r\nDEBUG  | h5py._conv           | 13.01 15:06:07.384 | MainThread | Creating converter from 7 to 5\r\nDEBUG  | h5py._conv           | 13.01 15:06:07.384 | MainThread | Creating converter from 5 to 7\r\n\r\n2022-01-13 15:06:07.604639: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2022-01-13 15:06:07.605714: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\r\n2022-01-13 15:06:07.605794: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2022-01-13 15:06:07.606156: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \r\npciBusID: 0000:01:00.0 name: GeForce RTX 3070 computeCapability: 8.6\r\ncoreClock: 1.725GHz coreCount: 46 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s\r\n2022-01-13 15:06:07.606178: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\r\n2022-01-13 15:06:07.608513: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\r\n2022-01-13 15:06:07.608551: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\r\n2022-01-13 15:06:07.609137: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\r\n2022-01-13 15:06:07.609413: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\r\n2022-01-13 15:06:07.610018: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\r\n2022-01-13 15:06:07.610494: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\r\n2022-01-13 15:06:07.610601: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\r\n2022-01-13 15:06:07.610717: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2022-01-13 15:06:07.611128: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2022-01-13 15:06:07.611518: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\r\n2022-01-13 15:06:07.611541: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\r\n2022-01-13 15:06:07.885629: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2022-01-13 15:06:07.885646: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \r\n2022-01-13 15:06:07.885649: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \r\n2022-01-13 15:06:07.885728: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2022-01-13 15:06:07.886190: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2022-01-13 15:06:07.886622: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2022-01-13 15:06:07.887028: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/device:GPU:0 with 6132 MB memory) -> physical GPU (device: 0, name: GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6)\r\n2022-01-13 15:06:07.887347: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2022-01-13 15:06:07.887722: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \r\npciBusID: 0000:01:00.0 name: GeForce RTX 3070 computeCapability: 8.6\r\ncoreClock: 1.725GHz coreCount: 46 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s\r\n2022-01-13 15:06:07.887751: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2022-01-13 15:06:07.888140: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2022-01-13 15:06:07.888499: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\r\n2022-01-13 15:06:07.888510: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2022-01-13 15:06:07.888514: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \r\n2022-01-13 15:06:07.888517: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \r\n2022-01-13 15:06:07.888554: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2022-01-13 15:06:07.888883: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2022-01-13 15:06:07.889206: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/device:GPU:0 with 6132 MB memory) -> physical GPU (device: 0, name: GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6)\r\n\r\n2022-01-13 15:06:07.902646: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2022-01-13 15:06:07.902992: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \r\npciBusID: 0000:01:00.0 name: GeForce RTX 3070 computeCapability: 8.6\r\ncoreClock: 1.725GHz coreCount: 46 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s\r\n2022-01-13 15:06:07.903029: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2022-01-13 15:06:07.903344: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2022-01-13 15:06:07.903676: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\r\n2022-01-13 15:06:07.903861: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2022-01-13 15:06:07.904215: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \r\npciBusID: 0000:01:00.0 name: GeForce RTX 3070 computeCapability: 8.6\r\ncoreClock: 1.725GHz coreCount: 46 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s\r\n2022-01-13 15:06:07.904241: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2022-01-13 15:06:07.904597: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2022-01-13 15:06:07.904998: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\r\n2022-01-13 15:06:07.905033: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2022-01-13 15:06:07.905036: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \r\n2022-01-13 15:06:07.905039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \r\n2022-01-13 15:06:07.905079: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2022-01-13 15:06:07.905395: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2022-01-13 15:06:07.905698: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6132 MB memory) -> physical GPU (device: 0, name: GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6)\r\n | MainThread | Model (/home/workingsrc/model/tensorflow/1_12/frozen_inference_graph.pb) placed on GPU:0\r\n2022-01-13 15:06:08.201813: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2022-01-13 15:06:08.202197: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \r\npciBusID: 0000:01:00.0 name: GeForce RTX 3070 computeCapability: 8.6\r\ncoreClock: 1.725GHz coreCount: 46 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s\r\n2022-01-13 15:06:08.202233: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2022-01-13 15:06:08.202661: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2022-01-13 15:06:08.203071: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\r\n2022-01-13 15:06:08.203089: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2022-01-13 15:06:08.203093: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \r\n2022-01-13 15:06:08.203096: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \r\n2022-01-13 15:06:08.203139: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2022-01-13 15:06:08.203500: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2022-01-13 15:06:08.203909: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6132 MB memory) -> physical GPU (device: 0, name: GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6)\r\n2022-01-13 15:06:08.250684: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2899885000 Hz\r\n2022-01-13 15:06:08.615925: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\r\n2022-01-13 15:06:08.974842: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8101\r\n2022-01-13 15:06:09.421154: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\r\n2022-01-13 15:06:09.751559: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\r\n", "comments": ["@dradenvandewind Could you please try to upgrade to latest TF version and refer [this](https://www.tensorflow.org/install/source) ,please let us know if it helps?Thanks!", "hello  i have update  my docker file  with cuda and cudnn with good tags .   it s ok now.", "@dradenvandewind \r\nThank you for the update!\r\nCould you please move this issue to closed status if it is resolved for you ?Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53755\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53755\">No</a>\n"]}, {"number": 53754, "title": "Master build fails on s390x arch due to FloatList struct changes in tpu/c_api_conversions.cc", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: Master\r\n- Python version: 3.6.9\r\n- Installed using virtualenv? pip? conda?: No\r\n- Bazel version (if compiling from source): 4.2.2- (@non-git)\r\n- GCC/Compiler version (if compiling from source): 7.5.0\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n\r\n\r\n**Describe the problem**\r\nRecently, master builds on `s390x` arch is failing due to following error:\r\n```\r\ntensorflow/stream_executor/tpu/c_api_conversions.cc:175:66:   required from here\r\ntensorflow/stream_executor/tpu/c_api_conversions.cc:164:15: error: cannot convert 'float*' to 'float_t* {aka double*}' in assignment\r\n     dst->heap = new Dst[dst->size];\r\n     ~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~\r\n```\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n```\r\nbazel --host_jvm_args=\"-Xms1024m\" --host_jvm_args=\"-Xmx2048m\" build  --define=tensorflow_mkldnn_contraction_kernel=0 --define tflite_with_xnnpack=false //tensorflow/tools/pip_package:build_pip_package\r\n```\r\n\r\n**Any other info / logs**\r\nI believe the problem occurs at this line: https://github.com/tensorflow/tensorflow/blob/276e5c51c310983923b8078bcf6fcf78844c6211/tensorflow/stream_executor/tpu/c_api_decl.h#L197\r\n\r\nI was able to successfully build by changing `float_t` occurrences in `FloatList` struct to `float`.  However, I am not sure if this change has a wider implication.\r\n\r\nAny help appreciated.\r\n\r\nThanks.", "comments": ["@rposts \r\nCould you please use a stable version, please use tf 2.6 or 2.7 and let us know if you still face any issues, as it is tested and verified versions.", "@Saduf2019 - problem happens on master branch as this is a new code introduced by this [commit](https://github.com/tensorflow/tensorflow/commit/dfd06f8cf01fb0a1cf12ca29f7798d16a692396a#diff-235daf4799407636e32920a062d4c08b50e10ef1c222df0c623c78c8cbc258ae) on Jan 4, 2022.", "@rposts \r\nHence please use stable versions that are already tested, as its master branch would have updates to it and is not tested as yet.", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53754\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53754\">No</a>\n", "2 month since initial post and still not resolved"]}, {"number": 53751, "title": "Keras Could not find matching function to load & run the model", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Windows 10\r\n- TensorFlow installed from (source or binary): conda install tensorflow\r\n- TensorFlow version:2.6.0  (CPU only)\r\n- Python version: 3.88\r\n- Installed using virtualenv? pip? conda?: conda\r\n\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nI am try train a TF Keras model (summary below) :-\r\n\r\nbert_en_uncased_L-12_H-768_A-12/4\r\n\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nI run model = build_model(bert_layer, max_len=160) but the model gives the error.\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\n\r\nValueError: in user code:\r\n\r\n    C:\\Users\\h.swamy\\Anaconda3\\lib\\site-packages\\tensorflow_hub\\keras_layer.py:237 call  *\r\n        result = smart_cond.smart_cond(training,\r\n    C:\\Users\\h.swamy\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:664 _call_attribute  **\r\n        return instance.__call__(*args, **kwargs)\r\n    C:\\Users\\h.swamy\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:885 __call__\r\n        result = self._call(*args, **kwds)\r\n    C:\\Users\\h.swamy\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:924 _call\r\n        results = self._stateful_fn(*args, **kwds)\r\n    C:\\Users\\h.swamy\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3038 __call__\r\n        filtered_flat_args) = self._maybe_define_function(args, kwargs)\r\n    C:\\Users\\h.swamy\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3463 _maybe_define_function\r\n        graph_function = self._create_graph_function(args, kwargs)\r\n    C:\\Users\\h.swamy\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3298 _create_graph_function\r\n        func_graph_module.func_graph_from_py_func(\r\n    C:\\Users\\h.swamy\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1007 func_graph_from_py_func\r\n        func_outputs = python_func(*func_args, **func_kwargs)\r\n    C:\\Users\\h.swamy\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:668 wrapped_fn\r\n        out = weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n    C:\\Users\\h.swamy\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\saved_model\\function_deserialization.py:288 restored_function_body\r\n        raise ValueError(\r\n\r\n    ValueError: Could not find matching function to call loaded from the SavedModel. Got:\r\n      Positional arguments (3 total):\r\n        * [<tf.Tensor 'inputs:0' shape=(None, 160) dtype=int32>, <tf.Tensor 'inputs_1:0' shape=(None, 160) dtype=int32>, <tf.Tensor 'inputs_2:0' shape=(None, 160) dtype=int32>]\r\n        * False\r\n        * None\r\n      Keyword arguments: {}\r\n    \r\n    Expected these arguments to match one of the following 4 option(s):\r\n    \r\n    Option 1:\r\n      Positional arguments (3 total):\r\n        * {'input_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_type_ids'), 'input_word_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_word_ids'), 'input_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_mask')}\r\n        * False\r\n        * None\r\n      Keyword arguments: {}\r\n    \r\n    Option 2:\r\n      Positional arguments (3 total):\r\n        * {'input_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_type_ids'), 'input_word_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_word_ids'), 'input_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_mask')}\r\n        * False\r\n        * None\r\n      Keyword arguments: {}\r\n    \r\n    Option 3:\r\n      Positional arguments (3 total):\r\n        * {'input_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_mask'), 'input_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_type_ids'), 'input_word_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_word_ids')}\r\n        * True\r\n        * None\r\n      Keyword arguments: {}\r\n    \r\n    Option 4:\r\n      Positional arguments (3 total):\r\n        * {'input_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_mask'), 'input_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_type_ids'), 'input_word_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_word_ids')}\r\n        * True\r\n        * None\r\n      Keyword arguments: {}\r\n", "comments": ["Hi @himswamy ! Could you please provide a stand alone code to reproduce this issue?", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "@mohantym  :- Below is the code\r\n\r\nimport numpy as np\r\nimport pandas as pd\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.layers import Dense, Input\r\nfrom tensorflow.keras.optimizers import Adam\r\nfrom tensorflow.keras.models import Model\r\nfrom tensorflow.keras.callbacks import ModelCheckpoint\r\nimport tensorflow_hub as hub\r\nfrom sklearn.model_selection import train_test_split\r\n\r\nimport tokenization\r\n\r\ndef bert_encode(texts, tokenizer, max_len=512):\r\n    all_tokens = []\r\n    all_masks = []\r\n    all_segments = []\r\n    \r\n    for text in texts:\r\n        text = tokenizer.tokenize(text)\r\n            \r\n        text = text[:max_len-2]\r\n        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\r\n        pad_len = max_len - len(input_sequence)\r\n        \r\n        tokens = tokenizer.convert_tokens_to_ids(input_sequence)\r\n        tokens += [0] * pad_len\r\n        pad_masks = [1] * len(input_sequence) + [0] * pad_len\r\n        segment_ids = [0] * max_len\r\n        \r\n        all_tokens.append(tokens)\r\n        all_masks.append(pad_masks)\r\n        all_segments.append(segment_ids)\r\n    \r\n    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)\r\n\r\n\r\ndef build_model(bert_layer, max_len=512):\r\n    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\r\n    input_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\r\n    segment_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\r\n\r\n    _, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\r\n    clf_output = sequence_output[:, 0, :]\r\n    out = Dense(1, activation='sigmoid')(clf_output)\r\n    \r\n    model = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=out)\r\n    model.compile(Adam(lr=1e-5), loss='binary_crossentropy', metrics=['accuracy'])\r\n    \r\n    return model\r\n\r\n%%time\r\nmodule_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\"  \r\nbert_layer = hub.KerasLayer(module_url, trainable=True)\r\n\r\ndef train_validate_test_split(df, train_percent=.6, validate_percent=.2, seed=None):\r\n    np.random.seed(seed)\r\n    perm = np.random.permutation(df.index)\r\n    m = len(df.index)\r\n    train_end = int(train_percent * m)\r\n    validate_end = int(validate_percent * m) + train_end\r\n    train = df.iloc[perm[:train_end]]\r\n    validate = df.iloc[perm[train_end:validate_end]]\r\n    test = df.iloc[perm[validate_end:]]\r\n    return train, validate, test\r\n\r\ntrain, validate, test = train_validate_test_split(data1)\r\n\r\nvocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\r\n\r\ndo_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\r\n\r\ntokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)\r\n\r\ntrain_input = bert_encode(train.text.values, tokenizer, max_len=160)\r\n\r\n\r\ntest_input = bert_encode(test.text.values, tokenizer, max_len=160)\r\n\r\ntrain_labels = train.Sub_Flag.values\r\nmodel = build_model(bert_layer, max_len=160)\r\nmodel.summary()", "Hi @himswamy !Sorry for the late response. Can you please provide above code as Colab gist? I was getting lot of import errors earlier . Attaching relevant threads for reference [1](https://stackoverflow.com/a/58836080/11530462), [2](https://stackoverflow.com/questions/68017902/could-not-find-matching-function-from-the-savedmodel) . It might be about matching the input shape with trained model shape or serializing the model .", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53751\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53751\">No</a>\n"]}, {"number": 53748, "title": "The custom op with nccl communication in MirroredStrategy cause hanging in the eager mode", "body": "I write a custom op with nccl communication, and I run it under the `MirroredStrategy` in the eager mode. The expected behavior is to do nccl communication in such an op among all replicas.\r\n\r\nAs the nccl communication waits util it is aware of all peers, the custom op hangs before other op replicas run. However, the python GIL restrict other op replicas running parallelly, which cause the training step hanging in a deadlock ...\r\n\r\nI need help to know whether my analysis above is correct or not about my unexpected hanging problem. And if it is correct, how can I fix it?\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux CentOS 7.2\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.6\r\n- Python version: 3.9.7\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: CUDA 11/cuDNN 8.1\r\n- GPU model and memory: V100 with 32GB", "comments": ["@gavin1332 ,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code and dataset to reproduce the issue reported here.", "As the code of my custom op is not open source, it is not easy to supply. Could we just have a discussion about whether it is possible to hang under my conidtion? If my analysis makes sense and it is not suggested to use nccl in custom op under the MirroredStrategy, I could change my implementation.", "@gavin1332 ,\r\nIf you are unable to provide the code, can you please post this question on TensorFlow [discussion Forum](https://discuss.tensorflow.org/) since it is not a bug or feature request. There is also a larger community that reads questions there.", "close this issue for no response for a long time", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53748\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53748\">No</a>\n"]}, {"number": 53747, "title": "F tensorflow/core/grappler/optimizers/constant_folding.cc:1172] Check failed: value->FromProto(raw_val)", "body": "Windows10/tf1.14.0\r\nwhen i runing my project\r\n\"\r\nEpoch 1/2\r\n2022-01-13 10:53:49.459951: W tensorflow/core/framework/allocator.cc:107] Allocation of 19874709504 exceeds 10% of system memory.\r\n2022-01-13 10:53:49.572648: W tensorflow/core/framework/allocator.cc:107] Allocation of 19874709504 exceeds 10% of system memory.\r\n2022-01-13 10:53:49.611016: F tensorflow/core/grappler/optimizers/constant_folding.cc:1172] Check failed: value->FromProto(raw_val)\r\n\r\nProcess finished with exit code -1073740791 (0xC0000409)\r\n\"\r\nwhat can i do ?", "comments": ["Hi @susoooon ! \r\nIt seems you are using older versions(1.x versions) of Tensorflow which is not supported any more. You can reduce the batch size in your model to see the difference.Attaching relevant [thread](https://stackoverflow.com/questions/50304156/tensorflow-allocation-memory-allocation-of-38535168-exceeds-10-of-system-memor) for reference.  Please post on SO for further assistance. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53747\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53747\">No</a>\n"]}, {"number": 53745, "title": "Small mathematical typo at https://www.tensorflow.org/guide/basics", "body": "\r\n## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/guide/basics\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nCurrently: \r\nAt x = 1.0, y = f(x) = (1**2 + 3 - 5) = -2\r\n\r\nProposed:\r\nAt x = 1.0, y = f(x) = (1**2 + 2 - 5) = -2\r\n\r\n### Submit a pull request?\r\n\r\nYes, I can submit a pull request if issue approved \r\n", "comments": ["will transfer issue to tensorflow/docs", "Nevermind, just read 'To file a docs issue, use the issue tracker in the tensorflow/tensorflow repo.'", "@urrutiag ,\r\nPlease feel free to submit a PR for the requested change or share the link where requested change is to be made\r\n", "have solved this issue and submitted a PR <br>\r\nhttps://github.com/tensorflow/docs/pull/1998", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Thanks @Cheril311! Appears fixed on the guide."]}, {"number": 53744, "title": "Conversion to TFLite crashes without any Error", "body": "### System information\r\n\r\n-   **Have I written custom code (as opposed to using a stock example script\r\n    provided in TensorFlow)**:\r\n-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10, 10.0.19043 Build 19043\r\n-   **TensorFlow installed from (source or binary)**: Binary\r\n-   **TensorFlow version (use command below)**: v2.5.0-rc3-213-ga4dfb8d1a71 2.5.0\r\n-   **Python version**: Python 3.8.2 (tags/v3.8.2:7b3ab59, Feb 25 2020, 23:03:10) [MSC v.1916 64 bit (AMD64)] on win32\r\n-   **CUDA/cuDNN version**: \r\n-   **GPU model and memory**: GeForce GTX 1050\r\n-   **Exact command to reproduce**:\r\n```\r\nimport tensorflow as tf\r\n\r\nmodel_file = 'mobilenet_v2_1.0_224_frozen_pb'\r\nconverter = tf.lite.TFLiteConverter.from_saved_model(model_file)\r\nconverter.experimental_new_converter = True\r\nconverter.allow_custom_ops = True\r\ntflite_model = converter.convert()\r\n\r\nwith open(model_file + '.tflite', 'wb') as f:\r\n    f.write(tflite_model)\r\n```\r\n[mobilenet_v2_1.0_224_frozen_pb.zip](https://github.com/tensorflow/tensorflow/files/7858479/mobilenet_v2_1.0_224_frozen_pb.zip)\r\n### Describe the problem\r\nWhen running this command with the model provided, the script terminates without any error message or conversion to TFLite. The model is created from converting an ONNX model to Saved Model using the onnx_tf library.\r\n\r\nExpected Behaviour: The model converts to TFLite or provides an error message for further debugging.\r\n\r\n### Source code / logs\r\n2022-01-12 16:02:06.422817: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2022-01-12 16:02:06.424495: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2022-01-12 16:02:06.426841: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]\r\n2022-01-12 16:02:21.969931: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:345] Ignored output_format.\r\n2022-01-12 16:02:21.970194: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:348] Ignored drop_control_dependency.\r\n2022-01-12 16:02:21.972195: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:354] Ignored change_concat_input_ranges.\r\n2022-01-12 16:02:21.974709: I tensorflow/cc/saved_model/reader.cc:38] Reading SavedModel from: mobilenet_v2_1.0_224_frozen_pb\r\n2022-01-12 16:02:22.188729: I tensorflow/cc/saved_model/reader.cc:90] Reading meta graph with tags { serve }\r\n2022-01-12 16:02:22.189000: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: mobilenet_v2_1.0_224_frozen_pb\r\n2022-01-12 16:02:22.190593: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2022-01-12 16:02:22.190790: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]\r\n2022-01-12 16:02:23.052605: I tensorflow/cc/saved_model/loader.cc:206] Restoring SavedModel bundle.\r\n2022-01-12 16:02:24.285677: I tensorflow/cc/saved_model/loader.cc:190] Running initialization op on SavedModel bundle at path: mobilenet_v2_1.0_224_frozen_pb\r\n2022-01-12 16:02:25.318756: I tensorflow/cc/saved_model/loader.cc:277] SavedModel load for tags { serve }; Status: success: OK. Took 3344022 microseconds.\r\n2022-01-12 16:02:29.185145: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:210] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\r\n2022-01-12 16:02:31.117089: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties:\r\npciBusID: 0000:01:00.0 name: GeForce GTX 1050 computeCapability: 6.1\r\ncoreClock: 1.442GHz coreCount: 6 deviceMemorySize: 3.00GiB deviceMemoryBandwidth: 78.32GiB/s\r\n2022-01-12 16:02:31.117492: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1766] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\r\nSkipping registering GPU devices...\r\n2022-01-12 16:02:31.558830: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2022-01-12 16:02:31.559036: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0\r\n2022-01-12 16:02:31.559895: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N\r\n\r\nThe command fully terminates at this line without anything further or debugging.\r\n\r\n", "comments": ["Hi @msquigle ! I could not find any issue in TF 2.7 . Attaching [gist](https://colab.sandbox.google.com/gist/mohantym/db9e3bb16b4e66d55aec2c916610c177/github_53744.ipynb#scrollTo=ltzDBqiYqPaO) for reference. Thank you!\r\n\r\n> converter.optimizations = [tf.lite.Optimize.DEFAULT] ", "Thank you! That also resolves the issue in 2.5! ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53744\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53744\">No</a>\n", "@mohantym So this partially solves my issue, I am looking to generate a full float TFLite, which adding that line does not allow. Is there a solution that is possible for generating a non-quantized TFLite model?", "@msquigle ! The original code is also working with out  \"`converter.optimizations = [tf.lite.Optimize.DEFAULT]\"`  snippet in 2.7. Thank you!\r\n\r\n", "Closing this issue as it is resolved in 2.7. Please reopen this issue if needed. Thank you!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53744\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53744\">No</a>\n"]}, {"number": 53740, "title": "hdf5_format.py method load_weights_from_hdf5_group() fails when you exclude layers", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **from https://github.com/ahmedfgad/Mask-RCNN-TF2** with some other TF2 fixes\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  **Windows Pro**\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:  **n/a**\r\n- TensorFlow installed from (source or binary):  **via pip install**\r\n- TensorFlow version (use command below):  **v2.7.0-rc1-69-gc256c071bb2 2.7.0**\r\n- Python version:   **v3.7.3:ef4ec6ed12, Mar 25 2019, 22:22:05) [MSC v.1916 64 bit (AMD64)] on win32**\r\n- Bazel version (if compiling from source):   **n/a**\r\n- GCC/Compiler version (if compiling from source):   **n/a**\r\n- CUDA/cuDNN version:   **cuda_11.2.r11.2/compiler.29373293_0**\r\n- GPU model and memory:   **Quadro 2000 32GB**\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\n**No windows version**\r\n\r\n**Describe the current behavior**\r\nWhen you call `load_weights()` using the `exclude=` parameter you get errors like \"**You are trying to load a weight file containing 233 layers into a model with 229 layers.**\". Several issues have been posted about this type error but none of them addressed the fundamental problem which is in the method `load_weights_from_hdf5_group()`.\r\n```\r\nif len(layer_names) != len(filtered_layers):\r\n    msg = f'You are trying to load a weight file containing {str(len(layer_names))} layers into a '\\\r\n          f'model with {str(len(filtered_layers))} layers.'\r\n    raise ValueError(msg)\r\n```\r\n\r\n**Describe the expected behavior**\r\nDepending on which way layers count goes either being greater than or less than we can either auto-correct the layers or report the actual layer that is missing when it checks for matching layer sizes:\r\n\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n- Do you want to contribute a PR? (yes/no):  **yes**\r\n- Briefly describe your candidate solution(if contributing):\r\n**see https://github.com/tensorflow/tensorflow/pull/53739**\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["@quaesitor-scientiam \r\n Could please share complete code to replicate the issue or a gist with the error reported for us to help you resolve it.", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53740\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53740\">No</a>\n"]}, {"number": 53739, "title": "hdf5_format.py bug/enhancement fix", "body": "When you call `load_weights()` using the `exclude=` parameter you get errors like \"**You are trying to load a weight file containing 233 layers into a model with 229 layers.**\". Several issues have been posted about this type error but none of them addressed the fundamental problem which is in the method `load_weights_from_hdf5_group()`.\r\n\r\nDepending on which way layers count goes either being greater than or less than we can either auto-correct the layers or report the actual layer that is missing when it checks for matching layer sizes:\r\n```\r\nif len(layer_names) != len(filtered_layers):\r\n    msg = f'You are trying to load a weight file containing {str(len(layer_names))} layers into a'\\\r\n          f'model with {str(len(filtered_layers))} layers.'\r\n    raise ValueError(msg)\r\n```\r\nwith:\r\n```\r\n  if len(layer_names) != len(filtered_layers):\r\n    if len(layer_names) > len(filtered_layers):\r\n      for name in layer_names:\r\n        if name in filtered_layers.keys(): continue\r\n        layer_names.remove(name)\r\n    else:\r\n      missing_layer_names = []\r\n      for name in filtered_layers.keys():\r\n        if name in layer_names: continue\r\n        missing_layer_names.append(name)\r\n      msg = f'You are trying to load a weight file containing {str(len(layer_names))} layers into a '\\\r\n            f'model with {str(len(filtered_layers))} layers. Missing layer names are: {missing_layer_names}'\r\n      raise ValueError(msg)\r\n```\r\nNow if we call with an empty exclude list we get this message **\"You are trying to load a weight file containing 233 layers into a model with 234 layers. Missing layer names are: ['anchors']\"**\r\n\r\nWith enhanced message we now know the missing name and it can be added it to the exclude list and the call will work instead of wondering what is wrong.\r\n\r\n[hdf5_format.zip](https://github.com/tensorflow/tensorflow/files/7856823/hdf5_format.zip)\r\n\r\n", "comments": ["Check out this pull request on&nbsp; <a href=\"https://app.reviewnb.com/tensorflow/tensorflow/pull/53739\"><img align=\"absmiddle\"  alt=\"ReviewNB\" height=\"28\" class=\"BotMessageButtonImage\" src=\"https://raw.githubusercontent.com/ReviewNB/support/master/images/button_reviewnb.png\"/></a> \n\n See visual diffs & provide feedback on Jupyter Notebooks. \n\n---\n\n <i>Powered by <a href='https://www.reviewnb.com/?utm_source=gh'>ReviewNB</a></i>", "Please open against `master` branch and make sure it only includes the relevant commits."]}]