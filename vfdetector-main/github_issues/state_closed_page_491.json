[{"number": 39051, "title": "GPU Kernel for SparseFillEmptyRows OP", "body": "**System information**\r\n- TensorFlow version : 1.13.1\r\n- Are you willing to contribute it \uff1aYes\r\n\r\nI found that `SparseFillEmptyRowsOP` does not have GPU kernel support. Can someone explain the following reasons for that to me?\r\n\r\nIn my training, SparseFillEmptyRows executed on the CPU consumes a lot of time cost. Therefore, if you can move SparseFillEmptyRows OP to the GPU, I think there will be a considerable performance improvement.", "comments": ["@firejq \r\n\r\nDo you have any use case that requires the feature you are interested in? Please feel free to submit a PR if you have use cases that supports that feature.Thanks!", "> @firejq\r\n> \r\n> Do you have any use case that requires the feature you are interested in? Please feel free to submit a PR if you have use cases that supports that feature.Thanks!\r\n\r\nThanks for your attention and I will make some attempts to support this op.\r\n\r\nRegarding my use case, it is a training for recommended system with massive sparse features. Here is [a related question](https://stackoverflow.com/questions/61520266/why-so-few-gpu-kernels-for-the-sparse-operation-in-tensorflow) I have asked on StackOverFlow with a specific timeline. If you don\u2019t mind, maybe you can help me answer this question, i.e. **why so few GPU kernels for the sparse operation in tensorflow?** Thanks anyway!", "Closing this since the [GPU kernel](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/sparse_fill_empty_rows_op_gpu.cu.cc) has been added in https://github.com/tensorflow/tensorflow/pull/46172. (Thank you very much, @benbarsdell!)\r\n"]}, {"number": 39049, "title": "AttributeError: module 'tensorflow.python.data.experimental.ops.optimization' has no attribute 'AUTOTUNE'", "body": "system:ubuntu18.04\r\ntf:2.0.0b0\r\npython:3.6.9\r\n\r\nI want to train a model for object recognition\uff0cThen I run [python3 train.py --logtostderr --train_dir=training/ --pipeline_config_path=ssd_mobilenet_v2_quantized_300x300_coco.config]\r\n\r\nGet this error\uff1aAttributeError: module 'tensorflow.python.data.experimental.ops.optimization' has no attribute 'AUTOTUNE'\r\n\r\n", "comments": ["@LINYOUWEI0804\r\nPlease share simple standalone code to replicate the issue faced, along with the tensorflow version used.", "this my pipeline_config_path: [ssd_mobilenet_v2_quantized_300x300_coco.config.txt](https://github.com/tensorflow/tensorflow/files/4557323/ssd_mobilenet_v2_quantized_300x300_coco.config.txt)\r\n\r\ntensorflow version:2.0.0b0\r\n", "I follow this instruction\uff1a\u300chttps://chtseng.wordpress.com/2019/02/16/%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8google-object-detection-api%E8%A8%93%E7%B7%B4%E8%87%AA%E5%B7%B1%E7%9A%84%E6%A8%A1%E5%9E%8B/   \u300d", "@LINYOUWEI0804\r\nI ran the code shared and it says invalid syntax, please share indented complete stand alone code or if possible share colab gist with the error for us to analyse.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39049\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39049\">No</a>\n"]}, {"number": 39048, "title": "[INTEL_MKL] Threadpool changes with dnnl 1.4 release.", "body": "Adding const qualifier to a few functions inorder to keep up with the DNNL1.4 rls interface changes.", "comments": ["@penpornk Sorry, just realized i had the logic for balance reversed. Kindly approve again and apologize for the trouble. :-)"]}, {"number": 39047, "title": "Docstring is not misleading.", "body": "The docstring says \" it is a negative quantity between -1 and 0, where 0 indicates orthogonality and values closer to -1 indicate greater similarity\". Although it is true that the function reverses the sign of the classic cosine similarity so that -1 will denote \"similarity\" instead of 1 in the original formula, the actual range is still -1 to 1 (not -1 to 0 as misleading by the docstring). \r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/e5bf8de410005de06a7ff5393fafdf832ef1d4ad/tensorflow/python/keras/losses.py#L1073", "comments": ["@MarkDaoust Are you working on this issue? If not I can pick this. Thanks!", "This is fixed on master."]}, {"number": 39046, "title": "when using \"tensorboard --logdir\", reported \"ImportError: No module named '_markerlib\"", "body": "when run the code\r\n`cd  E:\\python3\\tensorflow1\\Flower\\log`\r\n`tensorboard --logdir`\r\nreport error:\r\n`Traceback (most recent call last):\r\n  File \"d:\\appdatas\\anaconda3\\envs\\tensorflow\\lib\\runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"d:\\appdatas\\anaconda3\\envs\\tensorflow\\lib\\runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"D:\\AppDatas\\Anaconda3\\envs\\tensorflow\\Scripts\\tensorboard.exe\\__main__.py\", line 7, in <module>\r\n  File \"d:\\appdatas\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\main.py\", line 58, in run_main\r\n    default.get_plugins() + default.get_dynamic_plugins(),\r\n  File \"d:\\appdatas\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\default.py\", line 110, in get_dynamic_plugins\r\n    for entry_point in pkg_resources.iter_entry_points('tensorboard_plugins')\r\n  File \"d:\\appdatas\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\default.py\", line 110, in <listcomp>\r\n    for entry_point in pkg_resources.iter_entry_points('tensorboard_plugins')\r\n  File \"e:\\python3\\whls\\distribute-0.7.3\\pkg_resources.py\", line 2241, in load\r\n    if require: self.require(env, installer)\r\n  File \"e:\\python3\\whls\\distribute-0.7.3\\pkg_resources.py\", line 2254, in require\r\n    working_set.resolve(self.dist.requires(self.extras),env,installer)))\r\n  File \"e:\\python3\\whls\\distribute-0.7.3\\pkg_resources.py\", line 2471, in requires\r\n    dm = self._dep_map\r\n  File \"e:\\python3\\whls\\distribute-0.7.3\\pkg_resources.py\", line 2682, in _dep_map\r\n    self.__dep_map = self._compute_dependencies()\r\n  File \"e:\\python3\\whls\\distribute-0.7.3\\pkg_resources.py\", line 2699, in _compute_dependencies\r\n    from _markerlib import compile as compile_marker`\r\n`ImportError: No module named '_markerlib'`\r\nbg: tf-gpu 1.5 win10 X64 anaconda", "comments": ["@jz1998,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here. Thanks!", "Also, please check [this StackOverflow comment](https://stackoverflow.com/a/41162847) on a similar issue and let us know if it helps. Thanks!", "i find other way to solve this problem.\r\nthe complete code... just i run my train.py and save the log.\r\nthen i cd..... to my project index \r\n`cd E:\\python3\\tensorflow1\\Flower`\r\n`tensorboard --logdir=log`\r\n\r\nso reported those error.\r\n\r\nbut when i deactivate this environment and activate another \r\nstill run the two line code.\r\nsuccessful! \r\n\r\nmaybe the installation of tensorflow exist some wrong.\r\n\r\nThese operation conducted in anaconda powershell prompt.\r\nTHX! ", "@jz1998,\r\nIs this still an issue? Please feel free to close the issue if resolved. Thanks!"]}, {"number": 39045, "title": "tensorflow 2.0 does not detect the gpus ", "body": "actually I have 2 gpus but \r\n\r\n```\r\n> gpus = tf.config.experimental.list_physical_devices('GPU')\r\n> [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\r\n> \r\n```\r\n\r\nbut this only detect the first gpu ", "comments": ["Is CudNN and CUDA both installed on the GPUs?\r\nIs the version as per tensorflow requirements ?\r\nI see that first GPU is detected.\r\n\r\n> \r\n> \r\n> actually I have 2 gpus but\r\n> \r\n> ```\r\n> > gpus = tf.config.experimental.list_physical_devices('GPU')\r\n> > [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\r\n> > \r\n> ```\r\n> \r\n> but this only detect the first gpu\r\n\r\n", "@SlowMonk \r\nPlease update as per above comments ", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39045\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39045\">No</a>\n"]}, {"number": 39044, "title": "Tensorflow GPU installation ", "body": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/install/gpu\r\n\r\n## Description of issue (what needs changing):\r\n\r\nThe tf-nightly pip package does not support GPU. It should be: tf-nightly-gpu\r\n\r\nOn the Windows Setup section, the path:\r\n\r\nSET PATH=C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.1\\extras\\CUPTI\\libx64;%PATH%\r\n\r\nshould be:\r\n\r\nSET PATH=C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.1\\extras\\CUPTI\\lib64;%PATH% \r\n\r\nSince the CUDA toolkit generates this path with lib64 and not libx64.\r\n", "comments": ["Thanks for the issue. This is fixed now.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39044\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39044\">No</a>\n"]}, {"number": 39043, "title": "Remove unnecessary objc_library target", "body": "With the current versions of rules_swift + rules_apple we no longer need\r\na shim `objc_library` target to interface with Swift, or to build a\r\n`ios_static_framework`. This simplifies building these iOS targets by\r\ndepending on the `cc_library` directly.", "comments": ["Adding in @teijeong and @yyoon to confirm, but looks good on my end, thanks!", "IIRC, the duplicate symbols problem occurred when building / linking the Flex delegate (i.e. `TensorFlowLiteSelectTfOps_framework`) to the final iOS app. Let me verify if that flow works with this PR and get back here.", "Seems to work. Thanks! I needed to resolve an undefined symbol error, but it's unrelated to this PR, which needs to be fixed separately.", "Thanks!"]}, {"number": 39042, "title": "Fixed recompute grad issue - no memory savings", "body": "This PR addresses an issue where no memory saving was observed with gradient checkpointing in eager mode.\r\nResults can be found here - https://github.com/pidajay/tf2_gradient_checkpointing/blob/master/Results_tf_recompute_grad_bug_fix.txt\r\nSummary: Peak memory for a sample CNN model before fix is 3.3 GB and after fix is 704 MB.\r\nThis is the script used to generate results - https://github.com/pidajay/tf2_gradient_checkpointing/blob/master/run_recompute_grad_with_profile.py.", "comments": ["There seems to be a lack of documentation on how to use this feature. I have a tutorial in works over here - https://github.com/pidajay/tf2_gradient_checkpointing/blob/master/tf_recompute_grad_tutorial.ipynb. I would be happy to add it to tensorflow docs if someone can point me to the right location.\r\n", "The use of this feature depends on the user having to manually partition the model. This can be an unpleasant user experience in many cases. For example someone might just be interested in transfer learning by leveraging a very large pre-trained model. I have created a github issue with preliminary solution over here - https://github.com/tensorflow/tensorflow/issues/38766", "@alextp  Looking for guidance on a strategy to test this. The benefits of this feature can only be seen on large models that generate huge number of intermediate activations. I can think of two ways\r\n1. Train one step without grad checkpointing on a GPU that causes OOM. Then successfully train the same model with grad checkpointing on same GPU without OOM. But this approach assumes specific hardware config for running tensorflow tests which may not be desirable.\r\n2. Train one step on CPU with and without grad checkpointing and profile the memory. This is what I have shown [here](https://github.com/pidajay/tf2_gradient_checkpointing/blob/master/Results_tf_recompute_grad_bug_fix.txt). But again this involves training a large model in a tensorflow test on a CPU which is not desirable.\r\nI am not sure if there exists an easy way to profile GPU memory. Then step 2 on a GPU might be plausible. Any thoughts?", "You're proposing a change to TF's public API and for us to review it you should be able to write documentation specifying how this change needs to be used and to write a unit test that exercises this change.\r\n\r\nI will say though that I do not like the API change, and I also don't understand why replacing the variable watcher with an explicit list of variables solves the problem. Can't we fix the problem by fixing the variable watcher without any API changes?", "@alextp . Thanks for your comments and appreciate your patience, especially since this is my first PR to TF core :).\r\nI understand API change is a hassle. The hatchet was definitely required in TF2.1 where there was no variable_watcher and tape.watch was storing all the intermediate outputs while tape.stop_recording would not give me the trainable variables. It is quite possible this may not be the case anymore with variable_watcher. I will try to explore ways to avoid this API change and build a more solid case. Thanks!", "Thanks! Please keep me updated on your progress, and post here if you get\nstuck.\n\nOn Mon, May 4, 2020 at 2:39 PM pidajay <notifications@github.com> wrote:\n\n> @alextp <https://github.com/alextp> . Thanks for your comments and\n> appreciate your patience, especially since this is my first PR to TF core\n> :).\n> I understand API change is a hassle. The hatchet was definitely required\n> in TF2.1 where there was no variable_watcher and tape.watch was storing all\n> the intermediate outputs while tape.stop_recording would not give me the\n> trainable variables. It is quite possible this may not be the case anymore\n> with variable_watcher. I will try to explore ways to avoid this API change\n> and build a more solid case. Thanks!\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/39042#issuecomment-623722086>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAABHRNGMDRWGIKABU5GF6TRP4YZLANCNFSM4MUEMYXQ>\n> .\n>\n\n\n-- \n - Alex\n", "@alextp Turns out API change is not necessary. The introduction of variable watcher post tf 2.1 voids the need for this. I have updated the PR and added tests to show the efficacy of the fix. Additional memory profile results can be found [here](https://github.com/pidajay/tf2_gradient_checkpointing/blob/master/Results_tf_recompute_grad_bug_fix.txt). If the code changes look ok I can look into fixing the doc as the current doc is quite sparse with no explanation on how to use this feature. Thanks!", "@pidajay can you please check build failures.", "@rthadur gradient_checkpoint_test.py fails because it needs to run only on GPU. I guess I need to tag it as a cuda_py_test. I will investigate the other failing test (forward_prop_test) tonight. Thanks!", "@alextp My minor modification to recompute_grad seems to have impacted testCustomGradientRecomputeGrad(). This test tries to use recompute_grad to compute gradients in forward mode differentiation. I am not an expert but intuitively this does not make sense to me. The point of recompute_grad is to save memory while using reverse mode auto diff. My options\r\n1. Eliminate the test if it serves no purpose. \r\n2. If the test does serve a purpose then I got a problem on my hands. Gradient checkpointing saves memory by not saving intermediate activations. So it is fundamentally incompatible with forward mode diff. Back to the drawing board?\r\n\r\nThanks! ", "@allenlavoie the comment by @pidajay makes me think we should delete that test. WDYT?", "To be clear that test isn't about saving memory, just that forwardprop doesn't crash and gives the right answer with recompute_grad. The program in that test is not even crashing, it's just giving the wrong answer (0) silently. So just deleting the test is definitely not the right thing to do.\r\n\r\nIt's catching a correctness issue here that's not related to forwardprop infrastructure (i.e. a user could reproduce it with some GradientTapes). With this change we're basically inserting some stop_gradients that define gradients with respect to args/kwargs of the custom gradient function to be zero when they aren't.\r\n\r\nWe don't have to support transposing recompute_grad-decorated things on a tape necessarily, so defining a new inner nested custom_gradient that throws an error here is an option (in which case please just modify the test to look for the error instead of a correct gradient). Or we could define an inner nested custom_gradient that gives the right answer (and maybe throw a warning that it's probably not saving memory?). `tf.custom_gradient`'s docstring mentions how to define gradients for forwardprop: https://www.tensorflow.org/api_docs/python/tf/custom_gradient", "@allenlavoie Thanks for the detailed response. I like both your suggestions :). However for me to execute any of those recompute_grad will need to know if it is in forward or reverse mode. I can think of doing it two ways, explicitly through an optional arg or implicitly through **kwargs. Either ways wouldn't this constitute an API change and isn't that a problem?", "You can do all of this with just more custom_gradient decorators:\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\n@tf.custom_gradient\r\ndef original_f(x):\r\n  y = x * 2.\r\n\r\n  @tf.custom_gradient\r\n  def f_grad(dy):\r\n\r\n    @tf.custom_gradient\r\n    def f_grad_impl(x_dupe):\r\n\r\n      def second_order(ddy):\r\n        raise ValueError(\"You tried to take a second-order gradient of original_f\")\r\n\r\n      return dy * 2, second_order\r\n\r\n    def transpose(ddy):\r\n      raise ValueError(\"You tried to transpose original_f!\")\r\n\r\n    return f_grad_impl(x), transpose\r\n\r\n  return y, f_grad\r\n\r\nwith tf.GradientTape(persistent=True) as tape:\r\n  x = tf.constant(1.)\r\n  tape.watch(x)\r\n  y = original_f(x)\r\n  grad = tape.gradient(y, x)\r\n\r\n  try:\r\n    grad_grad = tape.gradient(grad, x)\r\n  except ValueError as e:\r\n    assert \"second-order\" in str(e)\r\n\r\n  tangent = tf.constant(1.)\r\n  tape.watch(tangent)\r\n  grad = tape.gradient(y, x, tangent)\r\n\r\n  try:\r\n    transpose = tape.gradient(grad, tangent)\r\n  except ValueError as e:\r\n    assert \"transpose\" in str(e)\r\n```\r\n\r\nThe \"transpose\" path is what is being triggered by the forwardprop test. But it's also checking second-order gradients, so you may have to do something similar there (do we not have other tests for second-order gradients of recompute_grad?).", "Actually second-order gradients look like they're fine. So maybe ignore that part.", "@pidajay Can you please check @allenlavoie's comments and keep us posted. Thanks!", "@gbaned Planning to update the PR this afternoon. Thanks!", "@allenlavoie Thanks for the explanation and the code snippet. That clarified things for me. I have tried to incorporate your suggestions. Please let me know if they look ok.", "How do I specify a test to be GPU only? I thought the label cuda_py_test will automatically do it for you. But it looks the the internal CI system tries to run it on CPU too.", "You can skip the test on CPU, like this: https://github.com/tensorflow/tensorflow/blob/f38355dab31bb466e9fdc900089dcd4abba536d6/tensorflow/python/eager/tensor_test.py#L80-L82", "Actually can you add a test for higher-order backward gradients too? Like I say based on what was failing in _test_gradients in the forwardprop tests they're probably fine, but as far as I can see we're not testing them. You can copy _test_gradients and omit the forward-mode bits and we can use that in gradients_test.py if you want.", "Sorry I think I missed the last part. If I understood it right, we are not explicitly testing the higher order backward gradients since I moved the assertRaisesRegexp around the whole of _test_gradients. So you are suggesting I create another _test_gradients to just test the backward gradients and possibly move this method into /tensorflow/python/ops/gradients_test.py?", "Oh, right, that's why you had the argument in the forwardprop test. Sorry for the ping-ponging. Yeah I think that's probably cleaner than having a backward-only test in the forwardprop test suite. I certainly wouldn't think to look there. If you remove the forwardprop bits _test_gradients should be trivial to copy I think (just _grad and _test_gradients?).\r\n\r\nIf you want you can move the transpose error message test next to the other recompute_grad tests too. It doesn't need the forwardprop _test_gradients implementation to reproduce, you can either use a GradientTape like in my example or just a manual ForwardAccumulator.", "Ok that sounds good to me. Will work on it and update the PR possibly tomorrow morning. Thanks for your patience and appreciate all the suggestions. ", "@allenlavoie I reorganized the tests as you suggested. Sorry for the delay. I am having trouble executing the tests on my setup. Some of these tests fail locally in graph mode even prior to any of my changes. I noticed some of the gradients tests have been decorated with @test_util.deprecated_graph_mode_only. Also the bazel label for the entire gradients test target is 'no_oss'. Not sure if these tests meant to be executed on the github CI?", "Oh wow, disabled 2 years ago because of flakiness on GPUs. Yeah, with no_oss they won't run on the github CI. The deprecated_graph_mode_only decorators mean we don't run them with 2.x behavior, probably because they assume Graph+Sessions. I wouldn't add it to new tests, but we do still run them in some places.\r\n\r\nYou can start a new test suite (custom_gradient_test.py ?) if you want to work around the no_oss tag for now. But if you add it to that file we do have CI builds that run those tests still. I tried and they do run internally; which errors are you seeing?", "These are the errors I see which seem to predate my changes. But if they do run successfully on your internal system, then I will re-verify on my end.\r\n\r\nERROR: testFnRecomputeWithScopeGradientTape (__main__.VariablesGradientTest)\r\nValueError: The custom_gradient decorator currently supports keywords arguments only when eager execution is enabled.\r\n\r\nERROR: testFnRecomputeWithScopeGradients (__main__.VariablesGradientTest)\r\nValueError: The custom_gradient decorator currently supports keywords arguments only when eager execution is enabled.\r\n\r\nERROR: testFnRecompute (__main__.VariablesGradientTest)\r\ntensorflow.python.framework.errors_impl.FailedPreconditionError: Error while reading resource variable test/test_var from Container: localhost. This could mean that the variable was uninitialized. Not found: Container localhost does not exist. (Could not find resource: localhost/test/test_var)\r\n\t [[{{node test/ReadVariableOp}}]] ", "My bad. Looks like the some of the failed tests are indeed capturing a problem. In my quest to make things work in eager mode, I never paid attention to graph mode. Seems like the design to use nested custom gradients is not sitting happy with the graph_mode_decorator. Specifically graph mode decorator is not happy with kwargs while we do have to make use of kwargs in the nested calls.", "Ugh, that's annoying. Is it just the `variables` argument? I think if you take that explicitly it'll be OK\r\n\r\nOtherwise you can work around it with `nest.flatten` and `nest.pack_sequence_as` (pass arguments through custom_gradient as a flat list, re-structure them inside). \r\n", "It is not just that. I think the root cause has something to do with the use of resource variables. Somehow it does not seem happy with the resource variables that appear in the nested call.\r\n\r\nThis is the mini-test I run\r\n```\r\n# this passes\r\ndef testFnRecompute(self):\r\n\ttest_input = constant(np.zeros((1, 2), dtype=np.float32))\r\n\tgrads_re, grads = self._TestFnVariablesGradient(test_input, TestFn, test_input)\r\n\r\n# this will fail\r\ndef testFnRecompute(self):\r\n\ttest_input = constant(np.zeros((1, 2), dtype=np.float32))\t\r\n\twith variable_scope.variable_scope(\"test\", use_resource=True):\r\n             test_var = variable_scope.get_variable(name=\"test_var\",\r\n             shape=2, trainable=True)\r\n        grads_re, grads = self._TestFnVariablesGradient(test_input, TestFn, test_var)\r\n```\r\nIt fails with this error message.\r\ntensorflow.python.framework.errors_impl.FailedPreconditionError: Error while reading resource variable test/test_var from Container: localhost. This could mean that the variable was uninitialized. Not found: Container localhost does not exist. (Could not find resource: localhost/test/test_var)\r\n\t [[{{node test/ReadVariableOp}}]] \r\nThis seems to be the line in the graph mode decorator that triggers it. \r\n``` args = [ops.convert_to_tensor(x)for x in args] ```", "Oh, ha, so the test just isn't initializing its variable, and previously that was fine because the value was never used? I think it's fine to insert a self.evaluate(test_var.assign(tf.zeros([10]))) to initialize it if so.", "Thanks @allenlavoie. That fixed it. Looks like working with eager mode has spoilt me :). I have updated the PR. I had to re-wire the 'variable scope' deprecated graph mode tests to make them pass. Specifically defining a new variable scope within a function call exercises the kwargs in graph mode decorator which raises an exception. My other option would be to modify the graph mode decorator which I feel might be riskier. I hope that is ok. But if this is a valid user scenario then I guess I need to take that route.  Now all the tests pass on my setup. Hopefully the CI does not grumble!", "For now can we work around the `variables` keyword issue by adding a function in between that converts it to a positional argument?\r\n\r\n```\r\ndef forward(*args, **kwargs):\r\n  ...\r\n  def grad_wrapper(*output_grads, variables=None):\r\n    @tf.custom_gradient\r\n    def grad(variables, *output_grads):\r\n      ...\r\n    return grad(variables, *output_grads)\r\n```\r\n\r\nI agree that fixing the graph-mode decorator is a more satisfying solution. But it'd be good to avoid regressing on recompute_grad if we can work around it.", "Sounds reasonable. Will work on it.", "Done! But down to one last test - testFnRecomputeWithScopeGradients. Unfortunately it just hangs without any explanation on my system. Will try to investigate later. Meanwhile if the changes look ok it will be nice to see if the same issue occurs on CI. Thanks again!", "@alextp Thanks for triggering the CI. But I think the concerned tests are marked as no_oss. These are the gradients_test target in tensorflow/python/BUILD. I think you might need to trigger an internal CI somewhere. ", "@allenlavoie Is there anything I need to do? Did the internal CI pass?", "@allenlavoie Copybara looks unhappy. Is there anything I need to do?", "Ah, yeah, everything else seems OK now but python:gradients_test is timing out on testFnRecomputeWithScopeGradients. It looks like ` self.evaluate(test_var.assign(...` just needs to move outside the TestFn. You can just run tf.global_variables_initializer (looking the variable up in the global collection) or something like that if it's easier.\r\n\r\nThe issue is that tf.gradients grabs a lock for the graph (since it mutates it), and Session.run grabs the same lock (though self.evaluate, since it requires the graph to stay the same while it Session.runs). The lock isn't reentrant so it deadlocks. The easy fix is just to not run Session.run calls while tf.gradients is mutating the graph.", "Ah, got it. I have pushed the changes. It  seems to work now locally. I will keep my fingers crossed :)", "@allenlavoie You might need to jumpstart copybara", "Do I need to do something on my end regarding the MacOS python2 failure? The errors do not seem related to my changes.", "No action needed; if there are a bunch of unrelated failures it probably means the presubmit has been marked as non-blocking for now. It's running some final tests now, I'll let you know if there are failures.", "In tensorflow/python:gradients_test, VariablesGradientTest.testCustomGradientRecomputeGradHigherOrder says \"TypeError: If using @custom_gradient with a function that uses variables, the enclosing variable scope must have use_resource=True.\"\r\n\r\nI think the issue is that it's trying to run with v2 behaviors disabled (among the many other configurations). Can you add a run_v2_only decorator to the test? Like this: https://github.com/tensorflow/tensorflow/blob/3e95e9f03aea5592eef2bcfa6eb8ec94cbb73db3/tensorflow/python/ops/stateful_random_ops_test.py#L92\r\n\r\nThere's no reason to worry about v1 here, it's just a quirk of the test infrastructure.", "How can I update my tensorflow so that I use this new changes?  \r\nAnd how is the correct way to use it?\r\n\r\nWhat a awesome feature!!", "Thanks guys for helping get this PR through. Really appreciate all your help and your patience! ", "@rafafael03 Since the PR is merged you should be able to get it from the tf-nightly build (pip install tf-nightly-gpu) from tomorrow I assume. You can find an example of how to use this feature over [here](https://github.com/pidajay/tf2_gradient_checkpointing/blob/master/tf_recompute_grad_tutorial.ipynb). Unfortunately you still have to manually partition/split the model to see the benefits. I had something in the works where this thing can be done automatically without manual split and better memory savings. You can find it [here](https://github.com/pidajay/tf2_gradient_checkpointing/blob/master/gradient_checkpointing.py) with an example how to use it [here](https://github.com/pidajay/addons/blob/grad_checkpointing_eager/docs/tutorials/training_gradient_checkpointing.ipynb). But currently it works only in eager mode for sequential models only. Hopefully if I find some time I can polish it and try to get it over to TF core."]}, {"number": 39041, "title": "tensorflowrun for distributed training (MultiWorkerMirroredStrategy & ParameterServerStrategy)", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 2.2\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nThere currently is no unified way to run multiworkermirroredstrategy. From the tutorials we are expected to start each script on each instance manually. On GCP tutorials it comes with a premade run script. \r\n\r\nHorovod has horovodrun which like mpirun. For tensorflow, why don't create a tensorflowrun. \r\n\r\nBasic features of the horovodrun. \r\ntensorflowrun --n 2 --np 2 --clusterSpec cspec python tensorflow_script.py\r\nRun on 2 workers, two processes locally\r\nThe clusterspec passed to tensorflowrun can have assumptions or explicitly setup. \r\ntask ids will be defined by index in cluster\r\n\r\nExample:\r\n{\"cluster\": {\"worker\": [\"192.168.1.1:5555\", \"192.168.1.2:5555\"]}}\r\ntask id 0 assigned to *.1\r\ntask id 1 assigned to *.2\r\n\r\n{'cluster': {'chief': ['10.0.0.4:2224'], 'worker': ['10.0.0.4:2223', '10.0.0.5:2222', '10.0.0.6:2222'], 'ps': ['10.0.0.4:2222']}, 'environment': 'cloud'}\r\n\r\nworker\r\ntask id 0 *4\r\ntask id 1 *5\r\ntask id 2 *6\r\n\r\nps \r\ntask id 0 *4\r\n\r\n\r\n**Will this change the current api? How?**\r\nNo APIs will change\r\n\r\n**Who will benefit with this feature?**\r\nAnyone trying to run MultiWorkerMirrorredStrategy, Parameter Server can also be included.\r\n\r\n**Any Other info.**\r\n", "comments": ["Currently have something for Multi-worker mirrored strategy\r\ntensorflowrun.py \u2014cluster_spec \u2018{\"cluster\": {\"worker\": [\"w1:5555\", \"w2:5555\"]}}\u2019 python /absolute/path/script.py\r\n\r\nAssumptions: You have ssh access without key to workers. The run script is in the same location in all workers.", "It is a simple utility which I guess users can create by themselves.", "It is relatively simple, but could be a pain point for users trying out the different distribution strategies.\r\nAll tutorials mention starting a process on each node with the correct TF_CONFIG env. This simple utility could be expanded to solve many other pain points. \r\nI believe most other frameworks have something similar built into the framework that alleviates this problem.", "@sboshin Is this still a feature request you are interested to work on? \r\n\r\nIf there is any actionable PRs, please feel free to open them to contribute. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 39040, "title": "Segmentation fault when converting a ReLU6 op to TFlite", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (or github SHA if from source):  2.1\r\n\r\n\r\n**Command used to run the converter or code if you\u2019re using the Python API**\r\nIf possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.layers import Input, Activation, Conv2D\r\nfrom tensorflow.keras import Model\r\nfrom tensorflow import lite\r\n\r\ndef model_relu6_only():\r\n    input_ = Input(shape=[50, 50, 3])\r\n    output = Activation(lambda x: tf.nn.relu6(x + 3) * 0.16667)(input_)\r\n    return Model(inputs=input_, outputs=output)\r\n\r\ndef model_conv_relu6():\r\n    input_ = Input(shape=[50, 50, 3])\r\n    output = Conv2D(3, 3)(input_)\r\n    output = Activation(lambda x: tf.nn.relu6(x + 3) * 0.16667)(output)\r\n    return Model(inputs=input_, outputs=output)\r\n\r\ndef tflite_model_conversion(model, filename):\r\n    converter = lite.TFLiteConverter.from_keras_model(model)\r\n    tflite_model = converter.convert()\r\n    with open(filename, \"wb+\") as f:\r\n        f.write(tflite_model)\r\n\r\nif __name__ == '__main__':\r\n\r\n    model = model_conv_relu6()\r\n    tflite_model_conversion(model, \"conv_relu6.tflite\")\r\n\r\n    model = model_relu6_only()\r\n    tflite_model_conversion(model, \"relu6_only.tflite\")\r\n```\r\n\r\n**The output from the converter invocation**\r\n\r\n```\r\n/Users/hw1000254892/miniconda3/envs/tf-2.1/bin/python /Users/hw1000254892/PycharmProjects/wd_obj_det/wd_obj_det/sandbox/relu_only_fail.py\r\n2020-04-29 14:25:02.594509: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2020-04-29 14:25:02.630218: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa3a268ade0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-04-29 14:25:02.630237: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2020-04-29 14:25:02.665720: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)\r\n2020-04-29 14:25:02.665825: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\r\n2020-04-29 14:25:02.677242: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: graph_to_optimize\r\n2020-04-29 14:25:02.677259: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.414ms.\r\n2020-04-29 14:25:02.677263: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-04-29 14:25:02.692790: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)\r\n2020-04-29 14:25:02.692847: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\r\n2020-04-29 14:25:02.702864: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: graph_to_optimize\r\n2020-04-29 14:25:02.702880: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 11 nodes (-2), 12 edges (-2), time = 7.837ms.\r\n2020-04-29 14:25:02.702883: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 11 nodes (0), 12 edges (0), time = 0.287ms.\r\n2020-04-29 14:25:05.324556: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)\r\n2020-04-29 14:25:05.324658: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\r\n2020-04-29 14:25:05.325629: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: graph_to_optimize\r\n2020-04-29 14:25:05.325640: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n2020-04-29 14:25:05.325646: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-04-29 14:25:05.335367: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)\r\n2020-04-29 14:25:05.335431: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\r\n2020-04-29 14:25:05.337047: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: graph_to_optimize\r\n2020-04-29 14:25:05.337060: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 7 nodes (0), 6 edges (0), time = 0.322ms.\r\n2020-04-29 14:25:05.337064: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 7 nodes (0), 6 edges (0), time = 0.198ms.\r\nTraceback (most recent call last):\r\n  File \"/Users/hw1000254892/PycharmProjects/wd_obj_det/wd_obj_det/sandbox/relu_only_fail.py\", line 29, in <module>\r\n    tflite_model_conversion(model, \"relu6_only.tflite\")\r\n  File \"/Users/hw1000254892/PycharmProjects/wd_obj_det/wd_obj_det/sandbox/relu_only_fail.py\", line 19, in tflite_model_conversion\r\n    tflite_model = converter.convert()\r\n  File \"/Users/hw1000254892/miniconda3/envs/tf-2.1/lib/python3.7/site-packages/tensorflow_core/lite/python/lite.py\", line 464, in convert\r\n    **converter_kwargs)\r\n  File \"/Users/hw1000254892/miniconda3/envs/tf-2.1/lib/python3.7/site-packages/tensorflow_core/lite/python/convert.py\", line 457, in toco_convert_impl\r\n    enable_mlir_converter=enable_mlir_converter)\r\n  File \"/Users/hw1000254892/miniconda3/envs/tf-2.1/lib/python3.7/site-packages/tensorflow_core/lite/python/convert.py\", line 203, in toco_convert_protos\r\n    raise ConverterError(\"See console for info.\\n%s\\n%s\\n\" % (stdout, stderr))\r\ntensorflow.lite.python.convert.ConverterError: See console for info.\r\n2020-04-29 14:25:08.186306: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 4 operators, 7 arrays (0 quantized)\r\n2020-04-29 14:25:08.186470: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 4 operators, 7 arrays (0 quantized)\r\n2020-04-29 14:25:08.186628: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 2 operators, 5 arrays (0 quantized)\r\nFatal Python error: Segmentation fault\r\n\r\nCurrent thread 0x000000010c7e2dc0 (most recent call first):\r\n  File \"/Users/hw1000254892/miniconda3/envs/tf-2.1/lib/python3.7/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 56 in execute\r\n  File \"/Users/hw1000254892/miniconda3/envs/tf-2.1/lib/python3.7/site-packages/absl/app.py\", line 250 in _run_main\r\n  File \"/Users/hw1000254892/miniconda3/envs/tf-2.1/lib/python3.7/site-packages/absl/app.py\", line 299 in run\r\n  File \"/Users/hw1000254892/miniconda3/envs/tf-2.1/lib/python3.7/site-packages/tensorflow_core/python/platform/app.py\", line 40 in run\r\n  File \"/Users/hw1000254892/miniconda3/envs/tf-2.1/lib/python3.7/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 93 in main\r\n  File \"/Users/hw1000254892/miniconda3/envs/tf-2.1/bin/toco_from_protos\", line 8 in <module>\r\n\r\n\r\n\r\n\r\nProcess finished with exit code 1\r\n\r\n```\r\n\r\n**Also, please include a link to the saved model or GraphDef**\r\n\r\n```\r\nN/A\r\n```\r\n\r\n**Failure details**\r\nIf the conversion is successful, but the generated model is wrong,\r\nstate what is wrong:\r\n- Producing wrong results and/or decrease in accuracy\r\n- Producing correct results, but the model is slower than expected (model generated from old converter)\r\n\r\nConversion failed\r\n\r\n**RNN conversion support**\r\nIf converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.\r\n\r\n**Any other info / logs**\r\n\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@wuhy08 \r\nI ran the code shared by on 2.1 and face a different error,please find the [gist here.](https://colab.sandbox.google.com/gist/Saduf2019/a6af2d4e4439870329d492ef5f4de9bd/untitled162.ipynb)\r\nWhereas in  nightly there is no error faced [it works fine] , please find the [gist here](https://colab.sandbox.google.com/gist/Saduf2019/19f50a7c073ede328a71f531e85e0741/untitled163.ipynb).", "Hi @Saduf2019 \r\n\r\nThank for for the reply. It seems nightly version resolve this issue, although another issue related to optimization appears. I will open another issue about that.\r\n\r\nThank you.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39040\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39040\">No</a>\n"]}, {"number": 39039, "title": "For the same model Keras trains about 4x slower compared to Estimators.", "body": "<em>Please make sure that this is an issue related to performance of TensorFlow.\r\nAs per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:performance_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Linux (Colab)\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 1.15 through 2.2-rc3\r\n- Python version: 3.6\r\n\r\n**Describe the current behavior**\r\nFor a simple model (3 layer neural net), Estimator trains about 4x faster compared to Keras. \r\nSomething slows keras `model.fit()` down significantly.\r\n\r\n**Describe the expected behavior**\r\nExpecting Keras and Estimator performance to be roughly on par. \r\n\r\n**Standalone code to reproduce the issue**\r\nhttps://colab.research.google.com/gist/yzhuang/35f037713f4181070f52b7502846f862/estimator_keras_speed_comparison.ipynb\r\n\r\n(Reproduction script are written by @pavanky )", "comments": ["@yzhuang \r\n\r\nI have tried in colab with TF 2.2-rc3 and was able to reproduce the issue. Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/90355a3669004d6d92a0007c67666138/untitled841.ipynb).Thanks!", "I can also reproduce this. It only happens when I use validation data or validation split. Training works as expected if no validation step happens.\r\n\r\nEDIT: The slowing down is more severe when providing validation data over validation split, but it's still observed.", "I did some more testing, and this discrepancy seems to affect CPU only but not GPU training. \r\n\r\nWith the model and data I supplied in the colab, i am seeing the following performance:\r\n\r\n**On CPU: (TF 1.15 and TF 2.2 has similar performance on CPU)**\r\n- Estimator: about 400 steps / second\r\n- Keras: about 90-100 steps / second\r\n- Summary: on CPU, with both 1.15 and 2.2, Estimator trains about 4x faster.\r\n\r\n**On GPU with TF 2.2 (eager mode):**\r\n- Estimator: about 280 - 320 steps / second\r\n- Keras: about 270-280 steps / second\r\n- Summary: on GPU with TF 2.2., Estimator and Keras performances are close.  Surprisingly, Keras got a 3x speed boost from the GPU, while Estimator became 25% slower on GPU.\r\n\r\n**On GPU with TF 1.15 (graph mode):**\r\n- Estimator: about 200 steps / second\r\n- Keras: about 200 steps / second\r\n- Summary: on GPU with TF 1.15, Estimator and Keras performed similar.  Estimator is only half as fast on GPU compared to on CPU.", "Did some further testing and seems the overhead (time per step) in keras does not grow with the total training time, thus can be amortized with more complex models.\r\n\r\nI change the model in \r\n> https://colab.research.google.com/gist/yzhuang/35f037713f4181070f52b7502846f862/estimator_keras_speed_comparison.ipynb\r\n\r\nto have 4 hidden layers (excluding input and output layers) and each layer contains 512 nodes.\r\nOn CPU, TF 2.2:\r\nEstimator: 34 steps/second = 29 ms/step \r\nKeras: 36 ms/step\r\n\r\nConverting the numbers from the original model to time per step\r\n> On CPU: (TF 1.15 and TF 2.2 has similar performance on CPU)\r\n> \r\n> Estimator: about 400 steps / second\r\n> Keras: about 90-100 steps / second\r\n\r\nWe get\r\nEstimator: 2.5 ms/step \r\nKeras: 10 ms/step\r\n\r\nSeems there are constant overhead per step on keras training. \r\n", "@yzhuang Is this still an issue for you? I am not an expert in estimator but noticed difference in training through `model.fit` and estimator. You are passing validation data to `model.fit`  whereas there is no validation in estimator. \r\n\r\nSo, i removed validation for bth the cases and compared them. When i averaged computational time for 1024 steps as ~ 8 sec (for model.fit) and 7.1 sec (for estimator).\r\n\r\nPlease check the gist [here](https://colab.research.google.com/gist/jvishnuvardhan/1c19c7656d6f875b58299443c6aa749c/copy-of-untitled841.ipynb).\r\n\r\nOutput from model.fit \r\n```\r\nEpoch 1/2\r\nWARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'categorical': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=string>, 'numerical': <tf.Tensor 'IteratorGetNext:1' shape=(None, 64) dtype=float64>}\r\nConsider rewriting this model with the Functional API.\r\nWARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'categorical': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=string>, 'numerical': <tf.Tensor 'IteratorGetNext:1' shape=(None, 64) dtype=float64>}\r\nConsider rewriting this model with the Functional API.\r\n1024/1024 [==============================] - 9s 8ms/step - loss: 0.6986 - accuracy: 0.5002\r\nEpoch 2/2\r\n1024/1024 [==============================] - 8s 8ms/step - loss: 0.6976 - accuracy: 0.5008\r\n<tensorflow.python.keras.callbacks.History at 0x7f9c9e037f90>\r\n```\r\n\r\nOutput from estimator\r\n\r\n```\r\nINFO:tensorflow:loss = 0.700911, step = 0\r\nINFO:tensorflow:global_step/sec: 132.648\r\nINFO:tensorflow:loss = 0.68739957, step = 100 (0.756 sec)\r\nINFO:tensorflow:global_step/sec: 144.999\r\nINFO:tensorflow:loss = 0.6920862, step = 200 (0.690 sec)\r\nINFO:tensorflow:global_step/sec: 146.693\r\nINFO:tensorflow:loss = 0.6899321, step = 300 (0.682 sec)\r\nINFO:tensorflow:global_step/sec: 147.972\r\nINFO:tensorflow:loss = 0.6954447, step = 400 (0.676 sec)\r\nINFO:tensorflow:global_step/sec: 134.756\r\nINFO:tensorflow:loss = 0.69063807, step = 500 (0.742 sec)\r\nINFO:tensorflow:global_step/sec: 143.593\r\nINFO:tensorflow:loss = 0.6985817, step = 600 (0.696 sec)\r\nINFO:tensorflow:global_step/sec: 144.751\r\nINFO:tensorflow:loss = 0.69656044, step = 700 (0.695 sec)\r\nINFO:tensorflow:global_step/sec: 141.261\r\nINFO:tensorflow:loss = 0.6985014, step = 800 (0.704 sec)\r\nINFO:tensorflow:global_step/sec: 139.664\r\nINFO:tensorflow:loss = 0.69251335, step = 900 (0.716 sec)\r\nINFO:tensorflow:global_step/sec: 139.489\r\nINFO:tensorflow:loss = 0.6981477, step = 1000 (0.717 sec)\r\nINFO:tensorflow:global_step/sec: 135.272\r\nINFO:tensorflow:loss = 0.6925006, step = 1100 (0.743 sec)\r\nINFO:tensorflow:global_step/sec: 136.393\r\nINFO:tensorflow:loss = 0.6949903, step = 1200 (0.732 sec)\r\nINFO:tensorflow:global_step/sec: 140.563\r\nINFO:tensorflow:loss = 0.6931845, step = 1300 (0.712 sec)\r\nINFO:tensorflow:global_step/sec: 140.613\r\nINFO:tensorflow:loss = 0.6967716, step = 1400 (0.709 sec)\r\nINFO:tensorflow:global_step/sec: 139.909\r\nINFO:tensorflow:loss = 0.68925714, step = 1500 (0.714 sec)\r\nINFO:tensorflow:global_step/sec: 139.813\r\nINFO:tensorflow:loss = 0.69458735, step = 1600 (0.716 sec)\r\nINFO:tensorflow:global_step/sec: 139.44\r\nINFO:tensorflow:loss = 0.69630384, step = 1700 (0.718 sec)\r\nINFO:tensorflow:global_step/sec: 140.243\r\nINFO:tensorflow:loss = 0.69852537, step = 1800 (0.712 sec)\r\nINFO:tensorflow:global_step/sec: 145.233\r\nINFO:tensorflow:loss = 0.69779515, step = 1900 (0.689 sec)\r\nINFO:tensorflow:global_step/sec: 145.86\r\nINFO:tensorflow:loss = 0.6958998, step = 2000 (0.686 sec)\r\nINFO:tensorflow:Calling checkpoint listeners before saving checkpoint 2048...\r\nINFO:tensorflow:Saving checkpoints for 2048 into /tmp/tmp45khjgyd/model.ckpt.\r\nINFO:tensorflow:Calling checkpoint listeners after saving checkpoint 2048...\r\n```\r\n\r\nAverage time for estimator train\r\n\r\n```\r\n#  1       2    3      4     5    6    7     8    9     10     11    12    13     14     15      16     17     18    19      20 \r\n(0.756+0.690+0.682+0.676+0.742+0.696+0.695+0.704+0.716+0.717+0.743+0.732+0.712 + 0.709 +0.714 + 0.716 +0.718+0.712+ 0.689 + 0.686)/2\r\n\r\n# 7.10 seconds\r\n```\r\n\r\nPlease verify once and close the issue if this was resolved for you. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 39038, "title": "OwnedMultiDeviceIterator can cause an error on TPU pods", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.2.0-rc4\r\n- Python version: \r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n\r\n\r\n**Describe the current behavior**\r\nOwnedMultiDeviceIterator can cause an error on TPU pods.\r\n\r\nthe resulting stack trace :\r\n\r\ngc/0 E0428 07:24:15.171094 132699 main app.py:658 Top-level exception:  could not parse rpc response\r\n\t [[{{node iterator_13/_89}}]] [Op:__inference_minimize_49326]\r\nFunction call stack:\r\nminimize\r\ngc/0 E0428 07:24:15.172459 132699 main app.py:659 Traceback (most recent call last):\r\n  File \"/launcher_root/google3/third_party/py/absl/app.py\", line 463, in run\r\n    _run_main(main, args)\r\n  File \"/launcher_root/google3/third_party/py/absl/app.py\", line 392, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"/launcher_root/google3/experimental/users/wendyshang/smarl/football/football/vtrace_main.py\", line 153, in main\r\n    env.create_environment(0), create_agent, create_optimizer)\r\n  File \"/launcher_root/google3/experimental/users/wendyshang/smarl/football/football/learner_object.py\", line 574, in learner_loop\r\n    minimize(it)\r\n  File \"/launcher_root/google3/third_party/tensorflow/python/eager/def_function.py\", line 695, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"/launcher_root/google3/third_party/tensorflow/python/eager/def_function.py\", line 760, in _call\r\n    return self._concrete_stateful_fn._filtered_call(canon_args, canon_kwds)  # pylint: disable=protected-access\r\n  File \"/launcher_root/google3/third_party/tensorflow/python/eager/function.py\", line 1904, in _filtered_call\r\n    cancellation_manager=cancellation_manager)\r\n  File \"/launcher_root/google3/third_party/tensorflow/python/eager/function.py\", line 1981, in _call_flat\r\n    ctx, args, cancellation_manager=cancellation_manager))\r\n  File \"/launcher_root/google3/third_party/tensorflow/python/eager/function.py\", line 615, in call\r\n    ctx=ctx)\r\n  File \"/launcher_root/google3/third_party/tensorflow/python/eager/execute.py\", line 60, in quick_execute\r\n    inputs, attrs, num_outputs)\r\ngoogle3.third_party.tensorflow.python.framework.errors_impl.InternalError:  could not parse rpc response\r\n\t [[{{node iterator_13/_89}}]] [Op:__inference_minimize_49326]\r\nFunction call stack:\r\nminimize\r\n**Describe the expected behavior**\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["The issue was fixed the by this [commit](https://github.com/tensorflow/tensorflow/commit/54fa7e441969792fa03f897cbd1fdbaf2e4d18e4)", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39038\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39038\">No</a>\n"]}, {"number": 39037, "title": "Convert Mobilenet SSD to TensorFlowLite with quantization", "body": "**System information**\r\n- Didn't change the code but used my own data:\r\n- Windows 10 + conda\r\n- TensorFlow installed from binary\r\n- TensorFlow version: v2.0.1 (also happened in newer version)\r\n- Python version: 3.7.6\r\n- CUDA/cuDNN version: 10.0\r\n- GPU model and memory: GeForce GTX 1080 Ti\r\n\r\n\r\nMy goal is simple, I think. I want to convert a pre-trained mobilenetv2 (or v1) ssd model to TFLite with quantization and optimization as described [HERE](https://www.tensorflow.org/lite/convert/quantization). But even without any quantization, I am getting errors converting the model to TFLite model. \r\n\r\n```\r\n    model = tf.saved_model.load(detection_model_dir)\r\n    concrete_func = model.signatures[tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY]\r\n    concrete_func.inputs[0].set_shape([1,300,300,3])\r\n    converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])\r\n    #converter = tf.compat.v1.lite.TFLiteConverter.from_saved_model(detection_model_dir, input_shapes={\"image_tensor\" : [1,300,300,3]})\r\n    tflite_model = converter.convert() \r\n```\r\n\r\nError Messages:\r\n\r\n> 2020-04-29 13:23:58.432192: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayWriteV3\r\n2020-04-29 13:23:58.432342: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayWriteV3\r\n2020-04-29 13:23:58.782402: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 4058 operators, 6882 arrays (0 quantized)\r\n2020-04-29 13:23:59.302999: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 4005 operators, 6778 arrays (0 quantized)\r\n2020-04-29 13:23:59.925648: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 4005 operators, 6778 arrays (0 quantized)\r\n2020-04-29 13:24:00.227644: F .\\tensorflow/lite/toco/toco_tooling.h:38] Check failed: s.ok() Found StridedSlice as non-selected output from Switch, but only Merge supported. Control flow ops like Switch and Merge are not generally supported. We are working on fixing this, please see the Github issue at https://github.com/tensorflow/tensorflow/issues/28485.\r\nFatal Python error: Aborted\r\n\r\nI have spent days on converting a pretrained mobilenetv2 ssd model to TFLite. I know the command line (export_tflite_ssd_graph.py) solution works for the conversion but not the qualization part. I also would like to write python code to do the same thing and optimize (compress, quantize) the model. I have been failing in doing it. Any suggestions? \r\n\r\nMy questions can be summarized as below:\r\n\r\n1. How to convert a pre-trained mobilenetv2 (or v1) ssd model to TFLite with quantization and optimization using python code similar to the above code block. \r\n2. How to convert a pre-trained mobilenetv2 (or v1) ssd model to TFLite with quantization and optimization with command lines (object detection API and TFLite APIs if any) \r\n", "comments": ["@jackyvr \r\nPlease provide simple stand alone code for us to replicate the issue, the code shared seems incomplete.", "> @jackyvr\r\n> Please provide simple stand alone code for us to replicate the issue, the code shared seems incomplete.\r\n\r\nThe other part of the code is mostly from the object detection tutorial. \r\n\r\n```\r\nimport pathlib\r\nimport numpy as np\r\nimport os\r\nimport six.moves.urllib as urllib\r\nimport sys\r\nimport tarfile\r\nimport tensorflow as tf\r\nimport zipfile\r\n\r\nfrom collections import defaultdict\r\nfrom io import StringIO\r\nfrom matplotlib import pyplot as plt\r\nfrom PIL import Image\r\nfrom IPython.display import display\r\nfrom object_detection.utils import ops as utils_ops\r\nfrom object_detection.utils import label_map_util\r\nfrom object_detection.utils import visualization_utils as vis_util\r\n\r\nutils_ops = tf.compat.v1\r\ntf.gfile = tf.io.gfile\r\n\r\ndef load_model(model_name):\r\n    base_url = 'http://download.tensorflow.org/models/object_detection/'\r\n    model_file = model_name + '.tar.gz'\r\n    model_dir = tf.keras.utils.get_file(\r\n        fname=model_name,\r\n        origin=base_url + model_file,\r\n        untar=True)\r\n    \r\n    model_dir = pathlib.Path(model_dir)/\"saved_model\"\r\n    \r\n    model = tf.saved_model.load(str(model_dir))\r\n    model = model.signatures['serving_default']\r\n    \r\n    return model, str(model_dir)\r\n\r\nmodel_name = 'ssd_mobilenet_v1_coco_2017_11_17'\r\ndetection_model, detection_model_dir = load_model(model_name)\r\n\r\nmodel = tf.saved_model.load(detection_model_dir)\r\nconcrete_func = model.signatures[tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY]\r\nconcrete_func.inputs[0].set_shape([1,300,300,3])\r\nconverter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])\r\ntflite_model = converter.convert() \r\n```", "@jackyvr \r\nI ran the code shared above but face a different error, please find the [gist here](https://colab.sandbox.google.com/gist/Saduf2019/7dd6e3f97350ead1d9e277e48057e5ff/39037.ipynb)", "@jackyvr\r\nPlease update as per above comment", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39037\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39037\">No</a>\n"]}, {"number": 39036, "title": "Training Property on Keras Layers", "body": "**System information**\r\n- TensorFlow version (you are using): 2.1\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nKeras Layers support a `training` argument. Since `training` is only available as an argument it cannot be varied for sublayers without constructing a new class.\r\n\r\nConsider a model with two subnetworks, backbone and head. The encapsulating model exposes an inputs and training arg, consistent with the Keras API. Without constructing a different model it becomes impossible to change the value of `training` passed to subnetworks. \r\n\r\n```\r\nclass Model(Layer):\r\n\r\n    def __init__(self, backbone, head, **kwargs):\r\n        super().__init__(**kwargs)\r\n        self.backbone: Layer = backbone\r\n        self.head: Layer = head\r\n\r\n    def call(self, inputs, training=True, **kwargs):\r\n        features = self.backbone(inputs, training=training)\r\n        outputs = self.head(features, training=training)\r\n        return outputs\r\n    \r\n    \r\n# -- Training\r\nmodel = Model(...)\r\nx, y = dataset()\r\nmodel(x, training=True)\r\n\r\n# -- Inference\r\nmodel(x, training=False)\r\n\r\n# -- Transfer learning (Proposed)\r\n\r\nmodel.backbone.trainable = False  # freeze backbone weights and batch norm\r\nmodel.backbone.training = False # used later in fine tuning\r\n# the head trains with trainable weights and active batchnorm\r\nmodel(x, training=True)\r\n\r\n# unfreeze backbone for fine tuning while keeping batchnorm frozen\r\nmodel.backbone.trainable = True\r\nmodel(x, training=True)\r\n\r\n```\r\n\r\n\r\n\r\n\r\n**Will this change the current api? How?**\r\n\r\nIt will alter the precedence for handling the `training` argument [here](https://github.com/tensorflow/tensorflow/blob/1e2c8c6873770a70ace0613a65c11826666c4623/tensorflow/python/keras/engine/base_layer.py#L843-L873). \r\n\r\nA possible implementation could look something like this:\r\n\r\nA new property:\r\n```\r\n@property\r\ndef training(self):\r\n    return self.__training\r\n\r\n\r\n@training.setter\r\ndef training(self, value: bool):\r\n    if value is not None:\r\n        if tensor_util.is_tensor(value):\r\n            training_value = math_ops.cast(value, dtypes.bool)\r\n        else:\r\n            training_value = bool(value)\r\n        self.__training = training_value\r\n        self._training_arg_passed_by_property = True\r\n\r\n    else:\r\n        training_value = None\r\n        self._training_arg_passed_by_property = False\r\n    self.__training = training_value\r\n```\r\n\r\n\r\nInside `__call__`:\r\n```\r\n# Priority 1\r\nif self._training_arg_passed_by_property:\r\n    training_value = self.training\r\n    if self._expects_training_arg:\r\n        kwargs[\"training\"] = training_value\r\nelse:\r\n    # Priority 2: `training` was explicitly passed.\r\n    if self._call_arg_was_passed(\"training\", args, kwargs):\r\n        training_value = self._get_call_arg_value(\"training\", args, kwargs)\r\n        if not self._expects_training_arg:\r\n            kwargs.pop(\"training\")\r\n```\r\n\r\n\r\n\r\n**Who will benefit with this feature?**\r\n\r\nTensorflow users who have develop models using OO patterns that require setting of the `training` parameter for sublayers. \r\n", "comments": ["This feature request was prompted by this [colab](https://colab.research.google.com/drive/17vHSAj7no7RMdJ18MJomTf8twqw1suYC#scrollTo=IMBpAwbegtdP) on transfer learning by @fchollet ", "@gdj0nes Are you still interested? Can you try to open that PR?", "@bhack I would be interested. I haven't taken a look at the latest changes to Keras but I will see if what I currently have is compatible.  ", "@bhack I've opened an RFC and have a pr to submit if it passes", "@gdj0nes Sorry for the late response. Are you still interested in contributing? If yes, please feel free to open a PR in  [keras-team/keras repo.](https://github.com/keras-team/keras/issues) repository.\r\n\r\nPlease note that Keras development moved to keras-team/keras repository to focus on only keras. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 39035, "title": "TF Lite Hexagon delegate support for snapdragon 865", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\nThe Snapdragon 865 (Hexagon 698 DSP) is not included in the list of supported Qualcomm SoCs:\r\nhttps://www.tensorflow.org/lite/performance/hexagon_delegate\r\n\r\nWas wondering if you have plans to add support for it to the tflite Hexagon delegate.", "comments": ["The guide page has only sample of the devices listed, not all.\r\nDid you try running it on SD 865 and didn't work ?", "@karimnosseir I got access to a phone equipped with the SD 865 and confirm that the delegate works after the recent update of `hexagon_nn_skel` to v. 1.17. Thank you!"]}, {"number": 39034, "title": "[r1.15-CherryPick] Add __reduce__ method in virtual pip root due to lazy loading", "body": "Fixes pickling issue #32159\r\n\r\nTested manually: just applied patch to tensorflow nightly and checked required imports.\r\n\r\nPiperOrigin-RevId: 276301497\r\nChange-Id: I6b3b6ae8b1218b43c31403ea7cc595ed11136ff9\r\n(cherry picked from commit 353b8a1adcb471a48ef9b1c5cbfc6097d036473e)\r\n\r\nIntended for a possible future r1.15 patch.", "comments": []}, {"number": 39033, "title": "impl.OpError: file is too short to be an sstable & DataLossError: Checksum does not match- TensorFlow 2.1.0", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (Linux Ubuntu 16.04):\r\n- TensorFlow version (2.1.0):\r\n- Python version: (3.6)\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n- Kubernetes version (v1.14.3)\r\n- Kubeflow version (v1.0)\r\n\r\n**Describe the current behavior**\r\nHi guys! i am trying to run this TensorFlow job on Kubernetes cluster using kubeflow. But i keep getting these indeterministic errors, which are really hard to follow. I have to run the same job again and again using different tfconfigs ... and every time, there's a chance that the job might fail because of one of the following issues. The job uses TensorFlow2.0, and kubeflow1.0. The fact that the job fails with a chance is really weird which makes it very hard to isolate. If I simply delete and restart the job, sometimes it runs fine(but there's a chance it might give the same error again - slight chance!). Could someone please point out the root cause that might be causing such behavior!\r\n\r\n**Describe the expected behavior**\r\nThe jobs should not fail in an indeterministic manner. \r\n\r\n**Error Log1**\r\n```\r\n2020-04-16 03:32:10.840927: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory\r\n2020-04-16 03:32:10.841009: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory\r\n2020-04-16 03:32:10.841016: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\r\nI0416 03:32:11.778649 140150905272128 dataset_builder.py:199] Overwrite dataset info from restored data version.\r\nI0416 03:32:11.781358 140150905272128 dataset_builder.py:285] Reusing dataset cifar10 (./dataDir/cifar10/3.0.0)\r\nI0416 03:32:11.781544 140150905272128 dataset_builder.py:458] Constructing tf.data.Dataset for split train, from ./dataDir/cifar10/3.0.0\r\n2020-04-16 03:32:11.785308: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\r\n2020-04-16 03:32:11.785339: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: UNKNOWN ERROR (303)\r\n2020-04-16 03:32:11.785361: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (tftestaccuracy7-testjob-temp-1-7-3-3-0-master-0): /proc/driver/nvidia/version does not exist\r\n2020-04-16 03:32:11.785606: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\r\n2020-04-16 03:32:11.794453: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2194825000 Hz\r\n2020-04-16 03:32:11.796551: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4895200 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-04-16 03:32:11.796574: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\nINFO:1587007938.6536536:tensorflow:TF_CONFIG environment variable: {'cluster': {'master': ['tftestaccuracy7-testjob-temp-1-7-3-3-0-master-0.ali.svc:2222'], 'ps': ['tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-0.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-1.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-2.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-3.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-4.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-5.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-6.ali.svc:2222'], 'worker': ['tftestaccuracy7-testjob-temp-1-7-3-3-0-worker-0.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-worker-1.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-worker-2.ali.svc:2222']}, 'task': {'type': 'master', 'index': 0}, 'environment': 'cloud'}\r\nI0416 03:32:18.653653 140150905272128 run_config.py:535] TF_CONFIG environment variable: {'cluster': {'master': ['tftestaccuracy7-testjob-temp-1-7-3-3-0-master-0.ali.svc:2222'], 'ps': ['tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-0.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-1.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-2.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-3.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-4.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-5.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-6.ali.svc:2222'], 'worker': ['tftestaccuracy7-testjob-temp-1-7-3-3-0-worker-0.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-worker-1.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-worker-2.ali.svc:2222']}, 'task': {'type': 'master', 'index': 0}, 'environment': 'cloud'}\r\nINFO:1587007938.6553543:tensorflow:Using the Keras model provided.\r\nI0416 03:32:18.655354 140150905272128 keras.py:540] Using the Keras model provided.\r\nWARNING:1587007938.7225273:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nIf using Keras pass *_constraint arguments to layers.\r\nW0416 03:32:18.722527 140150905272128 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nIf using Keras pass *_constraint arguments to layers.\r\nINFO:1587007950.8246615:tensorflow:Using config: {'_model_dir': './out/tftestaccuracy7-testjob-temp-1-7-3-3-0', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 20000, '_save_checkpoints_secs': None, '_session_config': device_filters: \"/job:ps\"\r\ndevice_filters: \"/job:master\"\r\nallow_soft_placement: true\r\ngraph_options {\r\n  rewrite_options {\r\n    meta_optimizer_iterations: ONE\r\n  }\r\n}\r\n, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({'master': ['tftestaccuracy7-testjob-temp-1-7-3-3-0-master-0.ali.svc:2222'], 'ps': ['tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-0.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-1.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-2.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-3.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-4.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-5.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-6.ali.svc:2222'], 'worker': ['tftestaccuracy7-testjob-temp-1-7-3-3-0-worker-0.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-worker-1.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-worker-2.ali.svc:2222']}), '_task_type': 'master', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://tftestaccuracy7-testjob-temp-1-7-3-3-0-master-0.ali.svc:2222', '_evaluation_master': '', '_num_ps_replicas': 7, '_num_worker_replicas': 4, '_is_chief': True}\r\nI0416 03:32:30.824661 140150905272128 estimator.py:216] Using config: {'_model_dir': './out/tftestaccuracy7-testjob-temp-1-7-3-3-0', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 20000, '_save_checkpoints_secs': None, '_session_config': device_filters: \"/job:ps\"\r\ndevice_filters: \"/job:master\"\r\nallow_soft_placement: true\r\ngraph_options {\r\n  rewrite_options {\r\n    meta_optimizer_iterations: ONE\r\n  }\r\n}\r\n, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({'master': ['tftestaccuracy7-testjob-temp-1-7-3-3-0-master-0.ali.svc:2222'], 'ps': ['tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-0.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-1.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-2.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-3.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-4.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-5.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-6.ali.svc:2222'], 'worker': ['tftestaccuracy7-testjob-temp-1-7-3-3-0-worker-0.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-worker-1.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-worker-2.ali.svc:2222']}), '_task_type': 'master', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://tftestaccuracy7-testjob-temp-1-7-3-3-0-master-0.ali.svc:2222', '_evaluation_master': '', '_num_ps_replicas': 7, '_num_worker_replicas': 4, '_is_chief': True}\r\nINFO:1587007950.825566:tensorflow:Not using Distribute Coordinator.\r\nI0416 03:32:30.825566 140150905272128 estimator_training.py:186] Not using Distribute Coordinator.\r\nINFO:1587007950.8260767:tensorflow:Start Tensorflow server.\r\nI0416 03:32:30.826076 140150905272128 training.py:744] Start Tensorflow server.\r\n2020-04-16 03:32:30.835044: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:300] Initialize GrpcChannelCache for job master -> {0 -> localhost:2222}\r\n2020-04-16 03:32:30.835109: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:300] Initialize GrpcChannelCache for job ps -> {0 -> tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-0.ali.svc:2222, 1 -> tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-1.ali.svc:2222, 2 -> tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-2.ali.svc:2222, 3 -> tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-3.ali.svc:2222, 4 -> tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-4.ali.svc:2222, 5 -> tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-5.ali.svc:2222, 6 -> tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-6.ali.svc:2222}\r\n2020-04-16 03:32:30.835125: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:300] Initialize GrpcChannelCache for job worker -> {0 -> tftestaccuracy7-testjob-temp-1-7-3-3-0-worker-0.ali.svc:2222, 1 -> tftestaccuracy7-testjob-temp-1-7-3-3-0-worker-1.ali.svc:2222, 2 -> tftestaccuracy7-testjob-temp-1-7-3-3-0-worker-2.ali.svc:2222}\r\n2020-04-16 03:32:30.838051: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:390] Started server with target: grpc://localhost:2222\r\nWARNING:1587007950.8507316:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\r\nW0416 03:32:30.850731 140150905272128 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\r\nI0416 03:32:30.867805 140150905272128 dataset_builder.py:199] Overwrite dataset info from restored data version.\r\nI0416 03:32:30.875023 140150905272128 dataset_builder.py:285] Reusing dataset cifar10 (./dataDir/cifar10/3.0.0)\r\nI0416 03:32:30.875263 140150905272128 dataset_builder.py:458] Constructing tf.data.Dataset for split train, from ./dataDir/cifar10/3.0.0\r\nINFO:1587007951.0019863:tensorflow:Calling model_fn.\r\nI0416 03:32:31.001986 140150905272128 estimator.py:1151] Calling model_fn.\r\nINFO:1587007957.5129364:tensorflow:Done calling model_fn.\r\nI0416 03:32:37.512936 140150905272128 estimator.py:1153] Done calling model_fn.\r\nINFO:1587007957.5134861:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='./out/tftestaccuracy7-testjob-temp-1-7-3-3-0/keras/keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\r\nI0416 03:32:37.513486 140150905272128 estimator.py:1372] Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='./out/tftestaccuracy7-testjob-temp-1-7-3-3-0/keras/keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\r\nINFO:1587007957.513585:tensorflow:Warm-starting from: ./out/tftestaccuracy7-testjob-temp-1-7-3-3-0/keras/keras_model.ckpt\r\nI0416 03:32:37.513585 140150905272128 warm_starting_util.py:464] Warm-starting from: ./out/tftestaccuracy7-testjob-temp-1-7-3-3-0/keras/keras_model.ckpt\r\nINFO:1587007957.513649:tensorflow:Warm-starting variables only in TRAINABLE_VARIABLES.\r\nI0416 03:32:37.513648 140150905272128 warm_starting_util.py:343] Warm-starting variables only in TRAINABLE_VARIABLES.\r\ntfds.core.DatasetInfo(\r\n    name='cifar10',\r\n    version=3.0.0,\r\n    description='The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.',\r\n    homepage='https://www.cs.toronto.edu/~kriz/cifar.html',\r\n    features=FeaturesDict({\r\n        'image': Image(shape=(32, 32, 3), dtype=tf.uint8),\r\n        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\r\n    }),\r\n    total_num_examples=60000,\r\n    splits={\r\n        'test': 10000,\r\n        'train': 50000,\r\n    },\r\n    supervised_keys=('image', 'label'),\r\n    citation=\"\"\"@TECHREPORT{Krizhevsky09learningmultiple,\r\n        author = {Alex Krizhevsky},\r\n        title = {Learning multiple layers of features from tiny images},\r\n        institution = {},\r\n        year = {2009}\r\n    }\"\"\",\r\n    redistribution_info=,\r\n)\r\n\r\nInput data (batch size 64): <DatasetV1Adapter shapes: ((None, 128, 128, 3), (None,)), types: (tf.float32, tf.int64)>\r\n+++++ Building Keras model +++++\r\nOutput of feature extraction (original model): (64, 4, 4, 2048)\r\nOutput of 0th classification layer (<tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7f766056aa58>): (64, 2048)\r\nOutput of 1th classification layer (<tensorflow.python.keras.layers.core.Dense object at 0x7f766056aba8>): (64, 10)\r\nModel: \"sequential_1\"\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\nresnet50 (Model)             (None, 4, 4, 2048)        23587712  \r\n_________________________________________________________________\r\nsequential (Sequential)      (None, 10)                20490     \r\n=================================================================\r\nTotal params: 23,608,202\r\nTrainable params: 23,555,082\r\nNon-trainable params: 53,120\r\n_________________________________________________________________\r\nModel: \"sequential\"\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\nglobal_average_pooling2d (Gl (None, 2048)              0         \r\n_________________________________________________________________\r\ndense (Dense)                (None, 10)                20490     \r\n=================================================================\r\nTotal params: 20,490\r\nTrainable params: 20,490\r\nNon-trainable params: 0\r\n_________________________________________________________________\r\n+++++ Train and evaluate the Estimator model +++++\r\ntfds.core.DatasetInfo(\r\n    name='cifar10',\r\n    version=3.0.0,\r\n    description='The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.',\r\n    homepage='https://www.cs.toronto.edu/~kriz/cifar.html',\r\n    features=FeaturesDict({\r\n        'image': Image(shape=(32, 32, 3), dtype=tf.uint8),\r\n        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\r\n    }),\r\n    total_num_examples=60000,\r\n    splits={\r\n        'test': 10000,\r\n        'train': 50000,\r\n    },\r\n    supervised_keys=('image', 'label'),\r\n    citation=\"\"\"@TECHREPORT{Krizhevsky09learningmultiple,\r\n        author = {Alex Krizhevsky},\r\n        title = {Learning multiple layers of features from tiny images},\r\n        institution = {},\r\n        year = {2009}\r\n    }\"\"\",\r\n    redistribution_info=,\r\n)\r\n\r\nInput data (batch size 64): <DatasetV1Adapter shapes: ((None, 128, 128, 3), (None,)), types: (tf.float32, tf.int64)>\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/py_checkpoint_reader.py\", line 95, in NewCheckpointReader\r\n    return CheckpointReader(compat.as_bytes(filepattern))\r\nRuntimeError: file is too short to be an sstable\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/app/keras_to_est.py\", line 242, in <module>\r\n    app.run(main)\r\n  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\r\n    _run_main(main, args)\r\n  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"/app/keras_to_est.py\", line 227, in main\r\n    tf.estimator.train_and_evaluate(model_est, train_spec, eval_spec)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 473, in train_and_evaluate\r\n    return executor.run()\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 640, in run\r\n    getattr(self, task_to_run)()\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 677, in run_master\r\n    self._start_distributed_training(saving_listeners=saving_listeners)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 796, in _start_distributed_training\r\n    saving_listeners=saving_listeners)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 374, in train\r\n    loss = self._train_model(input_fn, hooks, saving_listeners)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1164, in _train_model\r\n    return self._train_model_default(input_fn, hooks, saving_listeners)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1198, in _train_model_default\r\n    saving_listeners)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1373, in _train_with_estimator_spec\r\n    warm_starting_util.warm_start(*self._warm_start_settings)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/warm_starting_util.py\", line 476, in warm_start\r\n    ckpt_to_initialize_from, grouped_variables.keys())\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/warm_starting_util.py\", line 397, in _get_object_checkpoint_renames\r\n    names_to_keys = saver_lib.object_graph_key_mapping(fname)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py\", line 1617, in object_graph_key_mapping\r\n    reader = py_checkpoint_reader.NewCheckpointReader(checkpoint_path)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/py_checkpoint_reader.py\", line 99, in NewCheckpointReader\r\n    error_translator(e)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/py_checkpoint_reader.py\", line 48, in error_translator\r\n    raise errors_impl.OpError(None, None, error_message, errors_impl.UNKNOWN)\r\ntensorflow.python.framework.errors_impl.OpError: file is too short to be an sstable\r\n```\r\n**Error Log2**\r\n```\r\n2020-04-17 11:10:04.594547: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory\r\n2020-04-17 11:10:04.594650: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory\r\n2020-04-17 11:10:04.594665: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\r\nI0417 11:10:05.664701 140220500707136 dataset_builder.py:199] Overwrite dataset info from restored data version.\r\nI0417 11:10:05.667569 140220500707136 dataset_builder.py:285] Reusing dataset cifar10 (./dataDir/cifar10/3.0.0)\r\nI0417 11:10:05.667821 140220500707136 dataset_builder.py:458] Constructing tf.data.Dataset for split train, from ./dataDir/cifar10/3.0.0\r\n2020-04-17 11:10:05.672440: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\r\n2020-04-17 11:10:05.672469: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: UNKNOWN ERROR (303)\r\n2020-04-17 11:10:05.672494: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (tftestaccuracy6-testjob-temp-1-6-11-11-0-master-0): /proc/driver/nvidia/version does not exist\r\n2020-04-17 11:10:05.672896: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\r\n2020-04-17 11:10:05.685860: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2194855000 Hz\r\n2020-04-17 11:10:05.688580: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4db8fe0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-04-17 11:10:05.688621: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\nINFO:1587121814.71867:tensorflow:TF_CONFIG environment variable: {'cluster': {'master': ['tftestaccuracy6-testjob-temp-1-6-11-11-0-master-0.ali.svc:2222'], 'ps': ['tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-0.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-1.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-2.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-3.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-4.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-5.ali.svc:2222'], 'worker': ['tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-0.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-1.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-2.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-3.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-4.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-5.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-6.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-7.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-8.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-9.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-10.ali.svc:2222']}, 'task': {'type': 'master', 'index': 0}, 'environment': 'cloud'}\r\nI0417 11:10:14.718669 140220500707136 run_config.py:535] TF_CONFIG environment variable: {'cluster': {'master': ['tftestaccuracy6-testjob-temp-1-6-11-11-0-master-0.ali.svc:2222'], 'ps': ['tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-0.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-1.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-2.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-3.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-4.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-5.ali.svc:2222'], 'worker': ['tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-0.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-1.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-2.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-3.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-4.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-5.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-6.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-7.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-8.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-9.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-10.ali.svc:2222']}, 'task': {'type': 'master', 'index': 0}, 'environment': 'cloud'}\r\nINFO:1587121814.7204363:tensorflow:Using the Keras model provided.\r\nI0417 11:10:14.720436 140220500707136 keras.py:540] Using the Keras model provided.\r\nINFO:1587121814.7229145:tensorflow:Using config: {'_model_dir': './out/tftestaccuracy6-testjob-temp-1-6-11-11-0', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 20000, '_save_checkpoints_secs': None, '_session_config': device_filters: \"/job:ps\"\r\ndevice_filters: \"/job:master\"\r\nallow_soft_placement: true\r\ngraph_options {\r\n  rewrite_options {\r\n    meta_optimizer_iterations: ONE\r\n  }\r\n}\r\n, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({'master': ['tftestaccuracy6-testjob-temp-1-6-11-11-0-master-0.ali.svc:2222'], 'ps': ['tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-0.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-1.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-2.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-3.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-4.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-5.ali.svc:2222'], 'worker': ['tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-0.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-1.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-2.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-3.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-4.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-5.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-6.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-7.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-8.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-9.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-10.ali.svc:2222']}), '_task_type': 'master', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://tftestaccuracy6-testjob-temp-1-6-11-11-0-master-0.ali.svc:2222', '_evaluation_master': '', '_num_ps_replicas': 6, '_num_worker_replicas': 12, '_is_chief': True}\r\nI0417 11:10:14.722914 140220500707136 estimator.py:216] Using config: {'_model_dir': './out/tftestaccuracy6-testjob-temp-1-6-11-11-0', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 20000, '_save_checkpoints_secs': None, '_session_config': device_filters: \"/job:ps\"\r\ndevice_filters: \"/job:master\"\r\nallow_soft_placement: true\r\ngraph_options {\r\n  rewrite_options {\r\n    meta_optimizer_iterations: ONE\r\n  }\r\n}\r\n, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({'master': ['tftestaccuracy6-testjob-temp-1-6-11-11-0-master-0.ali.svc:2222'], 'ps': ['tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-0.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-1.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-2.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-3.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-4.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-5.ali.svc:2222'], 'worker': ['tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-0.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-1.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-2.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-3.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-4.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-5.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-6.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-7.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-8.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-9.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-10.ali.svc:2222']}), '_task_type': 'master', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://tftestaccuracy6-testjob-temp-1-6-11-11-0-master-0.ali.svc:2222', '_evaluation_master': '', '_num_ps_replicas': 6, '_num_worker_replicas': 12, '_is_chief': True}\r\nINFO:1587121814.7236319:tensorflow:Not using Distribute Coordinator.\r\nI0417 11:10:14.723631 140220500707136 estimator_training.py:186] Not using Distribute Coordinator.\r\nINFO:1587121814.7240767:tensorflow:Start Tensorflow server.\r\nI0417 11:10:14.724076 140220500707136 training.py:744] Start Tensorflow server.\r\n2020-04-17 11:10:14.731863: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:300] Initialize GrpcChannelCache for job master -> {0 -> localhost:2222}\r\n2020-04-17 11:10:14.731898: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:300] Initialize GrpcChannelCache for job ps -> {0 -> tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-0.ali.svc:2222, 1 -> tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-1.ali.svc:2222, 2 -> tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-2.ali.svc:2222, 3 -> tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-3.ali.svc:2222, 4 -> tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-4.ali.svc:2222, 5 -> tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-5.ali.svc:2222}\r\n2020-04-17 11:10:14.731910: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:300] Initialize GrpcChannelCache for job worker -> {0 -> tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-0.ali.svc:2222, 1 -> tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-1.ali.svc:2222, 2 -> tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-2.ali.svc:2222, 3 -> tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-3.ali.svc:2222, 4 -> tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-4.ali.svc:2222, 5 -> tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-5.ali.svc:2222, 6 -> tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-6.ali.svc:2222, 7 -> tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-7.ali.svc:2222, 8 -> tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-8.ali.svc:2222, 9 -> tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-9.ali.svc:2222, 10 -> tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-10.ali.svc:2222}\r\n2020-04-17 11:10:14.733813: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:390] Started server with target: grpc://localhost:2222\r\nWARNING:1587121814.7500741:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nIf using Keras pass *_constraint arguments to layers.\r\nW0417 11:10:14.750074 140220500707136 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nIf using Keras pass *_constraint arguments to layers.\r\nWARNING:1587121814.7521474:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\r\nW0417 11:10:14.752147 140220500707136 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\r\nI0417 11:10:14.775437 140220500707136 dataset_builder.py:199] Overwrite dataset info from restored data version.\r\nI0417 11:10:14.781437 140220500707136 dataset_builder.py:285] Reusing dataset cifar10 (./dataDir/cifar10/3.0.0)\r\nI0417 11:10:14.781795 140220500707136 dataset_builder.py:458] Constructing tf.data.Dataset for split train, from ./dataDir/cifar10/3.0.0\r\nINFO:1587121814.9113212:tensorflow:Calling model_fn.\r\nI0417 11:10:14.911321 140220500707136 estimator.py:1151] Calling model_fn.\r\nINFO:1587121822.074707:tensorflow:Done calling model_fn.\r\nI0417 11:10:22.074707 140220500707136 estimator.py:1153] Done calling model_fn.\r\nINFO:1587121822.0750966:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='./out/tftestaccuracy6-testjob-temp-1-6-11-11-0/keras/keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\r\nI0417 11:10:22.075096 140220500707136 estimator.py:1372] Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='./out/tftestaccuracy6-testjob-temp-1-6-11-11-0/keras/keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\r\nINFO:1587121822.075177:tensorflow:Warm-starting from: ./out/tftestaccuracy6-testjob-temp-1-6-11-11-0/keras/keras_model.ckpt\r\nI0417 11:10:22.075176 140220500707136 warm_starting_util.py:464] Warm-starting from: ./out/tftestaccuracy6-testjob-temp-1-6-11-11-0/keras/keras_model.ckpt\r\nINFO:1587121822.0752382:tensorflow:Warm-starting variables only in TRAINABLE_VARIABLES.\r\nI0417 11:10:22.075238 140220500707136 warm_starting_util.py:343] Warm-starting variables only in TRAINABLE_VARIABLES.\r\nINFO:1587121823.262496:tensorflow:Warm-started 214 variables.\r\nI0417 11:10:23.262495 140220500707136 warm_starting_util.py:538] Warm-started 214 variables.\r\nINFO:1587121823.2661114:tensorflow:Create CheckpointSaverHook.\r\nI0417 11:10:23.266111 140220500707136 basic_session_run_hooks.py:546] Create CheckpointSaverHook.\r\nINFO:1587121825.0649378:tensorflow:Graph was finalized.\r\nI0417 11:10:25.064937 140220500707136 monitored_session.py:246] Graph was finalized.\r\ntfds.core.DatasetInfo(\r\n    name='cifar10',\r\n    version=3.0.0,\r\n    description='The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.',\r\n    homepage='https://www.cs.toronto.edu/~kriz/cifar.html',\r\n    features=FeaturesDict({\r\n        'image': Image(shape=(32, 32, 3), dtype=tf.uint8),\r\n        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\r\n    }),\r\n    total_num_examples=60000,\r\n    splits={\r\n        'test': 10000,\r\n        'train': 50000,\r\n    },\r\n    supervised_keys=('image', 'label'),\r\n    citation=\"\"\"@TECHREPORT{Krizhevsky09learningmultiple,\r\n        author = {Alex Krizhevsky},\r\n        title = {Learning multiple layers of features from tiny images},\r\n        institution = {},\r\n        year = {2009}\r\n    }\"\"\",\r\n    redistribution_info=,\r\n)\r\n\r\nInput data (batch size 64): <DatasetV1Adapter shapes: ((None, 128, 128, 3), (None,)), types: (tf.float32, tf.int64)>\r\n+++++ Building Keras model +++++\r\nOutput of feature extraction (original model): (64, 4, 4, 2048)\r\nOutput of 0th classification layer (<tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7f86ec14b9e8>): (64, 2048)\r\nOutput of 1th classification layer (<tensorflow.python.keras.layers.core.Dense object at 0x7f86ec14bb38>): (64, 10)\r\nModel: \"sequential_1\"\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\nresnet50 (Model)             (None, 4, 4, 2048)        23587712  \r\n_________________________________________________________________\r\nsequential (Sequential)      (None, 10)                20490     \r\n=================================================================\r\nTotal params: 23,608,202\r\nTrainable params: 23,555,082\r\nNon-trainable params: 53,120\r\n_________________________________________________________________\r\nModel: \"sequential\"\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\nglobal_average_pooling2d (Gl (None, 2048)              0         \r\n_________________________________________________________________\r\ndense (Dense)                (None, 10)                20490     \r\n=================================================================\r\nTotal params: 20,490\r\nTrainable params: 20,490\r\nNon-trainable params: 0\r\n_________________________________________________________________\r\n+++++ Train and evaluate the Estimator model +++++\r\ntfds.core.DatasetInfo(\r\n    name='cifar10',\r\n    version=3.0.0,\r\n    description='The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.',\r\n    homepage='https://www.cs.toronto.edu/~kriz/cifar.html',\r\n    features=FeaturesDict({\r\n        'image': Image(shape=(32, 32, 3), dtype=tf.uint8),\r\n        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\r\n    }),\r\n    total_num_examples=60000,\r\n    splits={\r\n        'test': 10000,\r\n        'train': 50000,\r\n    },\r\n    supervised_keys=('image', 'label'),\r\n    citation=\"\"\"@TECHREPORT{Krizhevsky09learningmultiple,\r\n        author = {Alex Krizhevsky},\r\n        title = {Learning multiple layers of features from tiny images},\r\n        institution = {},\r\n        year = {2009}\r\n    }\"\"\",\r\n    redistribution_info=,\r\n)\r\n\r\nInput data (batch size 64): <DatasetV1Adapter shapes: ((None, 128, 128, 3), (None,)), types: (tf.float32, tf.int64)>\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1367, in _do_call\r\n    return fn(*args)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1352, in _run_fn\r\n    target_list, run_metadata)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1445, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.DataLossError: From /job:ps/replica:0/task:3:\r\nChecksum does not match: stored 3880206044 vs. calculated on the restored bytes 1782481297\r\n\t [[{{node checkpoint_initializer_53}}]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/app/keras_to_est.py\", line 242, in <module>\r\n    app.run(main)\r\n  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\r\n    _run_main(main, args)\r\n  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"/app/keras_to_est.py\", line 227, in main\r\n    tf.estimator.train_and_evaluate(model_est, train_spec, eval_spec)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 473, in train_and_evaluate\r\n    return executor.run()\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 640, in run\r\n    getattr(self, task_to_run)()\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 677, in run_master\r\n    self._start_distributed_training(saving_listeners=saving_listeners)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 796, in _start_distributed_training\r\n    saving_listeners=saving_listeners)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 374, in train\r\n    loss = self._train_model(input_fn, hooks, saving_listeners)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1164, in _train_model\r\n    return self._train_model_default(input_fn, hooks, saving_listeners)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1198, in _train_model_default\r\n    saving_listeners)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1493, in _train_with_estimator_spec\r\n    log_step_count_steps=log_step_count_steps) as mon_sess:\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 604, in MonitoredTrainingSession\r\n    stop_grace_period_secs=stop_grace_period_secs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1038, in __init__\r\n    stop_grace_period_secs=stop_grace_period_secs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 749, in __init__\r\n    self._sess = _RecoverableSession(self._coordinated_creator)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1231, in __init__\r\n    _WrappedSession.__init__(self, self._create_session())\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1236, in _create_session\r\n    return self._sess_creator.create_session()\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 902, in create_session\r\n    self.tf_sess = self._session_creator.create_session()\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 669, in create_session\r\n    init_fn=self._scaffold.init_fn)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/session_manager.py\", line 300, in prepare_session\r\n    sess.run(init_op, feed_dict=init_feed_dict)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 960, in run\r\n    run_metadata_ptr)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1183, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1361, in _do_run\r\n    run_metadata)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1386, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.DataLossError: From /job:ps/replica:0/task:3:\r\nChecksum does not match: stored 3880206044 vs. calculated on the restored bytes 1782481297\r\n\t [[node checkpoint_initializer_53 (defined at usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py:1373) ]]\r\n\r\nOriginal stack trace for 'checkpoint_initializer_53':\r\n  File \"app/keras_to_est.py\", line 242, in <module>\r\n    app.run(main)\r\n  File \"usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\r\n    _run_main(main, args)\r\n  File \"usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"app/keras_to_est.py\", line 227, in main\r\n    tf.estimator.train_and_evaluate(model_est, train_spec, eval_spec)\r\n  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 473, in train_and_evaluate\r\n    return executor.run()\r\n  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 640, in run\r\n    getattr(self, task_to_run)()\r\n  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 677, in run_master\r\n    self._start_distributed_training(saving_listeners=saving_listeners)\r\n  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 796, in _start_distributed_training\r\n    saving_listeners=saving_listeners)\r\n  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 374, in train\r\n    loss = self._train_model(input_fn, hooks, saving_listeners)\r\n  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1164, in _train_model\r\n    return self._train_model_default(input_fn, hooks, saving_listeners)\r\n  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1198, in _train_model_default\r\n    saving_listeners)\r\n  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1373, in _train_with_estimator_spec\r\n    warm_starting_util.warm_start(*self._warm_start_settings)\r\n  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/warm_starting_util.py\", line 533, in warm_start\r\n    checkpoint_utils.init_from_checkpoint(ckpt_to_initialize_from, vocabless_vars)\r\n  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/checkpoint_utils.py\", line 291, in init_from_checkpoint\r\n    init_from_checkpoint_fn)\r\n  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/distribute_lib.py\", line 1949, in merge_call\r\n    return self._merge_call(merge_fn, args, kwargs)\r\n  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/distribute_lib.py\", line 1956, in _merge_call\r\n    return merge_fn(self._strategy, *args, **kwargs)\r\n  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/checkpoint_utils.py\", line 286, in <lambda>\r\n    ckpt_dir_or_file, assignment_map)\r\n  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/checkpoint_utils.py\", line 334, in _init_from_checkpoint\r\n    _set_variable_or_list_initializer(var, ckpt_file, tensor_name_in_ckpt)\r\n  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/checkpoint_utils.py\", line 458, in _set_variable_or_list_initializer\r\n    _set_checkpoint_initializer(variable_or_list, ckpt_file, tensor_name, \"\")\r\n  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/checkpoint_utils.py\", line 412, in _set_checkpoint_initializer\r\n    ckpt_file, [tensor_name], [slice_spec], [base_type], name=name)[0]\r\n  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_io_ops.py\", line 1506, in restore_v2\r\n    name=name)\r\n  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py\", line 742, in _apply_op_helper\r\n    attrs=attr_protos, op_def=op_def)\r\n  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 3322, in _create_op_internal\r\n    op_def=op_def)\r\n  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 1756, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n```", "comments": ["@ali-raza-tariq \r\nPlease share a simple stand alone code for us to replicate the error faced.", "@Saduf2019 please find below the code for reproducing the error. But as I mentioned, reproducing the error would be difficult as the issue is not deterministic. I run a large number of jobs simultaneously with various tfconfigs (using Kubeflow) using scripts for benchmarking. Hence its easier for me to reproduce, so if there is anything I can do help along the debug process please let me know! \r\n\r\n```\r\n# from __future__ import absolute_import, division, print_function, unicode_literals\r\n\r\nfrom absl import flags, app\r\nimport sys, logging\r\n\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nimport tensorflow_datasets as tfds\r\n# tfds.disable_progress_bar()\r\n\r\nFLAGS = flags.FLAGS\r\n\r\nflags.DEFINE_string(name='model_dir', default='./keras_est_model', help='Directory to store model checkpoints')\r\n\r\n### Dataset specs ###\r\n#flags.DEFINE_string(name='', default='', help='')\r\nflags.DEFINE_string(name='dataset', default='cifar10', help='Dataset name for training and evaluation.')\r\nflags.DEFINE_integer(name='img_size', default=128, help='Set the size of the image (img_size, img_size, 3).')\r\nflags.DEFINE_integer(name='num_class', default=10, help='Set the number of classes in the dataset.')\r\n\r\n### Training specs ###\r\n#flags.DEFINE_integer(name='', default='', help='')\r\nflags.DEFINE_integer(name='num_epochs', default=5, help='Number of epochs for training.')\r\nflags.DEFINE_integer(name='max_steps', default=None, help='Number of steps for training, need to work with num_epoches.')\r\nflags.DEFINE_integer(name='summ_steps', default=100, help='Number of steps to save summary.')\r\nflags.DEFINE_integer(name='checkpoint_steps', default=500, help='Number of steps to save checkpoint which also controls evaluation frequency.')\r\n# flags.DEFINE_integer(name='checkpoint_time', default=None, help='Number of seconds to save checkpoint.')\r\nflags.DEFINE_integer(name='log_steps', default=100, help='Number of steps to print log message.')\r\nflags.DEFINE_integer(name='eval_sec', default=10, help='Throttle evaluation for at least this many seconds.')\r\nflags.DEFINE_bool(name='train_distribute', default=False, help='Whether to the train with ParameterServer strategy.')\r\n\r\n### Model specs ###\r\nK_MODELS = {\r\n    'resnet50':keras.applications.resnet.ResNet50,\r\n    'resnet101':keras.applications.resnet.ResNet101,\r\n    'resnet152':keras.applications.resnet.ResNet152,\r\n    'resnet50v2':keras.applications.resnet_v2.ResNet50V2,\r\n    'resnet101v2':keras.applications.resnet_v2.ResNet101V2,\r\n    'resnet152v2':keras.applications.resnet_v2.ResNet152V2,\r\n    'mobilenet':keras.applications.MobileNet,\r\n    'mobilenetv2':keras.applications.MobileNetV2,\r\n    'densenet121':keras.applications.densenet.DenseNet121,\r\n    'densenet169':keras.applications.densenet.DenseNet169,\r\n    'densenet201':keras.applications.densenet.DenseNet201,\r\n    'nasnetlarge':keras.applications.nasnet.NASNetLarge,\r\n    'nasnetmobile':keras.applications.nasnet.NASNetMobile,\r\n    'xception':keras.applications.xception.Xception,\r\n    'inceptionv3':keras.applications.inception_v3.InceptionV3,\r\n    'inceptionresnetv2':keras.applications.inception_resnet_v2.InceptionResNetV2,\r\n    'vgg16':keras.applications.vgg16.VGG16,\r\n    'vgg19':keras.applications.vgg19.VGG19,\r\n}\r\nOUT_LAYERS_2 = ['resnet50', 'resnet101', 'resnet152', 'resnet50v2', 'resnet101v2', 'resnet152v2',\r\n                'mobilenet', 'mobilenetv2', 'densenet121', 'densenet169', 'densenet201',\r\n                'nasnetlarge', 'nasnetmobile', 'xception', 'inceptionv3', 'inceptionresnetv2']\r\nOUT_LAYERS_4 = ['vgg16', 'vgg19']\r\n\r\nOPTIMIZERS = {\r\n    'adadelta': keras.optimizers.Adadelta,\r\n    'adagrad': keras.optimizers.Adagrad,\r\n    'adam': keras.optimizers.Adam,\r\n    'adamax': keras.optimizers.Adamax,\r\n    'ftrl': keras.optimizers.Ftrl,\r\n    'nadam': keras.optimizers.Nadam,\r\n    'rmsprop': keras.optimizers.RMSprop,\r\n    'sgd': keras.optimizers.SGD,\r\n}\r\n\r\nLOSS = ['binary_crossentropy', 'categorical_crossentropy', 'sparse_categorical_crossentropy',\r\n    'cosine_similarity', 'huber_loss', 'logcosh' , 'poisson']\r\n\r\nflags.DEFINE_enum(name='model', default='resnet50',\r\n      enum_values=K_MODELS.keys(),\r\n      help='Set the name of the neural network model.')\r\nflags.DEFINE_bool(name='pretrain', default=True, help='Whether to use weights pre-trained on ImageNet.')\r\n\r\n### Tuning parameters ###\r\nflags.DEFINE_integer(name='batch_size', default=64, help='Set batch size.')\r\nflags.DEFINE_integer(name='buffer_size', default=1000, help='Set buffer size for image preprocess.')\r\nflags.DEFINE_enum(name='optimizer', default='adam', enum_values=OPTIMIZERS.keys(), help='Optimizer for training.')\r\nflags.DEFINE_float(name='learning_rate', default=0.001, help='Learning rate for optimizer.')\r\nflags.DEFINE_float(name='momentum', default=0.0, help='Learning rate for optimizer.')\r\nflags.DEFINE_enum(name='loss', default='sparse_categorical_crossentropy', enum_values=LOSS, help='Loss for training.')\r\n\r\n\r\ndef data_fn(ds_name, mode, repeat_cnt=1):\r\n\r\n    if mode not in ['train', 'test']:\r\n        raise Exception(f'Dataset can only be splitted with \"train\" and \"test\", {mode} is not supported.')\r\n\r\n    if ds_name == 'mnist_numpy':\r\n        ### Load image data using Keras API in numpy matrix\r\n        (train_img, train_label), (test_img, test_label) = keras.datasets.mnist.load_data()\r\n        if mode == 'train':\r\n            print('MNIST training image dataset:', train_img.shape)\r\n            ### Create TF dataset objects from numpy matrix including features AND labels\r\n            dataset = tf.data.Dataset.from_tensor_slices((train_img, train_label))\r\n        else:\r\n            print('MNIST testing image dataset:', train_img.shape)\r\n            ### Create TF dataset objects from numpy matrix including features AND labels\r\n            dataset = tf.data.Dataset.from_tensor_slices((test_img, test_label))\r\n    elif ds_name in ['cifar10', 'mnist']:\r\n        dataset, metadata = tfds.load(ds_name, split=mode, as_supervised=True, with_info=True)\r\n    else:\r\n        raise Exception(f'Dataset {ds_name} is not supported')\r\n\r\n    assert isinstance(dataset, tf.data.Dataset)\r\n    print(metadata)\r\n\r\n    ### Show an example of the imported image dataset\r\n    # if tf.executing_eagerly():\r\n    #   get_label_name = metadata.features['label'].int2str\r\n    #   for image, label in train_ds.take(2):\r\n    #     plt.figure()\r\n    #     plt.imshow(image)\r\n    #     plt.title(get_label_name(label))\r\n\r\n    def preprocess(image, label):\r\n        image = tf.cast(image, tf.float32)  # Cast to float for the following feature scaling (0,1)\r\n        image = image / 255.0               # Scale feature values\r\n        image = tf.image.resize(image, (FLAGS.img_size, FLAGS.img_size))  # Resize images\r\n        return image, label\r\n\r\n    ### Shuffle images using 5000 buffer and then batch them to 32\r\n    dataset = dataset.map(preprocess).repeat(repeat_cnt).shuffle(FLAGS.buffer_size).batch(FLAGS.batch_size)\r\n    print(f'Input data (batch size {FLAGS.batch_size}): {dataset}')\r\n\r\n    return dataset\r\n\r\n\r\ndef train_input_fn():\r\n    return data_fn(FLAGS.dataset, 'train', FLAGS.num_epochs)\r\n\r\n\r\ndef eval_input_fn():\r\n    return data_fn(FLAGS.dataset, 'test')\r\n\r\n\r\ndef build_keras_model(model_name, pretrain, num_class, img_size, image_batch=None):\r\n\r\n    print('+++++ Building Keras model +++++')\r\n    w = 'imagenet' if pretrain and model_name not in ['nasnetmobile', 'nasnetlarge'] else None\r\n    keras_app = K_MODELS[model_name](input_shape=(img_size, img_size, 3), include_top=False, weights=w)\r\n#    if not pretrain:\r\n    keras_app.trainable = True\r\n\r\n    ### Build new output layers ###\r\n    # global_average_layer = keras.layers.GlobalAveragePooling2D()\r\n    # prediction_layer = keras.layers.Dense(num_class, activation='softmax')\r\n\r\n    ### Build new output layers ###\r\n    if model_name in OUT_LAYERS_2:\r\n        new_output = keras.Sequential([\r\n                keras.layers.GlobalAveragePooling2D(),\r\n                keras.layers.Dense(num_class, activation='softmax')\r\n            ])\r\n    elif model_name in OUT_LAYERS_4:\r\n        new_output = keras.Sequential([\r\n                keras.layers.Flatten(),\r\n                keras.layers.Dense(4096, activation='relu'),\r\n                keras.layers.Dense(4096, activation='relu'),\r\n                # keras.layers.Dropout(0.5),\r\n                keras.layers.Dense(num_class, activation='softmax')\r\n            ])\r\n    else:\r\n        raise Exception(f'{model_name} is not supported yet.')\r\n\r\n    ### image_batch is an optional image sample for testing ###\r\n    if image_batch is not None:\r\n        output_batch = keras_app(image_batch)\r\n        print(f'Output of feature extraction (original model):', output_batch.shape)\r\n\r\n        for i, layer in enumerate(new_output.layers):\r\n            output_batch = layer(output_batch)\r\n            print(f'Output of {i}th classification layer ({layer}): {output_batch.shape}')\r\n\r\n\r\n    keras_model = keras.Sequential([\r\n        keras_app,\r\n        new_output,\r\n    ])\r\n\r\n    ### Compile the model ###\r\n    keras_model.compile(\r\n        optimizer=OPTIMIZERS[FLAGS.optimizer](learning_rate=FLAGS.learning_rate),\r\n        loss=FLAGS.loss,\r\n        metrics=['accuracy'])\r\n\r\n    keras_model.summary()\r\n    new_output.summary()\r\n\r\n    return keras_model\r\n\r\n\r\ndef main(_):\r\n    if FLAGS.model not in K_MODELS:\r\n        raise Exception(f'{FLAGS.model} is not supported yet.')\r\n\r\n    train_ds = data_fn(FLAGS.dataset, 'train')\r\n    for image_batch, label_batch in train_ds.take(1):\r\n        pass\r\n\r\n    ### Create and compile a Keras model ###\r\n    model_keras = build_keras_model(FLAGS.model, FLAGS.pretrain,\r\n            FLAGS.num_class, FLAGS.img_size, image_batch)\r\n\r\n    ### Create RunConfig with distribution strategy ###\r\n    run_config = tf.estimator.RunConfig(\r\n        train_distribute=None,\r\n        log_step_count_steps=FLAGS.log_steps,\r\n        save_summary_steps=FLAGS.summ_steps,\r\n        save_checkpoints_steps=FLAGS.checkpoint_steps,\r\n    )\r\n    if FLAGS.train_distribute:\r\n        strategy = tf.distribute.experimental.ParameterServerStrategy()\r\n        # strategy = tf.distribute.MirroredStrategy()\r\n        run_config.replace(train_distribute=strategy)\r\n\r\n    ### Convert the Keras model to Estimator model\r\n    model_est = keras.estimator.model_to_estimator(keras_model=model_keras, model_dir=FLAGS.model_dir, config=run_config)\r\n\r\n    ### Train and evaluate the Estimator model\r\n    print('+++++ Train and evaluate the Estimator model +++++')\r\n    train_spec = tf.estimator.TrainSpec(input_fn=train_input_fn, max_steps=FLAGS.max_steps) #STEPS_PER_EPOCH * NUM_EPOCHS)\r\n    eval_spec = tf.estimator.EvalSpec(input_fn=eval_input_fn, throttle_secs=FLAGS.eval_sec)\r\n    tf.estimator.train_and_evaluate(model_est, train_spec, eval_spec)\r\n    print('+++++ Done with train_and_evaluate +++++')\r\n\r\n    ### estimator.train() => ValueError: Only `STANDALONE_CLIENT` mode is supported when you call `estimator.train`\r\n#    print('+++++ Training estimator model')\r\n#    model_est.train(input_fn=lambda: train_input_fn(), steps=5000)\r\n#    print('+++++ Estimating estimator model')\r\n#    model_est.evaluate(input_fn=lambda: train_input_fn(32), steps=10)\r\n\r\n\r\nif __name__ == '__main__':\r\n    tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\r\n    tf_logger = logging.getLogger('tensorflow')\r\n    formatter = logging.Formatter('%(levelname)s:%(created)s:%(name)s:%(message)s')\r\n    tf_logger.handlers[0].setFormatter(formatter)\r\n    app.run(main)\r\n\r\n```", "@ali-raza-tariq Are you using tensorflow 2.0 or 2.1? In the title you mentioned 2.1 but in the issue you mentioned 2.0", "@gowthamkpr ... By default, the base image is the latest Tensorflow version of 2.1.0, but it also works with 2.0. Currently I was running it using 2.1.0.", "Looks like for one of the errors, it looks like the checksum does not match in tensor_bundle.cc? @allenlavoie any idea on why this might be happening or who else would know? I'm not particularly well versed in distributed.", "Sounds like a race condition between producers and consumers of checkpoints. One possibility is that the trainer job deletes checkpoints before the eval job loads them, in which case you can make a Scaffold for your Estimator with a custom `tf.train.Saver(..., max_to_keep=None)`. By default `Saver` keeps only the most recent 5 checkpoints (and from `'_keep_checkpoint_max': 5` in your logs I see that's what's happening here too).\r\n\r\nThat's not the only possible race. Could be the eval job tries to read a checkpoint before it's completely written, but I don't think that will happen with default configurations.", "Hi @ali-raza-tariq ! \r\nWe are checking to see whether you still need help in this issue .Have you tried latest versions  (TF 2.6/2.7) yet?  Thanks!", "Hi @mohantym!\r\n\r\nApologies for the late response. I am no longer facing this issue but like I mentioned in the description, even before the issue was not deterministic. There was a chance it would happen although I must say that the frequency of it happening has reduced a lot and I could not figure out the reason behind it. Rightnow, I am still using tensorflow 2.1 with kubeflow 1.1 and everything is working fine.  Thank you for your insights!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39033\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39033\">No</a>\n"]}, {"number": 39032, "title": "Use Estimator 2.2.0", "body": "", "comments": []}, {"number": 39031, "title": "Improvements to QAT support in TFLite conversion", "body": "Improvements to QAT support in TFLite conversion.\r\n\r\n    Adds a warning if redundant back-to-back fake quantization ops are detected + associated imrpovements - typically as sign of an error in construction of a quantization-aware-traininable model construction is detect.\r\n\r\n    suppress premature elimination of Dequant ; Quant pairs that are not no-ops (i.e. applied to value of differing quantization) by mlir::TFL::Optimize: .\r\n\r\n    Handling of FakeQuantWithMinMaxArgsOp in mlir::TFL::PrepareTFPass is now consistent with that of constant min/max input FakeQuantWithMinMaxVarsPerChannelOp and FakeQuantWithMinMaxVarsOp.\r\n\r\n    tf_tfl_translate test application now exposes command-line options controlling MLIR::PassManager logging.\r\n\r\nImplementation follows guidance by Feng Liu fengliuai@google.com.", "comments": ["@andrewstevens-infineon Can you please check @liufengdb's comments and keep us posted. Thanks!", "@andrewstevens-infineon  Can you please resolve conflicts? Thanks!", "Damn  master introduced another  insertion at the same spot in the file.   Latest master is now merged to PR branch with conflict resolved.   I've also fixed formatting oops overlooked earlier.\r\n "]}, {"number": 39030, "title": "TPU training error", "body": "Tensorflow: 2.2.0-rc3\r\nPython: 3.6.9\r\n\r\nI am training on colab TPU. But got the following error:\r\n```\r\nNotFoundError: {{function_node __inference_train_function_128421}} No registered 'PyFunc' OpKernel for 'CPU' devices compatible with node {{node PyFunc}}\r\n\t.  Registered:  <no registered kernels>\r\n\r\n\t [[PyFunc]]\r\n\t [[MultiDeviceIteratorGetNextFromShard]]\r\n\t [[RemoteCall]]\r\n\t [[IteratorGetNextAsOptional]]\r\n```\r\n\r\nThen I tried to use tfrecord from generator. But got another error:\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-7-a14d46c75435> in <module>()\r\n      3 serialized_features_dataset = tf.data.Dataset.from_generator(train_D.__iter__, output_types=(tf.int32, tf.int32, tf.int32, tf.int32))\r\n      4 with tf.io.TFRecordWriter(filename) as writer:\r\n----> 5     writer.write(serialized_features_dataset)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/tf_record.py in write(self, record)\r\n    311       record: str\r\n    312     \"\"\"\r\n--> 313     super(TFRecordWriter, self).write(record)\r\n    314 \r\n    315   def flush(self):\r\n\r\nTypeError: write(): incompatible function arguments. The following argument types are supported:\r\n    1. (self: tensorflow.python._pywrap_record_io.RecordWriter, record: str) -> None\r\n\r\nInvoked with: <tensorflow.python.lib.io.tf_record.TFRecordWriter object at 0x7f299d088b48>, <FlatMapDataset shapes: (<unknown>, <unknown>, <unknown>, <unknown>), types: (tf.int32, tf.int32, tf.int32, tf.int32)>\r\n```\r\n\r\nTo help replicate my issue, this is my notebook\r\nhttps://colab.research.google.com/drive/1tQbhe_gGhIFoMuHu-HqazHzlP0Z83kwj\r\n\r\nAnd this is the dataset to run the codes:\r\nhttps://drive.google.com/drive/folders/1abgTg2uuWBmo2TTvipqiXVhxkBuLmNwb?usp=sharing\r\n", "comments": ["I have tried in colab with TF 2.1.0, 2.2-rc3 and was able to reproduce the issue. Please, find the gist [here.](https://colab.sandbox.google.com/gist/ravikyram/b06a5b1bd52117b174351203706e9caf/untitled842.ipynb)Thanks!", "@acmilannesta For the 1st error, You cannot run `PyFunc` on `TPU worker` as there is no python interpreter on TPU machines.\r\nYou can refer to the following [comment](https://github.com/tensorflow/tensorflow/issues/24099#issuecomment-468030849) for more information.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing this issue as it has been inactive for more than 2 weeks. Please add additional comments for us to open this issue again. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39030\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39030\">No</a>\n"]}, {"number": 39029, "title": "Fix regex for scope name specification", "body": "This PR tries to address the issue raised in #39019 where\r\nregex for scope name does not capture `\\` symbol.\r\n```\r\nVALID_OP_NAME_REGEX = re.compile(\"^[A-Za-z0-9.][A-Za-z0-9_.\\\\-/>]*$\")\r\n_VALID_SCOPE_NAME_REGEX = re.compile(\"^[A-Za-z0-9_.\\\\-/>]*$\")\r\n```\r\nThe reason was:\r\n1. `-` was placed in the middle and was incorrectly considered by python as a range.\r\n2. `\\\\` was considered as escape by python, so only one `\\` when `re` starts processing.\r\n\r\nThis PR moves `-` to the end, and prefix with `r` for the string:\r\n```\r\nVALID_OP_NAME_REGEX = re.compile(r\"^[A-Za-z0-9.][A-Za-z0-9_.\\\\/>-]*$\")\r\n_VALID_SCOPE_NAME_REGEX = re.compile(r\"^[A-Za-z0-9_.\\\\/>-]*$\")\r\n```\r\n\r\nThis PR fixes #39019.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["Thanks @mdanatg for the review. The PR has been updated with test case added. Please take a look.", "@mdanatg Thanks for the review. The PR has been updated."]}, {"number": 39028, "title": "tf.one_hot should support strings", "body": "**System information**\r\n- TensorFlow version: 2.2.0rc3\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nI'm sure this has been asked before, but I can't find any issue related. `tf.one_hot` should support string tensors for encoding string labels. Currently, passing a string tensor gives:\r\n\r\n```\r\n>>> tf.one_hot(tf.constant([\"a\", \"b\", \"c\"]), depth=3)\r\n---------------------------------------------------------------------------\r\nNotFoundError                             Traceback (most recent call last)\r\n<ipython-input-19-f9e0ea7fe045> in <module>\r\n----> 1 tf.one_hot(tf.constant([\"a\", \"b\", \"c\"]), depth=3)\r\n\r\n~/anaconda3/envs/ml/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py in wrapper(*args, **kwargs)\r\n    178     \"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\r\n    179     try:\r\n--> 180       return target(*args, **kwargs)\r\n    181     except (TypeError, ValueError):\r\n    182       # Note: convert_to_eager_tensor currently raises a ValueError, not a\r\n\r\n~/anaconda3/envs/ml/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py in one_hot(indices, depth, on_value, off_value, axis, dtype, name)\r\n   4008 \r\n   4009     return gen_array_ops.one_hot(indices, depth, on_value, off_value, axis,\r\n-> 4010                                  name)\r\n   4011 \r\n   4012 \r\n\r\n~/anaconda3/envs/ml/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py in one_hot(indices, depth, on_value, off_value, axis, name)\r\n   6191         pass  # Add nodes to the TensorFlow graph.\r\n   6192     except _core._NotOkStatusException as e:\r\n-> 6193       _ops.raise_from_not_ok_status(e, name)\r\n   6194   # Add nodes to the TensorFlow graph.\r\n   6195   if axis is None:\r\n\r\n~/anaconda3/envs/ml/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in raise_from_not_ok_status(e, name)\r\n   6651   message = e.message + (\" name: \" + name if name is not None else \"\")\r\n   6652   # pylint: disable=protected-access\r\n-> 6653   six.raise_from(core._status_to_exception(e.code, message), None)\r\n   6654   # pylint: enable=protected-access\r\n   6655 \r\n\r\n~/anaconda3/envs/ml/lib/python3.6/site-packages/six.py in raise_from(value, from_value)\r\n\r\nNotFoundError: Could not find valid device for node.\r\n```\r\n\r\nThis leads to clunky practices of encoding labels outside of TF before `one_hot` can be used, which is problematic in graph mode:\r\n\r\n```python\r\nfrom sklearn.preprocessing import LabelEncoder\r\n\r\nclasses = tf.constant([\"a\", \"b\", \"c\"]).numpy()  # problematic with graph mode\r\nle = LabelEncoder().fit(classes)\r\n\r\n>>> tf.one_hot(le.transform(classes), depth=3)\r\n<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\r\narray([[1., 0., 0.],\r\n       [0., 1., 0.],\r\n       [0., 0., 1.]], dtype=float32)>\r\n```\r\n\r\nCan `tf.one_hot` be adapted to support string input with a vocabulary given a priori?\r\n\r\n**Will this change the current api? How?**\r\nIt will add type support, but shouldn't change the API.\r\n\r\n**Who will benefit with this feature?**\r\nML developers.\r\n", "comments": ["Can't this be already done as a composition of a vocabulary (maybe implemented using tf.lookup) and one_hot?", "Pretty clunky to have to do something like:\r\n\r\n```python\r\nlabel_ids = lookup_ops.index_table_from_tensor(\r\n        vocabulary_list=tuple(label_vocabulary),\r\n        name=\"class_id_lookup\"\r\n    ).lookup(labels)\r\n```\r\n\r\nEspecially when other ML libraries have evolved to allow strings in one-hot encoding operations (scikit, for instance). Why ignore a useful, intuitive feature like this?"]}, {"number": 39027, "title": "Fix build failures for python 3.8", "body": "According to https://bugzilla.redhat.com/show_bug.cgi?id=1718837:\r\n\r\n> In Python 3.8, the reserved \"tp_print\" slot was changed from a function pointer to a number, `Py_ssize_t tp_vectorcall_offset`.\r\n\r\nThis fix our nightly Python 3.8 builds. \r\n\r\ncc @mihaimaruseac \r\n\r\n", "comments": ["See https://www.python.org/dev/peps/pep-0590/#id12 for the rationale. It seems the original `tp_print` slot is unused and should be fixed in Py >= 3.8.\r\n\r\nEarlier Python versions are not affected as they accepts either 0 or `nullptr`.", "Thanks @byronyi "]}, {"number": 39026, "title": "C-API input tensor type of all run functions", "body": "**System information**\r\n\r\n- all platform: C-API\r\n- version R2.2, R2.1, R2.0\r\n\r\n**Describe the current behavior**\r\n\r\nThe C-API has two types for input and output tensor, no real difference just naming, but it is disturbing to use the prefix \"output\" for an \"input\"\r\n\r\nIn the C API tensor API  has two types: input and ouput\r\n\r\n```\r\n// Represents a specific input of an operation.\r\ntypedef struct TF_Input {\r\n  TF_Operation* oper;\r\n  int index;  // The index of the input within oper.\r\n} TF_Input;\r\n\r\n// Represents a specific output of an operation.\r\ntypedef struct TF_Output {\r\n  TF_Operation* oper;\r\n  int index;  // The index of the output within oper.\r\n} TF_Output;\r\n```\r\n\r\nHowever all the run session function has the following signature \r\n\r\n```\r\nTF_CAPI_EXPORT extern void TF_SessionRun(\r\n    TF_Session* session,\r\n    // RunOptions\r\n    const TF_Buffer* run_options,\r\n    // Input tensors\r\n    const TF_Output* inputs, TF_Tensor* const* input_values, int ninputs,\r\n    // Output tensors\r\n    const TF_Output* outputs, TF_Tensor** output_values, int noutputs,\r\n        // Target operations\r\n    const TF_Operation* const* target_opers, int ntargets,\r\n    // RunMetadata\r\n    TF_Buffer* run_metadata,\r\n    // Output status\r\n    TF_Status*);\r\n```\r\n\r\nAlthough `TF_Output*` type for input does not change anything, it is a bit disturbing to use an output convention name for an input \r\n\r\n**Describe the expected behavior**\r\n\r\nAPI for the input should change `TF_Input` instead of `TF_Output`\r\n\r\n```\r\nTF_CAPI_EXPORT extern void TF_SessionRun(\r\n    TF_Session* session,\r\n    // RunOptions\r\n    const TF_Buffer* run_options,\r\n    // Input tensors\r\n    const TF_Input* inputs, TF_Tensor* const* input_values, int ninputs,\r\n    // Output tensors\r\n    const TF_Output* outputs, TF_Tensor** output_values, int noutputs,\r\n        // Target operations\r\n    const TF_Operation* const* target_opers, int ntargets,\r\n    // RunMetadata\r\n    TF_Buffer* run_metadata,\r\n    // Output status\r\n    TF_Status*);\r\n```\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/c/c_api.h \r\n\r\n**Other info / logs** \r\n\r\nThe change is cosmetic, but make more sense. I may miss something behind the current logic. all the best.\r\n", "comments": ["@timocafe \r\n Please let us know the tensorflow version used to reproduce this issue ", "Version R2.0, R2.1, R2.2 ... ", "@timocafe It looks like you are using an older Version of Tensorflow (2.2). Many bugs have been fixed in the latest version. Can you please execute your code using Latest Version (2.6) and let us know if the issue still persists? Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39026\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39026\">No</a>\n"]}, {"number": 39025, "title": "Linker errors in individual TensorFlow Lite OpenGL delegate op tests for android_arm64", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS Mojave 10.14.06\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: OnePlus 6 (Android 10, OxygenOS 10.3.2)\r\n- TensorFlow installed from (source or binary): using source\r\n- TensorFlow version:  master, commit 277fa1bbd1ffa0a54b9a4fba51fb951033ce0eca\r\n- Python version: 2.7.16\r\n- Installed using virtualenv? pip? conda?: not installed\r\n- Bazel version (if compiling from source): 2.0.0\r\n- GCC/Compiler version (if compiling from source): Apple clang version 11.0.0 (clang-1100.0.33.12)\r\n- CUDA/cuDNN version: none\r\n- GPU model and memory: AMD Radeon R9 M370X 2 GB\r\n\r\n\r\n\r\n**Describe the problem**\r\nI cannot seem to build any of the *_test targets in tensorflow/lite/delegates/gpu/gl/kernels for Android arm64. It results in the errors shown in the long log at the bottom of this post.\r\nI have tried adding `linkopts = [\"-ldl\", \"-lm\"]` to the target (resize_test), which results in a successful build, but attempting to run it on a device results in this error:\r\n`adb shell /data/local/tmp/resize_test\r\nWARNING: linker: Warning: unable to normalize \"$EXEC_ORIGIN/../../../../../../_solib_arm64-v8a/\" (ignoring)\r\nWARNING: linker: Warning: unable to normalize \"$EXEC_ORIGIN/../../../../../../_solib___Caarch64-linux-android-clang7.0.2-libcpp/\" (ignoring)\r\nWARNING: linker: Warning: unable to normalize \"$EXEC_ORIGIN/_solib___Caarch64-linux-android-clang7.0.2-libcpp/\" (ignoring)\r\nCANNOT LINK EXECUTABLE \"/data/local/tmp/resize_test\": library \"libtensorflow_Slite_Sdelegates_Sgpu_Sgl_Skernels_Slibresize.so\" not found`\r\n\r\nTrying to build for android_arm (32-bit) builds successfully without the linkopts change, but it results in a similar CANNOT LINK EXECUTABLE error:\r\n\r\n`adb shell /data/local/tmp/resize_test_\r\nWARNING: linker: Warning: unable to normalize \"$EXEC_ORIGIN/../../../../../../_solib_armeabi-v7a/\" (ignoring)\r\nWARNING: linker: Warning: unable to normalize \"$EXEC_ORIGIN/../../../../../../_solib___Carm-linux-androideabi-clang7.0.2-v7a-libcpp/\" (ignoring)\r\nWARNING: linker: Warning: unable to normalize \"$EXEC_ORIGIN/_solib___Carm-linux-androideabi-clang7.0.2-v7a-libcpp/\" (ignoring)\r\nCANNOT LINK EXECUTABLE \"/data/local/tmp/resize_test_\": library \"libtensorflow_Slite_Sdelegates_Sgpu_Sgl_Skernels_Slibresize.so\" not found`\r\n\r\nI am trying to add custom gpu ops, and need to be able to run similar tests for debugging.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n`bazel build -s -c opt --config=android_arm64 tensorflow/lite/delegates/gpu/gl/kernels:resize_test`\r\n\r\n**Any other info / logs**\r\n`bazel build -s -c opt --config=android_arm64 tensorflow/lite/delegates/gpu/gl/kernels:resize_test\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=272\r\nINFO: Reading rc options for 'build' from /Users/valentinmiu/2019/tensorflow/.bazelrc:\r\n  Inherited 'common' options: --experimental_repo_remote_exec\r\nINFO: Reading rc options for 'build' from /Users/valentinmiu/2019/tensorflow/.bazelrc:\r\n  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=v2\r\nINFO: Reading rc options for 'build' from /Users/valentinmiu/2019/tensorflow/.tf_configure.bazelrc:\r\n  'build' options: --host_force_python=PY2 --action_env PYTHON_BIN_PATH=/usr/bin/python --action_env PYTHON_LIB_PATH=/Library/Python/2.7/site-packages --python_path=/usr/bin/python --config=xla --action_env ANDROID_NDK_HOME=/Users/valentinmiu/Downloads/android-ndk-r18b --action_env ANDROID_NDK_API_LEVEL=21 --action_env ANDROID_BUILD_TOOLS_VERSION=28.0.3 --action_env ANDROID_SDK_API_LEVEL=28 --action_env ANDROID_SDK_HOME=/Users/valentinmiu/library/Android/Sdk --action_env TF_CONFIGURE_IOS=1\r\nINFO: Found applicable config definition build:v2 in file /Users/valentinmiu/2019/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1\r\nINFO: Found applicable config definition build:xla in file /Users/valentinmiu/2019/tensorflow/.bazelrc: --action_env=TF_ENABLE_XLA=1 --define=with_xla_support=true\r\nINFO: Found applicable config definition build:android_arm64 in file /Users/valentinmiu/2019/tensorflow/.bazelrc: --config=android --cpu=arm64-v8a --fat_apk_cpu=arm64-v8a\r\nINFO: Found applicable config definition build:android in file /Users/valentinmiu/2019/tensorflow/.bazelrc: --crosstool_top=//external:android/crosstool --host_crosstool_top=@bazel_tools//tools/cpp:toolchain\r\nINFO: Found applicable config definition build:macos in file /Users/valentinmiu/2019/tensorflow/.bazelrc: --copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14\r\nINFO: Analyzed target //tensorflow/lite/delegates/gpu/gl/kernels:resize_test (1 packages loaded, 92 targets configured).\r\nINFO: Found 1 target...\r\nSUBCOMMAND: # //tensorflow/lite/delegates/gpu/gl/kernels:resize_test [action 'Linking tensorflow/lite/delegates/gpu/gl/kernels/resize_test', configuration: 44182232d54477a9f9dc3ac6d26e592e936a6eb23e121761b47c234d0221e035]\r\n(cd /private/var/tmp/_bazel_valentinmiu/94cd6c8db58787268db4435bda1fd58c/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    ANDROID_BUILD_TOOLS_VERSION=28.0.3 \\\r\n    ANDROID_NDK_API_LEVEL=21 \\\r\n    ANDROID_NDK_HOME=/Users/valentinmiu/Downloads/android-ndk-r18b \\\r\n    ANDROID_SDK_API_LEVEL=28 \\\r\n    ANDROID_SDK_HOME=/Users/valentinmiu/library/Android/Sdk \\\r\n    PATH=/usr/local/opt/qt/bin:/usr/local/opt/qt/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/usr/local/share/dotnet:/Users/valentinmiu/.dotnet/tools:/Library/Frameworks/Mono.framework/Versions/Current/Commands:/Users/valentinmiu/Library/Android/sdk/tools:/Users/valentinmiu/Library/Android/sdk/platform-tools \\\r\n    PWD=/proc/self/cwd \\\r\n    PYTHON_BIN_PATH=/usr/bin/python \\\r\n    PYTHON_LIB_PATH=/Library/Python/2.7/site-packages \\\r\n    TF2_BEHAVIOR=1 \\\r\n    TF_CONFIGURE_IOS=1 \\\r\n    TF_ENABLE_XLA=1 \\\r\n  external/androidndk/ndk/toolchains/llvm/prebuilt/darwin-x86_64/bin/clang -o bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/gl/kernels/resize_test '-Wl,-rpath,$EXEC_ORIGIN/../../../../../../_solib_arm64-v8a/' '-Wl,-rpath,$EXEC_ORIGIN/../../../../../../_solib___Caarch64-linux-android-clang7.0.2-libcpp/' '-Wl,-rpath,$EXEC_ORIGIN/_solib___Caarch64-linux-android-clang7.0.2-libcpp/' -Lbazel-out/arm64-v8a-opt/bin/_solib_arm64-v8a -Lbazel-out/arm64-v8a-opt/bin/_solib___Caarch64-linux-android-clang7.0.2-libcpp bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/gl/kernels/_objs/resize_test/resize_test.o -ltensorflow_Slite_Sdelegates_Sgpu_Sgl_Skernels_Slibresize -ltensorflow_Slite_Sdelegates_Sgpu_Sgl_Skernels_Slibtest_Uutil -ltensorflow_Slite_Sdelegates_Sgpu_Sgl_Slibapi -ltensorflow_Slite_Sdelegates_Sgpu_Sgl_Slibcompiler -ltensorflow_Slite_Sdelegates_Sgpu_Sgl_Slibfloat16_Uconversions -ltensorflow_Slite_Sdelegates_Sgpu_Sgl_Scompiler_Slibfuse_Uauto_Uinput -ltensorflow_Slite_Sdelegates_Sgpu_Sgl_Scompiler_Slibfuse_Uinline -ltensorflow_Slite_Sdelegates_Sgpu_Sgl_Scompiler_Slibfuse_Uinplace -ltensorflow_Slite_Sdelegates_Sgpu_Scommon_Slibmodel_Utransformer -ltensorflow_Slite_Sdelegates_Sgpu_Sgl_Scompiler_Slibshader_Ucodegen -ltensorflow_Slite_Sdelegates_Sgpu_Sgl_Scompiler_Slibcompiled_Unode -ltensorflow_Slite_Sdelegates_Sgpu_Sgl_Scompiler_Slibrename -ltensorflow_Slite_Sdelegates_Sgpu_Sgl_Scompiler_Slibobject_Uaccessor -ltensorflow_Slite_Sdelegates_Sgpu_Sgl_Scompiler_Slibvariable_Uaccessor -ltensorflow_Slite_Sdelegates_Sgpu_Sgl_Scompiler_Slibpreprocessor -ltensorflow_Slite_Sdelegates_Sgpu_Sgl_Slibruntime -ltensorflow_Slite_Sdelegates_Sgpu_Sgl_Slibcommand_Uqueue -ltensorflow_Slite_Sdelegates_Sgpu_Sgl_Slibgl_Usync -ltensorflow_Slite_Sdelegates_Sgpu_Sgl_Slibgl_Uprogram -ltensorflow_Slite_Sdelegates_Sgpu_Sgl_Slibgl_Ushader -ltensorflow_Slite_Sdelegates_Sgpu_Scommon_Slibmemory_Umanagement -lexternal_Scom_Ugoogle_Uabsl_Sabsl_Scontainer_Slibraw_Uhash_Uset -lexternal_Scom_Ugoogle_Uabsl_Sabsl_Scontainer_Slibhashtablez_Usampler -lexternal_Scom_Ugoogle_Uabsl_Sabsl_Sbase_Slibexponential_Ubiased -lexternal_Scom_Ugoogle_Uabsl_Sabsl_Ssynchronization_Slibsynchronization -lexternal_Scom_Ugoogle_Uabsl_Sabsl_Ssynchronization_Slibgraphcycles_Uinternal -lexternal_Scom_Ugoogle_Uabsl_Sabsl_Stime_Slibtime -lexternal_Scom_Ugoogle_Uabsl_Sabsl_Stime_Sinternal_Scctz_Slibtime_Uzone -lexternal_Scom_Ugoogle_Uabsl_Sabsl_Stime_Sinternal_Scctz_Slibcivil_Utime -ltensorflow_Slite_Sdelegates_Sgpu_Sgl_Slibserialization -lexternal_Sflatbuffers_Ssrc_Slibflatbuffers -ltensorflow_Slite_Sdelegates_Sgpu_Sgl_Slibegl_Uenvironment -ltensorflow_Slite_Sdelegates_Sgpu_Sgl_Slibegl_Ucontext -ltensorflow_Slite_Sdelegates_Sgpu_Sgl_Slibegl_Usurface -ltensorflow_Slite_Sdelegates_Sgpu_Sgl_Slibobject_Umanager -ltensorflow_Slite_Sdelegates_Sgpu_Sgl_Slibgl_Ubuffer -ltensorflow_Slite_Sdelegates_Sgpu_Sgl_Slibgl_Utexture -ltensorflow_Slite_Sdelegates_Sgpu_Scommon_Slibconvert -ltensorflow_Slite_Sdelegates_Sgpu_Sgl_Slibrequest_Ugpu_Uinfo -ltensorflow_Slite_Sdelegates_Sgpu_Sgl_Slibgl_Uerrors -ltensorflow_Slite_Sdelegates_Sgpu_Sgl_Sworkgroups_Slibdefault_Ucalculator -ltensorflow_Slite_Sdelegates_Sgpu_Sgl_Sworkgroups_Slibcalculator -ltensorflow_Slite_Sdelegates_Sgpu_Scommon_Slibgpu_Uinfo -lexternal_Scom_Ugoogle_Ugoogletest_Slibgtest_Umain -ltensorflow_Slite_Sdelegates_Sgpu_Scommon_Sliboperations -ltensorflow_Slite_Sdelegates_Sgpu_Scommon_Slibmodel -ltensorflow_Slite_Sdelegates_Sgpu_Scommon_Slibdata_Utype -lexternal_Scom_Ugoogle_Uabsl_Sabsl_Stypes_Slibbad_Uany_Ucast_Uimpl -ltensorflow_Slite_Sdelegates_Sgpu_Scommon_Slibshape -lexternal_Scom_Ugoogle_Uabsl_Sabsl_Shash_Slibhash -lexternal_Scom_Ugoogle_Uabsl_Sabsl_Shash_Slibcity -lexternal_Scom_Ugoogle_Uabsl_Sabsl_Sstatus_Slibstatus -lexternal_Scom_Ugoogle_Uabsl_Sabsl_Sdebugging_Slibstacktrace -lexternal_Scom_Ugoogle_Uabsl_Sabsl_Sdebugging_Slibsymbolize -lexternal_Scom_Ugoogle_Uabsl_Sabsl_Sdebugging_Slibdebugging_Uinternal -lexternal_Scom_Ugoogle_Uabsl_Sabsl_Sdebugging_Slibdemangle_Uinternal -lexternal_Scom_Ugoogle_Uabsl_Sabsl_Sbase_Slibmalloc_Uinternal -lexternal_Scom_Ugoogle_Uabsl_Sabsl_Sstrings_Slibcord -lexternal_Scom_Ugoogle_Uabsl_Sabsl_Sstrings_Slibstr_Uformat_Uinternal -lexternal_Scom_Ugoogle_Uabsl_Sabsl_Sstrings_Slibstrings -lexternal_Scom_Ugoogle_Uabsl_Sabsl_Sstrings_Slibinternal -lexternal_Scom_Ugoogle_Uabsl_Sabsl_Sbase_Slibbase -lexternal_Scom_Ugoogle_Uabsl_Sabsl_Sbase_Slibdynamic_Uannotations -lexternal_Scom_Ugoogle_Uabsl_Sabsl_Sbase_Slibspinlock_Uwait -lexternal_Scom_Ugoogle_Uabsl_Sabsl_Snumeric_Slibint128 -lexternal_Scom_Ugoogle_Uabsl_Sabsl_Sbase_Slibthrow_Udelegate -lexternal_Scom_Ugoogle_Uabsl_Sabsl_Stypes_Slibbad_Uoptional_Uaccess -lexternal_Scom_Ugoogle_Uabsl_Sabsl_Stypes_Slibbad_Uvariant_Uaccess -lexternal_Scom_Ugoogle_Uabsl_Sabsl_Sbase_Slibraw_Ulogging_Uinternal -lexternal_Scom_Ugoogle_Uabsl_Sabsl_Sbase_Sliblog_Useverity -lexternal_Scom_Ugoogle_Ugoogletest_Slibgtest -lc++_shared -lEGL -lGLESv3 -pthread -pthread -pthread -pthread -static-libgcc -gcc-toolchain external/androidndk/ndk/toolchains/aarch64-linux-android-4.9/prebuilt/darwin-x86_64 -target aarch64-none-linux-android -no-canonical-prefixes -Lexternal/androidndk/ndk/sources/cxx-stl/llvm-libc++/libs/arm64-v8a '--sysroot=external/androidndk/ndk/platforms/android-21/arch-arm64')\r\nERROR: /Users/valentinmiu/2019/tensorflow/tensorflow/lite/delegates/gpu/gl/kernels/BUILD:712:1: Linking of rule '//tensorflow/lite/delegates/gpu/gl/kernels:resize_test' failed (Exit 1)\r\nbazel-out/arm64-v8a-opt/bin/_solib_arm64-v8a/libexternal_Scom_Ugoogle_Uabsl_Sabsl_Sstrings_Slibstrings.so: undefined reference to `nan'\r\nbazel-out/arm64-v8a-opt/bin/_solib_arm64-v8a/libexternal_Scom_Ugoogle_Uabsl_Sabsl_Sbase_Slibexponential_Ubiased.so: undefined reference to `log2'\r\nbazel-out/arm64-v8a-opt/bin/_solib_arm64-v8a/libexternal_Scom_Ugoogle_Uabsl_Sabsl_Sstrings_Slibstr_Uformat_Uinternal.so: undefined reference to `frexpf'\r\nbazel-out/arm64-v8a-opt/bin/_solib_arm64-v8a/libexternal_Scom_Ugoogle_Uabsl_Sabsl_Sstrings_Slibstr_Uformat_Uinternal.so: undefined reference to `frexpl'\r\nbazel-out/arm64-v8a-opt/bin/_solib_arm64-v8a/libexternal_Scom_Ugoogle_Uabsl_Sabsl_Stime_Slibtime.so: undefined reference to `modf'\r\nbazel-out/arm64-v8a-opt/bin/_solib_arm64-v8a/libexternal_Scom_Ugoogle_Uabsl_Sabsl_Sstrings_Slibstr_Uformat_Uinternal.so: undefined reference to `frexp'\r\nbazel-out/arm64-v8a-opt/bin/_solib_arm64-v8a/libexternal_Sflatbuffers_Ssrc_Slibflatbuffers.so: undefined reference to `acos'\r\nbazel-out/arm64-v8a-opt/bin/_solib_arm64-v8a/libexternal_Sflatbuffers_Ssrc_Slibflatbuffers.so: undefined reference to `sin'\r\nbazel-out/arm64-v8a-opt/bin/_solib_arm64-v8a/libexternal_Scom_Ugoogle_Uabsl_Sabsl_Sstrings_Slibstrings.so: undefined reference to `nanf'\r\nbazel-out/arm64-v8a-opt/bin/_solib_arm64-v8a/libexternal_Sflatbuffers_Ssrc_Slibflatbuffers.so: undefined reference to `atan'\r\nbazel-out/arm64-v8a-opt/bin/_solib_arm64-v8a/libexternal_Sflatbuffers_Ssrc_Slibflatbuffers.so: undefined reference to `asin'\r\nbazel-out/arm64-v8a-opt/bin/_solib_arm64-v8a/libexternal_Sflatbuffers_Ssrc_Slibflatbuffers.so: undefined reference to `tan'\r\nbazel-out/arm64-v8a-opt/bin/_solib_arm64-v8a/libexternal_Sflatbuffers_Ssrc_Slibflatbuffers.so: undefined reference to `cos'\r\nbazel-out/arm64-v8a-opt/bin/_solib_arm64-v8a/libexternal_Scom_Ugoogle_Uabsl_Sabsl_Snumeric_Slibint128.so: undefined reference to `truncl'\r\nbazel-out/arm64-v8a-opt/bin/_solib_arm64-v8a/libexternal_Scom_Ugoogle_Uabsl_Sabsl_Sstrings_Slibstr_Uformat_Uinternal.so: undefined reference to `ldexpl'\r\nbazel-out/arm64-v8a-opt/bin/_solib_arm64-v8a/libexternal_Scom_Ugoogle_Uabsl_Sabsl_Sstrings_Slibstr_Uformat_Uinternal.so: undefined reference to `ldexpf'\r\nclang: error: linker command failed with exit code 1 (use -v to see invocation)\r\nTarget //tensorflow/lite/delegates/gpu/gl/kernels:resize_test failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 0.722s, Critical Path: 0.28s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully`\r\n\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["It seems to work if I force static linking in addition to linkopts (even though the binary size jumps from 1.2 MB to >30 MB).\r\n\r\ncc_test(\r\n    name = \"resize_test\",\r\n    srcs = [\"resize_test.cc\"],\r\n    tags = tf_gpu_tests_tags() + [\r\n        \"notap\",\r\n        \"tflite_not_portable_ios\",\r\n    ],\r\n    deps = [\r\n        \":resize\",\r\n        \":test_util\",\r\n        \"//tensorflow/lite/delegates/gpu/common:operations\",\r\n        \"@com_google_googletest//:gtest\",\r\n    ],\r\n    linkopts = [\r\n        \"-ldl\",\r\n        \"-lm\",\r\n    ],\r\n    linkstatic = 1,\r\n)", "QQ: what does bazel build -s do?", "It shows full build commands Bazel is using.", "PR was merged. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39025\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39025\">No</a>\n"]}, {"number": 39024, "title": "[TFLite] Failed to create Hexagon delegate on Pixel 3", "body": "This template is for miscellaneous issues not covered by the other issue categories.\r\n\r\nFor questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\r\n\r\nIf you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).\r\n\r\nFor high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.\r\n#\r\n* Device information\r\n```\r\n$ adb shell getprop ro.product.device\r\nblueline\r\n$ adb shell getprop ro.board.platform\r\nsdm845\r\n```\r\n* ($APP_ROOT)/app/src/main/jniLibs\r\n```\r\n.\r\n\u251c\u2500\u2500 arm64-v8a\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 libhexagon_nn_skel.so\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 libhexagon_nn_skel_v65.so\r\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 libhexagon_nn_skel_v66.so\r\n\u2514\u2500\u2500 armeabi-v7a\r\n    \u251c\u2500\u2500 libhexagon_nn_skel.so\r\n    \u251c\u2500\u2500 libhexagon_nn_skel_v65.so\r\n    \u2514\u2500\u2500 libhexagon_nn_skel_v66.so\r\n```\r\n\r\n* ($APP_ROOT)/app/build.gradle\r\n```\r\napply plugin: 'com.android.application'\r\n\r\nandroid {\r\n    compileSdkVersion 28\r\n    defaultConfig {\r\n        applicationId \"org.tensorflow.lite.examples.classification\"\r\n        minSdkVersion 21\r\n        targetSdkVersion 28\r\n        versionCode 1\r\n        versionName \"1.0\"\r\n    }\r\n    buildTypes {\r\n        release {\r\n            minifyEnabled false\r\n            proguardFiles getDefaultProguardFile('proguard-android.txt'), 'proguard-rules.pro'\r\n        }\r\n    }\r\n    aaptOptions {\r\n        noCompress \"tflite\"\r\n    }\r\n    compileOptions {\r\n        sourceCompatibility = '1.8'\r\n        targetCompatibility = '1.8'\r\n    }\r\n}\r\n\r\nrepositories {\r\n    flatDir {\r\n        dirs 'libs'\r\n    }\r\n}\r\n\r\n// Download default models; if you wish to use your own models then\r\n// place them in the \"assets\" directory and comment out this line.\r\napply from:'download.gradle'\r\n\r\ndependencies {\r\n    implementation fileTree(dir: 'libs', include: ['*.jar'])\r\n    implementation 'com.android.support:appcompat-v7:28.0.0'\r\n    implementation 'com.android.support:design:28.0.0'\r\n\r\n    // Build off of nightly TensorFlow Lite\r\n    implementation 'org.tensorflow:tensorflow-lite:0.0.0-nightly'\r\n    implementation 'org.tensorflow:tensorflow-lite-hexagon:0.0.0-nightly'\r\n}\r\n```\r\n\r\nI followed the [TensorFlow Lite Hexagon delegate](https://www.tensorflow.org/lite/performance/hexagon_delegate) guide on Pixel 3. Tensorflow Lite was failed to create Hexagon delegate.\r\n\r\n* Log\r\n```\r\nW/inference: type=1400 audit(0.0:127864): avc: denied { search } for name=\"soc0\" dev=\"sysfs\" ino=66478 scontext=u:r:untrusted_app_27:s0:c190,c256,c512,c768 tcontext=u:object_r:sysfs_soc:s0 tclass=dir permissive=0\r\nD/org.tensorflow.lite.examples.classification: vendor/qcom/proprietary/commonsys-intf/adsprpc/src/fastrpc_apps_user.c:1615: Error: Device node open failed for domain 3 (errno Permission denied)\r\nD/org.tensorflow.lite.examples.classification: vendor/qcom/proprietary/commonsys-intf/adsprpc/src/fastrpc_apps_user.c:1916: Error 0x57: apps_dev_init failed for domain 3, errno Permission denied\r\nD/org.tensorflow.lite.examples.classification: vendor/qcom/proprietary/commonsys-intf/adsprpc/src/fastrpc_apps_user.c:2009: Error 0x57: open_dev (-1) failed for domain 3\r\nD/org.tensorflow.lite.examples.classification: vendor/qcom/proprietary/commonsys-intf/adsprpc/src/fastrpc_apps_user.c:1179: Error 0x3b: remote_handle_control_domain failed for request ID 1 on domain 3\r\nD/org.tensorflow.lite.examples.classification: vendor/qcom/proprietary/commonsys-intf/adsprpc/src/fastrpc_apps_user.c:1190: Error 0x3b: remote_handle_control failed for request ID 1\r\nW/tflite: Failed to fetch Hexagon NN version. This might be because you're using incompatible versions of libhexagon_interface and libhexagon_nn_skel. You must use compatible versions. Refer to Tensorflow Lite Hexagon Delegate Guide.\r\nI/tflite: Hexagon Delegate is not supported.\r\nW/System.err: java.lang.UnsupportedOperationException: This Device doesn't support Hexagon DSP execution.\r\nW/System.err:     at org.tensorflow.lite.experimental.HexagonDelegate.<init>(HexagonDelegate.java:40)\r\nW/System.err:     at org.tensorflow.lite.examples.classification.tflite.Classifier.<init>(Classifier.java:182)\r\nW/System.err:     at org.tensorflow.lite.examples.classification.tflite.ClassifierQuantizedMobileNet.<init>(ClassifierQuantizedMobileNet.java:37)\r\nW/System.err:     at org.tensorflow.lite.examples.classification.tflite.Classifier.create(Classifier.java:97)\r\nW/System.err:     at org.tensorflow.lite.examples.classification.ClassifierActivity.recreateClassifier(ClassifierActivity.java:167)\r\nW/System.err:     at org.tensorflow.lite.examples.classification.ClassifierActivity.lambda$onInferenceConfigurationChanged$0(ClassifierActivity.java:146)\r\nW/System.err:     at org.tensorflow.lite.examples.classification.-$$Lambda$ClassifierActivity$83lGy2TUjuj0M5n4BhMB9qlLgSY.run(Unknown Source:8)\r\nW/System.err:     at android.os.Handler.handleCallback(Handler.java:883)\r\nW/System.err:     at android.os.Handler.dispatchMessage(Handler.java:100)\r\nW/System.err:     at android.os.Looper.loop(Looper.java:214)\r\nW/System.err:     at android.os.HandlerThread.run(HandlerThread.java:67)\r\n```", "comments": ["Hi,\r\nIs this Pixel rooted ? If not, then you can't use the delegate on this phone.\r\nThe delegate won't work on non-rooted Pixel phones.\r\nYou can try any other phone (not pixel) with QC chip.\r\n\r\nThanks", "@karimnosseir I remember seeing the TFLite team mentioning that the Hexagon Delegate won't work on Pixel phones a few months ago, but no mention of why simply copying the libhexagon*.so libraries to /data/local/tmp won't work.\r\n\r\nIs it matter of running the libraries in escalated privilege under /system/lib64 or /vendor/lib64, which will require rooting and modifying those read-only partitions?  Or something to do with DSP library / driver signatures?\r\n\r\nI'm curious how one needs to mod a rooted Pixel 1 phone to get the Hexagon Delegate working.    That would make a handy compact testing device instead of an EVM dev board.\r\n\r\nI don't think the Hexagon Delegate worked on an unrooted Samsung Galaxy Tab S6 (with a QCOM SD855 SOC) either, at least when I tried a several months ago (using NNAPI didn't seem to make things run on DSP either).\r\n\r\nThanks\r\n", "@holokai-ai \r\n\r\nPixel phones have SELinux policy that disables the DSP access directly, the only way is through HAL (NNAPI).\r\nIf you have a rooted Pixel phones, you can disable SELinux policy \"abd shell setenforce 0\" and then it will work same as other phones.\r\n\r\nIt should work on other production phones fine. I don't have Samsung Galaxy tab S6, but it should work. I don't have one to try it, but i used multiple Samsung phones for testing and was working fine on all the phones i've tried..\r\nIf you can get more details about the failure i can check what is wrong.\r\n\r\nThanks", "@karimnosseir \r\n\r\nAhh ...  SELinux was the missing ingredient!   Will give it a try.\r\n\r\nWill also retry on the Tab S6 without rooting when I get a chance.  Don't want to root that tablet because it's my primary Netflix viewing platform.  :-)   :-)   Netflix won't play on rooted devices last time I checked ...\r\n\r\nThanks!\r\n", "> @holokai-ai\r\n> \r\n> Pixel phones have SELinux policy that disables the DSP access directly, the only way is through HAL (NNAPI).\r\n> If you have a rooted Pixel phones, you can disable SELinux policy \"abd shell setenforce 0\" and then it will work same as other phones.\r\n> \r\n> It should work on other production phones fine. I don't have Samsung Galaxy tab S6, but it should work. I don't have one to try it, but i used multiple Samsung phones for testing and was working fine on all the phones i've tried..\r\n> If you can get more details about the failure i can check what is wrong.\r\n> \r\n> Thanks\r\n\r\n@karimnosseir, thank you for the guide. Hexagon delegate is working with `abd shell setenforce 0` disabling SELinux.\r\n\r\n```\r\nI/inference: type=1400 audit(0.0:2179): avc: denied { search } for name=\"soc0\" dev=\"sysfs\" ino=66478 scontext=u:r:untrusted_app_27:s0:c106,c256,c512,c768 tcontext=u:object_r:sysfs_soc:s0 tclass=dir permissive=1 app=org.tensorflow.lite.examples.classification\r\nvendor/qcom/proprietary/commonsys-intf/adsprpc/src/fastrpc_apps_user.c:1744: Successfully opened fastrpc_shell_3\r\nI/inference: type=1400 audit(0.0:2185): avc: denied { read } for name=\"fastrpc_shell_3\" dev=\"dm-4\" ino=399 scontext=u:r:untrusted_app_27:s0:c106,c256,c512,c768 tcontext=u:object_r:adsprpcd_file:s0 tclass=file permissive=1 app=org.tensorflow.lite.examples.classification\r\nvendor/qcom/proprietary/commonsys-intf/adsprpc/src/fastrpc_apps_user.c:1890: Successfully created user PD on domain 3 (attrs 0x0)\r\nvendor/qcom/proprietary/commonsys-intf/adsprpc/src/fastrpc_apps_user.c:278: FastRPC latency thread started for QoS\r\nvendor/qcom/proprietary/commonsys-intf/adsprpc/src/apps_std_imp.c:749: Warning: fopen returned 0x2 for file testsig-0x5fee24bd.so. (No such file or directory)\r\nvendor/qcom/proprietary/commonsys-intf/adsprpc/src/apps_std_imp.c:749: Warning: fopen returned 0x2 for file testsig.so. (No such file or directory)\r\nvendor/qcom/proprietary/commonsys-intf/adsprpc/src/fastrpc_apps_user.c:1028: remote_handle64_open: Successfully opened handle 0x25c6a190 for file:///libhexagon_nn_skel_v65.so?hexagon_nn_domains_skel_handle_invoke&_modver=1.0&_dom=cdsp on domain 3\r\nI/tflite: Created TensorFlow Lite delegate for Hexagon.\r\nI/tflite: Hexagon delegate: 31 nodes delegated out of 31 nodes with 1 partitions.\r\n```\r\n\r\n* What I did\r\n  * Rooted Pixel 3 (AOSP)\r\n  * `adb root` and `adb shell setenforce 0`\r\n\r\nThanks", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39024\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39024\">No</a>\n"]}, {"number": 39023, "title": "Fix misspelling in tensorflow/lite/tools", "body": "Small typos in source code and Makefile.", "comments": []}, {"number": 39022, "title": "use float math calls, add tanh operation, and update abs op to use fabsf", "body": "Updates to element-wise floating point math ops, as discussed here: https://github.com/tensorflow/tensorflow/issues/39020\r\n\r\nUpdated implementation to call float-valued math.h functions instead of double-valued, e.g. `float logf(float x)` instead of `double log(double x)`.\r\n\r\nChanged AbsEval to reference `fabsf` instead of `std::abs`, which is integer-valued.\r\n\r\nChanging `#include <cmath>` to `#include <math.h>` and removing `std` namespace prefix is required due to an issue with the gcc `cmath` header file (see e.g. [this discussion](https://stackoverflow.com/questions/55458487/stdexpf-and-stdlogf-not-recognized-by-gcc-7-2-0)).\r\n\r\nThis PR also adds the tanh operator, with a trivial math.h implementation.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F39022) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F39022) for more info**.\n\n<!-- ok -->", "@pingdynasty  Can you please resolve conflicts? Thanks!", "> @pingdynasty Can you please resolve conflicts? Thanks!\r\n\r\ndone!", "Thanks Martin.\r\n\r\nThanks for your PR! \r\n\r\nDo you mind splitting this PR into 3 standalone ones? \r\n1) Changes to tensorflow/lite/micro/testing/micro_test.h \r\n2) Adding Tanh\r\n3) Using float match calls\r\n\r\nI think the first two makes sense but I have some doubts on 3) especially around using the C headers in C++. Not an expert here but isn't std::abs an overloaded function that accepts both float (which is used here) and double? http://www.cplusplus.com/reference/cmath/abs/\r\n\r\nThx", "@pingdynasty Can you please check @wangtz's comments and keep us posted. Thanks!", "@pingdynasty Can you please check @wangtz's comments and resolve conflicts?. Thanks!", "sorry @gbaned I wasn't receiving notifications for some reason.\r\nI will split the PR.", "@pingdynasty Any update on this PR? Please. Thanks!", "apologies, will get this done first part of next week @gbaned ", "@pingdynasty Any update on this PR? Please. Thanks!", "@pingdynasty, Any update on this PR? and can you please resolve conflicts. Thanks!", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "I'm going to go ahead and close this PR, because it seems to have stalled. If you're still interested in pursing this (and responding to my comments), please feel free to reopen!"]}, {"number": 39021, "title": "Buggy behaviour of dataset API", "body": "**System information**\r\n- Have I written custom code: yes, see [https://colab.research.google.com/drive/1AeVRilpcGp8zb0hZijTIxGWdL9GkzfN_](https://colab.research.google.com/drive/1AeVRilpcGp8zb0hZijTIxGWdL9GkzfN_)\r\n- OS Platform and Distribution: Google Colab (Ubuntu 18.04.3 LTS)\r\n- TensorFlow installed from (source or binary): provided by Colab\r\n- TensorFlow version (use command below): 2.2.0-rc3\r\n- Python version: 3.6.9\r\n\r\n**Describe the current behavior**\r\nAt Dataset graph branching points, the node, which is the root of the branching is resampled for each branch during one round of execution. With non-randomized inputs to the Dataset, this does not cause any problems. If the root node is after a .shuffle() call, the branches will receive different inputs in the same computation round. \r\n\r\n**Describe the expected behavior**\r\nDownstream branches should receive the same data even if shuffle() is applied.\r\n\r\n**Standalone code to reproduce the issue**\r\n[https://colab.research.google.com/drive/1AeVRilpcGp8zb0hZijTIxGWdL9GkzfN_](https://colab.research.google.com/drive/1AeVRilpcGp8zb0hZijTIxGWdL9GkzfN_)\r\n\r\n**More info**:\r\n\r\nThis behaviour is also present if the dataset is created from a generator, which handles the shuffling implicitly.\r\n\r\nEdit: fixed the links here as well", "comments": ["@csxeba \r\nThe code shared required access permission to view it, please provide with simple standalone code to replicate issue faced.", "[Right link](https://colab.research.google.com/drive/1AeVRilpcGp8zb0hZijTIxGWdL9GkzfN_)\r\nSorry, the underscore at the end of the link causes problems with MarkDown", "i am able to replicate this, please find the [gist here](https://colab.sandbox.google.com/gist/Saduf2019/6b32a8396582948eed6285215435b7af/untitled164.ipynb)", "It is also affecting TF 2.0 if that matters.", "@aaudiber could you please take a look? thanks", "Hi @csxeba,\r\n\r\nThis is working as intended. Datasets can be much larger than the memory of a single machine, so Dataset objects act like blueprints for how to produce data (instead of trying to hold the entire dataset at once). Datasets provide a streaming API for consuming data through an iterator. If you want each iterator created on a shuffled dataset to produce elements in the same order, use the `reshuffle_each_iteration` argument to `Datasest.shuffle`:\r\n\r\n```\r\nindex = index.shuffle(buffer_size=len(self.index), reshuffle_each_iteration=False)\r\n```", "Hi Audiber, thank you for the clarification!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39021\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39021\">No</a>\n"]}]