[{"number": 50459, "title": "JSON error when saving Tensorflow model. ", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): windows 10 x64 \r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): 1.14.0 gpu\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10\r\n- GPU model and memory: GeForce GTX TITAN X\r\n\r\n\r\n**Describe the current behavior**\r\nWhen saving the model the following error occurs: typeerror: ('not json serializable:', b'\\n\\x03add\\x12\\x03add\\x1a\\x14dropout_1/cond/merge\\x1a\\x12dropout/cond/merge*\\x07\\n\\x01t\\x12\\x020\\x01') addition\r\n\r\n**Describe the expected behavior**\r\nSaving of the model and continuation to the next epoch.\r\n\r\n\r\n\r\n\r\n**Standalone code to reproduce the issue**\r\nThe code for the model:\r\n`#!/usr/bin/env python\r\n# coding: utf-8\r\n\r\n# In[1]:\r\n\r\n\r\nimport tensorflow\r\nimport miscnn\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.models import Model\r\nfrom tensorflow.keras.layers import Input, concatenate\r\nfrom tensorflow.keras.layers import Conv3D, MaxPooling3D, Conv3DTranspose\r\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Conv2DTranspose, SeparableConv2D, DepthwiseConv2D\r\nfrom tensorflow.keras.layers import BatchNormalization\r\nfrom tensorflow.keras.layers import Dense, Dropout\r\nfrom tensorflow.keras.layers import Concatenate, Add, concatenate\r\nfrom tensorflow.keras.layers import ReLU\r\nfrom tensorflow.keras.initializers import glorot_normal, Identity\r\n#from tensorflow.keras.contrib.layers import repeat\r\n#from tensorflow.keras.contrib.framework import Arg_Scope\r\nfrom tensorflow.keras.regularizers import l2\r\n\r\nfrom miscnn.neural_network.architecture.abstract_architecture import Abstract_Architecture\r\n\r\nfc = Dense\r\nconv = Conv2D\r\ndeconv = Conv2DTranspose\r\nrelu = ReLU\r\nmaxpool = MaxPooling2D\r\ndropout_layer = Dropout\r\nbatchnorm = BatchNormalization\r\nwinit = glorot_normal()\r\n#repeat = repeat\r\n#arg_scope = Aarg_Scope\r\nl2_regularizer = l2\r\n\r\nclass Architecture(Abstract_Architecture):\r\n    def __init__(self,  n_classes=1, l2=None, is_training=True, upsampling=1):\r\n#         self.input_x = input_x\r\n        self.n_classes = n_classes\r\n        self.l2=None\r\n        self.is_training=True\r\n        self.upsampling=1\r\n    \r\n    def create_model_2D(self, input_shape, n_classes=1, n_labels=1,is_training=True,l2=None,upsampling=1):\r\n        inputs = Input(input_shape) \r\n    \r\n        x = downsample(inputs, n_filters_in=3, n_filters_out=16, is_training=is_training, l2=l2, name=\"d1\")\r\n        \r\n\r\n        x = downsample(x, n_filters_in=16, n_filters_out=64, is_training=is_training, l2=l2, name=\"d2\")\r\n        \r\n        x = encoder_module(x,n_filters=64, is_training=is_training, dilation=[1, 1], l2=l2, name=\"fres3\", dropout=0.0)\r\n        \r\n        x = encoder_module(x, n_filters=64,is_training=is_training, dilation=[1, 1], l2=l2, name=\"fres4\", dropout=0.0)\r\n        \r\n        x = encoder_module(x, n_filters=64,is_training=is_training, dilation=[1, 1], l2=l2, name=\"fres5\", dropout=0.0)\r\n        \r\n        x = encoder_module(x, n_filters=64,is_training=is_training, dilation=[1, 1], l2=l2, name=\"fres6\", dropout=0.0)\r\n        \r\n        x = encoder_module(x, n_filters=64,is_training=is_training, dilation=[1, 1], l2=l2, name=\"fres7\", dropout=0.0)\r\n        \r\n    \r\n        x = downsample(x,  n_filters_in=64, n_filters_out=128, is_training=is_training, l2=l2, name=\"d8\")\r\n        \r\n        x = encoder_module_multi(x, n_filters=128,is_training=is_training, dilation=[1, 2], l2=l2, name=\"fres9\", dropout=0.25)\r\n        \r\n        x = encoder_module_multi(x,n_filters=128, is_training=is_training, dilation=[1, 4], l2=l2, name=\"fres10\", dropout=0.25)\r\n        \r\n        x = encoder_module_multi(x, n_filters=128,is_training=is_training, dilation=[1, 8], l2=l2, name=\"fres11\", dropout=0.25)\r\n        \r\n        x = encoder_module_multi(x,n_filters=128, is_training=is_training, dilation=[1, 16], l2=l2, name=\"fres12\", dropout=0.25)\r\n        \r\n\r\n        x = encoder_module_multi(x, n_filters=128,is_training=is_training, dilation=[1, 1], l2=l2, name=\"fres13\", dropout=0.25)\r\n        \r\n        x = encoder_module_multi(x,n_filters=128, is_training=is_training, dilation=[1, 2], l2=l2, name=\"fres14\", dropout=0.25)\r\n        \r\n        x = encoder_module_multi(x, n_filters=128,is_training=is_training, dilation=[1, 8], l2=l2, name=\"fres15\", dropout=0.25)\r\n        \r\n        x = encoder_module_multi(x,n_filters=128, is_training=is_training, dilation=[1, 16], l2=l2, name=\"fres16\", dropout=0.25)\r\n        \r\n    \r\n        x = upsample(x, n_filters=64, is_training=is_training, l2=l2, name=\"up17\")\r\n        \r\n        x3 = downsample(inputs, n_filters_in=3, n_filters_out=16, is_training=is_training, l2=l2, name=\"d7\")\r\n        \r\n        x3 = downsample(x3, n_filters_in=16, n_filters_out=66, is_training=is_training, l2=l2, name=\"d7\")\r\n        print(x.shape)\r\n        print(x3.shape)\r\n        \r\n        #x = x+x3\r\n        x = Add()([x, x3])\r\n\r\n        x = encoder_module(x, n_filters=64,is_training=is_training, dilation=[1, 1], l2=l2, name=\"fres18\", dropout=0)\r\n        x = encoder_module(x, n_filters=64,is_training=is_training, dilation=[1, 1], l2=l2, name=\"fres19\", dropout=0)\r\n        x = upsample(x, n_filters=1, is_training=is_training, l2=l2, name=\"up23\", last=True)\r\n\r\n        #if upsampling > 1:\r\n        x = tensorflow.image.resize(x, size= [128,128], align_corners=True)\r\n        print(x.shape)\r\n        \r\n        x = Conv2D(1, (1, 1), activation='sigmoid')(x)\r\n        \r\n        model = Model(inputs=[inputs], outputs=[x])\r\n        return model\r\n\r\n    def create_model_3D(self, input_shape, n_labels=1, is_training=True):\r\n        \r\n        inputs = Input(input_shape)    \r\n        \r\n        x = downsample(inputs, n_filters_in=3, n_filters_out=16, is_training=is_training, l2=l2, name=\"d1\")\r\n\r\n        x = downsample(x, n_filters_in=16, n_filters_out=64, is_training=is_training, l2=l2, name=\"d2\")\r\n        x = encoder_module(x,n_filters=64, is_training=is_training, dilation=[1, 1], l2=l2, name=\"fres3\", dropout=0.0)\r\n        x = encoder_module(x, n_filters=64,is_training=is_training, dilation=[1, 1], l2=l2, name=\"fres4\", dropout=0.0)\r\n        x = encoder_module(x, n_filters=64,is_training=is_training, dilation=[1, 1], l2=l2, name=\"fres5\", dropout=0.0)\r\n        x = encoder_module(x, n_filters=64,is_training=is_training, dilation=[1, 1], l2=l2, name=\"fres6\", dropout=0.0)\r\n        x = encoder_module(x, n_filters=64,is_training=is_training, dilation=[1, 1], l2=l2, name=\"fres7\", dropout=0.0)\r\n    \r\n        x = downsample(x,  n_filters_in=64, n_filters_out=128, is_training=is_training, l2=l2, name=\"d8\")\r\n        x = encoder_module_multi(x, n_filters=128,is_training=is_training, dilation=[1, 2], l2=l2, name=\"fres9\", dropout=0.25)\r\n        x = encoder_module_multi(x,n_filters=128, is_training=is_training, dilation=[1, 4], l2=l2, name=\"fres10\", dropout=0.25)\r\n        x = encoder_module_multi(x, n_filters=128,is_training=is_training, dilation=[1, 8], l2=l2, name=\"fres11\", dropout=0.25)\r\n        x = encoder_module_multi(x,n_filters=128, is_training=is_training, dilation=[1, 16], l2=l2, name=\"fres12\", dropout=0.25)\r\n\r\n        x = encoder_module_multi(x, n_filters=128,is_training=is_training, dilation=[1, 1], l2=l2, name=\"fres13\", dropout=0.25)\r\n        x = encoder_module_multi(x,n_filters=128, is_training=is_training, dilation=[1, 2], l2=l2, name=\"fres14\", dropout=0.25)\r\n        x = encoder_module_multi(x, n_filters=128,is_training=is_training, dilation=[1, 8], l2=l2, name=\"fres15\", dropout=0.25)\r\n        x = encoder_module_multi(x,n_filters=128, is_training=is_training, dilation=[1, 16], l2=l2, name=\"fres16\", dropout=0.25)\r\n    \r\n        x = upsample(x, n_filters=64, is_training=is_training, l2=l2, name=\"up17\")\r\n        x3 = downsample(input_x, n_filters_in=3, n_filters_out=16, is_training=is_training, l2=l2, name=\"d7\")\r\n        x3 = downsample(x3, n_filters_in=16, n_filters_out=64, is_training=is_training, l2=l2, name=\"d7\")\r\n        #x = x+x3\r\n        x = Add()([x, x3])\r\n\r\n        x = encoder_module(x, n_filters=64,is_training=is_training, dilation=[1, 1], l2=l2, name=\"fres18\", dropout=0)\r\n        x = encoder_module(x, n_filters=64,is_training=is_training, dilation=[1, 1], l2=l2, name=\"fres19\", dropout=0)\r\n        x = upsample(x, n_filters=n_classes, is_training=is_training, l2=l2, name=\"up23\", last=True)\r\n\r\n        if upsampling > 1:\r\n            x = tensorflow.image.resize_bilinear(x, size=[x.shape[1] * upsampling, x.shape[2] * upsampling], align_corners=True)\r\n        \r\n        \r\n        model = Model(inputs=[inputs], outputs=[x])\r\n        return model\r\n\r\ndef residual_separable(input, n_filters,  is_training=True, dropout=0.3, dilation=1, l2=None, name=\"down\"):\r\n        x = SeparableConv2D(n_filters, (3, 3), strides=1, padding='same', activation='relu', dilation_rate=dilation, use_bias=False, depthwise_initializer=winit, pointwise_initializer=winit, pointwise_regularizer=l2_regularizer(0.00004))(input)\r\n        x = BatchNormalization()(x)\r\n        x = dropout_layer(rate=dropout)(x)\r\n        if input.shape[3] == x.shape[3]:\r\n            x = Add()([x, input])\r\n        return x\r\n\r\ndef residual_separable_multi(input, n_filters,  is_training, dropout=0.3, dilation=1, l2=None, name=\"down\"):\r\n        input_b = input\r\n        d = DepthwiseConv2D(3, strides=(1, 1), depth_multiplier=1,  activation='relu', padding='same', use_bias=False)\r\n        x = d(input)\r\n        x = BatchNormalization()(x)\r\n\r\n        d2= DepthwiseConv2D(3, strides=(1, 1), depth_multiplier=1,  activation='relu', padding='same', use_bias=False)\r\n        d2.dilation_rate = (dilation, dilation)\r\n        x2 = d2(input)\r\n        x2 = BatchNormalization()(x2)\r\n\r\n        #x +=x2\r\n        x = Add()([x, x2])\r\n\r\n        x = Conv2D(n_filters, 1, strides=1, padding='same', activation='relu', kernel_initializer=winit,\r\n                         dilation_rate=1, use_bias=False, kernel_regularizer=l2_regularizer(0.00004))(x)\r\n        x = BatchNormalization()(x)\r\n\r\n        x = dropout_layer(rate=dropout)(x)\r\n\r\n        if input.shape[3] == x.shape[3]:\r\n            x = Add()([x, input_b])\r\n\r\n        return x\r\n\r\n\r\ndef encoder_module(input, n_filters,  is_training = True, dropout=0.3, dilation=[1,1], l2=None, name=\"down\"):\r\n        x = residual_separable(input, n_filters,  is_training, dropout=dropout, dilation=dilation[0], l2=l2, name=name)\r\n        x = residual_separable(x, n_filters,  is_training, dropout=dropout, dilation=dilation[1], l2=l2, name=name)\r\n        return x\r\n\r\ndef encoder_module_multi(input, n_filters,  is_training = True, dropout=0.3, dilation=[1,1], l2=None, name=\"down\"):\r\n        x = residual_separable_multi(input, n_filters,  is_training, dropout=dropout, dilation=dilation[0], l2=l2, name=name)\r\n        x = residual_separable_multi(x, n_filters,  is_training, dropout=dropout, dilation=dilation[1], l2=l2, name=name)\r\n        return x\r\n\r\ndef upsample(x, n_filters, is_training=True, last=False, l2=None, name=\"down\"):\r\n        x = Conv2DTranspose(n_filters, 3, strides=2, padding='same',use_bias=True,\r\n                               kernel_initializer=winit, activation='relu',\r\n                                   kernel_regularizer=l2_regularizer(0.00004))(x)\r\n        if not last:\r\n            x = BatchNormalization()(x)\r\n\r\n        return x\r\n    \r\ndef upsample2(x, n_filters, is_training=True, last=False, l2=None, name=\"down\"):\r\n        x = Conv2DTranspose(n_filters, 3, strides=4, padding='same',use_bias=True,\r\n                               kernel_initializer=winit, activation='relu',\r\n                                   kernel_regularizer=l2_regularizer(0.00004))(x)\r\n        if not last:\r\n            x = BatchNormalization()(x)\r\n\r\n        return x    \r\n\r\ndef downsample(input, n_filters_in, n_filters_out, is_training=True, bn=False, use_relu=False, l2=None, name=\"down\"):\r\n    \r\n        maxpool_use = n_filters_in < n_filters_out\r\n\r\n        if not maxpool_use:\r\n            filters_conv = n_filters_out\r\n        else:\r\n            filters_conv = n_filters_out - n_filters_in\r\n\r\n        x = Conv2D(filters_conv, kernel_size = 3,  strides=2, padding='same', activation='relu', kernel_initializer=winit,\r\n                        dilation_rate=1, use_bias=False, kernel_regularizer=l2_regularizer(0.00004))(input)\r\n        if maxpool_use:\r\n            y = MaxPooling2D(pool_size=2, strides=2)(input)\r\n            x = Concatenate(axis=-1)([x, y]) \r\n\r\n        x = BatchNormalization()(x)\r\n#         x = ReLU(x)\r\n        return x`\r\n\r\nAnd the code I'm running:\r\n`#!/usr/bin/env python\r\n# coding: utf-8\r\n\r\n# In[7]:\r\n\r\n\r\nimport os\r\nimport tensorflow as tf\r\nimport keras\r\n\r\nimport keras.backend.tensorflow_backend\r\n\r\ngpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.40)\r\nsession = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\r\nkeras.backend.tensorflow_backend.set_session(session)\r\n\r\nos.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\r\n\r\nos.environ[\"LD_LIBRABY_PATH\"]=\"/usr/local/cuda-10.2/lib64\"\r\n\r\nimport sys\r\nimport miscnn\r\nfrom miscnn.evaluation import cross_validation\r\nfrom miscnn.data_loading.interfaces.png_IO import png_IO\r\n#from miscnn.data_loading.interfaces.image_io import Image_interface\r\nfrom miscnn.neural_network.metrics import dice_soft, dice_coefficient, dice_coefficient_loss\r\nfrom miscnn.evaluation import split_validation\r\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\r\n#from tf2cv.model_provider import get_model as tf2cv_get_model\r\nimport numpy as np\r\n\r\n#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\r\n\r\n\r\n# In[3]:\r\n\r\n\r\ndata_path = \"Zip_files/CCA_ICA_Snake\"#sys.argv[1]\r\noutput_path = \"Zip_files/Results/MiniNet_Training_1_MiniNet_GPU_notebook\" #sys.argv[2]\r\nfold = 1 #int(sys.argv[3])\r\n# print(fold)\r\n# miscnn_surf(data_path,output_path)\r\n\r\n\r\n# In[4]:\r\n\r\n\r\nprint('standard')\r\ninterface = png_IO( channels=1,classes=1,three_dim=False, im_width=128, im_height=128)\r\n#interface = png_IO(classes=1, img_type=\"grayscale\", img_format=\"png\", pattern=None)\r\n# Create the Data I/O object\r\ndata_io = miscnn.Data_IO(interface, data_path,output_path=output_path)\r\n    # Create and configure the Data Augmentation class\r\ndata_aug = miscnn.Data_Augmentation(cycles=1, scaling=True, rotations=True,\r\n                                        elastic_deform=True, mirror=True,\r\n                                        brightness=True, contrast=True,\r\n                                        gamma=True, gaussian_noise=True)\r\n        \r\n        # Create and configure the Preprocessor class\r\npp = miscnn.Preprocessor(data_io, data_aug=data_aug,batch_size=10,analysis=\"fullimage\")\r\n\r\n    # Import standard U-Net architecture and Soft Dice\r\nfrom miscnn.neural_network.architecture.unet.MiniNetMiscnn import Architecture\r\n\r\n\r\n#model = MiniNet2\r\n\r\n\r\n# In[5]:\r\n\r\n\r\nfrom miscnn.neural_network.metrics import dice_soft_loss\r\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Input, Dense, Flatten\r\n\r\n#import warnings\r\n#warnings.filterwarnings('ignore')\r\n\r\n#H =  256;\r\n#W = 256;\r\n#n_classes = 1\r\n#input_xx = Input((H,W,1),name='img')\r\n#input_xx = tf.placeholder(tf.float32,shape=[1,H,W,3], name = 'input')\r\n#training_flag = True\r\n#output_resize_factor = 1\r\n#Mininet = MiniNet2(input_xx, n_classes, is_training=training_flag, upsampling=output_resize_factor)\r\n\r\nMiniNet = Architecture(n_classes=1, l2=None, is_training=False, upsampling=2)\r\n\r\n# Create a deep learning neural network model with a standard U-Net architecture\r\nmodel = miscnn.Neural_Network(preprocessor=pp, architecture=MiniNet,\r\n                                 metrics=[dice_soft, dice_coefficient],\r\n                                learninig_rate=0.0001,loss=dice_coefficient_loss)#, gpu_number=1)\r\n\r\nsample_list = data_io.get_indiceslist()\t\r\n\r\nprint(\"done\")\r\n\r\n\r\n# In[8]:\r\n\r\n\r\ncross_validation(sample_list, model, k_fold=2, epochs=200,\r\n                    iterations=None, evaluation_path=output_path+\"evaluation\",\r\n                  draw_figures=False, run_detailed_evaluation=False,\r\n                  callbacks=[], save_models=True, return_output=False)\r\n\r\n\r\n# In[ ]:\r\n\r\n\r\n#MiniNet\r\n\r\n\r\n# In[ ]:\r\n\r\n\r\n#model.model.summary()\r\n\r\n\r\n# In[ ]:\r\n\r\n\r\nmodel.model.save_weights('saved_model_MiniNet/weights')\r\n\r\n\r\n# In[ ]:\r\n\r\n\r\n\r\n\r\n`\r\n\r\n\r\n\r\nComplete error log:\r\n`Epoch 00001: val_loss improved from inf to 0.95021, saving model to Zip_files/Results/MiniNet_Training_1_MiniNet_GPU_notebookevaluation/fold_0/model.hdf5\r\nTraceback (most recent call last):\r\n  File \"script_werkend_MiniNet.py\", line 105, in <module>\r\n    callbacks=[], save_models=True, return_output=False)\r\n  File \"/data/mapit/Data_Joerik/miscnn/evaluation/cross_validation.py\", line 84, in cross_validation\r\n    iterations=iterations, callbacks=cb_list)\r\n  File \"/data/mapit/Data_Joerik/miscnn/neural_network/model.py\", line 269, in evaluate\r\n    max_queue_size=self.batch_queue_size)\r\n  File \"/home/mapit/anaconda3/envs/MiniNet/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\", line 673, in fit\r\n    initial_epoch=initial_epoch)\r\n  File \"/home/mapit/anaconda3/envs/MiniNet/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\", line 1433, in fit_generator\r\n    steps_name='steps_per_epoch')\r\n  File \"/home/mapit/anaconda3/envs/MiniNet/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_generator.py\", line 331, in model_iteration\r\n    callbacks.on_epoch_end(epoch, epoch_logs)\r\n  File \"/home/mapit/anaconda3/envs/MiniNet/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\", line 311, in on_epoch_end\r\n    callback.on_epoch_end(epoch, logs)\r\n  File \"/home/mapit/anaconda3/envs/MiniNet/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\", line 969, in on_epoch_end\r\n    self._save_model(epoch=epoch, logs=logs)\r\n  File \"/home/mapit/anaconda3/envs/MiniNet/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\", line 1000, in _save_model\r\n    self.model.save(filepath, overwrite=True)\r\n  File \"/home/mapit/anaconda3/envs/MiniNet/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py\", line 1211, in save\r\n    saving.save_model(self, filepath, overwrite, include_optimizer, save_format)\r\n  File \"/home/mapit/anaconda3/envs/MiniNet/lib/python3.7/site-packages/tensorflow/python/keras/saving/save.py\", line 113, in save_model\r\n    model, filepath, overwrite, include_optimizer)\r\n  File \"/home/mapit/anaconda3/envs/MiniNet/lib/python3.7/site-packages/tensorflow/python/keras/saving/hdf5_format.py\", line 101, in save_model_to_hdf5\r\n    default=serialization.get_json_type).encode('utf8')\r\n  File \"/home/mapit/anaconda3/envs/MiniNet/lib/python3.7/json/__init__.py\", line 238, in dumps\r\n    **kw).encode(obj)\r\n  File \"/home/mapit/anaconda3/envs/MiniNet/lib/python3.7/json/encoder.py\", line 199, in encode\r\n    chunks = self.iterencode(o, _one_shot=True)\r\n  File \"/home/mapit/anaconda3/envs/MiniNet/lib/python3.7/json/encoder.py\", line 257, in iterencode\r\n    return _iterencode(o, 0)\r\n  File \"/home/mapit/anaconda3/envs/MiniNet/lib/python3.7/site-packages/tensorflow/python/util/serialization.py\", line 69, in get_json_type\r\n    raise TypeError('Not JSON Serializable:', obj)\r\nTypeError: ('Not JSON Serializable:', b'\\n\\x15resize/ResizeBilinear\\x12\\x0eResizeBilinear\\x1a\\x17conv2d_transpose_1/Relu\\x1a\\x0bresize/size*\\x13\\n\\ralign_corners\\x12\\x02(\\x01*\\x18\\n\\x12half_pixel_centers\\x12\\x02(\\x00*\\x07\\n\\x01T\\x12\\x020\\x01')\r\n`\r\n", "comments": ["@PitMilan \r\nAs there is no active support for 1.x, please upgrade to 2.x and let us know if you still face the error.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50459\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50459\">No</a>\n"]}, {"number": 50457, "title": "Tensorflow failed to build with ERROR: Skipping '//tensorflow/tools/pip_package:build_pip_package': error loading MSVCpackage 'tensorflow/tools/pip_package'  on windows with MSVC", "body": "Hi All,\r\n\r\nTensorflow failed to build with ERROR: Skipping '//tensorflow/tools/pip_package:build_pip_package': error loading package 'tensorflow/tools/pip_package': in F:/gitp/tensorflow/tensorflow/tensorflow/tensorflow.bzl: in F:/gitp/tensorflow/tensorflow/tensorflow/core/platform/rules_cc.bzl: in F:/gitp/tensorflow/tensorflow/tensorflow/core/platform/default/rules_cc.bzl: in F:/bazeltemp/2powapgf/external/rules_cc/cc/defs.bzl: Extension file 'cc/private/rules_impl/cc_flags_supplier.bzl' has errors on windows with MSVC. This issue can be reproduced on latest version 32634e9, Could you please look at this issue?\r\n\r\nRepro steps:\r\n1. git clone https://github.com/tensorflow/tensorflow F:\\gitP\\tensorflow\\tensorflow\r\n2. git -C \"F:\\gitP\\tensorflow\\tensorflow\" submodule update --init --recursive\r\n3. Apply tensorflow_set_bazel_version.patch\r\n4. Open a vs2019 x64 command prompt\r\n5. cd F:\\gitP\\tensorflow\\tensorflow\r\n6. pip3 install six numpy wheel\r\n7. pip3 install keras_applications==1.0.6 --no-deps\r\n8. pip3 install keras_preprocessing==1.0.5 --no-deps\r\n9. set PATH=F:\\gitP\\tensorflow\\tensorflow\\..\\tools;%path%\r\n10. set PATH=F:\\gitP\\tensorflow\\tensorflow\\..\\tools\\msys64\\usr\\bin;%path%\r\n11. yes \"\" 2>nul | python ./configure.py\r\n12. set BAZEL_VC=C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Enterprise\\VC\r\n13. set BAZEL_VC_FULL_VERSION=14.29.30037\r\n14. bazel --output_user_root F:\\bazelTemp build --config=opt --subcommands //tensorflow/tools/pip_package:build_pip_package\r\n\r\nPatch file:\r\n[tensorflow_set_bazel_version.zip](https://github.com/tensorflow/tensorflow/files/6715357/tensorflow_set_bazel_version.zip)\r\n\r\nBuild log:\r\n[build.log](https://github.com/tensorflow/tensorflow/files/6715358/build.log)\r\n\r\nError info:\r\nWARNING: Download from http://mirror.tensorflow.org/github.com/tensorflow/runtime/archive/4b20d65ea59434890477d1f24f4b660fd5a0491f.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found\r\n...\r\nERROR: F:/bazeltemp/2powapgf/external/rules_cc/cc/private/rules_impl/cc_flags_supplier.bzl:28:21: unexpected keyword 'incompatible_use_toolchain_transition', for call to function rule(implementation, test = False, attrs = None, outputs = None, executable = False, output_to_genfiles = False, fragments = [], host_fragments = [], _skylark_testable = False, toolchains = [], doc = '', provides = [], exec_compatible_with = [], analysis_test = False, build_setting = None, cfg = None)\r\nERROR: Skipping '//tensorflow/tools/pip_package:build_pip_package': error loading package 'tensorflow/tools/pip_package': in F:/gitp/tensorflow/tensorflow/tensorflow/tensorflow.bzl: in F:/gitp/tensorflow/tensorflow/tensorflow/core/platform/rules_cc.bzl: in F:/gitp/tensorflow/tensorflow/tensorflow/core/platform/default/rules_cc.bzl: in F:/bazeltemp/2powapgf/external/rules_cc/cc/defs.bzl: Extension file 'cc/private/rules_impl/cc_flags_supplier.bzl' has errors\r\nWARNING: Target pattern parsing failed.\r\nERROR: error loading package 'tensorflow/tools/pip_package': in F:/gitp/tensorflow/tensorflow/tensorflow/tensorflow.bzl: in F:/gitp/tensorflow/tensorflow/tensorflow/core/platform/rules_cc.bzl: in F:/gitp/tensorflow/tensorflow/tensorflow/core/platform/default/rules_cc.bzl: in F:/bazeltemp/2powapgf/external/rules_cc/cc/defs.bzl: Extension file 'cc/private/rules_impl/cc_flags_supplier.bzl' has errors\r\nINFO: Elapsed time: 19.654s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (1 packages loaded)\r\nFAILED: Build did NOT complete successfully (1 packages loaded)\r\n##[debug] Command #6 exited with code [1].\r\n##[error] Detected error code [1].", "comments": ["@spacelg \r\nCan you please confirm the bazel version used and roll back to a lower version and see if you are facing the issue, also please verify your system requirements and cuda if you are using from the tensorflow official page.", "@Saduf2019 \r\nThanks for your reply and info. The bazel version currently we use is 2.0.0, We try to modify configure.py to change the bazel version to the latest 4.0.0, Re-build still failed the same as above. \r\n\r\nWe regularly update the commit of the open source. This time we encountered this problem after updating the commit of Tensorflow. The old Tensorflow commit(458bb34) before this, we can build successfully. \r\n\r\nThe cuda version we use is 10.1 as below.\r\nF:\\gitP\\tensorflow\\tensorflow>nvcc --version\r\nnvcc: NVIDIA (R) Cuda compiler driver\r\nCopyright (c) 2005-2019 NVIDIA Corporation\r\nBuilt on Sun_Jul_28_19:12:52_Pacific_Daylight_Time_2019\r\nCuda compilation tools, release 10.1, V10.1.243\r\n\r\nDid our lower version of cuda cause this problem? What is the minimum cuda version to meet the build success?\r\n\r\nThanks,\r\nLin\r\n\r\n", "@Saduf2019 \r\nPlease ignore the comments above, re-downloaded bazel version 3.7.2, and it has been able to build. I will close this ticket. Thanks again for your help.\r\n\r\nThanks,\r\nLin", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50457\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50457\">No</a>\n"]}, {"number": 50456, "title": "Update DepthwiseConv2D documentation", "body": "resolves #49933\r\n\r\nI fixed the documentation of `DepthwiseConv2D` and additionally clarified the documentation regarding the `depth_multiplyer` argument.", "comments": ["@vinhill  Please create PR in keras-team/keras repo instead of tensorflow repo. Thank you!"]}, {"number": 50455, "title": "De-standardizing the output in LSTM model if the input was not standardized", "body": "I was using the LSTM model for time series prediction when I observed that the model standardises the input when given non-standard input. While predicting, the output is also standardized, but there seems no way to de-standardize. \r\nThe current solution is to standardize beforehand (using sklearn or any other) and perform the invert operation on the output.\r\n\r\n\r\n**System information**\r\n- TensorFlow version : 2.5.0\r\n\r\n**The feature and the current behaviour.**\r\nThere seems no way to de-standardize the output. One way is to add another attribute that de-standardizes when called or make a flag in the model, which tell whether the input is standardised or not, and if it's not, then standardize and return the de-standardized output.\r\n\r\n**Change the current API**\r\nI am asking for an attribute addition, at the least.\r\n\r\n**Other Info**\r\nThe following links might be of some help:\r\n[https://stackoverflow.com/a/49398454/13428777](https://stackoverflow.com/a/49398454/13428777)\r\n[https://stackoverflow.com/questions/44100837/disable-keras-batch-normalization-standardization](https://stackoverflow.com/questions/44100837/disable-keras-batch-normalization-standardization)", "comments": ["@akhil14shukla Sorry for late response.\r\n\r\nData normalization is important for any training and for many models. AFAIK, all the models under `keras.applications` normalizes data because it results in better performance. what is your use-case and can you describe more about it.\r\n\r\nPlease note that Keras development moved to keras-team/keras repo.](https://github.com/keras-team/keras/issues) repository to focus on only keras. Thanks!\r\n\r\nIf there is any actionable items, please feel free to open a PR in keras-team/keras  repository.", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 50454, "title": "assign_add() not working on GPU?", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution: Linux Ubuntu 16.04\r\n- TensorFlow version: 2.5.0\r\n- Python version: 3.9\r\n- CUDA/cuDNN version: 11.2\r\n- GPU model and memory: 4x GeForce 1080 Ti\r\n\r\n**Describe the current behavior**\r\n\r\nI have implemented a patch for optimizers which should perform simple gradient accumulation (see [link on stackoverflow](https://stackoverflow.com/questions/68121006/why-are-these-gradient-accumulation-implementations-not-working)).\r\n\r\nThe interesting observation here is that using just `assign()`, the implementation seems to work (on CPU as well as on GPU). Obviously, this would not accumulate gradients and is therefore pointless.\r\n\r\nHowever, using `assign_add()`, as it would be required for GA, the model does not converge anymore if I run the training with one GPU. I have also tried to work around this by computing `acc_grad[i].assign(acc_grad[i] + new_grad[i] / n)` but this is not working either.\r\n\r\n![image](https://user-images.githubusercontent.com/43335432/123426304-8f08f500-d5c3-11eb-8bbf-6c5a5544d926.png)\r\n\r\n**Describe the expected behavior**\r\n\r\nIf `assign_add()` worked here, the model should do at least _something_ but in the best case start to converge.\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\nIt's not entirely standalone but the code below would be use as follows:\r\n\r\n```python\r\nmodel.build()\r\noptimizer = get_patched_optimizer(optimizer, n, trainable_variables)\r\nmodel.compile(optimizer=optimizer)\r\n```\r\n\r\nwhere we have\r\n\r\n```python\r\nclass _GradientAccumulationPatch:\r\n\r\n    def __init__(\r\n        self,\r\n        n: int,\r\n        orig_apply_gradients,\r\n        trainable_variables\r\n    ):\r\n        self.n = tf.constant(n, dtype=tf.int64)\r\n        policy = tf.keras.mixed_precision.global_policy()\r\n        self.variable_dtype = policy.variable_dtype\r\n        self.accu_gradients = [\r\n            tf.Variable(\r\n                tf.zeros(g.shape, dtype=g.dtype),\r\n            ) for g in trainable_variables\r\n        ]\r\n\r\n        self._current_step = tf.Variable(0, dtype=tf.int64)\r\n        self._orig_apply_gradients = orig_apply_gradients\r\n\r\n    def apply_gradients(self, grads_and_vars, *args, **kwargs):\r\n\r\n        can_apply = self._can_apply_on_next_step()\r\n        # 1.0 whenever we want to apply gradients; 0.0 otherwise\r\n        apply = tf.cast(can_apply, dtype=self.variable_dtype)\r\n        # Will be 0.0 if apply is 1.0 and vice versa\r\n        keep = tf.cast(tf.logical_not(can_apply), dtype=self.variable_dtype)\r\n\r\n        grads_and_vars = list(grads_and_vars)\r\n        gradients = [grad for (grad, _) in grads_and_vars]\r\n        trainable_variables = [var for (_, var) in grads_and_vars]\r\n\r\n        # Accumulate gradients\r\n        for i, grad in enumerate(gradients):\r\n            # FIXME should be assign_add()\r\n            self.accu_gradients[i].assign(grad / tf.cast(self.n, dtype=grad.dtype))\r\n\r\n        # Multiply each gradient with our apply-signal\r\n        final_gradients = [grad * apply for grad in self.accu_gradients]\r\n\r\n        self._orig_apply_gradients(zip(final_gradients, trainable_variables), *args, **kwargs)\r\n\r\n        # This will reset our buffer whenever \"keep\" is 0.0\r\n        for g in self.accu_gradients:\r\n            g.assign(g * keep)\r\n\r\n    def apply_accu_gradients(self, trainable_variables, *args, **kwargs):\r\n\r\n        # Call the original apply_gradients() function\r\n        self._orig_apply_gradients(zip(self.accu_gradients, trainable_variables), *args, **kwargs)\r\n\r\n        # Reset all accumulated gradients to zero\r\n        for i in range(len(self.accu_gradients)):\r\n            self.accu_gradients[i].assign(tf.zeros_like(trainable_variables[i]))\r\n\r\n    def _can_apply_on_next_step(self):\r\n        \"\"\"\r\n        :return: True if gradients should be applied; False otherwise.\r\n        \"\"\"\r\n        # Increment (always do this first)\r\n        self._current_step.assign_add(1)\r\n        count_mod_steps = tf.math.mod(self._current_step, self.n)\r\n        return tf.equal(count_mod_steps, 0)\r\n\r\n\r\ndef get_patched_optimizer(optimizer, n, trainable_variables):\r\n    \"\"\"Patch optimizer for gradient accumulation.\r\n\r\n    :param optimizer:\r\n        The optimizer to patch.\r\n    :param n:\r\n        The number of accumulation steps before applying gradients.\r\n    :param trainable_variables:\r\n        Trainable parameters of the model\r\n    :return:\r\n        A patched patched optimizer for gradient accumulation.\r\n    \"\"\"\r\n    accumulator = _GradientAccumulationPatch(\r\n        n=n,\r\n        orig_apply_gradients=optimizer.apply_gradients,\r\n        trainable_variables=trainable_variables\r\n    )\r\n\r\n    # Replace the original function\r\n    optimizer.apply_gradients = accumulator.apply_gradients\r\n\r\n    return optimizer\r\n```\r\n\r\n----\r\n\r\n### Update\r\n\r\nI have now tried this on MNIST and it appears to work for that example. \r\n\r\nAny idea why this might not be working in my example above .. \ud83d\ude1e \r\n\r\n<details>\r\n<summary>MNIST example (click me)</summary>\r\n\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras import layers\r\n\r\n\r\nclass _GradientAccumulationPatch:\r\n\r\n    def __init__(\r\n        self,\r\n        n: int,\r\n        orig_apply_gradients,\r\n        trainable_variables\r\n    ):\r\n        self.n = tf.constant(n, dtype=tf.int64)\r\n        policy = tf.keras.mixed_precision.global_policy()\r\n        self.variable_dtype = policy.variable_dtype\r\n        self.accu_gradients = [\r\n            tf.Variable(\r\n                tf.zeros(g.shape, dtype=g.dtype),\r\n            ) for g in trainable_variables\r\n        ]\r\n\r\n        self._current_step = tf.Variable(0, dtype=tf.int64)\r\n        self._orig_apply_gradients = orig_apply_gradients\r\n\r\n    def apply_gradients(self, grads_and_vars, *args, **kwargs):\r\n\r\n        can_apply = self._can_apply_on_next_step()\r\n        # 1.0 whenever we want to apply gradients; 0.0 otherwise\r\n        apply = tf.cast(can_apply, dtype=self.variable_dtype)\r\n        # Will be 0.0 if apply is 1.0 and vice versa\r\n        keep = tf.cast(tf.logical_not(can_apply), dtype=self.variable_dtype)\r\n\r\n        grads_and_vars = list(grads_and_vars)\r\n        gradients = [grad for (grad, _) in grads_and_vars]\r\n        trainable_variables = [var for (_, var) in grads_and_vars]\r\n\r\n        # Accumulate gradients\r\n        for i, grad in enumerate(gradients):\r\n            self.accu_gradients[i].assign_add(grad / tf.cast(self.n, dtype=self.variable_dtype))\r\n\r\n        # Multiply each gradient with our apply-signal\r\n        final_gradients = [grad * apply for grad in self.accu_gradients]\r\n\r\n        self._orig_apply_gradients(zip(final_gradients, trainable_variables), *args, **kwargs)\r\n\r\n        # This will reset our buffer whenever \"keep\" is 0.0\r\n        for g in self.accu_gradients:\r\n            g.assign(g * keep)\r\n\r\n    def apply_accu_gradients(self, trainable_variables, *args, **kwargs):\r\n\r\n        # Call the original apply_gradients() function\r\n        self._orig_apply_gradients(zip(self.accu_gradients, trainable_variables), *args, **kwargs)\r\n\r\n        # Reset all accumulated gradients to zero\r\n        for i in range(len(self.accu_gradients)):\r\n            self.accu_gradients[i].assign(tf.zeros_like(trainable_variables[i]))\r\n\r\n    def _can_apply_on_next_step(self):\r\n        \"\"\"\r\n        :return: True if gradients should be applied; False otherwise.\r\n        \"\"\"\r\n        # Increment (always do this first)\r\n        self._current_step.assign_add(1)\r\n        count_mod_steps = tf.math.mod(self._current_step, self.n)\r\n        return tf.equal(count_mod_steps, 0)\r\n\r\n\r\ndef get_patched_optimizer(optimizer, n, trainable_variables):\r\n    \"\"\"Patch optimizer for gradient accumulation.\r\n\r\n    :param optimizer:\r\n        The optimizer to patch.\r\n    :param n:\r\n        The number of accumulation steps before applying gradients.\r\n    :param trainable_variables:\r\n        Trainable parameters of the model\r\n    :return:\r\n        A patched patched optimizer for gradient accumulation.\r\n    \"\"\"\r\n    accumulator = _GradientAccumulationPatch(\r\n        n=n,\r\n        orig_apply_gradients=optimizer.apply_gradients,\r\n        trainable_variables=trainable_variables\r\n    )\r\n\r\n    # Replace the original function\r\n    optimizer.apply_gradients = accumulator.apply_gradients\r\n\r\n    return optimizer\r\n\r\n\r\ndef get_ffn_model(input_size: int, output_size: int, hidden_size: int = 64) -> keras.Model:\r\n    inputs = layers.Input(shape=(input_size,))\r\n    x = inputs\r\n    x = layers.Dense(units=hidden_size, activation='tanh')(x)\r\n    x = layers.Dense(units=hidden_size, activation='tanh')(x)\r\n    x = layers.Dense(units=output_size, activation='softmax')(x)\r\n    return keras.Model(inputs=inputs, outputs=x)\r\n\r\n\r\ndef make_dataset(inputs, targets, batch_size: int):\r\n    def sample_generator_():\r\n        while True:\r\n            idx = np.random.randint(0, len(inputs))\r\n            yield inputs[idx].flatten(), tf.one_hot(targets[idx], depth=num_classes)\r\n\r\n    inputs = inputs.astype(np.float32) / 255.0\r\n    inputs = np.expand_dims(inputs, axis=-1)\r\n    num_classes = len(set(targets))\r\n\r\n    input_shape = (np.prod(inputs[0].shape),)\r\n    target_shape = (num_classes,)\r\n\r\n    return tf.data.Dataset.from_generator(\r\n        lambda: sample_generator_(),\r\n        output_types=(tf.float32, tf.float32),\r\n        output_shapes=(input_shape, target_shape)\r\n    ).padded_batch(batch_size)\r\n\r\n\r\ndef main():\r\n    train_batch_size = 1\r\n    valid_batch_size = 10\r\n    grad_acc_n = 10\r\n    steps_per_epoch = 1000 # * grad_acc_n  # Make sure we have the same number of updates\r\n\r\n    (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\r\n    train_data = make_dataset(x_train, y_train, batch_size=train_batch_size)\r\n    valid_data = make_dataset(x_test, y_test, batch_size=valid_batch_size)\r\n\r\n    input_size = train_data.element_spec[0].shape[-1]\r\n    output_size = train_data.element_spec[1].shape[-1]\r\n\r\n    model = get_ffn_model(input_size=input_size, output_size=output_size, hidden_size=128)\r\n    optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005)\r\n    optimizer = get_patched_optimizer(optimizer, n=grad_acc_n, trainable_variables=model.trainable_variables)\r\n\r\n    model.compile(\r\n        optimizer=optimizer,\r\n        loss='categorical_crossentropy',\r\n        metrics=['accuracy']\r\n    )\r\n\r\n    model.fit(\r\n        train_data,\r\n        epochs=10,\r\n        steps_per_epoch=steps_per_epoch // train_batch_size,\r\n        validation_data=valid_data,\r\n        validation_steps=10\r\n    )\r\n\r\n\r\nif __name__ == '__main__':\r\n    main()\r\n```\r\n</details>", "comments": ["It turns out that this was totally my fault and it was due to the fact that whenever I trained with a `mixed_float16` policy, I would have patched the _wrong_ instance. \r\n\r\nWhat I had was something like:\r\n\r\n```python\r\nif precision_policy.name.startswith('mixed'):\r\n    logger.info(f'Using LossScaleOptimizer (policy: \"{precision_policy.name})\"')\r\n    optimizer = keras.mixed_precision.LossScaleOptimizer(optimizer)\r\n\r\nif grad_acc_n > 1:\r\n    # --> This patched the LossScaleOptimizer which caused the problem:\r\n    optimizer = grad_acc.get_patched_optimizer(optimizer=optimizer, n=grad_acc_n)\r\n```\r\n\r\nSo I would require a check like:\r\n\r\n```python\r\nif isinstance(optimizer, keras.mixed_precision.LossScaleOptimizer):\r\n    # Warning: This does NOT work either (just an example)!\r\n    optimizer.inner_optimizer.apply_gradients = accumulator.apply_gradients\r\n    raise Exception('Don\\'t do this!')\r\nelse:\r\n    optimizer.apply_gradients = accumulator.apply_gradients\r\n```\r\n\r\nHowever, as stated in the comment, patching the `inner_optimizer` does not work either. I haven't figured out why but at least I am now able to run a \"normal\" `float32`-policy training with my `_GradientAccumulationPatch`-implementation.\r\n\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50454\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50454\">No</a>\n"]}, {"number": 50453, "title": "how to translate known tensor?", "body": "hi,dear\r\nIn dist training, I must use **for** to get matrices concat, but I can not translate it to constant tensor,\r\nthe codes down for the bug reproduce\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\nnp.random.seed(123)\r\ntf.random.set_seed(123)\r\n\r\nclass MyModel(tf.keras.Model):\r\n    def __init__(self,):\r\n        super(MyModel,self).__init__()\r\n    def call(self,inputs):\r\n        @tf.function(autograph=True)\r\n        def f():\r\n            v = tf.constant((0,))\r\n            for i in tf.range(3):\r\n                tf.autograph.experimental.set_loop_options(\r\n                shape_invariants=[(v, tf.TensorShape([None]))]\r\n                )\r\n                v = tf.concat((v, [i]), 0)\r\n            return v\r\n        print(tf.constant(f()))#bug\r\n        \r\n        return tf.math.reduce_sum(f())\r\nstrategy = tf.distribute.MirroredStrategy(\r\n        devices=[\"device:GPU:%d\" % i for i in range(2)],\r\n        cross_device_ops=None)\r\ntrain_dataset = tf.data.Dataset.from_tensor_slices((np.random.randint(0,12,size=(100,3)).astype(np.int32))).shuffle(10).batch(4)\r\ntrain_dist_dataset = strategy.experimental_distribute_dataset(train_dataset)\r\nwith strategy.scope():\r\n    model=MyModel()\r\n\r\ndef train_step(inputs):\r\n    with tf.GradientTape() as tape:\r\n        predictions = model(inputs, training=True)\r\n    return predictions\r\n@tf.function\r\ndef distributed_train_step(dataset_inputs):\r\n    per_replica_losses = strategy.run(train_step, args=(dataset_inputs,))\r\n    return strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses,\r\n                         axis=None)\r\np=0\r\nfor x in train_dist_dataset:\r\n    p+=distributed_train_step(x)\r\n```\r\nI want to translate the known tensor to constant,how to deal with it ?\r\nthx\r\n", "comments": ["got success,thx\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50453\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50453\">No</a>\n"]}, {"number": 50452, "title": "api_docs tensor incoherent sentence", "body": "\r\n## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/Tensor \r\n\r\n## Description of issue (what needs changing):\r\nThe first code snippet in the URL is coming in between the sentence which makes it incoherent.\r\n\r\n### Submit a pull request?\r\n\r\nI am new to open-source and wish to fix it myself. Can you please direct me to the file wherein the \"view aliases\" and \"code snippets\" are included. In the definition given in https://github.com/tensorflow/tensorflow/blob/v2.5.0/tensorflow/python/framework/ops.py#L264 would removing the newline character after first line in multiline comment solve the issue?  \r\n", "comments": ["@Jahnvi13 Removing the newline character after first line in multiline comment will not resolve the issue here since the changes need to be done in different element/section. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "I am having a difficulty in understanding your query here. Can you please elaborate further, perhaps using screenshots to visualize better? Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 50451, "title": "support fixed64 in features parser .", "body": "### Current:\r\n1. Our model have 900+ features(will be expanded to 2000 features within one year).\r\n2. We run tensorflow on A100 machine, and our model currently consumes TFRecord very fast, now 1700,000 TFRecords/s. PS:We replace TFRecord reader from disk to high-performance network and memory cache.\r\nAfter the above change, we find deserialize varint64 is very hot, so we check how to decode varint64 in pb.\r\n\r\n### Varint64 and Fixed64\r\n\r\n**Varint64:** A variable-length storage format, the details:https://developers.google.com/protocol-buffers/docs/encoding\r\n**Fixed64**: A fixed-length storage format, fixed use 64bit to save uint64_t\r\nDecoding varint64 needs two loop.\r\n1. Check whether the highest bit of each byte is 1\r\n2. Iterate and decode each byte, and then compose each byte into uint64_t\r\nVarint64 decodes very fast when the number is small, such as using 2-3 bytes numbers(1bytes special deal).\r\n\r\n### Why we replace Varint64 to fixed64:\r\n\r\nBut unfortunately, because our confidential data, we have to save big hash values.The storage of the hash value usually uses 7-8 bytes, and varint64 is very unfriendly to decode the hash value.\r\nso I want to replace from varint64 to fixed64, we have **a small test in _protobuf_**, through varint64 and fixed64 decoding the same hash data, we get fixed64 10 times faster than varint64.(The example is a bit complicated, but I can provide it if necessary)\r\n\r\n**Do you think it is necessary for TF to add the fixed64 type? If necessary, I can contribute this part of the code.**\r\n\r\n ### Remarks some profiling result:\r\n![image](https://user-images.githubusercontent.com/33950866/123361876-5f95c080-d5a2-11eb-8184-e9cb79b5875c.png)\r\n![image](https://user-images.githubusercontent.com/33950866/123410135-8aebd000-d5e1-11eb-9770-197fdfb8473b.png)\r\n![image](https://user-images.githubusercontent.com/33950866/123410172-963efb80-d5e1-11eb-9f0c-b015cba5c07b.png)", "comments": ["@gbaned I have not developed this feature at present, I would like to know if this feature is needed? and reviewer hasn't been online for a long time.", "> @gbaned I have not developed this feature at present, I would like to know if this feature is needed? and reviewer hasn't been online for a long time.\r\n\r\nHi @gbaned ", "@rohan100jain  Can you please assist on above comments from @zhaozheng09. Thanks!", "There is already a bytes field; what about just `tf.bitcast`ing to/from an array of bytes?", "> There is already a bytes field; what about just `tf.bitcast`ing to/from an array of bytes?\r\n\r\nMaybe it's a good idea~ I will try it.", "> > There is already a bytes field; what about just `tf.bitcast`ing to/from an array of bytes?\r\n> \r\n> Maybe it's a good idea~ I will try it.\r\n\r\n@allenlavoie \r\nI successfully write data with bytes type, then I found a problem, the output of the decoder does not match the input of tf.bitcast.\r\n\r\ndecoder(parse example) support type:```tf.float32 (`FloatList`), `tf.int64` (`Int64List`), and `tf.string` (`BytesList`) are supported. ```\r\n\r\ntf.bitcast error tips:```TypeError: Value passed to parameter 'input' has DataType string not in list of allowed values: bfloat16, float16, float32, float64, int64, int32, uint8, uint16, uint32, uint64, int8, int16, complex64, complex128, qint8, quint8, qint16, quint16, qint32```\r\n\r\n\r\na simple example:\r\n```\r\nimport tensorflow as tf\r\nimport os\r\nimport sys\r\n#from tensorflow.contrib.afo import AfoDataset\r\n\r\n#input(\"pid : \" + str(os.getpid()) + \", press enter to continue .\")\r\ntf.compat.v1.disable_eager_execution()\r\n\r\ndef _int64_feature(value) :\r\n    return tf.train.Feature(int64_list = tf.train.Int64List(value = [value]))\r\ndef _bytes_feature(value) :\r\n    return tf.train.Feature(bytes_list = tf.train.BytesList(value = [value]))\r\n\r\ndef WriteRecords(filename, data_type=True):\r\n    with tf.compat.v1.python_io.TFRecordWriter(filename) as writer:\r\n        for i in range(50):\r\n            write_one_record(data=i, label=i+1, writer = writer, data_type=data_type)\r\n\r\n# data_type: True: int64, False: bytes\r\ndef write_one_record(data, label, writer, data_type=True):\r\n    if data_type == True:\r\n      feature = {\r\n              'label': _int64_feature(label),\r\n              'image':_int64_feature(data),\r\n              }\r\n    else:\r\n      #b_data = bytes(str(data), encoding='utf-8')\r\n      #b_label = bytes(str(label), encoding='utf-8')\r\n      b_data = (data).to_bytes(8, byteorder='little')\r\n      b_label = (label).to_bytes(8, byteorder='little')\r\n      feature = {\r\n              'label': _bytes_feature(b_data),\r\n              'image':_bytes_feature(b_label),\r\n              }\r\n\r\n    tf_example = tf.train.Example(features = tf.train.Features(feature = feature))\r\n    tf_example = tf.train.Example(features = tf.train.Features(feature = feature))\r\n\r\n    writer.write(tf_example.SerializeToString())\r\n\r\ndef ReadRecordsByReader():\r\n\r\n    tf.enable_eager_execution()\r\n\r\n    image_dataset = tf.data.TFRecordDataset('image.tfrecords')\r\n\r\n    image_feature_description = {\r\n            'label':tf.FixedLenFeature([], tf.int64),\r\n            'image':tf.FixedLenFeature([], tf.int64),\r\n            }\r\n    def parser(example_proto):\r\n        return tf.parse_single_example(example_proto, image_feature_description)\r\n\r\n    parse_dataset = image_dataset.map(parser)\r\n\r\n    for image_feature in parse_dataset:\r\n        image = image_feature['image']\r\n        label = image_feature['label'].numpy()\r\n        tensorLabel = tf.constant(label)\r\n        print (image)\r\n        print (tensorLabel)\r\n\r\ndef GetResult(sess, data):\r\n   return sess.run(data)\r\n\r\ndef PrepareProto(data_type):\r\n  if data_type == True:\r\n    image_feature_description = {\r\n            'label':tf.compat.v1.FixedLenFeature([], tf.int64),\r\n            'image':tf.compat.v1.FixedLenFeature([], tf.int64),\r\n            }\r\n  else:\r\n    image_feature_description = {\r\n            'label':tf.compat.v1.FixedLenFeature([], tf.string),\r\n            'image':tf.compat.v1.FixedLenFeature([], tf.string),\r\n            }\r\n  return image_feature_description\r\n\r\ndef PrepareData(filename, data_type=True):\r\n    dataset = tf.data.TFRecordDataset(filename)\r\n    image_feature_description = PrepareProto(data_type)\r\n    def parser(example_proto):\r\n        return tf.compat.v1.parse_example(example_proto, image_feature_description)\r\n        #return tf.parse_single_example(example_proto, image_feature_description)\r\n\r\n    dataset = dataset.batch(2)\r\n    dataset = dataset.map(parser)\r\n    #iter = dataset.make_one_shot_iterator();\r\n    f_iter = tf.compat.v1.data.make_one_shot_iterator(dataset);\r\n    one = f_iter.get_next()\r\n    #one['image'] = tf.bitcast(one['image'], tf.int64)\r\n    if data_type == False:\r\n      #pass\r\n      one['image'] = tf.io.decode_raw(one['image'], tf.int64)\r\n      one['label'] = tf.io.decode_raw(one['label'], tf.int64)\r\n      one['image'] = tf.squeeze(one['image'], axis=-1)\r\n      one['label'] = tf.squeeze(one['label'], axis=-1)\r\n\r\n    one['image'] = tf.compat.v1.Print(one['image'], [tf.shape(one['image'])], \"zz:\", 10,10)\r\n    sess = tf.compat.v1.Session();\r\n    return sess, one\r\n\r\n\r\ndef ReadFixed64RecordsByIter(filename) :\r\n    sess, one = PrepareData(filename, data_type=True)\r\n    for i in range(25):\r\n        record = GetResult(sess, one);\r\n        #record = sess.run(one)\r\n        image = record['image']\r\n        label = record['label']\r\n        print(image, label)\r\ndef ReadBytesRecordsByIter(filename) :\r\n    sess, one = PrepareData(filename, data_type=False)\r\n    for i in range(25):\r\n        record = GetResult(sess, one);\r\n        #record = sess.run(one)\r\n        image = record['image']\r\n        label = record['label']\r\n        print(image, label)\r\n\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    WriteRecords('int64.tfr', True)\r\n    WriteRecords('bytes.tfr', False)\r\n    ReadFixed64RecordsByIter('int64.tfr')\r\n    ReadBytesRecordsByIter('bytes.tfr')\r\n    #ReadRecordsByReader()\r\n```", "I don't see how this PR helps that case. It doesn't handle strings either, does it?\r\n\r\nYou might be able to use `tf.strings.bytes_split` or something like that to make bytes from strings.", "Sorry, misread your comment. You're saying it's coming out as a tf.string dtype and you want it as uint8/int8/etc. again so you can bitcast it back? For that I would suggest inserting `tf.io.decode_raw` on the string to get it back to a dense array of bytes.", "Please try Allen's suggestion to see if that works. Other than that, would be okay adding this field to the proto but tf.Example is used a fair amount and we'll have to update all the places its parsed\r\n\r\nhttps://cs.opensource.google/search?q=int64_list&sq=&ss=tensorflow \r\n\r\nIf we can do that, it'll be fine adding this.", "https://cs.opensource.google/search?q=%22.int64_list%22&sq=&ss=tensorflow is maybe a better list", "@zhaozheng09 Can you please check @rohan100jain's comments and keep us posted ? Thanks!", "@zhaozheng09 Any update on this PR? Please. Thanks!", "> Please try Allen's suggestion to see if that works. Other than that, would be okay adding this field to the proto but tf.Example is used a fair amount and we'll have to update all the places its parsed\r\n> \r\n> https://cs.opensource.google/search?q=int64_list&sq=&ss=tensorflow\r\n> \r\n> If we can do that, it'll be fine adding this.\r\n\r\nget I will try it.", "> Sorry, misread your comment. You're saying it's coming out as a tf.string dtype and you want it as uint8/int8/etc. again so you can bitcast it back? For that I would suggest inserting `tf.io.decode_raw` on the string to get it back to a dense array of bytes.\r\n\r\nget I will try it.", "@allenlavoie  ```decode_raw``` looks okay.\r\n Do we still need this pr, if not, I will close this pr.\r\ncc @rohan100jain ", "If decode_raw works for you, then we can close the PR", "> If decode_raw works for you, then we can close the PR\r\n\r\nthx"]}, {"number": 50450, "title": "CombinedNMS plugin deactivated with TRT < 8. Only FP32 allowed with TRT >= 8", "body": "This PR closes and replaces https://github.com/tensorflow/tensorflow/pull/48950.\r\n\r\n- Disallow CombinedNMS Converter for TensorRT < 8.\r\n- Only allow FP32 CombinedNMS with TensorRT >= 8.\r\n\r\nThis PR addresses issues with the CombinedNMS TensorRT plugin.\r\n\r\n@bixia1 for review\r\nCC: @jhalakpatel @tfeher ", "comments": ["@DEKHTIARJonathan  Can you please assist on above comments from @jhalakp-nvidia. Thanks!", "@DEKHTIARJonathan Any update on this PR? and please resolve conflicts Thanks!", "@DEKHTIARJonathan Any update on this PR? Please. Thanks!"]}, {"number": 50448, "title": "Tflite: issue with dilated convolution in a dynamic shape CNN", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 (for model creation)\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: OnePlus 8 (Android 11), Sony Xperia 10 (Android 10)\r\n- TensorFlow installed from (source or binary): from pip\r\n- TensorFlow version (use command below): 2.5.0 (v2.5.0-rc3-213-ga4dfb8d1a71 2.5.0)\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 11.3\r\n- GPU model and memory: Geforce RTX 3060\r\n\r\n\r\n**Describe the current behavior**\r\n\r\nI'm trying to use a pre-trained model for image processing in my android app. The input shape is [None, None, None, 3]\r\nand the output shape is inferred from the input shape. My issue happens when the model has a convolution layer with \r\ndilation (same models without dilation work fine).\r\n\r\nThe android code I use for inference is has the following part:\r\n    \r\n    interpreter.resizeInput(0, new int[]{1, height, width, 3});\r\n    interpreter.allocateTensors();\r\n    Tensor tensor = interpreter.getOutputTensor(0);\r\n    int[] outShape = tensor.shape();\r\n\r\nMy issue is that the content of outShape is always [1, 1, 1, outChannels]. I'm also not able to recover the output\r\nof the model with interpreter.runForMultipleInputsOutputs even if I provide arrays with the correct output sizes.\r\n\r\n**Describe the expected behavior**\r\n\r\nThe content of shape should depend on the input (in the example I provide it should be [1, height, width, 16])\r\n\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\nHere is a link to minimal models which show the issue I described:\r\n\r\n[dilated_conv.zip](https://github.com/tensorflow/tensorflow/files/6712927/dilated_conv.zip)\r\n\r\nI've tried 3 different quantization options but it doesn't change anything.\r\n\r\nHere is the python code I used to produce the tflite models. \r\n\r\n    import tensorflow as tf\r\n    import numpy as np\r\n    \r\n    \r\n    def convert(model, fname, quantize_level=0):\r\n        converter = tf.lite.TFLiteConverter.from_keras_model(model)\r\n        if quantize_level > 0:\r\n            converter.optimizations = [tf.lite.Optimize.DEFAULT]\r\n            if quantize_level > 1:\r\n                converter.target_spec.supported_types = [tf.float16]\r\n                fname = \"{}_quantized_f16\".format(fname)\r\n            else:\r\n                fname = \"{}_quantized_default\".format(fname)\r\n    \r\n        tflite_model = converter.convert()\r\n        with open(\"{}.tflite\".format(fname), 'wb') as f:\r\n            f.write(tflite_model)\r\n    \r\n    \r\n    x = tf.keras.layers.Input([None, None, 3], dtype=tf.float32)\r\n    conv = tf.keras.layers.Conv2D(filters=16, kernel_size=(3, 3), padding=\"same\", dilation_rate=6, activation=None)\r\n    conv.build(x.shape)\r\n    conv.set_weights([np.random.rand(3, 3, 3, 16), np.random.rand(16)])\r\n    y = conv(x)\r\n    model = tf.keras.Model(x, y)\r\n    \r\n    for i in range(3):\r\n        convert(model, \"dilated_conv\", quantize_level=i)\r\n\r\nI have also tried to add a reshape layer but it doesn't make any difference:\r\n\r\n    x = tf.keras.layers.Input([None, None, 3], dtype=tf.float32)\r\n    conv = tf.keras.layers.Conv2D(filters=16, kernel_size=(3, 3), padding=\"same\", dilation_rate=6, activation=None)\r\n    conv.build(x.shape)\r\n    conv.set_weights([np.random.rand(3, 3, 3, 16), np.random.rand(16)])\r\n    y = conv(x)\r\n    y = tf.reshape(y, tf.shape(x))\r\n    model = tf.keras.Model(x, y)\r\n\r\nFor the android part, I am using the java API and the issue is there with tflite versions 2.2.0, 2.3.0 and 2.5.0.\r\nJust creating an interpreter from one of the above models (without GPU or NNApi delegate) and trying to resize the \r\ninput shows the behavior I described. (if you feed it an image it will do some computations and produce an output with the\r\nwrong shape)", "comments": ["@haozha111 Do you have time to take a look? or feel free to rebalance this to other people. Thanks", "I think this might be an issue happened during shape propagation after you call `ResizeInput`. Have you tried to set the input shape as a static shape (instead of `None` in the dimensions) and see whether the output tensor has the expected shape?", "Yes, my issue is specifically for dynamic shapes. If I use static shapes to prepare the model and then convert it it works\\*, but I need dynamic shapes in my app.\r\n\r\n\\* actually if I set a static shape with the batch size set to 1, I get a crash on the default delegate and the NNApi delegate, but it works well on the GPU one. Batch size set to None works with all delegate but is then slower on the GPU one. I feel like this is a different issue though and it is less critical to my use case. \r\nI haven't reported this problem yet because it happens on my full model, and doesn't happen if I remove the dilated convolution, but I haven't been able to make a minimal example. The crash doesn't happen if the model is a single dilated convolution layer.", "@haozha111 Any idea why this happens? By the way the problem seems to be specific to the android tflite library, and not to the model itself. I tried to run the same model with the python interpreter and it works as expected.", "Thanks for the info. If the issue only happens in the android tflite library, and not reproducible on desktop with the python interpreter, then I guess it's probably not caused by the dilated conv in the model. Have you tried the latest tf-nightly and see if the problem fixes? ", "Thank you for the answer.\r\n\r\nI just tried with tf-nightly and it gives the same results.\r\n\r\n> it's probably not caused by the dilated conv in the model\r\n\r\nI'm not sure what you mean by that, but the issue doesn't happen with other layers. In the minimal model I provided, which is only one convolutional layer, if you remove dilation then the bug doesn't happen. Similarly in my actual model (which has many more layers), if the bug only happens if there is some dilation somewhere.\r\n\r\nWhat's weird is that I have tried adding a reshape layer after the dilated convolution to enforce the correct shape but it doesn't change anything.", "Sure. So the issue is gone if you use the python interpreter (on desktop) ?", "Yes, the python interpreter has the correct shape, and give the same output as the original tensorflow (not lite) model.", "Hi,\r\n\r\nI checked the float tflite model you shared, and I found that the dilated conv pattern is not folded (there is still the SpaceToBatchNd, and BatchToSpaceNd op in your model). This is because the BatchToSpaceNd op is taking > 1 input. Given it's not folded, I think the shape issue is not caused by the dilated conv folding pass in MLIR.\r\n\r\nI also checked that your model's input has static shape [1, 1, 1, 3] while its shape signature is [-1, -1, -1, 3], this is correct since the first 3 dimensions are dynamic. Given that the output shape is correct when you run in python interpreter, but becomes incorrect when you run on android, I suspect this is caused by the JNI binding layer. When you call Resize in Java, I suspect something is going wrong in the JNI layer which fails to propagate the new shape to each tensor. Could you also share your Java code that resizes the model's input shape?", "Hi, thank you for the answer.\r\n\r\nI tried to extract only the relevant parts of the code, if you need more details please let me know. The models I provided are in the assets folder of the app. Here is the class responsible for running the model on a bitmap.\r\n\r\n```\r\npublic class TfLiteIssue {\r\n\r\n    private final static String TAG = \"TfLiteIssue\";\r\n    private final Interpreter interpreter;\r\n\r\n    public TfLiteIssue(Context context) throws IOException {\r\n        this(context, \"dilated_conv.tflite\");\r\n    }\r\n\r\n    public TfLiteIssue(Context context, String modelPath) throws IOException {\r\n        AssetFileDescriptor fileDescriptor = context.getAssets().openFd(modelPath);\r\n        FileInputStream inputStream = new FileInputStream(fileDescriptor.getFileDescriptor());\r\n        long startOffset = fileDescriptor.getStartOffset();\r\n        long declaredLength = fileDescriptor.getDeclaredLength();\r\n        FileChannel fileChannel = inputStream.getChannel();\r\n        interpreter = new Interpreter(fileChannel.map(FileChannel.MapMode.READ_ONLY, startOffset, declaredLength),\r\n                new Interpreter.Options());\r\n    }\r\n\r\n\r\n    public float[][][][] runModel(Bitmap input) {\r\n        interpreter.resizeInput(0, new int[]{1, input.getHeight(), input.getWidth(), 3});\r\n        interpreter.allocateTensors();\r\n        Log.d(TAG, \"Output shape \" + Arrays.toString(interpreter.getOutputTensor(0).shape()));\r\n        Map<Integer, Object> tfOutput = new HashMap<>();\r\n        tfOutput.put(0, createOutputArray());\r\n        interpreter.runForMultipleInputsOutputs(new float[][][][][]{asFloatArray(input)}, tfOutput);\r\n        return (float[][][][]) tfOutput.get(0);\r\n    }\r\n\r\n\r\n    private float[][][][] createOutputArray() {\r\n        Tensor tensor = interpreter.getOutputTensor(0);\r\n        int[] shape = tensor.shape();\r\n        return new float[1][shape[1]][shape[2]][shape[3]];\r\n    }\r\n\r\n    private float[][][][] asFloatArray(Bitmap bitmap) {\r\n        int width = bitmap.getWidth();\r\n        int height = bitmap.getHeight();\r\n        int[] intPixels = new int[height * width];\r\n        float[][][][] floatPixels = new float[1][height][width][3];\r\n        bitmap.getPixels(intPixels, 0, width, 0, 0, width, height);\r\n        for (int i = 0; i < height; i++) {\r\n            for (int j = 0; j < width; j++) {\r\n                int pixel = intPixels[j + i * width];\r\n                floatPixels[0][i][j][0] = (float) (pixel & 0x00FF0000 >> 16) / 255;\r\n                floatPixels[0][i][j][1] = (float) (pixel & 0x0000FF00 >> 8) / 255;\r\n                floatPixels[0][i][j][2] = (float) (pixel & 0x000000FF) / 255;\r\n            }\r\n        }\r\n        return floatPixels;\r\n    }\r\n}\r\n```\r\n\r\nIn my main activity, I simply call\r\n\r\n`TfLiteIssue(getContext()).runModel(bitmap);`\r\n\r\nIn the logcat this shows an output shape of [1, 1, 1, 3], instead of something with the same shape as the input image.\r\nMy bitmap comes from a content provider but it gives the same result with a constant color, for example\r\n\r\n```\r\nBitmap image = Bitmap.createBitmap(256, 256, Bitmap.Config.ARGB_8888);\r\nimage.eraseColor(android.graphics.Color.GREEN);\r\nTfLiteIssue(getContext()).runModel(bitmap);\r\n```\r\n", "@lu-wang-g Hi Lu, since this is related with the Java API, do you know if this is the recommended way to do resizing in Java? Is there any API that the TF Lite support library can provide here? Thanks!", "The code snippet from @arolet looks good to me. Through I have no clue yet why this happened. I can reproduce the issue locally. I'll take a closer look at it tomorrow.", "Found that the output tensor shape won't be updated until `runForMultipleInputsOutputs` is called. So if you move your log after inference, it will show the correct output shape. I also verified and confirmed this behaviour with the Python API.\r\n\r\nBefore this issue, I also thought `allocateTensors()` is good enough to update the output tensor shape. And I'm pretty sure it works for some dynamic shape models I've been before. Not sure if certain ops may break the rule. @haozha111 do you have any pointers?\r\n", "From the code description here:\r\nhttps://github.com/tensorflow/tensorflow/blob/411666f39a4ed530a9e9f95655de022cb675c655/tensorflow/lite/java/src/main/java/org/tensorflow/lite/InterpreterApi.java#L299\r\n\r\nSpecifically:\r\nNote that, for graphs with output shapes that are dependent on input *values*, the output shape may not be fully determined until\r\n running inference.\r\n", "I think the reason is that, in your model the `SpaceToBatchND` op's padding input is a tensor (int32[2, 2]). The value of the padding tensor will determine the output shape of the `SpaceToBatchND` op, see documentation here on the role of `padding`:\r\nhttps://www.tensorflow.org/api_docs/python/tf/space_to_batch\r\n\r\nSo I think your model's actual output shape can only be determined after the first inference run. Could you just get the output shape after inference finishes?", "@lu-wang-g Thank you for your answer. On my device (a OnePlus 8 with android 11), the shape is still wrong after runForMultipleInputsOutputs. allocateTensors reshapes the outputs correctly with all the layers I tried, only convolution with dilation yields a wrong shape.\r\n\r\n@haozha111 It could be a solution, however: 1) it doesn't work on the devices I tried and 2) it would require to run the inference twice, since with the android api we need to give buffers of the correct shape for the output (so the one inference to propagate the shape and one to actually get the output), which is quite slow. Also it should be possible to compute the output shape beforehand, since it's done correctly when there is no dilation and in any case, a convolution with padding='same' is not supposed to change the size.\r\n\r\nAlso, adding a reshape layer to force the correct shape after the dilated convolution doesn't change the issue (see the initial post). To me it shows that there is probably something more going on doesn't it?", "Hi,\r\n\r\nWhen you say that the output shape is still wrong after `runForMultipleInputsOutputs`, what's the output shape you get? Is it different from what the python API is giving to you (supposing python API is working normally).\r\n\r\nI'm just curious why the behavior is different between the Java and python API.", "@haozha111 the \"wrong\" output shape on android is [1, 1, 1, 16], just like before. In python the output shape is the correct one (i.e. [1, im_height, im_width, 16].", "Hi @arolet, here is the code I used to run your model:\r\n\r\n```\r\n    Interpreter interpreter = new Interpreter(dilated, new Interpreter.Options());\r\n    int[] inputDims = {1, 10, 10, 3};\r\n    interpreter.resizeInput(0, inputDims);\r\n\r\n    interpreter.allocateTensors();\r\n    Map<Integer, Object> tfOutput = new HashMap<>();\r\n    tfOutput.put(0, new float[1][10][10][16]);\r\n    float[][][][] input = new float[1][10][10][3];\r\n    interpreter.runForMultipleInputsOutputs(new float[][][][][]{input}, tfOutput);\r\n    Log.d(TAG, \"output shape \" + Arrays.toString(interpreter.getOutputTensor(0).shape()));\r\n```\r\n\r\nThe printed shape is [1, 10, 10, 16], And I verified it using a Pixel 4 device. Please check if the code snippet works for you.", "Hello @lu-wang-g, thank you for your update.\r\n\r\nThat's something I actually tried before and I get an IllegalArgumentException with the following message:\r\n\r\n`Cannot copy from a TensorFlowLite tensor (Identity) with shape [1, 1, 1, 16] to a Java object with shape [1, 384, 704, 16].`\r\n\r\nJust to be sure I tried again with the 2.5.0 and nightly versions and both gave me the error. I only tried with my OnePlus 8 yet, I will check other devices later.", "@arolet Do you mind to try the exactly same code I pasted above, and see if it works for you? After that, we can continue debugging your code.", "@lu-wang-g your exact code works! I have tried to check what the difference with mine is and it looks like the problem only arises with non-square images.\r\n\r\nMore specifically I created this function:\r\n\r\n```\r\n    public float[][][][] runModel(int width, int height){\r\n        int[] inputDims = {1, height, width, 3};\r\n        Interpreter interpreter = new Interpreter(dilated, new Interpreter.Options());\r\n        interpreter.resizeInput(0, inputDims);\r\n\r\n        interpreter.allocateTensors();\r\n        Log.d(TAG, \"Output shape \" + Arrays.toString(interpreter.getOutputTensor(0).shape()));\r\n        Map<Integer, Object> tfOutput = new HashMap<>();\r\n        tfOutput.put(0, new float[1][height][width][16]);\r\n        float[][][][] input = new float[1][height][width][3];\r\n        interpreter.runForMultipleInputsOutputs(new float[][][][][]{input}, tfOutput);\r\n        Log.d(TAG, \"output shape \" + Arrays.toString(interpreter.getOutputTensor(0).shape()));\r\n        return (float[][][][]) tfOutput.get(0);\r\n    }\r\n```\r\n\r\nIt gives the crash I described the other day if \"width!=height\" (width=100 and height=200 in my test). If I replace the first line with dimensions in the wrong order, then there is no crash anymore:\r\n```\r\n    public float[][][][] runModel(int width, int height){\r\n        int[] inputDims = {1, width, height, 3};\r\n        Interpreter interpreter = new Interpreter(dilated, new Interpreter.Options());\r\n        interpreter.resizeInput(0, inputDims);\r\n\r\n        interpreter.allocateTensors();\r\n        Log.d(TAG, \"Output shape \" + Arrays.toString(interpreter.getOutputTensor(0).shape()));\r\n        Map<Integer, Object> tfOutput = new HashMap<>();\r\n        tfOutput.put(0, new float[1][height][width][16]);\r\n        float[][][][] input = new float[1][height][width][3];\r\n        interpreter.runForMultipleInputsOutputs(new float[][][][][]{input}, tfOutput);\r\n        Log.d(TAG, \"output shape \" + Arrays.toString(interpreter.getOutputTensor(0).shape()));\r\n        return (float[][][][]) tfOutput.get(0);\r\n    }\r\n```\r\nI don't know if this helps. (note that dimensions are inversed only in the first line)", "If you remove the `Log` right after `allocateTensors()`, it will work. Calling `interpreter.getOutputTensor(0)` will create the Java output tensor from the native layer immediately. Right after `allocateTensors()`, the output tensor shape remains [1, 1, 1, 16]. It will not be refreshed in `runForMultipleInputsOutputs`. Therefore you ended up with the issue that \"Cannot copy from a TensorFlowLite tensor (Identity) with shape [1, 1, 1, 16] to a Java object with shape [1, 100, 200, 16].\". If you don't call `interpreter.getOutputTensor(0)` before `runForMultipleInputsOutputs `, `runForMultipleInputsOutputs` will create the Java output tensor from native layer during the process, and by that time, the output tensor shape has been updated to [1,  100, 200, 16].\r\n\r\nWhen you reversed `height` and `width`, you changed the input tensor shape,  meaning the input shape of `runForMultipleInputsOutputs` does not match the input shape set from `resizeInput`. Therefore, `runForMultipleInputsOutputs` triggered an implicit resize and updated both input and output tensor shape.\r\n\r\nThis is a flaw in the workflow of the Java API, and it's not easy to fix right away. So the short answer is don't trigger `interpreter.getOutputTensor()` before `runForMultipleInputsOutputs`.", "@lu-wang-g oh it does work without the log, that's great thanks!!!\r\n\r\nSo as long as I know the output size before-hand it should be fine I guess. I will try with my actual model (for which the output size is not actually the same as the input size) and close the issue if it works.", "I tried with my actual model, and TL;DR: it now works.\r\n\r\nIf there is an `getOutputTensor()` anywhere before `runForMultipleInputsOutputs()` though, then I get the error I described earlier, even if it is also before `resizeInput()` and `allocateTensors()`. So basically I had to remove all calls to `getOutputTensor()` (I had some just after the interpreter instantiation to get the number of output channels dynamically).\r\n\r\nThanks a lot for your help, I'm closing the issue since there is a workaround (although I still hope it gets fixed some day).", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50448\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50448\">No</a>\n", "@arolet Hi, I'm currently writing a [test case](https://github.com/tensorflow/tflite-support/pull/612#issuecomment-891764933) that checks the ability of the model to re-dim the graph as per the given input. The model you've provided could serve as the testing model.  Do you mind if I use your model? ", "@jonpsy sure go ahead, feel free to use any of the code too."]}, {"number": 50447, "title": "Why the output tensor device type is GPU even though I set the HostMemory attr?", "body": "Hi folks,\r\nI am trying to create an Op recently. This is part of my Op kernel builder:\r\n```\r\nREGISTER_KERNEL_BUILDER(Name(\"Test\").Device(::tensorflow::DEVICE_GPU)\r\n                                                      .HostMemory(\"output\"),\r\n                        TestOp);\r\n\r\nREGISTER_OP(\"Test\")\r\n    .Input(\"tensor: T\")\r\n    .Output(\"output: T\")\r\n    .SetShapeFn([](::tensorflow::shape_inference::InferenceContext* c) {\r\n      ::tensorflow::shape_inference::ShapeHandle output;\r\n      TF_RETURN_IF_ERROR(c->ReplaceDim(c->input(0), 0, c->UnknownDim(), &output));\r\n      c->set_output(0, output);\r\n      return ::tensorflow::Status::OK();\r\n    })\r\n```\r\nFor my Op, it's expected the input is on the device while the output will be on the host. However, after I call my python Op and obtain the ```output``` tensor, I tried to print the device type ```print(output.device)```. I found that the output tensor is on the ```GPU```, which is supposed to be ```CPU``` for my case?\r\n\r\nI also tried to set the attribute manually inside the Op_kernel.\r\n```\r\n::tensorflow::AllocatorAttributes alloc_attrs;\r\nalloc_attrs.set_on_host(true);\r\nOP_REQUIRES_OK_ASYNC(context, context->allocate_output(0, result_shape, &output), done);\r\n```\r\nBut the result ```print(output.device)``` is still on the device(GPU). Anyone can help me figure out this issue?", "comments": []}, {"number": 50446, "title": "[TFTRT] Correct SimpleITensor Assertion", "body": "This fixes an incorrect assertion where the tensor type should be checked as kSIMPLE instead of kTRT.\r\n\r\nCC @bixia1 @DEKHTIARJonathan @tfeher ", "comments": []}, {"number": 50445, "title": "TFLite converts splits of int64 tensors, but fails to evaluate the conversion", "body": "\r\n**System information**\r\n- OS Platform and Distribution MacOS \r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from  binary:\r\n- TensorFlow version 2.5.0:\r\n- Python version: 3.8\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n```\r\ndef test_split_export():\r\n    @tf.function\r\n    def test_fn(inp: tf.Tensor) -> tf.Tensor:\r\n        return tf.concat(tf.split(inp, 3, axis=1), axis=1)\r\n\r\n    concrete_f = test_fn.get_concrete_function(tf.TensorSpec((None, 3), tf.int64))\r\n    converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_f])\r\n    tflite_model = converter.convert()\r\n    interpreter = tf.lite.Interpreter(model_content=tflite_model)\r\n    interpreter.allocate_tensors()\r\n\r\n```\r\n**Describe the current behavior**\r\n\r\nThe example converts fine, but attempt to instantiate evaluation breaks in allocate_tensors with the error:\r\n\r\nE     RuntimeError: tensorflow/lite/kernels/split.cc:90 input_type == kTfLiteFloat32 || input_type == kTfLiteUInt8 || input_type == kTfLiteInt8 || input_type == kTfLiteInt16 || input_type == kTfLiteInt32 was not true.Node number 0 (SPLIT) failed to prepare.\r\n\r\n**Describe the expected behavior**\r\nTFLite1 did not produce this error. Ideally behavior should be identical to TFLite1 (I think it downconverted all int64s to int32. If TFLite does not do downconversion, then the split should be able to support int64 tensors.(\r\n\r\nThank you.", "comments": ["Thanks. I can reproduce this issue at my side.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50445\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50445\">No</a>\n", "Please consider using the Select TF ops for enabling int64 type inputs in the TF Split op.", "We considered using SELECT_TF_OPS, but the increase in the size of the resulting binary makes this option very unattractive.\r\n\r\nThe fact that the converter produces an artifact that the interpreter cannot run definitely seems like an issue with one or both products. The fact that the TfLite 1.15 converter/interpreter pair did not have this problem seems like a regression.\r\n\r\nGiven that the concatenation kernel and the split_v kernel support kTfLiteInt64, it is surprising that the split kernel does not. After comparing the the split and split_v kernels, I think that the behavior described in this ticket seems almost trivial to address.\r\n\r\nIn fact, I made the obvious (but maybe incorrect) update to split.cc, built from source, and the issue was resolved.", "Please consider uploading a separate issue for filing a feature request for int64 support in TFLite split kernels with your usage's context information.\r\n\r\nFor the binary size issue, you can reduce the selective build for Select TF enabled TFLite AAR. https://www.tensorflow.org/lite/guide/reduce_binary_size", "I dont think so. TOCO converter in the TF version one does not have enough type support checks.."]}, {"number": 50444, "title": "Create 90-keras-issue.md", "body": "Added a tf.keras template to notify the users about `tf.keras` code moved from [tensorflow/tensorflow](https://github.com/tensorflow/tensorflow) repository to [keras-team/keras](https://github.com/keras-team/keras) repository. \r\n\r\nAlso, asking users to create new issues in [keras-team/keras](https://github.com/keras-team/keras/issues) repository.", "comments": []}, {"number": 50442, "title": "Add tf.keras template", "body": "Added a tf.keras template to notify the users about `tf.keras` code moved from [tensorflow/tensorflow](https://github.com/tensorflow/tensorflow) repository to [keras-team/keras](https://github.com/keras-team/keras) repository. \r\n\r\nAlso, asking users to create new issues in [keras-team/keras](https://github.com/keras-team/keras/issues) repository.", "comments": ["Sorry, by mistake i edited performance issue template. Closing this and deleting this branch. Will create new template (without editing other templates). Thanks Scott"]}, {"number": 50439, "title": "Android Studio is unable to Load https://github.com/tensorflow/examples/tree/master/lite/examples/image_classification/android", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version:\r\n- Python version:\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\nAfter cloning the repository https://github.com/tensorflow/examples/tree/master/lite/examples/image_classification/android when I try to open the project in Android Studio version 4.2, the left window of IDE shows loading but it never loads..", "comments": ["@VirVisha ,\r\n\r\nIn order to expedite the trouble-shooting process, could you please provide the tensorflow version,complete code and dataset or colag gist to reproduce the issue reported here.", "@tilakrayal I am following the instructions mentioned on https://github.com/tensorflow/examples/tree/master/lite/examples/image_classification/android. \r\nAs mentioned in the link that Android Studio should be 3.2 or more, I am using Android Studio 4.2. Still the repository never gets loaded into Studio, it just waits there with Loading .. prompt in the Left window of the IDE\r\n\r\n", "@VirVisha ,\r\n\r\nThis is not related to TensorFlow bug or feature request, it is better asked on [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow). There is a larger community that reads questions there. Thanks!\r\n", "@tilakrayal I have rectified it, there is a dependency of Android SDK 29 for the repository to be loaded correctly. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50439\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50439\">No</a>\n"]}, {"number": 50438, "title": "Code from TF2.4.1 does not work in TF2.5", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (use command below): v2.5.0-rc3-213-ga4dfb8d1a71 2.5.0\r\n- Python version: 3.9\r\n- CUDA/cuDNN version: 11.2/8\r\n- GPU model and memory: RTX3070\r\n\r\n**Describe the current behavior**\r\nInstall tensorflow 2.4 through\r\n```\r\npip install tensorflow==2.4.1\r\n```\r\n\r\nNotice that the following code works: \r\n```python\r\nimport tensorflow.experimental.numpy as tnp\r\n\r\narange = tnp.arange(10, dtype=tnp.float32)\r\npos_vs = tnp.tile(arange, (4, 10, 1))\r\npos_us = tnp.transpose(pos_vs, [0, 2, 1])\r\nprint(pos_us)\r\n```\r\n\r\nInstall tensorflow 2.5 through\r\n```\r\npip install tensorflow==2.5.0\r\n```\r\n\r\nThe code above fails with the following error:\r\n```\r\nAttributeError: \r\n        'EagerTensor' object has no attribute 'reshape'.\r\n        If you are looking for numpy-related methods, please run the following:\r\n        import tensorflow.python.ops.numpy_ops.np_config\r\n        np_config.enable_numpy_behavior()\r\n```\r\n\r\n**Describe the expected behavior**\r\nThe code in TF2.5 should work just fine, as no related breaking change has been introduced.\r\n\r\nGist with link to colab: https://gist.github.com/benjs/6955171d577536fdf0df3528ea673674\r\n", "comments": ["Have you tried with\r\n```python\r\nimport tensorflow.python.ops.numpy_ops.np_config as np_config\r\nnp_config.enable_numpy_behavior()\r\n```", "@benjs \r\nAs reported in the error message to use the \"enable numpy behavior\" and as bhack has highlighted, the error does not appear, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/7c6f1bc38818e7acb2051b965fadc95e/untitled609.ipynb)", "Wether the bug can be fixed or not, the behavior of the framework should not differ as [no breaking change has been introduced](https://github.com/tensorflow/tensorflow/releases/tag/v2.5.0).\n\nAlso, the error message should be adjusted to recommend using [tensorflow.experimental.numpy.experimental_enable_numpy_behavior](https://www.tensorflow.org/api_docs/python/tf/experimental/numpy/experimental_enable_numpy_behavior) which is the same function and can be found in the docs already.\n\nI can submit a PR on that if you like.", ">tensorflow.experimental.numpy.experimental_enable_numpy_behavior\u00a0only exists in\u00a0tf-nightly.\n\nhttps://www.tensorflow.org/guide/tf_numpy?hl=en", "This part of the documentation is outdated too.\r\n\r\nPlease test this yourself:\r\n```\r\npip install tensorflow\r\n```\r\n```python\r\nimport tensorflow as tf\r\nimport tensorflow.experimental.numpy as tnp\r\n\r\nprint(tf.__version__)\r\n\r\ntnp.experimental_enable_numpy_behavior()\r\n\r\narange = tnp.arange(3, dtype=tnp.float32)\r\npos_vs = tnp.tile(arange, (2, 3, 1))\r\npos_us = tnp.transpose(pos_vs, [0, 2, 1])\r\n\r\nprint(\"No error raised until here!\")\r\n``` \r\n```\r\n2.5.0\r\nNo error raised until here!\r\n```\r\n", "Ok, so you can submit a PR.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50438\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50438\">No</a>\n"]}, {"number": 50437, "title": "An macro defination mistake in test_benchmark.h", "body": "branch r2.5\r\ntensorflow/tensorflow/core/platform/default/test_benchmark.h: 32\r\n```cpp\r\n#define BENCHMARK(n)                                            \\\r\n  static ::tensorflow::testing::Benchmark* TF_BENCHMARK_CONCAT( \\\r\n      __benchmark_, n, __LINE__) TF_ATTRIBUTE_UNUSED =          \\\r\n      (new ::tensorflow::testing::Benchmark(#n, (n)))\r\n#define TF_BENCHMARK_CONCAT(a, b, c) TF_BENCHMARK_CONCAT2(a, b, c)\r\n#define TF_BENCHMARK_CONCAT2(a, b, c) a##b##c\r\n```\r\nconv_benchmark\u4f7f\u7528\u5b8f\u65f6\uff0c\u5176\u5f62\u5f0f\u53c2\u6570\u4e5f\u5305\u542b\u5b8f\r\n\r\n```cpp\r\nBENCHMARK(BM_NAME(BM_Conv2D, type, N, H, W, C, FW, FH, FC))->Arg(/*unused arg*/ 1);\r\n```\r\n\u5b9e\u9645\u4e0aBM_NAME\u5e76\u6ca1\u6709\u88ab\u5c55\u5f00\uff0c\u6b64benchmar test \u7684\u540d\u5b57\u5c06\u53d8\u6210\r\ne.g. BM_NAME(BM_Conv2D, cpu, 16, 1, 8, 8, 16, 16, 8)\r\n\r\n\u63d0\u4f9b\u4e00\u5c42\u5c01\u88c5\u624d\u4f1a\u5c55\u5f00\r\n```cpp\r\n#define _BENCHMARK(n)                                           \\\r\n  static ::tensorflow::testing::Benchmark* TF_BENCHMARK_CONCAT( \\\r\n      __benchmark_, n, __LINE__) TF_ATTRIBUTE_UNUSED =          \\\r\n      (new ::tensorflow::testing::Benchmark(#n, (n)))\r\n#define TF_BENCHMARK_CONCAT(a, b, c) TF_BENCHMARK_CONCAT2(a, b, c)\r\n#define TF_BENCHMARK_CONCAT2(a, b, c) a##b##c\r\n\r\n#define BENCHMARK(n) _BENCHMARK(n)\r\n```", "comments": ["@huxiao0 \r\n\r\nIn order to expedite the trouble-shooting process, please provide a colab gist with all the dependencies to reproduce the issue reported here. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 50435, "title": "Fix -Wloop-analysis warnings.", "body": "Bug: chromium:1223264", "comments": []}, {"number": 50434, "title": "[MLIR][DISC] legalize disc to llvm", "body": "This PR provides conversion patterns to convert `disc_ral.dispatch_op`\r\nand `gpu.launch_op` to its disc-compatible llvm format.", "comments": ["@joker-eph Hi, could you help to review the updated version? Thanks!", "@joker-eph Hi, could you help to take a look? Thanks!", "@joker-eph Hi\uff0ccould you help to take a look? Thanks!", "You may have missed my comment inline: https://github.com/tensorflow/tensorflow/pull/50434#discussion_r661107002 ?"]}, {"number": 50433, "title": "Saved Keras model cannot be loaded using hub.KerasLayer API", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): `Yes`\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): `Linux 8d350c6303d5 5.4.104+ #1 SMP Sat Jun 5 09:50:34 PDT 2021 x86_64 x86_64 x86_64 GNU/Linux`\r\n\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: `N/A`\r\n- TensorFlow installed from (source or binary): `binary`\r\n- TensorFlow version (use command below): `v2.5.0-0-ga4dfb8d1a71 2.5.0`\r\n- Python version: `sys.version_info(major=3, minor=7, micro=10, releaselevel='final', serial=0)`\r\n- Bazel version (if compiling from source):  `N/A`\r\n- GCC/Compiler version (if compiling from source):  `N/A`\r\n- CUDA/cuDNN version:  `N/A`\r\n- GPU model and memory:  `N/A`\r\n\r\n**Describe the current behavior**\r\n\r\nAfter creating a simple `tf.keras.Model` with `IntegerLookup`, the model can be saved using `save` API but cannot be load using `hub.KerasLayer` API. It throws the following error:\r\n\r\n```\r\n\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-9-a9c000ccc830> in <module>()\r\n----> 1 loaded_model = hub.KerasLayer('./saved_model')\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow_hub/keras_layer.py in __init__(self, handle, trainable, arguments, _sentinel, tags, signature, signature_outputs_as_dict, output_key, output_shape, load_options, **kwargs)\r\n    170 \r\n    171     self._callable = self._get_callable()\r\n--> 172     self._setup_layer(trainable, **kwargs)\r\n    173 \r\n    174   def _setup_layer(self, trainable=False, **kwargs):\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow_hub/keras_layer.py in _setup_layer(self, trainable, **kwargs)\r\n    187       for v in self._func.variables:\r\n    188         if id(v) not in trainable_variables:\r\n--> 189           self._add_existing_weight(v, trainable=False)\r\n    190 \r\n    191     # Forward the callable's regularization losses (if any).\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow_hub/keras_layer.py in _add_existing_weight(self, weight, trainable)\r\n    201     \"\"\"Calls add_weight() to register but not create an existing weight.\"\"\"\r\n    202     if trainable is None: trainable = weight.trainable\r\n--> 203     self.add_weight(name=weight.name, shape=weight.shape, dtype=weight.dtype,\r\n    204                     trainable=trainable, getter=lambda *_, **__: weight)\r\n    205 \r\n\r\nAttributeError: 'NoneType' object has no attribute 'name'\r\n```\r\n\r\n**Describe the expected behavior**\r\n\r\nBased on [Tensorflow's doc](https://www.tensorflow.org/hub/tf2_saved_model#saving_from_keras), the expected behavior is:\r\n> Starting with TensorFlow 2, `tf.keras.Model.save()` and `tf.keras.models.save_model()` default to the SavedModel format (not HDF5). The resulting SavedModels that can be used with `hub.load()`, `hub.KerasLayer` and similar adapters for other high-level APIs as they become available.\r\n\r\n- Do you want to contribute a PR? (yes/no): no\r\n- Briefly describe your candidate solution(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\nPlease find the gist here: https://gist.github.com/bxshi/b0b99c4ed537fd57c05e2b1ef8964c52 \r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["Was able to reproduce the issue. Please find the gist [here](https://colab.research.google.com/gist/saikumarchalla/0b24e7bf30745e4677bfb1df05e56092/reproduce-integerlookup-issue.ipynb). Thanks!\r\n\r\n@bxshi The Documentation reference which you have provided is incorrect.", "@saikumarchalla link updated, thanks for following up.", "@jvishnuvardhan if you can instruct me on how to fix this, I'd be happy to contribute. Thanks!", "Hi @jvishnuvardhan and @saikumarchalla, could you please help ping someone from Google and give me some actionable instruction on fixing this? Thank you!", "Hi @bxshi. The model must implement the interface specified [here](https://www.tensorflow.org/hub/reusable_saved_models#interface_definition). See [this gist](https://colab.research.google.com/gist/RichK0/7d39eaf2e3dfba50128067f73f0851d0/reproduce-integerlookup-issue.ipynb#scrollTo=2QSLT69MZ-Zb) for an example fix. [Here](https://www.tensorflow.org/guide/saved_model) is some documentation to learn more about Saved Models in TensorFlow.", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50433\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50433\">No</a>\n"]}, {"number": 50432, "title": "Update prefetching_ops.py", "body": "Added an example of using `prefetch_to_device`\r\n\r\nFixes https://github.com/tensorflow/tensorflow/issues/29848", "comments": []}, {"number": 50431, "title": "[ROCm] Updating Dockerfile.rocm to drop support for gfx803", "body": "/cc @cheshire @chsigg ", "comments": []}, {"number": 50430, "title": "[ROCm] Fix for a bug in GpuLaunchConfig calculation for kernels with explicitly specified non-std launch bounds", "body": "Fix for SWDEV 277899 - hipLaunchKernel called with threads per block  value greater than launch bounds attribute.\r\n\r\nPrior to the fix for SWDEV 252801, if the application code launches a GPU kernel with a threads per block value which is greater than the `__launch_bounds__` attribute value for that kernel, HIP runtime only issues a warning for this scenario.\r\n\r\nAfter the fix for SWDEV 252801, HIP runtime issues an error message instead (for this scenario), and reports an error status back to the application code.\r\n\r\nThis change results in the following four TF unit test failures\r\n\r\n```\r\n//tensorflow/compiler/tests:depthwise_conv_op_test_gpu\r\n//tensorflow/compiler/tests:depthwise_conv_op_test_gpu_mlir_bridge_test\r\n//tensorflow/python:nn_grad_test_gpu\r\n//tensorflow/python/keras/distribute:saved_model_mixed_api_test_gpu\r\n//tensorflow/python/kernel_tests/signal:fft_ops_test\r\n```\r\n\r\nThis commit fixes the failure in the first three of the above tests. It was caused by an incorrect calculation of the \"threads per block\" value. The upper bound for that value (i.e. the `__launch_bounds__` attribute value) was not getting passed to the `GetGpuLaunchConfig`. Passing that value, results in `GetGpuLaunchConfig` returning the correct \"threads per block\" value and the unit tests start passing\r\n\r\n---------------------------------\r\n\r\n/cc @cheshire @chsigg ", "comments": []}, {"number": 50429, "title": "Add Spresense instructions in README.md files on each examples of lite micro.", "body": "@tensorflow/micro\r\n\r\n**System information**\r\n- Target platform : Sony Spresense\r\n\r\n**Describe the problem**\r\nThere is no instructions for Sony Spresense board in README.md files of each examples in lite micro.\r\n\r\n**Please provide the exact sequence of commands/steps when you ran into the problem**\r\nNothing. Just README.md file.\r\n", "comments": ["@takayoshi-k \r\n\r\nThank you for reporting this issue.It will be closed once the PR is merged.\r\n\r\nThanks\r\n\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 50428, "title": "Add instructions for Spresense  on each examples", "body": "Add Spresense instruction in README.mds of hello_world, micro_speach and person_detection in lite/micro/examples.\r\nPlease review it. ", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n", "I have added issue as #50429"]}, {"number": 50427, "title": "Assign unique path to go package", "body": "PR assigns a unique go_package path for full_types.proto; paths for those in core/framework are unique since 4221d1a ", "comments": []}, {"number": 50426, "title": "Training with tf.data API gives different results than passing in data directly using Numpy", "body": "\r\n**System information**\r\n- OS Platform and Distribution : **Linux Ubuntu 18.04**\r\n- TensorFlow installed from  : **source**\r\n- TensorFlow version : **2.5.0**  \r\n- Python version: **3.7.10**\r\n- CUDA/cuDNN version: **CUDA 11.0/cuDNN 8**\r\n- GPU model and memory: **Tesla T4 15GB**\r\n\r\n**Describe the current behavior**\r\nHello,\r\nI have a big difference in the results when I train with the tf.data API compared to when I pass the data directly using Numpy.\r\nIndeed, after 5 epochs, training with tf.data gives the following results \r\n`Epoch 5/5\r\n690/690 [==============================] - 28s 41ms/step - loss: 1.0746 - accuracy: 0.4408 - val_loss: 1.1136 - val_accuracy: 0.3683`\r\ncompared to these results when I train with Numpy:\r\n`Epoch 5/5\r\n690/690 [==============================] - 28s 41ms/step - loss: 0.3204 - accuracy: 0.8693 - val_loss: 5.4233 - val_accuracy: 0.3453`\r\n\r\n\r\n**Describe the expected behavior**\r\nThe expected behavior is to have no difference between tf.data API and Numpy data.\r\n\r\n\r\n**Standalone code to reproduce the issue**\r\nHere is a link to Google Colab to reproduce the issue: [Google Colab](https://colab.research.google.com/drive/1Ffq2qB7A5jg_ATBUN1qad-3QMDLD2a2p?usp=sharing)\r\n\r\nIf you can't run Google Colab, here is the code:  [Code to reproduce ](https://gist.github.com/oubathAI/4e20d7b1d7b17b5b4a30a31c3cc8983a)\r\n\r\nTo download the data, here are the links: \r\n\r\n[train_inputs](https://ec2-spotter.s3.eu-west-1.amazonaws.com/tmp/train_inputs.npy.pkl )\r\n[train_labels](https://ec2-spotter.s3.eu-west-1.amazonaws.com/tmp/train_labels.npy.pkl )\r\n[val_inputs](https://ec2-spotter.s3.eu-west-1.amazonaws.com/tmp/val_inputs.npy.pkl )\r\n[val_labels](https://ec2-spotter.s3.eu-west-1.amazonaws.com/tmp/val_labels.npy.pkl)\r\n\r\n**Other info / logs** \r\nFull training logs using tf.data \r\n```\r\nEpoch 1/5\r\n690/690 [==============================] - 64s 43ms/step - loss: 1.3643 - accuracy: 0.3942 - val_loss: 1.0925 - val_accuracy: 0.4102\r\nEpoch 2/5\r\n690/690 [==============================] - 28s 40ms/step - loss: 1.0938 - accuracy: 0.3999 - val_loss: 1.1260 - val_accuracy: 0.4157\r\nEpoch 3/5\r\n690/690 [==============================] - 28s 41ms/step - loss: 1.0866 - accuracy: 0.4276 - val_loss: 1.0832 - val_accuracy: 0.4199\r\nEpoch 4/5\r\n690/690 [==============================] - 28s 40ms/step - loss: 1.0871 - accuracy: 0.4186 - val_loss: 1.0825 - val_accuracy: 0.4062\r\nEpoch 5/5\r\n690/690 [==============================] - 28s 41ms/step - loss: 1.0746 - accuracy: 0.4408 - val_loss: 1.1136 - val_accuracy: 0.3683\r\n```\r\n\r\nFull training logs using Numpy array\r\n```\r\nEpoch 1/5\r\n690/690 [==============================] - 33s 44ms/step - loss: 1.1418 - accuracy: 0.5239 - val_loss: 1.3560 - val_accuracy: 0.3668\r\nEpoch 2/5\r\n690/690 [==============================] - 28s 41ms/step - loss: 0.6565 - accuracy: 0.7227 - val_loss: 2.4518 - val_accuracy: 0.3578\r\nEpoch 3/5\r\n690/690 [==============================] - 28s 41ms/step - loss: 0.4320 - accuracy: 0.8248 - val_loss: 4.3772 - val_accuracy: 0.3306\r\nEpoch 4/5\r\n690/690 [==============================] - 28s 41ms/step - loss: 0.3603 - accuracy: 0.8544 - val_loss: 4.9844 - val_accuracy: 0.3387\r\nEpoch 5/5\r\n690/690 [==============================] - 28s 41ms/step - loss: 0.3204 - accuracy: 0.8693 - val_loss: 5.4233 - val_accuracy: 0.3453\r\n```\r\n", "comments": ["Please check https://keras.io/getting_started/faq/#how-can-i-obtain-reproducible-results-using-keras-during-development\r\n\r\nAlso try to print the first element from the dataset and from the numpy array to check that they are exactly the same input in the same order.", "@bhack \r\nThanks for your reply.\r\nI tried with `PYTHONHASHSEED=0`  but it didn't change anything.\r\n\r\nI build the dataset directly with numpy array `tf.data.Dataset.from_tensor_slices((train_inputs, train_labels))`  ; so the elements are exactly the same when I'm not shuffling the dataset. ", "Have you also set all the seeds as suggested in the FAQ?\r\n\r\n`when I'm not shuffling the dataset.`\r\n\r\nI think that you need to use the same shuffle method with fixed seeds to exactly reproduce the same batch sequence or to exclude the shuffle if the methods are not exactly the same.", "While I agree that randomness have an impact on the results, what I can't figure out is that every time this randomness gives results where Numpy's way overfit and the tf data API have trouble learning.\r\nHave you looked at the Google Colab? You can run it as many times as you want, and every time the difference between the two ways of training will be the same: The training with Numpy will overfit with the val_loss incrementing, and the loss with TF Dataset will have a hard time decreasing, stuck around 1\r\nI doubt that setting the randomseed will change this behavior, and that's what I'm pointing out in my issue: Why TF Data is not learning while Numpy overfit  everytime I'm trying to train. \r\n\r\n", "@sachinprasadhs ,\r\nI was able to reproduce the issue in [v2.4](https://colab.research.google.com/gist/tilakrayal/7ab6b903d4e3c788d000d8984640026c/2-4tfdataset_issue.ipynb),[v2.5](https://colab.research.google.com/gist/tilakrayal/8fb3afb71b18871898b67cc43dac6358/2-5tfdataset_issue.ipynb) and nightly.Please find the gist.", "You need to change the order of  shuffle, batch, cache in your `tf.data` pipeline. \r\nYou should use `cache()` before `shuffle()` ,`batch()` and `prefetch()`, so that your data will be loaded only once instead of each epoch, but data will be shuffled differently during each epoch. \r\nYou should use `shuffle` before `batch`.\r\nI have changed the order and I'm able to see the increase in the accuracy, see the gist [here](https://colab.research.google.com/gist/sachinprasadhs/f5378198aa131a46efab7a960f91d74b/2-5tfdataset_issue.ipynb).\r\n\r\nBut your model is overfitting, training loss is getting decreased but validation loss is increasing. \r\nYou can rectify using below methods.\r\n\r\n- Increase number of samples.\r\n- Shuffle data before splitting into train and validation set.\r\n- Try changing the model layers and other hyper-parameters.\r\n- Use regularization techniques.\r\n- Try reducing batch size.", "Thanks for your reply. I thought I needed to cache at the very last steps of dataset to improve performance.\r\nThanks for your insighs about the overfitting, I'm trying to mitigate it right now.\r\nHave a nice day!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50426\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50426\">No</a>\n"]}, {"number": 50425, "title": "Cannot Compile tensorflow 1.14.0", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOs 11.2.3\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 1.14.0\r\n- Python version: 3.7\r\n- Installed using virtualenv? pip? conda?: pip\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nOne script I need to use has the line `from tensorflow.examples.tutorials.mnist import input_data`. Since the tutorials folder is removed from tensorflow2, I activated another environment to use Python 3.7 and installed tensorflow 1.14.0 using `pip3 install https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-1.14.0-py3-none-any.whl\r\n` found from [https://stackoverflow.com/questions/63059979/cannot-install-tensorflow-1-x](https://stackoverflow.com/questions/63059979/cannot-install-tensorflow-1-x).\r\n\r\nHowever, when running the script, I have an error saying `ModuleNotFoundError: No module named 'keras_applications', but I do have installed keras.\r\n\r\nI found a related issue here [https://github.com/tensorflow/tensorflow/issues/21518](https://github.com/tensorflow/tensorflow/issues/21518) which was posted quite a while ago. Based on this pose, I ran successfully\r\n```\r\npip install keras_applications==1.0.4 --no-deps\r\npip install keras_preprocessing==1.0.2 --no-deps\r\npip install h5py==2.8.0\r\n```\r\nbut encountered another error saying `ImportError: Keras requires TensorFlow 2.2 or higher. Install TensorFlow via `pip install tensorflow`` Below is my traceback.\r\n\r\n**Any other info / logs**\r\nTraceback (most recent call last):\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/__init__.py\", line 3, in <module>\r\n    from tensorflow.keras.layers.experimental.preprocessing import RandomRotation\r\n  File \"/Applications/PyCharm CE.app/Contents/plugins/python-ce/helpers/pydev/_pydev_bundle/pydev_import_hook.py\", line 21, in do_import\r\n    module = self._system_import(name, *args, **kwargs)\r\nModuleNotFoundError: No module named 'tensorflow.keras.layers.experimental.preprocessing'\r\nDuring handling of the above exception, another exception occurred:\r\nTraceback (most recent call last):\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2869, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-2-c54fbe678627>\", line 1, in <module>\r\n    runfile('/Users/zhli12/Desktop/scGAIN/example.py', wdir='/Users/zhli12/Desktop/scGAIN')\r\n  File \"/Applications/PyCharm CE.app/Contents/plugins/python-ce/helpers/pydev/_pydev_bundle/pydev_umd.py\", line 197, in runfile\r\n    pydev_imports.execfile(filename, global_vars, local_vars)  # execute the script\r\n  File \"/Applications/PyCharm CE.app/Contents/plugins/python-ce/helpers/pydev/_pydev_imps/_pydev_execfile.py\", line 18, in execfile\r\n    exec(compile(contents+\"\\n\", file, 'exec'), glob, loc)\r\n  File \"/Users/zh12/Desktop/scGAIN/example.py\", line 25, in <module>\r\n    from keras import applications\r\n  File \"/Applications/PyCharm CE.app/Contents/plugins/python-ce/helpers/pydev/_pydev_bundle/pydev_import_hook.py\", line 21, in do_import\r\n    module = self._system_import(name, *args, **kwargs)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/__init__.py\", line 6, in <module>\r\n    'Keras requires TensorFlow 2.2 or higher. '\r\nImportError: Keras requires TensorFlow 2.2 or higher. Install TensorFlow via `pip install tensorflow`\r\n", "comments": ["TF 1.x is end of life, please install a recent TF 2.x release. \r\nFor the MINST dataset you can use https://keras.io/api/datasets/mnist/", "> TF 1.x is end of life, please install a recent TF 2.x release.\r\n> For the MINST dataset you can use https://keras.io/api/datasets/mnist/\r\n\r\nThanks! Should I replace `from tensorflow.examples.tutorials.mnist import input_data` with `tf.keras.datasets.mnist.load_data(path=\"mnist.npz\")` then?", "You could use it like this https://github.com/tensorflow/tensorflow/issues/32790#issuecomment-594816297\r\n\r\nOr \r\n\r\nhttps://www.tensorflow.org/datasets/keras_example", "@zhli12  Also Please check this Tensorflow [tutorial](https://www.tensorflow.org/tutorials/quickstart/beginner) for  more information. Thanks!", "@zhli12 Please let us know if you are facing any issues still else go ahead and close the issue.Thanks!", "Thanks! I'll switch to tensorflow 2.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50425\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50425\">No</a>\n"]}, {"number": 50422, "title": "Tensorflow type 21 not convertible to numpy dtype.", "body": "A minimal example to reproduce the exception:\r\n\r\ntf-version: 2.5.0\r\nCPU\r\npython 3.9\r\n\r\n```\r\nimport tensorflow.compat.v1 as tf\r\n\r\ntf.disable_v2_behavior()\r\n\r\nss = tf.constant([[1, 2, 3, 4, 5], [0, 0, 0, 2, 1]], dtype=tf.float32)\r\nindecies = tf.where(tf.not_equal(ss, 0))\r\n\r\nb = tf.compat.v1.raw_ops.DenseToCSRSparseMatrix(dense_input=ss, indices=indecies)\r\n\r\nwith tf.Session() as sess:\r\n    sess.run(tf.global_variables_initializer())\r\n    print(sess.run(b))\r\n```\r\n\r\nAnother way to reproduce the error:\r\n\r\n```\r\nimport tensorflow.compat.v1 as tf\r\n\r\nfrom tensorflow.python.ops.linalg.sparse import sparse_csr_matrix_ops\r\n\r\ntf.compat.v1.disable_eager_execution()\r\n\r\nss = tf.constant([[1, 2, 3, 4, 5], [0, 0, 0, 2, 1]], dtype=tf.float32)\r\na_st = tf.sparse.from_dense(ss)\r\ntmp = sparse_csr_matrix_ops.sparse_tensor_to_csr_sparse_matrix(a_st.indices, a_st.values, a_st.dense_shape)\r\n\r\n\r\nwith tf.Session() as sess:\r\n    sess.run(tf.global_variables_initializer())\r\n    print(sess.run(tmp))\r\n\r\n```", "comments": ["@hadifar ,\r\n\r\nPlease take a look this [comment](https://github.com/tensorflow/tensorflow/issues/34683#issuecomment-572791147) from a similar issues and let us know if it helps. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50422\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50422\">No</a>\n"]}]