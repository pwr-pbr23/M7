[{"number": 54398, "title": "Please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`.", "body": "can't set run_eagerly,but running is wrong:\r\n`model.compile(\r\n        loss=CRFLoss(model.crf, model.dtype),\r\n        optimizer=tf.keras.optimizers.Adam(params[\"lr\"]),\r\n        metrics=[model.crf.viterbi_accuracy, IOBESF1(id2tag)],\r\n        run_eagerly = None)\r\n    model.build((None, train_text.shape[-1]))\r\n    model.summary()\r\n\r\n    callbacks = [\r\n        tf.keras.callbacks.ModelCheckpoint(\r\n            filepath=config[\"ckpt_path\"],\r\n            save_weights_only=True,\r\n            save_best_only=True,\r\n            monitor=\"val_f1\",\r\n            mode=\"max\"),\r\n    ]\r\n    model.fit(\r\n        train_dataset,\r\n        epochs=params[\"epochs\"],\r\n        callbacks=callbacks,\r\n        validation_data=dev_dataset)`\r\n\r\n", "comments": ["@daan0701 ,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code, dataset  and the tensorflow version you are using to reproduce the issue reported here.", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54398\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54398\">No</a>\n"]}, {"number": 54395, "title": "Use assertEqual instead of asserTrue", "body": "Fixes https://github.com/tensorflow/tensorflow/issues/54392", "comments": []}, {"number": 54394, "title": "abseil: wyhash is now called low_level_hash", "body": "With https://github.com/tensorflow/tensorflow/commit/e45ca6adf2458d4759e5c40f1f27bbf9505a3c79 we have upgraded to the latest abseil LTS version. This did break the build with system abseil as the `wyhash` library was renamed to `low_level_hash`.", "comments": []}, {"number": 54393, "title": "WARNING: 404 Not Found", "body": "Extracting Bazel installation...\r\nStarting local Bazel server and connecting to it...\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=0 --terminal_columns=80\r\nINFO: Reading rc options for 'build' from d:\\vcpkg\\buildtrees\\tensorflow-cc\\x64-windows-dbg\\.bazelrc:\r\n  Inherited 'common' options: --experimental_repo_remote_exec\r\nINFO: Options provided by the client:\r\n  'build' options: --python_path=D:/vcpkg/downloads/tools/msys2/16665682389be3a4/mingw64/bin/python.exe\r\nINFO: Reading rc options for 'build' from d:\\vcpkg\\buildtrees\\tensorflow-cc\\x64-windows-dbg\\.bazelrc:\r\n  'build' options: --define framework_shared_object=true --java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --host_java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2 --define=no_aws_support=true --define=no_hdfs_support=true\r\nINFO: Reading rc options for 'build' from d:\\vcpkg\\buildtrees\\tensorflow-cc\\x64-windows-dbg\\.tf_configure.bazelrc:\r\n  'build' options: --action_env PYTHON_BIN_PATH=D:/vcpkg/downloads/tools/msys2/16665682389be3a4/mingw64/bin/python3.exe --action_env PYTHON_LIB_PATH=D:/vcpkg/downloads/tools/msys2/16665682389be3a4/mingw64/lib/python3.8/site-packages --python_path=D:/vcpkg/downloads/tools/msys2/16665682389be3a4/mingw64/bin/python3.exe --define=with_xla_support=false --copt=/d2ReducedOptimizeHugeFunctions --host_copt=/d2ReducedOptimizeHugeFunctions --define=override_eigen_strong_inline=true\r\nINFO: Reading rc options for 'build' from d:\\vcpkg\\buildtrees\\tensorflow-cc\\x64-windows-dbg\\.bazelrc:\r\n  'build' options: --deleted_packages=tensorflow/compiler/mlir/tfrt,tensorflow/compiler/mlir/tfrt/benchmarks,tensorflow/compiler/mlir/tfrt/jit/python_binding,tensorflow/compiler/mlir/tfrt/jit/transforms,tensorflow/compiler/mlir/tfrt/python_tests,tensorflow/compiler/mlir/tfrt/tests,tensorflow/compiler/mlir/tfrt/tests/saved_model,tensorflow/compiler/mlir/tfrt/transforms/lhlo_gpu_to_tfrt_gpu,tensorflow/core/runtime_fallback,tensorflow/core/runtime_fallback/conversion,tensorflow/core/runtime_fallback/kernel,tensorflow/core/runtime_fallback/opdefs,tensorflow/core/runtime_fallback/runtime,tensorflow/core/runtime_fallback/util,tensorflow/core/tfrt/common,tensorflow/core/tfrt/eager,tensorflow/core/tfrt/eager/backends/cpu,tensorflow/core/tfrt/eager/backends/gpu,tensorflow/core/tfrt/eager/core_runtime,tensorflow/core/tfrt/eager/cpp_tests/core_runtime,tensorflow/core/tfrt/fallback,tensorflow/core/tfrt/gpu,tensorflow/core/tfrt/run_handler_thread_pool,tensorflow/core/tfrt/runtime,tensorflow/core/tfrt/saved_model,tensorflow/core/tfrt/saved_model/tests,tensorflow/core/tfrt/tpu,tensorflow/core/tfrt/utils\r\nINFO: Found applicable config definition build:short_logs in file d:\\vcpkg\\buildtrees\\tensorflow-cc\\x64-windows-dbg\\.bazelrc: --output_filter=DONT_MATCH_ANYTHING\r\nINFO: Found applicable config definition build:v2 in file d:\\vcpkg\\buildtrees\\tensorflow-cc\\x64-windows-dbg\\.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1\r\nINFO: Found applicable config definition build:windows in file d:\\vcpkg\\buildtrees\\tensorflow-cc\\x64-windows-dbg\\.bazelrc: --copt=/W0 --copt=/D_USE_MATH_DEFINES --host_copt=/D_USE_MATH_DEFINES --cxxopt=/std:c++14 --host_cxxopt=/std:c++14 --config=monolithic --copt=-DWIN32_LEAN_AND_MEAN --host_copt=-DWIN32_LEAN_AND_MEAN --copt=-DNOGDI --host_copt=-DNOGDI --copt=/experimental:preprocessor --host_copt=/experimental:preprocessor --linkopt=/DEBUG --host_linkopt=/DEBUG --linkopt=/OPT:REF --host_linkopt=/OPT:REF --linkopt=/OPT:ICF --host_linkopt=/OPT:ICF --verbose_failures --features=compiler_param_file --distinct_host_configuration=false\r\nINFO: Found applicable config definition build:monolithic in file d:\\vcpkg\\buildtrees\\tensorflow-cc\\x64-windows-dbg\\.bazelrc: --define framework_shared_object=false\r\nLoading: \r\nLoading: 0 packages loaded\r\nLoading: 0 packages loaded\r\nLoading: 0 packages loaded\r\nLoading: 0 packages loaded\r\nLoading: 0 packages loaded\r\nLoading: 0 packages loaded\r\nWARNING: Download from http://mirror.tensorflow.org/github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found\r\nLoading: 0 packages loaded\r\nLoading: 0 packages loaded\r\nLoading: 0 packages loaded\r\nLoading: 0 packages loaded\r\nLoading: 0 packages loaded\r\nLoading: 0 packages loaded\r\nLoading: 0 packages loaded\r\nLoading: 0 packages loaded\r\nLoading: 0 packages loaded\r\nLoading: 0 packages loaded\r\nLoading: 0 packages loaded\r\nLoading: 0 packages loaded\r\nLoading: 0 packages loaded\r\nLoading: 0 packages loaded\r\nWARNING: Download from https://storage.googleapis.com/mirror.tensorflow.org/github.com/llvm/llvm-project/archive/43d6991c2a4cc2ac374e68c029634f2b59ffdfdf.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found\r\nLoading: 0 packages loaded\r\nAnalyzing: 2 targets (1 packages loaded, 0 targets configured)\r\nDEBUG: Rule 'io_bazel_rules_docker' indicated that a canonical reproducible form can be obtained by modifying arguments shallow_since = \"1596824487 -0400\"\r\nDEBUG: Repository io_bazel_rules_docker instantiated at:\r\n  D:/vcpkg/buildtrees/tensorflow-cc/x64-windows-dbg/WORKSPACE:23:14: in <toplevel>\r\n  D:/vcpkg/buildtrees/tensorflow-cc/x64-windows-dbg/tensorflow/workspace0.bzl:108:34: in workspace\r\n  D:/vcpkg/buildtrees/tensorflow-cc/.bzl/hwfhzki5/external/bazel_toolchains/repositories/repositories.bzl:35:23: in repositories\r\nRepository rule git_repository defined at:\r\n  D:/vcpkg/buildtrees/tensorflow-cc/.bzl/hwfhzki5/external/bazel_tools/tools/build_defs/repo/git.bzl:199:33: in <toplevel>\r\nINFO: Repository local_config_cc instantiated at:\r\n  D:/vcpkg/buildtrees/tensorflow-cc/x64-windows-dbg/WORKSPACE:23:14: in <toplevel>\r\n  D:/vcpkg/buildtrees/tensorflow-cc/x64-windows-dbg/tensorflow/workspace0.bzl:106:24: in workspace\r\n  D:/vcpkg/buildtrees/tensorflow-cc/.bzl/hwfhzki5/external/rules_cc/cc/repositories.bzl:28:17: in rules_cc_toolchains\r\n  D:/vcpkg/buildtrees/tensorflow-cc/.bzl/hwfhzki5/external/rules_cc/cc/private/toolchain/cc_configure.bzl:180:16: in cc_configure\r\nRepository rule cc_autoconf defined at:\r\n  D:/vcpkg/buildtrees/tensorflow-cc/.bzl/hwfhzki5/external/rules_cc/cc/private/toolchain/cc_configure.bzl:143:30: in <toplevel>\r\nERROR: An error occurred during the fetch of repository 'local_config_cc':\r\n   Traceback (most recent call last):\r\n\tFile \"D:/vcpkg/buildtrees/tensorflow-cc/.bzl/hwfhzki5/external/rules_cc/cc/private/toolchain/cc_configure.bzl\", line 120, column 36, in cc_autoconf_impl\r\n\t\tconfigure_windows_toolchain(repository_ctx)\r\n\tFile \"D:/vcpkg/buildtrees/tensorflow-cc/.bzl/hwfhzki5/external/rules_cc/cc/private/toolchain/windows_cc_configure.bzl\", line 694, column 31, in configure_windows_toolchain\r\n\t\tmsvc_vars = _get_msvc_vars(repository_ctx, paths)\r\n\tFile \"D:/vcpkg/buildtrees/tensorflow-cc/.bzl/hwfhzki5/external/rules_cc/cc/private/toolchain/windows_cc_configure.bzl\", line 535, column 28, in _get_msvc_vars\r\n\t\tenv = setup_vc_env_vars(repository_ctx, vc_path)\r\n\tFile \"D:/vcpkg/buildtrees/tensorflow-cc/.bzl/hwfhzki5/external/rules_cc/cc/private/toolchain/windows_cc_configure.bzl\", line 318, column 24, in setup_vc_env_vars\r\n\t\t_check_env_vars(env_map, cmd, expected = envvars)\r\n\tFile \"D:/vcpkg/buildtrees/tensorflow-cc/.bzl/hwfhzki5/external/rules_cc/cc/private/toolchain/windows_cc_configure.bzl\", line 324, column 32, in _check_env_vars\r\n\t\tauto_configure_fail(\r\n\tFile \"D:/vcpkg/buildtrees/tensorflow-cc/.bzl/hwfhzki5/external/rules_cc/cc/private/toolchain/lib_cc_configure.bzl\", line 112, column 9, in auto_configure_fail\r\n\t\tfail(\"\\n%sAuto-Configuration Error:%s %s\\n\" % (red, no_color, msg))\r\nError in fail: \r\nAuto-Configuration Error: Setting up VC environment variables failed, WINDOWSSDKDIR is not set by the following command:\r\n    \"C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Auxiliary\\Build\\VCVARSALL.BAT\" amd64  -vcvars_ver=14.29.30133\r\nERROR: Error fetching repository: Traceback (most recent call last):\r\n\tFile \"D:/vcpkg/buildtrees/tensorflow-cc/.bzl/hwfhzki5/external/rules_cc/cc/private/toolchain/cc_configure.bzl\", line 120, column 36, in cc_autoconf_impl\r\n\t\tconfigure_windows_toolchain(repository_ctx)\r\n\tFile \"D:/vcpkg/buildtrees/tensorflow-cc/.bzl/hwfhzki5/external/rules_cc/cc/private/toolchain/windows_cc_configure.bzl\", line 694, column 31, in configure_windows_toolchain\r\n\t\tmsvc_vars = _get_msvc_vars(repository_ctx, paths)\r\n\tFile \"D:/vcpkg/buildtrees/tensorflow-cc/.bzl/hwfhzki5/external/rules_cc/cc/private/toolchain/windows_cc_configure.bzl\", line 535, column 28, in _get_msvc_vars\r\n\t\tenv = setup_vc_env_vars(repository_ctx, vc_path)\r\n\tFile \"D:/vcpkg/buildtrees/tensorflow-cc/.bzl/hwfhzki5/external/rules_cc/cc/private/toolchain/windows_cc_configure.bzl\", line 318, column 24, in setup_vc_env_vars\r\n\t\t_check_env_vars(env_map, cmd, expected = envvars)\r\n\tFile \"D:/vcpkg/buildtrees/tensorflow-cc/.bzl/hwfhzki5/external/rules_cc/cc/private/toolchain/windows_cc_configure.bzl\", line 324, column 32, in _check_env_vars\r\n\t\tauto_configure_fail(\r\n\tFile \"D:/vcpkg/buildtrees/tensorflow-cc/.bzl/hwfhzki5/external/rules_cc/cc/private/toolchain/lib_cc_configure.bzl\", line 112, column 9, in auto_configure_fail\r\n\t\tfail(\"\\n%sAuto-Configuration Error:%s %s\\n\" % (red, no_color, msg))\r\nError in fail: \r\nAuto-Configuration Error: Setting up VC environment variables failed, WINDOWSSDKDIR is not set by the following command:\r\n    \"C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Auxiliary\\Build\\VCVARSALL.BAT\" amd64  -vcvars_ver=14.29.30133\r\nINFO: Repository rules_proto instantiated at:\r\n  D:/vcpkg/buildtrees/tensorflow-cc/x64-windows-dbg/WORKSPACE:23:14: in <toplevel>\r\n  D:/vcpkg/buildtrees/tensorflow-cc/x64-windows-dbg/tensorflow/workspace0.bzl:120:20: in workspace\r\n  D:/vcpkg/buildtrees/tensorflow-cc/.bzl/hwfhzki5/external/com_github_grpc_grpc/bazel/grpc_extra_deps.bzl:29:18: in grpc_extra_deps\r\n  D:/vcpkg/buildtrees/tensorflow-cc/.bzl/hwfhzki5/external/com_google_protobuf/protobuf_deps.bzl:42:21: in protobuf_deps\r\nRepository rule http_archive defined at:\r\n  D:/vcpkg/buildtrees/tensorflow-cc/.bzl/hwfhzki5/external/bazel_tools/tools/build_defs/repo/http.bzl:336:31: in <toplevel>\r\nERROR: D:/vcpkg/buildtrees/tensorflow-cc/x64-windows-dbg/tensorflow/cc/BUILD:125:11: //tensorflow/cc:gradient_checker depends on @local_config_cc//:cc-compiler-x64_windows in repository @local_config_cc which failed to fetch. no such package '@local_config_cc//': \r\nAuto-Configuration Error: Setting up VC environment variables failed, WINDOWSSDKDIR is not set by the following command:\r\n    \"C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Auxiliary\\Build\\VCVARSALL.BAT\" amd64  -vcvars_ver=14.29.30133\r\nERROR: Analysis of target '//tensorflow:install_headers' failed; build aborted: Analysis failed\r\nINFO: Elapsed time: 120.017s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (60 packages loaded, 167 targets configured)\r\nFAILED: Build did NOT complete successfully (60 packages loaded, 167 targets configured)\r\n", "comments": ["@yIllusionSky ,\r\nCan you please take a look at this [issue](https://github.com/tensorflow/tensorflow/issues/43979) with the similar error.It helps.\r\nIn order to expedite the trouble-shooting process, could you please provide the following information\r\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\nTensorFlow installed from (source or binary):\r\nTensorFlow version:\r\nPython version:\r\nInstalled using virtualenv? pip? conda?:\r\nBazel version (if compiling from source):\r\nGCC/Compiler version (if compiling from source):\r\nCUDA/cuDNN version:\r\nGPU model and memory:\r\n", "> @yIllusionSky \uff0c \u4f60\u80fd\u7528\u7c7b\u4f3c\u7684\u9519\u8bef\u770b\u770b\u8fd9\u4e2a [\u95ee\u9898 ](https://github.com/tensorflow/tensorflow/issues/43979)\u6709\u5e2e\u52a9\u3002 \u4e3a\u4e86\u52a0\u5feb\u6545\u969c\u6392\u9664\u8fc7\u7a0b\uff0c\u60a8\u80fd\u5426\u63d0\u4f9b\u4ee5\u4e0b\u4fe1\u606f \u64cd\u4f5c\u7cfb\u7edf\u5e73\u53f0\u548c\u53d1\u884c\u7248\uff08\u4f8b\u5982\uff0cLinux Ubuntu 16.04\uff09\uff1a \u79fb\u52a8\u8bbe\u5907\uff08\u4f8b\u5982 iPhone 8\u3001Pixel 2\u3001Samsung Galaxy\uff09\u5982\u679c\u95ee\u9898\u53d1\u751f\u5728\u79fb\u52a8\u8bbe\u5907\u4e0a\uff1a TensorFlow \u5b89\u88c5\u81ea\uff08\u6e90\u4ee3\u7801\u6216\u4e8c\u8fdb\u5236\u6587\u4ef6\uff09\uff1a TensorFlow \u7248\u672c\uff1a \u87d2\u86c7\u7248\u672c\uff1a \u4f7f\u7528 virtualenv \u5b89\u88c5\uff1f \u70b9\u5b50\uff1f \u5eb7\u8fbe\uff1f\uff1a Bazel \u7248\u672c\uff08\u5982\u679c\u4ece\u6e90\u4ee3\u7801\u7f16\u8bd1\uff09\uff1a GCC/\u7f16\u8bd1\u5668\u7248\u672c\uff08\u5982\u679c\u4ece\u6e90\u4ee3\u7801\u7f16\u8bd1\uff09\uff1a CUDA / cuDNN \u7248\u672c\uff1a GPU\u578b\u53f7\u548c\u5185\u5b58\uff1a\r\n\r\nIt seems to have been installed successfully again. Thank you. It's all right", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54393\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54393\">No</a>\n"]}, {"number": 54392, "title": "Some tests misusing assertTrue for comparisons", "body": "`assertTrue` is not for comparing arguments, should use `assertEqual` for that.\n\nThe developer's intent of the test was to compare argument 1 with argument 2, which is not happening. Really what is happening is the test is passing because first argument is truthy. The correct method to use is assertEqual. [more details](https://codereview.doctor/features/python/best-practice/avoid-misusing-unittest-assert-true)\n\nhttps://github.com/tensorflow/tensorflow/blob/d9e5d3c634c2ab1221e7d30b562c48b0b0e110b7/tensorflow/python/autograph/pyct/cfg_test.py#L85\nhttps://github.com/tensorflow/tensorflow/blob/d9e5d3c634c2ab1221e7d30b562c48b0b0e110b7/tensorflow/python/distribute/distributed_variable_test.py#L383\nhttps://github.com/tensorflow/tensorflow/blob/d9e5d3c634c2ab1221e7d30b562c48b0b0e110b7/tensorflow/python/eager/def_function_xla_jit_test.py#L1182\nhttps://github.com/tensorflow/tensorflow/blob/d9e5d3c634c2ab1221e7d30b562c48b0b0e110b7/tensorflow/python/keras/mixed_precision/loss_scale_optimizer_test.py#L1007\nhttps://github.com/tensorflow/tensorflow/blob/d9e5d3c634c2ab1221e7d30b562c48b0b0e110b7/tensorflow/python/ops/parallel_for/control_flow_ops_test.py#L2549\n\nI found this issue automatically, see other issues [here](https://codereview.doctor/tensorflow/tensorflow)", "comments": ["we've also raised a PR for the keras one [upstream](https://github.com/keras-team/keras/issues/16072)", "Thank you created a PR https://github.com/tensorflow/tensorflow/pull/54395 for the same.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54392\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54392\">No</a>\n"]}, {"number": 54389, "title": "BlazePose model support in iOS sample", "body": "Hi Team, I was checking https://github.com/tensorflow/examples/tree/master/lite/examples/pose_estimation/ios example it supports\r\nPosenet, Movenet Lightning, Movenet Thunder models. I just wanted to know, Is it possible to add googles BlazePose model  support ? If yes how can I do that ?\r\n\r\nThank you", "comments": ["@pratimash ,\r\nPlease take a look at this link [1](https://ai.googleblog.com/2020/08/on-device-real-time-body-pose-tracking.html) [2](https://google.github.io/mediapipe/solutions/pose#personpose-detection-model-blazepose-detector) and [3](https://blog.tensorflow.org/2021/05/high-fidelity-pose-tracking-with-mediapipe-blazepose-and-tfjs.html) which delivers the approach towards BlazePose.It helps.Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 54388, "title": "Building unit tests on non-GPU build is broken", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: git HEAD\r\n- Python version: 3.8.10\r\n- Installed using virtualenv? pip? conda?: No\r\n- Bazel version (if compiling from source): 5.0.0\r\n- GCC/Compiler version (if compiling from source): 10.3.0\r\n- CUDA/cuDNN version: n/a\r\n- GPU model and memory: n/a\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nBuild errors out with\r\n\r\n`ERROR: /home/builder/1/tensorflow_build/tensorflow-git/tensorflow/compiler/xla/service/gpu/BUILD:653:11: Compiling tensorflow/compiler/xla/service/gpu/triangular_solve_thunk.cc failed: undeclared inclusion(s) in rule '//tensorflow/compiler/xla/service/gpu:gpu_executable':\r\nthis rule is missing dependency declarations for the following files included by 'tensorflow/compiler/xla/service/gpu/triangular_solve_thunk.cc':\r\n  'tensorflow/compiler/xla/service/gpu/precompiled_kernels.h'\r\nINFO: Elapsed time: 4632.439s, Critical Path: 957.38s\r\nINFO: 40192 processes: 12988 internal, 27204 local.\r\nFAILED: Build did NOT complete successfully\r\n`\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nbazel test --test_timeout=300,500,-1,-1 --flaky_test_attempts=3 --test_output=all --cache_test_results=no --remote_http_cache=\"\"  --remote_cache_proxy=\"\" --noremote_accept_cached --config=nonccl --build_tag_filters=-no_oss,-oss_serial,-gpu,-tpu,-benchmark-test,-v1only,-no_aarch64,-requires-gpu --test_tag_filters=-no_oss,-oss_serial,-gpu,-tpu,-benchmark-test,-v1only,-no_aarch64,-requires-gpu --verbose_failures -- //tensorflow/... -//tensorflow/python/integration_testing/... -//tensorflow/compiler/tf2tensorrt/... -//tensorflow/compiler/xrt/... -//tensorflow/core/tpu/... -//tensorflow/java/... -//tensorflow/go/... -//tensorflow/lite/... -//tensorflow/python/tools/... -//tensorflow/compiler/mlir/lite/tests:const-fold.mlir.test -//tensorflow/python/data/experimental/kernel_tests/service:fault_tolerance_test -//tensorflow/python/eager:function_test -//tensorflow/python/kernel_tests/linalg:linear_operator_circulant_test -//tensorflow/python/kernel_tests/linalg:self_adjoint_eig_op_test\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nThe commit https://github.com/tensorflow/tensorflow/commit/3e3d3cb87d1f747928d26d832e9bbc231b201c43 is involved but that seems to have been partially addressing another problem, so not sure where the root cause is.\r\n", "comments": ["@cfRod @nSircombe ", "@elfringham \r\nCan you clear the cache before running Bazel build command\r\n\r\nTry to wipe out bazel cache using\r\n`rm -rf ~/.cache/bazel  `\r\nOr\r\n`bazel clean --expunge`.\r\n\r\nPlease let us know if that helps!\r\n", "No, that does not help at all.", "@elfringham,\r\nLooks like its more of Bazel issue. Please check similar issue [#13135](https://github.com/bazelbuild/bazel/issues/13135) ", "@gadagashwini I disagree. Cleaning the cache is no help. That issue does not seem to relate in any way.", "It looks like this was resolved by https://github.com/tensorflow/tensorflow/commit/31acf21fda3d6a443afd58c594ec6b9ba09cf23f", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54388\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54388\">No</a>\n"]}, {"number": 54387, "title": "ImportError: undefined symbol: _ZNK10tensorflow8OpKernel11TraceStringERKNS_15OpKernelContextEb", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Arch Linux\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): Fails, tested with 2.7.1 and 2.8.0\r\n- Python version: Python 3.9.10\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: cuda 11.6.0-1, cudnn 8.3.1.22-1\r\n- GPU model and memory: GTX 1050ti\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\nWhen `import tensorflow` in a Python 3.9.10, failed to load:\r\n\r\n```\r\n>>> import tensorflow\r\nTraceback (most recent call last):\r\n  File \"/home/david/git/project/venv/lib/python3.9/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 64, in <module>\r\n    from tensorflow.python._pywrap_tensorflow_internal import *\r\nImportError: /home/david/git/project/venv/lib/python3.9/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so: undefined symbol: _ZNK10tensorflow8OpKernel11TraceStringERKNS_15OpKernelContextEb\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\n  File \"/home/david/git/project/venv/lib/python3.9/site-packages/tensorflow/__init__.py\", line 41, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"/home/david/git/project/venv/lib/python3.9/site-packages/tensorflow/python/__init__.py\", line 40, in <module>\r\n    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\r\n  File \"/home/david/git/project/venv/lib/python3.9/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 79, in <module>\r\n    raise ImportError(\r\nImportError: Traceback (most recent call last):\r\n  File \"/home/david/git/project/venv/lib/python3.9/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 64, in <module>\r\n    from tensorflow.python._pywrap_tensorflow_internal import *\r\nImportError: /home/david/git/project/venv/lib/python3.9/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so: undefined symbol: _ZNK10tensorflow8OpKernel11TraceStringERKNS_15OpKernelContextEb\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\nSee https://www.tensorflow.org/install/errors for some common causes and solutions.\r\nIf you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message.\r\n```\r\n\r\n**Describe the expected behavior**\r\n\r\n```\r\n>>> import tensorflow\r\n```\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no): no\r\n- Briefly describe your candidate solution(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n```\r\n>>> import tensorflow\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\nWhen importing tensorflow in Python 3.10 it works well", "comments": ["Updating Cudnn, Cuda, etc to last version with `pacman -Syu` solves the problem.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54387\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54387\">No</a>\n"]}, {"number": 54384, "title": "does tensorflow support cuda 11.3?", "body": "\r\nHi,\r\n\r\nI noticed that tensorflow support cuda 11.2 but you do not mention if tensorflow supports cuda 11.3.\r\n\r\nWhen I use cuda 11.3 with tensorflow 2.4, it shows that \r\n`failed call to cuInit: CUDA_ERROR_NOT_INITIALIZED: initialization error\r\nlibcuda reported version is: Not found: was unable to find libcuda.so DSO loaded into this program\r\n`\r\n\r\nFor the details, please refer to[ this issue ](https://github.com/open-mmlab/mmdetection3d/issues/1233#issue-1133840656)", "comments": ["@MinWang1997 Could you please have a look at the [link](https://github.com/tensorflow/docs/blob/master/site/en/install/source.md#gpu) and try with the latest TF version with compatible configurations ?Please let us know if it helps?Thanks!", "Hi @sushreebarsa according the compatibility table, all the tensorflow doesnot support cuda11.3 since the latest supported version is cuda 11.2.\r\n\r\n", "@MinWang1997 anything compiled with cuda=11.2 should work with anything cuda>=11.2, see more here : https://docs.nvidia.com/deploy/cuda-compatibility/#default-to-minor-version. I have recently used tensorflow 2.7 and tensorflow 2.8 with cudatoolkit 11.5 and 11.6 with no problems. Are you seeing any problems?\r\n\r\nyour error above indicates that you're not seeing the cuda libraries at all... what's your LD_LIBRARY_PATH and where di you get this tensorflow from?", "@MinWang1997 The Error is not related to Version compatibility it is more of CUDA path setup.\r\nPlease follow the steps mentioned in [TensorFlow.org](https://www.tensorflow.org/) to set path properly.Please refer to the [comment](https://github.com/tensorflow/tensorflow/issues/54384#issuecomment-1043467342) above as well.Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54384\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54384\">No</a>\n"]}, {"number": 54383, "title": "README.md useless", "body": "This is the most time and nerve-consuming library in the whole dev eco!!! To install it you have to spend hours and hours, just because you assume that all of us have prior knowledge that you have.", "comments": ["@zmajew ,\r\nTensorFlow is an end-to-end open source platform for machine learning. It has a comprehensive, flexible ecosystem of tools, libraries and community resources that lets researchers push the state-of-the-art in ML and developers easily build and deploy ML powered applications.Can you please try to follow and install from this [link](https://www.tensorflow.org/install).Thanks!\r\n\r\n", "No template filled. Rant issues are not productive, they just waste the time of everyone."]}, {"number": 54382, "title": "[ROCm] Fixes to enable the cholesky unit test for BEF thunk on ROCm.", "body": "This captures the TF repo changes needed to enable the cholesky unit test on ROCm.\r\n\r\n/cc @chsigg @hanbinyoon ", "comments": ["Additional changes are required in TFRT but this PR captures all the necessary changes in TF.", "Some of the constants used in this PR are defined in a separate commit as part of: https://github.com/tensorflow/tensorflow/pull/54926", "Hi Rohit, would you mind rebasing the change? Thanks!", "> Hi Rohit, would you mind rebasing the change? Thanks!\r\n\r\nDone.", "I used git rebase instead of git merge - I hope that was the right thing to do.", "No, this PR now touches 484 files.", "Closing this and opening a new PR due to git rebase error."]}, {"number": 54381, "title": "Changes to add user scratch pad for matmul primitive to fix OOM issue in Transformer LT", "body": "Adding changes for the matmul primitive to use user scratch pad. This reduces memory footprint of the primitive. It fixes an out of memory issue when running Transformer LT with multiple instances and total thread count is large. Managing scratch pad for the primitive from the framework, fixes the out of memory issue, reduces memory footprint and does not affect performance. The changes :\r\n    Creates a new struct that hold the Tensor for scratch pad arg.\r\n    Allocates memory based on scratch pad size queried from  primitive description.\r\n    Sets user scratch pad in post ops for the primitive.\r\n   \r\n      ", "comments": ["@penpornk we are working to enable oneDNN scratchpad \"user-mode\" for conv, inner-product, and matmul ops. \r\n@TF side, we will continue to reuse primitives with LRU caching; but it will control oneDNN memory consumption (oneDNN will execute an op with provided scratchpad buffter and won't allocate anything more). \r\n\r\nTo answer the last quest:\r\n   (1) all conv/inner-product (matmul fused)/matmul (sgemm) ops will be cached at TF\r\n\r\n   (2) scratchpad buffer is allocated with Compute(), just before invoking oneDNN execution. \r\n        The buffer size is decided by oneDNN. Please check the \"struct UserScratchPad\" implementation in core/util/mkl_util.h\r\n\r\nThanks\r\n\r\n\r\n", "> (2) scratchpad buffer is allocated with Compute(), just before invoking oneDNN execution.\r\nThe buffer size is decided by oneDNN. Please check the \"struct UserScratchPad\" implementation in core/util/mkl_util.h\r\n\r\n@gzmkl Thank you for the quick reply! I understand that the user scratchpad is allocated in `Compute()`. But I don't understand how this differs from letting oneDNN allocate the buffer itself, since the matmul primitive here is not cached in LRU and is created every time `Compute()` is called too (and oneDNN allocates memory at primitive creation time). Both approaches seem to allocate scratchpad memory with similar lifetime, and the sizes shouldn't be too different since the user-allocated approach also gets the size from oneDNN. So I'm wondering what makes the difference here (in this PR).\r\n", "@penpornk \r\nWhen user scratch pad is not used by framework, oneDNN primitive adds its own scratch pad and hold it as long as the primitive is alive. TF also keeps all primitives alive till the LRU cache is full. In cases where there are many threads, each thread can create primitives for same dimensions, since the cache is thread local (this is essential). This results is many (similar) primitives created across multiple threads. For example, in the case of transformer (for which the issue was reported), the matmul dimensions varies based on input. This results in 100s of primitives getting created in each thread (when the thread count is greater than 1), each holding its scratch pad mem alive. And transformer with greater than 4 threads was going out of memory in machines with less memory (<182 GB)\r\n\r\n  With UserScratchPad, the TF framework controls the scratchpad by creating and releasing the scratchpad memory as needed : -ie (as of now) create it before execution and release it after execution of the primitive. This keeps the memory consumption low for the entire model"]}, {"number": 54380, "title": "Text generation isn't predicting correctly", "body": "hello, \r\n\r\nI am building a text generation model in Chinese and trying to pull out the probabilities between words for another task. This is the model I follow : https://www.tensorflow.org/text/tutorials/text_generation.\r\n\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.keras import models, layers, preprocessing, Model, callbacks, activations\r\n\r\ninputShape = (X_converted_final.shape[1],)\r\ninput = layers.Input(shape=inputShape)\r\nx=layers.Embedding(vocab_size2, embedding_dim, input_length=50, trainable=True, embeddings_initializer=\"uniform\")(input)\r\nx = layers.GRU(rnn_units, return_sequences=True, bias_initializer=\"zeros\")(x)\r\noutput= layers.Dense(vocab_size2, activation=activations.softmax)(x)\r\n\r\ngru_fpi_model = models.Model(input, output)\r\ngru_fpi_model.compile(loss=tf.losses.SparseCategoricalCrossentropy(from_logits=False),\r\n              optimizer='adam', metrics=[\"accuracy\"])\r\ncallback = callbacks.EarlyStopping(monitor='accuracy', patience=1)\r\ngru_fpi_model.summary()\r\n```\r\n\r\n\r\nSo this model should be able to give me '\u5929' as the highest possible next word if \u2019\u6628\u2019 is provided in the sequence, since '\u6628\u5929' means 'yesterday' in Chinese and we have a lot of examples in the training data. This model always takes a sequence so I tried to give the model a sequence and regard the highest probabilities of next words as the best candidate, given a previous word.  Here is what I did.\r\n\r\n\r\n`prediction=np.argmax(loaded_model(sentence)[:,2,:], axis=-1)`\r\n\r\nWith this line, if I give the model a sentence '\u6211\u6628\u5929\u665a\u4e0a\u53bb\u4e0a\u5b66', the model should give me the word that has the highest probabilities after '\u6628' (in the second position, including the beginning marker of sentence), which should be '\u5929' or other words, but it instead gives me '\u6628'. I couldn't find any sequence '\u6628\u6628' in the training data so there must be something wrong. For some words, it predicts well, e.g. '\u6211', it gives me '\u5011'and it means 'we' in English. So I think this model still works for some words, but it just doesn't work for some.\r\n\r\nCould anyone give me some hints on this? Thank you so much", "comments": ["Hi @limkhaiin1012 ! \r\nPlease post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues)\r\nTo know more see;\r\n[https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999](https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999) . Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54380\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54380\">No</a>\n"]}, {"number": 54378, "title": "Trying to convert faster_rcnn_resnet101_coco model to a tflite model", "body": "**System information**\r\nMac OS Big Sur (Version 11.6)\r\nTF 2.2.3\r\nPython 3.7\r\n\r\n**Command used to run the converter or code if you\u2019re using the Python API\r\nIf possible, please share a link to Colab/Jupyter/any notebook.**\r\n\r\nhttps://colab.research.google.com/drive/1F-KqnVYFq4UEEcwKSt2hxWb161QNS668?usp=sharing\r\n\r\nimport tensorflow as tf\r\n\r\n  converter =  tf.compat.v1.lite.TFLiteConverter.from_frozen_graph(\r\n    graph_def_file = 'faster_rcnn_resnet101_coco_2018_01_28/frozen_inference_graph.pb', \r\n    input_arrays = ['image_tensor'],\r\n    input_shapes={'image_tensor': [1,300,300,3]},\r\n    output_arrays = ['detection_boxes', 'detection_scores', 'detection_classes'] \r\n  )\r\n\r\n  converter.use_experimental_new_converter = True\r\n  converter.allow_custom_ops = True\r\n  converter.target_spec.supported_types = [tf.float16]\r\n  tflite_model = converter.convert()\r\n\r\n  with open('custom_model.tflite', 'wb') as f:\r\n    f.write(tflite_model)\r\n\r\n**The output from the converter invocation**\r\n\r\n**Model obtained from Model Zoo**\r\nhttp://download.tensorflow.org/models/object_detection/faster_rcnn_resnet101_coco_2018_01_28.tar.gz\r\n\r\n**Any other info / logs**\r\n\r\nI'm trying to convert the faster_rcnn_resnet101_coco pre-trained model from the TF Model Zoo to TFLite. \r\n\r\nIs there anything wrong with my process?", "comments": ["@SteveArias We see that you are using older version of TF 2.2.3 which is not actively supported .Could you please try to upgrade the TF version to 2.4 or later ? Please  let us know if the issue persists in newer versions? Thanks! ", "@sushreebarsa I have updated the Colab notebook (https://colab.research.google.com/drive/1F-KqnVYFq4UEEcwKSt2hxWb161QNS668?usp=sharing) to use tensorflow v2.8.0. I still get the same error.", "@SteveArias \r\nIn order to expedite the trouble-shooting process, could you please provide the access to your code  ?Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54378\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54378\">No</a>\n"]}, {"number": 54377, "title": "fix msvc build break on non en-US codepage (#53219)", "body": "#53219 it's not complete.", "comments": []}, {"number": 54376, "title": "[TF-TRT] Fix pylint error in `trt_convert.py`", "body": "cc @bixia1 \r\n\r\nFixes a pylint error that causes the pylint CI job to fail on any PR that touches `trt_convert.py`.\r\n\r\nThe pylint error that I saw on one of my PRs earlier wasn't a false positive but a change that was already in master and not in my branch, hence why it appeared in CI but not when I was running pylint locally. The error was introduced in #52248", "comments": []}, {"number": 54372, "title": "try and except do not work with tensorflow exceptions + impossible to debug shapes issue", "body": "You'll this [notebook][1] to reproduce the issue which downloads the files below and runs the exact same code following the description.\r\n\r\n - `labels.csv`: each row contains `x0`, `y0`, `x1`, `y1` text coordinates, and other columns not affecting the outcome.\r\n - `yolo-train-0.tfrecord`: Contains 90% of the examples found in `labels.csv`. Each example contains all labels/rows corresponding to the image in the example.\r\n\r\nI'm experiencing a recurring error that happens when iterating over a tfrecord dataset.\r\nAfter 2000-4000 iterations that successfully read batches from the dataset, I get the following error:\r\n\r\n    iteration: 3240 2022-02-14 04:25:15.376625: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at scatter_nd_op.cc:219 : INVALID_ARGUMENT: indices[189] = [6, 30, 38, 0] does not index into shape [8,38,38,3,6]\r\n    Traceback (most recent call last):\r\n      File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\", line 800, in __next__\r\n        return self._next_internal()\r\n      File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\", line 786, in _next_internal\r\n        output_shapes=self._flat_output_shapes)\r\n      File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 2845, in iterator_get_next\r\n        _ops.raise_from_not_ok_status(e, name)\r\n      File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 7107, in raise_from_not_ok_status\r\n        raise core._status_to_exception(e) from None  # pylint: disable=protected-access\r\n    tensorflow.python.framework.errors_impl.InvalidArgumentError: indices[189] = [6, 30, 38, 0] does not index into shape [8,38,38,3,6]\r\n    \t [[{{function_node __inference_transform_targets_for_output_1051}}{{node TensorScatterUpdate}}]] [Op:IteratorGetNext]\r\n\r\nIt is near impossible to tell which exact inputs that are causing the issue thanks to tensorflow's brilliant graph execution. I tried using `pdb`, `tf.print` statements and many other desperate measures trying to identify which examples in `labels.csv` that cause the problem and need to be excluded, and nothing looks particularly suspicious.\r\n\r\nHere's what the notebook runs and eventually results in the error mentioned.\r\n\r\n    import numpy as np\r\n    import pandas as pd\r\n    import tensorflow as tf\r\n    \r\n    \r\n    def transform_images(x, image_shape):\r\n        x = tf.image.resize(x, image_shape)\r\n        return x / 255\r\n    \r\n    \r\n    @tf.function\r\n    def transform_targets_for_output(y_true, grid_size, anchor_indices):\r\n        n = tf.shape(y_true)[0]\r\n        y_true_out = tf.zeros((n, grid_size, grid_size, tf.shape(anchor_indices)[0], 6))\r\n        anchor_indices = tf.cast(anchor_indices, tf.int32)\r\n        indexes = tf.TensorArray(tf.int32, 1, dynamic_size=True)\r\n        updates = tf.TensorArray(tf.float32, 1, dynamic_size=True)\r\n        idx = 0\r\n        for i in tf.range(n):\r\n            for j in tf.range(tf.shape(y_true)[1]):\r\n                if tf.equal(y_true[i][j][2], 0):\r\n                    continue\r\n                anchor_eq = tf.equal(anchor_indices, tf.cast(y_true[i][j][5], tf.int32))\r\n                if tf.reduce_any(anchor_eq):\r\n                    box = y_true[i][j][0:4]\r\n                    box_xy = (y_true[i][j][0:2] + y_true[i][j][2:4]) / 2\r\n                    anchor_idx = tf.cast(tf.where(anchor_eq), tf.int32)\r\n                    grid_xy = tf.cast(box_xy // (1 / grid_size), tf.int32)\r\n                    indexes = indexes.write(\r\n                        idx, [i, grid_xy[1], grid_xy[0], anchor_idx[0][0]]\r\n                    )\r\n                    updates = updates.write(\r\n                        idx, [box[0], box[1], box[2], box[3], 1, y_true[i][j][4]]\r\n                    )\r\n                    idx += 1\r\n        return tf.tensor_scatter_nd_update(y_true_out, indexes.stack(), updates.stack())\r\n    \r\n    \r\n    def transform_targets(y, anchors, anchor_masks, size):\r\n        y_outs = []\r\n        grid_size = size // 32\r\n        anchors = tf.cast(anchors, tf.float32)\r\n        anchor_area = anchors[..., 0] * anchors[..., 1]\r\n        box_wh = y[..., 2:4] - y[..., 0:2]\r\n        box_wh = tf.tile(tf.expand_dims(box_wh, -2), (1, 1, tf.shape(anchors)[0], 1))\r\n        box_area = box_wh[..., 0] * box_wh[..., 1]\r\n        intersection = tf.minimum(box_wh[..., 0], anchors[..., 0]) * tf.minimum(\r\n            box_wh[..., 1], anchors[..., 1]\r\n        )\r\n        iou = intersection / (box_area + anchor_area - intersection)\r\n        anchor_idx = tf.cast(tf.argmax(iou, axis=-1), tf.float32)\r\n        anchor_idx = tf.expand_dims(anchor_idx, axis=-1)\r\n        y = tf.concat([y, anchor_idx], axis=-1)\r\n        for anchor_indices in anchor_masks:\r\n            y_outs.append(transform_targets_for_output(y, grid_size, anchor_indices))\r\n            grid_size *= 2\r\n        return tuple(y_outs)\r\n    \r\n    \r\n    def read_example(\r\n        example,\r\n        feature_map,\r\n        class_table,\r\n        max_boxes,\r\n        image_shape,\r\n    ):\r\n        features = tf.io.parse_single_example(example, feature_map)\r\n        image = tf.image.decode_png(features['image'], channels=3)\r\n        image = tf.image.resize(image, image_shape)\r\n        object_name = tf.sparse.to_dense(features['object_name'])\r\n        label = tf.cast(class_table.lookup(object_name), tf.float32)\r\n        label = tf.stack(\r\n            [tf.sparse.to_dense(features[feature]) for feature in ['x0', 'y0', 'x1', 'y1']]\r\n            + [label],\r\n            1,\r\n        )\r\n        padding = [[0, max_boxes - tf.shape(label)[0]], [0, 0]]\r\n        label = tf.pad(label, padding)\r\n        return image, label\r\n    \r\n    \r\n    def read_tfrecord(\r\n        fp,\r\n        classes_file,\r\n        image_shape,\r\n        max_boxes,\r\n        shuffle_buffer_size,\r\n        batch_size,\r\n        anchors,\r\n        masks,\r\n        classes_delimiter='\\n',\r\n    ):\r\n        text_initializer = tf.lookup.TextFileInitializer(\r\n            classes_file, tf.string, 0, tf.int64, -1, delimiter=classes_delimiter\r\n        )\r\n        class_table = tf.lookup.StaticHashTable(text_initializer, -1)\r\n        files = tf.data.Dataset.list_files(fp)\r\n        dataset = files.flat_map(tf.data.TFRecordDataset)\r\n        feature_map = {\r\n            'image': tf.io.FixedLenFeature([], tf.string),\r\n            'x0': tf.io.VarLenFeature(tf.float32),\r\n            'y0': tf.io.VarLenFeature(tf.float32),\r\n            'x1': tf.io.VarLenFeature(tf.float32),\r\n            'y1': tf.io.VarLenFeature(tf.float32),\r\n            'object_name': tf.io.VarLenFeature(tf.string),\r\n            'object_index': tf.io.VarLenFeature(tf.int64),\r\n        }\r\n        return (\r\n            dataset.map(\r\n                lambda x: read_example(x, feature_map, class_table, max_boxes, image_shape),\r\n                tf.data.experimental.AUTOTUNE,\r\n            )\r\n            .batch(batch_size)\r\n            .shuffle(shuffle_buffer_size)\r\n            .map(\r\n                lambda x, y: (\r\n                    transform_images(x, image_shape),\r\n                    transform_targets(y, anchors, masks, image_shape[0]),\r\n                )\r\n            )\r\n            .prefetch(tf.data.experimental.AUTOTUNE)\r\n        )\r\n\r\n\r\n    if __name__ == '__main__':\r\n        input_shape = (608, 608, 3)\r\n        labels = pd.read_csv('labels.csv')\r\n        classes_file = 'classes.txt'\r\n        max_boxes = max([g[1].shape[0] for g in labels.groupby('image')])\r\n        shuffle_buffer_size = 256\r\n        batch_size = 8\r\n        anchors = np.array(\r\n                [\r\n                    (10, 13),\r\n                    (16, 30),\r\n                    (33, 23),\r\n                    (30, 61),\r\n                    (62, 45),\r\n                    (59, 119),\r\n                    (116, 90),\r\n                    (156, 198),\r\n                    (373, 326),\r\n                ]\r\n            ) / np.array(input_shape[:-1])\r\n        masks = np.array([[6, 7, 8], [3, 4, 5], [0, 1, 2]])\r\n        train_dataset = read_tfrecord(\r\n                    '/content/yolo-train-0.tfrecord',\r\n                    classes_file,\r\n                    input_shape[:-1],\r\n                    max_boxes,\r\n                    shuffle_buffer_size,\r\n                    batch_size,\r\n                    anchors,\r\n                    masks,\r\n                )\r\n        for i, _ in enumerate(train_dataset, 1):  # There should be around 11000 iterations\r\n            print(f'\\riteration: {i}', end='')\r\n\r\nIs there a way to filter out the problematic examples? How am i exactly supposed to figure out what's wrong?\r\n\r\nI tried the following using try and except blocks and it doesn't work and gives the same exception\r\n\r\n    dataset = iter(dataset)\r\n    while True:\r\n        try: \r\n            yield next(dataset)\r\n        except InvalidArgumentError:\r\n            pass\r\n\r\n\r\n  [1]: https://colab.research.google.com/drive/1PsPyJNCwOen5RVI3wQ0g2VrHLrrytaE3?usp=sharing", "comments": ["Hi @alternativebug ! Check for anomaly in your datasets using panda's histogram feature first. You can [iterate](https://thispointer.com/pandas-loop-or-iterate-over-all-or-certain-columns-of-a-dataframe/) through concerned column  having shape values with  [6, 30, 38, 0]  and truncate the respective rows  before inputting them for training.Thanks!", "Hi @mohantym, I included in the notebook [labels.csv](https://drive.google.com/file/d/1iWYECzkoyxm_2mfnrXqkaKvfEgPKiGrZ/view?usp=sharing) which looks like the following:\r\n\r\n                     x0            y0            x1            y1  object_index\r\n    count  4.620389e+06  4.620389e+06  4.620389e+06  4.620389e+06     4620389.0\r\n    mean   3.950749e-01  3.928320e-01  5.115363e-01  5.254216e-01           0.0\r\n    std    2.760872e-01  2.686311e-01  2.758303e-01  2.688573e-01           0.0\r\n    min    0.000000e+00  0.000000e+00  1.125402e-02  9.338521e-02           0.0\r\n    25%    1.534743e-01  1.433692e-01  2.723535e-01  2.829268e-01           0.0\r\n    50%    3.800892e-01  4.277457e-01  4.983571e-01  5.499022e-01           0.0\r\n    75%    6.320837e-01  5.817490e-01  7.487703e-01  7.153846e-01           0.0\r\n    max    9.828326e-01  8.983287e-01  1.056757e+00  1.000000e+00           0.0\r\n\r\nand here's the histogram output:\r\n\r\n![Figure_1](https://user-images.githubusercontent.com/58062537/154009856-a1eef714-f508-4d37-861a-468c6cd82577.png)", "@alternativebug \r\nIssue might be because of CSV may has malformed data or empty lines. In such case you can use `tf.data.experimental.make_csv_dataset('file_name.csv')` which has argument called `ignore_errors`\r\n\r\n> ignore_errors = If True, ignores errors with CSV file parsing, such as malformed data or empty lines, and moves on to the next valid CSV record. Otherwise, the dataset raises an error and stops processing when encountering any invalid records. Defaults to False. \r\n\r\n\r\nFor more information about the library refer [here](https://www.tensorflow.org/api_docs/python/tf/data/experimental/make_csv_dataset)", "I had the same doubts about the labels, and by checking the csv using pandas, I didn't and still don't find any null / nan values and nothing looks suspicious. Besides, I assume running  `tf.data.experimental.make_csv_dataset` without `ignore_errors` on the very same labels, should give an error if something somewhere is wrong, which didn't happen when I tried shortly after your comment. I also think that if something is wrong with the labels, the code should fail during the creation of tfrecord because the null/nan input won't match the [feature](https://www.tensorflow.org/api_docs/python/tf/train/Feature)'s dtype which is also not the case.", "@alternativebug, Load the data in batch manner to see which data point is creating this issue.\r\n`\r\nbatched_dataset = dataset.batch(4)`. For more information take a look [here](https://www.tensorflow.org/guide/data#batching_dataset_elements) ", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54372\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54372\">No</a>\n"]}, {"number": 54371, "title": "AttributeError: module 'tensorflow.python.framework.ops' has no attribute '_TensorLike'", "body": "**System information**\r\n\r\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): windows 10 professional 19042.1466\r\nTensorFlow installed from (source or binary):pip install\r\nTensorFlow version (use command below):v2.7.0-rc1-69-gc256c071bb2 , 2.7.0\r\nPython version:3.7\r\nCUDA/cuDNN version: CUDA:11.4.0_471.11,cuDNN:8.3.2.44\r\nGPU model and memory:GTX 970,4G memory\r\n\r\n**Describe the current behavior**\r\nI have a problem, when running the code, it prompts:\r\n```\r\n  File \"D:/Tony/Documents/yunpan/invest/2022/quant/gym/study PG/pg.py\", line 79, in __init__\r\n    self.model = tl.models.Model(inputs=input_layer, outputs=all_act)\r\n  File \"D:\\Anaconda3\\envs\\gym_env\\lib\\site-packages\\tensorlayer\\models\\core.py\", line 213, in __init__\r\n    if isinstance(check_argu, tf_ops._TensorLike) or tf_ops.is_dense_tensor_like(check_argu):\r\nAttributeError: module 'tensorflow.python.framework.ops' has no attribute '_TensorLike'\r\n```\r\n\r\n**Standalone code to reproduce the issue**\r\n[tutorial_PG.py](https://github.com/tensorlayer/tensorlayer/blob/master/examples/reinforcement_learning/tutorial_PG.py)", "comments": ["Update tensorlayer to version 2.2.5 and solved."]}, {"number": 54370, "title": "`MirroredVariable`s not recorded on the gradient tape", "body": "I am unsure whether this is the right place to post this, so feel free to remove if this is the case.\r\n\r\nI\u2019m currently trying to understand the internal functioning of the `MirroredStrategy` and the recording of gradients of `MirroredVariable`s in particular and doing so running into an issue where the gradient tape does not record any mirrored variables at all.\r\n\r\nI understand the concept of the `MirroredVariable` but it\u2019s unclear to me how a correct gradient tape is recorded over these variables in `_call_for_each_replica` in `mirrored_strategy`. As this implementation seems mostly covered by `mirrored_run` I tried to mainly focus on this file instead. Say we have 1 `MirroredVariable` with the following signature:\r\n\r\n```\r\nMirroredVariable {\r\n  0: <tf.Variable 'w:0' shape=() dtype=float32>,\r\n  1: <tf.Variable 'w/replica_1:0' shape=() dtype=float32>\r\n}\r\n```\r\n\r\nI\u2019ve tried to understand this behavior by altering the `_call_for_each_replica` implementation so it runs every function sequentially on the defined device (just removing the replica threads). This works for variable creation, computation and reduction, but breaks when recording gradients. Say I have the following function:\r\n\r\n```\r\n@def_function.function\r\ndef step(x):\r\n    with backprop.GradientTape() as tape:\r\n        loss = w * x\r\n\r\n    optimizer.minimize(loss, var_list=[w], tape=tape)\r\n\r\nstrategy.run(step, args=(2.0,))\r\n```\r\n\r\nThis yields:\r\n```\r\nNo gradients provided for any variable: ['w:0']\r\n```\r\n\r\nAdding `tape.watch(w)` doesn\u2019t change anything and my guess is that it\u2019s due to the function wrapping happening in `call_for_each_replica` in `mirrored_run`. I would have expected this to record on a per gradient basis. Could anyone shine some light on how these gradients are recorded here?", "comments": ["@caandewiel ,\r\nWe see that the issue [template](https://github.com/tensorflow/tensorflow/issues/new/choose) has not been filled, could you please do so as it helps us analyse the issue [tf version, steps followed before you ran into this error or stand alone code to reproduce the issue faced] or if possible share a colab gist with the issue reported.", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 54369, "title": "Cannot install tensorflow_text in virtual environment of python 3.8 mac m1", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac M1\r\n- TensorFlow version: 2.7.0\r\n- Python version: 3.8\r\n- Installed using virtualenv? pip? conda?: virtualenv (see https://developer.apple.com/metal/tensorflow-plugin/)\r\n\r\n\r\n\r\n\r\n**Describe the problem**\r\nTo use the [`xx_use_md` model](https://pypi.org/project/spacy-universal-sentence-encoder/0.2.1/), I started a virtualenv. \r\n\r\nI tried to load the model by \r\n\r\n```\r\nimport spacy_universal_sentence_encoder\r\nnlp = spacy_universal_sentence_encoder.load_model('xx_use_md')\r\n```\r\n\r\nThen, I encountered the error:\r\n\r\n```\r\nFileNotFoundError: Op type not registered 'SentencepieceOp' in binary running on MacBook-Air. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\r\n You may be trying to load on a different device from the computational device. Consider setting the `experimental_io_device` option in `tf.saved_model.LoadOptions` to the io_device such as '/job:localhost'.\r\n```\r\n\r\nGuided by the discussion here: https://github.com/tensorflow/tensorflow/issues/38597, I tried to install `tensorflow_text` in the virtualenv via pip3, but this raised another error:\r\n\r\n```\r\nERROR: Could not find a version that satisfies the requirement tensorflow_text (from versions: none)\r\nERROR: No matching distribution found for tensorflow_text\r\n```\r\n\r\nAdditionally, I tried to load the model by\r\n\r\n```\r\nimport spacy\r\nnlp = spacy.load('xx_use_md')\r\n```\r\n\r\nwhich raised the error\r\n\r\n```\r\nOSError: [E050] Can't find model 'xx_use_md'. It doesn't seem to be a Python package or a valid path to a data directory.\r\n```\r\n\r\nThen, I used the command `pip3 install https://github.com/MartinoMensio/spacy-universal-sentence-encoder-tfhub/releases/download/xx_use_md-0.2.1/xx_use_md-0.2.1.tar.gz#xx_use_md-0.2.1` on https://pypi.org/project/spacy-universal-sentence-encoder/0.2.1/ . Another error happened:\r\n\r\n```\r\nERROR: Could not find a version that satisfies the requirement tensorflow==2.1.0 (from spacy-universal-sentence-encoder) (from versions: none)\r\nERROR: No matching distribution found for tensorflow==2.1.0\r\n```\r\n\r\nIt is impossible to use the 'xx_use_md' model by `import spacy` or `import spacy_universal_sentence_encoder` in the virtualenv. However, when I tried with the same code on Colab, similar errors occurred and were resolved by installing and importing `tensowflow_text`.", "comments": ["Hi @sijia-w ! Please change your command  \"pip install tensorflow_text\"  to \"pip install tensorflow-text\" . You can import tensorflow -text with this command \"import tensorflow_text as [tf_text](https://www.tensorflow.org/text)\" after that. Thanks!", "Hi @mohantym  Thanks a lot for your quick response! Unfortunately, still the same error.\r\n\r\n<img width=\"908\" alt=\"image\" src=\"https://user-images.githubusercontent.com/53718687/153872757-8a6adea8-5155-4276-9747-08a266b5da1e.png\">\r\n", "Hi @sijia-w ! Could you please post on [Tensorflow-text ](https://github.com/tensorflow/text/issues)repo ?Attaching relevant [thread ](https://github.com/tensorflow/text/issues/89#issuecomment-1015848485)for reference. Thanks!", "Hi @mohantym, Sure! See https://github.com/tensorflow/text/issues/837.  Shall I close this issue?", "Ok @sijia-w ! Closing this issue here as it will be tracked in Tensorflow-text repo. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54369\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54369\">No</a>\n"]}, {"number": 54368, "title": "fix slow training start when using sample_weight (issue #48965)", "body": "fix issue 'Keras model.fit takes long until training begins when sample_weight is provided #48965.' previous version used list comprehension to check if any of the sample weights are 'None'. This is very slow. This replaces the list comprehension with array operations by converting the tensor to a numpy array.", "comments": ["It looks like your PR relates to the Keras component. Please submit it to the github.com/keras-team/keras repository instead. Thankyou.\r\n@fchollet, @qlzh727"]}, {"number": 54367, "title": "InvalidArgumentError: indices[189] = [6, 30, 38, 0] does not index into shape [8,38,38,3,6]", "body": "You'll this [notebook][1] to reproduce the issue which downloads the files below and runs the exact same code following the description.\r\n\r\n - `labels.csv`: each row contains `x0`, `y0`, `x1`, `y1` text coordinates, and other columns not affecting the outcome.\r\n - `yolo-train-0.tfrecord`: Contains 90% of the examples found in `labels.csv`. Each example contains all labels/rows corresponding to the image in the example.\r\n\r\nI'm experiencing a recurring error that happens when iterating over a tfrecord dataset.\r\nAfter 2000-4000 iterations that successfully read batches from the dataset, I get the following error:\r\n\r\n    iteration: 3240 2022-02-14 04:25:15.376625: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at scatter_nd_op.cc:219 : INVALID_ARGUMENT: indices[189] = [6, 30, 38, 0] does not index into shape [8,38,38,3,6]\r\n    Traceback (most recent call last):\r\n      File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\", line 800, in __next__\r\n        return self._next_internal()\r\n      File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\", line 786, in _next_internal\r\n        output_shapes=self._flat_output_shapes)\r\n      File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 2845, in iterator_get_next\r\n        _ops.raise_from_not_ok_status(e, name)\r\n      File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 7107, in raise_from_not_ok_status\r\n        raise core._status_to_exception(e) from None  # pylint: disable=protected-access\r\n    tensorflow.python.framework.errors_impl.InvalidArgumentError: indices[189] = [6, 30, 38, 0] does not index into shape [8,38,38,3,6]\r\n    \t [[{{function_node __inference_transform_targets_for_output_1051}}{{node TensorScatterUpdate}}]] [Op:IteratorGetNext]\r\n\r\nIt is near impossible to tell which exact inputs that are causing the issue thanks to tensorflow's brilliant graph execution. I tried using `pdb`, `tf.print` statements and many other desperate measures trying to identify which examples in `labels.csv` that cause the problem and need to be excluded, and nothing looks particularly suspicious.\r\n\r\nHere's what the notebook runs and eventually results in the error mentioned.\r\n\r\n    import numpy as np\r\n    import pandas as pd\r\n    import tensorflow as tf\r\n    \r\n    \r\n    def transform_images(x, image_shape):\r\n        x = tf.image.resize(x, image_shape)\r\n        return x / 255\r\n    \r\n    \r\n    @tf.function\r\n    def transform_targets_for_output(y_true, grid_size, anchor_indices):\r\n        n = tf.shape(y_true)[0]\r\n        y_true_out = tf.zeros((n, grid_size, grid_size, tf.shape(anchor_indices)[0], 6))\r\n        anchor_indices = tf.cast(anchor_indices, tf.int32)\r\n        indexes = tf.TensorArray(tf.int32, 1, dynamic_size=True)\r\n        updates = tf.TensorArray(tf.float32, 1, dynamic_size=True)\r\n        idx = 0\r\n        for i in tf.range(n):\r\n            for j in tf.range(tf.shape(y_true)[1]):\r\n                if tf.equal(y_true[i][j][2], 0):\r\n                    continue\r\n                anchor_eq = tf.equal(anchor_indices, tf.cast(y_true[i][j][5], tf.int32))\r\n                if tf.reduce_any(anchor_eq):\r\n                    box = y_true[i][j][0:4]\r\n                    box_xy = (y_true[i][j][0:2] + y_true[i][j][2:4]) / 2\r\n                    anchor_idx = tf.cast(tf.where(anchor_eq), tf.int32)\r\n                    grid_xy = tf.cast(box_xy // (1 / grid_size), tf.int32)\r\n                    indexes = indexes.write(\r\n                        idx, [i, grid_xy[1], grid_xy[0], anchor_idx[0][0]]\r\n                    )\r\n                    updates = updates.write(\r\n                        idx, [box[0], box[1], box[2], box[3], 1, y_true[i][j][4]]\r\n                    )\r\n                    idx += 1\r\n        return tf.tensor_scatter_nd_update(y_true_out, indexes.stack(), updates.stack())\r\n    \r\n    \r\n    def transform_targets(y, anchors, anchor_masks, size):\r\n        y_outs = []\r\n        grid_size = size // 32\r\n        anchors = tf.cast(anchors, tf.float32)\r\n        anchor_area = anchors[..., 0] * anchors[..., 1]\r\n        box_wh = y[..., 2:4] - y[..., 0:2]\r\n        box_wh = tf.tile(tf.expand_dims(box_wh, -2), (1, 1, tf.shape(anchors)[0], 1))\r\n        box_area = box_wh[..., 0] * box_wh[..., 1]\r\n        intersection = tf.minimum(box_wh[..., 0], anchors[..., 0]) * tf.minimum(\r\n            box_wh[..., 1], anchors[..., 1]\r\n        )\r\n        iou = intersection / (box_area + anchor_area - intersection)\r\n        anchor_idx = tf.cast(tf.argmax(iou, axis=-1), tf.float32)\r\n        anchor_idx = tf.expand_dims(anchor_idx, axis=-1)\r\n        y = tf.concat([y, anchor_idx], axis=-1)\r\n        for anchor_indices in anchor_masks:\r\n            y_outs.append(transform_targets_for_output(y, grid_size, anchor_indices))\r\n            grid_size *= 2\r\n        return tuple(y_outs)\r\n    \r\n    \r\n    def read_example(\r\n        example,\r\n        feature_map,\r\n        class_table,\r\n        max_boxes,\r\n        image_shape,\r\n    ):\r\n        features = tf.io.parse_single_example(example, feature_map)\r\n        image = tf.image.decode_png(features['image'], channels=3)\r\n        image = tf.image.resize(image, image_shape)\r\n        object_name = tf.sparse.to_dense(features['object_name'])\r\n        label = tf.cast(class_table.lookup(object_name), tf.float32)\r\n        label = tf.stack(\r\n            [tf.sparse.to_dense(features[feature]) for feature in ['x0', 'y0', 'x1', 'y1']]\r\n            + [label],\r\n            1,\r\n        )\r\n        padding = [[0, max_boxes - tf.shape(label)[0]], [0, 0]]\r\n        label = tf.pad(label, padding)\r\n        return image, label\r\n    \r\n    \r\n    def read_tfrecord(\r\n        fp,\r\n        classes_file,\r\n        image_shape,\r\n        max_boxes,\r\n        shuffle_buffer_size,\r\n        batch_size,\r\n        anchors,\r\n        masks,\r\n        classes_delimiter='\\n',\r\n    ):\r\n        text_initializer = tf.lookup.TextFileInitializer(\r\n            classes_file, tf.string, 0, tf.int64, -1, delimiter=classes_delimiter\r\n        )\r\n        class_table = tf.lookup.StaticHashTable(text_initializer, -1)\r\n        files = tf.data.Dataset.list_files(fp)\r\n        dataset = files.flat_map(tf.data.TFRecordDataset)\r\n        feature_map = {\r\n            'image': tf.io.FixedLenFeature([], tf.string),\r\n            'x0': tf.io.VarLenFeature(tf.float32),\r\n            'y0': tf.io.VarLenFeature(tf.float32),\r\n            'x1': tf.io.VarLenFeature(tf.float32),\r\n            'y1': tf.io.VarLenFeature(tf.float32),\r\n            'object_name': tf.io.VarLenFeature(tf.string),\r\n            'object_index': tf.io.VarLenFeature(tf.int64),\r\n        }\r\n        return (\r\n            dataset.map(\r\n                lambda x: read_example(x, feature_map, class_table, max_boxes, image_shape),\r\n                tf.data.experimental.AUTOTUNE,\r\n            )\r\n            .batch(batch_size)\r\n            .shuffle(shuffle_buffer_size)\r\n            .map(\r\n                lambda x, y: (\r\n                    transform_images(x, image_shape),\r\n                    transform_targets(y, anchors, masks, image_shape[0]),\r\n                )\r\n            )\r\n            .prefetch(tf.data.experimental.AUTOTUNE)\r\n        )\r\n\r\n\r\n    if __name__ == '__main__':\r\n        input_shape = (608, 608, 3)\r\n        labels = pd.read_csv('labels.csv')\r\n        classes_file = 'classes.txt'\r\n        max_boxes = max([g[1].shape[0] for g in labels.groupby('image')])\r\n        shuffle_buffer_size = 256\r\n        batch_size = 8\r\n        anchors = np.array(\r\n                [\r\n                    (10, 13),\r\n                    (16, 30),\r\n                    (33, 23),\r\n                    (30, 61),\r\n                    (62, 45),\r\n                    (59, 119),\r\n                    (116, 90),\r\n                    (156, 198),\r\n                    (373, 326),\r\n                ]\r\n            ) / np.array(input_shape[:-1])\r\n        masks = np.array([[6, 7, 8], [3, 4, 5], [0, 1, 2]])\r\n        train_dataset = read_tfrecord(\r\n                    '/content/yolo-train-0.tfrecord',\r\n                    classes_file,\r\n                    input_shape[:-1],\r\n                    max_boxes,\r\n                    shuffle_buffer_size,\r\n                    batch_size,\r\n                    anchors,\r\n                    masks,\r\n                )\r\n        for i, _ in enumerate(train_dataset, 1):  # There should be around 11000 iterations\r\n            print(f'\\riteration: {i}', end='')\r\n\r\nIs there a way to filter out the problematic examples?\r\n\r\n\r\n  [1]: https://colab.research.google.com/drive/1PsPyJNCwOen5RVI3wQ0g2VrHLrrytaE3?usp=sharing", "comments": []}, {"number": 54366, "title": "[oneDNN] Parallelize UnsortedSegmentOp by simpler method", "body": "This PR is a simpler version of the reverted PR: https://github.com/tensorflow/tensorflow/pull/49152\r\n\r\nThe previous PR **used a complex method to balance workload** for better parallelism efficiency, but it's failed in internal test and reverted automatically. I removed the balance policy to make it simpler and safer. The new implementation can also get good performance if the workload is balance naturally. Even in the imbalance scenario it won't be worse than original single thread implementation.\r\n\r\nThe new method is just to parallelize `UnsortedSegmentOp` by each output row:\r\n```\r\n//   input   segment_ids                 num_segments  operation\r\n//   | a0 |  | 0 |            worker 1:  |0|           f(a0, a1)\r\n//   | b0 |  | 1 |            worker 2:  |1|           f(b0, b1)\r\n// N | c0 |  | 2 |       -->  worker 3:  |2|           f(c0)\r\n//   | b1 |  | 1 |\r\n//   | a1 |  | 0 |\r\n```\r\n\r\nSingle op improvement in TF benchmark: **1.92x ~ 14.46x**\r\nBefore opt:\r\n```\r\n--------------------------------------------------------------------------------------------------------------\r\nBenchmark                                                    Time             CPU   Iterations UserCounters...\r\n--------------------------------------------------------------------------------------------------------------\r\nBM_UnsortedSegmentSum_4096_1024_1                       520890 ns       520870 ns         1344 bytes_per_second=29.9979G/s\r\nBM_UnsortedSegmentSum_4096_1024_128                     700895 ns       700889 ns         1019 bytes_per_second=22.2931G/s\r\n```\r\nAfter opt:\r\n```\r\n--------------------------------------------------------------------------------------------------------------\r\nBenchmark                                                    Time             CPU   Iterations UserCounters...\r\n--------------------------------------------------------------------------------------------------------------\r\nBM_UnsortedSegmentSum_4096_1024_1                       270874 ns       270875 ns         2586 bytes_per_second=57.6835G/s\r\nBM_UnsortedSegmentSum_4096_1024_128                     115952 ns        48465 ns        14288 bytes_per_second=322.396G/s\r\n```\r\n\r\nWe also see more than 5% throughput improvement when run public recommendation model on CPU with this OPT.\r\n\r\nSigned-off-by: Lu Teng [teng.lu@intel.com](mailto:teng.lu@intel.com)", "comments": ["Hi @ezhulenev , can you help to review this simpler version since you have checked the original PR?"]}, {"number": 54365, "title": "C compatible for external delegate", "body": "Fixes for `variably modified` compilation error.", "comments": []}, {"number": 54364, "title": "convert .meta,and chkpoint to .pb gives error \"maximum protobuf size of 2GB\"", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below): 1.15\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n**Describe the current behavior**\r\n\r\nI am converting .meta and chkpoint file to protobuf type, but getting error-\r\n\r\n\r\nTraceback (most recent call last):\r\n  File \"converttofrozen.py\", line 28, in <module>\r\n    pickle.dump(frozen_graph, frozen_graph_file)\r\n  File \"/home/marlin/anaconda/envs/hific-compress1/lib/python3.7/site-packages/google/protobuf/message.py\", line 408, in __reduce__\r\n    return type(self), (), self.__getstate__()\r\n  File \"/home/marlin/anaconda/envs/hific-compress1/lib/python3.7/site-packages/google/protobuf/message.py\", line 393, in __getstate__\r\n    return dict(serialized=self.SerializePartialToString())\r\nValueError: Message tensorflow.GraphDef exceeds maximum protobuf size of 2GB: 2237555411\r\n\r\n\r\nI followed the suggestion [here ](https://stackoverflow.com/questions/45864363/tensorflow-how-to-convert-meta-data-and-index-model-files-into-one-graph-pb/45868106#45868106) for conversion.\r\n\r\nThe chkpt file size is bigger than 2 GB.\r\n![image](https://user-images.githubusercontent.com/20053548/153773801-826d6bd9-d0d5-48ed-906d-829e2e5d013f.png)\r\n\r\n\r\nIs there a way to get rid of the hard limit of 2GB in conversion?\r\n\r\n", "comments": ["@prmudgal ,\r\nCan you please take a look at this link [1](https://github.com/tensorflow/tensorflow/issues/47326) and [2](https://github.com/tensorflow/tensorflow/issues/45041) with the similar error.It helps.Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54364\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54364\">No</a>\n"]}, {"number": 54363, "title": "graph - AttributeError: can't set attribute", "body": "OS: windows\r\ntenosrflow  '2.8.0' (usingas  import tensorflow._api.v2.compat.v1 as tf)\r\n\r\nHi \r\nI am not able to do update operations for tensorflow graph nodes (graph -> node -> node.node_def) [https://github.com/davidsandberg/facenet/issues/161](https://github.com/davidsandberg/facenet/issues/161) I have explored few repos, none of them seems to be working.\r\n\r\ncode \r\n\r\n```\r\nmodel_path = '../deepmind-research/meshgraphnets/chk/flag_simple/chk/model.ckpt-29872'\r\nsess = tf.Session()\r\n\r\nsaver = tf.train.import_meta_graph(model_path + \".meta\")\r\nsaver.restore(sess, model_path)\r\n\r\n\r\ninit_op =  tf.global_variables_initializer()    \r\nwith tf.Session() as session:\r\n    session.run(init_op)\r\n    gd = sess.graph.as_graph_def()\r\n    output_graph_def = graph_util.convert_variables_to_constants(sess, gd, output)\r\n    graph_io.write_graph(graphdef_frozen, save_pb_dir, 'frozen_model1.pb', as_text=save_pb_as_text)\r\n        \r\n\r\n\r\nnode = graph.get_operations()\r\nprint(node.node_def)\r\n```\r\nname: \"Model/output_normalizer/Variable/Assign\"\r\nop: \"AssignVariableOp\"\r\ninput: \"Model/output_normalizer/Variable\"\r\ninput: \"Model/output_normalizer/Variable/Initializer/initial_value\"\r\nattr {\r\n  key: \"dtype\"\r\n  value {\r\n    type: DT_FLOAT\r\n  }\r\n}\r\nattr {\r\n  key: \"validate_shape\"\r\n  value {\r\n    b: false\r\n  }\r\n}\r\n\r\n```\r\nnode.node_def.op = 'VariableOp'\r\n(runs without error but, not reflecting in node_def)\r\nprint(node.node_def)\r\n```\r\nname: \"Model/output_normalizer/Variable/Assign\"\r\nop: \"AssignVariableOp\"\r\ninput: \"Model/output_normalizer/Variable\"\r\ninput: \"Model/output_normalizer/Variable/Initializer/initial_value\"\r\nattr {\r\n  key: \"dtype\"\r\n  value {\r\n    type: DT_FLOAT\r\n  }\r\n}\r\nattr {\r\n  key: \"validate_shape\"\r\n  value {\r\n    b: false\r\n  }\r\n}\r\n```\r\na = node.node_def\r\na.op = node.node_def.op[6:]\r\nnode.node_def = a\r\n\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\nInput In [111], in <module>\r\n      1 a = node.node_def\r\n      2 a.op = node.node_def.op[6:]\r\n----> 3 node.node_def = a\r\n\r\nAttributeError: can't set attribute\r\n\r\n```\r\n\r\nWould you please show me some relevant resources to explore in this problem, I am exhausted from searching :-| \r\n\r\n\r\nHere I added link to frozen inference graph [https://github.com/Nagakiran1/data/blob/main/frozen_model.pb](url)\r\n", "comments": ["Hi @Nagakiran1 ! Could you please share another stand alone code as a colab gist with reference to below code snippet? \r\n\r\n```\r\na = node.node_def\r\na.op = node.node_def.op[6:]\r\nnode.node_def = a\r\n\r\n```\r\n\r\n\r\n", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54363\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54363\">No</a>\n"]}, {"number": 54362, "title": "GPU keeps deactivating while running model.fit", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 11\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): pip install tensorflow\r\n- TensorFlow version (use command below): 2.7\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: Cuda: 11.2, cudnn: 8.1\r\n- GPU model and memory: NVidia 2.50Ti 4Gb\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nGPU keeps disappearing/disabling after using tensorflow. I've used the following steps to create an environment.\r\n- ```conda create -n tf python==3.8```\r\n- ```conda activate tf```\r\n- ```conda install cudatoolkit=11.2 cudnn=8.1 -c=conda-forge```\r\n- ```pip install --upgrade tensorflow-gpu==2.7.0```\r\n\r\nIf I run \r\n``` \r\nimport tensorflow as tf\r\ntf.test.is_gpu_available() \r\n```\r\nin the interactive python, I can see my GPU with its model.\r\n```\r\n2022-02-13 10:30:58.539032: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2022-02-13 10:31:14.682633: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /device:GPU:0 with 2776 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\r\nTrue\r\n```\r\nBut when I try to run the ```mode.fit()``` code in jupyter notebook, exactly when its supposed to use the GPU, GPU somehow disables itself and I can't view it in the interactive python terminal either and I have to restart my computer to view it again. And it keeps repeating no matter how many environments I recreate.\r\n\r\n```\r\n2022-02-13 10:26:52.177899: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2022-02-13 10:26:52.556208: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\r\n2022-02-13 10:26:52.575207: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: pecmun\r\n2022-02-13 10:26:52.575920: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: pecmun\r\nFalse\r\n```\r\n\r\n**Describe the expected behavior**\r\nIt should work\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no):\r\n- Briefly describe your candidate solution(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["@sugamkarki \r\nIn order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n"]}, {"number": 54361, "title": "[BUG] Random initializer produces different values inside/outside a gradient tape.", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04\r\n- TensorFlow installed from (source or binary):  Binary\r\n- TensorFlow version (use command below): 2.8\r\n- Python version: 3.8\r\n\r\n**Describe the current behavior**\r\n\r\nAs the script below shows, no matter API version of random intializer is v1 or v2, values produced are different between inside a gradient tape or not. \r\n\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\nw1_init = tf.compat.v1.random_normal_initializer(mean=0., stddev=1., seed=3)\r\nw1_val = w1_init(shape=[4,5], dtype=tf.float64)\r\n\r\nw2_init = tf.initializers.RandomNormal(mean=0., stddev=1., seed=3)\r\nw2_val = w2_init(shape=[4,5], dtype=tf.float64)\r\n\r\n# assert np.allclose(w1_val, w2_val), 'W1 == W2?'\r\n\r\nwith tf.GradientTape() as tape:\r\n    w3_init = tf.compat.v1.random_normal_initializer(mean=0., stddev=1., seed=3)\r\n    w3_val = w3_init(shape=[4,5], dtype=tf.float64)\r\n    w3_plus_one = w3_val + 1.\r\n\r\n# assert np.allclose(w1_val, w3_val), 'W1 == W3?'\r\n\r\nwith tf.GradientTape() as tape:\r\n    w4_init = tf.initializers.RandomNormal(mean=0., stddev=1., seed=3)\r\n    w4_val = w4_init(shape=[4,5], dtype=tf.float64)\r\n    w4_plus_one = w4_val + 1.\r\n\r\n# assert np.allclose(w2_val, w4_val), 'W2 == W4?'\r\n```\r\n\r\n**Describe the expected behavior**\r\n\r\nWe want `w1_val == w3_val` and `w2_val == w4_val`, then  reproducity can be ensured.\r\n\r\nDue to API version change, `w1_val != w2_val` can be accepted.\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no): no", "comments": ["@shishaochen ,\r\nWhile executing the given code i was not able to found any results which was mentioned in the issue.Please find the gist [here](https://colab.research.google.com/gist/tilakrayal/4bf4fc134b8c60bdb01f7e72e31fe791/untitled222.ipynb) and let us know if we are missing anything", "> @shishaochen , While executing the given code i was not able to found any results which was mentioned in the issue.Please find the gist [here](https://colab.research.google.com/gist/tilakrayal/4bf4fc134b8c60bdb01f7e72e31fe791/untitled222.ipynb) and let us know if we are missing anything\r\n\r\n@tilakrayal You need uncomment the last 2 assertions and the value inconsistency will occur.\r\n\r\nFor example, `w1` does not equal `w3`.\r\n![image](https://user-images.githubusercontent.com/17514649/153893171-0b0debde-da74-49f6-b892-75ce0eae49ed.png)\r\n", "I can confirm this bug and be a bit more precise: the random initializer is not deterministic (@shishaochen maybe you want to adjust the title accordingly?). Maybe this needs to be switched on?\r\n\r\nHere is a snipped, simply using the exact same random initializer (same input arguments and seed) yields completely different results.\r\n\r\nhttps://colab.research.google.com/drive/1tcX4WbsQgnv13OI2krdOPTY7t-1_ZVSa?usp=sharing\r\n\r\nThe code in plain text\r\n```\r\nimport tensorflow as tf\r\n\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\ndtype = tf.float64  # also for 32\r\nmean = 0.\r\nstddev = 1.\r\nseed = 3\r\nshape = [4,5]\r\n\r\nw1_init = tf.initializers.RandomNormal(mean=mean, stddev=stddev, seed=seed)\r\nw1_val = w1_init(shape=shape, dtype=dtype)\r\n\r\nw2_init = tf.initializers.RandomNormal(mean=mean, stddev=stddev, seed=seed)\r\nw2_val = w2_init(shape=shape, dtype=dtype)\r\n\r\n# print(w1_val, w2_val)\r\nprint('Difference', np.abs(w1_val - w2_val))\r\nassert np.allclose(w1_val, w2_val), 'W1 == W2?'\r\n\r\n```", "> I can confirm this bug and be a bit more precise: the random initializer is not deterministic (@shishaochen maybe you want to adjust the title accordingly?). Maybe this needs to be switched on?\r\n> \r\n> Here is a snipped, simply using the exact same random initializer (same input arguments and seed) yields completely different results.\r\n> \r\n> https://colab.research.google.com/drive/1tcX4WbsQgnv13OI2krdOPTY7t-1_ZVSa?usp=sharing\r\n> \r\n> The code in plain text\r\n> \r\n> ```\r\n> import tensorflow as tf\r\n> \r\n> import numpy as np\r\n> import tensorflow as tf\r\n> \r\n> dtype = tf.float64  # also for 32\r\n> mean = 0.\r\n> stddev = 1.\r\n> seed = 3\r\n> shape = [4,5]\r\n> \r\n> w1_init = tf.initializers.RandomNormal(mean=mean, stddev=stddev, seed=seed)\r\n> w1_val = w1_init(shape=shape, dtype=dtype)\r\n> \r\n> w2_init = tf.initializers.RandomNormal(mean=mean, stddev=stddev, seed=seed)\r\n> w2_val = w2_init(shape=shape, dtype=dtype)\r\n> \r\n> # print(w1_val, w2_val)\r\n> print('Difference', np.abs(w1_val - w2_val))\r\n> assert np.allclose(w1_val, w2_val), 'W1 == W2?'\r\n> ```\r\n\r\n@jonas-eschle There is no error when I execute your codes. My mentioned difference occurs between inisde GradientTape case and outside one.", " > @jonas-eschle There is no error when I execute your codes. My mentioned difference occurs between inisde GradientTape case and outside one.\r\n\r\nHm, that is weird, it does fail for me. I understand that you meant the case inside GradientTape, but I suspect to have found (weirdly) a more general bug. Did you check the [colab notebook I've linked](https://colab.research.google.com/drive/1tcX4WbsQgnv13OI2krdOPTY7t-1_ZVSa?usp=sharing)? It fails there, do you agree? So if it doesn't fail for you, which version are you using? Or am I missing something somewhere in my notebook snippet?\r\n", "@chunduriv ,\r\nI was able to reproduce the issue in tf v2.7, v2.8 and nightly.Please find the gist [here](https://colab.research.google.com/gist/tilakrayal/f9f93283accd1e1d65c07b3e87fd2b8c/54361.ipynb).", "> > @jonas-eschle There is no error when I execute your codes. My mentioned difference occurs between inisde GradientTape case and outside one.\r\n> \r\n> Hm, that is weird, it does fail for me. I understand that you meant the case inside GradientTape, but I suspect to have found (weirdly) a more general bug. Did you check the [colab notebook I've linked](https://colab.research.google.com/drive/1tcX4WbsQgnv13OI2krdOPTY7t-1_ZVSa?usp=sharing)? It fails there, do you agree? So if it doesn't fail for you, which version are you using? Or am I missing something somewhere in my notebook snippet?\r\n\r\n@jonas-eschle Your Tensorflow release of version `2.9.0-dev20220214` seems a private one?\r\nMy version is the official one `2.8.0`.", "\r\n> @jonas-eschle Your Tensorflow release of version `2.9.0-dev20220214` seems a private one? My version is the official one `2.8.0`.\r\n\r\nI've also tried with the 2.8, but the one 2.9.0-dev20220214 is the \"nightly\": that's the develop branch. Every night they create a package using the very newest version.\r\n\r\nSure, first thing is to check if it works with the official 2.8. But since that failed, it's good to also test against the nightlies, maybe the bug was just recently fixed.\r\n\r\nbtw, you see the version number is 2.9.something. So this is \"the next one\". dev indicates that it is the development version.\r\n\r\nTo install the nightlies, you can use `pip install tf-nightly` (just for testing purpose, you should not use this normally)", "@qlzh727", "This is working-as-intended. Both V1 and V2 (since 2.7) initializers are stateful objects. Calling the same initializer the second time will give different results.\r\n\r\nNote that V1 initializers are deprecated and have many problems. Please use V2 initializers.", "> This is working-as-intended. Both V1 and V2 (since 2.7) initializers are stateful objects. Calling the same initializer the second time will give different results.\r\n> \r\n> Note that V1 initializers are deprecated and have many problems. Please use V2 initializers.\r\n\r\n@wangpengmit If the initializer is stateful, the parameter `seed` seems useless\uff1fAs a result, reproducibility is not supported by TensorFlow which is enssial in scientific calculation.", "> If the initializer is stateful, the parameter seed seems useless\uff1f\r\n\r\nNo. `seed` determines the random-number *sequence* you'll get from an initializer. Two initializers sharing the same seed will give you the same sequence. (And different seeds lead to different sequences.)", "> > If the initializer is stateful, the parameter seed seems useless\uff1f\r\n> \r\n> No. `seed` determines the random-number _sequence_ you'll get from an initializer. Two initializers sharing the same seed will give you the same sequence. (And different seeds lead to different sequences.)\r\n\r\n@wangpengmit Yes, the seed determines the random number sequence.\r\nYou said \"Calling the same initializer the second time will give different results\". However, my code snippet (in the issue description) created 2 independent initializers with the same seed and they were called only once. Since the sequence was same, the first random numbers generated by these 2 initializers should be the same.", "You mean the failure of the `assert np.allclose(w2_val, w4_val), 'W2 == W4?'` assertion? Ah sorry I missed that part. It hits the same problem as https://github.com/keras-team/keras/issues/15586#issuecomment-966577975 . Basically a recent change of V2 initializers in TF2.7 to use `tf.random.uniform` etc caused a reproducibility regression (because `tf.random.uniform`'s weird kernel-reuse behaviors). It will be fixed in a future release by changing V2 initializers to use `tf.random.Generator` (or back to use `tf.random.stateless_*`). (@qlzh727)", "> You mean the failure of the `assert np.allclose(w2_val, w4_val), 'W2 == W4?'` assertion? Ah sorry I missed that part. It hits the same problem as [keras-team/keras#15586 (comment)](https://github.com/keras-team/keras/issues/15586#issuecomment-966577975) . Basically a recent change of V2 initializers in TF2.7 to use `tf.random.uniform` etc caused a reproducibility regression (because `tf.random.uniform`'s weird kernel-reused behaviors). It will be fixed in a future release by changing V2 initializers to use `tf.random.Generator` (or back to use `tf.random.stateless_*`). (@qlzh727)\r\n\r\nGot it! ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54361\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54361\">No</a>\n"]}, {"number": 54360, "title": "Document for tensorflow>=2.8 in wsl2 ?", "body": "## URL(s) with the issue:\r\n\r\nhttps://github.com/tensorflow/tensorflow/releases\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\nIs there any document for ```get start in wsl2``` since I notice the section\r\n```TensorFlow has been validated on Windows Subsystem for Linux 2 (aka WSL 2) for both GPUs and CPUs.``` ?\r\n\r\n", "comments": ["@DachuanZhao,\r\n\r\nExperimental support for WSL2 on Windows 10 19044 or higher with GPU access is now available. This corresponds to the most recent update of Windows 10 (aka version 21H2/November 2021 Update). You can get the latest update from here: [Download Windows 10](https://www.microsoft.com/en-us/software-download/windows10).\r\n\r\nFor instructions, please see [NVIDIA\u2019s setup docs](https://docs.nvidia.com/cuda/wsl-user-guide/index.html) for CUDA in WSL.Thanks!", "The WSL2 usage should be handled by Microsoft or other documentation. There is nothing special about TF for this.", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 54359, "title": "Machine learningNatural language processingNonlinear controlPattern", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\n\n**System information**\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\n- TensorFlow installed from (source or binary):\n- TensorFlow version:\n- Python version:\n- Installed using virtualenv? pip? conda?:\n- Bazel version (if compiling from source):\n- GCC/Compiler version (if compiling from source):\n- CUDA/cuDNN version:\n- GPU model and memory:\n\n\n\n**Describe the problem**\n\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\n\n\n**Any other info / logs**\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\n", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54359\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54359\">No</a>\n"]}]