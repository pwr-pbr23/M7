[{"number": 13046, "title": "tf.reduce_max inconsistent with numpy.max when handling NaN values", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04.3 LTS\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: v1.3.0-rc2-20-g0787eee 1.3.0\r\n- **Python version**: 3.5.2\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: 8.0 / 6.0\r\n- **GPU model and memory**: P100 (16GB)\r\n- **Exact command to reproduce**: [see below]\r\n\r\n### Describe the problem\r\nThe documentation for `tf.reduce_max` states that it is \"Equivalent to `np.max`\". This is not true when the provided `input_tensor` includes NaN values.\r\n\r\nTensorFlow ignores NaN values and returns inf (if present) or the largest finite value. Numpy will propagate NaN values in `np.max / np.amax` and has a special function `np.nanmax` for ignoring NaN values. (See the Notes section here: https://docs.scipy.org/doc/numpy/reference/generated/numpy.amax.html)\r\n\r\nExpected behavior is that `tf.reduce_max` returns NaN when its input includes NaN values.\r\n\r\n### Source code / logs\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\nvals = [float('1'), float('nan')]\r\n\r\nnp_max = np.max(vals)\r\ntf_max = tf.reduce_max(tf.constant(vals))\r\n\r\nwith tf.Session() as sess:\r\n    print('TF max: {}'.format(sess.run(tf_max)))\r\nprint('numpy max: {}'.format(np_max))\r\n```\r\nWhen run, this code produces the following output:\r\n```\r\nTF max: 1.0\r\nnumpy max: nan\r\n```", "comments": ["I think this issue is related to #12659", "Well-spotted -- I didn't turn up that issue in the search I did.\r\n\r\nReading through #12659, it looks like the issue is more subtle (and worse?) than what I've shown here -- NaNs are sometimes propagated and sometimes not, and it depends on the implementation you happen to get.", "Thanks, @yongtang. Let's close this issue in favor of #12659. "]}, {"number": 13045, "title": "Can I install and run TensorFlow on my machine with this much of information----->", "body": "C:\\Users\\SEM>python Python 3.5.2 (v3.5.2:4def2a2901a5, Jun 25 2016, 22:18:55) [MSC v.1900 64 bit (AMD64)] on win32 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>>", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 13044, "title": "Getting assertion failed: [Unable to decode bytes as JPEG, PNG, or GIF] when training using tensorflow object detection api", "body": "I tried to use `Tensorflow Object detection API` with my own dataset.   \r\nEverything was working just fine until all of a sudden it crashed with the following error messages :   \r\n\r\n    ...\r\n    INFO:tensorflow:global step 10560: loss = 0.4366 (0.809 sec/step)\r\n    INFO:tensorflow:global step 10561: loss = 0.3834 (0.822 sec/step)\r\n    INFO:tensorflow:global step 10562: loss = 0.3611 (0.829 sec/step)\r\n    INFO:tensorflow:global step 10563: loss = 0.3549 (0.901 sec/step)\r\n    INFO:tensorflow:global step 10564: loss = 0.3634 (0.839 sec/step)\r\n    INFO:tensorflow:global step 10565: loss = 0.3396 (0.813 sec/step)\r\n    INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, assertion failed: [Unable to decode bytes as JPEG, PNG, or GIF]\r\n             [[Node: case/If_0/decode_image/cond_jpeg/cond_png/Assert/Assert = Assert[T=[DT_STRING], summarize=3, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](case/If_0/decode_image/cond_jpeg/cond_png/is_gif, case/If_0/decode_image/cond_jpeg/cond_png/Assert/Assert/data_0)]]\r\n    INFO:tensorflow:global step 10566: loss = 0.3459 (0.889 sec/step)\r\n    INFO:tensorflow:Finished training! Saving model to disk.\r\n    Traceback (most recent call last):\r\n      File \"train.py\", line 198, in <module>\r\n        tf.app.run()\r\n      File \"C:\\Users\\Master\\Anaconda3\\envs\\anaconda35\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 48, in run\r\n        _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n      File \"train.py\", line 194, in main\r\n        worker_job_name, is_chief, FLAGS.train_dir)\r\n      File \"C:\\Users\\Master\\Anaconda3\\envs\\anaconda35\\lib\\site-packages\\object_detection-0.1-py3.5.egg\\object_detection\\trainer.py\", line 296, in train\r\n        saver=saver)\r\n      File \"C:\\Users\\Master\\Anaconda3\\envs\\anaconda35\\lib\\site-packages\\tensorflow\\contrib\\slim\\python\\slim\\learning.py\", line 759, in train\r\n        sv.saver.save(sess, sv.save_path, global_step=sv.global_step)\r\n      File \"C:\\Users\\Master\\Anaconda3\\envs\\anaconda35\\Lib\\contextlib.py\", line 66, in __exit__\r\n        next(self.gen)\r\n      File \"C:\\Users\\Master\\Anaconda3\\envs\\anaconda35\\lib\\site-packages\\tensorflow\\python\\training\\supervisor.py\", line 964, in managed_session\r\n        self.stop(close_summary_writer=close_summary_writer)\r\n      File \"C:\\Users\\Master\\Anaconda3\\envs\\anaconda35\\lib\\site-packages\\tensorflow\\python\\training\\supervisor.py\", line 792, in stop\r\n        stop_grace_period_secs=self._stop_grace_secs)\r\n      File \"C:\\Users\\Master\\Anaconda3\\envs\\anaconda35\\lib\\site-packages\\tensorflow\\python\\training\\coordinator.py\", line 389, in join\r\n        six.reraise(*self._exc_info_to_raise)\r\n      File \"C:\\Users\\Master\\Anaconda3\\envs\\anaconda35\\lib\\site-packages\\six.py\", line 686, in reraise\r\n        raise value\r\n      File \"C:\\Users\\Master\\Anaconda3\\envs\\anaconda35\\lib\\site-packages\\tensorflow\\python\\training\\queue_runner_impl.py\", line 238, in _run\r\n        enqueue_callable()\r\n      File \"C:\\Users\\Master\\Anaconda3\\envs\\anaconda35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1063, in _single_operation_run\r\n        target_list_as_strings, status, None)\r\n      File \"C:\\Users\\Master\\Anaconda3\\envs\\anaconda35\\Lib\\contextlib.py\", line 66, in __exit__\r\n        next(self.gen)\r\n      File \"C:\\Users\\Master\\Anaconda3\\envs\\anaconda35\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\", line 466, in raise_exception_on_not_ok_status\r\n        pywrap_tensorflow.TF_GetCode(status))\r\n    tensorflow.python.framework.errors_impl.InvalidArgumentError: assertion failed: [Unable to decode bytes as JPEG, PNG, or GIF]\r\n             [[Node: case/If_0/decode_image/cond_jpeg/cond_png/Assert/Assert = Assert[T=[DT_STRING], summarize=3, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](case/If_0/decode_image/cond_jpeg/cond_png/is_gif, case/If_0/decode_image/cond_jpeg/cond_png/Assert/Assert/data_0)]]\r\n    \r\n    G:\\Tensorflow_section\\models-master\\object_detection>\r\n\r\nWhen I upgraded to the `1.3.0`, the error has changed, and  this is what I get now:   \r\n\r\n    ...\r\n    INFO:tensorflow:global step 10635: loss = 0.3392 (0.822 sec/step)\r\n    INFO:tensorflow:global step 10636: loss = 0.3529 (0.823 sec/step)\r\n    INFO:tensorflow:global step 10637: loss = 0.3305 (0.831 sec/step)\r\n    2017-09-14 20:02:02.545415: W C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\35\\tensorflow\\core\\framework\\op_kernel.cc:1192] Invalid argument: Shape mismatch in tuple component 16. Expected [1,?,?,3], got [1,240,127,4]\r\n    INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, Shape mismatch in tuple component 16. Expected [1,?,?,3], got [1,240,127,4]\r\n             [[Node: batch/padding_fifo_queue_enqueue = QueueEnqueueV2[Tcomponents=[DT_STRING, DT_INT32, DT_FLOAT, DT_INT32, DT_FLOAT, DT_INT32, DT_INT64, DT_INT32, DT_INT64, DT_INT32, DT_INT64, DT_INT32, DT_BOOL, DT_INT32, DT_BOOL, DT_INT32, DT_FLOAT, DT_INT32, DT_STRING, DT_INT32, DT_STRING, DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](batch/padding_fifo_queue, Reshape_2, Shape_5, SparseToDense_1, Shape_2, Merge_1, Shape, Merge_2, Shape_3, SparseToDense_5, Shape_8, SparseToDense_3, Shape_6, Cast_1, Shape_1, Cast_2, Shape_7, ExpandDims_5, Shape_4, Reshape_5, Shape_10, Reshape_6, Shape_9)]]\r\n    INFO:tensorflow:global step 10638: loss = 0.3599 (0.858 sec/step)\r\n    INFO:tensorflow:Finished training! Saving model to disk.\r\n    Traceback (most recent call last):\r\n      File \"train.py\", line 198, in <module>\r\n        tf.app.run()\r\n      File \"C:\\Users\\Master\\Anaconda3\\envs\\anaconda35\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 48, in run\r\n        _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n      File \"train.py\", line 194, in main\r\n        worker_job_name, is_chief, FLAGS.train_dir)\r\n      File \"C:\\Users\\Master\\Anaconda3\\envs\\anaconda35\\lib\\site-packages\\object_detection-0.1-py3.5.egg\\object_detection\\trainer.py\", line 296, in train\r\n        saver=saver)\r\n      File \"C:\\Users\\Master\\Anaconda3\\envs\\anaconda35\\lib\\site-packages\\tensorflow\\contrib\\slim\\python\\slim\\learning.py\", line 767, in train\r\n        sv.stop(threads, close_summary_writer=True)\r\n      File \"C:\\Users\\Master\\Anaconda3\\envs\\anaconda35\\lib\\site-packages\\tensorflow\\python\\training\\supervisor.py\", line 792, in stop\r\n        stop_grace_period_secs=self._stop_grace_secs)\r\n      File \"C:\\Users\\Master\\Anaconda3\\envs\\anaconda35\\lib\\site-packages\\tensorflow\\python\\training\\coordinator.py\", line 389, in join\r\n        six.reraise(*self._exc_info_to_raise)\r\n      File \"C:\\Users\\Master\\Anaconda3\\envs\\anaconda35\\lib\\site-packages\\six.py\", line 686, in reraise\r\n        raise value\r\n      File \"C:\\Users\\Master\\Anaconda3\\envs\\anaconda35\\lib\\site-packages\\tensorflow\\python\\training\\queue_runner_impl.py\", line 238, in _run\r\n        enqueue_callable()\r\n      File \"C:\\Users\\Master\\Anaconda3\\envs\\anaconda35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1235, in _single_operation_run\r\n        target_list_as_strings, status, None)\r\n      File \"C:\\Users\\Master\\Anaconda3\\envs\\anaconda35\\Lib\\contextlib.py\", line 66, in __exit__\r\n        next(self.gen)\r\n      File \"C:\\Users\\Master\\Anaconda3\\envs\\anaconda35\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\", line 466, in raise_exception_on_not_ok_status\r\n        pywrap_tensorflow.TF_GetCode(status))\r\n    tensorflow.python.framework.errors_impl.InvalidArgumentError: Shape mismatch in tuple component 16. Expected [1,?,?,3], got [1,240,127,4]\r\n             [[Node: batch/padding_fifo_queue_enqueue = QueueEnqueueV2[Tcomponents=[DT_STRING, DT_INT32, DT_FLOAT, DT_INT32, DT_FLOAT, DT_INT32, DT_INT64, DT_INT32, DT_INT64, DT_INT32, DT_INT64, DT_INT32, DT_BOOL, DT_INT32, DT_BOOL, DT_INT32, DT_FLOAT, DT_INT32, DT_STRING, DT_INT32, DT_STRING, DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](batch/padding_fifo_queue, Reshape_2, Shape_5, SparseToDense_1, Shape_2, Merge_1, Shape, Merge_2, Shape_3, SparseToDense_5, Shape_8, SparseToDense_3, Shape_6, Cast_1, Shape_1, Cast_2, Shape_7, ExpandDims_5, Shape_4, Reshape_5, Shape_10, Reshape_6, Shape_9)]]\r\n    \r\n    G:\\Tensorflow_section\\models-master\\object_detection>\r\n\r\nI have no idea what is causing the issue, Could this be that some images have wrong extensions? for example, an image which was actually a png with 4 channels, has been saved as a jpg ?!\r\nif this is the case, how to spot the faulty image file? or even better why does not TF use the correct type/number of channels by itself? \r\nright now, the error is not descriptive enough, it doesn't give any hint which image file is corrupted or is making the problem. \r\nif the cause of these errors is what I pointed out earlier, then they should be caught when the TF Record is being created. or if TF records are not the only means of inputs, then the same mechanism for knowing the culprit needs to be implemented as well\r\nAnyway, if all my thoughts are wrong, then I would appreciate any help regarding this issue. \r\n \r\n\r\n\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10 x64 1703, Build 15063.540\r\n- **TensorFlow installed from (source or binary)**:binary (used pip install )\r\n- **TensorFlow version (use command below)**: 1.2.1 and 1.3.0\r\n- **Python version**: 3.5.3(Anaconda)\r\n- **Bazel version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: Cuda 8.0 /cudnn v5.1 and v6.0 (after upgrading to 1.3.0, cudnnv6.0 is in the PATH)\r\n- **GPU model and memory**: GTX-1080 - 8G\r\n", "comments": ["I recheck all the images for mismatched extensions and the actual type of the image and fixed them all.\r\nAfter recreating the TFRecords and retraining again I am faced with these errors: \r\n```\r\nINFO:tensorflow:global step 1334: loss = 0.4126 (1.323 sec/step)\r\nINFO:tensorflow:global step 1335: loss = 0.6324 (1.341 sec/step)\r\n2017-09-15 21:08:58.766691: W C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\35\\tensorflow\\core\\framework\\op_kernel.cc:1192] Invalid argument: Shape mismatch in tuple component 16. Expected [1,?,?,3], got [1,157,80,4]\r\nINFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, Shape mismatch in tuple component 16. Expected [1,?,?,3], got [1,157,80,4]\r\n         [[Node: batch/padding_fifo_queue_enqueue = QueueEnqueueV2[Tcomponents=[DT_STRING, DT_INT32, DT_FLOAT, DT_INT32, DT_FLOAT, DT_INT32, DT_INT64, DT_INT32, DT_INT64, DT_INT32, DT_INT64, DT_INT32, DT_BOOL, DT_INT32, DT_BOOL, DT_INT32, DT_FLOAT, DT_INT32, DT_STRING, DT_INT32, DT_STRING, DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](batch/padding_fifo_queue, Reshape_2, Shape_1, SparseToDense_4, Shape_10, Merge_1, Shape_9, Merge_2, Shape_8, SparseToDense_3, Shape_6, SparseToDense, Shape_5, Cast_1, Shape_7, Cast_2, Shape_3, ExpandDims_5, Shape_4, Reshape_5, Shape, Reshape_6, Shape_2)]]\r\nINFO:tensorflow:global step 1336: loss = 0.4120 (1.394 sec/step)\r\nINFO:tensorflow:Finished training! Saving model to disk.\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 198, in <module>\r\n    tf.app.run()\r\n  File \"C:\\Users\\Master\\Anaconda3\\envs\\anaconda35\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 48, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"train.py\", line 194, in main\r\n    worker_job_name, is_chief, FLAGS.train_dir)\r\n  File \"C:\\Users\\Master\\Anaconda3\\envs\\anaconda35\\lib\\site-packages\\object_detection-0.1-py3.5.egg\\object_detection\\trainer.py\", line 296, in train\r\n    saver=saver)\r\n  File \"C:\\Users\\Master\\Anaconda3\\envs\\anaconda35\\lib\\site-packages\\tensorflow\\contrib\\slim\\python\\slim\\learning.py\", line 767, in train\r\n    sv.stop(threads, close_summary_writer=True)\r\n  File \"C:\\Users\\Master\\Anaconda3\\envs\\anaconda35\\lib\\site-packages\\tensorflow\\python\\training\\supervisor.py\", line 792, in stop\r\n    stop_grace_period_secs=self._stop_grace_secs)\r\n  File \"C:\\Users\\Master\\Anaconda3\\envs\\anaconda35\\lib\\site-packages\\tensorflow\\python\\training\\coordinator.py\", line 389, in join\r\n    six.reraise(*self._exc_info_to_raise)\r\n  File \"C:\\Users\\Master\\Anaconda3\\envs\\anaconda35\\lib\\site-packages\\six.py\", line 686, in reraise\r\n    raise value\r\n  File \"C:\\Users\\Master\\Anaconda3\\envs\\anaconda35\\lib\\site-packages\\tensorflow\\python\\training\\queue_runner_impl.py\", line 238, in _run\r\n    enqueue_callable()\r\n  File \"C:\\Users\\Master\\Anaconda3\\envs\\anaconda35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1235, in _single_operation_run\r\n    target_list_as_strings, status, None)\r\n  File \"C:\\Users\\Master\\Anaconda3\\envs\\anaconda35\\Lib\\contextlib.py\", line 66, in __exit__\r\n    next(self.gen)\r\n  File \"C:\\Users\\Master\\Anaconda3\\envs\\anaconda35\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\", line 466, in raise_exception_on_not_ok_status\r\n    pywrap_tensorflow.TF_GetCode(status))\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Shape mismatch in tuple component 16. Expected [1,?,?,3], got [1,157,80,4]\r\n         [[Node: batch/padding_fifo_queue_enqueue = QueueEnqueueV2[Tcomponents=[DT_STRING, DT_INT32, DT_FLOAT, DT_INT32, DT_FLOAT, DT_INT32, DT_INT64, DT_INT32, DT_INT64, DT_INT32, DT_INT64, DT_INT32, DT_BOOL, DT_INT32, DT_BOOL, DT_INT32, DT_FLOAT, DT_INT32, DT_STRING, DT_INT32, DT_STRING, DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](batch/padding_fifo_queue, Reshape_2, Shape_1, SparseToDense_4, Shape_10, Merge_1, Shape_9, Merge_2, Shape_8, SparseToDense_3, Shape_6, SparseToDense, Shape_5, Cast_1, Shape_7, Cast_2, Shape_3, ExpandDims_5, Shape_4, Reshape_5, Shape, Reshape_6, Shape_2)]]\r\n\r\n```\r\nThis is getting really annoying! \r\nI fixed what I thought could be the issue here, and yet this pops up. any feedback on this issue is greatly appreciated. ", "This doesn't seem like it's necessarily a bug in the object detection code. I agree that the error message about Tensor shapes: \"Expected [1,?,?,3], got [1,157,80,4]\" suggests that the API is looking for RGB input data but something in your input data is somehow being decoded into depth-4, rather than depth-3. \r\nYou do say that you're using your own input data. Can you add checks about the cleanliness of your input dataset? \r\n\r\nI think in many ways, this question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!", "@cy89 : Thank you very much for your attention, \r\nBut thats what I did and thats why I think there is a need for better error messages. If there is an issue in the input, this must be caught when a tfrecord is being created.\r\nI have checked multiple times that my images are consistent i.e a png is indeed a png and not mistakenly saved as a jpg or vice versa and also their correct depth is retrieved and used. \r\nI checked all image headers for such discrepancies and fixed them. yet I get this error. \r\nhere is the code I used to check each image and retrieve its true type: \r\n```\r\nprivate string IsImage(Stream stream)\r\n{\r\n\tstring jpg = \"FFD8\";\r\n\tstring bmp = \"424D\" ;\r\n\tstring gif = \"474946\" ;\r\n\tstring png = \"89504E470D0A1A0A\" ;\r\n\tstring sig = \"\";\r\n\r\n\tstream.Seek(0, SeekOrigin.Begin);\r\n\tfor (int i = 0; i < 8; i++)\r\n\t{\r\n\t\tsig += stream.ReadByte().ToString(\"X2\");\r\n\t\tif (sig.Length == 4 && sig == jpg)\r\n\t\t{\r\n\t\t\tsig = \"jpg\";\r\n\t\t\tbreak;\r\n\t\t}\r\n\t\telse if(sig.Length == 4 && sig == bmp)\r\n\t\t{\r\n\t\t\tsig = \"bmp\";\r\n\t\t\tbreak;\r\n\t\t}\r\n\t\telse if (sig.Length == 6 && sig == gif)\r\n\t\t{\r\n\t\t\tsig = \"gif\";\r\n\t\t\tbreak;\r\n\t\t}\r\n\t\telse if (sig.Length == 16 && sig == png)\r\n\t\t{\r\n\t\t\tsig = \"png\";\r\n\t\t\tbreak;\r\n\t\t}\r\n\t}\r\n\treturn sig;\r\n}\r\n\r\n```\r\nAnd for image depth( # of channels) I used OpenCV (EmguCV). \r\n\r\nI don't know what else I was supposed to do that I have not done already. that's why it strikes me as a bug or if its not a bug, its clear that error message is not helping at all and more information needs to be disclosed. \r\nyet better, all input related checks need to be done at the time of creating the dataset (i.e. tfrecords for easier error handling or trouble shooting!) \r\nright now I'm clueless and I have no idea where to dig in! ", "I rescanned 280K images of mine. There is no image with the shape of what is being reported in the error message!", "@Coderx7 Thanks for checking. Those look like entirely reasonable checks on your input data set.\r\n\r\nThe kinds of checks that you're asking for seem like reasonable feature requests. I can't speak for the object detection team about whether they have time to do that kind of work. @tombstone, can you comment? \r\n\r\nIn the meantime, I'll mark this as \"contributions welcome\". ", "I tried two more scenarios,\r\nI randomly selected 10K images from the existing 300K images and ran the training again.(re-annotated each image,created new tfrecords and ran the training). still the same error ,\r\nand I need to add that, there is not a single image with the depth of 4, nor the dimensions reported in this and former error messages exist. \r\nHere is the error message : \r\n```\r\nINFO:tensorflow:global step 2310: loss = 0.5332 (0.459 sec/step)\r\nINFO:tensorflow:global step 2311: loss = 0.3647 (0.444 sec/step)\r\nINFO:tensorflow:global step 2312: loss = 0.5550 (0.447 sec/step)\r\n2017-09-17 12:42:02.975898: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: Shape mismatch in tuple component 16. Expected [1,?,?,3], got [1,256,341,4]\r\nINFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, Shape mismatch in tuple component 16. Expected [1,?,?,3], got [1,256,341,4]\r\n\t [[Node: batch/padding_fifo_queue_enqueue = QueueEnqueueV2[Tcomponents=[DT_STRING, DT_INT32, DT_FLOAT, DT_INT32, DT_FLOAT, DT_INT32, DT_INT64, DT_INT32, DT_INT64, DT_INT32, DT_INT64, DT_INT32, DT_BOOL, DT_INT32, DT_BOOL, DT_INT32, DT_FLOAT, DT_INT32, DT_STRING, DT_INT32, DT_STRING, DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](batch/padding_fifo_queue, Reshape_2, Shape_7, SparseToDense_4, Shape_9, Merge_1, Shape_1, Merge_2, Shape_4, SparseToDense_1, Shape_10, SparseToDense_2, Shape_6, Cast_1, Shape_3, Cast_2, Shape_8, ExpandDims_5, Shape_2, Reshape_5, Shape, Reshape_6, Shape_5)]]\r\nINFO:tensorflow:global step 2313: loss = 0.5081 (0.481 sec/step)\r\nINFO:tensorflow:Finished training! Saving model to disk.\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 195, in <module>\r\n    tf.app.run()\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/app.py\", line 48, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"train.py\", line 191, in main\r\n    worker_job_name, is_chief, FLAGS.train_dir)\r\n  File \"/media/hossein/tmpstore/models-master/object_detection/trainer.py\", line 296, in train\r\n    saver=saver)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/slim/python/slim/learning.py\", line 767, in train\r\n    sv.stop(threads, close_summary_writer=True)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/supervisor.py\", line 792, in stop\r\n    stop_grace_period_secs=self._stop_grace_secs)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/coordinator.py\", line 389, in join\r\n    six.reraise(*self._exc_info_to_raise)\r\n  File \"/usr/local/lib/python3.5/dist-packages/six.py\", line 686, in reraise\r\n    raise value\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/queue_runner_impl.py\", line 238, in _run\r\n    enqueue_callable()\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1235, in _single_operation_run\r\n    target_list_as_strings, status, None)\r\n  File \"/usr/lib/python3.5/contextlib.py\", line 66, in __exit__\r\n    next(self.gen)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\", line 466, in raise_exception_on_not_ok_status\r\n    pywrap_tensorflow.TF_GetCode(status))\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Shape mismatch in tuple component 16. Expected [1,?,?,3], got [1,256,341,4]\r\n\t [[Node: batch/padding_fifo_queue_enqueue = QueueEnqueueV2[Tcomponents=[DT_STRING, DT_INT32, DT_FLOAT, DT_INT32, DT_FLOAT, DT_INT32, DT_INT64, DT_INT32, DT_INT64, DT_INT32, DT_INT64, DT_INT32, DT_BOOL, DT_INT32, DT_BOOL, DT_INT32, DT_FLOAT, DT_INT32, DT_STRING, DT_INT32, DT_STRING, DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](batch/padding_fifo_queue, Reshape_2, Shape_7, SparseToDense_4, Shape_9, Merge_1, Shape_1, Merge_2, Shape_4, SparseToDense_1, Shape_10, SparseToDense_2, Shape_6, Cast_1, Shape_3, Cast_2, Shape_8, ExpandDims_5, Shape_2, Reshape_5, Shape, Reshape_6, Shape_5)]]\r\n(tensorflow_vp3) hossein@hossein-pc:/media/hossein/tmpstore/models-master/object_detection$ \r\n\r\n```\r\nAnd by the way this is the config file\r\n```\r\n# SSD with Mobilenet v1, configured for Oxford-IIIT Pets Dataset.\r\n# Users should configure the fine_tune_checkpoint field in the train config as\r\n# well as the label_map_path and input_path fields in the train_input_reader and\r\n# eval_input_reader. Search for \"PATH_TO_BE_CONFIGURED\" to find the fields that\r\n# should be configured.\r\n\r\nmodel {\r\n  ssd {\r\n    num_classes: 2\r\n    box_coder {\r\n      faster_rcnn_box_coder {\r\n        y_scale: 10.0\r\n        x_scale: 10.0\r\n        height_scale: 5.0\r\n        width_scale: 5.0\r\n      }\r\n    }\r\n    matcher {\r\n      argmax_matcher {\r\n        matched_threshold: 0.5\r\n        unmatched_threshold: 0.5\r\n        ignore_thresholds: false\r\n        negatives_lower_than_unmatched: true\r\n        force_match_for_each_row: true\r\n      }\r\n    }\r\n    similarity_calculator {\r\n      iou_similarity {\r\n      }\r\n    }\r\n    anchor_generator {\r\n      ssd_anchor_generator {\r\n        num_layers: 6\r\n        min_scale: 0.2\r\n        max_scale: 0.95\r\n        aspect_ratios: 1.0\r\n        aspect_ratios: 2.0\r\n        aspect_ratios: 0.5\r\n        aspect_ratios: 3.0\r\n        aspect_ratios: 0.3333\r\n      }\r\n    }\r\n    image_resizer {\r\n      fixed_shape_resizer {\r\n        height: 300\r\n        width: 300\r\n      }\r\n    }\r\n    box_predictor {\r\n      convolutional_box_predictor {\r\n        min_depth: 0\r\n        max_depth: 0\r\n        num_layers_before_predictor: 0\r\n        use_dropout: false\r\n        dropout_keep_probability: 0.8\r\n        kernel_size: 1\r\n        box_code_size: 4\r\n        apply_sigmoid_to_scores: false\r\n        conv_hyperparams {\r\n          activation: RELU_6,\r\n          regularizer {\r\n            l2_regularizer {\r\n              weight: 0.00004\r\n            }\r\n          }\r\n          initializer {\r\n            truncated_normal_initializer {\r\n              stddev: 0.03\r\n              mean: 0.0\r\n            }\r\n          }\r\n          batch_norm {\r\n            train: true,\r\n            scale: true,\r\n            center: true,\r\n            decay: 0.9997,\r\n            epsilon: 0.001,\r\n          }\r\n        }\r\n      }\r\n    }\r\n    feature_extractor {\r\n      type: 'ssd_mobilenet_v1'\r\n      min_depth: 16\r\n      depth_multiplier: 1.0\r\n      conv_hyperparams {\r\n        activation: RELU_6,\r\n        regularizer {\r\n          l2_regularizer {\r\n            weight: 0.00004\r\n          }\r\n        }\r\n        initializer {\r\n          truncated_normal_initializer {\r\n            stddev: 0.03\r\n            mean: 0.0\r\n          }\r\n        }\r\n        batch_norm {\r\n          train: true,\r\n          scale: true,\r\n          center: true,\r\n          decay: 0.9997,\r\n          epsilon: 0.001,\r\n        }\r\n      }\r\n    }\r\n    loss {\r\n      classification_loss {\r\n        weighted_sigmoid {\r\n          anchorwise_output: true\r\n        }\r\n      }\r\n      localization_loss {\r\n        weighted_smooth_l1 {\r\n          anchorwise_output: true\r\n        }\r\n      }\r\n      hard_example_miner {\r\n        num_hard_examples: 3000\r\n        iou_threshold: 0.99\r\n        loss_type: CLASSIFICATION\r\n        max_negatives_per_positive: 3\r\n        min_negatives_per_image: 0\r\n      }\r\n      classification_weight: 1.0\r\n      localization_weight: 1.0\r\n    }\r\n    normalize_loss_by_num_matches: true\r\n    post_processing {\r\n      batch_non_max_suppression {\r\n        score_threshold: 1e-8\r\n        iou_threshold: 0.6\r\n        max_detections_per_class: 100\r\n        max_total_detections: 100\r\n      }\r\n      score_converter: SIGMOID\r\n    }\r\n  }\r\n}\r\n\r\ntrain_config: {\r\n  batch_size: 24\r\n  optimizer {\r\n    rms_prop_optimizer: {\r\n      learning_rate: {\r\n        exponential_decay_learning_rate {\r\n          initial_learning_rate: 0.004\r\n          decay_steps: 800720\r\n          decay_factor: 0.95\r\n        }\r\n      }\r\n      momentum_optimizer_value: 0.9\r\n      decay: 0.9\r\n      epsilon: 1.0\r\n    }\r\n  }\r\n  fine_tune_checkpoint: \"ssd_mobilenet_v1_coco_11_06_2017/model.ckpt\"\r\n  from_detection_checkpoint: true\r\n  # Note: The below line limits the training process to 200K steps, which we\r\n  # empirically found to be sufficient enough to train the pets dataset. This\r\n  # effectively bypasses the learning rate schedule (the learning rate will\r\n  # never decay). Remove the below line to train indefinitely.\r\n  num_steps: 200000\r\n  data_augmentation_options {\r\n    random_horizontal_flip {\r\n    }\r\n  }\r\n  data_augmentation_options {\r\n    ssd_random_crop {\r\n    }\r\n  }\r\n}\r\n\r\ntrain_input_reader: {\r\n  tf_record_input_reader {\r\n    input_path: \"train.record\"\r\n  }\r\n  label_map_path: \"obj_detection_label_map.pbtxt\"\r\n}\r\n\r\neval_config: {\r\n  num_examples: 101\r\n  # Note: The below line limits the evaluation process to 10 evaluations.\r\n  # Remove the below line to evaluate indefinitely.\r\n  max_evals: 10\r\n}\r\n\r\neval_input_reader: {\r\n  tf_record_input_reader {\r\n    input_path: \"test.record\"\r\n  }\r\n  label_map_path: \"obj_detection_label_map.pbtxt\"\r\n  shuffle: false\r\n  num_readers: 1\r\n}\r\n```\r\nAny idea how I myself can dig and find the culprit to this? I'd be greatful if anyone could suggest even a slight thing to do. I'm out of options here!", "OK , Thanks to God, I could finally figure out what the issue was. \r\nit seems in creating TFRecords, only jpeg images are supported and no where in the documentation this is indicated! also when you try to use other types, it does not issue any warnings or doesn't through any exceptions and therefore people like me lose an immense amount of time debugging something that could be easily spotted and fixed in first place. \r\nAnyway, converting all images to `jpg `solved this weird hellbound issue.\r\n", "@Coderx7 we need more heroes like you :) ", "@Coderx7  I also make a mistake with jpg. What's the matter", "I received the same error while attempting to obtain online prediction from gcloud ml-engine deployed model. Yet, just like the above commenter, the test image is a JPEG. \r\n\r\nMy TF is version 1.6 and model version runtime was set to 1.4. When I set runtime to 1.6 I instead get the following error: \r\n\r\n`...AbortionError(code=StatusC\r\node.INVALID_ARGUMENT, details=\\\"NodeDef mentions attr 'dilations' not in Op<name=Conv2D\r\n; signature=input:T...`\r\n\r\nResolution urgently needed, please.", "@guandeng  I get this error too!", "Interesting, I've just bumped into this as well... fully jpg converted dataset. Will update if I resolve.", "I wasn't able to figure out to fix it, but my way around it was to convert my images/annotations to this format and use this [script](https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10/blob/master/generate_tfrecord.py)  ", "Ah yeah, thanks for the tip. I ended up adapting [this rad tool](https://github.com/visipedia/tfrecords) to suit my dataset.", "Oh, Sometimes training or testing data mix of JPEG and PNG format image. You can try this:\r\n\r\n```\r\n    def _parse_function(filename):\r\n         image_string = tf.read_file(filename)\r\n         image_decoded = tf.cond(\r\n             tf.image.is_jpeg(image_string),\r\n             lambda: tf.image.decode_jpeg(image_string, channels=3),\r\n             lambda: tf.image.decode_png(image_string, channels=3))\r\n         image_resized = tf.image.resize_images(image_decoded, [90, 90])\r\n    return image_resized\r\n    \r\n    filenames = [\"/var/data/image1.jpg\", \"/var/data/image2.jpg\", ...]\r\n    labels = [0, 37, 29, 1, ...]\r\n    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\r\n    dataset = dataset.map(_parse_function)\r\n    dataset = dataset.batch(batch_size)\r\n    iterator = dataset.make_one_shot_iterator()\r\n```\r\n", "There's a simple way I fixed this using imghdr and OpenCV. In my case, all the image files had the extension of '.jpg', but some of these extensions were invalid.  After running this code, regenerate your tf record file and you should be good to go.\r\n```        import cv2    \r\n        import imghdr     \r\n        for file in image_file_list:    \r\n            image = cv2.imread(file)\r\n            file_type = imghdr.what(file)  \r\n            if file_type != 'jpeg':  \r\n                print(file +  \" - invalid - \" +  str(file_type))  \r\n                cv2.imwrite(file, image)```", "Closing as this resolved", "> There's a simple way I fixed this using imghdr and OpenCV. In my case, all the image files had the extension of '.jpg', but some of these extensions were invalid. After running this code, regenerate your tf record file and you should be good to go.\r\n> \r\n> ```\r\n>         import imghdr     \r\n>         for file in image_file_list:    \r\n>             image = cv2.imread(file)\r\n>             file_type = imghdr.what(file)  \r\n>             if file_type != 'jpeg':  \r\n>                 print(file +  \" - invalid - \" +  str(file_type))  \r\n>                 cv2.imwrite(file, image)```\r\n> ```\r\n\r\nHi, where will I run this code? thanks :)", "For those who are still having trouble, that is because some of the stupid files disguised themselves as jpg but are not actually jpeg. Create a python file and copy this code(modified from above). (Change the directories if you need to.) This program will pick out files that are not actually jpeg. Delete them then you are good to go.\r\n\"\"\"import imghdr\r\nimport cv2\r\nimport os\r\nimport glob\r\n\r\nfor folder in ['train', 'test']:\r\n    image_path = os.path.join(os.getcwd(), ('images/' + folder))\r\n    print(image_path)\r\n    for file in glob.glob(image_path + '/*.jpg'):\r\n        image = cv2.imread(file)\r\n        file_type = imghdr.what(file)\r\n        if file_type != 'jpeg':\r\n            print(file + \" - invalid - \" + str(file_type))\r\n            # cv2.imwrite(file, image)\r\n\"\"\"", "\r\nAn assumption I had when working on this was that sending scipy image data was reasonable - this is not the case. Trying to pass a numpy/scipy array will fail. Where as reading the file directly as a jpeg seems to keep whatever magic bytes are needed and it works. Hopefully this helps someone as this was pretty tough to debug.", "@Coderx7 comment gave me an idea to solve my problem. At first I was encoding the image with base64 which didn't help at all. So, i referenced this [link](https://github.com/visipedia/tfrecords/blob/master/create_tfrecords.py)\r\nThe main takeaway functions and class are \r\n\r\n- ImageCoder\r\n\r\n- _is_png\r\n\r\n- _process_image\r\n\r\nuse these and implement in your code.", "> \u597d\u7684\uff0c\u611f\u8c22\u4e0a\u5e1d\uff0c\u6211\u7ec8\u4e8e\u53ef\u4ee5\u5f04\u6e05\u695a\u95ee\u9898\u51fa\u5728\u54ea\u91cc\u3002\r\n> \u4f3c\u4e4e\u5728\u521b\u5efaTFRecords\u65f6\uff0c\u4ec5\u652f\u6301jpeg\u56fe\u50cf\uff0c\u800c\u5728\u6587\u6863\u4e2d\u6ca1\u6709\u6b64\u6307\u793a\uff01\u540c\u6837\uff0c\u5f53\u60a8\u5c1d\u8bd5\u4f7f\u7528\u5176\u4ed6\u7c7b\u578b\u65f6\uff0c\u5b83\u4e0d\u4f1a\u53d1\u51fa\u4efb\u4f55\u8b66\u544a\uff0c\u4e5f\u4e0d\u4f1a\u51fa\u73b0\u4efb\u4f55\u5f02\u5e38\uff0c\u56e0\u6b64\u50cf\u6211\u8fd9\u6837\u7684\u4eba\u4f1a\u6d6a\u8d39\u5927\u91cf\u7684\u65f6\u95f4\u6765\u8c03\u8bd5\u4e00\u4e9b\u5f88\u5bb9\u6613\u53d1\u73b0\u5e76\u9996\u5148\u89e3\u51b3\u7684\u95ee\u9898\u3002\r\n> \u65e0\u8bba\u5982\u4f55\uff0c\u5c06\u6240\u6709\u56fe\u50cf\u8f6c\u6362\u4e3a`jpg `\u53ef\u89e3\u51b3\u6b64\u602a\u5f02\u7684\u5730\u72f1\u95ee\u9898\u3002\r\n\r\n\r\n\r\n> OK , Thanks to God, I could finally figure out what the issue was.\r\n> it seems in creating TFRecords, only jpeg images are supported and no where in the documentation this is indicated! also when you try to use other types, it does not issue any warnings or doesn't through any exceptions and therefore people like me lose an immense amount of time debugging something that could be easily spotted and fixed in first place.\r\n> Anyway, converting all images to `jpg `solved this weird hellbound issue.\r\n\r\nHello, excuse me, why is JPEG on the top and. JPG on the bottom? The picture used in my project is. JPG running error is\"Invalid argument: assertion failed: [Unable to decode bytes as JPEG, PNG, GIF, or BMP]\".Why?\r\n", "I have got the solution, images to be trained must be in dimension of 960x540, convert all the images in dataset to such resolution and then try. My issue is resolved by doing this.\r\n\r\n\r\nimport os, sys\r\nimport cv2\r\n# Open a file\r\npath = \"C:/Tensorflow1/images_to_resize/images/train/\"\r\ndirs = os.listdir( path )\r\n\r\n# This would would write all the images in directory to 960x540\r\nfor file in dirs:\r\n    read = cv2.imread(path+'/'+file)\r\n    read_resize = cv2.resize(read,(960,540))\r\n    #cv2.imshow(file,read_resize)\r\n    cv2.imwrite(\"C:/Tensorflow1/images_to_resize/resized/train/\"+file,read_resize)\r\n    print('done')\r\n\r\n", "> OK , Thanks to God, I could finally figure out what the issue was.\r\n> it seems in creating TFRecords, only jpeg images are supported and no where in the documentation this is indicated! also when you try to use other types, it does not issue any warnings or doesn't through any exceptions and therefore people like me lose an immense amount of time debugging something that could be easily spotted and fixed in first place.\r\n> Anyway, converting all images to `jpg `solved this weird hellbound issue.\r\n\r\nhow can i change the image type", "> OK , Thanks to God, I could finally figure out what the issue was.\r\n> it seems in creating TFRecords, only jpeg images are supported and no where in the documentation this is indicated! also when you try to use other types, it does not issue any warnings or doesn't through any exceptions and therefore people like me lose an immense amount of time debugging something that could be easily spotted and fixed in first place.\r\n> Anyway, converting all images to `jpg `solved this weird hellbound issue.\r\n\r\nI don't no how did you solve this issue. But you are HERO . Big thanks. ", "> There's a simple way I fixed this using imghdr and OpenCV. In my case, all the image files had the extension of '.jpg', but some of these extensions were invalid. After running this code, regenerate your tf record file and you should be good to go.\r\n> \r\n> ```\r\n>         import imghdr     \r\n>         for file in image_file_list:    \r\n>             image = cv2.imread(file)\r\n>             file_type = imghdr.what(file)  \r\n>             if file_type != 'jpeg':  \r\n>                 print(file +  \" - invalid - \" +  str(file_type))  \r\n>                 cv2.imwrite(file, image)```\r\n> ```\r\n\r\nThanks, this Solved my issue.", "Hello everyone, I have all my images in jpeg format and I resized all of them as @AsadAhmed361 suggested, but I still get the same error:\r\n`tensorflow.python.framework.errors_impl.InvalidArgumentError: {{function_node Dataset_map_TfExampleDecoder.decode_56}} assertion failed: [Unable to decode bytes as JPEG, PNG, GIF, or BMP]\r\n         [[{{node case/cond/cond_jpeg/decode_image/cond_jpeg/cond_png/cond_gif/Assert_1/Assert}}]]\r\n         [[IteratorGetNext]]`\r\ncan anyone help please?", "> There's a simple way I fixed this using imghdr and OpenCV. In my case, all the image files had the extension of '.jpg', but some of these extensions were invalid. After running this code, regenerate your tf record file and you should be good to go.\r\n> \r\n> ```\r\n>         import imghdr     \r\n>         for file in image_file_list:    \r\n>             image = cv2.imread(file)\r\n>             file_type = imghdr.what(file)  \r\n>             if file_type != 'jpeg':  \r\n>                 print(file +  \" - invalid - \" +  str(file_type))  \r\n>                 cv2.imwrite(file, image)```\r\n> ```\r\n\r\ndid you add these lines in the generate_tfrecord.py ?"]}, {"number": 13043, "title": "Update readme of CRF", "body": "PR [12056](https://github.com/tensorflow/tensorflow/pull/12056) implemented CRF decoding in tensor way, but the README hasn't been updated. This PR got this done.", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "Jenkins, test this please", "Jenkins, test this please.", "Can you pull rebase? That should fix the error. Thanks.", "Also, can you check the CLA status? For some reason the googlebot believes it's not clean."]}, {"number": 13042, "title": "docs: Fix Anaconda environment creation step", "body": "There is a bug in the [install instructions for Anaconda users][1].  Before you can use `pip` to install tensorflow, you must first install `python` (which includes `pip`) to the new environment.  Otherwise, the user will accidentally use the system's `pip`, and tensorflow will be installed to the system python instead of the intended environment.\r\n\r\n[1]: https://www.tensorflow.org/install/install_linux#InstallingAnaconda\r\n\r\n", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->", "I signed the CLA.", "CLAs look good, thanks!\n\n<!-- ok -->"]}, {"number": 13041, "title": "Load model in C++ API and get \"from device: CUDA_ERROR_OUT_OF_MEMORY\" error", "body": "My model is about 2.4GB\u3002In my inference step, I  want to load model by multi-processing method in each GPU. That means I try to make two process in one GPU and each load a model\u3002\r\nAfter I make configuration of each session done, each session get about 5GB memory, But I still meet the \"from device: CUDA_ERROR_OUT_OF_MEMORY\"\u3002I am wondering\u3002\u3002\u3002 Asking for help\r\n\r\n##  **GPU information:**\r\n[search@qrwt01 /home/s/apps/qtfserverd/bin]$ nvidia-smi\r\nThu Sep 14 21:42:48 2017       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 375.26                 Driver Version: 375.26                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  Tesla K80           Off  | 0000:08:00.0     Off |                    0 |\r\n| N/A   48C    P0    61W / 149W |  11366MiB / 11439MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   1  Tesla K80           Off  | 0000:09:00.0     Off |                    0 |\r\n| N/A   32C    P0    72W / 149W |  11359MiB / 11439MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID  Type  Process name                               Usage      |\r\n|=============================================================================|\r\n|    0     33056    C   ...ome/s/apps/qtfserverd/etc/qtfserverd.conf  5823MiB |\r\n|    0     33057    C   ...ome/s/apps/qtfserverd/etc/qtfserverd.conf  5515MiB |\r\n|    1     33058    C   ...ome/s/apps/qtfserverd/etc/qtfserverd.conf  5823MiB |\r\n|    1     33059    C   ...ome/s/apps/qtfserverd/etc/qtfserverd.conf  5516MiB |\r\n+-----------------------------------------------------------------------------+\r\n\r\n\r\n## **Session configuration:**\r\n 46 void* create_session(void* graph, std::string& checkpoint_path,\r\n 47     int intra_op_threads, int inter_op_threads, std::string& device_list) {\r\n 48     Session* session = NULL;\r\n 49     SessionOptions sess_opts;\r\n 50     //int NUM_THREADS = 8;\r\n 51     if (intra_op_threads > 0) {\r\n 52         sess_opts.config.set_intra_op_parallelism_threads(intra_op_threads);\r\n 53     }\r\n 54     if (inter_op_threads > 0) {\r\n 55         sess_opts.config.set_inter_op_parallelism_threads(inter_op_threads);\r\n 56     }\r\n 57 \r\n 58     sess_opts.config.set_allow_soft_placement(true);\r\n 59     sess_opts.config.mutable_gpu_options()->set_visible_device_list(device_list);\r\n 60     sess_opts.config.mutable_gpu_options()->set_allocator_type(\"BFC\");\r\n 61     sess_opts.config.mutable_gpu_options()->set_per_process_gpu_memory_fraction(0.5);\r\n 62     sess_opts.config.mutable_gpu_options()->set_allow_growth(true);\r\n 63     Status status = NewSession(sess_opts, &session);\r\n 64     if (!status.ok()) {\r\n 65         fprintf(stderr, \"Create Session Failed %s\\n\", status.ToString().c_str());\r\n 66         return NULL;\r\n 67     }\r\n\r\n\r\n## **Error information**\r\nload /home/search/tensorflow/deploy_combine.model.meta graph to /gpu:1 success\r\n2017-09-14 21:42:31.188212: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Found device 0 with properties: \r\nname: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\r\npciBusID: 0000:09:00.0\r\ntotalMemory: 11.17GiB freeMemory: 11.05GiB\r\n2017-09-14 21:42:31.188260: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1055] Creating TensorFlow device (/device:GPU:0) -> (device: 1, name: Tesla K80, pci bus id: 0000:09:00.0, compute capability: 3.7)\r\nqss_switch:1, lstm_switch:1\r\nqss_switch:1, lstm_switch:1\r\n2017-09-14 21:42:33.826598: E tensorflow/stream_executor/cuda/cuda_driver.cc:936] failed to allocate 1.58G (1701773312 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY\r\n2017-09-14 21:42:33.838694: E tensorflow/stream_executor/cuda/cuda_driver.cc:936] failed to allocate 1.43G (1531596032 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY\r\n2017-09-14 21:42:33.893832: E tensorflow/stream_executor/cuda/cuda_driver.cc:936] failed to allocate 439.82M (461180672 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY\r\n2017-09-14 21:42:33.903917: E tensorflow/stream_executor/cuda/cuda_driver.cc:936] failed to allocate 439.82M (461180672 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY\r\n2017-09-14 21:42:33.913843: E tensorflow/stream_executor/cuda/cuda_driver.cc:936] failed to allocate 439.82M (461180672 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY\r\n2017-09-14 21:42:33.924008: E tensorflow/stream_executor/cuda/cuda_driver.cc:936] failed to allocate 439.82M (461180672 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY\r\n2017-09-14 21:42:33.935385: E tensorflow/stream_executor/cuda/cuda_driver.cc:936] failed to allocate 439.82M (461180672 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY\r\n2017-09-14 21:42:33.946556: E tensorflow/stream_executor/cuda/cuda_driver.cc:936] failed to allocate 439.82M (461180672 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY\r\n2017-09-14 21:42:33.956340: E tensorflow/stream_executor/cuda/cuda_driver.\r\n", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 13040, "title": "Feature request: Dataset.from_py_func", "body": "I have an input pipeline that is especially complex. It is coded entirely in plain Python. While it *may* be possible to reimplement it in TensorFlow operations, that would be a huge amount of work and take far too much time to be worth it right now.\r\n\r\nIt would be great if I could hook my existing pipeline into the new Dataset approach via something like `Dataset.from_py_func`. One would pass a reference to a Python function that has no inputs and, when executed, acts as a generator that yields examples one-at-a-time as numpy arrays. For example:\r\n\r\n    def generate():\r\n        for example in complex_input_pipeline():\r\n            yield example\r\n\r\n    dataset = Dataset.from_py_func(generate)\r\n    # Do normal things with dataset\r\n        \r\nI've been unable to figure out a way to do something like this using existing functionality so it would be great if it could be added.", "comments": ["Have a look at`Dataset.from_generator()` in the nightly build... it is almost exactly what you're looking for! "]}, {"number": 13038, "title": "cub::BlockReduce error while building tensorflow in windows using cmake", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n    No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n    Windows 10 (64 bit)\r\n- **TensorFlow installed from (source or binary)**:\r\n    Using CMake and instructions present at (tensorflow/tensorflow/contrib/cmake)\r\n- **TensorFlow version (use command below)**:\r\n    -Using Master Branch\r\n- **Python version**: \r\n    3.6.1\r\n- **Bazel version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n   CUDA-8.0.61\r\n   cuDNN-5.1\r\n- **GPU model and memory**:\r\n   NVIDIA GeForce GTX TITAN X (382.05)\r\n- **Exact command to reproduce**:\r\n   MSBuild /p:Configuration=Release tf_label_image_example.vcxproj\r\n\r\n### Describe the problem\r\nI encounter the following error while building the tensorflow project for image recognition (tf_label_image_example.vcxproj). The error occurs when this image recognition project builds tf_core_gpu_kernels.vcxproj.\r\n\r\nerror : argument list for template \"cub::BlockReduce<T, BLOCK_DIM_X, ALGORITHM, BLOCK_DIM_Y, BLOCK_DIM_Z, PTX_ARCH>::Reduce [with T=std::iterator_tra its<T>::value_type, BLOCK_DIM_X=num_threads, ALGORITHM=cub::BLOCK_REDUCE_WARP_REDUCTIONS, BLOCK_DIM_Y=1, BLOCK_DIM_Z=1, PTX_ARCH=0]\" is missing.\r\n\r\n\r\n\r\n", "comments": ["I am having the same/similar issue in Windows 7, using the same CMake instructions you linked above.\r\n\r\nCompilation: MSBuild /p:Configuration=Release tf_tutorials_example_trainer.vcxproj\r\n\r\nErrors: \r\n\"C:\\Users\\tjb3\\tensorflow\\tensorflow\\contrib\\cmake\\build2\\tf_tutorials_example_\r\ntrainer.vcxproj\" (default target) (1) ->\r\n\"C:\\Users\\tjb3\\tensorflow\\tensorflow\\contrib\\cmake\\build2\\tf_core_gpu_kernels.v\r\ncxproj\" (default target) (113) ->\r\n(CustomBuild target) ->\r\n  C:/Users/tjb3/tensorflow\\tensorflow/core/kernels/reduction_ops_gpu_kernels.h(\r\n179): error : argument list for template \"cub::BlockReduce<T, BLOCK_DIM_X, ALGO\r\nRITHM, BLOCK_DIM_Y, BLOCK_DIM_Z, PTX_ARCH>::Reduce [with T=std::iterator_traits\r\n<T>::value_type, BLOCK_DIM_X=num_threads, ALGORITHM=cub::BLOCK_REDUCE_WARP_REDU\r\nCTIONS, BLOCK_DIM_Y=1, BLOCK_DIM_Z=1, PTX_ARCH=0]\" is missing [C:\\Users\\tjb3\\te\r\nnsorflow\\tensorflow\\contrib\\cmake\\build2\\tf_core_gpu_kernels.vcxproj]\r\n  C:/Users/tjb3/tensorflow\\tensorflow/core/kernels/reduction_ops_gpu_kernels.h(\r\n214): error : argument list for template \"cub::WarpReduce<T, LOGICAL_WARP_THREA\r\nDS, PTX_ARCH>::Reduce [with T=std::iterator_traits<T>::value_type, LOGICAL_WARP\r\n_THREADS=32, PTX_ARCH=0]\" is missing [C:\\Users\\tjb3\\tensorflow\\tensorflow\\contr\r\nib\\cmake\\build2\\tf_core_gpu_kernels.vcxproj]\r\n", "@ekelsen I think this is the same bug that was reported yesterday with a fix in the works... can you close this issue when the change makes it to `HEAD`?", "btw, you can do \"blabla, fixes #13038\" in public changelist description, and github will automatically close the issue when commit gets merged into master", "1) I got same error but while building a different file\r\n`\"E:\\AkashJ\\projects\\tensorflow\\tensorflow\\contrib\\cmake\\build\\ALL_BUILD.vcxproj\" (default target) (1) ->\r\n       \"E:\\AkashJ\\projects\\tensorflow\\tensorflow\\contrib\\cmake\\build\\_beam_search_ops.vcxproj\" (default target) (3) ->\r\n       \"E:\\AkashJ\\projects\\tensorflow\\tensorflow\\contrib\\cmake\\build\\pywrap_tensorflow_internal.vcxproj\" (default target) (4) ->\r\n       \"E:\\AkashJ\\projects\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_core_gpu_kernels.vcxproj\" (default target) (130) ->\r\n       (CustomBuild target) ->\r\n         E:/AkashJ/projects/tensorflow\\tensorflow/core/kernels/reduction_ops_gpu_kernels.h(179): error : argument list for template \"cub::BlockReduce<T, BLOCK_DIM_X, A\r\n       LGORITHM, BLOCK_DIM_Y, BLOCK_DIM_Z, PTX_ARCH>::Reduce [with T=std::iterator_traits<T>::value_type, BLOCK_DIM_X=num_threads, ALGORITHM=cub::BLOCK_REDUCE_WARP_RED\r\n       UCTIONS, BLOCK_DIM_Y=1, BLOCK_DIM_Z=1, PTX_ARCH=0]\" is missing [E:\\AkashJ\\projects\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_core_gpu_kernels.vcxproj]\r\n         E:/AkashJ/projects/tensorflow\\tensorflow/core/kernels/reduction_ops_gpu_kernels.h(214): error : argument list for template \"cub::WarpReduce<T, LOGICAL_WARP_TH\r\n       READS, PTX_ARCH>::Reduce [with T=std::iterator_traits<T>::value_type, LOGICAL_WARP_THREADS=32, PTX_ARCH=0]\" is missing [E:\\AkashJ\\projects\\tensorflow\\tensorflow\r\n       \\contrib\\cmake\\build\\tf_core_gpu_kernels.vcxproj]`\r\n\r\n2) Where's the fix @mrry mentioned above ?", "Are you sure you're at HEAD?  That line number doesn't correspond to anything anymore and the error you're referring to should be fixed.", "Ok, my mistake. Did `git pull` and re-executed build commands. Now #13065 is encountered."]}, {"number": 13037, "title": "How to check tensorflow/inception - version number from an inception .pb-file?", "body": "Hi, I am trying to figure out which Tensorflow version an inception .pb file is (https://storage.googleapis.com/download.tensorflow.org/models/inception5h.zip). This file is used in a OpenCV-plugin to Unity3D game engine (OpenCV for Unity, Enox-software, wraps OpenCV 3.3.0). I replaced these files with a model I re-trained with TF 1.3.0 yesterday and it made the whole Unity3D editor crash. So I assume I have the wrong tensorflow/inception-version (as the default zip-version worked, and my re-trained model worked inside docker-test), but I do not know what is the right version to use due to lack of documentation / knowledle / being tf-noobie. Does anybody here know how to check the version from the .pb-file ?", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 13036, "title": "delete dummy 'r' in front of annotation", "body": "I just delete this dummy r character in the front of multi-line annotation with the newest version.\r\n\r\n", "comments": ["I have signed it (CLA)", "Hi @wei-yuan, the `r` is fine, it's just telling that the text is a raw string.", "@drpngx thx for the reply"]}, {"number": 13035, "title": "[W tensorflow/core/framework/op_kernel.cc:993] Failed precondition", "body": "I want to run the tensorflow-deeplab-resnet,and I prepared my own training data for it. But When I try to run train.py to train data, it always did not work. And the error are as  follows:\r\n![Uploading error.jpg\u2026]()\r\n\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally\r\nTensor(\"create_inputs/batch:0\", shape=(2, 4000, 4000, 3), dtype=float32) sssssssssssss\r\nTensor(\"create_inputs/batch:1\", shape=(2, 4000, 4000, 1), dtype=uint8) sssssssssss\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: \r\nname: Quadro M4000\r\nmajor: 5 minor: 2 memoryClockRate (GHz) 0.7725\r\npciBusID 0000:03:00.0\r\nTotal memory: 7.92GiB\r\nFree memory: 7.51GiB\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Quadro M4000, pci bus id: 0000:03:00.0)\r\nRestored model parameters from /home/precision/code/tensorflow-deeplab-resnet-master/deeplab_resnet.ckpt\r\nW tensorflow/core/framework/op_kernel.cc:993] Failed precondition: /home/precision/code/tensorflow-deeplab-resnet-master/dataset/VOCdevkit\r\nW tensorflow/core/framework/op_kernel.cc:993] Failed precondition: /home/precision/code/tensorflow-deeplab-resnet-master/dataset/VOCdevkit\r\nW tensorflow/core/framework/op_kernel.cc:993] Out of range: FIFOQueue '_1_create_inputs/batch/fifo_queue' is closed and has insufficient elements (requested 2, current size 0)\r\n     [[Node: create_inputs/batch = QueueDequeueManyV2[component_types=[DT_FLOAT, DT_UINT8], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](create_inputs/batch/fifo_queue, create_inputs/batch/n)]]\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 258, in <module>\r\n    main()\r\n  File \"train.py\", line 247, in main\r\n    loss_value, images, labels, preds, summary, _ = sess.run([reduced_loss, image_batch, label_batch, pred, total_summary, train_op], feed_dict=feed_dict)\r\n  File \"/home/precision/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 767, in run\r\n    run_metadata_ptr)\r\n  File \"/home/precision/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 965, in _run\r\n    feed_dict_string, options, run_metadata)\r\n  File \"/home/precision/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1015, in _do_run\r\n    target_list, options, run_metadata)\r\n  File \"/home/precision/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 1035, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.OutOfRangeError: FIFOQueue '_1_create_inputs/batch/fifo_queue' is closed and has insufficient elements (requested 2, current size 0)\r\n     [[Node: create_inputs/batch = QueueDequeueManyV2[component_types=[DT_FLOAT, DT_UINT8], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](create_inputs/batch/fifo_queue, create_inputs/batch/n)]]\r\n\r\nCaused by op u'create_inputs/batch', defined at:\r\n  File \"train.py\", line 258, in <module>\r\n    main()\r\n  File \"train.py\", line 142, in main\r\n    image_batch, label_batch = reader.dequeue(args.batch_size)\r\n  File \"/home/precision/code/tensorflow-deeplab-resnet-master/deeplab_resnet/image_reader.py\", line 180, in dequeue\r\n    num_elements)\r\n  File \"/home/precision/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/training/input.py\", line 872, in batch\r\n    name=name)\r\n  File \"/home/precision/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/training/input.py\", line 667, in _batch\r\n    dequeued = queue.dequeue_many(batch_size, name=name)\r\n  File \"/home/precision/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/data_flow_ops.py\", line 458, in dequeue_many\r\n    self._queue_ref, n=n, component_types=self._dtypes, name=name)\r\n  File \"/home/precision/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/gen_data_flow_ops.py\", line 1310, in _queue_dequeue_many_v2\r\n    timeout_ms=timeout_ms, name=name)\r\n  File \"/home/precision/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\r\n    op_def=op_def)\r\n  File \"/home/precision/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2327, in create_op\r\n    original_op=self._default_original_op, op_def=op_def)\r\n  File \"/home/precision/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1226, in __init__\r\n    self._traceback = _extract_stack()\r\n\r\nOutOfRangeError (see above for traceback): FIFOQueue '_1_create_inputs/batch/fifo_queue' is closed and has insufficient elements (requested 2, current size 0)\r\n     [[Node: create_inputs/batch = QueueDequeueManyV2[component_types=[DT_FLOAT, DT_UINT8], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](create_inputs/batch/fifo_queue, create_inputs/batch/n)]]\r\n\r\n**[W tensorflow/core/framework/op_kernel.cc:993] Failed precondition**\r\nI have written the path address for the training set explicitly\uff0cbut the training program doesn't work properly.\r\n\r\nCan you help me with this problem?\r\n                                                                 Thanks a lot!", "comments": ["The first error seems to be\r\n\r\n```\r\n'_1_create_inputs/batch/fifo_queue' is closed and has insufficient elements (requested 2, current size 0)\r\n```\r\n\r\nwhich indicates tensorflow-deeplab-resnet is trying to get elements from a queue after it is closed.\r\n\r\nYou should file an issue with tensorflow-deeplab-resnet, or even better, ask on StackOverflow.", "@luoxiaoliaolan  did u make it run? The documentation of this project is very limited. I am trying to train with my own dataset also. Actually, I picked one class (person) of the original classes of the pretrained model and trying to ignore the other classes. However, the label and prediction images resulted from here:\r\n```\r\n    total_summary = tf.summary.image('images', \r\n                                     tf.concat(axis=2, values=[images_summary, labels_summary, preds_summary]), \r\n                                     max_outputs=args.save_num_images)\r\n```\r\n\r\nare displayed as black. Then, when I try to inference, the result is incorrect. When I train the model using the original number of classes, 21, the result is ok. I read all the possible issues from the forum of the project but now, the forum is closed and I cannot get the info of how to make it work for less than 21 classes.\r\n\r\nAbout your question, it happened to me when I left some images outside the folder. ", "@fastlater  I'm very glad that we studied it together\uff01\uff01I encountered this problem for a long time, and I tried to slove it, but I failed. The key to the problem is that the train.py  is not able to read the training data into the queue. Maybe it is a bug of the lastest TensorFlow\uff08v1.2\uff09 or it is a bug of the  tensorflow-deeplab-resnet , but its coder closed issue, and I can't read the Q&A.\r\nI will continue to solve the problem."]}, {"number": 13034, "title": "AttributeError: 'RunConfig' object has no attribute 'environment'", "body": "Problem with the learn_runner.run() method.\r\n\r\n# **System Info:**\r\n\r\n**Windows 10**\r\n**TF 1.3.0**\r\n**Python 3.5**\r\n\r\n**Code :**\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\nimport tensorflow.contrib.learn as tflearn\r\nfrom tensorflow.contrib.learn.python.learn import learn_runner\r\n\r\nprint('Tensorflow Version - ', tf.__version__)\r\ntf.logging.set_verbosity(tf.logging.INFO)\r\n\r\ntrain_file = 'data/iris_training.csv'\r\ntest_file = 'data/iris_test.csv'\r\n\r\nfeature_names = [\r\n    'SepalLength',\r\n    'SepalWidth',\r\n    'PetalLength',\r\n    'PetalWidth'\r\n]\r\n\r\n\r\ndef input_fn(file, perform_shuffle=False, repeat_count=1):\r\n    def decode_csv(line):\r\n        parsed_line = tf.decode_csv(line, [[0.], [0.], [0.], [0.], [0]])\r\n        label = parsed_line[-1:]\r\n        del parsed_line[-1]\r\n        features = parsed_line\r\n        parsed_data = dict(zip(feature_names, features)), label\r\n        return parsed_data\r\n\r\n    data_set = (tf.contrib.data.TextLineDataset(file).skip(1).map(decode_csv))\r\n\r\n    if perform_shuffle:\r\n        data_set = data_set.shuffle(buffer_size=256)\r\n\r\n    data_set = data_set.repeat(repeat_count)\r\n    data_set = data_set.batch(32)\r\n    iterator = data_set.make_one_shot_iterator()\r\n    batch_features, batch_label = iterator.get_next()\r\n    return batch_features, batch_label\r\n\r\nfeature_columns = [tf.feature_column.numeric_column(feature, normalizer_fn=lambda x: normalize_fn(x)) for feature in\r\n                   feature_names]\r\n\r\n\r\ndef json_serving_input_fn():\r\n    \"\"\"Build the serving inputs.\"\"\"\r\n    \"\"\"Build the serving inputs.\"\"\"\r\n\r\n    inputs = {}\r\n    for feat in feature_columns:\r\n        inputs[feat.name] = tf.placeholder(shape=[None], dtype=feat.dtype)\r\n    return tf.estimator.export.ServingInputReceiver(inputs, inputs)\r\n\r\ndef normalize_fn(feature):\r\n    print('\\n')\r\n    print(tf.shape(feature))\r\n    mean, variance = tf.nn.moments(feature, axes=[0])\r\n    print('\\n Mean - ', mean)\r\n    print('\\n Variance - ', variance)\r\n    return (feature - mean) / variance\r\n\r\n\r\ndef experiment_fn(output_dir):\r\n    classifier = tf.estimator.DNNClassifier(hidden_units=[10, 10], feature_columns=feature_columns, n_classes=3,\r\n                                            model_dir=output_dir)\r\n\r\n    from tensorflow.contrib.learn.python.learn.utils import saved_model_export_utils\r\n\r\n    return tflearn.Experiment(classifier,\r\n                              train_input_fn=lambda: input_fn(train_file, perform_shuffle=True, repeat_count=10),\r\n                              eval_input_fn=lambda: input_fn(test_file, perform_shuffle=False, repeat_count=1),\r\n                              eval_metrics=None,\r\n                              export_strategies=[saved_model_export_utils.make_export_strategy(\r\n                                  serving_input_fn=json_serving_input_fn, default_output_alternative_key=None,\r\n                                  exports_to_keep=1\r\n                              )],\r\n                              train_steps=100\r\n                              )\r\n\r\nlearn_runner.run(experiment_fn=experiment_fn, output_dir='build2/')\r\n\r\n```\r\n\r\n**Exception:**\r\n\r\nFile \"F:/Git/Tensorflow-Tutorials/iris/linear_classifier.py\", line 107, in <module>\r\n    learn_runner.run(experiment_fn=experiment_fn, output_dir='build2/')\r\n  File \"F:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\learn_runner.py\", line 209, in run\r\n    return _execute_schedule(experiment, schedule)\r\n  File \"F:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\learn_runner.py\", line 46, in _execute_schedule\r\n    return task()\r\n  File \"F:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\experiment.py\", line 502, in train_and_evaluate\r\n    self.train(delay_secs=0)\r\n  File \"F:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\experiment.py\", line 253, in train\r\n    if (config.environment != run_config.Environment.LOCAL and\r\nAttributeError: 'RunConfig' object has no attribute 'environment'", "comments": ["@kishorenayar Does the workaround in https://github.com/tensorflow/tensorflow/issues/11038 help? ", "@cy89 I have a question, how do I set rc.environment = None ?\r\n\r\n```python\r\ndef experiment_fn(output_dir):\r\n    config = run_config.RunConfig(model_dir=output_dir)\r\n    config.environment = None\r\n    classifier = tf.estimator.DNNClassifier(hidden_units=[10, 10], feature_columns=feature_columns, n_classes=3, config=config)\r\n\r\n    from tensorflow.contrib.learn.python.learn.utils import saved_model_export_utils\r\n\r\n    return tflearn.Experiment(classifier,\r\n                              train_input_fn=lambda: input_fn(train_file, perform_shuffle=True, repeat_count=10),\r\n                              eval_input_fn=lambda: input_fn(test_file, perform_shuffle=False, repeat_count=1),\r\n                              eval_metrics=None,\r\n                              export_strategies=[saved_model_export_utils.make_export_strategy(\r\n                                  serving_input_fn=json_serving_input_fn, default_output_alternative_key=None,\r\n                                  exports_to_keep=1\r\n                              )],\r\n                              train_steps=100\r\n                              )\r\n\r\n\r\nlearn_runner.run(experiment_fn=experiment_fn, output_dir='build2/')\r\n```\r\n\r\n**Exception** \r\nFile \"E:\\Programs\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\learn_runner.py\", line 200, in run\r\n    experiment = experiment_fn(output_dir=output_dir)\r\n  File \"D:/PyCharm-Workspace/Tensorflow-Projects/iris/iris_github_issue.py\", line 67, in experiment_fn\r\n    config.environment = None\r\nAttributeError: can't set attribute", "@cy89 I don't understand this. I Just modified the above code and it's running fine.\r\n\r\n```python\r\ndef experiment_fn(output_dir):\r\n    config = run_config.RunConfig(model_dir=output_dir)\r\n    #config.environment = None\r\n    classifier = tf.estimator.DNNClassifier(hidden_units=[10, 10], feature_columns=feature_columns, n_classes=3, config=config)\r\n\r\n    from tensorflow.contrib.learn.python.learn.utils import saved_model_export_utils\r\n\r\n    return tflearn.Experiment(classifier,\r\n                              train_input_fn=lambda: input_fn(train_file, perform_shuffle=True, repeat_count=10),\r\n                              eval_input_fn=lambda: input_fn(test_file, perform_shuffle=False, repeat_count=1),\r\n                              eval_metrics=None,\r\n                              train_steps=100\r\n                              )\r\n\r\n\r\nlearn_runner.run(experiment_fn=experiment_fn, output_dir='build2/')\r\n```\r\n\r\n\r\n**Output**\r\naccuracy = 0.925926, average_loss = 0.40835, global_step = 38, loss = 11.0254"]}, {"number": 13033, "title": "Update workspace.bzl to use latest farmhash commit to support s390x", "body": "We had raised an issue in google/farmhash master earlier for big endian. However due to restructuring in the code via latest commits, the support for s390x needs to be explicitly added.\r\nThis support is added through [this](https://github.com/google/farmhash/commit/816a4ae622e964763ca0862d9dbd19324a1eaf45) commit.\r\n\r\nNow, tensorflow/workspace.bzl can be updated with this commit id for farmhash.\r\n\r\n", "comments": ["@Nayana-ibm, thanks for your PR! By analyzing the history of the files in this pull request, we identified @jart, @tensorflower-gardener and @kirilg to be potential reviewers.", "Can one of the admins verify this patch?", "@jart Could you please check if sha256 used for farmhash is correct.\r\nAlso, need to update mirror dependencies on GCS.", "old issue id (before restructure ): https://github.com/tensorflow/tensorflow/issues/9107", "@gunan Could you please review changes?", "Jenkins, test this please.", "Jenkins, test this please.", "Jenkins, test this please."]}, {"number": 13032, "title": "delete dummy 'r'", "body": "I just delete this dummy r character in the front of multi-line annotation.", "comments": ["@wei-yuan, thanks for your PR! By analyzing the history of the files in this pull request, we identified @vrv, @petewarden and @tensorflower-gardener to be potential reviewers.", "Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->", "I have signed it\r\nThe update [#13036](https://github.com/tensorflow/tensorflow/pull/13036) version cuz I used older repo here\r\n", "CLAs look good, thanks!\n\n<!-- ok -->", "Duplicate"]}, {"number": 13031, "title": "Has this issue been solved for all containers - ImportError: cannot import name audio_ops", "body": "\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: I am running the tutorial \"audio recognition network\"\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 14.04\r\n- **TensorFlow installed from (source or binary)**: Binary\r\n- **TensorFlow version (use command below)**:('v1.0.0-rc2-15-g47bba63-dirty', '1.0.0')\r\n- **Python version**: 2.7.6\r\n- **Bazel version (if compiling from source)**:NA\r\n- **CUDA/cuDNN version**:NA\r\n- **GPU model and memory**:NA\r\n- **Exact command to reproduce**: python tensorflow/examples/speech_commands/train.py\r\n\r\n### Describe the problem\r\nI pip-installed tensorflow using virtualenv. Then I run -  \r\n\r\npython tensorflow/examples/speech_commands/train.py       for which the following error message appears: \r\n\r\n  Traceback (most recent call last):\r\n  File \"/home/cogknit/tensorflow/tensorflow/examples/speech_commands/train.py\", line 79, in <module>\r\n    import input_data\r\n  File \"/home/cogknit/tensorflow/tensorflow/examples/speech_commands/input_data.py\", line 35, in <module>\r\n    from tensorflow.contrib.framework.python.ops import audio_ops as contrib_audio\r\nImportError: cannot import name audio_ops\r\n\r\nIn stack overflow, I came across the same issue only with anaconda install in the following link -\r\nhttps://stackoverflow.com/questions/45952387/anaconda-install-of-tensorflow-missing-audio-ops-from-contrib-framework \r\nThere, the answer indicated that the \"audio_ops.py\" file is missing from the framework and hasn't been released yet .This indication seems to be validated by a developer in the following link and recently an update seems to have been made/released per the same link  : https://github.com/tensorflow/tensorflow/issues/11339\r\n\r\nMy question in particular is does the release solve the error in virtualenv installation too? Or hasn't it been solved at all? Is it better to move to a docker installation?Are there any alternatives/commands that   I can use to circumvent this error?\r\n\r\n#12722  dealt with the same error but the solution seems to have worked only for tensorflow built from source. Is there anything that I should check again?\r\n\r\nThank you,", "comments": ["You are using TensorFlow 1.0, but I believe you need the master branch, which requires compiling from source.\r\n\r\n@petewarden can you confirm this? If it doesn't work with 1.3, we should probably document that in the tutorial.", "I use python3.6.2 to install tensowflow1.3 on win10, the issue can also be reproduced. and there has no file name audio_ops.py in the folder \"Python\\Python36\\Lib\\site-packages\\tensorflow\\python\\ops\" which is the tensorflow's location.\r\nReproduce steps:\r\ncommand: python .\\tensorflow\\examples\\speech_commands\\train.py\r\nThe error is as bellows:\r\nTraceback (most recent call last):\r\nFile \".\\tensorflow\\examples\\speech_commands\\train.py\", line 80, in <module>\r\nimport input_dataFile \"C:\\Users\\**\\Desktop\\tensorflow\\tensorflow\\tensorflow\\examples\\speech_commands\\input_data.py\", line 35, in <module>\r\nfrom tensorflow.contrib.framework.python.ops import audio_ops as contrib_audio\r\nImportError: cannot import name 'audio_ops'\r\n", "I have to admit, I am getting the same error, using python 3.5, Tensorflow 1.3, on Debian 9\r\n(tensorflow) charles@Kong-Zi:~$ python tensorflow/examples/speech_commands/train.py\r\nTraceback (most recent call last):\r\n  File \"tensorflow/examples/speech_commands/train.py\", line 80, in <module>\r\n    import input_data\r\n  File \"/home/charles/tensorflow/examples/speech_commands/input_data.py\", line 35, in <module>\r\n    from tensorflow.contrib.framework.python.ops import audio_ops as contrib_audio\r\nImportError: cannot import name 'audio_ops'\r\n(tensorflow) charles@Kong-Zi:~$ python3 tensorflow/examples/speech_commands/train.py\r\nTraceback (most recent call last):\r\n  File \"tensorflow/examples/speech_commands/train.py\", line 80, in <module>\r\n    import input_data\r\n  File \"/home/charles/tensorflow/examples/speech_commands/input_data.py\", line 35, in <module>\r\n    from tensorflow.contrib.framework.python.ops import audio_ops as contrib_audio\r\nImportError: cannot import name 'audio_ops'\r\n", "I have the same error using Windows 10, Python 3.5, tensorflow 1.3\r\n\r\nC:\\tensorflow-master>python tensorflow/examples/speech_commands/train.py\r\nTraceback (most recent call last):\r\n  File \"tensorflow/examples/speech_commands/train.py\", line 80, in <module>\r\n    import input_data\r\n  File \"C:\\tensorflow-master\\tensorflow\\examples\\speech_commands\\input_data.py\", line 35, in <module>\r\n    from tensorflow.contrib.framework.python.ops import audio_ops as contrib_audio\r\nImportError: cannot import name 'audio_ops'\r\n\r\n", "audio_ops is available in their nightly docker builds. This is somewhat along the lines of what I did:\r\n1. `docker pull tensorflow/tensorflow:nightly-gpu-py3`\r\n2. `nvidia-docker run -it -p 8888:8888 tensorflow/tensorflow:nightly-gpu-py3`\r\n3. `docker exec -it jolly_lamport bash` (assuming Linux)\r\n4. If you want to run the speech command example, it isn't Python 3 compatible. You'll need to fix the errors manually. I believe it's just like 4 lines of changes...", "@everybody, along the lines of suggestions by @reedwm ,the following steps seems to have solved the issue : \r\n  1. Install anaconda for python\r\n  2. Compile tensorflow from the source \r\n\r\nA few errors crop up during training as @daemon mentioned above due to incompatibility of train.py with Python 3. It has to do with the usage of map and xrange in particular.(while calculating len, len(list( )) has to be used and xrange has to be replaced with range)  \r\n\r\nThank you @reedwm for your help earlier.", "Yep, https://github.com/tensorflow/tensorflow/pull/13111 should fix it.", "Hi all,\r\n\r\nThe issue of audio_ops is not yet resolved even for python2.7. It throws the same error as mentioned in the issue that started the thread.\r\n\r\nPlease resolve it at the earliest.", "Hi guys,\r\n\r\nthe solution is to install:\r\npip install tf-nightly\r\n\r\nprior to \r\npython train.py", "Hi @NikolayStarikov ,\r\n\r\nI have original tf installed. I installed tf-nightly over that and still, the problem persists.", "problem still there.\r\neven on google cloud", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "used GCP datalab - python 2&3\r\naudio_ops is not yet resolved. ", "According to #14004, this requires a recently nightly build from the last month or so. The issue is not yet fixed with TensorFlow 1.4, but will be with Tensorflow 1.5 once it comes out.\r\n\r\nClosing this since the issue seems to be resolved in nightly.", " can slove it by using \r\n\r\n> sudo pip3 install tf-nightly -i https://pypi.tuna.tsinghua.edu.cn/simple/ "]}, {"number": 13030, "title": "Crash when load Fine-tune model on Android", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: 1.3.0\r\n- **Python version**: 2.7.12\r\n- **Bazel version (if compiling from source)**: 0.5.4\r\n- **CUDA/cuDNN version**:  8.0.61\r\n- **GPU model and memory**: NVIDIA Corporation Device 1b06\r\n- **Exact command to reproduce**: \r\n\r\nHow I do Fine-tune : \r\n```\r\n\r\n# Convert imagenet data to TFrecord ( No bounding box , just for classification ) \r\npython build_image_data.py \\\r\n--train_directory='imagenet/train' \\\r\n--validation_directory='imagenet/train' \\\r\n--labels_file='imagenet/labels.txt' \\\r\n--output_directory='imagenet/tfrecord' \r\n\r\n# Train from checkpoint\r\npython train_image_classifier.py \\\r\n    --dataset_dir=.../imagenet/tfrecord \\\r\n    --train_dir=.../imagenet/train_logs \\\r\n    --checkpoint_path=.../checkpoint/mobilenet_v1_0.50_224.ckpt \\\r\n    --model_name=mobilenet_v1_050 \\\r\n    --dataset_name=flowers \\                       ( _NUM_CLASSES and sizes has been modified )\r\n    --dataset_split_name=train \\\r\n    --max_number_of_steps=10000 \\\r\n    --checkpoint_exclude_scopes=MobilenetV1/Logits \\\r\n    --trainable_scopes=MobilenetV1/Logits \\\r\n\r\n# Produce .pb file (use .pbtxt)\r\nbazel-bin/tensorflow/python/tools/freeze_graph \\\r\n--input_graph=.../imagenet/train_logs/graph.pbtxt \\\r\n--input_checkpoint=.../imagenet/train_logs/model.ckpt-10000 \\\r\n--output_graph=.../imagenet/train_logs/frozen_graph.pb \\\r\n--output_node_names=MobilenetV1/Predictions/Reshape_1\r\n\r\n# Removes parts of a graph that are only needed for training\r\nbazel-bin/tensorflow/python/tools/optimize_for_inference \\\r\n--input=.../imagenet/train_logs/frozen_graph.pb \\\r\n--output=.../imagenet/train_logs/optimized_graph.pb \\\r\n--frozen_graph=True \\\r\n--input_names='prefetch_queue/fifo_queue' \\\r\n--output_names='MobilenetV1/Predictions/Reshape_1'\r\n\r\n```\r\n### Describe the problem\r\n\r\nHi , I am doing some fine-tune with mobilenet , I got some trouble at beginning since the input node \" prefetch_queue/fifo_queue \" , which Op \"FIFOQueueV2\" is disabled on Android , but I think it's okay  after using \"bazel-bin/tensorflow/python/tools/optimize_for_inference\" . ( I am not sure about it or I still need to customize my own TF library like mentioned [here](https://github.com/tensorflow/tensorflow/issues/8454) ? )\r\n\r\nBut now there is a new problem , after modify the parameter at \"ClassifierActivity.java\" like this : \r\n( input_name and output_name is from summarize_graph tool )\r\n```\r\n\r\n  private static final int INPUT_SIZE = 224;\r\n  private static final int IMAGE_MEAN = 117;\r\n  private static final float IMAGE_STD = 1;\r\n  private static final String INPUT_NAME = \"prefetch_queue/fifo_queue\";\r\n  private static final String OUTPUT_NAME = \"MobilenetV1/Predictions/Reshape_1\";\r\n\r\n  private static final String MODEL_FILE = \"file:///android_asset/tensorflow_inception_graph.pb\";\r\n  private static final String LABEL_FILE =\r\n      \"file:///android_asset/imagenet_comp_graph_label_strings.txt\";\r\n\r\n```\r\n\r\nand implement the demo on android , the TF Classify can be launched , but crash when press the volume key to turn on the debug mode. \r\n\r\nthe crash prints the following log :\r\n### Source code / logs\r\n\r\nError Message from adb logcat\r\n```\r\nE/InputEventSender( 4197): Exception dispatching finished signal.\r\nE/MessageQueue-JNI( 4197): Exception in MessageQueue callback: handleReceiveCallback\r\nE/MessageQueue-JNI( 4197): java.lang.NullPointerException: Attempt to invoke interface method 'void org.tensorflow.demo.Classifier.enableStatLogging(boolean)' on a null object reference\r\nE/MessageQueue-JNI( 4197):      at org.tensorflow.demo.ClassifierActivity.onSetDebug(ClassifierActivity.java:183)\r\nE/MessageQueue-JNI( 4197):      at org.tensorflow.demo.CameraActivity.onKeyDown(CameraActivity.java:381)\r\nE/MessageQueue-JNI( 4197):      at android.view.KeyEvent.dispatch(KeyEvent.java:2758)\r\nE/MessageQueue-JNI( 4197):      at android.app.Activity.dispatchKeyEvent(Activity.java:2755)\r\nE/MessageQueue-JNI( 4197):      at com.android.internal.policy.impl.PhoneWindow$DecorView.dispatchKeyEvent(PhoneWindow.java:2380)\r\nE/MessageQueue-JNI( 4197):      at android.view.ViewRootImpl$ViewPostImeInputStage.processKeyEvent(ViewRootImpl.java:4556)\r\nE/MessageQueue-JNI( 4197):      at android.view.ViewRootImpl$ViewPostImeInputStage.onProcess(ViewRootImpl.java:4512)\r\nE/MessageQueue-JNI( 4197):      at android.view.ViewRootImpl$InputStage.deliver(ViewRootImpl.java:4034)\r\nE/MessageQueue-JNI( 4197):      at android.view.ViewRootImpl$InputStage.onDeliverToNext(ViewRootImpl.java:4087)\r\nE/MessageQueue-JNI( 4197):      at android.view.ViewRootImpl$InputStage.forward(ViewRootImpl.java:4053)\r\nE/MessageQueue-JNI( 4197):      at android.view.ViewRootImpl$AsyncInputStage.forward(ViewRootImpl.java:4190)\r\nE/MessageQueue-JNI( 4197):      at android.view.ViewRootImpl$InputStage.apply(ViewRootImpl.java:4061)\r\nE/MessageQueue-JNI( 4197):      at android.view.ViewRootImpl$AsyncInputStage.apply(ViewRootImpl.java:4247)\r\nE/MessageQueue-JNI( 4197):      at android.view.ViewRootImpl$InputStage.deliver(ViewRootImpl.java:4034)\r\nE/MessageQueue-JNI( 4197):      at android.view.ViewRootImpl$InputStage.onDeliverToNext(ViewRootImpl.java:4087)\r\nE/MessageQueue-JNI( 4197):      at android.view.ViewRootImpl$InputStage.forward(ViewRootImpl.java:4053)\r\nE/MessageQueue-JNI( 4197):      at android.view.ViewRootImpl$InputStage.apply(ViewRootImpl.java:4061)\r\nE/MessageQueue-JNI( 4197):      at android.view.ViewRootImpl$InputStage.deliver(ViewRootImpl.java:4034)\r\nE/MessageQueue-JNI( 4197):      at android.view.ViewRootImpl$InputStage.onDeliverToNext(ViewRootImpl.java:4087)\r\nE/MessageQueue-JNI( 4197):      at android.view.ViewRootImpl$InputStage.forward(ViewRootImpl.java:4053)\r\nE/MessageQueue-JNI( 4197):      at android.view.ViewRootImpl$AsyncInputStage.forward(ViewRootImpl.java:4223)\r\nE/MessageQueue-JNI( 4197):      at android.view.ViewRootImpl$ImeInputStage.onFinishedInputEvent(ViewRootImpl.java:4393)\r\nE/MessageQueue-JNI( 4197):      at android.view.inputmethod.InputMethodManager$PendingEvent.run(InputMethodManager.java:2285)\r\nE/MessageQueue-JNI( 4197):      at android.view.inputmethod.InputMethodManager.invokeFinishedInputEventCallback(InputMethodManager.java:1909)\r\nE/MessageQueue-JNI( 4197):      at android.view.inputmethod.InputMethodManager.finishedInputEvent(InputMethodManager.java:1900)\r\nE/MessageQueue-JNI( 4197):      at android.view.inputmethod.InputMethodManager$ImeInputEventSender.onInputEventFinished(InputMethodManager.java:2262)\r\nE/MessageQueue-JNI( 4197):      at android.view.InputEventSender.dispatchInputEventFinished(InputEventSender.java:141)\r\nE/MessageQueue-JNI( 4197):      at android.os.MessageQueue.nativePollOnce(Native Method)\r\nE/MessageQueue-JNI( 4197):      at android.os.MessageQueue.next(MessageQueue.java:148)\r\nE/MessageQueue-JNI( 4197):      at android.os.Looper.loop(Looper.java:151)\r\nE/MessageQueue-JNI( 4197):      at android.app.ActivityThread.main(ActivityThread.java:5631)\r\nE/MessageQueue-JNI( 4197):      at java.lang.reflect.Method.invoke(Native Method)\r\nE/MessageQueue-JNI( 4197):      at java.lang.reflect.Method.invoke(Method.java:372)\r\nE/MessageQueue-JNI( 4197):      at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:959)\r\nE/MessageQueue-JNI( 4197):      at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:754)\r\nE/AndroidRuntime( 4197): FATAL EXCEPTION: main\r\nE/AndroidRuntime( 4197): Process: org.tensorflow.demo, PID: 4197\r\nE/AndroidRuntime( 4197): java.lang.NullPointerException: Attempt to invoke interface method 'void org.tensorflow.demo.Classifier.enableStatLogging(boolean)' on a null object reference\r\nE/AndroidRuntime( 4197):        at org.tensorflow.demo.ClassifierActivity.onSetDebug(ClassifierActivity.java:183)\r\nE/AndroidRuntime( 4197):        at org.tensorflow.demo.CameraActivity.onKeyDown(CameraActivity.java:381)\r\nE/AndroidRuntime( 4197):        at android.view.KeyEvent.dispatch(KeyEvent.java:2758)\r\nE/AndroidRuntime( 4197):        at android.app.Activity.dispatchKeyEvent(Activity.java:2755)\r\nE/AndroidRuntime( 4197):        at com.android.internal.policy.impl.PhoneWindow$DecorView.dispatchKeyEvent(PhoneWindow.java:2380)\r\nE/AndroidRuntime( 4197):        at android.view.ViewRootImpl$ViewPostImeInputStage.processKeyEvent(ViewRootImpl.java:4556)\r\nE/AndroidRuntime( 4197):        at android.view.ViewRootImpl$ViewPostImeInputStage.onProcess(ViewRootImpl.java:4512)\r\nE/AndroidRuntime( 4197):        at android.view.ViewRootImpl$InputStage.deliver(ViewRootImpl.java:4034)\r\nE/AndroidRuntime( 4197):        at android.view.ViewRootImpl$InputStage.onDeliverToNext(ViewRootImpl.java:4087)\r\nE/AndroidRuntime( 4197):        at android.view.ViewRootImpl$InputStage.forward(ViewRootImpl.java:4053)\r\nE/AndroidRuntime( 4197):        at android.view.ViewRootImpl$AsyncInputStage.forward(ViewRootImpl.java:4190)\r\nE/AndroidRuntime( 4197):        at android.view.ViewRootImpl$InputStage.apply(ViewRootImpl.java:4061)\r\nE/AndroidRuntime( 4197):        at android.view.ViewRootImpl$AsyncInputStage.apply(ViewRootImpl.java:4247)\r\nE/AndroidRuntime( 4197):        at android.view.ViewRootImpl$InputStage.deliver(ViewRootImpl.java:4034)\r\nE/AndroidRuntime( 4197):        at android.view.ViewRootImpl$InputStage.onDeliverToNext(ViewRootImpl.java:4087)\r\nE/AndroidRuntime( 4197):        at android.view.ViewRootImpl$InputStage.forward(ViewRootImpl.java:4053)\r\nE/AndroidRuntime( 4197):        at android.view.ViewRootImpl$InputStage.apply(ViewRootImpl.java:4061)\r\nE/AndroidRuntime( 4197):        at android.view.ViewRootImpl$InputStage.deliver(ViewRootImpl.java:4034)\r\nE/AndroidRuntime( 4197):        at android.view.ViewRootImpl$InputStage.onDeliverToNext(ViewRootImpl.java:4087)\r\nE/AndroidRuntime( 4197):        at android.view.ViewRootImpl$InputStage.forward(ViewRootImpl.java:4053)\r\nE/AndroidRuntime( 4197):        at android.view.ViewRootImpl$AsyncInputStage.forward(ViewRootImpl.java:4223)\r\nE/AndroidRuntime( 4197):        at android.view.ViewRootImpl$ImeInputStage.onFinishedInputEvent(ViewRootImpl.java:4393)\r\nE/AndroidRuntime( 4197):        at android.view.inputmethod.InputMethodManager$PendingEvent.run(InputMethodManager.java:2285)\r\nE/AndroidRuntime( 4197):        at android.view.inputmethod.InputMethodManager.invokeFinishedInputEventCallback(InputMethodManager.java:1909)\r\nE/AndroidRuntime( 4197):        at android.view.inputmethod.InputMethodManager.finishedInputEvent(InputMethodManager.java:1900)\r\nE/AndroidRuntime( 4197):        at android.view.inputmethod.InputMethodManager$ImeInputEventSender.onInputEventFinished(InputMethodManager.java:2262)\r\nE/AndroidRuntime( 4197):        at android.view.InputEventSender.dispatchInputEventFinished(InputEventSender.java:141)\r\nE/AndroidRuntime( 4197):        at android.os.MessageQueue.nativePollOnce(Native Method)\r\nE/AndroidRuntime( 4197):        at android.os.MessageQueue.next(MessageQueue.java:148)\r\nE/AndroidRuntime( 4197):        at android.os.Looper.loop(Looper.java:151)\r\nE/AndroidRuntime( 4197):        at android.app.ActivityThread.main(ActivityThread.java:5631)\r\nE/AndroidRuntime( 4197):        at java.lang.reflect.Method.invoke(Native Method)\r\nE/AndroidRuntime( 4197):        at java.lang.reflect.Method.invoke(Method.java:372)\r\nE/AndroidRuntime( 4197):        at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:959)\r\nE/AndroidRuntime( 4197):        at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:754)\r\n\r\n```\r\n\r\nI am not sure which part result in this , if any further information is needed , please tell me , thank you !\r\n\r\n", "comments": ["Sorry , it seems like the crash happens when TF Classify launch : \r\n\r\nHere is the log when app is implemented : \r\n```\r\n\r\nE/tensorflow(24851): CameraActivity: Exception!\r\nE/tensorflow(24851): java.lang.RuntimeException: Failed to load model from 'file:///android_asset/tensorflow_inception_graph.pb'\r\nE/tensorflow(24851):    at org.tensorflow.contrib.android.TensorFlowInferenceInterface.<init>(TensorFlowInferenceInterface.java:104)\r\nE/tensorflow(24851):    at org.tensorflow.demo.TensorFlowImageClassifier.create(TensorFlowImageClassifier.java:103)\r\nE/tensorflow(24851):    at org.tensorflow.demo.ClassifierActivity.onPreviewSizeChosen(ClassifierActivity.java:107)\r\nE/tensorflow(24851):    at org.tensorflow.demo.CameraActivity.onPreviewFrame(CameraActivity.java:111)\r\nE/tensorflow(24851):    at android.hardware.Camera$EventHandler.handleMessage(Camera.java:1274)\r\nE/tensorflow(24851):    at android.os.Handler.dispatchMessage(Handler.java:111)\r\nE/tensorflow(24851):    at android.os.Looper.loop(Looper.java:194)\r\nE/tensorflow(24851):    at android.app.ActivityThread.main(ActivityThread.java:5631)\r\nE/tensorflow(24851):    at java.lang.reflect.Method.invoke(Native Method)\r\nE/tensorflow(24851):    at java.lang.reflect.Method.invoke(Method.java:372)\r\nE/tensorflow(24851):    at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:959)\r\nE/tensorflow(24851):    at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:754)\r\nE/tensorflow(24851): Caused by: java.io.IOException: Not a valid TensorFlow Graph serialization: Invalid GraphDef\r\nE/tensorflow(24851):    at org.tensorflow.contrib.android.TensorFlowInferenceInterface.loadGraph(TensorFlowInferenceInterface.java:511)\r\nE/tensorflow(24851):    at org.tensorflow.contrib.android.TensorFlowInferenceInterface.<init>(TensorFlowInferenceInterface.java:96)\r\nE/tensorflow(24851):    ... 11 more\r\n\r\n```\r\n\r\nSo this problem probably is still  all about 'FIFOQueueV2'  , I will try to fix it up , and if any changes I will report again.", "I try again using the origin mobilenet from https://storage.googleapis.com/download.tensorflow.org/models/...  \r\n( change the INPUT_NAME also )\r\nBut the log still prints like above , and crash when turn on debug mode.\r\n\r\nI wonder is it possible result from the recent commit of tensorflow ? I update local repo yesterday.\r\nOr any other ideas ? ", "Here is some progress : \r\nI recovered TensorFlowInferenceInterface.java at tensorflow/contrib/android/java/org/tensorflow/contrib/android/ to version on Jul 29 , the original mobilenet works well now , no longer Failed to load model from 'file:///android_asset/tensorflow_inception_graph.pb' .\r\n\r\nBut still , the fine-tune model \r\n**\"Failed to load model from 'file:///android_asset/tensorflow_inception_graph.pb'\"** and crash when the debug mode turn on.\r\n\r\nThe error log is the same as \r\n\"**java.lang.NullPointerException: Attempt to invoke interface method 'void org.tensorflow.demo.Classifier.enableStatLogging(boolean)' on a null object reference**\" , \r\nI guess which is from \"FIFOQueueV2\" .\r\n\r\nHere is the result from \"summarize_graph\"\r\n```\r\nFound 1 possible inputs: (name=prefetch_queue/fifo_queue, type=float(1), shape=None)\r\nNo variables spotted.\r\nFound 1 possible outputs: (name=MobilenetV1/Predictions/Reshape_1, op=Reshape)\r\nFound 820331 (820.33k) const parameters, 0 (0) variable parameters, and 0 control_edges\r\nOp types used: 170 Const, 83 Mul, 56 Add, 55 Squeeze, 54 Mean, 28 Sub, 27 StopGradient, 27 SquaredDifference, 27 Rsqrt, 27 Relu6, 15 Conv2D, 13 DepthwiseConv2dNative, 2 Reshape, 1 QueueDequeueV2, 1 Softmax, 1 RealDiv, 1 RandomUniform, 1 Placeholder, 1 Floor, 1 BiasAdd, 1 AvgPool\r\nTo use with tensorflow/tools/benchmark:benchmark_model try these arguments:\r\nbazel run tensorflow/tools/benchmark:benchmark_model -- --graph=~/tensorflow/tensorflow/examples/android/assets/tensorflow_inception_graph.pb --show_flops --input_layer=prefetch_queue/fifo_queue --input_layer_type=float --input_layer_shape= --output_layer=MobilenetV1/Predictions/Reshape_1\r\n```\r\nIs it a weird thing there is no input_layer_shape ? ", "Did you found any solution for crash ?", "Did you found any solution for crash ?\r\n\r\n", "yes, check this [link](https://github.com/tensorflow/tensorflow/issues/16752) ", "Still i am facing the issue. Kindly help\r\n"]}, {"number": 13029, "title": "GMM clustering example not working", "body": "\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS 10.12.6\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: v1.0.0-rc2-15-g47bba63-dirty 1.0.0\r\n- **Python version**: Python 3.6.0 |Anaconda 4.3.1 (x86_64)| (default, Dec 23 2016, 13:19:00) \r\n- **Bazel version (if compiling from source)**: NA\r\n- **CUDA/cuDNN version**: NA\r\n- **GPU model and memory**: NA\r\n- **Exact command to reproduce**: python gmm_test.py\r\n\r\n### Describe the problem\r\nI'm trying to use the gaussian mixed model clustering algorithm from contrib. However, the gmm class is really buggy and I'm unable to get the test cases in the gmm_test.py file to work. \r\n\r\n### Source code / logs\r\nUsing the iris dataset from sklearn, I've tried to update the gmm.fit step to use it (as opposed to an input_fn). ", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 13028, "title": "Update README.md", "body": "", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->", "I'm not sure it's something that we want to merge. The comment has no place here."]}, {"number": 13027, "title": "persist nsync.a across different platform builds", "body": "Persist nsync.a across different platform builds via copying them into gen folder, then later make can manage them (clean or something else). nsync.a is required when the built tensorflow static lib is linked by other libs, while currently the nsync.a is cleaned from each build.", "comments": ["@resec, thanks for your PR! By analyzing the history of the files in this pull request, we identified @tensorflower-gardener to be a potential reviewer.", "Can one of the admins verify this patch?", "Jenkins, test this please.", "/CC @yifeif \r\n\r\nCan you describe a little more about the use case? I'm not sure I understand why this is needed.", "@drpngx when I am trying to build the another ios lib that is linking the Tensorflow static lib, the nsync.a is required as well for linking. If not provided, then below error would occur.\r\n\r\n```\r\nShowing Recent Messages\r\nLd /Users/resec/Library/Developer/Xcode/DerivedData/aabb-gflqvuqcsigceaevcvqprvmfrfol/Build/Products/Debug-iphonesimulator/aabb.app/aabb normal x86_64\r\n    cd /project/aabb_ios_demo\r\n    export IPHONEOS_DEPLOYMENT_TARGET=10.2\r\n    export PATH=\"/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/usr/bin:/Applications/Xcode.app/Contents/Developer/usr/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin\"\r\n    /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/clang++ -arch x86_64 -isysroot /Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator10.2.sdk -L/Users/resec/Library/Developer/Xcode/DerivedData/aabb-gflqvuqcsigceaevcvqprvmfrfol/Build/Products/Debug-iphonesimulator -F/Users/resec/Library/Developer/Xcode/DerivedData/aabb-gflqvuqcsigceaevcvqprvmfrfol/Build/Products/Debug-iphonesimulator -filelist /Users/resec/Library/Developer/Xcode/DerivedData/aabb-gflqvuqcsigceaevcvqprvmfrfol/Build/Intermediates/aabb.build/Debug-iphonesimulator/aabb.build/Objects-normal/x86_64/aabb.LinkFileList -Xlinker -rpath -Xlinker @executable_path/Frameworks -mios-simulator-version-min=10.2 -dead_strip -Xlinker -object_path_lto -Xlinker /Users/resec/Library/Developer/Xcode/DerivedData/aabb-gflqvuqcsigceaevcvqprvmfrfol/Build/Intermediates/aabb.build/Debug-iphonesimulator/aabb.build/Objects-normal/x86_64/aabb_lto.o -Xlinker -export_dynamic -Xlinker -no_deduplicate -Xlinker -objc_abi_version -Xlinker 2 -stdlib=libc++ -fobjc-arc -fobjc-link-runtime /project/agent/aabb/gen/sentencepiece/lib/libsentencepiece.a /project/agent/aabb/gen/protobuf_ios/lib/libprotobuf.a -force_load /project/agent/aabb/gen/lib/libtensorflow-core.a -Xlinker -sectcreate -Xlinker __TEXT -Xlinker __entitlements -Xlinker /Users/resec/Library/Developer/Xcode/DerivedData/aabb-gflqvuqcsigceaevcvqprvmfrfol/Build/Intermediates/aabb.build/Debug-iphonesimulator/aabb.build/aabb.app.xcent -lz -framework Accelerate -Xlinker -dependency_info -Xlinker /Users/resec/Library/Developer/Xcode/DerivedData/aabb-gflqvuqcsigceaevcvqprvmfrfol/Build/Intermediates/aabb.build/Debug-iphonesimulator/aabb.build/Objects-normal/x86_64/aabb_dependency_info.dat -o /Users/resec/Library/Developer/Xcode/DerivedData/aabb-gflqvuqcsigceaevcvqprvmfrfol/Build/Products/Debug-iphonesimulator/aabb.app/aabb\r\n\r\nUndefined symbols for architecture x86_64:\r\n  \"nsync::nsync_mu_rlock(nsync::nsync_mu_s_*)\", referenced from:\r\n      tensorflow::ResourceMgr::DoLookup(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::type_index, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tensorflow::ResourceBase**) const in libtensorflow-core.a(resource_mgr.o)\r\n  \"nsync::nsync_mu_runlock(nsync::nsync_mu_s_*)\", referenced from:\r\n      tensorflow::ResourceMgr::DoLookup(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::type_index, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tensorflow::ResourceBase**) const in libtensorflow-core.a(resource_mgr.o)\r\n  \"nsync::nsync_cv_wait(nsync::nsync_cv_s_*, nsync::nsync_mu_s_*)\", referenced from:\r\n      tensorflow::Notification::WaitForNotification() in libtensorflow-core.a(direct_session.o)\r\n      tensorflow::Notification::WaitForNotification() in libtensorflow-core.a(graph_runner.o)\r\n      tensorflow::Notification::WaitForNotification() in libtensorflow-core.a(cancellation.o)\r\n      tensorflow::Notification::WaitForNotification() in libtensorflow-core.a(op_kernel.o)\r\n      tensorflow::Notification::WaitForNotification() in libtensorflow-core.a(reader_base.o)\r\n      tensorflow::Notification::WaitForNotification() in libtensorflow-core.a(rendezvous.o)\r\n      tensorflow::grappler::MeasuringCostEstimator::PredictCosts(tensorflow::GraphDef const&, tensorflow::CostGraphDef*, tensorflow::grappler::Costs*) const in libtensorflow-core.a(measuring_cost_estimator.o)\r\n      ...\r\n  \"nsync::nsync_from_time_point_(std::__1::chrono::time_point<std::__1::chrono::system_clock, std::__1::chrono::duration<long long, std::__1::ratio<1l, 1000000l> > >)\", referenced from:\r\n      std::__1::cv_status tensorflow::condition_variable::wait_for<long long, std::__1::ratio<1l, 1000l> >(tensorflow::mutex_lock&, std::__1::chrono::duration<long long, std::__1::ratio<1l, 1000l> >) in libtensorflow-core.a(allocator_retry.o)\r\n      std::__1::cv_status tensorflow::condition_variable::wait_for<long long, std::__1::ratio<1l, 1000000l> >(tensorflow::mutex_lock&, std::__1::chrono::duration<long long, std::__1::ratio<1l, 1000000l> >) in libtensorflow-core.a(direct_session.o)\r\n      std::__1::cv_status tensorflow::condition_variable::wait_for<long long, std::__1::ratio<1l, 1000000l> >(tensorflow::mutex_lock&, std::__1::chrono::duration<long long, std::__1::ratio<1l, 1000000l> >) in libtensorflow-core.a(rendezvous.o)\r\n      std::__1::cv_status tensorflow::condition_variable::wait_for<long long, std::__1::ratio<1l, 1000000l> >(tensorflow::mutex_lock&, std::__1::chrono::duration<long long, std::__1::ratio<1l, 1000000l> >) in libtensorflow-core.a(utils.o)\r\n  \"nsync::nsync_mu_unlock(nsync::nsync_mu_s_*)\", referenced from:\r\n      tensorflow::AllocatorRetry::AllocateRaw(std::__1::function<void* (unsigned long, unsigned long, bool)>, int, unsigned long, unsigned long) in libtensorflow-core.a(allocator_retry.o)\r\n      tensorflow::BFCAllocator::AllocateRawInternal(unsigned long, unsigned long, bool) in libtensorflow-core.a(bfc_allocator.o)\r\n      tensorflow::BFCAllocator::DeallocateRaw(void*) in libtensorflow-core.a(bfc_allocator.o)\r\n      tensorflow::BFCAllocator::DeallocateRawInternal(void*) in libtensorflow-core.a(bfc_allocator.o)\r\n      tensorflow::BFCAllocator::AddAllocVisitor(std::__1::function<void (void*, unsigned long)>) in libtensorflow-core.a(bfc_allocator.o)\r\n      tensorflow::BFCAllocator::RequestedSize(void*) in libtensorflow-core.a(bfc_allocator.o)\r\n      tensorflow::BFCAllocator::AllocatedSize(void*) in libtensorflow-core.a(bfc_allocator.o)\r\n      ...\r\n  \"nsync::nsync_cv_wait_with_deadline(nsync::nsync_cv_s_*, nsync::nsync_mu_s_*, timespec, nsync::nsync_note_s_*)\", referenced from:\r\n      std::__1::cv_status tensorflow::condition_variable::wait_for<long long, std::__1::ratio<1l, 1000l> >(tensorflow::mutex_lock&, std::__1::chrono::duration<long long, std::__1::ratio<1l, 1000l> >) in libtensorflow-core.a(allocator_retry.o)\r\n      std::__1::cv_status tensorflow::condition_variable::wait_for<long long, std::__1::ratio<1l, 1000000l> >(tensorflow::mutex_lock&, std::__1::chrono::duration<long long, std::__1::ratio<1l, 1000000l> >) in libtensorflow-core.a(direct_session.o)\r\n      std::__1::cv_status tensorflow::condition_variable::wait_for<long long, std::__1::ratio<1l, 1000000l> >(tensorflow::mutex_lock&, std::__1::chrono::duration<long long, std::__1::ratio<1l, 1000000l> >) in libtensorflow-core.a(rendezvous.o)\r\n      std::__1::cv_status tensorflow::condition_variable::wait_for<long long, std::__1::ratio<1l, 1000000l> >(tensorflow::mutex_lock&, std::__1::chrono::duration<long long, std::__1::ratio<1l, 1000000l> >) in libtensorflow-core.a(utils.o)\r\n  \"nsync::nsync_mu_lock(nsync::nsync_mu_s_*)\", referenced from:\r\n      tensorflow::AllocatorRetry::AllocateRaw(std::__1::function<void* (unsigned long, unsigned long, bool)>, int, unsigned long, unsigned long) in libtensorflow-core.a(allocator_retry.o)\r\n      tensorflow::BFCAllocator::AllocateRawInternal(unsigned long, unsigned long, bool) in libtensorflow-core.a(bfc_allocator.o)\r\n      tensorflow::BFCAllocator::DeallocateRaw(void*) in libtensorflow-core.a(bfc_allocator.o)\r\n      tensorflow::BFCAllocator::DeallocateRawInternal(void*) in libtensorflow-core.a(bfc_allocator.o)\r\n      tensorflow::BFCAllocator::AddAllocVisitor(std::__1::function<void (void*, unsigned long)>) in libtensorflow-core.a(bfc_allocator.o)\r\n      tensorflow::BFCAllocator::RequestedSize(void*) in libtensorflow-core.a(bfc_allocator.o)\r\n      tensorflow::BFCAllocator::AllocatedSize(void*) in libtensorflow-core.a(bfc_allocator.o)\r\n      ...\r\n  \"nsync::nsync_cv_broadcast(nsync::nsync_cv_s_*)\", referenced from:\r\n      tensorflow::BFCAllocator::DeallocateRaw(void*) in libtensorflow-core.a(bfc_allocator.o)\r\n      tensorflow::DirectSession::Run(tensorflow::RunOptions const&, std::__1::vector<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::Tensor>, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::Tensor> > > const&, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&, std::__1::vector<tensorflow::Tensor, std::__1::allocator<tensorflow::Tensor> >*, tensorflow::RunMetadata*) in libtensorflow-core.a(direct_session.o)\r\n      tensorflow::Notification::Notify() in libtensorflow-core.a(direct_session.o)\r\n      tensorflow::Notification::Notify() in libtensorflow-core.a(graph_runner.o)\r\n      tensorflow::Notification::Notify() in libtensorflow-core.a(cancellation.o)\r\n      tensorflow::Notification::Notify() in libtensorflow-core.a(op_kernel.o)\r\n      tensorflow::Notification::Notify() in libtensorflow-core.a(reader_base.o)\r\n      ...\r\n  \"nsync::nsync_mu_init(nsync::nsync_mu_s_*)\", referenced from:\r\n      tensorflow::AllocatorRetry::AllocatorRetry() in libtensorflow-core.a(allocator_retry.o)\r\n      tensorflow::AllocatorRetry::AllocatorRetry() in libtensorflow-core.a(allocator_retry.o)\r\n      tensorflow::BFCAllocator::BFCAllocator(tensorflow::SubAllocator*, unsigned long, bool, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&) in libtensorflow-core.a(bfc_allocator.o)\r\n      tensorflow::(anonymous namespace)::get_device_factory_lock() in libtensorflow-core.a(device_factory.o)\r\n      tensorflow::DirectSession::DirectSession(tensorflow::SessionOptions const&, tensorflow::DeviceMgr const*, tensorflow::DirectSessionFactory*) in libtensorflow-core.a(direct_session.o)\r\n      tensorflow::DirectSession::Run(tensorflow::RunOptions const&, std::__1::vector<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::Tensor>, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::Tensor> > > const&, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&, std::__1::vector<tensorflow::Tensor, std::__1::allocator<tensorflow::Tensor> >*, tensorflow::RunMetadata*) in libtensorflow-core.a(direct_session.o)\r\n      tensorflow::DirectSession::PRunSetup(std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >*) in libtensorflow-core.a(direct_session.o)\r\n      ...\r\n  \"nsync::nsync_cv_init(nsync::nsync_cv_s_*)\", referenced from:\r\n      tensorflow::AllocatorRetry::AllocatorRetry() in libtensorflow-core.a(allocator_retry.o)\r\n      tensorflow::AllocatorRetry::AllocatorRetry() in libtensorflow-core.a(allocator_retry.o)\r\n      tensorflow::DirectSession::RunState::RunState(std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&, long long, std::__1::vector<tensorflow::Device*, std::__1::allocator<tensorflow::Device*> > const*) in libtensorflow-core.a(direct_session.o)\r\n      tensorflow::Executor::Run(tensorflow::Executor::Args const&) in libtensorflow-core.a(graph_runner.o)\r\n      tensorflow::CancellationManager::CancellationManager() in libtensorflow-core.a(cancellation.o)\r\n      tensorflow::AsyncOpKernel::Compute(tensorflow::OpKernelContext*) in libtensorflow-core.a(op_kernel.o)\r\n      tensorflow::ReaderBase::GetNextWorkLocked(tensorflow::QueueInterface*, tensorflow::OpKernelContext*) const in libtensorflow-core.a(reader_base.o)\r\n      ...\r\nld: symbol(s) not found for architecture x86_64\r\nclang: error: linker command failed with exit code 1 (use -v to see invocation)\r\n```\r\n\r\nSame case occurred in Android when linking with Tensorflow static lib.\r\n\r\nHowever, the build script is cleaning the built nsync lib across different builds, and the nsync lib is stored in a place that is different than other dependency libs (e.g. protobuf).\r\n\r\nSo Here is to copy the generated libs into gen folder like other lib would be placed when generated, so user or `make` can manage them in a consist way.\r\n\r\nHope these make sense to you, thanks.", "@resec just to understand the scenario better, why are you running two builds? What are the builds that you are running? thanks.", "@drpngx I have multiple projects are using different tf built model on Android/iOS mobile device. And I am pre-building the tf and its dependencies lib, before I build my projects(to save compilation time and unifying the tf version for my projects). It was done by gathering(copying) required generated libs and headers files from tf and its dependencies to my projects. \r\n\r\nAdditional information, my projects are not building with bezel.", "@drpngx do you have an update for this?", "Sorry, not sure why this was not sent: why can't use the `$arch` file that's already built, ie why do we need to copy this somewhere else?", "@drpngx \r\n\r\n> However, the build script is cleaning the built nsync lib across different builds, and the nsync lib is stored in a place that is different than other dependency libs (e.g. protobuf).\r\nSo Here is to copy the generated libs into gen folder like other lib would be placed when generated, so user or make can manage them in a consist way.", "Why can't you run the script, collect the artifact, before you start another build?", "@drpngx then users can not reuse those build scripts existed in tensorflow, and have to write their own one.\r\n\r\nAny first-time user trying to build the tensorflow lib, would very likely meet I met, and feel strange and uncomfortable. User can either just like you said, write another script,  then \"run the script, collect the artifact, before you start another build?\", or like what I did, just add some lines somewhere to copy the libs.\r\n\r\nCopying will remove those obtascles. ", "drpngx@ I have no objections to this, but I also skeptical about the long term prospects of this makefile build in general, so I may not be the best person to ask.\r\n\r\n@petewarden Do you have an opinion on this?", "@resec the build drops the lib in a place that's specific to the arch etc. If you move it somewhere else, it loses the information. If it survives cleanups, then it's adding a confusing side effect with weaker guarantees on which people would accidentally depend. I'd rather we avoid this.", "@drpngx just FYI, the arch etc info is kept via folder/path just like tensorflow and protobuf lib.", "What do you mean? It's copied to `${makefile_dir}/gen/nsync`, and `makefile_dir=tensorflow/contrib/makefile`.", "@drpngx please see \r\nhttps://github.com/resec/tensorflow/blob/d3784bd37d493faee266ee9311a5a4b91bb5d7e4/tensorflow/contrib/makefile/compile_nsync.sh#L133 \r\nand \r\nhttps://github.com/resec/tensorflow/blob/d3784bd37d493faee266ee9311a5a4b91bb5d7e4/tensorflow/contrib/makefile/compile_nsync.sh#L191\r\nThe final destination folder is arch-related.", "Why is it sometimes with arch (as in the two examples) and sometimes not (e.g. mac)?", "@drpngx it is simply following the current handling of tensorflow, protobuf lib.\r\n\r\nIf the lib is building for mobile, then lib is stored in a arch-related folder, if is it building for \"server-side\" (I guess the designer somehow assumed that if it is building for linux/mac, then it is building for host), then the lib is just stored into a \"lib\" without arch info.\r\n\r\nIf we want to change them, I think we should change them (including tensorflow, etc.) all together.", "Isn't what `$bin_prefix` is doing?", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly."]}, {"number": 13026, "title": "Get sysroot path in a robust way for nsync ios build", "body": "The sysroot path in nsync ios build is hardcoded. this PR changed it to use `xcrun`, just like how other build scripts did.", "comments": ["Can one of the admins verify this patch?"]}, {"number": 13025, "title": "Branch 168619288", "body": "", "comments": ["@tensorflow-jenkins , test this please", "api_compatibility_test is failing. But it is not due to commits in this PR. So I'm merging this PR."]}, {"number": 13024, "title": "nightly link broken on github README.md", "body": "On github page, nightly for Linux GPU Python 3.5 is broken, points to\r\n\r\nhttps://ci.tensorflow.org/view/Nightly/job/nightly-matrix-linux-gpu/TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON3.5,label=gpu-linux/lastSuccessfulBuild/artifact/pip_test/whl/tensorflow_gpu-1.4.0dev-cp35-cp35m-linux_x86_64.whl\r\n\r\n![screenshot 2017-09-13 17 28 11](https://user-images.githubusercontent.com/23068/30406796-00aa9d00-98a9-11e7-8d7b-4226c2401df7.png)\r\n\r\n\r\n![screenshot 2017-09-13 17 28 56](https://user-images.githubusercontent.com/23068/30406804-130eaa40-98a9-11e7-887d-00a39ec0bdc5.png)\r\n", "comments": ["cc @gunan in case he knows where those links come from", "We just updated the way nightlies are versioned. tonight after the first pip packages are generated it should be fixed.\r\nWe are also planning to move all our nightly pip packages to pypi, which will resolve repeated breakage in nightly links.", "We have rolled out [tf-nightly](https://pypi.python.org/pypi/tf-nightly) packages and I've [merged](https://github.com/tensorflow/tensorflow/pull/13198) a fix for the links. The package name has changed, but these are consistently built every night."]}, {"number": 13023, "title": "Invalid argument: shape must be a vector of {int32,int64}, got shape []", "body": "I try to use the interface of RandomUniform as follows:\r\n\r\n```\r\nfunc TestRandomUniform(t *testing.T) {\r\n\troot := op.NewScope()\r\n\r\n\tT := op.Placeholder(root.SubScope(\"input\"), tf.Int64)\r\n\r\n\tseed := op.RandomUniformSeed(-1.0)\r\n\tseed2 := op.RandomUniformSeed2(1.0)\r\n\tproduct := op.RandomUniform(root,T,tf.Float,seed,seed2)\r\n\r\n\r\n\tgraph, err := root.Finalize()\r\n\tif err != nil {\r\n\t\tpanic(err.Error())\r\n\t}\r\n\r\n\tvar sess *tf.Session\r\n\tsess, err = tf.NewSession(graph, &tf.SessionOptions{})\r\n\tif err != nil {\r\n\t\tpanic(err.Error())\r\n\t}\r\n\r\n\tvar A *tf.Tensor\r\n\r\n\tif A, err = tf.NewTensor(int64(1)); err != nil {\r\n\t\tpanic(err.Error())\r\n\t}\r\n\r\n\tvar results []*tf.Tensor\r\n\tif results, err = sess.Run(\r\n\t\tmap[tf.Output]*tf.Tensor{\r\n\t\t\tT: A,\r\n\t\t},\r\n\t\t[]tf.Output{product}, nil); err != nil {\r\n\t\t\tpanic(err.Error())\r\n\t}\r\n\tfor _, result := range results {\r\n\t\tfmt.Println(result.Value().([]int64))\r\n\t}\r\n\r\n}\r\n```\r\n\r\n```\r\nInvalid argument: shape must be a vector of {int32,int64}, got shape []\r\npanic: shape must be a vector of {int32,int64}, got shape []\r\n\t [[Node: RandomUniform = RandomUniform[T=DT_INT64, _class=[], dtype=DT_FLOAT, seed=-1, seed2=1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_arg_input/Placeholder_0_0)]] [recovered]\r\n\tpanic: shape must be a vector of {int32,int64}, got shape []\r\n\t [[Node: RandomUniform = RandomUniform[T=DT_INT64, _class=[], dtype=DT_FLOAT, seed=-1, seed2=1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_arg_input/Placeholder_0_0)]]\r\n\r\ngoroutine 5 [running]\r\n```\r\n\r\nBut it  prints the error for me. What's it means?I am not good at c.And where are the demo i can find?", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 13022, "title": "Give accumulate_n op a gradient", "body": "This pull request addresses issue #10607 by adding a gradient to the existing `accumulate_n` operator. I followed the approach suggested by @alextp: rewrite `accumulate_n` as an atomic op which has a gradient defined for it and which gets rewritten by the runtime into the current implementation. Previously, this op had been implemented in Python as a constellation of lower-level ops, some of which are not differentiable.\r\n\r\n**Implementation Details**\r\nI have added a new C++ op, `AccumulateN`, which serves as a placeholder for type inference and gradient computation. A new rewrite, implemented in `accumulate_n_optimizer.cc`, replaces this placeholder with a group of `AssignAdd` ops and some additional ops that create, initialize, and destroy temporary variables.\r\n\r\nThe original Python code for `accumulate_n` has been replaced by a function that validates its arguments and creates an instance of the `AccumulateN` placeholder op.\r\n\r\n**Testing**\r\nI added a more complete set of tests for `accumulate_n` in a previous pull request (https://github.com/tensorflow/tensorflow/pull/12196) to ensure that the op would still be correct after the changes in the current pull request. I also added one additional test to verify that `accumulate_n` now has a gradient. All the tests under `//tensorflow/python/...` currently pass on my MacOS and Linux test machines.\r\n\r\n**Things to Note**\r\nThe semantics of the new implementation are broadly the same as the original, with the exception of one corner case. The original implementation allowed all the inputs to `accumulate_n` to have an undefined shape. My new code requires that at least one input have a defined shape; or that the user provides a shape using the `shape` argument to the `accumulate_n` function.\r\n\r\nWhile implementing the `AccumulateN` op, I noticed that the code to do the kind of shape initialization I needed was repeated verbatim at several places in the TensorFlow code base. I refactored this code into a new function `shape_inference::ExplicitShape()` and replaced all the existing copies.\r\n\r\n\r\n", "comments": ["Can one of the admins verify this patch?", "I will be splitting this PR into two sets of changes: One change set with the refactoring changes around the `ExplicitShape()` function I added to `common_shape_fns.cc`; and a second change set that adds a new `AccumulateN`-like op to `contrib/framework`.", "Closing this PR in favor of https://github.com/tensorflow/tensorflow/pull/13325"]}, {"number": 13021, "title": "Fixes in MKL add_n  to address several regressions", "body": "Fixed failures due to scalar and empty tensors", "comments": ["@agramesh1, thanks for your PR! By analyzing the history of the files in this pull request, we identified @jinghuangintel to be a potential reviewer.", "Can one of the admins verify this patch?", "@rmlarsen could you take a look?", "Gentle ping, @rmlarsen", "@tensorflow-jenkins test this please", "@tensorflow-jenkins test this please", "@agramesh1 thanks for the improvement."]}, {"number": 13019, "title": "Failed to Load the native TensorFlow Runtime", "body": "I installed tensorflow through Anaconda with Python 3.6.2 . It got installed successfully. But I am not able to import tensorflow. and I am using a 64 bit machine with Windows 10 OS. I got following error:\r\n\r\n>>> import tensorflow as tf\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\HP\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 18, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"C:\\Users\\HP\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 978, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 961, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 950, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 648, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 560, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 922, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 205, in _call_with_frames_removed\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\HP\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 41, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\HP\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 21, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\HP\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 20, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow_internal')\r\n  File \"C:\\Users\\HP\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nModuleNotFoundError: No module named '_pywrap_tensorflow_internal'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Users\\HP\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"C:\\Users\\HP\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\HP\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 52, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\HP\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 18, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"C:\\Users\\HP\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 978, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 961, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 950, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 648, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 560, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 922, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 205, in _call_with_frames_removed\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\HP\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 41, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\HP\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 21, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\HP\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 20, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow_internal')\r\n  File \"C:\\Users\\HP\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nModuleNotFoundError: No module named '_pywrap_tensorflow_internal'\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.", "comments": ["/CC @mrry any ideas?", "Try following the instructions [here](https://www.tensorflow.org/install/install_windows#validate_your_installation), and if those fail to help please answer all of the questions in the issue template so we can triage the problem.", "Pay attention to CUDA operation, since exactly this error is reported when CUDA is not working at all. Try from cmd e.g. c:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v8.0\\extras\\demo_suite>oceanFFT.exe  \r\nIf it fails, try to update driver (Device manager / Display adapters / NVIDIA...) of your graphics card."]}, {"number": 13018, "title": "Add `Dataset.from_variable_length` to accept numpy arrays with varying length", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac OS x\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: `v1.3.0-rc2-20-g0787eee 1.3.0`\r\n- **Python version**: `Python 3.5.2 :: Continuum Analytics, Inc.`\r\n- **Bazel version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**: \r\n```\r\nimport numpy as np\r\nfrom tensorflow.contrib.data import Dataset\r\na=[np.arange(3), np.arange(5)]\r\nDataset.from_tensor_slices(np.asarray(a))\r\n```\r\n\r\n### Describe the problem\r\n`Dataset` has a nice `.padded_batch` feature which allows padding batches to ensure all tensors have the same size, which is very nice for the common use-case of having sequences of different lengths.\r\n\r\nHowever, it seems impossible to create such a dataset from a list of numpy array with different lengths. See command above.\r\n\r\nIt would be very nice to have a `Dataset.from_variable_length_tensor_slices` or such that could take such inputs.\r\n\r\nI know I'm supposed to use a `TextLineDataset` or something similar, and then use a series of map functions, but I think tensorflow should support doing all of the pre-processing outside of tensorflow instead of forcing it into a delayed execution graph paradigm, which is harder to reason about and debug. Also, my data is stored in JSON files, and requires complex pre-processing, so the `TextLineDataset/map` approach doesn't cut it.", "comments": ["You can use the new `Dataset.from_generator()` to do this (and in general wrap any Python code written as a generator in a `Dataset`):\r\n\r\n```python\r\na = [np.arange(3), np.arange(5)]\r\ndataset = tf.contrib.data.Dataset.from_generator(lambda: a, tf.int64)\r\n```\r\n\r\n[EDIT: Fixed code to reflect @rasmusbergpalm's correction... thanks!]", "Yes that works beautifully. Thanks!\r\n\r\nOne small change to the code:\r\n\r\n```python\r\na = [np.arange(3), np.arange(5)]\r\ndataset = tf.contrib.data.Dataset.from_generator(lambda: a, tf.int64)\r\n```", "It doesn't seem to be in 1.3... when will this be released? What's the minimal thing I can do the get it *now*? :smile_cat:\r\n\r\nEDIT: or is there some other nice way of using a list of variable sized numpy arrays with a Dataset?\r\nEDIT2: OK I just copypasted the corresponding dataset module...", "@harpone: `pip install tf-nightly` should do it!\r\n\r\nBut as you observed in EDIT2, the code in `Dataset.from_generator()` is built entirely out of transformations that were available in TF 1.3, so you can copy its implementation into your project and use it directly.", "@mrry Yeah already installed a nightly build but thanks! BTW I'm getting some weirdness with (yesterday's) nightly: I'm doing\r\n\r\n```\r\n    def input_fn():\r\n        \r\n        if y is not None:\r\n            data_this = [(x_, y_) for x_, y_ in zip(x, y)]\r\n        else:\r\n            data_this = x\r\n\r\n        dataset = tf.contrib.data.Dataset.from_generator(lambda: data_this, (tf.float32, tf.float32))\r\n        dataset = dataset.map(cropper)\r\n        dataset = dataset.repeat(epochs)\r\n        if shuffle:\r\n            dataset = dataset.shuffle(buffer_size=10000)\r\n        dataset = dataset.batch(batch_size)\r\n        iterator = dataset.make_one_shot_iterator()\r\n\r\n        if y is not None:\r\n            features, targets = iterator.get_next()\r\n            return features, targets\r\n```\r\nwith a dataset formed of lists of same but varying shape x, y tensors. I get\r\n`2017-09-23 12:26:55.844395: W tensorflow/core/framework/op_kernel.cc:1192] Out of range: StopIteration: Iteration finished.` which repeats `epoch` number of before the actual training. If I just do `.repeat()` it just throws the Out of range message forever...\r\n\r\nAnyway, I'm starting to really like the Dataset class (together with the Estimator). Really impressive work :)\r\n\r\nEDIT: I think the preoblem occurs because the generator is spitting out an entire batch of data instead of single `(feature, label)` at a time...", "`a = [np.arange(3), np.arange(5)] `\r\n`dataset = tf.contrib.data.Dataset.from_generator(lambda: a, tf.int64)`\r\n`ds1=dataset.repeat(10)`\r\n`value = ds1.make_one_shot_iterator().get_next()`\r\n `sess.run(value)   /// first element`\r\n `sess.run(value)   /// second element`\r\n` sess.run(value) // Out of range message`\r\n`\r\n\r\nthrows OutOfRangeError : End of sequence\r\n", "@harpone did **just** copying \r\ntensorflow/tensorflow/contrib/data/python/ops/ suffice when using 1.3 as the base installation ?\r\n\r\nFor me it gave error\r\n```\r\nFile \"tf1.3/lib/python2.7/site-packages/tensorflow/contrib/data/python/ops/dataset_ops.py\", line 22, in <module>\r\n    from tensorflow.python.data.ops import dataset_ops\r\nImportError: No module named data.ops\r\n```\r\n\r\n\r\nI tried copying\r\n../tf1.4/lib/python2.7/site-packages/tensorflow/python/data  to tf1.3 but then had other errors \r\n\r\n```\r\nvalue = ds.make_one_shot_iterator().get_next()\r\n  File \"tf1.3/lib/python2.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 411, in make_one_shot_iterator\r\n    _make_dataset.add_to_graph(ops.get_default_graph())\r\n  File \"tf1.3/lib/python2.7/site-packages/tensorflow/python/framework/function.py\", line 449, in add_to_graph\r\n    self._create_definition_if_needed()\r\n  File \"tf1.3/lib/python2.7/site-packages/tensorflow/python/framework/function.py\", line 384, in _create_definition_if_needed\r\n    **self._extra_kwargs)\r\n  File \"tf1.3/lib/python2.7/site-packages/tensorflow/python/framework/function.py\", line 999, in _parse_kwargs_as_attrs\r\n    raise ValueError(\"Unknown keyword arguments: %s\" % kwargs.keys())\r\nValueError: Unknown keyword arguments: ['capture_by_value']\r\n\r\n```\r\n", "I actually got some other errors when I tried the copying, but yeah, no... I just created a new virtual env and installed the nightly."]}, {"number": 13017, "title": "tf.extract_image_patches gradient transpose extremely slow", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS 10.12.6\r\n- **TensorFlow installed from (source or binary)**: Binary, official docker image\r\n- **TensorFlow version (use command below)**: v1.3.0-rc2-20-g0787eee 1.3.0\r\n- **Python version**: 3.5\r\n\r\n### Problem\r\nBackprop through `extract_image_patches` is extremly slow, specifically the `transpose` call. It appears to be this specific call: [tensorflow/python/ops/array_grad.py#L747](https://github.com/tensorflow/tensorflow/blob/f282bb1/tensorflow/python/ops/array_grad.py#L747)\r\n\r\n### Logs\r\nTimeline of the problem:\r\n\r\n<img width=\"1723\" alt=\"screen shot 2017-09-13 at 16 01 49\" src=\"https://user-images.githubusercontent.com/3015996/30382640-f5a003b8-989f-11e7-871c-1aae1a51102b.png\">\r\n\r\nComparable timeline when using conv2d (which, in its Eigen implementation, also [extracts image patches](https://github.com/tensorflow/tensorflow/blob/f282bb1/tensorflow/core/kernels/eigen_spatial_convolutions.h#L1063-L1064)):\r\n<img width=\"1300\" alt=\"screen shot 2017-09-13 at 16 08 45\" src=\"https://user-images.githubusercontent.com/3015996/30382983-e898d338-98a0-11e7-9e76-1ba01e571c0d.png\">\r\n\r\n", "comments": ["@ahoereth What are the dimensions of the input tensors? Can you post code that reproduces the problem and outputs the timeline file?", "You are correct, it only occurs when the input grows over a specific size.\r\n\r\nHere a code example with some random computations:\r\n\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow.python.client import timeline\r\n\r\nsize = 21\r\nchannels = 64\r\n\r\nx = tf.random_uniform((100, 20))\r\nw0 = tf.get_variable('w', (20, size * size * channels))\r\nh = tf.reshape(tf.matmul(x, w0), (100, size, size, channels))\r\nout = tf.extract_image_patches(images=h,\r\n                               ksizes=(1, 5, 5, 1),\r\n                               strides=(1, 1, 1, 1),\r\n                               rates=(1, 1, 1, 1),\r\n                               padding='VALID')\r\n\r\nloss = tf.reduce_mean(out)\r\nop = tf.train.AdamOptimizer().minimize(out)\r\n\r\noptions = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\r\nrun_metadata = tf.RunMetadata()\r\nwith tf.Session() as sess:\r\n    sess.run(tf.global_variables_initializer())\r\n    sess.run(op, run_metadata=run_metadata, options=options)\r\n    tl = timeline.Timeline(run_metadata.step_stats)\r\n    ctf = tl.generate_chrome_trace_format()\r\n    with open('timeline.json', 'w') as f:\r\n        f.write(ctf)\r\n```\r\n\r\nRunning this as above with  `size = 21` gives me the following timeline, note the time (3000ms+):\r\n<img width=\"1337\" alt=\"screen shot 2017-09-14 at 11 36 02\" src=\"https://user-images.githubusercontent.com/3015996/30422734-1f798f8c-9941-11e7-872f-497f05fc1d80.png\">\r\n\r\nRunning it with `size = 20` instead, results in this timeline (~8ms):\r\n<img width=\"1306\" alt=\"screen shot 2017-09-14 at 11 36 28\" src=\"https://user-images.githubusercontent.com/3015996/30422785-3c849c2a-9941-11e7-8beb-55f240cd83d6.png\">\r\n\r\nWe just ran this test on multiple MacBooks (mid 2015, TensorFlow 1.3, both with Python 3.5 and 3.6) and an Ubuntu 16.04 desktop (TensorFlow 1.2.1, i7 with 4ghz, 31gb memory), all with very similar results (thanks @shoeffner).", "Thank you for the code sample! I can reproduce this on 1.3, but not on master, so I'm assuming its fixed and closing the issue. Feel free to reopen if you find a case where it's still slow on master.", "Just ran it using the current nightly-py3 docker tag and yes, it got a lot better, but still slower by a factor of ten:\r\n\r\n`size=21`:\r\n<img width=\"1306\" alt=\"screen shot 2017-09-14 at 19 29 23\" src=\"https://user-images.githubusercontent.com/3015996/30444418-339d194c-9983-11e7-97c0-6008b90c91b8.png\">\r\n\r\n`size=20`:\r\n<img width=\"1287\" alt=\"screen shot 2017-09-14 at 19 30 12\" src=\"https://user-images.githubusercontent.com/3015996/30444419-339d1320-9983-11e7-8f85-6a56eafeaa5d.png\">\r\n\r\nWill run again tomorrow to see if it changed just today, but this still seems like an extreme slow down at a very specific point (`size=22` appear to not result in performance like that anymore).", "You're right, it its still significantly slower when `size=21`. \r\n\r\nWhen disabling optimizations, the case where `size=20` slows down to about the speed of `size=21`, which makes me suspect certain optimizations are only applied when `size=20`. Disabling optimizations when `size=21` does not significantly affect performance.\r\n\r\n/CC @zhangyaobit, can you comment on whether optimizations are being applied when `size=20`? A code sample with warmup batches with optmizations disabled is below:\r\n\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow.python.client import timeline\r\nimport time\r\n\r\nsize = 21\r\nchannels = 64\r\n\r\nwith tf.device('/CPU:0'):\r\n  x = tf.random_uniform((100, 20))\r\n  w0 = tf.get_variable('w', (20, size * size * channels))\r\n  h = tf.reshape(tf.matmul(x, w0), (100, size, size, channels))\r\n  out = tf.extract_image_patches(images=h,\r\n                                 ksizes=(1, 5, 5, 1),\r\n                                 strides=(1, 1, 1, 1),\r\n                                 rates=(1, 1, 1, 1),\r\n                                 padding='VALID')\r\n\r\n  loss = tf.reduce_mean(out)\r\n  op = tf.train.AdamOptimizer().minimize(out)\r\n\r\n  options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\r\n  run_metadata = tf.RunMetadata()\r\n  optimizer_options = tf.OptimizerOptions(opt_level=tf.OptimizerOptions.L0)\r\n  config = tf.ConfigProto(\r\n      graph_options=tf.GraphOptions(optimizer_options=optimizer_options))\r\n  with tf.Session(config=config) as sess:\r\n    sess.run(tf.global_variables_initializer())\r\n    for _ in range(10):  # Warmup\r\n      sess.run(op)\r\n    start_time = time.time()\r\n    for _ in range(50):\r\n      sess.run(op)\r\n    total_time = time.time() - start_time\r\n    print('total time: {}'.format(total_time))\r\n    sess.run(op, run_metadata=run_metadata, options=options)\r\n    tl = timeline.Timeline(run_metadata.step_stats)\r\n    ctf = tl.generate_chrome_trace_format()\r\n    with open('timeline.json', 'w') as f:\r\n      f.write(ctf)\r\n```", "I think you can try (1) benchmark transpose alone with size = 20 and size = 21; and (2) turn on/off optimizations individually to see which optimization is related (https://github.com/tensorflow/tensorflow/blob/r1.3/tensorflow/core/protobuf/config.proto#L85). I know constant folding won't be applied if the size of the constant in bytes is too large (> 10M) to  prevents the size of the Graph from growing too large. But I don't see how it could be related to transpose, which I don't think could be folded anyway.", "@zhangyaobit, assigning to you to keep continuity of this performance problem.", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "Some performance profiling (e.g. with pprof: https://github.com/google/pprof) needs to be done for extract_image_patches and the transpose in the gradient op for the mentioned input sizes (preferably with two standalone benchmarks respectively for extract_image_patches's gradient op and transpose), in order to identify the slow part of the code and to suggest a potential fix.\r\n\r\nMarking this as contribution welcome for now.", "Is there any progress on this issue? I'm seeing a similar dramatic slow-down when using extract_image_patches with tensors beyond a certain size.", "Hi @ahoereth! We are checking to see if you still need help in this issue , Have you tried latest stable version TF 2.6  yet?I was getting 2.94 ms after using migration document in Colab . Attaching [Gist](https://colab.research.google.com/gist/mohantym/ca610cde83b2fc0574fbb883041d4598/github_13017.ipynb) for Reference.  Please create a new issue if the issue is replicating in newer version. Thanks!", "Are you satisfied with the resolution of your issue?\r\n[Yes](https://goo.gl/forms/Oe0tEvODFRoI2gJF3)\r\n[No](https://goo.gl/forms/fUjzOfrtkFbrOT8d2)"]}, {"number": 13015, "title": "Ubuntu installation instruction is too obsolete!", "body": "For successful build on Ubuntu it's required to do much more than stated on the installation instructions!\r\n\r\nMy system:\r\n```\r\nCUDA support: YES\r\nBazel: 0.5.4\r\ngcc (Ubuntu 5.4.1-8ubuntu1) 5.4.1 20170304\r\nLinux Desktop 4.10.0-33-generic #37-Ubuntu SMP Fri Aug 11 10:55:28 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\nCPU i7-7820x (with AVX512 support)\r\n```\r\n\r\nIt's required change the build command:\r\n\r\n`bazel build --config=opt --config=cuda --cxxopt=\"-fabi-version=0\" //tensorflow/tools/pip_package:build_pip_package --verbose_failures`\r\n\r\nAnd it's still not enough :( I still can't make successful build...", "comments": ["Are you missing the configure step?", "No, of course. The issue happens after compiling 3500 source files.", "@rmlarsen any idea what the problem is with `_mm512_insertf64x2`?", "It looks like problem with `_mm512_insertf64x2` is caused by gcc 4 - it doesn't support avx512. Of course, compilation must be successful anyway. But even gcc 5 doesn't work with another error :( Nothing works at all.\r\n\r\nIt's so disappointing. I can't build tensorflow for a week on macOS, Windows and Ubuntu using hundreds of different compilation options, but always with GPU support. Without GPU support it works on Ubuntu.\r\n\r\nI believe that it happens because of my CPU (Intel Skylake - i7-7820X). Please, anybody who can understand what's going on, help me!", "More information about errors that I get both with gcc-4.9 and gcc-5: https://github.com/tensorflow/tensorflow/issues/13014\r\nThe current issue report is about obsolete installation instruction and incorrect build command in it.", "Only gcc-4.8 works fine on the new CPUs. Please update installation instruction.", "Hi, no matter for me with this command line : \"bazel build -c opt --copt=-mavx --copt=-mavx2 --copt=-mfma --copt=-mfpmath=both --config=cuda -k //tensorflow/tools/pip_package:build_pip_package\"", "@wolffg, could you update the docs:?", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "These installation instructions have been updated several times since this bug was opened.  I'm closing this; if you are still having issues compiling from source, please file a new issue and fill out the template so we can get more information on your issues.\r\n\r\nThanks!", "Thanks @wolffg "]}, {"number": 13014, "title": "Can't compile tensorflow on Ubuntu with Skylake CPU (i7-7820X)", "body": "Can't compile tensorflow on Ubuntu with Skylake CPU (i7-7820X). I get the following error:\r\n\r\n```\r\nERROR: /home/Dmitry/Private/Kaggle/tensorflow/tensorflow/core/kernels/BUILD:1369:1: C++ compilation of rule '//tensorflow/core/kernels:range_sampler' failed (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command \r\n  (cd /home/Dmitry/.cache/bazel/_bazel_Dmitry/a3a733ca304216612b7ed32f720401f1/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    CUDA_TOOLKIT_PATH=/usr/local/cuda \\\r\n    CUDNN_INSTALL_PATH=/usr/local/cuda-8.0 \\\r\n    GCC_HOST_COMPILER_PATH=/usr/bin/gcc-4.9 \\\r\n    PWD=/proc/self/cwd \\\r\n    PYTHON_BIN_PATH=/usr/bin/python \\\r\n    PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \\\r\n    TF_CUDA_CLANG=0 \\\r\n    TF_CUDA_COMPUTE_CAPABILITIES=6.1 \\\r\n    TF_CUDA_VERSION=8.0 \\\r\n    TF_CUDNN_VERSION=6 \\\r\n    TF_NEED_CUDA=1 \\\r\n    TF_NEED_OPENCL=0 \\\r\n  external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections '-march=native' '-std=c++11' '-march=native' '-fabi-version=0' '-D_GLIBCXX_USE_CXX11_ABI=0' -MD -MF bazel-out/local_linux-opt/bin/tensorflow/core/kernels/_objs/range_sampler/tensorflow/core/kernels/range_sampler.pic.d '-frandom-seed=bazel-out/local_linux-opt/bin/tensorflow/core/kernels/_objs/range_sampler/tensorflow/core/kernels/range_sampler.pic.o' -fPIC -DEIGEN_MPL2_ONLY -DTENSORFLOW_USE_JEMALLOC -DSNAPPY -iquote . -iquote bazel-out/local_linux-opt/genfiles -iquote external/nsync -iquote bazel-out/local_linux-opt/genfiles/external/nsync -iquote external/bazel_tools -iquote bazel-out/local_linux-opt/genfiles/external/bazel_tools -iquote external/jemalloc -iquote bazel-out/local_linux-opt/genfiles/external/jemalloc -iquote external/protobuf_archive -iquote bazel-out/local_linux-opt/genfiles/external/protobuf_archive -iquote external/eigen_archive -iquote bazel-out/local_linux-opt/genfiles/external/eigen_archive -iquote external/local_config_sycl -iquote bazel-out/local_linux-opt/genfiles/external/local_config_sycl -iquote external/gif_archive -iquote bazel-out/local_linux-opt/genfiles/external/gif_archive -iquote external/jpeg -iquote bazel-out/local_linux-opt/genfiles/external/jpeg -iquote external/com_googlesource_code_re2 -iquote bazel-out/local_linux-opt/genfiles/external/com_googlesource_code_re2 -iquote external/farmhash_archive -iquote bazel-out/local_linux-opt/genfiles/external/farmhash_archive -iquote external/fft2d -iquote bazel-out/local_linux-opt/genfiles/external/fft2d -iquote external/highwayhash -iquote bazel-out/local_linux-opt/genfiles/external/highwayhash -iquote external/png_archive -iquote bazel-out/local_linux-opt/genfiles/external/png_archive -iquote external/zlib_archive -iquote bazel-out/local_linux-opt/genfiles/external/zlib_archive -iquote external/snappy -iquote bazel-out/local_linux-opt/genfiles/external/snappy -isystem external/nsync/public -isystem bazel-out/local_linux-opt/genfiles/external/nsync/public -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/jemalloc/include -isystem bazel-out/local_linux-opt/genfiles/external/jemalloc/include -isystem external/protobuf_archive/src -isystem bazel-out/local_linux-opt/genfiles/external/protobuf_archive/src -isystem external/eigen_archive -isystem bazel-out/local_linux-opt/genfiles/external/eigen_archive -isystem external/gif_archive/lib -isystem bazel-out/local_linux-opt/genfiles/external/gif_archive/lib -isystem external/farmhash_archive/src -isystem bazel-out/local_linux-opt/genfiles/external/farmhash_archive/src -isystem external/png_archive -isystem bazel-out/local_linux-opt/genfiles/external/png_archive -isystem external/zlib_archive -isystem bazel-out/local_linux-opt/genfiles/external/zlib_archive -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -fno-canonical-system-headers -c tensorflow/core/kernels/range_sampler.cc -o bazel-out/local_linux-opt/bin/tensorflow/core/kernels/_objs/range_sampler/tensorflow/core/kernels/range_sampler.pic.o)\r\nIn file included from external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/Core:378:0,\r\n                 from external/eigen_archive/unsupported/Eigen/CXX11/Tensor:14,\r\n                 from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1,\r\n                 from ./tensorflow/core/lib/random/random_distributions.h:27,\r\n                 from ./tensorflow/core/lib/random/simple_philox.h:24,\r\n                 from ./tensorflow/core/lib/random/distribution_sampler.h:38,\r\n                 from ./tensorflow/core/kernels/range_sampler.h:23,\r\n                 from tensorflow/core/kernels/range_sampler.cc:16:\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/arch/AVX512/PacketMath.h: In function 'Packet Eigen::internal::ploaddup(const typename Eigen::internal::unpacket_traits<Packet>::type*) [with Packet = __vector(16) float; typename Eigen::internal::unpacket_traits<Packet>::type = float]':\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/arch/AVX512/PacketMath.h:469:77: error: '_mm512_castsi512_ps' was not declared in this scope\r\n   __m512 even_elements = _mm512_castsi512_ps(_mm512_cvtepu32_epi64(low_half));\r\n                                                                             ^\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/arch/AVX512/PacketMath.h: In function 'Packet Eigen::internal::ploaddup(const typename Eigen::internal::unpacket_traits<Packet>::type*) [with Packet = __vector(8) double; typename Eigen::internal::unpacket_traits<Packet>::type = double]':\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/arch/AVX512/PacketMath.h:478:56: error: '_mm512_insertf64x2' was not declared in this scope\r\n   x = _mm512_insertf64x2(x, _mm_loaddup_pd(&from[0]), 0);\r\n                                                        ^\r\nIn file included from ./tensorflow/core/platform/default/logging.h:24:0,\r\n                 from ./tensorflow/core/platform/logging.h:25,\r\n                 from ./tensorflow/core/lib/core/status.h:25,\r\n                 from ./tensorflow/core/kernels/range_sampler.h:21,\r\n                 from tensorflow/core/kernels/range_sampler.cc:16:\r\n./tensorflow/core/platform/default/logging.h: In instantiation of 'std::string* tensorflow::internal::Check_LEImpl(const T1&, const T2&, const char*) [with T1 = long unsigned int; T2 = long long int; std::string = std::basic_string<char>]':\r\ntensorflow/core/kernels/range_sampler.cc:86:5:   required from here\r\n./tensorflow/core/platform/default/logging.h:230:35: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n TF_DEFINE_CHECK_OP_IMPL(Check_LE, <= )\r\n                                   ^\r\n./tensorflow/core/platform/macros.h:79:29: note: in definition of macro 'TF_PREDICT_TRUE'\r\n #define TF_PREDICT_TRUE(x) (x)\r\n                             ^\r\n./tensorflow/core/platform/default/logging.h:230:1: note: in expansion of macro 'TF_DEFINE_CHECK_OP_IMPL'\r\n TF_DEFINE_CHECK_OP_IMPL(Check_LE, <= )\r\n ^\r\n./tensorflow/core/platform/default/logging.h: In instantiation of 'std::string* tensorflow::internal::Check_EQImpl(const T1&, const T2&, const char*) [with T1 = long long int; T2 = long unsigned int; std::string = std::basic_string<char>]':\r\ntensorflow/core/kernels/range_sampler.cc:244:3:   required from here\r\n./tensorflow/core/platform/default/logging.h:228:25: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n                         == )  // Compilation error with CHECK_EQ(NULL, x)?\r\n                         ^\r\n./tensorflow/core/platform/macros.h:79:29: note: in definition of macro 'TF_PREDICT_TRUE'\r\n #define TF_PREDICT_TRUE(x) (x)\r\n                             ^\r\n./tensorflow/core/platform/default/logging.h:227:1: note: in expansion of macro 'TF_DEFINE_CHECK_OP_IMPL'\r\n TF_DEFINE_CHECK_OP_IMPL(Check_EQ,\r\n ^\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 1.894s, Critical Path: 1.15s\r\nFAILED: Build did NOT complete successfully\r\n```\r\n\r\nOR the following error:\r\n\r\n```\r\nERROR: /home/Dmitry/Private/Kaggle/tensorflow/tensorflow/core/BUILD:1299:1: C++ compilation of rule '//tensorflow/core:lib_internal' failed (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command \r\n  (cd /home/Dmitry/.cache/bazel/_bazel_Dmitry/a3a733ca304216612b7ed32f720401f1/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    CUDA_TOOLKIT_PATH=/usr/local/cuda \\\r\n    CUDNN_INSTALL_PATH=/usr/local/cuda-8.0 \\\r\n    GCC_HOST_COMPILER_PATH=/usr/bin/gcc-4.9 \\\r\n    PWD=/proc/self/cwd \\\r\n    PYTHON_BIN_PATH=/usr/bin/python3 \\\r\n    PYTHON_LIB_PATH=/usr/local/lib/python3.5/dist-packages \\\r\n    TF_CUDA_CLANG=0 \\\r\n    TF_CUDA_COMPUTE_CAPABILITIES=6.1 \\\r\n    TF_CUDA_VERSION=8.0 \\\r\n    TF_CUDNN_VERSION=6 \\\r\n    TF_NEED_CUDA=1 \\\r\n    TF_NEED_OPENCL=0 \\\r\n  external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections '-march=native' '-std=c++11' '-march=native' '-fabi-version=0' '-D_GLIBCXX_USE_CXX11_ABI=0' -MD -MF bazel-out/local_linux-py3-opt/bin/tensorflow/core/_objs/lib_internal/tensorflow/core/lib/random/distribution_sampler.pic.d '-frandom-seed=bazel-out/local_linux-py3-opt/bin/tensorflow/core/_objs/lib_internal/tensorflow/core/lib/random/distribution_sampler.pic.o' -fPIC -DEIGEN_MPL2_ONLY -DTENSORFLOW_USE_JEMALLOC -DSNAPPY -iquote . -iquote bazel-out/local_linux-py3-opt/genfiles -iquote external/nsync -iquote bazel-out/local_linux-py3-opt/genfiles/external/nsync -iquote external/bazel_tools -iquote bazel-out/local_linux-py3-opt/genfiles/external/bazel_tools -iquote external/jemalloc -iquote bazel-out/local_linux-py3-opt/genfiles/external/jemalloc -iquote external/protobuf_archive -iquote bazel-out/local_linux-py3-opt/genfiles/external/protobuf_archive -iquote external/eigen_archive -iquote bazel-out/local_linux-py3-opt/genfiles/external/eigen_archive -iquote external/local_config_sycl -iquote bazel-out/local_linux-py3-opt/genfiles/external/local_config_sycl -iquote external/gif_archive -iquote bazel-out/local_linux-py3-opt/genfiles/external/gif_archive -iquote external/jpeg -iquote bazel-out/local_linux-py3-opt/genfiles/external/jpeg -iquote external/com_googlesource_code_re2 -iquote bazel-out/local_linux-py3-opt/genfiles/external/com_googlesource_code_re2 -iquote external/farmhash_archive -iquote bazel-out/local_linux-py3-opt/genfiles/external/farmhash_archive -iquote external/fft2d -iquote bazel-out/local_linux-py3-opt/genfiles/external/fft2d -iquote external/highwayhash -iquote bazel-out/local_linux-py3-opt/genfiles/external/highwayhash -iquote external/png_archive -iquote bazel-out/local_linux-py3-opt/genfiles/external/png_archive -iquote external/zlib_archive -iquote bazel-out/local_linux-py3-opt/genfiles/external/zlib_archive -iquote external/snappy -iquote bazel-out/local_linux-py3-opt/genfiles/external/snappy -isystem external/nsync/public -isystem bazel-out/local_linux-py3-opt/genfiles/external/nsync/public -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/jemalloc/include -isystem bazel-out/local_linux-py3-opt/genfiles/external/jemalloc/include -isystem external/protobuf_archive/src -isystem bazel-out/local_linux-py3-opt/genfiles/external/protobuf_archive/src -isystem external/eigen_archive -isystem bazel-out/local_linux-py3-opt/genfiles/external/eigen_archive -isystem external/gif_archive/lib -isystem bazel-out/local_linux-py3-opt/genfiles/external/gif_archive/lib -isystem external/farmhash_archive/src -isystem bazel-out/local_linux-py3-opt/genfiles/external/farmhash_archive/src -isystem external/png_archive -isystem bazel-out/local_linux-py3-opt/genfiles/external/png_archive -isystem external/zlib_archive -isystem bazel-out/local_linux-py3-opt/genfiles/external/zlib_archive -DEIGEN_AVOID_STL_ARRAY -Iexternal/gemmlowp -Wno-sign-compare -fno-exceptions '-ftemplate-depth=900' '-DGOOGLE_CUDA=1' -msse3 -pthread -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -fno-canonical-system-headers -c tensorflow/core/lib/random/distribution_sampler.cc -o bazel-out/local_linux-py3-opt/bin/tensorflow/core/_objs/lib_internal/tensorflow/core/lib/random/distribution_sampler.pic.o)\r\nIn file included from external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/Core:378:0,\r\n                 from external/eigen_archive/unsupported/Eigen/CXX11/Tensor:14,\r\n                 from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1,\r\n                 from ./tensorflow/core/lib/random/random_distributions.h:27,\r\n                 from ./tensorflow/core/lib/random/simple_philox.h:24,\r\n                 from ./tensorflow/core/lib/random/distribution_sampler.h:38,\r\n                 from tensorflow/core/lib/random/distribution_sampler.cc:16:\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/arch/AVX512/PacketMath.h: In function 'Packet Eigen::internal::ploaddup(const typename Eigen::internal::unpacket_traits<Packet>::type*) [with Packet = __vector(16) float; typename Eigen::internal::unpacket_traits<Packet>::type = float]':\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/arch/AVX512/PacketMath.h:469:77: error: '_mm512_castsi512_ps' was not declared in this scope\r\n   __m512 even_elements = _mm512_castsi512_ps(_mm512_cvtepu32_epi64(low_half));\r\n                                                                             ^\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/arch/AVX512/PacketMath.h: In function 'Packet Eigen::internal::ploaddup(const typename Eigen::internal::unpacket_traits<Packet>::type*) [with Packet = __vector(8) double; typename Eigen::internal::unpacket_traits<Packet>::type = double]':\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/arch/AVX512/PacketMath.h:478:56: error: '_mm512_insertf64x2' was not declared in this scope\r\n   x = _mm512_insertf64x2(x, _mm_loaddup_pd(&from[0]), 0);\r\n                                                        ^\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 183.759s, Critical Path: 16.18s\r\nFAILED: Build did NOT complete successfully\r\n```\r\n\r\nCompilation command: \r\n\r\n`bazel build --config=opt --config=cuda --cxxopt=\"-fabi-version=0\" //tensorflow/tools/pip_package:build_pip_package --verbose_failures`\r\n\r\nIs it possible to disable AVX512 but leave all other native optimization parameters?\r\n", "comments": ["@zyavrik I think eigen is downloaded from source in TensorFlow, not built against the installed library in your dev machine (libeigen3-dev) directly.\r\n\r\nInstalling libeigen3-dev may actually complicate the issue as there are mixed header files from different versions of eigen3 (one from downloaded source, another from the sys directory in your dev machine).\r\n\r\nIt is hard to see but from the limited information above, I tends to think the compiling error might be related to gcc version (or some `#define` in Eigen library).\r\n\r\nCan you provide more details about the OS and GCC version?", "More details about my system:\r\n```\r\n\r\nCUDA support: YES\r\nBazel: 0.5.4\r\ngcc (Ubuntu 4.9.4-2ubuntu1) 4.9.4\r\nLinux Desktop 4.10.0-33-generic #37-Ubuntu SMP Fri Aug 11 10:55:28 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\nCPU i7-7820x (with AVX512 support)\r\n```\r\n\r\nHow can I download eigen from source in TensorFlow?", "@zyavrik The downloading of Eigen is handled by bazel when you invoke `basel build`. ", "By the way, have you tried another version of gcc (like 5?)", "Yes, I've tried. With gcc 5 I get the following error:\r\n\r\n```\r\nERROR: /home/Dmitry/Private/Kaggle/tensorflow/tensorflow/contrib/framework/BUILD:88:1: undeclared inclusion(s) in rule '//tensorflow/contrib/framework:python/ops/_variable_ops_gpu':\r\nthis rule is missing dependency declarations for the following files included by 'tensorflow/contrib/framework/kernels/zero_initializer_op_gpu.cu.cc':\r\n  '/usr/local/cuda-8.0/targets/x86_64-linux/include/cuda_runtime.h'\r\n  '/usr/local/cuda-8.0/targets/x86_64-linux/include/host_config.h'\r\n  '/usr/local/cuda-8.0/targets/x86_64-linux/include/builtin_types.h'\r\n  '/usr/local/cuda-8.0/targets/x86_64-linux/include/device_types.h'\r\n  '/usr/local/cuda-8.0/targets/x86_64-linux/include/host_defines.h'\r\n  '/usr/local/cuda-8.0/targets/x86_64-linux/include/driver_types.h'\r\n  '/usr/local/cuda-8.0/targets/x86_64-linux/include/surface_types.h'\r\n  '/usr/local/cuda-8.0/targets/x86_64-linux/include/texture_types.h'\r\n  '/usr/local/cuda-8.0/targets/x86_64-linux/include/vector_types.h'\r\n  '/usr/local/cuda-8.0/targets/x86_64-linux/include/library_types.h'\r\n  '/usr/local/cuda-8.0/targets/x86_64-linux/include/channel_descriptor.h'\r\n  '/usr/local/cuda-8.0/targets/x86_64-linux/include/cuda_runtime_api.h'\r\n  '/usr/local/cuda-8.0/targets/x86_64-linux/include/cuda_device_runtime_api.h'\r\n  '/usr/local/cuda-8.0/targets/x86_64-linux/include/driver_functions.h'\r\n  '/usr/local/cuda-8.0/targets/x86_64-linux/include/vector_functions.h'\r\n  '/usr/local/cuda-8.0/targets/x86_64-linux/include/vector_functions.hpp'\r\n  '/usr/local/cuda-8.0/targets/x86_64-linux/include/common_functions.h'\r\n  '/usr/local/cuda-8.0/targets/x86_64-linux/include/math_functions.h'\r\n  '/usr/local/cuda-8.0/targets/x86_64-linux/include/math_functions.hpp'\r\n  '/usr/local/cuda-8.0/targets/x86_64-linux/include/math_functions_dbl_ptx3.h'\r\n  '/usr/local/cuda-8.0/targets/x86_64-linux/include/math_functions_dbl_ptx3.hpp'\r\n  '/usr/local/cuda-8.0/targets/x86_64-linux/include/cuda_surface_types.h'\r\n  '/usr/local/cuda-8.0/targets/x86_64-linux/include/cuda_texture_types.h'\r\n  '/usr/local/cuda-8.0/targets/x86_64-linux/include/device_functions.h'\r\n  '/usr/local/cuda-8.0/targets/x86_64-linux/include/device_functions.hpp'\r\n  '/usr/local/cuda-8.0/targets/x86_64-linux/include/device_atomic_functions.h'\r\n  '/usr/local/cuda-8.0/targets/x86_64-linux/include/device_atomic_functions.hpp'\r\n  '/usr/local/cuda-8.0/targets/x86_64-linux/include/device_double_functions.h'\r\n  '/usr/local/cuda-8.0/targets/x86_64-linux/include/device_double_functions.hpp'\r\n  '/usr/local/cuda-8.0/targets/x86_64-linux/include/sm_20_atomic_functions.h'\r\n  '/usr/local/cuda-8.0/targets/x86_64-linux/include/sm_20_atomic_functions.hpp'\r\n  '/usr/local/cuda-8.0/targets/x86_64-linux/include/sm_32_atomic_functions.h'\r\n  '/usr/local/cuda-8.0/targets/x86_64-linux/include/sm_32_atomic_functions.hpp'\r\n  '/usr/local/cuda-8.0/targets/x86_64-linux/include/sm_35_atomic_functions.h'\r\n  '/usr/local/cuda-8.0/targets/x86_64-linux/include/sm_60_atomic_functions.h'\r\n  '/usr/local/cuda-8.0/targets/x86_64-linux/include/sm_60_atomic_functions.hpp'\r\n  '/usr/local/cuda-8.0/targets/x86_64-linux/include/sm_20_intrinsics.h'\r\n  '/usr/local/cuda-8.0/targets/x86_64-linux/include/sm_20_intrinsics.hpp'\r\n  '/usr/local/cuda-8.0/targets/x86_64-linux/include/sm_30_intrinsics.h'\r\n  '/usr/local/cuda-8.0/targets/x86_64-linux/include/sm_30_intrinsics.hpp'\r\n  '/usr/local/cuda-8.0/targets/x86_64-linux/include/sm_32_intrinsics.h'\r\n  '/usr/local/cuda-8.0/targets/x86_64-linux/include/sm_32_intrinsics.hpp'\r\n  '/usr/local/cuda-8.0/targets/x86_64-linux/include/sm_35_intrinsics.h'\r\n  '/usr/local/cuda-8.0/targets/x86_64-linux/include/sm_61_intrinsics.h'\r\n  '/usr/local/cuda-8.0/targets/x86_64-linux/include/sm_61_intrinsics.hpp'\r\n  '/usr/local/cuda-8.0/targets/x86_64-linux/include/surface_functions.h'\r\n  '/usr/local/cuda-8.0/targets/x86_64-linux/include/texture_fetch_functions.h'\r\n  '/usr/local/cuda-8.0/targets/x86_64-linux/include/texture_indirect_functions.h'\r\n  '/usr/local/cuda-8.0/targets/x86_64-linux/include/surface_indirect_functions.h'\r\n  '/usr/local/cuda-8.0/targets/x86_64-linux/include/device_launch_parameters.h'\r\n  '/usr/local/cuda-8.0/targets/x86_64-linux/include/cuda_fp16.h'\r\n  '/usr/local/cuda-8.0/targets/x86_64-linux/include/math_constants.h'\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9218): error: argument of type \"const void *\" is incompatible with parameter of type \"const float *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9229): error: argument of type \"const void *\" is incompatible with parameter of type \"const float *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9242): error: argument of type \"const void *\" is incompatible with parameter of type \"const double *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9253): error: argument of type \"const void *\" is incompatible with parameter of type \"const double *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9266): error: argument of type \"const void *\" is incompatible with parameter of type \"const float *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9277): error: argument of type \"const void *\" is incompatible with parameter of type \"const float *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9290): error: argument of type \"const void *\" is incompatible with parameter of type \"const double *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9301): error: argument of type \"const void *\" is incompatible with parameter of type \"const double *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9314): error: argument of type \"const void *\" is incompatible with parameter of type \"const int *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9325): error: argument of type \"const void *\" is incompatible with parameter of type \"const int *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9338): error: argument of type \"const void *\" is incompatible with parameter of type \"const long long *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9350): error: argument of type \"const void *\" is incompatible with parameter of type \"const long long *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9363): error: argument of type \"const void *\" is incompatible with parameter of type \"const int *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9374): error: argument of type \"const void *\" is incompatible with parameter of type \"const int *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9387): error: argument of type \"const void *\" is incompatible with parameter of type \"const long long *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9399): error: argument of type \"const void *\" is incompatible with parameter of type \"const long long *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9408): error: argument of type \"void *\" is incompatible with parameter of type \"float *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9417): error: argument of type \"void *\" is incompatible with parameter of type \"float *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9426): error: argument of type \"void *\" is incompatible with parameter of type \"double *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9435): error: argument of type \"void *\" is incompatible with parameter of type \"double *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9443): error: argument of type \"void *\" is incompatible with parameter of type \"float *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9452): error: argument of type \"void *\" is incompatible with parameter of type \"float *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9461): error: argument of type \"void *\" is incompatible with parameter of type \"double *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9470): error: argument of type \"void *\" is incompatible with parameter of type \"double *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9479): error: argument of type \"void *\" is incompatible with parameter of type \"int *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9488): error: argument of type \"void *\" is incompatible with parameter of type \"int *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9497): error: argument of type \"void *\" is incompatible with parameter of type \"long long *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9506): error: argument of type \"void *\" is incompatible with parameter of type \"long long *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9515): error: argument of type \"void *\" is incompatible with parameter of type \"int *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9524): error: argument of type \"void *\" is incompatible with parameter of type \"int *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9533): error: argument of type \"void *\" is incompatible with parameter of type \"long long *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9542): error: argument of type \"void *\" is incompatible with parameter of type \"long long *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512pfintrin.h(54): error: argument of type \"const void *\" is incompatible with parameter of type \"const long long *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512pfintrin.h(62): error: argument of type \"const void *\" is incompatible with parameter of type \"const int *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512pfintrin.h(70): error: argument of type \"const void *\" is incompatible with parameter of type \"const long long *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512pfintrin.h(78): error: argument of type \"const void *\" is incompatible with parameter of type \"const int *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512pfintrin.h(86): error: argument of type \"void *\" is incompatible with parameter of type \"const long long *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512pfintrin.h(95): error: argument of type \"void *\" is incompatible with parameter of type \"const int *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512pfintrin.h(104): error: argument of type \"void *\" is incompatible with parameter of type \"const long long *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512pfintrin.h(112): error: argument of type \"void *\" is incompatible with parameter of type \"const int *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512pfintrin.h(120): error: argument of type \"void *\" is incompatible with parameter of type \"const long long *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512pfintrin.h(129): error: argument of type \"void *\" is incompatible with parameter of type \"const int *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512pfintrin.h(138): error: argument of type \"void *\" is incompatible with parameter of type \"const long long *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512pfintrin.h(146): error: argument of type \"void *\" is incompatible with parameter of type \"const int *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10223): error: argument of type \"const void *\" is incompatible with parameter of type \"const float *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10235): error: argument of type \"const void *\" is incompatible with parameter of type \"const float *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10247): error: argument of type \"const void *\" is incompatible with parameter of type \"const double *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10259): error: argument of type \"const void *\" is incompatible with parameter of type \"const double *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10271): error: argument of type \"const void *\" is incompatible with parameter of type \"const float *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10283): error: argument of type \"const void *\" is incompatible with parameter of type \"const float *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10295): error: argument of type \"const void *\" is incompatible with parameter of type \"const double *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10307): error: argument of type \"const void *\" is incompatible with parameter of type \"const double *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10319): error: argument of type \"const void *\" is incompatible with parameter of type \"const int *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10331): error: argument of type \"const void *\" is incompatible with parameter of type \"const int *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10343): error: argument of type \"const void *\" is incompatible with parameter of type \"const long long *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10355): error: argument of type \"const void *\" is incompatible with parameter of type \"const long long *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10367): error: argument of type \"const void *\" is incompatible with parameter of type \"const int *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10379): error: argument of type \"const void *\" is incompatible with parameter of type \"const int *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10391): error: argument of type \"const void *\" is incompatible with parameter of type \"const long long *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10403): error: argument of type \"const void *\" is incompatible with parameter of type \"const long long *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10413): error: argument of type \"void *\" is incompatible with parameter of type \"float *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10424): error: argument of type \"void *\" is incompatible with parameter of type \"float *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10433): error: argument of type \"void *\" is incompatible with parameter of type \"float *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10444): error: argument of type \"void *\" is incompatible with parameter of type \"float *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10453): error: argument of type \"void *\" is incompatible with parameter of type \"double *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10464): error: argument of type \"void *\" is incompatible with parameter of type \"double *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10473): error: argument of type \"void *\" is incompatible with parameter of type \"double *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10484): error: argument of type \"void *\" is incompatible with parameter of type \"double *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10493): error: argument of type \"void *\" is incompatible with parameter of type \"float *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10504): error: argument of type \"void *\" is incompatible with parameter of type \"float *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10513): error: argument of type \"void *\" is incompatible with parameter of type \"float *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10524): error: argument of type \"void *\" is incompatible with parameter of type \"float *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10533): error: argument of type \"void *\" is incompatible with parameter of type \"double *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10544): error: argument of type \"void *\" is incompatible with parameter of type \"double *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10553): error: argument of type \"void *\" is incompatible with parameter of type \"double *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10564): error: argument of type \"void *\" is incompatible with parameter of type \"double *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10573): error: argument of type \"void *\" is incompatible with parameter of type \"int *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10584): error: argument of type \"void *\" is incompatible with parameter of type \"int *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10593): error: argument of type \"void *\" is incompatible with parameter of type \"int *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10604): error: argument of type \"void *\" is incompatible with parameter of type \"int *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10613): error: argument of type \"void *\" is incompatible with parameter of type \"long long *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10624): error: argument of type \"void *\" is incompatible with parameter of type \"long long *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10633): error: argument of type \"void *\" is incompatible with parameter of type \"long long *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10644): error: argument of type \"void *\" is incompatible with parameter of type \"long long *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10653): error: argument of type \"void *\" is incompatible with parameter of type \"int *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10664): error: argument of type \"void *\" is incompatible with parameter of type \"int *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10673): error: argument of type \"void *\" is incompatible with parameter of type \"int *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10684): error: argument of type \"void *\" is incompatible with parameter of type \"int *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10693): error: argument of type \"void *\" is incompatible with parameter of type \"long long *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10704): error: argument of type \"void *\" is incompatible with parameter of type \"long long *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10713): error: argument of type \"void *\" is incompatible with parameter of type \"long long *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10724): error: argument of type \"void *\" is incompatible with parameter of type \"long long *\"\r\n\r\n92 errors detected in the compilation of \"/tmp/tmpxft_00007a4c_00000000-7_zero_initializer_op_gpu.cu.cpp1.ii\".\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 2.846s, Critical Path: 2.32s\r\nFAILED: Build did NOT complete successfully\r\n```\r\n\r\nOR the following error:\r\n\r\n```\r\nERROR: /home/dmitry/Private/Kaggle/tensorflow/tensorflow/core/kernels/BUILD:2294:1: C++ compilation of rule '//tensorflow/core/kernels:self_adjoint_eig_v2_op' failed (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command \r\n  (cd /home/dmitry/.cache/bazel/_bazel_dmitry/45cfecd68ef4f076728c861b104b36a6/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    CUDA_TOOLKIT_PATH=/usr/local/cuda \\\r\n    CUDNN_INSTALL_PATH=/usr/local/cuda-8.0 \\\r\n    GCC_HOST_COMPILER_PATH=/usr/bin/gcc \\\r\n    PWD=/proc/self/cwd \\\r\n    PYTHON_BIN_PATH=/usr/bin/python \\\r\n    PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \\\r\n    TF_CUDA_CLANG=0 \\\r\n    TF_CUDA_COMPUTE_CAPABILITIES=6.1 \\\r\n    TF_CUDA_VERSION=8.0 \\\r\n    TF_CUDNN_VERSION=6 \\\r\n    TF_NEED_CUDA=1 \\\r\n    TF_NEED_OPENCL=0 \\\r\n  external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections '-march=native' '-std=c++11' '-march=native' '-fabi-version=0' '-D_GLIBCXX_USE_CXX11_ABI=0' -MD -MF bazel-out/local_linux-opt/bin/tensorflow/core/kernels/_objs/self_adjoint_eig_v2_op/tensorflow/core/kernels/self_adjoint_eig_v2_op.pic.d '-frandom-seed=bazel-out/local_linux-opt/bin/tensorflow/core/kernels/_objs/self_adjoint_eig_v2_op/tensorflow/core/kernels/self_adjoint_eig_v2_op.pic.o' -fPIC -DEIGEN_MPL2_ONLY -DTENSORFLOW_USE_JEMALLOC -DSNAPPY -iquote . -iquote bazel-out/local_linux-opt/genfiles -iquote external/nsync -iquote bazel-out/local_linux-opt/genfiles/external/nsync -iquote external/bazel_tools -iquote bazel-out/local_linux-opt/genfiles/external/bazel_tools -iquote external/jemalloc -iquote bazel-out/local_linux-opt/genfiles/external/jemalloc -iquote external/protobuf_archive -iquote bazel-out/local_linux-opt/genfiles/external/protobuf_archive -iquote external/eigen_archive -iquote bazel-out/local_linux-opt/genfiles/external/eigen_archive -iquote external/local_config_sycl -iquote bazel-out/local_linux-opt/genfiles/external/local_config_sycl -iquote external/gif_archive -iquote bazel-out/local_linux-opt/genfiles/external/gif_archive -iquote external/jpeg -iquote bazel-out/local_linux-opt/genfiles/external/jpeg -iquote external/com_googlesource_code_re2 -iquote bazel-out/local_linux-opt/genfiles/external/com_googlesource_code_re2 -iquote external/farmhash_archive -iquote bazel-out/local_linux-opt/genfiles/external/farmhash_archive -iquote external/fft2d -iquote bazel-out/local_linux-opt/genfiles/external/fft2d -iquote external/highwayhash -iquote bazel-out/local_linux-opt/genfiles/external/highwayhash -iquote external/png_archive -iquote bazel-out/local_linux-opt/genfiles/external/png_archive -iquote external/zlib_archive -iquote bazel-out/local_linux-opt/genfiles/external/zlib_archive -iquote external/snappy -iquote bazel-out/local_linux-opt/genfiles/external/snappy -iquote external/local_config_cuda -iquote bazel-out/local_linux-opt/genfiles/external/local_config_cuda -isystem external/nsync/public -isystem bazel-out/local_linux-opt/genfiles/external/nsync/public -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/jemalloc/include -isystem bazel-out/local_linux-opt/genfiles/external/jemalloc/include -isystem external/protobuf_archive/src -isystem bazel-out/local_linux-opt/genfiles/external/protobuf_archive/src -isystem external/eigen_archive -isystem bazel-out/local_linux-opt/genfiles/external/eigen_archive -isystem external/gif_archive/lib -isystem bazel-out/local_linux-opt/genfiles/external/gif_archive/lib -isystem external/farmhash_archive/src -isystem bazel-out/local_linux-opt/genfiles/external/farmhash_archive/src -isystem external/png_archive -isystem bazel-out/local_linux-opt/genfiles/external/png_archive -isystem external/zlib_archive -isystem bazel-out/local_linux-opt/genfiles/external/zlib_archive -isystem external/local_config_cuda/cuda -isystem bazel-out/local_linux-opt/genfiles/external/local_config_cuda/cuda -isystem external/local_config_cuda/cuda/cuda/include -isystem bazel-out/local_linux-opt/genfiles/external/local_config_cuda/cuda/cuda/include -DEIGEN_AVOID_STL_ARRAY -Iexternal/gemmlowp -Wno-sign-compare -fno-exceptions '-ftemplate-depth=900' '-DGOOGLE_CUDA=1' -msse3 -pthread '-DGOOGLE_CUDA=1' -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -fno-canonical-system-headers -c tensorflow/core/kernels/self_adjoint_eig_v2_op.cc -o bazel-out/local_linux-opt/bin/tensorflow/core/kernels/_objs/self_adjoint_eig_v2_op/tensorflow/core/kernels/self_adjoint_eig_v2_op.pic.o)\r\nIn file included from external/eigen_archive/Eigen/Core:451:0,\r\n                 from ./third_party/eigen3/Eigen/Core:1,\r\n                 from tensorflow/core/kernels/self_adjoint_eig_v2_op.cc:18:\r\nexternal/eigen_archive/Eigen/src/Core/util/BlasUtil.h: In instantiation of 'struct Eigen::internal::conj_helper<__vector(8) double, std::complex<double>, false, false>':\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:339:77:   required from 'void Eigen::internal::apply_rotation_in_the_plane(Eigen::DenseBase<Derived>&, Eigen::DenseBase<Derived>&, const Eigen::JacobiRotation<OtherScalar>&) [with VectorX = Eigen::Block<Eigen::Map<Eigen::Matrix<std::complex<double>, -1, -1>, 0, Eigen::Stride<0, 0> >, -1, 1, true>; VectorY = Eigen::Block<Eigen::Map<Eigen::Matrix<std::complex<double>, -1, -1>, 0, Eigen::Stride<0, 0> >, -1, 1, true>; OtherScalar = double]'\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:297:40:   required from 'void Eigen::MatrixBase<Derived>::applyOnTheRight(Eigen::Index, Eigen::Index, const Eigen::JacobiRotation<OtherScalar>&) [with OtherScalar = double; Derived = Eigen::Map<Eigen::Matrix<std::complex<double>, -1, -1>, 0, Eigen::Stride<0, 0> >; Eigen::Index = long int]'\r\nexternal/eigen_archive/Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h:861:7:   required from 'void Eigen::internal::tridiagonal_qr_step(RealScalar*, RealScalar*, Index, Index, Scalar*, Index) [with int StorageOrder = 0; RealScalar = double; Scalar = std::complex<double>; Index = long int]'\r\nexternal/eigen_archive/Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h:520:87:   required from 'Eigen::ComputationInfo Eigen::internal::computeFromTridiagonal_impl(DiagType&, SubDiagType&, Eigen::Index, bool, MatrixType&) [with MatrixType = Eigen::Matrix<std::complex<double>, -1, -1>; DiagType = Eigen::Matrix<double, -1, 1>; SubDiagType = Eigen::Matrix<double, -1, 1>; Eigen::Index = long int]'\r\nexternal/eigen_archive/Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h:439:49:   required from 'Eigen::SelfAdjointEigenSolver<MatrixType>& Eigen::SelfAdjointEigenSolver<_MatrixType>::compute(const Eigen::EigenBase<OtherDerived>&, int) [with InputType = Eigen::Map<const Eigen::Matrix<std::complex<double>, -1, -1, 1, -1, -1>, 0, Eigen::Stride<0, 0> >; _MatrixType = Eigen::Matrix<std::complex<double>, -1, -1, 1, -1, -1>]'\r\nexternal/eigen_archive/Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h:168:14:   required from 'Eigen::SelfAdjointEigenSolver<_MatrixType>::SelfAdjointEigenSolver(const Eigen::EigenBase<OtherDerived>&, int) [with InputType = Eigen::Map<const Eigen::Matrix<std::complex<double>, -1, -1, 1, -1, -1>, 0, Eigen::Stride<0, 0> >; _MatrixType = Eigen::Matrix<std::complex<double>, -1, -1, 1, -1, -1>]'\r\ntensorflow/core/kernels/self_adjoint_eig_v2_op.cc:66:73:   required from 'void tensorflow::SelfAdjointEigV2Op<Scalar>::ComputeMatrix(tensorflow::OpKernelContext*, const ConstMatrixMaps&, tensorflow::SelfAdjointEigV2Op<Scalar>::MatrixMaps*) [with Scalar = std::complex<double>; tensorflow::SelfAdjointEigV2Op<Scalar>::ConstMatrixMaps = tensorflow::gtl::InlinedVector<Eigen::Map<const Eigen::Matrix<std::complex<double>, -1, -1, 1, -1, -1>, 0, Eigen::Stride<0, 0> >, 4>; tensorflow::SelfAdjointEigV2Op<Scalar>::MatrixMaps = tensorflow::gtl::InlinedVector<Eigen::Map<Eigen::Matrix<std::complex<double>, -1, -1, 1, -1, -1>, 0, Eigen::Stride<0, 0> >, 4>]'\r\ntensorflow/core/kernels/self_adjoint_eig_v2_op.cc:95:1:   required from here\r\nexternal/eigen_archive/Eigen/src/Core/util/BlasUtil.h:63:74: error: no type named 'ReturnType' in 'struct Eigen::ScalarBinaryOpTraits<__vector(8) double, std::complex<double>, Eigen::internal::scalar_product_op<__vector(8) double, std::complex<double> > >'\r\n   typedef typename ScalarBinaryOpTraits<LhsScalar,RhsScalar>::ReturnType Scalar;\r\n                                                                          ^\r\nIn file included from external/eigen_archive/Eigen/Jacobi:27:0,\r\n                 from external/eigen_archive/Eigen/Eigenvalues:16,\r\n                 from ./third_party/eigen3/Eigen/Eigenvalues:1,\r\n                 from tensorflow/core/kernels/self_adjoint_eig_v2_op.cc:19:\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h: In instantiation of 'void Eigen::internal::apply_rotation_in_the_plane(Eigen::DenseBase<Derived>&, Eigen::DenseBase<Derived>&, const Eigen::JacobiRotation<OtherScalar>&) [with VectorX = Eigen::Block<Eigen::Map<Eigen::Matrix<std::complex<double>, -1, -1>, 0, Eigen::Stride<0, 0> >, -1, 1, true>; VectorY = Eigen::Block<Eigen::Map<Eigen::Matrix<std::complex<double>, -1, -1>, 0, Eigen::Stride<0, 0> >, -1, 1, true>; OtherScalar = double]':\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:297:40:   required from 'void Eigen::MatrixBase<Derived>::applyOnTheRight(Eigen::Index, Eigen::Index, const Eigen::JacobiRotation<OtherScalar>&) [with OtherScalar = double; Derived = Eigen::Map<Eigen::Matrix<std::complex<double>, -1, -1>, 0, Eigen::Stride<0, 0> >; Eigen::Index = long int]'\r\nexternal/eigen_archive/Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h:861:7:   required from 'void Eigen::internal::tridiagonal_qr_step(RealScalar*, RealScalar*, Index, Index, Scalar*, Index) [with int StorageOrder = 0; RealScalar = double; Scalar = std::complex<double>; Index = long int]'\r\nexternal/eigen_archive/Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h:520:87:   required from 'Eigen::ComputationInfo Eigen::internal::computeFromTridiagonal_impl(DiagType&, SubDiagType&, Eigen::Index, bool, MatrixType&) [with MatrixType = Eigen::Matrix<std::complex<double>, -1, -1>; DiagType = Eigen::Matrix<double, -1, 1>; SubDiagType = Eigen::Matrix<double, -1, 1>; Eigen::Index = long int]'\r\nexternal/eigen_archive/Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h:439:49:   required from 'Eigen::SelfAdjointEigenSolver<MatrixType>& Eigen::SelfAdjointEigenSolver<_MatrixType>::compute(const Eigen::EigenBase<OtherDerived>&, int) [with InputType = Eigen::Map<const Eigen::Matrix<std::complex<double>, -1, -1, 1, -1, -1>, 0, Eigen::Stride<0, 0> >; _MatrixType = Eigen::Matrix<std::complex<double>, -1, -1, 1, -1, -1>]'\r\nexternal/eigen_archive/Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h:168:14:   required from 'Eigen::SelfAdjointEigenSolver<_MatrixType>::SelfAdjointEigenSolver(const Eigen::EigenBase<OtherDerived>&, int) [with InputType = Eigen::Map<const Eigen::Matrix<std::complex<double>, -1, -1, 1, -1, -1>, 0, Eigen::Stride<0, 0> >; _MatrixType = Eigen::Matrix<std::complex<double>, -1, -1, 1, -1, -1>]'\r\ntensorflow/core/kernels/self_adjoint_eig_v2_op.cc:66:73:   required from 'void tensorflow::SelfAdjointEigV2Op<Scalar>::ComputeMatrix(tensorflow::OpKernelContext*, const ConstMatrixMaps&, tensorflow::SelfAdjointEigV2Op<Scalar>::MatrixMaps*) [with Scalar = std::complex<double>; tensorflow::SelfAdjointEigV2Op<Scalar>::ConstMatrixMaps = tensorflow::gtl::InlinedVector<Eigen::Map<const Eigen::Matrix<std::complex<double>, -1, -1, 1, -1, -1>, 0, Eigen::Stride<0, 0> >, 4>; tensorflow::SelfAdjointEigV2Op<Scalar>::MatrixMaps = tensorflow::gtl::InlinedVector<Eigen::Map<Eigen::Matrix<std::complex<double>, -1, -1, 1, -1, -1>, 0, Eigen::Stride<0, 0> >, 4>]'\r\ntensorflow/core/kernels/self_adjoint_eig_v2_op.cc:95:1:   required from here\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:359:24: error: 'struct Eigen::internal::conj_helper<__vector(8) double, std::complex<double>, false, false>' has no member named 'pmul'\r\n         pstore(px, padd(pm.pmul(pc,xi),pcj.pmul(ps,yi)));\r\n                        ^\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:359:24: error: 'struct Eigen::internal::conj_helper<__vector(8) double, std::complex<double>, false, false>' has no member named 'pmul'\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:360:24: error: 'struct Eigen::internal::conj_helper<__vector(8) double, std::complex<double>, false, false>' has no member named 'pmul'\r\n         pstore(py, psub(pcj.pmul(pc,yi),pm.pmul(ps,xi)));\r\n                        ^\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:360:24: error: 'struct Eigen::internal::conj_helper<__vector(8) double, std::complex<double>, false, false>' has no member named 'pmul'\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:374:25: error: 'struct Eigen::internal::conj_helper<__vector(8) double, std::complex<double>, false, false>' has no member named 'pmul'\r\n         pstoreu(px, padd(pm.pmul(pc,xi),pcj.pmul(ps,yi)));\r\n                         ^\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:374:25: error: 'struct Eigen::internal::conj_helper<__vector(8) double, std::complex<double>, false, false>' has no member named 'pmul'\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:375:36: error: 'struct Eigen::internal::conj_helper<__vector(8) double, std::complex<double>, false, false>' has no member named 'pmul'\r\n         pstoreu(px+PacketSize, padd(pm.pmul(pc,xi1),pcj.pmul(ps,yi1)));\r\n                                    ^\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:375:36: error: 'struct Eigen::internal::conj_helper<__vector(8) double, std::complex<double>, false, false>' has no member named 'pmul'\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:376:25: error: 'struct Eigen::internal::conj_helper<__vector(8) double, std::complex<double>, false, false>' has no member named 'pmul'\r\n         pstore (py, psub(pcj.pmul(pc,yi),pm.pmul(ps,xi)));\r\n                         ^\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:376:25: error: 'struct Eigen::internal::conj_helper<__vector(8) double, std::complex<double>, false, false>' has no member named 'pmul'\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:377:36: error: 'struct Eigen::internal::conj_helper<__vector(8) double, std::complex<double>, false, false>' has no member named 'pmul'\r\n         pstore (py+PacketSize, psub(pcj.pmul(pc,yi1),pm.pmul(ps,xi1)));\r\n                                    ^\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:377:36: error: 'struct Eigen::internal::conj_helper<__vector(8) double, std::complex<double>, false, false>' has no member named 'pmul'\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:385:35: error: 'struct Eigen::internal::conj_helper<__vector(8) double, std::complex<double>, false, false>' has no member named 'pmul'\r\n         pstoreu(x+peelingEnd, padd(pm.pmul(pc,xi),pcj.pmul(ps,yi)));\r\n                                   ^\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:385:35: error: 'struct Eigen::internal::conj_helper<__vector(8) double, std::complex<double>, false, false>' has no member named 'pmul'\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:386:35: error: 'struct Eigen::internal::conj_helper<__vector(8) double, std::complex<double>, false, false>' has no member named 'pmul'\r\n         pstore (y+peelingEnd, psub(pcj.pmul(pc,yi),pm.pmul(ps,xi)));\r\n                                   ^\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:386:35: error: 'struct Eigen::internal::conj_helper<__vector(8) double, std::complex<double>, false, false>' has no member named 'pmul'\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:415:22: error: 'struct Eigen::internal::conj_helper<__vector(8) double, std::complex<double>, false, false>' has no member named 'pmul'\r\n       pstore(px, padd(pm.pmul(pc,xi),pcj.pmul(ps,yi)));\r\n                      ^\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:415:22: error: 'struct Eigen::internal::conj_helper<__vector(8) double, std::complex<double>, false, false>' has no member named 'pmul'\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:416:22: error: 'struct Eigen::internal::conj_helper<__vector(8) double, std::complex<double>, false, false>' has no member named 'pmul'\r\n       pstore(py, psub(pcj.pmul(pc,yi),pm.pmul(ps,xi)));\r\n                      ^\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:416:22: error: 'struct Eigen::internal::conj_helper<__vector(8) double, std::complex<double>, false, false>' has no member named 'pmul'\r\nIn file included from external/eigen_archive/Eigen/Core:451:0,\r\n                 from ./third_party/eigen3/Eigen/Core:1,\r\n                 from tensorflow/core/kernels/self_adjoint_eig_v2_op.cc:18:\r\nexternal/eigen_archive/Eigen/src/Core/util/BlasUtil.h: In instantiation of 'struct Eigen::internal::conj_helper<__vector(16) float, std::complex<float>, false, false>':\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:339:77:   required from 'void Eigen::internal::apply_rotation_in_the_plane(Eigen::DenseBase<Derived>&, Eigen::DenseBase<Derived>&, const Eigen::JacobiRotation<OtherScalar>&) [with VectorX = Eigen::Block<Eigen::Map<Eigen::Matrix<std::complex<float>, -1, -1>, 0, Eigen::Stride<0, 0> >, -1, 1, true>; VectorY = Eigen::Block<Eigen::Map<Eigen::Matrix<std::complex<float>, -1, -1>, 0, Eigen::Stride<0, 0> >, -1, 1, true>; OtherScalar = float]'\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:297:40:   required from 'void Eigen::MatrixBase<Derived>::applyOnTheRight(Eigen::Index, Eigen::Index, const Eigen::JacobiRotation<OtherScalar>&) [with OtherScalar = float; Derived = Eigen::Map<Eigen::Matrix<std::complex<float>, -1, -1>, 0, Eigen::Stride<0, 0> >; Eigen::Index = long int]'\r\nexternal/eigen_archive/Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h:861:7:   required from 'void Eigen::internal::tridiagonal_qr_step(RealScalar*, RealScalar*, Index, Index, Scalar*, Index) [with int StorageOrder = 0; RealScalar = float; Scalar = std::complex<float>; Index = long int]'\r\nexternal/eigen_archive/Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h:520:87:   required from 'Eigen::ComputationInfo Eigen::internal::computeFromTridiagonal_impl(DiagType&, SubDiagType&, Eigen::Index, bool, MatrixType&) [with MatrixType = Eigen::Matrix<std::complex<float>, -1, -1>; DiagType = Eigen::Matrix<float, -1, 1>; SubDiagType = Eigen::Matrix<float, -1, 1>; Eigen::Index = long int]'\r\nexternal/eigen_archive/Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h:439:49:   required from 'Eigen::SelfAdjointEigenSolver<MatrixType>& Eigen::SelfAdjointEigenSolver<_MatrixType>::compute(const Eigen::EigenBase<OtherDerived>&, int) [with InputType = Eigen::Map<const Eigen::Matrix<std::complex<float>, -1, -1, 1, -1, -1>, 0, Eigen::Stride<0, 0> >; _MatrixType = Eigen::Matrix<std::complex<float>, -1, -1, 1, -1, -1>]'\r\nexternal/eigen_archive/Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h:168:14:   required from 'Eigen::SelfAdjointEigenSolver<_MatrixType>::SelfAdjointEigenSolver(const Eigen::EigenBase<OtherDerived>&, int) [with InputType = Eigen::Map<const Eigen::Matrix<std::complex<float>, -1, -1, 1, -1, -1>, 0, Eigen::Stride<0, 0> >; _MatrixType = Eigen::Matrix<std::complex<float>, -1, -1, 1, -1, -1>]'\r\ntensorflow/core/kernels/self_adjoint_eig_v2_op.cc:66:73:   required from 'void tensorflow::SelfAdjointEigV2Op<Scalar>::ComputeMatrix(tensorflow::OpKernelContext*, const ConstMatrixMaps&, tensorflow::SelfAdjointEigV2Op<Scalar>::MatrixMaps*) [with Scalar = std::complex<float>; tensorflow::SelfAdjointEigV2Op<Scalar>::ConstMatrixMaps = tensorflow::gtl::InlinedVector<Eigen::Map<const Eigen::Matrix<std::complex<float>, -1, -1, 1, -1, -1>, 0, Eigen::Stride<0, 0> >, 4>; tensorflow::SelfAdjointEigV2Op<Scalar>::MatrixMaps = tensorflow::gtl::InlinedVector<Eigen::Map<Eigen::Matrix<std::complex<float>, -1, -1, 1, -1, -1>, 0, Eigen::Stride<0, 0> >, 4>]'\r\ntensorflow/core/kernels/self_adjoint_eig_v2_op.cc:95:1:   required from here\r\nexternal/eigen_archive/Eigen/src/Core/util/BlasUtil.h:63:74: error: no type named 'ReturnType' in 'struct Eigen::ScalarBinaryOpTraits<__vector(16) float, std::complex<float>, Eigen::internal::scalar_product_op<__vector(16) float, std::complex<float> > >'\r\n   typedef typename ScalarBinaryOpTraits<LhsScalar,RhsScalar>::ReturnType Scalar;\r\n                                                                          ^\r\nIn file included from external/eigen_archive/Eigen/Jacobi:27:0,\r\n                 from external/eigen_archive/Eigen/Eigenvalues:16,\r\n                 from ./third_party/eigen3/Eigen/Eigenvalues:1,\r\n                 from tensorflow/core/kernels/self_adjoint_eig_v2_op.cc:19:\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h: In instantiation of 'void Eigen::internal::apply_rotation_in_the_plane(Eigen::DenseBase<Derived>&, Eigen::DenseBase<Derived>&, const Eigen::JacobiRotation<OtherScalar>&) [with VectorX = Eigen::Block<Eigen::Map<Eigen::Matrix<std::complex<float>, -1, -1>, 0, Eigen::Stride<0, 0> >, -1, 1, true>; VectorY = Eigen::Block<Eigen::Map<Eigen::Matrix<std::complex<float>, -1, -1>, 0, Eigen::Stride<0, 0> >, -1, 1, true>; OtherScalar = float]':\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:297:40:   required from 'void Eigen::MatrixBase<Derived>::applyOnTheRight(Eigen::Index, Eigen::Index, const Eigen::JacobiRotation<OtherScalar>&) [with OtherScalar = float; Derived = Eigen::Map<Eigen::Matrix<std::complex<float>, -1, -1>, 0, Eigen::Stride<0, 0> >; Eigen::Index = long int]'\r\nexternal/eigen_archive/Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h:861:7:   required from 'void Eigen::internal::tridiagonal_qr_step(RealScalar*, RealScalar*, Index, Index, Scalar*, Index) [with int StorageOrder = 0; RealScalar = float; Scalar = std::complex<float>; Index = long int]'\r\nexternal/eigen_archive/Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h:520:87:   required from 'Eigen::ComputationInfo Eigen::internal::computeFromTridiagonal_impl(DiagType&, SubDiagType&, Eigen::Index, bool, MatrixType&) [with MatrixType = Eigen::Matrix<std::complex<float>, -1, -1>; DiagType = Eigen::Matrix<float, -1, 1>; SubDiagType = Eigen::Matrix<float, -1, 1>; Eigen::Index = long int]'\r\nexternal/eigen_archive/Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h:439:49:   required from 'Eigen::SelfAdjointEigenSolver<MatrixType>& Eigen::SelfAdjointEigenSolver<_MatrixType>::compute(const Eigen::EigenBase<OtherDerived>&, int) [with InputType = Eigen::Map<const Eigen::Matrix<std::complex<float>, -1, -1, 1, -1, -1>, 0, Eigen::Stride<0, 0> >; _MatrixType = Eigen::Matrix<std::complex<float>, -1, -1, 1, -1, -1>]'\r\nexternal/eigen_archive/Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h:168:14:   required from 'Eigen::SelfAdjointEigenSolver<_MatrixType>::SelfAdjointEigenSolver(const Eigen::EigenBase<OtherDerived>&, int) [with InputType = Eigen::Map<const Eigen::Matrix<std::complex<float>, -1, -1, 1, -1, -1>, 0, Eigen::Stride<0, 0> >; _MatrixType = Eigen::Matrix<std::complex<float>, -1, -1, 1, -1, -1>]'\r\ntensorflow/core/kernels/self_adjoint_eig_v2_op.cc:66:73:   required from 'void tensorflow::SelfAdjointEigV2Op<Scalar>::ComputeMatrix(tensorflow::OpKernelContext*, const ConstMatrixMaps&, tensorflow::SelfAdjointEigV2Op<Scalar>::MatrixMaps*) [with Scalar = std::complex<float>; tensorflow::SelfAdjointEigV2Op<Scalar>::ConstMatrixMaps = tensorflow::gtl::InlinedVector<Eigen::Map<const Eigen::Matrix<std::complex<float>, -1, -1, 1, -1, -1>, 0, Eigen::Stride<0, 0> >, 4>; tensorflow::SelfAdjointEigV2Op<Scalar>::MatrixMaps = tensorflow::gtl::InlinedVector<Eigen::Map<Eigen::Matrix<std::complex<float>, -1, -1, 1, -1, -1>, 0, Eigen::Stride<0, 0> >, 4>]'\r\ntensorflow/core/kernels/self_adjoint_eig_v2_op.cc:95:1:   required from here\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:359:24: error: 'struct Eigen::internal::conj_helper<__vector(16) float, std::complex<float>, false, false>' has no member named 'pmul'\r\n         pstore(px, padd(pm.pmul(pc,xi),pcj.pmul(ps,yi)));\r\n                        ^\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:359:24: error: 'struct Eigen::internal::conj_helper<__vector(16) float, std::complex<float>, false, false>' has no member named 'pmul'\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:360:24: error: 'struct Eigen::internal::conj_helper<__vector(16) float, std::complex<float>, false, false>' has no member named 'pmul'\r\n         pstore(py, psub(pcj.pmul(pc,yi),pm.pmul(ps,xi)));\r\n                        ^\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:360:24: error: 'struct Eigen::internal::conj_helper<__vector(16) float, std::complex<float>, false, false>' has no member named 'pmul'\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:374:25: error: 'struct Eigen::internal::conj_helper<__vector(16) float, std::complex<float>, false, false>' has no member named 'pmul'\r\n         pstoreu(px, padd(pm.pmul(pc,xi),pcj.pmul(ps,yi)));\r\n                         ^\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:374:25: error: 'struct Eigen::internal::conj_helper<__vector(16) float, std::complex<float>, false, false>' has no member named 'pmul'\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:375:36: error: 'struct Eigen::internal::conj_helper<__vector(16) float, std::complex<float>, false, false>' has no member named 'pmul'\r\n         pstoreu(px+PacketSize, padd(pm.pmul(pc,xi1),pcj.pmul(ps,yi1)));\r\n                                    ^\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:375:36: error: 'struct Eigen::internal::conj_helper<__vector(16) float, std::complex<float>, false, false>' has no member named 'pmul'\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:376:25: error: 'struct Eigen::internal::conj_helper<__vector(16) float, std::complex<float>, false, false>' has no member named 'pmul'\r\n         pstore (py, psub(pcj.pmul(pc,yi),pm.pmul(ps,xi)));\r\n                         ^\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:376:25: error: 'struct Eigen::internal::conj_helper<__vector(16) float, std::complex<float>, false, false>' has no member named 'pmul'\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:377:36: error: 'struct Eigen::internal::conj_helper<__vector(16) float, std::complex<float>, false, false>' has no member named 'pmul'\r\n         pstore (py+PacketSize, psub(pcj.pmul(pc,yi1),pm.pmul(ps,xi1)));\r\n                                    ^\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:377:36: error: 'struct Eigen::internal::conj_helper<__vector(16) float, std::complex<float>, false, false>' has no member named 'pmul'\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:385:35: error: 'struct Eigen::internal::conj_helper<__vector(16) float, std::complex<float>, false, false>' has no member named 'pmul'\r\n         pstoreu(x+peelingEnd, padd(pm.pmul(pc,xi),pcj.pmul(ps,yi)));\r\n                                   ^\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:385:35: error: 'struct Eigen::internal::conj_helper<__vector(16) float, std::complex<float>, false, false>' has no member named 'pmul'\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:386:35: error: 'struct Eigen::internal::conj_helper<__vector(16) float, std::complex<float>, false, false>' has no member named 'pmul'\r\n         pstore (y+peelingEnd, psub(pcj.pmul(pc,yi),pm.pmul(ps,xi)));\r\n                                   ^\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:386:35: error: 'struct Eigen::internal::conj_helper<__vector(16) float, std::complex<float>, false, false>' has no member named 'pmul'\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:415:22: error: 'struct Eigen::internal::conj_helper<__vector(16) float, std::complex<float>, false, false>' has no member named 'pmul'\r\n       pstore(px, padd(pm.pmul(pc,xi),pcj.pmul(ps,yi)));\r\n                      ^\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:415:22: error: 'struct Eigen::internal::conj_helper<__vector(16) float, std::complex<float>, false, false>' has no member named 'pmul'\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:416:22: error: 'struct Eigen::internal::conj_helper<__vector(16) float, std::complex<float>, false, false>' has no member named 'pmul'\r\n       pstore(py, psub(pcj.pmul(pc,yi),pm.pmul(ps,xi)));\r\n                      ^\r\nexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:416:22: error: 'struct Eigen::internal::conj_helper<__vector(16) float, std::complex<float>, false, false>' has no member named 'pmul'\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 212.911s, Critical Path: 19.15s\r\nFAILED: Build did NOT complete successfully\r\n```\r\n\r\nBuild command is the following:\r\n\r\n`bazel build --config=opt --config=cuda --cxxopt=\"-fabi-version=0\" --cxxopt=\"-D_GLIBCXX_USE_CXX11_ABI=0\" //tensorflow/tools/pip_package:build_pip_package --verbose_failures\r\n`", "So, the problem is with error: '_mm512_insertf64x2' was not declared in this scope. What can I do to fix it?", "Finally, I was able to compile tensorflow on CPU with AVX512 (without AVX512 support) using gcc 4.8!", "Finally, I was able to compile tensorflow on CPU with AVX512 (without AVX512 support) using gcc 4.8!\r\nUnfortunately, now I get the following warning from tensorflow:\r\n\r\n`2017-09-13 21:45:51.237971: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F\r\n`", "@zyavrik It looks like avx512 was introduced in gcc 4.9 so 4.8 works (as it does not have avx 512)\r\nhttps://gcc.gnu.org/gcc-4.9/changes.html\r\n\r\nI probably could take a look at it though I don't have access to Skylake so it will be hard to debug. Will play with gcc to see if I could reproduce the issue you encounter by feeding `-m` flags.\r\n\r\nIn the mean time, is your linux Ubuntu 16.04 or 14.04?", "we have not tested TF with avx512, I think that is the problem. It is fairly new and we have not tested it thoroughly yet. Looks like you have resolved the build issue, but please fill in the issue template next time for us to be able to quickly help with your problem.", "@yongtang, thanks! I'm using Ubuntu 17.04.", "@gunan, why have you closed it? It's not resolved - it's impossible to use gcc 4.9+. Also it's impossible to compile tensorflow with AVX512. You can't just close it - the issues must be fixed.", "Sorry for quickly closing it, but your issue did not include enough debugging information. If you are filing an issue, please make sure to fill the template we have for issues.\r\n\r\nFor AVX512 support, I know it is frustrating for you, but there are still not many CPUs that suport these.\r\nAFAICR, there is already an open feature request that tracks avx512 support, so no need to keep a duplicate issue open for it. But we are happy to accept contributions that enable TF on avx512 CPUs, in case you are interested.\r\n\r\nFor issues with GCC 4.9 and above, it is not clear from the above that was one of the problems you had.\r\nAll logs you shared seem to point to issues with avx512. For the issues with gcc 4.9 and above, please file a new issue, this time filling out all of the questions posed by the template including the command you used to build, your OS and compiler versions, and we will be happy to debug the problems.", "have look at i9-7900x version\r\nhttps://github.com/thupalo/TF1.4_GPU_CUDA9_AVX512F\r\nI hope that the sources/tools are better now\r\nI have no messages regarding the new instructions:\r\n```\r\n2017-11-14 23:03:04.797397: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1064] Found device 0 with properties: \r\nname: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.62\r\npciBusID: 0000:17:00.0\r\ntotalMemory: 10.91GiB freeMemory: 10.75GiB\r\n2017-11-14 23:03:05.023753: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1064] Found device 1 with properties: \r\nname: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.62\r\npciBusID: 0000:65:00.0\r\ntotalMemory: 10.91GiB freeMemory: 9.34GiB\r\n2017-11-14 23:03:05.024254: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1079] Device peer to peer matrix\r\n2017-11-14 23:03:05.024269: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1085] DMA: 0 1 \r\n2017-11-14 23:03:05.024273: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1095] 0:   Y Y \r\n2017-11-14 23:03:05.024275: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1095] 1:   Y Y \r\n2017-11-14 23:03:05.024287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1154] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:17:00.0, compute capability: 6.1)\r\n2017-11-14 23:03:05.024291: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1154] Creating TensorFlow device (/device:GPU:1) -> (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:65:00.0, compute capability: 6.1)\r\n\r\n```\r\n"]}]