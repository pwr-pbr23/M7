[{"number": 15466, "title": "Add a wrapper for cc_library: tf_cc_library", "body": "I'll replace every cc_library under //tensorflow with tf_cc_library", "comments": ["Can one of the admins verify this patch?", "@meteorcloudy any thoughts here? I'd really like to avoid having `is_external` around every contrib cc_library() rule. In theory, couldn't we just default is_external to True and then add it to the _pywrap_tensorflow_internal rule only?", "Not every contrib cc_library() rule. Some modules under tensorflow/contrib is part of _pywrap_tensorflow_internal.so, and we need to set is_external=False in these dirs. \r\n\r\nAnother thing: we may disable --config=monolithic on windows. So every kernel is external to the framework shared library. It would be eaiser for us to set CFLAGS correctly. ", "I have a suggestion:\r\n1. remove the is_external arugment\r\n2. manually add \"-DTF_COMPILE_LIBRARY\" to every cc_libraries who is part of the _pywrap_tensorflow_internal.so\r\nThat's sounds more straightforward, because we may have multiple so libraries in the future. We'll add -DTF_COMPILE_AAA to the libraries of libaaa.so , -DTF_COMPILE_BBB to the libraries of libbbb.so, etc.\r\n\r\n\r\n\r\n\r\n", "I am really not fond of either this solution, or the previous one where we added `tf_copts` to all the `cc_library` rules.\r\nI have two alternate suggestions:\r\n * Setting the flag we need to pass in windows build through the windows Crosstool.\r\n * Writing the flag we need to pass in windows build in our bazelrc file during configure. We already write windows-specific things into our bazelrc anyway.\r\n\r\n@meteorcloudy WDYT?", "Close it as I don't have a good solution right now. ", "Sorry everyone, I was on vacation for the last two weeks.\r\n\r\nIn my opinion, if the options are applied to all compile or linking actions, they should be added into CROSSTOOL, that also means TF team has to maintain their own CROSSTOOL file.\r\n\r\nAnd for options, like `-DTF_COMPILE_LIBRARY`, that are only supposed to be applied to certain targets, using a macro would be better.\r\n\r\n> Some modules under tensorflow/contrib is part of _pywrap_tensorflow_internal.so\r\n\r\n@gunan @snnn Is this true? I didn't notice any targets under tensorflow/contrib that's a part of _pywrap_tensorflow_internal.so", "There may be exceptions, but our goal is nothing outside of contrib should depend on anything under contrib.\r\nI think nccl is one of the exceptions we have. But that is OK because for GPUs we maintain our crosstool files (not sure for windows GPU).\r\n\r\n@meteorcloudy is it possible for us to create a crosstool file that inherits from core bazel crosstool files?\r\nWe do not need to maintain most of the CPU crosstools, but such things come up every now and then where things can be fixed with a single line added to the crosstool file.", "The CROSSTOOL for Windows GPU is still on Bazel side, but I'm planing to move it to TF repo just like Unix one.\r\nI'd like to see TF has its own CPU CROSSTOOL as well. There is no way to directly inherit from the default one in Bazel, but we can reuse the MSVC detect mechanism from Bazel, see https://github.com/bazelbuild/bazel/commit/ff12a22fde96a28d6ad1279b60a421163e772aa6\r\n\r\n@gunan but I don't quite understand how does having TF's own CROSSTOOL solve this exact problem.\r\nIIUC, we want `-DTF_COMPILE_LIBRARY` passed for some targets, but not for all. However, adding it to CROSSTOOL will apply it to every compilation.\r\n", "Why do we need to define `-DTF_COMPILE_LIBRARY` only for a subset. What is the harm of defining it for all TF libraries in our crosstool?", "It's a common way to export and import symbol in VC++.\r\nLook at this code:\r\nhttps://github.com/tensorflow/tensorflow/blob/d89cf1347405e36ada4eb09be809c3c7ac01d451/tensorflow/core/platform/macros.h#L59-L65\r\n\r\n`TF_EXPORT` is used here:\r\nhttps://github.com/tensorflow/tensorflow/blob/f5f2f789ea395e585ddcbc43e088fa63d6b41d0e/tensorflow/core/framework/types.h#L73-L75\r\n\r\nWe define `TF_COMPILE_LIBRARY` when building code for `_pywrap_tensorflow_internal.so`, and undefine it when building contrib ops, so that symbols can be exported and imported correctly.\r\n\r\nWe also do it in CMake build in AddUserOps function\r\nhttps://github.com/tensorflow/tensorflow/blob/79422ab39b5fe0e1491abb8deabc7ecb5fd9f3a2/tensorflow/contrib/cmake/tf_cc_ops.cmake#L182-L186\r\n\r\nRelated: https://stackoverflow.com/questions/8863193/what-does-declspecdllimport-really-mean", "I feel like we need a different way to choose what to export in contrib libraries. I do not feel good about conditionally changed value of a macro. I think it would be confusing to anyone who may need to touch these later.\r\n", "Why do we depend on macros like PLATFORM\\_WINDOWS and COMPILER\\_MSVC other than \\_WIN32 and \\_MSC\\_VER ? \\_WIN32 and \\_MSC\\_VER are builtin macros, we don't need to pass them through compiler command line args. \r\n\r\nNow we have such code in some header files:\r\n```c\r\n#if defined(PLATFORM_WINDOWS) \r\nx = 1;\r\n#else\r\nx = 2;\r\n#endif\r\n```\r\nThen, we have to add \"-DPLATFORM\\_WINDOWS\" to the copts of every file who includes such header.  Otherwise, we'll get incorrect behavior at runtime.\r\n", "Quite a lot of open-sourced Google code that runs on Windows use `PLATFORM_WINDOWS` and `COMPILER_MSVC`.\r\n\r\nHowever, a few Google projects will define `COMPILER_MSVC` *in header file*, not build script (https://cs.chromium.org/search/?q=%22%23define+COMPILER_MSVC%22+OR+%22define+V8_CC_MSVC%22&type=cs)\r\n\r\nOther open-sourced projects like zlib and icu that needs to support many compilers simply rely on `_MSC_VER` and `_WIN32` in source files and still have no issue. (https://cs.chromium.org/search/?q=_MSC_VER+OR+_WIN32&type=cs)\r\n\r\nNote:\r\n\r\n- `_WIN32` is defined in all Windows compilers targeting 32-bit and 64-bit, including Mingw[64] GCC, Mingw[64] Clang, MSVC Clang (`clang-cl`) and pure MSVC (`cl`).\r\n- `_WIN64` is defined in all Windows compilers targeting 64-bit, including Mingw64 GCC, Mingw64 Clang, MSVC Clang (`clang-cl`) and pure MSVC (`cl`).\r\n- `_MSC_VER` is defined in all MSVC-compatible compilers, including MSVC Clang (`clang-cl`) and pure MSVC (`cl`).\r\n\r\nGCC and Clang cross compilers on Linux and Mac OS targeting Windows will also define `_WIN32`, `_WIN64` and `_MSC_VER` according to the above rules. Directly relying on these macros will not break cross compilation."]}, {"number": 15464, "title": "[Feature Request] Sparse compute_gradient", "body": "I am working on an extremely large scale linear model and have been trying to optimize the performance of the TF optimizer.\r\n\r\n**Have I written custom code**\r\nVersion I.\r\nMy feature size is huge (500Mil) and sparse, so I was testing if I could make TF only compute the necessary gradients and apply it using some function like tf.scatter_sub()\r\nMy graph is like this:\r\n```\r\ncost = fn(w)\r\nvars_to_update = tf.gather(w, non_zero_indices)\r\ngrads = tf.gradients(cost, vars_to_update)\r\nupdate_op = tf.scatter_sub(w, non_zero_indeces, grads)\r\n```\r\nI found that tf.graidents() always returns None for tf.gather(). Similar condition if I pass tf.gather() to any optimizer like tf.train.GradientDescentOpitmizer(cost, tf.gather(w, indices)), it will throw unsupported error for tf.gather(). \r\n\r\nI was wondering if I did anything wrong or TF just doesn't support sparse gradient computation? If latter does TF team plan to have that implemented in short future?\r\n\r\nVersion II.\r\nIn stead of creating a sparse tensor and do sparse_tensor_dense_matmul(), I also tried using tf.gather() follow by tf.segment_sum() to implement W*X. By doing this the optimizer apparently automatically performed sparse grad computation and sparse update. However, the speed of the optimizer was **horribly slower (15seconds)** than the sparse tensor approach. And idea why?\r\n\r\nPseudo code:\r\n```\r\nactive_weights = tf.gather(weights, non_zero_indices)\r\ntotal = tf.segment_sum(\r\n                tf.reshape(activated_weights, [-1]),\r\n                segment_ids //which is the row number e.g. [0,0,0,0,1,1,1,2,2,2,3,3,...]\r\n                )\r\nupdate_op = tf.train.GradientDescentOptimizer().minimize(total, active_weights)\r\n```\r\n\r\n**OS Platform and Distribution**\r\nCentos Linux version 3.10.0-229.4.2.el7.x86_64 (gcc version 4.8.2 20140120 (Red Hat 4.8.2-16) (GCC) )\r\n\r\n**TensorFlow installed from (source or binary)**\r\npip install tensorflow\r\n\r\n**TF version**\r\n1.3.0\r\n\r\n**Python version**\r\n2.7.5\r\n\r\n**Bazel version, CUDA/cuDNN, GPU model and memory, Exact command to reproduce**\r\nN/A\r\n\r\n**Also there might be a potential bug**\r\nIf in the second approach (tf.gather() and tf.segment_sum()) I replace GradientDescentOptimizer with Adam or Adagrad optimizer, the memory would blow up very quickly. I did not look into why that happened so I am not sure if this worth a bug ticket.", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "@tensorflowbutler Thanks for the reminder. I've updated my post according to your suggestions.", "Did you try `embedding_lookup_sparse`?", "@formath Thanks for your suggestion. I am not sure how embddeing_lookup_sparse help in my case. Could you elaborate?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "The original poster has replied to this issue after the stat:awaiting response label was applied.", "@OscarDPan how did that work out for you?", "@drpngx Yes I have found the solution. The trick is to use tf.scatter_sub().op "]}, {"number": 15463, "title": "Bug: StagingArea.size() always return 0 when placed on a different device", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: ubuntu 14.04\r\n- **TensorFlow installed from (source or binary)**:source\r\n- **TensorFlow version (use command below)**:b'v1.3.0-rc1-6044-g0b80606' 1.4.0\r\n- **Python version**:  3.6\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:9.0/7.0\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow.python.ops.data_flow_ops import StagingArea\r\n\r\nareas = []\r\nstage_ops = []\r\nsizes = []\r\nfor idx, d in enumerate(['/gpu:0', '/gpu:1']):\r\n    with tf.device(d):\r\n        inputs = [tf.constant(1.0), tf.constant(2, dtype=tf.uint8)]\r\n        dtypes = [k.dtype for k in inputs]\r\n        stage = StagingArea(dtypes, shapes=None)\r\n        stage_ops.append(stage.put(inputs))\r\n        areas.append(stage)\r\n        # sizes.append(stage.size())   # this gives correct result\r\n\r\nsizes = [k.size() for k in areas]    # this gives wrong result\r\nwith tf.Session() as sess:\r\n    print(sess.run(sizes))    # [0, 0]\r\n    sess.run(stage_ops[0])\r\n    sess.run(stage_ops[1])\r\n    sess.run(stage_ops[0])\r\n    sess.run(stage_ops[1])\r\n    print(sess.run(sizes))  # expected: [2,2]; actual: [2,0]\r\n```", "comments": ["This is definitely one for @mrry.", "Reassigning to @ekelsen, who wrote the `StagingArea` code.", "It has been half a year and this still exists in 1.8", "unassign", "@ppwwyyxx Is this still an issue with latest versions (1.12, 1.13.1, and 2.0)? Could you check and let us know whether the bug persists with latest versions. Thanks!", "The issue exists in 1.13 compiled from github master yesterday.", "We recommend using tf.data and specifically Dataset.prefetch instead of StagingArea, when building your input pipelines. It allows for higher performance and has better tuning knobs.\r\n\r\nSo I'm closing this issue as wontfix as StagingArea is deprecated.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=15463\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=15463\">No</a>\n", "Data loading is not the only use of `StagingArea`.\r\n\r\nIt can be used to access stale variables/tensors (access variables/tensors from the previous step) to reduce latency in training. And because the user controls when to call `StagingArea.put/get`, the staleness is accurately controlled.\r\n\r\nThis usage appears several times in `tensorflow/benchmarks`:\r\nhttps://github.com/tensorflow/benchmarks/blob/ac830fc902b8743ff2cec83cb103df7d0fffce84/scripts/tf_cnn_benchmarks/variable_mgr_util.py#L316\r\nhttps://github.com/tensorflow/benchmarks/blob/ac830fc902b8743ff2cec83cb103df7d0fffce84/scripts/tf_cnn_benchmarks/batch_allreduce.py#L432\r\n\r\nI don't see how this can be easily done with other tools in tensorflow.", "You can always replace a StagingArea with a variable, no?\n\nOn Thu, Apr 25, 2019 at 4:31 PM Yuxin Wu <notifications@github.com> wrote:\n\n> Data loading is not the only use of StagingArea.\n>\n> It can be used to access stale variables/tensors (access variables/tensors\n> from the previous step) to reduce latency in training. And because the user\n> controls when to call StagingArea.put/get, the staleness is accurately\n> controlled.\n>\n> This usage appears several times in tensorflow/benchmarks:\n>\n> https://github.com/tensorflow/benchmarks/blob/ac830fc902b8743ff2cec83cb103df7d0fffce84/scripts/tf_cnn_benchmarks/variable_mgr_util.py#L316\n>\n> https://github.com/tensorflow/benchmarks/blob/ac830fc902b8743ff2cec83cb103df7d0fffce84/scripts/tf_cnn_benchmarks/batch_allreduce.py#L432\n>\n> I don't see how this can be easily done with other tools in tensorflow.\n>\n> \u2014\n> You are receiving this because you modified the open/close state.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/15463#issuecomment-486872514>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAABHRM644CU5WWGOP53LTDPSI5ONANCNFSM4EIZEGSA>\n> .\n>\n\n\n-- \n - Alex\n", "Yeah, for StagingArea with size=1 it's straightforward with variables + control dependencies. Getting more complicated to mimic larger StagingArea, but I suppose those are not very useful anymore.\r\nIn fact using variables to mimic a queue was suggested before StagingArea was added to TF (https://github.com/tensorflow/tensorflow/issues/4526#issuecomment-249021613), though I don't know if anyone actually did it.\r\nThanks for your response!", "In fact I just realized that a variable cannot mimic a StagingArea because the Tensors put into a StagingArea can have different sizes.\r\nWe're also having some work that needs a queue of size >1, therefore having a GPU-resided queue is still extremely useful.", "Tensors put into variables can also have partially unknown shapes.\n\nOn Thu, Oct 31, 2019 at 2:35 AM Yuxin Wu <notifications@github.com> wrote:\n\n> In fact I just realized that a variable cannot mimic a StagingArea because\n> the Tensors put into a StagingArea can have different sizes.\n> We're also having some work that needs a queue of size >1, therefore\n> having a GPU-resided queue is still extremely useful.\n>\n> \u2014\n> You are receiving this because you modified the open/close state.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/15463?email_source=notifications&email_token=AAABHRLSK3HVSIMU7EK4Q3TQRKRHFA5CNFSM4EIZEGSKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOECXBIQQ#issuecomment-548279362>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAABHRK5HLK6MTXMRBE32C3QRKRHFANCNFSM4EIZEGSA>\n> .\n>\n\n\n-- \n - Alex\n"]}, {"number": 15462, "title": "Disable failing testcases on windows.", "body": "", "comments": []}, {"number": 15461, "title": "Updating MKL to the latest release.", "body": "", "comments": ["Can one of the admins verify this patch?", "@jart Can you mirror the new MKL URL?", "Mirror is now available.", "Thanks @gunan!", "@tensorflow-jenkins test this please", "windows cmake rerun at http://ci.tensorflow.org/job/tensorflow-pr-win-cmake-py/5902/"]}, {"number": 15460, "title": "Branch 179464468", "body": "Push", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please", "@tensorflow-jenkins test this please"]}, {"number": 15459, "title": "Enable api compatibility test to also run on macos.", "body": "Looks like it also passes on macos when we use python 2.\r\n", "comments": []}, {"number": 15458, "title": "Upgrade all TF base images to ubuntu 16.", "body": "", "comments": ["@tensorflow-jenkins test this please", "There are some failures again, but I don't understand why they might be occurring (cpu-python could be a change in the Ubuntu 14-16 change) -- copying some below in case Jenkins doesn't cache them long enough:\r\n\r\n```\r\n(sanity)\r\nFAIL: Found 1 non-whitelited pylint errors:\r\npython3: can't open file '/usr/local/lib/python3.4/dist-packages/pylint/lint.py': [Errno 2] No such file or directory\r\n```\r\n\r\n```\r\n(cpu-python3)\r\nERROR: /workspace/tensorflow/core/BUILD:1504:1: undeclared inclusion(s) in rule '//tensorflow/core:lib_hash_crc32c_accelerate_internal':\r\nthis rule is missing dependency declarations for the following files included by 'tensorflow/core/lib/hash/crc32c_accelerate.cc':\r\n  '/usr/lib/gcc/x86_64-linux-gnu/5/include/stddef.h'\r\n  '/usr/lib/gcc/x86_64-linux-gnu/5/include/stdint.h'\r\n  '/usr/lib/gcc/x86_64-linux-gnu/5/include/nmmintrin.h'\r\n  '/usr/lib/gcc/x86_64-linux-gnu/5/include/smmintrin.h'\r\n  '/usr/lib/gcc/x86_64-linux-gnu/5/include/tmmintrin.h'\r\n  '/usr/lib/gcc/x86_64-linux-gnu/5/include/pmmintrin.h'\r\n  '/usr/lib/gcc/x86_64-linux-gnu/5/include/emmintrin.h'\r\n  '/usr/lib/gcc/x86_64-linux-gnu/5/include/xmmintrin.h'\r\n  '/usr/lib/gcc/x86_64-linux-gnu/5/include/mmintrin.h'\r\n  '/usr/lib/gcc/x86_64-linux-gnu/5/include/mm_malloc.h'\r\n  '/usr/lib/gcc/x86_64-linux-gnu/5/include/popcntintrin.h'.\r\nINFO: Building complete.\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nERROR: /workspace/tensorflow/tools/pip_package/BUILD:141:1 undeclared inclusion(s) in rule '//tensorflow/core:lib_hash_crc32c_accelerate_internal':\r\nthis rule is missing dependency declarations for the following files included by 'tensorflow/core/lib/hash/crc32c_accelerate.cc':\r\n  '/usr/lib/gcc/x86_64-linux-gnu/5/include/stddef.h'\r\n  '/usr/lib/gcc/x86_64-linux-gnu/5/include/stdint.h'\r\n  '/usr/lib/gcc/x86_64-linux-gnu/5/include/nmmintrin.h'\r\n  '/usr/lib/gcc/x86_64-linux-gnu/5/include/smmintrin.h'\r\n  '/usr/lib/gcc/x86_64-linux-gnu/5/include/tmmintrin.h'\r\n  '/usr/lib/gcc/x86_64-linux-gnu/5/include/pmmintrin.h'\r\n  '/usr/lib/gcc/x86_64-linux-gnu/5/include/emmintrin.h'\r\n  '/usr/lib/gcc/x86_64-linux-gnu/5/include/xmmintrin.h'\r\n  '/usr/lib/gcc/x86_64-linux-gnu/5/include/mmintrin.h'\r\n  '/usr/lib/gcc/x86_64-linux-gnu/5/include/mm_malloc.h'\r\n  '/usr/lib/gcc/x86_64-linux-gnu/5/include/popcntintrin.h'.\r\nINFO: Elapsed time: 6.483s, Critical Path: 0.22s\r\nBuild failed.\r\n```", "Looks like Ubuntu16.04 python3 defaults to be python3.5 and our pylint script is looking for /usr/local/lib/python3.4/dist-packages/pylint/lint.py.", "@mhlopko I think we are running into a bazel bug. Please see the following failure:\r\n```\r\nERROR: /workspace/tensorflow/tools/pip_package/BUILD:141:1 undeclared inclusion(s) in rule '//tensorflow/core:lib_hash_crc32c_accelerate_internal':\r\nthis rule is missing dependency declarations for the following files included by 'tensorflow/core/lib/hash/crc32c_accelerate.cc':\r\n  '/usr/lib/gcc/x86_64-linux-gnu/5/include/stddef.h'\r\n  '/usr/lib/gcc/x86_64-linux-gnu/5/include/stdint.h'\r\n  '/usr/lib/gcc/x86_64-linux-gnu/5/include/nmmintrin.h'\r\n  '/usr/lib/gcc/x86_64-linux-gnu/5/include/smmintrin.h'\r\n  '/usr/lib/gcc/x86_64-linux-gnu/5/include/tmmintrin.h'\r\n  '/usr/lib/gcc/x86_64-linux-gnu/5/include/pmmintrin.h'\r\n  '/usr/lib/gcc/x86_64-linux-gnu/5/include/emmintrin.h'\r\n  '/usr/lib/gcc/x86_64-linux-gnu/5/include/xmmintrin.h'\r\n  '/usr/lib/gcc/x86_64-linux-gnu/5/include/mmintrin.h'\r\n  '/usr/lib/gcc/x86_64-linux-gnu/5/include/mm_malloc.h'\r\n  '/usr/lib/gcc/x86_64-linux-gnu/5/include/popcntintrin.h'.\r\n```\r\n\r\nI think we should be using built-in crosstool for our CPU builds. Maybe the default crosstools missing cxx include directories?", "I have sent cls for failing tests internally. When those are submitted and pushed we can merge this (finally!)", "@gunan I did a push yesterday but didn't notice your CLs. Please ping on this thread when they're submitted.", "CCd you in the cls. Will ping this thread as you requested once the cls are in so we can retrigger tests.", "Thank you!", "The cls are submitted, and should be pushed wednesday or thursday.\r\nJenkins, test this please."]}, {"number": 15457, "title": "Small fix in the example", "body": "There's a typo in the example\r\n\r\ntflite_modeL -> tflite_model", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address on your commit.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot. The email used to register you as an authorized contributor must be the email used for the Git commit.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n<!-- need_sender_cla -->", "Fix looks good, thanks @leandroBorgesFerreira. Could you fix cla?", "@leandroBorgesFerreira could you fix the CLA? If you signed it, you should reply on this thread with \"I signed it!\"", "@tensorflow-jenkins test this please", "No response. Feel free to reopen."]}, {"number": 15456, "title": "Use Eigen version of the `scalar_fmod_op` for `fmod` ops", "body": "It seems that scalar_fmod_op is supported in Eigen so this fix changes `scalar_fmod2_op` to use Eigen version of the `scalar_fmod_op`.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": []}, {"number": 15455, "title": "Add customerized kernel implementation for clip_by_value", "body": "This fix is a follow up on #13998 as it was reverted in https://github.com/tensorflow/tensorflow/commit/943201bf1a959acf6a08b88a488b3db55404835c\r\n\r\nThis fix adds the customerized kernel implementation for `tf.clip_by_value`.\r\n\r\nThis fix is related to #13998, also see #15427\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["@benoitsteiner WDYT?", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @benoitsteiner: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "The PR has been rebased to address merge conflict.", "Nagging Assignee @benoitsteiner: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Rebased to address the merge conflict."]}, {"number": 15454, "title": "Update core.py", "body": "Corrected the documentation of the Dense layer, regarding the computation performed by the layer", "comments": ["Can one of the admins verify this patch?"]}, {"number": 15453, "title": "Update math_ops.py", "body": "Corrected documentation of tf.reduce_mean()", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please."]}, {"number": 15452, "title": "Build break on locale Windows", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug or a feature request.\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10 1703\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: d752244 1.4.0\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**: cmake 3.9.6\r\n- **GCC/Compiler version (if compiling from source)**: msvc 1900\r\n- **CUDA/cuDNN version**: cuda 8.0.61 / cudnn 6.0\r\n- **GPU model and memory**: 1080ti 11GiB\r\n- **Exact command to reproduce**:\r\n\r\n    cmake .. -A x64 -DCMAKE_BUILD_TYPE=Release ^\r\n    -DSWIG_EXECUTABLE=C:\\Users\\User\\swigwin-3.0.10\\swig.exe ^\r\n    -DPYTHON_EXECUTABLE=C:\\Users\\User\\Anaconda3\\python.exe ^\r\n    -DPYTHON_LIBRARIES=C:\\Users\\User\\Anaconda3\\python36.lib ^\r\n    -Dtensorflow_ENABLE_GPU=ON ^\r\n    -DCUDNN_HOME=\"C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v8.0\" ^\r\n    -Dtensorflow_WIN_CPU_SIMD_OPTIONS=/arch:AVX2\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nBecause msvc use locale code page to open source file, build fail on re2's test if use locale Windows.\r\n\r\nAlready create a PR on upstream, https://github.com/google/re2/pull/163\r\n\r\nPlease help,\r\n\r\nThanks.\r\n\r\n### Source code / logs\r\n    C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2\\testing\\re2_test.cc(1281): error C2001: \u5e38\u6578\u4e2d\u5305\u542b\u65b0\u884c\u5b57\u5143 [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2_test.vcxproj] [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2.vcxproj]\r\n    C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2\\testing\\re2_test.cc(1282): error C2064: \u8a5e\u5f59\u4e0d\u7b49\u65bc\u4f7f\u7528 1 \u5f15\u6578\u7684\u51fd\u5f0f [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2_test.vcxproj] [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2.vcxproj]\r\n    C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2\\testing\\re2_test.cc(1284): error C2001: \u5e38\u6578\u4e2d\u5305\u542b\u65b0\u884c\u5b57\u5143 [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2_test.vcxproj] [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2.vcxproj]\r\n    C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2\\testing\\re2_test.cc(1285): error C2064: \u8a5e\u5f59\u4e0d\u7b49\u65bc\u4f7f\u7528 1 \u5f15\u6578\u7684\u51fd\u5f0f [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2_test.vcxproj] [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2.vcxproj]\r\n    C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2\\testing\\re2_test.cc(1287): error C2001: \u5e38\u6578\u4e2d\u5305\u542b\u65b0\u884c\u5b57\u5143 [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2_test.vcxproj] [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2.vcxproj]\r\n    C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2\\testing\\re2_test.cc(1288): error C2064: \u8a5e\u5f59\u4e0d\u7b49\u65bc\u4f7f\u7528 1 \u5f15\u6578\u7684\u51fd\u5f0f [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2_test.vcxproj] [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2.vcxproj]\r\n    C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2\\testing\\re2_test.cc(1296): error C2059: \u8a9e\u6cd5\u932f\u8aa4: ';' [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2_test.vcxproj] [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2.vcxproj]\r\n    C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2\\testing\\re2_test.cc(1298): error C2070: 're2::ErrorTest []': sizeof \u904b\u7b97\u5143\u4e0d\u5408\u6cd5\uff0c\u5fc5\u9808\u662f\u904b\u7b97\u5f0f\u6216\u985e\u578b\u540d\u7a31 [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2_test.vcxproj] [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2.vcxproj]\r\n    C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2\\testing\\re2_test.cc(1365): error C2001: \u5e38\u6578\u4e2d\u5305\u542b\u65b0\u884c\u5b57\u5143 [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2_test.vcxproj] [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2.vcxproj]\r\n    C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2\\testing\\re2_test.cc(1366): error C2146: \u8a9e\u6cd5\u932f\u8aa4: \u907a\u6f0f ';' (\u5728\u8b58\u5225\u9805 'string' \u4e4b\u524d) [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2_test.vcxproj] [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2.vcxproj]\r\n    C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2\\testing\\re2_test.cc(1375): error C2001: \u5e38\u6578\u4e2d\u5305\u542b\u65b0\u884c\u5b57\u5143 [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2_test.vcxproj] [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2.vcxproj]\r\n    C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2\\testing\\re2_test.cc(1376): error C2001: \u5e38\u6578\u4e2d\u5305\u542b\u65b0\u884c\u5b57\u5143 [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2_test.vcxproj] [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2.vcxproj]\r\n    C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2\\testing\\re2_test.cc(1377): error C2001: \u5e38\u6578\u4e2d\u5305\u542b\u65b0\u884c\u5b57\u5143 [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2_test.vcxproj] [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2.vcxproj]\r\n    C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2\\testing\\re2_test.cc(1378): error C2001: \u5e38\u6578\u4e2d\u5305\u542b\u65b0\u884c\u5b57\u5143 [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2_test.vcxproj] [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2.vcxproj]\r\n    C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2\\testing\\re2_test.cc(1379): error C2001: \u5e38\u6578\u4e2d\u5305\u542b\u65b0\u884c\u5b57\u5143 [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2_test.vcxproj] [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2.vcxproj]\r\n    C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2\\testing\\re2_test.cc(1380): error C2001: \u5e38\u6578\u4e2d\u5305\u542b\u65b0\u884c\u5b57\u5143 [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2_test.vcxproj] [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2.vcxproj]\r\n    C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2\\testing\\re2_test.cc(1382): error C2001: \u5e38\u6578\u4e2d\u5305\u542b\u65b0\u884c\u5b57\u5143 [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2_test.vcxproj] [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2.vcxproj]\r\n    C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2\\testing\\re2_test.cc(1383): error C2001: \u5e38\u6578\u4e2d\u5305\u542b\u65b0\u884c\u5b57\u5143 [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2_test.vcxproj] [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2.vcxproj]\r\n    C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2\\testing\\re2_test.cc(1384): error C2001: \u5e38\u6578\u4e2d\u5305\u542b\u65b0\u884c\u5b57\u5143 [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2_test.vcxproj] [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2.vcxproj]\r\n    C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2\\testing\\re2_test.cc(1385): error C2001: \u5e38\u6578\u4e2d\u5305\u542b\u65b0\u884c\u5b57\u5143 [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2_test.vcxproj] [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2.vcxproj]\r\n    C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2\\testing\\re2_test.cc(1386): error C2001: \u5e38\u6578\u4e2d\u5305\u542b\u65b0\u884c\u5b57\u5143 [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2_test.vcxproj] [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2.vcxproj]\r\n    C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2\\testing\\re2_test.cc(1387): error C2001: \u5e38\u6578\u4e2d\u5305\u542b\u65b0\u884c\u5b57\u5143 [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2_test.vcxproj] [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2.vcxproj]\r\n    C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2\\testing\\re2_test.cc(1389): error C2001: \u5e38\u6578\u4e2d\u5305\u542b\u65b0\u884c\u5b57\u5143 [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2_test.vcxproj] [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2.vcxproj]\r\n    C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2\\testing\\re2_test.cc(1390): error C2001: \u5e38\u6578\u4e2d\u5305\u542b\u65b0\u884c\u5b57\u5143 [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2_test.vcxproj] [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2.vcxproj]\r\n    C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2\\testing\\re2_test.cc(1391): error C2001: \u5e38\u6578\u4e2d\u5305\u542b\u65b0\u884c\u5b57\u5143 [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2_test.vcxproj] [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2.vcxproj]\r\n    C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2\\testing\\re2_test.cc(1392): error C2001: \u5e38\u6578\u4e2d\u5305\u542b\u65b0\u884c\u5b57\u5143 [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2_test.vcxproj] [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2.vcxproj]\r\n    C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2\\testing\\re2_test.cc(1393): error C2001: \u5e38\u6578\u4e2d\u5305\u542b\u65b0\u884c\u5b57\u5143 [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2_test.vcxproj] [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2.vcxproj]\r\n    C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2\\testing\\re2_test.cc(1394): error C2001: \u5e38\u6578\u4e2d\u5305\u542b\u65b0\u884c\u5b57\u5143 [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2_test.vcxproj] [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2.vcxproj]\r\n    C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2\\testing\\re2_test.cc(1416): error C2001: \u5e38\u6578\u4e2d\u5305\u542b\u65b0\u884c\u5b57\u5143 [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2_test.vcxproj] [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2.vcxproj]\r\n    C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2\\testing\\re2_test.cc(1417): error C2001: \u5e38\u6578\u4e2d\u5305\u542b\u65b0\u884c\u5b57\u5143 [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2_test.vcxproj] [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2.vcxproj]\r\n    C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2\\testing\\re2_test.cc(1418): error C2001: \u5e38\u6578\u4e2d\u5305\u542b\u65b0\u884c\u5b57\u5143 [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2_test.vcxproj] [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2.vcxproj]\r\n    C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2\\testing\\re2_test.cc(1630): error C2001: \u5e38\u6578\u4e2d\u5305\u542b\u65b0\u884c\u5b57\u5143 [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2_test.vcxproj] [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2.vcxproj]\r\n    C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2\\testing\\re2_test.cc(1631): error C2001: \u5e38\u6578\u4e2d\u5305\u542b\u65b0\u884c\u5b57\u5143 [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2_test.vcxproj] [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2.vcxproj]\r\n    C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2\\testing\\re2_test.cc(1375): fatal error C1057: \u5de8\u96c6\u5c55\u958b\u4e2d\u672a\u9810\u671f\u7684\u6a94\u6848\u7d50\u5c3e [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2_test.vcxproj] [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2.vcxproj]\r\n    \r\n    C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2\\testing\\search_test.cc(244): error C2001: \u5e38\u6578\u4e2d\u5305\u542b\u65b0\u884c\u5b57\u5143 [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\search_test.vcxproj] [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2.vcxproj]\r\n    C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2\\testing\\search_test.cc(245): error C2001: \u5e38\u6578\u4e2d\u5305\u542b\u65b0\u884c\u5b57\u5143 [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\search_test.vcxproj] [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2.vcxproj]\r\n    C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2\\testing\\search_test.cc(246): error C2001: \u5e38\u6578\u4e2d\u5305\u542b\u65b0\u884c\u5b57\u5143 [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\search_test.vcxproj] [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2.vcxproj]\r\n    C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2\\testing\\search_test.cc(247): error C2001: \u5e38\u6578\u4e2d\u5305\u542b\u65b0\u884c\u5b57\u5143 [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\search_test.vcxproj] [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2.vcxproj]\r\n    C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2\\testing\\search_test.cc(248): error C2001: \u5e38\u6578\u4e2d\u5305\u542b\u65b0\u884c\u5b57\u5143 [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\search_test.vcxproj] [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2.vcxproj]\r\n    C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2\\testing\\search_test.cc(249): error C2001: \u5e38\u6578\u4e2d\u5305\u542b\u65b0\u884c\u5b57\u5143 [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\search_test.vcxproj] [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2.vcxproj]\r\n    C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2\\testing\\search_test.cc(250): error C2001: \u5e38\u6578\u4e2d\u5305\u542b\u65b0\u884c\u5b57\u5143 [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\search_test.vcxproj] [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2.vcxproj]\r\n    C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2\\testing\\search_test.cc(252): error C2064: \u8a5e\u5f59\u4e0d\u7b49\u65bc\u4f7f\u7528 1 \u5f15\u6578\u7684\u51fd\u5f0f [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\search_test.vcxproj] [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2.vcxproj]\r\n    C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2\\testing\\search_test.cc(311): error C2064: \u8a5e\u5f59\u4e0d\u7b49\u65bc\u4f7f\u7528 1 \u5f15\u6578\u7684\u51fd\u5f0f [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\search_test.vcxproj] [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2.vcxproj]\r\n    C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2\\testing\\search_test.cc(311): error C2059: \u8a9e\u6cd5\u932f\u8aa4: ';' [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\search_test.vcxproj] [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2.vcxproj]\r\n    C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\re2\\testing\\search_test.cc(315): error C2070: 're2::RegexpTest []': sizeof \u904b\u7b97\u5143\u4e0d\u5408\u6cd5\uff0c\u5fc5\u9808\u662f\u904b\u7b97\u5f0f\u6216\u985e\u578b\u540d\u7a31 [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2\\src\\re2\\search_test.vcxproj] [C:\\Users\\User\\tensorflow\\tensorflow\\contrib\\cmake\\build\\re2.vcxproj]\r\n", "comments": ["This issue was fixed in 6a35171131331a31d70e67e6d244422f3d15aafb."]}, {"number": 15451, "title": "Tensorflow Installation Problem in Anaconda3-5.0.1Environment", "body": "After installing the Anaconda3-5.0.1 on Ubuntu 17.10, I have followed the following steps to install the Tesnorflow -\r\n\r\n$ conda create -n tensorflow python=3.6\r\n$ source activate tensorflow\r\n(tensorflow)$ pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-1.4.0-cp36-cp36m-linux_x86_64.whl\r\nAfter installing the above pakages, I have verified the above installation in Anaconda environment, following issues are faced -\r\nwe6aisol@we6aisol-H170-Gaming-3:$ source activate tensorflow\r\n(tensorflow) we6aisol@we6aisol-H170-Gaming-3:$ python\r\nPython 3.6.3 |Anaconda, Inc.| (default, Nov 20 2017, 20:41:42)\r\n[GCC 7.2.0] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n\r\nimport tensorflow as tf\r\n/home/we6aisol/anaconda3/envs/tensorflow/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\r\nreturn f(*args, **kwds)\r\nPlease help me to resolve this issue.\r\n\r\nThanks & Regards\r\nManoj Bansal", "comments": ["I have already tried several times and observed that latest tensorflow will\nrequire python3.6.\nPls. explain me the steps to follow to use python 3.5.\nThanks & Regards\nManoj Bansal\n\nOn Mon, Dec 18, 2017 at 8:47 PM, Changming Sun <notifications@github.com>\nwrote:\n\n> Please use python 3.5\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/15451#issuecomment-352453913>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAeI0_yATtB_so4q8OgnlhCEupByvC8Vks5tBoIAgaJpZM4RFmjc>\n> .\n>\n", "Please follow #14182 for updates on this issue."]}, {"number": 15450, "title": "TensorFlow binary was not compiled to use: AVX AVX2 from Java 1.8", "body": "\r\n![image](https://user-images.githubusercontent.com/12063612/34111971-2b81c42a-e446-11e7-8482-6e3f3867e8d6.png)\r\n\r\n![image](https://user-images.githubusercontent.com/12063612/34112074-6ad1b824-e446-11e7-8541-02ae054aefa0.png)\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform from Windows 10\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version 1.4.0\r\n- **Java version** : 1.8.0_144\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: \r\n- **GPU model and memory**: GTX 1060 6G and Memory 8G\r\n- **Exact command to reproduce**: javac\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\n\"C:\\Program Files\\Java\\jdk1.8.0_144\\bin\\java\" -agentlib:jdwp=transport=dt_socket,address=127.0.0.1:56173,suspend=y,server=n -javaagent:C:\\Users\\Administrator\\.IntelliJIdea2017.3\\system\\captureAgent\\debugger-agent.jar=C:\\Users\\Administrator\\AppData\\Local\\Temp\\capture.props -Dfile.encoding=UTF-8 -classpath \"C:\\Program Files\\Java\\jdk1.8.0_144\\jre\\lib\\charsets.jar;C:\\Program Files\\Java\\jdk1.8.0_144\\jre\\lib\\deploy.jar;C:\\Program Files\\Java\\jdk1.8.0_144\\jre\\lib\\ext\\access-bridge-64.jar;C:\\Program Files\\Java\\jdk1.8.0_144\\jre\\lib\\ext\\cldrdata.jar;C:\\Program Files\\Java\\jdk1.8.0_144\\jre\\lib\\ext\\dnsns.jar;C:\\Program Files\\Java\\jdk1.8.0_144\\jre\\lib\\ext\\jaccess.jar;C:\\Program Files\\Java\\jdk1.8.0_144\\jre\\lib\\ext\\jfxrt.jar;C:\\Program Files\\Java\\jdk1.8.0_144\\jre\\lib\\ext\\localedata.jar;C:\\Program Files\\Java\\jdk1.8.0_144\\jre\\lib\\ext\\nashorn.jar;C:\\Program Files\\Java\\jdk1.8.0_144\\jre\\lib\\ext\\sunec.jar;C:\\Program Files\\Java\\jdk1.8.0_144\\jre\\lib\\ext\\sunjce_provider.jar;C:\\Program Files\\Java\\jdk1.8.0_144\\jre\\lib\\ext\\sunmscapi.jar;C:\\Program Files\\Java\\jdk1.8.0_144\\jre\\lib\\ext\\sunpkcs11.jar;C:\\Program Files\\Java\\jdk1.8.0_144\\jre\\lib\\ext\\zipfs.jar;C:\\Program Files\\Java\\jdk1.8.0_144\\jre\\lib\\javaws.jar;C:\\Program Files\\Java\\jdk1.8.0_144\\jre\\lib\\jce.jar;C:\\Program Files\\Java\\jdk1.8.0_144\\jre\\lib\\jfr.jar;C:\\Program Files\\Java\\jdk1.8.0_144\\jre\\lib\\jfxswt.jar;C:\\Program Files\\Java\\jdk1.8.0_144\\jre\\lib\\jsse.jar;C:\\Program Files\\Java\\jdk1.8.0_144\\jre\\lib\\management-agent.jar;C:\\Program Files\\Java\\jdk1.8.0_144\\jre\\lib\\plugin.jar;C:\\Program Files\\Java\\jdk1.8.0_144\\jre\\lib\\resources.jar;C:\\Program Files\\Java\\jdk1.8.0_144\\jre\\lib\\rt.jar;C:\\gitspase\\zczdemo\\target\\classes;E:\\maven\\Jars\\org\\tensorflow\\tensorflow\\1.4.0\\tensorflow-1.4.0.jar;E:\\maven\\Jars\\org\\tensorflow\\libtensorflow\\1.4.0\\libtensorflow-1.4.0.jar;E:\\maven\\Jars\\org\\tensorflow\\libtensorflow_jni\\1.4.0\\libtensorflow_jni-1.4.0.jar;E:\\maven\\Jars\\org\\projectlombok\\lombok\\1.16.18\\lombok-1.16.18.jar;C:\\Program Files\\JetBrains\\IntelliJ IDEA 2017.3.1\\lib\\idea_rt.jar\" com.zcz.tensorflow.zczdemo.HelloTF\r\nConnected to the target VM, address: '127.0.0.1:56173', transport: 'socket'\r\nHello from 1.4.0\r\nDisconnected from the target VM, address: '127.0.0.1:56173', transport: 'socket'\r\n", "comments": ["2017-12-18 22:59:15.864242: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2\r\n\r\nfrom java VM options Can you specify the GPU?", "![image](https://user-images.githubusercontent.com/12063612/34112468-96bedb6e-e447-11e7-865b-5946f4accfdc.png)\r\n", "\r\n\r\n[display]\r\nOperating System: Windows 10 Pro, 64-bit\r\nDirectX version: 12.0\r\nGPU Processor: GeForce GTX 1060\r\nDriver Version: 388.59\r\nDirect3D API version: 12\r\nDirect3D functional level: 12_1\r\nCUDA core: 1280\r\nCore clock: 1404 MHz\r\nMemory data rate: 8008 MHz\r\nMemory Interface: 192-bit\r\nMemory Bandwidth: 192.19 GB / s\r\nTotal available graphics memory: 10180MB\r\nDedicated video memory: 6144 MB GDDR5\r\nSystem video memory: 0MB\r\nShared system memory: 4036MB\r\nVideo BIOS version: 86.06.18.00.04\r\nIRQ: Not used\r\nBus: PCI Express x16 Gen3\r\nDevice ID: 10DE 1C20 6A011558\r\nPart Number: 2914 0030\r\n\r\n[Component]\r\n\r\nnvui.dll\t\t8.17.13.8859\t\tNVIDIA User Experience Driver Component\r\nnvxdplcy.dll\t\t8.17.13.8859\t\tNVIDIA User Experience Driver Component\r\nnvxdbat.dll\t\t8.17.13.8859\t\tNVIDIA User Experience Driver Component\r\nnvxdapix.dll\t\t8.17.13.8859\t\tNVIDIA User Experience Driver Component\r\nNVCPL.DLL\t\t8.17.13.8859\t\tNVIDIA User Experience Driver Component\r\nnvCplUIR.dll\t\t8.1.940.0\t\tNVIDIA Control Panel\r\nnvCplUI.exe\t\t8.1.940.0\t\tNVIDIA Control Panel\r\nnvViTvSR.dll\t\t23.21.13.8859\t\tNVIDIA Video Server\r\nnvViTvS.dll\t\t23.21.13.8859\t\tNVIDIA Video Server\r\nNVSTVIEW.EXE\t\t7.17.13.8859\t\tNVIDIA 3D Vision Photo Viewer\r\nNVSTTEST.EXE\t\t7.17.13.8859\t\tNVIDIA 3D Vision Test Application\r\nNVSTRES.DLL\t\t7.17.13.8859\t\tNVIDIA 3D Vision Module\r\nnvDispSR.dll\t\t23.21.13.8859\t\tNVIDIA Display Server\r\nNVMCTRAY.DLL\t\t23.21.13.8859\t\tNVIDIA Media Center Library\r\nnvDispS.dll\t\t23.21.13.8859\t\tNVIDIA Display Server\r\nnvWSSR.dll\t\t23.21.13.8859\t\tNVIDIA Workstation Server\r\nnvWSS.dll\t\t23.21.13.8859\t\tNVIDIA Workstation Server\r\nPhysX\t\t09.17.0524\t\tNVIDIA PhysX\r\nNVCUDA.DLL\t\t23.21.13.8859\t\tNVIDIA CUDA 9.1.104 driver\r\nnvGameSR.dll\t\t23.21.13.8859\t\tNVIDIA 3D Settings Server\r\nnvGameS.dll\t\t23.21.13.8859\t\tNVIDIA 3D Settings Server\r\n", "![image](https://user-images.githubusercontent.com/12063612/34112625-2277d408-e448-11e7-9b99-92f3618b977f.png)\r\n", "Trouble to help me locate the problem, thanks", "It's a warning, not a bug.\r\nIf you need AVX support, compile libtensorflow by yourself. \r\n", "https://storage.googleapis.com/tensorflow/  i find storage,not find  libtensorflow_jni-gpu-windows-x86_64-1.4.0.zip ,only libtensorflow-gpu-linux-x86_64-1.4.0.tar.gz \r\n\r\n", "Have a tutorial, please send me, thank you", "Np. Your suggestion is nice, I feel sad that I can't help you. My English is bad. You may seek help from the others.", "This is a better question for stackoverflow. You can find some discussions about this by searching 'build tensorflow avx'. Essentially you need to [build from source](https://www.tensorflow.org/install/install_sources) specifying the right optimization flags for your platform in order to silence the warning.", "Just lower the warning level:\r\n\r\nimport os\r\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"]}, {"number": 15449, "title": "Tensorflow-gpu 1.4.1 windows binaries couldn't be found", "body": "------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10 1709\r\n- **TensorFlow installed from (source or binary)**: looking for the binary\r\n- **TensorFlow version (use command below)**: 1.4.1\r\n- **Python version**: 3.6.3 64-bit\r\n- **Exact command to reproduce**: \"pip3 install --upgrade tensorflow-gpu\"\r\n\r\n### Describe the problem\r\n\r\nCan't find the binaries for the 1.4.1 windows version", "comments": ["They didn't release TF 1.4.1 for Windows. I hope you've read the release note.\r\n\"NOTE: There is no Windows binary for 1.4.1. The only difference to 1.4.0 is the CloudML Engine fix, and since CloudML Engine only supports Linux, Windows is unaffected.\"\r\n", "Apparently I haven't. Thx"]}, {"number": 15448, "title": "[Feature] Dataset API - Reinitializable Iterator resets to first dataset element", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: slightly altered stock example (see below)\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: 1.4.0 from source\r\n- **Python version**: 3.6.3\r\n- **Bazel version (if compiling from source)**: 0.7.0\r\n- **GCC/Compiler version (if compiling from source)**: gcc (Ubuntu 5.4.0-6ubuntu1~16.04.5) 5.4.0 20160609\r\n- **CUDA/cuDNN version**: 8.0\r\n- **GPU model and memory**: Nvidia 1060\r\n\r\n### Describe the problem\r\nCurrently the re-initializable iterator API using .from_structure and Iterator.make_initializer always resets the get_next() op of the iterator to fetch the first element of its Dataset instance again after running `sess.run(training_init_op)` or `sess.run(validation_init_op)`, respectively. \r\n\r\nIs this really the intended behavior? This means, that if you want to switch between training and validation Datasets within one epoch (i.e. in a shorter rhythm than the full dataset length) you will always only iterate over the first `batch_size * number-of-training-steps-before-validation-step` elements of the training set during training. \r\n\r\n### Source code / logs\r\nI guess the code example will make it clearer:\r\n```\r\n# Define training and validation datasets with the same structure.\r\ntraining_dataset = tf.data.Dataset.range(100)\r\nvalidation_dataset = tf.data.Dataset.range(50)\r\n\r\n# A reinitializable iterator is defined by its structure. We could use the\r\n# `output_types` and `output_shapes` properties of either `training_dataset`\r\n# or `validation_dataset` here, because they are compatible.\r\niterator = tf.data.Iterator.from_structure(training_dataset.output_types,\r\n                                  training_dataset.output_shapes)\r\n\r\nnext_element = iterator.get_next()\r\n\r\n\r\ntraining_init_op = iterator.make_initializer(training_dataset)\r\nvalidation_init_op = iterator.make_initializer(validation_dataset)\r\n\r\nwith tf.Session() as sess:\r\n   # Run 20 epochs in which the training dataset is traversed, followed by the\r\n   # validation dataset.\r\n   for i in range(5):\r\n       # Initialize an iterator over the training dataset.\r\n       print(\"#########################  \", i)\r\n       sess.run(training_init_op)\r\n       for _ in range(10):\r\n           nel = sess.run(next_element)\r\n           print(\"train: \", type(nel), nel)\r\n\r\n       # Initialize an iterator over the validation dataset.\r\n       sess.run(validation_init_op)\r\n       for _ in range(5):\r\n           nel = sess.run(next_element)\r\n           print(\"valid: \", type(nel), nel)\r\n```\r\n\r\nProduces the output:\r\n\r\n```\r\n#########################   0\r\ntrain:  <class 'numpy.int64'> 0\r\ntrain:  <class 'numpy.int64'> 1\r\ntrain:  <class 'numpy.int64'> 2\r\ntrain:  <class 'numpy.int64'> 3\r\ntrain:  <class 'numpy.int64'> 4\r\ntrain:  <class 'numpy.int64'> 5\r\ntrain:  <class 'numpy.int64'> 6\r\ntrain:  <class 'numpy.int64'> 7\r\ntrain:  <class 'numpy.int64'> 8\r\ntrain:  <class 'numpy.int64'> 9\r\nvalid:  <class 'numpy.int64'> 0\r\nvalid:  <class 'numpy.int64'> 1\r\nvalid:  <class 'numpy.int64'> 2\r\nvalid:  <class 'numpy.int64'> 3\r\nvalid:  <class 'numpy.int64'> 4\r\n#########################   1\r\ntrain:  <class 'numpy.int64'> 0\r\ntrain:  <class 'numpy.int64'> 1\r\ntrain:  <class 'numpy.int64'> 2\r\ntrain:  <class 'numpy.int64'> 3\r\ntrain:  <class 'numpy.int64'> 4\r\ntrain:  <class 'numpy.int64'> 5\r\ntrain:  <class 'numpy.int64'> 6\r\ntrain:  <class 'numpy.int64'> 7\r\ntrain:  <class 'numpy.int64'> 8\r\ntrain:  <class 'numpy.int64'> 9\r\nvalid:  <class 'numpy.int64'> 0\r\nvalid:  <class 'numpy.int64'> 1\r\nvalid:  <class 'numpy.int64'> 2\r\nvalid:  <class 'numpy.int64'> 3\r\nvalid:  <class 'numpy.int64'> 4\r\n...\r\n```\r\nApparently, the latter 90 elements of the training set and the latter 45 elements of the validation set never get evaluated. I don't really see the real-world use-case for this behavior. \r\n\r\n\r\nI know that you can implement the other functionality via the feedable iterator scheme using one_shot_iterators (but not using initializable iterators) as highlighted by the code below (pay attention to the different iterators used for training and validation here):\r\n\r\n```\r\n# Define training and validation datasets with the same structure.\r\ntraining_dataset = tf.data.Dataset.range(10000000).repeat(2)\r\nvalidation_dataset = tf.data.Dataset.range(5000000).repeat(2)\r\n\r\n# A feedable iterator is defined by a handle placeholder and its structure. We\r\n# could use the `output_types` and `output_shapes` properties of either\r\n# `training_dataset` or `validation_dataset` here, because they have\r\n# identical structure.\r\nhandle = tf.placeholder(tf.string, shape=[])\r\niterator = tf.data.Iterator.from_string_handle(\r\n    handle, training_dataset.output_types, training_dataset.output_shapes)\r\nnext_element = iterator.get_next()\r\n\r\n# You can use feedable iterators with a variety of different kinds of iterator\r\ntraining_iterator = training_dataset.make_one_shot_iterator()\r\nvalidation_iterator = validation_dataset.make_initializable_iterator()\r\n\r\nwith tf.Session() as sess:\r\n    # The `Iterator.string_handle()` method returns a tensor that can be evaluated\r\n    # and used to feed the `handle` placeholder.\r\n    training_handle = sess.run(training_iterator.string_handle())\r\n    validation_handle = sess.run(validation_iterator.string_handle())\r\n    # Loop forever, alternating between training and validation.\r\n    for i in range(5):\r\n        print(\"######################## \", i)\r\n        i += 1\r\n        # Run 10 steps using the training dataset. Note that the training dataset is\r\n        # 2 * the original set, i.e. we run 2 epochs (see .repeat() argument), and we resume from where\r\n        # we left off in the previous `while` loop iteration.\r\n        for _ in range(10):\r\n            nel = sess.run(next_element, feed_dict={handle: training_handle})\r\n            print(\"train: \", type(nel), nel)\r\n\r\n        # Run one pass over the validation dataset.\r\n        sess.run(validation_iterator.initializer)\r\n        for _ in range(5):\r\n            nel = sess.run(next_element, feed_dict={handle: validation_handle})\r\n            print(\"valid: \", type(nel), nel)\r\n```\r\n\r\ncreates output:\r\n\r\n```\r\n########################  0\r\ntrain:  <class 'numpy.int64'> 0\r\ntrain:  <class 'numpy.int64'> 1\r\ntrain:  <class 'numpy.int64'> 2\r\ntrain:  <class 'numpy.int64'> 3\r\ntrain:  <class 'numpy.int64'> 4\r\ntrain:  <class 'numpy.int64'> 5\r\ntrain:  <class 'numpy.int64'> 6\r\ntrain:  <class 'numpy.int64'> 7\r\ntrain:  <class 'numpy.int64'> 8\r\ntrain:  <class 'numpy.int64'> 9\r\nvalid:  <class 'numpy.int64'> 0\r\nvalid:  <class 'numpy.int64'> 1\r\nvalid:  <class 'numpy.int64'> 2\r\nvalid:  <class 'numpy.int64'> 3\r\nvalid:  <class 'numpy.int64'> 4\r\n########################  1\r\ntrain:  <class 'numpy.int64'> 10\r\ntrain:  <class 'numpy.int64'> 11\r\ntrain:  <class 'numpy.int64'> 12\r\ntrain:  <class 'numpy.int64'> 13\r\ntrain:  <class 'numpy.int64'> 14\r\ntrain:  <class 'numpy.int64'> 15\r\ntrain:  <class 'numpy.int64'> 16\r\ntrain:  <class 'numpy.int64'> 17\r\ntrain:  <class 'numpy.int64'> 18\r\ntrain:  <class 'numpy.int64'> 19\r\nvalid:  <class 'numpy.int64'> 0\r\nvalid:  <class 'numpy.int64'> 1\r\nvalid:  <class 'numpy.int64'> 2\r\nvalid:  <class 'numpy.int64'> 3\r\nvalid:  <class 'numpy.int64'> 4\r\n########################  2\r\ntrain:  <class 'numpy.int64'> 20\r\ntrain:  <class 'numpy.int64'> 21\r\ntrain:  <class 'numpy.int64'> 22\r\ntrain:  <class 'numpy.int64'> 23\r\ntrain:  <class 'numpy.int64'> 24\r\ntrain:  <class 'numpy.int64'> 25\r\ntrain:  <class 'numpy.int64'> 26\r\ntrain:  <class 'numpy.int64'> 27\r\ntrain:  <class 'numpy.int64'> 28\r\ntrain:  <class 'numpy.int64'> 29\r\nvalid:  <class 'numpy.int64'> 0\r\nvalid:  <class 'numpy.int64'> 1\r\nvalid:  <class 'numpy.int64'> 2\r\nvalid:  <class 'numpy.int64'> 3\r\nvalid:  <class 'numpy.int64'> 4\r\n```", "comments": ["I'm having the same problem, how can you switch between training and validation pipeline, without resetting the iterators?", "Indeed, I have also observed the same issue.\r\nPrior to using the Dataset API, I could implement multiple queues that would fetch data in parallel; what was unfortunately not possible was to reset (reuse) them after an epoch, e.g. for repeated evaluation of the validation set.\r\n\r\nNow, with a re-initializable iterator, the queue(s) seem to be coupled to the iterator and will be forcibly reset by switching (if I see this correctly), which makes the whole thing a bit pointless to be used with training data; see OP's example.\r\n\r\nI also cannot see good use cases for this behavior. In our code base, we intend to evaluate the validation set periodically after a certain number of training iterations, multiple times per training epoch. For this (supposedly quite common) use case seamless switching is necessary.", "It sounds like the reinitializable iterator is working as intended (resetting to its initial state when you run the initializer). You should use the feedable iterator if you want to switch between two iterators without resetting. Feedable iterators work with both one-shot and initializable iterators. Feel free to reopen the bug if the feedable iterators aren't working as expected.", "IIRC there's a performance hit when using the feedable API. Is that still the case or not?", "I haven't seen any specific reports about a performance hit. Feeding an extra value might cost ~10s of microseconds per step, but that's usually in the noise.", "@mrry Thanks for clarifying. I am still wondering what real-life use case the re-initializable iterators serve then? To me it seems that it can only be used practically for complete batch optimization but not for stochastic gradient descent or mini-batch or if I am content to get a validation loss only after each full training epoch. \r\nOr are there other possibilities to manipulate your dataset in such a way that you can still intertwine training and validation set mini batches using the re-initializable iterator API?", "Reinitializable iterators allow you to change the parameters of a dataset by feeding placeholders when you initialize them. This lets you do things like changing the training or test set at the end of an epoch to reflect new input files that have been added in the meantime. Even if they aren't appropriate for your use case, remember that TensorFlow users are a diverse and creative bunch, and might have different requirements!", "I see, thanks for laying it out to me :)", "I'm having the same problem\uff0cI train my network always using the process:\r\nfor i in range(train_step):\r\n    sess.run(train_op_with_next_train_batch)\r\n    if i%100==0:\r\n        sess.run(test_with_next_test_batch)\r\nbut, i can't do that with tf.data, .make_one_shot_iterator() can only train data one epoch, make_initializable_iterator() will restart from the begining, how to solve this problem?\r\nI try to solve this problem by set data_set.repead(10000), but i don't think this is a good ieda.\r\nDo you have any idea?thanks very much.", "~~It looks like you could manually [save and restore the state of the iterator](https://www.tensorflow.org/programmers_guide/datasets#saving_iterator_state), and this would allow you to swap between different datasets without resetting to the first dataset element.  I haven't tried it yet, though, so I can't guarantee for sure.~~\r\n\r\nLooks like this will throw an UnimplementedError, as [not all iterators support saving state](https://www.tensorflow.org/api_docs/python/tf/contrib/data/make_saveable_from_iterator).\r\n\r\n\r\n"]}, {"number": 15446, "title": "call within the loop", "body": "optimize call within the loop", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please", "Jenkins, test this please."]}, {"number": 15445, "title": "Cannot compile tensorflow lite (TfLiteCameraDemo and tensorflow/python/tools:freeze_graph) on macOS Sierra", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS Sierra 10.12.6\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: 1.4.1 (fdf34a8 on master branch)\r\n- **Python version**: 2.7.13\r\n- **Bazel version (if compiling from source)**: 0.8.1-homebrew\r\n- **GCC/Compiler version (if compiling from source)**: Xcode 9.2\r\n- **CUDA/cuDNN version**:  (not using cuda)\r\n- **GPU model and memory**: (not using GPU)\r\n- **Exact command to reproduce**: `bazel build -c opt --cxxopt='--std=c++11' //tensorflow/contrib/lite/java/demo/app/src/main:TfLiteCameraDemo`\r\n\r\n### Describe the problem\r\nI can compile tensorflow android demo on macOS, but cannot compile tensorflow lite android demo successfully. What I actually want to do is convert a tensorflow model to tensorflow lite model. Similar errors happen.\r\n\r\n**UPDATE on Dec 19, 2017: I found the workaround/solution. See my reply below.**\r\n\r\n### Source code / logs\r\nCompiled tensorflow android demo on macOS successfully.\r\n```\r\n$ bazel build -c opt //tensorflow/examples/android:tensorflow_demo\r\n...\r\nTarget //tensorflow/examples/android:tensorflow_demo up-to-date:\r\n  bazel-bin/tensorflow/examples/android/tensorflow_demo_deploy.jar\r\n  bazel-bin/tensorflow/examples/android/tensorflow_demo_unsigned.apk\r\n  bazel-bin/tensorflow/examples/android/tensorflow_demo.apk\r\nINFO: Elapsed time: 862.549s, Critical Path: 112.20s\r\nINFO: Build completed successfully, 776 total actions\r\n```\r\n\r\nBut failed to compile tensorflow lite android demo.\r\n```\r\n$ bazel build -c opt --cxxopt='--std=c++11' //tensorflow/contrib/lite/java/demo/app/src/main:TfLiteCameraDemo\r\nERROR: /Users/XXX/GitRoot/OpenSourceProjects/tensorflow/tensorflow/contrib/lite/BUILD:193:12: Label '//tensorflow/contrib/lite:downloads/absl/absl/types/optional.h' crosses boundary of subpackage 'tensorflow/contrib/lite/downloads/absl/absl/types' (perhaps you meant to put the colon here: '//tensorflow/contrib/lite/downloads/absl/absl/types:optional.h'?)\r\nERROR: /Users/XXX/GitRoot/OpenSourceProjects/tensorflow/tensorflow/contrib/lite/BUILD:193:12: Label '//tensorflow/contrib/lite:downloads/absl/absl/base/config_test.cc' crosses boundary of subpackage 'tensorflow/contrib/lite/downloads/absl/absl/base' (perhaps you meant to put the colon here: '//tensorflow/contrib/lite/downloads/absl/absl/base:config_test.cc'?)\r\nERROR: /Users/XXX/GitRoot/OpenSourceProjects/tensorflow/tensorflow/contrib/lite/BUILD:193:12: Label '//tensorflow/contrib/lite:downloads/absl/absl/debugging/internal/address_is_readable.h' crosses boundary of subpackage 'tensorflow/contrib/lite/downloads/absl/absl/debugging' (perhaps you meant to put the colon here: '//tensorflow/contrib/lite/downloads/absl/absl/debugging:internal/address_is_readable.h'?)\r\nERROR: /Users/XXX/GitRoot/OpenSourceProjects/tensorflow/tensorflow/contrib/lite/BUILD:193:12: Label '//tensorflow/contrib/lite:downloads/absl/absl/debugging/leak_check.h' crosses boundary of subpackage 'tensorflow/contrib/lite/downloads/absl/absl/debugging' (perhaps you meant to put the colon here: '//tensorflow/contrib/lite/downloads/absl/absl/debugging:leak_check.h'?)\r\nERROR: /Users/XXX/GitRoot/OpenSourceProjects/tensorflow/tensorflow/contrib/lite/BUILD:193:12: Label '//tensorflow/contrib/lite:downloads/absl/absl/strings/BUILD.bazel' crosses boundary of subpackage 'tensorflow/contrib/lite/downloads/absl/absl/strings' (perhaps you meant to put the colon here: '//tensorflow/contrib/lite/downloads/absl/absl/strings:BUILD.bazel'?)\r\n...\r\n```\r\n\r\nSimilar errors happen when I wanted to build the tool of converting tensorflow model to tensorflow lite model which is what I really need.\r\n```\r\n$ bazel build tensorflow/python/tools:freeze_graph\r\nWARNING: /Users/XXX/GitRoot/OpenSourceProjects/tensorflow/tensorflow/core/BUILD:1806:1: in includes attribute of cc_library rule //tensorflow/core:framework_headers_lib: '../../external/nsync/public' resolves to 'external/nsync/public' not below the relative path of its package 'tensorflow/core'. This will be an error in the future. Since this rule was created by the macro 'cc_header_only_library', the error might have been caused by the macro implementation in /Users/XXX/GitRoot/OpenSourceProjects/tensorflow/tensorflow/tensorflow.bzl:1131:30\r\nERROR: /Users/XXX/GitRoot/OpenSourceProjects/tensorflow/tensorflow/contrib/lite/BUILD:193:12: Label '//tensorflow/contrib/lite:downloads/absl/absl/types/optional.h' crosses boundary of subpackage 'tensorflow/contrib/lite/downloads/absl/absl/types' (perhaps you meant to put the colon here: '//tensorflow/contrib/lite/downloads/absl/absl/types:optional.h'?)\r\nERROR: /Users/XXX/GitRoot/OpenSourceProjects/tensorflow/tensorflow/contrib/lite/BUILD:193:12: Label '//tensorflow/contrib/lite:downloads/absl/absl/base/config_test.cc' crosses boundary of subpackage 'tensorflow/contrib/lite/downloads/absl/absl/base' (perhaps you meant to put the colon here: '//tensorflow/contrib/lite/downloads/absl/absl/base:config_test.cc'?)\r\nERROR: /Users/XXX/GitRoot/OpenSourceProjects/tensorflow/tensorflow/contrib/lite/BUILD:193:12: Label '//tensorflow/contrib/lite:downloads/absl/absl/debugging/internal/address_is_readable.h' crosses boundary of subpackage 'tensorflow/contrib/lite/downloads/absl/absl/debugging' (perhaps you meant to put the colon here: '//tensorflow/contrib/lite/downloads/absl/absl/debugging:internal/address_is_readable.h'?)\r\nERROR: /Users/XXX/GitRoot/OpenSourceProjects/tensorflow/tensorflow/contrib/lite/BUILD:193:12: Label '//tensorflow/contrib/lite:downloads/absl/absl/debugging/leak_check.h' crosses boundary of subpackage 'tensorflow/contrib/lite/downloads/absl/absl/debugging' (perhaps you meant to put the colon here: '//tensorflow/contrib/lite/downloads/absl/absl/debugging:leak_check.h'?)\r\nWARNING: /Users/XXX/GitRoot/OpenSourceProjects/tensorflow/tensorflow/contrib/learn/BUILD:15:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:exporter': No longer supported. Switch to SavedModel immediately.\r\nWARNING: /Users/XXX/GitRoot/OpenSourceProjects/tensorflow/tensorflow/contrib/learn/BUILD:15:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:gc': No longer supported. Switch to SavedModel immediately.\r\nERROR: /Users/XXX/GitRoot/OpenSourceProjects/tensorflow/tensorflow/contrib/lite/BUILD:193:12: Label '//tensorflow/contrib/lite:downloads/absl/absl/strings/BUILD.bazel' crosses boundary of subpackage 'tensorflow/contrib/lite/downloads/absl/absl/strings' (perhaps you meant to put the colon here: '//tensorflow/contrib/lite/downloads/absl/absl/strings:BUILD.bazel'?)\r\n...\r\n```\r\n\r\nMy config in `WORKSPACE`\r\n```\r\nandroid_sdk_repository(\r\n    name = \"androidsdk\",\r\n    api_level = 23,\r\n    build_tools_version = \"26.0.1\",\r\n    path = \"/Users/XXX/Resources/Android/sdk\",\r\n)\r\n\r\nandroid_ndk_repository(\r\n    name=\"androidndk\",\r\n    path=\"/Users/XXX/Resources/Android/ndk/android-ndk-r14b\",\r\n    api_level=14,\r\n)\r\n```\r\n\r\nOther\r\n```\r\n$ python --version\r\nPython 2.7.13 :: Continuum Analytics, Inc.\r\n$ bazel version\r\nBuild label: 0.8.1-homebrew\r\nBuild target: bazel-out/darwin-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Tue Dec 5 19:33:07 2017 (1512502387)\r\nBuild timestamp: 1512502387\r\nBuild timestamp as int: 1512502387\r\n```\r\n\r\n```\r\n\r\n== cat /etc/issue ===============================================\r\nDarwin ITSG000227-MAC.local 16.7.0 Darwin Kernel Version 16.7.0: Wed Oct  4 00:17:00 PDT 2017; root:xnu-3789.71.6~1/RELEASE_X86_64 x86_64\r\nMac OS X 10.12.6\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\nApple LLVM version 9.0.0 (clang-900.0.39.2)\r\nTarget: x86_64-apple-darwin16.7.0\r\nThread model: posix\r\nInstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin\r\n\r\n== uname -a =====================================================\r\nDarwin ITSG000227-MAC.local 16.7.0 Darwin Kernel Version 16.7.0: Wed Oct  4 00:17:00 PDT 2017; root:xnu-3789.71.6~1/RELEASE_X86_64 x86_64\r\n\r\n== check pips ===================================================\r\nnumpy (1.13.3)\r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\n  File \"tensorflow/__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"tensorflow/python/__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"tensorflow/python/pywrap_tensorflow.py\", line 25, in <module>\r\n    from tensorflow.python.platform import self_check\r\nImportError: No module named platform\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH is unset\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\n./tools/tf_env_collect.sh: line 105: nvidia-smi: command not found\r\n\r\n== cuda libs  ===================================================\r\n```", "comments": ["I have the same problem\uff0cwhen i build this:`bazel build //tensorflow/contrib/lite/toco:toco`\r\nthese errors involves  this path\uff1a\u201ctensorflow/contrib/lite/downloads/absl/absl/\u201d.\r\n\r\nmaybe the bazel version 0.8.1  is mismatch\uff1fI have no idea at all.\r\n\r\n\r\n", "@jakajacky I also tried the old version of bazel which is used to build the official tensorflow releases. Same errors.\r\n\r\n**Good news! I accidentally built TensorFlow Lite successfully on macOS Sierra.** Since I could not build the TensorFlow Lite converter, I wanted to convert TensorFlow model to CoreML. Then I installed [coremltools](https://apple.github.io/coremltools/). Because you mentioned you could not build `bazel build //tensorflow/contrib/lite/toco:toco` and I had the same problem, I tried to build it again. It worked! Probably it is because it installs `protobuf` and the older version of `six`.\r\n\r\n```\r\n$ sudo pip install -U coremltools\r\nPassword:\r\nThe directory '/Users/XXX/Library/Caches/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\r\nThe directory '/Users/XXX/Library/Caches/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\r\nCollecting coremltools\r\n  Downloading coremltools-0.7-cp27-none-macosx_10_12_intel.whl (3.7MB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3.7MB 198kB/s \r\nCollecting protobuf>=3.1.0 (from coremltools)\r\n  Downloading protobuf-3.5.0.post1-py2.py3-none-any.whl (389kB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 389kB 1.6MB/s \r\nCollecting six==1.10.0 (from coremltools)\r\n  Downloading six-1.10.0-py2.py3-none-any.whl\r\nRequirement already up-to-date: numpy>=1.6.2 in /anaconda/envs/mypython2/lib/python2.7/site-packages (from coremltools)\r\nRequirement already up-to-date: setuptools in /anaconda/envs/mypython2/lib/python2.7/site-packages (from protobuf>=3.1.0->coremltools)\r\nInstalling collected packages: six, protobuf, coremltools\r\n  Found existing installation: six 1.11.0\r\n    Uninstalling six-1.11.0:\r\n      Successfully uninstalled six-1.11.0\r\nSuccessfully installed coremltools-0.7 protobuf-3.5.0.post1 six-1.10.0\r\n```\r\n\r\n```\r\n$ bazel build tensorflow/contrib/lite/toco:toco\r\nINFO: Analysed target //tensorflow/contrib/lite/toco:toco (5 packages loaded).\r\nINFO: Found 1 target...\r\nINFO: From ProtoCompile tensorflow/contrib/lite/toco/toco_flags.pb.cc:\r\nbazel-out/darwin-opt/genfiles/external/protobuf_archive/src: warning: directory does not exist.\r\nbazel-out/darwin-opt/genfiles/external/protobuf_archive/src: warning: directory does not exist.\r\n...\r\nTarget //tensorflow/contrib/lite/toco:toco up-to-date:\r\n  bazel-bin/tensorflow/contrib/lite/toco/toco\r\nINFO: Elapsed time: 312.332s, Critical Path: 35.52s\r\nINFO: Build completed successfully, 748 total actions\r\n```\r\n\r\n```\r\n$ bazel build tensorflow/python/tools:freeze_graph\r\nINFO: Analysed target //tensorflow/python/tools:freeze_graph (1 packages loaded).\r\nINFO: Found 1 target...\r\nINFO: From Linking tensorflow/core/liblib_internal_impl.a [for host]:\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: bazel-out/host/bin/tensorflow/core/liblib_internal_impl.a(android_armv7a_cpu_utils_helper.o) has no symbols\r\nINFO: From Compiling tensorflow/core/framework/op_kernel.cc [for host]:\r\ntensorflow/core/framework/op_kernel.cc:962:8: warning: unused function 'FindKernelRegistration' [-Wunused-function]\r\nStatus FindKernelRegistration(const DeviceType& device_type, const Node& node,\r\n       ^\r\n1 warning generated.\r\nINFO: From Compiling tensorflow/core/common_runtime/executor.cc [for host]:\r\ntensorflow/core/common_runtime/executor.cc:1945:19: warning: calling function 'ActivateNodes' requires holding mutex 'output_frame->mu' exclusively [-Wthread-safety-precise]\r\n    output_frame->ActivateNodes(item, is_dead, output_iter, outputs, ready);\r\n...\r\nTarget //tensorflow/python/tools:freeze_graph up-to-date:\r\n  bazel-bin/tensorflow/python/tools/freeze_graph\r\nINFO: Elapsed time: 6941.332s, Critical Path: 104.91s\r\nINFO: Build completed successfully, 3787 total actions\r\n```\r\n\r\n```\r\n$ bazel build -c opt --cxxopt='--std=c++11' //tensorflow/contrib/lite/java/demo/app/src/main:TfLiteCameraDemo\r\nINFO: Analysed target //tensorflow/contrib/lite/java/demo/app/src/main:TfLiteCameraDemo (3 packages loaded).\r\nINFO: Found 1 target...\r\nTarget //tensorflow/contrib/lite/java/demo/app/src/main:TfLiteCameraDemo up-to-date:\r\n  bazel-bin/tensorflow/contrib/lite/java/demo/app/src/main/TfLiteCameraDemo_deploy.jar\r\n  bazel-bin/tensorflow/contrib/lite/java/demo/app/src/main/TfLiteCameraDemo_unsigned.apk\r\n  bazel-bin/tensorflow/contrib/lite/java/demo/app/src/main/TfLiteCameraDemo.apk\r\nINFO: Elapsed time: 63.940s, Critical Path: 26.61s\r\nINFO: Build completed successfully, 211 total actions\r\n```", "@vinceyuan  Ah, that's really awesome, i copy `protobuf` from tensorflow repo i usually used  to path `tensorflow/contrib/lite/downloads`, it worked. hah, you just saved me.", "@jakajacky All errors came back on my machine again! Extremely weird, because I did not update any code. Even if I reinstall protobuf or coremltools via pip, I still cannot build toco. I am very confused now. 8 hours ago, I used toco to convert a model to lite model successfully, but now I cannot do it. I also tried rebooting my mac. It did not help. \ud83d\ude22 \r\n\r\n```\r\n$ bazel build tensorflow/contrib/lite/toco:toco\r\n............................................................\r\nERROR: /Users/XXX/GitRoot/OpenSourceProjects/tensorflow/tensorflow/contrib/lite/BUILD:193:12: Label '//tensorflow/contrib/lite:downloads/absl/absl/types/optional.h' crosses boundary of subpackage 'tensorflow/contrib/lite/downloads/absl/absl/types' (perhaps you meant to put the colon here: '//tensorflow/contrib/lite/downloads/absl/absl/types:optional.h'?)\r\nERROR: /Users/XXX/GitRoot/OpenSourceProjects/tensorflow/tensorflow/contrib/lite/BUILD:193:12: Label '//tensorflow/contrib/lite:downloads/absl/absl/base/config_test.cc' crosses boundary of subpackage 'tensorflow/contrib/lite/downloads/absl/absl/base' (perhaps you meant to put the colon here: '//tensorflow/contrib/lite/downloads/absl/absl/base:config_test.cc'?)\r\nERROR: /Users/XXX/GitRoot/OpenSourceProjects/tensorflow/tensorflow/contrib/lite/BUILD:193:12: Label '//tensorflow/contrib/lite:downloads/absl/absl/debugging/internal/address_is_readable.h' crosses boundary of subpackage 'tensorflow/contrib/lite/downloads/absl/absl/debugging' (perhaps you meant to put the colon here: '//tensorflow/contrib/lite/downloads/absl/absl/debugging:internal/address_is_readable.h'?)\r\nERROR: /Users/XXX/GitRoot/OpenSourceProjects/tensorflow/tensorflow/contrib/lite/BUILD:193:12: Label '//tensorflow/contrib/lite:downloads/absl/absl/debugging/leak_check.h' crosses boundary of subpackage 'tensorflow/contrib/lite/downloads/absl/absl/debugging' (perhaps you meant to put the colon here: '//tensorflow/contrib/lite/downloads/absl/absl/debugging:leak_check.h'?)\r\n...\r\n```", "@vinceyuan it's weird, I have encountered the same situation, but it back to normal when i copy another tensorflow library \u201cre2\u201d to `tensorflow/contrib/lite/downloads`.  ", "@jakajacky where are `protobuf` and `re2` located in tensorflow repo?", "these are downloaded by executing the script  `tensorflow/contrib/makefile/download_dependencies.sh` in tensorflow repo , also you can find the href in this script. perhaps you can user this href [https://github.com/google/re2/archive/b94b7cd42e9f02673cd748c1ac1d16db4052514c.tar.gz](url) to get \"re2\"", "@jakajacky It works again! \ud83d\ude05 Thanks a lot! Let me write down the steps in case other people need it.\r\n\r\n1. ~~Download makefile dependencies by running `tensorflow/contrib/makefile/download_dependencies.sh`~~\r\n2. ~~Manually copy `protobuf` and `re2` folders from `tensorflow/contrib/makefile/downloads` to `tensorflow/contrib/lite/downloads`~~\r\n\r\nIt worked once, but does not work again.", "Great, at least it's useful for now, and I am worried about this issue recurring when we build it later\ud83d\ude06. @m3bm3b reply me in #13220, but i have no idea about his explanation, perhaps you can figure it out.", "When I failed to build `bazel build tensorflow/contrib/lite/toco:toco`, I also failed to build `bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package`. ~~But now I can build it successfully. I believe the solution above also works for #13220.~~", "@vinceyuan \ud83d\udc4dthe above steps  are believed to help a lot of people.", "@jakajacky OMG, the disgusting compiling errors about TensorFlow Lite came back AGAIN after I compiled/used a standard TensorFlow tool (e.g. transform_graph). It seems that the development environments of standard TensorFlow and TensorFlow Lite conflict with each other.\r\n\r\nManually copying protobuf and re2 folders from tensorflow/contrib/makefile/downloads to tensorflow/contrib/lite/downloads DOES NOT HELP this time. **TensorFlow lite toco tool compiles after I ran `tensorflow/contrib/lite/download_dependencies.sh`** ", "@vinceyuan  I came across the same problem with you at the top. But \r\n\r\n> 1. Download makefile dependencies by running tensorflow/contrib/makefile/download_dependencies.sh \r\n> 2. Manually copy protobuf and re2 folders from tensorflow/contrib/makefile/downloads to tensorflow/contrib/lite/downloads\r\n\r\ndoesn't work for me. My bazel version is 0.8.0. Have you solved the problem?", "@knsong Try to run `tensorflow/contrib/lite/download_dependencies.sh` instead of `tensorflow/contrib/makefile/download_dependencies.sh`. No need to copy folders.", "@vinceyuan  Great! It works! Thanks a lot!", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "This is the weirdest project I worked with. Same errors appeared again. I changed nothing in tensorflow folder. Just rebooted my computer. I tried all solutions mentioned above but nothing worked. I manually copied absl, protobuf and re2 folders from `tensorflow/contrib/makefile/downloads` to `tensorflow/contrib/lite/downloads` and finally I could compile.\r\nJust log it down. Hope it helps others.", "Nagging Assignee @cy89: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Hey @vinceyuan Sorry you are having so much trouble with TF Lite. It looks like you are seeing some conflict between the bazel setup and the dependencies used in the Makefile build.\r\n\r\nYou shouldn't need to run download_dependencies.sh if you are building with bazel.", "Nagging Assignee @miaout17: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @miaout17: It has been 31 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @miaout17: It has been 45 days with no activity and this issue has an assignee. Please update the label and/or status accordingly."]}, {"number": 15444, "title": "Fix lib_strings_str_util_test on Windows", "body": "", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please.", "@tensorflow-jenkins test this please."]}, {"number": 15443, "title": "New metric: Cohen's kappa", "body": "resolve #15285.\r\n\r\nAdd new metric: `cohen_kappa`, which is equivalent to `sklearn.metrics.cohen_kappa_score`(>=0.19), but the implementation doesn't support weighted matrix yet.\r\n\r\nRef:\r\n+ [Cohen's kappa - Wiki](https://en.wikipedia.org/wiki/Cohen's_kappa)\r\n+ [Cohen's kappa: Index of Inter-rater Reliability](http://psych.unl.edu/psycrs/handcomp/hckappa.PDF)\r\n+ [sklearn.metrics.cohen_kappa_score](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.cohen_kappa_score.html)\r\n\r\n### How to test\r\n\r\n+ [x] add test cases.\r\n+ [ ] pass all tests.", "comments": ["Can one of the admins verify this patch?", "I checked the log, and found that scikit-learn (>= 0.19) has not been deploy in CI environments.\r\n```bash\r\ntensorflow/contrib/metrics/python/ops/metric_ops_test.py:6799: [E1123(unexpected-keyword-arg), CohenKappaTest.testWeighted] Unexpected keyword argument 'sample_weight' in function call\r\n```\r\n\r\nBecause `sklearn.metrics.cohen_kappa_score` has supported `sample_weight` from 0.19 (August 12, 2017), and the function is necessary to check `weights` of `cohen_kappa` we proposed. So could we upgrade the scikit-learn dependency?", "@roumposg Thanks for your review and comments. I have revised those codes as suggested, except of two unresolved comments.", "Thank you, @roumposg. I think all comments left have been resolved. Could you take a look again?", "Jenkins, test this please.", "@caisq any idea what the `math_grad_test` problem is? It seems to happen on multiple PRs.", "Maybe it's some flakiness. Will take a look later unless you know what it is.", "@drpngx : that looks like a flaky test. we should keep an eye on it."]}, {"number": 15442, "title": "Tensorflow installation error", "body": "Tensorflow installation error.\r\n\r\nMethod followed: https://www.tensorflow.org/install/install_linux#InstallingAnaconda\r\n\r\n(Environment ubuntu 16.04, anaconda 4.3.29, Python 2.7.13, nvidia 1070 GPU)\r\nPlease help.\r\n\r\n>>>>>\r\ngopi@gp:~$ source activate tensorflow\r\n(tensorflow) gopi@gp:~$ pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-1.4.0-cp27-none-linux_x86_64.whl\r\nCollecting tensorflow-gpu==1.4.0 from https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-1.4.0-cp27-none-linux_x86_64.whl\r\n  Using cached https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-1.4.0-cp27-none-linux_x86_64.whl\r\nCollecting enum34>=1.1.6 (from tensorflow-gpu==1.4.0)\r\n  Using cached enum34-1.1.6-py2-none-any.whl\r\nCollecting six>=1.10.0 (from tensorflow-gpu==1.4.0)\r\n  Using cached six-1.11.0-py2.py3-none-any.whl\r\nCollecting protobuf>=3.3.0 (from tensorflow-gpu==1.4.0)\r\n  Using cached protobuf-3.5.0.post1-cp27-cp27mu-manylinux1_x86_64.whl\r\nCollecting numpy>=1.12.1 (from tensorflow-gpu==1.4.0)\r\n  Using cached numpy-1.13.3-cp27-cp27mu-manylinux1_x86_64.whl\r\nCollecting wheel (from tensorflow-gpu==1.4.0)\r\n  Using cached wheel-0.30.0-py2.py3-none-any.whl\r\nCollecting backports.weakref>=1.0rc1 (from tensorflow-gpu==1.4.0)\r\n  Using cached backports.weakref-1.0.post1-py2.py3-none-any.whl\r\nCollecting tensorflow-tensorboard<0.5.0,>=0.4.0rc1 (from tensorflow-gpu==1.4.0)\r\n  Using cached tensorflow_tensorboard-0.4.0rc3-py2-none-any.whl\r\nCollecting mock>=2.0.0 (from tensorflow-gpu==1.4.0)\r\n  Using cached mock-2.0.0-py2.py3-none-any.whl\r\nCollecting setuptools (from protobuf>=3.3.0->tensorflow-gpu==1.4.0)\r\n  Downloading setuptools-38.2.4-py2.py3-none-any.whl (489kB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 491kB 30kB/s \r\nCollecting futures>=3.1.1; python_version < \"3.2\" (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow-gpu==1.4.0)\r\n  Downloading futures-3.2.0-py2-none-any.whl\r\nCollecting werkzeug>=0.11.10 (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow-gpu==1.4.0)\r\n  Downloading Werkzeug-0.13-py2.py3-none-any.whl (311kB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 317kB 31kB/s \r\nCollecting html5lib==0.9999999 (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow-gpu==1.4.0)\r\nCollecting markdown>=2.6.8 (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow-gpu==1.4.0)\r\n  Downloading Markdown-2.6.10.zip (414kB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 419kB 43kB/s \r\nCollecting bleach==1.5.0 (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow-gpu==1.4.0)\r\n  Using cached bleach-1.5.0-py2.py3-none-any.whl\r\nCollecting funcsigs>=1; python_version < \"3.3\" (from mock>=2.0.0->tensorflow-gpu==1.4.0)\r\n  Using cached funcsigs-1.0.2-py2.py3-none-any.whl\r\nCollecting pbr>=0.11 (from mock>=2.0.0->tensorflow-gpu==1.4.0)\r\n  Using cached pbr-3.1.1-py2.py3-none-any.whl\r\nBuilding wheels for collected packages: markdown\r\n  Running setup.py bdist_wheel for markdown ... done\r\n  Stored in directory: /home/gopi/.cache/pip/wheels/1e/5a/55/a80b200d12e234d575ad68c1528593d1ce488720b65b24e48c\r\nSuccessfully built markdown\r\nInstalling collected packages: enum34, six, setuptools, protobuf, numpy, wheel, backports.weakref, futures, werkzeug, html5lib, markdown, bleach, tensorflow-tensorboard, funcsigs, pbr, mock, tensorflow-gpu\r\nException:\r\nTraceback (most recent call last):\r\n  File \"/home/gopi/.local/lib/python2.7/site-packages/pip/basecommand.py\", line 215, in main\r\n    status = self.run(options, args)\r\n  File \"/home/gopi/.local/lib/python2.7/site-packages/pip/commands/install.py\", line 342, in run\r\n    prefix=options.prefix_path,\r\n  File \"/home/gopi/.local/lib/python2.7/site-packages/pip/req/req_set.py\", line 784, in install\r\n    **kwargs\r\n  File \"/home/gopi/.local/lib/python2.7/site-packages/pip/req/req_install.py\", line 851, in install\r\n    self.move_wheel_files(self.source_dir, root=root, prefix=prefix)\r\n  File \"/home/gopi/.local/lib/python2.7/site-packages/pip/req/req_install.py\", line 1064, in move_wheel_files\r\n    isolated=self.isolated,\r\n  File \"/home/gopi/.local/lib/python2.7/site-packages/pip/wheel.py\", line 345, in move_wheel_files\r\n    clobber(source, lib_dir, True)\r\n  File \"/home/gopi/.local/lib/python2.7/site-packages/pip/wheel.py\", line 329, in clobber\r\n    os.utime(destfile, (st.st_atime, st.st_mtime))\r\nOSError: [Errno 1] Operation not permitted: '/home/gopi/anaconda2/lib/python2.7/site-packages/enum/README'\r\n(tensorflow) gopi@gp:~$ \r\n", "comments": ["Seems like an authorization issue rather TensorFlow's. Your user is probably not authorized to access a directory necessary for the installation. Using `sudo` will work but be sure you know what you're doing.", "Thanks for the reply.\r\nStill error. Please check\r\n\r\n(tensorflow) gopi@gp:~$ sudo pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-1.4.0-cp27-none-linux_x86_64.whl\r\nThe directory '/home/gopi/.cache/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\r\nThe directory '/home/gopi/.cache/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\r\ntensorflow_gpu-1.4.0-cp27-none-linux_x86_64.whl is not a supported wheel on this platform.\r\n\r\n(tensorflow) gopi@gp:~$ sudo -H pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-1.4.0-cp27-none-linux_x86_64.whl\r\ntensorflow_gpu-1.4.0-cp27-none-linux_x86_64.whl is not a supported wheel on this platform.\r\n\r\n--------------------------\r\n\r\nFYI:\r\n\r\ngopi@gp:~/NVIDIA_CUDA-8.0_Samples/1_Utilities/deviceQuery$ ./deviceQuery \r\n./deviceQuery Starting...\r\n\r\n CUDA Device Query (Runtime API) version (CUDART static linking)\r\n\r\nDetected 1 CUDA Capable device(s)\r\n\r\nDevice 0: \"GeForce GTX 1070\"\r\n  CUDA Driver Version / Runtime Version          9.0 / 8.0\r\n  CUDA Capability Major/Minor version number:    6.1\r\n  Total amount of global memory:                 8113 MBytes (8506769408 bytes)\r\n  (15) Multiprocessors, (128) CUDA Cores/MP:     1920 CUDA Cores\r\n  GPU Max Clock rate:                            1835 MHz (1.84 GHz)\r\n  Memory Clock rate:                             4004 Mhz\r\n  Memory Bus Width:                              256-bit\r\n  L2 Cache Size:                                 2097152 bytes\r\n  Maximum Texture Dimension Size (x,y,z)         1D=(131072), 2D=(131072, 65536), 3D=(16384, 16384, 16384)\r\n  Maximum Layered 1D Texture Size, (num) layers  1D=(32768), 2048 layers\r\n  Maximum Layered 2D Texture Size, (num) layers  2D=(32768, 32768), 2048 layers\r\n  Total amount of constant memory:               65536 bytes\r\n  Total amount of shared memory per block:       49152 bytes\r\n  Total number of registers available per block: 65536\r\n  Warp size:                                     32\r\n  Maximum number of threads per multiprocessor:  2048\r\n  Maximum number of threads per block:           1024\r\n  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)\r\n  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)\r\n  Maximum memory pitch:                          2147483647 bytes\r\n  Texture alignment:                             512 bytes\r\n  Concurrent copy and kernel execution:          Yes with 2 copy engine(s)\r\n  Run time limit on kernels:                     Yes\r\n  Integrated GPU sharing Host Memory:            No\r\n  Support host page-locked memory mapping:       Yes\r\n  Alignment requirement for Surfaces:            Yes\r\n  Device has ECC support:                        Disabled\r\n  Device supports Unified Addressing (UVA):      Yes\r\n  Device PCI Domain ID / Bus ID / location ID:   0 / 1 / 0\r\n  Compute Mode:\r\n     < Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) >\r\n\r\ndeviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 9.0, CUDA Runtime Version = 8.0, NumDevs = 1, Device0 = GeForce GTX 1070\r\nResult = PASS\r\n\r\n--------------------------\r\n\r\ngopi@gp:~$ cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2\r\n#define CUDNN_MAJOR      5\r\n#define CUDNN_MINOR      1\r\n#define CUDNN_PATCHLEVEL 10\r\n--\r\n#define CUDNN_VERSION    (CUDNN_MAJOR * 1000 + CUDNN_MINOR * 100 + CUDNN_PATCHLEVEL)\r\n\r\n\r\n\r\n", "Now it's a different error. Could you perhaps have created an environment for Python 3 rather 2?\r\nThis error occurs when the binary doesn't correspond with the local environment, e.g. different OS, Python version etc.\r\nAlso could you try the PYPI package instead `sudo -H pip install tensorflow-gpu`? Unless I'm missing something here If there's an actual issue with the URL binary you can at least get it going while it's checked.", "Sorry for late response.\r\nPYPI package meaning this one ? -> https://pypi.python.org/pypi/tensorflow \r\nGPU version of tensorflow for ubuntu 16.04 available here?\r\n\r\nI also tried installing it using below conda command, but still the version shows older 1.2.1\r\n>>>\r\ngopi@gp:~$ conda install -c conda-forge tensorflow-gpu\r\nFetching package metadata .............\r\nSolving package specifications: .\r\n\r\n# All requested packages already installed.\r\n# packages in environment at /home/gopi/anaconda2:\r\n#\r\ntensorflow-gpu            1.3.0                         0  \r\ngopi@gp:~$ python\r\nPython 2.7.13 |Anaconda custom (64-bit)| (default, Dec 20 2016, 23:09:15) \r\n[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)] on linux2\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\nAnaconda is brought to you by Continuum Analytics.\r\nPlease check out: http://continuum.io/thanks and https://anaconda.org\r\n>>> import tensorflow as tf\r\n>>> print tf.VERSION\r\n1.2.1\r\n>>> \r\n\r\n\r\n", "Yes, Linux packages are right there for TensorFlow v1.4.1. You can install as I mentioned above."]}, {"number": 15441, "title": "[WIP] Add tf_copts to XLA libraries", "body": "Split from #14531 \r\nRequired by #15213\r\nDepends on #15466\r\n\r\nTo fix a build error in //tensorflow/compiler/xla:util\r\nThere is a name conflict in  xla_data.pb.h\r\n```\r\nenum PrimitiveType {\r\n  PRIMITIVE_TYPE_INVALID = 0,\r\n  PRED = 1,\r\n  S8 = 2,\r\n  S16 = 3,\r\n  S32 = 4,\r\n  S64 = 5,\r\n  U8 = 6,\r\n  U16 = 7,\r\n  U32 = 8,\r\n  U64 = 9,\r\n  F16 = 10,\r\n  F32 = 11,\r\n  BF16 = 16,\r\n  F64 = 12,\r\n  C64 = 15,\r\n  TUPLE = 13,\r\n  OPAQUE = 14,\r\n  PrimitiveType_INT_MIN_SENTINEL_DO_NOT_USE_ = ::google::protobuf::kint32min,\r\n  PrimitiveType_INT_MAX_SENTINEL_DO_NOT_USE_ = ::google::protobuf::kint32max\r\n};\r\n```\r\nHowever, **OPAQUE** is already defined in wingdi.h as:\r\n```\r\n#define OPAQUE              2\r\n```\r\nSo, \"/DNOGDI\u201c compiler flag  is a must for who includes this file.\r\n\r\n@rongjiecomputer \r\n@jhseu ", "comments": ["Can one of the admins verify this patch?", "This might be a brittle fix. If a new rule is added that forgets to add tf_copts, then it'll break again. @gunan not sure who owns this build rule. Should we do this more generally by adding a new library rule?\r\n\r\n@snnn I'm not sure from your description why this doesn't build. The enum should be under a separate namespace. See xla_data.proto.\r\n", "I am also not fond of this solution. I think us redefining the cc_library rule will  be better, if we have to add tf_copts to these rules.\r\nThat is unless @mhlopko has a better recommendation for us.", "Though we can create a new macro like tf_cc_library, it doesn't mean I could change fewer lines. \r\nAs this change is huge, you may want to do it internally. ", "Hi @jhseu\r\n\r\nYes,  The enum is under a separate namespace. But, OPAQUE in Windows.h is a macro. macro comes first. It's like:\r\n```c\r\n#define OPAQUE              2\r\nenum something{\r\n  a,\r\n  b,\r\n  OPAQUE,  //here, you will get an error, no matter which namespace the enum lives\r\n};\r\n```", "Another alternative is to #undef OPAQUE where Windows.h is included. That seems preferable.", "@jhseu `windows.h` is included in a lot of places, trying to track down all these files and `#undef OPAQUE` right after `windows.h` can be difficult. If a new file includes `windows.h` and forgot to undef macros again, it will break again.\r\n\r\n`windows.h` is known as one of the most namespace/macro polluting header file for a reason.", "Hi @jhseu,\r\n\r\nThen you just solved one of these problems.  Please take a look at #15302\r\n\r\nInstead of adding\r\n```\r\n#include \"tensorflow/core/platform/cpu_info.h\"\r\n```\r\nI could do \r\n```\r\n#if defined(PLATFORM_WINDOWS)\r\n#include \"tensorflow/core/platform/windows/cpu_info.h\"\r\n#endif\r\n```\r\n\r\nThen \\_\\_BYTE_ORDER\\_\\_  will remain undefined if PLATFORM_WINDOWS is not defined (because of lacking tf_copts)\r\nHowever, we have code like\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/framework/numeric_types.h#L55\r\n```\r\n#if __BYTE_ORDER__ == __ORDER_BIG_ENDIAN__\r\n    value = p[0];\r\n#else\r\n    value = p[1];\r\n#endif\r\n```\r\n\r\nWho includes this file will get a silent error.\r\n", "The problem is even more tricky for cc_tests. \r\nEvery cc_test is binary exe on Windows, it may either link to tf framework libraries statically or dynamically.\r\nFor link statically, you should define TF_COMPILE_LIBRARY, otherwise, you must be care of not defining it. \r\nFor every cc file under tensorflow/core, we need to **define** TF_COMPILE_LIBRARY while compiling.\r\nFor every cc file under tensorflow/contrib, we need to **undefine** TF_COMPILE_LIBRARY while compiling.\r\nTo accomplish that,  we have to add tf_copts everywhere. \r\n", "@meteorcloudy, any suggestion?", "Yeah, perhaps let's just create a tf_cc_library and add the copts there, and modify all of these to use tf_cc_library.", "Got it. I will do it", "Hi @jhseu\r\n\r\nHow about this #15466 ?\r\n"]}, {"number": 15440, "title": "Make get_placeholders() accessible and add example", "body": "This is an improvement of PR #14541.\r\nThis PR makes get_placeholders() visible in the document as `tf.contrib.framework.get_placeholders` and add example to the docstring.\r\n\r\n- [x] Make get_placeholders() accessible\r\n- [x] Add example", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please", "Tests for python import and placeholder's name added.", "Oh, I didn't realize there was already a test, sorry. You can undo that commit."]}, {"number": 15439, "title": "Add an is_external arg to tf_copts", "body": "It's for support build custom ops on Windows\r\n@meteorcloudy This is what we talked last week.", "comments": ["Can one of the admins verify this patch?", "Please re-run the tests", "@tensorflow-jenkins Test this please", "CI machine's disk is full.  ", "Jenkins, test this please.", "python3 rerun at http://ci.tensorflow.org/job/tensorflow-pull-requests-cpu-python3/7629/"]}, {"number": 15438, "title": "can tf  use the dataset from western faces to predict the Asia people's faces? ", "body": "can tf  use the dataset from western faces to predict the Asia people's faces? \r\n\r\n\u662f\u5426\u53ef\u4ee5 \u7528\u897f\u65b9\u4eba\u7684\u4eba\u8138\u6570\u636e \u68c0\u6d4b \u4e9a\u6d32\u4eba\u8138\uff1f", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "I don't think so.  Because the face color and other features may be different ", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue? Please update the label and/or status accordingly.", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new). Thanks!\r\n"]}, {"number": 15437, "title": "R0.7", "body": "", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address on your commit.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot. The email used to register you as an authorized contributor must be the email used for the Git commit.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n<!-- need_sender_cla -->"]}, {"number": 15436, "title": "Simple Recurrent Unit", "body": "As per https://github.com/tensorflow/tensorflow/pull/15434#issuecomment-352343576.", "comments": ["Can one of the admins verify this patch?", "There are two test issues.\r\nFirst with the function_test:\r\nhttps://source.cloud.google.com/results/invocations/6b22c584-f73d-4c1b-b939-1c68fce02e6e/targets/%2F%2Ftensorflow%2Fpython:function_test?page=log\r\n\r\n2nd, api_compatibility_test:\r\nhttps://source.cloud.google.com/results/invocations/6b22c584-f73d-4c1b-b939-1c68fce02e6e/targets/%2F%2Ftensorflow%2Ftools%2Fapi%2Ftests:api_compatibility_test?page=log\r\n```\r\n    $ bazel build tensorflow/tools/api/tests:api_compatibility_test\r\n    $ bazel-bin/tensorflow/tools/api/tests/api_compatibility_test \\\r\n          --update_goldens True\r\n\r\nYou will need an API approval to make changes to the public TensorFlow API. This\r\nincludes additions to the API.\r\n```\r\nThese instructions should be followed on a linux machine with python 2.", "@gunan the function test seems to be unrelated to this PR. Specifically, the error msg was:\r\n```\r\nNo gradient defined for op: ClipByValue\r\n```", "@tensorflow-jenkins test this please", "A better solution would be to move the SRUCell into tf.contrib.rnn python/ops (rnn_cell.py maybe?) since this was never meant to go directly into core.", "@ebrevdo sounds good, I'll revert my last commit and instead move it under contrib.", "Hi @ebrevdo should I stick to `_LayerRNNCell ` as the base class or switch back to `RNNCell` as the base class as for other rnn architectures in rnn_cell.py in the contrib directory (e.g., https://github.com/tensorflow/tensorflow/blob/810394550571c5feb333cb6da66afb4b20c3bd85/tensorflow/contrib/rnn/python/ops/rnn_cell.py#L92).", "Use the _LayerRNNCell; the other contrib classes will be moved over to that\neventually as well.\n\nOn Tue, Dec 19, 2017 at 7:13 PM, Tian Jin <notifications@github.com> wrote:\n\n> Hi @ebrevdo <https://github.com/ebrevdo> should I stick to _LayerRNNCell\n> as the base class or switch back to RNNCell as the base class as for\n> other rnn architectures in rnn_cell.py in the contrib directory (e.g.,\n> https://github.com/tensorflow/tensorflow/blob/\n> 810394550571c5feb333cb6da66afb4b20c3bd85/tensorflow/contrib/\n> rnn/python/ops/rnn_cell.py#L92).\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/15436#issuecomment-352952987>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtim3CKTp5joayQ9_ML1o5UPgiido1Uks5tCHtsgaJpZM4RFEU8>\n> .\n>\n", "@ebrevdo @asimshankar should be good now.", "@tensorflow-jenkins test this please"]}, {"number": 15435, "title": "tensorflow-gpu not working with pycharm", "body": "I am trying to get the tensorflow-gpu working on pycharm but it doesn't compile. When I compile it, it gives me the following compile error\r\n\r\n> ImportError: Could not find 'cudart64_80.dll'. TensorFlow requires that this DLL be installed in a directory that is named in your %PATH% environment variable. Download and install CUDA 8.0 from this URL:\r\n\r\nI am using Pycharm with the Python 3.6 venv and I am pretty sure I have CUDA 8.0 installed. When I check the directory of CUDA\\v8.0\\bin, it shows the cudart64_80.dll \r\n\r\nIt works perfectly on the CPU version but I want it working on the GPU side", "comments": ["Is it in your PATH?\r\nPlease run\r\n```bat\r\necho %PATH%\r\n```", "Microsoft Windows [Version 10.0.16299.125]\r\n(c) 2017 Microsoft Corporation. All rights reserved.\r\n\r\nC:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v8.0\\bin;C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v8.0\\libnvvp;;C:\\ProgramData\\Oracle\\Java\\javapath;C:\\Program Files (x86)\\Intel\\iCLS Client\\;C:\\Program Files\\Intel\\iCLS Client\\;C:\\Windows\\system32;C:\\Windows;C:\\Windows\\System32\\Wbem;C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\;C:\\Program Files\\Intel\\Intel(R) Management Engine Components\\DAL;C:\\Program Files\\Intel\\Intel(R) Management Engine Components\\IPT;C:\\Program Files (x86)\\Intel\\Intel(R) Management Engine Components\\DAL;C:\\Program Files (x86)\\Intel\\Intel(R) Management Engine Components\\IPT;C:\\Program Files\\Java\\jdk1.8.0_25\\bin;C:\\Program Files (x86)\\Windows Kits\\8.1\\Windows Performance Toolkit\\;C:\\Program Files\\Microsoft SQL Server\\110\\Tools\\Binn\\;C:\\Program Files (x86)\\Microsoft SDKs\\TypeScript\\1.0\\;C:\\Program Files (x86)\\NVIDIA Corporation\\PhysX\\Common;C:\\WINDOWS\\system32;C:\\WINDOWS;C:\\WINDOWS\\System32\\Wbem;C:\\WINDOWS\\System32\\WindowsPowerShell\\v1.0\\;D:\\Program Files\\Git\\cmd;D:\\Python27;D:\\Python27\\Scripts;D:\\protobuf;C:\\Program Files (x86)\\nodejs\\;F:\\Python\\Python36\\Scripts\\;F:\\Python\\Python36\\;C:\\Users\\Tori\\AppData\\Local\\Microsoft\\WindowsApps;C:\\Users\\Tori\\AppData\\Roaming\\npm;C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v8.0\\bin;\r\n\r\nIs this what you're looking for? ", "You have 2 Python here. How does it work?", "One of it is python 2.7 and the other one is 3.6\r\nI deleted the python 2.7 though and only have the 3.6 at the moment", "Can you run your code directly on command line, without PyCharm?  Is your problem specific to PyCharm or not?", "It is specific to pycharm. I don't think I have tensorflow working on command line but I am planning on working with pycharm only ", "This is a pycharm specific issue, it's not a tensorflow library bug. This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow). There is also a larger community that reads questions there. Thanks!", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "I can confirm the same observation: command line usage works fine, but in PyCharm I get:\r\n\r\n```\r\n File \"C:\\Python35\\lib\\site-packages\\tensorflow\\python\\platform\\self_check.py\", line 82, in preload_check\r\n    % (build_info.cudart_dll_name, build_info.cuda_version_number))\r\nImportError: Could not find 'cudart64_80.dll'. TensorFlow requires that this DLL be installed in a directory that is named in your %PATH% environment variable. Download and install CUDA 8.0 from this URL: https://developer.nvidia.com/cuda-toolkit\r\n```\r\n\r\nPATH includes CUDA directories bin, lib/x64 and extras/CUPTI/libx64. I noticed the file cudart64_80.dll does in fact exist in <CUDA>/bin, not sure what is causing this.", "OK, it took two restarts and now I can't reproduce the bug... Not sure what happened. I should point out that I had attempted to upgrade to cuda 9 before this happened, discovered that it wasn't supported under Windows, downgraded to TF1.4, and after uninstalling cuda and reinstalling v8, this bug happened, and persisted after one restart, despite everything being in path. I also restarted PyCharm a bunch of times, so it seems that's not enough.\r\n\r\nNow I rebooted again and everything is just working in PyCharm and CLI... Sorry for the confusion!", "Had the same issue here - adding LD_LIBRARY_PATH=/usr/local/cuda-8.0/lib64/ to the pycharm environment did the trick", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Closing since it appears to be resolved."]}]