[{"number": 40280, "title": "simple tf.vectorized_map raises error UnrecognizedFlagError: Unknown command line flag 'f'", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab\r\n- TensorFlow installed from (source or binary): Default Colab\r\n- TensorFlow version (use command below): 2.2.0\r\n- Python version: 3.6.9\r\n- CUDA/cuDNN version: N/A tested on CPU\r\n- GPU model and memory: N/A tested on CPU\r\n\r\n**Describe the current behavior**\r\n\r\n```py\r\nimport tensorflow as tf\r\n\r\nprint(tf.vectorized_map(\r\n    lambda seq: tf.reduce_min(tf.where(seq)),\r\n    tf.constant([[False, True],\r\n                 [True, False]])\r\n))\r\n```\r\n\r\nOutputs the following error:\r\n\r\n```\r\nUnrecognizedFlagError: Unknown command line flag 'f'\r\n```\r\n\r\nI've seen this error quite often when using `tf.vectorized_map`, in very different settings. However, this is the simplest cast I've found so far. So I suspect the error is not limited to `tf.where()`.\r\n\r\n**Describe the expected behavior**\r\n\r\nI would expect the output to be:\r\n```\r\ntf.constant([1, 0], dtype=tf.dtypes.bool)\r\n```\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\nhttps://colab.research.google.com/gist/AndreasMadsen/9ee1fa1669aa7c656070ca5a850d7210/vectorized-map-bug.ipynb\r\n\r\n**Other info / logs**\r\n\r\n```\r\nStagingError: in user code:\r\n\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/parallel_for/control_flow_ops.py:183 f  *\r\n        return _pfor_impl(loop_fn, iters, parallel_iterations=parallel_iterations)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/parallel_for/control_flow_ops.py:269 _pfor_impl  **\r\n        outputs.append(converter.convert(loop_fn_output))\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/parallel_for/pfor.py:1284 convert\r\n        output = self._convert_helper(y)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/parallel_for/pfor.py:1457 _convert_helper\r\n        if flags.FLAGS.op_conversion_fallback_to_while_loop:\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/flags.py:85 __getattr__\r\n        wrapped(_sys.argv)\r\n    /usr/local/lib/python3.6/dist-packages/absl/flags/_flagvalues.py:633 __call__\r\n        name, value, suggestions=suggestions)\r\n\r\n    UnrecognizedFlagError: Unknown command line flag 'f'\r\n```", "comments": ["@AndreasMadsen \r\n\r\nCan you try with TF nightly version (`2.3.0-dev20200608`) and see if the issue still persists.I am not seeing any issue with nightly version.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/c450a39bee1221aad6654174fd845165/untitled968.ipynb). You could use tf-nightly for now and in the next couple of months new stable version will be released.Please,verify once and close the issue.Thanks!", "I can confirm it works on nightly. I was looking through the commits and I think https://github.com/tensorflow/tensorflow/commit/867673d63b6ee56229498176fc3a00235b8eb2cf#diff-081213481ade84ce14e9afaa3f3505b9L283 fixed it. Although, I think it hides an underlying bug with the `flags` API, when used with Colab.\r\n\r\nThe code\r\n\r\n```\r\nimport sys\r\nprint(sys.argv)\r\n```\r\n\r\nOutputs `['/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py',\r\n '-f',\r\n '/root/.local/share/jupyter/runtime/kernel-d86e104c-d0a6-40e7-9533-ce825b3cb03d.json']`. Which causes the flag parser to fail. Because it doesn't understand the `-f` flag.\r\n\r\nThe error can be reproduced with:\r\n\r\n```\r\nfrom absl import flags\r\nflags.FLAGS(sys.argv)\r\n```\r\n\r\nI don't know if this is an issue with\r\n* `absl` for not supporting Colab\r\n* or TensorFlow to not instructing `absl` on how to handle `-f`\r\n* or Colab for passing in the `-f` flag.", "@AndreasMadsen \r\n\r\nPlease, close the issue as the original issue was resolved. Request you to raise a new issue with flags API by filling issue template.Thanks!", "I submitted an issue here: https://github.com/googlecolab/colabtools/issues/1323", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40280\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40280\">No</a>\n", "FWIW, I do think there's a deeper TF-side issue here: a library shouldn't be parsing `sys.argv`, since it has no control over the program that invoked it. A simple fix might be allowing unknown flags when parsing `sys.argv`.\r\n\r\nThat said, for this particular issue, it looks like the code in question is gone, so mostly leaving this comment as a breadcrumb for posterity.", "Seems like this is the workaround for at least TF2.2.0: https://github.com/google-research/bleurt/issues/4#issuecomment-635118502"]}, {"number": 40279, "title": "Develop upstream sync 200608", "body": "", "comments": ["All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F40279) for more info**.\n\n<!-- need_author_consent -->"]}, {"number": 40278, "title": "Documentation instructions on installing tensorflow with CUDA support doesn't work", "body": "OS: Ubuntu 18.04\r\nGraphics card: Nvidia 1050Ti\r\n\r\n**Problem**\r\nFollowing the instructions under https://www.tensorflow.org/install/gpu#install_cuda_with_apt gives the following error: \r\n\r\n```ssh\r\n...\r\n\r\nUnpacking libcudnn7-dev (7.6.4.38-1+cuda10.1) ...\r\nErrors were encountered while processing:\r\n /tmp/apt-dpkg-install-fjAi3S/55-libnvidia-compute-450_450.36.06-0ubuntu1_amd64.deb\r\nE: Sub-process /usr/bin/dpkg returned an error code (1)\r\n```\r\nafter executing this step\r\n```ssh\r\nsudo apt-get install --no-install-recommends \\\r\n>     cuda-10-1 \\\r\n>     libcudnn7=7.6.4.38-1+cuda10.1  \\\r\n>     libcudnn7-dev=7.6.4.38-1+cuda10.1\r\n```\r\n\r\n**Additional Info**\r\nThe complete message after running the above command is\r\n\r\n```ssh\r\nReading package lists... Done\r\nBuilding dependency tree       \r\nReading state information... Done\r\nThe following packages were automatically installed and are no longer required:\r\n  libnvidia-common-440 libnvidia-extra-440\r\nUse 'sudo apt autoremove' to remove them.\r\nThe following additional packages will be installed:\r\n  cuda-command-line-tools-10-1 cuda-compiler-10-1 cuda-cudart-10-1\r\n  cuda-cudart-dev-10-1 cuda-cufft-10-1 cuda-cufft-dev-10-1 cuda-cuobjdump-10-1\r\n  cuda-cupti-10-1 cuda-curand-10-1 cuda-curand-dev-10-1 cuda-cusolver-10-1\r\n  cuda-cusolver-dev-10-1 cuda-cusparse-10-1 cuda-cusparse-dev-10-1\r\n  cuda-demo-suite-10-1 cuda-documentation-10-1 cuda-driver-dev-10-1\r\n  cuda-drivers cuda-drivers-450 cuda-gdb-10-1 cuda-gpu-library-advisor-10-1\r\n  cuda-libraries-10-1 cuda-libraries-dev-10-1 cuda-license-10-1\r\n  cuda-license-10-2 cuda-memcheck-10-1 cuda-misc-headers-10-1 cuda-npp-10-1\r\n  cuda-npp-dev-10-1 cuda-nsight-10-1 cuda-nsight-compute-10-1\r\n  cuda-nsight-systems-10-1 cuda-nvcc-10-1 cuda-nvdisasm-10-1 cuda-nvgraph-10-1\r\n  cuda-nvgraph-dev-10-1 cuda-nvjpeg-10-1 cuda-nvjpeg-dev-10-1\r\n  cuda-nvml-dev-10-1 cuda-nvprof-10-1 cuda-nvprune-10-1 cuda-nvrtc-10-1\r\n  cuda-nvrtc-dev-10-1 cuda-nvtx-10-1 cuda-nvvp-10-1 cuda-runtime-10-1\r\n  cuda-samples-10-1 cuda-sanitizer-api-10-1 cuda-toolkit-10-1 cuda-tools-10-1\r\n  cuda-visual-tools-10-1 default-jre default-jre-headless libcublas-dev\r\n  libcublas10 libnvidia-cfg1-450 libnvidia-common-450 libnvidia-compute-450\r\n  libnvidia-decode-450 libnvidia-encode-450 libnvidia-fbc1-450\r\n  libnvidia-gl-450 libnvidia-ifr1-450 nsight-compute-2019.5.0\r\n  nsight-systems-2019.5.2 nvidia-compute-utils-450 nvidia-dkms-450\r\n  nvidia-driver-450 nvidia-kernel-common-450 nvidia-kernel-source-450\r\n  nvidia-modprobe nvidia-settings nvidia-utils-450 openjdk-11-jre\r\n  openjdk-11-jre-headless xserver-xorg-video-nvidia-450\r\nSuggested packages:\r\n  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei\r\n  | fonts-wqy-zenhei\r\nThe following packages will be REMOVED:\r\n  libnvidia-cfg1-440 libnvidia-compute-440 libnvidia-decode-440\r\n  libnvidia-encode-440 libnvidia-fbc1-440 libnvidia-fbc1-440:i386\r\n  libnvidia-gl-440 libnvidia-ifr1-440 nvidia-compute-utils-440 nvidia-dkms-440\r\n  nvidia-driver-430 nvidia-driver-440 nvidia-kernel-common-440\r\n  nvidia-kernel-source-440 nvidia-utils-440 xserver-xorg-video-nvidia-440\r\nThe following NEW packages will be installed:\r\n  cuda-10-1 cuda-command-line-tools-10-1 cuda-compiler-10-1 cuda-cudart-10-1\r\n  cuda-cudart-dev-10-1 cuda-cufft-10-1 cuda-cufft-dev-10-1 cuda-cuobjdump-10-1\r\n  cuda-cupti-10-1 cuda-curand-10-1 cuda-curand-dev-10-1 cuda-cusolver-10-1\r\n  cuda-cusolver-dev-10-1 cuda-cusparse-10-1 cuda-cusparse-dev-10-1\r\n  cuda-demo-suite-10-1 cuda-documentation-10-1 cuda-driver-dev-10-1\r\n  cuda-drivers cuda-drivers-450 cuda-gdb-10-1 cuda-gpu-library-advisor-10-1\r\n  cuda-libraries-10-1 cuda-libraries-dev-10-1 cuda-license-10-1\r\n  cuda-license-10-2 cuda-memcheck-10-1 cuda-misc-headers-10-1 cuda-npp-10-1\r\n  cuda-npp-dev-10-1 cuda-nsight-10-1 cuda-nsight-compute-10-1\r\n  cuda-nsight-systems-10-1 cuda-nvcc-10-1 cuda-nvdisasm-10-1 cuda-nvgraph-10-1\r\n  cuda-nvgraph-dev-10-1 cuda-nvjpeg-10-1 cuda-nvjpeg-dev-10-1\r\n  cuda-nvml-dev-10-1 cuda-nvprof-10-1 cuda-nvprune-10-1 cuda-nvrtc-10-1\r\n  cuda-nvrtc-dev-10-1 cuda-nvtx-10-1 cuda-nvvp-10-1 cuda-runtime-10-1\r\n  cuda-samples-10-1 cuda-sanitizer-api-10-1 cuda-toolkit-10-1 cuda-tools-10-1\r\n  cuda-visual-tools-10-1 default-jre default-jre-headless libcublas-dev\r\n  libcublas10 libcudnn7 libcudnn7-dev libnvidia-cfg1-450 libnvidia-common-450\r\n  libnvidia-compute-450 libnvidia-decode-450 libnvidia-encode-450\r\n  libnvidia-fbc1-450 libnvidia-gl-450 libnvidia-ifr1-450\r\n  nsight-compute-2019.5.0 nsight-systems-2019.5.2 nvidia-compute-utils-450\r\n  nvidia-dkms-450 nvidia-driver-450 nvidia-kernel-common-450\r\n  nvidia-kernel-source-450 nvidia-modprobe nvidia-settings nvidia-utils-450\r\n  openjdk-11-jre openjdk-11-jre-headless xserver-xorg-video-nvidia-450\r\n0 upgraded, 79 newly installed, 16 to remove and 239 not upgraded.\r\nNeed to get 0 B/2,205 MB of archives.\r\nAfter this operation, 4,855 MB of additional disk space will be used.\r\nDo you want to continue? [Y/n] \r\nExtracting templates from packages: 100%\r\n(Reading database ... 294935 files and directories currently installed.)\r\nRemoving nvidia-driver-430 (440.59-0ubuntu0.18.04.1) ...\r\nRemoving nvidia-driver-440 (440.82-0ubuntu0~0.18.04.2) ...\r\nRemoving xserver-xorg-video-nvidia-440 (440.82-0ubuntu0~0.18.04.2) ...\r\nRemoving libnvidia-cfg1-440:amd64 (440.82-0ubuntu0~0.18.04.2) ...\r\nRemoving libnvidia-encode-440:amd64 (440.82-0ubuntu0~0.18.04.2) ...\r\nRemoving libnvidia-decode-440:amd64 (440.82-0ubuntu0~0.18.04.2) ...\r\nRemoving nvidia-utils-440 (440.82-0ubuntu0~0.18.04.2) ...\r\nRemoving libnvidia-fbc1-440:i386 (440.82-0ubuntu0~0.18.04.2) ...\r\nRemoving libnvidia-fbc1-440:amd64 (440.82-0ubuntu0~0.18.04.2) ...\r\nRemoving libnvidia-ifr1-440:amd64 (440.82-0ubuntu0~0.18.04.2) ...\r\nRemoving libnvidia-gl-440:amd64 (440.82-0ubuntu0~0.18.04.2) ...\r\nRemoving nvidia-compute-utils-440 (440.82-0ubuntu0~0.18.04.2) ...\r\nRemoving nvidia-dkms-440 (440.82-0ubuntu0~0.18.04.2) ...\r\nRemoving all DKMS Modules\r\nDone.\r\nINFO:Disable nvidia\r\nDEBUG:Parsing /usr/share/ubuntu-drivers-common/quirks/dell_latitude\r\nDEBUG:Parsing /usr/share/ubuntu-drivers-common/quirks/put_your_quirks_here\r\nDEBUG:Parsing /usr/share/ubuntu-drivers-common/quirks/lenovo_thinkpad\r\nupdate-initramfs: deferring update (trigger activated)\r\nRemoving nvidia-kernel-common-440 (440.82-0ubuntu0~0.18.04.2) ...\r\nupdate-initramfs: deferring update (trigger activated)\r\nRemoving nvidia-kernel-source-440 (440.82-0ubuntu0~0.18.04.2) ...\r\nRemoving libnvidia-compute-440:amd64 (440.82-0ubuntu0~0.18.04.2) ...\r\nSelecting previously unselected package cuda-license-10-1.\r\n(Reading database ... 294368 files and directories currently installed.)\r\nPreparing to unpack .../00-cuda-license-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-license-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-misc-headers-10-1.\r\nPreparing to unpack .../01-cuda-misc-headers-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-misc-headers-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-nvcc-10-1.\r\nPreparing to unpack .../02-cuda-nvcc-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-nvcc-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-cuobjdump-10-1.\r\nPreparing to unpack .../03-cuda-cuobjdump-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-cuobjdump-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-nvprune-10-1.\r\nPreparing to unpack .../04-cuda-nvprune-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-nvprune-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-compiler-10-1.\r\nPreparing to unpack .../05-cuda-compiler-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-compiler-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-nvdisasm-10-1.\r\nPreparing to unpack .../06-cuda-nvdisasm-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-nvdisasm-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-gdb-10-1.\r\nPreparing to unpack .../07-cuda-gdb-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-gdb-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-nvprof-10-1.\r\nPreparing to unpack .../08-cuda-nvprof-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-nvprof-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-sanitizer-api-10-1.\r\nPreparing to unpack .../09-cuda-sanitizer-api-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-sanitizer-api-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-memcheck-10-1.\r\nPreparing to unpack .../10-cuda-memcheck-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-memcheck-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-cudart-10-1.\r\nPreparing to unpack .../11-cuda-cudart-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-cudart-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-driver-dev-10-1.\r\nPreparing to unpack .../12-cuda-driver-dev-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-driver-dev-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-cudart-dev-10-1.\r\nPreparing to unpack .../13-cuda-cudart-dev-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-cudart-dev-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-cupti-10-1.\r\nPreparing to unpack .../14-cuda-cupti-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-cupti-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-gpu-library-advisor-10-1.\r\nPreparing to unpack .../15-cuda-gpu-library-advisor-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-gpu-library-advisor-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-nvtx-10-1.\r\nPreparing to unpack .../16-cuda-nvtx-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-nvtx-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-command-line-tools-10-1.\r\nPreparing to unpack .../17-cuda-command-line-tools-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-command-line-tools-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package openjdk-11-jre-headless:amd64.\r\nPreparing to unpack .../18-openjdk-11-jre-headless_11.0.7+10-2ubuntu2~18.04_amd64.deb ...\r\nUnpacking openjdk-11-jre-headless:amd64 (11.0.7+10-2ubuntu2~18.04) ...\r\nSelecting previously unselected package default-jre-headless.\r\nPreparing to unpack .../19-default-jre-headless_2%3a1.11-68ubuntu1~18.04.1_amd64.deb ...\r\nUnpacking default-jre-headless (2:1.11-68ubuntu1~18.04.1) ...\r\nSelecting previously unselected package openjdk-11-jre:amd64.\r\nPreparing to unpack .../20-openjdk-11-jre_11.0.7+10-2ubuntu2~18.04_amd64.deb ...\r\nUnpacking openjdk-11-jre:amd64 (11.0.7+10-2ubuntu2~18.04) ...\r\nSelecting previously unselected package default-jre.\r\nPreparing to unpack .../21-default-jre_2%3a1.11-68ubuntu1~18.04.1_amd64.deb ...\r\nUnpacking default-jre (2:1.11-68ubuntu1~18.04.1) ...\r\nSelecting previously unselected package cuda-nsight-10-1.\r\nPreparing to unpack .../22-cuda-nsight-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-nsight-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-nvvp-10-1.\r\nPreparing to unpack .../23-cuda-nvvp-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-nvvp-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-nvrtc-10-1.\r\nPreparing to unpack .../24-cuda-nvrtc-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-nvrtc-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-nvrtc-dev-10-1.\r\nPreparing to unpack .../25-cuda-nvrtc-dev-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-nvrtc-dev-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-cusolver-10-1.\r\nPreparing to unpack .../26-cuda-cusolver-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-cusolver-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-cusolver-dev-10-1.\r\nPreparing to unpack .../27-cuda-cusolver-dev-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-cusolver-dev-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-license-10-2.\r\nPreparing to unpack .../28-cuda-license-10-2_10.2.89-1_amd64.deb ...\r\nUnpacking cuda-license-10-2 (10.2.89-1) ...\r\nSelecting previously unselected package libcublas10.\r\nPreparing to unpack .../29-libcublas10_10.2.2.89-1_amd64.deb ...\r\nUnpacking libcublas10 (10.2.2.89-1) ...\r\nSelecting previously unselected package libcublas-dev.\r\nPreparing to unpack .../30-libcublas-dev_10.2.2.89-1_amd64.deb ...\r\nUnpacking libcublas-dev (10.2.2.89-1) ...\r\nSelecting previously unselected package cuda-cufft-10-1.\r\nPreparing to unpack .../31-cuda-cufft-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-cufft-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-cufft-dev-10-1.\r\nPreparing to unpack .../32-cuda-cufft-dev-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-cufft-dev-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-curand-10-1.\r\nPreparing to unpack .../33-cuda-curand-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-curand-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-curand-dev-10-1.\r\nPreparing to unpack .../34-cuda-curand-dev-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-curand-dev-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-cusparse-10-1.\r\nPreparing to unpack .../35-cuda-cusparse-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-cusparse-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-cusparse-dev-10-1.\r\nPreparing to unpack .../36-cuda-cusparse-dev-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-cusparse-dev-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-npp-10-1.\r\nPreparing to unpack .../37-cuda-npp-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-npp-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-npp-dev-10-1.\r\nPreparing to unpack .../38-cuda-npp-dev-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-npp-dev-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-nvml-dev-10-1.\r\nPreparing to unpack .../39-cuda-nvml-dev-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-nvml-dev-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-nvjpeg-10-1.\r\nPreparing to unpack .../40-cuda-nvjpeg-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-nvjpeg-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-nvjpeg-dev-10-1.\r\nPreparing to unpack .../41-cuda-nvjpeg-dev-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-nvjpeg-dev-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package nsight-compute-2019.5.0.\r\nPreparing to unpack .../42-nsight-compute-2019.5.0_2019.5.0.14-1_amd64.deb ...\r\nUnpacking nsight-compute-2019.5.0 (2019.5.0.14-1) ...\r\nSelecting previously unselected package cuda-nsight-compute-10-1.\r\nPreparing to unpack .../43-cuda-nsight-compute-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-nsight-compute-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package nsight-systems-2019.5.2.\r\nPreparing to unpack .../44-nsight-systems-2019.5.2_2019.5.2.16-b54ef97_amd64.deb ...\r\nUnpacking nsight-systems-2019.5.2 (2019.5.2.16-b54ef97) ...\r\nSelecting previously unselected package cuda-nsight-systems-10-1.\r\nPreparing to unpack .../45-cuda-nsight-systems-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-nsight-systems-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-nvgraph-10-1.\r\nPreparing to unpack .../46-cuda-nvgraph-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-nvgraph-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-nvgraph-dev-10-1.\r\nPreparing to unpack .../47-cuda-nvgraph-dev-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-nvgraph-dev-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-visual-tools-10-1.\r\nPreparing to unpack .../48-cuda-visual-tools-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-visual-tools-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-tools-10-1.\r\nPreparing to unpack .../49-cuda-tools-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-tools-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-samples-10-1.\r\nPreparing to unpack .../50-cuda-samples-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-samples-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-documentation-10-1.\r\nPreparing to unpack .../51-cuda-documentation-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-documentation-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-libraries-dev-10-1.\r\nPreparing to unpack .../52-cuda-libraries-dev-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-libraries-dev-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-toolkit-10-1.\r\nPreparing to unpack .../53-cuda-toolkit-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-toolkit-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package libnvidia-common-450.\r\nPreparing to unpack .../54-libnvidia-common-450_450.36.06-0ubuntu1_all.deb ...\r\nChecking for existing driver runfile install\r\n/var/lib/dpkg/tmp.ci/preinst: 6: /var/lib/dpkg/tmp.ci/preinst: [[: not found\r\nUnpacking libnvidia-common-450 (450.36.06-0ubuntu1) ...\r\nPreparing to unpack .../55-libnvidia-compute-450_450.36.06-0ubuntu1_amd64.deb ...\r\nUnpacking libnvidia-compute-450:amd64 (450.36.06-0ubuntu1) ...\r\ndpkg: error processing archive /tmp/apt-dpkg-install-fjAi3S/55-libnvidia-compute-450_450.36.06-0ubuntu1_amd64.deb (--unpack):\r\n trying to overwrite '/usr/lib/x86_64-linux-gnu/libnvidia-allocator.so', which is also in package libnvidia-extra-440:amd64 440.82-0ubuntu0~0.18.04.2\r\nSelecting previously unselected package libnvidia-decode-450:amd64.\r\nPreparing to unpack .../56-libnvidia-decode-450_450.36.06-0ubuntu1_amd64.deb ...\r\nUnpacking libnvidia-decode-450:amd64 (450.36.06-0ubuntu1) ...\r\nSelecting previously unselected package libnvidia-encode-450:amd64.\r\nPreparing to unpack .../57-libnvidia-encode-450_450.36.06-0ubuntu1_amd64.deb ...\r\nUnpacking libnvidia-encode-450:amd64 (450.36.06-0ubuntu1) ...\r\nSelecting previously unselected package libnvidia-fbc1-450:amd64.\r\nPreparing to unpack .../58-libnvidia-fbc1-450_450.36.06-0ubuntu1_amd64.deb ...\r\nUnpacking libnvidia-fbc1-450:amd64 (450.36.06-0ubuntu1) ...\r\nSelecting previously unselected package libnvidia-gl-450:amd64.\r\nPreparing to unpack .../59-libnvidia-gl-450_450.36.06-0ubuntu1_amd64.deb ...\r\nUnpacking libnvidia-gl-450:amd64 (450.36.06-0ubuntu1) ...\r\nSelecting previously unselected package libnvidia-ifr1-450:amd64.\r\nPreparing to unpack .../60-libnvidia-ifr1-450_450.36.06-0ubuntu1_amd64.deb ...\r\nUnpacking libnvidia-ifr1-450:amd64 (450.36.06-0ubuntu1) ...\r\nSelecting previously unselected package nvidia-compute-utils-450.\r\nPreparing to unpack .../61-nvidia-compute-utils-450_450.36.06-0ubuntu1_amd64.deb ...\r\nUnpacking nvidia-compute-utils-450 (450.36.06-0ubuntu1) ...\r\nSelecting previously unselected package nvidia-kernel-source-450.\r\nPreparing to unpack .../62-nvidia-kernel-source-450_450.36.06-0ubuntu1_amd64.deb ...\r\nUnpacking nvidia-kernel-source-450 (450.36.06-0ubuntu1) ...\r\nSelecting previously unselected package nvidia-kernel-common-450.\r\nPreparing to unpack .../63-nvidia-kernel-common-450_450.36.06-0ubuntu1_amd64.deb ...\r\nUnpacking nvidia-kernel-common-450 (450.36.06-0ubuntu1) ...\r\nSelecting previously unselected package nvidia-dkms-450.\r\nPreparing to unpack .../64-nvidia-dkms-450_450.36.06-0ubuntu1_amd64.deb ...\r\nUnpacking nvidia-dkms-450 (450.36.06-0ubuntu1) ...\r\nSelecting previously unselected package nvidia-utils-450.\r\nPreparing to unpack .../65-nvidia-utils-450_450.36.06-0ubuntu1_amd64.deb ...\r\nUnpacking nvidia-utils-450 (450.36.06-0ubuntu1) ...\r\nSelecting previously unselected package libnvidia-cfg1-450:amd64.\r\nPreparing to unpack .../66-libnvidia-cfg1-450_450.36.06-0ubuntu1_amd64.deb ...\r\nUnpacking libnvidia-cfg1-450:amd64 (450.36.06-0ubuntu1) ...\r\nSelecting previously unselected package xserver-xorg-video-nvidia-450.\r\nPreparing to unpack .../67-xserver-xorg-video-nvidia-450_450.36.06-0ubuntu1_amd64.deb ...\r\nUnpacking xserver-xorg-video-nvidia-450 (450.36.06-0ubuntu1) ...\r\nSelecting previously unselected package nvidia-driver-450.\r\nPreparing to unpack .../68-nvidia-driver-450_450.36.06-0ubuntu1_amd64.deb ...\r\nUnpacking nvidia-driver-450 (450.36.06-0ubuntu1) ...\r\nSelecting previously unselected package nvidia-modprobe.\r\nPreparing to unpack .../69-nvidia-modprobe_450.36.06-0ubuntu1_amd64.deb ...\r\nUnpacking nvidia-modprobe (450.36.06-0ubuntu1) ...\r\nSelecting previously unselected package nvidia-settings.\r\nPreparing to unpack .../70-nvidia-settings_450.36.06-0ubuntu1_amd64.deb ...\r\nUnpacking nvidia-settings (450.36.06-0ubuntu1) ...\r\nSelecting previously unselected package cuda-drivers-450.\r\nPreparing to unpack .../71-cuda-drivers-450_450.36.06-1_amd64.deb ...\r\nUnpacking cuda-drivers-450 (450.36.06-1) ...\r\nSelecting previously unselected package cuda-drivers.\r\nPreparing to unpack .../72-cuda-drivers_450.36.06-1_amd64.deb ...\r\nUnpacking cuda-drivers (450.36.06-1) ...\r\nSelecting previously unselected package cuda-libraries-10-1.\r\nPreparing to unpack .../73-cuda-libraries-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-libraries-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-runtime-10-1.\r\nPreparing to unpack .../74-cuda-runtime-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-runtime-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-demo-suite-10-1.\r\nPreparing to unpack .../75-cuda-demo-suite-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-demo-suite-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package cuda-10-1.\r\nPreparing to unpack .../76-cuda-10-1_10.1.243-1_amd64.deb ...\r\nUnpacking cuda-10-1 (10.1.243-1) ...\r\nSelecting previously unselected package libcudnn7.\r\nPreparing to unpack .../77-libcudnn7_7.6.4.38-1+cuda10.1_amd64.deb ...\r\nUnpacking libcudnn7 (7.6.4.38-1+cuda10.1) ...\r\nSelecting previously unselected package libcudnn7-dev.\r\nPreparing to unpack .../78-libcudnn7-dev_7.6.4.38-1+cuda10.1_amd64.deb ...\r\nUnpacking libcudnn7-dev (7.6.4.38-1+cuda10.1) ...\r\nErrors were encountered while processing:\r\n /tmp/apt-dpkg-install-fjAi3S/55-libnvidia-compute-450_450.36.06-0ubuntu1_amd64.deb\r\nE: Sub-process /usr/bin/dpkg returned an error code (1)\r\n```", "comments": ["By the way, following the tutorial will leave the packages in a broken state, that's quite hard to fix. `apt --fix-broken install`will give something like: \r\n\r\n```ssh\r\nE: Sub-process /usr/bin/dpkg returned an error code (1)\r\n```\r\nbecause it can't overwrite `libnvidia-extra-440`, so you need to [force install it](https://askubuntu.com/questions/176121/dpkg-error-trying-to-overwrite-file-which-is-also-in). \r\n\r\nThe issue is because the tutorial installs cuda driver version 430, but the latest version is 450, so it's overwritten and it fails because of conflicts. ", "@dhiegomaga  Hi, quite same issues. I am installing CUDA 11.0 on ubuntu 18.04\r\n\r\n> $ apt-get -f install \r\nReading package lists... Done\r\nBuilding dependency tree       \r\nReading state information... Done\r\nCorrecting dependencies... Done\r\nThe following additional packages will be installed:\r\n  nvidia-compute-utils-450 nvidia-utils-450\r\nThe following NEW packages will be installed:\r\n  nvidia-compute-utils-450 nvidia-utils-450\r\n0 upgraded, 2 newly installed, 0 to remove and 106 not upgraded.\r\n251 not fully installed or removed.\r\nNeed to get 0 B/489 kB of archives.\r\nAfter this operation, 1570 kB of additional disk space will be used.\r\nDo you want to continue? [Y/n] y\r\nGet:1 file:/var/cuda-repo-ubuntu1804-11-0-local  nvidia-compute-utils-450 450.36.06-0ubuntu1 [123 kB]\r\nGet:2 file:/var/cuda-repo-ubuntu1804-11-0-local  nvidia-utils-450 450.36.06-0ubuntu1 [366 kB]\r\ndebconf: unable to initialize frontend: Dialog\r\ndebconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line\r\n 76, <> line 2.)debconf: falling back to frontend: Readline\r\n(Reading database ... 89397 files and directories currently installed.)\r\nPreparing to unpack .../nvidia-compute-utils-450_450.36.06-0ubuntu1_amd64.deb ...\r\nUnpacking nvidia-compute-utils-450 (450.36.06-0ubuntu1) ...\r\ndpkg: error processing archive /var/cuda-repo-ubuntu1804-11-0-local/./nvidia-compute-utils-450_450.36.06-0ubuntu1_amd64.deb (--unpack):\r\n unable to make backup link of './usr/bin/nvidia-cuda-mps-control' before installing new version: Invalid cross-device link\r\ndpkg-deb: error: paste subprocess was killed by signal (Broken pipe)\r\nPreparing to unpack .../nvidia-utils-450_450.36.06-0ubuntu1_amd64.deb ...\r\nUnpacking nvidia-utils-450 (450.36.06-0ubuntu1) ...\r\ndpkg: error processing archive /var/cuda-repo-ubuntu1804-11-0-local/./nvidia-utils-450_450.36.06-0ubuntu1_amd64.deb (--unpack):\r\n unable to make backup link of './usr/bin/nvidia-debugdump' before installing new version: Invalid cross-device link\r\ndpkg-deb: error: paste subprocess was killed by signal (Broken pipe)\r\nErrors were encountered while processing:\r\n /var/cuda-repo-ubuntu1804-11-0-local/./nvidia-compute-utils-450_450.36.06-0ubuntu1_amd64.deb\r\n /var/cuda-repo-ubuntu1804-11-0-local/./nvidia-utils-450_450.36.06-0ubuntu1_amd64.deb\r\nE: Sub-process /usr/bin/dpkg returned an error code (1)\r\n\r\nAlthough I run apt-get -f install, still get this error. Do you have any advice to fix this conflicts?\r\n\r\nI also try\r\n`dpkg -i --force-overwrite cuda-repo-ubuntu1804-11-0-local_11.0.1-450.36.06-1_amd64.deb` before install.", "With a force-overwrite option like\r\n`apt-get -o Dpkg::Options::=\"--force-overwrite\" install -f`\r\n\r\nError still followed:\r\n\r\n> $ apt-get -o Dpkg::Options::=\"--force-overwrite\" install --fix-broken\r\nReading package lists... Done\r\nBuilding dependency tree       \r\nReading state information... Done\r\nCorrecting dependencies... Done\r\nThe following packages were automatically installed and are no longer required:\r\n  adwaita-icon-theme at-spi2-core ...(mannually omit) ... xserver-common xserver-xorg-core-hwe-18.04 xserver-xorg-video-nvidia-450 xtrans-dev\r\nUse 'apt autoremove' to remove them.\r\nThe following additional packages will be installed:\r\n  nvidia-compute-utils-450 nvidia-utils-450\r\nThe following NEW packages will be installed:\r\n  nvidia-compute-utils-450 nvidia-utils-450\r\n0 upgraded, 2 newly installed, 0 to remove and 106 not upgraded.\r\n250 not fully installed or removed.\r\nNeed to get 0 B/489 kB of archives.\r\nAfter this operation, 1570 kB of additional disk space will be used.\r\nDo you want to continue? [Y/n] y\r\nGet:1 file:/var/cuda-repo-ubuntu1804-11-0-local  nvidia-compute-utils-450 450.36.06-0ubuntu1 [123 kB]\r\nGet:2 file:/var/cuda-repo-ubuntu1804-11-0-local  nvidia-utils-450 450.36.06-0ubuntu1 [366 kB]\r\ndebconf: unable to initialize frontend: Dialog\r\ndebconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line\r\n 76, <> line 2.)debconf: falling back to frontend: Readline\r\n(Reading database ... 89395 files and directories currently installed.)\r\nPreparing to unpack .../nvidia-compute-utils-450_450.36.06-0ubuntu1_amd64.deb ...\r\nUnpacking nvidia-compute-utils-450 (450.36.06-0ubuntu1) ...\r\ndpkg: error processing archive /var/cuda-repo-ubuntu1804-11-0-local/./nvidia-compute-utils-450_450.36.06-0ubuntu1_amd64.deb (--unpack):\r\n unable to make backup link of './usr/bin/nvidia-cuda-mps-control' before installing new version: Invalid cross-device link\r\ndpkg-deb: error: paste subprocess was killed by signal (Broken pipe)\r\nPreparing to unpack .../nvidia-utils-450_450.36.06-0ubuntu1_amd64.deb ...\r\nUnpacking nvidia-utils-450 (450.36.06-0ubuntu1) ...\r\ndpkg: error processing archive /var/cuda-repo-ubuntu1804-11-0-local/./nvidia-utils-450_450.36.06-0ubuntu1_amd64.deb (--unpack):\r\n unable to make backup link of './usr/bin/nvidia-debugdump' before installing new version: Invalid cross-device link\r\ndpkg-deb: error: paste subprocess was killed by signal (Broken pipe)\r\nErrors were encountered while processing:\r\n /var/cuda-repo-ubuntu1804-11-0-local/./nvidia-compute-utils-450_450.36.06-0ubuntu1_amd64.deb\r\n /var/cuda-repo-ubuntu1804-11-0-local/./nvidia-utils-450_450.36.06-0ubuntu1_amd64.deb\r\nE: Sub-process /usr/bin/dpkg returned an error code (1)\r\n", "Also been having this problem.  Spent all day, and was on the verge of reinstalling my OS because this broke my package system so badly.\r\n\r\nI don't really know what I am doing... but the following command was at least enough to fix the package manager so that I don't have to reinstall the OS.\r\n\r\nsudo apt-get -o Dpkg::Options::=\"--force-overwrite\" install libnvidia-compute-450\r\n", "I did manage to get TF to recognize my GPU!  Nvidia driver is version 450.", "This installation process just nuked my Nvidia drivers too. Ubuntu 18.04. ", "The issue seems to be that the command\r\n\r\n`sudo apt-get install --no-install-recommends nvidia-driver-430`\r\n\r\nno longer installs a nvidia 430 driver, but defaults to installing nvidia-440 on ubuntu.\r\n\r\nnvidia-430 drivers are a \"transitional package\", so it is not actually possible to install 430 anymore through apt-get nor from ppa. \r\nhttps://packages.ubuntu.com/bionic-updates/nvidia-driver-430\r\nhttps://askubuntu.com/questions/1240294/cannot-downgrade-nvidia-driver-440-to-nvidia-driver-430-on-ubuntu-18-04\r\n\r\nDoes the nvidia 440 driver result in a mismatch with cuda 10.1? Drivers should be backwards compatible with older versions of cuda.\r\n\r\nEdit: Following the installation process after purging all nvidia/cuda drivers leads to:\r\n\r\n```\r\n$ nvidia-smi\r\nFailed to initialize NVML: Driver/library version mismatch\r\n```\r\n\r\nThis mismatch comes after running the CUDA 10.1-specific parts of the installation:\r\n\r\n```\r\n# Install development and runtime libraries (~4GB)\r\nsudo apt-get install --no-install-recommends \\\r\n    cuda-10-1 \\\r\n    libcudnn7=7.6.4.38-1+cuda10.1  \\\r\n    libcudnn7-dev=7.6.4.38-1+cuda10.1\r\n\r\n\r\n# Install TensorRT. Requires that libcudnn7 is installed above.\r\nsudo apt-get install -y --no-install-recommends libnvinfer6=6.0.1-1+cuda10.1 \\\r\n    libnvinfer-dev=6.0.1-1+cuda10.1 \\\r\n    libnvinfer-plugin6=6.0.1-1+cuda10.1\r\n```\r\n\r\nBefore attempting to install CUDA 10.1, `nvidia-smi` shows nvidia-440 driver successfully installed and it prints CUDA: 10.2 (highest compatible version for that driver?). \r\n\r\nEdit2: After rebooting the computer drivers are detected again. Installation process worked after purging old drivers and cuda. ", "@nluehr what would be the instructions to install cuda/cudnn?\r\nWho would be the best person to ask this?", "If it helps people undoing their cuda install, I found 2 useful commands by browsing stackoverflow:\r\n\r\n`dpkg --configure -a`: this command (ran with `sudo`) identified errors with a select few of my pacakges. Namely:\r\n```\r\nErrors were encountered while processing:\r\n libnvidia-ifr1-450:amd64\r\n cuda-drivers-450\r\n nvidia-driver-450\r\n cuda-drivers\r\n cuda-runtime-11-0\r\n cuda-11-0\r\n cuda-demo-suite-11-0\r\n cuda\r\n```\r\n\r\nAfter that, I ran this command to purge the packages:\r\n`apt purge cuda cuda-demo-suite-11-0 cuda-11-0 cuda-runtime-11-0 cuda-drivers nvidia-driver-450 cuda-drivers-450 libnvidia-ifr1-450:amd64`\r\n\r\nFinally, I could `apt autoremove` and my computer appears to be completely free of nvidia drivers now.\r\n\r\nMy next step is to go back to the nvidia website and to follow their instructions for installing the most recent version of `cuda` ...", "The users appear to be doing the correct things. There may be a bug in nvidia's driver packaging. I'm checking with the driver team.", "To help someone new come, I find this problem may be related to the conflict between cuda and GPU Driver. In my case, I have no right to reinstall GPU driver. At first, I try to install cuda 11, but failed. Finally, I reinstall cuda 10.2 (this version can be correctly installed before), but it get broken again.\r\n\r\nSome logs:\r\nResults for `nvidia-smi`\r\n> +---------------------------------------------------------------------------+\r\n| NVIDIA-SMI 418.43       Driver Version: 418.43       CUDA Version: 10.2     |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+===============|\r\n|   0  GeForce RTX 2080    Off  | 00000000:02:00.0 Off |                  N/A |\r\n| 17%   38C    P0    37W / 215W |      0MiB /  7952MiB |      1%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n\r\nResults for `apt --fix-broken install`  (install cuda 10.2)\r\n\r\n> ... \r\nGet:1 https://developer.download.nvidia.cn/compute/cuda/repos/ubuntu1604/x86_64  nvidia-440 440.64.00-0ubuntu1 [131 MB]\r\nFetched 131 MB in 43s (3015 kB/s)                                                                                                                    \r\ndebconf: unable to initialize frontend: Dialog\r\ndebconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line\r\n 76, <> line 1.)debconf: falling back to frontend: Readline\r\n(Reading database ... 90252 files and directories currently installed.)\r\nPreparing to unpack .../nvidia-440_440.64.00-0ubuntu1_amd64.deb ...\r\nUnpacking nvidia-440 (440.64.00-0ubuntu1) ...\r\ndpkg: error processing archive /var/cache/apt/archives/nvidia-440_440.64.00-0ubuntu1_amd64.deb (--unpack):\r\n trying to overwrite '/usr/lib/x86_64-linux-gnu/libGLX_indirect.so.0', which is also in package libglx-mesa0:amd64 19.2.8-0ubuntu0~18.04.3\r\nErrors were encountered while processing:\r\n /var/cache/apt/archives/nvidia-440_440.64.00-0ubuntu1_amd64.deb\r\nE: Sub-process /usr/bin/dpkg returned an error code (1)\r\n(base) \r\n", "anyone solve this problem?", "If I recall correctly you need to install the 450 nvidia driver.  Which essentially just means replacing the number '430' with '450' in the install instructions.\r\n\r\nUnless you broke your package manager, in which case you have to force overwrite the broken library.  As per my comment above, the following command fixed things for me:\r\n\r\nsudo apt-get -o Dpkg::Options::=\"--force-overwrite\" install libnvidia-compute-450", "I eventually got this worked out for Ubuntu 20.04 LTS with an NVIDIA GTX 1070. This is a hack, and hopefully the packages are fixed correctly in the future.  Be advised that messing around with graphics drivers can be a messy business and **there's a real risk here that your screen may not turn on afterwords**; I would keep a bootable USB stick handy in case these instructions don't work for you. Please read that again:\r\n# There's a real risk here that your screen may not turn on after messing with graphics drivers; make bootable USB!\r\n\r\nYou can [do this via unetbootin](https://unetbootin.github.io/) with an [Ubuntu ISO](https://ubuntu.com/download/desktop). Anyways, moving on:\r\n\r\n**Problem**\r\nI ran the documented instructions [on the Tensorflow site](https://www.tensorflow.org/install/gpu) and they left me with a bunch of broken packages and now `nvidia-smi` doesn't work.\r\n\r\n**Solution**\r\nFind the path of the package that is causing the issue and force install it with `dpkg`. I don't have the exact command I ran, but I had the same error message about a .dpkg file `trying to overwrite ...  which is also in package ...`. Going on @ChenFengYe's example above, we see:\r\n```\r\nUnpacking nvidia-440 (440.64.00-0ubuntu1) ...\r\ndpkg: error processing archive /var/cache/apt/archives/nvidia-440_440.64.00-0ubuntu1_amd64.deb (--unpack):\r\ntrying to overwrite '/usr/lib/x86_64-linux-gnu/libGLX_indirect.so.0', which is also in package libglx-mesa0:amd64 19.2.8-0ubuntu0~18.04.3\r\nErrors were encountered while processing:\r\n/var/cache/apt/archives/nvidia-440_440.64.00-0ubuntu1_amd64.deb\r\nE: Sub-process /usr/bin/dpkg returned an error code (1)\r\n```\r\nso the command to run would be:\r\n```\r\nsudo dpkg -i --force-all /var/cache/apt/archives/nvidia-440_440.64.00-0ubuntu1_amd64.deb\r\n```\r\nI then rebooted afterwords, confirmed I could run `nvidia-smi`, and confirmed that my specific issue (trying to make sure TensorFlow could see my GPUs) was fixed:\r\n```\r\n>>> import tensorflow as tf\r\n>>> print(\"GPUs Available: \", tf.config.experimental.list_physical_devices('GPU'))\r\nGPUs Available:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\r\n```\r\n\r\nLooking at @ecpoppenheimer 's comment above after writing this, I think that would also work as well but I didn't try it. \r\n\r\n\r\n-----------\r\nHere's a separate issue some of you may be having:\r\n\r\n**Problem**\r\nI ran the instructions from TensorFlow's setup page and now my machine is all screwed up with broken packages and that little annoying red symbol in the status bar won't go away. Also, I am having trouble installing other packages now. I hate Linux. Maybe I should quit my job.\r\n\r\n**Solution**\r\nNo need to change career tracks. Just uninstall the broken packages. There is probably a nifty programmatic way to do this, but I just did it by hand. Run `sudo apt-get remove -f` to see which packages are broken, then add them to the list and run `sudo apt-get remove -f <package-name1> <package-name2> ...` until you are actually able to uninstall everything. \r\n\r\n**MAKE SURE YOU HAVE A GRAPHICS DRIVER PACKAGE INSTALLED BEFORE YOU REBOOT UNLESS YOU WANT TO SPEND SEVERAL HOURS SEARCHING STACK OVERFLOW FROM YOUR PHONE AND WISHING FOR THE SWEET EMBRACE OF DEATH**. This should do it (though you may need a different version number; YMMV):\r\n```\r\nsudo apt-get install nvidia-driver-450\r\n```", "This error happens to me as well since I'd followed along this instruction\r\n```\r\n$ sudo apt-get install --no-install-recommends nvidia-driver-440\r\n\r\n$ sudo apt-get install --no-install-recommends \\\r\n    cuda-10-1 \\\r\n    libcudnn7=7.6.4.38-1+cuda10.1  \\\r\n    libcudnn7-dev=7.6.4.38-1+cuda10.1\r\n```\r\nAfter I forced install `libnvidia-compute-450`, my `nvidia-smi` is now changed like this which its driver supposes to be `440.83` doesn't it?\r\n\r\n![Screenshot from 2020-06-17 12-24-41](https://user-images.githubusercontent.com/51353899/84858581-ab5f8100-b095-11ea-80f5-a9cd66f46f00.png)\r\n", "@tanyapohn - `450` is the latest version of `nvidia-driver-*` available through `apt` (though I see `440` on the [nvidia website for drivers](https://www.geforce.com/drivers)). Are you having other `nvidia-smi` issues, or is this just something you noticed? ", "@jsgoller1 Hi, \r\nThank you for replying my comment.\r\n\r\nIt's something that I noticed after I encountered the error of:\r\n```\r\nErrors were encountered while processing:\r\n /tmp/apt-dpkg-install-fjAi3S/55-libnvidia-compute-450_450.36.06-0ubuntu1_amd64.deb\r\nE: Sub-process /usr/bin/dpkg returned an error code (1)\r\n``` \r\nAnd I fixed it by:\r\n```\r\nsudo apt-get -o Dpkg::Options::=\"--force-overwrite\" install libnvidia-compute-450\r\n```\r\nThen, my `nvidia-smi` has changed from `440.83` to `450`.\r\n\r\nIs that weird? However, training a model seems normal right now.", "440 or 450 are just nvidia driver versions. CUDA versions usually have a minimum supported driver, anything newer will just work.\r\n\r\nBut again, I will defer to nvidia for the correct instructions.", "> @dhiegomaga Hi, quite same issues. I am installing CUDA 11.0 on ubuntu 18.04\r\n\r\nSame problem here, installing CUDA 10.1 on Ubuntu 20.04 (Linux Mint 20). It corrupted my nvidia drivers, too... :(", "+1\r\n Following the TensorFlow GPU instructions on a clean Ubuntu 18.04 fails with library conflicts. I thought it odd that I installed the '430' driver and yet most of the libs installed reported 440.  Running the following resolved it for me as well.\r\n\r\n`sudo apt-get -o Dpkg::Options::=\"--force-overwrite\" install libnvidia-compute-450`", "@michaelgallacher ,thanks for your comments, your solution could help temprarily workaround this serious mistake in tensorflow's installation.", "> Also been having this problem. Spent all day, and was on the verge of reinstalling my OS because this broke my package system so badly.\r\n> \r\n> I don't really know what I am doing... but the following command was at least enough to fix the package manager so that I don't have to reinstall the OS.\r\n> \r\n> sudo apt-get -o Dpkg::Options::=\"--force-overwrite\" install libnvidia-compute-450\r\n\r\nthe last command works\r\n", "facing the exact same issue:\r\n\r\n```\r\nsudo apt --fix-broken install\r\nReading package lists... Done\r\nBuilding dependency tree       \r\nReading state information... Done\r\nCorrecting dependencies... Done\r\nThe following packages were automatically installed and are no longer required:\r\n  cuda-command-line-tools-10-1 cuda-compiler-10-1 cuda-cudart-10-1 cuda-cudart-dev-10-1 cuda-cufft-10-1 cuda-cufft-dev-10-1 cuda-cuobjdump-10-1 cuda-cupti-10-1 cuda-curand-10-1 cuda-curand-dev-10-1\r\n  cuda-cusolver-10-1 cuda-cusolver-dev-10-1 cuda-cusparse-10-1 cuda-cusparse-dev-10-1 cuda-demo-suite-10-1 cuda-documentation-10-1 cuda-driver-dev-10-1 cuda-drivers cuda-drivers-450 cuda-gdb-10-1\r\n  cuda-gpu-library-advisor-10-1 cuda-libraries-10-1 cuda-libraries-dev-10-1 cuda-license-10-1 cuda-license-10-2 cuda-memcheck-10-1 cuda-misc-headers-10-1 cuda-npp-10-1 cuda-npp-dev-10-1 cuda-nsight-10-1\r\n  cuda-nsight-compute-10-1 cuda-nsight-systems-10-1 cuda-nvcc-10-1 cuda-nvdisasm-10-1 cuda-nvgraph-10-1 cuda-nvgraph-dev-10-1 cuda-nvjpeg-10-1 cuda-nvjpeg-dev-10-1 cuda-nvml-dev-10-1 cuda-nvprof-10-1\r\n  cuda-nvprune-10-1 cuda-nvrtc-10-1 cuda-nvrtc-dev-10-1 cuda-nvtx-10-1 cuda-nvvp-10-1 cuda-runtime-10-1 cuda-samples-10-1 cuda-sanitizer-api-10-1 cuda-toolkit-10-1 cuda-tools-10-1 cuda-visual-tools-10-1\r\n  dkms freeglut3 freeglut3-dev libatomic1:i386 libbsd0:i386 libcublas-dev libcublas10 libdrm-amdgpu1:i386 libdrm-dev libdrm-intel1:i386 libdrm-nouveau2:i386 libdrm-radeon1:i386 libdrm2:i386\r\n  libedit2:i386 libelf1:i386 libexpat1:i386 libffi6:i386 libgl1:i386 libgl1-mesa-dev libgl1-mesa-dri:i386 libglapi-mesa:i386 libgles1 libglu1-mesa-dev libglvnd-core-dev libglvnd-dev libglvnd0:i386\r\n  libglx-mesa0:i386 libglx0:i386 libice-dev libllvm9:i386 libnvidia-cfg1-450 libnvidia-common-440 libnvidia-common-450 libnvidia-compute-450 libnvidia-decode-450 libnvidia-encode-450 libnvidia-extra-440\r\n  libnvidia-fbc1-450 libnvidia-gl-450 libnvidia-ifr1-450 libopengl0 libpciaccess0:i386 libpthread-stubs0-dev libsensors4:i386 libsm-dev libstdc++6:i386 libx11-6:i386 libx11-dev libx11-xcb-dev\r\n  libx11-xcb1:i386 libxau-dev libxau6:i386 libxcb-dri2-0:i386 libxcb-dri2-0-dev libxcb-dri3-0:i386 libxcb-dri3-dev libxcb-glx0:i386 libxcb-glx0-dev libxcb-present-dev libxcb-present0:i386\r\n  libxcb-randr0-dev libxcb-render0-dev libxcb-shape0-dev libxcb-sync-dev libxcb-sync1:i386 libxcb-xfixes0-dev libxcb1:i386 libxcb1-dev libxdamage-dev libxdamage1:i386 libxdmcp-dev libxdmcp6:i386\r\n  libxext-dev libxext6:i386 libxfixes-dev libxfixes3:i386 libxi-dev libxmu-dev libxmu-headers libxnvctrl0 libxshmfence-dev libxshmfence1:i386 libxt-dev libxxf86vm-dev libxxf86vm1:i386 mesa-common-dev\r\n  nsight-compute-2020.1.0 nsight-systems-2019.5.2 nvidia-compute-utils-450 nvidia-dkms-450 nvidia-driver-450 nvidia-kernel-common-450 nvidia-kernel-source-450 nvidia-modprobe nvidia-prime\r\n  nvidia-settings nvidia-utils-450 pkg-config screen-resolution-extra x11proto-core-dev x11proto-damage-dev x11proto-dev x11proto-fixes-dev x11proto-input-dev x11proto-xext-dev x11proto-xf86vidmode-dev\r\n  xorg-sgml-doctools xserver-xorg-video-nvidia-450 xtrans-dev\r\nUse 'sudo apt autoremove' to remove them.\r\nThe following additional packages will be installed:\r\n  libnvidia-compute-450\r\nThe following NEW packages will be installed:\r\n  libnvidia-compute-450\r\n0 upgraded, 1 newly installed, 0 to remove and 201 not upgraded.\r\n124 not fully installed or removed.\r\nNeed to get 0 B/21.8 MB of archives.\r\nAfter this operation, 115 MB of additional disk space will be used.\r\nDo you want to continue? [Y/n] y\r\n(Reading database ... 201507 files and directories currently installed.)\r\nPreparing to unpack .../libnvidia-compute-450_450.36.06-0ubuntu1_amd64.deb ...\r\nUnpacking libnvidia-compute-450:amd64 (450.36.06-0ubuntu1) ...\r\ndpkg: error processing archive /var/cache/apt/archives/libnvidia-compute-450_450.36.06-0ubuntu1_amd64.deb (--unpack):\r\n trying to overwrite '/usr/lib/x86_64-linux-gnu/libnvidia-allocator.so', which is also in package libnvidia-extra-440:amd64 440.100-0ubuntu0.18.04.1\r\nErrors were encountered while processing:\r\n /var/cache/apt/archives/libnvidia-compute-450_450.36.06-0ubuntu1_amd64.deb\r\n\r\n```", "@nluehr, are there any updates from the nvidia driver team?", "The 450.51.05 driver posted earlier this week with the CUDA 11 [toolkit](https://developer.nvidia.com/cuda-downloads?target_os=Linux&target_arch=x86_64) resolves this issue. It is also included in the cuda developer deb repos, so a one line fix in the instructions will be sufficient.\r\n\r\nOpened [PR 1616](https://github.com/tensorflow/docs/pull/1616) with fix.", "@dhiegomaga,\r\nIs this still an issue?\r\n\r\nThe documentation has been updated for TensorFlow v2.4.1 and I did not face any errors on running the commands.\r\n\r\nPlease feel free to close the issue if resolved. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40278\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40278\">No</a>\n"]}, {"number": 40277, "title": "tf2.0 Multi-worker training with Keras  only utilizing one GPU", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n```\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):yes\r\n- OS  : Ubuntu 16.04LTS\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:No\r\n- TensorFlow installed from (source or binary): Frome docker TF2.1.0-gpu-py3\r\n- TensorFlow version (use command below): TF2.1.0-gpu-py3\r\n- Python version: 3.6\r\n- CUDA/cuDNN version:10.1 not sure cuDNN version\r\n- docker18.09.7-3\r\n- nvidia-container-runtime=2.0.0\r\n- kubernetes 1.5.7\r\n- kubeflow 1.01\r\n- 1Master   IP:14X.XXX.XXX.1\r\n- node1     IP:14X.XXX.XXX.8     GTX1060\r\n- node2     IP:14X.XXX.XXX.9     GTX1060\r\n- node3     IP:14X.XXX.XXX.10    GTX1070\r\n\r\n```\r\n**Describe the current behavior**\r\nI use  Multi-worker training with Keras but it only use one Gpu\r\nError:\r\n1.error: Internal: Complete shape not known for Adam/allreduce/CollectiveReduce_2\r\n2.`eval_fn` is not passed in. The `worker_fn` will be used if an \"evaluator\" task exists in the cluster\r\n3.Most import it only run one gpu\r\nI run the code described below:\r\n\r\nTEST 1: (3 machine)\r\n\r\n![image](https://user-images.githubusercontent.com/50796022/84034018-556f4700-a9cc-11ea-8865-944bb5c13e51.png)\r\n\r\n\r\nTEST 2 : (2 machine)\r\n![image](https://user-images.githubusercontent.com/50796022/84033957-396ba580-a9cc-11ea-84ac-c9af37f06710.png)\r\n**Describe the expected behavior**\r\nUse Multi gpu\r\n### My Docker File\r\n```\r\nFROM tensorflow/tensorflow:2.1.0-gpu-py3\r\nRUN apt-get update\r\nRUN apt-get install -y libsm6 libxext6 libxrender-dev\r\nRUN pip install opencv-python\r\nRUN pip install Pillow\r\nRUN mkdir -p /app\r\nADD tp720_1.py /app/\r\nCOPY nspo /app/\r\n```\r\n### My yaml\r\n```\r\napiVersion: kubeflow.org/v1\r\nkind: TFJob\r\nmetadata:\r\n  name: nspo-rice\r\nspec:\r\n  tfReplicaSpecs:\r\n    Chief:\r\n      replicas: 1\r\n      template:\r\n        metadata:\r\n          annotations:\r\n            sidecar.istio.io/inject: \"false\"\r\n          name: tensorflow\r\n        spec:\r\n          containers:\r\n          - command:\r\n            - python\r\n            - tp720_1.py\r\n            image: nsporice:270_7\r\n            name: tensorflow\r\n            env:\r\n            - name: test_tmpdir\r\n              value: /app/data\r\n            resourceas:\r\n              limits:\r\n                cpu: '1'\r\n            volumeMounts:\r\n            - mountPath: /app/data\r\n              name: nspo-rice-volume\r\n            workingDir: /app\r\n          restartPolicy: Never\r\n          volumes:\r\n          - name: nspo-rice-volume\r\n            persistentVolumeClaim:\r\n              claimName: nspo-rice-volume\r\n    Worker:\r\n      replicas: 2\r\n      template:\r\n        metadata:\r\n          annotations:\r\n            sidecar.istio.io/inject: \"false\"\r\n          name: tensorflow\r\n        spec:\r\n          containers:\r\n          - command:\r\n            - python\r\n            - tp720_1.py\r\n            image: nsporice:270_7\r\n            name: tensorflow\r\n            env:\r\n            - name: test_tmpdir\r\n              value: /app/data\r\n            resourceas:\r\n              limits:\r\n                nvidia.com/gpu: 1\r\n            volumeMounts:\r\n            - mountPath: /app/data\r\n              name: nspo-rice-volume\r\n            workingDir: /app\r\n          restartPolicy: Never\r\n          volumes:\r\n          - name: nspo-rice-volume\r\n            persistentVolumeClaim:\r\n              claimName: nspo-rice-volume\r\n\r\n```\r\nMy code\r\n```\r\nfrom os import walk\r\nfrom os.path import join\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\nimport cv2\r\nimport time\r\nimport random\r\nfrom scipy import signal\r\nimport os\r\nimport json\r\nimport tensorflow as tf\r\nfrom tensorflow.keras import layers\r\nfrom tensorflow.keras.models import Sequential\r\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, GRU, LSTM, TimeDistributed, RepeatVector, Bidirectional\r\nfrom tensorflow.keras.layers import BatchNormalization\r\nfrom tensorflow.keras.layers import LeakyReLU\r\nfrom tensorflow.keras import losses\r\nfrom tensorflow.keras import optimizers\r\nfrom tensorflow.keras import metrics\r\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\r\nimport tensorflow.keras.backend as K\r\nfrom tensorflow.keras.models import load_model\r\nclass TimeHistory(tf.keras.callbacks.Callback):\r\n    def on_train_begin(self, logs={}):\r\n        self.losses = {'batch':[], 'epoch':[]}\r\n        self.accuracy = {'batch':[], 'epoch':[]}\r\n        self.val_loss = {'batch':[], 'epoch':[]}\r\n        self.val_acc = {'batch':[], 'epoch':[]}\r\n        self.times = []\r\n        self.totaltime = time.time()\r\n        \r\n    def on_train_end(self, logs={}):\r\n        self.totaltime = time.time() - self.totaltime\r\n    \r\n    def on_batch_end(self, batch, logs={}):\r\n        self.losses['batch'].append(logs.get('loss'))\r\n        self.accuracy['batch'].append(logs.get('acc'))\r\n        self.val_loss['batch'].append(logs.get('val_loss'))\r\n        self.val_acc['batch'].append(logs.get('val_acc'))\r\n\r\n    def on_epoch_begin(self, batch, logs={}):\r\n        self.epoch_time_start = time.time()\r\n        \r\n    def on_epoch_end(self, batch, logs={}):\r\n        self.losses['epoch'].append(logs.get('loss'))\r\n        \r\n        self.accuracy['epoch'].append(logs.get('acc'))\r\n        self.val_loss['epoch'].append(logs.get('val_loss'))\r\n        self.val_acc['epoch'].append(logs.get('val_acc'))\r\n        self.times.append(time.time() - self.epoch_time_start)\r\n   \r\n    def loss_plot(self, loss_type):\r\n        acc =[]\r\n        loss = []\r\n        val = []\r\n        iters = range(len(self.losses[loss_type]))\r\n        # acc\r\n        acc.extend(self.accuracy[loss_type])\r\n        # loss\r\n        print(\"loss = \",self.losses[loss_type])\r\n        loss.extend(self.losses[loss_type])\r\n        # val\r\n        print(\"val = \",self.losses[loss_type])\r\n        val.extend(self.val_acc[loss_type])\r\n        return(acc, loss,val)\r\ntime_callback = TimeHistory()\r\n      \r\ndef buildManyToOneModel(shape):\r\n\r\n    model = tf.keras.models.Sequential([\r\n        GRU(32, input_dim = shape[2], input_length = shape[1], return_sequences = True),\r\n        GRU(64, return_sequences = True),\r\n        GRU(128, return_sequences = False),\r\n        #LSTM(16, return_sequences = True),\r\n        #LSTM(16, return_sequences = False),\r\n        BatchNormalization(),\r\n        Dense(1, activation='sigmoid')\r\n    ])\r\n    model.compile(loss='mse', optimizer = 'adam', metrics=['acc'])\r\n    model.summary()\r\n    return model\r\n\r\ndef slice_(data, node_num):\r\n    total = float(data.shape[0])\r\n    store = []\r\n    if node_num == 1:\r\n        store.append(data[0:int(total),:])\r\n        store.append([0])\r\n        store.append([0])\r\n    elif node_num == 2:\r\n        slice_index = int(total / 2)\r\n        store.append(data[0:slice_index, :])\r\n        store.append(data[slice_index:int(total), :])\r\n        store.append([0])\r\n    elif node_num == 3:\r\n        slice_index = int(total / 3)\r\n        store.append(data[0:slice_index, :])\r\n        store.append(data[slice_index:2*slice_index, :])\r\n        store.append(data[2*slice_index:int(total), :])\r\n    return store\r\n\r\ndef train():\r\n    print(\"TensorFlow version: \", tf.__version__)\r\n    tf_config = os.environ.get('TF_CONFIG', '{}')\r\n    print(\"TF_CONFIG %s\", tf_config)\r\n    tf_config_json = json.loads(tf_config)\r\n    cluster = tf_config_json.get('cluster')\r\n    job_name = tf_config_json.get('task', {}).get('type')\r\n    task_index = tf_config_json.get('task', {}).get('index')\r\n\r\n    print(\"cluster={} job_name={} task_index={}}\", cluster, job_name, task_index)\r\n    \r\n    gpus = tf.config.experimental.list_physical_devices('GPU')\r\n    if gpus:\r\n        try:\r\n            for gpu in gpus:\r\n                tf.config.experimental.set_memory_growth(gpu, True)\r\n        except RuntimeError as e:\r\n            print(e)\r\n    strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy(communication=tf.distribute.experimental.CollectiveCommunication.RING)\r\n    print ('Number of devices: {}'.format(strategy.num_replicas_in_sync))\r\n\r\n    data0 = np.load('/app/data/2017_360w_data_0.npy')\r\n    data1 = np.load('/app/data/2017_360w_data_1.npy')\r\n    data0 = data0[:,:,0]\r\n    data1 = data1[:,:,0]\r\n    print(\"data0:\",data0.shape)\r\n    print(\"data1:\",data1.shape)\r\n    a1 = np.array(data0)[0 : int(data0.shape[0]*0.7), :]\r\n    a2 = np.array(data1)[0 : int(data1.shape[0]*0.7), :]\r\n    a3 = np.array(data0)[int(data0.shape[0]*0.7) : data0.shape[0], :]\r\n    a4 = np.array(data1)[int(data1.shape[0]*0.7) : data1.shape[0], :]\r\n    X_train = np.concatenate((a1, a2), axis=0) \r\n    X_val = np.concatenate((a3, a4), axis=0) \r\n\r\n    b1 = np.zeros((a1.shape[0], 1))\r\n    b2 = np.ones((a2.shape[0], 1))\r\n\r\n    b3 = np.zeros((a3.shape[0], 1))\r\n\r\n    b4 = np.ones((a4.shape[0], 1))\r\n\r\n    Y_train = np.concatenate((b1, b2), axis=0)\r\n    Y_val = np.concatenate((b3, b4), axis=0)\r\n    X_train = X_train.astype(np.float32)\r\n    Y_train = Y_train.astype(np.float32)\r\n    X_val = X_val.astype(np.float32)\r\n    Y_val = Y_val.astype(np.float32)\r\n    X_train = X_train[:,:,np.newaxis]\r\n\r\n    X_val = X_val[:,:,np.newaxis]\r\n    print(X_train.shape)\r\n    print(Y_train.shape)\r\n    print(X_val.shape)\r\n    print(Y_val.shape)\r\n    print(type(X_train)) \r\n    print(type(Y_train))    \r\n    BUFFER_SIZE = X_train.shape[0]\r\n \r\n    BATCH_SIZE_PER_REPLICA = 5000\r\n    GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA  * (strategy.num_replicas_in_sync-1)\r\n    \r\n    #train_dist_dataset = strategy.experimental_distribute_dataset(train_dataset)\r\n    #test_dist_dataset = strategy.experimental_distribute_dataset(test_dataset) \r\n   \r\n    if BUFFER_SIZE % GLOBAL_BATCH_SIZE != 0:\r\n        parallel_steps =  X_train.shape[0] // GLOBAL_BATCH_SIZE + 1\r\n        a =  X_val.shape[0] // GLOBAL_BATCH_SIZE + 1\r\n    else:\r\n        parallel_steps =  X_train.shape[0] // GLOBAL_BATCH_SIZE\r\n        a =  X_val.shape[0] // GLOBAL_BATCH_SIZE         \r\n    print(parallel_steps) \r\n    t2 = time.time()\r\n    with strategy.scope():\r\n         train_dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_train)).repeat().shuffle(buffer_size=5000000).batch(GLOBAL_BATCH_SIZE)\r\n         #test_dataset = tf.data.Dataset.from_tensor_slices((X_val, Y_val)).batch(GLOBAL_BATCH_SIZE) \r\n         options = tf.data.Options()\r\n         options.experimental_distribute.auto_shard_policy = \\\r\n                                        tf.data.experimental.AutoShardPolicy.DATA\r\n         train_dataset = train_dataset.with_options(options)    \r\n         #test_dataset = test_dataset.with_options(options)        \r\n         multi_worker_model = buildManyToOneModel(X_train.shape)    \r\n\r\n    #history = multi_worker_model.fit(train_dataset, epochs=30, validation_data=test_dataset,steps_per_epoch=parallel_steps,validation_steps=a,callbacks=[time_callback])\r\n    history = multi_worker_model.fit(train_dataset, epochs=30,steps_per_epoch=parallel_steps,callbacks=[time_callback])\r\n    t3 = time.time()    \r\n    print (\"It cost \", t3 - t2, \" seconds\")\r\n\r\n\r\n    accuracy, loss,val = time_callback.loss_plot('epoch')\r\n    print(\"totaltime:%.4f\"%time_callback.totaltime)\r\n    for i in range(len(accuracy)):\r\n        print(\"acc: %.4f, loss: %.4f,val:%.4f -----epoch:%d\" %(accuracy[i], loss[i],val[i],i+1))\r\n    totaltime='%.2f'%time_callback.totaltime\r\n    ttime= t3 - t2\r\n    traningtime='%.2f'%ttime\r\n    maxval='%.2f'%max(val)\r\n    save_dir = '/app/data'\r\n    f = open(save_dir+\"/720_1.txt\", \"a\")\r\n    f.write(\"\\ntotaltime:{},traningtime:{},val:{}\".format(totaltime,traningtime,maxval))\r\n    f.close()\r\nif __name__ == '__main__':\r\n    train()  \r\n```\r\n\r\n\r\n\r\nPod logs\r\n```\r\n2020-06-08 12:52:04.146322: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer.so.6\r\n2020-06-08 12:52:04.147962: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer_plugin.so.6\r\n2020-06-08 12:52:04.788595: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\r\n2020-06-08 12:52:04.795356: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \r\npciBusID: 0000:05:00.0 name: GeForce GTX 1070 computeCapability: 6.1\r\ncoreClock: 1.7715GHz coreCount: 15 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 238.66GiB/s\r\n2020-06-08 12:52:04.795467: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\r\n2020-06-08 12:52:04.795550: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\r\n2020-06-08 12:52:04.798357: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\r\n2020-06-08 12:52:04.799032: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\r\n2020-06-08 12:52:04.802641: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\r\n2020-06-08 12:52:04.804156: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\r\n2020-06-08 12:52:04.804221: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2020-06-08 12:52:04.805601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\r\n2020-06-08 12:52:04.806525: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2020-06-08 12:52:04.814745: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2198720000 Hz\r\n2020-06-08 12:52:04.815811: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5c54090 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-06-08 12:52:04.815832: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2020-06-08 12:52:04.933082: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5cb9890 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\r\n2020-06-08 12:52:04.933126: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1070, Compute Capability 6.1\r\n2020-06-08 12:52:04.934468: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \r\npciBusID: 0000:05:00.0 name: GeForce GTX 1070 computeCapability: 6.1\r\ncoreClock: 1.7715GHz coreCount: 15 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 238.66GiB/s\r\n2020-06-08 12:52:04.934575: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\r\n2020-06-08 12:52:04.934620: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\r\n2020-06-08 12:52:04.934658: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\r\n2020-06-08 12:52:04.934694: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\r\n2020-06-08 12:52:04.934746: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\r\n2020-06-08 12:52:04.934794: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\r\n2020-06-08 12:52:04.934850: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2020-06-08 12:52:04.938735: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\r\n2020-06-08 12:52:04.938852: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\r\n2020-06-08 12:52:05.301356: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-06-08 12:52:05.301383: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 \r\n2020-06-08 12:52:05.301391: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N \r\n2020-06-08 12:52:05.302813: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6927 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:05:00.0, compute capability: 6.1)\r\n2020-06-08 12:52:05.305432: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \r\npciBusID: 0000:05:00.0 name: GeForce GTX 1070 computeCapability: 6.1\r\ncoreClock: 1.7715GHz coreCount: 15 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 238.66GiB/s\r\n2020-06-08 12:52:05.305510: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\r\n2020-06-08 12:52:05.305552: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\r\n2020-06-08 12:52:05.305590: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\r\n2020-06-08 12:52:05.305617: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\r\n2020-06-08 12:52:05.305649: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\r\n2020-06-08 12:52:05.305686: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\r\n2020-06-08 12:52:05.305721: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2020-06-08 12:52:05.306950: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\r\n2020-06-08 12:52:05.306975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-06-08 12:52:05.306983: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 \r\n2020-06-08 12:52:05.306988: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N \r\n2020-06-08 12:52:05.308211: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:worker/replica:0/task:1/device:GPU:0 with 6927 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:05:00.0, compute capability: 6.1)\r\n2020-06-08 12:52:05.314693: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:300] Initialize GrpcChannelCache for job chief -> {0 -> nspo-rice-chief-0.kubeflow.svc:2222}\r\n2020-06-08 12:52:05.314716: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:300] Initialize GrpcChannelCache for job worker -> {0 -> nspo-rice-worker-0.kubeflow.svc:2222, 1 -> localhost:2222}\r\n2020-06-08 12:52:05.315663: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:390] Started server with target: grpc://localhost:2222\r\nWARNING:tensorflow:`eval_fn` is not passed in. The `worker_fn` will be used if an \"evaluator\" task exists in the cluster.\r\nWARNING:tensorflow:`eval_strategy` is not passed in. No distribution strategy will be used for evaluation.\r\nWARNING:tensorflow:ModelCheckpoint callback is not provided. Workers will need to restart training if any fails.\r\n2020-06-08 12:52:16.277123: W tensorflow/core/grappler/optimizers/scoped_allocator_optimizer.cc:440] error: Internal: Complete shape not known for Adam/allreduce/CollectiveReduce_2\r\n2020-06-08 12:52:16.277150: W tensorflow/core/grappler/optimizers/scoped_allocator_optimizer.cc:1056] error: Internal: Complete shape not known for Adam/allreduce/CollectiveReduce_2\r\n2020-06-08 12:52:16.277227: E tensorflow/core/grappler/optimizers/scoped_allocator_optimizer.cc:1073] ScopedAllocatorOptimizer: Internal: Complete shape not known for Adam/allreduce/CollectiveReduce_2\r\n2020-06-08 12:52:16.277234: W tensorflow/core/grappler/optimizers/scoped_allocator_optimizer.cc:846] error: Internal: Complete shape not known for Adam/allreduce/CollectiveReduce_2\r\n2020-06-08 12:52:16.277886: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] scoped_allocator_optimizer failed: Internal: Complete shape not known for Adam/allreduce/CollectiveReduce_2\r\n2020-06-08 12:52:16.672402: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\r\nTensorFlow version:  2.1.0\r\nTF_CONFIG %s {\"cluster\":{\"chief\":[\"nspo-rice-chief-0.kubeflow.svc:2222\"],\"worker\":[\"nspo-rice-worker-0.kubeflow.svc:2222\",\"nspo-rice-worker-1.kubeflow.svc:2222\"]},\"task\":{\"type\":\"worker\",\"index\":1},\"environment\":\"cloud\"}\r\ncluster={} job_name={} task_index={}} {'chief': ['nspo-rice-chief-0.kubeflow.svc:2222'], 'worker': ['nspo-rice-worker-0.kubeflow.svc:2222', 'nspo-rice-worker-1.kubeflow.svc:2222']} worker 1\r\nNumber of devices: 3\r\ndata0: (1760157, 14)\r\ndata1: (1839843, 14)\r\n(2519999, 14, 1)\r\n(2519999, 1)\r\n(1080001, 14, 1)\r\n(1080001, 1)\r\n<class 'numpy.ndarray'>\r\n<class 'numpy.ndarray'>\r\n252\r\nModel: \"sequential\"\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\ngru (GRU)                    (None, 14, 32)            3360      \r\n_________________________________________________________________\r\ngru_1 (GRU)                  (None, 14, 64)            18816     \r\n_________________________________________________________________\r\ngru_2 (GRU)                  (None, 128)               74496     \r\n_________________________________________________________________\r\nbatch_normalization (BatchNo (None, 128)               512       \r\n_________________________________________________________________\r\ndense (Dense)                (None, 1)                 129       \r\n=================================================================\r\nTotal params: 97,313\r\nTrainable params: 97,057\r\nNon-trainable params: 256\r\n_________________________________________________________________\r\nTrain for 252 steps\r\nEpoch 1/30\r\n252/252 [==============================] - 53s 209ms/step - loss: 0.1431 - acc: 0.8200\r\nEpoch 2/30\r\n252/252 [==============================] - 38s 149ms/step - loss: 0.0953 - acc: 0.8733\r\nEpoch 3/30\r\n252/252 [==============================] - 38s 149ms/step - loss: 0.0890 - acc: 0.8798\r\n````", "comments": ["@LearnKen confirming you are trying to train across multiple machines, correct? Can you share your TF-CONFIG environment variable? ", "Yes different meachine\r\nthis is my TF_CONFIG log\r\n```\r\nTF_CONFIG %s {\"cluster\":{\"chief\":[\"nspo-rice-chief-0.kubeflow.svc:2222\"],\"worker\":[\"nspo-rice-worker-0.kubeflow.svc:2222\",\"nspo-rice-worker-1.kubeflow.svc:2222\"]},\"task\":{\"type\":\"worker\",\"index\":1},\"environment\":\"cloud\"}\r\n```\r\nIs that right?", "@LearnKen\r\nIs this still an issue.", "@Saduf2019  YES\r\n", "I don't see obvious sign that only one GPU is being utilized. It might be a matter of performance (MultiWorkerMirroredStrategy is still experimental and one may not get ideal performance out of the box). Can you try changing communication from RING to NCCL? Also, can you try a newer version of TF?", "If you are able to get multiple GPUs on one machine, it is worth trying out MirroredStrategy and see what performance number we can get.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40277\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40277\">No</a>\n"]}, {"number": 40276, "title": "TensorArray concat() throws _FallbackException", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.2.0\r\n- Python version: 3.7.5\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10.1/ 7.6.5\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\n- For a image classification challenge, i need to save the predictions with the corresponding filenames to a json-file. In this example this is simply replaced by an manual added index, because fashion_mnist doesn't contain filenames.\r\n- As the dataset is batched, at the end of the prediction, it is necessary to flatten the TensorArray via the concat()-Function after all samples in the testset have been processed.  \r\n- If i run this code without @tf.function by setting tf.config.experimental_run_functions_eagerly(True), the issue won't happen.\r\n- If i run the code with the @tf.function annotator, the error below is thrown. \r\n- Error occurs with tf-gpu 2.1.0 as well as with tf-gpu 2.2.0\r\n\r\n**Describe the expected behavior**\r\nThe concat-Function should work like without the @tf.function annotator.\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n[Link to colab notebook](https://github.com/MilimaBwana/Issues/blob/master/TFFunction_Issue.ipynb)\r\n\r\n```python\r\nimport tensorflow as tf\r\nfrom pathlib import Path\r\nimport json\r\nimport keras\r\nimport numpy as np\r\nimport os\r\n\r\n\r\nclass JSONLogger:\r\n\r\n    def __init__(self, model, directory):\r\n        self.model = model\r\n        self.directory = directory\r\n        Path(directory).mkdir(parents=True, exist_ok=True)\r\n\r\n        self.idx_list = tf.TensorArray(tf.int32, size=0, dynamic_size=True, clear_after_read=False)\r\n        self.predictions_list = tf.TensorArray(tf.int64, size=0, dynamic_size=True, clear_after_read=False)\r\n        self.index = 0\r\n\r\n    def on_batch_predict_end(self, indices, predictions):\r\n        self.idx_list = self.idx_list.write(self.index, indices)\r\n        self.predictions_list = self.predictions_list.write(self.index, predictions)\r\n        self.index += 1\r\n\r\n    def on_predict_end(self):\r\n        indices = self.idx_list.concat() # Error gets thrown here\r\n        predictions_list = self.predictions_list.concat()\r\n        helper_list = []\r\n\r\n        for index, prediction in zip(indices.numpy(),\r\n                                     predictions_list.numpy()):\r\n            tmp_dict = {'Index': str(index), 'Class': str(prediction)}\r\n            helper_list.append(tmp_dict)\r\n        \r\n        with open(self.directory + '/predictions.json', 'w') as file:\r\n            json.dump(helper_list, file)\r\n\r\n\r\nclass fashion_model(tf.keras.Model):\r\n    def __init__(self):\r\n        super(fashion_model, self).__init__()\r\n        self.optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\r\n        self.flatten = tf.keras.layers.Flatten(data_format='channels_last')\r\n        self.dense1 = tf.keras.layers.Dense(units=128, input_shape=(28 * 28,), activation='relu')\r\n        self.out_layer = tf.keras.layers.Dense(units=10)\r\n\r\n        self.loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\r\n            from_logits=True,\r\n            reduction=tf.keras.losses.Reduction.SUM_OVER_BATCH_SIZE)\r\n\r\n        self.train_loss = tf.keras.metrics.Mean('train_loss')\r\n\r\n    def call(self, inputs, training=None, mask=None):\r\n        x = self.flatten(inputs)\r\n        x = self.dense1(x)\r\n        x = self.out_layer(x)\r\n        return x\r\n\r\n\r\n@tf.function\r\ndef train_step(model, sample):\r\n    images, labels, _ = sample\r\n\r\n    with tf.GradientTape() as tape:\r\n        logits = model(images, training=True)\r\n        loss = model.loss_object(y_pred=logits, y_true=labels)\r\n\r\n    gradients = tape.gradient(loss, model.trainable_variables)\r\n    model.optimizer.apply_gradients(grads_and_vars=zip(gradients, model.trainable_variables))\r\n\r\n    model.train_loss(loss)\r\n\r\n\r\n@tf.function\r\ndef predict_step(model, sample, logger):\r\n    images, labels, indices = sample\r\n    logits = model(images, training=False)\r\n    logger.on_batch_predict_end(indices, tf.argmax(logits, axis=-1))\r\n\r\n\r\ndef tf_run(run_eagerly=False):\r\n    # pip install ..  only works on colab\r\n    !pip install tensorflow-gpu==2.2.0\r\n    print('TFVersion: ', tf.__version__)\r\n    print('Run eagerly', run_eagerly)\r\n    if run_eagerly:\r\n        tf.config.experimental_run_functions_eagerly(True)\r\n\r\n    fashion_mnist = keras.datasets.fashion_mnist\r\n\r\n    (train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\r\n\r\n    class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\r\n                   'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\r\n    train_idx = np.arange(len(train_labels), dtype=np.int32)\r\n    train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels, train_idx))\r\n    train_dataset.shuffle(5000)\r\n    train_dataset = train_dataset.batch(32, drop_remainder=True)\r\n\r\n    test_idx = np.arange(len(test_labels), dtype=np.int32)\r\n    test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels, test_idx))\r\n    test_dataset = test_dataset.batch(32, drop_remainder=True)\r\n    model = fashion_model()\r\n    logger = JSONLogger(model, os.getcwd())\r\n    print('Path', os.getcwd())\r\n\r\n    for epoch in range(1, 3):\r\n\r\n        for sample in train_dataset:\r\n            train_step(model, sample)\r\n\r\n        template = 'Epoch {}, Loss: {}'\r\n        print(template.format(epoch,\r\n                              model.train_loss.result()))\r\n\r\n        model.train_loss.reset_states()\r\n\r\n    for sample in test_dataset:\r\n        predict_step(model, sample, logger)\r\n\r\n    logger.on_predict_end()\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    tf_run(False)\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n```python\r\n_FallbackException                        Traceback (most recent call last)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py in identity(input, name)\r\n   3888         _ctx._context_handle, tld.device_name, \"Identity\", name,\r\n-> 3889         tld.op_callbacks, input)\r\n   3890       return _result\r\n\r\n_FallbackException: This function does not handle the case of the path where all inputs are not already EagerTensors.\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTypeError                                 Traceback (most recent call last)\r\n\r\n12 frames\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\r\n     58     ctx.ensure_initialized()\r\n     59     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\n---> 60                                         inputs, attrs, num_outputs)\r\n     61   except core._NotOkStatusException as e:\r\n     62     if name is not None:\r\n\r\nTypeError: An op outside of the function building code is being passed\r\na \"Graph\" tensor. It is possible to have Graph tensors\r\nleak out of the function building context by including a\r\ntf.init_scope in your function building code.\r\nFor example, the following function will fail:\r\n  @tf.function\r\n  def has_init_scope():\r\n    my_constant = tf.constant(1.)\r\n    with tf.init_scope():\r\n      added = my_constant * 2\r\nThe graph tensor has name: sample_2:0\r\n```\r\n\r\n", "comments": ["I have tried in colab with TF version 2.2, nightly versions and was able to reproduce the issue.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/f2033c65dbfcc13578d16b17b68d52b2/untitled967.ipynb).Thanks!", "Hi @MilimaBwana, this error has been reported before. There's no fix currently, but I can update this thread when a change has been made. Essentially the issue you're facing has to do with trying to pass in a TensorArray created outside in eager mode to a tf.function. This is currently unsupported due to somewhat inconsistent behavior of TensorArrays in graph and eager mode.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40276\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40276\">No</a>\n"]}, {"number": 40275, "title": "Import error : dll load failed Tensorflow 2.0 version", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1.  It must be a bug, a feature request, or a significant problem with the\r\n    documentation (for small docs fixes please send a PR instead).\r\n2.  The form below must be filled out.\r\n3.  It shouldn't be a TensorBoard issue. Those go\r\n    [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n\r\n-   **Have I written custom code (as opposed to using a stock example script\r\n    provided in TensorFlow)**:\r\n-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue\r\n    happens on a mobile device**:\r\n-   **TensorFlow installed from (source or binary)**:\r\n-   **TensorFlow version (use command below)**:\r\n-   **Python version**:\r\n-   **Bazel version (if compiling from source)**:\r\n-   **GCC/Compiler version (if compiling from source)**:\r\n-   **CUDA/cuDNN version**:\r\n-   **GPU model and memory**:\r\n-   **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with:\r\n\r\n```bash\r\npython -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"\r\n```\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["@Samgithub1997,\r\nPlease fill in the issue template along with the complete error log and the TensorFlow version you are using. \r\n\r\nAlso, please take a look at [this similar issue](https://github.com/tensorflow/tensorflow/issues/36167#issuecomment-577886156) and let us know if it helps. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40275\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40275\">No</a>\n"]}, {"number": 40274, "title": "TFLu: Port TFL detection postprocess operator", "body": "", "comments": ["@njeffrie Right, it is done.", "@njeffrie I realized that the output dimension handling needed an update.", "@mansnils can you please check below errors as well \r\n\r\n`tensorflow/lite/micro/kernels/detection_postprocess.cc:18:10: error: module ///tensorflow/lite/micro/kernels:micro_ops does not depend on a module exporting '/flatbuffers/include/flatbuffers/flexbuffers.h'\r\n\r\nbuild_cleaner ///tensorflow/lite/micro/kernels:micro_ops\r\n#include \"/flatbuffers/include/flatbuffers/flexbuffers.h\"\r\n         ^/tensorflow/lite/micro/kernels/detection_postprocess.cc:859:66: error: missing field 'profiling_string' initializer [-Werror,-Wmissing-field-initializers]\r\n      detection_postprocess::Prepare, detection_postprocess::Eval};`", "@rthadur build errors and review comments resolved", "@mansnils Can you please check @rthadur's comments and keep us posted ? Thanks!", "@mansnils, Any update on this PR? Please. Thanks!\r\n", "@rthadur Comment and conflicts resolved.", "```\r\ntensorflow/lite/micro/kernels/detection_postprocess.cc:288:20: error: unknown type name 'uint8'; did you mean 'uint'?\r\n  float operator()(uint8 x) \r\n\r\nthird_party/tensorflow/lite/micro/kernels/detection_postprocess.cc:301:9: error: unknown type name 'uint8'; did you mean 'uint'\r\n\r\nthird_party/tensorflow/lite/micro/kernels/detection_postprocess.cc:302:21: error: unknown type name 'uint8'; did you mean 'uint'\r\n\r\nthird_party/tensorflow/lite/micro/kernels/detection_postprocess.cc:746:9: error: unknown type name 'uint8'; did you mean 'uint'\r\n\r\nthird_party/tensorflow/lite/micro/kernels/detection_postprocess.cc:746:45: error: unknown type name 'uint8'; did you mean 'uint'\r\n```\r\n\r\n@mansnils can you please check this errors ?", "@rthadur errors resolved.", "@mansnils can you please check below errors \r\n\r\n```\r\n/tensorflow/lite/micro/kernels/detection_postprocess_test.cc:19:10: error: module ///tensorflow/lite/micro/kernels:detection_postprocess_test_binary does not depend on a module exporting '/tensorflow/lite/micro/all_ops_resolver.h'\r\nbuild_cleaner ///tensorflow/lite/micro/kernels:detection_postprocess_test_binary\r\n#include \"third_party/tensorflow/lite/micro/all_ops_resolver.h\"\r\n         ^\r\n/tensorflow/lite/micro/kernels/detection_postprocess_test.cc:125:17: error: unused variable 'input_scale2' \r\n    const float input_scale2 = ScaleFromMinMax<uint8_t>(input_min2, input_max2);\r\n                ^\r\n/tensorflow/lite/micro/kernels/detection_postprocess_test.cc:263:13: error: unused variable 'kInputElements2' \r\n  const int kInputElements2 = tflite::testing::kInputShape2[1] *\r\n            ^\r\n/tensorflow/lite/micro/kernels/detection_postprocess_test.cc:266:13: error: unused variable 'kInputElements3' \r\n  const int kInputElements3 =\r\n            ^\r\n/tensorflow/lite/micro/kernels/detection_postprocess_test.cc:319:13: error: unused variable 'kInputElements2' \r\n  const int kInputElements2 = tflite::testing::kInputShape2[1] *\r\n            ^\r\n/tensorflow/lite/micro/kernels/detection_postprocess_test.cc:322:13: error: unused variable 'kInputElements3'\r\n  const int kInputElements3 =\r\n            ^\r\n/tensorflow/lite/micro/kernels/detection_postprocess_test.cc:470:13: error: unused variable 'kInputElements3' \r\n  const int kInputElements3 =\r\n            ^\r\n/tensorflow/lite/micro/kernels/detection_postprocess_test.cc:467:13: error: unused variable 'kInputElements2'\r\n  const int kInputElements2 = tflite::testing::kInputShape2[1] *\r\n```", "@rthadur errors resolved", "Apologies for the repeated back-and-forth M\u00e5ns - we have an internal version of this CL now and there are a few more things we will need before we can land this:\r\n\r\n- We recently switched to TfLiteEvalTensor instead of TfLiteTensor during invoke stage.  Init and prepare can still use the TfLiteTensor, but they are de-allocated at invoke for significant memory savings. See https://github.com/tensorflow/tensorflow/commit/88461053262f02bbc15887daa172c02db7419780 for how we ported the cmsis-nn kernels over to this new kernel API.\r\n\r\n- It seems like there are some unused variables which are causing compiler errors. Can you try to compile with -Werror=unused-variable?\r\n\r\nI left a few inline comments on the change as well.\r\n\r\nThanks and sorry again for the repeated back-and-forth.\r\n", "@njeffrie Thanks for the comments. I added -Wunused-variable and -Werror but could not find any more unused variables. I also manually added an unused variable to provoke an error to see that the -W options was getting through.\r\n", "@njeffrie Updated after comments.", "@rthadur gentle ping for merge", "@mansnils thanks for your patience , still in progress merging internally , will keep you updated ..!", "@rthadur still merging internally?", "yes, @njeffrie has been working on merging this internally , @njeffrie gentle ping for update ?"]}, {"number": 40273, "title": "Shuffle buffer filled", "body": "I am getting the following logging:\r\n\r\n```\r\n2020-06-08 06:09:37.995077: I tensorflow/core/kernels/shuffle_dataset_op.cc:112] Filling up shuffle buffer (this may take a while): 59921 of 64000\r\n\r\n2020-06-08 06:09:38.725673: I tensorflow/core/kernels/shuffle_dataset_op.cc:126] Shuffle buffer filled.\r\n````\r\n\r\nWhat does it mean?", "comments": ["@nashid \r\nPlease provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\nMake sure you also include the exact command if possible to produce the output included in your test case. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new).\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!\r\n", "Please find details:\r\n\r\n```\r\n-   **Have I written custom code (as opposed to using a stock example script\r\n    provided in TensorFlow)**: used the default example from https://github.com/tensorflow/nmt\r\n\r\n-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: RHEL 6\r\n\r\n-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue\r\n    happens on a mobile device**: NA\r\n\r\n-   **TensorFlow installed from (source or binary)**: using pip install tensorflow\r\n\r\n-   **TensorFlow version (use command below)**: 1.5.0\r\n\r\n-   **Python version**: 3.6.10\r\n-   **Bazel version (if compiling from source)**: N/A\r\n-   **GCC/Compiler version (if compiling from source)**: N/A\r\n-   **CUDA/cuDNN version**: N/A\r\n-   **GPU model and memory**: N/A\r\n```\r\n\r\n", "@nashid \r\nPlease refer to these link with similar error:\r\n\r\n[link](https://github.com/beringresearch/ivis/issues/56#issuecomment-571191817)\r\n[link1](https://stackoverflow.com/questions/51366082/tensorflow-get-high-loss-after-filling-up-shuffle-buffer)\r\n[link2](https://forum.opennmt.net/t/tensorflow-error-with-training-command/3290/2)\r\n\r\nPlease update details on the version on tensorflow used and the exact steps or code before which this log is faced.\r\n\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "In the code below, where do I change the font of the bounding box label?\r\n\r\n\"vis_util.visualize_boxes_and_labels_on_image_array(\r\n      image_np,\r\n      output_dict['detection_boxes'],\r\n      output_dict['detection_classes'],\r\n      output_dict['detection_scores'],\r\n      category_index,\r\n      instance_masks=output_dict.get('detection_masks'),\r\n      use_normalized_coordinates=True,\r\n      line_thickness=8)\r\n  plt.figure(figsize=IMAGE_SIZE)\r\n  plt.imshow(image_np)\"", "@BAParanjape \r\nKindly open a stackoverflow issue for this as it is not a bug or feature request, Please post this kind of support questions at Stackoverflow. There is a big community to support and learn from your questions.\r\nThanks!"]}, {"number": 40272, "title": "Bazel build option \"--config=v1\" does not build Tensorflow 1.x", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- Linux Ubuntu 18.04:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 2.2.0\r\n- Python version: 3.6.9\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source): 2.0.0\r\n- GCC/Compiler version (if compiling from source): 7.5.0\r\n- CUDA/cuDNN version: 10.2/7.6.5\r\n- GPU model and memory: GeForce RTX 2080 SUPER 8GB\r\n\r\n\r\n**Describe the problem**\r\n\r\nWhen trying to build the v1.x form the v2.2.0, the actual version built is not 1.x, but 2.2.0.\r\n\r\nHere are the steps I took:\r\n```\r\n$ ./configure\r\nYou have bazel 2.0.0 installed.\r\nPlease specify the location of python. [Default is /usr/bin/python]: /usr/bin/python3\r\n\r\n\r\nFound possible Python library paths:\r\n  /usr/lib/python3/dist-packages\r\n  /usr/local/lib/python3.6/dist-packages\r\nPlease input the desired Python library path to use.  Default is [/usr/lib/python3/dist-packages]\r\n \r\nDo you wish to build TensorFlow with OpenCL SYCL support? [y/N]: \r\nNo OpenCL SYCL support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with ROCm support? [y/N]: \r\nNo ROCm support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with CUDA support? [y/N]: y\r\nCUDA support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with TensorRT support? [y/N]: \r\nNo TensorRT support will be enabled for TensorFlow.\r\n\r\nFound CUDA 10.2 in:\r\n    /usr/local/cuda/lib64\r\n    /usr/local/cuda/include\r\nFound cuDNN 7 in:\r\n    /usr/lib/x86_64-linux-gnu\r\n    /usr/include\r\n\r\n\r\nPlease specify a list of comma-separated CUDA compute capabilities you want to build with.\r\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\r\nPlease note that each additional compute capability significantly increases your build time and binary size, and that TensorFlow only supports compute capabilities >= 3.5 [Default is: 7.5]: \r\n\r\n\r\nDo you want to use clang as CUDA compiler? [y/N]: \r\nnvcc will be used as CUDA compiler.\r\n\r\nPlease specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: \r\n\r\n\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native -Wno-sign-compare]: \r\n\r\n\r\nWould you like to interactively configure ./WORKSPACE for Android builds? [y/N]: \r\nNot configuring the WORKSPACE for Android builds.\r\n\r\nPreconfigured Bazel build configs. You can use any of the below by adding \"--config=<>\" to your build command. See .bazelrc for more details.\r\n\t--config=mkl         \t# Build with MKL support.\r\n\t--config=monolithic  \t# Config for mostly static monolithic build.\r\n\t--config=ngraph      \t# Build with Intel nGraph support.\r\n\t--config=numa        \t# Build with NUMA support.\r\n\t--config=dynamic_kernels\t# (Experimental) Build kernels into separate shared objects.\r\n\t--config=v2          \t# Build TensorFlow 2.x instead of 1.x.\r\nPreconfigured Bazel build configs to DISABLE default on features:\r\n\t--config=noaws       \t# Disable AWS S3 filesystem support.\r\n\t--config=nogcp       \t# Disable GCP support.\r\n\t--config=nohdfs      \t# Disable HDFS support.\r\n\t--config=nonccl      \t# Disable NVIDIA NCCL support.\r\nConfiguration finished\r\n\r\n\r\n$ bazel build --jobs 12 --config=opt --config=cuda --config=v1 //tensorflow/tools/pip_package:build_pip_package\r\n\r\n$ ./bazel-bin/tensorflow/tools/pip_package/build_pip_package path-to-package/\r\n\r\n$ pip3 install path-to-package/tensorflow-2.2.0-cp36-cp36m-linux_x86_64.whl\r\n\r\n$ python3 -c \"import tensorflow as tf; print(tf.__version__)\"\r\n2.2.0\r\n```\r\n\r\nMy expectation is that when I pass \"--config=v1\" I would get Tensorflow 1.x built, not 2.2.0.", "comments": ["`--config=v1` only enables V1 APIs and behavior, does not change version number constant.\r\n\r\nIf you want to build TF v1, recommendation is to start from `r1.15` branch", "@sogartar \r\n\r\nAny update on this issue please? \r\nPlease,,close this thread if your issue was resolved.Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40272\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40272\">No</a>\n"]}, {"number": 40271, "title": "Update pywrap_tensorflow.py", "body": "indentation correction", "comments": ["@yoosoomin Can you please check @av8ramit's comments and keep us posted. Thanks!", "I check it thank you !"]}, {"number": 40270, "title": "TfLite Sign Op Support", "body": "How long will the sign op be surpported? Or would you please provide some suggestions for implementing a tflite custom op using eigen lib as tf sign op.", "comments": ["You can use tf sign with Flex delegate.\r\nhttps://www.tensorflow.org/lite/guide/ops_select\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/delegates/flex/whitelisted_flex_ops.cc#L369\r\n\r\nFor custom operator implementation, plz check https://www.tensorflow.org/lite/guide/ops_custom\r\n\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 40269, "title": "CMSIS-NN wrapper update for interface changes", "body": "Background: CMSIS-NN int8  APIs are changed\r\nwhere the pass by value function arguments\r\nare replaced by pass by reference struct\r\narguments.\r\n\r\nThe following changes are done in TFL micro\r\n\r\n1. Update int8 cmsis-nn's depthwise conv,\r\n   fully connected and average pooling\r\n   wrapper files to use the new  interface.\r\n\r\n2. For the above mentioned operators,\r\n   updates from the reference implementation\r\n   (e.g, CalculateOpData() in Prepare() instead\r\n   of Eval()) are ported as well.", "comments": ["sorry about the delete-restore cycle there! Re-based and adapted to new change in cmsis.inc where new build files have to be explicitly added.", "@njeffrie Hi Nat! Hope all is well. Could you have a look at this PR? thanks in advance :-) ", "Rebased to resolve merge conflicts.\r\n", "@njeffrie Hi Nat! Could you have a look at the changes ?", "Thanks for the reviews Nat @njeffrie !"]}, {"number": 40268, "title": "AutoGraph saved model with uint8 input will not convert to tflite", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nBoth Windows and Linux\r\n- TensorFlow installed from (source or binary):\r\nFrom binary with pip and preinstalled on colab\r\n\r\n- TensorFlow version (or github SHA if from source):\r\n'2.2.0'\r\n\r\n**Command used to run the converter or code if you\u2019re using the Python API**\r\nIf possible, please share a link to Colab/Jupyter/any notebook.\r\nhttps://colab.research.google.com/drive/1cnxZOljJUz_Z-q4MNvvm4nQaRQL5C6Pf#scrollTo=h_QP1TGd3sRa\r\n```\r\nclass Net(tf.Module):\r\n    @tf.function(input_signature=[tf.TensorSpec(shape=(1,1,3),dtype=tf.uint8)])\r\n    def process(self,image):\r\n        return image\r\n\r\ntest_exp=Net()\r\n\r\ntf.saved_model.save(test_exp,\"saved_model\")\r\n\r\nconverter_tlite=tf.lite.TFLiteConverter.from_saved_model(\"saved_model\")\r\n\r\nconverter_tlite.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]\r\n\r\nconverter_tlite.inference_input_type=tf.uint8\r\nconverter_tlite.inference_output_type=tf.uint8\r\n\r\ntest_tflite=converter_tlite.convert()\r\n```\r\n\r\n**The output from the converter invocation**\r\n\r\n```\r\nConverterError: See console for info.\r\n2020-06-08 08:52:53.152754: W tensorflow/compiler/mlir/lite/python/graphdef_to_tfl_flatbuffer.cc:89] Ignored output_format.\r\n2020-06-08 08:52:53.152800: W tensorflow/compiler/mlir/lite/python/graphdef_to_tfl_flatbuffer.cc:95] Ignored drop_control_dependency.\r\nloc(\"Func/PartitionedCall/input/_0\"): error: requires all operands to be either same as or ref type of results\r\nTraceback (most recent call last):\r\n  File \"/usr/local/bin/toco_from_protos\", line 8, in <module>\r\n    sys.exit(main())\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 93, in main\r\n    app.run(main=execute, argv=[sys.argv[0]] + unparsed)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/platform/app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"/usr/local/lib/python2.7/dist-packages/absl/app.py\", line 300, in run\r\n    _run_main(main, args)\r\n  File \"/usr/local/lib/python2.7/dist-packages/absl/app.py\", line 251, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 56, in execute\r\n    enable_mlir_converter)\r\nException: <unknown>:0: error: loc(\"Func/PartitionedCall/input/_0\"): requires all operands to be either same as or ref type of results\r\n```\r\n\r\n**Failure details**\r\nThe graph will not convert to tflite. See error above\r\n\r\n\r\n**Any other info / logs**\r\n\r\nReproducible in Colab. Graph with float32 input works fine", "comments": ["I am able to replicate this issue, please find the [gist here](https://colab.sandbox.google.com/gist/Saduf2019/f11a683353239f85a7b33e98b8d9a7ee/untitled216.ipynb)", "Seeing same error, with tf-nightly 2.3.0.dev20200613, it says:\r\n```\r\nsee current operation: %1 = \"tf.Identity\"(%arg0) {device = \"\"} : (tensor<?x?x?x3x!tf.quint8>) -> tensor<?x?x?x3xui8>\r\n```", "SAME as above:\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \".\\lite-con.py\", line 8, in <module>\r\n    tflite_model = converter.convert()\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py\", line 1076, in convert\r\n    return super(TFLiteConverterV2, self).convert()\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py\", line 899, in convert\r\n    return super(TFLiteFrozenGraphConverterV2,\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py\", line 629, in convert\r\n    result = _toco_convert_impl(\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py\", line 569, in toco_convert_impl\r\n    data = toco_convert_protos(\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py\", line 202, in toco_convert_protos\r\n    raise ConverterError(str(e))\r\ntensorflow.lite.python.convert.ConverterError: <unknown>:0: error: loc(\"Func/StatefulPartitionedCall/input/_0\"): requires all operands and results to have compatible element types\r\n<unknown>:0: note: loc(\"Func/StatefulPartitionedCall/input/_0\"): see current operation: %1 = \"tf.Identity\"(%arg0) {device = \"\"} : (tensor<1x?x?x3x!tf.quint8>) -> tensor<1x?x?x3xui8>", "Was able to reproduce the error with `dtype = tf.uint8 `but when I changed to` tf.float32` I am not facing issue in TF 2.5 and TF-Nightly versions. Please find the gist [here](https://colab.research.google.com/gist/saikumarchalla/ec471be820d0aa6867c33f484422c053/untitled82.ipynb).Thanks!", "Hi @hegman12 ! I used a representative dataset and changed signature type to uint8 to resolve the issue. Attaching[ gist](https://colab.sandbox.google.com/gist/mohantym/1323c3e138ab62713a4b05d1e5827255/untitled82.ipynb#scrollTo=yjiYrreF5Kt6) for [reference](https://www.tensorflow.org/lite/performance/post_training_integer_quant#convert_using_integer-only_quantization).", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40268\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40268\">No</a>\n"]}, {"number": 40267, "title": "Keras layer on TPU, Cannot assign a device for operation RandomUniform", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: None\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): 2.2.0, v2.2.0-rc4-8-g2b96f3662b\r\n- Python version: 3.6.9\r\n- Bazel version (if compiling from source): None\r\n- GCC/Compiler version (if compiling from source): None\r\n- CUDA/cuDNN version: None\r\n- GPU model and memory: TPU\r\n\r\n**Describe the current behavior**\r\n\r\nI'm trying to use the `tf.keras.layers.Dense` layer on TPU.\r\nI get the exception `InvalidArgumentError: Cannot assign a device for operation encoder/kernel/Initializer/random_uniform/RandomUniform: Could not satisfy explicit device specification '' because the node {{colocation_node encoder/kernel/Initializer/random_uniform/RandomUniform}} was colocated with a group of nodes that required incompatible device '/device:TPU:0'. All available devices [/job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:XLA_CPU:0].`.\r\n\r\n**Describe the expected behavior**\r\n\r\nI would expect that this works.\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n```\r\nimport os\r\nimport tensorflow as tf\r\nimport numpy\r\n\r\n# https://www.tensorflow.org/guide/tpu\r\nif os.environ.get('COLAB_TPU_ADDR', \"\"):\r\n  resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\r\n  tf.config.experimental_connect_to_cluster(resolver)\r\n  # This is the TPU initialization code that has to be at the beginning.\r\n  tf.tpu.experimental.initialize_tpu_system(resolver)\r\n\r\ntf.compat.v1.disable_v2_behavior()\r\ntf.compat.v1.reset_default_graph()\r\n\r\nwith tf.device(\"/TPU:0\"):\r\n  x = tf.compat.v1.placeholder(tf.float32, shape=(3, 4, 2), name=\"x\")\r\n  encoder = tf.keras.layers.Dense(units=5, activation=\"tanh\", name=\"encoder\")(x)\r\n\r\n  vars_init_op = tf.compat.v1.global_variables_initializer()\r\n\r\nrnd = numpy.random.RandomState(42)\r\nx_np = rnd.normal(size=(3, 4, 2))\r\n\r\nwith tf.compat.v1.Session() as session:\r\n  session.run(vars_init_op)\r\n  session.run(encoder, feed_dict={x: x_np})\r\n\r\n```\r\n\r\n[Colab](https://colab.research.google.com/drive/1WTzn71tXYWeyyDxqFwXxblnDhZtxAbQX?usp=sharing).\r\n\r\n**Other info / logs**\r\n\r\n```\r\nInvalidArgumentError: Cannot assign a device for operation encoder/kernel/Initializer/random_uniform/RandomUniform: Could not satisfy explicit device specification '' because the node {{colocation_node encoder/kernel/Initializer/random_uniform/RandomUniform}} was colocated with a group of nodes that required incompatible device '/device:TPU:0'. All available devices [/job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:XLA_CPU:0]. \r\nColocation Debug Info:\r\nColocation group had the following types and supported devices: \r\nRoot Member(assigned_device_name_index_=-1 requested_device_name_='/device:TPU:0' assigned_device_name_='' resource_device_name_='/device:TPU:0' supported_device_types_=[CPU, XLA_CPU] possible_devices_=[]\r\nAssignVariableOp: CPU XLA_CPU \r\nRandomUniform: CPU XLA_CPU \r\nVarIsInitializedOp: CPU XLA_CPU \r\nConst: CPU XLA_CPU \r\nMul: CPU XLA_CPU \r\nReadVariableOp: CPU XLA_CPU \r\nSub: CPU XLA_CPU \r\nVarHandleOp: CPU XLA_CPU \r\nAdd: CPU XLA_CPU \r\n\r\nColocation members, user-requested devices, and framework assigned devices, if any:\r\n  encoder/kernel/Initializer/random_uniform/shape (Const) \r\n  encoder/kernel/Initializer/random_uniform/min (Const) \r\n  encoder/kernel/Initializer/random_uniform/max (Const) \r\n  encoder/kernel/Initializer/random_uniform/RandomUniform (RandomUniform) \r\n  encoder/kernel/Initializer/random_uniform/sub (Sub) \r\n  encoder/kernel/Initializer/random_uniform/mul (Mul) \r\n  encoder/kernel/Initializer/random_uniform (Add) \r\n  encoder/kernel (VarHandleOp) /device:TPU:0\r\n  encoder/kernel/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /device:TPU:0\r\n  encoder/kernel/Assign (AssignVariableOp) /device:TPU:0\r\n  encoder/kernel/Read/ReadVariableOp (ReadVariableOp) /device:TPU:0\r\n  encoder/Tensordot/ReadVariableOp (ReadVariableOp) \r\n\r\n\t [[{{node encoder/kernel/Initializer/random_uniform/RandomUniform}}]]\r\n```\r\n\r\nMaybe #31318 is related?\r\n", "comments": ["I have tried in colab with TFversion 2.2, nightly version(`2.3.0-dev20200605`) .Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/5f37166e7ea2ee16949175caab8ae467/untitled965.ipynb).Is this the expected behavior?.Thanks!", "What do you mean by expected? I expect that my code runs without error. But you have reproduced exactly the error I was reporting (for TF 2.2.0).\r\nFor nightly TF 2.3, you get another error. Which also looks strange and wrong. But this might be a different problem or bug? Or the same? Or related? I don't know.", "Hi @albertz, the tf-nightly error is unrelated and explained in this comment here:  https://github.com/tensorflow/tensorflow/issues/40622#issuecomment-654488935\r\n\r\nAs for the error you've reported, it seems that initializing the variables is what's causing the problem since it says\r\n`Cannot assign a device for operation encoder/kernel/Initializer/random_uniform/RandomUniform`\r\nGiven that the message also says `supported_device_types_=[CPU, XLA_CPU]` then the TPU implementation does not exist for RandomUniform. If you set allow_soft_placement, your code will run:\r\n\r\n`sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(allow_soft_placement=True, log_device_placement=True))`\r\n\r\nNote that since you're using legacy TF 1  code, your code is prone to running into more errors and unsupported features like this. Switching to TF2 should allow you to run the computation for your encoder on the TPU, as I think it's the use of the placeholder that's causing the problem.\r\n", "Yes, I think the error is clear. But I would still expect that this code works, or not? This is sth which can (and should) be fixed on the TF side. You can e.g. implement `RandomUniform` for TPU. Or some extra logic in `tf.keras.layers.Dense` which would use `with tf.device(\"/CPU:0\"):` for the initializers.\r\n\r\nAlso, I really prefer the non-eager mode, and explicit sessions.\r\n\r\nBut why does that even matter? `tf.function` would use `allow_soft_placement=True` by default? Is this a good idea?\r\n", "There's better support and testing when using TF2 with TPUs without disabling v2 behavior. In TF2, variables are initialized automatically both in eager and graph contexts.\r\n\r\nThe following should be equivalent TF2 code. If you set `tf.debugging.set_log_device_placement(True)` you'll see that TPU is being used for all computation\r\n\r\n```\r\n@tf.function\r\ndef encoder_fn(x,encoder):\r\n    return encoder(x)\r\n\r\nwith tf.device(\"/TPU:0\"):\r\n  rnd = numpy.random.RandomState(42)\r\n  x_np = rnd.normal(size=(3, 4, 2))\r\n  x_np = tf.constant(x_np, dtype=tf.float32)\r\n  encoder = tf.keras.layers.Dense(units=5, activation=\"tanh\", name=\"encoder\")\r\n  encoder_fn(x_np, encoder)\r\n```\r\n\r\nYou'll notice that with `tf.debugging.set_log_device_placement(True)` the first line of the logs show\r\n`Executing op RandomUniform on task /job:worker/replica:0/task:0/device:TPU:0`\r\nSo looks like RandomUniform is being executed on the TPU. I think the problem you're running into is just from trying to use TPUs with TF2 and disabling v2 behavior.\r\n\r\n", "How can `RandomUniform` be calculated on TPU, if the op doesn't support TPU for computation? This is independent from which behavior is enabled/disabled, right?\r\n", "I don't think it's independent since variable initialization has different behavior in TF1 and TF2. For example, Keras and TPUStrategy work best with eager execution enables as noted in issue #38506.", "I'm just speaking about the `RandomUniform` op, not about variable initialization. Whether this op can be executed on TPU or not does not depend on the enabled behavior.", "Hi There,\n\n This is a stale issue. As you are using an older version of tensorflow, we are checking to see if you still need help on this issue. Please test the issue with the latest TensorFlow (TF2.7 and tf-nightly). If the issue still persists with the newer versions of TF, please feel free to open it in [keras-team/keras](https://github.com/keras-team/keras/issues) repository by providing details about the issue and a standalone code to reproduce the issue. Thanks! \n\n Please note that Keras development has moved to a separate Keras-team/keras repository to focus entirely on only Keras. Thanks! ", "The same problem is still there in TF 2.7.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40267\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40267\">No</a>\n", "@nikitamaia Why was this closed? There is no solution."]}, {"number": 40266, "title": "Unexpected rise in inference time after quantization", "body": "<em>Please make sure that this is an issue related to performance of TensorFlow.\r\nAs per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:performance_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 and Colab\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): 1.15.0 ,2.2.0, 2.2.0-dev20200508 for QAT\r\n- Python version: 3.6.5\r\n- GPU model and memory: using CPU\r\n\r\n**Describe the current behavior**\r\nThe inference time of TF-Lite model becomes extremely high after the post training integer quantization and after Quantization Aware Training of model when using calibration dataset for static quantization.\r\nTried on various models and with different datasets on 1.15.0 and also on 2.2.0 and  2.2.0-dev20200508 for QAT\r\n\r\n**Describe the expected behavior**\r\nThe inference time of TFlite model (with post-training static quantization and after QAT) should be less or at least equal to TFLite model without quantization. \r\n\r\n**Steps and code to reproduce the issue**\r\n\r\nLinks for notebook files: \r\nhttps://drive.google.com/file/d/1XFWXp-nXhEdBuikaW3q3uJ2EmPy8fbOZ/view?usp=sharing\r\nhttps://drive.google.com/file/d/16kEu87nj-Q2gjgET6CcZUvKxJvpi6pMW/view?usp=sharing\r\n\r\nTrain keras model using the dataset.(Using california housing data)\r\n\r\ninput_size = 8 \r\n\r\nmodel = keras.Sequential()\r\nmodel.add(tf.keras.layers.Flatten())\r\nfor i in range(0,2):\r\n    model.add(tf.keras.layers.Dense(1024,activation='relu'))\r\n    \r\nmodel.add(tf.keras.layers.Dense(1))\r\n\r\nIn TF 1.15.0:\r\n----------------\r\nCreated ONNX model using h5 file of saved model using keras2onnx. (Also tried the same flow by generating ONNX model using pytorch with same model architecture)\r\nCreated '.pb' file from ONNX model. \r\nUsing  'tf.lite.TFLiteConverter.from_frozen_graph' to create TFLite model. \r\n\r\nIn TF 2.2.0:\r\n----------------\r\nUsing  'tf.lite.TFLiteConverter.from_keras_model' to create TFLite model.\r\n\r\n\r\ncase-1\r\n=======\r\nconverter = tf.lite.TFLiteConverter.from_frozen_graph(<path to .pb file>,['input_1'],['output_1'])    \r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]    \r\nconverter.representative_dataset = representative_data_gen\r\ntflite_int_model = converter.convert()\r\n\r\ncase-2\r\n=======\r\nconverter = tf.lite.TFLiteConverter.from_frozen_graph(<path to .pb file>,['input_1'],['output_1'])    \r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]    \r\nconverter.representative_dataset = representative_data_gen\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\r\nconverter.inference_input_type = tf.uint8\r\nconverter.inference_output_type = tf.uint8\r\n\r\ncase-3(QAT):\r\n=======\r\nquantize_model = tfmot.quantization.keras.quantize_model\r\nq_aware_model = quantize_model(model)\r\nq_aware_model.compile(optimizer='rmsprop',loss='mean_squared_error')\r\nq_aware_model.summary()\r\n\r\nq_aware_model.fit(x, y, batch_size=128, epochs=2, validation_split=0.2)\r\n\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\ntflite_model = converter.convert()\r\n\r\n\r\nNow loading the quantized TFLite models for inference. \r\n\r\nWithout quantization, the average inference time of TFLite model is 100 microseconds in my PC and around 200 on google colab (avg for one record when run inference for 1000 input records)\r\nIn all the cases(case1,case2 and case3 mentioned above), After quantization, the average inference time of TFLite model is around 10000 microseconds in my PC and its around 500 on colab(avg for one record when run inference for 1000 input records)\r\n\r\n\r\n", "comments": ["@syamsruthin,\r\nOn running the code, I'm facing an error stating `KeyError: \"The name 'sequential/Identity' refers to an Operation not in the graph.\"`. \r\n\r\nPlease find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/1bb99d7b7ec2c1c95254da120f170afd/40266-1-15.ipynb). Thanks!", "@amahendrakar \r\n- This is because of enabling eager execution during model creation and training. Can you please comment this \"tf.enable_eager_execution()\" and run the model training again before converting it to onnx. \r\n- tf.enable_eager_execution() is required when we are creating and during inference of static quantized tflite model. (When giving representation data set to create static quantized tflite model)\r\n- So, after creating onnx model, this option needs to be enabled before running quantization code. \r\n\r\nHope this is clear. ", "@amahendrakar  any update on this?  were you able to reproduce this issue? ", "@amahendrakar  Modified the notebook that you shared. I'm able to reproduce the error. You can find the results there in the notebook. \r\nhttps://colab.research.google.com/gist/syamsruthin/c64279c9e348b39d558b0ceba2697baa/40266-1-15.ipynb", "@syamsruthin,\r\nSorry for the delayed response. I am still unable to reproduce the issue. \r\n\r\nOn running the code, I am facing an error stating `ValueError: Invalid tensors 'input_1' were found.` Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/878b611c6dfe8bf617634647d7a8d329/40266-1-15.ipynb#scrollTo=rIs794paf4Ql). Thanks!", "@amahendrakar  Looks like a day before the library tf2onnx got updated and I guess this issue is because of this. \r\nI tried to recreate this same issue in another way. \r\nPlease find the gist of it in this link: [https://colab.research.google.com/gist/syamsruthin/f2b1307bf09542d62ebf3b15d6ae9a85/issue_40266.ipynb](url)\r\nThanks!\r\n", "@amahendrakar The Above link to the notebook is not working. Please copy-paste the link in the browser.\r\nThanks!", "@syamsruthin,\r\nThank you for providing the gist. I was able to reproduce the issue with [TF v1.15](https://colab.sandbox.google.com/gist/amahendrakar/5fcca3d3215a49166f711469c28eefab/40266-1-15.ipynb). \r\n\r\nCould you please share the `model.h5` file you are using while running the code in TF 2.x. Thanks!", "@amahendrakar  Here is the gist for creating .h5 file for tf2.2\r\nhttps://colab.research.google.com/gist/syamsruthin/3485c5e7cce5961bf45c554f38ba1ac7/issue_40266_tf_2.ipynb\r\nThanks. ", "@ymodak @amahendrakar  \r\nHi... any update on this? ", "@ymodak  @amahendrakar \r\nLooking forward to you answer !! \r\nThanks. ", "@syamsruthin Apologies for the delay in response. Is this still an issue?\r\nThe colab you shared contains incomplete code, I do not see quantization inference stats. \r\nThanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 40265, "title": "`from tensorflow import keras` errors if it's in a file named `code.py`", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): ubuntu:18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b 2.2.0 \r\n- Python version: Python 3.8.3\r\n- Bazel version (if compiling from source): N+A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\nIf you have a single line with `from tensorflow import keras` in a file called `code.py` and run `python3 code.py` you get following error: \r\n```\r\nTraceback (most recent call last):\r\n  File \"code.py\", line 1, in <module>\r\n    from tensorflow import keras\r\n  File \"/usr/local/lib/python3.8/site-packages/tensorflow/__init__.py\", line 41, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"/usr/local/lib/python3.8/site-packages/tensorflow/python/__init__.py\", line 64, in <module>\r\n    from tensorflow.python.framework.framework_lib import *  # pylint: disable=redefined-builtin\r\n  File \"/usr/local/lib/python3.8/site-packages/tensorflow/python/framework/framework_lib.py\", line 25, in <module>\r\n    from tensorflow.python.framework.ops import Graph\r\n  File \"/usr/local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\", line 64, in <module>\r\n    from tensorflow.python.platform import app\r\n  File \"/usr/local/lib/python3.8/site-packages/tensorflow/python/platform/app.py\", line 23, in <module>\r\n    from absl.app import run as _run\r\n  File \"/usr/local/lib/python3.8/site-packages/absl/app.py\", line 35, in <module>\r\n    import pdb\r\n  File \"/usr/local/lib/python3.8/pdb.py\", line 77, in <module>\r\n    import code\r\n  File \"/code.py\", line 1, in <module>\r\n    from tensorflow import keras\r\n  File \"/usr/local/lib/python3.8/site-packages/tensorflow/keras/__init__.py\", line 14, in <module>\r\n    from . import activations\r\n  File \"/usr/local/lib/python3.8/site-packages/tensorflow/keras/activations/__init__.py\", line 10, in <module>\r\n    from tensorflow.python.keras.activations import deserialize\r\n  File \"/usr/local/lib/python3.8/site-packages/tensorflow/python/keras/__init__.py\", line 27, in <module>\r\n    from tensorflow.python.keras import models\r\n  File \"/usr/local/lib/python3.8/site-packages/tensorflow/python/keras/models.py\", line 23, in <module>\r\n    from tensorflow.python.keras import backend as K\r\n  File \"/usr/local/lib/python3.8/site-packages/tensorflow/python/keras/backend.py\", line 36, in <module>\r\n    from tensorflow.python.client import session as session_module\r\n  File \"/usr/local/lib/python3.8/site-packages/tensorflow/python/client/session.py\", line 38, in <module>\r\n    from tensorflow.python.framework import sparse_tensor\r\n  File \"/usr/local/lib/python3.8/site-packages/tensorflow/python/framework/sparse_tensor.py\", line 29, in <module>\r\n    from tensorflow.python.framework import constant_op\r\n  File \"/usr/local/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py\", line 324, in <module>\r\n    ops.register_tensor_conversion_function(\r\nAttributeError: partially initialized module 'tensorflow.python.framework.ops' has no attribute 'register_tensor_conversion_function' (most likely due to a circular import)\r\n```\r\nThis does *not* happen when the file is not called exactly `code.py`. \r\n\r\n**Describe the expected behavior**\r\nYou can just import the code, no error. \r\n\r\n**Standalone code to reproduce the issue**\r\n`docker run -it --rm python:3 bash`\r\nthen \r\n```\r\npython3 -m pip install -y tensorflow \r\necho \"from tensorflow import keras\" > code.py\r\npython3 code.py # ==> error happens\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\nLinked Stackoverflow issue, proving at least 2 people had this issue: \r\nhttps://stackoverflow.com/questions/62165354/cannot-import-keras-from-tensorflow-depending-on-if-there-exists-a-file-in-the-c/62243098?noredirect=1#comment110099265_62243098", "comments": ["This is not TensorFlow related. In your stack trace, you see:\r\n```\r\n  File \"/usr/local/Cellar/python/3.7.7/Frameworks/Python.framework/Versions/3.7/lib/python3.7/pdb.py\", line 76, in <module>\r\n    import code\r\n```\r\nI.e. the official Python `pdb` package does `import code`, i.e. it loads the [official `code` module](https://docs.python.org/3/library/code.html).\r\n\r\nWhen you start some Python script, it will add the current path to `sys.path` at the very first position. Because of that, you can also not name your script `sys.py`, `os.py`, or the name of any other official Python module.", "@fredo838 \r\nPlease refer to above comment and confirm if we may close this issue", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40265\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40265\">No</a>\n"]}, {"number": 40264, "title": "Uniform indentation with other functions.", "body": "Uniform indentation with other functions.", "comments": ["Since the line fits within 80 columns this formatting is not needed. Hence the formatter did not change it. I believe we only split lines for arguments if all the arguments can't fit within 80 columns."]}, {"number": 40262, "title": "Use the trained k-NN classifier model to classify new, previously unseen objects ", "body": "I am trying to run below following lines in Jupiter notebook using necessary libraries and packages but yet its not running for me:\r\n\r\nfruit_prediction = knn.predict([[20, 4.3, 5.5]])\r\nlookup_fruit_name[fruit_prediction[0]]\r\n\r\nMoreover below is the following error I am getting:\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-12-1d28f9746e24> in <module>\r\n----> 1 fruit_prediction = knn.predict([[20, 4.3, 5.5]])\r\n      2 lookup_fruit_name[fruit_prediction[0]]\r\n\r\n~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\neighbors\\_classification.py in predict(self, X)\r\n    171         X = check_array(X, accept_sparse='csr')\r\n    172 \r\n--> 173         neigh_dist, neigh_ind = self.kneighbors(X)\r\n    174         classes_ = self.classes_\r\n    175         _y = self._y\r\n\r\n~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\neighbors\\_base.py in kneighbors(self, X, n_neighbors, return_distance)\r\n    661                 delayed_query(\r\n    662                     self._tree, X[s], n_neighbors, return_distance)\r\n--> 663                 for s in gen_even_slices(X.shape[0], n_jobs)\r\n    664             )\r\n    665         else:\r\n\r\n~\\OneDrive\\Documents\\Python\\lib\\site-packages\\joblib\\parallel.py in __call__(self, iterable)\r\n   1027             # remaining jobs.\r\n   1028             self._iterating = False\r\n-> 1029             if self.dispatch_one_batch(iterator):\r\n   1030                 self._iterating = self._original_iterator is not None\r\n   1031 \r\n\r\n~\\OneDrive\\Documents\\Python\\lib\\site-packages\\joblib\\parallel.py in dispatch_one_batch(self, iterator)\r\n    845                 return False\r\n    846             else:\r\n--> 847                 self._dispatch(tasks)\r\n    848                 return True\r\n    849 \r\n\r\n~\\OneDrive\\Documents\\Python\\lib\\site-packages\\joblib\\parallel.py in _dispatch(self, batch)\r\n    763         with self._lock:\r\n    764             job_idx = len(self._jobs)\r\n--> 765             job = self._backend.apply_async(batch, callback=cb)\r\n    766             # A job can complete so quickly than its callback is\r\n    767             # called before we get here, causing self._jobs to\r\n\r\n~\\OneDrive\\Documents\\Python\\lib\\site-packages\\joblib\\_parallel_backends.py in apply_async(self, func, callback)\r\n    204     def apply_async(self, func, callback=None):\r\n    205         \"\"\"Schedule a func to be run\"\"\"\r\n--> 206         result = ImmediateResult(func)\r\n    207         if callback:\r\n    208             callback(result)\r\n\r\n~\\OneDrive\\Documents\\Python\\lib\\site-packages\\joblib\\_parallel_backends.py in __init__(self, batch)\r\n    568         # Don't delay the application, to avoid keeping the input\r\n    569         # arguments in memory\r\n--> 570         self.results = batch()\r\n    571 \r\n    572     def get(self):\r\n\r\n~\\OneDrive\\Documents\\Python\\lib\\site-packages\\joblib\\parallel.py in __call__(self)\r\n    251         with parallel_backend(self._backend, n_jobs=self._n_jobs):\r\n    252             return [func(*args, **kwargs)\r\n--> 253                     for func, args, kwargs in self.items]\r\n    254 \r\n    255     def __reduce__(self):\r\n\r\n~\\OneDrive\\Documents\\Python\\lib\\site-packages\\joblib\\parallel.py in <listcomp>(.0)\r\n    251         with parallel_backend(self._backend, n_jobs=self._n_jobs):\r\n    252             return [func(*args, **kwargs)\r\n--> 253                     for func, args, kwargs in self.items]\r\n    254 \r\n    255     def __reduce__(self):\r\n\r\n~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\neighbors\\_base.py in _tree_query_parallel_helper(tree, *args, **kwargs)\r\n    488     under PyPy.\r\n    489     \"\"\"\r\n--> 490     return tree.query(*args, **kwargs)\r\n    491 \r\n    492 \r\n\r\nsklearn\\neighbors\\_binary_tree.pxi in sklearn.neighbors._kd_tree.BinaryTree.query()\r\n\r\nValueError: query data dimension must match training data dimension\r\n\r\nCan someone please tell me what I should I do ?", "comments": ["I want to fix this issue.", "@Udityanshu,\r\nThis question is better asked on [StackOverflow](https://stackoverflow.com/questions/ask) since it is not a TensorFlow bug or feature request. There is also a larger community that reads questions there. Thanks!", "Sounds good "]}, {"number": 40261, "title": "model.predict is much slower on TF 2.1+", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): WIndows 10 and Ubuntu 18.04\r\n- TensorFlow installed from (source or binary): Binary with pip3\r\n- TensorFlow version (use command below): 2.1+ vs. 2.0\r\n- Python version: 3.7\r\n- CUDA/cuDNN version: Used with CPU\r\n- CPU model: Intel i7 5930\r\n\r\n**Describe the current behavior**\r\nStarting from tensorflow-cpu 2.1, my program spends multiple fold of time on model.predict() compared to tensorflow 2.0. TF 2.2 get about the same result as 2.1.\r\nMy original program is fairly complicate. I wrote a simpliest example code below.\r\nWith TF 2.0, it takes 0.13 seconds to run.\r\nWith TF 2.2, it takes about 3 seconds.\r\n\r\n**Describe the expected behavior**\r\nIt should have similar execution time with TF 2.1+\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nfrom tensorflow.keras import Input, Model\r\nimport time\r\nimport numpy as np\r\n\r\nx = Input(shape=(1, 1))\r\nmodel = Model(inputs=x, outputs=x)\r\n\r\nt = time.time()\r\ni = 0\r\nwhile i<100:\r\n    model.predict(np.zeros((1, 1, 1)))\r\n    i += 1\r\nprint(time.time() - t)\r\n```", "comments": ["@lihanchen \r\nI ran the code shared by you on [tensorflow 2.0](https://colab.sandbox.google.com/gist/Saduf2019/490e7394f67121bc4997845b4491c610/untitled216.ipynb), [tf 2.1](https://colab.sandbox.google.com/gist/Saduf2019/54e2392e40ed2afd588ede7cd298a7ca/untitled208.ipynb) and [tf 2.2 ](https://colab.sandbox.google.com/gist/Saduf2019/47f16b6ecdd34f22e019f8ab50ad61ac/untitled216.ipynb) and do not see much of a difference.", "Hi, I just tried with another machine with i7-6700 and Linux Mint 19. I can repro it.\r\nDid you run it on CPU only? Also, since tf 2.1 has a difference package name (tensorflow-cpu vs tensorflow), you need to uninstall the other one or use virtualenv.\r\n\r\n```\r\nREMOTE lhc@LHC-DEV-Desktop \ue0b0 ~/venv \ue0b0 cd tf2.0/bin\r\nREMOTE lhc@LHC-DEV-Desktop \ue0b0 ~/venv/tf2.0/bin \ue0b0 source activate\r\n(tf2.0) REMOTE lhc@LHC-DEV-Desktop \ue0b0 ~/venv/tf2.0/bin \ue0b0 cd -\r\n~/venv\r\n(tf2.0) REMOTE lhc@LHC-DEV-Desktop \ue0b0 ~/venv \ue0b0 python3 test.py\r\n2020-06-08 14:59:32.578253: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2020-06-08 14:59:32.599598: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3399905000 Hz\r\n2020-06-08 14:59:32.600206: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3ffd1f0 executing computations on platform Host. Devices:\r\n2020-06-08 14:59:32.600234: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\r\n0.09805583953857422\r\n(tf2.0) REMOTE lhc@LHC-DEV-Desktop \ue0b0 ~/venv \ue0b0 python3 test.py\r\n2020-06-08 14:59:36.514623: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2020-06-08 14:59:36.535721: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3399905000 Hz\r\n2020-06-08 14:59:36.536023: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x588ddf0 executing computations on platform Host. Devices:\r\n2020-06-08 14:59:36.536045: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\r\n0.09672117233276367\r\n(tf2.0) REMOTE lhc@LHC-DEV-Desktop \ue0b0 ~/venv \ue0b0 cd tflatest/bin\r\n(tf2.0) REMOTE lhc@LHC-DEV-Desktop \ue0b0 ~/venv/tflatest/bin \ue0b0 source activate\r\n(tflatest) REMOTE lhc@LHC-DEV-Desktop \ue0b0 ~/venv/tflatest/bin \ue0b0 cd -\r\n~/venv\r\n(tflatest) REMOTE lhc@LHC-DEV-Desktop \ue0b0 ~/venv \ue0b0 python3 test.py\r\n2020-06-08 14:59:52.216610: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2020-06-08 14:59:52.239617: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 3399905000 Hz\r\n2020-06-08 14:59:52.239968: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47f95c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-06-08 14:59:52.239992: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n1.5681874752044678\r\n(tflatest) REMOTE lhc@LHC-DEV-Desktop \ue0b0 ~/venv \ue0b0 python3 test.py\r\n2020-06-08 14:59:57.516289: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2020-06-08 14:59:57.539687: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 3399905000 Hz\r\n2020-06-08 14:59:57.540030: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x334c360 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-06-08 14:59:57.540052: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n1.567026138305664\r\n\r\n```\r\nI also zipped the entire directory of testing code and 2 venvs.\r\nhttps://drive.google.com/file/d/1G4GqDAi0z2jscEc7WSVcMxHr-dyr5QZc/view?usp=sharing\r\n\r\n\r\n", "I can reproduce this with mac OS Catalina version 10.15.\r\nTF 2.0 took 0.116 seconds.\r\nTF 2.2 ran for 2.09 seconds.\r\n\r\n@lihanchen The colab links given by @Saduf2019 use cpu accelerator also the cpu and gpu packages are combined in `tensorflow` unless we specifically flag it as `tensorflow-cpu` or `tensorflow-gpu` in TF 2.1 and above. \r\n", "Any updates?", "Hi @lihanchen, judging by your filed bug and your example code, I'm assuming you're running `model.predict` inside of a loop?\r\n\r\nModel.predict is a top-level API designed for batch-predicting outside of any loops, with the fully featureset of the Keras apis. This means it manages things like converting your input to a tf.dataset and batching it, putting your computation into a tf.function, handling keras callbacks, etc.\r\n\r\nIf you're looking for a quick low-overhead model call to put inside of a loop / inside your own tf.function, we suggest directly calling the model on your data instead (w/ `training=True` to put the model in inference mode)\r\n\r\nFor example, running the following in colab with the tf.nightlies:\r\n```\r\nx = Input(shape=(1, 1))\r\nmodel = Model(inputs=x, outputs=x)\r\n\r\nt = time.time()\r\ni = 0\r\nwhile i<100:\r\n    model.predict(np.zeros((1, 1, 1)))\r\n    i += 1\r\nprint(time.time() - t)\r\n```\r\nprints `3.521230459213257`\r\n\r\n```\r\nx = Input(shape=(1, 1))\r\nmodel = Model(inputs=x, outputs=x)\r\n\r\nt = time.time()\r\ni = 0\r\nwhile i<100:\r\n    model(np.zeros((1, 1, 1)), training=False)\r\n    i += 1\r\nprint(time.time() - t)\r\n```\r\nprints `0.01329183578491211`\r\n\r\nAs you can see there's a 300x difference in the constant overheads.\r\n\r\n-------------------------\r\nAll that being said:\r\n\r\n1. If I'm mistaken about how you're actually using predict (and you're using it outside of any loops), please let us know!\r\n\r\nIf you can point us to an example (or input data) where a single predict call that's actually processing multiple batches of data (& possibly using various keras `predict` functionality) is much slower than in 2.0 that would be super helpful.\r\n\r\n2. 35 milliseconds / `predict` seems like a shockingly high overhead for `predict`, I'll look into this. It's unlikely to make it into 2.3 unless we cherrypick, but I'll see what can be done.\r\n", "Hi. Thank you for taking time. After changing from model.predict() to model().\r\nThe execution take much shorter time with above model.\r\n\r\nMy real model is a GRU followed by a few dense layers.\r\nHere is the example code:\r\n```\r\nfrom tensorflow.keras import Input, Model\r\nfrom tensorflow.keras.layers import GRU, Dense\r\nimport time\r\nimport numpy as np\r\n\r\nx = Input(shape=(15, 60))\r\n\r\nrnn = GRU(50, dropout=0.5, recurrent_dropout=0.5)(x)\r\n\r\ny = Dense(1)(rnn)\r\n\r\nmodel = Model(inputs=x, outputs=y)\r\n\r\nt = time.time()\r\ni = 0\r\nwhile i<100:\r\n    model.predict(np.random.rand(1, 15, 60))\r\n    i += 1\r\nprint(time.time() - t)\r\n```\r\n\r\nI found some interesting result:\r\n1. with TF 2.2, model.predict() call, it takes about 3.5 seconds with or without both GRU dropouts\r\n2. with TF 2.2, model() call, it takes about 1.2 seconds without both GRU dropouts\r\n3. with TF 2.2, model() call, it takes about 5 seconds with both GRU dropouts\r\n4. with TF 2.0, model.predict() call, it takes less than 0.6 seconds with or without both GRU dropouts\r\n\r\nBasically TF 2.0 is still much faster even I use model() cal to predict. 3 seems like a bug to me as dropouts make model() call slower than model.predict(). Is there a way I can achieve close to TF 2.0 performance with my model with TF 2.2?", "What exactly does your workload look like? Is it a batch predict situation? Are you serving a lot of very small predictions interactively?\r\n\r\nIf you have a batch-predicting situation where you have a lot of data you're trying to predict on, I suggest loading it with `tf.data` datasets and passing it directly to `.predict` instead of calling `.predict` in a loop. This is the setting `model.predict` is optimized for performance-wise\r\n\r\n`model.predict` automatically wraps your model in a `tf.function`, which will generally improve performance for all but the smallest models.\r\nIf you want the advantage of a `tf.function` without the other overheads of `predict` for an environment where you're interactively predicting, then I would suggest defining a tf.function that calls your model, e.g.\r\n\r\n```\r\n@tf.function\r\ndef serve(x):\r\n  return model(x, training=False)\r\n```\r\n", "It is a stock prediction software. Every hour, I feed in the corrent features into RNN and hopefully it will generate some output as a prediction of stock trend in next time period.\r\nI want the computation time to be minimum so the software can submit order based on current knowledge as soon as possible.\r\nBasically, I do this every hour when market is open:\r\n1. get current stock quotes\r\n2. calculate some metrics\r\n3. feed into model with model.predict() or model()\r\n4. Make order based on return of 3\r\n5. wait for another hour", "I see.\r\n\r\nAfter doing some tracing of `model.predict` in the no-op model, almost all the time is spent in a constant overhead when converting the single numpy value to a tf.data dataset. If you were to convert your entire dataset to a tf.data.dataset once at the start (outside of the loop), you would only have to pay that 30ms cost once.\r\n\r\nSo, if need to minimize latency on a very very small amount of data, I'd suggest using the `tf.function`'d serve method I mentioned above. This will minimize any constant-time overheads while still tf.functioning & optimizing your model.\r\n\r\nIf you expect your operations to take longer & your data is bigger, I'd suggest calling `.predict` once on your whole dataset outside of any loops. `predict` will be able to parallelize your input pipeline for you which may produce better throughput than just calling `serve` in a loop you've written yourself.", "Thanks for investigating.\r\n30ms to covert an 1x1x1 numpy sounds a long time but with no-op model I can achieve short time with model() call.\r\nThe question is why dropouts take much long time and why TF2.0 is much faster.", "Creating datasets comes with a constant overhead regardless of the data size. We may be able to improve it in the future for the case of small numpy data, but it's unlikely to improve real use cases so it's not a high priority.\r\n\r\nDo your dropouts take a long time/is tf 2.0 faster when you `tf.function` the forward pass as mentioned in the above `serve` method?", "I didn't use tf.data before. I will learn it and try.", "When I change it to create a dataset in the loop, it is much faster\r\n```\r\nwhile i<100:\r\n    train_dataset = tf.data.Dataset.from_tensor_slices(np.random.rand(1, 15, 60)).batch(1)\r\n    model.predict(train_dataset)\r\n    i += 1\r\n```\r\nIt take about 150% - 200% time of TF 2.0. I think there are still rooms to optimize as I create the data set in the loop, but I am satisfied with current solution.", "I have met the same problem. I solved this by downgrading keras 2.4.3 to 2.3.1 while I keep tf as 2.2.0.", "I see a huge difference between TF 1.13 and TF 2.2 \u2014 running predict on a single image now takes 0.04 seconds, it was 0.011 seconds on TF 1.13 (25 fps vs 90 fps on video data). \r\n\r\nUsing model(x) instead of model.predict(x, training=False) brings this up to 48 fps, but still not as close as TF1.\r\n\r\nDoes anyone have a solution?", "@ectg Did you try tf.function-ing your `model.call` method before calling your model?\r\nAs such:\r\n\r\n```\r\nmodel.call = tf.function(model.call, experimental_relax_shapes)\r\nmodel(..., training=False)\r\n```\r\n\r\nAlso, what are the use cases where you all are finding that building a `tf.dataset` at the start and batch predicting is impractical?\r\nKnowing this would help our prioritization.", "@tomerk I tried out your suggestion just now. The frame rate has gone up from 48 fps to 253 fps. Thanks! \r\n\r\nAs to building a tf.dataset at the start -- the network is intended for real time object detection on a video stream, so the dataset is not available beforehand.", "@tomerk This is the exact solution. Thanks. I guess this is a bug you should change", "@tomerk Thanks! I replaced many \"predict\" in my projects. I think this is a critical performance issue.", "Hi,\r\n\r\ni got a Problem with the returnValue from model(xxx, training=False).\r\nI have a working Program with predict.\r\n\r\n`valueRed    = float(col.r)`\r\n`valueGreen  = float(col.g)`\r\n`valueBlue   = float(col.b)`\r\n`data = np.array([[valueRed/255, valueGreen/255, valueBlue/255]])  `\r\n`result = model.predict(data, batch_size=32)`\r\n`index = result.argmax(1)`\r\n`return (labelList[int(index)])`\r\n\r\nThe Result is a numpy:\r\n[[1.8138054e-03 5.4888315e-03 6.9668889e-04 2.9702934e-03 8.9826369e-01\r\n  9.0765595e-02 1.0664122e-06]]\r\n\r\n\r\nif i change the predict to model(xxx, training=False) it will be much faster but the Result isn't a numpy anymore and i can't use argmax on result.\r\nThe result looks like:\r\ntf.Tensor(\r\n[[1.8138054e-03 5.4888315e-03 6.9668889e-04 2.9702934e-03 8.9826369e-01\r\n  9.0765595e-02 1.0664122e-06]], shape=(1, 7), dtype=float32)\r\n\r\nHow can i easy handle it to get my code working?\r\n\r\nthanks a lot", "@tomerk Hi tomerk,\r\n\r\nI know it might be an old issue, but it still exists today. I am using `tensorflow-gpu 2.6.0` with `keras 2.6.0`.\r\nThese two lines of code have the same output but the `predict` function spends much much more time than `model`.\r\n```\r\nself.model.predict(state) # slow\r\nself.model(state, training=False) # fast\r\n```\r\nThe output type of `predict` is a Python Array, while `model` is a TensorFlow Array. I don't think there is any actual difference. Please forgive me I did not view the code in these parts but just throw the question.\r\nJust to inform that it should be an issue since the time difference is huge but the results are the same.\r\n\r\nThere is also a strange part but might be my problem. I feel like the `predict` function did not use my GPU since the usage of GPU is 0% when it calling. Training does use GPU.\r\n\r\nThanks a lot.", "@owni1337  sorry if this is too late, but you can grab the numpy value of an eager tensor `tensor.numpy()`\r\n\r\n@cccat6 As mentioned above, `model.predict` Model.predict is a top-level API designed for batch-predicting outside of any other loops. Because it is designed for batch prediction and comes with other functionality, it comes with an inherently higher overhead. Much of this overhead is python or cpu-side overhead and is unrelated to the actual model computation.\r\n\r\nYou can use tensor.numpy() if you need access to the tensor as a numpy array.\r\n\r\nI'm going to go ahead and close this issue for now, as we have added to the model.predict documentation & I've opened the above PR to update the docstring further.", "@tomerk My model is **InceptionResNetV2_U-Net** which is large in size about 149Mb after pruning. I am using it for real-time video processing.  For frame by frame predicting its taking much time. code sample\r\n\r\n```\r\ncap = cv2.VideoCapture('testvideo.mp4') \r\n\r\nwhile (True):\r\n\r\n    _, frame = cap.read()\r\n\r\n    img_face = cv2.resize(frame,(IMG_WIDTH,IMG_HEIGHT)) \r\n    img_face = cv2.cvtColor(img_face, cv2.COLOR_BGR2RGBA)\r\n    img_face_f = tf.image.convert_image_dtype((img_face/255.0), dtype=tf.float32).numpy()\r\n\r\n    #mask\r\n    %timeit model.predict(np.expand_dims(img_face_f[:,:,:3], axis=0))[0] \r\n```\r\n\r\nIt's returning: \r\n\r\n662 ms \u00b1 4.53 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\r\n685 ms \u00b1 27.6 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\r\n690 ms \u00b1 67.3 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\r\n..................\r\n\r\n**Any faster way for predicting video frames?** Thanks", "Hello, everyone!\r\n\r\nI would like to get prediction results from my trained model as fast as possible \r\n\r\nThus, I tried several combinations which suggested previously \r\nand the speed result is look like this (left is fastest)\r\n\r\n`import tf1  result = model(input)` > `import tf2  result = model(input)` >= `import tf1  result = model.predict(input)`\r\n\r\nEspecially, `import tf1  result = model(input)` is super faster than the other methods\r\nHowever,  in tf1, converting \"result\" tensor to numpy array using (sess.run() or eval and other way like No.1) is very time consuming \r\n\r\nThus, I would be really appreciated it if you guys give some opinions or tips to solve this problem. \r\n\r\nI attached my code  \r\nThe code function named as \"AI_simulation\" is the callback function \r\n\r\nIn the code, speed result is,,\r\nNo.1 -> 4.1 FPS ~3.6 FPS getting slow (I think there is some memory leak)\r\nNo.2 -> 1.6 FPS (sess.run() is very time consuming )\r\nNo.3 -> 3.9 FPS\r\nNo.4 -> 3.8 FPS\r\n\r\n\r\nNo.1 \r\n```\r\n\r\nimport tensorflow.compat.v1 as tf\r\ntf.disable_eager_execution()\r\ntf.disable_v2_behavior()\r\n\r\nsess = tf.Session()\r\nwith sess.as_default():\r\n\r\n    G_A2B = model_from_json(loded_model_json, custom_objects={'ReflectionPadding3D':ReflectionPadding3D, 'InstanceNormalization':InstanceNormalization})\r\n    G_A2B.load_weights(model_path+'G_A2B_model_epoch_'+str(model_num)+'.hdf5')\r\n    place_holder = tf.compat.v1.placeholder(tf.float32, shape=(1,170,110,110,1))\r\n    G_A2B = G_A2B(place_holder, training=False)\r\n\r\ndef AI_simulation(AI_input):\r\n\r\n    result = sess.run(G_A2B, feed_dict={place_holder: AI_input[np.newaxis, :, :, :, np.newaxis]})\r\n    result = np.squeeze(result)\r\n\r\n    return result\r\n```\r\n \r\n\r\nNo.2 \r\n```\r\n\r\nimport tensorflow.compat.v1 as tf\r\ntf.disable_eager_execution()\r\ntf.disable_v2_behavior()\r\n\r\nsess = tf.Session()\r\nwith sess.as_default():\r\n\r\n    G_A2B = model_from_json(loded_model_json, custom_objects={'ReflectionPadding3D':ReflectionPadding3D, 'InstanceNormalization':InstanceNormalization})\r\n    G_A2B.load_weights(model_path+'G_A2B_model_epoch_'+str(model_num)+'.hdf5')\r\n\r\n\r\ndef AI_simulation(AI_input):\r\n\r\n    result = G_A2B(AI_input[np.newaxis, :, :, :, np.newaxis])\r\n    result = sess.run(result )\r\n    result = np.squeeze(result)\r\n\r\n    return result\r\n```\r\n\r\n\r\n\r\nNo.3\r\n\r\n```\r\nimport tensorflow.compat.v1 as tf\r\ntf.disable_eager_execution()\r\ntf.disable_v2_behavior()\r\n\r\nG_A2B = model_from_json(loded_model_json, custom_objects={'ReflectionPadding3D':ReflectionPadding3D, 'InstanceNormalization':InstanceNormalization})\r\nG_A2B.load_weights(model_path+'G_A2B_model_epoch_'+str(model_num)+'.hdf5')\r\nG_A2B.call = tf.function(G_A2B.call, experimental_relax_shapes = True)\r\n\r\ndef AI_simulation(AI_input):\r\n\r\n    result = G_A2B.predict(AI_input[np.newaxis, :, :, :, np.newaxis])\r\n    result = np.squeeze(result)\r\n    return result\r\n\r\n```\r\n\r\n\r\n\r\nNo.4 \r\n\r\n```\r\nimport tensorflow as tf  #tf2\r\n\r\nG_A2B = model_from_json(loded_model_json, custom_objects={'ReflectionPadding3D':ReflectionPadding3D, 'InstanceNormalization':InstanceNormalization})\r\nG_A2B.load_weights(model_path+'G_A2B_model_epoch_'+str(model_num)+'.hdf5')\r\nG_A2B.call = tf.function(G_A2B.call, experimental_relax_shapes = True)\r\n\r\ndef AI_simulation(AI_input):\r\n    result = G_A2B(AI_input[np.newaxis, :, :, :, np.newaxis])\r\n    result = np.squeeze(result.numpy())\r\n    return result\r\n\r\n```\r\n\r\n\r\n\r\n\r\n"]}, {"number": 40260, "title": "Failed to build TF on macOS with CUDA 10.1 due to cusparse_10_1.inc", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution: macOS 10.13.6\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 2.2.0\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source): 2.2.0\r\n- GCC/Compiler version (if compiling from source): XCode 10.1\r\n- CUDA/cuDNN version: 10.1.243/ 7.6.5\r\n- GPU model and memory: Nvidia Titan V\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n\r\nBuilding tensorflow from source encountered the following error:\r\n```\r\nERROR: /Volumes/Data/github/tensorflow/tensorflow/stream_executor/cuda/BUILD:448:1: C++ compilation of rule '//tensorflow/stream_executor/cuda:cusparse_stub' failed (Exit 1)\r\nIn file included from tensorflow/stream_executor/cuda/cusparse_stub.cc:59:\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7786:21: error: unknown type name 'cusparseSpVecDescr_t'\r\ncusparseCreateSpVec(cusparseSpVecDescr_t *spVecDescr, int64_t size, int64_t nnz,\r\n                    ^\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7790:7: error: unknown type name 'cusparseSpVecDescr_t'; did you mean 'cusparseSpMatDescr_t'?\r\n      cusparseSpVecDescr_t *, int64_t, int64_t, void *, void *,\r\n      ^~~~~~~~~~~~~~~~~~~~\r\n      cusparseSpMatDescr_t\r\nbazel-out/host/bin/external/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/cusparse.h:6964:36: note: 'cusparseSpMatDescr_t' declared here\r\ntypedef struct cusparseSpMatDescr* cusparseSpMatDescr_t;\r\n                                   ^\r\nIn file included from tensorflow/stream_executor/cuda/cusparse_stub.cc:59:\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7799:22: error: unknown type name 'cusparseSpVecDescr_t'; did you mean 'cusparseSpMatDescr_t'?\r\ncusparseDestroySpVec(cusparseSpVecDescr_t spVecDescr) {\r\n                     ^~~~~~~~~~~~~~~~~~~~\r\n                     cusparseSpMatDescr_t\r\nbazel-out/host/bin/external/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/cusparse.h:6964:36: note: 'cusparseSpMatDescr_t' declared here\r\ntypedef struct cusparseSpMatDescr* cusparseSpMatDescr_t;\r\n                                   ^\r\nIn file included from tensorflow/stream_executor/cuda/cusparse_stub.cc:59:\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7800:51: error: unknown type name 'cusparseSpVecDescr_t'; did you mean 'cusparseSpMatDescr_t'?\r\n  using FuncPtr = cusparseStatus_t(CUSPARSEAPI *)(cusparseSpVecDescr_t);\r\n                                                  ^~~~~~~~~~~~~~~~~~~~\r\n                                                  cusparseSpMatDescr_t\r\nbazel-out/host/bin/external/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/cusparse.h:6964:36: note: 'cusparseSpMatDescr_t' declared here\r\ntypedef struct cusparseSpMatDescr* cusparseSpMatDescr_t;\r\n```\r\n\r\n", "comments": ["It seems to be an environment variable problem. I've solved the problem by passing `action_env` as \r\n```\r\nbazel build --config=nonccl --config=monolithic  --config=opt --action_env PATH --action_env LD_LIBRARY_PATH --action_env DYLD_LIBRARY_PATH //tensorflow/tools/pip_package:build_pip_package\r\n```\r\nHowever, this is not a necessary parameter using CUDA 10.0.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40260\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40260\">No</a>\n"]}, {"number": 40259, "title": "How to convert tensorflow::tensorproto to tensorflow::tensor in C++", "body": "My question is just like the title.\r\n\r\nWhen using tfserving, you need to get the following\uff1a\r\n```\r\ntensorflow::SavedModelBundle bundle;\r\ntensorflow::LoadSavedModel(...)\r\n```\r\nThe model needs to be predicted after loading\uff1a\r\n```\r\nbundle.session.Run(...)\r\n```\r\nHowever, one input requirement of the run function is tensorflow::tensor type, and my a priori data is of tensorflow::tensorproto type, how do I convert it? In addition, where is the interface documentation for C++?", "comments": ["What version of tensorflow are you using? You can refer to the following question [here](https://stackoverflow.com/questions/44125403/how-to-access-tensor-content-values-in-tensorproto-in-tensorflow) to acess tensor content values in tensorproto", "> What version of tensorflow are you using? You can refer to the following question [here](https://stackoverflow.com/questions/44125403/how-to-access-tensor-content-values-in-tensorproto-in-tensorflow) to acess tensor content values in tensorproto\r\n\r\n\r\n\r\nThe version used is tf2.1 C++\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "@wangwenchao-job Did you take a look at this [issue](https://stackoverflow.com/questions/44125403/how-to-access-tensor-content-values-in-tensorproto-in-tensorflow) as mentioned in the above comment?", "Use [`FromProto`](https://cs.opensource.google/tensorflow/tensorflow/+/master:tensorflow/core/framework/tensor.h;l=361;drc=a67ee929f5aa2e16478d10e3287a248f34078cb5)\r\n\r\nThis is better suited for StackOverflow. Closing."]}, {"number": 40258, "title": "TFLiteConverter: failed to convert `tf.cast` (from `uint8` to `float32`)", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes (https://gist.github.com/kalaluthien/1cb86948d8f8e58260a1ee81ca6f8482)\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): colab\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): `2.1.0`\r\n- Python version: `3.6`\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n**Describe the current behavior**\r\nFailed to convert tf model to tflite model when using `tf.cast` to convert `tf.uint8` to `tf.float32`.\r\nBecause MLIR-based converter refuses uint8 input. (But tflite's CAST ops support conversion of uint8 to float32!)\r\n\r\nI need to convert input with uint8 to float32 in order to feed **integer input** to **float models** in order to exploit same interface with other **interger quantized models**.\r\n(actually float models = post-training float models but this is not a concern)\r\n\r\n**Describe the expected behavior**\r\nSuccess to convert Input tensor with integer type to float type.\r\n\r\n**Standalone code to reproduce the issue**\r\nhttps://gist.github.com/kalaluthien/1cb86948d8f8e58260a1ee81ca6f8482\r\n\r\n**Other info / logs** \r\n```\r\nTraceback (most recent call last):\r\n  File \"/usr/local/bin/toco_from_protos\", line 8, in <module>\r\n    sys.exit(main())\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 93, in main\r\n    app.run(main=execute, argv=[sys.argv[0]] + unparsed)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\r\n    _run_main(main, args)\r\n  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 56, in execute\r\n    enable_mlir_converter)\r\nException: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py:497:13: error: 'tfl.cast' op operand #0 must be tensor of 32-bit float or 1-bit integer or 32-bit integer or 64-bit integer values, but got 'tensor<1x14x14x3x!tf.quint8>'\r\n            *args, **kwds))\r\n            ^\r\n```", "comments": ["Could you try the conversion with tf-nightly?", "@abattery Thanks for your advice! The conversion has succeed.\r\nI need to use (Customized TFLite Interpreter Wrapper) which based on tensorflow 2.1.0. But TFLite does not guarantee forward compatibility (as I know), so I need to check the tf2.2-converted_model can be used as-is for my specific case.", "It works. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40258\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40258\">No</a>\n", "I am still getting this error with tf-nightly (2.5.0.dev20200627):\r\n\r\n```\r\ninput = tf.keras.layers.Input(shape=(360,360,3), dtype=tf.uint8, name='image')\r\noutput = tf.keras.layers.Lambda(lambda x: tf.keras.backend.cast(x, tf.float32))(input)\r\nmodel = tf.keras.models.Model(inputs=input, outputs=output)\r\nmodel.summary()\r\nmodel.save(MODEL_DIR)\r\n\r\nconverter = tf.lite.TFLiteConverter.from_saved_model(MODEL_DIR)\r\nconverter.allow_custom_ops = True\r\nconverter.target_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\r\nconverter.target_spec.supported_types = [tf.uint8, tf.float32]\r\ntflite_model = converter.convert()\r\n```\r\n\r\n```\r\nModel: \"functional_1\"\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\nimage (InputLayer)           [(None, 360, 360, 3)]     0         \r\n_________________________________________________________________\r\nlambda (Lambda)              (None, 360, 360, 3)       0         \r\n=================================================================\r\nTotal params: 0\r\nTrainable params: 0\r\nNon-trainable params: 0\r\n\r\n2020-06-27 11:07:26.172512: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: Graph size after: 6 nodes (3), 5 edges (3), time = 0.624ms.\r\n2020-06-27 11:07:26.172527: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.015ms.\r\nI0627 11:07:26.183743 140661122586432 lite.py:620] Using new converter: If you encounter a problem please file a bug. You can opt-out by setting experimental_new_converter=False\r\n2020-06-27 11:07:26.185712: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:313] Ignored output_format.\r\n2020-06-27 11:07:26.185744: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:316] Ignored drop_control_dependency.\r\nloc(\"Func/PartitionedCall/input/_0\"): error: requires all operands and results to have compatible element types\r\nTraceback (most recent call last):\r\n  File \"/home/alok/.local/lib/python3.6/site-packages/tensorflow/lite/python/convert.py\", line 199, in toco_convert_protos\r\n    enable_mlir_converter)\r\n  File \"/home/alok/.local/lib/python3.6/site-packages/tensorflow/lite/python/wrap_toco.py\", line 38, in wrapped_toco_convert\r\n    enable_mlir_converter)\r\nException: <unknown>:0: error: loc(\"Func/PartitionedCall/input/_0\"): requires all operands and results to have compatible element types\r\n<unknown>:0: note: loc(\"Func/PartitionedCall/input/_0\"): see current operation: %1 = \"tf.Identity\"(%arg0) {device = \"\"} : (tensor<?x360x360x3x!tf.quint8>) -> tensor<?x360x360x3xui8>\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"./tf2lite.py\", line 28, in <module>\r\n    app.run(main)\r\n  File \"/home/alok/.local/lib/python3.6/site-packages/absl/app.py\", line 299, in run\r\n    _run_main(main, args)\r\n  File \"/home/alok/.local/lib/python3.6/site-packages/absl/app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"./tf2lite.py\", line 25, in main\r\n    tflite_model = converter.convert()\r\n  File \"/home/alok/.local/lib/python3.6/site-packages/tensorflow/lite/python/lite.py\", line 1072, in convert\r\n    return super(TFLiteConverterV2, self).convert()\r\n  File \"/home/alok/.local/lib/python3.6/site-packages/tensorflow/lite/python/lite.py\", line 896, in convert\r\n    self).convert(graph_def, input_tensors, output_tensors)\r\n  File \"/home/alok/.local/lib/python3.6/site-packages/tensorflow/lite/python/lite.py\", line 629, in convert\r\n    **converter_kwargs)\r\n  File \"/home/alok/.local/lib/python3.6/site-packages/tensorflow/lite/python/convert.py\", line 574, in toco_convert_impl\r\n    enable_mlir_converter=enable_mlir_converter)\r\n  File \"/home/alok/.local/lib/python3.6/site-packages/tensorflow/lite/python/convert.py\", line 202, in toco_convert_protos\r\n    raise ConverterError(str(e))\r\ntensorflow.lite.python.convert.ConverterError: <unknown>:0: error: loc(\"Func/PartitionedCall/input/_0\"): requires all operands and results to have compatible element types\r\n<unknown>:0: note: loc(\"Func/PartitionedCall/input/_0\"): see current operation: %1 = \"tf.Identity\"(%arg0) {device = \"\"} : (tensor<?x360x360x3x!tf.quint8>) -> tensor<?x360x360x3xui8>\r\n\r\n```"]}, {"number": 40257, "title": "Code for univariate_data() preprocessing function in LSTM Timeseries documentation example incorrect", "body": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/tutorials/structured_data/time_series\r\n\r\n\r\n## Description of issue (what needs changing):\r\n\r\nThe code for the univariate_data function in the example located at the above site creates a series of indexing and method not found errors. It can be resolved by the following code. \r\n\r\ndef univariate_data(dataset, start_index, end_index, history_size, target_size):\r\n  data = []\r\n  labels = []\r\n\r\n  start_index = start_index + history_size\r\n  if end_index is None:\r\n    end_index = len(dataset) - target_size\r\n\r\n  for i in range(start_index, end_index):\r\n    #indices = range(i-history_size, i)\r\n\r\n    # Reshape data from (history_size,) to (history_size, 1)\r\n    data.append(dataset[i-history_size:i].values.reshape(history_size, 1))\r\n    labels.append(dataset[i+target_size])\r\n  return np.array(data), np.array(labels)\r\n", "comments": ["Tensorflow/Tensorflow is dynamic being. You can not steal her soul and keep\nit static.\nCure your programming addiction by taking vacation.\n\nOn Mon, Jun 8, 2020, 4:36 AM Brian Waite <notifications@github.com> wrote:\n\n> Thank you for submitting a TensorFlow documentation issue. Per our GitHub\n> policy, we only address code/doc bugs, performance issues, feature\n> requests, and\n> build/installation issues on GitHub.\n>\n> The TensorFlow docs are open source! To get involved, read the\n> documentation\n> contributor guide: https://www.tensorflow.org/community/contribute/docs\n> URL(s) with the issue:\n>\n> https://www.tensorflow.org/tutorials/structured_data/time_series\n> Description of issue (what needs changing):\n>\n> The code for the univariate_data function in the example located at the\n> above site creates a series of indexing and method not found errors. It can\n> be resolved by the following code.\n>\n> def univariate_data(dataset, start_index, end_index, history_size,\n> target_size):\n> data = []\n> labels = []\n>\n> start_index = start_index + history_size\n> if end_index is None:\n> end_index = len(dataset) - target_size\n>\n> for i in range(start_index, end_index):\n> #indices = range(i-history_size, i)\n>\n> # Reshape data from (history_size,) to (history_size, 1)\n> data.append(dataset[i-history_size:i].values.reshape(history_size, 1))\n> labels.append(dataset[i+target_size])\n>\n> return np.array(data), np.array(labels)\n>\n> \u2014\n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/40257>, or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AIT525SOLLV5KZXCBJ3IXZ3RVRFD3ANCNFSM4NX3ZK7A>\n> .\n>\n", "@Ujustwaite \r\n\r\nCan you provide the colab link to show where exactly you are facing the problem.Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 40256, "title": "Can TensorFlow models be saved and restored with multiple optimizers using tf.train.Checkpoint?", "body": "As per the [documentation](https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/train/Checkpoint), the recommendation for object-based checkpoints is to use `tf.train.Checkpoint` and one can simply use it as:\r\n\r\n`    checkpoint = tf.train.Checkpoint(optimizer=optimizer, model=model)`\r\n\r\nBut if there are multiple optimizers involved in the overall training process, how does one save and restore the model with all optimizers resuming from where they left off during training? I've attached a sample code below which uses two optimizers (i.e. L-BFGS and Adam). It can and save and restore the model using `tf.train.Saver` but this only saves the model without maintaining the optimizers from where they left off during training. Therefore any insights into adapting the below code to use `tf.train.Checkpoint` and save/restore it with multiple optimizers is sought, if possible at all. \r\n\r\n```\r\n    import numpy as np \r\n    import tensorflow as tf\r\n    \r\n    path_save = '/home/mathewsa/stored_models/' #custom path to save network\r\n    save_model = str(path_save)+\"test_save.ckpt\"\r\n    end_it = 1000 #number of iterations\r\n    frac_train = 1.0 #randomly sampled fraction of data to create training set\r\n    frac_sample_train = 0.01 #randomly sampled fraction of data from training set to train in batches\r\n    layers = [2, 20, 20, 20, 20, 20, 20, 20, 20, 1]\r\n    \r\n    #Generate training data\r\n    len_data = 10000\r\n    x_x = np.array([np.linspace(0.,1.,len_data)])\r\n    x_y = np.array([np.linspace(0.,1.,len_data)]) \r\n    y_true = np.array([np.linspace(-1.,1.,len_data)])\r\n    \r\n    N_train = int(frac_train*len_data)\r\n    idx = np.random.choice(len_data, N_train, replace=False)\r\n    \r\n    x_train = x_x.T[idx,:]\r\n    y_train = x_y.T[idx,:] \r\n    v1_train = y_true.T[idx,:] \r\n    \r\n    sample_batch_size = int(frac_sample_train*N_train)\r\n    \r\n    np.random.seed(1234)\r\n    tf.set_random_seed(1234)\r\n    import logging\r\n    logging.getLogger('tensorflow').setLevel(logging.ERROR)\r\n    tf.logging.set_verbosity(tf.logging.ERROR)\r\n    \r\n    class NeuralNet:\r\n        def __init__(self, x, y, v1, layers):\r\n            X = np.concatenate([x, y], 1)  \r\n            self.lb = X.min(0)\r\n            self.ub = X.max(0)\r\n            self.X = X\r\n            self.x = X[:,0:1]\r\n            self.y = X[:,1:2] \r\n            self.v1 = v1 \r\n            self.layers = layers \r\n            self.weights_v1, self.biases_v1 = self.initialize_NN(layers) \r\n            self.sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=False,\r\n                                                         log_device_placement=False)) \r\n            self.x_tf = tf.placeholder(tf.float32, shape=[None, self.x.shape[1]])\r\n            self.y_tf = tf.placeholder(tf.float32, shape=[None, self.y.shape[1]]) \r\n            self.v1_tf = tf.placeholder(tf.float32, shape=[None, self.v1.shape[1]])  \r\n            self.v1_pred = self.net(self.x_tf, self.y_tf) \r\n            self.loss = tf.reduce_mean(tf.square(self.v1_tf - self.v1_pred)) \r\n            self.optimizer = tf.contrib.opt.ScipyOptimizerInterface(self.loss,\r\n                                                                    var_list=self.weights_v1+self.biases_v1,\r\n                                                                    method = 'L-BFGS-B',\r\n                                                                    options = {'maxiter': 50,\r\n                                                                               'maxfun': 50000,\r\n                                                                               'maxcor': 50,\r\n                                                                               'maxls': 50,\r\n                                                                               'ftol' : 1.0 * np.finfo(float).eps})\r\n            self.optimizer_Adam = tf.train.AdamOptimizer()\r\n            self.train_op_Adam_v1 = self.optimizer_Adam.minimize(self.loss, var_list=self.weights_v1+self.biases_v1) \r\n            self.saver = tf.train.Saver()\r\n            init = tf.global_variables_initializer()  \r\n            self.sess.run(init)\r\n        def initialize_NN(self, layers):\r\n            weights = []\r\n            biases = []\r\n            num_layers = len(layers)\r\n            for l in range(0,num_layers-1):\r\n                W = self.xavier_init(size=[layers[l], layers[l+1]])\r\n                b = tf.Variable(tf.zeros([1,layers[l+1]], dtype=tf.float32), dtype=tf.float32)\r\n                weights.append(W)\r\n                biases.append(b) \r\n            return weights, biases\r\n        def xavier_init(self, size):\r\n            in_dim = size[0]\r\n            out_dim = size[1]\r\n            xavier_stddev = np.sqrt(2/(in_dim + out_dim)) \r\n            return tf.Variable(tf.truncated_normal([in_dim, out_dim], stddev=xavier_stddev), dtype=tf.float32)\r\n        def neural_net(self, X, weights, biases):\r\n            num_layers = len(weights) + 1\r\n            H = 2.0*(X - self.lb)/(self.ub - self.lb) - 1.0\r\n            for l in range(0,num_layers-2):\r\n                W = weights[l]\r\n                b = biases[l]\r\n                H = tf.tanh(tf.add(tf.matmul(H, W), b))\r\n            W = weights[-1]\r\n            b = biases[-1]\r\n            Y = tf.add(tf.matmul(H, W), b) \r\n            return Y\r\n        def net(self, x, y): \r\n            v1_out = self.neural_net(tf.concat([x,y], 1), self.weights_v1, self.biases_v1)\r\n            v1 = v1_out[:,0:1]\r\n            return v1\r\n        def callback(self, loss):\r\n            global Nfeval\r\n            print(str(Nfeval)+' - Loss in loop: %.3e' % (loss))\r\n            Nfeval += 1\r\n        def fetch_minibatch(self, x_in, y_in, v1_in, N_train_sample):  \r\n            idx_batch = np.random.choice(len(x_in), N_train_sample, replace=False)\r\n            x_batch = x_in[idx_batch,:]\r\n            y_batch = y_in[idx_batch,:] \r\n            v1_batch = v1_in[idx_batch,:] \r\n            return x_batch, y_batch, v1_batch\r\n        def train(self, end_it): \r\n            saver = tf.train.Saver()\r\n            print('Stage 4.20')\r\n            try:\r\n                saver.restore(self.sess, save_model) \r\n                print('Using previous model')\r\n            except:\r\n                self.Nfeval = 1\r\n                print('No previous model') \r\n            it = 0\r\n            while it < end_it: \r\n                x_res_batch, y_res_batch, v1_res_batch = self.fetch_minibatch(self.x, self.y, self.v1, sample_batch_size) # Fetch residual mini-batch\r\n                tf_dict = {self.x_tf: x_res_batch, self.y_tf: y_res_batch,\r\n                           self.v1_tf: v1_res_batch}\r\n                self.sess.run(self.train_op_Adam_v1, tf_dict)\r\n                self.optimizer.minimize(self.sess,\r\n                                        feed_dict = tf_dict,\r\n                                        fetches = [self.loss],\r\n                                        loss_callback = self.callback) \r\n                it = it + 1\r\n            self.save_path = saver.save(self.sess, save_model)\r\n            print('Finishing up training and saving as: ') \r\n            print(save_model) \r\n        def restore_model(self, path_full_saved):\r\n            saver = tf.train.Saver()\r\n            print('Stage 4.20')\r\n            try:\r\n                saver.restore(self.sess, str(path_full_saved))\r\n                print('Using previous model')\r\n            except:\r\n                print('No previous model')\r\n        def predict(self, x_star, y_star): \r\n            tf_dict = {self.x_tf: x_star, self.y_tf: y_star}\r\n            v1_star = self.sess.run(self.v1_pred, tf_dict)  \r\n            return v1_star\r\n    \r\n    model = NeuralNet(x_train, y_train, v1_train, layers)\r\n     \r\n    Nfeval = 1\r\n    model.train(end_it)\r\n```", "comments": ["The `optimizer=` keyword to `Checkpoint` is arbitrary; you can have `opt1=` and `opt2=`. \r\n\r\nIt sounds like the real problem is ScipyOptimizerInterface doesn't use tf.Variables. `contrib` isn't maintained / doesn't exist anymore, so the first step would be finding a supported implementation of ScipyOptimizerInterface or L-BFGS. I don't know of one. Could be a nice thing to add to tensorflow/addons.", "@tanzhenyu please chime in if you know of a successor to ScipyOptimizerInterface or an implementation of L-BFGS that works with 2.x."]}, {"number": 40254, "title": "[INTEL MKL] matmul,qmatmul and fusedops support for threadpool api.", "body": "", "comments": []}, {"number": 40251, "title": "`AttributeError due to '_TensorLike'", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NO\r\n- TensorFlow installed from (source or binary):Binary\r\n- TensorFlow version (use command below): tf-nightly-gpu latest\r\n- Python version:3.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:10.1\r\n- GPU model and memory: gtx 1060\r\n\r\nI'm getting the following error,\r\n\r\n`AttributeError: module 'tensorflow.python.framework.ops' has no attribute '_TensorLike'\r\n`\r\nand this error points to the following line,\r\n\r\n`    x = Conv2D(32, (3,3), strides=(1,1), padding='same', name='conv_1', use_bias=False)(input_image)\r\n`\r\n", "comments": ["@Zumbalamambo  \r\nIn order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!\r\n\r\n", "@Zumbalamambo  When error description include '_TensorLike', then mostly the error is due to mixing of functions from `keras` and `tf.keras` in the code. Can you please share a standalone code that is throwing an error. Thanks!\r\n\r\nCheck this issue which mights be similar to your issue. https://github.com/tensorflow/tensorflow/issues/39817\r\n\r\nPlease close the issue if this was already resolved for you. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "+1", "@Zumbalamambo Please let us know whether issue was resolved for you. \r\n\r\nPlease close the issue if the issue was resolved for you. Thanks!", "I am closing this issue as i think it was resolved. Please feel free to reopen if the issue persists again. Thanks!"]}, {"number": 40250, "title": "tf.raw_ops.CollectivePermute bug caused by strange device numbering", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes.\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.2.0\r\n- Python version: 3.6\r\n\r\n**Describe the current behavior**\r\nThe 8 cores are numbered as 0,1,2,3,6,7,4,5 by CollectivePermute and  tensorflow.python.tpu.ops.tpu_ops.all_to_all.\r\n\r\n**Describe the expected behavior**\r\nThey should be numbered as 0,1,2,3,4,5,6,7.\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\n\r\nresolver = tf.distribute.cluster_resolver.TPUClusterResolver(\r\n  tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\r\ntf.config.experimental_connect_to_cluster(resolver)\r\ntf.tpu.experimental.initialize_tpu_system(resolver)\r\nstrategy = tf.distribute.experimental.TPUStrategy(resolver)\r\n\r\n@tf.function\r\ndef step_fn():\r\n  context = tf.distribute.get_replica_context()\r\n  v = context.replica_id_in_sync_group\r\n  v = tf.raw_ops.CollectivePermute(\r\n      input=v,\r\n      source_target_pairs=[[0,1],[1,2],[2,3],[3,4],[4,5],[5,6],[6,7],[7,0]])\r\n  return v\r\n\r\nret = strategy.run(step_fn)\r\nprint(ret)\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\nThe following is the output. \r\n```\r\nPerReplica:{\r\n  0: tf.Tensor(5, shape=(), dtype=int32),\r\n  1: tf.Tensor(0, shape=(), dtype=int32),\r\n  2: tf.Tensor(1, shape=(), dtype=int32),\r\n  3: tf.Tensor(2, shape=(), dtype=int32),\r\n  4: tf.Tensor(7, shape=(), dtype=int32),\r\n  5: tf.Tensor(4, shape=(), dtype=int32),\r\n  6: tf.Tensor(3, shape=(), dtype=int32),\r\n  7: tf.Tensor(6, shape=(), dtype=int32)\r\n}\r\n```\r\nThe correct output should be 7,0,1,2,3,4,5,6", "comments": ["I have tried in colab with TF version 2.2 and was able to reproduce the issue.But in NIghtly version(`2.3.0-dev20200605`) i am seeing the below error message.(`InvalidArgumentError: NodeDef expected inputs 'string' do not match 0 inputs specified; Op<name=_Send; signature=tensor:T -> ; attr=T:type; attr=tensor_name:string; attr=send_device:string; attr=send_device_incarnation:int; attr=recv_device:string; attr=client_terminated:bool,default=false; is_stateful=true>; NodeDef: {{node _Send}}`).Thanks!", "I think this is expected behavior as XLA could interpret `replica id` differently than user's `replica id`.\r\n\r\nSee comment here: https://github.com/tensorflow/tensorflow/blob/v2.2.0/tensorflow/python/distribute/distribute_lib.py#L2444-L2445", "@hthu For the following code\r\n```\r\nimport os\r\nimport tensorflow as tf\r\nfrom tensorflow.python.distribute.values import PerReplica\r\n\r\nresolver = tf.distribute.cluster_resolver.TPUClusterResolver(\r\n  tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\r\ntf.config.experimental_connect_to_cluster(resolver)\r\ntf.tpu.experimental.initialize_tpu_system(resolver)\r\nstrategy = tf.distribute.experimental.TPUStrategy(resolver)\r\n\r\n@tf.function\r\ndef gen_id():\r\n  context = tf.distribute.get_replica_context()\r\n  return context.replica_id_in_sync_group\r\n\r\nt = strategy.run(gen_id)\r\nprint(t)\r\n\r\n@tf.function\r\ndef step_fn(v):\r\n  v = tf.raw_ops.CollectivePermute(\r\n      input=v,\r\n      source_target_pairs=[[0,1],[1,2],[2,3],[3,4],[4,5],[5,6],[6,7],[7,0]])\r\n  return v\r\n\r\nret = strategy.run(step_fn, args=[t])\r\nprint(ret)\r\n```\r\n\r\nThe output is \r\n```\r\nPerReplica:{\r\n  0: tf.Tensor(0, shape=(), dtype=int32),\r\n  1: tf.Tensor(1, shape=(), dtype=int32),\r\n  2: tf.Tensor(2, shape=(), dtype=int32),\r\n  3: tf.Tensor(3, shape=(), dtype=int32),\r\n  4: tf.Tensor(4, shape=(), dtype=int32),\r\n  5: tf.Tensor(5, shape=(), dtype=int32),\r\n  6: tf.Tensor(6, shape=(), dtype=int32),\r\n  7: tf.Tensor(7, shape=(), dtype=int32)\r\n}\r\nPerReplica:{\r\n  0: tf.Tensor(5, shape=(), dtype=int32),\r\n  1: tf.Tensor(0, shape=(), dtype=int32),\r\n  2: tf.Tensor(1, shape=(), dtype=int32),\r\n  3: tf.Tensor(2, shape=(), dtype=int32),\r\n  4: tf.Tensor(7, shape=(), dtype=int32),\r\n  5: tf.Tensor(4, shape=(), dtype=int32),\r\n  6: tf.Tensor(3, shape=(), dtype=int32),\r\n  7: tf.Tensor(6, shape=(), dtype=int32)\r\n}\r\n```\r\n\r\nAre these outputs still expected behavior?", "Unfortunately yes. \nFor the first part, we are merely exercising replica id in context.\nThe point being, when you execute collectivePermute, xla would view the IDs differently. \nMore specifically, the id 4 in context might not be viewed as id 4 when performing collectivePermute.\nYou can also do a quick check by just providing single pair [0,3] and see what that returns.\n\nThat said, I do think we should be more clear on this.\nI'll follow up tomorrow and see what we can do here.\n\nLMK if you have any questions!", "The input and output of strategy.run are sent to and received from the 8 cores, respectively. Are the order of sending and receiving related to XLA replica ID?", "Yes. And that ID isn't really the same as the context `replica id` here.", "In this call in the code above, there is no replica id involved. But the order is still strange.\r\n```\r\nret = strategy.run(step_fn, args=[t])\r\n```", "I think you are running this with the `replica_id_in_sync_group` from context, right?\r\n`replica_id_in_sync_group` 0 isn't necessarily isn't necessarily the `0` in XLA world.\r\n\r\nYou could try this to verify the mapping:\r\n```python\r\n@tf.function\r\ndef step_fn():\r\n  context = tf.distribute.get_replica_context()\r\n  v = context.replica_id_in_sync_group\r\n  v = tf.raw_ops.CollectivePermute(\r\n      input=v,\r\n      source_target_pairs=[[1,4]])\r\n  return v\r\n```", "I have figured out the current mapping and switching 4 <-> 6, 5 <-> 7 can lead to the result I want.\r\n\r\nLet us get rid of replica_id_in_sync_group. My question is that the output of the following code looks strange.\r\n\r\n```\r\nimport os\r\nimport tensorflow as tf\r\nfrom tensorflow.python.distribute.values import PerReplica\r\n\r\nresolver = tf.distribute.cluster_resolver.TPUClusterResolver(\r\n  tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\r\ntf.config.experimental_connect_to_cluster(resolver)\r\ntf.tpu.experimental.initialize_tpu_system(resolver)\r\nstrategy = tf.distribute.experimental.TPUStrategy(resolver)\r\n\r\nt = tf.range(8)\r\nt = tf.unstack(t)\r\n\r\n@tf.function\r\ndef step_fn(v):\r\n  v = tf.raw_ops.CollectivePermute(\r\n      input=v,\r\n      source_target_pairs=[[0,1],[1,2],[2,3],[3,4],[4,5],[5,6],[6,7],[7,0]])\r\n  return v\r\n\r\nret = strategy.run(step_fn, args=[PerReplica(t)])\r\nprint(ret)\r\n```", "Sorry for the late reply!\r\nThis is the due to the same reason as the ones with the Id.\r\nTpuStrategy has a context that records `replica_id_in_sync_group`. When performing XLA operations, the participating TPU group in the strategy will inherently have a `id`, which again, might not map to the XLA `id`.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40250\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40250\">No</a>\n"]}, {"number": 40249, "title": "The parameters for BatchNormalization are not updated", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): OS\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): Official Website\r\n- TensorFlow version (use command below): 2.2.0\r\n- Python version: 3.7.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: No\r\n- GPU model and memory: No\r\n\r\n**Describe the current behavior**\r\n\r\nI am simply changing to codes from `tf.layers` to `tf.keras.layers`, based on the migration instructions on the official website. But it turned out the parameters for `tf.keras.layers.BatchNormalization` are not updated properly, while everything works fine for `tf.layers.BatchNormalization()`. I do not know the reasons.\r\n\r\n**Describe the expected behavior**\r\n\r\nThe parameters for `tf.keras.layers.BatchNormalization` should be updated just like what have been done for `tf.layers.BatchNormalization`.\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\nCodes:\r\n```\r\nimport tensorflow.compat.v1 as tf\r\ntf.disable_v2_behavior()\r\nimport numpy as np\r\n\r\ndef get_positive(batch_size):\r\n    train_images = np.zeros((50, 28, 28, 1), dtype=np.float32) + 1.\r\n    train_labels = np.int8(np.zeros((50, 1)) + 1)\r\n    dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\r\n    dataset = dataset.repeat(1)\r\n    dataset = dataset.batch(batch_size)\r\n    dataset = dataset.prefetch(1)\r\n    return dataset.make_one_shot_iterator().get_next()\r\n\r\ndef get_negative(batch_size):\r\n    train_images = np.zeros((50, 28, 28, 1), dtype=np.float32)\r\n    train_labels = np.int8(np.zeros((50, 1)))\r\n    dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\r\n    dataset = dataset.repeat(1)\r\n    dataset = dataset.batch(batch_size)\r\n    dataset = dataset.prefetch(1)\r\n    return dataset.make_one_shot_iterator().get_next()\r\n\r\ndef tf_model(feature, is_training):\r\n    with tf.variable_scope(\"tf_model\", reuse=tf.AUTO_REUSE):\r\n        net = tf.layers.Conv2D(\r\n            8, (3, 3), strides=(2, 2),\r\n            activation=tf.nn.relu)(feature)  # 13x13x8\r\n        net = tf.layers.BatchNormalization()(net, is_training)\r\n        net = tf.layers.Conv2D(\r\n            1, (3, 3), strides=(2, 2), activation=tf.nn.relu)(net)  # 6x6x1\r\n        net = tf.layers.Flatten()(net)  # 36\r\n        net = tf.layers.Dense(1)(net)\r\n        return net\r\n\r\ndef tf_keras_model(feature, is_training):\r\n    with tf.variable_scope(\"tf_model\", reuse=tf.AUTO_REUSE):\r\n        net = tf.keras.layers.Conv2D(\r\n            8, (3, 3), strides=(2, 2),\r\n            activation=tf.nn.relu)(feature)  # 13x13x8\r\n        net = tf.keras.layers.BatchNormalization()(net, is_training)\r\n        net = tf.keras.layers.Conv2D(\r\n            1, (3, 3), strides=(2, 2), activation=tf.nn.relu)(net)  # 6x6x1\r\n        net = tf.keras.layers.Flatten()(net)  # 36\r\n        net = tf.keras.layers.Dense(1)(net)\r\n        return net\r\n\r\ndef get_bn_vars(collection):\r\n    moving_mean, moving_variance = None, None\r\n    for var in collection:\r\n        name = var.name.lower()\r\n        if \"variance\" in name:\r\n            moving_variance = var\r\n        if \"mean\" in name:\r\n            moving_mean = var\r\n\r\n    if moving_mean is not None and moving_variance is not None:\r\n        return moving_mean, moving_variance\r\n    raise ValueError(\"Unable to find moving mean and variance\")\r\n\r\ndef main_layers(case):\r\n    positive, positive_labels = get_positive(10)\r\n    negative, negative_labels = get_negative(10)\r\n\r\n    model_true = tf_model(positive, True)\r\n\r\n    loss = tf.losses.sigmoid_cross_entropy(positive_labels, model_true)\r\n    if case == 2:\r\n        model_false = tf_model(negative, True)\r\n        loss += tf.losses.sigmoid_cross_entropy(negative_labels, model_false)\r\n\r\n    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\r\n    with tf.control_dependencies(update_ops):\r\n        train_op = tf.train.GradientDescentOptimizer(1e-3).minimize(loss)\r\n\r\n    mean, variance = get_bn_vars(tf.global_variables())\r\n    init = tf.global_variables_initializer()\r\n    with tf.Session() as sess:\r\n        sess.run(init)\r\n        while True:\r\n            try:\r\n                loss_value, _ = sess.run([loss, train_op])\r\n                print(\"loss: \", loss_value)\r\n            except tf.errors.OutOfRangeError:\r\n                break\r\n        print(sess.run([mean, variance]))\r\n\r\ndef main_tf_keras_layers(case):\r\n    tf.keras.backend.set_learning_phase(True)\r\n    positive, positive_labels = get_positive(10)\r\n    negative, negative_labels = get_negative(10)\r\n\r\n    model_true = tf_keras_model(positive, True)\r\n\r\n    loss = tf.losses.sigmoid_cross_entropy(positive_labels, model_true)\r\n    if case == 2:\r\n        model_false = tf_model(negative, True)\r\n        loss += tf.losses.sigmoid_cross_entropy(negative_labels, model_false)\r\n\r\n    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\r\n    with tf.control_dependencies(update_ops):\r\n        train_op = tf.train.GradientDescentOptimizer(1e-3).minimize(loss)\r\n\r\n    mean, variance = get_bn_vars(tf.global_variables())\r\n    init = tf.global_variables_initializer()\r\n    with tf.Session() as sess:\r\n        sess.run(init)\r\n        while True:\r\n            try:\r\n                loss_value, _ = sess.run([loss, train_op])\r\n                print(\"loss: \", loss_value)\r\n            except tf.errors.OutOfRangeError:\r\n                break\r\n        print(sess.run([mean, variance]))\r\n```\r\n\r\nIf we run `main_layers(1)`, we would get:\r\n```\r\nloss:  0.69315034\r\nloss:  0.6928972\r\nloss:  0.69264734\r\nloss:  0.6923976\r\nloss:  0.6921481\r\n[array([0.        , 0.        , 0.        , 0.01786391, 0.02162646,\r\n       0.        , 0.00420831, 0.        ], dtype=float32), array([0.95099014, 0.95099014, 0.95099014, 0.95099014, 0.95099014,\r\n       0.95099014, 0.95099014, 0.95099014], dtype=float32)]\r\n```\r\n\r\nHowever, if we run `main_tf_keras_layers(1)`, we would get:\r\n```\r\nloss:  0.6930456\r\nloss:  0.69101626\r\nloss:  0.688996\r\nloss:  0.68698376\r\nloss:  0.68497455\r\n[array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)]\r\n```\r\n\r\nIt turns out that parameters for `tf.keras.layers.BatchNormalization` are not updated properly. They should be expected to be similar to  `tf.layers.BatchNormalization`.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["My further question would be like: is it safe that we could simply replace `tf.layers` with `tf.keras.layers`? If it not safe, how should we deal with the codes written in tf1.x, and we want to write them in tf2.x (I do know that there is a guide about migrations)?", "Was able to reproduce the issue with [TF v2.2](https://colab.research.google.com/gist/amahendrakar/636025752e44225cf3773dd6fb7bf5ed/40249.ipynb) and [TF-nightly](https://colab.research.google.com/gist/amahendrakar/f78949f716361e77a039a6095c4161ae/40249-tf-nightly.ipynb). Please find the attached gist. Thanks!", "The code and repro in in TF1 and v2_behavior disabled. The issue should be gone if it's migrated to TF2. Could you follow this [migration guide](https://www.tensorflow.org/guide/migrate) to update the code to TF2? Thanks.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40249\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40249\">No</a>\n"]}, {"number": 40248, "title": " Error while reading resource variable _AnonymousVar117 from Container while training with colab", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): colab\r\n- TensorFlow version (use command below): 2.3\r\n- Python version:3.8\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: colab\r\n- GPU model and memory: gtx 1060\r\n\r\n\r\nI'm getting the following error,\r\n```\r\n\r\nFailedPreconditionError                   Traceback (most recent call last)\r\n<ipython-input-6-daf439831857> in <module>()\r\n     89 \r\n     90 if __name__ == '__main__':\r\n---> 91     _main_()\r\n\r\n11 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\r\n     58     ctx.ensure_initialized()\r\n     59     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\n---> 60                                         inputs, attrs, num_outputs)\r\n     61   except core._NotOkStatusException as e:\r\n     62     if name is not None:\r\n\r\nFailedPreconditionError:  Error while reading resource variable _AnonymousVar117 from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/_AnonymousVar117/N10tensorflow3VarE does not exist.\r\n\t [[node loss/lambda_2_loss/custom_loss/Less_2/ReadVariableOp (defined at /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3009) ]] [Op:__inference_keras_scratch_graph_19741]\r\n\r\nFunction call stack:\r\nkeras_scratch_graph\r\n```\r\n\r\nThe error log is pointless that it doesn't even tell me where the error could be in my code. ", "comments": ["@Zumbalamambo \r\nIn order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "+1", "@Zumbalamambo \r\nPlease update as per above comment", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "closing because tensorflow 2 is the storehouse of bugs and unusable", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40248\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40248\">No</a>\n"]}, {"number": 40247, "title": "Functional Keras API not getting converted using TFLiteTransferConverter in Model Personalization", "body": "**Working on Colab**\r\n- TensorFlow version: 2.2.0\r\n\r\n## Error\r\nWhile reading about PR **RFC: On-Device Training with TensorFlow**([https://github.com/tensorflow/community/pull/124](https://github.com/tensorflow/community/pull/124)), and trying to include 'train' option in convert(I know tflite currently does not support on-device training, but was curious to check how operations would look like), I am facing the following error:\r\n\r\n```\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/importer.py in _import_graph_def_internal(graph_def, input_map, return_elements, validate_colocation_constraints, name, producer_op_list)\r\n    496         results = c_api.TF_GraphImportGraphDefWithResults(\r\n--> 497             graph._c_graph, serialized, options)  # pylint: disable=protected-access\r\n    498         results = c_api_util.ScopedTFImportGraphDefResults(results)\r\n\r\nInvalidArgumentError: Input 0 of node SGD/SGD/update_11/ResourceApplyGradientDescent was passed float from sequential/dense_1/BiasAdd/ReadVariableOp/resource:0 incompatible with expected resource.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nValueError                                Traceback (most recent call last)\r\n12 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/importer.py in _import_graph_def_internal(graph_def, input_map, return_elements, validate_colocation_constraints, name, producer_op_list)\r\n    499       except errors.InvalidArgumentError as e:\r\n    500         # Convert to ValueError for backwards compatibility.\r\n--> 501         raise ValueError(str(e))\r\n    502 \r\n    503     # Create _DefinedFunctions for any imported functions.\r\n\r\nValueError: Input 0 of node SGD/SGD/update_11/ResourceApplyGradientDescent was passed float from sequential/dense_1/BiasAdd/ReadVariableOp/resource:0 incompatible with expected resource.\r\n```\r\n\r\n### Command used to run the converter or code if you\u2019re using the Python API\r\n**Model Description**\r\n```\r\nmodel = tf.keras.Sequential([tf.keras.layers.Conv2D(32, kernel_size=3, padding='same', activation='relu', input_shape=(32,32,3)),\r\n                             tf.keras.layers.Conv2D(32, kernel_size=3, activation='relu', padding='same'),\r\n                             tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2)),\r\n                             tf.keras.layers.Conv2D(64, kernel_size=3, activation='relu', padding='same'),\r\n                             tf.keras.layers.Conv2D(64, kernel_size=3, activation='relu', padding='same'),\r\n                             tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2)),\r\n                             tf.keras.layers.Flatten(),\r\n                             tf.keras.layers.Dense(128, activation='relu'),\r\n                             tf.keras.layers.Dense(10)])\r\n\r\nmodel.compile(optimizer='sgd', loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\r\n```\r\n\r\n **Convert Code**\r\n```\r\n_LOSS_FN = tf.keras.losses.CategoricalCrossentropy()\r\n_OPTIM = tf.optimizers.SGD()\r\n\r\n@tf.function(input_signature=[\r\n    tf.TensorSpec(model.inputs[0].shape, model.inputs[0].dtype),\r\n    tf.TensorSpec(model.outputs[0].shape, model.outputs[0].dtype),\r\n])\r\ndef train(x, y):\r\n  with tf.GradientTape() as tape:\r\n    prediction = model(x)\r\n    loss = _LOSS_FN(prediction, y)\r\n  gradients = tape.gradient(loss, model.trainable_variables)\r\n  _OPTIM.apply_gradients(zip(gradients, model.trainable_variables))\r\n\r\nconcrete_func = train.get_concrete_function()\r\n\r\n# convert to tflite\r\nconverter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])\r\nconverted_tflite_model = converter.convert()\r\n```\r\n\r\nCan anyone please help me out with the error? ", "comments": ["Currently, TFLite do not support on-device training officially and also does not support natively mutable variable use cases. The above error is an intended behavior.", "I think that error is because of the `AssignVariableOp` that is not supported by `convert()` function. Looking at the Traceback error, it shows that `convert()` function by default freezes the parameters. \r\n\r\nThough I am yet to explore in detail, [https://github.com/tensorflow/examples/blob/master/lite/examples/model_personalization/README.md](https://github.com/tensorflow/examples/blob/master/lite/examples/model_personalization/README.md), shows that there is a way to do transfer learning on-device, that is, train some of the layers on android device, using a `base` model and a `head` model. Does this train only the dense layers? Or can it be used to train Conv layers too?", "@sarthak-chakraborty you're right. We have a limited mutable variable support via flex delegate and AssignVariableOp is a typical example of that.\r\n\r\n@jaeyoo could you answer the model personalization questions?", "As for the Model Personalization questions, I have the following questions:\r\n\r\n1. It contains the `head` and `base` model. I have checked that including a full CNN model in head layer works and it gets trained as well in an android phone. However, head models created with only `Sequential` API is getting converted. Does it mean there is no support for head models with `Functional` API? Particularly, the problem lies if we define an Input layer, i.e., `tf.keras.Input(shape=())` causes the error in both functional as well as Sequential API. However, Sequential API can be bypassed without mentioning the Input Layer which cannot be done in Functional API. Using Input Layer gives the error: ```RuntimeError: Unexpected Keras eval signature inputs```\r\n\r\n2. I understand that some layers like `DepthwiseConv2d` will not be converted since there is no support of `DepthwiseConv2dNativeBackpropFilter` and `DepthwiseConv2dNativeBackpropInput` in whitelisted flex ops. However, is it possible to freeze certain layers in the head model (example, freeze the depthwiseConv2d layer so that no backprop takes place)? I have tried the following:\r\n        a) Made some layers as non-trainable in head model\r\n        b) In the `train` function of the file `tfltransfer/heads/keras_model_head.py`, I used only the variables that are corresponding to the trainable layers for calculating `tf.gradients()` (i.e. variables in \r\n   ```\r\n   with tf.name_scope(scope + '/backprop'):\r\n       gradients = tf.gradients(loss, variables, stop_gradients=variables)\r\n   ``` \r\n    contains only the variables corresponding to trainable layers) gives the error:\r\n    ```Placeholder head/depth_conv1024_12/depthwise_kernel should be specified by input_arrays.```\r\n\r\n\r\nAny help regarding this matter will be highly appreciated.", "> 1. It contains the `head` and `base` model. I have checked that including a full CNN model in head layer works and it gets trained as well in an android phone. However, head models created with only `Sequential` API is getting converted. Does it mean there is no support for head models with `Functional` API? Particularly, the problem lies if we define an Input layer, i.e., `tf.keras.Input(shape=())` causes the error in both functional as well as Sequential API. However, Sequential API can be bypassed without mentioning the Input Layer which cannot be done in Functional API. Using Input Layer gives the error: `RuntimeError: Unexpected Keras eval signature inputs`\r\n\r\nYou can provide name in InputLayer in  Sequential API like this:\r\nlayers.InputLayer(input_shape=(whatever), name='target_input') and perhaps its not gonna be an error.", "> As for the Model Personalization questions, I have the following questions:\r\n> \r\n> 1. It contains the `head` and `base` model. I have checked that including a full CNN model in head layer works and it gets trained as well in an android phone. However, head models created with only `Sequential` API is getting converted. Does it mean there is no support for head models with `Functional` API? Particularly, the problem lies if we define an Input layer, i.e., `tf.keras.Input(shape=())` causes the error in both functional as well as Sequential API. However, Sequential API can be bypassed without mentioning the Input Layer which cannot be done in Functional API. Using Input Layer gives the error: `RuntimeError: Unexpected Keras eval signature inputs`\r\n\r\nYes, currently, model personalization doesn't support Functional API. Could you try to specify your input specification as listed in `keras_head_model.py` and `tflite_transfer_converter.py`?\r\n```python\r\n      loss, gradients, variables = self.head_model.train(bottleneck, labels)\r\n      converter = tfv1.lite.TFLiteConverter.from_session(\r\n          sess, [bottleneck, labels] + variables, [loss] + gradients)\r\n```\r\n\r\n> 2. I understand that some layers like `DepthwiseConv2d` will not be converted since there is no support of `DepthwiseConv2dNativeBackpropFilter` and `DepthwiseConv2dNativeBackpropInput` in whitelisted flex ops. However, is it possible to freeze certain layers in the head model (example, freeze the depthwiseConv2d layer so that no backprop takes place)? I have tried the following:\r\n>    a) Made some layers as non-trainable in head model\r\n>    b) In the `train` function of the file `tfltransfer/heads/keras_model_head.py`, I used only the variables that are corresponding to the trainable layers for calculating `tf.gradients()` (i.e. variables in\r\n>    ```\r\n>    with tf.name_scope(scope + '/backprop'):\r\n>        gradients = tf.gradients(loss, variables, stop_gradients=variables)\r\n>    ```\r\n>    \r\n>    \r\n>    contains only the variables corresponding to trainable layers) gives the error:\r\n>    `Placeholder head/depth_conv1024_12/depthwise_kernel should be specified by input_arrays.`\r\n> \r\n> Any help regarding this matter will be highly appreciated.\r\n\r\nCould you remove the variables from the following two lists in `__init__()` of `keras_head_model.py`? \r\n```python\r\nvariables = tfv1.global_variables()\r\n      self._variable_names = [variable.name for variable in variables]\r\n      self._initial_params = [variable.eval() for variable in variables]\r\n```", "> Yes, currently, model personalization doesn't support Functional API.\r\n\r\nSupport of Functional API in personalization layer is being easily achieved by changing line 124 in `keras_model_head.py` from `if key.endswith('_input')` to `if 'input' in key`. Or, it can be done by following @Egorovlvan 's suggestion.\r\n\r\n>  2. I understand that some layers like `DepthwiseConv2d` will not be converted since there is no support of `DepthwiseConv2dNativeBackpropFilter` and `DepthwiseConv2dNativeBackpropInput` in whitelisted flex ops. However, is it possible to freeze certain layers in the head model (example, freeze the depthwiseConv2d layer so that no backprop takes place)? I have tried the following:\r\n>     a) Made some layers as non-trainable in head model\r\n>    b) In the `train` function of the file `tfltransfer/heads/keras_model_head.py`, I used only the variables that are corresponding to the trainable layers for calculating `tf.gradients()` (i.e. variables in\r\n>    ```\r\n>    with tf.name_scope(scope + '/backprop'):\r\n>        gradients = tf.gradients(loss, variables, stop_gradients=variables)\r\n>    ```\r\n>    \r\n>    \r\n>    contains only the variables corresponding to trainable layers) gives the error:\r\n>    `Placeholder head/depth_conv1024_12/depthwise_kernel should be specified by input_arrays.`\r\n> \r\n\r\nIn regards to this, I have also made changes in `keras_model_head.py` and by introducing `train_variables`.\r\n\r\nBoth changes are reflected in PR [https://github.com/tensorflow/examples/pull/228](https://github.com/tensorflow/examples/pull/228)\r\n\r\n\r\n", "PR tensorflow/examples#228 is merged.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40247\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40247\">No</a>\n"]}]