[{"number": 6085, "title": "Tensorflow SVD inaccurate.  U is not orthogonal.", "body": "NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.\r\n\r\nFor general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\r\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed\r\nout of scope for GitHub Issues and point people to StackOverflow.\r\n\r\nFor bugs or installation issues, please provide the following information.\r\nThe more information you provide, the more easily we will be able to offer\r\nhelp and advice.\r\n\r\n### What related GitHub issues or StackOverflow threads have you found by searching the web for https://github.com/tensorflow/tensorflow/issues/2207\r\n\r\n### Environment info\r\nOperating System: Linux Mint 17.3 a.k.a. Ubuntu 14.04.4 LTS, Trusty Tahr\r\n\r\nInstalled version of CUDA and cuDNN: \r\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\r\nCUDA 7.5\r\ncuDNN 5.5\r\n-rw-r--r-- 1 root root 322936 Aug 15  2015 /usr/local/cuda/lib64/libcudadevrt.a\r\nlrwxrwxrwx 1 root root     16 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.7.5\r\nlrwxrwxrwx 1 root root     19 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18\r\n-rwxr-xr-x 1 root root 383336 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5.18\r\n-rw-r--r-- 1 root root 720192 Aug 15  2015 /usr/local/cuda/lib64/libcudart_static.a\r\n\r\nIf installed from binary pip package, provide:\r\n\r\n1. A link to the pip package you installed:\r\nexport TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.10.0-cp34-cp34m-linux_x86_64.whl\r\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\r\nkps3@newton ~ $ python3 -c \"import tensorflow; print(tensorflow.__version__)\"\r\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally\r\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally\r\n0.10.0\r\n\r\nIf installed from source, provide \r\n\r\n1. The commit hash (`git rev-parse HEAD`)\r\n2. The output of `bazel version`\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\n\r\nimport pickle\r\nimport tensorflow as tf\r\nimport numpy as np\r\n#pickle.dump( u_np, open( \"A.txt\", \"wb\" ) )\r\nA = pickle.load( open( \"A.txt\", \"rb\" ) )\r\n\r\nu_np, s, V = np.linalg.svd(A, full_matrices=False)\r\nnp.dot(np.transpose(u_np), u_np)\r\n#orthogonal in numpy\r\narray([[  1.00000024e+00,  -9.31322575e-09],\r\n       [ -9.31322575e-09,   1.00000036e+00]], dtype=float32)\r\n\r\n#analysis of orthogonality\r\nsess = tf.Session()\r\nA = tf.constant(A)\r\nS,U,V = tf.svd(A)\r\n#singular values look ok\r\nsess.run(S)\r\nu_np = sess.run(U)\r\nnp.dot(np.transpose(u_np), u_np)\r\n#This should give the identity but does not, indicating\r\n#U is not orthonormal\r\narray([[  9.99998868e-01,  -1.16007868e-07],\r\n       [ -1.16007868e-07,   1.00000167e+00]], dtype=float32)\r\n\r\n### What other attempted solutions have you tried?\r\nI need to obtain orthonormal vectors such as output by a QR decomposition.\r\nI have tried getting orthonormal vectors using the Cholesky operation to do a QR (still missing in tensorflow). \r\nL=Cholesky(A^T*A)\r\nU=A*L^-1\r\n In this case the matrix inverse operation introduces stochastic variation into a completely deterministic net with identity weights and the results is slightly not orthonormal.  Additionally using the tf.assign operation (to save L^-1) on the results of the L^-1 output from the cholesky actually changes its value.  tf.assign seems to work in other cases.\r\n\r\n### Logs or other output that would be helpful\r\n(If logs are large, please upload as attachment or provide link).\r\nThe following is the pickled matrix needed for the example\r\n\r\n[A.txt](https://github.com/tensorflow/tensorflow/files/630980/A.txt)\r\n", "comments": ["From your example it looks like numpy produces vectors that are orthogonal to 1 part in 10^8 (off-diagonal elements are   approx. -9e-09) and TensorFlow produces vectors that are orthogonal to 1 part in 10^7 (off-diagonal elements are approx. -1.2e-07). While differering by a factor of 10, both are _numerically_ very close to the identity, and certainly no cause for alarm. This is as good as one can expect in 32 bit floating point arithmetic. You can convert your tensors double (float64) if you want higher accuracy.\r\n\r\nBTW, a QR factorization op was recently added to TensorFlow, see this commit: https://github.com/tensorflow/tensorflow/commit/715f951eb9ca20fdcef20bb544b74dbe576734da"]}, {"number": 6084, "title": "Confused by the bottle_neck name in retrain tutorial and the inception-v3 model definition", "body": "Inception-v3 model definition link: https://github.com/tensorflow/models/blob/master/inception/inception/slim/inception_model.py\r\n\r\nThe 'retrain.py' tutorial link: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/image_retraining/retrain.py\r\n\r\n\r\nIn the retrain.py, I find the bottle_neck name of inception3 model is 'pool_3/_reshape:0' (line 95), but in the inception model definition file i can not find definition of 'pool3'.\r\n\r\nAlso I load the file 'http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz', and get the bottle_neck tensor by using name 'pool_3:0'. And it is a 4 dimension tensor instead of 2.\r\n\r\nWhat is the real name of bottle_neck tensor? Why can not find the bottle_name in model definition python file?\r\n\r\n", "comments": ["The inception model described in this file:\r\nhttps://github.com/tensorflow/models/blob/master/inception/inception/slim/inception_model.py\r\ncorresponds to this tar-ball\r\nhttp://download.tensorflow.org/models/image/imagenet/inception-v3-2016-03-01.tar.gz\r\n\r\nThe inception model employed by retrain.py here:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/image_retraining/retrain.py\r\nis a *different and older* version of the model. That model is\r\nhttp://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz\r\n", "Thank a lot. Besides, how to find the corresponding model definition of tar-ball and the model definition of the retrain.py?\r\n@shlens ", "@petewarden Pete, would you have know the corresponding model definition for the tar-ball version of Inception-v3 used by retrain.py?", "I download the inception-v3-2016-03-01.tar.gz and find the model file is 'model.ckpt-157585'.\r\nHowever, the model file in inception-2015-12-05.tgz is a '.pb' file named as 'classify_image_graph_def.pb'. \r\n\r\nIs the 'model.ckpt' model file created by slim while 'classify_image_graph_def.pb' not?\r\n If so, i think it is convenient to update 'retrain.py' according to the new definition of inception-v3 to avoid confusion. ", "The GraphDef file you need is currently not available from slim unfortunately. We should be able to do something similar to export_for_serving, but with `f.write(inference_graph.as_graph_def().SerializeToString())` to write out the correct file, but nobody's added that yet.", "Hi, thanks for your support guys. Is the file mentioned by @petewarden available now?\r\nWould be possible to tell please where I can find the mapping between the old layer/node/tensor names and the new ones? e.g. what's the corresponding tensor for \"pool_3/_reshape:0\"?", "The file is now available at https://storage.googleapis.com/download.tensorflow.org/models/inception_v3_2016_08_28_frozen.pb.tar.gz\r\n\r\nTo figure out the node names to use, try the summarize_graph tool:\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/graph_transforms#inspecting-graphs\r\n\r\nThis will tell you the input and output names, and the `--print_structure` flag will give you a full listing of all the nodes. If you look for the inputs to the final output node, you should be able to figure out the right layer name. If not, paste the output here and I can take a look.", "@petewarden Thanks! I could manage to make it work. ", "@AihamTaleb I have the same issue, but still couldn't figure out how to solve it. Could you share your solution? e.g. the corresponding tensor for \"pool_3/_reshape:0\"?", "@pronot Well, I didn't need the name of the corresponding tensor. For the model in this file: https://github.com/tensorflow/models/blob/master/inception/inception/slim/inception_model.py \r\n\r\nI did the following:\r\n\r\n- I constructed inception_v3 model only until the avg_pool layer. (Line 320). And then returned the net. This operation is the one that gives you the 2048 vector for each image. Because all consequent operations are related to the actual classification.\r\n- Then, you just have to call this function and pass a list of images as its inputs. However, you have to consider performing the same image preprocessing steps that were performed before the training procedure. I.e. you have to create Tf-records out of your test images list.\r\n- After creating the tf-records for your test set, convert it to a tensor. And just pass it as a parameter to the function inception_v3 you created in the first step.\r\n- Then you just have to evaluate the bottleneck tensor using a default session.\r\n\r\nActually, the flow of inference from the bottleneck layer I followed is very similar to the evaluation of inception shown in this file: \r\nhttps://github.com/tensorflow/models/blob/master/inception/inception/inception_eval.py\r\nBut instead of constructing the full graph, I constructed until the bottleneck (avg_pool).\r\n\r\nPlease let me know if you need more elaboration, and/or code snippets. ", "@aihamtaleb thanks for those tips. If you do have a code snippet sitting in a file somewhere, would be wonderful to be able to check it out as a gist.", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "Due to inactivity, I presume this issue is now resolved but please reopen otherwise."]}, {"number": 6083, "title": "Cuda Compute Capability 3.0 not supported on Windows?", "body": "Running on Windows 8.1, Python 3.5.2, Cuda 8.0\r\n\r\nname: GeForce GTX 660M\r\nmajor: 3 minor: 0 memoryClockRate (GHz) 0.95\r\npciBusID 0000:01:00.0\r\nTotal memory: 2.00GiB\r\nFree memory: 1.64GiB\r\n\r\nI c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:948] Ignoring visible gpu device (device: 0, name: GeForce GTX 660M, pci bus id: 0000:01:00.0) with Cuda compute capability 3.0. The minimum required Cuda capability is 3.5.", "comments": ["We currently build the PIP package for compute capabilities 3.5 and 5.2 by default. I just sent a PR to expand this to 3.0 (#6092)... if you want to try building it yourself, you could clone that PR and give it a try!", "Note that this support will soon be available in the nightly builds, and we'll cherry-pick it into the final release of 0.12."]}, {"number": 6082, "title": "0.12 Saver.restore broken? Unsuccessful TensorSliceReader constructor: Failed to find any matching files ", "body": "Here is the traceback:\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for model_epoch0_128_0.100_[200].ckpt-577569\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for model_epoch0_128_0.100_[200].ckpt-577569\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for model_epoch0_128_0.100_[200].ckpt-577569\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for model_epoch0_128_0.100_[200].ckpt-577569\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for model_epoch0_128_0.100_[200].ckpt-577569\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for model_epoch0_128_0.100_[200].ckpt-577569\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for model_epoch0_128_0.100_[200].ckpt-577569\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for model_epoch0_128_0.100_[200].ckpt-577569\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for model_epoch0_128_0.100_[200].ckpt-577569\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for model_epoch0_128_0.100_[200].ckpt-577569\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for model_epoch0_128_0.100_[200].ckpt-577569\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for model_epoch0_128_0.100_[200].ckpt-577569\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for model_epoch0_128_0.100_[200].ckpt-577569\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for model_epoch0_128_0.100_[200].ckpt-577569\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for model_epoch0_128_0.100_[200].ckpt-577569\r\nTraceback (most recent call last):\r\n  File \"validate.py\", line 163, in <module>\r\n    tf.app.run()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 43, in run\r\n    sys.exit(main(sys.argv[:1] + flags_passthrough))\r\n  File \"validate.py\", line 155, in main\r\n    model.saver.restore(session,i[:-5])\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 1388, in restore\r\n    {self.saver_def.filename_tensor_name: save_path})\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 766, in run\r\n    run_metadata_ptr)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 964, in _run\r\n    feed_dict_string, options, run_metadata)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1014, in _do_run\r\n    target_list, options, run_metadata)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1034, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.NotFoundError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for model_epoch0_128_0.100_[200].ckpt-577569\r\n\t [[Node: save/RestoreV2_12 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save/Const_0, save/RestoreV2_12/tensor_names, save/RestoreV2_12/shape_and_slices)]]\r\n\t [[Node: save/RestoreV2_7/_11 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_4_save/RestoreV2_7\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\r\n\r\nCaused by op u'save/RestoreV2_12', defined at:\r\n  File \"validate.py\", line 163, in <module>\r\n    tf.app.run()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 43, in run\r\n    sys.exit(main(sys.argv[:1] + flags_passthrough))\r\n  File \"validate.py\", line 148, in main\r\n    model = cnnW2v(opts, session)\r\n  File \"/nobackup/s1/nlip/hejunqing/tf-lstm-char-cnn-gpu/cnn_w2v.py\", line 152, in __init__\r\n    self.build_graph()\r\n  File \"/nobackup/s1/nlip/hejunqing/tf-lstm-char-cnn-gpu/cnn_w2v.py\", line 206, in build_graph\r\n    self.saver = tf.train.Saver()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 1000, in __init__\r\n    self.build()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 1030, in build\r\n    restore_sequentially=self._restore_sequentially)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 624, in build\r\n    restore_sequentially, reshape)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 361, in _AddRestoreOps\r\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 200, in restore_op\r\n    [spec.tensor.dtype])[0])\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_io_ops.py\", line 441, in restore_v2\r\n    dtypes=dtypes, name=name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 759, in apply_op\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op\r\n    original_op=self._default_original_op, op_def=op_def)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1128, in __init__\r\n    self._traceback = _extract_stack()\r\n\r\nNotFoundError (see above for traceback): Unsuccessful TensorSliceReader constructor: Failed to find any matching files for model_epoch0_128_0.100_[200].ckpt-577569\r\n\t [[Node: save/RestoreV2_12 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save/Const_0, save/RestoreV2_12/tensor_names, save/RestoreV2_12/shape_and_slices)]]\r\n\t [[Node: save/RestoreV2_7/_11 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_4_save/RestoreV2_7\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]\r\n\r\ntf version:\r\n0.12.0-rc0 \r\nIt is done on Debian Jessie with CUDA-8.0 and cudnn-5.1,using python 2.7\r\n\r\nThe model is in the directory,\r\nHere are the models in the directory:\r\nmodel_epoch0_128_0.100_[200].ckpt-577569.meta\r\nmodel_epoch1_128_0.100_[200].ckpt-1155138.meta\r\nmodel_epoch2_128_0.100_[200].ckpt-1732707.meta\r\nmodel_epoch3_128_0.100_[200].ckpt-2310276.meta\r\nmodel_epoch4_128_0.100_[200].ckpt-2887845.meta\r\nmodel_epoch0_128_0.100_[200].ckpt-577569.index\r\nmodel_epoch1_128_0.100_[200].ckpt-1155138.index\r\nmodel_epoch0_128_0.100_[200].ckpt-577569.data-00000-of-00001\r\nmodel_epoch1_128_0.100_[200].ckpt-1155138.data-00000-of-00001\r\nmodel_epoch2_128_0.100_[200].ckpt-1732707.data-00000-of-00001\r\nmodel_epoch2_128_0.100_[200].ckpt-1732707.index\r\nmodel_epoch3_128_0.100_[200].ckpt-2310276.data-00000-of-00001\r\nmodel_epoch3_128_0.100_[200].ckpt-2310276.index\r\nmodel_epoch4_128_0.100_[200].ckpt-2887845.data-00000-of-00001\r\nmodel_epoch4_128_0.100_[200].ckpt-2887845.index\r\nmodel_epoch5_128_0.100_[200].ckpt-3465414.data-00000-of-00001\r\nmodel_epoch5_128_0.100_[200].ckpt-3465414.index\r\nmodel_epoch5_128_0.100_[200].ckpt-3465414.meta\r\nmodel_epoch6_128_0.100_[200].ckpt-4042983.data-00000-of-00001\r\nmodel_epoch6_128_0.100_[200].ckpt-4042983.index\r\nmodel_epoch6_128_0.100_[200].ckpt-4042983.meta\r\nmodel_epoch7_128_0.100_[200].ckpt-4620552.data-00000-of-00001\r\nmodel_epoch7_128_0.100_[200].ckpt-4620552.index\r\nmodel_epoch7_128_0.100_[200].ckpt-4620552.meta\r\nmodel_epoch8_128_0.100_[200].ckpt-5198121.data-00000-of-00001\r\nmodel_epoch8_128_0.100_[200].ckpt-5198121.index\r\nmodel_epoch8_128_0.100_[200].ckpt-5198121.meta\r\nmodel_epoch9_128_0.100_[200].ckpt-5775690.data-00000-of-00001\r\nmodel_epoch9_128_0.100_[200].ckpt-5775690.index\r\nmodel_epoch9_128_0.100_[200].ckpt-5775690.meta\r\nmodel_epoch10_128_0.100_[200].ckpt-6353259.data-00000-of-00001\r\nmodel_epoch10_128_0.100_[200].ckpt-6353259.index\r\nmodel_epoch10_128_0.100_[200].ckpt-6353259.meta\r\nmodel_epoch11_128_0.100_[200].ckpt-6930828.data-00000-of-00001\r\nmodel_epoch11_128_0.100_[200].ckpt-6930828.index\r\nmodel_epoch11_128_0.100_[200].ckpt-6930828.meta\r\nmodel_epoch12_128_0.100_[200].ckpt-7508397.data-00000-of-00001\r\nmodel_epoch12_128_0.100_[200].ckpt-7508397.index\r\nmodel_epoch12_128_0.100_[200].ckpt-7508397.meta\r\nmodel_epoch13_128_0.100_[200].ckpt-8085966.data-00000-of-00001\r\nmodel_epoch13_128_0.100_[200].ckpt-8085966.index\r\nmodel_epoch13_128_0.100_[200].ckpt-8085966.meta\r\n\r\n", "comments": ["also the same error using import_meta_graph", "Can you fill in the issues template, and also give more details of what you were doing when the error occurred?", "Thank you.Michaelisard.\r\nI am trying to restore  the saved models trained yesterday,The saved models are listed as above but  can't be restored because of the NotFoundError. There is no warning or error when I saved models.\r\nI want to load each model and evaluate, not just the latest one.\r\n\r\n\r\nThe codes of restoring models are in validate.py below.The zip also includes my model.If there is anything that lead to the restore failure in model, please let me know.The doc about restore is quite brief.\r\nThanks!\r\n[validate_models.zip](https://github.com/tensorflow/tensorflow/files/633192/validate_models.zip)\r\n\r\n", "Could you try the following:\r\n1. use a model name without the character `[]`, and:\r\n2. when you tried to restore, use the full relative path `./model_epoch10` rather than `model_epoch10`\r\n\r\nIf my guess is right then you should see it work. It it doesn't, could you give the __steps__ so that people can reproduce the problem (i.e. how to use your code).", "@ppwwyyxx your advice help! \r\nI use the model name without [] and retrained models.Then they can be restore!\r\nI will add this special characters to DON'T USE list.\r\nThank you very much\r\n", "\"when you tried to restore, use the full relative path ./model_epoch10 rather than model_epoch10\"\r\nIt works, thank you", "Thank you @ppwwyyxx using the full path also works for me", "If anyone has some trouble with loading a checkpoint via saver.restore(), here is an alternative way I have working\r\n\r\nsaver = tf.train.import_meta_graph(name_of_the_meta_file)\r\n # create a session in which we can load the checkpoint values\r\nsess = tf.Session()\r\n# get checkpoint state\r\nckpt = tf.train.get_checkpoint_state(path_to_your_checkpoint)\r\n\r\n# restore session if both variables are not empty\r\nif ckpt and ckpt.model_checkpoint_path:\r\n    saver.restore(sess, ckpt.model_checkpoint_path)\r\n", "I met a problem \r\n\r\nINFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.NotFoundError'>, Unsuccessful TensorSliceReader constructor: Failed to find any matching files for ./object_detection/training/model.ckpt-0\r\n         [[Node: save/RestoreV2_901 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:ps/replica:0/task:0/device:CPU:0\"](_recv_save/Const_0_S1, save/RestoreV2_901/tensor_names, save/RestoreV2_901/shape_and_slices)]]\r\n         [[Node: save/restore_all/NoOp_S4 = _Recv[client_terminated=false, recv_device=\"/job:master/replica:0/task:0/device:CPU:0\", send_device=\"/job:ps/replica:0/task:0/device:CPU:0\", send_device_incarnation=5144029972012398702, tensor_name=\"edge_4518_save/restore_all/NoOp\", tensor_type=DT_FLOAT, _device=\"/job:master/replica:0/task:0/device:CPU:0\"]()]]\r\n\r\nCaused by op 'save/RestoreV2_901', defined at:\r\n  File \"/home/deeplearning/projects/Google/tensorflow/models/research/object_detection/train.py\", line 198, in <module>\r\n    tf.app.run()\r\n  File \"/home/deeplearning/virtualenv/python3/lib/python3.5/site-packages/tensorflow/python/platform/app.py\", line 48, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"/home/deeplearning/projects/Google/tensorflow/models/research/object_detection/train.py\", line 194, in main\r\n    worker_job_name, is_chief, FLAGS.train_dir)\r\n  File \"/home/deeplearning/projects/Google/tensorflow/models/research/object_detection/trainer.py\", line 281, in train\r\n    keep_checkpoint_every_n_hours=keep_checkpoint_every_n_hours)\r\n  File \"/home/deeplearning/virtualenv/python3/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1218, in __init__\r\n    self.build()\r\n  File \"/home/deeplearning/virtualenv/python3/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1227, in build\r\n    self._build(self._filename, build_save=True, build_restore=True)\r\n  File \"/home/deeplearning/virtualenv/python3/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1263, in _build\r\n    build_save=build_save, build_restore=build_restore)\r\n  File \"/home/deeplearning/virtualenv/python3/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 751, in _build_internal\r\n    restore_sequentially, reshape)\r\n  File \"/home/deeplearning/virtualenv/python3/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 427, in _AddRestoreOps\r\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\r\n  File \"/home/deeplearning/virtualenv/python3/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 267, in restore_op\r\n    [spec.tensor.dtype])[0])\r\n  File \"/home/deeplearning/virtualenv/python3/lib/python3.5/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1021, in restore_v2\r\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\r\n  File \"/home/deeplearning/virtualenv/python3/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/home/deeplearning/virtualenv/python3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\r\n    op_def=op_def)\r\n  File \"/home/deeplearning/virtualenv/python3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\n\r\nmy command is \r\npython ./object_detection/train.py --logtostderr --train_dir=/home/deeplearning/projects/Google/tensorflow/models/research/object_detection/training --pipeline_config_path=/home/deeplearning/projects/Google/tensorflow/models/research/object_detection/training/faster_rcnn_resnet101_coco.config\r\n\r\ni don't konw how to salve! anyone once met ?", "the problem is that running the command , the training_dir only 2 files \r\nmodel.ckpt-0.data-00000-of-00001\r\nmodel.ckpt-0.index", "This is the result I got although I employed virtual machine...\r\n\r\n![screenshot from 2018-08-08 15-25-00](https://user-images.githubusercontent.com/33311950/43840039-f2657e48-9b1f-11e8-8d36-ecbe5477d00f.png)\r\n", "Having the same issue.\r\n\r\nprint(os.listdir('/opt/ml/input/training'))   shows\r\n\r\n['snapshot-3.data-00000-of-00001', 'events.out.tfevents.1547818794.aws', 'snapshot-3.index', 'snapshot-3.meta', 'checkpoint', 'events.out.tfevents.1547818798.aws']\r\n\r\nwith tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\r\n            sess.run(tf.global_variables_initializer())\r\n            sess.run(tf.local_variables_initializer())\r\n\r\n            ckpt = tf.train.get_checkpoint_state(args.log_dir)\r\n\r\n            # Load the latest model\r\n            if ckpt and ckpt.model_checkpoint_path:\r\n            # Restores from checkpoint\r\n                saver.restore(sess, ckpt.model_checkpoint_path)\r\n            else:\r\n                return\r\n\r\nErr: /usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\r\n  from ._conv import register_converters as _register_converters\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1322, in _do_call\r\n    return fn(*args)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1307, in _run_fn\r\n    options, feed_dict, fetch_list, target_list, run_metadata)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1409, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Unsuccessful TensorSliceReader constructor: Failed to get matching files on /opt/ml/model/training/snapshot-3: Not found: /opt/ml/model/training; No such file or directory\r\n#011 [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\n\r\n\r\n\r\nAny suggestions?", "forgot to mention that\r\n\r\nargs.log_dir = '/opt/ml/input/training'", "i met the same problem\uff0cwhen i first restore the params\uff0cno problem accur\uff0cbut when i second restore the params\uff0cit cause this problem. After that, I referred to everyone's opinions, try to solve this problem, but failed. But when i put the load code befor my main code\uff0cthis problem is solved (for example, you can load params after import some packages and before your main class function).\r\n\r\n\u81ea\u5e26\u4e2d\u6587\u7ffb\u8bd1\uff0c\u5624\u5624\u5624\u3002\r\n\u4e4b\u524d\u6211\u4e5f\u9047\u5230\u4e86\u8fd9\u6837\u7684\u95ee\u9898\uff0c\u8bd5\u4e86\u4e0a\u9762\u7684\u8001\u54e5\u4eec\u63d0\u5230\u7684\u89e3\u51b3\u65b9\u6cd5\uff0c\u53d1\u73b0\u4e0d\u8d77\u4f5c\u7528\u3002\u56e0\u4e3a\u6211\u7684\u60c5\u51b5\u662f\uff0c\u6211\u80fd\u8bfb\u8fdb\u53bb\u4e4b\u524d\u4fdd\u5b58\u7684\u53c2\u6570\uff0c\u800c\u4e14\u4e5f\u80fd\u4f7f\u7528\u8fd9\u4e9b\u53c2\u6570\u5206\u7c7b\u6216\u8005\u9884\u6d4b\uff0c\u4f46\u662f\u6211\u7b2c\u4e8c\u6b21\u8bfb\u7684\u65f6\u5019\uff0c\u5c31\u62a5\u9519\uff0c\u5206\u6790\u4e86\u4e00\u4e0b\uff0c\u53d1\u73b0\u7b2c\u4e8c\u6b21\u8bfb\u7684\u65f6\u5019\uff0c\u53c2\u6570\u7684\u540d\u5b57\u90fd\u88ab\u4fee\u6539\u4e86\uff0c\u5bfc\u81f4\u627e\u4e0d\u5230\u3002\u6211\u731c\u6d4b\u53ef\u80fd\u662fsess\u7684\u7f18\u6545\uff0c\u6240\u4ee5\u628a\u8bfb\u53d6\u53c2\u6570\u7684\u90a3\u4e9b\u4ee3\u7801\u5168\u653e\u5230\u6700\u524d\u9762\uff0c\u4e3b\u51fd\u6570\u7684\u5916\u9762\u3002\r\n\r\nexample code\uff1a\r\nimport tensorflow as tf\r\n....\r\nclass Test:\r\n    saver.restore....\r\n\r\nyou can change it to:\r\n\r\nimport tensorflow as tf\r\nsaver.restore....\r\n....\r\nclass Test:\r\n    ", "Generally, the catalog of the model is incorrect."]}, {"number": 6081, "title": "How to restore training when MonitoredTrainingSession is used", "body": "I ran cifar10_train.py from [master branch](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/image/cifar10/cifar10_train.py). My  question is how to restore the checkpoint file in case that `MonitoredTrainingSession` is being used instead of `Session`. I have modified the code like this:\r\n```python\r\ndef train():\r\n  \"\"\"Train CIFAR-10 for a number of steps.\"\"\"\r\n  with tf.Graph().as_default():\r\n    global_step = tf.contrib.framework.get_or_create_global_step()\r\n\r\n    # Get images and labels for CIFAR-10.\r\n    images, labels = cifar10.distorted_inputs()\r\n\r\n    # Build a Graph that computes the logits predictions from the\r\n    # inference model.\r\n    logits = cifar10.inference(images)\r\n\r\n    # Calculate loss.\r\n    loss = cifar10.loss(logits, labels)\r\n\r\n    # Build a Graph that trains the model with one batch of examples and\r\n    # updates the model parameters.\r\n    train_op = cifar10.train(loss, global_step)\r\n\r\n    class _LoggerHook(tf.train.SessionRunHook):\r\n      \"\"\"Logs loss and runtime.\"\"\"\r\n\r\n      def begin(self):\r\n        self._step = -1\r\n\r\n      def before_run(self, run_context):\r\n        self._step += 1\r\n        self._start_time = time.time()\r\n        return tf.train.SessionRunArgs(loss)  # Asks for loss value.\r\n\r\n      def after_run(self, run_context, run_values):\r\n        duration = time.time() - self._start_time\r\n        loss_value = run_values.results\r\n        if self._step % 10 == 0:\r\n          num_examples_per_step = FLAGS.batch_size\r\n          examples_per_sec = num_examples_per_step / duration\r\n          sec_per_batch = float(duration)\r\n\r\n          format_str = ('%s: step %d, loss = %.2f (%.1f examples/sec; %.3f '\r\n                        'sec/batch)')\r\n          print (format_str % (datetime.now(), self._step, loss_value,\r\n                               examples_per_sec, sec_per_batch))\r\n\r\n    saver = tf.train.Saver()\r\n    with tf.train.MonitoredTrainingSession(checkpoint_dir=FLAGS.train_dir,\r\n                                           hooks=[tf.train.StopAtStepHook(last_step=FLAGS.max_steps),\r\n                                                  tf.train.NanTensorHook(loss),\r\n                                                  _LoggerHook()],\r\n                                           config=tf.ConfigProto(log_device_placement=FLAGS.log_device_placement),\r\n                                           save_checkpoint_secs=600,\r\n                                           save_summaries_steps=100) as mon_sess:\r\n        ckpt = tf.train.get_checkpoint_state(FLAGS.train_dir)\r\n        if ckpt and ckpt.model_checkpoint_path:\r\n            # Restores from checkpoint\r\n            saver.restore(mon_sess, ckpt.model_checkpoint_path)\r\n            # Assuming model_checkpoint_path looks something like:\r\n            #   /my-favorite-path/cifar10_train/model.ckpt-0,\r\n            # extract global_step from it.\r\n            global_step = ckpt.model_checkpoint_path.split('/')[-1].split('-')[-1]\r\n        while not mon_sess.should_stop():\r\n            mon_sess.run(train_op)\r\n\r\n\r\ndef main(argv=None):  # pylint: disable=unused-argument\r\n  # cifar10.maybe_download_and_extract()\r\n  # if tf.gfile.Exists(FLAGS.train_dir):\r\n  #   tf.gfile.DeleteRecursively(FLAGS.train_dir)\r\n  # tf.gfile.MakeDirs(FLAGS.train_dir)\r\n  # train()\r\n  cifar10.maybe_download_and_extract()\r\n  if not tf.gfile.Exists(FLAGS.train_dir):\r\n      tf.gfile.MakeDirs(FLAGS.train_dir)\r\n  train()\r\n```\r\nThe training variables seem to be restored, but the step variable still started from 0, how to make the step increases from the restored checkpoint step?\r\n", "comments": ["So I modified the code in `train()` like this, and it worked, but it's not a elegant way. Is there a better way to restore in MonitoredTrainingSession?\r\n```python\r\n  with tf.Graph().as_default():\r\n\r\n    ckpt = tf.train.get_checkpoint_state(FLAGS.train_dir)\r\n    global_step_init = -1\r\n    if ckpt and ckpt.model_checkpoint_path:\r\n        # Assuming model_checkpoint_path looks something like:\r\n        #   /my-favorite-path/cifar10_train/model.ckpt-0,\r\n        # extract global_step from it.\r\n        global_step_init = int(ckpt.model_checkpoint_path.split('/')[-1].split('-')[-1])\r\n        global_step = tf.Variable(global_step_init, name='global_step', dtype=dtypes.int64, trainable=False)\r\n    else:\r\n        global_step = tf.contrib.framework.get_or_create_global_step()\r\n\r\n    # Get images and labels for CIFAR-10.\r\n    images, labels = cifar10.distorted_inputs()\r\n\r\n    # Build a Graph that computes the logits predictions from the\r\n    # inference model.\r\n    logits = cifar10.inference(images)\r\n\r\n    # Calculate loss.\r\n    loss = cifar10.loss(logits, labels)\r\n\r\n    # Build a Graph that trains the model with one batch of examples and\r\n    # updates the model parameters.\r\n    train_op = cifar10.train(loss, global_step)\r\n\r\n    class _LoggerHook(tf.train.SessionRunHook):\r\n      \"\"\"Logs loss and runtime.\"\"\"\r\n\r\n      def begin(self):\r\n        self._step = global_step_init\r\n\r\n      def before_run(self, run_context):\r\n        self._step += 1\r\n        self._start_time = time.time()\r\n        return tf.train.SessionRunArgs(loss)  # Asks for loss value.\r\n\r\n      def after_run(self, run_context, run_values):\r\n        duration = time.time() - self._start_time\r\n        loss_value = run_values.results\r\n        if self._step % 1 == 0:\r\n          num_examples_per_step = FLAGS.batch_size\r\n          examples_per_sec = num_examples_per_step / duration\r\n          sec_per_batch = float(duration)\r\n\r\n          format_str = ('%s: step %d, loss = %.2f (%.1f examples/sec; %.3f '\r\n                        'sec/batch)')\r\n          print (format_str % (datetime.now(), self._step, loss_value,\r\n                               examples_per_sec, sec_per_batch))\r\n\r\n    saver = tf.train.Saver()\r\n    with tf.train.MonitoredTrainingSession(checkpoint_dir=FLAGS.train_dir,\r\n                                           hooks=[tf.train.StopAtStepHook(last_step=FLAGS.max_steps),\r\n                                                  tf.train.NanTensorHook(loss),\r\n                                                  _LoggerHook()],\r\n                                           config=tf.ConfigProto(log_device_placement=FLAGS.log_device_placement),\r\n                                           save_checkpoint_secs=600,\r\n                                           save_summaries_steps=100) as mon_sess:\r\n\r\n        ckpt = tf.train.get_checkpoint_state(FLAGS.train_dir)\r\n        if ckpt and ckpt.model_checkpoint_path:\r\n            # Restores from checkpoint\r\n            saver.restore(mon_sess, ckpt.model_checkpoint_path)\r\n        while not mon_sess.should_stop():\r\n            mon_sess.run(train_op)\r\n```\r\n", "This kind of usage question is better asked on (stackoverflow)[http://stackoverflow.com/questions/tagged/tensorflow].", "@CTTC have you got an answer for this? I'm after the same solution.", "In your initial post, you're confusing the logging output with the actual value of global_step. In your follow-up code, you're not taking advantage of the MonitoredTrainingSession's restoring of variables. I think you can get away with this:\r\n\r\n```\r\nckpt = tf.train.get_checkpoint_state(FLAGS.train_dir)\r\nglobal_step_init = -1\r\n# The correct value will be assigned with the restore.\r\n# The global step variable used by the optimizer (in cifar10.train()) \r\n# and I assume by whatever is using the Saver object (and more?).\r\nglobal_step = tf.contrib.framework.get_or_create_global_step()\r\nif ckpt and ckpt.model_checkpoint_path:\r\n        # This is only for the logger (e.g., it is not responsible for saving).\r\n        global_step_init = int(ckpt.model_checkpoint_path.split('/')[-1].split('-')[-1])\r\ntrainable=False)\r\n```", "The answer is actually pretty simple. If you want to further train the network, just increase `FLAGS.max_steps`. For example, if it was `100000` and you want to train up to `200000` then you only have to modify the flag. \r\n\r\nYou already removed the directory deletion part, so when you pass the `checkpoint_dir` as input to the monitored training session, it will automatically try to restore the latest saved checkpoint. Just increase the max_steps flag and you're good to go. ", "> So I modified the code in `train()` like this, and it worked, but it's not a elegant way. Is there a better way to restore in MonitoredTrainingSession?\r\n> \r\n> ```python\r\n>   with tf.Graph().as_default():\r\n> \r\n>     ckpt = tf.train.get_checkpoint_state(FLAGS.train_dir)\r\n>     global_step_init = -1\r\n>     if ckpt and ckpt.model_checkpoint_path:\r\n>         # Assuming model_checkpoint_path looks something like:\r\n>         #   /my-favorite-path/cifar10_train/model.ckpt-0,\r\n>         # extract global_step from it.\r\n>         global_step_init = int(ckpt.model_checkpoint_path.split('/')[-1].split('-')[-1])\r\n>         global_step = tf.Variable(global_step_init, name='global_step', dtype=dtypes.int64, trainable=False)\r\n>     else:\r\n>         global_step = tf.contrib.framework.get_or_create_global_step()\r\n> \r\n>     # Get images and labels for CIFAR-10.\r\n>     images, labels = cifar10.distorted_inputs()\r\n> \r\n>     # Build a Graph that computes the logits predictions from the\r\n>     # inference model.\r\n>     logits = cifar10.inference(images)\r\n> \r\n>     # Calculate loss.\r\n>     loss = cifar10.loss(logits, labels)\r\n> \r\n>     # Build a Graph that trains the model with one batch of examples and\r\n>     # updates the model parameters.\r\n>     train_op = cifar10.train(loss, global_step)\r\n> \r\n>     class _LoggerHook(tf.train.SessionRunHook):\r\n>       \"\"\"Logs loss and runtime.\"\"\"\r\n> \r\n>       def begin(self):\r\n>         self._step = global_step_init\r\n> \r\n>       def before_run(self, run_context):\r\n>         self._step += 1\r\n>         self._start_time = time.time()\r\n>         return tf.train.SessionRunArgs(loss)  # Asks for loss value.\r\n> \r\n>       def after_run(self, run_context, run_values):\r\n>         duration = time.time() - self._start_time\r\n>         loss_value = run_values.results\r\n>         if self._step % 1 == 0:\r\n>           num_examples_per_step = FLAGS.batch_size\r\n>           examples_per_sec = num_examples_per_step / duration\r\n>           sec_per_batch = float(duration)\r\n> \r\n>           format_str = ('%s: step %d, loss = %.2f (%.1f examples/sec; %.3f '\r\n>                         'sec/batch)')\r\n>           print (format_str % (datetime.now(), self._step, loss_value,\r\n>                                examples_per_sec, sec_per_batch))\r\n> \r\n>     saver = tf.train.Saver()\r\n>     with tf.train.MonitoredTrainingSession(checkpoint_dir=FLAGS.train_dir,\r\n>                                            hooks=[tf.train.StopAtStepHook(last_step=FLAGS.max_steps),\r\n>                                                   tf.train.NanTensorHook(loss),\r\n>                                                   _LoggerHook()],\r\n>                                            config=tf.ConfigProto(log_device_placement=FLAGS.log_device_placement),\r\n>                                            save_checkpoint_secs=600,\r\n>                                            save_summaries_steps=100) as mon_sess:\r\n> \r\n>         ckpt = tf.train.get_checkpoint_state(FLAGS.train_dir)\r\n>         if ckpt and ckpt.model_checkpoint_path:\r\n>             # Restores from checkpoint\r\n>             saver.restore(mon_sess, ckpt.model_checkpoint_path)\r\n>         while not mon_sess.should_stop():\r\n>             mon_sess.run(train_op)\r\n> ```\r\n\r\nI'm a little confused that why this statement `saver.restore(mon_sess, ckpt.model_checkpoint_path)` can take effect? As shown in Tensorflow official documentation, MonitoredTrainingSession can't be passed to saver. It will raise exception.\r\n![image](https://user-images.githubusercontent.com/18288851/58246146-e73bf000-7d88-11e9-8830-c0bd91d8389e.png)\r\n"]}, {"number": 6080, "title": "TF_Input and TF_Output", "body": "`TF_Input` and `TF_Output` were introduced in 0.12, and the graph and session APIs were updated accordingly. There are the following five functions right now:\r\n\r\n```c\r\nextern void TF_AddInput(TF_OperationDescription* desc, TF_Output input);\r\n\r\nextern void TF_AddInputList(TF_OperationDescription* desc,\r\n                            const TF_Output* inputs, int num_inputs);\r\n\r\nextern void TF_SessionRun(TF_Session* session,\r\n                          // RunOptions\r\n                          const TF_Buffer* run_options,\r\n                          // Input tensors\r\n                          const TF_Output* inputs,\r\n                          TF_Tensor* const* input_values, int ninputs,\r\n                          // Output tensors\r\n                          const TF_Output* outputs, TF_Tensor** output_values,\r\n                          int noutputs,\r\n                          // Target operations\r\n                          const TF_Operation* const* target_opers, int ntargets,\r\n                          // RunMetadata\r\n                          TF_Buffer* run_metadata,\r\n                          // Output status\r\n                          TF_Status*);\r\n\r\nextern void TF_SessionPRunSetup(TF_Session*,\r\n                                // Input names\r\n                                const TF_Output* inputs, int ninputs,\r\n                                // Output names\r\n                                const TF_Output* outputs, int noutputs,\r\n                                // Target operations\r\n                                const TF_Operation* const* target_opers,\r\n                                int ntargets,\r\n                                // Output handle\r\n                                const char** handle,\r\n                                // Output status\r\n                                TF_Status*);\r\n\r\nextern void TF_SessionPRun(TF_Session*, const char* handle,\r\n                           // Input tensors\r\n                           const TF_Output* inputs,\r\n                           TF_Tensor* const* input_values, int ninputs,\r\n                           // Output tensors\r\n                           const TF_Output* outputs, TF_Tensor** output_values,\r\n                           int noutputs,\r\n                           // Target operations\r\n                           const TF_Operation* const* target_opers,\r\n                           int ntargets,\r\n                           // Output status\r\n                           TF_Status*);\r\n```\r\n\r\nAssuming that there are no typos here, I am trying to understand how one should think about the `input` and `inputs` arguments of these functions as their corresponding types involve `TF_Output`, not `TF_Input`. Take `TF_SessionRun`, for instance. It is a bit confusing that both `inputs` and `outputs` are `TF_Output`. It would be great if somebody could explain the reasoning behind this. Thank you.\r\n\r\nRegards,\r\nIvan", "comments": ["FYI @josh11b @jhseu \r\n\r\n- `TF_Operation` refers to an operation in the graph, which can have multiple inputs and multiple outputs.\r\n- `TF_Output` identifies the one of possibly many outputs of an operation.\r\n- `TF_Input` identifies the one of possibly many inputs of an operation.\r\n\r\nFor example, the [QuantizedMatMul](https://github.com/tensorflow/tensorflow/blob/d0aac2b/tensorflow/core/ops/math_ops.cc#L2233) operation has 6 inputs and 3 outputs.  `TF_Input{op, 0}` refers to the input `a`, `TF_Input{op, 2}` refers to the input `min_a` etc. while `TF_Output{op, 0}` refers to output`out`, `TF_Output{op, 1}` refers to the output `min_out` etc.\r\n\r\n`TF_SessionRun` takes as feeds the outputs of some operations and returns as fetches the outputs of others. Thus `TF_Output` is used to identify both.\r\n\r\nHope that clarifies things. That said, any suggestions to improve the naming here are appreciated. Perhaps naming the arguments to `TF_SessionRun` etc. as `feeds` and `fetches` instead of `inputs` and `outputs` would help a bit?", "Yeah, perhaps we should rename the arguments to those functions. The main confusion (it was initially confusing to me too) is that outputs of nodes are inputs to other nodes, and the type refers to its role as the output and the variable name refers to its usage as input.\r\n\r\nWe're open to suggestions, but I can't think of anything that improves on the current naming. `feeds` and `fetches` only resolves the issue for the various `Run` functions.", "I was confused myself... and happened to come across this old issue searching about TF_SessionRun.\r\n\r\nIt seems TF_Output could have been called TF_OperationValue to choose a neutral name for the type, and then input/outputs are terms relative to TF_SessionRun.\r\n\r\nJust thought I'd share, even though this has been long closed.", "If its any incentive to find a solution, I was also confused by this."]}, {"number": 6079, "title": "Different Graphs on Tensorboard when running cifar10_train.py from master branch and r0.12 branch", "body": "I got different views of network graphs when running cifar10_train.py from [master branch](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/image/cifar10/cifar10_train.py) and [r0.12 bracnch](https://github.com/tensorflow/tensorflow/blob/r0.12/tensorflow/models/image/cifar10/cifar10_train.py).\r\n\r\nSo running cifar10_train.py from r0.12 gave a complete graph in which each layer like conv1 and conv2 are connected, just like this:\r\n\r\n[cifar10_train.py graph from r0.12 branch][1]\r\n\r\n\r\nBut running cifar10_train.py from master gave several graphs where each layer like conv1 and conv2 are not connected, just like this:\r\n\r\n[cifar10_train.py graph from master branch][2]\r\n\r\n\r\nI saw that cifar10_train.py from master branch used tf.train.MonitoredTrainingSession, is this a bug of this class or is this just what it is expected to generate?\r\n\r\n\r\n  [1]: https://i.stack.imgur.com/dk0zl.png\r\n  [2]: https://i.stack.imgur.com/NdAFs.png", "comments": ["You should probably ask this question on (stackoverflow)[http://stackoverflow.com/questions/tagged/tensorflow] since it's a Tensorboard usage question not a bug report.\r\n\r\nI am not entirely sure without seeing the running Tensorboard instances, but this may just be a result of the heuristic it uses to decide how to plot things. Notice that in the disconnected case conv1 has an input from shuffle_batch, and conv2 has an input from norm1, just as in the connected case. In the disconnected case if you click around e.g. conv2 is there an 'add to main graph' option? That might result in more what you are expecting."]}, {"number": 6078, "title": "Replace 0.12.0 deprecated functions in python, contrib, and models directories", "body": "Used [this script](https://github.com/samjabrahams/tensorcrack/blob/master/scripts/migrate_0.12/migrate.sh) to get initial changes, and then cleaned up using the diff.", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please.", "Whoops- misspelled `global_variables_initializer` as `global_variable_initializer`. Will fix when I get back to my rig.", "Ok, I fixed the `global_variables_initializer` typo. Additionally, I took out the changes to `python/kernel_tests/scalar_strict_test.py`, as the tests in it don't work with the new op. Finally, I noticed there were a few typos elsewhere with `global_variables_initializer` being spelled `global_variable_initializers` (extra 's' at the end), so I fixed those as well.", "Jenkins, test this please.", "Let me know if I should rebase. I don't _think_ the GPU failures were from these changes, but there may be lingering bugs from elsewhere.", "I don't think they are, but I will run them again once to make sure they are flakes.\r\nJenkins, test this please."]}, {"number": 6077, "title": "Replace deprecated function `all_variables()`", "body": "Replace deprecated function `all_variables()` with `global_variables()`", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->", "This change is made in #6078."]}, {"number": 6076, "title": "Session has been closed", "body": "using ubuntu 16.04 tensorflow 0.11\r\n\r\nInstalled from binary\r\nexport TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.11.0-cp27-none-linux_x86_64.whl\r\nsudo pip install --upgrade $TF_BINARY_URL\r\n\r\n\r\n### What other attempted solutions have you tried?\r\nI tried using version 0.12. But getting some other import errors for them\r\n\r\n### Logs or other output that would be helpful\r\n![sessionclosed](https://cloud.githubusercontent.com/assets/11742991/20874179/6a0f8006-bad5-11e6-9eb1-20d6c5e6c95a.png)\r\n", "comments": ["Can you give more details on what you were attempting when you got this error? It looks as if there was an exception in some file-reading code.", "Closing due to inactivity. It's possible that the code closed the file and tried to read from it again. Since the stack trace indicates threads are being used, it's possible that there's a bug in the user code. If the problem persists, please consider posting the code to [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) for community-driven support."]}, {"number": 6075, "title": "Fix sample code of embedding_viz", "body": "According to [projector_config.proto](https://github.com/tensorflow/tensorflow/blob/r0.12/tensorflow/contrib/tensorboard/plugins/projector/projector_config.proto), `single_image_dim` is also `SpriteMetadata` field.", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please", "This is same as #6321. Should I close this?", "Yes, it is the same as #6321 except that you are merging directly into the r0.12 release. @caisq, up to you if you want to cherry pick this into the r0.12 branch.\r\n\r\nThanks @sugyan for the contribution!", "We found a Contributor License Agreement for you (the sender of this pull request) and all commit authors, but as best as we can tell these commits were authored by someone else.  If that's the case,  please add them to this pull request and have them confirm that they're okay with these commits being contributed to Google.  If we're mistaken and you did author these commits, just reply here to confirm.\n\n<!-- need_author_consent -->", "@dsmilkov's added merge commit is fine for CLA."]}, {"number": 6074, "title": "Change base datasets dtype default to float32", "body": "So this following warning can be avoided in many examples:\r\n\r\n`WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.`", "comments": ["Aborting this since it seems like a lot of tests rely on this. Not important change. "]}, {"number": 6073, "title": "Add document for secure HDFS accessing", "body": "Improve HDFS accessing document and add document for secure HDFS accessing", "comments": ["Can one of the admins verify this patch?", "@jhseu Could you have a look?", "Jenkins, test this please"]}, {"number": 6072, "title": "Support to convert CudnnLSTM params to normal Weights and Bias", "body": "\r\nMy environment is Tensorflow r0.11, Linux 16.04, CUDA8.0, cuDNN5.1\r\n\r\nI am using the CudnnLSTM class  from tensorflow.contrib.cudnn_rnn , the training speed is really fast with about 5~6x speedup. However after training I need to move the model to an embeded system which is not CUDA based. So how can I convert the CudnnLSTM params to normal weights and bias. \r\n\r\nIs this feature still in plan or already have other solutions to this issue ?\r\n", "comments": ["Yes, it is being worked on. Adding zhangyaobit@.", "@robotnc Yes, we have checked in https://github.com/tensorflow/tensorflow/commit/ebcf0ee4e7e5541ffc418ca832223c409b9a2e57\r\n\r\nYou can use RNNParamsSaveable and your customized function canonical_to_params to restore the previously saved cuDNN parameters the way you need.\r\n\r\nPlease let us know how it goes. This will be very cool!", "Adding @ebrevdo, who is interested in this.", "@zhangyaobit Yeah, it looks cool. I think I need some time to recompile and have a try, because I am not so familiar with how to patch,compile and etc.\r\n\r\nAnd one more question, I see the function below:\r\n\r\n    def params_to_canonical(self, params):\r\n        \"\"\"Converts params from a specific format of cuDNN to the canonical format.\r\n        ...\r\n        return weights, biases\r\n\r\nIf the RNN is multi-layer, how can I get the weights and bias for each layer? Because I need to convert the model to an embedded system where a new model will be  re-contructed with each layer's weights and bias.", "@robotnc, as you see, the return values of params_to_canonical are weights and biases; they are stored in a layer-by-layer order.\r\n\r\nFor example, for LSTM, there are 8 matrices in each layer and the first 8 weight matrices stored in weights belong to the first layer; out of these 8 matrices, the first 4 matrices are applied to the input from the previous layer, and the second 4 matrices are applied to the recurrent input. Biases are stored in the same order.\r\n\r\nYou can write your canonical_to_params to take in weights and biases and output whatever data format you want for your model.\r\n\r\nPlease let me if anything is not clear.", "@zhangyaobit I succeed to run the code, and hope to know more detail about the weights structure.\r\nMy model is two layer LSTM with 128cells each, now I use params_to_cannoical(params) get the weights. The weights include 16 tensors inside, which I can see it like this:\r\n\r\n  weights = [W0,W1,W2,W3, ... W15], total 16 tensors in a list\r\n\r\nI assume that the first 8 tensors are for layer-0, and the last 8 tensors are for layer-1.\r\nHowever in each layer, we have 8 matrixes which are \r\n\r\n  W_f,W_o,W_c,W_i,R_f,R_o,R_c,R_i (f: forget gate, o: output gate, c: saved status, i: input gate)\r\n\r\nSo the question is what is the correct order(f, o, c, i) of these matrixes?\r\nFinally I need to convert the weights to be compatible with tf.nn.rnn_cell.BasicLSTMCell.\r\n\r\n![cudnn_lstm](https://cloud.githubusercontent.com/assets/18507467/21179737/5ff2233c-c230-11e6-8b57-6a73e92dfab0.png)\r\n", "I believe this is the answer you are looking for. \r\n\r\nExcerpt from \"4.105.\u00a0cudnnGetRNNLinLayerMatrixParams\" in the cuDNN documentation:\r\n\r\nIf mode in rnnDesc was set to CUDNN_LSTM values of 0-3\r\nreference matrix multiplications applied to the input from the\r\nprevious layer, value of 4-7 reference matrix multiplications\r\napplied to the recurrent input.\r\n\u2023 Values 0 and 4 reference the input gate.\r\n\u2023 Values 1 and 5 reference the forget gate.\r\n\u2023 Values 2 and 6 reference the new memory gate.\r\n\u2023 Values 3 and 7 reference the output gate.", "That\u2019s great! Thanks a lot!\n\n> \u5728 2016\u5e7412\u670819\u65e5\uff0c\u4e0b\u53483:19\uff0czhangyaobit <notifications@github.com> \u5199\u9053\uff1a\n> \n> I believe this is the answer you are looking for.\n> \n> Excerpt from \"4.105. cudnnGetRNNLinLayerMatrixParams\" in cuDNN guide:\n> \n> If mode in rnnDesc was set to CUDNN_LSTM values of 0-3\n> reference matrix multiplications applied to the input from the\n> previous layer, value of 4-7 reference matrix multiplications\n> applied to the recurrent input.\n> \u2023 Values 0 and 4 reference the input gate.\n> \u2023 Values 1 and 5 reference the forget gate.\n> \u2023 Values 2 and 6 reference the new memory gate.\n> \u2023 Values 3 and 7 reference the output gate.\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub <https://github.com/tensorflow/tensorflow/issues/6072#issuecomment-267897694>, or mute the thread <https://github.com/notifications/unsubscribe-auth/ARpmy3PgLXA_5c-dScbxzxG6FSd7sculks5rJjASgaJpZM4LDzUJ>.\n> \n\n", "@zhangyaobit I met another issue in Cudnn_LSTM about dropout, it seems the dropout didn't take effect. I have raised a new issue here, can you check it for me ?\r\nhttps://github.com/tensorflow/tensorflow/issues/6466", "If a layer is bidirectional, how are the 16 (8 * 2) matrices ordered ?", "I don't think being bidirectional affect the order; the same order is used. \r\n\r\nCould you clarify what 16, 8, and 2 respectively mean here?", "@zhangyaobit \r\nIf unidirectional, one layer has 8 matrices ordered like W_i,W_f,W_c,W_o,R_i,R_f,R_c,R_o.\r\nIf bidirectional, one layer will then have 16 matrices right, since we have a forward matrix and a backward matrix for each W_x or R_x, so my question is how are these 16 matrices ordered?\r\n\r\nIt can be appended like W^f_i, ...,R^f_o, W^b_i, ..., R^b_o\r\nor interleaved as W^f_i, W^b_i, ..., R^f_o, R^b_o\r\n^f: stand for forward matrix, ^b stand for backward matrix\r\n\r\nI am not sure which way is it organized (appending form, interleaving form, or some other form), and which direction is put first (forward first or backward first). Hope this clarifies my question.", "Also I found a bug @zhangyaobit. I am using params_to_canonical to export parameters.\r\n\r\nWhen my model is bidirectional, I always have this mistake\r\n\r\n> F tensorflow/contrib/cudnn_rnn/kernels/cudnn_rnn_ops.cc:550] Check failed: size == width * height Params size mismatch. Expected 100, got 1290\r\n\r\nHere my input size is 129, num_units is 10. But when I switch my model to unidirectional, there is no such mistake.\r\n\r\nI think the bug is in line 548.\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/cudnn_rnn/kernels/cudnn_rnn_ops.cc#L548-L550\r\n\r\nThe logic of this line is to use input_size as width for the first half parameters (W matrix), and num_units as width for the second half parameters (R matrix). But in bidirectional case, the param is probably not organized in the order of first W and then R, for example it can be W^f_x, R^f_x, W^b_x, R^b_x (f: forward, b: backward, x: stand for different gates).", "@boche Thanks for reporting the issue. Could you file a separate github issue on this? As the original issue of this thread has been resolved, I'm closing it now. Thanks.\r\n\r\nI will double check if bidirectional RNN is currently supported. Looks like not yet. https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/cudnn_rnn/python/kernel_tests/cudnn_rnn_ops_test.py#L148", "Hi @robotnc @zhangyaobit    \r\n\r\nIt's still confusing for me that how cudnn lstm put the weights.   \r\nMy case is a layer of cudnn lstm with input 1024-dim feauture and hidden state size is 512.\r\nThe shape of cudnn lstm param matrix is  (512, 6152)\r\n\r\nAccording to the previous comments, I notice that the order of gates are [I,F,C,O], but how is the order of weights and bias? [W W W W W W W W B B B B B B B B] or [W B W B W B W B W B W B W B W B ] ?\r\n\r\nIf it is like [Wi, Wf, Wc, Wo, Ri, Rf, Rc, Ro, Bwi, Bwf, Bwc, Bwo, Bri, Brf, Brc, Bro],\r\nthen the codes should be\r\n \r\n```\r\n        input_size = 1024\r\n        hidden_size = 512     \r\n        input_w_ifco = trained_weights[:,  0 :4*input_size]\r\n        hidden_w_ifco = trained_weights[:, 4*input_size: 4*input_size + 4*hidden_size]\r\n        input_b_ifco = trained_weights[:, 4*input_size + 4*hidden_size: 4*input_size + 4*hidden_size + 4]\r\n        hidden_b_ifco = trained_weights[:, 4*input_size + 4*hidden_size + 4 : 4*input_size + 4*hidden_size + 8]\r\n```\r\n\r\nOr if it is like [Wi, Wf, Wc, Wo, Bwi, Bwf, Bwc, Bwo, Ri, Rf, Rc, Ro, Bri, Brf, Brc, Bro]\r\n\r\n```\r\n        input_size = 1024\r\n        hidden_size = 512\r\n        input_w_ifco = trained_weights[:,  0 :4*input_size]\r\n        input_b_ifco = trained_weights[:, 4*input_size: 4*input_size+ 4]\r\n        hidden_w_ifco = trained_weights[:, 4*input_size + 4: 4*input_size + 4 + 4*hidden_size]\r\n        hidden_b_ifco = trained_weights[:, 4*input_size + +4 +4*hidden_size : 4*input_size + + 4 + 4*hidden_size + 4]\r\n```\r\n\r\nMany thanks !"]}, {"number": 6071, "title": "[Feature request] To add the ability to use own data during the training a RNN network for translation by the translate.py script", "body": "Right now the script [translate.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/rnn/translate/translate.py) does not allow to use own data for training. At the moment it works only with the data, that the script downloads from the Internet (en/fr). Also there is not any documentation on the format of the input data that it expects in the input. In order to have the ability to train the model with own data 2 changes need to be made to the script:\r\n* to document the format of the input data;\r\n* enable the ability to pass an own input file path via the script arguments, the file path should be used for training instead of downloading the data from the internet.", "comments": ["The [source of the training data](http://www.statmt.org/wmt10/translation-task.html) has some information about the file format and some parsing tools.\r\n\r\nFor the ability to pass in your own data, we may not get to it immediately but I have marked it contributions welcome. @girving ", "I'm working on the version that will allow to train a model with any pair of languages, and planning to start sending PR upcoming weekends.", "FYI I believe these models are being moved into a new repository to clearly separate library code from examples.  @nealwu ", "vrv@ in the light of new information I have 2 questions:\r\n- could you point me to the correct repo with the examples?\r\n- can I remove code from here, in order to avoid further confusion? ", "You'll have to ask @nealwu ", "@b0noI: We're in the process of moving this file to https://github.com/tensorflow/models in a folder that will be called 'tutorials', which you should see soon. The file contents will remain largely the same though, so feel free to base off of the current file.", "FYI, as of a few days ago this code is now sitting in https://github.com/tensorflow/models/tree/master/tutorials. I'm going to close this issue since it no longer applies to this repo."]}, {"number": 6070, "title": "tf.contrib.learn.LinearRegressor builds bad model for a data with one feature", "body": "Reproduce steps:\r\n\r\n[csv with data](http://%22https//vincentarelbundock.github.io/Rdatasets/csv/car/Davis.csv%22). Data includes weight and height values of some people. Overall learning process is very simple:\r\n\r\n```\r\nMAX_STEPS = 2000\r\n# ...\r\nfeatures = [tf.contrib.layers.real_valued_column(feature_name) for feature_name in FEATURES_COL]\r\n# ...\r\nlinear_regressor = tf.contrib.learn.LinearRegressor(feature_columns=features)\r\nlinear_regressor.fit(input_fn=prepare_input, max_steps=MAX_STEPS)\r\n```\r\n\r\nHowever, the model that is built by the regressor is, unexpectedly, bad. Result could be illustrated with the next picture: \r\n<img width=\"556\" alt=\"umbhj\" src=\"https://cloud.githubusercontent.com/assets/554101/20871476/1aaa1f42-ba4b-11e6-84cb-3bb5f3544f1a.png\">\r\nVisualization code(just in case):\r\n```\r\nplt.plot(height_and_weight_df_filtered[WEIGHT_COL], \r\n         linear_regressor.predict(input_fn=prepare_full_input), \r\n         color='blue',\r\n         linewidth=3)\r\n```\r\nWhy I think the model is bad? Here is the same data been given to the LinearRegression class from the scikit-learn:\r\n\r\n```\r\nlr_updated = linear_model.LinearRegression()\r\nlr_updated.fit(weight_filtered_reshaped, height_filtered)\r\n```\r\n\r\nAnd the visualization: \r\n\r\n<img width=\"548\" alt=\"gi1ui\" src=\"https://cloud.githubusercontent.com/assets/554101/20871501/5949a3e4-ba4b-11e6-970c-d5afaf002b85.png\">\r\n\r\nIncreasing amount of steps has no effect. I would assume I'm using regressor from the TensorFlow in a wrong way.\r\n\r\n[iPython notebook with the code.](https://storage.googleapis.com/stackoverflow-b0noi/Intro%2Bwith%2BTensorFlow.ipynb)\r\n\r\nEnv details\r\n\r\n1. A link to the pip package you installed:\r\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\r\n0.11.0rc0\r\n\r\n### What other attempted solutions have you tried?\r\n\r\nThe issue was opened originally as a question on the [stackoverflow](http://stackoverflow.com/questions/40734394/tf-contrib-learn-linearregressor-builds-unexpectedly-bad-model-for-a-data-with-o).", "comments": ["This type of question is better asked on [stackoverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it's a usage question rather than a bug report.", "closing the issue until I have confirmation that there is no mistake in the way of how I'm using the Regressor. If there is no mistakes in the usage logic, then there is an issue with TF."]}, {"number": 6069, "title": "R0.12", "body": "", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->", "Looks like a misoperation. Closing PR.", "Sorry. I don't know what is pull request.\n\nSent from my iPhone 7Plus Jet Black\n\nOn Dec 5, 2016, at 9:39 AM, Shanqing Cai <notifications@github.com<mailto:notifications@github.com>> wrote:\n\n\nLooks like a misoperation. Closing PR.\n\n-\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub<https://github.com/tensorflow/tensorflow/pull/6069#issuecomment-264869991>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AXP1TOYHogxGcODVSJxqQo1dkMeI4yJ8ks5rFCIagaJpZM4LDukl>.\n"]}, {"number": 6068, "title": "RNN Tutorial Code cant find sample data", "body": "Followed the directions here on my mac\r\nhttps://www.tensorflow.org/versions/master/tutorials/recurrent/index.html#recurrent-neural-networks\r\n\r\n```\r\ncd tensorflow/models/rnn/ptb\r\npython ptb_word_lm.py --data_path=/tmp/simple-examples/data/ --model small\r\n```\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"ptb_word_lm.py\", line 368, in <module>\r\n    tf.app.run()\r\n  File \"/Users/shleifer/flow/kensho-learn/kml/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 43, in run\r\n    sys.exit(main(sys.argv[:1] + flags_passthrough))\r\n  File \"ptb_word_lm.py\", line 315, in main\r\n    raw_data = reader.ptb_raw_data(FLAGS.data_path)\r\n  File \"/Users/shleifer/flow/kensho-learn/kml/lib/python2.7/site-packages/tensorflow/models/rnn/ptb/reader.py\", line 73, in ptb_raw_data\r\n    word_to_id = _build_vocab(train_path)\r\n  File \"/Users/shleifer/flow/kensho-learn/kml/lib/python2.7/site-packages/tensorflow/models/rnn/ptb/reader.py\", line 34, in _build_vocab\r\n    data = _read_words(filename)\r\n  File \"/Users/shleifer/flow/kensho-learn/kml/lib/python2.7/site-packages/tensorflow/models/rnn/ptb/reader.py\", line 30, in _read_words\r\n    return f.read().decode(\"utf-8\").replace(\"\\n\", \"<eos>\").split()\r\n  File \"/Users/shleifer/flow/kensho-learn/kml/lib/python2.7/site-packages/tensorflow/python/lib/io/file_io.py\", line 106, in read\r\n    self._preread_check()\r\n  File \"/Users/shleifer/flow/kensho-learn/kml/lib/python2.7/site-packages/tensorflow/python/lib/io/file_io.py\", line 73, in _preread_check\r\n    compat.as_bytes(self.__name), 1024 * 512, status)\r\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/contextlib.py\", line 24, in __exit__\r\n    self.gen.next()\r\n  File \"/Users/shleifer/flow/kensho-learn/kml/lib/python2.7/site-packages/tensorflow/python/framework/errors_impl.py\", line 469, in raise_exception_on_not_ok_status\r\n    pywrap_tensorflow.TF_GetCode(status))\r\ntensorflow.python.framework.errors_impl.NotFoundError: /tmp/simple-examples/data/ptb.train.txt\r\n```\r\n\r\nVersions:\r\n\r\ntensorflow==0.12.0rc0\r\n\r\n\r\n\r\nI think I am missing something simple. Where should the data directory be? thanks\r\n", "comments": ["You can just cd to the directory where you put the code files, and run the following command:\r\n`wget http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz`\r\n`tar xvf simple-examples.tgz`\r\n`python ptb_word_lm.py --data_path=simple-examples/data/`\r\nThis gets the code to find the data file. However, you may find the code is still not executable and reports new errors like \"module does not have an attribute 'deprecate' \". ", "maybe deprecated?", "yeah i figured it out fee free to close\nOn Tue, Dec 20, 2016 at 7:24 AM xusong2008 <notifications@github.com> wrote:\n\n> maybe deprecated?\n>\n>\n>\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/6068#issuecomment-268230451>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AFw9YVaohwrvtgItXh985VzeGp4Z07rPks5rJ8kLgaJpZM4LDq0V>\n> .\n>\n>\n>\n>\n>\n>\n>\n>\n>\n>\n>\n>\n>\n>\n>\n>\n>\n>\n>\n", "@wolffg  could we update this in the docs to not have \"/tmp\" in the example command line maybe just \"simple-examples/...\" so that it is clear it is relative from where you tar xvfz'd it (maybe add a comment)\r\n", "Solved by getting rid of the the first forward slash in the directory i.e. changing \r\n\r\n`--data_path=/tmp/simple-examples/data/` \r\n\r\nto \r\n\r\n`--data_path=tmp/simple-examples/data/` \r\n\r\nthx @aselle ", "Thank you @chrisrytting  @aselle ", "I updated this for clarity, please see #9059."]}, {"number": 6067, "title": "Improve severly lacking Trainable.fit() documentation", "body": "I'm a beginner, some questions that came to mind after reading it multiple times:\r\n\r\n- Give examples of x and y, I never got those to work. It either breaks because they have no \"dtype\" or complains that I should use input_fn instead.\r\n- Are x/y supposed to be tensors?\r\n- When is input_fn called?\r\n- If input_fn returns some kind of \"queue\" how is it used?\r\n- What would you actually expect a \"step\" to do? (Needed to know estimate a good value of \"steps\")\r\n- How many training examples does each step consume/look at?\r\n- Why can't batch_size be specified together with input_fn?\r\n- What does batch_size actually do? What is a batch?\r\n- Do you always want to do training with limited batch size?\r\n\r\nThanks.", "comments": ["Sorry you're having a hard time.  I've been through that too.\r\n\r\nThis forum is for bug reports, not use questions, which are better addressed on stackoverflow.\r\n\r\nIf the documentation is poor, that counts as a bug, but in this case the python documentation for learn.Trainable.fit is on a consistent level of detail with the documentation throughout.  It sounds like you need a gentle introduction to TensorFlow, because your questions are largely about basic concepts.  I would suggest working through some of the basic tutorials first, like maybe https://www.tensorflow.org/versions/r0.10/tutorials/mnist/tf/index.html\r\n\r\nA confusing aspect of TensorFlow is that one typically defines programs in python, but most of the real computation happens in a C++ -built backend runtime.   The python program execution builds up an Op graph, then passes it to the backend along with input data, requests execution, and waits for the result.  Usually a 'step' is a single iteration of running the TensorFlow Op graph for some inputs and updating any parameters that are being trained.  In the backend all input/output values are Tensors, but in the python program they are python data types, which sometimes but not always correspond to Tensors or Ops in the backend.  After working through some tutorials, hopefully this will start to make more sense.\r\n\r\n\r\n", "I've already been introduced to TF so I would say that I'm aware of the absolute basics and the things you mention here. You can consider this a bug report of the fit() documentation, rather than a problem I am specifically having. I'm already using fit() today, but mostly through trial and error. I've read most of the TF documentation without finding many examples or explanations that answers my questions, that could improve my use of fit().\r\n\r\nI don't think fit() is on a \"consistent level of detail with the documentation throughout\", unless you  measure consistency in something trivial like \"same amount of characters\". Even in that case I think it should not just be that, it should be great in general.\r\n\r\nIn my opinion any API should carefully document:\r\n- Guarantees\r\n- Constraints\r\n- Intended use\r\n- Important design motivations and historical changes\r\n\r\nConsidering how important fit() actually is for users to easily implement ML, I can see that it easily need twice as much detail. I think most people would currently need plenty of context to just understand some of the phrases used in the documentation.\r\n\r\nHere's some examples:\r\n\r\n      x: Matrix of shape [n_samples, n_features...] or the dictionary of Matrices.\r\n         Can be iterator that returns arrays of features or dictionary of arrays of features.\r\n         The training input samples for fitting the model. If set, `input_fn` must be `None`.\r\n\r\nWhat's n_samples and n_features? Why the ... and how is it obvious how that sequence would continue? What's \"the dictionary of Matrices\"? Where is that term defined? Why \"arrays of features\" and not just \"an array of features\"? Do you mean \"iterator over arrays of features\"? Can the iterator also return a dictionary or do you mean that x can also be a dictionary? Why is that in the same sentence? What is the key in the mentioned dictionaries, how are they indexed? When it says \"The training input samples for fitting the model.\" what exactly is an \"input sample\" and what is it not? Is it a feature or a label? What actual datatypes/values is acceptable for an input matrix contains?\r\n\r\nThroughout the documentation there is also no specified reason why both \"x\" and \"input_fn\" exists. Is x just a historical artifact? Should you always use an input_fn? What is the purpose of \"x\" if you can have an \"input_fn\"?\r\n\r\nThat's just the first argument, I could continue, but I think this makes my point clear. Note that I can probably make an educated guess and be right for some of these questions. But I think the documentation should be better than that. I think the documentation should be clear enough that usage doesn't require guesswork or dissecting examples.\r\n\r\nI could accept the argument that the documentation is so general and context-full because the trainable class itself is so general that it's hard to be specific. But in this case classes like DNNRegressor need to have their own documentation on their fit() implementation and not just refer to the trainable documentation.\r\n\r\nThat said, I could have missed some topic that describe fit() better. I might also have unrealistic expectations. I apologize if that is the case.", "Your expectations are not unrealistic, but we are talking about a component in contrib. Its interface is still evolving (you'll see that looking at head), and its documentation is not complete. You can use the examples in the tutorials section as a starting point, for example:\r\nhttps://www.tensorflow.org/versions/r0.12/tutorials/tflearn/index.html#fit-dnnclassifier\r\nhttps://www.tensorflow.org/versions/r0.12/tutorials/input_fn/index.html#building-input-functions-with-tf-contrib-learn\r\n\r\nx and y are supposed to be numpy arrays, or dictionaries of numpy arrays. If you use an input_fn, the return values of said function should be dictionaries of tensors containing a single batch of data when evaluated.\r\n\r\nI will close this bug, we will rework the documentation soon."]}, {"number": 6066, "title": "Fix rnn cell scope bug in _linear", "body": "The optional `scope` argument of `_linear` is currently ignored, as explained here: https://github.com/tensorflow/tensorflow/issues/6065\r\n\r\nThis pull request should fix that bug.", "comments": ["Can one of the admins verify this patch?", "@rdipietro - Made the same fix in #6009. :)", "Oh ok. Closing this pull request. Leaving https://github.com/tensorflow/tensorflow/issues/6065 open."]}, {"number": 6065, "title": "Bug: _linear's optional scope argument is ignored", "body": "Here is the relevant code from https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/rnn_cell_impl.py\r\n\r\n```\r\ndef _linear(args, output_size, bias, bias_start=0.0, scope=None):\r\n  # ...\r\n  scope = vs.get_variable_scope()\r\n  with vs.variable_scope(scope) as outer_scope:\r\n    # ...\r\n```", "comments": ["Update: A fix was proposed a few days ago in https://github.com/tensorflow/tensorflow/pull/6009\r\n\r\nLeaving this open until that fix is accepted.", "From #6009 \"It is hidden for a reason; you should not be using it. Use tf.contrib.layers.linear instead. The scope argument will be removed soon.\""]}, {"number": 6064, "title": "AttributeError: module 'tensorflow.contrib.slim' has no attribute 'nets'", "body": "### Environment info\r\nOperating System:` Mac os x 10.10`\r\n\r\n1. A link to the pip package you installed: `https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.12.0rc0-py3-none-any.whl`\r\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`:  `0.12.0-rc0`\r\n\r\n### reproducible example\r\n\r\n    import tensorflow as tf\r\n    import tensorflow.contrib.slim as slim\r\n    from tensorflow.examples.tutorials.mnist import input_data\r\n    vgg = tf.contrib.slim.nets.vgg\r\n\r\n    mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\r\n    x = tf.placeholder(\"float\", shape=[None, 784])\r\n    y_ = tf.placeholder(\"float\", shape=[None, 10])\r\n    pred = vgg.vgg16(x)\r\n\r\n    cross_entropy = -tf.reduce_sum(y_ * tf.log(pred))\r\n\r\n\r\n\r\n### Error Message:\r\n\r\n    Traceback (most recent call last):\r\n    File \"resnet.py\", line 4, in <module>\r\n    vgg = tf.contrib.slim.nets.vgg\r\n    AttributeError: module 'tensorflow.contrib.slim' has no attribute 'nets'\r\n", "comments": ["Where did you come up with this example, and why do you expect it to work?  \r\n\r\nSee https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/slim/nets.py\r\nand\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/slim/python/slim/nets/vgg.py\r\n\r\nMaybe you don't have all of slim installed? Or maybe the name usage has to be slightly different?  (This is really outside of my area of familiarity.)\r\n", "@poxvoculi  Hi Paul, thanks for your reply. Here is the [example](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim#training-models).", "The problem is caused by the fact that https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/slim/__init__.py does not export `nets`.\r\n\r\nHowever, you can get around you problem by explicitly importing `nets`, adding the `> marked line <`:\r\n```python\r\nimport tensorflow as tf\r\nimport tensorflow.contrib.slim as slim\r\n> import tensorflow.contrib.slim.nets <\r\nfrom tensorflow.examples.tutorials.mnist import input_data\r\nvgg = tf.contrib.slim.nets.vgg\r\n```", "@foxik Thanks for your reply! It solves my problem perfectly!", "@foxik I receive a syntax error running your code, what kind of syntax is that? \r\n`    > import tensorflow.contrib.slim.nets <\r\n    ^\r\n\r\nSyntaxError: invalid syntax\r\n`", "@paolov The correct line is of course\r\n```python\r\nimport tensorflow.contrib.slim.nets\r\n```\r\nthe `>` and `<` are just meant as visual notification, sorry if it unclear.", "@rylanchiu I have got error like this:\r\n```\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-12-647e80c0237f> in <module>()\r\n     25 \r\n     26   # Define the model:\r\n---> 27   predictions = vgg.vgg16(images, is_training=True)\r\n     28 \r\n     29   # Specify the loss function:\r\n\r\nAttributeError: module 'tensorflow.contrib.slim.python.slim.nets.vgg' has no attribute 'vgg16'\r\n```\r\nMy tf.__version__ is 1.3.0", "I have the same problem, any idea to solve it?", "Looks like there's a name error in the README, and the function you want is actually vgg_16:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/slim/python/slim/nets/vgg.py#L139"]}, {"number": 6063, "title": "AttributeError: 'module' object has no attribute 'deprecated'", "body": "### Environment info\r\nOperating System: Ubuntu 14.04.5 LTS\r\n\r\nInstalled version of CUDA and cuDNN: \r\nNo CUDA, I use CPU-only.\r\n\r\n* Pip version: pip 1.5.4\r\n* Python version: 2.7.6\r\n* Operating System: Ubuntu 14.04.5 LTS\r\n* Tensorflow version: tensorflow-0.12.0rc0-cp27-none-linux_x86_64 , CPU-only\r\n### Description:\r\n\r\nI was testing the tutorial example of LSTM [here](https://www.tensorflow.org/versions/r0.12/tutorials/recurrent/index.html). \r\nI followed the instructions to download the code and dataset, and run the program using the command. But the code cannot execute and reports the error message:\r\n`  File \"ptb_word_lm.py\", line 332, in main\r\n    tf.contrib.deprecated.scalar_summary(\"Training Loss\", m.cost)`\r\n`AttributeError: 'module' object has no attribute 'deprecated'`\r\n### What I've run:\r\n\r\nI just ran the following commands:\r\n`wget http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz`\r\n`tar xvf simple-examples.tgz`\r\n`python ptb_word_lm.py --data_path=simple-examples/data/`\r\n\r\nI download the code from the [github repository](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/models/rnn). \r\nMy tensorflow version is the very latest tensorflow-0.12.0rc0-cp27-none-linux_x86_64.\r\nWhy can't I run this example?\r\nThank you all for your kind help!!!\r\n\r\n", "comments": ["I am trying to work through the same issue right now. Have you had any luck finding a solution?", "Probably not the best solution but once I commented out lines that had tf.contrib.deprecated in it the code ran. \r\n\r\nI am not sure what those lines of code do so use this solution at your own risk. ", "Might have some version skew here (@danmane).  As a temporary fix, try removing just the \"contrib.deprecated\" parts leaving just tf.scalar_summary instead.  \r\n", "I also tried to comment the \"contrib.deprecated\". But this leads to another error message saying\"\r\n`File \"/d2/fpengaa/work/learntf/lstm-ptb/reader.py\", line 100, in ptb_producer\r\n    with tf.name_scope(name, \"PTBProducer\", [raw_data, batch_size, num_steps]):`\r\n`TypeError: name_scope() takes exactly 1 argument (3 given)`\r\nMoreover, I used to get another error saying \r\n`AttributeError: 'module' object has no attribute 'ptb_producer'`\r\nI learned that to rectify this error, I have to change the import:\r\n`from tensorflow.models.rnn.ptb import reader`\r\nto\r\n`import reader`\r\nThen I succeeded in rectifying the last error. Though this error seems not related to my current question, it did make me to think whether it is because the code in the github repository has been updated by the developers but the tutorial has not been updated accordingly. Since the problem happens on the \"import\" is obviously because the version has been changed, not because the implementation has errors.\r\nAnyway, thank you all for helping me, and should you have some progress in solving this problem, please kindly share your solution.\r\nThank you very much!!!", "It seems I have got the solution. It's just, abort the version r0.12 and install the version \"master\", which is r0.11. \r\nThen, replace the line \r\n`from tensorflow.models.rnn.ptb import reader`\r\nwith\r\n`import reader`\r\nAnd then comment all the lines containing the \"deprecated\".\r\nCurrently, only in this way can the program run correctly.\r\nI think the reasons may be that the tutorial and the latest version of tensorflow, somehow do not match perfectly. I hope my problem and solution may help a little.\r\nThank you all for helping me.", "I meet the same question after install version-r0.12.\r\nI ran the cifar10_muti_gpu_train.py and get this message: \r\nAttributeError: 'module' object has no attribute 'deprecated'", "tf.contrib.deprecated.scalar_summary -> tf.scalar_summary -> tf.summary.scalar\r\n???", "Try to use tf.summary.scalar: https://github.com/tensorflow/tensorflow/blob/cb17d1b0e2b581b5da1d9597b7929ba764749d38/tensorflow/tools/compatibility/tf_upgrade.py", "why? I'm\r\nThen, replace the line\r\nfrom tensorflow.models.rnn.ptb import reader\r\nwith\r\nimport reader\r\n\r\nbut \r\nTraceback (most recent call last):\r\n  File \"ptb_word_lm.py\", line 367, in <module>\r\n    tf.app.run()\r\n  File \"/Library/Python/2.7/site-packages/tensorflow/python/platform/app.py\", line 30, in run\r\n    sys.exit(main(sys.argv))\r\n  File \"ptb_word_lm.py\", line 327, in main\r\n    train_input = PTBInput(config=config, data=train_data, name=\"TrainInput\")\r\n  File \"ptb_word_lm.py\", line 93, in __init__\r\n    data, batch_size, num_steps, name=name)\r\n  File \"/Users/wangqian/tensorflow/ptb/reader.py\", line 100, in ptb_producer\r\n    with tf.name_scope(name, \"PTBProducer\", [raw_data, batch_size, num_steps]):\r\nTypeError: name_scope() takes exactly 1 argument (3 given)\r\n\r\nhelp me,please!\r\n", "maybe I am so also running into some version trouble, tensorflow is 1.0.0, tflearn is 0.2.2, but have trouble running such code\r\nregression = tflearn.regression(linear, optimizer='sgd', loss='mean_square',\r\n                                metric='R2', learning_rate=0.01)\r\nm = tflearn.DNN(regression)\r\n \r\nTraceback (most recent call last):\r\n  File \"C:\\ProgramData\\Anaconda2\\envs\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 491, in apply_op\r\n    preferred_dtype=default_dtype)\r\n  File \"C:\\ProgramData\\Anaconda2\\envs\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 716, in internal_convert_to_tensor\r\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n  File \"C:\\ProgramData\\Anaconda2\\envs\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\", line 176, in _constant_tensor_conversion_function\r\n    return constant(v, dtype=dtype, name=name)\r\n  File \"C:\\ProgramData\\Anaconda2\\envs\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\", line 169, in constant\r\n    attrs={\"value\": tensor_value, \"dtype\": dtype_value}, name=name).outputs[0]\r\n  File \"C:\\ProgramData\\Anaconda2\\envs\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2395, in create_op\r\n    original_op=self._default_original_op, op_def=op_def)\r\n  File \"C:\\ProgramData\\Anaconda2\\envs\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1220, in __init__\r\n    raise ValueError(\"'%s' is not a valid node name\" % node_def.name)\r\nValueError: '-_Loss/tags' is not a valid node name,\r\nHoping some help\r\n", "@sherrym  hello,how do you solve the problem? thanks", "@FCInter The summary op used in this model is no longer present in TensorFlow  (hence the `deprecated` namespace)  I believe the change suggested by @linbojin will fix your problem until the model is updated.\r\n\r\n@sherrysack Your problem is completely unrelated to the original issue.  If you believe there is a real bug in this code, please open a separate issue."]}, {"number": 6062, "title": "Feature Request: Argument of a complex number", "body": "There has been `tf.complex_abs` for absolute value.\r\nI request for something like `tf.complex_arg` which calculate the argument of complex numbers.\r\nConstructor like `tf.complex_polar(abs, arg, name=None)` is also nice. ", "comments": ["This is a dupe of https://github.com/tensorflow/tensorflow/issues/483"]}, {"number": 6061, "title": "Get tensor dimension error when retrain Inception3", "body": "I followed the 'retrain.py' example, but get error.\r\nI print the bottleneck tensor shape, and it is [1, 1, 1, 2048]. It runs into error when execute \"tf.placeholder_with_default(\r\n        bottleneck_tensor, shape=[None, BOTTLENECK_TENSOR_SIZE],\r\n        name='BottleneckInputPlaceholder')\"\r\n\r\nIt seems that bottleneck_tensor is a tensor with 4 dimension, what does each dimension mean? And Why it is not a 2 dimension tensor?\r\n\r\nMy code:\r\n\r\n    BOTTLENECK_TENSOR_NAME = 'pool_3:0'\r\n    BOTTLENECK_TENSOR_SIZE = 2048\r\n    sess = tf.InteractiveSession()\r\n    graph = create_inception_graph()\r\n    bottleneck_tensor = graph.get_tensor_by_name(ensure_name_has_port(\r\n        BOTTLENECK_TENSOR_NAME))\r\n    print bottleneck_tensor.get_shape()\r\n\r\n    bottleneck_input = tf.placeholder_with_default(\r\n        bottleneck_tensor, shape=[None, BOTTLENECK_TENSOR_SIZE],\r\n        name='BottleneckInputPlaceholder')\r\n\r\nThe error:\r\n\r\n> ValueError: Shapes must be equal rank, but are 4 and 2 for 'BottleneckInputPlaceholder' (op: 'PlaceholderWithDefault') with input shapes: [1,1,1,2048].\r\n\r\nThe retrain.py:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/image_retraining/retrain.py", "comments": ["I referred to the source code of Incception3 model. Also it confuses me that i can not find the tensor name as 'pool_3' in the model graph.\r\n\r\nThe model definition link:\r\nhttps://github.com/tensorflow/models/blob/master/inception/inception/slim/inception_model.py", "This forum is for bug reports and similar, not usage questions.  This sort of question is best asked on stackoverflow.  You might have a better chance of getting help if you post more contextual information: a link to the tutorial you're following or a list of the commands you've executed.  I spent a few minutes looking at this and can't figure out how you came up with pool_3 as a bottleneck.", "The bottle_neck definition came from the example 'retrain.py', and the link is already added at the end of my question content.\r\nThanks for your reminding, i will post this question on stackoverflow "]}, {"number": 6060, "title": "fix the number on ImageNet classification validation error", "body": "According to the three paper, Inception(https://arxiv.org/pdf/1409.4842v1.pdf), Inception V2(https://arxiv.org/pdf/1502.03167v3.pdf), Inception V3(https://arxiv.org/pdf/1512.00567v3.pdf).\r\nTheir ImageNet Classification Validation Error should be 6.67%, 4.9%, 3.46%\u3002", "comments": ["Can one of the admins verify this patch?", "@vrv "]}, {"number": 6059, "title": "Learning works on 0.11 but fails on .12rc0 (Titan X Pascal) ", "body": "I have a training experiment which fails to learn using TF 0.12rc0, but works fine if I revert TF version to 0.11 and run on the same machine. Unfortunately there are no errors logged, and the symptom is that original run starts improving after 5 minutes, but the 0.12rc0 graph fails to improve. This is blocking our transition to 0.12. It would take a bit of time to isolate the difference to a specific op, meanwhile, any suggestions of things to try?\r\n\r\nNVIDIA-SMI 370.28                 Driver Version: 370.28 \r\n/usr/local/cuda-8.0/lib64/libcublas.so.8.0.27\r\n/usr/local/cuda-8.0/lib64/libcudnn.so.5.1.5\r\n<img width=\"506\" alt=\"screen shot 2016-12-03 at 3 39 03 pm\" src=\"https://cloud.githubusercontent.com/assets/23068/20862957/de5d955a-b96e-11e6-8c7f-fa268465872f.png\">\r\n", "comments": ["Are you using the same versions of CUDA and CUDNN with both releases?\r\n\r\nRelease notes https://github.com/tensorflow/tensorflow/releases  say there were some changes to gradient calculations.  If you could dump the activation/gradient values from a single step on both versions, initialized from the same checkpoint, that might show something useful.\r\n\r\n", "Just to bump this - I'm seeing exactly the same behavior. Models which train well on 0.11 do not improve in 0.12.\r\n\r\nI am using the same GPU & library versions as @yaroslavvb. I've also attempted to use cudnn 5.0 without success.\r\n\r\nI will try and post the requested values when I have time as well.", "Retrying at HEAD and on a Maxwell GPU, next will try on a K80\r\n\r\n@poxvoculi yes, same version CUDA/CUDNN and same machine", "I pulled from head and built it and things seem to learn again \r\n`tf.__git_version__==\"b'0.12.0-rc0-437-g6d63f67'\"\r\n`\r\nHere's a version built for CUDA 8/Ubuntu\r\nhttps://www.dropbox.com/s/pyu92nj4oifw6cg/tensorflow-0.12.0rc0-cp35-cp35m-linux_x86_64.whl?dl=0\r\n\r\n", "Shall I close the bug or wait for more confirmation?", "@michaelisard I am currently re-running tests with libraries built from head. Can we leave this open please through tomorrow?", "Sure!", "@michaelisard I can confirm that this seems to work fine w/ head. Thank you!", "Good news. Closing."]}, {"number": 6058, "title": "tf.cond() + tf.dynamic_rnn() gives AttributeError: 'NoneType' object has no attribute 'pivot'", "body": "### Environment info\r\nOperating System: ubuntu 14.04.5\r\nInstalled version of CUDA and cuDNN: cuda7.5 + cuDNNv5\r\nInstalled from pip package: python 2.7+0.11.0rc0\r\n\r\n### Code\r\n```python\r\nimport tensorflow as tf\r\n\r\ndef linear(input_, output_size, scope, init_bias=0.0):\r\n    shape = input_.get_shape().as_list()\r\n    with tf.variable_scope(scope):\r\n        W = tf.get_variable(\"Matrix\", [shape[-1], output_size], tf.float32, tf.random_normal_initializer(stddev=1.0 / math.sqrt(shape[-1])))\r\n    with tf.variable_scope(scope):\r\n        b = tf.get_variable(\"bias\", [output_size], initializer=tf.constant_initializer(init_bias))\r\n    return tf.matmul(input_, W) + b\r\n\r\nbatch_size = 64\r\nhidden_size = 300\r\nvocab_size = 10000\r\n\r\nsession = tf.Session()\r\nsource = tf.placeholder(tf.float32, [batch_size, 10, hidden_size])\r\nsrc_len = tf.placeholder(tf.int32, [batch_size])\r\nenc_holder = tf.placeholder(tf.float32, [batch_size, hidden_size])\r\ndecode_mode = tf.placeholder(tf.bool)\r\nlabel = tf.placeholder(tf.int32, [batch_size])\r\n\r\ndef encoder():\r\n    src_cell = tf.nn.rnn_cell.GRUCell(hidden_size)\r\n    src_init = src_cell.zero_state(batch_size, tf.float32)\r\n    src_hiddens, src_final = tf.nn.dynamic_rnn(src_cell, source, initial_state=src_init, sequence_length=src_len, scope=\"encoder\")\r\n    return src_final\r\n\r\ndecode_state = tf.cond(decode_mode, lambda:enc_holder, lambda:encoder())\r\noutputs = linear(decode_state, vocab_size, \"output\")\r\nloss = tf.nn.sparse_softmax_cross_entropy_with_logits(outputs, label)\r\noptimizer = tf.train.AdamOptimizer().minimize(loss)\r\n```\r\n\r\n## Error Message:\r\n```\r\nTraceback (most recent call last):\r\n  File \"issue.py\", line 33, in <module>\r\n    optimizer = tf.train.AdamOptimizer().minimize(loss)\r\n  File \"~/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py\", line 196, in minimize\r\n    grad_loss=grad_loss)\r\n  File \"~/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py\", line 253, in compute_gradients\r\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\r\n  File \"~/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gradients.py\", line 469, in gradients\r\n    in_grads = _AsList(grad_fn(op, *out_grads))\r\n  File \"~/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_grad.py\", line 91, in _MergeGrad\r\n    return control_flow_ops._SwitchRefOrTensor(grad, grad_ctxt.pivot)\r\nAttributeError: 'NoneType' object has no attribute 'pivot'\r\n```\r\n## Note\r\nIf I change the line \r\n```python\r\ndecode_state = tf.cond(decode_mode, lambda:enc_holder, lambda:encoder())\r\n```\r\nto\r\n```python\r\ndecode_state = tf.cond(decode_mode, lambda:enc_holder, lambda:enc_holder)\r\n```\r\nor\r\n```python\r\ndecode_state = encoder()\r\n```\r\nNo error thrown. So I guess there must be something wrong when tf.cond() + tf.dynamic_rnn() is combined. ", "comments": ["Could it be that your use of \"lambda:encoder()\" should just be \"encoder\"?\r\n", "@poxvoculi That will raise error:\r\n```python\r\nTraceback (most recent call last):\r\n  File \"issue.py\", line 30, in <module>\r\n    decode_state = tf.cond(decode_mode, lambda:enc_holder, encoder())\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 1694, in cond\r\n    raise TypeError(\"fn2 must be callable.\")\r\nTypeError: fn2 must be callable.\r\n```", "I fixed something that is probably related to this a couple of weeks ago. Could you sync to the HEAD and try again?", "I am seeing something similar for bucketize in wide_n_deep_tutorial. I have Python 3.5.2 and TF 0.12.0 on Windows 10. Note that earlier this example was failing in dense_shape but  followed an advice on stackoverflow and named it to just shape. Now seeing the following error:\r\n\r\nAttributeError: 'NoneType' object has no attribute 'bucketize'", "Automatically closing due to lack of recent activity. We hope that you were able to resolve it on your own. However, since this is a support issue rather than a bug or feature request, you will probably get more information by posting it on StackOverflow."]}, {"number": 6057, "title": "Install error on Ubuntu 16.04 with Cuda 8.", "body": "I am trying to install tensorflow 0.12.  I am running Ubuntu 16.04 with a GTX 1080.  I get the following error.\r\n\r\n./configure \r\n~/Desktop/tensorflow-r0.12 ~/Desktop/tensorflow-r0.12\r\nPlease specify the location of python. [Default is /usr/bin/python]: /usr/bin/python3\r\nDo you wish to build TensorFlow with Google Cloud Platform support? [y/N] n\r\nNo Google Cloud Platform support will be enabled for TensorFlow\r\nDo you wish to build TensorFlow with Hadoop File System support? [y/N] n\r\nNo Hadoop File System support will be enabled for TensorFlow\r\nFound possible Python library paths:\r\n  /usr/local/lib/python3.5/dist-packages\r\n  /usr/lib/python3/dist-packages\r\nPlease input the desired Python library path to use.  Default is [/usr/local/lib/python3.5/dist-packages]\r\n\r\nUsing python library path: /usr/local/lib/python3.5/dist-packages\r\nDo you wish to build TensorFlow with OpenCL support? [y/N] n\r\nNo OpenCL support will be enabled for TensorFlow\r\nDo you wish to build TensorFlow with GPU support? [y/N] y\r\nGPU support will be enabled for TensorFlow\r\nPlease specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: \r\nPlease specify the Cuda SDK version you want to use, e.g. 7.0. [Leave empty to use system default]: 8.0\r\nPlease specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: \r\nPlease specify the Cudnn version you want to use. [Leave empty to use system default]: 8.0\r\nPlease specify the location where cuDNN 8.0 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: \r\nInvalid path to cuDNN  toolkit. Neither of the following two files can be found:\r\n/usr/local/cuda-8.0/lib64/libcudnn.so.8.0\r\n/usr/local/cuda-8.0/libcudnn.so.8.0\r\n/usr/local/cuda/lib64/libcudnn.so.8.0\r\nPlease specify the Cudnn version you want to use. [Leave empty to use system default]: 5\r\nPlease specify the location where cuDNN 5 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: \r\nPlease specify a list of comma-separated Cuda compute capabilities you want to build with.\r\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\r\nPlease note that each additional compute capability significantly increases your build time and binary size.\r\n[Default is: \"3.5,5.2\"]: 6.1\r\n.\r\nINFO: Starting clean (this may take a while). Consider using --expunge_async if the clean takes more than several minutes.\r\n.\r\nERROR: com.google.devtools.build.lib.packages.BuildFileContainsErrorsException: error loading package '': Encountered error while reading extension file 'cuda/build_defs.bzl': no such package '@local_config_cuda//cuda': Traceback (most recent call last):\r\n\tFile \"/home/chase/Desktop/tensorflow-r0.12/third_party/gpus/cuda_configure.bzl\", line 517\r\n\t\t_create_cuda_repository(repository_ctx)\r\n\tFile \"/home/chase/Desktop/tensorflow-r0.12/third_party/gpus/cuda_configure.bzl\", line 432, in _create_cuda_repository\r\n\t\t_cuda_toolkit_path(repository_ctx, cuda_version)\r\n\tFile \"/home/chase/Desktop/tensorflow-r0.12/third_party/gpus/cuda_configure.bzl\", line 148, in _cuda_toolkit_path\r\n\t\tstr(repository_ctx.path(cuda_toolkit...)\r\n\tFile \"/home/chase/Desktop/tensorflow-r0.12/third_party/gpus/cuda_configure.bzl\", line 148, in str\r\n\t\trepository_ctx.path(cuda_toolkit_path).realpath\r\nObject of type 'path' has no field \"realpath\".", "comments": ["Please include all the information requested by the new issue template.  You did not specify the OS, or GPU model.  ", "@chasep255, any reason why you elected to not use the pip package?\r\n\r\nAlso, what bazel version are you using?", "I fixed the issue. \u00a0I was using an older bazel.\n\n\nSent via the Samsung Galaxy S\u00ae 6, an AT&T 4G LTE smartphone\n-------- Original message --------From: gunan <notifications@github.com> Date: 12/19/16  3:17 AM  (GMT-05:00) To: tensorflow/tensorflow <tensorflow@noreply.github.com> Cc: chasep255 <chasepreuninger@gmail.com>, Mention <mention@noreply.github.com> Subject: Re: [tensorflow/tensorflow] Install error on Ubuntu 16.04 with Cuda\n\u00a0 8. (#6057) \n@chasep255, any reason why you elected to not use the pip package?\nAlso, what bazel version are you using?\n\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub, or mute the thread.\n\n\n  \n  \n\n\n\n\n{\"api_version\":\"1.0\",\"publisher\":{\"api_key\":\"05dde50f1d1a384dd78767c55493e4bb\",\"name\":\"GitHub\"},\"entity\":{\"external_key\":\"github/tensorflow/tensorflow\",\"title\":\"tensorflow/tensorflow\",\"subtitle\":\"GitHub repository\",\"main_image_url\":\"https://cloud.githubusercontent.com/assets/143418/17495839/a5054eac-5d88-11e6-95fc-7290892c7bb5.png\",\"avatar_image_url\":\"https://cloud.githubusercontent.com/assets/143418/15842166/7c72db34-2c0b-11e6-9aed-b52498112777.png\",\"action\":{\"name\":\"Open in GitHub\",\"url\":\"https://github.com/tensorflow/tensorflow\"}},\"updates\":{\"snippets\":[{\"icon\":\"PERSON\",\"message\":\"@gunan in #6057: @chasep255, any reason why you elected to not use the pip package?\\r\\n\\r\\nAlso, what bazel version are you using?\"}],\"action\":{\"name\":\"View Issue\",\"url\":\"https://github.com/tensorflow/tensorflow/issues/6057#issuecomment-267905907\"}}}"]}, {"number": 6056, "title": "accuracy.eval on MNIST, extremely slow on Win7, P3.5 CPU only", "body": "Hi I tested the MNIST tutorial on Win7, Python3.5, CPU only. Icore5.\r\nTested with Geany+CMD console, and Idle+Python shell.\r\n\r\nI found that everything runs fine, but the accuracy.eval routine takes more than 20min to run on the MNIST test data. Normally that is done within less than a minute (Ubuntu).  As soon as the evaluation starts, I am not able to use any other programs. Looks like the CPU is completely blocked by calculations from the eval routine. Any idea how to optimize??\r\n\r\nprint(\"test accuracy %g\"%accuracy.eval(feed_dict={\r\n    x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))", "comments": ["The ubuntu OS evaluation you're comparing for speed, is that on the same processor?  (I.e. is it a dual-boot system?)  Otherwise it's not clear from what you've posted that the Win7/ICore5 system you're comparing it to is as capable.  MNIST is a simple model, most of the eval runtime is floating point matrix multiply.  Is it possible that somehow you're running out of memory and swapping?  That could cause a huge slowdown and also prevent you from being able to access another process.", "Ok, it is basically the same out of memory issue what people with GPUs 2-4GB VRAM encounter.  The I5-Win Machine  has only 6GB of RAM and about 8GB are needed to test MNIST quickly all at once. Ubuntu was an I7 16GB RAM, so no problem.\r\n\r\nSolution to the problem: feed in batches. Recommendation: (I5,6GB ) batchsize=5000, and (QuadroK620,2GBVram) batchsize=1000. After that use numpy.mean to get the overall accuracy.\r\nOk, it is basically the same out of memory issue what GPU people with 2-4GB VRAM encounter.  The I5-Win Machine  has only 6GB of RAM and about 8GB are needed to test MNIST quickly all at once. Ubuntu was an I7 16GB RAM, so no problem.\r\n\r\nSolution to the problem: feed in batches. Recommendation: (I5,6GB ) batchsize=5000, and (QuadroK620,2GBVram) batchsize=1000. After that use numpy.mean to get the overall accuracy."]}]