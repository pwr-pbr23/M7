[{"number": 40020, "title": "TypeError: 'tuple' object is not callable", "body": "tensorflow 2.0\r\npycharm \r\npython 3.7 \r\n\r\n\r\n```\r\ndef run_train(dataset, num_epochs=2):\r\n    start_time = time.perf_counter()\r\n    model = VGGBase()\r\n    for _ in tf.data.Dataset.range(num_epochs):\r\n        for image,target in dataset: # (batch_size (N), 300, 300, 3)\r\n            predicted_locs, predicted_socres = model(image) <============error here \r\n            print(predicted_locs,predicted_socres)\r\n            pass\r\n            break\r\n        pass\r\n    tf.print(\"\uc2e4\ud589 \uc2dc\uac04:\", time.perf_counter() - start_time)\r\n\r\nvgg16\r\nclass  VGGBase(Model):\r\n    def __init__(self):\r\n        super(VGGBase,self).__init__()\r\n        self.conv1_1 = tf.keras.layers.Conv2D(3, kernel_size=3,padding='same',strides=1, activation='relu'),\r\n        self.conv1_2 = tf.keras.layers.Conv2D(64, kernel_size=3, padding='same',strides=1,activation='relu'),\r\n        self.pool1 = tf.keras.layers.MaxPool2D(2,2),\r\n\r\n        self.conv2_1  =  tf.keras.layers.Conv2D(128, kernel_size=3, padding='same',strides= 1),\r\n        self.conv2_2 = tf.keras.layers.Conv2D(128, kernel_size=3,padding='same',strides= 1),\r\n        self.pool2 = tf.keras.layers.MaxPool2D(2,2),\r\n\r\n        self.conv3_1 =  tf.keras.layers.Conv2D(256, kernel_size=3, padding='same',strides= 1),\r\n        self.conv3_2 =  tf.keras.layers.Conv2D(256, kernel_size=3, padding='same',strides= 1),\r\n        self.conv3_3 =  tf.keras.layers.Conv2D(256, kernel_size=3, padding='same',strides= 1),\r\n        self.pool3 = tf.keras.layers.MaxPool2D(2,2),\r\n\r\n        self.conv4_1 = tf.keras.layers.Conv2D(512, kernel_size=3, padding='same', strides=1),\r\n        self.conv4_2 = tf.keras.layers.Conv2D(512, kernel_size=3, padding='same', strides=1),\r\n        self.conv4_3 = tf.keras.layers.Conv2D(512, kernel_size=3, padding='same', strides=1),\r\n        self.pool4 = tf.keras.layers.MaxPool2D(2, 2),\r\n\r\n        self.conv5_1 = tf.keras.layers.Conv2D(512, kernel_size=3, padding='same', strides=1),\r\n        self.conv5_2 = tf.keras.layers.Conv2D(512, kernel_size=3, padding='same', strides=1),\r\n        self.conv5_3 = tf.keras.layers.Conv2D(512, kernel_size=3, padding='same', strides=1),\r\n        self.pool5 = tf.keras.layers.MaxPool2D(2, 2),\r\n\r\n        self.conv6 = tf.keras.layers.Conv2D(1024, kernel_size=3, padding='same',dilation_rate=6) # atrous convolution\r\n        self.conv7 = tf.keras.layers.Conv2D(1024, kernel_size=1)\r\n\r\n        #self.load_weights()\r\n    def call(self,x):\r\n        x = self.conv1_1(x)\r\n        x = self.conv1_2(x)\r\n        x = self.pool1(x)\r\n\r\n        x = relu(self.conv2_1(x))\r\n        x = relu(self.conv2_2(x))\r\n        x = relu(self.pool2(x))\r\n\r\n        x = relu(self.conv3_1(x))\r\n        x = relu(self.conv3_2(x))\r\n        x = relu(self.pool3(x))\r\n\r\n        x = relu(self.conv4_1(x))\r\n        x = relu(self.conv4_2(x))\r\n        conv4_3_feats = x\r\n        x = relu(self.pool4(x))\r\n\r\n        x = relu(self.conv5_1(x))\r\n        x = relu(self.conv5_2(x))\r\n        x = relu(self.pool5(x))\r\n\r\n        x = relu(self.conv6(x))\r\n        x = relu(self.conv7(x))\r\n        conv7_feats = x\r\n\r\n        return conv4_3_feats, conv7_feats\r\n```\r\n\r\nFile \"/home/jake/Gits/ssd_tensorflow/train.py\", line 36, in train\r\n    run_train(dataset.map(resize_image, num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(64).prefetch(tf.data.experimental.AUTOTUNE))\r\n  File \"/home/jake/Gits/ssd_tensorflow/train.py\", line 22, in run_train\r\n    predicted_locs, predicted_socres = model(image)# (N, 8732, 4), (N, 8732, n_classes)\r\n  File \"/home/jake/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 891, in __call__\r\n    outputs = self.call(cast_inputs, *args, **kwargs)\r\n  File \"/home/jake/Gits/ssd_tensorflow/model.py\", line 38, in call\r\n    x = self.conv1_1(x)\r\nTypeError: 'tuple' object is not callable\r\n", "comments": ["@SlowMonk \r\nPlease provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\nMake sure you also include the exact command if possible to produce the output included in your test case. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new).\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "That's because you forgot the commas `,` after copying this from a `Sequential` model.\r\n```\r\nself.pool3 = tf.keras.layers.MaxPool2D(2,2),\r\n                                           ^\r\n                                      remove me\r\n```"]}, {"number": 40019, "title": "When subclassing the `Model` class, you should implement a `call` method.", "body": "tf version: tf 2.1.0\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\ndef sub_test_model():\r\n    x = inputs = tf.keras.Input((5,), name='input')\r\n    x = tf.keras.layers.Dense(8)(x)\r\n    x = tf.keras.layers.Softmax()(x)\r\n    \r\n    return tf.keras.Model(inputs, x)  \r\n\r\ndef test_create_model():\r\n    x = inputs = tf.keras.Input((3,), name='input')\r\n    x = tf.keras.layers.Dense(5)(x)\r\n    x = tf.keras.layers.Softmax()(x)\r\n    \r\n    x = sub_test_model()(x)\r\n    \r\n    return tf.keras.Model(inputs, x)\r\n\r\n\r\ntest_model = test_create_model()\r\ntest_model.save(\"checkpoints/test_model\")\r\ntest_model_restore = tf.keras.models.load_model(\"checkpoints/test_model\")\r\n```\r\n\r\nwithout sub_test_model, the model save/load will work fine. with the sub model, it will occur the following error.\r\n![image](https://user-images.githubusercontent.com/731496/83344067-e3945f00-a334-11ea-813d-7819e99a7db9.png)\r\n", "comments": ["@w19787 \r\n\r\nCan you please try with TF 2.2 .I am not seeing any issue with TF version 2.2.Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/c9beebb86c45ef7bcb9f4df1eef40d91/untitled938.ipynb).Thanks!", "> @w19787\r\n> \r\n> Can you please try with TF 2.2 .I am not seeing any issue with TF version 2.2.Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/c9beebb86c45ef7bcb9f4df1eef40d91/untitled938.ipynb).Thanks!\r\n\r\nyeap, it works on TF 2.2.0. thanks. i will close this issue.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40019\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40019\">No</a>\n"]}, {"number": 40018, "title": "Update tf2.py", "body": "I changed the comment symbol.('''->#)\r\nBecause it's a line of comment.", "comments": ["What is the difference between this and #40009?", "It's the same. But I posted it wrong, so I'm sending it again."]}, {"number": 40017, "title": "Image recognition with TensorFlow Lite for Andorid", "body": "0\r\n\r\n\r\nI am new to Android Studio and TensorFlow lite, I have used google teachable machines to train some model an create my tflite files I started working form this git code that tensorflow provides for image-classification:\r\n\r\nhttps://github.com/tensorflow/examples/tree/master/lite/examples/image_classification/android\r\n\r\nAnd after following this tutorial:\r\n\r\nhttps://codelabs.developers.google.com/codelabs/recognize-flowers-with-tensorflow-on-android/index.html?index=..%2F..index#0\r\n\r\nMy android phone can now recognise objects using the camera, I would like to add a feature so that the app would read the name on the Object Label using the \"text to speech\" function, I need this to help a blind person recognising object using this app, but the code is too complex and I don't know how to implement this, can anyone help me? this video show more ore less what the app is supposed to do: https://www.youtube.com/watch?v=sa4qGxQAlqs I only miss the text to speech feature", "comments": ["@Vivaldi64 Can you please check [here](https://teachablemachine.withgoogle.com/v1/). You can select \"Speech\" tab for your application. Down the page there are additional resources that can help you. This is more related to `tensorflow.js` so please post further questions in that repo. Thanks!\r\n\r\nPlease close the issue if this resolved for you. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 40016, "title": "Overflow in tf.keras.layers.experimental.preprocessing.Normalization", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nYes (see below for code to reproduce).\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nWindows 10 10.0.18363.836\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\nN/A\r\n- TensorFlow installed from (source or binary):\r\nBinary ([conda](https://anaconda.org/anaconda/tensorflow-gpu))\r\n- TensorFlow version (use command below):\r\nunknown 2.1.0\r\n- Python version:\r\n3.6.10\r\n- Bazel version (if compiling from source):\r\nN/A\r\n- GCC/Compiler version (if compiling from source):\r\nN/A\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n**Describe the current behavior**\r\n\r\nUsing for a `tf.keras.layers.experimental.preprocessing.Normalization` layer `norm`, `norm.adapt(dataset)` encounters overflow warnings.\r\n\r\n**Describe the expected behavior**\r\n\r\nCalculate norm and standard deviation correctly.\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\n\r\ndef gen():\r\n    for i in range(2 ** 13):\r\n        array = np.random.random_sample(1024*1024*4).reshape(\r\n            (1024, 1024, 4)).astype(np.float32)\r\n        yield array * 1024 # Exacerbate the issue.\r\n\r\ndataset = tf.data.Dataset.from_generator(\r\n    gen, tf.float32, tf.TensorShape([1024, 1024, 4]))\r\n\r\ndataset = dataset.batch(4)\r\n\r\nnorm = tf.keras.layers.experimental.preprocessing.Normalization()\r\n\r\nnorm.adapt(dataset)             # This ends up with RuntimeWarnings.\r\n\r\nprint(norm.mean)                  # Result is all 'inf'.\r\nprint(norm.variance)              # Result is 0.\r\n```\r\n\r\n\r\n**Other info / logs**\r\n\r\n```\r\nd:\\local\\envs\\tf_2_1\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\preprocessing\\normalization.py:181: RuntimeWarning: divide by zero encountered in true_divide\r\n  ]) / combined_count\r\nd:\\local\\envs\\tf_2_1\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\preprocessing\\normalization.py:190: RuntimeWarning: invalid value encountered in reduce\r\n  variance_contribution(accumulator) for accumulator in accumulators\r\nd:\\local\\envs\\tf_2_1\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\preprocessing\\normalization.py:187: RuntimeWarning: overflow encountered in square\r\n  accumulator.variance + np.square(accumulator.mean - combined_mean))\r\nd:\\local\\envs\\tf_2_1\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\preprocessing\\normalization.py:187: RuntimeWarning: invalid value encountered in multiply\r\n  accumulator.variance + np.square(accumulator.mean - combined_mean))\r\n<tf.Variable 'mean:0' shape=(4,) dtype=float32, numpy=array([inf, inf, inf, inf], dtype=float32)>\r\n<tf.Variable 'variance:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>\r\n```\r\n\r\nThe count overflow problem could potentially be mitigated by changing the dtype [here](https://github.com/tensorflow/tensorflow/blob/2b96f3662bd776e277f86997659e61046b56c315/tensorflow/python/keras/layers/preprocessing/normalization.py#L158) to int64,\r\n", "comments": ["@gfkeith \r\nI ran the code shared on tf 2.1 and do not face any issues, please refer to this [gist here](https://colab.sandbox.google.com/gist/Saduf2019/98438a3fdb809ce58e8ece5b2932d0bd/untitled205.ipynb) ", "Hi @Saduf2019,\r\n\r\nThe behaviour appears to be different on Colab, I'm not sure why. It still isn't 100% correct, if you run [this](https://gist.github.com/gfkeith/055a0519535b1f2fdba633bc9611931b) the count is negative (indicating overflow) but the mean and variance still seem reasonable. On my computer, they are also negative.\r\n\r\nThis seems to be the due to the default numpy dtype. On colab, `np.sum` (relevant [here](https://github.com/tensorflow/tensorflow/blob/v2.2.0/tensorflow/python/keras/layers/preprocessing/normalization.py#L178)) seems to return int64 (even when summing dtype int32 arrays), whereas on my computer it returns int32 (hence the overflow), unless the dtype is set specifically to int64. For some reason, it is set to int32 for count [here](https://github.com/tensorflow/tensorflow/blob/v2.2.0/tensorflow/python/keras/layers/preprocessing/normalization.py#L158). I think if this were set to int64, the behaviour would be the same (i.e. overflow not a problem for count until the state variable is set, which is only [dtype int32](https://github.com/tensorflow/tensorflow/blob/v2.2.0/tensorflow/python/keras/layers/preprocessing/normalization.py#L101), hence why `norm.count` is negative for both). The mean and variance being negative for mine and not colab is explained by the working `accumulator.count` overflowing on mine (so negative) and not colab, as it multiplies mean [here](https://github.com/tensorflow/tensorflow/blob/v2.2.0/tensorflow/python/keras/layers/preprocessing/normalization.py#L184) and variance [here](https://github.com/tensorflow/tensorflow/blob/v2.2.0/tensorflow/python/keras/layers/preprocessing/normalization.py#L191).", "Interestingly, it looks like the dtype of the layer is changed to int64 in master [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/layers/preprocessing/normalization.py#L119), but the running type is still int32 [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/layers/preprocessing/normalization.py#L180).", "#40101 ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40016\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40016\">No</a>\n", "@bhack this issue has been fixed in 2.3.0, is there a reason why its moved back to \"in progress\"", "Honestly I don't remeber this action as I was not in this thread. But ok.", "> Interestingly, it looks like the dtype of the layer is changed to int64 in master [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/layers/preprocessing/normalization.py#L119), but the running type is still int32 [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/layers/preprocessing/normalization.py#L180).\r\n\r\nYou probably need to install tf-nightly to verify that, given colab doesn't automatically include latest changes"]}, {"number": 40015, "title": "Error ImageDataGenerator in multiple GPU", "body": "I have the following error when running code using multiple GPUs. I am using ImageDataGenerator to classify images that are separated by directories.\r\nThe error is:\r\n\r\nTraceback (most recent call last):\r\n  File \"new_train_alg_CNN.py\", line 113, in <module>\r\n    train = model.fit_generator(generator=train_generator,steps_per_epoch = trai              n_generator.samples/BATCH_SIZE,validation_data=validation_generator,validation_s              teps=validation_generator.samples/BATCH_SIZE,epochs= 100,callbacks=[checkpoint,               early_stop],use_multiprocessing=True)\r\n  File \"/root/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/pytho              n/util/deprecation.py\", line 324, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/root/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/pytho              n/keras/engine/training_v1.py\", line 1217, in fit_generator\r\n    return self.fit(\r\n  File \"/root/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/pytho              n/keras/engine/training_v1.py\", line 766, in fit\r\n    return func.fit(\r\n  File \"/root/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/pytho              n/keras/engine/training_distributed.py\", line 612, in fit\r\n    dataset = model._distribution_standardize_user_data(\r\n  File \"/root/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/pytho              n/keras/engine/training_v1.py\", line 2167, in _distribution_standardize_user_dat              a\r\n    assert isinstance(x, dataset_ops.DatasetV2)\r\nAssertionError\r\n", "comments": ["@tsbressan \r\n\r\nPlease provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version.\r\nRequest you to fill [Github new issue template.](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\n\r\nWill it be possible to share colab link or simple standalone code to reproduce the issue in our environment.It helps is in localizing the issue faster.Thanks!", "Ubuntu 18.04.4 , cuda:10.1, cudnn7, running on docker.\r\nuse 3 GPUs, nVidia RTX 2080\r\n\r\nbelow is the code:\r\n\r\n#import librarys\r\nimport json\r\nimport os\r\nimport numpy as np \r\nimport pandas as pd\r\nimport sys\r\nimport cv2\r\n\r\n\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\n\r\nconfig = tf.compat.v1.ConfigProto()\r\nconfig.gpu_options.allow_growth = True\r\nsess = tf.compat.v1.Session(config=config)\r\nBATCH_SIZE = 10\r\n\r\nwith tf.compat.v1.Session(config=config) as sess:\r\n    \r\n    patch_out = \"output/train\"\r\n\r\n    #save the contents of the complete arrays\r\n    np.set_printoptions(threshold=sys.maxsize)\r\n\r\n\r\n    #read files in directory\r\n    files = []\r\n    size_files = []\r\n    for filename in os.listdir(patch_out):\r\n        files.append (filename)\r\n        size_files.append (os.path.getsize(patch_out+\"/\"+filename))\r\n          \r\n    \r\n    \r\n    # Create a MirroredStrategy.\r\n    strategy = tf.distribute.MirroredStrategy()\r\n    print(\"Number of devices: {}\".format(strategy.num_replicas_in_sync))\r\n\r\n    # Open a strategy scope.\r\n    with strategy.scope():\r\n\r\n        model = keras.models.Sequential()\r\n        model.add(keras.layers.Conv2D(32, (3, 3), padding='same', input_shape=(256,256,3)))\r\n        model.add(keras.layers.Activation('relu'))\r\n        model.add(keras.layers.Conv2D(32, (3, 3)))\r\n        model.add(keras.layers.Activation('relu'))\r\n        model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\r\n        model.add(keras.layers.Dropout(0.25))\r\n\r\n        model.add(keras.layers.Conv2D(64, (3, 3), padding='same'))\r\n        model.add(keras.layers.Activation('relu'))\r\n        model.add(keras.layers.Conv2D(64, (3, 3)))\r\n        model.add(keras.layers.Activation('relu'))\r\n        model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\r\n        model.add(keras.layers.Dropout(0.25))\r\n\r\n        model.add(keras.layers.Flatten())\r\n\r\n        model.add(keras.layers.Dense(256))\r\n        model.add(keras.layers.Activation('relu'))\r\n        model.add(keras.layers.Dropout(0.5))\r\n        model.add(keras.layers.Dense(14, activation='softmax'))\r\n\r\n        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\r\n\r\n        checkpoint = keras.callbacks.ModelCheckpoint('logs/model_train.hdf5', monitor='val_loss', verbose=1, mode='min', save_best_only=True)\r\n\r\n        early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.001, patience=5, mode='min',verbose=1)\r\n       \r\n\r\n        \r\n        # Train the model on all available devices.\r\n        \r\n        data_generator = keras.preprocessing.image.ImageDataGenerator(rescale=1./255, validation_split=0.15)\r\n\r\n        train_generator = data_generator.flow_from_directory(patch_out, shuffle=True, seed=13,\r\n                                                             class_mode='categorical', batch_size=BATCH_SIZE, subset=\"training\")\r\n        validation_generator = data_generator.flow_from_directory(patch_out, shuffle=True, seed=13, \r\n                                                            class_mode='categorical', batch_size=BATCH_SIZE, subset=\"validation\")\r\n                                                            \r\n        file = validation_generator.filenames                                                     \r\n        for i in range(0,len(file)):\r\n            files = file[i].split('/')\r\n            print (files[1])    \r\n    \r\n    \r\n        train = model.fit(train_generator,steps_per_epoch = train_generator.samples/BATCH_SIZE,validation_data=validation_generator,validation_steps=validation_generator.samples/BATCH_SIZE,epochs= 100,callbacks=[checkpoint, early_stop])  \r\n        #train = model.fit(train_generator,epochs= 5, validation_data=validation_generator)  \r\n\r\n\r\n\r\n        print(train.history.keys())\r\n", "@tsbressan \r\n\r\nPlease, let us know the Tensorflow version you are using?.Thanks!", "CUDA 10.1.243\r\ntensorFlow: 2.2.0\r\ncudnn: 7.6.5\r\n\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 435.21       Driver Version: 435.21       CUDA Version: 10.1     |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  GeForce RTX 2080    Off  | 00000000:17:00.0 Off |                  N/A |\r\n| 41%   25C    P8     1W / 225W |     25MiB /  7979MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   1  GeForce RTX 2080    Off  | 00000000:65:00.0 Off |                  N/A |\r\n| 41%   26C    P8     7W / 225W |      1MiB /  7982MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   2  GeForce RTX 2080    Off  | 00000000:B3:00.0 Off |                  N/A |\r\n| 41%   25C    P8     1W / 225W |      1MiB /  7982MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n\r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID   Type   Process name                             Usage      |\r\n|=============================================================================|\r\n+-----------------------------------------------------------------------------+\r\n", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\nThanks!\r\n"]}, {"number": 40014, "title": "DNNLinearCombinedClassifier serving input format", "body": "I used the code below to train and export a DNNLinearCombinedClassifier model, but the input format is not what I want, **is there a way to export DNNLinearCombinedClassifier model to support serving input format like below?\r\n'{\"signature_name\":\"xxx\", \"instances\":[{\"feature1\": [1.0, 1.0, 1.0, 1.0..........], \"feature2\": [1.0, 1.0, 1.0, 1.0..........], \"feature3\": [1.0, 1.0, 1.0, 1.0..........]...........}]}'**\r\nThe idea is, we may post K records to server, but we don't need to repeat feature names for K times, we just need to post K feature values.\r\nFor exmple, we post data below to tf serving\r\n'{\"signature_name\":\"xxx\", \"instances\":[{\"feature1\": [1.0, 1.0, 1.0, 1.0], \"feature2\": [1.0, 1.0, 1.0, 1.0], \"feature3\": [1.0, 1.0, 1.0, 1.0]}]}'\r\nWe can get prediction result:\r\n[0.1, 0.1, 0.1, 0.1]\r\nMy training and exporting code:\r\n```\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\nimport sys\r\nimport os\r\nimport tensorflow as tf\r\n\r\n\r\ntf.logging.set_verbosity(tf.logging.INFO)\r\n\r\nROOT_PATH = './Data/adult/'\r\nTRAIN_PATH = ROOT_PATH + 'train.csv'\r\nEVAL_PATH = ROOT_PATH + 'test.csv'\r\nPREDICT_PATH = ROOT_PATH + 'predict.csv'\r\nMODEL_PATH = '/tmp/adult_model'\r\nEXPORT_PATH = '/tmp/adult_export_model'\r\n_CSV_COLUMNS = [\r\n    'age', 'workclass', 'fnlwgt', 'education', 'education_num',\r\n    'marital_status', 'occupation', 'relationship', 'race', 'gender',\r\n    'capital_gain', 'capital_loss', 'hours_per_week', 'native_country',\r\n    'income_bracket'\r\n]\r\n\r\n_CSV_COLUMN_DEFAULTS = [[0], [''], [0], [''], [0], [''], [''], [''], [''], [''],\r\n                        [0], [0], [0], [''], [0]]\r\n\r\n_HASH_BUCKET_SIZE = 1000\r\n\r\n_NUM_EXAMPLES = {\r\n    'train': 32561,\r\n    'validation': 16281,\r\n}\r\n\r\n\r\ndef build_model_columns():\r\n    age = tf.feature_column.numeric_column('age')\r\n    education_num = tf.feature_column.numeric_column('education_num')\r\n    capital_gain = tf.feature_column.numeric_column('capital_gain')\r\n    capital_loss = tf.feature_column.numeric_column('capital_loss')\r\n    hours_per_week = tf.feature_column.numeric_column('hours_per_week')\r\n\r\n    education = tf.feature_column.categorical_column_with_vocabulary_list(\r\n        'education', [\r\n            'Bachelors', 'HS-grad', '11th', 'Masters', '9th', 'Some-college',\r\n            'Assoc-acdm', 'Assoc-voc', '7th-8th', 'Doctorate', 'Prof-school',\r\n            '5th-6th', '10th', '1st-4th', 'Preschool', '12th'])\r\n\r\n    marital_status = tf.feature_column.categorical_column_with_vocabulary_list(\r\n        'marital_status', [\r\n            'Married-civ-spouse', 'Divorced', 'Married-spouse-absent',\r\n            'Never-married', 'Separated', 'Married-AF-spouse', 'Widowed'])\r\n\r\n    relationship = tf.feature_column.categorical_column_with_vocabulary_list(\r\n        'relationship', [\r\n            'Husband', 'Not-in-family', 'Wife', 'Own-child', 'Unmarried',\r\n            'Other-relative'])\r\n\r\n    workclass = tf.feature_column.categorical_column_with_vocabulary_list(\r\n        'workclass', [\r\n            'Self-emp-not-inc', 'Private', 'State-gov', 'Federal-gov',\r\n            'Local-gov', '?', 'Self-emp-inc', 'Without-pay', 'Never-worked'])\r\n\r\n    occupation = tf.feature_column.categorical_column_with_hash_bucket(\r\n        'occupation', hash_bucket_size=_HASH_BUCKET_SIZE)\r\n\r\n    age_buckets = tf.feature_column.bucketized_column(\r\n        age, boundaries=[18, 25, 30, 35, 40, 45, 50, 55, 60, 65])\r\n\r\n    base_columns = [\r\n        education, marital_status, relationship, workclass, occupation,\r\n        age_buckets,\r\n    ]\r\n\r\n    crossed_columns = [\r\n        tf.feature_column.crossed_column(\r\n            ['education', 'occupation'], hash_bucket_size=_HASH_BUCKET_SIZE),\r\n        tf.feature_column.crossed_column(\r\n            [age_buckets, 'education', 'occupation'],\r\n            hash_bucket_size=_HASH_BUCKET_SIZE),\r\n    ]\r\n\r\n    wide_columns = base_columns + crossed_columns\r\n\r\n    deep_columns = [\r\n        age,\r\n        education_num,\r\n        capital_gain,\r\n        capital_loss,\r\n        hours_per_week,\r\n        tf.feature_column.indicator_column(workclass),\r\n        tf.feature_column.indicator_column(education),\r\n        tf.feature_column.indicator_column(marital_status),\r\n        tf.feature_column.indicator_column(relationship),\r\n        # To show an example of embedding\r\n        tf.feature_column.embedding_column(occupation, dimension=8),\r\n    ]\r\n\r\n    return wide_columns, deep_columns\r\n\r\n\r\ndef input_fn(data_path, shuffle, num_epochs, batch_size):\r\n    def parse_csv(value):\r\n        columns = tf.decode_csv(value, record_defaults=_CSV_COLUMN_DEFAULTS)\r\n        features = dict(zip(_CSV_COLUMNS, columns))\r\n        labels = features.pop('income_bracket')\r\n        # classes = tf.equal(labels, '>50K')  # binary classification\r\n        return features, labels\r\n\r\n    # Extract lines from input files using the Dataset API.\r\n    dataset = tf.data.TextLineDataset(data_path)\r\n\r\n    if shuffle:\r\n        dataset = dataset.shuffle(buffer_size=_NUM_EXAMPLES['train'])\r\n\r\n    dataset = dataset.map(parse_csv, num_parallel_calls=5)\r\n\r\n    # We call repeat after shuffling, rather than before, to prevent separate\r\n    # epochs from blending together.\r\n    dataset = dataset.repeat(num_epochs)\r\n    dataset = dataset.batch(batch_size)\r\n    return dataset\r\n\r\n\r\ndef run():\r\n    wide_columns, deep_columns = build_model_columns()\r\n\r\n    config = tf.estimator.RunConfig(save_checkpoints_steps=100)\r\n    estimator = tf.estimator.DNNLinearCombinedClassifier(model_dir=MODEL_PATH,\r\n                                                         linear_feature_columns=wide_columns,\r\n                                                         linear_optimizer=tf.train.FtrlOptimizer(learning_rate=0.01),\r\n                                                         dnn_feature_columns=deep_columns,\r\n                                                         dnn_hidden_units=[256, 64, 32, 16],\r\n                                                         dnn_optimizer=tf.train.AdamOptimizer(learning_rate=0.001),\r\n                                                         config=config)\r\n    estimator.train(\r\n        input_fn=lambda: input_fn(data_path=TRAIN_PATH, shuffle=True, num_epochs=40, batch_size=100), steps=2000)\r\n    # Evaluate the model.\r\n    eval_result = estimator.evaluate(\r\n        input_fn=lambda: input_fn(data_path=EVAL_PATH, shuffle=False, num_epochs=1, batch_size=40))\r\n\r\n    print('Test set accuracy:', eval_result)\r\n    \r\n    # Predict.\r\n    pred_dict = estimator.predict(\r\n        input_fn=lambda: input_fn(data_path=PREDICT_PATH, shuffle=False, num_epochs=1, batch_size=40))\r\n    for pred_res in pred_dict:\r\n        print(pred_res['probabilities'][1])\r\n\r\n    columns = wide_columns + deep_columns\r\n    feature_spec = tf.feature_column.make_parse_example_spec(feature_columns=columns)\r\n    serving_input_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(feature_spec)\r\n    estimator.export_savedmodel(EXPORT_PATH, serving_input_fn)\r\n\r\n\r\nif __name__ == '__main__':\r\n    run()\r\n```", "comments": ["@amahendrakar Hi sir, could you please take a look at this", "@acrushdjn,\r\nSince this question is not a TensorFlow bug or feature request, it is better asked on [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow) as there is a larger community that reads questions there. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 40013, "title": "Fix invalid fusion of Matmul and Mul", "body": "This PR fix #39572, add some test cases.", "comments": ["@kroware Can you please address Ubuntu Sanity errors? Thanks!", "@liufengdb Can you please review this PR ? Thanks!\r\n", "@liufengdb @joker-eph could you take another look at this? I seems like this PR fixes #39572 which sounds like a quite serious issue.", "@ghost  Can you please check @liufengdb's comments and keep us posted. Thanks!\r\n", "> @ghost Can you please check @liufengdb's comments and keep us posted. Thanks!\r\n\r\n@gbaned The GitHub user profile of the original PR author has been deleted and doesn't exist anymore, so I don't think the request will reach anyone. I am happy to address the small comment in a follow up PR after this has been merged as I am currently running into this issue myself and would really like to see this fix land.", "@lgeiger sure you can submit a new PR", "@lgeiger did you submit a new PR ? Closing this PR due to lack of actively , feel free to @mention us to reopen the PR.", "@rthadur I didn't submit a new PR as I thought this would be merged soon. Will do so now."]}, {"number": 40012, "title": "Connectionist Temporal Classification Ops Fix", "body": "The year of publication has been wrongly mentioned as 2016. \r\n\r\nThis PR fixes that.\r\n\r\n[Source](http://www.cs.toronto.edu/~graves/icml_2006.pdf)", "comments": []}, {"number": 40011, "title": "[ROCm] Adding a GPU kernel for dropout", "body": "This implements dropout as a single fused kernel. I see performance gains on the order of 5% in BERT-Large compared with the default implementation.", "comments": ["All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F40011) for more info**.\n\n<!-- need_author_consent -->", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F40011) for more info**.\n\n<!-- ok -->", "This is not ROCm-specific, right?\r\n@chsigg could you take a look?", "@reedwm", "It is only enabled for ROCm at present, but I expect it would work fine with CUDA as well.", "Thank you for the PR! There has been discussion internally on having a fused Dropout op as well. I haven't taken a close look at this PR yet but here is some API feedback.\r\n\r\nOne tricky aspect is how to pass the mask from the forward op to the backward op. Currently this PR checks if the output is zero in the backward op and if so, assumes it was dropped. But this assumption is not necessarily correct. An output could be zero if the input was zero, in which case the gradient isn't necessarily zero.\r\n\r\nA preliminary solution we decided on is to have two ops. The first, called GenerateDropoutMask, would generate a mask, either as a bitarray encoded in an uint8 tensor or as a boolean tensor. The second, Dropout, would take in the mask and do the dropout. Similarly, DropoutGrad would take in the mask. Only GenerateDropoutMask would be stateful.\r\n\r\nAn alternative is to wrap part of the dropout function with `tf.function(experimental_compile=True)`. This will use XLA to fuse the dropout op automatically. I'm not sure how feasible this is.\r\n\r\nIn either case, this will likely have a negative performance impact over the current implementation in this PR, which does not materialize the mask on the GPU but instead generates random numbers on the fly. But we need a way to distinguish whether and output was dropped or not when the output is zero.\r\n\r\n@alextp, @sanjoy, @ekuznetsov139, or any others, thoughts on one of the two preliminary solutions I mentioned? ", "If you just compile the forward function with XLA we still need to have some mechanism to send the mask to the backwards pass.\r\n\r\nI like the idea of splitting dropout into a stateful and a stateless op, so the stateless one is the only one which has gradients. Can we benchmark this alternative?\r\n\r\nIt might be ok to take a graph with these two ops and no further uses of the mask tensor and rewrite it to use a fused no-gradient-defined op. This way we keep the user code portable and keep the performance, and it's not hard I think to write such a grappler pass.", "Dropout necessarily introduces a degree of randomness, and the impact of failure to transmit the gradient when the input is exactly zero ought to be low, since that would be a rare event (a nonzero value, especially in fp32, is extremely unlikely to become exactly zero through gradient updates, you would expect something like 1 in 2^32 inputs to dropout to be exactly zero.) I did runs of 1M steps of BERT-Large with and without this PR and there was no statistically significant effect on final loss.\r\nAfter some consideration, my only concern is that training variables may get \"stuck\" at zero with this logic in some cases. It may be safer to tweak the logic: propagate gradients whenever output is nonzero _or_ input is zero.", "Even though it likely won't affect convergence on any models, I think we should still correctly handle the case where the input is exactly 0. A user may pass inputs with 0s when writing unit tests or debugging, and if we treated that case specially, the user could become very confused. Also it's currently unclear what the performance gain would be by handling inputs of 0 incorrectly as compared to having a separate `GenerateDropoutMask` and a `Dropout` op. Depending on the op(s) following Dropout, handing 0s differently may use more memory as it requires keeping the output tensor in memory to pass to DropoutGrad.\r\n\r\nIf we find we can significantly improve performance even further by handing inputs of 0 differently, we can add an argument to the dropout op to gain the additional performance. But we should first make the normal version of dropout as fast as possible.\r\n\r\n@alextp let me know if you disagree with any of this.\r\n\r\n> It might be ok to take a graph with these two ops and no further uses of the mask tensor and rewrite it to use a fused no-gradient-defined op. This way we keep the user code portable and keep the performance, and it's not hard I think to write such a grappler pass.\r\n\r\nAgreed.\r\n\r\n@ekuznetsov139 let me know your thoughts.", "From the performance perspective, both forward and backward kernels are mostly memory-bound. And we need to be concerned with launch overhead. Splitting out GenerateDropoutMask adds an extra kernel launch, and the work running the RNG in it is no longer overlapped with memory accesses, so the forward pass would get substantially slower. On the other hand, the backward pass would be faster, since it'll only need to read 9 bytes per fp32 element (even less if the mask is packed) instead of 12 or 16.\r\n\r\nThe optimal approach would be to start with the forward kernel I have in the PR, and to make it generate the mask while applying dropout, and then pass that mask instead of the output tensor to ApplyDropoutGrad. \r\n\r\nIt may not even be too hard to change the PR. At the Python level, I'm thinking somewhere along these lines\r\nIn nn_ops.py:\r\n\r\n```\r\nout, mask = gen_nn_ops.dropout(x,rate,noise_shape=noise_shape,seed=seed)\r\nreturn out\r\n```\r\n\r\nin nn_grad.py:\r\n\r\n```\r\ndef _DropoutGrad(op, grad):\r\n  dx = gen_nn_ops.dropout_grad(grad, op.inputs[1], op.outputs[1]) # inputs[1] is rate\r\n```\r\n\r\nWould that work?\r\n\r\nAs to the order of actions, it depends on whether anyone actually intends to write the version with GenerateDropoutMask in the near future. It's one thing to reject a (possibly a bit flawed) solution in the PR in favor of your preferred architecture if that architecture is expected to go in some time soon. It's something else to reject it now and end up with unfused dropout because the alternate solution does not materialize.", "The main issue with having the Dropout op return the mask is that it becomes stateful. I'm not sure what the practical disadvantages of this are (@alextp might know) but this is fixed by splitting the op into `GenerateDropoutMask` and `Dropout`. Also @alextp suggested, we can use grappler to turn this into what you suggested, although admittedly this would not work in Eager mode outside tf.functions.\r\n\r\nHaving `GenerateDropoutMask` return a boolean tensor representing the mask instead of returning the mask from `Dropout` means an extra kernel launch and one more byte per input element needs to be written and read (or bit if we pack the mask). I don't think this would be too bad, although I haven't done any concrete research of measuring the added time this would take compared to the total time of the step in typical models.\r\n\r\nIn terms of order of actions: I can find someone to work on `GenerateDropoutMask` and implement this, copying parts of your PR (we can add you as a co-author). We first need to decide on the API we want. The reason we don't want to start with a slightly flawed solution first is that we cannot remove an op once we add it. \r\n\r\n> since it'll only need to read 9 bytes per fp32 element (even less if the mask is packed) instead of 12 or 16.\r\n\r\nWouldn't only 5 bytes need to be read for the backwards pass? 4 for the fp32 output gradient, 1 for the mask\r\n\r\n", "> The main issue with having the Dropout op return the mask is that it becomes stateful.\r\n\r\nI'm not sure what it means and why it is an issue. Perhaps someone could elaborate?\r\n\r\n>Wouldn't only 5 bytes need to be read for the backwards pass? 4 for the fp32 output gradient, 1 for the mask\r\n\r\nYes, I meant 9 bytes of memory traffic. 5 bytes read, 4 bytes written.\r\n\r\n> The reason we don't want to start with a slightly flawed solution first is that we cannot remove an op once we add it.\r\n\r\nWould this be alleviated by making the op internal (rename it into _Dropout)?\r\n", "Maybe this is too naive, but can `GenerateDropoutMask` statefully generate a PRNG *seed* that both the forward and backward passes use?  Then it could run on the host and the PRNG seed could be copied to the device for the fwd and bwd kernels.", "> I'm not sure what it means...\r\n\r\nSome ops, like [most random ops](https://cs.opensource.google/tensorflow/tensorflow/+/master:tensorflow/core/ops/random_ops.cc;l=28;drc=07eff9985278bf62d3e24f93f9d01b66bade12e5), are set as stateful. The framework uses this information in various ways, like preventing constant folding from removing the op.\r\n\r\n> ...and why it is an issue\r\n\r\n@alextp can you elaborate? \r\n\r\nAlso /CC @sanjoy, would setting `Dropout` as stateful instead of separating it into a stateful `GenerateDropoutMask` op and a non-stateful `Dropout` op have an effect on XLA?\r\n\r\n> Would this be alleviated by making the op internal (rename it into _Dropout)?\r\n\r\nI think the op would still be considered external if it can be created from the Python side and exported as a GraphDef or SavedModel, and we would still have to permenantly maintain the op. @alextp can you confirm?", "> Maybe this is too naive, but can GenerateDropoutMask statefully generate a PRNG seed that both the forward and backward passes use? Then it could run on the host and the PRNG seed could be copied to the device for the fwd and bwd kernels.\r\n\r\nYeah, this also sounds like a good idea and would save memory bandwidth (but not the extra kernel launch). It's a bit confusing from a user's perspective, since the `GenerateDropoutSeed` op would also take in two seeds as all legacy stateful ops do, but this wouldn't exposed to Python users", "> (but not the extra kernel launch)\r\n\r\nI was thinking we'd do:\r\n\r\n```\r\nu64[2] seed = GenerateDropoutMask() // Runs on host\r\nLaunchKernel(FwdPassKernel, seed[0], seed[1]);\r\n...\r\nLaunchKernel(BwdPassKernel, seed[0], seed[1]);\r\n```\r\n\r\nwhich would still have two kernel launches.", "> Also /CC @sanjoy, would setting `Dropout` as stateful instead of separating it into a stateful `GenerateDropoutMask` op and a non-stateful `Dropout` op have an effect on XLA?\r\n\r\nShould work just fine as long as the state is preserved as resource variables.\r\n\r\nPlease don't put state in `OpKernel` instances. :)\r\n\r\nAlso CC @cheshire ", "Unfortunately we would put the state in the OpKernel instances :(. We cannot create a new resource variable without breaking backwards compatibility, since the current `tf.nn.dropout` op does not create variables.", "> We cannot create a new resource variable without breaking backwards compatibility, since the current `tf.nn.dropout` op does not create variables.\r\n\r\nWhy?  Because they will be part of the checkpoints we generate?  If yes, should we create a new kind of \"anonymous\" reference variable that has no implications for checkpoints?  Putting state in `OpKernel`s is compiler hostile and I'd avoid it if at all possible.", "> Unfortunately we would put the state in the OpKernel instances :(. We cannot create a new resource variable without breaking backwards compatibility, since the current tf.nn.dropout op does not create variables.\r\n\r\nWhy not put the state into a tensor, as in my proposal?", "> Why? Because they will be part of the checkpoints we generate?\r\n\r\nYes, and if `tf.compat.v1.disable_v2_behavior()` is called, they need to be initialized.\r\n\r\n> If yes, should we create a new kind of \"anonymous\" reference variable that has no implications for checkpoints? Putting state in OpKernels is compiler hostile and I'd avoid it if at all possible.\r\n\r\nThis could potentially work, but it adds a lot of complexity. It seems better just to go with the original plan of a stateful `GenerateDropoutMask` or `GenerateDropoutSeed` op and a `Dropout` op, which essentially emulates what `tf.nn.dropout` already does but fuses it.\r\n\r\n> Why not put the state into a tensor, as in my proposal?\r\n\r\nIIUC, your proposal still has state within the OpKernel. In the current PR, you call `random::New64()` with implicitly uses state from the random number generator, so the `Dropout` op should be marked as stateful if we go with your approach.", "> IIUC, your proposal still has state within the OpKernel. In the current PR, you call random::New64() with implicitly uses state from the random number generator, so the Dropout op should be marked as stateful if we go with your approach.\r\n\r\nMy proposal does not guarantee that saving and reloading the graph would result in the same operation (unless 'seed' is explicitly specified as nonzero). \r\n\r\nIf the requirement is to have this kind of reproducibility, then yes, some kind of state needs to be saved somewhere. But, in that case, I don't see how anything changes from splitting Dropout into GenerateDropoutMask+Dropout. Instead of Dropout being stateful, GenerateDropoutMask becomes stateful.", "@ekuznetsov139 Can you please resolve conflicts? Thanks!", "> My proposal does not guarantee that saving and reloading the graph would result in the same operation (unless 'seed' is explicitly specified as nonzero).\r\n\r\nI don't think it needs to meet that requirement. However, if the kernel uses state, it must be marked as stateful. One reason for this is to prevent certain optimizations. For example, you wouldn't want grappler to use constant propagation to remove the Dropout layer, since then the output of the layer would be the same in every case.\r\n\r\n> @ekuznetsov139 Can you please resolve conflicts? Thanks!\r\n\r\nNo need to do so until we resolve what the next steps are.\r\n\r\n@ekuznetsov139 would you want to change this PR to implement and use the `GenerateDropoutMask` or `GenerateDropoutSeed` op? If not, I can find someone internally to work on this. In either case, we first need to decide which of the two ops to go with.\r\n", "How about I just add the IsStateful tag to the Dropout op as implemented?", "The issue with adding IsStateful to the Dropout op is that we have to maintain this Dropout op indefinitely. We'll then later create a `GenerateDropoutMask` and `DropoutV2` op but we'll still have to maintain the original op.", "Why would you want to create GenerateDropoutMask later? What is there to be gained from having this (slower) two-step process?", "@reedwm Can you please assist on above comments from @ekuznetsov139. Thanks!", "@ekuznetsov139 we discussed why a GenerateDropoutMask is useful in a few messages in this thread. For example it allows you to use the same dropout mask across all cells of an RNN, whether it's unrolled statically (with a python for loop without autograph) or dynamically (with tf.while_loop). It also allows for more reproducible experiments, which is important for some of the researchers in our audience.\r\n\r\nWe should also try to find a way of making all state used by TF serializable somewhere. Ideally this can be done using the new tf.random.Generator API (which can be an argument to the GenerateDropoutMask op).", "The op as implemented takes a seed as one of the inputs. It only falls back on the internal RNG if the seed is zero. If and when these use cases are covered, the op will not need to be changed - you just need to implement GenerateDropoutSeed, add a call to it into python code, and pass the result to the dropout op.", "@ekuznetsov139 Can you please resolve conflicts? Thanks!", "@ekuznetsov139  Any update on this PR? Please. Thanks!", "@gbaned at this point it is totally up to @reedwm and @alextp. Sounds like they don't want this architecture and they either want to reject it or they want me to implement GenerateDropoutSeed, which I can't do unless I have some directions (the intended API interface in particular).", "@reedwm, @alextp  Any update on this PR? Please. Thanks!", "@reedwm, @alextp Any update on this PR? Please. Thanks!", "@reedwm, @alextp  Any update on this PR? Please. Thanks!", "@reedwm, @alextp Any update on this PR? Please. Thanks!", "@reedwm, @alextp Any update on this PR? Please. Thanks!", "@reedwm, @alextp Any update on this PR? Please. Thanks!"]}, {"number": 40010, "title": "update python_api.md", "body": "This fixes #39962\r\nChanged `tf.gfile.GFile` with `tf.io.gfile.GFile` for the code to work in TF 2.2\r\nThe former is an alias declared in TF 1.X and fails in TF 2 due to absence.", "comments": []}, {"number": 40009, "title": "Update tf2.py", "body": "I changed the comment symbol.('''->#)\r\nBecause it's a line of comment.", "comments": []}, {"number": 40008, "title": "convert error", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (or github SHA if from source):\r\n\r\n\r\n**Provide the text output from tflite_convert**\r\n\r\n```\r\n and pasting the following:\r\n\r\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CONV_2D, DEPTHWISE_CONV_2D, DIV, FLOOR, FULLY_CONNECTED, MAX_POOL_2D, MUL, RESHAPE, SUB. Here is a list of operators for which you will need custom implementations: RandomUniform.\r\n```\r\n\r\n**Standalone code to reproduce the issue** \r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\nAlso, please include a link to a GraphDef or the model if possible.\r\n\r\n**Any other info / logs**\r\n\r\nInclude any logs or source code that would be helpful to diagnose the problem.\r\nIf including tracebacks, please include the full traceback. Large logs and files\r\nshould be attached.\r\n", "comments": ["@307509256 \r\nPlease provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\nMake sure you also include the exact command if possible to produce the output included in your test case. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new).\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 40007, "title": "Is there a way to train large amount of variable size data in TF", "body": "Hi, I am working on a model (structure shown below). I have 9 inputs, 8 is images whose size is (224,224,3) and the other is audio whose size is (1, 96, 1366). I use tf.keras to construct model following: `model = Model([image_1...image_8, audio_input], output)`\r\n![image](https://user-images.githubusercontent.com/14579257/83305598-ed438880-a1b5-11ea-81ec-626acff96b11.png)\r\n\r\nSince my data is too large, I use the `fit_generator` to train it (I know it is `fit` now, I use the old name for distinguishing from each other). \r\n\r\nFirstly I tried tensorflow dataset following below:\r\n```\r\nclass BasicDatasetLight(object):\r\n    def __init__(self, run_data, batch_size):\r\n        \"\"\"\r\n        :param run_data: a dictionary storing the data info\r\n        :param batch_size:\r\n        \"\"\"\r\n        from os.path import splitext\r\n        data_array = np.load(run_data[\"data_file\"], allow_pickle=True)\r\n        self.run_info = run_data\r\n        self.x, self.y = data_array[:,:-1], data_array[:,-1].astype(dtype=int)\r\n        self.img_num = len(data_array[0][0])        # input image number\r\n        _, self.image_type = splitext(data_array[0][0][0])      # input image type\r\n        self.model_input_num = run_data[\"input_num\"]\r\n        self.gen_out_type = self.__gen_out_type_shape()[0]     # get output type tuple\r\n        self.gen_out_shape = self.__gen_out_type_shape()[1]     # get output shape tuple\r\n        self.batch_size = batch_size\r\n\r\n    def __len__(self):\r\n        \"\"\"\r\n        generate batch number\r\n        :return:\r\n        \"\"\"\r\n        return len(self.x) // self.batch_size\r\n\r\n    def __gen_out_type_shape(self):\r\n        \"\"\"\r\n        generate output type tuple according the input\r\n        :return:\r\n        \"\"\"\r\n        peep_file = self.x[:,0][0][0]\r\n        peep_shape = self.run_info[\"image_shape\"]\r\n        peep_image = _tf_load_img(peep_file, peep_shape[0], decode_image=self.image_type)\r\n        out_type = peep_image.dtype\r\n        # type list [type] * image_input_num + [audio type]\r\n        type_list = [out_type] * (len(peep_shape)*self.img_num) + [out_type]\r\n        # shape list [shape] * image_input_num + [audio shape]\r\n        shape_list = [peep_shape[0]]*(len(peep_shape)*self.img_num) + [self.run_info[\"audio_shape\"]]\r\n        gen_out_shape = fake_gen_shape(shape_list)\r\n        assert len(type_list)==self.model_input_num,\"wrong input number\"\r\n        return (tuple(type_list),tf.int8), (gen_out_shape, tf.TensorShape(1,))\r\n\r\n    def give_dataset(self):\r\n        \"\"\"\r\n        serve the dataset to model\r\n        :return:\r\n        \"\"\"\r\n        ds = tf.data.Dataset.from_generator(\r\n            lambda: _get_generator_light(self.x, self.y, self.run_info,self.image_type),\r\n             output_types=self.gen_out_type,\r\n             output_shapes=self.gen_out_shape)\r\n        ds = ds.repeat()\r\n        ds = ds.batch(self.batch_size, drop_remainder=True)\r\n        ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\r\n        return ds\r\n```\r\nThe the methods starting with \"__\" are all internal functions. The `give_dataset` is the method serving dataset. It calls the `_get_generator_light` to form dataset from generator. The function is listed below:\r\n```\r\ndef _tf_load_img(img_file, target_shape, decode_image=\".jpg\"):\r\n    \"\"\"\r\n    tensorflow load image\r\n    :param img_file:\r\n    :param target_shape: (H x W x C) channel last\r\n    :param decode_image: image extension for decoding mode\r\n    :return:\r\n    \"\"\"\r\n    image = tf.io.read_file(img_file)\r\n    # image shape channel last\r\n    if \"png\" in decode_image: image = tf.image.decode_png(image, channels=target_shape[-1])\r\n    else: image = tf.image.decode_jpeg(image, channels=target_shape[-1])\r\n    image = tf.cast(image, tf.float32)\r\n    image = (image/127.5) - 1\r\n    image = tf.image.resize(image, (target_shape[0], target_shape[1]))\r\n    return image\r\n\r\n\r\ndef _get_generator_light(x, y, run_info, image_type=\".jpg\"):\r\n    \"\"\"\r\n    a generator function for tensorflow dataset\r\n    :param x:   input data\r\n    :param y:   label\r\n    :param run_info:    run information dictionary\r\n    :param image_type:  image type for identifying decoding mode\r\n    :return: ([input list], output)\r\n    \"\"\"\r\n    # images number x copies (models may need different inputs) + audio input\r\n    image_in,audio_in,y = x[:,0],x[:,1],y\r\n    image_shape = run_info[\"image_shape\"]\r\n    image_num = len(image_in[0])\r\n    decode_image = image_type\r\n    buff_size = len(image_shape)*image_num + 1\r\n    for data_read_index in range(len(x)):\r\n        # data_buff = np.empty(buff_size, dtype=object)\r\n        data_buff = [None] * buff_size\r\n        buff_index = 0\r\n        for ii in range(image_num):\r\n            for neti in range(len(image_shape)):\r\n                image = _tf_load_img(image_in[data_read_index][ii],\r\n                                     image_shape[neti],\r\n                                     decode_image=decode_image)\r\n                data_buff[buff_index] = image\r\n                buff_index += 1\r\n        data_buff[buff_index] = np.expand_dims(audio_in[data_read_index],axis=0)\r\n        label = y[data_read_index]\r\n        assert buff_index==buff_size-1, \"wrong data buff size\"\r\n        yield data_buff, label\r\n```\r\nNOTICE: `_get_generator_light` calls `_tf_load_img`, which is also listed. \r\nHowever, it shows the error:\r\n```\r\nTraceback (most recent call last):\r\n\r\n  File \"/opt/anaconda3/envs/mau/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\", line 795, in generator_py_func\r\n    flattened_values = nest.flatten_up_to(output_types, values)\r\n\r\n  File \"/opt/anaconda3/envs/mau/lib/python3.7/site-packages/tensorflow_core/python/data/util/nest.py\", line 396, in flatten_up_to\r\n    assert_shallow_structure(shallow_tree, input_tree)\r\n\r\n  File \"/opt/anaconda3/envs/mau/lib/python3.7/site-packages/tensorflow_core/python/data/util/nest.py\", line 324, in assert_shallow_structure\r\n    check_types=check_types)\r\n\r\n  File \"/opt/anaconda3/envs/mau/lib/python3.7/site-packages/tensorflow_core/python/data/util/nest.py\", line 299, in assert_shallow_structure\r\n    \"Input has type: %s.\" % type(input_tree))\r\n\r\nTypeError: If shallow structure is a sequence, input must also be a sequence. Input has type: <class 'list'>.\r\n```\r\n\r\nThen I tried to use python generator:\r\n```\r\nclass BasicGeneratorLight(tf.keras.utils.Sequence):\r\n    def __init__(self, run_data, batch_size):\r\n        \"\"\"\r\n        :param run_data: a dictionary storing the data info\r\n        :param batch_size:\r\n        \"\"\"\r\n        from os.path import splitext\r\n        data_array = np.load(run_data[\"data_file\"], allow_pickle=True)\r\n        self.run_info = run_data\r\n        self.x, self.y = data_array[:,:-1], data_array[:,-1].astype(dtype=int)\r\n        self.img_num = len(data_array[0][0])        # input image number\r\n        _, self.image_type = splitext(data_array[0][0][0])      # input image type\r\n        self.model_input_num = run_data[\"input_num\"]\r\n        self.batch_size = batch_size\r\n\r\n    def __len__(self):\r\n        return len(self.x) // self.batch_size\r\n\r\n    def __getitem__(self, idx):\r\n        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\r\n        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\r\n        img_num = self.img_num    # check how many images we have\r\n        imagenet_shapes = self.run_info[\"image_shape\"]      #  input shape for each image net (ORDER MATTERS!)\r\n        imgnet_num = len(imagenet_shapes)\r\n        input_num = img_num*imgnet_num+1\r\n        model_data = np.empty(input_num,dtype=object)     # data buffer\r\n        model_data_index = 0\r\n        audio_buff = np.empty([self.batch_size] + list(self.run_info[\"audio_shape\"]), dtype=float)\r\n        audio_read = True\r\n        for ii in range(img_num):   # read every image\r\n            for neti in range(imgnet_num):  # prepare for each image model\r\n                image_buff = np.empty([self.batch_size] + list(imagenet_shapes[neti]), dtype=float)\r\n                # load data per img\r\n                for di in range(self.batch_size):\r\n                    curr_imgfile = batch_x[di, 0][ii]\r\n                    #image_buff[di, :, :, :] = _tf_load_img(curr_imgfile,\r\n                    #                                       imagenet_shapes[neti], self.image_type)\r\n                    image_buff[di, :, :, :] = _keras_load_img(curr_imgfile,\r\n                                                              imagenet_shapes[neti],'vgg')  # use 'vgg' for all\r\n                    if audio_read:\r\n                        aud_len = batch_x[di, 1].shape[-1]\r\n                        audio_buff[di, 0, :, :aud_len] = batch_x[di, 1]  # set channle axis to 0 as only mono channel\r\n                audio_read = False  # disable audio_read after reading audio one time\r\n                model_data[model_data_index] = image_buff\r\n                model_data_index += 1\r\n        model_data[model_data_index] = audio_buff  # append audio data to the end\r\n        assert model_data_index==input_num-1, \"input number wrong\"\r\n        return list(model_data), batch_y\r\n```\r\nIt finally can run the experiment, however, it gives the error:\r\n```\r\n2020-05-30 04:14:00.228692: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\r\n2020-05-30 04:14:00.232101: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\r\n2020-05-30 04:14:00.235563: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\r\n2020-05-30 04:14:00.238860: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\r\n```\r\nI use 32 workers and max_queue_size 32. Though the experiment is running without stop, the error seems something wrong to me.\r\n\r\nWithout the generator way and tf.data way, how can I train my model?", "comments": ["Does anyone have the same problem? It seems a dead end for me to use TF to train my system.", "@sun-peach \r\n\r\nPlease provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version.\r\n\r\nRequest you to share colab link or simple standalone code with supporting files to reproduce the issue in our environment.It helps us in localizing the issue faster.Thanks!", "I use Ubuntu 16.04, TF 2.1.0. The whole program is too large to share. I past the key parts in the original post. Thank you.", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\nThanks!\r\n"]}, {"number": 40006, "title": "custom operators by reference in tf2.2.0", "body": "**System information**\r\n- TensorFlow version (you are using): 2.2.0\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nFollowing the [custom operator guide](https://www.tensorflow.org/guide/create_op) we learn how to build a custom operator.\r\n\r\nHowever, the guide does not explain how to build custom operators when the input and output are passed by reference. In fact, following the [AssignOp](https://github.com/tensorflow/tensorflow/blob/7817237d5852c7778d3ba03c40f139e6f2c37a76/tensorflow/core/kernels/assign_op.h) as a naive example, we get errors concerning the impossibility to run it on eager mode and when using `@tf.function` / disabling eager that the input tensors must be mutable, even if the object we are passing is already a `tf.Variable`.\r\n\r\nSearching for the `tf.Variable.assign` function in v2.2.0 we realize that its c++ operator is [AssignVariableOp](https://github.com/tensorflow/tensorflow/blob/7769f52b9f6433c4e97ae42ba2060034e357a071/tensorflow/core/kernels/resource_variable_ops.cc) which is interfaced in `gen_resource_variable_ops` (generated during compilation) and it performs the `tf.Variable` updates through a resource object mechanism.\r\n\r\nAs far as I understand, there is no simple side load mechanism for custom operators by reference without modifying the `gen_resource_variable_ops` / `resource_variable_ops.py`, thus I am wondering if there are less intrusive alternatives to this approach and the respective documentation.\r\n\r\n**Will this change the current api? How?**\r\n\r\nProbably yes.\r\n\r\n**Who will benefit with this feature?**\r\n\r\nProjects that require custom operators based on mutable objects.\r\n", "comments": ["cc @saxenasaurabh @allenlavoie for more insight\r\n\r\nYou shouldn't need to modify existing code. It should be possible to create a new op, e.g. by copying parts of e.g. `AssignVariableOp`, and instead of using existing classes, define a new class for your resource. So you'd copy `Var` - see `core/framework/resource_var.h` - to create a new `ResourceBase` subclass; its comments have an example. I'm not very familiar with it, but it looks like just a thin wrapper over a pointer to a tensor, and if you make that a `DT_VARIANT` then you can store anything inside those (see `core/kernels/tensor_map.h` for an example).\r\n\r\nBut before going the route of resources, I think it'd be worth looking into whether you can use regular variants for that. Those aren't references and instead use value semantics, but for things like small containers they can be efficient since you're only really copying pointers. `TensorArray` uses those for example.", "I think Dan covered it pretty well. Summary writers, Dataset iterators, and tables are all reasonable examples of kernels that handle resource tensors. There isn't anything they can do that isn't public; the C++ custom op API is what they all use to specify their kernels.\r\n\r\nHaving pointers in the custom op guide sounds reasonable. And probably also a discussion of the issues Dan mentions: stateful things are difficult to handle with gradients and other transformations, so keeping things stateless and conforming to the dataflow model are generally good where possible.", "@mdaley and @allenlavoie thank you for the details. Would be great to have a summary in the docs and/or in [custom-op](https://github.com/tensorflow/custom-op), with an example showing how to construct custom operators for variants as input tensors.", "Additional 2c, `DT_VARIANT` is effectively `void*`. You only need it if you want to have a tensor backed by an arbitrary C++ object. If you all you care about is rectangular tensors then maybe [buffer forwarding](https://cs.opensource.google/tensorflow/tensorflow/+/master:tensorflow/core/kernels/scatter_nd_op.cc;l=204-205;drc=3cbb50768909c585d33e99ba10172d1c44c04d6f) is all you need?", "@saxenasaurabh @allenlavoie @mdanatg thank you for the suggestions and references. Let me just share a couple of comments about my current application layout in order to understand if the approaches you are proposing are the best for my specific test case. \r\n\r\nI have to deal with custom operations of large tensors with usually `size=2^35` tf.complex128 elements. So far, in order to avoid copies, I am updating in place the elements stored inside `Tensor::flat<T>::data()` and this obviously disables/destroys useful features such as gradients and `tf.function`. Thus I was thinking about passing variables to custom operators, however at this point, which approach do you suggest for my specific test case? If I understand correctly, buffer forwarding does not guarantees a copy free operator, is the `TensorArray` approach the best so far?\r\n", "So the idea with TensorArray is that you'd have N chunks of size M (N*M ~= 2^35), and only a small number of the N chunks would be updated? If so it sounds plausible that it could work; every time backprop keeps a \"copy\" of the TensorList it'll make an O(N) copy of the list of chunks, but the data in the chunks themselves should be shared (since they're refcounted Tensors).\r\n\r\nEven if TensorList doesn't quite fit (e.g. because the update pattern is sparse but isn't nicely chunked along one axis) I think using similar variant-dtype tensor scheme sounds reasonable and doable with custom ops today. If you want backprop to work you need to provide the illusion that forward pass inputs are available to the backward pass, but you can control how those inputs are stored (dense vs. dense + sparse delta); dense buffer forwarding won't really help since backprop references the old buffers.", "@scarrazza,\r\nCan you please respond to the above comment? Thanks! ", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 40005, "title": "Conflict python between Tensorflow, Spyder and Octave", "body": "Hello,\r\nI am very new of python environment.\r\nAfter some time spent learning python through Anaconda on Windows PC (in particular with Spyder), I also decided to learn Tensorflow, always in Spyder. So, I created a new dedicated environment for TF with the v3.6.9 and v1.17.2, respectively, for python and numpy.\r\n\r\nI have never had problems running codes that require TF import with this configuration.\r\nHowever, after some time, to use the Octave symbolic library I had to download Python from Microsoft Store. The downloaded version were 3.8.3 and I also installed the pip package from cmd. The symbolic package in Octave works, but from that moment when I run a code in Spyder that requires the import of tensorflow, I get the following error:\r\n\r\n```\r\nIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\r\n\r\nImporting the numpy C-extensions failed. This error can happen for\r\nmany reasons, often due to issues with your setup or how NumPy was\r\ninstalled.\r\n\r\nWe have compiled some common reasons and troubleshooting tips at:\r\n\r\n    https://numpy.org/devd_ocs/user/trou_bleshooting-importerror.html\r\n\r\nPlease note and check the following:\r\n\r\n  * The Python version is: Python3.6 from \"C:\\Users\\ivang\\.conda\\envs\\tensorflow_cpu\\python.exe\"\r\n  * The NumPy version is: \"1.18.4\"\r\n\r\nand make sure that they are the versions you expect.\r\nPlease carefully study the documentation linked above for further help.\r\n\r\nOriginal error was: No module named `'numpy.core._multiarray_umath_'\r\n```\r\n\r\nAs suggested, checking my PATH and PYTHONPATH environment variables I obtained the paths in the attached picture. \r\n![PATHS](https://user-images.githubusercontent.com/47055464/83290215-999d6300-a1e6-11ea-92c7-b71af5a9f7a7.png)\r\nThese environment variables were not created by me, but by Python at the time of its stand-alone installation.\r\n\r\nI understand that the problem is related to the different versions of python installed, but why this conflict happens if I created a dedicated environment in Anaconda, as explained at the beginning of the post? How can I solve this conflict using both TF in Spyder and the library in Octave on the same PC?\r\n\r\nI tried to uninstall Python 3.8 but the environment variables remain and also the directory in C:\\Program Files\\Python38\\ where site packages are installed.\r\n\r\nThank you so much for the help,\r\nIG", "comments": ["Can you please refer to this [comment](https://github.com/tensorflow/tensorflow/issues/39130#issuecomment-623335820) also can you down grade your python [3.7] and let us know if it helps.\r\nplease refer to his [page](https://www.tensorflow.org/install/pip)\r\n\r\n#33374  #33543  [link](https://github.com/tensorflow/tensorflow/issues/38750#issuecomment-623088620)", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Please, see the solution reported [here](https://github.com/spyder-ide/spyder/issues/12899).\r\n\r\nBest regards.", "@IvanGas \r\nPlease confirm if we may move this to closed status.", "@Saduf2019 \r\nI confirm that the issue can be closed.\r\n\r\nThank you and regards,\r\nIG", "Moving this to closed status with confirmation", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40005\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40005\">No</a>\n"]}, {"number": 40004, "title": "Link error for libtensorflow_cc.so when using LoadSavedModel", "body": "The version scripts don't export any symbols from protobuf. This is fine as long as basic functionality doesn't use symbols from protobuf, but LoadSavedModel seems to me to be a part of the basic functionality of tensorflow. Adding `*google*protobuf*` to the version scripts fixes the issue, as would hiding the protobuf data from the interface\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 2.2.0\r\n- Python version: n/a\r\n- Bazel version (if compiling from source): 2.0.0\r\n- GCC/Compiler version (if compiling from source): GCC 7.5.0\r\n- CUDA/cuDNN version: CUDA 10.1, cuDNN 7.6.3\r\n- GPU model and memory: n/a\r\n\r\n**Describe the current behavior**\r\nWhen using the LoadSavedModel function from c++ and linking against tensorflow_cc.so, a link error appears saying `undefined reference to 'google::protobuf::internal::MapFieldBase::SyncMapWithRepeatedField() const'`\r\n\r\n**Describe the expected behavior**\r\nThe program links and runs without issues\r\n\r\n**Standalone code to reproduce the issue**\r\nAny c++ program using LoadSavedModel and linking libtensorflow_cc.so will do", "comments": ["@dgel \r\n\r\nCan you go through the l[ink1](https://github.com/tensorflow/tensorflow/issues/35623),[link2](https://github.com/tensorflow/tensorflow/issues/14632),[link3](https://github.com/tensorflow/tensorflow/issues/22980) and see if it helps you.Thanks!", "Hi @ravikyram \r\n\r\nIt seems links 1 and 3 are about building tensorflow_cc.so itself. I'm having no issues building the tensorflow library, just with linking against it, so I'll discard those. \r\n\r\n~If I understand correctly from link 2, any any code that calls some tensorflow API that uses parts of protobuf needs to additionally link against libtensorflow_framework.so? Why is this done instead of just exporting the protobuf symbols from libtensorflow_cc.so directly? I haven't built libtensorflow_framework yet, so I'll try that and see how it goes~\r\n\r\nI just realised, I built tensorflow_cc with the commandline `bazel build --config=opt --config=monolithic tensorflow:libtensorflow_cc.so tensorflow:install_headers`. If I recall correctly, the monolithic config already includes libtensorflow_cc.so inside the binary, so the advice from link 2 does not apply", "To supplement the information I already put here, I continued developing my program after having exported the protobuf symbols from libtensorflow_cc.so. However, I ran into a version issue where another dependency used a different version of protobuf.\r\n\r\nI understand that such are not really concerns of tensorflow, and just exporting the symbols is the simpler option, but an ideal solution for me would be to make sure the header \"tensorflow/cc/saved_model/loader.h\" does not depend on protobuf symbols. Or more likely, implement an alternative interface that does not use protobuf::Map and an implementation similar to SavedModelBundleLite", "@dgel could you have a look on https://github.com/tensorflow/tensorflow/issues/44899", "@xiandong79 That is exactly the error I reported here, perhaps mark it duplicate and close? No need to open multiple issues for the same problem", "@dhgelling Sure, I have closed it. https://github.com/tensorflow/tensorflow/issues/44899\r\n\r\ndo you have solutions to overcome/bypass the error?", "yes, expanding on the solution I mentioned when reporting the issue, before building / linking libtensorflow_cc.so, add `*google*protobuf*` to the version scripts (that's `tensorflow/tf_version_script.lds` for linux and `tensorflow/tf_exported_symbols.lds` for mac) ", "add `*google*protobuf*;` into `tensorflow/tf_version_script.lds`\r\n```\r\nubuntu@ip-172-31-14-28:~$ cat /home/ubuntu/tensorflow_cc/tensorflow_cc/build/tensorflow/tensorflow/tf_version_script.lds\r\ntensorflow {\r\n  global:\r\n    *tensorflow*;\r\n    *absl*kSeed*;\r\n    *toco*;\r\n    *google*protobuf*;\r\n    *perftools*gputools*;\r\n    *tf_*;\r\n    *TF_*;\r\n    *Eager*;\r\n    *TFE_*;\r\n    *nsync_*;\r\n    *stream_executor*;\r\n    *xla*;\r\n    *PyInit_*;\r\n  local:\r\n    *;\r\n};\r\n```\r\n\r\nAs I use [ FloopCZ /tensorflow_cc ](https://github.com/FloopCZ/tensorflow_cc)\r\n\r\n### (re-)Build and (re-)install the library\r\n```\r\ncd /home/ubuntu/tensorflow_cc/tensorflow_cc/build\r\ncmake ..\r\nmake\r\nsudo make install\r\n```\r\n\r\n**however, it does not work yet.** @dhgelling should I do other modification?\r\nI will try https://github.com/FloopCZ/tensorflow_cc/issues/219 this solution for now.", "I mean if that solution works then go with that, no? The reason my solution doesn't work with `FloopCZ/tensorflow_cc` is that the resulting make script will download all the sources needed, and overwrite any changes we make. I 'solved' this by running make, waiting for bazel to start compiling, then interrupt with `ctrl+c`, then edit the version script and running make again.\r\n\r\nAnother option would be to just make the changes in a branch of tensorflow and make `FloopCZ/tensorflow_cc` use that branch instead. Also, it's possible that you won't need the fix at all if you use `SavedModelBundleLite` instead of `SavedModelBundle`", "@dgel \r\nIt looks like you are using an older Version of Tensorflow. Many bugs have been fixed in the latest version. Can you please try using Latest Version 2.7.0 and let us know if it helps? Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40004\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40004\">No</a>\n"]}, {"number": 40003, "title": "About the official document variable name introduced by Profiler is inconsistent\uff01", "body": "About the official document variable name introduced by Profiler is inconsistent\uff01\r\n\r\nPlease see the URL\uff1a\r\n[https://tensorflow.google.cn/guide/profiler?hl=en](https://tensorflow.google.cn/guide/profiler?hl=en)\r\n\r\n![WechatIMG6](https://user-images.githubusercontent.com/61530230/83288790-8c986800-a216-11ea-94aa-0b6ddc2d4e51.png)\r\n\r\nYou can find problems with two variables\uff1a\u201ctb_callback\u201d and \u201ctensorboard_callback\u201d \uff01", "comments": ["This is fixed now. Thanks!"]}, {"number": 40002, "title": "The tf.keras.Model.compile metrics do not respect masking since TF 2.2", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **Yes**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Linux Debian Stable**\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: --\r\n- TensorFlow installed from (source or binary): **binary**\r\n- TensorFlow version (use command below): **TF 2.2, TF-nightly 2.3.0-dev20200529**\r\n- Python version: **3.7**\r\n\r\n**Describe the current behavior**\r\nThe metrics passed to `tf.keras.Model.compile` as `metrics` do not respect model masks.\r\n\r\n**Describe the expected behavior**\r\nUntil TF 2.1, these metrics did respect model masks.\r\n\r\n**Standalone code to reproduce the issue**\r\nConsider the following code which masks the input element.\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\nprint(tf.__version__)\r\n\r\nmodel = tf.keras.Sequential([\r\n    tf.keras.layers.Masking(1.),\r\n    tf.keras.layers.Dense(1)\r\n])\r\nmodel.compile(optimizer=tf.optimizers.Adam(),\r\n              loss=tf.losses.MeanSquaredError(),\r\n              metrics=[tf.metrics.MeanSquaredError()],\r\n              weighted_metrics=[tf.metrics.MeanSquaredError()])\r\n\r\nprint(model.train_on_batch(np.ones([1, 1]), np.ones([1, 1])))\r\n```\r\n\r\nTensorFlow until 2.1 masks also the metric in `metrics`, while TensorFlow 2.2 and later do not.\r\n- TensorFlow 2.1 [(colab)](https://colab.research.google.com/drive/1q_CgkAh-wMdXy93ENXUBqU6JKWSPraBi?usp=sharing) prints `[0.0, 0.0, 0.0]`\r\n- TensorFlow 2.2 [(colab)](https://colab.research.google.com/drive/1_iEw5yPbJInfjWAjmgYZijUjvqrzpjTZ?usp=sharing) prints `[0.0, 1.0, 0.0]`\r\n- TensorFlow-Nightly 2.3.0-dev20200529 [(colab)](https://colab.research.google.com/drive/1d4_B_rxfRcPdJcCAFPNw2fV1_VG2kcVv?usp=sharing) prints `[0.0, 1.0, 0.0]`\r\n\r\n**Other info / logs**\r\nThe logic of applying the mask in `master` is here:\r\nhttps://github.com/tensorflow/tensorflow/blob/a1ae008076e14f7e445abf2605759779d2a1fb8b/tensorflow/python/keras/engine/compile_utils.py#L404-L414\r\nThe `metrics` do not get called with `sample_weight`, but that is the place where the masks are applied (in `apply_mask`).\r\n\r\nOn the other hand, in TF 2.1\r\nhttps://github.com/tensorflow/tensorflow/blob/3ffdb91f122f556a74a6e1efd2469bfe1063cb5c/tensorflow/python/keras/engine/training.py#L2000-L2012\r\nthe `output_mask` was passed even for the unweighted metrics.", "comments": ["I am able to replicate this issue, [masking occurring in 2.1](https://colab.sandbox.google.com/gist/Saduf2019/16ac32138d26f2a15b72c284d30b2442/untitled205.ipynb) and works as not in [tf 2.2](https://colab.sandbox.google.com/gist/Saduf2019/32c69933c866dce75e755d620ad8b663/untitled208.ipynb)", "@foxik this issue has been fixed in [f66d36cc](https://github.com/tensorflow/tensorflow/commit/1c144fdb678efa94511685872ba7dcccf66d36cc). \r\nPlease reopen if thats not the case.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40002\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40002\">No</a>\n"]}, {"number": 40001, "title": "cannot import name 'compiler'", "body": "Hello,\r\n\r\n**System information**\r\nI try to run a code on Google Colab. I'm using Tensorflow 2.2.0\r\n\r\nWhen I try to run my code to import tensorflow_probability as tfp.\r\n\r\n`import tensorflow_probability as tfp\r\nimport tensorflow as tf`\r\n\r\nAnd then when I execute I get : \r\n`ImportError: cannot import name 'compiler' `\r\n\r\n\r\n\r\n", "comments": ["@LucasColas \r\n\r\nI have tried in colab with TF version 2.2.0 and i am not seeing any issue.Please, find the gist [here.](https://colab.sandbox.google.com/gist/ravikyram/ea2fd1e6569cc8e7cfaede2f9634f66e/untitled936.ipynb).Thanks!", "I tried your gist, and now it's working ! I think it was a problem of version. Thank you !", "@LucasColas \r\n\r\nI am closing this thread as your issue was resolved.Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40001\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40001\">No</a>\n"]}, {"number": 40000, "title": "TFLite, 2.2.0, accuracy drops significantly when tf.lite.Optimize.DEFAULT option is used", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): ubuntu\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (or github SHA if from source):\r\n\r\n\r\n**Command used to run the converter or code if you\u2019re using the Python API**\r\nIf possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\nColab:\r\nhttps://colab.research.google.com/drive/1Z2Xvh2dufYR8y9U-9735KgBOGYYd9NtN#scrollTo=X-vMKEjgTIp0\r\n\r\n```\r\nimport tensorflow as tf\r\nprint(tf.__version__)\r\n\r\nfrom tensorflow.keras.applications import MobileNet\r\nfrom tensorflow.keras.layers import *\r\nfrom tensorflow.keras.models import *\r\nimport numpy as np\r\nimport random\r\nimport tensorflow_datasets as tfds\r\n\r\nnp.random.seed(42)\r\ntf.random.set_seed(42)\r\n\r\ntrain_ds, validation_ds = tfds.load(\r\n    \"tf_flowers\",\r\n    split=[\"train[:90%]\", \"train[90%:]\"],\r\n    as_supervised=True\r\n)\r\n\r\nsize = (224, 224)\r\ntrain_ds = train_ds.map(lambda x, y: (tf.image.resize(x, size), y))\r\nvalidation_ds = validation_ds.map(lambda x, y: (tf.image.resize(x, size), y))\r\n\r\ndef normalize_img(img, label):\r\n    img = tf.cast(img, tf.float32) / 255.\r\n    return (img, label)\r\n\r\ntrain_ds = train_ds.map(normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE).\\\r\n    shuffle(1024).\\\r\n    batch(32).\\\r\n    prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\r\nvalidation_ds = validation_ds.map(normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE).\\\r\n    batch(32).\\\r\n    prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\r\n\r\nbase = MobileNet(weights=\"imagenet\", include_top=False,\r\n                    input_shape=(224, 224, 3))\r\n\r\ndef get_training_model():\r\n    base.trainable = False\r\n    class_head = base.output\r\n    class_head = GlobalAveragePooling2D()(class_head)\r\n    class_head = Dense(512, activation=\"relu\")(class_head)\r\n    class_head = Dropout(0.5)(class_head)\r\n    class_head = Dense(5, activation=\"softmax\")(class_head)\r\n\r\n    classifier = Model(inputs=base.input, outputs=class_head)\r\n\r\n    classifier.compile(loss=\"sparse_categorical_crossentropy\", \r\n                          optimizer=\"adam\",\r\n                          metrics=[\"accuracy\"])\r\n\r\n    return classifier\r\n\r\ntest_model = get_training_model()\r\nhistory = test_model.fit(train_ds,\r\n              validation_data=validation_ds,\r\n              epochs=5)\r\n\r\ntest_model_dir = \"./test_model\"\r\ntest_model.save(test_model_dir)\r\n\r\nconverter = tf.lite.TFLiteConverter.from_saved_model(test_model_dir)\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\n\r\nquantized_tflite_model = converter.convert()\r\nf = open(\"test_model.tflite\", \"wb\")\r\nf.write(quantized_tflite_model)\r\nf.close()\r\n\r\n# Referred from: https://www.tensorflow.org/lite/performance/post_training_integer_quant\r\ndef evaluate_model(interpreter):\r\n    accurate_count = 0\r\n\r\n    input_index = interpreter.get_input_details()[0][\"index\"]\r\n    output_index = interpreter.get_output_details()[0][\"index\"]\r\n\r\n    # Run predictions on every image in the \"test\" dataset.\r\n    predictions = []\r\n    for (val_images, val_labels) in validation_ds:\r\n        for val_image, val_label in zip(val_images, val_labels):\r\n            val_image = tf.expand_dims(val_image, 0)\r\n            interpreter.set_tensor(input_index, val_image)\r\n\r\n            # Run inference.\r\n            interpreter.invoke()\r\n\r\n            # Post-processing: remove batch dimension and find the digit with highest\r\n            # probability.\r\n            probability = interpreter.get_tensor(output_index)\r\n            flower_id = np.argmax(probability[0])\r\n            predictions.append(flower_id)\r\n\r\n            # Compare prediction results with ground truth labels to calculate accuracy.\r\n            if flower_id == val_label:\r\n                accurate_count += 1\r\n    \r\n    accuracy = accurate_count * 1.0 / len(predictions)\r\n\r\n    return accuracy\r\n\r\ninterpreter_test = tf.lite.Interpreter(model_path=\"test_model.tflite\")\r\ninterpreter_test.allocate_tensors()\r\n\r\naccuracy = evaluate_model(interpreter_test)\r\nprint(\"accuracy is {}\".format(accuracy))\r\n\r\n```\r\n\r\n**The output from the converter invocation**\r\n\r\n```\r\naccuracy is 0.4332425068119891\r\n```\r\n\r\n**Failure details**\r\nIf I remove the line:\r\n**converter.optimizations = [tf.lite.Optimize.DEFAULT]**\r\nfrom the script, then \r\naccuracy is 0.9264305177111717\r\n\r\nThe converted model with this settings is wrong.", "comments": ["Hi @wwwind,\r\nenabling `converter.optimizations = [tf.lite.Optimize.DEFAULT]` results in the weights being quantized from `float32` to `int8` - see [here](https://www.tensorflow.org/lite/performance/post_training_quantization#dynamic_range_quantization).\r\nIf you disable this option your converted network stores the weights in `float32`, as your original keras model. You shouldn't see a difference in accuracy and network size. While your network with `int8` weights should be ~1/4 of the size and the accuracy usually decreases.\r\n\r\nQuantizing the weights can result in a significant decrease in the accuracy, as you limit the dynamic range of the weights. You might want to explore the dynamic range of your original network. Looks like your model accuracy suffers immensely under the quantization.\r\n\r\nYou can also try to quantize the weights into `float16` and check the accuracy again, see [here](https://www.tensorflow.org/lite/performance/post_training_float16_quant).", "@wwwind,\r\nCould you please check @lheim's comment and let us know if it works. Thanks!", "@amahendrakar No, \r\nThe bug is that with weights quantized, the accuracy drops significantly - \r\nfrom 0.9264305177111717 to 0.4332425068119891\r\nThis does not look right. ", "Was able to reproduce the issue with [TF v2.2](https://colab.research.google.com/gist/amahendrakar/5499064b5f2c4d7efef5fa15157f6389/40000.ipynb) and [TF-nightly](https://colab.research.google.com/gist/amahendrakar/6738428ca9ce427126d2c3c1e22ede01/40000-tf-nightly.ipynb). Please find the attached gist. Thanks!", "@wwwind Are you looking for int8 tflite model or float tflite model? Let me check the converted model and respond to you. Thanks!", "Hi @jvishnuvardhan Problem is that accuracy is much worse with just weights in int8 than when the model is fully int8 quantized.", "@liufengdb could you take a look at this?", "@wwwind I think this was resolved in recent `tf-nightly`. I cannot reproduce low accuracy issue with `tf-nightly`. Please check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/01f38bea020865c336258d81fe7ba9ed/40000-tf-nightly.ipynb). Thanks!\r\n\r\nPlease verify once and close the issue if this was resolved for you. Thanks!", "thanks for fixing!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40000\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40000\">No</a>\n"]}, {"number": 39999, "title": "Wrong output shape with ellipsis in tflite from keras models", "body": "I'm working on converting a model using tflite, starting from a keras model, and I noticed that if I use ellipsis to slice up tensors something weird happens: once I loaded the tflite model inside the interpreter, before allocating tensors (through `interpreter.allocate_tensors`) calling the function `interpreter.get_output_details()` gives as output shape the same one that I got with my keras model, but after the tensor allocations `interpreter.get_output_details()` gives an output shape different from the one of the keras model. This does not happen if I use normal slicing instead of ellipsis.\r\nI create a toy example for replicating this behavior:\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow.keras import layers\r\nfrom tensorflow import keras\r\n\r\ninput_layer = keras.Input(shape=(3, 4))\r\nX = layers.Dense(10)(input_layer)\r\nX = layers.Dense(1)(X)[..., 0]      #      <-----------  with ellipsis\r\nmodel = keras.Model(input_layer, X)\r\nloss = keras.losses.MeanSquaredError()\r\noptimizer = keras.optimizers.Adam()\r\nmodel.compile(optimizer, loss=loss)\r\nmodel.fit(\r\n    np.random.random((10, 3, 4)).astype(np.float32),\r\n    np.ones((10, 3)).astype(np.float32),\r\n    epochs=10,\r\n    batch_size=5,\r\n)\r\ntflite_model_multi = tf.lite.TFLiteConverter.from_keras_model(\r\n    model\r\n)\r\ntflite_model_multi = tflite_model_multi.convert()\r\n\r\nwith open('my_model.tflite', 'wb') as fin:\r\n    fin.write(tflite_model_multi)\r\ninterpreter = tf.lite.Interpreter(model_path='my_model.tflite')\r\nprint(interpreter.get_output_details())\r\ninterpreter.allocate_tensors()\r\nprint(interpreter.get_output_details())\r\n```\r\noutputs:\r\n```\r\n[{'name': 'Identity', 'index': 14, 'shape': array([1, 3], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}}]\r\n[{'name': 'Identity', 'index': 14, 'shape': array([1, 1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}}]\r\n```\r\n Instead if in the same chunk of code I use slices:\r\n```\r\n...\r\nX = layers.Dense(1)(X)[:, :, 0]      #      <-----------  without ellipsis\r\n...\r\n```\r\nit outputs\r\n```\r\n[{'name': 'Identity', 'index': 14, 'shape': array([1, 3], dtype=int32), 'shape_signature': array([1, 3], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\r\n[{'name': 'Identity', 'index': 14, 'shape': array([1, 3], dtype=int32), 'shape_signature': array([1, 3], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\r\n```\r\n\r\nI don't know if this behavior is wanted, but likely one can spend easily a couple of hours debugging around in order to find it.", "comments": ["@lkubin \r\nI ran the code shared and face a different error, please find the [gist here](https://colab.sandbox.google.com/gist/Saduf2019/3853ecfcd242b09241a3add0aa25ced4/untitled205.ipynb)", "@Saduf2019 I see, the error is expected and in this case it is needed, the fact is that I'm not facing that error. The only difference between my environment and your one is that I'm using python 3.7.4 and tensorflow 2.2.0 running on ubuntu 18.04. I have an environment running 3.6.10 and even on that I cannot reproduce the exception that is throwing to you, the weird part is that I created a brand new environment with python 3.6.9 and even on that one the error message is not shown. ", "I just run the same code with tensorflow==2.1.0 and I confirm that the error is raised as expected ", "As the error suggests: `RuntimeError: tensorflow/lite/kernels/strided_slice.cc ellipsis_mask is not implemented yet.Node number 8 (STRIDED_SLICE) failed to prepare.`\r\n\r\n\r\nWe do not support models where the `StridedSlice` op has the `ellipsis_mask` field set to a non-zero value. In the  'with ellipsis' case, this field has a value of 1 as result of which the error is raised. \r\n\r\nMarking this as resolved. \r\n\r\n ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39999\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39999\">No</a>\n", "@MeghnaNatraj  the problem is that I didn't receive that error message.  The message is fine and it is pretty explicit about what's going on.\r\nThe tag here is wrong I'm not running tf 2.1 but tf 2.2, in tf 2.1 the error message correctly appears, in version 2.2 it doesn't. \r\n\r\nsee\r\nhttps://github.com/tensorflow/tensorflow/issues/39999#issuecomment-638946876", "@lkubin  You are right! Sorry I think I misunderstood the problem before. I was able to reproduce the issue. There is no error in 2.2 (and instead the output tensor shape is incorrect after being allocated in the interpreter) but I did successfully get an error in 2.1 and 2.2rc4. I'll update this issue once I figure out the right way to resolve this problem.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39999\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39999\">No</a>\n"]}, {"number": 39998, "title": "STOP UPDATING", "body": "More updations, more pains!!!\r\n", "comments": ["@creatist \r\nPlease provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. \r\n\r\nMake sure you also include the code snippet to reproduce the issue. If you are unclear what to include see the issue template displayed in the Github [new issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 39997, "title": "Clarify documentation of output shape from DepthwiseConv2D", "body": "The number of output channels is the number of input channels multiplied by the `depth_multiplier`.", "comments": ["@tanzhenyu I have rebased it to try make import/copybara accept it. Please re-review."]}, {"number": 39996, "title": "tf.Module break gradient registration", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab default\r\n\r\n**Describe the current behavior**\r\nWhen using operations within a tf.Module init, the gradient is broken\r\n\r\n**Describe the expected behavior**\r\nThe gradient should still be registered properly\r\n\r\n**Standalone code to reproduce the issue**\r\nhttps://colab.research.google.com/drive/1X3DTc5-E-WadufSHUbVfBnVFEPQ0iOSR?usp=sharing\r\n", "comments": ["Was able to reproduce the issue with [TF v2.2](https://colab.research.google.com/gist/amahendrakar/af9e7b3b1a72432c7561691518453a40/39996.ipynb) and [TF-nightly](https://colab.research.google.com/gist/amahendrakar/627d9652a3c45160e098f4bdb32d0fef/39996-tf-nightly.ipynb). Please find the attached gist. Thanks!", "So I think the issue is that you're doing computation in __init__ but not wrapping that in the GradientTape call.\r\n\r\nModifying the code as \r\n\r\n```\r\nphi = tf.Variable(tf.zeros(5), trainable=True)\r\nwith tf.GradientTape() as tape:\r\n  m = MyModule(phi)\r\n  x = tf.ones(5)\r\n  tape.watch(phi)\r\n  res = m.fun(x)\r\nprint(tape.gradient(res, phi))\r\n```\r\n\r\nseems to work now. Let me know if you run into more issues.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39996\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39996\">No</a>\n", "Yes you're right that was me being stupid. Sorry to have made you lost time"]}, {"number": 39995, "title": "broadcasting behavior in tensorflow keras layers vs base tensorflow operators", "body": "ubuntu : 20.04\r\nTensorflow : 2.2.0\r\n\r\nTensorflow keras layers have different broadcasting semantics than numpy broadcasting (same as tensorflow core). Briefly speaking, AFAIK, broadcasting should keep adding a dimension on left hand side to the point where ndim of two arrays being operated on become equal and then the operation is carried out by required number of replications along all the axis of size 1. for example (5,10) + (2,5,10) would be changed to (1,5,10) + (2,5,10) and then (1,5,10) would be added to (2,5,10) by replicating itself along axis 2. But keras does not seem to follow this. Below is the code to reproduce the issue\r\n```\r\nfrom tensorflow import keras as k\r\nfrom tensorflow.keras import layers as l\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\ninp = k.Input(shape=(10),dtype=tf.float32)\r\nvec1 = tf.constant(np.arange(start=1000,stop=1010,dtype=np.float32).reshape(10,))\r\nvec2 = tf.constant(np.arange(start=100,stop=110,dtype=np.float32).reshape(1,10))\r\nou1 = inp+vec1\r\nou2 = l.Add()([inp,vec1])\r\nou3 = inp+vec2\r\nou4 = l.Add()([inp,vec2])\r\nout5 = vec1+vec2\r\nprint(ou1,'\\n',ou2,'\\n',ou3,'\\n',ou4,'\\n',ou5)\r\nout6 = l.Add()([vec1,vec2])\r\n\r\n\r\n```\r\noutput:\r\n```\r\nTensor(\"AddV2_55:0\", shape=(None, 10), dtype=float32) \r\nTensor(\"AddV2_56:0\", shape=(10, 10), dtype=float32) \r\nTensor(\"AddV2_57:0\", shape=(None, 10), dtype=float32) \r\nTensor(\"AddV2_58:0\", shape=(None, 10), dtype=float32) \r\nTensor(\"Add_1:0\", shape=(None, 10), dtype=float32)\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-49-0cd687be06bc> in <module>\r\n     13 out5 = vec1+vec2\r\n     14 print(ou1,'\\n',ou2,'\\n',ou3,'\\n',ou4,'\\n',ou5)\r\n---> 15 out6 = l.Add()([vec1,vec2])\r\n     16 \r\n\r\n~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py in __call__(self, *args, **kwargs)\r\n    962         # Eager execution on data tensors.\r\n    963         with backend.name_scope(self._name_scope()):\r\n--> 964           self._maybe_build(inputs)\r\n    965           cast_inputs = self._maybe_cast_inputs(inputs)\r\n    966           with base_layer_utils.autocast_context_manager(\r\n\r\n~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py in _maybe_build(self, inputs)\r\n   2414         # operations.\r\n   2415         with tf_utils.maybe_init_scope(self):\r\n-> 2416           self.build(input_shapes)  # pylint:disable=not-callable\r\n   2417       # We must set also ensure that the layer is marked as built, and the build\r\n   2418       # shape is stored since user defined build functions may not be calling\r\n\r\n~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/utils/tf_utils.py in wrapper(instance, input_shape)\r\n    314     if input_shape is not None:\r\n    315       input_shape = convert_shapes(input_shape, to_tuples=True)\r\n--> 316     output_shape = fn(instance, input_shape)\r\n    317     # Return shapes from `fn` as TensorShapes.\r\n    318     if output_shape is not None:\r\n\r\n~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/layers/merge.py in build(self, input_shape)\r\n    100       raise ValueError(\r\n    101           'Can not merge tensors with different '\r\n--> 102           'batch sizes. Got tensors with shapes : ' + str(input_shape))\r\n    103     if input_shape[0] is None:\r\n    104       output_shape = None\r\n\r\nValueError: Can not merge tensors with different batch sizes. Got tensors with shapes : [(10,), (1, 10)]\r\n```\r\n", "comments": ["I am able to replicate this issue, please find the [gist here](https://colab.sandbox.google.com/gist/Saduf2019/73e91c8d3f3e1a9091d69a771b0a0254/untitled208.ipynb) ", "any updates on this?", "I was able to reproduce the issue using TF 2.5. please find the gist [here](https://colab.research.google.com/gist/saikumarchalla/70e5a61bd24940441463a2f5b1b10986/untitled80.ipynb).Thanks!", "I was able to replicate issue in `tf2.6` and `tf-nightly(2.8.0-dev20211012)`. Please find the gist [here](https://colab.research.google.com/gist/chunduriv/bb5a62a8e81e281a7cd62af885319f39/39995.ipynb#scrollTo=I5C3xKFDEfWM).Thanks!\r\n\r\n", "Hi There,\n\n This is a stale issue. As you are using an older version of tensorflow, we are checking to see if you still need help on this issue. Please test the issue with the latest TensorFlow (TF2.7 and tf-nightly). If the issue still persists with the newer versions of TF, please feel free to open it in [keras-team/keras](https://github.com/keras-team/keras/issues) repository by providing details about the issue and a standalone code to reproduce the issue. Thanks! \n\n Please note that Keras development has moved to a separate Keras-team/keras repository to focus entirely on only Keras. Thanks! ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39995\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39995\">No</a>\n"]}, {"number": 39994, "title": "Make third_party/gpus/... build pass. fix issue #39759", "body": "", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F39994) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!\r\n", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F39994) for more info**.\n\n<!-- ok -->"]}, {"number": 39993, "title": "TensorFlow 2.2.0 - Can't create layer of type \"Max\" in function 'getLayerInstance' OpenCV", "body": "**System information**\r\nhttps://pastebin.com/QVAkgHib\r\n- Tensorflow-GPU => 2.2.0\r\n- OpenCV => 4.3.0-dev\r\n- Operating System / Platform => Ubuntu 20.04\r\n- Compiler => GCC 8.4.0\r\n\r\nI have created a Triplet Model based on a ResNet50: \r\n```\r\n    base_model = ResNet50(weights='imagenet', include_top=False, pooling='max')\r\n    for layer in base_model.layers:\r\n        layer.trainable = False\r\n    x = base_model.output\r\n    x = Dropout(0.6)(x)\r\n    x = Dense(embedding_dim)(x)\r\n    out = Lambda(lambda x: K.l2_normalize(x, axis=1))(x)\r\n    embedding_model = Model(base_model.input, out, name=\"embedding\")\r\n```\r\nAfter training this model, I froze all the layers and then saved it like this:\r\n```\r\n    for layer in embedding_model.layers:\r\n        layer.trainable = False\r\n    embedding_model.save('triplet_embedding_model')\r\n```\r\nwhich results in a folder containing a pb file and assets and variables folder.\r\n\r\nThen I am using the following script to generate a frozen graph based on the model saved earlier: \r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2\r\nimport os\r\nos.environ['CUDA_VISIBLE_DEVICES'] = '-1'\r\n\r\n\r\nloaded = tf.saved_model.load('triplet_embedding_model')\r\ninfer = loaded.signatures['serving_default']\r\n\r\nf = tf.function(infer).get_concrete_function(input_1=tf.TensorSpec(shape=[None, 224, 224, 3], dtype=tf.float32))\r\nf2 = convert_variables_to_constants_v2(f)\r\ngraph_def = f2.graph.as_graph_def()\r\n\r\n# Export frozen graph\r\nwith tf.io.gfile.GFile('frozen_graph.pb', 'wb') as f:\r\n   f.write(graph_def.SerializeToString())\r\n```\r\nWhen I try to load the model in OpenCV using: \r\n```\r\nnet = cv2.dnn.readNet('frozen_graphs/frozen_graph.pb')\r\n```\r\nI get the following error: \r\n```\r\ncv2.error: OpenCV(4.3.0-dev) /home/andreilica/OpenCV/opencv/modules/dnn/src/dnn.cpp:610: error: (-2:Unspecified error) Can't create layer \"StatefulPartitionedCall/StatefulPartitionedCall/embedding/max_pool/Max\" of type \"Max\" in function 'getLayerInstance'\r\n```\r\nWhat am I doing wrong here? ", "comments": ["@andreilica \r\n\r\nLooks like the error is with opencv and not Tensorflow. If you feel the error is related to Tensorflow please share colab link or simple standalone code to reproduce the issue in our environment.It helps us in localizing the issue faster.Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39993\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39993\">No</a>\n"]}, {"number": 39992, "title": "Suboptimal execution order of parallel map calls for tf.data", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 and Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.2\r\n- Python version: 3.6.7\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**Describe the current behavior**\r\nWhen using a num_parallel_calls larger than the number of worker threads in the threadpool in a Dataset.map call, the order of execution is more or less random, causing a busty output behavior.\r\n\r\nIf the dataset map transform has a list of 20 elements to process, it typically processes them in a order that looks something like this:\r\n5, 4, 7, 6, 1, 0, 2, 3, 18, 15, 10, 9, 13, 19, 14, 8, 17, 10, 12, 11\r\n\r\nThis is problematic since the output has to be contiguous, so no output will be available until a large portion of the calls in the threadpool have been processed.\r\n\r\nI have attached a file with a self contained example which reproduces this behavior.\r\n\r\nThere are workarounds, such as allowing non-deterministic output, but in the long run, we want our trainings to be as deterministic as possible to aid debugging, so fixing this behavior would be very helpful for us.\r\n\r\n\r\n**Describe the expected behavior**\r\nI expect the map call to start processing the next unprocessed element in the dataset whenever it has a free worker thread, so the results can be made available as soon as possible.\r\n\r\n**Standalone code to reproduce the issue**\r\nSee attached file.\r\n[parallel_map_test.zip](https://github.com/tensorflow/tensorflow/files/4702027/parallel_map_test.zip)\r\n\r\n\r\n**Other info / logs**\r\nExample output from the code is also available in the attached file.\r\n", "comments": ["Was able to reproduce the issue with [TF v2.2](https://colab.research.google.com/gist/amahendrakar/8471d51d7c8204008b6d6e62726ae9bf/39992.ipynb) and [TF-nightly](https://colab.research.google.com/gist/amahendrakar/1a32d5ca9f34b8dcb1b68916d3430cc6/39992-tf-nightly.ipynb). Please find the attached gist. Thanks!", "@eriikj tf.data uses Eigen's threadpool [under the hoods](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/platform/threadpool.cc#L96-L106), which does not guarantee FIFO scheduling. Switching to a different threadpool implementation and/or implementing FIFO ordering within tf.data would be non-trivial and it is not clear to me that it would be worthwhile.\r\n\r\nAs per tf.data [performance guide](https://www.tensorflow.org/guide/data_performance), users are recommended to use `tf.data.experimental.AUTOTUNE` for `num_parallel_calls` and leave the determination of the optimal value to the tf.data runtime. It is much more likely that the tf.data team will prioritize improving the autotuning logic over improving performance of misconfigured input pipelines.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39992\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39992\">No</a>\n", "Sorry, didn't mean to close this -- to give you a chance to respond.", "I'm not sure why you consider this to be misconfigured, but fair enough. I will try using autotune and see what happens. Is it ok to keep the issue open until I have tested this?\r\n\r\nAs a side note: autotune would likely be able to do a better job if it didn't have to deal with this problem, so when improving autotune, it might be worthwhile to keep this in mind.", "@eriikj \r\nI think using autotune is the same as setting a lower num_parallel_calls, because the inner logic of autotune in ParallelMapDataset is:\r\n```c++\r\n      if (num_parallel_calls_->value == model::kAutotune) {\r\n        num_parallel_calls_->value = ctx->runner_threadpool_size();\r\n      }\r\n```\r\nAny reason why you need a num_parallel_calls that is much larger than worker threads in the threadpool?", "@zhuzilin \r\nIf that's how autotune works, using it will cause another problem. Our first approach was to just use num_parallel_calls=8 (which is the same as the threadpool size), but we found that we did not have the same performance as before using the tf.data API (we are currently using a Keras Sequence as input, which handles the queuing as expected in these cases).\r\n\r\nMy first investigation found that setting num_parallel_calls to 8 implicitly creates a queue limited to the same size 8. Every started call holds a place in the queue until it can be sent as output. Since the output still has to be in order, this might be at a time later than when the call is completed. This causes the queue to sometimes be full, even though there are worker threads without work, causing a loss in performance. I thought that increasing the number of parallel calls, but keeping the number of worker threads low would solve this, and that's when I ran into the problem originally described in this issue.\r\n\r\nI have attached a modified variant of the example I provided earlier with the same problems we saw with that configuration (with a little more variance in the sample fetch time to amplify the problem).\r\n\r\n[parallel_map_test_num_parallel_calls_8.zip](https://github.com/tensorflow/tensorflow/files/4723607/parallel_map_test_num_parallel_calls_8.zip)\r\n\r\nHere is a part of the output from the script which illustrates the problem that some worker threads have to wait (in this case more than a second) to start processing a new call:\r\n\r\n2020-06-03 15:15:58.447852: I tensorflow/core/kernels/logging_ops.cc:166] started 31\r\n2020-06-03 15:15:58.456823: I tensorflow/core/kernels/logging_ops.cc:166] stopped 26\r\n2020-06-03 15:15:58.505422: I tensorflow/core/kernels/logging_ops.cc:166] stopped 28\r\n2020-06-03 15:15:58.571174: I tensorflow/core/kernels/logging_ops.cc:166] stopped 30\r\n2020-06-03 15:15:58.909244: I tensorflow/core/kernels/logging_ops.cc:166] stopped 25\r\n2020-06-03 15:15:59.413419: I tensorflow/core/kernels/logging_ops.cc:166] stopped 24\r\n2020-06-03 15:15:59.609620: I tensorflow/core/kernels/logging_ops.cc:166] stopped 23\r\n2020-06-03 15:15:59.610705: I tensorflow/core/kernels/logging_ops.cc:166] output available: 23\r\n2020-06-03 15:15:59.611575: I tensorflow/core/kernels/logging_ops.cc:166] started 32\r\n", "My definition for misconfiguration is to be using a fixed value of `num_parallel_calls` that results in sub-optimal performance.\r\n\r\nI do not follow your explanation for why using `num_parallel_calls` that matches the size of the threadpool did not work for you. I am also not sure how to interpret your comment about the use of Keras Sequence API; are you currently using Keras Sequence APIs and are in the process of switching to tf.data? or have you used tf.data and because of issue with `num_parallel_calls` switched to using Keras Sequence API?\r\n\r\nAs for parallel map internals: the `num_parallel_calls` argument controls two things: 1) the maximum degree of parallelism and the size of internal buffer used for storing the results. If the buffer is full, the no further computation is performed. If you find the depth of the buffer insufficient (because of variance in the speed of produced and consumer), you should add `prefetch` to your input pipeline (as opposed to increasing the size of `num_parallel_calls` beyond the size of the threadpool).", "We are currently using the Keras Sequence API and trying to migrate to the tf.data API.\r\n\r\nWe are limited by our data pipeline, prefetch does not do anything for us, since all elements are consumed almost immediately.\r\n\r\nI have provided some code that should illustrate the problem with setting num_parallel_calls to the same as the number of threads in the pool, but I will try to explain the problem as well:\r\n\r\nIf we have 8 worker threads and num_parallel_calls set to 8, we will have a internal buffer of size 8 as well. If we have 8 calls (call 0 to 7) running in 8 threads and any call after call 0 finishes before call 0. the results of the finished calls will occupy a position in the buffer until all calls before it finishes. This causes the that thread to sit idle during this time.\r\n\r\nHere is an example of when worker threads are idle, even though the dataset has more items to process:\r\n\r\ninitial state: 0, 1, 2, 3, 4, 5, 6, 7 running\r\ncall 5 finishes: 0, 1, 2, 3, 4, 6, 7 running, the results of call 5 still in the buffer (thread 5 is idle)\r\ncall 6 finishes: 0, 1, 2, 3, 4, 5, 6, 7 running, the results of call 5 and 6 still in the buffer (thread 5 and 6 are idle)\r\ncall 0, 1, 2, 3 and 4 finishes: 7, 8, 9, 10, 11, 12, 13, 14 running, results of call 0, 1, 2, 3, 4, 5 and 6 is sent as output\r\n\r\nThis would also apply to the case with autotune, if it works as stated in the comments above (that it simply sets num_parallel_calls to the number of worker threads). It's possible that better autotune logic might work around this problem, but I think it would be easier to address the cause of the problem. I realize that the change might not be trivial (I actually had a go at it before writing this issue, but came to the same conclusion), so I guess it comes down to a question of priority.", "Thank you for your explanation. I acknowledge the problem. A possible solution for it would be to decouple the configuration of parallelism from the configuration of the buffering. I was hoping to achieve this using existing building blocks through my suggestion to use `prefetch` but I realized it would not work because of head-of-the-line blocking. \r\n\r\nAs you pointed out, it is possible to avoid this issue by using non-determinism. What you are requesting is to improve the performance of deterministic parallel map (at the expense of increased memory usage). However, there is a fundamental trade-off between performance and determinism. Even if tf.data would allow for extra buffering in its map transformation, the performance might not be as good as for the non-deterministic transformation (unless the buffering is unlimited but even then non-deterministc execution might achieve better cache locality). \r\n\r\nFor what it is worth, most users are happy with the \"fast and non-deterministic\" and \"slower and deterministic\" options. Having said that, I think that we should be able to investigate opportunities for the decoupling the parallelism and buffer size configurations in the context of our ongoing autotuning efforts.\r\n\r\n", "@jsimsa \r\nApart from the trade-off between buffer size and performance, I think one barrier of implementing the background buffer of parallel mapping is that it is not sure whether it need to process the next one. For example, we may have code like:\r\n```python\r\ndef parse_and_preprocessing(x):\r\n  # very slow\r\n\r\nds = tf.data.Dataset.TFRecordDataset(\"example.tfrecord\")\r\nds = ds.repeat()\r\nds = ds.map(parse_and_preprocessing, num_parallel_calls=10)\r\nds = ds.take(3)\r\n```\r\nIn this snippet, the map does not need to continue to process more than 3 elements and make it continue to run in background may be wasteful. For this specific problem, we may add a grappler pass to hoist the `take`. But the main idea is the dataset op has no idea what will happen after it. I believe some systematic graph optimization for the data pipeline would help. I wonder if this is among the team's interests and I'd love to contribute :).", "@zhuzilin the inefficiency related to asychronously pre-computing more data than is needed is not specific to this issue and applies to any of the existing asynchronous tf.data transformations (parallel map, parallel interleave, fused map + batch, and prefetch).\r\n\r\nPushing transformations that discard data (such as `skip`, `take`, and `shard`) as close to the data source as possible through graph rewrites makes sense and the tf.data team would welcome your contributions to that end. To get started, I suggest you take a look at existing tf.data [graph rewrites](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/core/grappler/optimizers/data), such as the [no-op elimination](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/grappler/optimizers/data/noop_elimination.cc) optimization.", "@jsimsa Great! Thank you for your advice and I'll start working on that.", "Was able to reproduce your issue in Tf Nightly 2.6.0-dev20210531, please find the gist [here](https://colab.research.google.com/gist/sachinprasadhs/ca03b425f5ddd67bbe6e71cdfeb3b447/39992.ipynb). Thanks!", "Hi @eriikj ! \r\nWe are checking to see whether you still need help in this issue. Have you checked above [suggestion](https://github.com/tensorflow/tensorflow/issues/39992#issuecomment-642797494) yet?", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39992\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39992\">No</a>\n"]}, {"number": 39990, "title": "Add TF-TRT converter for Shape op", "body": "This PR adds TF-TRT converter for the shape op. To facilitate testing, the following additional changes were made:\r\n - Test helper routines modified to handle different output data types.\r\n - Test helper and profile creation routines updated to handle TRT engines that have no input tensors.", "comments": ["@tfeher  Can you please resolve conflicts? Thanks!", "@tfeher Any update on this PR? Please. Thanks!", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "Sorry for the delay.  I will update the PR soon. This, and many of the TF-TRT PRs that I have opened, are part of a large series of PRs that update / improve all the TF-TRT op converter tests. I will work on this as soon as some open issues are fixed in other related PRs.", "I don't see a way to response to this, so copy the link and response here https://github.com/tensorflow/tensorflow/pull/39990#discussion_r458295651\r\nI am fine with either renaming here or in another PR.\r\n"]}]