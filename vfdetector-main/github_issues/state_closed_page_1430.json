[{"number": 10073, "title": "fail to load tensorflow 1.1.0 inside docker container - libcuda.so.1 missing", "body": "Hi,\r\n\r\nI ran into this bug while trying to upgrade tensorflow version to 1.1.0\r\nUsing 'nvidia/cuda:8.0-cudnn5-devel-ubuntu16.04' docker image (I also tried other docker images as well).\r\n\r\nNote that same code runs fine with tensorflow 1.0.0\r\n\r\nAttached is python script that prints tensorflow version (see README.txt for instruction of how to build & run the docker image). \r\n[fail-to-load-tf-bug.zip](https://github.com/tensorflow/tensorflow/files/1016737/fail-to-load-tf-bug.zip)\r\n\r\n\r\nHere is the stack trace for tensorflow 1.1.0:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/run.py\", line 3, in <module>\r\n    import tensorflow as tf\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py\", line 51, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py\", line 52, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py\", line 41, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\nImportError: libcuda.so.1: cannot open shared object file: No such file or directory\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n```\r\n\r\n\r\nHere is the logs for tensorflow 1.0.0: (Here it works fine)\r\nPlease pay attention message 'Couldn't open CUDA library libcuda.so.1'\r\n```\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:126] Couldn't open CUDA library libcuda.so.1. LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\r\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:165] hostname: 522f0c0e9705\r\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] libcuda reported version is: Not found: was unable to find libcuda.so DSO loaded into this program\r\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:193] kernel reported version is: Permission denied: could not open driver version path for reading: /proc/driver/nvidia/version\r\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1065] LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\r\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1066] failed to find libcuda.so on this system: Failed precondition: could not dlopen DSO: libcuda.so.1; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally\r\ntensorflow version 1.0.0\r\ntensorflow git version v1.0.0-rc2-15-g47bba63-dirty\r\n```\r\n\r\n\r\nThanks :)\r\nErez\r\n\r\nP.S:\r\nI built and ran the docker image on 2 machines:\r\n* MAC \r\n    - Docker version 17.03.1-ce, build c6d412e\r\n    - no GPU\r\n* Ubuntu 14.04.5 LTS \r\n   - Docker version 1.13.0, build 49bf474 \r\n   - GPU info:\r\n\r\n```\r\n$nvidia-smi\r\nSun May 21 11:11:31 2017\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 367.57                 Driver Version: 367.57                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  GeForce GTX TIT...  Off  | 0000:05:00.0     Off |                  N/A |\r\n| 22%   57C    P8    31W / 250W |      0MiB / 12206MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   1  GeForce GTX TIT...  Off  | 0000:06:00.0     Off |                  N/A |\r\n| 22%   54C    P8    21W / 250W |      0MiB / 12206MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   2  GeForce GTX TIT...  Off  | 0000:09:00.0     Off |                  N/A |\r\n| 22%   45C    P8    15W / 250W |      0MiB / 12206MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   3  GeForce GTX TIT...  Off  | 0000:0A:00.0     Off |                  N/A |\r\n| 22%   36C    P8    16W / 250W |      0MiB / 12206MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n\r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID  Type  Process name                               Usage      |\r\n|=============================================================================|\r\n|  No running processes found                                                 |\r\n+-----------------------------------------------------------------------------+  \r\n\r\n```", "comments": ["To use GPU docker images, you have to use `nvidia-docker`\r\nDid you start your docker containers using `nvidia-docker`?", "Hi, \r\nThanks for the response. \r\n\r\nYou are right, running with nvidia-docker works.\r\n\r\nBut it used to work also with docker (just not using the GPU).\r\nIs there any way to support using docker command line?\r\n\r\nI want to explain the motivation:\r\n\r\nWe use CPU for:\r\n* inference (serving) in production\r\n* train & inference unit tests\r\n* train & inference sanity tests\r\n* developer machines\r\n\r\nWe use GPU for:\r\n* training in production\r\n\r\nEnabling one docker to run both GPU and CPU makes our development cycle simple.\r\nOtherwise for each one of our services we will need to maintain 2 docker images - one of CPU and one for GPU.\r\n\r\nThanks :)\r\nErez", "If you want to run the tensorflow-gpu docker image, you have to use nvidia-docker.\r\nUnfortunately, the way the library is built right now, when TF starts running, it will try to load GPU libraries, and on non-gpu machines I am guessing this is failing.\r\n\r\nI am not aware if our gpu docker images ever worked without nvidia-docker, could you point me to a version that you can get working? If it used to work, maybe we can get it to work the same way. But I cannot promise anything.", "Hi,\r\n\r\nIt used to work in version 1.0.0.\r\n\r\nPlease look in the attachment 'fail-to-load-tf-bug.zip':\r\n\r\nIn the 'Dockerfile':\r\n- comment the line installing tensorflow 1.1.0\r\n- uncomment the line installing tensorflow 1.0.0\r\n\r\nThe Readme.txt file for the docker command to build & run.\r\n\r\nThe 'docker run' command works on 1.0.0 and fails on 1.1.0\r\n\r\nThanks for the help :)\r\nErez\r\n ", "I just tried on my machine, and with 1.0, this is what I see if I use `docker`:\r\n\r\n```\r\n>>> import tensorflow as tf\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:126] Couldn't open CUDA library libcuda.so.1. LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\r\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:165] hostname: 80869fa6cca4\r\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] libcuda reported version is: Not found: was unable to find libcuda.so DSO loaded into this program\r\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:363] driver version file contents: \"\"\"NVRM version: NVIDIA UNIX x86_64 Kernel Module  370.28  Thu Sep  1 19:45:04 PDT 2016\r\nGCC version:  gcc version 4.8.4 (Ubuntu 4.8.4-2ubuntu1~14.04.3) \r\n\"\"\"\r\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:193] kernel reported version is: 370.28.0\r\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1065] LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\r\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1066] failed to find libcuda.so on this system: Failed precondition: could not dlopen DSO: libcuda.so.1; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally\r\n>>> tf.__version__\r\n'1.0.0'\r\n>>> \r\n```\r\n\r\nIt does complain about libcuda.so.1, but I do not see an explicit crash. However, when I try to start a session, I see errors:\r\n```\r\n>>> sess = tf.Session()\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\r\nE tensorflow/stream_executor/cuda/cuda_driver.cc:509] failed call to cuInit: CUDA_ERROR_NO_DEVICE\r\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:152] no NVIDIA GPU device is present: /dev/nvidia0 does not exist\r\n>>> \r\n```\r\n\r\nSo I think the failure was more silent in 1.0, but with 1.1 we crash to avoid further errors.\r\n\r\nadding @martinwicke @vrv to see if they have more input.\r\n", "I think your diagnosis is correct, this never really worked, it just failed silently. \r\n\r\nHowever, I think the 1.0 failure mode is a little more subtle: it is possible that TF worked fine assuming you never placed an op on the GPU. \r\n\r\nThat means that you could always use a GPU build of tensorflow, independent of whether a GPU (or libraries) were actually available. Now, with a GPU build, you actually need CUDA installed.\r\n\r\nI don't think we want to support running GPU tensorflow on non-GPU machines (or rather, non-CUDA machines). I don't see a particularly compelling reason why you would want to do that.", "Hi,\r\n\r\nIt does work for us. \r\n\r\nLet me explain to you our use case.\r\n\r\nI work at Taboola, an Ad Tech company  (I just logged in to github using my private account).\r\n\r\nIn this specific project I am working on:\r\nCurrently We use tensorflow version 12.0.1 in production.\r\nWe A/B test RNNs, CNNs and other deep architectures.\r\n \r\nWe have daily training of models, and a fully automated continues delivery pipeline (both of models and code changes). \r\nAt inference We predict scores for 600K items a second.\r\n\r\nOur team contains 6 members (Data Scientists & Engineers) working full time on this project.\r\n\r\nThe main motivation to use **one image**, in order to keep development & CD cycle simple (see earlier post that explain what runs CPU vs GPU ).\r\n\r\nSo I hope I convinced you this is a real & interesting use case  :)\r\n\r\nI appreciate your effort, and I do understand if you do not want to support it any more.\r\n\r\nThanks,\r\nErez\r\n", "I'm very sympathetic to keeping CD simple. :)\r\n\r\nCan you install CUDA on all your machines, even if they don't have a GPU? That ought to solve the problem. The issue is that the library cannot be loaded. It doesn't complain about not finding a GPU. \r\n\r\nFundamentally, we link against this library, so it's expected to be there -- you can run the same tensorflow installation on all your servers as long as the environment is also the same. But apparently (unless I'm missing something), you have two different environments, one of which lacks a working CUDA installation.", "Thanks for the response:\r\n\r\nI think that there are 3 options here:\r\n\r\n1. Install Cuda on machines (the downside is that it is painful on developer machines)\r\n2. build GPU and CPU docker images\r\n3. build one docker image, and install both GPU and CPU tensorflow versions with virtual env\r\n\r\nI will have to think about what suits us best...\r\n\r\nThanks guys for your time.\r\nKeep up the good work :)", "Looks like @KashiErez is going to work around this problem on their end.\r\nI will close this issue.", "@KashiErez Do you have a recommendation which of these solutions works best?", "Hi Ophiry,\r\n\r\nI found the 3rd solution the best.\r\n\r\nThis post contains a code snippet of the Dockerfile:\r\nhttp://engineering.taboola.com/deep-learning-from-prototype-to-production\r\n\r\nWhen you want to run on CPU, you have to:\r\n   *  override the docker cmd, and use the CPU venv\r\n\r\nWhen you want to run on GPU, you have to do 2 things:\r\n   * override the docker cmd, and use the GPU venv\r\n   * use nvidia-docker command line tool\r\n\r\n  \r\n", "Hi @gunan & @martinwicke,\r\n\r\nMy advice is to add GPU & CPU support at one tensorflow installation, for 2 reasons:\r\n   1. The work around is very tedious\r\n   2. Almost anyone going to production with Tensorflow will face this issue (regardless of using docker)\r\n\r\n@ophiry, do you agree?\r\n\r\nThanks,\r\nErez", "Agree - the simplest thing would be to have tf use GPU if it's avaiable, and CPU if not.\r\nof possibly have a configuration variable that can force GPU, force CPU, or do automatic selection", "A related issue - what is a good way to detect whether a GPU is present?\r\n\r\nlspci is an option, but it requires installing extra packages,", "check that docker-nvidia-plugin is running, wasn't runnig for me and libcuda.so missing was the result\r\nsudo -b nohup nvidia-docker-plugin > /tmp/nvidia-docker.log", "We are facing the same issue. \r\n\r\nWe are building an open-source toolkit called HistomicsTK for analyzing histopathology images. We are currently trying to integrate some keras/tensorflow code into our toolkit. We would like our toolkit to work on all machines (with or without a GPU) and take advantage of the GPU if it is available or default to the CPU.\r\n\r\nWe also have some command-line programs/pipelines based on our toolkit that are packaged into a docker image derived from nvidia/cuda:8.0-cudnn6-devel-ubuntu16.04. We want these to run with both plain `docker run` and `nvidia-docker run`.\r\n\r\nThe solution proposed by @KashiErez of creating two virtual environments -- one with tensforflow installed and another with tensorflow-gpu installed -- works but is very cumbersome.\r\n\r\nAre there any plans of merging tensorflow and tensorflow-gpu into a single package?\r\n\r\n", "In the longer term we have some projects that may merge the two packages, but the short term answer is no.", "FWIW I tried option 1 from @KashiErez  - Installing cuda on non-gpu machines as well. It turns out that while I can in fact install cuda on a machine with no GPUs, nvidia-docker dies with \"unknown error\". My guess is that cuda relies on an actual GPU being present in order to work correctly. Looks like virtualenv is the way to go.", "Try this way\r\n```\r\nversion: '2'\r\nservices:\r\n  tensorflow:\r\n    image: tensorflow/tensorflow:latest-gpu-py3\r\n    devices:\r\n    - /dev/nvidia0:/dev/nvidia0:rwm\r\n    - /dev/nvidiactl:/dev/nvidiactl:rwm\r\n    - /dev/nvidia-uvm:/dev/nvidia-uvm:rwm\r\n    volumes:\r\n    - /usr/lib/x86_64-linux-gnu/libcuda.so:/usr/lib/x86_64-linux-gnu/libcuda.so\r\n    - /usr/lib/x86_64-linux-gnu/libcuda.so.1:/usr/lib/x86_64-linux-gnu/libcuda.so.1\r\n    - /usr/lib/x86_64-linux-gnu/libcuda.so.384.130:/usr/lib/x86_64-linux-gnu/libcuda.so.384.130\r\n    - /usr/lib/nvidia-384/libnvidia-fatbinaryloader.so.384.130:/usr/lib/x86_64-linux-gnu/libnvidia-fatbinaryloader.so.384.130\r\n    ports:\r\n    - 8889:8888/tcp\r\n```"]}, {"number": 10072, "title": "can it stop printing not requested information?", "body": "when i restore a ckpt, I found that there is an automated printing that:\r\n\r\nINFO:tensorflow:Restoring parameters from checkpoint/fnn/params.ckpt-37000\r\n\r\ncan i stop this?", "comments": ["this is better question for stackoverflow (I usually pipe output of TensorFlow through \"grep -v\" to stop unwanted output)"]}, {"number": 10071, "title": "Cannot build jemalloc support using CMake on Linux (fails trying to include <windows.h>)", "body": "I am using the provided cmake build project files to compile tensorflow because I have a custom clang binary built with additional optimization passes of my own.\r\n\r\nThe build works fine without Jemalloc\r\n\r\n    cmake -DCMAKE_BUILD_TYPE=Release ../tensorflow/contrib/cmake/  \r\n    make -j4   # compiles O.K.\r\n\r\nbut when I add the jemalloc option it fails. \r\n\r\n    cmake -Dtensorflow_ENABLE_JEMALLOC_SUPPORT=ON -DCMAKE_BUILD_TYPE=Release ../tensorflow/contrib/cmake/  \r\n    make \r\n\r\n    [  5%] Performing configure step for 'jemalloc'\r\n    -- CMAKE_C_COMPILER_ID: Clang\r\n    -- void* size is 8\r\n    -- int size is 4\r\n    -- long size is 8\r\n    -- long long size is 8\r\n    -- intmax_t size is 8\r\n    -- CMAKE_SYSTEM_NAME: Linux\r\n    -- whether pause instruction is compilable ... yes\r\n    CMake Error at Utilities.cmake:755 (message):\r\n      GetSystemPageSize failed compilation see\r\n      cmake/jemalloc/src/jemalloc/GetPageSize/getpagesize.log\r\n    Call Stack (most recent call first):\r\n      CMakeLists.txt:464 (GetSystemPageSize)\r\n\r\n\r\nLooking at cmake/jemalloc/src/jemalloc/GetPageSize/getpagesize.log there is\r\n\r\n    Building C object CMakeFiles/cmTC_129ba.dir/getpagesize.c.o\r\n    clang     -o CMakeFiles/cmTC_129ba.dir/getpagesize.c.o   -c  tensorflow-github/build-cmake/jemalloc/src/jemalloc/GetPageSize/getpagesize.c\r\n    tensorflow-github/build-cmake/jemalloc/src/jemalloc/GetPageSize/getpagesize.c:1:10: fatal error: 'windows.h' file not found\r\n    #include <windows.h>\r\n                 ^~~~~~~~~~~\r\n    1 error generated.\r\n\r\nBy looking at getpagesize.c it is clear it is a windows-only source file that should not have been compiled on Linux.\r\n\r\nI went further investigating why jemalloc is trying to compile a windows source under Linux but I got nowhere after an hour or so. I lack understanding of the jemalloc build and I will continue to look into this but if you have someone on your side with a more prompt answer, that would save me time, thank you. \r\n", "comments": ["Are you building on windows or linux?", "As the title says, I am building under Linux, which is why I found strange that the build is trying to include a windows-only test.", "This sounds like a bug @mrry.\r\n\r\nAs a workaround, have you considered using Bazel? IIUC the history of cmake in TensorFlow has been primarily to support Windows users.", "I am using cmake because I could not use bazel - after a week trying I gave up. I have to use clang and libc++ (instead of GCC's stdlibc++) and it seems bazel cannot accommodate that. It only supports GCC+STLIBC++ and CLANG+STDLIBC++ native on Linux. To have any other compiler you have to create a completely separate toolchain, which I wrote (here: https://github.com/HFTrader/BazelCustomToolchain) but I could not get bazel to invoke it after a couple of days trying.\r\n\r\nI asked the question about the failing bazel/clang build on your google groups and then I was told to ask it on stack overflow. Here is the link \r\n\r\nhttps://stackoverflow.com/questions/44052877/compiling-tensorflow-with-a-custom-clang-libc-instead-of-stdlibc/44088951#44088951\r\n\r\nSo far it seems the bazel team could not crack this mistery which is baffling to me since it looks like such a common use case. \r\n\r\n", "Apparently it's a bug in the CMake build for jemalloc, which we include:\r\n\r\nhttps://github.com/jemalloc/jemalloc-cmake/blob/88c2dc8be23f85694bc3a3f015e0f9fb8f8ab942/CMakeLists.txt#L1\r\n\r\n```\r\n# This make file supports Windows build of Jemalloc\r\n#\r\n# Prerequisites:\r\n#     You must have Visual Studio 2013 Update 4 installed or Visual Studio 2015 Update 1.\r\n#      Start the Developer Command Prompt window that is a part of Visual Studio installation.\r\n#      This will provide you with the accessible toolchain commands.\r\n#      You must have a path git.exe in your %PATH%.\r\n#\r\n# 1. Create a build directory\r\n#\r\n# 2. Run cmake to generate project files for Windows\r\n#        sample command: cmake -G \"Visual Studio 12 Win64\"  ..\r\n#        OR for VS Studio 15 cmake -G \"Visual Studio 14 Win64\"  [optional switches described below] ..\r\n#\r\n# 3. Then build the project in debug mode (you may want to add /m[:<N>] flag to run msbuild in <N> parallel threads\r\n#                                          or simply /m ot use all avail cores)\r\n#        msbuild jemalloc.sln\r\n#\r\n# 4. And release mode (/m[:<N>] is also supported)\r\n#        msbuild jemalloc.sln /p:Configuration=Release\r\n#\r\n```\r\n\r\nIn particular, that build generates a file that includes the `#include <Windows.h>` and unconditionally compiles it, leading to the mysterious error that you're seeing.\r\n\r\nIt might be possible to rig the CMake build on Linux to include the non-CMake build for jemalloc. Since we're prioritizing the Bazel build on Linux, I'm going to mark this as contributions welcome.", "Gave it a crack today - it looks like that project is also windows-hardcoded everywhere. It will require some extensive intervention to get it to work. ", "Nice, thanks!\n\nOn May 25, 2017 9:23 PM, \"Henrique Bucher\" <notifications@github.com> wrote:\n\n> Gave it a crack today - it looks like that project is also\n> windows-hardcoded everywhere. It will require some extensive intervention\n> to get it to work.\n>\n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/10071#issuecomment-304187446>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AT_SbRFY-caLJDu01z-NkLkEATvW8F6-ks5r9lPEgaJpZM4NhffP>\n> .\n>\n", "I see some discussion in jemalloc about moving to CMake (https://github.com/jemalloc/jemalloc/issues/303). I guess they will be upgrading soon.", "Can we close this?", "Hi @HFTrader! We see that you are using old version of Tensorflow which is officially considered as end of life, We recommend that you upgrade to 2.6 version and let us know if the issue still persists in newer versions .Please open a new issue in case you face any errors, we will get you the right help .Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/10071\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/10071\">No</a>\n"]}, {"number": 10070, "title": "clear compiler warnings in tensor_format.h", "body": "", "comments": ["Can one of the admins verify this patch?", "Jenkins test this please.", "Jenkins test this please."]}, {"number": 10069, "title": "Conversion to int64 for output_buffer_size", "body": "Add conversion to int64 when output_buffer_size is initialized with num_threads (of type int32).\r\n\r\nThe following snippet will output an error `Input 'output_buffer_size' of 'ParallelMapDataset' Op has type int32 that does not match expected type of int64` when `num_threads` is initialized but not `output_buffer_size`.\r\n\r\n```python\r\ndataset = tf.contrib.data.Dataset.range(10)\r\ndataset = dataset.map(lambda x: x+1, num_threads=2)\r\niterator = dataset.make_one_shot_iterator()\r\n```\r\n\r\nThis is because in this case, `output_buffer_size` is initialized with `num_threads` of type `tf.int32` without any conversion to `tf.int64`.", "comments": ["Can one of the admins verify this patch?", "Jenkins test this please.", "Jenkins test this please."]}, {"number": 10068, "title": "InferenceContext::UnknownShapeOfRank support unknown rank, check rank>=0", "body": "", "comments": ["Can one of the admins verify this patch?", "Jenkins test this please.", "Jenkins test this please."]}, {"number": 10067, "title": "Tensorboard problem with pandas", "body": "This is my first time to practice the tensorflow and tensorboard function.\r\nMy code below:\r\n`import tensorflow as tf\r\na = tf.constant(10,name='a')\r\nb = tf.constant(90,name='b')\r\ny=tf.Variable(a+b*2, name = 'y')\r\nmodel = tf.global_variables_initializer()\r\nwith tf.Session() as session:\r\n    merged = tf.summary.merge_all()\r\n    file_writer = tf.summary.FileWriter(\"/temp/to/logs\",session.graph)\r\n    session.run(model)\r\n    print(session.run(y))`\r\nThen I open the terminal and enter the following:\r\n`tensorboard --logdir=/tmp/tensorflowlogs`\r\nBut tensorboar no work, and show the error as below:\r\nc:\\anaconda3\\lib\\site-packages\\dask\\dataframe\\hashing.py:8: FutureWarning: The pandas.lib module is deprecated and will be removed in a future version. These are private functions and can be accessed from pandas._libs.lib instead\r\n  from pandas.lib import is_bool_array\r\nTraceback (most recent call last):\r\n  File \"c:\\anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"c:\\anaconda3\\lib\\runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"C:\\Anaconda3\\Scripts\\tensorboard.exe\\__main__.py\", line 5, in <module>\r\n  File \"c:\\anaconda3\\lib\\site-packages\\tensorflow\\tensorboard\\tensorboard.py\", line 33, in <module>\r\n    from tensorflow.tensorboard.backend import application\r\n  File \"c:\\anaconda3\\lib\\site-packages\\tensorflow\\tensorboard\\backend\\application.py\", line 47, in <module>\r\n    from tensorflow.tensorboard.plugins.projector import projector_plugin\r\n  File \"c:\\anaconda3\\lib\\site-packages\\tensorflow\\tensorboard\\plugins\\projector\\projector_plugin.py\", line 28, in <module>\r\n    from tensorflow.contrib.tensorboard.plugins.projector import PROJECTOR_FILENAME\r\n  File \"c:\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\__init__.py\", line 30, in <module>\r\n    from tensorflow.contrib import factorization\r\n  File \"c:\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\factorization\\__init__.py\", line 24, in <module>\r\n    from tensorflow.contrib.factorization.python.ops.gmm import *\r\n  File \"c:\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\factorization\\python\\ops\\gmm.py\", line 27, in <module>\r\n    from tensorflow.contrib.learn.python.learn.estimators import estimator\r\n  File \"c:\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\__init__.py\", line 87, in <module>\r\n    from tensorflow.contrib.learn.python.learn import *\r\n  File \"c:\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\__init__.py\", line 23, in <module>\r\n    from tensorflow.contrib.learn.python.learn import *\r\n  File \"c:\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\__init__.py\", line 25, in <module>\r\n    from tensorflow.contrib.learn.python.learn import estimators\r\n  File \"c:\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\__init__.py\", line 297, in <module>\r\n    from tensorflow.contrib.learn.python.learn.estimators.dnn import DNNClassifier\r\n  File \"c:\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\dnn.py\", line 29, in <module>\r\n    from tensorflow.contrib.learn.python.learn.estimators import dnn_linear_combined\r\n  File \"c:\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\dnn_linear_combined.py\", line 31, in <module>\r\n    from tensorflow.contrib.learn.python.learn.estimators import estimator\r\n  File \"c:\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py\", line 49, in <module>\r\n    from tensorflow.contrib.learn.python.learn.learn_io import data_feeder\r\n  File \"c:\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\learn_io\\__init__.py\", line 21, in <module>\r\n    from tensorflow.contrib.learn.python.learn.learn_io.dask_io import extract_dask_data\r\n  File \"c:\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\learn_io\\dask_io.py\", line 26, in <module>\r\n    import dask.dataframe as dd\r\n  File \"c:\\anaconda3\\lib\\site-packages\\dask\\dataframe\\__init__.py\", line 3, in <module>\r\n    from .core import (DataFrame, Series, Index, _Frame, map_partitions,\r\n  File \"c:\\anaconda3\\lib\\site-packages\\dask\\dataframe\\core.py\", line 40, in <module>\r\n    pd.computation.expressions.set_use_numexpr(False)\r\nAttributeError: module 'pandas' has no attribute 'computation'\r\n\r\nC:\\Users\\Soars>tensorboard --logdir=/tmp/to/logs\r\nc:\\anaconda3\\lib\\site-packages\\dask\\dataframe\\hashing.py:8: FutureWarning: The pandas.lib module is deprecated and will be removed in a future version. These are private functions and can be accessed from pandas._libs.lib instead\r\n  from pandas.lib import is_bool_array\r\nTraceback (most recent call last):\r\n  File \"c:\\anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"c:\\anaconda3\\lib\\runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"C:\\Anaconda3\\Scripts\\tensorboard.exe\\__main__.py\", line 5, in <module>\r\n  File \"c:\\anaconda3\\lib\\site-packages\\tensorflow\\tensorboard\\tensorboard.py\", line 33, in <module>\r\n    from tensorflow.tensorboard.backend import application\r\n  File \"c:\\anaconda3\\lib\\site-packages\\tensorflow\\tensorboard\\backend\\application.py\", line 47, in <module>\r\n    from tensorflow.tensorboard.plugins.projector import projector_plugin\r\n  File \"c:\\anaconda3\\lib\\site-packages\\tensorflow\\tensorboard\\plugins\\projector\\projector_plugin.py\", line 28, in <module>\r\n    from tensorflow.contrib.tensorboard.plugins.projector import PROJECTOR_FILENAME\r\n  File \"c:\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\__init__.py\", line 30, in <module>\r\n    from tensorflow.contrib import factorization\r\n  File \"c:\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\factorization\\__init__.py\", line 24, in <module>\r\n    from tensorflow.contrib.factorization.python.ops.gmm import *\r\n  File \"c:\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\factorization\\python\\ops\\gmm.py\", line 27, in <module>\r\n    from tensorflow.contrib.learn.python.learn.estimators import estimator\r\n  File \"c:\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\__init__.py\", line 87, in <module>\r\n    from tensorflow.contrib.learn.python.learn import *\r\n  File \"c:\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\__init__.py\", line 23, in <module>\r\n    from tensorflow.contrib.learn.python.learn import *\r\n  File \"c:\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\__init__.py\", line 25, in <module>\r\n    from tensorflow.contrib.learn.python.learn import estimators\r\n  File \"c:\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\__init__.py\", line 297, in <module>\r\n    from tensorflow.contrib.learn.python.learn.estimators.dnn import DNNClassifier\r\n  File \"c:\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\dnn.py\", line 29, in <module>\r\n    from tensorflow.contrib.learn.python.learn.estimators import dnn_linear_combined\r\n  File \"c:\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\dnn_linear_combined.py\", line 31, in <module>\r\n    from tensorflow.contrib.learn.python.learn.estimators import estimator\r\n  File \"c:\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py\", line 49, in <module>\r\n    from tensorflow.contrib.learn.python.learn.learn_io import data_feeder\r\n  File \"c:\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\learn_io\\__init__.py\", line 21, in <module>\r\n    from tensorflow.contrib.learn.python.learn.learn_io.dask_io import extract_dask_data\r\n  File \"c:\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\learn_io\\dask_io.py\", line 26, in <module>\r\n    import dask.dataframe as dd\r\n  File \"c:\\anaconda3\\lib\\site-packages\\dask\\dataframe\\__init__.py\", line 3, in <module>\r\n    from .core import (DataFrame, Series, Index, _Frame, map_partitions,\r\n  File \"c:\\anaconda3\\lib\\site-packages\\dask\\dataframe\\core.py\", line 40, in <module>\r\n    pd.computation.expressions.set_use_numexpr(False)\r\nAttributeError: module 'pandas' has no attribute 'computation'\r\n\r\nWhat's wrong with me?\r\n\r\nMy environment:\r\nOS: windows 10\r\nIDE: Visual studio 2015\r\nPackage version:\r\n1) tensorflow: .1.1.0\r\n2) pandas: 0.20.1\r\n3) matplotlib: 2.0.0\r\nPlease help me, thank you.", "comments": ["I solved this problem.\r\nDowngrade pandas version to 0.19.2, and it worked."]}, {"number": 10066, "title": "cifar10 example running slower with Windows 10", "body": "### System information 1\r\n- **Have I written custom code**: No\r\n- **OS Platform and Distribution**: Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 0.12.1\r\n- **CUDA/cuDNN version**: 8.0.44 / 5.1\r\n- **GPU model and memory**: GTX 1080 8gb\r\n- **Exact command to reproduce**: 'python3 cifar10_train.py'\r\n\r\n### System information 2\r\n- **Have I written custom code**: No\r\n- **OS Platform and Distribution**: Windows 10 Pro\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 0.12.1\r\n- **CUDA/cuDNN version**: 8.0.44 / 5.1\r\n- **GPU model and memory**: GTX 1080 8gb\r\n- **Exact command to reproduce**: 'python cifar10_train.py'\r\n\r\n### System information 3\r\n- **Have I written custom code**: No\r\n- **OS Platform and Distribution**: Windows 7 Pro\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 0.12.1\r\n- **CUDA/cuDNN version**: 8.0.44 / 5.1\r\n- **GPU model and memory**: Titan X maxwell 12gb\r\n- **Exact command to reproduce**: 'python cifar10_train.py'\r\n\r\n### Describe the problem\r\nWhen running the cifar 10 CNN example code (https://github.com/tensorflow/models/tree/master/tutorials/image/cifar10/), I get very different performance on several OS while having same installations of CUDA, CuDNN & TF, and the same code of course.\r\nWith _System 1_ (described above): running at ~2600 images/sec, Python CPU usage at ~50%\r\nWith _System 2_ (described above): running at ~600 images/sec, Python CPU usage at **100%** (!)\r\nWith _System 3_ (described above): running at ~2600 images/sec, Python CPU usage at ~50%\r\n\r\nI'm experiencing the same problems with TF r1.0.1.\r\nSeems like something in this code (pherhaps the queue threading?) doesn't go well with win10? CPU usage reaches 100% with win10, and significantly slower, that's very weird.\r\n\r\nThanks.", "comments": ["Why don't you use the latest TF version? Maybe it's fixed there.", "Tried with the latest release now as well. Same issue still exists.", "@mrry, any ideas. Could you take a look?", "What are the CPUs and memory you are using on these machines, are they all the same?\r\n", "intel i7-7700\r\nCORSAIR Vengeance LPX 32GB (2 x 16GB) DDR4\r\n\r\nIt's all the same hardware for all OS - it's a dual boot machine with windows 10 and ubuntu 16.04", "Anything new on this?", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "@reedwm Any ideas why this may be happening?", "I'm not sure, sorry. I don't have a Windows machine to reproduce this on. @oranshayer can you try again on Tensorflow 1.4?\r\n\r\n/CC @mrry again, any ideas why TensorFlow on windows could be slower than on Ubuntu?", "No idea, but the two variables seem to be that the configuration (Windows 10 Pro, GTX 1080 8gb) is slower than (Windows 7 Pro, Titan X maxwell 12gb), and the latter version is as fast as Ubuntu.\r\n\r\nThis makes me suspect that something in the configuration of your Windows 10 system is causing the problem, rather than TensorFlow. Driver version perhaps?", "Nagging Assigneee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "I'm closing this due to lack of recent activity. Since TensorFlow 1.5.0rc0 with CUDA 9 support is now available, I expect much has changed since TensorFlow 0.12.1, which is over a year old now. If the problem reproduces with the latest version of TensorFlow, please feel free to reopen the issue. "]}, {"number": 10065, "title": "Fix docstring for method `flip_up_down`", "body": "", "comments": ["Can one of the admins verify this patch?", "Jenkins test this please.", "Jenkins test this please.", "Flaky timeout of a GPU test, not related to the PR."]}, {"number": 10064, "title": "Fixed typo", "body": "Fixed typo", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "Jenkins test this please.", "Jenkins test this please."]}, {"number": 10063, "title": "R1.0", "body": "Tensorflow on windows 32 bit", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->"]}, {"number": 10062, "title": "C++ compilation of rule '//tensorflow/stream_executor:cuda_platform' failed", "body": "I got the following error when installing tensorflow v1.1.0 from source:\r\n\r\n> ERROR: /home/software/tensorflow-1.1.0/tensorflow/stream_executor/BUILD:39:1: C++ compilation of rule '//tensorflow/stream_executor:cuda_platform' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter ... (remaining 121 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\r\n\r\nMy OS is centos7 with cuda 8.0 and cudnn 5.", "comments": ["TensorFlow does not have official support for CentOS.\r\nI recommend reaching out to StackOverflow for support on this issue.", "OK\uff0cthanks @gunan.", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 10061, "title": "tensorflow is not a supported wheel on this p latform", "body": "I have python 2.7.13 (Anaconda 4). When i try install **tensorflow** its raise error.\r\n```\r\ntensorflow_gpu-1.1.0-cp35-cp35m-win_amd64.whl is not a supported wheel on this p\r\nlatform.\r\n```\r\n\r\nI try use gpu version - same result.", "comments": ["Only Python 3.5 packages are available on Windows -- so use Python 3.5 instead of 2.7.", "The comment by @foxik is correct.\r\nOn windows, TF only has support for Python 3.5"]}, {"number": 10060, "title": "[XLA] [macOS] tfcompile via tf_library does not work on macOS", "body": "I am trying to compile a model using XLA on macOS. I know the XLA is still in experimental stage, but I would be happy to help fix the problem. The problem can be reproduced from supplied tests, i.e: tensorflow/compiler/aot/tests:test_graph_tfadd.\r\n\r\n### Environment\r\nOS: macOS Sierra 10.12.4\r\nTensorflow source: v1.1.0-rc2\r\nBazel: bazel release 0.4.5-homebrew\r\n\r\n### Describe the problem\r\nThe generated object file from the graph seems to be invalid or is not recognized by libtool:\r\n\r\n`libtool: file: bazel-out/local-opt/genfiles/tensorflow/compiler/aot/tests/test_graph_tfadd.o is not an object file (not allowed in a library)`\r\n\r\n`file bazel-out/local-opt/genfiles/tensorflow/compiler/aot/tests/test_graph_tfadd.o\r\nbazel-out/local-opt/genfiles/tensorflow/compiler/aot/tests/test_graph_tfadd.o: ELF 64-bit LSB relocatable, x86-64, version 1 (SYSV), not stripped`\r\n\r\n### How to reproduce the problem\r\nThe problem can be reproduced on a fresh checkout issuing the following commands:\r\n`bazel build //tensorflow/compiler/aot/tests:test_graph_tfadd`\r\n\r\nIf you need more information, I am happy to provide it!", "comments": ["Ok, I found the Problem:\r\n\r\nfile: tensorflow/compiler/aot/tfcompile.bzl:277\r\n```\r\ndef target_llvm_triple():\r\n  \"\"\"Returns the target LLVM triple to be used for compiling the target.\"\"\"\r\n  # TODO(toddw): Add target_triple for other targets.  For details see:\r\n  # http://llvm.org/docs/doxygen/html/Triple_8h_source.html\r\n  return select({\r\n      \"//tensorflow:android_arm\": \"armv7-none-android\",\r\n      \"//tensorflow:android_arm64\": \"aarch64-none-android\",\r\n      \"//tensorflow:android_x86\": \"i686-none-android\",\r\n      \"//tensorflow:linux_ppc64le\": \"ppc64le-ibm-linux-gnu\",\r\n      \"//conditions:default\": \"x86_64-pc-linux\",\r\n  })\r\n```\r\n\r\nAdding \r\n```\r\n\"//tensorflow:darwin\": \"x86_64-none-darwin\",\r\n```\r\nfixes the problem. I can provide a pull request for that, but it seems there are more targets missing.\r\nMaybe someone with more overview of supported platforms (@tatatodd ?) can take a look here.\r\n", "I think we may have missed this, as XLA is still listed as experimental.\r\nYour fix looks correct to me.\r\nWould you like to contribute the fix with a pull request?"]}, {"number": 10059, "title": "tf.summary not working in tf.cond functions...", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution**: Windows 10 as well as Linux Ubuntu 16.04.2\r\n- **TensorFlow installed from (source or binary)**: installed with pip (in root of anaconda) like in the documentation (not installed from master)\r\n- **TensorFlow version**: v1.1\r\n- **CUDA/cuDNN version**: CUDA Version 8.0.44\r\n- **GPU model and memory**: GeForce GTX TITAN X 12GB\r\n- **Exact command to reproduce**: python test_summarizing.py\r\n\r\n### Describe the problem\r\nHi everyone,\r\nI was trying to write a function to do data augmentation on images. With a probability of 0.5, the function should do the augmentation and if not return the image unmodified. The basic idea of my usage you can extract from the code below.\r\n`\r\nimage = tf.cond(tf.less(probability, 0.5), lambda: do_augmentation(image), lambda: image)\r\n`\r\nIn the augmentation function, I want to see how the image changed so I added `tf.summary.image(...)` after every image-processing step. But when running the summary operation (after I merged all summaries with `tf.summary.merge_all()`) I get the following error:\r\n```\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: The tensor returned for Merge/MergeSummary:0 was not valid.\r\n```\r\nI tried to debug the problem and saw that when I don't use the summaries (commenting them) in the augmentation function, the whole code works.\r\n\r\nI couldn't find any help on StackOverflow regarding this problem. However, I saw only one other post (http://stackoverflow.com/questions/39275641/tensorflow-how-to-write-multistep-decay) which had this kind of error, so I took that code (to be sure that it was not a problem with `tf.summary.image()` but a problem in general with `tf.summary`) and played around to see where the problem is. Sadly, I couldn't figure it out...\r\n\r\nIn the attached zip file ([test_summarizing.zip](https://github.com/tensorflow/tensorflow/files/1015955/test_summarizing.zip)) there is the test_summarizing.py file, which contains 2 functions. \r\n\r\n1. `summary_not_working_simple()`:\r\nIs a minimal example to replicate the error of my code and of the original problem I had.\r\n(I used the scalar summary instead of the image summary because it doesn't make a difference...)\r\n\r\n- If you comment both summaries in f1 and f2, the code always works. \r\n- If you comment one out of the 2 summary-calls (in either function f1 or f2), the code sometimes works and sometimes produces the traceback found below. \r\nTo replicate, try commenting both calls then run the code. Then comment only one call and run the code (possibly multiple times). Then comment the other call and run the code again. You should see that with one commented call to `tf.summary.scalar`, the code sometimes produces the error and sometimes it simply works...\r\n- If you don't comment anything (leaving both calls to the summary), the code never works and always produces the traceback shown below.\r\n\r\n2. `summary_not_working_stack_overflow()`:\r\nTo replicate the error you must in the function `multi_step_decay` of class MultiStepDecay at lines 62-63 comment (resp. uncomment) the `with tf.control_dependencies` block and the error will appear.\r\n\r\nCould someone please look into the problem of the `summary_not_working_simple()` and explain to me, why the summary is not working? I have found a workaround to using the `tf.cond()` but the code is very messy now :) Plus it would make sense to have the possibility of writing summaries from every point of the tensorflow code, right?\r\nAnd if you could also explain why the issue in the second function `summary_not_working_stack_overflow()` occurs, I would appreciate it very much!\r\n\r\n### Source code / logs\r\nTraceback for summary_not_working_simple() example:\r\n```\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Andrei\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1039, in _do_call\r\n    return fn(*args)\r\n  File \"C:\\Users\\Andrei\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1021, in _run_fn\r\n    status, run_metadata)\r\n  File \"C:\\Users\\Andrei\\Anaconda\\lib\\contextlib.py\", line 66, in __exit__\r\n    next(self.gen)\r\n  File \"C:\\Users\\Andrei\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\", line 466, in raise_exception_on_not_ok_status\r\n    pywrap_tensorflow.TF_GetCode(status))\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: The tensor returned for Merge/MergeSummary:0 was not valid.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:/Users/Andrei/PycharmProjects/testing/test_summarizing.py\", line 93, in <module>\r\n    summary_not_working_simple()\r\n  File \"C:/Users/Andrei/PycharmProjects/testing/test_summarizing.py\", line 30, in summary_not_working_simple\r\n    _ = session.run(summary_merge_opt)\r\n  File \"C:\\Users\\Andrei\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 778, in run\r\n    run_metadata_ptr)\r\n  File \"C:\\Users\\Andrei\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 982, in _run\r\n    feed_dict_string, options, run_metadata)\r\n  File \"C:\\Users\\Andrei\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1032, in _do_run\r\n    target_list, options, run_metadata)\r\n  File \"C:\\Users\\Andrei\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1052, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: The tensor returned for Merge/MergeSummary:0 was not valid.\r\n```\r\n\r\nSource code of my the original function:\r\n```\r\ndef preprocess_for_train_summary_error(image, height, width, fast_mode=True, scope=None, central_fraction=0.875):\r\n    with tf.name_scope(scope, 'train_image', [image, height, width]):\r\n        if image.dtype != tf.float32:\r\n            image = tf.image.convert_image_dtype(image, dtype=tf.float32)\r\n\r\n        tf.summary.image(\"original_image\", tf.expand_dims(image, axis=0), max_outputs=1)\r\n\r\n        random_augment = tf.random_uniform([], minval=0, maxval=1, dtype=tf.float32)\r\n\r\n        def augmentation_pipeline(image_arg):\r\n            random_translate = tf.random_uniform([], minval=0, maxval=1, dtype=tf.float32)\r\n            translated_image = tf.cond(tf.less(random_translate, 0.5),\r\n                                       lambda: translate(image_arg),\r\n                                       lambda: image_arg)\r\n            tf.summary.image('translated_image', tf.expand_dims(translated_image, axis=0), max_outputs=1)\r\n\r\n            random_rotate = tf.random_uniform([], minval=0, maxval=1)\r\n            rotated_image = tf.cond(tf.less(random_rotate, 0.8),\r\n                                    lambda: rotate(translated_image),\r\n                                    lambda: translated_image)\r\n            tf.summary.image('rotated_image', tf.expand_dims(rotated_image, axis=0), max_outputs=1)\r\n\r\n            random_flip = tf.random_uniform([], minval=0, maxval=1)\r\n            flipped_image = tf.cond(tf.less(random_flip, 0.5),\r\n                                    lambda: flip(rotated_image),\r\n                                    lambda: rotated_image)\r\n            tf.summary.image('flipped_image', tf.expand_dims(flipped_image, axis=0), max_outputs=1)\r\n\r\n            def f(x, ordering):\r\n                return distort_color(x, color_ordering=ordering, fast_mode=fast_mode)\r\n\r\n            random_distort_colors = tf.random_uniform([], minval=0, maxval=1)\r\n            color_distorted_image = tf.cond(tf.less(random_distort_colors, 0.5),\r\n                                            lambda: apply_with_random_selector(flipped_image, f, 4),\r\n                                            lambda: flipped_image)\r\n            tf.summary.image('color_distorted_image', tf.expand_dims(color_distorted_image, axis=0), max_outputs=1)\r\n\r\n            return image_arg\r\n\r\n        image = tf.cond(tf.less(random_augment, 0.5),\r\n                        lambda: augmentation_pipeline(image),\r\n                        lambda: image)\r\n\r\n        image = tf.image.central_crop(image, central_fraction=central_fraction)\r\n        tf.summary.image('central_cropped_image', tf.expand_dims(image, axis=0), max_outputs=1)\r\n        image = tf.expand_dims(image, 0)\r\n        image = tf.image.resize_bilinear(image, [height, width], align_corners=False)\r\n        image = tf.squeeze(image, [0])\r\n        tf.summary.image('resized_image', tf.expand_dims(image, axis=0), max_outputs=1)\r\n\r\n        # Subtract off the mean and divide by the variance of the pixels.\r\n        image = tf.subtract(image, 0.5, name=\"sub_mean\")\r\n        image = tf.multiply(image, 2.0, name=\"div_var\")\r\n        return image\r\n```", "comments": ["Similar in #2714, #8660. Looks like summary cannot be created in control flow and hasn't been fixed.", "How come it is not a bug or a feature request? \r\nWe cannot create summaries from tf.conds so the feature request is that we can :D", "@yuanbyu Any thoughts on tf.cond not working with summaries?", "I think this problem is not solved in tf v1.3.\r\n@jart  @yuanbyu  Any plans to fix this bug in TensorFlow? It seems a very serious bug.", "@xcyan and not solved in tf v1.4.", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "We're working on a new contrib/summary/ package that's going to be the future. This system is already in place and works with tf.cond by design. However it's still under active development and not API stable. Eventually it's going to be moved to tb.summary (i.e. tensorboard.summary) and will yield numerous other benefits such as database support and performance.", "@jart When can i use this feature?", "@jart What's the status of this feature?", "Punting to @alextp ", "tf.contrib.summary is usable now for both graph and eager execution. See the documentation in the package for instructions on how to enable it. The only caveat is that it is not compatible with legacy tf.summary, so you need to choose (thankfully switching just means turning tf.summary.* into tf.contrib.summary.*).", "Thank you for the solution @alextp!\r\nThis means that from tf 1.5 we should only use tf.contrib.summary or will the package eventually be moved to the \"core\" tensorflow?", "The package will eventually be moved into core tensorboard, not core\ntensorflow.\n\nOn Fri, Feb 16, 2018 at 1:01 PM, Andrei Costinescu <notifications@github.com\n> wrote:\n\n> Thank you for the solution @alextp <https://github.com/alextp>!\n> This means that from tf 1.5 we should only use tf.contrib.summary or will\n> the package will eventually be moved to the \"core\" tensorflow?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/10059#issuecomment-366356123>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAATxTQgbhjyYj1JjUJ0ym8rpptTlqi9ks5tVeyYgaJpZM4NhNSL>\n> .\n>\n\n\n\n-- \n - Alex\n", "Awesome that you are trying to improve summaries, but it seems like while_loops don't work yet. Are you working on that and if so, when can we expect a solution? You would reduce my debugging time quite a lot if you could.", "while loops work on tf.contrib.summary. If they don't for your use case\nplease file an issue with instructions to reproduce.\n\n\nOn Thu, Mar 15, 2018 at 11:44 AM guidocalvano <notifications@github.com>\nwrote:\n\n> Awesome that you are trying to improve summaries, but it seems like\n> while_loops don't work yet. Are you working on that and if so, when can we\n> expect a solution? You would reduce my debugging time quite a lot if you\n> could.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/10059#issuecomment-373481937>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAATxXXzJcgAYeu3eSEUnICHmhZWJjisks5teraXgaJpZM4NhNSL>\n> .\n>\n\n\n-- \n - Alex\n"]}, {"number": 10058, "title": "Windows Installation permission denied. Why it required Admin?", "body": "Hello, first time install Windows Tensorflow, and I am running Python3.5.2 and following example, I got \"Permission Denied\". I don't believe it requires admin, or does it?\r\n\r\n```\r\nd:\\Experiments>conda create -n tensorflow\r\nFetching package metadata ...........\r\nSolving package specifications:\r\nPackage plan for installation in environment C:\\Users\\mmansour\\AppData\\Local\\conda\\conda\\envs\\tensorflow:\r\n\r\nProceed ([y]/n)? Y\r\n\r\n#\r\n# To activate this environment, use:\r\n# > activate tensorflow\r\n#\r\n# To deactivate this environment, use:\r\n# > deactivate tensorflow\r\n#\r\n# * for power-users using bash, you must source\r\n#\r\n\r\n\r\nd:\\Experiments>activate tensorflow\r\n\r\n(tensorflow) d:\\Experiments>pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/windows/gpu/tensorflow_gpu-1.1.0-cp35-cp35m-win_amd64.whl\r\nCollecting tensorflow-gpu==1.1.0 from https://storage.googleapis.com/tensorflow/windows/gpu/tensorflow_gpu-1.1.0-cp35-cp35m-win_amd64.whl\r\n  Using cached https://storage.googleapis.com/tensorflow/windows/gpu/tensorflow_gpu-1.1.0-cp35-cp35m-win_amd64.whl\r\nCollecting six>=1.10.0 (from tensorflow-gpu==1.1.0)\r\n  Using cached six-1.10.0-py2.py3-none-any.whl\r\nCollecting protobuf>=3.2.0 (from tensorflow-gpu==1.1.0)\r\nCollecting wheel>=0.26 (from tensorflow-gpu==1.1.0)\r\n  Using cached wheel-0.29.0-py2.py3-none-any.whl\r\nCollecting werkzeug>=0.11.10 (from tensorflow-gpu==1.1.0)\r\n  Using cached Werkzeug-0.12.2-py2.py3-none-any.whl\r\nCollecting numpy>=1.11.0 (from tensorflow-gpu==1.1.0)\r\n  Using cached numpy-1.12.1-cp35-none-win_amd64.whl\r\nCollecting setuptools (from protobuf>=3.2.0->tensorflow-gpu==1.1.0)\r\n  Using cached setuptools-35.0.2-py2.py3-none-any.whl\r\nCollecting packaging>=16.8 (from setuptools->protobuf>=3.2.0->tensorflow-gpu==1.1.0)\r\n  Using cached packaging-16.8-py2.py3-none-any.whl\r\nCollecting appdirs>=1.4.0 (from setuptools->protobuf>=3.2.0->tensorflow-gpu==1.1.0)\r\n  Using cached appdirs-1.4.3-py2.py3-none-any.whl\r\nCollecting pyparsing (from packaging>=16.8->setuptools->protobuf>=3.2.0->tensorflow-gpu==1.1.0)\r\n  Using cached pyparsing-2.2.0-py2.py3-none-any.whl\r\nInstalling collected packages: six, pyparsing, packaging, appdirs, setuptools, protobuf, wheel, werkzeug, numpy, tensorflow-gpu\r\nException:\r\nTraceback (most recent call last):\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\basecommand.py\", line 215, in main\r\n    status = self.run(options, args)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\commands\\install.py\", line 342, in run\r\n    prefix=options.prefix_path,\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\req\\req_set.py\", line 784, in install\r\n    **kwargs\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\req\\req_install.py\", line 851, in install\r\n    self.move_wheel_files(self.source_dir, root=root, prefix=prefix)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\req\\req_install.py\", line 1064, in move_wheel_files\r\n    isolated=self.isolated,\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\wheel.py\", line 345, in move_wheel_files\r\n    clobber(source, lib_dir, True)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\wheel.py\", line 323, in clobber\r\n    shutil.copyfile(srcfile, destfile)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\shutil.py\", line 121, in copyfile\r\n    with open(dst, 'wb') as fdst:\r\nPermissionError: [Errno 13] Permission denied: 'C:\\\\ProgramData\\\\Anaconda3\\\\Lib\\\\site-packages\\\\six-1.10.0.dist-info\\\\DESCRIPTION.rst'\r\n\r\n(tensorflow) d:\\Experiments>\r\n```", "comments": ["Non-admin shouldn't have write access to ProgramData and \"Program Files\". They are system wide files.", "use the cmd as administrator and then install it.\r\n \r\n![capture](https://cloud.githubusercontent.com/assets/15058478/26287104/3000a872-3e42-11e7-9236-99aefd565ac6.PNG)\r\n\r\n", "This is related to how anaconda manages its environments, and where it places all environment files.\r\nThe issue is unrelated to TF itself. The comments by @snnn and @Wendy0601 explain the root cause, and provide a good workaround.\r\nI am closing this issue.", "1.close all python progress(include jupter,python,and so on)\r\n2.Windows PowerShell(with Authorization), run : your code", "I got this error\r\n\r\nRequirement already satisfied: setuptools in c:\\users\\deepu\\anaconda3\\lib\\site-packages (from protobuf>=3.6.1->tensorflow-gpu==1.12.0)\r\nInstalling collected packages: tensorflow-gpu\r\n  Found existing installation: tensorflow-gpu 1.14.0\r\n    Uninstalling tensorflow-gpu-1.14.0:\r\n      Successfully uninstalled tensorflow-gpu-1.14.0\r\n  Rolling back uninstall of tensorflow-gpu\r\nException:\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Deepu\\Anaconda3\\lib\\site-packages\\pip\\basecommand.py\", line 215, in main\r\n    status = self.run(options, args)\r\n  File \"C:\\Users\\Deepu\\Anaconda3\\lib\\site-packages\\pip\\commands\\install.py\", line 342, in run\r\n    prefix=options.prefix_path,\r\n  File \"C:\\Users\\Deepu\\Anaconda3\\lib\\site-packages\\pip\\req\\req_set.py\", line 784, in install\r\n    **kwargs\r\n  File \"C:\\Users\\Deepu\\Anaconda3\\lib\\site-packages\\pip\\req\\req_install.py\", line 851, in install\r\n    self.move_wheel_files(self.source_dir, root=root, prefix=prefix)\r\n  File \"C:\\Users\\Deepu\\Anaconda3\\lib\\site-packages\\pip\\req\\req_install.py\", line 1064, in move_wheel_files\r\n    isolated=self.isolated,\r\n  File \"C:\\Users\\Deepu\\Anaconda3\\lib\\site-packages\\pip\\wheel.py\", line 377, in move_wheel_files\r\n    clobber(source, dest, False, fixer=fixer, filter=filter)\r\n  File \"C:\\Users\\Deepu\\Anaconda3\\lib\\site-packages\\pip\\wheel.py\", line 323, in clobber\r\n    shutil.copyfile(srcfile, destfile)\r\n  File \"C:\\Users\\Deepu\\Anaconda3\\lib\\shutil.py\", line 121, in copyfile\r\n    with open(dst, 'wb') as fdst:\r\nPermissionError: [Errno 13] Permission denied: 'C:\\\\Users\\\\Deepu\\\\Anaconda3\\\\Lib\\\\site-packages\\\\tensorflow\\\\python\\\\_pywrap_tensorflow_internal.pyd'", "@manideepdv if you use the admin account to install tensorflow once, the files created will be owned by the administrator, and your user wont be able to remove them.\r\nThis is purely due to your system and the files on them, and has nothing to do with tensorflow.", "python 3.8 does not support tensorflow 2.2 but 3.6."]}, {"number": 10057, "title": "fix: typos using misspell", "body": "fix: typos\r\n\r\nThis PR is part of a campaign to fix a lot of typos on github!\r\nYou can see the progress on https://github.com/fixTypos/fix_typos/\r\n\r\nhttps://github.com/client9/misspell", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please"]}, {"number": 10056, "title": "Add support for sparse_reduce_max and sparse_reduce_max_sparse", "body": "This commit tries to address the issue raised in #10002 to have\r\nthe support for sparse_reduce_max and sparse_reduce_max_sparse.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["Can one of the admins verify this patch?", "@yongtang I was imagining the code for `sparse_reduce_sum_op.cc` and `sparse_reduce_max_op.cc` can be mostly shared. A remotely related example is the `ScatterUpdateOp`, which has a template param on `UpdateOp` (`ADD`, etc.).  ", "Thanks @concretevitamin for the review. The PR has been updated so that `sparse_reduce_sum` and `sparse_reduce_max` share the same code base. Please take a look.", "@concretevitamin Thanks for the review. The PR has been updated. Please take.a look.", "Thanks @concretevitamin. The PR has been updated.", "Jenkins, test this please.\r\n\r\n@andrewharp feel free to merge.", "This change will require API review.", "Fine for API review.", "Can you rebase and fix the conflicts? I cannot fix things in this PR.", "Thanks @martinwicke. The PR has been rebased. Please take a look", "Jenkins, test this please.", "Can you please run the API goldens updater as described in the error message of the failing Linux-CPU test?", "@martinwicke The API goldens has been updated with the PR. Please take a look and let me know if there are any issues.", "Jenkins, test this please."]}, {"number": 10055, "title": "Updating the release.md file.", "body": "", "comments": []}, {"number": 10054, "title": "Inconsistent functionality from tf.Graph with simple linear regression (not caused from random-seed-state)", "body": "I am getting very inconsistent behavior with my `tf.Graph` objects and I can't explain why it's happening.  I'm running this in a Jupyter notebook.  Could this affect it at all?  \r\n\r\nMy versions: \r\n```\r\ntf.__version__\r\n'1.0.1'\r\nsys.version\r\n'3.6.1 |Anaconda custom (x86_64)| (default, Mar 22 2017, 19:25:17) \\n[GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)]'\r\n```\r\n```\r\nfrom sklearn.datasets import *\r\nimport multiprocessing\r\nimport pandas as pd\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\n\r\ntf_max_threads = tf.ConfigProto(intra_op_parallelism_threads=multiprocessing.cpu_count())\r\ndef iris_data():\r\n    # Iris dataset\r\n    X = pd.DataFrame(load_iris().data,\r\n                           index = [\"iris_%d\" % i for i in range(load_iris().data.shape[0])],\r\n                           columns = [x.split(\" (cm)\")[0].replace(\" \",\"_\") for x in load_iris().feature_names])\r\n\r\n    y = pd.Series(load_iris().target,\r\n                           index = [\"iris_%d\" % i for i in range(load_iris().data.shape[0])],\r\n                           name = \"Species\")\r\n    color_list = [{0:\"red\",1:\"green\",2:\"blue\"}[x] for x in y]\r\n    cmap = {k:v for k,v in zip(X.index, color_list)}\r\n    return (X, y, cmap)\r\n\r\n# Data\r\nX,y,c = iris_data()\r\nx = X[\"petal_width\"].as_matrix()\r\ny = X[\"sepal_length\"].as_matrix()\r\nn = 50\r\n\r\n# Containers\r\nlasso_data = list()\r\nA_data = list()\r\nb_data = list()\r\n\r\n# Graph\r\nG_3_78 = tf.Graph()\r\n\r\n# Iterations\r\nn_iter = 1500\r\n\r\n# Functions\r\ndef lasso_penalty(coef, alpha=0.9):\r\n    lasso_param = tf.constant(alpha)\r\n    heavyside_step = tf.truediv(1.0, tf.add(1.0, tf.exp(tf.multiply(-100.0, tf.subtract(coef, lasso_param)))))\r\n    regularization_param = tf.multiply(heavyside_step, 99.0)\r\n    return regularization_param\r\ndef l2(y, y_model):\r\n    return tf.square(y - y_model)\r\n\r\n# Build Graph\r\nwith G_3_78.as_default():\r\n    # Placeholders\r\n    pH_x_petal_width = tf.placeholder(tf.float32, shape=[None,1], name=\"pH_x_petal_width\")\r\n    pH_y_hat = tf.placeholder(tf.float32, shape=[None,1])\r\n    \r\n    # Model\r\n    A = tf.Variable(tf.random_normal(mean=0, stddev=1, shape=[1,1]), name=\"A\")\r\n    b = tf.Variable(tf.random_normal(mean=0, stddev=1, shape=[1,1]), name=\"b\")\r\n    model = tf.add(tf.matmul(pH_x_petal_width, A), b)\r\n    \r\n    # Loss\r\n    loss_lasso = tf.add(tf.reduce_mean(l2(pH_y_hat, model)), lasso_penalty(A, 0.9))\r\n    \r\n    with tf.Session(graph=G_3_78, config=tf_max_threads) as sess:\r\n        sess.run(tf.global_variables_initializer())\r\n        # Optimizer\r\n        op = tf.train.GradientDescentOptimizer(0.001)\r\n        train_step = op.minimize(loss_lasso)\r\n        # Train linear model \r\n        for i in range(n_iter):\r\n            idx_random = np.random.RandomState(i).choice(y.shape[0], size=n)\r\n            tr_x = x[idx_random].reshape(-1,1)\r\n            tr_y = y[idx_random].reshape(-1,1)\r\n            sess.run(train_step, feed_dict={ pH_x_petal_width:tr_x, pH_y_hat:tr_y})\r\n            # Iterations\r\n            A_iter = sess.run(A)[0][0]\r\n            b_iter = sess.run(b)[0][0]\r\n            \r\n            lasso_iter = sess.run(loss_lasso, feed_dict={ pH_x_petal_width:tr_x, pH_y_hat:tr_y})[0][0]\r\n            lasso_data.append(lasso_iter)\r\n            A_data.append(A_iter)\r\n            b_data.append(b_iter)\r\n            # Log\r\n            if (i + 1) % 500 == 0:\r\n                print(f\"Step #{i + 1}\\n\\tA = {A_iter}\")\r\n                print(f\"\\tb = {b_iter}\")\r\n                print(f\"\\tLoss = {lasso_iter}\")\r\n                print()        \r\n# Plot path\r\nwith plt.style.context(\"seaborn-white\"):\r\n    fig, ax = plt.subplots(nrows=3, figsize=(6,6))\r\n    pd.Series(lasso_data,).plot(ax=ax[0], label=\"loss(lasso)\", legend=True)\r\n    pd.Series(A_data,).plot(ax=ax[1], color=\"red\", label=\"A\", legend=True)\r\n    pd.Series(b_data,).plot(ax=ax[2], color=\"black\", label=\"b\", legend=True)\r\n    fig.suptitle(\"training-process\", fontsize=15, y=0.95)\r\n\r\n    # Plot linear separation\r\nwith plt.style.context(\"seaborn-white\"):\r\n    fig, ax = plt.subplots(figsize=(5,5))\r\n    ax.scatter(x, y, c=X.index.map(lambda x:c[x]))\r\n    x_lims = ax.get_xlim()\r\n#     y_lims = ax.get_ylim()\r\n    for i in range(n_iter):\r\n        ax.plot(x, x*A_data[i] + b_data[i], alpha=i/(n_iter*100), color=\"black\")\r\n    ax.set_xlim(x_lims)\r\n#     ax.set_ylim(y_lims)\r\n```\r\n\r\nI will run this code block and get the desired results: \r\n```\r\nStep #500\r\n\tA = 0.8209055066108704\r\n\tb = 3.338909149169922\r\n\tLoss = 2.8257622718811035\r\n\r\nStep #1000\r\n\tA = 0.812068521976471\r\n\tb = 4.303615570068359\r\n\tLoss = 0.5661464929580688\r\n\r\nStep #1500\r\n\tA = 0.8036581873893738\r\n\tb = 4.6621904373168945\r\n\tLoss = 0.23930419981479645\r\n```\r\n![image](https://cloud.githubusercontent.com/assets/9061708/26270528/6378cea2-3cb0-11e7-9a7c-3ab10850bd5d.png)\r\n\r\nand then I will run the exact same code block again: \r\n```\r\nStep #500\r\n\tA = nan\r\n\tb = nan\r\n\tLoss = nan\r\n\r\nStep #1000\r\n\tA = nan\r\n\tb = nan\r\n\tLoss = nan\r\n\r\nStep #1500\r\n\tA = nan\r\n\tb = nan\r\n\tLoss = nan\r\n```\r\n![image](https://cloud.githubusercontent.com/assets/9061708/26270550/946e57ca-3cb0-11e7-877a-0674c45ddd66.png)\r\n\r\n\r\nand then one more time: \r\n```\r\nStep #500\r\n\tA = 2.6116130352020264\r\n\tb = 1.91126549243927\r\n\tLoss = 101.70783233642578\r\n\r\nStep #1000\r\n\tA = 2.3814141750335693\r\n\tb = 2.4998815059661865\r\n\tLoss = 100.85863494873047\r\n\r\nStep #1500\r\n\tA = 2.11511492729187\r\n\tb = 2.9327337741851807\r\n\tLoss = 99.995849609375\r\n```\r\n![image](https://cloud.githubusercontent.com/assets/9061708/26270564/a97558ee-3cb0-11e7-8bad-85cb2f5f4f1c.png)\r\n\r\n\r\n", "comments": ["Sorry if this is obvious, but why do you say in the title that the inconsistency isn't caused by the random seed? Is the seed being set in the code somewhere and I am missing it?", "When I was generating the training set: `idx_random = np.random.RandomState(i).choice(y.shape[0], size=n)`.  The differences look much more significant than something from a random-seed ", "Your variables are initialized using tf.random_normal though, right? So there is a difference per run coming from that.\r\n\r\nIn general the easiest way to debug this kind of issue is unfortunately just printing out values to see where the different runs diverge. E.g., you can print out the loss on the first step, and see if it's already wildly different between runs, and if so work backwards from there.", "Sorry for the delay, I've been out of the country not looking at my computer.  You can kind of see how different the starting values are from the figs. I guess my question is more theoretical instead of a bug in TensorFlow but it's difficult to know with a non-toy example if the model is good when the results vary using the same code on different instances. Shown below for 4 different runs using the same code block.  Note below is with demming loss instead of lasso: \r\n\r\n```\r\n    # Loss\r\n    numerator = tf.abs(pH_y_hat - model)\r\n    denominator = tf.sqrt(tf.add(tf.square(A), 1))\r\n    deming = tf.truediv(numerator, denominator)\r\n    loss_deming = tf.reduce_mean(deming)\r\n    \r\n    with tf.Session(graph=G_3_75, config=tf_max_threads) as sess:\r\n        sess.run(tf.global_variables_initializer())\r\n        # Optimizer\r\n        op = tf.train.GradientDescentOptimizer(0.1)\r\n        train_step = op.minimize(loss_deming)\r\n```\r\n![image](https://user-images.githubusercontent.com/9061708/27494989-12cfa8ca-5805-11e7-9073-93efd721158b.png)\r\n", "This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 10053, "title": "Updating the md files.", "body": "", "comments": []}, {"number": 10052, "title": "Fixing documentation 404-URL", "body": "", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please"]}, {"number": 10050, "title": "Function img_to_array() gives error for JPEG on Windows", "body": "Hello,\r\n\r\nI'm getting error when I use `img_to_array()` function for particular JPEG file. Here is stack trace:\r\n\r\n    Traceback (most recent call last):\r\n      File \"file.py\", line 41, in <module>\r\n        tf.app.run()\r\n      File \"C:\\Users\\...\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 48, in run\r\n        _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n      File \"file.py\", line 38, in main\r\n        print('label: ' + x.name + ', files: ' + str(load_label(x)))\r\n      File \"file.py\", line 28, in load_label\r\n        array = preprocessing.image.img_to_array(image)\r\n      File \"C:\\Users\\...\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\contrib\\keras\\python\\keras\\preprocessing\\image.py\", line 331, in img_to_array\r\n        x = np.asarray(img, dtype=K.floatx())\r\n      File \"C:\\Users\\...\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\numpy\\core\\numeric.py\", line 531, in asarray\r\n        return array(a, dtype, copy=False, order=order)\r\n    TypeError: float() argument must be a string or a number, not 'JpegImageFile'\r\n\r\nImage was loaded with `load_img()` from same package. I found that if I try to convert image directly with NumPy and without `dtype` parameter like `np.asarray(image)` then it works.\r\n\r\nI am using tensorflow-gpu 1.1.0 on Windows 8.1, cuda8, python3.5, pillow (for PIL).", "comments": ["Does it work if you just do\r\n\r\nimg = pil_image.open(...)\r\nx = np.as_array(img, dtype=float32)\r\n\r\ni.e. just using pillow and np? If not, I guess you may have to follow up with those projects."]}, {"number": 10049, "title": "Fixing documentation 404-URL", "body": "", "comments": ["Can one of the admins verify this patch?", "Did the PR wrongly, i am closing it and PR again."]}, {"number": 10048, "title": "Seal learn_runner.", "body": "PiperOrigin-RevId: 156488276", "comments": []}, {"number": 10047, "title": "Cherrypicks", "body": "", "comments": ["So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored by someone other than the pull request submitter.  We need to confirm that they're okay with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of the commit author(s) and merge this pull request when appropriate.*\n\n<!-- need_author_consent -->"]}, {"number": 10046, "title": "Update RELEASE.md", "body": "add feature_column into the list.", "comments": ["Can one of the admins verify this patch?"]}, {"number": 10045, "title": "Allow Disabling Password and Token Requirement in Jupyter Notebook", "body": "Jupyter Notebook [allows disabling password / token requirements](http://jupyter-notebook.readthedocs.io/en/latest/security.html#alternatives-to-token-authentication) however the way `jupyter_notebook_config.py` is coded does not allow for this.\r\n```\r\nc.NotebookApp.password = passwd(os.environ['PASSWORD'])\r\n```\r\nshould be be written as:\r\n```\r\npassword = os.environ['PASSWORD']\r\nif password:\r\n   c.NotebookApp.password = passwd(password)\r\nelse:\r\n   c.NotebookApp.password = ''\r\n```\r\n\r\nsince `passwd('') == 'sha1:7d18ca389fad:8b3a353d37eb3caf006aa47a5cd6559511979278'`", "comments": ["Thanks @cancan101, for pointing this out. @mrry, are we intentionally disallowing the disabling of jupyter's password/token requirements, or is it ok to do as suggested by @cancan101.", "I have no idea about that file. The fix sounds reasonable though!"]}, {"number": 10044, "title": "Upgrading from tf 0.11 to tf 1.1 results in much slower GPU inference for same architecture.", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttp://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug or a feature request.\r\n2. The form below must be filled out.\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nYes.\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nLinux Ubuntu 14.04\r\n- **TensorFlow installed from (source or binary)**:\r\nbinary\r\n- **TensorFlow version (use command below)**:\r\n0.11 and 1.1\r\n- **Bazel version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n8.0, 5.1.5\r\n- **GPU model and memory**:\r\nTitan X Pascal\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\nLast December, I created a finetuned a segmentation using the inception v1 using tensorflow 0.11.  I used the freeze_model.py script to freeze the model (Freeze A).  I have recently upgraded to tensorflow 1.1 and retrained a model using the (mostly) the same architecture.  I used the model_freeze.py to freeze the updated network (Freeze B).  I also created an optimized version of this model using the optimize for inference script (Freeze C)\r\n\r\nI have run these frozen networks in the tensorflow 1.1 environment.  The Freeze A runs in 20ms, where as the Freeze B runs in 80ms and Freeze C runs in 60ms.\r\n\r\nI have used the Timeline trace command to profile a single inference pass of a single image through the network. I have attached the profiling result files.  They have an extension of txt, because github doesnt accept json, but they should be loadable into chrome://tracing\r\n\r\n[Freeze A.txt](https://github.com/tensorflow/tensorflow/files/1015360/Freeze.A.txt)\r\n[Freeze B.txt](https://github.com/tensorflow/tensorflow/files/1015357/Freeze.B.txt)\r\n[Freeze C.txt](https://github.com/tensorflow/tensorflow/files/1015359/Freeze.C.txt)\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["Here are the summary files describing each of the graphs.  Let me know if you would like the freeze files themselves.  Again I added.txt to the end but they are event files that should be able to be used by tensorboard\r\n\r\n", "\r\n[events.out.tfevents.1495219228 .freezeA.txt](https://github.com/tensorflow/tensorflow/files/1015366/events.out.tfevents.1495219228.freezeA.txt)\r\n", "[events.out.tfevents.1495219622.FreezeB.txt](https://github.com/tensorflow/tensorflow/files/1015374/events.out.tfevents.1495219622.FreezeB.txt)\r\n", "[events.out.tfevents.1495220933.FreezeC.txt](https://github.com/tensorflow/tensorflow/files/1015379/events.out.tfevents.1495220933.FreezeC.txt)\r\n", "One of the main things I notice about the FreezeB/C is there are many repeats of the same convolution operation in comparison to the Freeze A model which only has the convolution opertaion with a given name occuring only once.", "After further investigation, it looks as though I may be using two different inception architectures.  One for tensorflow.contrib.slim.nets.inception and one from the tensorflow/models/slim.nets.inception_v1 repo.  These may be resulting in different run rates."]}, {"number": 10043, "title": "Dynamic_attention_wrapper using rnn output or state to caculate next attention?", "body": "In tensorflow 1.1,  https://github.com/tensorflow/tensorflow/blob/r1.1/tensorflow/contrib/seq2seq/python/ops/dynamic_attention_wrapper.py#L535, dynamic_attention_wrapper use RNN output to calculate next attention \r\nbut in previous seq2seq api, https://github.com/tensorflow/tensorflow/blob/r1.1/tensorflow/contrib/legacy_seq2seq/python/ops/seq2seq.py#L692, attention_decoder use RNN state to calculate next attention. \r\nIn paper, https://arxiv.org/pdf/1409.0473.pdf. page 3, under equation 6, it use RNN state. I hope some could tell me whether it will affect model in practice.\r\nThere is also a stackoverflow post without satisfied answer http://stackoverflow.com/questions/43248613/attention-decoder-implementation-in-tensorflow-r1-0\r\n", "comments": ["Hi @yanyankangkang, this question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. I know you mentioned that this question has already been asked there. Please hold on until someone from our team or the community gets to it. Thanks!"]}]