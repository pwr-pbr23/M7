[{"number": 34574, "title": "tf-trt using error", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\nwhen I run  the model of  trensorrt model transforming from a tensorflow pb modle, it turn out to be an error.\r\nthe code is below:\r\nimport numpy as np\r\nimport tensorflow as tf\r\nimport time\r\n\r\nimport os\r\nos.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\r\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\r\n\r\nfloat16 = False\r\n\r\nif float16:\r\n    trtfilepath = \"/home/andy/models_trt/ssd/ssd_rt_16.pb\"\r\nelse:\r\n    trtfilepath = \"/home/andy/models_trt/ssd/ssd_rt_32.pb\"\r\n\r\nfeaturepath = \"/home/andy/model_data/cat.npy\"\r\n\r\noutputpath1 = \"/home/andy/model_data/ssdoutput1.npy\"\r\noutputpath2 = \"/home/andy/model_data/ssdoutput2.npy\"\r\noutputpath3 = \"/home/andy/model_data/ssdoutput3.npy\"\r\noutputpath4 = \"/home/andy/model_data/ssdoutput4.npy\"\r\n\r\nfeatures = np.load(featurepath)\r\n\r\nif float16:\r\n    features = np.load(featurepath).astype(np.float16)\r\nelse:\r\n    features = np.load(featurepath).astype(np.float32)\r\n\r\n\r\ninputs = \"image_tensor:0\"\r\noutputs1 = \"detection_boxes:0\"\r\noutputs2 = \"detection_scores:0\"\r\noutputs3 = \"num_detections:0\"\r\noutputs4 = \"detection_classes:0\"\r\n\r\nconfig = tf.ConfigProto()\r\nconfig.gpu_options.per_process_gpu_memory_fraction = 0.6\r\n\r\nwith tf.Session(config=config) as sess:\r\n    with tf.gfile.GFile(trtfilepath, 'rb') as f:\r\n        frozen_graph = tf.GraphDef()\r\n        frozen_graph.ParseFromString(f.read())\r\n        sess.graph.as_default()\r\n        tf.import_graph_def(frozen_graph, name='')\r\n        tf_input = sess.graph.get_tensor_by_name(inputs)\r\n\r\n        tf_output1 = sess.graph.get_tensor_by_name(outputs1)\r\n        tf_output2 = sess.graph.get_tensor_by_name(outputs2)\r\n        tf_output3 = sess.graph.get_tensor_by_name(outputs3)\r\n        tf_output4 = sess.graph.get_tensor_by_name(outputs4)\r\n        t1 = time.time()\r\n        output1, output2, output3, output4 = sess.run([tf_output1, tf_output2, tf_output3, tf_output4], feed_dict={\r\n            tf_input: features\r\n        })\r\n        t2 = time.time() \r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):no\r\n- OS Platform and Distribution :Linux Ubuntu 16.04):\r\n\r\n- TensorFlow installed from (source or binary):yes\r\n- TensorFlow version (use command below):tensorflow-1.14.0\r\n- Python version:python3.6\r\n- Bazel version (if compiling from source):0.24.1\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:cuda version:10.0/cudnn version7.6.2\r\n- GPU model and memory:GForce \uff11\uff10\uff16\uff10\r\n\r\nthe error list as:\r\n2019-11-25 14:23:12.077309: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1558] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\r\n2019-11-25 14:23:12.635331: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2019-11-25 14:23:13.452120: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.04GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n2019-11-25 14:23:13.457413: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.04GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n2019-11-25 14:23:13.462873: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.06GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n2019-11-25 14:23:13.468059: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.05GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n2019-11-25 14:23:13.473325: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.09GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n2019-11-25 14:23:13.478631: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.08GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n2019-11-25 14:23:13.484220: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.15GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n2019-11-25 14:23:13.490953: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.15GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n2019-11-25 14:23:13.502852: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n2019-11-25 14:23:13.510147: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\r\n\r\nProcess finished with exit code 139 (interrupted by signal 11: SIGSEGV)\r\n\r\nwhich make me puzzle.wish to get your reply soon.\r\n", "comments": ["@andyqian2015 ,\r\nCan you please refer link of[ similar issue](https://stackoverflow.com/questions/49414841/process-finished-with-exit-code-139-interrupted-by-signal-11-sigsegv) and the [answers](https://stackoverflow.com/a/53961885/12337152) and let us know if it helps.Thanks!", "You may try ```allow_growth``` option, which attempts to allocate  GPU memory based on task:\r\n```python\r\nimport tensorflow as tf\r\nconfig = tf.ConfigProto()\r\nconfig.gpu_options.allow_growth = True\r\nsession = tf.Session(config=config)\r\n```", "@ymodak , thx, I try,but it still has that error", "Hi @andyqian2015, may I know if your `trtfilepath` is a TF-TRT converted model? If so, could you describe more on how you run the TF-TRT conversion? Also, is it possible to share the model file? Thanks.\r\n\r\nAlso @pooyadavoodi @sanjoy ", "@andyqian2015 I think Geforce1060 has 6GB memory. Since `allow_growth` also fails, that 6GB may not be big enough for the model you run. The memory usage of TF-TRT is a bit larger than TF due to weights duplication.\r\n\r\nI suggest  to try with smaller batch size and smaller TRT workspace size.", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34574\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34574\">No</a>\n"]}, {"number": 34573, "title": "fix typo inside and outside", "body": "", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F34573) for more info**.\n\n<!-- need_sender_cla -->", "@mingting  thank you for your contribution, please sign CLA.", "@googlebot I signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F34573) for more info**.\n\n<!-- ok -->", "> ou for your contribution, please sign CLA.\r\n\r\nthanks for your reply,  CLA done just now.", "Are you sure it's a typo? I think the text is intentional: xla.compile wants to have as much of the computation inside itself as possible, including the gradient computation.", "> Are you sure it's a typo? I think the text is intentional: xla.compile wants to have as much of the computation inside itself as possible, including the gradient computation.\r\n@cheshire  \r\nfrom the context, gradient computation in xla.compile is prohibited. so I think to avoid performance drop,  suggest develop to move gradient computation outside of xla.compile, not inside.\r\n\r\n\r\nNote: Gradient computation of graph in xla.compile() is prohibited because it can cause performance degradation. To avoid this issue, move gradient computation insideoutside xla.compile().\r\n", "I don't think it's a typo."]}, {"number": 34572, "title": "How to achieve elementwise convolution for two tensors?", "body": "In my problem, I want to convolve two tensors in my neural network model. \r\n\r\nThe shape of two tensors is **[None, 2, 1], [None, 3, 1]** respectively. The axis with dimension None means the batch size of the input tensor. For each sample in batch, I want to convolve the two tensors with shape [2, 1] and [3, 1].\r\n\r\nHowever, the tf.nn.conv1d in TensorFlow can only convolve the input with **a fixed kernel.** Is there any function that can support the convolution of two tensors according to the batch size axis, similar to the tf.multiply which can multiply two tensors for each sample or just elementwise multiplication.", "comments": ["@bugzhu ,\r\nHi, can you please provide a standalone code used?Thanks!", "The code I ran can be simplified as follows:\r\n```\r\ninput_signal = Input(shape=(L, M), name='input_signal')\r\ninput_h = Input(shape=(N), name='input_h')\r\nfaded= Lambda(lambda x: tf.nn.conv1d(input, x))(input_h) \r\n```\r\nWhat I want to do is that the sample of input_signal can be convolved by the sample of input_h with the same index. However, it just shows my pure idea which can not be able to run in the env. My question is that how I can modify the code to enable the input tensor can be convolved with another input tensor for every sample in the batch.", "This is not Build/Installation or Bug/Performance issue. Please post this kind of support questions at [Stackoverflow](https://stackoverflow.com/questions/tagged/tensorflow). There is a big community to support and learn from your questions. GitHub is mainly for addressing bugs in installation and performance. Thanks!"]}, {"number": 34571, "title": "How to convolve two tensor according to the batch axis?", "body": "In my problem, I want to convolve two tensors in my neural network model. The shape of two tensors is [None, 2, 1], [None, 3, 1] respectively. The axis with dimension None means the batch size of the input tensor. For each sample in batch, I want to convolve the two tensors with shape [2, 1] and [3, 1].\r\nHowever, the tf.nn.conv1d in TensorFlow can only convolve the input with a fixed kernel. Is there any function that can support the convolution of two tensors according to the batch size axis, similar to the tf.multiply which can element wisely multiply two tensors.", "comments": ["Hi, did you find the solution to this? I'm trying to figure out the same thing.", "I am trying to achiever this, but have no idea till now. Maybe there are some possible solutions in the stackoverflow.  @sahilinneurospace ", "Hi @tinyxuyan , I've done some workaround using mentioned tf.nn.conv1d for the same purposes you mentioned in the post:\r\n\r\n```\r\ndef cross_correlation(vectors, batch_size):\r\n    '''\r\n    The goal is to convolute outputs from both networks,\r\n    each one from the batch of the first network's output\r\n    over appropriate one from another network's output\r\n    '''\r\n    \r\n    # x and y have shape: [batch_size, vector_size]\r\n    x, y = vectors\r\n\r\n    # We need to add 'channels' dimension -> [batch_size, vector_size, 1]\r\n    x = tf.expand_dims(x, -1)\r\n    y = tf.expand_dims(y, -1)\r\n    \r\n    # Firstly, we do convolution as the second network\r\n    # output vectors from the batch are all filters.\r\n    # Technically, we've done convolution of all y over each x.\r\n    # From documentation(https://www.tensorflow.org/api_docs/python/tf/nn/conv1d) desired shapes should be:\r\n    # x shape: [batch_shape(batch_size), in_width(vector_size), in_channels(1)]\r\n    # y shape: [filter_width(vector_size), in_channels(1), out_channels(batch_size)]\r\n    # Output shape is [batch_size, vector_length, batch_size].\r\n    conv1d = tf.nn.conv1d(x, tf.transpose(y, perm=[1, 2, 0]), stride=1, padding='SAME')\r\n    conv1d_shape = conv1d.shape\r\n    \r\n    # We need now to apply mask to the output in order to get desired\r\n    # convolution results in the shape [batch_size, vector_length]\r\n    bool_diag = tf.linalg.diag(tf.constant([True] * batch_size))\r\n    mask = tf.repeat(tf.expand_dims(bool_diag, axis=1), conv1d_shape[1], axis=1)\r\n    out = tf.squeeze(tf.ragged.boolean_mask(conv1d, mask), axis=-1)\r\n    \r\n    # Only maximum value of each batch sample convolution is returned\r\n    return tf.reduce_max(out, 1)\r\n```\r\nI hope this is helpful."]}, {"number": 34570, "title": "How to convolve two tensor according to the batch axis?", "body": "In my problem, I want to convolve two tensors in my neural network model. The shape of two tensors is [None, 2, 1], [None, 3, 1] respectively. The axis with dimension None means the batch size of the input tensor. For each sample in batch, I want to convolve the two tensors with shape [2, 1] and [3, 1].\r\nHowever, the tf.nn.conv1d in TensorFlow can only convolve the input with a fixed kernel. Is there any function that can support the convolution of two tensors according to the batch size axis, similar to the tf.multiply which can element wisely multiply two tensors.", "comments": []}, {"number": 34569, "title": "Sort layers before the loop", "body": "Issue #34479, #32672\r\n\r\nLayer names sometimes contain hierarchy char \"/\", e.g., \"Layer1\", \"Layer1/SubLayer1\", etc.. Since for each layer, we create a new group, so if we pass layers whose name like \"Layer1/SubLayer1\", it would create both \"Layer1\" and \"Layer1/SubLayer1\", afterwards, if we pass \"Layer1\", it will throw \"Unable to create group (name already exists)\" error. \r\n\r\nThis commit solves the issue by sorting the layers by name before the loop.", "comments": ["I've recently encountered described bug and found this way your commit. Shouldn't similar sorting be inserted in load_weights_XXX methods?", "@fchollet Can you please take a look at this PR? Thanks!", "@gekowa Can you please resolve conflicts? Thanks!", "It has been 16 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "I'm going to go ahead and close this PR, because it seems to have stalled. If you're still interested in pursing this (and responding to my comments), please feel free to reopen!"]}, {"number": 34568, "title": "RuntimeError: Collective ops must be configured at program startup", "body": "Running distributed TensorFlow gives:\r\n\r\n> RuntimeError: Collective ops must be configured at program startup\r\n\r\n**System information**\r\n- Tutorial: https://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras\r\n- Ubuntu 18.04 (4.15.0-70-generic)\r\n- TensorFlow installed from pip using pip install tensorflow==2.0.0\r\n- Python 2.7.15\r\n\r\n> numpy                    1.16.5\r\n> protobuf                 3.10.0\r\n> tensorflow-datasets      1.3.0\r\n> tensorflow-estimator     2.0.1\r\n> tensorflow-metadata      0.15.1\r\n\r\n\r\nIn the sequence of code, first TF_CONFIG is set using:\r\n`os.environ[\"TF_CONFIG\"] = json.dumps({\"cluster\": {\"worker\": [\"abc:12345\", \"bcd:23456\", \"cde:34567\"]},\"task\": {\"type\": \"worker\", \"index\": 0}})`\r\n\r\nand then:\r\n`strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()`\r\n\r\nThe expected behavior should be that this strategy should work but I get: \r\n`RuntimeError: Collective ops must be configured at program startup`\r\n\r\nAs per the documentation, the TF_CONFIG is defined before the strategy command. I read some of the issues and people suggested to upgrade to the latest tf-nightly but even after I did that I still get the same issue.", "comments": ["@MoizArif, I tried the tutorial colab link, its working without any error. Looks like Python version incompatibility. Try upgrading `Python `to `3.x` and check once.  Let us know how it progresses. Thanks!", "Hi, thank you for your response. \r\n\r\nUpgrading my environment to Python 3.6.8 still gives the same error as described earlier. In the tutorial:\r\n`strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()`\r\ngives a warning:\r\n`WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.`\r\n but in my environment, it gives this as an error instead of a warning. \r\n`RuntimeError: Collective ops must be configured at program startup`\r\n\r\nI am confused since other issues suggest this has already been fixed but even with the latest tensorflow/tf-nightly code I still get this as an error. Even when I do define the collective ops at startup. ", "@MoizArif, \r\nIn the tutorial it is mentioned that `Currently there is a limitation in MultiWorkerMirroredStrategy where TensorFlow ops need to be created after the instance of strategy is created. If you see RuntimeError: Collective ops must be configured at program startup, try creating the instance of MultiWorkerMirroredStrategy at the beginning of the program and put the code that may create ops after the strategy is instantiated.`.\r\nPlease see [here](https://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras#train_the_model_with_multiworkermirroredstrategy) for more information. Thanks!", "I have created the strategy instance before the collection ops definition and it seems to have by-passed my original error.", "@MoizArif \r\nI am also facing the same issue, is it resolved?"]}, {"number": 34567, "title": "No way to use tensorflow with cuda on windows.  cudaGetDevice() failed.", "body": "Hi,\r\n\r\nI'm trying to use cuda with tensorflow. I installed cuda 10.0 and tensorflow 2.0, my version of VS is 2017. I set my env variables and the problem persists.\r\n\r\nThis is the error message: **cudaGetDevice() failed. Status: cudaGetErrorString symbol not found.**\r\n\r\nThanks to u all!", "comments": ["@acarrill \r\n\r\nPlease, see [software requirements](https://www.tensorflow.org/install/gpu#software_requirements) are met.Also go through [link1](https://stackoverflow.com/questions/58868272/what-may-be-the-problem-with-this-cudagetdevice-failed-status-cudageterrorst) and [link2](https://stackoverflow.com/questions/58235018/cuda-issue-how-to-clean-install-cuda-in-win-10-to-resolve-cudagetdevice-fail) and see if it helps you.Also see which TF binary suits your case https://www.tensorflow.org/install/pip?lang=python3#older-versions-of-tensorflow. Thanks!", "@acarrill \r\n\r\nAny update on the issue please. Thanks!", "@ravikyram Yep, sorry!\r\nI'm now able to use tensorflow with gpu. I only had to uninstall tensorflow and tensorflow-gpu, next I reinstalled tensorflow-gpu, also I included this line in my code:\r\n\r\n`os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"`\r\n\r\nNow I have other issue. I can't confirm what physical device I'm using. It's looks like gpu, even if \r\nI change CUDA_VISIBLE_DEVICES if I execute the following command I always  receive a \"True\" answer\r\n\r\n`tf.test.is_gpu_available( cuda_only=False, min_cuda_compute_capability=None )`\r\n\r\nIf I use this code i have not answer:\r\n\r\n`with tf.device('/CPU:0'):\r\n    tf.test.is_gpu_available( cuda_only=False, min_cuda_compute_capability=None )\r\n`\r\n\r\nIf I use this other one, \r\n\r\n`tf.config.experimental.list_physical_devices(device_type=None)`\r\n\r\nthis is the answer: \r\n\r\n[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\r\n PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\r\n\r\nI have other doubts about \"tf.compat.v1.Session()\" but I'm not pretty sure i should open other topic.\r\n\r\nCheers, and sry for the late response!", "@acarrill \r\n\r\nLooks like original issue got resolved.Please, feel free to open new issue if you are facing other issues.Please provide all the information as per the new issue template and raise new issue. Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34567\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34567\">No</a>\n"]}, {"number": 34566, "title": "Google Colab: InvalidArgumentError: Cannot update variable with shape [] using a Tensor with shape [32], shapes must be equal. \t [[{{node metrics_26/acc/AssignAddVariableOp}}]]", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution: Google Colab\r\n- TensorFlow installed from (source or binary): 2.00\r\n- TensorFlow version (use command below): 2.00\r\n- Python version: 3.6\r\n\r\n**Describe the current behavior**\r\nI'm working on an image classification project using Tensorflow and running the code on Google Colab. The dataset is hosted on my Google Drive.\r\nEverything works as expected until the model begins to train and I get an error as shown below.\r\n\r\n\r\n**Describe the expected behavior**\r\nIf I run the same code on my Windows 10 setup, I do not run into any errors.\r\n\r\n\r\n\r\n**Code to reproduce the issue**\r\n```\r\n!pip install --quiet tensorflow==2.0.0-rc0\r\n!pip install --quiet neural-structured-learning\r\n\r\nfrom __future__ import absolute_import, division, print_function, unicode_literals\r\n\r\n# TensorFlow and tf.keras\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras import datasets, layers, models\r\n\r\nprint(tf.__version__)\r\n\r\n\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\nimport os\r\nimport cv2\r\nfrom tqdm import tqdm\r\nimport pathlib\r\nimport random\r\n\r\nfrom google.colab import drive\r\ndrive.mount('/content/gdrive')\r\n\r\ntrain_data_dir = \"/content/gdrive/My Drive/Resize/train\"\r\ntrain_label_dir = pathlib.Path(train_data_dir)\r\n\r\ntest_data_dir = \"/content/gdrive/My Drive/Resize/test\"\r\ntest_label_dir = pathlib.Path(test_data_dir)\r\n\r\n\r\n\r\nCATEGORIES = np.array([item.name for item in train_label_dir.glob('*') if item.name != \"LICENSE.txt\"])\r\nclass_names = CATEGORIES\r\nprint(CATEGORIES)\r\n\r\n\r\n\r\ndef createdataset(DATADIR, label_dir, CATEGORIES, img_size):\r\n    image_count = len(list(label_dir.glob('*/*.jpg')))\r\n    print(image_count)\r\n\r\n\r\n    IMG_SIZE = img_size\r\n\r\n    datalist = []\r\n\r\n    for category in CATEGORIES:  # do dogs and cats\r\n\r\n        path = os.path.join(DATADIR,category)  # create path to dogs and cats\r\n        class_num = np.where(CATEGORIES == category)\r\n\r\n        for img in tqdm(os.listdir(path)):  # iterate over each image per dogs and cats\r\n            try:\r\n                img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)  # convert to array\r\n                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize to normalize data size\r\n                datalist.append([new_array, class_num])  # add this to our training_data\r\n            except Exception as e:  # in the interest in keeping the output clean...\r\n                pass\r\n            #except OSError as e:\r\n            #    print(\"OSErrroBad img most likely\", e, os.path.join(path,img))\r\n            #except Exception as e:\r\n            #    print(\"general exception\", e, os.path.join(path,img))\r\n    return datalist\r\n\r\n\r\ntraining_dataset = createdataset(train_data_dir, train_label_dir, CATEGORIES, 200)\r\ntesting_dataset = createdataset(test_data_dir, test_label_dir, CATEGORIES, 200)\r\n\r\nprint(len(training_dataset))\r\nprint(len(testing_dataset))\r\n\r\n\r\ndef dataset(datasets):\r\n    xdata = []\r\n    ylabels = []\r\n    # random.shuffle(datasets)\r\n    for datas,labels in datasets:\r\n        xdata.append(datas)\r\n        ylabels.append(labels)\r\n    return xdata, ylabels\r\n\r\ntrain_images, train_labels = dataset(training_dataset)\r\ntest_images, test_labels = dataset(testing_dataset)\r\nprint(len(train_images))\r\nprint(len(train_labels))\r\nprint(len(test_images))\r\nprint(len(test_labels))\r\n\r\ntrain_images = np.array(train_images)\r\ntest_images = np.array(test_images)\r\ntrain_labels = np.array(train_labels)\r\ntest_labels = np.array(test_labels)\r\n\r\nprint(train_images.shape)\r\nprint(test_images.shape)\r\n\r\ntrain_images = train_images.reshape(train_images.shape[0], 200, 200, 1)\r\ntest_images = test_images.reshape(test_images.shape[0], 200, 200, 1)\r\n\r\ntrain_images = train_images / 255.0\r\ntest_images = test_images / 255.0\r\n\r\nmodel = models.Sequential()\r\n\r\nmodel.add(layers.Conv2D(32, (3, 3), input_shape=(200,200,1)))\r\nmodel.add(layers.BatchNormalization(axis=-1))\r\nmodel.add(layers.Activation('relu'))\r\nmodel.add(layers.Conv2D(32, (3, 3)))\r\nmodel.add(layers.BatchNormalization(axis=-1))\r\nmodel.add(layers.Activation('relu'))\r\nmodel.add(layers.MaxPooling2D(pool_size=(2,2)))\r\n\r\nmodel.add(layers.Conv2D(64,(3, 3)))\r\nmodel.add(layers.BatchNormalization(axis=-1))\r\nmodel.add(layers.Activation('relu'))\r\nmodel.add(layers.Conv2D(64, (3, 3)))\r\nmodel.add(layers.BatchNormalization(axis=-1))\r\nmodel.add(layers.Activation('relu'))\r\nmodel.add(layers.MaxPooling2D(pool_size=(2,2)))\r\n\r\nmodel.add(layers.Flatten())\r\n\r\n# Fully connected layer\r\nmodel.add(layers.Dense(512))\r\nmodel.add(layers.BatchNormalization())\r\nmodel.add(layers.Activation('relu'))\r\nmodel.add(layers.Dropout(0.2))\r\nmodel.add(layers.Dense(4))\r\n\r\nmodel.add(layers.Activation('softmax'))\r\n\r\nmodel.compile(optimizer='adam',\r\n              loss='sparse_categorical_crossentropy',\r\n              metrics=['accuracy'])\r\n\r\nmodel.fit(train_images, train_labels, epochs=3)\r\n\r\ntest_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\r\n\r\nprint('\\nTest accuracy:', test_acc)\r\n```\r\n\r\n\r\n**Other info / logs**\r\n```\r\nTrain on 1610 samples\r\nEpoch 1/3\r\n---------------------------------------------------------------------------\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n<ipython-input-59-e10ee906ee19> in <module>()\r\n     36               metrics=['accuracy'])\r\n     37 \r\n---> 38 model.fit(train_images, train_labels, epochs=3)\r\n     39 \r\n     40 test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\r\n\r\n4 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\r\n    725         shuffle=shuffle,\r\n    726         class_weight=class_weight,\r\n--> 727         sample_weight=sample_weight,\r\n    728         initial_epoch=initial_epoch,\r\n    729         steps_per_epoch=steps_per_epoch,\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\r\n    673         validation_freq=validation_freq,\r\n    674         steps_name='steps_per_epoch')\r\n--> 675 \r\n    676   def evaluate(self,\r\n    677                model,\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py in model_iteration(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\r\n    392         # Get outputs.\r\n    393         batch_outs = f(ins_batch)\r\n--> 394         if not isinstance(batch_outs, list):\r\n    395           batch_outs = [batch_outs]\r\n    396 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py in __call__(self, inputs)\r\n   3474     # CompositeTensors. E.g., if output_structure contains a SparseTensor, then\r\n   3475     # this ensures that we return its value as a SparseTensorValue rather than\r\n-> 3476     # a SparseTensor.\r\n   3477     return nest.map_structure(self._eval_if_composite, output_structure)\r\n   3478 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py in __call__(self, *args, **kwargs)\r\n   1470         ret = tf_session.TF_SessionRunCallable(self._session._session,\r\n   1471                                                self._handle, args,\r\n-> 1472                                                run_metadata_ptr)\r\n   1473         if run_metadata:\r\n   1474           proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\r\n\r\nInvalidArgumentError: Cannot update variable with shape [] using a Tensor with shape [32], shapes must be equal.\r\n\t [[{{node metrics_26/acc/AssignAddVariableOp}}]]\r\n```", "comments": ["Upgrade your tensorflow version to Tensorflow 2.0 and it should work without any issues.\r\n\r\n`!pip install tensorflow==2.0.0`\r\n\r\nFor more information please refer to the following [question](https://stackoverflow.com/questions/57823554/invalidargumenterror-cannot-update-variable-with-shape-using-a-tensor-with-s). Thanks!", "Is that different from my first line of code: `!pip install --quiet tensorflow==2.0.0-rc0` ?\r\nBecause the same code works when the Notebook Settings are changed to 'GPU'.", "Yes it is. As Tensorflow 2.0.0 is a stable release where as 2.0.0-rc0 is not.", "Closing this issue as it has been answered. Please add additional comments and we can open this issue again."]}, {"number": 34565, "title": "Applying certain ImgAug augmenters inside of a `tf.py_function` causes AutoGraph errors.", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS 1.15.1\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.0.0\r\n- Python version: 3.7.5\r\n- Bazel version (if compiling from source): N / A\r\n- GCC/Compiler version (if compiling from source): N / A\r\n- CUDA/cuDNN version: N / A\r\n- GPU model and memory: N / A\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nI'm currently using `imgaug==0.3.0` to augment images as part of a map function applied to a tf.data.Dataset. I'm using `tf.py_function` to call the augmenter and it appears that Autograph is incorrectly generating ops for some of the augmenters causing the pipeline to error.\r\n\r\n**Describe the expected behavior**\r\nI'm upgrading from `tf.py_func` in TF 1.14 to `tf.py_function` TF 2.0 and it was possible to map the `tf.py_func` that called the augmentation onto the dataset.\r\n\r\n**Code to reproduce the issue**\r\nHere is a minimal example, [also runable in Colab](https://colab.research.google.com/drive/1X6NiCnGxNFG9pAZ1Jzd7R1In8BNh9pts#scrollTo=Q_scaVKrpKwJ):\r\n\r\n```\r\nimport imgaug.augmenters as iaa\r\nimport tensorflow as tf\r\n\r\nseq = iaa.Sequential([\r\n    # A non-offending augmenter\r\n    iaa.Multiply(200),\r\n    # the offending augmenter\r\n    iaa.ChangeColorspace(\"HSV\")\r\n])\r\n\r\ndef augment_batch(image):\r\n\r\n    def augment_image(image):\r\n        return seq.augment(images=image.numpy())\r\n\r\n    image = tf.cast(image, tf.uint8)\r\n    image = tf.py_function(augment_image, [image], tf.uint8)\r\n    return image\r\n\r\n# Create a dataset and apply the augmentation.\r\nimage = tf.random.uniform((2, 256, 256, 3), minval=0, maxval=100, dtype=tf.float32)\r\ndataset = tf.data.Dataset.from_tensor_slices((image))\r\ndataset = dataset.batch(2)\r\ndataset = dataset.map(augment_batch)\r\n\r\nfor record in dataset:\r\n    break\r\n```\r\n\r\n**Other info / logs**\r\nFull stack trace:\r\n```\r\n---------------------------------------------------------------------------\r\nUnknownError                              Traceback (most recent call last)\r\n<ipython-input-2-84e7acd87c82> in <module>()\r\n     24 dataset = dataset.map(augment_batch)\r\n     25 \r\n---> 26 for record in dataset:\r\n     27     break\r\n\r\n4 frames\r\n/tensorflow-2.0.0/python3.6/tensorflow_core/python/data/ops/iterator_ops.py in __next__(self)\r\n    620 \r\n    621   def __next__(self):  # For Python 3 compatibility\r\n--> 622     return self.next()\r\n    623 \r\n    624   def _next_internal(self):\r\n\r\n/tensorflow-2.0.0/python3.6/tensorflow_core/python/data/ops/iterator_ops.py in next(self)\r\n    664     \"\"\"Returns a nested structure of `Tensor`s containing the next element.\"\"\"\r\n    665     try:\r\n--> 666       return self._next_internal()\r\n    667     except errors.OutOfRangeError:\r\n    668       raise StopIteration\r\n\r\n/tensorflow-2.0.0/python3.6/tensorflow_core/python/data/ops/iterator_ops.py in _next_internal(self)\r\n    649             self._iterator_resource,\r\n    650             output_types=self._flat_output_types,\r\n--> 651             output_shapes=self._flat_output_shapes)\r\n    652 \r\n    653       try:\r\n\r\n/tensorflow-2.0.0/python3.6/tensorflow_core/python/ops/gen_dataset_ops.py in iterator_get_next_sync(iterator, output_types, output_shapes, name)\r\n   2671       else:\r\n   2672         message = e.message\r\n-> 2673       _six.raise_from(_core._status_to_exception(e.code, message), None)\r\n   2674   # Add nodes to the TensorFlow graph.\r\n   2675   if not isinstance(output_types, (list, tuple)):\r\n\r\n/usr/local/lib/python3.6/dist-packages/six.py in raise_from(value, from_value)\r\n\r\nUnknownError: {{function_node __inference_Dataset_map_augment_batch_17}} KeyError: 'to_colorspace'\r\nTraceback (most recent call last):\r\n\r\n  File \"/tensorflow-2.0.0/python3.6/tensorflow_core/python/ops/script_ops.py\", line 219, in __call__\r\n    return func(device, token, args)\r\n\r\n  File \"/tensorflow-2.0.0/python3.6/tensorflow_core/python/ops/script_ops.py\", line 113, in __call__\r\n    ret = self._func(*args)\r\n\r\n  File \"/tmp/tmpu_6oegng.py\", line 17, in augment_image\r\n    retval__1 = augment_image_scope.mark_return_value(ag__.converted_call(seq.augment, augment_image_scope.callopts, (), {'images': ag__.converted_call(image.numpy, augment_image_scope.callopts, (), None, augment_image_scope)}, augment_image_scope))\r\n\r\n  File \"/tensorflow-2.0.0/python3.6/tensorflow_core/python/autograph/impl/api.py\", line 539, in converted_call\r\n    result = converted_f(*effective_args, **kwargs)\r\n\r\n  File \"/tmp/tmp5wnqr3ev.py\", line 298, in tf__augment\r\n    batch_aug = ag__.converted_call(self.augment_batch, augment_scope.callopts, (batch,), {'hooks': hooks}, augment_scope)\r\n\r\n  File \"/tensorflow-2.0.0/python3.6/tensorflow_core/python/autograph/impl/api.py\", line 539, in converted_call\r\n    result = converted_f(*effective_args, **kwargs)\r\n\r\n  File \"/tmp/tmp_d1lunu_.py\", line 78, in tf__augment_batch\r\n    ag__.for_stmt(augmentables, None, loop_body, get_state_2, set_state_2, (), (), ())\r\n\r\n  File \"/tensorflow-2.0.0/python3.6/tensorflow_core/python/autograph/operators/control_flow.py\", line 339, in for_stmt\r\n    return _py_for_stmt(iter_, extra_test, body, get_state, set_state, init_vars)\r\n\r\n  File \"/tensorflow-2.0.0/python3.6/tensorflow_core/python/autograph/operators/control_flow.py\", line 350, in _py_for_stmt\r\n    state = body(target, *state)\r\n\r\n  File \"/tmp/tmp_d1lunu_.py\", line 75, in loop_body\r\n    aug = ag__.converted_call(ag__.converted_call(getattr, augment_batch_scope.callopts, (augseq, 'augment_%s' % (attr_name,)), None, augment_batch_scope), augment_batch_scope.callopts, (attr,), {'hooks': hooks}, augment_batch_scope)\r\n\r\n  File \"/tensorflow-2.0.0/python3.6/tensorflow_core/python/autograph/impl/api.py\", line 539, in converted_call\r\n    result = converted_f(*effective_args, **kwargs)\r\n\r\n  File \"/tmp/tmpwzc17v74.py\", line 237, in tf__augment_images\r\n    do_return, retval_ = ag__.if_stmt(cond_10, if_true_10, if_false_10, get_state_10, set_state_10, ('do_return', 'retval_'), ())\r\n\r\n  File \"/tensorflow-2.0.0/python3.6/tensorflow_core/python/autograph/operators/control_flow.py\", line 895, in if_stmt\r\n    return _py_if_stmt(cond, body, orelse)\r\n\r\n  File \"/tensorflow-2.0.0/python3.6/tensorflow_core/python/autograph/operators/control_flow.py\", line 1004, in _py_if_stmt\r\n    return body() if cond else orelse()\r\n\r\n  File \"/tmp/tmpwzc17v74.py\", line 216, in if_false_10\r\n    images_result = ag__.if_stmt(cond_8, if_true_8, if_false_8, get_state_8, set_state_8, ('images_result',), ())\r\n\r\n  File \"/tensorflow-2.0.0/python3.6/tensorflow_core/python/autograph/operators/control_flow.py\", line 895, in if_stmt\r\n    return _py_if_stmt(cond, body, orelse)\r\n\r\n  File \"/tensorflow-2.0.0/python3.6/tensorflow_core/python/autograph/operators/control_flow.py\", line 1004, in _py_if_stmt\r\n    return body() if cond else orelse()\r\n\r\n  File \"/tmp/tmpwzc17v74.py\", line 210, in if_true_8\r\n    images_result_1 = ag__.if_stmt(cond_7, if_true_7, if_false_7, get_state_7, set_state_7, ('images_result',), ())\r\n\r\n  File \"/tensorflow-2.0.0/python3.6/tensorflow_core/python/autograph/operators/control_flow.py\", line 895, in if_stmt\r\n    return _py_if_stmt(cond, body, orelse)\r\n\r\n  File \"/tensorflow-2.0.0/python3.6/tensorflow_core/python/autograph/operators/control_flow.py\", line 1004, in _py_if_stmt\r\n    return body() if cond else orelse()\r\n\r\n  File \"/tmp/tmpwzc17v74.py\", line 204, in if_true_7\r\n    images_result_1 = ag__.converted_call(self._augment_images, augment_images_scope.callopts, (images_copy,), {'random_state': self.random_state, 'parents': parents_1, 'hooks': hooks}, augment_images_scope)\r\n\r\n  File \"/tensorflow-2.0.0/python3.6/tensorflow_core/python/autograph/impl/api.py\", line 539, in converted_call\r\n    result = converted_f(*effective_args, **kwargs)\r\n\r\n  File \"/tmp/tmppisluv_j.py\", line 15, in tf___augment_images\r\n    retval_ = _augment_images_scope.mark_return_value(ag__.converted_call(self._augment_augmentables, _augment_images_scope.callopts, (images, random_state, parents, hooks, 'augment_images'), None, _augment_images_scope))\r\n\r\n  File \"/tensorflow-2.0.0/python3.6/tensorflow_core/python/autograph/impl/api.py\", line 541, in converted_call\r\n    result = converted_f(*effective_args)\r\n\r\n  File \"/tmp/tmpjnm069kq.py\", line 56, in tf___augment_augmentables\r\n    augmentables = ag__.if_stmt(cond_1, if_true_1, if_false_1, get_state_2, set_state_2, ('augmentables',), ())\r\n\r\n  File \"/tensorflow-2.0.0/python3.6/tensorflow_core/python/autograph/operators/control_flow.py\", line 895, in if_stmt\r\n    return _py_if_stmt(cond, body, orelse)\r\n\r\n  File \"/tensorflow-2.0.0/python3.6/tensorflow_core/python/autograph/operators/control_flow.py\", line 1004, in _py_if_stmt\r\n    return body() if cond else orelse()\r\n\r\n  File \"/tmp/tmpjnm069kq.py\", line 50, in if_true_1\r\n    augmentables_1, = ag__.for_stmt(order, None, loop_body, get_state_1, set_state_1, (augmentables_1,), ('augmentables',), ())\r\n\r\n  File \"/tensorflow-2.0.0/python3.6/tensorflow_core/python/autograph/operators/control_flow.py\", line 339, in for_stmt\r\n    return _py_for_stmt(iter_, extra_test, body, get_state, set_state, init_vars)\r\n\r\n  File \"/tensorflow-2.0.0/python3.6/tensorflow_core/python/autograph/operators/control_flow.py\", line 350, in _py_for_stmt\r\n    state = body(target, *state)\r\n\r\n  File \"/tmp/tmpjnm069kq.py\", line 48, in loop_body\r\n    augmentables_1 = ag__.converted_call(ag__.converted_call(getattr, _augment_augmentables_scope.callopts, (self[index], augfunc_name), None, _augment_augmentables_scope), _augment_augmentables_scope.callopts, (augmentables_1,), {'parents': parents + [self], 'hooks': hooks}, _augment_augmentables_scope)\r\n\r\n  File \"/tensorflow-2.0.0/python3.6/tensorflow_core/python/autograph/impl/api.py\", line 539, in converted_call\r\n    result = converted_f(*effective_args, **kwargs)\r\n\r\n  File \"/tmp/tmpwzc17v74.py\", line 237, in tf__augment_images\r\n    do_return, retval_ = ag__.if_stmt(cond_10, if_true_10, if_false_10, get_state_10, set_state_10, ('do_return', 'retval_'), ())\r\n\r\n  File \"/tensorflow-2.0.0/python3.6/tensorflow_core/python/autograph/operators/control_flow.py\", line 895, in if_stmt\r\n    return _py_if_stmt(cond, body, orelse)\r\n\r\n  File \"/tensorflow-2.0.0/python3.6/tensorflow_core/python/autograph/operators/control_flow.py\", line 1004, in _py_if_stmt\r\n    return body() if cond else orelse()\r\n\r\n  File \"/tmp/tmpwzc17v74.py\", line 88, in if_true_10\r\n    do_return, retval_ = ag__.if_stmt(cond, if_true, if_false, get_state, set_state, ('do_return', 'retval_'), ())\r\n\r\n  File \"/tensorflow-2.0.0/python3.6/tensorflow_core/python/autograph/operators/control_flow.py\", line 895, in if_stmt\r\n    return _py_if_stmt(cond, body, orelse)\r\n\r\n  File \"/tensorflow-2.0.0/python3.6/tensorflow_core/python/autograph/operators/control_flow.py\", line 1004, in _py_if_stmt\r\n    return body() if cond else orelse()\r\n\r\n  File \"/tmp/tmpwzc17v74.py\", line 83, in if_false\r\n    images_result = ag__.converted_call(self._augment_images, augment_images_scope.callopts, (images,), {'random_state': self.random_state, 'parents': parents, 'hooks': hooks}, augment_images_scope)\r\n\r\n  File \"/tensorflow-2.0.0/python3.6/tensorflow_core/python/autograph/impl/api.py\", line 539, in converted_call\r\n    result = converted_f(*effective_args, **kwargs)\r\n\r\n  File \"/tmp/tmpyhqkjn3y.py\", line 48, in tf___augment_images\r\n    ag__.for_stmt(ag__.converted_call(sm.xrange, _augment_images_scope.callopts, (nb_images,), None, _augment_images_scope), None, loop_body, get_state_1, set_state_1, (), (), ())\r\n\r\n  File \"/tensorflow-2.0.0/python3.6/tensorflow_core/python/autograph/operators/control_flow.py\", line 339, in for_stmt\r\n    return _py_for_stmt(iter_, extra_test, body, get_state, set_state, init_vars)\r\n\r\n  File \"/tensorflow-2.0.0/python3.6/tensorflow_core/python/autograph/operators/control_flow.py\", line 350, in _py_for_stmt\r\n    state = body(target, *state)\r\n\r\n  File \"/tmp/tmpyhqkjn3y.py\", line 46, in loop_body\r\n    ag__.if_stmt(cond, if_true, if_false, get_state, set_state, (), ('result[i]',))\r\n\r\n  File \"/tensorflow-2.0.0/python3.6/tensorflow_core/python/autograph/operators/control_flow.py\", line 895, in if_stmt\r\n    return _py_if_stmt(cond, body, orelse)\r\n\r\n  File \"/tensorflow-2.0.0/python3.6/tensorflow_core/python/autograph/operators/control_flow.py\", line 1004, in _py_if_stmt\r\n    return body() if cond else orelse()\r\n\r\n  File \"/tmp/tmpyhqkjn3y.py\", line 42, in if_false\r\n    image_aug = ag__.converted_call(change_colorspace_, _augment_images_scope.callopts, (image, to_colorspace, self.from_colorspace), None, _augment_images_scope)\r\n\r\n  File \"/tensorflow-2.0.0/python3.6/tensorflow_core/python/autograph/impl/api.py\", line 541, in converted_call\r\n    result = converted_f(*effective_args)\r\n\r\n  File \"/tmp/tmpr5xrj81x.py\", line 221, in tf__change_colorspace_\r\n    do_return, retval_ = ag__.if_stmt(cond_6, if_true_6, if_false_6, get_state_7, set_state_7, ('do_return', 'retval_'), ())\r\n\r\n  File \"/tensorflow-2.0.0/python3.6/tensorflow_core/python/autograph/operators/control_flow.py\", line 895, in if_stmt\r\n    return _py_if_stmt(cond, body, orelse)\r\n\r\n  File \"/tensorflow-2.0.0/python3.6/tensorflow_core/python/autograph/operators/control_flow.py\", line 1004, in _py_if_stmt\r\n    return body() if cond else orelse()\r\n\r\n  File \"/tmp/tmpr5xrj81x.py\", line 151, in if_false_6\r\n    ag__.for_stmt(['to_colorspace', 'from_colorspace'], None, loop_body, get_state_3, set_state_3, (), (), ())\r\n\r\n  File \"/tensorflow-2.0.0/python3.6/tensorflow_core/python/autograph/operators/control_flow.py\", line 339, in for_stmt\r\n    return _py_for_stmt(iter_, extra_test, body, get_state, set_state, init_vars)\r\n\r\n  File \"/tensorflow-2.0.0/python3.6/tensorflow_core/python/autograph/operators/control_flow.py\", line 350, in _py_for_stmt\r\n    state = body(target, *state)\r\n\r\n  File \"/tmp/tmpr5xrj81x.py\", line 149, in loop_body\r\n    assert ag__.converted_call(locals, change_colorspace__scope.callopts, (), None, change_colorspace__scope)[arg_name] in CSPACE_ALL, 'Expected `%s` to be one of: %s. Got: %s.' % (arg_name, CSPACE_ALL, ag__.converted_call(locals, change_colorspace__scope.callopts, (), None, change_colorspace__scope)[arg_name])\r\n\r\nKeyError: 'to_colorspace'\r\n\r\n\r\n\t [[{{node EagerPyFunc}}]] [Op:IteratorGetNextSync]\r\n```\r\n", "comments": ["This appears to be fixed in `tf-nightly==2.1.0.dev20191124`, but if anyone has a work around for 2.0 that would be great.", "@jamesonthecrow ,\r\nHello, as the issue is fixed in latest` tf-nightly` can you try using the same version? \r\nAlso looks like complete code is not given, please provide the same. Thanks!", "I just updated the comment with a working Colab notebook that reproduces the error. I also noticed, that the kernel only dies when `imgaug==0.3.0` is used. `imgaug==0.2.9` throws an error, but doesn't appear to actually kill the kernel.", "For the updated code, issue replicating in both `TF-2.0` and` tf-nightly`.Kindly find the [gist](https://colab.sandbox.google.com/gist/oanush/7d178d1e212fd596b1386ff3b9d1ffae/tensorflow-2-0-py_function-bug.ipynb#scrollTo=XLjFY-URu6RH) of colab.", "It is likely there is some existing issue in your `augment_batch` code that is not surfacing clearly due to autograph. Could you try annotating `augment_batch` with `@tf.function(autograph=False)` and see if you get a clearer error message?", "@jamesonthecrow,\r\nCan you please respond to @jaingaurav's comment. Thanks!  ", "Given that things work fine on TF 2.1, we're just going to go with that. I'm closing this out.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34565\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34565\">No</a>\n", "try something like this `example` is a single element of your dataset after you parse for example tf records:\r\n```\r\n@tf.function\r\ndef process_sample(example):\r\n    shape = example['image'].get_shape(_\r\n    image = tf.py_function( your_augmentation_function, inp=[example['image']], Tout=tf.float32)\r\n    image.set_shape(shape)\r\n    return image, example['label']\r\n```\r\nthen map the transformations with `dataset.map(process_sample, num_parallel_calls=tf.data.experimental.AUTOTUNE)`"]}, {"number": 34564, "title": "experimental_connect_to_cluster hangs", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):No custom code\r\n\r\n- TensorFlow installed from (source or binary):Binary\r\n- TensorFlow version (use command below): '2.1.0-dev20191124'\r\n- Python version:3.5.3\r\n- Using GCP image: debian-9-tf-nightly-2-x-v20191124\r\n- Using TPU version: v2-8 , nightly-2.x , preempitble\r\n- zone(probably irrelevent): us-central1-b\r\n\r\n*The TPU and Host were built without `ctpu` tool\r\n\r\n**Code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\nresolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://10.0.101.2:8470')\r\ntf.config.experimental_connect_to_cluster(resolver)\r\n```\r\n\r\n\r\n**Describe the current behavior**\r\nThe `experimental_connect_to_cluster` call hangs indefinitely. \r\nNo error message is produced, it is unclear what should be done.\r\nI had the same problem in 2.0.0.\r\n\r\n**Describe the expected behavior**\r\na.Call shouldn't hang and should provide informative error information\r\nb. If some environment settings need to be set to facilitate TPU-host communications, it should be better documented.\r\n\r\n**Other info / logs**\r\nJupyter log is:\r\n```\r\n[I 22:07:17.299 NotebookApp] Kernel restarted: c9cf10ac-3d03-4a62-a737-3f8e94b44aec\r\n[W 22:07:18.426 NotebookApp] SSL Error on 13 ('79.181.28.67', 59971): [SSL: SSLV3_ALERT_CERTIFICATE_UNKNOWN] sslv3 alert certificate unknown (_ssl.c:720)\r\n[I 22:07:18.935 NotebookApp] Restoring connection for c9cf10ac-3d03-4a62-a737-3f8e94b44aec:c5d1ab723abe433986849772ed497483\r\n[I 22:07:18.935 NotebookApp] Replaying 3 buffered messages\r\n2019-11-24 22:07:31.539205: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2019-11-24 22:07:31.546892: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\r\n2019-11-24 22:07:31.547399: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55dc09561c30 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2019-11-24 22:07:31.547455: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2019-11-24 22:07:31.554227: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:300] Initialize GrpcChannelCache for job worker -> {0 -> 10.0.101.2:8470}\r\n2019-11-24 22:07:31.554338: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:300] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:31900}\r\n[I 22:07:43.819 NotebookApp] Saving file at /project_drive/project/Trainv3.ipynb\r\n[W 22:07:43.820 NotebookApp] Notebook project_drive/project/Trainv3.ipynb is not trusted\r\n```\r\n\r\ngcloud compute instances describe host:\r\n```\r\ncanIpForward: false                                                                                                                        \r\ncpuPlatform: Intel Haswell                                                                                                                 \r\ncreationTimestamp: '2019-11-24T10:28:54.344-08:00'                                                                                         \r\ndeletionProtection: false                                                                                                                  \r\ndescription: ''                                                                                                                            \r\ndisks:                                                                                                                                     \r\n- autoDelete: false                                                                                                                        \r\n  boot: true                                                                                                                               \r\n  deviceName: instance-1                                                                                                                   \r\n  guestOsFeatures:                                                                                                                         \r\n  - type: VIRTIO_SCSI_MULTIQUEUE                                                                                                           \r\n  index: 0                                                                                                                                 \r\n  interface: SCSI                                                                                                                          \r\n  kind: compute#attachedDisk                                                                                                               \r\n  licenses:                                                                                                                                \r\n  - https://www.googleapis.com/compute/v1/projects/debian-cloud/global/licenses/debian-9-stretch                                           \r\n  - https://www.googleapis.com/compute/v1/projects/ml-images/global/licenses/debian-tensorflow                                             \r\n  mode: READ_WRITE                                                                                                                         \r\n  source: https://www.googleapis.com/compute/v1/projects/deeplearning-257902/zones/us-central1-b/disks/instance-1                          \r\n  type: PERSISTENT                                                                                                                         \r\n- autoDelete: false                                                                                                                        \r\n  boot: false                                                                                                                              \r\n  deviceName: yaop-project                                                                                                                 \r\n  index: 1                                                                                                                                 \r\n  interface: SCSI                                                                                                                          \r\n  kind: compute#attachedDisk                                                                                                               \r\n  mode: READ_WRITE                                                                                                                         \r\n  source: https://www.googleapis.com/compute/v1/projects/deeplearning-257902/zones/us-central1-b/disks/yaop-project                        \r\n  type: PERSISTENT                                                                                                                         \r\ndisplayDevice:                                                                                                                             \r\n  enableDisplay: false                                                                                                                     \r\nid: '7023192423693513994'                                                                                                                  \r\nkind: compute#instance                                                                                                                     \r\nlabelFingerprint: 42WmSpB8rSM=                                                                                                             \r\nmachineType: https://www.googleapis.com/compute/v1/projects/deeplearning-257902/zones/us-central1-b/machineTypes/n1-highmem-4              \r\nmetadata:                                                                                                                                  \r\n  fingerprint: oW9kyu6jwEE=                                                                                                                \r\n  kind: compute#metadata                                                                                                                   \r\nname: instance-1                                                                                                                           \r\nnetworkInterfaces:                                                                                                                         \r\n- accessConfigs:                                                                                                                           \r\n  - kind: compute#accessConfig                                                                                                             \r\n    name: External NAT                                                                                                                     \r\n    natIP: 35.225.64.207                                                                                                                   \r\n    networkTier: PREMIUM                                                                                                                   \r\n    type: ONE_TO_ONE_NAT                                                                                                                   \r\n  fingerprint: VbmPG2_4Dak=                                                                                                                \r\n  kind: compute#networkInterface                                                                                                           \r\n  name: nic0                                                                                                                               \r\n  network: https://www.googleapis.com/compute/v1/projects/deeplearning-257902/global/networks/default                                      \r\n  networkIP: 10.128.0.18                                                                                                                   \r\n  subnetwork: https://www.googleapis.com/compute/v1/projects/deeplearning-257902/regions/us-central1/subnetworks/default                   \r\nreservationAffinity:                                                                                                                       \r\n  consumeReservationType: ANY_RESERVATION                                                                                                  \r\nscheduling:                                                                                                                                \r\n  automaticRestart: true                                                                                                                   \r\n  onHostMaintenance: MIGRATE                                                                                                               \r\n  preemptible: false                                                                                                                       \r\nselfLink: https://www.googleapis.com/compute/v1/projects/deeplearning-257902/zones/us-central1-b/instances/instance-1                      \r\nserviceAccounts:                                                                                                                           \r\n- email: 312164605303-compute@developer.gserviceaccount.com                                                                                \r\n  scopes:                                                                                                                                  \r\n  - https://www.googleapis.com/auth/devstorage.read_only                                                                                   \r\n  - https://www.googleapis.com/auth/logging.write                                                                                          \r\n  - https://www.googleapis.com/auth/monitoring.write                                                                                       \r\n  - https://www.googleapis.com/auth/servicecontrol                                                                                         \r\n  - https://www.googleapis.com/auth/service.management.readonly                                                                            \r\n  - https://www.googleapis.com/auth/trace.append                                                                                           \r\nstartRestricted: false                                                                                                                     \r\nstatus: RUNNING                                                                                                                            \r\ntags:                                                                                                                                      \r\n  fingerprint: Uv7CXg8qQhM=                                                                                                                \r\n  items:                                                                                                                                   \r\n  - http-server                                                                                                                            \r\n  - https-server                                                                                                                           \r\n  - jupyter                                                                                                                                \r\n  - nomachine                                                                                                                              \r\nzone: https://www.googleapis.com/compute/v1/projects/deeplearning-257902/zones/us-central1-b                                               \r\n```\r\n", "comments": ["Trying to get tpu connection to work, I observed similar behavior in TF 1.15, in\r\n`tf.contrib.distribute.initialize_tpu_system(resolver)`\r\nwhich seems to be the previous name for the function.\r\n\r\nIn a test case using all default settings with ctpu, and TF 1.15.\r\nif the tpu is down or the ip is incorrect, or it is unreachable for some reason,  it will hang similarly forever.\r\n\r\nIn my case, it seems to be something about the network connectivity.", "@MikeOfZen, Could try with proper network connectivity and check again. Thanks!", "@gadagashwini ,Hi, yes, I got it working, it was due to `tf.config.experimental_connect_to_cluster(resolver)` not being able to reach the server, for any reason (might be down, wrong address, firewalled, etc...).\r\nIt's continuously polling for the server and if the server comes online, the call will proceed.\r\nIt might be the design, but I believe it's an issue for a number of reasons.\r\n1. It doesn't log that it's waiting for the server, it just logs that it's initializing it\r\n2. This behavior is undocumented.\r\n3. The typical behavior in such functions is to have a number of retries (as a parameter of the function call), and an appropriate informative exception if it fails + logging information for each retry. \r\n\r\nThis issue is compounded by the TPU network accessibility, the TPU servers don't respond to pings and it's hard to verify they are indeed accessible.\r\nThe only way I found to work to test connectivity is `nmap -Pn -p8470 TPUIP`\r\n", "There's Another problem with this command that might warrant a separate issue, but for now I'm gonna bundle with this, because it's about the command input.\r\n\r\nThe simple code:\r\n```\r\nimport tensorflow as tf\r\ntpu_address = 'grpc://10.0.3.28470'  #missing ':' between ip and port\r\nresolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=tpu_address)\r\ntf.config.experimental_connect_to_cluster(resolver)\r\n```\r\nHas the distinction of being able to crash the python kernel (3.5).\r\n\r\n*omitting the port as in \"`'grpc://123.123.123.13`'\" has the same effect\r\n", "@MikeOfZen It looks like you are using an older Version of Tensorflow (2.0) .Many bugs have been fixed in the latest version. Can you please execute your code using Latest Version (2.6.0) and let us know if the issue still persists? Please refer to the similar [issue](https://stackoverflow.com/questions/61371684/gcp-and-tpu-experimental-connect-to-cluster-give-no-response) and let us know if it helps ?Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34564\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34564\">No</a>\n"]}, {"number": 34563, "title": "operators in the model are not supported by the standard TensorFlow Lite runtime", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Win 10 x64\r\n- TensorFlow version (or github SHA if from source):  2.0\r\n\r\n\r\n**Provide the text output from tflite_convert**\r\n\r\n\r\n\r\n```\r\n# CODE\r\n```\r\n----------------------------------------------------------------------------\r\n\r\n\r\n\r\nimport tensorflow as tf\r\n\r\nfilename = 'model_24_11_19_3'\r\nmodel = tf.saved_model.load(filename)\r\n\r\nconcrete_func = model.signatures[\r\n  tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY]\r\n\r\nconcrete_func.inputs[0].set_shape([1,8])\r\nconverter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])\r\n\r\nTflite_model = converter.convert()\r\nopen(\"converted_model_new1.tflite\", \"wb\").write(Tflite_model)\r\n\r\n\r\n\r\n*LOGS* \r\n\r\n\r\n\r\n2019-11-25 02:07:37.676230: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\n2019-11-25 02:07:38.516215: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)\r\n2019-11-25 02:07:38.516605: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\r\n2019-11-25 02:07:38.537041: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: graph_to_optimize\r\n2019-11-25 02:07:38.537143: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: Graph size after: 243 nodes (231), 405 edges (393), time = 7.653ms.\r\n2019-11-25 02:07:38.537239: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: Graph size after: 243 nodes (0), 405 edges (0), time = 3.096ms.\r\n2019-11-25 02:07:38.537326: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: __inference_sequential_lstm_while_body_296488_706\r\n2019-11-25 02:07:38.537407: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2019-11-25 02:07:38.537479: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2019-11-25 02:07:38.537555: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: __inference_sequential_lstm_while_cond_296487_4136\r\n2019-11-25 02:07:38.537652: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2019-11-25 02:07:38.537730: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2019-11-25 02:07:38.537821: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: __inference_sequential_lstm_1_while_cond_296673_1329\r\n2019-11-25 02:07:38.537908: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2019-11-25 02:07:38.537982: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2019-11-25 02:07:38.538056: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: __inference_sequential_lstm_1_while_body_296674_505\r\n2019-11-25 02:07:38.538147: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n2019-11-25 02:07:38.538697: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2019-11-25 02:07:38.963864: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)\r\n2019-11-25 02:07:38.964405: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\r\n2019-11-25 02:07:40.804458: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: graph_to_optimize\r\n2019-11-25 02:07:40.804545: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 167 nodes (-77), 290 edges (-115), time = 1596.62ms.\r\n2019-11-25 02:07:40.804631: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 167 nodes (0), 290 edges (0), time = 168.831ms.\r\n2019-11-25 02:07:40.804719: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: __inference_sequential_lstm_while_cond_296487_4136_frozen\r\n2019-11-25 02:07:40.804817: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 16 nodes (0), 4 edges (0), time = 0.611ms.\r\n2019-11-25 02:07:40.804907: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 16 nodes (0), 4 edges (0), time = 0.151ms.\r\n2019-11-25 02:07:40.804991: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: __inference_sequential_lstm_1_while_body_296674_505_frozen\r\n2019-11-25 02:07:40.805089: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 53 nodes (-1), 71 edges (0), time = 1.521ms.\r\n2019-11-25 02:07:40.805182: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 53 nodes (0), 71 edges (0), time = 0.589ms.\r\n2019-11-25 02:07:40.805618: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: __inference_sequential_lstm_1_while_cond_296673_1329_frozen\r\n2019-11-25 02:07:40.805734: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 14 nodes (0), 4 edges (0), time = 0.561ms.\r\n2019-11-25 02:07:40.805837: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 14 nodes (0), 4 edges (0), time = 0.155ms.\r\n2019-11-25 02:07:40.805941: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: __inference_sequential_lstm_while_body_296488_706_frozen\r\n2019-11-25 02:07:40.806047: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 69 nodes (-1), 95 edges (0), time = 1.81ms.\r\n2019-11-25 02:07:40.806125: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 69 nodes (0), 95 edges (0), time = 0.815ms.\r\nTraceback (most recent call last):\r\n  File \"D:/Projects/Test3/NMT.py\", line 15, in <module>\r\n    Tflite_model = converter.convert()\r\n  File \"C:\\Users\\Jiraiya\\Anaconda3\\envs\\env_tensorflow2\\lib\\site-packages\\tensorflow_core\\lite\\python\\lite.py\", line 474, in convert\r\n    **converter_kwargs)\r\n  File \"C:\\Users\\Jiraiya\\Anaconda3\\envs\\env_tensorflow2\\lib\\site-packages\\tensorflow_core\\lite\\python\\convert.py\", line 475, in toco_convert_impl\r\n    enable_mlir_converter=enable_mlir_converter)\r\n  File \"C:\\Users\\Jiraiya\\Anaconda3\\envs\\env_tensorflow2\\lib\\site-packages\\tensorflow_core\\lite\\python\\convert.py\", line 215, in toco_convert_protos\r\n    raise ConverterError(\"See console for info.\\n%s\\n%s\\n\" % (stdout, stderr))\r\ntensorflow.lite.python.convert.ConverterError: See console for info.\r\n2019-11-25 02:07:42.853028: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\n2019-11-25 02:07:42.970994: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListFromTensor\r\n2019-11-25 02:07:42.971178: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21\r\n2019-11-25 02:07:42.971275: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListFromTensor\r\n2019-11-25 02:07:42.971504: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21\r\n2019-11-25 02:07:42.971600: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListReserve\r\n2019-11-25 02:07:42.971734: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21\r\n2019-11-25 02:07:42.971851: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: While\r\n2019-11-25 02:07:42.971919: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21\r\n2019-11-25 02:07:42.972082: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21\r\n2019-11-25 02:07:42.972184: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21\r\n2019-11-25 02:07:42.972291: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListStack\r\n2019-11-25 02:07:42.972388: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListFromTensor\r\n2019-11-25 02:07:42.972463: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21\r\n2019-11-25 02:07:42.972543: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListReserve\r\n2019-11-25 02:07:42.972613: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21\r\n2019-11-25 02:07:42.972845: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: While\r\n2019-11-25 02:07:42.972914: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21\r\n2019-11-25 02:07:42.973048: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21\r\n2019-11-25 02:07:42.973170: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListStack\r\n2019-11-25 02:07:42.992717: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 77 operators, 174 arrays (0 quantized)\r\n2019-11-25 02:07:42.993725: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 77 operators, 174 arrays (0 quantized)\r\n2019-11-25 02:07:43.009358: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 53 operators, 139 arrays (0 quantized)\r\n2019-11-25 02:07:43.012720: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 2: 51 operators, 136 arrays (0 quantized)\r\n2019-11-25 02:07:43.013768: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 51 operators, 136 arrays (0 quantized)\r\n2019-11-25 02:07:43.014716: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 51 operators, 136 arrays (0 quantized)\r\n2019-11-25 02:07:43.015495: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Identify nearest upsample.: 51 operators, 136 arrays (0 quantized)\r\n2019-11-25 02:07:43.016573: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 32896 bytes, theoretical optimal value: 32768 bytes.\r\n2019-11-25 02:07:43.016915: I tensorflow/lite/toco/toco_tooling.cc:471] Number of parameters: 8969974\r\n2019-11-25 02:07:43.017550: E tensorflow/lite/toco/toco_tooling.cc:498] We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md\r\n and pasting the following:\r\n\r\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CAST, CONCATENATION, DIV, EXP, EXPAND_DIMS, FILL, FULLY_CONNECTED, GATHER, LOGISTIC, MUL, NOT_EQUAL, PACK, REDUCE_MAX, RESHAPE, SHAPE, SPLIT, STRIDED_SLICE, SUB, SUM, TANH, TILE, TRANSPOSE, ZEROS_LIKE. Here is a list of operators for which you will need custom implementations: TensorListFromTensor, TensorListReserve, TensorListStack, While.\r\nTraceback (most recent call last):\r\n  File \"c:\\users\\jiraiya\\anaconda3\\envs\\env_tensorflow2\\lib\\runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"c:\\users\\jiraiya\\anaconda3\\envs\\env_tensorflow2\\lib\\runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"C:\\Users\\Jiraiya\\Anaconda3\\envs\\env_tensorflow2\\Scripts\\toco_from_protos.exe\\__main__.py\", line 7, in <module>\r\n  File \"c:\\users\\jiraiya\\anaconda3\\envs\\env_tensorflow2\\lib\\site-packages\\tensorflow_core\\lite\\toco\\python\\toco_from_protos.py\", line 93, in main\r\n    app.run(main=execute, argv=[sys.argv[0]] + unparsed)\r\n  File \"c:\\users\\jiraiya\\anaconda3\\envs\\env_tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\platform\\app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"c:\\users\\jiraiya\\anaconda3\\envs\\env_tensorflow2\\lib\\site-packages\\absl\\app.py\", line 299, in run\r\n    _run_main(main, args)\r\n  File \"c:\\users\\jiraiya\\anaconda3\\envs\\env_tensorflow2\\lib\\site-packages\\absl\\app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"c:\\users\\jiraiya\\anaconda3\\envs\\env_tensorflow2\\lib\\site-packages\\tensorflow_core\\lite\\toco\\python\\toco_from_protos.py\", line 56, in execute\r\n    enable_mlir_converter)\r\nException: We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md\r\n and pasting the following:\r\n\r\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CAST, CONCATENATION, DIV, EXP, EXPAND_DIMS, FILL, FULLY_CONNECTED, GATHER, LOGISTIC, MUL, NOT_EQUAL, PACK, REDUCE_MAX, RESHAPE, SHAPE, SPLIT, STRIDED_SLICE, SUB, SUM, TANH, TILE, TRANSPOSE, ZEROS_LIKE. Here is a list of operators for which you will need custom implementations: TensorListFromTensor, TensorListReserve, TensorListStack, While.\r\n\r\n\r\n\r\n\r\nProcess finished with exit code 1\r\n", "comments": ["Hi,\r\n\r\nSorry for late reply. The missing ops could be supported by the new MLIR-based TF Lite converter. Can you download the latest tf-nightly and then set:\r\nconverter.experimental_new_converter = True\r\n\r\nThis should resolve your issue.\r\n\r\nFor detailed examples, please see:\r\nhttps://groups.google.com/a/tensorflow.org/forum/#!topic/tflite/C7Ag0sUrLYg\r\n\r\nThanks.", "Thank You .Its working now.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34563\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34563\">No</a>\n"]}, {"number": 34562, "title": "multi previous states RNN ", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using):\r\n- Are you willing to contribute it (Yes/No):\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\n\r\nI try to use the RNN model to do the time series as \r\nh_t  = F(  h_{t-1},   h_{t-2}   X_t  )\r\nI found that  RNN in TF2.0  not works.\r\n\r\nIt only works for the following model.\r\nh_t  = F(  h_{t-1},  X_t  )\r\n\r\nCould you give me some help  which RNN model in TF2.0 could do the \r\nh_t  = F(  h_{t-1},   h_{t-2}   X_t  ),\r\n\r\nwhere t is a sequence of time [t_0, t_1,  t_2,  ...,   t_N ].\r\n\r\nThanks\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n**Will this change the current api? How?**\r\n\r\n**Who will benefit with this feature?**\r\n\r\n**Any Other info.**\r\n", "comments": ["So far, all the classic RNN cell only access the state from t-1, rather than from any previous state further. This is why we design the API interface like at as well, where cell takes inputs and state from t-1. \r\n\r\nYou will have to write your own code achieve the behavior you described. Eg:\r\n\r\n```\r\nclass DoubleStateCell(layer):\r\n\r\n  def __init__(self, units):\r\n     # having 2 states like LSTM, but tracking t-1 and t-2\r\n     self.state_size = [units, units] \r\n\r\n  def call(self, inputs, states):\r\n     state_t-1 = states[0]\r\n     state_t-2 = states[1]\r\n     .....\r\n     new_state = ...\r\n     output = ....\r\n     return output, [new_state, state_t-1]\r\n```\r\n"]}, {"number": 34561, "title": "Import statement for Tensorflow returning error", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): windows 10 x64\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 2.0.0\r\n- Python version: 3.6.2\r\n- Installed using: pip\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- UserBenchmarks: Game 11%, Desk 12%, Work 11%\r\n- CPU: Intel Pentium D 3.40GHz - 1.4%\r\n- GPU: Nvidia GeForce 8600 GT - 1%\r\n- HDD: Seagate Barracuda 7200.10 320GB - 17.9%\r\n- USB: JetFlash Transcend 8GB - 1.5%\r\n- RAM: Unknown 3GB - 2.8%\r\n- MBD: Gigabyte GA-945PL-S3\r\n\r\n\r\n<em>Hi, I recently installed tensorflow using pip (after going through so much problems), and just when i tried to import tensorflow as tf in my project it returns this error:</em>\r\n\r\n<p>Traceback (most recent call last):\r\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Program Files\\Python36\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Program Files\\Python36\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Lase\\Documents\\Programming stuff\\Python\\demo 1\\.vs\\demo 1\\main.py\", line 137, in <module>\r\n    import tensorflow as tf\r\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\__init__.py\", line 98, in <module>\r\n    from tensorflow_core import *\r\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 40, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Program Files\\Python36\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Program Files\\Python36\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Program Files\\Python36\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n</p>\r\n\r\n<em>Steps taken to solve problem</em>\r\n1. Repeatedly uninstalling and reinstalling tensorflow to see any change, but none worked\r\n2. I also noticed the same thing happens when i try to import keras . Keras tries to import tensorflow and returns the same error\r\n3. Tried installing it on a virtual environment using virtualenv but still didnt work\r\n\r\n   ", "comments": ["Maybe a duplicate of https://github.com/tensorflow/tensorflow/issues/19584.\r\n@jothamsl , you have installed with pip which means you have installed the binary and not from the source. Please make that correction. Thank you.", "**Installing **TensorFlow** (TF) prebuilt binaries**\r\n\r\n*TensorFlow release binaries version 1.6 and higher are prebuilt with AVX instruction sets.*\r\n\r\nTherefore on any CPU that does not have these instruction sets, either CPU or GPU version of TF will fail to load.\r\nApparently, your CPU model does not support AVX instruction sets. You can still use TensorFlow with the alternatives given below:\r\n* Try Google Colab to use TensorFlow.\r\n    * The easiest way to use TF will be to switch to [google colab](https://colab.sandbox.google.com/notebooks/welcome.ipynb#recent=true). You get pre-installed latest stable TF version. Also you can use ```pip install``` to install any other preferred TF version.\r\n    * It has an added advantage since you can you easily switch to different hardware accelerators     \r\n      (cpu, gpu, tpu) as per the task. \r\n    * All you need is a good internet connection and you are all set.\r\n* Try to build TF from sources by changing CPU optimization flags.\r\n\r\n*Please let us know if this helps.*", "<p>Ok i'm using Google colab and it works perfectly, thanks!</p>", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34561\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34561\">No</a>\n"]}, {"number": 34560, "title": "Check failed: s.ok() copy tensor to gpu sync", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): [v1.13.1](https://github.com/tensorflow/tensorflow/archive/v1.13.1.zip)\r\n- Python version: 2.7\r\n- Bazel version (if compiling from source): 0.19.2\r\n- GCC/Compiler version (if compiling from source): 5.4.0\r\n- CUDA/cuDNN version: 9.0 / 7\r\n- GPU model and memory: Tesla K40c 12GB\r\n\r\n\r\n**Describe the current behavior**\r\nI tried to run distributed training (1 ps and 1 worker). I used VGG19 from [tensorflow/benchmark v1.13 compatible](https://github.com/tensorflow/benchmarks) as the training model.  \r\nWhen `server_protocol` was set to `grpc` or `grpc+gdr`, the training was normal. But when it was set to `grpc+verbs`, the error `F tensorflow/contrib/verbs/rdma.cc:1635] Check failed: s.ok() copy tensor to gpu sync\r\nAborted (core dumped)` occured at PS (not at worker).  Is this a bug?\r\nThe whole log is as follows:\r\n\r\n```\r\n$ CUDA_VISIBLE_DEVICES='' python benchmarks/scripts/tf_cnn_benchmarks/tf_cnn_benchmarks.py --local_parameter_device=cpu --num_gpus=1 --batch_size=64 --model=vgg19 --variable_update=parameter_server --num_batches=5000 --server_protocol=grpc+verbs --ps_hosts=\"localhost:2222\" --worker_hosts=\"localhost:3333\" --job_name=ps --task_index=0\r\n2019-11-24 22:06:17.143431: E tensorflow/stream_executor/cuda/cuda_driver.cc:300] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\r\n2019-11-24 22:06:17.143507: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:161] retrieving CUDA diagnostic information for host: g3-nasp\r\n2019-11-24 22:06:17.143525: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:168] hostname: g3-nasp\r\n2019-11-24 22:06:17.143595: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:192] libcuda reported version is: 418.39.0\r\n2019-11-24 22:06:17.143652: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:196] kernel reported version is: 418.39.0\r\n2019-11-24 22:06:17.143668: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:303] kernel version seems to match DSO: 418.39.0\r\n2019-11-24 22:06:17.145757: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:252] Initialize GrpcChannelCache for job ps -> {0 -> localhost:2222}\r\n2019-11-24 22:06:17.145788: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:252] Initialize GrpcChannelCache for job worker -> {0 -> 12.12.12.13:3333}\r\n2019-11-24 22:06:17.151396: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:252] Initialize GrpcChannelCache for job ps -> {0 -> localhost:2222}\r\n2019-11-24 22:06:17.151432: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:252] Initialize GrpcChannelCache for job worker -> {0 -> 12.12.12.13:3333}\r\n2019-11-24 22:06:17.161484: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:391] Started server with target: grpc://localhost:2222\r\n2019-11-24 22:06:17.164512: I tensorflow/contrib/verbs/rdma_mgr.cc:130] Connected to remote node /job:worker/replica:0/task:0\r\nTensorFlow:  1.13\r\nModel:       vgg19\r\nDataset:     imagenet (synthetic)\r\nMode:        training\r\nSingleSess:  False\r\nBatch size:  64 global\r\n             64 per device\r\nNum batches: 5000\r\nNum epochs:  0.25\r\nDevices:     ['/job:worker/replica:0/task:0/gpu:0']\r\nNUMA bind:   False\r\nData format: NCHW\r\nOptimizer:   sgd\r\nVariables:   parameter_server\r\nSync:        True\r\n==========\r\nRunning parameter server 0\r\n2019-11-24 22:06:22.987281: F tensorflow/contrib/verbs/rdma.cc:1635] Check failed: s.ok() copy tensor to gpu sync\r\nAborted (core dumped)\r\n```\r\nand the gdb log is as follows:\r\n```\r\n[...]\r\n[Thread debugging using libthread_db enabled]\r\nUsing host libthread_db library \"/lib/x86_64-linux-gnu/libthread_db.so.1\".\r\nCore was generated by `python benchmarks/scripts/tf_cnn_benchmarks/t'.\r\nProgram terminated with signal SIGABRT, Aborted.\r\n#0  0x00007fc91eb02428 in __GI_raise (sig=sig@entry=6) at ../sysdeps/unix/sysv/linux/raise.c:54\r\n54      ../sysdeps/unix/sysv/linux/raise.c: No such file or directory.\r\n[Current thread is 1 (Thread 0x7fc782ffd700 (LWP 1941))]\r\n(gdb) where\r\n#0  0x00007fc91eb02428 in __GI_raise (sig=sig@entry=6) at ../sysdeps/unix/sysv/linux/raise.c:54\r\n#1  0x00007fc91eb0402a in __GI_abort () at abort.c:89\r\n#2  0x00007fc8c14a2a94 in tensorflow::internal::LogMessageFatal::~LogMessageFatal() ()\r\n   from /tf1.13/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#3  0x00007fc8bc9a6fe3 in tensorflow::RdmaTensorRequest::RecvTensorContent()::{lambda(tensorflow::Status const&)#2}::operator()(tensorflow::Status const&) const ()\r\n   from /tf1.13/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#4  0x00007fc8ba236688 in tensorflow::GPUUtil::CopyCPUTensorToGPU(tensorflow::Tensor const*, tensorflow::DeviceContext const*, tensorflow::Device*, tensorflow::Tensor*, std::function<void (tensorflow::Status const&)>) () from /tf1.13/lib/python2.7/site-packages/tensorflow/python/../libtensorflow_framework.so\r\n#5  0x00007fc8bc9a9199 in tensorflow::RdmaTensorRequest::RecvTensorContent() ()\r\n   from /tf1.13/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#6  0x00007fc8bc9ab95e in tensorflow::RdmaAdapter::Process_CQ() ()\r\n   from /tf1.13/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#7  0x00007fc8b0545c80 in ?? () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6\r\n#8  0x00007fc91f5ae6ba in start_thread (arg=0x7fc782ffd700) at pthread_create.c:333\r\n#9  0x00007fc91ebd441d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:109\r\n```", "comments": ["Looks like the error is from `tensorflow/contrib/verbs/rdma.cc`.  Unfortunately I'm not familiar with that codebase (and it no longer is in TensorFlow), probably @byronyi (the maintaner) can help?", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34560\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34560\">No</a>\n"]}, {"number": 34559, "title": "Gradient doesn't exist/ becomes None for conv_transpose layers", "body": "**System information**\r\n- Custom code\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS Catalina\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.0\r\n- Python version: 3.6.8\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source):N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**Describe the current behavior**\r\nI get a warning \r\n`WARNING:tensorflow:Gradients do not exist for variables ['mrf__block_2/conv2d_transpose_5/kernel:0', 'mrf__block_2/conv2d_transpose_5/bias:0'] when minimizing the loss.` \r\nwhen trying to backprop loss for a specific layer in my model. The gradients keep turning out to be None regardless of optimizer.\r\n\r\n\r\n**Describe the expected behavior**\r\nThe gradients should exist for these layers.\r\n\r\n\r\n**Code to reproduce the issue**\r\nThis is the model in question:\r\n```\r\nimport tensorflow as tf\r\nimport tensorflow.keras.layers as layers\r\nfrom tensorflow.keras import Model\r\n\r\nclass MRF_Block(Model):\r\n  def __init__(self, out_channels, num_inputs, use_deconv=True, \r\n               kernel_size=(3,3), strides=(1,1), padding='same'):\r\n    super(MRF_Block, self).__init__()\r\n\r\n    # Add the conv/deconv layers.\r\n    for i in range(num_inputs):\r\n      # Convolve input tensors to output tensors of same channel depth (# of channels)\r\n      conv_layer = layers.Conv2D(out_channels, kernel_size, strides=strides, padding=padding)\r\n      setattr(self, f'conv_{i}', conv_layer)\r\n\r\n      # Deconv input tensors. Input tensor at index i will be upsampled by factor 2^(n_inputs - (i+1))\r\n      # Eg: if input tensors are [t1, t2, t3], t1 will be upsampled x 4, t2 upsampled x 2, t3 not upsampled.\r\n      if use_deconv:\r\n        deconv_layer = layers.Conv2DTranspose(out_channels, kernel_size, padding='same',\r\n                                              strides=(2**(num_inputs-(i+1)), 2**(num_inputs-(i+1))))\r\n        setattr(self, f'deconv_{i}', deconv_layer)\r\n\r\n  ## inputs: a list of tensors being inputted to the block.\r\n  def call(self, inputs):\r\n\r\n    # Make #channels the same for input tensors (smallest depth)\r\n    convolved = []\r\n    for i, t in enumerate(inputs):\r\n      conv = getattr(self, f'conv_{i}')\r\n      convolved.append(conv(t))\r\n\r\n    # Upsample to largest (h, w) resolution\r\n    largest_res = max(inputs, key=lambda t: t.shape[1] * t.shape[2])\r\n    resized = []\r\n    for i, t in enumerate(convolved):\r\n      deconv = getattr(self, f'deconv_{i}', lambda t: t)\r\n      up_sampled = deconv(t)\r\n      \r\n      # Use bilinear resizing if resolution of optional conv_transpose doesn't match\r\n      if up_sampled.shape[1:3] != largest_res.shape[1:3]:\r\n        up_sampled = tf.image.resize(t, size=largest_res.shape[1:3])\r\n    \r\n      resized.append(up_sampled)\r\n\r\n    # Fuse by summing\r\n    return sum(resized)\r\n```\r\n\r\nAnd then running this code is what results in the error:\r\n```\r\nt = tf.random.normal((2, 224, 224, 3))\r\noptimizer = tf.keras.optimizers.SGD()\r\n\r\nmrf = MRF_Block(12, 2)\r\nwith tf.GradientTape() as tape: \r\n    preds = mrf([t, t]) \r\n    loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)(tf.random.normal((2, 224, 224, 12)), preds) \r\ngradients = tape.gradient(loss, mrf.trainable_variables)\r\noptimizer.apply_gradients(zip(gradients, mrf.trainable_variables))  \r\n```\r\nChanging SGD() to Adam() yields the same warning. Is it a problem with how the model is defined? Repeatedly running the above code yields the same warning (with/without reinitialising the optimizer).\r\n\r\n**Other info / logs**\r\nNone at the moment.\r\n", "comments": ["@Dieblitzen Can you please provide a minimal reproducible code in colab as I cannot reproduce this issue. Thanks!", "Sure. Here is the link. I have also edited the original code to reflect the additional few lines to make it run.\r\n\r\nhttps://colab.research.google.com/drive/1e8IQIeqOvecb2xu-otMfXMmIgpEDnaKK", "If the gradients are zero, they return null and this is perceived by tape as that the gradients don't exist.\r\nSetting the null gradients to zero should help overcome this problem.\r\n\r\nPlease go through the similar issue [here](https://www.reddit.com/r/tensorflow/comments/bcl5ke/help_with_custom_training_loops_in_tensorflow_20/) and let me know if it helps @Dieblitzen ", "I saw that issue earlier, but I find it odd that no matter how many times I run the code (in the colab link) it always emits that warning. How can the gradients systematically always be zero for those conv_transpose bias and kernel terms, no matter how many times I run it?", "@dieblitzen Please look at my gist where the warning is no longer present [here](https://colab.sandbox.google.com/gist/gowthamkpr/733310a5fe0e35c52ffde2a5e869355a/copy-of-tf2-0_convtranspose_issue.ipynb)", "@gowthamkpr Yes that suppresses the warning, but my question is why are the gradients for those bias/weight terms always 0? Even if I manually set the gradients to 0 using the code you shared, I still find that the gradients are 0 for every run. A gradient of 0 won't update those weights at all. Do you know why this is happening?", "@Dieblitzen Your code has a bug, it should be:\r\n```python\r\nif up_sampled.shape[1:3] != largest_res.shape[1:3]:\r\n        up_sampled = tf.image.resize(up_sampled, size=largest_res.shape[1:3])\r\n```\r\n\r\nnot:\r\n```python\r\nif up_sampled.shape[1:3] != largest_res.shape[1:3]:\r\n        up_sampled = tf.image.resize(t, size=largest_res.shape[1:3])\r\n```"]}, {"number": 34558, "title": "undefined reference to `_imp__TF_Version' when compiling in C", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 x86 Version 10.0.18362.476]\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version: Below 2.0\r\n**GCC:**\r\nCOLLECT_GCC=gcc\r\nCOLLECT_LTO_WRAPPER=c:/mingw/bin/../libexec/gcc/mingw32/8.2.0/lto-wrapper.exe\r\nTarget: mingw32\r\nConfigured with: ../src/gcc-8.2.0/configure --build=x86_64-pc-linux-gnu --host=mingw32 --target=mingw32 --prefix=/mingw --disable-win32-registry --with-arch=i586 --with-tune=generic --enable-languages=c,c++,objc,obj-c++,fortran,ada --with-pkgversion='MinGW.org GCC-8.2.0-3' --with-gmp=/mingw --with-mpfr=/mingw --with-mpc=/mingw --enable-static --enable-shared --enable-threads --with-dwarf2 --disable-sjlj-exceptions --enable-version-specific-runtime-libs --with-libiconv-prefix=/mingw --with-libintl-prefix=/mingw --enable-libstdcxx-debug --with-isl=/mingw --enable-libgomp --disable-libvtv --enable-nls --disable-build-format-warnings\r\nThread model: win32\r\ngcc version 8.2.0 (MinGW.org GCC-8.2.0-3)\r\n\r\n**Describe the problem**\r\nTensorflow functions for C api doesn't work.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nVisited: https://www.tensorflow.org/install/lang_c\r\nDownloaded Binary for Windows (CPU Only): https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow-cpu-windows-x86_64-1.14.0.zip\r\nExtracted zip file into folder.\r\nCopy and Pasted lib files (including the dll file) into C:\\MinGW\\lib \r\nCopy and Pasted include files and folders into C:\\MinGW\\include\r\n\r\nMade new file called \"hello_tf.c\".\r\nCopy and pasted the example program source code from https://www.tensorflow.org/install/lang_c into the file.\r\n\r\nOpened up cmd, went to the file directory and typed:\r\n**gcc hello_tf.c -ltensorflow -o hello_tf.exe && hello_tf.exe**\r\n\r\nOutput:\r\n![image](https://user-images.githubusercontent.com/36951064/69496153-c6f91380-0f1a-11ea-8be0-80786052dfcb.png)\r\n\r\nBasically the same on other functions like TF_DataTypeSize:\r\n![image](https://user-images.githubusercontent.com/36951064/69496162-e8f29600-0f1a-11ea-86a6-a92afa4229a5.png)\r\n\r\nCode: \r\n![image](https://user-images.githubusercontent.com/36951064/69496178-20614280-0f1b-11ea-84cd-ea039b5d1ad1.png)\r\n\r\n\r\n", "comments": ["This issue is still ongoing.", "Update:\r\nThis issue is is present in Linux as well, though except it says \"invaild instruction\", even tested on python. The solution is compiling tensorflow, though I cant be 100% sure because i haven't finished compiling yet, its been 2 days with RAM Usage Issues but dont mind that. If successful with Linux when installed for my CPU I will attempt to try to compile a DLL and lib for Windows and see how it goes.\r\n\r\nI have tried v1.15 for C, havent tested python though it is now expected to not work on my CPU unless I compile.", "What is your CPU make and model?\r\nAll tf binaries require CPUs with AVX instruction sets at the minimum.", "Intel(R) Pentium(R) CPU N4200 @ 1.10GHz, 1101 Mhz, 4 Core(s), 4 Logical Processor(s)\r\n", "Invalid instruction issue is definitely https://github.com/tensorflow/tensorflow/issues/19584\r\nYou will have to build libtensorflow from scratch to be able to use it.\r\n\r\n@bmzhao Could you try to see if the above example works?", "Okay.", "I exactly have the same problem. I also implented the same hello.cpp in Windows with MinGW and came across the same problem. But my CPU is Intel i5-8250u, which has AVX. Can you help me @gunan ", "Use msvc instead of gcc from mingw. As I can understand mingw doesn't support AVX.\r\n```\r\ncl main.c tensorflow.lib -link -LIBPATH:.\r\n```", "Will try later.", "Hello. Does anybody know how to add `cl` to the path? Because it is not recognized as an internal or external command. Thank you very much!\r\n\r\n", "@cciprianmihai you should open Command Prompt for VS in windows start menu.", "@JushBJJ \r\nAs tf version below 2.0 is not actively supported, please upgrade to 2.x and let us know if this is still an issue.", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34558\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34558\">No</a>\n", "> @JushBJJ \n> As tf version below 2.0 is not actively supported, please upgrade to 2.x and let us know if this is still an issue.\n\nI've recently changed computers (intel i5 CPU), and Tensorflow works 2.x works for me. This is no longer an issue. Sorry for late response.", "@JushBJJ\r\nThank you for your update, glad the issue is resolved for you."]}, {"number": 34557, "title": "Failed to load the native TensorFlow runtime", "body": "**System information**\r\n- Windows 10\r\n- pip install tensorflow in Anaconda\r\n- TensorFlow version: 2.0.0\r\n- Python version: 3.6\r\n- Installed using virtualenv? pip? conda?: pip\r\n\r\nWhile trying to load keras.datasets,\r\n\r\nTraceback (most recent call last):\r\n  File \"c:\\users\\chris\\anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"c:\\users\\chris\\anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"c:\\users\\chris\\anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"c:\\users\\chris\\anaconda3\\envs\\ml\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"c:\\users\\chris\\anaconda3\\envs\\ml\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"c:\\users\\chris\\anaconda3\\envs\\ml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-7-d6cb0ef8e627>\", line 15, in <module>\r\n    from keras import datasets\r\n  File \"c:\\users\\chris\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\__init__.py\", line 3, in <module>\r\n    from . import utils\r\n  File \"c:\\users\\chris\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\utils\\__init__.py\", line 6, in <module>\r\n    from . import conv_utils\r\n  File \"c:\\users\\chris\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\utils\\conv_utils.py\", line 9, in <module>\r\n    from .. import backend as K\r\n  File \"c:\\users\\chris\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\backend\\__init__.py\", line 1, in <module>\r\n    from .load_backend import epsilon\r\n  File \"c:\\users\\chris\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\backend\\load_backend.py\", line 90, in <module>\r\n    from .tensorflow_backend import *\r\n  File \"c:\\users\\chris\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 5, in <module>\r\n    import tensorflow as tf\r\n  File \"c:\\users\\chris\\anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\__init__.py\", line 98, in <module>\r\n    from tensorflow_core import *\r\n  File \"c:\\users\\chris\\anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 40, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"c:\\users\\chris\\anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"c:\\users\\chris\\anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"c:\\users\\chris\\anaconda3\\envs\\ml\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"c:\\users\\chris\\anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"c:\\users\\chris\\anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"c:\\users\\chris\\anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"c:\\users\\chris\\anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"c:\\users\\chris\\anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"c:\\users\\chris\\anaconda3\\envs\\ml\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"c:\\users\\chris\\anaconda3\\envs\\ml\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n", "comments": ["Solved by installing tensorflow 1.5 version and keras 2.2 version."]}, {"number": 34556, "title": "tf.keras fit is incompatible with tf.function", "body": "**System information**\r\n- TensorFlow version (use command below): 2.0.0\r\n- Python version: 3.7\r\n\r\n**Describe the current behavior**\r\nI'm not sure if this is a bug or a documentation issue. The [migration guide](https://www.tensorflow.org/guide/migrate#mixed_variables_v1layers) recommends adding the `@tf.function` decorator to the `call` method of subclassed Keras models or layers. However, this causes problems when using the `Layer.add_loss` method with input-dependent losses as described in the [Keras guide](https://www.tensorflow.org/guide/keras/custom_layers_and_models#layers_recursively_collect_losses_created_during_the_forward_pass). In retrospect it makes sense that this doesn't work since `tf.function` requires all outputs to be returned from the function, but this is not made very clear in the docs and the resulting error message is not very helpful.\r\n\r\n**Code to reproduce the issue**\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow.keras import layers\r\n\r\nclass MyModel(tf.keras.Model):\r\n    def __init__(self, num_classes):\r\n        super().__init__()\r\n        self.num_classes = num_classes\r\n        self.dense = layers.Dense(num_classes, activation='sigmoid')\r\n\r\n    @tf.function\r\n    def call(self, inputs):\r\n        self.add_loss(tf.reduce_sum(inputs), inputs=True)\r\n        return self.dense(inputs)\r\n\r\ndata = np.random.random((1000, 32))\r\nlabels = np.random.random((1000, 10))\r\nmodel = MyModel(num_classes=10)\r\nmodel.compile(optimizer=tf.keras.optimizers.RMSprop(0.001),\r\n              loss='categorical_crossentropy')\r\nmodel.fit(data, labels, epochs=50)\r\n```\r\nAnd the resulting error:\r\n```\r\nTypeError: An op outside of the function building code is being passed\r\na \"Graph\" tensor. It is possible to have Graph tensors\r\nleak out of the function building context by including a\r\ntf.init_scope in your function building code.\r\nFor example, the following function will fail:\r\n  @tf.function\r\n  def has_init_scope():\r\n    my_constant = tf.constant(1.)\r\n    with tf.init_scope():\r\n      added = my_constant * 2\r\nThe graph tensor has name: Sum:0\r\n```\r\n\r\n**Expected behavior**\r\nIdeally `add_loss` and `tf.function` would somehow be compatible. This would give me the flexibility to use the model directly by calling it or use the keras `fit` and `predict` functions as I please without hurting performance. Alternatively, at least the `tf.keras` guide should make the incompatibility clear, and perhaps an explicit check should be added to make sure `add_loss` is not called inside a `tf.function`.", "comments": ["The issue reproduces with tf-nightly version 2.1.0-dev20191125.", "Was able to reproduce the issue in TF 2.6.0-dev20210529,please find the gist [here](https://colab.research.google.com/gist/sushreebarsa/7a8c1ce66ad5eb7a990c64829dfcb0d7/untitled87.ipynb)..Thanks !", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34556\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34556\">No</a>\n"]}, {"number": 34555, "title": "ppc64le hang nsync::nsync_mu_semaphore_p_with_deadline", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\ncustom\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n```\r\nuname -a    \r\nLinux 00da561b85b1 4.14.0-115.13.1.el7a.ppc64le #1 SMP Thu Sep 19 14:12:21 UTC 2019 ppc64le ppc64le ppc64le GNU/Linux\r\n```\r\n```\r\ncpu\t\t: POWER9, altivec supported\r\nclock\t\t: 3783.000000MHz\r\nrevision\t: 2.2 (pvr 004e 1202)\r\n\r\ntimebase\t: 512000000\r\nplatform\t: PowerNV\r\nmodel\t\t: 8335-GTH\r\nmachine\t\t: PowerNV 8335-GTH\r\nfirmware\t: OPAL\r\nMMU\t\t: Radix\r\n```\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\nsource compiled with\r\n```\r\nENV PYTHON_BIN_PATH=/usr/bin/python \\\r\n    PYTHON_LIB_PATH=/usr/lib/python2.7/site-packages \\\r\n    TF_NEED_JEMALLOC=1 \\\r\n    TF_NEED_GCP=0 \\\r\n    TF_NEED_HDFS=0 \\\r\n    TF_NEED_AWS=0 \\\r\n    TF_NEED_KAFKA=0 \\\r\n    TF_ENABLE_XLA=0 \\\r\n    TF_NEED_GDR=0 \\\r\n    TF_NEED_VERBS=0 \\\r\n    TF_NEED_NGRAPH=0 \\\r\n    TF_NEED_OPENCL_SYCL=0 \\\r\n    TF_NEED_CUDA=0 \\\r\n    TF_CUDA_CLANG=0 \\\r\n    TF_DOWNLOAD_CLANG=0 \\\r\n    TF_NEED_MPI=0 \\\r\n    GCC_HOST_COMPILER_PATH=gcc \\\r\n    CC_OPT_FLAGS=FROM_OPT \\\r\n    TF_SET_ANDROID_WORKSPACE=0\r\n```\r\n- TensorFlow version (use command below):\r\nhttps://github.com/tensorflow/tensorflow/archive/v1.13.1.tar.gz\r\n- Python version:\r\n2.7\r\n- Bazel version (if compiling from source):\r\nhttps://github.com/bazelbuild/bazel/releases/download/0.19.2/bazel-0.19.2-dist.zip\r\n- GCC/Compiler version (if compiling from source):\r\n```\r\ngcc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-36)\r\n```\r\n- CUDA/cuDNN version:\r\nNone\r\n- GPU model and memory:\r\nTesla V100-SXM2-32GB, but tf is compiled without gpu support\r\n\r\nProcess hangs sometimes. bt is in attachments\r\n[bt.log](https://github.com/tensorflow/tensorflow/files/3883495/bt.log)\r\n \r\n\r\n", "comments": ["@sh1ng,\r\nProvide the exact sequence of commands / steps that you executed before running into the problem. Thanks!", "It's not so easy as it includes a lot of our internal code(python) and we see the issue periodically in the smoke test. ", "@sh1ng, Its hard to analyze the issue without code snippet. Could you write minimum code snippet which generates reported issue. Thanks!"]}, {"number": 34554, "title": "Forward-mode-by-double-backprop fails on tf.square ops", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): colab\r\n- TensorFlow version (use command below): 1.15\r\n- Python version: 3.x\r\n\r\nThe double-backprop trick (https://j-towns.github.io/2017/06/12/A-new-trick.html) for computing jacobian-vector products (JVPs) fails when `tf.square` ops are in the graph. Recall the double-backprop trick constructs an initial throwaway backward graph, which linearly depends on some dummy variables, and then backpropagates through this throwaway graph with respect to the dummy variables. The result should be constant wrt the dummy variables, and the throwaway graph should be disconnected from the final result.\r\n\r\nBelow I've taken the example JVP code from https://github.com/renmengye/tensorflow-forward-ad/issues/2#issue-234418055 and changed `tf.tanh` to `tf.square` to illustrate the failure. The code crashes with an `InvalidArgumentError` because the dummy placeholder created in `fwd_gradients` is not fed a value. The true underlying issue is that the dummy should have disappeared in the second call to `tf.gradients` inside `fwd_gradients` (because `g` is linear in `v`). Presumably the cause is that the backward op for `tf.square` somehow depends nonlinearly on the dummy variables.\r\n\r\n```python\r\n%tensorflow_version 1.x\r\nimport numpy as np\r\nimport numpy.random as npr\r\nimport tensorflow as tf\r\n\r\ndef fwd_gradients(ys, xs, d_xs):\r\n  \"\"\"Forward-mode pushforward analogous to the pullback defined by tf.gradients.\r\n  With tf.gradients, grad_ys is the vector being pulled back, and here d_xs is\r\n  the vector being pushed forward.\"\"\"\r\n  v = tf.placeholder(ys.dtype, shape=ys.get_shape(), name=\"dummy\")\r\n  g = tf.gradients(ys, xs, grad_ys=v)\r\n  return tf.gradients(g, v, grad_ys=d_xs)\r\n\r\nA = tf.constant(npr.randn(5, 3), dtype=tf.float32)\r\nx = tf.placeholder(tf.float32, [1, 5])\r\ny = tf.square(tf.matmul(x, A))\r\nu = tf.placeholder(tf.float32, [1, 5])\r\n\r\njvp = fwd_gradients(y, x, u)\r\n\r\nx_val = npr.randn(1, 5)\r\nu_val = npr.randn(1, 5)\r\n\r\ninit_op = tf.initialize_all_variables()\r\nwith tf.Session() as sess:\r\n  sess.run(init_op)\r\n  print(sess.run(jvp, feed_dict={x: x_val, u: u_val}))\r\n```", "comments": ["Could replicate the issue with TF 1.15.\r\nPlease find the gist [here](https://colab.sandbox.google.com/gist/gadagashwini/4e94cfb813d5d912fddb371cfa67ef63/untitled272.ipynb). Thanks!", "This is expected if a bit ugly. Gradient functions can use `tf.shape` and similar operations on the will-be-pruned placeholders, and Session can't really tell in advance that the value itself isn't necessary since there's enough shape information.\r\n\r\nYou can fill the tensor with NaNs to make sure its value isn't used:\r\n\r\n```\r\ndef fwd_gradients(ys, xs, d_xs):\r\n  \"\"\"Forward-mode pushforward analogous to the pullback defined by tf.gradients.\r\n  With tf.gradients, grad_ys is the vector being pulled back, and here d_xs is\r\n  the vector being pushed forward.\"\"\"\r\n  v = tf.fill(value=float('NaN'), dims=tf.shape(ys))\r\n  g = tf.gradients(ys, xs, grad_ys=v)\r\n  return tf.gradients(g, v, grad_ys=d_xs)\r\n```\r\n\r\nThat works for me. But please do comment/reopen if you still think something's wrong.\r\n\r\nWe do have a [new 2.x API for forward-mode autodiff](https://www.tensorflow.org/versions/r2.1/api_docs/python/tf/autodiff/ForwardAccumulator):\r\n\r\n```\r\nimport numpy as np\r\nimport numpy.random as npr\r\nimport tensorflow as tf\r\n\r\nA = tf.constant(npr.randn(5, 3), dtype=tf.float32)\r\n\r\ndef jvp(x, u):\r\n  with tf.autodiff.ForwardAccumulator(x, u) as acc:\r\n    y = tf.square(tf.matmul(x, A))\r\n  return acc.jvp(y)\r\n\r\nx_val = tf.constant(npr.randn(1, 5), dtype=tf.float32)\r\nu_val = tf.constant(npr.randn(1, 5), dtype=tf.float32)\r\nprint(jvp(x_val, u_val))\r\n```\r\n\r\nIt's implemented with the same double-gradient trick, but runs in a `tf.function` so the pruning works when executed eagerly too. And of course you can wrap `jvp` in `@tf.function` if you don't want to execute it eagerly.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34554\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34554\">No</a>\n", "I know it's a fragile trick and it's sort of a miracle it works at all. The main reason for reporting this issue is because using `x ** 2` instead of `tf.square(x)` works fine, so supposedly the fix would be simple. That said, after continuing to push on my problem I've found out that graphical black boxes like `tf.function` and presumably `tf.while_loop` also break this trick, so it's a dead end.\r\n\r\nI'm happy to see there's forward-mode in eager now! That was my only reason for sticking with graph mode.", "That is a bit of an odd difference between `x**2` and `tf.square(x)` I agree. Likely because of the control dependency here: https://github.com/tensorflow/tensorflow/blob/d1265d5e7897898b30b53f9337d0fc7c64d87258/tensorflow/python/ops/math_grad.py#L583\r\n\r\nBut like I say, even if we changed that gradient there will be others that run operations on the gradients to get their size and such. I don't think placeholders will work, but using NaNs should be pretty robust.", "Well, filling with NaNs gives me NaNs in the output (in my real graph, not in this MWE). Generally I could fill with any value such as ones to get the correct result. However this hides the fact that the intermediate graph is not thrown away. It is kept around and actually computed, which roughly doubles the time/space/graph complexity of the whole operation. Just a word of warning for people finding this thread in the future.", "Even if the original NaN tensor is referenced for a shape or control dependency, the first tf.gradient call can still be pruned out. I expect that would actually be fine, although inspecting the optimized graph would be the way to tell for sure.\r\n\r\nHaving the NaN show up in the computation itself does sound bad. If you can isolate that I'd be interested. The MWE does seem to work fine."]}, {"number": 34553, "title": "numpy.dot and tensorflow.tensordot can't be used together in MacBook", "body": "Hi, \r\n\r\nI was using tensorflow (2.0.0) and numpy (1.7.3) on my MacBook (with Python 3.7.5), but it failed to use both `numpy.dot` (or `numpy.tensordot`) and `tensorflow.tensordot` in one jupyter notebook (no error reported but never finish), though any of them alone works properly.\r\n\r\nI have tried the same codes on Linux with the same conda environment, and there is no such issue.\r\n\r\nCodes I tested:\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\nNd, Nk, Ns = 3, 2, 5\r\nw_np = np.ones([Nd, Nk], dtype=np.float32)\r\nz_np = np.ones([Nk, Ns], dtype=np.float32)\r\n```\r\n\r\nOnly one the the following two works on MacBook:\r\n```\r\ntf.tensordot(w_np, z_np, axes=1)\r\n```\r\n\r\nOr\r\n\r\n```\r\nnp.tensordot(w_np, z_np, axes=1) # or np.dot(w_np, z_np)\r\n```", "comments": ["I have tried on colab with TF version 2.0 in Linux and i am not seeing any issue. Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/9fafbfb43166245d6ebc0e5b28b2106c/untitled399.ipynb).Thanks!", "Thanks for testing this. Yes, it works in Linux for myself too, but not in MacBook.\r\n\r\nYuanhua", "When I tested again in teminal instead of ipython notebook, the session has been closed with following log:\r\n\r\n```\r\nOMP: Error #15: Initializing libiomp5.dylib, but found libiomp5.dylib already initialized.\r\nOMP: Hint This means that multiple copies of the OpenMP runtime have been linked into the program. That is dangerous, since it can degrade performance or cause incorrect results. The best thing to do is to ensure that only a single OpenMP runtime is linked into the process, e.g. by avoiding static linking of the OpenMP runtime in any library. As an unsafe, unsupported, undocumented workaround you can set the environment variable KMP_DUPLICATE_LIB_OK=TRUE to allow the program to continue to execute, but that may cause crashes or silently produce incorrect results. For more information, please see http://www.intel.com/software/products/support/.\r\n```\r\n\r\nAs suggested in the log, adding the following lines before running the code can avoid the issue.\r\n```\r\nimport os\r\nos.environ['KMP_DUPLICATE_LIB_OK']='True'\r\n```\r\nAlso see here: https://github.com/dmlc/xgboost/issues/1715#issuecomment-420305786\r\n\r\nYuanhua", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34553\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34553\">No</a>\n"]}, {"number": 34552, "title": "Tensorflow 2.0  build fail in Windows 10", "body": "### Environment\r\nWindows 10\r\ngtx 1050Ti\r\nCUDA driver 441\r\nCUDA tool kit 10.0\r\nCuDNN 7\r\nPython 3.5\r\nBazel 0.27.1\r\n\r\n### Action\r\nfollow the official instruction. https://www.tensorflow.org/install/source_windows\r\n\r\nrun :\r\n`C:\\Users\\admin\\tensorflow>bazel build //tensorflow/tools/pip_package:build_pip_package`\r\n### ERROR INFO\r\n\r\n> **ERROR: An error occurred during the fetch of repository 'local_config_cuda':**\r\n   Traceback (most recent call last):\r\n        File \"C:/users/admin/tensorflow/third_party/gpus/cuda_configure.bzl\", line 1304\r\n                _create_local_cuda_repository(repository_ctx)\r\n        File \"C:/users/admin/tensorflow/third_party/gpus/cuda_configure.bzl\", line 1132, in _create_local_cuda_repository\r\n                find_cc(repository_ctx)\r\n        File \"C:/users/admin/tensorflow/third_party/gpus/cuda_configure.bzl\", line 227, in find_cc\r\n                _get_msvc_compiler(repository_ctx)\r\n        File \"C:/users/admin/tensorflow/third_party/gpus/cuda_configure.bzl\", line 145, in _get_msvc_compiler\r\n                find_msvc_tool(repository_ctx, vc_path, \"cl.exe\").replace(\"\\\\\", \"/\")\r\ntype 'NoneType' has no method replace()\r\n**ERROR: Skipping '//tensorflow/tools/pip_package:build_pip_package': error loading package 'tensorflow/tools/pip_package': Encountered error while reading extension file 'cuda/build_defs.bzl': no such package '@local_config_cuda//cuda':** Traceback (most recent call last):\r\n        File \"C:/users/admin/tensorflow/third_party/gpus/cuda_configure.bzl\", line 1304\r\n                _create_local_cuda_repository(repository_ctx)\r\n        File \"C:/users/admin/tensorflow/third_party/gpus/cuda_configure.bzl\", line 1132, in _create_local_cuda_repository\r\n                find_cc(repository_ctx)\r\n        File \"C:/users/admin/tensorflow/third_party/gpus/cuda_configure.bzl\", line 227, in find_cc\r\n                _get_msvc_compiler(repository_ctx)\r\n        File \"C:/users/admin/tensorflow/third_party/gpus/cuda_configure.bzl\", line 145, in _get_msvc_compiler\r\n                find_msvc_tool(repository_ctx, vc_path, \"cl.exe\").replace(\"\\\\\", \"/\")\r\ntype 'NoneType' has no method replace()\r\nWARNING: Target pattern parsing failed.\r\n**ERROR: error loading package 'tensorflow/tools/pip_package': Encountered error while reading extension file 'cuda/build_defs.bzl': no such package '@local_config_cuda//cuda':** Traceback (most recent call last):\r\n        File \"C:/users/admin/tensorflow/third_party/gpus/cuda_configure.bzl\", line 1304\r\n                _create_local_cuda_repository(repository_ctx)\r\n        File \"C:/users/admin/tensorflow/third_party/gpus/cuda_configure.bzl\", line 1132, in _create_local_cuda_repository\r\n                find_cc(repository_ctx)\r\n        File \"C:/users/admin/tensorflow/third_party/gpus/cuda_configure.bzl\", line 227, in find_cc\r\n                _get_msvc_compiler(repository_ctx)\r\n        File \"C:/users/admin/tensorflow/third_party/gpus/cuda_configure.bzl\", line 145, in _get_msvc_compiler\r\n                find_msvc_tool(repository_ctx, vc_path, \"cl.exe\").replace(\"\\\\\", \"/\")\r\ntype 'NoneType' has no method replace()\r\nINFO: Elapsed time: 31.315s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (0 packages loaded)\r\n    currently loading: tensorflow/tools/pip_package\r\n\r\nHope for your help", "comments": ["@googincheng \r\nI think the problem is with Bazel and MSVC.Please, go through the [link](https://docs.bazel.build/versions/0.27.0/install-compile-source.html#bootstrap-windows-bootstrapp) and see if it helps you.Please, check whether you set the environment variable BAZEL_VS (or BAZEL_VC) correctly. Thanks!", "@ravikyram Thanks! Seems it would work. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34552\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34552\">No</a>\n"]}, {"number": 34551, "title": "Bound method <Conv.call> could not be transformed", "body": "Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f2557c76048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f2557c76048>>: AssertionError: Bad argument number for Name: 3, expecting 4 ", "comments": ["Not sure what the bug is exactly. But installing installing gast 0.2.2 version fixed it.\r\n\r\npip install --user gast==0.2.2", "Pack node (map_1/while/stack) axis attribute is out of bounds: 0                               2019-11-24 21:22:04.734195: W ./tensorflow/core/grappler/optimizers/graph_optimizer_stage.h:241] Failed to run optimizer ArithmeticOptimizer, stage RemoveStackStridedSliceSameAxis node map_1/while/ChangeCoordinateFrame/strided_slice_2. Error: Pack node (map_1/while/stack) axis attribute is out of bounds: 0 ", "now i am getting this above error when i am evaluating this model", "Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\nMake sure you also include the exact command if possible to produce the output included in your test case. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!\r\n", "actually i am using  centos 3.10.0-693.el7.x86_64  and tensorflow version is 1.13.1 yes,\r\n\r\n okay and i am using CUDA 10.0 and GPU Version is Quadro P4000 with 8GB RAM\r\n", "Will it be possible to provide minimal standalone code to reproduce the issue in our environment. It helps us in localizing the issue faster. Thanks!", "actually i am using ssdssd_mobilenet_v2_oid_v4.config  arch to train model rest of i ma using eval.py to evaluate my model.\r\nthat is already available inside tensorflow directory module", "when evaluating my model it is producing that error?", "As mentioned in the comment [here](https://github.com/tensorflow/tensorflow/issues/29052#issuecomment-504946289), this should be fixed in Tensorflow 1.14. Can you try using Tensorflow 1.14 and see if the error still persists. Thanks!", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Closing this issue as it has been inactive for more than 2 weeks. Please add additional comments and we can open the issue again. Thanks!", "I encounted this problem everytime(more than 3 times) I try to re-install tf v1.13, v1.14, so I wrote down this memo for myself and other people.\r\n\r\nI guess that the reason of this problem is gast==0.3.3 and its mismatch with  tf 1.13 and 1.14.\r\n```\r\n$pip install tensorflow-gpu==1.14\r\n...\r\nCollecting gast>=0.2.0\r\n  Using cached gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\r\n```\r\nThis should be gast-0.2.2 for tf 1.13 and tf 1.14\r\ngast-0.3.3 >= 0.2.0\r\nBut gast-0.3.3 is obvioursly incompatible with tf1.13 and tf1.14\r\n\r\nSo the solution is as darsh8200 commented above.\r\n$pip install gast==0.2.2\r\n\r\n* Test environment\r\nCentOS Linux release 7.5.1804 (Core)\r\ntensorflow_gpu-1.14.0-cp27-cp27mu-manylinux1_x86_64.whl\r\ntensorflow_gpu-1.14.0-cp36-cp36mu-manylinux1_x86_64.whl\r\nvirtualenv with pip\r\n"]}, {"number": 34550, "title": "Cannot install tensorflow on raspberry pi-0, raspbian buster", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Raspbian Buster\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Raspberry Pi-0\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version:1.14.0, 1.13.0\r\n- Python version: 3.7.3\r\n- Installed using virtualenv? pip? conda?: virtualenv and pip3\r\n- Bazel version (if compiling from source): NA\r\n- GCC/Compiler version (if compiling from source): NA\r\n- CUDA/cuDNN version: NA\r\n- GPU model and memory: NA\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nI tried to perform steps given here: https://www.tensorflow.org/install/pip?lang=python3\r\nfor full tf install using binary\r\n\r\nlast command to install tensorflow being \r\npip3 install https://storage.googleapis.com/tensorflow/raspberrypi/tensorflow-1.14.0-cp34-none-linux_armv6l.whl\r\n\r\n**Any other info / logs**\r\nI get the following error\r\nERROR: tensorflow-1.14.0-cp34-none-linux_armv6l.whl is not a supported wheel on this platform.\r\n\r\nIf I just do pip3 install --no-cache-dir tensorflow (rpi-0 memory is too small) I get,\r\n\r\nERROR: THESE PACKAGES DO NOT MATCH THE HASHES FROM THE REQUIREMENTS FILE. If you                                                                                                                                                              have updated the package versions, please update the hashes. Otherwise, examine                                                                                                                                                              the package contents carefully; someone may have tampered with them.\r\n    tensorflow from https://www.piwheels.org/simple/tensorflow/tensorflow-1.13.1                                                                                                                                                             -cp37-none-linux_armv6l.whl#sha256=25f4ff027beec1e568baf8e90a07bad59d354560533d6                                                                                                                                                             b37318b9efeb70beeb1:\r\n        Expected sha256 25f4ff027beec1e568baf8e90a07bad59d354560533d6b37318b9efe                                                                                                                                                             b70beeb1\r\n             Got        3aad2c162168a62adae30e226bcddfef74e5db1ca98bec1383958fb5                                                                                                                                                             80e67123\r\n\r\n\r\n\r\n\r\n", "comments": ["@sidwa ,\r\nCan you please refer the [link](https://github.com/MycroftAI/mycroft-precise/issues/79#issuecomment-532723758) of similar issue and let us know if it helped ?Thanks!", "pipenv doesn't seem to work adding sudo to those commands don't help either", "Currently I can install tensorflow using, \"pip3 --no-cache-dir install tensorflow\" there is no hash mismatch anymore.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34550\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34550\">No</a>\n", "still has the error when i used \"pip3 --no-cache-dir install tensorflow\" \r\n"]}, {"number": 34549, "title": "Dynamic assignment of tensor elements fails in custom layer", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\nI'm not an expert but after a week of research, I would like to know your opinion. \r\n\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution : Linux Ubuntu 18\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): S\r\n- TensorFlow version (use command below): 2.0\r\n- Python version: 3.6.8\r\n- CUDA/cuDNN version:10.0\r\n- GPU model and memory:  GeForce RTX 2060\r\n\r\n**Describe the current behavior**\r\nIt seems that I can't build a graph in which I assign dynamically some specific values in some specific positions of the filters during the training phase. However I'm not an expert on TF2.0 maybe I didn't understand the new usage of the hidden placeholders, or some operations do not respect the symbolic programming. \r\n\r\nValueError: tf.function-decorated function tried to create variables on non-first call.\r\n\r\n**Describe the expected behavior**\r\nWith the script below my idea is to understand how I can modify, with a customized layer, the value of the tensors of a network being trained. \r\nI would like to model this behaviour with static and dynamic assignments. \r\nIt seems that I succeeded by assigning constant values see the function *assign_op*, \r\nwhile if I use the symbolic values \u200b\u200bof the tensor to modify the same values of the tensor\r\n\u200b\u200bI cannot understand what is wrong. I make several tests but fail, in particular, with atomic assignments. Where for atomic assignments I mean single value tensor assignments. \r\n\r\n**Code to reproduce the issue**\r\nHere I provide a reproducible test case. The problem is in the function: assign_dyn_vals() once I instantiate a variable and I try to assign to this variable some computations. \r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow.compat.v1 import ConfigProto\r\nfrom tensorflow.compat.v1 import InteractiveSession\r\nconfig = ConfigProto()\r\nconfig.gpu_options.allow_growth = True\r\nsession = InteractiveSession(config=config)\r\n\r\nimport keras\r\nfrom keras.models import Sequential\r\nfrom keras.datasets import mnist\r\nfrom keras import layers\r\nfrom keras import backend as K\r\nfrom keras.layers import Dense, Dropout, Flatten, Lambda\r\nfrom keras.layers import Conv2D\r\n\r\n\r\nbatch_size = 128\r\nnum_classes = 10\r\nepochs = 12\r\n# input image dimensions\r\nimg_rows, img_cols = 28, 28\r\n\r\n\r\ndef create_model():\r\n    model = Sequential()\r\n    model.add(Conv2D(32, kernel_size=(3, 3),\r\n                     activation='relu',\r\n                     input_shape=input_shape))\r\n    model.add(Conv2D(2, (3, 3), activation='relu'))\r\n    model.add(CustomLayer())\r\n    model.add(Conv2D(1, (3, 3), activation='relu'))\r\n    model.add(Dropout(0.25))\r\n    model.add(Flatten())\r\n    model.add(Dense(128, activation='relu'))\r\n    model.add(Dropout(0.5))\r\n    model.add(Dense(num_classes, activation='softmax'))\r\n    return model\r\n\r\ndef ith_element(x, i, j, n_chan):\r\n    return tf.reshape( x[i:i + 1, j:j + 1, n_chan ], (-1,))\r\n\r\n#A sort of dynamic assignment\r\ndef assign_dyn_vals( x, h, w, n_chan, T=0.5):\r\n    row = 1\r\n    col = 1\r\n    sel_chan = 1\r\n    out_val0 = ith_element(x, row, col, sel_chan)*T\r\n    out_val1 = ith_element(x, row, col, sel_chan)*T\r\n    x1 = tf.Variable(tf.zeros([h,w,n_chan], tf.float32)) ###???????????????\r\n    #x1=tf.identity(x) #obviously with this works...\r\n    x1 = x1[1:2,1:2, sel_chan].assign(tf.math.accumulate_n([out_val0, out_val1 ], name=\"value_to_assign\")) ###???????????????\r\n    return(x1)\r\n\r\n\r\n@tf.function\r\n#Static assignment\r\ndef assign_op(x, up_val, cord_i, cord_j, n_chan):\r\n    updates = tf.constant([up_val])\r\n    indices = tf.constant([[-1, cord_i, cord_j, n_chan]])\r\n    updated = tf.tensor_scatter_nd_update(x, indices, updates)\r\n    return(updated)\r\n\r\n@tf.function\r\ndef out_res(x):\r\n    dim = x.shape\r\n    h = dim[1]\r\n    w = dim[2]\r\n    n_chan = dim[3]\r\n\r\n    #Dynamic assignment on a tensor with some modifications ???????????????\r\n    copy_img = tf.identity(x)\r\n    thresh_img= assign_dyn_vals(copy_img, h, w, n_chan, 0.5)\r\n\r\n    #Static assignment.\r\n    up_val =  17.0\r\n    thresh_img = assign_op(thresh_img, up_val, 0, 2, 1)\r\n    return thresh_img\r\n\r\n@tf.custom_gradient\r\ndef custom_op(x):\r\n    result = out_res(x) # do forward computation\r\n    def custom_grad(dy):\r\n        print(dy, [dy])\r\n        grad = dy # compute gradient\r\n        return grad\r\n    return result, custom_grad\r\n\r\nclass CustomLayer(layers.Layer):\r\n    def __init__(self):\r\n        super(CustomLayer, self).__init__()\r\n\r\n    def call(self, x):\r\n        return custom_op(x)\r\n\r\n# the data, split between train and test sets\r\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\r\n\r\nif K.image_data_format() == 'channels_first':\r\n    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\r\n    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\r\n    input_shape = (1, img_rows, img_cols)\r\nelse:\r\n    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\r\n    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\r\n    input_shape = (img_rows, img_cols, 1)\r\n\r\nx_train = x_train.astype('float32')\r\nprint(x_train.shape)\r\nx_test = x_test.astype('float32')\r\nx_train /= 255\r\nx_test /= 255\r\nprint('x_train shape:', x_train.shape)\r\nprint(x_train.shape[0], 'train samples')\r\nprint(x_test.shape[0], 'test samples')\r\n\r\n# convert class vectors to binary class matrices\r\ny_train = keras.utils.to_categorical(y_train, num_classes)\r\ny_test = keras.utils.to_categorical(y_test, num_classes)\r\n# build the model\r\n\r\nmodel = create_model()\r\n# compile the model\r\n\r\nmodel.compile(loss=keras.losses.categorical_crossentropy,\r\n              optimizer=keras.optimizers.Adadelta(),\r\n              metrics=['accuracy'])\r\n# train the model\r\nmodel.summary()\r\n\r\nmodel.fit(x_train, y_train,\r\n          batch_size=batch_size,\r\n          epochs=epochs,\r\n          verbose=1,\r\n          validation_data=(x_test, y_test))\r\n```\r\n\r\n\r\n", "comments": ["@lodeguns, I tried reproducing the issue but got different error. Please try to use tf.keras with Tensorflow 2.0 instead of Keras. Please take a look at gist [here](https://colab.sandbox.google.com/gist/gadagashwini/15d77607eacd466cac64cdeea1e62062/untitled271.ipynb). Thanks! ", "Hi Francesco,\r\nYour attempt to create a custom layer looks very ingenious. I have tried to reproduce the issue and i sent you in private the code that works correctly.\r\nFeel free to post the solution, because the documentation on that is very lack and the right versioning in order to get a result is mandatory. \r\nCheers", "Ciao Mattia @MDP-DL-UNISA ,  yes the problem was in the versioning as checked by @gadagashwini and also because of some wrong indices. \r\nSure, this code is a good starting point to write custom layers. \r\nWe don't know why _tf.math.accumulate_n_ doesn't work, instead _tf.math.add_n_ works. Maybe, we should check better the documentation. \r\nHowever, I downgraded Keras from _2.3.1_ to _2.3.0_, don't ask me why but now it works. \r\n\r\nThank you, guys! \r\n\r\nAttached the code:\r\n\r\n```python\r\n\r\nimport tensorflow as tf\r\nfrom tensorflow.compat.v1 import ConfigProto\r\nfrom tensorflow.compat.v1 import InteractiveSession\r\nconfig = ConfigProto()\r\nconfig.gpu_options.allow_growth = True\r\nsession = InteractiveSession(config=config)\r\n\r\nimport keras\r\nfrom keras.models import Sequential\r\nfrom keras.datasets import mnist\r\nfrom keras import layers\r\nfrom tensorflow.keras import backend as K\r\nfrom keras.layers import Dense, Dropout, Flatten, Lambda\r\nfrom keras.layers import Conv2D\r\n\r\nbatch_size = 128\r\nnum_classes = 10\r\nepochs = 12\r\n# input image dimensions\r\nimg_rows, img_cols = 28, 28\r\n\r\n\r\ndef create_model():\r\n    model = Sequential()\r\n    model.add(Conv2D(32, kernel_size=(3, 3),\r\n                     activation='relu',\r\n                     input_shape=input_shape))\r\n    model.add(Conv2D(2, (3, 3), activation='relu'))\r\n    model.add(CustomLayer())\r\n    model.add(Conv2D(1, (3, 3), activation='relu'))\r\n    model.add(Dropout(0.25))\r\n    model.add(Flatten())\r\n    model.add(Dense(128, activation='relu'))\r\n    model.add(Dropout(0.5))\r\n    model.add(Dense(num_classes, activation='softmax'))\r\n    return model\r\n\r\n#extract the i-th element from the tensor\r\ndef ith_element(x, i, j, n_chan):\r\n    return tf.reshape( x[0, i:i + 1, j:j + 1, n_chan ], (-1,))\r\n\r\n@tf.function\r\ndef dyn_assignment(z, row, col, sel_chan, T ):\r\n    # some operatiions\r\n    out_val0 = ith_element(z, row, col, sel_chan)*T\r\n    out_val1 = ith_element(z, row, col, sel_chan)*T\r\n    value_to_assign = tf.math.add_n([out_val0, out_val1, out_val1])\r\n    z = assign_op_tensor(z, value_to_assign, row, col, sel_chan)\r\n    return z\r\n\r\n@tf.function\r\ndef static_assignment(x, row, col, sel_chan, T):\r\n    up_val =  tf.constant([T], dtype=tf.float32)\r\n    z = assign_op_tensor(x, up_val, row, col, sel_chan)\r\n    return z\r\n\r\n@tf.function\r\ndef assign_op_tensor(x, updates, cord_i, cord_j, n_chan):\r\n    indices = tf.constant([[0, cord_i, cord_j, n_chan]])\r\n    updated = tf.tensor_scatter_nd_update(x, indices, updates)\r\n    return(updated)\r\n\r\n@tf.function\r\ndef out_res(x):\r\n    dim = x.shape\r\n    h = dim[1]\r\n    w = dim[2]\r\n    n_chan = dim[3]\r\n    row = 6\r\n    col = 6\r\n    sel_chan = 1\r\n    z = tf.identity(x)\r\n    z = dyn_assignment(z, row, col, sel_chan,  1/3)\r\n    z = static_assignment(z, row, col, sel_chan, 1.)\r\n    return z\r\n\r\n@tf.custom_gradient\r\ndef custom_op(x):\r\n    result = out_res(x) # do forward computation\r\n    def custom_grad(dy):\r\n        print(dy, [dy])\r\n        grad = dy # compute gradient\r\n        return grad\r\n    return result, custom_grad\r\n\r\nclass CustomLayer(layers.Layer):\r\n    def __init__(self):\r\n        super(CustomLayer, self).__init__()\r\n\r\n    def call(self, x):\r\n        return custom_op(x)\r\n\r\n# the data, split between train and test sets\r\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\r\n\r\nif K.image_data_format() == 'channels_first':\r\n    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\r\n    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\r\n    input_shape = (1, img_rows, img_cols)\r\nelse:\r\n    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\r\n    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\r\n    input_shape = (img_rows, img_cols, 1)\r\n\r\nx_train = x_train.astype('float32')\r\nprint(x_train.shape)\r\nx_test = x_test.astype('float32')\r\nx_train /= 255\r\nx_test /= 255\r\nprint('x_train shape:', x_train.shape)\r\nprint(x_train.shape[0], 'train samples')\r\nprint(x_test.shape[0], 'test samples')\r\n\r\n# convert class vectors to binary class matrices\r\ny_train = keras.utils.to_categorical(y_train, num_classes)\r\ny_test = keras.utils.to_categorical(y_test, num_classes)\r\n# build the model\r\n\r\nmodel = create_model()\r\n# compile the model\r\n\r\nmodel.compile(loss=keras.losses.categorical_crossentropy,\r\n              optimizer=keras.optimizers.Adadelta(),\r\n              metrics=['accuracy'])\r\n# train the model\r\nmodel.summary()\r\n\r\nmodel.fit(x_train, y_train,\r\n          batch_size=batch_size,\r\n          epochs=epochs,\r\n          verbose=1,\r\n          validation_data=(x_test, y_test))\r\n\r\n```\r\n\r\n\r\n\r\n\r\n\r\n", "Hi Francesco,\r\ni'm wondering about back propagation when we add a Custom Layer inside a Keras model. \r\nMy question is about the custom gradient function. As i understand, your function backpropagate gradients coming from next layer. But a custom layer modifies the output, so the gradients computation is mandatory, i guess. Next i will post a code example for custom gradient function:\r\n```\r\n@tf.custom_gradient\r\ndef custom_op(x):\r\n    result = out_res(x) # do forward computation\r\n    def custom_grad(dy):\r\n        grads = tf.gradients(result, x)\r\n        #grad = dy # compute gradient\r\n        return grads\r\n    return result, custom_grad\r\n```\r\n\r\nIn that function i used tf.gradients, in order to compute the gradients between outputs and inputs. \r\nI don't know if this trial is good or not, so i hope that this community can help us understanding the right code for backpropagate gradients. If you add this modification at your custom_grad function, the training does not converge (loss stucks at about 2).\r\nCheers\r\n"]}, {"number": 34548, "title": "Does TFLite (Python API) require Tensorflow installed (RISCV64 porting)", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux from Buildroot 2019.08.2\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: RISCV64 Ariane core\r\n- TensorFlow installed from (source or binary): TF non installed, TFLite installed\r\n- TensorFlow version: 2.0.0\r\n- Python version: Python 3.7.5\r\n- Installed using virtualenv? pip? conda?: I cross-compiled a wheel after I adapted the instructions as https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/tools/pip_package\r\n- Bazel version (if compiling from source): none\r\n- GCC/Compiler version (if compiling from source): GCC 7.4.0 (Ubuntu)\r\n- CUDA/cuDNN version: none\r\n- GPU model and memory: none\r\n\r\n**Describe the problem**\r\n\r\nI have Python 3, NumPy and PyPi running on Ariane (RISCV64, https://github.com/pulp-platform/ariane). The CPU and system run on FPGA (emulated).\r\n\r\nI assumed that to run the TFLite Python interpreter, I needed just a wheel of the `tflite_runtime` that I crosscompiled (`tflite_runtime-2.0.0-cp37-cp37m-linux_riscv64.whl`).\r\n\r\nAfter I installed the `tflite_runtime` wheel, I tried the following:\r\n```\r\n# echo \"import tflite_runtime.interpreter as tflite\" > test.py\r\n# python test.py\r\n```\r\n\r\nThis gives the following error:\r\n```\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 27, in <module>\r\n    from tensorflow.python.util.lazy_loader import LazyLoader\r\nModuleNotFoundError: No module named 'tensorflow'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python3.7/site-packages/tflite_runtime/interpreter_wrapper.py\", line 14, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"/usr/lib/python3.7/importlib/__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 670, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 583, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 1015, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\nImportError: /usr/lib/python3.7/site-packages/tflite_runtime/_interpreter_wrapper.so: undefined symbol: shm_open\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 1, in <module>\r\n    import tflite_runtime.interpreter as tflite\r\n  File \"/usr/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 44, in <module>\r\n    from tflite_runtime import interpreter_wrapper as _interpreter_wrapper\r\n  File \"/usr/lib/python3.7/site-packages/tflite_runtime/interpreter_wrapper.py\", line 17, in <module>\r\n    _interpreter_wrapper = swig_import_helper()\r\n  File \"/usr/lib/python3.7/site-packages/tflite_runtime/interpreter_wrapper.py\", line 16, in swig_import_helper\r\n    return importlib.import_module('_interpreter_wrapper')\r\n  File \"/usr/lib/python3.7/importlib/__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nModuleNotFoundError: No module named '_interpreter_wrapper'\r\n```\r\n\r\nDo I need a wheel of Tensorflow as well? Is there a way to provide the `LazyLoader` without cross-compiling the entire Tensorflow for RISCV64?\r\n", "comments": []}, {"number": 34547, "title": "AttributeError: module 'tensorflow' has no attribute 'data'", "body": "**System information**\r\n- OS Platform and Distribution :Linux Ubuntu 18.0.4\r\n- TensorFlow installed from (source or binary): anaconda3\r\n- TensorFlow version (use command below):2.0.0\r\n- Python version:3.6.9\r\n- CUDA/cuDNN version:10.1\r\n- GPU model and memory:GTX2070 8GB\r\n\r\n**Code to reproduce the issue**\r\n``` python\r\nfrom net.baseline import Baseline\r\nfrom tensorflow import keras\r\nimport tensorflow as tf\r\nfrom data.dataset import MSRA\r\n\r\ntrain_data = tf.data.Dataset.from_tensor_slices((images, labels))\r\ntrain_data = train_data.apply(tf.data.experimental.shuffle_and_repeat(buffer_size=len(images)))\r\ntrain_data = train_data.map(dataset.load_and_preprocess_data)\r\ntrain_data = train_data.batch(BATCH_SIZE)\r\n```\r\n\r\n**info / logs**\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/lxz/PycharmProjects/PoseREN_tf2/src/train_baseline.py\", line 26, in <module>\r\n    train_data = tf.data.Dataset.from_tensor_slices((images, labels))\r\nAttributeError: module 'tensorflow' has no attribute 'data'\r\n```", "comments": ["@lxz1104 ,\r\nHi, in the given code `from data.dataset import MSRA` its not a tensorflow dataset import. Can you please check the line. Rest of the code when tried executing worked fine without any issues.\r\n`from tensorflow import data `can be used.\r\nKindly find the [gist](https://colab.sandbox.google.com/gist/oanush/dd1b6136a323001d662a593f0cdb5783/untitled269.ipynb) of colab.\r\nFor more information on the syntax of tf.data, kindly refer the [link](https://github.com/tensorflow/tensorflow/issues/33654#issuecomment-546414347).", "I have fixed this problem by change `import` to this:\r\n``` python\r\nimport tensorflow as tf\r\nfrom net.baseline import Baseline\r\nfrom tensorflow import keras\r\nfrom data.dataset import MSRA\r\nfrom tensorflow_core.python.keras.callbacks import EarlyStopping\r\n```", "Closing since the issue is resolved,Thanks!"]}, {"number": 34546, "title": "fix: functools32 srcs_version to PY2 only", "body": "On Ubuntu 19.10, when locking dependencies using pipenv for a python3.7 project, pipenv detects functools32 as a required dependency and fails installing it. This should not happen for Python >= 3. Specified the srcs_version of the functools32 py_library to PY2.\r\nAside from this change, maybe the py_library of special_math_ops under /tensorflow/python/BUILD also needs to be changed as it explicitly lists functools32 as a dependency, which might cause pipenv to want to install it.", "comments": ["Updated to PY2ONLY due to failing unit tests", "@Janssena Could you please check failed build errors? Thanks!", "@gbaned I'll look into those tonight, likely have to make some more changes to the sub-dependencies of special_math_ops", "I found out that the issue is related to the linux wheels being used by pipenv and other package managers (see https://github.com/tensorflow/tensorflow/issues/31767#issuecomment-522786795). It thus seems that pipenv will try to install tensorflow as a python2.7 package so changing the srcs_version will not solve the issue. I will therefore close this PR, as the fix is in the current pipenv master so will be released soon. There also is a workaround by running the pip command to install it using the correct wheel: `pipenv run pip install tensorflow`.\r\nThank you for your time all."]}, {"number": 34545, "title": "fix: set srcs_version to PY2", "body": "When creating lock file using pipenv on Python3 (Ubuntu 19.10), locking fails because functools32 is added to the list of dependencies. This PR sets the py_library srcs_versions config for functools32 correctly to PY2. Wondering if also changes need to be made to the _special_math_ops_ py_library under tensorflow/python/BUILD (it also explicitly mentions functools32 as a dep, which might cause pipenv to want to install it)", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F34545) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F34545) for more info**.\n\n<!-- need_author_cla -->"]}]