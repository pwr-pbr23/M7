[{"number": 46364, "title": "add support for concatenated gzip in ZlibInputStream", "body": "This PR will fix #45137.\r\n\r\nTo support concatenated gzip, we need to call `inflateReset()` when `inflate()` returns `Z_STREAM_END`, as the zlib's doc explained:\r\n> Unlike the gunzip utility and gzread() (see below), inflate() will not automatically decode concatenated gzip streams. inflate() will return Z_STREAM_END at the end of the gzip stream. The state would need to be reset to continue decoding a subsequent gzip stream.\r\n\r\nfrom https://github.com/madler/zlib/blob/cacf7f1d4e3d44d871b605da3b647f07d718623f/zlib.h#L868\r\n\r\nThank you for your time on reviewing this pr.", "comments": []}, {"number": 46363, "title": "Kernel Silently dies while Generating an Image", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 Pro\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below):2.5.0-dev20210111\r\n- Python version: 3.8.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 11.1 ,8.0.5\r\n- GPU model and memory: RTX 3070 8GB\r\n\r\n**Describe the current behavior**\r\nThe Kernel silently dies when it tried to generate the image made via the generator.\r\n\r\n**Describe the expected behavior**\r\nShould generate the image and continue the code\r\n\r\n**Standalone code to reproduce the issue**\r\n[Using the example here on the Tensorflow site for GANs](https://www.tensorflow.org/tutorials/generative/dcgan)\r\nWhile executing it till we generate the image via the untrained generator. The notebook just stops, looking at the logs shows that the kernel then gets restarted.\r\n\r\n**Other info / logs**\r\n```\r\n[I 2021-01-12 16:02:30.618 ServerApp] Kernel started: 0227f971-d1fe-44a3-8db7-a948217de0bb\r\n2021-01-12 16:02:51.057848: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\r\n2021-01-12 16:02:54.205477: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library nvcuda.dll\r\n2021-01-12 16:02:54.226746: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1760] Found device 0 with properties:\r\npciBusID: 0000:0a:00.0 name: GeForce RTX 3070 computeCapability: 8.6\r\ncoreClock: 1.77GHz coreCount: 46 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 417.29GiB/s\r\n2021-01-12 16:02:54.226918: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\r\n2021-01-12 16:02:54.258395: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll\r\n2021-01-12 16:02:54.258550: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll\r\n2021-01-12 16:02:54.279408: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll\r\n2021-01-12 16:02:54.284138: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll\r\n2021-01-12 16:02:54.345037: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll\r\n2021-01-12 16:02:54.348822: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll\r\n2021-01-12 16:02:54.350356: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll\r\n2021-01-12 16:02:54.350512: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1902] Adding visible gpu devices: 0\r\n2021-01-12 16:02:57.436724: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2021-01-12 16:02:57.437783: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1760] Found device 0 with properties:\r\npciBusID: 0000:0a:00.0 name: GeForce RTX 3070 computeCapability: 8.6\r\ncoreClock: 1.77GHz coreCount: 46 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 417.29GiB/s\r\n2021-01-12 16:02:57.438036: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1902] Adding visible gpu devices: 0\r\n2021-01-12 16:02:57.821516: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1300] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2021-01-12 16:02:57.821707: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1306]      0\r\n2021-01-12 16:02:57.821818: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1319] 0:   N\r\n2021-01-12 16:02:57.822077: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1446] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5474 MB memory) -> physical GPU (device: 0, name: GeForce RTX 3070, pci bus id: 0000:0a:00.0, compute capability: 8.6)\r\n2021-01-12 16:03:00.249533: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll\r\n2021-01-12 16:03:00.804621: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll\r\n2021-01-12 16:03:00.805722: I tensorflow/stream_executor/cuda/cuda_blas.cc:1838] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\r\n2021-01-12 16:03:00.810208: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll\r\n2021-01-12 16:03:01.400017: I tensorflow/stream_executor/cuda/cuda_dnn.cc:334] Loaded cuDNN version 8005\r\n```\r\n\r\nThe kernel then crashes after this and jupyter restarts it\r\n\r\n```\r\n[I 2021-01-12 16:03:39.603 ServerApp] KernelRestarter: restarting kernel (1/5), keep random ports\r\nkernel 0227f971-d1fe-44a3-8db7-a948217de0bb restarted\r\nkernel 0227f971-d1fe-44a3-8db7-a948217de0bb restarted\r\n[I 2021-01-12 16:03:39.626 ServerApp] Starting buffering for 0227f971-d1fe-44a3-8db7-a948217de0bb:c751d222-0788-4d6b-8fb6-b564f4dd14f5\r\n```", "comments": ["@Lunchb0ne \r\n\r\nI have tried in colab with TF-GPU nightly version(`2.5.0-dev20210112`) and I am not seeing any issue.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/89aa4fe1a7a4b20da5524f4f9fae4379/untitled610.ipynb).\r\nColab is using CUDA 10.1.Thanks!", "Yeah, seems like an issue with CUDA/ cudnn and TensorFlow.\r\n\r\nI downgraded it to 2.4 but still have CUDA 11.1 and cudnn 8.0.5 and it works fine now.\r\n\r\nThis is all very confusing because I thought 2.5 has support for 11.1", "@Lunchb0ne \r\n\r\nPlease use TF 2.4 as it is latest stable version. Thanks!", "Alright, Thanks a lot!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46363\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46363\">No</a>\n"]}, {"number": 46362, "title": "ModuleNotFoundError: No module named 'tensorflow.core'", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- Windows 10):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- Installed from whl:  tensorflow_gpu-2.4.0-cp36-cp36m-win_amd64.whl\r\n- TensorFlow version: 2.4.0\r\n- Python version: 3.6\r\n- Installed using virtualenv? pip? conda?: pip within conda\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10.1\r\n- GPU model and memory: NVIDIA GeForce RTX 2080 Ti\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nI have installed the following packages in a conda environment\r\nabsl-py                   0.4.1                     <pip>\r\nabsl-py                   0.7.1                    py36_0    <unknown>\r\nabsl-py                   0.10.0                    <pip>\r\nastunparse                1.6.3                     <pip>\r\nbeautifulsoup4            4.9.3                     <pip>\r\ncachetools                4.1.0                     <pip>\r\ncertifi                   2018.4.16                py36_0\r\nchardet                   4.0.0                     <pip>\r\nCython                    0.29.14                   <pip>\r\nflatbuffers               1.12                      <pip>\r\ngast                      0.3.3                     <pip>\r\ngoogle                    3.0.0                     <pip>\r\ngoogle-auth               1.14.1                    <pip>\r\ngoogle-auth-oauthlib      0.4.2                     <pip>\r\ngoogle-pasta              0.2.0                     <pip>\r\ngrpcio                    1.32.0                    <pip>\r\nh5py                      2.10.0                    <pip>\r\nidna                      2.10                      <pip>\r\nKeras                     2.4.3                     <pip>\r\nKeras-Preprocessing       1.1.2                     <pip>\r\nMarkdown                  3.2.1                     <pip>\r\nnumpy                     1.19.2                    <pip>\r\noauthlib                  3.1.0                     <pip>\r\nopt-einsum                3.3.0                     <pip>\r\npackaging                 20.8                      <pip>\r\npip                       10.0.1                   py36_0\r\npkgconfig                 1.5.1                     <pip>\r\nprotobuf                  3.14.0                    <pip>\r\npyasn1                    0.4.5                      py_0    <unknown>\r\npyasn1                    0.4.8                     <pip>\r\npyasn1-modules            0.2.8                     <pip>\r\npyparsing                 2.4.7                     <pip>\r\npython                    3.6.5                h0c2934d_0\r\nPyYAML                    5.3                       <pip>\r\nrequests                  2.25.1                    <pip>\r\nrequests-oauthlib         1.3.0                     <pip>\r\nrsa                       4.0                       <pip>\r\nscipy                     1.5.2                     <pip>\r\nsetuptools                39.1.0                   py36_0\r\nsetuptools                46.2.0                    <pip>\r\nsix                       1.15.0                    <pip>\r\nsoupsieve                 2.1                       <pip>\r\ntensorboard               2.4.0                     <pip>\r\ntensorboard-plugin-wit    1.7.0                     <pip>\r\ntensorflow-estimator      2.4.0                     <pip>\r\ntensorflow-gpu            2.4.0                     <pip>\r\ntermcolor                 1.1.0                     <pip>\r\ntyping-extensions         3.7.4.1                   <pip>\r\nurllib3                   1.26.2                    <pip>\r\nvc                        14                   h0510ff6_3\r\nvs2015_runtime            14.0.25123                    3\r\nWerkzeug                  1.0.1                     <pip>\r\nwheel                     0.35.0                    <pip>\r\nwheel                     0.31.1                   py36_0\r\nwincertstore              0.2              py36h7fe50ca_0\r\nwrapt                     1.12.1                    <pip>\r\n\r\nI am working within a firewall so packages are installed painstakingly one by one. It takes days to get it right\r\n\r\nRunning python code\r\nimport numpy as np\r\nimport tensorflow as tf\r\nimport google\r\nimport datetime\r\nfrom tensorflow import keras\r\nimport os\r\nfrom tensorflow.keras.layers.experimental.preprocessing import TextVectorization\r\n\r\n(Running from command line)\r\n\r\nI get:\r\n\r\n c:\\Users\\mosheho\\NLP>python Keras_embeddings.py\r\n2021-01-12 14:24:20.125275: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\r\nTraceback (most recent call last):\r\n  File \"Keras_embeddings.py\", line 51, in <module>\r\n    from tensorflow import keras\r\n  File \"C:\\Users\\mosheho\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow2_test\\lib\\site-packages\\tensorflow\\keras\\__init__.py\", line 14, in <module>\r\n    from . import activations\r\n  File \"C:\\Users\\mosheho\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow2_test\\lib\\site-packages\\tensorflow\\keras\\activations\\__init__.py\", line 10, in <module>\r\n    from tensorflow.python.keras.activations import deserialize\r\n  File \"C:\\Users\\mosheho\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow2_test\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 41, in <module>\r\n    from tensorflow.python.eager import context\r\n  File \"C:\\Users\\mosheho\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow2_test\\lib\\site-packages\\tensorflow\\python\\eager\\context.py\", line 32, in <module>\r\n    from tensorflow.core.framework import function_pb2\r\nModuleNotFoundError: No module named 'tensorflow.core'\r\n\r\nI do not know where to start. This is in TF 2.4 where most issues have been in TF 1 versions\r\nThanks\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["conda install tensorflow\r\n             or\r\npip3 install tensorflow", "Thanks\nI installed the tensorflow using pip. I can only install package by package\nbecause of being behind a firewall. Each package must be individually\ntested. But I don't think I am missing anything. If I am, I  can add it. I\njust don't know.\n\n\u05d1\u05ea\u05d0\u05e8\u05d9\u05da \u05d9\u05d5\u05dd \u05d2\u05f3, 12 \u05d1\u05d9\u05e0\u05d5\u05f3 2021, 19:32, \u05de\u05d0\u05ea Utkarsh \u200f<notifications@github.com\n>:\n\n> conda install tensorflow\n> or\n> pip3 install tensorflow\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/46362#issuecomment-758818772>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/ABBFRZRS327BIFJWDEUTA5LSZSBUBANCNFSM4V7FNGMQ>\n> .\n>\n", " Create a virtual environment and then install tensorflow into that.", "Also you may re-installed anaconda, python and all libraries.", "Thanks\nI am within a virtual environment and installing within it\nThe packages I printed were those in this environment\n\nDr. Moshe Hoshen  \u05de\u05e9\u05d4 \u05d7\u05e9\u05df\nDegania St \u05d3\u05d2\u05e0\u05d9\u05d4 15\nJerusalem \u05d9\u05e8\u05d5\u05e9\u05dc\u05d9\u05dd 96143\nIsrael\nTel. (972-2) 6519199\n\u05e0\u05d9\u05d9\u05d3 054-8061962\nmbhoshen@gmail.com\nhttp://www.linkedin.com/profile/view?id=92054595&trk=tab_pro\n\n\nOn Tue, 12 Jan 2021 at 20:41, Utkarsh <notifications@github.com> wrote:\n\n> Create a virtual environment and then install tensorflow into that.\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/46362#issuecomment-758858640>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/ABBFRZVJQIXT2WOXKRXBVNDSZSJW5ANCNFSM4V7FNGMQ>\n> .\n>\n", "@mbhoshen,\r\nInstallation issues within the Anaconda environment are tracked in the Anaconda repo.\r\n\r\nCould you please submit a new issue using [this link](https://github.com/ContinuumIO/anaconda-issues/issues) and fill in the template, so that the issue can be tracked there. \r\n\r\nAlso, please take a look at [this comment](https://stackoverflow.com/a/51505274) from a similar StackOverflow query and check if it helps. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46362\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46362\">No</a>\n"]}, {"number": 46361, "title": "custom normalizer_fn in tf.feature_column.numeric_column & tf.Keras Denselayer API results in failure when loading saved model.", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes. \r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Cloud AI platform notebook\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No.\r\n- TensorFlow installed from (source or binary): Binary. \r\n- TensorFlow version (use command below): 2.4\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n\r\n**Describe the current behavior**\r\nWhen using the `tf.feature_column.numeric` column api with a custom normalizer function, and passing the feature columns to ``tf.keras`` functional API via ```tf.keras.denselayer``` results in the model unable to be loaded once saved.\r\n\r\nThis is due to the fact the custom normalizer is not found. \r\n\r\n**Describe the expected behavior**\r\nThe model loads as usual. \r\n\r\n\r\n**Standalone code to reproduce the issue**\r\n This [colab]( https://colab.research.google.com/gist/fuhailin/15cc24100e6de025a98688f4927cebac/untitled418.ipynb#scrollTo=YsjNrRf-pG8B) was posted to StackOverflow and illustrates exactly the same problem.\r\n\r\n**Other info / logs** \r\n```python\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-7-865d10c0a905> in <module>\r\n      1 model = load_model(\r\n----> 2     model_directory=\"./checkpoint\"\r\n      3 )\r\n\r\n<ipython-input-6-62298af7498d> in load_model(model_directory)\r\n     10     \"\"\"\r\n     11 \r\n---> 12     model = tf.keras.models.load_model(model_directory, compile=False)\r\n     13 \r\n     14     return model\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/saving/save.py in load_model(filepath, custom_objects, compile, options)\r\n    210       if isinstance(filepath, six.string_types):\r\n    211         loader_impl.parse_saved_model(filepath)\r\n--> 212         return saved_model_load.load(filepath, compile, options)\r\n    213 \r\n    214   raise IOError(\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/load.py in load(path, compile, options)\r\n    136   # Recreate layers and metrics using the info stored in the metadata.\r\n    137   keras_loader = KerasObjectLoader(metadata, object_graph_def)\r\n--> 138   keras_loader.load_layers()\r\n    139 \r\n    140   # Generate a dictionary of all loaded nodes.\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/load.py in load_layers(self)\r\n    374       self.loaded_nodes[node_metadata.node_id] = self._load_layer(\r\n    375           node_metadata.node_id, node_metadata.identifier,\r\n--> 376           node_metadata.metadata)\r\n    377 \r\n    378     for node_metadata in metric_list:\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/load.py in _load_layer(self, node_id, identifier, metadata)\r\n    403     # Detect whether this object can be revived from the config. If not, then\r\n    404     # revive from the SavedModel instead.\r\n--> 405     obj, setter = self._revive_from_config(identifier, metadata, node_id)\r\n    406     if obj is None:\r\n    407       obj, setter = revive_custom_object(identifier, metadata)\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/load.py in _revive_from_config(self, identifier, metadata, node_id)\r\n    421       obj = (\r\n    422           self._revive_graph_network(metadata, node_id) or\r\n--> 423           self._revive_layer_from_config(metadata, node_id))\r\n    424 \r\n    425     if obj is None:\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/load.py in _revive_layer_from_config(self, metadata, node_id)\r\n    481     try:\r\n    482       obj = layers_module.deserialize(\r\n--> 483           generic_utils.serialize_keras_class_and_config(class_name, config))\r\n    484     except ValueError:\r\n    485       if must_restore_from_config:\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/layers/serialization.py in deserialize(config, custom_objects)\r\n    175       module_objects=LOCAL.ALL_OBJECTS,\r\n    176       custom_objects=custom_objects,\r\n--> 177       printable_module_name='layer')\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/utils/generic_utils.py in deserialize_keras_object(identifier, module_objects, custom_objects, printable_module_name)\r\n    356             custom_objects=dict(\r\n    357                 list(_GLOBAL_CUSTOM_OBJECTS.items()) +\r\n--> 358                 list(custom_objects.items())))\r\n    359       with CustomObjectScope(custom_objects):\r\n    360         return cls.from_config(cls_config)\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/feature_column/base_feature_layer.py in from_config(cls, config, custom_objects)\r\n    139     config_cp = config.copy()\r\n    140     config_cp['feature_columns'] = serialization.deserialize_feature_columns(\r\n--> 141         config['feature_columns'], custom_objects=custom_objects)\r\n    142     config_cp['partitioner'] = generic_utils.deserialize_keras_object(\r\n    143         config['partitioner'], custom_objects)\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/feature_column/serialization.py in deserialize_feature_columns(configs, custom_objects)\r\n    184   return [\r\n    185       deserialize_feature_column(c, custom_objects, columns_by_name)\r\n--> 186       for c in configs\r\n    187   ]\r\n    188 \r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/feature_column/serialization.py in <listcomp>(.0)\r\n    184   return [\r\n    185       deserialize_feature_column(c, custom_objects, columns_by_name)\r\n--> 186       for c in configs\r\n    187   ]\r\n    188 \r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/feature_column/serialization.py in deserialize_feature_column(config, custom_objects, columns_by_name)\r\n    136       cls_config,\r\n    137       custom_objects=custom_objects,\r\n--> 138       columns_by_name=columns_by_name)\r\n    139 \r\n    140   # If the name already exists, re-use the column from columns_by_name,\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/feature_column/feature_column_v2.py in from_config(cls, config, custom_objects, columns_by_name)\r\n   2620     kwargs = _standardize_and_copy_config(config)\r\n   2621     kwargs['normalizer_fn'] = serialization._deserialize_keras_object(  # pylint: disable=protected-access\r\n-> 2622         config['normalizer_fn'], custom_objects=custom_objects)\r\n   2623     kwargs['dtype'] = dtypes.as_dtype(config['dtype'])\r\n   2624 \r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/feature_column/serialization.py in _deserialize_keras_object(identifier, module_objects, custom_objects, printable_module_name)\r\n    271       obj = custom_objects.get(object_name)\r\n    272     else:\r\n--> 273       obj = module_objects.get(object_name)\r\n    274       if obj is None:\r\n    275         raise ValueError(\r\n\r\nAttributeError: 'NoneType' object has no attribute 'get'\r\n\r\n```\r\n\r\nAny pointers how to tackle this? ", "comments": ["@robinvanschaik \r\nI ran the code shared and face a different error, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/f35e030f2ddd8f1984623bf52e8c42c7/untitled.ipynb).\r\n", "@Saduf2019 My apologies. The original missed an import from sklearn. \r\n\r\nI re-uploaded the colab as [here](https://colab.research.google.com/gist/robinvanschaik/701ab926088a2b96d81b2a2aa546164c/untitled418.ipynb). \r\n\r\nPlease let me know if you run into issues regarding this colab. ", "I ran the code shared and am able to replicate the issue, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/abc2dced3e3a59399509e05a37754d72/untitled493.ipynb)", "I am running on the same issue when loading my saved model too.\r\nDo we have any fix on that?", "@robinvanschaik you need to pass your custom objects to `.load_model(...)` otherwise it can't recreate your rescaling function. This [guide](https://www.tensorflow.org/guide/keras/save_and_serialize#how_savedmodel_handles_custom_objects) provides more information about it.\r\n\r\nI was able to get your code working by changing your last row to:\r\n```\r\nloaded_model = tf.keras.models.load_model('./saved_models/1', custom_objects={\"scale_fn\": scale_fn})\r\n```\r\n\r\nYou can check that both models have the same weights with the following snippet I copied from TF's guide:\r\n```python\r\nimport numpy as np\r\n\r\nsample_input, _ = next(iter(dataset))\r\nnp.testing.assert_allclose(\r\n    model.predict(sample_input), loaded_model.predict(sample_input)\r\n)\r\n\r\nfor mw, lmw in zip(model.weights, loaded_model.weights):\r\n    np.testing.assert_allclose(mw.numpy(), lmw.numpy())\r\n```", "Thanks @bguisard  for your comment this was very helpful, however, how can we handle custom scaling functions which need to maintain states. For example, min-max where we need to maintain min and max values from training data?", "Did anyone come up with a solution for this? `normalizer_fn` is practically useless if it does not use the values from the training dataset to scale/normalize new inputs to the loaded model. Is this not documented anywhere? It seems like a pretty common issue.", "@fonnesbeck I think that applying [layer-normalization](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LayerNormalization) on the input layer w.r.t. the appropriate axis might achieve a similar result, no? \r\n\r\nUnfortunately, it would mean that these parameters have to be learned during training, and I believe that this may extend training time.  \r\n\r\nOther than that, I do not have any other solutions for the current predicament. \r\n", "@robinvanschaik this is an Estimator (`DNNClassifier`), so I'm not manually building the layers, otherwise that's what I would have tried. I've resorted to manually serializing numpy arrays of normalization parameters.", "> @robinvanschaik you need to pass your custom objects to `.load_model(...)` otherwise it can't recreate your rescaling function. This [guide](https://www.tensorflow.org/guide/keras/save_and_serialize#how_savedmodel_handles_custom_objects) provides more information about it.\r\n> \r\n> I was able to get your code working by changing your last row to:\r\n> \r\n> ```\r\n> loaded_model = tf.keras.models.load_model('./saved_models/1', custom_objects={\"scale_fn\": scale_fn})\r\n> ```\r\n> \r\n> You can check that both models have the same weights with the following snippet I copied from TF's guide:\r\n> \r\n> ```python\r\n> import numpy as np\r\n> \r\n> sample_input, _ = next(iter(dataset))\r\n> np.testing.assert_allclose(\r\n>     model.predict(sample_input), loaded_model.predict(sample_input)\r\n> )\r\n> \r\n> for mw, lmw in zip(model.weights, loaded_model.weights):\r\n>     np.testing.assert_allclose(mw.numpy(), lmw.numpy())\r\n> ```\r\n\r\nhow to load if use \"normalizer_fn=lambda x: (x - 3.0) / 4.2)\"", "@robinvanschaik Is this still an issue for you? \r\nYou are trying to load a Tensorflow model as a keas model. When you load the model as a TF model, everything works as expected. Please check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/badf69e20d2a6a4f3f01d805efc83738/untitled418.ipynb).\r\n\r\n```\r\n# loaded_model = tf.keras.models.load_model('./saved_models/1')\r\nloaded_model = tf.saved_model.load('./saved_models/1')\r\n```", "> @robinvanschaik Is this still an issue for you? \n> You are trying to load a Tensorflow model as a keas model. When you load the model as a TF model, everything works as expected. Please check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/badf69e20d2a6a4f3f01d805efc83738/untitled418.ipynb).\n> \n> ```\n> # loaded_model = tf.keras.models.load_model('./saved_models/1')\n> loaded_model = tf.saved_model.load('./saved_models/1')\n> ```\n\nHi @jvishnuvardhan, \n\nThanks for coming back to me. Unfortunately, I cannot verify whether this would have solved my issue. \n\nI have switched companies and do not tackle my use case with TFX. \n\n\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46361\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46361\">No</a>\n"]}, {"number": 46360, "title": "added double braces to initialization", "body": "Not raised an issue, however this fixes and error with the `expected_output_data.h`.\r\n\r\nIssue came about when running:\r\n\r\n```\r\nmake -f tensorflow/lite/micro/tools/make/Makefile test\r\n```\r\n\r\nError message was:\r\n\r\n```\r\nwarning: suggest braces around initialization of subobject [-Wmissing-braces]\r\n```\r\n\r\nThis failed on:\r\n\r\n```\r\nApple clang version 12.0.0 (clang-1200.0.32.27)\r\nTarget: x86_64-apple-darwin19.6.0\r\nThread model: posix\r\nInstalledDir: /Library/Developer/CommandLineTools/usr/bin\r\n```\r\n\r\nFix:\r\n\r\nadded set of braces around the initialisation.", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n"]}, {"number": 46358, "title": "[tf.data] Implement SkipInternal for TFRecordDataset", "body": "This is a PR from JIZHI Team & TaiJi AI platform in Tencent.\r\n\r\nThis PR is a follow-up of #40963 and #41222. In those 2 PRs, I added the `Skip` method to `IteratorBase` and `RecordReader` so that we can potentially reduce the IO when user is using `tf.data.Dataset.shard()` method on samples instead of filenames.\r\n\r\nThis PR adds the `SkipInternal` for `TFRecordDatasetOp`. The implementation is very similar to `GetNextInternal`. And to test the new method, I added the helper functions and macros for `Skip`, which are also very similar to that of `GetNext`.\r\n\r\nI'm not sure the proper way to deal with `metrics::GetTFDataBytesReadCounter` in `SkipInternal`, so it is omitted for now. It would be great if you could give me some hints on it.\r\n\r\nSorry for this late follow-up, I would try to add the meaningful `SkipInternal`s in the coming months.\r\n\r\ncc @aaudiber @jsimsa ", "comments": ["@aaudiber I've experimented with imagenet dataset. The test code I used is:\r\n```python\r\nfrom time import time\r\nfrom tqdm import tqdm\r\n\r\nimport tensorflow as tf\r\nfrom tensorflow.python.platform import gfile\r\n# Use the internal class to bypass the flat_map\r\nfrom tensorflow.python.data.ops.readers import _TFRecordDataset\r\n\r\nglob_pattern = \"~/imagenet/train-*-of-*\"\r\nfile_names = gfile.Glob(glob_pattern)\r\n\r\nnum_shard = 8\r\nds = _TFRecordDataset(file_names)\r\n# use \"ds = ds.repeat().shard(num_shard, 0)\" as the version without using skip\r\nds = ds.shard(num_shard, 0).repeat()\r\n\r\ni = 0\r\n_ = next(iter(ds))\r\nstart = time()\r\nfor _ in tqdm(ds):\r\n    if i == 10000:\r\n        break\r\n    i += 1\r\nprint(time() - start)\r\n```\r\nThe result is that when dataset is cached by OS (e.g. running the above script for the second time), the version with skip will have obvious improvement:\r\n|num_shard|origin (iter/s)|with skip (iter/s)|\r\n|-|-|-|\r\n|2|6231|7925|\r\n|4|3883|5901|\r\n|8|2253|3949|\r\n|16|1169|2537|\r\n\r\nwith the dataset's own speed at 9548 iter/s.\r\n\r\nBut when the dataset is not cached by OS, the performance of the two come close.\r\n\r\nI think this is because tfrecord always needs to call `file_->Read` for the header underneath, no matter we are using `SkipRecords` or `ReadRecord`. And when file is not cached, the read operation itself is really slow, regardless of the amount of data we read.\r\n\r\nThe `shard` method after `TFRecordDataset` instead of after `list_files` is for user with one-file or uneven-size-files dataset. I think that the current speed up will give some help and I will continue to investigate why the performance is not improved for the uncached situation.", "@aaudiber Could you have another look at this pr? Thank you!", "@aaudiber Could you help me to check what is the build error? It's an internal one and I have no access to the log. Thank you~", "@aaudiber There is still error in \"feedback/copybara\"... Would you mind checking that again? Thank you.", "Here is the error:\r\n\r\nIn file included from third_party/tensorflow/core/kernels/data/tf_record_dataset_op_test.cc:14:\r\n./third_party/tensorflow/core/kernels/data/dataset_test_base.h:394:23: error: field 'compare_order' is uninitialized when used here [-Werror,-Wuninitialized]\r\n        compare_order(compare_order) {}\r\n                      ^\r\nthird_party/tensorflow/core/kernels/data/tf_record_dataset_op_test.cc:158:11: note: in instantiation of member function 'tensorflow::data::SkipTestCase<tensorflow::data::(anonymous namespace)::TFRecordDatasetParams>::SkipTestCase' requested here\r\n  return {{/*dataset_params=*/TFRecordDatasetParams1(),", ":joy: Thank you for your fast reply and aproval. I've fixed the typo. Don't understand why other tests could pass though...", "@aaudiber \r\nSome update for the performance. If we set the `buffer_size` of the `_TFRecordDataset` to `0` so that the `TFRecordDatasetOp` will no longer use the underlaying `BufferedInputStream`, this PR will make `shard` have almost no performance drop when the data was cached.\r\n\r\nnum_shard | origin (iter/s) | with skip (iter/s) | skip + buffer_size=0 (iter/s)\r\n-- | -- | -- | --\r\n2 | 6231 | 7925 | 9963\r\n4 | 3883 | 5901 | 9833\r\n8 | 2253 | 3949 | 9490\r\n16 | 1169 | 2537 | 8563\r\n\r\nAs for the data without cache, this PR would also be 2~4 times faster than the origin shard. The reason why last test showed no difference was also the  `BufferedInputStream`."]}, {"number": 46357, "title": "how to use doc", "body": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nFor example, why should someone use this method? How is it useful?\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n\r\n### Usage example\r\n\r\nIs there a usage example?\r\n\r\nSee the API guide: https://www.tensorflow.org/community/contribute/docs_ref\r\non how to write testable usage examples.\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs,\r\ndocs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n", "comments": []}, {"number": 46355, "title": "'<=' not supported between instances of 'list' and 'int' when using StringLookup", "body": "tf version: 2.4.0\r\n\r\n```\r\nvocab = [\"a\", \"b\", \"c\", \"d\"]\r\ntable = tf.keras.layers.experimental.preprocessing.StringLookup(vocab)\r\n```\r\n\r\n> ---------------------------------------------------------------------------\r\n> TypeError                                 Traceback (most recent call last)\r\n> <ipython-input-98-cc6cfb4d8df0> in <module>\r\n> ----> 1 table = tf.keras.layers.experimental.preprocessing.StringLookup(vocab)\r\n> \r\n> /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/preprocessing/string_lookup.py in __init__(self, max_tokens, num_oov_indices, mask_token, oov_token, vocabulary, encoding, invert, **kwargs)\r\n>     197         vocabulary=vocabulary,\r\n>     198         invert=invert,\r\n> --> 199         **kwargs)\r\n>     200     base_preprocessing_layer._kpl_gauge.get_cell(\"V2\").set(\"StringLookup\")\r\n>     201\r\n> \r\n> /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/preprocessing/index_lookup.py in __init__(self, max_tokens, num_oov_indices, mask_token, oov_token, vocabulary, invert, **kwargs)\r\n>      92     # If max_tokens is set, the value must be greater than 1 - otherwise we\r\n>      93     # are creating a 0-element vocab, which doesn't make sense.\r\n> ---> 94     if max_tokens is not None and max_tokens <= 1:\r\n>      95       raise ValueError(\"If set, `max_tokens` must be greater than 1.\")\r\n>      96\r\n> \r\n> TypeError: '<=' not supported between instances of 'list' and 'int'", "comments": ["I suppose the example just not works at all.\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/StringLookup", "@yananchen1989  It's because your are passing a positional argument while the example code snippet passes a keyword argument. Try this to fix it.\r\n\r\n```python\r\nvocab = [\"a\", \"b\", \"c\", \"d\"]\r\ntable = tf.keras.layers.experimental.preprocessing.StringLookup(vocabulary=vocab)\r\n```", "@yananchen1989 \r\nYou have to pass argument as (`vocabulary=vocab`).You can refer the [document](https://www.tensorflow.org/guide/keras/preprocessing_layers) with the below example.\r\n```\r\nvocab = [\"a\", \"b\", \"c\", \"d\"]\r\ndata = tf.constant([[\"a\", \"c\", \"d\"], [\"d\", \"z\", \"b\"]])\r\nlayer = preprocessing.StringLookup(vocabulary=vocab)\r\nvectorized_data = layer(data)\r\nprint(vectorized_data)\r\n```\r\nPlease, find the gist [here](https://colab.research.google.com/gist/ravikyram/b221a8c0faedd6ecbe1fba6d24cd312f/untitled609.ipynb).Please, verify once and close the issue . Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46355\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46355\">No</a>\n"]}, {"number": 46354, "title": "Docker+tf-gpu2.1.0: No such file or directory; /usr/local/nvidia/lib:/usr/local/nvidia/lib64", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution : linux ubuntu 18.04\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version: 2.1.0\r\n- Python version: 3.6.3\r\n- Installed using virtualenv? pip? conda?:  container\r\n- Bazel version (if compiling from source): \r\n- GCC/Compiler version (if compiling from source): 7.5\r\n- CUDA/cuDNN version: 10.1\r\n- GPU model and memory: rtx2080ti  12GB\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nI try to install through the mirror of NVIDIA, \r\nimage info:\r\nnvidia/cuda: 10.1-cudnn7-devel-ubuntu18.04\r\nserver diver info:\r\n NVIDIA-SMI 418.56       Driver Version: 418.56       CUDA Version: 10.1\r\n`nvdia-smi` can work.\r\nAfter finishing installing tf,\r\n\r\n\r\n**Any other info / logs**\r\n W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\r\n\r\nW tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\r\n\r\n W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\r\n\r\n", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46354\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46354\">No</a>\n", "GPU can work, Don't worry about these ..."]}, {"number": 46353, "title": "Merge pull request #1 from tensorflow/master", "body": "Bring up to date with upstream", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F46353) for more info**.\n\n<!-- need_sender_cla -->"]}, {"number": 46352, "title": "Rename directories to have underscores instead of dashes (cmsis-nn -> cmsis_nn and ethos-u -> ethos_u)", "body": "Fixes http://b/168824958\r\n- Rename ethos-u to ethos_u.\r\n- cmsis-nn -> cmsis_nn\r\n\r\n@mansnils @freddan80 : There is one more cleanup that might be worth addressing as part of this cleanup, and that is the use of OPTIMIZED_KERNEL_DIR instead of TAGS:\r\n\r\nThe issue at hand is that we are moving towards explicitly including the specific target and optimized_kernel dirs that are needed (as opposed to including all the *.inc and then filtering based on tags):\r\nhttps://github.com/tensorflow/tensorflow/blob/161fcca9a7767a63a304a875ff26d22026d5e1b5/tensorflow/lite/micro/tools/make/Makefile#L560-L583\r\n\r\n\r\nWhat this means is that we would like to change the make command to be:\r\n```\r\nmake TARGET=cortex_m_generic OPTIMIZED_KERNEL_DIR=cmsis_nn\r\n```\r\n\r\nThe catch is what to do about ethos_u since with this new approach we won't be including ext_libs/ethos_u.inc or specializing kernels/ethos_u/ethosu.cc unless we did something special.\r\n\r\nAn option would be to have cortex_m_generic_makefile.inc include ext_libs/ethos_u.inc (depending on a command line option). And have ethos_u.inc explicitly specialize kernels/ethos_u/ethos.cc (using this same command line option).\r\n\r\nI can think of other more involved approaches too, but wanted to type this up to get initial thoughts. Happy to prototype this so that you have a more concrete idea of what I'm suggesting.\r\n\r\nThe google-way of doing this would be to have separate PRs for each of these changes. I can line up the PRs and plan to merge them in the space of a day or two once they are all approved so that you can pull in all the changes in one go.\r\n\r\nHowever, if you guys would prefer, I can do this all in a single PR too. Let me know.", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n", "@advaitjain If we update Ethos-U in same was as CMSIS-NN, would this not work?\r\nmake TARGET=cortex_m_generic OPTIMIZED_KERNEL_DIR=ethos_u\r\nThe same way as this (or what is the catch?)\r\nmake TARGET=cortex_m_generic OPTIMIZED_KERNEL_DIR=cmsis_nn\r\n\r\nAnother thing is that we actually use TAGS=\"cmsis-nn ethos-u\". I realize that it will not be possible with OPTIMIZED_KERNEL_DIR.\r\nPotentially a CMSIS-NN operator might not be supported by Ethos-U, then we may want to fall back on CMSIS-NN instead of Reference kernel. So I am thinking how we could support this, perhaps as a special case for Ethos-U, where this logic is moved to ext_libs/ethos_u.inc..?", "Yes, the `TAGS=\"cmsis-nn ethos-u\"` was the case that I was referring to as the catch. We want to disallow multiple directories of optimized kernels because for the most part the optimized kernel implementations are incompatible.\r\n\r\nDo you imagine having more ethos-u kernels or will the current one be the only ethos-u specific kernel?\r\n\r\nIf you always use cmsis_nn with ethos_u then we could consolidate ethos-u and cmsis_nn into one optimized kernel directory and have an ifdef in there. This would be the approach that we are taking for xtensa.\r\n\r\nSo we would move ethosu.cc to cmsis_nn and have something like:\r\n\r\n```\r\nif defined(ETHOSU)\r\n// current contents of ethosu.\r\n#else\r\n// fallback no-op ethosu kernel.\r\n#endif\r\n```\r\n\r\nand ext_libs/cmsis_nn.inc can include ext_libs/ethosu.inc (or move that logic into cmsis_nn.inc, if it doesn't clutter things up).\r\n\r\n\r\nIf you do need a way to have all reference kernels with ethos-u then your idea of adding a specialize call for cmsis_nn from  ethos_u.inc would be the way to go.\r\n\r\nLet me know what you guys need and we can dive deeper in that direction.", "There might be some other Ethos-X. I think we would like to support both TAGS=ethos-u and TAGS=\"ethos-u cmsis-nn\". Another potential use case might be that there is for example a Cortex-M4+DSP, with specific conv optimizations for the DSP. Then one would want to run conv with the DSP but still benefit from the rest of the CMSIS-NN optimizations (so TAGS=\"some-co-processor cmsis-nn\").", "Thanks for the additional context.\r\n\r\nSome background on where I am coming at this from:\r\n * We would like to have fewer specialized kernel directories and group things under a common directory, as much as possible.\r\n * We are going through a similar exercise with engineers at Cadence where we are consolidating different variations into a common xtensa directory and using -D{TARGET_ARCH} as a way to have ifdefs in the code.\r\n * The trade-off here is reduced maintenance overhead over time at the cost of more work up-front when implementing the kernels or refactoring of the existing implementations that follow the older pattern.\r\n\r\nThe co-processor use-case is not something we thought through. I'd still like for this to be a deliberate choice on the command line instead of relying on `TAGS`.\r\n\r\nHow about something like:\r\n * `TAGS=\"ethos-u cmsis-nn\"` is replaced with `OPTIMIZED_KERNEL_DIR=cmsis_nn CO_PROCESSOR=ethos_u`\r\n * `TAGS=\"ethos-u\"` is replaced with `OPTIMIZED_KERNEL_DIR=none CO_PROCESSOR=ethos_u`\r\n    *  we need `OPTIMIZED_KERNEL_DIR=none` for backwards compatibility.\r\n\r\nAnd the makefile explicitly includes and specializes, giving preference to `CO_PROCESSOR` and then `OPTIMIZED_KERNEL_DIR` when specializing kernel implementations.\r\n\r\nAnd is it worth having the co-processor directory be called `ethos` instead of `ethos_u` so that any variants can go in there in the future?", "Having OPTIMIZED_KERNEL_DIR and CO_PROCESSOR seem good, although naming could be confusing in the case of OPTIMIZED_KERNEL_DIR=cmsis_nn and CO_PROCESSOR=main_processor, anyway that is a minor detail a long as it works.\r\nPerhaps this could then work with the general example I mentioned, for example OPTIMIZED_KERNEL_DIR=cmsis_nn and CO_PROCESSOR=DSP.\r\nSo we would prefer the more general case where CO_PROCESSOR is just that and is not named after Ethos-U or Ethos.", "ok, I think we're converging on a solution. I have created #46473\r\n\r\nThe steps that I am thinking of is to have you guide #46473 to where it does what you need as a stand-alone change. If you can check it out and test it locally, that would be great.\r\n\r\nAnd then I make a follow-up PR that renames the dash to underscore. Once both are approved we merge them as separate PRs (in quick succession).\r\n\r\nLet me know what you think.", "Closing this PR in favor of a new one https://github.com/tensorflow/tensorflow/pull/46584 for the dreictory renaming."]}, {"number": 46351, "title": "Lower Size to Prod(Shape)", "body": "Fixes #46285. This PR adds `tf.SizeOp` lowering pattern to make TFL users use `tf.size` without `SELECT_TF_OPS`. Because number of elements is the product of each dimension size, it can be lowered to `Prod(Shape, reduction_indices=0, keep_dims=false)`. The pattern is safe to apply any kind of Tensor. For ranked tensor with static shape, operations can be folded to a constant. For ranked tensor with dynamic shape or unranked tensor, the pattern does as what it is.\r\n\r\nWe also remove the `TF::SizeOp` legalization in HLO, which targets on ranked tensor only and extracts/multiplies each dimension. The lowering pattern in this PR will produce a `mhlo.reduce` for ranked tensor with dynamic shape instead of combining many `mhlo.get_dimension_size` and `mhlo.multiply` before. For ranked tensor with static shape, operations are folded into a constant as before.\r\n\r\n/cc @smit-hinsu.", "comments": ["here is the output for original tests. The main different is that the ranked tensor with dynamic shape also uses reduce instead of extracting each dimension and multiplying them.\r\n\r\n```\r\n  func @size_scalar_i32(%arg0: tensor<f32>) -> tensor<i32> {\r\n    %0 = mhlo.constant dense<1> : tensor<i32>\r\n    %1 = tensor.cast %0 : tensor<i32> to tensor<i32>\r\n    return %1 : tensor<i32>\r\n  }\r\n  func @size_scalar_i64(%arg0: tensor<f32>) -> tensor<i64> {\r\n    %0 = mhlo.constant dense<1> : tensor<i64>\r\n    %1 = tensor.cast %0 : tensor<i64> to tensor<i64>\r\n    return %1 : tensor<i64>\r\n  }\r\n  func @size_rank_one_i64(%arg0: tensor<?xf32>) -> tensor<i64> {\r\n    %0 = mhlo.constant dense<0> : tensor<i64>\r\n    %1 = tensor.cast %0 : tensor<i64> to tensor<i64>\r\n    %2 = shape.shape_of %arg0 : tensor<?xf32> -> tensor<?xindex>\r\n    %3 = shape.to_extent_tensor %2 : tensor<?xindex> -> tensor<1xindex>\r\n    %4 = index_cast %3 : tensor<1xindex> to tensor<1xi64>\r\n    %5 = \"mhlo.convert\"(%4) : (tensor<1xi64>) -> tensor<1xi64>\r\n    %6 = mhlo.constant dense<1> : tensor<i64>\r\n    %7 = \"mhlo.reduce\"(%5, %6) ( {\r\n    ^bb0(%arg1: tensor<i64>, %arg2: tensor<i64>):  // no predecessors\r\n      %9 = mhlo.multiply %arg1, %arg2 : tensor<i64>\r\n      \"mhlo.return\"(%9) : (tensor<i64>) -> ()\r\n    }) {dimensions = dense<0> : tensor<1xi64>} : (tensor<1xi64>, tensor<i64>) -> tensor<i64>\r\n    %8 = \"mhlo.convert\"(%7) : (tensor<i64>) -> tensor<i64>\r\n    return %8 : tensor<i64>\r\n  }\r\n  func @size_ranked(%arg0: tensor<2x?x8xf32>) -> tensor<i32> {\r\n    %0 = mhlo.constant dense<0> : tensor<i32>\r\n    %1 = tensor.cast %0 : tensor<i32> to tensor<i32>\r\n    %2 = shape.shape_of %arg0 : tensor<2x?x8xf32> -> tensor<?xindex>\r\n    %3 = shape.to_extent_tensor %2 : tensor<?xindex> -> tensor<3xindex>\r\n    %4 = index_cast %3 : tensor<3xindex> to tensor<3xi32>\r\n    %5 = \"mhlo.convert\"(%4) : (tensor<3xi32>) -> tensor<3xi32>\r\n    %6 = mhlo.constant dense<1> : tensor<i32>\r\n    %7 = \"mhlo.reduce\"(%5, %6) ( {\r\n    ^bb0(%arg1: tensor<i32>, %arg2: tensor<i32>):  // no predecessors\r\n      %9 = mhlo.multiply %arg1, %arg2 : tensor<i32>\r\n      \"mhlo.return\"(%9) : (tensor<i32>) -> ()\r\n    }) {dimensions = dense<0> : tensor<1xi64>} : (tensor<3xi32>, tensor<i32>) -> tensor<i32>\r\n    %8 = \"mhlo.convert\"(%7) : (tensor<i32>) -> tensor<i32>\r\n    return %8 : tensor<i32>\r\n  }\r\n  func @size_unranked(%arg0: tensor<*xf32>) -> tensor<i32> {\r\n    %0 = mhlo.constant dense<0> : tensor<i32>\r\n    %1 = tensor.cast %0 : tensor<i32> to tensor<i32>\r\n    %2 = shape.shape_of %arg0 : tensor<*xf32> -> tensor<?xindex>\r\n    %3 = shape.to_extent_tensor %2 : tensor<?xindex> -> tensor<?xindex>\r\n    %4 = index_cast %3 : tensor<?xindex> to tensor<?xi32>\r\n    %5 = \"mhlo.convert\"(%4) : (tensor<?xi32>) -> tensor<?xi32>\r\n    %6 = mhlo.constant dense<1> : tensor<i32>\r\n    %7 = \"mhlo.reduce\"(%5, %6) ( {\r\n    ^bb0(%arg1: tensor<i32>, %arg2: tensor<i32>):  // no predecessors\r\n      %9 = mhlo.multiply %arg1, %arg2 : tensor<i32>\r\n      \"mhlo.return\"(%9) : (tensor<i32>) -> ()\r\n    }) {dimensions = dense<0> : tensor<1xi64>} : (tensor<?xi32>, tensor<i32>) -> tensor<i32>\r\n    %8 = \"mhlo.convert\"(%7) : (tensor<i32>) -> tensor<i32>\r\n    return %8 : tensor<i32>\r\n  }\r\n```", "Updated the description. Thanks for reviewing!"]}, {"number": 46350, "title": "Explicitly disable layering check for TFLM bazel packages.", "body": "Note that we will need to manually ensure that any new bazel package has the layering_check disabled.\r\n\r\nThe internal builds have layering_check turned on by default, while the open-source builds have them turned off by default. Ideally, we would explicitly turn them on for the open-source build.\r\n\r\nHowever, turning it on (with `layering_check` instead of `-layering_check`) and building with this command:\r\n```\r\nbazel build tensorflow/lite/micro/kernels:add_test --repo_env=CC=`which clang`\r\n```\r\n\r\nresults in a number of additional build errors that will need much broader changes to the TFLM BUILD files to fix.\r\n\r\nAs a result, we are currently turning off the layering_check to at least make the internal and external builds consistent.\r\n\r\nFixes #46347\r\n\r\nSee http://b/177257332 for more internal-only context.\r\n", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n"]}, {"number": 46349, "title": "[Cherrypick:r2.4] Fix issue when using mixed precision with RMSprop.", "body": "Before, accessing the `op` attribute on the return value of AutoCastVariable.assign in Eager mode would raise an AttributeError instead of returning None. Accessing the `op` attribute on an AutoCastVariable itself (that is not the return value of `assign`) still raises an AttributeError, to be consistent with tf.Variable.\n\nResolves https://github.com/tensorflow/tensorflow/issues/45536.\n\nPiperOrigin-RevId: 347524886\nChange-Id: I663731c0ff4c557608eae352096a527e4dcabb18", "comments": []}, {"number": 46348, "title": "Set CUDA Version Manually", "body": "I was using TF 2.4 and my machines were already configed with CUDA 10.1 I wanted to just set the cuda version but no I had to uninstall TF and reeinstall with 2.3 kinda frustrating wish I could just tell it what CUDA version I had.\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\n**Will this change the current api? How?**\r\n\r\n**Who will benefit with this feature?**\r\n\r\n**Any Other info.**\r\n", "comments": ["TF 2.4 is compatible with cuda 11.0 thus upgrading your cuda version to 11.0 should suffice.\r\nSee https://www.tensorflow.org/install/gpu#software_requirements\r\nTF pre built binaries support specific cuda version as stated in this [table](https://www.tensorflow.org/install/source#tested_build_configurations).\r\nFor using different cuda version than stated in above table with your choice of TF version you have to [build TF from sources](https://www.tensorflow.org/install/source) which takes a longer time to build.", "Ok, was just wondering if it was possible. Thanks"]}, {"number": 46347, "title": "layering check mismatch between internal and open-source TFLM bazel builds", "body": "@tensorflow/micro\r\n\r\nThe Google-internal bazel builds have layering checks turned on while the open-source builds do not. This results in PRs passing external checks but then failing internally (see https://github.com/tensorflow/tensorflow/pull/46242 as an example).\r\n\r\nIf we can have the same behavior in the OSS bazel build then there will be one less discrepancy between the internal and open-source builds.", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46347\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46347\">No</a>\n"]}, {"number": 46346, "title": "[CherryPick:r2.4] Update build_pip_package.sh", "body": null, "comments": ["All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F46346) for more info**.\n\n<!-- need_author_consent -->"]}, {"number": 46345, "title": "Model converted does't recognize image properly", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- TensorFlow version (or github SHA if from source):2.4.0\r\n\r\n\r\nHi all, i'm trying to make this model: [SSD MobileNet V2 FPNLite 320x320](http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz)\r\nrecognizing my face instead of all other objects of coco dataset. I have already did some training to the model and i wanted to test it out even if wasn't working perfectly fine since the total loss was still high, the problem is that the model is not recognizing anything, the output of the recognized objects is always:\r\n![image](https://user-images.githubusercontent.com/10716240/104225249-71493880-5446-11eb-851a-756dd887f1b9.png)\r\nEven if i move the camera around, so i suppose something is wrong with the model itself. \r\nCan someone give me a feedback about it? \r\nThis is the model: [Model](https://gofile.io/d/N17Jf4)\r\n\r\nMy application use more models (same model copied and trained with different dataset for different purpose, and they all works, this is the only that doesn't work properly. ) \r\n\r\nI had a problem with another model and someone suggested me to change IMAGE_MEAN and IMAGE_STD from TFLiteObjectDetectionAPIModel to those values\r\n```\r\nprivate static final float IMAGE_MEAN = 0.0f;\r\nprivate static final float IMAGE_STD = 1.0f;\r\n```\r\n\r\nBut this doesn't work. Any more suggestion?", "comments": ["I actually already fixed the problem. The problem was the loss, after a few more hours of training the model started to work as expected, i'm sorry for the useless issue."]}, {"number": 46344, "title": "tf.keras.callbacks.BaseLogger() is broken since \"metrics\" is no longer a key in Callback.params dict", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Oracle Linux Server 7.4\r\n- TensorFlow version (use command below): v2.3.0-54-gfcc4b966f1 2.3.1\r\n- Python version: 3.8.5\r\n\r\n**Problem description**\r\nI get an error when using tf.keras.callbacks.BaseLogger() since \"metrics\" is no longer a key of self.params within Callbacks. This same issue was handled in the new implementation of the TQDM progress bar Callback. The changes in code can be seen by checking the old and new versions of the TQDM callback.\r\n\r\nOld: https://github.com/tensorflow/addons/blob/r0.8/tensorflow_addons/callbacks/tqdm_progress_bar.py\r\nNew: https://github.com/tensorflow/addons/blob/v0.11.2/tensorflow_addons/callbacks/tqdm_progress_bar.py#L26-L259\r\n\r\n**Standalone code to reproduce the issue**\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nmodel = tf.keras.Sequential()\r\nmodel.add(tf.keras.layers.Dense(8, input_shape=(5,)))\r\nmodel.add(tf.keras.layers.Dense(1))\r\nmodel.compile(optimizer=\"Adam\", loss=\"binary_crossentropy\")\r\nx = np.random.rand(4,5)\r\ny = np.random.randint(0, 2, (4,))\r\nmodel.fit(x, y, epochs=10, callbacks=[tf.keras.callbacks.BaseLogger()])\r\n```\r\n\r\n**Output/Traceback**\r\nEpoch 1/10\r\n1/1 [==============================] - ETA: 0s - loss: 0.2872Traceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/scratch/emsu/py38_tf23/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\", line 108, in _method_wrapper\r\n    return method(self, *args, **kwargs)\r\n  File \"/scratch/emsu/py38_tf23/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\", line 1137, in fit\r\n    callbacks.on_epoch_end(epoch, epoch_logs)\r\n  File \"/scratch/emsu/py38_tf23/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\", line 416, in on_epoch_end\r\n    callback.on_epoch_end(epoch, numpy_logs)\r\n  File \"/scratch/emsu/py38_tf23/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\", line 873, in on_epoch_end\r\n    for k in self.params['metrics']:\r\nKeyError: 'metrics'\r\n", "comments": ["@CubasMike \r\nI ran the stand alone code shared and face a different error, please refer to the [gist here](https://colab.research.google.com/gist/Saduf2019/d37c9154077ce362b67b92eb527c60e8/untitled493.ipynb), if possible please share a colab gist with the error reported.", "> @CubasMike\r\n> I ran the stand alone code shared and face a different error, please refer to the [gist here](https://colab.research.google.com/gist/Saduf2019/d37c9154077ce362b67b92eb527c60e8/untitled493.ipynb), if possible please share a colab gist with the error reported.\r\n\r\nSorry, I copied the wrong line from the terminal. It should say:\r\n```python\r\nx = np.random.rand(4,5)\r\ny = np.random.randint(0, 2, (4,))\r\n```\r\n\r\nI updated the code with the correct line.", "I am able to replicate the issue reported, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/f2306d6dfdfdcc1a6c384dadb73da903/untitled495.ipynb)", "Was able to reproduce the issue in Tf Nighly 2.6 as well. Please find the gist [here](https://colab.research.google.com/gist/saikumarchalla/4c19285d753f1ad75c00829512911ee8/untitled90.ipynb).Thanks!", "@rmothukuru @Saduf2019  Have you had any luck with this issue? I have been hit by this and trying to understand what the Tensorflow team's vision is with BaseLogger.\r\n\r\nLooks like BaseLogger was applied by default on all keras model but this is only true for TensorFlow V1 models as indicated here https://github.com/tensorflow/tensorflow/blob/e104b6a9e87ea5956451ab56c1f5ca486c511bc4/tensorflow/python/keras/callbacks.py#L73-L112.\r\nI have been debugging into this code flow and it appears that BaseLogger is no longer applied by default to V2 models. \r\n\r\nAlso, it appears that BaseLogger is severely broken for use in v2 graphs as no such `metrics` exists in param https://github.com/tensorflow/tensorflow/blob/e104b6a9e87ea5956451ab56c1f5ca486c511bc4/tensorflow/python/keras/callbacks.py#L944. I think the right fix here is to change `self.params['metrics']`  to `logs.keys()`. However, looking at how averaging is done, that part also seems broken as `self.seem` is always zero for generator, dataset-based training as `batch` value is always 0 for those cases. Also, then here https://github.com/tensorflow/tensorflow/blob/e104b6a9e87ea5956451ab56c1f5ca486c511bc4/tensorflow/python/keras/callbacks.py#L927-L930\r\nno such thing as `size` or `num_steps` exists on log anymore on `v2` graphs, so the default of 0/1 is picked that makes seen ==0 leading to `ZeroDivisionError: float division by zero`. \r\n\r\nIs there another alternative approach recommended for BaseLogger for v2 then? Documentation seems to suggest https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/BaseLogger?hl=en BaseLogger continues to be applied on by default to all keras model v2 or v1 but I disagree with this, this is not true anymore with v2, I never break into this flow unless I have custom callback-based of BaseLogger.\r\n\r\nI am confused looking at inactivity on this issue, surely this should be a very critical bug that should be fixed ASAP if BaseLogger is the `the` way to add to customize log stream, if not what is the alternate method. \r\n\r\nIf I was to ignore BaseLogger completely, what is the recommended approach to write custom Callback so I can compute `seen` sample counts if I use generator/dataset based train where `model.fit` is not called with batch size?\r\n\r\nCould you please advise?\r\n\r\n\r\n", "@CubasMike \r\nPlease post this issue on [keras-team/keras repo](https://github.com/keras-team/keras/issues).\r\nTo know more refer to:\r\nhttps://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999", "@CubasMike This is a bug. Thanks for finding this bug.\r\n\r\nAs this is related to keras and keras code moved to a [separate repo](https://github.com/keras-team/keras/issues) to focus on only keras, we will track the  progress in the following issue which was already assigned to a codeowner.\r\nhttps://github.com/keras-team/keras/issues/15246\r\n\r\nSo, I am closing this issue here and lets track progress in keras-team/keras repo. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46344\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46344\">No</a>\n"]}, {"number": 46343, "title": "Missing headers (TensorFlow C, 2.4.0, Windows)", "body": "- OS Platform and Distribution: Windows\r\n- TensorFlow installed from: https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow-cpu-windows-x86_64-2.4.0.zip\r\n- TensorFlow version: 2.4.0\r\n\r\nWindows archive seems to be missing some header files. This leads to errors during build\r\n`tensorflow/c/tf_tensor.h(22,10): fatal error C1083: Cannot open include file: 'tensorflow/c/c_api_macros.h': No such file or directory`\r\n", "comments": ["What about\r\n```\r\ngit clone https://github.com/tensorflow/tensorflow.git\r\ncd tensorflow\r\ngit checkout r2.4\r\n```\r\nclone TF2.4\r\nthen, copy \"c_api_macros.h\" file from cloned directory\r\n", "I've just copied all missing headers from Linux version locally to make it work\r\nhttps://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow-cpu-linux-x86_64-2.4.0.tar.gz\r\n", "Were the headers present during 2.3?", "I tested @Nekto89's idea and mines also worked.", "https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow-cpu-windows-x86_64-2.4.0.zip is definitely missing some headers for me too.\r\nCopying headers from another archive **IS NOT** an acceptable solution.\r\n\r\nI see not a lot of efforts are put into TF C/C++, especially on Windows. \r\nTF C API is not even documented. \r\nTF C++ compiled dll doesn't even export the appropriate symbols.\r\nI dont know if you are aware, but Python is not the main technology used in the industry in production. There are a lot of Windows systems too. \r\nAnother reason to migrate to PyTorch.\r\n", "Still missing..\r\n", "Those headers exist in the `libtensorflow-gpu-windows-x86_64-2.5.0`.\r\n", "And from where should I get it ? I have searched this kit, `libtensorflow-gpu-windows-x86_65-2.5.0`, didn't find it. Could you put here the download page / link ?\r\n\r\nThank you.\r\n", "@flaviu22 The first Google result for \"libtensorflow\" is https://www.tensorflow.org/install/lang_c which contains the required links.\r\n\r\nCheers.", "@flaviu22 i had a typo in my comment (fixed). The link is here https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow-gpu-windows-x86_64-2.5.0.zip\r\n\r\nAnother option that might work for you is https://vcpkg.io/ (search for `tensorflow` -- it has both c and c++ api versions 2.4.1).\r\nI'm installing from vcpkg right now. ", "The headers were not present in 2.3\r\nBut I see that they are available in TF 2.5 and latest 2.6 release https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow-cpu-windows-x86_64-2.6.0.zip\r\n\r\nPerhaps we can close this now. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46343\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46343\">No</a>\n"]}, {"number": 46341, "title": "[XLA:GPU] Add a check to help prevent future bug", "body": "https://github.com/tensorflow/tensorflow/commit/67adc58cd64f3b86417d4466b6b656ecb8df3b2f\r\nFixed a wrong value bug. We got it by that for a long time and lost too much time due to it in parallel to you.\r\n\r\nSo to help prevent it from coming back, I added some extra check in the code. So if the codegen have this bug again, it will crash instead of producing wrong value.\r\n\r\n@cheshire ", "comments": ["The CI failure doesn't look related to my changes. It is an OOM error and my changes doesn't affect the memory used.", "let's try few more times, we've recently fixed an OOM in the OSS build", "@nouiz We also traced down a XLA/GPU bug with respect to dynamic scale with `tf.math.reduce_all` in `tf.keras.mixed_precision.LossScaleOptimizer` to check if the gradients overflow. \r\n\r\nThe commit you mentioned 67adc58 somehow fixed this issue but we don't know why. \r\n\r\nThis issue could be reproduced using official model garden RN50 with ``--loss_scale=dynamic``, under TF 2.3-2.4. TF 2.2 and nightlies after 67adc58 (tf-nightly==2.5.0.dev20201118) are not affected.\r\n\r\n/cc @reedwm ", "@byronyi Model garden models do not include XLA compilation though? Or are you using the CompiledTransformer variant?", "> @byronyi Model garden models do not include XLA compilation though? Or are you using the CompiledTransformer variant?\r\n\r\nIt's ResNet50 Keras model with XLA enabled. We use the r2.2.0 branch: https://github.com/tensorflow/models/tree/r2.2.0\r\n\r\nAnd the following command benchmark case on V100:\r\n\r\n```\r\nPYTHONPATH=$PWD/official \\\r\npython3 official/vision/image_classification/resnet/resnet_imagenet_main.py \\\r\n    --dd=<imagenet_dataset> \\\r\n    --ds=mirrored \\\r\n    --ara=nccl \\\r\n    --bs=3072 \\\r\n    --dtype=fp16 \\\r\n    --enable_xla \\\r\n    --use_tensor_lr \\\r\n    --datasets_num_private_threads=48 \\\r\n    --train_epochs=90 \\\r\n    --ebe=10 \\\r\n    --enable_checkpoint_and_export=True \\\r\n    --ls=dynamic   # only affect when dynamic loss scaling is enabled\r\n```\r\n\r\nThis issue has affected us since TF 2.3.0, and only got fixed in nightly after 67adc58.", "Found the offending commit c03e49d2c2d309cfa0c41d0892d9ffed5c485c4e.\r\n\r\nIt seems `__shfl*` intrinsics produces invalid values when block dim < 32.", "I think __shfl* instruction can be used when the block dim < 32.\r\nThe problem is the code that call them suppose block dim >= 32.\r\nThe function name tell the limitation: `EmitFullWarpShuffleDownLoopForReduce`. A full warp is 32 threads.\r\n\r\nI could have updated it work with small power of 2 or complex cases.\r\nBut using so few threads per block isn't good CUDA programming and will give very poor performance.\r\nSo instead of implementing a complex solution that shouldn't be used, I just make it raise an error. So no wrong value will appear in the future.\r\n\r\nIf we ever need to support cases when block dim < 32 in the future, we can just add it then.", "Did we resolve the issue?  Should https://github.com/tensorflow/tensorflow/commit/c03e49d2c2d309cfa0c41d0892d9ffed5c485c4e be rolled back?\r\n\r\nCC @akuegel ", "> Did we resolve the issue? Should [c03e49d](https://github.com/tensorflow/tensorflow/commit/c03e49d2c2d309cfa0c41d0892d9ffed5c485c4e) be rolled back?\r\n> \r\n> CC @akuegel\r\n\r\nIt's been fixed by 67adc58"]}, {"number": 46339, "title": "Update find_cuda_config.py", "body": "I copied it from r1.15. After changing those lines,  I could be able to get a build with CUDA 10.2. Otherwise configure script gets stuck.", "comments": ["We no longer update `r1.*` branches as all TF 1.x versions have reached end of support."]}, {"number": 46338, "title": "[cherry-pick:r2.4] Keras SavedModel: Ignore custom metrics failure when compile=False", "body": "As discussed in https://github.com/tensorflow/tensorflow/pull/45278#issuecomment-742875383, this PR cherrypicks #45278 onto the `r2.4` branch, in case there is a 2.4.1 patch release.\r\n\r\n/cc @mihaimaruseac", "comments": []}, {"number": 46337, "title": "Export all Types of python.keras.type as module (for type hints)", "body": "**System information**\r\n- TensorFlow version (you are using): 2.4.0\r\n- Are you willing to contribute it (Yes/No): No\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nWhen using type hints in python, it might be necessary to access the parent classes of e.g. keras layers.\r\n\r\nThey are defined in the file [tensorflow/tensorflow/python/keras/type/types.py](https://github.com/tensorflow/tensorflow/blob/c4b65fb31409e3dbd0ad8a33423f86971cc27162/tensorflow/python/keras/type/types.py).\r\n\r\nBecause there is no `__init__.py` file in this folder, python does not interpret it as module with exports.\r\nWe would need to create an `__init__.py` file with the appropriate class imports.\r\n\r\nCurrently, using a type hint like this: `net_layers: [tf.keras.type.Layer] = []` results in: `AttributeError: module 'tensorflow.keras' has no attribute 'type'`\r\n\r\n**Will this change the current api? How?** \r\nAlready existing classes will be made publicly available by a new module, but nothing should break.\r\n\r\n**Who will benefit with this feature?**\r\nEveryone who uses [typing / type hints](https://docs.python.org/3/library/typing.html). ([why use type hints?](https://stackoverflow.com/a/32558710))\r\n\r\n**Any Other info.**\r\nThere is already a [TODO hint (types.py:30)](https://github.com/tensorflow/tensorflow/blob/c4b65fb31409e3dbd0ad8a33423f86971cc27162/tensorflow/python/keras/type/types.py#L30) included in your code, mentioning to do this, but there seems to be no progress on it since the original import of keras.\r\n\r\n", "comments": ["This `types` file is an experiment for the time being. It would be a significant effort to list all of our class interfaces in there. If we eventually get to do it, we can expose it as a module, but we won't do it for the time being.", "tf.keras.types is also trying to align with the tensorflow/python/types.py, which is currently under implementation as well. See more details at https://github.com/tensorflow/tensorflow/tree/master/tensorflow/python/types."]}, {"number": 46335, "title": "Fix tablegen definitions of ops base structs", "body": "Prior to this the build failed with erros like:\r\n```\r\n[build] [..] lhlo_gpu_ops_structs.td:35:18: error: Value 'summary' unknown!\r\n[build]    let summary = \"GPU Convolution backend configuration\";\r\n```", "comments": ["Tested against an outdated LLVM commit, so this is obsolete."]}, {"number": 46334, "title": "Error when compiling a fully-integer quantized model for the EdgeTPU", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (or github SHA if from source): tf-nightly\r\n\r\n\r\n**Command used to run the converter or code if you\u2019re using the Python API**\r\nIf possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n```\r\nimport cv2\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\ndef representative_dataset_gen():\r\n\tfor image in raw_image_paths:\r\n\t\timage = cv2.imread(image)\r\n\t\timage = cv2.resize(image, (128, 256))\r\n\t\timage = image[..., ::-1]\r\n\t\timage = image * (1 / 255)\r\n\t\timage[0, ...] = (image[0, ...] - 0.485) / 0.229\r\n\t\timage[1, ...] = (image[1, ...] - 0.456) / 0.224\r\n\t\timage[2, ...] = (image[2, ...] - 0.406) / 0.225\r\n\t\timage = tf.expand_dims(tf.convert_to_tensor(image, dtype = tf.float32), axis = 0)\r\n\t\tyield [image]\r\n\r\nwith open('selected_files.txt') as f:\r\n\traw_image_paths = f.read().split('\\n')[:-1]\r\n\r\n# Full Integer Quantization - Input/Output=float32\r\nconverter = tf.lite.TFLiteConverter.from_saved_model('/home/parth/Internships/Clutterbot/Trial_4/saved_model')\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\r\nconverter.inference_input_type = tf.uint8\r\nconverter.inference_output_type = tf.uint8\r\nconverter.allow_custom_ops = True\r\nconverter.representative_dataset = representative_dataset_gen\r\ntflite_quant_model = converter.convert()\r\n```\r\n\r\n**The output from the converter invocation**\r\n\r\n```\r\nNo issues here\r\n```\r\n\r\n**Also, please include a link to the saved model or GraphDef**\r\nThe Zip file contains the Saved_Model, as well as the full-integer quantized TFLite model.\r\n[osnet_x0_25_msmt17_batch_1.zip](https://github.com/tensorflow/tensorflow/files/5794906/osnet_x0_25_msmt17_batch_1.zip)\r\n\r\n**Failure details**\r\nIf the conversion is successful, but the generated model is wrong,\r\nstate what is wrong:\r\n - The conversion is successful\r\n - The issue arises when trying to compile the TFLite model for the EdgeTPU.\r\n ```\r\nEdge TPU Compiler version 15.0.340273435\r\nloc(\"model/depthwise_conv2d_3/depthwise\"): error: Invalid argument: Quantized tensors must have non-zero scales\r\nerror: could not translate function : Quantized tensors must have non-zero scales\r\n\r\nInternal compiler error. Aborting! \r\n```\r\n\r\n**Any other info / logs**\r\nI have also mentioned the error in the issue [here](https://github.com/google-coral/edgetpu/issues/290).\r\n", "comments": ["@jingpu could you take a look at this?", "@arsenal-2004 Could you attached the converted TFLite model?", "@jingpu I have attached the TFLite model as part of the Zip file.\r\n> [osnet_x0_25_msmt17_batch_1.zip](https://github.com/tensorflow/tensorflow/files/5794906/osnet_x0_25_msmt17_batch_1.zip)\r\n\r\nThank you for your help :)\r\n\r\n\r\n", "@jingpu I have also attached the original Saved_Model, in case you want to convert it with some different settings.", "I looked at the converted TFLite model. The weight of the \"model/depthwise_conv2d_3/depthwise\" node is INT8 type but doesn't have quantization parameter, which causes the Edge TPU compiler to raise the error. \r\n@abattery Could you take a look if the conversion is correct?", "@jingpu How did you check that? I used Netron and it does show a quantization parameter, although it's quite small.\r\n![image](https://user-images.githubusercontent.com/32266223/104227304-2e4f8b00-546f-11eb-8dd9-38c73c7b9d80.png)\r\n", "The input and output do have quantization parameters, but the weights and bias don't.\r\n\r\n![image](https://user-images.githubusercontent.com/2155368/104228115-3e2f8680-53ff-11eb-8182-35aab1b5225e.png)\r\n\r\n", "Oh okay. I guess I misunderstood. I thought that since even the Conv2D nodes do not have a quantization parameter for the 'filter' and 'bias', none of the nodes would have it", "I dug a little more. It seems like the weights have quantization parameter but it is using per-axis quantization and Netron fails to visualize it.\r\n\r\nAnd so the real issue is for one of the axis the quantization scale is zero, which I think it is a bug in the quantizer of the TFLite Converter.", "Oh okay. That seems like it would take a while to resolve. Thank you though.\r\n\r\nIf I may ask, do you know of any person-reid models that have been tested on the Coral? I have been looking a lot but couldn't get anything like that.", "Parth, you can set `converter._experimental_new_quantizer=True` to avoid the zero scale issue. The new quantizer will set the scale to fixed small value and hopefully the edge tpu compiler can handle that.", "@liufengdb @abattery @jingpu Thank you guys so much. Using the new quantizer worked for the compilation :)\r\nI'll try out the new compiled model today and see if the results are as expected. If it works out, I'll close this issue in the evening", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46334\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46334\">No</a>\n"]}, {"number": 46333, "title": "Docker install", "body": "Mac OS Big Sur 11.0.1\r\nDocker\r\n\r\nMount local warehouse\r\n\r\n sudo docker run -itd -p 8888:8888 -v /Users/kh/Desktop/Tensorflow/work:/work tensoflow/tensorflow:2.2.0-jupyter bash\r\n\r\nThe operation failed.\r\nError content:\r\nUnable to find image 'tensoflow/tensorflow:2.2.0-jupyter' locally\r\ndocker: Error response from daemon: pull access denied for tensoflow/tensorflow, repository does not exist or may require 'docker login': denied: requested access to the resource is denied.\r\nSee 'docker run --help'.\r\n\r\nBut when I try not to mount the local warehouse:\r\n\r\nsudo docker run -it -p 8888:8888 tensorflow/tensorflow:2.2.0-jupyter\r\n\r\nCan run successfully.\r\n\r\n", "comments": ["@sinduke \r\n\r\nCan you try with latest stable TF version 2.4 and see if the issue still persists.\r\nStill if you are facing the issue please Provide the exact sequence of commands / steps that you executed before running into the problem. Thanks!", "kh@khdeMacBook-Pro-2 work % sudo docker run -it -p 8888:8888 tensorflow/tensorflow:2.4.0-jupyter  \r\n[I 03:20:30.341 NotebookApp] Writing notebook server cookie secret to /root/.local/share/jupyter/runtime/notebook_cookie_secret\r\njupyter_http_over_ws extension initialized. Listening on /http_over_websocket\r\n[I 03:20:30.602 NotebookApp] Serving notebooks from local directory: /tf\r\n[I 03:20:30.602 NotebookApp] Jupyter Notebook 6.1.5 is running at:\r\n[I 03:20:30.603 NotebookApp] http://b1ef941107e0:8888/?token=064b8f0e6146b775f4b4e85cb50920a8a230110ebb976b1e\r\n[I 03:20:30.603 NotebookApp]  or http://127.0.0.1:8888/?token=064b8f0e6146b775f4b4e85cb50920a8a230110ebb976b1e\r\n[I 03:20:30.603 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).\r\n[C 03:20:30.612 NotebookApp] \r\n\r\n\r\nkh@khdeMacBook-Pro-2 work % sudo docker run -itd -p 8888:8888 -v /Users/kh/Desktop/Tensorflow/work:/work tensoflow/tensorflow:2.4.0-jupyter bash\r\nPassword:\r\nUnable to find image 'tensoflow/tensorflow:2.4.0-jupyter' locally\r\ndocker: Error response from daemon: pull access denied for tensoflow/tensorflow, repository does not exist or may require 'docker login': denied: requested access to the resource is denied.\r\nSee 'docker run --help'.\r\n\r\nStill the same. The above is the execution process I use 2.4.0\r\n", "Is there anything else I need to provide?", "sudo docker run -itd -p 8888:8888 -v /Users/kh/Desktop/Tensorflow/work:/work **tensoflow**/tensorflow:2.4.0-jupyter bash\r\n\r\nThis should be \"tensorflow.\" The \"r\" is missing.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46333\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46333\">No</a>\n"]}, {"number": 46332, "title": "The final solution for the sigmoid_cross_entropy_with_logits is different between tensorflow 1.0 and tensorflow 2.0", "body": "Under the version of tensorflow 2.40, we run following codes:\r\n```python\r\nimport tensorflow as tf\r\na = np.zeros((2,2))\r\ntest_image = tf.constant(a, dtype=tf.float32)\r\nd_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=test_image, labels = tf.ones_like(test_image)))\r\nprint(d_loss_real)\r\nAnd the result is : tf.Tensor(0.6931472, shape=(), dtype=float32)\r\n```\r\nHowever, when I run the above codes by this way:\r\n```python\r\nimport tensorflow.compat.v1 as tf\r\ntf.disable_v2_behavior()\r\na = np.zeros((2,2))\r\ntest_image = tf.constant(a, dtype=tf.float32)\r\nd_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=test_image, labels = tf.ones_like(test_image)))\r\nprint(d_loss_real)\r\nAnd the result is:  Tensor(\"Mean:0\", shape=(), dtype=float32)\r\n```\r\nAs both the results are scalar, but the error is too large between these two versions. \r\nCould you please explain it? Thank you very much. \r\nAdditionally, the initial weights for neural layers between TensorFlow v1.0 and v2.0 are also seemly different. Is that so?\r\n", "comments": ["Was able to reproduce the issue with TF v2.3, TF v2.4 and TF-nightly. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/3852767666465681d46de65adb79be5d/46332.ipynb). Thanks!", "With  `tf.disable_v2_behavior()` (TF 1.X versions) you cannot see the content of actual tensor unless you evaluate it in a session.\r\nCurrently you see;\r\n```python\r\nTensor(\"Mean:0\", shape=(), dtype=float32)\r\n```\r\nwhere `Mean:0` is the type of operation\r\n `shape=()` is the dimension of the tensor\r\n `dtype=float32` is datatype of the elements in tensor\r\n\r\nTo see the actual value of the tensor you need to evaluate it in a session.\r\nAdd following lines at end of the your code snippet.\r\n```python\r\nwith tf.Session() as sess: \r\n   print(d_loss_real.eval()) \r\n```\r\nOutput:\r\n```python\r\nTensor(\"Mean:0\", shape=(), dtype=float32)\r\n0.6931472\r\n```\r\n", "Thank you very much. I ignore the important details. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46332\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46332\">No</a>\n"]}, {"number": 46331, "title": "Remove cusparseDnVecDescr_t from cusparse_10_1.inc", "body": "This pr removes `cusparseDnVecDescr_t` and `cusparseSpVecDescr_t` relevant functions in `cusparse_10_1.inc` because those types were introduced in cuda 10.2.\r\n\r\nThis pr also removes some functions in `cusparse_10_1.inc` that would trigger errors like:\r\n\r\n```\r\nExecution platform: @local_execution_config_platform//:platform\r\nIn file included from tensorflow/stream_executor/cuda/cusparse_stub.cc:59:0:\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc: In function 'cusparseStatus_t cusparseDnMatGetStridedBatch(cusparseDnMatDescr_t, int*, int64_t*)':\r\n./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7932:1: error: conflicting declaration of C function 'cusparseStatus_t cusparseDnMatGetStridedBatch(cusparseDnMatDescr_t, int*, int64_t*)'\r\n cusparseDnMatGetStridedBatch(const cusparseDnMatDescr_t dnMatDescr,\r\n ^~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n```\r\n\r\nThank you for your time on reviewing this pr.", "comments": ["The file does say:\r\n> // Auto-generated, do not edit.\r\n\r\nIs there a generator to modify instead? Regardless, I'm probably not a good reviewer for this change.", "@allenlavoie\r\nI agree that it would be better to regenerate the inc file for cuda 10.1. But I have no idea how to do that...", "I have it on my queue to finally open-source the generator. It's unfortunately tied to the internal build currently. But we have a version in tensorflow/runtime that works in open source. The plan is to carry that one over."]}, {"number": 46330, "title": "Encountered error when building tensorflow with TPU support", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution: Linux Ubuntu 18.04\r\n- TensorFlow installed from: source\r\n- TensorFlow version: github master branch\r\n- Python version: 3.6\r\n- Bazel version: 3.7.2\r\n- GCC/Compiler version: 7.5.0\r\n- CUDA/cuDNN version: no CUDA support  \r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nI'm trying Cloud TPU on GCP, and is building tensorflow with TPU support from source code.\r\nThe build command: bazel build --config=opt --distinct_host_configuration=false --define=framework_shared_object=false --define=with_tpu_support=true //tensorflow/tools/pip_package:build_pip_package\r\nThe build failed with error info: /home/liushijun/tensorflow/tensorflow/python/tools/BUILD:282:10 Executing genrule //tensorflow/python/keras/api:keras_python_api_gen_compat_v2 failed (Aborted): bash failed: error executing command.\r\n\r\nI tried to re-install Keras-preprocessing, bu still failed with the same error.\r\n\r\nThen I also found another info in the messed log: 2021-01-11 07:17:46.832743: F ./tensorflow/core/tpu/tpu_library_init_fns.inc:33] TpuCompile_XrtCompileAndBuild not available in this library.\r\n\r\nAny clue of this error?\r\n\r\n**Any other info / logs**\r\nThe whole log here:\r\nERROR: /home/liushijun/tensorflow/tensorflow/python/keras/api/BUILD:138:19: Executing genrule //tensorflow/python/keras/api:keras_python_api_gen_compat_v2 failed (Aborted): bash failed: error executing command \r\n  (cd /home/liushijun/.cache/bazel/_bazel_liushijun/5b47ddbf1618141ff87889ecf7bd0be1/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    PATH=/home/liushijun/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/home/liushijun/bin:/home/liushijun/bin:/home/liushijun/bin:/usr/local/lib/python3.6 \\\r\n    PYTHON_BIN_PATH=/usr/bin/python3 \\\r\n    PYTHON_LIB_PATH=/usr/lib/python3/dist-packages \\\r\n    TF2_BEHAVIOR=1 \\\r\n    TF_CONFIGURE_IOS=0 \\\r\n  /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/k8-opt/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen_compat_v2  --apidir=bazel-out/k8-opt/bin/tensorflow/python/keras/api_v2/ --apiname=keras --apiversion=2  --loading=default --package=tensorflow.python,tensorflow.python.keras,tensorflow.python.keras.activations,tensorflow.python.keras.applications.densenet,tensorflow.python.keras.applications.efficientnet,tensorflow.python.keras.applications.imagenet_utils,tensorflow.python.keras.applications.inception_resnet_v2,tensorflow.python.keras.applications.inception_v3,tensorflow.python.keras.applications.mobilenet,tensorflow.python.keras.applications.mobilenet_v2,tensorflow.python.keras.applications.mobilenet_v3,tensorflow.python.keras.applications.nasnet,tensorflow.python.keras.applications.resnet,tensorflow.python.keras.applications.resnet_v2,tensorflow.python.keras.applications.vgg16,tensorflow.python.keras.applications.vgg19,tensorflow.python.keras.applications.xception,tensorflow.python.keras.backend,tensorflow.python.keras.backend_config,tensorflow.python.keras.callbacks,tensorflow.python.keras.callbacks_v1,tensorflow.python.keras.constraints,tensorflow.python.keras.datasets.boston_housing,tensorflow.python.keras.datasets.cifar10,tensorflow.python.keras.datasets.cifar100,tensorflow.python.keras.datasets.fashion_mnist,tensorflow.python.keras.datasets.imdb,tensorflow.python.keras.datasets.mnist,tensorflow.python.keras.datasets.reuters,tensorflow.python.keras.engine.base_layer,tensorflow.python.keras.engine.data_adapter,tensorflow.python.keras.engine.input_layer,tensorflow.python.keras.engine.input_spec,tensorflow.python.keras.engine.sequential,tensorflow.python.keras.engine.training,tensorflow.python.keras.estimator,tensorflow.python.keras.feature_column.sequence_feature_column,tensorflow.python.keras.initializers,tensorflow.python.keras.initializers.initializers_v1,tensorflow.python.keras.initializers.initializers_v2,tensorflow.python.keras.layers.advanced_activations,tensorflow.python.keras.layers.convolutional,tensorflow.python.keras.layers.convolutional_recurrent,tensorflow.python.keras.layers.core,tensorflow.python.keras.layers.cudnn_recurrent,tensorflow.python.keras.layers.dense_attention,tensorflow.python.keras.layers.embeddings,tensorflow.python.keras.layers.local,tensorflow.python.keras.layers.merge,tensorflow.python.keras.layers.noise,tensorflow.python.keras.layers.normalization,tensorflow.python.keras.layers.normalization_v2,tensorflow.python.keras.layers.preprocessing,tensorflow.python.keras.layers.pooling,tensorflow.python.keras.layers.recurrent,tensorflow.python.keras.layers.recurrent_v2,tensorflow.python.keras.layers.serialization,tensorflow.python.keras.layers.wrappers,tensorflow.python.keras.losses,tensorflow.python.keras.metrics,tensorflow.python.keras.mixed_precision.get_layer_policy,tensorflow.python.keras.mixed_precision.loss_scale_optimizer,tensorflow.python.keras.mixed_precision.policy,tensorflow.python.keras.models,tensorflow.python.keras.optimizer_v2.adadelta,tensorflow.python.keras.optimizer_v2.adagrad,tensorflow.python.keras.optimizer_v2.adam,tensorflow.python.keras.optimizer_v2.adamax,tensorflow.python.keras.optimizer_v2.ftrl,tensorflow.python.keras.optimizer_v2.gradient_descent,tensorflow.python.keras.optimizer_v2.learning_rate_schedule,tensorflow.python.keras.optimizer_v2.nadam,tensorflow.python.keras.optimizer_v2.optimizer_v2,tensorflow.python.keras.optimizer_v2.rmsprop,tensorflow.python.keras.optimizers,tensorflow.python.keras.premade.linear,tensorflow.python.keras.premade.wide_deep,tensorflow.python.keras.preprocessing.image,tensorflow.python.keras.preprocessing.sequence,tensorflow.python.keras.preprocessing.text,tensorflow.python.keras.regularizers,tensorflow.python.keras.saving.model_config,tensorflow.python.keras.saving.save,tensorflow.python.keras.saving.saved_model_experimental,tensorflow.python.keras.utils.data_utils,tensorflow.python.keras.utils.generic_utils,tensorflow.python.keras.utils.io_utils,tensorflow.python.keras.utils.layer_utils,tensorflow.python.keras.utils.losses_utils,tensorflow.python.keras.utils.multi_gpu_utils,tensorflow.python.keras.utils.np_utils,tensorflow.python.keras.utils.vis_utils,tensorflow.python.keras.wrappers.scikit_learn --output_package=tensorflow.python.keras.api._v2 --use_relative_imports=True bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/activations/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/densenet/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/efficientnet/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/imagenet_utils/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/inception_resnet_v2/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/inception_v3/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/mobilenet/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/mobilenet_v2/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/mobilenet_v3/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/nasnet/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/resnet/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/resnet_v2/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/resnet50/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/vgg16/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/vgg19/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/xception/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/backend/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/callbacks/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/callbacks/experimental/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/constraints/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/datasets/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/datasets/boston_housing/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/datasets/cifar10/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/datasets/cifar100/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/datasets/fashion_mnist/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/datasets/imdb/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/datasets/mnist/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/datasets/reuters/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/estimator/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/experimental/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/initializers/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/layers/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/layers/experimental/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/layers/experimental/preprocessing/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/losses/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/metrics/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/mixed_precision/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/mixed_precision/experimental/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/premade/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/models/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/optimizers/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/optimizers/schedules/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/preprocessing/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/preprocessing/image/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/preprocessing/sequence/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/preprocessing/text/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/regularizers/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/utils/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/wrappers/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/wrappers/scikit_learn/__init__.py')\r\nExecution platform: @local_execution_config_platform//:platform\r\n2021-01-11 07:17:46.832743: F ./tensorflow/core/tpu/tpu_library_init_fns.inc:33] TpuCompile_XrtCompileAndBuild not available in this library.\r\n/bin/bash: line 1: 71019 Aborted                 (core dumped) bazel-out/k8-opt/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen_compat_v2 --apidir=bazel-out/k8-opt/bin/tensorflow/python/keras/api_v2/ --apiname=keras --apiversion=2 --loading=default --package=tensorflow.python,tensorflow.python.keras,tensorflow.python.keras.activations,tensorflow.python.keras.applications.densenet,tensorflow.python.keras.applications.efficientnet,tensorflow.python.keras.applications.imagenet_utils,tensorflow.python.keras.applications.inception_resnet_v2,tensorflow.python.keras.applications.inception_v3,tensorflow.python.keras.applications.mobilenet,tensorflow.python.keras.applications.mobilenet_v2,tensorflow.python.keras.applications.mobilenet_v3,tensorflow.python.keras.applications.nasnet,tensorflow.python.keras.applications.resnet,tensorflow.python.keras.applications.resnet_v2,tensorflow.python.keras.applications.vgg16,tensorflow.python.keras.applications.vgg19,tensorflow.python.keras.applications.xception,tensorflow.python.keras.backend,tensorflow.python.keras.backend_config,tensorflow.python.keras.callbacks,tensorflow.python.keras.callbacks_v1,tensorflow.python.keras.constraints,tensorflow.python.keras.datasets.boston_housing,tensorflow.python.keras.datasets.cifar10,tensorflow.python.keras.datasets.cifar100,tensorflow.python.keras.datasets.fashion_mnist,tensorflow.python.keras.datasets.imdb,tensorflow.python.keras.datasets.mnist,tensorflow.python.keras.datasets.reuters,tensorflow.python.keras.engine.base_layer,tensorflow.python.keras.engine.data_adapter,tensorflow.python.keras.engine.input_layer,tensorflow.python.keras.engine.input_spec,tensorflow.python.keras.engine.sequential,tensorflow.python.keras.engine.training,tensorflow.python.keras.estimator,tensorflow.python.keras.feature_column.sequence_feature_column,tensorflow.python.keras.initializers,tensorflow.python.keras.initializers.initializers_v1,tensorflow.python.keras.initializers.initializers_v2,tensorflow.python.keras.layers.advanced_activations,tensorflow.python.keras.layers.convolutional,tensorflow.python.keras.layers.convolutional_recurrent,tensorflow.python.keras.layers.core,tensorflow.python.keras.layers.cudnn_recurrent,tensorflow.python.keras.layers.dense_attention,tensorflow.python.keras.layers.embeddings,tensorflow.python.keras.layers.local,tensorflow.python.keras.layers.merge,tensorflow.python.keras.layers.noise,tensorflow.python.keras.layers.normalization,tensorflow.python.keras.layers.normalization_v2,tensorflow.python.keras.layers.preprocessing,tensorflow.python.keras.layers.pooling,tensorflow.python.keras.layers.recurrent,tensorflow.python.keras.layers.recurrent_v2,tensorflow.python.keras.layers.serialization,tensorflow.python.keras.layers.wrappers,tensorflow.python.keras.losses,tensorflow.python.keras.metrics,tensorflow.python.keras.mixed_precision.get_layer_policy,tensorflow.python.keras.mixed_precision.loss_scale_optimizer,tensorflow.python.keras.mixed_precision.policy,tensorflow.python.keras.models,tensorflow.python.keras.optimizer_v2.adadelta,tensorflow.python.keras.optimizer_v2.adagrad,tensorflow.python.keras.optimizer_v2.adam,tensorflow.python.keras.optimizer_v2.adamax,tensorflow.python.keras.optimizer_v2.ftrl,tensorflow.python.keras.optimizer_v2.gradient_descent,tensorflow.python.keras.optimizer_v2.learning_rate_schedule,tensorflow.python.keras.optimizer_v2.nadam,tensorflow.python.keras.optimizer_v2.optimizer_v2,tensorflow.python.keras.optimizer_v2.rmsprop,tensorflow.python.keras.optimizers,tensorflow.python.keras.premade.linear,tensorflow.python.keras.premade.wide_deep,tensorflow.python.keras.preprocessing.image,tensorflow.python.keras.preprocessing.sequence,tensorflow.python.keras.preprocessing.text,tensorflow.python.keras.regularizers,tensorflow.python.keras.saving.model_config,tensorflow.python.keras.saving.save,tensorflow.python.keras.saving.saved_model_experimental,tensorflow.python.keras.utils.data_utils,tensorflow.python.keras.utils.generic_utils,tensorflow.python.keras.utils.io_utils,tensorflow.python.keras.utils.layer_utils,tensorflow.python.keras.utils.losses_utils,tensorflow.python.keras.utils.multi_gpu_utils,tensorflow.python.keras.utils.np_utils,tensorflow.python.keras.utils.vis_utils,tensorflow.python.keras.wrappers.scikit_learn --output_package=tensorflow.python.keras.api._v2 --use_relative_imports=True bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/activations/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/densenet/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/efficientnet/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/imagenet_utils/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/inception_resnet_v2/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/inception_v3/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/mobilenet/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/mobilenet_v2/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/mobilenet_v3/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/nasnet/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/resnet/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/resnet_v2/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/resnet50/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/vgg16/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/vgg19/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/xception/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/backend/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/callbacks/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/callbacks/experimental/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/constraints/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/datasets/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/datasets/boston_housing/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/datasets/cifar10/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/datasets/cifar100/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/datasets/fashion_mnist/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/datasets/imdb/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/datasets/mnist/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/datasets/reuters/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/estimator/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/experimental/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/initializers/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/layers/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/layers/experimental/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/layers/experimental/preprocessing/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/losses/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/metrics/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/mixed_precision/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/mixed_precision/experimental/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/premade/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/models/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/optimizers/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/optimizers/schedules/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/preprocessing/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/preprocessing/image/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/preprocessing/sequence/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/preprocessing/text/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/regularizers/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/utils/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/wrappers/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/wrappers/scikit_learn/__init__.py\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nERROR: /home/liushijun/tensorflow/tensorflow/python/tools/BUILD:282:10 Executing genrule //tensorflow/python/keras/api:keras_python_api_gen_compat_v2 failed (Aborted): bash failed: error executing command \r\n  (cd /home/liushijun/.cache/bazel/_bazel_liushijun/5b47ddbf1618141ff87889ecf7bd0be1/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    PATH=/home/liushijun/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/home/liushijun/bin:/home/liushijun/bin:/home/liushijun/bin:/usr/local/lib/python3.6 \\\r\n    PYTHON_BIN_PATH=/usr/bin/python3 \\\r\n    PYTHON_LIB_PATH=/usr/lib/python3/dist-packages \\\r\n    TF2_BEHAVIOR=1 \\\r\n    TF_CONFIGURE_IOS=0 \\\r\n  /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/k8-opt/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen_compat_v2  --apidir=bazel-out/k8-opt/bin/tensorflow/python/keras/api_v2/ --apiname=keras --apiversion=2  --loading=default --package=tensorflow.python,tensorflow.python.keras,tensorflow.python.keras.activations,tensorflow.python.keras.applications.densenet,tensorflow.python.keras.applications.efficientnet,tensorflow.python.keras.applications.imagenet_utils,tensorflow.python.keras.applications.inception_resnet_v2,tensorflow.python.keras.applications.inception_v3,tensorflow.python.keras.applications.mobilenet,tensorflow.python.keras.applications.mobilenet_v2,tensorflow.python.keras.applications.mobilenet_v3,tensorflow.python.keras.applications.nasnet,tensorflow.python.keras.applications.resnet,tensorflow.python.keras.applications.resnet_v2,tensorflow.python.keras.applications.vgg16,tensorflow.python.keras.applications.vgg19,tensorflow.python.keras.applications.xception,tensorflow.python.keras.backend,tensorflow.python.keras.backend_config,tensorflow.python.keras.callbacks,tensorflow.python.keras.callbacks_v1,tensorflow.python.keras.constraints,tensorflow.python.keras.datasets.boston_housing,tensorflow.python.keras.datasets.cifar10,tensorflow.python.keras.datasets.cifar100,tensorflow.python.keras.datasets.fashion_mnist,tensorflow.python.keras.datasets.imdb,tensorflow.python.keras.datasets.mnist,tensorflow.python.keras.datasets.reuters,tensorflow.python.keras.engine.base_layer,tensorflow.python.keras.engine.data_adapter,tensorflow.python.keras.engine.input_layer,tensorflow.python.keras.engine.input_spec,tensorflow.python.keras.engine.sequential,tensorflow.python.keras.engine.training,tensorflow.python.keras.estimator,tensorflow.python.keras.feature_column.sequence_feature_column,tensorflow.python.keras.initializers,tensorflow.python.keras.initializers.initializers_v1,tensorflow.python.keras.initializers.initializers_v2,tensorflow.python.keras.layers.advanced_activations,tensorflow.python.keras.layers.convolutional,tensorflow.python.keras.layers.convolutional_recurrent,tensorflow.python.keras.layers.core,tensorflow.python.keras.layers.cudnn_recurrent,tensorflow.python.keras.layers.dense_attention,tensorflow.python.keras.layers.embeddings,tensorflow.python.keras.layers.local,tensorflow.python.keras.layers.merge,tensorflow.python.keras.layers.noise,tensorflow.python.keras.layers.normalization,tensorflow.python.keras.layers.normalization_v2,tensorflow.python.keras.layers.preprocessing,tensorflow.python.keras.layers.pooling,tensorflow.python.keras.layers.recurrent,tensorflow.python.keras.layers.recurrent_v2,tensorflow.python.keras.layers.serialization,tensorflow.python.keras.layers.wrappers,tensorflow.python.keras.losses,tensorflow.python.keras.metrics,tensorflow.python.keras.mixed_precision.get_layer_policy,tensorflow.python.keras.mixed_precision.loss_scale_optimizer,tensorflow.python.keras.mixed_precision.policy,tensorflow.python.keras.models,tensorflow.python.keras.optimizer_v2.adadelta,tensorflow.python.keras.optimizer_v2.adagrad,tensorflow.python.keras.optimizer_v2.adam,tensorflow.python.keras.optimizer_v2.adamax,tensorflow.python.keras.optimizer_v2.ftrl,tensorflow.python.keras.optimizer_v2.gradient_descent,tensorflow.python.keras.optimizer_v2.learning_rate_schedule,tensorflow.python.keras.optimizer_v2.nadam,tensorflow.python.keras.optimizer_v2.optimizer_v2,tensorflow.python.keras.optimizer_v2.rmsprop,tensorflow.python.keras.optimizers,tensorflow.python.keras.premade.linear,tensorflow.python.keras.premade.wide_deep,tensorflow.python.keras.preprocessing.image,tensorflow.python.keras.preprocessing.sequence,tensorflow.python.keras.preprocessing.text,tensorflow.python.keras.regularizers,tensorflow.python.keras.saving.model_config,tensorflow.python.keras.saving.save,tensorflow.python.keras.saving.saved_model_experimental,tensorflow.python.keras.utils.data_utils,tensorflow.python.keras.utils.generic_utils,tensorflow.python.keras.utils.io_utils,tensorflow.python.keras.utils.layer_utils,tensorflow.python.keras.utils.losses_utils,tensorflow.python.keras.utils.multi_gpu_utils,tensorflow.python.keras.utils.np_utils,tensorflow.python.keras.utils.vis_utils,tensorflow.python.keras.wrappers.scikit_learn --output_package=tensorflow.python.keras.api._v2 --use_relative_imports=True bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/activations/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/densenet/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/efficientnet/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/imagenet_utils/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/inception_resnet_v2/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/inception_v3/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/mobilenet/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/mobilenet_v2/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/mobilenet_v3/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/nasnet/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/resnet/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/resnet_v2/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/resnet50/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/vgg16/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/vgg19/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/applications/xception/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/backend/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/callbacks/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/callbacks/experimental/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/constraints/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/datasets/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/datasets/boston_housing/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/datasets/cifar10/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/datasets/cifar100/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/datasets/fashion_mnist/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/datasets/imdb/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/datasets/mnist/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/datasets/reuters/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/estimator/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/experimental/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/initializers/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/layers/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/layers/experimental/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/layers/experimental/preprocessing/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/losses/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/metrics/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/mixed_precision/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/mixed_precision/experimental/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/premade/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/models/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/optimizers/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/optimizers/schedules/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/preprocessing/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/preprocessing/image/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/preprocessing/sequence/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/preprocessing/text/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/regularizers/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/utils/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/wrappers/__init__.py bazel-out/k8-opt/bin/tensorflow/python/keras/api/_v2/keras/wrappers/scikit_learn/__init__.py')\r\nExecution platform: @local_execution_config_platform//:platform\r\nINFO: Elapsed time: 762.285s, Critical Path: 329.93s\r\nINFO: 8903 processes: 128 internal, 8775 local.\r\nFAILED: Build did NOT complete successfully\r\n\r\n", "comments": ["Hi @THULiusj, are you trying to use TPUs with Google Compute Engine (GCE)? I'm linking to the GCP [TPU documentation here](https://cloud.google.com/tpu/docs/quickstart), in case you haven't seen it, which shows how to use the ctpu tool to use TPUs (much easier than building from source)\r\nIf you do need to build from source, to isolate the issue can you try building first without the TPU flag and see if that works?", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46330\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46330\">No</a>\n"]}]