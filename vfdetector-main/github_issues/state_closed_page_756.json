[{"number": 30880, "title": "[INTEL_MKL] Parallelizing scatter update op.", "body": "This is a follow up for https://github.com/tensorflow/tensorflow/pull/30375 and fixes the regression failure.\r\n\r\nINTRA_OP=1\r\nBenchmark Time(ns) Iterations\r\nBM_ScatterAddInt32/1 89109380 100 11.2M items/s\r\nBM_ScatterAddInt32/10 123866710 100 80.7M items/s\r\nBM_ScatterAddInt32/64 177304560 100 361.0M items/s\r\nBM_ScatterAddInt32/256 270029460 100 948.0M items/s\r\nBM_ScatterAddInt32/1024 762985280 100 1342.1M items/s\r\n\r\nINTRA_OP=13\r\nRunning main() from test_main.cc\r\nBenchmark Time(ns) Iterations\r\nBM_ScatterAddInt32/1 47192100 100 21.2M items/s\r\nBM_ScatterAddInt32/10 48498980 100 206.2M items/s\r\nBM_ScatterAddInt32/64 52246600 100 1225.0M items/s\r\nBM_ScatterAddInt32/256 70786030 100 3616.5M items/s\r\nBM_ScatterAddInt32/1024 150688620 100 6795.5M items/s", "comments": ["@penpornk Gentle reminder for reviewing!", "Hi @penpornk, I have made the changes requested. Please let me know if they are okay. Thanks", "@penpornk Done!", "Hi @penpornk , Please let me know how the tests look. The failing test has passed this time!", "Hi @Srini511, Sorry for the delay! There is a compilation error in scatter_functor.h:\r\n```\r\nerror: variable length array used [-Werror,-Wvla]\r\n    mutex accessed[num_locks];\r\n```\r\nPlease either dynamically allocate the array or use `kMaxLock`.", "Hi @penpornk , how did the tests pass then?", "@penpornk Pushed the change to fix the array allocation. Thanks", "@penpornk Thanks! crossing fingers again!", "Hi @penpornk are the tests okay?", "@Srini511 Sorry for the delay! There was a problem pulling this PR in yesterday. We are trying again now. (The internal tests will be run after the changes are pulled in.)", "Thanks @penpornk! No problem. Please let me know if there is any change needed from my end.  Has import/copybara failed?", "@Srini511 Thanks for your understanding! Yes, import/copybara failure was the problem.", "Thanks @penpornk. Is it from my end? ", "> Thanks @penpornk. Is it from my end?\r\n\r\nnot from your end.!", "No, it's from our end. In fact, it looks like `import/copybara` still has a problem. I'm going to force run the tests again just so `import/copybara` gets rerun.", "Thanks @penpornk. I looked at the new failing Ubuntu contrib tests. They seem to be spurious and not related to the PR. Can you please take a look! \r\n//tensorflow/contrib/layers:target_column_test is passing at my end\r\n", "@Srini511 The errors are unrelated. And those tests used to pass before (without changes to the PR) so no worries! I only reran the tests in hopes to get rid of the `import/copybara` problem.", "This PR slowed down a test by 2-3x. I'll have to roll it back. Sorry about this!\r\n\r\nHow to replicate:\r\n```\r\n$ bazel build --config=opt --test_arg=--logtostderr --test_output=streamed  //tensorflow/contrib/metrics:metric_ops_large_test\r\n$ bazel-bin/tensorflow/contrib/metrics/metric_ops_large_test\r\n```\r\nResults before this PR: Ran 2 tests in 7.639s\r\nResults after this PR: Ran 2 tests in 17.330s\r\n", "Thanks @penpornk , can you please tell me if there is anything else that we need to look at?", "@Srini511 I didn't get any other regression warnings so hopefully this is the only thing. Sorry again for the inconvenience!", "No worries @penpornk! We analyzed the test and found that the slowdown is due to lock contention.\r\nThe value of limit = 201 and N =  4M in this test. This means that 4M updates are being performed on just 201 possible indices and hence there is contention. It appears like a corner case and wondering if the PR can be accepted as is for now since the implementation is functionally correct and the benchmarks give good performance. We are also working on a solution that will address similar case too. Thanks! ", "@Srini511 Thank you for investigating! I think we can use the original serial code when there is high potential for lock contention. Would `N / lock > 100` work for you? I'm testing it right now. It got through `metric_ops_large_test` with a pretty small slowdown.\r\n```c++\r\nconst float const float accesses_per_index = static_cast<float>(N) / limit;\r\nif (accesses_per_index > 100) {\r\n  // Serial code.\r\n} else {\r\n  // Parallel code.\r\n}\r\n```\r\n\r\nIf this (or other numbers) works for you, would you like to submit the PR again or should I just make the changes directly?", "Thanks a lot for the kind gesture @penpornk. Please make the changes directly and keep the number as 1024 as the benchmark test has max(N/limit) = 102.4 ", "@Srini511 Unfortunately, the benchmarks (ScatterAddInt*) are significantly slower with the PR than without when run internally. I don't have much time to work on this today so this PR will probably miss r2.0. Is that okay with you? (Otherwise I can try to guard the changes with `#ifdef INTEL_MKL`.)", "No issues @penpornk , I will submit another PR.", "@Srini511 Thank you! You might have to try compiling with clang too, since the problem was that the parallelized version is slower than the serial version when compiled with clang. Otherwise, I can try to look at this in several days.\r\n\r\nI also realized that you have to put different benchmarking calls in different functions, i.e.,\r\n```c++\r\nstatic void BM_ScatterAddInt32(int iters, int embedding_size) {\r\n  BM_ScatterHelper<int32>(iters, embedding_size, \"ScatterAdd\");\r\n  BM_ScatterHelper<int32>(iters, embedding_size, \"ScatterAdd\", true);\r\n}\r\n```\r\nShould be\r\n```c++\r\nstatic void BM_ScatterAddInt32(int iters, int embedding_size) {\r\n  BM_ScatterHelper<int32>(iters, embedding_size, \"ScatterAdd\");\r\n}\r\nstatic void BM_ScatterAddInt32Large(int iters, int embedding_size) {\r\n  BM_ScatterHelper<int32>(iters, embedding_size, \"ScatterAdd\", true);\r\n}\r\n```", "Thanks @penpornk. can you please provide me with a patch of your changes, I can apply them and debug. I have a version internally which seems to be doing okay.", "@Srini511 I just wrapped `if-else` around your code to bypass that one case (metric_ops_large_test).\r\n```c++\r\nconst int kMaxAddressesPerIndexForParallelScatter = 1024;\r\nconst float const float accesses_per_index = static_cast<float>(N) / limit;\r\nstd::atomic<Index> bad_index(-1);\r\nif (accesses_per_index > kMaxAddressesPerIndexForParallelScatter) {\r\n  // Serial code. (The original code.)\r\n} else {\r\n  // Parallel code. (Your code.)\r\n}\r\n```\r\nThe benchmark performance is similar to your PR so you can just debug your PR as well. \r\n\r\n> I have a version internally which seems to be doing okay.\r\n\r\nHave you tried `clang`? The PR is doing fine with `gcc` for me too.", "@penpornk, To clarify ScatterAddInt* benchmarks were significantly slower when run with clang but were okay when run with gcc?\r\nWhen i split the BM_ScatterAddInt32 and BM_ScatterAddInt32Large, i saw that gcc also had some regression. I added an extra condition which says, \r\nconst bool execute_serial =\r\n        ((N < 10000) || ((N / limit) > ser_par_ratio)) ? true : false; If you can quickly check if this is fine internally, that would be great. Thanks! "]}, {"number": 30879, "title": "TFLite conversion: AudioSpectogram, Mfcc, RandomUniform not supported", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (or github SHA if from source): 1.13\r\n\r\n\r\n**Provide the text output from tflite_convert**\r\n\r\n```\r\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CONV_2D, DIV, FLOOR, FULLY_CONNECTED, MAX_POOL_2D, MUL, RESHAPE, SHAPE, SUB. Here is a list of operators for which you will need custom implementations: AudioSpectrogram, Mfcc, RandomUniform.\r\n```\r\n\r\nAlso, please include a link to a GraphDef or the model if possible.\r\n\r\n**Any other info / logs**\r\n\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@PragmaticSoftwareSolutions ,\r\nIn order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. \r\nProvide the exact sequence of commands / steps that you executed before running into the problem.Thanks!\r\n", "Some operations not implemented in TensorFlow Lite.\r\nSee \r\nhttps://www.tensorflow.org/lite/guide/faq#models_operations\r\n```--enable_select_tf_ops``` - https://www.tensorflow.org/lite/guide/ops_select\r\n```custom implementations``` - https://www.tensorflow.org/lite/guide/ops_custom\r\nThanks!"]}, {"number": 30877, "title": "Feature request: 24-bit audio support in tf.audio.decode_wav", "body": "**System information**\r\n- TensorFlow version (you are using): 1.14\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n**Describe the feature and the current behavior/state.**\r\nI'm working with music data of \"DVD-quality\" i.e. 48 kHz / 24-bit WAV and want to read the files into a `tf.data` pipeline for model training via `tf.io.read_file` and `tf.audio.decode_wav` but unfortunately I got caught up on this exception:\r\n\r\n> InvalidArgumentError: Can only read 16-bit WAV files, but received 24 [Op:DecodeWav]\r\n\r\nWhile mastered mixes tend to end up being 44.1 kHz / 16-bit, in my experience 24-bit audio is extremely common among music producers as that format has a good trade-off between disk space and noise floor so the mic gain isn't as finicky etc.\r\n\r\n**Will this change the current api? How?**\r\nNo.\r\n\r\n**Who will benefit with this feature?**\r\nAudio researchers\r\n\r\n**Any Other info.**\r\n", "comments": ["@carlthome do you have a sample to share? Might be able to take a look.", "Here's an example: https://github.com/tensorflow/io/issues/49#issuecomment-518213854", "Related link https://github.com/tensorflow/io/pull/409", "@carlthome was this resolved by @yongtang PR that was merged? Please close the issue if it was already resolved. Thanks!", "@jvishnuvardhan, no as far as `tf.audio.decode_wav` goes this happens on 2.0.0:\r\n\r\n>InvalidArgumentError: Bad file size for WAV: Expected 16 or 18, but got40 [Op:DecodeWav]", "Hi, I would like to give this problem a try. Is it still open or is it resolved?", "@levivosWOW The PR in tensorflow-io has been merged and you can use:\r\n```\r\nimport tensdorflow as tf\r\nimport tensorflow_io as tfio\r\n\r\ntfio.audio.decode_wav(tf.io.read_file('24-bit.wav'), dtype=tf.int32))\r\n```\r\nfor 24bit wav files.\r\n\r\nI will close this issue for now. If you have any questions you can open a new issue in https://github.com/tensorflow/io"]}, {"number": 30876, "title": "tensorflow issue. I have installed keras and tensorflow but still get issues loading data", "body": "ImportError                               Traceback (most recent call last)\r\n~\\Anaconda3\\envs\\AirtificialIntelligence\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py in <module>\r\n     57 \r\n---> 58   from tensorflow.python.pywrap_tensorflow_internal import *\r\n     59   from tensorflow.python.pywrap_tensorflow_internal import __version__\r\n\r\n~\\Anaconda3\\envs\\AirtificialIntelligence\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py in <module>\r\n     27             return _mod\r\n---> 28     _pywrap_tensorflow_internal = swig_import_helper()\r\n     29     del swig_import_helper\r\n\r\n~\\Anaconda3\\envs\\AirtificialIntelligence\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py in swig_import_helper()\r\n     23             try:\r\n---> 24                 _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n     25             finally:\r\n\r\n~\\Anaconda3\\envs\\AirtificialIntelligence\\lib\\imp.py in load_module(name, file, filename, details)\r\n    241         else:\r\n--> 242             return load_dynamic(name, filename, file)\r\n    243     elif type_ == PKG_DIRECTORY:\r\n\r\n~\\Anaconda3\\envs\\AirtificialIntelligence\\lib\\imp.py in load_dynamic(name, path, file)\r\n    341             name=name, loader=loader, origin=path)\r\n--> 342         return _load(spec)\r\n    343 \r\n\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nImportError                               Traceback (most recent call last)\r\n<ipython-input-17-725e8432e2c0> in <module>\r\n----> 1 from keras.models import Sequential\r\n      2 from keras.layers import Dense\r\n      3 from keras.layers import Flatten\r\n      4 from keras.layers import Dropout\r\n      5 #from keras.layers.convolutional import Conv1D\r\n\r\n~\\Anaconda3\\envs\\AirtificialIntelligence\\lib\\site-packages\\keras\\__init__.py in <module>\r\n      1 from __future__ import absolute_import\r\n      2 \r\n----> 3 from . import utils\r\n      4 from . import activations\r\n      5 from . import applications\r\n\r\n~\\Anaconda3\\envs\\AirtificialIntelligence\\lib\\site-packages\\keras\\utils\\__init__.py in <module>\r\n      4 from . import data_utils\r\n      5 from . import io_utils\r\n----> 6 from . import conv_utils\r\n      7 \r\n      8 # Globally-importable utils.\r\n\r\n~\\Anaconda3\\envs\\AirtificialIntelligence\\lib\\site-packages\\keras\\utils\\conv_utils.py in <module>\r\n      7 from six.moves import range\r\n      8 import numpy as np\r\n----> 9 from .. import backend as K\r\n     10 \r\n     11 \r\n\r\n~\\Anaconda3\\envs\\AirtificialIntelligence\\lib\\site-packages\\keras\\backend\\__init__.py in <module>\r\n     87 elif _BACKEND == 'tensorflow':\r\n     88     sys.stderr.write('Using TensorFlow backend.\\n')\r\n---> 89     from .tensorflow_backend import *\r\n     90 else:\r\n     91     # Try and load external backend.\r\n\r\n~\\Anaconda3\\envs\\AirtificialIntelligence\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py in <module>\r\n      3 from __future__ import print_function\r\n      4 \r\n----> 5 import tensorflow as tf\r\n      6 from tensorflow.python.framework import ops as tf_ops\r\n      7 from tensorflow.python.training import moving_averages\r\n\r\n~\\Anaconda3\\envs\\AirtificialIntelligence\\lib\\site-packages\\tensorflow\\__init__.py in <module>\r\n     22 \r\n     23 # pylint: disable=g-bad-import-order\r\n---> 24 from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n     25 \r\n     26 from tensorflow._api.v1 import app\r\n\r\n~\\Anaconda3\\envs\\AirtificialIntelligence\\lib\\site-packages\\tensorflow\\python\\__init__.py in <module>\r\n     47 import numpy as np\r\n     48 \r\n---> 49 from tensorflow.python import pywrap_tensorflow\r\n     50 \r\n     51 # Protocol buffers\r\n\r\n~\\Anaconda3\\envs\\AirtificialIntelligence\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py in <module>\r\n     72 for some common reasons and solutions.  Include the entire stack trace\r\n     73 above this error message when asking for help.\"\"\" % traceback.format_exc()\r\n---> 74   raise ImportError(msg)\r\n     75 \r\n     76 # pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\r\n\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\PIPES\\Anaconda3\\envs\\AirtificialIntelligence\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\PIPES\\Anaconda3\\envs\\AirtificialIntelligence\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\PIPES\\Anaconda3\\envs\\AirtificialIntelligence\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\PIPES\\Anaconda3\\envs\\AirtificialIntelligence\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\PIPES\\Anaconda3\\envs\\AirtificialIntelligence\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n", "comments": ["@drpipespromzy ,\r\nPlease provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version.\r\nProvide the exact sequence of commands / steps that you executed before running into the problem.Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 30875, "title": "getting unexpected result from customize pre-Training model form Keras (Xception model) in C++ after freezing the model .pb .", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution  (debian 9.1):\r\n- TensorFlow installed from (source):\r\n- TensorFlow version (13.1):\r\n- Python version: python 3.5\r\n- Bazel version (11):\r\n- CUDA/cuDNN version: 10\r\n- GPU model and memory: 32 GB, GTX 1080 TI\r\n\r\n**Describe the current behavior**\r\nI am wondering why I can not get the same result when i run the frozen model in c++. I do not know exactly if the tf.keras does preprocessing step when I load the model.  \r\n\r\n\r\n**Python code: **\r\n-  creat tfrecord:\r\ndef get_example_object(image_string, label): ##label is in integer value( from 1 to number of classes )\r\n  feature = {'image':  _bytes_feature(tf.compat.as_bytes(image_string.tostring())),\r\n           'label':  _int64_feature(int(label))}\r\n  return tf.train.Example(features=tf.train.Features(feature=feature))\r\nimage = cv2.imread(img_path)\r\nimage= cv2.resize(image, (required_height, required_width))\r\n\r\n-  training:\r\ndef XceptionCNN(IMG_SIZE,OUTPUT_SIZE):\r\n\r\n    INPUT_SHAPE = (IMG_SIZE, IMG_SIZE,3)\r\n    input = tf.keras.layers.Input(\r\n        shape=INPUT_SHAPE, dtype=tf.float32,name='input') # \r\n\r\n    Xception_model = Xception(input_tensor=input, include_top=False,weights=None) \r\n    print('XceptionCNN Model loaded.')\r\n    print(Xception_model.summary())\r\n    x = Xception_model.output    \r\n    x = GlobalAveragePooling2D()(x)\r\n    return model\r\ndef _parse_function(proto):\r\n    image_size=150\r\n    class_number =16\r\n    keys_to_features = {'image': tf.FixedLenFeature([], tf.string),\r\n                        \"label\": tf.FixedLenFeature([], tf.int64)}\r\n\r\n    parsed_features = tf.parse_single_example(proto, keys_to_features)\r\n    image = tf.decode_raw(parsed_features['image'], tf.uint8)\r\n    image = tf.cast(image, tf.float32) * (1. / 255)\r\n    image = tf.reshape(image, shape=(image_size, image_size, 3))\r\n \r\n    label = tf.cast(parsed_features[\"label\"], tf.int32)\r\n    onehot_labels = tf.one_hot(tf.cast(label, tf.int32), class_number)\r\n    return image, onehot_labels\r\n\r\ndef get_dataset(filepath,epochs, batch_size ):\r\n    dataset = tf.data.TFRecordDataset(filepath)\r\n    dataset = dataset.map(_parse_function, mt.cpu_count())\r\n    dataset = dataset.repeat(epochs).shuffle(1000).batch(batch_size)\r\n    return dataset\r\n\r\n**CPP code: **\r\n-  creat float tensor:\r\n        cv::cvtColor(rgbImage, inputImage, CV_RGB2BGR);\r\n        cv::Mat img(imageTargetSize, CV_32FC1, dataTensor);\r\n         resizedPic.convertTo(img, CV_32FC3, 1.0 / 255, 0);\r\n        dataTensor += imageTargetSize.width * imageTargetSize.height * depth;\r\n\r\n**output**\r\n- The Training process:\r\n2019-07-18 13:07:35.544638: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally\r\n2306/2307 [============================>.] - ETA: 0s - loss: 0.0218 - acc: 0.9935     \r\nEpoch 00001: val_loss improved from inf to 0.00693, saving model to /mnt/4TB_HD/Training/flaps_keras/txt/model/class_net_normal/weights\r\n2307/2307 [==============================] - 1074s 466ms/step - loss: 0.0217 - acc: 0.9935 - val_loss: 0.0069 - val_acc: 0.9979\r\nEpoch 2/4\r\n2306/2307 [============================>.] - ETA: 0s - loss: 0.0074 - acc: 0.9981       \r\nEpoch 00002: val_loss did not improve from 0.00693\r\n2307/2307 [==============================] - 1029s 446ms/step - loss: 0.0074 - acc: 0.9981 - val_loss: 0.0162 - val_acc: 0.9968\r\nEpoch 3/4\r\n2306/2307 [============================>.] - ETA: 0s - loss: 0.0053 - acc: 0.9988   \r\nEpoch 00003: val_loss improved from 0.00693 to 0.00427, saving model to /mnt/4TB_HD/Training/flaps_keras/txt/model/class_net_normal/weights\r\n2307/2307 [==============================] - 1008s 437ms/step - loss: 0.0053 - acc: 0.9988 - val_loss: 0.0043 - val_acc: 0.9991\r\nEpoch 4/4\r\n2306/2307 [============================>.] - ETA: 0s - loss: 0.0046 - acc: 0.9991       \r\nEpoch 00004: val_loss did not improve from 0.00427\r\n2307/2307 [==============================] - 1012s 439ms/step - loss: 0.0046 - acc: 0.9991 - val_loss: 0.0090 - val_acc: 0.9986\r\ntf_input: Tensor(\"input:0\", shape=(?, 150, 150, 3), dtype=float32)\r\nmodel_input: <tensorflow.python.keras.engine.training.Model object at 0x7f8fac3f2f98>\r\ntf_output: Tensor(\"dense/Softmax:0\", shape=(?, 16), dtype=float32)\r\nmodel_output: dense/Softmax\r\n\r\n", "comments": ["@kerolos \r\nLooks like the code is incomplete.Can you please provide full code snippet to reproduce it on our environment.Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 30874, "title": "base64 strings contains  \" \"", "body": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/api_docs/python/tf/io/decode_base64\r\n\r\n## Description of issue (what needs changing):\r\nSome base64 strings contains  \" \".\r\n### Clear description\r\nIt could be useful to add this information after this paragraph:\r\n\r\n> Input may or may not have padding at the end. See EncodeBase64 for padding. Web-safe means that input must use - and _ instead of + and  /.\r\n\r\n\r\n", "comments": ["Argument ```input``` should cover all string cases.\r\nhttps://www.tensorflow.org/api_docs/python/tf/io/decode_base64#args\r\nPerhaps you can elaborate more for your doc request? Thanks!", "My input argument is a base64 string containing spaces.\r\nThe standard library base64 is able to decode (ignoring the spaces since are used just for readability) while tf.io.decode_base64 does not recognize that string as a base64 string.\r\nWhen the spaces are eliminated everything works fine.\r\n\r\nI think add a warning on this could be useful:\r\n\r\n> Input may or may not have padding at the end. See EncodeBase64 for padding. Web-safe means that input must use - and _ instead of + and /. \r\n> Input cannot contain \" \".\r\n", "Thanks for elaborating. Its clear now.  Would you like to send a PR to add the message?\r\n", "```tf.io.decode_base64``` ignores spaces in the string too. I made a toy example to elaborate;\r\nTested with TF 1.14.0\r\n- String without space\r\n\r\n```python\r\ntf.io.decode_base64(input='mystring',name=None) \r\n<tf.Tensor 'DecodeBase64_14:0' shape=() dtype=string>\r\n```\r\n- String with space\r\n```python\r\ntf.io.decode_base64(input='my string',name=None)\r\n<tf.Tensor 'DecodeBase64_15:0' shape=() dtype=string>\r\n```\r\nThanks!"]}, {"number": 30873, "title": "TF2: Memory leak during implicit conversion from EagerTensor to numpy", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): tensorflow-gpu==2.0.0-beta1\r\n- Python version: 3.7\r\n- CUDA/cuDNN version: 10.0 / 7.5\r\n- GPU model and memory: GTX 1080Ti\r\n\r\n\r\nRunning the following code on GPU causes a memory leak on my machine during implicit conversion to numpy. Leak does not manifest when doing explicit conversion (`r = np.sum(x.numpy())`).\r\n\r\n**Code to reproduce the issue**\r\n\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nN = 100000\r\n\r\nx = tf.zeros((10000)).gpu()\r\nfor i in range(N):\r\n    r = np.sum(x)\r\n```\r\n\r\n", "comments": ["Was able to reproduce the issue with TF version gpu==2.0.0-beta1.Thanks!", "Thanks for reporting that @ivankreso! I think the fix (d5b287d6c93332ba73b99b375bd21f81266e3112) did not make it into the -beta1 release. Could you try with the latest nightly and let us know if it works OK?\r\n\r\n```\r\n$ pip install tf-nightly-gpu-2.0-preview\r\n```", "It works ok with the latest nightly version. Thanks.\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=30873\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=30873\">No</a>\n"]}, {"number": 30872, "title": "cna't use tf.image.resize_images in TFLite", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux Ubuntu 18.04.2\r\n- TensorFlow installed from (source or binary):binary\r\n- TensorFlow version (or github SHA if from source):1.13.1\r\n\r\n\r\n**Provide the text output from tflite_convert**\r\n\r\n```\r\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, AVERAGE_POOL_2D, CONV_2D, FULLY_CONNECTED, MEAN, MUL, RSQRT, SQUARED_DIFFERENCE, SQUEEZE, SUB. Here is a list of operators for which you will need custom implementations: ResizeArea.\r\n```\r\n\r\nI think the error happened because of using function of tf.image.resize_images:\r\n```stft = tf.image.resize_images(stft, (128, 128), method=3)```\r\n\r\n", "comments": ["You many wanna take a look at [TensorFlow Lite and TensorFlow operator compatibility](https://www.tensorflow.org/lite/guide/ops_compatibility) and the document of [tf.image.resize](https://www.tensorflow.org/api_docs/python/tf/image/resize_images). In short,  `method=3`, that is, `ResizeMethod.AREA` is not supported by TFLite now. I think what you can do is either replacing it with a supported one (bilinear and nearest neighor) or implementing it.", "Please try to build the custom ops  from [here](https://www.tensorflow.org/lite/guide/ops_custom). This is the only workaround as of now. Thanks!"]}, {"number": 30871, "title": "TensorRT INT8 Calibration Table is Missing", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\r\n- TensorFlow installed from (source or binary):binary\r\n- TensorFlow version (use command below): v1.13.0-rc1-0-g54c5616308\r\n- Python version:3.5.2\r\n- CUDA/cuDNN version: CUDA 10\r\n- GPU model and memory: Tesla V100 16GB\r\n\r\n**Describe the current behavior**\r\nTFTRT failed to collect calibration info and cannot create the INT8 inference graph. \r\n\r\n**Code to reproduce the issue**\r\nHere is the model [link](https://drive.google.com/drive/folders/1hi23VeNomhHGj6Ai94Z44S6NRJ6uByJ5?usp=sharing).\r\n```\r\ndef run_calibration(calib_graph, dataset):\r\n    tf.reset_default_graph()\r\n    tf_config = tf.ConfigProto()\r\n    tf_config.gpu_options.allow_growth = True\r\n    x = np.random.randint(0,10000,(1,40))\r\n    with tf.Graph().as_default() as g:\r\n        input, output = tf.import_graph_def(graph_def=calib_graph, return_elements=[\"X\", \"model/dense/BiasAdd\"],\r\n                                            name='')\r\n        input = input.outputs[0]\r\n        output = output.outputs[0]\r\n        sess = tf.Session(config=tf_config, graph=g)\r\n\r\n        for i in range(10):\r\n            val = sess.run(output, {input: x})\r\n        return calib_graph\r\n\r\n\r\ndef int8quant():\r\n    with tf.Session() as sess:\r\n        saver = tf.train.import_meta_graph(\"/workspace/exps/ptb/ptb_rnn_128/ptb_rnn_128-72600.meta\")\r\n        saver.restore(sess, \"/workspace/exps/ptb/ptb_rnn_128/ptb_rnn_128-72600\")\r\n        your_outputs = ['model/dense/BiasAdd']\r\n        frozen_graph = tf.graph_util.convert_variables_to_constants(\r\n            sess,\r\n            tf.get_default_graph().as_graph_def(),\r\n            output_node_names=your_outputs)\r\n        trt_graph = trt.create_inference_graph(\r\n            input_graph_def=frozen_graph,\r\n            outputs=your_outputs,\r\n            max_batch_size=10,\r\n            max_workspace_size_bytes=2 << 30,\r\n            precision_mode='INT8',\r\n            minimum_segment_size=2  # minimum number of nodes in an engine\r\n       )\r\n    int8graph = run_calibration(trt_graph, None)\r\n    int8_graph = trt.calib_graph_to_infer_graph(int8graph)\r\n```\r\n\r\n**Other info / logs**\r\nHere is the trace logs.\r\n```\r\n2019-07-19 03:47:34.167937: E tensorflow/contrib/tensorrt/log/trt_logger.cc:38] DefaultLogger Tensor TensorRTOutputPH_0cannot be both input and output\r\n2019-07-19 03:47:34.167960: E tensorflow/contrib/tensorrt/log/trt_logger.cc:38] DefaultLogger Network must have at least one output\r\n2019-07-19 03:47:38.553760: E tensorflow/contrib/tensorrt/log/trt_logger.cc:38] DefaultLogger Tensor (Unnamed ITensor* 3) is uniformly zero; network calibration failed.\r\n2019-07-19 03:47:38.578654: E tensorflow/contrib/tensorrt/convert/convert_graph.cc:220] Calibration table is empty\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/workspace/code/rnnquant/trt/convert.py\", line 99, in <module>\r\n    main()\r\n  File \"/workspace/code/rnnquant/trt/convert.py\", line 95, in main\r\n    int8quant()\r\n  File \"/workspace/code/rnnquant/trt/convert.py\", line 89, in int8quant\r\n    int8_graph = trt.calib_graph_to_infer_graph(int8graph)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/tensorrt/python/trt_convert.py\", line 416, in calib_graph_to_infer_graph\r\n    int(msg[0]))\r\ntensorflow.python.framework.errors_impl.UnknownError: Calibration table is missing. This shouldn't have happened!\r\n\r\n```\r\n\r\n", "comments": ["@jiarongqiu Did you check whether the issue persists with latest versions (TF1.14, or nightly builds) of TF? Thanks!", "> > @jiarongqiu Did you check whether the issue persists with latest versions (TF1.14, or nightly builds) of TF? Thanks!\r\n> \r\n> I just tested on TF1.14 version following [trt_convert_test.py](https://github.com/tensorflow/tensorflow/blob/5912f51d580551e5cee2cfde4cb882594b4d3e60/tensorflow/python/compiler/tensorrt/trt_convert_test.py#L105). I succeeded in converting the graph but found a problem here. \r\n> I tested the converted graph with both calibration dataset and random data but got same result during the inference. I guessed my current conversion did not collect any info from the calibration dataset.\r\nIs there somewhere that I could check the cache and the threshold T TensorRT chose for activations and weights?\r\n", "@jiarongqiu there is a problem in 1.14.0 and we're fixing that. Meanwhile, can you try with `tf-nightly-gpu` and follow [these](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/compiler/tensorrt/trt_convert.py#L316-L327) instructions to see if it works?\r\n\r\nThanks.", "This is my current code. I import the graph through GraphDef.\r\n```\r\n    with tf.Session() as sess:\r\n        saver = tf.train.import_meta_graph(\"/workspace/exps/ptb/ptb_rnn_128/ptb_rnn_128-72600.meta\")\r\n        saver.restore(sess, \"/workspace/exps/ptb/ptb_rnn_128/ptb_rnn_128-72600\")\r\n        outputs = ['model/dense/BiasAdd']\r\n        frozen_graph = tf.graph_util.convert_variables_to_constants(\r\n            sess,\r\n            tf.get_default_graph().as_graph_def(),\r\n            output_node_names=outputs)\r\n        converter = trt_convert.TrtGraphConverter(\r\n            input_graph_def=frozen_graph,\r\n            nodes_blacklist=outputs,\r\n            precision_mode=trt_convert.TrtPrecisionMode.INT8,\r\n        )\r\n\r\n        class CalibrationData(object):\r\n\r\n            def __init__(self,dataset=None):\r\n                self.dataset = dataset\r\n\r\n            def next(self):\r\n                X =  np.random.randint(0, 10000, (1, 40))\r\n                return {\"X:0\": X}\r\n\r\n        calib_graph = converter.convert()\r\n        calib_graph = converter.calibrate(\r\n            fetch_names=[\"model/dense/BiasAdd:0\"],\r\n            num_runs=10,\r\n            feed_dict_fn=CalibrationData().next)\r\n        tf.train.write_graph(calib_graph, \"/workspace/exps/ptb/ptb_rnn_128\", \"trt_model_int8.pb\", as_text=False)\r\n```\r\nAnd, I tested it on the tf-nightly-gpu but got some errors during the conversion.\r\n```\r\n2019-07-24 06:16:59.855323: E tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:41] DefaultLogger Tensor (Unnamed ITensor* 3) is uniformly zero; network calibration failed.\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/client/session.py\", line 1352, in _do_call\r\n    return fn(*args)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/client/session.py\", line 1337, in _run_fn\r\n    target_list, run_metadata)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/client/session.py\", line 1430, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found.\r\n  (0) Unknown: Calibration table is empty.\r\n         [[{{node GetCalibrationDataOp}}]]\r\n  (1) Unknown: Calibration table is empty.\r\n         [[{{node GetCalibrationDataOp}}]]\r\n         [[GetCalibrationDataOp/_7]]\r\n0 successful operations.\r\n0 derived errors ignored.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/workspace/code/rnnquant/trt/convert.py\", line 142, in <module>\r\n    main()\r\n  File \"/workspace/code/rnnquant/trt/convert.py\", line 138, in main\r\n    int8quantv2()\r\n  File \"/workspace/code/rnnquant/trt/convert.py\", line 128, in int8quantv2\r\n    feed_dict_fn=CalibrationData().next)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/compiler/tensorrt/trt_convert.py\", line 643, in calibrate\r\n    resource_name_input: _get_canonical_engine_name(node.name)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/client/session.py\", line 945, in run\r\n    run_metadata_ptr)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/client/session.py\", line 1168, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/client/session.py\", line 1346, in _do_run\r\n    run_metadata)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/client/session.py\", line 1371, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found.\r\n  (0) Unknown: Calibration table is empty.\r\n         [[node GetCalibrationDataOp (defined at usr/local/lib/python3.5/dist-packages/tensorflow_core/python/framework/ops.py:1657) ]]\r\n  (1) Unknown: Calibration table is empty.\r\n         [[node GetCalibrationDataOp (defined at usr/local/lib/python3.5/dist-packages/tensorflow_core/python/framework/ops.py:1657) ]]\r\n         [[GetCalibrationDataOp/_7]]\r\n0 successful operations.\r\n0 derived errors ignored.\r\n\r\nOriginal stack trace for 'GetCalibrationDataOp':\r\n  File \"usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"usr/lib/python3.5/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"workspace/code/rnnquant/trt/convert.py\", line 142, in <module>\r\n    main()\r\n  File \"workspace/code/rnnquant/trt/convert.py\", line 138, in main\r\n    int8quantv2()\r\n  File \"workspace/code/rnnquant/trt/convert.py\", line 128, in int8quantv2\r\n    feed_dict_fn=CalibrationData().next)\r\n  File \"usr/local/lib/python3.5/dist-packages/tensorflow_core/python/compiler/tensorrt/trt_convert.py\", line 635, in calibrate\r\n    gen_trt_ops.get_calibration_data_op(resource_name_input))\r\n  File \"usr/local/lib/python3.5/dist-packages/tensorflow_core/compiler/tf2tensorrt/ops/gen_trt_ops.py\", line 265, in get_calibration_data_op\r\n    \"GetCalibrationDataOp\", resource_name=resource_name, name=name)\r\n  File \"usr/local/lib/python3.5/dist-packages/tensorflow_core/python/framework/op_def_library.py\", line 793, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"usr/local/lib/python3.5/dist-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"usr/local/lib/python3.5/dist-packages/tensorflow_core/python/framework/ops.py\", line 3261, in create_op\r\n    attrs, op_def, compute_device)\r\n  File \"usr/local/lib/python3.5/dist-packages/tensorflow_core/python/framework/ops.py\", line 3330, in _create_op_internal\r\n    op_def=op_def)\r\n  File \"usr/local/lib/python3.5/dist-packages/tensorflow_core/python/framework/ops.py\", line 1657, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\n```", "@jiarongqiu this is what I got when running calibration:\r\n```\r\n2019-10-09 08:08:48.328837: W tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:37] DefaultLogger Tensor (Unnamed Layer* 2) [Constant]_output is uniformly zero; network calibration failed.\r\n```\r\nI'm running this with the latest TF r1.15.0rc3. It seems that the TRT portion of your model always output 0 regardless of the input. Can you double check the model and see if it's correct?", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30871\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30871\">No</a>\n"]}, {"number": 30870, "title": "Post-Training Integer Quantization on Models for 'Edge' / Coral TPUs", "body": "**System information**\r\n- Have I written custom code: Yes (below)\r\n- OS Platform and Distribution: Arch\r\n- TensorFlow installed from (source or binary): Binary (pip)\r\n- TensorFlow version: v2.0.0-beta0-17-g8e423e3\r\n- Python version: 3.7.3\r\n\r\n**Description**\r\nI'm interested in using TF2.0's ```tf.function``` to build graphs that can be run on an Edge TPU. As that device only supports (8-bit) integer quantized models, I'm trying to use the relatively new [post-training integer quantization](https://medium.com/tensorflow/tensorflow-model-optimization-toolkit-post-training-integer-quantization-b4964a1ea9ba). That Medium post states,\r\n> Our new post-training integer quantization enables users to take an already-trained floating-point model and fully quantize it to only use 8-bit signed integers (i.e. `int8`). ... Fixed point hardware accelerators, such as Edge TPUs, will also be able to run these models.\r\n\r\nHowever, even a simple proof-of-concept graph doesn't seem to be accepted by the [Coral web compiler](https://coral.withgoogle.com/web-compiler) (with no useful error messages). Unless this is an issue with the Coral site, I wanted to write in here\u2014whether this is a bug or a not-yet-implemented feature, in hopes that it may be resolved. Am I doing anything unsupported at this time? Or, has anyone been able to compile a model for Coral/Edge that may be able to serve as an example?\r\n\r\n**Code to reproduce the issue**\r\n```python\r\nimport pathlib\r\nimport tensorflow as tf\r\n\r\n@tf.function\r\ndef simple_layer(x):\r\n    return tf.nn.relu(2 * x + 1)\r\n\r\nc_fn = simple_layer.get_concrete_function(tf.TensorSpec(shape=[1], dtype=tf.float32))\r\n\r\nconverter = tf.lite.TFLiteConverter.from_concrete_functions([c_fn])\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nconverter.target_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\r\nmy_dataset = tf.data.Dataset.from_tensor_slices(np.arange(-100, 100, 0.01, dtype=np.float32))\r\nmy_dataset = my_dataset.batch(1)\r\n\r\ndef rep_dataset():\r\n    for val in my_dataset.shuffle(tf.data.experimental.cardinality(my_dataset)).take(1000):\r\n        yield [val]\r\nconverter.representative_dataset = rep_dataset\r\n\r\ntflite_quant_model = converter.convert()\r\n\r\ndir = 'supersimple_coral'\r\ntflite_models_dir = pathlib.Path(dir)\r\ntflite_models_dir.mkdir(exist_ok=True, parents=True)\r\ntflite_model_file = tflite_models_dir/\"model_quant.tflite\"\r\ntflite_model_file.write_bytes(tflite_quant_model)\r\n```", "comments": ["FYI, Edge TPU [July 2019 Updates](https://coral.withgoogle.com/news/updates-07-2019/) includes post-training quant support. Didn't try web compiler, offline compiler does work.", "@freedomtan, many thanks for the message. I hadn't seen that update \u2014 even wrote to coral support, but only got back that post-training quantization wasn't yet supported. Much appreciated!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=30870\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=30870\">No</a>\n"]}, {"number": 30869, "title": "\"'NoneType' object has no attribute '_fetch_cloud_tpu_metadata'\" when using TPU", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (use command below): 1.14.0\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: 10.0\r\n- GPU model and memory: Cloud TPU v2\r\n\r\n**Describe the current behavior**\r\nI've been using T2T training script using cloud TPU. After upgrading to TF 1.14.0 from TF 1.13.1, I'm getting the error below:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\r\n    self.run()\r\n  File \"/app/poodle/asr/t2t/t2t_train_venv.image.binary.runfiles/skelterlabs/poodle/asr/t2t/py-pkg/tensorflow/python/tpu/preempted_hook.py\", line 86, in run\r\n    response = self._cluster._fetch_cloud_tpu_metadata()  # pylint: disable=protected-access\r\nAttributeError: 'NoneType' object has no attribute '_fetch_cloud_tpu_metadata'\r\n```\r\n\r\nThe training script continues w/o any further issue despite the error.\r\n\r\n**Describe the expected behavior**\r\nNo error.\r\n\r\n**Code to reproduce the issue**\r\nRun https://github.com/tensorflow/tensor2tensor#speech-recognition problems using transformer model on TPUs.\r\n\r\n**Other info / logs**\r\nN/A", "comments": ["I also meet this problem, have you solved it? ", "@w4-sjcho @HeimingX Do you have issues with this [colab](https://colab.sandbox.google.com/github/tensorflow/tensor2tensor/blob/master/tensor2tensor/notebooks/hello_t2t.ipynb#scrollTo=wfF8_cW-OXPN). Please let us know the location/item which is breaking. Thanks!", "@jvishnuvardhan @jhseu Also seeing this with tensorflow 1.14 and t2t 1.14, happy to help. This is running in batch on ctpu v3 with tf 1.14 runtime (in graph mode).\r\n\r\nAs you can see the error above `self._cluster._fetch_cloud_tpu_metadata()` is failing because self._cluster is None; this is being passed to CloudTPUPreemptedHook [in tpu_estimator.py](https://github.com/tensorflow/estimator/blob/master/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py#L3237).\r\n\r\nSee there has recently been a [change to tpu_estimator.py](https://github.com/tensorflow/estimator/commit/6a8b06637a73d070ca5ccbeeb5fdc280c8aa9994) that modifies:\r\n\r\n```python\r\n         if tpu_cluster_resolver.is_running_in_gce():\r\n            hooks.extend(\r\n                [preempted_hook.CloudTPUPreemptedHook(self._config.cluster)])\r\n```\r\nto\r\n\r\n```python\r\n         if _check_add_preemption_hook(self._config.cluster):\r\n            hooks.extend(\r\n                [preempted_hook.CloudTPUPreemptedHook(self._config.cluster)])\r\n```\r\n\r\nwhere the latter wraps the former to include a check for the TPUClusterResolver object not being None, here:\r\n\r\n```python\r\ndef _check_add_preemption_hook(cluster):\r\n  return (tpu_cluster_resolver.is_running_in_gce() and\r\n          cluster and\r\n          isinstance(cluster, tpu_cluster_resolver.TPUClusterResolver) and\r\n          cluster._should_resolve)\r\n```\r\n\r\nwhich seems like one solution (i.e. avoid adding the problematic hook if we don't have a cluster resolver object).\r\n\r\nAnother would be to ensure the cluster resolver gets initialized when the run config is constructed in t2t trainer_lib.py, [here](https://github.com/tensorflow/tensor2tensor/blob/2036ffe309b86bda367b1e687fafb114534500f9/tensor2tensor/utils/trainer_lib.py#L232); looking at the logic there the portion initializing the cluster resolver won't be reached when using TPUs via GKE because KUBE_GOOGLE_CLOUD_TPU_ENDPOINTS will be set.\r\n\r\nIdk if it will break something else but I'm just going to try moving the initialization of the cluster resolver outside of the logic about whether master and KUBE_GOOGLE_CLOUD_TPU_ENDPOINTS are set. Or re-build tf with the modification to tpu_estimator.py mentioned above. The tpu runtime tf version would still be stock 1.14 but afaict that pertains to ops not session hooks.", "@jvishnuvardhan @jhseu @w4-sjcho @HeimingX So it does look like there's a side effect in moving the cluster resolver instantiation from its current place but [patching in](https://gist.github.com/cwbeitel/2ab6bb9c5c418d390bedb23b8c959c0b#file-patch_tpu_estimator-py) the `_check_add_preemption_hook` change mentioned above gets rid of the error and training appears to proceed normally.", "Yeah, this'll be fixed in TF 1.15. You can also pass the cluster to the RunConfig instead of passing master directly and it should work.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=30869\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=30869\">No</a>\n"]}, {"number": 30868, "title": "Tensorflow on Jetson TX2's performance suddenly decrease, don't know reason ", "body": "A week ago, I run my face-id project, that achieved 7fps, but now, after one week, I dont know why my project just achieve 3-4 fps, I dont modify source code and any dependency library.\r\n\r\n**Project**: Face-Id based on Tensorflow (FaceNet)\r\n**OS**: Ubuntu 16.04\r\n**Board**: Jetson TX2\r\n**Cuda/CuDNN**: 9.0/7.1.5.14\r\n**Tensorflow**: 1.9.0", "comments": ["@theiron97 In order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!\r\n", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 30867, "title": "Fix make_csv_dataset error when combined with compression type", "body": "This fix tries to address the issue raised in #30849 where make_csv_dataset throw out an error if combined with compression_type. This fix address the issue by using different file io functions\r\nin case compression_type is provided.\r\n\r\nNote this fix only addresses GZIP format. For ZLIB format, as python's zlib package does not comes with a way to read file stream (only from data buffer) as gzip package, it is not supported.\r\n\r\nThis fix fixes #30849.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["@rachellim, please take a look", "@yongtang Could you please check failed build errors? Thanks!", "Thanks @gbaned. The CI test failure has been fixed. The failure was cause by Python 2 vs 3 where python 3 use byte as default (python 2 use string). Please take a look and let me know if there are any other issues.", "Thanks @rachellim for the review. The PR has been updated. Please take a look and let me know if there are other issues.", "> This fix tries to address the issue raised in #30849 where make_csv_dataset throw out an error if combined with compression_type. This fix address the issue by using different file io functions\r\n> in case compression_type is provided.\r\n> \r\n> Note this fix only addresses GZIP format. For ZLIB format, as python's zlib package does not comes with a way to read file stream (only from data buffer) as gzip package, it is not supported.\r\n> \r\n> This fix fixes #30849.\r\n> \r\n> Signed-off-by: Yong Tang [yong.tang.github@outlook.com](mailto:yong.tang.github@outlook.com)\r\n\r\nI know this is for fix #30849. While I use the latest version to run the same code in pasted in #30849, which it still turns to error. Or do we need change only configure to run the origin code in #30849? \r\n![image](https://user-images.githubusercontent.com/3108520/85141989-43b65b00-b27a-11ea-8345-ec02d37f3678.png)\r\n", "@wuhaifengdhu you have to pass the compression type as string `GZIP`, not tensor `tf.constant('GZIP')`.", "> @wuhaifengdhu you have to pass the compression type as string `GZIP`, not tensor `tf.constant('GZIP')`.\r\n\r\nThanks for the reply. It works with a simple string. ", "Will the support for zip files be added?", "for the code:\r\nimport tensorflow as tf\r\ntitanic_batches = tf.data.experimental.make_csv_dataset(\r\n    '/content/drive/MyDrive/predict/train.csv.zip',\r\n    batch_size=4,\r\n    compression_type=zip,\r\n    label_name=\"resp\")\r\n\r\nI get the following error:\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-3-857432d2fc17> in <module>()\r\n      4     batch_size=4,\r\n      5     compression_type=zip,\r\n----> 6     label_name=\"resp\")\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/experimental/ops/readers.py in make_csv_dataset_v2(file_pattern, batch_size, column_names, column_defaults, label_name, select_columns, field_delim, use_quote_delim, na_value, header, num_epochs, shuffle, shuffle_buffer_size, shuffle_seed, prefetch_buffer_size, num_parallel_reads, sloppy, num_rows_for_inference, compression_type, ignore_errors)\r\n    457       elif compression_type_value != \"\":\r\n    458         raise ValueError(\"compression_type (%s) is not supported\" %\r\n--> 459                          compression_type)\r\n    460   if column_names is None:\r\n    461     if not header:\r\n\r\nValueError: compression_type (<class 'zip'>) is not supported"]}, {"number": 30866, "title": "Tensorflow 2.0 add regularization losses", "body": "<em>In Tensorflow 1.x, I can add regularization losses by using code like this:\r\n`regularization_loss = tf.add_n(tf.losses.get_regularization_losses(), 'regu')`\r\n`total_loss = loss + regularization_loss`\r\nBut in tensorflow 2.0.0beta1 api, the 'losses.get_regularization_losses()' was canceled.So how can I add that loss In this case?\r\n\r\n\r\n**System information**\r\n- TensorFlow version :2.0.0beta1\r\n\r\n", "comments": ["This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged//tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n", "Closing this as it is support issue. Thanks!", "TF2.0 style for achieving the same. @moshimo2019 \r\n```\r\nregularization_loss = tf.math.add_n(model.losses)\r\n```\r\n", "> regularization_loss = tf.math.add_n(model.losses)\r\n\r\nI used this style, but model.losses return [],Why?", "@Jessespace Do you set the kernel_regularizer of the layer ? See the doc [tensorflow.keras.layers.Dense](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense)"]}, {"number": 30865, "title": "TF2.0 is graph_transform still available in TF 2.0?", "body": "This template is for miscellaneous issues not covered by the other issue categories.\r\n\r\nFor questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\r\n\r\nIf you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).\r\n\r\nFor high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.\r\n", "comments": ["Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\nMake sure you also include the exact command if possible to produce the output included in your test case. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!\r\n", "@gadagashwini I am try to ask if the API tensorflow.tools.graph_transforms still available in TensorFlow 2.0 official release. So I think it is does not matter the OS version, or TensorFlow version I current in use.\r\n\r\nIf you really need this, I use Ubuntu 16.04 x86_64. And the TensorFlow version would be TensorFlow 2.0 via pip install.", "@guizili0 [Here](https://github.com/tensorflow/tensorflow/tree/r2.0/tensorflow/tools/graph_transforms) is the link to graph_transform in 2.0. Thanks!", "@jvishnuvardhan thank you! But when compile with --config=v2, this api would not compile, did TensorFlow Team decide not compile this, or just miss this API by mistake, thanks.", "The graph transforms API is in contrib, right? If so, it's not a part of TF2.", "Sorry I confused it with another API.\r\n\r\nGraph transforms is not in contrib but it's not built by default as a part of tf2. Just build it without --config=v2 if you need to build it.", "@alextp Thank you for the response, that means in TF 2.0, this API would be remove? ", "It's not a part of TF's core APIs, it's a separate tool you can build if\nyou want. I don't know of plans to deleting it.\n\nOn Tue, Jul 23, 2019 at 6:10 PM Li, Guizi <notifications@github.com> wrote:\n\n> @alextp <https://github.com/alextp> Thank you for the response, that\n> means in TF 2.0, this API would be remove?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/30865?email_source=notifications&email_token=AAABHRNLPTIEAOFO3D44LH3QA6TY5A5CNFSM4IFBRDYKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD2U3FUY#issuecomment-514437843>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAABHRJEH6CUIG4IUKR3UETQA6TY5ANCNFSM4IFBRDYA>\n> .\n>\n\n\n-- \n - Alex\n", "How can I build this tool separately, what's the command to do that? I'm seeing the same issue and stumbled upon this conversation. ", "@venky-intel https://github.com/tensorflow/tensorflow/issues/30865#issuecomment-513938021 the comment here specifies it, just few pointers, you might face issues with `bazel` which needs to installed to build tf libraries, keep the bazel version above 2.0 to build the tool seperately.", "The comment #30865 indeed explains the usage of Graph transforms using bazel. \r\n\r\n> bazel build tensorflow/tools/graph_transforms:transform_graph\r\nbazel-bin/tensorflow/tools/graph_transforms/transform_graph \\\r\n--in_graph=tensorflow_inception_graph.pb \\\r\n--out_graph=optimized_inception_graph.pb \\\r\n--inputs='Mul:0' \\\r\n--outputs='softmax:0' \\\r\n--transforms='\r\nstrip_unused_nodes(type=float, shape=\"1,299,299,3\")\r\nremove_nodes(op=Identity, op=CheckNumerics)\r\nfold_old_batch_norms\r\n\r\nInoder to use this tool the way the community is suggesting, is to use bazel-bin. \r\n\r\nI am now wondering how can I  convert this bazel-bin package with graph transforms to a whl file which can be installed using pip just like a normal Tensorflow package as mentioned at the [guide to build tensorflow from source](https://www.tensorflow.org/install/source#build_the_pip_package) .\r\n\r\nI want to access the graph transforms tools in TF 2.0 in a similar way to TF 1.14\r\n`from tensorflow.tools.graph_transforms import TransformGraph` \r\n\r\nAny help on this front will be really helpful. Thanks in advance.", "@PreethaVeera you cannot install graph_transform with pip in any way. it is written in c++ and it is intended to be built from source using basel. Please [install bazel first]() then clone the Tensorflow repository and use the instructions above to build it and run it"]}, {"number": 30864, "title": "How can I get h5 file to tflite file. I tried to do with the documentation but it is giving me an error", "body": "`from keras.models import load_model\r\nkeras_file =\"project.h5\"\r\nkeras.models.save_model(model,keras_file)\r\nfrom tensorflow import lite\r\ncoverter = lite.TFLiteConverter.from_keras_model_file(keras_file)`\r\n\r\nThis is the error I am getting\r\n\r\n```\r\n`ValueError                                Traceback (most recent call last)\r\n<ipython-input-27-d2fc0cb4c75c> in <module>\r\n----> 1 coverter = tf.compat.v1.lite.TFLiteConverter.from_keras_model_file(keras_file)\r\n\r\n/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/lite/python/lite.py in from_keras_model_file(cls, model_file, input_arrays, input_shapes, output_arrays, custom_objects)\r\n    741 \r\n    742       frozen_func = _convert_to_constants.convert_variables_to_constants_v2(\r\n--> 743           concrete_func)\r\n    744       _set_tensor_shapes(frozen_func.inputs, input_shapes)\r\n    745       return cls(frozen_func.graph.as_graph_def(), frozen_func.inputs,\r\n\r\n/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/convert_to_constants.py in convert_variables_to_constants_v2(func)\r\n    164         input_name = get_name(map_name_to_node[input_name].input[0])\r\n    165       if map_name_to_node[input_name].op != \"Placeholder\":\r\n--> 166         raise ValueError(\"Cannot find the Placeholder op that is an input \"\r\n    167                          \"to the ReadVariableOp.\")\r\n    168       # Build a map of Placeholder ops that are inputs to ReadVariableOps to the\r\n\r\nValueError: Cannot find the Placeholder op that is an input to the ReadVariableOp.\r\n```\r\n\r\n\r\n\r\n\r\nThis is my keras model.\r\n```\r\nmodel = keras.Sequential()\r\nmodel.add(keras.layers.Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=Combined.shape[1]))\r\nmodel.add(keras.layers.SpatialDropout1D(0.2))\r\nmodel.add(keras.layers.LSTM(100, dropout=0.2, recurrent_dropout=0.2))\r\nmodel.add(keras.layers.Dense(11, activation='softmax'))\r\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\r\nmodel.summary()\r\nepochs = 40\r\nbatch_size = 64\r\nhistory = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])\r\n\r\n\r\nModel: \"sequential\"\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\nembedding (Embedding)        (None, 50, 100)           40000     \r\n_________________________________________________________________\r\ndropout (Dropout)            (None, 50, 100)           0         \r\n_________________________________________________________________\r\nlstm (LSTM)                  (None, 100)               80400     \r\n_________________________________________________________________\r\ndense (Dense)                (None, 11)                1111      \r\n=================================================================\r\n```\r\n`", "comments": ["@sajagkc11 ,\r\nPlease provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version.Thanks!", "\r\nThank you for the reply\r\n\r\n  Model Name:\tMacBook Pro\r\n  Model Identifier:\tMacBookPro11,3\r\n  Processor Name:\tIntel Core i7\r\n  Processor Speed:\t2.5 GHz\r\n  Number of Processors:\t1\r\n  Total Number of Cores:\t4\r\n  L2 Cache (per Core):\t256 KB\r\n  L3 Cache:\t6 MB\r\n  Hyper-Threading Technology:\tEnabled\r\n  Memory:\t16 GB\r\n  Boot ROM Version:\t153.0.0.0.0\r\n  SMC Version (system):\t2.19f12\r\n  Serial Number (system):\tC02NF1XAG3QD\r\n  Hardware UUID:\t411A542B-6D05-553C-A6D5-7C2EBA5068C6\r\n\r\ntensorflow  version                       2.0.0b1 \r\npython version .                         3.7.3\r\n\r\n", "@tensorflowbutler Could you help me with this issue?", "@gargn, is this is bug in converter v2, or do you think its just a lstm converter example.", "@aselle Thank you for responding. I was thinking if this is the issue on the parameter.(input_arrays and output_arrays)", "This is an issue with converting LSTMs. There is currently limited support for LSTMs in TFLite. The documented path is available [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/experimental/examples/lstm/g3doc/README.md). We are working on improving our support of control flow based operations and models. We will update documentation and the GitHub issues as we make progress on this issue.", "converter = tf.compat.v1.lite.TFLiteConverter.from_keras_model_file(keras_file)\r\nWhen I run with the v1 \r\n```\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-23-d22030c3debe> in <module>\r\n----> 1 converter = tf.compat.v1.lite.TFLiteConverter.from_keras_model_file(keras_file)\r\n\r\n/anaconda3/lib/python3.7/site-packages/tensorflow_core/lite/python/lite.py in from_keras_model_file(cls, model_file, input_arrays, input_shapes, output_arrays, custom_objects)\r\n    833     _set_tensor_shapes(input_tensors, input_shapes)\r\n    834 \r\n--> 835     graph_def = _freeze_graph(sess, input_tensors, output_tensors)\r\n    836     return cls(\r\n    837         graph_def,\r\n\r\n/anaconda3/lib/python3.7/site-packages/tensorflow_core/lite/python/util.py in freeze_graph(sess, input_tensors, output_tensors)\r\n    247     output_arrays = [get_tensor_name(tensor) for tensor in output_tensors]\r\n    248     return tf_graph_util.convert_variables_to_constants(sess, graph_def,\r\n--> 249                                                         output_arrays)\r\n    250   else:\r\n    251     return sess.graph_def\r\n\r\n/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py in new_func(*args, **kwargs)\r\n    322               'in a future version' if date is None else ('after %s' % date),\r\n    323               instructions)\r\n--> 324       return func(*args, **kwargs)\r\n    325     return tf_decorator.make_decorator(\r\n    326         func, new_func, 'deprecated',\r\n\r\n/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/graph_util_impl.py in convert_variables_to_constants(sess, input_graph_def, output_node_names, variable_names_whitelist, variable_names_blacklist)\r\n    300         source_op_name = get_input_name(map_name_to_node[source_op_name])\r\n    301       if map_name_to_node[source_op_name].op != \"VarHandleOp\":\r\n--> 302         raise ValueError(\"Cannot find the variable that is an input \"\r\n    303                          \"to the ReadVariableOp.\")\r\n    304 \r\n\r\nValueError: Cannot find the variable that is an input to the ReadVariableOp.\r\n```", "I want to convert my keras model into a tf lite file.\r\nthis is my code\r\n\r\nimport tensorflow as tf\r\nconverter = tf.lite.TFLiteConverter.from_keras_model_file( r'/content/drive/My Drive/inceptionv3-transfer-learning__fine_tune.h5') # Your model's name\r\nmodel = converter.convert()\r\nfile = open( 'model.tflite' , 'wb' )\r\nfile.write( model )\r\n\r\nValueError: None is only supported in the 1st dimension. Tensor 'input_1' has invalid shape '[None, None, None, 3]'.\r\n\r\nwhat can I do?\r\n", "TF Lite currently only support the batch dimension to be None, not the other dimensions. Could you specify the image width/height in your model?", "@ haozha111\r\nthe Image_width and Image_height = 299,299\r\niIused inception model but iI noticed now that my model input is\r\n\r\n[<tf.Tensor 'input_1_1:0' shape=(?, ?, ?, 3) dtype=float32>]\r\nhow can i correct this?", "One way to do this is to call the `from_keras_model_file` API:\r\nhttps://www.tensorflow.org/api_docs/python/tf/lite/TFLiteConverter#from_keras_model_file\r\n\r\nYou can pass your model's input array, input shapes, output_arrays to this function. In this case, you will first need to know what your input_arrays/output_arrays are (by looking at model.inputs()). Hope that helps.", "I am using tensorflow version 1.14 and i am using the older keras packages in my model creation python file not the tf.keras package within tensorflow. Can i still use `from_keras_model_file` with my model.h5 file created with older Keras packages because in the tflite converter documentation it is mentionted that this function`from_keras_model_file` is to be used with tf.keras model. \r\n\r\nIf `from_keras_model_file`  cant be used with models created with older keras packages which procedure do i follow . I found another procedure to convert .h5 -> .pb ->.tflite and use https://github.com/amir-abdi/keras_to_tensorflow for conversion to .pb. Is this the correct procedure or should i follow some other way?\r\n\r\nSorry i am a beginner and this might be a pretty basic question but this is my doubt", "The best way is something like the following (I haven't tested this code):\r\n\r\n```\r\nkeras_model = tf.keras.models.load_model(model_file, custom_objects)\r\nsess = tf.keras.backend.get_session()\r\n\r\nconverter = tf.lite.TFLiteConverter(sess, keras_model.inputs, keras_model.outputs)\r\nconverter.convert()\r\n```\r\n\r\nYou might optionally need to call the following before calling `load_model`:\r\n```\r\ntf.keras.backend.clear_session()\r\ntf.keras.backend.set_learning_phase(False)\r\n```", "how can  I stop my model from predicting what is not trained for?\r\nI trained my model based on tomato leaves but if I feed in any picture apart from tomato leaves my model will still classifier it?\r\nwhat can I do?\r\n", "> The best way is something like the following (I haven't tested this code):\r\n> \r\n> ```\r\n> keras_model = tf.keras.models.load_model(model_file, custom_objects)\r\n> sess = tf.keras.backend.get_session()\r\n> \r\n> converter = tf.lite.TFLiteConverter(sess, keras_model.inputs, keras_model.outputs)\r\n> converter.convert()\r\n> ```\r\n> \r\n> You might optionally need to call the following before calling `load_model`:\r\n> \r\n> ```\r\n> tf.keras.backend.clear_session()\r\n> tf.keras.backend.set_learning_phase(False)\r\n> ```\r\n\r\nSo is this for keras models created with normal keras packages or models created with tf.keras module ?", "@raghavk92 The code snippet provided works with `tf.keras` models.", "@sajagkc11 Can you try to use `converter.experimental_new_converter = True` and let us know whether it resolved for you or not. \r\n\r\nYou could check the solution provided [here](https://github.com/tensorflow/tensorflow/issues/32693) and [here](https://github.com/tensorflow/tensorflow/issues/32608). Thanks!", "I think the issue was resolved. I am closing the issue. Please feel free to open it if the issue persists again. Thanks!", "I am using Keras = 2.2.4, Tensorflow = 1.14.0, I wanted to convert **.h5 to tf-lite** but getting the below error. My keras model has LSTM in it. \r\n```\r\nTraceback (most recent call last):\r\n  File \"h5_to_tf_lite.py\", line 3, in <module>\r\n    converter = tf.lite.TFLiteConverter.from_keras_model_file('6054c838ad0cf20001c8357e_tr_seq_pred_bidirectional_five_word.h5')\r\n  File \"/home/10670769/miniconda3/envs/lym/lib/python3.7/site-packages/tensorflow/lite/python/lite.py\", line 762, in from_keras_model_file\r\n    graph_def = _freeze_graph(sess, input_tensors, output_tensors)\r\n  File \"/home/10670769/miniconda3/envs/lym/lib/python3.7/site-packages/tensorflow/lite/python/util.py\", line 238, in freeze_graph\r\n    output_arrays)\r\n  File \"/home/10670769/miniconda3/envs/lym/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 324, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/home/10670769/miniconda3/envs/lym/lib/python3.7/site-packages/tensorflow/python/framework/graph_util_impl.py\", line 302, in convert_variables_to_constants\r\n    raise ValueError(\"Cannot find the variable that is an input \"\r\nValueError: Cannot find the variable that is an input to the ReadVariableOp.\r\n```\r\n\r\nI am using this script\r\n```\r\nimport tensorflow as tf\r\n#from tensorflow.contrib import lite\r\nconverter = tf.lite.TFLiteConverter.from_keras_model_file('model.h5')\r\nconverter.experimental_new_converter = True\r\ntfmodel = converter.convert()\r\nopen(\"model.tflite\" , \"wb\").write(tfmodel)\r\n```\r\n", "@ajaysg94 Please open a new issue as this was an old issue. Thanks!"]}, {"number": 30863, "title": "tf.test.is_gpu_available return False", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Amazon Linux 2 AMI\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): pip3\r\n- TensorFlow version:tensorflow-gpu-1.14.0\r\n- Python version:3.7.3\r\n- Installed using virtualenv? pip? conda?:pip3\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:10.1\r\n- GPU model and memory:Nvidia Tesla K80, 11441MiB\r\n\r\n\r\n\r\n**Describe the problem**\r\ntf.test.is_gpu_available returns Flase\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\npython3\r\nimport tensorflow as tf\r\ntf.test.is_gpu_available()\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n<img width=\"688\" alt=\"Screen Shot 2019-07-18 at 17 21 57\" src=\"https://user-images.githubusercontent.com/22419710/61493054-ae7f5800-a980-11e9-9234-175b26c624c3.png\">\r\n", "comments": ["I removed CUDA 10.1 and reinstalled 10.0 but the error persists", "@aspenlin Please check software requirements for Cuda10 [here](https://www.tensorflow.org/install/gpu#software_requirements). \r\n\r\n```\r\nSoftware requirements\r\nThe following NVIDIA\u00ae software must be installed on your system:\r\n\r\nNVIDIA\u00ae GPU drivers \u2014CUDA 10.0 requires 410.x or higher.\r\nCUDA\u00ae Toolkit \u2014TensorFlow supports CUDA 10.0 (TensorFlow >= 1.13.0)\r\nCUPTI ships with the CUDA Toolkit.\r\ncuDNN SDK (>= 7.4.1)\r\n(Optional) TensorRT 5.0 to improve latency and throughput for inference on some models.\r\n```\r\n\r\nLooking at error trace, I strongly feel CUDA drivers were not compatible to load CUDA10. Tensorflow correctly detects your GPU, but cuDNN you have is 3.7 (major 3 and minor 7) where as the requirements say it is compatible with >=7.4.1. I would say, please check NVIDIA drivers you have installed. It requires >= 410.48. Please check table 1 in this NVIDIA [resource](https://docs.nvidia.com/deploy/cuda-compatibility/index.html). Thanks!\r\n\r\n`CUDA 10.0 | >= 410.48`\r\n", "Yep you are right. Somehow AWS installs CUDA for you but some of the libraries are missing. I solved the problem by 'sudo yum install cuda-libraries-10-0' and install new cudnn. And now tensorflow.test.is_gpu_available() returns True!", "@aspenlin Thanks for posting solution here as it will help other users. Thanks again.", "UPDATE: I didn't have tensorflow-gpu installed  -- only tensorflow.  doing a `conda install tensorflow-gpu` resolved my particular problem.\r\n\r\nI'm running 441.08, which is >= 410.48 with Cuda compilation tools, release 10.0, V10.0.130 and tensorflow 2.0.0 yet, despite having 2 1070 GPUs, is_gpu_available == False:\r\n\r\nIn [3]: tf.test.is_gpu_available()\r\n2019-12-09 16:50:55.953081: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  AVX AVX2\r\nTo enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\r\nOut[3]: False\r\n\r\n"]}, {"number": 30862, "title": "How can I get h5 file to tflite file. I tried to do with the documentation but it is giving me an error.", "body": "`from keras.models import load_model\r\nkeras_file =\"project.h5\"\r\nkeras.models.save_model(model,keras_file)\r\nfrom tensorflow import lite\r\ncoverter = lite.TFLiteConverter.from_keras_model_file(keras_file)`\r\n\r\nThis is the error I am getting\r\n\r\n```\r\n`ValueError                                Traceback (most recent call last)\r\n<ipython-input-27-d2fc0cb4c75c> in <module>\r\n----> 1 coverter = tf.compat.v1.lite.TFLiteConverter.from_keras_model_file(keras_file)\r\n\r\n/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/lite/python/lite.py in from_keras_model_file(cls, model_file, input_arrays, input_shapes, output_arrays, custom_objects)\r\n    741 \r\n    742       frozen_func = _convert_to_constants.convert_variables_to_constants_v2(\r\n--> 743           concrete_func)\r\n    744       _set_tensor_shapes(frozen_func.inputs, input_shapes)\r\n    745       return cls(frozen_func.graph.as_graph_def(), frozen_func.inputs,\r\n\r\n/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/convert_to_constants.py in convert_variables_to_constants_v2(func)\r\n    164         input_name = get_name(map_name_to_node[input_name].input[0])\r\n    165       if map_name_to_node[input_name].op != \"Placeholder\":\r\n--> 166         raise ValueError(\"Cannot find the Placeholder op that is an input \"\r\n    167                          \"to the ReadVariableOp.\")\r\n    168       # Build a map of Placeholder ops that are inputs to ReadVariableOps to the\r\n\r\nValueError: Cannot find the Placeholder op that is an input to the ReadVariableOp.\r\n```\r\n\r\n\r\n\r\n\r\nThis is my keras model.\r\n```\r\nmodel = keras.Sequential()\r\nmodel.add(keras.layers.Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=Combined.shape[1]))\r\nmodel.add(keras.layers.SpatialDropout1D(0.2))\r\nmodel.add(keras.layers.LSTM(100, dropout=0.2, recurrent_dropout=0.2))\r\nmodel.add(keras.layers.Dense(11, activation='softmax'))\r\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\r\nmodel.summary()\r\nepochs = 40\r\nbatch_size = 64\r\nhistory = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])\r\n\r\n\r\nModel: \"sequential\"\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\nembedding (Embedding)        (None, 50, 100)           40000     \r\n_________________________________________________________________\r\ndropout (Dropout)            (None, 50, 100)           0         \r\n_________________________________________________________________\r\nlstm (LSTM)                  (None, 100)               80400     \r\n_________________________________________________________________\r\ndense (Dense)                (None, 11)                1111      \r\n=================================================================\r\n```\r\n`", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F30862) for more info**.\n\n<!-- need_sender_cla -->", "All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only \"I consent.\" in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F30862) for more info**.\n\n<!-- need_author_consent -->", "> Thanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\r\n> \r\n> \ud83d\udcdd **Please visit https://cla.developers.google.com/ to sign.**\r\n> \r\n> Once you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\r\n> \r\n> #### What to do if you already signed the CLA\r\n> ##### Individual signers\r\n> * It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\r\n> \r\n> ##### Corporate signers\r\n> * Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\r\n> * The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\r\n> * The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\r\n> \r\n> \u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F30862) for more info**.\r\n\r\nI have signed it", "Closing this PR as this not against `master`, please open a new PR against `master` \r\nCC @mihaimaruseac"]}, {"number": 30861, "title": "representative_dataset error for TFlite converter quantization", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 1.14\r\n- Python version: 3.6.8\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10.0\r\n- GPU model and memory: Titan Xp, 12GB\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nMy representative_data_gen() iterate through a dataset that i created with some custom images and I set converter.representative_dataset with the function and convert the frozen model to tflite with int8 quantization. It produces the following error:\r\n\r\n> Traceback (most recent call last):\r\n>   File \"./src/freeze_graph.py\", line 100, in <module>\r\n>     tflite_quant_model = converter.convert()\r\n>   File \"/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/lite.py\", line 908, in convert\r\n>     inference_output_type)\r\n>   File \"/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/lite.py\", line 200, in _calibrate_quantize_model\r\n>     inference_output_type, allow_float)\r\n>   File \"/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/optimize/calibrator.py\", line 76, in calibrate_and_quantize\r\n>     self._calibrator.FeedTensor(calibration_sample)\r\n>   File \"/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/optimize/tensorflow_lite_wrap_calibration_wrapper.py\", line 112, in FeedTensor\r\n>     return _tensorflow_lite_wrap_calibration_wrapper.CalibrationWrapper_FeedTensor(self, input_value)\r\n> ValueError: Cannot set tensor: Got tensor of type STRING but expected type FLOAT32 for input 98, name: image_input \r\n\r\nI tried to only quantize the weights with tf.lite.Optimized set to OPTIMIZE_FOR_SIZE and without setting representative_dataset option. It can produce tflite model successfully.\r\n\r\n**Describe the expected behavior**\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n```\r\ntrain = []\r\npath = '/home/liuyanqi/caffe/pyramid_cnn/data/adversarial'\r\nfor i in range(1, 11):\r\n    filename = os.path.join(path, 'exp{:03d}_B'.format(i), 'scenergb.jpg' )\r\n    im = cv2.imread(filename)\r\n    im = im.astype(np.float32, copy=False)\r\n    input_image = im - mc.BGR_MEANS\r\n    train.append(input_image)\r\n\r\ntrain = tf.convert_to_tensor(np.array(train, dtype='float32'))\r\nmy_ds = tf.data.Dataset.from_tensor_slices((train)).batch(1)\r\n\r\n#POST TRAINING QUANTIZATION\r\ndef representative_dataset_gen():\r\n    for input_value in my_ds.take(10):\r\n        yield [input_value]\r\n\r\n\r\n\r\ngraph_def_file = '/tmp/logs/+zynqDet+tmp/train/freeze_graph.pbtxt'\r\ninput_arrays = [\"image_input\"]\r\n# # output_arrays = [\"probability/final_class_prob_concat\",\"IOU_1/det_boxes_concat\"]\r\noutput_arrays = [\"predictor/bias_add\",\"predictor_1/bias_add\", \"predictor_2/bias_add\"]\r\nconverter = tf.lite.TFLiteConverter.from_frozen_graph(\r\n    graph_def_file, input_arrays, output_arrays, input_shapes={input_arrays[0]:[1, 480, 640, 3]})\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nconverter.representative_dataset = representative_dataset_gen\r\ntflite_quant_model = converter.convert()\r\n```\r\n\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["I met the same problem before, you can try add this `tf. Enable_eager_execution() ` at the beginning. ", " @eric4337 Wow. I'm not sure why but this solves the problem. \r\n\r\nI visualize the generated tflite model using netron. Can anyone explain why it only insert Quantize layer after a certain convolution layer?\r\n \r\n![image](https://user-images.githubusercontent.com/7076268/61813651-3dbebc80-ae14-11e9-8108-3521e49e71b0.png)\r\n", "U need 'yield [sess.run(input value)]', or it's still a tensor  ", "@eric4337 @liuyanqi can you share you solution ? when I reproduce the demo ,i always get the error:Process finished with exit code 139 (interrupted by signal 11: SIGSEGV),any help ?", "> @eric4337 @liuyanqi can you share you solution ? when I reproduce the demo ,i always get the error:Process finished with exit code 139 (interrupted by signal 11: SIGSEGV),any help ?\r\n\r\nGot the same problem with tf1.14!", "> @eric4337 Wow. I'm not sure why but this solves the problem.\r\n> \r\n> I visualize the generated tflite model using netron. Can anyone explain why it only insert Quantize layer after a certain convolution layer?\r\n> \r\n> ![image](https://user-images.githubusercontent.com/7076268/61813651-3dbebc80-ae14-11e9-8108-3521e49e71b0.png)\r\n\r\nAny update on why there is a Quantize node?", "When we concat two tensors, we need to make sure they use the same quantization range so that we can append the values together as is. The Quantize() op there is to adapt the range. The datatype remains as int8 after that op.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30861\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30861\">No</a>\n", "> @eric4337 Wow. I'm not sure why but this solves the problem.\r\n> \r\n> I visualize the generated tflite model using netron. Can anyone explain why it only insert Quantize layer after a certain convolution layer?\r\n> \r\n> ![image](https://user-images.githubusercontent.com/7076268/61813651-3dbebc80-ae14-11e9-8108-3521e49e71b0.png)\r\n\r\nHi, could you please share that how did you get the quantized graph?\r\nLooking forward to it!", "@Ekta246 With [netron](https://lutzroeder.github.io/netron/) download & drag the `.tflite` to the web/desktop app , hope the answer is not too late :)", "> When we concat two tensors, we need to make sure they use the same quantization range so that we can append the values together as is. The Quantize() op there is to adapt the range. The datatype remains as int8 after that op.\r\n\r\n@liyunlu0618 \r\nI have met the same problem about int8-quantization before concat\u3002The trouble is that the int8->int8 Quantize op can not be supported by nnapi-dsp delegate\u3002It means that the graph will be splited to several sub-graphs to run on nnapi-dsp and will take much more time to do the inference. So does the int8->int8 Quantize op is necessory, even though the two concat tensors are all from conv+relu and have the same data range? Or May I just modify the tflite model to remove the Quantize op using some tools, like coremltools to modify the apple's mlmodel? "]}, {"number": 30860, "title": "Copy cluster_def from TPUClusterResolver to session config", "body": "This patch fixes a TPU issue, where TPU pods cannot work with some variants of TPUStrategy because the cluster_def wasn't set.\r\n\r\nOriginal commit: 5874bc234851a8ab7f86c67a99c43ba9ca12aece\r\nPiperOrigin-RevId: 254299719", "comments": []}, {"number": 30859, "title": "Allow Metric objects to be called with DistributionStrategy.", "body": "PiperOrigin-RevId: 250593081", "comments": []}, {"number": 30858, "title": "Nested Layer saving with tf.train.Checkpoint", "body": "**System information**\r\n\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 1.13.1\r\n- Python version: 3.5.6\r\n\r\n**Describe the current behavior**\r\ntf.train.CheckPoint fails to save variables associated with the child layer, but displays the variables associated with it. \r\n\r\n**Describe the expected behavior**\r\ntf.train.CheckPoint should save variables associated with the child layer\r\n\r\nI was trying to compare model saving between nested and non-nested `tf.keras` layers, since I need a nested layer for my task.\r\n\r\nI put together a simple script and its corresponding output. \r\n\r\nIn the first case, the `Linear` Layer is its own parent and in the second case, the `Linear` layer is made the child of an `NestedLinear` layer. A `tf.keras.Model` is setup with the inputs and outputs and the trainable variables are printed out. After initializing, I attempt to save a checkpoint and list the variables in the checkpoint. \r\n\r\nIf you see the output, the number of trainable variables are the same in both cases and the child layer variables are joined to the parent layer.\r\n\r\nI assumed that the Checkpoint saving would work in a similar fashion with gathering all variable tensors and having a mapping between the Tensor and its position in the graph topology and save them but the checkpoints fail to save the `Linear` layer variables in the second case.\r\n\r\nMaybe there is something I missed, and would like some help on this.\r\n\r\n**Code**\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\nfrom tensorflow.keras import layers\r\nimport os\r\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\r\n\r\nclass Linear(layers.Layer):\r\n\r\n  def __init__(self, units=32, input_dim=32):\r\n    super(Linear, self).__init__()\r\n    self.w = self.add_weight(shape=(input_dim, units),\r\n                             initializer='random_normal',\r\n                             trainable=True, name=\"W\")\r\n    self.b = self.add_weight(shape=(units,),\r\n                             initializer='zeros',\r\n                             trainable=True, name='b')\r\n\r\n  def call(self, inputs):\r\n    return tf.matmul(inputs, self.w) + self.b\r\n\r\nclass NestedLinear(layers.Layer):\r\n\r\n  def __init__(self):\r\n    super(NestedLinear, self).__init__()\r\n    self.linear_1 = Linear(32)\r\n\r\n  def call(self, inputs):\r\n    x = self.linear_1(inputs)\r\n    return x\r\n\r\ninputs = layers.Input(shape=(32,))\r\n\r\nprint(\"SAVING SINGLE LAYER\")\r\noutputs = Linear(32)(inputs)\r\n\r\nmodel = tf.keras.Model(inputs=inputs, outputs=outputs)\r\nfor var in model.trainable_variables:\r\n    print(var)\r\nckpt = tf.train.Checkpoint(model=model)\r\n\r\nsess = tf.Session()\r\nsess.run(tf.global_variables_initializer())\r\nwith sess.as_default():\r\n    ckpt.save(\"ckpt\")\r\n\r\nfor var in tf.train.list_variables(\"./\"):\r\n    print(var)\r\n\r\nprint(\"--------------------------------------\")\r\n\r\nnl_layer = NestedLinear()\r\noutputs = nl_layer(inputs)\r\n\r\nprint(\"SAVING NESTED LAYER\")\r\n\r\nmodel = tf.keras.Model(inputs=inputs, outputs=outputs)\r\nfor var in model.trainable_variables:\r\n    print(var)\r\nckpt = tf.train.Checkpoint(model=model)\r\n\r\nsess = tf.Session()\r\nsess.run(tf.global_variables_initializer())\r\nwith sess.as_default():\r\n    ckpt.save(\"ckpt\")\r\n\r\nfor var in tf.train.list_variables(\"./\"):\r\n    print(var)\r\n```\r\n**Output**\r\n\r\n```\r\nSAVING SINGLE LAYER\r\n<tf.Variable 'W:0' shape=(32, 32) dtype=float32>\r\n<tf.Variable 'b:0' shape=(32,) dtype=float32>\r\n('_CHECKPOINTABLE_OBJECT_GRAPH', [])\r\n('model/.ATTRIBUTES/OBJECT_CONFIG_JSON', [])\r\n('model/layer-0/.ATTRIBUTES/OBJECT_CONFIG_JSON', [])\r\n('model/layer_with_weights-0/.ATTRIBUTES/OBJECT_CONFIG_JSON', [])\r\n('model/layer_with_weights-0/W/.ATTRIBUTES/VARIABLE_VALUE', [32, 32])\r\n('model/layer_with_weights-0/b/.ATTRIBUTES/VARIABLE_VALUE', [32])\r\n('save_counter/.ATTRIBUTES/VARIABLE_VALUE', [])\r\n--------------------------------------\r\nSAVING NESTED LAYER\r\n<tf.Variable 'W_1:0' shape=(32, 32) dtype=float32>\r\n<tf.Variable 'b_1:0' shape=(32,) dtype=float32>\r\n('_CHECKPOINTABLE_OBJECT_GRAPH', [])\r\n('model/.ATTRIBUTES/OBJECT_CONFIG_JSON', [])\r\n('model/layer-0/.ATTRIBUTES/OBJECT_CONFIG_JSON', [])\r\n('model/layer_with_weights-0/.ATTRIBUTES/OBJECT_CONFIG_JSON', [])\r\n('save_counter/.ATTRIBUTES/VARIABLE_VALUE', [])\r\n```\r\n", "comments": ["Can you try with a more recent version of TensorFlow? 1.14 should have this fixed I believe. sub-Layer tracking was not automatic like Model's in 1.13.", "That worked, yes, thanks!"]}, {"number": 30857, "title": "TF2: Out of Memory using model.fit with class_weight parameter", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): \r\n```\r\nYes\r\n```\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n```\r\nContainer derived from nvidia/cuda:10.0-cudnn7-runtime-ubuntu18.04 running on Ubuntu 18.04 via Kubernetes 1.13\r\n```\r\n- TensorFlow installed from (source or binary):\r\n```\r\npip3 install tensorflow-gpu==2.0.0-beta1\r\n```\r\n- TensorFlow version (use command below):\r\n```\r\nv1.12.1-6250-g37eafe0e74 2.0.0-dev20190715\r\n```\r\n- Python version:\r\n```\r\nPython 3.6.8\r\n```\r\n- CUDA/cuDNN version:\r\n```\r\nNVIDIA-SMI 410.78       Driver Version: 410.78       CUDA Version: 10.0\r\n```\r\n```\r\n        libcudnn.so.7 -> libcudnn.so.7.6.0\r\nlibcudnn is installed\r\n```\r\n- GPU model and memory:\r\n```\r\nname, pci.bus_id, vbios_version\r\nTesla V100-SXM2-32GB, 00000000:1B:00.0, 88.00.43.00.03\r\n```\r\n\r\n**Describe the current behavior**\r\nDoing a training with tf.keras results in out of memory after some time when including the `class_weight` parameter. Also there is a long delay between the start of each epoch. If I omit the `class_weight` parameter, training proceeds normally with constant memory.\r\n\r\n**Describe the expected behavior**\r\nTraining proceed normally when the `class_weight` parameter is included without running out of memory.\r\n\r\n**Code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\n\r\n################ Data\r\ndef _parse_fn2(fn, label):\r\n    img = tf.random.uniform([224, 224, 3])\r\n    return img, label\r\n\r\ntrain_data2 = tf.data.Dataset.from_tensor_slices(\r\n  (tf.random.uniform([100]), tf.random.uniform([100], maxval=9, dtype=tf.dtypes.int32))\r\n)\r\n\r\nval_data2 = tf.data.Dataset.from_tensor_slices(\r\n  (tf.random.uniform([100]), tf.random.uniform([100], maxval=9, dtype=tf.dtypes.int32))\r\n)\r\ntrain_data2 = (train_data2.map(_parse_fn2)).batch(32)\r\nval_data2 = (val_data2.map(_parse_fn2)).batch(32)\r\n\r\n############### Model\r\nIMG_SHAPE = (224, 224, 3)\r\n\r\nbase_model = tf.keras.applications.ResNet50(input_shape=IMG_SHAPE,include_top=False, weights=None)\r\nbase_model.trainable = True\r\nmaxpool_layer = tf.keras.layers.GlobalMaxPooling2D()\r\nprediction_layer = tf.keras.layers.Dense(9, activation='softmax')\r\n\r\nmodel = tf.keras.Sequential([\r\n    base_model,\r\n    maxpool_layer,\r\n    tf.keras.layers.Dropout(0.4),\r\n    prediction_layer\r\n])\r\n\r\nmodel.compile(optimizer=tf.keras.optimizers.Adam(lr=0.01), loss='categorical_crossentropy', metrics=['accuracy'])\r\n\r\nmodel.summary()\r\nhistory = model.fit(train_data2.repeat(),\r\n                epochs=100,\r\n                steps_per_epoch = 50,\r\n                validation_data=val_data2.repeat(),\r\n                validation_steps=10,\r\n                class_weight={0:1,1:1,2:1,3:1,4:1,5:1,6:1,7:1,8:1,9:1},\r\n                callbacks = [])\r\n```\r\n\r\n**Other info / logs**\r\nMemory Usage at Each Epoch:\r\n```\r\n              total        used        free      shared  buff/cache   available\r\nE1:           502G         11G        461G        140M         30G        487G\r\nE2:           502G         16G        456G        140M         30G        483G\r\nE3:           502G         22G        449G        140M         30G        476G\r\nE4:           502G         30G        441G        141M         30G        468G\r\nE5:           502G         40G        431G        141M         30G        458G\r\nE6:           502G         52G        419G        141M         30G        446G\r\n```\r\nvmstat output:\r\n[vmstat_output.txt](https://github.com/tensorflow/tensorflow/files/3407988/vmstat_output.txt)\r\n\r\n", "comments": ["@814HiManny I was able to reproduce the issue with `tf-nightly-gpu-2.0-preview==2.0.0.dev20190718`. However, when I remove `class_weights` from the model.fit, the model runs without any issue. Thanks!", "This looks like it's the same as #31253?", "Yep, looks like a duplicate, I'll close this one to unify threads", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=30857\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=30857\">No</a>\n", "Hi, #31253 is for TF 1.x. What is the fixed version for TF2.X?"]}, {"number": 30856, "title": "ImportError: /opt/gnu/gcc/lib64/libstdc++.so.6: version `GLIBCXX_3.4.21' not found ", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOs 6.10 Linux: 2.6.32-754.2.1.el6.x86_64\r\n- TensorFlow installed from (source or binary): Conda install\r\n- TensorFlow version: 1.14.0\r\n- Python version: 3.7.5\r\n- Installed using virtualenv? pip? conda?: Conda\r\n- GCC/Compiler version (if compiling from source): c++ 4.9.2\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\nImport error ImportError: /opt/gnu/gcc/lib64/libstdc++.so.6: version `GLIBCXX_3.4.21' not found (required by /home/atanteck/anaconda3/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so). Indicated file is there at the path.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nImport tensorflow\r\n\r\n**Any other info / logs**\r\n>>> import tensorflow\r\nTraceback (most recent call last):\r\n  File \"/home/atanteck/anaconda3/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"/home/atanteck/anaconda3/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"/home/atanteck/anaconda3/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"/home/atanteck/anaconda3/lib/python3.7/imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"/home/atanteck/anaconda3/lib/python3.7/imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: /opt/gnu/gcc/lib64/libstdc++.so.6: version `GLIBCXX_3.4.21' not found (required by /home/atanteck/anaconda3/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so)\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/atanteck/anaconda3/lib/python3.7/site-packages/tensorflow/__init__.py\", line 34, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"/home/atanteck/anaconda3/lib/python3.7/site-packages/tensorflow/python/__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"/home/atanteck/anaconda3/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"/home/atanteck/anaconda3/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"/home/atanteck/anaconda3/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"/home/atanteck/anaconda3/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"/home/atanteck/anaconda3/lib/python3.7/imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"/home/atanteck/anaconda3/lib/python3.7/imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: /opt/gnu/gcc/lib64/libstdc++.so.6: version `GLIBCXX_3.4.21' not found (required by /home/atanteck/anaconda3/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so)\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.", "comments": ["This issue looks like a duplicate of https://github.com/tensorflow/tensorflow/issues/26826", "I am closing this issue as it is duplicate of https://github.com/tensorflow/tensorflow/issues/26826 and workaround for the problem is provided there. We will followup with the issue there. Thanks!", "I find this link very useful:\r\nhttp://www.programmersought.com/article/3932478100/", "> I find this link very useful:\r\n> http://www.programmersought.com/article/3932478100/\r\n\r\nthis could help me, thanks.", "> \r\n> \r\n> I find this link very useful:\r\n> http://www.programmersought.com/article/3932478100/\r\n\r\nthanks,it is useful for me"]}, {"number": 30855, "title": "TF2: tf.distribute.MirroredStrategy() running sequentially on GPUs", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Amazon Linux AMI release 2018.03\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below): 2.0 beta\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory: Tesla K80\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nI have built a custom subclassed Keras model and am using MirroredStrategy for multi-GPU training. I am using custom training loops exactly as described in the official guide here:\r\nhttps://www.tensorflow.org/beta/tutorials/distribute/training_loops\r\n\r\nHowever, I am running it in `eager-mode` without using `@tf.function`\r\n\r\nI am also using `TFRecordDataset` as part of the input pipeline and when I run it separately, it iterates over the dataset very fast, so that is not a bottleneck. \r\n\r\nWhen I use `nvidia-smi` to monitor the GPU usage during training, I can see that each GPU gets used in a sequential manner. I am not sure why this behavior is arising. \r\n\r\n**Describe the expected behavior**\r\nThe model should be running parallel on all GPUs at the same time. \r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\n\r\nWhen using the basic MirroredStrategy, I keep getting a warning that Efficient Allreduce does not support IndexedSlices. What does that mean? \r\n\r\nI have also changed to `tf.distribute.ReductionToOneDevice()` which removes the warning but the sequential behavior still persists. \r\n", "comments": ["I'm pretty sure this is the expected behavior since the default execution mode is `SYNC`. You can try changing it to `ASYNC`, https://github.com/tensorflow/tensorflow/blob/3794c88add3f4d5dec3d3e4147940ef76e21f030/tensorflow/python/eager/context.py#L62.\r\n\r\nI've run into all types of strange errors when I do. Maybe there should be warning about using MirroredStrategy outside a `tf.function` context.", "@ppham27 How/Where do I set this mode? ", "Further updates: I recreated the model (omitting a custom-layer) using the Tensorflow Functional API. When I run that model, I can see that it parallelizes across the GPUs (to a certain extent, even though the execution % is quite imbalanced). However, with the exact same layers with my subclassed Keras model, I only ever get sequential execution. \r\n\r\nDoes the functional API have graph mode execution enabled by default even in Tensorflow 2.0? I am using the same trainers, data loaders, etc. and just swapping the models, but I see parallel execution for the model created using Functional API. Is this expected behavior too?", "I am also struggling with this issue. When I try to add the \"@tf.function\" decorator to my function which executes the distribute step, my performance goes from ~2 seconds per batch to over 10 seconds across 4 GPUs. When I try to profile, I mostly just see empty space in the profiler in Tensorboard, where there's some sporadic activity on my CPU seemingly due to the only layers in my model where I subclassed \"keras.layer\". I will check if switching to functional API fixes the problem. ", "@christopherbate If it's not a problem, could you please share the steps involved to profile using `tensorboard` or maybe point me to documentation/tutorial you followed? Even I am getting extremely weird behavior when I try to use `@tf.function`", "@dsgupta \r\n\r\nSee https://www.tensorflow.org/api_docs/python/tf/config/experimental/set_synchronous_execution?hl=en.\r\n\r\nYou can try `tf.config.experimental.set_synchronous_execution(False)`. I'm not that optimistic that this will fix your issue, though.", "I tried that but the execution is still sequential. If I try to use `@tf.function` decorator for `dist_train_step` and `dist_test_step`, I am getting the following error: \r\n\r\n`ValueError: No gradients provided for any variable:`\r\n\r\nBut it is working perfectly in `eager` mode. ", "@dsgupta \r\nPut: \r\n```\r\nwith self.writer.as_default():\r\n         tf.summary.trace_on(graph=False, profiler=True)\r\n```\r\n\r\nRight before you want to start profiling, then:\r\n``` \r\nwith self.writer.as_default():\r\n         tf.summary.trace_export(step=step, name=\"model_profile\", profiler_outdir=\"./test_profile\")\r\n```\r\n\r\nTo stop profiling. Generally I try to capture 2-3 batches to see what things look like.\r\n\r\nCan you provide your code for reproducing the issue? My code base is large, so paring it down to isolate the cause is difficult, although it sounds like it might be a common cause. ", "@christopherbate Sorry, I am not able to share the code. However, I am using the Keras Functional API with Bidirectional LSTM, and basic Dense and Embedding layers. \r\nMy training script is exactly like the one in the tutorial here, only swapping out the model with mine, and the input dataset is something else using TFRecordDataset: https://www.tensorflow.org/beta/tutorials/distribute/training_loops\r\n\r\nIt works in `eager` mode, but when I decorate the distributed train and val steps with `@tf.function` as given in the tutorial, I get all kinds of weird errors. \r\n\r\n@ppham27 Would you mind sharing your email so I can privately share the model structure with you? \r\n\r\nIn any case, when I swap out my custom Pooling layer with `AveragePool1D` and try to use `@tf.function` decorator, I get the following error: \r\n\r\n```\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.\r\n  (0) Invalid argument:  Cannot place the graph because a reference or resource edge connects colocation groups with incompatible assigned devices: \r\n/job:localhost/replica:0/task:0/device:GPU:0 vs /job:localhost/replica:0/task:0/device:CPU:0. \r\nThe edge src node is while_20/exit/_95 , and the dst node is while_1_RetVal\r\n         [[node model/bi_rnn/StatefulPartitionedCall_1 (defined at /SageMaker/efs/Damayanti/ChargeBackModel_TF2/src/trainer.py:68) ]]\r\n  (1) Invalid argument:  Cannot place the graph because a reference or resource edge connects colocation groups with incompatible assigned devices: \r\n/job:localhost/replica:0/task:0/device:GPU:0 vs /job:localhost/replica:0/task:0/device:CPU:0. \r\nThe edge src node is while_20/exit/_95 , and the dst node is while_1_RetVal\r\n```", "My custom layer is a dynamic one as it has operations using the shape of its inputs, which is the output of `padded_batch`, so it's `None`. Hence, if I remove `dynamic=True`, it throws an error. And if I keep in the `dynamic=True` and try `Autograph`, it can't find the gradients for any of the trainable variables. I assume this is expected behavior. \r\n\r\nEdit: I fixed the `dyanmic=True` problem by using `tf.shape()` instead of accessing a tensor's shape directly, and now it's allowing me to use `@tf.function` decorator for training and not giving any gradient issues. \r\nHowever, the execution seems stuck with 100% CPU usage and I don't see any GPU activity, so I'm assuming the graph keeps getting built. The only output I can see is this line repeated many times: \r\n\r\n`E tensorflow/core/grappler/optimizers/meta_optimizer.cc:502] constant folding failed: Invalid argument: Unsupported type: 21`\r\n", "@ppham27 Sorry for spamming your notifs, but I just wanted to confirm. So there's no way to ensure asynchronous execution in a multi-GPU setting outside of graph mode, right? \r\n\r\nIs there a way to do distributed training without using MirroredStrategy or any way to train in parallel in eager mode? Otherwise, there's no point in doing multi-GPU training...", "Hi @dsgupta,\r\n\r\nIf you want, you can send me code to ppham27-github@google.com. Yes, it doesn't seem that the ASYNC execution mode is fully working, so you probably have to be using graph mode.\r\n\r\nThe last easy fix that I can think of to improve performance with `tf.function` is trying:\r\n\r\n```\r\nfrom tensorflow.python.eager import context\r\n\r\ncontext.context().mirroring_policy = context.MIRRORING_ALL\r\n```\r\n\r\nI doubt that this will work, too, though.", "Hi @ppham27, \r\n\r\nWhen I try using @tf.function, my execution just hangs without progressing (no activity on GPU) but with lots of activity on CPU. Can you please help me debug the issue? There are no errors being shown. ", "Are using using the `tf.function` in the right part?\r\n\r\nIdeally use use `tf.function` *only* in the outermost region:\r\n\r\n```\r\n@tf.function\r\ndef train_with_strategy(strategy, model, optimizer, dataset):\r\n  def train_step(x, y):\r\n    return _train_step(model, optimizer, x, y)\r\n\r\n  def update_state(state, x_and_y):\r\n    per_replica_loss = strategy.experimental_run_v2(train_step, x_and_y)\r\n    state['loss'] = strategy.reduce(\r\n        tf.distribute.ReduceOp.SUM, per_replica_loss, axis=None)       \r\n    state['step'] += 1\r\n    return state\r\n\r\n  initial_state = {'loss': np.nan, 'step': 0}\r\n  return dataset.reduce(initial_state, update_state)\r\n```\r\n\r\nWhere dataset comes from `strategy.experimental_distribute_dataset`. Also, run `tf.debugging.set_log_device_placement(True)` to help debug where ops are being placed.\r\n\r\n", "Hi @ppham27 , thanks for that example. Please also see issue: #31210 where I solved the decorator problem, but am now facing issues iterating over the dataset. I think the reason my program was unable to start because I have a large dataset with variable length sequences and padded batching. Is it possible that the graph is being retraced each time? \r\n\r\n[Click](https://colab.research.google.com/gist/dsgupta/7114aa6e13b4f33264ccf3758d169bab/test.ipynb) for Colab gist.\r\n\r\nI also had a doubt regarding the code above. What exactly is `state` and why should we use `dataset.reduce`? I followed the tutorial [here](https://www.tensorflow.org/beta/tutorials/distribute/training_loops) and then changed it to send the dataset directly to the function decorated by `@tf.function` as mentioned in issue #29911 \r\n\r\nIs the above snippet part of a bigger code that I can refer for efficient iteration and logging of metrics for multi-GPU training? \r\n", "What error am I suppose to be seeing?\r\n\r\nI made some small modifications to your Colab and everything seems fine: https://colab.sandbox.google.com/gist/ppham27/fb8b9eb2e46a05b3ad796d38a7174a6c/test.ipynb.\r\n\r\nThe dataset reduce and state stuff is what a for loop compiles down into after applying the tf.function and Autograph. Sometimes it's better to write it that way if you're experiencing problems with Autograph.", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=30855\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=30855\">No</a>\n", "Same issue, look like the mirrored strategy only works on multi-GPUs when the `fn` in strategy.experimental_run_v2(fn) is wrapped with tf.function, eager mode or only wrap with tf.function inside `fn`   will fail. Finally I got the meaning of this warning:\r\n\r\n> Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `experimental_run_v2` inside a tf.function to get the best performance.\r\n\r\n1. Is there any work on the eager mode support ? If not, we should issue a feature require.\r\n2. Is this behavior also apply to TPU or any other strategy? I can not find any doc on this problem\r\n", "For ppl struggling with this problem, [horovod](https://github.com/horovod) is a good workaround at this time, if you have to run in eager mode or tf.function only decorated in sub-block of model.  Here is my code for creating a distributed optimizer, other things follow the example of horovod.\r\n\r\n```\r\ndef create_distributed_optimizer(optimizer, name=None, device_dense='', device_sparse='',\r\n                         compression=hvd.Compression.none, sparse_as_dense=False):\r\n    class _DistributedOptimizer(tf.keras.optimizers.Optimizer):\r\n        def __init__(self, name, device_dense, device_sparse, compression, sparse_as_dense, config):\r\n            if name is None:\r\n                name = \"Distributed%s\" % self.__class__.__base__.__name__\r\n            self._allreduce_grads = hvd._make_allreduce_grads_fn(\r\n                name, device_dense, device_sparse, compression, sparse_as_dense)\r\n            super(self.__class__, self).__init__(**config)\r\n\r\n        def apply_gradients(self, grads_and_vars, *args, **kwargs):\r\n            if hvd.size() > 1:\r\n                grads, vars = zip(*grads_and_vars)\r\n                avg_grads = self._allreduce_grads(grads)\r\n                grads_and_vars = list(zip(avg_grads, vars))\r\n            return super(self.__class__, self).apply_gradients(grads_and_vars, *args, **kwargs)\r\n\r\n        @classmethod\r\n        def from_config(cls, cfg):\r\n            return cls(name, device_dense, device_sparse, compression, sparse_as_dense, cfg)\r\n\r\n    cls = type(optimizer.__class__.__name__, (optimizer.__class__,), dict(_DistributedOptimizer.__dict__))\r\n    return cls(name, device_dense, device_sparse, compression, sparse_as_dense, optimizer.get_config())\r\n```\r\n\r\nE.g.,\r\n\r\n```\r\nhvd.init()\r\nopt = tf.keres.optimizers.Adam()\r\nopt = create_distributed_optimizer(opt)\r\n\r\ndataset = tf.data.Dataset instance\r\nmode = Model()\r\n\r\nfirst_batch = True\r\nfor input in dataset:\r\n    results = model(input)\r\n    if first_batch:\r\n        hvd.broadcast_variables(model.variables, root_rank=0)\r\n        hvd.broadcast_variables(opt.variables(), root_rank=0)\r\n        first_batch = False\r\n     results = hvd.allreduce(results)\r\n```", "I observe the same issue here, that GPU run in sequential way for eager execution when I use MirroredStrategy, I'd like to confirm, the best way to address this issue is to use horovod? it is surprise that until now tf2.x still haven't resolved this problems"]}, {"number": 30854, "title": "Out of Memory Issues with beam search decoder ", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 1.13\r\n- Python version: 3.7\r\n- CUDA/cuDNN version: 10/7.66\r\n- GPU model and memory: v100 and 16GB\r\n\r\n**Describe the current behaviour**\r\nI am trying to implement a beam search decoder for a project. Currently, I am following the TensorFlow tutorial for neural machine translation from this link \r\n[tensorflow tutorial](https://github.com/tensorflow/tensorflow/blob/r1.13/tensorflow/contrib/eager/python/examples/nmt_with_attention/nmt_with_attention.ipynb\r\n)\r\nI have replaced the default GRU layer with LSTM layer. Without using beam search decoder, it was working fine with LSTM.\r\n\r\n**Code to reproduce the issue**\r\n\r\nMy current decoder looks as follows:\r\n`\r\nclass Decoder(tf.keras.Model):\r\n    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz, start_tokens, end_token):\r\n        super(Decoder, self).__init__()\r\n        self.batch_sz = batch_sz\r\n        self.dec_units = dec_units\r\n        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\r\n        self.lstm = lstm(self.dec_units)\r\n        self.fc = tf.keras.layers.Dense(vocab_size)\r\n        self.cell = tf.contrib.rnn.BasicLSTMCell(self.dec_units)  # tf.contrib.rnn.LSTMCell(self.dec_units)\r\n        self.beam_size = BEAM_SIZE\r\n        self.start_tokens = start_tokens\r\n        self.end_token = end_token\r\n\r\n        # used for attention\r\n        self.W1 = tf.keras.layers.Dense(self.dec_units)\r\n        self.W2 = tf.keras.layers.Dense(self.dec_units)\r\n        self.W3 = tf.keras.layers.Dense(self.dec_units)\r\n        self.V = tf.keras.layers.Dense(1)\r\n\r\n\r\n\r\n    def call(self, x, hidden, hidden2, enc_output):\r\n        # enc_output shape == (batch_size, max_length, hidden_size)\r\n\r\n        # hidden shape == (batch_size, hidden size)\r\n        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\r\n        # we are doing this to perform addition to calculate the score\r\n\r\n        hidden_with_time_axis = tf.expand_dims(hidden, 1)\r\n\r\n        hidden_with_time_axis2 = tf.expand_dims(hidden2, 1)\r\n\r\n        # score shape == (batch_size, max_length, 1)\r\n        # we get 1 at the last axis because we are applying tanh(FC(EO) + FC(H)) to self.V\r\n        score = self.V(\r\n            tf.nn.tanh(self.W1(enc_output) + self.W2(hidden_with_time_axis) + self.W3(hidden_with_time_axis2)))\r\n\r\n        # attention_weights shape == (batch_size, max_length, 1)\r\n        attention_weights = tf.nn.softmax(score, axis=1)\r\n\r\n        # context_vector shape after sum == (batch_size, hidden_size)\r\n        context_vector = attention_weights * enc_output\r\n        context_vector = tf.reduce_sum(context_vector, axis=1)\r\n\r\n        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\r\n        x = self.embedding(x)\r\n\r\n        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\r\n        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\r\n\r\n        output, h, c = self.lstm(x)\r\n\r\n        logits = self.fc(output)\r\n\r\n        beam = tf.contrib.seq2seq.BeamSearchDecoder(self.cell, self.embedding, self.start_tokens, self.end_token,\r\n                                                    tf.contrib.rnn.LSTMStateTuple(\r\n                                                        tf.contrib.seq2seq.tile_batch(h, multiplier=self.beam_size),\r\n                                                        tf.contrib.seq2seq.tile_batch(c,\r\n                                                                                      multiplier=self.beam_size)),\r\n                                                    self.beam_size)\r\n        output, beamOp , _ = tf.contrib.seq2seq.dynamic_decode(\r\n            beam, output_time_major=True, maximum_iterations=MAX_SEQUENCE_LENGTH)\r\n\r\n        predicted_ids = tf.transpose(tf.cast(output.predicted_ids[:, :, 0], tf.float32))\r\n        beamOp_h = beamOp[0][0][:, 0]\r\n\r\n        beamOp_c = beamOp[0][1][:, 0]\r\n\r\n        return predicted_ids, logits, beamOp_h, beamOp_c, attention_weights\r\n\r\n    def initialize_hidden_state(self):\r\n        return tf.zeros((self.batch_sz, self.dec_units))\r\n`\r\n\r\n\r\nI am a newbie to deep learning and TensorFlow and not sure if I am doing it in the correct way.\r\n\r\nI am getting Out of memory issue when I start training the model.\r\n\r\nI have already asked the question on StackOverflow a few days back since there is no reply, I am raising the issue here. Apologies if it's not an issue from the tensorflow side, as, as of now I am not sure if the issue in my code or not. \r\n\r\n", "comments": ["Apologies for the delay in response. Can you please provide the stack trace?\r\nFrom the issue title looks like you are hitting your gpu memory limit.\r\nYou can try reducing the ```batch_size``` and limiting gpu memory usage.\r\nSee https://www.tensorflow.org/guide/using_gpu#allowing_gpu_memory_growth", "Hi,\r\n\r\nYes, I am hitting GPU memory limit, I have reduced my batch size to 32 and units to 512, even then after a few iterations, I am hitting out of memory.\r\n\r\nAs per my current understanding by default, its using maximum allowed memory (I am running in eager execution mode), I am seeing it in my nvidia-smi output. Also, this is the only task using the GPU:\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 418.40.04    Driver Version: 418.40.04    CUDA Version: 10.1     |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  Tesla V100-SXM2...  On   | 00000000:00:1E.0 Off |                    0 |\r\n| N/A   46C    P0    42W / 300W |  15855MiB / 16130MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n\r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID   Type   Process name                             Usage      |\r\n|=============================================================================|\r\n|    0     24696      C   ...envs/amazonei_tensorflow_p36/bin/python 15845MiB |\r\n+-----------------------------------------------------------------------------+\r\n\r\n\r\nStack trace,\r\n\r\n`\r\n---------------------------------------------------------------------------\r\nResourceExhaustedError                    Traceback (most recent call last)\r\n<ipython-input-22-6135fcffc75e> in <module>\r\n     24             for t in range(1, targ.shape[1]):\r\n     25                 # passing enc_output to the decoder\r\n---> 26                 predicted_ids ,predictions, dec_hidden, dec_hidden2,_ = decoder(dec_input, dec_hidden, dec_hidden2,enc_output)\r\n     27 \r\n     28                 #loss += loss_function(targ[:, t], predictions[:,t])\r\n\r\n~/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py in __call__(self, inputs, *args, **kwargs)\r\n    590       else:\r\n    591         # Eager execution on data tensors.\r\n--> 592         outputs = self.call(inputs, *args, **kwargs)\r\n    593         self._handle_activity_regularization(inputs, outputs)\r\n    594         return outputs\r\n\r\n<ipython-input-18-8cdf4ffa6193> in call(self, x, hidden, hidden2, enc_output)\r\n     36         # score shape == (batch_size, max_length, 1)\r\n     37         # we get 1 at the last axis because we are applying tanh(FC(EO) + FC(H)) to self.V\r\n---> 38         score = self.V(tf.nn.tanh(self.W1(enc_output) + self.W2(hidden_with_time_axis) + self.W3(hidden_with_time_axis2)))\r\n     39 \r\n     40         # attention_weights shape == (batch_size, max_length, 1)\r\n\r\n~/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py in __call__(self, inputs, *args, **kwargs)\r\n    590       else:\r\n    591         # Eager execution on data tensors.\r\n--> 592         outputs = self.call(inputs, *args, **kwargs)\r\n    593         self._handle_activity_regularization(inputs, outputs)\r\n    594         return outputs\r\n\r\n~/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py in call(self, inputs)\r\n    975       outputs = gen_math_ops.mat_mul(inputs, self.kernel)\r\n    976     if self.use_bias:\r\n--> 977       outputs = nn.bias_add(outputs, self.bias)\r\n    978     if self.activation is not None:\r\n    979       return self.activation(outputs)  # pylint: disable=not-callable\r\n\r\n~/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py in bias_add(value, bias, data_format, name)\r\n   1978       value = ops.convert_to_tensor(value, name=\"input\")\r\n   1979       bias = ops.convert_to_tensor(bias, dtype=value.dtype, name=\"bias\")\r\n-> 1980     return gen_nn_ops.bias_add(value, bias, data_format=data_format, name=name)\r\n   1981 \r\n   1982 \r\n\r\n~/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py in bias_add(value, bias, data_format, name)\r\n    737       else:\r\n    738         message = e.message\r\n--> 739       _six.raise_from(_core._status_to_exception(e.code, message), None)\r\n    740   # Add nodes to the TensorFlow graph.\r\n    741   if data_format is None:\r\n\r\n~/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/six.py in raise_from(value, from_value)\r\n\r\nResourceExhaustedError: OOM when allocating tensor with shape[64,40,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:BiasAdd] name: decoder/dense_1/BiasAdd/\r\n`\r\nEDIT: This is the stack trace when I am using default batch size: 64 and LSTM units: 1024\r\n\r\n\r\n", "Reducing the embeddings dimensions did the trick.\r\n\r\nI have reduced the size of embeddings, units and then batch size and finally, I am able to train, but it's super slow compared to the default decoder. \r\n\r\nI have total 65K rows in my data it used to take around 2-3 hours for training with 30-35 epochs.\r\nBut now with reduced dimensions, it's been more than 2 hours and I am yet to finish an epoch. \r\nIs something wrong with my code? or it's usually this slow.", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=30854\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=30854\">No</a>\n"]}, {"number": 30853, "title": "Update README.md - specify Arduino IDE version", "body": "This commit specifies that the HOWTO described in the README applies to the Arduino *Desktop* IDE. Specific features, eg. Serial Plotter, are for the time being only available on the Desktop version.", "comments": ["cc @petewarden "]}, {"number": 30852, "title": "Teacher-forcing in the Transformer tutorial", "body": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/beta/tutorials/text/transformer#training_and_checkpointing\r\n\r\n## Description of issue (what needs changing):\r\nTeacher-forcing seems to not be implemented?\r\n\r\n### Clear description\r\nThe documentation here mentions that the training uses teacher-forcing, however, it doesn't seem like, with the code shown, that this is implemented. The variable `tar_real` is the true outputs, but it seems to only be used for loss and accuracy computations?\r\n\r\nPlease let me know if I'm making a mistake here! Thanks in advance.", "comments": ["Each `train_step` takes in `inp` and `tar` objects from the dataset in the training loop. Teacher forcing is indeed used since the correct example from the dataset is always used as input during training (as opposed to the \"incorrect\" output from the previous training step): \r\n\r\n* `tar` is split into `tar_inp`, `tar_real` (offset by one character)\r\n* `inp`, `tar_inp` is used as input to the model\r\n* model produces an output which is compared with `tar_real` to calculate loss\r\n* model output is discarded (not used anymore)\r\n* repeat loop\r\n\r\n> Teacher forcing is a procedure ... in which during training the model receives the ground truth output y(t) as input at time t+1.\r\n> Page 372, Deep Learning, 2016.", "@tlkh Thanks for the response! I see what you mean."]}, {"number": 30851, "title": "Can not Exporting a GraphDef from file", "body": "Hi, i used code provided in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/convert/cmdline_examples.md. \r\n\r\nConvert a TensorFlow GraphDef \r\n\r\n```\r\ncurl https://storage.googleapis.com/download.tensorflow.org/models/mobilenet_v1_0.50_128_frozen.tgz \\\r\n  | tar xzv -C /tmp\r\ntflite_convert \\\r\n  --output_file=/tmp/foo.tflite \\\r\n  --graph_def_file=/tmp/mobilenet_v1_0.50_128/frozen_graph.pb \\\r\n  --input_arrays=input \\\r\n  --output_arrays=MobilenetV1/Predictions/Reshape_1**\r\n```\r\n\r\n### error\r\n Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2019-07-18 17:14:34.558992: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2494150000 Hz\r\n2019-07-18 17:14:34.559779: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x560a0f59d790 executing computations on platform Host. Devices:\r\n2019-07-18 17:14:34.559868: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\r\n2019-07-18 17:14:35.103189: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)\r\n2019-07-18 17:14:35.103362: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\r\n2019-07-18 17:14:35.426148: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:716] Optimization results for grappler item: graph_to_optimize\r\n2019-07-18 17:14:35.426184: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   constant folding: Graph size after: 174 nodes (-381), 173 edges (-408), time = 270.209ms.\r\n2019-07-18 17:14:35.426195: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   constant folding: Graph size after: 174 nodes (0), 173 edges (0), time = 14.101ms.\r\nTraceback (most recent call last):\r\n  File \"/home/wangxy/miniconda3/envs/ml/bin/tflite_convert\", line 10, in <module>\r\n    sys.exit(main())\r\n  File \"/home/wangxy/miniconda3/envs/ml/lib/python3.6/site-packages/tensorflow_core/lite/python/tflite_convert.py\", line 515, in main\r\n    app.run(main=run_main, argv=sys.argv[:1])\r\n  File \"/home/wangxy/miniconda3/envs/ml/lib/python3.6/site-packages/tensorflow_core/python/platform/app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"/home/wangxy/miniconda3/envs/ml/lib/python3.6/site-packages/absl/app.py\", line 300, in run\r\n    _run_main(main, args)\r\n  File \"/home/wangxy/miniconda3/envs/ml/lib/python3.6/site-packages/absl/app.py\", line 251, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"/home/wangxy/miniconda3/envs/ml/lib/python3.6/site-packages/tensorflow_core/lite/python/tflite_convert.py\", line 511, in run_main\r\n    _convert_tf1_model(tflite_flags)\r\n  File \"/home/wangxy/miniconda3/envs/ml/lib/python3.6/site-packages/tensorflow_core/lite/python/tflite_convert.py\", line 199, in _convert_tf1_model\r\n    output_data = converter.convert()\r\n  File \"/home/wangxy/miniconda3/envs/ml/lib/python3.6/site-packages/tensorflow_core/lite/python/lite.py\", line 983, in convert\r\n    **converter_kwargs)\r\n  File \"/home/wangxy/miniconda3/envs/ml/lib/python3.6/site-packages/tensorflow_core/lite/python/convert.py\", line 437, in toco_convert_impl\r\n    enable_mlir_converter=enable_mlir_converter)\r\n  File \"/home/wangxy/miniconda3/envs/ml/lib/python3.6/site-packages/tensorflow_core/lite/python/convert.py\", line 155, in toco_convert_protos\r\n    fp_debug.write(debug_info_str)\r\n  File \"/home/wangxy/miniconda3/envs/ml/lib/python3.6/tempfile.py\", line 485, in func_wrapper\r\n    return func(*args, **kwargs)\r\nTypeError: a bytes-like object is required, not 'str'\r\nException ignored in: <bound method _TensorCacheDeleter.__del__ of <tensorflow.python.eager.context._TensorCacheDeleter object at 0x7f484fd2c550>>\r\nTraceback (most recent call last):\r\n  File \"/home/wangxy/miniconda3/envs/ml/lib/python3.6/site-packages/tensorflow_core/python/eager/context.py\", line 316, in __del__\r\nTypeError: argument of type 'NoneType' is not iterable\r\n\r\n\r\nI also try code fromhttps://www.tensorflow.org/lite/convert/cmdline_examples?source=post_page\r\nthere still appears mistake and it can not get tflite\r\n\r\n```\r\nimport tensorflow as tf\r\ngraph_def_file = \"/path/to/Downloads/mobilenet_v1_1.0_224/frozen_graph.pb\"\r\ninput_arrays = [\"input\"]\r\noutput_arrays = [\"MobilenetV1/Predictions/Softmax\"]\r\n\r\nconverter = tf.lite.TFLiteConverter.from_frozen_graph(\r\n  graph_def_file, input_arrays, output_arrays)\r\ntflite_model = converter.convert()\r\nopen(\"converted_model.tflite\", \"wb\").write(tflite_model)\r\n```\r\n\r\n### error:\r\n2019-07-18 17:51:00.100545: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2019-07-18 17:51:00.130812: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2494150000 Hz\r\n2019-07-18 17:51:00.131427: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564072ecb610 executing computations on platform Host. Devices:\r\n2019-07-18 17:51:00.131468: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 2, in <module>\r\n  File \"/home/wangxy/miniconda3/envs/ml/lib/python3.6/site-packages/tensorflow_core/lite/python/lite.py\", line 668, in from_frozen_graph\r\n    raise IOError(\"File '{0}' does not exist.\".format(graph_def_file))\r\nOSError: File '/home/python/frozen_graph.pb' does not exist.\r\n>>> tflite_model = converter.convert()\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\nNameError: name 'converter' is not defined\r\n>>> open(\"converted_model.tflite\", \"wb\").write(tflite_model)\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\nNameError: name 'tflite_model' is not defined\r\n>>> \r\nException ignored in: <bound method _TensorCacheDeleter.__del__ of <tensorflow.python.eager.context._TensorCacheDeleter object at 0x7fa9c5d9c278>>\r\nTypeError: argument of type 'NoneType' is not iterable\r\n\r\n\r\n**System information**\r\n- OS Platform is Linux Ubuntu 18.04\r\n- TensorFlow installed from binary and its version is 1.15.0-dev20190717 \r\n- environment is anaconda  \r\n- Python version:Python 3.6.8\r\n\r\n\r\nSo, if anyone have the solution please tell me, thank you very much\r\n\r\n\r\n", "comments": ["hi, does this problem still exist? can you try in tf-nightly?", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30851\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30851\">No</a>\n"]}, {"number": 30850, "title": "Restoring Keras model fails inside a distribution strategy scope", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **yes**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Arch Linux**\r\n- TensorFlow installed from (source or binary): **binary** (using `pip`)\r\n- TensorFlow version (use command below): both `v1.14.0-rc1-22-gaf24dc9 1.14.0` and `v2.0.0-beta0-17-g8e423e3 2.0.0-beta1`\r\n- Python version: **3.7.3**\r\n- CUDA/cuDNN version: **CUDA 10.1.168-4, cuDNN 7.6.1.34-1**\r\n- GPU model and memory: **NVIDIA Quadro P2000, 4GB**\r\n\r\n**Describe the current behavior**\r\nInside a distribution strategy scope, restoring a Keras model (that has been trained at all) with `tf.keras.models.load_model` raises the exception shown below (while handling the optimizer in particular, it seems).\r\n\r\n(Looks a bit similar to #28599 if you squint, but many details differ.)\r\n\r\n**Describe the expected behavior**\r\nRestoring the model should succeed.\r\n\r\n**Code to reproduce the issue**\r\n```python\r\nimport numpy as np, tensorflow as tf\r\n\r\nstrategy = tf.distribute.MirroredStrategy()\r\npath = \"/tmp/model.hdf5\"\r\n\r\nwith strategy.scope():\r\n    # Construct model.\r\n    model = tf.keras.models.Sequential([tf.keras.layers.Dense(1, input_shape=(1,))])\r\n    model.compile(optimizer=tf.keras.optimizers.SGD(), loss=tf.keras.metrics.mse)\r\n    # Do a fit so the optimizer weights are created. Removing this lets the restore succeed.\r\n    model.fit(np.array([[1]]), np.array([[1]]))\r\n    # Save and attempt to restore.\r\n    tf.keras.models.save_model(model, path)\r\n    tf.keras.models.load_model(path)\r\n```\r\n**Other info / logs**\r\nTraceback for TF 2.0 (TF 1.14 is the same except for line numbers):\r\n```\r\n  File \".../tensorflow/python/keras/saving/save.py\", line 137, in load_model\r\n    return hdf5_format.load_model_from_hdf5(filepath, custom_objects, compile)\r\n  File \".../tensorflow/python/keras/saving/hdf5_format.py\", line 187, in load_model_from_hdf5\r\n    model._make_train_function()\r\n  File \".../tensorflow/python/keras/engine/training.py\", line 1974, in _make_train_function\r\n    params=self._collected_trainable_weights, loss=self.total_loss)\r\n  File \".../tensorflow/python/keras/optimizer_v2/optimizer_v2.py\", line 491, in get_updates\r\n    grads = self.get_gradients(loss, params)\r\n  File \".../tensorflow/python/keras/optimizer_v2/optimizer_v2.py\", line 391, in get_gradients\r\n    grads = gradients.gradients(loss, params)\r\n  File \".../tensorflow/python/ops/gradients_impl.py\", line 158, in gradients\r\n    unconnected_gradients)\r\n  File \".../tensorflow/python/ops/gradients_util.py\", line 543, in _GradientsHelper\r\n    for x in xs\r\n  File \".../tensorflow/python/ops/gradients_util.py\", line 543, in <listcomp>\r\n    for x in xs\r\n  File \".../tensorflow/python/distribute/values.py\", line 643, in handle\r\n    raise ValueError(\"`handle` is not available outside the replica context\"\r\nValueError: `handle` is not available outside the replica context or a `tf.distribute.Strategy.update()` call.\r\n```", "comments": ["Hi - we don't support saving with hdf5 format. However, you can save and restore with the standard TF format - just remove the hdf5 extension from the file path. See https://www.tensorflow.org/beta/tutorials/distribute/save_and_load for more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=30850\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=30850\">No</a>\n", "Unfortunately, that does not resolve the issue: it makes `save_model` fail, so that the program never even gets a chance to load the model.\r\n\r\n_With TF 1.14:_ removing the extension still defaults to HDF5, leading to the same exception, and specifying `save_format=\"tf\"` gives this:\r\n```\r\n  File \".../tensorflow/python/keras/saving/save.py\", line 86, in save_model\r\n    'Saving the model as SavedModel is not supported in TensorFlow 1.X'\r\nNotImplementedError: Saving the model as SavedModel is not supported in TensorFlow 1.Xgraph mode. Please enable eager execution or use the \"h5\" save format.\r\n```\r\n(I don't think it would be feasible for me to use eager execution, due to external constraints.)\r\n\r\n_With TF 2.0:_ removing the extension and specifying `save_format=\"tf\"` both give this exception:\r\n```\r\n  File \".../tensorflow/python/keras/saving/save.py\", line 106, in save_model\r\n    saved_model.save(model, filepath, overwrite, include_optimizer)\r\n  File \".../tensorflow/python/keras/saving/saved_model.py\", line 1492, in save\r\n    save_lib.save(model, filepath)\r\n  File \".../tensorflow/python/saved_model/save.py\", line 835, in save\r\n    meta_graph_def, saveable_view, signatures)\r\n  File \".../tensorflow/python/saved_model/save.py\", line 531, in _fill_meta_graph_def\r\n    object_map, resource_map, asset_info = saveable_view.map_resources()\r\n  File \".../tensorflow/python/saved_model/save.py\", line 252, in map_resources\r\n    new_variable = resource_variable_ops.copy_to_graph_uninitialized(obj)\r\n  File \".../tensorflow/python/ops/resource_variable_ops.py\", line 1791, in copy_to_graph_uninitialized\r\n    synchronization=var.synchronization,\r\n  File \".../tensorflow/python/ops/variables.py\", line 514, in synchronization\r\n    raise NotImplementedError\r\nNotImplementedError\r\n```\r\nUsing `model.save` instead of `save_model` has the same issues.\r\n\r\nThose exceptions occur even with the modified and reduced code shown below, with (1) the call to `save_model` outside the scope, as suggested by the linked document, and (2) no call to `fit` (though the same exceptions happen with `fit` present as well).\r\n```python\r\nimport tensorflow as tf\r\n\r\nstrategy = tf.distribute.MirroredStrategy()\r\n\r\nwith strategy.scope():\r\n    model = tf.keras.models.Sequential([tf.keras.layers.Dense(1, input_shape=(1,))])\r\n    model.compile(optimizer=tf.keras.optimizers.SGD(), loss=tf.keras.metrics.mse)\r\ntf.keras.models.save_model(model, \"/tmp/model\", save_format=\"tf\")\r\n```\r\n\r\n(Side note: Though I am able to test with 2.0, a solution for 1.x would be more immediately useful for me. But any help with either version is highly appreciated, of course!)", "The error you see with 2.0 has been fixed, which version of 2.0 are you testing with?\r\n\r\nFor 1.x, maybe you need to use a different API then if that one is not supported. Do you need only the weights from the trained model or do you need the graph too? ", "For TF 2.0, I have `tf.version.VERSION == '2.0.0-beta1'` and `tf.version.GIT_VERSION == 'v2.0.0-beta0-17-g8e423e3'`. I installed via `pip install tensorflow-gpu==2.0.0b1`. That is the latest released version on both [GitHub](https://github.com/tensorflow/tensorflow/releases) and [PyPI](https://pypi.org/project/tensorflow-gpu/#history), as far as I can tell.\r\n\r\nIf I understand TF correctly, I don't need to store the graph, as I am restoring in Python with access to the same code that created the model originally. So perhaps `save_model` and `load_model` are overkill. However, I do need the state of the optimizer, which rules out using just `model.{save,load}_weights`. I also attempted to load one copy of the model outside the scope, construct another copy inside the scope, and then use `model.{get,set}_weights` and `model.optimizer.{get,set}_weights`, but it seems that the optimizer weights are not created until `model.fit` has been called with data, so that runs into issues around mismatch of expected number of weights.\r\n\r\nIn TF 1.14, I also tried `tf.contrib.saved_model.{save,load}_keras_model`, which fails in a different way:\r\n```python\r\nimport numpy as np, tensorflow as tf\r\n\r\nstrategy = tf.distribute.MirroredStrategy()\r\npath = \"/tmp/model\"\r\n\r\nwith strategy.scope():\r\n    model = tf.keras.models.Sequential([tf.keras.layers.Dense(1, input_shape=(1,))])\r\n    model.compile(optimizer=tf.keras.optimizers.SGD(), loss=tf.keras.metrics.mse)\r\n    model.fit(np.array([[1]]), np.array([[1]]))\r\n    tf.contrib.saved_model.save_keras_model(model, path)\r\n\r\n    model = tf.contrib.saved_model.load_keras_model(path)\r\n    model.compile(optimizer=tf.keras.optimizers.SGD(), loss=tf.keras.metrics.mse)\r\n    model.fit(np.array([[1]]), np.array([[1]]))\r\n```\r\ngives this exception inside the second `model.fit`:\r\n```\r\n  File \".../tensorflow/python/keras/engine/training.py\", line 649, in fit\r\n    validation_freq=validation_freq)\r\n  File \".../tensorflow/python/keras/engine/training_distributed.py\", line 143, in fit_distributed\r\n    steps_name='steps_per_epoch')\r\n  File \".../tensorflow/python/keras/engine/training_arrays.py\", line 274, in model_iteration\r\n    batch_outs = f(actual_inputs)\r\n  File \".../tensorflow/python/keras/backend.py\", line 3292, in __call__\r\n    run_metadata=self.run_metadata)\r\n  File \".../tensorflow/python/client/session.py\", line 1458, in __call__\r\n    run_metadata_ptr)\r\ntensorflow.python.framework.errors_impl.FailedPreconditionError: Error while reading resource variable dense_2/kernel from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/dense_2/kernel/N10tensorflow3VarE does not exist.\r\n         [[{{node dense_3/MatMul/ReadVariableOp}}]]\r\n```", "for 2.0, please test with the latest nightly version: https://pypi.org/project/tf-nightly-gpu-2.0-preview/\r\n\r\n", "Thanks, it seems to work with the 2.0 preview version.\r\n\r\nFor TF 1.14, I've found a workaround, which I'll document here for anyone else coming across this:\r\n\r\n1. Save the model with `tf.keras.models.save_model`.\r\n1. Load a copy of the model outside the strategy scope using `tf.keras.models.load_model`. Retrieve its weights using `model.get_weights()` and `model.optimizer.get_weights()`.\r\n1. Create and compile a new copy of the model inside the scope, in the same way as you did the first time.\r\n1. Now, _in a callback_, copy the loaded weights to the newly compiled model and its optimizer. The callback is key: the optimizer weights are not created before the call to `model.fit`, so the copying cannot be done in the normal flow of code, but the `on_train_begin` callback runs after the weights are created and before any training has happened.\r\n\r\nAn example of what the callback might look like:\r\n\r\n```python\r\nclass LoadWeightsCallback(tf.keras.callbacks.Callback):\r\n    _chief_worker_only = False\r\n\r\n    def __init__(self, weights, optimizer_weights):\r\n        self.weights = weights\r\n        self.optimizer_weights = optimizer_weights\r\n\r\n    def on_train_begin(self, logs=None):\r\n        self.model.set_weights(self.weights)\r\n        self.model.optimizer.set_weights(self.optimizer_weights)\r\n```", "Hi @guptapriya , I tried your suggestion of removing 'h5' extension from the file's name and then I followed tutorial on your provided line but I am receiving following error. Please suggest me if there is a way to train the model again on multiple GPUs from lastly saved model file. Thank you!\r\n`````\r\n  File \"model_with_tfsplit.py\", line 98, in <module>\r\n    model =tf.keras.models.load_model(model_path) # Loading for retraining\r\n  File \"/home/rishabh/.local/lib/python2.7/site-packages/tensorflow_core/python/keras/saving/save.py\", line 138, in load_model\r\n    return hdf5_format.load_model_from_hdf5(filepath, custom_objects, compile)\r\n  File \"/home/rishabh/.local/lib/python2.7/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py\", line 187, in load_model_from_hdf5\r\n    model._make_train_function()\r\n  File \"/home/rishabh/.local/lib/python2.7/site-packages/tensorflow_core/python/keras/engine/training.py\", line 2059, in _make_train_function\r\n    params=self._collected_trainable_weights, loss=self.total_loss)\r\n  File \"/home/rishabh/.local/lib/python2.7/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\", line 506, in get_updates\r\n    return [self.apply_gradients(grads_and_vars)]\r\n  File \"/home/rishabh/.local/lib/python2.7/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\", line 438, in apply_gradients\r\n    return distribute_ctx.get_replica_context().merge_call(\r\nAttributeError: 'NoneType' object has no attribute 'merge_call'", "Looking at the logs, it seems that the hdf5 code is still being used in the loading part? Can you use the tf format instead? (or use 2.0 which automatically uses TF format i believe?) ", "Hallo Priya,\nthank you for your reply. I am actually using TF 2.0 latest nightly.\nAlthough, just to be clear, do I have to save the file during initial\ntraining without \".h5\" extension? or Can I just rename the file because I\nsaved the model with \".h5\" extension and then renamed the file for the\nreloading and training which resulted in the error above.\n\nOn Tue, Aug 6, 2019 at 6:22 PM guptapriya <notifications@github.com> wrote:\n\n> Looking at the logs, it seems that the hdf5 code is still being used in\n> the loading part? Can you use the tf format instead? (or use 2.0 which\n> automatically uses TF format i believe?)\n>\n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/30850?email_source=notifications&email_token=ADZMMPAH4CSOIJF4IHJ7QZ3QDGQKXA5CNFSM4IE5S5O2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD3VVJ6Y#issuecomment-518739195>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ADZMMPAG5E7ISMB5DB57XPTQDGQKXANCNFSM4IE5S5OQ>\n> .\n>\n", "Yes, you need to save it in tf format to begin with to be able to load back with tf format. just changing the filename later does not help. ", "Alright, I understand. So, there is no other way to continue training on\nmultiple GPUs.? The thing is my model and datasets are huge so it take many\nhours to train for one epoch even. :(\nI already have issues (raise this issue here on Github already) training my\nmodel faster on 4 GPUs. Thank you for your help Priya!\n\nOn Tue, Aug 6, 2019 at 8:29 PM guptapriya <notifications@github.com> wrote:\n\n> Yes, you need to save it in tf format to begin with to be able to load\n> back with tf format. just changing the filename later does not help.\n>\n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/30850?email_source=notifications&email_token=ADZMMPGOZCFGCGGJANP2SATQDG7JTA5CNFSM4IE5S5O2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD3WA57I#issuecomment-518786813>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ADZMMPDSMOITGZZQLNF42H3QDG7JTANCNFSM4IE5S5OQ>\n> .\n>\n", "@rishabhsahrawat if you only care about weights and have the model code still, you can simply load the weights into a non distributed setup first. Then copy the weights into a distributed model using set_weights. Similar to workaround proposed in https://github.com/tensorflow/tensorflow/issues/30850#issuecomment-513523828 ", "Yes I still have the model. I will try your suggestion tomorrow morning and\nwill get back to you. Thank you:)\n\nOn Tue, Aug 6, 2019 at 9:02 PM guptapriya <notifications@github.com> wrote:\n\n> @rishabhsahrawat <https://github.com/rishabhsahrawat> if you only care\n> about weights and have the model code still, you can simply load the\n> weights into a non distributed setup first. Then copy the weights into a\n> distributed model using set_weights. Similar to workaround proposed in #30850\n> (comment)\n> <https://github.com/tensorflow/tensorflow/issues/30850#issuecomment-513523828>\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/30850?email_source=notifications&email_token=ADZMMPEYYZBAPVM2W5UU6KTQDHDEZA5CNFSM4IE5S5O2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD3WDXVA#issuecomment-518798292>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ADZMMPHOZ3AKUKZLDWJCOGLQDHDEZANCNFSM4IE5S5OQ>\n> .\n>\n", "Hi @guptapriya , I tried your suggestion on which I am facing following error. \r\n````\r\nValueError: You called `set_weights(weights)` on optimizer Adam with a  weight list of length 19, but the optimizer was expecting 0 weights\r\n`````\r\nThis is how I am applying it.\r\n\r\n`````\r\nmodel =tf.keras.models.load_model('saved_model.h5')# weight loading\r\nmodel_weights = model.get_weights()\r\nopt_weights = model.optimizer.get_weights()# optimizers weight\r\n\r\nmirrored_strategy = tf.distribute.MirroredStrategy()\r\nwith mirrored_strategy.scope():\r\n    <model definition including model.compile()>\r\n\r\nclass LoadWeightsCallback(tf.keras.callbacks.Callback):\r\n    _chief_worker_only = False\r\n\r\n    def __init__(self, weights, optimizer_weights):\r\n        self.weights = weights\r\n        self.optimizer_weights = optimizer_weights\r\n\r\n    def on_train_begin(self, logs=None):\r\n        self.model.set_weights(self.weights)\r\n        self.model.optimizer.set_weights(self.optimizer_weights)\r\n\r\nmodel.fit(train_data, epochs=20 , callbacks = [LoadWeightsCallback(model_weights, opt_weights)]\r\n`````\r\n\r\nIf I try without loading optimizer's weight and just update layers weights, then I receive `Resource Exhausted Error`, but if I either choose only one device in `tf.distribute.MirroredStrategy(devices= [\"/gpu:0\"])` or just don't define the model inside `mirror_strategy.scope()` then it trains. I only have 2 Tesla T4 GPUs now but earlier when I had 4, I could train the same model on selecting 2 GPUs. I also could use all 4 GPUs but the training speed was slower on 4. There is really a lot going on in `Mirror Strategy` function. Here is my [issue](https://github.com/tensorflow/tensorflow/issues/31162) with this.", "I think the optimizer weights issue is because sometimes optimizer weights are only created during the first step. So when you try to load the weights before training starts, weights have not yet been created. \r\nOne workaround can be to just do 1 step first and then load the weights. @k-w-w do you know what could be a better alternative for loading optimizer weights ? \r\n", "with official released tf 2.0, I meet the similar error even try to load the tf format model. \r\n\r\ntensorflow.python.framework.errors_impl.FailedPreconditionError: Error while reading resource variable dense/kernel_34381 from Container: localhost. This could mean that the variable was uninitialized. Not found: Container localhost does not\r\n exist. (Could not find resource: localhost/dense/kernel_34381) [Op:ReadVariableOp]                                                                                                                                                              ", "> For TF 2.0, I have `tf.version.VERSION == '2.0.0-beta1'` and `tf.version.GIT_VERSION == 'v2.0.0-beta0-17-g8e423e3'`. I installed via `pip install tensorflow-gpu==2.0.0b1`. That is the latest released version on both [GitHub](https://github.com/tensorflow/tensorflow/releases) and [PyPI](https://pypi.org/project/tensorflow-gpu/#history), as far as I can tell.\r\n> \r\n> If I understand TF correctly, I don't need to store the graph, as I am restoring in Python with access to the same code that created the model originally. So perhaps `save_model` and `load_model` are overkill. However, I do need the state of the optimizer, which rules out using just `model.{save,load}_weights`. I also attempted to load one copy of the model outside the scope, construct another copy inside the scope, and then use `model.{get,set}_weights` and `model.optimizer.{get,set}_weights`, but it seems that the optimizer weights are not created until `model.fit` has been called with data, so that runs into issues around mismatch of expected number of weights.\r\n> \r\n> In TF 1.14, I also tried `tf.contrib.saved_model.{save,load}_keras_model`, which fails in a different way:\r\n> \r\n> ```python\r\n> import numpy as np, tensorflow as tf\r\n> \r\n> strategy = tf.distribute.MirroredStrategy()\r\n> path = \"/tmp/model\"\r\n> \r\n> with strategy.scope():\r\n>     model = tf.keras.models.Sequential([tf.keras.layers.Dense(1, input_shape=(1,))])\r\n>     model.compile(optimizer=tf.keras.optimizers.SGD(), loss=tf.keras.metrics.mse)\r\n>     model.fit(np.array([[1]]), np.array([[1]]))\r\n>     tf.contrib.saved_model.save_keras_model(model, path)\r\n> \r\n>     model = tf.contrib.saved_model.load_keras_model(path)\r\n>     model.compile(optimizer=tf.keras.optimizers.SGD(), loss=tf.keras.metrics.mse)\r\n>     model.fit(np.array([[1]]), np.array([[1]]))\r\n> ```\r\n> \r\n> gives this exception inside the second `model.fit`:\r\n> \r\n> ```\r\n>   File \".../tensorflow/python/keras/engine/training.py\", line 649, in fit\r\n>     validation_freq=validation_freq)\r\n>   File \".../tensorflow/python/keras/engine/training_distributed.py\", line 143, in fit_distributed\r\n>     steps_name='steps_per_epoch')\r\n>   File \".../tensorflow/python/keras/engine/training_arrays.py\", line 274, in model_iteration\r\n>     batch_outs = f(actual_inputs)\r\n>   File \".../tensorflow/python/keras/backend.py\", line 3292, in __call__\r\n>     run_metadata=self.run_metadata)\r\n>   File \".../tensorflow/python/client/session.py\", line 1458, in __call__\r\n>     run_metadata_ptr)\r\n> tensorflow.python.framework.errors_impl.FailedPreconditionError: Error while reading resource variable dense_2/kernel from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/dense_2/kernel/N10tensorflow3VarE does not exist.\r\n>          [[{{node dense_3/MatMul/ReadVariableOp}}]]\r\n> ```\r\n\r\nanyluck on resolving this?\r\n", "Same error here too", "> Hi @guptapriya , I tried your suggestion on which I am facing following error.\r\n> \r\n> ```\r\n> ValueError: You called `set_weights(weights)` on optimizer Adam with a  weight list of length 19, but the optimizer was expecting 0 weights\r\n> ```\r\n> \r\n> This is how I am applying it.\r\n> \r\n> ```\r\n> model =tf.keras.models.load_model('saved_model.h5')# weight loading\r\n> model_weights = model.get_weights()\r\n> opt_weights = model.optimizer.get_weights()# optimizers weight\r\n> \r\n> mirrored_strategy = tf.distribute.MirroredStrategy()\r\n> with mirrored_strategy.scope():\r\n>     <model definition including model.compile()>\r\n> \r\n> class LoadWeightsCallback(tf.keras.callbacks.Callback):\r\n>     _chief_worker_only = False\r\n> \r\n>     def __init__(self, weights, optimizer_weights):\r\n>         self.weights = weights\r\n>         self.optimizer_weights = optimizer_weights\r\n> \r\n>     def on_train_begin(self, logs=None):\r\n>         self.model.set_weights(self.weights)\r\n>         self.model.optimizer.set_weights(self.optimizer_weights)\r\n> \r\n> model.fit(train_data, epochs=20 , callbacks = [LoadWeightsCallback(model_weights, opt_weights)]\r\n> ```\r\n> \r\n> If I try without loading optimizer's weight and just update layers weights, then I receive `Resource Exhausted Error`, but if I either choose only one device in `tf.distribute.MirroredStrategy(devices= [\"/gpu:0\"])` or just don't define the model inside `mirror_strategy.scope()` then it trains. I only have 2 Tesla T4 GPUs now but earlier when I had 4, I could train the same model on selecting 2 GPUs. I also could use all 4 GPUs but the training speed was slower on 4. There is really a lot going on in `Mirror Strategy` function. Here is my [issue](https://github.com/tensorflow/tensorflow/issues/31162) with this.\r\n\r\nwhere do i get the callback `LoadWeightsCallback`"]}]