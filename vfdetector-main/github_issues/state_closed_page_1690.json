[{"number": 2201, "title": "issues when installing on EC2", "body": "I am trying to install TF on EC2 GPU instance, I'm following http://eatcodeplay.com/installing-gpu-enabled-tensorflow-with-python-3-4-in-ec2/ tutorial. In following step I will get this error. I should mention I am using Master not the specific head that is in tutorial (I guess it's version 6.5):\n\n```\nubuntu@ip:/mnt/tmp/tensorflow$ bazel build -c opt --verbose_failures --config=cuda //tensorflow/cc:tutorials_example_trainer\nINFO: Found 1 target...\nINFO: From Compiling tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:\ntensorflow/stream_executor/cuda/cuda_gpu_executor.cc:198:15: warning: 'std::string perftools::gputools::cuda::GetBinaryDir(bool)' defined but not used [-Wunused-function]\n static string GetBinaryDir(bool strip_exe) {\n               ^\nINFO: From Compiling tensorflow/stream_executor/cuda/cuda_dnn.cc:\ntensorflow/stream_executor/cuda/cuda_dnn.cc: In constructor 'perftools::gputools::cuda::ScopedFilterDescriptor::ScopedFilterDescriptor(perftools::gputools::cuda::CUDAExecutor*, const perftools::gputools::dnn::FilterDescriptor&, const perftools::gputools::dnn::BatchDescriptor&, cudnnDataType_t)':\ntensorflow/stream_executor/cuda/cuda_dnn.cc:404:25: warning: variable 'format' set but not used [-Wunused-but-set-variable]\n     cudnnTensorFormat_t format;\n                         ^\ntensorflow/stream_executor/cuda/cuda_dnn.cc: In instantiation of 'cudnnStatus_t perftools::gputools::cuda::dynload::DynLoadShim__cudnnSetConvolutionNdDescriptor::operator()(perftools::gputools::cuda::CUDAExecutor*, Args ...) [with Args = {cudnnConvolutionStruct*, int, int*, int*, int*, cudnnConvolutionMode_t, cudnnDataType_t}]':\ntensorflow/stream_executor/cuda/cuda_dnn.cc:485:43:   required from here\ntensorflow/stream_executor/cuda/cuda_dnn.cc:159:38: error: too many arguments to function\n       cudnnStatus_t retval = DynLoad()(args...);                     \\\n                                      ^\ntensorflow/stream_executor/cuda/cuda_dnn.cc:185:3: note: in expansion of macro 'PERFTOOLS_GPUTOOLS_CUDNN_WRAP'\n   __macro(cudnnSetConvolutionNdDescriptor)                \\\n   ^\ntensorflow/stream_executor/cuda/cuda_dnn.cc:192:1: note: in expansion of macro 'CUDNN_DNN_ROUTINE_EACH'\n CUDNN_DNN_ROUTINE_EACH(PERFTOOLS_GPUTOOLS_CUDNN_WRAP)\n ^\ntensorflow/stream_executor/cuda/cuda_dnn.cc: In member function 'virtual bool perftools::gputools::cuda::CudnnSupport::DoNormalize(perftools::gputools::Stream*, const perftools::gputools::dnn::NormalizeDescriptor&, const perftools::gputools::DeviceMemory<float>&, perftools::gputools::DeviceMemory<float>*)':\ntensorflow/stream_executor/cuda/cuda_dnn.cc:1423:1: warning: control reaches end of non-void function [-Wreturn-type]\n }\n ^\ntensorflow/stream_executor/cuda/cuda_dnn.cc: In member function 'virtual bool perftools::gputools::cuda::CudnnSupport::DoElementwiseOperate(perftools::gputools::Stream*, perftools::gputools::dnn::ElementwiseOperation, tensorflow::gtl::ArraySlice<perftools::gputools::dnn::BatchDescriptor>, tensorflow::gtl::ArraySlice<const perftools::gputools::DeviceMemory<float>*>, const perftools::gputools::dnn::BatchDescriptor&, perftools::gputools::DeviceMemory<float>*)':\ntensorflow/stream_executor/cuda/cuda_dnn.cc:1484:1: warning: control reaches end of non-void function [-Wreturn-type]\n }\n ^\ntensorflow/stream_executor/cuda/cuda_dnn.cc: In member function 'virtual bool perftools::gputools::cuda::CudnnSupport::DoXYPad(perftools::gputools::Stream*, const perftools::gputools::dnn::BatchDescriptor&, const perftools::gputools::DeviceMemory<float>&, tensorflow::int64, tensorflow::int64, tensorflow::int64, tensorflow::int64, perftools::gputools::DeviceMemory<float>*)':\ntensorflow/stream_executor/cuda/cuda_dnn.cc:1492:1: warning: control reaches end of non-void function [-Wreturn-type]\n }\n ^\ntensorflow/stream_executor/cuda/cuda_dnn.cc: In member function 'virtual bool perftools::gputools::cuda::CudnnSupport::DoXYSlice(perftools::gputools::Stream*, const perftools::gputools::dnn::BatchDescriptor&, const perftools::gputools::DeviceMemory<float>&, tensorflow::int64, tensorflow::int64, tensorflow::int64, tensorflow::int64, perftools::gputools::DeviceMemory<float>*)':\ntensorflow/stream_executor/cuda/cuda_dnn.cc:1501:1: warning: control reaches end of non-void function [-Wreturn-type]\n }\n ^\ntensorflow/stream_executor/cuda/cuda_dnn.cc: At global scope:\ntensorflow/stream_executor/cuda/cuda_dnn.cc:114:26: warning: 'tensorflow::thread::ThreadPool* perftools::gputools::cuda::dynload::GetCudaThreadpool()' defined but not used [-Wunused-function]\n static port::ThreadPool* GetCudaThreadpool() {\n                          ^\nERROR: /mnt/tmp/tensorflow/tensorflow/stream_executor/BUILD:5:1: C++ compilation of rule '//tensorflow/stream_executor:stream_executor' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command\n  (cd /home/ubuntu/.cache/bazel/_bazel_ubuntu/de8e797a514efeb5b22d3fa9bb2a44c2/tensorflow && \\\n  exec env - \\\n    PATH=/home/ubuntu/anaconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games \\\n  third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections '-std=c++11' -iquote . -iquote bazel-out/local_linux-py3-opt/genfiles -iquote external/bazel_tools -iquote bazel-out/local_linux-py3-opt/genfiles/external/bazel_tools -iquote external/jpeg_archive -iquote bazel-out/local_linux-py3-opt/genfiles/external/jpeg_archive -iquote external/png_archive -iquote bazel-out/local_linux-py3-opt/genfiles/external/png_archive -iquote external/re2 -iquote bazel-out/local_linux-py3-opt/genfiles/external/re2 -iquote external/eigen_archive -iquote bazel-out/local_linux-py3-opt/genfiles/external/eigen_archive -isystem google/protobuf/src -isystem bazel-out/local_linux-py3-opt/genfiles/google/protobuf/src -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/jpeg_archive/jpeg-9a -isystem bazel-out/local_linux-py3-opt/genfiles/external/jpeg_archive/jpeg-9a -isystem external/png_archive/libpng-1.2.53 -isystem bazel-out/local_linux-py3-opt/genfiles/external/png_archive/libpng-1.2.53 -isystem external/re2 -isystem bazel-out/local_linux-py3-opt/genfiles/external/re2 -isystem third_party/eigen3 -isystem bazel-out/local_linux-py3-opt/genfiles/third_party/eigen3 -isystem external/eigen_archive/eigen-eigen-50812b426b7c -isystem bazel-out/local_linux-py3-opt/genfiles/external/eigen_archive/eigen-eigen-50812b426b7c -isystem third_party/gpus/cuda -isystem bazel-out/local_linux-py3-opt/genfiles/third_party/gpus/cuda -isystem third_party/gpus/cuda/include -isystem bazel-out/local_linux-py3-opt/genfiles/third_party/gpus/cuda/include -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -fno-canonical-system-headers '-frandom-seed=bazel-out/local_linux-py3-opt/bin/tensorflow/stream_executor/_objs/stream_executor/tensorflow/stream_executor/cuda/cuda_dnn.o' -MD -MF bazel-out/local_linux-py3-opt/bin/tensorflow/stream_executor/_objs/stream_executor/tensorflow/stream_executor/cuda/cuda_dnn.d -c tensorflow/stream_executor/cuda/cuda_dnn.cc -o bazel-out/local_linux-py3-opt/bin/tensorflow/stream_executor/_objs/stream_executor/tensorflow/stream_executor/cuda/cuda_dnn.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1: crosstool_wrapper_driver_is_not_gcc failed: error executing command\n  (cd /home/ubuntu/.cache/bazel/_bazel_ubuntu/de8e797a514efeb5b22d3fa9bb2a44c2/tensorflow && \\\n  exec env - \\\n    PATH=/home/ubuntu/anaconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games \\\n  third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections '-std=c++11' -iquote . -iquote bazel-out/local_linux-py3-opt/genfiles -iquote external/bazel_tools -iquote bazel-out/local_linux-py3-opt/genfiles/external/bazel_tools -iquote external/jpeg_archive -iquote bazel-out/local_linux-py3-opt/genfiles/external/jpeg_archive -iquote external/png_archive -iquote bazel-out/local_linux-py3-opt/genfiles/external/png_archive -iquote external/re2 -iquote bazel-out/local_linux-py3-opt/genfiles/external/re2 -iquote external/eigen_archive -iquote bazel-out/local_linux-py3-opt/genfiles/external/eigen_archive -isystem google/protobuf/src -isystem bazel-out/local_linux-py3-opt/genfiles/google/protobuf/src -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/jpeg_archive/jpeg-9a -isystem bazel-out/local_linux-py3-opt/genfiles/external/jpeg_archive/jpeg-9a -isystem external/png_archive/libpng-1.2.53 -isystem bazel-out/local_linux-py3-opt/genfiles/external/png_archive/libpng-1.2.53 -isystem external/re2 -isystem bazel-out/local_linux-py3-opt/genfiles/external/re2 -isystem third_party/eigen3 -isystem bazel-out/local_linux-py3-opt/genfiles/third_party/eigen3 -isystem external/eigen_archive/eigen-eigen-50812b426b7c -isystem bazel-out/local_linux-py3-opt/genfiles/external/eigen_archive/eigen-eigen-50812b426b7c -isystem third_party/gpus/cuda -isystem bazel-out/local_linux-py3-opt/genfiles/third_party/gpus/cuda -isystem third_party/gpus/cuda/include -isystem bazel-out/local_linux-py3-opt/genfiles/third_party/gpus/cuda/include -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -fno-canonical-system-headers '-frandom-seed=bazel-out/local_linux-py3-opt/bin/tensorflow/stream_executor/_objs/stream_executor/tensorflow/stream_executor/cuda/cuda_dnn.o' -MD -MF bazel-out/local_linux-py3-opt/bin/tensorflow/stream_executor/_objs/stream_executor/tensorflow/stream_executor/cuda/cuda_dnn.d -c tensorflow/stream_executor/cuda/cuda_dnn.cc -o bazel-out/local_linux-py3-opt/bin/tensorflow/stream_executor/_objs/stream_executor/tensorflow/stream_executor/cuda/cuda_dnn.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\nTarget //tensorflow/cc:tutorials_example_trainer failed to build\nINFO: Elapsed time: 6.773s, Critical Path: 6.41s\n```\n\nThanks\n", "comments": ["Most likely we don't work properly for cudnn6.5, since it's now two generations old.\n\nhttps://github.com/tensorflow/tensorflow/commit/57b4b9b401f5600d58e040664471a2cdcbcc818f probably broke it.  Can you try to sync before that change, and/or upgrade to a newer version of cudnn?  I doubt we want to support all the various versions, the code is already getting too complex for that, given the breaking API changes cudnn makes.\n", "https://gist.github.com/AlexJoz/1670baf0b32573ca7923 , this is for r0.7, worked for me. Not sure about 0.8 \n", "TBH, xlarge.2 isnt fast at all, twice as fast my i7 4700mq laptop. \n", "you need to install Cuda 7.5 and Cudnn 7.0 for Tensorflow 0.8, I have managed to make it work, it can be done!\n\nFor Cuda:\n\nwget http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1404/x86_64/cuda-repo-ubuntu1404_7.5-18_amd64.deb\nsudo dpkg -i cuda-repo-ubuntu1404_7.5-18_amd64.deb \nrm cuda-repo-ubuntu1404_7.5-18_amd64.deb \nsudo apt-get update\nsudo apt-get install -y cuda\n\nFor Cudnn 7.0 you need to register in Nvidia and download: https://developer.nvidia.com/rdp/assets/cudnn-70-linux-x64-v40\n\nThen something like: \ntar -zxf cudnn-7.0-linux-x64-v4.0-prod.tgz && rm cudnn-7.0-linux-x64-v4.0-prod.tgz\nsudo cp -R cuda/lib64/\\* /usr/local/cuda-7.5/lib64\nsudo cp cuda/include/cudnn.h /usr/local/cuda-7.5/include/\n\nGood luck!\n", "@cristianmarti Thanks, what version of Bazel are you using?\n", "Bazel 0.1.4\n\nhttps://github.com/bazelbuild/bazel/releases/download/0.1.4/bazel-0.1.4-installer-linux-x86_64.sh\n", "@omidb: You've inspired us to open up our build scripts, check out https://github.com/RealScout/deep-learning-images\n", "Closing since the issue seems to be resolved by using a more recent cuDNN.  Please comment if that's inaccurate and I'll reopen.\n"]}, {"number": 2200, "title": "Change gpu_device.cc so that per process fraction uses total memory fraction, not available memory", "body": "This change is for making the memory allocation from the whole memory not only the remaining memory to achieve better configuration for multi processes\n", "comments": ["Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "this change was according to this issue #2176  @vrv \n@googlebot I signed it!\n", "CLAs look good, thanks!\n\n<!-- ok -->\n", "@tensorflow-jenkins test this please\n\n(Thanks!  This was the intention of the field, so hopefully people aren't expecting the current behavior).\n", "Is Android Demo App failure related to this change?! it seems that it cant add jenkins group!\n@vrv\n", "Looks like infrastructure failure, you can ignore. I will merge tomorrow!\n\nCc @jendap @caisq\n"]}, {"number": 2199, "title": "Tensorflow GRU error when trying to concatenate activations to outputs", "body": "I have been trying to grab the activations of the GRU cell layer in the following manner\n\n```\ndef __call__(self, inputs, state, scope=None):\n    \"\"\"Gated recurrent unit (GRU) with nunits cells.\"\"\"\n    with vs.variable_scope(scope or type(self).__name__):  # \"GRUCell\"\n      with vs.variable_scope(\"Gates\"):  # Reset gate and update gate.\n        # We start with bias of 1.0 to not reset and not update.\n        r, u = array_ops.split(1, 2, linear([inputs, state], 2 * self._num_units, True, 1.0))\n        r, u = sigmoid(r), sigmoid(u)\n      with vs.variable_scope(\"Candidate\"):\n        c = tanh(linear([inputs, r * state], self._num_units, True))\n      new_h = u * state + (1 - u) * c\n\n      # store the activations, everything else is the same\n      h_activations = array_ops.concat(1, [new_h,r,u,c])\n    return h_activations, h_activations\n```\n\nLater I try to grab the activations in the following way\n\n`cell = ClusterableGRUCell(num_units=hidden_neurons)\ninitial_state = tf.zeros([batch_size, cell.state_size])\noutputs_activations, outputs_activations = rnn.rnn(cell=cell, inputs=x, initial_state=initial_state, sequence_length=s)\noutputs_activations = tf.concat(0, outputs_activations)\noutputs, rs, us, cs = tf.split(1, 4, outputs_activations)\nactivations = tf.concat(1, [rs, us, cs])`\n\nHowever this fails in the `rnn()` step with the following error\n\nTraceback (most recent call last):\n  File \"myautoencoder.py\", line 29, in <module>\n    outputs_activations, outputs_activations = rnn.rnn(cell=cell, inputs=x, initial_state=initial_state, sequence_length=s)\n  File \"xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py\", line 141, in rnn\n    zero_output, state, call_cell)\n  File \"/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py\", line 265, in _rnn_step\n    _maybe_copy_some_through)\n  File \"/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 1157, in cond\n    res_f = context_f.BuildCondBranch(fn2)\n  File \"/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 1073, in BuildCondBranch\n    r = fn()\n  File \"/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py\", line 247, in _maybe_copy_some_through\n    lambda: _copy_some_through(new_output, new_state))\n  File \"/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 1157, in cond\n    res_f = context_f.BuildCondBranch(fn2)\n  File \"/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 1073, in BuildCondBranch\n    r = fn()\n  File \"/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py\", line 247, in <lambda>\n    lambda: _copy_some_through(new_output, new_state))\n  File \"/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py\", line 236, in _copy_some_through\n    return (math_ops.select(copy_cond, zero_output, new_output),\n  File \"/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 1396, in select\n    name=name)\n  File \"/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/op_def_library.py\", line 655, in apply_op\n    op_def=op_def)\n  File \"/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2156, in create_op\n    set_shapes_for_outputs(ret)\n  File \"/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1612, in set_shapes_for_outputs\n    shapes = shape_func(op)\n  File \"/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py\", line 1411, in _SelectShape\n    t_e_shape = t_shape.merge_with(e_shape)\n  File \"/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/tensor_shape.py\", line 554, in merge_with\n    (self, other))\nValueError: Shapes (32, 33) and (32, 132) are not compatible\n\nMy batch size is 32 and number of neurons is 33, 132 = 33*4 which makes sense. What I dont understand is why is there a lingering (32,33) tensor? Thank you.\n", "comments": ["Did you update the state_size property of your gru cell?\n", "The state_size is equal to number of neurons which is 33 in this case, right? My understanding is that both `input` and `state` are `batch_size x num_neurons` in dimension?\n"]}, {"number": 2198, "title": "Allow manual changing a restored TensorFlowEstimator", "body": "For TensorFlowEstimator models, currently there's no way to change learning rate once the model is saved and restored.\n\nReferencing: /tensorflow/tensorflow/contrib/learn/python/learn/estimators/base.py\n", "comments": ["Have you tried changing/accessing `estimator.learning_rate` after you restored the model? \n", "Thanks! Yes, I'm able to access the learning rate, but it doesn't seem like I can change the learning rate  tho, since the flow has already been established after calling restore.\n", "Yeah it's currently not possible. I'll submit a fix soon. cc: @ilblackdragon \n", "@mirikle See #2279. Once it's merged, you'll be able to specify e.g. `new_params={'learning_rate': 0.2}`\n", "@terrytangyuan Thank you so much!\n", "@mirikle It requires different mechanism to make it work. I'll try fix it later when I get a chance. \n", "@ilblackdragon Could you re-open this and assign to me? I'll try work on this soon. \n", "I am facing the same problem. Is this solved now?"]}, {"number": 2197, "title": "Importing the fast protobuf installed from pip package results in segmentation fault", "body": "### Operating System:\n\nUbuntu 14.04 amd64\n### Installed version of CUDA and cuDNN:\n\nno version of CUDA installed\n### If installed from binary pip package, provide:\n\nhttps://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.8.0-cp34-cp34m-linux_x86_64.whl\nVersion 0.8.0\n### Steps to reproduce\n\ntry `import tensorflow`, it works as expected.\nThen install the suggested package for fast protobuf: https://storage.googleapis.com/tensorflow/linux/cpu/protobuf-3.0.0b2.post2-cp34-none-linux_x86_64.whl\n\nNow trying `import tensorflow` results in a segmentation fault.\n", "comments": ["Adding @martinwicke. \n\nCould you post the log to gist? \n", "Here you are: https://gist.github.com/fcole90/b5cd9bf6d972d5554173624986a359b6\n", "I have the same issue on CentOS7\n", "@keveman, do you know what could be going on?\n", "Hard to say, but I am guessing the binary protobuf package needs updating.\n", "Is there any workaround available until this gets fixed? :smiley: \n", "@fcole90 Do you mind trying this wheel package for protobuf?\nhttps://storage.googleapis.com/tensorflow/linux/cpu/protobuf-3.0.0b3-cp34-cp34m-linux_x86_64.whl\n\n(Here is the one for Python 2 : https://storage.googleapis.com/tensorflow/linux/cpu/protobuf-3.0.0b3-cp27-none-linux_x86_64.whl)\n", "@fcole90 Gentle ping. Please let me know if the new protobuf wheel package solves this issue.\n", "Sorry for my late reply. \n\nI just tested the just tried both and I still received a segmentation fault.\n\n[Python2 log](https://gist.github.com/fcole90/0ed450312a1306c35330f5fc9d65a148) \n[Python3 log](https://gist.github.com/fcole90/f64d8ee051a6b453a8ad8482aea61bb1)\n", "I am unable to reproduce this with the 0.9.0rc0 version of TensorFlow, available here https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.9.0rc0-cp34-cp34m-linux_x86_64.whl. Closing this one out. Feel free to open again if you still get the segfault.\n"]}, {"number": 2196, "title": "Tensorflow GRU cell error when fetching activations with variable sequence length", "body": "I want to run a GRU cell on some time series data to cluster them according to the activations in the last layer. I made one small change to the GRU cell implementation\n\n`def **call**(self, inputs, state, scope=None):\n\"\"\"Gated recurrent unit (GRU) with nunits cells.\"\"\"\nwith vs.variable_scope(scope or type(self).**name**):  # \"GRUCell\"\n  with vs.variable_scope(\"Gates\"):  # Reset gate and update gate.\n    # We start with bias of 1.0 to not reset and not update.\n    r, u = array_ops.split(1, 2, linear([inputs, state], 2 \\* self._num_units, True, 1.0))\n    r, u = sigmoid(r), sigmoid(u)\n  with vs.variable_scope(\"Candidate\"):\n    c = tanh(linear([inputs, r \\* state], self._num_units, True))\n  new_h = u \\* state + (1 - u) \\* c\n\n  # store the activations, everything else is the same\n  self.activations = [r,u,c]\nreturn new_h, new_h`\n\nAfter this I concatenate the activations in the following manner before I return them in the script which calls this GRU cell\n\n`@property\ndef activations(self):\n    return self._activations\n\n@activations.setter\ndef activations(self, activations_array):\n    print \"PRINT THIS\"  \n    concactivations = tf.concat(concat_dim=0, values=activations_array, name='concat_activations')\n    self._activations = tf.reshape(tensor=concactivations, shape=[-1], name='flatten_activations')\n `\n\nI invoke the GRU cell in the following manner\n\n`outputs, state = rnn.rnn(cell=cell, inputs=x, initial_state=initial_state, sequence_length=s)`\n\nWhere `s` is an array of batch length with the number of timestamps in each element of the input batch.\n\nAnd finally I fetch using\n\n`fetched = sess.run(fetches=cell.activations, feed_dict=feed_dict)`\n\nWhen executing I get the following error\n\nTraceback (most recent call last): File \"xxx.py\", line 162, in fetched = sess.run(fetches=cell.activations, feed_dict=feed_dict) File \"/xxx/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 315, in run return self._run(None, fetches, feed_dict) File \"/xxx/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 511, in _run feed_dict_string) File \"/xxx/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 564, in _do_run target_list) File \"/xxx/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 588, in _do_call six.reraise(e_type, e_value, e_traceback) File \"/xxx/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 571, in _do_call return fn(*args) File \"/xxx/local/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 555, in _run_fn\n\nreturn tf_session.TF_Run(session, feed_dict, fetch_list, target_list) tensorflow.python.pywrap_tensorflow.StatusNotOK: Invalid argument: The tensor returned for RNN/cond_396/ClusterableGRUCell/flatten_activations:0 was not valid.\n\nCan someone give an insight as to how to fetch the activations from a GRU cell at the last step, with passing variable length sequences? Thanks.\n", "comments": ["rnn() assumes your cell is not stateful.  What you want to do is probably concatenate your activations into the output and then split them off after reading all the outputs off the rnn call.\n", "Thanks for your response. Actually this doesn't explain why I this code actually works if I pass `sequence_length=None` into rnn(). Can you explain that?\n", "I would need to see all your code and a longer stack trace to answer your question fully. For now, avoid creating stateful RNNCells. Treat them like functions.\n"]}, {"number": 2195, "title": "Adding validation_steps and batch_size to VaidationMonitor", "body": "This allows to do less frequent and mini batch evaluation while training.\n\nRef https://github.com/tensorflow/skflow/issues/133\n", "comments": ["thar be conflicts, please update!\n", "Ping @ilblackdragon. Is this still relevant?\n"]}, {"number": 2194, "title": "how to convert std::vector<float> to tensor in c++", "body": "", "comments": ["Hi there!\n\n> GitHub issues are for bugs / installation problems / feature requests.  \n> For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\n> To make bugs and feature requests more easy to find and organize, we close issues that are deemed\n> out of scope for GitHub Issues and point people to StackOverflow.\n\nI'm going to close this issue because it's a question rather than a bug, but if you'd like to ask it on Stack Overflow then one of the team will respond with an answer (and it will be easier for other people to find if they hit the same problem).\n"]}, {"number": 2193, "title": "tf.py_func returned object doesn't supported in tf.train.shuffle_batch", "body": "```\ndef unpackbits(arr):\n    return np.unpackbits(arr).astype(np.int64)\n\nlabels, = tf.py_func(unpackbits, [labels], [tf.int64])\n```\n\nI use py_func for reading input data. Returned object from tf.py_func(...) has get_shape()._dim equal to None. Its raise exception when passing to tf.train.shuffle_batch\n", "comments": ["Use `labels.set_shape(())`\n\n`batch` is a kind of FIFOQueue and it needs to know sizes of inputs for memory allocation reasons. It can either get it from `shapes` argument, or use shape inference to infer it automatically. Since `py_func` can call arbitrary Python code and give different-shaped argument between invocations, `py_func` doesn't set static shape and you need to either use `shapes` argument to `batch` or `set_shape` on `labels` tensor.\n\nSo you either need to \n\n`labels.set_shape(())`\n\nor do\n\n`labels_batch = tf.batch(..., shapes=[()])`\n\nHere's an end-to-end example to test this\n\n```\n# Create queue, initialize it with 0,1,2,3,4,5,6,7,8,9\nqueue_size = 10\ntf.reset_default_graph()\nqueue = tf.FIFOQueue(capacity=queue_size, dtypes=tf.int64)\nenqueue_placeholder = tf.placeholder(dtype=tf.int64)\nenqueue_op = queue.enqueue(enqueue_placeholder)\ndequeue_op = queue.dequeue()\n\nsess = tf.InteractiveSession()\nfor f in range(queue_size):\n  sess.run([enqueue_op], feed_dict={enqueue_placeholder: f})\nsess.run(queue.close())\n\ndef unpackbits(arr):\n    return arr.astype(np.int64)\n\nlabels = dequeue_op\nlabels2, = tf.py_func(unpackbits, [labels], [tf.int64])\n\nlabels2.set_shape(())\nlabels2_batch = tf.batch([labels2], 2, capacity=10)\n\ntf.start_queue_runners()\n\nfor i in range(5):\n  print labels2_batch.eval()\n```\n", "Thank you.\n"]}, {"number": 2192, "title": "Row distances Tensorflow for models like K-Means, SOM and RBFN", "body": "I am wondering if Tensorflow has some op for fast calculation of distances. For example like Matlab's [pdist](http://nl.mathworks.com/help/stats/pdist.html) or [pdist2](http://nl.mathworks.com/help/stats/pdist2.html)\n\nOr do you know of any way to optimize this piece of code?\n\n``` python\nwith tf.name_scope(\"Hidden_layer\") as scope:\n  centroids = tf.Variable(tf.random_uniform([num_centr,D],dtype=tf.float32),name='centroids')\n  var = tf.Variable(tf.truncated_normal([num_centr],mean=225,stddev=1,dtype=tf.float32))\n  exp_list = []\n\n  for i in xrange(num_centr):\n        exp_list.append(tf.exp((-1*tf.reduce_sum(tf.square(tf.sub(x,centroids[i,:])),1))/(2*var[i])))\n        phi = tf.transpose(tf.pack(exp_list))\n```\n\nFor now my code works and the results beautifully surpass my expectations. My prof deemed this impossible. With Tensorflow, I was able to prototype within two hours. \nFor future, I am curious if TensorFlow can improve this for-loop for calculating distances with a function like matlab's pdist()\n\nThanks for your help!\n\nRob\n", "comments": ["This code looks reasonable for the prototype. In general, a few ways to make it faster when you get serious about performance: \n1. Use Tensor form and avoid the loop as much as possible. Give each node more things to compute tend to improve performance. \n2. Look at the timeline / profile of the nodes, and see which one is more expensive that it should. And optimize the implementation of that one. \n3. Write a custom op or kernel and manually fuse together the operations. There are research efforts on how to automatically facilitate that. But before that becomes main stream, manual fusing is the way to go. \n", "You could also compare your speed against @dave-andersen 's K-means implementation here https://gist.github.com/dave-andersen/265e68a5e879b5540ebc\n", "Thank you @zheng-xq @yaroslavvb \nFor now, I'm happy with the implementation. I look forward to a distance implementation in Tensorflow.\n\nThanks again for responding\n"]}, {"number": 2191, "title": "Typos in the example. Their shape [4, 4, 1] is fixed to [1, 4, 4, 1]", "body": "[4, 4, 1] is fixed to [1, 4, 4, 1]\n\n```\nx = [[[1],   [2],  [3],  [4]],\n     [[5],   [6],  [7],  [8]],\n     [[9],  [10], [11],  [12]],\n     [[13], [14], [15],  [16]]]\n```\n\nx's shape is [4, 4, 1], and this throws the \"tf.space_to_depth() requires tensors with exactly 4 dimensions\" error.\n\nThis PR fixes it to  [1, 4, 4, 1]:\n\n```\nx = [[[[1],   [2],  [3],  [4]],\n     [[5],   [6],  [7],  [8]],\n     [[9],  [10], [11],  [12]],\n     [[13], [14], [15],  [16]]]]\n```\n", "comments": ["Can one of the admins verify this patch?\n"]}, {"number": 2190, "title": "failed to enqueue CUDNN_STATUS_MAPPING_ERROR", "body": "GitHub issues are for bugs / installation problems / feature requests.  \nFor general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed\nout of scope for GitHub Issues and point people to StackOverflow.\n\nFor bugs or installation issues, please provide the following information.\nThe more information you provide, the more easily we will be able to offer\nhelp and advice.\n### Environment info\n\nOperating System: Ubuntu 15\n\nInstalled version of CUDA and cuDNN: \n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\n\nThe following were installed\n\ncuda-repo-ubuntu1504_7.5-18_amd64.deb\ncudnn-7.0-linux-x64-v4.0-prod.tgz\n\n```\njeffw@chill:~/src/tensorflow/tensorflow/examples/skflow$ ls -l /usr/local/cuda/lib64/libcud*\n-rw-r--r-- 1 root root 322936 Aug 15  2015 /usr/local/cuda/lib64/libcudadevrt.a\nlrwxrwxrwx 1 root root     16 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.7.5\nlrwxrwxrwx 1 root root     19 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18\n-rwxr-xr-x 1 root root 383336 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5.18\n-rw-r--r-- 1 root root 720192 Aug 15  2015 /usr/local/cuda/lib64/libcudart_static.a\nlrwxrwxrwx 1 root root     34 Apr 30 16:31 /usr/local/cuda/lib64/libcudnn.so -> /usr/local/cudnn/lib64/libcudnn.so\nlrwxrwxrwx 1 root root     36 Apr 30 16:32 /usr/local/cuda/lib64/libcudnn.so.4 -> /usr/local/cudnn/lib64/libcudnn.so.4\nlrwxrwxrwx 1 root root     40 Apr 30 16:32 /usr/local/cuda/lib64/libcudnn.so.4.0.7 -> /usr/local/cudnn/lib64/libcudnn.so.4.0.7\nlrwxrwxrwx 1 root root     40 Apr 30 16:31 /usr/local/cuda/lib64/libcudnn_static.a -> /usr/local/cudnn/lib64/libcudnn_static.a\n```\n\nIf installed from binary pip package, provide:\n1. Which pip package you installed.\n2. The output from python -c \"import tensorflow; print(tensorflow.**version**)\".\n\nthe above command fails, with `AttributeError: 'module' object has no attribute 'version'`however, the version is 0.8.0\n- pip freeze:\n  tensorflow==0.8.0\n\nIf installed from sources, provide the commit hash:\n### Steps to reproduce\n1. start with  the example `tensorflow/tensorflow/examples/skflow/text_classification_cnn.py`\n2. use GTX 980 \n3. modify example steps fairly large number (e.g. 2400)\n4. modify **EMBEDDING_SIZE** to 16\n5. modify **N_FILTERS** to 16\n6. modify **WINDOW_SIZE** to 32.\n7. run until crash \n### What have you tried?\n1. various step numbers.  The default (100) does not crash, various other step crash eventually with larger number crashing sooner.  Perhaps this is a memory leak or other general failure to maintain datastructures. \n2. various values for the above variables some combinations work some don't.\n### Logs or other output that would be helpful\n\n(If logs are large, please upload as attachment).\n\nCan be found in [this gist](https://gist.github.com/waTeim/f243b94ff52f0bc1d9584991cd3cad8d)\n", "comments": ["can you copy the first lines when tensorflow tries to load libcudnn?\n\nI think maybe it's because your are using cuDNN v5.\n", "Hmm well I just obtained cudnn on Saturday and specifically avoided v5, however cuda itself might be older; they're dated Aug 2015 (see below).  Also, previously i had cudnn v3 installed for caffe and deep dreams.  Maybe I need to reinstall (recompile) all the support packages obtained via pip?  \n\nNevertheless, here's the output (note I've modified/renamed the example) \n\n```\njeffw@chill:~/src/tensorflow/tensorflow/examples/skflow$ CUDA_VISIBLE_DEVICES=0 python text_classification_mkp2b.py\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally\nusing saved form\nTotal words: 26744\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: \nname: GeForce GTX 980\nmajor: 5 minor: 2 memoryClockRate (GHz) 1.2785\npciBusID 0000:03:00.0\nTotal memory: 4.00GiB\nFree memory: 3.91GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:755] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 980, pci bus id: 0000:03:00.0)\n\n\nlrwxrwxrwx  1 root  root       8 Nov 15 20:27 cuda -> cuda-7.5\ndrwxr-xr-x 13 root  root    4096 Nov 15 20:26 cuda-7.5\nlrwxrwxrwx  1 root  root      24 Apr 30 16:22 cudnn -> cudnn-7.0-linux-x64-v4.0\ndrwxr-xr-x  4 root  root    4096 Nov 15 21:00 cudnn-7.0-linux-x64-v3.0\ndrwxr-xr-x  4 root  root    4096 Apr 30 16:22 cudnn-7.0-linux-x64-v4.0\n```\n\nI've already cut-pasted the cudnn libs (above) here are the others\n\n```\n ls -l /usr/local/cuda/lib64/libcublas*\n-rw-r--r-- 1 root root 28585480 Aug 15  2015 /usr/local/cuda/lib64/libcublas_device.a\nlrwxrwxrwx 1 root root       16 Aug 15  2015 /usr/local/cuda/lib64/libcublas.so -> libcublas.so.7.5\nlrwxrwxrwx 1 root root       19 Aug 15  2015 /usr/local/cuda/lib64/libcublas.so.7.5 -> libcublas.so.7.5.18\n-rwxr-xr-x 1 root root 23938736 Aug 15  2015 /usr/local/cuda/lib64/libcublas.so.7.5.18\n-rw-r--r-- 1 root root 28220076 Aug 15  2015 /usr/local/cuda/lib64/libcublas_static.a\nls -l /usr/local/cuda/lib64/libcufft*\nlrwxrwxrwx 1 root root        15 Aug 15  2015 /usr/local/cuda/lib64/libcufft.so -> libcufft.so.7.5\nlrwxrwxrwx 1 root root        18 Aug 15  2015 /usr/local/cuda/lib64/libcufft.so.7.5 -> libcufft.so.7.5.18\n-rwxr-xr-x 1 root root 111231960 Aug 15  2015 /usr/local/cuda/lib64/libcufft.so.7.5.18\n-rw-r--r-- 1 root root 115104400 Aug 15  2015 /usr/local/cuda/lib64/libcufft_static.a\nlrwxrwxrwx 1 root root        16 Aug 15  2015 /usr/local/cuda/lib64/libcufftw.so -> libcufftw.so.7.5\nlrwxrwxrwx 1 root root        19 Aug 15  2015 /usr/local/cuda/lib64/libcufftw.so.7.5 -> libcufftw.so.7.5.18\n-rwxr-xr-x 1 root root    447664 Aug 15  2015 /usr/local/cuda/lib64/libcufftw.so.7.5.18\n-rw-r--r-- 1 root root     42206 Aug 15  2015 /usr/local/cuda/lib64/libcufftw_static.a\nls -l /usr/local/cuda/lib64/libcuda*\n-rw-r--r-- 1 root root 322936 Aug 15  2015 /usr/local/cuda/lib64/libcudadevrt.a\nlrwxrwxrwx 1 root root     16 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.7.5\nlrwxrwxrwx 1 root root     19 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18\n-rwxr-xr-x 1 root root 383336 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5.18\n-rw-r--r-- 1 root root 720192 Aug 15  2015 /usr/local/cuda/lib64/libcudart_static.a\nls -l /usr/local/cuda/lib64/libcurand*\nlrwxrwxrwx 1 root root       16 Aug 15  2015 /usr/local/cuda/lib64/libcurand.so -> libcurand.so.7.5\nlrwxrwxrwx 1 root root       19 Aug 15  2015 /usr/local/cuda/lib64/libcurand.so.7.5 -> libcurand.so.7.5.18\n-rwxr-xr-x 1 root root 51765952 Aug 15  2015 /usr/local/cuda/lib64/libcurand.so.7.5.18\n-rw-r--r-- 1 root root 51992564 Aug 15  2015 /usr/local/cuda/lib64/libcurand_static.a\n```\n", "As a step to debug this problem, could you try to run without modify the classifier? \n\nIn Cudnn documentation about this particular error: \n\nCUDNN_STATUS_MAPPING_ERROR\nAn access to GPU memory space failed, which is usually caused by a failure to bind a texture.\nTo correct: prior to the function call, unbind any previously bound textures.\nOtherwise, this may indicate an internal error/bug in the library.\n\nTensorFlow doesn't bind any texture with its Cudnn calls. So the last part indicated that it could be a problem in the library itself. \n", "After some experimentation, I found that to be able to reproduce the error, the dataset does not need to be changed, but changes do need to be made to one or more of the parameters **EMBEDDING_SIZE**,  **N_FILTERS**, and **WINDOW_SIZE**.  For example, setting these parameters to the following causes the error.\n\n```\nEMBEDDING_SIZE = 16\nN_FILTERS = 16\nWINDOW_SIZE = 29\n```\n\nvarious values of **WINDOW_SIZE** were tried and some cause the error and some don't.  Larger values tend to cause the error (29,30,31,32) while smaller values don't (20,21,22). \n\nI'll update the original report to indicate this.\n", "Hi,\nI am having similar problem on the project I am working. I am implementing [Convolutional Neural Networks for Sentence Classification](http://emnlp2014.org/papers/pdf/EMNLP2014181.pdf). I am getting this error irrespective of the parameter I choose. I have tried window size of 3, 4, 5 and various number of filters (32, 64, 128). It crashes at step **8100**  in all the parameter settings.\n\nBelow is small snippet from the log. I have attached complete log file [here](https://gist.github.com/agupta83/ecb3b4a7ba5e948216aa94cba755d26f). I am using TF 0.80 (2296dd8060ce77c71fc820c77442835f050399dd) and cuDNN v4. \n\n```\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so.7.5 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so.7.5 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so.7.5 locally\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: \nname: GeForce GTX TITAN X\nmajor: 5 minor: 2 memoryClockRate (GHz) 1.076\npciBusID 0000:0a:00.0\nTotal memory: 12.00GiB\nFree memory: 11.76GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 1 with properties: \nname: GeForce GTX TITAN X\nmajor: 5 minor: 2 memoryClockRate (GHz) 1.076\npciBusID 0000:09:00.0\nTotal memory: 12.00GiB\nFree memory: 11.87GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 2 with properties: \nname: GeForce GTX TITAN X\nmajor: 5 minor: 2 memoryClockRate (GHz) 1.076\npciBusID 0000:06:00.0\nTotal memory: 12.00GiB\nFree memory: 11.87GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 3 with properties: \nname: GeForce GTX TITAN X\nmajor: 5 minor: 2 memoryClockRate (GHz) 1.076\npciBusID 0000:05:00.0\nTotal memory: 12.00GiB\nFree memory: 11.33GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 1 2 3 \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y Y Y Y \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 1:   Y Y Y Y \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 2:   Y Y Y Y \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 3:   Y Y Y Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:756] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:0a:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:756] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GeForce GTX TITAN X, pci bus id: 0000:09:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:756] Creating TensorFlow device (/gpu:2) -> (device: 2, name: GeForce GTX TITAN X, pci bus id: 0000:06:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:756] Creating TensorFlow device (/gpu:3) -> (device: 3, name: GeForce GTX TITAN X, pci bus id: 0000:05:00.0)\nDevice mapping:\n/job:localhost/replica:0/task:0/gpu:0 -> device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:0a:00.0\n/job:localhost/replica:0/task:0/gpu:1 -> device: 1, name: GeForce GTX TITAN X, pci bus id: 0000:09:00.0\n/job:localhost/replica:0/task:0/gpu:2 -> device: 2, name: GeForce GTX TITAN X, pci bus id: 0000:06:00.0\n/job:localhost/replica:0/task:0/gpu:3 -> device: 3, name: GeForce GTX TITAN X, pci bus id: 0000:05:00.0\nI tensorflow/core/common_runtime/direct_session.cc:151] Device mapping:\n/job:localhost/replica:0/task:0/gpu:0 -> device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:0a:00.0\n/job:localhost/replica:0/task:0/gpu:1 -> device: 1, name: GeForce GTX TITAN X, pci bus id: 0000:09:00.0\n/job:localhost/replica:0/task:0/gpu:2 -> device: 2, name: GeForce GTX TITAN X, pci bus id: 0000:06:00.0\n/job:localhost/replica:0/task:0/gpu:3 -> device: 3, name: GeForce GTX TITAN X, pci bus id: 0000:05:00.0\n\n...\n...\n...\nI tensorflow/core/common_runtime/simple_placer.cc:667] save/control_dependency: /job:localhost/replica:0/task:0/cpu:0\n2016-05-09 18:27:25.888013: step 10, loss = 3.76 (281.4 examples/sec; 0.227 sec/batch)\n2016-05-09 18:27:28.206509: step 20, loss = 3.71 (282.3 examples/sec; 0.227 sec/batch)\n...\n...\n2016-05-09 18:34:27.086410: step 1700, loss = 1.23 (295.2 examples/sec; 0.217 sec/batch)\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 176886 get requests, put_count=175848 evicted_count=1000 eviction_rate=0.00568673 and unsatisfied allocation rate=0.0120869\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:256] Raising pool_size_limit_ from 100 to 110\n2016-05-09 18:34:31.962832: step 1710, loss = 1.16 (291.8 examples/sec; 0.219 sec/batch)\n2016-05-09 18:34:34.287784: step 1720, loss = 0.99 (270.6 examples/sec; 0.237 sec/batch)\n...\n...\n2016-05-09 19:01:22.861471: step 8100, loss = 1.08 (262.5 examples/sec; 0.244 sec/batch)\nF tensorflow/stream_executor/cuda/cuda_dnn.cc:917] failed to enqueue convolution on stream: CUDNN_STATUS_MAPPING_ERROR\nAborted (core dumped)\n```\n", "I'm updating this now as a placeholder with additional verification to follow; though this bug appears to be completely reproducible, it also appears to be tied to some subtle component of the install for the error appears to have ceased after upgrading to Ubuntu 16 from Ubuntu 15.  It appears that neither cuda nor cudnn libraries were changed, so possibly this is due to a change of libraries (sklearn?) reinstalled by a global upgrade of pip, or other support libraries or possibly this is a change to the kernel.\n", "@zheng-xq: Any thoughts as to how to better diagnose?\n\n@agupta83: What platform are you on?  I'd like to know if it's Ubuntu version specific, since @waTeim says it goes away at a later version. \n", "I have Ubuntu 14.04 LTS (3.16.0-71-generic kernel) on my system.\n", "Since the bug is fixed by upgrading Ubuntu and thus is likely to be a bug outside TensorFlow, I'm going to close this issue.  If upgrading is not an option and more information is available we can reopen, and of course we're happy to accept PRs fixing TensorFlow for older systems.\n", "It seems that this problem still exists for Tensorflow 0.9 and 0.10. @agupta83  Have you solved the problem without upgrading Ubuntu system?\n", "@chenxi116 Nope. I couldn't figure out the issue.\n", "@chenxi116 I'm facing this exact same issue and stuck at iteration 3000 or so.\n- Ubuntu 14.04.4 LTS\n- TensorFlow 0.8.0\n- Keras 1.0.4\n- Python 2.7\n- CUDA 7.5\n- CuDNN 5\n\nI'm attempting to upgrade to Ubuntu 16 and the latest TensorFlow version.\n"]}, {"number": 2189, "title": "No scalar data was found", "body": "GitHub issues are for bugs / installation problems / feature requests.  \nFor general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed\nout of scope for GitHub Issues and point people to StackOverflow.\n\nFor bugs or installation issues, please provide the following information.\nThe more information you provide, the more easily we will be able to offer\nhelp and advice.\n### Environment info\n\nOperating System: CentOS 7\n\nInstalled version of CUDA and cuDNN:  Using CPU version\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\n\nIf installed from binary pip package, provide:\n1. Which pip package you installed. \n   https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.8.0-cp27-none-linux_x86_64.whl\n2. The output from python -c \"import tensorflow; print(tensorflow.**version**)\".\n   >>> print(tensorflow.**version**)\n   0.8.0\n\nIf installed from sources, provide the commit hash:\n### Steps to reproduce\n\n1.In you TensorFlow program:\n # Set logs writer into folder /tmp/tensorflow_logs\nsummary_writer = tf.train.SummaryWriter('/tmp/tensorflow_logs', graph_def=sess.graph_def)\n2.\npython ./lib/python2.7/site-packages/tensorflow/tensorboard/tensorboard.py --logdir=/tmp/tensorflow_logs \n3.Open http://[address]:6006/ into your web browser\n### What have you tried?\n1. Tried to enable debug and see if anything is wrong.\n   python ./lib/python2.7/site-packages/tensorflow/tensorboard/tensorboard.py --logdir=/tmp/tensorflow_logs --debug\n2. Looked if there files in exist in /tmp/tensorflow_logs \n3. Checked their sizes\n4. Everything looked correct\n### Logs or other output that would be helpful\n\n(If logs are large, please upload as attachment).\nWhen I open web page:\nWeb application itself works, but this error is shown:\n\"No scalar data was found.\"\n", "comments": ["Can you please tell us a bit more about the TensorFlow program that you were running. In particular, what `tf.scalar_summary()` ops did you expect to see in the TensorBoard output, and how did you write them to `summary_writer`? Also, when you say \"Checked their sizes / Everything looked correct\", does this mean that there were events in the file, or just a graph?\n", "1. Here is the code I was using: https://github.com/aymericdamien/TensorFlow-Examples/blob/master/notebooks/5%20-%20User%20Interface/graph_visualization.ipynb\n2. In the folder \"/tmp/tensorflow_logs\" there was a file \"events.out.tfevents.1462126139.localhost.localdomain\" and it was around 8kb\n", "Looking at the code of that notebook, I think the \"No scalar data was found\" error message is expected behavior: the notebook doesn't explicitly log anything to the `summary_writer`, apart from `sess.graph_def` (which probably accounts for the 8kb of data in the event log file). If you click on the \"Graph\" link at the top of the TensorBoard page, you should be able to see the graph visualization, as described in the notebook.\n", "I'm closing this due to inactivity. Let us know if you still have problems!\n"]}, {"number": 2188, "title": "Missing support for Ubuntu 16.04 with Python 3.5", "body": "### Environment info\n\nOperating System:\nUbuntu 16.04 Xenial Xerus\n\nInstalled version of CUDA and cuDNN: \nnone (using CPU version)\n\nIf installed from binary pip package, provide:\n\nhttps://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.8.0-cp34-cp34m-linux_x86_64.whl\n### What have you tried?\n\nI tried to install\n\n```\nhttps://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.8.0-cp34-cp34m-linux_x86_64.whl\n```\n\nbut it failed with the following message:\n\n```\ntensorflow-0.8.0-cp34-cp34m-linux_x86_64.whl is not a supported wheel on this platform.\n```\n\nThis is probably because the python3 version in Xenial is Python 3.5.x\n\nI managed to install tensorflow using instead:\n\n```\nlinux/cpu/tensorflow-0.7.0-py3-none-linux_x86_64.whl\n```\n\nbut there's not anything like that neither for the protobuf nor for the tensorflow-0.8.0 packages.\n", "comments": ["+1\n", "i have download it and rename to tensorflow-0.8.0-cp35-cp35m-linux_x86_64.whl to install it\n", "@caisq: Can you take a look as someone more familiar with pip-land? \n", "+1\n", "We are in the process of getting python3.5 build to work for linux. Stay tuned. Renaming is the temporary solution.\n", "+1\n", "With PR #2585, we now have Linux Python 3.5 whl files built and tested nightly. The links to the whl files and build history can be found in the main README.md: \nhttps://github.com/tensorflow/tensorflow/\n\nLinux Python 3.5 whl files will also be included in future releases.\n"]}, {"number": 2187, "title": "Fix convert_to_tensor error in tf.one_hot", "body": "Addresses more issues found in #1799. When a user passes in a TensorFlow constant that is not of type `tf.int64` for `indices` or type `tf.int32` for `depth`, `one_hot()` throws a \"Tensor conversion requested...\" error due to using `convert_to_tensor` for those parameters. This PR addresses this by using `tf.cast()` instead for `indices` and `depth`.\n\nAdditionally, this PR adds more test coverage (has tests using `tf.constant`) and renames some tests introduced in #1869 to be more descriptive.\n", "comments": ["Can one of the admins verify this patch?\n", "This is not a good change, since it makes type errors silently work with strange behavior.  What are you trying to do?\n", "For example, if you pass some floats in as indices, it is a type error.  Floor is not what the user expects.\n", "Thanks, good to know.\n\nThe issue, as seen [here](https://github.com/tensorflow/tensorflow/issues/1799#issuecomment-215913080), is that when a tensor with a defined data-type is passed to `convert_to_tensor` with a different datatype, we get a ValueError. For example:\n\n``` python\n>>> import tensorflow as tf\n>>> a = tf.constant(3, dtype=tf.int32)\n>>> b = tf.convert_to_tensor(a, dtype=tf.int64)\n\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 565, in convert_to_tensor\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 510, in _TensorTensorConversionFunction\n    % (dtype.name, t.dtype.name, str(t)))\nValueError: Tensor conversion requested dtype int64 for Tensor with dtype int32: 'Tensor(\"Const_2:0\", shape=(), dtype=int32)'\n```\n\nYou get similar results with Tensors of different data types. Numpy arrays work fine, however. I'm not sure whether this is intended behavior for `convert_to_tensor`. \n\nI understand the primary use case for `one_hot` will be when reading in data from a file, so having to convert TensorFlow objects isn't crucial, but the thought was to support as many data types as possible.\n", "I believe this should be fixed by making `one_hot` natively work for `int32` tensors and then removing the `int64` default.\n", "That sounds good. I guess I'll try to dive into this one.\n", "Thanks!  Let me know if you have questions.\n", "@girving assigning to you for now.  i can pick up after may 10th if it's still open.\n", "Sorry it took a while to get something posted! I've pushed the WIP, and the code is working as intended. Not sure if this is the most elegant solution, however. I have a couple of questions:\n- Is there a better pattern to iterate over combinations of data types when using `REGISTER_KERNEL_BUILDER`? I'm wondering if we should just extend `indices` compatibility to be of any `int` type. Ideally, I'd like to use both `TF_CALL_NUMBER_TYPES` and `TF_CALL_INTEGRAL_TYPES` (or modified versions of those macros), but they aren't designed for builders with multiple generic types. For example, in [lines 116-133](https://github.com/tensorflow/tensorflow/pull/2187/files#diff-9069716f50988af959734fd72f49c31fR116), I wrote nearly identical code in order to register an implementation for both `int32` and `int64`. I could copy and paste a bunch for `int8`, `int16`, etc., but I figured I would ask first.\n- Am I going overboard with the tests? I modified them to iterate over NumPy dtypes and TensorFlow dtypes, as we weren't testing `tf.constant` objects before ([which gave us surprise errors](https://github.com/tensorflow/tensorflow/issues/1799#issuecomment-215913080)). However, this jumps the test time from ~2.5 seconds to ~5 seconds for CPU-only, and from ~4.5 seconds to ~9 seconds with GPU.\n\nThanks!\n", "@ebrevdo: Assigning to you since you seem to be looking over it already.  Let me know if you want me to take over, but one reviewer seems sufficient. \n", "I've pushed the next WIP commit. Here's the summary:\n- Refactored the various kernel registration macros\n- Changed generic typename `I` to `TI`\n- Added support for int8, int16, int32, and uint8 for the `indices` parameter\n- Separated out test for various indices types into `testIndicesTypes`\n- Added base test for string support - _not passing_\n- Adjusted Python wrapper to maintain backwards compatibility. If `dtype` is not passed in, `one_hot`'s output will now take on the dtype of `on_value` and/or `off_value` (instead of converting to `float32`).\n  - If none of `on_value`, `off_value`, or `dtype` is provided, the output will be of type `float32`\n\n---\n\nI'm having trouble getting strings to work properly. In [the current, simple string test](https://github.com/tensorflow/tensorflow/pull/2187/files#diff-305762e23976349d47a199ab48ded4e4R309), I get the following error:\n\n```\nAssertionError: Shape mismatch: expected (3, 3), got ().\n```\n\n@ebrevdo Thoughts, when you get the chance?\n", "The test failure with the string test: truth should not be a tf.constant but a np.array([[b\"1.0\", b\"0.0\", ...]], ...)\n", "Sweet! Everything appears to be in order, now. Just had to add an extra check inside of `_testOneHot` to make sure it didn't try to run `assertAllClose` on a string tensor. Let me know if there's anything else that looks fishy.\n", "Alright, I've pushed the next patch. Here's what's included:\n- Altered handling of `on_value`, `off_value`, and `dtype` in array_ops.py to match requested implementation\n- Removed int8, int16, uint8 registration\n- Modified default value tests to match how dtype handles mismatches\n- Add tests to assert TypeErrors when `on_value` and `off_value` are of different types, or when either of their types differs from `dtype`\n- Added a documentation to describe new behavior and provide example of default value use\n", "Jenkins, test this please.\n", "Thank you @ebrevdo for your continued notes. How does this most recent patch look? Here are the highlights:\n- Changed `assertAllClose` to `assertAllEqual`, and removed the check for string data-type. The `assertAllClose` check was from the initial implementation of the Op, but it's a good catch to change it.\n- All white space changes should be gone\n- Removed the `cast` on depth in the Python wrapper. Letting depth use the same generic type as indices, TI, doesn't work with the backwards compatibility check. But you're right in that the cast is unnecessary in general\n- Added a default value of `DT_INT64` for the generic type TI- this was needed for the test to pass the backwards compatibility test\n\nLet me know if you have anything else!\n", "Uh-oh.  We can't break the backwards compatibility.  What this means is folks who have created a graph with a previous version of this op will not be able to run it on a more recently compiled version of TF.  That's a big no-no.  Sorry for suggesting it.  Can we revert the change on dtype of depth?\n", "I think I miscommunicated what I did (unless I've done goofed)- the latest patch was made to _maintain_ backwards compatibility. We couldn't implement the suggestion to pass `TI` as the type of `depth` without breaking backwards compatibility, so I've already reverted it. The rest of that bullet indicates that I simply removed the `depth = tf.cast(...)` line in the Python wrapper, as it A. was unnecessary and B. allowed for bad `depth` inputs to work when they shouldn't (as both you and @girving pointed out). I also registered the required default dtype for `TI` so that it matches the `int64` type used by `indices` previously.\n\nLet me know if I've done goofed, though :)\n", "Jenkins, test this please.\n", "Jenkins, test this please.\n", "Thank you for bearing with me!\n", "Absolutely! Thank you for your guidance with this PR- I've definitely learned a ton from this process.\n", "@ebrevdo next time squash before merging \n"]}, {"number": 2186, "title": "TensorBoard build failure on Jenkins", "body": "TensorBoard build has failed for quite a while in Jenkins now. The failure seems to have to do with gulp config, for example:\n\n> [16:46:28] Using gulpfile /workspace/tensorflow/tensorboard/gulpfile.js\n> [16:46:28] Task 'compile.all' is not in your gulpfile\n> [16:46:28] Please check the documentation for proper gulpfile formatting\n\nFor full build log, see example: http://ci.tensorflow.org/job/tensorflow-master-tensorboard/161/console\n### Environment info\n\nOperating System: Linux + Docker\n\nInstalled version of CUDA and cuDNN: Not applicable.\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\n\nIf installed from binary pip package, provide: N/A\n\nTo reproduce locally:\n`tensorflow/tools/ci_build/ci_build.sh TENSORBOARD tensorflow/tools/ci_build/builds/tensorboard.sh\n`\n", "comments": ["@danmane Can you take a look?\n", "Ah, I know what the problem is. Will fix.\n", "@danmane Gentle ping. Any ETA to fix?\n", "@danmane says he's still working on the fix.\n", "I believe this was fixed. \nIn any case, our testing story for tensorboard now involves internal screendiffing tests and not the jenkins dockerfile.\n"]}, {"number": 2185, "title": "How to compute confusion matrix from CNN example?", "body": "In the tutorial 'Convolutional Neural Networks', tensorflow just computed the accuracy, but I wanted to compute the confusion matrix. I have trained the model, saved the variable and don't want to do it again. I am able to load the variables. Then three approaches crossed my mind: give new input to cifar10.inference; replace with new operations; directly output the prediction result. But I failed all of them, because: the inference does not take placeholder, no such operation could be implemented; multi-threaded code stopped me.\n\nI posted a more detailed way of my trial in [stackoverflow](http://stackoverflow.com/questions/36960457/tensorflow-evaluate-with-confusion-matrix). Please help. And even will be more grateful if solutions are given more than one. \n\nThanks in advance.\n", "comments": ["That question was a bit broad -- I think you were asking how to use skflow to compute confusion matrix on CIFAR input pipeline which possibly nobody has done before, hence no answers. I think if you break this task into smaller tasks, maybe only using TensorFlow, you'd have better luck. Closing this for now since it's not a bug or feature request.\n", "Posted [an answer on SO](http://stackoverflow.com/questions/36960457/tensorflow-evaluate-with-fusion-matrix/36987469#36987469) - leaving here link in case people stumble this issue.\n"]}, {"number": 2184, "title": "Added clear description: -1 can also be used to infer the shape", "body": "The current description, \"also be used with higher dimensional shapes\" is not very clear.\n\n-1 very commonly used to infer the shape. So, I added clear descriptions and examples how to use -1 in reshape.\n", "comments": ["Can one of the admins verify this patch?\n", "Thanks for the wonderful comments. It is merged with PR #2183 and colons are added.\n", "@tensorflow-jenkins test this please.\n", "Merged. Thanks.\n"]}, {"number": 2183, "title": "In the doc example, commas in tensors are missing.", "body": "Missing commas in the doc example are added to show tensors more precisely. Also, they are now consistent with other reshape examples. \n", "comments": ["Can one of the admins verify this patch?\n", "Can you combine this with 2184 please?\n", "Merged with PR #2184. Thanks!\n"]}, {"number": 2182, "title": "added cuda/extras and cuda/lib to gitignore", "body": "on OS X these folders need to be gitignored\n", "comments": ["Can one of the admins verify this patch?\n"]}, {"number": 2181, "title": "Fixed a typo: a -> tensor", "body": "Fixed a typo in the API doc.\n", "comments": ["Can one of the admins verify this patch?\n"]}, {"number": 2180, "title": "SparseTensor   transpose", "body": "Is  there a way to transpose a SparseTensor without converting it to dense?\n", "comments": ["There's no built-in op for doing this, but you could do something like the following:\n\n``` python\ninput_st = ...  # object of type `tf.SparseTensor`, with 2-D indices\n\nindices = input_st.indices\n# Reverse the columns of `indices`\ntransposed_indices = tf.concat(1, [indices[:, 1:2], indices[:, 0:1]])\n\ndense_shape = input_st.dense_shape\n# Reverse the elements of `dense_shape`\ntransposed_dense_shape = tf.pack([dense_shape[1], dense_shape[0]])\n\ntransposed_st = tf.SparseTensor(transposed_indices, input_st.values, transposed_dense_shape)\n```\n", "(Assigning this to @concretevitamin, since he is looking at the sparse ops right now.)\n", "Don't forget to call Reorder Sparse on the result of Derek's code.\n", "@concretevitamin: Are you planning to work on this?  If not, we should mark it as contributions welcome.\n\n@mrry: `tf.reverse` is a better way to reverse a Tensor that extracting each component and manually reassembling them in the opposite order. \n", "I see Eugene has marked it as contributions welcome.  I am happy to review any PRs!\n", "Hi, I would like to work on this. Please let me know if it would be fine to proceed. Thanks.\n", "@maniteja123 please feel free to take it.  Besides all of the above suggestions, I'd imagine adding an additional bool flag (`reorder`?) to the Python function can be useful, with default to True.\n", "Thanks for the response. Could you please clarify some questions ? Would adding a wrapper suffice ? I was thinking `sparse_ops.py` where similar functions are there ? Or should it be added to the core code ?\n\nAlso the implementation AFAICU would be something like \n\n```\ntransposed_indices  = tf.reverse(sp_input.indices), [False, True])\ntransposed_values = sp_input.values\ntransposed_shape = tf.reverse(sp_input.shape), [True])\nsp_output = tf.SparseTensor(transosed_indices, transposed_values, transposed_shape)\nsp_output = tf.sparse_reorder(sp_output)\n```\n\nPlease let me know if this is  the right approach here ? Thanks.\n", "AFAICT, adding a wrapper function to sparse_ops.py sounds good.\n\nOn Wednesday, June 15, 2016, Maniteja Nandana notifications@github.com\nwrote:\n\n> Thanks for the response. Could you please clarify some questions ? Would\n> adding a wrapper suffice ? I was thinking sparse_ops.py where similar\n> functions are there ? Or should it be added to the core code ?\n> \n> Also the implementation AFAICU would be something like\n> \n> transposed_indices  = tf.reverse(sp_input.indices), [False, True])\n> transposed_values = sp_input.values\n> transposed_shape = tf.reverse(sp_input.shape), [True])\n> sp_output = tf.SparseTensor(transosed_indices, transposed_values, transposed_shape)\n> sp_output = tf.sparse_reorder(sp_output)\n> \n> Please let me know if this is the right approach here ? Thanks.\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/2180#issuecomment-226123114,\n> or mute the thread\n> https://github.com/notifications/unsubscribe/AAkLHs3DOY2wBLyLt7yCCqyVP4sa2LlXks5qL7kqgaJpZM4ITiLc\n> .\n", "Thank you. Will try working on it and send a PR as soon as possible.\n", "Hi @concretevitamin , sorry for the delay. I have tried adding a wrapper to the function in `sparse_ops.py`. What is the general procedure to register it in case it is only a python op and doesn't have a corresponding kernel op ? I couldn't find something similar done before. Could you please help me here ? Thanks and sorry for many questions. It is my first attempt to contribute here.\n", "In case of a Python wrapper function, it really is not an Op, but just an ordinary Python function that introduces Ops to the graph by composing other Op wrappers.\n\nIn other words, there's no need to register anything (gradient function, shape function, kernel) in this case.\n\nThere are many PRs that does exactly this for Issues #1968 and #1828.   Could you take a look at those?\n", "Thnaks for the response. I did follow those PRs. If I understand it correctly, I just add the wrapper function and build again. This should show the function in the `tf` namespace ? Right now, I am using the instructions [here](https://www.tensorflow.org/versions/r0.9/get_started/os_setup.html#installing-from-sources) and using `python setup.py develop`. Please do let me know if I am doing it correctly ? Thanks.\n", "The instructions should work.  To explicitly expose the documentation,\nyou'll need to add `@@sparse_transpose()` near the top of the file.  Are\nyou seeing some errors?  It'd be better if we are talking about concrete\nissues.\n\nOn Fri, Jun 24, 2016 at 7:27 AM, Maniteja Nandana notifications@github.com\nwrote:\n\n> Thnaks for the response. I did follow those PRs. If I understand it\n> correctly, I just add the wrapper function and build again. This should\n> show the function in the tf namespace ? Right now, I am using the\n> instructions here\n> https://www.tensorflow.org/versions/r0.9/get_started/os_setup.html#installing-from-sources\n> and using python setup.py develop. Please do let me know if I am doing it\n> correctly ? Thanks.\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/2180#issuecomment-228360411,\n> or mute the thread\n> https://github.com/notifications/unsubscribe/AAkLHkIXDgs5IMcHU4w4Vz3YCUZ2yfSCks5qO-lAgaJpZM4ITiLc\n> .\n", "Apologies for the trivial doubts. I did add `@@sparse_transpose` to top of the file but was getting the following error in the bazel build. I was using the current master to build it.\n\n```\nERROR: /root/FOSS/tensorflow/tensorflow/contrib/session_bundle/example/BUILD:38:1:\n Executing genrule //tensorflow/contrib/session_bundle/example:half_plus_two faile\nd: bash failed: error executing command /bin/bash -c ... (remaining 1 argument(s)\nskipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exit\ned with status 1.\nTraceback (most recent call last):\n  File \"/root/.cache/bazel/_bazel_root/5b738bf9edce520d5df62c48e6337528/tensorflow\n/bazel-out/host/bin/tensorflow/contrib/session_bundle/example/export_half_plus_two\n.runfiles/org_tensorflow/tensorflow/contrib/session_bundle/example/export_half_plu\ns_two.py\", line 115, in <module>\n    tf.app.run()\n  File \"/root/FOSS/tensorflow/_python_build/tensorflow/python/platform/app.py\", li\nne 30, in run\n    sys.exit(main(sys.argv))\n  File \"/root/.cache/bazel/_bazel_root/5b738bf9edce520d5df62c48e6337528/tensorflow\n/bazel-out/host/bin/tensorflow/contrib/session_bundle/example/export_half_plus_two\n.runfiles/org_tensorflow/tensorflow/contrib/session_bundle/example/export_half_plu\ns_two.py\", line 111, in main\n    Export()\n  File \"/root/.cache/bazel/_bazel_root/5b738bf9edce520d5df62c48e6337528/tensorflow\n/bazel-out/host/bin/tensorflow/contrib/session_bundle/example/export_half_plus_two\n.runfiles/org_tensorflow/tensorflow/contrib/session_bundle/example/export_half_plu\ns_two.py\", line 106, in Export\n    assets_callback=CopyAssets)\n  File \"/root/FOSS/tensorflow/_python_build/tensorflow/contrib/session_bundle/expo\nrter.py\", line 200, in init\n    graph_any_buf.Pack(copy)\nAttributeError: 'Any' object has no attribute 'Pack'\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\n```\n\nSorry if I am missing something trivial but I couldn't find any issue related to this. Thanks.\n", "Sorry I got that solved by updating protobuf.\n", "Hi, I have tried to use the following implementation for transpose as suggested above\n\n```\ntransposed_indices  = tf.reverse(sp_input.indices), [False, True])\ntransposed_values = sp_input.values\ntransposed_shape = tf.reverse(sp_input.shape), [True])\nsp_output = tf.SparseTensor(transosed_indices, transposed_values, transposed_shape)\nsp_output = tf.sparse_reorder(sp_output)\n```\n\nBut it seems that `tf.reverse` doesn't support `int64` and raises an error\n\n```\n File \"<stdin>\", line 1, in <module>\n  File \"tensorflow/python/ops/gen_array_ops.py\", line 1598, in reverse\n  File \"tensorflow/python/framework/op_def_library.py\", line 529, in apply_op\n  File \"tensorflow/python/framework/op_def_library.py\", line 60, in _SatisfiesType\nConstraint\nTypeError: DataType int64 for attr 'T' not in list of allowed values: uint8, int8,\n int32, bool, float16, float32, float64\n```\n\nIs there any workaround for this ? Since this is used only for `indices` and `shape` would it be okay to downcast to `int32` ? Thanks.\n", "Hi, I have opened a PR at #3031. Please do have a look and give your suggestions. Thanks.\n"]}, {"number": 2179, "title": "fix typo", "body": "", "comments": ["Can one of the admins verify this patch?\n", "@tensorflow-jenkins test this please\n", "Merged. Thanks.\n"]}, {"number": 2178, "title": "Remove loading sklearn even if it's present and only load when env flag is set", "body": "Ref #2034 to reduce load time of import tf when people are not interested in tf.learn / sklearn integration.\n", "comments": ["Can you fix the error?\n", "@martinwicke Fixed.\n", "Thanks!\n"]}, {"number": 2177, "title": "tf.argmax Should Not Permit Backprop Through It", "body": "Hey Tensorflow,\n\nLately, I have been using the argmax function but I have always placed a tf.stop_gradient before using it. However, when I remove the stop_gradient, tensorflow still works fine. \n\nMaybe I'm misunderstanding something, but argmax is not a differentiable function. How is backprop still working when you remove it? Shouldn't an error be thrown when you pass argmax without any stop_gradient?\n\nIf it is possible to differentiate argmax, then I would greatly appreciate any resource showing how this is done. Thanks TF!\n", "comments": ["Gradient is defined almost everywhere, so it could be defined in practice. It's not very useful though, so it's not registered for this op in TensorFlow.\n\n```\nx = tf.Variable([1., 1])\nz = tf.argmax(x, 0)\nsess = create_session()\nxgrad = tf.gradients(z, x)\nsess.run(tf.initialize_all_variables())\nsess.run(xgrad)\n\nLookupError: No gradient defined for operation 'ArgMax' (op type: ArgMax)\n```\n"]}, {"number": 2176, "title": "setting allocated memory of gpu", "body": "By using options like `gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)` , it gives  the process this fraction of **free** gpu's memory. it means when you want to give a process an exact value of memory you must change the fractions due to running sequence of processes. For example if you want to run 2 process simultaneously with half of the memory you have to run the first one with 0.5 fraction and the second one with 1.0 fraction.\nIs there any way to allocate an exact  size for each process (for example 2gb)?\n", "comments": ["The current logic is implemented as a fraction of the remaining free memory. \n\nAdding @vrv to decide whether it is okay to switch to a fraction of total memory. \n\nYou are also welcome to make a contribution. The logic is here:\n\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/common_runtime/gpu/gpu_device.cc#L599\n", "Seems fine to switch to fraction of total memory.  Please send a PR!\n", "thanks @vrv. The related PR has been sent.\n"]}, {"number": 2175, "title": "Can't run TensorFlow on CPU, defaults to GPU", "body": "### Environment info\n\nOperating System: \n\n```\nUbuntu 16.04\n```\n\nInstalled version of CUDA and cuDNN: \n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\n\n```\n-rw-r--r--   1 root root    322936 Eyl 19  2015 libcudadevrt.a\nlrwxrwxrwx   1 root root        16 Mar 30 15:25 libcudart.so -> libcudart.so.7.5\nlrwxrwxrwx   1 root root        19 Mar 30 15:25 libcudart.so.7.5 -> libcudart.so.7.5.18\n-rw-r--r--   1 root root    383336 Eyl 19  2015 libcudart.so.7.5.18\n-rw-r--r--   1 root root    720192 Eyl 19  2015 libcudart_static.a\nlrwxrwxrwx   1 root root        12 Nis 14 18:53 libcuda.so -> libcuda.so.1\nlrwxrwxrwx   1 root root        17 Nis 14 18:53 libcuda.so.1 -> libcuda.so.361.42\n-rw-r--r--   1 root root  16881416 Mar 23 02:42 libcuda.so.361.42\n-rwxr-xr-x   1 root root  61453024 Nis 30 11:36 libcudnn.so\n-rwxr-xr-x   1 root root  61453024 Nis 30 11:36 libcudnn.so.4\n-rwxr-xr-x   1 root root  61453024 Nis 30 11:36 libcudnn.so.4.0.7\n-rwxr-xr-x   1 root root  59823168 Nis 30 11:12 libcudnn.so.5\n-rwxr-xr-x   1 root root  59823168 Nis 30 11:12 libcudnn.so.5.0.4\n-rw-r--r--   1 root root  62025862 Nis 30 11:36 libcudnn_static.a\n```\n\nIf installed from binary pip package, provide:\n1. Which pip package you installed.\n   Installed using the command \n\n```\nsudo pip install --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.8.0-cp27-none-linux_x86_64.whl\n```\n1. The output from python -c \"import tensorflow; print(tensorflow.**version**)\".\n\n```\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally\n0.8.0\n```\n\nIf installed from sources, provide the commit hash:\n### Steps to reproduce\n\n```\n>>> import tensorflow as tf\n>>> \n>>> with tf.Session() as sess:\n...     with tf.device('/cpu:0'):\n...             matrix1 = tf.constant([[3., 3.]])\n...             matrix2 = tf.constant([[2.],[2.]])\n...             product = tf.matmul(matrix1, matrix2)\n...             result = sess.run(product)\n...             print(result)\n... \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: \nname: GeForce GTX 980 Ti\nmajor: 5 minor: 2 memoryClockRate (GHz) 1.291\npciBusID 0000:01:00.0\nTotal memory: 6.00GiB\nFree memory: 5.48GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:755] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 980 Ti, pci bus id: 0000:01:00.0)\n[[ 12.]]\n```\n", "comments": ["It's not related to your problem. But suitable cuDNN version for tensorflow 0.8.0 is v4. It works fine in some cases btw but maybe it cause some other problems in the future ;)\n", "I know, the MNIST tutorial didn't work with v5, so I downloaded v4, and it works.. \n", "Just as a note, pinning the ops to cpu:0 may not prevent tensorflow from initializing the GPU device. \n\nIs there still an issue here? Closing for now.\n", "Could do something like this to see placement, I bet your ops are still on CPU.\n\nAlso, to remove GPU from consideration completely, run `export CUDA_VISIBLE_DEVICES=`\n\n```\n  config = tf.ConfigProto(log_device_placement=True)\n  config.gpu_options.per_process_gpu_memory_fraction=0.3 # don't hog all vRAM\n  config.operation_timeout_in_ms=50000   # terminate on long hangs\n  sess = tf.InteractiveSession(\"\", config=config)\n\n```\n", "Yep ops are on cpu. Set the visible gpu devices to blank, observed correct behaviour, and got the correct final result of the matmult.\n\n```\n(tensorflow)username@pcname:~$ export CUDA_VISIBLE_DEVICES=\n(tensorflow)username@pcname:~$ python\nPython 2.7.11 |Continuum Analytics, Inc.| (default, Dec  6 2015, 18:08:32) \n[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)] on linux2\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\nAnaconda is brought to you by Continuum Analytics.\nPlease check out: http://continuum.io/thanks and https://anaconda.org\n>>> import tensorflow as tf\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally\n>>> \n>>> with tf.Session() as sess:\n...     with tf.device('/cpu:0'):\n...             matrix1 = tf.constant([[3., 3.]])\n...             matrix2 = tf.constant([[2.],[2.]])\n...             product = tf.matmul(matrix1, matrix2)\n...             result = sess.run(product)\n...             print(result)\n... \nE tensorflow/stream_executor/cuda/cuda_driver.cc:481] failed call to cuInit: CUDA_ERROR_NO_DEVICE\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:114] retrieving CUDA diagnostic information for host: pcname\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:121] hostname: pcname\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:146] libcuda reported version is: 361.42\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] driver version file contents: \"\"\"NVRM version: NVIDIA UNIX x86_64 Kernel Module  361.42  Tue Mar 22 18:10:58 PDT 2016\nGCC version:  gcc version 5.3.1 20160413 (Ubuntu 5.3.1-14ubuntu2) \n\"\"\"\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:150] kernel reported version is: 361.42\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:226] kernel version seems to match DSO: 361.42\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:81] No GPU devices available on machine.\n[[ 12.]]\n>>> \n```\n", "I'm on Windows and `CUDA_VISIBLE_DEVICES=` or `os.environ['CUDA_VISIBLE_DEVICES'] = ''` still didn't work for me, GPU devices were still created, even if not used. However setting `os.environ['CUDA_VISIBLE_DEVICES'] = '-1'` did work for me, only giving me a warning (seems to be a kind of recommended way of masking devices according to [the docs](http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#env-vars)).", "@javidcf  Thanks javier for the hint. \r\nI have a laptop with nvidia optimus (dual gpu)  with seamless transition. It has a led which indicates which gpu is using (intel iGPU or nvidia dedicated gpu), with: \r\n`os.environ['CUDA_VISIBLE_DEVICES'] = ''` or `os.environ['CUDA_VISIBLE_DEVICES'] = '0'`\r\nTensorflow was creating a gpu process on cuda without anyload and my laptop was turning on the nvidia gpu for nothing, even the operations are done on the cpu.\r\n\r\nBut with your solution the tensorflow is not instantiating the empty process anymore and then my laptop is shutting down the dedicated gpu.\r\n\r\nthanks for your solution.", "When I set CUDA_VISIBLE_DEVICES=-1 on my machine with a single GPU I get the following error:\r\n```\r\n2017-07-13 16:13:00.617400: E tensorflow/stream_executor/cuda/cuda_driver.cc:406] failed call to cuInit: CUDA_ERROR_NO_DEVICE\r\n2017-07-13 16:13:00.617475: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:158] retrieving CUDA diagnostic information for host: eggplant-ed-ubuntu\r\n2017-07-13 16:13:00.617495: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:165] hostname: eggplant-ed-ubuntu\r\n2017-07-13 16:13:00.617567: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] libcuda reported version is: 381.22.0\r\n2017-07-13 16:13:00.617599: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:369] driver version file contents: \"\"\"NVRM version: NVIDIA UNIX x86_64 Kernel Module  381.22  Thu May  4 00:55:03 PDT 2017\r\nGCC version:  gcc version 6.3.0 20170406 (Ubuntu 6.3.0-12ubuntu2) \r\n\"\"\"\r\n2017-07-13 16:13:00.617613: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:193] kernel reported version is: 381.22.0\r\n2017-07-13 16:13:00.617618: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:300] kernel version seems to match DSO: 381.22.0\r\n```\r\n\r\nSeems like this is an edge case that should ideally be handled (unless there is some way to enumerate CUDA devices before calling cuInit and avoid calling it at all). Interestingly the docs for cuInit don't mention CUDA_ERROR_NO_DEVICE as a valid return code so it's probably not surprising that this is how TF behaves.", "@ed-alertedh I also get that error log message when I create the first session with `CUDA_VISIBLE_DEVICES=-1`, but at least for me the code still works fine. If you want, you can filter out log messages up to error level (leaving only fatal messages) setting the environment variable `TF_CPP_MIN_LOG_LEVEL=3` before loading TensorFlow.", "Ah OK, I assumed it was hanging but perhaps this graph just runs really slowly on CPU!", "I found this code by [Franck Dernoncourt](https://stackoverflow.com/users/395857/franck-dernoncourt) from his question in [Stack Overflow](https://stackoverflow.com/questions/42422042/forcing-tensorflow-gpu-to-use-the-cpu-from-the-command-line):\r\n\r\n```\r\nsession_conf = tf.ConfigProto(\r\n    device_count={'CPU' : 1, 'GPU' : 0},\r\n    allow_soft_placement=True,\r\n    log_device_placement=False\r\n)\r\n```\r\n\r\nThen use that `ConfigProto` in `tf.Session`, that is:\r\n\r\n```\r\nwith tf.Session(config=session_conf) as sess:\r\n    # run commands\r\n    ...\r\n```\r\n\r\nI did the above code in a simple implementation:\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\na = tf.constant([x for x in range(0, 3)], dtype=tf.float32, shape=[2, 3], name='a')\r\nb = tf.constant([x for x in range(3, 6)], dtype=tf.float32, shape=[3, 2], name='b')\r\nc = tf.matmul(a, b)\r\n\r\nsession_conf = tf.ConfigProto(\r\n    device_count={'CPU' : 1, 'GPU' : 0},\r\n    allow_soft_placement=True,\r\n    log_device_placement=False\r\n)\r\n\r\nwith tf.Session(config=session_conf) as sess:\r\n    print(sess.run(c))\r\n```\r\n\r\nThen I had the following result:\r\n\r\n```\r\n2017-07-26 14:34:42.208873: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 960M, pci bus id: 0000:02:00.0)\r\nDevice mapping: no known devices.\r\n2017-07-26 14:34:42.208980: I tensorflow/core/common_runtime/direct_session.cc:265] Device mapping:\r\n\r\nMatMul: (MatMul): /job:localhost/replica:0/task:0/cpu:0\r\n2017-07-26 14:34:42.210952: I tensorflow/core/common_runtime/simple_placer.cc:847] MatMul: (MatMul)/job:localhost/replica:0/task:0/cpu:0\r\nb: (Const): /job:localhost/replica:0/task:0/cpu:0\r\n2017-07-26 14:34:42.211003: I tensorflow/core/common_runtime/simple_placer.cc:847] b: (Const)/job:localhost/replica:0/task:0/cpu:0\r\na: (Const): /job:localhost/replica:0/task:0/cpu:0\r\n2017-07-26 14:34:42.211029: I tensorflow/core/common_runtime/simple_placer.cc:847] a: (Const)/job:localhost/replica:0/task:0/cpu:0\r\n[[ 15.  15.]\r\n [ 26.  28.]]\r\n```\r\n\r\nAs you can see, it did map the computation to `cpu:0`.", "Unix shell alias:\r\n\r\n```sh\r\nalias nogpu='export CUDA_VISIBLE_DEVICES=-1;'\r\n```\r\n\r\nUsage:\r\n\r\n```sh\r\nnogpu python your_tensorflow_script.py\r\n```", "Worked for me\r\n`os.environ['CUDA_VISIBLE_DEVICES'] = '-1' `", "I made a few changes to a utility by @yaroslavvb to handle this nicely as well as making it easy to grab a specific number of GPUs. The previous comment reminded me so thought I may as well share it here https://gist.github.com/ed-alertedh/58d3eb96cf1ba70542b657471dd377ca", "Is it possible to disable cpu usage in tensorflow or limiting the number of cores?  ", "This environment variable is pretty universal - it can be used to block out access to all GPUs completely in many ML frameworks, not restricted to DNN and Tensorflow. I've verified in a docker container with several DNN frameworks compiled with CUDA 9.0 support, that setting:\r\n```\r\nENV CUDA_VISIBLE_DEVICES=-1\r\n```\r\nat the very end of the Dockerfile blocked out GPU access completely (with graceful error handling). The list where this GPU block is verified to work includes: \r\n- Chainer\r\n- CNTK\r\n- Keras with Tensorflow backend\r\n- Lasagne\r\n- MXNET\r\n- Tensorflow\r\n- Theano\r\n- PyTorch.\r\n\r\nSome of these, including Keras + Tensorflow will also fall back to CPU to complete the calculations.\r\n\r\n\r\n", "what if you want to change it back? what are you suppose to set os.environ['CUDA_VISIBLE_DEVICES'] to?", "@erotavlas You cannot change the effect of the variable once you have already loaded TensorFlow (you can change the value, but it will not have any effect, as it is only used by CUDA on load). If you want to set the variable _before_ loading TensorFlow, you may have a look at [the documentation](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#env-vars), where it explains that `CUDA_\u200bVISIBLE_\u200bDEVICES` is:\r\n\r\n> A comma-separated sequence of GPU identifiers\r\n\r\nAnd then elaborates:\r\n\r\n> GPU identifiers are given as integer indices or as UUID strings. GPU UUID strings should follow the same format as given by _nvidia-smi_, such as GPU-8932f937-d72c-4106-c12f-20bd9faed9f6. However, for convenience, abbreviated forms are allowed; simply specify enough digits from the beginning of the GPU UUID to uniquely identify that GPU in the target system. For example, CUDA_VISIBLE_DEVICES=GPU-8932f937 may be a valid way to refer to the above GPU UUID, assuming no other GPU in the system shares this prefix.\r\n> \r\n> Only the devices whose index is present in the sequence are visible to CUDA applications and they are enumerated in the order of the sequence. If one of the indices is invalid, only the devices whose index precedes the invalid index are visible to CUDA applications. For example, setting CUDA_VISIBLE_DEVICES to 2,1 causes device 0 to be invisible and device 2 to be enumerated before device 1. Setting CUDA_VISIBLE_DEVICES to 0,2,-1,1 causes devices 0 and 2 to be visible and device 1 to be invisible.\r\n\r\nEssentially, if  `CUDA_\u200bVISIBLE_\u200bDEVICES` is set then CUDA (and therefore TensorFlow) will only \"see\" the GPUs enumerated in there (by index or UUID), and `-1` can be used as a value guaranteed to be invalid."]}, {"number": 2174, "title": "Unable to find a suitable algorithm for doing forward convolution", "body": "### Environment info\n\nOperating System: Ubuntu 14.04 LTS\nGraphics card: GeForce GTX 750 Ti/PCIe/SSE2\n\nInstalled version of CUDA and cuDNN: CUDA 7.5, cuNN v5\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`): see cudalib.txt\n\nIf installed from sources, provide the commit hash:\nI installed from source -> git clone --recurse-submodules https://github.com/tensorflow/tensorflow\nPulled it today: 04/29/2016\n### Steps to reproduce\n1.  From the tutorial section I copied the partial differential equations example exactly\n2. I started a tensorflow environment: \"source ~/tensorflow/bin/activate\"\n3. I ran example from the command line: \"python pde_example.py\"\n4. I get this segmentation fault when I run it on a system using GPUs (details of this are in pde_error.txt) in the loop at:  step.run({eps: 0.03, damping: 0.04})\n   NOTE: I've run this example on a system not using GPUs and it works splendidly.  Also, I've run other scripts just fine using using the GPUs, it's just this one that doesn't seem to be working.\n### What have you tried?\n1. I've tried running ./configure with the system default values and putting in them myself, then rebuilding.\n2. Running other scripts using the GPU work fine.\n3. Running this script using a CPU on other machines works fine.\n### Logs or other output that would be helpful\n\n(If logs are large, please upload as attachment).\n\n[pde_error.txt](https://github.com/tensorflow/tensorflow/files/243444/pde_error.txt)\n[cudalib.txt](https://github.com/tensorflow/tensorflow/files/243447/cudalib.txt)\n", "comments": ["I think zhengxq@ was looking at the auto-selection algorithm in CuDNN, any ideas?\n", "@vrv: Presumably more information is required, but I'm not sure what to ask for.\n", "I think I saw on another issues that Ubuntu 14.04 has problems with Cuda 7.5 \n", "@taylorhughmorgan, could you try the latest TensorFlow again, and see if you still have this problem? Thanks. \n", "I just pulled this morning and re-built tensorflow.  I still get the same problem.  when I call `watch nvidia-smi` it looks like it starts using the gpu. \n[gpu_pde_error.txt](https://github.com/tensorflow/tensorflow/files/335810/gpu_pde_error.txt)\n", "Could you double check this is from the latest TensorFlow master branch, and not using a stable binary? This line number 675 for this check seems to be quite old. \n\nF tensorflow/stream_executor/cuda/cuda_dnn.cc:675] Check failed: status == CUDNN_STATUS_SUCCESS (3 vs. 0)Unable to find a suitable algorithm for doing forward convolution\n\nAlso this line will only be triggered if there is no auto-tuning. But more recent TensorFlow has switched to Autotun by default. \n\nHowever, even if this is older code, why would this be triggered is still unknown. The return status is \"CUDNN_STATUS_BAD_PARAM\". That means somehow a bad parameter was passed in. \n", "Automatically closing due to lack of activity.\n"]}, {"number": 2173, "title": "Import numpy before a call to sys.setdlopenflags", "body": "Must import numpy before a call to sys.setdlopenflags, or there may be a segfault in certain situations. Fixes #2034.\n\nThe situation occurs when users have compiled TensorFlow, but use binary distributions of SciPy. Alternatives to this patch would be documentation stating that users who compile TensorFlow from source should also recompile SciPy if they need it.\n", "comments": ["Can one of the admins verify this patch?\n", "Nice investigation...how did you find it/any idea why this happens? Adding @keveman who added this part of code (although he may be slow to respond due to ICLR)\n", "Jenkins, test this please.\n\nNice catch. Very obscure, much wow.\n", "Yeah so this is just like some horrible edge case and part of the reason for the UNIQUE_SYMBOL mess in NumPy I guess.\n\nAnyway when you include NumPy, you have to call import_array to populate some function pointers. Each C module needs to do this separately, and is supposed to have its own housekeeping for these function pointers. With the GLOBAL flag on though, there is overlap in some of these shared symbols (the UNIQUE_SYMBOL is the same in NumPy and Scipy:  PyArray_API). The result is the initialization code generated by any f2py module will clobber the housekeeping and dereference a bad pointer. Whoops! But if you do the import _before_ the GLOBAL flag is set, then there is no shared symbol conflict, so the modules happily do their own housekeeping like they expect. O_o\n\n@yaroslavvb I have just really, really wanted to use TensorFlow on the Texas supercomputing clusters, which use too old GLIBC to use the binary distribution, so I've been stuck compiling TF myself :stuck_out_tongue: \n", "Hm... timeout, probably infrastructure failure. Will try again later.\n", "@tensorflow-jenkins test this please\n"]}, {"number": 2172, "title": "Blacklist py tests in python/platform/default", "body": "These tests are superseded by the corresponding ones in python/platform\nin the OSS tests. They are currently used only internally and will be\neventually removed in the future.\n\nThis PR also fixes a bug in test_installation.sh that could cause infinite\nloops in certain cases.\n", "comments": ["Ready to merge. This should fix an error we are currently seeing in the nightly builds right now.\n"]}]