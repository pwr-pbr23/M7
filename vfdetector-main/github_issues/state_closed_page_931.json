[{"number": 25518, "title": "prediction of image segmentation after training the network tensorflow", "body": "hello everyone,\r\ni am working for vessel segmentation from retinal image. i am using an autoencoder network with softmax activation function for the final layer. this is my following code for training and prediction:\r\n\r\n** training code\r\n//loss function\r\nlosses =tf.nn.softmax_cross_entropy_with_logits(labels=net_output, logits=network)\r\n\r\ncost = tf.reduce_mean(losses)\r\ntf.summary.scalar(\"cross_entropy\", cost)\r\n//Adam optimizer\r\nopt = tf.train.AdamOptimizer(args.learning_rate).minimize(cost, var_list=[var for var in tf.trainable_variables()])\r\n\r\ninit = tf.global_variables_initializer()\r\n\r\ncorrect_prediction = tf.equal(tf.argmax(network, 1), tf.argmax(net_output, 1))\r\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\r\n\r\nfor epoch in range(0, args.num_epochs):\r\n\r\n```\r\nfor i in range(0, len(train_input_names)):\r\n\r\n   input_black_ring_image = preprocessing(train_input_names[i])\r\n   input_image, segmented_image = data_augmentation(input_black_ring_image, train_segmented_names[i])\r\n       for k in range(0, len(input_image)):\r\n\r\n            for j in range(0, args.batch_size):\r\n\r\n                index= k*args.batch_size + j\r\n                    with tf.device('/gpu:0'):\r\n                      input_slice = np.float32(input_image[index]) / 255.0\r\n\r\n                      output_slice = np.float32(helpers.one_hot_it(label=segmented_image[index], label_values=label_values))\r\n\r\n\r\n                                input_image_batch.append(np.expand_dims(input_slice, axis=0))\r\n                                segmented_image_batch.append(np.expand_dims(output_slice, axis=0))                        \r\n            if args.batch_size == 1:\r\n                input_img = input_image_batch[0]\r\n\r\n\r\n                 output_img = segmented_image_batch[0]\r\n\r\n            else:\r\n                 input_img = np.squeeze(np.stack(input_image_batch, axis=1))\r\n                 output_img = np.squeeze(np.stack(segmented_image_batch, axis=1))  \r\n```\r\n\r\n//training\r\n_,current=sess.run([opt, cost],feed_dict={net_input:input_img, net_output:output_img})\r\nprint(\"loss of img \"+str(i) +\" slice \" +str(k)+\" =\"+str(current))\r\n\r\n**prediction code\r\n\r\n```\r\n            //image for prediction\r\n             input_slice_test = np.float32(input_image_test[15]) / 255.0 \r\n\r\n\r\n            input_image_test = np.expand_dims(input_slice_test, axis=0)\r\n            print(\"input     \", input_image_test)\r\n         //prediction    \r\n            output_image = sess.run(network, feed_dict={net_input:input_image_test})\r\n            print(\"output\", output_image)`\r\n```\r\n\r\nthe value of accuracy look logic it converge after each epoch but when i try to predict an image after training all the epochs, the value of predicted array output look like this:\r\n\r\n//result of prediction\r\n[[[[4.4425573e-02 8.8295966e-01]\r\n[5.4390044e-03 9.7242403e-01]\r\n[1.9392670e-03 9.8569876e-01]\r\n\r\nand the image is full white.\r\nany help please!!", "comments": ["@hendaboudegga Please post this kind of support questions at [Stackoverflow](https://stackoverflow.com/questions/tagged/tensorflow). There is a big community to support and learn from your questions. GitHub is mainly for addressing bugs in installation and performance. Thanks!", "Closing this support issue. Please post this kind of support questions at [Stackoverflow](https://stackoverflow.com/questions/tagged/tensorflow). Thanks!"]}, {"number": 25517, "title": "AttributeError: module 'tensorflow.python.ops.losses.losses_impl' has no attribute 'ReductionV2'", "body": "Installing tensorflow 1.12.0 with `pip install tensorflow` results in the following error:\r\n\r\n```\r\nPython 3.6.8 |Anaconda, Inc.| (default, Dec 30 2018, 01:22:34)\r\n[GCC 7.3.0] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/s.ivanov/miniconda3/envs/tf_env/lib/python3.6/site-packages/tensorflow/__init__.py\", line 24, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"/home/s.ivanov/miniconda3/envs/tf_env/lib/python3.6/site-packages/tensorflow/python/__init__.py\", line 55, in <module>\r\n    'tensorflow_estimator.python.estimator'))\r\n  File \"/home/s.ivanov/miniconda3/envs/tf_env/lib/python3.6/site-packages/tensorflow/python/tools/component_api_helper.py\", line 56, in package_hook\r\n    child_pkg = importlib.import_module(child_package_str)\r\n  File \"/home/s.ivanov/miniconda3/envs/tf_env/lib/python3.6/importlib/__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"/home/s.ivanov/miniconda3/envs/tf_env/lib/python3.6/site-packages/tensorflow_estimator/__init__.py\", line 8, in <module>\r\n    from tensorflow_estimator._api.v2 import estimator\r\n  File \"/home/s.ivanov/miniconda3/envs/tf_env/lib/python3.6/site-packages/tensorflow_estimator/_api/v2/estimator/__init__.py\", line 8, in <module>\r\n    from tensorflow_estimator._api.v2.estimator import experimental\r\n  File \"/home/s.ivanov/miniconda3/envs/tf_env/lib/python3.6/site-packages/tensorflow_estimator/_api/v2/estimator/experimental/__init__.py\", line 8, in <module>\r\n    from tensorflow_estimator.python.estimator.canned.dnn import dnn_logit_fn_builder\r\n  File \"/home/s.ivanov/miniconda3/envs/tf_env/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/__init__.py\", line 25, in <module>\r\n    import tensorflow_estimator.python.estimator.estimator_lib\r\n  File \"/home/s.ivanov/miniconda3/envs/tf_env/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator_lib.py\", line 22, in <module>\r\n    from tensorflow_estimator.python.estimator.canned.baseline import BaselineClassifier\r\n  File \"/home/s.ivanov/miniconda3/envs/tf_env/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/canned/baseline.py\", line 67, in <module>\r\n    from tensorflow_estimator.python.estimator.head import head_utils\r\n  File \"/home/s.ivanov/miniconda3/envs/tf_env/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/head/head_utils.py\", line 23, in <module>\r\n    from tensorflow_estimator.python.estimator.head import binary_class_head\r\n  File \"/home/s.ivanov/miniconda3/envs/tf_env/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/head/binary_class_head.py\", line 24, in <module>\r\n    from tensorflow.python.keras.utils import metrics_utils\r\n  File \"/home/s.ivanov/miniconda3/envs/tf_env/lib/python3.6/site-packages/tensorflow/python/keras/utils/metrics_utils.py\", line 31, in <module>\r\n    from tensorflow.python.keras.utils.losses_utils import squeeze_or_expand_dimensions\r\n  File \"/home/s.ivanov/miniconda3/envs/tf_env/lib/python3.6/site-packages/tensorflow/python/keras/utils/losses_utils.py\", line 144, in <module>\r\n    weighted_losses, reduction=losses_impl.ReductionV2.SUM_OVER_BATCH_SIZE):\r\nAttributeError: module 'tensorflow.python.ops.losses.losses_impl' has no attribute 'ReductionV2'\r\n```\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux\r\n- TensorFlow version: 1.12.0\r\n- Python version: 3.6\r\n- Installed using virtualenv? pip? conda?: pip", "comments": ["@nd7141 Did you follow the instructions on [tensorflow website](https://www.tensorflow.org/install/source). While installing from source, please also note that [tested build configuration](https://www.tensorflow.org/install/source#linux) for Linux system. Please let me know how it progresses. Thanks!", "Will deleting the tensorflow directory help? If you are not in a virtual environment:\r\n```bash\r\nsudo pip3 uninstall tensorflow\r\nsudo rm -r /usr/local/lib/python3.6/dist-packages/tensorflow/\r\nsudo pip3 install tensorflow\r\npython3 -c \"import tensorflow as tf; tf.enable_eager_execution(); print(tf.reduce_sum(tf.random_normal([1000, 1000])))\"\r\n```\r\nThese commands apparently got my system working.", "I think it was resolved. I am closing the issue. Open a new ticket if the bug persists. Thanks!"]}, {"number": 25516, "title": "Defining metrics within loss functions was possible in Keras!", "body": "**System information**\r\n- TensorFlow version: 1.12.0\r\n- Are you willing to contribute it: (Yes/No)\r\n\r\nIn Keras, it was possible to define metrics inside loss functions using closures. This means that something like the following \r\n\r\n```\r\nclass Loss():\r\n    def __init__(self):\r\n        self.metrics = []\r\n    \r\n    def loss(self, y_true, y_pred):\r\n        \r\n        # the following can be some complicated intermediate stuff that\r\n        # would otherwise require redundant code\r\n        t1 = tf.reduce_mean(y_true-y_pred)\r\n        m2 = tf.reduce_max(y_true-y_pred)\r\n        m3 = tf.reduce_min(y_true-y_pred)\r\n        \r\n        def m1(y_true, y_pred):\r\n            return t1\r\n        self.metrics.append(m1)\r\n        \r\n        def make_fcn(tensor, name):\r\n            f = lambda y_true, y_pred: tensor\r\n            f.__name__ = name\r\n            return f\r\n        for m in ['m2', 'm3']:\r\n            self.metrics.append(make_fcn(eval(m),m))\r\n        \r\n        return tf.reduce_sum((y_true-y_pred)**2)\r\n\r\noutput2_loss = Loss()\r\n\r\nmodel.compile(\r\n    optimizer=keras.optimizers.RMSprop(lr=0.001, decay=1e-6), \r\n    loss={'pred': 'categorical_crossentropy', 'output2': output2_loss.loss},\r\n    metrics={'pred': ['accuracy'], 'output2': output2_loss.metrics}\r\n)\r\n```\r\n\r\nworks perfectly fine in normal Keras but does not work in TensorFlow Keras.\r\n\r\nI assume that there is no clear specification when the loss functions are evaluated and it is also clear to me that the approach may not work with eager execution.\r\n\r\nIs there any elegant mechanism or workaround to achieve a similar behaviour?\r\n", "comments": ["The following works, but it is still more a hack than a solution...\r\n```\r\nclass Loss():\r\n    def __init__(self):\r\n        self.metric_names = ['m1', 'm2', 'm3']\r\n        \r\n        def make_fcn(name):\r\n            f = lambda y_true, y_pred: self._metric_functions[name](y_true, y_pred)\r\n            f.__name__ = name\r\n            return f\r\n        self._metric_functions = {}\r\n        self.metrics = [make_fcn(name) for name in self.metric_names]\r\n    \r\n    def loss(self, y_true, y_pred):\r\n        \r\n        # the following can be some complicated intermediate stuff that otherwise requires redundant code\r\n        m1 = tf.reduce_mean(y_true-y_pred)\r\n        m2 = tf.reduce_max(y_true-y_pred)\r\n        m3 = tf.reduce_min(y_true-y_pred)\r\n        \r\n        def make_fcn(tensor):\r\n            return lambda y_true, y_pred: tensor\r\n        for name in self.metric_names:\r\n            self._metric_functions[name] = make_fcn(eval(name))\r\n        \r\n        return tf.reduce_sum((y_true-y_pred)**2)\r\n\r\noutput2_loss = Loss()\r\n\r\nmodel.compile(\r\n    optimizer=keras.optimizers.RMSprop(lr=0.001, decay=1e-6), \r\n    loss={'pred': 'categorical_crossentropy', 'output2': output2_loss.loss},\r\n    metrics={'pred': ['accuracy'], 'output2': output2_loss.metrics}\r\n)\r\n```", "Hello @mvoelk, definition of metric functions should not be dependent of when a loss function is called. This happens to work in keras-team/keras but it is definitely not an input that is supported.\r\n\r\nLoss or metric inputs can be \r\n1. strings which are names of inbuilt functions\r\n2. inbuilt functions\r\n3. instances of inbuilt loss or metric classes\r\n4. custom functions with standard (y_true, y_pred, ..) signature\r\n5. instances of custom classes where the __call__ function has the standard signature."]}, {"number": 25515, "title": "install_pip_packages.sh: 'pep8' is now 'pycodestyle'", "body": "As discussed at https://pep8.readthedocs.io\r\n\r\nhttps://pypi.org/project/pep8/ says:\r\n### Changelog\r\n### 1.7.1 (2017-10-22)\r\nChanges:\r\n* Prominently note via warning message that the tool is no longer released as pep8 and will only be fixed in the pycodestyle package\r\n\r\n\r\n", "comments": []}, {"number": 25514, "title": "Add tf.keras.layers.Log_Softmax", "body": "Applies the logarithm after softmax function of the logit. This implementation should be more efficient using \r\nlogsoftmax = logits - log(reduce_sum(exp(logits), axis))\r\n", "comments": ["@XuesongYang Looks like this is a new layer type and it doesn't exist in keras-team/keras yet. Adding folks from the Keras team as reviewers.", "Thanks for the PR.\r\n\r\nWe don't add new layers that are simply wrapping a simple stateless TF op (in this case `nn.log_softmax_v2`). You can just use `nn.log_softmax_v2` as-is, or if you need to wrap it in a layer, you can use `tf.keras.layers.Lambda(nn.log_softmax_v2)`.", "I wish you can add this to Keras.  I had troubles with this.  I took me quite some time to land this page to learn this lambda wrap approach.  At least, I learned something new.  "]}, {"number": 25513, "title": "Custom Reader Op results in undefined symbol: _ZTIN10tensorflow8OpKernelE on library load", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): Docker container, also tried source\r\n- TensorFlow version: 1.12.0\r\n- Python version: 2.7\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source): 0.18\r\n- GCC/Compiler version (if compiling from source): 5.4\r\n- CUDA/cuDNN version: 9/7\r\n- GPU model and memory: 1080ti\r\n\r\n\r\nI have a custom Reader op that inherits ReaderBase class (tensorflow/core/framework/reader_base.h). The op compiled and worked as expected under TF 1.3 and earlier.\r\n\r\nI have now upgraded to TF1.12.0. Shared library for the custom op builds successfully, but  loading it with `import tensorFlow as tf; tf.load_op_library()` fails due to missing symbols:\r\n`tensorflow.python.framework.errors_impl.NotFoundError: ./libjson_record_reader_op.so: undefined symbol: _ZTIN10tensorflow8OpKernelE`\r\n\r\nActually, at first it was reporting undefined symbol ReaderBaseE, but now reporting OpKernelE.\r\n\r\nI tried building the op in the following Docker containers with the following tags: 1.12.0, 1.12.0-devel, 1.12.0-gpu-devel.\r\n\r\nI have also built TF from source with bazel 0.18 and installed via pip (also in tensorflow/tensorflow-devel-gpu container) with the same result as above.\r\n\r\nBuilding custom op as per current instructions in the docs using g++. I tried building with g++ 5.5, 5.4, 4.8, 4.9 with the same result.\r\n", "comments": ["We also need to see what commands you used to build your custom op.\r\n\r\n@yifeif could you link our official custom op guide?", "```\r\nTF_CFLAGS=( $(python -c 'import tensorflow as tf; print(\" \".join(tf.sysconfig.get_compile_flags()))') )\r\nTF_LFLAGS=( $(python -c 'import tensorflow as tf; print(\" \".join(tf.sysconfig.get_link_flags()))') )\r\n\r\ng++ ${TF_CFLAGS[@]}  \\\r\n    ${TF_LFLAGS[@]} \\\r\n    -Ithird_party \\\r\n    -std=c++11 -shared -fPIC -O2 -Wall -fdiagnostics-color \\\r\n    -Wl,--no-as-needed \\\r\n    -o custom_op.so \\\r\n    custom_op.cc\r\n```", "Could you try following the guide at https://github.com/tensorflow/custom-op ?", "I followed the provided instructions to build zero-out example op using Bazel with success. Executing the op works as expected\r\nI replaced zero-out kernel with a simple kernel that inherits ReaderBase. The package builds fine. But when I try to load and execute the op I get\r\n```\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\n  File \"tensorflow_zero_out/__init__.py\", line 19, in <module>\r\n    from tensorflow_zero_out.python.ops.zero_out_ops import zero_out\r\n  File \"tensorflow_zero_out/python/ops/zero_out_ops.py\", line 25, in <module>\r\n    resource_loader.get_path_to_datafile('_zero_out_ops.so'))\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/load_library.py\", line 60, in load_op_library\r\n    lib_handle = py_tf.TF_LoadLibrary(library_filename)\r\ntensorflow.python.framework.errors_impl.NotFoundError: tensorflow_zero_out/python/ops/_zero_out_ops.so: undefined symbol: _ZTIN10tensorflow10ReaderBaseE\r\n```", "@agnz As @gunan [asked](https://github.com/tensorflow/tensorflow/issues/25513#issuecomment-461120767), could you share commands you used to build custom op. Thanks!", "@jvishnuvardhan I'm not sure what exactly you're asking me to share...\r\nI built the custom op in 2 ways:\r\n1) Using g++ directly and I shared the command [here](https://github.com/tensorflow/tensorflow/issues/25513#issuecomment-461168577)\r\n2) Using bazel, as asked by @yifeif, and I used exact instructions specified on the page she linked to.\r\n\r\nCan you please elaborate what you're asking?\r\n\r\n", "@agnz were you using the docker container from the guide? You might need ubuntu 14.04.", "@yifeif I used the docker container from the guide and followed the guide exactly. The only difference is in the custom op class inheriting ReaderBase.", "@agnz could you add -D_GLIBCXX_USE_CXX11_ABI=0 to your g++ flag?", "@yifeif  - Sorry for a very delayed response.\r\n\r\nThis flag is already automatically added from TF_CFLAGS...\r\n\r\nPlease see below a full set of steps to reproduce the problem. Steps are taken from this guide: [https://github.com/tensorflow/custom-op](https://github.com/tensorflow/custom-op)\r\n```\r\ndocker pull tensorflow/tensorflow:custom-op\r\ndocker run -it tensorflow/tensorflow:custom-op /bin/bash\r\n```\r\nThen inside the container\r\n```\r\nroot@be9528464b95:/custom-op#  cd custom-op\r\nroot@be9528464b95:/custom-op# make pip_pkg\r\ng++ -I/usr/local/lib/python2.7/dist-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -O2 -std=c++11 -o tensorflow_zero_out/python/ops/_zero_out_ops.so tensorflow_zero_out/cc/kernels/zero_out_kernels.cc tensorflow_zero_out/cc/ops/zero_out_ops.cc -shared -L/usr/local/lib/python2.7/dist-packages/tensorflow -ltensorflow_framework\r\n### intermediate output removed\r\nroot@be9528464b95:/custom-op# pip install artifacts/*.whl\r\nroot@be9528464b95:/custom-op# cd ..\r\nroot@be9528464b95:/# python -c \"import tensorflow as tf;import tensorflow_zero_out as zero_out_module;print(zero_out_module.zero_out([[1,2], [3,4]]).eval(session=tf.Session()))\"\r\n[[1 0]\r\n [0 0]]\r\nroot@be9528464b95:/custom-op# pip uninstall tensorflow_zero_out\r\n```\r\nEverything works as expected. Now modifying zero_out_kernel.cc to include an additional SimpleReader custom op that inherits from ReaderBase (see source below). It does absolutely nothing and is used just for demonstration purposes.\r\n```\r\nroot@be9528464b95:/custom-op# git diff tensorflow_zero_out/cc/kernels/zero_out_kernels.cc\r\ndiff --git a/tensorflow_zero_out/cc/kernels/zero_out_kernels.cc b/tensorflow_zero_out/cc/kernels/zero_out_kernels.cc\r\nindex 5627142..3338574 100644\r\n--- a/tensorflow_zero_out/cc/kernels/zero_out_kernels.cc\r\n+++ b/tensorflow_zero_out/cc/kernels/zero_out_kernels.cc\r\n@@ -14,6 +14,8 @@ limitations under the License.\r\n ==============================================================================*/\r\n\r\n #include \"tensorflow/core/framework/op_kernel.h\"\r\n+#include \"tensorflow/core/framework/reader_op_kernel.h\"\r\n+#include \"tensorflow/core/framework/reader_base.h\"\r\n\r\n using namespace tensorflow;\r\n\r\n@@ -44,3 +46,42 @@ class ZeroOutOp : public OpKernel {\r\n };\r\n\r\n REGISTER_KERNEL_BUILDER(Name(\"ZeroOut\").Device(DEVICE_CPU), ZeroOutOp);\r\n+\r\n+\r\n+class SimpleReader : public ReaderBase {\r\n+ public:\r\n+  SimpleReader(const string& node_name)\r\n+      : ReaderBase(strings::StrCat(\"SimpleReader '\", node_name, \"'\")) {}\r\n+\r\n+  Status OnWorkStartedLocked() override {\r\n+    return Status::OK();\r\n+  }\r\n+\r\n+  Status OnWorkFinishedLocked() override {\r\n+    return Status::OK();\r\n+  }\r\n+\r\n+  Status ReadLocked(string* key, string* value, bool* produced,\r\n+                    bool* at_end) override {\r\n+    return Status::OK();\r\n+  }\r\n+\r\n+  Status ResetLocked() override {\r\n+    return ReaderBase::ResetLocked();\r\n+  }\r\n+\r\n+};\r\n+\r\n+class SimpleReaderOp : public ReaderOpKernel {\r\n+ public:\r\n+  explicit SimpleReaderOp(OpKernelConstruction* context)\r\n+      : ReaderOpKernel(context) {\r\n+    SetReaderFactory([this]() {\r\n+      return new SimpleReader(name());\r\n+    });\r\n+  }\r\n+};\r\n+\r\n+REGISTER_KERNEL_BUILDER(Name(\"SimpleReader\").Device(DEVICE_CPU),\r\n+                        SimpleReaderOp);\r\n```\r\nTrying to compile and run zero_out op again - this part is identical to the first set of steps, except an additional op has been compiled.\r\n```\r\nroot@be9528464b95:/custom-op# vim tensorflow_zero_out/cc/kernels/zero_out_kernels.cc\r\nroot@be9528464b95:/custom-op# make pip_pkg\r\ng++ -I/usr/local/lib/python2.7/dist-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -O2 -std=c++11 -o tensorflow_zero_out/python/ops/_zero_out_ops.so tensorflow_zero_out/cc/kernels/zero_out_kernels.cc tensorflow_zero_out/cc/ops/zero_out_ops.cc -shared -L/usr/local/lib/python2.7/dist-packages/tensorflow -ltensorflow_framework\r\nroot@be9528464b95:/custom-op# pip install artifacts/*.whl\r\nroot@be9528464b95:/custom-op# python -c \"import tensorflow as tf;import tensorflow_zero_out as zero_out_module;print(zero_out_module.zero_out([[1,2], [3,4]]).eval(session=tf.Session()))\"\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\n  File \"tensorflow_zero_out/__init__.py\", line 19, in <module>\r\n    from tensorflow_zero_out.python.ops.zero_out_ops import zero_out\r\n  File \"tensorflow_zero_out/python/ops/zero_out_ops.py\", line 25, in <module>\r\n    resource_loader.get_path_to_datafile('_zero_out_ops.so'))\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/load_library.py\", line 60, in load_op_library\r\n    lib_handle = py_tf.TF_LoadLibrary(library_filename)\r\ntensorflow.python.framework.errors_impl.NotFoundError: tensorflow_zero_out/python/ops/_zero_out_ops.so: undefined symbol: _ZTIN10tensorflow10ReaderBaseE\r\n```\r\n", "> @agnz could you add -D_GLIBCXX_USE_CXX11_ABI=0 to your g++ flag?\r\n\r\nThis helps me on a similar issue. ", "angz, I am having a similar issue.  Were you able to solve this?  If so what was the solution? Thanks.", "No, sorry, I was not able to make it work and moved to PyTorch since.\r\n", "Thanks for the quick reply on an old post.", "me totototototototototooo!!! using gcc494 and gcc830, both don't work, and  -D_GLIBCXX_USE_CXX11_ABI=0 this is not helpful too.", "@agnz \r\nIs this still an issue? Please take a look at this [link](https://github.com/tensorflow/tensorflow/issues/36691#issuecomment-586026016).It helps.\r\nCould you please update TensorFlow to the latest stable version v.2.6 and let us know if you are facing the same error. Please open a new issue in case you face any issue .Hence moving this to closed status.Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/25513\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/25513\">No</a>\n", "> @agnz Is this still an issue? Please take a look at this [link](https://github.com/tensorflow/tensorflow/issues/36691#issuecomment-586026016).It helps. Could you please update TensorFlow to the latest stable version v.2.6 and let us know if you are facing the same error. Please open a new issue in case you face any issue .Hence moving this to closed status.Thanks!\r\n\r\nI did the test on tf2 2.6.0 with following commands, zero_out.cc exactly from [create_op](https://www.tensorflow.org/guide/create_op)\r\n\r\n```sh\r\n g++ -std=c++11 -I/usr/local/lib/python3.8/dist-packages/tensorflow/include/ -D_GLIBCXX_USE_CXX11_ABI=0 -I/usr/local/cuda/include -I/usr/local/lib/python3.8/dist-packages/tensorflow/include/external/nsync/public  -L/usr/local/cuda/lib64/ -lcudart -L/usr/local/lib/python3.8/dist-packages/tensorflow -l:libtensorflow_framework.so.2 -fPIC -shared zero_out.cc -o zero_out.so  -O2 \r\n```\r\n\r\nit build well but in python  `tf.load_op_library(\"./zero_out.so\"), still has same error:\r\n\r\n```yml\r\nPython 3.8.10 (default, Jun  2 2021, 10:49:15) \r\n[GCC 9.4.0] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\n>>> tf.__version__\r\n'2.6.0'\r\n>>> zero_out_module = tf.load_op_library('./zero_out.so')\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/load_library.py\", line 58, in load_op_library\r\n    lib_handle = py_tf.TF_LoadLibrary(library_filename)\r\ntensorflow.python.framework.errors_impl.NotFoundError: ./zero_out.so: undefined symbol: _ZTIN10tensorflow8OpKernelE\r\n```\r\n\r\nsystem:\r\n\r\n* gpu driver 470.57.02\r\n* cuda 11.4\r\n* gpu: rtx a6000\r\n* ubuntu: 20.04\r\n\r\nplease help out, thanks \r\n\r\n", "Is there any solution to this issue? I'm seeing the same issue and no luck getting past it.\r\n\r\nThanks"]}, {"number": 25512, "title": "Cannot access layer losses attribute under MirroredStrategy", "body": "### System information\r\n- **Have I written custom code**: Yes\r\n- **OS Platform and Distribution**: Linux Ubuntu 18.04\r\n- **TensorFlow installed from**: Binary\r\n- **TensorFlow version**: 1.12.0\r\n- **Python version**: 2.7.15\r\n- **GPU model and memory**: 2 x TITAN V 12GB\r\n\r\n### Describe the problem\r\n\r\nI tried to run some of our code with multiple GPUs using MirroredStrategy instead of Horovod and noticed that it fails with a cryptic error in _tensor_conversion_mirrored. It seems like accessing the losses attribute of a layer doesn't work with MirroredStrategy and the documentation doesn't seem to explain why this shouldn't be possible.\r\n\r\n### Source code / logs\r\n\r\nThe following snippet of code reproduces the error.\r\n\r\n```python\r\nimport os\r\nimport shutil\r\n\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\ntf.logging.set_verbosity(tf.logging.INFO)\r\n\r\n\r\ndef model_fn(features, labels, mode):\r\n    inputs = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\r\n\r\n    conv = tf.layers.Conv2D(\r\n        filters=8,\r\n        kernel_size=3,\r\n        padding=\"same\",\r\n        activation=\"relu\",\r\n        kernel_regularizer=\"l2\",\r\n    )\r\n    x = conv(inputs)\r\n    flat = tf.layers.flatten(x)\r\n    logits = tf.layers.dense(inputs=flat, units=10)\r\n\r\n    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\r\n    total_loss = loss + tf.add_n(conv.losses)\r\n\r\n    optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\r\n    train_op = optimizer.minimize(\r\n        loss=total_loss, global_step=tf.train.get_global_step())\r\n    return tf.estimator.EstimatorSpec(mode=mode, loss=total_loss, train_op=train_op)\r\n\r\n\r\ndef input_fn():\r\n    mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\r\n    data = mnist.train.images\r\n    labels = np.asarray(mnist.train.labels, dtype=np.int32)\r\n    dataset = tf.data.Dataset.from_tensor_slices(({\"x\": data}, labels))\r\n    dataset = dataset.batch(128)\r\n    return dataset\r\n\r\n\r\ndef main(unused_argv):\r\n    model_dir = os.path.expanduser(\"~/experiments/regularization\")\r\n    shutil.rmtree(model_dir, ignore_errors=True)\r\n    os.makedirs(model_dir)\r\n\r\n    strategy = tf.contrib.distribute.MirroredStrategy(num_gpus=2)\r\n    config = tf.estimator.RunConfig(train_distribute=strategy)\r\n\r\n    mnist_classifier = tf.estimator.Estimator(\r\n        model_fn=model_fn, model_dir=model_dir, config=config\r\n    )\r\n    mnist_classifier.train(input_fn, steps=10)\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    tf.app.run()\r\n```", "comments": ["I just tested your code with the latest TF from master and it seems to work. Could you perhaps try again with a TF nightly build? Lots of improvements have happened since the 1.12 release. Feel free to re-open if this still doesn't work for you. "]}, {"number": 25511, "title": "Added missing conditions in the TC's", "body": "Added two test cases for the missing conditions", "comments": ["@aselle , thanks for reviewing my other PRs, can you pls review this PR.", "@jdduke , thanks for the review, i have updated the code as per suggestion. Kindly check.\r\n\r\nRegards\r\nAmit"]}, {"number": 25510, "title": "ci_build: Upgrade the Python 'six' compatibility module", "body": "https://github.com/benjaminp/six/blob/master/CHANGES Fixes a metaclass bug and adds __six.ensure_binary()__, __six.ensure_text()__, and __six.ensure_str()__.", "comments": ["@protoget Your review please?", "Do these test failures make sense?"]}, {"number": 25509, "title": "[tf.data] non-used attributes in some tf.data operation definitions", "body": "Some attributes in [tf.data operation definition](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/ops/dataset_ops.cc) (e.g. `RangeDataset`, `TensorDataset`, `TensorSliceDataset`) do not seem to be used in other places. \r\n\r\nTaken [RangeDataset](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/ops/dataset_ops.cc#L339-L340) as an example, the `output_types` and `output_shapes` are required, but these attributes are not used in [range_dataset_op.cc](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/data/range_dataset_op.cc).", "comments": ["I wouldn't be surprised if these were used in shape inference when iterating over the Dataset. But someone who works on tf.data would know better.", "@allenlavoie Thanks for your explanation. It makes sense if these attributes were used in shape inference. \r\n\r\n@rachellim If you could confirm it, I will close this issue.  ", "These attrs are not used for shape inference. It is possible that these attrs were used before, but the internal implementation of datasets has since changed such that the attrs aren't used in the kernels. Because of TF compatibility guarantees, the OpDefs can't be changed to remove them, and we have no plans to remove the unused attrs. Furthermore, these attrs are actually referenced in some optimizations, such as [map_vectorization](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/grappler/optimizers/data/map_vectorization.cc#L135). ", "Got it. Thanks, @rachellim."]}, {"number": 25508, "title": "Updated interpreter.py for typo errors", "body": "Fixed typo errors in interpreter.py", "comments": ["@aselle , can you pls review this PR", "@amitsrivastava78 please resolve conflicts", "Closing the PR as similar change is already merged.\r\n\r\nRegards\r\nAmit"]}, {"number": 25507, "title": "Cannot import tensorflow-gpu in jupyter notebook.", "body": "Hi,\r\n\r\nI am using the following conda environment and jupyter notebook.\r\n\r\npython==3.5\r\ntensorflow-gpu==1.4.0\r\ncuda==8.0\r\ncudnn==6.0\r\n\r\nWhile I can correctly import tensorflow in the cmd line:\r\n```\r\n(tensorflow) [dushu@ip-172-20-149-210 Mask_RCNN]$ python\r\nPython 3.5.5 |Anaconda, Inc.| (default, May 13 2018, 21:12:35)\r\n[GCC 7.2.0] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as t\r\n/home/dushu/anaconda3/envs/tensorflow/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\r\n  from ._conv import register_converters as _register_converters\r\n>>> t.test\r\n<module 'tensorflow.python.platform.test' from '/home/dushu/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/platform/test.py'>\r\n>>> t.test.gpu_device_name()\r\n2019-02-05 04:08:32.393567: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\r\n2019-02-05 04:08:35.257250: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:892] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-02-05 04:08:35.257629: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:\r\nname: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\r\npciBusID: 0000:00:1e.0\r\ntotalMemory: 11.17GiB freeMemory: 11.10GiB\r\n2019-02-05 04:08:35.257662: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7)\r\n'/device:GPU:0'\r\n```\r\n I can' t import it in the jupyter notebook:\r\n```\r\nImportError: Traceback (most recent call last):\r\n  File \"/home/dushu/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"/home/dushu/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"/home/dushu/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"/home/dushu/anaconda3/envs/tensorflow/lib/python3.5/imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"/home/dushu/anaconda3/envs/tensorflow/lib/python3.5/imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: libcublas.so.8.0: cannot open shared object file: No such file or directory\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n```\r\n\r\nThe jupyter seems cannot find cuda path. The other similar issues don' t work either.\r\n\r\nAny help please ?", "comments": ["solved by specifying \r\n```\r\nsudo ldconfig /usr/local/cuda-8.0/lib64\r\n```\r\n\r\n", "any updated for windows 10 ? I am getting this same error "]}, {"number": 25506, "title": "[Intel MKL] Convolution op perchannel  support", "body": "## Convolution_Perchannel_op\r\n\r\n1. Adding operators to support convolution to be performed perchannel and provided the mkl implementation for the same.\r\n\r\n        QuantizedConv2DPerChannel\r\n\r\n2. Provided Unit test to test the implementation logic of the above mentioned op.\r\n\r\n### IMPORTANT NOTE: \r\nDepends on Requantization perchannel OP PR: https://github.com/tensorflow/tensorflow/pull/25203. The above mentioned PR Needs to be merged before this!", "comments": ["@rthadur @penpornk this PR is a follow up to the requantization op per channel,  https://github.com/tensorflow/tensorflow/pull/25203 that needs review and approval. ", "I think between @penpornk and @tatianashp you have better reviewers than me for this code.", "So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored or co-authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of all the commit author(s), set the `cla` label to `yes` (if enabled on your project), and then merge this pull request when appropriate.*\n\n<!-- need_author_consent -->", "@penpornk ( and @tatianashp )\r\nSorry for the delay! Was pulled into other project and blog work for Intel(google request). Finally got some time to finish this PR. I think I have addressed all the review comments. let me know.\r\n@rthadur can you please trigger the tests again. Highly appreciate it.", "@nammbash  could you please sign CLA", "@rthadur that CLA is because of @Penpornk and a new feature of github. You can look at the comment below for further explanation. \r\nhttps://github.com/tensorflow/tensorflow/pull/25203#issuecomment-461987678", "@rthadur copied below for your quick reference.\r\n\r\nFrom @penpornk here: #25203 (comment)\r\n@hgadig He already signed the CLA. The bot detected his CLA and assigned CLA: yes since the beginning of the PR. Even the message right now says the bot found the CLA for @nammbash. What makes the bot assign CLA: no is because some of the commits are his accepting my online one-line suggestions (GitHub's new feature). For those commits, the author's emails that GitHub automatically used are 38869685+nammbash@users.noreply.github.com and 38085909+penpornk@users.noreply.github.com, which are not recognized by the googlebot.\r\n\r\nGooglebot wants us to verify that all the coauthors in this PR have signed the CLA. There are only two people contributing to this PR: @nammbash and I. So I think we are fine. :)", "> #25203\r\n\r\nsound good", "A Googler has manually verified that the CLAs look good.\n\n(Googler, please make sure the reason for overriding the CLA status is clearly documented in these comments.)\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F25506) for more info**.\n\n<!-- cla_yes -->", "Sorry for my delay. Will take a look at this soon. \r\nRegarding CLA, the situation is different from https://github.com/tensorflow/tensorflow/pull/25203#issuecomment-461987678\r\n\r\nLooking at the commit info, there are two contributors, @nammbash and @ashahba, both have signed their CLAs individually. Quoting googlebot,\r\n\r\n> \ud83d\ude15 The bad news is that it appears that one or more commits were authored or co-authored by someone other than the pull request submitter. We need to confirm that all authors are ok with their commits being contributed to this project. Please have them confirm that here in the pull request.\r\n\r\nEach of you need to confirm here that you are ok with your commits being contributed to this project. I'm setting the CLA to no until then. Thank you!", "So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored or co-authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of all the commit author(s), set the `cla` label to `yes` (if enabled on your project), and then merge this pull request when appropriate.*\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F25506) for more info**.\n\n<!-- need_author_consent -->", "/label cla:yes\r\n/label cla:google", "@penpornk Looks like the one commit from me within the list of commits has caused the `cla` to be marked as no. Here is the link to the commit: https://github.com/tensorflow/tensorflow/pull/25506/commits/d851fbed77f6998dd9bab6ee045077a6c61ff44d\r\nI tried to add label but I don't have access so if you need my consent then sure I am perfectly fine with the PR incorporating that commit.\r\n\r\nPlease let me know if you need anything else from me to unblock the PR.\r\nThanks.", "@penpornk Done! Thank you for the quick reviews on the week of Google Tensorflow Dev Summit.\r\nI got the changes done.\r\nCLA confusion should be resolved with this https://github.com/tensorflow/tensorflow/pull/25506#issuecomment-470231069\r\n\r\nAre the tests passing? Seems like the api tests are failing even wihthout new api changes. Not from my PR?", "@penpornk https://github.com/tensorflow/tensorflow/pull/25506#issuecomment-470263913\r\nFriendly reminder!", "A Googler has manually verified that the CLAs look good.\n\n(Googler, please make sure the reason for overriding the CLA status is clearly documented in these comments.)\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F25506) for more info**.\n\n<!-- cla_yes -->", "@nammbash can you please check failed test", "So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored or co-authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of all the commit author(s), set the `cla` label to `yes` (if enabled on your project), and then merge this pull request when appropriate.*\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F25506) for more info**.\n\n<!-- need_author_consent -->", "@penpornk @rthadur https://github.com/tensorflow/tensorflow/pull/25506#pullrequestreview-213796078\r\nDone! please verify", "A Googler has manually verified that the CLAs look good.\n\n(Googler, please make sure the reason for overriding the CLA status is clearly documented in these comments.)\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F25506) for more info**.\n\n<!-- cla_yes -->", "@nammbash We still need the changes to `tensorflow.raw_ops.pbtxt` anyway (which are related to your PR because it adds `QuantizedConv2DPerChannel`). :) But I'm curious if we can remove the changes to `tensorflow.summary.pbtxt`. ", "@penpornk I see! Anyways let me know! and thank you for your quick responses.", "So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored or co-authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of all the commit author(s), set the `cla` label to `yes` (if enabled on your project), and then merge this pull request when appropriate.*\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F25506) for more info**.\n\n<!-- need_author_consent -->", "@penpornk @rthadur Can you accept the cla so that the tests are triggered please!", "A Googler has manually verified that the CLAs look good.\n\n(Googler, please make sure the reason for overriding the CLA status is clearly documented in these comments.)\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F25506) for more info**.\n\n<!-- cla_yes -->", "@rthadur @penpornk I suppose All tests have passed and the ones failed below are unrelated to my PR? Merge-able now?\r\n\r\nMacOS Contrib \r\nWindows Bazel GPU\r\nimport/copybara", "So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored or co-authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of all the commit author(s), set the `cla` label to `yes` (if enabled on your project), and then merge this pull request when appropriate.*\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F25506) for more info**.\n\n<!-- need_author_consent -->", "@penpornk Done!. Accept the CLA and run the tests please!(Not sure if it is necessary though. Google Bot shows just the previous unwanted PR's to be tested again. :) ) other than the cla.", "A Googler has manually verified that the CLAs look good.\n\n(Googler, please make sure the reason for overriding the CLA status is clearly documented in these comments.)\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F25506) for more info**.\n\n<!-- cla_yes -->", "@penpornk @rthadur Thank you for the quick responses. (I take it there is nothing from my end to do anymore, unless API team pings again)\r\nhttps://github.com/tensorflow/tensorflow/pull/25506#pullrequestreview-214862831\r\nWe actually have 2 other internal PRs waiting on this to merge and hence pending.\r\nIs there someone I can friendly request from the API team for a quick review? Much appreciated!", "@nammbash I left the tests running yesterday and hadn't checked the results until I last commented, so these errors are probably from yesterday. They are from `tensorflow.raw_ops.pbtxt` and are not from removing `tensorflow.summary.pbtxt`.", "@penpornk Yup! I tried to get the fresh public master and ran the command below:\r\n```\r\nbazel --output_base=../testmaster build --cache_test_results=no tensorflow/tools/api/tests:api_compatibility_test\r\nbazel-bin/tensorflow/tools/api/tests/api_compatibility_test\r\n```\r\nit fails even without my PR Changes. Can you verify this and pull my PR in? or let me know otherwise? Thank you for the help Penporn!", "So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored or co-authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of all the commit author(s), set the `cla` label to `yes` (if enabled on your project), and then merge this pull request when appropriate.*\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F25506) for more info**.\n\n<!-- need_author_consent -->", "@penpornk https://github.com/tensorflow/tensorflow/pull/25506#pullrequestreview-216077162\r\nAah! Got it! I did update the files earlier, but was confused as the api test was still failing even after the changes(as with the master).\r\nAnyways, I think you hinted you changed it internally and is going through reviews. I have updated the files just in case.\r\n\r\nLet me know! ", "@nammbash Thanks for changing, but yes I've fixed it internally. The PR has been merged internally and the status here should change soon.", "I'm also setting the CLA to yes again (doesn't really matter now since we are not pulling more updates in, but just in case). Both contributors to this PR, @nammbash and @ashahba have said they are fine with their commits being used in the PR.\r\n\r\n@rthadur The bottom of the page says this branch has a merging conflict (files out of date). I don't think this needs to be fixed since we are not pulling any new changes in. I had fixed the conflicts internally and the PR has been merged.", "A Googler has manually verified that the CLAs look good.\n\n(Googler, please make sure the reason for overriding the CLA status is clearly documented in these comments.)\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F25506) for more info**.\n\n<!-- cla_yes -->", "The changes are already in https://github.com/tensorflow/tensorflow/commit/f949ead8b27a948b8319369875c7f048644dd194 so I'm closing this PR now. ", "@penpornk Thank you for Merging and closing this PR. internally we have a question.\r\nThe Clang format does not seem to be pulled into the main branch and we happen to do the clang formatting again for unrelated PRs.\r\nSpecifically: (see clang format differences the PR had in Intel public branch)\r\nsee Intel-public branch here: https://github.com/Intel-tensorflow/tensorflow/blob/intel-mkl-483/tensorflow/core/kernels/mkl_conv_ops.cc#L464-L468\r\nvs\r\nGoogle public branch here: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/mkl_conv_ops.cc#L464-L468\r\n\r\nYour Internal PR with commit ID f949ead8b27a948b8319369875c7f048644dd194 : has the included 2 parent commit ID's one of which is 54105bde9a2649d6e8b3ee6aafed75cfda3db669 which has the right clang formatting. \r\n\r\nWe are wondering internally as to whether we include clang formatting with unrelated PR's and that is fine and best/simpler course of action for now.\r\n\r\n"]}, {"number": 25505, "title": "Updated backend.py for the typo error", "body": "Fixed one typo error in backend.py", "comments": []}, {"number": 25504, "title": "tf.gather produces Invalid argument error while the code is working on GPU", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): linux ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): v1.8.0-8-g23c2187 1.8.0\r\n- Python version: 3.5\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: CUDA Patch Version 9.2.88.1/ cudnn: 1.7.4\r\n- GPU model and memory: Titan X (Pascal) 12GB\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n**Describe the current behavior**\r\nwhen I run tf.gather, it returns invalid argument error. I found a document saying that tf.gather returns zero when there is an invalid argument on GPU. Even though I am using GPU for running my code, it produces an invalid argument error when I put -1 as an input of tf.gather. \r\n\r\n**Describe the expected behavior**\r\n\r\n**Code to reproduce the issue**\r\nWhen I tested the same code on the terminal, it works.\r\nI can say my tf.gather is in tower/cond/while\r\nI think tower is the problem, since i used tf.gather in cond/while.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n/usr/bin/python3.5 /home/blackfoot/git/tensorpack/examples/FasterRCNN/train.py --config MODE_MASK=True MODE_FPN=True BACKBONE.WEIGHTS=/home/blackfoot/git/tensorpack/examples/FasterRCNN/pretrained/COCO-R50FPN-MaskRCNN-Standard.npz\r\n[0204 23:11:13 @logger.py:87] Argv: /home/blackfoot/git/tensorpack/examples/FasterRCNN/train.py --config MODE_MASK=True MODE_FPN=True BACKBONE.WEIGHTS=/home/blackfoot/git/tensorpack/examples/FasterRCNN/pretrained/COCO-R50FPN-MaskRCNN-Standard.npz\r\n[0204 23:11:13 @config.py:284] Config: ------------------------------------------\r\n{'BACKBONE': {'FREEZE_AFFINE': False,\r\n'FREEZE_AT': 2,\r\n'NORM': 'FreezeBN',\r\n'RESNET_NUM_BLOCKS': [3, 4, 6, 3],\r\n'STRIDE_1X1': False,\r\n'TF_PAD_MODE': False,\r\n'WEIGHTS': '/home/blackfoot/git/tensorpack/examples/FasterRCNN/pretrained/COCO-R50FPN-MaskRCNN-Standard.npz'},\r\n'CASCADE': {'BBOX_REG_WEIGHTS': [[10.0, 10.0, 5.0, 5.0], [20.0, 20.0, 10.0, 10.0],\r\n[30.0, 30.0, 15.0, 15.0]],\r\n'IOUS': [0.5, 0.6, 0.7]},\r\n'DATA': {'BASEDIR': '/data1/coco',\r\n'CLASS_NAMES': ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\r\n'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign',\r\n'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\r\n'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag',\r\n'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite',\r\n'baseball bat', 'baseball glove', 'skateboard', 'surfboard',\r\n'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon',\r\n'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot',\r\n'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant',\r\n'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\r\n'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink',\r\n'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear',\r\n'hair drier', 'toothbrush'],\r\n'NUM_CATEGORY': 80,\r\n'NUM_CLASS': 81,\r\n'TRAIN': ['train2014', 'valminusminival2014'],\r\n'VAL': ('minival2014',)},\r\n'DEBUG': False,\r\n'EPSILON': 0.01,\r\n'FPN': {'ANCHOR_STRIDES': (4, 8, 16, 32, 64),\r\n'CASCADE': False,\r\n'FRCNN_CONV_HEAD_DIM': 256,\r\n'FRCNN_FC_HEAD_DIM': 1024,\r\n'FRCNN_HEAD_FUNC': 'fastrcnn_2fc_head',\r\n'MRCNN_HEAD_FUNC': 'maskrcnn_up4conv_head',\r\n'NORM': 'None',\r\n'NUM_CHANNEL': 256,\r\n'PROPOSAL_MODE': 'Level',\r\n'RESOLUTION_REQUIREMENT': 32},\r\n'FRCNN': {'BATCH_PER_IM': 512,\r\n'BBOX_REG_WEIGHTS': [10.0, 10.0, 5.0, 5.0],\r\n'FG_RATIO': 0.25,\r\n'FG_THRESH': 0.5},\r\n'IDN_FEAT_DIM': 256,\r\n'MODE_FPN': True,\r\n'MODE_MASK': True,\r\n'MRCNN': {'HEAD_DIM': 256},\r\n'PREPROC': {'MAX_SIZE': 1344.0,\r\n'PIXEL_MEAN': [123.675, 116.28, 103.53],\r\n'PIXEL_STD': [58.395, 57.12, 57.375],\r\n'TEST_SHORT_EDGE_SIZE': 800,\r\n'TRAIN_SHORT_EDGE_SIZE': [800, 800]},\r\n'RPN': {'ANCHOR_RATIOS': (0.5, 1.0, 2.0),\r\n'ANCHOR_SIZES': (32, 64, 128, 256, 512),\r\n'ANCHOR_STRIDE': 16,\r\n'BATCH_PER_IM': 256,\r\n'CROWD_OVERLAP_THRESH': 9.99,\r\n'FG_RATIO': 0.5,\r\n'HEAD_DIM': 1024,\r\n'MIN_SIZE': 0,\r\n'NEGATIVE_ANCHOR_THRESH': 0.3,\r\n'NUM_ANCHOR': 15,\r\n'POSITIVE_ANCHOR_THRESH': 0.7,\r\n'PROPOSAL_NMS_THRESH': 0.7,\r\n'TEST_PER_LEVEL_NMS_TOPK': 1000,\r\n'TEST_POST_NMS_TOPK': 1000,\r\n'TEST_PRE_NMS_TOPK': 6000,\r\n'TRAIN_PER_LEVEL_NMS_TOPK': 2000,\r\n'TRAIN_POST_NMS_TOPK': 2000,\r\n'TRAIN_PRE_NMS_TOPK': 12000},\r\n'TEST': {'FRCNN_NMS_THRESH': 0.5,\r\n'RESULTS_PER_IM': 100,\r\n'RESULT_SCORE_THRESH': 0.05,\r\n'RESULT_SCORE_THRESH_VIS': 0.3},\r\n'TRAIN': {'BASE_LR': 0.01,\r\n'DPP_SCORE_THRESH': 0.0,\r\n'EVAL_PERIOD': 25,\r\n'LABEL_LIM': 20,\r\n'LR_SCHEDULE': [30000],\r\n'NUM_GPUS': 1,\r\n'QUAL_TOPN': 10,\r\n'SIM_LR': 1,\r\n'STARTING_EPOCH': 1,\r\n'STEPS_PER_EPOCH': 500,\r\n'WARMUP': 1000,\r\n'WARMUP_INIT_LR': 0.0033000000000000004,\r\n'WEIGHT_DECAY': 0.0001},\r\n'TRAINER': 'replicated'}\r\n[0204 23:11:13 @train.py:573] Warm Up Schedule (steps, value): [(0, 0.0033000000000000004), (1000, 0.01)]\r\n[0204 23:11:13 @train.py:574] LR Schedule (epochs, value): [(2, 0.01)]\r\nloading annotations into memory...\r\nDone (t=9.42s)\r\ncreating index...\r\nindex created!\r\n[0204 23:11:24 @dataset.py:45] Instances loaded from /data1/coco/annotations/instances_train2014.json.\r\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 82783/82783 [00:18<00:00, 4515.45it/s]\r\n[0204 23:11:42 @timer.py:48] Load Groundtruth Boxes for train2014 finished, time:18.3824sec.\r\nloading annotations into memory...\r\nDone (t=8.37s)\r\ncreating index...\r\nindex created!\r\n[0204 23:11:51 @dataset.py:45] Instances loaded from /data1/coco/annotations/instances_valminusminival2014.json.\r\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 35504/35504 [00:08<00:00, 4344.10it/s]\r\n[0204 23:12:00 @timer.py:48] Load Groundtruth Boxes for valminusminival2014 finished, time:8.2563sec.\r\n[0204 23:12:09 @data.py:49] Ground-Truth Boxes:\r\n| class | #box |\r\n|:---------------|-------:|\r\n| BG | 0 |\r\n| person | 257221 |\r\n| bicycle | 7056 |\r\n| car | 43532 |\r\n| motorcycle | 8654 |\r\n| airplane | 5129 |\r\n| bus | 6061 |\r\n| train | 4570 |\r\n| truck | 9970 |\r\n| boat | 10575 |\r\n| traffic light | 12834 |\r\n| fire hydrant | 1865 |\r\n| stop sign | 1983 |\r\n| parking meter | 1283 |\r\n| bench | 9820 |\r\n| bird | 10512 |\r\n| cat | 4766 |\r\n| dog | 5500 |\r\n| horse | 6567 |\r\n| sheep | 9223 |\r\n| cow | 8014 |\r\n| elephant | 5484 |\r\n| bear | 1294 |\r\n| zebra | 5269 |\r\n| giraffe | 5128 |\r\n| backpack | 8713 |\r\n| umbrella | 11265 |\r\n| handbag | 12340 |\r\n| tie | 6445 |\r\n| suitcase | 6112 |\r\n| frisbee | 2681 |\r\n| skis | 6620 |\r\n| snowboard | 2679 |\r\n| sports ball | 6291 |\r\n| kite | 8792 |\r\n| baseball bat | 3273 |\r\n| baseball glove | 3742 |\r\n| skateboard | 5536 |\r\n| surfboard | 6093 |\r\n| tennis racket | 4803 |\r\n| bottle | 24070 |\r\n| wine glass | 7839 |\r\n| cup | 20574 |\r\n| fork | 5474 |\r\n| knife | 7759 |\r\n| spoon | 6159 |\r\n| bowl | 14323 |\r\n| banana | 9195 |\r\n| apple | 5776 |\r\n| sandwich | 4356 |\r\n| orange | 6302 |\r\n| broccoli | 7261 |\r\n| carrot | 7757 |\r\n| hot dog | 2883 |\r\n| pizza | 5807 |\r\n| donut | 7005 |\r\n| cake | 6296 |\r\n| chair | 38072 |\r\n| couch | 5779 |\r\n| potted plant | 8631 |\r\n| bed | 4192 |\r\n| dining table | 15695 |\r\n| toilet | 4149 |\r\n| tv | 5803 |\r\n| laptop | 4960 |\r\n| mouse | 2261 |\r\n| remote | 5699 |\r\n| keyboard | 2854 |\r\n| cell phone | 6405 |\r\n| microwave | 1672 |\r\n| oven | 3334 |\r\n| toaster | 225 |\r\n| sink | 5609 |\r\n| refrigerator | 2634 |\r\n| book | 24077 |\r\n| clock | 6319 |\r\n| vase | 6577 |\r\n| scissors | 1464 |\r\n| teddy bear | 4729 |\r\n| hair drier | 198 |\r\n| toothbrush | 1945 |\r\n| total | 849814 |\r\n[0204 23:12:09 @data.py:294] Filtered 1021 images which contain no non-crowd groudtruth boxes. Total #images for training: 117266\r\n[0204 23:12:09 @train.py:578] Total passes of the training set is: 2.0466\r\n[0204 23:12:11 @input_source.py:220] Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...\r\n[0204 23:12:11 @training.py:109] Building graph for training tower 0 on device /gpu:0 ...\r\n[0204 23:12:12 @registry.py:125] conv0 input: [None, 3, None, None]\r\n[0204 23:12:12 @batch_norm.py:164] WRN [BatchNorm] Using moving_mean/moving_variance in training.\r\n[0204 23:12:12 @registry.py:133] conv0 output: [None, 64, None, None]\r\n[0204 23:12:12 @registry.py:125] pool0 input: [None, 64, None, None]\r\n[0204 23:12:12 @registry.py:133] pool0 output: [None, 64, None, None]\r\n[0204 23:12:12 @registry.py:125] group0/block0/conv1 input: [None, 64, None, None]\r\n[0204 23:12:12 @batch_norm.py:164] WRN [BatchNorm] Using moving_mean/moving_variance in training.\r\n[0204 23:12:12 @registry.py:133] group0/block0/conv1 output: [None, 64, None, None]\r\n[0204 23:12:12 @registry.py:125] group0/block0/conv2 input: [None, 64, None, None]\r\n[0204 23:12:12 @batch_norm.py:164] WRN [BatchNorm] Using moving_mean/moving_variance in training.\r\n[0204 23:12:12 @registry.py:133] group0/block0/conv2 output: [None, 64, None, None]\r\n[0204 23:12:12 @registry.py:125] group0/block0/conv3 input: [None, 64, None, None]\r\n[0204 23:12:12 @batch_norm.py:164] WRN [BatchNorm] Using moving_mean/moving_variance in training.\r\n[0204 23:12:12 @registry.py:133] group0/block0/conv3 output: [None, 256, None, None]\r\n[0204 23:12:12 @registry.py:125] group0/block0/convshortcut input: [None, 64, None, None]\r\n[0204 23:12:12 @batch_norm.py:164] WRN [BatchNorm] Using moving_mean/moving_variance in training.\r\n[0204 23:12:12 @registry.py:133] group0/block0/convshortcut output: [None, 256, None, None]\r\n[0204 23:12:12 @registry.py:125] group0/block1/conv1 input: [None, 256, None, None]\r\n[0204 23:12:12 @batch_norm.py:164] WRN [BatchNorm] Using moving_mean/moving_variance in training.\r\n[0204 23:12:12 @registry.py:133] group0/block1/conv1 output: [None, 64, None, None]\r\n[0204 23:12:12 @registry.py:125] group0/block1/conv2 input: [None, 64, None, None]\r\n[0204 23:12:12 @batch_norm.py:164] WRN [BatchNorm] Using moving_mean/moving_variance in training.\r\n[0204 23:12:12 @registry.py:133] group0/block1/conv2 output: [None, 64, None, None]\r\n[0204 23:12:12 @registry.py:125] group0/block1/conv3 input: [None, 64, None, None]\r\n[0204 23:12:12 @batch_norm.py:164] WRN [BatchNorm] Using moving_mean/moving_variance in training.\r\n[0204 23:12:12 @registry.py:133] group0/block1/conv3 output: [None, 256, None, None]\r\n[0204 23:12:12 @registry.py:125] group0/block2/conv1 input: [None, 256, None, None]\r\n[0204 23:12:12 @batch_norm.py:164] WRN [BatchNorm] Using moving_mean/moving_variance in training.\r\n[0204 23:12:12 @registry.py:133] group0/block2/conv1 output: [None, 64, None, None]\r\n[0204 23:12:12 @registry.py:125] group0/block2/conv2 input: [None, 64, None, None]\r\n[0204 23:12:12 @batch_norm.py:164] WRN [BatchNorm] Using moving_mean/moving_variance in training.\r\n[0204 23:12:12 @registry.py:133] group0/block2/conv2 output: [None, 64, None, None]\r\n[0204 23:12:12 @registry.py:125] group0/block2/conv3 input: [None, 64, None, None]\r\n[0204 23:12:12 @batch_norm.py:164] WRN [BatchNorm] Using moving_mean/moving_variance in training.\r\n[0204 23:12:12 @registry.py:133] group0/block2/conv3 output: [None, 256, None, None]\r\n[0204 23:12:12 @registry.py:125] group1/block0/conv1 input: [None, 256, None, None]\r\n[0204 23:12:12 @batch_norm.py:164] WRN [BatchNorm] Using moving_mean/moving_variance in training.\r\n[0204 23:12:12 @registry.py:133] group1/block0/conv1 output: [None, 128, None, None]\r\n[0204 23:12:12 @registry.py:125] group1/block0/conv2 input: [None, 128, None, None]\r\n[0204 23:12:12 @batch_norm.py:164] WRN [BatchNorm] Using moving_mean/moving_variance in training.\r\n[0204 23:12:12 @registry.py:133] group1/block0/conv2 output: [None, 128, None, None]\r\n[0204 23:12:12 @registry.py:125] group1/block0/conv3 input: [None, 128, None, None]\r\n[0204 23:12:12 @batch_norm.py:164] WRN [BatchNorm] Using moving_mean/moving_variance in training.\r\n[0204 23:12:12 @registry.py:133] group1/block0/conv3 output: [None, 512, None, None]\r\n[0204 23:12:12 @registry.py:125] group1/block0/convshortcut input: [None, 256, None, None]\r\n[0204 23:12:12 @batch_norm.py:164] WRN [BatchNorm] Using moving_mean/moving_variance in training.\r\n[0204 23:12:12 @registry.py:133] group1/block0/convshortcut output: [None, 512, None, None]\r\n[0204 23:12:12 @registry.py:125] group1/block1/conv1 input: [None, 512, None, None]\r\n[0204 23:12:12 @batch_norm.py:164] WRN [BatchNorm] Using moving_mean/moving_variance in training.\r\n[0204 23:12:13 @registry.py:133] group1/block1/conv1 output: [None, 128, None, None]\r\n[0204 23:12:13 @registry.py:125] group1/block1/conv2 input: [None, 128, None, None]\r\n[0204 23:12:13 @batch_norm.py:164] WRN [BatchNorm] Using moving_mean/moving_variance in training.\r\n[0204 23:12:13 @registry.py:133] group1/block1/conv2 output: [None, 128, None, None]\r\n[0204 23:12:13 @registry.py:125] group1/block1/conv3 input: [None, 128, None, None]\r\n[0204 23:12:13 @batch_norm.py:164] WRN [BatchNorm] Using moving_mean/moving_variance in training.\r\n[0204 23:12:13 @registry.py:133] group1/block1/conv3 output: [None, 512, None, None]\r\n[0204 23:12:13 @registry.py:125] group1/block2/conv1 input: [None, 512, None, None]\r\n[0204 23:12:13 @batch_norm.py:164] WRN [BatchNorm] Using moving_mean/moving_variance in training.\r\n[0204 23:12:13 @registry.py:133] group1/block2/conv1 output: [None, 128, None, None]\r\n[0204 23:12:13 @registry.py:125] group1/block2/conv2 input: [None, 128, None, None]\r\n[0204 23:12:13 @batch_norm.py:164] WRN [BatchNorm] Using moving_mean/moving_variance in training.\r\n[0204 23:12:13 @registry.py:133] group1/block2/conv2 output: [None, 128, None, None]\r\n[0204 23:12:13 @registry.py:125] group1/block2/conv3 input: [None, 128, None, None]\r\n[0204 23:12:13 @batch_norm.py:164] WRN [BatchNorm] Using moving_mean/moving_variance in training.\r\n[0204 23:12:13 @registry.py:133] group1/block2/conv3 output: [None, 512, None, None]\r\n[0204 23:12:13 @registry.py:125] group1/block3/conv1 input: [None, 512, None, None]\r\n[0204 23:12:13 @batch_norm.py:164] WRN [BatchNorm] Using moving_mean/moving_variance in training.\r\n[0204 23:12:13 @registry.py:133] group1/block3/conv1 output: [None, 128, None, None]\r\n[0204 23:12:13 @registry.py:125] group1/block3/conv2 input: [None, 128, None, None]\r\n[0204 23:12:13 @batch_norm.py:164] WRN [BatchNorm] Using moving_mean/moving_variance in training.\r\n[0204 23:12:13 @registry.py:133] group1/block3/conv2 output: [None, 128, None, None]\r\n[0204 23:12:13 @registry.py:125] group1/block3/conv3 input: [None, 128, None, None]\r\n[0204 23:12:13 @batch_norm.py:164] WRN [BatchNorm] Using moving_mean/moving_variance in training.\r\n[0204 23:12:13 @registry.py:133] group1/block3/conv3 output: [None, 512, None, None]\r\n[0204 23:12:13 @registry.py:125] group2/block0/conv1 input: [None, 512, None, None]\r\n[0204 23:12:13 @batch_norm.py:164] WRN [BatchNorm] Using moving_mean/moving_variance in training.\r\n[0204 23:12:13 @registry.py:133] group2/block0/conv1 output: [None, 256, None, None]\r\n[0204 23:12:13 @registry.py:125] group2/block0/conv2 input: [None, 256, None, None]\r\n[0204 23:12:13 @batch_norm.py:164] WRN [BatchNorm] Using moving_mean/moving_variance in training.\r\n[0204 23:12:13 @registry.py:133] group2/block0/conv2 output: [None, 256, None, None]\r\n[0204 23:12:13 @registry.py:125] group2/block0/conv3 input: [None, 256, None, None]\r\n[0204 23:12:13 @batch_norm.py:164] WRN [BatchNorm] Using moving_mean/moving_variance in training.\r\n[0204 23:12:13 @registry.py:133] group2/block0/conv3 output: [None, 1024, None, None]\r\n[0204 23:12:13 @registry.py:125] group2/block0/convshortcut input: [None, 512, None, None]\r\n[0204 23:12:13 @batch_norm.py:164] WRN [BatchNorm] Using moving_mean/moving_variance in training.\r\n[0204 23:12:13 @registry.py:133] group2/block0/convshortcut output: [None, 1024, None, None]\r\n[0204 23:12:13 @registry.py:125] group2/block1/conv1 input: [None, 1024, None, None]\r\n[0204 23:12:13 @batch_norm.py:164] WRN [BatchNorm] Using moving_mean/moving_variance in training.\r\n[0204 23:12:13 @registry.py:133] group2/block1/conv1 output: [None, 256, None, None]\r\n[0204 23:12:13 @registry.py:125] group2/block1/conv2 input: [None, 256, None, None]\r\n[0204 23:12:13 @batch_norm.py:164] WRN [BatchNorm] Using moving_mean/moving_variance in training.\r\n[0204 23:12:13 @registry.py:133] group2/block1/conv2 output: [None, 256, None, None]\r\n[0204 23:12:13 @registry.py:125] group2/block1/conv3 input: [None, 256, None, None]\r\n[0204 23:12:13 @batch_norm.py:164] WRN [BatchNorm] Using moving_mean/moving_variance in training.\r\n[0204 23:12:13 @registry.py:133] group2/block1/conv3 output: [None, 1024, None, None]\r\n[0204 23:12:13 @registry.py:125] group2/block2/conv1 input: [None, 1024, None, None]\r\n[0204 23:12:13 @batch_norm.py:164] WRN [BatchNorm] Using moving_mean/moving_variance in training.\r\n[0204 23:12:13 @registry.py:133] group2/block2/conv1 output: [None, 256, None, None]\r\n[0204 23:12:13 @registry.py:125] group2/block2/conv2 input: [None, 256, None, None]\r\n[0204 23:12:13 @batch_norm.py:164] WRN [BatchNorm] Using moving_mean/moving_variance in training.\r\n[0204 23:12:13 @registry.py:133] group2/block2/conv2 output: [None, 256, None, None]\r\n[0204 23:12:13 @registry.py:125] group2/block2/conv3 input: [None, 256, None, None]\r\n[0204 23:12:13 @batch_norm.py:164] WRN [BatchNorm] Using moving_mean/moving_variance in training.\r\n[0204 23:12:13 @registry.py:133] group2/block2/conv3 output: [None, 1024, None, None]\r\n[0204 23:12:13 @registry.py:125] group2/block3/conv1 input: [None, 1024, None, None]\r\n[0204 23:12:13 @batch_norm.py:164] WRN [BatchNorm] Using moving_mean/moving_variance in training.\r\n[0204 23:12:13 @registry.py:133] group2/block3/conv1 output: [None, 256, None, None]\r\n[0204 23:12:13 @registry.py:125] group2/block3/conv2 input: [None, 256, None, None]\r\n[0204 23:12:13 @batch_norm.py:164] WRN [BatchNorm] Using moving_mean/moving_variance in training.\r\n[0204 23:12:13 @registry.py:133] group2/block3/conv2 output: [None, 256, None, None]\r\n[0204 23:12:13 @registry.py:125] group2/block3/conv3 input: [None, 256, None, None]\r\n[0204 23:12:13 @batch_norm.py:164] WRN [BatchNorm] Using moving_mean/moving_variance in training.\r\n[0204 23:12:13 @registry.py:133] group2/block3/conv3 output: [None, 1024, None, None]\r\n[0204 23:12:13 @registry.py:125] group2/block4/conv1 input: [None, 1024, None, None]\r\n[0204 23:12:13 @batch_norm.py:164] WRN [BatchNorm] Using moving_mean/moving_variance in training.\r\n[0204 23:12:13 @registry.py:133] group2/block4/conv1 output: [None, 256, None, None]\r\n[0204 23:12:13 @registry.py:125] group2/block4/conv2 input: [None, 256, None, None]\r\n[0204 23:12:13 @batch_norm.py:164] WRN [BatchNorm] Using moving_mean/moving_variance in training.\r\n[0204 23:12:13 @registry.py:133] group2/block4/conv2 output: [None, 256, None, None]\r\n[0204 23:12:13 @registry.py:125] group2/block4/conv3 input: [None, 256, None, None]\r\n[0204 23:12:13 @batch_norm.py:164] WRN [BatchNorm] Using moving_mean/moving_variance in training.\r\n[0204 23:12:13 @registry.py:133] group2/block4/conv3 output: [None, 1024, None, None]\r\n[0204 23:12:13 @registry.py:125] group2/block5/conv1 input: [None, 1024, None, None]\r\n[0204 23:12:13 @batch_norm.py:164] WRN [BatchNorm] Using moving_mean/moving_variance in training.\r\n[0204 23:12:14 @registry.py:133] group2/block5/conv1 output: [None, 256, None, None]\r\n[0204 23:12:14 @registry.py:125] group2/block5/conv2 input: [None, 256, None, None]\r\n[0204 23:12:14 @batch_norm.py:164] WRN [BatchNorm] Using moving_mean/moving_variance in training.\r\n[0204 23:12:14 @registry.py:133] group2/block5/conv2 output: [None, 256, None, None]\r\n[0204 23:12:14 @registry.py:125] group2/block5/conv3 input: [None, 256, None, None]\r\n[0204 23:12:14 @batch_norm.py:164] WRN [BatchNorm] Using moving_mean/moving_variance in training.\r\n[0204 23:12:14 @registry.py:133] group2/block5/conv3 output: [None, 1024, None, None]\r\n[0204 23:12:14 @registry.py:125] group3/block0/conv1 input: [None, 1024, None, None]\r\n[0204 23:12:14 @batch_norm.py:164] WRN [BatchNorm] Using moving_mean/moving_variance in training.\r\n[0204 23:12:14 @registry.py:133] group3/block0/conv1 output: [None, 512, None, None]\r\n[0204 23:12:14 @registry.py:125] group3/block0/conv2 input: [None, 512, None, None]\r\n[0204 23:12:14 @batch_norm.py:164] WRN [BatchNorm] Using moving_mean/moving_variance in training.\r\n[0204 23:12:14 @registry.py:133] group3/block0/conv2 output: [None, 512, None, None]\r\n[0204 23:12:14 @registry.py:125] group3/block0/conv3 input: [None, 512, None, None]\r\n[0204 23:12:14 @batch_norm.py:164] WRN [BatchNorm] Using moving_mean/moving_variance in training.\r\n[0204 23:12:14 @registry.py:133] group3/block0/conv3 output: [None, 2048, None, None]\r\n[0204 23:12:14 @registry.py:125] group3/block0/convshortcut input: [None, 1024, None, None]\r\n[0204 23:12:14 @batch_norm.py:164] WRN [BatchNorm] Using moving_mean/moving_variance in training.\r\n[0204 23:12:14 @registry.py:133] group3/block0/convshortcut output: [None, 2048, None, None]\r\n[0204 23:12:14 @registry.py:125] group3/block1/conv1 input: [None, 2048, None, None]\r\n[0204 23:12:14 @batch_norm.py:164] WRN [BatchNorm] Using moving_mean/moving_variance in training.\r\n[0204 23:12:14 @registry.py:133] group3/block1/conv1 output: [None, 512, None, None]\r\n[0204 23:12:14 @registry.py:125] group3/block1/conv2 input: [None, 512, None, None]\r\n[0204 23:12:14 @batch_norm.py:164] WRN [BatchNorm] Using moving_mean/moving_variance in training.\r\n[0204 23:12:14 @registry.py:133] group3/block1/conv2 output: [None, 512, None, None]\r\n[0204 23:12:14 @registry.py:125] group3/block1/conv3 input: [None, 512, None, None]\r\n[0204 23:12:14 @batch_norm.py:164] WRN [BatchNorm] Using moving_mean/moving_variance in training.\r\n[0204 23:12:14 @registry.py:133] group3/block1/conv3 output: [None, 2048, None, None]\r\n[0204 23:12:14 @registry.py:125] group3/block2/conv1 input: [None, 2048, None, None]\r\n[0204 23:12:14 @batch_norm.py:164] WRN [BatchNorm] Using moving_mean/moving_variance in training.\r\n[0204 23:12:14 @registry.py:133] group3/block2/conv1 output: [None, 512, None, None]\r\n[0204 23:12:14 @registry.py:125] group3/block2/conv2 input: [None, 512, None, None]\r\n[0204 23:12:14 @batch_norm.py:164] WRN [BatchNorm] Using moving_mean/moving_variance in training.\r\n[0204 23:12:14 @registry.py:133] group3/block2/conv2 output: [None, 512, None, None]\r\n[0204 23:12:14 @registry.py:125] group3/block2/conv3 input: [None, 512, None, None]\r\n[0204 23:12:14 @batch_norm.py:164] WRN [BatchNorm] Using moving_mean/moving_variance in training.\r\n[0204 23:12:14 @registry.py:133] group3/block2/conv3 output: [None, 2048, None, None]\r\n[0204 23:12:14 @registry.py:125] fpn input: [None, 256, None, None],[None, 512, None, None],[None, 1024, None, None],[None, 2048, None, None]\r\n[0204 23:12:14 @registry.py:125] fpn/lateral_1x1_c2 input: [None, 256, None, None]\r\n[0204 23:12:14 @registry.py:133] fpn/lateral_1x1_c2 output: [None, 256, None, None]\r\n[0204 23:12:14 @registry.py:125] fpn/lateral_1x1_c3 input: [None, 512, None, None]\r\n[0204 23:12:14 @registry.py:133] fpn/lateral_1x1_c3 output: [None, 256, None, None]\r\n[0204 23:12:14 @registry.py:125] fpn/lateral_1x1_c4 input: [None, 1024, None, None]\r\n[0204 23:12:14 @registry.py:133] fpn/lateral_1x1_c4 output: [None, 256, None, None]\r\n[0204 23:12:14 @registry.py:125] fpn/lateral_1x1_c5 input: [None, 2048, None, None]\r\n[0204 23:12:14 @registry.py:133] fpn/lateral_1x1_c5 output: [None, 256, None, None]\r\n[0204 23:12:14 @registry.py:125] fpn/upsample_lat5 input: [None, 256, None, None]\r\n[0204 23:12:14 @registry.py:133] fpn/upsample_lat5 output: [None, 256, None, None]\r\n[0204 23:12:14 @registry.py:125] fpn/upsample_lat4 input: [None, 256, None, None]\r\n[0204 23:12:14 @registry.py:133] fpn/upsample_lat4 output: [None, 256, None, None]\r\n[0204 23:12:14 @registry.py:125] fpn/upsample_lat3 input: [None, 256, None, None]\r\n[0204 23:12:14 @registry.py:133] fpn/upsample_lat3 output: [None, 256, None, None]\r\n[0204 23:12:14 @registry.py:125] fpn/posthoc_3x3_p2 input: [None, 256, None, None]\r\n[0204 23:12:14 @registry.py:133] fpn/posthoc_3x3_p2 output: [None, 256, None, None]\r\n[0204 23:12:14 @registry.py:125] fpn/posthoc_3x3_p3 input: [None, 256, None, None]\r\n[0204 23:12:14 @registry.py:133] fpn/posthoc_3x3_p3 output: [None, 256, None, None]\r\n[0204 23:12:14 @registry.py:125] fpn/posthoc_3x3_p4 input: [None, 256, None, None]\r\n[0204 23:12:14 @registry.py:133] fpn/posthoc_3x3_p4 output: [None, 256, None, None]\r\n[0204 23:12:14 @registry.py:125] fpn/posthoc_3x3_p5 input: [None, 256, None, None]\r\n[0204 23:12:14 @registry.py:133] fpn/posthoc_3x3_p5 output: [None, 256, None, None]\r\n[0204 23:12:14 @registry.py:125] fpn/maxpool_p6 input: [None, 256, None, None]\r\n[0204 23:12:14 @registry.py:133] fpn/maxpool_p6 output: [None, 256, None, None]\r\n[0204 23:12:14 @registry.py:133] fpn output: [None, 256, None, None],[None, 256, None, None],[None, 256, None, None],[None, 256, None, None],[None, 256, None, None]\r\n[0204 23:12:14 @registry.py:125] rpn input: [None, 256, None, None]\r\n[0204 23:12:14 @registry.py:125] rpn/conv0 input: [None, 256, None, None]\r\n[0204 23:12:14 @registry.py:133] rpn/conv0 output: [None, 256, None, None]\r\n[0204 23:12:14 @registry.py:125] rpn/class input: [None, 256, None, None]\r\n[0204 23:12:14 @registry.py:133] rpn/class output: [None, 3, None, None]\r\n[0204 23:12:14 @registry.py:125] rpn/box input: [None, 256, None, None]\r\n[0204 23:12:14 @registry.py:133] rpn/box output: [None, 12, None, None]\r\n[0204 23:12:14 @registry.py:133] rpn output: [None, None, 3],[None, None, 3, 4]\r\n[0204 23:12:18 @registry.py:125] fastrcnn input: [None, 256, 7, 7]\r\n[0204 23:12:18 @registry.py:125] fastrcnn/fc6 input: [None, 256, 7, 7]\r\n[0204 23:12:18 @registry.py:133] fastrcnn/fc6 output: [None, 1024]\r\n[0204 23:12:18 @registry.py:125] fastrcnn/fc7 input: [None, 1024]\r\n[0204 23:12:18 @registry.py:133] fastrcnn/fc7 output: [None, 1024]\r\n[0204 23:12:18 @registry.py:133] fastrcnn output: [None, 1024]\r\n[0204 23:12:18 @registry.py:125] fastrcnn/outputs input: [None, 1024]\r\n[0204 23:12:18 @registry.py:125] fastrcnn/outputs/class input: [None, 1024]\r\n[0204 23:12:18 @registry.py:133] fastrcnn/outputs/class output: [None, 81]\r\n[0204 23:12:18 @registry.py:125] fastrcnn/outputs/box input: [None, 1024]\r\n[0204 23:12:18 @registry.py:133] fastrcnn/outputs/box output: [None, 324]\r\n[0204 23:12:18 @registry.py:133] fastrcnn/outputs output: [None, 81],[None, 81, 4]\r\n[0204 23:12:19 @registry.py:125] maskrcnn input: [None, 256, 14, 14]\r\n[0204 23:12:19 @registry.py:125] maskrcnn/fcn0 input: [None, 256, 14, 14]\r\n[0204 23:12:19 @registry.py:133] maskrcnn/fcn0 output: [None, 256, 14, 14]\r\n[0204 23:12:19 @registry.py:125] maskrcnn/fcn1 input: [None, 256, 14, 14]\r\n[0204 23:12:19 @registry.py:133] maskrcnn/fcn1 output: [None, 256, 14, 14]\r\n[0204 23:12:19 @registry.py:125] maskrcnn/fcn2 input: [None, 256, 14, 14]\r\n[0204 23:12:19 @registry.py:133] maskrcnn/fcn2 output: [None, 256, 14, 14]\r\n[0204 23:12:19 @registry.py:125] maskrcnn/fcn3 input: [None, 256, 14, 14]\r\n[0204 23:12:19 @registry.py:133] maskrcnn/fcn3 output: [None, 256, 14, 14]\r\n[0204 23:12:19 @registry.py:125] maskrcnn/deconv input: [None, 256, 14, 14]\r\n[0204 23:12:19 @registry.py:133] maskrcnn/deconv output: [None, 256, 28, 28]\r\n[0204 23:12:19 @registry.py:125] maskrcnn/conv input: [None, 256, 28, 28]\r\n[0204 23:12:19 @registry.py:133] maskrcnn/conv output: [None, 80, 28, 28]\r\n[0204 23:12:19 @registry.py:133] maskrcnn output: [None, 80, 28, 28]\r\n[0204 23:12:19 @registry.py:125] idn/idn input: [None, 256, None, None]\r\n[0204 23:12:19 @registry.py:125] idn/idn/conv0 input: [None, 256, None, None]\r\n[0204 23:12:19 @registry.py:133] idn/idn/conv0 output: [None, 128, None, None]\r\n[0204 23:12:19 @batch_norm.py:164] WRN [BatchNorm] Using moving_mean/moving_variance in training.\r\n[0204 23:12:19 @registry.py:125] idn/idn/conv1 input: [None, 128, None, None]\r\n[0204 23:12:19 @registry.py:133] idn/idn/conv1 output: [None, 128, None, None]\r\n[0204 23:12:19 @batch_norm.py:164] WRN [BatchNorm] Using moving_mean/moving_variance in training.\r\n[0204 23:12:19 @registry.py:125] idn/idn/conv2 input: [None, 128, None, None]\r\n[0204 23:12:19 @registry.py:133] idn/idn/conv2 output: [None, 256, None, None]\r\n[0204 23:12:19 @batch_norm.py:164] WRN [BatchNorm] Using moving_mean/moving_variance in training.\r\n[0204 23:12:19 @registry.py:125] idn/idn/conv3 input: [None, 256, None, None]\r\n[0204 23:12:19 @registry.py:133] idn/idn/conv3 output: [None, 256, None, None]\r\n[0204 23:12:19 @batch_norm.py:164] WRN [BatchNorm] Using moving_mean/moving_variance in training.\r\n[0204 23:12:19 @registry.py:125] idn/idn/pool0 input: [None, 256, None, None]\r\n[0204 23:12:19 @registry.py:133] idn/idn/pool0 output: [None, 256, None, None]\r\n[0204 23:12:19 @registry.py:125] idn/idn/conv4 input: [None, 256, None, None]\r\n[0204 23:12:19 @registry.py:133] idn/idn/conv4 output: [None, 256, None, None]\r\n[0204 23:12:19 @batch_norm.py:164] WRN [BatchNorm] Using moving_mean/moving_variance in training.\r\n[0204 23:12:19 @registry.py:125] idn/idn/conv5 input: [None, 256, None, None]\r\n[0204 23:12:19 @registry.py:133] idn/idn/conv5 output: [None, 256, None, None]\r\n[0204 23:12:19 @batch_norm.py:164] WRN [BatchNorm] Using moving_mean/moving_variance in training.\r\n[0204 23:12:19 @registry.py:125] idn/idn/conv6 input: [None, 256, None, None]\r\n[0204 23:12:19 @registry.py:133] idn/idn/conv6 output: [None, 256, None, None]\r\n[0204 23:12:19 @batch_norm.py:164] WRN [BatchNorm] Using moving_mean/moving_variance in training.\r\n[0204 23:12:20 @registry.py:125] idn/idn/fc1 input: [None, 256, 15, 15]\r\n[0204 23:12:20 @registry.py:133] idn/idn/fc1 output: [None, 1000]\r\n[0204 23:12:20 @batch_norm.py:164] WRN [BatchNorm] Using moving_mean/moving_variance in training.\r\n[0204 23:12:20 @registry.py:125] idn/idn/fc2 input: [None, 1000]\r\n[0204 23:12:20 @registry.py:133] idn/idn/fc2 output: [None, 1000]\r\n[0204 23:12:20 @batch_norm.py:164] WRN [BatchNorm] Using moving_mean/moving_variance in training.\r\n[0204 23:12:20 @registry.py:125] idn/idn/idn_feat input: [None, 1000]\r\n[0204 23:12:20 @registry.py:133] idn/idn/idn_feat output: [None, 256]\r\n[0204 23:12:20 @registry.py:133] idn/idn output: [None, 256]\r\n[0204 23:12:20 @regularize.py:95] regularize_cost() found 10 variables to regularize.\r\n[0204 23:12:20 @regularize.py:20] The following tensors will be regularized: idn/idn/conv0/W:0, idn/idn/conv1/W:0, idn/idn/conv2/W:0, idn/idn/conv3/W:0, idn/idn/conv4/W:0, idn/idn/conv5/W:0, idn/idn/conv6/W:0, idn/idn/fc1/W:0, idn/idn/fc2/W:0, idn/idn/idn_feat/W:0\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/Prod_3_grad/Rank with an op tower0/cond/Prod_3 that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/Prod_3_grad/add_1 with an op tower0/cond/Prod_3 that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/Prod_3_grad/mod_1 with an op tower0/cond/Prod_3 that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/Prod_3_grad/range_1/start with an op tower0/cond/Prod_3 that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/Prod_3_grad/range_1/delta with an op tower0/cond/Prod_3 that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/Prod_3_grad/range_1 with an op tower0/cond/Prod_3 that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/Prod_3_grad/ListDiff with an op tower0/cond/Prod_3 that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/Prod_3_grad/concat/axis with an op tower0/cond/Prod_3 that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/Prod_3_grad/concat with an op tower0/cond/Prod_3 that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/Prod_3_grad/GatherV2/axis with an op tower0/cond/Prod_3 that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/Prod_3_grad/GatherV2 with an op tower0/cond/Prod_3 that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/Prod_3_grad/Const with an op tower0/cond/Prod_3 that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/Prod_3_grad/Prod with an op tower0/cond/Prod_3 that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/Prod_3_grad/GatherV2_1/axis with an op tower0/cond/Prod_3 that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/Prod_3_grad/GatherV2_1 with an op tower0/cond/Prod_3 that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/Prod_3_grad/Const_1 with an op tower0/cond/Prod_3 that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/Prod_3_grad/Prod_1 with an op tower0/cond/Prod_3 that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py\ud83d\udcaf UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\r\n\"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/while_2/Prod_grad/Rank with an op tower0/cond/while_2/Prod that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/while_2/Prod_grad/add_1 with an op tower0/cond/while_2/Prod that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/while_2/Prod_grad/mod_1 with an op tower0/cond/while_2/Prod that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/while_2/Prod_grad/range_1/start with an op tower0/cond/while_2/Prod that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/while_2/Prod_grad/range_1/delta with an op tower0/cond/while_2/Prod that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/while_2/Prod_grad/range_1 with an op tower0/cond/while_2/Prod that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/while_2/Prod_grad/ListDiff with an op tower0/cond/while_2/Prod that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/while_2/Prod_grad/concat/axis with an op tower0/cond/while_2/Prod that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/while_2/Prod_grad/concat with an op tower0/cond/while_2/Prod that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/while_2/Prod_grad/GatherV2/axis with an op tower0/cond/while_2/Prod that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/while_2/Prod_grad/GatherV2 with an op tower0/cond/while_2/Prod that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/while_2/Prod_grad/Const with an op tower0/cond/while_2/Prod that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/while_2/Prod_grad/Prod with an op tower0/cond/while_2/Prod that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/while_2/Prod_grad/GatherV2_1/axis with an op tower0/cond/while_2/Prod that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/while_2/Prod_grad/GatherV2_1 with an op tower0/cond/while_2/Prod that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/while_2/Prod_grad/Const_1 with an op tower0/cond/while_2/Prod that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/while_2/Prod_grad/Prod_1 with an op tower0/cond/while_2/Prod that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/Prod_1_grad/Rank with an op tower0/cond/Prod_1 that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/Prod_1_grad/add_1 with an op tower0/cond/Prod_1 that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/Prod_1_grad/mod_1 with an op tower0/cond/Prod_1 that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/Prod_1_grad/range_1/start with an op tower0/cond/Prod_1 that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/Prod_1_grad/range_1/delta with an op tower0/cond/Prod_1 that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/Prod_1_grad/range_1 with an op tower0/cond/Prod_1 that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/Prod_1_grad/ListDiff with an op tower0/cond/Prod_1 that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/Prod_1_grad/concat/axis with an op tower0/cond/Prod_1 that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/Prod_1_grad/concat with an op tower0/cond/Prod_1 that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/Prod_1_grad/GatherV2/axis with an op tower0/cond/Prod_1 that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/Prod_1_grad/GatherV2 with an op tower0/cond/Prod_1 that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/Prod_1_grad/Const with an op tower0/cond/Prod_1 that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/Prod_1_grad/Prod with an op tower0/cond/Prod_1 that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/Prod_1_grad/GatherV2_1/axis with an op tower0/cond/Prod_1 that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/Prod_1_grad/GatherV2_1 with an op tower0/cond/Prod_1 that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/Prod_1_grad/Const_1 with an op tower0/cond/Prod_1 that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/Prod_1_grad/Prod_1 with an op tower0/cond/Prod_1 that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/Prod_grad/Rank with an op tower0/cond/Prod that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/Prod_grad/add_1 with an op tower0/cond/Prod that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/Prod_grad/mod_1 with an op tower0/cond/Prod that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/Prod_grad/range_1/start with an op tower0/cond/Prod that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/Prod_grad/range_1/delta with an op tower0/cond/Prod that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/Prod_grad/range_1 with an op tower0/cond/Prod that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/Prod_grad/ListDiff with an op tower0/cond/Prod that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/Prod_grad/concat/axis with an op tower0/cond/Prod that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/Prod_grad/concat with an op tower0/cond/Prod that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/Prod_grad/GatherV2/axis with an op tower0/cond/Prod that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/Prod_grad/GatherV2 with an op tower0/cond/Prod that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/Prod_grad/Const with an op tower0/cond/Prod that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/Prod_grad/Prod with an op tower0/cond/Prod that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/Prod_grad/GatherV2_1/axis with an op tower0/cond/Prod that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/Prod_grad/GatherV2_1 with an op tower0/cond/Prod that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/Prod_grad/Const_1 with an op tower0/cond/Prod that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/Prod_grad/Prod_1 with an op tower0/cond/Prod that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/Prod_2_grad/Rank with an op tower0/cond/Prod_2 that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/Prod_2_grad/add_1 with an op tower0/cond/Prod_2 that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/Prod_2_grad/mod_1 with an op tower0/cond/Prod_2 that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/Prod_2_grad/range_1/start with an op tower0/cond/Prod_2 that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/Prod_2_grad/range_1/delta with an op tower0/cond/Prod_2 that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/Prod_2_grad/range_1 with an op tower0/cond/Prod_2 that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/Prod_2_grad/ListDiff with an op tower0/cond/Prod_2 that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/Prod_2_grad/concat/axis with an op tower0/cond/Prod_2 that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/Prod_2_grad/concat with an op tower0/cond/Prod_2 that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/Prod_2_grad/GatherV2/axis with an op tower0/cond/Prod_2 that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/Prod_2_grad/GatherV2 with an op tower0/cond/Prod_2 that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/Prod_2_grad/Const with an op tower0/cond/Prod_2 that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/Prod_2_grad/Prod with an op tower0/cond/Prod_2 that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/Prod_2_grad/GatherV2_1/axis with an op tower0/cond/Prod_2 that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/Prod_2_grad/GatherV2_1 with an op tower0/cond/Prod_2 that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/Prod_2_grad/Const_1 with an op tower0/cond/Prod_2 that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/Prod_2_grad/Prod_1 with an op tower0/cond/Prod_2 that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/while/Prod_grad/Rank with an op tower0/cond/while/Prod that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/while/Prod_grad/add_1 with an op tower0/cond/while/Prod that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/while/Prod_grad/mod_1 with an op tower0/cond/while/Prod that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/while/Prod_grad/range_1/start with an op tower0/cond/while/Prod that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/while/Prod_grad/range_1/delta with an op tower0/cond/while/Prod that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/while/Prod_grad/range_1 with an op tower0/cond/while/Prod that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/while/Prod_grad/ListDiff with an op tower0/cond/while/Prod that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/while/Prod_grad/concat/axis with an op tower0/cond/while/Prod that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/while/Prod_grad/concat with an op tower0/cond/while/Prod that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/while/Prod_grad/GatherV2/axis with an op tower0/cond/while/Prod that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/while/Prod_grad/GatherV2 with an op tower0/cond/while/Prod that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/while/Prod_grad/Const with an op tower0/cond/while/Prod that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/while/Prod_grad/Prod with an op tower0/cond/while/Prod that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/while/Prod_grad/GatherV2_1/axis with an op tower0/cond/while/Prod that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/while/Prod_grad/GatherV2_1 with an op tower0/cond/while/Prod that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/while/Prod_grad/Const_1 with an op tower0/cond/while/Prod that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/while/Prod_grad/Prod_1 with an op tower0/cond/while/Prod that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/while_1/cond/Prod_grad/Rank with an op tower0/cond/while_1/cond/Prod that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/while_1/cond/Prod_grad/add_1 with an op tower0/cond/while_1/cond/Prod that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/while_1/cond/Prod_grad/mod_1 with an op tower0/cond/while_1/cond/Prod that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/while_1/cond/Prod_grad/range_1/start with an op tower0/cond/while_1/cond/Prod that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/while_1/cond/Prod_grad/range_1/delta with an op tower0/cond/while_1/cond/Prod that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/while_1/cond/Prod_grad/range_1 with an op tower0/cond/while_1/cond/Prod that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/while_1/cond/Prod_grad/ListDiff with an op tower0/cond/while_1/cond/Prod that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/while_1/cond/Prod_grad/concat/axis with an op tower0/cond/while_1/cond/Prod that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/while_1/cond/Prod_grad/concat with an op tower0/cond/while_1/cond/Prod that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/while_1/cond/Prod_grad/GatherV2/axis with an op tower0/cond/while_1/cond/Prod that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/while_1/cond/Prod_grad/GatherV2 with an op tower0/cond/while_1/cond/Prod that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/while_1/cond/Prod_grad/Const with an op tower0/cond/while_1/cond/Prod that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/while_1/cond/Prod_grad/Prod with an op tower0/cond/while_1/cond/Prod that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/while_1/cond/Prod_grad/GatherV2_1/axis with an op tower0/cond/while_1/cond/Prod that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/while_1/cond/Prod_grad/GatherV2_1 with an op tower0/cond/while_1/cond/Prod that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/while_1/cond/Prod_grad/Const_1 with an op tower0/cond/while_1/cond/Prod that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\nWARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/while_1/cond/Prod_grad/Prod_1 with an op tower0/cond/while_1/cond/Prod that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\r\n[0204 23:12:23 @training.py:347] 'sync_variables_from_main_tower' includes 0 operations.\r\n[0204 23:12:23 @model_utils.py:64] Trainable Variables:\r\nname shape dim\r\n\r\nidn/idn/conv0/W:0 [3, 3, 256, 128] 294912\r\nidn/idn/bn0/gamma:0 [128] 128\r\nidn/idn/bn0/beta:0 [128] 128\r\nidn/idn/conv1/W:0 [3, 3, 128, 128] 147456\r\nidn/idn/bn1/gamma:0 [128] 128\r\nidn/idn/bn1/beta:0 [128] 128\r\nidn/idn/conv2/W:0 [3, 3, 128, 256] 294912\r\nidn/idn/bn2/gamma:0 [256] 256\r\nidn/idn/bn2/beta:0 [256] 256\r\nidn/idn/conv3/W:0 [3, 3, 256, 256] 589824\r\nidn/idn/bn3/gamma:0 [256] 256\r\nidn/idn/bn3/beta:0 [256] 256\r\nidn/idn/conv4/W:0 [3, 3, 256, 256] 589824\r\nidn/idn/bn4/gamma:0 [256] 256\r\nidn/idn/bn4/beta:0 [256] 256\r\nidn/idn/conv5/W:0 [3, 3, 256, 256] 589824\r\nidn/idn/bn5/gamma:0 [256] 256\r\nidn/idn/bn5/beta:0 [256] 256\r\nidn/idn/conv6/W:0 [3, 3, 256, 256] 589824\r\nidn/idn/bn6/gamma:0 [256] 256\r\nidn/idn/bn6/beta:0 [256] 256\r\nidn/idn/fc1/W:0 [57600, 1000] 57600000\r\nidn/idn/fc1/b:0 [1000] 1000\r\nidn/idn/bn7/gamma:0 [1000] 1000\r\nidn/idn/bn7/beta:0 [1000] 1000\r\nidn/idn/fc2/W:0 [1000, 1000] 1000000\r\nidn/idn/fc2/b:0 [1000] 1000\r\nidn/idn/bn8/gamma:0 [1000] 1000\r\nidn/idn/bn8/beta:0 [1000] 1000\r\nidn/idn/idn_feat/W:0 [1000, 256] 256000\r\nidn/idn/idn_feat/b:0 [256] 256\r\nTotal #vars=31, #params=61961904, size=236.37MB\r\n[0204 23:12:23 @base.py:208] Setup callbacks graph ...\r\n[0204 23:12:23 @argtools.py:146] WRN \"import prctl\" failed! Install python-prctl so that processes can be cleaned with guarantee.\r\n[0204 23:12:24 @tower.py:130] Building graph for predict tower 'tower-pred-0' on device /gpu:0 ...\r\n[0204 23:12:30 @collection.py:151] Size of these collections were changed in tower-pred-0: (tf.GraphKeys.MODEL_VARIABLES: 561->892)\r\nloading annotations into memory...\r\nDone (t=0.51s)\r\ncreating index...\r\nindex created!\r\n[0204 23:12:30 @dataset.py:45] Instances loaded from /data1/coco/annotations/instances_minival2014.json.\r\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5000/5000 [00:00<00:00, 250918.53it/s]\r\n[0204 23:12:30 @timer.py:48] Load Groundtruth Boxes for minival2014 finished, time:0.0225sec.\r\nloading annotations into memory...\r\nDone (t=0.47s)\r\ncreating index...\r\nindex created!\r\n[0204 23:12:31 @dataset.py:45] Instances loaded from /data1/coco/annotations/instances_minival2014.json.\r\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5000/5000 [00:00<00:00, 174367.43it/s]\r\n[0204 23:12:31 @timer.py:48] Load Groundtruth Boxes for minival2014 finished, time:0.0315sec.\r\n[0204 23:12:31 @summary.py:46] [MovingAverageSummary] 75 operations in collection 'MOVING_SUMMARY_OPS' will be run with session hooks.\r\n[0204 23:12:31 @summary.py:93] Summarizing collection 'summaries' of size 78.\r\n[0204 23:12:35 @base.py:229] Creating the session ...\r\n2019-02-04 23:12:35.297084: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties:\r\nname: TITAN X (Pascal) major: 6 minor: 1 memoryClockRate(GHz): 1.531\r\npciBusID: 0000:09:00.0\r\ntotalMemory: 11.91GiB freeMemory: 11.55GiB\r\n2019-02-04 23:12:35.297112: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0\r\n2019-02-04 23:12:35.514816: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-02-04 23:12:35.514841: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929] 0\r\n2019-02-04 23:12:35.514846: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0: N\r\n2019-02-04 23:12:35.515089: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12074 MB memory) -> physical GPU (device: 0, name: TITAN X (Pascal), pci bus id: 0000:09:00.0, compute capability: 6.1)\r\n[0204 23:12:39 @base.py:235] Initializing the session ...\r\n[0204 23:12:39 @sessinit.py:204] Variables to restore from dict: group1/block2/conv1/bn/mean/EMA:0, group2/block1/conv1/bn/gamma:0, group2/block1/conv3/bn/variance/EMA:0, group0/block1/conv2/W:0, group2/block2/conv1/bn/gamma:0, rpn/class/b:0, group2/block5/conv1/W:0, group2/block0/conv1/bn/mean/EMA:0, rpn/class/W:0, group0/block0/convshortcut/W:0, maskrcnn/conv/W:0, conv0/bn/mean/EMA:0, group0/block0/convshortcut/bn/gamma:0, group1/block3/conv1/bn/mean/EMA:0, group0/block2/conv3/W:0, group1/block1/conv3/bn/mean/EMA:0, group0/block2/conv1/W:0, group2/block0/conv2/W:0, group1/block1/conv2/bn/gamma:0, group3/block0/conv1/bn/variance/EMA:0, fpn/posthoc_3x3_p2/b:0, group1/block0/conv2/bn/variance/EMA:0, group1/block3/conv3/bn/variance/EMA:0, group0/block1/conv1/bn/mean/EMA:0, group0/block2/conv1/bn/mean/EMA:0, group1/block2/conv2/bn/gamma:0, group0/block1/conv2/bn/beta:0, group0/block2/conv3/bn/mean/EMA:0, group2/block5/conv1/bn/variance/EMA:0, group2/block2/conv2/bn/beta:0, fastrcnn/outputs/box/W:0, fpn/posthoc_3x3_p2/W:0, group1/block3/conv1/W:0, group2/block5/conv2/bn/gamma:0, group0/block0/conv3/bn/variance/EMA:0, fpn/lateral_1x1_c3/b:0, group3/block2/conv2/bn/mean/EMA:0, group1/block3/conv1/bn/beta:0, group3/block2/conv1/bn/gamma:0, conv0/bn/gamma:0, group2/block4/conv3/W:0, group1/block0/convshortcut/bn/mean/EMA:0, group3/block0/conv1/W:0, group2/block3/conv1/bn/variance/EMA:0, group3/block0/convshortcut/bn/gamma:0, group3/block1/conv2/W:0, group1/block1/conv2/bn/mean/EMA:0, group3/block2/conv1/bn/variance/EMA:0, group1/block2/conv1/bn/gamma:0, group0/block0/conv3/bn/mean/EMA:0, maskrcnn/fcn3/W:0, group1/block0/conv1/bn/beta:0, group0/block0/conv1/bn/mean/EMA:0, rpn/box/b:0, group0/block2/conv1/bn/gamma:0, group0/block1/conv1/bn/variance/EMA:0, group3/block0/conv3/bn/beta:0, group2/block5/conv2/bn/beta:0, group2/block0/conv3/bn/gamma:0, group0/block0/conv2/W:0, group2/block0/convshortcut/bn/beta:0, maskrcnn/fcn1/W:0, group2/block1/conv2/bn/beta:0, fpn/posthoc_3x3_p5/b:0, group1/block2/conv3/bn/mean/EMA:0, group3/block0/conv3/bn/mean/EMA:0, group0/block0/convshortcut/bn/mean/EMA:0, group2/block0/convshortcut/W:0, group2/block4/conv2/bn/gamma:0, group2/block1/conv2/W:0, fpn/lateral_1x1_c2/W:0, group3/block0/conv2/bn/variance/EMA:0, group1/block3/conv2/W:0, group2/block0/convshortcut/bn/variance/EMA:0, group2/block3/conv3/W:0, group2/block5/conv1/bn/mean/EMA:0, group3/block2/conv1/W:0, group2/block1/conv2/bn/gamma:0, fpn/posthoc_3x3_p3/W:0, group1/block1/conv3/bn/beta:0, group1/block2/conv3/W:0, group1/block1/conv1/bn/beta:0, group2/block2/conv3/bn/mean/EMA:0, rpn/conv0/b:0, group2/block0/conv3/W:0, group2/block4/conv1/W:0, group2/block0/conv1/bn/variance/EMA:0, group2/block3/conv1/bn/mean/EMA:0, group1/block0/conv3/W:0, conv0/bn/variance/EMA:0, group2/block1/conv1/bn/beta:0, group0/block1/conv2/bn/gamma:0, group2/block4/conv3/bn/gamma:0, group2/block1/conv2/bn/mean/EMA:0, group2/block2/conv3/bn/gamma:0, group3/block0/conv3/bn/variance/EMA:0, group0/block1/conv3/W:0, group3/block1/conv2/bn/gamma:0, group2/block3/conv1/W:0, group2/block5/conv2/W:0, group1/block0/conv2/bn/beta:0, group2/block1/conv1/bn/variance/EMA:0, group3/block1/conv1/W:0, group2/block2/conv3/bn/variance/EMA:0, group1/block2/conv3/bn/beta:0, group1/block1/conv1/bn/gamma:0, group1/block2/conv1/bn/beta:0, group3/block0/convshortcut/bn/beta:0, group0/block0/conv1/W:0, maskrcnn/conv/b:0, group2/block3/conv3/bn/variance/EMA:0, group2/block3/conv3/bn/gamma:0, group2/block2/conv1/bn/mean/EMA:0, group1/block0/conv2/bn/gamma:0, group2/block5/conv3/bn/mean/EMA:0, fastrcnn/fc7/W:0, group1/block1/conv1/bn/mean/EMA:0, group2/block2/conv1/bn/beta:0, group0/block0/conv3/W:0, group3/block2/conv3/bn/mean/EMA:0, group2/block1/conv3/bn/beta:0, fpn/lateral_1x1_c2/b:0, maskrcnn/deconv/b:0, group2/block3/conv3/bn/mean/EMA:0, group2/block4/conv2/bn/mean/EMA:0, group3/block0/conv2/W:0, group1/block0/convshortcut/bn/gamma:0, maskrcnn/fcn3/b:0, group3/block0/convshortcut/bn/mean/EMA:0, group2/block2/conv1/W:0, group1/block0/conv2/bn/mean/EMA:0, group1/block0/convshortcut/bn/variance/EMA:0, group2/block0/conv2/bn/variance/EMA:0, group3/block0/conv1/bn/mean/EMA:0, group1/block2/conv1/W:0, group3/block2/conv3/bn/beta:0, group1/block1/conv2/bn/variance/EMA:0, group1/block1/conv2/bn/beta:0, group1/block0/conv1/bn/variance/EMA:0, group2/block0/conv2/bn/mean/EMA:0, group1/block1/conv1/W:0, group0/block2/conv1/bn/variance/EMA:0, group2/block2/conv3/bn/beta:0, group1/block0/conv3/bn/beta:0, group3/block1/conv3/W:0, group1/block0/conv2/W:0, group0/block1/conv3/bn/gamma:0, fpn/posthoc_3x3_p5/W:0, fastrcnn/fc6/W:0, group0/block2/conv2/bn/variance/EMA:0, group1/block0/conv3/bn/variance/EMA:0, group1/block1/conv3/W:0, group2/block3/conv2/W:0, group0/block1/conv2/bn/mean/EMA:0, group1/block0/convshortcut/bn/beta:0, fpn/lateral_1x1_c4/b:0, group2/block5/conv2/bn/mean/EMA:0, group0/block0/convshortcut/bn/beta:0, group1/block2/conv2/W:0, group3/block1/conv3/bn/beta:0, maskrcnn/fcn0/W:0, group0/block0/conv3/bn/beta:0, group2/block4/conv2/W:0, group3/block1/conv1/bn/mean/EMA:0, group2/block0/convshortcut/bn/gamma:0, group2/block1/conv3/bn/gamma:0, group3/block2/conv2/bn/beta:0, group2/block0/conv3/bn/mean/EMA:0, group3/block0/conv3/bn/gamma:0, group3/block0/conv2/bn/gamma:0, group2/block3/conv2/bn/beta:0, group2/block4/conv1/bn/mean/EMA:0, group2/block0/conv3/bn/beta:0, group1/block3/conv2/bn/gamma:0, fastrcnn/outputs/class/W:0, group2/block3/conv2/bn/gamma:0, fpn/lateral_1x1_c4/W:0, group2/block5/conv3/bn/gamma:0, group1/block1/conv3/bn/variance/EMA:0, group3/block2/conv2/W:0, fastrcnn/fc6/b:0, group2/block2/conv2/W:0, group1/block3/conv3/bn/beta:0, group3/block2/conv2/bn/gamma:0, group1/block3/conv2/bn/beta:0, group2/block5/conv2/bn/variance/EMA:0, fastrcnn/fc7/b:0, group0/block2/conv1/bn/beta:0, maskrcnn/fcn2/W:0, group3/block0/conv1/bn/gamma:0, group2/block2/conv1/bn/variance/EMA:0, group1/block0/conv3/bn/mean/EMA:0, group3/block1/conv2/bn/variance/EMA:0, group3/block2/conv1/bn/mean/EMA:0, group0/block1/conv3/bn/mean/EMA:0, group0/block0/conv2/bn/variance/EMA:0, group2/block2/conv2/bn/variance/EMA:0, group1/block2/conv2/bn/beta:0, group1/block0/conv1/bn/gamma:0, group1/block3/conv3/W:0, group1/block3/conv3/bn/gamma:0, group3/block1/conv1/bn/gamma:0, group2/block3/conv3/bn/beta:0, group3/block2/conv3/W:0, group0/block2/conv2/bn/gamma:0, group2/block3/conv2/bn/mean/EMA:0, group2/block4/conv3/bn/mean/EMA:0, group3/block1/conv3/bn/variance/EMA:0, group1/block3/conv1/bn/gamma:0, group2/block0/conv1/W:0, group0/block2/conv2/bn/mean/EMA:0, group2/block5/conv3/W:0, fpn/posthoc_3x3_p4/W:0, group2/block0/conv2/bn/gamma:0, group0/block2/conv3/bn/gamma:0, group3/block0/conv3/W:0, group0/block0/convshortcut/bn/variance/EMA:0, group1/block3/conv2/bn/mean/EMA:0, group2/block4/conv3/bn/beta:0, group2/block5/conv1/bn/gamma:0, group0/block0/conv1/bn/gamma:0, rpn/conv0/W:0, group3/block2/conv1/bn/beta:0, group3/block0/convshortcut/bn/variance/EMA:0, group2/block0/convshortcut/bn/mean/EMA:0, group1/block0/convshortcut/W:0, group1/block2/conv2/bn/variance/EMA:0, group1/block3/conv2/bn/variance/EMA:0, group2/block5/conv3/bn/variance/EMA:0, group3/block2/conv2/bn/variance/EMA:0, group1/block2/conv3/bn/variance/EMA:0, group2/block3/conv1/bn/beta:0, group2/block5/conv3/bn/beta:0, group2/block0/conv2/bn/beta:0, fpn/posthoc_3x3_p3/b:0, group0/block0/conv2/bn/beta:0, conv0/bn/beta:0, group3/block0/conv2/bn/mean/EMA:0, group2/block2/conv2/bn/gamma:0, group1/block1/conv1/bn/variance/EMA:0, group3/block1/conv1/bn/beta:0, group0/block0/conv2/bn/mean/EMA:0, fpn/lateral_1x1_c3/W:0, group2/block3/conv1/bn/gamma:0, group1/block0/conv3/bn/gamma:0, group0/block0/conv1/bn/beta:0, group0/block0/conv2/bn/gamma:0, rpn/box/W:0, group2/block4/conv2/bn/beta:0, maskrcnn/fcn0/b:0, group0/block2/conv2/bn/beta:0, group0/block1/conv1/W:0, group2/block3/conv2/bn/variance/EMA:0, group3/block2/conv3/bn/gamma:0, group2/block2/conv2/bn/mean/EMA:0, group0/block1/conv1/bn/beta:0, group1/block2/conv3/bn/gamma:0, group3/block2/conv3/bn/variance/EMA:0, group3/block1/conv1/bn/variance/EMA:0, group0/block2/conv3/bn/beta:0, group2/block4/conv2/bn/variance/EMA:0, maskrcnn/fcn1/b:0, group2/block4/conv1/bn/gamma:0, group2/block5/conv1/bn/beta:0, fastrcnn/outputs/box/b:0, group2/block0/conv1/bn/beta:0, group3/block0/convshortcut/W:0, group2/block4/conv3/bn/variance/EMA:0, group3/block1/conv2/bn/beta:0, fpn/lateral_1x1_c5/b:0, fpn/lateral_1x1_c5/W:0, group2/block4/conv1/bn/beta:0, group0/block1/conv3/bn/variance/EMA:0, group2/block1/conv2/bn/variance/EMA:0, group0/block2/conv3/bn/variance/EMA:0, group0/block1/conv2/bn/variance/EMA:0, maskrcnn/deconv/W:0, fastrcnn/outputs/class/b:0, group3/block1/conv2/bn/mean/EMA:0, group1/block3/conv3/bn/mean/EMA:0, group3/block1/conv3/bn/gamma:0, conv0/W:0, group0/block1/conv3/bn/beta:0, group3/block1/conv3/bn/mean/EMA:0, group1/block1/conv2/W:0, group0/block0/conv3/bn/gamma:0, group1/block0/conv1/bn/mean/EMA:0, group0/block1/conv1/bn/gamma:0, group2/block1/conv1/bn/mean/EMA:0, group1/block2/conv1/bn/variance/EMA:0, group1/block3/conv1/bn/variance/EMA:0, group1/block0/conv1/W:0, group2/block4/conv1/bn/variance/EMA:0, group3/block0/conv2/bn/beta:0, group1/block2/conv2/bn/mean/EMA:0, maskrcnn/fcn2/b:0, fpn/posthoc_3x3_p4/b:0, group1/block1/conv3/bn/gamma:0, group2/block1/conv3/W:0, group2/block1/conv3/bn/mean/EMA:0, group0/block2/conv2/W:0, group3/block0/conv1/bn/beta:0, group2/block0/conv3/bn/variance/EMA:0, group2/block0/conv1/bn/gamma:0, group0/block0/conv1/bn/variance/EMA:0, group2/block2/conv3/W:0, group2/block1/conv1/W:0\r\n[0204 23:12:39 @sessinit.py:87] WRN The following variables are in the graph, but not found in the dict: global_step, idn/idn/bn0/beta, idn/idn/bn0/gamma, idn/idn/bn0/mean/EMA, idn/idn/bn0/variance/EMA, idn/idn/bn1/beta, idn/idn/bn1/gamma, idn/idn/bn1/mean/EMA, idn/idn/bn1/variance/EMA, idn/idn/bn2/beta, idn/idn/bn2/gamma, idn/idn/bn2/mean/EMA, idn/idn/bn2/variance/EMA, idn/idn/bn3/beta, idn/idn/bn3/gamma, idn/idn/bn3/mean/EMA, idn/idn/bn3/variance/EMA, idn/idn/bn4/beta, idn/idn/bn4/gamma, idn/idn/bn4/mean/EMA, idn/idn/bn4/variance/EMA, idn/idn/bn5/beta, idn/idn/bn5/gamma, idn/idn/bn5/mean/EMA, idn/idn/bn5/variance/EMA, idn/idn/bn6/beta, idn/idn/bn6/gamma, idn/idn/bn6/mean/EMA, idn/idn/bn6/variance/EMA, idn/idn/bn7/beta, idn/idn/bn7/gamma, idn/idn/bn7/mean/EMA, idn/idn/bn7/variance/EMA, idn/idn/bn8/beta, idn/idn/bn8/gamma, idn/idn/bn8/mean/EMA, idn/idn/bn8/variance/EMA, idn/idn/conv0/W, idn/idn/conv1/W, idn/idn/conv2/W, idn/idn/conv3/W, idn/idn/conv4/W, idn/idn/conv5/W, idn/idn/conv6/W, idn/idn/fc1/W, idn/idn/fc1/b, idn/idn/fc2/W, idn/idn/fc2/b, idn/idn/idn_feat/W, idn/idn/idn_feat/b, learning_rate\r\n[0204 23:12:39 @sessinit.py:217] Restoring 307 variables from dict ...\r\n[0204 23:13:34 @base.py:242] Graph Finalized.\r\n[0204 23:13:34 @concurrency.py:38] Starting EnqueueThread QueueInput/input_queue ...\r\n[0204 23:13:34 @graph.py:73] Running Op sync_variables/sync_variables_from_main_tower ...\r\n[0204 23:13:36 @param.py:158] [HyperParamSetter] At global_step=0, learning_rate is set to 0.003300\r\n[0204 23:13:36 @eval.py:250] [EvalCallback] Will evaluate every 25 epochs\r\n[0204 23:13:36 @base.py:274] Start Epoch 1 ...\r\n0%| |0/500[00:00<?,?it/s]2019-02-04 23:13:47.543598: I tensorflow/core/kernels/cuda_solvers.cc:159] Creating CudaSolver handles for stream 0x137ae830\r\n[0204 23:13:48 @param.py:161] [HyperParamSetter] At global_step=1, learning_rate changes from 0.003300 to 0.003307\r\n0%| |1/500[00:12<1:41:44, 0.08it/s]\r\n[0204 23:13:49 @input_source.py:176]2019-02-04 23:13:49.209144: W tensorflow/core/kernels/queue_base.cc:277] _0_QueueInput/input_queue: Skipping cancelled enqueue attempt with queue not closed\r\nTraceback (most recent call last):\r\nEnqueueThread QueueInput/input_queue Exited.\r\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1322, in _do_call\r\nreturn fn(*args)\r\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1307, in _run_fn\r\noptions, feed_dict, fetch_list, target_list, run_metadata)\r\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1409, in _call_tf_sessionrun\r\nrun_metadata)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: indices[40] = -1 is not in [0, 517)\r\n[[Node: tower0/cond/while/GatherV2 = GatherV2[Taxis=DT_INT32, Tindices=DT_INT32, Tparams=DT_FLOAT, _class=[\"loc:@tower0/gradients/concat_5\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](tower0/cond/while/Identity_3, tower0/cond/while/strided_slice_2, tower0/cond/while/boolean_mask_1/GatherV2/axis/_1305)]]\r\n[[Node: tower0/gradients/tower0/cond/while_2/Prod_grad/DynamicStitch/StackPushV2/_1668 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_11639...tackPushV2\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](%5E_clooptower0/cond/while_2/NextIteration_3/_690)]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\nFile \"/home/blackfoot/git/tensorpack/examples/FasterRCNN/train.py\", line 620, in \r\nlaunch_train_with_config(traincfg, trainer)\r\nFile \"/home/blackfoot/git/tensorpack/tensorpack/train/interface.py\", line 94, in launch_train_with_config\r\nextra_callbacks=config.extra_callbacks)\r\nFile \"/home/blackfoot/git/tensorpack/tensorpack/train/base.py\", line 343, in train_with_defaults\r\nsteps_per_epoch, starting_epoch, max_epoch)\r\nFile \"/home/blackfoot/git/tensorpack/tensorpack/train/base.py\", line 315, in train\r\nself.main_loop(steps_per_epoch, starting_epoch, max_epoch)\r\nFile \"/home/blackfoot/git/tensorpack/tensorpack/utils/argtools.py\", line 176, in wrapper\r\nreturn func(*args, **kwargs)\r\nFile \"/home/blackfoot/git/tensorpack/tensorpack/train/base.py\", line 280, in main_loop\r\nself.run_step() # implemented by subclass\r\nFile \"/home/blackfoot/git/tensorpack/tensorpack/train/base.py\", line 180, in run_step\r\nself.hooked_sess.run(self.train_op)\r\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 567, in run\r\nrun_metadata=run_metadata)\r\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1043, in run\r\nrun_metadata=run_metadata)\r\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1134, in run\r\nraise six.reraise(*original_exc_info)\r\nFile \"/usr/local/lib/python3.5/dist-packages/six.py\", line 693, in reraise\r\nraise value\r\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1119, in run\r\nreturn self._sess.run(*args, **kwargs)\r\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1191, in run\r\nrun_metadata=run_metadata)\r\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 971, in run\r\nreturn self._sess.run(*args, **kwargs)\r\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 900, in run\r\nrun_metadata_ptr)\r\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1135, in _run\r\nfeed_dict_tensor, options, run_metadata)\r\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1316, in _do_run\r\nrun_metadata)\r\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1335, in _do_call\r\nraise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: indices[40] = -1 is not in [0, 517)\r\n[[Node: tower0/cond/while/GatherV2 = GatherV2[Taxis=DT_INT32, Tindices=DT_INT32, Tparams=DT_FLOAT, _class=[\"loc:@tower0/gradients/concat_5\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](tower0/cond/while/Identity_3, tower0/cond/while/strided_slice_2, tower0/cond/while/boolean_mask_1/GatherV2/axis/_1305)]]\r\n[[Node: tower0/gradients/tower0/cond/while_2/Prod_grad/DynamicStitch/StackPushV2/_1668 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_11639...tackPushV2\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](%5E_clooptower0/cond/while_2/NextIteration_3/_690)]]\r\n\r\nCaused by op 'tower0/cond/while/GatherV2', defined at:\r\nFile \"/home/blackfoot/git/tensorpack/examples/FasterRCNN/train.py\", line 620, in \r\nlaunch_train_with_config(traincfg, trainer)\r\nFile \"/home/blackfoot/git/tensorpack/tensorpack/train/interface.py\", line 84, in launch_train_with_config\r\nmodel._build_graph_get_cost, model.get_optimizer)\r\nFile \"/home/blackfoot/git/tensorpack/tensorpack/utils/argtools.py\", line 176, in wrapper\r\nreturn func(*args, **kwargs)\r\nFile \"/home/blackfoot/git/tensorpack/tensorpack/train/tower.py\", line 214, in setup_graph\r\ntrain_callbacks = self._setup_graph(input, get_cost_fn, get_opt_fn)\r\nFile \"/home/blackfoot/git/tensorpack/tensorpack/train/trainers.py\", line 193, in _setup_graph\r\ngrad_list = self._builder.call_for_each_tower(tower_fn)\r\nFile \"/home/blackfoot/git/tensorpack/tensorpack/graph_builder/training.py\", line 225, in call_for_each_tower\r\nuse_vs=[False] + [True] * (len(self.towers) - 1))\r\nFile \"/home/blackfoot/git/tensorpack/tensorpack/graph_builder/training.py\", line 121, in build_on_towers\r\nreturn DataParallelBuilder.call_for_each_tower(*args, **kwargs)\r\nFile \"/home/blackfoot/git/tensorpack/tensorpack/graph_builder/training.py\", line 116, in call_for_each_tower\r\nret.append(func())\r\nFile \"/home/blackfoot/git/tensorpack/tensorpack/train/tower.py\", line 266, in get_grad_fn\r\nreturn compute_grad_from_inputs(*inputs)\r\nFile \"/home/blackfoot/git/tensorpack/tensorpack/train/tower.py\", line 245, in compute_grad_from_inputs\r\ncost = get_cost_fn(*inputs)\r\nFile \"/home/blackfoot/git/tensorpack/tensorpack/tfutils/tower.py\", line 286, in **call**\r\noutput = self._tower_fn(*args)\r\nFile \"/home/blackfoot/git/tensorpack/tensorpack/graph_builder/model_desc.py\", line 262, in _build_graph_get_cost\r\nret = self.build_graph(*inputs)\r\nFile \"/home/blackfoot/git/tensorpack/examples/FasterRCNN/train.py\", line 166, in build_graph\r\nlambda: zerof())\r\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py\", line 432, in new_func\r\nreturn func(*args, **kwargs)\r\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2063, in cond\r\norig_res_t, res_t = context_t.BuildCondBranch(true_fn)\r\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 1913, in BuildCondBranch\r\noriginal_result = fn()\r\nFile \"/home/blackfoot/git/tensorpack/examples/FasterRCNN/train.py\", line 165, in \r\nlambda: self.idn_layer(features[0], input_boxes),\r\nFile \"/home/blackfoot/git/tensorpack/examples/FasterRCNN/train.py\", line 417, in idn_layer\r\nID_loss = cfg.TRAIN.SIM_LR * id_loss(idn_feat_sim, pIOU, dppLabel, intraDppLabel, clssLabel, quality)\r\nFile \"/home/blackfoot/git/tensorpack/examples/FasterRCNN/model_dpp.py\", line 57, in id_loss\r\nintra_denom = tf.divide(whilef(intra_clss_index, mbody), tf.cast(tf.shape(clssLabel)[0], tf.float32))\r\nFile \"/home/blackfoot/git/tensorpack/examples/FasterRCNN/utils/tf_utils.py\", line 35, in whilef\r\nreturn tf.while_loop(condition, body, params)[1]\r\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 3224, in while_loop\r\nresult = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants)\r\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2956, in BuildLoop\r\npred, body, original_loop_vars, loop_vars, shape_invariants)\r\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2893, in _BuildLoop\r\nbody_result = body(*packed_vars_for_body)\r\nFile \"/home/blackfoot/git/tensorpack/examples/FasterRCNN/utils/tf_utils.py\", line 28, in mbody\r\nLc = tf.gather(tf.cast(tf.transpose(tf.gather(tf.cast(L,tf.float32), label[index])),tf.float32), label[index])\r\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/array_ops.py\", line 2736, in gather\r\nreturn gen_array_ops.gather_v2(params, indices, axis, name=name)\r\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 3065, in gather_v2\r\n\"GatherV2\", params=params, indices=indices, axis=axis, name=name)\r\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\nop_def=op_def)\r\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\r\nop_def=op_def)\r\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1718, in **init**\r\nself._traceback = self._graph._extract_stack() # pylint: disable=protected-access\r\n\r\nInvalidArgumentError (see above for traceback): indices[40] = -1 is not in [0, 517)\r\n[[Node: tower0/cond/while/GatherV2 = GatherV2[Taxis=DT_INT32, Tindices=DT_INT32, Tparams=DT_FLOAT, _class=[\"loc:@tower0/gradients/concat_5\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](tower0/cond/while/Identity_3, tower0/cond/while/strided_slice_2, tower0/cond/while/boolean_mask_1/GatherV2/axis/_1305)]]\r\n[[Node: tower0/gradients/tower0/cond/while_2/Prod_grad/DynamicStitch/StackPushV2/_1668 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_11639...tackPushV2\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](%5E_clooptower0/cond/while_2/NextIteration_3/_690)]]\r\n\r\nMultiProcessMapDataZMQ successfully cleaned-up.", "comments": ["I created a simple example to check ```tf.gather``` function's result. It is working as expected, The following code snippet produces ```0``` in GPU \r\n```python\r\nimport tensorflow as tf\r\nx = tf.constant([1,2,3])\r\ny = tf.constant(12)\r\nsess = tf.Session()\r\nsess.run(tf.gather(x,y,validate_indices=True))\r\n```\r\nand throws following error in CPU\r\n```python\r\nInvalidArgumentError: indices = 12 is not in [0, 3)\r\n\t [[node GatherV2_11 (defined at <ipython-input-33-f08aaa0fc5cb>:5) ]]\r\n```\r\n\r\nI noticed you are using lower version of TF.\r\nCan you please switch to latest version of TF and try again.\r\nYou can try latest TF version 1.13.0.rc0", "When you set x = tf.constant([1.,2.,3.])\r\nIt returns 0.0\r\nThere are multiple severs in our lab and i tried it for many servers with different settings and there was the same error. :(", "Also, I already said that the error I wrote does not happen in the terminal, just for my code :(", "@alextp Can you PTAL? thanks!", "You might seeing it work sometimes with tf.constant because tf.constant runs constant folding which runs on the CPU and not the GPU.\r\n\r\nI think this (failing on out of range) is intended behavior of the gather op.", "@alextp As you said, I also think the tf.gather is working on CPU, not GPU.\r\nI think the part in the log,\r\n\"\"WARNING:tensorflow:Tried to colocate tower0/gradients/tower0/cond/while_1/cond/Prod_grad/GatherV2_1/axis with an op tower0/cond/while_1/cond/Prod that had a different device: /device:CPU:0 vs /device:GPU:0. Postponing error-checking until all devices are assigned.\"\", shows the problem...\r\nHow can I make both operations work on GPU?\r\nWould you help me?", "@iganichev do you know why the placer is getting confused here?", "This error message is checking for obvious device assignment violations during op creation in Python (ops.py). It appears that the tower0/gradients/tower0/cond/while_1/cond/Prod_grad/GatherV2_1/axis op has \"/device:GPU:0\" explicitly requested in the code and there is a colocation context active that asks for this op to be colocated with tower0/cond/while_1/cond/Prod, which is on \"/device:CPU:0\".\r\n\r\nIn this case, Python does not do anything. Surprisingly, the C++ Placer will unset the type (CPU/GPU) and id (i.e. 0) field when it sees a conflict. Then, it will decide based on (1) is there another device spec in the same colocation group that was not yet incorporated, (2) are there resource edges that were not incorporated, (3) supported and preferred devices. It is quite possible that this process chooses a CPU. \r\n\r\nAs a side note, the Python check was removed in the beginning of December. It should have no impact in this case.\r\n\r\nI can't quite follow how the actual error has anything to do with device placement. If the index is out of range, it should be fixed.", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 25503, "title": "Update astor version to fix https://github.com/berkerpeksag/astor/iss\u2026", "body": "\u2026ues/86 which we are hitting in Python 3.7\r\n\r\nPiperOrigin-RevId: 225966877", "comments": []}, {"number": 25502, "title": "[Intel MKL]: Added missing data type for MKL quantized ops", "body": "", "comments": []}, {"number": 25501, "title": "Reverting a commit that caused Wide and Deep model inference to fail", "body": "This PR fixes this issue #25443 by reverting this commit https://github.com/tensorflow/tensorflow/commit/eb376a3dc2841f08ad2b54c08864e4c2653dbb9c\r\n", "comments": ["I don't think we should revert this change, it's a pretty big performance improvement. What error are you seeing with it? Do you have instructions to reproduce it?\r\n\r\nI'll close this PR since I don't think we should merge it, but let's keep the discussion here about the issue (or file a separate issue and link here).\r\n\r\nI'm not sure this even fixes the behavior from the linked to issue."]}, {"number": 25500, "title": "[Intel MKL]: Fixing a failure in conv_ops_test unit test caused by MKL pad fusion", "body": "", "comments": []}, {"number": 25499, "title": "Build tensorflow from source[centos]", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Centos\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: v1.12.0\r\n- Python version: 3.5\r\n- Installed using virtualenv? pip? conda?: none\r\n- Bazel version (if compiling from source): 0.18.0\r\n- GCC/Compiler version (if compiling from source): GCC8.2.0\r\n- CUDA/cuDNN version: cudatoolkit9.1/cudnn7.4.2\r\n- GPU model and memory:\r\nK20\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nI've finished `./configure` and trying to `bazel test` or `bazel build` as instructed in manual.\r\n\r\nWhen I tried to `bazel test` with `bazel test -c opt -- //tensorflow/... -//tensorflow/compiler/... -//tensorflow/contrib/lite/...`, I got the following error message [gist](https://gist.github.com/jw447/a191d193b17926fd98f23ce1232d3d28)\r\n\r\n\r\nWhen I tried to 'bazel build' with `bazel build --config=opt --config=mkl --config=monolithic --config=cuda //tensorflow/tools/pip_package:build_pip_package`, I got the following error message [gist](https://gist.github.com/jw447/bdfb2aef5dddc2552958115e5cc21f4b).\r\n\r\nFor the second problem, installing a newer version of glibc is temporarily unavailable. I'm wondering if both questions are triggered by the same reason, the version of glibc?\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@sub-mod could you have a look at this, why have we not build a py35 wheel file?\r\n", "Now that we have the manylinux 2010 packages, they should work out of the box with centos 6 or later.\r\nAnything older may not work.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/25499\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/25499\">No</a>\n"]}, {"number": 25498, "title": "Fix applications integration test to be compatible with latest release of Keras-Applications", "body": "Keras_applications 1.0.6 had a breaking change which caused an integration test to fail. This relaxes the test requirements.", "comments": []}, {"number": 25497, "title": "Revert dataset warning fix as it breaks many tests.", "body": "Unfortunately, the fix to warning brings in dependencies to a bunch of other features that we are not yet ready to merge and test into 1.13.", "comments": ["So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored or co-authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of all the commit author(s), set the `cla` label to `yes` (if enabled on your project), and then merge this pull request when appropriate.*\n\n<!-- need_author_consent -->", "Approve assuming this is a pure reverting commit", "A Googler has manually verified that the CLAs look good.\n\n(Googler, please make sure the reason for overriding the CLA status is clearly documented in these comments.)\n\n<!-- cla_yes -->"]}, {"number": 25496, "title": "Add the tests for the TensorDatasetOp kernel", "body": "This PR adds the tests and the shape & dtype validation for `TensorDatasetOp`.\r\n\r\ncc @jsimsa ", "comments": ["@jsimsa Thanks for your review! The comments have been addressed in [this commit](https://github.com/tensorflow/tensorflow/pull/25496/commits/fb2ed20fb3009ed5582355caf21374e0dbcc34ca). Could you help review the changes?\r\n\r\nThe tests for `TensorSliceDataset` are ready for review as well. Should I submit the commit here or create another PR?\r\n\r\n ", "@jsimsa @rthadur The test failures seem to be unrelated.", "@feihugis could you please resolve conflicts.", "@rthadur @jsimsa The conflicts are resolved. Also, replace a `TF_CHECK_OK` by `TF_RETURN_IF_ERROR` in [this commit](https://github.com/tensorflow/tensorflow/pull/25496/commits/b07dae2fce62dc394758878f480a28656d71c607).", "@jsimsa The PR has been refactored to be consistent with other unit tests by [this commit](https://github.com/tensorflow/tensorflow/pull/25496/commits/18f90d1adc9131de89f8e5793b1f6eb8441227b0) . I just notice the recent change in `DatasetBase` API (https://github.com/tensorflow/tensorflow/commit/4ea3fca0902e84a1e6aa1876c34a9f78bfd9e440#diff-4cf3c43698043116f0f14b0f9377f9d8L574): remove `name()`, and add `type_string()` & `node_name()`. The tests for new APIs are added as well."]}, {"number": 25494, "title": "[DONOTMERGE] Test pip test failure.", "body": "Revert \"Correctly handle return statements in with statements.\"\r\n\r\nThis reverts commit 610db7b37196ba8a75d5133b124848beeedd803f.", "comments": []}, {"number": 25493, "title": "[DONOTMERGE] Test pip test failure.", "body": "Revert \"Rename thread to \"profiler_server\" from \"profiler server\" (replace space with \"_\").\"\r\n\r\nThis reverts commit 5458340eced84db0827af1464d216dea9257b8dd.", "comments": []}, {"number": 25492, "title": "Executor failed to create kernel. Not found: No registered 'NGraphVariable' OpKernel for GPU devices compatible with node {{node FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7/BatchNorm/beta}} = NGraphVariable[_class=[\"loc:@Assign\"], container=\"\", dtype=DT_FLOAT, just_looking=false, shape=[64], shared_name=\"\", _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()     .  Registered:  device='CPU'", "body": "### **Executor failed to create kernel. Not found: No registered 'NGraphVariable' OpKernel for GPU devices compatible with node {{node FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7/BatchNorm/beta}} = NGraphVariable[_class=[\"loc:@Assign\"], container=\"\", dtype=DT_FLOAT, just_looking=false, shape=[64], shared_name=\"\", _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()     .  Registered:  device='CPU'**\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nNo\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nLinux Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\nsource\r\n- TensorFlow version (use command below):\r\nTensorflow GPU 1.11.0-rc1\r\n- Python version:\r\npython 3.6.6\r\n- CUDA/cuDNN version:\r\ncuda 10 cuDNN 7.2\r\n- GPU model and memory:\r\nQuadro M4000\r\n8126MiB\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\nWhile giving the command for training tensorflow model _(tensorflow models_master/research/object_detection)_ for object detection, it gives an error given below\r\n\r\n### **Command:**\r\npython model_main.py --logtostderr --train_dir=training/ --pipeline_config_path=training/pipeline.config\r\n\r\n### **Error:**\r\nE tensorflow/core/common_runtime/executor.cc:623] Executor failed to create kernel. Not found: No registered 'NGraphVariable' OpKernel for GPU devices compatible with node {{node FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7/BatchNorm/beta}} = NGraphVariable[_class=[\"loc:@Assign\"], container=\"\", dtype=DT_FLOAT, just_looking=false, shape=[64], shared_name=\"\", _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()\r\n    .  Registered:  device='CPU'\r\n\r\n     [[{{node FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7/BatchNorm/beta}} = NGraphVariable[_class=[\"loc:@Assign\"], container=\"\", dtype=DT_FLOAT, just_looking=false, shape=[64], shared_name=\"\", _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\r\n    return fn(*args)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1319, in _run_fn\r\n    options, feed_dict, fetch_list, target_list, run_metadata)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1407, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.NotFoundError: No registered 'NGraphVariable' OpKernel for GPU devices compatible with node {{node FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7/BatchNorm/beta}} = NGraphVariable[_class=[\"loc:@Assign\"], container=\"\", dtype=DT_FLOAT, just_looking=false, shape=[64], shared_name=\"\", _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()\r\n    .  Registered:  device='CPU'\r\n\r\n     [[{{node FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7/BatchNorm/beta}} = NGraphVariable[_class=[\"loc:@Assign\"], container=\"\", dtype=DT_FLOAT, just_looking=false, shape=[64], shared_name=\"\", _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"model_main.py\", line 109, in <module>\r\n    tf.app.run()\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"model_main.py\", line 105, in main\r\n    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/training.py\", line 471, in train_and_evaluate\r\n    return executor.run()\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/training.py\", line 610, in run\r\n    return self.run_local()\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/training.py\", line 711, in run_local\r\n    saving_listeners=saving_listeners)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py\", line 354, in train\r\n    loss = self._train_model(input_fn, hooks, saving_listeners)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py\", line 1183, in _train_model\r\n    return self._train_model_default(input_fn, hooks, saving_listeners)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py\", line 1217, in _train_model_default\r\n    saving_listeners)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py\", line 1408, in _train_with_estimator_spec\r\n    log_step_count_steps=self._config.log_step_count_steps) as mon_sess:\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 504, in MonitoredTrainingSession\r\n    stop_grace_period_secs=stop_grace_period_secs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 921, in __init__\r\n    stop_grace_period_secs=stop_grace_period_secs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 643, in __init__\r\n    self._sess = _RecoverableSession(self._coordinated_creator)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 1107, in __init__\r\n    _WrappedSession.__init__(self, self._create_session())\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 1112, in _create_session\r\n    return self._sess_creator.create_session()\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 800, in create_session\r\n    self.tf_sess = self._session_creator.create_session()\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 566, in create_session\r\n    init_fn=self._scaffold.init_fn)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/session_manager.py\", line 287, in prepare_session\r\n    sess.run(init_op, feed_dict=init_feed_dict)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 929, in run\r\n    run_metadata_ptr)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1152, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\r\n    run_metadata)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.NotFoundError: No registered 'NGraphVariable' OpKernel for GPU devices compatible with node node FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7/BatchNorm/beta (defined at /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/framework/python/ops/variables.py:277)  = NGraphVariable[_class=[\"loc:@Assign\"], container=\"\", dtype=DT_FLOAT, just_looking=false, shape=[64], shared_name=\"\", _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()\r\n    .  Registered:  device='CPU'\r\n\r\n     [[node FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7/BatchNorm/beta (defined at /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/framework/python/ops/variables.py:277)  = NGraphVariable[_class=[\"loc:@Assign\"], container=\"\", dtype=DT_FLOAT, just_looking=false, shape=[64], shared_name=\"\", _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n\r\nCaused by op 'FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7/BatchNorm/beta', defined at:\r\n  File \"model_main.py\", line 109, in <module>\r\n    tf.app.run()\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"model_main.py\", line 105, in main\r\n    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/training.py\", line 471, in train_and_evaluate\r\n    return executor.run()\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/training.py\", line 610, in run\r\n    return self.run_local()\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/training.py\", line 711, in run_local\r\n    saving_listeners=saving_listeners)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py\", line 354, in train\r\n    loss = self._train_model(input_fn, hooks, saving_listeners)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py\", line 1183, in _train_model\r\n    return self._train_model_default(input_fn, hooks, saving_listeners)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py\", line 1213, in _train_model_default\r\n    features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py\", line 1171, in _call_model_fn\r\n    model_fn_results = self._model_fn(features=features, **kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/model_lib.py\", line 284, in model_fn\r\n    features[fields.InputDataFields.true_image_shape])\r\n  File \"/usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/meta_architectures/faster_rcnn_meta_arch.py\", line 647, in predict\r\n    image_shape) = self._extract_rpn_feature_maps(preprocessed_inputs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/meta_architectures/faster_rcnn_meta_arch.py\", line 978, in _extract_rpn_feature_maps\r\n    scope=self.first_stage_feature_extractor_scope))\r\n  File \"/usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/meta_architectures/faster_rcnn_meta_arch.py\", line 163, in extract_proposal_features\r\n    return self._extract_proposal_features(preprocessed_inputs, scope)\r\n  File \"/usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/models/faster_rcnn_inception_v2_feature_extractor.py\", line 138, in _extract_proposal_features\r\n    scope=scope)\r\n  File \"/usr/local/lib/python3.6/dist-packages/slim-0.1-py3.6.egg/nets/inception_v2.py\", line 117, in inception_v2_base\r\n    scope=end_point)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 182, in func_with_args\r\n    return func(*args, **current_args)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/layers/python/layers/layers.py\", line 2790, in separable_convolution2d\r\n    outputs = normalizer_fn(outputs, **normalizer_params)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 182, in func_with_args\r\n    return func(*args, **current_args)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/layers/python/layers/layers.py\", line 650, in batch_norm\r\n    outputs = layer.apply(inputs, training=is_training)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 828, in apply\r\n    return self.__call__(inputs, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/layers/base.py\", line 364, in __call__\r\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 759, in __call__\r\n    self.build(input_shapes)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/normalization.py\", line 297, in build\r\n    trainable=True)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/layers/base.py\", line 278, in add_weight\r\n    getter=vs.get_variable)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 586, in add_weight\r\n    aggregation=aggregation)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/checkpointable/base.py\", line 639, in _add_variable_with_custom_getter\r\n    **kwargs_for_getter)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\", line 1484, in get_variable\r\n    aggregation=aggregation)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\", line 1234, in get_variable\r\n    aggregation=aggregation)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\", line 521, in get_variable\r\n    return custom_getter(**custom_getter_kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\", line 1922, in wrapped_custom_getter\r\n    *args, **kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/layers/python/layers/layers.py\", line 1749, in layer_variable_getter\r\n    return _model_variable_getter(getter, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/layers/python/layers/layers.py\", line 1740, in _model_variable_getter\r\n    aggregation=aggregation)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 182, in func_with_args\r\n    return func(*args, **current_args)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/framework/python/ops/variables.py\", line 350, in model_variable\r\n    aggregation=aggregation)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 182, in func_with_args\r\n    return func(*args, **current_args)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/framework/python/ops/variables.py\", line 277, in variable\r\n    aggregation=aggregation)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/layers/python/layers/layers.py\", line 1749, in layer_variable_getter\r\n    return _model_variable_getter(getter, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/layers/python/layers/layers.py\", line 1740, in _model_variable_getter\r\n    aggregation=aggregation)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 182, in func_with_args\r\n    return func(*args, **current_args)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/framework/python/ops/variables.py\", line 350, in model_variable\r\n    aggregation=aggregation)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 182, in func_with_args\r\n    return func(*args, **current_args)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/framework/python/ops/variables.py\", line 277, in variable\r\n    aggregation=aggregation)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\", line 492, in _true_getter\r\n    aggregation=aggregation)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\", line 920, in _get_single_variable\r\n    aggregation=aggregation)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\", line 145, in __call__\r\n    return cls._variable_call(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\", line 141, in _variable_call\r\n    aggregation=aggregation)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\", line 120, in <lambda>\r\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\", line 2441, in default_variable_creator\r\n    expected_shape=expected_shape, import_scope=import_scope)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\", line 147, in __call__\r\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\", line 1104, in __init__\r\n    constraint=constraint)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\", line 1218, in _init_from_args\r\n    name=name)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/state_ops.py\", line 77, in variable_op_v2\r\n    shared_name=shared_name)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_state_ops.py\", line 1357, in variable_v2\r\n    shared_name=shared_name, name=name)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\nNotFoundError (see above for traceback): No registered 'NGraphVariable' OpKernel for GPU devices compatible with node node FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7/BatchNorm/beta (defined at /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/framework/python/ops/variables.py:277)  = NGraphVariable[_class=[\"loc:@Assign\"], container=\"\", dtype=DT_FLOAT, just_looking=false, shape=[64], shared_name=\"\", _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()\r\n    .  Registered:  device='CPU'\r\n\r\n     [[node FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7/BatchNorm/beta (defined at /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/framework/python/ops/variables.py:277)  = NGraphVariable[_class=[\"loc:@Assign\"], container=\"\", dtype=DT_FLOAT, just_looking=false, shape=[64], shared_name=\"\", _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n\r\nERROR:tensorflow:==================================\r\nObject was never used (type <class 'tensorflow.python.framework.ops.Tensor'>):\r\n<tf.Tensor 'report_uninitialized_variables_1/boolean_mask/GatherV2:0' shape=(?,) dtype=string>\r\nIf you want to mark it as used call its \"mark_used()\" method.\r\nIt was originally created here:\r\n  File \"model_main.py\", line 109, in <module>\r\n    tf.app.run()  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py\", line 125, in run\r\n    _sys.exit(main(argv))  File \"model_main.py\", line 105, in main\r\n    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/training.py\", line 471, in train_and_evaluate\r\n    return executor.run()  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/training.py\", line 610, in run\r\n    return self.run_local()  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/training.py\", line 711, in run_local\r\n    saving_listeners=saving_listeners)  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py\", line 356, in train\r\n    return self  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py\", line 1183, in _train_model\r\n    return self._train_model_default(input_fn, hooks, saving_listeners)  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py\", line 1217, in _train_model_default\r\n    saving_listeners)  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py\", line 1408, in _train_with_estimator_spec\r\n    log_step_count_steps=self._config.log_step_count_steps) as mon_sess:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 504, in MonitoredTrainingSession\r\n    stop_grace_period_secs=stop_grace_period_secs)  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 921, in __init__\r\n    stop_grace_period_secs=stop_grace_period_secs)  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 643, in __init__\r\n    self._sess = _RecoverableSession(self._coordinated_creator)  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 1107, in __init__\r\n    _WrappedSession.__init__(self, self._create_session())  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 1121, in _create_session\r\n    'the job. Error: %s', e)  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 800, in create_session\r\n    self.tf_sess = self._session_creator.create_session()  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 566, in create_session\r\n    init_fn=self._scaffold.init_fn)  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 219, in finalize\r\n    return self  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 268, in get_or_default\r\n    return op  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 199, in default_ready_for_local_init_op\r\n    variables.global_variables())  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/tf_should_use.py\", line 189, in wrapped\r\n    return _add_should_use_warning(fn(*args, **kwargs))\r\n\r\nWhat can be the solution to this?", "comments": ["The code you are trying is taken from `tensorflow models_master/research/object_detection` repository.\r\nThis issue is more on suitable on TensorFlow/models repo. Since its not a bug or feature request on TF side,Please post on TF Models from [here](https://github.com/tensorflow/models/issues). If you think we have misinterpreted the bug please provide a minimal code snippet to reproduce the issue reported here. Thanks!", "I have the same problem here, I've trained a model on my local PC and it worked just fine. However, when I use the same model on the cloud, this problem occurs. Why @ymodak thought this is a TF Model's problem, if you don't mind me asking. ", "Has anyone solved this? Same issue here."]}, {"number": 25491, "title": "TFTRT: Fix #if logic for TRT 5.1+", "body": "The previous logic wouldn't work for TRT 6.0, 7.0, etc.", "comments": []}, {"number": 25490, "title": "Compilation fails on protobuf_archive", "body": "**System information**\r\n- OS Platform and Distribution: Linux Ubuntu 18.04\r\n- TensorFlow installed from: source\r\n- TensorFlow version: 1.12\r\n- Python version: 3.6.7\r\n- Installed using virtualenv? pip? conda?: virtualenv\r\n- Bazel version (if compiling from source): 0.22.0\r\n- GCC/Compiler version (if compiling from source): 7.3.0\r\n- CUDA/cuDNN version: N/A, compiling for CPU\r\n- GPU model and memory: N/A, compiling for CPU\r\n\r\n**Describe the problem**\r\n\r\nBazel build fails on _protobuf_archive_ with the following error:\r\n\r\n> builtin variable 'REPOSITORY_NAME' is referenced before assignment.\r\n\r\nI'm building for CPU only because I'm running on an old Xeon that does not have AVX. I've checked out the v1.12 tag and answered _**n**_ to every question on `./configure`.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n```\r\n$ git checkout v1.12.0\r\n$ ./configure\r\nWARNING: The following rc files are no longer being read, please transfer their contents or import their path into one of the standard rc files\r\n:\r\n/home/vitor/tensorflow/tools/bazel.rc\r\nWARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command \"bazel shutdown\".\r\nINFO: Invocation ID: 942c71ae-f211-47ba-bbfe-b9a1b929dd5a\r\nYou have bazel 0.22.0 installed.\r\nPlease specify the location of python. [Default is /usr/bin/python]:\r\n\r\n\r\nFound possible Python library paths:\r\n  /usr/lib/python3/dist-packages\r\n  /usr/local/lib/python3.6/dist-packages\r\nPlease input the desired Python library path to use.  Default is [/usr/lib/python3/dist-packages]\r\n\r\nDo you wish to build TensorFlow with Apache Ignite support? [Y/n]: n\r\nNo Apache Ignite support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with XLA JIT support? [Y/n]: n\r\nNo XLA JIT support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with OpenCL SYCL support? [y/N]: n\r\nNo OpenCL SYCL support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with ROCm support? [y/N]: n\r\nNo ROCm support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with CUDA support? [y/N]: n\r\nNo CUDA support will be enabled for TensorFlow.\r\n\r\nDo you wish to download a fresh release of clang? (Experimental) [y/N]: n\r\nClang will not be downloaded.\r\n\r\nDo you wish to build TensorFlow with MPI support? [y/N]: n\r\nNo MPI support will be enabled for TensorFlow.\r\n\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native]:\r\n\r\n\r\nWould you like to interactively configure ./WORKSPACE for Android builds? [y/N]: n\r\nNot configuring the WORKSPACE for Android builds.\r\n\r\nPreconfigured Bazel build configs. You can use any of the below by adding \"--config=<>\" to your build command. See tools/bazel.rc for more deta\r\nils.\r\n        --config=mkl            # Build with MKL support.\r\n        --config=monolithic     # Config for mostly static monolithic build.\r\n        --config=gdr            # Build with GDR support.\r\n        --config=verbs          # Build with libverbs support.\r\n        --config=ngraph         # Build with Intel nGraph support.\r\nConfiguration finished\r\n$ bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package\r\n\r\nWARNING: The following rc files are no longer being read, please transfer their contents or import their path into one of the standard rc files\r\n:\r\n/home/vitor/tensorflow/tools/bazel.rc\r\nStarting local Bazel server and connecting to it...\r\nINFO: Invocation ID: f013afad-a38e-4b6d-a3bd-f2f48351c346\r\nERROR: error loading package '': Encountered error while reading extension file 'closure/defs.bzl': no such package '@io_bazel_rules_closure//c\r\nlosure': The native http_archive rule is deprecated. load(\"@bazel_tools//tools/build_defs/repo:http.bzl\", \"http_archive\") for a drop-in replace\r\nment.\r\nUse --incompatible_remove_native_http_archive=false to temporarily continue using the native rule.\r\nERROR: error loading package '': Encountered error while reading extension file 'closure/defs.bzl': no such package '@io_bazel_rules_closure//c\r\nlosure': The native http_archive rule is deprecated. load(\"@bazel_tools//tools/build_defs/repo:http.bzl\", \"http_archive\") for a drop-in replace\r\nment.\r\nUse --incompatible_remove_native_http_archive=false to temporarily continue using the native rule.\r\nINFO: Elapsed time: 2.204s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (0 packages loaded)\r\n    Fetching @io_bazel_rules_closure; fetching\r\n$ bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package --incompatible_remove_native_http_archive=false\r\nWARNING: The following rc files are no longer being read, please transfer their contents or import their path into one of the standard rc files\r\n:\r\n/home/vitor/tensorflow/tools/bazel.rc\r\nINFO: Invocation ID: 86bed03e-2ee9-40f3-a646-9637f9c77ac2\r\nERROR: /home/vitor/.cache/bazel/_bazel_vitor/24c362ffbb1041b0533e8d298828b5ea/external/protobuf_archive/BUILD:591:1: Traceback (most recent cal\r\nl last):\r\n        File \"/home/vitor/.cache/bazel/_bazel_vitor/24c362ffbb1041b0533e8d298828b5ea/external/protobuf_archive/BUILD\", line 591\r\n                internal_gen_well_known_protos_java(srcs = WELL_KNOWN_PROTOS)\r\n        File \"/home/vitor/.cache/bazel/_bazel_vitor/24c362ffbb1041b0533e8d298828b5ea/external/protobuf_archive/protobuf.bzl\", line 269, in inte\r\nrnal_gen_well_known_protos_java\r\n                Label((\"%s//protobuf_java\" % REPOSITOR...))\r\n        File \"/home/vitor/.cache/bazel/_bazel_vitor/24c362ffbb1041b0533e8d298828b5ea/external/protobuf_archive/protobuf.bzl\", line 269, in Labe\r\nl\r\n                REPOSITORY_NAME\r\nbuiltin variable 'REPOSITORY_NAME' is referenced before assignment.\r\nERROR: /home/vitor/.cache/bazel/_bazel_vitor/24c362ffbb1041b0533e8d298828b5ea/external/protobuf_archive/BUILD:373:1: Target '@protobuf_archive/\r\n/:android' contains an error and its package is in error and referenced by '@protobuf_archive//:protoc'\r\nERROR: /home/vitor/.cache/bazel/_bazel_vitor/24c362ffbb1041b0533e8d298828b5ea/external/protobuf_archive/BUILD:373:1: Target '@protobuf_archive/\r\n/:msvc' contains an error and its package is in error and referenced by '@protobuf_archive//:protoc'\r\nERROR: /home/vitor/tensorflow/tensorflow/contrib/boosted_trees/proto/BUILD:25:1: Target '@protobuf_archive//:protobuf_python_genproto' contains\r\n an error and its package is in error and referenced by '//tensorflow/contrib/boosted_trees/proto:split_info_proto_py_genproto'\r\nERROR: /home/vitor/tensorflow/tensorflow/contrib/boosted_trees/proto/BUILD:25:1: Target '@protobuf_archive//:protoc' contains an error and its\r\npackage is in error and referenced by '//tensorflow/contrib/boosted_trees/proto:split_info_proto_py_genproto'\r\nERROR: /home/vitor/tensorflow/tensorflow/contrib/boosted_trees/proto/BUILD:25:1: Target '@protobuf_archive//:protobuf_python' contains an error\r\n and its package is in error and referenced by '//tensorflow/contrib/boosted_trees/proto:split_info_proto_py'\r\nERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: Analysis failed\r\nINFO: Elapsed time: 8.874s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (166 packages loaded, 2541 targets configured)\r\n    currently loading: tensorflow/core/kernels ... (3 packages)\r\n    Fetching @org_sqlite; fetching\r\n    Fetching @swig; fetching\r\n    Fetching @absl_py; fetching\r\n    Fetching @com_google_absl; fetching\r\n    Fetching @nsync; fetching\r\n```\r\n\r\n**Any other info / logs**\r\n\r\nI've looked around for this error and I haven't found anything. Closest I got is https://github.com/tensorflow/tensorflow/issues/17709 which seems completely unrelated. I'm following [the documentation](https://www.tensorflow.org/install/source) ipsis litteris and I know nothing of the internals of TensorFlow so the error doesn't give me any clue as to what I can do.", "comments": ["Related: after this I checked out the master branch (as of 62eec96637f0d7c4cf3493a676fada4a2b903821) and successfully built TensorFlow. The only thing I changed was I ran `./configure` again with a virtualenv activated. I'll try rebuilding the v1.12.0 tag.\r\n\r\nI'm kinda surprised that I failed with a release and succeeded with a random commit on the master branch, but this might be relevant information.", "@vdemario Could you follow the instructions [here](https://github.com/rnreich/ubuntu-tensorflow-gpu-all-versions) and let us know how it works. I recently used those steps and successfully installed tensorflow-gpu. Specifically, I followed instructions till git clean -xdf. After that I ran the following commands\r\nsudo pip3 install numpy\r\nsudo pip3 install --upgrade tensorflow-gpu\r\n\r\nIt worked for me. No issues. Thanks!", "@jvishnuvardhan this is going to be very useful on another environment where I'm trying to build tensorflow-gpu and failing but in this scenario I'm actually building for cpu, not gpu. Do you recommend I try starting from the _install bazel 0.8.0_ part and skip everything before that?", "I am getting a similar \"builtin variable 'REPOSITORY_NAME' is referenced before assignment.\" error, only on Mac, and not for tensorflow-gpu, but regular tensorflow.\r\n\r\n$ bazel version\r\nINFO: Invocation ID: 60e05d85-7949-45e0-af23-3be9a9a2b9b4\r\nBuild label: 0.22.0\r\nBuild target: bazel-out/darwin-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Mon Jan 28 13:00:18 2019 (1548680418)\r\nBuild timestamp: 1548680418\r\nBuild timestamp as int: 1548680418\r\n", "@vdemario Actually sudo pip3 install --upgrade tensorflow worked for me for CPU version of TF. You might try \r\nsudo apt-get update && sudo apt-get upgrade\r\nsudo ubuntu-drivers autoinstall\r\nsudo reboot\r\nsudo apt-get install python3-dev python3-pip\r\nsudo pip3 install numpy\r\nsudo pip3 install --upgrade tensorflow\r\nsudo pip3 install pandas keras\r\n\r\nPlease let me know how it goes. Thanks!", "It's not a matter of installing the prebuilt binary, that won't work for my old CPU.\r\n\r\nSee this issue: https://github.com/tensorflow/tensorflow/issues/19584. The title of the issue explains my situation perfectly:\r\n\r\n> Prebuilt binaries do not work with CPUs that do not have AVX instruction sets.\r\n\r\nOn that same issue the official recommendation is:\r\n\r\n> Our recommendation is to build TF from sources on these systems.\r\n\r\nThat's what I'm trying to do.\r\n\r\nI'm building on a system with a Xeon E5540. According to _/proc/cpuinfo_ these are the flags available:\r\n\r\n> flags           : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx est tm2 ssse3 cx16 xtpr pdcm dca sse4_1 sse4_2 popcnt lahf_lm pti tpr_shadow vnmi flexpriority ept vpid dtherm ida\r\n\r\nMy issue is by following the [official docs for building TensorFlow from source](https://www.tensorflow.org/install/source), I can't get the compilation to work on release v1.12, with the error I reported originally. I can compile successfully with the code on master, see https://github.com/tensorflow/tensorflow/issues/25490#issuecomment-460387311.", "I think this is a problem of having a \"too new\" version of bazel.\r\nYou can try 1.13 branch with bazel 0.22, or downgrade bazel to the version we tested here:\r\nhttps://www.tensorflow.org/install/source#tested_build_configurations", "Similar error happens: \"builtin variable 'REPOSITORY_NAME' is referenced before assignment\". I am working on MacOS Majove 10.14.2 with bazel of 0.22.0 and Tensorflow r1.9. The compiling command I used is \"bazel build -c dbg //tensorflow/tools/pip_package:build_pip_package\", and the error messages are detailed below:\r\n\r\nERROR: /private/var/tmp/_bazel_sam/870243a2e9f6c8f6d71c0be6efaf0c54/external/protobuf_archive/BUILD:600:1: Traceback (most recent call last):\r\n\tFile \"/private/var/tmp/_bazel_sam/870243a2e9f6c8f6d71c0be6efaf0c54/external/protobuf_archive/BUILD\", line 600\r\n\t\tinternal_gen_well_known_protos_java(srcs = WELL_KNOWN_PROTOS)\r\n\tFile \"/private/var/tmp/_bazel_sam/870243a2e9f6c8f6d71c0be6efaf0c54/external/protobuf_archive/protobuf.bzl\", line 266, in internal_gen_well_known_protos_java\r\n\t\tLabel((\"%s//protobuf_java\" % REPOSITOR...))\r\n\tFile \"/private/var/tmp/_bazel_sam/870243a2e9f6c8f6d71c0be6efaf0c54/external/protobuf_archive/protobuf.bzl\", line 266, in Label\r\n\t\tREPOSITORY_NAME\r\nbuiltin variable 'REPOSITORY_NAME' is referenced before assignment.\r\nERROR: /private/var/tmp/_bazel_sam/870243a2e9f6c8f6d71c0be6efaf0c54/external/protobuf_archive/BUILD:383:1: Target '@protobuf_archive//:android' contains an error and its package is in error and referenced by '@protobuf_archive//:protoc'\r\nERROR: /private/var/tmp/_bazel_sam/870243a2e9f6c8f6d71c0be6efaf0c54/external/protobuf_archive/BUILD:383:1: Target '@protobuf_archive//:windows' contains an error and its package is in error and referenced by '@protobuf_archive//:protoc'\r\nERROR: /private/var/tmp/_bazel_sam/870243a2e9f6c8f6d71c0be6efaf0c54/external/protobuf_archive/BUILD:383:1: Target '@protobuf_archive//:windows_msvc' contains an error and its package is in error and referenced by '@protobuf_archive//:protoc'\r\nERROR: /Users/sam/workspace/tensorflow_decent_1.9/tensorflow/core/profiler/BUILD:39:1: Target '@protobuf_archive//:protobuf_python_genproto' contains an error and its package is in error and referenced by '//tensorflow/core/profiler:protos_all_py_genproto'\r\nERROR: /Users/sam/workspace/tensorflow_decent_1.9/tensorflow/core/profiler/BUILD:39:1: Target '@protobuf_archive//:protoc' contains an error and its package is in error and referenced by '//tensorflow/core/profiler:protos_all_py_genproto'\r\nERROR: /Users/sam/workspace/tensorflow_decent_1.9/tensorflow/core/profiler/BUILD:39:1: Target '@protobuf_archive//:protobuf_python' contains an error and its package is in error and referenced by '//tensorflow/core/profiler:protos_all_py'\r\nERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: Analysis failed", "Again, you are using a too new version of bazel on an old branch.\r\nPlease see here:\r\nhttps://www.tensorflow.org/install/source#tested_build_configurations", "I downgraded bazel to 0.15 and the 1.12.0 compilation worked. Thanks @gunan!\r\n\r\nI think this should be made more clear on https://www.tensorflow.org/install/source but that's another discussion and I'll open an issue on https://github.com/tensorflow/docs for that.\r\n\r\nFor those having similar issues, I can share the wheel if you'd like, let me know.", "@vdemario Great. If possible post here the steps you followed to resolve this issue so that community get benefited. Thanks!", "Thanks for verifying @vdemario \r\nIn latest versions, we are adding a maximum bazel version check to avoid such issues.\r\nSorry for the inconvenience, and thank you very much for your patience.", "@jvishnuvardhan Sure, here's what I did:\r\n\r\n```\r\n# remove bazel 0.22\r\nrm -rf ~/.bazel\r\n\r\n# download bazel 0.15\r\nwget https://github.com/bazelbuild/bazel/releases/download/0.15.0/bazel-0.15.0-installer-linux-x86_64.sh\r\n\r\n# install bazel 0.15\r\nchmod u+x bazel-0.15.0-installer-linux-x86_64.sh\r\n./bazel-0.15.0-installer-linux-x86_64.sh --user\r\n\r\n# checkout release 1.12.0\r\ncd tensorflow\r\ngit checkout v1.12.0\r\n\r\n# clean up\r\ngit clean -xdf\r\nbazel shutdown\r\nbazel clean\r\n\r\n# compile\r\n./configure\r\nbazel build --config=opt //tensorflow/tools/pip_package:build_pip_package --incompatible_remove_native_http_archive=false --verbose_failures --\r\ncxxopt=\"-D_GLIBCXX_USE_CXX11_ABI=0\"\r\n./bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg\r\n```\r\n\r\nSome of these flags or directory paths need to be adjusted depending on each person's configuration.", "@vdemario Thanks for taking time to post all the steps. I am sure community will get benefited. Thanks again!", "Are you satisfied with the resolution of your issue?\r\n[Yes](https://goo.gl/forms/Oe0tEvODFRoI2gJF3)\r\n[No](https://goo.gl/forms/fUjzOfrtkFbrOT8d2)", "@gunan Thanks for your useful info, I downgraded bazel to 0.11.0 for TF r1.9, and the issue's solved. But a new error appears, could you please give me some advice? The error message is shown as below.\r\n\r\nERROR: /private/var/tmp/_bazel_sam/870243a2e9f6c8f6d71c0be6efaf0c54/external/protobuf_archive/BUILD:259:1: **undeclared inclusion(s) in rule '@protobuf_archive//:js_embed'**:\r\nthis rule is missing dependency declarations for the following files included by 'external/protobuf_archive/src/google/protobuf/compiler/js/embed.cc':\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/assert.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/cdefs.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_symbol_aliasing.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_posix_availability.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/stdlib.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/Availability.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/AvailabilityInternal.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/_types.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_types.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/machine/_types.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/i386/_types.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_pthread/_pthread_types.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/wait.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_pid_t.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_id_t.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/signal.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/appleapiopts.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/machine/signal.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/i386/signal.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/machine/_mcontext.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/i386/_mcontext.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/mach/machine/_structs.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/mach/i386/_structs.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/machine/types.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/i386/types.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_int8_t.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_int16_t.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_int32_t.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_int64_t.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_u_int8_t.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_u_int16_t.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_u_int32_t.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_u_int64_t.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_intptr_t.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_uintptr_t.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_pthread/_pthread_attr_t.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_sigaltstack.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_ucontext.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_sigset_t.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_size_t.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_uid_t.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/resource.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/stdint.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/_types/_uint8_t.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/_types/_uint16_t.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/_types/_uint32_t.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/_types/_uint64_t.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/_types/_intmax_t.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/_types/_uintmax_t.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_timeval.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/machine/endian.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/i386/endian.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_endian.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/libkern/_OSByteOrder.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/libkern/i386/_OSByteOrder.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/alloca.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_ct_rune_t.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_rune_t.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_wchar_t.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_null.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/malloc/_malloc.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_dev_t.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_mode_t.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/wchar.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_mbstate_t.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/stdio.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/_stdio.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_va_list.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/stdio.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_off_t.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_ssize_t.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/time.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_clock_t.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_time_t.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_timespec.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/_wctype.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/__wctype.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_wint_t.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/_types/_wctype_t.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/ctype.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/_ctype.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/runetype.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/string.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/strings.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/wctype.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/_types/_wctrans_t.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/limits.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/machine/limits.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/i386/limits.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/i386/_limits.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/syslimits.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/errno.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/errno.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/pthread.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/pthread/pthread_impl.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/pthread/sched.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_pthread/_pthread_cond_t.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_pthread/_pthread_condattr_t.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_pthread/_pthread_key_t.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_pthread/_pthread_mutex_t.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_pthread/_pthread_mutexattr_t.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_pthread/_pthread_once_t.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_pthread/_pthread_rwlock_t.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_pthread/_pthread_rwlockattr_t.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_pthread/_pthread_t.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/pthread/qos.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/qos.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_mach_port_t.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/locale.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/_locale.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/xlocale.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/_xlocale.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/xlocale/_ctype.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/xlocale/__wctype.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/xlocale/_stdio.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/xlocale/_stdlib.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/xlocale/_string.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/xlocale/_time.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/xlocale/_wchar.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/xlocale/_wctype.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/nl_types.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/types.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_u_char.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_u_short.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_u_int.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_caddr_t.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_blkcnt_t.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_blksize_t.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_gid_t.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_in_addr_t.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_in_port_t.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_ino_t.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_ino64_t.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_key_t.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_nlink_t.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_useconds_t.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_suseconds_t.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_rsize_t.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_errno_t.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_fd_def.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_fd_setsize.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_fd_set.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_fd_clr.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_fd_zero.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_fd_isset.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_fd_copy.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_fsblkcnt_t.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/_types/_fsfilcnt_t.h'\r\n  '/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/_types/_nl_item.h'"]}, {"number": 25489, "title": "Change version to 1.13.0-rc1", "body": "", "comments": []}, {"number": 25488, "title": "import_meta_graph raises KeyError: InfeedEnqueueTuple when importing a graph trained on TPU", "body": "Function `import_meta_graph` fails with `KeyError: InfeedEnqueueTuple` when importing a meta file of a graph trained on TPU (and with `TPUEstimator`). For graphs trained on CPU (also with `TPUEstimator`) it works correctly. Is this expected behaviour? How can I load a graph with parameters trained on TPU for CPU evaluation?\r\n\r\nI noticed a similar error also related to TPU in another Github project, but no solution: https://github.com/tensorflow/minigo/issues/426.\r\n\r\n**System information**\r\n- Reproduced on MacOS and on Colab.\r\n- tensorflow 1.12.0 (from PyPI)\r\n- Python 3.6\r\n- CUDA/cuDNN/GPU not used\r\n\r\n**Describe the current behavior**\r\nRaises exception `KeyError: InfeedEnqueueTuple`.\r\n\r\n**Describe the expected behavior**\r\nShould load the graph without an exception.\r\n\r\n**Code to reproduce the issue**\r\n```\r\n tf.train.import_meta_graph(META_PATH, clear_devices=True)\r\n```\r\nwhere `META_PATH` is a path to a meta file saved with `TPUEstimator`.\r\n\r\n**Other info / logs**\r\nFull traceback:\r\n```\r\n---------------------------------------------------------------------------\r\n\r\n\r\nKeyError                                  Traceback (most recent call last)\r\n\r\n\r\n<ipython-input-9-962933bf6153> in <module>()\r\n      1 \r\n----> 2 tf.train.import_meta_graph(META_PATH, clear_devices=True)\r\n\r\n\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py in import_meta_graph(meta_graph_or_file, clear_devices, import_scope, **kwargs)\r\n   1672   \"\"\"  # pylint: disable=g-doc-exception\r\n   1673   return _import_meta_graph_with_return_elements(\r\n-> 1674       meta_graph_or_file, clear_devices, import_scope, **kwargs)[0]\r\n   1675 \r\n   1676 \r\n\r\n\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py in _import_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs)\r\n   1694           import_scope=import_scope,\r\n   1695           return_elements=return_elements,\r\n-> 1696           **kwargs))\r\n   1697 \r\n   1698   saver = _create_saver_from_imported_meta_graph(\r\n\r\n\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/meta_graph.py in import_scoped_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate, return_elements)\r\n    804         input_map=input_map,\r\n    805         producer_op_list=producer_op_list,\r\n--> 806         return_elements=return_elements)\r\n    807 \r\n    808     # Restores all the other collections.\r\n\r\n\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py in new_func(*args, **kwargs)\r\n    486                 'in a future version' if date is None else ('after %s' % date),\r\n    487                 instructions)\r\n--> 488       return func(*args, **kwargs)\r\n    489     return tf_decorator.make_decorator(func, new_func, 'deprecated',\r\n    490                                        _add_deprecated_arg_notice_to_docstring(\r\n\r\n\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/importer.py in import_graph_def(graph_def, input_map, return_elements, name, op_dict, producer_op_list)\r\n    389   if producer_op_list is not None:\r\n    390     # TODO(skyewm): make a copy of graph_def so we're not mutating the argument?\r\n--> 391     _RemoveDefaultAttrs(op_dict, producer_op_list, graph_def)\r\n    392 \r\n    393   graph = ops.get_default_graph()\r\n\r\n\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/importer.py in _RemoveDefaultAttrs(op_dict, producer_op_list, graph_def)\r\n    156     # Remove any default attr values that aren't in op_def.\r\n    157     if node.op in producer_op_dict:\r\n--> 158       op_def = op_dict[node.op]\r\n    159       producer_op_def = producer_op_dict[node.op]\r\n    160       # We make a copy of node.attr to iterate through since we may modify\r\n\r\nKeyError: 'InfeedEnqueueTuple'\r\n```", "comments": ["Hello @mluszczyk!\r\n\r\nThanks for your bug report, but this is known and not really considered a bug right now.\r\n\r\nDuring training, TensorFlow doesn't guarantee that the TensorFlow graph stored with the checkpoints can be used elsewhere. Your scenario would also not work if you trained with multi-GPUs using GPU specific ops like NCCL AllReduce.\r\n\r\nIf you want to export a model that can be imported by others, you should use one of the export functions, e.g. (TPU)Estimator.export_savedmodel().\r\n\r\nThanks!\r\n\r\nFrank"]}]