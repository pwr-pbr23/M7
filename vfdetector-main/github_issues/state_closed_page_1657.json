[{"number": 3195, "title": "Documentation of Session arguments seems outdated", "body": "In [README.md](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/public/README.md) a session is created as `tf.Session(\"local\")`. At the same time, the [docstring](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/client/session.py#L888) says \"no value other than an empty string is supported\". This is clearly an inconsistency.\n", "comments": ["The documentation is incorrect. You should probably be using tf.Session() most of the time. so we will updates the tf.Session() docstring as well ad the README.md.\nSee here for another example https://www.tensorflow.org/versions/r0.9/how_tos/distributed/index.html.\n"]}, {"number": 3194, "title": "[install error] install failed on RedHat ", "body": "In large scale cluster,  Entherprise RedHat system is mainstream distribution branch, and its always encounter a low version of kernel and libc problem.  There  several similar issue in this project.  I'm wondering that\n1  is there any method to build tensorflow offline? \n2  how can I build tensorflow cc part as static library instead of shared library. \n3  is there any way to pay a cheap price to replace the bazel build tool?  Here we encounter a build tool bug.\nhttps://github.com/bazelbuild/bazel/issues/1474, which had been labeled as a bug in bazel, is there any alternative method?\n\nThanks\nSystem info:\n\n```\n(gcc version 4.4.4 20100726 (Red Hat 4.4.4-13) (GCC) )\nldd --version\nldd  2.18\n```\n", "comments": ["You did not specify what version of RedHat you are using (Please paste cat /etc/issue or cat /etc/redhat-release). But judging from the gcc version 4.4.4, I am guessing it is RHEL6.x. Bazel itself is not supported on less than RHEL/CentOS 7. Others have managed to get it to work by changing Bazel's source significantly, but this is not supported).\n1. I don't understand what this means? You could install the same operating system in a VM on your local machine and build tensorflow there.\n2. probably not easily. you'd need to build a python binary replacement, because otherwise all modules are typically brought in as dso's\n3. we are unlikely to support other build systems other than bazel in the long-term or near-term. \n", " as you guessed, release version is RHEL6.3, actually .\n1. this is a problem in fact, because our cluster is offline, which means the cluster physical isolation with internet. And bazel clone a lot of dependency files from elsewhere.\n   I use tensorflow smoothly on my workstation, but when it comes to company level cluster envrionment, Since the building tool system do not support linux version lower RHEL/CentOS 7,  we really need to port tensorflow to other buiding tools.\n\nIt seems the best solving method is build tensorflow in VM env, then pack it and distribute.\n\nBecause i will going to test tensorflow in cluster,  \n", "The simplest easiest way to deploy tensorflow is probably through docker or virtual machine. People do get it to work on older clusters, and if you search around issues you might find the solution to your problem. But it will not be easy. Good luck!\n", "We now have cmake support under contrib. So you may be able to use that.\r\nAs for offline build support, I am not sure but I guess you can build a pip package on a machine with internet access and deploy that on other machines.", "https://github.com/tensorflow/tensorflow/issues/7118\r\n\r\nWe were able to get TensorFlow build on RHEL6. Looks like you need to make some local changes, but things seem to build fine. I will close this issue to merge the discussion on the other thread, which currently has a solution."]}, {"number": 3193, "title": "AttributeError: 'LinearClassifier' object has no attribute 'save'", "body": "### Environment info\n\nOperating System:\nOS X 10.11.5\n\nInstalled version of CUDA and cuDNN: \n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\nNA\n\nIf installed from binary pip package, provide:\n1. Which pip package you installed.\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\n\nTensor Flow verison: `0.9`\n\nIf installed from sources, provide the commit hash:\nCommit Hash:`70de76e696c21da617fd2e6435cf7fedab220db8`\n### Steps to reproduce\n1. Run the example commands give at [sklearn doc](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/learn/python/learn#linear-classifier)\n2. Try to save the model with .save() function [sklearn doc](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/learn/python/learn#saving--restoring-models)\n### What have you tried?\n1. I tried using `tf.train.Saver()` but I guess it can save the session but not the classifier.\n### Logs or other output that would be helpful\n\n(If logs are large, please upload as attachment).\n\n``` python\nPython 2.7.10 (default, Oct 23 2015, 19:19:21) \n[GCC 4.2.1 Compatible Apple LLVM 7.0.0 (clang-700.0.59.5)] on darwin\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>> import tensorflow.contrib.learn as learn\n>>> from sklearn import datasets, metrics\n>>> iris = datasets.load_iris()\n>>> classifier = learn.LinearClassifier(n_classes=3)\n>>> classifier.fit(iris.data, iris.target, steps=200, batch_size=32)\nLinearClassifier()\n>>> classifier.save('/tmp/tf_examples/my_model_1/')\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nAttributeError: 'LinearClassifier' object has no attribute 'save'\n>>> import tensorflow as tf\n>>> saver = tf.train.Saver()\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"/Users/Vijay/Library/Python/2.7/lib/python/site-packages/tensorflow/python/training/saver.py\", line 837, in __init__\n    raise ValueError(\"No variables to save\")\nValueError: No variables to save\n>>> \n```\n", "comments": ["Correct me if I'm wrong @martinwicke, I believe that if you specify model_dir to the classifier constructor, you will get an autosaved model i.e.\n\n``` python\nimport tensorflow.contrib.learn as learn\n\ndef input_fn():\n    foo=tf.constant([1.,2.,3.])\n    bar=tf.constant([0,1,0])\n    return {\"x\":foo}, bar\nclassifier = learn.LinearClassifier(n_classes=3,model_dir=\"/tmp/cool-awesome-model\")\nclassifier.fit(input_fn=input_fn, steps=200)\n\n```\n\nLet me know if this fixes your issue.\n", "Thanks @aselle. Providing model_dir parameter to the classifier worked. It saved 8 files in a folder. I was expecting one `.ckpt` file.\nHow do I restore this classifier? `learn.Estimator.restore()` does not work. \n", "Right now that's a bit of a mess. Provide the same model_dir, call fit\nagain (you can pass max_steps to prevent it from actually doing anything),\nthen predict should work.\n\nWe're working on re-enabling proper save/restore.\nOn Sat, Jul 9, 2016 at 01:51 Vijayenthiran Subramaniam <\nnotifications@github.com> wrote:\n\n> Thanks @aselle https://github.com/aselle. Providing model_dir parameter\n> to the classifier worked. It saved 8 files in a folder. I was expecting one\n> .ckpt file.\n> How do I restore this classifier? learn.Estimator.restore() does not\n> work.\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/3193#issuecomment-231523945,\n> or mute the thread\n> https://github.com/notifications/unsubscribe/AAjO_d6eGqrswPhGqnltM4tmG9kTKIXMks5qT2EXgaJpZM4JE_bs\n> .\n", "@martinwicke Pardon my daftness, `classifier.fit()` doesn't seems to accept `max_steps` are parameter. Can you provide an example?\n", "Oh sorry. That is at master but not in 0.9. You should be able to use the\nsteps argument. Just be warned that we're in the process of changing this.\nOn Sat, Jul 9, 2016 at 08:47 Vijayenthiran Subramaniam <\nnotifications@github.com> wrote:\n\n> @martinwicke https://github.com/martinwicke Pardon my daftness,\n> classifier.fit() doesn't seems to accept max_steps are parameter. Can you\n> provide an example?\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/3193#issuecomment-231540743,\n> or mute the thread\n> https://github.com/notifications/unsubscribe/AAjO_fIEnnV4nogtgRygnGREMnzE2tBcks5qT8JygaJpZM4JE_bs\n> .\n", "Will be good if these are updated in the docs. :)\n", "Since Martin has provided the workaround, I am closing this.  (Please feel free to file a separate issue about updating the docs; although as already mentioned this code path is in heavy development now.)\n"]}, {"number": 3192, "title": "R0.9", "body": "", "comments": ["Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "This PR looks like misoperation. I'm closing it.\n"]}, {"number": 3191, "title": "iOS build breaks", "body": "git rev-parse HEAD\n70de76e696c21da617fd2e6435cf7fedab220db8\n\nld: symbol(s) not found for architecture x86_64\nclang: error: linker command failed with exit code 1 (use -v to see invocation)\nmake: **\\* [/Users/Shared/Develop/google/tensorflow/tensorflow/contrib/makefile/gen/host_bin/proto_text] Error 1\n- '[' 2 -ne 0 ']'\n- echo 'armv7 compilation failed.'\n  armv7 compilation failed.\n- exit 1\n\nThe rest of the output is here:\n\nhttps://gist.github.com/john-difool/67126c4ccf5d8201cd1842ca18acc78b\n", "comments": ["tensorflow/contrib/makefile/compile_ios_protobuf.sh PASSED\nmake -f tensorflow/contrib/makefile/Makefile TARGET=IOS IOS_ARCH=ARM64   FAILS\n", "I met the same problem\n", "How did you fix this issue?\n", "encounter the same issue.\n", "I have a pending fix in PR #3253. It was caused by an error in the ordering of header and library paths, so the build would pull from global /usr/local installations of different versions of the protobuf library, which didn't match the results from the locally-built protoc.\n", "can work, cool!\n"]}, {"number": 3190, "title": "How does wide_n_deep model support install app columns?", "body": "wide_n_deep model in paper [1] support embedding for users' installed app features. \nBut in wide_n_deep.py and feature_column.py, I haven't find something about supporting embedding for users' installed app features, which trains embedding jointly for multi-columns.\nDo I miss anything? or misunderstanding  \n\n[1] Wide & Deep Learning for Recommender Systems @moonboots \n", "comments": ["I figure out a simple way, define a IdenticalSparseColumn(_SparseColumn), and transform data into multi-column SparseTensor in data preparation\n\n```\n1 import tensorflow as tf\n```\n\n  2 from tensorflow.python.framework import dtypes\n  3 from tensorflow.contrib.layers import feature_column\n  4\n  5\n  6 class IdenticalSparseColumn(feature_column._SparseColumn):\n  7   \"\"\"Identical sparse column to support transformation in data layer\"\"\"\n  8\n  9   def __new__(cls, column_name, bucket_size, combiner=\"sum\"):\n 10\n 11     return super(IdenticalSparseColumn, cls).**new**(cls,\n 12                                                    column_name,\n 13                                                    bucket_size=bucket_size,\n 14                                                    combiner=combiner,\n 15                                                    dtype=dtypes.int32)\n 16\n 17   def insert_transformed_feature(self, columns_to_tensors):\n 18     \"\"\"Handles sparse column to id conversion.\"\"\"\n 19     columns_to_tensors[self] = columns_to_tensors[self.name]\n\nand preprocessing data into SparseTensor\n"]}, {"number": 3189, "title": "Update README.md", "body": "Add more detail on required project changes to include TensorFlow support.\n", "comments": ["Can one of the admins verify this patch?\n", "@tensorflow-jenkins test this please\n", "//tensorflow/contrib/learn:export_test failed. I'm not sure how this commit could cause that. Is it a flaky test?\n", "@dauba-dauba yeah it should be fixed now. @tensorflow-jenkins test this please\n", "Pete can you take a look?\n", "These updates look good to me, thanks @dauba-dauba!\n"]}, {"number": 3188, "title": "BasicLSTMCell __call__ fails. ", "body": "### Environment info\n\nOperating System: \nOSX Yosemite 10.10.5\n\nIf installed from binary pip package, provide:\n1. Which pip package you installed: CPU only mac-version\n2. The output from `python -c \"import tensorflow; print(tensorflow.**version**)\": 0.9.0rc0\n\nI've been getting a strange error when trying to use the BasicLSTM cell. Running the below code:\n\n```\nimport tensorflow as tf\n\nsess =  tf.Session()\ninit_state = tf.zeros([32, 6])\ninit_state2 = tf.zeros([32, 6])\ninput = tf.placeholder(tf.float32, [32, 10])\ninput2 = tf.placeholder(tf.float32, [32, 10])\nprint init_state.get_shape()\noutput, state = tf.nn.rnn_cell.BasicLSTMCell(3)(input, init_state)\noutput2, state2 = tf.nn.rnn_cell.BasicLSTMCell(3)(input2, init_state2)\n```\n\nresults in a ValueError:\n\n```\nValueError: Variable BasicLSTMCell/Linear/Matrix already exists, disallowed. Did you mean to set reuse=True in VarScope? Originally defined at:\noutput, state = tf.nn.rnn_cell.BasicLSTMCell(3)(input, init_state)\n```\n\nthe error doesn't occur if the line generating `(output2, state2)` is omitted. \n", "comments": ["I think each lstm cell should be defined in it's own named scope.\n\n```\nwith tf.variable_scope('lstm1'):\n  output, state = tf.nn.rnn_cell.BasicLSTMCell(3)(input, init_state)\nwith tf.variable_scope('lstm2'):\n  output2, state2 = tf.nn.rnn_cell.BasicLSTMCell(3)(input2, init_state2)\n```\n", "Thank you for the response @ajaech. That should prevent the name conflict. @chrisgrimm  please close the issue if this solved your problem.\n", "Thanks for clearing this up! \n"]}, {"number": 3187, "title": "fixed link to tensorboard readme in image retraining how-to", "body": "I noticed my update to the image retraining how-to had a broken link to the TensorBoard README when viewing the content at https://www.tensorflow.org/versions/master/how_tos/image_retraining/index.html#visualizing-the-retraining-with-tensorboard. Therefore, I updated the relative link to be an absolute link so people will be able to browse to it regardless of which page they're viewing the tutorial (tensorflow.org or github).\n", "comments": ["Can one of the admins verify this patch?\n", "@tensorflow-jenkins test this please\n", "Martin what's the correct way to link to the source tree in READMEs so that it works in both github and on the website (tensorflow.org) ?\n", "Prepend https://www.tensorflow.org/code/ to the path inside the repo:\n\nhttps://www.tensorflow.org/code/README.md for example is the top-level readme.\n", "Thanks @vrv @martinwicke! I updated the link for the Tensorboard README to be https://www.tensorflow.org/code/tensorflow/tensorboard/README.md per Martin's guidance. Let me know if you need anything else!\n"]}, {"number": 3186, "title": "Insufficient alignment in u_ union in tensorflow/core/lib/gtl/inlined_vector.h", "body": "### Environment info\n\nOperating System: Linux\n\nInstalled version of CUDA and cuDNN: None\n\nIf installed from sources, provide the commit hash: aa2cacd6627ffb296bedc910c957a0fd4a2f957f\n### Steps to reproduce\n1. Find an architecture with 32 bit pointers but strict alignment requirements for 64 bit\n2. Compile and run \"benchmark\" from tensorflow/contrib/makefile\n3. Get bus error from misaligned pointer\n### What have you tried?\n1. Fixing the issue by increasing the u_ alignment.  This works.\n\nIn tensorflow/core/lib/gtl/inlined_vector.h, the data buf is aligned by adding a pointer.  However, it is cast to other types, including uint64_t.  On architectures where pointers are 32 bits, this cast causes errors.\n\nThe fix is to add another component to the union that will force alignment to the largest size, such as uint64_t.\n\nFor example:\n\ndiff --git a/tensorflow/core/lib/gtl/inlined_vector.h b/tensorflow/core/lib/gtl/inlined_vector.h\nindex e8fe66c..518b421 100644\n--- a/tensorflow/core/lib/gtl/inlined_vector.h\n+++ b/tensorflow/core/lib/gtl/inlined_vector.h\n@@ -276,6 +276,8 @@ class InlinedVector {\n     unsigned char data[kSize];\n     // Force data to be aligned enough for a pointer.\n     T\\* unused_aligner;\n-    // EJP: force 8 byte alignment, as pointers could be 4-byte but data elements 8-byte?\n-    uint64_t unused_64;\n  } u_;\n\nYou won't see this issue on architectures where pointers are the size of the largest type (aarch64, x86-64) or where a 32-bit architecture loads 64-bit things but can do so at arbitrary 32-bit boundaries (x86, armv7 with misaligned pointers enabled).  \n\nBut it might improve performance to have 64-bit values on 64-bit boundaries.\n", "comments": ["What you're saying makes sense. What are some example processor architectures with this property? It's unlikely we are going to support it, but we would be open to a patch that detects this property in a architecture and does this alignment only when necessary. You indicate it might improve performance to do this extra alignment but it actually also might hurt performance, and without testing we are hesitant to make such a change. Adding @vrv to comment.\n", "Some ARM variants will give an exception on misaligned LDRD (but some do\nnot, especially if misaligned support is enabled in ARMv7).\n\nYou'd probably have a problem if someone used the buffer for a double\nprecision value on many targets that don't support misaligned loads and\nstores (MIPS, ARM)\n\nSorry, my patch got formatted by github:\n\n# \n\ndiff --git a/tensorflow/core/lib/gtl/inlined_vector.h\nb/tensorflow/core/lib/gtl/inlined_vector.h\nindex e8fe66c..518b421 100644\n--- a/tensorflow/core/lib/gtl/inlined_vector.h\n+++ b/tensorflow/core/lib/gtl/inlined_vector.h\n@@ -276,6 +276,8 @@ class InlinedVector {\n     unsigned char data[kSize];\n     // Force data to be aligned enough for a pointer.\n     T\\* unused_aligner;\n-    // EJP: force 8 byte alignment, as pointers could be 4-byte but data\n  elements 8-byte\n-    uint64_t unused_64;\n  } u_;\n  \n  # inline void InitRep() { u_.data[kSize - 1] = 0; }\n\nBasically a one-liner: since a 64-bit value could go into the data (by\ncast), you put a 64-bit value into the union to ensure alignment.\n\nOn Thu, Jul 7, 2016 at 11:42 AM, Andrew Selle notifications@github.com\nwrote:\n\n> What you're saying makes sense. What are some example processor\n> architectures with this property? It's unlikely we are going to support it,\n> but we would be open to a patch that detects this property in a\n> architecture and does this alignment only when necessary. You indicate it\n> might improve performance to do this extra alignment but it actually also\n> might hurt performance, and without testing we are hesitant to make such a\n> change. Adding @vrv https://github.com/vrv to comment.\n> \n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/3186#issuecomment-231136191,\n> or mute the thread\n> https://github.com/notifications/unsubscribe/ABkOanmmqCpZ4crPg83EvlyqGFA_-GfRks5qTSx9gaJpZM4JEg_y\n> .\n", "Created pull request with fix, #3237 \n"]}, {"number": 3185, "title": "Udacity Notebook with \"None\" kernel", "body": "I use Jupyter notebook to open the .ipynb files, but it shows a red \"None\" kernel on top right corner and all lines of code cannot run. \n\nMethod I use:\n1. Build a new directory and extract .ipynb files from `examples/udacity` to the directory\n2. In terminal, run `jupyter notebook`\n", "comments": ["You haven't provided sufficient information for us to help. The new issue template provides a list of information we need to help. It sounds like a installation problem where jupyter installation or tensorflow installation. If you see indication of a bug in tensorflow, please reopen.\n"]}, {"number": 3184, "title": "Configure script attemps to seek for libcudart.so in wrong path", "body": "Hi! I'm trying to configure build for cuda utilization. When I answer the question \n\n> Please specify the location where CUDA  toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: /usr/lib/x86_64-linux-gnu/libcudart.so\n\ni get the following error:\n\n> Invalid path to CUDA  toolkit. /usr/lib/x86_64-linux-gnu/**lib64**/libcudart.so cannot be found\n\nbut i have cuda installed in:\n\n> $ ll /usr/lib/x86_64-linux-gnu/libcudart.so\n> lrwxrwxrwx 1 root root 16 \u043c\u0430\u0440 30 15:25 /usr/lib/x86_64-linux-gnu/libcudart.so -> libcudart.so.7.5\n\nThis happens because of the following code in `configure` file:\n\n```\n  if [ \"$OSNAME\" == \"Linux\" ]; then\n    CUDA_RT_LIB_PATH=\"lib64/libcudart.so${TF_CUDA_EXT}\"\n\n```\n\nWhy it tries to look for cuda installation in `lib64` subdirectory? I think make me to symlink /usr/lib/**lib64**/ -> /usr/lib/**x86_64-linux-gnu**/ is cruel.\n\nForgot. My system is Ubuntu 16.04:\n\n> $ uname -a\n> Linux user-desktop 4.4.0-28-generic #47-Ubuntu SMP Fri Jun 24 10:09:13 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux\n", "comments": ["Most users install CUDA using the .sh run scripts NVIDIA provides. I assume you used a different installation method. We can't support every permutation of install methods for NVIDIA drivers, so we have chosen the way most people tend to do it, because usually people directly download from NVIDIA to get the most up to date driver. Hopefully doing such will solve your problem without the need to symlink. \n", "Yes, I think you're right. Preferred installation method solved my problem. My bad, thank you. I think you may close the issue...\n"]}, {"number": 3183, "title": "Implement tf-slim from tensorflow/models.", "body": "Feature request: Implement tf-slim from `tensorflow/models` into `tensorflow/tensorflow`.\nSee requests from models: https://github.com/tensorflow/models/issues/186, https://github.com/tensorflow/models/issues/203. Maybe mark for 0.9 as suggested by @sguada?\n", "comments": ["It is already part of 'master' take a look at contrib/slim, we plan to include more docs, nets, examples and make it part of 0.9.1\nMore updates would come for the 0.10\n", "Does this address your need @TimZaman? If so I will close this bug.\n"]}, {"number": 3182, "title": "Fixing typos", "body": "", "comments": ["Can one of the admins verify this patch?\n", "@tensorflow-jenkins test this please\n"]}, {"number": 3181, "title": "tf.initialize_variables fails on missing Tensor initializer attribute", "body": "### Environment info\n\nOperating System: `Ubuntu 14.04.4`\n\nInstalled version of CUDA and cuDNN:  CUDA 7.5 and cuDNN 4.0.7\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\n\n``` bash\nls -l /usr/local/cuda-7.5/lib64/libcud*\n-rw-r--r-- 1 root root    322936 Aug 15  2015 /usr/local/cuda-7.5/lib64/libcudadevrt.a\nlrwxrwxrwx 1 root root        16 Aug 15  2015 /usr/local/cuda-7.5/lib64/libcudart.so -> libcudart.so.7.5\nlrwxrwxrwx 1 root root        19 Aug 15  2015 /usr/local/cuda-7.5/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18\n-rwxr-xr-x 1 root root    383336 Aug 15  2015 /usr/local/cuda-7.5/lib64/libcudart.so.7.5.18\n-rw-r--r-- 1 root root    720192 Aug 15  2015 /usr/local/cuda-7.5/lib64/libcudart_static.a\nlrwxrwxrwx 1 3319 users       13 Feb  9 19:48 /usr/local/cuda-7.5/lib64/libcudnn.so -> libcudnn.so.4\nlrwxrwxrwx 1 3319 users       17 Feb  9 19:48 /usr/local/cuda-7.5/lib64/libcudnn.so.4 -> libcudnn.so.4.0.7\n-rwxrwxr-x 1 3319 users 61453024 Feb  9 00:12 /usr/local/cuda-7.5/lib64/libcudnn.so.4.0.7\n-rw-rw-r-- 1 3319 users 62025862 Feb  9 00:12 /usr/local/cuda-7.5/lib64/libcudnn_static.a\n```\n\nIf installed from binary pip package, provide:\n1. Which pip package you installed. Nightly build, Ubuntu/Linux 64-bit, GPU enabled, Python 2.7 \n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\n\n``` bash\n$ python -c \"import tensorflow; print(tensorflow.__version__)\"\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally\n0.9.0\n```\n\nIf installed from sources, provide the commit hash:\n### Steps to reproduce\n1. Running the following python script\n\n``` python\nimport tensorflow as tf\n\nwith tf.Session() as S:\n    V = tf.linspace(0., 100., 10)\n    S.run(tf.initialize_variables([V]))\n```\n\nproduces the following output:\n\n``` python\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:924] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: \nname: GeForce GTX 850M\nmajor: 5 minor: 0 memoryClockRate (GHz) 0.9015\npciBusID 0000:01:00.0\nTotal memory: 4.00GiB\nFree memory: 3.56GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:806] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 850M, pci bus id: 0000:01:00.0)\nTraceback (most recent call last):\n  File \"test_init_fail.py\", line 5, in <module>\n    S.run(tf.initialize_variables([V]))\n  File \"/home/foobar/venv/mb/local/lib/python2.7/site-packages/tensorflow/python/ops/variables.py\", line 907, in initialize_variables\n    *[v.initializer for v in var_list], name=name)\nAttributeError: 'Tensor' object has no attribute 'initializer'\n\n```\n### What have you tried?\n1. See above\n### Logs or other output that would be helpful\n\n(If logs are large, please upload as attachment).\n", "comments": ["`tf.linspace` needed to be wrapped in a `tf.Variable` like so:\n\n``` python\nimport tensorflow as tf\n\nwith tf.Session() as S:\n    V = tf.Variable(tf.linspace(0., 100., 10))\n    S.run(tf.initialize_variables([V]))\n```\n"]}, {"number": 3180, "title": "Execution order of ReLU and Max-Pooling", "body": "Hello Everyone,\n\nI'm new to Deep Learning and TensorFlow. From studying tutorials / research papers / online lectures it appears that people always have the execution order: ReLU -> Pooling. But in case of e.g. 2x2 max-pooling it seems that we can save 75% of the ReLU operations by simply reversing the execution order to: Max-Pooling -> ReLU. This should calculate the exact same thing using only a quarter of the ReLU operations. This reversal of operations can be done in general for max-pooling and all non-decreasing activation functions (which I guess they all are?), but it won't work for average-pooling.\n\nThis is an optimization that TensorFlow could perform automatically when compiling the computation graph. I haven't quite figured out how to use TensorBoard yet, so I can't tell if this automatic reversal of ReLU and max-pooling is already being done in TensorFlow.\n\nSo I've done a few experiments instead, timing the optimization of a convolutional net on MNIST, but the results are inconclusive for the two execution orders. Perhaps this means that TensorFlow already does the reversal automatically, or it means that there's no consistent advantage because the saved ReLU operations are such a tiny fraction of the overall computational cost, or perhaps it takes much larger images than MNIST and much deeper convolutional networks for the performance difference to become apparent.\n\nAny thoughts?\n", "comments": ["Reversing the order 'optimizing' auto**magically** is a bad idea imo, especially (relatively to other DNN frameworks) tensorflow being relatively low level. Moreover, computationally, it might be inconclusive because the ReLU is a relatively cheap operation compared to the heavy convolutions, it would be a very minor optimization in terms of computational cost.\nIn any case, I think you're right in thinking that MaxPoolin(ReLU(x)) = ReLU(MaxPoolin(x)). I think this isn't the standard because one super-layer can be seen as {conv, ReLu} while the MaxPooling is an intermediate step to prepare for the next super-layer.\n\nTensorboard is a no-brainer to set-up initially, just run the `tensorboard --logdir=/foo/bar` and make sure you log your summary writer in `/foo/bar`, see the docs for this. You will be amaze: https://www.tensorflow.org/versions/r0.9/how_tos/summaries_and_tensorboard/index.html\n", "Such code optimizations are common in e.g. C / C++ compilers. It has probably been 15 years since I've implemented a compiler, but as I recall, these kinds of optimizations are called Peephole Optimizations. TensorFlow is a kind of compiler which uses a computational graph, so it would make sense for it to do automatic code optimizations like this.\n\nRegarding the potential time savings, I think more investigation is needed before we rule it out. Let's do a quick back-of-the-envelope calculation to begin with. This may seem a little confusing and I hope I got the numbers right as I'm still new to these things.\n\nThe convolution performs approximately O(input_width \\* input_height \\* input_channels \\* filter_width \\* filter_height \\* num_filters) operations for each input image. This results in a tensor having approximately input_width \\* input_height \\* num_filters elements, depending on the padding settings. Dividing the two numbers shows that there's O(filter_width \\* filter_height \\* input_channels) arithmetic operations being performed to calculate one element of the output tensor. If we assume the ReLU operations take the same time to execute as each of those convolutional operations, then we should expect to save approximately 0.75 \\* (1 / (filter_width \\* filter_height \\* input_channels)) of the overall computational costs, because the cost of one single ReLU operation is approximately (1 / (filter_width \\* filter_height \\* input_channels)) of the total computational cost of the convolutional layer, and we can save 75% of those operations simply by switching the order of the ReLU operation and the 2x2 Max-Pooling.\n\nFor example, having filter_width == filter_height == 5 and input_channels == 1 we would get 0.75 \\* 0.04 = 0.03, that is, approximately 3% of the overall computational cost of the convolutional layer would be saved from this simple reversal of ReLU and Max-Pooling. That's actually a quite nice saving for such a simple code optimization! However, if input_channels == 64 then the saving is only 0.75 \\* (1 / 1600) which is about 0.0005 or about 0.05% which is clearly insignificant.\n\nBut if more expensive functions are used instead of ReLU, e.g. something with floating-point division which is computationally expensive, then perhaps it would still make sense to do this optimization even if the number of input channels is high.\n\nAnother thing to consider is the number of layers in the network, because the number of input channels to a convolutional layer is low in the first layer (e.g. 1-channel for gray-scale images and 3-channels for RGB colours), and the number of channels becomes higher in later layers because of the higher number of filter-channels. So the first layer might actually provide a small but tangible saving to the overall computational cost of the network, simply by switching the order of ReLU and Max-Pooling, while the deeper layers may only provide a tiny and insignificant computational saving. But if this optimization was done transparently by the TensorFlow compiler, then any potential time-saving would be gratis to the user of TensorFlow.\n\nNevertheless, I find it curious that people in Deep Learning continue to have the ReLU -> Max-Pooling ordering and apparently not realizing that it wastes operations. It suggests that people in the field might have a slightly rigid way of thinking about these things, and perhaps there are more substantial improvements waiting to be discovered.\n", "Good write-up.\n\n> It suggests that people in the field might have a slightly rigid way of thinking about these things\n\nThis is probably due to the empirical basis of many findings. We can also question why we are using MaxPooling at all? I have recently seen many nets where MaxPooling is substituted just by an extra convolutional stride, without significant loss of performance (if any).\n", "Seems like a nice option for a future compiler optimization -- as @TimZaman said, I suspect this doesn't show up as a huge performance win yet, but these types of optimizations are definitely on our mind.\n\nBtw, I would argue that when the user can't tell the difference, we should automatically do the optimization (e.g., if the only consumer of ReLU is MaxPooling -- no manual fetching or summaries, then it is probably safe to reorder them since the observed output is the same).\n", "@vrv Thanks for commenting on the dev-status on Peephole Optimizations, I was curious if it was already included or not in TensorFlow.\n\nI've now tried PrettyTensor which automatically adds the activation function to the layer, e.g. like this for adding ReLU to each layer:\n\n```\nwith pt.defaults_scope(activation_fn=tf.nn.relu):\n    y_pred, loss = x_pretty.\\\n        conv2d(kernel=5, depth=16, name='layer_conv1').\\\n        max_pool(kernel=2, stride=2).\\\n        conv2d(kernel=5, depth=36, name='layer_conv2').\\\n        max_pool(kernel=2, stride=2).\\\n        flatten().\\\n        fully_connected(size=128, name='layer_fc1').\\\n        softmax_classifier(class_count=10, labels=y_true)\n```\n\nI think it would make most sense to do Peephole Optimizations inside the TensorFlow compiler, rather than have people doing them manually in e.g. PrettyTensor, TFLearn, Keras, user-code, etc. As discussed above, there might not be a huge gain by reversing the activation function and max-pooling, but perhaps you will start to discover more possible optimizations once you see the code from this angle. I would be curious to hear of any discoveries - perhaps you can post in this thread if you find something significant?\n\n@TimZaman Regarding max-pooling vs. stride in the convolutional layer, I did notice this redundancy when I was watching online lectures, reading tutorials and papers, etc. It is not a mathematical equivalency as in the case of execution order for relu/max-pool, so the TensorFlow compiler should not replace one for the other. But it would make sense that max-pooling and stride were quite similar, because nearby pixels in images are usually quite similar. If you have some references for papers that study max-pooling vs. stride then I'd like to see them. Thanks.\n", "This would be a great optimization pass to contribute when XLA (our compiler framework is open soruced) [see here](https://www.tensorflow.org/versions/master/resources/xla_prerelease.html) \n", "Now that XLA is open-source, this might be worth reviving. Feel free to open a new issue referencing this one if you're ready to go!", "@Hvass-Labs Your own explanation about the insignificant cost performance is very nice and correct, yet of course it is interesting to wonder if it would make sense to reverse the layer order anyways. IMHO I would expect industry or embedded-level networks to be optimized in such a way when possible, as any \"free\" computation saving is beneficial.\r\n\r\nHowever, I wanted to point out that some networks **do** need the ReLU to be performed right after the convolution. In semantic segmentation, for example, recurrent CNNs use the \"convolution output\" (including the ReLU) to feed again later stages of the architecture where an upsampling is required, and the original activations are necessary in the original size, to recover the exact neuron which fired the activation. If the MaxPool was done before the ReLU, this detailed local information would be lost, and therefore it wouldnt be possible to recover an output as big (or almost) as the original image.\r\n\r\nI know it is not a big deal, and of course this only involves some small subset of CNNs, but hopefully I satisfied a bit of your curiosity! :)", "@scanyameres That is interesting. I didn't know that."]}, {"number": 3179, "title": "ImportError: cannot import name pywrap_tensorflow", "body": "### Environment info\n\nOperating System: Mac OS X 10.10\n### Steps to reproduce\n\n1.\n%matplotlib inline\n%load_ext autoreload\n%autoreload 2\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nfrom matplotlib import gridspec\n2.\nimport sys\nsys.path.append('..')\n3.\nfrom tasks import *\n\ninput_dim=10\noutput_dim=10\n\nsess = tf.InteractiveSession()\n\ncell = NTMCell(input_dim=input_dim, output_dim=output_dim)\nntm = NTM(cell, sess, 1, 10, 100, forward_only=True)\nntm.load('../checkpoint', 'copy')\n\n---\n\nImportError                               Traceback (most recent call last)\n<ipython-input-18-0a6f382608e4> in <module>()\n----> 1 from tasks import *\n      2 \n      3 input_dim=10\n      4 output_dim=10\n      5 \n\n/Users/William_Chuang/Documents/NTM/NTM-tensorflow-master/tasks/**init**.py in <module>()\n----> 1 from copy import *\n      2 from recall import *\n\n/Users/William_Chuang/Documents/NTM/NTM-tensorflow-master/tasks/copy.py in <module>()\n      2 import time\n      3 import numpy as np\n----> 4 import tensorflow as tf\n      5 from random import randint\n      6 \n\n/Users/William_Chuang/cuting_edge/anaconda/lib/python2.7/site-packages/tensorflow/**init**.py in <module>()\n     21 from **future** import print_function\n     22 \n---> 23 from tensorflow.python import *\n\n/Users/William_Chuang/cuting_edge/anaconda/lib/python2.7/site-packages/tensorflow/python/**init**.py in <module>()\n     46 _default_dlopen_flags = sys.getdlopenflags()\n     47 sys.setdlopenflags(_default_dlopen_flags | ctypes.RTLD_GLOBAL)\n---> 48 from tensorflow.python import pywrap_tensorflow\n     49 sys.setdlopenflags(_default_dlopen_flags)\n     50 \n\nImportError: cannot import name pywrap_tensorflow\n", "comments": ["Please provide more information.\nHow did you install tensorflow? is it from binary or source? If from binary, which pip package? We typically only support and test on Mac OS X 10.11.  \n", "Automatically closing due to lack of recent activity. Please reopen when further information becomes available.\n", "Hi, \r\nI am trying to use tensorflow in ipython, Mac and I got the following error\r\n\r\n---------------------------------------------------------------------------\r\nImportError                               Traceback (most recent call last)\r\n<ipython-input-7-836278fb1688> in <module>()\r\n      1 import sys\r\n      2 sys.path.append('/Users/vasanti/miniconda2/lib/python2.7/site-packages')\r\n----> 3 from keras.utils import np_utils\r\n      4 import theano\r\n      5 import theano.tensor as T\r\n\r\n/Users/vasanti/miniconda2/lib/python2.7/site-packages/keras/__init__.py in <module>()\r\n      1 from __future__ import absolute_import\r\n      2 \r\n----> 3 from . import activations\r\n      4 from . import applications\r\n      5 from . import backend\r\n\r\n/Users/vasanti/miniconda2/lib/python2.7/site-packages/keras/activations.py in <module>()\r\n      2 import six\r\n      3 import warnings\r\n----> 4 from . import backend as K\r\n      5 from .utils.generic_utils import deserialize_keras_object\r\n      6 from .engine import Layer\r\n\r\n/Users/vasanti/miniconda2/lib/python2.7/site-packages/keras/backend/__init__.py in <module>()\r\n     71 elif _BACKEND == 'tensorflow':\r\n     72     sys.stderr.write('Using TensorFlow backend.\\n')\r\n---> 73     from .tensorflow_backend import *\r\n     74 else:\r\n     75     raise ValueError('Unknown backend: ' + str(_BACKEND))\r\n\r\n/Users/vasanti/miniconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py in <module>()\r\n----> 1 import tensorflow as tf\r\n      2 from tensorflow.python.training import moving_averages\r\n      3 from tensorflow.python.ops import tensor_array_ops\r\n      4 from tensorflow.python.ops import control_flow_ops\r\n      5 from tensorflow.python.ops import functional_ops\r\n\r\n/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/__init__.py in <module>()\r\n     22 \r\n     23 # pylint: disable=wildcard-import\r\n---> 24 from tensorflow.python import *\r\n     25 # pylint: enable=wildcard-import\r\n     26 \r\n\r\n/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/__init__.py in <module>()\r\n     49 import numpy as np\r\n     50 \r\n---> 51 from tensorflow.python import pywrap_tensorflow\r\n     52 \r\n     53 # Protocol buffers\r\n\r\nImportError: cannot import name pywrap_tensorflow\r\n\r\nIt will be great if someone could help me with this!\r\nThanks in advance! ", "Is it supported on mac os 10.14.5 now??", "---------------------------------------------------------------------------\r\n\r\n//anaconda2/lib/python2.7/site-packages/tensorflow/__init__.py in <module>()\r\n     26 \r\n     27 # pylint: disable=g-bad-import-order\r\n---> 28 from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n     29 from tensorflow.python.tools import module_util as _module_util\r\n     30 \r\n\r\n//anaconda2/lib/python2.7/site-packages/tensorflow/python/__init__.py in <module>()\r\n     47 import numpy as np\r\n     48 \r\n---> 49 from tensorflow.python import pywrap_tensorflow\r\n     50 \r\n     51 # Protocol buffers\r\n\r\nImportError: cannot import name pywrap_tensorflow"]}, {"number": 3178, "title": "How to check/enlarge computer memory in Mac OS when running .py code? ", "body": "Hi everyone,\n\nI'm new to python, and learning tensorflow recently on my mac OS X Yosemite system with 8g memory. I'm using anaconda with tensorflow installed within it. When trying some demo codes, I found they run very slowly.\n\n I've saw somewhere previously that python only use 2g (or 1g? sorry I cannot remember clearly) memory in Mac OS since it was installed in virtual environment, so one can enlarge the memory to 8g to speed up the programme by using just several command lines. \n\nUnfortunately I  cannot find out that webpage now. Does anyone have idea how to do this? Thanks a lot!\n", "comments": ["@takluyver @carreau \n", "> I've saw somewhere previously that python only use 2g (or 1g? sorry I cannot remember clearly) memory in Mac OS since it was installed in virtual environment\n\nIf you are really using a virtual _environment_, it cannot, as far as I know, limit the memory a process can use. If you're using a virtual _machine_, or a container system such as Docker, it can.\n", "Yeah, that's one of the issues with tensor flow we heard about. I've heard the you can configure tensor flow not to do that but that. IIUC you need to do that when you create a session:\n\nhttp://stackoverflow.com/questions/34199233/how-to-prevent-tensorflow-from-allocating-the-totality-of-a-gpu-memory\n", "\"If you are really using a virtual environment, it cannot, as far as I know, limit the memory a process can use. If you're using a virtual machine, or a container system such as Docker, it can.\" -- Thanks for the reply. Actually I'm not 100% sure whether I'm using a virtual environment or virtual machine or Docker (sorry I'm not major in computer and not very familiar with computer systems). If I'm using VM or Docker, how can I do it? @takluyver \n", "Yeah it cannot solve my problem... But still thanks for your kind help! @Carreau \n", "> Actually I'm not 100% sure whether I'm using a virtual environment or virtual machine or Docker\n\nIf you are not sure, then there is 99% chance that you are not using either Docker or a VM. If you are you would explicitly start these and you would thus be able to pass an option at startup to limit the RAM, in te case of Docker `--memory=\"<memory>\"`. In case of OS X it's worse as you run Docker in a VM. \n\nOs it's unlikely that your python is memory limited already:\n\n```\nIn [15]: import numpy as np\nIn [18]: z = np.random.rand(*((1000,)*3)\nIn [17]: %whos\nVariable   Type       Data/Info\n-------------------------------\nnp         module     <module 'numpy' from '/Us<...>kages/numpy/__init__.py'>\nz          ndarray    1000x1000x1000: 1000000000 elems, type `float64`, 8000000000 bytes (7629.39453125 Mb)\n```\n\n(note we might want to update `whos`, sic) but I'm actually using 7.5Gb Ram.\n\n<img width=\"540\" alt=\"screen shot 2016-07-04 at 19 59 36\" src=\"https://cloud.githubusercontent.com/assets/335567/16572830/e1681c26-4221-11e6-800b-057a03f7640b.png\">\n\nThe \"limited to 2 Gb\" would make sens on 32bits OS, especialy windows, which you are extremely unlikely to get, you had to boot with `/LARGEADDRESSAWARE` flag, or upgrade your windows version (of vista) which was limited _on purpose_.\n\nMy guess is that tensorflow is ment to be used on much more powerful machines (eg the machines I have seen it use have 100 of GB of memory of 10s of GB of GPUs). It is slow because your machine is just not up to the task. \n", "Get it. Currently I\u2019m just in a learning phase. Though the macbook is slow, I think I can live with it for the moment. Thanks again! @Carreau \n", "@QLQLQL, If your question has  been answered sufficiently, I will close.\n", "Yeah, please close the issue. Thanks.\n\n```\nOn Thursday, July 7, 2016 8:21 AM, Andrew Selle <notifications@github.com> wrote:\n```\n\n @QLQLQL, If your question has been answered sufficiently, I will close.\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub, or mute the thread.  \n"]}, {"number": 3177, "title": "Is wide_n_deep compatible with python3.5?", "body": "GitHub issues are for bugs / installation problems / feature requests.  \nFor general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed\nout of scope for GitHub Issues and point people to StackOverflow.\n\nFor bugs or installation issues, please provide the following information.\nThe more information you provide, the more easily we will be able to offer\nhelp and advice.\n### Environment info\n\nOperating System: Ubuntu 14/04\n\nInstalled version of CUDA and cuDNN: \n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\n\nIf installed from binary pip package, provide:\n1. Which pip package you installed.\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\n\nIf installed from sources, provide the commit hash:\n### Steps to reproduce\n1. run wide_n_deep.py on python 3.5\n   2.\n   3.\n### What have you tried?\n\n1.\n### Logs or other output that would be helpful\n\n(If logs are large, please upload as attachment).\nTypeError: unsupported operand type(s) for +: 'dict_items' and 'dict_items'\n\nThis is because python3.5 does not support + between dict_items. I worked around using dict.copy(), but still get error and could proceed. Do you have plan to release python 3.5 version in near future?\n", "comments": ["in wide_n_deep_tutorial.py, change the following line:\nfeature_cols = dict(continuous_cols.items() + categorical_cols.items())\nto\nfeature_cols = {_**continuous_cols , *_*categorical_cols}\nthis change makes wide_n_deep_tutorial.py compatible with Python 3.x.\nNow simply run it like:\npython3.5 wide_n_deep_tutorial.py --model_type=wide\n\nnote that the wide_n_deep option (--model_type=wide_n_deep) still has an error due to a compatibility issue in dnn_linear_combined.py\n", "@hengtze could you fix this?\n"]}, {"number": 3176, "title": "Mutability of TF_NewTensor\u2019s arguments", "body": "The C API provides the [following function](https://github.com/tensorflow/tensorflow/blob/v0.9.0/tensorflow/core/public/tensor_c_api.h#L195) for creating tensors:\n\n``` c\nextern TF_Tensor* TF_NewTensor(TF_DataType, long long* dims, int num_dims,\n                               void* data, size_t len,\n                               void (*deallocator)(void* data, size_t len,\n                                                   void* arg),\n                               void* deallocator_arg);\n```\n\nBased on what the function does conceptually and on how it is [implemented](https://github.com/tensorflow/tensorflow/blob/v0.9.0/tensorflow/core/client/tensor_c_api.cc#L122), it doesn\u2019t seem to be reasonable that `dims` is required to be a pointer to mutable data. This makes the usage of the function a bit inconvenient, especially when developing bindings for other languages. If it\u2019s OK to change the signature of the function, I can submit a pull request. Thanks!\n\nRegards,\nIvan\n", "comments": ["That sounds like a fine change to me.\n", "Fixed in #3214.\n"]}, {"number": 3175, "title": "Android demo: unable to build with Bazel, could not read RELEASE.TXT", "body": "### Environment info\n\nOperating System: Ubuntu 14.04 LTS 64-bit\n\nInstalled version of CUDA and cuDNN: none (not using GPU)\n### Steps to reproduce\n\nNote: TensorFlow was installed previously.\n1. Install Bazel as instructed here: http://www.bazel.io/docs/install.html#install-on-ubuntu\n2. Install Android Studio (which includes the SDK).\n3. Install Android NDK through the Android Studio SDK Manager.\n4. Download and unzip the TensorFlow graph as instructed here: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/android/README.md\n5. Uncomment the Android entries in the WORKSPACE file and add in paths to the SDK and NDK (in my case, these were `/home/me/Android/Sdk` and `/home/me/android-studio/android-studio/plugins/android-ndk`)\n6. Run `$ bazel build //tensorflow/examples/android:tensorflow_demo`\n### What have you tried?\n1. I've looked around, and my understanding is that the RELEASE.TXT file is not included in the most recent version of the Android NDK. Since the NDK installed via Android Studio is a .jar file, I wasn't sure what to do with that, so I went to the path indicated by the terminal log and created a blank RELEASE.TXT file. This made no difference.\n2. According to #1468, it can be resolved by downgrading to an earlier version of the NDK which contains RELEASE.TXT. I downloaded the version of Bazel (for Linux) from the links given, but the downloaded file is a .bin, which is unusable to me. As such, I found this solution to be a dead end.\n3. Commenting out the NDK entry is said to resolve the issue, but I haven't tried this yet, since I don't know if it'll cause more complications down the road.\n### Logs or other output that would be helpful\n\n```\nERROR: no such package '@androidndk//': Could not read RELEASE.TXT in Android NDK: /home/me/.cache/bazel/_bazel_me/f3471be34d1e62bf21975aa777cedaa3/external/androidndk/ndk/RELEASE.TXT (No such file or directory).\nERROR: no such package '@androidndk//': Could not read RELEASE.TXT in Android NDK: /home/me/.cache/bazel/_bazel_me/f3471be34d1e62bf21975aa777cedaa3/external/androidndk/ndk/RELEASE.TXT (No such file or directory).\n```\n\nIs there another way to resolve this issue without downgrading or commenting out the NDK entry? If not, how can I install a previous version of Android NDK? Thanks in advance.\n", "comments": ["This seems to be a duplicate of https://github.com/tensorflow/tensorflow/issues/1468\nUnfortunately #1468 was closed by the submitter after people suggested he download an old version of the NDK.\n\nThe workaround helps the person that submitted #1468, but the issue with the TensorFlow build system remains ...\n", "@cardshuffle Which version of Bazel did you install? 0.3.0 is required for NDK 11 support. Otherwise you'll need to use Android NDK r10e (links in #1468) as @lukesleeman suggests.\n", "Automatically closing due to lack of recent activity. Please reopen when further information becomes available.\n", "@lukesleeman #1468 was the issue I linked to, and I already discussed how I tried the solutions suggested there.\n@andrewharp I installed version 0.3.0 as confirmed by `bazel version`. This is the log output:\n\n```\nBuild label: 0.3.0\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel /BazelServer_deploy.jar\nBuild time: Fri Jun 10 11:38:23 2016 (1465558703)\nBuild timestamp: 1465558703\nBuild timestamp as int: 1465558703\n```\n\nAlso, a correction: I mistakenly said that #1468 suggested downgrading Bazel where it was actually the Android NDK, and I just fixed it. In the end, I still have not resolved this issue. Could this be reopened?\n", "@cardshuffle \nCan you please clarify what issue \"it\" was that you fixed by downgrading your ndk, what version you downgraded to, and what issue still remains?\n\nI was just able to clone the TF repo and build the tensorflow demo using NDK r11c and Bazel 0.3.0 on Ubuntu. The RELEASE.TXT issues should no longer occur with this version combination.\n\nIt's possible that Android Studio has downloaded a different variant for you, though -- Bazel does not officially support r12 at the moment. You could try manually downloading r11c here: http://dl.google.com/android/repository/android-ndk-r11c-linux-x86_64.zip and see if that works.\n\nIf that doesn't help, can you please paste the NDK entry from your WORKSPACE?\n", "@andrewharp I didn't downgrade the NDK (at the time of that post). What I \"fixed\" was my initial post in this thread, when I mistakenly said Bazel instead of NDK. I also stated in my initial post that I was unable to downgrade to NDK using the links provided in #1468 (I tried to downgrade to r10e). Sorry if my wording was confusing.\n\nI downloaded the NDK r11c using the link you provided, unzipped it to the Documents directory, and modified the WORKSPACE file:\n\n```\nandroid_ndk_repository(\n    name=\"androidndk\",\n    path=\"/home/me/Documents/android-ndk-r11c\",\n    api_level=21)\n```\n\nThen I ran the Bazel build command again, and I got this error:\n\n```\nERROR: /home/me/tf/tensorflow/tensorflow/examples/android/BUILD:12:1: error loading package 'tensorflow/core': Extension file not found. Unable to load package for '//google/protobuf:protobuf.bzl': BUILD file not found on package path and referenced by '//tensorflow/examples/android:libtensorflow_demo.so'.\nERROR: Analysis of target '//tensorflow/examples/android:tensorflow_demo' failed; build aborted.\nINFO: Elapsed time: 0.491s\n```\n", "Did you git clone with the --recurse_submodules option?\n", "@andrewharp When I initially installed TensorFlow and cloned the repository, I didn't use --recursive, but I just re-cloned it in a new folder using --recursive, and redid all the steps (excluding installation of the SDK/NDK/Bazel), up to the Bazel build. However, I got this output:\n\n```\nWARNING: /home/me/.cache/bazel/_bazel_me/95be766f297ed076701dc5f5e00e0a6b/external/protobuf/WORKSPACE:1: Workspace name in /home/me/.cache/bazel/_bazel_me/95be766f297ed076701dc5f5e00e0a6b/external/protobuf/WORKSPACE (@__main__) does not match the name given in the repository's definition (@protobuf); this will cause a build error in future versions.\nWARNING: /home/me/.cache/bazel/_bazel_me/95be766f297ed076701dc5f5e00e0a6b/external/highwayhash/WORKSPACE:1: Workspace name in /home/me/.cache/bazel/_bazel_me/95be766f297ed076701dc5f5e00e0a6b/external/highwayhash/WORKSPACE (@__main__) does not match the name given in the repository's definition (@highwayhash); this will cause a build error in future versions.\nWARNING: /home/me/.cache/bazel/_bazel_me/95be766f297ed076701dc5f5e00e0a6b/external/re2/WORKSPACE:1: Workspace name in /home/me/.cache/bazel/_bazel_me/95be766f297ed076701dc5f5e00e0a6b/external/re2/WORKSPACE (@__main__) does not match the name given in the repository's definition (@re2); this will cause a build error in future versions.\nWARNING: /home/me/tf_m/tensorflow/tensorflow/core/BUILD:619:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:avgpooling_op.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/me/tf_m/tensorflow/tensorflow/core/BUILD:619:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:bounds_check.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/me/tf_m/tensorflow/tensorflow/core/BUILD:619:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_activations.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/me/tf_m/tensorflow/tensorflow/core/BUILD:619:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_attention.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/me/tf_m/tensorflow/tensorflow/core/BUILD:619:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_backward_cuboid_convolutions.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/me/tf_m/tensorflow/tensorflow/core/BUILD:619:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_backward_spatial_convolutions.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/me/tf_m/tensorflow/tensorflow/core/BUILD:619:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_cuboid_convolution.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/me/tf_m/tensorflow/tensorflow/core/BUILD:619:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_patch_3d.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/me/tf_m/tensorflow/tensorflow/core/BUILD:619:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_pooling.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/me/tf_m/tensorflow/tensorflow/core/BUILD:619:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_softmax.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/me/tf_m/tensorflow/tensorflow/core/BUILD:619:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_spatial_convolutions.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/me/tf_m/tensorflow/tensorflow/core/BUILD:619:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:maxpooling_op.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/me/tf_m/tensorflow/tensorflow/core/BUILD:619:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:ops_util.cc' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/me/tf_m/tensorflow/tensorflow/core/BUILD:619:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:ops_util.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/me/tf_m/tensorflow/tensorflow/core/BUILD:619:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:pooling_ops_common.cc' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/me/tf_m/tensorflow/tensorflow/core/BUILD:619:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:pooling_ops_common.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/me/tf_m/tensorflow/tensorflow/core/BUILD:619:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_beam_entry.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/me/tf_m/tensorflow/tensorflow/core/BUILD:619:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_beam_scorer.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/me/tf_m/tensorflow/tensorflow/core/BUILD:619:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_beam_search.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/me/tf_m/tensorflow/tensorflow/core/BUILD:619:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_decoder.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /home/me/tf_m/tensorflow/tensorflow/core/BUILD:619:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_loss_util.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nINFO: Found 1 target...\nERROR: missing input file '@androidsdk//:platforms/android-23/android.jar'.\nERROR: /home/me/tf_m/tensorflow/tensorflow/examples/android/BUILD:47:1: //tensorflow/examples/android:tensorflow_demo: missing input file '@androidsdk//:platforms/android-23/android.jar'.\nTarget //tensorflow/examples/android:tensorflow_demo failed to build\nUse --verbose_failures to see the command lines of failed build steps.\nERROR: /home/me/tf_m/tensorflow/tensorflow/examples/android/BUILD:47:1 1 input file(s) do not exist.\nINFO: Elapsed time: 11.984s, Critical Path: 0.27s\n```\n", "Does platforms/android-23/android.jar exist in your sdk directory? Can you paste the WORKSPACE entry for your sdk and ndk please?\n", "No, but the path platforms/android-24/android.jar does. This is my WORKSPACE entry:\n\n```\nandroid_sdk_repository(\n    name = \"androidsdk\",\n    api_level = 23,\n    build_tools_version = \"23.0.1\",\n    # Replace with path to Android SDK on your system\n    path = \"/home/me/Android/Sdk\",\n)\n\nandroid_ndk_repository(\n    name=\"androidndk\",\n    path=\"/home/me/Documents/android-ndk-r11c\",\n    api_level=21)\n```\n\nI suspect that the error is because the file says that the api is version 23 whereas I think I have version 24 installed. Is this the case? If so, then will I have to change the version of the build tools too?\n", "Sounds like it. You can use `/home/me/Android/Sdk/tools/android` to confirm. \n\nThere's no problem having multiple Android api levels installed in your SDK, so you can use the `android` tool to install 23, or just change WORKSPACE to match what you have.\n", "This is the error now:\n\n```\nERROR: /home/me/.cache/bazel/_bazel_me/95be766f297ed076701dc5f5e00e0a6b/external/gif_archive/BUILD:14:1: C++ compilation of rule '@gif_archive//:gif' failed: namespace-sandbox failed: error executing command /home/me/.cache/bazel/_bazel_me/95be766f297ed076701dc5f5e00e0a6b/execroot/tensorflow/_bin/namespace-sandbox ... (remaining 46 argument(s) skipped).\nexternal/gif_archive/giflib-5.1.4/lib/gif_err.c:10:29: fatal error: gif_lib_private.h: No such file or directory\n #include \"gif_lib_private.h\"\n                             ^\ncompilation terminated.\nTarget //tensorflow/examples/android:tensorflow_demo failed to build\nUse --verbose_failures to see the command lines of failed build steps.\nINFO: Elapsed time: 6.687s, Critical Path: 3.33s\n```\n\nAnd this is my SDK entry for the WORKSPACE file:\n\n```\nandroid_sdk_repository(\n    name = \"androidsdk\",\n    api_level = 24,\n    build_tools_version = \"24.0.0\",\n    # Replace with path to Android SDK on your system\n    path = \"/home/me/Android/Sdk\",\n)\n```\n", "Now you've run into an outstanding TF issue :)\nhttps://github.com/tensorflow/tensorflow/issues/3374\n\nI have a fix incoming, until then just run ./configure for a simple workaround.\n", "Thanks for all your help! ./configure worked and the Bazel build was successful. One final question: is there a way to open up a project built with Bazel in Android Studio? I find it easier to view and edit code that way.\n", "glad you got it working!\n\nAndroid Studio should be able to let you edit the Android/Java portion of the demo, and maybe the native code too. See http://stackoverflow.com/questions/27570516/how-to-open-an-existing-project-in-android-studio\n\nHowever, you're probably better off using bazel directly to actually build it for deployment.\n", "this is a noob question but can i know how to find the location of bazel in my system", "@swarathesh try `which bazel`", "thanks @andrewharp ", "while ./configure im getting this error Can't find swig.  Ensure swig is in $PATH or set $SWIG_PATH.\r\nbut i have already installed brew install swig , what to do now @andrewharp "]}, {"number": 3174, "title": "C Stack smashing from inside python when using tensorflow", "body": "I am trying to implement Fully Connected Convolutional Network in python using tensorflow and I am getting a Stack Smashing error in one of the Convolution operators. I have checked and all the filter sizes match up and are perfectly in sync with the layer shapes. I did my research on the error and found that this error is caused when you overflow the alloted buffer but I cant see any place where I exceed this buffer and the most weird part is that it's running for 10 layers (7 convolutions and 3 max pool ones of the VGG network) and crashing on the next convolution.\n(Posted this on Stack Overflow and was told that this error is due to a bug in tensorflow and hence should be posted here. The reason I was told was that the stack smashing is happening in the C++ code and not the python code and I havent written any C++ code myself so the most likely place for the error to have happened is inside tensorflow)\n\nThe error I get is:\n`-> _, loss_value = sess.run([train_op, loss],feed_dict=feed_dict)\n(Pdb) c\nI tensorflow/core/kernels/logging_ops.cc:79] Shape of input image: [1 375 1242 3]\nI tensorflow/core/kernels/logging_ops.cc:79] Shape of conv1_1[1 375 1242 64]\nI tensorflow/core/kernels/logging_ops.cc:79] Shape of conv1_2[1 375 1242 64]\nI tensorflow/core/kernels/logging_ops.cc:79] Shape of pool1[1 188 621 64]\nI tensorflow/core/kernels/logging_ops.cc:79] Shape of conv2_1[1 188 621 128]\nI tensorflow/core/kernels/logging_ops.cc:79] Shape of conv2_2[1 188 621 128]\nI tensorflow/core/kernels/logging_ops.cc:79] Shape of pool2[1 94 311 128]\nI tensorflow/core/kernels/logging_ops.cc:79] Shape of conv3_1[1 94 311 256]\nI tensorflow/core/kernels/logging_ops.cc:79] Shape of conv3_2[1 94 311 256]\nI tensorflow/core/kernels/logging_ops.cc:79] Shape of conv3_3[1 94 311 256]\nI tensorflow/core/kernels/logging_ops.cc:79] Shape of pool3[1 47 156 256]\n*** stack smashing detected ***: python terminated\nAborted (core dumped)`\n\nHere is the relevant part of my code:\n\n```\n`class FCN8VGG:\ndef __init__(self, vgg16_npy_path=None):\n    if vgg16_npy_path is None:\n        path = sys.modules[self.__class__.__module__].__file__\n        # print path\n        path = os.path.abspath(os.path.join(path, os.pardir))\n        # print path\n        path = os.path.join(path, \"vgg16.npy\")\n        print(path)\n        vgg16_npy_path = path\n\n    self.data_dict = np.load(vgg16_npy_path).item()\n    self.wd = 5e-4\n    print(\"npy file loaded\")\ndef build(self, rgb, train=True, num_classes=14, random_init_fc8=True,\n          debug=True):\n    \"\"\"\n    Build the VGG model using loaded weights\n    Parameters\n    ----------\n    rgb: image batch tensor\n        Image in rgb shap. Scaled to Intervall [0, 255]\n    train: bool\n        Whether to build train or inference graph\n    num_classes: int\n        How many classes should be predicted (by fc8)\n    random_init_fc8 : bool\n        Whether to initialize fc8 layer randomly.\n        Finetuning is required in this case.\n    debug: bool\n        Whether to print additional Debug Information.\n    \"\"\"\n    # Convert RGB to BGR\n\n    with tf.name_scope('Processing'):\n        #import pdb;pdb.set_trace()\n        red, green, blue = tf.split(3, 3, rgb)\n        # assert red.get_shape().as_list()[1:] == [224, 224, 1]\n        # assert green.get_shape().as_list()[1:] == [224, 224, 1]\n        # assert blue.get_shape().as_list()[1:] == [224, 224, 1]\n        bgr = tf.concat(3, [\n            blue - VGG_MEAN[0],\n            green - VGG_MEAN[1],\n            red - VGG_MEAN[2],\n        ])\n\n        if debug:\n            bgr = tf.Print(bgr, [tf.shape(bgr)],\n                           message='Shape of input image: ',\n                           summarize=4, first_n=1)\n\n    self.conv1_1 = self._conv_layer(bgr, \"conv1_1\")\n    self.conv1_2 = self._conv_layer(self.conv1_1, \"conv1_2\")\n    self.pool1 = self._max_pool(self.conv1_2, 'pool1', debug)\n\n    print(\"Pool1 layer ready\")\n\n    self.conv2_1 = self._conv_layer(self.pool1, \"conv2_1\")\n    self.conv2_2 = self._conv_layer(self.conv2_1, \"conv2_2\")\n    self.pool2 = self._max_pool(self.conv2_2, 'pool2', debug)\n    self.conv3_1 = self._conv_layer(self.pool2, \"conv3_1\")\n    self.conv3_2 = self._conv_layer(self.conv3_1, \"conv3_2\")\n    self.conv3_3 = self._conv_layer(self.conv3_2, \"conv3_3\")\n    self.pool3 = self._max_pool(self.conv3_3, 'pool3', debug)\n\n    print(\"Pool 3 layer ready\")\n    #pdb.set_trace()\n    self.conv4_1 = self._conv_layer(self.pool3, \"conv4_1\")\n    self.conv4_2 = self._conv_layer(self.conv4_1, \"conv4_2\")\n    self.conv4_3 = self._conv_layer(self.conv4_2, \"conv4_3\")\n    self.pool4 = self._max_pool(self.conv4_3, 'pool4', debug)\n\n    print(\"Pool 4 layer ready\")\n    #pdb.set_trace()\n    self.conv5_1 = self._conv_layer(self.pool4, \"conv5_1\")\n    self.conv5_2 = self._conv_layer(self.conv5_1, \"conv5_2\")\n    self.conv5_3 = self._conv_layer(self.conv5_2, \"conv5_3\")\n    self.pool5 = self._max_pool(self.conv5_3, 'pool5', debug)\n\n    print(\"Pool 5 layer ready\")\n    #pdb.set_trace()\n    self.fc6 = self._fc_layer(self.pool5, \"fc6\")\n\n    if train:\n        self.fc6 = tf.nn.dropout(self.fc6, 0.5)\n\n    self.fc7 = self._fc_layer(self.fc6, \"fc7\")\n    if train:\n        self.fc7 = tf.nn.dropout(self.fc7, 0.5)\n\n    if random_init_fc8:\n        self.score_fr = self._score_layer(self.fc7, \"score_fr\",\n                                          num_classes)\n    else:\n        self.score_fr = self._fc_layer(self.fc7, \"score_fr\",\n                                       num_classes=num_classes,\n                                       relu=False)\n\n    self.pred = tf.argmax(self.score_fr, dimension=3)\n\n    self.upscore2 = self._upscore_layer(self.score_fr,\n                                        shape=tf.shape(self.pool4),\n                                        num_classes=num_classes,\n                                        debug=debug, name='upscore2',\n                                        ksize=4, stride=2)\n    self.score_pool4 = self._score_layer(self.pool4, \"score_pool4\",\n                                         num_classes=num_classes)\n    self.fuse_pool4 = tf.add(self.upscore2, self.score_pool4)\n    self.upscore4 = self._upscore_layer(self.fuse_pool4,\n                                        shape=tf.shape(self.pool3),\n                                        num_classes=num_classes,\n                                        debug=debug, name='upscore4',\n                                        ksize=4, stride=2)\n    self.score_pool3 = self._score_layer(self.pool3, \"score_pool3\",\n                                         num_classes=num_classes)\n    self.fuse_pool3 = tf.add(self.upscore4, self.score_pool3)\n\n    self.upscore32 = self._upscore_layer(self.fuse_pool3,\n                                         shape=tf.shape(bgr),\n                                         num_classes=num_classes,\n                                         debug=debug, name='upscore32',\n                                         ksize=16, stride=8)\n\n    self.pred_up = tf.argmax(self.upscore32, dimension=3)\n\ndef _max_pool(self, bottom, name, debug):\n    pool = tf.nn.max_pool(bottom, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1],\n                          padding='SAME', name=name)\n\n    if debug:\n        pool = tf.Print(pool, [tf.shape(pool)],\n                        message='Shape of %s' % name,\n                        summarize=4, first_n=1)\n    return pool\n\ndef _conv_layer(self, bottom, name):\n    with tf.variable_scope(name) as scope:\n        filt = self.get_conv_filter(name)\n        conv = tf.nn.conv2d(bottom, filt, [1, 1, 1, 1], padding='SAME')\n\n        conv = tf.Print(conv, [tf.shape(conv)], message='Shape of %s' % name, summarize=4, first_n=1)\n\n        conv_biases = self.get_bias(name)\n        bias = tf.nn.bias_add(conv, conv_biases)\n        if relu:\n            bias = tf.nn.relu(bias)\n        _activation_summary(bias)\n\n        if debug:\n            bias = tf.Print(bias, [tf.shape(bias)],\n                            message='Shape of %s' % name,\n                            summarize=4, first_n=1)\n        return bias`\n\nThe driver tensorflow code has this command which produces the error:\n\n` _, loss_value = sess.run([train_op, loss],feed_dict=feed_dict)`\n\nWhere loss is the tensorflow op for:\n\n`def loss(logits, labels):\n\"\"\"Calculate the loss from the logits and the labels.\n\nArgs:\n  logits: Logits tensor, float - [batch_size, height, width, NUM_CLASSES].  Must be unsclaed and unsoftmaxed.\n  labels: Labels tensor, int32 - [batch_size, height, width].\n\nReturns:\n  loss: Loss tensor of type float.\n\"\"\"\nwith tf.name_scope('loss'):\n    reshaped_logits = tf.reshape(logits, [-1, 14])  # shape [batch_size*height*width, 14]\n    reshaped_labels = tf.reshape(labels, [-1])  # shape [batch_size*height*width]   #Need fix size images for this\n    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(reshaped_logits, reshaped_labels)\nreturn loss   `\n\nAnd training is the driver training function:\n\n`def training(loss, learning_rate):\n  \"\"\"Sets up the training Ops.\n\n  Creates a summarizer to track the loss over time in TensorBoard.\n\n  Creates an optimizer and applies the gradients to all trainable variables.\n\n  The Op returned by this function is what must be passed to the\n  `sess.run()` call to cause the model to train.\n\n  Args:\n    loss: Loss tensor, from loss().\n    learning_rate: The learning rate to use for gradient descent.\n\n  Returns:\n    train_op: The Op for training.\n  \"\"\"\n  # Add a scalar summary for the snapshot loss.\n  tf.scalar_summary(loss.op.name, loss)\n  # Create the gradient descent optimizer with the given learning rate.\n  #optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n  optimizer = tf.train.AdamOptimizer(1e-6)\n  # Create a variable to track the global step.\n  print(\"Setting step size to 1e-6 for Adam Optimizer\")\n  global_step = tf.Variable(0, name='global_step', trainable=False)\n  # Use the optimizer to apply the gradients that minimize the loss\n  # (and also increment the global step counter) as a single training step.\n  print(\"Running optimizer\")\n  train_op = optimizer.minimize(loss, global_step=global_step)\n  return train_op `\n```\n\nThe debug log from the building of the network is: This contains details of filter and layer shapes etc.\n\n```\n`Layer name: conv1_1\nLayer shape: (3, 3, 3, 64)\nINFO:tensorflow:Created variable conv1_1/filter:0 with shape (3, 3, 3, 64) and init <function _initializer at 0x7fcc27c85ed8>\n2016-06-30 14:15:53,939 INFO Created variable conv1_1/filter:0 with shape (3, 3, 3, 64) and init <function _initializer at 0x7fcc27c85ed8>\n\nINFO:tensorflow:Created variable conv1_1/biases:0 with shape (64,) and init <function _initializer at 0x7fcc27c85ed8>\n2016-06-30 14:15:53,944 INFO Created variable conv1_1/biases:0 with shape (64,) and init <function _initializer at 0x7fcc27c85ed8>\nLayer name: conv1_2\nLayer shape: (3, 3, 64, 64)\n\nINFO:tensorflow:Created variable conv1_2/filter:0 with shape (3, 3, 64, 64) and init <function _initializer at 0x7fcc27c96488>\n2016-06-30 14:15:53,952 INFO Created variable conv1_2/filter:0 with shape (3, 3, 64, 64) and init <function _initializer at 0x7fcc27c96488>\n\nINFO:tensorflow:Created variable conv1_2/biases:0 with shape (64,) and init <function _initializer at 0x7fcc27c96488>\n2016-06-30 14:15:53,956 INFO Created variable conv1_2/biases:0 with shape (64,) and init <function _initializer at 0x7fcc27c96488>\nPool1 layer ready\nLayer name: conv2_1\nLayer shape: (3, 3, 64, 128)\n\nINFO:tensorflow:Created variable conv2_1/filter:0 with shape (3, 3, 64, 128) and init <function _initializer at 0x7fcc27c9dc08>\n2016-06-30 14:15:53,967 INFO Created variable conv2_1/filter:0 with shape (3, 3, 64, 128) and init <function _initializer at 0x7fcc27c9dc08>\n\nINFO:tensorflow:Created variable conv2_1/biases:0 with shape (128,) and init <function _initializer at 0x7fcc27c9dc08>\n2016-06-30 14:15:53,972 INFO Created variable conv2_1/biases:0 with shape (128,) and init <function _initializer at 0x7fcc27c9dc08>\nLayer name: conv2_2\nLayer shape: (3, 3, 128, 128)\n\nINFO:tensorflow:Created variable conv2_2/filter:0 with shape (3, 3, 128, 128) and init <function _initializer at 0x7fcbb3012488>\n2016-06-30 14:15:53,980 INFO Created variable conv2_2/filter:0 with shape (3, 3, 128, 128) and init <function _initializer at 0x7fcbb3012488>\n\nINFO:tensorflow:Created variable conv2_2/biases:0 with shape (128,) and init <function _initializer at 0x7fcbb2f8af50>\n2016-06-30 14:15:53,985 INFO Created variable conv2_2/biases:0 with shape (128,) and init <function _initializer at 0x7fcbb2f8af50>\nPool 2 layer ready\nLayer name: conv3_1\nLayer shape: (3, 3, 128, 256)\n\nINFO:tensorflow:Created variable conv3_1/filter:0 with shape (3, 3, 128, 256) and init <function _initializer at 0x7fcbb3012488>\n2016-06-30 14:15:53,995 INFO Created variable conv3_1/filter:0 with shape (3, 3, 128, 256) and init <function _initializer at 0x7fcbb3012488>\n\nINFO:tensorflow:Created variable conv3_1/biases:0 with shape (256,) and init <function _initializer at 0x7fcbb1a7cb90>\n2016-06-30 14:15:54,000 INFO Created variable conv3_1/biases:0 with shape (256,) and init <function _initializer at 0x7fcbb1a7cb90>\nLayer name: conv3_2\nLayer shape: (3, 3, 256, 256)\n\nINFO:tensorflow:Created variable conv3_2/filter:0 with shape (3, 3, 256, 256) and init <function _initializer at 0x7fcbb3012488>\n2016-06-30 14:15:54,010 INFO Created variable conv3_2/filter:0 with shape (3, 3, 256, 256) and init <function _initializer at 0x7fcbb3012488>\n\nINFO:tensorflow:Created variable conv3_2/biases:0 with shape (256,) and init <function _initializer at 0x7fcbb3012488>\n2016-06-30 14:15:54,015 INFO Created variable conv3_2/biases:0 with shape (256,) and init <function _initializer at 0x7fcbb3012488>\nLayer name: conv3_3\nLayer shape: (3, 3, 256, 256)\n\nINFO:tensorflow:Created variable conv3_3/filter:0 with shape (3, 3, 256, 256) and init <function _initializer at 0x7fcbb1a8aaa0>\n2016-06-30 14:15:54,024 INFO Created variable conv3_3/filter:0 with shape (3, 3, 256, 256) and init <function _initializer at 0x7fcbb1a8aaa0>\n\nINFO:tensorflow:Created variable conv3_3/biases:0 with shape (256,) and init <function _initializer at 0x7fcbb1a8aaa0>\n2016-06-30 14:15:54,029 INFO Created variable conv3_3/biases:0 with shape (256,) and init <function _initializer at 0x7fcbb1a8aaa0>\nPool 3 layer ready\nLayer name: conv4_1\nLayer shape: (3, 3, 256, 512)\n\nINFO:tensorflow:Created variable conv4_1/filter:0 with shape (3, 3, 256, 512) and init <function _initializer at 0x7fcbb1a4c7d0>\n2016-06-30 14:15:54,043 INFO Created variable conv4_1/filter:0 with shape (3, 3, 256, 512) and init <function _initializer at 0x7fcbb1a4c7d0>\n\nINFO:tensorflow:Created variable conv4_1/biases:0 with shape (512,) and init <function _initializer at 0x7fcbb1a4c7d0>\n2016-06-30 14:15:54,048 INFO Created variable conv4_1/biases:0 with shape (512,) and init <function _initializer at 0x7fcbb1a4c7d0>\nLayer name: conv4_2\nLayer shape: (3, 3, 512, 512)\n\nINFO:tensorflow:Created variable conv4_2/filter:0 with shape (3, 3, 512, 512) and init <function _initializer at 0x7fcbb1a12500>\n2016-06-30 14:15:54,063 INFO Created variable conv4_2/filter:0 with shape (3, 3, 512, 512) and init <function _initializer at 0x7fcbb1a12500>\n\nINFO:tensorflow:Created variable conv4_2/biases:0 with shape (512,) and init <function _initializer at 0x7fcbb1a12500>\n2016-06-30 14:15:54,068 INFO Created variable conv4_2/biases:0 with shape (512,) and init <function _initializer at 0x7fcbb1a12500>\nLayer name: conv4_3\nLayer shape: (3, 3, 512, 512)\n\nINFO:tensorflow:Created variable conv4_3/filter:0 with shape (3, 3, 512, 512) and init <function _initializer at 0x7fcbb19d89b0>\n2016-06-30 14:15:54,083 INFO Created variable conv4_3/filter:0 with shape (3, 3, 512, 512) and init <function _initializer at 0x7fcbb19d89b0>\n\nINFO:tensorflow:Created variable conv4_3/biases:0 with shape (512,) and init <function _initializer at 0x7fcbb19d89b0>\n2016-06-30 14:15:54,088 INFO Created variable conv4_3/biases:0 with shape (512,) and init <function _initializer at 0x7fcbb19d89b0>\nPool 4 layer ready\nLayer name: conv5_1\nLayer shape: (3, 3, 512, 512)\n\nINFO:tensorflow:Created variable conv5_1/filter:0 with shape (3, 3, 512, 512) and init <function _initializer at 0x7fcbb199f6e0>\n2016-06-30 14:15:54,103 INFO Created variable conv5_1/filter:0 with shape (3, 3, 512, 512) and init <function _initializer at 0x7fcbb199f6e0>\n\nINFO:tensorflow:Created variable conv5_1/biases:0 with shape (512,) and init <function _initializer at 0x7fcbb199f6e0>\n2016-06-30 14:15:54,108 INFO Created variable conv5_1/biases:0 with shape (512,) and init <function _initializer at 0x7fcbb199f6e0>\nLayer name: conv5_2\nLayer shape: (3, 3, 512, 512)\n\nINFO:tensorflow:Created variable conv5_2/filter:0 with shape (3, 3, 512, 512) and init <function _initializer at 0x7fcbb1961488>\n2016-06-30 14:15:54,122 INFO Created variable conv5_2/filter:0 with shape (3, 3, 512, 512) and init <function _initializer at 0x7fcbb1961488>\n\nINFO:tensorflow:Created variable conv5_2/biases:0 with shape (512,) and init <function _initializer at 0x7fcbb18daf50>\n2016-06-30 14:15:54,127 INFO Created variable conv5_2/biases:0 with shape (512,) and init <function _initializer at 0x7fcbb18daf50>\nLayer name: conv5_3\nLayer shape: (3, 3, 512, 512)\n\nINFO:tensorflow:Created variable conv5_3/filter:0 with shape (3, 3, 512, 512) and init <function _initializer at 0x7fcbb1961488>\n2016-06-30 14:15:54,141 INFO Created variable conv5_3/filter:0 with shape (3, 3, 512, 512) and init <function _initializer at 0x7fcbb1961488>\n\nINFO:tensorflow:Created variable conv5_3/biases:0 with shape (512,) and init <function _initializer at 0x7fcbb1961488>\n2016-06-30 14:15:54,146 INFO Created variable conv5_3/biases:0 with shape (512,) and init <function _initializer at 0x7fcbb1961488>\nPool 5 layer ready\nLayer name: fc6\nLayer shape: [7, 7, 512, 4096]\n\nINFO:tensorflow:Created variable fc6/weights:0 with shape (7, 7, 512, 4096) and init <function _initializer at 0x7fcbb186b5f0>\n2016-06-30 14:15:54,435 INFO Created variable fc6/weights:0 with shape (7, 7, 512, 4096) and init <function _initializer at 0x7fcbb186b5f0>\n\nINFO:tensorflow:Created variable fc6/biases:0 with shape (4096,) and init <function _initializer at 0x7fcbb186b5f0>\n2016-06-30 14:15:54,438 INFO Created variable fc6/biases:0 with shape (4096,) and init <function _initializer at 0x7fcbb186b5f0>\nLayer name: fc7\nLayer shape: [1, 1, 4096, 4096]\n\nINFO:tensorflow:Created variable fc7/weights:0 with shape (1, 1, 4096, 4096) and init <function _initializer at 0x7fcbb189fed8>\n2016-06-30 14:15:54,492 INFO Created variable fc7/weights:0 with shape (1, 1, 4096, 4096) and init <function _initializer at 0x7fcbb189fed8>\n\nINFO:tensorflow:Created variable fc7/biases:0 with shape (4096,) and init <function _initializer at 0x7fcbb189fed8>\n2016-06-30 14:15:54,495 INFO Created variable fc7/biases:0 with shape (4096,) and init <function _initializer at 0x7fcbb189fed8>\n\nINFO:tensorflow:Created variable score_fr/weights:0 with shape (1, 1, 4096, 14) and init <function _initializer at 0x7fcbb186b5f0>\n2016-06-30 14:15:54,506 INFO Created variable score_fr/weights:0 with shape (1, 1, 4096, 14) and init <function _initializer at 0x7fcbb186b5f0>\n\nINFO:tensorflow:Created variable score_fr/biases:0 with shape (14,) and init <function _initializer at 0x7fcbb186b5f0>\n2016-06-30 14:15:54,510 INFO Created variable score_fr/biases:0 with shape (14,) and init <function _initializer at 0x7fcbb186b5f0>\n\nINFO:tensorflow:Created variable upscore2/up_filter:0 with shape (4, 4, 14, 14) and init <function _initializer at 0x7fcbb17a48c0>\n2016-06-30 14:15:54,525 INFO Created variable upscore2/up_filter:0 with shape (4, 4, 14, 14) and init <function _initializer at 0x7fcbb17a48c0>\n\nINFO:tensorflow:Created variable score_pool4/weights:0 with shape (1, 1, 512, 14) and init <function _initializer at 0x7fcbb17a48c0>\n2016-06-30 14:15:54,536 INFO Created variable score_pool4/weights:0 with shape (1, 1, 512, 14) and init <function _initializer at 0x7fcbb17a48c0>\n\nINFO:tensorflow:Created variable score_pool4/biases:0 with shape (14,) and init <function _initializer at 0x7fcbb17a48c0>\n2016-06-30 14:15:54,540 INFO Created variable score_pool4/biases:0 with shape (14,) and init <function _initializer at 0x7fcbb17a48c0>\n\nINFO:tensorflow:Created variable upscore4/up_filter:0 with shape (4, 4, 14, 14) and init <function _initializer at 0x7fcbb16c0aa0>\n2016-06-30 14:15:54,555 INFO Created variable upscore4/up_filter:0 with shape (4, 4, 14, 14) and init <function _initializer at 0x7fcbb16c0aa0>\n\nINFO:tensorflow:Created variable score_pool3/weights:0 with shape (1, 1, 256, 14) and init <function _initializer at 0x7fcbb16c0aa0>\n2016-06-30 14:15:54,566 INFO Created variable score_pool3/weights:0 with shape (1, 1, 256, 14) and init <function _initializer at 0x7fcbb16c0aa0>\n\nINFO:tensorflow:Created variable score_pool3/biases:0 with shape (14,) and init <function _initializer at 0x7fcbb16c0aa0>\n2016-06-30 14:15:54,570 INFO Created variable score_pool3/biases:0 with shape (14,) and init <function _initializer at 0x7fcbb16c0aa0>\n\nINFO:tensorflow:Created variable upscore32/up_filter:0 with shape (16, 16, 14, 14) and init <function _initializer at 0x7fcbb15eb758>\n2016-06-30 14:15:54,585 INFO Created variable upscore32/up_filter:0 with shape (16, 16, 14, 14) and init <function _initializer at 0x7fcbb15eb758>`\n```\n\nBeen stuck on this for quite some time and cant figure out whats wrong... Any help will be appreciated :)\n", "comments": ["Is this still occurring (try the 0.10RC for example).  If it is still occurring, it will be difficult to help you any further without you providing a self-contained reproducible test case. I understand these errors are frustrating.\n", "Automatically closing due to lack of recent activity. Please reopen when additional becomes available.\n"]}, {"number": 3173, "title": "Pip should not install as super user in the install tutorial (sudo pip install \u2026)", "body": "Is there a particular reason it is installed as root in this case? It is usually deprecated to do it this way. \n", "comments": ["See also this SO Q/A: http://stackoverflow.com/questions/33004708/osx-el-capitan-sudo-pip-install-oserror-errno-1-operation-not-permitted/33004920#33004920\n", "That stackoverflow is interesting, but the comment which suggests not using sudo pip install does not suggest a solution that works for all users globally. That is one reason that sudo pip install  could be preferred.\n", "Automatically closing due to lack of recent activity. Please reopen when further information becomes available.\n"]}, {"number": 3172, "title": "float division by zero", "body": "It seems that if you only run 1 training step at a time then you can come to a point where it is too fast\n\n```\nTraceback (most recent call last):\n  File \"main.py\", line 6, in <module>\n    connection.start_socket(8089, callback=handler.message_processor)\n  File \"/mnt/d/workspace/SketchRecognitionWithTensorFlow/src/main/python/connection/python_socket_server.py\", line 13, in start_socket\n    process_message(connection, callback=callback)\n  File \"/mnt/d/workspace/SketchRecognitionWithTensorFlow/src/main/python/connection/python_socket_server.py\", line 38, in process_message\n    result = callback(general_proto)\n  File \"/mnt/d/workspace/SketchRecognitionWithTensorFlow/src/main/python/recognition/proto_handler.py\", line 39, in message_processor\n    return train_shape(general_proto.template)\n  File \"/mnt/d/workspace/SketchRecognitionWithTensorFlow/src/main/python/recognition/proto_handler.py\", line 23, in train_shape\n    rec.add_training_data(recognition_template.interpretation.label, recognition_template.shape)\n  File \"/mnt/d/workspace/SketchRecognitionWithTensorFlow/src/main/python/recognition/recognition_manager.py\", line 98, in add_training_data\n    self.recognizers[label].train(label, points)\n  File \"/mnt/d/workspace/SketchRecognitionWithTensorFlow/src/main/python/recognition/simple/recognizer.py\", line 82, in train\n    self.classifier.fit(x=reshaped_points, y=target, steps=1)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 182, in fit\n    monitors=monitors)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 484, in _train_model\n    monitors=monitors)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/graph_actions.py\", line 296, in train\n    supervisor.Stop(close_summary_writer=False)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py\", line 768, in stop\n    stop_grace_period_secs=self._stop_grace_secs)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/coordinator.py\", line 322, in join\n    six.reraise(*self._exc_info_to_raise)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/coordinator.py\", line 267, in stop_on_exception\n    yield\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/coordinator.py\", line 411, in run\n    self.run_loop()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py\", line 1012, in run_loop\n    steps_per_sec = added_steps / elapsed_time\nZeroDivisionError: float division by zero\n```\n\nThis happens because the time between the start of the step and the end is exactly the same because it is a single step.\n\nHere is the code snippet\n\n```\ncurrent_time = time.time()\n    elapsed_time = current_time - self._last_time\n    self._last_time = current_time\n    # Reports the number of steps done per second\n    steps_per_sec = added_steps / elapsed_time\n    summary = Summary(value=[Summary.Value(tag=self._summary_tag,\n                                           simple_value=steps_per_sec)])\n```\n\nMaybe add an if statement to just say zero if elapsed_time is zero?\n", "comments": ["You can measure the elapsed time in microseconds (**datetime.timedelta**) and than scale it to get steps done per seconds.\n", "I added an if statement that says if elapsed time is zero just set it to\nadded steps. That fixed it too\nOn Jul 3, 2016 4:33 PM, \"ahmetemir\" notifications@github.com wrote:\n\n> You can measure the elapsed time in microseconds (_datetime.timedelta_)\n> and than scale it to get steps done per seconds.\n> \n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/3172#issuecomment-230179376,\n> or mute the thread\n> https://github.com/notifications/unsubscribe/AB2CDKGUOklf0AvwMg82Da6RemPqdkhGks5qSDjCgaJpZM4JD5RE\n> .\n", "It can mislead you.Think that elapsed time is zero and you get 10 steps.This doesn't mean 10 steps per seconds.If the elpased time is actually 100 microseconds than you should know that it's  100 steps per seconds.\n", "I think the right answer is probably inf steps / second since as seconds goes to zero the relative performance should become arbitrarily large. The question is whether the Summary system is able to handle that..\n", "And statistically you can't trust the results of such a low sample measurement.To get more precise results, same test have to run for a long period of time over and over and you have to analyze the results using statistics.\n", "This references code that moved quite substantially in the last few months. Feel free to open a new github issue if the problem still persists in recent versions."]}, {"number": 3171, "title": "R0.9", "body": "", "comments": ["Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n"]}, {"number": 3170, "title": "Gradients are always zero during training", "body": "I have implemented [YOLO](http://pjreddie.com/media/files/papers/yolo.pdf) algorithm in tensorflow and face with an issue during training: all my gradients are equal to zero from the very beginning of training. I also noticed that with some weights initialization gradients become non-zero at first several iterations and then stick to zero. Thanks in advance for any help!\n### Environment info\n\nOperating System: Ubuntu 16.04 lts\nTensorflow version: 0.8.0\n", "comments": ["The issue has been fixed by itself.\n", "Can you explain a bit about how you fixed it ?", "This message was created automatically by mail delivery software.\n\nA message that you sent could not be delivered to one or more of its\nrecipients. This is a temporary error. The following address(es) deferred:\n\n  mazecreator@gmail.com\n    Domain mazecreator.com has exceeded the max emails per hour (28/25 (112%)) allowed.  Message will be reattempted later\n\n------- This is a copy of the message, including all the headers. ------\nReceived: from github-smtp2-ext6.iad.github.net ([192.30.252.197]:51228 helo=github-smtp2b-ext-cp1-prd.iad.github.net)\n\tby server2.lowesthostingrates.com with esmtps (TLSv1.2:ECDHE-RSA-AES256-GCM-SHA384:256)\n\t(Exim 4.89)\n\t(envelope-from <noreply@github.com>)\n\tid 1demwa-0005nS-Ff\n\tfor mazecreator@mazecreator.com; Mon, 07 Aug 2017 13:40:30 -0500\nDate: Mon, 07 Aug 2017 11:50:53 -0700\nDKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=github.com;\n\ts=pf2014; t=1502131853;\n\tbh=wnmIVO8laFF0/QYZjd0HsbZDsIKi1MP3qQarBGXHvo4=;\n\th=From:Reply-To:To:Cc:In-Reply-To:References:Subject:List-ID:\n\t List-Archive:List-Post:List-Unsubscribe:From;\n\tb=ojwXFYfc7BzmEQlBPlWzcORr6EGUAPGYzbPOJJNqWanb+B7ecIPDoxeGNxUvaW92x\n\t tJ7vYUNoUXaVAPBO/5O8UGQv9JWh6Gveg8bxEkc9wXZFa+XW7twYtIFj23skNjBTuA\n\t rIeZFIvwcnuRkgxYY+dT5/pA7bxCE8LExK99pLNk=\nFrom: samrat1997 <notifications@github.com>\nReply-To: tensorflow/tensorflow <reply@reply.github.com>\nTo: tensorflow/tensorflow <tensorflow@noreply.github.com>\nCc: Subscribed <subscribed@noreply.github.com>\nMessage-ID: <tensorflow/tensorflow/issues/3170/320748207@github.com>\nIn-Reply-To: <tensorflow/tensorflow/issues/3170@github.com>\nReferences: <tensorflow/tensorflow/issues/3170@github.com>\nSubject: Re: [tensorflow/tensorflow] Gradients are always zero during training\n (#3170)\nMime-Version: 1.0\nContent-Type: multipart/alternative;\n boundary=\"--==_mimepart_5988b68d84af9_53e13fb096101c34317762\";\n charset=UTF-8\nContent-Transfer-Encoding: 7bit\nPrecedence: list\nX-GitHub-Sender: samrat1997\nX-GitHub-Recipient: Mazecreator\nX-GitHub-Reason: subscribed\nList-ID: tensorflow/tensorflow <tensorflow.tensorflow.github.com>\nList-Archive: https://github.com/tensorflow/tensorflow\nList-Post: <mailto:reply@reply.github.com>\nList-Unsubscribe: <mailto:unsub+0118f3a0d282c3ae987647e5aba0e4aa1db327e6515cd58a92cf0000000115a0788d92a169ce09bfc4ba@reply.github.com>,\n <https://github.com/notifications/unsubscribe/ARjzoBlP33jLOO83253dVH28h6LOx53Yks5sV1yNgaJpZM4JD3wR>\nX-Auto-Response-Suppress: All\nX-GitHub-Recipient-Address: mazecreator@mazecreator.com\nX-Spam-Status: No, score=\nX-Spam-Score:\nX-Spam-Bar:\nX-Ham-Report:\nX-Spam-Flag: NO\n\n\n----==_mimepart_5988b68d84af9_53e13fb096101c34317762\nContent-Type: text/plain;\n charset=UTF-8\nContent-Transfer-Encoding: 7bit\n\nCan you explain a bit about how you fixed it ?\n\n-- \nYou are receiving this because you are subscribed to this thread.\nReply to this email directly or view it on GitHub:\nhttps://github.com/tensorflow/tensorflow/issues/3170#issuecomment-320748207\n----==_mimepart_5988b68d84af9_53e13fb096101c34317762\nContent-Type: text/html;\n charset=UTF-8\nContent-Transfer-Encoding: 7bit\n\n<p>Can you explain a bit about how you fixed it ?</p>\n\n<p style=\"font-size:small;-webkit-text-size-adjust:none;color:#666;\">&mdash;<br />You are receiving this because you are subscribed to this thread.<br />Reply to this email directly, <a href=\"https://github.com/tensorflow/tensorflow/issues/3170#issuecomment-320748207\">view it on GitHub</a>, or <a href=\"https://github.com/notifications/unsubscribe-auth/ARjzoOpgOjmRM4ynQledW8EUQ6x4o_-Qks5sV1yNgaJpZM4JD3wR\">mute the thread</a>.<img alt=\"\" height=\"1\" src=\"https://github.com/notifications/beacon/ARjzoAAET1czgZovZim4dwqsK9HTjrcAks5sV1yNgaJpZM4JD3wR.gif\" width=\"1\" /></p>\n<div itemscope itemtype=\"http://schema.org/EmailMessage\">\n<div itemprop=\"action\" itemscope itemtype=\"http://schema.org/ViewAction\">\n  <link itemprop=\"url\" href=\"https://github.com/tensorflow/tensorflow/issues/3170#issuecomment-320748207\"></link>\n  <meta itemprop=\"name\" content=\"View Issue\"></meta>\n</div>\n<meta itemprop=\"description\" content=\"View this Issue on GitHub\"></meta>\n</div>\n\n<script type=\"application/json\" data-scope=\"inboxmarkup\">{\"api_version\":\"1.0\",\"publisher\":{\"api_key\":\"05dde50f1d1a384dd78767c55493e4bb\",\"name\":\"GitHub\"},\"entity\":{\"external_key\":\"github/tensorflow/tensorflow\",\"title\":\"tensorflow/tensorflow\",\"subtitle\":\"GitHub repository\",\"main_image_url\":\"https://cloud.githubusercontent.com/assets/143418/17495839/a5054eac-5d88-11e6-95fc-7290892c7bb5.png\",\"avatar_image_url\":\"https://cloud.githubusercontent.com/assets/143418/15842166/7c72db34-2c0b-11e6-9aed-b52498112777.png\",\"action\":{\"name\":\"Open in GitHub\",\"url\":\"https://github.com/tensorflow/tensorflow\"}},\"updates\":{\"snippets\":[{\"icon\":\"PERSON\",\"message\":\"@samrat1997 in #3170: Can you explain a bit about how you fixed it ?\"}],\"action\":{\"name\":\"View Issue\",\"url\":\"https://github.com/tensorflow/tensorflow/issues/3170#issuecomment-320748207\"}}}</script>\n----==_mimepart_5988b68d84af9_53e13fb096101c34317762--\n"]}, {"number": 3169, "title": "AttributeError: 'module' object has no attribute 'linear'", "body": "I'm trying to run this tutorial : https://medium.com/@ilblackdragon/tensorflow-tutorial-part-1-c559c63c0cb1#.1a7hit535\n\nI have got some errors on this bug report : https://github.com/tensorflow/tensorflow/issues/3167\n\nThen I have tried to fix it by modifying the TF Learn code. \n### Environment info\n\nOperating System: Linux Mint 17.3 Rosa\n$uname -a\n\nLinux Pabeda 3.19.0-32-generic #37~14.04.1-Ubuntu SMP Thu Oct 22 09:41:40 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux\n\n$python -c \"import tensorflow; print(tensorflow.version)\"\n0.9.0\n### Steps to reproduce\n1. $ git clone https://github.com/ilblackdragon/tf_examples.git\n2. edit /usr/local/lib/python2.7/dist-packages/skflow/trainer.py\n\nLine 146 \n\nreplace\n`if summaries`\nwith\n`if summaries is not None:`\n\nLine 167\n\nreplace\n`if summaries  and summary_writer and summ is not None`\nwith\n`if summaries is not None and summary_writer is not None and summ is not None:`\n\n3.$python titanic.py\n### Errors\n\nTraceback (most recent call last):\n  File \"titanic.py\", line 41, in <module>\n    classifier.fit(X_train, y_train)\n  File \"/usr/local/lib/python2.7/dist-packages/skflow/estimators/base.py\", line 200, in fit\n    self._setup_training()\n  File \"/usr/local/lib/python2.7/dist-packages/skflow/estimators/base.py\", line 139, in _setup_training\n    self._inp, self._out)\n  File \"/usr/local/lib/python2.7/dist-packages/skflow/estimators/dnn.py\", line 82, in _model_fn\n    models.logistic_regression)(X, y)\n  File \"/usr/local/lib/python2.7/dist-packages/skflow/models.py\", line 99, in dnn_estimator\n    layers = dnn(X, hidden_units)\n  File \"/usr/local/lib/python2.7/dist-packages/skflow/ops/dnn_ops.py\", line 39, in dnn\n    tensor_in = tf.nn.rnn_cell.linear(tensor_in, n_units, True)\nAttributeError: 'module' object has no attribute 'linear'\n", "comments": ["Like #3167, I believe the problem here is that @ilblackdragon tutorial is not up to date for 0.9. So I am closing for now. \n"]}, {"number": 3168, "title": "fully_connected_preloaded example: Attempting to use uninitialized value input/input_producer/input_producer/fraction_of_32_full/limit_epochs/epochs", "body": "I have the error `Attempting to use uninitialized value input/input_producer/input_producer/fraction_of_32_full/limit_epochs/epochs` when I load data in my code. I have found the same issue on the fully_connected_preloaded example, so I think it may be a regression.\n### Environment info\n\nOperating System: Ubuntu 16.04\n\nInstalled version of CUDA and cuDNN: Cuda 8.0 and CuDnn 8.0\n\n``` bash\n$ ls -l /path/to/cuda/lib*/libcud*\n-rw-r--r-- 1 root root   560184 juin  30 00:45 /usr/local/cuda/lib64/libcudadevrt.a\nlrwxrwxrwx 1 root root       16 juin  30 00:45 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0\nlrwxrwxrwx 1 root root       19 juin  30 00:45 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.27\n-rwxr-xr-x 1 root root   394472 juin  30 00:45 /usr/local/cuda/lib64/libcudart.so.8.0.27\n-rw-r--r-- 1 root root   737516 juin  30 00:45 /usr/local/cuda/lib64/libcudart_static.a\n-rwxr-xr-x 1 root root 78065952 juin  30 01:08 /usr/local/cuda/lib64/libcudnn.so\n-rwxr-xr-x 1 root root 78065952 juin  30 01:08 /usr/local/cuda/lib64/libcudnn.so.5\n-rwxr-xr-x 1 root root 78065952 juin  30 01:08 /usr/local/cuda/lib64/libcudnn.so.5.0.5\n-rw-r--r-- 1 root root 68709594 juin  30 01:08 /usr/local/cuda/lib64/libcudnn_static.a\n```\n\nIf installed from sources, provide the commit hash: db90885e9f27b1e069dd689ddd2dd3b743ed1cb7\n### Steps to reproduce\n1. cd tensorflow/examples/how_tos/reading_data\n2. python fully_connected_preloaded.py\n### What have you tried?\n1. `bazel run -c opt tensorflow/examples/how_tos/reading_data:fully_connected_preloaded``\n2. `python fully_connected_preloaded.py`\n3. My code, which is similar\n### Logs or other output that would be helpful\n\n(If logs are large, please upload as attachment).\n\n``` python\npython fully_connected_preloaded.py\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally\nExtracting /tmp/data/train-images-idx3-ubyte.gz\nExtracting /tmp/data/train-labels-idx1-ubyte.gz\nExtracting /tmp/data/t10k-images-idx3-ubyte.gz\nExtracting /tmp/data/t10k-labels-idx1-ubyte.gz\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties:\nname: GeForce GTX 1080\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.7335\npciBusID 0000:02:00.0\nTotal memory: 7.92GiB\nFree memory: 7.52GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:02:00.0)\nSaving\nW tensorflow/core/framework/op_kernel.cc:936] Out of range: FIFOQueue '_1_input/input_producer/input_producer/fraction_of_32_full/fraction_of_32_full' is closed and has insufficient elements (requested 1, current size 0)\n     [[Node: input/input_producer/fraction_of_32_full_Dequeue = QueueDequeue[_class=[\"loc:@input/input_producer/input_producer/fraction_of_32_full/fraction_of_32_full\"], component_types=[DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](input/input_producer/input_producer/fraction_of_32_full/fraction_of_32_full)]]\nDone training for 2 epochs, 0 steps.\nTraceback (most recent call last):\n  File \"fully_connected_preloaded.py\", line 157, in <module>\n    tf.app.run()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 30, in run\n    sys.exit(main(sys.argv))\n  File \"fully_connected_preloaded.py\", line 153, in main\n    run_training()\n  File \"fully_connected_preloaded.py\", line 148, in run_training\n    coord.join(threads)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/coordinator.py\", line 333, in join\n    six.reraise(*self._exc_info_to_raise)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/queue_runner.py\", line 185, in _run\n    sess.run(enqueue_op)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 382, in run\n    run_metadata_ptr)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 655, in _run\n    feed_dict_string, options, run_metadata)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 723, in _do_run\n    target_list, options, run_metadata)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 743, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors.FailedPreconditionError: Attempting to use uninitialized value input/input_producer/input_producer/fraction_of_32_full/limit_epochs/epochs\n     [[Node: input/input_producer/input_producer/fraction_of_32_full/limit_epochs/CountUpTo = CountUpTo[T=DT_INT64, _class=[\"loc:@input/input_producer/input_producer/fraction_of_32_full/limit_epochs/epochs\"], limit=2, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](input/input_producer/input_producer/fraction_of_32_full/limit_epochs/epochs)]]\nCaused by op u'input/input_producer/input_producer/fraction_of_32_full/limit_epochs/CountUpTo', defined at:\n  File \"fully_connected_preloaded.py\", line 157, in <module>\n    tf.app.run()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 30, in run\n    sys.exit(main(sys.argv))\n  File \"fully_connected_preloaded.py\", line 153, in main\n    run_training()\n  File \"fully_connected_preloaded.py\", line 73, in run_training\n    [input_images, input_labels], num_epochs=FLAGS.num_epochs)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/input.py\", line 266, in slice_input_producer\n    shared_name=shared_name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/input.py\", line 223, in range_input_producer\n    shared_name, name, \"fraction_of_%d_full\" % capacity)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/input.py\", line 133, in input_producer\n    input_tensor = limit_epochs(input_tensor, num_epochs)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/input.py\", line 84, in limit_epochs\n    counter = epochs.count_up_to(num_epochs)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py\", line 573, in count_up_to\n    return state_ops.count_up_to(self._variable, limit=limit)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_state_ops.py\", line 127, in count_up_to\n    result = _op_def_lib.apply_op(\"CountUpTo\", ref=ref, limit=limit, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 703, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2297, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1231, in __init__\n    self._traceback = _extract_stack()\n```\n", "comments": ["This appears to be a regression since r0.9. Can you try r0.9 and see if it works for you?\n", "Assigning @josh11b as he is the original author of fully_connected_preloaded.py\n", "Same issue with cuda-7.0 cudnn v4 and tesla k40c.\n", "`init_op = tf.group(tf.initialize_all_variables(),\n                           tf.initialize_local_variables())`\nsolves the issue\n", "usage of `num_epochs` means you apparently _have_ to use `initialize_local_variables()`\n", "@MatthieuBizien, could you confirm that your issue is resolved by using initialize_local_variables so we can close hte issue?\n", "This issue is already closed though.\n", "The issue resolved in my case by calling initialize_local_variables(). It's a regression compared with r0.9.\n", "Thanks for the update.\n"]}, {"number": 3167, "title": "Using a `tf.Tensor` as a Python `bool` is not allowed.", "body": "### Environment info\n\nOperating System: Linux Mint 17.3 Rosa\n$uname -a\n\nLinux Pabeda 3.19.0-32-generic #37~14.04.1-Ubuntu SMP Thu Oct 22 09:41:40 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux\n\n$python -c \"import tensorflow; print(tensorflow.**version**)\"\n0.9.0\n### Steps to reproduce\n\n$ git clone https://github.com/ilblackdragon/tf_examples.git\n$ python titanic.py\n### What have you tried?\n1. I'm trying to run the tutorial on : https://medium.com/@ilblackdragon/tensorflow-tutorial-part-1-c559c63c0cb1#.1a7hit535\n### Errors\n\n/usr/local/lib/python2.7/dist-packages/skflow/io/data_feeder.py:217: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n  out.itemset((i, self.y[sample]), 1.0)\nTraceback (most recent call last):\n  File \"titanic.py\", line 30, in <module>\n    tflr.fit(X_train, y_train)\n  File \"/usr/local/lib/python2.7/dist-packages/skflow/estimators/base.py\", line 227, in fit\n    feed_params_fn=self._data_feeder.get_feed_params)\n  File \"/usr/local/lib/python2.7/dist-packages/skflow/trainer.py\", line 146, in train\n    if summaries:\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 528, in __nonzero__\n    raise TypeError(\"Using a `tf.Tensor` as a Python `bool` is not allowed. \"\nTypeError: Using a `tf.Tensor` as a Python `bool` is not allowed. Use `if t is not None:` instead of `if t:` to test if a tensor is defined, and use the logical TensorFlow ops to test the value of a tensor.\n", "comments": ["This is not a TensorFlow issue.  You should report to https://github.com/ilblackdragon/tf_examples not here.\n\nAnyway, to fix it, just follow the instructions: replace `if t` with `if t is not None`.\n", "@ilblackdragon, what do you think about @thinxer's reponse?\n", "Closing for now as now as this is intended behavior. Using implicit bool conversions is error prone which is why it is disallowed. Thanks!\n"]}, {"number": 3166, "title": "update tflearn example digits.py", "body": "the previous `classifier.fit(X_train, y_train, val_monitor)` has a problem,\nthe `learn.TensorFlowEstimator.fit(x, y, steps=None, monitors=None, logdir=None)` now has `monitors` as the fourth argument, and should be a `list`\nI modified it to `classifier.fit(X_train, y_train, monitors=[val_monitor])` but this cause a new problem.\nIs is this a bug from `TensorFlowEstimators` or `ValidationMonitor`\n\n```\nTypeError                                 Traceback (most recent call last)\n/home/wenjian/digits.py in <module>()\n     55                                         steps=1000, learning_rate=0.05,\n     56                                         batch_size=128)\n---> 57 classifier.fit(X_train, y_train, monitors=[val_monitor])\n     58 score = metrics.accuracy_score(y_test, classifier.predict(X_test))\n     59 print('Test Accuracy: {0:f}'.format(score))\n\n/home/wenjian/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/base.py in fit(self, x, y, steps, monitors, logdir)\n    164                       feed_fn=self._data_feeder.get_feed_dict_fn(),\n    165                       steps=steps or self.steps,\n--> 166                       monitors=monitors)\n    167     return self\n    168 \n\n/home/wenjian/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py in _train_model(self, input_fn, steps, feed_fn, init_op, init_feed_fn, init_fn, device_fn, monitors, log_every_steps, fail_on_nan_loss, max_steps)\n    528           fail_on_nan_loss=fail_on_nan_loss,\n    529           monitors=monitors,\n--> 530           max_steps=max_steps)\n    531 \n    532   def _extract_metric_update_ops(self, eval_dict):\n\n/home/wenjian/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/graph_actions.py in train(graph, output_dir, train_op, loss_op, global_step_tensor, init_op, init_feed_dict, init_fn, log_every_steps, supervisor_is_chief, supervisor_master, supervisor_save_model_secs, keep_checkpoint_max, supervisor_save_summaries_steps, feed_fn, steps, fail_on_nan_loss, monitors, max_steps)\n    362       finally:\n    363         if excinfo:\n--> 364           reraise(*excinfo)\n    365     return loss_value\n    366 \n\n/home/wenjian/anaconda3/lib/python3.5/site-packages/six.py in reraise(tp, value, tb)\n    684         if value.__traceback__ is not tb:\n    685             raise value.with_traceback(tb)\n--> 686         raise value\n    687 \n    688 else:\n\n/home/wenjian/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/graph_actions.py in train(graph, output_dir, train_op, loss_op, global_step_tensor, init_op, init_feed_dict, init_fn, log_every_steps, supervisor_is_chief, supervisor_master, supervisor_save_model_secs, keep_checkpoint_max, supervisor_save_summaries_steps, feed_fn, steps, fail_on_nan_loss, monitors, max_steps)\n    287         try:\n    288           outputs, should_stop = _run_with_monitors(\n--> 289               session, last_step + 1, [train_op, loss_op], feed_dict, monitors)\n    290         except errors.AbortedError as e:\n    291           # Happens when PS restarts, keep training.\n\n/home/wenjian/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/graph_actions.py in _run_with_monitors(session, step, tensors, feed_dict, monitors)\n    121   should_stop = False\n    122   for monitor in monitors:\n--> 123     induce_stop = monitor.step_end(step, outputs)\n    124     should_stop = should_stop or induce_stop\n    125   return outputs, should_stop\n\n/home/wenjian/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/monitors.py in step_end(self, step, output)\n    205     if (self._active_step is not None) and (self._active_step == step):\n    206       self._last_step = step\n--> 207       to_stop = self.every_n_step_end(step, output)\n    208       self._active_step = None\n    209     return to_stop\n\n/home/wenjian/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/monitors.py in every_n_step_end(self, step, outputs)\n    371     outputs = self._estimator.evaluate(\n    372         x=self.x, y=self.y, input_fn=self.input_fn, batch_size=self.batch_size,\n--> 373         steps=self.eval_steps, metrics=self.metrics, name=self.name)\n    374     stats = []\n    375     for name in outputs:\n\nTypeError: evaluate() got an unexpected keyword argument 'batch_size'\n```\n", "comments": ["Can one of the admins verify this patch?\n", "@tensorflow-jenkins test this please.\n"]}]