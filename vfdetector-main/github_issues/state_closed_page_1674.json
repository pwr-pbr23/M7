[{"number": 2684, "title": "parameterized_docker_build includes three CUDA capabilities", "body": "", "comments": []}, {"number": 2683, "title": "parameterized_docker_build includes three CUDA capabilities", "body": "Before it included only one (3.0).\n", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request) and all commit authors, but as best as we can tell these commits were authored by someone else.  If that's the case,  please add them to this pull request and have them confirm that they're okay with these commits being contributed to Google.  If we're mistaken and you did author these commits, just reply here to confirm.\n\n<!-- need_author_consent -->\n"]}, {"number": 2682, "title": "hessian free optimizer needed", "body": "Hessian free optimizers are successfully applied on neural networks  (especially RNNs). Currently need one in TF!\n", "comments": ["PRs welcome!\n", "I would like to work on this.\n", "@ajaybhat Let us know if you have questions or issues!\n", "@girving Could you let me know which classes to look for as a reference to implement optimizers? I'm having a bit of trouble finding them.\n", "@ajaybhat Search for classes which inherit from `Optimizer`.  However, note that for Hessian free methods the standard split into `compute_gradients` and `apply_gradients` won't work, since you need to compute partial second order gradients.  There are a few different ways one could handle that; the simplest would be to compute gradients as normal during `compute_gradients` and do the higher order stuff in `apply_gradients`.\n", "Thanks! I'll let you know if i've any more questions.\n", "I was also try to implement HessianFree (HF) optimization on another framework, however i did not success. I am not sure if you can use this git (https://github.com/drasmuss/hessianfree) as reference or ask for help. The implementation is already on python and cuda, but he did not implemented convolutional. If you have a code to test let me know so i can compare with my others results.\n", "Is there anyone who is still trying to implement HF optimization on the tensorflow framework?", "I was attempting to implement HF optimisation and Saddle Free Newton. These algorithms are doable in a FFN framework. Unfortunately for RNN's as discussed in #5985 it is currently not possible to calculate second order derivatives from DynamicRNN's due to the use of a while loop. The current workaround would be to use StaticRNN. However, the while loop second derivative issue seems to be the major issue when attempting to implement a general Hessian Free optimisation algorithm or any other general second order method which requires Hessian Vector Products.", "Automatically closing due to lack of recent activity. Since this issue is old at this point, please reopen the issue if it still occurs when tried with the latest version of Tensorflow. Thank you.", "It's been more than a year since the Issue was closed, TF 1.3 was recently deployed and I still think that a Hessian Free Optimizer implementation for TF would be great. \r\n\r\nConsider reopening?", "Pardon me to promote my second-order optimization methods here. If interested, please check my tensorflow package at https://github.com/lixilinx/psgd_tf  \r\nSecond-order optimization with five different preconditioners and rnn/cnn examples are provided. It works for both FNN and RNN with while loop. We know that tf.while_loop still does not support second-order derivative. To work around it, you can just use perturbation of gradient to approximate the Hessian-vector product you want.\r\n\r\nAs for HF optimization, its damping factor and step size in line search are obtained by trial-and-error, and this could cause further troubles for its tensorflow implementation. A second-order method without line search is preferred, and methods in the above link are such examples.", "Here is an implementation of the Saddle Free method:\r\nhttps://github.com/dave-fernandes/SaddleFreeOptimizer", "amazing"]}, {"number": 2681, "title": "Enable tf.size() for SparseTensor", "body": "Added an override for `tf.size()`, that takes care of `SparseTensor` objects as well. Added tests and verified locally. This partially addresses #1968.\n", "comments": ["Can one of the admins verify this patch?\n", "Jenkins, test this please.\n", "@ebrevdo Is there something I need to do here? I mean apart from the rebase.\n", "@siddharth-agrawal I took a quick look and left a few minor comments.  Let's wait for Eugene's thought on the returned dtype.\n", "@ebrevdo Could you comment on @concretevitamin's comment on dtype?\n", "Jenkins, test this please. \n", "Merged into master. Thanks.\n"]}, {"number": 2680, "title": "Loading model in Android and No OpKernel was registered to support Op error", "body": "I encountered a problem when using a self-trained face-recognition model to make inference on android platform (using c++ api, just like the android demo). The error says something like this:\n\n```\n06-05 16:25:11.322 28605-28605/jp.narr.tensorflowmnist I/native: tensorflow_jni.cc:196 End computing.\n06-05 16:25:11.322 28605-28605/jp.narr.tensorflowmnist E/native: tensorflow_jni.cc:199 Error during inference: Invalid argument: No OpKernel was registered to support Op 'Inv' with these attrs\n                                                                      [[Node: incept5b/in4_conv1x1_55/batch_norm/moments/moments_1/divisor = Inv[T=DT_FLOAT](incept5b/in4_conv1x1_55/batch_norm/moments/moments/Const)]]\n06-05 16:25:11.322 28605-28605/jp.narr.tensorflowmnist A/libc: Fatal signal 11 (SIGSEGV), code 1, fault addr 0x10 in tid 28605 (tensorflowmnist)\n06-05 16:25:11.423 186-186/? I/DEBUG: *** *** *** *** *** *** *** *** *** *** *** *** \n```\n\nIt is similar to the issue #1269 \n\nI don't understand why it causes an error? \nAll the other layers ( from incept3a  to incept5a) have almost the same structures, but there's no error....\n\nCould anyone give me some advice?\nThanks a lot!\n\nThe structure of the model I use is like this:\n\n```\n\ndef inference_nn4_max_pool_96(images, pool_type, use_lrn, keep_probability, phase_train=True):\n  conv1 = _conv(images, 3, 64, 7, 7, 2, 2, 'SAME', 'conv1_7x7', phase_train=phase_train, use_batch_norm=True)\n  pool1 = _mpool(conv1,  3, 3, 2, 2, 'SAME')\n  if use_lrn:\n    lrn1 = tf.nn.local_response_normalization(pool1, depth_radius=5, bias=1.0, alpha=1e-4, beta=0.75)\n  else:\n    lrn1 = pool1\n  conv2 = _conv(lrn1,  64, 64, 1, 1, 1, 1, 'SAME', 'conv2_1x1', phase_train=phase_train, use_batch_norm=True)\n  conv3 = _conv(conv2,  64, 192, 3, 3, 1, 1, 'SAME', 'conv3_3x3', phase_train=phase_train, use_batch_norm=True)\n  if use_lrn:\n    lrn2 = tf.nn.local_response_normalization(conv3, depth_radius=5, bias=1.0, alpha=1e-4, beta=0.75)\n  else:\n    lrn2 = conv3\n  pool3 = _mpool(lrn2,  3, 3, 2, 2, 'SAME')\n\n  incept3a = _inception(pool3,    192, 1, 64, 96, 128, 16, 32, 3, 32, 1, 'MAX', 'incept3a', phase_train=phase_train, use_batch_norm=True)\n  incept3b = _inception(incept3a, 256, 1, 64, 96, 128, 32, 64, 3, 64, 1, pool_type, 'incept3b', phase_train=phase_train, use_batch_norm=True)\n  incept3c = _inception(incept3b, 320, 2, 0, 128, 256, 32, 64, 3, 0, 2, 'MAX', 'incept3c', phase_train=phase_train, use_batch_norm=True)\n\n  incept4a = _inception(incept3c, 640, 1, 256, 96, 192, 32, 64, 3, 128, 1, pool_type, 'incept4a', phase_train=phase_train, use_batch_norm=True)\n  incept4b = _inception(incept4a, 640, 1, 224, 112, 224, 32, 64, 3, 128, 1, pool_type, 'incept4b', phase_train=phase_train, use_batch_norm=True)\n  incept4c = _inception(incept4b, 640, 1, 192, 128, 256, 32, 64, 3, 128, 1, pool_type, 'incept4c', phase_train=phase_train, use_batch_norm=True)\n  incept4d = _inception(incept4c, 640, 1, 160, 144, 288, 32, 64, 3, 128, 1, pool_type, 'incept4d', phase_train=phase_train, use_batch_norm=True)\n  incept4e = _inception(incept4d, 640, 2, 0, 160, 256, 64, 128, 3, 0, 2, 'MAX', 'incept4e', phase_train=phase_train, use_batch_norm=True)\n\n  incept5a = _inception(incept4e,    1024, 1, 384, 192, 384, 0, 0, 3, 128, 1, pool_type, 'incept5a', phase_train=phase_train, use_batch_norm=True)\n  incept5b = _inception(incept5a, 896, 1, 384, 192, 384, 0, 0, 3, 128, 1, 'MAX', 'incept5b', phase_train=phase_train, use_batch_norm=True)\n  pool6 = _apool(incept5b,  3, 3, 1, 1, 'VALID')\n\n  resh1 = tf.reshape(pool6, [-1, 896])\n  affn1 = _affine(resh1, 896, 128)\n  if keep_probability<1.0:\n    affn1 = control_flow_ops.cond(phase_train,\n                                  lambda: tf.nn.dropout(affn1, keep_probability), lambda: affn1)\n  norm = tf.nn.l2_normalize(affn1, 1, 1e-10, name='embeddings')\n\n  return norm\n```\n", "comments": ["Hi, do you still experience this error after syncing past https://github.com/tensorflow/tensorflow/commit/7ee839a3ecb68ea0eedb1193638c05c53f06e56d? It adds the \"Inv\" operation that was previously not in the Android kernel filegroups.\n", "@andrewharp , thanks a lot for your help!\nI use the new version(actually, I add the inverse to Android kernel filegroups ), and this error disappears.\n\nHowever, I meet some other errors:\n\n```\n06-06 15:26:10.871 16634-16634/jp.narr.tensorflowmnist E/native: tensorflow_jni.cc:262 Error during inference: Invalid argument: No OpKernel was registered to support Op 'Switch' with these attrs\n                                                                      [[Node: incept5b/in4_conv1x1_55/batch_norm/cond/Switch = Switch[T=DT_BOOL](phase_train, phase_train)]]\n06-06 15:26:10.871 16634-16634/jp.narr.tensorflowmnist A/libc: Fatal signal 11 (SIGSEGV), code 1, fault addr 0x10 in tid 16634 (tensorflowmnist)\n```\n\nIt needs a op called Switch\", do you know what that is?\nThanks.\n", "There is a \"Switch\" op in control_flow_ops.cc which is also included by android_extended_ops_group1. Can you confirm that this file/filegroup are being used by your build?\n", "Thanks, @andrewharp .\nYes, I found the \"control_flow_ops.cc\" in my BUILD file. I think the file I use includse this op.\nIs it possible that the error is cause by a wrong tensor definition? \n\nI create the tensor using c++,\n\n```\nstatic bool tensor_phase_value =  false;\n\n    tensorflow::Tensor tensor_phase(\n        tensorflow::DT_BOOL,\n        tensorflow::TensorShape({ 1}));\n    auto tensor_phase_mapped = tensor_phase.tensor<bool, 1>();\n    tensor_phase_mapped(0) = tensor_phase_value;\n```\n\nIt should be a bool tensor, in python model , it looks like this:\n`phase_train_placeholder = tf.placeholder(tf.bool, name='phase_train')`\n\nIs there anything improper here?\n\nThanks\n", "I think your problem node results from the following python:\n\n```\n    affn1 = control_flow_ops.cond(phase_train,\n                                  lambda: tf.nn.dropout(affn1, keep_probability), lambda: affn1)\n```\n\nThe node summary from the error: \n`Switch[T=DT_BOOL](phase_train, phase_train)]`\nimplies it's looking to instantiate a SwitchOp node taking phase_train as both inputs 1 and 2.\n\nHowever looking at the actual SwitchOp definition, it seems the second input must be a scalar, not a tensor as phase_train is defined to be.\n\nI may be misinterpreting something here, but does anything stand out given this?\n", "Thanks, @andrewharp but I'm a little confused here...:\n\n1, In python code, there are 2 input(I think both of them are tensors):\n\n```\n        images_placeholder = tf.placeholder(tf.float32, shape=(FLAGS.batch_size, FLAGS.image_size, FLAGS.image_size, 3), name='input')     \n        phase_train_placeholder = tf.placeholder(tf.bool, name='phase_train')\n```\n\nand they are feed together to the session:\n\n```\n                feed_dict = { images_placeholder: images, phase_train_placeholder: False }\n                sess.run([embeddings], feed_dict=feed_dict)\n```\n\nwhat I 'm doing in C++ api is the same:\n\n```\n   tensorflow::Tensor input_tensor(\n        tensorflow::DT_FLOAT,\n        tensorflow::TensorShape({\n              1, IMAGE_SIZE, IMAGE_SIZE, 3}));\n    auto input_tensor_mapped = input_tensor.tensor<float, 4>();\n\n\n    tensorflow::Tensor tensor_phase(\n        tensorflow::DT_BOOL,\n        tensorflow::TensorShape());\n    tensor_phase.scalar<bool>()() = 0;\n\n// input tensor definition\n    std::vector<std::pair<std::string, tensorflow::Tensor> > input_tensors(\n        {{\"input\", input_tensor}, {\"phase_train\", tensor_phase}});\n\n    std::vector<Tensor> output_tensors;\n    std::vector<std::string> output_names({\"embeddings\"});\n\n    Status run_status = session->Run( input_tensors, output_names, {}, &output_tensors );\n```\n\nI kind of don't understand why it works in python, but not in c++? \n\n2, I looked at the c++ api again, it seems that the input of \" tensorflow::Session::Run()\"  has to be pair< string, Tensor > format. So I don't really know how to feed a scalar to it....\n", "@petewarden Do you know how the cc code here could be formulated to satisfy the Switch op? Alternatively, is this a situation in which [strip_unused.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/strip_unused.py) could be used to simply remove it?\n", "The first thing I would double-check is that the Switch kernel is actually being registered. I normally do this by adding a `LOG(INFO) << op_name;` call to the KernelDefBuilder constructor:\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/framework/kernel_def_builder.cc#L22\n\nOnce we know for sure the kernel is being linked in, then we can look at exactly what permutations are listed in the registry.\n", "@petewarden \nCould you please advise me how to get the \"op_name\" more specifically? \nThanks!\n", "Try editing the constructor Pete linked to in kernel_def_builder.cc to this:\n\n```\n#include \"tensorflow/core/platform/logging.h\"\n...\nKernelDefBuilder::KernelDefBuilder(const char* op_name) {\n  kernel_def_ = new KernelDef;\n  kernel_def_->set_op(op_name);\n  LOG(INFO) << op_name;\n}\n\n```\n", "@andrewharp  Thanks!\nI edit the kernel_def_builder.cc and rebuild the program again, it still shows same error. (I didn't see the log for op_name output...) Is it necessary to call some other function?\n\nBeside, I build this android program using \"libandroid_tensorflow_kernels.lo\" (which is built in \"bazel-out\" when using bazel to build the android demo). Does this influence the use of  Switch kernel ?\n", "Thanks for trying that. Do you see any op names listed in the output?\n", "@petewarden No....the output are the same...\nIs it possible that I didn't called the right function? Is KernelDefBuilder constructor called automotively during the inference process?\n\n```\n06-07 09:16:27.724 11127-11127/jp.narr.tensorflowmnist I/native: tensorflow_jni.cc:66 Loading Tensorflow.\n06-07 09:16:27.724 11127-11127/jp.narr.tensorflowmnist I/native: tensorflow_jni.cc:67 Making new SessionOptions.\n06-07 09:16:27.724 11127-11127/jp.narr.tensorflowmnist I/native: tensorflow_jni.cc:71 Got config, 0 devices\n06-07 09:16:27.725 11127-11127/jp.narr.tensorflowmnist I/native: tensorflow_jni.cc:73 Session created.\n06-07 09:16:27.725 11127-11127/jp.narr.tensorflowmnist I/native: tensorflow_jni.cc:77 Graph created.\n06-07 09:16:27.726 11127-11127/jp.narr.tensorflowmnist I/native: tensorflow_jni.cc:82 Acquired AssetManager.\n06-07 09:16:27.726 11127-11127/jp.narr.tensorflowmnist I/native: tensorflow_jni.cc:84 Reading file to proto: file:///android_asset/newgraph.pb\n06-07 09:16:27.726 11127-11127/jp.narr.tensorflowmnist I/native: jni_utils.cc:130 Opening asset newgraph.pb from disk with copy.\n06-07 09:16:28.334 11127-11127/jp.narr.tensorflowmnist I/native: tensorflow_jni.cc:88 Creating session.\n06-07 09:16:28.538 11127-11127/jp.narr.tensorflowmnist I/native: tensorflow_jni.cc:106 6678 nodes in graph\n06-07 09:16:28.627 11127-11127/jp.narr.tensorflowmnist I/native: tensorflow_jni.cc:113 6235:tf_weights\n06-07 09:16:28.628 11127-11127/jp.narr.tensorflowmnist I/native: tensorflow_jni.cc:113 6237:tf_weights_1\n06-07 09:16:28.628 11127-11127/jp.narr.tensorflowmnist I/native: tensorflow_jni.cc:113 6239:tf_weights_2\n06-07 09:16:28.628 11127-11127/jp.narr.tensorflowmnist I/native: tensorflow_jni.cc:113 6241:tf_weights_3\n....\n06-07 09:16:28.692 11127-11127/jp.narr.tensorflowmnist I/native: tensorflow_jni.cc:113 6677:tf_weights_221\n06-07 09:16:29.431 11127-11127/jp.narr.tensorflowmnist I/native: tensorflow_jni.cc:131 Tensorflow graph loaded from: file:///android_asset/newgraph.pb\n06-07 09:16:29.588 11127-11270/jp.narr.tensorflowmnist D/OpenGLRenderer: Use EGL_SWAP_BEHAVIOR_PRESERVED: true\n06-07 09:16:29.595 11127-11127/jp.narr.tensorflowmnist D/Atlas: Validating map...\n06-07 09:16:29.635 11127-11270/jp.narr.tensorflowmnist I/Adreno-EGL: <qeglDrvAPI_eglInitialize:379>: QUALCOMM Build: 01/14/15, ab0075f, Id3510ff6dc\n06-07 09:16:29.636 11127-11270/jp.narr.tensorflowmnist I/OpenGLRenderer: Initialized EGL, version 1.4\n06-07 09:16:29.654 11127-11270/jp.narr.tensorflowmnist D/OpenGLRenderer: Enabling debug mode 0\n06-07 09:16:35.076 11127-11127/jp.narr.tensorflowmnist I/native: tensorflow_jni.cc:141 Tensorflow: Making inference on Graph.\n06-07 09:16:35.076 11127-11127/jp.narr.tensorflowmnist I/native: tensorflow_jni.cc:185 Tensorflow: input_tensor:image.\n06-07 09:16:35.076 11127-11127/jp.narr.tensorflowmnist I/native: tensorflow_jni.cc:194 Tensorflow: Copying Data.\n06-07 09:16:35.077 11127-11127/jp.narr.tensorflowmnist I/native: tensorflow_jni.cc:214 Tensorflow: tensor_phase.\n06-07 09:16:35.077 11127-11127/jp.narr.tensorflowmnist I/native: tensorflow_jni.cc:237 Start computing.\n06-07 09:16:35.471 11127-11127/jp.narr.tensorflowmnist I/native: tensorflow_jni.cc:257 End computing.\n06-07 09:16:35.471 11127-11127/jp.narr.tensorflowmnist E/native: tensorflow_jni.cc:260 Error during inference: Invalid argument: No OpKernel was registered to support Op 'Switch' with these attrs\n                                                                     [[Node: incept5b/in4_conv1x1_55/batch_norm/cond/Switch = Switch[T=DT_BOOL](phase_train, phase_train)]]\n06-07 09:16:35.471 11127-11127/jp.narr.tensorflowmnist A/libc: Fatal signal 11 (SIGSEGV), code 1, fault addr 0x10 in tid 11127 (tensorflowmnist)\n```\n", "@TianweiXing The op name output should be the first native log output from the app. It should be above even \"Loading Tensorflow\" (since it happens as the library is loaded, not when the session is initialized).\n\nIf you're not seeing anything there at all, it's possible you're not linking in the kernel lib successfully. What is the command you're using to build?\n", "Closing; please reopen if you're still experiencing the issue.\n", "hi, @andrewharp .\n\nI am encountering the issue. Welcome any advice.\n\nThe results after adding  LOG(INFO) << op_name; in KernelDefBuilder::KernelDefBuilder(const char\\* op_name) are as follows:\n07-30 16:44:09.091 3412-3412/? I/native: kernel_def_builder.cc:24 Switch\n07-30 16:44:09.092 3412-3412/? I/native: kernel_def_builder.cc:24 Switch\n07-30 16:44:09.094 3412-3412/? I/native: kernel_def_builder.cc:24 RefSwitch\n07-30 16:44:09.094 3412-3412/? I/native: kernel_def_builder.cc:24 RefSwitch\n07-30 16:44:09.095 3412-3412/? I/native: kernel_def_builder.cc:24 Switch\n07-30 16:44:09.095 3412-3412/? I/native: kernel_def_builder.cc:24 RefSwitch\n07-30 16:44:09.096 3412-3412/? I/native: kernel_def_builder.cc:24 Switch\n07-30 16:44:09.096 3412-3412/? I/native: kernel_def_builder.cc:24 RefSwitch\n07-30 16:44:09.097 3412-3412/? I/native: kernel_def_builder.cc:24 Switch\n07-30 16:44:09.097 3412-3412/? I/native: kernel_def_builder.cc:24 RefSwitch\n07-30 16:44:09.098 3412-3412/? I/native: kernel_def_builder.cc:24 Switch\n07-30 16:44:09.099 3412-3412/? I/native: kernel_def_builder.cc:24 RefSwitch\n07-30 16:44:09.100 3412-3412/? I/native: kernel_def_builder.cc:24 RefSelect\n\nBut error occurs similar with @TianweiXing as follows:\n07-30 16:44:16.619 3412-3412/? E/native: tensorflow_jni.cc:80 Invalid argument: No OpKernel was registered to support Op 'Switch' with these attrs [[Node: evaluation/while/Switch_7 = Switch[T=DT_STRING, _class=[\"loc:@evaluation/while/Merge_7\"]](evaluation/while/Merge_7, evaluation/while/LoopCond)]]\n\nPS: the code about control_flow_ops in python is \"cf.cond(beam_gold_slot[0] >= 0, _ComputeCrossEntropy, _Pass)\"\n", "It's been fixed.\nSolutions are as follows:\ncheck the file control_flow_ops.cc where 'Switch' registered. TF_CALL_ALL_TYPES are called to register 'Switch'. Then TF_CALL_ALL_TYPES(m) calls TF_CALL_string(m), while TF_CALL_string(m) will not actually called in Mobile platforms. So modify TF_CALL_string(m) to call m(string)  for all platforms in  Register_types.h (tensorflow\\core\\framework),\n", "Can you be more specific about implementing this fix? Because it is not working for me. I've tried changing:\r\n**line 94**: `#define TF_CALL_string(m)` to `#define TF_CALL_string(m) m(string)`\r\n\r\nStill get the same \"No OpKernel was registered to support Op 'Switch'\" error.\r\n\r\nI've also tried changing:\r\n**line 98**: `#define TF_CALL_bool(m)` to `#define TF_CALL_bool(m) m(bool)`\r\nTo no avail...\r\n\r\n@leftstone2015 in your comment you said add m(string) to the TF_CALL_string(m) macro, but you did not specify which one. There is a second one on **line 121**, but when I try to add m(string) to that one my bazel build fails with:\r\n\r\n> tensorflow/core/kernels/concat_lib_cpu.cc:68:44: error: duplicate explicit instantiation of 'void tensorflow::ConcatCPU(tensorflow::DeviceBase*, const std::vector<std::unique_ptr<typename tensorflow::TTypes<T, 2>::ConstMatrix> >&, typename tensorflow::TTypes<T, 2>::Matrix*) [with T = std::basic_string<char>; typename tensorflow::TTypes<T, 2>::ConstMatrix = Eigen::TensorMap<Eigen::Tensor<const std::basic_string<char>, 2, 1, int>, 16, Eigen::MakePointer>; typename tensorflow::TTypes<T, 2>::Matrix = Eigen::TensorMap<Eigen::Tensor<std::basic_string<char>, 2, 1, int>, 16, Eigen::MakePointer>]' [-fpermissive]\r\n>        typename TTypes<T, 2>::Matrix* output);\r\n>                                             ^\r\n> tensorflow/core/kernels/concat_lib_cpu.cc:79:1: note: in expansion of macro 'REGISTER'\r\n>  REGISTER(string);\r\n\r\nI have been struggling with this bug for a while now, and from what I've read in similar posts, the only solution is to freeze your model without is_training. Unfortunately this is not an option for me as I do not have any way of modifying my graph.pb file. So any help would be appreciated! ", "Hi, @Mr-Grieves . I fix the same problem by change all occurrences(2) of the following in tensorflow/core/framework/register_types.h\r\n`#define TF_CALL_bool(m)`\r\nto\r\n`#define TF_CALL_bool(m) m(bool)`.\r\nIt work for me, hope it will help you.", "Hi,\r\n\r\n @Mr-Grieves I am getting the same error. Did that fix work for you? It's not working for me. \r\n\r\n> tensorflow/core/kernels/concat_lib_cpu.cc:68:44: error: duplicate explicit instantiation of 'void tensorflow::ConcatCPU(tensorflow::DeviceBase*, const std::vector<std::unique_ptr<typename tensorflow::TTypes<T, 2>::ConstMatrix> >&, typename tensorflow::TTypes<T, 2>::Matrix*) [with T = std::basic_string<char>; typename tensorflow::TTypes<T, 2>::ConstMatrix = Eigen::TensorMap<Eigen::Tensor<const std::basic_string<char>, 2, 1, int>, 16, Eigen::MakePointer>; typename tensorflow::TTypes<T, 2>::Matrix = Eigen::TensorMap<Eigen::Tensor<std::basic_string<char>, 2, 1, int>, 16, Eigen::MakePointer>]' [-fpermissive]\r\n>        typename TTypes<T, 2>::Matrix* output);\r\n>                                             ^\r\n> tensorflow/core/kernels/concat_lib_cpu.cc:79:1: note: in expansion of macro 'REGISTER'\r\n>  REGISTER(string);\r\n>  ^\r\n\r\n\r\n@nesadiankemo I tried changing all the occurences(2) of the following in tensorflow/core/framework/register_types.h\r\n`#define TF_CALL_string(m)`\r\nto\r\n`#define TF_CALL_string(m) m(string)`\r\nAND\r\n`#define TF_CALL_bool(m)`\r\nto\r\n`#define TF_CALL_bool(m) m(bool)`\r\nStill the error persists. Any help would be appreciated. Thanks !", "Hey, @Mr-Grieves @nesadiankemo @leftstone2015 @andrewharp \r\nThat error is gone . I did change only the TF_CALL_bool macros at lines L#98 and L#125 only and not at any other places. Also i didn't change the TF_CALL_string macro. So it worked for me but now I'm getting error at the later stage when i am running the benchmark for \"frozen_inference_graph.pb\" as provided for object detection model. \r\n\r\n>  adb shell /data/local/tmp/benchmark_model --graph=/data/local/tmp/frozen_inference_graph.pb --input_layer=image_tensor:0 --input_layer_shape=\"1,224,224,3\" --input_layer_type=\"float\" --output_layer=\"detection_scores/detection_scores:0\"\r\n> native : benchmark_model.cc:404 Graph: [/data/local/tmp/frozen_inference_graph.pb]\r\n> native : benchmark_model.cc:405 Input layers: [image_tensor:0]\r\n> native : benchmark_model.cc:406 Input shapes: [1,224,224,3]\r\n> native : benchmark_model.cc:407 Input types: [float]\r\n> native : benchmark_model.cc:408 Output layers: [detection_scores/detection_scores:0]\r\n> native : benchmark_model.cc:409 Num runs: [50]\r\n> native : benchmark_model.cc:410 Inter-run delay (seconds): [-1.0]\r\n> native : benchmark_model.cc:411 Num threads: [-1]\r\n> native : benchmark_model.cc:412 Benchmark name: []\r\n> native : benchmark_model.cc:413 Output prefix: []\r\n> native : benchmark_model.cc:414 Show sizes: [0]\r\n> native : benchmark_model.cc:415 Warmup runs: [2]\r\n> native : benchmark_model.cc:54 Loading TensorFlow.\r\n> native : benchmark_model.cc:61 Got config, 0 devices\r\n> can't determine number of CPU cores: assuming 4\r\n> can't determine number of CPU cores: assuming 4\r\n> native : benchmark_model.cc:74 Could not create TensorFlow Session: Invalid argument: No OpKernel was registered to support Op 'Switch' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n>   device='GPU'; T in [DT_STRING]\r\n>   device='GPU'; T in [DT_BOOL]\r\n>   device='GPU'; T in [DT_INT32]\r\n>   device='GPU'; T in [DT_FLOAT]\r\n>   device='CPU'; T in [DT_FLOAT]\r\n>   device='CPU'; T in [DT_INT32]\r\n> \r\n> \t [[Node: Postprocessor/BatchMultiClassNonMaxSuppression/PadOrClipBoxList/cond_2/Switch = Switch[T=DT_BOOL](Postprocessor/BatchMultiClassNonMaxSuppression/PadOrClipBoxList/Greater_2, Postprocessor/BatchMultiClassNonMaxSuppression/PadOrClipBoxList/Greater_2)]]\r\n\r\nOne workout mentioned here #8404 is that \" to freeze the graph without phase_train\"\r\nIs there any other fix without re-freezing the graph? \r\n*Note: And also my error mentioned above (after [[Node: ...........]]) is bit different from the one mentioned at #8404 ", "@Lucky94: I could not get it working with the suggested edits to register_types.h\r\nEventually I was able to get my hands on a .pb file with the problematic nodes removed, but I realize that doesn't help you much.\r\n\r\nHopefully somebody will be able to provide an alternative solution soon.\r\nSorry! ", "Hi, @Lucky94 . Since I change the TF_CALL_bool macros and build a .so file to use in Android. \r\nError likes \"Could not create TensorFlow Session: Invalid argument: No OpKernel was registered to support Op 'Switch' with these attrs. \" were never occured again. The model I use also have to feed phase_train as an input, it work.\r\nSo, maybe you can check if you does replace the newer .so file in you Android Application.", "@Lucky94 , same to u . i solved this issue on android by : \r\nchange only the TF_CALL_bool macros at lines L#98 and L#125 only and not at any other places.\r\n\r\nyour name made me lucky ,  love u guys~!\r\n", "Hi @Mr-Grieves @nesadiankemo . Forgot to update. I got that runtime error solved after re-building it for r1.3 . The  reason I think might be this: \"A more efficient implementation of non-max suppression.\" as it is mentioned in the bug fixes under 1.3 release.\r\nThanks !\r\n\r\nps: @jakiechris Glad to know it helped :)", "We had a similar issue today trying to run the Android example project. The app worked when we built it early last week but started failing today. Here is the stacktrace that it dumps:\r\n```\r\n10-11 11:46:48.856 6064-6064/org.tensorflow.demo V/InputMethodManager: Starting input: tba=android.view.inputmethod.EditorInfo@27b5b67 nm : org.tensorflow.demo ic=null\r\n10-11 11:46:49.176 6064-6105/org.tensorflow.demo D/gralloc: gralloc_lock_ycbcr success. format : 11, usage: 3, ycbcr.y: 0x6fa1c06000, .cb: 0x6fa1c51001, .cr: 0x6fa1c51000, .ystride: 640 , .cstride: 640, .chroma_step: 2\r\n10-11 11:46:49.177 6064-6105/org.tensorflow.demo D/tensorflow: CameraActivity: Initializing buffer 0 at size 307200\r\n10-11 11:46:49.178 6064-6105/org.tensorflow.demo D/tensorflow: CameraActivity: Initializing buffer 1 at size 153599\r\n10-11 11:46:49.179 6064-6105/org.tensorflow.demo D/tensorflow: CameraActivity: Initializing buffer 2 at size 153599\r\n10-11 11:46:49.192 6064-6105/org.tensorflow.demo E/tensorflow: ObjectTracker: libtensorflow_demo.so not found, tracking unavailable\r\n10-11 11:46:49.192 6064-6105/org.tensorflow.demo I/tensorflow: MultiBoxTracker: Initializing ObjectTracker: 640x480\r\n10-11 11:46:49.193 6064-6105/org.tensorflow.demo E/tensorflow: ObjectTracker: Native object tracking support not found. See tensorflow/examples/android/README.md for details.\r\n10-11 11:46:49.193 6064-6105/org.tensorflow.demo I/tensorflow: DetectorActivity: Preparing image 1 for detection in bg thread.\r\n10-11 11:46:49.195 6064-6105/org.tensorflow.demo E/art: No implementation found for void org.tensorflow.demo.env.ImageUtils.convertYUV420ToARGB8888(byte[], byte[], byte[], int[], int, int, int, int, int, boolean) (tried Java_org_tensorflow_demo_env_ImageUtils_convertYUV420ToARGB8888 and Java_org_tensorflow_demo_env_ImageUtils_convertYUV420ToARGB8888___3B_3B_3B_3IIIIIIZ)\r\n10-11 11:46:49.195 6064-6105/org.tensorflow.demo W/tensorflow: ImageUtils: Native YUV420 -> RGB implementation not found, falling back to Java implementation\r\n10-11 11:46:49.268 6064-6104/org.tensorflow.demo I/tensorflow: DetectorActivity: Running detection on image 1\r\n10-11 11:46:49.268 6064-6105/org.tensorflow.demo D/gralloc: gralloc_lock_ycbcr success. format : 11, usage: 3, ycbcr.y: 0x6f8e543000, .cb: 0x6f8e58e001, .cr: 0x6f8e58e000, .ystride: 640 , .cstride: 640, .chroma_step: 2\r\n10-11 11:46:49.299 6064-6105/org.tensorflow.demo D/gralloc: gralloc_lock_ycbcr success. format : 11, usage: 3, ycbcr.y: 0x6f8e460000, .cb: 0x6f8e4ab001, .cr: 0x6f8e4ab000, .ystride: 640 , .cstride: 640, .chroma_step: 2\r\n10-11 11:46:49.335 6064-6105/org.tensorflow.demo D/gralloc: gralloc_lock_ycbcr success. format : 11, usage: 3, ycbcr.y: 0x6f8e37d000, .cb: 0x6f8e3c8001, .cr: 0x6f8e3c8000, .ystride: 640 , .cstride: 640, .chroma_step: 2\r\n10-11 11:46:49.367 6064-6105/org.tensorflow.demo D/gralloc: gralloc_lock_ycbcr success. format : 11, usage: 3, ycbcr.y: 0x6f8e29a000, .cb: 0x6f8e2e5001, .cr: 0x6f8e2e5000, .ystride: 640 , .cstride: 640, .chroma_step: 2\r\n10-11 11:46:49.404 6064-6104/org.tensorflow.demo E/TensorFlowInferenceInterface: Failed to run TensorFlow inference with inputs:[image_tensor], outputs:[detection_boxes, detection_scores, detection_classes, num_detections]\r\n10-11 11:46:49.404 6064-6104/org.tensorflow.demo E/AndroidRuntime: FATAL EXCEPTION: inference\r\n                                                                   Process: org.tensorflow.demo, PID: 6064\r\n                                                                   java.lang.IllegalArgumentException: No OpKernel was registered to support Op 'Switch' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n                                                                     device='CPU'; T in [DT_FLOAT]\r\n                                                                     device='CPU'; T in [DT_INT32]\r\n                                                                     device='GPU'; T in [DT_STRING]\r\n                                                                     device='GPU'; T in [DT_BOOL]\r\n                                                                     device='GPU'; T in [DT_INT32]\r\n                                                                     device='GPU'; T in [DT_FLOAT]\r\n                                                                   \r\n                                                                   \t [[Node: Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/cond/Switch = Switch[T=DT_BOOL](Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater, Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater)]]\r\n                                                                       at org.tensorflow.Session.run(Native Method)\r\n                                                                       at org.tensorflow.Session.access$100(Session.java:48)\r\n                                                                       at org.tensorflow.Session$Runner.runHelper(Session.java:295)\r\n                                                                       at org.tensorflow.Session$Runner.run(Session.java:245)\r\n                                                                       at org.tensorflow.contrib.android.TensorFlowInferenceInterface.run(TensorFlowInferenceInterface.java:143)\r\n                                                                       at org.tensorflow.demo.TensorFlowObjectDetectionAPIModel.recognizeImage(TensorFlowObjectDetectionAPIModel.java:158)\r\n                                                                       at org.tensorflow.demo.DetectorActivity$3.run(DetectorActivity.java:294)\r\n                                                                       at android.os.Handler.handleCallback(Handler.java:751)\r\n                                                                       at android.os.Handler.dispatchMessage(Handler.java:95)\r\n                                                                       at android.os.Looper.loop(Looper.java:154)\r\n                                                                       at android.os.HandlerThread.run(HandlerThread.java:61)\r\n10-11 11:46:49.406 6064-6105/org.tensorflow.demo D/gralloc: gralloc_lock_ycbcr success. format : 11, usage: 3, ycbcr.y: 0x6f8e1b7000, .cb: 0x6f8e202001, .cr: 0x6f8e202000, .ystride: 640 , .cstride: 640, .chroma_step: 2\r\n10-11 11:46:49.430 6064-6064/org.tensorflow.demo D/ViewRootImpl@cea784e[DetectorActivity]: MSG_WINDOW_FOCUS_CHANGED 0\r\n10-11 11:46:49.451 6064-6105/org.tensorflow.demo D/gralloc: gralloc_lock_ycbcr success. format : 11, usage: 3, ycbcr.y: 0x6f8df65000, .cb: 0x6f8dfb0001, .cr: 0x6f8dfb0000, .ystride: 640 , .cstride: 640, .chroma_step: 2\r\n10-11 11:46:49.486 6064-6105/org.tensorflow.demo D/gralloc: gralloc_lock_ycbcr success. format : 11, usage: 3, ycbcr.y: 0x6f8de22000, .cb: 0x6f8de6d001, .cr: 0x6f8de6d000, .ystride: 640 , .cstride: 640, .chroma_step: 2\r\n10-11 11:46:49.528 6064-6105/org.tensorflow.demo D/gralloc: gralloc_lock_ycbcr success. format : 11, usage: 3, ycbcr.y: 0x6f8dd3f000, .cb: 0x6f8dd8a001, .cr: 0x6f8dd8a000, .ystride: 640 , .cstride: 640, .chroma_step: 2\r\n10-11 11:46:49.566 6064-6105/org.tensorflow.demo D/gralloc: gralloc_lock_ycbcr success. format : 11, usage: 3, ycbcr.y: 0x6fa1c06000, .cb: 0x6fa1c51001, .cr: 0x6fa1c51000, .ystride: 640 , .cstride: 640, .chroma_step: 2\r\n10-11 11:46:49.605 6064-6105/org.tensorflow.demo D/gralloc: gralloc_lock_ycbcr success. format : 11, usage: 3, ycbcr.y: 0x6f9871c000, .cb: 0x6f98767001, .cr: 0x6f98767000, .ystride: 640 , .cstride: 640, .chroma_step: 2\r\n10-11 11:46:49.665 6064-6105/org.tensorflow.demo D/gralloc: gralloc_lock_ycbcr success. format : 11, usage: 3, ycbcr.y: 0x6f98639000, .cb: 0x6f98684001, .cr: 0x6f98684000, .ystride: 640 , .cstride: 640, .chroma_step: 2\r\n10-11 11:46:49.724 6064-6105/org.tensorflow.demo D/gralloc: gralloc_lock_ycbcr success. format : 11, usage: 3, ycbcr.y: 0x6f8e543000, .cb: 0x6f8e58e001, .cr: 0x6f8e58e000, .ystride: 640 , .cstride: 640, .chroma_step: 2\r\n10-11 11:46:50.398 6064-6064/org.tensorflow.demo D/tensorflow: CameraActivity: onPause org.tensorflow.demo.DetectorActivity@e59c695\r\n```", "Does not work for me either, here is dump:\r\n\r\n10-13 10:19:44.727 20504-20504/? I/zygote: Late-enabling -Xcheck:jni\r\n10-13 10:19:44.888 20504-20504/org.tensorflow.demo I/InstantRun: starting instant run server: is main process\r\n10-13 10:19:44.929 20504-20504/org.tensorflow.demo D/tensorflow: CameraActivity: onCreate org.tensorflow.demo.DetectorActivity@d97a4c5\r\n10-13 10:19:44.949 20504-20504/org.tensorflow.demo I/CameraManagerGlobal: Connecting to camera service\r\n10-13 10:19:44.977 20504-20504/org.tensorflow.demo I/tensorflow: CameraActivity: Camera API lv2?: true\r\n10-13 10:19:45.012 20504-20504/org.tensorflow.demo D/tensorflow: CameraActivity: onStart org.tensorflow.demo.DetectorActivity@d97a4c5\r\n10-13 10:19:45.014 20504-20504/org.tensorflow.demo D/tensorflow: CameraActivity: onResume org.tensorflow.demo.DetectorActivity@d97a4c5\r\n10-13 10:19:45.025 20504-20539/org.tensorflow.demo D/OpenGLRenderer: HWUI GL Pipeline\r\n10-13 10:19:45.053 20504-20539/org.tensorflow.demo I/Adreno: QUALCOMM build                   : 7142022, Ib5823dd10c\r\n                                                             Build Date                       : 06/23/17\r\n                                                             OpenGL ES Shader Compiler Version: EV031.18.00.00\r\n                                                             Local Branch                     : O11A\r\n                                                             Remote Branch                    : \r\n                                                             Remote Branch                    : \r\n                                                             Reconstruct Branch               : \r\n10-13 10:19:45.059 20504-20539/org.tensorflow.demo I/Adreno: PFP: 0x005ff087, ME: 0x005ff063\r\n10-13 10:19:45.061 20504-20539/org.tensorflow.demo I/OpenGLRenderer: Initialized EGL, version 1.4\r\n10-13 10:19:45.061 20504-20539/org.tensorflow.demo D/OpenGLRenderer: Swap behavior 2\r\n10-13 10:19:45.084 20504-20504/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Desired size: 640x480, min size: 480x480\r\n10-13 10:19:45.085 20504-20504/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Valid preview sizes: [4048x3036, 4000x3000, 3840x2160, 3264x2448, 3200x2400, 2976x2976, 2592x1944, 2688x1512, 2048x1536, 1920x1080, 1600x1200, 1440x1080, 1280x960, 1280x768, 1280x720, 1024x768, 800x600, 800x480, 720x480, 640x480, 480x640]\r\n10-13 10:19:45.086 20504-20504/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Rejected preview sizes: [640x360, 480x360, 480x320, 352x288, 320x240, 240x320, 176x144, 160x120, 144x176]\r\n10-13 10:19:45.086 20504-20504/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Exact size match found.\r\n10-13 10:19:45.094 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: ???\r\n10-13 10:19:45.094 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: person\r\n10-13 10:19:45.094 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: bicycle\r\n10-13 10:19:45.094 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: car\r\n10-13 10:19:45.094 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: motorcycle\r\n10-13 10:19:45.094 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: airplane\r\n10-13 10:19:45.094 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: bus\r\n10-13 10:19:45.094 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: train\r\n10-13 10:19:45.095 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: truck\r\n10-13 10:19:45.095 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: boat\r\n10-13 10:19:45.095 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: traffic light\r\n10-13 10:19:45.095 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: fire hydrant\r\n10-13 10:19:45.095 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: ???\r\n10-13 10:19:45.095 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: stop sign\r\n10-13 10:19:45.095 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: parking meter\r\n10-13 10:19:45.095 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: bench\r\n10-13 10:19:45.095 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: bird\r\n10-13 10:19:45.095 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: cat\r\n10-13 10:19:45.095 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: dog\r\n10-13 10:19:45.095 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: horse\r\n10-13 10:19:45.095 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: sheep\r\n10-13 10:19:45.095 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: cow\r\n10-13 10:19:45.096 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: elephant\r\n10-13 10:19:45.096 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: bear\r\n10-13 10:19:45.096 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: zebra\r\n10-13 10:19:45.096 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: giraffe\r\n10-13 10:19:45.096 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: ???\r\n10-13 10:19:45.096 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: backpack\r\n10-13 10:19:45.096 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: umbrella\r\n10-13 10:19:45.096 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: ???\r\n10-13 10:19:45.096 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: ???\r\n10-13 10:19:45.096 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: handbag\r\n10-13 10:19:45.096 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: tie\r\n10-13 10:19:45.096 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: suitcase\r\n10-13 10:19:45.096 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: frisbee\r\n10-13 10:19:45.096 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: skis\r\n10-13 10:19:45.097 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: snowboard\r\n10-13 10:19:45.097 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: sports ball\r\n10-13 10:19:45.097 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: kite\r\n10-13 10:19:45.097 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: baseball bat\r\n10-13 10:19:45.097 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: baseball glove\r\n10-13 10:19:45.097 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: skateboard\r\n10-13 10:19:45.097 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: surfboard\r\n10-13 10:19:45.097 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: tennis racket\r\n10-13 10:19:45.097 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: bottle\r\n10-13 10:19:45.097 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: ???\r\n10-13 10:19:45.097 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: wine glass\r\n10-13 10:19:45.097 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: cup\r\n10-13 10:19:45.097 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: fork\r\n10-13 10:19:45.097 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: knife\r\n10-13 10:19:45.097 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: spoon\r\n10-13 10:19:45.098 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: bowl\r\n10-13 10:19:45.098 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: banana\r\n10-13 10:19:45.098 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: apple\r\n10-13 10:19:45.098 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: sandwich\r\n10-13 10:19:45.098 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: orange\r\n10-13 10:19:45.098 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: broccoli\r\n10-13 10:19:45.098 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: carrot\r\n10-13 10:19:45.098 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: hot dog\r\n10-13 10:19:45.098 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: pizza\r\n10-13 10:19:45.098 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: donut\r\n10-13 10:19:45.098 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: cake\r\n10-13 10:19:45.098 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: chair\r\n10-13 10:19:45.098 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: couch\r\n10-13 10:19:45.098 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: potted plant\r\n10-13 10:19:45.098 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: bed\r\n10-13 10:19:45.099 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: ???\r\n10-13 10:19:45.099 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: dining table\r\n10-13 10:19:45.099 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: ???\r\n10-13 10:19:45.099 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: ???\r\n10-13 10:19:45.099 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: toilet\r\n10-13 10:19:45.099 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: ???\r\n10-13 10:19:45.099 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: tv\r\n10-13 10:19:45.099 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: laptop\r\n10-13 10:19:45.099 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: mouse\r\n10-13 10:19:45.099 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: remote\r\n10-13 10:19:45.099 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: keyboard\r\n10-13 10:19:45.099 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: cell phone\r\n10-13 10:19:45.099 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: microwave\r\n10-13 10:19:45.099 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: oven\r\n10-13 10:19:45.099 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: toaster\r\n10-13 10:19:45.099 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: sink\r\n10-13 10:19:45.100 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: refrigerator\r\n10-13 10:19:45.100 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: ???\r\n10-13 10:19:45.100 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: book\r\n10-13 10:19:45.100 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: clock\r\n10-13 10:19:45.100 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: vase\r\n10-13 10:19:45.100 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: scissors\r\n10-13 10:19:45.100 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: teddy bear\r\n10-13 10:19:45.100 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: hair drier\r\n10-13 10:19:45.100 20504-20504/org.tensorflow.demo W/tensorflow: TensorFlowObjectDetectionAPIModel: toothbrush\r\n10-13 10:19:45.102 20504-20504/org.tensorflow.demo I/TensorFlowInferenceInterface: Checking to see if TensorFlow native methods are already loaded\r\n10-13 10:19:45.102 20504-20504/org.tensorflow.demo E/zygote: No implementation found for long org.tensorflow.contrib.android.RunStats.allocate() (tried Java_org_tensorflow_contrib_android_RunStats_allocate and Java_org_tensorflow_contrib_android_RunStats_allocate__)\r\n10-13 10:19:45.102 20504-20504/org.tensorflow.demo I/TensorFlowInferenceInterface: TensorFlow native methods not found, attempting to load via tensorflow_inference\r\n10-13 10:19:45.133 20504-20504/org.tensorflow.demo I/TensorFlowInferenceInterface: Successfully loaded TensorFlow native methods (RunStats error may be ignored)\r\n10-13 10:19:46.277 20504-20504/org.tensorflow.demo I/TensorFlowInferenceInterface: Model load took 1118ms, TensorFlow version: 1.3.0-rc2\r\n10-13 10:19:46.279 20504-20504/org.tensorflow.demo I/TensorFlowInferenceInterface: Successfully loaded model from 'file:///android_asset/ssd_mobilenet_v1_android_export.pb'\r\n10-13 10:19:46.282 20504-20504/org.tensorflow.demo I/tensorflow: DetectorActivity: Sensor orientation: 90, Screen orientation: 0\r\n10-13 10:19:46.282 20504-20504/org.tensorflow.demo I/tensorflow: DetectorActivity: Initializing at size 640x480\r\n10-13 10:19:46.330 20504-20538/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Opening camera preview: 640x480\r\n10-13 10:19:46.349 20504-20504/org.tensorflow.demo I/Choreographer: Skipped 74 frames!  The application may be doing too much work on its main thread.\r\n10-13 10:19:46.618 20504-20538/org.tensorflow.demo D/tensorflow: CameraActivity: Initializing buffer 0 at size 307200\r\n10-13 10:19:46.619 20504-20538/org.tensorflow.demo D/tensorflow: CameraActivity: Initializing buffer 1 at size 153599\r\n10-13 10:19:46.620 20504-20538/org.tensorflow.demo D/tensorflow: CameraActivity: Initializing buffer 2 at size 153599\r\n10-13 10:19:46.624 20504-20538/org.tensorflow.demo I/tensorflow: MultiBoxTracker: Initializing ObjectTracker: 640x480\r\n10-13 10:19:46.624 20504-20538/org.tensorflow.demo I/native: Initializing object tracker. 320x240 @0xd7e3817c\r\n10-13 10:19:46.627 20504-20538/org.tensorflow.demo I/native: Initialized!\r\n10-13 10:19:46.630 20504-20538/org.tensorflow.demo I/tensorflow: DetectorActivity: Preparing image 1 for detection in bg thread.\r\n10-13 10:19:46.664 20504-20537/org.tensorflow.demo I/tensorflow: DetectorActivity: Running detection on image 1\r\n10-13 10:19:47.004 20504-20537/org.tensorflow.demo E/TensorFlowInferenceInterface: Failed to run TensorFlow inference with inputs:[image_tensor], outputs:[detection_boxes, detection_scores, detection_classes, num_detections]\r\n10-13 10:19:47.006 20504-20537/org.tensorflow.demo E/AndroidRuntime: FATAL EXCEPTION: inference\r\n                                                                     Process: org.tensorflow.demo, PID: 20504\r\n                                                                     java.lang.IllegalArgumentException: No OpKernel was registered to support Op 'Switch' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n                                                                       device='GPU'; T in [DT_STRING]\r\n                                                                       device='GPU'; T in [DT_BOOL]\r\n                                                                       device='GPU'; T in [DT_INT32]\r\n                                                                       device='GPU'; T in [DT_FLOAT]\r\n                                                                       device='CPU'; T in [DT_FLOAT]\r\n                                                                       device='CPU'; T in [DT_INT32]\r\n                                                                     \r\n                                                                     \t [[Node: Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/cond/Switch = Switch[T=DT_BOOL](Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater, Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater)]]\r\n                                                                         at org.tensorflow.Session.run(Native Method)\r\n                                                                         at org.tensorflow.Session.access$100(Session.java:48)\r\n                                                                         at org.tensorflow.Session$Runner.runHelper(Session.java:295)\r\n                                                                         at org.tensorflow.Session$Runner.run(Session.java:245)\r\n                                                                         at org.tensorflow.contrib.android.TensorFlowInferenceInterface.run(TensorFlowInferenceInterface.java:143)\r\n                                                                         at org.tensorflow.demo.TensorFlowObjectDetectionAPIModel.recognizeImage(TensorFlowObjectDetectionAPIModel.java:158)\r\n                                                                         at org.tensorflow.demo.DetectorActivity$3.run(DetectorActivity.java:292)\r\n                                                                         at android.os.Handler.handleCallback(Handler.java:789)\r\n                                                                         at android.os.Handler.dispatchMessage(Handler.java:98)\r\n                                                                         at android.os.Looper.loop(Looper.java:164)\r\n                                                                         at android.os.HandlerThread.run(HandlerThread.java:65)\r\n10-13 10:19:47.473 20504-20504/org.tensorflow.demo D/tensorflow: CameraActivity: onPause org.tensorflow.demo.DetectorActivity@d97a4c5\r\n", "Hi @pacey ,\r\n`10-11 11:46:49.192 6064-6105/org.tensorflow.demo E/tensorflow: ObjectTracker: libtensorflow_demo.so not found, tracking unavailable`\r\nThe above line contains the error from your dump. Please try looking for it from here you will get to know. It seems like library linking error, try properly linking it (it's more like path or include errors).\r\n\r\nThanks.", "> \u4e86c ++ api\uff0c\u4f3c\u4e4e\u201ctensorflow :: Session :: Run\uff08\uff09\u201d\u7684\u8f93\u5165\u5fc5\u987b\u662fpair <string\uff0cTensor>\u683c\u5f0f\u3002\u6240\u4ee5\u6211\u771f\u7684\u4e0d\u77e5\u9053\u5982\u4f55\u4e3a\u5b83\u63d0\u4f9b\u6807\u91cf....\r\n\r\nHello, how do you solve this problem?\r\n"]}, {"number": 2679, "title": "Fix broken link to Anaconda installation", "body": "", "comments": ["Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "I signed it!\n", "CLAs look good, thanks!\n\n<!-- ok -->\n"]}, {"number": 2678, "title": "Fix broken link to Anaconda installation", "body": "", "comments": ["Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n"]}, {"number": 2677, "title": "Import error", "body": "I am trying to import tensorflow (I have installed on 14.04 LTS and tensorflow 0.8) but it shows atributeError: module 'imp' has no attribute 'find_module'\n\nTraceback (most recent call last): File \"\", line 1, in File \"/home/prayalankar/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/init.py\", line 23, in from tensorflow.python import \\* File \"/home/prayalankar/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/init.py\", line 45, in from tensorflow.python import pywrap_tensorflow File \"/home/prayalankar/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 28, in _pywrap_tensorflow = swig_import_helper() File \"/home/prayalankar/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 18, in swig_import_helper fp, pathname, description = imp.find_module('_pywrap_tensorflow', [dirname(file)]) AttributeError: module 'imp' has no attribute 'find_module'\n\nHow to proceed.\n", "comments": ["I got tensorflow  working but by installing on Python 2.7 on my conda platform without any error. Above problem is still there i checked it and i think Python has changed the find_module to reload() in 3.x so it might be the problem but i do not know how to fix this .\nStill looking for solution (solid) for 3.x\n", "In your Python 3.x shell, can you please run the following:\n\n``` python\nimport imp\nprint(dir(imp))\nprint(imp.__file__)\n```\n\n...and let us know what it prints. The `find_module()` function [should be available](https://docs.python.org/3/library/imp.html#imp.find_module) in Python 3.5, which you appear to be using, so I'm not sure why this would happen. (One possibility is that there's a file called `imp.py` in your PYTHONPATH, and that's causing it to get confused.)\n", "I am getting following output. I think there is no **find_module()**\n\n> > > import imp\n> > > print(dir(imp))\n> > > ['Example', 'Flask', 'SQLAlchemy', '**builtins**', '**cached**', '**doc**', '**file**', '**loader**', '**name**', '**package**', '**spec**', 'app', 'db']\n> > > print(imp.**file**)\n> > > /home/prayalankar/imp.py\n", "The problem is that there's a file called `imp.py` in your PYTHONPATH. In particular, it looks like it's in `/home/prayalankar/imp.py`.\n\nThere are two options for fixing this:\n1. Rename `/home/prayalankar/imp.py` to something else, so that it doesn't clash with the name of a built-in Python module, or\n2. Change your PYTHONPATH so that it no longer includes `/home/prayalankar`.\n"]}, {"number": 2676, "title": "Replace assertEquals in graph_io_test; disable a session_bundle test", "body": "assertEquals is deprecated and causes Python 3.5 test failures.\n", "comments": ["LGTM\n"]}, {"number": 2675, "title": "temporarily disable contrib/session_bundle from test_installation.sh", "body": "", "comments": ["@caisq does this look right? or do wait for the builds?\n", "closing as it is also added in #2676 \n"]}, {"number": 2674, "title": "[learn] add an lstm regression example", "body": "", "comments": ["Can one of the admins verify this patch?\n", "Thanks for this! Added few comments.\n", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for the commit author(s).  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\n\n<!-- need_author_cla -->\n", "CLAs look good, thanks!\n\n<!-- ok -->\n", "@ilblackdragon looks like comments were addressed?\n", "Also can you add this example to the README.md file.\n\nOtherwise, @vrv looks good.\n", "@ilblackdragon I reviewed your comments, let me know if I misunderstood something during the reviewing. \n", "@tensorflow-jenkins Jenkins, test this please\n", "FAIL: Found 2 non-whitelited pylint errors:\ntensorflow/examples/skflow/lstm_regression.py:158: [E1123(unexpected-keyword-arg), ] Unexpected keyword argument 'batch_size' in method call\n\ntensorflow/examples/skflow/lstm_regression.py:185: [E1123(unexpected-keyword-arg), ] Unexpected keyword argument 'batch_size' in method call\n", "@vrv The 2 errors are related to this [comment](https://github.com/tensorflow/tensorflow/pull/2674#discussion_r65827134), I already mentioned that `TensorFlowEstimator`'s `fit` function is not updated yet to accept `batch_size` as an arg.\n", "@mouradmourafiq let's either use `Estimator` then or change `TensorFlowEstimator.fit` to take `batch_size` for consistency.\n", "@ilblackdragon I opened a new PR #2817  to update the `TensorFlowEstimator.fit` function.\n", "@ilblackdragon Ping. Could you review this and the other PR @mouradmourafiq created? I am not too sure what the future refactoring plan is. @mouradmourafiq Thanks for your patience. \n", "Ping. Any progress on this?\n"]}, {"number": 2673, "title": "temporarily disable contrib/session_bundle", "body": "The genrule makes problems in integration testing. We disable it for now and fix it after 0.9 release.\n", "comments": ["@nfiedel - we are disabling this for now. It have problems to build in [ci.tensorflow.org](http://ci.tensorflow.org). It is not needed for 0.9, is it?\n\nFYI @caisq @martinwicke @gunan \n", "The problem is with the shell script inside genrule in session_bundle/example. It picks wrong version of swig or python or something like that. See [log from a failed build](http://ci.tensorflow.org/view/Release/job/release-matrix-cpu/TF_BUILD_CONTAINER_TYPE=CPU,TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON3,label=cpu-slave/45/console).\n\nAlso, such a shell script in genrule may cause problems for builds on windows (no \"cp\") or when two builds would run on the same machine (hardcoded /tmp path).\n"]}, {"number": 2672, "title": "Mention fix for building on 16.04 in Troubleshooting", "body": "I ended up using @fayeshine fix from https://github.com/tensorflow/tensorflow/pull/2073 to get tensorflow building on Ubuntu 16.04, add a mention to this work-around under \"Linux Issues\"\n", "comments": ["Can one of the admins verify this patch?\n", "@yaroslavvb do you have a problem with it? I have just build on 16.04 without issues. CI build is coming.\n", "Yes, I couldn't build after upgrading my Ubuntu last week. The upgrade changed gcc to version \ngcc version 4.9.3 (Ubuntu 4.9.3-13ubuntu2) \n", "@jendap: Assigning you since you commented; feel free to change. \n", "As mentioned on the issue, we should probably recommend upgrading to cuda 8.0 instead.\n"]}, {"number": 2671, "title": "image_retraining example creates inconsistently named nodes when run multiple times", "body": "I don't know if this is a thing you want to support, but I've been running the image_retraining example from Jupyter like so:\n\nFLAGS._parse_flags()\nFLAGS.image_dir = '/data/corpus'\nFLAGS.output_graph = '/data/output_graph4.pb'\nFLAGS.output_labels = '/data/output_labels4.txt'\nFLAGS.bottleneck_dir = '/data/bottleneck/'\nFLAGS.model_dir = '/data/imagenet/'\n\nmain('')\n\nUnlike the example, I end up running the example multiple times in the same python process, and .: in the same default graph, so everything after the first run is badly named when output, i.e. instead of being named DecodeJpeg, I found DecodeJpeg_3\n\nAdding tf.reset_default_graph() to the top of main fixes this.\n", "comments": ["This is expected behavior.  TensorFlow ensures that names are unique within the same graph, so if you generate the same ops twice without changing graphs you'll get different names.\n", "Trigger update_date\n"]}, {"number": 2670, "title": "Add a method to remove entries from registry.", "body": "I'm using this to remove incompatible shape functions from the registry to make \"immediate\" tensors work as a drop-in replacement for regular TensorFlow tensors.\n\nSince \"static shape inference\" doesn't make sense for persistent tensors, I'm returning Dimension(None) for the shape for such tensors. But, there's at least one shape function which doesn't allow `Dimension(None)` -- (`_ReverseShape(op):`), so as a work-around, I'm using `unregister followed by`register(None)` \n\n@mrry \n", "comments": ["Can one of the admins verify this patch?\n", "@tensorflow-jenkins test this please\n", "@jendap: Tests look good.  Merge if you've reviewed? \n", "I don't think this is a good idea. We should just fix `_ReverseShape()` if there's a bug in it.\n", "@yaroslavvb: Are bugs in shape functions the only issues here? \n", "Yes, I think it's a bug in shape inference, filed https://github.com/tensorflow/tensorflow/issues/2690, will close this then\n", "FYI: Yes, I have read it but I was not sure why to add it ... I have triggered the build because I needed some pull request build to test jenkins ;-)\n"]}, {"number": 2669, "title": "image_retraining example is extremely slow when cropping/rotating", "body": "### Environment info\n\nOperating System: Ubuntu 14.04\n\nInstalled version of CUDA and cuDNN: CUDA 7.5, cuDNN 4\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\n\n$ ls -l /usr/local/cuda/lib64/\ntotal 987720\n-rw-r--r-- 1 root root  28585480 Aug 15  2015 libcublas_device.a\nlrwxrwxrwx 1 root root        16 Aug 15  2015 libcublas.so -> libcublas.so.7.5\nlrwxrwxrwx 1 root root        19 Aug 15  2015 libcublas.so.7.5 -> libcublas.so.7.5.18\n-rwxr-xr-x 1 root root  23938736 Aug 15  2015 libcublas.so.7.5.18\n-rw-r--r-- 1 root root  28220076 Aug 15  2015 libcublas_static.a\n-rw-r--r-- 1 root root    322936 Aug 15  2015 libcudadevrt.a\nlrwxrwxrwx 1 root root        16 Aug 15  2015 libcudart.so -> libcudart.so.7.5\nlrwxrwxrwx 1 root root        19 Aug 15  2015 libcudart.so.7.5 -> libcudart.so.7.5.18\n-rwxr-xr-x 1 root root    383336 Aug 15  2015 libcudart.so.7.5.18\n-rw-r--r-- 1 root root    720192 Aug 15  2015 libcudart_static.a\n-rwxr-xr-x 1 root root  61453024 Jun  3 17:11 libcudnn.so\n-rwxr-xr-x 1 root root  61453024 Jun  3 17:11 libcudnn.so.4\n-rwxr-xr-x 1 root root  61453024 Jun  3 17:11 libcudnn.so.4.0.7\n-rw-r--r-- 1 root root  62025862 Jun  3 17:11 libcudnn_static.a\nlrwxrwxrwx 1 root root        15 Aug 15  2015 libcufft.so -> libcufft.so.7.5\nlrwxrwxrwx 1 root root        18 Aug 15  2015 libcufft.so.7.5 -> libcufft.so.7.5.18\n-rwxr-xr-x 1 root root 111231960 Aug 15  2015 libcufft.so.7.5.18\n-rw-r--r-- 1 root root 115104400 Aug 15  2015 libcufft_static.a\nlrwxrwxrwx 1 root root        16 Aug 15  2015 libcufftw.so -> libcufftw.so.7.5\nlrwxrwxrwx 1 root root        19 Aug 15  2015 libcufftw.so.7.5 -> libcufftw.so.7.5.18\n-rwxr-xr-x 1 root root    447664 Aug 15  2015 libcufftw.so.7.5.18\n-rw-r--r-- 1 root root     42206 Aug 15  2015 libcufftw_static.a\nlrwxrwxrwx 1 root root        17 Aug 15  2015 libcuinj64.so -> libcuinj64.so.7.5\nlrwxrwxrwx 1 root root        20 Aug 15  2015 libcuinj64.so.7.5 -> libcuinj64.so.7.5.18\n-rwxr-xr-x 1 root root   5751400 Aug 15  2015 libcuinj64.so.7.5.18\n-rw-r--r-- 1 root root   1649726 Aug 15  2015 libculibos.a\nlrwxrwxrwx 1 root root        16 Aug 15  2015 libcurand.so -> libcurand.so.7.5\nlrwxrwxrwx 1 root root        19 Aug 15  2015 libcurand.so.7.5 -> libcurand.so.7.5.18\n-rwxr-xr-x 1 root root  51765952 Aug 15  2015 libcurand.so.7.5.18\n-rw-r--r-- 1 root root  51992564 Aug 15  2015 libcurand_static.a\nlrwxrwxrwx 1 root root        18 Aug 15  2015 libcusolver.so -> libcusolver.so.7.5\nlrwxrwxrwx 1 root root        21 Aug 15  2015 libcusolver.so.7.5 -> libcusolver.so.7.5.18\n-rwxr-xr-x 1 root root  37034328 Aug 15  2015 libcusolver.so.7.5.18\n-rw-r--r-- 1 root root  16613348 Aug 15  2015 libcusolver_static.a\nlrwxrwxrwx 1 root root        18 Aug 15  2015 libcusparse.so -> libcusparse.so.7.5\nlrwxrwxrwx 1 root root        21 Aug 15  2015 libcusparse.so.7.5 -> libcusparse.so.7.5.18\n-rwxr-xr-x 1 root root  36816424 Aug 15  2015 libcusparse.so.7.5.18\n-rw-r--r-- 1 root root  44445334 Aug 15  2015 libcusparse_static.a\nlrwxrwxrwx 1 root root        14 Aug 15  2015 libnppc.so -> libnppc.so.7.5\nlrwxrwxrwx 1 root root        17 Aug 15  2015 libnppc.so.7.5 -> libnppc.so.7.5.18\n-rwxr-xr-x 1 root root    427168 Aug 15  2015 libnppc.so.7.5.18\n-rw-r--r-- 1 root root     20664 Aug 15  2015 libnppc_static.a\nlrwxrwxrwx 1 root root        14 Aug 15  2015 libnppi.so -> libnppi.so.7.5\nlrwxrwxrwx 1 root root        17 Aug 15  2015 libnppi.so.7.5 -> libnppi.so.7.5.18\n-rwxr-xr-x 1 root root  63516808 Aug 15  2015 libnppi.so.7.5.18\n-rw-r--r-- 1 root root  90106200 Aug 15  2015 libnppi_static.a\nlrwxrwxrwx 1 root root        14 Aug 15  2015 libnpps.so -> libnpps.so.7.5\nlrwxrwxrwx 1 root root        17 Aug 15  2015 libnpps.so.7.5 -> libnpps.so.7.5.18\n-rwxr-xr-x 1 root root   6047400 Aug 15  2015 libnpps.so.7.5.18\n-rw-r--r-- 1 root root   8647292 Aug 15  2015 libnpps_static.a\nlrwxrwxrwx 1 root root        16 Aug 15  2015 libnvblas.so -> libnvblas.so.7.5\nlrwxrwxrwx 1 root root        19 Aug 15  2015 libnvblas.so.7.5 -> libnvblas.so.7.5.18\n-rwxr-xr-x 1 root root    456112 Aug 15  2015 libnvblas.so.7.5.18\nlrwxrwxrwx 1 root root        24 Aug 15  2015 libnvrtc-builtins.so -> libnvrtc-builtins.so.7.5\nlrwxrwxrwx 1 root root        27 Aug 15  2015 libnvrtc-builtins.so.7.5 -> libnvrtc-builtins.so.7.5.18\n-rwxr-xr-x 1 root root  22408512 Aug 15  2015 libnvrtc-builtins.so.7.5.18\nlrwxrwxrwx 1 root root        15 Aug 15  2015 libnvrtc.so -> libnvrtc.so.7.5\nlrwxrwxrwx 1 root root        18 Aug 15  2015 libnvrtc.so.7.5 -> libnvrtc.so.7.5.17\n-rwxr-xr-x 1 root root  18199288 Aug 15  2015 libnvrtc.so.7.5.17\nlrwxrwxrwx 1 root root        18 Aug 15  2015 libnvToolsExt.so -> libnvToolsExt.so.1\nlrwxrwxrwx 1 root root        22 Aug 15  2015 libnvToolsExt.so.1 -> libnvToolsExt.so.1.0.0\n-rwxr-xr-x 1 root root     37936 Aug 15  2015 libnvToolsExt.so.1.0.0\n-rw-r--r-- 1 root root     25840 Aug 15  2015 libOpenCL.so\ndrwxr-xr-x 2 root root      4096 Jun  3 13:47 stubs\n\nIf installed from binary pip package, provide:\n1. Which pip package you installed. Linux x64 w/ GPU support\n2. The output from python -c \"import tensorflow; print(tensorflow.**version**)\".\n\n0.8.0\n### Steps to reproduce\n\nI've been running the image_retrain example from Jupyter like so:\n\nFLAGS._parse_flags()\nFLAGS.image_dir = '/data/corpus'\nFLAGS.output_graph = '/data/output_graph4.pb'\nFLAGS.output_labels = '/data/output_labels4.txt'\nFLAGS.bottleneck_dir = '/data/bottleneck/'\nFLAGS.model_dir = '/data/imagenet/'\n# FLAGS.flip_left_right = True\n\nFLAGS.random_crop = 5\nFLAGS.random_scale = 5\nFLAGS.random_brightness = 5\n\nmain('')\n\nWhen I run it without any of the crop/scale options, it runs pretty quickly on my AWS instance; creating the bottlneck images takes under an hour and the training takes minutes for 4k steps.\n\nWhen I specify those flags, it took on the order of 13 hours to complete when I had ~9k images.\n\nObviously it has to do more work, but needing to do more than 13x the work to transform 15% of my images seems wrong.\n", "comments": ["@petewarden: Can you take a look at this? \n", "Unfortunately this is expected behavior. All of the images are being transformed, the percentage values are for the amount of cropping, etc, not how many images are being affected. This means the original images can't be cached at the bottleneck stage as they are without transformations applied, so running each training step is a lot more expensive. I recommend switching to GPUs once you have heavier duty training needs like this.\n\nClosing since this is working as intended.\n", "Trigger update_date\n"]}, {"number": 2668, "title": "Error: unexpected EOF from Bazel server", "body": "==> tensorflow : r0.9   bazel : 0.2.3  gcc:6.1.1  python: 3.5\nWhen i try to compile tensorflow from source on my archlinux(kernel : 4.5.4-1) ,errror occured. Something like \" Linking tensorflow/cc/ops/data_flow_ops_gen_cc [for host]\nError: nexpected EOF from Bazel server.\"\n", "comments": ["And when i tried again ,i got the same error :\ntensorflow/core/kernels/reduce_join_op.cc:108:31: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n   for (int32 index = 0; index < index_is_reduced.size(); ++index) {\n                         ~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~\n[1,652 / 2,403] Compiling tensorflow/core/common_runtime/simple_graph_execution_state.cc\nError: unexpected EOF from Bazel server.\n\nMaybe there is a bug in GCC-6.1.1 ?? How can I change the default compiler ? Thanks\n", "This seems like a bazel issue, unfortunately.  @damienmg: Do you have any ideas?\n", "Copy-paste of my answer on bazel-discuss to another similar issue:\n\"This means that something has killed Bazel during its run. I saw this behavior on some system where the memory of the OS was reaching the limit and the OOM killer was always choosing Bazel because it was the most memory consuming process.\"\n", "Thanks @damienmg!  Closing since it is not a TensorFlow issue. \n"]}, {"number": 2667, "title": "How to save and restore tensorflow graph and it's state in C++?", "body": "I'm training my model using tensorflow in C++ (I have a lot of stuff in c++ for my model). Python is used only for constructing the graph. So is there way to save and restore graph and its state purely in C++? I know about python tf.train.Saver but as I've understood it is not exists in C++.\n\nIs it possible to get GraphDef from already running session?\n\nHere is StackOverflow question\nhttp://stackoverflow.com/questions/37508771/how-to-save-and-restore-tensorflow-graph-and-its-state-in-c\n", "comments": ["I posted an [answer](http://stackoverflow.com/a/37671613/3574081) on Stack Overflow. Feel free to continue the discussion over there!\n", "hi,bro @mrry ,before I tried to frozen the graph and run it in C++. It works, but  it takes much more time than runing the graph in python(not the frozen one but the one restored from check point). It sucks me badly. So I wounder whether the way you posted can run faster?", "Freeze and save model, Example here: https://github.com/rockzhuang/tensorflow/commit/fb6a6f4e3dd6e663a14b672ab5c616d968d62bc5\r\nhttps://github.com/rockzhuang/tensorflow/commit/eb0ecaecd30848190f4d40d7ff7cd7fedcacf4f2\r\nhttps://github.com/rockzhuang/tensorflow/commit/74545f9c7a618f3aa57d7c7027a67281131cc6dd\r\n"]}, {"number": 2666, "title": "add doc for packaging TF in format of tar.gz", "body": "tackle issue: #2631 \n", "comments": ["Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "I signed it!\n", "CLAs look good, thanks!\n\n<!-- ok -->\n", "This file is already big. It does not feel right to put there all those instructions...\n\nWhy to build tar.gz anyway?\n", "I think this would be great as a gist or something hosted elsewhere, and we'd be happy to link to it at the bottom of the install page -- our installation instructions are already way too long and it's already a pain to maintain right now :)\n"]}, {"number": 2665, "title": "TypeError when using distributed TensorFlow", "body": "I follow the document to run TensorFlow in distributed mode in https://www.tensorflow.org/versions/r0.8/how_tos/distributed/index.html . But I got this error \"TypeError: 'str' object is not callable\".\n\n```\nroot@b8ff53209db2:/# python trainer.py \\\n>      --ps_hosts=ps0.example.com:2222,ps1.example.com:2222 \\\n>      --worker_hosts=worker0.example.com:2222,worker1.example.com:2222 \\\n>      --job_name=ps --task_index=0\nTraceback (most recent call last):\n  File \"trainer.py\", line 74, in <module>\n    tf.app.run()\n  File \"/usr/local/lib/python3.4/site-packages/tensorflow/python/platform/app.py\", line 30, in run\n    sys.exit(main(sys.argv))\n  File \"trainer.py\", line 18, in main\n    worker_hosts = FLAGS.worker_hosts(\",\")\nTypeError: 'str' object is not callable\n```\n### Environment info\n\nOperating System: Ubuntu, 4.4.0-22-generic\n\nInstalled version of CUDA and cuDNN: None\n\nIf installed from binary pip package, provide:\n\n```\npip 8.1.2\nPython 3.4.4\ntensorflow 0.8.0\n```\n\nIf installed from sources, provide the commit hash:\n### Steps to reproduce\n1. `python trainer.py --ps_hosts=\"ps0.example.com:2222,ps1.example.com:2222\" --worker_hosts=\"worker0.example.com:2222,worker1.example.com:2222\" --job_name=\"worker\" --task_index=1`\n### Logs or other output that would be helpful\n\n```\nTraceback (most recent call last):\n  File \"trainer.py\", line 74, in <module>\n    tf.app.run()\n  File \"/usr/local/lib/python3.4/site-packages/tensorflow/python/platform/app.py\", line 30, in run\n    sys.exit(main(sys.argv))\n  File \"trainer.py\", line 18, in main\n    worker_hosts = FLAGS.worker_hosts(\",\")\nTypeError: 'str' object is not callable\n```\n", "comments": ["`FLAGS.worker_hosts` is the string (type `str`) value of the `--worker_hosts` flag. It doesn't define a `__call__()` method, hence the error you are seeing.\n\nI think instead you want to have:\n\n``` python\nworker_hosts = FLAGS.worker_hosts.split(\",\")\n```\n", "Thank @mrry for helping. But actually I have used `worker_hosts = FLAGS.worker_hosts.split(\",\")`, just like what the official document said. \n\nHere's the complete code.\n\n```\nimport tensorflow as tf\n\n# Flags for defining the tf.train.ClusterSpec\ntf.app.flags.DEFINE_string(\"ps_hosts\", \"\",\n                           \"Comma-separated list of hostname:port pairs\")\ntf.app.flags.DEFINE_string(\"worker_hosts\", \"\",\n                           \"Comma-separated list of hostname:port pairs\")\n\n# Flags for defining the tf.train.Server\ntf.app.flags.DEFINE_string(\"job_name\", \"\", \"One of 'ps', 'worker'\")\ntf.app.flags.DEFINE_integer(\"task_index\", 0, \"Index of task within the job\")\n\nFLAGS = tf.app.flags.FLAGS\n\n\ndef main(_):\n  ps_hosts = FLAGS.ps_hosts.split(\",\")\n  worker_hosts = FLAGS.worker_hosts(\",\")\n\n  # Create a cluster from the parameter server and worker hosts.\n  cluster = tf.train.ClusterSpec({\"ps\": ps_hosts, \"worker\": worker_hosts})\n\n  # Create and start a server for the local task.\n  server = tf.train.Server(cluster,\n                           job_name=FLAGS.job_name,\n                           task_index=FLAGS.task_index)\n\n  if FLAGS.job_name == \"ps\":\n    server.join()\n  elif FLAGS.job_name == \"worker\":\n\n    # Assigns ops to the local worker by default.\n    with tf.device(tf.train.replica_device_setter(\n        worker_device=\"/job:worker/task:%d\" % FLAGS.task_index,\n        cluster=cluster)):\n\n      # Build model...\n      loss = ...\n      global_step = tf.Variable(0)\n\n      train_op = tf.train.AdagradOptimizer(0.01).minimize(\n          loss, global_step=global_step)\n\n      saver = tf.train.Saver()\n      summary_op = tf.merge_all_summaries()\n      init_op = tf.initialize_all_variables()\n\n    # Create a \"supervisor\", which oversees the training process.\n    sv = tf.train.Supervisor(is_chief=(FLAGS.task_index == 0),\n                             logdir=\"/tmp/train_logs\",\n                             init_op=init_op,\n                             summary_op=summary_op,\n                             saver=saver,\n                             global_step=global_step,\n                             save_model_secs=600)\n\n    # The supervisor takes care of session initialization and restoring from\n    # a checkpoint.\n    sess = sv.prepare_or_wait_for_session(server.target)\n\n    # Start queue runners for the input pipelines (if any).\n    sv.start_queue_runners(sess)\n\n    # Loop until the supervisor shuts down (or 1000000 steps have completed).\n    step = 0\n    while not sv.should_stop() and step < 1000000:\n      # Run a training step asynchronously.\n      # See `tf.train.SyncReplicasOptimizer` for additional details on how to\n      # perform *synchronous* training.\n      _, step = sess.run([train_op, global_step])\n\n\nif __name__ == \"__main__\":\n  tf.app.run()\n```\n", "It looks like the error is still present in the code snippet you posted:\n\n![worker_hosts = FLAGS.worker_hosts(\",\")](http://i.imgur.com/7eH14HE.png)\n", "Sorry for such a bother. It works after fixing this and I think we can fix the document in the TensorFlow site because we always copy-and-paste its code snippet.\n\nThank @mrry  again. \n"]}, {"number": 2664, "title": "Added linker options to armv7 in iOS makefile", "body": "", "comments": ["Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "Jenkins, test this please.\n", "I signed it.\n", "@martinwicke Can you figure out why the CLA bot thinks I'm not authorized? I've checked the commit and it seems to have my correct google.com address attached.\n", "Hmm. Jenkins ignored you too.\n", "The creator of the PR shows as @petewarden4prs, not @petewarden, maybe that's why? Have you successfully created PRs from that special account before?\n"]}, {"number": 2663, "title": "Added linker flags for iOS build", "body": "", "comments": []}, {"number": 2662, "title": "contrib/session_bundle does not work with python3", "body": "Branch r0.9 \n### Environment info\n\nOperating System: Ubuntu 14.4\n\nInstalled version of CUDA and cuDNN: no\n### Steps to reproduce\n1.  ./configure -> python path = /usr/local/bin/python3\n2.  bazel build -c opt //tensorflow/tools/pip_package:build_pip_package\n\nError with:\n//tensorflow/contrib/session_bundle/example:export_half_plus_two\n### What have you tried?\n1.  Cloning branch r0.8, which does not include the broken target, works\n", "comments": ["Can we see the full error message?\n", "Automatically closing due to lack of recent activity. Please reopen when further information becomes available.\n"]}, {"number": 2661, "title": "Map/Scan/Fold cannot be nested.", "body": "import tensorflow as tf\na=tf.constant([[[1,2,3],[10,20,30]],[[1,2,3],[10,20,30]],[[1,2,3],[10,20,30]],[[1,2,3],[10,20,30]]])\n\nsess=tf.InteractiveSession()\nprint sess.run(tf.map_fn(lambda x: tf.scan(lambda y,z:tf.add(y,z),x),a))\n\nERROR:\n\nAlreadyExistsError: Resource _tensor_arrays/map_10/while/scan/TensorArray/N10tensorflow11TensorArrayE\n     [[Node: map_10/while/scan/TensorArray = TensorArray[clear_after_read=true, dtype=DT_INT32, dynamic_size=false, tensor_array_name=\"\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](map_10/while/scan/Squeeze/_72, ^_cloopmap_10/while/scan/TensorArrayWrite/index/_19)]]\n     [[Node: map_10/while/scan/while/Identity/_73 = _HostSend[T=DT_INT32, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_190_map_10/while/scan/while/Identity\", _device=\"/job:localhost/replica:0/task:0/gpu:0\"](map_10/while/scan/while/Identity)]]\nCaused by op u'map_10/while/scan/TensorArray', defined at:\n  File \"/usr/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\", line 589, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py\", line 405, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py\", line 840, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(_args, *_kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(_args, *_kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(_args, *_kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 260, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 212, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 370, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py\", line 175, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2723, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2825, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2885, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-26-ae3c447b43e3>\", line 2, in <module>\n    print sess.run(tf.map_fn(lambda x: tf.scan(lambda y,z:tf.add(y,z),x),a))\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/functional_ops.py\", line 259, in map_fn\n    swap_memory=swap_memory)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 1671, in while_loop\n    result = context.BuildLoop(cond, body, loop_vars)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 1572, in BuildLoop\n    body_result = body(*vars_for_body_with_tensor_arrays)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/functional_ops.py\", line 253, in compute\n    ta = ta.write(i, fn(elems_ta.read(i)))\n  File \"<ipython-input-26-ae3c447b43e3>\", line 2, in <lambda>\n    print sess.run(tf.map_fn(lambda x: tf.scan(lambda y,z:tf.add(y,z),x),a))\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/functional_ops.py\", line 319, in scan\n    infer_shape=True)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/tensor_array_ops.py\", line 126, in __init__\n    tensor_array_name=tensor_array_name, name=scope)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_data_flow_ops.py\", line 659, in _tensor_array\n    tensor_array_name=tensor_array_name, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py\", line 694, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2153, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1153, in __init__\n    self._traceback = _extract_stack()\n", "comments": ["This is a known issue.  Right now you cannot nest map/scan/fold*.  No ETA on the fix unfortunately :(\n", "@ebrevdo  OK to close this as contributions welcome?\n", "Sorry for not updating this thread. Support for this was added last week. Should be on github now.  Try your example off HEAD.\n", "@ebrevdo thanks! I have reopened the issue! So now tensorflow supports nest map/scan/fold? Is this in  nightly binaries version? \n", "Yes, this was fixed in #2918.\n", "@ebrevdo  I have downloaded the latest nightly build but the same problem is there! my tensorflow version is '0.9.0rc0'. \n"]}, {"number": 2660, "title": "Max Pooling NCHW", "body": "In the documentation for the tf.nn.max_pool() op, it is written: \n\n`data_format: A string. 'NHWC' and 'NCHW' are supported.`\n\nHowever, when I specify 'NCHW' as the data format, I receive the error \"Default MaxPoolingOp only supports NHWC\" (generated [here](https://github.com/tensorflow/tensorflow/blob/3488ac22f156cbcfd27c242ccbdac58679385ddc/tensorflow/core/kernels/pooling_ops_common.h#L83) in master when this was written). \n\nIt was my understanding that most ops have been ported to NCHW to support CuDNN natively - so I was surprised to see this wasn't implemented. \n", "comments": ["@vrv: Can you take a look?  At best, the error message isn't very explanatory.  \n", "I talked to @zheng-xq: NCHW is supported only for GPU (because we call cudnn), we do not have an implementation for CPU.\n\nI'm not sure how to correct the documentation though -- the data_format strings indicate the potentially supported formats, not the actually supported ones :(.\n\nTo reiterate:\n\nMaxPool on GPU supports NCHW and NHWC\nMaxPool on CPU only supports NHWC.\n\nIf you have a concrete suggestion for how I should change the documentation, please let me know and I'll be happy to make the improvement!\n", "@vrv: Maybe just add \"(on device %s)\" to the error message so that we know which device it isn't supported on?\n", "Yep I think that would help a lot - the error message seemed to imply that NCHW wasn't supported at all, vs only not being supported on CPU. \n", "So, this is quite inconsistent with the suggestions of using NCHW for the gpu, due to cudnn. Can we just have MaxPooling actually work with NCHW on the CPU as well? At the moment we literally can not test our code on a CPU for dev because of this issue...", "This Documentation [TensorFlow* Optimizations on Modern Intel\u00ae Architecture](https://software.intel.com/en-us/articles/tensorflow-optimizations-on-modern-intel-architecture), says \"Data format: we suggest that users can specify the NCHW format for their specific neural network model to get maximum performance. TensorFlow default NHWC format is not the most efficient data layout for CPU and it results in some additional conversion overhead.\"\r\nDue to the MKL in version 1.2, is this necessary to fix this issue?\r\n@lakshayg ", "I received this error message that didn't say device info, still `Default MaxPoolingOp only supports NHWC`. The error doesn't always occur when I run [tensorflow benchmark code](https://github.com/tensorflow/benchmarks/blob/master/scripts/tf_cnn_benchmarks/tf_cnn_benchmarks.py). The placer put this op on `cpu:0`, maybe because I set `allow_soft_placement` as true.", "I find one worker got `failed call to cuInit: CUDA_ERROR_NOT_INITIALIZED` error so it's not tensorflow code problem."]}, {"number": 2659, "title": "Enable tf.shape() for SparseTensor", "body": "Added an override for `tf.shape()`, that takes care of `SparseTensor` objects as well. Added tests and verified locally. This partially addresses #1968.\n", "comments": ["Can one of the admins verify this patch?\n", "@siddharth-agrawal: looks good, could you rebase?  I will kick off the Jenkins run after that.\n", "Jenkins, test this please. \n", "@concretevitamin Done. I have a question though. I thought I needed to rebase only when there were conflicts in my branch, or is there another reason?\n", "yeah, rebasing only needed on conflicts (most of the time).\n\n@tensorflow-jenkins test this please\n", "You're right -- I saw the merge button being gray but I didn't look too closely.  It was not due to conflicts but due to the lack of Jenkins results.  Will merge after green.\n", "Merged into master.  Thanks @siddharth-agrawal!\n", "@concretevitamin No problem!\n"]}, {"number": 2658, "title": "Android permission check", "body": "Added a simple permission check and request to prevent crashing on api 23+\n", "comments": ["Can one of the admins verify this patch?\n", "ping for @andrewharp \n", "Hi, thanks for the PR. We had previously merged a commit to add a permissions check (https://github.com/tensorflow/tensorflow/pull/926), but reverted it because at the time it was causing some Google-internal build complications.\n\nInstead it was easier to change the app to build at API level 21, where all required permissions are granted on install automatically (are you trying to build at API 23? If so, maybe adb install -g will work for you in the short term?)\n\nMy major concern here is bringing in the Android support libraries as a dependency, since that complicates the build. I can test the previous PR again and see if that builds internally now, if this works for you.\n", "I checked, and I can no longer reproduce the internal issue with the previous change.\n\nAlso, it does make more sense to put the authorization code in CameraActivity.java and to additionally request the storage permission, as you've done. Would you mind modifying your commit remove the use of the Android support libraries (you can use the previous solution for reference)?\n", "@andrewharp made the change. Do you want to set the target at 23 in the same commit?\n", "Thanks!\n\nWith the runtime checks on Android M for devices at API < 23, yes it should be safe (and required) to set the target level to 23.\n", "@andrewharp let me know if everything looks good.\n", "@tensorflow-jenkins: test this please\n", "@andrewharp ready to merge?\n"]}, {"number": 2657, "title": "Android permission check", "body": "Added a simple permission check and request to prevent crashing on api 23+\n", "comments": ["Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "I signed it!\n", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for the commit author(s).  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\n\n<!-- need_author_cla -->\n"]}, {"number": 2656, "title": "update release and roadmap", "body": "", "comments": []}, {"number": 2655, "title": "Feature Request: Support for YARN cluster manager for Distributed TensorFlow", "body": "The Distributed TensorFlow documentation said to open an issue to request support for a specific cluster manager, support for YARN would be beneficial. \n\nThanks\n", "comments": ["Yes, we'd like to do that. Nobody is working on it right now though.\n", "@j9ac9k In the meantime if you are interested there is an initial work on Mesos that already can use GPU resources at https://github.com/tensorflow/tensorflow/issues/1996\n", "Is anyone working on this now?\n", "We've started looking at this internally. @jhseu will be leading up this effort.\n", "So are you supporting internally yarn and on contribution mesos?\n", "We'll likely do both.\n", "Great. Any timeline on this?\n", "There are some prerequisites that need to be done first for it to be useful (e.g. HDFS support). Definitely soonish, but I'd prefer not commit externally to a timeline :)\n", "Also, YARN has some complications that don't exist in Mesos and Kubernetes, so we're not completely sure we'll add support for it.\n", "How tensorflow will support hdfs ? Any progress? I'm going to contribute on it.\n", "We're working on HDFS, it's close.\n", "@martinwicke hi guy, how does the HDFS support going on? very looking forward to this feature.\n", "@martinwicke Looking forward to this feature. Let me know if you need any help on this to get it out quicker\n", "Hi @jhseu and @martinwicke , I am from YARN community. Just noticed some comments above to say extra complications on YARN over Mesos/Kubernetes. Can you shed more light on this? I can see how can I help here, especially from YARN side. Thx!\n", "Any update ?? \n", "No update. We'll publish Mesos/Kubernetes examples fairly soon and then consider YARN next.\n\n@JunpingDu I'll follow up with you through e-mail.\n", "is there any HDFS support release plan recently? \nThanks.\n", "HDFS support is available in 0.11 (and at head). See this [howto](https://www.tensorflow.org/versions/r0.11/how_tos/hadoop/index.html).\n", "You can ignore those instructions and just start using hdfs paths if you use this Docker image:\nhttps://github.com/tensorflow/ecosystem/blob/master/docker/Dockerfile.hdfs\n", "I am working on this and will use Slider to support tensorflow on YARN. I have created a JIRA in Slider Project to make a introduction. https://issues.apache.org/jira/browse/SLIDER-1174\n", "Nice! When you have a working configuration, would you mind sending a pull request to [github.com/tensorflow/ecosystem](https://github.com/tensorflow/ecosystem)?\n", "Sure, I will send a pull request to ecosystem when it could work\n", "@JunpingDu @jhseu , this is zhankun from intel focused on Hadoop. We are glad to help on YARN too. How can I join your thread? :)\n", "@wangyang0918 A great job. Any progresses?\n", "Thanks for your attention. @formath \nI have already done most of the INCLUDED features in SLIDER-1174 and will attach a alpha patch next week.\n", "Hi! Yarn support would be great! Could you share your progress please? Thank you for your efforts!", "@wangyang0918 I didn't find a PR there yet. Hope you're progressing.", "@drpngx Note there is also [YARN-6043 TensorFlow on YARN](https://issues.apache.org/jira/browse/YARN-6043) in the Hadoop community that doesn't require docker. You may check out the details in the design document. ", "I have a high level question regarding this feature request: what are the key benefits of a native approach (directly running TF on YARN) compared with a Spark based approach, most notably https://github.com/yahoo/TensorFlowOnSpark?", "In Hadoop 3.0, YARN native services can support running Tensorflow services on YARN without adding any dependencies or implement a new YARN application master.\r\n\r\nPlease see our blogpost: https://hortonworks.com/blog/distributed-tensorflow-assembly-hadoop-yarn/ and let me know if you have any questions. Thanks!", "Nice", "In the meantime, while waiting for Hadoop 3.0, this could be an alternative, an YARN native implementation:\r\nhttps://github.com/hopshadoop/hops-tensorflow", "Not sure there's any update for this effort?", "Just to echo @tobiajo  - there is a version of distributed YARN-native tensorflow available here:\r\nhttps://github.com/hopshadoop/hops-tensorflow\r\nThis also includes support for GPUs as a resource in YARN:\r\nhttps://hopshadoop.atlassian.net/browse/HOPS-11\r\n\r\nGUI support for running distributed TF jobs on YARN will be provided in Hopsworks by the end of the month (including Jupyter to write/run jobs):\r\nhttps://www.youtube.com/watch?v=rop6bhuBHT0\r\n", "@jimdowling Thanks for the pointers. One quick question - does this YARN-native Tensorflow work with regular Hadoop (i.e. Apache Hadoop, rather than Hops)?", "@xiaoyaozhuzi  - no. Hops Hadoop is a fork of Apache Hadoop. The YARN code is identical to the Apache code (version 2.7.3) with only a few additions: cluster state is recovered from MySQL Cluster and support for GPUs. If somebody wanted they could take our code and introduce it to YARN. But the YARN folks would prob reject the PR as they want to redesign YARN's resource model before accepting support for GPUs. That will take time.", "@xiaoyaozhuzi no since we added GPU support as a resource, Apache Hadoop is not supported. One could, with just a little effort, fork the repo, strip the GPU stuff and change the dependencies in the [pom.xml](https://github.com/hopshadoop/hops-tensorflow/blob/master/pom.xml) to Apache Hadoop.", "I'm closing this -- a feature request for YARN support and any discussion should probably happen at  tensorflow/ecosystem instead. "]}]