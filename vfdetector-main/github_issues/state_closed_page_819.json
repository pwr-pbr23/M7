[{"number": 28964, "title": "Corrected log-format to %s. Removes build-warning", "body": "", "comments": []}, {"number": 28963, "title": "Fixed param ordering of RESIZE_BILINEAR for NNAPI", "body": "This commit swaps the ordering of the parameters sent to RESIZE_BILINEAR.\r\nCurrently width is sent as height. For reference see the documentation of RESIZE_BILINEAR.\r\nhttps://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a42bd92518e273b6716ecd56b571fcd3e", "comments": ["This is not a bug, there was an inconsistency between the documentation & the NNAPI driver pre-Android Q. So this should work as intended. Are you seeing an accuracy drop for any model with NNAPI?", "@srjoglekar246 That is odd. We're running a model on a Xiaomi MI9 as well as a Samsung S10, both with the snapdragon 855. When we disable RESIZE_BILINEAR in the delegate the model is executed correctly, as well as when we run the model without the NNAPI. \r\n\r\nHowever when delegating to RESIZE_BILINEAR the model returns different/invalid data. Aligning the parameters according to the NNAPI-documentation fixes our problem and gives us consistent results when using the delegate. I assumed this was a bug. Could the parameter-implementation vary between different drivers?\r\n\r\n\r\n\r\n", "Unfortunately, there seems discrepancy in NNAPI's CPU reference implementation and the driver implementation for devices running Android P. In Q, NNAPI fixed the documentation and advised QCOM to fix the driver implementation.\r\n\r\nI think we should probably make sure width == height before delegating to devices running Android P.", "@miaowang14 Yes that seems to be the case. I agree that validating width == height makes sense to avoid incorrect behaviour. I could update this pull request with that validation if that is acceptable @srjoglekar246 ?", "Will defer to Miao for that :-)", "@silfverstrom , sounds good to me.", "@miaowang14 I've updated this PR, it now disables bilinear when width != height for nnapi < 1.2.", "@miaowang14 @srjoglekar246 Is it possible to merge this pr?", "Could you rebase this PR? It shows some errors while merging internally", "@srjoglekar246 Sure, I've rebased the branch.", "@silfverstrom Could you please resolve the conflicts? Thanks!", "> @silfverstrom Could you please resolve the conflicts? Thanks!\r\n\r\nSure, i've resolved the conflicts.", "Changes have been pushed earlier, auto merge did not happen ,so closing this PR."]}, {"number": 28962, "title": "Rename WorkerCacheInterface::CreateWorker to GetOrCreateWorker().", "body": "for this\r\n```\r\n  // TODO(mrry): rename this to GetOrCreateWorker() or something that\r\n  // makes it more obvious that this method returns a potentially\r\n  // shared object.\r\n  virtual WorkerInterface* CreateWorker(const string& target) = 0;\r\n```", "comments": ["@gbaned Would you mind adding another reviewer?", "@gbaned \r\n> hawkinsp removed their request for review just now\r\n  \r\nWould you mind adding another reviewer?", "Reassigning this to @swpnlptl to take a look.", "@swpnlptl \r\nHere are six Internal CI builds failed. I don't think it's caused by my changes. What else do I need to do?"]}, {"number": 28961, "title": "tensorflow compile error", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n**grpc** **sha256** checksum was\"*\" but wanted\"*\"\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):source\r\n- TensorFlow version:branch:master  05/23/2019\r\n- Python version:2.7\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):0.24.1\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:10/7.5.1\r\n- GPU model and memory:\r\n\r\n\r\n8g\r\n**Describe the problem**\r\nDownloading  **grpc** from github ,the sha256 checksum is not suit for the .bzl files.\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nAlmost every time I compile tensorflow ,this bug will turn out.\r\nthe last few times I was lucky,the  sha code was right after  tried so .many times.\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["> _Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template_\r\n> **grpc** **sha256** checksum was\"_\" but wanted\"_\"\r\n> **System information**\r\n> \r\n> * OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n> * Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n> * TensorFlow installed from (source or binary):source\r\n> * TensorFlow version:branch:master  05/23/2019\r\n> * Python version:2.7\r\n> * Installed using virtualenv? pip? conda?:\r\n> * Bazel version (if compiling from source):0.24.1\r\n> * GCC/Compiler version (if compiling from source):\r\n> * CUDA/cuDNN version:10/7.5.1\r\n> * GPU model and memory:\r\n> \r\n> 8g\r\n> **Describe the problem**\r\n> Downloading **grpc** from github ,the sha256 checksum is not suit for the .bzl files.\r\n> **Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n> Almost every time I compile tensorflow ,this bug will turn out.\r\n> the last few times I was lucky,the sha code was right after tried so .many times.\r\n> \r\n> **Any other info / logs**\r\n> Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\nBad network will lead this problem,you can download grpc package from browser and set a web server for the package,then you change bzl url to your server url and you can download package from your server directly.\r\n", "> > _Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template_\r\n> > **grpc** **sha256** checksum was\"_\" but wanted\"_\"\r\n> > **System information**\r\n> > \r\n> > * OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n> > * Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n> > * TensorFlow installed from (source or binary):source\r\n> > * TensorFlow version:branch:master  05/23/2019\r\n> > * Python version:2.7\r\n> > * Installed using virtualenv? pip? conda?:\r\n> > * Bazel version (if compiling from source):0.24.1\r\n> > * GCC/Compiler version (if compiling from source):\r\n> > * CUDA/cuDNN version:10/7.5.1\r\n> > * GPU model and memory:\r\n> > \r\n> > 8g\r\n> > **Describe the problem**\r\n> > Downloading **grpc** from github ,the sha256 checksum is not suit for the .bzl files.\r\n> > **Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n> > Almost every time I compile tensorflow ,this bug will turn out.\r\n> > the last few times I was lucky,the sha code was right after tried so .many times.\r\n> > **Any other info / logs**\r\n> > Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n> \r\n> Bad network will lead this problem,you can download grpc package from browser and set a web server for the package,then you change bzl url to your server url and you can download package from your server directly.\r\nTHANKS"]}, {"number": 28960, "title": "Release r1.14rc0 cherry-pick request: make tensorflow-gpu work on machine w/o CUDA setup", "body": "", "comments": []}, {"number": 28959, "title": "`BaseSession._Callable.__del__` doesn\u2019t detect closed session correctly", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Arch Linux\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Not tested\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (use command below): 1.13.1\r\n- Python version: 3.7.3\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**Describe the current behavior**\r\n\r\n`BaseSession._Callable.__del__` doesn\u2019t detect closed session correctly. Running the code I provided below will causes the following error message being printed:\r\n\r\n```\r\nException ignored in: <function BaseSession._Callable.__del__ at 0x7fe50cc480d0>\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python3.7/site-packages/tensorflow/python/client/session.py\", line 1455, in __del__\r\n    self._session._session, self._handle, status)\r\n  File \"/usr/lib/python3.7/site-packages/tensorflow/python/framework/errors_impl.py\", line 528, in __exit__\r\n    c_api.TF_GetCode(self.status.status))\r\ntensorflow.python.framework.errors_impl.CancelledError: Session has been closed.\r\n```\r\n\r\nThe error message doesn\u2019t affect the correctness of the program, but it is annoying to see.\r\n\r\n**Describe the expected behavior**\r\n\r\nThe test program exits without printing the error message.\r\n\r\n**Code to reproduce the issue**\r\n\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow.core.protobuf.config_pb2 import CallableOptions\r\n\r\n\r\ndef main():\r\n    with tf.Session() as session:\r\n        t = tf.zeros(shape=())\r\n\r\n        c = session._make_callable_from_options(CallableOptions(fetch=[t.name]))\r\n\r\n        print(c())\r\n\r\n\r\nif __name__ == '__main__':\r\n    main()\r\n```\r\n\r\n**Other info / logs**\r\n\r\nHere is my analysis:\r\n\r\n- This is the definition of `BaseSession.close`:\r\n\r\n  https://github.com/tensorflow/tensorflow/blob/592fa18bc134d9b9527f3d87ba51d6ae0378e3da/tensorflow/python/client/session.py#L736-L747\r\n\r\n  If it is called on an alive session, `self._closed` will be set to `True` but `self._session` will not change.\r\n- This is the definition of `BaseSession.__del__`:\r\n\r\n  https://github.com/tensorflow/tensorflow/blob/592fa18bc134d9b9527f3d87ba51d6ae0378e3da/tensorflow/python/client/session.py#L749-L764\r\n\r\n  This method will set `self._session` to `None`.\r\n\r\n- This is the definition of `BaseSession._Callable.__del__`:\r\n\r\n  https://github.com/tensorflow/tensorflow/blob/592fa18bc134d9b9527f3d87ba51d6ae0378e3da/tensorflow/python/client/session.py#L1467-L1473\r\n\r\n  It only detect `self._session._session`, but not `self._session._closed`.\r\n\r\nSo if a `BaseSession._Callable` is being destroyed after the corresponding session being closed, but before the session being destroyed, `TF_SessionReleaseCallable` will be called on a closed session, which will raise the exception mentioned above.\r\n\r\nThere are two possible fixes:\r\n\r\n1. Set `self._session` to `None` in `BaseSession.close`.\r\n2. Detect `self._session._closed` in `BaseSession._Callable.__del__`.\r\n\r\nMaybe related: #3388, #24367.", "comments": ["I was able to reproduce the issue on Colab with TensorFlow version 1.13."]}, {"number": 28958, "title": "Merge bn with depthwise conv for *.bp ", "body": "**System information**\r\n- TensorFlow version (you are using):1.10\r\n- Are you willing to contribute it (Yes/No):yes\r\n\r\nI used graph_transforms  and optimize_for_inference to optimize the freeze_graph. I  focus on merging bn with  conv layers to speed up the inference time. But both method can only merge bn with CONV2D, and can not merge bn with DEPTHWISE CONV. As far as  i know, the tool toco can merge all the conv with  bn to *.tflite. So, will the graph_transforms support to do so for *.bp.\r\n\r\n", "comments": ["@holyhao Please refer the [link](https://github.com/google-research/morph-net/issues/32) and let us know if that answers your query", "@muddham It has nothing to do with it, i want a optimizer for *bp to merge the bn with  DEPTHWISE CONV.", "@holyhao Can you try latest version of TF (1.13.1 or 2.0) and check whether the issue is persisting? Could you provide any standalone code to reproduce the issue? Thanks!", "Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will open a new issue. Thanks!"]}, {"number": 28956, "title": "Distribute Strategy wrong reduction", "body": "## URL(s) with the issue: https://www.tensorflow.org/guide/distribute_strategy#using_tfdistributestrategy_with_custom_training_loops\r\n\r\n## Description of issue (what needs changing):\r\nIn the documentation the snippet:\r\n\r\n```python\r\ndef train_step():\r\n  def step_fn(inputs):\r\n    features, labels = inputs\r\n    logits = model(features)\r\n    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\r\n        logits=logits, labels=labels)  \r\n    loss = tf.reduce_sum(cross_entropy) * (1.0 / global_batch_size)\r\n    train_op = optimizer.minimize(loss)\r\n    with tf.control_dependencies([train_op]):\r\n      return tf.identity(loss)\r\n\r\n  per_replica_losses = mirrored_strategy.experimental_run(\r\n      step_fn, input_iterator)\r\n  mean_loss = mirrored_strategy.reduce(\r\n      tf.distribute.ReduceOp.MEAN, per_replica_losses)\r\n  return mean_loss\r\n```\r\ncalculates the loss using the distribution strategy. However the loss for each replica is reduced using `tf.distribute.ReduceOp.MEAN`. I think that the correct loss to return is the loss reduced using `tf.distribute.ReduceOp.SUM` since every loss is already reduced using the partial mean over the `global_batch_size` (` tf.reduce_sum(cross_entropy) * (1.0 / global_batch_size)`) . \r\n\r\nI think a better snippet would be:\r\n\r\n```python\r\ndef train_step():\r\n  def step_fn(inputs):\r\n    features, labels = inputs\r\n    logits = model(features)\r\n    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\r\n        logits=logits, labels=labels)  \r\n    loss = tf.reduce_sum(cross_entropy) * (1.0 / global_batch_size)\r\n    train_op = optimizer.minimize(loss)\r\n    with tf.control_dependencies([train_op]):\r\n      return tf.identity(loss)\r\n\r\n  per_replica_losses = mirrored_strategy.experimental_run(\r\n      step_fn, input_iterator)\r\n  loss = mirrored_strategy.reduce(\r\n      tf.distribute.ReduceOp.SUM, per_replica_losses)\r\n  return loss\r\n```\r\n\r\nAm I wrong?\r\n\r\n### Submit a pull request?\r\n\r\nMaybe I can submit a pull request to fix this.\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n", "comments": ["hi @EmanueleGhelfi - you're absolutely right, and looks like we've fixed the documentation too :) thanks for reporting and apologies for the delay! "]}, {"number": 28955, "title": "fatal error LNK1000: Internal error during CImplib::EmitThunk", "body": "**System information**\r\n- Windows 10\r\n- TensorFlow installed from (source or binary): source\r\n- C++ Visual Studio 2015 Update 3\r\n- GPU model and memory: NO USE\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nHi,\r\nI have a Static library project, containing some codes that are using Tensorflow as Additional Dependencies.\r\nI want to make a static libray (name \"`myLib.lib`\") from these codes to use in another Win32 App.\r\nIn my static library project, I used `/WHOLEARCHIVE` flag to include all tensorflow's lib files to the my final static library, `myLib.lib` file.\r\nI build it and make `myLib.lib` file.\r\nIn another Win32 App I link this `myLib.lib` to use it and also use `/WHOLEARCHIVE:myLib.lib` as a Additional options in Linker->Command Line.\r\nBut when I run this win32app, I got the error:\r\n\r\n`fatal error LNK1000: Internal error during CImplib::EmitThunk`\r\n\r\nI searched many topics but I didn't find any appropriate solution. I totaly confused. What should I do?\r\n\r\nI have to say that I added `/WHOLEARCHIVE` flag in order to prevent error `No session factory registered for the given session options` when using Tensorflow.\r\n", "comments": ["i encounter this too, do you have some metheds to solve it. i build tensorflowr1.13.0 with bazel.", "@fmmohammadi ", "No idea ??", "@fmmohammadi Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\nMake sure you also include the exact command if possible to produce the output included in your test case. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!", "@muddham @ZLeopard \r\nAfter tons of searching I found that the problem is because of Visual Studio 2015. As mentioned [here](https://support.microsoft.com/en-us/help/4020481/fix-link-exe-crashes-with-a-fatal-lnk1000-error-when-you-use-wholearch) the cause of problem is:\r\n\r\n> This problem occurs in rare cases because Link.exe might not handle import objects and incremental linking correctly if it uses the /WHOLEARCHIVE switch.\r\n\r\nAnd the solution is to download and install a hotfix (vc14-kb4020481.exe) from [here](https://download.microsoft.com/download/8/1/d/81dbe6bb-ed92-411a-bef5-3a75ff972c6a/vc14-kb4020481.exe).\r\n\r\nIt's worth to mention that my OS is Windows 10, I use vs2015 update 3, TensorFlow version 1.10.1 which is compiled from source code and I have .lib files to use.\r\n\r\n\r\n", "@fmmohammadi Glad to hear that your issue was resolved.Hence this issue will be closed."]}, {"number": 28954, "title": "mfcc", "body": "preprocess: Spectrogram processing mode. Can be \"mfcc\" or \"average\".\r\n\r\n\r\nwhat is average?", "comments": ["Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\nMake sure you also include the exact command if possible to produce the output included in your test case. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!\r\n", "Closing this issue since the associated PR has been merged. Feel free to reopen if the problem still persists. Thanks!"]}, {"number": 28953, "title": "[TF 2.0] Cannot use `tf.image.decode_image` with `tf.map_fn` in `tf.data.Dataset.map` when `elems` is empty", "body": "- Tensorflow: latest `tf-nightly-2.0-preview` (as of today).\r\n- Python 3.7\r\n- Ubuntu 19.04\r\n\r\nWhen using `tf.data.Dataset.map` , it can happen that an image does not have any objects in it and so tensors describing masks or boxes are empty.\r\n\r\nA common preprocessing step is to decode a list of masks encoded as string in JPEG or PNG. Consider the following code:\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\ndef generate_encoded_image():\r\n    im = np.random.random((256, 256, 1)).astype('uint8')\r\n    return tf.image.encode_png(im)\r\n\r\ndef fake_data_generator(feature):\r\n    # Here you can change the range to modify the number of objects.\r\n    # The issue araise when feature does not have any objects in it,\r\n    # when `n_objects = 0`.\r\n    n_objects = np.random.randint(0, 1)\r\n    \r\n    feature = {}\r\n    feature['label_ids'] = np.random.random((n_objects,)).astype('int64')\r\n    feature['bboxes'] = np.random.random((n_objects, 4)).astype('float32')    \r\n    \r\n    if n_objects == 0:\r\n        feature['masks'] = tf.constant([], dtype=tf.string)\r\n    else:\r\n        feature['masks'] = [generate_encoded_image() for _ in range(n_objects)]\r\n        \r\n    return feature\r\n\r\ndef decode_masks(feature):\r\n    decode_image_fn = lambda x: tf.image.decode_image(x)\r\n    \r\n    # Using the following works\r\n    # decode_image_fn = lambda x: tf.constant([3, 4, 5], dtype=tf.uint8)\r\n    \r\n    feature['masks_new'] = tf.map_fn(decode_image_fn, feature['masks'], dtype=tf.uint8)\r\n    return feature\r\n   \r\ndataset = tf.data.Dataset.from_tensors(tf.range(20))\r\ndataset = dataset.map(fake_data_generator)\r\ndataset = dataset.map(decode_masks)\r\n\r\nfor feature in dataset:\r\n    pass\r\n```\r\n\r\nRunning it as this will raise this error:\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n<ipython-input-135-af99bdf86e00> in <module>\r\n     36 dataset = dataset.map(decode_masks)\r\n     37 \r\n---> 38 for feature in dataset:\r\n     39     pass\r\n\r\n~/local/conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py in __next__(self)\r\n    584 \r\n    585   def __next__(self):  # For Python 3 compatibility\r\n--> 586     return self.next()\r\n    587 \r\n    588   def _next_internal(self):\r\n\r\n~/local/conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py in next(self)\r\n    621     \"\"\"\r\n    622     try:\r\n--> 623       return self._next_internal()\r\n    624     except errors.OutOfRangeError:\r\n    625       raise StopIteration\r\n\r\n~/local/conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py in _next_internal(self)\r\n    613             self._iterator_resource,\r\n    614             output_types=self._flat_output_types,\r\n--> 615             output_shapes=self._flat_output_shapes)\r\n    616 \r\n    617       return self._structure._from_compatible_tensor_list(ret)  # pylint: disable=protected-access\r\n\r\n~/local/conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/ops/gen_dataset_ops.py in iterator_get_next_sync(iterator, output_types, output_shapes, name)\r\n   2118       else:\r\n   2119         message = e.message\r\n-> 2120       _six.raise_from(_core._status_to_exception(e.code, message), None)\r\n   2121   # Add nodes to the TensorFlow graph.\r\n   2122   if not isinstance(output_types, (list, tuple)):\r\n\r\n~/local/conda/envs/tf/lib/python3.7/site-packages/six.py in raise_from(value, from_value)\r\n\r\nInvalidArgumentError: Tried to stack elements of an empty list with non-fully-defined element_shape: <unknown>\r\n\t [[{{node map/TensorArrayV2Stack/TensorListStack}}]] [Op:IteratorGetNextSync]\r\n```\r\n\r\nThe error only happens when `n_objects = 0` and when I use `tf.image.decode_image`.\r\n\r\nI also tried to use something like:\r\n\r\n```python\r\nif tf.shape(feature['masks'])[0] == 0:\r\n        feature['masks_new'] = tf.constant([], dtype=tf.uint8)\r\n    else:\r\n        feature['masks_new'] = tf.map_fn(decode_image_fn, feature['masks'], dtype=tf.uint8)\r\n```\r\n\r\nBut it raises the same error. It looks like ` tf.shape(feature['masks'])[0] == 0` is never `True`.\r\n\r\nI also tried to `@tf.function` for `decode_masks()` but then TF complains because I modify the input structure:\r\n\r\n```\r\nValueError: The two structures don't have the same nested structure.\r\n\r\nFirst structure: type=tuple str=({'label_ids': <tf.Tensor 'feature_1:0' shape=(0,) dtype=int64>, 'bboxes': <tf.Tensor 'feature:0' shape=(0, 4) dtype=float32>, 'masks': <tf.Tensor 'feature_2:0' shape=(0,) dtype=string>},)\r\n\r\nSecond structure: type=tuple str=({'label_ids': <tf.Tensor 'feature_1:0' shape=(0,) dtype=int64>, 'bboxes': <tf.Tensor 'feature:0' shape=(0, 4) dtype=float32>, 'masks': <tf.Tensor 'feature_2:0' shape=(0,) dtype=string>, 'masks_new': <tf.Tensor 'map/TensorArrayV2Stack/TensorListStack:0' shape=<unknown> dtype=uint8>},)\r\n\r\nMore specifically: The two dictionaries don't have the same set of keys. First structure has keys type=list str=['label_ids', 'bboxes', 'masks'], while second structure has keys type=list str=['label_ids', 'bboxes', 'masks', 'masks_new']\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n```\r\n\r\nI am out of idea here. Help is welcome :-)", "comments": ["I was able to reproduce the issue with TensorFlow version 2.0 on Colab.", "Could you try rewriting you `decode_image_fn` as follows\r\n\r\n    def decode_image_fn(x):\r\n      t = tf.image.decode_image(x)\r\n      t.set_shape((256, 256, 1))\r\n      return t\r\n\r\nThe `set_shape` is important here because otherwise the _runtime_ has no way of knowing the complete shape of the output tensor of `tf.map_fn`.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=28953\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=28953\">No</a>\n", "Thank you @saxenasaurabh.\r\n\r\nIt works using  `t.set_shape((256, 256, 1))` but the image dimensions are dynamic and read during runtime. So the following:\r\n\r\n```python\r\ndef decode_masks(feature):\r\n    \r\n    image_shape = tf.TensorShape([feature['size'], feature['size'], 1])\r\n    \r\n    def _decode_image_fn(encoded_image):\r\n        image = tf.image.decode_image(encoded_image)\r\n        image.set_shape(image_shape)\r\n        return image\r\n    \r\n    feature['masks_new'] = tf.map_fn(_decode_image_fn, feature['masks'], dtype=tf.uint8)\r\n    return feature\r\n```\r\n\r\nraises this error:\r\n\r\n```\r\n<ipython-input-25-46810f3be453> in decode_masks(feature)\r\n     23 def decode_masks(feature):\r\n     24 \r\n---> 25     image_shape = tf.TensorShape([feature['size'], feature['size'], 1])\r\n     26 \r\n     27     def _decode_image_fn(encoded_image):\r\n\r\n~/local/conda/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/tensor_shape.py in __init__(self, dims)\r\n    772       else:\r\n    773         # Got a list of dimensions\r\n--> 774         self._dims = [as_dimension(d) for d in dims_iter]\r\n    775 \r\n    776   @property\r\n\r\n~/local/conda/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/tensor_shape.py in <listcomp>(.0)\r\n    772       else:\r\n    773         # Got a list of dimensions\r\n--> 774         self._dims = [as_dimension(d) for d in dims_iter]\r\n    775 \r\n    776   @property\r\n\r\n~/local/conda/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/tensor_shape.py in as_dimension(value)\r\n    714     return value\r\n    715   else:\r\n--> 716     return Dimension(value)\r\n    717 \r\n    718 \r\n\r\n~/local/conda/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/tensor_shape.py in __init__(self, value)\r\n    183       raise TypeError(\"Cannot convert %s to Dimension\" % value)\r\n    184     else:\r\n--> 185       self._value = int(value)\r\n    186       if (not isinstance(value, compat.bytes_or_text_types) and\r\n    187           self._value != value):\r\n\r\nTypeError: int() argument must be a string, a bytes-like object or a number, not 'Tensor'\r\n```\r\n\r\nIs there is any workaround to resize from dynamic values? After all, my code was working well (without using the reshaping step). All I need is to make it work when `batch_size = 0`.", "@hadim  Did you find the solution to this problem ? It will be appreciated as I am facing the same ", "@hadim \r\n\r\nWere you able to resolve this error?\r\nI am facing a similar issue.\r\n\r\nThanks", "With BatchNormalization layers, I think batching with `dataset.batch(batch_size, drop_remainder=True)` might help"]}, {"number": 28952, "title": "feature_bin_count", "body": "train.py\u4e2d\u7684\u4e09\u4e2a\u53c2\u6570\r\nparser.add_argument(\r\n      '--window_size_ms',\r\n      type=float,\r\n      default=30.0,\r\n      help='How long each spectrogram timeslice is.',)\r\nparser.add_argument(\r\n      '--window_stride_ms',\r\n      type=float,\r\n      default=10.0,\r\n      help='How far to move in time between spectogram timeslices.',)\r\nparser.add_argument(\r\n      '--feature_bin_count',\r\n      type=int,\r\n      default=40,\r\n      help='How many bins to use for the MFCC fingerprint',\r\n  )\r\n\r\n\u662f \u4e0b\u9762\u7684\u610f\u601d\u5417\uff1f\uff1f\r\n1\u6bcf\u969430\u79d2\uff0c\u751f\u6210\u4e00\u4e2a40\u7ef4\u7684\u5411\u91cf\u3002\r\n2\u7a97\u53e3\u5411\u524d\u79fb\u52a810\u79d2\uff0c\u91cd\u590d1\u7684\u64cd\u4f5c\u3002", "comments": ["@yangjinghit Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\nMake sure you also include the exact command if possible to produce the output included in your test case. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!\r\n", "Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 28951, "title": "Added parameter `n` to DCT operation.", "body": "\r\n\r\nHello, \r\n\r\nThis PR closes issue #26074 and adds the optional argument `n` to the Discrete Cosine Transform Operation. While there are more than one ways to do this, I've done it in a fashion that adds minimal changes to the code and retains the original function as much as possible. \r\nPlease also find attached a demo [notebook](https://colab.research.google.com/drive/1BIGm4ACLT6Ndg_zPZokyO59CnX0wbUUQ) illustrating some test cases (ran locally on my test build) where I compare different dct operations with the `n` argument changing and compare it to `scipy.fftpack.dct()`. In all cases it matches the scipy outputs. \r\n\r\n", "comments": ["@alextp I was actually going to raise it as a separate PR because currently there is no `signal_ops_test.py`/`spectral_ops_test.py`, so I was planning to create one and add testing to all the other signal operations(fft, rfft, dft, dct etc) too. It will be a bigger PR so I wanted to first discuss before working on it. Let me know what you think! \r\n\r\nIn the meanwhile I added a test notebook and uploaded on Google Colab so that it can serve as a reference. ", "The tests are in\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/python/kernel_tests/signal\n\nOn Thu, May 23, 2019 at 10:37 AM Karthik Muthuraman <\nnotifications@github.com> wrote:\n\n> @alextp <https://github.com/alextp> I was actually going to raise it as a\n> separate PR because currently there is no signal_ops_test.py/\n> spectral_ops_test.py, so I was planning to create one and add testing to\n> all the other signal operations(fft, rfft, dft, dct etc) too. It will be a\n> bigger PR so I wanted to first discuss before working on it. Let me know\n> what you think!\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/28951?email_source=notifications&email_token=AAABHRJTVEAWMKDK4K7MDD3PW3I53A5CNFSM4HOZDV7KYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODWC5YWI#issuecomment-495311961>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAABHRPLDNYDOLYABBGCOMLPW3I53ANCNFSM4HOZDV7A>\n> .\n>\n\n\n-- \n - Alex\n", "@alextp Sorry, seem to have missed that! Will add the tests and update here. Thank you. ", "@alextp I've added `n` to the test cases. Also added a test for verifying the right error being raised for invalid `n`. ", "@alextp should I raise a separate PR similarly adding the argument for the IDCT operation? I didn't add it so far in this PR to keep features of different functions separate, let me know whatever works best!", "@alextp I fixed a couple of minor linting issues (whitespaces) which were failing the Ubuntu Sanity build, and it seems to have dismissed your review/approval.  "]}, {"number": 28950, "title": "Added examples and corrected a typo", "body": "Added examples and corrected a typo", "comments": ["Closing this PR as this not against `master`, please open a new PR against `master` \r\nCC @mihaimaruseac"]}, {"number": 28949, "title": "R1.14 Bug Fix", "body": "# https://github.com/tensorflow/tensorflow/issues/23756 \r\nThis pull request fixes documentation issues.\r\nNew URL: https://github.com/aaronhma/tensorflow-R14\r\n\r\nThis is my first pull request to Tensorflow.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F28949) for more info**.\n\n<!-- need_sender_cla -->", "I signed it!", "So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored or co-authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of all the commit author(s), set the `cla` label to `yes` (if enabled on your project), and then merge this pull request when appropriate.*\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F28949) for more info**.\n\n<!-- need_author_consent -->", "@aaronhma Your change list doesn't match your PR description. The description seems to indicate this is a simple documentation change, but your PR actually includes many commits and touches many files. Can you check whether this is correct?", "@aaronhma please check caisq@ comments and open a new PR, as this PR includes lot of commits , thanks for your contribution."]}, {"number": 28948, "title": "Updated Eigen breaks builds", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Fedora 30\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 2.0\r\n- Python version: 3.7\r\n- Installed using virtualenv? pip? conda?: source in virtualenv\r\n- Bazel version (if compiling from source): 0.25.2-1\r\n- GCC/Compiler version (if compiling from source): 9.1.1-1\r\n- CUDA/cuDNN version: 10.1\r\n\r\n**Describe the problem**\r\n\r\nmaster branch earlier today could compile fine, now it no longer can with the following error in many files:\r\n\r\n```\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/arch/GPU/Half.h(717): error: no suitable constructor exists to convert from \"float\" to \"Eigen::half\"\r\n```\r\n\r\nIt seems commit cf5687d4b3f66fecbab4ac35f89be0b9edac17eb may have caused this since it updated the Eigen version.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n```\r\nvirtualenv tensorflow\r\ncd tensorflow\r\n. bin/activate\r\npip install --upgrade --force-reinstall pip setuptools\r\npip install wheel numpy scipy keras\r\ngit clone https://github.com/tensorflow/tensorflow.git --single-branch --branch master\r\ncd tensorflow\r\n\r\n./configure\r\n# Use default values except:\r\n#   CUDA support: Y and TensorRT support: Y\r\n#   Only support compute capability 7.0 and not 6.1\r\n\r\nexport TMP=/tmp\r\nbazel build --jobs 15 -c opt --config=opt --config=v2 --config=mkl --config=numa \\\r\n    --copt=-march=native --cxxopt=-march=native --copt=-O3 --cxxopt=-O3 \\\r\n    //tensorflow/tools/pip_package:build_pip_package --verbose_failures\r\n```\r\n", "comments": ["It looks like commit 6b58886adedecdebfab069367f1cf78c893bab24 (which rolls back cf5687d4b3f66fecbab4ac35f89be0b9edac17eb) fixes the issue. I have gotten a lot further with compiling, including at least a few of the files that failed previously. Will update more upon compilation completion.\r\n\r\nAs a side note, the update of Eigen seemed to only effect CUDA-compiled code (.cu.cc files), but there were so many errors from it that I am not certain.", "@coderforlife Were you able to resolve the issue? Thanks!", "Building master after commit 6b58886adedecdebfab069367f1cf78c893bab24 worked fine.", "Closing this out since I understand it to be resolved, but please let me know if I'm mistaken. Thanks!"]}, {"number": 28947, "title": "Fix TF GPU build with Bazel 0.25.2", "body": "When I tried to upgrade Bazel to 0.25.2, the GPU build failed with Bazel 0.25.2 with the following error:\r\n\r\nexternal/grpc/src/core/tsi/alts/handshaker/handshaker.pb.c(118): error C2118: negative subscript\r\n\r\nThe reason is missing flags (/DPB_FIELD_32BIT=1 /DGRPC_ARES=0) when using the GPU toolchain. I compared cc_toolchain_config.bzl.tpl and Bazel's windows_cc_toolchain_config.bzl and found enable = True is missing for preprocessor_defines_feature\r\n\r\nPiperOrigin-RevId: 249444921", "comments": []}, {"number": 28946, "title": "Update doc.go", "body": "updated a link that was not working. \r\nThe issue is related to #28514", "comments": []}, {"number": 28945, "title": "CUDA GPU support for contrib static makefile build on Linux and possibly MacOS and Windows", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): v1.13.1\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nUsing contrib make file I can build static libraries on Windows and Linux\r\n\r\ngit clone https://github.com/tensorflow/tensorflow.git\r\ncd tensorflow\r\ngit checkout v1.13.1\r\n./configure #give details for CPU\r\nbazel build --opt config //tensorflow:libtensorflow_cc.so #setup up proto headers etc\r\n./tensorflow/contrib/makefile/build_all_linux.sh\r\nexport LD_LIBRARY_PATH=$PWD/tensorflow/contrib/makefile/gen/host-protobuf/lib\r\n./tensorflow/contrib/makefile/gen/bin/benchmark --help\r\n\r\n(The above works pretty well under OSX also)\r\n\r\nI can see in the Makefile there is some support for CUDA builds on the NVIDIA Tegra platform for Android.\r\n\r\nwould it be possible to make it create the .a file for CUDA linkage mentioned in the Tegra part of the build script?\r\n\r\n**Will this change the current api? How?**\r\nNo\r\n\r\n**Who will benefit with this feature?**\r\nPeople integrating Tensorflow who need static linkage AND GPU acceleration using C++ API.\r\n\r\nIf you are using Tensorflow as a plugin then the function init can only be called once\r\n\r\nsee\r\nhttps://stackoverflow.com/questions/43665674/what-is-the-purpose-of-tensorflowportinitmain\r\nhttps://github.com/tensorflow/tensorflow/issues/22810\r\nhttps://stackoverflow.com/questions/52683649/libtensorflow-cc-so-initialised-a-second-time-causes-segfault\r\n\r\nAllowing static linking overcomes this problem\r\n\r\n**Any Other info.**\r\nAlso see:\r\nhttps://github.com/tensorflow/tensorflow/issues/28388", "comments": ["I am having moderate success with the tensorflow/contrib/cmake project.\r\n\r\nThere is only a minor modification needed to the CMakelists.txt as the cudnn static is not available for OSX and it is called cudnn.dylib.7 rather than cudnn.so", "The success was shortlived, the dnn.proto is not accounted for in the contrib CMake, not is the absl/containers/flatbuffer...\r\n\r\nThis experience was after getting the CMake file to run succefully on MacOS to find CUDNN, CUDA CUPTI etc", "I am continuing on CentOS 7.4 to see if I can get a build done, the configuration via CMake 3.7.2 on CentOS 6.10 was successful but the build was lacking the ability to pull down dependency packages.", "Adding related issue\r\nhttps://github.com/tensorflow/tensorflow/issues/29042", "I think we should close this as makefile build is no longer supported"]}, {"number": 28944, "title": "Link for migrating from deprecated DNNLinearCombinedRegressor is broken", "body": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/learn/python/learn/estimators/dnn_linear_combined.py#L849\r\n\r\n## Description of issue (what needs changing):\r\n\r\nLink is broken. Why is it deprecated? What should I do about it?", "comments": ["Perhaps this is the link you are looking for,\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/learn\r\nIt covers the migration instructions. Thanks!", "Ok, that works! The link in the docstring is still broken, so other people may encounter the same problem, but thanks."]}, {"number": 28943, "title": "Two more cherrypicks", "body": "", "comments": []}, {"number": 28942, "title": "Missing Op DenseToDenseSetOperation in contrib makefile static build", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux el6 and MacOS 10.13\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: na\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: v1.13.1\r\n- Python version: na\r\n- Installed using virtualenv? pip?  na\r\n- Bazel version (if compiling from source): 19.1\r\n- GCC/Compiler version (if compiling from source): clang Xcode 9.4 and gcc 4.8.5\r\n- CUDA/cuDNN version: na yet\r\n- GPU model and memory: na yet\r\n\r\n\r\n\r\n**Describe the problem**\r\nWith one of models derived from Materport RCNN\r\n\r\nI get the following error during inference in C++ which doesn\u2019t happen with dynamic linking to the bazel targets libtensorflow_cc.so and libtensorflow_framework.so\r\n\r\nERROR: Op type not registered 'DenseToDenseSetOperation' in binary running on creative2. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) tf.contrib.resampler should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\r\n\r\nCreative2 is the clients machine name\r\n\r\nHaving a quick GitHub search it seems this op is a thing\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/9590c4c32dd4346ea5c35673336f5912c6072bf2/tensorflow/core/ops/set_ops.cc\r\n\r\nSo given that it is there in core I don\u2019t know what to do to make sure it is initialised it is in the dynamic version of the same software\r\n\r\nSam\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nBuild Tensorflow makefile contrib to build libtensorflow_core.a nsync.a and libprotobuf.a\r\n\r\nLink load a model with the above mentioned Op\r\n\r\nThis doesn\u2019t happen with libtensorflow_framework.so and libtensorflow_cc.so and identical inference code and model.\r\n\r\n**Any other info / logs**\r\n", "comments": ["I noticed this in the docs\r\n\r\nThe most common cause of breakages are files that have been added to the Bazel build scripts, but that the makefile isn't aware of. Typical symptoms of this include linker errors mentioning missing symbols or protobuf headers that aren't found. To address these problems, take a look at the *.txt files in tensorflow/contrib/makefile. If you have a new operator, you may need to add it to tf_op_files.txt, or for a new proto to tf_proto_files.txt.\r\n\r\nI will check this and see if it resolves the issue.", "booya!\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/v1.13.1/tensorflow/contrib/makefile/tf_op_files.txt\r\n\r\ndoesnt contain \r\ntensorflow/core/ops/set_ops.cc\r\n\r\nProblem solved by @samhodge \r\n\r\nSorry for the traffic.", "Dear @samhodge ,\r\nI have the same issue with Missing Op DenseToDenseSetOperation when loading a network started from matterport MaskRCNN. I followed your response:\r\n\r\n> booya!\r\n> \r\n> https://github.com/tensorflow/tensorflow/blob/v1.13.1/tensorflow/contrib/makefile/tf_op_files.txt\r\n> \r\n> doesnt contain\r\n> tensorflow/core/ops/set_ops.cc\r\n> \r\n> Problem solved by @samhodge\r\n> \r\n> Sorry for the traffic.\r\n\r\nbut the error is still there. More specifically, I just added the file tensorflow/core/set_ops.cc at the end  tf_op_files.txt and recompiled using basel, by running build_all_ios.sh . Am I missing something?\r\nThank you! \r\n\r\n**EDIT**:\r\nI succeeded to run the matterport graph, in the following way: \r\n\r\nAs @samhodge said, I add \"tensorflow/core/ops/set_ops.cc\" to tf_op_files.txt file.\r\n\r\nI follow the tutorial to build the Tensorflow (branch r1.13):\r\nhttps://medium.com/@vvalouch/how-to-build-custom-tensorflow-binary-for-android-and-ios-29d107690af9\r\n\r\nBefore I run build_all_ios.sh, I add the following line to the core/framework/ops_to_register.h (because I have the same problem with the Gather operation):\r\n`    || isequal(op, \"Gather\")`\r\n\r\nIn plus, I modified the script _build_all_ios.sh_ to make sure we set the flag ANDROID_TYPES to -D__ANDROID_TYPES_FULL__, by extracting this line out of the if statement.\r\n`export ANDROID_TYPES=\"-D__ANDROID_TYPES_FULL__\".`\r\nI did this because I didn't set the -g <path to graph.pb> flag, to make sure that the ops_to_register.h file is not overwritten.\r\n\r\nI also include the following file, before loading the graph:\r\n`#include \"tensorflow/core/kernels/set_kernels.cc\"`\r\n\r\n\r\n\r\n\r\n\r\n"]}, {"number": 28941, "title": "Can't use padded_batch on dataset with distributed strategy make_dataset_iterator", "body": "I can't use padded_batch when I'm trying to create a distributed iterator using the following code.\r\n\r\n```\r\nimport tensorflow_datasets as tfds\r\nimport tensorflow as tf\r\n\r\ntf.enable_v2_behavior()\r\n\r\nstrategy = tf.distribute.MirroredStrategy()\r\n\r\ndef encode(lang1, lang2):\r\n    lang1 = [tokenizer_pt.vocab_size] + tokenizer_pt.encode(\r\n        lang1.numpy()) + [tokenizer_pt.vocab_size+1]\r\n\r\n    lang2 = [tokenizer_en.vocab_size] + tokenizer_en.encode(\r\n        lang2.numpy()) + [tokenizer_en.vocab_size+1]\r\n\r\n    return lang1, lang2\r\n\r\ndef tf_encode(pt, en):\r\n    return tf.py_function(encode, [pt, en], [tf.int64, tf.int64])\r\n\r\nwith strategy.scope():\r\n    examples, metadata = tfds.load('ted_hrlr_translate/pt_to_en', with_info=True, as_supervised=True)\r\n    train_examples, test_examples = examples['train'], examples['test']\r\n\r\n    tokenizer_en = tfds.features.text.SubwordTextEncoder.build_from_corpus((en.numpy() for pt, en in train_examples), target_vocab_size=10000)\r\n\r\n    tokenizer_pt = tfds.features.text.SubwordTextEncoder.build_from_corpus((pt.numpy() for pt, en in train_examples), target_vocab_size=10000)\r\n\r\n    train_dataset = train_examples.map(tf_encode)\r\n    train_dataset = train_dataset.shuffle(200000)\r\n    train_dataset = train_dataset.padded_batch(64, padded_shapes=([-1], [-1]))\r\n    train_dataset = strategy.make_dataset_iterator(train_dataset)\r\n```\r\n\r\nIt throws this exception:\r\n\r\n```\r\nValueError: Unable to get batched dataset from the input dataset. `batch` `map_and_batch` need to be the last operations on the dataset. The batch operations can be followed by a prefetch.\r\n```\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (use command below): 1.13\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: CUDA 10.0/CuDNN 7.3.1\r\n- GPU model and memory: Nvidia Titan V\r\n", "comments": ["I was able to get the mentioned error when tried on Colab with TensorFlow GPU version 1.13.", "`padded_batch` should be supported. Can you try updating your TensorFlow version to 1.14 and try again?", "@anj-s I confirm that the issue is fixed on 1.14. Thank you.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=28941\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=28941\">No</a>\n"]}, {"number": 28940, "title": "Misleading \"Not built with GPU enabled. Skip GPU library dlopen check.\" message when using GPU 2.0 nightly build", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No \r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04 x86\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): pip install tf-nightly-gpu-2.0-preview==2.0.0.dev20190521\r\n- TensorFlow version (use command below): ('v1.12.1-2420-g4fd6e533f6', '2.0.0-dev20190521')\r\n- Python version:  2.7\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: 10.0 / 7\r\n- GPU model and memory: P100 16 GB\r\n\r\n**Describe the current behavior**\r\n\r\nTensorFlow compiled with GPU support prints the misleading message:\r\n```\r\nI tensorflow/stream_executor/platform/default/dlopen_checker.cc:62] Not built with GPU enabled. Skip GPU library dlopen check.\r\n```\r\n\r\nThis confuses the user into believe GPU is not working (or at least not fully working), when it really is.\r\n\r\n**Describe the expected behavior**\r\n\r\nThe message should not be printed when built with GPU support, or should be worded better.\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n```\r\npip install tf-nightly-gpu-2.0-preview==2.0.0.dev20190521\r\npython\r\nimport tensorflow as tf\r\ninput_string = 'Hello, TensorFlow!'\r\nhello = tf.constant(input_string)\r\n```\r\n\r\n**Other info / logs**\r\n```\r\nroot@f2ce3e981b16:~# python\r\nPython 2.7.15rc1 (default, Nov 12 2018, 14:31:15)\r\n[GCC 7.3.0] on linux2\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\n>>> input_string = 'Hello, TensorFlow!'\r\n>>> hello = tf.constant(input_string)\r\n2019-05-22 18:10:31.116739: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\r\n2019-05-22 18:10:31.936204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties:\r\nname: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\r\npciBusID: 0000:06:00.0\r\n2019-05-22 18:10:31.937373: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 1 with properties:\r\nname: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\r\npciBusID: 0000:81:00.0\r\n2019-05-22 18:10:31.937394: I tensorflow/stream_executor/platform/default/dlopen_checker.cc:62] Not built with GPU enabled. Skip GPU library dlopen check.\r\n2019-05-22 18:10:31.942721: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0, 1\r\n2019-05-22 18:10:31.944135: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2019-05-22 18:10:32.163526: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5611c578aac0 executing computations on platform CUDA. Devices:\r\n2019-05-22 18:10:32.163568: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\r\n2019-05-22 18:10:32.163580: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (1): Tesla P100-PCIE-16GB, Compute Capability 6.0\r\n2019-05-22 18:10:32.167321: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199905000 Hz\r\n2019-05-22 18:10:32.171784: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5611c5bc4df0 executing computations on platform Host. Devices:\r\n2019-05-22 18:10:32.171814: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\r\n2019-05-22 18:10:32.173360: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties:\r\nname: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\r\npciBusID: 0000:06:00.0\r\n2019-05-22 18:10:32.174698: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 1 with properties:\r\nname: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\r\npciBusID: 0000:81:00.0\r\n2019-05-22 18:10:32.174718: I tensorflow/stream_executor/platform/default/dlopen_checker.cc:62] Not built with GPU enabled. Skip GPU library dlopen check.\r\n2019-05-22 18:10:32.179748: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0, 1\r\n2019-05-22 18:10:32.180155: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\r\n2019-05-22 18:10:32.183049: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-05-22 18:10:32.183069: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 1\r\n2019-05-22 18:10:32.183083: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N N\r\n2019-05-22 18:10:32.183093: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 1:   N N\r\n2019-05-22 18:10:32.189364: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:06:00.0, compute capability: 6.0)\r\n2019-05-22 18:10:32.191715: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 15216 MB memory) -> physical GPU (device: 1, name: Tesla P100-PCIE-16GB, pci bus id: 0000:81:00.0, compute capability: 6.0)\r\n```\r\n", "comments": ["@yifeif , this message was added in this commit:\r\nhttps://github.com/tensorflow/tensorflow/commit/fcfb99bc3aa3110feae5233dbe4634bffa70dc59\r\n\r\nIs the #if GOOGLE_CUDA variable not getting set correctly ?", "Thanks @wdirons! I also noticed this and it should be fixed in https://github.com/tensorflow/tensorflow/commit/eae5d0bc15bf8bdb7635a9692fb19d747352a445. \r\nCould you give the latest tf-nightly-gpu a try?\r\n", "I verified this fix with `pip install tf-nightly-gpu-2.0-preview==2.0.0.dev20190523`\r\n\r\nThank you @yifeif!", "Hi @wdirons. Thanks for your solution. You save my life. I can run cuda and cublas now.\r\n\r\nby using \ud83d\udc4d \r\npip install tf-nightly-gpu-2.0-preview==2.0.0.dev20191002\r\n!!"]}, {"number": 28939, "title": "TypeError in RNNs tutorial", "body": "\r\n## URL(s) with the issue:\r\nhttps://www.tensorflow.org/tutorials/keras/basic_regression\r\n#### Description of issue (what needs changing): https://www.tensorflow.org/tutorials/keras/basic_regression#build_the_model\r\n\r\n### Clear description\r\n\r\nThe `model = build_model()` function results in a `TypeError` and gives the following trace:\r\n```\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-19-671884cecb64> in <module>\r\n----> 1 model = build_model()\r\n\r\n<ipython-input-18-d3556ed39f80> in build_model()\r\n      3     layers.Dense(64, activation=tf.nn.relu, input_shape=[64]),\r\n      4     layers.Dense(64, activation=tf.nn.relu),\r\n----> 5     layers.Dense(1)\r\n      6   ])\r\n      7 \r\n\r\n~/anaconda3/lib/python3.7/site-packages/keras/engine/sequential.py in __init__(self, layers, name)\r\n     91         if layers:\r\n     92             for layer in layers:\r\n---> 93                 self.add(layer)\r\n     94 \r\n     95     @property\r\n\r\n~/anaconda3/lib/python3.7/site-packages/keras/engine/sequential.py in add(self, layer)\r\n    130             raise TypeError('The added layer must be '\r\n    131                             'an instance of class Layer. '\r\n--> 132                             'Found: ' + str(layer))\r\n    133         self.built = False\r\n    134         if not self._layers:\r\n\r\nTypeError: The added layer must be an instance of class Layer. Found: <tensorflow.python.keras.layers.core.Dense object at 0x7efe86908f28>\r\n\r\n\r\n```\r\n\r\n\r\n\r\n\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly? <br>\r\nYes. This method does not use any parameters apart from `train_dataset` which has been replaced with a constant in my above example.\r\n\r\n\r\n\r\n### Raises listed and defined\r\n\r\nThis raises a TypeError.\r\n\r\n\r\n\r\n\r\n\r\n\r\n", "comments": ["@chennakeshava1998 I ran the tutorial without any issues. Here is the [gist](https://colab.sandbox.google.com/gist/jvishnuvardhan/138d0e438232934cd0c7b759ca411923/basic_regression.ipynb). Can you create a gist or share code to reproduce the issue? Thanks!", "Here is the gist of a reduced version of the tutorial. I am using it for a different application, so I only needed the model creation parts. Gist: https://gist.github.com/chennakeshava1998/e38e8da0a6adf0640d8b5640095f3b83\r\n\r\nThe only change I have made is in specifying the input dimension to the RNN. I have used a constant of [64] instead of the length of an array.\r\n\r\n", "@chennakeshava1998 [Here](https://colab.sandbox.google.com/gist/jvishnuvardhan/7b883cfc17e36c39676e268d1e94b3a3/baseline.ipynb) is the working version. `keras.Sequential` and  `tensorflow.keras.Sequential` are different where one is implemented inside other framework. When model was built entirely on tensorflow framework there is no issue. Thanks!\r\n\r\nI am closing this issue. Thanks!", "okay, thanks a lot!\r\n\r\n"]}, {"number": 28938, "title": "Is there any difference in mAP from fronzen graph to .tflite model?", "body": "I'm running android example following this [artichle](https://medium.com/tensorflow/training-and-serving-a-realtime-mobile-object-detector-in-30-minutes-with-cloud-tpus-b78971cf1193) from tensorflow. On it, the author talk about the mAP while the training is running. The mAP[0.5] it's equals to 82%. Then, next in the article, the model is transformed to .tflite, but he do not talk about mAP or any difference on this value. Can any one tell me if there is any change or some documentation that can help me on that? Thanks!", "comments": ["The mAP should remain the same, since the model was trained with quantization-aware training. Typically, accuracies fall a bit with [post-training quantization](https://www.tensorflow.org/lite/performance/post_training_quantization), but not vanilla conversion to TFLite.", "Thanks for answer me, @srjoglekar246 ! Do you have any documentation that comprove it? Sorry if its sound that i don't trust you rs, i just need a better explanation", "Its basically a function of how the [TFLite converter](https://www.tensorflow.org/lite/convert) works. For conversion that doesn't employ post-training quantization, we simply copy over the weights from the original TF graph. You could probably dig around the [converter code](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/toco) to see how it works.", "I see! Thank you again"]}, {"number": 28937, "title": "C++17 features used even though C++11 standard explicitly given", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Fedora 30\r\n- TensorFlow installed from (source or binary): source, master branch (c156831c298e27ce4d058c6ab03ec61bc6e910bf)\r\n- TensorFlow version: 2.0\r\n- Python version: 3.7\r\n- Installed using virtualenv? pip? conda?: building in virtualenv\r\n- Bazel version (if compiling from source): 0.25.2-1\r\n- GCC/Compiler version (if compiling from source): 9.1.1-1\r\n- CUDA/cuDNN version: 10.1.168\r\n- GPU model and memory: (unimportant)\r\n\r\n**Describe the problem**\r\n\r\nBuilding error messages about use of C++17 features but the `-std=c++17` is not being passed to GCC (even if I do `--copt=-std=c++17` for the `bazel` command). Temporary workaround was to change that `constexpr` to `const` however I cannot be certain that actually worked since I have not successfully built yet due to other errors.\r\n\r\n```\r\nERROR: /home/x/tf/tensorflow/tensorflow/tensorflow/compiler/tf2tensorrt/BUILD:330:1: C++ compilation of rule '//tensorflow/compiler/tf2tensorrt:trt_conversion' failed (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command \r\n  (cd /home/x/.cache/bazel/_bazel_x/5f286644534b1c99abf8273939acd3e7/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    LD_LIBRARY_PATH=/usr/local/cuda/lib64:/opt/intel/mkl/lib/intel64:/usr/local/cuda/lib64:/opt/intel/mkl/lib/intel64 \\\r\n    PATH=/usr/local/cuda/bin:/home/x/.npm-packages/bin:/usr/local/cuda/bin:/home/x/.npm-packages/bin:/home/x/.local/bin:/home/x/bin:/usr/lib64/ccache:/usr/local/bin:/usr/bin:/bin:/usr/local/sbin:/usr/sbin \\\r\n    PWD=/proc/self/cwd \\\r\n  external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -MD -MF bazel-out/host/bin/tensorflow/compiler/tf2tensorrt/_objs/trt_conversion/convert_nodes.pic.d '-frandom-seed=bazel-out/host/bin/tensorflow/compiler/tf2tensorrt/_objs/trt_conversion/convert_nodes.pic.o' -D__CLANG_SUPPORT_DYN_ANNOTATION__ -DEIGEN_MPL2_ONLY '-DEIGEN_MAX_ALIGN_BYTES=64' '-DEIGEN_HAS_TYPE_TRAITS=0' -DTF_USE_SNAPPY -DTENSORFLOW_USE_NUMA -iquote . -iquote bazel-out/host/bin -iquote external/com_google_absl -iquote bazel-out/host/bin/external/com_google_absl -iquote external/eigen_archive -iquote bazel-out/host/bin/external/eigen_archive -iquote external/local_config_sycl -iquote bazel-out/host/bin/external/local_config_sycl -iquote external/nsync -iquote bazel-out/host/bin/external/nsync -iquote external/gif_archive -iquote bazel-out/host/bin/external/gif_archive -iquote external/jpeg -iquote bazel-out/host/bin/external/jpeg -iquote external/protobuf_archive -iquote bazel-out/host/bin/external/protobuf_archive -iquote external/com_googlesource_code_re2 -iquote bazel-out/host/bin/external/com_googlesource_code_re2 -iquote external/farmhash_archive -iquote bazel-out/host/bin/external/farmhash_archive -iquote external/fft2d -iquote bazel-out/host/bin/external/fft2d -iquote external/highwayhash -iquote bazel-out/host/bin/external/highwayhash -iquote external/zlib_archive -iquote bazel-out/host/bin/external/zlib_archive -iquote external/local_config_cuda -iquote bazel-out/host/bin/external/local_config_cuda -iquote external/double_conversion -iquote bazel-out/host/bin/external/double_conversion -iquote external/local_config_tensorrt -iquote bazel-out/host/bin/external/local_config_tensorrt -Ibazel-out/host/bin/external/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual -Ibazel-out/host/bin/external/local_config_tensorrt/_virtual_includes/tensorrt_headers -Ibazel-out/host/bin/external/local_config_cuda/cuda/_virtual_includes/cudnn_header -isystem third_party/eigen3/mkl_include -isystem bazel-out/host/bin/third_party/eigen3/mkl_include -isystem external/eigen_archive -isystem bazel-out/host/bin/external/eigen_archive -isystem external/nsync/public -isystem bazel-out/host/bin/external/nsync/public -isystem external/gif_archive/lib -isystem bazel-out/host/bin/external/gif_archive/lib -isystem external/protobuf_archive/src -isystem bazel-out/host/bin/external/protobuf_archive/src -isystem external/farmhash_archive/src -isystem bazel-out/host/bin/external/farmhash_archive/src -isystem external/zlib_archive -isystem bazel-out/host/bin/external/zlib_archive -isystem external/local_config_cuda/cuda -isystem bazel-out/host/bin/external/local_config_cuda/cuda -isystem external/local_config_cuda/cuda/cuda/include -isystem bazel-out/host/bin/external/local_config_cuda/cuda/cuda/include -isystem external/double_conversion -isystem bazel-out/host/bin/external/double_conversion '-std=c++11' -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -fPIC -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -fno-omit-frame-pointer -no-canonical-prefixes -fno-canonical-system-headers -DNDEBUG -g0 -O2 -ffunction-sections -fdata-sections -g0 '-march=native' -g0 -DEIGEN_AVOID_STL_ARRAY -Iexternal/gemmlowp -Wno-sign-compare -fno-exceptions '-ftemplate-depth=900' '-DGOOGLE_CUDA=1' '-DGOOGLE_TENSORRT=1' '-DINTEL_MKL=1' -DEIGEN_USE_VML -DENABLE_MKL -fopenmp -msse3 -pthread '-DGOOGLE_CUDA=1' '-DINTEL_MKL=1' -DENABLE_MKL '-DGOOGLE_TENSORRT=1' -c tensorflow/compiler/tf2tensorrt/convert/convert_nodes.cc -o bazel-out/host/bin/tensorflow/compiler/tf2tensorrt/_objs/trt_conversion/convert_nodes.pic.o)\r\nExecution platform: @bazel_tools//platforms:host_platform\r\ntensorflow/compiler/tf2tensorrt/convert/convert_nodes.cc: In function 'tensorflow::Status tensorflow::tensorrt::convert::ConvertMatMulHelper(tensorflow::tensorrt::convert::OpConverterParams*, tensorflow::tensorrt::convert::TRT_TensorOrWeights, tensorflow::tensorrt::convert::TRT_TensorOrWeights, bool, bool, std::string)':\r\ntensorflow/compiler/tf2tensorrt/convert/convert_nodes.cc:4198:18: error: the type 'const tensorflow::tensorrt::convert::ConvertMatMulHelper(tensorflow::tensorrt::convert::OpConverterParams*, tensorflow::tensorrt::convert::TRT_TensorOrWeights, tensorflow::tensorrt::convert::TRT_TensorOrWeights, bool, bool, std::string)::<lambda(nvinfer1::ITensor*, bool)>' of 'constexpr' variable 'get_matrix_op' is not literal\r\n 4198 |   constexpr auto get_matrix_op =\r\n      |                  ^~~~~~~~~~~~~\r\ntensorflow/compiler/tf2tensorrt/convert/convert_nodes.cc:4199:8: note: 'tensorflow::tensorrt::convert::ConvertMatMulHelper(tensorflow::tensorrt::convert::OpConverterParams*, tensorflow::tensorrt::convert::TRT_TensorOrWeights, tensorflow::tensorrt::convert::TRT_TensorOrWeights, bool, bool, std::string)::<lambda(nvinfer1::ITensor*, bool)>' is not literal because:\r\n 4199 |       [](nvinfer1::ITensor* in, bool transpose) -> nvinfer1::MatrixOperation {\r\n      |        ^\r\ncc1plus: note:   'tensorflow::tensorrt::convert::ConvertMatMulHelper(tensorflow::tensorrt::convert::OpConverterParams*, tensorflow::tensorrt::convert::TRT_TensorOrWeights, tensorflow::tensorrt::convert::TRT_TensorOrWeights, bool, bool, std::string)::<lambda(nvinfer1::ITensor*, bool)>' is a closure type, which is only literal in C++17 and later\r\ntensorflow/compiler/tf2tensorrt/convert/convert_nodes.cc: At global scope:\r\ntensorflow/compiler/tf2tensorrt/convert/convert_nodes.cc:637:41: warning: 'std::vector<std::pair<int, int> > tensorflow::tensorrt::convert::CreateSamePadding(const nvinfer1::DimsHW&, const nvinfer1::DimsHW&, const std::vector<long int>&)' defined but not used [-Wunused-function]\r\n  637 | static std::vector<std::pair<int, int>> CreateSamePadding(\r\n      |                                         ^~~~~~~~~~~~~~~~~\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\n```\r\n\r\nThe command line explicitly contains `'-std=c++11'` but GCC says that the feature used cannot be used without `'-std=c++17'`.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n```\r\nsudo dnf install @development-tools @\"C Development Tools and Libraries\" dnf-plugins-core cmake xz wget llvm clang python3-devel openssl-devel zlib-devel bzip2-devel readline-devel sqlite-devel ncurses-devel tk-devel libnccl-devel libcudnn7-devel libnvinfer-devel\r\nvirtualenv tensorflow\r\ncd tensorflow\r\n. bin/activate\r\npip install --upgrade --force-reinstall pip setuptools\r\npip install wheel numpy scipy keras\r\ngit clone https://github.com/tensorflow/tensorflow.git --single-branch --branch master\r\ncd tensorflow\r\n./configure # all defaults except Y for CUDA and TensorRT support and 7.0 for compute support\r\nexport TMP=/tmp\r\nbazel build -c opt --config=opt --config=v2 --config=mkl --config=numa --verbose_failures \\\r\n    //tensorflow/tools/pip_package:build_pip_package\r\n```\r\n\r\nSome other arguments tried with `bazel` are `--copt=-std=c++17` (didn't fix problem \\#1 and caused other issues) and `--verbose_failures` to get longer messages.", "comments": ["Did you try building from [TensorFlow website](https://www.tensorflow.org/install/source). Also TensorFlow versions above 1.13.0 support CUDA 10.0 and bazel 0.24.1. Let us know if that helps to build the TensorFlow successfully. Thanks!", "No I didn't. Using a different version of bazel and CUDA is extremely unlikely to have an impact on the result since bazel would still pass the `-std=c++11` command line but the feature in your code (not CUDA's code) is a C++17 feature.\r\n\r\nThe more likely reason is that GCC 9 was being used to compile it is likely stricter on the use of C++17 features in C++11 code unlike GCC 8.\r\n\r\nI can give you the patch that simply changes `constexpr` to `const` which causes the entire code base to compile with GCC 9 and apparently still function correctly. Just trying to give you an extremely small change to make your code more compatible with newer versions of GCC and more consistent with the C++ standard you claim to be using.", "@coderforlife Thanks for filing the issue, and sorry for the delay.\r\nI have recently saw a few other cases where we violate our rule to restrict ourselves to C++11.\r\nWe would be happy to accept your patch.", "I hope this patch still works. But should be easy to re-make though, it's a one-word-change.\r\n\r\n```\r\ndiff --git a/tensorflow/compiler/tf2tensorrt/convert/convert_nodes.cc b/tensorflow/compiler/tf2tensorrt/convert/convert_nodes.cc\r\nindex 6cb09cb122..4aac41cd0b 100644\r\n--- a/tensorflow/compiler/tf2tensorrt/convert/convert_nodes.cc\r\n+++ b/tensorflow/compiler/tf2tensorrt/convert/convert_nodes.cc\r\n@@ -4195,7 +4195,7 @@ Status ConvertMatMulHelper(OpConverterParams* params,\r\n         params, input_a.tensor(), input_b.weights(), transpose_b, node_name);\r\n   }\r\n \r\n-  constexpr auto get_matrix_op =\r\n+  const/*expr*/ auto get_matrix_op =\r\n       [](nvinfer1::ITensor* in, bool transpose) -> nvinfer1::MatrixOperation {\r\n     return (in->getDimensions().nbDims < 2)\r\n                ? nvinfer1::MatrixOperation::kVECTOR\r\n```", "@coderforlife sorry for the late response. Please feel free to file a PR and I can review that.", "@coderforlife We are checking to see if you still need help on this issue. We recommend that you upgrade to 2.6 which is latest stable version of TF and let us know if the issue still persists in newer versions. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/28937\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/28937\">No</a>\n"]}, {"number": 28936, "title": "CUDA 10.1 Support (continued)", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Fedora 30\r\n- TensorFlow installed from (source or binary): source, master branch (c156831c298e27ce4d058c6ab03ec61bc6e910bf)\r\n- TensorFlow version: 2.0\r\n- Python version: 3.7\r\n- Installed using virtualenv? pip? conda?: building in virtualenv\r\n- Bazel version (if compiling from source): 0.25.2-1\r\n- GCC/Compiler version (if compiling from source): 9.1.1-1\r\n- CUDA/cuDNN version: 10.1.168\r\n- GPU model and memory: (unimportant)\r\n\r\n**Describe the problem**\r\n\r\nI can see that lots of progress has been made on CUDA 10.1 support recently however there still seem to be a few problems:\r\n\r\n1. libcublas.so.10 is not in the expected location. This is known and some recently fixes have corrected the issue during the configuration phase however during the actual build process there is still an error:\r\n\r\n```\r\n  /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; cp -f \"/usr/local/cuda/lib64/stubs/libcuda.so\" \"bazel-out/host/bin/external/local_config_cuda/cuda/cuda/lib/libcuda.so\" && cp -f \"/usr/local/cuda/lib64/libcudart.so.10.1\" \"bazel-out/host/bin/external/local_config_cuda/cuda/cuda/lib/libcudart.so.10.1\" && cp -f \"/usr/local/cuda/lib64/libcudart_static.a\" \"bazel-out/host/bin/external/local_config_cuda/cuda/cuda/lib/libcudart_static.a\" && cp -f \"/usr/local/cuda/lib64/libcublas.so.10\" \"bazel-out/host/bin/external/local_config_cuda/cuda/cuda/lib/libcublas.so.10\" && cp -f \"/usr/local/cuda/lib64/libcusolver.so.10\" \"bazel-out/host/bin/external/local_config_cuda/cuda/cuda/lib/libcusolver.so.10\" && cp -f \"/usr/local/cuda/lib64/libcurand.so.10\" \"bazel-out/host/bin/external/local_config_cuda/cuda/cuda/lib/libcurand.so.10\" && cp -f \"/usr/local/cuda/lib64/libcufft.so.10\" \"bazel-out/host/bin/external/local_config_cuda/cuda/cuda/lib/libcufft.so.10\" && cp -f \"/usr/lib64/libcudnn.so.7\" \"bazel-out/host/bin/external/local_config_cuda/cuda/cuda/lib/libcudnn.so.7\" && cp -f \"/usr/local/cuda/extras/CUPTI/lib64/libcupti.so.10.1\" \"bazel-out/host/bin/external/local_config_cuda/cuda/cuda/lib/libcupti.so.10.1\" && cp -f \"/usr/local/cuda/lib64/libcusparse.so.10\" \"bazel-out/host/bin/external/local_config_cuda/cuda/cuda/lib/libcusparse.so.10\" ')\r\nExecution platform: @bazel_tools//platforms:host_platform\r\ncp: cannot stat '/usr/local/cuda/lib64/libcublas.so.10': No such file or directory\r\n```\r\n\r\nWorkaround is as per #26150:\r\n\r\n```\r\nsudo ln -s /usr/lib64/libcublas.so.10 /usr/local/cuda-10.1/targets/x86_64-linux/lib/libcublas.so.10\r\n```\r\n\r\n2. The header files are also not being dealt with as is indicated in commit 922386b9fcc23596877da3500787a045a861cb52. They are supposed to be copied to \"cublas/include/cublas*.h\" (and then referenced as \"third_party/gpus/cuda/include/cublas*.h\"). However, when the following error occurs the copied files are nowhere to be found anywhere in the build tree. My guess is that the copy tasks are not marked as prereqs of some of the tasks that use the copied files. Example error messages:\r\n\r\n```\r\nERROR: /home/x/tf/tensorflow/tensorflow/tensorflow/core/kernels/BUILD:3135:1: C++ compilation of rule '//tensorflow/core/kernels:cuda_solvers' failed (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command \r\n  (cd /home/x/.cache/bazel/_bazel_x/5f286644534b1c99abf8273939acd3e7/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    LD_LIBRARY_PATH=/usr/local/cuda/lib64:/opt/intel/mkl/lib/intel64:/usr/local/cuda/lib64:/opt/intel/mkl/lib/intel64 \\\r\n    PATH=/usr/local/cuda/bin:/home/x/.npm-packages/bin:/usr/local/cuda/bin:/home/x/.npm-packages/bin:/home/x/.local/bin:/home/x/bin:/usr/lib64/ccache:/usr/local/bin:/usr/bin:/bin:/usr/local/sbin:/usr/sbin \\\r\n    PWD=/proc/self/cwd \\\r\n  external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -MD -MF bazel-out/host/bin/tensorflow/core/kernels/_objs/cuda_solvers/cuda_solvers.pic.d '-frandom-seed=bazel-out/host/bin/tensorflow/core/kernels/_objs/cuda_solvers/cuda_solvers.pic.o' -D__CLANG_SUPPORT_DYN_ANNOTATION__ -DEIGEN_MPL2_ONLY '-DEIGEN_MAX_ALIGN_BYTES=64' '-DEIGEN_HAS_TYPE_TRAITS=0' -DTF_USE_SNAPPY -DTENSORFLOW_USE_NUMA -iquote . -iquote bazel-out/host/bin -iquote external/com_google_absl -iquote bazel-out/host/bin/external/com_google_absl -iquote external/eigen_archive -iquote bazel-out/host/bin/external/eigen_archive -iquote external/local_config_sycl -iquote bazel-out/host/bin/external/local_config_sycl -iquote external/nsync -iquote bazel-out/host/bin/external/nsync -iquote external/gif_archive -iquote bazel-out/host/bin/external/gif_archive -iquote external/jpeg -iquote bazel-out/host/bin/external/jpeg -iquote external/protobuf_archive -iquote bazel-out/host/bin/external/protobuf_archive -iquote external/com_googlesource_code_re2 -iquote bazel-out/host/bin/external/com_googlesource_code_re2 -iquote external/farmhash_archive -iquote bazel-out/host/bin/external/farmhash_archive -iquote external/fft2d -iquote bazel-out/host/bin/external/fft2d -iquote external/highwayhash -iquote bazel-out/host/bin/external/highwayhash -iquote external/zlib_archive -iquote bazel-out/host/bin/external/zlib_archive -iquote external/local_config_cuda -iquote bazel-out/host/bin/external/local_config_cuda -Ibazel-out/host/bin/external/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual -isystem third_party/eigen3/mkl_include -isystem bazel-out/host/bin/third_party/eigen3/mkl_include -isystem external/eigen_archive -isystem bazel-out/host/bin/external/eigen_archive -isystem external/nsync/public -isystem bazel-out/host/bin/external/nsync/public -isystem external/gif_archive/lib -isystem bazel-out/host/bin/external/gif_archive/lib -isystem external/protobuf_archive/src -isystem bazel-out/host/bin/external/protobuf_archive/src -isystem external/farmhash_archive/src -isystem bazel-out/host/bin/external/farmhash_archive/src -isystem external/zlib_archive -isystem bazel-out/host/bin/external/zlib_archive -isystem external/local_config_cuda/cuda -isystem bazel-out/host/bin/external/local_config_cuda/cuda -isystem external/local_config_cuda/cuda/cuda/include -isystem bazel-out/host/bin/external/local_config_cuda/cuda/cuda/include '-std=c++11' -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -fPIC -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -fno-omit-frame-pointer -no-canonical-prefixes -fno-canonical-system-headers -DNDEBUG -g0 -O2 -ffunction-sections -fdata-sections -g0 '-march=native' -g0 -DEIGEN_AVOID_STL_ARRAY -Iexternal/gemmlowp -Wno-sign-compare -fno-exceptions '-ftemplate-depth=900' '-DGOOGLE_CUDA=1' '-DGOOGLE_TENSORRT=1' '-DINTEL_MKL=1' -DEIGEN_USE_VML -DENABLE_MKL -fopenmp -msse3 -pthread '-DGOOGLE_CUDA=1' '-DINTEL_MKL=1' -DENABLE_MKL '-DGOOGLE_TENSORRT=1' -c tensorflow/core/kernels/cuda_solvers.cc -o bazel-out/host/bin/tensorflow/core/kernels/_objs/cuda_solvers/cuda_solvers.pic.o)\r\nExecution platform: @bazel_tools//platforms:host_platform\r\nIn file included from tensorflow/core/kernels/cuda_solvers.cc:17:\r\n./tensorflow/core/kernels/cuda_solvers.h:29:10: fatal error: third_party/gpus/cuda/include/cublas_v2.h: No such file or directory\r\n   29 | #include \"third_party/gpus/cuda/include/cublas_v2.h\"\r\n      |          ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\ncompilation terminated.\r\n```\r\n\r\n```\r\nERROR: /home/x/tf/tensorflow/tensorflow/tensorflow/stream_executor/cuda/BUILD:211:1: C++ compilation of rule '//tensorflow/stream_executor/cuda:cublas_stub' failed (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command \r\n  (cd /home/x/.cache/bazel/_bazel_x/5f286644534b1c99abf8273939acd3e7/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    LD_LIBRARY_PATH=/usr/local/cuda/lib64:/opt/intel/mkl/lib/intel64:/usr/local/cuda/lib64:/opt/intel/mkl/lib/intel64 \\\r\n    PATH=/usr/local/cuda/bin:/home/x/.npm-packages/bin:/usr/local/cuda/bin:/home/x/.npm-packages/bin:/home/x/.local/bin:/home/x/bin:/usr/lib64/ccache:/usr/local/bin:/usr/bin:/bin:/usr/local/sbin:/usr/sbin \\\r\n    PWD=/proc/self/cwd \\\r\n  external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -MD -MF bazel-out/host/bin/tensorflow/stream_executor/cuda/_objs/cublas_stub/cublas_stub.pic.d '-frandom-seed=bazel-out/host/bin/tensorflow/stream_executor/cuda/_objs/cublas_stub/cublas_stub.pic.o' -D__CLANG_SUPPORT_DYN_ANNOTATION__ -DEIGEN_MPL2_ONLY '-DEIGEN_MAX_ALIGN_BYTES=64' '-DEIGEN_HAS_TYPE_TRAITS=0' -DTF_USE_SNAPPY -DTENSORFLOW_USE_NUMA -iquote . -iquote bazel-out/host/bin -iquote external/local_config_cuda -iquote bazel-out/host/bin/external/local_config_cuda -iquote external/com_google_absl -iquote bazel-out/host/bin/external/com_google_absl -iquote external/nsync -iquote bazel-out/host/bin/external/nsync -iquote external/eigen_archive -iquote bazel-out/host/bin/external/eigen_archive -iquote external/local_config_sycl -iquote bazel-out/host/bin/external/local_config_sycl -iquote external/gif_archive -iquote bazel-out/host/bin/external/gif_archive -iquote external/jpeg -iquote bazel-out/host/bin/external/jpeg -iquote external/protobuf_archive -iquote bazel-out/host/bin/external/protobuf_archive -iquote external/com_googlesource_code_re2 -iquote bazel-out/host/bin/external/com_googlesource_code_re2 -iquote external/farmhash_archive -iquote bazel-out/host/bin/external/farmhash_archive -iquote external/fft2d -iquote bazel-out/host/bin/external/fft2d -iquote external/highwayhash -iquote bazel-out/host/bin/external/highwayhash -iquote external/zlib_archive -iquote bazel-out/host/bin/external/zlib_archive -Ibazel-out/host/bin/external/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual -isystem external/local_config_cuda/cuda -isystem bazel-out/host/bin/external/local_config_cuda/cuda -isystem external/local_config_cuda/cuda/cuda/include -isystem bazel-out/host/bin/external/local_config_cuda/cuda/cuda/include -isystem external/nsync/public -isystem bazel-out/host/bin/external/nsync/public -isystem third_party/eigen3/mkl_include -isystem bazel-out/host/bin/third_party/eigen3/mkl_include -isystem external/eigen_archive -isystem bazel-out/host/bin/external/eigen_archive -isystem external/gif_archive/lib -isystem bazel-out/host/bin/external/gif_archive/lib -isystem external/protobuf_archive/src -isystem bazel-out/host/bin/external/protobuf_archive/src -isystem external/farmhash_archive/src -isystem bazel-out/host/bin/external/farmhash_archive/src -isystem external/zlib_archive -isystem bazel-out/host/bin/external/zlib_archive '-std=c++11' -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -fPIC -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -fno-omit-frame-pointer -no-canonical-prefixes -fno-canonical-system-headers -DNDEBUG -g0 -O2 -ffunction-sections -fdata-sections -g0 '-march=native' -g0 -c tensorflow/stream_executor/cuda/cublas_stub.cc -o bazel-out/host/bin/tensorflow/stream_executor/cuda/_objs/cublas_stub/cublas_stub.pic.o)\r\nExecution platform: @bazel_tools//platforms:host_platform\r\ntensorflow/stream_executor/cuda/cublas_stub.cc:15:10: fatal error: third_party/gpus/cuda/include/cublas.h: No such file or directory\r\n   15 | #include \"third_party/gpus/cuda/include/cublas.h\"\r\n      |          ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\ncompilation terminated.\r\n```\r\n```\r\nERROR: /home/x/tf/tensorflow/tensorflow/tensorflow/stream_executor/cuda/BUILD:231:1: C++ compilation of rule '//tensorflow/stream_executor/cuda:cublas_plugin' failed (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command \r\n  (cd /home/x/.cache/bazel/_bazel_x/5f286644534b1c99abf8273939acd3e7/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    LD_LIBRARY_PATH=/usr/local/cuda/lib64:/opt/intel/mkl/lib/intel64:/usr/local/cuda/lib64:/opt/intel/mkl/lib/intel64 \\\r\n    PATH=/usr/local/cuda/bin:/home/x/.npm-packages/bin:/usr/local/cuda/bin:/home/x/.npm-packages/bin:/home/x/.local/bin:/home/x/bin:/usr/lib64/ccache:/usr/local/bin:/usr/bin:/bin:/usr/local/sbin:/usr/sbin \\\r\n    PWD=/proc/self/cwd \\\r\n  external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -MD -MF bazel-out/host/bin/tensorflow/stream_executor/cuda/_objs/cublas_plugin/cuda_blas.pic.d '-frandom-seed=bazel-out/host/bin/tensorflow/stream_executor/cuda/_objs/cublas_plugin/cuda_blas.pic.o' -D__CLANG_SUPPORT_DYN_ANNOTATION__ -DEIGEN_MPL2_ONLY '-DEIGEN_MAX_ALIGN_BYTES=64' '-DEIGEN_HAS_TYPE_TRAITS=0' -DTF_USE_SNAPPY -DTENSORFLOW_USE_NUMA -iquote . -iquote bazel-out/host/bin -iquote external/local_config_cuda -iquote bazel-out/host/bin/external/local_config_cuda -iquote external/com_google_absl -iquote bazel-out/host/bin/external/com_google_absl -iquote external/nsync -iquote bazel-out/host/bin/external/nsync -iquote external/eigen_archive -iquote bazel-out/host/bin/external/eigen_archive -iquote external/local_config_sycl -iquote bazel-out/host/bin/external/local_config_sycl -iquote external/gif_archive -iquote bazel-out/host/bin/external/gif_archive -iquote external/jpeg -iquote bazel-out/host/bin/external/jpeg -iquote external/protobuf_archive -iquote bazel-out/host/bin/external/protobuf_archive -iquote external/com_googlesource_code_re2 -iquote bazel-out/host/bin/external/com_googlesource_code_re2 -iquote external/farmhash_archive -iquote bazel-out/host/bin/external/farmhash_archive -iquote external/fft2d -iquote bazel-out/host/bin/external/fft2d -iquote external/highwayhash -iquote bazel-out/host/bin/external/highwayhash -iquote external/zlib_archive -iquote bazel-out/host/bin/external/zlib_archive -Ibazel-out/host/bin/external/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual -isystem external/local_config_cuda/cuda -isystem bazel-out/host/bin/external/local_config_cuda/cuda -isystem external/local_config_cuda/cuda/cuda/include -isystem bazel-out/host/bin/external/local_config_cuda/cuda/cuda/include -isystem external/nsync/public -isystem bazel-out/host/bin/external/nsync/public -isystem third_party/eigen3/mkl_include -isystem bazel-out/host/bin/third_party/eigen3/mkl_include -isystem external/eigen_archive -isystem bazel-out/host/bin/external/eigen_archive -isystem external/gif_archive/lib -isystem bazel-out/host/bin/external/gif_archive/lib -isystem external/protobuf_archive/src -isystem bazel-out/host/bin/external/protobuf_archive/src -isystem external/farmhash_archive/src -isystem bazel-out/host/bin/external/farmhash_archive/src -isystem external/zlib_archive -isystem bazel-out/host/bin/external/zlib_archive '-std=c++11' -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -fPIC -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -fno-omit-frame-pointer -no-canonical-prefixes -fno-canonical-system-headers -DNDEBUG -g0 -O2 -ffunction-sections -fdata-sections -g0 '-march=native' -g0 -c tensorflow/stream_executor/cuda/cuda_blas.cc -o bazel-out/host/bin/tensorflow/stream_executor/cuda/_objs/cublas_plugin/cuda_blas.pic.o)\r\nExecution platform: @bazel_tools//platforms:host_platform\r\ntensorflow/stream_executor/cuda/cuda_blas.cc:16:10: fatal error: third_party/gpus/cuda/include/cublas_v2.h: No such file or directory\r\n   16 | #include \"third_party/gpus/cuda/include/cublas_v2.h\"\r\n      |          ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\ncompilation terminated.\r\n``` \r\n\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n```\r\nsudo dnf install @development-tools @\"C Development Tools and Libraries\" dnf-plugins-core cmake xz wget llvm clang python3-devel openssl-devel zlib-devel bzip2-devel readline-devel sqlite-devel ncurses-devel tk-devel libnccl-devel libcudnn7-devel libnvinfer-devel\r\nvirtualenv tensorflow\r\ncd tensorflow\r\n. bin/activate\r\npip install --upgrade --force-reinstall pip setuptools\r\npip install wheel numpy scipy keras\r\ngit clone https://github.com/tensorflow/tensorflow.git --single-branch --branch master\r\ncd tensorflow\r\n./configure # all defaults except Y for CUDA and TensorRT support and 7.0 for compute support\r\nexport TMP=/tmp\r\nbazel build -c opt --config=opt --config=v2 --config=mkl --config=numa --verbose_failures \\\r\n    //tensorflow/tools/pip_package:build_pip_package\r\n```", "comments": ["For the second problem I think I found a solution. Nothing was dependent on `@local_config_cuda//cuda:cublas_headers` in the entire code base. Adding it to the four builds that need it seems to fix that problem:\r\n\r\n```\r\ndiff --git a/tensorflow/compiler/xla/service/gpu/BUILD b/tensorflow/compiler/xla/service/gpu/BUILD\r\nindex 3ff115d0b5..76443486b8 100644\r\n--- a/tensorflow/compiler/xla/service/gpu/BUILD\r\n+++ b/tensorflow/compiler/xla/service/gpu/BUILD\r\n@@ -637,6 +637,7 @@ cc_library(\r\n     hdrs = [\"cusolver_context.h\"],\r\n     deps = [\r\n         \"@local_config_cuda//cuda:cuda_headers\",\r\n+        \"@local_config_cuda//cuda:cublas_headers\",\r\n         \"//tensorflow/compiler/xla:statusor\",\r\n         \"//tensorflow/compiler/xla:types\",\r\n         \"//tensorflow/compiler/xla:util\",\r\ndiff --git a/tensorflow/core/kernels/BUILD b/tensorflow/core/kernels/BUILD\r\nindex 98edaca4f0..66997ccb16 100644\r\n--- a/tensorflow/core/kernels/BUILD\r\n+++ b/tensorflow/core/kernels/BUILD\r\n@@ -3147,6 +3147,7 @@ tf_kernel_library(\r\n     }),\r\n     visibility = [\":friends\"],\r\n     deps = [\r\n+        \"@local_config_cuda//cuda:cublas_headers\",\r\n         \"//tensorflow/core:framework\",\r\n         \"//tensorflow/core:lib\",\r\n         \"//tensorflow/core/platform/default/build_config:cublas_plugin\",\r\ndiff --git a/tensorflow/stream_executor/cuda/BUILD b/tensorflow/stream_executor/cuda/BUILD\r\nindex d21b711164..277e11aa21 100644\r\n--- a/tensorflow/stream_executor/cuda/BUILD\r\n+++ b/tensorflow/stream_executor/cuda/BUILD\r\n@@ -214,6 +214,7 @@ cc_library(\r\n     textual_hdrs = glob([\"cublas_*.inc\"]),\r\n     deps = if_cuda_is_configured([\r\n         \"@local_config_cuda//cuda:cuda_headers\",\r\n+        \"@local_config_cuda//cuda:cublas_headers\",\r\n         \"//tensorflow/stream_executor/lib\",\r\n         \"//tensorflow/stream_executor/platform:dso_loader\",\r\n     ]),\r\n@@ -244,6 +245,7 @@ cc_library(\r\n         \"@com_google_absl//absl/strings\",\r\n         \"//third_party/eigen3\",\r\n         \"@local_config_cuda//cuda:cuda_headers\",\r\n+        \"@local_config_cuda//cuda:cublas_headers\",\r\n         \"//tensorflow/core:lib_internal\",\r\n         \"//tensorflow/stream_executor\",\r\n         \"//tensorflow/stream_executor:event\",\r\n```", "(Since `cuda:cublas_headers` is dependent on `cuda:cuda_headers` there is some redundancy there and the `@local_config_cuda//cuda:cuda_headers` dependencies could be removed, but it doesn't really hurt anything).", "Did a clean build with just the patch above (and the one in #28937 for TensorRT) and everything builds fine. The first bullet point must of been a caching issue. A clean copy of the code finds and copies the appropriate so files.", "It sounds like the issues described here are now resolved. I can confirm that the second issue was a bug, but has been fixed in the meantime.\r\n\r\nPlease reopen if you encounter further problems or have questions.", "Thanks!"]}, {"number": 28935, "title": "Safely terminate server RPC loops", "body": "**Issue:** Clean server shutdown is currently not supported. This is because the RPC loops in `GrpcWorkerService` and `GrpcMasterService` do not actually exit even after `Shutdown()` is called.\r\n\r\n**Fix:** This commit adds the mechanism to break out of the RPC loops in both of these classes, modeled after how `GrpcEagerServiceImpl` does it.\n\n<!-- Reviewable:start -->\n---\nThis change is\u2002[<img src=\"https://reviewable.io/review_button.svg\" height=\"34\" align=\"absmiddle\" alt=\"Reviewable\"/>](https://reviewable.io/reviews/tensorflow/tensorflow/28935)\n<!-- Reviewable:end -->\n", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F28935) for more info**.\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F28935) for more info**.\n\n<!-- ok -->", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "@andrewor14 gentle ping to add test cases.", "It has been 28 days that this pull-request has stalled. Please create a new pull-request with the requested changes."]}, {"number": 28934, "title": "Request for ScatterNd on Tensorflow Lite", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nUbuntu 16.04\r\n- TensorFlow installed from (source or binary):\r\nBinary\r\n- TensorFlow version (or github SHA if from source):\r\n1.13.1 and 2.0-preview\r\n\r\n\r\n**Provide the text output from tflite_convert**\r\n\r\n```\r\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime and are not recognized by TensorFlow. If you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ........\r\n\r\n. Here is a list of operators for which you will need custom implementations: ScatterNd.\r\n```\r\n\r\nAlso, please include a link to a GraphDef or the model if possible.\r\n\r\n**Any other info / logs**\r\n\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["New op requests are tracked at [#21526](https://github.com/tensorflow/tensorflow/issues/21526). Could you put a comment there? Closing this issue..."]}]