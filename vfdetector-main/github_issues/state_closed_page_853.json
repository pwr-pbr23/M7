[{"number": 27927, "title": "Under MirroredStrategy and ParameterStrategy tf.trainable_variables() doesn't return the correct wrapped variables", "body": "Under MirroredStrategy and ParameterStrategy tf.trainable_variables() returns the normal unwrapped variables.\r\n\r\nBut according to the comments in mirrored_strategy.py and parameter_server_strategy.py, tf.trainable_variables() should return the wrapped variables.\r\n\r\nHere tf 1.13.1 mirrored_strategy.py code segment,\r\n```\r\n if not context.executing_eagerly():\r\n    g = ops.get_default_graph()\r\n    # If \"trainable\" is True, next_creator() will add the member variables                                                                                                                    \r\n    # to the TRAINABLE_VARIABLES collection, so we manually remove                                                                                                                            \r\n    # them and replace with the MirroredVariable. We can't set                                                                                                                                \r\n    # \"trainable\" to False for next_creator() since that causes functions                                                                                                                     \r\n    # like implicit_gradients to skip those variables.                                                                                                                                        \r\n    if kwargs.get(\"trainable\", True) or kwargs.get(\"trainable\", True) is None:\r\n      collections.append(ops.GraphKeys.TRAINABLE_VARIABLES)\r\n      l = g.get_collection_ref(ops.GraphKeys.TRAINABLE_VARIABLES)\r\n      for v in index.values():\r\n        if v in l:\r\n          l.remove(v)\r\n    g.add_to_collections(collections, result)\r\n```\r\nThe problem is that in kwargs past from up stream API, \"trainable\" is set but the value is None, so just ckeck\r\n\r\n    if kwargs.get(\"trainable\", True): \r\n\r\nis not enough, it should be\r\n\r\n    if kwargs.get(\"trainable\", True) or  kwargs.get(\"trainable\", True) is None:\r\n\r\nThis bug exists in all version of tensorflow. For tf 1.13.1, here is the fix for mirred_strategy.py\r\n```\r\ndiff -u mirrored_strategy.py-org mirrored_strategy.py\r\n--- mirrored_strategy.py-org    2019-03-15 08:56:17.677027702 -0400\r\n+++ mirrored_strategy.py        2019-04-17 12:21:06.339507273 -0400\r\n@@ -256,7 +256,7 @@\r\n     # them and replace with the MirroredVariable. We can't set\r\n     # \"trainable\" to False for next_creator() since that causes functions\r\n     # like implicit_gradients to skip those variables.\r\n-    if kwargs.get(\"trainable\", True):\r\n+    if kwargs.get(\"trainable\", True) or kwargs.get(\"trainable\", True) is None:\r\n       collections.append(ops.GraphKeys.TRAINABLE_VARIABLES)\r\n       l = g.get_collection_ref(ops.GraphKeys.TRAINABLE_VARIABLES)\r\n       for v in index.values():\r\n```", "comments": ["In order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!\r\n", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=27927\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=27927\">No</a>\n"]}, {"number": 27926, "title": "Autodiff creates stack for loop-invariant data", "body": "In file `control_flow_ops.py`, `GetRealValue()` implements the functionality to get the value of an operation from each forward loop iteration to be used in the backward loop.\r\nThis function checks if the operation is a constant and skips creating a stack for these. Otherwise it creates a stack and pushes the value at each loop iteration.\r\nThe issue is that `GetRealValue()` doesn't check if the operation is loop invariant, or simply, if it's computed outside the loop, and still creates the stack. I see significant memory consumption because of this.\r\n\r\nI tried to find a way of checking if an operation is loop invariant or if it's computed outside the loop, but failed to find such a function (I'm new in TF source-code). If you could point me out to such a function, I would be happy to try to produce a patch.\r\nThanks!", "comments": ["@saxenasaurabh Any ideas about this?", "Could you provide a code snippet? v1 control flow [should not](https://github.com/tensorflow/tensorflow/blob/fd28b784b2e82ddb2c72196668374e244cfdf205/tensorflow/python/ops/control_flow_ops.py#L1006) be capturing loop invariants. Are you maybe passing the tensor in the list of loop_vars?", "I've uploaded a simple example here: https://gist.github.com/nunoplopes/5d98b7f8301ca3b74f6a32bd974fbae5\r\n\r\nSee the XLA output below, where green shows 'a', which is loop invariant. And in yellow you've the stack push to store 'a' on each iteration:\r\n![tf-loop](https://user-images.githubusercontent.com/2998477/56738201-05033e80-6764-11e9-8c8f-f66d16eaff44.jpg)\r\n\r\n", "Thanks for the repro. Even though variables are marked as loop invariants, they could get updated in the loop body. Arguing for constness of a variable used in the While body may be hard because they are updated in-place. Could you try reading the variable's value outside the loop using [`a.read_value()`](https://www.tensorflow.org/api_docs/python/tf/Variable#read_value) and use that in the loop body? That should fix your memory issue I think.", "That gets rid of the stack for `a` indeed, thank you.\r\nIn theory, just iterating over all the instructions in the loop and checking which variables they can potentially write to doesn't sound too hard. But I don't know enough of TF's internals to judge that. I couldn't even find a way to iterate over such instructions.\r\n\r\n@saxenasaurabh Do you think v2 loops will solve the issue (or at least make it easier to solve)?  Is there hope of fixing this?\r\nThanks!", "I don't think v2 loops will fix this (at least for now). I think there are some other issues with while loop accumulating _too much_. Maybe we can handle all those cases as an optimization pass. Let me know if you have other thoughts on this or if you would like to contribute :) I will close this for now since I might not be able to look into this immediately but this is definitely on my radar of potential performance improvements for tf.while_loop."]}, {"number": 27925, "title": "Support for micro_speech example on AP3B EVB", "body": "", "comments": []}, {"number": 27924, "title": "Estimator from Keras Model fails to learn when original keras Model learns fine", "body": "I have created a keras `Model` that learns a simple embedding from a deterministic function.  When I convert to an Estimator using ` tf.keras.estimator.model_to_estimator` learning fails to converge and the learned embeddings are incorrect.\r\n  \r\nI would expect that an Estimator constructed from a keras Model would have similar performance to the original keras Model.  However the keras model loss decays to zero quickly:\r\n\r\n![image](https://user-images.githubusercontent.com/10658783/56299648-760e7a80-6102-11e9-92d0-600480fe8659.png)\r\n\r\nBut the Estimator does not learn at all:\r\n![Screenshot from 2019-04-17 11-30-24](https://user-images.githubusercontent.com/10658783/56300844-a820dc00-6104-11e9-8fe8-fd4d7d70cbfa.png)\r\n\r\n\r\n**Code to reproduce the issue**\r\n```python\r\nimport numpy as np\r\nimport pandas as pd\r\nimport tensorflow as tf\r\n\r\n# Generate Some Data\r\nnp.random.seed(1234)\r\nn_obs = 200\r\nn_sensors = 50\r\nn_sources  = 5\r\n\r\nZ = np.random.randn(n_obs, n_sources)\r\nb = np.random.randn(n_sources, n_sensors)\r\ny = Z.dot(b)\r\n\r\ndata = []\r\nfor t in range(n_obs):\r\n    betas = pd.DataFrame(b).rename(lambda x: 'f_{}'.format(x)).T\r\n    data.append(\r\n        pd.DataFrame({'target': y[t,:], 't': t}).join(betas)\r\n    )\r\n\r\ndata = pd.concat(data)\r\n\r\ndef build_keras_model():\r\n\"\"\"\r\nA model to learn `Z` in f(b, t) = Z[t].dot(b)\r\n\"\"\"\r\n    betas = tf.keras.layers.Input(shape=(n_sources,), name='betas')\r\n    t = tf.keras.layers.Input(shape=(1,), name='t')\r\n\r\n    sources = tf.keras.layers.Embedding(\r\n        input_dim=n_obs,\r\n        output_dim=n_sources,\r\n        name='sources')(t)\r\n\r\n    fitted = tf.keras.layers.Dot(axes=-1)([sources, betas])\r\n    net = tf.keras.Model([betas, t], fitted)\r\n    net.compile(optimizer='adadelta', loss='mse')\r\n    return net\r\n\r\n# Train Keras Model \r\nnet = build_keras_model()\r\nloss = []\r\n\r\nhist = net.fit(\r\n    x=[data.filter(like='f_'), data.t],\r\n    y=data.target,\r\n    batch_size=100,\r\n    epochs=200)\r\nloss += hist.history['loss']\r\n\r\n#  get embedding weights and average squared different to ground truth\r\nZ_hat_keras = net.get_layer('sources').get_weights()\r\nprint ((Z_hat_keras - Z) ** 2).mean()\r\n# Out: 8.794945836110652e-05\r\n\r\n# convert to a Estimator object\r\nestimator = tf.keras.estimator.model_to_estimator(net)\r\n\r\n# construct input functions for Estimator\r\ndef input_fn(data, batch_size, num_epochs, shuffle):\r\n    ds = tf.data.Dataset.from_tensor_slices((\r\n        {'betas': data.filter(like='f_'), 't': data.t}, data.target\r\n    ))\r\n\r\n    if shuffle:\r\n        ds = ds.shuffle(len(data))\r\n\r\n    return ds.repeat(num_epochs).batch(batch_size)\r\n\r\ntrain_fn = lambda: input_fn(data, 100, 200, True)\r\neval_fn = lambda: input_fn(data, 500,1,False)\r\n\r\n# run training on estimator\r\nestimator.train(train_fn)\r\nestimator.evaluate(eval_fn)\r\n# Out: {'global_step': 20001, 'loss': 5.0131807}\r\n\r\n#  get embedding weights and average squared different to ground truth\r\nZ_hat_tensorflow = estimator.get_variable_value('sources/embeddings')\r\nprint ((Z_hat_tensorflow - Z) ** 2).mean()\r\n# Out 0.928678746751657\r\n```\r\n\r\n**Other info / logs**\r\nI have also posted on StackOverflow with a bit more detail:\r\nhttps://stackoverflow.com/questions/55712219/are-keras-embedding-layers-getting-added-regularization-when-converted-to-tensor\r\n", "comments": ["Here is the output of the environment script:\r\n[tf_env.txt](https://github.com/tensorflow/tensorflow/files/3090394/tf_env.txt)\r\n", "The issue looks to be with the tensorflow optimizers.  The tensorflow version will not learn on identical keras models\r\n\r\n![image](https://user-images.githubusercontent.com/10658783/56391791-b0a90d80-61fd-11e9-8a27-5b5f04213c23.png)\r\n\r\ncode for test:\r\n```python\r\n#  using build_keras_model defined in previous comment\r\nnet_w_keras_opt = build_keras_model()\r\nnet_w_keras_opt.compile(optimizer='adadelta', loss='mse')\r\nnet_w_tf_opt = build_keras_model()\r\nnet_w_tf_opt.compile(optimizer=tf.train.AdadeltaOptimizer(), loss='mse')\r\n\r\n# save loss for plotting\r\nkeras_loss = []\r\ntf_loss = []\r\n\r\n# train keras\r\nkeras_hist = net_w_keras_opt.fit(\r\n    x=[data.filter(like='f_'), data.t],\r\n    y=data.target,\r\n    batch_size=50,\r\n    epochs=200)\r\nkeras_loss += keras_hist.history['loss']\r\n\r\n# train tf version\r\ntf_hist = net_w_tf_opt.fit(\r\n    x=[data.filter(like='f_'), data.t],\r\n    y=data.target,\r\n    batch_size=50,\r\n    epochs=200)\r\ntf_loss += tf_hist.history['loss']\r\n\r\n# plotting\r\n%matplotlib inline\r\npd.Series(keras_loss).plot(label='Keras', legend=True)\r\npd.Series(tf_loss).plot(label='Tensorflow', legend=True, figsize=(10,5), grid=True)\r\n```", "which tf version is this? Can you try 1.14?", "The previous version was TF 1.13.1\r\nWith TF 1.14 we get similar performance.\r\n![image](https://user-images.githubusercontent.com/42785357/60372074-35f42f80-99b0-11e9-9714-1f525ccb7a97.png)\r\n", "I see you have put two different experiments:\r\n1) experiment between keras model and estimator converted from it.\r\n2) experiment between keras model using keras optimizer and tf optimizer.\r\n\r\nFor 1), can you try to reproduce it with 1.14?\r\nFor 2), this is expected, keras adadelta learning rate is 1.0, tf adadelta learning rate is 0.001. So latter learns much slower. You might want to adjust learning rate and test for consistency.", "@tanzhenyu Would you mind to point me out where you can see learning rate for Adadelta is 0.001? \r\nI can see 1.0 for 1.14 at https://github.com/tensorflow/tensorflow/blob/r1.14/tensorflow/python/keras/optimizers.py#L381\r\n\r\nplease correct me if I am wrong ", "I think I found proper defaults from https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/optimizer_v2/adadelta.py but in this case, it's pretty confusing and I am not sure what these old definitions for if they are not event exported ", "Not sure if I understand what do you mean...Does keras adadelta with learning rate of 1.0 help with your experiment?", "This appears to be a very old (almost 2 years, pre-dating tf 2.0) issue. So going ahead and closing. In general we strongly recommend avoiding estimators and using Keras directly.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/27924\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/27924\">No</a>\n"]}, {"number": 27923, "title": "The kernel appears to have died. It will restart automatically.", "body": "def make_generator_model():\r\n    model = tf.keras.Sequential()\r\n    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\r\n    model.add(layers.BatchNormalization())\r\n    model.add(layers.LeakyReLU())\r\n\r\n    model.add(layers.Reshape((7, 7, 256)))\r\n    assert model.output_shape == (None, 7, 7, 256) # Note: None is the batch size\r\n\r\n    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\r\n    assert model.output_shape == (None, 7, 7, 128)\r\n    model.add(layers.BatchNormalization())\r\n    model.add(layers.LeakyReLU())\r\n\r\n    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\r\n    assert model.output_shape == (None, 14, 14, 64)\r\n    model.add(layers.BatchNormalization())\r\n    model.add(layers.LeakyReLU())\r\n\r\n    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\r\n    assert model.output_shape == (None, 28, 28, 1)\r\n\r\n    return model\r\n\r\n\r\ngenerator = make_generator_model()\r\n\r\nnoise = tf.random.normal([1, 100])\r\ngenerated_image = generator(noise, training=False)\r\n\r\n#plt.imshow(generated_image[0, :, :, 0], cmap='gray')\r\n\r\n==============================\r\ntensorflow2 \r\ncuda 10.0 \r\n", "comments": ["@SlowMonk I was also having similar problems. I think this is because of limited memory capacity of your system.", "@SlowMonk  Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\nMake sure you also include the exact command if possible to produce the output included in your test case. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Also Please provide entire code for reproducing the issue.Thanks!\r\n", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 27922, "title": "Use tf_logging instead of print in lazy_loader.py", "body": "User may want to ignore warning sometimes.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F27922) for more info**.\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F27922) for more info**.\n\n<!-- ok -->", "How about print the message to the stderr if using tf.logging is a problem?\r\nIt can be piped out with other warning messages."]}, {"number": 27921, "title": "This company RANNED !!!!!!", "body": "THIS  company  is    By  Liberals .... For  You  a will see   Why U Think    Its a Good Compay . Your.   Wrong !!!!!!!!    Learn More.......", "comments": ["Spam"]}, {"number": 27920, "title": "How to compare two DimensionHandle objects in shape inference function?", "body": "I am writing some ops in C++.\r\nMy question is: how to compare two DimensionHandle objects in shape inference function?", "comments": []}, {"number": 27919, "title": "Fixed rendering errors in tf.GradientTape docs", "body": "Just adding blank lines before the code blocks can fix this problem.", "comments": []}, {"number": 27918, "title": "TensorFlowLite: failed to load native library: Library tensorflowlite_jni not found; at  /system/lib64", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  downloaded .aar file from https://mvnrepository.com/artifact/org.tensorflow/tensorflow-lite/1.13.1\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Samsung Galaxy A5\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 1.13.1\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: NA\r\n- GPU model and memory: NA\r\n\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n**Describe the current behavior** Trying to load .tflite file on Android device. Getting error \"TensorFlowLite: failed to load native library: Library tensorflowlite_jni not found; at  /system/lib64\". It is not able to find the tensorflowlite_jni.so at /system/lib64 path. If I push the file to /system/lib64 path in device it works\r\n\r\n**Describe the expected behavior**: It should work without the requirement of external push\r\n\r\n**Code to reproduce the issue**: 1. Generate a .tflite file after model training on desktop\r\n2. download .aar file from https://mvnrepository.com/artifact/org.tensorflow/tensorflow-lite/1.13.1\r\n3. Build Android binary using downloaded .aar file and .tflite file along with Android Application trying to load .tflite file\r\n4. Run time error while app is trying to load the .tflite file\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n04-17 17:50:00.518  4470  4470 W **System.err: TensorFlowLite: failed to load native library: Library tensorflowlite_jni not found; tried [/system/lib64/libtensorflowlite_jni.so]** 04-17 17:50:00.519  4470  4470 W System.err: TensorFlowLite: failed to load native library: Library tensorflowlite_jni not found; tried [/system/lib64/libtensorflowlite_jni.so] 04-17 17:50:00.528  8077  8077 D OpenGLRenderer: Skia GL Pipeline 04-17 17:50:00.539  5932  5959 V ContactsProvider_EventLog: contents_sample_query: [ uri = content://com.android.contacts/contacts(usr:0), pkg = com.samsung.android.bixby.service(6596), prj = [name_raw_contact_id, contact_last_updated_timestamp], sel = name_raw_contact_id <= 1 AND ( contact_last_updated_timestamp > 1555500415060 OR (contact_last_updated_timestamp = 1555500415060 AND name_raw_contact_id > 1 )), selArg = null, so = contact_last_updated_timestamp ASC LIMIT 300, cv = null, dur = 27, ret = 0, trw = false ] 04-17 17:50:00.541  8077  8077 D EmergencyMode: [EmergencyManager] android createPackageContext successful 04-17 17:50:00.543  4470  4470 E system_server: No implementation found for long org.tensorflow.lite.NativeInterpreterWrapper.createErrorReporter(int) (tried Java_org_tensorflow_lite_NativeInterpreterWrapper_createErrorReporter and Java_org_tensorflow_lite_NativeInterpreterWrapper_createErrorReporter__I) 04-17 17:50:00.544  4470  4470 E Zygote  : System zygote died with exception 04-17 17:50:00.544  4470  4470 E Zygote  : java.lang.UnsatisfiedLinkError: No implementation found for long org.tensorflow.lite.NativeInterpreterWrapper.createErrorReporter(int) (tried Java_org_tensorflow_lite_NativeInterpreterWrapper_createErrorReporter and Java_org_tensorflow_lite_NativeInterpreterWrapper_createErrorReporter__I) 04-17 17:50:00.544  4470  4470 E Zygote  :     at org.tensorflow.lite.NativeInterpreterWrapper.createErrorReporter(Native Method) 04-17 17:50:00.544  4470  4470 E Zygote  :     at org.tensorflow.lite.NativeInterpreterWrapper.<init>(NativeInterpreterWrapper.java:73) 04-17 17:50:00.544  4470  4470 E Zygote  :     at org.tensorflow.lite.NativeInterpreterWrapper.<init>(NativeInterpreterWrapper.java:54) 04-17 17:50:00.544  4470  4470 E Zygote  :     at org.tensorflow.lite.Interpreter.<init>(Interpreter.java:114) 04-17 17:50:00.544  4470  4470 E Zygote  :     at android.hardware.VirtualProximityService.initTflite(VirtualProximityService.java:184) 04-17 17:50:00.544  4470  4470 E Zygote  :     at android.hardware.VirtualProximityService.onCreate(VirtualProximityService.java:99) 04-17 17:50:00.544  4470  4470 E Zygote  :     at android.app.ActivityThread.handleCreateService(ActivityThread.java:3757) 04-17 17:50:00.544  4470  4470 E Zygote  :     at android.app.ActivityThread.access$1400(ActivityThread.java:237) 04-17 17:50:00.544  4470  4470 E Zygote  :     at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1808) 04-17 17:50:00.544  4470  4470 E Zygote  :     at android.os.Handler.dispatchMessage(Handler.java:106) 04-17 17:50:00.544  4470  4470 E Zygote  :     at android.os.Looper.loop(Looper.java:214) 04-17 17:50:00.544  4470  4470 E Zygote  :     at com.android.server.SystemServer.run(SystemServer.java:802) 04-17 17:50:00.544  4470  4470 E Zygote  :     at com.android.server.SystemServer.main(SystemServer.java:624) 04-17 17:50:00.544  44\r\n04-17 17:50:00.544  4470  4470 E Zygote  :     at com.android.server.SystemServer.main(SystemServer.java:624) 04-17 17:50:00.544  4470  4470 E Zygote  :     at java.lang.reflect.Method.invoke(Native Method) 04-17 17:50:00.544  4470  4470 E Zygote  :     at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:493) 04-17 17:50:00.544  4470  4470 E Zygote  :     at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:945) 04-17 17:50:00.545  4470  4470 D AndroidRuntime: Shutting down VM\r\n", "comments": ["@schawla1988 \r\n\r\nwould you share the below deatils to help you out the above problem,\r\n1- build script which use to compile android app? \r\n2- your handset cpu abi version(adb shell getprop ro.product.cpu.abi)?\r\n3- sdk and ndk version which you configure with tensorflow?", "I faced the same problem, @schawla1988 's solution is not working for me, could anybody have idea?\r\nThanks.", "It looks like you're trying to reference the shared library from a system service? In which case, it's your responsibility to put the native shared library where it can be used."]}, {"number": 27917, "title": "are the same tensorflow serving .pb file  with frozen graph .pb file", "body": "This template is for miscellaneous issues not covered by the other issue categories.\r\n\r\nFor questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\r\n\r\nIf you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).\r\n\r\nFor high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.\r\n", "comments": ["@Muhammad333 Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\nMake sure you also include the exact command if possible to produce the output included in your test case. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!\r\n"]}, {"number": 27916, "title": "[CI] Ubuntu CC  is still \"Expected \u2014 Waiting for status to be reported\" after 14 days.", "body": "It is strange. Let's see the operation status of Tensorflow CI on  PR #27466.  The work status of **Ubuntu CC**  is still \"**Expected \u2014 Waiting for status to be reported**\" even though 14 days is passed after the contributor submitted PR #27466. Why does not `Ubuntu CC`  report the result either PASS or FAILURE? Why Ubuntu CC is still running for 14 days?\r\n\r\n* https://github.com/tensorflow/tensorflow/pull/27466\r\n![image](https://user-images.githubusercontent.com/82404/56286270-50aa5c80-6154-11e9-993c-e2c6188d823b.png)\r\n\r\n\r\nAbove all, lots of PRs do not have got the execution result of Tensorflow CI.  Please see the red circles below. Why these situations have repeatedly generated?\r\n\r\n![image](https://user-images.githubusercontent.com/82404/56286707-5fddda00-6155-11e9-846a-177ccaa3e9ee.png)\r\n", "comments": ["@leemgs The yellow dot essentially means that not all checks have run. We don't run all the checks until a reviewer has approved the PR. Hope that clarifies it.", "> We don't run all the checks until a reviewer has approved the PR. Hope that clarifies it.\r\n\r\nIs it mean that the CI system does not report any results until a reviewer has approved the PR? It's weird. It is not helpful to the reviewers because the CI system works as one of the reviewers. In general, the major goal of the CI system is to help the reviewer (without the final approver of the PR)."]}, {"number": 27915, "title": "[feature request]check whether a data iterator is initialized", "body": "**System information**\r\n- TensorFlow version (you are using): r1.13\r\n- Are you willing to contribute it (Yes/No): yes\r\n\r\n**Describe the feature and the current behavior/state.**\r\nWhen a dataset iterator is shared among sessions by \"shared_name\", non-chief sessions need to wait for its initialization on the chief session. And what is the proper way to check the state of iterators currently\uff1f\r\nIdeally, iterators should be initialized by init_ops of monitoredsession, and checked in model_ready function.\r\n\r\n**Will this change the current api? How?**\r\nNo changes on current api. add one new api like \"is_initialized\".\r\n\r\n**Who will benefit with this feature?**\r\nall who use \"shared_name\" feature.", "comments": ["Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\nMake sure you also include the exact command if possible to produce the output included in your test case. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!\r\n", "> Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n> \r\n> Make sure you also include the exact command if possible to produce the output included in your test case. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\n> \r\n> We ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!\r\n\r\nmy fault\uff0cadded informations.", "awaiting tensorflower", "TF 1.X style iterators are deprecated in TF 2.0 and the tf.data team will not prioritize this request. I will mark this issue as contributions welcome.", "as the style iterators are deprecated , this is no longer a valid feature request, closing this issue. Thank you "]}, {"number": 27914, "title": "Keras' load_model() fix", "body": "Hi.\r\n\r\nI just faced a problem that I cannot load checkpoints of my Keras model. There was an `ValueError` exception with a following backtrace:\r\n\r\n```\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-3-8b604ef2029d> in <module>\r\n----> 1 model = tf.keras.models.load_model(model_file)\r\n\r\n~/Projects/__mangled__/__mangled__/venv/lib/python3.7/site-packages/tensorflow/python/keras/saving/hdf5_format.py in load_model(filepath, custom_objects, compile)\r\n    245           weighted_metrics=weighted_metrics,\r\n    246           loss_weights=loss_weights,\r\n--> 247           sample_weight_mode=sample_weight_mode)\r\n    248 \r\n    249       # Set optimizer weights.\r\n\r\n~/Projects/__mangled__/__mangled__/venv/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py in _method_wrapper(self, *args, **kwargs)\r\n    454     self._setattr_tracking = False  # pylint: disable=protected-access\r\n    455     try:\r\n--> 456       result = method(self, *args, **kwargs)\r\n    457     finally:\r\n    458       self._setattr_tracking = previous_value  # pylint: disable=protected-access\r\n\r\n~/Projects/__mangled__/__mangled__/venv/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py in compile(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, distribute, **kwargs)\r\n    302     # Prepare list of loss functions, same size of model outputs.\r\n    303     self.loss_functions = training_utils.prepare_loss_functions(\r\n--> 304         loss, self.output_names)\r\n    305 \r\n    306     self._feed_outputs = []\r\n\r\n~/Projects/__mangled__/__mangled__/venv/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_utils.py in prepare_loss_functions(loss, output_names)\r\n   1143       if name not in output_names:\r\n   1144         raise ValueError('Unknown entry in loss dictionary: {}. Only expected '\r\n-> 1145                          'following keys: {}'.format(name, output_names))\r\n   1146     loss_functions = []\r\n   1147     for name in output_names:\r\n\r\nValueError: Unknown entry in loss dictionary: class_name. Only expected following keys: ['output']\r\n```\r\n\r\nI use 2.0.0-alpha0, but the same story with 1.12.0.\r\n\r\nI figured out, that loss is not being deserialized before passing it to `model.compile()` call.\r\n\r\nMy quick fix seems work for me. Could you please check and approve, if all things done in the right way.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F27914) for more info**.\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F27914) for more info**.\n\n<!-- ok -->", "@k-w-w Could you PTAL and approve.", "Thanks for adding this change! Can you add a test to make sure this doesn't happen again?", "Found what was the deal with the issue and why there's no noise in the internet: it happened only in case if `tf.keras.losses.BinaryCrossentropy` or the other _built-in loss class instance_ was used while the model was compiled. In this case the loss is not a string (like in case if I just used `'binary_crossentropy'` string while compiling the model, but a dictionary, which was not de-serialized.", "@k-w-w Can you have a look on smyskoff's comments? Thanks!\r\n", "@smyskoff Can you please resolve conflicts? Thanks!", "@gbaned, ready", "Hi @smyskoff, does the test pass with as currently implemented? The code has changed a bit, and it should now handle custom object correctly. (The code that deserializes the loss object is here: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/saving/saving_utils.py#L210)", "@smyskoff Could you please address the reviewer comments. Thanks!", "Can one of the admins verify this patch?", "@smyskoff Gentle ping to check the reviewer comments. Thanks!", "Checked out the updated code. Seems like the problem has gone with changes, so my changes are not needed to make it work in the described flow.", "Thank you @smyskoff . Closing this PR as per your confirmation."]}, {"number": 27913, "title": "ptr bug tensorflow", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\nwrong ptr \r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):source\r\n- TensorFlow version (use command below):1.13\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:7.0/9.0\r\n- GPU model and memory: 1080ti\r\n\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n**Describe the current behavior**\r\nproject deeplab v3 +.When I open the memory, the network input is a pointer to mat, not a pointer to the raw file I opened, so the input is wrong. And remove the pointer input of mat, although the input pointer is correct,  the content read by tensor is wrong, resulting in the final output map is all 2 (label).This may be related to defining the location of the tensor.\r\n**Describe the expected behavior**\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n`    Mat img=imread(image_path);\r\n    cvtColor(img, img, CV_BGR2RGB);\r\n    unsigned char * q=img.data;\r\n         FILE *out; \r\n         out = fopen(\"./a011.raw\", \"rb\");\r\n    unsigned char *buf_tempx;\r\n    Tensor resized_tensor(DT_UINT8, TensorShape({1,input_height,input_width,3}));\r\n    buf_tempx = (unsigned char *)malloc(input_width*input_height*3);\r\n        fread(buf_tempx, 1, input_width*input_height*3, out);\r\n        fclose(out);\r\n    Point_to_Tensor(buf_tempx,&resized_tensor,input_height,input_width);\r\n    struct  timeval start;\r\n    struct  timeval end;\r\n    unsigned  long diff;\r\n    gettimeofday(&start,NULL);\r\n    cout<<endl<<\"<-------------Running the model with test_image--------------->\"<<endl;\r\n    vector<tensorflow::Tensor> outputs;\r\n    string output_node = output_tensor_name;\r\n    Status status_run = session->Run({{input_tensor_name, resized_tensor}}, {output_node}, {}, &outputs);\r\n`", "comments": ["@allendred I think it is related to TF models repo. Could you post it in the [model repo](https://github.com/tensorflow/models/issues). If you think the issue is more related to TF Core then share a reproducible code or a GitHub gist to reproduce the issue? It will help us to resolve the issue. \r\n\r\nThanks!", "Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will open a new issue. Thanks!\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=27913\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=27913\">No</a>\n"]}, {"number": 27912, "title": "There is still bug with function tf.keras.layers.Conv3DTranspose when its input shape is None", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04.2\r\n\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 1.13.1\r\n- Python version: 3.7\r\n\r\n\r\n\r\n\r\nYou can collect some of this information using our environment capture [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n**Describe the current behavior**\r\nHi, here's my code:\r\n\r\ninput_img = keras.layers.Input( shape=( None, len(params2), len(params2), 1 ) ) # adapt this if using `channels_first` image data format\r\n\r\nconv1 = keras.layers.Conv3D(filters=32, kernel_size=(1, 3, 3), strides=(1, 1, 1), activation='selu', padding='same', data_format='channels_last', name='conv1')(input_img)\r\nconv2 = keras.layers.Conv3D(filters=64, kernel_size=(1, 3, 3), strides=(1, 2, 2), activation='selu', padding='same', data_format='channels_last', name='conv2')(conv1)\r\nconv3 = keras.layers.Conv3D(filters=128,kernel_size=(1, 3, 3), strides=(1, 2, 2), activation='selu', padding='same', data_format='channels_last', name='conv3')(conv2)\r\nconv4 = keras.layers.Conv3D(filters=256,kernel_size=(1, 3, 3), strides=(1, 2, 2), activation='selu', padding='same', data_format='channels_last', name='conv4')(conv3)\r\n\r\nconvlstm1 = keras.layers.ConvLSTM2D(filters=32, return_sequences=True, kernel_size=(3, 3), strides=(1, 1), activation='selu', padding='same', data_format='channels_last', name='convlstm1')(conv1)\r\nconvlstm2 = keras.layers.ConvLSTM2D(filters=64, return_sequences=True, kernel_size=(3, 3), strides=(1, 1), activation='selu', padding='same', data_format='channels_last', name='convlstm2')(conv2)\r\nconvlstm3 = keras.layers.ConvLSTM2D(filters=128,return_sequences=True, kernel_size=(3, 3), strides=(1, 1), activation='selu', padding='same', data_format='channels_last', name='convlstm3')(conv3)\r\nconvlstm4 = keras.layers.ConvLSTM2D(filters=256,return_sequences=True, kernel_size=(3, 3), strides=(1, 1), activation='selu', padding='same', data_format='channels_last', name='convlstm4')(conv4)\r\n\r\ndeconv4 = keras.layers.Conv3DTranspose(filters=128, kernel_size=(1, 2, 2), strides=(1, 2, 2), activation='selu', padding='valid', output_padding=(0, -1, -1), data_format='channels_last', name='deconv4')(convlstm4)\r\nconcat4 = keras.layers.Concatenate(axis=4, name='concat4')([convlstm3, deconv4])\r\ndeconv3 = keras.layers.Conv3DTranspose(filters=64 , kernel_size=(1, 2, 2), strides=(1, 2, 2), activation='selu', padding='valid', output_padding=(0, -1, -1), data_format='channels_last', name='deconv3')(concat4)\r\nconcat3 = keras.layers.Concatenate(axis=4, name='concat3')([convlstm2, deconv3])\r\ndeconv2 = keras.layers.Conv3DTranspose(filters=32 , kernel_size=(1, 3, 3), strides=(1, 2, 2), activation='selu', padding='same' , data_format='channels_last', name='deconv2')(concat3)\r\nconcat2 = keras.layers.Concatenate(axis=4, name='concat2')([convlstm1, deconv2])\r\ndeconv1 = keras.layers.Conv3DTranspose(filters=1  , kernel_size=(1, 3, 3), strides=(1, 1, 1), activation='selu', padding='same' , data_format='channels_last', name='deconv1')(concat2)\r\n\r\nautoencoder = keras.models.Model(input_img, deconv1)\r\nautoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\r\nautoencoder.summary()\r\n\r\nand here's the error message:\r\n\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-150-83622ca7a77b> in <module>\r\n     28     return autoencoder\r\n     29 \r\n---> 30 autoencoder1(1700)\r\n\r\n<ipython-input-150-83622ca7a77b> in autoencoder1(file_length)\r\n     14     convlstm4 = keras.layers.ConvLSTM2D(filters=256,return_sequences=True, kernel_size=(3, 3), strides=(1, 1), activation='selu', padding='same', data_format='channels_last', name='convlstm4')(conv4)\r\n     15 \r\n---> 16     deconv4 = keras.layers.Conv3DTranspose(filters=128, kernel_size=(1, 2, 2), strides=(1, 2, 2), activation='selu', padding='valid', output_padding=(0, -1, -1), data_format='channels_last', name='deconv4')(convlstm4)\r\n     17     concat4 = keras.layers.Concatenate(axis=4, name='concat4')([convlstm3, deconv4])\r\n     18     deconv3 = keras.layers.Conv3DTranspose(filters=64 , kernel_size=(1, 2, 2), strides=(1, 2, 2), activation='selu', padding='valid', output_padding=(0, -1, -1), data_format='channels_last', name='deconv3')(concat4)\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py in __call__(self, inputs, *args, **kwargs)\r\n    552             # In graph mode, failure to build the layer's graph\r\n    553             # implies a user-side bug. We don't catch exceptions.\r\n--> 554             outputs = self.call(inputs, *args, **kwargs)\r\n    555           else:\r\n    556             try:\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/convolutional.py in call(self, inputs)\r\n   1138       else:\r\n   1139         outputs_4d = array_ops.reshape(outputs, [\r\n-> 1140             outputs_shape[0], outputs_shape[1] * outputs_shape[2],\r\n   1141             outputs_shape[3], outputs_shape[4]\r\n   1142         ])\r\n\r\nTypeError: unsupported operand type(s) for *: 'NoneType' and 'int'\r\n\r\nYou just said that this problem was solved. But I'm really not sure why I still have this problem today on April 2019.\r\n", "comments": ["Someone said that this problem was solved in February, but I found that there is still error, that it doesn't work.", "I encountered this problem too. It seems that this problem is fixed in [this commit](https://github.com/tensorflow/tensorflow/commit/bae74d26f93872374b48c60a73d189df148a6f99#diff-aa6c341a4b212afc57b49be73e689dc2), but it does not appear in version 1.13.1.", "@Meiyd : I observe that the merge is not included in version 1.13-rc2 or even 1.13.1 however it is not seen on 2.0.0-alpha0 version. Can you please try this and let us know? ", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=27912\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=27912\">No</a>\n"]}, {"number": 27911, "title": "First steps to support --incremental:github-commit", "body": "", "comments": []}, {"number": 27910, "title": "Want to optimize Tensorflow CUDA kernels", "body": "I want to go through Tensorflow's CUDA kernels and optimize them.  It seems like all the CUDA kernels are defined in `tensorflow/core/kernels` and `tensorflow/contrib` with some helper functions in `tensorflow/core/util`. \r\n\r\n1. Is it okay for me to optimize kernels in `tensorflow/core/kernels` and send pull request?\r\n2. now that tensorflow is moving to 2.0, are the CUDA kernels going to also change so dramatically that any improvements to them now could be rendered useless?\r\n3. what are some conventions or practices when writing CUDA kernels? I have read the [contrib.md](https://github.com/tensorflow/tensorflow/blob/master/CONTRIBUTING.md), but there was nothing special on CUDA kernels ( ex. \" Do not change kernel launch configurations \" or \" must support devices of compute capability >= 3.0 \" )\r\n4. must I use `CudaGridRangeX` over regular for loops?\r\n5. Is there way to test and profile each .cu file individually, instead of having to rebuild the entire tensorflow or even having to test all kernels?", "comments": ["I re-issued this as a feature request template. I thought that may be a better fit,", "@ThisIsIsaac,\r\nSorry for the delayed response. Appreciate your interest to **`Optimize`** the **`CUDA`** Kernels. Please feel free to submit a PR, if this Feature is still relevant. Thanks! ", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 27909, "title": "ModelCheckpoint callback error", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): Anaconda\r\n- TensorFlow version (use command below): 1.13.1\r\n- Python version: 3.5\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 7.3.4\r\n- GPU model and memory: GTX 2080 TI\r\n\r\n**Describe the current behavior**\r\nUsing tf.keras, when I fit the model with train dataset and validation dataset created from the tf.dataset, and use ModelCheckpoint with default policy, an error showed up. The error seemed to happen because the callbacks tried to save the model with the same name twice, one at the end of each training epoch, one at the end of each validation epoch twice(using validation dataset). This should not happen because I think the source code already set overwrite = true, but it still happened.\r\n\r\nThe error information:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"C:/Users/nones/iCloudDrive/Courses/DL/Ass8-CNN-MNIST/eager_tf_keras.py\", line 180, in <module>\r\n    fit_model_and_evaluate(model)\r\n  File \"C:/Users/nones/iCloudDrive/Courses/DL/Ass8-CNN-MNIST/eager_tf_keras.py\", line 172, in fit_model_and_evaluate\r\n    validation_steps=40, verbose=verbose)\r\n  File \"C:\\Users\\nones\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 851, in fit\r\n    initial_epoch=initial_epoch)\r\n  File \"C:\\Users\\nones\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 232, in model_iteration\r\n    callbacks.on_epoch_end(epoch, epoch_logs, mode=mode)\r\n  File \"C:\\Users\\nones\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\", line 251, in on_epoch_end\r\n    callback.on_epoch_end(epoch, logs)\r\n  File \"C:\\Users\\nones\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\", line 624, in on_epoch_end\r\n    self.model.save(filepath, overwrite=True)\r\n  File \"C:\\Users\\nones\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\network.py\", line 1334, in save\r\n    save_model(self, filepath, overwrite, include_optimizer)\r\n  File \"C:\\Users\\nones\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\saving.py\", line 152, in save_model\r\n    name, val.shape, dtype=val.dtype)\r\n  File \"C:\\Users\\nones\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\_hl\\group.py\", line 119, in create_dataset\r\n    self[name] = dset\r\n  File \"C:\\Users\\nones\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\_hl\\group.py\", line 287, in __setitem__\r\n    h5o.link(obj.id, self.id, name, lcpl=lcpl, lapl=self._lapl)\r\n  File \"h5py\\_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\r\n  File \"h5py\\_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\r\n  File \"h5py\\h5o.pyx\", line 202, in h5py.h5o.link\r\nRuntimeError: Unable to create link (name already exists)\r\n\r\n```\r\n\r\n**Describe the expected behavior**\r\nAt least the error should not happen when saving model with the same name twice. Better if we can explicitly control when a model is saved.\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n```\r\nimport os\r\n\r\nimport matplotlib.pyplot as plt\r\nimport tensorflow as tf\r\nfrom sklearn.model_selection import train_test_split\r\n\r\ntf.enable_eager_execution()\r\n\r\n# Mnist dataset\r\nIMAGE_ROW, IMAGE_COLS = 28, 28\r\nNUM_CLASSES = 10\r\nBATCH_SIZE = 32\r\n\r\ntemp_dir = './temp'\r\n\r\n\r\ndef get_input_datasets(use_bfloat16=False):\r\n    \"\"\"Creates train and test dataset objects for mnist dataset.\r\n    Args:\r\n      use_bfloat16: Boolean, to determine if input should be cast to bfloat16\r\n    Returns:\r\n      Train dataset, test dataset and input shape, and class names.\r\n    \"\"\"\r\n\r\n    cast_dtype = tf.bfloat16 if use_bfloat16 else tf.float32\r\n    class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\r\n                   'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\r\n\r\n    # the data, split between train and test sets\r\n    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\r\n\r\n    if tf.keras.backend.image_data_format() == 'channels_first':\r\n        x_train = x_train.reshape(x_train.shape[0], 1, IMAGE_ROW, IMAGE_COLS)\r\n        x_test = x_test.reshape(x_test.shape[0], 1, IMAGE_ROW, IMAGE_COLS)\r\n        input_shape = (1, IMAGE_ROW, IMAGE_COLS)\r\n    else:\r\n        x_train = x_train.reshape(x_train.shape[0], IMAGE_ROW, IMAGE_COLS, 1)\r\n        x_test = x_test.reshape(x_test.shape[0], IMAGE_ROW, IMAGE_COLS, 1)\r\n        input_shape = (IMAGE_ROW, IMAGE_COLS, 1)\r\n\r\n    # Preprocess\r\n    x_train = x_train.astype('float32')\r\n    x_test = x_test.astype('float32')\r\n    x_train /= 255\r\n    x_test /= 255\r\n\r\n    y_train = tf.keras.utils.to_categorical(y_train, NUM_CLASSES)\r\n    y_test = tf.keras.utils.to_categorical(y_test, NUM_CLASSES)\r\n\r\n    # build dataset\r\n    # ds_train = tf.data.Dataset.from_tensor_slices({'images': x_train, 'labels': y_train})\r\n    # ds_test = tf.data.Dataset.from_tensor_slices({'images': x_test, 'labels': y_test})\r\n\r\n    x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.1)\r\n\r\n    ds_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))\r\n    ds_valid = tf.data.Dataset.from_tensor_slices((x_valid, y_valid))\r\n    ds_test = tf.data.Dataset.from_tensor_slices((x_test,y_test))\r\n\r\n    # Preprocess dataset\r\n    ds_train = preprocess_dataset(ds_train, cast_dtype)\r\n    ds_valid = preprocess_dataset(ds_valid, cast_dtype)\r\n    ds_test = preprocess_dataset(ds_test, cast_dtype)\r\n\r\n    return ds_train, ds_valid, ds_test, input_shape, class_names\r\n\r\n\r\ndef preprocess_dataset(dataset, cast_dtype):\r\n    dataset = dataset.map(lambda x, y: (tf.cast(x, cast_dtype), y))\r\n    dataset = dataset.shuffle(buffer_size=6000)\r\n    dataset = dataset.repeat()\r\n    dataset = dataset.batch(BATCH_SIZE)\r\n    dataset = dataset.prefetch(buffer_size=1000)\r\n    return dataset\r\n\r\n\r\ndef plot_image(image):\r\n    plt.figure()\r\n    plt.imshow(image)\r\n    plt.colorbar()\r\n    plt.grid(False)\r\n\r\n\r\ndef test_ds(dataset, fname):\r\n    save_dir = os.path.join(temp_dir, \"%s.png\" % fname)\r\n    os.makedirs(temp_dir, exist_ok=True)\r\n    plt.figure()\r\n    for image, label in dataset.take(1):\r\n        for index in range(4):\r\n            plt.subplot(2, 2, index + 1)\r\n            plt.imshow(image[index].numpy().reshape(28, 28))\r\n            plt.xlabel(label[index].numpy())\r\n            plt.grid(False)\r\n    plt.savefig(save_dir, bbox_inches=\"tight\")\r\n    plt.clf()\r\n\r\ndef get_optimizer(optimizer_choice='SGD', learning_rate=0.01, momentum=0.9):\r\n    return {\r\n        'SGD':tf.keras.optimizers.SGD(lr=learning_rate, momentum=momentum),\r\n        'Adam': tf.keras.optimizers.Adam(lr=learning_rate)\r\n    }.get(optimizer_choice, 'SGD')\r\n    #\r\n    # return {\r\n    #     'SGD':tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=momentum),\r\n    #     'Adam': tf.train.AdamOptimizer(learning_rate=learning_rate)\r\n    # }.get(optimizer_choice, 'SGD')\r\n\r\n\r\ndef create_model(input_shapes):\r\n    model = tf.keras.Sequential()\r\n    model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu', input_shape=input_shapes))\r\n    model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\r\n    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\r\n    model.add(tf.keras.layers.Dropout(0.25))\r\n    model.add(tf.keras.layers.Flatten())\r\n    model.add(tf.keras.layers.Dense(128, activation='relu'))\r\n    model.add(tf.keras.layers.Dropout(0.5))\r\n    model.add(tf.keras.layers.Dense(NUM_CLASSES, activation='softmax'))\r\n    return model\r\n\r\n\r\ndef create_model_functional(input_shapes, kernel_size=(3, 3), dropout_rate=0, l2_regularizer=0.1):\r\n    input_tensor = tf.keras.Input(shape=input_shapes)\r\n    layer = tf.keras.layers.Conv2D(filters=64, kernel_size=kernel_size, activation='relu')(input_tensor)\r\n    layer = tf.keras.layers.Conv2D(filters=64, kernel_size=kernel_size, activation='relu')(layer)\r\n    layer = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(layer)\r\n    layer = tf.keras.layers.Dropout(rate=dropout_rate)(layer)\r\n    layer = tf.keras.layers.Flatten()(layer)\r\n    layer = tf.keras.layers.Dense(128, activation='relu')(layer)\r\n    layer = tf.keras.layers.Dropout(rate=dropout_rate)(layer)\r\n    predictions = tf.keras.layers.Dense(NUM_CLASSES, activation='softmax',\r\n                                        kernel_regularizer=tf.keras.regularizers.l2(l=l2_regularizer))(layer)\r\n    model = tf.keras.models.Model(inputs=input_tensor, outputs=predictions)\r\n    return model\r\n\r\ndef fit_model_and_evaluate(model, optimizer_choice='SGD', learning_rate=0.01, verbose=1):\r\n    optimizer = get_optimizer(optimizer_choice=optimizer_choice, learning_rate=learning_rate)\r\n    os.makedirs('graph', exist_ok=True)\r\n    os.makedirs('checkpoint', exist_ok=True)\r\n    file_path = 'checkpoint/model.{epoch:02d}-{val_loss:.4f}-{val_acc:.4f}.hdf5'\r\n    model_checkpoint = tf.keras.callbacks.ModelCheckpoint(file_path)\r\n    # log_dir = os.path.join()\r\n    board = tf.keras.callbacks.TensorBoard(log_dir='./graph', histogram_freq=0,\r\n                                           write_graph=True, write_images=True)\r\n    model.compile(loss=tf.keras.losses.categorical_crossentropy,\r\n                  optimizer=optimizer,\r\n                  metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\r\n    model.fit(x=ds_train, validation_data=ds_valid, epochs=20, steps_per_epoch=468,\r\n              callbacks=[board, model_checkpoint],\r\n              validation_steps=40, verbose=verbose)\r\n    score = model.evaluate(ds_test, steps=10, verbose=0)\r\n    print('Test loss:', score[0])\r\n    print('Test accuracy:', score[1])\r\n\r\nif __name__ == '__main__':\r\n    ds_train, ds_valid, ds_test, input_shapes, class_names = get_input_datasets()\r\n    model = create_model_functional(input_shapes)\r\n    fit_model_and_evaluate(model)\r\n    # test_ds(ds_train, 'train')\r\n    # test_ds(ds_test, 'test')\r\n```\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["If I get rid of the validation data by replacing\r\n```\r\nmodel.fit(x=ds_train, validation_data=ds_valid, epochs=20, steps_per_epoch=468,\r\n              callbacks=[board, model_checkpoint],\r\n              validation_steps=40, verbose=verbose)\r\n```\r\nwith\r\n```\r\nmodel.fit(x=ds_train, epochs=20, steps_per_epoch=468,\r\n              callbacks=[board, model_checkpoint], verbose=verbose)\r\n```\r\nAnother error comes:\r\n```\r\n  File \"C:/Users/nones/iCloudDrive/Courses/DL/Ass8-CNN-MNIST/eager_tf_keras.py\", line 183, in <module>\r\n    fit_model_and_evaluate(model)\r\n  File \"C:/Users/nones/iCloudDrive/Courses/DL/Ass8-CNN-MNIST/eager_tf_keras.py\", line 175, in fit_model_and_evaluate\r\n    callbacks=[board, model_checkpoint], verbose=verbose)\r\n  File \"C:\\Users\\nones\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 851, in fit\r\n    initial_epoch=initial_epoch)\r\n  File \"C:\\Users\\nones\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 232, in model_iteration\r\n    callbacks.on_epoch_end(epoch, epoch_logs, mode=mode)\r\n  File \"C:\\Users\\nones\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\", line 251, in on_epoch_end\r\n    callback.on_epoch_end(epoch, logs)\r\n  File \"C:\\Users\\nones\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\", line 597, in on_epoch_end\r\n    filepath = self.filepath.format(epoch=epoch + 1, **logs)\r\nKeyError: 'val_loss'\r\n```\r\nEverything works fine (with both versions of fit call) if I get rid of ModelCheckpoint callback.", "After set \"save_weight_only\"=True the error went away, but this is not desired.", "I am having the same problem with this one on Colab. However, The jupyter notebook is running Tensorflow 2 Pre-release.  \r\n\r\nhttps://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/tf2_image_retraining.ipynb\r\n\r\nIf I add model.save() at the end or use the ModelCheckpoint callback, I get this error, but save_weights and to_json works, but I really would like the h5 in order to convert it to Tensorflow Lite.\r\n\r\nTried all sorts of suggestions, overwrite=True, tried renaming layers etc.\r\n", "@jvishnuvardhan The code from keras.io (https://keras.io/examples/cifar10_resnet/), if I change everything from keras to those in tensorflow.python.keras, does not suffer from the same error. I dived in my code and noticed that the use of SGD optimizer basically create weight_names with the same value. The keras code does not have this problem.\r\n\r\nHere is how it goes wrong:\r\nI used ` tf.keras.optimizers.SGD(lr=learning_rate, momentum=momentum)`, and then in `tensorflow.python.keras.engine.saving.py`, inside the `save_model` function, this piece of code produce error:\r\n```\r\n        symbolic_weights = getattr(model.optimizer, 'weights')\r\n        if symbolic_weights:\r\n          optimizer_weights_group = f.create_group('optimizer_weights')\r\n          weight_values = K.batch_get_value(symbolic_weights)\r\n          weight_names = []\r\n          for w, val in zip(symbolic_weights, weight_values):\r\n            name = str(w.name)\r\n            weight_names.append(name.encode('utf8'))\r\n          optimizer_weights_group.attrs['weight_names'] = weight_names\r\n          for name, val in zip(weight_names, weight_values):\r\n            param_dset = optimizer_weights_group.create_dataset(\r\n                name, val.shape, dtype=val.dtype)\r\n```\r\n\r\nIn the first line, `symbolic_weights = getattr(model.optimizer, 'weights')` produce a list in which all elements are with the same name: `training/SGD/Variable:0.` In my code, the problem still continues even if I am using Adam. Still invesgating why codes keras.io does not suffer from the same problem.\r\n\r\n\r\n", "@raspberrypisig: The problem related to hub.KerasLayer in your [comment above](https://github.com/tensorflow/tensorflow/issues/27909#issuecomment-484033439) looks like an instance of issue https://github.com/tensorflow/hub/issues/287, which likely needs to be fixed in tensorflow/hub, not tensorflow/tensorflow.", "@atomextranova can you try disabling eager execution? I am facing the same issue and it only happens when eager execution is on.", "Totally agree with @dd1923. I encountered the same issue on Colab. I turned eager execution off and it was solved. However, by doing so I cannot view my datasets without transferring them into numpy array, that is inconvenient and RAM consuming.", "@dd1923 I have the same problem with @liyxi , since I have some projects that requires using eager execution. Also I would consider this to be a bug that need to be fixed.", "Hello ! I am facing the same problem here, with TensorFlow '2.0.0-dev20190527' and python 3.6 : when I call `ModelCheckpoint` callback with `model.fit`:\r\n```\r\n  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\r\n  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\r\n  File \"h5py/h5o.pyx\", line 202, in h5py.h5o.link\r\nRuntimeError: Unable to create link (name already exists)\r\n``` \r\nand everything works fine if I get rid of `ModelCheckpoint`. It occurs both under PyCharm and a jupyter notebook (I am not using Colab).\r\n\r\nOtherwise, I confirm that while disabling eager execution, it works fine.", "I am seeing this error on model.save() after fitting. Disabling eager execution works, but this breaks other code as I am iterating through datasets (which requires eager execution). \r\n\r\nI'm on TF stable (1.13) . If I run my code on colab (with TF 1.14rc1) the problem does not occur. [colab code here](https://colab.research.google.com/drive/1I86y--BZTKxT3Hz_r9Zrry6xKIDFGEoo)", "Any update here?", "Sorry for the delay. Will update here once we learn more. Thanks!", "Having the same issue here, my problem is it work if the model is the first time training. But if the model was load from saved model, then checkpoint will give me a \"KeyError\".\r\n\r\nBTW I'm using tensorflow gpu 2.0.0 version in notebook.", "@lynic Can you please create a new issue with more details and standalone code to reproduce the issue. We could resolve faster if we have a standalone code for your use case. Thanks!", "same bug with tensorflow 2.0", "@atomextranova Looks like this was resolved in recent stable version `TF2.4`. I ran your code (with two small modifications) and everything worked as expected. Please check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/b13a14584b101aeaa091dee26fd7784d/untitled.ipynb).\r\n\r\nThe following are the two small changes from \r\n```\r\n1. tf.enable_eager_execution()\r\n2. file_path = 'checkpoint/model.{epoch:02d}-{val_loss:.4f}-{val_acc:.4f}.hdf5'\r\n```\r\n\r\nto \r\n\r\n```\r\n1. # tf.enable_eager_execution()\r\n2. file_path = 'checkpoint/model.{epoch:02d}-{val_loss:.4f}-{val_accuracy:.4f}.hdf5'\r\n```\r\n\r\nI am closing this issue as this was resolved. Please feel free to reopen if I am mistaken. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/27909\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/27909\">No</a>\n"]}, {"number": 27908, "title": "Fix index bug in RemoveStackStridedSliceSameAxis", "body": "This arithmetic optimizer pass incorrectly used the Pack op's input rank (instead of output rank) as the limit of its axis attribute.\r\nI added a new test to check that it now works on scalar inputs and with negative axis values.\r\n\r\nThis probably went unnoticed because it only prints a warning on failure (and as of https://github.com/tensorflow/tensorflow/commit/8871d29c8f21317b5a421c4b143790c142f01d17 it only prints at VLOG(2)).\r\n\r\nFor reference, the correct range of the Pack op's axis value is documented here:\r\nhttps://github.com/tensorflow/tensorflow/blob/r1.13/tensorflow/core/api_def/base_api/api_def_Pack.pbtxt#L22", "comments": ["@ebrevdo Could you PTAL and approve.", "@ebrevdo Could you PTAL and approve.", "Thanks; looks good!", "We have to roll this back because it caused a test failure.  I'll try to identify the root cause.", "(internal test failure)"]}, {"number": 27907, "title": "Test case updated with unpack Op struct", "body": "Missing Unpack Op added", "comments": ["@aselle Could you PTAL and approve", "@aselle Could you PTAL and approve", "Can one of the admins verify this patch?", "Similar changes are merged by this [PR](https://github.com/tensorflow/tensorflow/pull/35296) , closing this. Thank you."]}, {"number": 27906, "title": "could not create a dilated convolution forward descriptor, in file tensorflow/core/kernels/mkl_conv_ops.cc:1111", "body": "When I tried to run some yolov3 codes, I always got the following error:\r\n`Traceback (most recent call last):\r\n\r\n  File \"<ipython-input-16-cd2eeb60d39b>\", line 1, in <module>\r\n    runfile('C:/Users/10137/Desktop/learn/python/yolov3_keras_qwe/train.py', wdir='C:/Users/10137/Desktop/learn/python/yolov3_keras_qwe')\r\n\r\n  File \"C:\\Users\\10137\\Anaconda3\\lib\\site-packages\\spyder_kernels\\customize\\spydercustomize.py\", line 786, in runfile\r\n    execfile(filename, namespace)\r\n\r\n  File \"C:\\Users\\10137\\Anaconda3\\lib\\site-packages\\spyder_kernels\\customize\\spydercustomize.py\", line 110, in execfile\r\n    exec(compile(f.read(), filename, 'exec'), namespace)\r\n\r\n  File \"C:/Users/10137/Desktop/learn/python/yolov3_keras_qwe/train.py\", line 190, in <module>\r\n    _main()\r\n\r\n  File \"C:/Users/10137/Desktop/learn/python/yolov3_keras_qwe/train.py\", line 65, in _main\r\n    callbacks=[logging, checkpoint])\r\n\r\n  File \"C:\\Users\\10137\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\", line 91, in wrapper\r\n    return func(*args, **kwargs)\r\n\r\n  File \"C:\\Users\\10137\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1418, in fit_generator\r\n    initial_epoch=initial_epoch)\r\n\r\n  File \"C:\\Users\\10137\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\", line 217, in fit_generator\r\n    class_weight=class_weight)\r\n\r\n  File \"C:\\Users\\10137\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1217, in train_on_batch\r\n    outputs = self.train_function(ins)\r\n\r\n  File \"C:\\Users\\10137\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 2715, in __call__\r\n    return self._call(inputs)\r\n\r\n  File \"C:\\Users\\10137\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 2675, in _call\r\n    fetched = self._callable_fn(*array_vals)\r\n\r\n  File \"C:\\Users\\10137\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1439, in __call__\r\n    run_metadata_ptr)\r\n\r\n  File \"C:\\Users\\10137\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\", line 528, in __exit__\r\n    c_api.TF_GetCode(self.status.status))\r\n\r\nAbortedError: Operation received an exception:Status: 3, message: could not create a dilated convolution forward descriptor, in file tensorflow/core/kernels/mkl_conv_ops.cc:1111\r\n\t [[{{node conv2d_2/convolution}}]]`\r\n", "comments": ["I am also getting the same error on TensorFlow 1.13.1. There appears to be a similar issue (#24650) that was to be resolved in 1.13.1 but the error line was different in that case.", "#24650 was not resolved in 1.13.1", "I downgraded the keras to 2.1.5 and the error didn't occur again. This may help.", "Hi nm46nm, thanks it worked but TensorFlow got downgraded to 1.9. I will try to apply TF 1.12 and see if it works noting that this was a non-issue in the latest master branch (thanks Yuxin)", "@nm46nm and @ianlokh : Is this resolved? Please let us know. Thanks!", "Downgrading to tensorflow 1.9 worked fine for me", "That's great. We will be closing the issue since it is resolved. Thanks!", "Hi achandraa, yes downgrading to TF 1.9 resolved my issue. As a side note, I upgraded TF to 1.12 and it worked as well.", "> @nm46nm and @ianlokh : Is this resolved? Please let us know. Thanks!\r\n\r\nI just use the version 2.1.5 in which there is no error. Haven't tried new version again.", "According to commits above, i tried to downgrade tensorflow from 1.13 to 1.12 and it also worked for me.", "I tried to update tensorflow from 1.13.1 to 1.14 and it work for me."]}, {"number": 27905, "title": "[TF-TRT] Changes to the MatMul and Binary Converters", "body": "This change consists of 2 major parts:\r\n1. Changes to the MatMul converter to use IMatrixMultiplyLayer instead of IFullyConnectedLayer where it is advantageous. The latter requires inputs to be at least rank 3, whereas the former does not. The IFullyConnectedLayer is only used when either int8 mode is specified (MM does not support int8) or when the input is already rank >= 3. \r\n2. Changes to the Binary converter to use the IElementWiseLayer instead of IScaleLayer. Once again, the latter requires inputs to be at least rank 3, whereas the former does not. Replacing it greatly simplifies the conversion logic and broadens support for some ops. ", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F27905) for more info**.\n\n<!-- need_sender_cla -->", "\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F27905) for more info**.\n\n<!-- need_sender_cla -->", "@pranavm-nvidia thank you for your contribution , can you please sign CLA ", "I've signed the CLA", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F27905) for more info**.\n\n<!-- ok -->", "I've created a new PR for the MatMul converter changes. I will remove them from this PR in the next commit (so this will only contain the binary converter/broadcasting changes)", "Closing this w.r.t #28805"]}, {"number": 27904, "title": "saved_model.load gives KeyError in 2.0.0 Same model loads fine in 1.13", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- TensorFlow installed from (source or binary):binary\r\n- TensorFlow version (use command below): 2.0.0\r\n- Python version: 3.6.5\r\n\r\n\r\n**Describe the current behavior**\r\nI am trying to load a model saved in 1.x in 2.0.0. Here is the model: https://storage.googleapis.com/marco-168219-model/savedmodel.zip\r\n\r\nThis is the error I am getting: KeyError: <tf.Tensor 'map/while/Switch_1:0' shape=() dtype=float32>\r\n\r\nThe same model loads fine in 1.13\r\n\r\n**Describe the expected behavior**\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\nmodel = tf.saved_model.load(model_dir)\r\n\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["Could you try a more recent 2.0 nightly? This SavedModel is loading for me in 2.0.0-dev20190416. It was likely fixed by https://github.com/tensorflow/tensorflow/commit/36611db67d01b77a59ecf120d9cfedede4dc29e8#diff-1c53130b8026996623d861b2d18d60ca", "Yes, it works with today's nightly. Thank you!"]}, {"number": 27903, "title": "Pylint checks from ci_sanity.sh `--incremental`", "body": "Currently we kind of support `--incremental` to run incremental sanity checks. In reality, we still run it for all files:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/0e4117f67192a140466ba66513035e24bbd1a474/tensorflow/tools/ci_build/ci_sanity.sh#L137\r\n\r\n```\r\n# For incremental builds, we still check all Python files in cases there\r\n# are function signature changes that affect unchanged Python files.\r\n```\r\n\r\nWould it make sense to just clean it up or what is the current idea? \r\n\r\nI started to add an incremental check for since a specific commit, so one can run checks for changes across multiple commits.\r\n\r\n", "comments": ["Something along these lines https://github.com/lc0/tensorflow/pull/1 - just to visualize the idea", "This question is better asked on StackOverflw.since it is not a bug or feature request. There is also a larger community that reads questions there. Thanks!", "I mean, it's a feature for incremental CI checks :) and CI checks are used for people contributing to TensorFlow", "I think your suggestion makes sense.\r\nCould you make a PR and assign it to @yifeif "]}, {"number": 27902, "title": "ResizeBilinear FP16 CUDA Kernel Support", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 1.13.1\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10/7.4.1\r\n- GPU model and memory: NVIDIA Titan V\r\n\r\n\r\n**Describe the current behavior**\r\nThe resize bilinear CUDA kernel omits FP16 support. The implementation accepts a templated tensor type, but then internally performs a hard-cast to a float during filtering, which is then written to a float tensor. Couldn't the templated type be propagated to the output as in resize nearest neighbor?\r\n\r\nThis causes a significant and anomalous perf drop when converting from FP32 to FP16 in networks that utilize this operation.\r\n\r\n\r\n**Describe the expected behavior**\r\nAn FP16 variant would be implemented alongside the FP32 CUDA implementation, with performance scaling appropriately between the two.\r\n", "comments": ["In order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!", "At its core this is a feature request, not a bug report. I just happened upon the missing feature through a performance drop. \r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/resize_bilinear_op_gpu.cu.cc#L350", "I did a quick-n-dirty conversion yesterday to just accept a second templated parameter throughout the call-stack and registration code - it just casts it at the beginning/end of the kernel. It built successfully but haven't gotten time to test it at all. \r\n\r\nIf it works I'll test the performance against a version that casts and performs all computations in the template type to determine whether its worth the additional code changes.\r\n\r\nThe commit is visible on my TF fork here: https://github.com/mhurliman/tensorflow/commit/6d807626656708d833552c888a749b93e7a726b6", "any update? @mhurliman", "@mhurliman, I'd be happy to review a PR that fixes this.", "I've been off this for a long time, haha. I don't know the state of this code in the main repository now. Has anything changed with the bilinear upscale kernel since May?", "I guess the update would be that I didn't get to testing the performance. It's a pretty simple change, should be able to cherry-pick the commit easily enough and create a small test network. ", "@mhurliman Great! Really need this feature!", "@mhurliman,\r\nSorry for the delayed response. Can you please let us know if the functionality you are looking for can be achieved using [Post Training Quantization](https://www.tensorflow.org/lite/performance/post_training_quantization), as it supports **`Floating Point 16 operations`** with **`GPU`**? Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 27901, "title": "Fix typo in tensorrt_include", "body": "", "comments": ["Also @chsigg in case there is a known issue that was caused by this."]}, {"number": 27900, "title": "pydoc.ErrorDuringImport: problem in tensorflow.keras - ImportError: cannot import name 'Layer'", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Centos 7\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version: 1.13.1\r\n- Python version: 3.6.8\r\n- Installed using virtualenv? pip? conda?: Conda\r\n- Bazel version (if compiling from source): Nope\r\n- GCC/Compiler version (if compiling from source): Nope\r\n- CUDA/cuDNN version: CUDA Version 10.1.105 /7\r\n\r\n- GPU model and memory:  GeForce GTX 1080 Ti and  11178 MiB\r\n\r\n\r\n**Describe the problem**\r\nI get the error when I was importing keras.\r\n\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n    `from tensorflow.python.estimator.keras import Layer`\r\n\r\n\r\n**Any other info / logs**\r\n`Traceback (most recent call last):\r\n  File \"/home/bjayakumar/.conda/envs/py36/lib/python3.6/pydoc.py\", line 343, in safeimport\r\n    module = __import__(path)\r\n  File \"/home/bjayakumar/.conda/envs/py36/lib/python3.6/site-packages/tensorflow/keras/__init__.py\", line 20, in <module>\r\n    from . import layers\r\n  File \"/home/bjayakumar/.conda/envs/py36/lib/python3.6/site-packages/tensorflow/keras/layers/__init__.py\", line 8, in <module>\r\n    from tensorflow.python.estimator.keras import Layer\r\nImportError: cannot import name 'Layer'`\r\n\r\n\r\nThis solution is not working for me.\r\n**https://github.com/tensorflow/tensorflow/issues/24847**", "comments": ["Can you try with,\r\n```from tensorflow.keras.layers import Layer```", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "> Can you try with,\r\n> `from tensorflow.keras.layers import Layer`\r\n\r\nI also have same issue. When I tried this I got following error\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/shivam/.local/lib/python3.6/site-packages/tensorflow/keras/__init__.py\", line 20, in <module>\r\n    from . import layers\r\n  File \"/home/shivam/.local/lib/python3.6/site-packages/tensorflow/keras/layers/__init__.py\", line 8, in <module>\r\n    from tensorflow.python.estimator.keras import Layer\r\nImportError: cannot import name 'Layer'", "> Can you try with,\r\n> `from tensorflow.keras.layers import Layer`\r\n\r\nI tried that and got this error:\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nImportError                               Traceback (most recent call last)\r\n<ipython-input-4-2c540853ba16> in <module>\r\n----> 1 from tensorflow.keras.layers import Layer\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\keras\\__init__.py in <module>\r\n     18 from tensorflow.keras import estimator\r\n     19 from tensorflow.keras import initializers\r\n---> 20 from tensorflow.keras import layers\r\n     21 from tensorflow.keras import losses\r\n     22 from tensorflow.keras import metrics\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\keras\\layers\\__init__.py in <module>\r\n      6 from __future__ import print_function\r\n      7 \r\n----> 8 from tensorflow.python.estimator.keras import Layer\r\n      9 from tensorflow.python.keras import Input\r\n     10 from tensorflow.python.keras.applications.densenet import Activation\r\n\r\nImportError: cannot import name 'Layer' from 'tensorflow.python.estimator.keras' (C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\keras.py)\r\n```\r\nI fixed it by upgrading to the latest version of tensorflow.\r\n", "try to downgrade keras=2.3.0 with tensorflow=2.2.0"]}, {"number": 27898, "title": "Patch loss scale to ignore None gradients", "body": "Attention @reedwm \r\n\r\n- Do not pass gradients through update() if they are None\r\n- Add test to make sure a None gradient is ignored", "comments": ["Thanks for the feedback, let me know if I can change anything else", "Thanks for the fix!", "Sure, thanks for your help!"]}, {"number": 27897, "title": "Spurious deprecation warnings", "body": "**System information**\r\n\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): gLinux\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): tf-nightly-2.0-preview-20190416-py2.7\r\n- TensorFlow version (use command below): 2.0.0-dev20190416\r\n- Python version: 2.7.16rc1\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**Describe the current behavior**\r\n\r\nWhen using `keras.callbacks.TensorBoard` or `keras.models.Sequential`, a\r\ndeprecation warning is emitted instructing the user to use the same\r\nsymbol that they\u2019re already using:\r\n\r\n>   - \u201cThe name keras.callbacks.TensorBoard is deprecated. Please use keras.callbacks.TensorBoard instead.\u201d\r\n>   - \u201cThe name keras.models.Sequential is deprecated. Please use keras.models.Sequential instead.\u201d\r\n\r\n**Describe the expected behavior**\r\n\r\nNo deprecation warning should be emitted.\r\n\r\n**Code to reproduce the issue**\r\n\r\n```\r\n$ cat /tmp/repro.py; echo\r\nimport tensorflow as tf\r\nprint(tf.__version__)\r\ntf.keras.callbacks.TensorBoard\r\ntf.keras.models.Sequential\r\n\r\n$ python /tmp/repro.py\r\n2.0.0-dev20190416\r\nWARNING: Logging before flag parsing goes to stderr.\r\nW0416 11:29:00.042920 139891507525376 deprecation_wrapper.py:76] From /tmp/repro.py:3: The name keras.callbacks.TensorBoard is deprecated. Please use keras.callbacks.TensorBoard instead.\r\n\r\nW0416 11:29:00.043119 139891507525376 deprecation_wrapper.py:76] From /tmp/repro.py:4: The name keras.models.Sequential is deprecated. Please use keras.models.Sequential instead.\r\n\r\n```\r\n", "comments": ["Looks like this happens with lots of symbols:\r\n\r\n```\r\n$ cat /tmp/repro.py; echo\r\nimport tensorflow as tf\r\nprint(tf.__version__)\r\ntf.io.gfile.exists\r\ntf.errors.OpError\r\ntf.train.Example\r\n\r\n$ python /tmp/repro.py\r\n2.0.0-dev20190416\r\nWARNING: Logging before flag parsing goes to stderr.\r\nW0416 12:01:54.716809 140711866500864 deprecation_wrapper.py:76] From /tmp/repro.py:3: The name io.gfile.exists is deprecated. Please use io.gfile.exists instead.\r\n\r\nW0416 12:01:54.716949 140711866500864 deprecation_wrapper.py:76] From /tmp/repro.py:4: The name errors.OpError is deprecated. Please use errors.OpError instead.\r\n\r\nW0416 12:01:54.716995 140711866500864 deprecation_wrapper.py:76] From /tmp/repro.py:5: The name train.Example is deprecated. Please use train.Example instead.\r\n\r\n```", "Makes sense: the warnings are there to inform you that on the next version of TensorFlow those symbols will no longer be present, so you should update your code to the new API.\r\n\r\nSee also: #27045, #27023, #27016, #26844, #26151, #26149, #26144, and many other similar issues.", "Hmm, as far as I can tell I _am_ using the new APIs, and the warnings\r\nare telling me to migrate to the same APIs that I\u2019m already using:\r\n\r\n> \u201cThe name **keras.models.Sequential** is deprecated. Please use\r\n> **keras.models.Sequential** instead.\u201d\r\n\r\nHow should I change \u201c`tf.keras.models.Sequential`\u201d to avoid a warning?\r\n", "Oh, my bad, I didn't notice that. Sorry", "No worries; thanks.", "Thank you for catching and sorry for the trouble! Fix is on the way.", "Should be fixed by this commit: e84d155152ab5a187d2c0e4c5eea6a73df3789e1 \r\nLet me know if you are still seeing issues!"]}]