[{"number": 46879, "title": "Keras UpSampling2D layer is converted with a `shape` op that should be constant-folded away", "body": "### 1. System information\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS 10.15.6\r\n- TensorFlow installation (pip package or built from source): PyPI pip package\r\n- TensorFlow library (version, if pip package or github SHA, if built from source): 2.4.1\r\n\r\n### 2. Code\r\n\r\nProvide code to help us reproduce your issues using one of the following options:\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\nm = tf.keras.models.Sequential(\r\n    [\r\n        tf.keras.layers.Input((32, 32, 3)),\r\n        tf.keras.layers.Conv2D(32, (3, 3)),\r\n        tf.keras.layers.UpSampling2D((2, 2), interpolation=\"nearest\"),\r\n    ]\r\n)\r\n\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(m)\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nwith open(\"tmp-model.tflite\", \"wb\") as f:\r\n    f.write(converter.convert())\r\n```\r\n\r\n### 3. Failure after conversion\r\n\r\nThe converted TFLite model looks like this:\r\n\r\n![image](https://user-images.githubusercontent.com/7688302/106741589-cde9de80-6613-11eb-96c0-60dfd88c3d61.png)\r\n\r\nSince the shape is statically known, I would expect the right-hand branch to be constant folded.\r\n\r\nPossibly related to #25086.", "comments": ["Thanks for the suggestion! In the above case, it can be constant-foled away. We will take this as a feature request and update this thread when there is a progress regarding this optimization effort. We would welcome contributions for this performance improvement's opportunity from the community as well.", "The model has dynamic batch which disables constant folding.\r\nKeras by default has dynamic batch size. \r\nSee this [answer](https://github.com/tensorflow/tensorflow/issues/43882#issuecomment-731636562)", "For example changing this line in your model will make it constant and the ops will go away\r\n```\r\ntf.keras.layers.Input((32, 32, 3), batch_size=1),\r\n```", "Fair enough, that does indeed work to enable constant folding. Thanks for your help :)\r\n\r\nFor this specific case, whether or not the batch size is static vs dynamic doesn't make any difference to whether or not the right-hand-side `shape`/`strided-slice` can be constant folded, because the shape is only being taken to get the spatial h/w info, which is static.", "@AdamHillier That's true. I think my reply confused multiple people, sorry about this.\r\n \r\nWhat i meant here is that you don't need to wait for any changes/features to land. Once you fix the batch size this should go away as expected.\r\n\r\nThanks"]}, {"number": 46878, "title": "RaggedTensor support for mean_squared_logarithmic_error.", "body": "Follow up to #46283.", "comments": ["@pedro-r-marques can you please check sanity build failures ?", "@rthadur Addressed pylint error. Would you please re-trigger the CI ? thanks.\r\n\r\n"]}, {"number": 46877, "title": "Update README.md :Added TensorFlow: Advanced Techniques Specialization to resources tab", "body": "Added TensorFlow: Advanced Techniques Specialization to resources tab. Extremely helpful specialization by Laurence Moroney for more in depth knowledge of TensorFlow.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F46877) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "Requested changes done."]}, {"number": 46876, "title": "Add support for RaggedTensors to mean_absolute_percentage_error.", "body": "Follow up to #46875.", "comments": []}, {"number": 46875, "title": "Add ragged tensor support to mean_absolute_error.", "body": "Use the same approach as PR #46283 for mean_absolute_error.\r\n\r\nMaintainers: I'm assuming that you would prefer the smallest possible PRs in order to extend the support across all/most predefined metric functions; even though that increases is overhead from your side in dealing with reviews / CI-handholding. Please advise if that is not the case.", "comments": []}, {"number": 46874, "title": "fix typo", "body": "", "comments": ["We will not be encouraging one liner grammatical changes as this is expensive process, thank you for your interest.\r\nCC @mihaimaruseac"]}, {"number": 46873, "title": "TFLu: Add UInt8 support for logistic operator", "body": "This patch is to add UInt8 support for logistic operator in TFLu.\r\n\r\nTried TFLu + ssd mobilenet v1 quantized model on i.mx8mp's Cortex-M7 core.\r\n\r\nThe related issue is https://github.com/tensorflow/tensorflow/issues/46882 .", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n", "\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F46873) for more info**.\n\n<!-- need_sender_cla -->", "@alisonwh  Can you please sign CLA. Thanks!", "> @alisonwh Can you please sign CLA. Thanks!\r\n\r\n@gbaned Sure, I signed it.", "@googlebot I signed it!", "> It seems this PR only contains kernel changes but no converter / quantization tool changes. Don't we need to change the code to produce models with UInt8 logistic operators?\r\n\r\nI used ssd mobilenet quant model from https://tfhub.dev/tensorflow/lite-model/ssd_mobilenet_v1/1/default/1. It is using UInt8 logistic operator. So I didn't think about producing models by myself.", "@alisonwh  Can you please check @daverim's comments and keep us posted ? Thanks!", "@alisonwh  Any update on this PR? Please. Thanks!", "@daverim  Can you please assist on above comments from @alisonwh. Thanks!", "@daverim Any update on this PR? Please. Thanks!", "@daverim Any update on this PR? Please. Thanks!", "@alisonwh  Can you please resolve conflicts? Thanks!", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on."]}, {"number": 46872, "title": "[BUG]ConvertGraphDefToGraph return an invalid tensorflow::Graph", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n> Binary\r\n- TensorFlow version (use command below):\r\n> 1.15 and 2.4.0\r\n- Python version:\r\n> 3.7.5\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\n\r\nI want to use the C++ API to process my pbtxt model. After the GraphDef file is correctly loaded from the file, I continue to call tensorflow::ConvertGraphDefToGraph to convert my model into a tensorflow::Graph object. The call is successful, however, nodes on graph objects are invalid. For example, core dump occurs when in_edge is invoked.\r\n\r\nFor further verification, I register a pass optimizer for the POST_REWRITE_FOR_EXEC phase on the TF of version 2.4, which prints only the input graph,\r\n\r\n> part of my pass\r\n\r\n```C\r\n    LOG(INFO) << \"------------------------------------Inputs------------------------------------\";\r\n    const tensorflow::EdgeSet &in_edges = node->out_edges();\r\n    for (auto edge : in_edges) {\r\n      if (edge == nullptr) {\r\n        LOG(INFO) << \"    nullptr\";\r\n      } else {\r\n        LOG(INFO) << \"    \" << edge->src()->DebugString();\r\n      }\r\n    }\r\n\r\n    LOG(INFO) << \"------------------------------------Outputs------------------------------------\";\r\n    const tensorflow::EdgeSet &out_edges = node->out_edges();\r\n    for (auto edge : out_edges) {\r\n      if (edge == nullptr) {\r\n        LOG(INFO) << \"    nullptr\";\r\n      } else {\r\n        LOG(INFO) << \"    \" << edge->dst()->DebugString();\r\n      }\r\n    }\r\n```\r\n\r\n> python test code\r\n\r\n```PYTHON\r\n@tf.function\r\ndef f(a, b):\r\n  return a + b\r\n\r\nf(tf.constant(1), tf.constant(2))\r\n```\r\n> and the result\r\n\r\n```\r\n{name:'_SOURCE' id:0 source}\r\n------------------------------------Inputs------------------------------------\r\n    {name:'_SOURCE' id:0 source}\r\n    {name:'_SOURCE' id:0 source}\r\n    nullptr\r\n------------------------------------Outputs------------------------------------\r\n    {name:'a' id:2 op device:{/job:localhost/replica:0/task:0/device:CPU:0} def:{{{node a}} = _Arg[T=DT_INT32, _output_shapes=[[]], _user_specified_name=\"a\", index=0, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()}}\r\n    {name:'b' id:3 op device:{/job:localhost/replica:0/task:0/device:CPU:0} def:{{{node b}} = _Arg[T=DT_INT32, _output_shapes=[[]], _user_specified_name=\"b\", index=1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()}}\r\n    nullptr\r\n{name:'b' id:3 op device:{/job:localhost/replica:0/task:0/device:CPU:0} def:{{{node b}} = _Arg[T=DT_INT32, _output_shapes=[[]], _user_specified_name=\"b\", index=1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()}}\r\n------------------------------------Inputs------------------------------------\r\n    nullptr\r\n------------------------------------Outputs------------------------------------\r\n    nullptr\r\n{name:'a' id:2 op device:{/job:localhost/replica:0/task:0/device:CPU:0} def:{{{node a}} = _Arg[T=DT_INT32, _output_shapes=[[]], _user_specified_name=\"a\", index=0, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()}}\r\n------------------------------------Inputs------------------------------------\r\n    nullptr\r\n------------------------------------Outputs------------------------------------\r\n    nullptr\r\n{name:'add' id:4 op device:{/job:localhost/replica:0/task:0/device:CPU:0} def:{{{node add}} = AddV2[T=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](a, b)}}\r\n------------------------------------Inputs------------------------------------\r\n    nullptr\r\n------------------------------------Outputs------------------------------------\r\n    nullptr\r\n{name:'identity_RetVal' id:5 op device:{/job:localhost/replica:0/task:0/device:CPU:0} def:{{{node identity_RetVal}} = _Retval[T=DT_INT32, index=0, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](add)}}\r\n------------------------------------Inputs------------------------------------\r\n    nullptr\r\n------------------------------------Outputs------------------------------------\r\n    nullptr\r\n{name:'_SINK' id:1 sink}\r\n------------------------------------Inputs------------------------------------\r\n    nullptr\r\n------------------------------------Outputs------------------------------------\r\n    nullptr\r\n```\r\n\r\nObviously, the edges on the figure are completely disordered. For example, AddV2 has the nullptr edge* input in both the input and output.\r\n\r\nI have also verified the ConvertGraphDefToGraph interface and the result is the same as that described above. I'm sure this function isn't working properly.\r\n\r\n**Describe the expected behavior**\r\n\r\nConvertGraphDefToGraph should return a valid tensorflow::Graph object, including complete input and output edge information.\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46872\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46872\">No</a>\n", "sorry i use output_edge to get input..."]}, {"number": 46871, "title": "RuntimeError: Unable to create link (name already exists)", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): kaggle kernel\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below): 2.4.0\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\n\r\nThis is my  Notebook:\r\n[Kaggle Notebook](https://www.kaggle.com/shanmukh05/cassave-leaf-diseases-tpu-final/edit/run/53396178)\r\nThis is the main model I am using:\r\n![error](https://user-images.githubusercontent.com/65073329/106710547-1e653a00-661c-11eb-856a-b8619f0d5a80.png)\r\n\r\n**I am getting following error as mentioned in below link**\r\n[Github Issue](https://github.com/tensorflow/tensorflow/issues/41021)\r\n![error_1](https://user-images.githubusercontent.com/65073329/106710888-ab0ff800-661c-11eb-97cf-6102280e8009.png)\r\n\r\n", "comments": ["@shanmukh05 \r\nPlease share error log and info shared as screenshots in text format for us and any other user who faces problem it would be helpful.", "**Code (This is the main model. Details of dataset are in notebook I mentioned earlier)**\r\n\r\n> I am using TPU\r\n\r\n``` \r\n    IMAGE_SIZE = [300,300]\r\n    import tensorflow as tf\r\n    efficient_net = {\r\n        0 : tf.keras.applications.EfficientNetB0(weights=\"imagenet\",include_top=False ,input_shape=[*IMAGE_SIZE, 3]),\r\n        1 : tf.keras.applications..EfficientNetB1(weights=\"imagenet\",include_top=False ,input_shape=[*IMAGE_SIZE, 3]),\r\n    }\r\n\r\n    output = {}\r\n    inputs = tf.keras.Input(shape=(*IMAGE_SIZE, 3))\r\n    \r\n    ls =   [0,1]      #[3,5,7]  \r\n\r\n    for i in ls:\r\n        pretrained_model = efficient_net[i]\r\n        x = pretrained_model(inputs)\r\n        x = tf.keras.layers.GlobalAveragePooling2D()(x)\r\n        output[i] = tf.keras.layers.Dense(CLASSES,activation=\"sigmoid\", dtype='float32')(x)\r\n        \r\n    outputs = tf.keras.layers.average(list(output.values()))\r\n    model = tf.keras.Model(inputs, outputs)\r\n    optimizer = tf.keras.optimizers.Adam(lr=lr)\r\n    \r\n    loss = tf.keras.losses.CategoricalCrossentropy()\r\n        \r\n    metrics = [\r\n       tf.keras.metrics.CategoricalAccuracy(name='categorical_accuracy')\r\n    ]\r\n\r\n    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\r\n    cpk_path = './best_model.h5'\r\n    \r\n    checkpoint = tf.keras.callbacks.ModelCheckpoint(\r\n        filepath=cpk_path,\r\n        monitor='val_categorical_accuracy',\r\n        mode='max',\r\n        save_best_only=True,\r\n        verbose=1,\r\n    )\r\n\r\n    reducelr = tf.keras.callbacks.ReduceLROnPlateau(\r\n        monitor='val_categorical_accuracy',\r\n        mode='max',\r\n        factor=0.1,\r\n        patience=3,\r\n        verbose=0\r\n    )\r\n\r\n    earlystop = tf.keras.callbacks.EarlyStopping(\r\n        monitor='val_categorical_accuracy',\r\n        mode='max',\r\n        patience=15, \r\n        verbose=1\r\n    )\r\n    \r\n   callbacks = [checkpoint, reducelr, earlystop] \r\n   EPOCHS= 3\r\n   VERBOSE =1\r\n\r\n  STEPS_PER_EPOCH = NUM_TRAINING_IMAGES//(BATCH_SIZE)\r\n\r\n  tf.keras.backend.clear_session()\r\n  with strategy.scope():\r\n    \r\n  model = create_model()\r\n  model = compile_model(model, lr=0.0001)\r\n   \r\n  callbacks = create_callbacks()\r\n    \r\n  history = model.fit(train_ds, \r\n                        epochs=EPOCHS,\r\n                        callbacks=callbacks,\r\n                        validation_data = valid_ds,\r\n                        steps_per_epoch = STEPS_PER_EPOCH,\r\n                        verbose=VERBOSE)\r\n ```\r\n\r\n\r\n**Error Log**\r\n\r\n  ```Downloading data from https://github.com/Callidior/keras-applications/releases/download/efficientnet/efficientnet-b0_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5\r\n16809984/16804768 [==============================] - 0s 0us/step\r\nDownloading data from https://github.com/Callidior/keras-applications/releases/download/efficientnet/efficientnet-b1_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5\r\n27164672/27164032 [==============================] - 0s 0us/step\r\nEpoch 1/3\r\n146/146 [==============================] - 165s 387ms/step - loss: 1.1287 - categorical_accuracy: 0.6490 - val_loss: 0.5770 - val_categorical_accuracy: 0.8000\r\n\r\nEpoch 00001: val_categorical_accuracy improved from -inf to 0.80000, saving model to ./best_model.h5\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-17-c8fdc0a8823e> in <module>\r\n     17                         validation_data = valid_ds,\r\n     18                         steps_per_epoch = STEPS_PER_EPOCH,\r\n---> 19                         verbose=VERBOSE)\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\r\n   1143           epoch_logs.update(val_logs)\r\n   1144 \r\n-> 1145         callbacks.on_epoch_end(epoch, epoch_logs)\r\n   1146         training_logs = epoch_logs\r\n   1147         if self.stop_training:\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py in on_epoch_end(self, epoch, logs)\r\n    426     for callback in self.callbacks:\r\n    427       if getattr(callback, '_supports_tf_logs', False):\r\n--> 428         callback.on_epoch_end(epoch, logs)\r\n    429       else:\r\n    430         if numpy_logs is None:  # Only convert once.\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py in on_epoch_end(self, epoch, logs)\r\n   1342     # pylint: disable=protected-access\r\n   1343     if self.save_freq == 'epoch':\r\n-> 1344       self._save_model(epoch=epoch, logs=logs)\r\n   1345 \r\n   1346   def _should_save_on_batch(self, batch):\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py in _save_model(self, epoch, logs)\r\n   1394                     filepath, overwrite=True, options=self._options)\r\n   1395               else:\r\n-> 1396                 self.model.save(filepath, overwrite=True, options=self._options)\r\n   1397             else:\r\n   1398               if self.verbose > 0:\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py in save(self, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\r\n   2000     # pylint: enable=line-too-long\r\n   2001     save.save_model(self, filepath, overwrite, include_optimizer, save_format,\r\n-> 2002                     signatures, options, save_traces)\r\n   2003 \r\n   2004   def save_weights(self,\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/saving/save.py in save_model(model, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\r\n    152           'or using `save_weights`.')\r\n    153     hdf5_format.save_model_to_hdf5(\r\n--> 154         model, filepath, overwrite, include_optimizer)\r\n    155   else:\r\n    156     saved_model_save.save(model, filepath, overwrite, include_optimizer,\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/saving/hdf5_format.py in save_model_to_hdf5(model, filepath, overwrite, include_optimizer)\r\n    129     if (include_optimizer and model.optimizer and\r\n    130         not isinstance(model.optimizer, optimizer_v1.TFOptimizer)):\r\n--> 131       save_optimizer_weights_to_hdf5_group(f, model.optimizer)\r\n    132 \r\n    133     f.flush()\r\n\r\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/saving/hdf5_format.py in save_optimizer_weights_to_hdf5_group(hdf5_group, optimizer)\r\n    594     for name, val in zip(weight_names, weight_values):\r\n    595       param_dset = weights_group.create_dataset(\r\n--> 596           name, val.shape, dtype=val.dtype)\r\n    597       if not val.shape:\r\n    598         # scalar\r\n\r\n/opt/conda/lib/python3.7/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds)\r\n    137             dset = dataset.Dataset(dsid)\r\n    138             if name is not None:\r\n--> 139                 self[name] = dset\r\n    140             return dset\r\n    141 \r\n\r\n/opt/conda/lib/python3.7/site-packages/h5py/_hl/group.py in __setitem__(self, name, obj)\r\n    371 \r\n    372             if isinstance(obj, HLObject):\r\n--> 373                 h5o.link(obj.id, self.id, name, lcpl=lcpl, lapl=self._lapl)\r\n    374 \r\n    375             elif isinstance(obj, SoftLink):\r\n\r\nh5py/_objects.pyx in h5py._objects.with_phil.wrapper()\r\n\r\nh5py/_objects.pyx in h5py._objects.with_phil.wrapper()\r\n\r\nh5py/h5o.pyx in h5py.h5o.link()\r\n\r\nRuntimeError: Unable to create link (name already exists)```", "@shanmukh05  This issue is mentioned on [StackOverflow](https://stackoverflow.com/questions/62169315/runtimeerror-unable-to-create-link-name-already-exists-keras).  This is occuring because you have 2 sets of layers of the same name, thus the model's weights cannot be saved:\r\nError is in the folowing line:\r\n\r\n```\r\nfor i in ls:\r\n        pretrained_model = efficient_net[i]\r\n        x = pretrained_model(inputs)\r\n        x = tf.keras.layers.GlobalAveragePooling2D()(x)\r\n        output[i] = tf.keras.layers.Dense(CLASSES,activation=\"sigmoid\", dtype='float32')(x)\r\n\r\n\r\n#You can use the name parameter in layer function. It is best if you do them seperately and not in a for loop.\r\n```\r\n\r\nHope this helps.", "> @shanmukh05 This issue is mentioned on [StackOverflow](https://stackoverflow.com/questions/62169315/runtimeerror-unable-to-create-link-name-already-exists-keras). This is occuring because you have 2 sets of layers of the same name, thus the model's weights cannot be saved:\r\n> Error is in the folowing line:\r\n> \r\n> ```\r\n> for i in ls:\r\n>         pretrained_model = efficient_net[i]\r\n>         x = pretrained_model(inputs)\r\n>         x = tf.keras.layers.GlobalAveragePooling2D()(x)\r\n>         output[i] = tf.keras.layers.Dense(CLASSES,activation=\"sigmoid\", dtype='float32')(x)\r\n> \r\n> \r\n> #You can use the name parameter in layer function. It is best if you do them seperately and not in a for loop.\r\n> ```\r\n> \r\n> Hope this helps.\r\n\r\n**I tried this, but getting the same error**\r\n````for i in ls:\r\n        j=0\r\n        for layer in efficient_net[i].layers:\r\n            layer._name = layer.name + \"_\"+str(i)\r\n        j+=1``", "@shanmukh05 \r\n\r\nWhen I tried reproducing your error, I face a different error, as shown below.\r\n\r\n```NameError: name 'CLASSES' is not defined.```\r\n\r\nPlease find the [Gist](https://colab.research.google.com/gist/Saduf2019/4a6845af0b4cc53766af7d55cbdfe75e/untitled520.ipynb).\r\n\r\nAlso refer to these resolved issues with same error: #43011, #26835, [link](https://github.com/keras-team/keras/issues/6844), [link1](https://fantashit.com/runtimeerror-unable-to-create-link-name-already-exists-during-model-saving-with-modelcheckpoint/)", "> @shanmukh05\r\n> \r\n> When I tried reproducing your error, I face a different error, as shown below.\r\n> \r\n> `NameError: name 'CLASSES' is not defined.`\r\n> \r\n> Please find the [Gist](https://colab.research.google.com/gist/Saduf2019/4a6845af0b4cc53766af7d55cbdfe75e/untitled520.ipynb).\r\n> \r\n> Also refer to these resolved issues with same error: #43011, #26835, [link](https://github.com/keras-team/keras/issues/6844), [link1](https://fantashit.com/runtimeerror-unable-to-create-link-name-already-exists-during-model-saving-with-modelcheckpoint/)\r\n\r\nThe problem is that, both `Efficientnet0,EfficientNet1` have same layer names. I tried changing names as given [here](https://github.com/tensorflow/tensorflow/issues/46871#issuecomment-772425509), but I am getting same error. The error was not there in previous versions of tensorflow. I tried `tf-nightly` but no use. Can you suggest any alternative for changing names of  `layers`", "@shanmukh05 \r\nPlease take a look at [this](https://www.kaggle.com/adityakane/issue-46871-solution) notebook. I believe it is the solution. ", "> @shanmukh05\r\n> Please take a look at [this](https://www.kaggle.com/adityakane/issue-46871-solution) notebook. I believe it is the solution.\r\n\r\nNope, still facing the issue. I don't know why just renaming layers is not working.", "> @shanmukh05\r\n> \r\n> When I tried reproducing your error, I face a different error, as shown below.\r\n> \r\n> `NameError: name 'CLASSES' is not defined.`\r\n> \r\n> Please find the [Gist](https://colab.research.google.com/gist/Saduf2019/4a6845af0b4cc53766af7d55cbdfe75e/untitled520.ipynb).\r\n> \r\n> Also refer to these resolved issues with same error: #43011, #26835, [link](https://github.com/keras-team/keras/issues/6844), [link1](https://fantashit.com/runtimeerror-unable-to-create-link-name-already-exists-during-model-saving-with-modelcheckpoint/)\r\n\r\nTry running this notebook: [Kaggle Notebook](https://www.kaggle.com/adityakane/issue-46871-solution)", "@shanmukh05 Using save_weights_only is a workaround, and it works correctly, as demonstrated in [this](https://www.kaggle.com/adityakane/issue-46871-solution) notebook. ", "> **I tried this, but getting the same error**\r\n> \r\n> ```\r\n>         j=0\r\n>         for layer in efficient_net[i].layers:\r\n>             layer._name = layer.name + \"_\"+str(i)\r\n>         j+=1``\r\n> ```\r\n@shanmukh05 \r\nTry to rename the weights as follows:\r\n\r\n ```\r\nfor w in efficient_net[i].weights:\r\n    w._handle_name = 'EP_' + str(i) + '_' + w.name\r\n```\r\n\r\nI know you shouldn't mess with underscore variables but it seems to work.", "> > **I tried this, but getting the same error**\r\n> > ```\r\n> >         j=0\r\n> >         for layer in efficient_net[i].layers:\r\n> >             layer._name = layer.name + \"_\"+str(i)\r\n> >         j+=1``\r\n> > ```\r\n> \r\n> @shanmukh05\r\n> Try to rename the weights as follows:\r\n> \r\n> ```\r\n> for w in efficient_net[i].weights:\r\n>    w._handle_name = 'EP_' + str(i) + '_' + w.name\r\n> ```\r\n> \r\n> I know you shouldn't mess with underscore variables but it seems to work.\r\n\r\nThanks, that is working", "@shanmukh05\r\n\r\nPlease move this issue to closed status if resolved", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46871\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46871\">No</a>\n"]}, {"number": 46870, "title": "Crash when Dense 2D without Bias on Android GPU Delegate", "body": "**System information**\r\n- Have I written custom code:Yes\r\n- OS Platform and Distribution:Ubuntu 20.04 and Win10\r\n- Mobile device: Huawei Honor V30 Pro (OXF-AN10)\r\n- TensorFlow installed from: Pip\r\n- TensorFlow version:2.4.1\r\n- Python version:3.8\r\n- CUDA/cuDNN version:11.0/8.0.5\r\n- GPU model and memory:GTX 1080 ti\r\n\r\nYou can collect some of this information using our environment capture\r\nv2.4.0-49-g85c8b2a817f 2.4.1\r\n\r\n**Describe the current behavior**\r\nA/libc: Fatal signal 11 (SIGSEGV), code 1 (SEGV_MAPERR), fault addr 0x0\r\n\r\n**Describe the expected behavior**\r\nWork fine as run the model on mobile CPU\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n```\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras import layers\r\nimport tensorflow as tf\r\n\r\nx = layers.Input(shape=(256,64,3))\r\ny = layers.Dense(1,use_bias=False)(x) #here use_bias=False is the key point\r\ny = layers.GlobalMaxPool2D()(y)\r\n\r\nmodel = keras.Model(inputs=[x],outputs=[y])\r\nmodel.summary()\r\n\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\nmodel_input = model.inputs[0]\r\ninput_shape = model_input.shape\r\nmodel_input.set_shape((1,*input_shape[1:]))\r\n\r\nlite_model = converter.convert()\r\nwith open('issue_dense_2dMustBias_android_gpu.tflite', \"wb\") as fp:\r\n    fp.write(lite_model)\r\n```\r\n\r\n[issue_dense_2dMustBias_android_gpu.zip](https://github.com/tensorflow/tensorflow/files/5916325/issue_dense_2dMustBias_android_gpu.zip)\r\n", "comments": ["TF Lite Android GPU Delegate problem", "Hey @Robird to help resolve this quicker, could you provide some details on how you are using the delegate? Is it from the Java API? Also, could you try adb logcat & see if you see specific errors from TFLite?", "Used [benchmark tool](https://www.tensorflow.org/lite/performance/measurement) to run some inferences. Tested with Galaxy S10e (Exynos 9820) and Pixel 2 XL (SD 835). Works fine on both phones with GPU delegate.\r\n\r\nIt seems the problem is specific to the device you're testing, so it would great if you can provide more detailed logs. Thanks!", "I tried to run the code in colab with  TF v2.5,please find the gist [here](https://colab.research.google.com/gist/sushreebarsa/dc15c71937ec21fc2f801095e6985071/untitled156.ipynb?authuser=1)..Thanks !", "TFLite CPU is able to reinterpret any tensor shape to any tensor shape as long as the number of elements match, TFLite GPU isn't; tensor shapes must be well formed.  If I look at your network, I see a couple of incompatibilities with the GPU backend:\r\n* batch dimension must be preserved across the network, i.e. the input to the FC layer must be 1x16384x3.\r\n* IIRC FC's weight tensor should have the form OHWI (1, 1, 16384, 3) and that's not the case, i.e. you're feeding (1, 1, 1, 3).", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46870\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46870\">No</a>\n"]}, {"number": 46869, "title": "[Graph C API] Util API", "body": "This PR is to add graph util C API, which includes:\r\n1. `TF_GrapplerItem` to get preserved/fetched nodes.\r\n2. `TF_GraphProperties` to infer tensor shapes.\r\n3. `TF_FunctionLibraryDefinition` to get OpDef.\r\n\r\nThis PR is following RFC [Modular TensorFlow Graph C API](https://github.com/tensorflow/community/blob/master/rfcs/20201027-modular-tensorflow-graph-c-api.md).", "comments": ["Hi @penpornk @ezhulenev,  please help to have a review. Thanks very much!", "@ezhulenev Could you please have a look on this PR? Thanks.", "@ezhulenev @penpornk Seems the test failure is caused by network issue, it cannot fetch Eigen repo. Could you please help rerun it?", "@ShengYang1 Thank you for checking! Rerunning. :)", "> @ShengYang1 Thank you for checking! Rerunning. :)\r\n\r\nThanks! I find windows gpu is failed this time, but it passed last time. I'm afraid this failure is still not related to this PR.", "> Could you please address merge conflicts? Thank you!\r\n\r\nOK, I have already rebased. Thanks!", "@penpornk May I know the status of this PR? What else should I do? Thanks.", "@ShengYang1 Sorry for the long silence! It's undergoing API review internally.", "@penpornk I have checked and found that this PR is merged into master, so I guess it is approved, am I right? Can we close this PR now?", "@ShengYang1 Yes, it was merged a while ago. I didn't notice that it doesn't show as merged here. Probably because we made some internal changes. I'll close this now. Thank you again for the PR! :)"]}, {"number": 46868, "title": "[Graph C API] Registration API", "body": "This PR is to add graph registration C API, which includes:\r\n1. Registration C API in `tensorflow/c/experimental/grappler/`.\r\n2. `PluginGraphOptimizerRegistry` in grappler to register and create optimizer.\r\n\r\nThis PR is following RFC [Modular TensorFlow Graph C API](https://github.com/tensorflow/community/blob/master/rfcs/20201027-modular-tensorflow-graph-c-api.md).", "comments": ["Hi @penpornk @ezhulenev,  please help to have a review. Thanks very much!", "@ezhulenev MacOS UT failure is fixed, please review again. Thanks!", "@ezhulenev @gbaned Seems the two MacOS UT failures are not related to this PR, one is about gRPC server, and the other is about python ImportError. Could you please help check? What should I do to fix the failures?", "@ShengYang1 It could be that the test instance was flaky. Let me rerun them.", "Just a heads up that I've made several changes internally before the merge. Most of them won't have any effects on other code. There are two changes that can break other codes using this PR:\r\n- Renamed `ConfigsList` to `ConfigList`.https://github.com/tensorflow/tensorflow/blob/88affffa8fc78966b4623f1e6e8c98045f94abfd/tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.h#L30\r\n- Changed the signature of `BufferToMessage` from\r\n```c++\r\nStatus BufferToMessage(const TF_Buffer* in,\r\n                       tensorflow::protobuf::MessageLite& out);\r\n```\r\nto\r\n```c++\r\nStatus BufferToMessage(const TF_Buffer* in,\r\n                       tensorflow::protobuf::MessageLite* out);\r\n```\r\n\r\nThank you again for the PR!", "One more minor change: Renamed the versioning variables from `SE_MAJOR`, etc. to `GO_MAJOR`, etc. https://github.com/tensorflow/tensorflow/commit/bca7074097cd86333cfb809e8b15d881afd83b69", "FYI, this code in `tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc`\r\n\r\n```\r\nPluginRegistrationMap* registered_plugin_optimizers = nullptr;\r\nPluginRegistrationMap* GetPluginRegistrationMap() {\r\n  if (registered_plugin_optimizers == nullptr)\r\n    registered_plugin_optimizers = new PluginRegistrationMap;\r\n  return registered_plugin_optimizers;\r\n}\r\n```\r\nis thread-unsafe (two threads calling `GetPluginRegistrationMap()` in parallel will race on `registered_plugin_optimizers`) and may result in a memory leak.\r\n\r\nFix forthcoming."]}, {"number": 46867, "title": "Shakespeare's style writing generation model cannot be exported with TensorFlow 2.3", "body": "[text_generation.ipynb]: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/text/text_generation.ipynb\r\n[Colab notebook]: https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/text/text_generation.ipynb\r\n## URL(s) with the issue:\r\n\r\n- TensorFlow Tutorial: Text generation with an RNN (the one that produces Shakespeare's style writing using RNN).\r\n\r\n    https://github.com/tensorflow/docs/blob/master/site/en/tutorials/text/text_generation.ipynb\r\n\r\n- Accompanying Colab.\r\n\r\n    https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/text/text_generation.ipynb\r\n\r\n## Description of issue (what needs changing):\r\n\r\nWith TensorFlow 2.4, the notebook [text_generation.ipynb] above works as expected (without throwing any error), but this is not the case with TensorFlow 2.3.\r\n\r\nA trivial solution is to upgrade to TensorFlow 2.4. However, this would require, when using pre-built TensorFlow, switching to CUDA 11 (cf. https://www.tensorflow.org/install/source#gpu). In a cloud environment I use from time to time, CUDA 11 is not yet supported; this is where my trouble comes from.\r\n\r\nSo the notebook better works well with TensorFlow 2.3 or higher.\r\n\r\n### Clear description\r\n\r\nTo reproduce the issue:\r\n\r\n1. Open the [Colab notebook].\r\n1. Select Runtime > Change runtime type > GPU.\r\n1. insert the line `!pip install 'tensorflow<2.4'` before the line `import tensorflow as tf`.\r\n1. Select Runtime > Run all.\r\n\r\nEnvironmental setup, text preprocessing, model building, and training run smoothly, but after the following cell in the \"Export the generator\" section, a `ValueError` is raised:\r\n\r\n```\r\ntf.saved_model.save(one_step_model, 'one_step')\r\none_step_reloaded = tf.saved_model.load('one_step')\r\n```\r\n\r\n```\r\nWARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x7f020a19e860>, because it is not built.\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nThis property should not be used in TensorFlow 2.0, as updates are applied automatically.\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nThis property should not be used in TensorFlow 2.0, as updates are applied automatically.\r\nINFO:tensorflow:Assets written to: one_step/assets\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-45-5089d08e324f> in <module>()\r\n      1 tf.saved_model.save(one_step_model, 'one_step')\r\n----> 2 one_step_reloaded = tf.saved_model.load('one_step')\r\n\r\n9 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saving/saveable_object_util.py in _add_saveable(saveables, seen_ops, saveable)\r\n    329   if saveable.op in seen_ops:\r\n    330     raise ValueError(\"The same saveable will be restored with two names: %s\" %\r\n--> 331                      saveable.name)\r\n    332   saveables.append(saveable)\r\n    333   seen_ops.add(saveable.op)\r\n\r\nValueError: The same saveable will be restored with two names: ids_from_chars/_table/.ATTRIBUTES/table\r\n```\r\n\r\nJust so you know, this notebook is not compatible with TensorFlow 2.2 for the very reason that `StringLookup` is not supported; running it with TensorFlow 2.2 raises an exception as follows:\r\n\r\n```\r\nids_from_chars = preprocessing.StringLookup(\r\n    vocabulary=list(vocab))\r\n```\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-9-aea607cfc6f7> in <module>()\r\n----> 1 ids_from_chars = preprocessing.StringLookup(\r\n      2     vocabulary=list(vocab))\r\n\r\nAttributeError: module 'tensorflow.keras.layers.experimental.preprocessing' has no attribute 'StringLookup'\r\n```\r\n\r\nSo the `ValueError` in concern is an exception peculiar to TensorFlow 2.3. So far I have no idea why the notebook is not compatible with TensorFlow 2.3, and any help or a single hint will be very much appreciated.", "comments": ["@nobutoba,\r\nAs you've mentioned, I was able to reproduce the error with TF v2.3 and looks like this error was fixed in TensorFlow v2.4.\r\n\r\nA hack that worked for me was to edit the module throwing the error i.e. changing line number 329 in the file\r\n`/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saving/saveable_object_util.py` from\r\n\r\n`if saveable.op in seen_ops:`\r\nto \r\n`if saveable.op is not None and saveable.op in seen_ops:`\r\n\r\nAfter the edit, save the changes, restart the runtime and check if it works. \r\n\r\nPlease be advised that this is just a workaround because of the restrictions on your machine and may result in unexpected behavior.\r\n\r\nReferences: \r\n- [Link 1](https://colab.research.google.com/gist/amahendrakar/054e49902bddd0182603cbbeabefb731/46867.ipynb#scrollTo=3Grk32H_CzsC&line=2&uniqifier=1) - Colab notebook without the edit\r\n- [Link 2](https://colab.research.google.com/gist/amahendrakar/225045bbc9ebd71c4a8aee62a8302d9c/46867-withedit.ipynb#scrollTo=jE8Pdbpoiw0d&line=1&uniqifier=1) - Colab notebook with edit \r\n- https://github.com/tensorflow/tensorflow/commit/2d9fb19f8d0672245c2becd06b05a59c1d43c33e - Commit ID\r\n\r\nHope this helps. Thanks :)", "@amahendrakar Thank you very much, your explanation was very thorough \ud83d\udc4d ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46867\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46867\">No</a>\n"]}, {"number": 46866, "title": "A mistake code on Model Maker Guide", "body": "The image classification code on [official Model Maker Guide](https://tensorflow.google.cn/lite/guide/model_maker) may get a mistake on training data name.\r\n\r\n![516441612286382_ pic_hd](https://user-images.githubusercontent.com/17171866/106685499-76437700-6603-11eb-83c3-6e4098e44183.jpg)\r\n\r\nMistake code in above red rectangle, I think should be replace with following code snippet.\r\n```\r\nmodel = image_classifier.create(train_data)\r\n```\r\n", "comments": ["Thank you for the suggestion! Will fix it soon."]}, {"number": 46865, "title": "[INTEL MKL] oneDNN partials and Dockerfiles for CentOS 7", "body": "This PR introduces:\r\n\r\n- Partials and Dockerfiles for oneDNN based on `CentOS 7` \r\n- Misc updates and fixes for existing oneDNN partials\r\n- Install Horovod from `git+https` which seems to be more reliable and flexible too\r\n\r\nLike before this is how you generate the new Docker files and build the images:\r\n\r\n```\r\n$ export DOCKER_BUILD_ARGS=<extra docker build args specific to your environment, like proxies>\r\n$ alias db=\"docker build ${DOCKER_BUILD_ARGS}\"\r\n$ export DOCKER_RUN_ENVS=\"extra docker run environment variables specific to your environment, like proxies\"\r\n$ alias dr=\"docker run --disable-content-trust ${DOCKER_RUN_ENVS}\"\r\n```\r\n\r\nFinally start building contaiers:\r\n\r\n```\r\n$ cd tensorflow/tools/dockerfiles\r\n$ db -t tf-tools -f tools.Dockerfile .\r\n\r\n$ alias asm_dockerfiles=\"dr --rm -u $(id -u):$(id -g) -v $(pwd):/tf tf-tools python3 assembler.py \"\r\n$ alias asm_images=\"dr --rm -v $(pwd):/tf -v /var/run/docker.sock:/var/run/docker.sock tf-tools python3 assembler.py \"\r\n$ asm_dockerfiles --release dockerfiles --construct_dockerfiles\r\n\r\n$ TF_VERSION=2.4.0 HOROVOD_VERSION=v0.21.1 && asm_images ${PARTIALS_BUILD_ARGS} --release onednn --repository intel/intel-optimized-tensorflow --arg BAZEL_VERSION=3.1.0 --arg TF_BRANCH=v${TF_VERSION} --arg TF_PACKAGE_VERSION=${TF_VERSION} --arg _TAG_PREFIX=${TF_VERSION}-centos --build_images --only_tags_matching '.*centos-7'\r\n```\r\n\r\nand this will produce the following images:\r\n```\r\nintel/intel-optimized-tensorflow:2.4.0-centos-7\r\nintel/intel-optimized-tensorflow:2.4.0-centos-7-devel\r\nintel/intel-optimized-tensorflow:2.4.0-centos-7-devel-jupyter\r\nintel/intel-optimized-tensorflow:2.4.0-centos-7-devel-mpich-horovod\r\nintel/intel-optimized-tensorflow:2.4.0-centos-7-devel-mpich-horovod-jupyter\r\nintel/intel-optimized-tensorflow:2.4.0-centos-7-devel-mpi-horovod\r\nintel/intel-optimized-tensorflow:2.4.0-centos-7-devel-mpi-horovod-jupyter\r\nintel/intel-optimized-tensorflow:2.4.0-centos-7-jupyter\r\nintel/intel-optimized-tensorflow:2.4.0-centos-7-mpich-horovod\r\nintel/intel-optimized-tensorflow:2.4.0-centos-7-mpich-horovod-jupyter\r\nintel/intel-optimized-tensorflow:2.4.0-centos-7-mpi-horovod\r\nintel/intel-optimized-tensorflow:2.4.0-centos-7-mpi-horovod-jupyter\r\n```\r\n", "comments": ["Hi @angerson \r\n\r\nPlease help review and merge this PR, thanks.", "See also https://github.com/tensorflow/build/pull/21 -- for what might eventually replace this system, and would probably separate the oneDNN work.", "Thanks @angerson \r\nI'll keep my eyes open on https://github.com/tensorflow/build/pull/21"]}, {"number": 46864, "title": "Improve MicroProfiler and make per-op profiling the default in the benchmarks.", "body": "* Maintain state within the MicroProfiler object such that all the logging can happen external to the interpreter.\r\n* Refactor the benchmarks to make use of this new functionality.\r\n\r\nThis command (keyword benchmark with xtensa Fusion F1):\r\n```\r\nmake -f tensorflow/lite/micro/tools/make/Makefile TARGET=xtensa OPTIMIZED_KERNEL_DIR=xtensa TARGET_ARCH=fusion_f1 XTENSA_CORE=F1_190305_swupgrade test_keyword_benchmark -j8\r\n```\r\n\r\ngives the following output at tip-of-tree:\r\n```\r\nInitializeKeywordRunner() took 199262 ticks (199 ms)\r\nKeywordRunNIerations(1) took 152158 ticks (152 ms)\r\nKeywordRunNIerations(10) took 1521087 ticks (1521 ms)\r\n```\r\n\r\nand with this change:\r\n```\r\nInitializeKeywordRunner took 152689 ticks (152 ms).\r\n\r\nKeywordRunNIerations(1) took 152628 ticks (152 ms)\r\nQUANTIZE took 3753 ticks (3 ms).\r\nSVDF took 37998 ticks (37 ms).\r\nFULLY_CONNECTED took 1363 ticks (1 ms).\r\nSVDF took 18798 ticks (18 ms).\r\nFULLY_CONNECTED took 1363 ticks (1 ms).\r\nSVDF took 18798 ticks (18 ms).\r\nFULLY_CONNECTED took 1363 ticks (1 ms).\r\nSVDF took 18798 ticks (18 ms).\r\nFULLY_CONNECTED took 1363 ticks (1 ms).\r\nSVDF took 13902 ticks (13 ms).\r\nSVDF took 15822 ticks (15 ms).\r\nSVDF took 15822 ticks (15 ms).\r\nFULLY_CONNECTED took 1087 ticks (1 ms).\r\nSOFTMAX took 2037 ticks (2 ms).\r\nQUANTIZE took 361 ticks (0 ms).\r\n\r\nKeywordRunNIerations(10) took 1526280 ticks (1526 ms)\r\n```\r\n\r\nNote:\r\n * overall increase due to the additional book-keeping for profiling is minimal (470 ticks).\r\n * The initialize time has decreased because we are no longer including the time needed to compute a random input and copy it into the input buffer as part of the initialization.\r\n\r\nPartially addresses http://b/158212576\r\n\r\n\r\nFor completeness, here is the output of the person_detection_benchmark:\r\n```\r\nmake -f tensorflow/lite/micro/tools/make/Makefile test_person_detection_benchmark -j8\r\n```\r\n\r\ntip-of-tree:\r\n```\r\nInitializeBenchmarkRunner() took 260 ticks (0 ms)\r\nbenchmark_runner->RunSingleIteration() took 31238 ticks (31 ms)\r\nPersonDetectionTenIerationsWithPerson() took 295380 ticks (295 ms)\r\nPersonDetectionTenIerationsWithoutPerson() took 288194 ticks (288 ms)\r\n```\r\n\r\nwith this change:\r\n```\r\nInitializeBenchmarkRunner took 302 ticks (0 ms).\r\n\r\nWithPersonDataIterations(1) took 25590 ticks (25 ms)\r\nDEPTHWISE_CONV_2D took 903 ticks (0 ms).\r\nDEPTHWISE_CONV_2D took 887 ticks (0 ms).\r\nCONV_2D took 1378 ticks (1 ms).\r\nDEPTHWISE_CONV_2D took 453 ticks (0 ms).\r\nCONV_2D took 1051 ticks (1 ms).\r\nDEPTHWISE_CONV_2D took 987 ticks (0 ms).\r\nCONV_2D took 2043 ticks (2 ms).\r\nDEPTHWISE_CONV_2D took 225 ticks (0 ms).\r\nCONV_2D took 1071 ticks (1 ms).\r\nDEPTHWISE_CONV_2D took 495 ticks (0 ms).\r\nCONV_2D took 1907 ticks (1 ms).\r\nDEPTHWISE_CONV_2D took 118 ticks (0 ms).\r\nCONV_2D took 938 ticks (0 ms).\r\nDEPTHWISE_CONV_2D took 234 ticks (0 ms).\r\nCONV_2D took 1817 ticks (1 ms).\r\nDEPTHWISE_CONV_2D took 228 ticks (0 ms).\r\nCONV_2D took 1909 ticks (1 ms).\r\nDEPTHWISE_CONV_2D took 224 ticks (0 ms).\r\nCONV_2D took 1769 ticks (1 ms).\r\nDEPTHWISE_CONV_2D took 224 ticks (0 ms).\r\nCONV_2D took 1797 ticks (1 ms).\r\nDEPTHWISE_CONV_2D took 223 ticks (0 ms).\r\nCONV_2D took 1787 ticks (1 ms).\r\nDEPTHWISE_CONV_2D took 80 ticks (0 ms).\r\nCONV_2D took 921 ticks (0 ms).\r\nDEPTHWISE_CONV_2D took 99 ticks (0 ms).\r\nCONV_2D took 1809 ticks (1 ms).\r\nAVERAGE_POOL_2D took 8 ticks (0 ms).\r\nCONV_2D took 2 ticks (0 ms).\r\nRESHAPE took 1 ticks (0 ms).\r\nSOFTMAX took 2 ticks (0 ms).\r\n\r\nNoPersonDataIterations(1) took 25310 ticks (25 ms)\r\nDEPTHWISE_CONV_2D took 912 ticks (0 ms).\r\nDEPTHWISE_CONV_2D took 988 ticks (0 ms).\r\nCONV_2D took 1356 ticks (1 ms).\r\nDEPTHWISE_CONV_2D took 510 ticks (0 ms).\r\nCONV_2D took 1013 ticks (1 ms).\r\nDEPTHWISE_CONV_2D took 964 ticks (0 ms).\r\nCONV_2D took 2004 ticks (2 ms).\r\nDEPTHWISE_CONV_2D took 323 ticks (0 ms).\r\nCONV_2D took 1012 ticks (1 ms).\r\nDEPTHWISE_CONV_2D took 480 ticks (0 ms).\r\nCONV_2D took 1770 ticks (1 ms).\r\nDEPTHWISE_CONV_2D took 113 ticks (0 ms).\r\nCONV_2D took 882 ticks (0 ms).\r\nDEPTHWISE_CONV_2D took 266 ticks (0 ms).\r\nCONV_2D took 1766 ticks (1 ms).\r\nDEPTHWISE_CONV_2D took 219 ticks (0 ms).\r\nCONV_2D took 1743 ticks (1 ms).\r\nDEPTHWISE_CONV_2D took 217 ticks (0 ms).\r\nCONV_2D took 2004 ticks (2 ms).\r\nDEPTHWISE_CONV_2D took 217 ticks (0 ms).\r\nCONV_2D took 1640 ticks (1 ms).\r\nDEPTHWISE_CONV_2D took 206 ticks (0 ms).\r\nCONV_2D took 1677 ticks (1 ms).\r\nDEPTHWISE_CONV_2D took 52 ticks (0 ms).\r\nCONV_2D took 1083 ticks (1 ms).\r\nDEPTHWISE_CONV_2D took 110 ticks (0 ms).\r\nCONV_2D took 1771 ticks (1 ms).\r\nAVERAGE_POOL_2D took 7 ticks (0 ms).\r\nCONV_2D took 2 ticks (0 ms).\r\nRESHAPE took 1 ticks (0 ms).\r\nSOFTMAX took 2 ticks (0 ms).\r\n\r\nWithPersonDataIterations(10) took 254901 ticks (254 ms)\r\n\r\nNoPersonDataIterations(10) took 241536 ticks (241 ms)\r\n```\r\n", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n", "@njeffrie, this PR is now ready for review."]}, {"number": 46863, "title": "[Keras Fit & Compile] Horovod worker desynchronization - Potentially deadlock training TF 2.4", "body": "CC: @reedwm @pkanwar23 @sanjoy \r\nCC2: @romerojosh @tgaddair \r\nCC3: @nluehr @WhiteFangBuck\r\n\r\nWe unfortunately found quite a serious bug in TF2.4.X with Keras Models (Compile and Fit approach) combined with Mixed Precision Policy when using Horovod.\r\n\r\nModels can ran into Deadlock or DeSynchronization (all reduce gradient of one step from worker A with gradient of another step of worker B) and stop training completely.\r\n\r\nTo make the matter worse, this issue increases in likelihood with the number of workers.\r\n\r\nI have put together a simple repro case showing how workers can deadlock and basically stalls:\r\n\r\nhttps://github.com/DEKHTIARJonathan/HVD_TF_Worker_Desync_BugReport\r\n\r\nSmall extract of the bug:\r\n```bash\r\n[2021-02-02 21:19:07.345988: W /tmp/pip-install-dxtho7yu/horovod_0bde588442554cf4b80c76441efc4e03/horovod/common/stall_inspector.cc:105] One or more tensors were submitted to be reduced, gathered or broadcasted by subset of ranks and are waiting for remainder of ranks for more than 10 seconds. This may indicate that different ranks are trying to submit different tensors or that only subset of ranks is submitting tensors, which will cause deadlock. \r\nMissing ranks:\r\n0: [cond_1/then/_10/cond_1/SGD/PartitionedCall/DistributedSGD_Allreduce/cond/then/_79/DistributedSGD_Allreduce/cond/HorovodAllreduce_grads_0]\r\n```\r\nAs a note, this bug wasn't present in prior versions of TF.\r\n\r\nAny help would be greatly appreciated.\r\n\r\nThanks a lot", "comments": ["I wanted to provide a bit more detail on this issue and the behavior we are observing. \r\n\r\nWe use the [Horovod](https://github.com/horovod/horovod) library to run distributed training. For Keras, Horovod operates by defining the `_aggregate_gradients` method of the optimizer to return an globally averaged (allreduced) gradient.  (https://github.com/horovod/horovod/blob/2f154afad39a0ef6d4f337a0da7e422d43961325/horovod/_keras/__init__.py#L83-L90)It seems that there is currently an incompatibility with the Kera `LossScaleOptimizer` in TF 2.4.x that is causing issues with this functionality related to the loss scaling/step skipping functionality.\r\n\r\nIn the repro case posted by @DEKHTIARJonathan, we have provided a small reproducer script that builds a trivial model in Keras and runs a single training step, with the mixed precision policy enabled or disabled via arg `--use_amp`. In the script, we set the input of rank 0 to a NaN value to generate a NaN gradient, and the input of rank 1 to a sane input value to generate a non-NaN gradient. \r\n\r\nThe expected behavior of this test is that during the call to `_aggregate_gradients`, the gradient will be allreduced by Horovod and produce a common NaN across the two workers. Following this in `apply_gradients`, the `LossScaleOptimizer` will detect this on both workers and they both skip the optimizer step in tandem. \r\n\r\nHowever, this is not the behavior we are seeing. Instead, we find that the worker that produces the NaN gradient (rank 0), skips the step independently of worker 1. Even worse, the worker that skips the step appears to completely bypass launching any Horovod operations at all, as though it skips the call to `_aggregate_gradients` entirely. The result of this is the output shown in the posted repo:\r\n```\r\n1/1 - 3s - loss: nan\r\nrank 0 completed step...\r\n\r\n\r\n[2021-02-02 21:19:07.345988: W /tmp/pip-install-dxtho7yu/horovod_0bde588442554cf4b80c76441efc4e03/horovod/common/stall_inspector.cc:105] One or more tensors were submitted to be reduced, gathered or broadcasted by subset of ranks and are waiting for remainder of ranks for more than 10 seconds. This may indicate that different ranks are trying to submit different tensors or that only subset of ranks is submitting tensors, which will cause deadlock. \r\nMissing ranks:\r\n0: [cond_1/then/_10/cond_1/SGD/PartitionedCall/DistributedSGD_Allreduce/cond/then/_79/DistributedSGD_Allreduce/cond/HorovodAllreduce_grads_0]\r\n```\r\nIn this output, we see that rank 0 is able to return from the `model.fit()` call while rank 1 is blocked on the call. The Horovod stall message printed indicates that the reason rank 1 is stalled is because rank 0 never launches its matching Horovod allreduce op for the gradient listed. \r\n\r\nWe see that this stall is remedied by using TF 2.3.x or if we disable the mixed precision policy in Keras using TF 2.4.x. \r\n\r\n@reedwm There was a long thread a while back working out Horovod interactions with Keras in #36398. The Horovod Keras implementation hasn't changed that much since then. Perhaps you are aware of something that changed in TF 2.4.x that might explain this new behavior?\r\n\r\n**Edit:** Updated comment to correct description of the Horovod Keras implementation.  ", "@DEKHTIARJonathan \r\n\r\nCan you please share colab link or simple standalone code to reproduce the issue in our environment.It helps us in localizing the issue faster. Thanks!", "@ravikyram that won't be doable I'm sorry. This issue is specifically a multi-GPU issue. So AFAIK, there's no way to use Google Colab to do that.\r\n\r\nFor the \"simple standalone\", I can't do more simple and standalone than a dummy python script running on top of the Google official docker container.\r\n\r\nPlease don't get me wrong, if there's something specific I can do to help, that will be my pleasure. Though here I don't know how to comply with your request.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46863\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46863\">No</a>\n"]}, {"number": 46862, "title": "[TFLM] Keyword benchmark broken when using generated Makefile project", "body": "See github issue: https://github.com/tensorflow/tensorflow/issues/46860\r\n\r\nWhen building the keyword benchmark like this: make -f tensorflow/lite/micro/tools/make/Makefile generate_keyword_benchmark_make_project\r\n\r\nDoesn't build (see above issue). This PR fixes that.\r\n", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n", ":frowning_face: Sorry, but only Googlers may change the label `cla: yes`.", "@yair-ehrenwald  Can you please check @advaitjain's comments and keep us posted ? Thanks!", "The underlying issue was fixed with https://github.com/tensorflow/tensorflow/pull/47018\r\n\r\nI am closing this PR."]}, {"number": 46861, "title": "Add missing import to compile micro kernels on Windows.", "body": "This inclusion allows building the TFLite micro kernels on Windows.\r\n\r\nSpecifically, `bazel build -c opt //tensorflow/lite/micro/kernels:micro_ops` currently throws a syntax error without this PR, on this line: https://github.com/tensorflow/tensorflow/blob/f7d0a77b539d47bbbffa9702c1e7329de79551ac/tensorflow/lite/micro/kernels/svdf.cc#L55-L60\r\n\r\nThis fixes the issue by including the correct definition of `__restrict__` for MSVC: https://github.com/tensorflow/tensorflow/blob/f7d0a77b539d47bbbffa9702c1e7329de79551ac/tensorflow/lite/kernels/internal/tensor_utils.h#L24-L26", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n", "Please run ```clang-format -i -style=google tensorflow/lite/micro/kernels/svdf.cc```", "Thanks for your help with this - after the linting, I ran `make -f tensorflow/lite/micro/tools/make/Makefile test` locally as you suggested and got a bunch of undefined-symbol errors, which I guess I should have expected. Since the thing I actually want is only three lines long, would it be a problem if I just copy those three lines to the top of the `svdf.cc` file instead of adding this extra import?\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/66dd98a10612e644a26a141cbdfc82e55ecf62eb/tensorflow/lite/kernels/internal/reference/portable_tensor_utils.h#L20-L22", "I tried running make ... test with your change and I'm not seeing any errors. Make sure you run make ... third_party_downloads first to ensure you have all dependencies downloaded correctly - that my fix your issue.\r\n\r\nPlease try uploading the clang-formatted version (or just make sure imports are alphabetical) to see if this passes micro presubmit as-is.", "Apologies for the delay, I just pushed the linted file, so we can see what happens on CI.\r\n\r\nWhat I see (on MacOS) when running the tests is a bunch of `undefined symbol` errors because `portable_tensor_utils.h` is being included but `portable_tensor_utils.cc` isn't being compiled. However, when I added `portable_tensor_utils.cc` to the `MICROLITE_CC_BASE_SRCS` in the makefile I then got a bunch of errors from that file because of `-Wdouble-promotion`, so that doesn't (immediately) solve the problem either.", "I'm going to close the current PR. If this is still an issue please feel free to create a new PR that removes `__restrict__` since that is an optimization which is not necessary in the reference implementation. The benefits of `__restrict__` in svdf are not entirely clear either so removing it to fix the Windows build will be ok."]}, {"number": 46860, "title": "[TFLM] keyword benchmark broken when using generated Makefile projects", "body": "@tensorflow/micro\r\n\r\n**System information**\r\n- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu\r\n- TensorFlow installed from (source or binary): source\r\n- Tensorflow version (commit SHA if source):\r\n- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.):\r\n\r\n**Describe the problem**\r\nWhen building the keyword benchmark project like this:\r\nmake -f tensorflow/lite/micro/tools/make/Makefile  generate_keyword_benchmark_make_project\r\n\r\nI get 2 errors. One is due to micro_benchmark.h not being copied into the generated project, the other is a duplicate object error for **g_keyword_scrambled_model_data**. That happens because keyword_scrambled_model_data.cc somehow appears twice in the generated Makefile :)\r\n\r\nI will open a PR with a fix shortly.\r\n\r\n\r\n\r\n**Please provide the exact sequence of commands/steps when you ran into the problem**\r\n\r\n", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46860\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46860\">No</a>\n"]}, {"number": 46859, "title": "Requesting MatrixDeterminant op in tflite", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 2.3+\r\n- Are you willing to contribute it (Yes/No): I would need guidance / access to someone who knows the tflite codebase\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nI request that the operator MatrixDeterminant be added to the tensorflow-lite operators.  Currently, tensorflow/core/kernels/determinant_op.[cc/h] defines the standard tensorflow MatrixDeterminant operation, but there appears to be no such operation for tflite.\r\n\r\nI am trying to convert the Glow model (https://github.com/openai/glow) to tflite, but I am running into the issue where I can't convert the trained pb file and invoke it because there is no MatrixDeterminant operation.\r\n\r\n**Will this change the current api? How?**\r\nIt would add an operation for MatrixDeterminant to tflite's operators.\r\n\r\n**Who will benefit with this feature?**\r\nAnyone trying to convert a model containing the MatrixDeterminant operation to tflite.\r\n\r\n**Any Other info.**\r\n", "comments": ["Will add MatrixDeterminant op to the Select TF option soon. https://www.tensorflow.org/lite/guide/ops_select", "Thank you very much for the quick response!!", "The operator is now included at the head. You can try the tomorrow's tf-nightly version if you are using the `pip` command."]}, {"number": 46858, "title": "InaccessibleTensorError in custom Model using add_loss and build", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10.0.18363\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v2.4.0-rc4-71-g582c8d236cb 2.4.0\r\n- Python version: Python 3.8.5\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: CUDA 11.2, cuDNN 8.1.0.77\r\n- GPU model and memory: NVIDIA GeForce GTX 1050 Ti 4096MiB\r\n\r\n**Describe the current behavior**\r\nWhen running the following code, which uses `add_loss()` and creates a layer in the `build()` method, I get an\r\n`InaccessibleTensorError`\r\n\r\n**Describe the expected behavior**\r\nExecution without errors\r\n\r\n**Standalone code to reproduce the issue**\r\nhttps://colab.research.google.com/drive/16wFnwjWx9n0RKCuCqdTyjFPzfyqOQdyW?usp=sharing\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\n\r\nclass MyModel(keras.models.Model):\r\n\r\n    def build(self, batch_input_shape):\r\n        self.output_layer = keras.layers.Dense(1)\r\n        super().build(batch_input_shape)\r\n\r\n    def call(self, inputs, training=None):\r\n        self.add_loss(tf.reduce_mean(self.output_layer(inputs)))\r\n        return self.output_layer(inputs)\r\n\r\nmodel = MyModel()\r\nmodel.compile(loss=\"mse\", optimizer=\"nadam\")\r\n\r\nX = tf.random.uniform((100, 10))\r\ny = tf.random.uniform((100, 1))\r\nhistory = model.fit(X, y, epochs=2)\r\n```\r\n\r\n**Other info / logs** \r\n```\r\nEpoch 1/2\r\n---------------------------------------------------------------------------\r\nInaccessibleTensorError                   Traceback (most recent call last)\r\n<ipython-input-1-9f83c1e2ea49> in <module>\r\n     17 X = tf.random.uniform((100, 10))\r\n     18 y = tf.random.uniform((100, 1))\r\n---> 19 history = model.fit(X, y, epochs=2)\r\n\r\nd:\\programs\\miniconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\r\n   1098                 _r=1):\r\n   1099               callbacks.on_train_batch_begin(step)\r\n-> 1100               tmp_logs = self.train_function(iterator)\r\n   1101               if data_handler.should_sync:\r\n   1102                 context.async_wait()\r\n\r\nd:\\programs\\miniconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py in __call__(self, *args, **kwds)\r\n    826     tracing_count = self.experimental_get_tracing_count()\r\n    827     with trace.Trace(self._name) as tm:\r\n--> 828       result = self._call(*args, **kwds)\r\n    829       compiler = \"xla\" if self._experimental_compile else \"nonXla\"\r\n    830       new_tracing_count = self.experimental_get_tracing_count()\r\n\r\nd:\\programs\\miniconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py in _call(self, *args, **kwds)\r\n    869       # This is the first call of __call__, so we have to initialize.\r\n    870       initializers = []\r\n--> 871       self._initialize(args, kwds, add_initializers_to=initializers)\r\n    872     finally:\r\n    873       # At this point we know that the initialization is complete (or less\r\n\r\nd:\\programs\\miniconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py in _initialize(self, args, kwds, add_initializers_to)\r\n    723     self._graph_deleter = FunctionDeleter(self._lifted_initializer_graph)\r\n    724     self._concrete_stateful_fn = (\r\n--> 725         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\r\n    726             *args, **kwds))\r\n    727 \r\n\r\nd:\\programs\\miniconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\eager\\function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)\r\n   2967       args, kwargs = None, None\r\n   2968     with self._lock:\r\n-> 2969       graph_function, _ = self._maybe_define_function(args, kwargs)\r\n   2970     return graph_function\r\n   2971 \r\n\r\nd:\\programs\\miniconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\eager\\function.py in _maybe_define_function(self, args, kwargs)\r\n   3359 \r\n   3360           self._function_cache.missed.add(call_context_key)\r\n-> 3361           graph_function = self._create_graph_function(args, kwargs)\r\n   3362           self._function_cache.primary[cache_key] = graph_function\r\n   3363 \r\n\r\nd:\\programs\\miniconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\eager\\function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)\r\n   3194     arg_names = base_arg_names + missing_arg_names\r\n   3195     graph_function = ConcreteFunction(\r\n-> 3196         func_graph_module.func_graph_from_py_func(\r\n   3197             self._name,\r\n   3198             self._python_function,\r\n\r\nd:\\programs\\miniconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\r\n    988         _, original_func = tf_decorator.unwrap(python_func)\r\n    989 \r\n--> 990       func_outputs = python_func(*func_args, **func_kwargs)\r\n    991 \r\n    992       # invariant: `func_outputs` contains only Tensors, CompositeTensors,\r\n\r\nd:\\programs\\miniconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py in wrapped_fn(*args, **kwds)\r\n    632             xla_context.Exit()\r\n    633         else:\r\n--> 634           out = weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n    635         return out\r\n    636 \r\n\r\nd:\\programs\\miniconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py in wrapper(*args, **kwargs)\r\n    975           except Exception as e:  # pylint:disable=broad-except\r\n    976             if hasattr(e, \"ag_error_metadata\"):\r\n--> 977               raise e.ag_error_metadata.to_exception(e)\r\n    978             else:\r\n    979               raise\r\n\r\nInaccessibleTensorError: in user code:\r\n\r\n    d:\\programs\\miniconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:805 train_function  *\r\n        return step_function(self, iterator)\r\n    d:\\programs\\miniconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:795 step_function  **\r\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\r\n    d:\\programs\\miniconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1259 run\r\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\r\n    d:\\programs\\miniconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2730 call_for_each_replica\r\n        return self._call_for_each_replica(fn, args, kwargs)\r\n    d:\\programs\\miniconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3417 _call_for_each_replica\r\n        return fn(*args, **kwargs)\r\n    d:\\programs\\miniconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:788 run_step  **\r\n        outputs = model.train_step(data)\r\n    d:\\programs\\miniconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:755 train_step\r\n        loss = self.compiled_loss(\r\n    d:\\programs\\miniconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:229 __call__\r\n        reg_loss = math_ops.add_n(regularization_losses)\r\n    d:\\programs\\miniconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\r\n        return target(*args, **kwargs)\r\n    d:\\programs\\miniconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3572 add_n\r\n        return gen_math_ops.add_n(inputs, name=name)\r\n    d:\\programs\\miniconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:417 add_n\r\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\r\n    d:\\programs\\miniconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:748 _apply_op_helper\r\n        op = g._create_op_internal(op_type_name, inputs, dtypes=None,\r\n    d:\\programs\\miniconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:588 _create_op_internal\r\n        inp = self.capture(inp)\r\n    d:\\programs\\miniconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:633 capture\r\n        raise errors.InaccessibleTensorError(\r\n\r\n    InaccessibleTensorError: The tensor 'Tensor(\"Mean:0\", shape=(), dtype=float32)' cannot be accessed here: it is defined in another function or code block. Use return values, explicit Python locals or TensorFlow collections to access it. Defined in: FuncGraph(name=build_graph, id=2106957634048); accessed from: FuncGraph(name=train_function, id=2106954072704).\r\n```\r\n**Additional info**\r\nWhen line 2709 in keras\\engine\\base_layer.py (`tf_utils.maybe_init_scope(self):`) is commented no errors are raised.\r\n", "comments": ["I have tried in colab with TF version 2.4, nightly version(`2.5.0-dev20210202`) and was able to reproduce the issue. Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/bb4885f15ab60ea5f5267f5a22041c1f/untitled651.ipynb). Thanks!", "Hello aprimostka@, thanks for the report. Would you be interested in making a contribution in addressing this?", "@rchao, I can make only ad-hoc patching. \r\nAs I wrote earlier removing scope initialization fixes this problem, so I can suppose that code needs a careful recheck of management of graphs and at first glance, this problem looks more architectural. But now I don't have too much time to read design documentation.", "A possible workaround would be to build the `Dense` layer before `call`, for instance in `build`. You can call `layer.build(input_shape)` to do so. Do that work?", "In example code `Dense` layer already is built inside `build` method.\r\nCurrently I used following workaround:\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\n\r\nclass MyModel(keras.models.Model):\r\n    def __init__(self, **kwargs):\r\n        super().__init__(**kwargs)\r\n        self.output_layer = keras.layers.Dense(1)\r\n\r\n    def call(self, inputs, training=None):\r\n        self.add_loss(tf.reduce_mean(self.output_layer(inputs)))\r\n        return self.output_layer(inputs)\r\n\r\nmodel = MyModel()\r\nmodel.compile(loss=\"mse\", optimizer=\"nadam\")\r\n\r\nX = tf.random.uniform((100, 10))\r\ny = tf.random.uniform((100, 1))\r\nhistory = model.fit(X, y, epochs=2)\r\n```\r\nbut adding to class \r\n```python\r\n    def build(self, batch_input_shape):\r\n        super().build(batch_input_shape)\r\n```\r\nleads to raising reported exception. With following code:\r\n```python\r\nmodel = MyModel()\r\nmodel.build((None, 10))\r\nmodel.compile(loss=\"mse\", optimizer=\"nadam\")\r\n```\r\nraised `ValueError: Expected a symbolic Tensors or a callable for the loss value. Please wrap your loss computation in a zero argument 'lambda'.`", "FYI, I ran this code in several TensorFlow versions:\r\n* 2.0.4: no error\r\n* 2.1.0: no error\r\n* 2.1.3: no error\r\n* 2.2.0rc0: InaccessibleTensorError\r\n* 2.2.0: InaccessibleTensorError\r\n* 2.3.0: InaccessibleTensorError\r\n* 2.4.1: InaccessibleTensorError\r\n\r\nSo it looks like the regression happened in 2.2.0rc0. Hope this helps.", "Was able to reproduce the issue in TF v2.5,please find the gist [here](https://colab.research.google.com/gist/sushreebarsa/f2c4b208c085dd2c335cc46b4d3dc8e1/untitled44.ipynb)..Thanks !", "I've tried to create a pull request but it seems that problem is complex enough.\r\nIn 2.2.0 code of `Network.build` was changed to call `Layer.build` instead of call `_track_layers`. And in turn `Layer.build` calls `Layer.call`.\r\nSo method `MyModel.call` executes twice: while building layer and then while calling it. And model had two losses: `Mean` and `Model/mean`.\r\nLooks like any side effects in `call` will introduce errors.", "@aprimostka As mentioned by @fchollet , the following (workaround) worked\r\n\r\n```\r\n    def build(self, batch_input_shape):\r\n        self.output_layer = keras.layers.Dense(1)\r\n        self.output_layer.build(batch_input_shape)\r\n        # super().build(batch_input_shape)\r\n```\r\n\r\n[Here](https://colab.research.google.com/gist/jvishnuvardhan/15360ea5e34cf7a3a0a10802db50a2e0/untitled44.ipynb) is a gist for reference. Thanks!\r\n\r\nIf there is any actionable PRs, please feel free to open them in [keras-team/keras](https://github.com/keras-team/keras/issues) repository. \r\n\r\nPlease note that Keras development moved to keras-team/keras repository to focus entirely on only keras. Thanks! ", "@jvishnuvardhan Even \r\n```\r\ndef build(self, batch_input_shape):\r\n        self.output_layer = keras.layers.Dense(1)\r\n        # self.output_layer.build(batch_input_shape)\r\n        # super().build(batch_input_shape)\r\n```\r\nwill be a working workaround for this code. But as you mentioned this is not the solution.\r\nAlso, I have written code changes that remove this error in the first comment. But I don't understand the guts of Keras and didn't find any documentation to understand them in a reasonable time. \r\nAnyway, my original code example seems to be legit so the bug still exists.", "@aprimostka Can you please open a PR in [keras-team/keras](https://github.com/keras-team/keras/issues) repository to update the code/bug so that it will be helpful for the community. Thanks for your contribution. ", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46858\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46858\">No</a>\n"]}, {"number": 46856, "title": "TFLite: tools: make: remove test_delegate_providers.cc from the build resources for libtensorflow-lite.a", "body": "lite/kernel/test_delegate_providers.cc should not be include in\r\nlibtensorflow-lite.a but it was not par of CORE_CC_EXCLUDE_SRCS because the\r\nfile syntax was not recognized as an excluded file.\r\nThis patch propose to exclude all the file containing in *test*.cc.\r\n\r\nSigned-off-by: Vincent ABRIOU <vincent.abriou@st.com>", "comments": []}, {"number": 46855, "title": "Training freezed at last batch of first epoch , not starting validation generator", "body": "[logs.txt](https://github.com/tensorflow/tensorflow/files/5911742/logs.txt)\r\n\r\n\r\nLog file attached \r\n\r\nCode \r\n\r\n```\r\n#!/usr/bin/env python\r\n# coding: utf-8\r\n\r\n# In[1]:\r\n\r\n\r\nfrom PIL import Image\r\nimport os \r\nimport cv2\r\nimport numpy as np\r\nimport time\r\nfrom scipy import ndimage\r\nimport random\r\nfrom model import Deeplabv3\r\nimport tensorflow as tf\r\n# import numpy as np\r\n# sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))\r\nimport math\r\nfrom tensorflow.python.keras.applications.imagenet_utils import preprocess_input\r\nfrom keras.utils import to_categorical\r\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\r\nfrom tensorflow.keras.callbacks import TensorBoard\r\nimport matplotlib.pyplot as plt\r\n\r\n\r\n# In[2]:\r\n\r\n\r\npd_dir='../../../ssd_scratch/cvit/ritvik_agr/Combined_Dataset/'\r\n#path to provided foreground images\r\nfg_path_1 = pd_dir+'Training_set/Adobe-licensed images/fg/'\r\n#path to provided alpha mattes\r\na_path_1 = pd_dir+'Training_set/Adobe-licensed images/alpha/'\r\n#path to provided foreground images\r\nfg_path_2 = pd_dir+'Training_set/Other/fg/'\r\n#path to provided alpha mattes\r\na_path_2 = pd_dir+'Training_set/Other/alpha/'\r\nbg_path_train = pd_dir+'train2014/'\r\nbg_path_val=pd_dir+'VOCtrainval_11-May-2012/VOCdevkit/VOC2012/JPEGImages/'\r\nval_path_a=pd_dir+'Test_set/Adobe-licensed_images/alpha/'\r\nval_path_fg=pd_dir+'Test_set/Adobe-licensed_images/fg/'\r\nbatch_size_user=20\r\ninput_image_shape=512\r\n#Path to folder where you want the composited images to go\r\n# out_path = 'merged/'\r\n\r\n\r\n# In[3]:\r\n\r\n\r\n# def composite4(fg, bg, a, w, h):\r\n#     bbox = fg.getbbox()\r\n#     bg = bg.crop((0,0,w,h))\r\n#     fg_list = fg.load()\r\n#     bg_list = bg.load()\r\n#     a_list = a.load()\r\n#     for y in range(h):\r\n#         for x in range (w):\r\n#             alpha = a_list[x,y] / 255\r\n#             t = fg_list[x,y][0]\r\n#             t2 = bg_list[x,y][0]\r\n#             if alpha >= 1:\r\n#                 r = int(fg_list[x,y][0])\r\n#                 g = int(fg_list[x,y][1])\r\n#                 b = int(fg_list[x,y][2])\r\n#                 bg_list[x,y] = (r, g, b, 255)\r\n#             elif alpha > 0:\r\n#                 r = int(alpha * fg_list[x,y][0] + (1-alpha) * bg_list[x,y][0])\r\n#                 g = int(alpha * fg_list[x,y][1] + (1-alpha) * bg_list[x,y][1])\r\n#                 b = int(alpha * fg_list[x,y][2] + (1-alpha) * bg_list[x,y][2])\r\n#                 bg_list[x,y] = (r, g, b, 255)\r\n#     return bg\r\n\r\n\r\n# In[4]:\r\n\r\n\r\ndef generate_trimap(alpha):\r\n   k_size = random.choice(range(2, 5))\r\n   iterations = np.random.randint(5, 15)\r\n   kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (k_size, k_size))\r\n   dilated = cv2.dilate(alpha, kernel, iterations=iterations)\r\n   eroded = cv2.erode(alpha, kernel, iterations=iterations)\r\n   trimap = 128*np.ones(alpha.shape, dtype=np.uint8)\r\n   trimap[eroded >= 255] = 255\r\n   trimap[dilated <= 0] = 0\r\n   return trimap\r\n\r\n\r\n# In[5]:\r\n\r\n\r\n# def composited_image(im_name,bg_name):\r\n#     if os.path.isfile(fg_path_1+im_name):\r\n#         im = Image.open(fg_path_1 + im_name);\r\n#         a = Image.open(a_path_1 + im_name);\r\n#     elif os.path.isfile(fg_path_2+im_name):\r\n#         im = Image.open(fg_path_2 + im_name);\r\n#         a = Image.open(a_path_2 + im_name); \r\n#     else:\r\n#         im = Image.open(val_path_fg + im_name);\r\n#         a = Image.open(val_path_a + im_name); \r\n        \r\n    \r\n    \r\n#     bbox = im.size\r\n#     w = bbox[0]\r\n#     h = bbox[1]\r\n    \r\n#     if im.mode != 'RGB' and im.mode != 'RGBA':\r\n#         im = im.convert('RGB')\r\n    \r\n#     if os.path.isfile(bg_path_train+bg_name):\r\n#         bg = Image.open(bg_path_train + bg_name);\r\n#     else:\r\n#         bg=Image.open(bg_path_val+bg_name)\r\n        \r\n#     if bg.mode != 'RGB':\r\n#         bg = bg.convert('RGB')\r\n\r\n#     bg_bbox = bg.size\r\n#     bw = bg_bbox[0]\r\n#     bh = bg_bbox[1]\r\n#     wratio = w / bw\r\n#     hratio = h / bh\r\n#     ratio = wratio if wratio > hratio else hratio     \r\n#     if ratio > 1:        \r\n#         bg = bg.resize((math.ceil(bw*ratio),math.ceil(bh*ratio)), Image.BICUBIC)\r\n#     out = composite4(im, bg, a, w, h)\r\n#     return cv2.resize(np.array(out),(512,512)),cv2.resize(generate_trimap(np.array(a)),(512,512))\r\n\r\n\r\n# In[6]:\r\n\r\n\r\ndef combined_img(im_name,bg_name):\r\n    if os.path.isfile(fg_path_1+im_name):\r\n        foreground = Image.open(fg_path_1 + im_name);\r\n        alpha = cv2.imread(a_path_1 + im_name);\r\n    elif os.path.isfile(fg_path_2+im_name):\r\n        foreground = Image.open(fg_path_2 + im_name);\r\n        alpha = cv2.imread(a_path_2 + im_name); \r\n    else:\r\n        foreground = Image.open(val_path_fg + im_name);\r\n        alpha = cv2.imread(val_path_a + im_name); \r\n\r\n    if foreground.mode != 'RGB':\r\n        foreground = foreground.convert('RGB')\r\n    \r\n    if os.path.isfile(bg_path_train+bg_name):\r\n        background = Image.open(bg_path_train + bg_name);\r\n    else:\r\n        background=Image.open(bg_path_val+bg_name)\r\n        \r\n    if background.mode != 'RGB':\r\n        background = background.convert('RGB')\r\n    \r\n    foreground = np.array(foreground)\r\n    background = np.array(background)\r\n\r\n    background=cv2.resize(background,dsize=(foreground.shape[1],foreground.shape[0]))\r\n    # Convert uint8 to float\r\n    foreground = foreground.astype(float)\r\n    background = background.astype(float)\r\n\r\n    # Normalize the alpha mask to keep intensity between 0 and 1\r\n    alpha = alpha.astype(float)/255\r\n\r\n    # Multiply the foreground with the alpha matte\r\n    foreground = cv2.multiply(alpha, foreground)\r\n\r\n    # Multiply the background with ( 1 - alpha )\r\n    background = cv2.multiply(1.0 - alpha, background)\r\n\r\n    # Add the masked foreground and background.\r\n    outImage = cv2.add(foreground, background)\r\n    return cv2.resize(np.array(outImage),(512,512)),cv2.resize(generate_trimap(np.array(255*alpha)),(512,512))[:,:,0]\r\n\r\n\r\n# In[7]:\r\n\r\n\r\ndef train_gen():\r\n    with open(pd_dir+'Training_set/training_fg_names.txt') as f:\r\n        fg_files = np.array(f.read().splitlines()).reshape((-1,1))\r\n    with open(pd_dir+'Training_set/training_bg_names.txt') as f:\r\n        bg_files = np.array(f.read().splitlines()).reshape((len(fg_files),-1))\r\n    \r\n    n=0\r\n    x_img=[]\r\n    y_img=[]\r\n    while True:\r\n        i=np.random.randint(0,431)\r\n        j=np.random.randint(0,100)\r\n        while bg_files[i,j]=='-1':\r\n            i=np.random.randint(0,431)\r\n            j=np.random.randint(0,100)\r\n        x,y=combined_img(fg_files[i,0],bg_files[i,j])\r\n        x_img.append(x)\r\n        y=to_categorical(y//127,num_classes=3)\r\n        y_img.append(y)\r\n        bg_files[i,j]=-1        \r\n        n+=1\r\n        if n==batch_size_user:\r\n            yield preprocess_input(np.array(x_img),mode='tf'),np.array(y_img)\r\n            n=0\r\n            x_img=[] \r\n            y_img=[]\r\n\r\n\r\n# In[8]:\r\n\r\n\r\ndef val_gen():\r\n    with open(pd_dir+'Test_set/test_fg_names.txt') as f:\r\n        val_fg_files = np.array(f.read().splitlines()).reshape((-1,1))\r\n    with open(pd_dir+'Test_set/test_bg_names.txt') as f:\r\n        val_bg_files = np.array(f.read().splitlines()).reshape((len(val_fg_files),-1))\r\n    n=0\r\n    x_img=[]\r\n    y_img=[]\r\n    while True:\r\n        i=np.random.randint(0,50)\r\n        j=np.random.randint(0,20)\r\n        while val_bg_files[i,j]=='-1':\r\n            i=np.random.randint(0,50)\r\n            j=np.random.randint(0,20)\r\n        x,y=combined_img(val_fg_files[i,0],val_bg_files[i,j])\r\n        x_img.append(x)\r\n        y=to_categorical(y//127,num_classes=3)\r\n        y_img.append(y)\r\n        val_bg_files[i,j]=-1        \r\n        n+=1\r\n        if n==batch_size_user:\r\n            yield preprocess_input(np.array(x_img),mode='tf'),np.array(y_img)\r\n            n=0\r\n            x_img=[] \r\n            y_img=[]\r\n\r\n\r\n# In[ ]:\r\n\r\n\r\n\r\n\r\n\r\n# In[9]:\r\n\r\n\r\nmodel_1=Deeplabv3(backbone='xception')\r\nmodel=Deeplabv3(backbone='xception',classes=3)\r\nfor l_tg,l_sr in zip(model.layers[:-2],model_1.layers[:-2]):\r\n        l_tg.set_weights(l_sr.get_weights())\r\ndel model_1\r\nfor l in model.layers[:356]:\r\n    l.trainable=False\r\ncheckpoint = ModelCheckpoint(\"./best_model.h5\", monitor='val_loss', verbose = 1, save_best_only=True, mode = 'auto')\r\nearlystop =  EarlyStopping(monitor='val_loss', min_delta=0.01, patience=5, verbose =1, mode=\"auto\", restore_best_weights=True)\r\ntb_callback=TensorBoard(log_dir=\"logs_tb/{}\".format(int(time.time())),histogram_freq=1)\r\nmodel.summary()\r\n\r\n\r\n# In[11]:\r\n\r\n\r\nmodel.compile(optimizer='adam', loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True))\r\n\r\n\r\n# In[14]:\r\n\r\n\r\nmodel.fit(train_gen(),steps_per_epoch=43100//batch_size_user,validation_data=val_gen(),validation_steps=1000//batch_size_user,epochs=100,callbacks=[checkpoint, earlystop,tb_callback])\r\n\r\n\r\n# In[ ]:\r\n\r\n\r\n\r\n```\r\n\r\n\r\n\r\n", "comments": ["@ritvikagrawal1 Can you please share a simple standalone code to reproduce the issue? I tried your code in the [gist](https://colab.research.google.com/gist/jvishnuvardhan/b7e22b438e79b0d20cc81d0b4d7e9a21/untitled.ipynb). It throws some errors. Can you please make it standalone (adding cloning model repo, etc).\r\n\r\nCan you also mention what TF version you have used and add any more details that you think will help us resolve this faster. Thanks!", "@jvishnuvardhan \r\nplease clone this repo: https://github.com/bonlime/keras-deeplab-v3-plus\r\nand additionally, add the code in a new file I mentioned above.", "@jvishnuvardhan \r\nin case if dataset is not accessible, you can try on any custom images\r\ni/p size - 512,512,3\r\no/p size - 512,512,3 (one-hot)", "in order to make code run, you can consider np.ones((512,512,3)) as both input-output @jvishnuvardhan ", "@ritvikagrawal1 It would really helpful if you provide a SIMPLE standalone code to reproduce the issue. It will also help minimizing back and forth communications and reach a resolution. Generally, we would ask the users to post any support related questions (with long code) to post them in Stackoverflow where SO team will resolve those issues. Thanks!", "@ritvikagrawal1 \r\nI don't think the training froze in the first place. Note that one batch of your data took 15 seconds to train. The validation data consists of 100 batches, which took 25 minutes to train on the last batch, looking at your logs. Thus, the validation of 100 batches will take about the same time, as the model is extremely complex. This may lead you into thinking that the training/validation has froze. \r\nI highly recommend using TensorFlow's in-built image preprocessing methods and using tf.data and @tf.function decorator. It will make the pipeline much faster, if used correctly. \r\nHope this helps.\r\n ", "@ritvikagrawal1 from your log, it looks like  you wanted to use GPU but it was not detecting GPU because some of the GPU related libraries that are missing. As your model is complex and was running on cpu, it was taking longer time. May be you can open a new issue related to build/install of TF. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 46854, "title": "Windows GUI application: ptxas.exe spawns a blank console window", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 Professional\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): Source\r\n- TensorFlow version (use command below): 2.4.0\r\n- Python version: N/A\r\n- Bazel version (if compiling from source): Unknown\r\n- GCC/Compiler version (if compiling from source): Visual Studio 2019\r\n- CUDA/cuDNN version: 10.1\r\n- GPU model and memory: GeForce GTX 1070\r\n\r\n**Describe the current behavior**\r\n\r\nWhen running our application that uses Tensorflow through a graphical interface, a command prompt window quickly appears and disappears the first time Tensorflow is used in the application.\r\n\r\n**Describe the expected behavior**\r\n\r\nNo command prompt window should appear.\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n```c++\r\n#include <windows.h>\r\n#include <iostream>\r\n#include <vector>\r\n\r\n#include <tensorflow/c/c_api.h>\r\n\r\nvoid deallocator(void* data, size_t, void*)\r\n{\r\n    delete[] static_cast<float*>(data);\r\n}\r\n\r\n// Standard \"console\" main: no problem\r\n// int main() \r\n\r\n// Windows \"GUI\" main: problem occurs\r\nint CALLBACK WinMain(_In_ HINSTANCE, _In_opt_ HINSTANCE, _In_ LPSTR, _In_ int)\r\n{\r\n    std::vector<unsigned char> config_opts =\r\n    {\r\n        0x32, 0xe, 0x9, 0x9a, 0x99, 0x99, 0x99, 0x99,\r\n        0x99, 0xb9, 0x3f, 0x20, 0x1, 0x2a, 0x1, 0x30, 0x38, 0x1\r\n    };\r\n\r\n    TF_Status* status = TF_NewStatus();\r\n    TF_Graph* graph = TF_NewGraph();\r\n    TF_SessionOptions* options = TF_NewSessionOptions();\r\n    TF_SetConfig(options, static_cast<const void*>(config_opts.data()), config_opts.size(), status);\r\n\r\n    const char* const tag = \"serve\";\r\n    TF_Session* session = TF_LoadSessionFromSavedModel(options, nullptr, \"model\", &tag, 1, graph, nullptr, status);\r\n\r\n    TF_Output graph_input_tensor = { TF_GraphOperationByName(graph, \"input_tensor_name\"), 0 };\r\n    TF_Output graph_output_tensor = { TF_GraphOperationByName(graph, \"output_tensor_name\"), 0 };\r\n\r\n    const int64_t image_size = 256;\r\n    const size_t image_area = image_size * image_size;\r\n    int64_t input_dimensions[4] = { 1, image_size, image_size, 1 };\r\n    const uint64_t buffer_size = sizeof(float) * image_area;\r\n\r\n    void* buffer_data = new float[image_area];\r\n\r\n    TF_Tensor* const input_tensor = TF_NewTensor(TF_FLOAT, input_dimensions, 4, buffer_data, buffer_size, &deallocator, nullptr);\r\n\r\n    TF_Tensor* output_tensor = nullptr;\r\n    TF_SessionRun(session, nullptr, &graph_input_tensor, &input_tensor, 1,\r\n        &graph_output_tensor, &output_tensor, 1, nullptr, 0, nullptr, status);\r\n\r\n    if (output_tensor) TF_DeleteTensor(output_tensor);\r\n    if (input_tensor)  TF_DeleteTensor(input_tensor);\r\n    if (session)       TF_DeleteSession(session, status);\r\n    if (options)       TF_DeleteSessionOptions(options);\r\n    if (graph)         TF_DeleteGraph(graph);\r\n    if (status)        TF_DeleteStatus(status);\r\n\r\n    return 0;\r\n}\r\n```\r\n\r\nNB: To trigger the problem, you need the following pre-requisites:\r\n - a saved model folder (the one we use is proprietary, I cannot share it, but any model should do)\r\n - a Windows machine with a CUDA-capable GPU\r\n - the CUDA 10.x SDK installed on the machine\r\n\r\nIf you compile and run the code above, you should experience the issue. If you comment out the ``WinMain`` line and use the standard ``main`` entry point, the problem disappears.\r\n\r\nI traced it down to Tensorflow spawning a sub-process to run ``ptxas.exe`` using the Windows API function ``CreateProcess``. This Windows API function [is called without specifying any \"process creation flag\" for the new process](https://github.com/tensorflow/tensorflow/blob/14cd0d3440908d4f8b4a9a557bfc88cf6ddaaeaf/tensorflow/core/platform/windows/subprocess.cc#L269). According to the [Windows API documentation](https://docs.microsoft.com/en-us/windows/win32/procthread/process-creation-flags), the flag ``CREATE_NO_WINDOW`` should be provided to avoid the sub-process creating any window (in this case, ``ptxas.exe`` opening a blank console window).\r\n\r\nThe different behavior of ``CreateProcess`` for GUI vs console applications doesn't seem to be documented (Edit: it is. The default behavior is to inherit the console of the parent process, but if the parent process has no console, a new one is created). But definitely the flag ``CREATE_NO_WINDOW``  should be passed, since the intent is just to run a console application in the background, not to open a new window for the user to interact with.\r\n\r\nTo be clear:\r\n - The problem won't occur if the main program is compiled as a console application, because ptxas.exe will then just reuse the console window of the main process.\r\n - The problem won't occur if the CUDA SDK is not installed on the machine, as ptxas.exe won't be found and won't be executed. I don't know if there are other instances where this program can end up in the system PATH, hence be found by Tensorflow.\r\n - AFAIK, the problem won't occur with CUDA 11 because from this version on, ptxas is a DLL and not an EXE.\r\n - The above is specific to ptxas.exe, but the root of the problem isn't. I don't know if Tensorflow uses CreateProcess for other purposes. If so, it will be affected in a similar manner.", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46854\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46854\">No</a>\n"]}, {"number": 46852, "title": "experimental apis in iOS pod is missing.", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): v2.4\r\n- Are you willing to contribute it (Yes/No): No\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nexperimental apis  in iOS pod is missing.\r\n\r\n**Will this change the current api? How?**\r\nNo\r\n\r\n**Who will benefit with this feature?**\r\n\r\n**Any Other info.**\r\n", "comments": ["@songww, \r\nCan you please elaborate. Also, can you please specify a use case with respect to this request. Thanks! ", "Invoke `TfLiteInterpreterResetVariableTensors` .\r\nthe results of prediction for same inputs super difference within one interpreter.", "It's still not clear what the issue is. \r\n\r\n> experimental apis in iOS pod is missing.\r\n\r\n> Invoke TfLiteInterpreterResetVariableTensors .\r\n\r\nAre you saying that you'd like this API to be added to the iOS Cocoapods?", "> Are you saying that you'd like this API to be added to the iOS Cocoapods?\r\n\r\nYes.\r\n", "Seems APIs in `tensorflow/lite/c/c_api_experimental.h` are not exported to to CocoaPods for now, not sure if we have plans to do so. Assigning @yyoon for further information.", "@yyoon  Any plan for that?", "Seems reasonable to add, given that the same feature has been available on Android side for a while. Will add this feature soon.", "> Seems reasonable to add, given that the same feature has been available on Android side for a while. Will add this feature soon.\r\n\r\nThanks.", "Hi @songww. I believe this should be done as #49313 is merged. This will be included in the next stable release, and also should be available through nightly builds in the meantime. Please let us know if you still have issues."]}, {"number": 46851, "title": "TF 2.5 nightly CUDA driver check failed ", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): linux ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version: 2.5.0-dev20210202\r\n- Python version: 3.6.9\r\n- Installed using virtualenv? pip? conda?: Pip \r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 11.0/8.0.4\r\n- GPU model and memory: 2 x RTX 3090 w/ 24GB\r\n\r\n\r\n**Describe the problem**\r\nI have installed the tensorflow 2.5 nightly builds: \r\n```\r\npip install tf-nightly-gpu\r\npip install tf-nightly\r\n```\r\ninto a virtual environment to try and address performance issues with using a dual RTX 3090 setup. When I try and execute the python script I get the following error from the CUDA driver: \r\n```\r\n2021-02-02 09:48:40.071972: F tensorflow/stream_executor/cuda/cuda_driver.cc:1289] Check failed: context != nullptr success should entail non-null context\r\n```\r\n\r\nI assume this might be linked to the CUDA/cuDNN revision being used but I can't find any instructions as to the versions being of CUDA/cuDNN being expected. \r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n```\r\npip install tf-nightly-gpu\r\npip install tf-nightly\r\n\r\n**run python script** \r\n\r\n```\r\n\r\nN.B. the script is working as it executes under other versions of TF. \r\n\r\n", "comments": ["@LastHorizon \r\n\r\nCan you try with CUDA 11.1 and see if the issue still persists?\r\nThanks!", "@ravikyram \r\n\r\nThe following have been installed and the problem still persists \r\n\r\nlibnvinfer7_7.2.2-1+cuda11.1_amd64.deb \r\ncuda-11-1\r\nlibcudnn8=8.0.4.30-1+cuda11.1\r\nlibcudnn8=8.0.4.30-1+cuda11.1\r\nlibnvinfer7=7.2.2-1+cuda11.1 \r\nlibnvinfer-dev=7.2.2-1+cuda11.1 \r\nlibnvinfer-plugin7=7.2.2-1+cuda11.1\r\n\r\n", "try cuda 11.0 and cudnn8.0.2 if rtx3090\r\nI worked successful.\r\nand cuda 11.1 and cudnn 8.0.4 worked on  rtx3080 but cannot work on rtx3090\r\n\r\n\r\n", "@Saptr,\r\nCan you please let us know if the above comment helped you. Thanks! ", "> @Saptr,\r\n> Can you please let us know if the above comment helped you. Thanks!\r\n\r\n@rmothukuru I think you pinged the wrong guy", "Yeah, sorry.\r\n@LastHorizon,\r\nCan you please let us know if the [above comment](https://github.com/tensorflow/tensorflow/issues/46851#issuecomment-773078880) helped you. Thanks!", "@rmothukuru \r\nAfter downgrading to libcudnn 8.0.02.39-1+cuda11.0 and upgrading tf-nightly-gpu through pip, I can report the tf-nightly build is now running. \r\n\r\nI am not getting the expected performance boosts from the GPUs though when compared to the old 2060s ", "@LastHorizon,\r\nAs the issue regarding Installation is resolved, Can you please close this issue and raise a new issue related to the performance of your GPUs. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46851\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46851\">No</a>\n"]}, {"number": 46850, "title": "Issue is not managed well", "body": "Friends, I opened this issue https://github.com/tensorflow/tensorflow/issues/46315 already 3 weeks ago and it look like it is not prioritized and no ETA.... And actually for me it looks like \"talking\" and not \"doing\" progress.\r\nI would like to understand if it is regular situation when the updates from support side come a week after ?\r\n\r\nThanks\r\n", "comments": ["@MaxxTr,\r\nI have gone through #46315 and was unable to reproduce the issue. I am facing an `AssertionError` while running the code, please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/9355221e3586c753152bfdd9823a4247/46315.ipynb#scrollTo=vezHfbbD89dF).\r\n\r\nThe zip file you have provided is fairly complicated and it would be difficult for us to pinpoint the source of the error. \r\n\r\nCould you please get the example down to the simplest possible repro and provide a **minimal** code snippet which we can copy/paste and run on our end. Thanks!", "Please don't create issues to talk about other issues. It just creates work for the triage team.\r\n\r\nClosing as duplicate.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46850\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46850\">No</a>\n", "@mihaimaruseac once there was no answer on the original thread I didn't have other solution then open a duplication", "You can comment back on that thread to resurface it."]}, {"number": 46848, "title": "LinearRegression Example in ForwardAccumulator docstring has an error", "body": "## URL(s) with the issue:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/85c8b2a817f95a3e979ecd1ed95bff1dc1335cff/tensorflow/python/eager/forwardprop.py#L234\r\n\r\n## Description of issue (what needs changing):\r\n\r\nI was trying to understand precisely how ForwardAccumulator.jvp works and was working through the example to which I have linked. From computing by hand what I believed to be the correct jvp formula, and comparing it to the linear regression code I found that in the line\r\n\r\n  ...   loss = tf.reduce_sum((dense(x) - tf.constant([1., -1.])) ** 2.)\r\n\r\nthe target \r\ntf.constant([1., -1.]) \r\nwhich I would call 'y', should be reshaped, for example replaced by \r\ntf.constant([[1.], [-1.]]) \r\n\r\nThe code as it stands introduces a multiplicative factor of n in the loss function where n is the number of samples. This same problem occurs in other places in this docstring. \r\n\r\nWould it be possible to include somewhere in this docstring a formula for the jacobian-vector-product?\r\n", "comments": ["Nice catch, I have a fix for the broadcasting issue pending.\r\n\r\n> Would it be possible to include somewhere in this docstring a formula for the jacobian-vector-product?\r\n\r\nAre you referring to a formula for the JVP of one of the examples, or just JVPs in general?", "\r\n> Are you referring to a formula for the JVP of one of the examples, or just JVPs in general?\r\n\r\nwell I thought just in general, write the formula for the JVP. Its a very simple formula but oddly enough I found it hard to find a precise reference. Im not sure how latex is rendered in the documentation environment however. I know github is a bit slack with latex.\r\n\r\n\r\n"]}, {"number": 46847, "title": "Hi everyone, I want to look at the person_detect.tflite model you mentioned in Arduino IDE ESP32 person detection code, I want to look at the input layer of it, my beetle classifier has 96 by 96 and is grayscale so it is 1 x 96 x96 x1, but I am not sure if I can modify the person detection code to detect beetle or cat and dog TFlite converted to c model. Would you please provide the person_detect.tflite model available online? ", "body": "@tensorflow/micro\r\n\r\n**System information**\r\n- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- TensorFlow installed from (source or binary):\r\n- Tensorflow version (commit SHA if source):\r\n- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.):\r\n\r\n**Describe the problem**\r\n\r\n**Please provide the exact sequence of commands/steps when you ran into the problem**\r\n\r\n", "comments": ["Also Would you please create a tutorial document, showing steps from TFLite to ESP 32 Tensorflow with a Colab example for image classification? like cat-dog classification or flower classification steps after TFLite.", "Hi, I haven't tried this myself, but with the tool added here: https://github.com/tensorflow/tensorflow/pull/42837\r\nYou should be able to get the tflite file from the c array model.\r\n", "@Paryavi I have a cats_and_dogs example here with Jupyter notebook here: https://github.com/vikramdattu/tensorflow/tree/master/tensorflow/lite/micro/examples/cats_and_dogs  ", "@Paryavi,\r\n\r\nCan you confirm if the above link provided by @vikramdattu helps in resolving this issue? Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Thanks, Sanat and @vikramdattu <https://github.com/vikramdattu>, I got busy\nwith other camera board detection projects like OpenMV, also college class\nworks.\n\nBefore that, I tried training the ESP32 classification models with edge\nimpulse framework;\nhttps://www.edgeimpulse.com/blog/add-sight-to-your-esp32\nIt was not very accurate, so I will check Vikram's design eventually, it is\ngreat to have a framework like it.\n\nThanks,\nMohsen\n\nOn Wed, Nov 10, 2021 at 4:32 AM google-ml-butler[bot] <\n***@***.***> wrote:\n\n> This issue has been automatically marked as stale because it has no recent\n> activity. It will be closed if no further activity occurs. Thank you.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/46847#issuecomment-965277163>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AO7JQRBDJDXXUTHTPQ3HJ3LULJ67BANCNFSM4W6FB4ZA>\n> .\n> Triage notifications on the go with GitHub Mobile for iOS\n> <https://apps.apple.com/app/apple-store/id1477376905?ct=notification-email&mt=8&pt=524675>\n> or Android\n> <https://play.google.com/store/apps/details?id=com.github.android&referrer=utm_campaign%3Dnotification-email%26utm_medium%3Demail%26utm_source%3Dgithub>.\n>\n>\n", "Thanks for the update @Paryavi, In this case, Can you close this issue and create a new one in future if you face any problems? Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46847\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46847\">No</a>\n"]}]